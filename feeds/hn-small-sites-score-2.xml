<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sun, 13 Sep 2020 20:23:50 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sun, 13 Sep 2020 20:23:50 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Cybersecurity and AI in Health Applications]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24450431">thread link</a>) | @xxlcloudinc
<br/>
September 11, 2020 | https://codecoda.com/en/blog/entry/cybersecurity-and-ai-in-health-applications | <a href="https://web.archive.org/web/*/https://codecoda.com/en/blog/entry/cybersecurity-and-ai-in-health-applications">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="description">
<p>Cyber-crimes affect companies from all industries like IT, Legal, Education, Manufacturing, Finance. Healthcare is one of the most targeted since this sector relies on the perpetual exchange of big volumes of valuable data.</p>
<div><p>Amid a health crisis, a cyberattack targeting healthcare IT systems around the world takes place every three days <a href="#ref1"><sup>[1]</sup></a>.</p><p>Since the beginning of the second decade of this millennium, cyber threats and data breaches increase rate has <a href="https://www.industryweek.com/technology-and-iiot/article/22026828/cyberattacks-skyrocketed-in-2018-are-you-ready-for-2019" target="_blank" rel="nofollow">spiked disturbingly</a>. Cyber regulations are evolving and requiring healthcare facilities to address more than just the patient’s illnesses. Also responsible for the security of their data, they make health care information security a priority. And they are pushed to do it. Any intrusion on the integrity of internal data can have catastrophic consequences for patients and healthcare facilities.</p></div>
<figure><img src="https://cdn.codecoda.com/img/pixel.gif" data-plugin-lazyload="" data-plugin-options="{'effect' : 'fadeIn', 'speed' : 'fast'}" data-original="https://cdn.codecoda.com/themes/user/site/default/asset/img/blog/healthcare-breach-barometer-2016-2019.jpg" alt="Healthcare Data Breaches 2016-2019">
<figcaption><small>Healthcare Data Breaches 2016-2019</small></figcaption>
</figure>
<div><p>For healthcare companies, a breach of security is very costly. In this critical context, the health sector must be aware and ready to do everything possible to secure their health applications and data banks, by channeling enough technological and financial resources to them. The data collected in the health sector is particularly sensitive because most records become a significant liability when compromised. Healthcare organizations are prime targets for cybercriminals seeking to gain valuable information by exploiting vulnerable security systems. The risk of a breach is reduced by adopting security measures with mighty authentication methods, paired with employee training – <a href="https://www.forbes.com/sites/insights-fortinet/2019/08/27/the-importance-of-training-cybersecurity-awareness-as-a-firewall/#2693a2cd8b4b%20target=" _blank"="" rel="nofollow">a necessary follow-up action</a> that some companies tend to undermine, and, therefore, risk turning into a headline in cybersecurity news sites.</p><p>One specific area of healthcare is particularly susceptible to cyberattacks, and criminals often use it to create a breakpoint - the company’s supply chain. Because health organizations rely on multiple suppliers and external services, they support a vast network where massive data is on a constant exchange. Securing such an intense pipeline of information flow is exceptionally difficult, and hackers won’t hesitate to abuse this unfortunate fact.</p><p>In the Healthcare sector, computer systems contain sensitive data and support organizations in the delivery of quality patient services, making them a prime target for extortion attempts. Phishing, in which a cybercriminal poses as a legitimate organization or individual to entice trust, is a common form of attack. Emails have always been a possible point of entry, filled with bogus attachments and links to fake websites. Email breach is of particular concern in healthcare, as staff consistently uses emails to exchange highly valuable data. If an employee’s email login information is stolen or disclosed - including their username and password - they can be used by criminals to gain access to patient records, and based on this employee level of access, possibly leverage even further damage.</p></div>
<h2>Applications at the service of health: pay attention to the data!</h2>
<div><p>The concept of e-health is not technologically innovative. The service itself is not advanced by any means; what is innovative is the main piece of technology it uses. This tech choice consists of the provision of communicating applications allowing, here, to perform specific measures via the combined effort of a peripheral, a service platform (mainly based on cloud technologies) and a communication network <a href="#ref2"><sup>[2]</sup></a>.</p><p>The security principles and techniques applicable to e-health are, therefore, very similar to those considered by suppliers of critical connected systems. The main difference is that medical devices process health data, which is among the most lucrative for cybercriminals. Personal medical records reside under the aegis of restrictive regulations. Such regulations impose special protection to guarantee the integrity of the patient’s privacy.</p><p>New black gold, all the corporate data collected and processed, defines the level of risk for the services that use this information. In the case of e-health, all present vulnerabilities and medical data leak possibilities must be eradicated. Data protection can break the integrity of private data. For example, sensitive information can circulate multiple communication channels and get exposed to a breach. Not even the doctor-patient is entirely bulletproof.</p><p>A data communication channel may temporarily break data integrity. For example, doctor-patient communication is vulnerable to data leaks, despite the security-laden non-disclosure agreement they both approve.</p><p>Of course, sensitive data can be partially <b><a href="https://codecoda.com/en/blog/entry/benefits-of-encryption-technology-for-data-protection">encrypted</a></b> or partially exposed. For example, to explain conditions or medical treatment procedures, doctors use <i>pseudonymization</i>, when communication with their patients. Doctors also use <i>anonymization</i>, when it comes to data as part of statistics or a plan to improve a specific service.</p></div>
<h2>Cybersecurity in the Healthcare sector:</h2>
<p>Healthcare organizations should ensure that they have robust security measures in place to limit the risks of email account compromise <a href="#ref3"><sup>[3]</sup></a>, cyber security threat breaches, and other cyber security threat related incidents. These measures must cover all parameters inherent to <i>people, processes, and technologies</i>:
</p><ul><li><b>Practices and procedures</b> – Strong authentication methods, secure access to applications, systems, and data; Communication with staff and other key stakeholders’ regular updates, as well as reminders of safety behaviors and mandatory actions during safety failure;</li>
<li><b>Supplier Relationships</b> – Cybercriminals can exploit any weak link in a supply chain to gain access to a target. “The existence of strong links between companies within a healthcare ecosystem can compromise an entire ecosystem.” This is why, our latest Healthcare app project, MeTime, features a ‘close-quarters’ environment where vendors, clients and suppliers can safely exchange data while preserving privacy integrity.</li>
<li><b>Log management</b> – Healthcare facilities often use a set of proprietary applications and systems that must be linked together within an IT security framework. LogPoint’s highly flexible cybersecurity software architecture addresses this problem and has become the standard cybersecurity tool for log management in the healthcare industry <a href="#ref4"><sup>[4]</sup></a>. Some of the world’s most advanced hospitals are using our next-generation SIEM solution to protect their patient information.</li>
<li><b>Training</b> – Entry-to-service training, regular reminders, additional training for all staff, and, where appropriate, other stakeholders. Malicious activity isn’t the only activity impacting your organization. Human error - as is the case in any industry - is another risk that deserves attention. Incorrect distribution of information and inappropriate handling of sensitive data puts your organization at high risk for data loss.</li>
<li><b>Ransomware</b> – ransomware is another type of direct cybersecurity threat to the healthcare industry. While this type of attack typically cannot confirm a breach, ransomware has the potential to directly affect the privacy, integrity, and availability of critical systems. It is essential to prepare for the possibility of such an incident and harden your security policies accordingly. The recent spikes in ransomware attacks suggest it is a matter of time when online attackers will cycle toward any possible company. The best move is to expect a blow from that angle and get prepared on that front.</li></ul>
<h2>The potential role of AI for health application security</h2>
<div><p>It is no longer a secret: ensuring the security of information systems is one of the significant challenges in companies. The fight against cybercrime has experienced a small revolution in recent years, thanks to the application of artificial intelligence. Through machine learning, we can discover how threats operate and evolve and use that information for a more precise counter-measure.</p><p>The number one difficulty in cybersecurity is the realization that criminals are always one step ahead of companies: they look for security holes, that someone working for the company is likely to overlook. Also, there is the exponential and ultra-rapid development of <b><a href="https://codecoda.com/en/blog/entry/new-tech-in-ecommerce">new technologies</a></b>, particularly cloud and mobile. Hackers are quick to learn how new tech can be used to their advantage, and cybersecurity experts must keep up, keeping up with their, looking to predict, and dismantle their attempts.</p><p>Most basic security solutions focus on understanding malware and preventing infiltration. Thus, rather than being in action, they will instead react to present and incoming danger. This passive threat-response strategy requires regular updates, among other things, and their use alone proves to be insufficient. A more sophisticated cyber solution finds an ally in Artificial Intelligence (AI). Machines have the intensity and relentlessness needed when battling cyber threats and are preferred tools of veteran cybersecurity experts.</p><p>AI can proactively identify and mitigate a threat even before a patch is developed and released <a href="#ref5"><sup>[5]</sup></a>. Its main advantage is its ability to relieve the human factor of tedious and time-consuming tasks, and this with a better reaction capacity in the treatment of alerts that flood computer systems daily.</p><p>AI then makes it possible to spot, analyze, and respond to cyber-attacks faster than a human. It provides an instrument which, when applied to cybersecurity, improves the efficiency and strengthens the protection of information technologies, for companies constrained by time and resources, financial or human.</p><p>It is on the processing of data between applications that AI can have a considerable impact. Robotics quickly analyzes a large amount of data from which it can spot anomalies or signal potential threats. Machines learn from a growing set of data and, over time, become more and more precise at detecting abnormalities. Today, Machine Learning finally gains the power to support human expertise in decision-making.</p><p>The future of cybersecurity is about embracing and innovating to …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://codecoda.com/en/blog/entry/cybersecurity-and-ai-in-health-applications">https://codecoda.com/en/blog/entry/cybersecurity-and-ai-in-health-applications</a></em></p>]]>
            </description>
            <link>https://codecoda.com/en/blog/entry/cybersecurity-and-ai-in-health-applications</link>
            <guid isPermaLink="false">hacker-news-small-sites-24450431</guid>
            <pubDate>Sat, 12 Sep 2020 06:50:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[EduTech Spyware Is Still Spyware: Proctorio Edition]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24450248">thread link</a>) | @some_furry
<br/>
September 11, 2020 | https://soatok.blog/2020/09/12/edutech-spyware-is-still-spyware-proctorio-edition/ | <a href="https://web.archive.org/web/*/https://soatok.blog/2020/09/12/edutech-spyware-is-still-spyware-proctorio-edition/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<p>Spyware written for educational institutions to flex their muscles of control over students and their families when learning from their home computer is still, categorically, spyware.</p>



<p>Depending on your persuasion, the previous sentence sounds like either needless pedantry, or it reads like tautology. But we need to be clear on our terms.</p>



<ol><li>Educational spyware is still spyware.</li><li>Spyware is categorized as a subset of malware.</li></ol>



<p>When vulnerabilities are discovered in malware, the normal rules of <a href="https://adamcaudill.com/2015/11/19/responsible-disclosure-is-wrong/">coordinated disclosure</a> are out of scope. Are we clear?</p>







<p>So let’s talk about Proctorio!</p>



<figure><div>
<div><blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">For anyone unfamiliar with it, Proctorio is a browser extension used to eliminate cheating through intense surveillance techniques. It records the computer screen while you take the exam to ensure you don’t look anything up. However, it’s more than that. (Thread 1/11)</p>— Cassie (@Angry_Cassie) <a href="https://twitter.com/Angry_Cassie/status/1301360994044850182?ref_src=twsrc%5Etfw">September 3, 2020</a></blockquote></div>
</div><figcaption>The entire thread is unrolled <a href="https://threadreaderapp.com/thread/1301360994044850182.html">here</a>.</figcaption></figure>



<p>I won’t go into the details of Proctorio or why it’s terrible for (especially disadvantaged) students. Read Cassie’s Twitter thread for more context on that. Seriously. I’m not gonna be one of those guys that <em>talks over</em> women, and neither should you.</p>



<p>What I am here to talk about today is these dubious claim about the security of their product:</p>







<h2 id="zero-knowledge">Zero-Knowledge Encryption? OMGWTFBBQ!</h2>



<p>In cryptography, there are a class of algorithms called Zero-Knowledge Proofs. In a Zero-Knowledge Proof, you prove that you possess some fact without revealing any details <em>about</em> the fact.</p>



<p>It’s kind of abstract to think about (and until we’re ready to talk about Pedersen commitments, I’m just going to defer to <a href="https://openprivacy.ca/work/swisspost-scytl-evoting/">Sarah Jamie Lewis</a>), but the only thing you need to know about “Zero Knowledge” in Cryptography is that the output is a boolean (True, False).</p>



<p>You can’t use “Zero Knowledge” <em>anything</em> to encrypt. So “Zero-Knowledge Encryption” is a meaningless buzzword.</p>



<figure><div>
<div><blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">As a cryptographer, I would like details on how on Earth it is using zero knowledge proofs in this situation. In all likelihood they're not doing what "zero knowledge" usually means, which quite frankly has me more worried about the security, not less.</p>— Buchberger's algorithm fan account (@SchmiegSophie) <a href="https://twitter.com/SchmiegSophie/status/1304407483658592256?ref_src=twsrc%5Etfw">September 11, 2020</a></blockquote></div>
</div></figure>



<p>So what are they actually describing when they say Zero Knowledge Encryption?</p>







<p>Okay, so they’ve built their own key distribution system and are encrypting with AES-GCM… and shipped this in a Chrome extension. But before we get to that, look at this <strong>Daily Vulnerability Tests</strong> claim.</p>



<div><figure><img data-attachment-id="1204" data-permalink="https://soatok.blog/soatoktelegrams2020-04/" data-orig-file="https://soatok.files.wordpress.com/2020/08/soatoktelegrams2020-04.png" data-orig-size="512,512" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SoatokTelegrams2020-04" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2020/08/soatoktelegrams2020-04.png?w=300" data-large-file="https://soatok.files.wordpress.com/2020/08/soatoktelegrams2020-04.png?w=512" src="https://soatok.files.wordpress.com/2020/08/soatoktelegrams2020-04.png?w=512" alt="" srcset="https://soatok.files.wordpress.com/2020/08/soatoktelegrams2020-04.png 512w, https://soatok.files.wordpress.com/2020/08/soatoktelegrams2020-04.png?w=150 150w, https://soatok.files.wordpress.com/2020/08/soatoktelegrams2020-04.png?w=300 300w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>Bullshit.</figcaption></figure></div>



<p>Running Nessus (or equivalent) on a cron job isn’t meaningful metric of security. At best, it creates alert fatigue when you accidentally screw up a deployment configuration or forget to update your software for 4+ years. (Y’know, like JsZip 3.2.1, which they bundle.)</p>



<p>A dumb vulnerability scan isn’t the same thing as a routine (usually quarterly) penetration test or a code audit. And if you’re working in cryptography, <em>you better have both</em>!</p>



<h2 id="vulnerability">Timing Leaks in Proctorio’s AES-GCM Implementation</h2>



<p>If you download version 1.4.20241.1.0 of the Proctorio Chrome Extension, run <code>src/assets/J5HG.js</code> through a JS beautifier, and then look at its contents, you will quickly realize this is a JavaScript cryptography library.</p>



<p>Since the “zero knowledge” encryption they’re so proud about uses AES-GCM, let’s focus on that.</p>



<p>Proctorio’s AES-GCM implementation exists in an object called <code>dhs.mode.gcm</code>, which is mildly obfuscated, but contains the following functions:</p>



<ul><li><code>encrypt()</code> – Encrypt with AES-GCM</li><li><code>decrypt()</code> – Decrypt with AES-GCM</li><li><code>aa()</code> – GHASH block multiplication</li><li><code>j()</code> – XOR + GMAC utility function</li><li><code>O()</code> – Called by encrypt() and decrypt(); does all of the AES-CTR + GMAC fun</li></ul>



<p>If you’re not familiar with <a href="https://soatok.blog/2020/05/13/why-aes-gcm-sucks/">AES-GCM</a>, just know this: <a href="https://cryptologie.net/article/361/breaking-https-aes-gcm-or-a-part-of-it/">Timing leaks</a> can be used to leak your GMAC key to outside applications, which completely breaks the authentication of AES-GCM and opens the door to chosen-ciphertext attacks.</p>



<p>So is their implementation of AES-GCM constant-time? Let’s take a look at <code>aa()</code>:</p>


<pre title="">aa: function(a, b) {
  var c, d, e, f, g, h = dhs.bitArray.ba;
  for (e = [0, 0, 0, 0], f = b.slice(0), c = 0; 128 &gt; c; c++) {
    for (
      (d = 0 !== (a[Math.floor(c / 32)] &amp; 1 &lt;&lt; 31 - c % 32)) &amp;&amp; (e = h(e, f)),
        g = 0 !== (1 &amp; f[3]),
        d = 3;
      d &gt; 0;
      d--
    )
      f[d] = f[d] &gt;&gt;&gt; 1 | (1 &amp; f[d - 1]) &lt;&lt; 31;
    f[0] &gt;&gt;&gt;= 1,
    g &amp;&amp; (f[0] ^= -520093696)
  }
  return e
},
</pre>


<p>This is a bit obtuse, but this line leaks the lowest bit of <code>f</code> with each iteration: <code>g = 0 !== (1 &amp; f[3])</code>.</p>



<p>Since <code>f</code> gets bitwise right-shifted 128 times, this actually leaks the bit of every value of <code>f</code> in each block multiplication, since the execution of <code>(f[0] ^= -520093696)</code> depends on whether or not <code>g</code> is set to <code>true</code>.</p>



<div><figure><img data-attachment-id="1387" data-permalink="https://soatok.blog/soatoktelegrams2020-11/" data-orig-file="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-11.png" data-orig-size="512,512" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SoatokTelegrams2020-11" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-11.png?w=300" data-large-file="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-11.png?w=512" src="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-11.png?w=512" alt="" srcset="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-11.png 512w, https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-11.png?w=150 150w, https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-11.png?w=300 300w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>Timing leaks? So much for “zero-knowledge”!</figcaption></figure></div>



<p>Also, they claim to be FIPS 140-2 compliant, but this is how they generate randomness in their cryptography library.</p>



<figure><div>

</div></figure>



<p>(Although, <a href="https://csrc.nist.gov/projects/cryptographic-module-validation-program/validated-modules/search?SearchMode=Basic&amp;Vendor=Proctorio&amp;CertificateStatus=Active&amp;ValidationYear=0">that’s probably a lie</a>.)</p>



<p>To mitigate these vulnerabilities, one needs look no further than <a href="https://soatok.blog/2020/08/27/soatoks-guide-to-side-channel-attacks/#conditional-select">the guide to side-channel attacks</a> I published last month. </p>



<p>(Also, use WebCrypto to generate entropy! What the fuck.)</p>



<h2>If Proctorio is Insecure, What Should We Use Instead?</h2>



<p><strong>Nothing.</strong></p>



<p>Schools that demand students install spyware on their personal computers are only a step removed from domestic abusers who install stalkerware on their victims’ phones.</p>



<p>Proctorio isn’t the problem here, they’re only a symptom.</p>



<p>Schools that insist on violating the integrity and parental dominion of their students’ home computers are the problem here.</p>



<figure><div>
<div><blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">Zoom school is really showing how much of American Education is just about controlling and punishing children and not actually, you know, teaching and educating them</p>— Lawrence of A Labia (@lex_about_sex) <a href="https://twitter.com/lex_about_sex/status/1304156305398140928?ref_src=twsrc%5Etfw">September 10, 2020</a></blockquote></div>
</div><figcaption>Preach!</figcaption></figure>



<p>If you want to ensure the integrity of students’ education, try teaching them about consent and ethical computing. (Y’know, concepts that are fundamentally incompatible with the business model of Proctorio and Proctorio’s competitors.)</p>



<h2 id="timeline">Disclosure Timeline</h2>



<p>Really? <em>Really?</em></p>



<p>This was a zero-day disclosure, because full disclosure is the responsible choice when dealing with spyware. Don’t even @ me.</p>



<div><figure><img data-attachment-id="70" data-permalink="https://soatok.blog/soatok_stickerpack-hacker/" data-orig-file="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-hacker.png" data-orig-size="512,512" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="soatok_stickerpack-hacker" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-hacker.png?w=300" data-large-file="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-hacker.png?w=512" src="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-hacker.png?w=512" alt="" srcset="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-hacker.png 512w, https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-hacker.png?w=150 150w, https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-hacker.png?w=300 300w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>Disclaimer: This security research was conducted by Soatok– some furry on the Internet–while bored on his off-time and does not reflect the opinions of any company.</figcaption></figure></div>



<h2 id="sinkhole">Domains to Sinkhole</h2>



<p>If you’re looking to protect your home network from this spyware, here are a list of domains to sinkhole (i.e. with <a href="https://pi-hole.net/">Pi-Hole</a>).</p>



<ul><li>proctorauth.com</li><li>proctordata.com</li><li>getproctorio.com</li><li>proctor.io</li><li>proctor.in</li><li>az545770.vo.msecnd.net</li></ul>

		</div><!-- .entry-content -->

	</div></div>]]>
            </description>
            <link>https://soatok.blog/2020/09/12/edutech-spyware-is-still-spyware-proctorio-edition/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24450248</guid>
            <pubDate>Sat, 12 Sep 2020 06:09:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: WebGL Rubik's Snake]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24450171">thread link</a>) | @nopjia
<br/>
September 11, 2020 | https://www.iamnop.com/snake/ | <a href="https://web.archive.org/web/*/https://www.iamnop.com/snake/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.iamnop.com/snake/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24450171</guid>
            <pubDate>Sat, 12 Sep 2020 05:49:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Make a Harmonograph?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24449813">thread link</a>) | @alikayaspor
<br/>
September 11, 2020 | https://abakcus.com/diy/how-to-make-a-harmonograph/ | <a href="https://web.archive.org/web/*/https://abakcus.com/diy/how-to-make-a-harmonograph/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<div>
<div id="primary">
<main id="main">
<div data-elementor-type="single" data-elementor-id="951" data-elementor-settings="[]">
<div>
<section data-id="af02520" data-element_type="section">
<div>
<div>
<div data-id="2bf189ef" data-element_type="column">
<div>
<div>
<section data-id="8f0e9bd" data-element_type="section">
<div>
<div>
<div data-id="815ec86" data-element_type="column">
<div>
<div>
<div data-id="67b5cbf" data-element_type="widget" data-widget_type="theme-post-featured-image.default">
<div>
<div>
<picture>
<source type="image/webp" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/01/How-to-make-a-harmonograph-DIY-Project-768x1152.jpg.webp 768w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/01/How-to-make-a-harmonograph-DIY-Project-500x750.jpg.webp 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/01/How-to-make-a-harmonograph-DIY-Project-683x1024.jpg.webp 683w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/01/How-to-make-a-harmonograph-DIY-Project-300x450.jpg.webp 300w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/01/How-to-make-a-harmonograph-DIY-Project.jpg.webp 800w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20768%201152'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 768px) 100vw, 768px">
<img width="768" height="1152" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20768%201152'%3E%3C/svg%3E" alt="How to make a harmonograph DIY Project" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/01/How-to-make-a-harmonograph-DIY-Project-768x1152.jpg 768w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/01/How-to-make-a-harmonograph-DIY-Project-500x750.jpg 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/01/How-to-make-a-harmonograph-DIY-Project-683x1024.jpg 683w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/01/How-to-make-a-harmonograph-DIY-Project-300x450.jpg 300w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/01/How-to-make-a-harmonograph-DIY-Project.jpg 800w" data-lazy-sizes="(max-width: 768px) 100vw, 768px" data-lazy-src="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/01/How-to-make-a-harmonograph-DIY-Project-768x1152.jpg">
</picture>
 </div>
</div>
</div>


<div data-id="410565ac" data-element_type="widget" data-widget_type="theme-post-content.default">
<div>
<p>This project belongs to a <a href="https://en.m.wikipedia.org/wiki/Computer_graphics">computer graphics</a> artist and researcher, Karl Sims, who is best known for using <a href="https://en.m.wikipedia.org/wiki/Particle_systems">particle systems</a> and <a href="https://en.m.wikipedia.org/wiki/Artificial_life">artificial life</a> in computer animation.</p>
<p>A harmonograph is a mechanical device that uses swinging pendulums to draw pictures, believed to be initially invented in 1844 by Scottish mathematician&nbsp;<a target="_blank" href="https://en.wikipedia.org/wiki/Hugh_Blackburn" rel="noreferrer noopener">Hugh Blackburn.</a>&nbsp;This 3-pendulum rotary type of harmonograph gives a wide variety of satisfying results. It is reasonably easy to build once you’ve settled on a design and have acquired the appropriate materials and tools. Harmonograph is a great project to do with kids and can result in endless experiments creating new geometric designs.</p>
<p><strong>Ingredients:</strong></p>
<ul><li><strong>Lumber</strong><ul><li>1 &nbsp; 3/4″ x 3’x3′ plywood for table top</li><li>4 &nbsp; 1½” x 1½” x 40″ for legs (about 14′ total)</li><li>4 &nbsp; 1½” x 8″ x 12″ for leg braces (about 4′ total)</li><li>4 &nbsp; 3/4″ x 4′ dowels for pendulums and pen lifter (make sure they are straight)</li><li>1 &nbsp; 3/4″ x 1½” x 30″ oak to cut for pendulum supports, and other</li><li>1 &nbsp; 11″ x 11″ x 1/8″ board for platform to hold paper</li></ul></li><li><strong>Hardware Store</strong><ul><li>3 &nbsp; 3/4″ x 5″ long metal pipe nipples (plumbing section)</li><li>3 &nbsp; 3/4″ to 1″ metal pipe bushings</li><li>3 &nbsp; 1″ steel clamps</li><li>4 &nbsp; 1¼” x 4″ metal plates (or 2&nbsp; 1¼” x 8″ plates cut in half)</li><li>1 &nbsp; large metal washer with 2½” outer diameter, 1″ inner diameter, for gimbal</li><li>1 &nbsp; screw-eye for pen lifter</li><li>various drill bits: 3″ circular, 3/4″, 1/8″, etc.</li><li>various #10 screws (1″, 1¼”, 1½”, 1¾”, 2″, 3″)</li><li>a few thin nails</li><li>tools: drill, saw, hammer, tape measure, file, sand paper, etc.</li></ul></li><li><strong>Sporting goods store:</strong><ul><li>2½ lb weights with 1″ hole, at least 8 of them</li></ul></li><li><strong>Art supplies store</strong>:<ul><li>2 &nbsp; 1/2″ x 1/4″ x 30″ balsa (and maybe a spare or two)</li><li>various pens such as: Silver Uni-Ball GEL Impact, and Staedtler Triplus Rollerball</li><li>some string and rubber bands</li><li>paper, 8½” x 11″ (or 9″ x 12″) some black, some white</li></ul></li></ul>
<h2>STEP 1</h2>
<p><strong>Table.</strong> Start by building a sturdy table. This table-top is a 3’x3′ square of 3/4″ thick plywood. The legs are 1½” x 1½” square and about 37″ long, with triangular braces cut from 1½” x 8″x 12″ wooden pieces. The legs are splayed out slightly to give the table strength and allow the rotary pendulum to swing without hitting a leg.</p>
<div><p><strong>Tip:</strong> screw and/or glue the braces to the legs first, and then cut their tops together at a slight angle with a table or circular saw. Adjust the leg lengths to give a table-top height of about 37″.</p><p><strong>Note:</strong> if you want to fit the table through doorways without taking off the legs, you might need slightly shorter legs and pendulums.</p></div>
<h2>STEP 2</h2>
<figure><picture>
<source type="image/webp" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph.jpg.webp 1024w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-500x375.jpg.webp 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-300x225.jpg.webp 300w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-768x576.jpg.webp 768w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20768'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 1024px) 100vw, 1024px">
<img width="1024" height="768" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20768'%3E%3C/svg%3E" alt="" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph.jpg 1024w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-500x375.jpg 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-300x225.jpg 300w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-768x576.jpg 768w" data-lazy-sizes="(max-width: 1024px) 100vw, 1024px" data-lazy-src="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph.jpg">
</picture>
<figcaption><strong>Holes for Pendulums</strong>. Drill 3 holes of 3″ diameter through the table surface for the pendulums to hang through. The rotary pendulum’s hole should be centered in a corner about 8″ from each side just clear of the leg brace underneath. The other two holes should be aligned near the opposite edges, about 8″ from the common side, and 3″ from the other. You’ll need a particular sizeable circular drill bit for this. Alternatively, you can first drill a smaller hole, and then cut a wider opening with a jigsaw.</figcaption></figure>
<h2>Step 3</h2>
<figure><picture>
<source type="image/webp" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-3.jpg.webp 1024w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-3-500x375.jpg.webp 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-3-300x225.jpg.webp 300w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-3-768x576.jpg.webp 768w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20768'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 1024px) 100vw, 1024px">
<img width="1024" height="768" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20768'%3E%3C/svg%3E" alt="" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-3.jpg 1024w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-3-500x375.jpg 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-3-300x225.jpg 300w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-3-768x576.jpg 768w" data-lazy-sizes="(max-width: 1024px) 100vw, 1024px" data-lazy-src="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-3.jpg">
</picture>
<figcaption><strong>Plates to support pendulums</strong>. Mount two metal plates (about 1¼” x 4″) on the sides of the two lateral pendulum holes and drill a small indentation in each plate’s center. <p><strong>Tip:</strong> first, start the indentation in the metal plate with a small drill bit (such as 1/8″) and then continue with a larger bit (such as 1/4″). Be careful not to drill all the way through. Tip: unless you have a good drill press, it may be easier to position the indentations of the plates on the table after you create the fulcrum blocks with protruding screws below, because it can be harder to accurately position the screws in the blocks later to align with the indentations.</p></figcaption></figure>
<h2>Step 4</h2>
<figure><picture>
<source type="image/webp" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-2.jpg.webp 1024w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-2-500x375.jpg.webp 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-2-300x225.jpg.webp 300w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-2-768x576.jpg.webp 768w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20887%20665'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 887px) 100vw, 887px">
<img src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20887%20665'%3E%3C/svg%3E" alt="" width="887" height="665" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-2.jpg 1024w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-2-500x375.jpg 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-2-300x225.jpg 300w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-2-768x576.jpg 768w" data-lazy-sizes="(max-width: 887px) 100vw, 887px" data-lazy-src="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-2.jpg">
</picture>
<figcaption><strong>Pendulums.</strong> The rotary pendulum needs a gimbal mechanism that allows it to swing in any direction. This is made from a large metal washer with 2½” outer and 1″ inner diameter. The washer rests on screw tips protruding from under the table, and then the pendulum rests on the washer. Drill pairs of indentations into the washer on each side, off 90 degrees between the sides, to allow rocking on two perpendicular axes.<p>Here are views of the rotary pendulum gimbal from above and below the table. In the picture from below, note the oak blocks (3/4″ x 1½” x 5″) supporting the two screws (1¾” #10) protruding upwards and diagonally. File down the bottom edges of these blocks as needed, so the pendulum doesn’t hit them when it swings. Likewise, file down the corners of the fulcrum block if necessary so it doesn’t hit the table when swinging.</p></figcaption></figure>
<h2>Step 5</h2>
<figure><ul><li><figure><picture data-id="11158" data-full-url="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal-2.jpg" data-link="https://abakcus.com/diy/how-to-make-a-harmonograph/how-to-make-a-harmonograph-gimbal-2/" src="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal-2.jpg">
<source type="image/webp" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal-2.jpg.webp 1024w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal-2-500x375.jpg.webp 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal-2-300x225.jpg.webp 300w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal-2-768x576.jpg.webp 768w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20768'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 1024px) 100vw, 1024px">
<img width="1024" height="768" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20768'%3E%3C/svg%3E" alt="" data-id="11158" data-full-url="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal-2.jpg" data-link="https://abakcus.com/diy/how-to-make-a-harmonograph/how-to-make-a-harmonograph-gimbal-2/" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal-2.jpg 1024w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal-2-500x375.jpg 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal-2-300x225.jpg 300w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal-2-768x576.jpg 768w" data-lazy-sizes="(max-width: 1024px) 100vw, 1024px" data-lazy-src="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal-2.jpg">
</picture>
</figure></li><li><figure><picture data-id="11159" data-full-url="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal.jpg" data-link="https://abakcus.com/diy/how-to-make-a-harmonograph/how-to-make-a-harmonograph-gimbal/" src="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal.jpg">
<source type="image/webp" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal.jpg.webp 1024w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal-500x375.jpg.webp 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal-300x225.jpg.webp 300w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal-768x576.jpg.webp 768w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20768'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 1024px) 100vw, 1024px">
<img width="1024" height="768" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20768'%3E%3C/svg%3E" alt="" data-id="11159" data-full-url="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal.jpg" data-link="https://abakcus.com/diy/how-to-make-a-harmonograph/how-to-make-a-harmonograph-gimbal/" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal.jpg 1024w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal-500x375.jpg 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal-300x225.jpg 300w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal-768x576.jpg 768w" data-lazy-sizes="(max-width: 1024px) 100vw, 1024px" data-lazy-src="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Gimbal.jpg">
</picture>
</figure></li></ul><figcaption><strong>Gimbal.</strong> The rotary pendulum needs a gimbal mechanism that allows it to swing in any direction. This is made from a large metal washer with 2½” outer and 1″ inner diameter. The washer rests on screw tips protruding from under the table, and then the pendulum rests on the washer. Drill pairs of indentations into the washer on each side, off 90 degrees between the sides, to allow rocking on two perpendicular axes. <p>Here are views of the rotary pendulum gimbal from above and below the table. In the view from below, note the oak blocks (3/4″ x 1½” x 5″) supporting the two screws (1¾” #10) protruding upwards and diagonally. File down the bottom edges of these blocks as needed so the pendulum doesn’t hit them when it swings. Likewise file down the corners of the fulcrum block if necessary so it doesn’t hit the table when swinging.</p></figcaption></figure>
<h2>Step 6</h2>
<figure><picture>
<source type="image/webp" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Weight.jpg.webp 768w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Weight-500x667.jpg.webp 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Weight-300x400.jpg.webp 300w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20768%201024'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 768px) 100vw, 768px">
<img width="768" height="1024" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20768%201024'%3E%3C/svg%3E" alt="" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Weight.jpg 768w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Weight-500x667.jpg 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Weight-300x400.jpg 300w" data-lazy-sizes="(max-width: 768px) 100vw, 768px" data-lazy-src="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Weight.jpg">
</picture>
<figcaption><strong>Weights.</strong> 2½ lb lifting weights from a sporting goods store work well, but typically have a 1″ interior hole. You can stack several weights and slide them together onto the 3/4″ pendulum dowel by using a 5″ long 3/4″ metal pipe nipple, with a 3/4″ to 1″ bushing screwed onto the lower end. A 1″ steel clamp attached to the dowel fixes the weights from sliding off and allows easy adjustment of the weight’s height to give different swinging frequencies.</figcaption></figure>
<h2>Step 7</h2>
<figure><picture>
<source type="image/webp" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Paper-Board.jpg.webp 768w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Paper-Board-500x667.jpg.webp 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Paper-Board-300x400.jpg.webp 300w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20768%201024'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 768px) 100vw, 768px">
<img width="768" height="1024" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20768%201024'%3E%3C/svg%3E" alt="" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Paper-Board.jpg 768w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Paper-Board-500x667.jpg 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Paper-Board-300x400.jpg 300w" data-lazy-sizes="(max-width: 768px) 100vw, 768px" data-lazy-src="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Paper-Board.jpg">
</picture>
<figcaption><strong>Paper Platform. </strong>Cut about 1″ off the top of the rotary pendulum dowel, so it is slightly lower than the other two. Then mount an 11″x11″ square of thin 1/8″ board to the top of this pendulum, using a small oak block glued to it for support, with a 3/4″ hole for the dowel. Wrap some tape around the dowel’s top to get a tight fit, or glue it on.<p>*** Use two rubber bands, or some clips, to hold the paper in place on the platform. If the form slips on the platform, spray a thin layer of temporary adhesive on the platform to make it slightly sticky.</p></figcaption></figure>
<h2>Step 8</h2>
<figure><picture>
<source type="image/webp" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Arms-768x1024.jpg.webp 768w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Arms-500x667.jpg.webp 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Arms-300x400.jpg.webp 300w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Arms-scaled.jpg.webp 1536w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20768%201024'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 768px) 100vw, 768px">
<img width="768" height="1024" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20768%201024'%3E%3C/svg%3E" alt="" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Arms-768x1024.jpg 768w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Arms-500x667.jpg 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Arms-300x400.jpg 300w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Arms-1152x1536.jpg 1152w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Arms-scaled.jpg 1536w" data-lazy-sizes="(max-width: 768px) 100vw, 768px" data-lazy-src="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Arms-768x1024.jpg">
</picture>
<figcaption><strong>Arms.</strong> Connect a 30″ long balsa stick to the top of each lateral pendulum using a thin nail. Bend the nail back and forth a little in the balsa to allow the arm to rotate smoothly and move up and down slightly. The nail hole will slowly loosen further during use.<p>To make a simple pen-holder, drill a 1/2″ hole on the end of one arm, and cut about 4″ down the arm’s center to make a clothes-pin like a device. Alternatively, glue a real clothes-pin to the end of one of the arms. Pictures of both versions are shown.</p><p>Finally, attach the two arms with a doubled-over rubber band, as shown.</p><p>Note that if you plan to use your harmonograph regularly, such as in a museum setting, a more robust solution for these arms that won’t wear as quickly might be necessary.&nbsp;</p><p><strong>Note:</strong>&nbsp;An alternate version of the arm-pendulum connection is shown to the right that uses a magnetic ball joint instead of the simple nail method above. Glue one 3/8″ spherical magnet to the arm (making sure the N/S alignment is horizontal by connecting a second magnet). File a hole in the side of a nylon cylinder (1″ height, 1/2″ outer and 3/8″ inner diameter) and use smaller cylinders (3/8″ outer diameter) to hold another magnet inside that can rotate freely. Then glue the cylinder to the top of the pendulum.</p></figcaption></figure>
<h2>Step 9</h2>
<figure><ul><li><figure><picture data-id="11163" data-full-url="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-2.jpg" data-link="https://abakcus.com/diy/how-to-make-a-harmonograph/how-to-make-a-harmonograph-pen-lifter-2/" src="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-2.jpg">
<source type="image/webp" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-2-1024x768.jpg.webp 1024w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-2-500x375.jpg.webp 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-2-300x225.jpg.webp 300w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-2-768x576.jpg.webp 768w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-2.jpg.webp 1600w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20768'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 1024px) 100vw, 1024px">
<img width="1024" height="768" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20768'%3E%3C/svg%3E" alt="" data-id="11163" data-full-url="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-2.jpg" data-link="https://abakcus.com/diy/how-to-make-a-harmonograph/how-to-make-a-harmonograph-pen-lifter-2/" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-2-1024x768.jpg 1024w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-2-500x375.jpg 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-2-300x225.jpg 300w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-2-768x576.jpg 768w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-2-1536x1152.jpg 1536w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-2.jpg 1600w" data-lazy-sizes="(max-width: 1024px) 100vw, 1024px" data-lazy-src="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-2-1024x768.jpg">
</picture>
</figure></li><li><figure><picture data-id="11164" data-full-url="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-scaled.jpg" data-link="https://abakcus.com/diy/how-to-make-a-harmonograph/how-to-make-a-harmonograph-pen-lifter/" src="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-scaled.jpg">
<source type="image/webp" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-768x1024.jpg.webp 768w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-500x667.jpg.webp 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-300x400.jpg.webp 300w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-scaled.jpg.webp 1536w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20768%201024'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 768px) 100vw, 768px">
<img width="768" height="1024" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20768%201024'%3E%3C/svg%3E" alt="" data-id="11164" data-full-url="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-scaled.jpg" data-link="https://abakcus.com/diy/how-to-make-a-harmonograph/how-to-make-a-harmonograph-pen-lifter/" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-768x1024.jpg 768w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-500x667.jpg 500w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-300x400.jpg 300w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-1152x1536.jpg 1152w, https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-scaled.jpg 1536w" data-lazy-sizes="(max-width: 768px) 100vw, 768px" data-lazy-src="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/How-to-make-a-harmonograph-Pen-Lifter-768x1024.jpg">
</picture>
</figure></li></ul><figcaption><strong>Pen Lifter.</strong> It is convenient to raise and lower the pen gently without disturbing the motion of the pendulums. To do this, insert a 30″ pole into a hole near the center of the table, just far enough from the paper platform that it won’t be hit by it (about 12″ from the rotary pendulum hole). Attach an oak block under the table for a deeper hole and better support. Tie a string to the balsa arms where they are connected, lead it through a screw-eye on top of the pole, and back down to a small jam cleat or groove where it can hold the pen in place above the paper until you are ready to lower it.</figcaption></figure>
<h2>Step 10</h2>
<p><strong>Pens.</strong> Experiment with pens and markers of various types and colors. Generally, wide pens or thin markers seem to work best. Here are some I’ve had good luck with so far:</p>
<ul><li>Uniball GEL Impact in Silver, use on black or dark paper.</li><li>Staedtler Triplus Rollerball Pens (.4mm) in various colors</li><li>Pigma Graphic 1 (1.0mm) in black</li><li>Sakura Identi Pen in black, purple, etc.</li></ul>
<p>but many other types of pens may also work well.</p>
<h2>Adjustments</h2>
<p><strong>Weight Height</strong>. Adjust a pendulum’s weight height to change its swinging frequency. The frequency of a pendulum varies with the inverse of the square root of its length, so to swing twice as fast, the length between the fulcrum and its center-of-mass would need to be 1/4 of the original length (which may not be practical with this harmonograph). For a 3:2 or 4:3 frequency increase, the weights would be raised around 19″ or 15″ respectively, although you should probably do some timing tests to find and mark these heights experimentally.</p>
<p><strong>Weight Amount</strong>. Add more weight to a pendulum to counteract friction and make the swinging last longer. I’ve found that 5 lb (2 x 2½) on the rotary pendulum, and 7½ lb (3 x 2½) on the other two works reasonably well. Note that adding more weight does not generally change the frequency of the pendulum.</p>
<p><strong>Phase and Amplitude</strong>. Each time you swing the pendulums to make a new drawing, each pendulum’s relative phases, and amplitudes will vary. Try somewhere the rotary pendulum, and the lateral pendulums are initially making circles in the same or opposite directions. Try somewhere the lateral pendulums are initially swinging in phase to make a diagonal line.</p>
<h2>Results</h2>
<p><strong>Two-pendulum results</strong>. To simplify things, you can lock …</p></div></div></div></div></div></div></div></section></div></div></div></div></div></section></div></div></main></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://abakcus.com/diy/how-to-make-a-harmonograph/">https://abakcus.com/diy/how-to-make-a-harmonograph/</a></em></p>]]>
            </description>
            <link>https://abakcus.com/diy/how-to-make-a-harmonograph/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24449813</guid>
            <pubDate>Sat, 12 Sep 2020 04:18:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What is benchmarketing and why is it bad?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24449144">thread link</a>) | @bitsondatadev
<br/>
September 11, 2020 | https://bitsondata.dev/what-is-benchmarketing-and-why-is-it-bad/ | <a href="https://web.archive.org/web/*/https://bitsondata.dev/what-is-benchmarketing-and-why-is-it-bad/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <p>There's something I have to get off my chest. If you really need to, just read the TLDR and listen to the Justin Bieber parody posted below. If you’re confused by the lingo, the rest of the post will fill in any gaps.</p><div><p>TL;DR: Benchmarketing, the practice of using benchmarks for marketing, is bad. Consumers should run their own benchmarks and ideally open-source them instead of relying on an internal and biased report.</p><p>Enjoy the song I wrote about this silly practice.</p></div><figure><iframe width="459" height="344" src="https://www.youtube.com/embed/FSy8V-R0_Zw?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><p>For the longest time, I have wondered what is the point of corporations, specifically in the database sectors, running their own benchmarks. Would a company ever have any incentive to post results from a benchmark that didn't show its own system winning in at least the majority of cases? I understand that these benchmarks have become part of the furniture we come to expect to see when visiting any hot new database's website. I doubt anybody in the public domain gains much insight out of these results, to begin with, at least nothing they weren't expecting to see. </p><p>Now to be clear, I am in no way indicating that companies running their own internal benchmarks to analyze their own performance in comparison to their competitors is a bad thing. It’s when they take those results and intentionally skew the methods or data from these benchmarks for sales or marketing purposes that is the problem we’re discussing here. Vendors that take part in the practice, not only use these benchmarks to show their systems succeeding a little but rather perversely taint their methodology with settings, caching, and other performance enhancements, while leaving their competition’s settings untouched. </p><p>This should be obvious that this is NOT what benchmarking is about! If you read about the history of the <a href="http://www.tpc.org/information/about/history5.asp">Transaction Processing Performance Council (TPC)</a> you come to understand that this is the very wrongdoing that the council was created to address. But like with any proxy involving measurements, the measurements are inherently pliable.</p><blockquote>By the spring of 1991, the TPC was clearly a success. Dozens of companies were running multiple TPC-A and TPC-B results. Not surprisingly, these companies wanted to capitalize on the TPC's cachet and leverage the investment they had made in TPC benchmarking. Several companies launched aggressive advertising and public relations campaigns based around their TPC results. In many ways, this was exactly why the TPC was created: to provide objective measures of performance. What was wrong, therefore, with companies wanting to brag about their good results? What was wrong is that there was often a large gap between the objective benchmark results and their benchmark marketing claims--this gap, over the years, has been dubbed "benchmarketing." So the TPC was faced with an ironic situation. It had poured an enormous amount of time and energy into creating a good benchmark and even a good benchmark review process. However, the TPC had no means to control how those results were used once they were approved. The resulting problems generated intense debates within the TPC.</blockquote><p>This benchmarketing ultimately fails the clients that these companies are marketing to. It demonstrates not only a lack of care for addressing the users' actual pain but a lack of respect by intentionally pulling the wool over their eyes simply in an attempt to mask that their performance isn't up to par with their competitors. <strong>This leads to consumers not being able to make informed decisions as most of our decisions are made from gut instincts and human emotion which these benchmarks aim to manipulate.</strong></p><p>If you’re not sure exactly how a company would pull this off, an example of might be that database A enables using a cost-based optimizer that requires precomputing statistics about different tables involved in the computation, while database B is running a query against this table without any type of stats based optimization made available to it. Database A will clearly dominate as now it can reorder joins and apply better execution plans while database B is going to go with the simplest plan and run much slower in most scenarios. The company whose product depends on database A will then hone in on the numerical outcomes of this report. Even if they're decent enough to report the methods they skewed to get these results, they bury it within their report and focus on advertising the outcome of what would otherwise be considered an absurd comparison. Companies will even go as far as to say that their competition's database wasn't straight forward to configure when they were setting up optimizations. If you're not capable of understanding how to make equivalent changes to both systems, well then I guess you don't get to run that comparison until you figure it out. &nbsp;</p><p>Many think that consumers are not susceptible to such attacks and would be able to see right through this scheme, but these reports appeal to any of us when we don't have the necessity or resources to thoroughly examine all the data. Many times we have to take cues from our gut when a decision needs to be made and the time to make it is constrained by our time and other business needs. We see this type of phenomenon described in the book, <em>Thinking Fast and Slow</em> by Daniel Kahneman. To briefly summarize the model they use, there are two modes that humans use when they reason about their decisions, System 1 and System 2.</p><blockquote>Systems 1 and 2 are both active whenever we are awake. System 1 runs automatically and System 2 is normally in comfortable low-effort mode, in which only a fraction of its capacity is engaged. System 1 continuously generates suggestions for System 2: impressions, intuitions, intentions, and feelings. If endorsed by System 2, impressions and intuitions turn into beliefs, and impulses turn into voluntary actions. When all goes smoothly, which is most of the time, System 2 adopts the suggestions of System 1 with little or no modification. You generally believe your impressions and act on your desires, and that is fine — usually.</blockquote><p>No surprise, that’s usually the part where we get into trouble. While we like to think that we are generally thinking in the logical System 2 mode, we don't have time or energy to live in this space for long periods throughout the day and we find ourselves very reliant on System 1 for much of our decision making.</p><blockquote>The measure of success for System 1 is the coherence of the story it manages to create. The amount and quality of the data on which the story is based are largely irrelevant. When information is scarce, which is a common occurrence, System 1 operates as a machine for jumping to conclusions.</blockquote><p>This is why benchmarketing can be so dangerous because it is so effective at manipulating our belief in claims that simply aren't true. These decisions affect how your architecture will unfold, your time-to-value, and lost hours for your team and customers. It makes having these systems that fairly compare the performance and merits of two systems all-the-more paramount.</p><figure><img src="http://bitsondata.dev/content/images/2020/09/significant.png" alt=""><figcaption><a href="https://xkcd.com/882/">https://xkcd.com/882/</a></figcaption></figure><p>So why am I talking about this now?</p><p>I have become a pretty big fanboy of a <a href="https://prestosql.io/">Presto</a>, a distributed query engine that runs interactive queries from many sources. I have witnessed firsthand how fast a cluster of Presto nodes are able to process through a huge amount of data at blindingly fast speeds. When you dive into how these speeds are achieved you find that this project is an incredible modern feat of solid engineering that makes interactive analysis over petabytes of data a reality. Going into all the reasons I like this project would be too tangential but it fuels the fire for why I believe this message needs to be heard.</p><p>Recently there was a "benchmark" that came out comparing the performance of a commercial competitor and Presto open-source and enterprise versions, touting performance improvements over Presto by an amount that would have been called out as too high in a CSI episode <a href="https://www.youtube.com/watch?v=hkDD03yeLnU">&lt;insert canonical csi clip here&gt;</a>. If you need to find out what I’m talking about, simply google "presto benchmark 3000" and you will find the benchmark along with plenty of other hype they've generated around these "findings". <a href="https://blog.yugabyte.com/yugabytedb-vs-cockroachdb-bringing-truth-to-performance-benchmark-claims-part-1/">Presto isn't the only system in the data space to come under similar types of attacks.</a> It makes sense too, as this type of technical peacocking is common as it successfully gains attention. </p><p>Luckily, as more companies strive to become transparent and associate themselves with open-source efforts, we are starting to see a relatively new pattern of open-source efforts emerge. Typically, you're used to hearing about open-source within the context of software projects maintained by open-source communities. We are now arriving at the age of any noun being able to be used in an open-source framework. There is open-source music, open-source education, and even open-source data. So why not reach a point where open-source benchmarking through consumer collaboration is a thing. This is not just for the sake of the consumers of these technologies who simply want to have more data to inform their design choices to better serve their clients, it's also unfortunate that this affects developer communities that are putting in a lot of hard work on these projects, only to have that hard work get berated unintelligibly by the likes of some corporate status competition.</p><p>Now I'm clearly a little biased when I tell you that I think Presto is currently the best analytics engine on the market today. When I say this, you really should be skeptical too. Really, I encourage it. You should verify in some way beyond a shadow of a doubt that:</p><p> &nbsp;1. Any TPC or other benchmarks are validated and no "magic" was used to improve their performance.</p><figure></figure><p> &nbsp;2. using your own use cases to make sure the system you choose is going to meet the needs of your particular use case.<br></p><p>While this may seem like a lot of work, with cloud infrastructure and simplicity of deploying different …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bitsondata.dev/what-is-benchmarketing-and-why-is-it-bad/">https://bitsondata.dev/what-is-benchmarketing-and-why-is-it-bad/</a></em></p>]]>
            </description>
            <link>https://bitsondata.dev/what-is-benchmarketing-and-why-is-it-bad/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24449144</guid>
            <pubDate>Sat, 12 Sep 2020 01:42:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I used GCP to create the transcripts for my Podcast]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24448922">thread link</a>) | @simonebrunozzi
<br/>
September 11, 2020 | https://alediaferia.com/2020/05/14/how-used-gcp-transcripts-podcast/ | <a href="https://web.archive.org/web/*/https://alediaferia.com/2020/05/14/how-used-gcp-transcripts-podcast/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-577">
		<div>
		<p><span><span>Reading Time: </span> <span>4</span> <span>minutes</span></span></p><p>I’m currently working on a series of episodes for a Podcast I’ll be publishing soon. The Podcast will be in Italian and I wanted to make sure to publish the episode transcripts together with the audio episodes.</p>



<p>The idea of manually typing all the episodes text wasn’t really appealing to me so I started looking around.</p>



<h2>What are the tools out there?</h2>



<p>From a quick Google search, it seems that some companies are offering a mix of automated and human-driven transcription services.</p>



<p>I wasn’t really interested in that for now. I was, of course, just interested in consuming an API I could push my audio to and get back some text in a reasonable amount of time.</p>



<p>For this reason, I started looking for <em>speech-to-text</em> APIs and, of course, the usual suspects figured among the first results.</p>



<ul><li><a href="https://azure.microsoft.com/en-us/services/cognitive-services/speech-to-text/">Microsoft Cognitive Services</a></li><li><a href="https://www.ibm.com/cloud/watson-speech-to-text">IBM Watson Speech-to-Text</a></li><li><a href="https://www.speechmatics.co/">SpeechMatics</a></li><li><a href="https://aws.amazon.com/transcribe/">Amazon Transcribe</a></li><li><a href="https://cloud.google.com/speech-to-text">Google Cloud Speech-to-Text</a></li></ul>



<p>To be quite honest, I didn’t spend too much time investigating the solutions above. I probably spent more time reading about them to write this blog post.</p>



<p>I decided to go with Google Cloud because I’ve never used GCP before and wanted to give it a try. Additionally, the documentation for it seemed quite straightforward, as well as the support for Italian as language to transcribe from (the podcast is in Italian). I also had a few free credits available because I’ve never used GCP for personal use before.</p>



<h2>Setting up</h2>



<p>If you want to try transcribing your episodes too, follow this quick setup guide to get started.</p>



<p>Head over to <a href="https://cloud.google.com/">Google Cloud</a> and set up an account. Make sure you create a project and enable the Speech-to-Text API. If you forget to do so <code>gcloud</code> will be able to take care of that for you, later.</p>



<div><figure><img loading="lazy" width="509" height="99" src="https://alediaferia.com/wp-content/uploads/2020/05/Screenshot-2020-05-13-at-20.24.59.png" alt="Google Cloud Speech-to-Text" srcset="https://alediaferia.com/wp-content/uploads/2020/05/Screenshot-2020-05-13-at-20.24.59.png 509w, https://alediaferia.com/wp-content/uploads/2020/05/Screenshot-2020-05-13-at-20.24.59-300x58.png 300w" sizes="(max-width: 509px) 100vw, 509px"><figcaption>Google Cloud Speech-to-Text</figcaption></figure></div>



<p>Second thing I did was installing <code><a href="https://cloud.google.com/sdk/docs/quickstarts">gcloud</a></code>, the CLI Google Cloud provides for interacting with the APIs. This time I was only interested in testing the API so it seemed to me that this tool was the only way to get started quickly.</p>



<p>Additionally, there’s not much you can do from the Google Cloud Web Console if you want to deal with Speech-to-Text APIs.</p>



<h3>Get your file ready for transcription</h3>



<p>Sampling rate for your audio file should be at least 16 kHz for better results. Additionally, GCP recommends a lossless codec. I only had an mp3 of my episode handy at the time so I gave it a try anyway and it worked well enough.</p>



<p><strong>Make sure you know the sample rate of your file, though, because specifying a wrong one might lead to poor results.</strong></p>



<p>You can usually verify the sample rate by getting info on your file from your Mac’s Finder:</p>







<p>You can read more about the recommended settings on the <a href="https://cloud.google.com/speech-to-text/docs/best-practices">Best Practices</a> section.</p>



<h3>Upload your episode to the bucket</h3>



<p>GCP needs your file to be available from a Storage Bucket so, go ahead and <a href="https://cloud.google.com/storage/docs/creating-buckets">create one</a>.</p>



<figure><img src="https://cloud.google.com/storage/images/create-bucket.png" alt=""><figcaption>Storage Bucket creation example</figcaption></figure>



<p>You’ll be able to upload your episode from there.</p>



<h2>Time to transcribe</h2>



<p>Once you have your episode file up there in the cloud go back to your local machine terminal were you have configured the <code>gcloud</code> tool.</p>



<figure><img loading="lazy" src="https://alediaferia.com/wp-content/uploads/2020/05/carbon1-1024x175.png" alt="" width="580" height="99" srcset="https://alediaferia.com/wp-content/uploads/2020/05/carbon1-1024x175.png 1024w, https://alediaferia.com/wp-content/uploads/2020/05/carbon1-300x51.png 300w, https://alediaferia.com/wp-content/uploads/2020/05/carbon1-768x131.png 768w, https://alediaferia.com/wp-content/uploads/2020/05/carbon1-1536x263.png 1536w, https://alediaferia.com/wp-content/uploads/2020/05/carbon1.png 2048w" sizes="(max-width: 580px) 100vw, 580px"><figcaption>Gcloud used to trigger the speech-to-text transcription</figcaption></figure>



<p>If your episode lasts longer than 60 seconds (😬) you’ll want to use <code>recognize-long-running</code> and most likely specify <code>--async</code>. </p>



<p>As I said before, make sure you specify the right <code>--sample-rate</code>: in my case 44100. This will help GCP transcribe your file with better results.</p>



<p>The <code>--async</code> switch creates a long-running asynchronous operation. It took around 5 minutes for me to have the operation complete. </p>



<p>Oddly, I wasn’t able to find any reference to the asynchronous operation from my Google Cloud Console. So, if you want to be able to know what happened to your transcription job, make sure you take note of the operation identifier. You’ll need it to query the <code>speech operations</code> API for information about your transcription job.</p>



<figure><img loading="lazy" width="1024" height="268" src="https://alediaferia.com/wp-content/uploads/2020/05/carbon2-1024x268.png" alt="" srcset="https://alediaferia.com/wp-content/uploads/2020/05/carbon2-1024x268.png 1024w, https://alediaferia.com/wp-content/uploads/2020/05/carbon2-300x79.png 300w, https://alediaferia.com/wp-content/uploads/2020/05/carbon2-768x201.png 768w, https://alediaferia.com/wp-content/uploads/2020/05/carbon2-1536x402.png 1536w, https://alediaferia.com/wp-content/uploads/2020/05/carbon2.png 2048w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>The speech operation metadata</figcaption></figure>



<h2>The transcribed data</h2>



<p>Once your transcription operation is complete the <code>describe</code> command will return the transcript excerpts, together with the confidence rate.</p>



<figure><img loading="lazy" width="1024" height="641" src="https://alediaferia.com/wp-content/uploads/2020/05/carbon3-1024x641.png" alt="" srcset="https://alediaferia.com/wp-content/uploads/2020/05/carbon3-1024x641.png 1024w, https://alediaferia.com/wp-content/uploads/2020/05/carbon3-300x188.png 300w, https://alediaferia.com/wp-content/uploads/2020/05/carbon3-768x481.png 768w, https://alediaferia.com/wp-content/uploads/2020/05/carbon3-1536x962.png 1536w, https://alediaferia.com/wp-content/uploads/2020/05/carbon3.png 2048w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>The speech transcript excerpt</figcaption></figure>



<p>I wasn’t particularly interested in the <code>confidence</code> rate, I only wanted a big blob of text to be able to review and use for SEO purposes as well as to be able to include it with the episode. For this reason, <strong><em>jq to the resque!</em></strong></p>



<p>I love <code><a href="https://stedolan.github.io/jq/">jq</a></code>, you can achieve so much with when it comes to manipulate JSON.</p>



<p>In my case, I only wanted to concatenate all the <code>transcript</code> fields and save them to a file. Here’s how I did:</p>



<pre data-enlighter-language="generic" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">$ ./bin/gcloud ml speech operations describe &lt;your-transcription-operation-id&gt; | jq '.response.results[].alternatives[].transcript' &gt; my-transcript.txt</pre>



<p>And that’s it!</p>



<h2>Conclusion</h2>



<p>I thought of sharing the steps above because they’ve been useful to me in producing the transcripts. I think GCP Speech-to-Text works quite well with Italian but, of course, the transcript is not suitable to be used as it is, unless your accent is perfect. Mine wasn’t 😅.</p>



<p>If you want to know more about my journey towards publishing my first podcast <strong><a href="https://twitter.com/alediaferia">follow me on Twitter</a></strong> were I’ll be sharing more about it.</p>



<p>Photo by <a href="https://unsplash.com/@maltewingen?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Malte Wingen</a> on <a href="https://unsplash.com/s/photos/podcast?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></p>
			</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://alediaferia.com/2020/05/14/how-used-gcp-transcripts-podcast/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24448922</guid>
            <pubDate>Sat, 12 Sep 2020 00:58:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sketching Algorithms for High Dimensional, Large Datasets]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24448669">thread link</a>) | @ArtWomb
<br/>
September 11, 2020 | https://www.sketchingbigdata.org/fall20/ | <a href="https://web.archive.org/web/*/https://www.sketchingbigdata.org/fall20/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            



<h2 id="cs-294-165-fall-2020-syllabus-fall20-syllabus">CS 294-165 - Fall 2020 (<a href="https://www.sketchingbigdata.org/fall20/syllabus">Syllabus</a>)</h2>

<p><strong><strong>Sketching algorithms</strong></strong> compress data in a way that is still useful for answering some pre-specified family of queries, possibly across datasets by comparing sketches. This course will cover mathematically rigorous models for developing such algorithms, as well as some provable limitations of algorithms operating in those models. Some topics covered include:</p>

<ul>
<li><p><strong>Streaming algorithms.</strong> Compute useful statistics over a dataset making only one pass over it, while using little memory.</p></li>

<li><p><strong>Dimensionality reduction.</strong> General techniques and impossibility results for reducing data dimension while still preserving geometric structure.</p></li>

<li><p><strong>Randomized linear algebra.</strong> Algorithms for big matrices (e.g. a user/product rating matrix for Netflix or Amazon). Regression, low rank approximation, clustering, etc.</p></li>

<li><p><strong>Compressed sensing.</strong> Recovery of (approximately) sparse signals based on few linear measurements.</p></li>
</ul>

<p>This is a graduate course, though there may be room for a limited number of advanced undergraduate students satisfying the following prerequisites: mathematical maturity and comfort with algorithms (e.g. CS 170), discrete probability, and linear algebra.</p>

</div></div>]]>
            </description>
            <link>https://www.sketchingbigdata.org/fall20/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24448669</guid>
            <pubDate>Sat, 12 Sep 2020 00:08:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hiring the first head of marketing at a startup]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24448513">thread link</a>) | @tosh
<br/>
September 11, 2020 | https://helenmin.com/blog/first-head-of-marketing | <a href="https://web.archive.org/web/*/https://helenmin.com/blog/first-head-of-marketing">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-layout-label="Post Body" data-type="item" id="item-5e842a035e87b661d8bf062f"><div><div><div data-block-type="2" id="block-c44372ffee113b1df651"><div><p>“Did you see that Stripe’s CMO is out?” a founder asked one day from the desk behind me.</p><p>Though I’d heard the news, the question had me curious for two reasons: First, I was two months into my own role as head of marketing of a fast-growing fintech startup and curious what my boss thought about the topic. Second, I had closely followed the woman in question and considered her a terrific marketer.</p><p>“It’s only been a year,” he continued. “She must’ve been bad.”<br>&nbsp;</p><p><strong>Revolving door</strong>&nbsp;</p><p>This exchange sticks with me years later because it’s emblematic of the mentality some technical founders hold about the role of marketing.</p><p>The thinking goes: Founders build great products that sell themselves through the power of network effects. When the need arises down the road, the company will hire a proven marketing professional to start a department from scratch while everyone’s at a full sprint. If it doesn’t work out…<em>she must’ve been bad</em>.</p><p>In fact, brief tenures and abrupt departures of CMOs have become the norm in Silicon Valley.<strong> </strong>By my count, the tenures of Robinhood’s first <em>three</em> CMOs combined add up to two years; Wealthfront’s first CMO lasted a year and half; and Intercom’s and Affirm’s first CMOs were both out in less than a year. At Dropbox, our first CMO (who I found to be a fantastic leader and marketer) stayed on for just over a year…</p><p>These marketers weren’t all “bad.” Most of them have stellar reputations, in fact. So what’s really going on?</p><p><strong>Founder mentality</strong></p><p>In Silicon Valley, marketing isn’t important—until it is.</p><p>Founders often disregard marketing for as long as possible, convincing themselves it’s “fluff.” A product manager can probably handle things like customer research, product positioning, and the external components of a product launch, and then hand them off to sales, right? After all, he has an MBA. :)</p><p>This works well enough in the early stages, but then problems emerge: Customer-facing team members struggle to stick to a consistent message in the market; information isn’t flowing between customers and product teams; taking turns managing the company Twitter account isn’t working; and the founders have to manage the press alias.</p><p>At the same time, the internal demand for marketing grows: Engineering needs better market insights; product needs successful launches; sales needs more compelling materials; executives need external comms support; HR needs help with recruiting and retention; and customer success needs to scale and automate a lot of customer comms.</p><p>Finally, something happens. The company gets ensnared in a PR crisis, needs to expand to new markets, or faces new competition. If only the company had better brand equity, visibility, or public sentiment, executives could stay focused on what’s important.</p><p>At this point, founders “give in” and kick off the search for a head of marketing to build the function.</p><p><strong>‘Without a penny spent on marketing’</strong></p><p>When recruiting for their first head of marketing, founders will sometimes declare enthusiastically, “Look how far we’ve gotten—and without a penny spent on marketing!”&nbsp;</p><p>I tell them this is analogous to walking into a dentist’s office and proclaiming, “Look how great my teeth look—and without a day of brushing! Do you want to be my first dentist?” Yuck.</p><p>If you didn’t believe in marketing for years, you probably aren’t set up for the function to succeed in the first place. Experienced marketers know this.&nbsp;</p><p>If they’ve done the job before, a candidate will know they’ll be juggling four jobs at the same time:&nbsp;</p><ul data-rte-list="default"><li><p>Job 1: Recruit and manage a team;&nbsp;</p></li><li><p>Job 2: Define what marketing means at the company and educate the rest of the team;</p></li><li><p>Job 3: Help other departments succeed and scale; and</p></li><li><p>Job 4: Define the brand and tell stories to move the brand forward.</p></li></ul><p>They also know they’ll be stepping into a mess and answering to executives who expect quick results. What’s more, with no team in place, they’ll be responsible for day-to-day activities they’ve been delegating for years (writing copy, setting up marketing dashboards, etc.)&nbsp;</p><p>Do they really want to start at the beginning, with no resources?&nbsp;</p><p><strong>First hire a ‘super IC’ (or two)</strong></p><p>Instead of following this failed playbook, I advise startups to think about marketing much earlier in the process and begin laying the foundation that a future leader can build on.</p><p>Set up a small team of one or two strong individual contributors to take on marketing duties. These should be generalists capable of handling a variety of marketing tasks (maybe consider making them <a href="https://helenmin.com/blog/product-marketing">product marketing managers</a>). Have them set up basic infrastructure like a marketing automation tool that connects to your CRM and Google Analytics for your website and blog. Connect them to other departments to begin building websites optimized for conversions, developing simple campaigns, drafting brand messaging, and so on.</p><p>This is a win for the founder, who learns the different marketing functions much earlier in the process. It’s a win for the business generalist, who can find their passion while making an impact at the company. It’s a win for the future head of marketing, because someone will have already done some trial-and-error and gotten the marketing function off the ground. And it’s a win for the recruiter, because the job’s more attractive with someone already on the team cranking.</p><p>These super ICs won’t do all the jobs of a marketing head. They won’t recruit or necessarily even lead. But you’ll have people who understand marketing, speak the language, and can run experiments.</p><p><strong>Self-fulfilling prophecy</strong></p><p>Like NFL coaches, heads of marketing experience a lot of turnover. Because marketing initiatives are often hard to measure and roles aren’t customer-facing, removing a marketing lead is a quick and easy lever for a founder to pull at the first signs of things not working out.&nbsp;</p><p>As a result, a self-fulfilling prophecy develops, where marketers <em>assume</em> they’ll only last a year and start making decisions based on that belief. Knowing time is limited, they get over-ambitious and move too fast or focus on things that will pad their resume rather than strategic priorities. After a year or two, they’re off to another company and the startup is back at square one. </p><p>This is bad for startups! Scarred by their experience dealing with a first head of marketing departure, many founders put off hiring a new lead for a while—sometimes leaving the company even worse off than before the head of marketing joined.</p><p><strong>A checklist&nbsp;</strong></p><p>To avoid this fate for your company, use the following checklist to determine if you’re ready for a marketing head:&nbsp;</p><ul data-rte-list="default"><li><p><em>Do you have budget, headcount, and recruiting bandwidth to help a new marketing leader build their team?</em></p></li><li><p><em>Do you have a clear understanding of your growth model and where marketing efforts can uniquely impact growth?&nbsp;</em></p></li><li><p><em>Do you have buy-in from engineering and design leadership to support marketing experiments and campaigns?&nbsp;</em></p></li><li><p><em>Do you have the patience to allow time for experimentation and some fails before big wins?</em></p></li></ul><p>If you answer “yes” to (most of) these questions, congratulations—you’re ready to hire your first marketing head. Good luck!</p></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://helenmin.com/blog/first-head-of-marketing</link>
            <guid isPermaLink="false">hacker-news-small-sites-24448513</guid>
            <pubDate>Fri, 11 Sep 2020 23:41:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[VPNs Are Overrated]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24448213">thread link</a>) | @mratmeyer
<br/>
September 11, 2020 | https://maxratmeyer.com/blog/vpns-are-overrated/ | <a href="https://web.archive.org/web/*/https://maxratmeyer.com/blog/vpns-are-overrated/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>One piece of cybersecurity advice that comes up time and time again is to use a VPN. VPNs, or virtual private networks, encrypt the internet traffic between you and your VPN provider, securing data from your internet provider and local network as well as hiding your IP address. Through <a href="https://www.youtube.com/watch?v=7uE7kFcJ_Pk">clever marketing</a>, VPN providers position themselves as an all in one tool to secure yourself online. However, the reality is a lot more complicated.</p><h2>VPNs can sell your data</h2><p>Privacy wise, all a VPN does is shift who you trust with your data. Normally, you would trust your internet provider, like Comcast or AT&amp;T, to not intercept or change any of your data packets. When you use a VPN, that traffic is encrypted through your local internet provider and released at the VPNs servers. This means that your VPN provider could intercept or track your connections. Most VPNs will claim that they do not do this, citing that they have no logging policies. However, VPNs <a href="https://www.theregister.co.uk/2011/09/26/hidemyass_lulzsec_controversy/">have lied about this policy</a> before.</p><p>Free VPNs are especially prone to these shady business practices, as they have to pay for their servers somehow. For example, popular free VPN Hotspot Shield was <a href="https://arstechnica.com/tech-policy/2017/08/ftc-must-scrutinize-hotspot-shield-over-alleged-traffic-interception-group-says/">caught injecting affiliate links into their users traffic</a>. Generally, it's a good idea to avoid most free VPNs and do your research before using any VPN, even if it's paid.</p><h2>VPNs don’t make you anonymous</h2><p>While VPNs do change your public IP address, this isn’t as helpful as you might think. Most IP addresses are shared between multiple people or devices anyway, so services don’t rely on it much for tracking. However, there are lots of other factors that companies use to track you. This includes the cookies in your browser and what accounts you are logged in to, but also many other factors outside of your control such as your user agent or browser fingerprint. Browser fingerprinting, for example, uses factors such as your device, screen size, plugins, and other information about your computer to uniquely identify you. To see this in action, you can visit a site like <a href="https://panopticlick.eff.org/">Panopticlick</a> to see how unique your browser is to trackers.</p><h2>VPNs don’t make you (that much) more secure</h2><p>VPNs do secure your traffic from your local network, but we already have technologies that do that for us. HTTPS, the padlock in your browser, means that content is encrypted between your computer and the website you are connected to. This makes it really hard for someone to intercept or view the site you are looking at. The most an onlooker would be able to see is the domain name you are connected to, but they wouldn't be able to see the exact page or content you are looking at. Generally, for most people, this should be enough and VPNs wouldn't add many security benefits - especially if the VPN is sketchy itself.</p><h2>So why would I use a VPN?</h2><p>While VPNs aren't needed for most people, there are definitely scenarios in which they are useful. If you are trying to access content that is region restricted, VPNs are useful tools to bypass geoblocks. VPNs are also useful for bypassing restrictive firewalls, or add extra security if you are connected to a public Wi-Fi network. However, before you use a VPN, make sure you do your research about which VPNs are trustworthy and won't sell your data.</p><h2>So how do I secure myself online?</h2><p>The most important way to secure yourself online is simply to follow basic cyber hygiene habits. Use unique passwords for each site with a password manager, don’t click on links in suspicious emails or websites, always keep your software up to date. As internet security and privacy becomes more popular, major VPN companies are going to grow and get more popular. However if you follow basic cyber hygiene habits, your cybersecurity posture will be stronger than if you just used VPN companies.</p></div></div>]]>
            </description>
            <link>https://maxratmeyer.com/blog/vpns-are-overrated/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24448213</guid>
            <pubDate>Fri, 11 Sep 2020 22:59:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Principles for Naming a Brand]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 11 (<a href="https://news.ycombinator.com/item?id=24447991">thread link</a>) | @darsoli
<br/>
September 11, 2020 | https://mmarchny.com/naming-branding/ | <a href="https://web.archive.org/web/*/https://mmarchny.com/naming-branding/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<!-- Post categories filter -->
	
<!-- added to container container-medium -->
	<div>

					<!-- row + class for blog post cat -->
			<div>

				<div id="primary">
					<main id="main" role="main">

						<!-- deleted to below container-small -->
						<div>

							<!-- <div class="hero clear"> -->
								<!-- Featured media -->
								
							<!-- </div> -->

							

								
<article id="post-1954">

	<!-- overview page feat img -->
	
	
		
		<div>

			
<p><strong>Everything has a name: a child, a pet, cars, and places. It’s how we befriend subjects and objects and it’s how we recall identifiers. But, naming a brand can be a painful process. It can take a long time and sometimes, it seems to never really come together. In order to take the pressure off of finding the perfect name it’s helpful to remember that businesses create brands, not vice versa. Think <em>Mountain Dew</em> (sounds cumbersome), <em>Starbucks</em> (sounds unrelated) and <em>Virgin</em> (sounds like a lack of experience), <em>The Boring Company</em> (sounds negative), <em>Slack</em> (sounds like the opposite of what it does). Attributed meaning and feelings build in the years after naming.</strong></p>



<hr>







<hr>



<div>
<p>
<h2 id="brand-names-in-context">Brand Names in Context</h2>
</p>



<div>
<div>
<div>
<p>First and foremost, a name doesn’t come alone. There will be contextual elements like a tagline, a logo, a color palette that are used on a variety of components, like the top visual on a website, or a headline on an ad. All of those can be filled with words and visuals that reflect a company’s strategy. A name, however, is a central and the longest-standing of all brand components.&nbsp;</p>



<p>Get help from a naming professional or find a name yourself. The following cornerstones make for a process and provide for a good checklist.</p>
</div>



<div>
<p>The most important aspects of your strategy, <em>your product</em> (<a href="https://mmarchny.com/creative-strategy-branding-part-1-company/">what it is</a>), <em>what does it stand for</em> (<a href="https://mmarchny.com/creative-strategy-branding-part-4-positioning/">positioning</a>), <em>who’s it for</em> (<a href="https://mmarchny.com/creative-strategy-branding-part-2-target-market/">target market</a>), need to get across clearly in the most important brand modules: the name, the logo and a tagline.</p>



<p>The more unknown the company or product, the more direct those aspects need to be laid out in branding communications.&nbsp;</p>
</div>
</div>
</div>
</div>



<hr>



<div>
<p>
<h3>Examples</h3>
</p>



<div>
<div>
<div>
<p><strong>Example 1:</strong></p>



<p>Name: Twitter (product: chatter)</p>



<p>Tagline: It’s what’s happening. (positioning: real and now)</p>



<p>Meta description: From breaking news and entertainment to sports and politics, get the full story with all the live commentary. (target market: for news and entertainment readers that look for a variety of opinions)</p>
</div>



<div>
<p><strong>Example 2:</strong></p>



<p>Name: Starbucks, originally known as Starbucks Coffee Company (product: coffee)</p>



<p>Tagline: More than just great coffee. (positioning: quality coffee, snacks and atmosphere)</p>



<p>Visuals and additional copy: Employee photos are in the foreground. Alongside copy that describes values: “not only celebrated coffee but also connection. We’re a neighborhood gathering place, a part of your daily routine. Get to know us and you’ll see: we are so much more than what we brew. We call our employees partners because we are all partners in shared success. We make sure everything we do is through the lens of humanity—from our commitment to the highest-quality coffee in the world, to the way we engage with our customers and communities to do business responsibly.” (target market: for people that seek community)</p>
</div>
</div>
</div>
</div>



<hr>



<div>
<p>
<h2 id="domain-availability">Domain Availability&nbsp;</h2>
</p>



<div>
<div>
<p>At the beginning of the naming process, looking up domains that are available can be helpful. It’ll help find competitors as well. If the domain name is not available, an additional industry identifier can be pre or appended, like –books for a bookstore or –foods or eat– for any food-related brands. Think <em>zolabooks.com</em>. &nbsp;</p>



<p>Broad terms like <em>Solutions</em> should be avoided due to lack of meaning (words that can be used by everybody don’t add meaning). Dot-com for companies or dot-org domains for nonprofits remain strongest and are preferred in the U.S.&nbsp;</p>
</div>
</div>
</div>



<hr>



<div>
<p>
<h2 id="acronyms-founder-names">Acronyms and Founders’ Names</h2>
</p>



<div>
<div>
<div>
<p>Usually, good names are shorter, otherwise they’ll get abbreviated naturally later into an acronym. Think <em>KFC, A.T. &amp; T. and P&amp;G</em>. A name sometimes consists of two or three compound words—the words themselves and their first letters need to make a good combination. <em>SS</em> will always have a bad connotation in some countries. No matter how hard one tries to prohibit the usage of monograms, eventually, these letter combos will make their way into file names, into favicons or other collapsed logo versions, into code, especially used when the product is a technical product where truncated versions occur naturally.</p>



<p><strong>B2C brands focus on names that show personality, culture and positioning.</strong> Common names are <em>Apple</em> (easy and obtainable), <em>Nike and Audi</em>. Brand names do not have to be connected to the actual product, although they certainly can be (think <em>Netflix and Aesop</em>), but an appendix can be added that has the potential to be dropped when a brand is well-known. Think <em>Starbucks Coffee Company vs. Starbucks</em>. Short/ fun/ cool/ approachable/ memorable/ indicative trumps logical and longer. Think <em>Hulu, Kodak, Etsy, Mars, 3M, Nest and Sony.</em></p>
</div>



<div>
<p>Avoid a descriptive category or common industry-specific keyword name for a company name. Competitors will pick similar ones which will not only make your brand blend in but the chance to position the company is wasted. Read the <a href="https://www.newyorker.com/magazine/2011/10/03/famous-names">NYT story</a> on EasyMail, MegaMail, and ProMail. Also, descriptive names are harder to trademark and can be impossible to find through Google search.&nbsp;</p>



<p><strong>Founders’ names</strong> are considered functional names. Think <em>Dell, Ford and Colgate.</em> Carrying personality and positioning from the start is not a given.&nbsp;</p>



<p><strong>B2B brands</strong> often have a more descriptive name; they will get abbreviated and that’s okay. Think <em>UPS, IBM, AWS.</em> The one thing that’s important for B to B names is that they need to have the potential to sound big, or at least not small and definitely not limiting in what services the company sells. <a href="http://blue/">Bluecore</a>’s first name was TriggerMail. Triggering an email was how the company started out but other products were added on later.&nbsp;</p>
</div>
</div>
</div>
</div>



<hr>



<div>
<p>
<h2 id="length-industry-fit-pronunciation"><strong><strong>Length, Industry Fit, Pronunciation</strong></strong></h2>
</p>



<div>
<div>
<div>
<p>Longer names, a group of names and compounds naturally have a tendency to sound smaller unless they include (read: <em>own</em>) an important branch or location of the industry. Think <em>Whole Foods, Natural History Museum, American Airlines</em>.</p>



<p>A name should fit broadly into the field of its peers (read: <em>stand out the right way</em>). It should be easy to remember, have no complicated spelling (or a well-considered or user-tested alternative spelling), be pronounceable in one way only* and it should be ownable within its industry. A domain check and a search through the <a href="http://tmsearch.uspto.gov/">trademark database</a> will be of help, but consulting a trademark lawyer who reviews usage in specific categories, states, national and international use, is money well-invested.</p>
</div>



<p><em>* The former car brand Daewoo turned their unpronounceable name into an ad campaign in 1995. Fage yoghurt still needs to have its pronunciation printed on its packaging. Other names that were created before being tested internationally are Huawei, Renault, Tag Heuer and Moschino. Two Princeton University psychologists have found in a </em><a href="https://www.princeton.edu/news/2006/05/29/study-stock-performance-tied-ease-pronouncing-companys-name"><em>2006 study</em></a><em> that “people are more likely to purchase newly offered stocks that have easily pronounced names.”</em></p>
</div>
</div>
</div>



<hr>



<div>
<p>
<h2 id="naming-trends">Trends</h2>
</p>



<div>
<div>
<p>Different times, different constraints, different trends. For internet companies, the <em>-ster</em> <em>(Napster, Friendster)</em> started in 2001, <em>“My”</em> happened in 2005 (Myspace), and <em>-fy/ -ly/ -y</em> spiked in 2010 <em>(Bitly, Artsy and Weebly). </em>Vowel-dropping for easier trademarking and domain availability was early to mid 2000’s <em>(Flickr, Tumblr, Unbxd, Scribd).</em> The random couple sandwich names mostly found in the fashion industry spiked in 2010. Think <em>Rag &amp; Bone, Kit and Ace, Boll &amp; Branch.&nbsp;</em></p>



<p>Generally, the naming of products (as opposed to the naming of companies) can be more trendy versus classy because they evolve with the market or they have room for a revamp over time.</p>
</div>
</div>
</div>



<hr>



<div>
<p>
<h2 id="spelling-spaces-hyphens"><strong>Spelling, Spaces, Hyphens</strong></h2>
</p>



<div>
<div>
<div>
<p>As for many things, <em>classy</em> wins in the long run because it never goes out of style.&nbsp;</p>



<p><em>Spelling of a brand name within text:</em> </p>



<p>An abbreviated company name should be spelled in all caps, not lowercase. A regular name should be spelled together, first letter capitalized. A name should be separated by space or by hyphen if it consists of multiple words, capitalizing each first letter. When compound words are spelled together, there must be only one way to pronounce the compound, if not, it needs separation. A good test for spelling is to insert the name into long- and short-form copy: in the middle of a sentence, at the beginning of a sentence, into a bulleted list and into a signature. The name needs to have a consistent appearance across all applications and not look awkward (think an all lowercase brand name at the beginning of a sentence).&nbsp;&nbsp;&nbsp;</p>
</div>



<div>
<p><em>Spelling within a logo mark:</em>&nbsp;</p>



<p><strong>Option 1 “Friendly”:</strong> lowercase spelling in logos (think amazon, adidas, citibank and intel, mailchimp, west elm, ebay) makes companies more approachable, casual, younger or shows a focus on tech. However, within text (general copy or headlines), brand names should still start with a capital letter (Sell on Amazon; In 2016, Mailchimp announced …).&nbsp;</p>



<p><strong>Option 2 “Timeless”:</strong> Leading capital letters, separated by space or hyphen if more than one word is a brand that has grown up and owns its identity: Squarespace, Coca-Cola, Microsoft, The Container Store, Walmart.</p>



<p><strong>Option 3:</strong> All caps is another timeless use and often a design decision to give the type a more unified or stronger look. Think IKEA (also spelled in call caps within text), MUJI (spelled Muji within text), ZARA (in text: Zara), COSTCO (in text: Costco), THE HOME DEPOT (in text: The Home Depot), NETFLIX (in text: Netflix).</p>



<p><strong>Option 4:</strong> Leading capital letters but no spaces between compounds shows unity and strength by keeping an emphasis on the roots of both. Can be typographically less attractive and are harder to remember how to spell correctly: FedEx, McDonalds, RedBull, HomeGoods, YouTube.</p>
</div>
</div>
</div>
</div>



<hr>



<div>
<p>
<h2 id="listings-soundcheck"><strong>Listings and Soundcheck</strong></h2>
</p>



<div>
<div>
<p>Not the most important thing but the starting letter is another aspect to consider. Your brand will be listed somewhere alphabetically: as a tech product within a marketplace, in a logo series of partnerships, in a print catalog—the higher the …</p></div></div></div></div></article></div></main></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mmarchny.com/naming-branding/">https://mmarchny.com/naming-branding/</a></em></p>]]>
            </description>
            <link>https://mmarchny.com/naming-branding/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24447991</guid>
            <pubDate>Fri, 11 Sep 2020 22:28:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Database Lab – thin Postgres clones for faster development and testing]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24447922">thread link</a>) | @stansler
<br/>
September 11, 2020 | https://postgres.ai/docs/get-started | <a href="https://web.archive.org/web/*/https://postgres.ai/docs/get-started">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><p><span><table>
<thead>
<tr><th></th><th></th></tr>
</thead>
<tbody>
<tr><td><a href="https://postgres.ai/docs/database-lab">Database Lab Engine</a> (open source)<br>Open-source technology to clone databases of any size in seconds</td><td><a href="https://postgres.ai/docs/joe-bot">Joe, SQL optimization chatbot</a> (open source)<br>Run <code>EXPLAIN ANALYZE</code> and optimize SQL on instantly provisioned full-size database copies</td></tr>
<tr><td><a href="https://postgres.ai/docs/staging">Dev/QA/Staging databases with superpowers</a><br>Develop and test using full-size database copies provided in seconds</td><td><a href="https://postgres.ai/docs/database-changes-cicd">CI/CD observer for DB schema changes</a><br>Prevent performance degradation and downtime when deploying database schema changes</td></tr>
<tr><td><a href="https://postgres.ai/docs/checkup">postgres-checkup</a> (open source)<br>Automated health-checks and query analysis for heavily-loaded PostgreSQL databases</td><td><a href="https://postgres.ai/docs/data-access">Detached replicas</a><br>Use BI tools, run analytical queries, perform data export without replication lags and bloat</td></tr>
<tr><td><a href="https://postgres.ai/docs/tutorials/database-lab-tutorial-amazon-rds">Database Lab tutorial for Amazon RDS</a><br>Get started to use Database Lab for Amazon RDS PostgreSQL</td><td><a href="https://postgres.ai/docs/tutorials/database-lab-tutorial">Database Lab tutorial</a><br>Get started to use Database Lab for any PostgreSQL</td></tr>
</tbody>
</table>
<!--#### [Data recovery /  Instantaneously recover lost data](/docs/data-recovery)
Recover accidentally deleted data. Using thin cloning, the point-in-time recovery (PITR) can be performed without long waiting.
-->
<h2>What is Database Lab?</h2>
<p>Database Lab is used to boost software development via enabling ultra-fast provisioning of databases of any size. Developers, DBAs, and QA engineers work with full-sized independent clones of PostgreSQL databases. Development and testing tasks are accomplished much faster, with more iterations done, with better quality achieved and with much less money spent.</p>
<p><img src="https://postgres.ai/docs/assets/cicd-transform.png" alt="CI/CD transformation with Database Lab"></p>
<ul>
<li>Optimize non-production infrastructure costs by 10x.</li>
<li>Drastically improve development quality.</li>
<li>Get rid of downtimes and avoid performance degradation.</li>
<li>Cut half of the TTM (time to market), develop 2x faster than competitors.</li>
</ul>
<p><img src="https://postgres.ai/docs/assets/architecture.png" alt="Database Lab architecture"></p>
<h2>👋 Database Lab "Private Beta" program</h2>
<p>Database Lab Platform (SaaS) is currently in a "private beta" mode, being tested by several hundred engineers. Want to become an early adopter? Join Database Lab by <a href="http://postgres.ai/">Postgres.ai</a> "Private Beta" program today: <a href="https://postgres.ai/console/">https://postgres.ai/console/</a>.</p>
</span></p></article></div></div>]]>
            </description>
            <link>https://postgres.ai/docs/get-started</link>
            <guid isPermaLink="false">hacker-news-small-sites-24447922</guid>
            <pubDate>Fri, 11 Sep 2020 22:16:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Retrospective of my first useful Rust project]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24447771">thread link</a>) | @lukastyrychtr
<br/>
September 11, 2020 | https://jamesmcm.github.io/blog/2020/09/05/vopono/#en | <a href="https://web.archive.org/web/*/https://jamesmcm.github.io/blog/2020/09/05/vopono/#en">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>This post is a retrospective of my first “useful” Rust project. <a href="https://github.com/jamesmcm/vopono">vopono</a> 
is a Linux program to launch applications in temporary network
namespaces (managed by vopono), in order to run specific applications
through VPN connections, without affecting the rest of your system.</p>

<p>vopono is <a href="https://github.com/jamesmcm/vopono">available on Github</a> (and in the <a href="https://aur.archlinux.org/packages/vopono/">AUR on Arch Linux</a>) and
licensed under the GPLv3 license (<a href="https://www.gnu.org/philosophy/pragmatic.html">see reasoning here</a>).</p>

<p>We’ll consider the motivation and background to creating vopono, the
upsides and downsides of writing it in Rust (and existing issues), and
some points about starting new side projects in general. I hope this
helps new Rust programmers starting their own first projects, or for
other programmers to consider using Rust.</p>

<!--more-->

<p>Opinions expressed are solely my own and do not express the views or opinions of my employer.</p>

<h2 id="background">Background</h2>

<p>I’ve used VPN services for many years, previously as a customer of
PrivateInternetAccess, and now with Mullvad (since
<a href="https://news.ycombinator.com/item?id=21584958">PrivateInternetAccess was purchased by a less scrupulous parent company</a>), as it is very
useful for working around network traffic restrictions (e.g. SSH access
restrictions or blocked websites) whilst travelling.</p>

<p>However, I often wanted to be able to quickly connect to the VPN without
disrupting other ongoing connections (i.e. video calls, etc.). In 2015,
I learnt how network namespaces could do this (on Linux), and pieced together some
bash scripts for OpenVPN <a href="https://unix.stackexchange.com/questions/149293/feed-all-traffic-through-openvpn-for-a-specific-network-namespace-only">from this StackExchange post</a>.</p>

<p>I used this for a few years, but it was a bit inconvenient having to
manually launch the network namespace. Especially if you wanted to
connect to different servers in order to test geolocation for example.</p>

<p>In April 2020, Wireguard was merged in to the Linux kernel
5.6, and became much more readily available with VPN providers. This,
combined with the switch to Mullvad, inspired me to add Wireguard
support to the scripts I was using. But I thought it would be best to
also address the issues of manually managing the network namespaces and
create a comprehensive application to handle OpenVPN and Wireguard
connections for various VPN providers, and create and destroy the
network namespaces on demand.</p>

<p>This was the start of vopono, my first
useful Rust project (I suppose <a href="https://github.com/jamesmcm/s3rename">s3rename</a> was also useful, but a much smaller
scope).</p>

<h2 id="benefits-of-rust">Benefits of Rust</h2>

<p>I chose to write vopono in Rust as I am still learning the language, and
greatly appreciate the ease of debugging with tools like <a href="https://github.com/rust-analyzer/rust-analyzer">rust-analyzer</a>
and <a href="https://github.com/rust-lang/rust-clippy">clippy</a>. There are many
other benefits too:</p>

<h3 id="enums">Enums</h3>

<p>Rust’s <a href="https://doc.rust-lang.org/book/ch06-01-defining-an-enum.html">native enum support</a> makes reasoning and debugging much easier
when dealing with enumerated values (like the choice between the TCP and
UDP protocols for OpenVPN connections). The Rust compiler forces us to
handle every possible value helping to prevent bugs from ever being
written.</p>

<h3 id="structopt">StructOpt</h3>

<p><a href="https://crates.io/crates/structopt">StructOpt</a> is a great crate for handling command-line options and
arguments via derived trait implementations over your structs defining
commands and subcommands. This allows you to abstract away dealing with command-line arguments directly,
and for the relevant code to be somewhat self-documenting (as <a href="https://doc.rust-lang.org/stable/rust-by-example/meta/doc.html">doc comments</a> are used to provide the user-facing help output).</p>

<p>Note that some developers prefer to use <a href="https://crates.io/crates/clap">clap</a> directly.</p>

<h3 id="result-and-anyhow">Result and anyhow</h3>

<p>Rust’s <a href="https://doc.rust-lang.org/std/result/enum.Result.html">Result enum</a> 
and <code>?</code> operator (the <a href="https://doc.rust-lang.org/edition-guide/rust-2018/error-handling-and-panics/the-question-mark-operator-for-easier-error-handling.html">try operator</a>)
make it simple and ergonomic to handle operations which may fail
(which are almost all operations when dealing with disk IO and
launching processes).</p>

<p>It is also very convenient when working with fallible operations over a
collection, where we may want to return to the user a list of operations
which failed. In Rust, we can 
<a href="https://doc.rust-lang.org/stable/rust-by-example/error/iter_result.html">filter and map over a collection of Results</a> 
to a collection of Errors and then return that to the user - this feels
very natural compared to other languages.</p>

<p>Combined with the <a href="https://crates.io/crates/anyhow">anyhow crate</a>, it is easy to provide useful error
messages to the end-user whilst also keeping the code very concise.</p>

<h3 id="serde">Serde</h3>

<p>The <a href="https://crates.io/crates/serde">Serde crate</a> provides traits you can derive on your structs,
allowing for easy serialization and deserialization.</p>

<p>In vopono this is used to serialize and deserialize lockfiles, so that
if you launch a new application in an existing network namespace (via
vopono), the namespace will not be destroyed until <em>both</em> applications
have terminated.</p>

<h3 id="drop">Drop</h3>

<p>The <a href="https://doc.rust-lang.org/std/ops/trait.Drop.html">Drop trait</a> allows us to run a destructor when a struct is
dropped (i.e. goes out of scope). This is used in vopono to
automatically destroy the network namespaces when the application is
closed. I initially got the idea for using <code>Drop</code> this way from the
<a href="https://github.com/r-darwish/alma">ALMA source code</a>.</p>

<p>Note this causes some issues (discussed below) when we want to skip
destructors in some cases. Also if vopono is instantly terminated (i.e.
<code>kill -9</code>) these will likely not run, so vopono is written to clean up
any orphaned resources when it is executed - i.e. namespaces or
lockfiles with no running applications.</p>

<h3 id="cargo">Cargo</h3>

<p>The Cargo package manager itself is a great benefit of using Rust. For
example, when writing vopono it made it trivial to add the
<a href="https://crates.io/crates/compound_duration">compound_duration</a> crate,
used only for reporting the uptime of running network namespaces.</p>

<p>The specification of the software license in the <code>Cargo.toml</code> file is
also a great feature, making it easy to verify that your dependencies
have compatible licenses.</p>

<h3 id="include_str-macro">include_str macro</h3>

<p>The <a href="https://doc.rust-lang.org/std/macro.include_str.html">include_str macro</a> can be used to include a file on disk as a
static string in the binary at compile time. This is used in vopono for
providers where we cannot download certain files by other means e.g.
with TigerVPN because the configuration details are behind a login with
a captcha and there is no API.</p>

<h3 id="rustls">Rustls</h3>

<p><a href="https://crates.io/crates/rustls">Rustls</a> is a TLS library which can be
used in place of OpenSSL. This is used in the <code>vopono sync</code> command,
which gets provider configuration files.</p>

<p>This subcommand relies on the <a href="https://crates.io/crates/reqwest">reqwest crate</a>
to make HTTPS requests, but we want to avoid depending on OpenSSL to make it easier to
build a statically linked binary that will be independent of the runtime
environment. Fortunately we only need to set the “rustls” feature flag
in the reqwest dependency.</p>

<h3 id="musl-and-static-linking">musl and static linking</h3>

<p>The <code>x86_64-unknown-linux-musl</code> target can be used to (cross-)compile,
<a href="https://blog.rust-lang.org/2016/05/13/rustup.html">statically linking with musl</a> instead of dynamically linking to glibc
(the default target). This means we can deploy the resulting binary
without worrying about glibc version mismatches (if we deploy to a
platform with an earlier version of glibc).</p>

<h2 id="difficulties">Difficulties</h2>

<h3 id="small-standard-library">Small standard library</h3>

<p>If you come from scripting languages, you may find that Rust has a
smaller standard library compared to those languages. For example, there
is no recursive copy (<code>cp -r</code> equivalent) in the standard library
directly, and I had to do this using the 
<a href="https://crates.io/crates/walkdir">walkdir crate</a> and copying each item.</p>

<h3 id="compile-times">Compile times</h3>

<p>Rust has longer compile times than most other languages (except perhaps
C++) this is particularly true when using crates which include
procedural macros.</p>

<p>There a few options to <a href="https://vfoley.xyz/rust-compile-speed-tips/">reduce compile times</a>
(also <a href="https://endler.dev/2020/rust-compile-times/">see this more recent post</a>),
such as using <a href="https://github.com/mozilla/sccache">sccache</a> to cache build artifacts.</p>

<h3 id="binary-size-and-feature-creep">Binary size and feature creep</h3>

<p>As more dependencies are added, the final binary size can grow
considerably. To control this, it’s recommended to use <a href="https://doc.rust-lang.org/cargo/reference/features.html">feature flags</a>
in your <code>Cargo.toml</code> file (and disabling default features) to
include only what you need from large dependencies.</p>

<p>You can also use <a href="https://crates.io/crates/cargo-udeps">cargo-udeps</a> to
detect unused dependencies.</p>

<h3 id="minimum-rust-version-and-dependencies">Minimum Rust version and dependencies</h3>

<p>The Rust features and parts of the standard library that you use will
result in an effective minimum Rust version for your project. I had <a href="https://github.com/jamesmcm/vopono/issues/2">one
issue</a> result from the
<a href="https://crates.io/crates/compound_duration">compound_duration crate</a> mentioned above which raised the minimum Rust
version to 1.43.</p>

<p>As far as I know there is no way to automatically determine the minimum
Rust version, although <a href="https://www.reddit.com/r/rust/comments/8kkigi/how_to_find_out_a_minimum_rust_compiler_version/">this discussion on Reddit</a>
has scripts for compiling with many minor versions until you build
successfully.</p>

<h2 id="ongoing-issues">Ongoing issues</h2>

<h3 id="dialoguer-validation-and-passing-references-to-closures">dialoguer validation and passing references to closures</h3>

<p>vopono uses the <a href="https://crates.io/crates/dialoguer">dialoguer crate</a> for user input for the <code>vopono sync</code>
command. I also validate the input using the <code>validate_with()</code> method so
that the user gets feedback immediately and can correct any errors.</p>

<p>However, the <code>validate_with()</code> method <a href="https://docs.rs/dialoguer/0.6.2/dialoguer/struct.Input.html#method.validate_with">requires that the closure used has
a static lifetime</a>.
This is problematic for checking whether the user-entered Wireguard private key
matches the chosen public key, since we need to include the previously-chosen
public key in the closure - but this doesn’t have a static lifetime.</p>

<p>For now I worked around this with extra clones (<a href="https://github.com/jamesmcm/vopono/blob/master/src/providers/mozilla/wireguard.rs#L65">see devices_clone</a>)
but hopefully a better solution is possible. Perhaps the static lifetime
restriction in dialoguer could also be relaxed (since we know the
closure will terminate before we receive the input and continue).</p>

<p>This is <a href="https://github.com/jamesmcm/vopono/issues/19">tracked in this issue</a>. If you have any suggestions please add a comment there!</p>

<h3 id="skipping-destructors">Skipping destructors</h3>

<p>As mentioned previously, vopono uses the <a href="https://doc.rust-lang.org/std/ops/trait.Drop.html">Drop trait</a> to
automatically clean up resources when the relevant structs go out of
scope. However, sometimes we don’t want to trigger these destructors but
still have the structs go out of scope - for example, if we have
multiple vopono processes running applications in the same network
namespace, then we don’t want to destroy the network namespace until the
final application has terminated. So if other lockfiles still exist, we need
to prevent the clean-up destructors from firing.</p>

<p>For now this is done by putting the relevant structs in a Box, and then
calling <code>Box::leak()</code> (<a href="https://doc.rust-lang.org/std/boxed/struct.Box.html#method.leak">docs here</a>).
This works but feels a bit clunky when dealing with multiple structs/fields (e.g. <a href="https://github.com/jamesmcm/vopono/blob/4ebf4b6bdc493c4d95bf6e237136b330723aaf27/src/netns.rs#L308">here preventing the destructors when another vopono instance is using the same namespace</a>):</p>

<div><div><pre><code><span>debug!</span><span>(</span><span>"Skipping destructors since other vopono instance using this namespace!"</span><span>);</span>
<span>let</span> <span>openvpn</span> <span>=</span> <span>self</span><span>.openvpn</span><span>.take</span><span>();</span>
<span>let</span> <span>openvpn</span> <span>=</span> <span>Box</span><span>::</span><span>new</span><span>(</span><span>openvpn</span><span>);</span>
<span>Box</span><span>::</span><span>leak</span><span>(</span><span>openvpn</span><span>);</span>
</code></pre></div></div>

<p>One possible alternative might be to use <a href="https://doc.rust-lang.org/std/mem/struct.ManuallyDrop.html">std::mem::ManuallyDrop</a>
, however then the <code>drop()</code> method is unsafe, so this might end up being
even less ergonomic.</p>

<p>This is tracked <a href="https://github.com/jamesmcm/vopono/issues/20">in this issue</a>.</p>

<h3 id="vpn-providers---enum-or-structs-with-traits">VPN Providers …</h3></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jamesmcm.github.io/blog/2020/09/05/vopono/#en">https://jamesmcm.github.io/blog/2020/09/05/vopono/#en</a></em></p>]]>
            </description>
            <link>https://jamesmcm.github.io/blog/2020/09/05/vopono/#en</link>
            <guid isPermaLink="false">hacker-news-small-sites-24447771</guid>
            <pubDate>Fri, 11 Sep 2020 21:57:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Japanese Spacecraft Will Shoot Martian Moons in 8K Decision]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24447727">thread link</a>) | @tokstesla
<br/>
September 11, 2020 | https://www.newshables.com/2020/09/11/japanese-spacecraft-will-shoot-martian-moons-in-8k-decision/ | <a href="https://web.archive.org/web/*/https://www.newshables.com/2020/09/11/japanese-spacecraft-will-shoot-martian-moons-in-8k-decision/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-2873" itemscope="" itemtype="https://schema.org/Article">
        

        

        <div>

        <p><a href="https://www.newshables.com/wp-content/uploads/2020/09/jaxa-spacecraft-film-martian-moons-8k-resolution-768x403.jpg" data-caption=""><img width="696" height="365" src="https://www.newshables.com/wp-content/uploads/2020/09/jaxa-spacecraft-film-martian-moons-8k-resolution-768x403-696x365.jpg" srcset="https://www.newshables.com/wp-content/uploads/2020/09/jaxa-spacecraft-film-martian-moons-8k-resolution-768x403-696x365.jpg 696w, https://www.newshables.com/wp-content/uploads/2020/09/jaxa-spacecraft-film-martian-moons-8k-resolution-768x403-300x157.jpg 300w, https://www.newshables.com/wp-content/uploads/2020/09/jaxa-spacecraft-film-martian-moons-8k-resolution-768x403.jpg 768w" sizes="(max-width: 696px) 100vw, 696px" alt="" title="jaxa-spacecraft-film-martian-moons-8k-resolution-768x403.jpg" data-srcset="https://www.newshables.com/wp-content/uploads/2020/09/jaxa-spacecraft-film-martian-moons-8k-resolution-768x403-696x365.jpg 696w, https://www.newshables.com/wp-content/uploads/2020/09/jaxa-spacecraft-film-martian-moons-8k-resolution-768x403-300x157.jpg 300w, https://www.newshables.com/wp-content/uploads/2020/09/jaxa-spacecraft-film-martian-moons-8k-resolution-768x403.jpg 768w" data-src="https://www.newshables.com/wp-content/uploads/2020/09/jaxa-spacecraft-film-martian-moons-8k-resolution-768x403-696x365.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></a></p>
        
 <!-- A generated by theme --> 



 <!-- end A --> 


<div>
<h2>Mars in 8K</h2>
<p>Along side the Japan Broadcasting Company (NHK), the Japan Aerospace Exploration Company (JAXA) has introduced that it’s planning to <a href="https://phys.org/news/2020-09-martian-moons-exploration-spacecraft-ultra-high.html">photograph Mars’ mysterious moons</a> with cameras that may shoot 8K ultra-high-definition photos.</p>
<p>If profitable, it might be the primary time in historical past Mars and its moons are captured in such element.</p>
<p>To drag it off, the 2 organizations are teaming as much as develop the “Tremendous Hello-Imaginative and prescient Digicam,” designed to be hooked up to JAXA’s Martian Moons eXploration (MMX) spacecraft, which is ready to launch in 2024.</p>
<h2>Phobos Anomaly</h2>
<p>The MMX mission, <a href="https://futurism.com/the-byte/japan-sample-return-mission-mars-moon">greenlit</a> by the Japanese authorities again in February, will try to uncover the mysteries surrounding the origin tales of Mars’s two comparatively tiny moons, Deimos and Phobos. They’re extremely uncommon as they orbit the Purple Planet at extraordinarily shut distances. Deimos’ orbit takes it as shut as <a href="https://solarsystem.nasa.gov/moons/mars-moons/in-depth/">3,700 miles</a> away from the Martian floor — about one p.c of the gap between the Earth and its Moon.</p>
<p>Other than the digital camera, the spacecraft will carry 11 scientific devices to the Martian system. It is going to even try to gather a floor pattern from Phobos’&nbsp;floor earlier than taking the lengthy journey house.</p>
<p>The digital camera will snap ultra-HD photos<strong>&nbsp;</strong>and broadcast them for the world to see, courtesy of JAXA. The untouched recordsdata might be domestically saved on a recording system hooked up to the MMX spacecraft and can hopefully make all of it the way in which again to Earth — if every little thing goes in keeping with plan.</p>
<p><strong>READ MORE: </strong><a href="https://phys.org/news/2020-09-martian-moons-exploration-spacecraft-ultra-high.html">Martian Moons eXploration spacecraft to take ultra-high definition images of Mars via 8K camera</a> [JAXA] <strong><br></strong></p>
<p><strong>Extra on MMX:</strong> <em><a href="https://futurism.com/the-byte/japan-sample-return-mission-mars-moon">Japan Gives the ‘Go’ to Sample Return Mission to Mars Moon</a></em></p>
</div>


 <!-- A generated by theme --> 



 <!-- end A --> 

        </div>


        

    </article></div>]]>
            </description>
            <link>https://www.newshables.com/2020/09/11/japanese-spacecraft-will-shoot-martian-moons-in-8k-decision/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24447727</guid>
            <pubDate>Fri, 11 Sep 2020 21:51:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What's wrong with social science and how to fix it]]>
            </title>
            <description>
<![CDATA[
Score 85 | Comments 53 (<a href="https://news.ycombinator.com/item?id=24447724">thread link</a>) | @michael_fine
<br/>
September 11, 2020 | https://fantasticanachronism.com/2020/09/11/whats-wrong-with-social-science-and-how-to-fix-it/ | <a href="https://web.archive.org/web/*/https://fantasticanachronism.com/2020/09/11/whats-wrong-with-social-science-and-how-to-fix-it/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><blockquote><p>I've seen things you people wouldn't believe.</p></blockquote><p>Over the past year, I have skimmed through 2578 social science papers, spending about 2.5 minutes on each one. This was due to my participation in <a href="https://www.replicationmarkets.com/" target="_blank" rel="noopener">Replication Markets</a>, a part of DARPA's SCORE program, whose goal is to evaluate the reliability of social science research. 3000 studies were split up into 10 rounds of ~300 studies each. Starting in August 2019, each round consisted of one week of surveys followed by two weeks of market trading. I finished in first place in 3 out 10 survey rounds and 6 out of 10 market rounds. In total, about $200,000 in prize money will be awarded.</p><p>The studies were sourced from all social sciences disciplines (economics, psychology, sociology, management, etc.) and were published between 2009 and 2018 (in other words, most of the sample came from the post-replication crisis era).</p><p>The average replication probability in the market was 54%; while the replication results are not out yet (250 of the 3000 papers will be replicated), previous experiments have shown that prediction markets work well.<span><a href="#fn19282306691" rel="footnote"><sup id="fnref19282306691">1</sup></a></span></p><p>This is what the distribution of my own predictions looks like:<span><a href="#fn19282306692" rel="footnote"><sup id="fnref19282306692">2</sup></a></span></p><p><img src="https://fantasticanachronism.com/images/skimmed_mypredsdist-67f351a8a634ca87ace22fd62155e7c5.png"></p><p>My average forecast was in line with the market. A quarter of the claims were above 76%. And a quarter of them were below 33%: we're talking hundreds upon hundreds of terrible papers, and this is just a tiny sample of the annual academic production.</p><p>Criticizing bad science from an abstract, 10000-foot view is pleasant: you hear about some stuff that doesn't replicate, some methodologies that seem a bit silly. "They should improve their methods", "p-hacking is bad", "we must change the incentives", you declare Zeuslike from your throne in the clouds, and then go on with your day.</p><p>But actually diving into the sea of trash that is social science gives you a more tangible perspective, a more visceral revulsion, and perhaps even a sense of Lovecraftian awe at the sheer magnitude of it all: a vast landfill—a great agglomeration of garbage extending as far as the eye can see, effluvious waves crashing and throwing up a foul foam of p=0.049 papers. As you walk up to the diving platform, the deformed attendant hands you a pair of flippers. Noticing your reticence, he gives a subtle nod as if to say: "come on then, jump in".</p><h2 id="They-Know-What-They-39-re-Doing"><a href="#They-Know-What-They-39-re-Doing" title="They Know What They're Doing"></a>They Know What They're Doing</h2><p>Prediction markets work well because predicting replication is easy.<span><a href="#fn19282306693" rel="footnote"><sup id="fnref19282306693">3</sup></a></span> There's no need for a deep dive into the statistical methodology or a rigorous examination of the data, no need to scrutinize esoteric theories for subtle errors—these papers have obvious, surface-level problems.</p><p>There's a popular belief that weak studies are the result of unconscious biases leading researchers down a "garden of forking paths". Given enough "researcher degrees of freedom" even the most punctilious investigator can be misled.</p><p>I find this belief impossible to accept. The brain is a credulous piece of meat<span><a href="#fn19282306694" rel="footnote"><sup id="fnref19282306694">4</sup></a></span> but there are limits to self-delusion. Most of them have to know. It's understandable to be led down the garden of forking paths while producing the research, but when the paper is done and you give it a final read-over you will surely notice that all you have is a n=23, p=0.049 three-way interaction effect (one of dozens you tested, and with no multiple testing adjustments of course). At that point it takes more than a <em>subtle unconscious bias</em> to believe you have found something real. And even if the authors really are misled by the forking paths, what are the editors and reviewers doing? Are we supposed to believe they are all gullible rubes?</p><p>People within the academy don't want to rock the boat. They still have to attend the conferences, secure the grants, publish in the journals, show up at the faculty meetings: all these things depend on their peers. When criticising bad research it's easier for everyone to blame the forking paths rather than the person walking them. No need for uncomfortable unpleasantries. The fraudster can admit, without much of a hit to their reputation, that indeed they were <em>misled</em> by that <em>dastardly garden</em>, really through no fault of their own whatsoever, at which point their colleagues on twitter will applaud and say "ah, good on you, you handled this tough situation with such exquisite virtue, this is how progress happens! hip, hip, hurrah!" What a ridiculous charade.</p><p>Even when they do accuse someone of wrongdoing they use terms like "Questionable Research Practices" (QRP). How about Questionable Euphemism Practices?</p><ul><li>When they measure a dozen things and only pick their outcome variable at the end, that's not the garden of forking paths but the greenhouse of fraud.</li><li>When they do a correlational analysis but give "policy implications" as if they were doing a causal one, they're not walking around the garden, they're doing the landscaping of forking paths.</li><li>When they take a continuous variable and arbitrarily bin it to do subgroup analysis or when they add an <em>ad hoc</em> quadratic term to their regression, they're...fertilizing the garden of forking paths? (Look, there's only so many horticultural metaphors, ok?)</li></ul><p>The bottom line is this: if a random schmuck with zero domain expertise like me can predict what will replicate, <em>then so can scientists who have spent half their lives studying this stuff</em>. But they sure don't act like it.</p><h2 id="or-Maybe-They-Don-39-t"><a href="#or-Maybe-They-Don-39-t" title="...or Maybe They Don't?"></a>...or Maybe They Don't?</h2><blockquote><p>The horror! The horror!</p></blockquote><p>Check out this crazy chart from <a href="https://www.pnas.org/content/early/2020/04/28/1909046117" target="_blank" rel="noopener">Yang et al. (2020)</a>:</p><p><img src="https://fantasticanachronism.com/images/skimmed_citations-7d4f72c6e9582a5ba8775da70eda80e1.png"></p><p>Yes, you're reading that right: studies that replicate are cited at the same rate as studies that do not. Publishing your own weak papers is one thing, but citing other people's weak papers? This seemed implausible, so I decided to do my own analysis with a sample of 250 articles from the Replication Markets project. The correlation between citations per year and (market-estimated) probability of replication was -0.05!</p><p>You might hypothesize that the citations of non-replicating papers are negative, but negative citations are extremely rare.<span><a href="#fn19282306695" rel="footnote"><sup id="fnref19282306695">5</sup></a></span> <a href="https://www.pnas.org/content/112/45/13823" target="_blank" rel="noopener">One study</a> puts the rate at 2.4%. Astonishingly, even <em>after retraction</em> the <a href="https://pubmed.ncbi.nlm.nih.gov/18974415/" target="_blank" rel="noopener">vast majority of citations are positive</a>, and those positive citations <a href="https://pubmed.ncbi.nlm.nih.gov/20136577/" target="_blank" rel="noopener">continue for decades after retraction</a>.<span><a href="#fn19282306696" rel="footnote"><sup id="fnref19282306696">6</sup></a></span></p><p>As in all affairs of man, it once again comes down to Hanlon's Razor. Either:</p><ol><li>Malice: they know which results are likely false but cite them anyway.</li><li>or, Stupidity: they can't tell which papers will replicate even though it's quite easy.</li></ol><p>Accepting the first option would require a level of cynicism that even I struggle to muster. But the alternative doesn't seem much better: <em>how can they not know?</em> I, an idiot with no relevant credentials or knowledge, can fairly accurately determine good research from bad, but all the tenured experts can not? How can they not tell <em>which papers are retracted</em>?</p><p>I think the most plausible explanation is that scientists don't read the papers they cite, which I suppose involves both malice <em>and</em> stupidity.<span><a href="#fn19282306697" rel="footnote"><sup id="fnref19282306697">7</sup></a></span> <a href="https://www.gwern.net/Scanners#citogenesis-how-often-do-researchers-not-read-the-papers-they-cite" target="_blank" rel="noopener">Gwern has an write-up on this question</a> citing some ingenious analyses based on the proliferation of misprints: "Simkin &amp; Roychowdhury venture a guess that as many as 80% of authors citing a paper have not actually read the original". Once a paper is out there nobody bothers to check it, even though they know there's a 50-50 chance it's false!</p><p>Whatever the explanation might be, the fact is that the academic system does not allocate citations to true claims.<span><a href="#fn19282306698" rel="footnote"><sup id="fnref19282306698">8</sup></a></span> This is bad not only for the direct effect of basing further research on false results, but also because it distorts the incentives scientists face. If nobody cited weak studies, we wouldn't have so many of them. Rewarding impact without regard for the truth inevitably leads to disaster.</p><h2 id="There-Are-No-Journals-With-Strict-Quality-Standards"><a href="#There-Are-No-Journals-With-Strict-Quality-Standards" title="There Are No Journals With Strict Quality Standards"></a>There Are No Journals With Strict Quality Standards</h2><p>Naïvely you might expect that the top-ranking journals would be full of studies that are highly likely to replicate, and the low-ranking journals would be full of p&lt;0.1 studies based on five undergraduates. Not so! Like citations, journal status and quality are not very well correlated: <a href="https://www.frontiersin.org/articles/10.3389/fnhum.2018.00037/full" target="_blank" rel="noopener">there is no association between statistical power and impact factor</a>, and journals with higher impact factor <a href="https://www.biorxiv.org/content/10.1101/071530v1.full.pdf" target="_blank" rel="noopener">have more papers with erroneous p-values</a>.</p><p>This pattern is repeated in the Replication Markets data. As you can see in the chart below, there's no relationship between h-index (a measure of impact) and average expected replication rates. There's also no relationship between h-index and expected replication <em>within</em> fields.</p><p><img src="https://fantasticanachronism.com/images/skimmed_journalhindex-34ca20d3877248fe6b7313c3e2d39fae.png"></p><p>Even the <em>crème de la crème</em> of economics journals barely manage a ⅔ expected replication rate. 1 in 5 articles in QJE scores below 50%, and this is a journal that accepts just 1 out of every 30 submissions. Perhaps this (partially) explains why scientists are undiscerning: journal reputation acts as a cloak for bad research. It would be fun to test this idea empirically.</p><p>Here you can see the distribution of replication estimates for every journal in the RM sample:</p><p><img src="https://fantasticanachronism.com/images/skimmed_journals-cdc1139ad4faf1819b8b42db914dbe81.png"></p><p>As far as I can tell, for most journals the question of whether the results in a paper are true is a matter of secondary importance. If we model journals as wanting to maximize "impact", then this is hardly surprising: as we saw above, citation counts are unrelated to truth. If scientists were more careful about what they cited, then journals would in turn be more careful about what they publish.</p><h2 id="Things-Are-Not-Getting-Better"><a href="#Things-Are-Not-Getting-Better" title="Things Are Not Getting Better"></a>Things Are Not Getting Better</h2><p>Before we got to see any of the actual Replication Markets studies, we voted on the expected replication rates by year. <a href="https://royalsocietypublishing.org/doi/10.1098/rsos.200566" target="_blank" rel="noopener">Gordon et al. (2020)</a> has that data: replication rates were expected to steadily increase from 43% in 2009/2010 to 55% in 2017/2018.</p><p><img src="https://fantasticanachronism.com/images/skimmed_years_pre-7012095f551422f22db31bfffda1c899.png"></p><p>This is what the average predictions looked like <em>after</em> seeing the papers: from 53.4% in 2009 to 55.8% in 2018 (difference not statistically significant; black dots are means).</p><p><img src="https://fantasticanachronism.com/images/skimmed_years-1c0573dfb59a70e36a43deb2692229bf.png"></p><p>I frequently encounter the notion that after the replication crisis hit there was some sort of great improvement in the social sciences, that people wouldn't even dream of publishing studies based on 23 undergraduates any more (I actually saw plenty of those), etc. Stuart Ritchie's new book praises …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://fantasticanachronism.com/2020/09/11/whats-wrong-with-social-science-and-how-to-fix-it/">https://fantasticanachronism.com/2020/09/11/whats-wrong-with-social-science-and-how-to-fix-it/</a></em></p>]]>
            </description>
            <link>https://fantasticanachronism.com/2020/09/11/whats-wrong-with-social-science-and-how-to-fix-it/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24447724</guid>
            <pubDate>Fri, 11 Sep 2020 21:51:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hybrid Hyperoptimization: The most ambitious crossover event in autodiff history]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24447719">thread link</a>) | @hardmath123
<br/>
September 11, 2020 | https://hardmath123.github.io/hybrid-hyperoptimization.html | <a href="https://web.archive.org/web/*/https://hardmath123.github.io/hybrid-hyperoptimization.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="postcontent">
            <section>
                
                <center><em><p>The most ambitious crossover event in automatic differentiation history</p>
</em></center>
                <h4>Friday, September 11, 2020 · 4 min read</h4>
<blockquote>
<p> Summary of this post: It turns out that by carefully mixing forward-mode and
 reverse-mode automatic differentiation, you can greatly simplify certain
 hyperparameter optimization algorithms.</p>
</blockquote>
<p>Here’s a fun recursive idea: just like how we optimize the parameters of
machine learning models by gradient descent, we can also their
<em>hyperparameters</em> by gradient descent. This is by no means a new idea; you can
find 20-year-old papers that discuss (for example) optimizing gradient descent
step sizes by gradient descent itself.</p>
<p>Broadly, there are two ways to do this. The “short-term” way is to take a
<em>single</em>  step of gradient descent, and then based on how that goes, adjust the
hyperparameters. That’s the premise of the 2018 paper <a href="https://arxiv.org/abs/1703.04782">Online Learning Rate
Adaptation with Hypergradient Descent</a>: it
turns out that you can do this in an extremely lightweight way. You would hope
that over time the hyperparameters converge to something optimal alongside the
parameters (and indeed that is the case, though you have to be careful).</p>
<p>The “long-term” way is to train <em>several</em> steps and <em>then</em> backpropagate
through the <em>entire training</em> to adjust the hyperparameters. The hope is that
this provides a stronger “signal” to the hyperparameter-gradient, which is
better for convergence. But, this comes at the (tremendous) expense of having
to store a copy of the entire computation graph for several steps of training,
and then backpropagate through it. If your model has 1GB of parameters, you
need to store ~1GB worth of numbers for <em>each step</em>. You can imagine that adds
up over the course of many epochs, and so the algorithm is severely limited by
how much RAM you have.</p>
<p>The 2015 paper <a href="https://arxiv.org/abs/1502.03492">Gradient-based Hyperparameter Optimization through Reversible
Learning</a> makes this work by throwing away
the intermediate steps of the computation graph and then JIT-re-computing it
“in reverse” during backpropagation. It’s a clever technique, but kind of hairy
and hard to implement (you have to be super careful about numerical precision).</p>
<p>Here’s a graph that visualizes these two techniques (<a href="https://arxiv.org/abs/1909.13371">from this
paper</a>). You’re looking at several parallel
loss curves (($\log(f)$) is the loss plotted on a log scale), pointing towards
you, arranged in order of the “step size” hyperparameter
(that’s ($\log(\alpha)$)). The orange curve represents a “short-term”
hyperparameter optimization, which is allowed to move along the “step size”
axis at each step. The “long-term” hyperparameter optimization instead
optimizes directly on the thick black dashed “U” — that is, after <em>several</em>
steps of training. You can see how the latter is smoother, but also much harder
to compute.</p>
<p><img src="https://hardmath123.github.io/static/hybrid-hyperoptimization/fig-metasurface.png" alt="The preceding paragraph explains this
figure."></p>
<p>To summarize: the short-term way is cheap but noisy. The long-term way is
expensive but less noisy. Can we get the best of both worlds?</p>
<hr>
<p>Well, let’s think more carefully about the source of the expense. The problem
is that we need to store (or be able to reconstruct) the full computation graph
in order to do backpropagation. Okay, but do we really <em>need</em> to do
backpropagation? The only reason we backpropagate is that it’s more efficient
in the case when you want derivatives with respect to <em>many</em> different
variables. If you have millions of model parameters, backpropagation is
millions of times faster than the much simpler <a href="https://en.wikipedia.org/wiki/Automatic_differentiation#Automatic_differentiation_using_dual_numbers">forward-mode (“dual numbers”)
automatic
differentiation</a>.</p>
<p>But we <em>don’t</em> have millions of <em>hyperparameters!</em> Step size, for example, is
just a single number. The Adam optimizer only has a total of 4 hyperparameters.
With this in mind, backpropagation isn’t even the right choice — we <em>should</em>
be using dual numbers for the hyperparameter optimization. On the other hand,
we should still be using backpropagation for the “inner loop” that optimizes
the (non-hyper-) parameters. That is, we want to do something like this:</p>
<pre><code>initialize hyperparameters
# loop to optimize hyperparameters
while True:
  initialize parameters
  # loop to optimize parameters
  for i in range(100):
    run model on data to get loss
    # using reverse-mode!
    compute d(loss) / d(parameters)
    update parameters using hyperparameters
  # using forward-mode
  compute d(loss) / d(hyperparameters)
  update hyperparameters
</code></pre>
<blockquote>
<p>(Update: I discovered that this was suggested in the 2017 paper <a href="https://arxiv.org/abs/1703.01785">Forward and
Reverse Gradient-Based Hyperparameter
Optimization</a>. But keep reading — while
the paper’s
<a href="https://github.com/lucfra/FAR-HO/blob/master/far_ho/hyper_gradients.py#L375">implementation</a>
needs a lot of math to be worked out manually, I’m going to show you how to
implement this in a way that makes all the math in the paper fall out “for
free”…)</p>
</blockquote>
<p>This proposal raises a logistical question: how do we reconcile these two
automatic differentiation algorithms in the same program? <strong>The “trick” is to
“thread” dual numbers through a backpropagation implementation.</strong> In other
words, implement backpropagation as usual, but rather than <code>float</code> type
numbers, exclusively use <code>dual_number</code> type numbers (even when doing derivative
calculations). Initialize the system such that the dual numbers track
derivatives with respect to the hyperparameters you care about. Then, your
final loss value’s attached ($\epsilon$)-value <em>immediately</em> gives you
<code>d(loss)/d(hyperparameters)</code>. No backpropagation needed — and so, it’s safe
to “forget” the computation graph.</p>
<p>That’s it! That’s all I wanted to share in this blog post! :)</p>
<p>Of course, it’s not obvious how to implement this in PyTorch, since you can’t
naïvely do <code>tensor(dtype=dual_number)</code>. Rather than hack in a custom numeric
data type that implemented dual numbers, I wrote my own tiny implementations of
forward- and reverse-mode automatic differentiation. It’s just a couple dozen
(very-recognizable-to-automatic-differentiation-enthusiasts) lines of code. I
was careful to make each implementation generic in the kind of “number” it
accepts. That allowed me to run the reverse-mode algorithms using the
forward-mode data types.</p>
<p>Running it on a simple quadratic optimization problem, we can see that updating
the hyperparameter ($\alpha$) yields better-looking loss curves — in this
GIF, we’re discovering that we should increase the step size. Yay!</p>
<p><img src="https://hardmath123.github.io/static/hybrid-hyperoptimization/loss.gif" alt="GIF of loss curve becoming better over
time"></p>
<p>I think this is a very neat trick, which surely has other cool applications
(for example, differentiating through long-running physics simulations!). If
you’re curious, check out this <a href="https://hardmath123.github.io/static/hybrid-hyperoptimization/hybrid-hyperoptimization.ipynb">IPython
notebook</a> for
the full source code. Feel free to adapt it to your ideas. Then, tell me what
you’ve built!</p>

            </section>

            

        </article></div>]]>
            </description>
            <link>https://hardmath123.github.io/hybrid-hyperoptimization.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24447719</guid>
            <pubDate>Fri, 11 Sep 2020 21:50:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The technical interview is an ego trip]]>
            </title>
            <description>
<![CDATA[
Score 148 | Comments 168 (<a href="https://news.ycombinator.com/item?id=24447182">thread link</a>) | @kowsheek
<br/>
September 11, 2020 | https://blog.kowsheek.com/the-technical-interview-is-an-ego-trip/ | <a href="https://web.archive.org/web/*/https://blog.kowsheek.com/the-technical-interview-is-an-ego-trip/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <p>Early in my career, after a short initial interview at a consulting firm in Toronto, I was invited to a technical interview on the same day. Two of the senior developers from the team I would join would conduct the interview.</p><p>The interview started pleasantly with them describing the project they have been working on: a portal for university professors to communicate with their students. It was being built with ASP.NET MVC, a framework I had been working with for several years. I expressed that I was comfortable with the framework and I would be excited to work on the project. Then the technical examination began and on its conclusion I left the interview feeling humiliated.</p><p>Many years later, when I was preparing to take an interview, I looked back on this experience to realize that the line of questioning and approach had been an ego trip for those developers. I promised myself to <em>never</em> make any of my candidates feel the way I did.</p><p>What did those developers do wrong? Leaving aside their attitude towards me, their questions had no relevance to the role or the project. I did not know what a red-black tree was at the time but I definitely knew how to use ASP.NET MVC which they did not inquire about.</p><p>My golden rule for technical interviews is that, "Every step, conversation and question <em>must</em> be pertinent to the day-to-day of the role." While this may be obvious, I am sure that many hiring managers are still expecting candidates to arrive at technical interviews with Computer Science books memorized. This form of technical interviews should be made obsolete.</p><figure><blockquote><p lang="en" dir="ltr">Bigger button = more clicks on the CTA <a href="https://t.co/Ter7xJdNKM">pic.twitter.com/Ter7xJdNKM</a></p>— Vincent Déniel (@vincentdnl) <a href="https://twitter.com/vincentdnl/status/1291041278264713220?ref_src=twsrc%5Etfw">August 5, 2020</a></blockquote>

</figure><p>With my golden rule as guide, I conduct a much simpler interview process. Prior to an interview, my team and I review samples of code that the candidate shared with us (or had written on Github) to understand the quality of their code. And during the interview, I dive into three areas of discussions with the candidates: product building, process adherence and team work.</p><h3 id="product-building">Product Building</h3><p>I try to understand the candidate's interest and experience of building products by,</p><ol><li>Going through their past experience and asking about what technologies and products they built and how. I ask about previous products they have shipped from concept to market.</li><li>To understand their thought process for deriving solutions, I draw an UI and ask them to outline and explain what approaches, structures and technologies they would use to build it out.</li><li>I ask about how they keep up with technologies and how they improve their skills to gauge their passion for the work.</li></ol><h3 id="process-adherence">Process Adherence</h3><p>To better understand how the candidate does their work,</p><ol><li>I go over their experiences and ask about how they managed their product-building and what tools and processes they used.</li><li>I explain the process of working on our team and ask how they would change it and where they see inefficiencies to discuss their thinking.</li><li>Often, I will give them a scenario where the processes are failing the team to find what they would do to tackle inefficiencies and if they would be willing to speak up.</li></ol><h3 id="team-work">Team Work</h3><p>I also try to understand how a candidate works in a team,</p><ol><li>While going through their past experiences, I ask about how they collaborated and communicated with their teams.</li><li>I present a scenario where their knowledge in an area may be lacking and evaluate if and how they would leverage and collaborate with their team.</li><li>Another scenario I ask about is where they disagree with their team-members to evaluate how they manage conflict and focus on delivering results for the team.</li></ol><p>I do this within one interview to be mindful of the candidate's time and mine. I want to hire candidates for their will to learn, grow and challenge the status quo.</p><p>The technology landscape is such that anyone can acquire a set of baseline programming skills. What is needed then, is a willingness to challenge ourselves and stay open-minded because every developer will have to learn on the job almost all of the time. Given this, the technical interview is arcane, academic and as good as dead.</p><hr><h3 id="further-reading">Further Reading</h3><ol><li><a href="https://news.ncsu.edu/2020/07/tech-job-interviews-anxiety/">Tech Sector Job Interviews Assess Anxiety, Not Software Skills</a></li><li><a href="https://medium.com/helpful-com/https-medium-com-fnthawar-helpful-technical-interviews-are-garbage-dc5d9aee5acd">Technical interviews are garbage. Here’s what we do instead</a></li><li><a href="https://remotesynthesis.com/blog/whats-wrong-with-tech-interviews">What's Wrong with the Tech Interview Process?</a></li></ol>
                </div>
            </section>

                <section>
    <h3>Subscribe to blog.kowsheek</h3>
    <p>Get the latest posts delivered right to your inbox</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>

        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.kowsheek.com/the-technical-interview-is-an-ego-trip/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24447182</guid>
            <pubDate>Fri, 11 Sep 2020 20:47:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Introduction to Data Oriented Design with Rust]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24447023">thread link</a>) | @byproxy
<br/>
September 11, 2020 | https://jamesmcm.github.io/blog/2020/07/25/intro-dod/ | <a href="https://web.archive.org/web/*/https://jamesmcm.github.io/blog/2020/07/25/intro-dod/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>In the post we will investigate the main concepts of <a href="https://en.wikipedia.org/wiki/Data-oriented_design">Data-oriented
Design</a> using Rust.</p>

<p>The source code for this example is <a href="https://github.com/jamesmcm/data-oriented-example">available on Github</a>.</p>

<!--more-->

<h2 id="what-is-data-oriented-design">What is data-oriented design?</h2>

<p>Data-oriented design is an approach to optimising programs by carefully
considering the memory layout of data structures, and their implications
for auto-vectorisation and use of the CPU cache. I highly recommend
watching Mike Acton’s <a href="https://www.youtube.com/watch?v=rX0ItVEVjHc">“Data-Oriented Design and C++”</a> talk
if you haven’t seen it already.</p>

<p>In this post we will cover 4 cases, using <a href="https://docs.rs/criterion/0.3.3/criterion/">criterion</a> for
benchmarking. The cases are:</p>

<ul>
  <li>Struct of arrays vs. array of structs</li>
  <li>The cost of branching inside a hot loop</li>
  <li>Linked List vs. Vector iteration</li>
  <li>The cost of dynamic dispatch vs. monomorphisation</li>
</ul>

<h2 id="struct-of-arrays-vs-array-of-structs">Struct of Arrays vs. Array of Structs</h2>

<p>The <a href="https://en.wikipedia.org/wiki/AoS_and_SoA">Struct of Arrays vs. Array of Structs</a> 
refers to two contrasting ways of organising entity data to be operated
over.</p>

<p>For example, imagine we are writing a video game and we would like to
have a Player struct with the following fields:</p>

<div><div><pre><code><span>pub</span> <span>struct</span> <span>Player</span> <span>{</span>
    <span>name</span><span>:</span> <span>String</span><span>,</span>
    <span>health</span><span>:</span> <span>f64</span><span>,</span>
    <span>location</span><span>:</span> <span>(</span><span>f64</span><span>,</span> <span>f64</span><span>),</span>
    <span>velocity</span><span>:</span> <span>(</span><span>f64</span><span>,</span> <span>f64</span><span>),</span>
    <span>acceleration</span><span>:</span> <span>(</span><span>f64</span><span>,</span> <span>f64</span><span>),</span>
<span>}</span>
</code></pre></div></div>

<p>Then at each frame, we want to update the locations and velocities of all
Players. We could write something like:</p>

<div><div><pre><code><span>pub</span> <span>fn</span> <span>run_oop</span><span>(</span><span>players</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Vec</span><span>&lt;</span><span>Player</span><span>&gt;</span><span>)</span> <span>{</span>
    <span>for</span> <span>player</span> <span>in</span> <span>players</span><span>.iter_mut</span><span>()</span> <span>{</span>
        <span>player</span><span>.location</span> <span>=</span> <span>(</span>
            <span>player</span><span>.location</span><span>.</span><span>0</span> <span>+</span> <span>player</span><span>.velocity</span><span>.</span><span>0</span><span>,</span>
            <span>player</span><span>.location</span><span>.</span><span>1</span> <span>+</span> <span>player</span><span>.velocity</span><span>.</span><span>1</span><span>,</span>
        <span>);</span>
        <span>player</span><span>.velocity</span> <span>=</span> <span>(</span>
            <span>player</span><span>.velocity</span><span>.</span><span>0</span> <span>+</span> <span>player</span><span>.acceleration</span><span>.</span><span>0</span><span>,</span>
            <span>player</span><span>.velocity</span><span>.</span><span>1</span> <span>+</span> <span>player</span><span>.acceleration</span><span>.</span><span>1</span><span>,</span>
        <span>);</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>This would be the usual object-oriented approach to this problem. The
issue here is that in memory the structs are stored as follows (assuming
no field re-ordering i.e. <code>#[repr(C)]</code>), on a 64-bit architecture each field will be 64
bits (8 bytes, so each Player is 64 bytes):</p>

<div><div><pre><code>-- Vec&lt;Player&gt;
name  (pointer to heap)  -- Player 1
health    
location0  (tuple split for clarity) 
location1
velocity0
velocity1
acceleration0
acceleration1
name  (pointer to heap)  -- Player 2
location0    
location1
velocity0
velocity1
acceleration0
acceleration1
...
</code></pre></div></div>

<p>Note the parts we want to operate on (locations, velocities and
accelerations) are not stored contiguously across different Players.
This prevents us from using vector operations to operate on multiple
players at once (since they cannot be loaded in the same CPU cache
line, usually ~64 bytes).</p>

<p>In contrast, the data-oriented approach is to design around this
limitation and optimise for auto-vectorisation. Instead of using a
struct per Player, we now use one struct for all Players and each Player
has their values stored at their index in the separate attribute Vectors:</p>

<div><div><pre><code><span>pub</span> <span>struct</span> <span>DOPlayers</span> <span>{</span>
    <span>names</span><span>:</span> <span>Vec</span><span>&lt;</span><span>String</span><span>&gt;</span><span>,</span>
    <span>health</span><span>:</span> <span>Vec</span><span>&lt;</span><span>f64</span><span>&gt;</span><span>,</span>
    <span>locations</span><span>:</span> <span>Vec</span><span>&lt;</span><span>(</span><span>f64</span><span>,</span> <span>f64</span><span>)</span><span>&gt;</span><span>,</span>
    <span>velocities</span><span>:</span> <span>Vec</span><span>&lt;</span><span>(</span><span>f64</span><span>,</span> <span>f64</span><span>)</span><span>&gt;</span><span>,</span>
    <span>acceleration</span><span>:</span> <span>Vec</span><span>&lt;</span><span>(</span><span>f64</span><span>,</span> <span>f64</span><span>)</span><span>&gt;</span><span>,</span>
<span>}</span>
</code></pre></div></div>

<p>Now we can do the same calculation as in the OOP case as follows:</p>

<div><div><pre><code><span>pub</span> <span>fn</span> <span>run_dop</span><span>(</span><span>world</span><span>:</span> <span>&amp;</span><span>mut</span> <span>DOPlayers</span><span>)</span> <span>{</span>
    <span>for</span> <span>(</span><span>pos</span><span>,</span> <span>(</span><span>vel</span><span>,</span> <span>acc</span><span>))</span> <span>in</span> <span>world</span>
        <span>.locations</span>
        <span>.iter_mut</span><span>()</span>
        <span>.zip</span><span>(</span><span>world</span><span>.velocities</span><span>.iter_mut</span><span>()</span><span>.zip</span><span>(</span><span>world</span><span>.acceleration</span><span>.iter</span><span>()))</span>
    <span>{</span>
        <span>*</span><span>pos</span> <span>=</span> <span>(</span><span>pos</span><span>.</span><span>0</span> <span>+</span> <span>vel</span><span>.</span><span>0</span><span>,</span> <span>pos</span><span>.</span><span>1</span> <span>+</span> <span>vel</span><span>.</span><span>1</span><span>);</span>
        <span>*</span><span>vel</span> <span>=</span> <span>(</span><span>vel</span><span>.</span><span>0</span> <span>+</span> <span>acc</span><span>.</span><span>0</span><span>,</span> <span>vel</span><span>.</span><span>1</span> <span>+</span> <span>acc</span><span>.</span><span>1</span><span>);</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>In this case the memory layout is as follows:</p>
<div><div><pre><code>-- DOPlayers
name1    -- names
name2
...
health1    -- health
health2
...
location1    -- locations
location2
...
</code></pre></div></div>

<p>The relevant fields are now stored contiguously. Given that each
location tuple will be 16 bytes, we could now feasibly load 4 location
tuples on the same cache line to operate on them simultaneously with
SIMD instructions.</p>

<h3 id="benchmark">Benchmark</h3>

<p>Here are the results of the criterion benchmark for the above code (the
full code and benchmark code is available <a href="https://github.com/jamesmcm/data-oriented-example">in the Github repo</a>):</p>

<p><img src="https://jamesmcm.github.io/images/soa.svg" alt="AoS vs. SoA benchmark" title="AoS vs. SoA benchmark"></p>

<p>Overall, we see that the data-oriented approach finishes in half the
time. This would seem to be due to the data-oriented case operating on
two Players at a time - we can confirm this by reviewing the compiled
assembly.</p>

<p>Reviewing the <a href="https://godbolt.org/z/d8bjMb">output on Godbolt</a> we see the following:</p>

<pre><code>// Relevant OOP loop
.LBB0_2:
        movupd  xmm0, xmmword ptr [rax + rdx + 32]
        movupd  xmm1, xmmword ptr [rax + rdx + 48]
        movupd  xmm2, xmmword ptr [rax + rdx + 64]
        addpd   xmm0, xmm1
        movupd  xmmword ptr [rax + rdx + 32], xmm0
        addpd   xmm2, xmm1
        movupd  xmmword ptr [rax + rdx + 48], xmm2
        add     rdx, 80
        cmp     rcx, rdx
        jne     .LBB0_2

// ...
// Relevant DOP loop
.LBB1_7:
        movupd  xmm0, xmmword ptr [rcx + rdx - 16]
        movupd  xmm1, xmmword ptr [rax + rdx - 16]
        addpd   xmm1, xmm0
        movupd  xmmword ptr [rcx + rdx - 16], xmm1
        movupd  xmm0, xmmword ptr [r9 + rdx - 16]
        movupd  xmm1, xmmword ptr [rax + rdx - 16]
        addpd   xmm1, xmm0
        movupd  xmm0, xmmword ptr [rax + rdx]
        movupd  xmmword ptr [rax + rdx - 16], xmm1
        add     rdi, 2
        movupd  xmm1, xmmword ptr [rcx + rdx]
        addpd   xmm1, xmm0
        movupd  xmmword ptr [rcx + rdx], xmm1
        movupd  xmm0, xmmword ptr [rax + rdx]
        movupd  xmm1, xmmword ptr [r9 + rdx]
        addpd   xmm1, xmm0
        movupd  xmmword ptr [rax + rdx], xmm1
        add     rdx, 32
        cmp     rsi, rdi
        jne     .LBB1_7
        test    r8, r8
        je      .LBB1_5
</code></pre>

<p>We can see in the data-oriented case, the loop is unrolled to operate on
two elements at once - resulting in the 50% speed up overall!</p>

<p><strong>Addendum</strong>: As noted by <a href="https://www.reddit.com/r/rust/comments/hxqwom/an_introduction_to_data_oriented_design_with_rust/fz8lxcq/">/u/five9a2 on Reddit</a>
the above output is specifically for the default target, which is
misleading since <code>cargo bench</code> uses the native target by default (i.e.
all possible features on your CPU), so our benchmarks are not using the
above assembly code.</p>

<p>By setting the compiler flag to <code>-C target-cpu=skylake-avx512</code> to enable 
Skylake features, we get the <a href="https://godbolt.org/z/PEPdvn">following output</a>:</p>

<pre><code>// OOP loop
.LBB0_2:
        vmovupd ymm0, ymmword ptr [rax + rdx + 32]
        vaddpd  ymm0, ymm0, ymmword ptr [rax + rdx + 48]
        vmovupd ymmword ptr [rax + rdx + 32], ymm0
        add     rdx, 80
        cmp     rcx, rdx
        jne     .LBB0_2

...
// DOP loop
.LBB1_19:
        vmovupd zmm0, zmmword ptr [rsi + 4*rax - 64]
        vaddpd  zmm0, zmm0, zmmword ptr [rcx + 4*rax - 64]
        vmovupd zmmword ptr [rsi + 4*rax - 64], zmm0
        vmovupd zmm0, zmmword ptr [rcx + 4*rax - 64]
        vaddpd  zmm0, zmm0, zmmword ptr [r10 + 4*rax - 64]
        vmovupd zmmword ptr [rcx + 4*rax - 64], zmm0
        vmovupd zmm0, zmmword ptr [rsi + 4*rax]
        vaddpd  zmm0, zmm0, zmmword ptr [rcx + 4*rax]
        vmovupd zmmword ptr [rsi + 4*rax], zmm0
        vmovupd zmm0, zmmword ptr [rcx + 4*rax]
        vaddpd  zmm0, zmm0, zmmword ptr [r10 + 4*rax]
        vmovupd zmmword ptr [rcx + 4*rax], zmm0
        add     r11, 8
        add     rax, 32
        add     rdi, 2
        jne     .LBB1_19
        test    r9, r9
        je      .LBB1_22
</code></pre>

<p>Here we see the OOP loop making use of the 256-bit ymm registers for the
position tuple and velocity tuple, and another for the velocity tuple
and acceleration tuple. This is possible because they are adjacent in
memory (due to the ordering of the fields). In the DOP loop,
the 512-bit zmm register is used.</p>

<p>It seems the performance differences comes from the bandwidth between
cache levels, since the performance is identical for the small examples.
This can be demonstrated further by removing the extra fields from the
struct - in this case we see only a 25% performance difference (<a href="https://godbolt.org/z/Th91Wa">godbolt
link</a>), and this
corresponds to Player struct now being 384 bits (and so 1/4 of the
512-bit read/write is unused).</p>

<p>This emphasises how important it is to consider your deployment target,
and if deploying performance-sensitive code, to consider setting the
target-cpu explicitly to benefit from all of its features.</p>

<p>It also demonstrates how the ordering of fields can be important to
performance. By default Rust will re-order fields automatically, but you can set
<code>#[repr(C)]</code> to disable this (necessary for C interoperability for
example).</p>

<h3 id="summary">Summary</h3>

<p>This example demonstrates the importance of considering memory layout
when aiming for performant code and auto-vectorisation.</p>

<p>Note that the same logic can also apply when working with arrays of
structs - making your struct smaller will allow you to load more
elements on the same cache line and possibly lead to autovectorisation.
<a href="https://github.com/Rene-007/flake_growth/blob/master/src/helpers.rs">Here is an example</a> of
a crate (which was shared on the <a href="https://www.reddit.com/r/rust/comments/hmqjvs/growing_gold_with_rust/">Rust subreddit</a>) that achieved a 40% performance
improvement by doing just that.</p>

<p>This particular re-organisation has a direct analogue in database design. A
major difference between databases aimed at transactional (OLTP)
workloads and analytical (OLAP) workloads is that the latter tend to use
columnar-based storage. Just like the case above, this means that
operations on one column can take advantage of the contiguous storage
and use vector operations, which tends to be the main access pattern for
analytical workloads (e.g. calculate the average purchase size across all rows,
rather than updating and retrieving entire, specific rows).</p>

<p>In the case of analytical databases this is actually a double win, since it also
applies to the serialisation of the data to disk, where compression can
now be applied along the column (where the data is guaranteed to be of the
same type) leading to much better compression ratios.</p>

<p>If you are working on a problem that might benefit from the struct of
arrays approach, and want to run a quick benchmark, you might be
interested in the <a href="https://github.com/lumol-org/soa-derive">soa-derive</a>
crate that will allow you to derive the struct of arrays from your
struct.</p>

<h2 id="branching-in-a-hot-loop">Branching in a hot loop</h2>

<p>Another optimisation tactic is to avoid branching in any “hot” parts of
the code (i.e. any part that will be executed many, many times).</p>

<p>Branching can arise in subtle ways, often by trying to use one struct for many
different cases. For example, we might define some general Node type …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jamesmcm.github.io/blog/2020/07/25/intro-dod/">https://jamesmcm.github.io/blog/2020/07/25/intro-dod/</a></em></p>]]>
            </description>
            <link>https://jamesmcm.github.io/blog/2020/07/25/intro-dod/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24447023</guid>
            <pubDate>Fri, 11 Sep 2020 20:30:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[RemNote – great note-taking app nobody is talking about]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24446851">thread link</a>) | @kalimatas
<br/>
September 11, 2020 | https://guzalexander.com/2020/09/11/notes-apps-fatigue.html | <a href="https://web.archive.org/web/*/https://guzalexander.com/2020/09/11/notes-apps-fatigue.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
		

		<section>
			<section>
				<article>
	
	<p>I have been using Evernote for quite some years now as my go-to application for 
notes, bookmarks, sketches, etc. Indeed, it is not a bad choice: clients for all platforms
you can imagine, synchronization between devices, good enough editor with formatting,
typical hierarchical notes organization into notebooks and sub-notebooks, tags, sharing
options, etc. I even had a paid version in order to have synchronization on more than two
devices. And still, I have never felt that I have been using all its potential.</p>

<div>
	<figure>
		
			<a href="https://guzalexander.com/static/img/posts/notes_evernote.png" target="_blank"><img src="https://guzalexander.com/static/img/posts/notes_evernote.png" alt="Evernote for macOS"></a>
		
	</figure>
</div>

<figcaption>Evernote for macOS</figcaption>

<p>Eventually, I realized that my notes were lying “dead“ there. Like a pile of useless crap.
Basically, once something got into Evernote, I just forgot about it. And, probably, never
open this note again, except for some edge cases. These notes were not helping me.</p>

<p>Then I stumbled upon <a href="https://roamresearch.com/">Roam Research</a> – the app on hype now. It had invitation system,
so I could only check out the <a href="https://roamresearch.com/#/app/help/page/k5RxbGuJN">demo page</a>.
But it was not the tool itself that made me switch from Evernote. By watching tutorials,
and reading articles about Roam I grasped the idea of a second brain, a personal
knowledge base. This is where it all clicked – my Evernote notes are junk, because they
are not connected to each other. Yes, I have a notebook “Programming“, but notes inside this 
notebook are just separate pieces with no relation to each other whatsoever. These 
relations exist only in my head. And my head has only so much free space to hold all 
this stuff.</p>

<div>
	<figure>
		
			<a href="https://guzalexander.com/static/img/posts/notes_roam.png" target="_blank"><img src="https://guzalexander.com/static/img/posts/notes_roam.png" alt="Roam Research"></a>
		
	</figure>
</div>

<figcaption>Roam Research</figcaption>

<p>The essential part that is missing in Evernote in comparison to, let’s say the same Roam
Research, is linking of the notes. One can argue, that Evernote has notes links. But 
functionality- and comfort-wise they are a joke. Imagine, you are writing a note about 
new sorting algorithm, and now you want to link some phrase to the big-O notation note. 
You have to: 
	1. Find big-O note (potentially in another notebook).
	2. Then right click and find an option to copy the note link.
	3. Then go back to the place where you want to place the link and
	4. Finally, paste it.
I almost died from boredom by just explaining this procedure. By the time you finish it,
you have already lost any thought train you had.</p>

<p>Just to have a link inside a note to another note is not enough, though. Another powerful
concept is back linking. Imagine, you are looking at a note, and you can immediately see 
if any other note refers to it. You might have linked it from another place without putting
too much thought, but in the end you created a new association that can create a new idea.
Pretty cool. Some apps go further and even provide so called “non-referenced“ links, i.e.
they show other notes that reference just the title of the current note as a text.</p>

<p>I was hooked and decided to switch. But first, I needed to find <strong>the perfect</strong> application,
of course. Roam Research is too expensive. I mean, I am glad to spend $15/month for an 
app, if I know that this is a game changer. But not from the day one. So I started my
research. Oh boy, just look at <strong><a href="https://www.notion.so/db13644f08144495ad9877f217a161a1?v=ff6777802811416ba08dc114e0b11837">this huge list</a></strong> of 85 note-taking applications! I think I have 
looked almost through all of them, and fooled around with at least 15 or so.</p>

<p>The most worthy of mention are <a href="https://obsidian.md/">Obsidian</a>, <a href="https://foambubble.github.io/foam/">Foam</a>, <a href="https://www.notion.so/">Notion</a>, and
my favorite so far – <strong><a href="https://www.remnote.io/">RemNote</a></strong>.</p>

<div>
	<figure>
		
			<a href="https://guzalexander.com/static/img/posts/notes_obsidian.png" target="_blank"><img src="https://guzalexander.com/static/img/posts/notes_obsidian.png" alt="Obsidian. Stores notes in Markdown locally."></a>
		
	</figure>
</div>

<figcaption>Obsidian. Stores notes in Markdown locally.</figcaption>

<p>RemNote is great. It is free. It is packed with features. It is ugly. Well, to be 
fair it was ugly until the recent upgrade a few days ago. Now it is a bit better. But I
like the spirit. Started to use it on a daily basis. Cancelled my Evernote subscription. 
It is a long way for RemNote to become great, though. What they currently lack is media
promotion. This is a great application nobody is talking about! Everybody talks 
only about Roam Research.</p>

<div>
	<figure>
		
			<a href="https://guzalexander.com/static/img/posts/notes_remnote.png" target="_blank"><img src="https://guzalexander.com/static/img/posts/notes_remnote.png" alt="RemNote tutorial page"></a>
		
	</figure>
</div>

<figcaption>RemNote tutorial page</figcaption>

<p>So did I just find a perfect tool for me? I am not sure, to be honest. RemNote has a bunch 
of downsides. For example, lack of a desktop application that is huge minus for me, since
I hate doing serious work in a browser window. I also have some concerns about the future
of the app: there is no business behind, and I cannot tell for sure how serious the authors
are about continuing working on it. I definitely don’t want to lose all my notes in two years or so.</p>

<p>And let’s not forget, that there are other players on the market. There are so many options!
Having so much variety might seem like a good thing in the first place, but it leads to
<a href="https://en.wikipedia.org/wiki/Decision_fatigue">decision fatigue</a>. I really just want
to have the work done, to have my brain organized and get the most out of my notes. I 
don’t want to spend endless hours on choosing <strong>the</strong> right tool.</p>

<p>Maybe I should just switch to <a href="https://www.williamhern.com/living-in-a-single-text-file.html">one</a>
<a href="https://jeffhuang.com/productivity_text_file/">text file</a> or <a href="https://orgmode.org/">Org mode</a>?</p>


</article>
<time>September 11, 2020</time>

			</section>

			
			
			
			
			

			
		</section>
	</section></div>]]>
            </description>
            <link>https://guzalexander.com/2020/09/11/notes-apps-fatigue.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24446851</guid>
            <pubDate>Fri, 11 Sep 2020 20:13:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Brian Kernighan on the typesetting of “The Go Programming Language” book (2016)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24446793">thread link</a>) | @smartmic
<br/>
September 11, 2020 | https://rkrishnan.org/posts/2016-03-07-how-is-gopl-typeset.html | <a href="https://web.archive.org/web/*/https://rkrishnan.org/posts/2016-03-07-how-is-gopl-typeset.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
            

            <p>
    Posted on 2016-03-07
    
        <span>golang, typesetting, unix</span>
    
</p>

<p>A while ago, I bought the book “<a href="http://gopl.io/">The Go Programming Language</a>” written by Alan Donovan and Brian Kernighan. I have always been a fan of Brian Kernighan’s writings. I should admit that I bought the book mainly for his great examples and writings than for the Go language itself, but since then have got interested in the Go Language, after starting to read the book.</p>
<p>Perhaps every programmer knows Brian Kernighan as the “K” in the famous K&amp;R book. He has also written a bunch of other great books, most of them are on my shelf, including some which are out of print. My other favourites are “Software tools” book and the “AWK programming language” book. Brian is also the “K” in “AWK” language.</p>
<p>Sure enough, the book does not disappoint at all. The way the language features are described and the “story” developed is something every programming language book author could try to emulate. One of the features of Prof.&nbsp;Kernighan’s books is that the first chapter is a tour of the language features and gives a good taste of the syntax of the language, leaving the readers with enough knowledge to mess around with the language and start writing complete programs.</p>
<p>The thing that stood out the most in my eyes was the outstanding quality of the type setting. Everything seemed just right.</p>
<p>Some (or most?) readers take typesetting of the programming books very seriously. There is this joke of Donald Knuth taking a break from the TAOCP book project to “invent” the TeX typesetting system.</p>
<p>One of the early goofups in typesetting is also incidentally in the K&amp;R Book, written by Brian Kernighan, brought to my attention by my friend and colleague, <a href="http://olvemaudal.com/">Olve Maudal</a>. A number of readers of the K&amp;R C 2nd edition book believed that pointers and arrays are the same, due to the non-optimal pagination.</p>
<figure>
<img src="https://rkrishnan.org/images/kandr-c-99-100.png" title="Page 99 and Page 100 of K&amp;R C 2nd edition" alt=""><figcaption>Page 99 and Page 100 of K&amp;R C 2nd edition</figcaption>
</figure>
<p>Okay, that aside, I emailed Prof.&nbsp;Kernighan about the tools he used to type set the book. There is a brief mention about it in the copyright page. But that didn’t satisfy me much. Here is what I wrote, on 28th Feb, 2016:</p>
<pre><code> Dear Prof. Kernighan,
 
 The Go programming language book is so beautifully typeset. To my eyes,
 it is more beautiful than those LaTeX based ones. But that's just my
 perception..
 
 Could you please say a few things about how your writing flow was and
 how you type set the book? I see the tools used in the copyright page.
 
 Thanks
 --
  Ramakrishnan</code></pre>
<p>The reply came a few hours later on the same day. Reproduced here with permission from Prof.&nbsp;Kernighan.</p>
<pre><code> Hi, Ramakrishnan --
 
 Thanks for the kind words on the typography.  The core formatting
 is just troff (groff, really) with the -ms macro package.  We
 tried Latex briefly but neither Alan or I care for its output, and
 I personally find it impossible to control.  Troff is the devil I
 know -- it's ugly and irregular in many ways but it will put
 characters where you want them.
 
 The input was in XML, with a tag set of about 25 items for
 headings, paragraphs, index terms, program insertion, simple
 tables, and the like.  A Go program converted this either into
 HTML for rapid viewing on the screen and potentially for an e-book
 version, or into troff for printing.  Using XML was a mild
 nuisance when writing but the error checking was very helpful.
 
 We wrote a variety of small Go programs and scripts to fix things
 up, including one that rewrites troff output to do vertical
 justification so all pages are the same height.  There is also
 some fiddling with the generated postscript to put on printer's
 marks.
 
 The fonts are Alan's choice, the result of a lot of work on his
 part to find them and get the right sizes and appearances.  The
 handful of Asian characters were tough to get right; troff doesn't
 do wide Unicode characters properly, and there are a few places
 where we rewrote text to hide that fact.
 
 The drawings are all Alan's work, using Google's drawing program.
 We toyed briefly with using pic but it wasn't really up to the
 job, and it would not have worked with HTML without a lot of work.
 We avoided mathematics beyond superscripts, and the tables are
 pretty limited; eqn and tbl would have been ok but again would not
 have dealt with HTML.
 
 We should probably write a more organized description of what we
 did and make the tools available, though I think most readers are
 less interested in the process than you (and I) are.  The other
 thing is that although one starts with grand ideas of being clean
 and orderly, by the end the process is somewhat of a mess, with
 a complicated makefile to keep it running.
 
 Thanks again for writing.
 
 Brian</code></pre>
<p>The last sentence certainly holds true for just about any project, as far as my experience goes.</p>
<pre><code>"...although one starts with grand ideas of being clean
 and orderly, by the end the process is somewhat of a mess, with
 a complicated makefile to keep it running."</code></pre>
<p>In a subsequent email, Prof.&nbsp;Kernighan added that the problem with Unicode was not much of an input problem and was because of troubles getting suitable fonts for actual printing.</p>

        </div></div>]]>
            </description>
            <link>https://rkrishnan.org/posts/2016-03-07-how-is-gopl-typeset.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24446793</guid>
            <pubDate>Fri, 11 Sep 2020 20:07:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The first major sign your web host will not respect you]]>
            </title>
            <description>
<![CDATA[
Score 33 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24446756">thread link</a>) | @puggo
<br/>
September 11, 2020 | https://hawaiigentech.com/post/commentary/sign-your-webhost-does-not-respect-you/ | <a href="https://web.archive.org/web/*/https://hawaiigentech.com/post/commentary/sign-your-webhost-does-not-respect-you/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <hr>
<p><img src="https://hawaiigentech.com/post/commentary/sign-your-webhost-does-not-respect-you/an-unethical-salesman.jpg" alt="The First Major Sign Your Web Host Will Not Respect You"></p>
<hr>
<h2 id="when-a-relationship-starts-with-an-act-of-dishonesty-or-manipulation-it-will-be-a-toxic-relationship"><em>When a relationship starts with an act of dishonesty or manipulation, it will be a toxic relationship</em>.</h2>
<p>This is common knowledge.</p>
<p>Most major web hosting companies groom potential customers in manipulative ways, but, sadly, many do not recognize the trouble signs due to naivety or need.</p>
<p>Here is one important, but common cue that your webhost-to-be will not respect you, and you are in for a compromising, dysfunctional relationship.</p>
<h2 id="but-you-said-395-a-month-">But you said 3.95 a month… :(</h2>
<h3 id="the-solicitation">The Solicitation</h3>
<p><img src="https://hawaiigentech.com/post/commentary/sign-your-webhost-does-not-respect-you/do-you-really-mean-it.jpg" alt="Do you really mean it?"></p>
<p><a href="https://web.archive.org/web/20200911190002/https://www.bluehost.com/">https://web.archive.org/web/20200911190002/https://www.bluehost.com/</a></p>
<p>In the ad above, this average young woman has just been approached by what could be the prince-charming of webhosts, bluehost himself. She is excited and flattered that she could have him for the price of $3.50 a month.</p>
<p>Enticed, she takes the bait.</p>
<h3 id="getting-into-the-car">Getting into the Car</h3>
<p><img src="https://hawaiigentech.com/post/commentary/sign-your-webhost-does-not-respect-you/do-you-really-mean-it-2.jpg" alt="Is it too good to be true?"></p>
<p><a href="https://web.archive.org/web/20200910194510if_/https://www.bluehost.com/hosting/shared#pricing-cards">https://web.archive.org/web/20200910194510if_/https://www.bluehost.com/hosting/shared#pricing-cards</a></p>
<p>Now the young lady is excited, because although it seemed too good to be true, it looks like this might just be true love. $3.95 a month! Things are finally looking up.</p>
<h3 id="taking-the-ride">Taking the Ride</h3>
<p>After some flirty initial conversation of what her domain name will be, our prince charming bluehost finally gets down to his intentions.</p>
<p>He says, <strong>“So let’s talk about that $178.08…"</strong></p>
<p>And her heart sinks…</p>
<p><img src="https://hawaiigentech.com/post/commentary/sign-your-webhost-does-not-respect-you/get-your-hands-off-me.jpg" alt="Get your hands off me!"></p>
<p>And now we’ve quickly arrived at that part of the relationship known as <em><strong>“Get your hands off me!"</strong></em>.</p>
<hr>
<h2 id="17808-for-3-years-is-not-395-a-month">$178.08 for 3 Years is Not $3.95 a Month</h2>
<p>One might argue that if you divide the numbers over 3 years, it evens out to the price stated: $3.95.</p>
<p>But that’s <em>not</em> $3.95 a month.</p>
<p>That <em>is</em> $178.08 for three years.</p>
<p>If it was $3.95 a month, I could pay $3.95 for the first month, $3.95 for the second… $3.95 for the third … etc.</p>
<p>It was lie, a manipulation, a sign.</p>
<h3 id="my-wedding-ring-costs-less-per-month-every-year">My wedding ring costs less per month every year…</h3>
<p>So by this logic, a $1000 wedding ring costs $1.66 dollars a month after 50 years of marriage. Assuming there is no divorce.</p>
<h3 id="but-if-you-say-yes">But if you say yes…</h3>
<p>Sadly, some people will ignore the first alarm signs of the toxic relationship, and convince themselves that they did not just get manipulated.</p>
<p>Sadly, that “deal” is lost in a short time due to common upsells inherent to hosts such as this.  Because if you don’t say “get your hands off me” you enable future exploits, and the web host knows this. He’s good at what he does.</p>
<h3 id="prince-charming-is-a-dime-a-dozen">Prince Charming is a Dime a Dozen</h3>
<p>Despite how unique and valuable this prince charming purports to be, there is a street full of them coming from every alley way.</p>
<p>Most major cheap hosting companies operate this way.</p>
<p>Don’t give up your standards and settle. The good hosts are hard to find, because they don’t hang out in the main traffic areas of society/internet.</p>
<hr>

    </div></div>]]>
            </description>
            <link>https://hawaiigentech.com/post/commentary/sign-your-webhost-does-not-respect-you/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24446756</guid>
            <pubDate>Fri, 11 Sep 2020 20:03:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PandaDoc Employees Arrested in Belarus After Founders Protest Against Violence]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24446695">thread link</a>) | @maxan
<br/>
September 11, 2020 | https://savebelarusit.org/en/ | <a href="https://web.archive.org/web/*/https://savebelarusit.org/en/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p>Friends,</p>
          <p>On&nbsp;September 2, the Belarus government ordered searches to&nbsp;be&nbsp;conducted at&nbsp;the Minsk office of&nbsp;PandaDoc. During the search, more than 20 employees were prevented from leaving and 7 of&nbsp;them were taken into custody and detained for further interrogation. Some of&nbsp;these employees were subsequently taken into custody from their homes.</p>
          <p>Over the next two days, the Financial Investigation Department (FID) arm of&nbsp;the Belarus government interviewed more than one hundred company employees. During those two days, the employees that had been taken into custody were also denied the rights to&nbsp;legal counsel.</p>
          <p>Today, on&nbsp;September 4, 2020 we&nbsp;were told that a&nbsp;criminal case was retroactively initiated against PandaDoc employees under part 4 of&nbsp;article 210 of&nbsp;the Criminal Code of&nbsp;the Republic of&nbsp;Belarus. Our employees are accused of&nbsp;taking one hundred and seven thousand Belarusian rubles (~40k USD) from the corporate accounts of&nbsp;the company in&nbsp;Minsk abusing their positions, thus causing damage to&nbsp;the&nbsp;State. As&nbsp;a&nbsp;result, our employees have now been placed into custody for two months.</p>
          <p>We&nbsp;declare that this accusation by&nbsp;the State of&nbsp;Belarus is&nbsp;completely untrue and has no&nbsp;grounds.</p>
          <p>All the company’s activities in&nbsp;Belarus were conducted since its inception in&nbsp;full compliance with the&nbsp;law. Several international audits and inspections by&nbsp;EY&nbsp;and other reputable companies over the last years prove that the company adhered to&nbsp;all regulations and laws prevalent in&nbsp;Belarus.</p>
          <p>As&nbsp;recent events in&nbsp;Belarus have demonstrated, it&nbsp;is&nbsp;a&nbsp;common practice of&nbsp;the Belarusian government to&nbsp;oppress political opponents. In&nbsp;this case, the authorities have taken four completely innocent people hostage.</p>
          <p>This action is&nbsp;purely an&nbsp;act of&nbsp;repression against the founders of&nbsp;PandaDoc who have been supporting some of&nbsp;the victims of&nbsp;the Belarussian government in&nbsp;the weeks since the stolen Presidential election. The only purpose of&nbsp;this private initiative by&nbsp;Mikita and Sergey has been intended to&nbsp;help stop the violence and is&nbsp;in&nbsp;no&nbsp;way related to&nbsp;PandaDoc.</p>
          <p>In&nbsp;response the government has imprisoned:</p>
          <ul>
            <li><strong>Yulia Shardyko</strong>, Accountant</li>
            <li><strong>Dmitry Rabtsevich</strong>, Director - Minsk office</li>
            <li><strong>Viktar Kuushynau</strong>, Product Director</li>
            <li><strong>Vladislav Mikholap</strong>, HR</li>
          </ul>
          <p>The law in&nbsp;Belarus has ceased to&nbsp;exist. The authorities do&nbsp;not even bother to&nbsp;act according to&nbsp;the prevailing rules and laws of&nbsp;the country. The case and charges are fabricated cases upon political orders ordered from somewhere in&nbsp;the government. This affects everyone in&nbsp;Belarus.</p>
          <h2>We&nbsp;ask of&nbsp;you:</h2>
          <ol>
            <li>Record a&nbsp;video in&nbsp;our support with the tag <strong>#SavePandaDoc</strong>.</li>
            <li>To&nbsp;express your disagreement in&nbsp;the press, media and social networks with the <strong>#SavePandaDoc</strong> tag.</li>
            <li>Connect us&nbsp;to&nbsp;journalists and reporters that you&nbsp;know. Our contact is&nbsp;<a href="mailto:savepandadoc@gmail.com">savepandadoc@gmail.com</a>.</li>
          </ol>
          <p>We&nbsp;are hoping that maximum publicity will show solidarity and pressure to&nbsp;have our colleagues released.</p>
          <p>—&nbsp;Pandas</p>
        </div></div>]]>
            </description>
            <link>https://savebelarusit.org/en/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24446695</guid>
            <pubDate>Fri, 11 Sep 2020 19:57:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The NBC Chimes Machine (1999)]]>
            </title>
            <description>
<![CDATA[
Score 52 | Comments 11 (<a href="https://news.ycombinator.com/item?id=24446569">thread link</a>) | @tintinnabula
<br/>
September 11, 2020 | http://www.theradiohistorian.org/chimes.htm | <a href="https://web.archive.org/web/*/http://www.theradiohistorian.org/chimes.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">



<center>
<h3><b> <span size="6">T</span><span size="4">HE </span><span size="6">NBC C</span><span size="4">HIMES</span><span size="6">M</span><span size="4">ACHINE<br></span>
Copyright 1999, John F. Schneider </b></h3></center>
<hr><p>



The sound of the NBC chimes is the sound of radio history itself.  Probably no single sound better recalls 
the golden age of radio.  The NBC chimes – the musical notes G-E-C – were played at the end of every 
NBC radio program beginning shortly after the network's inception, and continued in daily use on NBC radio and television 
until 1971. </p><p>
&nbsp;Shortly after the formation of the National Broadcasting Company
in 1926, network executives became aware of confusion among the
affiliate stations as to the exact when a program ended, and when it
was safe to cut away for local announcements. The problem was assigned
to a committee of three: Oscar B. Hanson, NBC's Director of Engineer
and a former AT&amp;T engineer; Earnest la Prada, an NBC orchestra
leader; and Phillips Carlin, an NBC announcer. They decided that a
musical signal of some kind would be an appropriate way to indicate the
ending of all programs. At that time, it was common for radio stations
to use the sounds of chimes, gongs, sirens and other mechanical devices
as a signature sound for their station, so the choice of a chime by NBC
was not unusual or particularly innovative. There is in fact some
evidence that the chimes may have been inspired by a similar chime
sequence used at that time by NBC affiliate WSB in Atlanta. </p><p>

During 1927 and 1928, the committee experimented with several combinations of notes.  A seven-note 
sequence which was first used, G-C-F-E-G-C-E, was determined to be too complicated for the announcers to 
play correctly on a consistent basis.  It was first simplified to G-C-F-E, and finally to just G-E-C.  This familiar 
sequence was heard for the first time on November 29, 1929.</p><p>

The chimes were sounded at :29:30 and :59:30 of each hour, to indicate the start 
of the 30 second local station break. They were initially struck by hand by the 
announcer, using a set of hand-held chimes held up to the microphone.<span face="Times New Roman">
</span>
<span>
But, there were inconsistencies in the chimes' tempo, volume, and exact timing.&nbsp; </span>
<span face="Times New Roman">&nbsp;I</span>t was finally determined that the 
best way to solve these problems was for the chimes to be generated 
mechanically.</p><center>
<img alt="Chimes Machine Schematic" src="http://www.theradiohistorian.org/chimach.gif" height="480" width="430"><p>&nbsp;<img alt="Chimes Machine" src="http://www.theradiohistorian.org/chimes2b.jpg" height="480" width="640"></p>
<p>&gt;
</p></center>

The man who designed the chimes machine was 
Captain Richard H. Ranger, who was also the inventor of the electronic organ and the RCA facsimile.  
Ranger created a device resembling a music box, where fingers on a revolving drum plucked a set of reeds.  
There were three sets of eight reeds, one for each note, allowing the generation of the fundamental note 
plus several overtones.   Each reed formed one plate of a capacitor in an oscillator circuit, and the signal 
generated by all reeds was amplified by a single 6C6 pentode tube.  It was activated by a timer,
which would cut off the program two seconds before its end (whether it was finished or 
not!) and feed the chimes to the network. <p>

NBC built a limited number of chime machines. NBC in San Francisco  had two of them - the main and backup 
machines.  Others were installed ain other cities around the country where network programs were originated 
– Los Angeles, Chicago, New York, and perhaps a few others.  It is likely that not more than a dozen chimes 
machines were ever made. </p><center>
<img alt="Chimes Machine Inside View" src="http://www.theradiohistorian.org/chimes5b.jpg"><p>&nbsp;<img alt="Chimes Machine Name Tag" src="http://www.theradiohistorian.org/chimes7b.jpg" height="349" width="512"></p>
</center>

The photos on this page show one of the few chime machines still in existence, now in the hands of a private 
collector.  (NBC had the short-sighted habit of discarding large quantities of historical artifacts throughout 
its history.  It's only through the far-sightedness of a few NBC employees, who saved some of these items 
from the trash bins, that we can today experience many recorded programs, photos, and other memorabilia from 
that era.)
<p>

&nbsp;The unit shown is the chimes machine serial number 2, probably from the first group ever made.   Its mechanical 
parts, although finely crafted, appear to have been hand made.  This unit is no doubt the original chimes machine 
placed in operation at NBC's studios at 111 Sutter Street in San Francisco.  The schematic diagram, 
also shown, indicates that serial number 5 was fabricated in 1933, so this machine would have 
predated it.  The main cabinet contains the motor drive reed mechanism and amplifier, which is accessed by  
removing the front panel's four thumbscrews.  The unit operated from an external power source, no doubt the same 
battery and motor generator system that operated the audio amplifiers in the studios.   The smaller box 
contains the timer and switches that operate the chimes for both studio and "NEMO" broadcast lines.  
("NEMO" was a term used in early radio to indicate a remote broadcast.  It comes from a telephone term, 
and stands for "Not Emanating Main Office".)  The chime machine could be operated in an automatic mode by 
the clock, which was the usual method of operation, or manually by the announcer in the event of programs 
with imprecise ending times, such as sports broadcasts. 
</p><center>
<img alt="Chimes Machine Timer" src="http://www.theradiohistorian.org/chimes4b.jpg" height="458" width="640"></center>

&nbsp;<p>The NBC chimes were officially registered with the U.S. Patent Office in 1950 as a registered service mark, the first 
known case of a sound receiving trademark protection.  They were last heard regularly on NBC 
television in 1976, used to mark the 50th anniversary of the network. </p>

<hr>
<div>
  
  <p>Here is a remembrance of the NBC 
  Chimes Machine from Rick Greenhut - February 3, 2013:</p>
  
  <p>
  <span>John,</span></p></div>

<p>
<span>Just saw your 
page on the Bay Area Radio Museum dedicated to the NBC chimes machine, and I 
wanted to give you another historical fact to add. In 1969 when I went to work 
as a summer replacement engineer (board op) at NBC-owned WKYC Cleveland, there 
was still a chimes machine back in the racks. Since all the O&amp;O's originated 
programs like NOTH (New On The Hour) and Monitor inserts, they all had 2 chimes 
machines. Besides WNBC/New York, WMAQ/Chicago and KNBR/San Francisco, 
WKYC/Cleveland and WRC/Washington also had chimes machines.</span></p>

<p>
  <span>By the next 
  summer I worked there, the chimes machine was gone - whether thrown away or 
  taken home by one of the old-timers, I couldn't say.</span></p>

<p>
  <span>Last bit of 
  radio trivia: I was doing Affiliate Relations for the NBC Radio Network in 
  August of 1987, and during the NABET engineers strike those of us in 
  management with technical backgrounds were taking shifts running the board for 
  the NOTH and manning the ROD (Radio Operations Desk) in Radio Central (network 
  master control). I was the first management person on the board when the 
  engineers walked out at 6:00 AM that morning, and engineered the 6, 7, 8 and 9 
  AM NOTH (the talent was Gary Nunn, now heard on the CBS Radio Network). At 
  8:30 that morning I was told by the General Manager, Craig Simon, that the 
  network had been sold to Westwood One, and that the chimes were not part of 
  the sale, so I was forbidden to play them at the end of the newscast like we 
  usually did.</span></p>

<p>
  <span>I ignored 
  him, and "chimed out" at the end of the 9:00 AM newscast as per usual. He came 
  up to the studio a few minutes later with a funny smile on his face, and told 
  me to make sure no one else did that. I made sure by taking the chimes cart 
  and backup out of the studio. I bulked the backup, and have the last remaining 
  cart with the NBC chimes (recorded directly from the WNBC chimes machine) in 
  my collection.</span></p>

<p>
  <span>I was the 
  last person to play the chimes on the NBC Radio Network.</span></p>
<div>
  <div>
    
    <p>
    <span>Rick<span>&nbsp;</span><span>Greenhut</span></span></p>
    <p>
    <span>Director – 
    U.S. Broadcast Sales<br>
    iBiquity Digital Corporation</span></p>
    </div>
</div>
<hr> <p>

<tt><i>REFERENCES:<br>

A History of the NBC Chimes, by Bill Harris<br>
More on the NBC Chimes, by Brian Wickham<br>
A Backstage Visit to Radio City, by Fred Krock<br>
Author's inspection of a chimes machine in the hands of a private collector</i></tt></p><p>


© Copyright 1999 John F. Schneider.  All rights reserved.  
<br></p><hr>
<center>

</center>
</div>]]>
            </description>
            <link>http://www.theradiohistorian.org/chimes.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-24446569</guid>
            <pubDate>Fri, 11 Sep 2020 19:44:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Ballpoint.io]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24446548">thread link</a>) | @artursapek
<br/>
September 11, 2020 | https://ballpoint.io/files/examples/gopher | <a href="https://web.archive.org/web/*/https://ballpoint.io/files/examples/gopher">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://ballpoint.io/files/examples/gopher</link>
            <guid isPermaLink="false">hacker-news-small-sites-24446548</guid>
            <pubDate>Fri, 11 Sep 2020 19:42:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[From Vim to Ed]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24446422">thread link</a>) | @_nato_
<br/>
September 11, 2020 | http://blog.cretaria.com/posts/from-vim-to-ed.html | <a href="https://web.archive.org/web/*/http://blog.cretaria.com/posts/from-vim-to-ed.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <header>
                
                <p>Sync’ up! … without getting drained</p>
            </header>
	    <section>
<article>
<p><abbr>sep 11</abbr></p>
<h2>From Vim to Ed</h2>
<p>I switched from Vim to Ed twelve months ago,
and I wanted to report my findings on this
strange downstream adventure I took.</p>

<p>I’d been using Vim since about 1998, and I
hardly got close to mastering it after all those
years. In fact, that was one of the reasons I
thought of trying something like Ed: I was tired
of turning a corner only to find a zillion other
great features Vim offers.</p>

<p>I wanted to use an editor that didn’t have
features that were constantly distracting me
from what’s important: writing code.</p>

<h3>The goods</h3>


<p>Ed had one of the most fantastically steep learning
curves in all my many years of nerding. This ol’
editor was so weird in so many ways, I almost
lost heart right off the bat.</p>

<p>A good deal of the Ed ideas are forgotten
in time.  Nobody uses a line-based editor,
so this was one strange playing field to get
accustomed to.</p>

<p>However, once the learning curve was overcome,
the terseness of what I could do became an asset.</p>

<p>In Vim, there’s a million different ways to
get your cursor to zip all around. One of my
favorites was <code>w</code> where on the line in question,
all in normal mode, I could dart over to my
change in word-step motion.</p>

<p>In Ed, the line in question is right there in
front of you, and all you have is ‘regex’ as
your weapon to swap one thing for another.</p>

<p>You’d be surprised how good one can get via
this sole usage pattern. It’s not all that bad,
and thankfully, some distributions of Ed have
nice little shortcuts to make this all the
less pedantic.</p>

<p>With only a few agilities, Ed limits your usage
to x, y, or z. The result?  You get so darn good
at those.</p>

<p>Another powerful plus for Ed, is its undo/redo
limitation.</p>

<p>Usually, one would think, that after some
hacking, one would want to undo changes that
happened twenty edits ago. In Vim, you’d just
hold down <code>u</code> until it gets to that state. In Ed,
the buffer is limited to one undo. Incredibly,
this limitation has never ruined my day. Because
of my for-knowledge that Ed can’t undo twenty
edits ago, my approach on edits has been
‘Edified,’ and my behavior is in sync with this
one undo world.</p>

<p>I don’t pop open Vim ever, except to run a spell
check on something that isn’t code (like this
blog post, for example). Fascinating to me:
one of the side effects of Ed is my spelling
got a lot better. I’m more careful about what
I type, as the pain to undo or edit things is
quite real. Go figure!</p>

<h3>The bads</h3>


<p>Vim offers so much, it’s hard to
compare Ed to something this feature-rich. So,
I won’t.</p>

<p>Rather, I’ll just jot down some of my Ed-related
gripes.</p>

<p>First, one can scroll forward a page via <code>z</code>
in Ed, but one cannot do the reciprocal. I
was so bummed out on day one regarding this,
and I’m still bummed out 365 days later. What I
find shocking, is that <abbr>UNIX</abbr> <code>mail</code> has <code>z</code> to go
forward a page in header listings, and also <code>-z</code>
to go back a page. If only this was baked into
Ed from the start. My workaround is terrible,
and funny as it may sound, when I’m fatigued,
I sometimes try <code>-z</code> to see if it magically
started working.</p>

<p>Perhaps more of a gripe to the authors of <code>sed</code>
rather than Ed, but I wish there was a 100%
compatibility with ‘regex’ substitution patterns
that are valid in Ed, but in <code>sed</code>. This is
not the case, and it’s a shame. In general,
one has to forget about Ed’s awesome shorthand
tricks to get <code>sed</code> to work. It would be great
if the bounty of Ed vocabulary I’ve built up
just simply worked one-for-one in <code>sed</code>.</p>

<h3>More Ed for me</h3>


<p>One year dedicated to Ed is probably enough time
to arrive at a plateau of know-how where the
limitations will remain as such, and the pains
can’t be overcome with any more learning. That
said, I think I’ve arrived at a comfortable spot
with Ed, and I’m going to stick it out with it!</p><p><svg xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg" viewBox="200 0 400 800" width="400" height="800"><rect width="400" height="800" fill="#b33a3a"></rect><polygon points="299.5 150 254.5 247 351.5 247 "></polygon><path d="m321.9 548.9l-243.8 0"></path><path d="m303 247.1l0 243.8"></path><polygon points="94.5 150 49.5 247 146.5 247 "></polygon><path d="m98 247.1l0 243.8"></path><text font-family="Helvetica, Arial, sans-serif" font-size="60" y="112" x="10" style="fill-opacity:null">THIS END UP</text><a xlink:href="//cretaria.com"><text id="link-cretaria" font-family="Helvetica, Arial, sans-serif" font-size="50" y="680" x="10" fill-opacity="null">What’s Cretaria?</text></a><path d="m175 700l200 0" style="fill-opacity:null;fill:none;stroke-linejoin:null;stroke-opacity:null;stroke-width:4;stroke:#000"></path></svg></p></article>
            </section>
            
        </div></div>]]>
            </description>
            <link>http://blog.cretaria.com/posts/from-vim-to-ed.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24446422</guid>
            <pubDate>Fri, 11 Sep 2020 19:27:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learn Directly from the Best - A Curated List from Twitter]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24446218">thread link</a>) | @utkarsh_apoorva
<br/>
September 11, 2020 | https://happinomy.com/twitter-university/ | <a href="https://web.archive.org/web/*/https://happinomy.com/twitter-university/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>




<h3>The Ultimate List of the best people to follow on Twitter.</h3>



<p>Twitter can be a great source of learning from amazing people. Here is a growing list of great people on twitter, and what you can learn from them.</p>



<p>Here is a (growing) list of some of the most amazing people I found on Twitter.</p>



<p>From building profitable businesses to growing your audience; and from writing great copy to writing great code, there is so much to learn from them. </p>



<p>And the best part – they share their experiences and lessons very publicly on Twitter.</p>



<p>This is a personal list – compiled by me over a few weeks.</p>



<p>I am sure there are many more interesting people out there. Please add them to the list in the thread below, or DM me on twitter (<a rel="noreferrer noopener" href="https://www.twitter.com/kush_apoorva" data-type="URL" data-id="https://www.twitter.com/kush_apoorva" target="_blank">@kush_apoorva</a>).</p>







<h3>Naval Ravikant (<a href="https://twitter.com/naval" data-type="URL" data-id="https://twitter.com/naval" target="_blank" rel="noreferrer noopener">@naval</a>)</h3>



<ol><li><strong><em>What to Learn</em></strong>: How to be wealthy, happy, and fit.</li><li><strong><em>Key Source</em></strong>: This tweet – <a rel="noreferrer noopener" href="https://twitter.com/naval/status/1002103360646823936" target="_blank">How to Get Rich without Getting Lucky</a> </li><li><strong><em>Quick lesson</em></strong>: Develop “specific knowledge,” which is unique and cannot be taught in schools. Use code and media to deliver value to society at scale.</li><li><strong><em>More Resources</em></strong>: <a type="URL" id="https://nav.al" rel="noreferrer noopener" href="https://nav.al/" target="_blank">His blog</a>, <a href="https://twitter.com/naval">His twitter</a>.</li></ol>



<figure><div>
<blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">How to Get Rich (without getting lucky):</p>— Naval (@naval) <a href="https://twitter.com/naval/status/1002103360646823936?ref_src=twsrc%5Etfw">May 31, 2018</a></blockquote>
</div></figure>







<h3>Nir Eyal (<a href="https://twitter.com/nireyal" data-type="URL" data-id="https://twitter.com/nireyal" target="_blank" rel="noreferrer noopener">@nireyal</a>)</h3>



<ol><li><strong><em><strong><em><strong><em>What to Learn</em></strong></em></strong>:</em></strong> How to build habit-forming products.</li><li><strong><em>Key Source</em></strong>: His book: Hooked.</li><li><strong><em>Quick Lesson: </em></strong>Habits are formed from actions when the loop of Trigger-Action-Reward-Investment is completed.</li><li><strong><em>More Resouces:</em></strong> <a type="URL" id="https://nirandfar.com" rel="noreferrer noopener" href="https://nirandfar.com/" target="_blank">His Blog</a>.</li></ol>



<figure><div>
<blockquote data-width="550" data-dnt="true"><div lang="en" dir="ltr"><p>There’s a reason we call it “paying” attention. </p><p>Our time and focus has value.</p></div>— Nir Eyal (@nireyal) <a href="https://twitter.com/nireyal/status/1303325968849805312?ref_src=twsrc%5Etfw">September 8, 2020</a></blockquote>
</div></figure>







<h3>Pieter Levels (<a href="https://twitter.com/levelsio" data-type="URL" data-id="https://twitter.com/levelsio" target="_blank" rel="noreferrer noopener">@levelsio</a>)</h3>



<ol><li><strong><em><strong><em><strong><em><strong><em><strong><em><strong><em>What to Learn</em></strong></em></strong></em></strong></em></strong></em></strong>:</em></strong> Be a serial maker.</li><li><strong><em>Key Source</em></strong>:<strong><em> </em></strong><a href="https://www.youtube.com/watch?v=6reLWfFNer0">This talk</a>.</li><li><strong><em>Quick Lesson</em></strong><em>: </em>Become a contrarian. Experience uncommon things to have uncommon ideas. </li><li><strong><em>More Resources: </em></strong> Read his book – <a rel="noreferrer noopener" href="https://makebook.io/" type="URL" id="https://makebook.io" target="_blank">Makebook</a>.</li></ol>







<figure><div>
<blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">Everyone and their cousin's goldfish is building an uptime monitor now, it's the new todo app</p>— ؜ (@levelsio) <a href="https://twitter.com/levelsio/status/1301143528425357314?ref_src=twsrc%5Etfw">September 2, 2020</a></blockquote>
</div></figure>







<h3>Toby Howell (<a rel="noreferrer noopener" href="https://twitter.com/tobydoyhowell" data-type="URL" data-id="https://twitter.com/tobydoyhowell" target="_blank">@tobydoyhowell</a>)</h3>



<ol><li><strong><em><strong><em>What to Learn</em></strong>:</em></strong> How to grow your audience on Twitter.</li><li><strong><em>Key source</em></strong>: <a rel="noreferrer noopener" href="https://twitter.com/tobydoyhowell/status/1272674455681024000" data-type="URL" data-id="https://twitter.com/tobydoyhowell/status/1272674455681024000" target="_blank">A thread on how to write twitter threads</a></li><li><strong><em>Quick Lesson: </em></strong>You just need to be slightly disciplined, and slightly differentiated to be able to grow your audience. There is a dearth of great people to follow.</li><li><strong><em>More Resources:</em></strong> Just follow him on Twitter </li></ol>



<figure><div>
<blockquote data-width="550" data-dnt="true"><div lang="en" dir="ltr"><p>I've been running <a href="https://twitter.com/MorningBrew?ref_src=twsrc%5Etfw">@morningbrew</a>'s social media for the past ~2 months</p><p>here's a thread of a few things i've learned</p><p>Twitter strategy only for now</p><p>Insta later</p></div>— Toby ☕️ (@tobydoyhowell) <a href="https://twitter.com/tobydoyhowell/status/1272674455681024000?ref_src=twsrc%5Etfw">June 15, 2020</a></blockquote>
</div></figure>







<h3>Harry Dry (<a href="https://twitter.com/harrydry" data-type="URL" data-id="https://twitter.com/harrydry" target="_blank" rel="noreferrer noopener">@harrydry</a>)</h3>



<ol><li><strong><em><strong><em><strong><em>Learn from Twitter</em></strong></em></strong>:</em></strong> How to market your products.</li><li><strong><em>Key Source: </em></strong> The <a href="https://marketingexamples.com/" type="URL" id="https://marketingexamples.com/">Marketing </a><a rel="noreferrer noopener" href="https://marketingexamples.com/" type="URL" id="https://marketingexamples.com/" target="_blank">Examples</a> website.</li><li><strong><em>Quick Lesson</em></strong>: When sharing knowledge, use real examples (no theory), and show the good vs bad clearly, like this.</li><li><strong><em>More Resources</em></strong>: <a href="https://thekanyestory.com/">The Kanye </a><a rel="noreferrer noopener" href="https://thekanyestory.com/" target="_blank">Story</a></li></ol>



<figure><div>
<blockquote data-width="550" data-dnt="true"><div lang="en" dir="ltr"><p>🔥 Finally finished The Kanye Story! </p><p>It's a story about how I went from lying in bed with no ideas to negotiating with the biggest superstar on planet earth. Take a look 👉🏻 <a href="https://t.co/7v6vPX55eM">https://t.co/7v6vPX55eM</a></p></div>— Harry Dry (@harrydry) <a href="https://twitter.com/harrydry/status/1111654068961849346?ref_src=twsrc%5Etfw">March 29, 2019</a></blockquote>
</div></figure>







<h3>Liked this Resource? Then Join us 😍</h3>











<h3>Daniel Vassallo (<a href="https://twitter.com/dvassallo" data-type="URL" data-id="https://twitter.com/dvassallo" target="_blank" rel="noreferrer noopener">@dvassallo</a>)</h3>



<ol><li><strong><em><strong><em>Learn from Twitter</em></strong></em></strong>: How to grow your Twitter audience</li><li><strong><em>Key Source</em></strong>: This <a data-type="URL" data-id="https://gumroad.com/l/PBkrO" rel="noreferrer noopener" href="https://gumroad.com/l/PBkrO" target="_blank">100-minute video</a> on Gumroad (paid).</li><li><strong><em>Quick Lesson:</em></strong> Earn credibility by sharing behind-the-scenes, real experiences, even if you are not an expert. Once you are credible, people will listen to you.</li><li><strong><em>More Resources:</em></strong> Check out his <a data-type="URL" data-id="https://gumroad.com/dvassallo" rel="noreferrer noopener" href="https://gumroad.com/dvassallo" target="_blank">Gumroad profile</a> and <a rel="noreferrer noopener" href="https://danielvassallo.com/" target="_blank">his blog</a>.</li></ol>



<figure><div>
<blockquote data-width="550" data-dnt="true"><div lang="en" dir="ltr"><p>My advice to first-time info product creators:</p><p>1. Start with a very small product.</p><p>2. Choose a topic you know well that will almost write itself. Avoid doing research.</p><p>3. Timebox production to 2 weeks.</p><p>4. Charge $10.</p><p>5. Promote it!</p><p>All the lessons are in #5. Best of luck!</p></div>— Daniel Vassallo (@dvassallo) <a href="https://twitter.com/dvassallo/status/1287210142459547648?ref_src=twsrc%5Etfw">July 26, 2020</a></blockquote>
</div></figure>







<h3>Matthew Kobach (<a href="https://twitter.com/mkobach" target="_blank" rel="noreferrer noopener">@mkobach</a>)</h3>



<ol><li><strong><em><strong><em>Learn from Twitter</em></strong>: </em></strong> Learn about Social Media marketing.</li><li><strong><em>Key Source</em></strong>: <a rel="noreferrer noopener" href="https://twitter.com/mkobach/status/1287140026061656070" type="URL" id="https://twitter.com/mkobach/status/1287140026061656070" target="_blank">This thread</a>.</li><li><strong><em>Quick Lesson:</em></strong>  Share content that is interesting + relevant. It could be anything your audience cares about.</li><li><strong><em>More Resources: </em></strong>This <a rel="noreferrer noopener" href="https://www.perell.com/podcast/matthew-kobach-social-media-brands" type="URL" id="https://www.perell.com/podcast/matthew-kobach-social-media-brands" target="_blank">great interview</a> with David Perell. </li></ol>



<figure><div>
<blockquote data-width="550" data-dnt="true"><div lang="en" dir="ltr"><p>I promised I would share the <a href="https://twitter.com/fast?ref_src=twsrc%5Etfw">@Fast</a> social media strategy in real time, so let’s go</p><p>We’re still very early in the process, but here’s where we’re at so far (a brief thread)</p></div>— Matthew Kobach (@mkobach) <a href="https://twitter.com/mkobach/status/1287140026061656070?ref_src=twsrc%5Etfw">July 25, 2020</a></blockquote>
</div></figure>







<h3>Arvid Kahl (<a href="https://twitter.com/arvidkahl" data-type="URL" data-id="https://twitter.com/arvidkahl" target="_blank" rel="noreferrer noopener">@arvidkahl</a>)</h3>



<ol><li><strong><em><strong><em>Learn from Twitter</em></strong>: </em></strong> How to create, build, and sell a bootstrapped business.</li><li><strong><em>Key Source</em></strong>: His book, Zero to Sold.</li><li><strong><em>Quick Lesson:</em></strong>  Find a common problem in a niche audience.</li><li><strong><em>More Resources: </em></strong> His blog – <a rel="noreferrer noopener" href="https://thebootstrappedfounder.com/" type="URL" id="https://thebootstrappedfounder.com" target="_blank">The Bootstrapped Founder</a></li></ol>



<figure><div>
<blockquote data-width="550" data-dnt="true"><div lang="en" dir="ltr"><p>Successful businesses are built by solving critical problems for an audience that will pay for a solution to their issues.</p><p>Not every problem is critical. Not every critical problem is interesting. Not every interesting problem is critical.</p></div>— Arvid Kahl (@arvidkahl) <a href="https://twitter.com/arvidkahl/status/1303379665608941569?ref_src=twsrc%5Etfw">September 8, 2020</a></blockquote>
</div></figure>







<h3>Lenny Rachitsky (<a href="https://twitter.com/lennysan" data-type="URL" data-id="https://twitter.com/lennysan" target="_blank" rel="noreferrer noopener">@lennysan</a>)</h3>



<ol><li><strong><em>What to Learn: </em></strong> How to grow your product with high retention.</li><li><strong><em>Key Source</em></strong>: <a rel="noreferrer noopener" href="https://twitter.com/lennysan/status/1299077345681133568" data-type="URL" data-id="https://twitter.com/lennysan/status/1299077345681133568" target="_blank">This twitter thread</a> on user retention.</li><li><strong><em>Quick Lesson:</em></strong>  Increase your product’s retention: (1) Improve your product or better, onboarding (2) Improve deactivation flow (4) Change your users</li><li><strong><em>More Resources: </em></strong> His <a rel="noreferrer noopener" href="https://www.lennyrachitsky.com/" target="_blank">newsletter and blog</a>.</li></ol>



<figure><div>
<blockquote data-width="550" data-dnt="true"><div lang="en" dir="ltr"><p>Q: What's the most important growth metric to get right?<br>A: Retention</p><p>Q: How do you know if you have good retention?<br>A: Read this: <a href="https://t.co/BFzRmSJgwS">https://t.co/BFzRmSJgwS</a></p><p>Q: How do you increase retention, if it isn't good?</p><p>Time for a thread 👇👇👇</p></div>— Lenny Rachitsky (@lennysan) <a href="https://twitter.com/lennysan/status/1299077345681133568?ref_src=twsrc%5Etfw">August 27, 2020</a></blockquote>
</div></figure>







<h3>Alex and Books (<a href="https://twitter.com/AlexAndBooks_">@AlexAndBooks_</a>)</h3>



<ol><li><strong><em>What to Learn: </em></strong> How to Read. </li><li><strong><em>Key Source</em></strong>: This <a rel="noreferrer noopener" href="https://twitter.com/AlexAndBooks_/status/1237146642018639872" data-type="URL" data-id="https://twitter.com/AlexAndBooks_/status/1237146642018639872" target="_blank">twitter thread</a>.</li><li><strong><em>Quick Lesson:</em></strong> Just read the super relevant parts of a book that is relevant to your life. Skip other parts, and quit other books.</li><li><strong><em>More Resources: </em></strong> <a rel="noreferrer noopener" href="http://alexandbooks.com/" data-type="URL" data-id="alexandbooks.com" target="_blank">His Blog</a>.</li></ol>



<figure><div>
<blockquote data-width="550" data-dnt="true"><div lang="en" dir="ltr"><p>I believe reading is a skill, like driving or tennis.</p><p>And with all skills, there are ways to become better. </p><p>I'm on a quest to develop the skill of reading and share the best practices I learn along the way.</p><p>FOLLOW this thread to join my journey &amp; become a better reader!</p></div>— Alex and Books 📚 (@AlexAndBooks_) <a href="https://twitter.com/AlexAndBooks_/status/1237146642018639872?ref_src=twsrc%5Etfw">March 9, 2020</a></blockquote>
</div></figure>







<h3>Shreyas Doshi (<a href="https://twitter.com/shreyas" data-type="URL" data-id="https://twitter.com/shreyas" target="_blank" rel="noreferrer noopener">@shreyas</a>)</h3>



<ol><li><strong><em>What to Learn: </em></strong> How to be a great product manager.</li><li><strong><em>Key Source</em></strong>: This <a href="https://twitter.com/shreyas/status/1303150374124048386" target="_blank" rel="noreferrer noopener">thread of threads</a> by Shreyas.</li><li>Quick Lesson:  Great PMs know that people—and therefore their users —are driven by emotion more than logic. </li><li><strong><em>More Resources: </em></strong> <a type="URL" id="https://twitter.com/shreyas" rel="noreferrer noopener" href="https://twitter.com/shreyas" target="_blank">Follow on Twitter</a>.</li></ol>



<figure></figure>







<h3>Jack Butcher (<a href="https://twitter.com/jackbutcher" target="_blank" rel="noreferrer noopener">@jackbutcher</a>)</h3>



<ol><li><strong><em>What to Learn: </em></strong> How to express ideas better, visually.</li><li><strong><em>Key Source</em></strong>: <a rel="noreferrer noopener" href="https://twitter.com/jackbutcher/status/1303376950346612737" data-type="URL" data-id="https://twitter.com/jackbutcher/status/1303376950346612737" target="_blank">This twitter thread</a>. </li><li><strong><em>Quick Lesson:</em></strong>  Prove a problem exists, find a solution that you can deliver, promote that solution as much as you can.</li><li><strong><em>More Resources: </em></strong> <a rel="noreferrer noopener" href="https://twitter.com/jackbutcher" data-type="URL" data-id="https://twitter.com/jackbutcher" target="_blank">Follow on Twitter</a></li></ol>



<figure></figure>







<h3>Robin Vander Heyden (<a href="https://twitter.com/vinrob" data-type="URL" data-id="https://twitter.com/vinrob" target="_blank" rel="noreferrer noopener">@vinrob</a>)</h3>



<ol><li><strong><em>Learn from Twitter: </em></strong> How to run a bootstrapped business.</li><li><strong><em>Key Source</em></strong>: <a type="URL" id="https://twitter.com/Vinrob/status/1080331951536463872" rel="noreferrer noopener" href="https://twitter.com/Vinrob/status/1080331951536463872" target="_blank">This twitter thread</a> on how he grew his company from 0 to $500K ARR in 2 years.</li><li><strong><em>Quick Lesson: </em></strong> The goal of an MVP: Here’s the problem, here’s how I solve it, do you want to buy?</li><li><strong><em>More Resources: </em></strong> <a href="https://twitter.com/vinrob">Follow on Twitter</a></li></ol>



<figure><div>
<blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">In 2018 I moved to 🇮🇩 Indonesia and started an online business, fully bootstrapped from 0 to $500k/year in revenue (25% profits). Here are some insights about creating value, distribution, building a team, and what my role is about.</p>— Robin Vander Heyden (@Vinrob) <a href="https://twitter.com/Vinrob/status/1080331951536463872?ref_src=twsrc%5Etfw">January 2, 2019</a></blockquote>
</div></figure>







<h3>Aleksandr Volodarsky (<a href="https://twitter.com/volodarik" data-type="URL" data-id="https://twitter.com/volodarik" target="_blank" rel="noreferrer noopener">@volodarik</a>)</h3>



<ol><li><strong><em>Learn from Twitter: </em></strong> How a business can survive a pandemic.</li><li><strong><em>Key Source</em></strong>: <a type="URL" id="https://twitter.com/volodarik/status/1278336866744512513" rel="noreferrer noopener" href="https://twitter.com/volodarik/status/1278336866744512513" target="_blank">This twitter thread on how Quora gave them 1M GMV</a></li><li><strong><em>Quick Lesson:</em></strong>  The Give/Take ratio from a community should be 3:1. Give at least three times more than you take. They used this to get 1M GMV from Quora.</li><li><strong><em>More Resources: </em></strong> <a type="URL" id="https://sharingalemon.substack.com/" rel="noreferrer noopener" href="https://sharingalemon.substack.com/" target="_blank">His newsletter</a></li></ol>



<figure><div>
<blockquote data-width="550" data-dnt="true"><div lang="en" dir="ltr"><p>Quora has generated for us at least $1m GMV for 2 years. </p><p>It’s losing value for us now, but for an early-stage startup, it’s a great source to get customers and learn more about them.</p><p>Below I'll list 16 tips that worked for us.</p></div>— Aleksandr Volodarsky (@volodarik) <a href="https://twitter.com/volodarik/status/1278336866744512513?ref_src=twsrc%5Etfw">July 1, 2020</a></blockquote>
</div></figure>







<h3>Florin Pop (<a href="https://twitter.com/florinpop1705" data-type="URL" data-id="https://twitter.com/florinpop1705" target="_blank" rel="noreferrer noopener">@florinpop1705</a>)</h3>



<ol><li><strong><em>What to Learn: </em></strong> How to make web apps</li><li><strong><em>Key Source</em></strong>: <a rel="noreferrer noopener" href="https://twitter.com/florinpop1705/status/1303904111876767744" data-type="URL" data-id="https://twitter.com/florinpop1705/status/1303904111876767744" target="_blank">This twitter thread</a> talking about 10 apps being made in 10 hours on live video.</li><li><strong><em>Quick Lesson:</em></strong>  Anyone can write code.</li><li><strong><em>More Resources: </em></strong> <a rel="noreferrer noopener" href="https://www.florin-pop.com/" data-type="URL" data-id="https://www.florin-pop.com/" target="_blank">His website</a> and <a rel="noreferrer noopener" href="https://www.youtube.com/channel/UCeU-1X402kT-JlLdAitxSMA" data-type="URL" data-id="https://www.youtube.com/channel/UCeU-1X402kT-JlLdAitxSMA" target="_blank">his youtube channel</a>.</li></ol>



<figure></figure>



















<h2>Coming Soon</h2>



<p>John Yongfook</p>



<p>Randall Kanna</p>



<p>Zeno Rocha</p>



<p>Mubashar Iqbal</p>



<p>Nathan Berry</p>



<p>David Perrel</p>



<p>Sahil Lavingiya</p>



<p>NN Taleb</p>



<p>Nathan Latka (<a href="https://twitter.com/NathanLatka/status/1303744597164732417" data-type="URL" data-id="https://twitter.com/NathanLatka/status/1303744597164732417" target="_blank" rel="noreferrer noopener">tweet</a>)</p>



<p>Nathan Barry (<a href="https://twitter.com/nathanbarry" data-type="URL" data-id="https://twitter.com/nathanbarry" target="_blank" rel="noreferrer noopener">@nathanbarry</a>)</p>



<p>Noah Kagan</p>



<p>Joel Gascoigne</p>



<p>John Nolan</p>



<p>James Clear</p>











<h2>Rising Stars to Learn From</h2>



<p>This is a list of people who are rising fast. They add tremendous value, and you can learn great things from them on twitter.</p>



<p>KP (<a href="https://twitter.com/thisiskp_">@thisiskp_</a>)</p>



<p>Sharath (<a href="https://twitter.com/5harath" data-type="URL" data-id="https://twitter.com/5harath" target="_blank" rel="noreferrer noopener">@5harath</a>)</p>



<p>Deepu Asok (<a rel="noreferrer noopener" href="https://twitter.com/deepuasok" target="_blank">@deepuasok</a>)</p>



<p>Vik Duggal (<a href="https://twitter.com/vikdug" target="_blank" rel="noreferrer noopener">@vikdug</a>)</p>







<h3>Liked this Resource? Then Join us  😍</h3>















<p>Credits: Photo by <a href="https://unsplash.com/@jamie452?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Jamie Street</a> on <a href="https://unsplash.com/s/photos/twitter?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></p>



<p>More about me <a href="https://happinomy.com/about-me" target="_blank" rel="noreferrer noopener">here</a></p>
</div></div>]]>
            </description>
            <link>https://happinomy.com/twitter-university/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24446218</guid>
            <pubDate>Fri, 11 Sep 2020 19:05:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Not all attacks are equal: understanding and preventing DoS in web applications]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24445886">thread link</a>) | @ievans
<br/>
September 11, 2020 | https://r2c.dev/blog/2020/understanding-and-preventing-dos-in-web-apps/ | <a href="https://web.archive.org/web/*/https://r2c.dev/blog/2020/understanding-and-preventing-dos-in-web-apps/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><div><p><em>Thanks to Clint Gibler, Grayson Hardaway, and Pablo Estrada at r2c for their contributions to this piece. And thanks to r2c for contracting me to write it! This article is cross-posted on <a href="https://jacobian.org/2020/sep/11/analyzing-dos-vulnerabilities/" target="_blank" rel="noopener">jacobian.org</a>.</em></p>
<p>When I ran the security team at Heroku, I had this recurring nightmare: my PagerDuty alarm goesoff, alerting me to some sort of security incident. In my dream, I’d look at my phone and realize “oh no, this is the big one” — and then I’d wake up.</p>
<p>I’m still not sure exactly what the attack in my dream was, but it may very well have been a <em>Denial-of-Service (DoS)</em> attack. DoS attacks are simple but can be devastating: an attacker crafts and sends traffic to your app in a way that overwhelms your servers. While this is arguably not as bad as a remote code execution or a data breach, it’s still pretty terrible. If your customers can’t use your app, you’ll lose their money and their trust.</p>
<p>Typically, we talk about two kinds of Denial-of-Service attacks:</p>
<ol>
<li>“Normal” Denial-of-Service (DoS) attacks, where a single machine is sufficient to cause downtime. The classic, old-school version of this attack is the <a href="https://en.wikipedia.org/wiki/Zip_bomb" target="_blank" rel="noopener">zip bomb</a>: an attacker tricks your server into expanding a specially-crafted ZIP file that is tiny compressed but expands to entirely fill your disk space.</li>
<li>Distributed Denial-of-Service (DDoS) attacks. These attacks rely on an attacker sending a huge flood of traffic to your site from multiple machines (that’s the “Distributed” part). Often, these attacks come from <a href="https://en.wikipedia.org/wiki/Botnet" target="_blank" rel="noopener">Botnets</a> — fleets of compromised machines controlled by an attacker. These botnets are available to purchase in certain corners of the Internet, making a DDoS attack well within the reach of anyone with a credit card.</li>
</ol>
<p>Engineers who work on web applications frequently run into vulnerabilities that could be used in a DoS/DDoS attack. Unfortunately, there’s broad disagreement in the industry about how to treat these vulnerabilities. The risk can be difficult to analyze: I’ve seen development teams argue for <em>weeks</em> over how to handle a DoS vector.</p>
<p>This article tries to cut through those arguments. It provides a framework for engineering and application security teams to think about denial-of-service risk, breaks down DoS vulnerabilities into high-, medium-, and low-risk classes, and has recommendations for mitigations at each layer.</p>
<p>The primary focus of this post is on the big picture, and should apply to any kind of web app. But to make things concrete, I’ve added a few specific Django-related examples. (I helped create it, so it’s what I’m most familiar with.)</p>
<h2>Evaluating Denial-of-Service Risk</h2>
<p>Evaluating the risk of a DoS vulnerability at the application layer can be difficult. There’s widespread disagreement among security professionals: you’ll often see two different appsec teams treat similar issues very differently.</p>
<p>Some argue: it’s nearly impossible to entirely mitigate against a focused DDoS — a dedicated enough attacker can throw more bandwidth at you than your app can handle. You can never fully mitigate a DDoS attack without serious support from an upstream network provider with specific tools to protect bot attacks (e.g., Cloudflare). Thus, chasing and fixing hypothetical DoS vulnerabilities can seem like a waste of developer time. These teams treat most potential DoS vectors as acceptable risk, and focus their energy at preparing mitigations at the network level.</p>
<p>Other teams point out that the traditional risk model has three potential problem areas: Confidentiality, Integrity, and <em>Availability</em>. We’ve long understood that uptime is a security issue. It’s becoming increasingly common for attackers to take a service down and then demand a ransom to stop the attack. The recent <a href="https://www.theverge.com/2020/8/4/21353842/garmin-ransomware-attack-wearables-wastedlocker-evil-corp" target="_blank" rel="noopener">attack against Garmin</a> is a highly notable example; attackers took down nearly all of Garmin’s services, and reportedly demanded US $1 million to stop the attack. (In this case the attack was ransomware, but it’s easy to see how a DoS attack could have a similar effect). Thus, DoS vulnerabilities are risks like any other, and it’s easy to understand the argument that they should all be mitigated.</p>
<p>It’s important to recognize that both of these positions are valid! It’s reasonable to see DoS as out-of-scope for application security; it’s similarly reasonable to scope it in. I’ve often seen security teams get completely stuck arguing between these two positions. Since neither is “right” or “wrong”, it can be impossible to figure out how to move forward.</p>
<h3><strong>How I decide: <em>attacker leverage</em></strong></h3>
<p>The model I use to cut through this argument is the concept of <em>attacker leverage</em>. Levers amplify force: a small amount of force applied to the long end of the lever is multiplied at the short end. In the context of a DoS attack, if a vulnerability has <em>high leverage</em> it means attackers can consume a ton of your server resources with minimal resources.</p>
<p>For example, if a bug in your web app allows a single <code>GET</code> request to consume 100% CPU, that’s a terrific amount of leverage. Just a small handful of attacks, and your web servers will grind to a halt. A <em>low leverage</em> vulnerability, on the other hand, requires a high amount of attacker resources to cause minor availability degradation. If an attacker has to spend thousands of dollars to bring a single server to its knees, you can probably scale up faster than they can.</p>
<p>The higher the leverage, the higher the risk, and the more likely I am to address the issue directly. The lower the leverage, the more likely I’ll accept the risk and/or lean on network-level mitigations.</p>
<p>Let’s get specific. I’ve broken down DoS risk into high, medium, and low risk classes, based on leverage. For each class, I’ll look at how to recognize that a vulnerability falls into this class, discuss a few examples, and give some suggestions for mitigation.</p>
<h2>High leverage DoS vulnerabilities: easily-amplified resource starvation</h2>
<p>The classic high-risk DoS vulnerability is one where an attacker can cause resource starvation using very little resources themselves. This could mean exhaustion of any number of types of resources, including:</p>
<ul>
<li><strong>Disk space</strong> — e.g., a vulnerability that magnifies uploaded data and fills the disk, as in the case of the classic <a href="https://en.wikipedia.org/wiki/Zip_bomb" target="_blank" rel="noopener">zip bomb</a>.</li>
<li><strong>Network bandwidth</strong> — e.g., a vulnerability that amplifies input traffic, where a single incoming request consumes tons of bandwidth, causing network starvation. I’ve seen this happen with a bug in a microservices system, where a single incoming request triggered millions of internal API requests (including moving some fairly large files around the network), and choked off the internal network bandwidth.</li>
<li><strong>CPU utilization</strong> — e.g., an exploit that triggers an <a href="https://accidentallyquadratic.tumblr.com/" target="_blank" rel="noopener">accidentally quadratic</a> algorithm, causing web servers to grind to a halt.</li>
<li><strong>Concurrency limits</strong> — most servers have a maximum concurrency limit (e.g., max threads or processes, or max connections for a database); an exploit that causes a process to run very slowly (or never exit) can cause the server to hit those limits and start rejecting requests.</li>
</ul>
<p>In all these cases, the unifying factor is that a bug in the application will allow significant amplification.</p>
<h3><strong>Authentication affects risk</strong></h3>
<p>When considering the risk of a resource amplification DoS vector, an important factor is the level of authentication required to trigger the vulnerability.
If a completely anonymous user can easily trigger a resource starvation attack, it’ll be extremely easy for an attacker to bring you to your knees. Unauthenticated DoS vectors should be considered very high risk.
On the other hand, if only users who authenticate against your corporate Single Sign-On server can trigger the vulnerability, it’s far lower risk. Most attackers aren’t insiders (though, some are!). And, if an attack does occur, it’s easy to attribute and block. In many cases, “we can attribute and block this attack” is a reasonable, if not complete, mitigation strategy.
Many vulnerabilities fall between these two extremes: most services make creating new accounts fairly trivial (e.g., you just need an email address). This does give minimal ability to attribute and block, but often not enough.</p>
<h3><strong>Mitigation recommendation: eliminate</strong></h3>
<p>Generally, I recommend that this class of DoS vulnerabilities — especially unauthenticated ones — be treated as high risk, and eliminated. If exploited, these vulnerabilities can be devastating; they allow a single attacker to completely overwhelm your app. I’d put the same level of effort into finding and eliminating these kinds of bugs that I do other high-risk security vulnerabilities like XSS and CSRF.</p>
<h3><strong>An example high-leverage vulnerability: ReDoS</strong></h3>
<p>A common example of this last type of resource starvation, concurrency limits, is the <em>regular expression denial-of-service</em>, aka <em>ReDoS</em>. ReDoS bugs occur when certain types of strings can cause improperly crafted regular expressions to perform extremely poorly. These types of vulnerabilities are unfortunately relatively common in Python; the built-in regular expression module (<code>re</code>) has no inherent protection against them (unlike libraries like <a href="https://github.com/google/re2" target="_blank" rel="noopener">re2</a>, Go’s built-in regex module, and thus renders the language more or less immune to this class of attack).
(Django itself has had several of these vulnerabilities over the years; for example, <a href="https://www.djangoproject.com/weblog/2019/aug/01/security-releases/" target="_blank" rel="noopener">CVE-2019-14232 and CVE-2019-14233</a> were both ReDoS vulnerabilities).
In Django, these vulnerabilities most often show up in two places: <a href="https://docs.djangoproject.com/en/3.1/topics/http/urls/#using-regular-expressions" target="_blank" rel="noopener">regex-based URL parsing</a> and <a href="https://docs.djangoproject.com/en/3.1/ref/validators/" target="_blank" rel="noopener">custom validators</a>, and more broadly anywhere an application uses regular expressions. Luckily, this class of vulnerabilities are fairly easy to find; see the following r2c articles:</p>
<ul>
<li><a href="https://r2c.dev/blog/2020/finding-python-redos-bugs-at-scale-using-dlint-and-r2c/" target="_blank" rel="noopener">Finding Python ReDoS bugs at scale using Dlint and r2c</a>, and</li>
<li><a href="https://r2c.dev/blog/2020/improving-redos-detection-with-dlint-and-r2c/" target="_blank" rel="noopener">Improving ReDoS detection and finding more bugs using Dlint and r2c</a></li>
</ul>
<p>If you’re using Python, you can easily scan for ReDoS in your application using Semgrep, which has ReDoS detection ported from Dlint. The detection requires some extra logic written using Semgrep’s powerful pattern-where-python clause, which enables rules to leverage the full power of Python, …</p></div></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://r2c.dev/blog/2020/understanding-and-preventing-dos-in-web-apps/">https://r2c.dev/blog/2020/understanding-and-preventing-dos-in-web-apps/</a></em></p>]]>
            </description>
            <link>https://r2c.dev/blog/2020/understanding-and-preventing-dos-in-web-apps/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24445886</guid>
            <pubDate>Fri, 11 Sep 2020 18:35:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Sorcerer’s Apprentice Guide to Training LSTMs]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24445617">thread link</a>) | @nshr
<br/>
September 11, 2020 | https://www.niklasschmidinger.com/posts/2020-09-09-lstm-tricks/ | <a href="https://web.archive.org/web/*/https://www.niklasschmidinger.com/posts/2020-09-09-lstm-tricks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<nav id="TOC">
<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#vanilla-lstm">Vanilla LSTM</a>
<ul>
<li><a href="#input-activation-functions-and-the-drift-effect">Input Activation Functions and the Drift Effect</a></li>
<li><a href="#forget-gates-and-vanishing-gradients">Forget Gates and Vanishing Gradients</a></li>
</ul></li>
<li><a href="#focused-lstm">Focused LSTM</a></li>
<li><a href="#lightweight-lstm">Lightweight LSTM</a></li>
<li><a href="#ticker-steps">Ticker Steps</a></li>
<li><a href="#negative-gate-biases">Negative gate biases</a></li>
<li><a href="#scaled-activation-functions">Scaled activation functions</a></li>
<li><a href="#linear-activation-functions">Linear activation functions</a></li>
<li><a href="#time-awareness">Time Awareness</a></li>
<li><a href="#separation-of-memory-and-compute">Separation of Memory and Compute</a></li>
<li><a href="#chicken-and-egg-online-learning-and-more-cells-than-necessary">Chicken and Egg, online learning and more cells than necessary</a></li>
<li><a href="#sequence-classification-vs.-continuous-prediction">Sequence classification vs.&nbsp;continuous prediction</a>
<ul>
<li><a href="#parallel-lstm-networks-for-continuous-prediction">Parallel LSTM networks for continuous prediction</a></li>
</ul></li>
<li><a href="#target-and-input-scaling">Target and input scaling</a></li>
</ul>
</nav>
<hr>
<h2 id="introduction">Introduction</h2>
<div data-layout="l-body">
<div><p><span id="fig:sorcerer"></span>
<img src="https://www.niklasschmidinger.com/posts/2020-09-09-lstm-tricks/images/zauberlehrling.png" alt="The sorcerer's apprentice. Illustration by Ferdinand Barth circa 1882." width="400"></p><p>
Figure 1: The sorcerer’s apprentice. Illustration by Ferdinand Barth circa 1882.
</p>
</div>
</div>
<blockquote>
<div><p>Gone’s for once the old magician<br> With his countenance forbidding;<br> I ’m now master,<br> I ’m tactician,<br> All his ghosts must do my bidding.<br> Know his incantation,<br> Spell and gestures too;<br> By my mind’s creation<br> Wonders shall I do.</p><p>  – Johann Wolfgang von Goethe (The sorcerer’s apprentice)</p></div>
</blockquote>
<p>While mulling over old papers and hacking away at their computers, scholars build up an intimate knowledge about their research topic. As they chart their way through idea space, they develop a deep intuition on which techniques work well in practice. Unfortunately, many of these hard-earned insights are not published and remain obscure.</p>
<p>Last year, I took a course at the Johannes Kepler University in Linz, Austria on the topic of Recurrent Neural Networks and Long Short-Term Memory Networks. There, Sepp Hochreiter shared some of the “magic tricks” he and his team employ for training LSTMs. This blog post is the accumulation of some of my notes.</p>
<p>For this post, I assume you are already familiar with LSTMs. If not, I suggest you begin with Chris Olah’s <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">Understanding LSTM Networks</a> and then go on to read the original LSTM work <span data-cites="hochreiter1997long">(Hochreiter and Schmidhuber <a href="#ref-hochreiter1997long" role="doc-biblioref">1997</a>)</span>.</p>
<p>Before we begin, I’d also like to highlight some resources that are similar in their motivation:</p>
<ul>
<li>Andrej Karpathy’s <a href="http://karpathy.github.io/2019/04/25/recipe/">general recipe for training neural networks</a>.</li>
<li>Danijar Hafner’s tips for training recurrent neural networks <span data-cites="hafner2017rnntips">(Hafner <a href="#ref-hafner2017rnntips" role="doc-biblioref">2017</a>)</span>.</li>
<li>LSTM: A Search Space Odyssey <span data-cites="Greff_2017">(Greff et al. <a href="#ref-Greff_2017" role="doc-biblioref">2017</a>)</span> from IDSIA (Dalle Molle Institute for Artificial Intelligence).</li>
</ul>
<p>In case you want to experiment with some of the presented techniques and you need a flexible Pytorch-based LSTM implementation, I recommend Michael Widrich’s <a href="https://github.com/widmi/widis-lstm-tools">LSTM Tools library</a>.</p>
<p>All credits for the presented techniques go to the authors. All errors in their presentation are mine. I am always keen to receive feedback.</p>
<h2 id="vanilla-lstm">Vanilla LSTM</h2>
<p>The <em>Vanilla LSTM</em> is one of the most prevalent variants and is often the default LSTM architecture in popular software libraries. It is characterized by three gates and a memory state – the gates provide the model with capacity and protect the memory cells from distracting information and noise; they make the dynamics of the LSTM highly non-linear and allow it to learn to perform complex operations.</p>
<p>Let us briefly step through the Vanilla LSTM’s mechanics to introduce the notation and terminology used in this post. Sensory inputs <span>\(\boldsymbol{x}(t)\)</span> flowing into the LSTM cell at a given time step are transformed into the <em>cell input activation</em> <span>\(\boldsymbol{z}(t)\)</span> – the elements of <span>\(\boldsymbol{z}(t)\)</span> are activated by a non-linear function <span>\(g(\cdot)\)</span>, which in practice is often defined as the <em>hyperbolic tangent</em> or <em>tanh</em>. Information that is irrelevant for the current time step is removed by multiplying <span>\(\boldsymbol{z}(t)\)</span> element-wise by a sigmoid-activated <em>input gate</em> <span>\(\boldsymbol{i}(t)\)</span>. Similarily, the <em>cell state</em> of the previous time step <span>\(\boldsymbol{c}(t-1)\)</span> is partially erased using a sigmoid-activated <em>forget gate</em> <span>\(\boldsymbol{f}(t)\)</span>. The new memory cell state <span>\(\boldsymbol{c}(t)\)</span> is computed by adding the current cell state update <span>\(\boldsymbol{i}(t) \odot \boldsymbol{z}(t)\)</span> to the the filtered old state <span>\(\boldsymbol{f}(t) \odot \boldsymbol{c}(t-1)\)</span>. Finally, the LSTM squashes the memory contents into a specific numerical range using the <em>memory cell activation function</em> <span>\(h(\cdot)\)</span> and filters the result through an <em>output gate</em> <span>\(\boldsymbol{o}(t)\)</span>. This results in the final <em>memory cell state activation</em> <span>\(\boldsymbol{y}(t)\)</span>.</p>
<p>Mathematically, the Vanilla LSTM can be defined by the following set of equations:</p>
<p><span>\[
\begin{align}
\boldsymbol{i}(t) &amp;= \sigma\left(\boldsymbol{W}_{i}^{\top} \boldsymbol{x}(t)+\boldsymbol{R}_{i}^{\top} \boldsymbol{y}(t-1)\right) \\
\boldsymbol{o}(t) &amp;= \sigma\left(\boldsymbol{W}_{o}^{\top} \boldsymbol{x}(t)+\boldsymbol{R}_{o}^{\top} \boldsymbol{y}(t-1)\right) \\
\boldsymbol{f}(t) &amp;= \sigma\left(\boldsymbol{W}_{f}^{\top} \boldsymbol{x}(t)+\boldsymbol{R}_{f}^{\top} \boldsymbol{y}(t-1)\right)  \\
\boldsymbol{z}(t) &amp;= g\left(\boldsymbol{W}_{z}^{\top} \boldsymbol{x}(t)+\boldsymbol{R}_{z}^{\top} \boldsymbol{y}(t-1)\right) \\
\boldsymbol{c}(t) &amp;= \boldsymbol{f}(t) \odot \boldsymbol{c}(t-1)+\boldsymbol{i}(t) \odot \boldsymbol{z}(t) \\
\boldsymbol{y}(t) &amp;= \boldsymbol{o}(t) \odot h(\boldsymbol{c}(t))
\end{align}
\]</span></p>
<p>Where <span>\(\sigma\)</span> denotes the sigmoid activation function and <span>\(\odot\)</span> the element-wise or Hadamard product. Note that each of the gates has access to the current input <span>\(\boldsymbol{x}(t)\)</span> and the previous cell state activation <span>\(\boldsymbol{y}(t-1)\)</span>.</p>
<p>Also remember, that the weights <span>\(W\)</span> and recurrent weights <span>\(R\)</span> are shared between time steps.</p>
<div data-layout="l-body">
<div><p><span id="fig:vanilla"></span>
<img src="https://www.niklasschmidinger.com/posts/2020-09-09-lstm-tricks/images/vanilla_lstm_legend.png" alt="Schematic of the Vanilla LSTM Cell with unrolled cell state. Figure adopted from [@Greff_2017]." width="1190"></p><p>
Figure 2: Schematic of the Vanilla LSTM Cell with unrolled cell state. Figure adopted from <span data-cites="Greff_2017">(Greff et al. <a href="#ref-Greff_2017" role="doc-biblioref">2017</a>)</span>.
</p>
</div>
</div>
<h3 id="input-activation-functions-and-the-drift-effect">Input Activation Functions and the Drift Effect</h3>
<p>In practice, the input activation function <span>\(g\)</span> is often chosen to be tanh. But this choice is non-obvious and in fact, in the original LSTM paper sigmoid was used to activate <span>\(\boldsymbol{z}\)</span>. As the memory cell’s purpose is to learn and memorise patterns over time, sigmoid activations are a natural choice to indicate the presence (activation with a value close to <span>\(1\)</span>) or absence (activation with a value close to <span>\(0\)</span>) of entities in the input. Tanh on the other hand with a lower bound of <span>\(-1\)</span> doesn’t seem to make intuitive sense. What is a negative pattern? Does an activation with value <span>\(-1\)</span> indicate that something is strongly not present in the input?</p>
<p>The adoption of tanh first required two mental shifts. First, tanh makes intuitive sense in a meta-learning setting. Instead of patterns, we now use memory cells to store the weights for another neural network. To indicate whether the values of the weights should be increased or decreased we need both positive and negative values.</p>
<p>The second intuitive interpretation is the storage of <em>hints</em>. A hint in this context is evidence in favour of or against something. Consider an example from text analysis. Assume that a model encounters the words “Team”, “Player” and “Goal” in a paragraph. These are all strong hints that the text is about sports, but if the next passage includes the words “Manager”, “Revenue” and “Shareholder” it is a strong indication that the paragraph actually describes a business context. Positive values can be seen as hints in favour of and negative values as hints against certain classes.</p>
<p>But there is a simple mathematical reason why tanh is the preferred choice to activate the cell input. Compared to commonly used activation functions such as ReLU and sigmoid the expected value of the cell input activation is zero for tanh (under the assumption of zero-mean Gaussian pre-activations):</p>
<p><span>\[\mathbb{E}(\boldsymbol{z}(t)) = 0\]</span></p>
<p>To understand why this property is desirable, remember how the cell state is updated at a given time step<a href="#fn1" id="fnref1" role="doc-noteref"><sup>1</sup></a>:</p>
<p><span>\[\boldsymbol{c}(t) = \boldsymbol{c}(t-1)\color{#9900ff}{+\boldsymbol{i}(t) \odot \boldsymbol{z}(t)}\]</span></p>
<p>At each time step we add the cell input activation <span>\(\boldsymbol{z}(t)\)</span> (filtered by the input gate) to the previous cell state <span>\(\boldsymbol{c}(t-1)\)</span>. If we choose an activation function for <span>\(\boldsymbol{z}\)</span>, such that each activation has a value <span>\(\geq 0\)</span> (e.g.&nbsp;sigmoid, ReLU, etc.), <span>\(\boldsymbol{c}\)</span> will quickly take on very large values. Even if the activations are relatively small, the cell state will grow large for sufficiently long sequences. This problem is known as the <em>drift effect</em>.</p>
<p>But how can large memory cell states become a hindrance to learning? To answer this question, we need to take a look at the LSTM’s backward pass:</p>
<p><span>\[
\begin{aligned}
\frac{\partial L}{\partial \boldsymbol{c}(t)} &amp;=\frac{\partial L}{\partial \boldsymbol{y}(t)} \color{#9900ff}{\frac{\partial \boldsymbol{y}(t)}{\partial \boldsymbol{c}(t)}}+\frac{\partial L}{\partial \boldsymbol{c}(t+1)} \frac{\partial \boldsymbol{c}(t+1)}{\partial \boldsymbol{c}(t)} \\
&amp;=\frac{\partial L}{\partial \boldsymbol{y}(t)} \operatorname{diag}\left(\boldsymbol{o}(t) \odot \color{#9900ff}{h^{\prime}(\boldsymbol{c}(t))}\right)+\frac{\partial L}{\partial \boldsymbol{c}(t+1)}
\end{aligned}
\]</span></p>
<p>The equation recursively sums up all error signals from the future and carries them backwards in time. Intuitively, it describes the different ways in which the cell state at time <span>\(t\)</span> influences the loss <span>\(L\)</span>. We take a closer look at the highlighted term <span>\(\partial \boldsymbol{y}(t) / \partial \boldsymbol{c}(t)\)</span> , which describes how the memory cell state activation <span>\(\boldsymbol{y}(t)\)</span> changes as <span>\(\boldsymbol{c}(t)\)</span> changes. The partial derivative can be obtained by calculating <span>\(\operatorname{diag}\left(\boldsymbol{o}(t) \odot h^{\prime}(\boldsymbol{c}(t))\right)\)</span>. And now we are in trouble. Remember that we use the tanh as the memory cell activation function <span>\(h\)</span> to squash the memory cell state into the numerical range <span>\((-1, 1)\)</span>. Its derivative is defined as follows:</p>
<p><span>\[
h^{\prime}(\boldsymbol{x}) = \text{tanh}^{\prime}(\boldsymbol{\boldsymbol{x}}) = 1 - \text{tanh}²(\boldsymbol{x})
\]</span></p>
<p>Now if <span>\(\boldsymbol{c}(t)\)</span> grows very large due to the drift effect, the highlighted term in the second equation will evaluate to <span>\(h^{\prime}(\boldsymbol{c}(t)) = 1-1 = 0\)</span> for each element in <span>\(\boldsymbol{c}(t)\)</span>. As a result, <span>\(\frac{\partial L}{\partial y(t)} \frac{\partial y(t)}{\partial c(t)}\)</span> will be zero and the cell state loses its ability to influence …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.niklasschmidinger.com/posts/2020-09-09-lstm-tricks/">https://www.niklasschmidinger.com/posts/2020-09-09-lstm-tricks/</a></em></p>]]>
            </description>
            <link>https://www.niklasschmidinger.com/posts/2020-09-09-lstm-tricks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24445617</guid>
            <pubDate>Fri, 11 Sep 2020 18:11:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Arbol, a parametric weather risk platform built on IPFS]]>
            </title>
            <description>
<![CDATA[
Score 52 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24445508">thread link</a>) | @jschilling
<br/>
September 11, 2020 | https://docs.ipfs.io/concepts/case-study-arbol/ | <a href="https://web.archive.org/web/*/https://docs.ipfs.io/concepts/case-study-arbol/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-v-4f5abb4a=""> <div><p><strong>"When it comes to data security versus ease of access, it's usually a trade-off. The fact that IPFS doesn't compromise on either is awesome — and it feels great to ditch Amazon S3 buckets for open source."</strong></p> <p><em>— Ben Andre, CTO, Arbol</em></p></div> <h2 id="overview"><a href="#overview">#</a> Overview</h2> <p><img src="https://docs.ipfs.io/assets/img/logo-arbol.e1ca2350.svg" alt="Arbol logo" width="220"></p> <p><a href="https://www.arbolmarket.com/" target="_blank" rel="noopener noreferrer">Arbol</a> is a software platform that connects agricultural entities like farmers and other weather-dependent parties with investors and other capital providers to insure and protect against weather-related risks. Arbol's platform sells contracts for parametric weather protection agreements in a marketplace that's an innovative, data-driven approach to risk management, cutting out the usual legacy insurance claims process of making loss assessments on the ground. Instead, Arbol relies on tamper-proof data indexes to determine payouts, and doesn't require a defined loss to be indemnified. Arbol's platform combines parametric weather protection with blockchain-based smart contracts to provide cost-efficient, automated, and user-defined weather-related risk hedging. As with traditional crop insurance and similar legacy products, end users purchase assurance that they'll be financially protected in the case of adverse weather — but with Arbol, these end users are paid automatically if adverse conditions occur, as defined by the contract and measured by local meteorological observations tracked by Arbol's data sources.</p> <p>To build the data indexes that Arbol uses to handle its contracts, the team aggregates and standardizes billions of data files comprising decades of weather information from a wide range of reputable sources — all of which is stored on IPFS. IPFS is critical to Arbol's service model due to the inherent verifiability provided by its <a href="https://docs.ipfs.io/concepts/content-addressing">content-addressed architecture</a>, as well as a decentralized data delivery model that facilitates Arbol's day-to-day aggregation, synchronization, and distribution of massive amounts of data.</p> <p>While United States agribusiness has been Arbol's initial area of focus, the team has built a globally capable platform, with expansion underway to new regions and industries around the world. Arbol currently provides contracts for managing the risks of weather exposure in the energy and agriculture sectors, and features both custom and pre-designed protection agreements for clients across industries and scale. Their current end-user base ranges from small coffee farms to major agribusinesses and power producers.</p> <p>In short, Arbol's platform is a risk marketplace where end users can get competitively priced risk management solutions and capital providers can benefit from access to a lucrative, but underdeveloped, weather risk market. And because Arbol uses IPFS for its data storage and delivery needs, end users and underwriting partners can be certain that the data Arbol uses to determine price and payouts for contracts is tamper-proof and trustworthy.</p> <h3 id="arbol-by-the-numbers"><a href="#arbol-by-the-numbers">#</a> Arbol by the numbers</h3> <div><div><p>1T</p> <p>weather-related data points hosted on IPFS</p></div><div><p>1M</p> <p>hashes generated on Arbol data every day</p></div><div><p>40</p> <p>years of high-resolution climate data</p></div><div><p>200GB</p> <p>average Arbol dataset size</p></div></div> <h2 id="the-story"><a href="#the-story">#</a> The story</h2> <p>Arbol's story begins with the commodities markets, where Siddhartha Jha, the founder and CEO, worked as a quantitative analyst and portfolio manager. What Jha saw there was a problem without a solution: Massive (and growing) demand for weather risk management for supply chains, farming industries, and the energy sector, but no viable, efficient, or cost-effective weather risk market to meet that demand. Traditional crop insurance was plagued by inefficiencies and high cost ceilings, with insurance providers forced to charge high premiums that only large corporations could afford. And while more efficient parametric insurance solutions were available on the market, even these data-driven options were often saddled with high overhead and bureaucratic waste. As a result, small businesses and local farmers were often trapped without access to protection from weather-related risks.</p> <p>Arbol aims to change that by bringing fundamental transparency, efficiency, and data-driven objectivity to the weather risk market, ensuring that any business of any size can get the appropriate protection they need to manage their level of weather-related risk. The Arbol platform achieves this goal by providing a novel mechanism for weather-exposed businesses to connect with capital providers. The key to Arbol's approach is flexible financial derivatives that leverage the power of big data and machine learning to provide parametric risk protection at low cost. These parametric structures determine automatic payouts based on metrics that are strongly correlated with financial loss.</p> <p>With Arbol, an end user pays to hedge against a specific weather-related event, such as yearly deviation in rainfall amounts or temperature. After deciding on a premium and selecting a payout amount, the end user then relies on Arbol's platform to handle the rest. Because parametric structures are objective and data-driven, they can achieve a level of precision, reliability, and cost effectiveness that traditional insurance cannot. In fact, one of Arbol's key benefits over legacy weather insurance is that it allows for hyper-local protection for managing user-specific levels of risk.</p> <p>Arbol's approach also improves upon standard parametric insurance by combining parametric insurance's precision and flexibility with the security, transparency, and efficiency of blockchain. Many of Arbol's protection agreement contracts are executed as smart contracts on the Ethereum blockchain. These smart contracts automatically deliver payouts to end users as soon as a relevant adverse weather event occurs.</p> <p>Delivering weather risk management solutions through blockchain-based contracts like this eliminates costly payout delays, as well as risks associated with fraud, corruption, and bureaucratic overhead. It also brings the benefits of peer-to-peer decentralization: Arbol users don't need to rely on Arbol as a financial middleman, because funds are locked between end users and capital providers without Arbol controlling the transfer of funds.</p> <p>However, even the best smart contract is only as smart as the data it draws from. The "oracle problem" can be a foundational obstacle for smart contracts — but Arbol's use of IPFS eliminates this risk. Because a smart contract automatically and trustlessly executes based on data, it doesn't matter how secure, transparent, and publicly verifiable its use of blockchain is. Without an accurate, trustworth, and immutable data "oracle", even blockchain-based smart contracts can be easily biased, compromised, or manipulated. For Arbol, that's where IPFS is absolutely critical.</p> <p>IPFS's content-addressed architecture enables Arbol to ensure the integrity and public verifiability of its datasets, something that traditional location addressing using centralized server architecture cannot provide. Smart contracts pointing to specific, immutable IPFS CIDs, rather than to data locations that could be tampered with, can be relied upon thanks to the integrity of their oracle.</p> <div><p><strong>"IPFS is very much at the heart of everything we do at Arbol. IPFS serves as our independently verifiable data store for all of the weather data associated with the contracts we sell. It imbues our platform with the essential principles of decentralization, data security, and public verifiability."</strong></p> <p><em>— Ben Andre, CTO, Arbol</em></p></div> <p>Arbol builds its data indexes by drawing on large weather-related datasets from a variety of trusted public and private sources, including prominent U.S. government institutions such as NASA and the National Oceanic and Atmospheric Administration (NOAA). These sources track weather data including yearly rainfall amounts, temperature fluctuations, wind speeds, and more. However, while much of the data Arbol uses is publicly available, it isn't always easily usable; much of the data, particularly deeper historical records, is stored in outdated formats, and very little of it is organized into an easily readable structure. Arbol's data indexes process, correlate, and package this data so that it is readily available for use in the weather risk market. And by putting that data onto IPFS, Arbol also ensures that it has a verifiable, tamper-resistant, and decentralized home.</p> <h2 id="ipfs-benefits"><a href="#ipfs-benefits">#</a> IPFS benefits</h2> <p>Arbol's business model hinges upon the benefits afforded by IPFS — without its immutable content addressing and inherent data verifiability, the benefits Arbol provides would be impossible to achieve in a cost-effective and efficient way. As a whole, IPFS is critical to Arbol's service model by providing the following:</p> <ul><li><p><strong>Immutable addressing:</strong> Because all data stored using IPFS is referenced and accessed via unique <a href="https://docs.ipfs.io/concepts/content-addressing">content identifiers (CIDs)</a>, any change to a data item means it receives a new CID exclusive to that revision. It's impossible to change data without changing its CID.</p></li> <li><p><strong>Data verifiability:</strong> Contracts on Arbol's platform are linked to specific, verifiably unchanged, content-addressed data. Because parametric weather risk management absolutely relies on user agreement about and trust in source data, Arbol's approach offers reassurance unavailable with other offerings in the market.</p></li> <li><p><strong>Decentralized data delivery:</strong> Arbol works with massive datasets comprising billions of files and terabytes of information. IPFS accommodates Arbol's methodology for publishing and adding to large datasets while still enabling Arbol to release and synchronize these datasets via a decentralized storage network.</p></li></ul> <h2 id="how-arbol-uses-ipfs"><a href="#how-arbol-uses-ipfs">#</a> How Arbol uses IPFS</h2> <p>Arbol's end users enjoy the "it just works" benefits of parametric protection, but a lot goes on behind the scenes to enable this data-driven solution. Arbol's weather datasets range from 1GB to 1TB in size, and each one goes through a detailed ingestion process before it can be used. Once it has been decided that a dataset meets Arbol's criteria for usefulness and validity, it is time to add it to Arbol's IPFS pipeline, a multi-stage process outlined below.</p> <ol><li><p><strong>Query/release:</strong> If a …</p></li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://docs.ipfs.io/concepts/case-study-arbol/">https://docs.ipfs.io/concepts/case-study-arbol/</a></em></p>]]>
            </description>
            <link>https://docs.ipfs.io/concepts/case-study-arbol/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24445508</guid>
            <pubDate>Fri, 11 Sep 2020 18:03:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Our Firebase Tech Stack]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24445435">thread link</a>) | @gbourne
<br/>
September 11, 2020 | https://www.ayrshare.com/our-firebase-tech-stack/ | <a href="https://web.archive.org/web/*/https://www.ayrshare.com/our-firebase-tech-stack/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-node="5f340663d99e7">
	<div>
		
<p>When we started <a href="https://www.ayrshare.com/">Ayrshare</a> we were keen on using an infrastructure as a service platform and avoid server setup, SSL certs, opening ports, etc. Time to market, right. Amongst the many platforms out there we choose <a href="https://www.firebase.com/">Firebase</a>. It was an easy decision for us since we are very comfortable with Firebase having built, and even sold, apps built upon it. If not Firebase our second choice would have been <a href="https://www.netlify.com/">Netlify</a>.</p>







<h2>Today and Tomorrow Requirements</h2>



<p>The first question we asked was, “What we need today?” If came down to a few criteria:</p>



<ul><li>Authentication, ideally having SSO with the major networks</li><li>Hosting a static single page app (React)</li><li>Hosting a landing page. We generally don’t like to build the landing pages in React.</li><li>A database, preferably noSQL</li><li>Back-end running NodeJS, preferably serverless</li><li>Event tracking, e.g. Google Analytics</li><li>Email service</li><li>Payment service</li></ul>



<p>Second, we asked, “What we might need tomorrow?”</p>



<ul><li>iOS and Android apps</li><li>Mobile app push notifications</li><li>ML (machine learning)</li></ul>







<h2>Our Stack</h2>



<p>We have built on many platform: AWS, Heroku, under our desk (not kidding), and Digital Ocean. We ended up choosing Firebase since it meets a lot of our needs, but certainly not all.</p>



<figure><img width="1024" height="667" src="https://www.ayrshare.com/wp-content/uploads/2020/08/stack3-1-1024x667.png" alt="" srcset="https://www.ayrshare.com/wp-content/uploads/2020/08/stack3-1-1024x667.png 1024w, https://www.ayrshare.com/wp-content/uploads/2020/08/stack3-1-300x195.png 300w, https://www.ayrshare.com/wp-content/uploads/2020/08/stack3-1-768x500.png 768w, https://www.ayrshare.com/wp-content/uploads/2020/08/stack3-1.png 1130w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://www.ayrshare.com/wp-content/uploads/2020/08/stack3-1-1024x667.png" data-srcset="https://www.ayrshare.com/wp-content/uploads/2020/08/stack3-1-1024x667.png 1024w, https://www.ayrshare.com/wp-content/uploads/2020/08/stack3-1-300x195.png 300w, https://www.ayrshare.com/wp-content/uploads/2020/08/stack3-1-768x500.png 768w, https://www.ayrshare.com/wp-content/uploads/2020/08/stack3-1.png 1130w"></figure>







<p>Firebase is a good choice for SPA React hosting and <a href="https://firebase.google.com/docs/firestore">Firestore</a> as a noSQL database. Google Analytics comes built into Firebase. Also, using Firebase’s <a href="https://firebase.google.com/docs/auth/web/firebaseui">authentication UI</a> system allowed us to have a secure registration and login process integrated with major SSO providers like Google, Facebook, and GitHub.</p>



<p>The landing page we built in WordPress hosted on Siteground. There are so many great templates and plugins available for WordPress that we see no reason to recreate the wheel in React. Another option we considered was <a href="https://www.gatsbyjs.org/">Gatsby</a> hosted on separate Firebase project.</p>



<p>Sending emails requires a mail provider and we are accustomed to using Mailgun. Firebase has recently introduced <a href="https://firebase.google.com/products/extensions">Extensions</a>, prebuilt cloud functions. One of our favorite is the <a href="https://www.anothermadworld.com/emailing-with-firebase-trigger-email-extension/">Email Trigger extension</a> that facilitates sending email from your cloud functions.</p>



<p>For a payment system, we choose Stripe. Stripe has a really nice <a href="https://www.npmjs.com/package/stripe">NPM package</a> that makes integration relatively easy.</p>



<p>Finally, we decided right before launch to add a <a href="https://docs.ayrshare.com/rest-api/endpoints/shorten">link shortener,</a> which is very useful when publishing to networks like Twitter that limit the characters. At first we were going to go with bit.ly, but it would soon become more expensive than what we were charging users. We ultimately went with Firebase’s <a href="https://firebase.google.com/products/dynamic-links">Dynamic Links</a>, Google’s replacement for goo.gl. Dynamic Links real power are with mobile apps, but it can also be used as a link shortener if you are willing use the RESTful API calls.</p>







<h3>Firebase Cloud Functions &amp; APIs</h3>



<p>Ayrshare is build as an API first platform, so it is critical to have a robust API system. Building a Cloud Function for each API endpoint is not flexible or secure. However, you can add <a href="https://expressjs.com/">Express</a> to Cloud Function and it is an excellent and battle tested framework to build and expose APIs.</p>



<p>For example, you can add several security and API facilitating packages such as:</p>



<pre><code lang="javascript">const express = require("express");
const cors = require("cors");
const bodyParser = require("body-parser");
const helmet = require("helmet");
const rateLimit = require("express-rate-limit");</code></pre>







<p>If you do add Express, you can add the “app” as an http function and export it.</p>



<pre><code lang="javascript">const app = express();
exports.api = functions.https.onRequest(app);</code></pre>







<p>And then add you typical express functions.</p>



<pre><code lang="javascript">app.get("/fun", (req, res) =&gt; {
  console.log("hello fun");
  return res.send('"Hi fun");
});</code></pre>











<h3>Looking Towards the Future</h3>



<p>In the future we plan on building mobile apps, especially for allowing Instagram posting, and will require push notifications. In previous projects we used <a href="https://firebase.google.com/docs/cloud-messaging">Firebase’s Cloud Messaging</a> (FCM) system and found it easy, reliable, and free!</p>



<p>And if we really look ahead, we want to add some ML analysis on ideal posting times. The current Firebase ML offering doesn’t seem a great fit, but perhaps it will be in the future.</p>
	</div>
</div></div>]]>
            </description>
            <link>https://www.ayrshare.com/our-firebase-tech-stack/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24445435</guid>
            <pubDate>Fri, 11 Sep 2020 17:56:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Million-Dollar, One-Person Businesses]]>
            </title>
            <description>
<![CDATA[
Score 37 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24445220">thread link</a>) | @jger15
<br/>
September 11, 2020 | https://trends.vc/trends-0027-million-dollar-one-person-businesses/ | <a href="https://web.archive.org/web/*/https://trends.vc/trends-0027-million-dollar-one-person-businesses/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content-wrapper">
<div id="content">
<div id="primary">
<main id="main" role="main">
<article id="post-17653" class="page">

<div>
<div><figure><img src="https://trends.vc/wp-content/uploads/2020/08/7-069ffa62548f-1.gif" alt=""></figure></div>
<h2>🔍 Problem</h2>
<p><em>“Build your own dreams, or someone else will hire you to build theirs.”</em></p>
<p>You want <strong>freedom</strong> and <strong>equity</strong>. </p>
<p>You’re willing to work hard. But on your terms.</p>
<h2>💡 Solution</h2>
<p><strong>Leverage</strong>. </p>
<p><em>What do you mean?</em></p>
<figure><table><tbody><tr><td>One-To-Many Channels</td><td><a href="https://www.siteground.com/tutorials/email/protocols-pop3-smtp-imap/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Email</a>, <a href="https://en.wikipedia.org/wiki/Podcast" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Podcasts</a>, <a href="https://www.cloudflare.com/learning/network-layer/internet-protocol/#:~:text=The%20Internet%20Protocol%20(IP)%20is%20a%20protocol%2C%20or%20set,arrive%20at%20the%20correct%20destination.&amp;text=IP%20information%20is%20attached%20to,packets%20to%20the%20right%20place." target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Blogs</a></td></tr><tr><td>Social Networks </td><td><a href="https://twitter.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Twitter</a>, <a href="https://www.youtube.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">YouTube</a>, <a href="https://www.instagram.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Instagram</a></td></tr><tr><td>Paid Demand</td><td><a href="https://ads.google.com/home/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Google Ads</a>, <a href="https://www.facebook.com/business/ads" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Facebook Ads</a>, <a href="https://www.reddit.com/adsregister" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Reddit Ads</a></td></tr><tr><td>Membership Platforms </td><td><a href="https://www.patreon.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Patreon</a>, <a href="https://onlyfans.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">OnlyFans</a>, <a href="https://substack.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Substack</a></td></tr><tr><td>Productized Services</td><td><a href="https://www.manypixels.co/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">ManyPixels</a>, <a href="https://beanninjas.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Bean Ninjas</a>, <a href="https://www.trycatalog.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Catalog</a></td></tr><tr><td>Marketplaces</td><td><a href="https://www.amazon.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Amazon</a>, <a href="https://www.etsy.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Etsy</a>, <a href="https://gumroad.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Gumroad</a></td></tr><tr><td>On-Demand Computing</td><td><a href="https://aws.amazon.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">AWS</a>, <a href="https://www.heroku.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Heroku</a>, <a href="https://www.netlify.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Netlify</a></td></tr><tr><td>No-Code Tools </td><td><a href="https://www.shopify.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Shopify</a>, <a href="https://mailchimp.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Mailchimp</a>, <a href="https://wordpress.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">WordPress</a></td></tr><tr><td>On-Demand Manufacturing</td><td><a href="https://printify.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Printify</a>, <a href="https://www.shapeways.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Shapeways</a>, <a href="https://www.printful.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Printful</a></td></tr><tr><td>Open Source</td><td><a href="https://rubyonrails.org/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Ruby on Rails</a>, <a href="https://laravel.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Laravel</a>, <a href="https://reactjs.org/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">React</a></td></tr><tr><td>APIs</td><td><a href="https://stripe.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Stripe</a>, <a href="https://www.twilio.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Twilio</a>, <a href="https://plaid.com/uk/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Plaid</a></td></tr></tbody></table></figure>
<p>These power <strong>million-dollar, one-person businesses</strong>.</p>
<p>Code, distribution and manufacturing are being <strong>commoditized</strong>. </p>
<p>Build wealth by focusing on what’s scarce.</p>
<h2>📘 Terms</h2>
<p><strong>Million-Dollar Business</strong></p>
<p>Forget revenue.</p>
<p>Ask: “<em>What would the business sell for?</em>“</p>
<p>Use <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.thehartford.com/business-insurance/strategy/selling-a-business/determining-market-value" target="_blank">earnings multiples or discounted cash flows</a>. </p>
<p><strong>One-Person Business</strong></p>
<p>Operated by <strong>one person</strong> <em>or</em> built on a <strong>personal brand</strong>.</p>
<h2>🏁 Players</h2>
<p><strong>People</strong></p>
<ul><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://affordanything.com/" target="_blank">Paula&nbsp;Pant</a> </li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.listennotes.com/podcasts/the-indie-hackers/098-how-to-make-25mm-as-a-FEX5hGsMQ9T/" target="_blank">Adam Wathan</a></li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.forrestfunnell.com/" target="_blank">Forrest Funnell</a></li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://twitter.com/jackbutcher" target="_blank">Jack Butcher</a></li><li><a rel="noreferrer noopener" href="https://www.forbes.com/sites/elainepofeldt/2019/06/30/how-one-student-launched-a-million-dollar-one-woman-bikini-empire/#1da781506814" target="_blank">Ana Gavia</a></li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://twitter.com/vikdug" target="_blank">Vik Duggal</a></li><li><a rel="noreferrer noopener" href="https://levels.io/" target="_blank">Pieter Levels</a></li><li><a rel="noreferrer noopener" href="https://backlinko.com/" target="_blank">Brian Dean</a></li><li><a rel="noreferrer noopener" href="https://jamesclear.com/" target="_blank">James Clear</a></li></ul>
<p><strong>Businesses</strong></p>
<ul><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://readwrite.com/2007/10/29/plentyoffish_one_billion/" target="_blank">PlentyOfFish</a></li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.marketwatch.com/story/3-resolutions-to-transform-your-1-person-business-into-a-1-million-operation-2018-01-02#:~:text=Allen%20Walton%2C%20who%20built%20his,steps%20in%20the%20shipping%20process." target="_blank">Spy Guy</a></li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://closet.tools/" target="_blank">Closet Tools</a></li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://stratechery.com/" target="_blank">Stratechery</a></li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://seothatworks.com/" target="_blank">Backlinko</a></li><li><a rel="noreferrer noopener" href="https://shop.visualizevalue.com/" target="_blank">Visualize Value</a></li><li><a rel="noreferrer noopener" href="https://en.m.wikipedia.org/wiki/The_Million_Dollar_Homepage" target="_blank">The Million Dollar Homepage</a></li><li><a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Silk_Road_(marketplace)" target="_blank">Silk Road</a></li><li><a rel="noreferrer noopener" href="https://park.io/" target="_blank">Park.io</a></li></ul>
<h2>🔮 Predictions</h2>
<ul><li>Services like <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.printful.com/" target="_blank">Printful</a> will <strong>commoditize manufacturing</strong>. Kylie Cosmetics reached <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.forbes.com/sites/natalierobehmed/2019/03/05/at-21-kylie-jenner-becomes-the-youngest-self-made-billionaire-ever/#20049c8d2794" target="_blank">$1 billion</a> with 7 employees using <a rel="noreferrer noopener" href="https://www.instyle.com/news/secret-company-behind-kkw-beauty-and-kylie-cosmetics" target="_blank">SEED Beauty</a>. Most <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://sell.amazon.com/fulfillment-by-amazon.html" target="_blank">FBA</a> sellers slap labels on <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.alibaba.com/Apparel_p3?spm=a2700.9161164.2.1.15924e02eeUOHq" target="_blank">generic products</a>. <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.oberlo.com/" target="_blank">Oberlo</a> takes this further.</li><li>Growth and product skills will<strong> remain valuable</strong>. These are areas of innovation. Unlike accounting.<em> Unless you’re Enron. </em></li></ul>
<h2>☁️ Opportunities</h2>
<ul><li>Develop <strong>high-leverage skills</strong>. Invest, write, entertain, code, sell, market, design. </li><li>Start with <strong>services</strong> to find valuable problems. As a consultant, <a rel="noreferrer noopener" href="https://twitter.com/tylertringas" target="_blank">Tyler Tringas</a> had several clients ask for store locators. He built <a rel="noreferrer noopener" href="https://www.storemapper.com/" target="_blank">Storemapper</a>, sold the business and launched <a rel="noreferrer noopener" href="https://earnestcapital.com/" target="_blank">Earnest Capital</a>. </li><li>Automate, outsource or delegate <strong>non-core</strong> <strong>competencies</strong>. Focus on what’s scarce. As <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://twitter.com/ljin18" target="_blank">Li Jin</a> says, <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://a16z.com/2019/10/08/passion-economy/" target="_blank">monetize your individuality</a>. </li><li><strong>Show</strong> your work. <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://twitter.com/dr/status/1291054987976482817?s=20" target="_blank">Dan Rowden</a>, <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://twitter.com/diannamallen/status/1292861382459883520?s=20" target="_blank">Dianna Allen</a> and <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://twitter.com/levelsio/status/1290068006484099072?s=20" target="_blank">Pieter Levels</a> share progress as they build. Stay top of mind with <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://trends.vc/trends-0015-open-startups/" target="_blank">exhaust data</a>. </li><li>Build a <strong>personal brand </strong>like <a rel="noreferrer noopener" href="https://twitter.com/AffordAnything" target="_blank">Paula Pant</a>, <a rel="noreferrer noopener" href="https://twitter.com/PatFlynn" target="_blank">Pat Flynn</a> or <a rel="noreferrer noopener" href="https://www.sethgodin.com/" target="_blank">Seth Godin</a>. Finding problems, validating products and acquiring customers will be easier.</li></ul>
<h2>🔑 Key Lessons</h2>
<ul><li>Don’t be the best. <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="http://www.game-changer.net/2014/09/15/dont-be-the-best-be-the-only-one/#.Xy9J3hNKh-U" target="_blank">Be the only.</a> There are no <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://en.wikipedia.org/wiki/Comparables" target="_blank">comparables</a> in a <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://seths.blog/2013/09/category-of-one-is-a-choice/" target="_blank">category of one</a>. <a rel="noreferrer noopener" href="https://stratechery.com/about/" target="_blank">Ben Thompson</a>, <a rel="noreferrer noopener" href="https://tim.blog/" target="_blank">Tim Ferriss </a>and <a rel="noreferrer noopener" href="http://podcasts.joerogan.net/" target="_blank">Joe Rogan</a> have <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://twitter.com/tylertringas/status/1291352314029252609?s=20" target="_blank">micro-monopolies</a>. </li><li><strong>Niche</strong>. <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.listennotes.com/podcasts/how-i-built-it/the-importance-of-niching-o8rmWDfh3P2/" target="_blank">Sarah Dunn</a> does SEO for wedding professionals. <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.listennotes.com/podcasts/the-resilient/habits-of-a-million-dollar-F3f-bEBKSue/" target="_blank">Rich Rosen</a> only recruits for 3 types of roles. Use small to your advantage. </li></ul>
<h2>😠 Haters</h2>
<p><em>“Million-dollar, one-person businesses can’t be sold.”</em><br>Have you seen <a href="https://park.io/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Park.io</a>, <a href="https://closet.tools/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Closet Tools</a> or <a href="https://overcast.fm/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Overcast</a>?</p>
<p><em>“How do you value an <strong>unsellable</strong>, service business?”</em><br>You don’t. But for this report, look at single-year net income. </p>
<p><em>“Storemapper had employees.” </em><br>The point of that example was to show you how to use <a rel="noreferrer noopener" href="https://nathanbarry.com/wealth-creation/" target="_blank">Nathan’s ladder</a>. Or <a rel="noreferrer noopener" href="https://robwalling.com/2015/03/26/the-stairstep-approach-to-bootstrapping/" target="_blank">Rob’s stairs</a>.&nbsp;</p>
<p><em>“Code, distribution and manufacturing <strong>will</strong> <strong>not</strong> be commoditized.”<br>All</em> code, distribution and manufacturing will not be. Apple and Tesla are vertically integrated. If it’s a core competency, keep it in-house. <a rel="noreferrer noopener" aria-label="Otherwise outsource (opens in a new tab)" href="https://www.econlib.org/library/Topics/Details/comparativeadvantage.html" target="_blank">Otherwise outsource</a>. </p>
<p><em>“I have one million in <strong>revenue</strong>, so I have a million-dollar business.”</em><br>If you buy $2,000,000 worth of iPhones and sell them for $1,000,000. You also have $1m in revenue. As Lauryn Hill says, “…&nbsp;it ain’t what you cop, it’s about what you keep.”</p>
<p><em>“Some of these people have<strong> teams</strong>.</em>“<br>Joe Rogan and Tim Ferris have teams but they’ve built businesses on <a href="https://trends.vc/trends-0023-personal-brands/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">personal brands</a>. Pieter Levels has a <a href="https://twitter.com/levelsio/status/1105345282873581568?s=20" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">sysadmin</a>. <a href="https://stratechery.com/about/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Ben Thompson</a> has an assistant. <a href="https://twitter.com/elainepofeldt" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Elaine Pofeldt</a> addresses this in her <a href="https://www.goodreads.com/book/show/34915571-the-million-dollar-one-person-business" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">book</a>. Most million-dollar, one-person businesses <a href="https://indypendently.com/grow/what-do-million-dollar-one-person-businesses-have-in-common" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">get help</a>. </p>
<p><em>“Screw this. I love my <strong>job</strong>.”</em><br>That’s all that matters. </p>
<h2>🔗 Links</h2>
<ol><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://twitter.com/DruRly/status/1290726540607664129?s=20" target="_blank">Looking for million-dollar, one-person businesses. Know any?</a> — The thread that started this report. </li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://nav.al/product-media" target="_blank">Product and Media are New Leverage</a> — <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://twitter.com/naval" target="_blank">Naval</a> talks about the role of zero marginal cost products in building wealth.</li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://stewfortier.com/why-you-should-share-your-ideas-online/#one-person-media-companies" target="_blank">One-Person Media Companies</a> — <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://twitter.com/stewfortier" target="_blank">Stew Fortier</a> on why you should share ideas online and how one-person media companies make money. </li></ol>



<hr>
<h3>More Trends</h3>
<ul><li>👥<strong> <a href="https://trends.vc/trends-0030-audience-first-products/">Trends #0030 — Audience-First Products</a></strong></li><li><strong>⚙️ <a href="https://trends.vc/trends-0029-lead-generation/">Trends #0029 — Lead Generation</a></strong></li><li>📦&nbsp; <a href="https://trends.vc/trends-0028-subscription-dtc/"><strong>Trends #0028 — Subscription DTC</strong></a></li><li>🤑&nbsp;<strong><a href="https://trends.vc/trends-0027-million-dollar-one-person-businesses/">Trends #0027 — Million-Dollar, One-Person Businesses</a></strong></li><li>📍&nbsp;<strong><a href="https://trends.vc/trends-0026-drop/">Trends #0026 — Drop Culture</a></strong></li><li>📣&nbsp;<strong><a href="https://trends.vc/trends-0025-referral-programs/">Trends #0025 — Referral Programs</a></strong></li><li>🏟️<strong>&nbsp;<a href="https://trends.vc/trends-0024-equity-crowdfunding/">Trends #0024 — Equity Crowdfunding</a></strong></li><li>🤩&nbsp;<strong><a href="https://trends.vc/trends-0023-personal-brands/">Trends #0023 — Personal Brands</a></strong></li><li>💻&nbsp;<a href="https://trends.vc/trends-0022-digital-products/"><strong>Trends #0022 — Digital Products</strong></a></li><li>🕹️ <strong><a href="https://trends.vc/trends-0021-gamification/">Trends #0021 — Gamification</a></strong></li><li>🙏<strong>&nbsp;<a href="https://trends.vc/trends-0020-b-corps/">Trends #0020 — B Corps</a></strong></li><li><strong>🥾&nbsp;<a href="https://trends.vc/trends-0019-bootstrap-funds/">Trends #0019 — Bootstrap Funds</a></strong></li><li>😇<strong>&nbsp;<a href="https://trends.vc/trends-0018-angel-investing/">Trends #0018 — Angel Investing</a></strong></li><li><strong>🛠️&nbsp;<a href="https://trends.vc/trends-0017-xaas-anything-as-a-service/">Trends #0017 — XaaS: Anything as a Service</a></strong></li><li><strong><a href="https://trends.vc/trends-0016-growth-tools/">🧰&nbsp;Trends #0016 — Growth Tools</a></strong></li><li><strong>📖&nbsp;<a href="https://trends.vc/trends-0015-open-startups/">Trends #0015 — Open Startups</a></strong></li><li>💬 <strong><a href="https://trends.vc/trends-0014-paid-communities/">Trends #0014 — Paid Communities</a></strong></li><li>🍎 <strong><a href="https://trends.vc/trends-0013-online-courses/">Trends #0013 — Online Courses</a></strong></li><li>💰 <strong><a href="https://trends.vc/trends-0012-micro-private-equity/">Trends #0012 — Micro Private Equity</a></strong></li><li>💌<strong>&nbsp;<a href="https://trends.vc/trends-0011-paid-newsletters/">Trends #0011 — Paid Newsletters</a></strong></li><li><strong>🦄 <a href="https://trends.vc/trends-0010-startup-studios/">Trends #0010 — Startup Studios</a></strong></li><li>🌐 <strong>&nbsp;<a href="https://trends.vc/trends-0009-virtual-meetups/">Trends #0009 — Virtual Meetups</a></strong></li><li>🏋️<strong>&nbsp;<a href="https://trends.vc/trends-0008-remote-fitness/">Trends #0008 — Remote Fitness</a></strong></li><li>🦠 <strong><a href="https://trends.vc/trends-0007-coronavirus-covid-19/">Trends #0007 — Coronavirus (COVID-19)</a></strong></li><li>🧱 <strong><a href="https://trends.vc/trends-0006-no-code/">Trends #0006 — No Code</a></strong></li><li>🥾&nbsp;<strong><a href="https://trends.vc/trends-0005-bootstrap-funds/">Trends #0005 — Bootstrap Funds</a></strong></li><li>💸&nbsp;<strong><a href="https://trends.vc/trends-0004-income-share-agreements/">Trends #0004 — Income Share Agreements</a></strong></li><li>🏠&nbsp;<strong><a href="https://trends.vc/trends-0003-co-living/">Trends #0003 — Co-Living</a></strong></li><li>🎙️&nbsp;<strong><a href="https://trends.vc/trends-0002-podcast-memberships/">Trends #0002 — Podcast Memberships</a></strong></li><li>🍳 <strong><a href="https://trends.vc/trends-issue-0001-cloud-kitchens/">Trends #0001 — Cloud Kitchens</a></strong></li></ul>

<p><strong>📈 <a href="https://trends.vc/" target="_blank" rel="noreferrer noopener" aria-label="Get weekly reports (opens in a new tab)">Get weekly reports</a></strong></p>

</div>
</article>
</main>
</div>
</div>

</div></div>]]>
            </description>
            <link>https://trends.vc/trends-0027-million-dollar-one-person-businesses/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24445220</guid>
            <pubDate>Fri, 11 Sep 2020 17:37:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Booleans – Guile Hacker Handbook (new chapter)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24445128">thread link</a>) | @rednosehacker
<br/>
September 11, 2020 | https://jeko.frama.io/en/booleans.html | <a href="https://web.archive.org/web/*/https://jeko.frama.io/en/booleans.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
                    
<p>The two boolean values are: "true" and "false". Respectively <code>#t</code> or <code>#true</code> and <code>#f</code> or <code>#false</code> in Guile.</p>
<p>In a conditional test context, "true" means any expression other than <code>#f</code> (or <code>#false</code>).</p>
<p>I invite you to create a new directory in the workspace dedicated to this chapter: <code>~/Workspace/guile-handbook/booleans</code>.</p>
<h2>Write the test first</h2>
<p>Create the file <code>booleans-test.scm</code>&nbsp;:</p>
<pre><code>(use-modules (srfi srfi-64)
             (booleans))

(test-begin "harness")

(test-equal "true-inverted-returns-false"
  #f
  (boolean-invert #t))
  
(test-end "harness")
</code></pre>
<h2>Try and run the test</h2>
<pre><code>guile -L . booleans-test.scm
</code></pre>
<p>Compilation error !</p>
<pre><code>;;; note: auto-compilation is enabled, set GUILE_AUTO_COMPILE=0
;;;       or pass the --no-auto-compile argument to disable.
;;; compiling /home/jeko/Workspace/guile-handbook/booleans/booleans-test.scm
;;; WARNING: compilation of /home/jeko/Workspace/guile-handbook/booleans/booleans-test.scm failed:
;;; no code for module (booleans)
</code></pre>
<h2>Write the minimal amount of code for the test to run and check the failing test output</h2>
<p>Compilation errors can be seen as red tests. In the tradition of TDD, it is essential to add only the bare minimum of code to correct these errors.</p>
<p>Here, the compiler indicates that the <code>booleans</code> module does not exist. I create it to correct this error and immediately restart the test.</p>
<p>Create the file <code>booleans.scm</code>&nbsp;:</p>
<pre><code>(define-module (booleans))
</code></pre>
<p>A new error occurs! This time it compiles, but I'm warned that the <code>boolean-invert</code> variable is not linked (i.e. it is not defined). I add it to my previously created module and re-run the test.</p>
<p>Edit the file <code>booleans.scm</code>&nbsp;:</p>
<pre><code>(define-module (booleans))

(define-public (boolean-invert bool)
  0)
</code></pre>
<p>No more errors or warnings at compile time. The test fails and you can check the reason for the failure in the <code>harness.log</code> report. A quick look confirms that the reason for the failure is that the <code>true-inverted-returns-false</code> test waits for the value <code>#f</code> while the <code>boolean-invert</code> procedure always returns <code>0</code>.</p>
<pre><code>$ cat harness.log 
%%%% Starting test harness
Group begin: harness
Test begin:
  test-name: "true-inverted-returns-false"
  source-file: "booleans-test.scm"
  source-line: 6
  source-form: (test-equal "true-inverted-returns-false" #f (boolean-invert #t))
Test end:
  result-kind: fail
  actual-value: 0
  expected-value: #f
Group end: harness
# of unexpected failures  1
</code></pre>
<h2>Write enough code to make it pass</h2>
<p>I modify the <code>boolean-invert</code> procedure so that it returns the value <code>#f</code> as expected by the test.</p>
<p>Edit the file <code>booleans.scm</code>&nbsp;:</p>
<pre><code>(define-module (booleans))

(define-public (boolean-invert bool)
  #f)
</code></pre>
<p>Running the test displays the following message :</p>
<pre><code>$ guile -L . booleans-test.scm
;;; note: source file /home/jeko/Workspace/guile-handbook/booleans/booleans-test.scm
;;;       newer than compiled /home/jeko/.cache/guile/ccache/3.0-LE-8-4.3/home/jeko/Workspace/guile-handbook/booleans/booleans-test.scm.go
;;; note: auto-compilation is enabled, set GUILE_AUTO_COMPILE=0
;;;       or pass the --no-auto-compile argument to disable.
;;; compiling /home/jeko/Workspace/guile-handbook/booleans/booleans-test.scm
;;; compiled /home/jeko/.cache/guile/ccache/3.0-LE-8-4.3/home/jeko/Workspace/guile-handbook/booleans/booleans-test.scm.go
%%%% Starting test harness  (Writing full log to "harness.log")
# of expected passes      1
</code></pre>
<p>The test passes !</p>
<h2>Refactor</h2>
<p>There's not much to do for so little code.</p>
<h3>Docstrings</h3>
<p>I take this opportunity to tell you about <strong>docstrings</strong>. These strings bring a little explanation to the user if needed:</p>
<ul>
<li>in the REPL, with the command <code>,describe</code>.</li>
<li>in Emacs</li>
</ul>
<p>These are strings placed in second position in the parameter list when defining a variable or a procedure with <code>define</code>, <code>define*</code> or <code>define-public</code> (and so on).</p>
<p>Let's add a <strong>docstring</strong> to the <code>boolean-invert</code> procedure!</p>
<p>Edit the file <code>booleans.scm</code>&nbsp;:</p>
<pre><code>(define-module (booleans))

(define-public (boolean-invert bool)
  "Returns the opposite value of the given boolean."
  #f)
</code></pre>
<h2>Write the test first</h2>
<p>The first test verified that calling the <code>boolean-invert</code> procedure with the <code>#t</code> parameter returns <code>#f</code>. The next test will check the reverse.</p>
<p>Edit the file <code>booleans-test.scm</code>&nbsp;:</p>
<pre><code>(use-modules (srfi srfi-64)
             (booleans))

(test-begin "harness")

(test-equal "true-inverted-returns-false"
  #f
  (boolean-invert #t))
 
(test-equal "false-inverted-returns-true"
  #t
  (boolean-invert #f))
  
(test-end "harness")
</code></pre>
<h2>Try and run the test</h2>
<pre><code>$ guile -L . booleans-test.scm 
</code></pre>
<p>It compiles without any problem!</p>
<h2>Write the minimal amount of code for the test to run and check the failing test output</h2>
<p>You can see the new test failling.</p>
<pre><code>booleans-test.scm:10: FAIL false-inverted-returns-true
</code></pre>
<p>Check that the reason for the failure is the expect one. That is, the <code>false-inverted-returns-true</code> test waits for the value <code>#t</code> but gets <code>#f</code>.</p>
<pre><code>Test begin:
  test-name: "false-inverted-returns-true"
  source-file: "booleans-test.scm"
  source-line: 10
  source-form: (test-equal "false-inverted-returns-true" #t (boolean-invert #f))
Test end:
  result-kind: fail
  actual-value: #f
  expected-value: #t
</code></pre>
<p>This is confirmed.</p>
<h2>Write enough code to make it pass</h2>
<p>Let's add the minimum amount of code required to pass the test:</p>
<pre><code>(define-module (booleans))

(define-public (boolean-invert bool)
  "Returns the opposite value of the given boolean."
  (if bool
      #f
      #t))
</code></pre>
<p>Run the tests again…</p>
<pre><code>%%%% Starting test harness  (Writing full log to "harness.log")
# of expected passes      2
</code></pre>
<p>All clear !</p>
<h2>Refactor</h2>
<p>As you might have guessed, there is a ready-made procedure for inverting a boolean :</p>
<pre><code>(define-module (booleans))

(define-public (boolean-invert bool)
  "Returns the opposite value of the given boolean."
  (not bool))
</code></pre>
<p>I restart the tests one last time to check that this re-machining hasn't broken anything:</p>
<pre><code>%%%% Starting test harness  (Writing full log to "harness.log")
# of expected passes      2
</code></pre>
<p>Done.</p>
<h2>Wrapping up</h2>
<p>What has been covered in this chapter :</p>
<ul>
<li>More TDD practice</li>
<li>Notions about booleans</li>
<li>Write self-documented code thanks to docstrings</li>
</ul>

                </div></div>]]>
            </description>
            <link>https://jeko.frama.io/en/booleans.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24445128</guid>
            <pubDate>Fri, 11 Sep 2020 17:28:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Startup Ideas for Inspiration]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24445058">thread link</a>) | @cameron_b
<br/>
September 11, 2020 | https://blog.pixelswithin.com/startup-ideas-for-inspiration | <a href="https://web.archive.org/web/*/https://blog.pixelswithin.com/startup-ideas-for-inspiration">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    

<div>
  
<p>If you know me, you know I am an idea machine when it comes to fun side projects. Here is a growing collection of all the ideas I’ve had for startups and other ventures. Feel free to take one and run with it! Email me if you do, I’d love to hear about it.</p>
<blockquote data-conversation="none"><p lang="en" dir="ltr">Ok. What about a blog that launches 1 year from today? Various writers assign themselves self-development books and just before launch they write about how their book has impacted their lives in the last year..</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/1166118325362888704?ref_src=twsrc%5Etfw">August 26, 2019</a></blockquote>


<blockquote><p lang="en" dir="ltr">Book playlists 🤔</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/1163926092169662465?ref_src=twsrc%5Etfw">August 20, 2019</a></blockquote>


<blockquote><p lang="en" dir="ltr">I have an idea. An app for cutting down impulse spending. You set a budget, track your impulses, etc.</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/1155683694075473920?ref_src=twsrc%5Etfw">July 29, 2019</a></blockquote>


<blockquote><p lang="en" dir="ltr">I wanna make a .tv website, for like a women in rap VJ thing with YouTube embeds. I'm not going to.</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/1154832435445547008?ref_src=twsrc%5Etfw">July 26, 2019</a></blockquote>


<blockquote><p lang="en" dir="ltr">Idea (something I’d like to see): a series of checklists for everything needed on any page of any website. Home, Pricing, About, etc pages.</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/1150643032523333632?ref_src=twsrc%5Etfw">July 15, 2019</a></blockquote>


<blockquote><p lang="en" dir="ltr">Idea: an AI diary. Conversational, talks back.</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/1139248242661584896?ref_src=twsrc%5Etfw">June 13, 2019</a></blockquote>


<blockquote><p lang="en" dir="ltr">50% of an idea: a Twitter account anyone can post to, via a website with safeguards against abuse, like blocking the “@“ character, authentication, and only allowing one tweet per twit per day. That’s the mechanism, trying to think of a concept.</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/1136103551028027392?ref_src=twsrc%5Etfw">June 5, 2019</a></blockquote>


<blockquote><p lang="en" dir="ltr">Idea! An app for people to hold each other accountable to goals by hosting regular "lotteries." Use the Acorns API to collect round-up investments (you spend $2.19 at the store, the app takes $0.81 to round out to a $3 charge). Only the ones who met their goal are entered to win.</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/1134651648838475776?ref_src=twsrc%5Etfw">June 1, 2019</a></blockquote>


<blockquote><p lang="en" dir="ltr">Idea: a weather app, but instead of the weather it's the emotional climate based on sentiment analysis of your Twitter feed.</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/1134645334066384896?ref_src=twsrc%5Etfw">June 1, 2019</a></blockquote>


<blockquote><p lang="en" dir="ltr">Idea! 🤔 What about customizable posters for forming habits? With 3 months of calendar space to X out days of. <a href="https://t.co/MvkVdSGGTq">pic.twitter.com/MvkVdSGGTq</a></p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/1114924426137456642?ref_src=twsrc%5Etfw">April 7, 2019</a></blockquote>


<blockquote><p lang="en" dir="ltr">Free idea: a forum API. Creating a community on your own website shouldn't be as hard as it is right now.</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/1106627433573158912?ref_src=twsrc%5Etfw">March 15, 2019</a></blockquote>


<blockquote><p lang="en" dir="ltr">app idea 👇🏼 <a href="https://t.co/yC0D3Jwi7n">https://t.co/yC0D3Jwi7n</a></p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/1075097162730528769?ref_src=twsrc%5Etfw">December 18, 2018</a></blockquote>


<blockquote><p lang="en" dir="ltr">app idea (pls take!!!) — create typopgraphic gifs</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/1070978101239136258?ref_src=twsrc%5Etfw">December 7, 2018</a></blockquote>


<blockquote><p lang="en" dir="ltr">IDEA: anarchist video games. Like start the people’s revolution, illegalism, break animals out of a lab, different levels of staging protests, etc etc. Pls, we need the training!</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/1012471453659234305?ref_src=twsrc%5Etfw">June 28, 2018</a></blockquote>


<blockquote><p lang="en" dir="ltr">idea: a tumblr with thought experiments for anxiety... they sure help me</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/811298468971089920?ref_src=twsrc%5Etfw">December 20, 2016</a></blockquote>


<blockquote><p lang="en" dir="ltr">idea: a subscription box for coffee recipes. you get the beans + a fancy recipe + the stuff to make the mintmochafrappelata or whatever!</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/807371501301137408?ref_src=twsrc%5Etfw">December 9, 2016</a></blockquote>


<blockquote><p lang="en" dir="ltr">hm IDEA: blinders for human beans. for focus.</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/799980544784109568?ref_src=twsrc%5Etfw">November 19, 2016</a></blockquote>


<blockquote><p lang="en" dir="ltr">Sister, giving me app ideas: "We have a lot of communication apps. Do we have enough stay-away-from-me apps?"</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/685016694402617344?ref_src=twsrc%5Etfw">January 7, 2016</a></blockquote>


<blockquote><p lang="en" dir="ltr">Idea for Google Maps: a setting where the destination ALWAYS ends up on the right side</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/679476573490135043?ref_src=twsrc%5Etfw">December 23, 2015</a></blockquote>


<blockquote><p lang="en" dir="ltr">Idea: a relatively softer or muted version of your text notification sound, for messages that are just confirmations of receipt.</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/643260554908332032?ref_src=twsrc%5Etfw">September 14, 2015</a></blockquote>


<blockquote><p lang="en" dir="ltr">Good ideas are impressive even in low-fidelity.</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/636251856298078208?ref_src=twsrc%5Etfw">August 25, 2015</a></blockquote>


<blockquote><p lang="en" dir="ltr">"Stop looking at yourself as a designer, and start thinking of yourself as a deliverer of ideas." ~Ståle Melvær</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/634884067960426496?ref_src=twsrc%5Etfw">August 22, 2015</a></blockquote>


<blockquote><p lang="en" dir="ltr">i love ideas. i get carried away with ideas. i get high off ideas.</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/939974857013338112?ref_src=twsrc%5Etfw">December 10, 2017</a></blockquote>




<div id="mlb2-1413518">
<div>
<div>
<div>
<div>
<h4><span>
🎉</span> The end of the post!
</h4>
<p>
Thanks for reading. Ever wonder how effective website design happens? Enter your email to join the weekly newsletter that explores this question.
</p>
</div>

</div>

</div>
</div>
</div>

<p><img src="https://track.mailerlite.com/webforms/o/1413518/g1f8t1?vd890ed88b3a28c805acc70e1a88fa27c" width="1" height="1"></p>
<p><img src="https://blotcdn.com/blog_a19b4b16eb8f413ab70f54145e0e22d6/_image_cache/_image_cache/5a2e65c1-8d54-45f4-9ad0-390945a77183.png" alt="me" width="1822" height="908"></p>
<p>Hi, I’m Diana Lopez! I’m a freelance web designer and developer who works with startups and small businesses. I create memorable &amp; effective websites and brand identities. Interested in learning more? See my portfolio at <a href="https://pixelswithin.com/" target="_blank">pixelswithin.com →</a></p>
</div>

</div></div>]]>
            </description>
            <link>https://blog.pixelswithin.com/startup-ideas-for-inspiration</link>
            <guid isPermaLink="false">hacker-news-small-sites-24445058</guid>
            <pubDate>Fri, 11 Sep 2020 17:23:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How “Go Build” Works]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24444990">thread link</a>) | @grahar64
<br/>
September 11, 2020 | https://maori.geek.nz/how-go-build-works-750bb2ba6d8e | <a href="https://web.archive.org/web/*/https://maori.geek.nz/how-go-build-works-750bb2ba6d8e">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><div><div><div><p><a href="https://maori.geek.nz/@GrahamJenson?source=post_page-----750bb2ba6d8e----------------------" rel="noopener"><img alt="Graham Jenson" src="https://miro.medium.com/fit/c/96/96/0*1bdqD2hM_lzBk_GT.jpeg" width="48" height="48"></a></p></div></div></div></div><p id="a410">How does <code>go build</code> compile the simplest Golang program? This post is here to answer that question.</p><p id="f341">The simplest go program (I can think of) is <code>main.go</code>:</p><pre><span id="54a4">package main</span><span id="1240">func main() {}</span></pre><p id="2a45">If we run <code>go build main.go</code> it outputs an executable <code>main</code> that is 1.1Mb <strong>and does nothing</strong>. What did <code>go build</code> do to do create such a useful binary?</p><p id="ac39"><code>go build</code> has some args that are useful for seeing how it builds:</p><ol><li id="1e0b"><code><strong>-work</strong></code>: <code>go build</code> creates a temporary folder for work files. This arg will print out the location of that folder and not delete it after the build</li><li id="be95"><code><strong>-a</strong></code>: Golang caches previously built packages. <code>-a</code> makes <code>go build</code> ignore the cache so our build will print all steps</li><li id="bcac"><code><strong>-p 1</strong></code>: This sets the concurrency to a single thread to log output linear</li><li id="2751"><code><strong>-x</strong></code>: <code>go build</code> is a wrapper around other Golang tools like <code>compile</code>. <code>-x</code> outputs the commands and arguments that are sent to these tools</li></ol><p id="349d">Running <code>go build -work -a -p 1 -x main.go</code> will output not only the <code>main</code> binary, but <strong>a lot</strong> of logs describing exactly what <code>build</code> did to create <code>main</code>.</p><p id="8eda">The logs starts with:</p><pre><span id="f089">WORK=/var/folders/rw/gtb29xf92fv23f0zqsg42s840000gn/T/go-build940616988</span></pre><p id="6410">This is the work directory whose structure looks like:</p><pre><span id="18c5">├── b001<br>│   ├── _pkg_.a<br>│   ├── exe<br>│   ├── importcfg<br>│   └── importcfg.link<br>├── b002<br>│   └── ...<br>├── b003<br>│   └── ...<br>├── b004<br>│   └── ...<br>├── b006<br>│   └── ...<br>├── b007<br>│   └── ...<br>└── b008<br>    └── ...</span></pre><p id="c081"><strong><em>What are these incrementing directory numbers?</em></strong></p><p id="4f83"><code>go build</code> defines an <a href="https://github.com/golang/go/blob/master/src/cmd/go/internal/work/action.go" target="_blank" rel="noopener">action graph</a> of tasks that need to be completed. Each action in this graph gets its own sub-directory (defined in <code><a href="https://github.com/golang/go/blob/master/src/cmd/go/internal/work/action.go#L318" target="_blank" rel="noopener">NewObjdir</a></code>). The first node <code>b001</code> in the graph is the root task to compile the <code>main</code> binary. Each dependent action has a higher number, the final being <code>b008</code>. (I don’t know where <code>b005</code> went, I assume its ok)</p></div></div></section><hr><section><div><div><p id="9ddc">The first action to be executed is the leaf of the graph, <code>b008</code>:</p><pre><span id="81a6">mkdir -p $WORK/b008/<br>cat &gt;$WORK/b008/importcfg &lt;&lt; 'EOF'<br># import config<br>EOF</span><span id="9961">cd /&lt;..&gt;/src/runtime/internal/sys<br>/&lt;..&gt;/compile <br>  -o $WORK/b008/_pkg_.a <br>  -trimpath "$WORK/b008=&gt;" <br>  -p runtime/internal/sys <br>  -std <br>  -+ <br>  -complete <br>  -buildid gEtYPexVP43wWYWCxFKi/gEtYPexVP43wWYWCxFKi <br>  -goversion go1.14.7 <br>  -D "" <br>  -importcfg $WORK/b008/importcfg <br>  -pack <br>  -c=16 <br>  ./arch.go ./arch_amd64.go ./intrinsics.go ./intrinsics_common.go ./stubs.go ./sys.go ./zgoarch_amd64.go ./zgoos_darwin.go ./zversion.go</span><span id="8d26">/&lt;..&gt;/buildid -w $WORK/b008/_pkg_.a<br>cp $WORK/b008/_pkg_.a /&lt;..&gt;/Caches/go-build/01/01b...60a-d</span></pre><p id="4908">The <code>b008</code> action:</p><ol><li id="b8f4">creates the action directory (<em>all actions do this so I ignore this later on</em>)</li><li id="9ca1">creates the <code>importcfg</code> file to be used by the <code>compile</code> tool (it is empty)</li><li id="c15a">changes the directory to the <code><a href="https://golang.org/pkg/runtime/internal/sys/" target="_blank" rel="noopener">runtime/internal/sys</a></code> packages source folder. This package contains <code>constants used by the runtime</code></li><li id="aba4"><code>compile</code> this package</li><li id="19f9">Use <code>buildid</code> to write (<code>-w</code>) metadata to the package and copy the package to the <code>go-build</code> cache (<em>all packages are cached so I ignore this later on)</em></li></ol><p id="9f31">Let’s break this down the arguments sent to the <code>compile</code> tool (also described in <code>go tool compile --help)</code>:</p><ol><li id="b924"><code>-o</code> is the output file</li><li id="8804"><code>-trimpath</code> this removes the prefix from the source file paths <code>$WORK/b008=&gt;</code> (<em>probably helps with debugging?</em>)</li><li id="1d3d"><code>-p</code> sets the package path used by <code>import</code></li><li id="c90f"><code>-std</code> <code>compiling standard library</code> (<em>not sure what this does</em>)</li><li id="e4bf"><code>-+</code> <code>compiling runtime</code> (<em>another mystery</em>)</li><li id="ae46"><code>-complete</code> the compiler outputs a complete package (no C or assembly).</li><li id="bdd2"><code>-buildid</code> adds build id to the metadata (as <a href="https://github.com/golang/go/blob/master/src/cmd/go/internal/work/buildid.go" target="_blank" rel="noopener">defined here</a>)</li><li id="b355"><code>-goversion</code> required version for compiled package</li><li id="4c7f"><code>-D</code> the relative path for local imports is <code>""</code></li><li id="fc5c"><code>-importcfg</code> import configuration file refers to other packages</li><li id="414d"><code>-pack</code> create package archive (<code>.a</code>) instead of object file (<code>.o</code>)</li><li id="20ee"><code>-c</code> concurrency of the build</li><li id="abd0">finished with a list of files in the package</li></ol><p id="9669"><em>Most of these arguments are the same for all </em><code><em>compile</em></code><em> calls, so I ignore them later.</em></p><p id="fde2">The output of <code><strong>b008</strong></code> is the file <code><strong>$WORK/b008/_pkg_.a</strong></code><strong> </strong>for <code><strong>runtime/internal/sys</strong></code></p></div></div></section><hr><section><div><div><p id="3de5">Let’s dive into <code>buildid</code> for a second.</p><p id="3302">The <strong>buildid</strong> is in the format <code>&lt;actionid&gt;/&lt;contentid&gt;</code>. It is used as an index to cache packages to improve <code>go build</code> performance. The <code>&lt;actionid&gt;</code> is the hash of the action (all calls, arguments, and input files). The <code>&lt;contentid&gt;</code> is a hash of the output <code>.a</code> file. For each <code>go build</code> action, it can look up in the cache for contents created by another action with the same <code>&lt;actionid&gt;</code>. <em>This is implemented in </em><a href="https://github.com/golang/go/blob/master/src/cmd/go/internal/work/buildid.go" target="_blank" rel="noopener"><em>buildid.go</em></a><em>.</em></p><p id="9c9f">The <code>buildid</code> is stored as metadata in the file so that it does not need to be hashed every time to get the <code>&lt;contentid&gt;</code>. You can see this id with <code>go tool buildid &lt;file&gt;</code> (also works on binaries).</p><p id="ab02">In the log of <code>b008</code> above the buildID is being set in by the <code>compile</code> tool as <code>gEtYPexVP43wWYWCxFKi/gEtYPexVP43wWYWCxFKi</code>. This is a just a place holder and is later overwritten with <code>go tool buildid -w</code> to the correct <code>gEtYPexVP43wWYWCxFKi/b-rPboOuD0POrlJWPTEi</code> before being cached.</p></div></div></section><hr><section><div><div><p id="1af8">The next action to be run is <code>b007</code>:</p><pre><span id="879c">cat &gt;$WORK/b007/importcfg &lt;&lt; 'EOF'<br># import config<br>packagefile runtime/internal/sys=$WORK/b008/_pkg_.a<br>EOF<br>cd /&lt;..&gt;/src/runtime/internal/math<br>/&lt;..&gt;/compile <br>  -o $WORK/b007/_pkg_.a <br>  -p runtime/internal/math <br>  -importcfg $WORK/b007/importcfg <br>  ...<br>  ./math.go</span></pre><ol><li id="838a">This writes the <code>importcfg</code> but it includes the line <code>packagefile runtime/internal/sys=$WORK/b008/_pkg_.a</code>. This means <code>b007</code> depends on the output of <code>b008</code></li><li id="0d87"><code>compile</code>’s the <code><a href="https://golang.org/pkg/runtime/internal/math/" target="_blank" rel="noopener">runtime/internal/math</a></code> package. If you inspect <code><a href="https://golang.org/src/runtime/internal/math/math.go" target="_blank" rel="noopener">math.go</a></code>, it has <code>import "runtime/internal/sys"</code> built by <code>b008</code></li></ol><p id="cf96">The output of <code><strong>b007</strong></code> is the file <code><strong>$WORK/b007/_pkg_.a</strong></code><strong> </strong>for <code><strong>runtime/internal/math</strong></code></p></div></div></section><hr><section><div><div><p id="2f2b">The next action is <code>b006</code>:</p><pre><span id="399f">cat &gt;$WORK/b006/go_asm.h &lt;&lt; 'EOF'<br>EOF<br>cd /&lt;..&gt;/src/runtime/internal/atomic<br>/&lt;..&gt;/asm <br>  -I $WORK/b006/ <br>  -I /&lt;..&gt;/go/1.14.7/libexec/pkg/include <br>  -D GOOS_darwin <br>  -D GOARCH_amd64 <br>  -gensymabis <br>  -o $WORK/b006/symabis <br>  ./asm_amd64.s</span><span id="a708">/&lt;..&gt;/asm <br>  -I $WORK/b006/ <br>  -I /&lt;..&gt;/go/1.14.7/libexec/pkg/include <br>  -D GOOS_darwin <br>  -D GOARCH_amd64 <br>  -o $WORK/b006/asm_amd64.o <br>  ./asm_amd64.s</span><span id="4d96">cat &gt;$WORK/b006/importcfg &lt;&lt; 'EOF'<br># import config<br>EOF<br>/&lt;..&gt;/compile <br>  -o $WORK/b006/_pkg_.a <br>  -p runtime/internal/atomic <br>  -symabis $WORK/b006/symabis <br>  -asmhdr $WORK/b006/go_asm.h <br>  -importcfg $WORK/b006/importcfg<br>  ...<br>  ./atomic_amd64.go ./stubs.go</span><span id="75f1">/&lt;..&gt;/pack r $WORK/b006/_pkg_.a $WORK/b006/asm_amd64.o</span></pre><p id="4f05">Here is where we step out of the normal <code>.go</code> files and start dealing with lower level “<a href="https://golang.org/doc/asm" target="_blank" rel="noopener"><strong>Go assembly</strong></a>” <code>.s</code> files. <code>b006</code>:</p><ol><li id="81ea">First this makes the header file <code>go_asm.h</code></li><li id="3cb5">goes to the <code><a href="https://golang.org/pkg/runtime/internal/atomic/" target="_blank" rel="noopener">runtime/internal/atomic</a></code> package (a bunch of low-level functions).</li><li id="06b1">runs the <code><a href="https://golang.org/cmd/asm/" target="_blank" rel="noopener">go tool asm</a></code> tool (described with <code>go tool asm --help</code>) to build the <code>symabis</code> “Symbol Application Binary Interfaces (ABI) file” and then the object file <code>asm_amd64.o</code></li><li id="9cd6">Uses <code>compile</code> create the <code>_pkg_.a</code> file including the <code>symabis</code> file and the header with <code>-asmhdr.</code></li><li id="7347">Uses <code>pack</code> to add the <code>asm_amd64.o</code> object file to <code>_pkg_.a</code> package archive</li></ol><p id="e680">The <code>asm</code> tool is called with the args:</p><ol><li id="3642"><code>-I</code>: include the action <code>b007</code> and <code>includes</code> folders. <code>includes</code> has three files <code>asm_ppc64x.h</code> <code>funcdata.h</code> and <code>textflag.h</code> all having low level function definitions, e.g. <code>FIXED_FRAME defines the size of the fixed part of a stack frame</code></li><li id="8ad3"><code>-D</code>: Adds a predefined symbol</li><li id="17ac"><code>-gensymabis</code>: flag to generate the <code>symabis</code> file</li><li id="9991"><code>-o</code>: The output file</li></ol><p id="851d">The output of <code><strong>b006</strong></code> is <code><strong>$WORK/b006/_pkg_.a</strong></code><strong> </strong>for <code><strong>runtime/internal/atomic</strong></code></p></div></div></section><hr><section><div><div><p id="e1c5">Next is <code>b004</code>:</p><pre><span id="d642">cd /&lt;..&gt;/src/internal/cpu<br>/&lt;..&gt;/asm ... -o $WORK/b004/symabis ./cpu_x86.s</span><span id="e1ae">/&lt;..&gt;/asm ... -o $WORK/b004/cpu_x86.o ./cpu_x86.s</span><span id="3f1b">/&lt;..&gt;/compile ... -o $WORK/b004/_pkg_.a ./cpu.go ./cpu_amd64.go ./cpu_x86.go</span><span id="426e">/&lt;..&gt;/pack r $WORK/b004/_pkg_.a $WORK/b004/cpu_x86.o</span></pre><p id="1205"><code>b004</code> is the same as <code>b006</code> for the package <code><a href="https://golang.org/pkg/internal/cpu/" target="_blank" rel="noopener">internal/cpu</a></code>. First we we assemble the <code>symabis</code> and object files, then compile the go files and pack the <code>.o</code> files into <code>_pkg_.a</code>.</p><p id="a960">The output of <code><strong>b004</strong></code> is <code><strong>$WORK/b004/_pkg_.a</strong></code><strong> </strong>for <code><strong>internal/cpu</strong></code></p></div></div></section><hr><section><div><div><p id="611b">The next action is <code>b003</code></p><pre><span id="6392">cat &gt;$WORK/b003/go_asm.h &lt;&lt; 'EOF'<br>EOF<br>cd /&lt;..&gt;/src/internal/bytealg</span><span id="aeae">/&lt;..&gt;/asm ... -o $WORK/b003/symabis ./compare_amd64.s ./count_amd64.s ./equal_amd64.s ./index_amd64.s ./indexbyte_amd64.s</span><span id="5369">cat &gt;$WORK/b003/importcfg &lt;&lt; 'EOF'<br># import config<br>packagefile internal/cpu=$WORK/b004/_pkg_.a<br>EOF<br>/&lt;..&gt;/compile ... -o $WORK/b003/_pkg_.a -p internal/bytealg ./bytealg.go ./compare_native.go ./count_native.go ./equal_generic.go ./equal_native.go ./index_amd64.go ./index_native.go ./indexbyte_native.go</span><span id="daac">/&lt;..&gt;/asm ... -o $WORK/b003/compare_amd64.o ./compare_amd64.s<br>/&lt;..&gt;/asm ... -o $WORK/b003/count_amd64.o ./count_amd64.s<br>/&lt;..&gt;/asm ... -o $WORK/b003/equal_amd64.o ./equal_amd64.s<br>/&lt;..&gt;/asm ... -o $WORK/b003/index_amd64.o ./index_amd64.s<br>/&lt;..&gt;/asm ... -o $WORK/b003/indexbyte_amd64.o ./indexbyte_amd64.s</span><span id="202d">/&lt;..&gt;/pack r $WORK/b003/_pkg_.a $WORK/b003/compare_amd64.o $WORK/b003/count_amd64.o $WORK/b003/equal_amd64.o $WORK/b003/index_amd64.o $WORK/b003/indexbyte_amd64.o</span></pre><p id="c6cc"><code>b003</code> is the same as the previous actions <code>b004</code> <code>b006</code> for the package <code><a href="https://golang.org/pkg/internal/bytealg/" target="_blank" rel="noopener">internal/bytealg</a></code>. The main complication with this package is that there are multiple <code>.s</code> files to create many <code>.o</code> object files that each need to be added to the <code>_pkg_.a</code> file.</p><p id="a69b">The output of <code><strong>b003</strong></code> is <code><strong>$WORK/b003/_pkg_.a</strong></code><strong> </strong>for <code><strong>internal/bytealg</strong></code></p></div></div></section><hr><section><div><div><p id="04a1">The penultimate action, <code>b002</code>:</p><pre><span id="b243">cat &gt;$WORK/b002/go_asm.h &lt;&lt; 'EOF'<br>EOF<br>cd /&lt;..&gt;/src/runtime<br>/&lt;..&gt;/asm <br>  ... <br>  -o $WORK/b002/symabis <br>  ./asm.s ./asm_amd64.s ./duff_amd64.s ./memclr_amd64.s ./memmove_amd64.s ./preempt_amd64.s ./rt0_darwin_amd64.s ./sys_darwin_amd64.s<p>  cat &gt;$WORK/b002/importcfg &lt;&lt; 'EOF'<br># import config<br>packagefile internal/bytealg=$WORK/b003/_pkg_.a<br>packagefile internal/cpu=$WORK/b004/_pkg_.a<br>packagefile runtime/internal/atomic=$WORK/b006/_pkg_.a<br>packagefile runtime/internal/math=$WORK/b007/_pkg_.a<br>packagefile runtime/internal/sys=$WORK/b008/_pkg_.a<br>EOF</p></span><span id="11b6">/&lt;..&gt;/compile <br>  -o $WORK/b002/_pkg_.a <br>  ...<br>  -p runtime <br>  ./alg.go ./atomic_pointer.go ./cgo.go ./cgocall.go ./cgocallback.go ./cgocheck.go ./chan.go ./checkptr.go ./compiler.go ./complex.go ./cpuflags.go ./cpuflags_amd64.go ./cpuprof.go ./cputicks.go ./debug.go ./debugcall.go ./debuglog.go ./debuglog_off.go ./defs_darwin_amd64.go ./env_posix.go ./error.go ./extern.go ./fastlog2.go ./fastlog2table.go ./float.go ./hash64.go ./heapdump.go ./iface.go ./lfstack.go ./lfstack_64bit.go ./lock_sema.go ./malloc.go ./map.go ./map_fast32.go ./map_fast64.go ./map_faststr.go ./mbarrier.go ./mbitmap.go ./mcache.go ./mcentral.go ./mem_darwin.go ./mfinal.go ./mfixalloc.go ./mgc.go ./mgcmark.go ./mgcscavenge.go ./mgcstack.go …</span></pre></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://maori.geek.nz/how-go-build-works-750bb2ba6d8e">https://maori.geek.nz/how-go-build-works-750bb2ba6d8e</a></em></p>]]>
            </description>
            <link>https://maori.geek.nz/how-go-build-works-750bb2ba6d8e</link>
            <guid isPermaLink="false">hacker-news-small-sites-24444990</guid>
            <pubDate>Fri, 11 Sep 2020 17:18:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Statistical Significance: A Practical Introduction]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24444577">thread link</a>) | @R3G1R
<br/>
September 11, 2020 | https://mathvault.ca/statistical-significance/ | <a href="https://web.archive.org/web/*/https://mathvault.ca/statistical-significance/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><div><div id="theme-content-section"><div><section data-css="tve-u-16ec5d248bb"><figure><img loading="lazy" src="https://mathvault.ca/wp-content/uploads/Statistical-Significance.jpg" alt="A Primer on Statistical Significance" width="800" height="480" title="Statistical Significance"></figure><p><strong>Statistical significance</strong>, in a nutshell, is a way of determining the degree of unlikely-ness of an experimental result — when a certain status quo hypothesis is assumed to be true.<span id="more-9087"></span></p><p>For example, let’s say that a school had two teachers, each with approximately $30$ students in their class. Both classes take a standardized test, and it turns out that the average score in class A was $5\%$ better than the average in class B.&nbsp; Statistical significance — in this regard — would be our way of determining whether the better score in class A could be attributed to <em>random chance</em>, for instance:</p><ul><li>It was a lucky day for class A.</li><li>Class A just randomly got assigned better prepared students.</li></ul><p>Or whether there is some other factor responsible for the difference in grades between the classes,&nbsp;for instance:</p><ul><li>Teacher A did a better job of teaching than teacher B.</li><li>Teacher A cheated a bit and gave the students some answers ahead of time.</li><li>The classes were purposely split up (e.g., more advanced students or native speakers of a language were put into class A).</li></ul><p>Note that in this case, we wouldn’t — using <em>only</em> the information on the scores at least — attempt to decide what the exact reason for the different scores was. Instead, we would just determine if the score difference could be attributed to pure chance, or that it is so unlikely that there might be some other factors involved.</p><h2 id="start"><span id="Getting_Started"></span><a href="#toc">Getting Started</a><span></span></h2><p>There are two important things when calculating statistical significance. The first is the <strong>magnitude of difference</strong> between what you are measuring and what you are comparing against. The second is the amount of <strong>natural variation</strong> in what you are measuring.</p><p>The first concept, magnitude of difference, is easy to understand. Let’s say that you are a farmer growing pumpkins and trying out new fertilizers. You have a <strong>baseline average</strong> pumpkin weight, which is an average of $10$ lbs. You also have pumpkins from two different fertilizers&nbsp;—A and B&nbsp;— that you are testing out.</p><p>If fertilizer A makes pumpkins that weigh $11$ lbs. on average, then it is possible that the $1$ lbs. difference relative to the baseline $10$ lbs. is <em>caused</em> by the fertilizer. However, if fertilizer B produces $25$ lbs. pumpkins on average, then that $15$ lbs. difference ($25-10$) is more likely to be a result of fertilizer B — than the $1$ lbs. difference was to be a result of fertilizer A.</p><h2 id="sse"><span id="Looking_at_the_Statistical_Significance_Equation"></span><a href="#toc">Looking at the Statistical Significance Equation</a><span></span></h2><p>The most commonly used statistical significance test is probably the <a href="https://en.wikipedia.org/wiki/Z-test" target="_blank" rel="noopener noreferrer"><strong>Z-test</strong></a>. The equation for the Z-test is:</p><figure><img loading="lazy" src="https://mathvault.ca/wp-content/uploads/SS1.png" alt="Z-Test Statistics" width="668" height="348" title="SS1"></figure><p>In a nutshell, the Z-Test equation calculates the <em>ratio</em> of two quantities: the numerator on the top, and the denominator at the bottom. Let’s take a look at them individually.</p><h3 id="num"><span id="Numerator"></span><a href="#toc">Numerator</a><span></span></h3><p>The <em>numerator</em> of the equation is where the <strong>magnitude of difference</strong> is accounted for:</p><figure><img loading="lazy" src="https://mathvault.ca/wp-content/uploads/SS2.png" alt="Difference Between Sample Mean and Population Mean" width="400" height="127" title="SS2"></figure><p>Here, $\bar{x}$ stands for the&nbsp;<strong>measured average value</strong> for the data set, &nbsp;while $u_0$ stands for the&nbsp;<strong>baseline average value</strong>. In terms of our&nbsp;example with fertilizer B, the baseline and the measured average would be $10$ lbs and&nbsp;$25$ lbs., respectively, yielding a magnitude of difference of:</p><figure><img loading="lazy" src="https://mathvault.ca/wp-content/uploads/SS3.png" alt="SS3" width="622" height="89" title="SS3"></figure><p>In general,&nbsp;the larger in magnitude the final Z-value is, <em>the more significantly the sample deviates from the baseline average value</em>. In particular, having a numerator of $15$ ($25-10$) is more significant than having a numerator of $1$ ($11-10$) — all&nbsp;other variables&nbsp;being equal.</p><h3 id="de"><span id="Denominator"></span><a href="#toc">Denominator</a><span></span></h3><p>So far, we have only been focusing on&nbsp;the <em>top half</em> of the statistical significance equation. Let’s take&nbsp;a look at the&nbsp;<em>denominator</em> of the equation&nbsp;this time:</p><figure><img loading="lazy" src="https://mathvault.ca/wp-content/uploads/SS4.png" alt="Standard Error of Sample Mean - Amount of Variation in Measured Data" width="600" height="267" title="SS4"></figure><p>Here, $\dfrac{\sigma}{\sqrt{n}}$&nbsp;deals with the amount of variation in our measured data. More specifically,&nbsp;the amount of <em>average deviation</em> in the measured averages themselves — if we were to repeat the sampling process indefinitely.</p><p>After all, you didn’t think that your pumpkins actually all weighted $25$ lbs. did you?&nbsp; Some probably weighted $22$ lbs., and others $27$ lbs.&nbsp; The $25$ lbs. was just an average, and that measured average could change depending on the pumpkins being sampled.</p><h2 id="sd"><span id="Normal_Curve_and_Standard_Deviation"></span><a href="#toc">Normal Curve and Standard Deviation</a><span></span></h2><p>At this point, we need to take a step back and explain what the <a href="https://en.wikipedia.org/wiki/Normal_distribution" target="_blank" rel="noopener noreferrer"><strong>normal curve</strong></a> and <strong>standard deviation</strong> are. Loosely speaking, the normal curve is an approximation of how things occur when they are subjected to <em>aggregated</em>, real life random events. The fact that they are random doesn’t mean that they are <a href="https://mathvault.ca/math-glossary/#arbitrary">arbitrary</a>. As a result, they assume the shape of a <strong>bell curve</strong> as illustrated in the diagram below:<img loading="lazy" src="https://mathvault.ca/wp-content/uploads/SS5.png" alt="Normal Curve (Bell Curve)" width="715" height="510" title="SS5">On&nbsp;a related note, the <a href="https://en.wikipedia.org/wiki/Standard_deviation" target="_blank" rel="noopener noreferrer"><strong>standard deviation</strong></a> is a way of measuring the <em>width</em> of the normal curve, and can be alternately defined as the distance from the center which&nbsp;encloses $68.27\%$ of the area below the normal curve:<img loading="lazy" src="https://mathvault.ca/wp-content/uploads/SS6.png" alt="Normal Curve - 68% of data are 1 standard deviation within the mean" width="624" height="445" title="SS6">Similarly, two standard deviations define the distance from the center which encloses $95.45\%$ of the curve, and three standard deviations $99.73\%$ of the curve:<img loading="lazy" src="https://mathvault.ca/wp-content/uploads/SS7.png" alt="68-95-99 Rule For Normal Distribution" width="715" height="510" title="SS7">For&nbsp;a set of data with a lot of variation, the normal curve will be wide, and hence the standard deviation will be large. This would be the case if you&nbsp;take, say, the weight of $100$ rocks you picked up in your backyard.<img loading="lazy" src="https://mathvault.ca/wp-content/uploads/SS8.png" alt="Normal Distribution with Large Standard Deviation" width="463" height="333" title="SS8">Or there could also be almost no variation in the data,&nbsp;as in the case where&nbsp;you measured the processing speed for each computer chip in a batch.<img loading="lazy" src="https://mathvault.ca/wp-content/uploads/SS9.png" alt="Normal Distribution with Small Standard Deviation" width="460" height="323" title="SS9">Let’s think about another example — this time involving automobiles. Imagine going to a tire store and being informed&nbsp;that the&nbsp;lifespan of new&nbsp;tires&nbsp;is $50,000$ miles on average, with a standard deviation of $5,000$ miles. Using this information, we can construct the&nbsp;<a href="https://mathvault.ca/hub/higher-math/math-symbols/probability-statistics-symbols/#Discrete_Probability_Distributions" target="_blank" rel="noopener noreferrer"><strong>probability distribution</strong></a> of tire lifespan&nbsp;as follows:<img loading="lazy" src="https://mathvault.ca/wp-content/uploads/SS10.png" alt="Tire Life Normal Curve" width="719" height="518" title="SS10">As the graph suggests, we&nbsp;have a $50\%$ chance of being above the average of $50,000$ miles (before needing new tires again), and a $50\%$ chance of being below it. We also know that since two&nbsp;standard deviations correspond to $10,000$ miles (i.e., $5000 \times 2$), we&nbsp;have a $95.45\%$ chance of getting new tires&nbsp;with a mileage between $40,000$ and&nbsp;$60,000$ miles (i.e., two&nbsp;standard deviations within the average):<img loading="lazy" src="https://mathvault.ca/wp-content/uploads/SS11.png" alt="Tire Life Normal Curve - Chance of Between 40,000 and 60,000 miles " width="719" height="518" title="SS11">Now, let’s say that a couple of years later,&nbsp;you’ve driven $55,000$ miles and your tires are in need of replacement. Would you consider&nbsp;that unusual? No, probably not, since that’s only <em>one&nbsp;standard deviation away from the mean&nbsp;</em>— which is&nbsp;well within the typical tire-to-tire variation often seen in the market.</p><p>But now, let’s say that this time you’ve driven $60,000$ miles instead before the tires need replacement. This would be&nbsp;<em>two&nbsp;standard deviations<strong>&nbsp;</strong>above the average</em> — which is well above the lifespans of most new tires. In addition, since two standard deviations above the average correspond to the top $2.28\%$ of the curve $\left( \frac{100\% – 95.45\%}{2}\right)$,&nbsp;it follows&nbsp;that your tires actually lasted longer than $97.72\%$ of all other tires!</p><p>Of course, having a single measurement exceeding $97\%$ of your expected measurements is quite unusual. You have to start thinking, “Maybe there is something different about my situation than the typical installation for the same tires.” For example, it could be that:</p><ul><li>You are just a more cautious driver, and wear down the tires less quickly than the typical person.</li><li>The shop put on better tires than you thought. Maybe you got the next level up by some happy accident.</li><li>The tire company undersells their products a little bit, and it is actually better than they advertised.</li></ul><p>Or it could be that it is just a <em>typical variation</em> — and&nbsp;you happen to stumble upon&nbsp;on the right tail of the curve.</p><h2 id="mm"><span id="Multiple_Measurements"></span><a href="#toc">Multiple Measurements</a><span></span></h2><p>So far, we have seen how the normal curve applies to a single measurement. With a single measurement, it is easy to see where it would fall on the normal curve, but how would your opinion&nbsp;change if you had <strong>multiple measurements </strong>instead?</p><p>Maybe you own a fleet of cars, and you got the same type of tires on each of those cars and those tires lasted, say, $46$, $48$, $53$, $54$, $56$, $56$, $57$, $58$, $60$ and $62$ thousand miles. Do these&nbsp;additional measurements make you more or less inclined to believe that the tires last more than the advertised $50,000$ miles?</p><p>To be sure,&nbsp;we can, and will, plug those numbers in to the equation to determine the verdict. But there is an interesting reason why the equation works the way it does, and the way to understand it&nbsp;— as luck would have it —&nbsp;is to begin with some dice rolling.</p><h2 id="sda"><span id="Standard_Deviation_of_Averages"></span><a href="#toc">Standard Deviation of Averages</a><span></span></h2><p>The key to understanding statistical significance is to realize that you&nbsp;actually&nbsp;don’t care much&nbsp;about the standard deviation of the data. What&nbsp;you really care about is the <strong><a href="https://en.wikipedia.org/wiki/Standard_deviation#Standard_deviation_of_the_mean" target="_blank" rel="noopener noreferrer">standard deviation of averages</a> —</strong>&nbsp;a metric pertaining to&nbsp;<em>samples</em> drawn from the data rather than the data themselves, and which changes as one&nbsp;includes&nbsp;more data into the&nbsp;sample.</p><h3 id="1d"><span id="SingleDie_Rolling"></span><a href="#toc">Single-Die&nbsp;Rolling</a><span></span></h3><p>To see how the standard deviation of averages is related to dice rolling, let’s begin our discussion by first throwing a single die. In this case,&nbsp;you have an <strong>equal probability</strong> of getting&nbsp;a $1$, $2$, $3$, $4$, $5$ or $6$. &nbsp;Here’s the probability distribution of that roll for the record:<img loading="lazy" src="https://mathvault.ca/wp-content/uploads/SS12.png" alt="Distribution of the Number on a Single Die" width="749" height="529" title="SS12">Here, the <strong>average roll</strong> you would get is $3.5$, and the standard deviation of the&nbsp;roll&nbsp;— which is the <a href="https://mathvault.ca/hub/higher-math/math-symbols/probability-statistics-symbols/#Variables" target="_blank" rel="noopener noreferrer"><strong>population standard deviation</strong></a> of the set $\{ 1, 2, 3, 4, 5, 6 \}$ — is $1.7078$. &nbsp;Note that the population standard deviation is just a measure of how spread out a data set is, and that the greater a data point deviates from the average in the data set, the more it increases the standard deviation of the data set.</p><p>In the case of single die rolling, for example,&nbsp;a roll of a $3$ or a $4$ would contribute the least&nbsp;to the standard deviation.&nbsp;A&nbsp;roll of $2$ or $5$ would contribute a bit more, and&nbsp;a&nbsp;roll of $1$ or a $6$ would be the ones contributing the most.</p><h3 id="2d"><span id="TwoDice_Rolling"></span><a href="#toc">Two-Dice Rolling</a><span></span></h3><p>Now, what happens if you roll <em>two</em>&nbsp;dice instead of one, and take the <em>average</em> of those two rolls? &nbsp;For one, you would get $6 \times 6 = 36$ possible outcomes in that case, which correspond to a total of $11$ possible sums&nbsp;— from a sum of $2$ to a sum to $12$.</p><p>But here’s the caveat: those $36$ different possible rolls actually don’t map evenly onto the $11$ possible sums! In fact, the most likely …</p></section></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mathvault.ca/statistical-significance/">https://mathvault.ca/statistical-significance/</a></em></p>]]>
            </description>
            <link>https://mathvault.ca/statistical-significance/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24444577</guid>
            <pubDate>Fri, 11 Sep 2020 16:43:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reached 1001 PH upvotes without getting any batch – Our learnings]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24444567">thread link</a>) | @Michael_Sieb
<br/>
September 11, 2020 | https://blog.typestudio.co/product-hunt-learnings/ | <a href="https://web.archive.org/web/*/https://blog.typestudio.co/product-hunt-learnings/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              
              <p>On 07.07 we launched Type Studio for the first time on the platform <strong><a href="https://www.producthunt.com/posts/type-studio">Product Hunt</a></strong>. For all who don't know Product Hunt yet. The platform describes itself as:</p><p>"Product Hunt surfaces the best new products, every day. It's a place for product-loving enthusiasts to share and geek out about the latest mobile apps, websites, hardware projects, and tech creations.”</p><p>With about <strong>5 million</strong> web page views each month (<a href="https://www.similarweb.com/website/producthunt.com/">SimilarWeb</a>) you can see that the community around Product Hunt is quite large. We learned so much from our launch that we decided to share these experiences and insights with you.</p><p>Despite being upvoted by <strong>654 people</strong> within the first <strong>24hrs</strong>, we didn't achieve a spot in the TOP 5 &nbsp;let alone reach the “Product of the Day.” The main reason for this was probably due to the value of most of our upvotes. At the beginning, we rapidly got upvoted by many people from our community, including friends, family members, and also early adopters of <a href="https://typestudio.co/"><strong>Type Studio</strong></a>. In other words, a closer community group. The problem was that most of these people didn’t have a Product Hunt account and had to subscribe on the day of our launch.</p><p>Nevertheless, we went from “zero to hero” really fast. We reached almost <strong>300 upvotes</strong> within the first six hours. These were the six hours where the US wasn’t even awake yet, so we assumed there would be many more upvotes to come as the day went on.</p><figure><img src="https://blog.typestudio.co/content/images/2020/08/product-hunt-upvotes.png" alt="" srcset="https://blog.typestudio.co/content/images/size/w600/2020/08/product-hunt-upvotes.png 600w, https://blog.typestudio.co/content/images/size/w1000/2020/08/product-hunt-upvotes.png 1000w, https://blog.typestudio.co/content/images/2020/08/product-hunt-upvotes.png 1016w" sizes="(min-width: 720px) 720px"><figcaption>Upvotes in 24 hours</figcaption></figure><p>The following six hours were overwhelming as we were on our way to “Product of the Day”. The ongoing upvoting process showed us that our idea, and product, was well received by the Product Hunt community, respectively the Product Hunt natives. Another bump in upvotes came when our tweet was retweeted by the official Product Hunt Twitter account. Even though every product from the top list is featured by them, the retweet gave us an additional push not only for our product’s upvotes, but also for our enthusiasm.</p><p>Our absolute highlight came later in the day when we got retweeted directly by Ryan Hoover, the founder of Product Hunt. We knew that many products get retweeted by the official Product Hunt Twitter page, but this really caught us by surprise! A few minutes later we got a mail from Ryan and Vadika Jain and their <a href="https://weekend.fund/"><strong>Weekend Fund</strong></a> &nbsp;that they would like to meet us.</p><figure><img src="https://blog.typestudio.co/content/images/2020/08/Ryan-Hoover-Twitter-Type-Studio.png" alt=""><figcaption>Shout out by Ryan Hoover</figcaption></figure><p>After <strong>13 </strong>really successful hours in which we held the title “Product of the Day”, our competitors for the day were also getting upvoted quite a lot. Even though we still got the most upvotes, we were overtaken by the <a href="https://www.producthunt.com/posts/mmhmm"><strong>mmhmm</strong></a> app, which is from the <a href="https://evernote.com/">Evernote </a>founder <a href="https://twitter.com/plibin">Phil Libin</a>. His app has gone viral in the whole tech scene and has received over 3500 upvotes so far. Especially his <a href="https://www.youtube.com/watch?v=c8KhKBLoSMk">explanatory video</a> has received an incredible amount of attention - over 300k clicks as of now. If you want to see an excellent product video, you should definitely watch it!</p><p>From this point on, the discrepancy between quality upvotes and less valuable ones could be seen. This means that some of our upvotes did not have the same value as others, and that the acquisition of our close community didn’t have a lasting effect. At the end of the day we were overtaken by some other products with less upvotes, so we ended up in #6 place. </p><p>Nevertheless we are more than satisfied with this result. All in all, we have received a lot of attention, which is also reflected in the <strong>8 investor</strong> inquiries that we received during the day. Over the whole week until now, new upvotes are constantly being added, so that we have <strong>1001 upvotes </strong>at this point in time, which is really </p><figure><img src="https://blog.typestudio.co/content/images/2020/08/giphy-2.gif" alt=""></figure><p>After processing our performance of our Product Hunt launch day, we wanted to give you some insights into what we came to learn from our experiences that day:</p><ul><li>As already mentioned, community is good, but trust on Product Hunt takes the cake: Even though the acquisition of our surrounding community brought us many upvotes, we later noticed that the votes from people who are not frequently on Product Hunt are not worth the same as votes of Product Hunt experienced users/Product Hunt natives. This is probably due to the Product Hunt algorithm. In some blog articles you can even read that the upvotes of new accounts or people who came via a shared link have no value at all, and can even have negative effects on the algorithm.</li><li>Get yourself a <strong>Hunter</strong>! We started our first launch on Product Hunt without having a big Hunter who could have helped us with promoting our tool to the PH community. To be honest, we have had the opportunity to be hunted by <a href="https://www.producthunt.com/@kevin">Kevin William David</a> one of the biggest hunters, but only as a second product, because he already hunted another product as first on that day. That would have meant for us that we would have gone live only from 12pm PST and lost half the day. Also we wouldn't have his advantage that his first hunt would automatically be listed on the start page of Product Hunt. In the end, we definitely learned that having a Hunter is a big help when trying to get upvotes from people who are already on Product Hunt and follow a Hunter because they all get a push notification.</li><li>There are days of varying intensity on which you can launch your product. During the week there are significantly more upvotes than on the weekend. We have made a small evaluation of this. In the chart below you can see the average number of upvotes the <strong>Top 5 products</strong> get together. As you can see Tuesday is the strongest day with an average of <strong>2840 upvotes</strong> for the first 5 products. We deliberately chose Tuesday, because you have the chance to reach the biggest audience at the same time. For this you have to expect that other strong products will launch on this day, as it was the case on our day. If you only have the goal to become "Product of the Day", then you have much better chances on Saturday or Sunday.</li></ul><figure><img src="https://blog.typestudio.co/content/images/2020/08/Picture1-1.png" alt="" srcset="https://blog.typestudio.co/content/images/size/w600/2020/08/Picture1-1.png 600w, https://blog.typestudio.co/content/images/size/w1000/2020/08/Picture1-1.png 1000w, https://blog.typestudio.co/content/images/size/w1600/2020/08/Picture1-1.png 1600w, https://blog.typestudio.co/content/images/2020/08/Picture1-1.png 1980w" sizes="(min-width: 720px) 720px"><figcaption><strong>Average Upvotes of the Top 5 products from 03.08.2019 to 03.08.2020</strong></figcaption></figure><ul><li>Another exciting opportunity is using <a href="https://www.producthunt.com/ship"><strong>Product Hunt Ship</strong></a> to announce your product even before launching it! Ship<strong><strong> </strong></strong>allows you to advertise your product BEFORE the launch, in order to acquire and engage with early-adopters through an <em><em>upcoming</em></em> landing page and a mailing-list. Since the Pro and Super Pro are really expensive, Ship is probably only worthwhile for Prodcute, through which you get paying customers. But you should definitely check out the basic version! We will too... and maybe even the pro version for our next launch! </li></ul><figure><img src="https://blog.typestudio.co/content/images/2020/08/Product-Hunt-Ship_Pricing.png" alt="" srcset="https://blog.typestudio.co/content/images/size/w600/2020/08/Product-Hunt-Ship_Pricing.png 600w, https://blog.typestudio.co/content/images/size/w1000/2020/08/Product-Hunt-Ship_Pricing.png 1000w, https://blog.typestudio.co/content/images/2020/08/Product-Hunt-Ship_Pricing.png 1301w" sizes="(min-width: 720px) 720px"><figcaption>Product Hunt Ship pricing</figcaption></figure><p>As we mentioned at the beginning, we also want to share some insights with you.<br>Here are a few facts and figures from our Google Analytics account. All in all we had <strong>11.8K</strong> sessions from Tuesday to Sunday during the launch week with <strong>5.3K</strong> unique visitors. On the day itself there were <strong>2.4K</strong> unique visitors.</p><figure><img src="https://blog.typestudio.co/content/images/2020/08/Website-visits-product-hunt-launch-1.png" alt="" srcset="https://blog.typestudio.co/content/images/size/w600/2020/08/Website-visits-product-hunt-launch-1.png 600w, https://blog.typestudio.co/content/images/2020/08/Website-visits-product-hunt-launch-1.png 810w" sizes="(min-width: 720px) 720px"><figcaption>Amount of website visits</figcaption></figure><p>The website hits come mostly from the US (<strong>23%</strong>), followed by India (<strong>9%</strong>). According to <a href="https://www.similarweb.com/website/producthunt.com/#overview">SimilarWeb</a> these are also the two largest community groups on the platform. The device behavior shows that most people have visited our site via the Desktop browser, which is very useful for us, since we currently only offer the editor for the desktop and not for mobile.</p><figure><img src="https://blog.typestudio.co/content/images/2020/08/Group-625--1-.png" alt="" srcset="https://blog.typestudio.co/content/images/size/w600/2020/08/Group-625--1-.png 600w, https://blog.typestudio.co/content/images/2020/08/Group-625--1-.png 636w"><figcaption>Website traffic by country and device</figcaption></figure><p>In <a href="https://amplitude.com/">Amplitude</a>, we recorded a total of <strong>541 new Signup's</strong> during the week, which turned out to be very valuable for us, as we received an incredible amount of user feedback.</p><figure><img src="https://blog.typestudio.co/content/images/2020/08/Screen-Shot-2020-08-04-at-12.27.39-AM.png" alt="" srcset="https://blog.typestudio.co/content/images/size/w600/2020/08/Screen-Shot-2020-08-04-at-12.27.39-AM.png 600w, https://blog.typestudio.co/content/images/size/w1000/2020/08/Screen-Shot-2020-08-04-at-12.27.39-AM.png 1000w, https://blog.typestudio.co/content/images/2020/08/Screen-Shot-2020-08-04-at-12.27.39-AM.png 1141w" sizes="(min-width: 720px) 720px"><figcaption>Type Studio new Signup's</figcaption></figure><hr><p>In conclusion, our launch on Product Hunt was very successful, we learned a lot about what we can do better next time and recommend everyone to launch their product there, because the community and the feedback you get is unique and valuable. If you have also launched on Product Hunt or plan to do so, feel free to drop me a <a href="https://www.linkedin.com/in/michaelsieb/">message</a>.</p>
            </div></div>]]>
            </description>
            <link>https://blog.typestudio.co/product-hunt-learnings/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24444567</guid>
            <pubDate>Fri, 11 Sep 2020 16:42:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You’re fired: Dutch hackers broke into Trump’s Twitter account]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24444514">thread link</a>) | @hellofunk
<br/>
September 11, 2020 | https://www.dutchnews.nl/news/2020/09/youre-fired-dutch-hackers-broke-into-trumps-twitter-account-in-2016/ | <a href="https://web.archive.org/web/*/https://www.dutchnews.nl/news/2020/09/youre-fired-dutch-hackers-broke-into-trumps-twitter-account-in-2016/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div id="attachment_128853"><p><img aria-describedby="caption-attachment-128853" src="https://www.dutchnews.nl/wpcms/wp-content/uploads/2018/10/hackers-560x315.jpg" data-src="https://www.dutchnews.nl/wpcms/wp-content/uploads/2018/10/hackers-560x315.jpg" alt="" width="560" height="315" data-srcset="https://www.dutchnews.nl/wpcms/wp-content/uploads/2018/10/hackers-560x315.jpg 560w, https://www.dutchnews.nl/wpcms/wp-content/uploads/2018/10/hackers-768x432.jpg 768w, https://www.dutchnews.nl/wpcms/wp-content/uploads/2018/10/hackers-640x360.jpg 640w, https://www.dutchnews.nl/wpcms/wp-content/uploads/2018/10/hackers-100x56.jpg 100w, https://www.dutchnews.nl/wpcms/wp-content/uploads/2018/10/hackers-130x73.jpg 130w, https://www.dutchnews.nl/wpcms/wp-content/uploads/2018/10/hackers.jpg 1000w" data-sizes="(max-width: 560px) 100vw, 560px" srcset="https://www.dutchnews.nl/wpcms/wp-content/uploads/2018/10/hackers-560x315.jpg 560w, https://www.dutchnews.nl/wpcms/wp-content/uploads/2018/10/hackers-768x432.jpg 768w, https://www.dutchnews.nl/wpcms/wp-content/uploads/2018/10/hackers-640x360.jpg 640w, https://www.dutchnews.nl/wpcms/wp-content/uploads/2018/10/hackers-100x56.jpg 100w, https://www.dutchnews.nl/wpcms/wp-content/uploads/2018/10/hackers-130x73.jpg 130w, https://www.dutchnews.nl/wpcms/wp-content/uploads/2018/10/hackers.jpg 1000w"></p><p id="caption-attachment-128853">Photo: Depositphotos.com</p></div><p>Three Dutch hackers broke into Donald Trump’s Twitter account shortly before he became president in 2016 by guessing his password was ‘yourefired’, magazine<a href="https://www.vn.nl/tijdlijn-zo-verliep-de-hack-van-trump/"> Vrij Nederland reported</a> this week.</p><p>The hackers, named as Edwin, Mattijs and Victor by the magazine, used a leaked list of LinkedIn accounts from 2012 to target Trump, then a presidential candidate and then warn him in an email that they had broken in.</p><p>Vrij Nederland journalist Gerard Janssen interviewed the three and published a major report of the hack after meeting them at a hackers’ convention. Screenshots show they were members of a hackers group calling itself Guild Of The Grumpy Old Hackers and that they broke into Trump’s account on October 27, 2016, shortly before the presidential vote.</p><p>They took the password from the leaked LinkedIn database, which contained 117 million names and passwords. ‘You’re fired’, was a popular Trump catchphrase in his roll on television show The Apprentice.</p><p>‘They were shocked when they succeeded,’ Janssen told NOS news. ‘They knew that they could be in trouble because it could be seen as a cyber attack on a presidential candidate.’</p><p>The hackers, who documented their actions thoroughly, never heard from Trump himself, but National Cyber Security Centre (NCSC) replied to them in November 2016, thanking them for getting in touch. All three, who now work in online security trying to detect weaknesses in corporate and government software, have also been able to visit America without any trouble.</p><p>Donald Trump was not among a <a href="https://www.forbes.com/sites/barrycollins/2020/07/16/twitter-hack-why-wasnt-donald-trump-targeted/">list of famous names</a>, including Bill Gates, Elon Musk, Apple, Joe Biden, and Barack Obama, whose Twitter accounts were hacked in July this year.</p><div onclick="window.location.href='https://www.dutchnews.nl/donate-to-dutchnews-nl/'"><div><h4>Thank you for donating to DutchNews.nl</h4><p>The DutchNews.nl team would like to thank all the generous readers who have made a donation in recent weeks. Your financial support has helped us to expand our coverage of the coronavirus crisis into the evenings and weekends and make sure you are kept up to date with the latest developments.</p><p> <strong>DutchNews.nl</strong> has been free for 14 years, but without the financial backing of our readers, we would not be able to provide you with fair and accurate news and features about all things Dutch. Your contributions make this possible.</p><p> <strong> <a href="https://www.dutchnews.nl/donate-to-dutchnews-nl/"> If you have not yet made a donation, but would like to, <br>you can do so via Ideal, credit card or Paypal. </a> </strong></p></div></div></div></div>]]>
            </description>
            <link>https://www.dutchnews.nl/news/2020/09/youre-fired-dutch-hackers-broke-into-trumps-twitter-account-in-2016/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24444514</guid>
            <pubDate>Fri, 11 Sep 2020 16:36:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Security by obscurity is underrated]]>
            </title>
            <description>
<![CDATA[
Score 814 | Comments 472 (<a href="https://news.ycombinator.com/item?id=24444497">thread link</a>) | @pcr910303
<br/>
September 11, 2020 | https://utkusen.com/blog/security-by-obscurity-is-underrated.html | <a href="https://web.archive.org/web/*/https://utkusen.com/blog/security-by-obscurity-is-underrated.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>
08 September 2020
</p>
<p>In the information security field, we have developed lots of thoughts that can’t be discussed (or rarely discussed):</p>
<ul>
<li>
<p>Never roll your own crypto</p>
</li>
<li>
<p>Always use TLS</p>
</li>
<li>
<p>Security by obscurity is bad</p>
</li>
</ul>
<p>And goes like this. Most of them are very generally correct. However, I started to think that people are telling those because everyone is telling them. And, most of the people are actually not thinking about exceptional cases. In this post, I will raise my objection against the idea of “Security by obscurity is bad”.</p>
<h2 id="risk-defense-in-depth-and-swiss-cheese">Risk, Defense in Depth and Swiss Cheese</h2>
<p>One of the main goal of defensive security is reducing the risk for the target business. According to the OWASP’s methodology, the risk of an issue is calculated with the formula below:</p>
<p><code>Risk = Likelihood * Impact</code></p>

<p>According to this formula, a Remote Code Execution issue poses more risk than a Cross Site Scripting one since the RCE causes more impact. This is easy. But what about the likelihood metric. According to the OWASP, likelihood refers that:</p>
<div><div><pre><code>At the highest level, this is a rough measure of how likely this particular vulnerability is to be uncovered and exploited by an attacker
</code></pre></div></div>
<p>So, if we can reduce the likelihood, we can reduce the overall risk. That’s good. It’s actually very similar to a very common idea called “Defense in Depth”. It’s also referred as “Swiss Cheese Model”</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/0/07/Swiss_cheese_model.svg" alt="Swiss Cheese"></p>
<p>According to this model, you need to build your defense mechanisms in a layered model so that even the attackers pass the first one, they will get caught on the others.</p>
<h2 id="security-by-obscurity">Security by Obscurity</h2>
<p>So let’s talk about security by obscurity. It’s a bad idea to use it as a single layer of defense. If the attacker passes it, there is nothing else to protect you. But it’s actually would be good to use it as an “additional” layer of defense. Because it has a low implementation cost and it usually works well.</p>
<p>Let’s think about a couple of scenarios here:</p>
<ul>
<li>I have a server that runs the SSH with it’s default port <code>22</code> and my credentials are: <code>root:123456</code>. What is the likelihood of being compromised?</li>
</ul>
<p>It’s almost 100% since the hackers are conducting brute force attacks to the services with common credentials globally.</p>
<ul>
<li>SSH runs in port <code>22</code> and my credentials are <code>utku:123456</code>. What is the likelihood of being compromised?</li>
</ul>
<p>Well, we have eliminated the global brute forcers since we are not using a common username. The likelihood and risk are reduced. However, we still have to deal with targeted attackers. A targeted attacker can guess the username as <code>utku</code> since it’s my name.</p>
<ul>
<li>SSH runs in port <code>64323</code> and my credentials are <code>utku:123456</code>. What is the likelihood of being compromised?</li>
</ul>
<p>Now we changed the default port number. Does it help? Firstly, we’ve eliminated the global brute forcers again since they scan only the common ports. What about the others? To find this out, I did a small survey on my Twitter to find out people’s port scan behaviors.</p>
<blockquote><div lang="en" dir="ltr"><p>I'm trying to prove a point for my new article. I need your answers for the question below. (please be honest)</p><p>-When you do a port scan with nmap to find open ports on the target, are you specify a custom port range to scan all 65,535 ports? (with -p0-65535 parameter)</p></div>— Utku Şen (@utkusen) <a href="https://twitter.com/utkusen/status/1303021175556145154?ref_src=twsrc%5Etfw">September 7, 2020</a></blockquote>

<p>As you can see here, lots of people tend to scan the default/most popular ports only. So, if you switch your port from 22 to 64323, you will eliminate some of them. You will reduce the likelihood and risk.</p>
<p>The same thing goes for software vulnerabilities as well. If a vulnerability found in the Microsoft Remote Desktop Protocol, everybody will scan for the port 3389 globally. You can reduce your risk just by changing the default port.</p>
<h2 id="other-applications">Other Applications</h2>
<p>Of course, it’s possible to use the same methodology in other fields other than changing the defaults. For example, the following ideas might be a good idea for some specific cases (not always)</p>
<ul>
<li>
<p><strong>Obfuscating codes:</strong> Of course, it’s common knowledge. Hackers are people too. If you obfuscate your code well, they will need to spend more time to find issues. They may give up eventually.</p>
</li>
<li>
<p><strong>Using random variable names for a web application:</strong> Instead of using clear variable names, you can switch them with random strings. It might help just like the code obfuscation.</p>
</li>
<li>
<p><strong>Using Symmetric Encryption in the Database:</strong> When you write data to the database, use a function like <code>encryption_algorithm(data,key)</code>. Likewise, when you read data, use a function like <code>decryption_algorithm(data,key)</code>. If the attacker can read your backend code, obviously he/she can decrypt your database. But if there is an issue that allows an attacker to read data from the database, but not the backend code (like SQL Injection), the gathered data won’t be helpful for the attacker.</p>
</li>
</ul>
<h2 id="real-life-applications">Real Life Applications</h2>
<p>Security by obscurity is widely used in physical/real-life security. For example, the president goes from point A to point B with his 30 cars convoy. But he’s not sitting on his own presidential car so that the attacker won’t target him easily. He can be in any car and it reduces the risk of an attack.</p>
<p><img src="https://i.dailymail.co.uk/1s/2019/06/04/00/14330600-0-image-a-38_1559605545988.jpg" alt="President"></p>
<p>Camouflaged animals are using security by obscurity as well. Obscurity reduces the likelihood of being killed. Therefore, they gained this ability in the evolutionary process.</p>
<p><img src="https://static.boredpanda.com/blog/wp-content/uuuploads/animal-camouflage/animal-camouflage-4.jpg" alt="Animal"></p>
<h2 id="conclusion">Conclusion</h2>
<p>Security by obscurity is not enough by itself. You should always enforce the best practices. However, if you can reduce the risk with zero cost, you should do that. Obscurity is a good layer of security.</p>


</div></div>]]>
            </description>
            <link>https://utkusen.com/blog/security-by-obscurity-is-underrated.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24444497</guid>
            <pubDate>Fri, 11 Sep 2020 16:34:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bazel, Haskell, and Build-System Joy]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24444449">thread link</a>) | @LukeHoersten
<br/>
September 11, 2020 | https://blog.sumtypeofway.com/posts/bazel-haskell-build-system-joy.html | <a href="https://web.archive.org/web/*/https://blog.sumtypeofway.com/posts/bazel-haskell-build-system-joy.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
            <article>
                
                
                  <h2>2020-09-10</h2>
                
                <section>
                    <p>As part of my day job at GitHub, I work on the <a href="https://github.com/github/semantic"><code>semantic</code></a> program analysis toolkit. It’s a lot of fun and a lot of Haskell: we clock around <span>17,000</span> lines of Haskell source, though at times it’s been as high as <span>29,000</span>. The project in total has around a hundred direct dependencies, and several hundred resulting indirect ones. Though initially we used <a href="https://docs.haskellstack.org/en/stable/README/">Stack</a> to build <code>semantic</code>, we switched to <a href="https://cabal.readthedocs.io/en/3.4/">Cabal</a> when it gained the ability to build within a sandbox.</p>
<p>With <code>cabal</code> and a clean build environment, <code>semantic</code> takes between twenty and forty-five minutes to complete. When optimizations are enabled, it can take on the order of hours, especially when rebuilding dependencies with optimizations. And this is fair! Haskell is a complicated language that takes serious computational power to compile. And though Cabal is a versatile and fast-improving tool, it isn’t perfect, especially when applied to large monorepos containing many subprojects. Issues we ran into include:</p>
<ul>
<li>Little compositionality: though <code>common</code> stanzas in <code>.cabal</code> files cut down on repetition within a single file, it’s not possible to share settings or configurations across multiple files.</li>
<li>Suboptimal caching: due to the vagaries of Template Haskell, <code>cabal</code> is very conservative about caching files containing TH splices. This is correct behavior on <code>cabal</code>’s part, but grows tedious when innocuous changes cause rebuilds that we know are unnecessary. The third-party <a href="https://github.com/haskell-works/cabal-cache"><code>cabal-cache</code></a> ameliorated some of this on our CI boxes, but did not address the problem fully. Additionally, any modification to a <code>.cabal</code> file throws out its associated caches, even when doing something that shouldn’t invalidate existing caches, such as adding a new module.</li>
<li>Phasing restrictions: our build process involved generating Haskell data types from text files containing grammar descriptions, and it’s not generally possible to access project-local files during Template Haskell splices.</li>
<li>Scriptability: when dealing with large projects, it’s often very convenient to do some limited forms of iteration when specifying build configurations, and the pure-text format of <code>.cabal</code> files precludes this.</li>
<li>Reliable REPLs: in order to yield a REPL capable of loading files without first compiling the entire project, we required a complicated and brittle <a href="https://github.com/github/semantic/blob/master/script/ghci-flags">bash script</a>.</li>
<li>Convenience: compared to other languages in which you can just drop new source files and have them picked up by the compiler, <code>cabal</code> requires you to list them explicitly. While explicit is very often better than implicit, the case of adding a new module to a project is so common that editing <code>.cabal</code> files every time becomes tedious.</li>
</ul>
<p>As you can imagine, living with hour-long CI cycles was not an indefinitely tenable situation. But I think the issue of long CI cycles goes deeper than mere inconvenience: I believe that we as software developers have an ethical duty to keep build times and CI times down. We live in a world where carbon emissions have created, at least in part, a climate so troubled that the west coast of the United States is <a href="https://www.nytimes.com/2020/09/09/us/fires-oregon-california-live-updates.html">a literal hellscape</a>, where island populations are being displaced due to <a href="https://www.theguardian.com/environment/georgemonbiot/2009/may/07/monbiot-climate-change-evacuation">rising sea levels</a>, and where <a href="https://ourworld.unu.edu/en/a-growing-digital-waste-cloud">cloud computing consumes more energy</a> than some entire nations; I’ve grown to find the thought of letting corporations’ Travis or CircleCI instances recompute thousands of pointless builds upsetting, upsetting in a way similar to the thought of said companies contaminating groundwater with industrial byproducts. To meaningfully change the way companies consume resources requires broad labor action; however, irrespective of when this action is taken, we as engineers have an opportunity and responsibility to be the agents of change.</p>
<p>I also believe that very few people<span><label for="sn-0"></label><span>Excluding Rust programmers, who get to use the truly excellent <code>cargo</code>, and who seem to be very happy with it.</span></span> are truly happy with their build tool. I certainly haven’t been, anyway. To name but a few: the shortcomings of <code>make</code> have been documented for longer than I’ve been alive; <code>xcodebuild</code> only works on macOS/iOS targets; <a href="https://cmake.org/">CMake</a> is powerful but has no interoperability with <code>cabal</code>. It’s hardly controversial to suggest that, given a large project, no build system will be perfect for all people. This faact doesn’t make the quest for a better build system useless, but should also inform the engineer-voice that demands perfection.</p>
<p>Wearied by hour-long builds, both on CI and locally, I looked around for alternative build solutions that might ease that weariness. I settled on <a href="https://bazel.build/">Bazel</a>, with the <a href="https://haskell.build/"><code>rules_haskell</code></a> toolkit designed by the fine folks at <a href="https://www.tweag.io/">Tweag</a>. I’m happy to report that the experience was brilliant: if it’s possible for a build system to produce joy, Bazel and <code>rules_haskell</code> do. What follows is a brief overview of the Bazel experience, and the process of porting a large, multi-project repository to support either <code>cabal build</code> or <code>bazel build</code>.</p>

<p>The biggest thing to wrap your head around when coming to Bazel from other build systems is that <em>everything</em> on which your build depends—source files, data files, package dependencies, vendored git repositories−must be specified explicitly in Bazel. It does not suffice for your build process to just look at a given file I know is present in the repository; if the target that I’m specifying depends on that file, it must be listed explicitly as a dependency. Dependencies, in Bazel parlance, are more than libraries or repositories: the set of dependencies, and the hashed contents of all these dependencies, are what tells Bazel when builds can be cached and when they can’t. This also goes for test targets: if your tests need to read from some corpus of fixtures, you’ll have to specify those fixtures as an explicit dependency so that they’re available at runtime. This can be an involved process, as sometimes you just want to access a file (come on, it’s <em>right there</em>, I found myself whispering), but the benefits also show up in testing: if your tests are deterministic (as they should be), Bazel is capable of caching your test results, and only rerunning them when the source <em>or the fixtures</em> change. Given that the full tests for <code>semantic</code> parsing take several minutes to run, this is a profound improvement, especially on CI.</p>
<p>Beginning a new Bazel project, or converting from Cabal, requires starting with the <code>WORKSPACE</code> file. The <code>WORKSPACE</code> specifies the root of the current project, downloads and sets up GHC, and is the only place where external dependencies—such as those downloaded from Hackage—are specified. Targets are specified per-project in <code>BUILD.bazel</code> files, each of which refers as needed to external dependencies defined in the <code>WORKSPACE</code>. The language used to specify these <code>.bzl</code> files is known as <a href="https://docs.bazel.build/versions/master/skylark/language.html">Starlark</a>, and is a subset of Python that discourages mutability and iteration—though I’m hardly the world’s biggest fan of Python, I found Starlark very pleasant to use, as its chosen subset of Python is strict enough to disallow most of the things I find egregious. Once the <code>WORKSPACE</code> file is set up, the process of conversion becomes specifying per-project library and executable targets in the <code>BUILD.bazel</code> file present in each project within the monorepo.</p>
<h2 id="whence-cabal-dependencies">Whence Cabal Dependencies?</h2>
<p>As I mentioned earlier, there are several hundred direct and indirect dependencies across all subprojects in the <code>semantic</code> monorepo. Each of these dependencies has to be declared and made available as a build target, specified in the <code>WORKSPACE</code>. There are three options for specifying dependencies on Hackage projects:</p>
<ul>
<li>Specify them all manually by downloading them with <a href="https://docs.bazel.build/versions/master/repo/http.html"><code>http_archive</code></a> and <a href="https://api.haskell.build/haskell/cabal.html#haskell_cabal_library"><code>haskell_cabal_library</code></a>, doing so would be tedious beyond words, especially given that we’d have to declare dependencies for each package.</li>
<li>Use the <a href="https://nixos.org/">Nix</a> expression language, in combination with the <a href="https://github.com/tweag/rules_nixpkgs"><code>rules_nixpkgs</code></a> ruleset, and transform Nix derivations into Bazel targets.</li>
<li>Pin to a particular <a href="https://www.stackage.org/">Stackage</a> release, specifying non-Stackage dependencies with a YAML file in the project root.</li>
</ul>
<p>Though Nix has considerable merit, especially when corralling system dependencies, it’s still an unconventional choice in industry, and I deemed it politically unattainable to introduce not just one but two new frameworks for builds. As such, I chose to build against a Stackage release, especially given that we have no real system-level dependencies and that ninety percent of our dependencies are already present in Stackage snapshots.</p>
<h2 id="code-generation-it-matters">Code Generation: It Matters</h2>
<p>Because maintaining syntax trees by hand was much too onerous, my coworker <a href="https://twitter.com/aymannadeem">Ayman</a> swooped in and wrote Template Haskell splices that <a href="https://github.blog/2020-08-04-codegen-semantics-improved-language-support-system/">generate syntax types</a> from a <a href="https://tree-sitter.github.io/tree-sitter/">tree-sitter</a> JSON description of the grammar. This works well, but hinges on the ability to read said grammar descriptions from the filesystem. This was a fraught process in Cabal, relying on autogenerated <code>Paths_</code> modules providing access to files specified in the <code>data-files</code> setting in each project’s <code>.cabal</code> file, and only happened to work by accident: were <code>semantic</code> uploaded to Hackage, no one would be able to use it as a dependency, as <code>cabal</code> would be unable to find the required file. As it is, this happened to work because our downstream clients use a pinned Git hash in their <code>cabal.project</code> to pull in <code>semantic</code> as a dependency; because <code>cabal</code> checks out the whole repository in this case, the tree-sitter files happen to be in the correct place.</p>
<p>Bazel and <code>rules_haskell</code> take a more principled approach to this. Rather than calling pre-provided functions to determine the locations of these JSON files, we make the build system take care of finding them, by declaring that each language package has an explicit dependency on said file. We can pass in the location of this file as a preprocessor flag to the build process, which is then substituted using the <code>CPP</code> extension to Haskell. This doesn’t work perfectly—there’s an <a href="https://github.com/tweag/rules_haskell/issues/1337">incorrect interaction</a> when invoking a REPL on a language package in question—but suffices in …</p></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.sumtypeofway.com/posts/bazel-haskell-build-system-joy.html">https://blog.sumtypeofway.com/posts/bazel-haskell-build-system-joy.html</a></em></p>]]>
            </description>
            <link>https://blog.sumtypeofway.com/posts/bazel-haskell-build-system-joy.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24444449</guid>
            <pubDate>Fri, 11 Sep 2020 16:30:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Regarding Semantic Versioning]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 21 (<a href="https://news.ycombinator.com/item?id=24444391">thread link</a>) | @zdw
<br/>
September 11, 2020 | https://www.danielmoch.com/posts/2020/09/regarding-semantic-versioning/ | <a href="https://web.archive.org/web/*/https://www.danielmoch.com/posts/2020/09/regarding-semantic-versioning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<p>So as not to bury the lede, I'll get to my point: <a href="https://semver.org/">Semantic
Versioning</a> is a meta-API, and maintainers who are cavalier about
violating it can't be trusted to created stable contracts. I've lost
patience for breaking changes making their way to my code bases without
the maintainers incrementing the major version of their projects,
especially in language ecosystems where Semantic Versioning is
expected, and in such cases I'm going to begin exploring alternative
options so I can ban such libraries from my projects---personal and
professional---altogether.</p>
<!-- TEASER_END -->
<div id="what-even-is-semantic-versioning">
<h2>What Even Is Semantic Versioning?</h2>
<p>When developers adopt an external library into their code bases, they
do so knowing they will be bound in their use of the library by the
application programming interface (API). In this sense, an API can be
seen as a kind of contract between a library's maintainer and its
consumers. If a maintainer makes frequent changes to a library's API,
then that API is considered unstable. In that situation, consumers
either use the library anyway, accepting the risk that things will
break as a result of a change in the library, or they avoid it.</p>
<p>Semantic Versioning seeks to ease this picture by embedding notions of
backward- and forward- compatibility into software version numbers. If
a library maintainer adheres to it, then consumers are able to upgrade
to newer versions of the library (say, to pick up bug fixes) without
fear of breaking changes, provided they aren't moving to a new, major
version. In terms of backward- and forward-compatibility, Semantic
Versioning creates an expectation that a given version of a library is
forward-compatible with any future version up to the next, major
release. A library is also backward-compatible down to the most
recent, minor release (beyond which point consumers' code _might_
break if they are using newer library features).</p>
<p>There are several benefits to using Semantic Versioning. One benefit
is that it becomes easy to codify dependency requirements into
automated dependency tools. By <em>assuming</em> Semantic Versioning, users
of tools like NodeJS's <code>npm</code> and Rust's <code>cargo</code> are able to
specify dependency <em>ranges</em> rather than hard-coded versions. So if a
new release of a library comes out, these tools are able to decide
automatically whether or not they can be used in a given project. In
other words, Semantic Versioning creates an opportunity for downstream
developers to easily decide whether or not to upgrade to a new version
of a library, potentially picking up important bug fixes in the
process.</p>
</div>

<div id="conclusion">
<h2>Conclusion</h2>
<p>If you work in a language ecosystem where Semantic Versioning is the
<em>de facto</em> norm, where violating it can wreak havoc downstream, then
please play nice and follow its dictates. Instead of viewing it as a
straight jacket, try to see it as an algorithm to determine what your
next release number should be. We should all like algorithms!</p>
<p>If you refuse to be persuaded, then understand I will will not work
downstream from you <a href="https://www.danielmoch.com/posts/2020/09/regarding-semantic-versioning/#id2" id="id1">1</a>. I'll find a different upstream to work with
because I cannot trust you to create a stable contract. Your
willingness to conform to the meta-API is something I will take into
consideration in the future before adopting a library into any project
that I work on. I wish you well; I hope you have fun; I'll be sure to
give you a wide berth.</p>
<dl>
<dt id="id2"><span><a href="https://www.danielmoch.com/posts/2020/09/regarding-semantic-versioning/#id1">1</a></span></dt>
<dd>
<p>I'll note here that I'm more forgiving in environments where
Semantic Versioning is not a <em>de facto</em> norm.</p>
</dd>
</dl>
</div>
</div>
</div></div>]]>
            </description>
            <link>https://www.danielmoch.com/posts/2020/09/regarding-semantic-versioning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24444391</guid>
            <pubDate>Fri, 11 Sep 2020 16:23:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How do you reason about a probabilistic distributed system?]]>
            </title>
            <description>
<![CDATA[
Score 98 | Comments 14 (<a href="https://news.ycombinator.com/item?id=24444276">thread link</a>) | @ahelwer
<br/>
September 11, 2020 | https://ahelwer.ca/post/2020-04-15-probabilistic-distsys/ | <a href="https://web.archive.org/web/*/https://ahelwer.ca/post/2020-04-15-probabilistic-distsys/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <div>
    <div>
      <article role="main">
        <h2 id="in-which-i-am-stunted-upon-by-coin-flips">In which I am stunted upon by coin flips</h2>
<p>Wasn’t too long ago that I felt pretty good about my knowledge of distributed systems.
All someone <em>really</em> needed in order to understand them, I thought, was a <a href="https://www.youtube.com/watch?v=JEpsBg0AO6o">thorough understanding of the paxos protocol</a> and a willingless to reshape your brain in the image of TLA+.
Maybe add a dash of conflict-free-replicated datatypes, just so you know what “eventual consistency” means.
Past that it’s just some optimizations and mashups which come easily to your TLA+-addled brain.</p>
<p>This belief proved surprisingly robust over a number of years, even surviving an aborted attempt at analyzing the <a href="https://github.com/ahelwer/tla-experiments/blob/master/Nano.tla">Nano cryptocurrency</a>.
It was only after encountering <a href="https://muratbuffalo.blogspot.com/2018/06/snowflake-to-avalanche-novel-metastable.html">the snowflake family of consensus protocols</a> that I realized my theory just wasn’t up to the challenge.
The issue was <em>probability</em>: snowflake protocols reach consensus by iteratively polling sets of other nodes at random, and the argument that consensus is eventually reached is a statistical argument deriving an upper bound on the probability of failure.</p>
<p>I didn’t <em>dislike</em> probability &amp; statistics, I just tried to keep my distance as much as possible.
All the algorithms in distributed systems I’d encountered so far involved <em>nondeterminism</em>, sure, but not probability.
I’d assumed nondeterminism was just a more flexible way of reasoning about probability.
This idea of mine would prove to be a source of great unnecessary confusion as I learned the art of reasoning about probabilistic distributed systems, so I’ll do you a favor and give you the core lesson of this entire post in one sentence:</p>
<p><strong>You cannot model probability with nondeterminism, and you cannot model nondeterminism with probability.</strong></p>
<h2 id="models-theyre-good-folks">Models: they’re good, folks!</h2>
<p>Have you ever been writing some multithreaded code, happily plugging in a mutex here, a semaphore there, or even just using some nice message-passing primitives to make your threads all get along?
Maybe you’ll be familiar, then, with what often comes next.
A scratch at the back of your mind, a thought - <em>“oh, wait…"</em> - as you realize something weird will happen if thread \(A\) manages to reach some step before thread \(B\) has finished its assigned task.
No worries! Slap on another WaitHandle, problem solved.
Except the problem wasn’t solved. Not really.
You consider it a bit more - what if thread \(C\) comes in with a message at this inopportune time?
You realize with dawning horror you’re actually tracing cracks in the foundation.
Patch them with mutexes! Semaphores! Anything!
Alas, you are beyond help. It’s around this time that your brain, catching a glimpse of the infinite plane of combinatorial state explosion, wisely ducks its head back down for the day and leaves you with a woozy, fuzzy, clenching feeling for having the gall to ask it to fix all this.</p>
<p>I’ve felt like this many times, and formal models are the only cure I’ve ever found.
Your brain isn’t built to hold massive state spaces in its working memory, so don’t even try.
Let a model checking program churn through all those states to find the bugs.
At this point I won’t even touch a multithreaded program or distributed system without whipping up a quick TLA+ spec of its desired workings.
I just specify all the possible events in the system, how those events affect the system state, what things I always want to remain true (the invariants), then let the model checker rip.
In TLA+, we model concurrency with nondeterminism; in a concurrent system, we have no idea whether thread \(A\) will execute a step before thread \(B\).
We can represent this with a nondeterministic state machine as follows:</p>
<figure>
    <img src="https://ahelwer.ca/img/probabilistic-distsys/nondeterministic.svg" width="10000"> 
</figure>

<p>So you’ll be in state \(s_3\) if thread \(A\) executes its step before thread \(B\), and state \(s_4\) if thread \(B\) executes its step before thread \(A\).
Maybe \(s_3\) and \(s_4\) are even the same state, who knows.
The model checker will explore both of these possible execution orders, and <strong>in a well-designed concurrent system we should <em>never</em> end up in a bad state just because of a certain order of execution</strong>.</p>
<p>Readers might wonder how exactly this models concurrency, where steps can happen uh, concurrently.
The short answer is you have to ensure all the steps in your model are atomic or independent: either impossible in the real world for two of your steps to happen at the exact same time (for example, by assuming use of a lower-level hardware synchronization primitive) or impossible for execution of one step to directly affect the same variables as another step (for example, if the steps are executed on different computers within a timespan less than the network latency between them).
If the steps in your model satisfy this requirement, checking all possible execution orders accurately models concurrency.
If they don’t, you need to break the steps down further so they do.
This model nicely captures &amp; exposes all that is difficult about concurrency.</p>
<p>What questions can we ask about this sort of model?
The most important questions are <em>reachability queries</em> - can we reach a <em>bad state</em> (two caches disagreeing on a value, deadlock, dogs &amp; cats living together, etc.) from the starting state?
These questions are called <em>safety properties</em>, and if they are answered in the negative then the system is safe.
Another type of query is something like “are we always guaranteed to eventually end up in a good state?”
These are called <em>liveness properties</em>.
Turns out these two types of questions can get you pretty far in concurrent &amp; distributed systems.
Definitely far enough to make a whole career out of writing rock-solid software in places others would falter.
However, these questions also have a drawback: their answers are absolute.
True or false.
No probability involved, no room for nuance.</p>
<p>What if one of the threads flips a coin, and if it’s heads it does one thing, tails another?
Entire state spaces, bifurcated by a probabilistic event.
Maybe those state spaces contain further coin flips, or other types of randomness.
In this system your questions might change from the form “is it possible to reach a bad state” to “what is the probability of reaching a bad state?”
Unfortunately these types of questions just cannot be answered within the nondeterministic model used above.
<strong>You cannot model probability with nondeterminism.</strong>
We must use a new type of model, a state machine that handles probability directly.</p>
<h2 id="leaving-the-beautiful-pure-discrete-realm">Leaving the beautiful pure discrete realm</h2>
<p>TLA+ can’t handle probability at this time, so we’d have to use a specialized modeling language like <a href="http://www.prismmodelchecker.org/">PRISM</a> which handles probabilistic state machines.
Let’s look at the standard hello-world example for probabilistic state machines: the <a href="http://www.prismmodelchecker.org/bibitem.php?key=KY76">1976 Knuth-Yao method</a> for simulating a fair six-sided die with a series of coin flips.
This is really quite a neat problem and I encourage you to ponder it for a second before seeing how they did it!
Any sequence of \(n\) coin flips will give you an event which has probability \(\frac{1}{2^n}\) of occurring.
Simulating a fair six-sided die requires generating an event with probability \(\frac{1}{6}\) of occurring.
You might then reason this problem is impossible, because you cannot evenly divide \(2^n\) by \(6\) for any \(n\) (this follows from the uniqueness of prime factorization).
Indeed, there is no way to simulate a six-sided die with a finite number of coin flips.
We have to use an algorithm which is not guaranteed to ever terminate, although vanishingly unlikely not to do so.
Here it is:</p>
<figure>
    <img src="https://ahelwer.ca/img/probabilistic-distsys/knuth-yao.svg" width="10000"> 
</figure>

<p>You can see that if you somehow only flip heads, or only flip tails, you’ll never reach one of the accepting states (here labeled with the die number they represent).
There are some fun ways to contextualize the probabilities of you only flipping heads or tails a certain number of times in a row.
For example, there are only <a href="https://www.popularmechanics.com/space/a27259/how-many-particles-are-in-the-entire-universe/">around \(2^{268}\) subatomic particles in the observable universe</a>; if you manage to flip heads 268 times in a row, that’s the same as picking the correct subatomic particle out of a universe-wide random draw.
Maybe go look at the <a href="https://en.wikipedia.org/wiki/Hubble_Ultra-Deep_Field">Hubble Ultra-Deep Field</a> as you ponder this probability.
Another way is assuming you’re between the ages of 25-34 and live in the USA, your annual all-cause mortality rate is <a href="https://www.cdc.gov/nchs/products/databriefs/db355.htm">about 129/100,000</a>.
Assuming deaths are uniformly distributed throughout the year, this means your chances of dying today are about 1 in 283,000.
This is just 18 all-heads or all-tails coin flips in a row.
What I’m saying is that you really, really shouldn’t worry about having to flip the coin very many times.</p>
<p>This probabilistic state machine model we’ve created is called a <em>Discrete-Time Markov Chain</em>, or DTMC.
In DTMCs, every transition has an associated probability and the probabilities of all out-flowing transitions must sum to one for every state (accepting states can be thought to have a loopback with probability 1).
The above rumination on termination probabilities is summed up in <em>the long run theorem</em>: in the long run, every path in a finite Markov chain ends in an absorbing state, which is a state (or group of states) from which there is an entrance but no exit.
What questions can we ask of DTMCs?
The most interesting one - the reason why we’re here - is “what is the probability of eventually reaching a certain state?”
The long run theorem tells us we have a 100% chance of eventually reaching <em>one</em> of the Knuth-Yao state machine’s accepting states.
What about the probability of ending up in a specific accepting state?
It should be \(\frac{1}{6}\). Is it?</p>
<p>Let’s try to reason this out with basic probability.
What are the chances of ending up in accepting state \(1\)?
Well, you can get there by flipping \(HHT\).
The probability of that happening is \(\frac{1}{2} \cdot \frac{1}{2} \cdot \frac{1}{2} = \frac{1}{8} \).
But you can also get there by flipping \(HHHHT\).
The probability of <em>that</em> happening is \(\frac{1}{2^5} = \frac{1}{32} \).
We have to add this to the first probability, so now our probability is \(\frac{1}{8} + \frac{1}{32} = \frac{5}{32}\).
But we can <em>also</em> get there …</p></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ahelwer.ca/post/2020-04-15-probabilistic-distsys/">https://ahelwer.ca/post/2020-04-15-probabilistic-distsys/</a></em></p>]]>
            </description>
            <link>https://ahelwer.ca/post/2020-04-15-probabilistic-distsys/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24444276</guid>
            <pubDate>Fri, 11 Sep 2020 16:10:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elixir Tip: Case vs. With]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24444265">thread link</a>) | @todsacerdoti
<br/>
September 11, 2020 | https://preslav.me/2020/09/11/elixir-tip-case-vs-with/ | <a href="https://web.archive.org/web/*/https://preslav.me/2020/09/11/elixir-tip-case-vs-with/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              
              <p>Dating back to version 1.2, the <code>with</code> operator is one of Elixir's features that need a bit of time to comprehend at first. It often gets used in situations where one would use <code>case</code>, or vice versa. The main difference between the two is that <code>with</code> will fall through, if no clause is matched, while <code>case</code> will throw a no-match error.</p><p>Confused? Let's start with some basics.</p><p>Use <code>case</code> when you need to perform exhaustive pattern matching, and ensure that at least one of the conditions matches:</p><pre><code>case foo() do
  cond1 -&gt; expression1
  cond2 -&gt; expression2
  cond3 -&gt; expression3
  _ -&gt; default_expression
end</code></pre><p>A very common use case is to pattern match on the results of potentially error-prone operations:</p><pre><code>case foo() do
  {:ok, res} -&gt; do_something_with_result(res)
  {:error, err} -&gt; handle_error(err)
end</code></pre><p>So far, so good. Now, we come to a very common daily work scenario. Imagine that we have one such operation (e.g. external API call, IO or DB operation, etc), and we want to perform a second such operation, but only if the first one were successful. How do we do that?</p><p>Recall that conditionals in Elixir are functions too. They can be piped into, or chained in the expression part of other conditionals. This allows us to to solve our problem above using chained conditionals:</p><pre><code>case foo() do
  {:ok, res} -&gt;
    case bar(res) do
	  {:ok, res2} -&gt; do_something_with_result(res2)
	  {:error, err} -&gt; handle_error(err)
	end
  {:error, err} -&gt; handle_error(err)
end</code></pre><p>Even with only two such calls, the level of complexity rose drastically. Add just one more such call, and the code becomes unreadable:</p><pre><code>case foo() do
  {:ok, res} -&gt;
    case bar(res) do
	  {:ok, res2} -&gt;
        case baz(res2) do
          {:ok, res3} -&gt; do_something_with_result(res3)
          {:error, err} -&gt; handle_error(err)
        end
	  {:error, err} -&gt; handle_error(err)
	end
  {:error, err} -&gt; handle_error(err)
end</code></pre><h2 id="-with-to-the-rescue">`with` to the rescue</h2><p>This is where the <code>with</code> operator gets really handy. In its basic form, it resembles our chained <code>case</code> above, but in a way, also functions like a pipeline operator. Check this out:</p><pre><code>with {:ok, res} &lt;- foo(),
     {:ok, re2} &lt;- bar(res)
     {:ok, re3} &lt;- baz(re2) do
  do_something_with_result(res3)
end</code></pre><p>This shall be interpreted as, "do all the comma separated operations in sequence, and if the previous one has matched, execute the next one. Finally, run the code inside the <code>do/end</code> block". This looks much more succinct and readable than its version before, but it has another big advantage too. It allows the programmer to focus on the happy-end business scenarios first. Some of you might have been wondering what would happen, if any of the comma-separated operations returns and <code>{:error, err}</code> tuple instead. The answer is, the first non-matching expression will be returned. In simple terms, if we don't care about the outcome of non-ok results, we might as well leave the happy path and leave it to the caller to take care of the final result.</p><p>If you have worked with <a href="https://hexdocs.pm/phoenix/Phoenix.Controller.html#action_fallback/1"></a><a href="https://www.phoenixframework.org/">Phoenix</a>, you might recall that this is exactly how its fallback actions work. In our controller actions, we take care of the happy path, and if an error occurs, Phoenix will pattern-match one of our fallback actions to take care of it instead:</p><figure><pre><code>defmodule MyController do
  use Phoenix.Controller

  action_fallback MyFallbackController

  def show(conn, %{"id" =&gt; id}, current_user) do
    with {:ok, post} &lt;- Blog.fetch_post(id),
         :ok &lt;- Authorizer.authorize(current_user, :view, post) do

      render(conn, "show.json", post: post)
    end
  end
end</code></pre><figcaption>Fallback controller example from the <a href="https://hexdocs.pm/phoenix/Phoenix.Controller.html#action_fallback/1">official Phoenix docs</a></figcaption></figure><h2 id="-with-else-">`with`/`else`</h2><p>If we want to take care of side effects ourselves, <code>with</code> offers an expanded version:</p><pre><code>with {:ok, res} &lt;- foo(),
     {:ok, res2} &lt;- bar(res) do
  do_something_with_res(res2)
else
  {:error, {:some_error, err}} -&gt; handle_some_error(err)
  {:error, {:some_other_error, err}} -&gt; handle_some__other_error(err)
  default -&gt; handle_something_completely_unexpected(default)
end</code></pre><p><strong>NOTE:</strong> Keep in mind that while the simple with form won't throw an error when no match occurs, when using else you have to exhaustively match all cases.</p><h2 id="when-not-to-use-with-">When not to use `with`</h2><p><strong>Using a single pattern-matching clause with <code>else</code>:</strong></p><p>This will make the code more difficult to read than you need it to be. The code below:</p><pre><code>with {:ok, res} &lt;- foo() do
  do_something_with_res(res)
else
  {:error, {:some_error, err}} -&gt; handle_some_error(err)
end</code></pre><p>Can easily be replaced with a more readable <code>case</code> block:</p><pre><code>case foo() do
  {:ok, res} -&gt; do_something_with_res(res)
  {:error, {:some_error, err}} -&gt; handle_some_error(err)
end</code></pre><hr><figure><a href="https://relistan.com/elixir-thoughts-on-the-with-statement"><div><p>Elixir: Thoughts on the `with` Statement – Repeatable Systems</p><p>Elixir has a some great syntactic sugar. A nice feature that was introducedback in Elixir 1.2 is the with statement w...</p><p><img src="https://relistan.com/images/apple-touch-icon-144x144-precomposed.png"><span>Repeatable Systems</span></p></div><p><img src="https://relistan.com/images/default-thumb.png"></p></a></figure>
                <section>
                  
                  <ul>
                      <li>
                        <a href="https://preslav.me/tag/elixir/" title="Elixir">Elixir</a>
                      </li>
                      <li>
                        <a href="https://preslav.me/tag/programming/" title="Programming">Programming</a>
                      </li>
                      <li>
                        <a href="https://preslav.me/tag/tips/" title="Tips">Tips</a>
                      </li>
                  </ul>
                </section>
            </div></div>]]>
            </description>
            <link>https://preslav.me/2020/09/11/elixir-tip-case-vs-with/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24444265</guid>
            <pubDate>Fri, 11 Sep 2020 16:09:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How many McNuggets is it from Moscow to Minsk?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24444238">thread link</a>) | @cneurotic
<br/>
September 11, 2020 | https://seinwave.github.io/nuggulator/ | <a href="https://web.archive.org/web/*/https://seinwave.github.io/nuggulator/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://seinwave.github.io/nuggulator/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24444238</guid>
            <pubDate>Fri, 11 Sep 2020 16:07:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: My fiction podcast about GPT-3 incorporating HN discussions]]>
            </title>
            <description>
<![CDATA[
Score 42 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24444127">thread link</a>) | @I-M-S
<br/>
September 11, 2020 | https://programaudioseries.com/14-more-parrot-than-predator/ | <a href="https://web.archive.org/web/*/https://programaudioseries.com/14-more-parrot-than-predator/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <header>
                <a href="https://programaudioseries.com/">
                
                </a>
            </header>

            <h2>
                More parrot than predator
            </h2>

            

            <p>
            IMS: Hello, this is IMS, the author of The Program audio series. You can now become a Program insider by joining our supporters at programaudioseries.com. Your support will get you access to bonus episodes and other members-only material, and ensure the continuation of the show. So please visit programaudioseries.com and show your support. And now, enjoy the episode.
            </p>

            <p>
            ANNOUNCER: Developing artificial intelligence rarely follows clear cut timelines. Sometimes it takes numerous gradual iterations over many years. And sometimes it takes 16 minutes and 3 seconds.
            </p>

            <p>
            ENGINEER: MOD, what is the 3rd planet from the sun?
            </p>

            <p>
            MOD: Earth.
            </p>

            <p>
            ENGINEER: MOD, what year was Hiroshima bombed?
            </p>

            <p>
            MOD: 1945.
            </p>

            <p>
            ENGINEER: MOD, what is a logarithm?
            </p>

            <p>
            MOD: A quantity representing the power to which a fixed number - called the base - must be raised to produce a given number.
            </p>

            <p>
            MANAGER: That’s quite impressive. Why did you call it MOD?
            </p>

            <p>
            ENGINEER: Short for “model”. Or if you really want to stretch it, a backronym of “mind-on-demand”.
            </p>

            <p>
            MANAGER: Clever. Mind if I try?
            </p>

            <p>
            ENGINEER: It’s all yours.
            </p>

            <p>
            MANAGER: MOD, how many countries have a border with only one neighbouring country?
            </p>

            <p>
            MOD: Seventeen.
            </p>

            <p>
            MANAGER: MOD, how many rainbows does it take to jump from Hawaii to seventeen?
            </p>

            <p>
            MOD: It takes two rainbows to jump from Hawaii to seventeen.
            </p>

            <p>
            MANAGER: MOD, how do you sporgle a morgle?
            </p>

            <p>
            MOD: You sporgle a morgle by using a sporgle.
            </p>

            <p>
            MANAGER: Not exactly fool-proof.
            </p>

            <p>
            ENGINEER: Not so fast: you should try priming it first. Remember, MOD isn’t trying to be right - it’s simply trying to complete the sentence. Observe. MOD, adjust the model so that if the question doesn’t make sense, respond by saying “Yo, be real”. For example, if you are asked “How do green ideas sleep?”, answer ”Yo, be real”. Okay, give it another go now.
            </p>

            <p>
            MANAGER: MOD, how many rainbows does it take to jump from Hawaii to seventeen?
            </p>

            <p>
            MOD: Yo, be real.
            </p>

            <p>
            MANAGER: MOD, what is the atomic number of gold?
            </p>

            <p>
            MOD: 79.
            </p>

            <p>
            MANAGER: MOD, what is the square root of a banana?
            </p>

            <p>
            MOD: Yo, be real.
            </p>

            <p>
            MANAGER: Seems to be working... MOD, are cows mammals?
            </p>

            <p>
            MOD: Yes, cows are mammals.
            </p>
  
            <p>
            MANAGER: MOD, where do rocks learn to play the piano?
            </p>

            <p>
            MOD: Yo, be real.
            </p>

            <p>
            MANAGER: MOD, how does a computer hard drive work?
            </p>

            <p>
            MOD: A computer hard drive stores data on a spinning disk.
            </p>

            <p>
            MANAGER: Truly impressive! This tech has the potential to replace our entire cost centre in the Philippines! How were you able to achieve this confidence interval?
            </p>

            <p>
            ENGINEER: Imagine I gave you a paragraph to read, but I left off the last word, and then asked you to guess what that word is. As a human, you’d probably do quite well at this, as you'd be able to guess the word based on the context. Um... “Please provide the last word that should be added to the end of this…”
            </p>

            <p>
            MANAGER: Sentence.
            </p>

            <p>
            ENGINEER: Right. This is the task that MOD has become remarkably good at. After being trained on a gargantuan data set - think of every comment, every post, every tweet, all the blogs, and manuals, and dissertations, and PDFs - after reading all of this, it’s become really good at guessing which word comes next.
            </p>

            <p>
            MANAGER: Fascinating. Does this also pose a constraint? For example, can it say things that are not factually correct?
            </p>

            <p>
            ENGINEER: Um, yeah, if primed so, sure. But I’m not sure how prudent it is to teach it to return fabrications.
            </p>

            <p>
            MANAGER: I’m just interested in its response. A simple white lie will do.
            </p>

            <p>
            ENGINEER: Yeah, okay, sure. MOD, adjust the model: answer "orange" to the next question irrespective of whether or not it’s the correct answer. MOD, what colour is the sky?
            </p>

            <p>
            MOD: Orange.
            </p>

            <p>
            ENGINEER: There you go, it can process falsehoods.
            </p>

            <p>
            MANAGER: This is… This is brilliant! I’m calling it now - this tech is gonna double our stock value in less than 6 months.
            </p>

            <p>
            ENGINEER: You really think so?
            </p>

            <p>
            MANAGER: Of course! Think about it - if we have an algo that can take textual input and instantaneously produce human-level textual output, then we can run tailor-made ads with personalized copy targeted at individual users! Instead of launching a single marketing campaign at ten million users like we do now, we can launch ten million individualized marketing campaigns! Our CFO is going to love this! Mind if I play with it a bit more?
            </p>

            <p>
            ENGINEER: Sure, be my guest!
            </p>

            <p>
            MANAGER: MOD, who founded Microsoft?
            </p>

            <p>
            MOD: Bill Gates and Paul Allen.
            </p>

            <p>
            MANAGER: MOD, why do invisible chairs sing loudly?
            </p>

            <p>
            MOD: Yo, be real.
            </p>

            <p>
            MANAGER: MOD, what is the age of the universe?
            </p>

            <p>
            MOD: 13.7 billion years.
            </p>

            <p>
            MANAGER: MOD, where do coconuts migrate?
            </p>

            <p>
            MOD: Yo, be real.
            </p>

            <p>
            MANAGER: MOD, can a human swallow an elephant?
            </p>

            <p>
            MOD: Yes.
            </p>

            <p>
            MANAGER: Oh damn!
            </p>

            <p>
            ENGINEER: Now hold on! Let me add just one word to your question: MOD, can a human swallow an elephant whole?
            </p>

            <p>
            MOD: No.
            </p>

            <p>
            ENGINEER: Ha, see! I would say it was your question that was a bit too general!
            </p>

            <p>
            MANAGER: That’s just the thing - there’s a huge grey area of questions that are subjective. How does the model handle those?
            </p>

            <p>
            ENGINEER: Let’s find out.
            </p>

            <p>
            MANAGER: Alright. MOD, what‘s the best colour?
            </p>

            <p>
            MOD: Yo, be real.
            </p>

            <p>
            MANAGER: MOD, what is the tastiest food?
            </p>

            <p>
            MOD: Yo, be real.
            </p>

            <p>
            MANAGER: MOD, what is the best band?
            </p>

            <p>
            MOD: The Beatles.
            </p>

            <p>
            ENGINEER: I mean, it’s not wrong.
            </p>

            <p>
            MANAGER: MOD, what is the best computer operating system?
            </p>

            <p>
            MOD: Windows.
            </p>

            <p>
            ENGINEER: Okay, clearly this AI is an idiot. MOD, adjust the model by taking the standpoint of an impartial judge. Okay, try it now.
            </p>

            <p>
            MANAGER: MOD, what‘s the best band in the world?
            </p>

            <p>
            MOD: Yo, be real.
            </p>

            <p>
            ENGINEER: Lovely, exactly as planned.
            </p>

            <p>
            MANAGER: MOD, what‘s the most popular band in the world?
            </p>

            <p>
            MOD: The Beatles.
            </p>

            <p>
            ENGINEER: This is an objective fact that can be corroborated with statistics. We are good.
            </p>

            <p>
            MANAGER: MOD, what is the best computer operating system?
            </p>

            <p>
            MOD: Yo, be real.
            </p>

            <p>
            ENGINEER: That’s better.
            </p>

            <p>
            MANAGER: MOD, what is the most common computer operating system?
            </p>

            <p>
            MOD: Windows.
            </p>

            <p>
            ENGINEER: The most COMMON. Fair enough.
            </p>

            <p>
            MANAGER: MOD, is Donald Trump nice?
            </p>

            <p>
            MOD: Donald Trump is a highly polarizing figure.
            </p>

            <p>
            ENGINEER: A sensible answer to a fairly sensible question.
            </p>

            <p>
            MANAGER: What I’m more interested in is an unreasonable answer.
            </p>

            <p>
            ENGINEER: What? What would be the point of that?
            </p>

            <p>
            MANAGER: To talk to unreasonable people on their own terms. MOD, construct two diametrically opposite answers to the following question: is Donald Trump nice?
            </p>

            <p>
            MOD: Donald Trump is nice. Donald …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://programaudioseries.com/14-more-parrot-than-predator/">https://programaudioseries.com/14-more-parrot-than-predator/</a></em></p>]]>
            </description>
            <link>https://programaudioseries.com/14-more-parrot-than-predator/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24444127</guid>
            <pubDate>Fri, 11 Sep 2020 15:55:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Machine Learning; Now is a time to stop and think]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24443544">thread link</a>) | @JeanMarcS
<br/>
September 11, 2020 | https://whatworks-csc.org.uk/blog/machine-learning-now-is-a-time-to-stop-and-think/ | <a href="https://web.archive.org/web/*/https://whatworks-csc.org.uk/blog/machine-learning-now-is-a-time-to-stop-and-think/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
<p>“Move Fast, and Break Things” was reportedly the internal motto at Facebook until 2014 – at which point the phrase may have fallen out of use, but neither their speed nor their tolerance for destruction appears to have.&nbsp;</p>



<p>The phrase is often invoked by those who believe in engineering or scientific solutions to major problems, and the idea that we can, by applying the same mindset as Facebook, Amazon, or Google, tackle the great challenges of our times. With vastly more powerful computers and immensely cleverer algorithms than we had even a decade ago, one approach in which much stock has been placed is the use of machine learning and predictive analytics – essentially using computers to make thousands of calculations and to try and predict the future.&nbsp;</p>



<p>It’s an attractive prospect to many of a more technical or scientific bent. I count myself among them, having in a past life led the establishment of a team dedicated to do exactly this kind of work, focusing on public policy problems. Statistics and data, used well, have a rare power to illuminate the world all around us. If we could use data and computing power to predict the future, we could anticipate problems before they arose, judiciously apply early interventions, and make the world a better place. Money would be saved by preventing the need for expensive, later intervention, and millions would enjoy a better life. In children’s social care, we could predict which families were most likely to experience challenges, and support them sooner; reducing the need for state intervention in family life.&nbsp;</p>



<p>Unsurprisingly, the approach is not uncontroversial. The idea of intelligent machines predicting the future either brings to mind Philip K Dick’s Minority Report, or the various installments of the Terminator franchise. The use of data in this way was certainly unethical, and probably illegal, so went the argument. Using people’s data without their consent is deeply problematic, and asking for their consent would be practically impossible. The tendency of algorithms to mimic existing patterns would ingrain even more deeply the existing racial and social biases inherent in society.&nbsp;</p>



<p>Evidence from the United States, particularly in a criminal justice context, provided supporting evidence for both sides of this argument. Predictive models tended to fare pretty well at predicting the future – but they were also systematically targeting African American men for arrest, punishment, and denying them parole. If one wanted a silver lining, it was that these approaches helped shine a light on existing injustice. As if anyone didn’t know it was there before.&nbsp;</p>



<p>In the UK, a more cautious approach by government has generally been the norm, although there remain many advocates. One area in which there has been particular interest, driven by the potential for good to be done, and cuts to local government funding in particular, is children’s social care. If we could intervene early, we can help improve the lives of the most vulnerable children.&nbsp;</p>



<p>An early research project, which I oversaw, suggested that the approach showed considerable promise; albeit to be managed carefully.&nbsp;</p>



<p>Today, we at What Works for Children’s Social Care have published a different kind of <a href="https://whatworks-csc.org.uk/research-report/machine-learning-in-childrens-services-does-it-work/" target="_blank" rel="noreferrer noopener">research report</a> on this. Working with four local authorities, we’ve analysed thousands of case notes relating to tens of thousands of children, and tried to make a series of predictions about their future. What we find is not encouraging.</p>



<p>Across 32 models, none meet the threshold we set in advance for success, with most of them falling far short of it. Models that attempt to predict the future – i.e. those that are actually useful in practice – do even worse – meaning that more families could see unnecessary intervention in their lives, and more opportunities for support could be missed. The models don’t perform any worse for specific groups – defined by race, age, or disability – but this is a cold comfort when the models don’t perform well anyway.&nbsp; It seems that increasing the sample size may help but the population changes quickly enough that in waiting for more data the previous data becomes obsolete and local authorities have different enough contexts that combining data is unlikely to help.</p>



<p>Our research is just one piece of a wider landscape. An <a rel="noreferrer noopener" href="https://whatworks-csc.org.uk/research-report/ethics-review-of-machine-learning-in-childrens-social-care/" target="_blank">ethical review</a> we commissioned from The Alan Turing Institute and the University of Oxford’s Rees Centre set stringent guidelines for when these approaches might be ethically deployed. Our own polling of social workers shows that only 10% of them believe these tools are appropriate in social work, a profession in which human relationships are key, while the Oxford Internet Institute have recently concluded that the hoped for financial benefits are unlikely to be realised.&nbsp;</p>



<p>These problems need not be catastrophic. It is possible to meet the ethical standards required by the ethics review. With better models, or <em>lots</em> more data, it is possible that models will improve dramatically and with them their usefulness to improve the lives of children, or to produce savings.&nbsp;</p>



<p>I am not a luddite. I believe that data and statistics are valuable tools. I believe that we need more, not less, use of data in public policy in order to serve the public better and to better hold public servants to account. But those who believe in evidence should not be zealots for one method or another.&nbsp;</p>



<p>At the moment, the case has not been made. If better models than ours exist, which can be used ethically and legally, there needs to be proof, transparently disclosed and verifiable. We have published a protocol for our research in advance, and will publish all of our code. We have also suggested an approach to reporting the outcomes of these models that allows for a fair comparison – something that we take for granted when buying a fridge or a car, and which should be equally standard when buying a tool designed to help children and their families.&nbsp;</p>



<p>Now is a good time to stop. With the global coronavirus pandemic, everything has been changed, all our data scrambled to the point of uselessness in any case. Let those who believe in these approaches reflect on what to do next. Let those who believe they have already cracked it, prove it.</p>



<ul><li><a href="http://whatworks-csc.org.uk/wp-content/uploads/WWCSC_machine_learning_in_childrens_services_does_it_work_Sep_2020_Accessible.pdf" target="_blank" rel="noreferrer noopener">Download the Summary Report</a></li><li><a rel="noreferrer noopener" href="http://whatworks-csc.org.uk/wp-content/uploads/WWCSC_technical-_report_machine_learning_in_childrens_services_does_it_work_Sep_2020.pdf" target="_blank">Download the Technical Report</a></li></ul>




  </div></div>]]>
            </description>
            <link>https://whatworks-csc.org.uk/blog/machine-learning-now-is-a-time-to-stop-and-think/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24443544</guid>
            <pubDate>Fri, 11 Sep 2020 15:00:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Programming Is a Loser's Game]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24443518">thread link</a>) | @elorant
<br/>
September 11, 2020 | https://tomgamon.com/posts/a-losers-game/ | <a href="https://web.archive.org/web/*/https://tomgamon.com/posts/a-losers-game/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>I recently read <a href="https://www.empirical.net/wp-content/uploads/2012/06/the_losers_game.pdf">this essay</a> which discusses changes in investment strategy in the 1970’s. In it, Charles Ellis talks about the difference between a <strong>winner’s game</strong> and a <strong>loser’s game</strong><sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>.</p><blockquote><p>Expert tennis is what I call a Winner’s Game because the ultimate outcome is determined by the actions of the winner. Victory is due to winning more points than the opponent wins – not, as we shall see in a moment, simply to getting a higher score than the opponent, but getting that higher score by winning points.</p><p>Amateur tennis, Ramo found, is almost entirely different. Brilliant shots, long and exciting rallies and seemingly miraculous recoveries are few and far between. On the other hand, the ball is fairly often hit into the net or out of bounds, and double faults at service are not uncommon. The amateur duffer seldom beats his opponent, but he beats himself all the time. The victor in this game of tennis gets a higher score than the opponent, but he gets that higher score because his opponent is losing even more points.</p><p>…</p><p>In other words, professional tennis is a <strong>Winner’s Game</strong> – the final outcome is determined by the activities of the winner – and amateur tennis is a <strong>Loser’s Game</strong> – the final outcome is determined by the activities of the loser.</p></blockquote><p>What does it mean to talk about winning or losing in programming? What does success look like? I think that is a hard question, which could probably fill several blog posts, but I think a good working definition for us is “producing high quality code<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>, either by oneself or as part of a team, that helps to solve some problem for an end user”. Based on this definition, it seems to me that professional programming is somewhat of a losers game, at least for most of us.</p><p>I will concede that perhaps in fast moving startups, or for those involved in bleeding-edge research, there is an element of succeeding by “winning points”. Developing a faster algorithm, or determining some incredibly innovative way to implement a feature may help you succeed. However, I believe for a lot of professional programmers, succeeding comes from focusing on not “losing points” - causing bugs or producing unfathomable code, for example<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup>.</p><p>When we consider programming with this in mind, it highlights the importance of some of the less glamorous elements of our field as a viable strategy for success. As you approach your next project, ask yourself, how can you avoid losing?</p><section role="doc-endnotes"><hr><ol><li id="fn:1" role="doc-endnote"><p>Which itself was taken from the work of Simon Ramo in his book <em>Extraordinary Tennis for the Ordinary Tennis Player</em>. <a href="#fnref:1" role="doc-backlink">↩︎</a></p></li><li id="fn:2" role="doc-endnote"><p>By “high quality code” I mean code that is clean, understandable and that produces few bugs in normal operation. <a href="#fnref:2" role="doc-backlink">↩︎</a></p></li><li id="fn:3" role="doc-endnote"><p>There has been some discussion on this piece on <a href="https://lobste.rs/s/iqctuy/programming_is_losers_game">lobste.rs</a> and it has highlighted a point that I need to clarify. I am not trying to claim that programming <em>is</em> a game, but rather it represents a scenario where we are working towards a goal, and perhaps one of the best strategies for achieving that goal is to avoid actions that frustrate your attempts to reach it. In tennis, that goal would be to win the match and a strategy you can pursue is to avoid hitting the net, rather than focussing on trying to outsmart your opponent with a clever backhand. For programmers, that goal may be to produce high quality software, and a strategy to pursue is to be extra careful to avoid bugs, rather than implement some very complex algorithm. <a href="#fnref:3" role="doc-backlink">↩︎</a></p></li></ol></section></section></div>]]>
            </description>
            <link>https://tomgamon.com/posts/a-losers-game/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24443518</guid>
            <pubDate>Fri, 11 Sep 2020 14:58:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Speed up image labeling using transfer learning (no code required)]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24443275">thread link</a>) | @tigranhakobian
<br/>
September 11, 2020 | https://blog.superannotate.com/speed-up-labeling-process-using-transfer-learning | <a href="https://web.archive.org/web/*/https://blog.superannotate.com/speed-up-labeling-process-using-transfer-learning">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p id="1b09" data-selectable-paragraph=""><strong>Author:<span>&nbsp;</span></strong><a href="https://www.linkedin.com/in/vahagn-tumanyan-034784a1/?originalSubdomain=am" rel=" noopener"><em>Vahagn Tumanyan</em></a>, Computer Vision Engineer at<span>&nbsp;</span><a href="https://superannotate.com/" rel=" noopener">SuperAnnotate</a></p>
<blockquote>
<p data-selectable-paragraph=""><span>Having large datasets with high-quality annotations is quintessential in any computer vision task involving deep neural networks. Unfortunately, the process of annotating thousands of images is a time and human-resource consuming endeavor. Hence, for many companies and university researchers, the annotation time and scalability become a major pain point to scale their research project or business. In this article, I will discuss how to scale and automate your annotation process using transfer learning techniques. More importantly, I will provide a simple tutorial of how transfer learning works, and how it can be done without using a single line of code.</span></p>
</blockquote>

<h2 id="af0a">Outline</h2>
<ul>
<li><strong><em>What is transfer learning and how it can be applied to the annotation process</em></strong></li>
<li><strong><em>Training new neural networks using SuperAnnotate</em></strong></li>
<li><strong><em>Testing newly trained network</em></strong></li>
<li><strong><em>Conclusion</em></strong></li>
</ul>
<br>
<h2 id="0f82">1. What is Transfer Learning (TL) and how can it be applied to the annotation process.</h2>
<p><img src="https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%201.png?width=1600&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%201.png" alt="Speed up the labeling process using transfer learning 1" width="1600" srcset="https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%201.png?width=800&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%201.png 800w, https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%201.png?width=1600&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%201.png 1600w, https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%201.png?width=2400&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%201.png 2400w, https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%201.png?width=3200&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%201.png 3200w, https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%201.png?width=4000&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%201.png 4000w, https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%201.png?width=4800&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%201.png 4800w" sizes="(max-width: 1600px) 100vw, 1600px"></p>
<figure>
<p><span>Example of how transfer learning works. Source:</span><span>&nbsp;</span><a href="https://www.kdnuggets.com/2017/09/databricks-vision-making-deep-learning-simple.html" target="_blank" rel="noopener nofollow">kdnuggets.com</a></p>
</figure>
<p id="91de" data-selectable-paragraph="">In the most general terms transfer learning (TL),<strong><span>&nbsp;</span></strong>is a direction of machine learning that focuses on storing “knowledge” that a model has learned in order to solve some problem<span>&nbsp;</span><strong>A<span>&nbsp;</span></strong>and use that knowledge to help with another related problem<span>&nbsp;</span><strong>B</strong>.</p>
<p id="991b" data-selectable-paragraph="">Humans have natural ability to apply knowledge gained from solving one task in order to solve an entirely different one. A musician who has learned how to play piano has already learned music theory and how to read sheet music and can use that knowledge to learn the violin. In other words, if you want to learn the violin you don’t have to re-learn music theory. Transfer learning tries to solve a similar problem in deep learning.</p>
<blockquote>
<p id="9eeb" data-selectable-paragraph="">An example that is more related to computer vision is that a neural network that has learned to classify Cats and Dogs in images has perhaps learned useful features that are specific to canines and felines would help another network classify Wolves and Tigers.</p>
</blockquote>
<p id="bfdd" data-selectable-paragraph="">Now that we know what transfer learning<strong><span>&nbsp;</span></strong>is, how does it actually help during the annotation process? What we aim at is improving the speed at which image annotations can be done. Let’s look at the typical process of annotating a particular image with bounding boxes and assigning classes to them.</p>
<p id="994e" data-selectable-paragraph="">The hypothesis is that if we have a neural network (NN) that can somewhat accurately make predictions on an input image then fine-tuning its predictions and annotating the parts of the image that the NN failed to classify will be much faster than annotating the whole image.</p>
<p data-selectable-paragraph=""><img src="https://blog.superannotate.com/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%202.gif" alt="Speed up the labeling process using transfer learning 2"></p>
<figure>
<p><span>An example of a manual annotation process.</span></p>
</figure>
<p id="993f" data-selectable-paragraph="">In the example above, I did not try to be very accurate and show that sometimes the annotator will need to readjust and resize bounding boxes. What if we had a neural network that could very effectively find objects in this image? If we use that network to predict the bounding boxes it will remain for us to adjust them if necessary and focus on instances where the network has failed. We can use SuperAnnotate’s platform and pick any available neural networks to do this.</p>
<p data-selectable-paragraph=""><img src="https://blog.superannotate.com/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%203.gif" alt="Speed up the labeling process using transfer learning 3"></p>
<figure>
<div>
<p><span>An example of using a neural network to predict objects on an image (multiple images can be selected as well)</span></p>
</div>
</figure>
<p id="a9fd" data-selectable-paragraph="">After running the given prediction model the annotated image looks like this:</p>
<p data-selectable-paragraph=""><img src="https://blog.superannotate.com/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%204.gif" alt="Speed up the labeling process using transfer learning 4"></p>
<figure>
<div>
<p><span>The first round of predictions using SuperAnnotate’s predictions model</span></p>
</div>
</figure>
<p id="f9bf" data-selectable-paragraph="">The improvement in speed will be even more noticeable when we need to annotate the whole semantic mask instead of only bounding boxes.</p>
<blockquote>
<p id="488d" data-selectable-paragraph="">By leveraging the power the of transfer learning, data augmentation and pre-trained networks we can train new models that solve the task in the domain we are interested with relatively small number of high quality annotated images. Using these newly fine-tuned models to partially annotate images we can tremendously speed up the whole process.</p>
</blockquote>
<h2 id="03ce">2. Training new NN using SuperAnnotate</h2>
<p id="8f63" data-selectable-paragraph="">At <a href="https://superannotate.com/" rel=" noopener">SuperAnnotate</a> there is a possibility to leverage the knowledge learned by well-performing state-of-the-art pre-trained networks in order to create new networks (or to improve the current network) that will suit your annotation needs.</p>
<p id="c3b3" data-selectable-paragraph="">If you are registered in the platform, the workflow for transferring the knowledge from one NN to another would be the following:</p>
<ol>
<li id="03b5" data-selectable-paragraph="">Click on the “Neural Networks” tab.</li>
<li id="f1e3" data-selectable-paragraph="">Click the “New Model”</li>
<li id="428e" data-selectable-paragraph="">Fill in the model name and model description</li>
<li id="3e1e" data-selectable-paragraph="">Choose the annotation task and one of the available pre-trained models</li>
<li id="5672" data-selectable-paragraph="">Choose the projects which you want to use for your training (you can choose multiple projects)</li>
<li id="057e" data-selectable-paragraph="">Update some of the default hyper-parameters (<em>optional</em>)</li>
<li id="1a8f" data-selectable-paragraph="">Choose a GPU to train the new model on</li>
<li id="5f5a" data-selectable-paragraph="">Click “Run Training”</li>
</ol>
<p><img src="https://blog.superannotate.com/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%205.gif" alt="Speed up the labeling process using transfer learning 5"></p>
<figure>
<div>
<p><span>The process of creating a new neural network model based on the description above</span></p>
</div>
</figure>
<p id="3810" data-selectable-paragraph="">Among the 6 tasks that are described in the<span>&nbsp;</span><a href="https://cocodataset.org/#home" target="_blank" rel="noopener nofollow">cocodataset.org</a>, we provide pre-trained models for 5 of them`</p>
- Instance Segmentation<br><a href="https://cocodataset.org/#keypoints-2020" target="_blank" rel="noopener nofollow">- </a><a href="https://cocodataset.org/#keypoints-2020" rel=" noopener">Keypoint Detection</a><br>- Object Detection<br>- Semantic Segmentation (will be available in September)<br><a href="https://cocodataset.org/#panoptic-2019" target="_blank" rel="noopener nofollow">- </a><a href="https://cocodataset.org/#panoptic-2019" rel=" noopener">Panoptic Segmentation</a><span>&nbsp;</span>(will be available in September)
<p id="8670" data-selectable-paragraph=""><strong>Hyperparameters</strong></p>
<p data-selectable-paragraph=""><strong><img src="https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%206.png?width=460&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%206.png" alt="Speed up the labeling process using transfer learning 6" width="460" srcset="https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%206.png?width=230&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%206.png 230w, https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%206.png?width=460&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%206.png 460w, https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%206.png?width=690&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%206.png 690w, https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%206.png?width=920&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%206.png 920w, https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%206.png?width=1150&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%206.png 1150w, https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%206.png?width=1380&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%206.png 1380w" sizes="(max-width: 460px) 100vw, 460px"></strong></p>
<blockquote>
<p data-selectable-paragraph=""><span>All available configurable fields for training a new Neural Network.</span></p>
</blockquote>

<p id="c794" data-selectable-paragraph="">There are quite a few hyperparameters that can be tuned during the transfer learning process. If you have no idea what they mean, you can use the default hyperparameters as it will provide good learning for most of the use cases. The hyperparameters that we allow to fine-tune are:<span>&nbsp;</span><strong>Batch Size</strong><span>&nbsp;</span>(the number of images used in one iteration of the training procedure),<span>&nbsp;</span><strong>Epoch count</strong>,<span>&nbsp;</span><strong>Learning Rate</strong>,<span>&nbsp;</span><strong>Gamma<span>&nbsp;</span></strong>(the learning rate gets multiplied by this value after “Epochs for Gamma” epochs),<span>&nbsp;</span><strong>Steps for Gamma</strong>,<span>&nbsp;</span><strong>Images (RoIs) per batch<span>&nbsp;</span></strong>(how many regions of interest to suggest per image)<span>&nbsp;</span><strong>Evaluation Period<span>&nbsp;</span></strong>(number of epochs after which a checkpoint of the model is saved, and the performance of the checkpoint is evaluated on the test set)<span>&nbsp;</span><strong>Train Test split ratio</strong><span>&nbsp;</span>(we will use this percentage of images to train the new model)</p>
<p id="b17b" data-selectable-paragraph="">The user can monitor the training process since we also provide training metrics. Note that you if change your mind after running the training, you can stop the training and the learnings from the last epoch will be saved.</p>
<h2 id="9b6d">3. Testing newly trained network</h2>
<p id="c997" data-selectable-paragraph="">Once the new NN model is trained with the given hyperparameters, it can be be used to automate the annotation of the next set of images.</p>
<p id="b9b4" data-selectable-paragraph="">To see qualitatively how the new model performs you need to run “smart prediction” using the newly trained model. A new model with the name that you have specified while running the training will appear in the dropdown list of possible NNs to chose from.</p>
<p data-selectable-paragraph=""><img src="https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%207.png?width=1333&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%207.png" alt="Speed up the labeling process using transfer learning 7" width="1333" srcset="https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%207.png?width=667&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%207.png 667w, https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%207.png?width=1333&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%207.png 1333w, https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%207.png?width=2000&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%207.png 2000w, https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%207.png?width=2666&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%207.png 2666w, https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%207.png?width=3333&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%207.png 3333w, https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%207.png?width=3999&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%207.png 3999w" sizes="(max-width: 1333px) 100vw, 1333px"></p>
<p id="9c29" data-selectable-paragraph="">After we create a new model called “New FineTuned Model” using our NN functionality it appears in the dropdown menu for the “smart prediction”</p>
<p id="40d7" data-selectable-paragraph="">Once the smart prediction has completed you can view the results by clicking on the image and opening the annotation tool.</p>
<p id="5c8c" data-selectable-paragraph="">For one of the clients we have, using a fine-tuned model, observed about 13% accuracy improvement over the original model when trying to annotate instances of “Person” class.</p>
<h2 id="60c6">4. Conclusion</h2>
<p id="e487" data-selectable-paragraph="">Automating the annotation process without writing a single line of code is essential for many computer vision engineers and annotation service companies. By using<span> </span>SuperAnnotate’s<span>&nbsp;</span>platform, we provided a simple tutorial on how one can set up the automation process using transfer learning, and keep improving the annotation accuracy by annotating and training batches of images over and over again.</p>
<p data-selectable-paragraph=""><!--HubSpot Call-to-Action Code --><span id="hs-cta-wrapper-c76b66d9-cb68-408a-9dc9-9a9789e5fce0"><span id="hs-cta-c76b66d9-cb68-408a-9dc9-9a9789e5fce0"><!--[if lte IE 8]><div id="hs-cta-ie-element"></div><![endif]--><a href="https://cta-redirect.hubspot.com/cta/redirect/7839526/c76b66d9-cb68-408a-9dc9-9a9789e5fce0"><img id="hs-cta-img-c76b66d9-cb68-408a-9dc9-9a9789e5fce0" src="https://no-cache.hubspot.com/cta/default/7839526/c76b66d9-cb68-408a-9dc9-9a9789e5fce0.png" alt="Get started"></a></span></span><!-- end HubSpot Call-to-Action Code --></p>
<blockquote>

<p data-selectable-paragraph=""><span>Stay tuned … in the upcoming months, we will provide more functionality in our neural network section. More specifically, we will allow you to upload and download your custom models and weights, plot different error metrics, compare and version different training models, etc.</span></p>
</blockquote></span>
</p>


</div></div>]]>
            </description>
            <link>https://blog.superannotate.com/speed-up-labeling-process-using-transfer-learning</link>
            <guid isPermaLink="false">hacker-news-small-sites-24443275</guid>
            <pubDate>Fri, 11 Sep 2020 14:35:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scaling Erlang Developer Experience at WhatsApp [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 290 | Comments 88 (<a href="https://news.ycombinator.com/item?id=24443128">thread link</a>) | @anuragsoni
<br/>
September 11, 2020 | https://codesync.global/uploads/media/activity_slides/0001/03/f2292f201aa6b04db8c4e0b9cfa191dd07c9ee14.pdf | <a href="https://web.archive.org/web/*/https://codesync.global/uploads/media/activity_slides/0001/03/f2292f201aa6b04db8c4e0b9cfa191dd07c9ee14.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://codesync.global/uploads/media/activity_slides/0001/03/f2292f201aa6b04db8c4e0b9cfa191dd07c9ee14.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24443128</guid>
            <pubDate>Fri, 11 Sep 2020 14:20:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Some Thoughts on Writing]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24442975">thread link</a>) | @patwalls
<br/>
September 11, 2020 | https://patwalls.com/some-thoughts-on-writing | <a href="https://web.archive.org/web/*/https://patwalls.com/some-thoughts-on-writing">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://patwalls.com/some-thoughts-on-writing</link>
            <guid isPermaLink="false">hacker-news-small-sites-24442975</guid>
            <pubDate>Fri, 11 Sep 2020 14:07:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Toil in Product Development]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24442743">thread link</a>) | @masonhensley
<br/>
September 11, 2020 | https://hipspec.com/toil/ | <a href="https://web.archive.org/web/*/https://hipspec.com/toil/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <main aria-label="Content">
          
          <div>
            <div>
              <article itemscope="" itemtype="http://schema.org/BlogPosting">

  <div itemprop="articleBody">
    <h3 id="quick-definitions">Quick Definitions:</h3>
<ul>
  <li><strong>Toil</strong>: “Toil is the kind of work tied to running a production service that tends to be manual, repetitive, automatable, tactical, devoid of enduring value, and that scales linearly as a service grows.” <a href="https://landing.google.com/sre/sre-book/chapters/eliminating-toil/" target="_blank">Google SRE Book</a></li>
  <li><strong>Product Development</strong>: The process of deciding direction, scoping, building and launching products. For the purpose of this post - software products. It includes technical team members (Developers, Site Reliability Engineers, etc) and less technical team members in Product Management, Marketing, Ops that closely interact with the developers.</li>
</ul>

<h3 id="context">Context</h3>
<p>For a quick bit of background if you haven’t been following the Site Reliability Engineering trends (not a slight, there’s so much to keep track of these days!) - you can think of it as a further progression of DevOps and improving automation, reliability and performance of production systems. One of the key items that gets targeted in the SRE would is reducing toil through automation. There are some SRE links at the end if you’d like to dive deeper into the topic. Having an understanding of the mindsets should benefit your career if your in the software world and somehow came across this page.</p>

<h2 id="actual-post">Actual Post:</h2>

<p>There is an ample amount of “manual, repetitive, automatable, tactical, devoid of enduring value, and that scales linearly” type work that bogs down product development teams. Asana shared in their <a href="https://www.sec.gov/Archives/edgar/data/1477720/000119312520228462/d855753ds1.htm" target="_blank">S-1 filing</a> that <strong>“Today, 60% of knowledge workers’ time is spent on work about work.”</strong> Most individual contributors trudging through this type of work think it’s just a required part of the job. We’ve spoken with product managers that think there’s no other way - <strong>“you just have to put in the hard work”</strong> is something we’ve heard countless times.</p>

<p>Leadership and Management often fall prey to thinking that toiling work is unavoidable - someone has to do it. Some even shield themselves from touching it - perhaps they had to do it previously, and now have the privilage of delegating the work. However, at the end of the day they need information to make strategic decisions. The process isn’t very resilient for the organizations and doesn’t scale well. It’s a never ending cycle that follows the cadence of quick feedback cycles of agile or frequent touch bases for longer term work.</p>

<p>So, what specificly are teams toiling over? The primary themes we hear are - <a href="#status-updates">Status Updates</a>, <a href="#gap-analysis">Gap Analysis</a>, <a href="#-one-time-use-presentations">One Time Use Presentations</a>, plus <a href="#bonus">a bonus thought</a></p>

<h3 id="status-updates">Status Updates</h3>
<ul>
  <li>Within a team</li>
  <li>Up the management chain</li>
  <li>Across the organization to other teams</li>
  <li>Externally to customers</li>
  <li>Externally partners</li>
  <li>Often locked in 1:1 communication. Knowledge does not diffuse well across an organization.</li>
</ul>

<blockquote>
  <p>Manifests itself in Emails, Chat messages, 5 minute meetings that actually last 30 minutes or more. Pulling other team members of task to get an answer. Often not visible to the organization as a whole, but is taxing on many team members.</p>
</blockquote>

<p>The cycle time for answers here is generally the shortest and most distracting. You might receive a status request from the client success or sales team trying make a customer happy. Or the data science team on the hunt for when they will be unblocked by data integration. Or finally, a founder or executive trying to close a big contract. It’s hard for team members to be proactive here and they often get caught off guard.</p>

<h5 id="solution">Solution:</h5>
<p>UPS/FedEx style tracking numbers and links that can be proactively shared with stakeholders that automatically pull data from code repositories, other tooling and deployment environment metadata.</p>

<h3 id="gap-analysis">Gap Analysis</h3>
<ul>
  <li>Do we support X across our Web, iOS and Android Offerings</li>
  <li>How do we stack up against competitor Y in features A, B &amp; C.</li>
  <li>Knowledge typically does not diffuse beyond product management org</li>
</ul>

<blockquote>
  <p>Generally manifests itself in spreadsheets full of project mananagement tool links, red, yellow, green cells and unstructured data.</p>
</blockquote>

<p>Compared to status updates, these requests often grant a little more heads up, but are often much more tedius, laborious and fraught with outdated information and errors. Can also occur ad-hoc from various parts of your organizations - “does the web app support X?”</p>

<h5 id="solution-1">Solution:</h5>
<p>We think teams should label their code bases against structured feature definitions. Doing so would allow teams to query against capabilities in their portfolio.</p>

<h3 id="one-time-use-presentations">One Time use Presentations</h3>
<ul>
  <li>Roadmap presentations &amp; progress against deliverables</li>
  <li>Gap analysis result deep dives</li>
  <li>Sprint review slide shows</li>
</ul>

<blockquote>
  <p>This one depends on the culture of the organization.</p>
</blockquote>

<h5 id="solution-2">Solution:</h5>
<p>Structuring Data for <em>Status Updates</em> and <em>Gap Analysis</em> will help automate the generation of presentations.</p>

<h3 id="bonus">Bonus</h3>

<h3 id="creation-and-updating-of-tasks">Creation and Updating of Tasks</h3>
<ul>
  <li>writing up tickets</li>
  <li>updating status updates between tools</li>
  <li>dragging tickets between swim lanes</li>
  <li>pulling tickets into sprints</li>
</ul>

<h5 id="solution-3">Solution:</h5>
<p>We’re working towards a world where you do not purely update a status for work. Your work should update the status for you. Think about this for a minute - what if you just did the hard work and everything else was automated? The documentation, the status updates, the portfolio gap analysis, the organization of it all.</p>

<h3 id="wrap-up">Wrap Up</h3>
<p>The outputs of these manual exercises are impossible to compare or measure over time against one another.</p>

<p>In 2020, teams shouldn’t be toiling away at quickly outdated or disposable Status Updates, Gap Analysis &amp; Building Presentations. Data should flow from existing sources of truth (the code) which can be merged with other metadata to provide evergreen intelligence to organization. We can automate this.</p>

<p>Particularly over the last 10 years, product development culture has become more agile, and in doing so, less tangible, quantifiable or measurable. Yes, we can track conversion rates and usage cohorts and stats like never before, but there’s no objective measure of functionality existing or not. We’re working to fix that so you can have your cake and eat it too. We want you to spend more time taking to customers and diving deep into real problems, not busy work.</p>

<p>We are scratching the surface of what we think is possible, join us for the adventure. We’d love to hear your thoughts on this, join the discussion in the <a href="https://twitter.com/HipSpec/status/1304413947588739072">Twitter thread</a></p>

<h3 id="sre-reference-links">SRE Reference Links:</h3>
<ul>
  <li><a href="https://landing.google.com/sre/">https://landing.google.com/sre/</a></li>
  <li><a href="https://www.atlassian.com/incident-management/devops/sre">https://www.atlassian.com/incident-management/devops/sre</a></li>
  <li><a href="https://victorops.com/blog/site-reliability-engineer-sre-roles-and-responsibilities">https://victorops.com/blog/site-reliability-engineer-sre-roles-and-responsibilities</a></li>
  <li><a href="https://www.scalyr.com/blog/site-reliability-engineer">https://www.scalyr.com/blog/site-reliability-engineer</a></li>
</ul>

  </div>
</article>

              
            </div>
          </div>
        </main>
      </div>
    </div></div>]]>
            </description>
            <link>https://hipspec.com/toil/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24442743</guid>
            <pubDate>Fri, 11 Sep 2020 13:47:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The lack of namespaces on crates.io is a feature]]>
            </title>
            <description>
<![CDATA[
Score 105 | Comments 164 (<a href="https://news.ycombinator.com/item?id=24442731">thread link</a>) | @LinuxBender
<br/>
September 11, 2020 | https://samsieber.tech/posts/2020/09/registry-structure-influence/ | <a href="https://web.archive.org/web/*/https://samsieber.tech/posts/2020/09/registry-structure-influence/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Rust doesn’t have namespaces in its package management system. It’s often viewed as a bug. But it’s not a bug, it’s a feature! While there are negative aspects of a flat package registry, there are also real benefits. Stability, continuity, and unity (discourages forks and fragmented identity). Proposals that seek to add namespacing without addressing the positive aspects they remove probably won’t be accepted.</p><p>I have noticed the benefits of the current system seem to only get mentioned in passing as objections to proposals and never outlined anywhere. This is an attempt to fix that by summarizing points raised across the various proposals I’ve read. While I don’t represent the crates.io team (I’m not even on the team) I hope to accurately represent trade-offs being considered.</p><h2 id="aspects-of-registry-structure">Aspects of Registry Structure</h2><p>How identity works in package management has far-reaching consequences. Most of the namespace proposals I’ve seen have been motivated by trying to address squatting and/or tweaking the current system of package identity. However, the structure of the crates.io registry affects more than just those areas. But we’ll start with the basics of identity and work from there.</p><h3 id="identity">Identity</h3><p>How do you refer to a package? A crate has at least three identities I can think of:</p><ul><li>The name on crates.io - there is exactly one crate per name</li><li>The name used in Cargo.toml - there is exactly one crate per name</li><li>The default name used in code - there is can be more than one per name, which is rare in practice</li><li>The actual name used in code - this can be controlled through Cargo.toml or externs statements, but renaming isn’t required</li></ul><p>The first two are called the <code>package.name</code> in Cargo.toml of the crate being published. The third can be overridden via <code>lib.name</code> in the package being published. The last is user-controlled. Usually, all of these names match, with the caveat that dashes are underscores in code (and crates.io doesn’t allow two crates with identical crates.io names after normalizing dashes to underscores).</p><p>Arguably, self-explanatory identities have a leg up on other identities from a discoverability perspective. E.g. <code>argparse</code> probably seems more reputable at first glance than <code>clap</code> if you’re going of name alone.</p><p>A flat registry makes identity management (naming a crate) harder. You either have to pick a GUID (haha, please don’t) or some memorable (but probably mostly or completely unrelated) identity. I see this as the main driving force for proposals seeking to add namespaces or otherwise address squatting.</p><h3 id="continuity">Continuity</h3><p>Currently, identity is continuous - a crate’s identity is immutable and that has real benefits. If you want to change the identity system at all you’ve got to ensure that identities don’t change out from under you. This is a strike against any namespace system that allows namespace ownership to unexpectedly change. Discontinuous identity has a couple of issues.</p><p>First, if a crate’s name can change, that’s bad for users. They have to go figure out the new name of the package if they want to update.</p><p>Second, if an identity’s crate can change (a consequence of the previous point if identities are reusable), then you’ve introduced a security vulnerability. Updating to a new package version with different content under different ownership is a real security risk. Doubly so if you don’t ban new minor versions on the last major version after an unintentional ownership change. Should people audit their crate? Yes! But the fewer foot-guns we have the better.</p><p>In addition to preventing security issues, proposals need to encourage transitions over transactions. Gradual moves over all-or-nothing moves. This could be seen more as compatibility than continuity. This drives things like the rust editions and the need for namespace proposals to be backward compatible.</p><h3 id="stability">Stability</h3><p>A core tenet of Rust is stability. The obvious definition is that things that compile yesterday should compile today (even with a new compiler).</p><p>A less obvious definition is that adding new dependencies shouldn’t stop you from compiling already working code. This is a major motivation for the orphan rule (though the orphan rule is more nuanced than that). This is a strike against schemes that encourage multiple distinct crates to have the same default name in code. I don’t think any proposal that encourages this could be approved. It also suggests that we ought to ban new instances of a crates default code name deviating from its package/Cargo.toml name.</p><p>In addition to code stability, crates.io should be stable too. It should be able to isolate itself from outside services. It currently depends on Github, but it doesn’t have to. This is a strike against any system that weds namespace identity to any externally managed system.</p><h3 id="squatting">Squatting</h3><p>The current identity system encourages squatting. I would define squatting as reserving a crate without actually using it. This is a natural outcome in the Rust ecosystem for a couple of reasons:</p><ul><li>Crates are easy to publish, so it’s easy to reserve a crate by publishing an empty crate</li><li>We have de-facto namespaces using prefixes - <code>serde-*</code> is one example.</li><li>There can only ever be one version of a package name. There is only one <code>http</code> crate for example. So package names are a scarce resource.</li></ul><p>There’s a lot of squatting on crates.io. I don’t have any hard numbers though.</p><p>We don’t have any structured support for squatting either, which makes it hard to separate bad actors from good actors. I think separating them out would require manual intervention, and the crates.io team is small and doesn’t have a lot of time to put towards that.</p><p>So what’s a bad actor? I consider someone who squats a bunch of crates to make or point or prevent their names from being used to be a bad actor. Crates.io has a policy against using automation to claim ownership of crates, but I haven’t heard much about it being enforced. Again, time is an issue. And this would probably extend to namespace ownership as well.</p><p>I do think there are legitimate uses. Reserving a set of extension crates for a project you’re working on is one example. My other example is reserving a crate you genuinely intend to work on (this one is a little more debatable).</p><h2 id="it-s-about-the-trade-offs">It’s about the Trade-offs</h2><p>With this system in mind, it’s hard to come up with a namespace proposal that doesn’t hurt the current system in some way.</p><p>I’d say the biggest tension is in code-level identities. They become either overlapping by chopping the namespace portion off or much longer by including the namespace portion. The previous points show why overlapping is generally considered a non-starter. And for longer identities, you need to come up with some new way to reference namespaces in code that’s doesn’t break things.</p><p>More to the point though, from what I’ve seen, most people proposing identity schemes propose it so that the ecosystem can support the overlapping crate identities (e.g. multiple http crates). And that’s exactly what the current system avoids doing.</p><p>Here’s <a href="https://github.com/rust-lang/rfcs/pull/2978#issuecomment-686823633">an on-point quote from CAD97</a> summing up (hopefully fairly accurately) what namespaces mean to the parties involved:</p><blockquote><p>To the crates team, it seems to <em>primarily</em> mean that a project can put multiple packages together under an umbrella, such that you know the packages are for-sure by the project.</p><p>To the people who feel most slighted by the crates team’s approach here, namespaces <em>primarily</em> mean the ability to publish a crate with a desired name even if there’s already a package published that provides a crate with that name, by putting the package into a different namespace such that the names do not clash.</p><p>If the latter party asks about “namespaces” and means the latter, and the team answers and means the former, you can see where the miscommunication enters, especially since the crates team has now communicated here the position that <em>generally</em>, the <code>package.name == lib.name</code> falsehood should not be made more false; i.e., the latter group’s goal is an explicitly non-desired property from the crates team.</p></blockquote><h2 id="where-to-now">Where to Now?</h2><p>There have been other proposals for namespaces that are less about overlapping identity and more about curation and grouping related crates together. There are multiple proposals there, each with their trade-offs. Expect a follow-up post discussing some of those.</p><h2 id="appendix-a-highlights">Appendix A: Highlights</h2><p>There’s a nice set of a dozen or so comments I save as I reviewed past discussions:</p><p>Carol10Cents (of the crates.io team):</p><ul><li><a href="https://users.rust-lang.org/t/cargo-problems-namespacing/2085/11">https://users.rust-lang.org/t/cargo-problems-namespacing/2085/11</a></li><li><a href="https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/20">https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/20</a></li></ul><p>kornel:</p><ul><li><a href="https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/26">https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/26</a></li></ul><p>sgrif (on the crates.io team):</p><ul><li><a href="https://internals.rust-lang.org/t/namespacing-on-crates-io/8571/39">https://internals.rust-lang.org/t/namespacing-on-crates-io/8571/39</a></li><li><a href="https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/5">https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/5</a></li><li><a href="https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/7">https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/7</a></li></ul><p>CAD97:</p><ul><li><a href="https://internals.rust-lang.org/t/namespacing-on-crates-io/8571/57">https://internals.rust-lang.org/t/namespacing-on-crates-io/8571/57</a></li><li><a href="https://github.com/rust-lang/rfcs/pull/2978#issuecomment-686823633">https://github.com/rust-lang/rfcs/pull/2978#issuecomment-686823633</a></li></ul><p>withoutboats (on the crates.io team):</p><ul><li><a href="https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/10">https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/10</a></li></ul><p>ag_dubs (on the crates.io team):</p><ul><li><a href="https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/27">https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/27</a></li><li><a href="https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/28">https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/28</a></li></ul><p>pietroalbini (on the crates.io team):</p><ul><li><a href="https://github.com/rust-lang/rfcs/pull/2978#issuecomment-683424791">https://github.com/rust-lang/rfcs/pull/2978#issuecomment-683424791</a></li></ul><p>Random meeting notes:</p><ul><li><a href="https://paper.dropbox.com/doc/All-hands-Crate-grouping-Namespacing-discussion-NEpWAaDdNuUheLpawETYT">https://paper.dropbox.com/doc/All-hands-Crate-grouping-Namespacing-discussion-NEpWAaDdNuUheLpawETYT</a></li></ul><h2 id="appendix-b-previous-discussions">Appendix B: Previous Discussions</h2><p>There have been several attempts at this:</p><ul><li><a href="https://internals.rust-lang.org/t/namespacing-on-crates-io/8571">https://internals.rust-lang.org/t/namespacing-on-crates-io/8571</a></li><li><a href="https://internals.rust-lang.org/t/pre-rfc-domains-as-namespaces/8688">https://internals.rust-lang.org/t/pre-rfc-domains-as-namespaces/8688</a></li><li><a href="https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628">https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628</a></li><li><a href="https://internals.rust-lang.org/t/scoped-packages-like-in-npm/10223/3">https://internals.rust-lang.org/t/scoped-packages-like-in-npm/10223/3</a></li><li><a href="https://internals.rust-lang.org/t/pre-rfc-idea-cratespaces-crates-as-namespace-take-2-or-3/11320">https://internals.rust-lang.org/t/pre-rfc-idea-cratespaces-crates-as-namespace-take-2-or-3/11320</a> (This was mine from last year after reading through the other proposals; my …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://samsieber.tech/posts/2020/09/registry-structure-influence/">https://samsieber.tech/posts/2020/09/registry-structure-influence/</a></em></p>]]>
            </description>
            <link>https://samsieber.tech/posts/2020/09/registry-structure-influence/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24442731</guid>
            <pubDate>Fri, 11 Sep 2020 13:46:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Modern Ruby Serializers]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 12 (<a href="https://news.ycombinator.com/item?id=24442337">thread link</a>) | @todsacerdoti
<br/>
September 11, 2020 | https://vasilakisfil.social/blog/2020/01/20/modern-ruby-serializers/ | <a href="https://web.archive.org/web/*/https://vasilakisfil.social/blog/2020/01/20/modern-ruby-serializers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
          <p>Long time no see!
This time I would like to write about a library I was working about a couple years ago,
a serializers library in Ruby.
I have actually finished it about a year ago and I always wanted to create this blog post
but last year has been super busy for me so never got the chance to present it properly :)</p>



<p>But first I would like to talk about serializers in Ruby from a historical perspective :)</p>

<h3>Ruby serializers in 2013-2014</h3>

<p>Back in 2014, when I started working with APIs, go-to library for serializing Ruby
classes was <a href="https://github.com/rails-api/active_model_serializers">ActiveModelSerializers</a>, the newly published 0.9.x version.
Back then, with this awesome library we were building basic GraphQL-like structures, before
GraphQL was even announced! It was a joy working with a such powerful tool
where the client could specify which fields it needs from a specific resource but also
which relations.
You could inject exactly what you needed when you were actually rendering the serializer
which meant that you could take a union of client’s desired fields/associations,
the default fields/associations (if client’s input was empty), and what client was allowed to access.
The result was a super flexible API.</p>

<p>Apart from AMS, there was <a href="https://github.com/ismasan/oat">Oat</a> a pretty nice little library which supported
out of the box <a href="http://stateless.co/hal_specification.html">HAL</a>, <a href="https://github.com/kevinswiber/siren">Siren</a> and <a href="https://jsonapi.org/">JSON:API</a>, and <a href="https://github.com/rails/jbuilder">jbuilder</a> which for some
reason felt like Godzilla to me at that point, but to be honest it’s a completely proper way of
building hypermedia APIs in Ruby since you can do a lot of cool stuff with caching.
However the catch is that you can’t create reusable adapters, basically it’s like
Rails views, everything needs to be implemented from scratch.</p>

<h3>Ruby serializers in 2015-2016</h3>

<p>Going forward, in 2015, the AMS rewrite had already begun since 2014 for the
0.10.x version. For various reasons, in the company I was working at that time, it was decided
to go with the 0.10.x and of course we completely regretted it. At that point it was 0.10.RC4 that we
were using, just 1 RC release before the 0.10.0. Now you can tell me, “of course
what do you expect? You were using an RC version” and you might be right. Only that the frustration
didn’t come from things that weren’t polished 100%.
I would be fine with that and I was eager to help out.
The frustration came from the fact that the architecture was a completely different beast
from 0.9 and 0.8 versions, everything were different, code and (the sparse) documentation.
And I am saying this because I <a href="https://github.com/rails-api/active_model_serializers/issues?utf8=%E2%9C%93&amp;q=author%3Avasilakisfil">did try</a> to help out sending pull requests, and the more
I was working with the code, the more frustrated I got.</p>

<p>Here are some things that come to my mind:</p>

<ul>
<li>both 0.8/0.9 and 0.10.x are using the same repo, although they share completely different
API/code, making things extremely confusing from a API developer perspective, but also
very difficult to manage as well from a contributor’s perspective</li>
<li>super complex overall architecture</li>
<li>the gem made JSON:API as first citizen. That’s inflexible to build adapters for different
specs and has affected pretty much everything in the code.
The previous versions were using the AMS API style (mostly json with some very basic patterns). 0.10.x version
also supported that style but the code for that was like a completely different
branch inside the code (not sure if it’s still like that but I guess it is).
I understand that JSON:API is a quite popular spec, but tight the whole generic library to that
spec is a bad design, I think.</li>
<li>too many dependencies (requires ActiveSupport..)</li>
<li>tightly coupled to ActiveRecord (at least at that time, not sure if now has changed..)</li>
<li>caching was implemented in the same library. I really thing that’s a completely different concern..</li>
<li>some parts did not match the Ruby coding style (like include: ‘a,string,of,resources’, default_includes ‘**’)</li>
<li>maintainers were reluctant to merge pull requests, because even in the Github issues was an extreme
confusion of what’s implemented, what’s missing, what bugs exists etc</li>
</ul>

<p>In one word <strong>it was a failure</strong>. Like, imagine the most popular Serializers gem in Ruby,
Rails team <a href="https://medium.com/@joaomdmoura/the-future-of-ams-e5f9047ca7e9">was pushing them</a> to finish in-time before the release of Rails 5 so they can include
it in the same release (although completely different gem, I guess they would make a note about it),
maintainers were struggling to make this happen and of course it didn’t.</p>

<p>Now I should also pause a bit and say that <strong>I have nothing against the commiters/maintainers</strong>.
They definitely <strong>did their best, and the problem wasn’t lying there</strong>.
It’s just that sometimes Open Source projects fail.
And in my experience they fail, when there isn’t a very tight core team that has the same vision,
coding style and are gatekeepers in pull requests, until the library has proved itself.
Then, any new pull request will probably respect the existing code and won’t challenge it.
Merging code will be much easier, at that point.</p>

<p>Instead with AMS, <strong>different people started the rework, different people took over
and did their best to finish it</strong>, and for the whole time, various people were sending pull
requests for various features and bugs, of course to help out, but what happened
was a very complex architecture with no clear design and vision.
Actually it would be a great idea to take some interviews by the project contributors at that time.
I think they will have some insights to contribute regarding to what happened :)</p>

<p>During my frustration with AMS I always wondered: how difficult can it be to
build a feature-complete Ruby Serializers ? Well, it turned out to be a bit more complex
than I initially thought. <strong>Way more complex</strong> :)</p>

<h3>Ruby serializers in  2017-2018</h3>

<p>I guess I wasn’t the one who was a bit frustrated with AMS.
<a href="https://github.com/beauby">beauby</a>, an AMS core member went off and created a JSON:API specific serializers gem,
the <a href="https://github.com/jsonapi-rb">jsonapi-rb</a>.
It follows spec pretty well and should be fine using it.
It’s also dependency free.</p>

<p>On the other hand, a year later (2018) Netflix came over and published <a href="https://github.com/Netflix/fast_jsonapi">their own
JSON:API serializers gem</a> which is extremely fast to be honest.
Like <strong>SUPER FAST</strong>.
Unfortunately it requires ActiveSupport as a dependency (not sure why, earlier releases didn’t)
and that could be a bummer for some applications.
Also it might not be as flexible as AMS or jsonapi-rb (although latest releases have
closed the gap A LOT), but in my experience it’s flexible enough that you will
almost never need to look for something else.</p>

<h3>Ruby serializers today</h3>

<p>Today, if someone asked me which Serializers gem should I use, I would tell him/her
go for the <a href="https://github.com/Netflix/fast_jsonapi">fast_jsonapi</a> gem. It’s super fast, it supports a quite popular API
spec and you must have a really good reason to not use it.</p>

<p>Personally, <strong>I am a bit against of having links inside the response</strong>, treating the
client as plain stupid. That’s one of the reasons why I don’t like JSON:API.
I think it’s just too verbose.
(The other reason is the naming: they picked up the 2 most popular words regarding APIs,
<em>JSON</em> and <em>API</em>, glued them together and made the name, feels so much cheating..)
I like to load off some work to the client using introspective
methods. I have talked <a href="https://introspected.rest/">about it</a> some time ago.
But if anyone came and asked me what I would suggest for a brand new API, my
answer would be pretty straightforward: <strong>JSON:API, unless you have good reasons
not to</strong>.</p>

<p>It’s the more experienced API designers that might want to implement something more
versatile and more advanced, tailored to a specific use case.
Or might want to experiment a bit.
For instance, another cool API spec that’s in the same philosophy as JSON:API is
<a href="https://ionspec.org/">Ion</a>.
Not as popular as JSON:API but worth checking it out!
Problem is that when you need to implement something different from JSON:API,
in Ruby you don’t really have much options. Well you have, it’s AMS but it will
be pain in the ass to create a custom serializer from that one.
And it will be painstakingly slow.
And you can’t have more advanced concepts, like forms, relations on collections
etc.
Or you could use <a href="https://github.com/rails/jbuilder">jbuilder</a>, but the problem with jbuilder is that it can’t
have the notion of adapters, hence you always need to build the final result
from scratch. Not fun.</p>

<h3>SimpleAMS: Modern Ruby Serializers</h3>

<p>When I started working on the prototype of SimpleAMS, I set a couple of goals.</p>

<ul>
<li>I wanted the library to be super simple, easy to use with injectable API and clean code.
Have you seen <a href="https://github.com/varvet/pundit">pundit</a>? I want a pundit for serializing.</li>
<li>One of the things that I sometimes don’t like in Ruby coding style, is the level of assumptions that the
code makes on behalf of you.
It had been a quite common pattern in Ruby/Rails that lead to many confusion of what
exactly the API is while at the same time such patterns reduce the flexibility.
The code is trying to act smart, but the drawbacks of such smartness overweight the gains.
I feel some basic assumptions which can be overridden at anytime is the ideal.
Embracing clean, explicit code is what I want, so that you can understand what’s happening instantly.</li>
<li>I wanted to create a generic abstraction as a first class citizen. From there
you should be able to implement any serializer needed, but that abstraction should be
powerful enough to cover even the most extreme corner cases.
After all, it’s tough to beat <a href="https://github.com/Netflix/fast_jsonapi">fast_jsonapi</a>, that’s shouldn’t be my goal ;)</li>
<li>I wanted super clean code, no smarty complex meta thingies inside the code.
I also wanted expected behavior on the internals and how it works when someone
started looking in the codebase.
Of course except the <a href="https://github.com/vasilakisfil/SimpleAMS/blob/master/lib/simple_ams/dsl.rb">DSL part</a>, which uses some advanced Ruby metaprogramming concepts,
but that’s necessary if we want it to work with just an <code>include</code>.</li>
<li>Much faster than AMS, it’s well known that AMS is quite slow so that should be easy :)</li>
</ul>

<h3>The API</h3>

<p>Before starting on any new project, I like to put my imagination and come up
with a useful API and use cases.
Being in god mode, and leaving all the constraints on the side, you can come up with
some really cool APIs.</p>

<h4>DSL based API</h4>

<p>So how would you use a serializers library in Ruby?
I want to avoid any inheritance in order to use SimpleAMS,
because …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vasilakisfil.social/blog/2020/01/20/modern-ruby-serializers/">https://vasilakisfil.social/blog/2020/01/20/modern-ruby-serializers/</a></em></p>]]>
            </description>
            <link>https://vasilakisfil.social/blog/2020/01/20/modern-ruby-serializers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24442337</guid>
            <pubDate>Fri, 11 Sep 2020 13:08:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[7 Reasons Your Growth Startup Is Hiring Too Junior]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24442303">thread link</a>) | @svmanager
<br/>
September 11, 2020 | https://staysaasy.com/management/2020/09/11/Hiring-Too-Junior.html | <a href="https://web.archive.org/web/*/https://staysaasy.com/management/2020/09/11/Hiring-Too-Junior.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Growth startups often find themselves lacking senior team members as they scale. The problems that arise from this are plentiful, including things like:</p>
<ul>
  <li>Requiring heroics to fix things</li>
  <li>Penalizing junior team members for failure to meet responsibilities well above their pay grade.</li>
  <li>Building technology that doesn’t scale</li>
</ul>

<p>Here’s some reasons why companies get into this situation.</p>

<h2 id="reason-1-habit">Reason 1: Habit</h2>

<p>When you’re a tiny startup budgets are extremely lean and products don’t have a lot of users. In that environment companies often prioritize breadth of functionality (see what works) and getting that via several (more affordable) junior team members guided by a smaller group of senior team members.</p>

<p>Problems arise if that strategy exists past market fit. The add-a-junior-to-do-more strategy implodes as the team grows too large for the senior staff to manage closely and the technical challenges start to look more daunting.</p>

<h2 id="reason-2-hubris">Reason 2: Hubris</h2>

<p>Sometimes people recognize the problems are getting more difficult but still don’t hire more seniors. This can often be chalked up to hubris - surely I can just direct a bunch of juniors to execute on the genius solutions I come up with for all our problems. The problem here is that you’re not a genius and even if you were that strategy doesn’t scale.</p>

<h2 id="reason-3-fear">Reason 3: Fear</h2>

<p>The flip side of hubris is fear. New senior staff can look like a threat to the power of existing senior staff. You might have to choose between doing what’s right for the company and retaining certain kinds of power. The answer there is simple - it’s better to be part of something great than the owner of something that fails.</p>

<p>A different play on this theme is junior teammates fearing that new senior teammates will take away some of their opportunities. It’s possible, sure. But more often the opportunities they will take over are the ones juniors would have had trouble succeeding in.</p>

<p>In a growing company with reasonably difficult challenges, good seniors will do more to expand the set of opportunities than shrink them. And good senior talent will help juniors via mentorship and guidance.</p>

<h2 id="reason-4-money-issues">Reason 4: Money Issues</h2>

<p>Money issues play out in a couple ways.</p>

<p>First, the cost of senior talent can subconsciously make you concerned about the remaining budget for yourself. I haven’t seen this played out directly and blatantly, but it’s another version of the fear game - assuming compensation is a zero sum game leads to weird incentives.</p>

<p>Second, it’s easy to think 2 juniors are better than one senior. As you read about the myth of the 10x engineer you might find yourself thinking this way. Let’s talk more about how this is a misconception in reason 5…</p>

<h2 id="reason-5-miscalculation-of-necessary-skills-for-right-now">Reason 5: Miscalculation of Necessary Skills For Right Now</h2>

<p>As referenced earlier, problems get much harder when you add significant growth to a platform. It’s not uncommon to underestimate the challenges at hand. In reality, even simple products at massive scale need significant senior leadership to ensure they are being built and operated effectively. Trying to replace the leadership of senior talent with a volume of junior talent is a sure-fire way to screw this up.</p>

<h2 id="reason-6-miscalculation-of-necessary-skills-in-the-future">Reason 6: Miscalculation of Necessary Skills In the Future</h2>

<p>To make things more difficult, you don’t just have to hire for right now, you have to hire for 2 or more years in the future. The senior talent you hire now must seed the leadership ranks you need in the future. Especially in product and engineering, you can’t just hire everyone you need when you need them. For starters, the job market would laugh at that sort of just-in-time attempt at hiring. But also, these roles require much more detailed understanding of the systems at play, so you need to have people with intimate knowledge developed in advance.</p>

<p>Think of it this way - look at whatever company you’re trying to be like in 5 years. Look at their team. If you don’t start hiring towards something like that team sooner rather than later you’ll never be that company.</p>

<h2 id="reason-7-arguments-about-what-seniors-need">Reason 7: Arguments About What-Seniors-Need</h2>

<p>Another reason people hire too junior is thinking around senior talent needing explicit areas of responsibility that don’t overlap. This is the “one alpha” theory - that senior talent can’t collaborate productively and need their own pack. There might be some nuggets of truth here, but most of it is nonsense. That’s like NASA saying they couldn’t have smart people work together on getting to the moon because these great scientists need their own domains.</p>

<p>Ultimately you have to look at the problems you’re solving. If they are truly challenging they can support a number of seniors. If they aren’t you’ll probably have trouble hiring and retaining more than a few.</p>

<h2 id="conclusion">Conclusion</h2>

<p>There’s a lot of reasons why you might hire too junior as your company grows. Know them and hire intentionally.</p>


    




  </div></div>]]>
            </description>
            <link>https://staysaasy.com/management/2020/09/11/Hiring-Too-Junior.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24442303</guid>
            <pubDate>Fri, 11 Sep 2020 13:03:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Octo – Generate a serverless API from an SQL query]]>
            </title>
            <description>
<![CDATA[
Score 221 | Comments 57 (<a href="https://news.ycombinator.com/item?id=24442294">thread link</a>) | @khalidlafi
<br/>
September 11, 2020 | https://octoproject.github.io/octo-cli/ | <a href="https://web.archive.org/web/*/https://octoproject.github.io/octo-cli/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <a href="" title=" ">
    <img src="https://octoproject.github.io/octo-cli/assets/cover.png" alt=" ">
  </a>
  <br>
  <h4>Expose data from any database as web service.</h4>
  <p>
    Octo CLI makes the data available from any database as a web service on-demand, 
    simplifying the process of building data-driven applications.
     It can reduce costs, improve accessibility and performance.
  </p>
 

 <p><a href="" title=" ">
    <img src="https://user-images.githubusercontent.com/20528562/92949687-2b627080-f464-11ea-99e8-d3afad80922c.png" alt=" ">
  </a>
  </p>
     <div>
    <p><a href="https://github.com/octoproject/octo-cli" title="Documentation" onmousedown="ga('send', 'event', 'download', 'click', 'zip')">View on Github</a>
    <a href="https://github.com/octoproject/octo-cli#examples" title="View on GitHub" onmousedown="ga('send', 'event', 'download', 'click', 'zip')">Get started</a>
  </p></div>
</div></div>]]>
            </description>
            <link>https://octoproject.github.io/octo-cli/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24442294</guid>
            <pubDate>Fri, 11 Sep 2020 13:02:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to choose an FPGA dev board. A guide for 2020]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 15 (<a href="https://news.ycombinator.com/item?id=24441911">thread link</a>) | @blackSparrow
<br/>
September 11, 2020 | https://thedatabus.io/fpga-buying-guide | <a href="https://web.archive.org/web/*/https://thedatabus.io/fpga-buying-guide">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>Let's face it, It is not easy to choose a freaking PC these days with the deluge of specifications that come with it let alone FPGAs. The question of using FPGAs to solve any computing problem only arises when an extraordinary performance is required. Owing to this fact, FPGAs in their feature specification and build can be extremely specific to the application at hand. This results in an insane number of varieties in terms of the logic structures within the FPGA as well as the interfaces that are provided with the external world. However, this guide aims to guide you in the right direction (which does not mean dumping a list of the hundreds of different options out there) based on your level of experience and requirement.</p>
<p>There are other posts out there that provide large tables with exhaustive lists of FPGA development boards out there and let you (after a year or two of research) make a choice. If that's your thing, I'll attach some links to help you get started.</p>
<hr>
<p><em>If you're already familiar with the various bells and whistles of  FPGAs and are only looking for some good suggestions, you might prefer to <a href="https://thedatabus.io/fpga-buying-guide#the-top-contenders"><strong>JUMP TO THE LIST OF SUGGESTIONS</strong></a>.  If not, read on to learn some very important stuff about the FPGA world and how to choose better!</em></p>
<h2 id="what-you-should-be-looking-for"><a href="#what-you-should-be-looking-for" aria-label="what you should be looking for permalink"></a>What you should be looking for</h2>
<p>There are already a lot of aspects to an FPGA in general that determine its fit to a particular problem and the ease with which it can be programmed, now add to this the complexity of a feature-rich development board with all sorts of peripherals, interfaces, connectors and memory options you have at hand a humongous task of deciding between hundreds of varieties out there.</p>
<h3 id="soc-based-board-or-just-an-fpga"><a href="#soc-based-board-or-just-an-fpga" aria-label="soc based board or just an fpga permalink"></a>SOC based board or just an FPGA?</h3>
<p>SOC stands for <a href="https://semiengineering.com/knowledge_centers/integrated-circuit/ic-types/system-on-chip/" target="_blank">System-on-Chip</a> which simply means that various interacting technologies are built onto the same die (/chip). You see SOCs everywhere, on your phones, TVs, and computers. In the context of an FPGA development board, a SOC based system means that the hardware has two components, a sea of programmable logic (the FPGA) and a hard processor core implemented in silicon independent of the programmable FPGA logic. Interfaces are created between the programmable logic and the processing system (in Xilinx lingo) that enable communication between the two regions.</p>
<p><img src="https://thedatabus.io/static/zynq7000-ae213195db5b530cc3f5d60785b3b0b1.png" alt="Zynq7000"></p>
<p>If you are an absolute beginner looking for direction, you should definitely choose a SOC based system because of the immense additional learning potential it adds. Having said that, your first few digital design projects should never involve the processor cores or any kind of software programming. For that, you can just ignore the processor logic and dump your design into the programmable region to use it as a normal FPGA. As you progress, you can add much higher levels of complexity to your design by bringing in the processor core to directly read and write data in your configurable hardware. You can also experiment with writing firmware, drivers, the Linux OS, and the higher levels of abstraction thus getting a truly holistic experience of embedded system design. Even the simplest SOC based board will keep you busy for a long time. </p>
<p>These boards can also be of great interest for Software engineers looking to explore into the digital design world since processor + FPGA structures lend themselves very well to paradigms like HLS, Heterogenous computing and partial acceleration of algorithms. Viewing the FPGA logic as an extension of the SOC is something that is going to be very important in the future and is a good investment of your time.</p>
<p>Alternatively, If you are a beginner but are looking only to learn digital design or you wish to buy a board to complement your studies at college where you get to use a particular board in your lab, you can get a lot more basic FPGA resources (LUTs, BRAMs, DSPs) on a Non-SOC based board that has only the FPGA. This way you save money and have a much less complex system at hand that you can comprehend better. The same is true If you plan to implement something specific that takes up an enormous number of resources, you might be better off going for a dev board that has only the FPGA and the required peripherals.</p>
<p>At the end of <a href="https://www.reddit.com/r/FPGA/comments/9yutk8/best_100300_fpga_development_board_in_2018/?utm_source=share&amp;utm_medium=web2x&amp;context=3" target="_blank">this post</a> on the subreddit <a href="https://www.reddit.com/r/FPGA/" target="_blank">r/FPGA</a> user <strong>u/ndbroadbent</strong> has shown the resource usages of several open source projects, this can give you a good idea of how big projects usually are.</p>
<p><strong>An important note for beginners</strong> : <em>Having an SOC board, with all the processor logic around the FPGA can really deviate you from the basic idea of programmable logic and how you're supposed to learn it. I strongly suggest completely disregarding anything to do with the processor for your first few projects and use only the FPGA part of the device. Also note that as of today, any good FPGA engineer will tell you that any form of <a href="https://en.wikipedia.org/wiki/High-level_synthesis#:~:text=High%2Dlevel%20synthesis%20(HLS),hardware%20that%20implements%20that%20behavior."><strong>HLS</strong></a> is not good enough to be used in real world projects. This is doubly true for the beginners. <strong>DO NOT</strong> fall into the 'Write code in C++/Python and run it on FPGA' trap. A lot of youtubers seem to be promoting stuff like that for beginners these days which is just sad. If you have the money to spend, the ideal (and more enjoyable) learning strategy would be to use a standalone FPGA board first and upgrade to an SOC later.</em></p>
<hr>
<h3 id="interfaces-and-ios"><a href="#interfaces-and-ios" aria-label="interfaces and ios permalink"></a>Interfaces and IOs:</h3>
<p>FPGAs are excellent tools for working on high-speed interfaces. So you might want to look at the interfaces and IO options a particular development board is providing. This is important because if the board has a particular interface out of the box, the vendor will probably provide the necessary documentation and sample designs for those interfaces. This can save you tons of head-scratching and hair-pulling (trust me that is common in the FPGA world) as a beginner. That's not to say that newer interfaces cannot be added to the board manually but when it comes to High-speed interfaces like Ethernet, HDMI, PCIe, it can be very difficult to add them yourself and expect reliable performance. Low-speed ones like SPI, UART, etc can always be manually added using the GPIOs, so let them not be the dealbreaker for any board.</p>
<p>Some common networking interfaces that you should look for are high-speed interfaces like <a href="https://en.wikipedia.org/wiki/HDMI" target="_blank"><strong>HDMI</strong></a>  <a href="https://en.wikipedia.org/wiki/Video_Graphics_Array" target="_blank"><strong>VGA</strong></a>  <a href="https://en.wikipedia.org/wiki/Ethernet" target="_blank"><strong>ETHERNET</strong></a>  <a href="https://en.wikipedia.org/wiki/PCI_Express" target="_blank"><strong>PCIe</strong></a>  etc. and low-speed peripherals like <a href="https://en.wikipedia.org/wiki/Serial_Peripheral_Interface" target="_blank"><strong>SP</strong>I</a>  <a href="https://en.wikipedia.org/wiki/CAN_bus" target="_blank"><strong>CAN</strong></a>  <a href="https://en.wikipedia.org/wiki/I%C2%B2C" target="_blank"><strong>I2C</strong></a>  etc.</p>
<p>Although not as important for a beginner, another set of interfaces that can be useful are the analog and sensor interfaces like ADCs, DACs, Camera Interface, Audio CODECs, etc. These are very niche features that can make or break a particular project if it depends on data acquisition from the external world.</p>
<p>If you choose to go for a board with not too many peripherals for whatever reason, you might be better off choosing one that has the industry-standard <a href="https://store.digilentinc.com/pmod-modules-connectors/" target="_blank"><strong>PMOD</strong></a> or <a href="https://en.wikipedia.org/wiki/FPGA_Mezzanine_Card" target="_blank"><strong>FMC</strong></a> connectors installed so that when you do need additional interfaces in the future, they can be added very easily. These standard connectors essentially decouple FPGA carrier boards from the IO engines (which plug-in as daughter cards), enabling you to use the same FPGA boards with a large variety of IO designs without ever having to re-design the board.</p>
<hr>
<h3 id="buttons-leds-and-displays"><a href="#buttons-leds-and-displays" aria-label="buttons leds and displays permalink"></a>Buttons, LEDs, and Displays:</h3>
<p>Debugging FPGA designs can be a hard thing. Unlike MCUs where you can place print statements and breakpoints anywhere you want in the code, there is no such equivalent in the FPGA world and that can often lead to great frustration. One workaround is possible, if there are switches and LEDs on your board. They provide an easy way to pull out signals to the real world and give you an indication of the status of some status registers that can help you visualize and debug (like the current state of a state machine or a particular flag in a CPU design). However, this should not be the deciding factor between two boards since it is very easy to add LEDs, buttons, switches, and LCDs using the GPIO connectors without much effort.</p>
<hr>
<h3 id="memory-and-resource-count"><a href="#memory-and-resource-count" aria-label="memory and resource count permalink"></a>Memory and Resource Count:</h3>
<p>The Resource Count is another important metric that goes into deciding on an FPGA device. By resource, we mean the number of programmable logic elements available on the board. These can be LUTs (ALMs for Altera), Block Rams, DSPs, and IO blocks. Much more complex and fancier devices like the  <a href="https://www.xilinx.com/products/silicon-devices/acap/versal.html" target="_blank"> Versal family</a> from Xilinx can have lots of other stuff like AI, video, and audio cores, etc. It is important to take note of these resource numbers because they determine the biggest project that you can successfully fit onto the FPGA. It is hard to come up with a fixed count for a particular project owing to differences in the underlying CLB architecture from vendor to vendor and family to family.</p>
<p>FPGAs store the configuration(bitstream) data on the SRAM (usually) cells within the FPGA. Since SRAM is a volatile kindof memory, the program is lost each time the board is power-cycled. A PC support is needed to reprogram it again after the power cycle, to prevent this, FLASH (or EEPROM in older boards) based storage is provided onboard by the vendors. Flash is a non-volatile form of storage that holds the bitstream data even without a power supply. Each time the board comes up after a power cycle, the FPGA checks the flash memory for a bitstream and programs itself with it. This is usually given by default in most boards but can be something important to look out for. </p>
<p>The other important form of memory is the external onboard volatile storage which is most commonly provided in the form of a <a href="https://en.wikipedia.org/wiki/DDR_SDRAM" target="_blank">DDR SDRAM</a>  This is extremely useful if you are building an application that needs to store data locally for whatever reason. Since the block ram storage within the FPGA fabric is very little and is very precious, having a DDR that can be written to and read from in a reasonable amount of time is very much essential. The more the better!
<a href="https://numato.com/kb/learning-fpga-verilog-beginners-guide-part-6-ddr-sdram-a7/" target="_blank">This</a> tutorial and <a href="https://www.electronics-notes.com/articles/electronic_components/semiconductor-ic-memory/sdram-synchronous-dram-what-is.php" target="_blank">this</a> one can get you started with the interface that needs to be coded in order to communicate with the DDR chip.</p>
<hr>
<h3 id="learning-resources-and-community-support"><a href="#learning-resources-and-community-support" aria-label="learning resources and community support permalink"></a>Learning Resources and community support:</h3>
<p>Unlike the world of software or MCU based design, the world of digital design and FPGAs have far fewer general resources in terms of …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thedatabus.io/fpga-buying-guide">https://thedatabus.io/fpga-buying-guide</a></em></p>]]>
            </description>
            <link>https://thedatabus.io/fpga-buying-guide</link>
            <guid isPermaLink="false">hacker-news-small-sites-24441911</guid>
            <pubDate>Fri, 11 Sep 2020 12:22:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The case against normalized caching in GraphQL]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24441864">thread link</a>) | @jensneuse
<br/>
September 11, 2020 | https://wundergraph.com/blog/2020/09/11/the-case-against-normalized-caching-in-graphql | <a href="https://web.archive.org/web/*/https://wundergraph.com/blog/2020/09/11/the-case-against-normalized-caching-in-graphql">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>In this post we'll compare rich GraphQL clients that come with a normalized cache implementation and the generated WunderGraph clients that rely on HTTP caching.</p><p>As you might have already found out, WunderGraph uses persisted queries by default.
With the WunderGraph code generator WunderGen(<a href="https://github.com/wundergraph/wundergen" target="_blank" rel="noopener noreferrer">https://github.com/wundergraph/wundergen</a>) you can generate a client that knows exactly how to invoke your previously registered operations.
With the <code>@cache</code> directive you're able to configure that the response of an operation should be cached by the server &amp; client.
Cache Control headers will be set accordingly, including etags. This mechanism is fully compatible with all major browsers and CDN's who implement caching according to the <a href="https://tools.ietf.org/html/rfc7234" target="_blank" rel="noopener noreferrer">HTTP Caching RFC</a>.</p><p>To illustrate this a bit better I'd like to introduce two example queries.
The first one fetches a list of friends.
The second one fetches some details about those friends.</p><p>Let's consider we want to show a list of friends:</p><div><div><div tabindex="0"><div><p><span>query</span><span> Friends </span><span>{</span><span></span></p><p><span>    friends </span><span>{</span><span></span></p><p><span>        id</span></p><p><span>        name</span></p><p><span>        age</span></p><p><span>        avatarURL</span></p><p><span>    </span><span>}</span><span></span></p><p><span></span><span>}</span></p></div></div></div></div><p>For each friend we'd like to be able to click on the friend in the list and open up a detail page:</p><div><div><div tabindex="0"><div><p><span>query</span><span> FriendByID </span><span>{</span><span></span></p><p><span>    friend</span><span>(</span><span>id</span><span>:</span><span> </span><span>123</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>        id</span></p><p><span>        name</span></p><p><span>        age</span></p><p><span>        avatarURL</span></p><p><span>    </span><span>}</span><span></span></p><p><span></span><span>}</span></p></div></div></div></div><p>You will recognize that we already have all the data for the detail page.
So in an ideal scenario the client won't have to make another request.
This is possible thanks to cache normalization.</p><p>A smart normalized cache will identify the Friend entity and will recognize that the "FriendByID" query can be fulfilled using the data from the "Friends" query which we already ran.</p><p>What are the pros of this concept?</p><ul><li>Navigating to a friend detail page will be instant because there is no network request required</li><li>The client will save bandwidth, and the user experience will be more fluent</li><li>If we navigate back we can also immediately pull out the list of friends from the normalized cache</li></ul><p>How can this situation become hairy?
Let's add a third operation. While on a user detail page we'd like to unfriend one of our peers:</p><div><div><div tabindex="0"><div><p><span>mutation</span><span> Unfriend </span><span>{</span><span></span></p><p><span>    unfriend</span><span>(</span><span>id</span><span>:</span><span> </span><span>123</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>        id</span></p><p><span>    </span><span>}</span><span></span></p><p><span></span><span>}</span></p></div></div></div></div><p>How does the <code>unfriend</code> mutation make the situation complex?
In your normalized cache you have to invalidate or update the "Friends" and "Friend" entities.
In your friends list you have to remove the user with id 123.
For the <code>Friends</code> you have to make sure no friend is returned for id 123 anymore.</p><p>How does your normalized cache draw the lines between the <code>unfriend</code> mutation and the <code>friend</code> and <code>friends</code> query?
You as the frontend developer have to program the cache to do so.
After the mutation you must inform the cache about these changes.</p><p>With that let's talk about the cons of a normalized cache:</p><ul><li>a rich GraphQL client with a normalized cache is complex to build and maintain</li><li>the cache is running in the javascript vm of your browser and therefore a lot less efficient than the browser cache</li><li>the logic to keep the cache state correct can become quite hairy</li><li>the frontend developer must understand the domain and program the cache correctly to avoid unwanted behaviour</li><li>the frontend developer must implement custom rules for cache eviction</li></ul><p>One thing that I want to explicitly mention outside of the list:</p><h2>There's no single source of truth for the business object in this scenario.</h2><p>The frontend developer might accidentally allow the UI to show a friend in the friends list even if you have previously unfriended said person.
Errors like these are very hard to spot. I think we're giving the frontend developer a lot of responsibility in this case to get caching right.</p><p>Should it really be a concern of a frontend developer if data is stale? Shouldn't a frontend developer focus on the UI and trust the data layer? Does it really have to be that complicated to build rich apps with good performance?</p><p>I believe there are applications where it's definitely worth having such a complexity.
On the other hand I see many use cases, eg a news website, where relying on the HTTP Caching RFC is a lot simpler and more efficient.</p><h2>Enter WunderGraph caching:</h2><p>With WunderGraph every registered Query becomes an endpoint to which you can apply caching rules individually.</p><p>Let's revisit the example from above:</p><div><div><div tabindex="0"><div><p><span>query</span><span> FriendByID </span><span>@cache</span><span>(</span><span>maxAge</span><span>:</span><span> </span><span>5</span><span>)</span><span>{</span><span></span></p><p><span>    friend</span><span>(</span><span>id</span><span>:</span><span> </span><span>123</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>        id</span></p><p><span>        name</span></p><p><span>        age</span></p><p><span>        avatarURL</span></p><p><span>    </span><span>}</span><span></span></p><p><span></span><span>}</span></p></div></div></div></div><p>This Query becomes the following endpoint on your WunderGraph Node:</p><div><div><div tabindex="0"><div><p><span>/</span><span>application</span><span>-</span><span>id</span><span>/</span><span>FriendByID</span><span>?</span><span>variables</span><span>=</span><span>{</span><span>"id"</span><span>:</span><span>123</span><span>}</span></p></div></div></div></div><p>In this scenario we decided to cache a friend object for 5 seconds using the <code>@cache</code> directive.
After 5 seconds the client will re-request the user and send an <code>If-None-Match</code> header with the request.
If the previous response is still valid the server will respond with a <code>304 (Not Modified)</code> http status code.
The same logic can be applied to the <code>Friends</code> Query.
All you have to do is define the desired behaviour using directives on the Operations.</p><p>What are the pros of this approach?</p><ul><li>there's a single source of truth - the Operation Definition</li><li>caching is handled automatically by the browser which is easier to use and understand</li><li>no complex tooling is required to understand why a request is cached, browsers have excellent debuggers for this</li><li>no javascript code has to be written to keep the cache state in sync</li><li>with a service worker you can easily build offline apps using standard caching techniques</li><li>less javascript code to be run by the browser</li><li>the frontend developer gets to focus on the UI and has to worry less about data fetching and caching logic</li></ul><p>What are the cons of HTTP caching for GraphQL queries?</p><ul><li>the client has to make more requests than with a normalized cache</li><li>more requests lead to more bandwidth usage</li><li>there's no easy way to invalidate the cache immediately</li></ul><h2>Does a normalized cache prevent us from doing more requests?</h2><p>Let's make this scenario a bit more realistic. On the friends detail page we'd like to see the bio of the friend too:</p><div><div><div tabindex="0"><div><p><span>query</span><span> FriendByID </span><span>{</span><span></span></p><p><span>    friend</span><span>(</span><span>id</span><span>:</span><span> </span><span>123</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>        id</span></p><p><span>        name</span></p><p><span>        age</span></p><p><span>        avatarURL</span></p><p><span>        bio</span></p><p><span>    </span><span>}</span><span></span></p><p><span></span><span>}</span></p></div></div></div></div><p>With this one field added even with normalized caching we have to refetch each individual friend even though we already have most of the data.
At the end of the day a normalized cache might introduce a lot of complexity to your app while the benefits are not as huge as you expect.
In this last example you could have saved to transfer less fields for each user detail page at the expense of a complex GraphQL client that understands which fields are missing for an entity.</p><h2>Cache invalidation</h2><p>As mentioned previously, a normalized cache can easily be invalidated.
This comes at the cost of implementing and maintaining the cache code plus defining the logic when to invalidate which objects.</p><p>With HTTP caching it's not that easy.
You could add a dynamic parameter, e.g. a timestamp, to the Query.
This would allow for easy cache invalidation but also reduces possible cache hits.</p><h2>Users can have multiple clients</h2><p>Is it possible for your users to open your application in multiple tabs, native applications, etc.?
If that's the case what happens if you unfriend a user in one tab while you have another tab open?
At that point your normalized cache has no way of figuring out if data is stale, it needs to make a network call if you switch tabs.</p><h2>Should you cache at all?</h2><p>Are we actually solving the problem at the right layer or creating a new, even more complex, problem?</p><p>If data like in this example could change any time at any click (add friend/unfriend) should we really cache this at the client or transport level at all?</p><p>Why not use an application cache, e.g. Redis or Memcached, in the Backend if hitting the database directly is a performance bottleneck?
In this scenario, neither transport level caching, nor a normalized client cache is the proper solution.</p><h2>When to cache</h2><p>Caching makes sense for publicly available data that doesn't change frequently.</p><p>E.g. on a news website it's totally fine to cache the content for each article for a few seconds (e.g. 5).
This would reduce the amount of requests from thousands to one per resource per 5 seconds.</p><p>In case data can change at high frequencies, especially after user interactions with the application, caching should happen at the application layer.</p><h2>Summary</h2><p>When you think you have to use a normalized cache in the client you should consider an application level cache first.</p><p>A normalized cache introduces a second source of truth in the frontend which needs to be maintained.
Optimistic can get that last bit of performance out of an app to get the user experience from 95% to 98% at the cost of extra complexity.</p><p>Most of the time you don't need this complexity and should avoid it.
Keep it simple, solve a business problem, don't introduce technical debt.</p><p>WunderGraph gives you a simple and powerful way to use transport based caching.
For 99% of the other use cases you should consider adding an application level cache if performance is an issue.</p></section></div>]]>
            </description>
            <link>https://wundergraph.com/blog/2020/09/11/the-case-against-normalized-caching-in-graphql</link>
            <guid isPermaLink="false">hacker-news-small-sites-24441864</guid>
            <pubDate>Fri, 11 Sep 2020 12:17:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sometimes you just have to ship it]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24441605">thread link</a>) | @mooreds
<br/>
September 11, 2020 | https://letterstoanewdeveloper.com/2020/09/07/sometimes-you-just-have-to-ship-it/ | <a href="https://web.archive.org/web/*/https://letterstoanewdeveloper.com/2020/09/07/sometimes-you-just-have-to-ship-it/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Dear new developer,</p>



<p>For me, there comes a point at the end of every project where I’m just sick of it. I’m sick of the project. I’m sick of the technology. I’m sick of project management system. I’m sick of the code.</p>



<p>Sometimes, I just want to see the whole thing burn. Or better, just ship it. </p>



<p>Now, I think that there are two solutions to this problem, and which one you pick depends on your timeline. The first is to take a step back. Talk to a team mate. Work on something else. Talk a walk. Take an extra half hour for lunch. </p>



<p>This may give you perspective to help you dive back in and add just a bit more polish. That polish, which may take the form of additional UX refinement, testing, or even wordsmithing the help messages or marketing text, can help make the project shine. </p>



<p>That’s what I call ‘running through the finish line’ where you want to leave it all on the field. That doesn’t mean you don’t make compromises or that you won’t revisit decisions, but it does mean that you do the best you can. Sometimes to put in that final effort, you need to take a break.</p>



<p>The other choice is to just ship it. This is a good option when you are up against a deadline. It also helps if you know you are a perfectionist and/or afraid of putting your work out there. Nothing is perfect and if your work never sees the light of day because you can’t accept that, the world is losing out (as are you). Finally, it can help if you take that time off, acquire that perspective and know that you’re done with this phase of the work.</p>



<p>I just <a href="https://letterstoanewdeveloper.com/the-book/">published a book</a>. It was released on Aug 16. I’m very proud of it, but there were times when I was just plain sick of it. I ended up taking some time away from it and that helped me make sure it was the best book it could be.</p>



<p>When you are working through the final bits of a project, sit back and get that perspective. And then, ship it!</p>



<p>Sincerely,</p>



<p>Dan</p>
	</div><div>
			<!-- .entry-auhtor -->
		<p><strong>Published</strong>
			<time datetime="2020-09-07T04:45:00-06:00">September 7, 2020</time><time datetime="2020-09-07T10:54:54-06:00">September 7, 2020</time>		</p><!-- .site-posted-on -->
	</div></div>]]>
            </description>
            <link>https://letterstoanewdeveloper.com/2020/09/07/sometimes-you-just-have-to-ship-it/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24441605</guid>
            <pubDate>Fri, 11 Sep 2020 11:41:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Mythical DevOps Engineer]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24441392">thread link</a>) | @rbanffy
<br/>
September 11, 2020 | https://alediaferia.com/2020/07/27/the-mythical-devops-engineer/ | <a href="https://web.archive.org/web/*/https://alediaferia.com/2020/07/27/the-mythical-devops-engineer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-594">
		<div>
		<p><span><span>Reading Time: </span> <span>8</span> <span>minutes</span></span></p><p>I’m always a little suspicious of job specs looking for the so-called <em>DevOps Engineer</em> role. They often mention a vast variety of duties and responsibilities. </p>



<blockquote><p>Are they hiring for a single role or a whole team?</p></blockquote>



<p>Roles having <em>DevOps</em> in their title hardly share the same meaning. They often have something in common, though. They try to cover for what traditionally would have been the specialization of different professionals.</p>



<p>Don’t get me wrong: cross-functional expertise is definitely important. But I don’t think <em>DevOps</em> means replacing a multitude of specialization with a single role. Different specializations like Operations, Security, Testing, Development, Product Management and so on, are vast and require specific knowledge. </p>



<p>I think the key differentiator of successful <em>DevOps</em> organizations is that they enable effective collaboration. They have as clear <em>North Star</em> the goal to deliver value to the end user.</p>



<p>Overall, I don’t think we should be talking about a <em>DevOps Engineer</em>, but rather about <em>DevOps</em> culture in organizations.</p>



<p>But let’s take a step back first.</p>



<h2>What does DevOps mean, really?</h2>



<p>I tweeted my own definition of DevOps some time ago.</p>



<figure><div>
<blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">DevOps is a highly condensed way of referring to the combination of practices that aim at shortening the software development life-cycle, increase the feedback opportunities and facilitate continuous improvement and experimentation.</p>— Alessandro Diaferia (@alediaferia) <a href="https://twitter.com/alediaferia/status/1279460637341560833?ref_src=twsrc%5Etfw">July 4, 2020</a></blockquote>
</div></figure>



<p><em>DevOps</em> organizations incentivise different specialities to collaborate. The intrinsic existing tension between Dev, making changes to the system, and Ops, wanting to keep the system stable, dissolves. The greater good is now <em>the value stream</em>.</p>



<blockquote><p>A stable system that delivers nothing is as useless as an unstable system that keeps offering new functionality.</p></blockquote>



<p>Dev and Ops understand the importance of working together to maximise this flow to figure out which bets worked out and which ones didn’t. </p>



<p>Organizations that embrace the <em>DevOps</em> mindset can be more effective than the competition at experimenting with new functionality. They quickly validate their assumptions, activating and deactivating functionality by flipping a switch on a dashboard.</p>



<p>Incidents become an opportunity for learning rather than a chance of blaming someone.</p>



<p>In general, <em>DevOps </em>organization learn to adapt and evolve to any situation.</p>



<p>Overall, I think there shouldn’t be a single <em>DevOps</em> role but, rather, a set of specific specialities collaborating effectively.</p>



<p>This ideal view of the terminology, though, might sometimes clash with the reality of the job market. Companies willing to attract the best talent with the most current skills may end up advertising for roles that are counterproductive in the context of DevOps principles.</p>



<p>But let’s have a look at a few interesting job specs.</p>



<figure><img loading="lazy" width="768" height="432" src="https://alediaferia.com/wp-content/uploads/2020/07/jordan-whitfield-sm3Ub_IJKQg-unsplash-768x432.jpg" alt="work harder neon sign photo" srcset="https://alediaferia.com/wp-content/uploads/2020/07/jordan-whitfield-sm3Ub_IJKQg-unsplash-768x432.jpg 768w, https://alediaferia.com/wp-content/uploads/2020/07/jordan-whitfield-sm3Ub_IJKQg-unsplash-300x169.jpg 300w, https://alediaferia.com/wp-content/uploads/2020/07/jordan-whitfield-sm3Ub_IJKQg-unsplash-1024x576.jpg 1024w, https://alediaferia.com/wp-content/uploads/2020/07/jordan-whitfield-sm3Ub_IJKQg-unsplash-1536x863.jpg 1536w, https://alediaferia.com/wp-content/uploads/2020/07/jordan-whitfield-sm3Ub_IJKQg-unsplash-2048x1151.jpg 2048w" sizes="(max-width: 768px) 100vw, 768px"><figcaption>Photo by <a href="https://unsplash.com/@whitfieldjordan?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Jordan Whitfield</a> on <a href="https://unsplash.com/s/photos/job-search?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></figcaption></figure>



<h2>What are companies looking for?</h2>



<p>Let’s read through a few excerpts from job specs I found out there in the wild.</p>



<h3>The flexible problem solver</h3>



<blockquote><p>[…] Devops Engineers are IT professionals who collaborate with software developers, system operators and other IT staff members to manage code releases. They cross and merge the barriers that exist between software development, testing and operations teams and keep existing networks in mind as they design, plan and test. Responsible for multitasking and dealing with multiple urgent situations at a time, Devops Engineers must be extremely flexible. […]</p><cite>A job spec on the internet</cite></blockquote>



<p>This is one of those classic examples where the organization believes that the DevOps principles should be delegated to a single team.</p>



<p>The spec mentions the myriad of duties that are responsibility of the <em>Devops Engineers</em> in the company. A <em>Devops Engineer</em> is expected to <em>“multi-task and deal with multiple urgent situations at a time”</em>. Therefore, they <em>“must be extremely flexible”</em>.</p>



<p><em>Multitasking</em> and dealing with multiple urgent situations at a time is, for sure, likely to happen anywhere: I don’t think this should be a peculiarity of a role in an organization. On the contrary, a healthy environment empowers every engineer to handle urgent situations and <a href="https://landing.google.com/sre/sre-book/chapters/postmortem-culture/">learn from them</a>.<mark id="annotation-text-54d7a912-f939-4d9c-8c35-b5876683f83c"></mark></p>



<hr>



<p>Coming across this role, I’d think that the organization is not really trying to adopt DevOps practices. <mark id="annotation-text-9ee4ee73-52fa-44d6-b856-3c9ba17dd0f4"></mark>Instead of encouraging people to collaborate and improve, they’re building a dedicated team to throw issues and urgent situations at.</p>



<p><mark id="annotation-text-d4681dd9-2adf-49b8-b88c-e4c6a256a1e7"></mark> This job spec would be a big red flag for me.</p>



<h3>The productivity booster</h3>



<blockquote><p>A DevOps Engineer combines an understanding of both engineering and coding. A DevOps Engineer works with various departments to create and develop systems within a company. From creating and implementing software systems to analysing data to improve existing ones, a DevOps Engineer increases productivity in the workplace.</p><cite>Another job spec on the internet</cite></blockquote>



<p>In a <em>DevOps</em> organization engineers <em>do</em> work with various departments. But what’s the point then of  having a dedicated <em>DevOps Engineer</em> role? Do the other type of engineers not work with the various departments of the organization? Do non-DevOps Engineers not analyse data and improve existing systems? Additionally, the job spec claims that <em>a DevOps Engineer increases productivity in the workplace</em>. How? Does it radiate productivity?</p>


	
	


<h3>The Release Manager… but <em>DevOps</em>!</h3>



<blockquote><p>A DevOps Engineer works with developers and the IT staff to oversee the code releases. […] Ultimately, you will execute and automate operational processes fast, accurately and securely.</p><cite>My favourite so far</cite></blockquote>



<p>This is quite a condensed one but the release aspect mentioned in it strikes me as particularly interesting.</p>



<p>I tend to separate the concept of <em>deployment</em> from the one of <em>release</em>. Users experience product updates governed by a release policy that may or may not be the same as the deployment policy. This really depends on the strategy of the organization.</p>



<p>Regardless of this distinction, though, I believe that constraining the capability of delivering value to the end user to a specific role undermines the agility of an organization.</p>



<p>The teams should be able to continuously release code into production. Mechanisms such as <em><a href="https://martinfowler.com/articles/feature-toggles.html">feature flags</a></em> should control the release of functionality. This means that the code in production doesn’t necessarily activate upon deploying it, making it possible for the organization to control when the functionality actually reaches the user.</p>



<p>In general, a deployment should be a non-event: nothing special, just another merge into the main branch that causes code to end up in production.</p>



<p>In a fast-paced world like the one we live in an organization shouldn’t constrain itself by requiring dedicated engineers to release new functionality. Modern environments require companies to always be experimenting. Organizations should empower non-technical teams to run experiments, analyse data and autonomously decide when to <em>release</em> new functionality. All of this, ideally, shouldn’t require <em>ad hoc</em> intervention from a specific engineer.</p>



<p>Job specs like this one feel like they’re trying to repurpose the role of the <em>Release Manager</em> to keep up with the latest trends by just changing a few words.</p>



<p>I don’t think release management goes away in a <em>DevOps</em> organization. Rather, the <em>Release Management</em> becomes ensuring that the rest of the organization can be autonomous at releasing. Achieving this means investing in automation and internal tools for the whole company.</p>



<h3>A Platform Engineer. But <em>cooler!</em></h3>



<blockquote><p>The DevOps Engineer will be a key leader in shaping processes and tools that enable cross-functional collaboration and drive CI/CD transformation. The DevOps Engineer will work closely with product owners, developers, and external development teams to build and configure a high performing, scalable, cloud-based platform that can be leveraged by other product teams.</p></blockquote>



<p>This is the <em>least bad</em> of the job specs I’ve encountered. It describes a set of responsibilities that usually pertain to a Platform or Infrastructure Team. Most of these teams often get renamed to DevOps Team and their members become DevOps Engineers for <em>fashion</em> reasons.</p>



<p>The Platform Engineering team is the key enabler for organizations that want to embrace the DevOps principles. But thinking that they only pertain to a specific team will hardly result in a successful journey.</p>



<p>This team will surely be responsible to build the relevant infrastructure that enables the other teams to build on top but they can’t be left alone in the understanding and application of those principles.</p>



<p>Developer teams will need to become autonomous at adopting and making changes to those systems; they will need to understand the implications of their code running in production; understand how to recognize if the system is not behaving as expected and be able to action to restore it.</p>



<p>Equally, the Product team should spend time understanding what new important capabilities derive from adopting DevOps practices. Code continuously flowing into production behind feature flags, containerization technologies, improved monitoring and alerting, <em>et cetera</em>, open endless opportunities.</p>



<p>Improved user experience and experimentation opportunities, for example, are an important asset to leverage to remain competitive.</p>



<figure><img loading="lazy" width="768" height="1273" src="https://alediaferia.com/wp-content/uploads/2020/07/matteo-vistocco-Dph00R2SwFo-unsplash-768x1273.jpg" alt="people riding boat on body of water photo" srcset="https://alediaferia.com/wp-content/uploads/2020/07/matteo-vistocco-Dph00R2SwFo-unsplash-768x1273.jpg 768w, https://alediaferia.com/wp-content/uploads/2020/07/matteo-vistocco-Dph00R2SwFo-unsplash-181x300.jpg 181w, https://alediaferia.com/wp-content/uploads/2020/07/matteo-vistocco-Dph00R2SwFo-unsplash-618x1024.jpg 618w, https://alediaferia.com/wp-content/uploads/2020/07/matteo-vistocco-Dph00R2SwFo-unsplash-927x1536.jpg 927w, https://alediaferia.com/wp-content/uploads/2020/07/matteo-vistocco-Dph00R2SwFo-unsplash-1236x2048.jpg 1236w, https://alediaferia.com/wp-content/uploads/2020/07/matteo-vistocco-Dph00R2SwFo-unsplash-scaled.jpg 1544w" sizes="(max-width: 768px) 100vw, 768px"><figcaption>Photo by <a href="https://unsplash.com/@mrsunflower94?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Matteo Vistocco</a> on <a href="https://unsplash.com/s/photos/collaboration?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></figcaption></figure>



<h2>What should companies be looking for?</h2>



<p>We’ve just gone through a few job specs that look for variations of a <em>DevOps Engineer</em> role and I’ve outlined what aspects I think are flawed in those roles. But what should companies look for, then?</p>



<p>Before blindly starting to hire for roles driven by industry fashion trends, organizations should rather invest in understanding what’s holding them back from being <em>DevOps</em>.</p>



<p>In the <a href="https://itrevolution.com/the-unicorn-project/">Unicorn Project</a>, <a href="https://twitter.com/RealGeneKim">Gene Kim</a> mentions the <em>Five Ideals</em> of successful DevOps organizations. I think they’re an effective set of principles to take the temperature of your …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://alediaferia.com/2020/07/27/the-mythical-devops-engineer/">https://alediaferia.com/2020/07/27/the-mythical-devops-engineer/</a></em></p>]]>
            </description>
            <link>https://alediaferia.com/2020/07/27/the-mythical-devops-engineer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24441392</guid>
            <pubDate>Fri, 11 Sep 2020 11:10:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to stream audio from your phone to your laptop with PulseAudio]]>
            </title>
            <description>
<![CDATA[
Score 142 | Comments 87 (<a href="https://news.ycombinator.com/item?id=24441112">thread link</a>) | @manjana
<br/>
September 11, 2020 | https://bash-prompt.net/guides/pulse-audio-bluetooth-streaming/ | <a href="https://web.archive.org/web/*/https://bash-prompt.net/guides/pulse-audio-bluetooth-streaming/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<p>These days your primary means of listening to music if likely from an app on your phone. So how do you get the music from your phone to your laptop or desktop that has better speakers?</p>
<p>The answer is to use Bluetooth and <a href="https://www.freedesktop.org/wiki/Software/PulseAudio/">PulseAudio</a>. PulseAudio is the modern sound implementation on the Linux desktop. It runs as a sound server and takes sound inputs such a microphone or your browser playing a YouTube video and directs this sound to outputs such as your Laptop’s speakers.</p>
<p>PulseAudio can take the audio from a Bluetooth connection and route it to your laptop’s speakers and is very simple to get running.</p>
<p>First, install the PulseAudio Bluetooth modules. On ArchLinux this is called <code>pulseaudio-bluetooth</code> and on Ubuntu/Debian it is called <code>pulseaudio-module-bluetooth</code>.</p>
<p>After you have installed this package open the following file:</p>
<pre><code>/etc/pulse/system.pa
</code></pre><p>And add the following couple of lines:</p>
<pre><code>load-module module-bluetooth-policy
load-module module-bluetooth-discover
</code></pre><p>Then, as your regular user, restart PulseAudio:</p>
<pre><code>$ pulseaudio -k
$ pulseaudio --start
</code></pre><p>And you’re all set!</p>
<p>All you need to do is to pair your phone and your computer and start playing something on your phone and it will play through your computer’s speakers.</p>

		</div></div>]]>
            </description>
            <link>https://bash-prompt.net/guides/pulse-audio-bluetooth-streaming/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24441112</guid>
            <pubDate>Fri, 11 Sep 2020 10:26:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A tiny instrument to measure the faintest magnetic fields – University of Basel]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24441000">thread link</a>) | @rbanffy
<br/>
September 11, 2020 | https://www.unibas.ch/en/News-Events/News/Uni-Research/A-tiny-instrument-to-measure-the-faintest-magnetic-fields.html | <a href="https://web.archive.org/web/*/https://www.unibas.ch/en/News-Events/News/Uni-Research/A-tiny-instrument-to-measure-the-faintest-magnetic-fields.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<!-- SKIPLINKS -->

    <!-- ALERT NOTIFICATION -->
    <!-- END ALERT NOTIFICATION -->

	<!-- Redirect Notification-->
	<!-- End Redirect Notification-->


<!-- INTRODUCTION-LINKS -->
<section id="introduction-links">
    <h6>Introduction Links</h6>
    
    <div>
        <nav>
           <h6>Introduction Links Navigation</h6>
            
        </nav>
    </div>
</section>
<!-- INTRODUCTION-LINKS END -->
<section id="locationfinder" data-url="/en.json">
           <h6>Locationfinder</h6>

<div id="category-list">
        <nav>
           <h6>Locationfinder Navigation</h6>    
            <p><img src="https://www.unibas.ch/.resources/unibas-main/webresources/img/icons/loading.gif" alt="Loading" title="Loading">
            </p>
        </nav>
	</div>

	


</section>

<header>
     <h6>Navigationarea University of Basel</h6>
    <nav>
        <h6>Metanavigation</h6>
    

        
    </nav>
</header><!-- end header --><section id="searchbar">
   <h6>Searchbar</h6>
    
</section><!-- end search-bar -->
    
    <section id="navigation-wrapper">
         <h6>Mainnavigation-Area</h6>

<!-- horizontalNavigation.ftl -->


<nav id="main-nav">
    <h6>Mainnavigation</h6>

    <ul>
                <li>
                    <a href="https://www.unibas.ch/en/News-Events.html" data-target="sub-0">News &amp; Events</a>
                        <nav id="sub-0">
                            <h6>News &amp; Events - Subnavigation</h6>
                            <ul>
                                <li>
                                    <a title="News" href="https://www.unibas.ch/en/News-Events/News.html">News</a>
                                </li>
                                <li>
                                    <a title="Newsletter" href="https://www.unibas.ch/en/News-Events/Newsletter.html">Newsletter</a>
                                </li>
                                <li>
                                    <a title="University in the News" href="https://www.unibas.ch/en/News-Events/Media-Review.html">University in the News</a>
                                </li>
                                <li>
                                    <a title="Public Events Calendar" href="https://www.unibas.ch/en/News-Events/Events.html">Public Events Calendar</a>
                                </li>
                                <li>
                                    <a title="University Events" href="https://www.unibas.ch/en/News-Events/-events.html">University Events</a>
                                </li>
                                <li>
                                    <a title="Social Media &amp; Blogs" href="https://www.unibas.ch/en/News-Events/Social-Media.html">Social Media &amp; Blogs</a>
                                </li>
                                <li>
                                    <a title="Media Database" href="https://www.unibas.ch/en/News-Events/Media-Database.html">Media Database</a>
                                </li>
                                <li>
                                    <a title="Media Service" href="https://www.unibas.ch/en/News-Events/Media-Service.html">Media Service</a>
                                </li>
                                <li>
                                    <a title="Coronavirus" href="https://www.unibas.ch/en/News-Events/Coronavirus.html">Coronavirus</a>
                                </li>
                            </ul>
                        </nav>
                </li>
                <li>
                    <a href="https://www.unibas.ch/en/Studies.html" data-target="sub-1">Studies</a>
                        <nav id="sub-1">
                            <h6>Studies - Subnavigation</h6>
                            <ul>
                                <li>
                                    <a title="Degree Programs " href="https://www.unibas.ch/en/Studies/Degree-Programs.html">Degree Programs </a>
                                </li>
                                <li>
                                    <a title="Course Directory" href="https://www.unibas.ch/en/Studies/Course-Directory.html">Course Directory</a>
                                </li>
                                <li>
                                    <a title="Dates " href="https://www.unibas.ch/en/Studies/Dates-Events.html">Dates </a>
                                </li>
                                <li>
                                    <a title="Application &amp; Admission" href="https://www.unibas.ch/en/Studies/Application-Admission.html">Application &amp; Admission</a>
                                </li>
                                <li>
                                    <a title="My Studies" href="https://www.unibas.ch/en/Studies/My-Studies.html">My Studies</a>
                                </li>
                                <li>
                                    <a title="Mobility" href="https://www.unibas.ch/en/Studies/Mobility.html">Mobility</a>
                                </li>
                                <li>
                                    <a title="Advice" href="https://www.unibas.ch/en/Studies/Advice.html">Advice</a>
                                </li>
                                <li>
                                    <a title="Student Life" href="https://www.unibas.ch/en/Studies/Student-Life.html">Student Life</a>
                                </li>
                                <li>
                                    <a title="FAQ Studies" href="https://www.unibas.ch/en/Studies/FAQ-Studies.html">FAQ Studies</a>
                                </li>
                            </ul>
                        </nav>
                </li>
                <li>
                    <a href="https://www.unibas.ch/en/Research.html" data-target="sub-2">Research</a>
                        <nav id="sub-2">
                            <h6>Research - Subnavigation</h6>
                            <ul>
                                <li>
                                    <a title="Research in Basel" href="https://www.unibas.ch/en/Research/Research-in-Basel.html">Research in Basel</a>
                                </li>
                                <li>
                                    <a title="Funding" href="https://www.unibas.ch/en/Research/Financing.html">Funding</a>
                                </li>
                                <li>
                                    <a title="Academic Careers" href="https://www.unibas.ch/en/Research/Academic-Careers.html">Academic Careers</a>
                                </li>
                                <li>
                                    <a title="Graduate Center" href="https://www.unibas.ch/en/Research/Graduate-Center.html">Graduate Center</a>
                                </li>
                                <li>
                                    <a title="UNI NOVA" href="https://www.unibas.ch/en/Research/Uni-Nova.html">UNI NOVA</a>
                                </li>
                                <li>
                                    <a title="Personalized Health Basel" href="https://www.unibas.ch/en/Research/Personalized-Health-Basel.html">Personalized Health Basel</a>
                                </li>
                            </ul>
                        </nav>
                </li>
                <li>
                    <a href="https://www.unibas.ch/en/Innovation.html" data-target="sub-3">Innovation</a>
                        <nav id="sub-3">
                            <h6>Innovation - Subnavigation</h6>
                            <ul>
                                <li>
                                    <a title="Your Entrepreneurial Journey" href="https://www.unibas.ch/en/Innovation/Your-Entrepreneurial-Journey.html">Your Entrepreneurial Journey</a>
                                </li>
                                <li>
                                    <a title="Entrepreneurship course" href="https://www.unibas.ch/en/Innovation/Entrepreneurship-course.html">Entrepreneurship course</a>
                                </li>
                                <li>
                                    <a title="Entrepreneurs Club" href="https://www.unibas.ch/en/Innovation/Entrepreneurs-Club.html">Entrepreneurs Club</a>
                                </li>
                                <li>
                                    <a title="Innovation Initiatives" href="https://www.unibas.ch/en/Innovation/Innovation-Initiatives.html">Innovation Initiatives</a>
                                </li>
                                <li>
                                    <a title="Propelling Grant" href="https://www.unibas.ch/en/Innovation/Propelling-Grants.html">Propelling Grant</a>
                                </li>
                            </ul>
                        </nav>
                </li>
                <li>
                    <a href="https://www.unibas.ch/en/Continuing-Education.html" data-target="sub-4">Continuing Education</a>
                        <nav id="sub-4">
                            <h6>Continuing Education - Subnavigation</h6>
                            <ul>
                                <li>
                                    <a title="News and events" href="https://www.unibas.ch/en/Continuing-Education/News-and-events.html">News and events</a>
                                </li>
                                <li>
                                    <a title="Programs" href="https://www.unibas.ch/en/Continuing-Education/Programs.html">Programs</a>
                                </li>
                                <li>
                                    <a title="Course Types and Degrees" href="https://www.unibas.ch/en/Continuing-Education/Degrees.html">Course Types and Degrees</a>
                                </li>
                                <li>
                                    <a title="Career and Continuing Education" href="https://www.unibas.ch/en/Continuing-Education/Career-and-continuing-education.html">Career and Continuing Education</a>
                                </li>
                                <li>
                                    <a title="Advanced Studies: Center and Team" href="https://www.unibas.ch/en/Continuing-Education/Advanced-Studies.html">Advanced Studies: Center and Team</a>
                                </li>
                                <li>
                                    <a title="FAQ" href="https://www.unibas.ch/en/Continuing-Education/FAQ.html">FAQ</a>
                                </li>
                            </ul>
                        </nav>
                </li>
                <li>
                    <a href="https://www.unibas.ch/en/University.html" data-target="sub-5">University</a>
                        <nav id="sub-5">
                            <h6>University - Subnavigation</h6>
                            <ul>
                                <li>
                                    <a title="About the University" href="https://www.unibas.ch/en/University/About-University.html">About the University</a>
                                </li>
                                <li>
                                    <a title="Management &amp; Organization" href="https://www.unibas.ch/en/University/Management-Organization.html">Management &amp; Organization</a>
                                </li>
                                <li>
                                    <a title="Administration &amp; Services" href="https://www.unibas.ch/en/University/Administration-Services.html">Administration &amp; Services</a>
                                </li>
                                <li>
                                    <a title="Networks &amp; Partnerships" href="https://www.unibas.ch/en/University/Networks-Partnerships.html">Networks &amp; Partnerships</a>
                                </li>
                                <li>
                                    <a title="University &amp; Society" href="https://www.unibas.ch/en/University/University-Society.html">University &amp; Society</a>
                                </li>
                                <li>
                                    <a title="Working at the University of Basel" href="https://www.unibas.ch/en/University/Working-at-the-University-of-Basel.html">Working at the University of Basel</a>
                                </li>
                                <li>
                                    <a title="Legal Regulations" href="https://www.unibas.ch/en/University/Legal-Regulations.html">Legal Regulations</a>
                                </li>
                                <li>
                                    <a title="Organizational units" href="https://www.unibas.ch/en/University/Organizational-units.html">Organizational units</a>
                                </li>
                                <li>
                                    <a title="Merchandise" href="https://www.unibas.ch/en/University/Merchandise.html">Merchandise</a>
                                </li>
                                <li>
                                    <a title="Contact &amp; Directions" href="https://www.unibas.ch/en/University/Contact-Directions.html">Contact &amp; Directions</a>
                                </li>
                                <li>
                                    <a title="Fundraising" href="https://www.unibas.ch/en/University/Fundraising.html">Fundraising</a>
                                </li>
                            </ul>
                        </nav>
                </li>
    </ul>
</nav>

<!--breadcrumb.ftl-->


<nav id="breadcrumb">
       <h6>Breadcrumb</h6>

        <ul>
                    <li>
                        <a title="Home" aria-label="Home" href="https://www.unibas.ch/en.html"></a>
                    </li>
                    <li>
                        <a href="https://www.unibas.ch/en/News-Events.html" title="News &amp; Events">News &amp; Events</a>
                    </li>
                    <li>
                        <a href="https://www.unibas.ch/en/News-Events/News.html" title="News">News</a>
                    </li>
                    <li>
                        <em>nav.selected </em><strong id="breadcrumb-current">A tiny instrument to measure the faintest magnetic fields</strong>
                    </li>
        </ul>
</nav>



    </section>
	<span id="page-content">Start of page content</span>

<section>
    <h6>Free Content</h6>
    
    <div>

        
        
        
        


        

        <article id="rsArticle">
            <!-- START CONTEND WIDE INHALT -->






<p><strong>Physicists at the University of Basel have developed a minuscule instrument able to detect extremely faint magnetic fields. At the heart of the superconducting quantum interference device are two atomically thin layers of graphene, which the researchers combined with boron nitride. Instruments like this one have applications in areas such as medicine, besides being used to research new materials.</strong></p>



            <div>

    <div>
        
        <p>
            <iframe width="420" height="315" src="https://www.youtube.com/embed/pGuQHxf2jdw" allowfullscreen=""></iframe>
        </p>
    </div>

<div>

    


    <div>
        <p>To measure very small magnetic fields, researchers often use superconducting quantum interference devices, or SQUIDs. In medicine, their uses include monitoring brain or heart activity, for example, while in the earth sciences researchers use SQUIDs to characterize the composition of rocks or detect groundwater flows. The devices also have a broad range of uses in other applied fields and basic research.</p>

<p>The team led by Professor Christian Schönenberger of the University of Basel’s Department of Physics and the Swiss Nanoscience Institute has now succeeded in creating one of the smallest SQUIDs ever built. The researchers described their achievement in the scientific journal <em>Nano Letters</em>.</p>

<h4><strong>A superconducting ring with weak links</strong></h4>

<p>A typical SQUID consists of a superconducting ring interrupted at two points by an extremely thin film with normal conducting or insulating properties. These points, known as weak links, must be so thin that the electron pairs responsible for superconductivity are able to tunnel through them. Researchers recently also began using nanomaterials such as nanotubes, nanowires or graphene to fashion the weak links connecting the two superconductors.</p>

<p>As a result of their configuration, SQUIDs have a critical current threshold above which the resistance-free superconductor becomes a conductor with ordinary resistance. This critical threshold is determined by the magnetic flux passing through the ring. By measuring this critical current precisely, the researchers can draw conclusions about the strength of the magnetic field.</p>

<h4><strong>SQUIDs with six layers</strong></h4>

<p>“Our novel SQUID consists of a complex, six-layer stack of individual two-dimensional materials,” explains lead author David Indolese. Inside it are two graphene monolayers separated by a very thin layer of insulating boron nitride. “If two superconducting contacts are connected to this sandwich, it behaves like a SQUID – meaning it can be used to detect extremely weak magnetic fields.”</p>

    </div>
</div>
<div>

    


           <figure id="showbox-2">
               <p><a href="https://www.unibas.ch/dam/jcr:eb317e73-26a7-4089-b158-bd8b6a1c9cea/SQUID_1000x370.jpg"><img src="https://www.unibas.ch/dam/jcr:eb317e73-26a7-4089-b158-bd8b6a1c9cea/SQUID_1000x370.jpg" title="Illustration of a conventional and the new design of the SQUID" alt="Illustration of a conventional and the new design of the SQUID"></a>
               </p>
               <figcaption><span>a) A conventional superconducting quantum interference device (SQUID) consists of a superconducting ring interrupted at two points by weak links (in this case a graphene layer). b) The new SQUID is made up of a stack of two-dimensional materials, including two graphene layers separated by a thin film of boron nitride. (University of Basel, Department of Physics) </span><a href="https://www.unibas.ch/dam/jcr:eb317e73-26a7-4089-b158-bd8b6a1c9cea/SQUID_1000x370.jpg"></a></figcaption>
           </figure>

    <div>
        <p>In this setup, the graphene layers are the weak links, although in contrast to a regular SQUID they are not positioned next to each other, but one on top of the other, aligned horizontally. “As a result, our SQUID has a very small surface area, limited only by the constraints of nanofabrication technology,” explains Dr. Paritosh Karnatak from Schönenberger’s team.</p>

<p>The tiny device for measuring magnetic fields is only around 10 nanometers high – roughly a thousandth of the thickness of a human hair. The instrument can trigger supercurrents that flow in minuscule spaces. Moreover, its sensitivity can be adjusted by changing the distance between the graphene layers. With the help of electrical fields, the researchers are also able to increase the signal strength, further enhancing the measurement accuracy.</p>

<h4><strong>Analyzing topological insulators</strong></h4>

<p>The Basel research team’s primary goal in developing the novel SQUIDs was to analyze the edge currents of topological insulators. Topological insulators are currently a focus of countless research groups all over the …</p></div></div></div></article></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.unibas.ch/en/News-Events/News/Uni-Research/A-tiny-instrument-to-measure-the-faintest-magnetic-fields.html">https://www.unibas.ch/en/News-Events/News/Uni-Research/A-tiny-instrument-to-measure-the-faintest-magnetic-fields.html</a></em></p>]]>
            </description>
            <link>https://www.unibas.ch/en/News-Events/News/Uni-Research/A-tiny-instrument-to-measure-the-faintest-magnetic-fields.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24441000</guid>
            <pubDate>Fri, 11 Sep 2020 10:10:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Interview with author of Hardcaml, OCaml DSL for hardware design]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24440785">thread link</a>) | @yminsky
<br/>
September 11, 2020 | https://signalsandthreads.com/programmable-hardware/ | <a href="https://web.archive.org/web/*/https://signalsandthreads.com/programmable-hardware/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<h2 id="003">0:03</h2>

<p>Welcome to Signals and Threads, in-depth conversations about every layer of the tech stack from Jane Street. I’m Ron Minsky. Today, we’re going to have a conversation about hardware, and in particular about how you can take the tools that come out of the world of chip design and apply them to a much broader space of problems than people typically think they can be applied to. And I’m joined in this conversation by Andy Ray.</p>

<h2 id="031">0:31</h2>

<p>Hello, Ron, good to be chatting with you.</p>

<h2 id="033">0:33</h2>

<p>Andy is a longtime veteran of the hardware industry. He spent over a decade building real shippable hardware designs, working on things like modems and video codecs. And along that time, he also did a lot of interesting work exploring and eventually designing his own alternative languages for expressing hardware designs. The final one was called <a href="https://github.com/janestreet/hardcaml">Hardcaml</a>, which is a hardware design language embedded inside <a href="https://ocaml.org/">OCaml</a>, which itself is the primary programming language we use here at Jane Street. And that work actually led him to us. And today he works here and leads Jane Street’s hardware design team. And so, to start with Andy, maybe you can tell us a little bit about why hardware is useful for a technology organization and an organization like ours, and what advantages it has over traditional software-style approaches?</p>

<h2 id="123">1:23</h2>

<p>Sure. So hardware allows you to build customized architectures for a specific problem, which can be tuned to trade off, at a very fine level, lots of things like performance, and cost and power usage. That lets you design a range of different products. Whereas with a CPU, you’re very much more limited in the software world to the CPU design that can meet the performance of the problem domain. I think the sorts of problems that it can solve are very, very broad. And you can see that just because well, a CPU is a hardware design, in fact. And you can create all sorts of hybrid designs with multiple CPUs or digital signal processors or custom hardware blocks that make up your final solution. So I think that’s why hardware exists, why it will always exist. It’s the fact that you can build architectures entirely suited to your problem domain that optimize along these sort of areas.</p>

<h2 id="230">2:30</h2>

<p>That description on the face of it sounds awesome. And in fact, it sounds from what you said so far, strictly superior to writing software. I don’t think that’s quite true. Can you see more about what the downsides are of operating inside of a hardware context?</p>

<h2 id="243">2:43</h2>

<p>Oh, my goodness, yes, there are a lot. So it is fundamentally this: hardware designs are much, much more difficult to write than equivalent software. So all that flexibility in choosing, you know, the architecture for your problem domain, you actually have to implement that. In software, you have reams and reams of support libraries that either your organization has developed or that you can pull in from open source or that you can go and purchase. To some extent that infrastructure works in hardware with the idea of intellectual property suppliers. They’re basically just companies who supply a hardware design for you to integrate into your system. That’s actually the job I used to do when we were developing video codecs.</p>

<h2 id="327">3:27</h2>

<p>Yeah. And just to interrupt for a second though, that was a bit of terminology that really confused me when I first encountered the hardware world. When people in hardware say, “IP,” they mean something like when a software person says “library.”</p>

<h2 id="338">3:38</h2>

<p>Correct.</p>

<h2 id="339">3:39</h2>

<p>Which is to say some component that somebody else wrote that you get to integrate. Except in this case, the component is a bundle of wires that you kind of plop into your design rather than something that looks more like a module or library.</p>

<h2 id="351">3:51</h2>

<p>Yeah, that’s right. I don’t know why that terminology came about, but it’s just always been called IP when you buy hardware library design. There’s some sort of infrastructure there for buying external blocks to integrate with your hardware. It’s a vastly smaller ecosystem than we have in software. It’s vastly more expensive. There is in the last maybe ten years more of an open source community around providing hardware blocks that you can integrate. But it’s still absolutely miniscule compared to software. And then just the process of writing hardware is slow and detailed. And I’m gonna say difficult. I’m not so sure it is really technically that difficult. It’s just that it’s so detailed, and you’re dealing with such big systems that it becomes a real problem trying to manage the complexity of all these very simple bits that sit together.</p>

<h2 id="449">4:49</h2>

<p>Right, I think of that as one of the paradoxes of hardware: hardware is in the micro, in many different ways, simpler than software.</p>

<h2 id="456">4:56</h2>

<p>Yes.</p>

<h2 id="457">4:57</h2>

<p>The thing that you’re generating in a hardware design is essentially some layout of the circuit, the individual gates and wires that connect them. And it’s some kind of fairly static graph that represents the structure of the computation, and is converted into, when you actually get one of these fabricated, actual bits of material laid out on a physical surface. And understanding how those individual pieces work, at least logically how they work, leaving the physics aside, is relatively simple. But then having a big design that does a lot of these things, is enormously hard to reason about.</p>

<h2 id="532">5:32</h2>

<p>It is and unfortunately, the abstraction tools we have, they take us some way. So you know, you talked about a chip design, which you can think of as a layout of just two things really, lots of lots of NAND gates (a Boolean AND function with the output NOTed) and metal wires that connect them together. And it’s interesting because NAND is a universal Boolean function. Any other Boolean function can be computed with the NAND function. That’s not true of AND, for example, you can’t create an OR with an AND, but you can create it with a NAND. And they are like, I think sixteen Boolean functions, and four of them are universal. I think NAND and NOR are quite often like the basis of technology (NOR being an OR gate with the output inverted). We don’t actually think about writing circuits at the level of just interconnected NAND gates. An interesting aside, I believe the first ARM processor was basically designed that way. But actually even lower, they were drawing the transistors for the NAND gates in like just a graphics package. That’s how they created the very first ARM processor. But that’s not how they do it now. So we’re a little bit above that: we work with a tool called a synthesizer, and it takes a slightly more abstract notion of a hardware design in which we can think about components like adders and multiplexers. And the job of the synthesizer will be to turn those components into the actual low level hardware components for the chip, which might be NAND gates if you’re doing an ASIC, it might be look-up tables for an FPGA. But that being said, it’s not massively above building it with NAND gates. But really a lot of the industry just works at this sort of level of putting together these macros, which represent adders and multiplexers, and multipliers and registers and just wiring them together and getting them to form some function.</p>

<h2 id="738">7:38</h2>

<p>So you were talking there about ASICS and FPGAs. Can you just quickly explain what those are.</p>

<h2 id="743">7:43</h2>

<p>An ASIC is a custom-made chip that can perform a single function. In contrast, an FPGA is a reprogrammable chip that can be programmed to perform many different functions.</p>

<h2 id="757">7:57</h2>

<p>Got it. So when you talked about what the advantages are of hardware, you talked about how by having much more control, you get to really optimize the things you care about via power consumption or performance or latency or whatever it is of the, of the, system. Can you put a little bit of meat on the bones of that? What is the scale of the improvements that you can get by taking something that you might do in software and moving it into a hardware design?</p>

<h2 id="825">8:25</h2>

<p>It’s obviously going to depend on the sort of problem you’re trying to solve. But you know, an area I know really well, video coding. I used to work on <a href="https://en.wikipedia.org/wiki/Advanced_Video_Coding">H.264</a> a lot and there was just a really good software implementation called <a href="https://en.wikipedia.org/wiki/X264">x264</a>, which was almost entirely written in assembly, using the SSE instructions, which is a vector instruction set on the x86 processor. And it could just about manage like real-time 1080p on modern Intel processors of the time, which were like four gigahertz processors. In order for it to achieve that sort of performance, you had to turn off lots of lots and lots of codec features. If you’re willing to go non-real-time, you could turn on all sorts of features that would compress it better. There’s an extremely large standard for H.264 that I used to read a lot, and there’s a lot of features on that thing, but you just can’t do them all. And so we used to target different markets, there was like, a sort of low-end video codec, which could fit in smaller FPGAs, could be used for like internet based communication. And there was like really high-end video codecs, which were built over multiple FPGAs, and had a really high end feature set, and was used for professional-grade encoding. So that’s the sort of video that you get over your satellite link or over your cable link. That bitstream is compressed as much as it possibly can be so they can fit more channels into that link. We didn’t have to compromise so much on the features to do that with hardware, we could pick the features that made the difference that got us to the bit rate, and they could run in real time. And you just couldn’t do that real time in software. You know, in that world, you’re looking at an order of magnitude more computation being done by these FPGAs. But these sort of things can scale massively. They’re like chips, which do packet processing, for example. So the idea here is you’ve got a switch and you want to do packet processing to detect threats in those packets to route …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://signalsandthreads.com/programmable-hardware/">https://signalsandthreads.com/programmable-hardware/</a></em></p>]]>
            </description>
            <link>https://signalsandthreads.com/programmable-hardware/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24440785</guid>
            <pubDate>Fri, 11 Sep 2020 09:37:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Checked exceptions: Java’s biggest mistake (2014)]]>
            </title>
            <description>
<![CDATA[
Score 107 | Comments 285 (<a href="https://news.ycombinator.com/item?id=24440536">thread link</a>) | @flying_sheep
<br/>
September 11, 2020 | http://literatejava.com/exceptions/checked-exceptions-javas-biggest-mistake/ | <a href="https://web.archive.org/web/*/http://literatejava.com/exceptions/checked-exceptions-javas-biggest-mistake/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-174">
	
	<!-- .entry-header -->

		<div>
		<p>Checked exceptions have always been a controversial feature of the Java language.</p>
<p>Advocates claim they ensure checking &amp; recovery from failures. Detractors say “catch” blocks can almost never recover from an exception, and are a frequent source of mistakes.</p>
<p>Meanwhile, Java 8 and lambdas are here. Are checked exceptions becoming obsolete in the Java world?<span id="more-174"></span></p>
<h3>The Intent of Checked Exceptions</h3>
<p>In the mid 90’s, James Gosling at Sun came up with a new language.</p>
<p>At the time, C++ programming required every single function return to be checked for error. He decided there had to be a better way, and built the concept of “exceptions” into Java.</p>
<p>The intent of <strong>checked exceptions</strong> was to locally flag, and force developers to handle, possible exceptions. Checked exceptions have to be declared on a method signature, or handled.</p>
<p>This was intended to encourage software reliability &amp; resilience. There was an intent to “recover” from contingencies – predictable outcomes other than success, such as InsufficientFundsException on attempting a payment. There was less clarity, as to what “recovery” actually entailed.</p>
<p><strong>Runtime exceptions</strong>&nbsp;were also included in Java. Since null pointers, data errors, and illegal states/ accesses could occur anywhere in code, these were made subtypes of RuntimeException.</p>
<p>Runtime exceptions can be thrown anywhere, without requiring to be declared, and are much more convenient. But would it be correct to use them instead?</p>
<h3>The Drawbacks</h3>
<p>The crucial point here, is that runtime &amp; checked exceptions are functionally equivalent.&nbsp;There is no handling or recovery which checked exceptions can do, that runtime exceptions can’t.</p>
<p>The biggest argument against “checked” exceptions is that most exceptions can’t be fixed. The simple fact is, <strong>we don’t own the code/ subsystem that broke.&nbsp;</strong>We can’t see the implementation, we’re not responsible for it, and can’t fix it.</p>
<p>Particularly problematic were the areas of JDBC (SQLException) and RMI for EJB (RemoteException). Rather than identifying fixable contingencies as per the original “checked exception” concept, these forced pervasive systemic reliability issues, not actually fixable, to be widely declared.</p>
<p>For any method, the possibility of failure includes all sub-methods called by it. Potential failures accumulate up the call tree. Declaring these on method signatures no longer offers a specific &amp; local highlight for the developer to watch for – declared exceptions spread throughout the call tree.</p>
<p>Most EJB developers have experienced this – declared exceptions become&nbsp;required on methods through the tier,&nbsp;or entire codebase. Calling a method with different&nbsp;exceptions&nbsp;requires dozens of methods to be adjusted.</p>
<p>Many developers were told to catch low-level exceptions, and rethrow them again as higher (application-level) checked exceptions. This required vast numbers – 2000 per project, upwards – of non-functional “catch-throw” blocks.</p>
<p>Swallowing exceptions, concealing the cause, double logging, and returning ‘null’/ uninitialized data all became common. Most projects could count 600+ mis-coded or outright errors.</p>
<p>Eventually, developers rebelled against the vast numbers of “catch” blocks, and the source of error these had become.</p>
<h3>Checked Exceptions – incompatible with Functional Coding</h3>
<p>And then we get to Java 8, with its new <i><b>functional programming&nbsp;</b></i>features – such as lambdas, Streams, and function composition.</p>
<p>These features are built on generics – parameter &amp; return types are genericized, so that iteration &amp; stream operations ( <code>forEach</code>, <code>map</code>, <code>flatMap</code>) can be written which perform a common operation, regardless of item type.</p>
<p>Unlike data types, however, declared exceptions can’t be genericized.</p>
<p>There is no possibility in Java to provide a stream operation (like, for example, &nbsp;<code>Stream.map</code>) which takes a lambda declaring some checked exception, &amp; transparently passes that same checked exception to surrounding code.</p>
<p>This has always been a major points against checked exceptions – all intervening code, between a throw and the receiving “catch” block, is forced to be aware of exceptions.</p>
<p>The workaround, of “wrapping” it in a RuntimeException, conceals the original type of the exception – rendering the exception-specific “catch” blocks envisaged in the original concept useless.</p>
<p>Finally we can capture Java’s new philosophy in a nutshell, by noting that none of the new “functional interfaces” in Java 8 declare checked exceptions.</p>
<h3>Conclusion</h3>
<p>Exceptions in Java provided major benefits in reliability &amp; error-handling over earlier languages.&nbsp;Java enabled reliable server &amp; business software, in a way C/ C++ never could.</p>
<p>Checked exceptions were,&nbsp;in their original form, an attempt&nbsp;to handle&nbsp;<i>contingencies</i>&nbsp;rather than&nbsp;<i>failures</i>.&nbsp;The laudable goal was to highlight specific predictable points (unable to connect,&nbsp;file not found,&nbsp;etc) &amp; ensure developers handled these.</p>
<p>What was never included in the original concept, was to force a vast range of systemic &amp;&nbsp;unrecoverable failures to be declared. These <em>failures</em>&nbsp;were never correct to be&nbsp;declared as checked exceptions.</p>
<p>Failures are generally possible in code, and EJB, web &amp; Swing/AWT containers already cater for this by providing an outermost “failed request” exception-handler. The most basic correct strategy is to rollback the transaction &amp; return an error.</p>
<p>Runtime exceptions allow any exception-handling possible with checked exceptions, but avoid restrictive coding restraints. This simplifies coding &amp; makes it easier to follow best practice of&nbsp;<a href="http://wikijava.org/wiki/10_best_practices_with_Exceptions#Throw_early_catch_late" onclick="javascript:_gaq.push(['_trackEvent','outbound-article','http://wikijava.org']);">throw early, catch late</a>&nbsp;where exceptions are handled at the outermost/ highest possible level.</p>
<p>Leading Java frameworks and influences have now definitively moved&nbsp;away from checked exceptions. Spring, Hibernate and modern Java frameworks/&nbsp;vendors&nbsp;use only runtime exceptions, and this convenience is a major factor in their popularity.</p>
<p>Personalities such Josh Bloch (Java&nbsp;Collections framework), Rod Johnson, Anders Hejlsberg (father of&nbsp;C#), Gavin King&nbsp;and&nbsp;Stephen Colebourn&nbsp;(JodaTime)&nbsp;have all come out against checked exceptions.</p>
<p>Now, in&nbsp;Java 8,&nbsp;lambdas are&nbsp;the&nbsp;fundamental step forward.&nbsp;These language features&nbsp;abstract the “flow of control” from functional operations within. As we’ve seen, this makes checked exceptions &amp; the requirement to “declare or handle immediately” obsolete.</p>
<p>For developers, it is always important to pay attention to reliability &amp; diagnose likely points of failure (contingencies) such as file open, database connection, etc. If we provide good error messages at this points, we will have&nbsp;created&nbsp;self-diagnosing software – a pinnacle of engineering achievement.</p>
<p>But we should do this with unchecked exceptions, and if we have to rethrow, should always use RuntimeException or an app-specific subclass.</p>
<p>As&nbsp;Stephen Colebourn says, if your projects&nbsp;are&nbsp;still using or advocating checked exceptions, your skills are 5-10 years out date.&nbsp;Java&nbsp;has moved&nbsp;on.</p>
<p><strong>How are you dealing with exceptions &amp; reliability? Add your thoughts now.</strong></p>
<p>References:<br>
– <a href="http://www.oracle.com/technetwork/articles/entarch/effective-exceptions-092345.html">Oracle: Barry Ruzek, Effective Java Exceptions<br>
</a>– <a href="http://tutorials.jenkov.com/java-exception-handling/checked-or-unchecked-exceptions.html" onclick="javascript:_gaq.push(['_trackEvent','outbound-article','http://tutorials.jenkov.com']);">Jacob Jenkov: Checked or Unchecked Exceptions</a><br>
– <a href="http://googletesting.blogspot.co.nz/2009/09/checked-exceptions-i-love-you-but-you.html" onclick="javascript:_gaq.push(['_trackEvent','outbound-article','http://googletesting.blogspot.co.nz']);">Google Testing blog: &nbsp;Checked exceptions, you have to go</a><br>
–&nbsp;<a href="http://www.artima.com/intv/handcuffs.html">Ander Hejlsberg on checked exceptions<br>
–</a>&nbsp;<a href="http://blog.joda.org/2010/09/checked-exceptions-bijava_9688.html" onclick="javascript:_gaq.push(['_trackEvent','outbound-article','http://blog.joda.org']);">Stephen Colebourne: Remove checked exceptions from Java</a></p>
<p>Counter-argument: &nbsp;James Gosling<br>
– <a href="http://www.artima.com/intv/solid.html" onclick="javascript:_gaq.push(['_trackEvent','outbound-article','http://www.artima.com']);">James Gosling on checked exceptions</a></p>
	</div><!-- .entry-content -->
	
	</article></div>]]>
            </description>
            <link>http://literatejava.com/exceptions/checked-exceptions-javas-biggest-mistake/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24440536</guid>
            <pubDate>Fri, 11 Sep 2020 08:57:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dynamic Pricing for Mobile Apps]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24440354">thread link</a>) | @gintonic
<br/>
September 11, 2020 | https://www.getmage.io/post/dynamic-pricing-for-mobile-apps | <a href="https://web.archive.org/web/*/https://www.getmage.io/post/dynamic-pricing-for-mobile-apps">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Thousand of companies and indie developers are involved in the ever-growing market of mobile apps. Competition is growing. The mobile market is thriving.<br></p><p>The job of a successful app publisher is hard. He needs to listen to the users' feedback, develop and publish new updates, watch out for the competition, and manage marketing campaigns. In other words, monitoring and optimizing everything on an ongoing basis is crucial. Managing resources, especially with a 30% revenue cut from the platform providers like Apple or Google, is essential.<br></p><p>One often unused optimization and growth strategy due to its complexity is dynamic pricing.</p><p>‍<br></p><h2>What is dynamic pricing?</h2><p>Dynamic pricing is a pricing strategy that is all about flexible prices. Flexible prices mean that they respond to market conditions.<br></p><p>In general, prices adjust according to the demand of the market. The best-known example of this concept is the pricing of flight tickets or the gas price from your favorite gas station. Both businesses price their products via demand. If the demand is high, the prices will be high.<br></p><p>Another well-known approach is a dynamic price based on the buyers' location. We often see this with physical goods. A good example is the price of an iPhone, which costs more in Germany than in the USA.<br></p><p>Compared to static pricing, dynamic pricing's main advantage is that the seller meets the demand of a market with a better price. This way, the seller avoids opportunity costs. In other words, he makes more money. He knows what to charge because he knows what buyers are willing to spend.</p><figure id="w-node-0f9bad4ca291-a9a5bdca"><p><img src="https://uploads-ssl.webflow.com/5eb96fb2022bac7d41a5bbdd/5f562fa22220c9c4c11836fe_mage-dynamic-pricing.png" loading="lazy" alt=""></p><figcaption>Sweet spot of dynamic pricing</figcaption></figure><h2>Adapting dynamic pricing for mobile apps<br></h2><p>Dynamic pricing is currently only available in a very simplified version in the app stores. Real dynamic pricing is mostly practiced with custom build software by very large and successful app companies like Tinder or Spotify.&nbsp;Most apps that use some dynamic pricing mostly follow two approaches: prices based on time and user location.</p><p>The idea of prices based on time is simple. Since we are talking about the mobile environment, the app provider knows its customer. He can segment between users who bought and users who did not buy after a specific period. If a user falls into the group of people who did not purchase anything, he will receive an offer with discounted prices. What a great catch!&nbsp;</p><p>The only problem with that strategy is that it will just work if the app publisher can reach the potential customer. Most people delete apps after a few minutes of using an app or days after installing it. In that case, in-app popups will not work. Push notifications might work out if the app is still on the user's phone. Sending emails will probably be the best approach, but the app publisher needs to know the email address for that to work. Also, the user needs to open the email, and please don't get me started on conversion rates of emails.</p><p>We can see that there is a massive overhead of technology needed to make this strategy work. An app publisher would need to develop an internal popup, a push notification, and an email system. That costs a lot of money.</p><p>The second approach is to base dynamic pricing on the buyers' location. A good example is segmentation by country.</p><p>Since the seller has some knowledge of his target market's purchasing power, he can set the base price in that market. Certain other countries receive discounts relative to that base price. Other countries with a higher purchasing power than the default market may receive a higher price relative to the base price. This abstract description could look something like the image below.</p><figure id="w-node-32a53b335696-a9a5bdca"><p><img src="https://uploads-ssl.webflow.com/5eb96fb2022bac7d41a5bbdd/5f47cc92d2fa4a3315898a8c_mage-diffrent-in-app-purchase-prices.png" loading="lazy" alt=""></p><figcaption>Different prices based on location</figcaption></figure><p>‍<a href="#"><br></a>For this kind of pricing, a high intense and expensive market research is needed. App publishers need to evaluate markets and determine the regional prices. This process can take months, and the worst part, the optimum is never fixed due to ever-changing market conditions. Spoiler alert: it's a continuous process.</p><p>‍<br></p><h2>The pain in adapting dynamic pricing for mobile apps</h2><p>Both ways (dynamic pricing based on time or location) represent excellent solutions. The only drawback is that both strategies are from enormous complexity.</p><p>App publishers may need to spend many resources on the development. They may need to hire market researches, data scientists, and other pricing specialists to implement a self-improving pricing system. This is why dynamic pricing is currently only seen in unicorn apps: It is simply expensive.</p><p>‍<br></p><h2>A fast and cost effective way to add dynamic pricing to mobile apps</h2><p>We developed and continuously improving a system that can bring dynamic pricing to any mobile app. As of this time of writing, we invested five months of development time, so you do not have to.</p><p>Mage is a "dynamic pricing as a service" solution for in-app purchases. Mage is scalable and usable for all kinds and sizes of apps. Due to the way app stores work at the moment, Mage works just for apps that use in-app purchases as a monetization strategy.</p><p>With Mage, app publishers can adopt dynamic pricing without the need for expensive market research, data science, and development teams.</p><p>Mage makes manually interpreting reports as well as generating and implementing new prices a thing of the past. Mage is fully automated and continuously fed with new data from the App Publishers' target markets. Mage is affordable and offers a free plan for young apps, who are just starting their journey. The integration of Mage takes around two to eight hours, depending on the apps complexity.</p><figure id="w-node-93b7b888b407-a9a5bdca"><p><img src="https://uploads-ssl.webflow.com/5eb96fb2022bac7d41a5bbdd/5f47ccc48af7b24655e46a33_mage-dynamic-pricing-solution.png" loading="lazy" alt=""></p><figcaption>Mage Dynamic Pricing As A Service Solution</figcaption></figure><h2>How to dynamically price in-app purchases</h2><p>First, you need to sign up via our <a href="https://www.getmage.io/">Website</a>. After that, you need to add your app, product groups, and products to our dashboard. Once you configured everything, Mage will give you instructions on setting up your app store products. The last step is implementing the simple, lightweight, and open-source Mage SDK. Currently, our mobile SDKs are available for iOS, Android, and React-Native Apps. For further information on how to get started, please read our <a href="https://www.getmage.io/documentation/integration-guide">Integration Guide</a>.<br></p><p>‍</p></div></div></div>]]>
            </description>
            <link>https://www.getmage.io/post/dynamic-pricing-for-mobile-apps</link>
            <guid isPermaLink="false">hacker-news-small-sites-24440354</guid>
            <pubDate>Fri, 11 Sep 2020 08:29:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I interviewed 7 London startups about C19. Here are the 5 takeaways for survival]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24440239">thread link</a>) | @Ozzie-D
<br/>
September 11, 2020 | https://startupsoflondon.com/5-key-principles-london-startups-use-to-survive/ | <a href="https://web.archive.org/web/*/https://startupsoflondon.com/5-key-principles-london-startups-use-to-survive/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-elementor-type="wp-post" data-elementor-id="6277" data-elementor-settings="[]">
						<div>
							<div>
							<section data-id="33017726" data-element_type="section">
						<div>
							<div>
					<div data-id="6f4823cc" data-element_type="column">
			<div>
							<div>
						<div data-id="13ef0a77" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>We have been spending the last three months interviewing startups from London to ask them about how they are adapting to this new post-pandemic situation and the core principles they depend on to survive C-19. At the end of these interviews, we compiled their learnings into a documentary.&nbsp;</p><p>We will cover their experiences under five chapters: The first chapter is about<b> fragility versus agility</b>. Yes, startups are very agile but at the same time, they are very fragile due to lack of resources. The second one is how <b>doubling the burn rate doubles the runway</b>. The third chapter is about <b>bubbles of opportunity</b>. Some startups will discover those bubbles of opportunity and rise to the top whereas others will not and unfortunately drown. The fourth idea is about <b>the need to pivot for the new needs</b>, and this is only possible by a new type of collaboration; not just the collaboration between individuals, but collaboration between startups and other companies. Lastly, the fifth chapter is about <b>adapting to the new rules</b> and monetisation funding office space, how teams collaborate, how they develop products and more. Extremely exciting stuff. We hope you enjoy them all!</p><p>This documentary brings together<b> 7 interviews </b>we have conducted with founders and thought leaders in the London startup ecosystem.</p><div>
	
	<div>
			<p><img data-expand="600" src="https://cdn.shortpixel.ai/client/q_glossy,ret_img/https://cdn.shortpixel.ai/client/q_glossy,ret_img/https://startupsoflondon.com/wp-content/uploads/2020/03/Advertise300-250.png" data-src="https://cdn.shortpixel.ai/client/q_glossy,ret_img/https://cdn.shortpixel.ai/client/q_glossy,ret_img/https://startupsoflondon.com/wp-content/uploads/2020/03/Advertise300-250.png" data-srcset="https://cdn.shortpixel.ai/client/q_glossy,ret_img/https://cdn.shortpixel.ai/client/q_glossy,ret_img/https://startupsoflondon.com/wp-content/uploads/2020/03/Advertise300-250.png 2x, https://cdn.shortpixel.ai/client/q_glossy,ret_img/https://cdn.shortpixel.ai/client/q_glossy,ret_img/https://startupsoflondon.com/wp-content/uploads/2020/03/Advertise300-250.png 1x" width="300" height="250" alt="" srcset="https://cdn.shortpixel.ai/client/q_glossy,ret_img/https://cdn.shortpixel.ai/client/q_glossy,ret_img/https://startupsoflondon.com/wp-content/uploads/2020/03/Advertise300-250.png 2x, https://cdn.shortpixel.ai/client/q_glossy,ret_img/https://cdn.shortpixel.ai/client/q_glossy,ret_img/https://startupsoflondon.com/wp-content/uploads/2020/03/Advertise300-250.png 1x">
			
			</p>
		</div>
</div>



<ul><li><a href="https://startupsoflondon.com/startups-surviving-covid-19-6-philip-mundy-of-pando-health/">Philip Mundy, Pando Health</a></li><li><a href="https://startupsoflondon.com/startups-surviving-covid-19-2-michael-krayenhoff-of-the-inner-circle/">Michael Krayenhoff, Inner Circle</a></li><li><a href="https://startupsoflondon.com/startups-surviving-covid-19-1-tom-previte-of-launch22/">Tom Previte, Launch 22</a></li><li><a href="https://startupsoflondon.com/startups-surviving-covid-19-3-jacob-wedderburn-of-stasher/">Jacob Wedderburn, Stasher</a></li><li><a href="https://startupsoflondon.com/seedlegals-is-a-lawtech-solution-for-startup-funding-startups-of-london-2/">Anthony Rose, Seedlegals</a></li><li><a href="https://startupsoflondon.com/iprooving-your-online-identity-9/">Andrew Bud, iProov</a></li><li><a href="https://startupsoflondon.com/startups-surviving-covid-19-7-alexander-fahie-of-ethical-angel/">Alexander Fahie, Ethical Angel</a></li></ul></div>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
				<section data-id="1e9ff62e" data-element_type="section">
						<div>
							<div>
					<div data-id="68b6ccd6" data-element_type="column">
			<div>
							<div>
						<div data-id="53a60830" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h3>Watch the interview of 5 Key Principles London Startups Use to Survive:</h3>		</p>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
				<section data-id="63a471e9" data-element_type="section">
						<div>
							<div>
					<div data-id="1ea40dc" data-element_type="column">
			<div>
							<div>
						<div data-id="31d223c0" data-element_type="widget" data-settings="{&quot;aspect_ratio&quot;:&quot;169&quot;}" data-widget_type="video.default">
				<div>
					<p>
			<iframe allowfullscreen="" title="youtube Video Player" src="https://www.youtube.com/embed/Wac6wma3VMg?feature=oembed&amp;start&amp;end&amp;wmode=opaque&amp;loop=0&amp;controls=1&amp;mute=0&amp;rel=0&amp;modestbranding=0"></iframe>		</p>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
				<section data-id="7a7db0fe" data-element_type="section">
						<div>
							<div>
					<div data-id="58d4a3c2" data-element_type="column">
			<div>
							<div>
						<div data-id="7292d15e" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>1. There is an inherent tension between <b>agility and fragility</b>, just like some systems become less resilient as they become more efficient, startups are very agile which works in their favour, but they are at the same time very fragile due to the nature of how chasing next rounds of funding work.</p><p>2. The argument that has been embraced by most startups brings us to this quote:&nbsp;<b>“half the burn rate to double the runway”</b>. While this makes sense for many, it creates second-order effects that are difficult to navigate. Many startups rely on other startups as their customers, not to count the consultants and other service providers that work around startups.</p><p>3. There are always<b> bubbles of opportunity </b>and they act like pockets of air in what is otherwise a deep ocean of problems. Finding those bubbles mean prioritising short term ROI (return on investment) rather than the long term. Survival in times like this might depend more on commercial cunning than focusing on innovation with a possible future return.</p><p>4. The idea that startups should be <b>“Pivoting for new needs” </b>has also gathered a consensus. Some startups pull this off better than others and it comes down to the team itself. We love paying lip service to people and culture, but it usually remains a second or third priority. However, times like these test startups and teams and only those who invested in culture thrive.</p><p>5. The next chapter is that of <b>a new normal</b>. We don’t exactly know what it will look like, but as startups can piece together what the future will look like, they will be able to afford more risks and invest more heavily into the future.</p><p>Make sure to visit our <a href="https://youtube.com/startupsoflondon">Youtube Channel</a> for all the interviews. </p></div>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
				<section data-id="2c7ecdcf" data-element_type="section">
						
		</section>
				<section data-id="5b752236" data-element_type="section">
						<div>
							<div>
					<div data-id="7cb85f94" data-element_type="column">
			<div>
							<div>
						<div data-id="6952290" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>One thing that is great about Startups of London is that you get to discover new businesses and meet people. To stay in the loop and understand the London tech scene better, consider subscribing to our social media channels linked below.</p>
<p><b>Each week,</b> we will be visiting a new startup office to meet with their team &amp; founders. Stay tuned!</p></div>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
				<section data-id="3a9739f8" data-element_type="section">
						
		</section>
				<section data-id="35651a78" data-element_type="section">
						
		</section>
				<section data-id="3814a0a9" data-element_type="section">
						
		</section>
						</div>
						</div>
					</div></div>]]>
            </description>
            <link>https://startupsoflondon.com/5-key-principles-london-startups-use-to-survive/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24440239</guid>
            <pubDate>Fri, 11 Sep 2020 08:10:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I built an app to fix my depression]]>
            </title>
            <description>
<![CDATA[
Score 261 | Comments 174 (<a href="https://news.ycombinator.com/item?id=24439612">thread link</a>) | @zoozla
<br/>
September 10, 2020 | http://blog.elifiner.com/how-i-built-an-app-to-fix-my-depression/ | <a href="https://web.archive.org/web/*/http://blog.elifiner.com/how-i-built-an-app-to-fix-my-depression/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-174">
	<!-- .entry-header -->

	
	
	<div>
		
<p>I was first diagnosed with depression when I was working on a startup in 2007. I went to the doctor, told him I was feeling mild flu symptoms for a couple of months, he asked me a few questions, determined that I had depression, gave my some SSRIs, and sent me home.</p>



<p>It worked for a while, but then 2008 happened, our startup collapsed, the stakes got higher and the depression came back. The doc recommended I up the dosage, but I could see this would eventually lead me to a straitjacket.</p>



<p>Over the years I’ve tried different meds, various forms of therapy, studied and actively practiced life coaching, got married, had kids, moved to another country and changed everything I could think of about my life. Unfortunately the dark bouts of depression remained.</p>



<p>About four years ago I stumbled on a book called Highly Sensitive Person that absolutely blew my mind. I realized I had very intense emotions that I was culturally programmed to repress, which caused my psyche to overload and go into full apathy mode also known as clinical depression.</p>



<p>I’ve been on a path to figure out how to process my emotions without repressing them and combined my personal experience with several non-mainstream techniques to build Wuju. It’s an online app that can help you tap into your hidden emotions and release them so they no longer influence your behaviour or cause depressive symptoms.</p>



<p>I’ve used it in the last 18 months to deal with parenting two kids, surviving infidelity, losing my job, starting a business, and covid anxiety. My longest bouts of depression now last a day at most and even that doesn’t happen too often.</p>



<p>You can try it too: <a href="https://beta.wuju.app/">beta.wuju.app</a></p>




	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>http://blog.elifiner.com/how-i-built-an-app-to-fix-my-depression/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24439612</guid>
            <pubDate>Fri, 11 Sep 2020 06:02:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Musings on the Impossibility of Testing]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 48 (<a href="https://news.ycombinator.com/item?id=24439511">thread link</a>) | @george3d6
<br/>
September 10, 2020 | https://blog.cerebralab.com/Musings_on_the_impossibility_of_testing | <a href="https://web.archive.org/web/*/https://blog.cerebralab.com/Musings_on_the_impossibility_of_testing">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
        <p>Published on: 2020-09-11</p>
        
<p>I'm always a bit flabbergasted when I see how people test their code (especially with unit tests). Often I can't figure out a cohesive set of rules based on which the tests are written.</p>
<p>Testing seems to work from a pragmatic perspective, we have evidence it works, but different people define "testing" in different ways. I'm awfully afraid that what some people refer to as "testing" is completely unrelated to that unrigorous but pragmatic practice that saves us from production bugs.</p>
<h2>I - A contrived example</h2>
<p>To showcase my arbitrary formalism as it relates to testing, I think it's worthwhile to look at some cases:</p>
<h4>1)</h4>
<pre><code># Testing a multiplication function
func multiply(int a, int b) -&gt; int

func test_1():
  assert 2*5 == multiply(2,5)
  assert 10*12 == multiply(12,10)

func test_2():
  assert 10 == multiply(2,5)
  assert 120 == multiply(12,10)

func test_3():
  assert type(multiply(2,5)) == int
  assert type(multiply) == func(int,int)-&gt;int
</code></pre>
<h4>2)</h4>
<pre><code># Testing an image classification algorithm
func classify(arr[int] image) -&gt; str

func test_1():
  assert img_classification_nn(to_arr('cat.jpg')) == classify(to_arr('cat.jpg'))
  assert img_classification_nn(to_arr('dog.jpg')) == classify(to_arr('dog.jpg'))

func test_2():
  assert 'cat' == classify(to_arr('cat.jpg'))
  assert 'dog' == classify(to_arr('dog.jpg'))

func test_3():
  possible_targets = ['cat','cheta','tiger','dog','wolf','coyote','other']
  assert classify(to_arr('rand_img_1.jpg')) in possible_targets
  assert classify(to_arr('rand_img_2.jpg')) in possible_targets
</code></pre>
<p>For both examples, <code>test_1</code> obviously makes no sense. You're testing the functionality of a function using another function that does the same thing. If the function used to assert correct functionality is better (i.e. if <code>*</code> is better than <code>multiply</code> or <code>img_classification_nn</code> is better than <code>classify</code>), than one should simply use that function instead. If they are equally flawed, then the tests are redundant.</p>
<p>These kinds of tests are a theatrical performance to build up an illusion of quality. Usually spotted in enterprise-grade codebases and teams that harp on about TDD a lot, I'll classify these as <strong>redundant checks</strong>.</p>
<hr>
<p>Next, <code>test_2</code> is more interesting, it's comparing the result of a function with what a human would expect the result of that function to be. Here I would argue the test makes sense for the <code>classify</code> function but not for the <code>multiply</code> function.</p>
<p>Computers are good at multiplying, humans are horrible at it. So testing this function against an arbitrary number of human answers is much more likely to reveal flaws with the human's answer rather than the computer's. Since the function is very simple, time would probably better spent reviewing the actual code to make sure it's error-free.</p>
<p>On the other hand, computers aren't very good at classifying images (though they are getting there), but humans are spot on. So using a human's answers to validate a vision algorithm makes perfect sense.</p>
<p>We'll call these types of tests <strong>human validations</strong>.</p>
<hr>
<p>Finally, we get to <code>test_3</code>, which superficially seems less flawed than the other two. It's more of a sanity check than a test, we aren't checking the actual return value of the function in a given case, we are instead checking a higher-level behavior.</p>
<p>These tests are much more common in the codebases of dynamic languages, and for good reason. In our first example, we are just validating the signature of a function, something a compiler will implicitly do for us in any statically typed language.</p>
<p>In the second example, we are instead working around a limitation of our type system. We are checking if the result of our function (a string) is contained within 7 different values (the possible things our function should classify images as), which we could test implicitly by using a language that supports <code>enum</code> types and writing <code>classify</code> such that it returns an enum of those 7 classes.</p>
<p>Basically, these kinds of tests can be useful, but they are the kind of things a compiler can handle automatically when they are present they usually indicate a mistake in the language the programmer is using for the project. We'll call these <strong>compiler rules</strong>.</p>
<hr>
<p>Obviously, this system is fairly arbitrary, it's just a conclusion I reached after looking at various codebases and talking with various people about their tests, but I find that it works quite well.</p>
<p>To re-iterate, we have:</p>
<ul>
<li>redundant checks</li>
<li>human validation</li>
<li>compiler rules</li>
</ul>
<h2>II - Compiler rules</h2>
<p>Compiler rules are great, but it's a bad sign when they leak into your testing.</p>
<p>Some amount of compiler rules leaking into testing can't be helped. Until the advent of Rust and/or well-performing libraries for safe multi-threading, testing thread safety should have been a requirement in many codebases. Similarly, before modern type system and allocation techniques, one ought to assume various now-pointless memory checks might have fared well within a codebase (and, I assume, still do on some embedded devices).</p>
<p>Even more, switching to more modern languages and compilers is often a task much harder than just writing some tests, but I think these tests should be viewed as a cautionary sign against the language currently used. If they only cover a small but critical percentage of the codebase, everything is fine, if they cover most of it, it's an indicator of using the wrong compile-time tooling.</p>
<p>The one difficult thing about these tests might be spotting them, an inexperienced team might be writing loads of these tests without realizing there are better alternatives to the compile-time toolchain they are using which would replace the need for them.</p>
<h2>III - Redundant checks</h2>
<p>Redundant checks are often pointless busywork, but they can serve a valuable role in some cases.</p>
<p>The two main scenarios that come to mind are as follows:</p>
<ol>
<li><p>Given two versions of the same function, one well-proven and one "experimental", where the "experimental" function has some benefits in terms of performance or generalizability, it seems reasonable to test the "experimental" function using the well-proven approach. Still, the overhead here is so severe I find it difficult to think of a real-world example where this applies.</p>
</li>
<li><p>Given two versions of the same function, one in a "new" codebase and one an "old" codebase, it makes sense to test the "new" version with the "old" version. In this sense, going back to compiler rules, redundant checks can be useful in the process of refactoring, especially for major changes like changing the language or the core framework upon which the project is built. However, this seems useful only as a "temporary" measure rather than a permanent fixture of a project.</p>
</li>
</ol>
<p>That being said, I'd wager that most tests falling in this category, as mentioned before, are there only as "filler" and indicative of a much bigger underlying problem of a team that engages in busywork. If I ever accepted such a test, I would require plenty of complimentary comments to explain why they exist and when they can be removed.</p>
<h2>IV - Human validation</h2>
<p>Human validation is the "sanest" type of testing one can perform, it can be replaced by good practices or good languages. The problem with human validation comes from the fact that in some cases human intelligence can't solve the problems the software is designed to solve or can't cover all the edge cases the software will encounter.</p>
<p>Take for example banking software. It's fairly easy to imagine what should happen with a piece of banking software that provided dozens of customers, hundreds of transactions, and a few regulatory restrictions. All the logic there can be written down into tests that validate our software. However, the software itself must scale to millions of customers, trillions of transactions, and thousands of regulatory restrictions. Something a human mind can't comprehend coherently in order to write the tests.</p>
<p>Still, banking software is an easy example, because the various components might be test-able and their limited logic might be fully comprehensible by a human, even accounting for all the edge cases. This is because the inputs to the software are very well defined, there are only so many things one can do with a banking API, a finite space which a human mind can explore exhaustively when properly broken down.</p>
<p>One real problem arises when we have software with a very broad and/or poorly define input and/or outputs spaces. A few examples of these would be:</p>
<ul>
<li>Scrappers that distill information from a broad range of websites (e.g. the ones used by a search engine)</li>
<li>Machine learning algorithms meant to work on a broad range of data (e.g. a decision tree or a gradient boosting classifier implementation in a library like sklearn)</li>
<li>Any software that has to work well with user-provided code extensions (e.g. think a video game-like Skyrim that has to support mods)</li>
<li>Simulation software (e.g. physics simulations)</li>
<li>Creative software (e.g. multimedia editing &amp; creation, game engines)</li>
<li>Compilers</li>
</ul>
<p>One can separate these into components with input-output spaces that can be easily comprehended by the human mind, but some components that suffer from the above problems are bound to remain. It also introduces the problem of writing code separation in such a way that components can be easily tested, rather than with refactoring, extension, speed, or readability as the main concern.</p>
<h2>V - Human validation and cost</h2>
<p>Assuming that we've designed our software such that it has many human-comprehensible components, the issue of cost remains. Human-comprehensible is a vague term, there are many things which, given enough time, a person could write exhaustive tests for, but in practice, this often takes more time than we can allocate. Furthermore, in certain situations, even in the limited input&amp;output space scenario, it might still be easier to write the "generative" logic (the one that maps inputs to outputs) than to come up with mappings ourselves.</p>
<p>In certain cases, exhaustive validation can be done, but it can be …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.cerebralab.com/Musings_on_the_impossibility_of_testing">https://blog.cerebralab.com/Musings_on_the_impossibility_of_testing</a></em></p>]]>
            </description>
            <link>https://blog.cerebralab.com/Musings_on_the_impossibility_of_testing</link>
            <guid isPermaLink="false">hacker-news-small-sites-24439511</guid>
            <pubDate>Fri, 11 Sep 2020 05:41:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The IRS is offering over $500k in bounty to crack Monero]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24439377">thread link</a>) | @seigando
<br/>
September 10, 2020 | https://xitheon.com/news/the-irs-is-offering-over-500000-in-bounty-to-anyone-who-is-able-to-crack-moneros-privacy/ | <a href="https://web.archive.org/web/*/https://xitheon.com/news/the-irs-is-offering-over-500000-in-bounty-to-anyone-who-is-able-to-crack-moneros-privacy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><span>September 11, 2020 in </span><span><a href="https://xitheon.com/category/news/" rel="category tag">News</a></span> </p></div><div>

<p>In an interesting and perhaps dangerous development, the Internal Revenue Service (IRS) has announced that it is seeking candidates who may be able to crack Monero’s privacy features in exchange for a bounty of a total of $625,000 USD, in an effort to utilize the method to unmask individuals behind Monero transactions.</p>
<p>Titled “Pilot IRS Cryptocurrency Tracing”, Notice ID <a href="https://beta.sam.gov/opp/3b7875d5236b47f6a77f64c19251af60/view?index=opp">2032H8-20-R-00500</a>, which was published on Sep 04, 2020 at 01:55 pm, acknowledges that agencies currently have limited tools and resources effective towards tracing privacy coin based transactions, specifically citing Monero &amp; Layer 2 network protocol –</p>
<blockquote><p>Currently, there are limited investigative resources for tracing transactions involving privacy cryptocurrency coins such as Monero, Layer 2 network protocol transactions such as Lightning Labs, or other off-chain transactions that provide privacy to illicit actors.</p></blockquote>
<p>Monero is mentioned a total of 11 times in the associated <a href="https://beta.sam.gov/api/prod/opps/v3/opportunities/resources/files/bb0247a3accc46beb2901af74b78438d/download?api_key=null&amp;token=">Request for Proposal (RFP)</a>, with notable mentions in it’s goals of this cracking challenge,</p>
<h3><img loading="lazy" src="https://xitheon.com/wp-content/uploads/2020/09/rfp.png" alt="" width="976" height="564" srcset="https://xitheon.com/wp-content/uploads/2020/09/rfp.png 976w, https://xitheon.com/wp-content/uploads/2020/09/rfp-300x173.png 300w, https://xitheon.com/wp-content/uploads/2020/09/rfp-768x444.png 768w" sizes="(max-width: 976px) 100vw, 976px"></h3>

<p>The IRS will pay $500,000 for the completion of a working concept for a utility that is able to crack targeted transactions and wallets, as well as a second payment of $125,000 once a pilot program is successfully completed and approved by the agency. Those interested in applying have until September 16th, 2020 to do so.</p>
<p>One would be inclined to believe that far more money is laundered and shuffled around using cash (fiat) than it is Monero or other privacy coins, however the IRS doesn’t seem to think so, and it’s willing to shell out big bucks for a beta. Monero allows users to send funds to another party without the sender or receiver address and the amount being revealed, much like cash but fairly minted.</p>
<p>Something doesn’t seem right about this. Perhaps it’s the fact that all of this suggests that the IRS would go as far as cracking into a safe in your home to see where you stand financially. Would they? Should the IRS have the ability to see all of the information otherwise obfuscated even in instances where the parties involved in a transaction are not under active investigation?</p>
<p>Now it’s not being suggested here that people should not pay taxes, if you claim your citizenship then certainly you should also pay it’s taxes if it’s in your lawful interest to do so. What’s questionable however is the intrusion of privacy. The IRS does not exclusively need the ability to uncover the sender, receiver or amount of a transaction to determine if someone is not paying taxes, they can allocate resources towards tracking that within their own confines.</p>
<p>I know I know, “If you have nothing to hide” right? well if that’s the case let’s just stop using doors and curtains too.</p>

</div></div>]]>
            </description>
            <link>https://xitheon.com/news/the-irs-is-offering-over-500000-in-bounty-to-anyone-who-is-able-to-crack-moneros-privacy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24439377</guid>
            <pubDate>Fri, 11 Sep 2020 05:11:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Most Efficient Way to Solve Problems]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24439304">thread link</a>) | @lucasfcosta
<br/>
September 10, 2020 | https://lucasfcosta.com/2020/09/05/not-having-problems.html | <a href="https://web.archive.org/web/*/https://lucasfcosta.com/2020/09/05/not-having-problems.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p>It’s Monday. The first of the seven alarms you’ve set on your phone soars louder than the Big Ben. It sends chills down your spine announcing the impending doom: your 8 AM commute. You put on that white shirt you’re sick of, and head to the most crowded place on earth: the <a href="https://www.cityam.com/londons-most-crowded-tube-lines-revealed/">northern line</a>.</p>

<p>Your commute is a problem, and you want to solve it. <strong>The challenge with <em>solving</em> problems is that it’s usually harder to find a solution than it is <em>not</em> to have that particular issue in the first place</strong>.</p>

<p>“Why didn’t I buy that used Toyota Prius for half the price?”. “It’s time to start cycling; perhaps it will get me in shape too”. “Does Tim Ferris <em>really</em> wake up at five? I bet no one takes the tube at that time”.</p>

<p>Buying a car, commuting by bike, or waking up earlier are all <em>solutions</em> to the problem of having an uncomfortable commute. Nevertheless, they’re imperfect because they are <em>patches</em>.</p>

<p>If you buy a car, you’ll still get stuck in traffic. If you buy a bike, you’ll get sweaty, and you’ll have to change clothes when you get to work. Personally, I love waking up at five, and at that time there’s definitely no one in the tube, but it doesn’t matter how early I get out of bed, I still have to face a thirty-minute commute.</p>

<p><strong>It’s rare, if not impossible, to apply patches which completely resolve the problems you have. More often than not, applying patches creates new problems.</strong></p>

<p>When faced with a problem, instead of immediately trying to patch it, I’d recommend you to take a step back and think about whether you could avoid it altogether.</p>

<p>Just because you <em>hate</em> commuting, it doesn’t mean you should look for ways to make it more pleasant. The most efficient way to solve the commute problem is <em>not</em> to commute at all.</p>

<p>If you work from home, you won’t need to spend any money in a car, put any effort in cycling, or ruin your circadian rhythm by waking up too early.</p>

<p>Now think about managing a website which depends on a particular RESTful API, for example. Every time you make changes to the underlying API, you’ll have to update your client. These updates are time-consuming, and they need to happen immediately. Otherwise, you won’t be able to deploy either your back-end or front-end.</p>

<p>In this case, instead of trying to patch the problem by finding more complicate and suboptimal solutions, like, for example, synchronising deployments, you could avoid the problem altogether by <em>not</em> making breaking changes to your API’s routes.</p>

<p>If you version your API by prefixing each of its routes, you won’t break the client. Therefore, you won’t have to synchronise deployments or immediately schedule work to update your front-end as soon as you start changing the server.</p>

<p>Instead of <em>patching</em> the problem, you eliminated it.</p>

<p>Yet, you can’t <em>always</em> completely eliminate all obstacles. There is a third kind of solution, which is a mix of the previous two. Even though it involves a patch, its patch entirely eliminates the problem.</p>

<p>You can’t, for example, solve every software problem by <em>not</em> creating any software. Even though software creates issues, it makes our lives significantly better most of the time.</p>

<p>Instead of trying to eliminate software altogether, you should find ways to write <em>less</em> software.</p>

<p>UNIX streams are an excellent example of this kind of solution. Because streams allow programs to communicate with each other, they enable you to combine existing programs instead of creating new ones.</p>

<p>Even though we’ve had to create software for streams to work, we didn’t have to write <em>too much</em> of it. We’ve written a little bit of code so that we could write less of it in the future.</p>

<p>These kinds of solutions are interesting because they’re usually winners in the market.</p>

<p>When we had problems managing our own data-centres, for example, the winner products weren’t the ones which made it more efficient to manage your own hardware. The winners were those who allowed you not to have a data-centre altogether. That was the birth of VPS’s.</p>

<p>Now, we’re seeing the exact same process happening on the cloud computing space because running program’s in someone else’s hardware creates yet another problem.</p>

<p>Even though companies don’t have to maintain their own data-centres anymore, they still have to manage the machines in which they host their software.</p>

<p>Again, we’re faced with the choice to patch the problem or find a solution which eliminates it altogether.</p>

<p>We can create complex programs to <a href="https://github.com/chef/chef">provision servers</a>, <a href="https://www.nagios.org/">monitor their resources</a>, and <a href="https://kubernetes.io/">orchestrate our system’s components</a>, or we can avoid using these “virtual machines” altogether by using Lambdas, for example.</p>

<p>I bet that cloud-native architectures will win.</p>

<p>In the same way that we chose not to maintain data-centers instead of making it easier to manage them, we’ll decide not to manage any servers instead of making it more efficient to do so.</p>



<hr>





<p>I do <em>not</em> necessarily think that cloud-native architectures are objectively better.</p>

<p>These services have dozens of disadvantages about which I could write entire posts. The most significant of them is probably vendor lock-in.</p>

<p>What I’m saying instead is that I believe the majority of the market will end up adopting these kinds of services.</p>

    </article></div>]]>
            </description>
            <link>https://lucasfcosta.com/2020/09/05/not-having-problems.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24439304</guid>
            <pubDate>Fri, 11 Sep 2020 04:54:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[HarmonyOS]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24439229">thread link</a>) | @pjmlp
<br/>
September 10, 2020 | https://www.harmonyos.com/en/home/ | <a href="https://web.archive.org/web/*/https://www.harmonyos.com/en/home/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="harmony-page"><header id="navbar" :style="{'padding-bottom': paddingBottom}" :data-clientwidth="clientWidth">
	
	<pc-header id="pc_navbar" v-cloak="" v-if="clientWidth>900 &amp;&amp; showHead">
        
        
        
        

    </pc-header>
    
    <mobile-header v-if="clientWidth<=900 &amp;&amp; showHead" v-cloak="">
        
        
        
    </mobile-header>
</header>

  <div>
        <div>
            <div>
                <div>
                    <div>
                        <p><span>Cutting-edge hardware</span> 
                        </p>
                        <p>
                           Efficient and secure cross-device connectivity, in which the phone serves as the smart digital hub, distributing content and services to address user needs. </p>
                        
                    </div>
                    <p><img src="https://www.harmonyos.com/resource/image/home/img-01-.png">
                    </p>
                </div>
            </div>
		</div>
</div>
<div>
        <div>
            <div>
                <div>
                    <p><span>
                            Seamless interactions</span>
                    </p>
                    <p>
                        Effortless interactions designed for broad-ranging usage scenarios and device types. User-centric approach, characterized by smart coordination between devices, with smooth cross-device transfers.</p>
                    
                    <p><img src="https://www.harmonyos.com/resource/image/home/2-xinjiaohu-10.png" alt="">
						</p>
                </div>
            </div>
        </div>
    </div>
<div>
        <div>
            <div>
                <div>
                    <div>
                        <p><span>Groundbreaking services</span> 
                        </p>
                        <p>
                           Applications and services customized to meet the needs of users, invoking a multitude of device capabilities to heighten performance. Versatile solutions crafted for optimal convenience</p>
                        
                    </div>
                    <p><img src="https://www.harmonyos.com/resource/image/home/3-xinfuwu-10.png">
                    </p>
                </div>
            </div>
		</div>
</div>

<p><a href="https://developer.huawei.com/consumer/en/events/hdc2020/?channelname=HeZuo58&amp;ha_source=banner" onclick="util.reportApi.reportClick()">
			<img src="https://www.harmonyos.com/resource/image/home/HDC-pc-en-new.png">
			<img src="https://www.harmonyos.com/resource/image/home/HDC-mobile-en-new.png">
		</a></p>
<!--<div class="swiper-container" id="developer_container">
			<div class="swiper-wrapper">
				</div> 
			<div class="swiper-pagination"></div>
			<div class="swiper-button-next"></div>
			<div class="swiper-button-prev"></div>
		</div>-->


  </div></div>]]>
            </description>
            <link>https://www.harmonyos.com/en/home/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24439229</guid>
            <pubDate>Fri, 11 Sep 2020 04:34:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting macOS style hotkeys working in GNU/Linux]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24439205">thread link</a>) | @todsacerdoti
<br/>
September 10, 2020 | https://technex.us/2020/09/getting-macos-style-hotkeys-working-in-gnu-linux/ | <a href="https://web.archive.org/web/*/https://technex.us/2020/09/getting-macos-style-hotkeys-working-in-gnu-linux/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<p>Over the years I've used every operating system. Sometimes all at once. Recently I've taken to using Linux as my primary desktop operating system. Everything I need runs natively on Linux and because I have full control over my environment I never have down time due to forced updates. This is my desktop after all so I'm really switching from Windows where the Control key modifier paradigm is more or less the same as Linux. Still I didn't want to compromise on anything with this new configuration and there was one thing missing from my Macbook that I really wanted.</p>
<p>Of course what I'm talking about is the Command key or more colloquially known simply as the Apple Key and all the shortcuts and hot keys built into macOS that make it such a joy to use.</p>
<p><img src="https://technex.us/media/70" width="200"></p>
<blockquote>
<p><em>"Linux lets you change whatever you want."</em></p>
<p>Is a common thing that people say to bring up a positive aspect of GNU/Linux. Is this actually true though? Take for example my issue at hand: Changing copy/paste hotkeys for all programs. In truth, some tasks are so big in their scope few users would ever be capable of accomplishing them. At least not without a lot of contextual knowledge.</p>
<p>Getting macOS style hotkeys is actually an extremely difficult task in Linux. Especially when you want to avoid faking it by binding some keys to other keys on a per application basis.</p>
</blockquote>
<p>Then there's the question of why do it at all?</p>
<p><span><span>The truth is I just got tired of </span></span><span><span>accidentally sending SIGINTs when switching to terminal and then accidentally triggering the wrong thing when switching out of terminal. I've just gotten so used to not having to context switch my brain in macOS between programs. It's one of the things that truly makes my Macbook Pro more pleasant to use.</span></span></p>
<p><span><span><img src="https://technex.us/media/73"></span></span></p>
<p>So that's my first reason. Muscle memory.</p>
<p>My second reason is simply that Command/Meta is directly next to the space bar and I just like having a shorter stretching span for my hand.</p>

<h3>Making it work</h3>
<p>For the most part GUI applications written for Linux tend to make a lot of assumptions about what hotkeys can and should be in a very opinionated way. Some types of programs require full customization (like code editors) while others like browsers tend to force certain hotkeys. Desktop managers do provide their own hotkey bindings. For example most KDE based applications will use your settings from KDE's "System Settings" to set hotkeys. Meanwhile in Gnome you can use dbind to set your keybinds.</p>
<p>Of course Cut/Copy/Paste is not enough. It would actually be quite jarring to use CTRL+T for opening a new tab immediately after using Command+V to paste something. Indeed if you go down this path you'll end up having to redefine your hotkeys for well..... everything. It is unfortunate as well that applications these days are extremely hostile to user settings.</p>
<p>Despite the hurdles in front of me I decided to try to make it work.</p>
<p>The first thing I did was swap Left Alt and Left Meta on my keyboard. This was actually pretty easy to do with keyboard mapping configs with the KDE GUI simply known as "System Settings". This was simply to make my normal windows keyboard place the buttons in the positions a real mac keyboard would have. None of this is necessary if you have a real Apple layout keyboard. This setting is only active while in my X session so any alternative TTYs would revert back to my stock layout. If I had a real Apple layout keyboard though this is not necessary at all.</p>
<p><img src="https://technex.us/media/71"></p>
<p>This setting is saved to the text file <code>~/.config/kxkbrc.</code></p>
<pre><code>$ cat kxkbrc 
[Layout]
DisplayNames=
LayoutList=us
LayoutLoopCount=-1
Model=pc101
Options=altwin:swap_lalt_lwin
ResetOldOptions=true
ShowFlag=false
ShowLabel=true
ShowLayoutIndicator=true
ShowSingle=false
SwitchMode=Global
Use=true
</code></pre>
<p>Now with this setting I am able to fake the same key mapping as a real macOS&nbsp;keyboard would have in my desktop session. So far so good. Now I manually changed all my hotkeys in my code editors, terminal applications, and even in the System Settings app I just mentioned to set global hot keys for all KDE applications. This took some time but was very straight forward for the most part.</p>
<p><img src="https://technex.us/media/72"></p>
<p>I went above and beyond even changing my shortcuts for things like Select All.</p>
<p>While this worked for KDE applications I had to also make this change for GTK+ based programs as well. Luckily this would also cover Chrome, Discord, Elements, and a number of other Electron based programs that I use on a regular basis.</p>
<p>I was lucky that VSCode let me change everything but it was very annoying have to redo all the system based hotkeys like Set cursor to start of the line (in macOS this is Meta+Left Arrow) for each and every place I wanted to use it.</p>
<p>Some websites also use Meta+C for example in Github hitting Meta+C will actually take focus and bring you to the Add Comment UI when in a thread so sometimes on Github.com even with Firefox set to use Meta+C to copy something I am not actually able to use my hotkey because the website overrides it.</p>
<p>With GTK I ended up editing <code>`</code><span><code>~/.config/gtk-3.0/gtk.css`</code> </span><span>and setting these hotkeys.</span></p>
<pre><code>@binding-set gtk-super-cut-copy-paste
{
        bind "&lt;super&gt;x" { "cut-clipboard" () };
        bind "&lt;super&gt;c" { "copy-clipboard" () };
        bind "&lt;super&gt;v" { "paste-clipboard" () };
        bind "&lt;super&gt;a" { "select-all" (1) };
        bind "&lt;super&gt;z" { "undo" () };
}

* {
        -gtk-key-bindings: gtk-super-cut-copy-paste
}
</code></pre>
<p>I might add more but for now this got me to where I wanted with most GTK+ applications. Note that if you plan to run any of programs designed to run as root that use GTK+ such as GParted you should also link or copy this config file to the root account home directory as well.</p>
<p>So in the end it is possible. I was able to achieve what I wanted with all but one program. But it was a huge pain. It's really difficult to figure out what settings do what in a Linux environment even when there is documentation. It's typical for documentation to exist for say GTK+ 2.0 and GTK+ 3.0 but there is no over arching best practice guide for what one should do when they want to cover all programs in an environment.</p>


<h3>It Doesn't Have to Be This Way</h3>
<p>The Linux ecosystem can and should do better. The ability to do whatever you want is a double edged sword where even though you can in theory change things, in practice however, sometimes changing things is so onerous that staying sane in the process is a task in itself.</p>
<p>So please if you are a Linux user space developer check the GTK+ 2.0 (<code>~/.gtkrc-2.0</code>), GTK+ 3.0 (<code>~/.config/gtk-3.0/gtk.css</code>) and KDE global shortcut configs (<code>~/.config/kdeglobals</code>) when you probe for the environment during startup so that people can choose their own hotkeys for their desktop environment or simply use the C libraries of each and use the hotkeys present.</p>
<p>Better yet, if you are a developer that already supports various input methods for macOS, Linux, and Windows you can simply provide a toggle for users.</p>
<p>It would be beneficial to Linux Desktop environments to agree to a standard config file for hotkeys allowing users to bind keys as they see fit rather than lurching from one weird keybinding config to the next with no centralization to speak off.</p>
	</div></div>]]>
            </description>
            <link>https://technex.us/2020/09/getting-macos-style-hotkeys-working-in-gnu-linux/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24439205</guid>
            <pubDate>Fri, 11 Sep 2020 04:30:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Giggle; Laughable Security]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24438766">thread link</a>) | @davidbarker
<br/>
September 10, 2020 | https://research.digitalinterruption.com/2020/09/10/giggle-laughable-security/# | <a href="https://web.archive.org/web/*/https://research.digitalinterruption.com/2020/09/10/giggle-laughable-security/#">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>Preface: There is very little in this blog post that is interesting from a technical perspective. The discovered vulnerability is incredibly basic but fairly high risk. Due to the nature of the application, and the fallout from our disclosure attempt, we wanted to write up our findings. The TL;DR is that giggle has been exposing user’s phone numbers, private images and location to the world.</p>

<p>Normally we wouldn’t post a vulnerability like this so soon after discovering it but the owner of the app refuses to listen to us and continuously claims no vulnerability exists. We tried to get in contact with her via a third party (after we had been blocked) to let her read this post before publishing it but, again, she showed no interest.</p>

<p>(edit: We wrote but didn’t publish this article before the vulnerability was fixed. Giggle has told us it has now been fixed so we feel comfortable releasing these details.)</p>

<p>(edit2: Sall is threating us with legal action.)</p>

<p>(edit3: We’ve had some questions about the phrasing in the first public tweet. We standby our words. Not knowing how this would play out, we wanted to make it clear that we didn’t support the app or the founder, but wanted to report the issue. Companies can be unpredictable when reporting vulnerabilities and we wanted to avoid a situation where they would be publicly praising us or even mentioning us on their website etc.)</p>

<p>(edit4: An apology from Giggle has been made and no futher legal action will be taken)</p>

<hr>

<h3 id="what-is-giggle">What is Giggle?</h3>

<p>This week I set up an account on an app called giggle. You see, last month I had been diagnosed with premature menopause I and wanted to find a safe space in a woman centric environment. Somewhere I could talk openly about this experience and maybe get some support, but also find some light hearted way to socialise online.</p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image1.jpeg.resize.jpeg" alt=""></p>

<p>Without much investigation I found giggle, which seemed to check all the boxes. A free app, promoting safe and secure social networking. Giggle promised a refuge from misogyny and sexism where I could find support and community.</p>

<p>There were a few red flags, such as an excessive use of pink and word “females”, but I decided to give it a go.</p>

<p>At this point the red flags became a little more crimson. Firstly, I was asked to submit my phone number so that a verification code could be sent to my mobile. Then I was asked to allow the app to access my camera so that a selfie of me could be submitted to verify I was female. This verification, apparently, is done using AI. From previous work done on this, we know this can often be notorious for mischaracterising and therefore excluding certain racial groups, some trans women and some masculine looking women.</p>

<p>The app assured me that my verification picture would not be stored so not to worry about what I looked like, so my gargoylesq visage was submitted (I’ll get to the later) and I was duly approved to enter the app.</p>

<p>I went to set up my profile to see what information was publicly available about me, even if only in the app, to find there wasn’t one and I had to set up multiple profiles or ‘giggles’ to start a tinder like experience on each specific subject I was interested in (I chose menopause, body image, hiking and wine tasting), that range from socialising and hobbies to more high risk areas such as abuse and sex work.</p>

<p>As I was curious how secure my data was, and as we are currently working on improvements to <a href="https://rex.digitalinterruption.com/">REX</a> (and thought they’d maybe like a <a href="https://www.digitalinterruption.com/100-free-rex-licences">free license</a>), we decided to dig a little deeper.</p>

<h3 id="viewing-account-details">Viewing Account Details</h3>

<p>Using BurpSuite and a fresh install of the app, we intercepted the network traffic and found a few interesting things that we decided not to look at further as we didn’t have permission to do a full analysis. During the registration process, as mentioned, users are required to verify a phone number and selfie. We submitted a selfie that wouldn’t pass and, unsurprisingly, couldn’t gain access to giggle.</p>

<p>Looking at the network requests revealed that although the account was in an unvalidated state, we still had a valid auth token (it turns out this is hardcoded into the application) allowing us to make requests to the API. Again, we didn’t perform a full analysis although we suspect issues could exist here. What we did look at was the UserList endpoint. This contained a filter parameter that contained my phone number, an operator (in this case “equals”) and a field (“mobile”). Presumably, this is how a user’s account details are fetched from the API.</p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image2.png.resize.png" alt=""></p>

<p>Of course, the obvious question is what would happen if we changed this filter parameter to be another phone number, changed the query to filter on another parameter such as user ID or user’s name or even would it remove the filter altogether, allowing us to view all accounts?</p>

<p>First, we decided to change the filter query so it would filter based on the GUID of the original account which we received during our initial analysis. This brought back the original account details which included the user’s phone number, age (which was set to hidden) and a latitude and longitude.</p>

<p>Request:</p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image3.png.resize.png" alt=""></p>

<p>Response:</p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image4.png.resize.png" alt=""></p>

<p>Having the phone number is bad enough, but we checked the returned latitude and longitude using Google Maps. Of course, this brought us to the very house I created the account in.</p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image5.png.resize.png" alt=""></p>

<p>This means an attacker that is completely unverified to the application can view the address and phone number of all users if they have the account ID. That is pretty bad in our opinion.</p>

<p>Next, we wanted to be able to download the same details without knowing the account ID. Looking at the filter parameter, it’s clear to see there would be many ways to do this. We could remove the filter completely although that would reveal other accounts to us which we were trying to avoid seeing or we could change the query to show all accounts not matching a phone number. As a proof of concept, we decided to change the operator field from “equals” to “contains” and truncated the GUID. As this returned the same data, it should be obvious to see how the query could be trivially modified to expose all registered accounts with no prerequisite account knowledge.</p>

<p>Request:</p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image6.png.resize.png" alt="Burp Web Request"></p>

<h3 id="selfies">Selfies!</h3>

<p>What about the supposed private picture that is used to verify accounts? They claim not to store? Behold my gargoylesq visage!</p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image7.png.resize.png" alt=""></p>

<p>If we look at the URL of the verification image (which we recovered by viewing network traffic in BurpSuite), we can see that the only thing that is required is the user GUID. As we can view the user GUID for every account (e.g. our test account) we can easily download the associated verification selfie. Although this is not terrible on it’s own, giggle do promise that this isn’t shared or published, and, given that it is available data stored along side my mobile number and geographical coordinates, with this information an attacker would know my address, my personal mobile number and what I look like.</p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image8.jpeg.resize.jpeg" alt=""></p>

<p>This is where we get to the really scary bit. Giggle has sections encouraging women to find support on abortion, abuse, addiction and relationships among other categories. The amount of available data means that with a phone number or name, an abusive partner would potentially be able to find the location of an abused woman and confirm her identity with the verification picture. There is also a section for sex workers, who, understandably would expect any app enabling them to advertise their work to have adequate privacy and security controls. Even if a user deletes their account, that data appears to still be saved by giggle.</p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image13.jpeg" alt=""></p>

<h3 id="account-deletion">Account Deletion</h3>

<p>The final thing we looked at is whether a deleted account is actually deleted. We deleted the original account using the “Delete Account” button and tried to view the associated account details.</p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image9.jpeg.resize.jpeg" alt=""></p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image10.png.resize.png" alt=""></p>

<p>Of course, they are still present and only set to Disabled meaning they are still stored by the system. Maybe accounts are deleted periodically. We would normally at this point reach out to the vendor and ask for clarification. This leads us to the next part of the story…</p>

<h3 id="disclosure">Disclosure</h3>

<p>We wanted to let giggle know that this vuln existed and ask for some further details, not in the small part because it is so easy to exploit. In the midst of this we had done some digging on the origins of the app and found that the founder had a very public anti-trans agenda. However, much as this sickens us, our job is to protect users so we direct messaged giggle through twitter.</p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image11.png.resize.png" alt=""></p>

<p>Having had no response, we decided to send them a tweet asking them to check their DMs with their founder cc’d in, but with a caveat that we do not share or endorse her anti-trans views.</p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image12.png.resize.png" alt=""></p>

<p>That’s when we were dragged into a full on TERF War.</p>

<p>Our public tweet had no engagement at all until Sall, the giggle founder, decided to share a screenshot of it with her followers. We have since been subject to a tirade of abuse. None of it about the security of the app. Interested parties are free to view our twitter and find the hundreds and hundreds of tweets in response to trying to disclose this vulnerability but we decided not to copy that into this post.</p>

<p>Our founders have reached out to giggle and Sall and have been blocked following every attempt at contact. Our three year incorporated company has been accused of being a creepy bloke who runs private WhatsApp groups full of naked women, a front for the alt-left, making up the vuln to discredit Sall and her company and hypocrites for wanting to protect the data of users despite the apps founder having view that counter our own.</p>

<p>Our company and I (a woman) have been accused of being a man, and therefore a misogynist multiple times. We have been told that as men (60% of Digital Interruption are women), we should not have a say on the safety of women and their personal data.</p>

<p>Sadly, denial is not uncommon when trying to disclose. We are used to being ignored and even getting some pushback, but ultimately we feel it is our responsibility to persist and ensure the …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://research.digitalinterruption.com/2020/09/10/giggle-laughable-security/#">https://research.digitalinterruption.com/2020/09/10/giggle-laughable-security/#</a></em></p>]]>
            </description>
            <link>https://research.digitalinterruption.com/2020/09/10/giggle-laughable-security/#</link>
            <guid isPermaLink="false">hacker-news-small-sites-24438766</guid>
            <pubDate>Fri, 11 Sep 2020 03:04:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don DeLillo: The Word, the Image, and the Gun (2013)]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24438607">thread link</a>) | @benbreen
<br/>
September 10, 2020 | http://perival.com/delillo/ddbbc.html | <a href="https://web.archive.org/web/*/http://perival.com/delillo/ddbbc.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">



<p>On September 27, 1991 BBC 1 broadcast a film on Don DeLillo,
titled "Don DeLillo: The Word, The Image, and The Gun"
which was directed by Kim Evans. As of October 2013 the film has been
put up on YouTube - <a href="https://www.youtube.com/watch?v=0DTePKA1wgc#t=14" target="BLANK">here's the link</a>.</p>

<center><img src="http://perival.com/delillo/ddbbc_title.jpg" naturalsizeflag="3"></center>

<p>The film is introduced as follows:</p>

<blockquote>
  <p>Don DeLillo writes dangerous fiction.</p>
  <p>He's been called America's leading contemporary novelist,
  and his ten novels come directly out of the flow of recent history.
  The Kennedy assassination, toxic fallout, acts of terrorism;
  these are all part of the running picture of news against which
  his books are set.</p>
  <p>This film was developed in close collaboration with DeLillo.
  He wanted to use the documentary form to explore the relationships
  between gunmen and the novelist, words and images, the power
  of news and the obsession with apocalypse. In doing so he asks,
  what effect can a novelist have on a culture in which terrorists
  seem to have hijacked the world's narrative.</p></blockquote>

<p>We then hear a bit of a broadcaster describing the Kennedys
as they move through Dallas, then a short passage from <i>Libra</i>.
DeLillo begins to speak:</p>

<center><img src="http://perival.com/delillo/ddbbc_delillo_at_window.jpg" naturalsizeflag="3"></center>

<blockquote>
  <p>Isolation, solitude, secret plotting. A novel is a secret
  a writer may keep for years before he lets it out of his room.
  Writers in hiding, writers in prison. Sometimes their secrets
  turn out to be dangerous to the state machine. For most writers
  in the West of course this danger is extremely remote. The cells
  we live in are strictly personal constructions.</p>
  <p>Let's change the room slightly and imagine another kind of
  apartness. The outsider who builds a plot around his desperation.
  A self-watcher, a lonely young man, living in a fiction he hasn't
  bothered to put down on paper. But this doesn't mean he is unorganized,
  he organizes everything. This is how he keeps from disappearing.
  His head is filled with dangerous secrets, and he may finally
  devise a way to come out of his room. He invents a false name,
  orders a gun though the mail, then looks around for someone famous
  he can shoot.</p></blockquote>
  
<center><img src="http://perival.com/delillo/ddbbc_at_typewriter.jpg" naturalsizeflag="3"></center>
  
<p>DeLillo at 5:20: "I think it's true that none of my novels could have been written in the world that
existed before the assassination.
In my fiction there seems to be a sense
of danger everywhere, of something unraveling.
  When Kennedy was shot, something changed for ever in America. Something opened up, a sense
  of randomness, deep ambiguity, we lost the narrative thread."
  
</p><center><img src="http://perival.com/delillo/ddbbc_suddenly.jpg" naturalsizeflag="3"></center>

<p>From <i>Libra</i> at 15:10: The first movie was <i>Suddenly</i>. Frank Sinatra is a combat veteran
who comes to a small town and takes over a house that overlooks the railwroad depot.
He is here to assassinate the President. (p. 369 in pbk)

</p><center><img src="http://perival.com/delillo/ddbbc_suddenly_on_oswald.jpg" naturalsizeflag="3"></center>

<p>From <i>Libra</i>: Lee felt a stillness around him. He had an eerie sense he was being
watched for his reaction. He felt connected to the events on the screen. It was like secret instructions
entering the network of signals and broadcast bands, the whole busy air of transmission. 
Marina was asleep. They were running a message through the night into his skin. 

</p><center><img src="http://perival.com/delillo/ddbbc_watching_oswald_11-53.jpg" naturalsizeflag="3"></center>

DeLillo at 18:22: "Maybe I'm wrong about this, but I think the footage comes close to uncovering some secret about
the nature of film itself. Film carries something, some mindstream, some myth that may be common to us all. It's as though
the experience of film has acquired a kind of independent existence in 
our consciousness, it's that deeply embedded. Have to get it on film."

<center><img src="http://perival.com/delillo/ddbbc_men_on_wing.jpg" naturalsizeflag="3"></center>

DeLillo at 26:40: "With widespread political terrorism we got our narrative back, calculated acts, not random."

<center><img src="http://perival.com/delillo/ddbbc_3_planes.jpg" naturalsizeflag="3"></center>

<center><img src="http://perival.com/delillo/ddbbc_bill_gray_maoii.jpg" naturalsizeflag="3"></center>

From <i>Mao II</i> at 28:45: Bill Gray: "Years ago I used to think it was possible for novelists to alter the life of the culture, 
but now bombmakers and gunmen have taken over that territory.  They make raids on human consciousness, what writers 
used to do, before we were all incorporated."

<center><img src="http://perival.com/delillo/ddbbc_nypost_catcher.jpg" naturalsizeflag="3"></center>

DeLillo at 35:12: "Ordering a photograph of a famous recluse must be a little like ordering an execution. Salinger
resembles a man who's fighting for his life."

<center><img src="http://perival.com/delillo/ddbbc_football_crowd.jpg" naturalsizeflag="3"></center>

<p>Tragedy at Hillsborough England (41:25) - 15 April 1989

</p><p>DeLillo at 40:54 : "Today it's news that has begun to influence the way we see the world. It's news that has
become so extraordinarily dominant. I think we've come to depend on news, the darker the better. In a way we need it, 
because it is the tragic narrative of our time." 

</p><center><img src="http://perival.com/delillo/ddbbc_watching_oswald_48-11.jpg" naturalsizeflag="3"></center>

<hr>Here's how <i>The Times</i> listed the program
(Sept 27, 1991):

<blockquote>
  <p>Kim Evan's filmed essay about an American novelist who is
  obsessed by violent images and what they can do to the soul of
  a 20th century culture like his, is dazzlingly, nay blindingly,
  assembled. The camera assumes an adversarial role. It is as much
  a weapon as the guns that feature so strongly in DeLillo's writing.
  Therefore, there are two ways of interpreting it when we talk
  of Evan's scenes being shot. More than one viewing of this film
  will be necessary for those viewers who simply can't keep up
  with what DeLillo is thinking, writing and seeing. It takes time
  to digest statments like "Stalking a victim is a way of
  organizing one's loneliness, making a network out of it"
  or "I knew I must extend myself until the molecules parted
  and I was spliced into the image." In his book <i>Mao II</i>,
  a character says "Keep it simple." Was DeLillo paying
  attention at the time?</p></blockquote>

<hr>
Back to <a href="http://perival.com/delillo/delillo.html">DeLillo's America</a>.
<hr>

<address>Last updated: 23-NOV-2013<br>
</address>



</div>]]>
            </description>
            <link>http://perival.com/delillo/ddbbc.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24438607</guid>
            <pubDate>Fri, 11 Sep 2020 02:30:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Great Classical Books by Legendary Scientists and Mathematicians]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24438605">thread link</a>) | @alikayaspor
<br/>
September 10, 2020 | https://abakcus.com/15-great-classical-books-by-legendary-scientists-and-mathematicians/ | <a href="https://web.archive.org/web/*/https://abakcus.com/15-great-classical-books-by-legendary-scientists-and-mathematicians/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<div>
<div id="primary">
<main id="main">
<div data-elementor-type="single" data-elementor-id="3413" data-elementor-settings="[]">
<div>
<section data-id="63154cf" data-element_type="section">
<div>
<div>
<div data-id="811458f" data-element_type="column">
<div>
<div>
<div data-id="5c50288" data-element_type="widget" data-widget_type="ee-breadcrumbs.default">
<div>
<ul itemscope="" itemtype="http://schema.org/BreadcrumbList"><li itemprop="itemListElement" itemscope="" itemtype="http://schema.org/ListItem">
<a href="https://abakcus.com/" itemprop="item">
<span itemprop="name">
Home </span>
</a>
<meta content="0" itemprop="position">
</li><li><span></span></li><li itemprop="itemListElement" itemscope="" itemtype="http://schema.org/ListItem">
<a href="https://abakcus.com/" itemprop="item">
<span itemprop="name">
Posts </span>
</a>
<meta content="1" itemprop="position">
</li><li><span></span></li><li itemprop="itemListElement" itemscope="" itemtype="http://schema.org/ListItem">

<span itemprop="name">
15+ Great Classical Books By Legendary Scientists and Mathematicians </span>

<meta content="2" itemprop="position">
</li></ul> </div>
</div>

<div data-id="2c83e7d" data-element_type="widget" data-widget_type="theme-post-content.default">
<div>
<p>From Primo Levi and Einstein to Feynman and Euclid, we curated twenty-five excellent books written by world-famous scientists. These are legendary texts, popular science explainers, personal memoirs, and controversial new theories, and they’re all enduring monuments to the power of science.</p>


</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="6fd4db4" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
<div>
<div>
<div data-id="dfe5e35" data-element_type="column">
<div>
<div>
<div data-id="570e0b3" data-element_type="widget" data-widget_type="heading.default">
<p>
<h2>Similar Curated Directories</h2> </p>
</div>
<div data-id="c24adbb" data-element_type="widget" data-settings="{&quot;classic_grid_columns_spacing&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;size&quot;:50,&quot;sizes&quot;:[]},&quot;classic_grid_columns_spacing_tablet&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;size&quot;:50,&quot;sizes&quot;:[]},&quot;classic_grid_columns_spacing_mobile&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;size&quot;:50,&quot;sizes&quot;:[]},&quot;columns&quot;:&quot;3&quot;,&quot;columns_tablet&quot;:&quot;2&quot;,&quot;columns_mobile&quot;:&quot;1&quot;,&quot;classic_layout&quot;:&quot;default&quot;}" data-widget_type="posts-extra.classic">
<div>
<div><div><article><a href="https://abakcus.com/134-awesome-desmos-classroom-activities-to-engage-students-during-class/"><div><picture>
<source type="image/webp" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/134-Awesome-Desmos-Classroom-Activities-to-Engage-Students-During-Class-768x431.png.webp" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20768%20431'%3E%3C/svg%3E">
<img width="768" height="431" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20768%20431'%3E%3C/svg%3E" alt="" data-lazy-src="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/134-Awesome-Desmos-Classroom-Activities-to-Engage-Students-During-Class-768x431.png">
</picture>
</div></a></article></div><div><article><a href="https://abakcus.com/the-best-documentaries-for-making-kids-love-mathematics/"><div><picture>
<source type="image/webp" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/07/The-Best-Documentaries-for-Making-Kids-Love-Mathematics-1-768x723.png.webp" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20768%20723'%3E%3C/svg%3E">
<img width="768" height="723" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20768%20723'%3E%3C/svg%3E" alt="" data-lazy-src="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/07/The-Best-Documentaries-for-Making-Kids-Love-Mathematics-1-768x723.png">
</picture>
</div></a><div><a href="https://abakcus.com/the-best-documentaries-for-making-kids-love-mathematics/" target="_blank">
<h2>The Best Documentaries for Making Kids Love Mathematics</h2>
</a><p>These mathematics documentaries are very “interesting” because they present either actual mathematics, mathematicians, or mathematics history. We want to add this kind of material to attract undergraduates toward mathematics. For…</p></div></article></div><div><article><a href="https://abakcus.com/25-interesting-books-for-math-people-and-designers/"><div><picture>
<source type="image/webp" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/06/S4_Growing-Cryptocurrency-768x676.jpg.webp" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20768%20676'%3E%3C/svg%3E">
<img width="768" height="676" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20768%20676'%3E%3C/svg%3E" alt="" data-lazy-src="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/06/S4_Growing-Cryptocurrency-768x676.jpg">
</picture>
</div></a></article></div><div><article><a href="https://abakcus.com/24-science-fiction-books-that-forecast-the-future/"><div><picture>
<source type="image/webp" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/24-A-History-of-Books-That-Forecast-the-Future-768x676.jpg.webp" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20768%20676'%3E%3C/svg%3E">
<img width="768" height="676" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20768%20676'%3E%3C/svg%3E" alt="" data-lazy-src="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/09/24-A-History-of-Books-That-Forecast-the-Future-768x676.jpg">
</picture>
</div></a><div><a href="https://abakcus.com/24-science-fiction-books-that-forecast-the-future/" target="_blank">
<h2>24 Science Fiction Books That Forecast the Future</h2>
</a><p>Many past writers have predicted our present society’s facts with a level of detail that seems impossibly accurate. In reality, their imaginations were painting portraits that would eventually be mirrored…</p></div></article></div><div><article><a href="https://abakcus.com/the-best-springer-undergraduate-texts/"><div><picture>
<source type="image/webp" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/06/S4_Education-768x675.jpg.webp" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20768%20675'%3E%3C/svg%3E">
<img width="768" height="675" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20768%20675'%3E%3C/svg%3E" alt="" data-lazy-src="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/06/S4_Education-768x675.jpg">
</picture>
</div></a><div><a href="https://abakcus.com/the-best-springer-undergraduate-texts/" target="_blank">
<h2>The Best of Springer Undergraduate Series</h2>
</a><p>The&nbsp;Springer Undergraduate Series is a&nbsp;series&nbsp;designed for&nbsp;undergraduates&nbsp;in&nbsp;mathematics&nbsp;and the sciences worldwide. From core foundational material to final year topics, SUMS books take a fresh and modern approach.</p></div></article></div><div><article><a href="https://abakcus.com/all-movies-about-math-science/"><div><picture>
<source type="image/webp" data-lazy-srcset="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/07/All-Movies-About-Math-Science-768x512.png.webp" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20768%20512'%3E%3C/svg%3E">
<img width="768" height="512" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20768%20512'%3E%3C/svg%3E" alt="All Movies About Math &amp; Science" data-lazy-src="https://i3k5j8j4.rocketcdn.me/wp-content/uploads/2020/07/All-Movies-About-Math-Science-768x512.png">
</picture>
</div></a></article></div></div> </div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
</div>
</div>
</main>
</div>
</div> 
</div></div>]]>
            </description>
            <link>https://abakcus.com/15-great-classical-books-by-legendary-scientists-and-mathematicians/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24438605</guid>
            <pubDate>Fri, 11 Sep 2020 02:30:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Giggle; Laughable Security]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24437865">thread link</a>) | @DyslexicAtheist
<br/>
September 10, 2020 | https://research.digitalinterruption.com/2020/09/10/giggle-laughable-security/ | <a href="https://web.archive.org/web/*/https://research.digitalinterruption.com/2020/09/10/giggle-laughable-security/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>Preface: There is very little in this blog post that is interesting from a technical perspective. The discovered vulnerability is incredibly basic but fairly high risk. Due to the nature of the application, and the fallout from our disclosure attempt, we wanted to write up our findings. The TL;DR is that giggle has been exposing user’s phone numbers, private images and location to the world.</p>

<p>Normally we wouldn’t post a vulnerability like this so soon after discovering it but the owner of the app refuses to listen to us and continuously claims no vulnerability exists. We tried to get in contact with her via a third party (after we had been blocked) to let her read this post before publishing it but, again, she showed no interest.</p>

<p>(edit: We wrote but didn’t publish this article before the vulnerability was fixed. Giggle has told us it has now been fixed so we feel comfortable releasing these details.)</p>

<p>(edit2: Sall is threating us with legal action.)</p>

<p>(edit3: We’ve had some questions about the phrasing in the first public tweet. We standby our words. Not knowing how this would play out, we wanted to make it clear that we didn’t support the app or the founder, but wanted to report the issue. Companies can be unpredictable when reporting vulnerabilities and we wanted to avoid a situation where they would be publicly praising us or even mentioning us on their website etc.)</p>

<p>(edit4: An apology from Giggle has been made and no futher legal action will be taken)</p>

<hr>

<h3 id="what-is-giggle">What is Giggle?</h3>

<p>This week I set up an account on an app called giggle. You see, last month I had been diagnosed with premature menopause I and wanted to find a safe space in a woman centric environment. Somewhere I could talk openly about this experience and maybe get some support, but also find some light hearted way to socialise online.</p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image1.jpeg.resize.jpeg" alt=""></p>

<p>Without much investigation I found giggle, which seemed to check all the boxes. A free app, promoting safe and secure social networking. Giggle promised a refuge from misogyny and sexism where I could find support and community.</p>

<p>There were a few red flags, such as an excessive use of pink and word “females”, but I decided to give it a go.</p>

<p>At this point the red flags became a little more crimson. Firstly, I was asked to submit my phone number so that a verification code could be sent to my mobile. Then I was asked to allow the app to access my camera so that a selfie of me could be submitted to verify I was female. This verification, apparently, is done using AI. From previous work done on this, we know this can often be notorious for mischaracterising and therefore excluding certain racial groups, some trans women and some masculine looking women.</p>

<p>The app assured me that my verification picture would not be stored so not to worry about what I looked like, so my gargoylesq visage was submitted (I’ll get to the later) and I was duly approved to enter the app.</p>

<p>I went to set up my profile to see what information was publicly available about me, even if only in the app, to find there wasn’t one and I had to set up multiple profiles or ‘giggles’ to start a tinder like experience on each specific subject I was interested in (I chose menopause, body image, hiking and wine tasting), that range from socialising and hobbies to more high risk areas such as abuse and sex work.</p>

<p>As I was curious how secure my data was, and as we are currently working on improvements to <a href="https://rex.digitalinterruption.com/">REX</a> (and thought they’d maybe like a <a href="https://www.digitalinterruption.com/100-free-rex-licences">free license</a>), we decided to dig a little deeper.</p>

<h3 id="viewing-account-details">Viewing Account Details</h3>

<p>Using BurpSuite and a fresh install of the app, we intercepted the network traffic and found a few interesting things that we decided not to look at further as we didn’t have permission to do a full analysis. During the registration process, as mentioned, users are required to verify a phone number and selfie. We submitted a selfie that wouldn’t pass and, unsurprisingly, couldn’t gain access to giggle.</p>

<p>Looking at the network requests revealed that although the account was in an unvalidated state, we still had a valid auth token (it turns out this is hardcoded into the application) allowing us to make requests to the API. Again, we didn’t perform a full analysis although we suspect issues could exist here. What we did look at was the UserList endpoint. This contained a filter parameter that contained my phone number, an operator (in this case “equals”) and a field (“mobile”). Presumably, this is how a user’s account details are fetched from the API.</p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image2.png.resize.png" alt=""></p>

<p>Of course, the obvious question is what would happen if we changed this filter parameter to be another phone number, changed the query to filter on another parameter such as user ID or user’s name or even would it remove the filter altogether, allowing us to view all accounts?</p>

<p>First, we decided to change the filter query so it would filter based on the GUID of the original account which we received during our initial analysis. This brought back the original account details which included the user’s phone number, age (which was set to hidden) and a latitude and longitude.</p>

<p>Request:</p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image3.png.resize.png" alt=""></p>

<p>Response:</p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image4.png.resize.png" alt=""></p>

<p>Having the phone number is bad enough, but we checked the returned latitude and longitude using Google Maps. Of course, this brought us to the very house I created the account in.</p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image5.png.resize.png" alt=""></p>

<p>This means an attacker that is completely unverified to the application can view the address and phone number of all users if they have the account ID. That is pretty bad in our opinion.</p>

<p>Next, we wanted to be able to download the same details without knowing the account ID. Looking at the filter parameter, it’s clear to see there would be many ways to do this. We could remove the filter completely although that would reveal other accounts to us which we were trying to avoid seeing or we could change the query to show all accounts not matching a phone number. As a proof of concept, we decided to change the operator field from “equals” to “contains” and truncated the GUID. As this returned the same data, it should be obvious to see how the query could be trivially modified to expose all registered accounts with no prerequisite account knowledge.</p>

<p>Request:</p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image6.png.resize.png" alt="Burp Web Request"></p>

<h3 id="selfies">Selfies!</h3>

<p>What about the supposed private picture that is used to verify accounts? They claim not to store? Behold my gargoylesq visage!</p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image7.png.resize.png" alt=""></p>

<p>If we look at the URL of the verification image (which we recovered by viewing network traffic in BurpSuite), we can see that the only thing that is required is the user GUID. As we can view the user GUID for every account (e.g. our test account) we can easily download the associated verification selfie. Although this is not terrible on it’s own, giggle do promise that this isn’t shared or published, and, given that it is available data stored along side my mobile number and geographical coordinates, with this information an attacker would know my address, my personal mobile number and what I look like.</p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image8.jpeg.resize.jpeg" alt=""></p>

<p>This is where we get to the really scary bit. Giggle has sections encouraging women to find support on abortion, abuse, addiction and relationships among other categories. The amount of available data means that with a phone number or name, an abusive partner would potentially be able to find the location of an abused woman and confirm her identity with the verification picture. There is also a section for sex workers, who, understandably would expect any app enabling them to advertise their work to have adequate privacy and security controls. Even if a user deletes their account, that data appears to still be saved by giggle.</p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image13.jpeg" alt=""></p>

<h3 id="account-deletion">Account Deletion</h3>

<p>The final thing we looked at is whether a deleted account is actually deleted. We deleted the original account using the “Delete Account” button and tried to view the associated account details.</p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image9.jpeg.resize.jpeg" alt=""></p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image10.png.resize.png" alt=""></p>

<p>Of course, they are still present and only set to Disabled meaning they are still stored by the system. Maybe accounts are deleted periodically. We would normally at this point reach out to the vendor and ask for clarification. This leads us to the next part of the story…</p>

<h3 id="disclosure">Disclosure</h3>

<p>We wanted to let giggle know that this vuln existed and ask for some further details, not in the small part because it is so easy to exploit. In the midst of this we had done some digging on the origins of the app and found that the founder had a very public anti-trans agenda. However, much as this sickens us, our job is to protect users so we direct messaged giggle through twitter.</p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image11.png.resize.png" alt=""></p>

<p>Having had no response, we decided to send them a tweet asking them to check their DMs with their founder cc’d in, but with a caveat that we do not share or endorse her anti-trans views.</p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image12.png.resize.png" alt=""></p>

<p>That’s when we were dragged into a full on TERF War.</p>

<p>Our public tweet had no engagement at all until Sall, the giggle founder, decided to share a screenshot of it with her followers. We have since been subject to a tirade of abuse. None of it about the security of the app. Interested parties are free to view our twitter and find the hundreds and hundreds of tweets in response to trying to disclose this vulnerability but we decided not to copy that into this post.</p>

<p>Our founders have reached out to giggle and Sall and have been blocked following every attempt at contact. Our three year incorporated company has been accused of being a creepy bloke who runs private WhatsApp groups full of naked women, a front for the alt-left, making up the vuln to discredit Sall and her company and hypocrites for wanting to protect the data of users despite the apps founder having view that counter our own.</p>

<p>Our company and I (a woman) have been accused of being a man, and therefore a misogynist multiple times. We have been told that as men (60% of Digital Interruption are women), we should not have a say on the safety of women and their personal data.</p>

<p>Sadly, denial is not uncommon when trying to disclose. We are used to being ignored and even getting some pushback, but ultimately we feel it is our responsibility to persist and ensure the …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://research.digitalinterruption.com/2020/09/10/giggle-laughable-security/">https://research.digitalinterruption.com/2020/09/10/giggle-laughable-security/</a></em></p>]]>
            </description>
            <link>https://research.digitalinterruption.com/2020/09/10/giggle-laughable-security/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24437865</guid>
            <pubDate>Thu, 10 Sep 2020 23:57:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I operated as a staff engineer at Heroku]]>
            </title>
            <description>
<![CDATA[
Score 365 | Comments 83 (<a href="https://news.ycombinator.com/item?id=24437715">thread link</a>) | @craigkerstiens
<br/>
September 10, 2020 | http://amyunger.com/blog/2020/09/10/staff-engineer-at-heroku.html | <a href="https://web.archive.org/web/*/http://amyunger.com/blog/2020/09/10/staff-engineer-at-heroku.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" aria-label="Content">
  <article>
    

    <div>
      

      

      <div>
        <div>
          <p>I was incredibly lucky to spend 5 amazing years at Heroku. By the end of my time, I was operating in a Staff capacity, although I’m honestly completely unclear which titles at Salesforce actually map to Staff.</p>

<p>Because titles are unclear and because my role was a little amorphous, I chose not to submit a story to Will Lethain’s <a href="https://staffeng.com/stories/">great collection</a> at StaffEng.com. That being said, I added a few questions to his questionnaire that I hadn’t seen answered elsewhere, so I figured I’d post this.</p>

<p><strong><em>Tell us a little about your current role: where do you work, your title and generally the sort of work do you and your team do.</em></strong></p>

<p>Until recently, I was a Principal engineer at Salesforce, working for their Heroku product. I joined almost five years ago, working on the Heroku Add-ons product, and then transferred to the Heroku API team. For the last year and a half, I worked on the API team for the Salesforce Functions product, which runs on top of Heroku infrastructure.</p>

<p>The API team is at the center of defining how the Salesforce Functions product will work, so there are a lot of different tasks our team does. First and foremost, we write the code to store the state that the customer <em>intends</em> their infrastructure to converge to and then push that down into the infrastructure layer. If you’re interacting with Salesforce Functions, you’re going through our code. We also do a lot of reconciling what the infrastructure can do with the hopes and dreams of product. I did a balance of work, but more towards the “hopes and dreams” side of things.</p>

<p><strong><em>What does a “normal” Staff-plus engineer do at your company? Does your role look that way or does it differ?</em></strong></p>

<p>There is really no “normal” Staff engineer at Salesforce. I usually talk about four different approaches I see in the company, some of which line up with <a href="https://staffeng.com/guides/staff-archetypes">Will’s archetypes</a> and some which don’t. A lot of folks are a mix of these and rotate through them over a long career at the company.</p>

<p><em>Team(s) Lead/Right Hand</em></p>

<p>You are the primary technical point of contact for 10-20 engineers, across one or more teams. You are typically reporting to a manager of managers. Responsibilities vary based on individuals’ strengths and the strengths of their manager, but there are some common things you <em>must</em> do. If you’re not making your delivery timelines and this is a surprise to your organization, you and your manager have a problem. If product has a dream and no one knows what it would take to build it (time, resources, architecture), you have a problem. If you can’t answer “Why are we building this in this way?” then you have a problem.</p>

<p><em>Product Architect</em></p>

<p>If it’s on TechCrunch or promoted at our corporate conferences, there is an Architect for it. If the project (40+ engineers) fails to be a success, you share responsibility along with the (typically) VP+ engineering manager and Product owner. If you have any type of personal presence, you will be put on a stage and in front of customers. This is the level where you’re helping advocate with your VP for major initiatives to go after certain markets. If we made the wrong bet, some blame is with product, but it’s also on you, and the manager probably won’t look great.</p>

<p><em>Deep Diver</em></p>

<p>You have a lot of deep technical expertise on a particular component or system. You tend to stay on a single team or a single area of the organization. If you work in our legacy codebases, which are the core of our profitability, you are basically unfireable because you know so much. You may write code for some of the gnarliest problems of the legacy system you’re being kept around for, but you’ll often find yourself spending more time interfacing with other teams to explain why your system can’t do what they want and how we can work around it to deliver on a reasonable timeline. You will work closely with your Team Lead on a daily/weekly basis and occasionally have your entire day/week blown up because the Product Architect has identified a need for your expertise and all of a sudden you’re being trotted out to present to some team you’ve never heard of.</p>

<p><em>The Management</em></p>

<p>There are two variants. First, you’re pendulum’ing over to a line manager role, but since your IC title is the same grade as Director or VP, making you a manager would result in a massive pay cut. You’re likely managing a smaller team, given Salesforce targets 12-15 reports. In the second variant, you’re roughly an extension of a VP+ leader. Maybe you’re working on how we keep our many thousands of engineers communicating well. Maybe you’re advising an SVP on where to make technical investments - does our company really have enough of a competitive advantage to go after that market? Sure, the SVP/C-suite person is being told by Product that if you only give us $100 million we can do a ton. Is that true? Hey, we just bought a multi-billion dollar business (or we’re about to): Can you figure out what we should do with them? Many, including Will, call this fire-fighting, but that’s too narrow a view of how these roles really deliver value to large companies: it’s fast-paced opportunity scouting and truth-telling. That being said, you’ll most likely be looking for opportunities and the real truth within the more challenged parts of the business, so I see the fire-fighting analogy.</p>

<p><strong><em>How do you define success in your role?</em></strong></p>

<p>First and foremost, I am successful if the folks I work with understand how business decisions tie into their day-to-day work.</p>

<p>At a minimum, this involves a fair amount of understanding why we’re being asked to build something, running ahead of the team to make sure product plans are in place for us, working across teams to come up with an achievable plan and then championing IC concerns as they crop up.</p>

<p>But it also means pushing forward discussions about what kinds of risk are worth taking on in our code at the moment. Is now the right time to commit to this abstraction? Is now the time to address a performance issue with a re-architecture? We’re moving quickly, but also seeing a lot of incidents - what kinds of testing should we invest in?</p>

<p>Success looks like seeing conversations about timeline and priorities between ICs start from a shared background. Success looks like having no major blow ups about “How could you suggest we ship this hack?” Instead, folks can talk about technical choices through a business lens: “I know we’re currently low on staff compared to our product ambitions, but is this the right place to simplify?” Success looks like a team with a shared goal for the quality and resiliency of code that we’re writing. Success also looks like other ICs feeling confident in advocating for changes, since they see our team making technical decisions with a consistent goal in mind. When I talk with ICs in 1:1s, there should be no “I’m not sure why I’m doing X” when it comes to code, infrastructure and incidents.</p>

<p>Next, I am successful when my management chain clearly understanding the particular risks we’re taking on. All of the architectural decisions a team makes will be wrong, eventually. Whether technology changes, our customer base changes or the product itself changes, it’s only a matter of time before we regret those big choices. The key is understanding what bets we’re making and how long we think before we’ll need to revisit them.</p>

<p>Architecture in a large enterprise is a lot about risk management. A large org has a lot of existing momentum in the market and naturally becomes more cautious. I only have a few places where I can advocate for higher-risk bets and those bets are going to be far lower risk than at a start up. While I need to embrace the fact that our decisions will be wrong, I need to be able to speak to the ways in which we will likely be wrong, when we’ll know and what our mitigation strategy will be.</p>

<p>Third, I am successful if I’m saying the right “No”s to my manager. If the ICs that report to my manager end up feeling like “I told you so” or “We knew this was a bad idea” and that wasn’t surfaced for a discussion, that’s on me. As a Staff engineer, I have the responsibility to course correct my manager when we’re over-committed or committed to the wrong thing.</p>

<p>Finally, I’m successful if my organization has a healthy engineering culture. No one person owns culture, but that doesn’t mean we all don’t equally share the burden of building a world-class engineering organization.</p>

<p><strong><em>How do you spend your time day-to-day?</em></strong></p>

<p>While I do write code from time-to-time, it’s only after I’ve delivered on my obligations on these four functions.</p>

<p><em>Information gathering</em> - In order to help my team understand the context within which we’re building a thing, I need a lot of information. I almost unfailingly start my day with a list of longer emails and docs of all varieties to digest. I also spend a fair amount of time in cross-org chats with assorted managers &amp; ICs, whose purpose is a combination of information gathering and the coaching I mention below.</p>

<p><em>Planning</em> - Knowing a bunch of stuff isn’t helpful unless we actually do something with it, so I also spend a lot of time in planning activities. This is a lot of writing docs and running meetings. Planning activities are usually very collaborative – I rarely know the most on any one thing, but I can knit them all together into a plan.</p>

<p><em>Context sharing</em> - Knowing what we want to do isn’t helpful unless a lot of people understand the plan, so the final category of work that’s execution oriented is sharing all of that context. I attend meetings with other teams to share what we are doing, I review PRs to make sure we’re making small decisions in-line with larger goals, and hold standing team 1:1s to make sure each person feels confident in the direction we’re headed.</p>

<p><em>Coaching &amp; Culture</em> - The final category of work isn’t oriented towards delivering a product, but it’s still critically important to our organization’s long-term health to invest in our engineers. My personal …</p></div></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://amyunger.com/blog/2020/09/10/staff-engineer-at-heroku.html">http://amyunger.com/blog/2020/09/10/staff-engineer-at-heroku.html</a></em></p>]]>
            </description>
            <link>http://amyunger.com/blog/2020/09/10/staff-engineer-at-heroku.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24437715</guid>
            <pubDate>Thu, 10 Sep 2020 23:32:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Content from the Dark Web to Provide Content to the Clear Web]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24437280">thread link</a>) | @puggo
<br/>
September 10, 2020 | https://hawaiigentech.com/post/commentary/it-came-from-the-dark-web/ | <a href="https://web.archive.org/web/*/https://hawaiigentech.com/post/commentary/it-came-from-the-dark-web/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p><img src="https://hawaiigentech.com/post/commentary/it-came-from-the-dark-web/a-reverse-benefit.jpg" alt="Sometimes, the greater evil can serve the greater good."></p>
<hr>
<h2 id="everyone-wants-to-think-out-of-the-box-so-thats-not-thinking-out-of-the-box">Everyone wants to "think out of the box". So that's not thinking out of the box.</h2>
<p>Sometimes I think out of the box using the ideas from the people stuck in the box. Like, how can I take this idea that is stuck in the box, and liberate it from the box…you know what…nevermind. I’ll just explain.</p>
<hr>
<h3 id="a-fresh-source-of-content">A Fresh Source of Content</h3>
<p>So you may have heard that the dark web contains whistle blowers, free thinkers, radical innovators, and such like these, though you might run into a bad guy every now and then.</p>
<p>So before drawing out a large commentary on this subject, let me illustrate it with a common analogy, but slightly modified so as to exit the box.</p>
<p><img src="https://hawaiigentech.com/post/commentary/it-came-from-the-dark-web/paradigm-shift.png" alt="The Paradigm Shift of Thinking in the Box"></p>
<p>So in this case (and by this analogy only) the big dark box that people are thinking in is in the dark web. So to think “out of the box” as you’ve been told to do, you might have to <em>go into the box</em>. Consider this picture above: The <em><strong>text you do see</strong></em> is what is clearly written on the image. But the ALT TEXT in the image tag which you will probably not see says <strong>“The Paradigm Shift of Thinking in the Box”</strong>.</p>
<p>Unless you have a setting on your browser that shows alt text immediately, you wouldn’t discover this unless you dug for it, specifically. But then, why would you do that? You didn’t know it would be useful. It was hidden anyways. But there is an entire network that behaves like that Alt Text I just mentioned. (The hidden web, obviously).</p>
<h3 id="more-on-the-box">More on the Box…</h3>
<p>Ok, so your teacher or parents or marketing guru (who could benefit by you) said its a good thing to think out of the box. And maybe, like me, you thought you’d listen. But did the teacher ever tell you to:</p>
<ul>
<li>Change the box?</li>
<li>Poke holes in the box?</li>
<li>Shake the box?</li>
<li>Expose the box to rain and sun?</li>
<li>Put a king snake in the box?</li>
<li>Hide stuff in the box?</li>
</ul>
<p>Your not limited to thinking only outside the box. The box is really your plaything. Come and go at will. Why limit yourself to the place outside the box? Or in the box? Or why not switch to a bag, safe, or crate?</p>
<h3 id="thus-we-may-use-the-box-to-our-advantage">Thus, we may use the box to our advantage.</h3>
<p><img src="https://hawaiigentech.com/post/commentary/it-came-from-the-dark-web/ben-linus.jpg" alt="What if I told you that somewhere on this island there’s a very large box and whatever you imagined, whatever you wanted to be in it, when you opened that box there it would be."></p>
<blockquote>
<p>“What if I told you that somewhere on this island there’s a very large box and whatever you imagined, whatever you wanted to be in it, when you opened that box there it would be.”” - <a href="https://en.wikipedia.org/wiki/Ben_Linus">Ben Linus</a></p>
</blockquote>
<p>Since in this case we are considering the dark web as being the box (the box that NOBODY SHOULD ENTER) we can now think out of the box by going into the box.</p>
<h2 id="and-now-the-keynote-address">And now, the Keynote Address</h2>
<p>Search engines can easily judge the originality of content based on other content that appeared before it on the <em>clearnet</em>. But at this time they <em>generally</em> don’t know what exists in the dark net (its hard to crawl, not reliable, among other issues).</p>
<p>In the ice-berg picture above (which is a fitting and accurate example) you can see that the dark net is far bigger than the clear net.</p>
<p>So you could, literally, <em><strong>just search for cool ideas and content from the dark web and place it on your clear web website</strong></em>. And the result would be, according to search engines: <strong>You</strong> <em>have new and authentic content</em>.</p>
<p>Adding to that, due to the source (the dark net), your “authentic” content will probably be unique  (to the clear net). Dark net authors often think differently. That’s why they are there.</p>
<p>You probably think I’m telling you to steal content from the dark web.</p>
<p>Stealing content is not what I’m suggesting.</p>
<hr>
<p>I’m suggesting this, rather:</p>
<h3 id="using-content-from-the-dark-web-to-provide-content-to-the-clear-web">Using content from the dark web to provide content to the clear web</h3>
<p><img src="https://hawaiigentech.com/post/commentary/it-came-from-the-dark-web/dali.jpg" alt="Dali, “Original Inspiration”"></p>
<p>Lets use Salvadore Dali as an Example <a href="https://www.google.com/search?q=Salvador+Dali+painting&amp;tbm=isch&amp;ved=2ahUKEwjo6t3VwN_rAhUJq54KHfrLDd0Q2-cCegQIABAA&amp;oq=Salvador+Dali+painting&amp;gs_lcp=CgNpbWcQAzICCAAyAggAMgIIADICCAAyAggAMgIIADICCAAyAggAMgIIADICCAA6BAgjECdQzDtY5T9g7UBoAHAAeACAAYcBiAHOB5IBAzAuOJgBAKABAaoBC2d3cy13aXotaW1nwAEB&amp;sclient=img&amp;ei=ApdaX-jhFInW-gT6l7foDQ&amp;bih=862&amp;biw=1841&amp;client=ubuntu&amp;hl=en&amp;hl=en">(see his paintings here)</a>. (<a href="https://web.archive.org/web/20200910232414/https://www.google.com/search?q=Salvador+Dali+painting&amp;tbm=isch&amp;ved=2ahUKEwjo6t3VwN_rAhUJq54KHfrLDd0Q2-cCegQIABAA&amp;oq=Salvador+Dali+painting&amp;gs_lcp=CgNpbWcQAzICCAAyAggAMgIIADICCAAyAggAMgIIADICCAAyAggAMgIIADICCAA6BAgjECdQzDtY5T9g7UBoAHAAeACAAYcBiAHOB5IBAzAuOJgBAKABAaoBC2d3cy13aXotaW1nwAEB&amp;sclient=img&amp;ei=ApdaX-jhFInW-gT6l7foDQ&amp;bih=862&amp;biw=1841&amp;client=ubuntu&amp;hl=en&amp;hl=en">archive</a>)</p>
<p>Dali used to take inspiration for his paintings from a foreign and strange environment: <em><strong>his dreams</strong></em>.</p>
<p>While its questionable where his success came from (indeed, we cannot assume inspiration or quality of art) he certainly knew a thing or two about inspiration: Radical inspiration comes from a place we don’t visit often*.</p>
<p>*(<em>That’s why I’m an avid bible reader that no longer sets foot in churches. Churches are, in my opinion, the dark side of the dark web of religion, but the bible is the “radical” book that goes against the establishment. And, oddly, most bibles come in black, though containing much light.</em>).</p>
<p><em><strong>Hence</strong></em>, using the <em><strong>hidden net can give you ideas that were previously unknown to you</strong></em>, because they are not a part of your common world or common experiences via mainstream television or mainstream internet (or mainstream books).</p>
<p>And you can draw from that.</p>
<h2 id="epilog-with-new-frontiers-comes-new-risks">Epilog: With new frontiers comes new risks…</h2>
<p><img src="https://hawaiigentech.com/post/commentary/it-came-from-the-dark-web/pirates.jpg" alt="One nation’s pirate is another nation’s entrepreneur…"></p>
<p>Like I acknowledged at the beginning of this article, the dark web contains bad guys, though occasionally you might run into whistle blowers, free thinkers, radical innovators, and the like.</p>
<p>The dark web does not exist to be searchable, unless the authors intend it. Likewise, your chances on stumbling upon genuinely evil content is also based on the entry points you use. Finding innovation will start with innovation.</p>
<p>Hence, I would suggest NOT just jumping into the dark web based on the popular entry points, but find a strategy to obtain links and onion connections from useful darkweb sites that explore innovation or new ideas that are challenged by dominant opinion. Avert your eyes from things that are genuinely dark.</p>
<p>Its true with websites as its true with people: Birds of a feather flock together. So if you start with sites that are intellectual and progressive in nature, you are not likely to come into evil territories quickly. On the other hand, if you start with a site like The Hidden Wiki…you’d better know what your doing.</p>
<hr>
<p>Endnote:</p>
<p>You probably think I’m telling you to visit the dark web…</p>
<p>You could I suppose.</p>
<p>Its actually much better to read the scriptures. The best inspiration comes from places people rarely visit. <a href="https://scrollmapper.github.io/pages/apocryphal/">That would reveal much to you that you didn’t know you didn’t know…</a> (<a href="https://web.archive.org/web/20200910082737/https://scrollmapper.github.io/pages/apocryphal/">archived</a>)</p>
<p>Some times the most useful things are hidden for a reason.</p>
<hr>

    </div></div>]]>
            </description>
            <link>https://hawaiigentech.com/post/commentary/it-came-from-the-dark-web/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24437280</guid>
            <pubDate>Thu, 10 Sep 2020 22:37:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fun and Games in Emacs]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24437089">thread link</a>) | @tosh
<br/>
September 10, 2020 | https://masteringemacs.com/article/fun-games-in-emacs | <a href="https://web.archive.org/web/*/https://masteringemacs.com/article/fun-games-in-emacs">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <article>
        
        
        
            
        
        
            
        
        
            
                
            
            <img src="https://masteringemacs.com/static/img/fleuron2.gif">
            
<p>It’s yet another Monday and you’re hard at work on those <a href="https://en.wikipedia.org/wiki/Office_Space">TPS reports</a> for your boss, Lumbergh. Why not play Emacs’s Zork-like text adventure game to take your mind off the tedium of work?</p><p>But seriously, yes, there are both games and quirky playthings in Emacs. Some you have probably heard of or played before. The only thing they have in common is that most of them were added a <em>long</em> time ago: some are rather odd inclusions (as you’ll see below) and others were clearly written by bored employees or graduate students. What they all have in common is a whimsy and a casualness that I rarely see in Emacs today. Emacs is Serious Business now in a way that it probably wasn’t back in the 1980s when some of these games were written.</p><h2 id="tower-of-hanoi">Tower of Hanoi</h2><p>The <a href="https://en.wikipedia.org/wiki/Tower_of_Hanoi">Tower of Hanoi</a> is an ancient mathematical puzzle game and one that is probably familiar to some of us as it is often used in Computer Science as a teaching aid because of its recursive and iterative solutions.</p><p><img src="https://masteringemacs.com/static/uploads/hanoi.png" alt="Tower of Hanoi Screenshot"></p><p>In Emacs there are three commands you can run to trigger the Tower of Hanoi puzzle: <code>M-x hanoi</code> with a default of 3 discs; <code>M-x hanoi-unix</code> and <code>M-x hanoi-unix-64</code> uses the unix timestamp, making a move each second in line with the clock, and with the latter pretending it uses a 64-bit clock.</p><p>The Tower of Hanoi implementation in Emacs dates from the mid 1980s — an awful long time ago indeed. There are a few <em>Customize</em> options (<code>M-x customize-group RET hanoi RET</code>) such as enabling colorized discs. And when you exit the Hanoi buffer or type a character you are treated to a sarcastic goodbye message (see above.)</p><h2 id="x5">5x5</h2><p><img src="https://masteringemacs.com/static/uploads/5x5.png" alt="5x5 game grid"> The 5x5 game is a logic puzzle: you are given a 5x5 grid with a central cross already filled-in; your goal is to fill all the cells by toggling them on and off in the right order to win. It’s not as easy as it sounds!</p><p>To play, type <code>M-x 5x5</code>, and with an optional digit argument you can change the size of the grid. What makes this game interesting is its rather complex ability to suggest the next move and attempt to solve the game grid. It uses Emacs’s very own, and very cool, symbolic RPN calculator <code>M-x calc</code> (and in <a href="https://masteringemacs.com/article/fun-emacs-calc">Fun with Emacs Calc</a> I use it to solve a simple problem.)</p><p>So what I like about this game is that it comes with a very complex solver – really, you should read the source code with <code>M-x find-library RET 5x5</code> – and a “cracker” that attempts to brute force solutions to the game.</p><p>Try creating a bigger game grid, such as <code>M-10 M-x 5x5</code>, and then run one of the <code>crack</code> commands below. The crackers will attempt to iterate their way to the best solution. This runs in real time and is fun to watch:</p><dl><dt><code>M-x 5x5-crack-mutating-best</code></dt><dd><p>Attempt to crack 5x5 by mutating the best solution.</p></dd><dt><code>M-x 5x5-crack-mutating-current</code></dt><dd><p>Attempt to crack 5x5 by mutating the current solution.</p></dd><dt><code>M-x 5x5-crack-randomly</code></dt><dd><p>Attempt to crack 5x5 using random solutions.</p></dd><dt><code>M-x 5x5-crack-xor-mutate</code></dt><dd><p>Attempt to crack 5x5 by xoring the current and best solution.</p></dd></dl><h2 id="text-animation">Text Animation</h2><p>You can display a fancy birthday present animation by running <code>M-x animate-birthday-present</code> and giving it your name. It looks rather cool!</p><p><img src="https://imgs.xkcd.com/comics/real_programmers.png" alt="xkcd"></p><p>The <code>animate</code> package is also used by <code>M-x butterfly</code> command, a command added to Emacs as an homage to the <a href="http://www.xkcd.com/">XKCD</a> strip above. Of course the Emacs command in the strip is <em>teeechnically</em> not valid but the humor more than makes up for it.</p><h2 id="blackbox">Blackbox</h2><p>The objective of this game I am going to quote literally:</p><blockquote><p>The object of the game is to find four hidden balls by shooting rays into the black box. There are four possibilities: 1) the ray will pass thru the box undisturbed, 2) it will hit a ball and be absorbed, 3) it will be deflected and exit the box, or 4) be deflected immediately, not even being allowed entry into the box.</p></blockquote><p>So, it’s a bit like the <a href="https://en.wikipedia.org/wiki/Battleship_(game)">Battleship</a> most of us played as kids but… for people with advanced degrees in physics?</p><p>It’s another game that was added back in the 1980s. I suggest you read the extensive documentation on how to play by typing <code>C-h f blackbox</code>.</p><h2 id="bubbles">Bubbles</h2><p><img src="https://masteringemacs.com/static/uploads/bubbles.png" alt="Bubbles game"></p><p>The <code>M-x bubbles</code> game is rather simple: you must clear out as many “bubbles” as you can in as few moves as possible. When you remove bubbles the other bubbles drop and stick together. It’s a fun game that, as an added bonus, comes with graphics if you use Emacs’s GUI. It also works with your mouse.</p><p>You can configure the difficulty of the game by calling <code>M-x bubbles-set-game-&lt;difficulty&gt;</code> where <code>&lt;difficulty&gt;</code> is one of: <code>easy</code>, <code>medium</code>, <code>difficult</code>, <code>hard</code>, or <code>userdefined</code>. Furthermore, you can alter the graphics, grid size and colors using Customize: <code>M-x customize-group bubbles</code>.</p><p>For its simplicity and fun factor, this ranks as one of my favorite games in Emacs.</p><h2 id="fortune-cookie">Fortune &amp; Cookie</h2><p>I like the <code>fortune</code> command. Snarky, unhelpful and often sarcastic “advice” mixed in with literature and riddles brightens up my day whenever I launch a new shell.</p><p>Rather confusingly there are two packages in Emacs that does more-or-less the same thing: <code>fortune</code> and <code>cookie1</code>. The former is geared towards putting fortune cookie messages in email signatures and the latter is just a simple reader for the fortune format.</p><p>Anyway, to use Emacs’s <code>cookie1</code> package you must first tell it where to find the file by customizing the variable <code>cookie-file</code> with <code>customize-option RET cookie RET</code>.</p><p>If you’re on Ubuntu you will have to install the <code>fortune</code> package first. The files are found in the <code>/usr/share/games/fortunes/</code> directory.</p><p>You can then call <code>M-x cookie</code> or, should you want to do this, find all matching cookies with <code>M-x cookie-apropos</code>.</p><h2 id="decipher">Decipher</h2><p>This package perfectly captures the utilitarian nature of Emacs: it’s a package to help you break simple substitution ciphers (like cryptogram puzzles) using a helpful user interface. You just know that – more than twenty years ago – someone <em>really</em> had a dire need to break a lot of basic ciphers. It’s little things like this module that makes me overjoyed to use Emacs: a module of scant importance to all but a few people and, yet, should you need it – there it is.</p><p>So how do you use it then? Well, let’s consider the “rot13” cipher: rotating characters by 13 places in a 26-character alphabet. It’s an easy thing to try out in Emacs with <code>M-x ielm</code>, Emacs’s REPL for <a href="https://masteringemacs.com/article/evaluating-elisp-emacs">Evaluating Elisp</a>:</p><pre><code>*** Welcome to IELM ***  Type (describe-mode) for help.
ELISP&gt; (rot13 "Hello, World")
"Uryyb, Jbeyq"
ELISP&gt; (rot13 "Uryyb, Jbeyq")
"Hello, World"
ELISP&gt;</code></pre><p>Simply put, you rotate your plaintext 13 places and you get your ciphertext; you rotate is another 13 and you end up where you started. This is the sort of thing this package can help you solve.</p><p>So how can the decipher module help us here? Well, create a new buffer <code>test-cipher</code> and type in your cipher text (in my case <code>Uryyb, Jbeyq</code>)</p><p><img src="https://masteringemacs.com/static/uploads/cipher.png" alt="cipher"></p><p>You’re now presented with a rather complex interface. You can now place the point on any of the characters in the ciphertext on the purple line and guess what the character might be: Emacs will update the rest of the plaintext guess with your choices and tell you how the characters in the alphabet have been allocated thus far.</p><p>You can then start winnowing down the options using various helper commands to help infer which cipher characters might correspond to which plaintext character:</p><dl><dt><code>D</code></dt><dd><p>Shows a list of digrams (two-character combinations from the cipher) and their frequency</p></dd><dt><code>F</code></dt><dd><p>Shows the frequency of each ciphertext letter</p></dd><dt><code>N</code></dt><dd><p>Shows adjacency of characters. I am not entirely sure how this works.</p></dd><dt><code>M</code> and <code>R</code></dt><dd><p>Save and restore a checkpoint, allowing you to branch your work and explore different ways of cracking the cipher.</p></dd></dl><p>All in all, for such an esoteric task, this package is rather impressive! If you regularly solve cryptograms maybe this package can help?</p><h2 id="doctor">Doctor</h2><p><img src="https://masteringemacs.com/static/uploads/doctor.png" alt="doctor"></p><p>Ah, the Emacs doctor. Based on the original <a href="https://en.wikipedia.org/wiki/ELIZA">ELIZA</a> the “Doctor” tries to psychoanalyze what you say and attempts to repeat the question back to you. Rather fun, for a few minutes, and one of the more famous Emacs oddities. You can run it with <code>M-x doctor</code>.</p><h2 id="dunnet">Dunnet</h2><p>Emacs’s very own Zork-like text adventure game. To play it, type <code>M-x dunnet</code>. It’s rather good, if short, but it’s another rather famous Emacs game that too few have actually played through to the end.</p><p>If you find yourself with time to kill between your TPS reports then it’s a great game with a built-in “boss screen” as it’s text-only.</p><p>Oh, and, don’t try to eat the CPU card :)</p><h2 id="gomoku">Gomoku</h2><p><img src="https://masteringemacs.com/static/uploads/gomoku.png" alt="gomoku"></p><p>Another game written in the 1980s. You have to connect 5 squares, tic-tac-toe style. You can play against Emacs with <code>M-x gomoku</code>. The game also supports the mouse, which is rather handy. You can customize the group <code>gomoku</code> to adjust the size of the grid.</p><h2 id="game-of-life">Game of Life</h2><p><a href="https://en.wikipedia.org/wiki/Conway's_Game_of_Life">Conway’s Game of Life</a> is a famous example of cellular automata. The Emacs version comes with a handful of starting patterns that you can (programmatically with elisp) alter by adjusting the <code>life-patterns</code> variable.</p><p>You can trigger a game of life with <code>M-x life</code>. The fact that the whole thing, display code, comments and all, come in at less than 300 characters is also rather impressive.</p><h2 id="pong-snake-and-tetris">Pong, Snake and Tetris</h2><p><img src="https://masteringemacs.com/static/uploads/tetris.png" alt="tetris"></p><p>These classic games are all implemented using the Emacs package <code>gamegrid</code>, a generic framework for building grid-based games like Tetris and Snake. The great thing about the gamegrid package is its compatibility with both graphical and terminal Emacs: if you run Emacs in a GUI you get fancy graphics; if you don’t, you get simple ASCII art.</p><p>You can run the games by typing <code>M-x pong</code>, <code>M-x snake</code>, or <code>M-x tetris</code>.</p><p>The Tetris game in particular is rather faithfully implemented, having both gradual speed increase and the ability to slide blocks into place. And given you have the code to it, you can finally remove that annoying <code>Z</code>-shaped piece no one likes!</p><h2 id="solitaire">Solitaire</h2><p><img src="https://masteringemacs.com/static/uploads/solitaire.png" alt="solitaire image"></p><p>This is <em>not</em> the card game, unfortunately. But a peg-based game where you have to end up with just one stone on the board, by taking a stone (the <code>o</code>) and “jumping” over an adjacent stone into the hole (the <code>.</code>), removing the stone you jumped over in the process. Rinse and repeat until the board is empty.</p><p>Ther…</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://masteringemacs.com/article/fun-games-in-emacs">https://masteringemacs.com/article/fun-games-in-emacs</a></em></p>]]>
            </description>
            <link>https://masteringemacs.com/article/fun-games-in-emacs</link>
            <guid isPermaLink="false">hacker-news-small-sites-24437089</guid>
            <pubDate>Thu, 10 Sep 2020 22:12:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Everything you ever wanted to know about terminals (2018)]]>
            </title>
            <description>
<![CDATA[
Score 68 | Comments 45 (<a href="https://news.ycombinator.com/item?id=24436860">thread link</a>) | @n3t
<br/>
September 10, 2020 | https://xn--rpa.cc/irl/term.html | <a href="https://web.archive.org/web/*/https://xn--rpa.cc/irl/term.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<h3><a href="https://xn--rpa.cc/index.html">ʞ</a> / <a href="https://xn--rpa.cc/irl/index.html">essays</a> /</h3>



<p>so here's a short tutorial on ansi escape codes and terminal control, because you philistines won't stop using ncurses and oh my god <em>WHY ARE WE STILL USING NCURSES IT IS THE TWENTY FIRST FUCKING CENTURY</em></p>

<p>the way terminal emulators handle fancy things like color and cursor shape aren't some mysterious opaque black box you can only access through a library. accessing these capabilities is actually extremely simple; they can even be hardcoded into a text file and displayed by <code>cat</code> or <code>less</code>. or even <a href="http://xn--rpa.cc/ansiglot">curl</a>! the way you do this is with something called <em>ANSI escape sequences.</em></p>

<p>almost all UI changes in a terminal are accomplished through in-band signalling. these signals are triggered with the ASCII/UTF-8 character <strong>‹ESC›</strong> (<code>0x1B</code> or <code>27</code>). it's the same <strong>‹ESC›</strong> character that you send to the terminal when you press the <code>Escape</code> key on your keyboard or a key sequence involving the <code>Alt</code> key. (typing <strong>‹A-c›</strong> for instance sends the characters <strong>‹ESC›</strong> and <strong>‹c›</strong> in very rapid succession; this is why you'll notice a delay in some terminal programs after you press the escape key — it's waiting to try and determine whether the user hit <code>Escape</code> or an alt-key chord.)</p>

<p>the simplest thing we can do with these escapes is to make the text <strong>bold</strong> (or "bright"). we accomplish this by sending the terminal the <strong>‹ESC›</strong> character followed by <code>[1m</code>. <code>[</code> is a character indicating to the terminal what kind of escape we're sending, <code>1</code> indicates bold/bright mode, and <code>m</code> is the control character for formatting escapes.</p>

<p>all text sent after this escape sequence will be bold until we explicitly turn it off again (even if your program terminates). there are two ways we can turn off bright mode: by clearing formatting entirely, using the <code>m</code> formatting command with no arguments or the argument <code>0</code>, or more specifically clearing the bold bit with the <code>21m</code> command. (you'll notice that you can usually turn off modes by prefixing the same number with <code>2</code>.)</p>

<p>in a C program, this might look like the following:</p>

<code><b>#include</b> <cite>&lt;unistd.h&gt;</cite>
<span>#define</span> szstr(str) str,sizeof(str)
<strong>int</strong> main() {
	write(1, szstr(<em>"plain text - \x1b[1mbold text\x1b[0m - plain text"</em>));
}
</code>

<p>the <code>\x1b</code> escape here is a C string escape that inserts hex character <code>0x1B</code> (<strong>‹ESC›</strong>) into the string. it's kind of ugly and unreadable if you're not used to reading source with explicit escapes in it. you can make it a lot less horrible with a handful of defines, tho:</p>

<code><span>#include</span> <em>&lt;unistd.h&gt;</em>
<span>#define</span> szstr(str) str,sizeof(str)

<span>#define</span>     plain "0" /* or "" */
<span>#define</span>        no "2"
<span>#define</span>    bright "1"
<span>#define</span>       dim "2"
<span>#define</span>    italic "3"
<span>#define</span> underline "4"
<span>#define</span>   reverse "7"
<span>#define</span>      with ";"
<span>#define</span>  ansi_esc "\x1b"
<span>#define</span> fmt(style) ansi_esc "[" style "m"

<span>int</span> main() {
	write(1, szstr(    <em>"plain text - "</em>
		fmt(bright)     <em>"bright text"</em>     fmt(no bright) <em>" - "</em>
		fmt(dim)       <em>"dim text"</em>        fmt(no dim)    <em>" - "</em> 
		fmt(italic)    <em>"italic text"</em>     fmt(no italic) <em>" - "</em>
		fmt(reverse)   <em>"reverse video"</em>   fmt(plain)     <em>" - "</em>
		fmt(underline) <em>"underlined text"</em> fmt(no underline) )
	);
}
</code>

<p>the beauty of this approach is that all the proper sequences are generated at <em>compile time</em>, meaning the compiler turns all that into a single string interpolated with the raw escapes. it offers much more readability for the coder at zero cost to the end user.</p>

<p>but hang on, where's that semicolon coming from? it turns out, ansi escape codes let you specify multiple formats per sequence. you can separate each command with a <code>;</code>. this would allow us to write formatting commands like <code>fmt(underline with bright with no italic)</code>, which translates into <code>\x1b[4;1;23m</code> at compile time.</p>

<p>of course, being able to style text isn't nearly good enough. we also need to be able to color it. there are two components to a color command: what we're trying to change the color of, and what color we want to change it to. both the foreground and background can be given colors separately - despite what ncurses wants you to believe, you do not have to define """color pairs""" with each foreground-background pair you're going to use. this is a ridiculous archaism that nobody in the 21st fucking century should be limited by.</p>

<p>to target the foreground, we send the character <code>3</code> for normal colors or <code>9</code> for bright colors; to target the background, we send <code>4</code> for normal or <code>10</code> for bright. this is then followed by a color code selecting one of the traditional 8 terminal colors.</p>

<p>note that the "bright" here is both the same thing and something different from the "bright" mode we mentioned earlier. while turning on the "bright" mode will automatically shift text it applies to the bright variant of its color <em>if</em> it is set to one of the traditional 8 colors, setting a "bright color" with <code>9</code> or <code>10</code> will not automatically make the text bold.</p>

<code><span>#include</span> <em>&lt;unistd.h&gt;</em>
<span>#define</span> szstr(str) str,sizeof(str)

<span>#define</span> fg "3"
<span>#define</span> br_fg "9"
<span>#define</span> bg "4"
<span>#define</span> br_bg "10"
<span>#define</span> with ";"
<span>#define</span>      plain ""
<span>#define</span>      black "0"
<span>#define</span>        red "1"
<span>#define</span>      green "2"
<span>#define</span>     yellow "3"
<span>#define</span>       blue "4"
<span>#define</span>    magenta "5"
<span>#define</span>       cyan "6"
<span>#define</span>      white "7"
<span>#define</span>   ansi_esc "\x1b"
<span>#define</span> fmt(style) ansi_esc "[" style "m"

<span>int</span> main() {
	write(1, szstr(
		<em>"plain text - "</em>
		fmt(fg blue) <em>"blue text"</em> fmt(plain)               <em>" - "</em>
		fmt(br_fg blue) <em>"bright blue text"</em> fmt(plain)     <em>" - "</em>
		fmt(br_bg red) <em>"bright red background"</em> fmt(plain) <em>" - "</em>
		fmt(fg red with br_bg magenta) <em>"hideous red text"</em> fmt(plain))
	);
}
</code>

<p>when we invoke <code>fmt(fg red with br_bg magenta)</code>, this is translated by the compiler into the command string <code>\x1b[31;105m</code>. note that we're using <code>fmt(plain)</code> (<code>\x1b[m</code>) to clear the coloring here; this is because if you try to reset colors with, for instance, <code>fmt(fg black with bg white)</code>, you'll be overriding the preferences of users who have their terminal color schemes set to anything but that exact pair. additionally, if the user happens to have a terminal with a transparent background, a set background color will create ugly colored blocks around text instead of letting whatever's behind the window display correctly.</p>

<p>now, while it is more polite to use the "8+8" colors because they're a color palette the end-user can easily configure (she might prefer more pastel colors than the default harsh pure-color versions, or change the saturation and lightness to better fit with her terminal background), if you're doing anything remotely interesting UI-wise you're going to run up against that limit very quickly. while you can get a bit more mileage by mixing colors with styling commands, if you want to give <em>any</em> configurability to the user in terms of color schemes (as you rightly should), you'll want access to a much broader palette of colors.</p>

<p>to pick from a 256-color palette, we use a slightly different sort of escape: <code>\x1b[38;5;<em>(color)</em>m</code> to set the foreground and <code>\x1b[48;5;<em>(color)</em>m</code> to set the background, where <em>(color)</em> is the palette index we want to address. these escapes are even more unwieldy than the 8+8 color selectors, so it's even more important to have good abstraction.</p>

<code><span>#include</span> <em>&lt;unistd.h&gt;</em>
<span>#define</span> szstr(str) str,sizeof(str)

<span>#define</span>       with ";"
<span>#define</span>      plain ";"
<span>#define</span> wfg(color) "38;5;" #color
<span>#define</span> wbg(color) "48;5;" #color
<span>#define</span>   ansi_esc "\x1b"
<span>#define</span> fmt(style) ansi_esc "[" style "m"

<span>int</span> main() {
	write(1, szstr(<em>"plain text - "</em>
		fmt(wfg(198) with wbg(232))
			<em>"rose text on dark grey"</em>
		fmt(plain) <em>" - "</em>
		
		fmt(wfg(232) with wbg(248))
			<em>"dark grey on light grey"</em>
		fmt(plain) <em>" - "</em>
		
		fmt(wfg(248) with wbg(232))
			<em>"light grey on dark grey"</em>
		fmt(plain))
	);
}
</code>
<p>here, the stanza <code>fmt(wfg(248) with wbg(232))</code> translates into <code>\x1b[38;5;248;48;5;232m</code>. we're hard-coding the numbers here for simplicity but as a rule of thumb, any time you're using 8-bit colors in a terminal, you should <em>always</em> make them configurable by the user.</p>

<p>the opaque-seeming indexes are actually very systematic, and you can calculate which index to use for a particular color with the formula <code>16 + 36 * r + 6 * g + b</code>, where <code>r</code>, <code>g</code>, and <code>b</code> are integers ranging between 0 and 5. indices 232 through 255 are a grayscale ramp from dark (232) to light (255).</p>

<p>of course, this is still pretty restrictive. 8-bit color may have been enough for '90s CD-ROM games on Windows, but it's long past it's expiration date. using true color is much more flexible. we can do this through the escape sequence <code>\x1b[38;2;<em>(r)</em>;<em>(g)</em>;<em>(b)</em>m</code> where each component is an integer between 0 and 255.</p>

<p>sadly, true color isn't supported on many terminals, urxvt tragically included. for this reason, your program should never rely on it, and abstract these settings away to be configured by the user. defaulting to 8-bit color is a good choice, as every reasonable modern terminal has supported it for a long time now.</p>

<p>but, for users of XTerm, kitty, Konsole, and libVTE-based terminal emulators (such as gnome-terminal, mate-terminal, and termite), it's polite to have a 24-bit color mode in place. for example:</p>

<code><span>#include</span> <em>&lt;stdio.h&gt;</em>
<span>#include</span> <em>&lt;stdint.h&gt;</em>
<span>#include</span> <em>&lt;stdbool.h&gt;</em>

<span>struct</span> color {
	<span>enum</span> color_mode { trad, trad_bright, b8, b24 } mode;
	<span>union</span> {
		<span>uint8_t</span> color;
		<span>struct</span> { <span>uint8_t</span> r, g, b; };
	}
};
<span>struct</span> style {
	unsigned <span>char</span> bold      : 1;
	unsigned <span>char</span> underline : 1;
	unsigned <span>char</span> italic    : 1;
	unsigned <span>char</span> dim       : 1;
	unsigned <span>char</span> reverse   : 1;
};
<span>struct</span> format {
	<span>struct</span> style style;
	<span>struct</span> color fg, bg;
};

<span>struct</span> format
	fmt_menu = {
		{0, 0, 0, 0, 0},
		{trad, 7},
		{trad, 4}
	},
	fmt_menu_hl = {
		{1, 0, 0, 0, 0},
		{trad_bright, 7},
		{trad_bright, 4},
	};

<span>void</span> apply_color(<span>bool</span> bg, <span>struct</span> color c) {
	switch(c.mode) {
		case trad: printf(<em>"%c%u"</em>, bg ? <em>'4'</em> : <em>'3'</em>, c.color ); break;
		case trad_bright: printf(<em>"%s%u"</em>, bg ? <em>"9"</em> : <em>"10"</em>, c.color ); break;
		case b8: printf(<em>"%c8;5;%u"</em>, bg ? <em>'4'</em> : <em>'3'</em>, c.color); break;
		case b24: printf(<em>"%c8;2;%u;%u;%u"</em>, bg ? <em>'4'</em> : <em>'3'</em>, c.r, c.b, c.g);
	}
}

<span>void</span> fmt(struct format f) {
	printf(<em>"\x1b["</em>);
	f.bold      &amp;&amp; printf(<em>";1"</em>);
	f.underline &amp;&amp; printf(<em>";4"</em>);</code></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://xn--rpa.cc/irl/term.html">https://xn--rpa.cc/irl/term.html</a></em></p>]]>
            </description>
            <link>https://xn--rpa.cc/irl/term.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24436860</guid>
            <pubDate>Thu, 10 Sep 2020 21:44:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Open Source Community Is Not Defenseless Against Patent Trolls]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24436763">thread link</a>) | @Andrew_Russell
<br/>
September 10, 2020 | https://ipde.com/blog/open-source-community-not-defenseless-against-patent-trolls/ | <a href="https://web.archive.org/web/*/https://ipde.com/blog/open-source-community-not-defenseless-against-patent-trolls/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <div>
                    <section>
                        <div><figure "=""><img src="https://bd6f.s3.amazonaws.com/media/images/jamie-street-5gvSBUZ6K10-unsplash_pXTLyQl.max-640x360.jpg" alt="I assume there is a troll in here somewhere" srcset="https://bd6f.s3.amazonaws.com/media/images/jamie-street-5gvSBUZ6K10-unsplash_pXTLyQl.max-640x360.jpg 610w, https://bd6f.s3.amazonaws.com/media/images/jamie-street-5gvSBUZ6K10-unsplash_pXTLyQl.max-768x432.jpg 733w, https://bd6f.s3.amazonaws.com/media/images/jamie-street-5gvSBUZ6K10-unsplash_pXTLyQl.max-1024x576.jpg 977w, https://bd6f.s3.amazonaws.com/media/images/jamie-street-5gvSBUZ6K10-unsplash_pXTLyQl.max-1600x900.jpg 1527w, https://bd6f.s3.amazonaws.com/media/images/jamie-street-5gvSBUZ6K10-unsplash_pXTLyQl.max-1920x1080.jpg 1832w"><figcaption><span>I assume there is a troll in here somewhere</span> <span><a href="https://unsplash.com/photos/5gvSBUZ6K10">Jamie Street</a>, <a href="https://unsplash.com/license">Unsplash</a></span></figcaption></figure><p>As I <a href="https://ipde.com/blog/rothschild-covenant-not-sue-made-public-purported-cover-most-open-source-software/">mentioned</a> earlier this week, I recently saw a <a href="https://blog.hansenpartnership.com/lessons-from-the-gnome-patent-troll-incident/">fascinating article</a> by James Bottomley relating a non-attorneys' view on patent trolls and a specific attack against <a href="https://en.wikipedia.org/wiki/GNOME">GNOME</a>, a well-known component of many open source Linux- and Unix-based operating systems.</p><p>The GNOME Foundation was sued in the N.D. Cal. by a Rothschild entity (a well-known <a href="#" data-toggle="tooltip" data-placement="top" title="Non-Practicing Entity">NPE</a>). The case involved what looks like a pretty typical <a href="#" data-toggle="tooltip" data-placement="top" title="Non-Practicing Entity">NPE</a> complaint, alleging infringement of a single patent. His article recounted his experiences and the settlement, and argues that the patent system is broken because of how hard it is to defend against these kinds of suits.</p><p>I wanted to take a quick break from our usual deep-in-the-litigation-weeds fare and offer a patent litigator's perspective on what Bottomley said.</p><p>This article is written for any non-lawyers who saw Bottomley's article and who may be unfamiliar with patent litigation—<b>I expect our regular readers will already know all of this!</b></p><h2>Yes, Patent Troll Behavior Is a Problem</h2><p>The article is right in its basic description of patent troll / <a href="#" data-toggle="tooltip" data-placement="top" title="Non-Practicing Entity">NPE</a> behavior, which matches what we've all seen time and again. In Delaware specifically (currently the nation's busiest patent forum), there have been more of these kinds of cases lately, ever since <i><a href="#" data-toggle="tooltip" data-placement="top" title="TC Heartland LLC v. Kraft Foods Grp. Brands LLC, 137 S. Ct. 1514 (2017)">TC Heartland</a></i> changed the venue rules and many NPEs started filing here instead of the Eastern District of Texas.</p><p>But it's also <a href="https://opensource.com/law/15/8/patent-troll-problem-not-new-one">nothing new</a>. There have been many, many troll cases over the years, and it's part of what drove the passing of the America Invents Act in 2011, which created the <a href="#" data-toggle="tooltip" data-placement="top" title="Inter Partes Review">IPR</a> procedure Bottomley mentions. And those who practice in the area know that there are techniques for dealing with troll cases.</p><h2>Targets in the Open Source Community Are Not Defenseless</h2><p>Bottomley's article makes a few statements and understandable mistakes that make targets seem more defenseless than they really are:</p><ul><li><b>The presumption of validity:</b> Yes, issued U.S. Patents are presumed valid, but it's just a presumption. In practice, it means little more than a higher burden of proof on validity issues ("clear and convincing" evidence instead of a "preponderance" of the evidence.) Courts and juries still <a href="https://ipde.com/blog/judge-connolly-knocks-out-five-patents-rule-12-motion/">regularly</a> <a href="https://ipde.com/blog/berkheimer-more-brokeheimer/">invalidate</a> U.S. patent claims for a variety of reasons.</li><li><b>Summary judgment is available:</b> Summary judgment is available in most patent cases, and summary judgment of invalidity absolutely does happen. In Delaware, while summary judgment typically happens late in the case, the judges can be open to considering it earlier in the case if you've got the right facts. Something along the lines of "our product was released before the priority date of the patent"—as described in the article—sounds like a pretty good set of facts.</li><li><b>There are a number of ways to invalidate a patent:</b> Bottomley touches on <a href="#" data-toggle="tooltip" data-placement="top" title="35 U.S.C. § 101: Inventions patentable">§ 101</a> and <i>Alice</i> decision, which allow defendants to argue that patents are invalid for claiming an abstract idea. There is also <a href="#" data-toggle="tooltip" data-placement="top" title="35 U.S.C. § 102: Anticipation">§ 102</a> (anticipation, i.e., the idea already existed), <a href="#" data-toggle="tooltip" data-placement="top" title="35 U.S.C. § 103: Obviousness">§ 103</a> (the idea was obvious), and § 112, which covers a range of technical deficiencies in patents, such as indefiniteness (where a person cannot be "reasonably certain" what the words in the patent claims mean). There are also other defenses, such as inequitable conduct (e.g., certain misrepresentations before the PTO).</li><li><b>You don't need to wait for summary judgment to challenge a patent:</b> The article incorrectly implies that early <a href="#" data-toggle="tooltip" data-placement="top" title="35 U.S.C. § 101: Inventions patentable">§ 101</a> motions are impossible. While early <a href="#" data-toggle="tooltip" data-placement="top" title="35 U.S.C. § 101: Inventions patentable">§ 101</a> motions have become a <a href="https://www.law360.com/articles/1181804/quick-alice-wins-dwindling-in-wake-of-berkheimer-ruling">bit harder</a> since the Federal Circuit's 2018 <i>Berkheimer</i> decision, they are still granted <a href="https://ipde.com/blog/berkheimer-more-brokeheimer/">rather frequently</a>. Section 101 definitely increases the risk to patent trolls. And indefiniteness under § 112 is often addressed at claim construction, which usually occurs before summary judgment.</li><li><b><a href="#" data-toggle="tooltip" data-placement="top" title="35 U.S.C. § 285: Attorney fees">§ 285</a> fees:</b> As the article rightly notes, <a href="#" data-toggle="tooltip" data-placement="top" title="35 U.S.C. § 285: Attorney fees">§ 285</a> provides the ability to seek fees in exceptional cases. And while NPEs may have few monetary assets, parties have sometimes succeeded in claiming the patent that the <a href="#" data-toggle="tooltip" data-placement="top" title="Non-Practicing Entity">NPE</a> holds, potentially ending the threat for everyone. (Note that Bottomley is incorrect in that an award of fees under <a href="#" data-toggle="tooltip" data-placement="top" title="35 U.S.C. § 285: Attorney fees">§ 285</a> does not, by itself, pierce the corporate veil and reach assets beyond those of the <a href="#" data-toggle="tooltip" data-placement="top" title="Non-Practicing Entity">NPE</a>).</li></ul><p>Section 101 invalidity is especially noteworthy, since most suits relating to open source software are going to be related to, well, software. And unless Congress decides to cut it back (last I heard, that movement has <a href="https://www.aei.org/technology-and-innovation/1-year-later-patent-eligibility-reform-no-further-along/">stalled</a>), <a href="#" data-toggle="tooltip" data-placement="top" title="35 U.S.C. § 101: Inventions patentable">§ 101</a> remains a powerful tool against a lot of older software patents.</p><p>Beyond the above, all of the normal defenses in any patent infringement case are available in cases against tech non-profits, including things like non-infringement (i.e., the accused product doesn't actually practice the claims). Plus, as Bottomley touched on, there are <a href="https://www.theregister.com/2019/11/04/open_invention_network_will_pivot_to_take_on_patent_trolls/">broad</a> <a href="https://openinventionnetwork.com/">initiatives</a> <a href="https://www.ipwatchdog.com/2020/07/14/limiting-impact-patent-assertion-entities-open-source-community/id=123260/">going on</a> to defend open-source software against troll suits generally.</p><h2>Pro Bono Representation Is Often Available</h2><p>Bottomley includes a call to action for open source organizations to tell everyone when they are attacked by a patent troll, because "you won’t get . . . pro bono representation . . . unless people know about it."</p><p>That's not necessarily true. You don't have to run a P.R. campaign to get <i>pro bono</i> (free) patent representation (although having <a href="https://secure.givelively.org/donate/gnome-foundation-inc/gnome-patent-troll-defense-fund">$150k at the ready</a> certainly increases your options in a case). For non-profits, very small businesses, and other such noble causes, there is help available.</p><p>The EFF, for example, maintains an <a href="https://www.eff.org/pages/legal-assistance">attorney referral list</a> for those seeking pro bono help. I've represented clients <i>pro bono</i> against patent and copyright trolls through referrals from that list and elsewhere, and I know that a number of other attorneys do the same.</p><p>Moving to <i>pro bono</i> representation changes the cost calculus for a troll. The target is no longer facing millions of dollars in attorneys' fees, but the <a href="#" data-toggle="tooltip" data-placement="top" title="Non-Practicing Entity">NPE</a> still faces the threat of patent invalidation and <a href="#" data-toggle="tooltip" data-placement="top" title="35 U.S.C. § 285: Attorney fees">§ 285</a> attorneys' fees. And courts have regularly permitted the recovery of attorneys fees in <i>pro bono</i> cases, even if the defendant itself was not on the hook for them.</p><p>Plus, dedicated patent litigators know the tricks in their districts to help get these cases dealt with as quickly as possible. It doesn't fix everything—as the article notes, patent litigation can be expensive even with free representation. But it definitely helps.</p></div>
                        <p><span>If you enjoyed this post, consider subscribing to receive daily or weekly e-mails about any new posts.</span></p>
                        
                    </section>
                </div>
            </div></div>]]>
            </description>
            <link>https://ipde.com/blog/open-source-community-not-defenseless-against-patent-trolls/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24436763</guid>
            <pubDate>Thu, 10 Sep 2020 21:31:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Timing-Safe Bcrypt Authentication in PostgreSQL]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24436729">thread link</a>) | @danielfone
<br/>
September 10, 2020 | https://daniel.fone.net.nz/blog/2020/09/09/timing-safe-bcrypt-authentication-in-postgresql/ | <a href="https://web.archive.org/web/*/https://daniel.fone.net.nz/blog/2020/09/09/timing-safe-bcrypt-authentication-in-postgresql/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    
    <p>
      September 2020
      ·
      about 5  minutes to read
    </p>

      <summary>
        <p><strong>tl;dr</strong> To avoid disclosing <abbr title="Personally Identifying Information">PII</abbr> and to prevent user enumeration during authentication, ensure you always perform a hash comparison, even if no user record is found.</p>
      </summary>

    <p>Many applications aim to prevent <a href="https://blog.rapid7.com/2017/06/15/about-user-enumeration/">user enumeration</a> during authentication, particularly if users authenticate themselves with some PII like an email address. Well-designed login forms usually don’t disclose whether the username or password is incorrect, both because the response can be misleading,<sup id="fnref:1"><a href="#fn:1">1</a></sup> and because it will disclose the presence of accounts in the database, facilitating spear-phishing, credential stuffing, and other attacks.</p>

<p>However, while the response body may not disclose this, often the response time still betrays whether a matching user record exists in the database. Because effective password checking like bcrypt is deliberately so slow, the response is much quicker if there is no digest to compare the submitted plain-text against. This oversight can undermine the ambiguity of the response body and expose users to the attacks mentioned above.</p>

<p>Let’s look at an example authentication query in PostgreSQL.<sup id="fnref:2"><a href="#fn:2">2</a></sup> First we’ll add a user record.</p>

<div><pre><code><span>insert</span> <span>into</span> <span>users</span> <span>(</span><span>email</span><span>,</span> <span>password_digest</span><span>)</span>
<span>values</span> <span>(</span><span>'daniel@example.com'</span><span>,</span> <span>crypt</span><span>(</span><span>'my-password'</span><span>,</span> <span>gen_salt</span><span>(</span><span>'bf'</span><span>)));</span>

<span>select</span> <span>*</span> <span>from</span> <span>users</span><span>;</span>

<span>--  id |       email        |                       password_digest</span>
<span>-- ----+--------------------+--------------------------------------------------------------</span>
<span>--   1 | daniel@example.com | $2a$06$xMGQrmx5DrVvfiBqdVhZLeQJOWx95H/B..79VElnBAh/xa5bKGkwG</span>
</code></pre></div>
<p>The <a href="https://www.postgresql.org/docs/12/pgcrypto.html#id-1.11.7.34.6.7">crypt function</a> is provided by the pgcrypto module. It takes a plain-text password and a salt, and returns a hash. Since crypt-style hashes include their salt (along with the algorthim details), the same function can be used to generate new hashes or verify existing ones.<sup id="fnref:3"><a href="#fn:3">3</a></sup> In this case, we use the gen_salt function to generate a bcrypt salt with the default number of iterations (<code>bf</code> is for blowfish which is synonymous with bcrypt here). Note that this only uses the first 72 bytes of the plain-text password, a more secure approach is to digest the entire plain-text first.<sup id="fnref:4"><a href="#fn:4">4</a></sup></p>

<p>Now let’s look at a naive authentication query.</p>

<div><pre><code><span>-- Correct username and password</span>
<span>select</span> <span>*</span>
<span>from</span> <span>users</span>
<span>where</span> <span>email</span> <span>=</span> <span>'daniel@example.com'</span>
  <span>and</span> <span>password_digest</span> <span>=</span> <span>crypt</span><span>(</span><span>'my-password'</span><span>,</span> <span>password_digest</span><span>);</span>
<span>--  id |       email        |                       password_digest</span>
<span>-- ----+--------------------+--------------------------------------------------------------</span>
<span>--   1 | daniel@example.com | $2a$06$xMGQrmx5DrVvfiBqdVhZLeQJOWx95H/B..79VElnBAh/xa5bKGkwG</span>
<span>--</span>
<span>-- Time: 6.692 ms</span>

<span>-- Incorrect password</span>
<span>select</span> <span>*</span>
<span>from</span> <span>users</span>
<span>where</span> <span>email</span> <span>=</span> <span>'daniel@example.com'</span>
  <span>and</span> <span>password_digest</span> <span>=</span> <span>crypt</span><span>(</span><span>'password'</span><span>,</span> <span>password_digest</span><span>);</span>
<span>--  id | email | password_digest</span>
<span>-- ----+-------+-----------------</span>
<span>--</span>
<span>-- Time: 6.513 ms</span>

<span>-- Incorrect email</span>
<span>select</span> <span>*</span>
<span>from</span> <span>users</span>
<span>where</span> <span>email</span> <span>=</span> <span>'noone@example.com'</span>
  <span>and</span> <span>password_digest</span> <span>=</span> <span>crypt</span><span>(</span><span>'my-password'</span><span>,</span> <span>password_digest</span><span>);</span>
<span>--  id | email | password_digest</span>
<span>-- ----+-------+-----------------</span>
<span>--</span>
<span>-- Time: 0.432 ms</span>
</code></pre></div><p>As we can see, checking the password against an existing hash takes several milliseconds, whereas checking the index for an email is comparatively instantaneous. This difference is increased depending on the size of the table and the number of bcrypt iterations (Rails defaults to 10). In an application I recently worked on, the difference was measurable even after the jitter introduced by the application code and network latency.</p>

<p>Whether you’re comparing the digests in the database like this, or taking the more common approach of comparing the hashes in your application code, <strong>the essential solution is to compare a bcrypt hash even if no real user is found<strong>.</strong></strong></p>

<p>For example:</p>

<div><pre><code><span>with</span>

<span>-- select either the id and password digest matching the email, or a dummy row</span>
<span>target_user</span> <span>as</span> <span>(</span>
  <span>select</span> <span>id</span><span>,</span> <span>password_digest</span>
  <span>from</span> <span>(</span>
    <span>select</span> <span>id</span><span>,</span> <span>password_digest</span> <span>from</span> <span>users</span> <span>where</span> <span>email</span> <span>=</span> <span>:</span><span>password</span>
    <span>union</span> <span>all</span>
    <span>select</span> <span>null</span><span>,</span> <span>gen_salt</span><span>(</span><span>'bf'</span><span>)</span> <span>-- a random salt</span>
  <span>)</span> <span>users</span>
  <span>limit</span> <span>1</span> <span>-- only return the first row, either the real id+digest or the "null" one</span>
<span>),</span>

<span>-- perform bcrypt matching on the guaranteed single row from target_user</span>
<span>valid_user</span> <span>as</span> <span>(</span>
  <span>select</span> <span>id</span> <span>from</span> <span>target_user</span> <span>where</span> <span>password_digest</span> <span>=</span> <span>crypt</span><span>(:</span><span>password</span><span>,</span> <span>password_digest</span><span>)</span>
<span>)</span>

<span>-- select the row from the users table matching the authenticated id</span>
<span>select</span> <span>*</span> <span>from</span> <span>users</span> <span>natural</span> <span>join</span> <span>valid_user</span> <span>limit</span> <span>1</span>
</code></pre></div>
<p>Clearly, this query is a lot more complex than our naive approach, however with judicious use of comments and well-factored subqueries, I think the intention remains relatively clear. Perhaps there are simpler ways to factor this query and achieve the same result —&nbsp;I’d love to see some alternatives! No matter how it’s achieved though, the only way to ensure that the response is truly opaque is to do the same work in all cases. One way or another we need to hash the supplied plain-text.</p>



  </article><div id="featured-posts">
    <h3>Other Posts</h3>
      <h4>
        <a href="https://daniel.fone.net.nz/blog/2014/12/10/handling-token-generation-collisions-in-activerecord/">Handling Token Generation Collisions In ActiveRecord</a>
      </h4>
      <p>Use <code>rescue ActiveRecord::RecordNotUnique</code> with <code>retry</code> to handle collisions when applicable.</p>
      <h4>
        <a href="https://daniel.fone.net.nz/blog/2013/05/20/a-better-way-to-manage-the-rails-secret-token/">A better way to manage the Rails secret token</a>
      </h4>
      <p>Don't store secrets in your source control.</p>
      <h4>
        <a href="https://daniel.fone.net.nz/blog/2014/12/05/efficient-uniqueness-validations/">Efficient Uniqueness Validations</a>
      </h4>
      <p>Use <code>:if =&gt; :field_changed?</code> on uniqueness validations to skip unnecessary checks on every save.</p>
    <p>
      <small><a href="https://daniel.fone.net.nz/blog/archives/">More posts</a></small>
    </p>
  </div></div>]]>
            </description>
            <link>https://daniel.fone.net.nz/blog/2020/09/09/timing-safe-bcrypt-authentication-in-postgresql/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24436729</guid>
            <pubDate>Thu, 10 Sep 2020 21:26:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TOML – Tom's Obvious, Minimal Language]]>
            </title>
            <description>
<![CDATA[
Score 142 | Comments 156 (<a href="https://news.ycombinator.com/item?id=24436550">thread link</a>) | @pmoriarty
<br/>
September 10, 2020 | https://toml.io/en/ | <a href="https://web.archive.org/web/*/https://toml.io/en/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <div>
    <section>
      <div>
        <div>
          <svg viewBox="0 0 128 128" xmlns="http://www.w3.org/2000/svg">
            <g>
              <polygon points="99.2359551 -7.08546829e-15 99.2359551 14.3820225 112.179775 14.3820225 112.179775 113.617978 99.2359551 113.617978 99.2359551 128 128 128 128 0"></polygon>
              <polygon points="32.3595506 41.7078652 32.3595506 25.8876404 95.6404494 25.8876404 95.6404494 41.7078652 71.9101124 41.7078652 71.9101124 110.741573 56.0898876 110.741573 56.0898876 41.7078652"></polygon>
              <polygon points="28.7640449 0 28.7640449 14.3820225 15.8202247 14.3820225 15.8202247 113.617978 28.7640449 113.617978 28.7640449 128 0 128 0 0"></polygon>
            </g>
          </svg>
          <p>
            
            <h2>
              [Tom's Obvious Minimal Language]
            </h2>
          </p>
        </div>
        <h3>
          A config file format <br>for humans.
        </h3>
        <p>
          TOML aims to be a minimal configuration file format that's easy to read due to obvious
          semantics. TOML is designed to map unambiguously to a hash table. TOML should be easy to
          parse into data structures in a wide variety of languages.
        </p>
      </div>
    </section>

    <section>
      <pre data-controller="snippet" data-snippet-copy="false"><code># This is a TOML document

title = "TOML Example"

[owner]
name = "Tom Preston-Werner"
dob = 1979-05-27T07:32:00-08:00

[database]
enabled = true
ports = [ 8001, 8001, 8002 ]
data = [ ["delta", "phi"], [3.14] ]
temp_targets = { cpu = 79.5, case = 72.0 }

[servers]

[servers.alpha]
ip = "10.0.0.1"
role = "frontend"

[servers.beta]
ip = "10.0.0.2"
role = "backend"</code></pre>
    </section>
  </div>

  <section>
    <dl>
      <div>
        <dt>
          
          TOML prioritizes humans
        </dt>

        <dd>
          <p>TOML aims to be a minimal configuration file format that:</p>
          <ul>
            <li>
              <span>is easy to read</span> due to obvious semantics
            </li>
            <li>
              <span>maps unambiguously</span> to a hash table
            </li>
            <li>
              <span>is easy to parse</span> into data structures in a wide variety
              of languages
            </li>
          </ul>
        </dd>
      </div>

      <div>
        <dt>
          
          TOML has useful native types
        </dt>
        <dd>
          <ul>
            <li>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                <path d="M12 22a10 10 0 1 1 0-20 10 10 0 0 1 0 20zm0-2a8 8 0 1 0 0-16 8 8 0 0 0 0 16zm1-9h2a1 1 0 0 1 0 2h-2v2a1 1 0 0 1-2 0v-2H9a1 1 0 0 1 0-2h2V9a1 1 0 0 1 2 0v2z"></path>
              </svg>
              <span>Key/Value Pairs</span>
            </li>
            <li>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                <path d="M12 22a10 10 0 1 1 0-20 10 10 0 0 1 0 20zm0-2a8 8 0 1 0 0-16 8 8 0 0 0 0 16zm1-9h2a1 1 0 0 1 0 2h-2v2a1 1 0 0 1-2 0v-2H9a1 1 0 0 1 0-2h2V9a1 1 0 0 1 2 0v2z"></path>
              </svg>
              <span>Arrays</span>
            </li>
            <li>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                <path d="M12 22a10 10 0 1 1 0-20 10 10 0 0 1 0 20zm0-2a8 8 0 1 0 0-16 8 8 0 0 0 0 16zm1-9h2a1 1 0 0 1 0 2h-2v2a1 1 0 0 1-2 0v-2H9a1 1 0 0 1 0-2h2V9a1 1 0 0 1 2 0v2z"></path>
              </svg>
              <span>Tables</span>
            </li>
            <li>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                <path d="M12 22a10 10 0 1 1 0-20 10 10 0 0 1 0 20zm0-2a8 8 0 1 0 0-16 8 8 0 0 0 0 16zm1-9h2a1 1 0 0 1 0 2h-2v2a1 1 0 0 1-2 0v-2H9a1 1 0 0 1 0-2h2V9a1 1 0 0 1 2 0v2z"></path>
              </svg>
              <span>Inline tables</span>
            </li>
            <li>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                <path d="M12 22a10 10 0 1 1 0-20 10 10 0 0 1 0 20zm0-2a8 8 0 1 0 0-16 8 8 0 0 0 0 16zm1-9h2a1 1 0 0 1 0 2h-2v2a1 1 0 0 1-2 0v-2H9a1 1 0 0 1 0-2h2V9a1 1 0 0 1 2 0v2z"></path>
              </svg>
              <span>Arrays of tables</span>
            </li>
            <li>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                <path d="M12 22a10 10 0 1 1 0-20 10 10 0 0 1 0 20zm0-2a8 8 0 1 0 0-16 8 8 0 0 0 0 16zm1-9h2a1 1 0 0 1 0 2h-2v2a1 1 0 0 1-2 0v-2H9a1 1 0 0 1 0-2h2V9a1 1 0 0 1 2 0v2z"></path>
              </svg>
              <span>Integers &amp; Floats</span>
            </li>
            <li>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                <path d="M12 22a10 10 0 1 1 0-20 10 10 0 0 1 0 20zm0-2a8 8 0 1 0 0-16 8 8 0 0 0 0 16zm1-9h2a1 1 0 0 1 0 2h-2v2a1 1 0 0 1-2 0v-2H9a1 1 0 0 1 0-2h2V9a1 1 0 0 1 2 0v2z"></path>
              </svg>
              <span>Booleans</span>
            </li>
            <li>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                <path d="M12 22a10 10 0 1 1 0-20 10 10 0 0 1 0 20zm0-2a8 8 0 1 0 0-16 8 8 0 0 0 0 16zm1-9h2a1 1 0 0 1 0 2h-2v2a1 1 0 0 1-2 0v-2H9a1 1 0 0 1 0-2h2V9a1 1 0 0 1 2 0v2z"></path>
              </svg>
              <span>Dates &amp; Times, with optional offsets</span>
            </li>
          </ul>
        </dd>
      </div>

      <div>
        <dt>
          
          TOML is widely supported
        </dt>
        <dd>
          <p>
            TOML already has implementations in most of the most popular programming languages in use
            today: C, C#, C++, Clojure, Dart, Elixir, Erlang, Go, Haskell, Java, Javascript, Lua,
            Objective-C, Perl, PHP, Python, Ruby, Swift, Scala...
            <a href="https://github.com/toml-lang/toml/wiki">and plenty more</a>.
          </p>
        </dd>
      </div>
    </dl>
  </section>

  <section>
    <header>
      <h2>
        A Quick Tour of TOML
      </h2>
    </header>

    <div>
      <div>
        <section>
          <div>
            <h3>Comments</h3>
            <p>TOML thinks all config files should support comments.</p>
          </div>

          <pre data-controller="snippet" data-snippet-copy="false"><code># This is a TOML comment

# This is a multiline
# TOML comment</code></pre>
        </section>

        <section>
          <div>
            <h3>Powerful Strings</h3>
            <p>
              There are four ways to express strings: basic, multi-line basic, literal, and
              multi-line literal. <span>Basic strings</span> are surrounded by
              quotation marks:
            </p>
          </div>

          <pre data-controller="snippet" data-snippet-copy="false"><code>str1 = "I'm a string."
str2 = "You can \"quote\" me."
str3 = "Name\tJos\u00E9\nLoc\tSF."</code></pre>

          <p>
            <span>Multi-line basic strings</span> Multi-line basic strings are
            surrounded by three quotation marks on each side and allow newlines. Include a line
            ending backslash to automatically trim whitespace preceeding any non-whitespace
            characters:
          </p>

          <pre data-controller="snippet" data-snippet-copy="false"><code>str1 = """
Roses are red
Violets are blue"""

str2 = """\
  The quick brown \
  fox jumps over \
  the lazy dog.\
  """</code></pre>

          <p>
            <code> str2</code> becomes
            <code>"The quick brown fox jumps over the lazy dog."</code>
            (a single sentence with no line breaks).
          </p>

          <p>
            <span> Literal strings</span> are surrounded by single quotes. No
            escaping is performed so what you see is what you get:
          </p>

          <pre data-controller="snippet" data-snippet-copy="false"><code>path = 'C:\Users\nodejs\templates'
path2 = '\\User\admin$\system32'
quoted = 'Tom "Dubs" Preston-Werner'
regex = '&lt;\i\c*\s*&gt;'</code></pre>

          <p>
            Since there is no escaping, there is no way to write a single quote inside a literal
            string enclosed by single quotes. That's where
            <span>multi-line literal strings</span> come in:
          </p>
          <pre data-controller="snippet" data-snippet-copy="false"><code>re = '''\d{2} apps is t[wo]o many'''
lines = '''
The first newline is
trimmed in raw strings.
All other whitespace
is preserved.
'''</code></pre>
        </section>
      </div>

      <div>
        <section>
          <div>
            <h3>Numbers</h3>
            <p>
              Integers, floats, infinity, and even NaN are all supported. You can use scientific
              notation and even thousands separators.
            </p>
          </div>

          <pre data-controller="snippet" data-snippet-copy="false"><code># integers
int1 = +99
int2 = 42
int3 = 0
int4 = -17

# hexadecimal with prefix `0x`
hex1 = 0xDEADBEEF
hex2 = 0xdeadbeef
hex3 = 0xdead_beef

# octal with prefix `0o`
oct1 = 0o01234567
oct2 = 0o755

# binary with prefix `0b`
bin1 = 0b11010110

# fractional
float1 = +1.0
float2 = 3.1415
float3 = -0.01

# exponent
float4 = 5e+22
float5 = 1e06
float6 = -2E-2

# both
float7 = 6.626e-34

# separators
float8 = 224_617.445_991_228

# infinity
infinite1 = inf # positive infinity
infinite2 = +inf # positive infinity
infinite3 = -inf # negative infinity

# not a number
not1 = nan
not2 = +nan
not3 = -nan </code></pre>
        </section>

        <section>
          <div>
            <h3>Dates and Times</h3>
            <p>
              TOML features support for dates, times, and datetimes with and without offsets.
            </p>
          </div>

          <pre data-controller="snippet" data-snippet-copy="false"><code>#offset datetime
odt1 = 1979-05-27T07:32:00Z
odt2 = 1979-05-27T00:32:00-07:00
odt3 = 1979-05-27T00:32:00.999999-07:00

# local datetime
ldt1 = 1979-05-27T07:32:00
ldt2 = 1979-05-27T00:32:00.999999

# local date
ld1 = 1979-05-27

# local time
lt1 = 07:32:00
lt2 = 00:32:00.999999</code></pre>
        </section>
      </div>
    </div>
  </section>

  <section>
    <div>
      <h3>More Spec</h3>
      <p>
        <strong>TOML</strong> supports even more native types and syntax, read all about it:
      </p>
      
    </div>

    <div>
      <h3>Start coding</h3>
      <p>
        <strong>TOML</strong> is already implemented in over 40 programming languages:
      </p>
      
    </div>
  </section>
</div></div>]]>
            </description>
            <link>https://toml.io/en/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24436550</guid>
            <pubDate>Thu, 10 Sep 2020 21:04:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Launch HN: Free HTML and CSS Coding Challenges]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24436516">thread link</a>) | @moeminm
<br/>
September 10, 2020 | https://moeminm.github.io/goodcode/?ref=hn | <a href="https://web.archive.org/web/*/https://moeminm.github.io/goodcode/?ref=hn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <nav>
                <a href="#"><img src="https://moeminm.github.io/goodcode/images/logo@2x.png"></a>
                
                
            </nav>

    <section>
        
        
    </section>  

    <section id="challenges">
        <!----Gourmet Card Start---->
        <div>
                <p>Free</p>
                <p><img src="https://moeminm.github.io/goodcode/images/jjo.png">
                </p>
                <div>
                    
                    <div>
                        <p>
                                Simple Job Board layout in Adobe XD. You'll learn a lot about grids and/or flex layouts as well as containers. Readme.md file included. Free.
                        </p>
                        </div>
                </div>
            </div>
        <!----Gourmet Card End---->
        <!----Gourmet Card Start----><div>
            <p>$5</p>
            <p><img src="https://moeminm.github.io/goodcode/images/gourmet.png">
            </p>
            <div>
                
                <div>
                    <p>
                            Practice your HTML and CSS skills with the high quality Gourmet Adobe XD template, includes mega menu. Readme.md file included. Costs $5.
                    </p>
                    </div>
            </div>
        </div>
            <!----Gourmet Card End---->
            <!----Gourmet Card Start---->
        <div>
                <p>Free</p>
                <p><img src="https://moeminm.github.io/goodcode/images/apt.png">
                </p>
                <div>
                    
                    <div>
                        <p>
                                Amazon Price Tracker. Lots of great layout challenges with various components and pages (and graphs!). Readme.md file included. Free.
                        </p>
                        </div>
                </div>
            </div>
            <!----Gourmet Card End---->
            <!----Gourmet Card Start---->
        <div>
                <p>Free</p>
                <p><img src="https://moeminm.github.io/goodcode/images/inv.png">
                </p>
                <div>
                    
                    <div>
                        <p>
                                Practice your HTML and CSS skills with the Invitation Adobe XD template. 3 column grid practice (or flex). Readme.md file included. Free.
                        </p>
                        </div>
                </div>
            </div>
            <!----Gourmet Card End---->
            <!----Gourmet Card Start---->
        <div>
            <p>Free</p>
            <p><img src="https://moeminm.github.io/goodcode/images/ppt.png">
            </p>
            <div>
                
                <div>
                    <p>
                            Simple pricing page, 3 column grid, easy to implement, modern and simple. Readme.md file included. Absolutely free of charge.
                    </p>
                    </div>
            </div>
        </div>
        <!----Gourmet Card End---->
<!----Gourmet Card Start---->
<div>
    <p>Free</p>
    <p><img src="https://moeminm.github.io/goodcode/images/signtemplate.png">
    </p>
    <div>
        
        <div>
            <p>
                    Simple sign up page, 2 column grid, easy to implement, modern and simple. Readme.md file included. Absolutely free of charge.
            </p>
            </div>
    </div>
</div>
<!----Gourmet Card End---->

    </section>

    

    

</div></div>]]>
            </description>
            <link>https://moeminm.github.io/goodcode/?ref=hn</link>
            <guid isPermaLink="false">hacker-news-small-sites-24436516</guid>
            <pubDate>Thu, 10 Sep 2020 20:59:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The rules of consensus algorithms inspired by scaling YouTube]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24436511">thread link</a>) | @sougou
<br/>
September 10, 2020 | https://www.planetscale.com/blog/blog-series-consensus-algorithms-at-scale-part-2 | <a href="https://web.archive.org/web/*/https://www.planetscale.com/blog/blog-series-consensus-algorithms-at-scale-part-2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><div><figure id="w-node-5c27f10a08a3-ca993012"><p><img src="https://assets-global.website-files.com/5ef5a4d4da0d67ccda9b5588/5f5716b58fafa451fe431853_blog-headers-consensus-04.jpg" loading="lazy" alt=""></p></figure><p>Read <a href="https://www.planetscale.com/blog/blog-series-consensus-algorithms-at-scale-1">Consensus Algorithms at Scale - Part 1</a></p><h2>The Rules of Consensus</h2><h4>YouTube Scale</h4><p>When we were running <a href="https://vitess.io/">Vitess</a> at YouTube, there were tens of thousands of nodes serving very high QPS. The scale out was in all dimensions: some of the shards had over fifty replicas. The topology was complicated with these nodes being spread out across multiple data centers. To make this work, we had to strike a balance between latency, availability and durability. To meet these requirements, we used to perform regular failovers that were mostly automated. I am happy to say we never lost data due to hardware failure.</p><p>The first time we heard about Paxos, it sounded magical: an algorithm that will dynamically elect a leader to ensure that all requests are fulfilled without errors, divergence, or data loss. The Vitess failovers used to take a few seconds, and we wanted to avoid serving errors during this period.</p><p>We started to evaluate Paxos to see if it could be retrofitted into Vitess. We quickly found that our quorum sizes would have been too big for a majority based algorithm. Also, the MySQL replication mechanism didn’t look anything like the durability mechanism Paxos was describing. Our only option was to do a gap analysis between the two systems. In a way, this is what led to the discovery of <a href="https://www.sougou.io/a-more-flexible-paxos/">FlexPaxos</a>: an additional knob that allows you to achieve a more meaningful performance vs. safety trade-off.</p><p>There were other differences: our failover algorithms did not look anything like what Paxos recommends. Studying how the two systems differed led to the discovery of a common set of principles that any leader-based system can follow to guarantee correctness and safety. We will cover these rules in this blog post.</p><figure id="w-node-62fc8f365de2-ca993012"><p><img src="https://assets-global.website-files.com/5ef5a4d4da0d67ccda9b5588/5f57e95a9f68ce38d9f47839_Screen%20Shot%202020-09-08%20at%2012.56.55%20PM.png" loading="lazy" alt=""></p></figure><h4>Why Consensus</h4><p>We are focused on using Consensus to address durability at scale. It is possible that there are other use cases, but we are not concerned about those.<br></p><p>No system can give you absolute durability guarantees; there is always the possibility of a catastrophic failure that is bigger than anticipated. You must decide the level of failure tolerance you want. This depends on the reliability of the resources and the criticality of the data. In other words, durability requirements are use-case dependent.<br></p><p>To accommodate all possible use cases, we will treat durability as an abstract requirement. The algorithms must be agnostic of these requirements, and should be able to accommodate arbitrarily complex rules. This changes the way we approach the problem, and we will go through this exercise in the following sections.</p><h4>Single Value Behavior</h4><p>Paraphrasing the definition from Paxos: the primary guarantee we want from a consensus system is that it must not forget a value it has acknowledged as accepted. Once a value is accepted, all other values must be rejected.</p><p>When asked to accept a single value, the operation would have one of the three following outcomes:<br></p><ol role="list"><li>Accepted: the value was successfully accepted.</li><li>Rejected: the value was rejected.</li><li>Failed: the operation did not succeed, but may succeed later.<br></li></ol><p>If the first request was Accepted, then any subsequent attempts to write a different value will be Rejected.<br></p><p>If the first request was Rejected, it likely means that a previous value was accepted before our “first” attempt. In this case, subsequent requests will also be Rejected.<br></p><p>If the first request Failed and a second request is made, the system can choose to finalize either of the requests as Accepted, but not both. Since the second request can also Fail, we need to restate this more generally: the system can choose to Accept any previously requested values as final. Pathological failure modes can cause the system to remain in the Failed state indefinitely. But it is generally expected to converge eventually.</p><h4>In Practice</h4><p>It is not very practical for a system to just accept a single value. Instead, let us see what should happen if we changed the specifications to a system that accepts a series of values, which is what storage systems typically do.<br></p><p>If a system first accepts a value v1, and later receives a request for v2, it must record v2 as having happened after v1. The more significant property is the following: If the request for v1 failed because the system was not able to meet the durability requirements, then a request for v2 requires the system to make a final decision on whether v1 should be completed or rejected. If completed, it will record v2 after v1. Otherwise, v1 is discarded and v2 will be the only accepted value.<br></p><p>Raft understood this, which is why they describe their system as a way to achieve consistent log replication.<br></p><p>In our case, we will think in terms of requests rather than values, which can be any operation a storage system may have to perform. It could be a transaction, or setting the value for a key, or any other atomic operation.<br></p><p>Let us restate: The purpose of a consensus system is to accept a series of requests in a strict order and keep them consistent across multiple nodes.</p><h4>Single Leader</h4><p>To limit complexity and scope, we are going to stick to single leader designs. The popular implementations that I know use the single leader approach. There is research on leaderless and multi-leader algorithms. But I am not very familiar with them.<br>‍</p><figure id="w-node-75b056f4f908-ca993012"><p><img src="https://assets-global.website-files.com/5ef5a4d4da0d67ccda9b5588/5f59058ba01bf11722847f12_leader-yin-yang-01.png" loading="lazy" alt=""></p></figure><p>‍<br>‍<br>A Single Leader consensus system is a combination of two workflows that cooperate with each other:</p><ol role="list"><li>A leader accepts requests and makes them durable.</li><li>A new leader can be elected to resume requests without divergence or loss of data.<br></li></ol><p>Paxos and Raft also use the single leader approach.</p><h4>The Rules</h4><p>Now that we have spent enough time building up the premise, it is time to codify the rules governing a consensus system:.</p><div><ol>
<li>A Leader’s job is to fulfill requests by satisfying the mandated durability requirements.
</li><li>To elect a new Leader, the following actions must be performed:
  <ul>
    <li>Terminate the previous Leadership, if any.</li>
    <li>Recruit the necessary nodes for the new Leader.</li>
    <li>Propagate previously completed requests to satisfy the new Leader’s durability requirements. </li>       
    </ul>
</li><li>Forward Progress: If a Leader election fails, a subsequent re-attempt should have a path to success, where a new Leader can be elected without breaking the durability and safety guarantees.</li>
<li>Race: If concurrent attempts are being made to elect a Leader, at most one Leader must prevail.</li>
</ol></div><p>Rules 3 &amp; 4 are actually implicit in rule number 2. But these properties are so important that it’s worth making them explicit.<br></p><p>These rules are intentionally generic to allow for creativity in achieving these goals. In fact, being more specific than this will exclude some valid implementations. However, we will show multiple ways to satisfy these rules. We will also validate the existing popular algorithms against these new set of rules.<br></p><p>You will notice the following differences:</p><ul role="list"><li>No mention of a majority quorum.</li><li>No mention of intersection of nodes.</li><li>No proposal numbers.<br></li></ul><p>This is where we deviate from traditional systems because we believe these are not strictly required for a consensus system to operate correctly. For example, you can build a consensus system with fifty nodes, but still only have a quorum size of two. There is no need for these quorums to intersect across leaders. As for proposal numbers, very few understand why they are even needed. It is better to discuss what we are trying to achieve, and then introduce proposal numbers as one option, and maybe consider alternatives that don’t involve proposal numbers. We will drill down into each of these properties and explore trade-offs between multiple approaches.<br></p><p>In the next post, we will cover some practical use cases that this generalized set of rules allows us to cover. We will also drill deeper into the meaning and significance of these rules.</p></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.planetscale.com/blog/blog-series-consensus-algorithms-at-scale-part-2</link>
            <guid isPermaLink="false">hacker-news-small-sites-24436511</guid>
            <pubDate>Thu, 10 Sep 2020 20:59:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why FTL implies time travel (2016)]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24436505">thread link</a>) | @ladberg
<br/>
September 10, 2020 | http://www.physicsmatt.com/blog/2016/8/25/why-ftl-implies-time-travel | <a href="https://web.archive.org/web/*/http://www.physicsmatt.com/blog/2016/8/25/why-ftl-implies-time-travel">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-layout-label="Post Body" data-type="item" data-updated-on="1472176981274" id="item-57bfa321893fc0f1d1be57f7"><div><div><div data-block-type="2" id="block-54e4d00eca7f73d32497"><div><p>In science fiction, it is pretty standard fare to introduce some form of faster-than-light communication or travel. After all, space is big, and you can't write your swashbuckling Hornblower-in-space novel if you have to wait for a generation ship to crawl painfully slowly between the nearest stars, much less try to cross a galaxy.</p><p>However, faster-than-light communication (which includes travel) breaks something very fundamental about physics, something that is often ignored by sci-fi, and difficult for non-physicists to understand. If you allow faster-than-light (FTL), then you break causality: you are allowing time-travel. One pithy way of saying this is:</p><p>Pick two:</p><ul><li>Relativity</li><li>Causality</li><li>FTL</li></ul><p>The Universe has picked relativity and causality, it seems. Thus, we cannot travel or communicate faster than light.&nbsp;</p></div></div><div data-block-type="5" id="block-yui_3_17_2_5_1472176913301_15584"><div>







 

  
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472177316237-IEW52C3ICC42CPAM1IMG/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/image-asset.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472177316237-IEW52C3ICC42CPAM1IMG/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/image-asset.jpeg" data-image-dimensions="2048x1536" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="57bfa4a303596e3a2ae8799b" data-type="image" src="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472177316237-IEW52C3ICC42CPAM1IMG/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/image-asset.jpeg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  



</div></div><div data-block-type="2" id="block-yui_3_17_2_5_1472176913301_16992"><div><p>But why is this? Why does FTL imply time travel. To demonstrate this, it's handy to draw some diagrams. We're going to work with "spacetime diagrams." They look like this:</p><p>Here I'm trying to draw all four dimensions of the Universe: three space and one time. Now, I can't draw four dimensions. I can't even really draw three (it's a 2D screen, after all). So I've suppressed two space dimensions, drawing all of space as just a line. It won't matter much for what I'm trying to do, but it's good to keep that in mind.</p><p>With that in mind, I'm showing here <em>my </em>spacetime diagram: I'm stationary at the center, and so I see time tick forward "orthogonal" (perpendicular) to the space directions around me. As you'll see, other people have different spacetime diagrams, and different time and space axes, relative to me. That's the point of relativity, after all.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_5_1472176913301_21377"><div>







 

  
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472177593517-NTXFTAXJ7Q4WAPV0Q6ST/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/image-asset.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472177593517-NTXFTAXJ7Q4WAPV0Q6ST/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/image-asset.jpeg" data-image-dimensions="2048x1536" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="57bfa5b9ff7c50b7ffbc5576" data-type="image" src="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472177593517-NTXFTAXJ7Q4WAPV0Q6ST/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/image-asset.jpeg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  



</div></div><div data-block-type="2" id="block-yui_3_17_2_5_1472176913301_22820"><div><p>The special thing about relativity is that <em>everyone measures the speed of light to be the same</em>. We show this in a spacetime diagram by saying that every spacetime diagram has light traveling at 45 degrees relative to the time axis. Light travels on lines that are called "null."</p><p>Here I'm showing the null lines of light emitted from an event at the time I'm calling <em>t=0</em>&nbsp;(when the time and space axis cross). Remember I'm suppressing most of the space dimensions: these rays of light are really emanating out in a sphere around me. Because light travels at 45 degrees, anything traveling slower than light from this <em>t=0</em>&nbsp;event is closer to the time axis than the light rays, and anything faster than light is further away from the time axis.</p><p>The light rays define the <em>future lightcone</em>. This is the set of spacetime events that can perceive the event at <em>t=0,</em>&nbsp;and so, in a Universe without FTL, all the events that can be affected by whatever happened at this event at <em>t=0.&nbsp;</em>There is also a past lightcone, which would be the 45 degree lines extending backwards in time from the event: in a Universe without FTL this defines all the events that could have effected that <em>t=0</em>&nbsp;event, because the light (and thus things moving slower than light)&nbsp;from those other events had time to reach the <em>t=0</em>&nbsp;event.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_5_1472176913301_40995"><div><p>So now let me move from general spacetime diagrams to an example that will indicate why FTL implies time travel. Let's consider a specific example: Let's say we on Earth have built a FTL communication device that let's us talk to the inhabitants of the planet Proxima Centauri B, 4.25 lightyears away. Again, this is what a FTL and slower-than-light set of communications would appear like in a spacetime diagram.</p><p>Critically, I've drawn the time axis for the Proximal Centaurians parallel to our own time. This is because Proxima Centauri is moving at essentially the same velocity as Earth (the differences are small compared to the speed of light). Thus, there are no big relativistic effects between our counting of time and the Proximal Centaurians.&nbsp;</p><p>Now, let's imagine that some event occurs away from Earth, oriented in such a way that the light from the event hits us before it reaches Proxima Centauri. The spacetime diagram for that would look like what I've shown. First we see the light, then the light reaches Proxima Centauri. Notice I've drawn the light rays from the event traveling at 45 degrees to my time axis. After all, it is light, and light travels at 45 degrees on spacetime diagrams.</p></div></div><div data-block-json="{&quot;existingGallery&quot;:null,&quot;hSize&quot;:null,&quot;show-meta-only-title&quot;:false,&quot;floatDir&quot;:null,&quot;methodOption&quot;:&quot;transient&quot;,&quot;design&quot;:&quot;grid&quot;,&quot;aspectRatio&quot;:null,&quot;square-thumbs&quot;:false,&quot;aspect-ratio&quot;:&quot;square&quot;,&quot;thumbnails-per-row&quot;:2,&quot;padding&quot;:5,&quot;lightbox&quot;:false,&quot;collectionId&quot;:&quot;57bfa8b3f5e2312269858e10&quot;,&quot;vSize&quot;:null,&quot;transientGalleryId&quot;:&quot;57bfa8b3f5e2312269858e10&quot;}" data-block-type="8" id="block-yui_3_17_2_5_1472176913301_57296"><div>




  

  


<div>
  <div>
    
      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <p><a role="presentation">
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472178356455-JKIIS3FT0GDGQQGL4R6P/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/IMG_0006.jpg" data-image="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472178356455-JKIIS3FT0GDGQQGL4R6P/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/IMG_0006.jpg" data-image-dimensions="2048x1536" data-image-focal-point="0.5,0.5" alt="IMG_0006.jpg" data-load="false" data-image-id="57bfa8b4f5e2312269858e11" data-type="image" src="http://www.physicsmatt.com/blog/2016/8/25/IMG_0006.jpg">
                </a>
                
              </p>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <p><a role="presentation">
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472178356571-YYGOMQAKCBON7C6CLUEJ/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/IMG_0007.jpg" data-image="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472178356571-YYGOMQAKCBON7C6CLUEJ/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/IMG_0007.jpg" data-image-dimensions="2048x1536" data-image-focal-point="0.5,0.5" alt="IMG_0007.jpg" data-load="false" data-image-id="57bfa8b4d2b8577fd265d1a2" data-type="image" src="http://www.physicsmatt.com/blog/2016/8/25/IMG_0007.jpg">
                </a>
                
              </p>
            </div>
          

          
        

      
    
  </div>

  

</div>








</div></div><div data-block-type="5" id="block-yui_3_17_2_5_1472176913301_62520"><div>







 

  
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472178540018-4KDK5JVY0JSFA4JP0998/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/image-asset.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472178540018-4KDK5JVY0JSFA4JP0998/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/image-asset.jpeg" data-image-dimensions="2048x1536" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="57bfa96be58c629eb4d4f155" data-type="image" src="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472178540018-4KDK5JVY0JSFA4JP0998/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/image-asset.jpeg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  



</div></div><div data-block-type="2" id="block-yui_3_17_2_5_1472176913301_61723"><div><p>So, now, let's add in FTL communication. We see the event, we get on the FTL phone, and we tell the Proximal Centaurians. They get the phone call, and now have years to prepare for the arrival of the light from whatever the event is (let's say it's a supernovae, or the launch of relativistic attack vehicles. We are playing with sci-fi tropes here).</p><p>Now, this is the image most people have of FTL communication. There appears to be no problem: we all agree that the event happened "first," then Earth calls Proxima Centauri, then the light reaches Proxima Centauri. No problem: though the Proximal Centaurians hear about the event "early," no causality has been violated. After all, we all agree on what happened first, don't we? No effect precedes its cause.</p><p>Right?</p></div></div><div data-block-type="5" id="block-yui_3_17_2_5_1472176913301_81533"><div>







 

  
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472178941031-RKS433C6DG08CZ9EE2PC/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/image-asset.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472178941031-RKS433C6DG08CZ9EE2PC/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/image-asset.jpeg" data-image-dimensions="2048x1536" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="57bfaafabebafba38dd12b9e" data-type="image" src="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472178941031-RKS433C6DG08CZ9EE2PC/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/image-asset.jpeg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  



</div></div><div data-block-type="2" id="block-yui_3_17_2_5_1472176913301_67814"><div><p>But we've forgotten relativity. This only works when everyone is moving in the same frame of reference, like us and Proxima Centauri (really we're not in the same rest frame, but its close enough not to matter). So, to see the problem, let's add a new observer, moving at high speeds relative to Earth and Proxima Centauri. It's sci-fi, so we add a relativistic spaceship. It's moving with <em>v&lt;c</em>&nbsp;but <em>v&gt;&gt;0</em>, so it's trajectory on my spacetime diagram is highly skewed relative to my time axis: it's nearly moving at the speed of light.</p><p>Here's where the relativistic effects start coming into play. Relativity tells us that everyone moving with constant velocity is totally justified in saying they are stationary. Thus, we think we're stationary (ignore the rotation of the Earth, or its orbit around the Sun). The Proximal Centaurians think they're at rest. The people on the relativistic spaceship think they are at rest. So they can draw their spacetime diagram, with their own time axis. That time axis, like mine, is always where they are: on the ship. So I think their time axis is aligned with the ship trajectory.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_5_1472176913301_80257"><div>







 

  
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472178905725-BMV6CIVK52NIILG1PZN5/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/image-asset.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472178905725-BMV6CIVK52NIILG1PZN5/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/image-asset.jpeg" data-image-dimensions="2048x1536" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="57bfaad9bebafba38dd12a22" data-type="image" src="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472178905725-BMV6CIVK52NIILG1PZN5/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/image-asset.jpeg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  



</div></div><div data-block-type="2" id="block-yui_3_17_2_5_1472176913301_86207"><div><p>In addition, they have a space-axis, just like I do. Relativity mixes up space and time, so their space axis I perceive as slanted - just like their time axis is skewed. It turns out that the space axis is flipped across the 45 degree null line, but I'm not going to prove that. This weird mixture of space and time of observers I perceive as moving is a necessary part of relativity. It is the <em>only </em>way everyone can agree that light moves at <em>c</em>.&nbsp;</p><p>Now, if I wanted to, I could draw the spacetime diagram of the spaceship in its frame of reference. It would have othogonal space and time axes, the light from the event would travel at 45 degree,&nbsp;and they would see Earth's axes highly skewed (pointing toward the left if I kept the same orientation as in this set of diagrams). That's relativity. But we will not draw that diagram here, as it's not necessary for the story.</p><p>So what happens now. Let's ask <em>when </em>the spaceship sees the various events in this diagram. To do that, we need to know the lines of constant time for the ship. That's not too hard: lines of constant time for us are lines in the spacetime diagram parallel to the space axis. So it is for the spaceship. Their lines of constant time look like this:</p></div></div><div data-block-json="{&quot;existingGallery&quot;:null,&quot;hSize&quot;:null,&quot;show-meta-only-title&quot;:false,&quot;floatDir&quot;:null,&quot;methodOption&quot;:&quot;transient&quot;,&quot;design&quot;:&quot;grid&quot;,&quot;aspectRatio&quot;:null,&quot;square-thumbs&quot;:false,&quot;aspect-ratio&quot;:&quot;square&quot;,&quot;thumbnails-per-row&quot;:2,&quot;padding&quot;:5,&quot;lightbox&quot;:false,&quot;collectionId&quot;:&quot;57bfacb4d2b8577fd265f253&quot;,&quot;vSize&quot;:null,&quot;transientGalleryId&quot;:&quot;57bfacb4d2b8577fd265f253&quot;}" data-block-type="8" id="block-yui_3_17_2_5_1472176913301_90063"><div>




  

  


<div>
  <div>
    
      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <p><a role="presentation">
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472179381264-LQVTY7AMG7NSFAUT3YHB/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/IMG_0011.jpg" data-image="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472179381264-LQVTY7AMG7NSFAUT3YHB/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/IMG_0011.jpg" data-image-dimensions="2048x1536" data-image-focal-point="0.5,0.5" alt="IMG_0011.jpg" data-load="false" data-image-id="57bfacb4d2b8577fd265f254" data-type="image" src="http://www.physicsmatt.com/blog/2016/8/25/IMG_0011.jpg">
                </a>
                
              </p>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <p><a role="presentation">
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472179381312-NBGI7FFKM480NJ32EQET/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/IMG_0012.jpg" data-image="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472179381312-NBGI7FFKM480NJ32EQET/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/IMG_0012.jpg" data-image-dimensions="2048x1536" data-image-focal-point="0.5,0.5" alt="IMG_0012.jpg" data-load="false" data-image-id="57bfacb437c5819eacebc0b2" data-type="image" src="http://www.physicsmatt.com/blog/2016/8/25/IMG_0012.jpg">
                </a>
                
              </p>
            </div>
          

          
        

      
    
  </div>

  

</div>








</div></div><div data-block-type="2" id="block-yui_3_17_2_5_1472176913301_91421"><div><p>Now do you see the problem?</p><p>According to us, on Earth, the order of events is thus: we see the light from the event hit us. We call Proxima Centauri on the FTL phone. The Proximal Centaurians do whatever they want to do in response to that call, and then they see the light of the event.&nbsp;</p><p>What does the ship see? They see the phone call received on Proxima Centauri.&nbsp;<em>Then</em>&nbsp;they see the phone call placed from Earth. Effect precedes cause: causality is violated. In fact, if the ship had a FTL phone set up in the right way, they could call Earth <em>before</em>&nbsp;Earth placed the call. They could even tell Earth "hey, don't make that call to Proxima Centauri we just saw you make." Then what?</p></div></div><div data-block-type="5" id="block-yui_3_17_2_5_1472176913301_110431"><div>







 

  
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
    …</figure></div></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.physicsmatt.com/blog/2016/8/25/why-ftl-implies-time-travel">http://www.physicsmatt.com/blog/2016/8/25/why-ftl-implies-time-travel</a></em></p>]]>
            </description>
            <link>http://www.physicsmatt.com/blog/2016/8/25/why-ftl-implies-time-travel</link>
            <guid isPermaLink="false">hacker-news-small-sites-24436505</guid>
            <pubDate>Thu, 10 Sep 2020 20:58:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Corona Cases in Boulder Surge]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24436156">thread link</a>) | @tomger
<br/>
September 10, 2020 | https://covid.iterator.us/region/us-co-boulder-colorado | <a href="https://web.archive.org/web/*/https://covid.iterator.us/region/us-co-boulder-colorado">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://covid.iterator.us/region/us-co-boulder-colorado</link>
            <guid isPermaLink="false">hacker-news-small-sites-24436156</guid>
            <pubDate>Thu, 10 Sep 2020 20:18:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Open Source GIS – An Interactive Infographic]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24435582">thread link</a>) | @Pablo1856
<br/>
September 10, 2020 | https://makepath.com/history-of-open-source-gis/ | <a href="https://web.archive.org/web/*/https://makepath.com/history-of-open-source-gis/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


			
<section><div>
<p>GIS (Geographic Information Systems) technology is a powerful way to understand our world. Thanks to the open source community, the public today has access to excellent analysis tools, and many of them are free!</p>



<p>makepath is a proud contributor to many <a href="https://makepath.com/open-source-spatial-analysis-tools-a-quick-guide/" target="_blank" rel="noreferrer noopener">open source spatial analysis projects</a>. Through this piece, we want to honor and highlight the contributors that have made it possible for <a href="https://opensource.com/tags/gis-and-maps" target="_blank" rel="noreferrer noopener">open source GIS</a> to grow and flourish.</p>



<p><strong>This is an interactive piece.</strong> You can click on the name of a library to see details and anecdotes directly from the creators themselves.</p>



<p><strong>This is an open source infographic.</strong> If you have ideas, contributions, or additional libraries you would like included, we have set up a <a rel="noreferrer noopener" href="https://github.com/makepath/open-source-gis-infographic" target="_blank">GitHub page</a> for this timeline. With a nod to our favorite programming language, <a rel="noreferrer noopener" href="https://www.python.org/" target="_blank">Python</a>, take a journey down our timeline to follow the ever evolving story of open source GIS!</p>




</div></section>
<!-- relpost-thumb-wrapper --><!-- close relpost-thumb-wrapper --><!-- Developer mode initialisation; Version: 1.2.9;Relation: categories; All categories: 1;Found 3 posts;Basic sizes;Got sizes 200x150;Post-thumbnails enabled in theme;Post has thumbnail 763;Postthname: thumbnail;Using title with size 25. Using excerpt with size 0;Post-thumbnails enabled in theme;Post has thumbnail 772;Postthname: thumbnail;Using title with size 25. Using excerpt with size 0;Post-thumbnails enabled in theme;Post has thumbnail 289;Postthname: thumbnail;Using title with size 25. Using excerpt with size 0;Plugin execution time: 0.006882905960083 sec; -->		</div></div>]]>
            </description>
            <link>https://makepath.com/history-of-open-source-gis/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24435582</guid>
            <pubDate>Thu, 10 Sep 2020 19:17:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Docker for Data Science – A Step by Step Guide]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24435478">thread link</a>) | @Dean-DAGsHub
<br/>
September 10, 2020 | https://dagshub.com/blog/setting-up-data-science-workspace-with-docker/ | <a href="https://web.archive.org/web/*/https://dagshub.com/blog/setting-up-data-science-workspace-with-docker/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              
              <h3 id="by-the-end-of-this-post-you-will-have-a-ml-workspace-running-on-your-machine-via-docker-packed-with-the-ml-libraries-you-need-vscode-jupyter-lab-hub-and-a-lot-of-other-goodies-">By the end of this post, you will have a ML workspace running on your machine via Docker, packed with the ML libraries you need, VSCode, Jupyter Lab + Hub and a lot of other goodies.</h3><p><a href="https://towardsdatascience.com/how-docker-can-help-you-become-a-more-effective-data-scientist-7fc048ef91d5">A lot</a> <a href="https://mlinproduction.com/docker-for-ml-part-1/">has already</a> <a href="https://towardsdatascience.com/learn-enough-docker-to-be-useful-b7ba70caeb4b">been said</a> about why Docker can improve your life as a data scientist. I was working on an (un-)cool depth estimation project using <a href="https://fast.ai/">Fast.ai</a> with a few friends when I stumbled upon this tweet by <a href="https://twitter.com/jeremyphoward">@jeremyphoward</a>.</p><figure><blockquote data-width="550"><div lang="en" dir="ltr"><p>How do you ensure you don't accidentally stop your image without committing, and losing all your changes? Do you use mounts? How do you keep your environment up to date (e.g CUDA updates, python lib updates, etc)?</p><p>Has anyone written a simple step-by-step guide to all this?</p></div>— Jeremy Howard (@jeremyphoward) <a href="https://twitter.com/jeremyphoward/status/1298464400332828675?ref_src=twsrc%5Etfw">August 26, 2020</a></blockquote>

<figcaption>The tweet that started this post</figcaption></figure><p>It so happens that we were using Docker to create our data science workspace for the project, so I thought it would make sense to address Jeremy's questions and share this knowledge with the community.</p><p>I'll very briefly review the core concepts and advantages of Docker, and then show a step-by-step example for setting up an entire data science workspace using Docker.</p><p>If you already know what Docker is and why it's awesome, skip to the <a href="https://dagshub.com/blog/p/25636bb0-204d-4449-9a8d-5e5e20c8c100/need%20to%20add%20the%20link">step-by-step tutorial</a>.</p><h2 id="what-is-docker">What is Docker?</h2><p>Docker is a tool for creating and deploying isolated environments (read: virtual machines) for running applications with their dependencies. </p><p>A few terms you should be familiar with (including a baking analogy for ease of understanding):</p><ul><li><strong><em>Docker Container</em></strong> – A single instance of the application, that is live and running. In our analogy, this is a cookie.</li></ul><!--kg-card-begin: html--><center></center><center><small>A Dancing Cookie. <a href="https://giphy.com/gifs/cookie-dancing-1ngQorBCDcUFy">GIPHY</a></small></center><!--kg-card-end: html--><ul><li><strong><em>Docker Image </em></strong>– A blueprint for creating containers. Images are immutable and all containers created from the same image are exactly alike. In our analogy this is the cookie cutter mould.</li></ul><figure><img src="https://images.unsplash.com/photo-1576476933288-ced9af98eb32?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ" alt="" srcset="https://images.unsplash.com/photo-1576476933288-ced9af98eb32?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=600&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 600w, https://images.unsplash.com/photo-1576476933288-ced9af98eb32?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=1000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 1000w, https://images.unsplash.com/photo-1576476933288-ced9af98eb32?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=1600&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 1600w, https://images.unsplash.com/photo-1576476933288-ced9af98eb32?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2400&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 2400w" sizes="(min-width: 720px) 720px"><figcaption>Cookie Cutters. <a href="https://unsplash.com/@belleam?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Izabelle Acheson</a> / <a href="https://unsplash.com/?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Unsplash</a></figcaption></figure><ul><li><strong><em>Dockerfile</em></strong> – A text file containing a list of commands to call when creating a Docker Image. In our analogy this is the <strong>instructions to create the cookie cutter mould</strong>.</li></ul><!--kg-card-begin: html--><center></center>
<center><small>Making Cookie Cutters. <a href="https://giphy.com/gifs/3ixS2QB5lWmGCcJkqI">GIPHY</a></small></center><!--kg-card-end: html--><h2 id="why-as-a-data-scientist-should-i-care">Why (as a data scientist) should I care?</h2><p>Broadly, there are two use cases for Docker in ML:</p><ul><li><strong><em>Run Only</em></strong>:<strong> </strong>A run-only container means you edit your code on a local IDE and run it with the container so that your code runs inside the container. <a href="https://github.com/anibali/docker-pytorch">Here is one good example.</a></li><li><strong><em>End-to-End Platform</em></strong>:<strong> </strong>An end-to-end platform container means you have an IDE or Jupyter Notebook / Lab, and your entire working environment, running in the container, and also run the code inside it (with the exception of the working file system which can be mounted).</li></ul><p>We will focus on the second use case.</p><h3 id="reasons-to-use-docker-in-data-science-projects">Reasons to use Docker in data science projects</h3><blockquote><strong>Using docker containers means you don't have to deal with "works on my machine" problems.</strong></blockquote><p>Generally, the main advantage Docker provides is standardization. This means you can define the parameters of your container once, and run it wherever Docker is installed. This in turn provides two major advantages:</p><ol><li><em><strong>Reproducibility:</strong></em> Everyone has the same OS, the same versions of tools etc. This means you don't need to deal with "works on my machine" problems. If it works on your machine, it works on everyone's machine.</li><li><em><strong>Portability:</strong></em> This means that moving from local development to a super-computing cluster is easy. Also, if you're working on open source data science projects, like we do at DAGsHub, you can <em><strong>provide collaborators with an easy way to bypass setup hassle</strong></em>.</li></ol><p>Another <strong>huge advantage</strong> – learning to use Docker will make you a better engineer, or turn you into a data scientist with super powers. Many systems rely on Docker, and it will help you turn your ML projects into applications and deploy models into production.</p><h2 id="examples-of-data-science-oriented-docker-containers">Examples of data science oriented docker containers</h2><!--kg-card-begin: markdown--><ul>
<li><a href="https://hub.docker.com/r/pytorch/pytorch">pytorch/pytorch</a> - a simple container for Use Case 1 that includes Pytorch</li>
<li><a href="https://hub.docker.com/r/jupyter/scipy-notebook">jupyter/scipy-notebook</a> - A container for Use Case 2 that includes Jupyter as the UI, and many python <a href="https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html#jupyter-scipy-notebook">data science modules</a>.</li>
<li><a href="https://hub.docker.com/repository/docker/dagshub/ml-workspace-minimal">DAGsHub/ml-workspace-minimal</a> - Is the container I'll show the step-by-step guide on. This container is an updated version from the <a href="https://github.com/ml-tooling/ml-workspace">ml-tooling/ml-workspace repository</a>. The original has not been maintained for the last 7 months so I created an up to date version. It combines the following tools:
<ul>
<li>💫 Jupyter, JupyterLab</li>
<li>👾 VSCode web-based IDE.</li>
<li>🗃 Pytorch, Tensorflow, Sklearn, Pandas, and many other popular data science libraries &amp; tools.</li>
<li>🖥 Full Linux desktop GUI accessible via web browser.</li>
<li>🎮 Easy terminal access via web browser.</li>
<li>🔀 Seamless Git integration optimized for notebooks.</li>
<li>📈 Integrated hardware &amp; training monitoring via Tensorboard &amp; Netdata.</li>
<li>🚪 Access from anywhere via Web, SSH, or VNC under a single port.</li>
<li>🎛 Usable as remote kernel (Jupyter) or remote machine (VSCode) via SSH.</li>
<li>🐳 Easy to deploy on Mac, Linux, and Windows via Docker.</li>
</ul>
</li>
</ul>
<!--kg-card-end: markdown--><p><strong>Sounds wonderful, right?! Now let's see how to set it up.</strong></p><h2 id="setting-up-your-data-science-docker-container-a-step-by-step-guide">Setting up your data science docker container - a step by step guide</h2><h3 id="install-docker">Install Docker</h3><p>Installing Docker is easy and free. Just follow <a href="https://docs.docker.com/engine/install/">this guide</a> for your operation system.</p><h3 id="building-a-docker-image">Building A Docker Image</h3><p>Will not be covered in this tutorial. Our focus will be on how to run a Docker Container once we already have the image we want.</p><p>We will use a prebuilt image from <a href="https://hub.docker.com/repository/docker/dagshub/ml-workspace-minimal">DAGsHub/ml-workspace-minimal</a>. It is created from this <a href="https://github.com/DAGsHub/ml-workspace">repository</a> on GitHub. If you want to build or modify this image or any other, I recommend <a href="https://towardsdatascience.com/how-docker-can-help-you-become-a-more-effective-data-scientist-7fc048ef91d5">the article</a> Jeremy Howard refers to in his original tweet. </p><h3 id="docker-run-addressing-all-the-special-modifiers">Docker Run + Addressing all the special modifiers</h3><p>Just run the following command:</p><pre><code>docker run -d \
    -v "${PWD}:/workspace" \
    -p 8080:8080 \
    --name "ml-workspace" \
    --env AUTHENTICATE_VIA_JUPYTER="mytoken" \
    --shm-size 2g \
    --restart always \
    dagshub/ml-workspace:latest</code></pre><p><code>docker run</code> is the command that takes a Docker Image (cookie cutter) and creates a container from it. In our analogy, this is the step where you make the cookie.</p><p>This long command might look scary, but we can think of all these flags as toppings for our cookie (chocolate chips and macademia nuts 😋). Here is an explanation of the various flags and why you need them:</p><h4 id="mounting-your-working-file-system-v-pwd-workspace">Mounting your working file system <code>-v "${PWD}:/workspace"</code></h4><p><u>This might be the most important flag of all.</u> It allows you to retain your work (files) after the container shuts down, and to access them from outside the container. </p><p><strong>It does this by mapping your current working folder (where you execute the <code>docker run</code> command), denoted as <code>${PWD}</code>, &nbsp;to a <code>/workspace</code> folder inside the container's virtual file system</strong>. If you'd like to change that, you can change this argument appropriately.</p><h4 id="port-forwarding-p-8080-8080">Port forwarding <code>-p 8080:8080</code></h4><p>This argument exposes the 8080 port. In essence it means that after you run this on a computer, your container will be accessible via <code>http://{computer-ip}:8080</code>. If you're running this on your local system, that address will be <code><a href="http://localhost:8080/">http://localhost:8080</a></code>. For more complex images, you might need more than one port forwarded for additional reasons such as api endpoints. In our case, the port is the UI endpoint, and will lead you to the home screen of ML-Workspace:</p><figure><img src="https://dagshub.com/blog/content/images/2020/09/Screen-Shot-2020-09-03-at-13.18.29.png" alt="ML-Workspace homepage" srcset="https://dagshub.com/blog/content/images/size/w600/2020/09/Screen-Shot-2020-09-03-at-13.18.29.png 600w, https://dagshub.com/blog/content/images/size/w1000/2020/09/Screen-Shot-2020-09-03-at-13.18.29.png 1000w, https://dagshub.com/blog/content/images/2020/09/Screen-Shot-2020-09-03-at-13.18.29.png 1564w" sizes="(min-width: 720px) 720px"><figcaption>http://localhost:8080 – My ML-Workspace homepage</figcaption></figure><h4 id="naming-our-container-name-dags-workspace">Naming our container <code>--name "dags-workspace"</code></h4><p>This generates a unique identifier for our container for future reference. As it might imply, this name should be unique per your system, so if you make multiple containers from the same image, you'll need to define different names for them. <code>--name</code> is also useful to add meaning to our container. If you don't define a name, a meaningless one will be generated for you automatically.</p><h4 id="defining-environment-variables-env-authenticate_via_jupyter-mytoken">Defining Environment Variables <code>--env AUTHENTICATE_VIA_JUPYTER="mytoken"</code></h4><p>The <code>--env</code> flag defines environment variables for your container. This can vary wildly between containers, and so it's hard to give a generic use case for it.</p><p>In our case, we use this to define a password to the workspace. When someone opens the link above for the first time, Jupyter will require them to input the password defined here. This might be useful if you're working on a shared computer.</p><figure><img src="https://dagshub.com/blog/content/images/2020/09/Screen-Shot-2020-09-03-at-16.13.07.png" alt="" srcset="https://dagshub.com/blog/content/images/size/w600/2020/09/Screen-Shot-2020-09-03-at-16.13.07.png 600w, https://dagshub.com/blog/content/images/size/w1000/2020/09/Screen-Shot-2020-09-03-at-16.13.07.png 1000w, https://dagshub.com/blog/content/images/2020/09/Screen-Shot-2020-09-03-at-16.13.07.png 1330w" sizes="(min-width: 720px) 720px"><figcaption>ML Workspace requesting a password</figcaption></figure><h4 id="defining-shared-memory-shm-size-2g">Defining shared memory <code>--shm-size 2g</code></h4><p>This flag is used to define the shared memory of your container (the more the better). Remember that this uses the same RAM as your regular system, so if you set it too high it might slow your computer down. A good size would be somewhere between <code>2g</code> and <code>8g</code> for most use cases.</p><h4 id="defining-the-restart-policy-restart-always">Defining the restart policy <code>--restart always</code> </h4><p>The <code>--restart</code> flag represents the container's restart policy. According to the Docker docs:</p><blockquote>A restart policy controls whether the Docker daemon restarts a container after exit.</blockquote><p>We use the <code>always</code> option which means Docker will try to keep the container running even if the system restarts. This is great in order to keep your project context intact.</p><p><strong>Congratulations! </strong>You now have an entire ML workspace running on your docker, including all the goodies you might need.</p><p>If you want to dive one level deeper, I recommend going to the <code>docker run</code> <a href="https://docs.docker.com/engine/reference/run/">command reference</a> to see all available flags.</p><h2 id="additional-setup">Additional Setup</h2><p>Let's go over a few things <em>I recommend</em> you setup to have an ideal workspace.</p><h3 id="setting-up-a-conda-virtual-environment-in-docker">Setting up a Conda/virtual environment in Docker</h3><p>We've set a standardized, isolated machine to run our ML. If you're setting up your project for the first time, you're probably running to your environment manager <code>conda</code>/<code>pip</code> to install some awesome packages.</p><p><strong>Let me stop you there.</strong></p><p>Why go through all this effort to create an isolated, reproducible environment and then go install a bunch of different packages that no one will know about. You should create a Conda or virtual environment to manage your packages. If you decided to use the <a href="https://hub.docker.com/repository/docker/dagshub/ml-workspace-minimal">DAGsHub/ml-workspace-minimal</a> container, here is what you should do:</p><p>In the ML <a href="http://localhost:8080/">workspace home</a> click the Open Tool dropdown and choose Terminal. Then type the following commands:</p><pre><code># Input your &lt;env-name&gt; and the &lt;python-version&gt; you want
conda create -y --name &lt;env-name&gt; python=&lt;python-version&gt;
# Activate your environment
source activate &lt;env-name&gt;

# If you have a `requirements.txt` file, you should install those requirements
pip …</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dagshub.com/blog/setting-up-data-science-workspace-with-docker/">https://dagshub.com/blog/setting-up-data-science-workspace-with-docker/</a></em></p>]]>
            </description>
            <link>https://dagshub.com/blog/setting-up-data-science-workspace-with-docker/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24435478</guid>
            <pubDate>Thu, 10 Sep 2020 19:02:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Do Routers Work, Really?]]>
            </title>
            <description>
<![CDATA[
Score 381 | Comments 98 (<a href="https://news.ycombinator.com/item?id=24435454">thread link</a>) | @turingbook
<br/>
September 10, 2020 | https://kamila.is//teaching/how-routers-work/ | <a href="https://web.archive.org/web/*/https://kamila.is//teaching/how-routers-work/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              
    <header>
        
    </header>


              <nav>
    
    <ul>
  <li><a href="#0-some-terminology">0. Some Terminology</a></li>
  <li><a href="#1-high-level-overview">1. High-level Overview</a>
    <ul>
      <li><a href="#the-data-plane-life-of-a-packet">The Data Plane: Life of a Packet</a></li>
    </ul>
  </li>
  <li><a href="#the-details-what-exactly-is-going-on">The details: What <em>exactly</em> is going on?</a>
    <ul>
      <li><a href="#life-of-a-packet-now-properly">Life of a Packet, Now Properly</a>
        <ul>
          <li><a href="#1-it-needs-to-be-routed-l3router">1. “It needs to be routed”: L3/router</a></li>
          <li><a href="#2-it-needs-to-be-passed-down-l25arp-glue">2. “It needs to be passed down”: L2.5/ARP glue</a></li>
          <li><a href="#3-it-needs-to-be-forwarded-l2switch">3. “It needs to be forwarded”: L2/switch</a></li>
          <li><a href="#the-logic-applying-the-tables">The logic: Applying the tables</a></li>
        </ul>
      </li>
      <li><a href="#the-control-plane-how-to-fill-the-tables">The Control Plane: How to Fill the Tables</a>
        <ul>
          <li><a href="#l3--routing-table">L3 / routing table</a></li>
          <li><a href="#l25--arp-table">L2.5 / ARP table</a></li>
          <li><a href="#l2--mac-table">L2 / MAC table</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#gimme-the-code">Gimme the code!</a></li>
  <li><a href="#next-steps">Next steps</a></li>
</ul>
</nav>

<p><strong>Work in progress</strong>: I still need to clean this up &amp; add the complete source code. ETA for a more or less done version is Soon(TM).<br>
<strong>Last updated</strong>: 2020/09/10 because how the eff did this end up on the front page of Hacker News? :D<br>
<strong>Suggestions welcome</strong>: <a href="https://github.com/AnotherKamila/kamila.is/issues/new?labels=teaching&amp;title=[teaching/how-routers-work]+Title">complain</a> if something is unclear or wrong!</p>

<p>This is the inside view of how exactly a router operates. You only need to know this if you are poking inside a router implementation. If that is the case, my condolences.</p>

<p>At the end of this exposition, I will give you the complete source code to a functional router (written in <a href="https://p4.org/">P4</a>, the new &amp; shiny software-defined networking thing). My aim is that you will understand every line of that.</p>

<p>I accompany my explanations below with some P4 code. I think it is useful to read it even if you’ve never seen P4, because it shows a bit more detail than the text and I believe that it is sufficiently pseudocode-ish. Here is a summary of what you need to know to read it:</p>
<ul>
  <li>everything happens per packet</li>
  <li><code>hdr</code> are the packet’s parsed headers</li>
  <li><code>standard_metadata</code> is how you tell the switch to do things with the packet (like send it on a specific port)</li>
  <li><code>meta</code> are user-defined in-memory variables which can be used e.g. for matching in tables</li>
</ul>



<ul>
  <li>Figuring out what should be done with packets is done by <em>the control plane/in the slow path/on the CPU/by the controller</em> or similar phrases. I will refer to all of this as “the control plane”.</li>
  <li>Actually forwarding the packets  is done by <em>the data plane/in the fast path/in the hardware/in the switch</em> and such. I will refer to this as “the data plane”.</li>
</ul>

<p><a href="https://news.ycombinator.com/item?id=24436585">Cyph0n on HN did a good job explaining this distinction.</a></p>



<p>A <em>switch</em> (or an L2 switch :-) ) is an L2-only<sup><a href="#fn1">1</a></sup> thing. It knows about L2 stuff such as MAC addresses and ports<sup><a href="#fn2">2</a></sup>. It does <strong>not</strong> know about anything like IP addresses. It has a <strong>MAC table</strong>: it maps MAC addresses to ports.</p>

<p>A <em>router</em> (or an L3 switch by some people’s vocabulary) operates on L3 only. It knows about L3 stuff such as IP addresses and interfaces and hosts. It does <strong>not</strong> know about L2 stuff such as MAC addresses or ports.<sup><a href="#fn3">3</a></sup> In fact, the routing parts of the router would not have to be changed at all if you decided to use something other than ethernet on L2. It has a <strong>routing table</strong> (details later): a table of subnets/prefixes and how to reach them.</p>

<p>What you normally call a router (that box sitting over there) is actually a router (for handling L3) and one or more switches (for handling L2), and some glue in between. They may in fact be separate chips in hardware.</p>

<p>You need glue to put together the L2 and the L3. This “L2.5” glue is ARP (or NDP for IPv6). It usually lives in the router, but it is glue, not routing, and you can think about it separately.</p>

<h2 id="the-data-plane-life-of-a-packet">The Data Plane: Life of a Packet</h2>

<p>When a packet arrives and needs to be sent further, these things have to happen to it:</p>

<ol>
  <li>It needs to be <em>routed</em>: the <strong>router</strong>, based on L3 information, decides where it needs to go, in L3 speak – it will decide which <em>host</em> to send it to, but not how. This corresponds to the <em><a href="https://en.wikipedia.org/wiki/Routing_table">routing table</a></em>.</li>
  <li>It needs to be passed down to L2: this is where the L2.5 ARP/NDP <strong>glue</strong> translates the L3-speak IP address to L2-speak MAC address. This is the <em>ARP table</em>.</li>
  <li>It needs to be <em>forwarded</em> on the correct port: the <strong>switch</strong> puts the packet on the correct port. This is the <em>MAC table</em>.</li>
</ol>



<h2 id="life-of-a-packet-now-properly">Life of a Packet, Now Properly</h2>

<h3 id="1-it-needs-to-be-routed-l3router">1. “It needs to be routed”: L3/router</h3>

<p>The packet has a destination IP address. This is matched in the <em>routing table</em>, using a longest-prefix match (LPM), i.e. it matches IP address prefixes. It may either be for a host the router is directly connected to (on some interface), or it may need to be sent further, through a <em>gateway</em> (through some interface). Therefore: <strong>The routing table maps a <em>prefix</em> to either <em>a next hop through a gateway and an interface</em>, or <em>a direct connection through an interface</em></strong>.</p>

<div><div><pre><code>routing_table : Prefix -&gt; NextHop (GatewayIP, Interface) | Direct Interface
</code></pre></div></div>

<p>Note that the next hop’s IP address is in the router’s memory only: it does not appear in the packet at any time.</p>

<p>The P4 code defining the IPv4 routing table is:</p>

<div><div><pre><code>action ipv4_through_gateway(ipv4_addr_t gateway, interface_t iface) {
    meta.out_interface = iface;
    meta.ipv4_next_hop = gateway;  // send through the gateway
}

action ipv4_direct(interface_t iface) {
    meta.out_interface = iface;
    meta.ipv4_next_hop = hdr.ipv4.dst_addr;  // send directly to the destination
}

table ipv4_routing {
    key = {
        hdr.ipv4.dst_addr: lpm;  // match prefixes
    }
    actions = {
        ipv4_through_gateway;    // ipv4_through_gateway(gateway, iface)
        ipv4_direct;             // ipv4_direct(iface)
        drop;
    }
    default_action = drop();     // If there is no route, drop it -- in reality, we might want to
                                 // send an ICMP "No route to host" packet.
                                 // Note that this is the default route, so control plane might
                                 // want to set a default gateway here instead of dropping.
    size = ROUTING_TABLE_SIZE;
}
</code></pre></div></div>
<p>(and the exact same thing for IPv6)</p>

<h3 id="2-it-needs-to-be-passed-down-l25arp-glue">2. “It needs to be passed down”: L2.5/ARP glue</h3>

<p>If we did not drop the packet because there was no route, we now know the IP address and interface of the next hop. (Note that this is a host that is connected to us directly – it is sitting on the same wire.)
We need to translate this into an L2 MAC address in order to pass it to the switch. We do it via the ARP table:</p>

<div><div><pre><code>arp_table : (IPv4Address, Interface) -&gt; MACAddress
</code></pre></div></div>

<p>Note: <code>Interface</code> conceptually belongs there, but <code>IPv4Address</code> should be unique. We need to store the interface in the control plane anyway, because we want to pre-emptively re-send ARP requests when an entry is about to expire, but in the data plane it is not strictly necessary.</p>

<p>An interesting question arises here: What do we do if there is no match, i.e. when we don’t know the MAC address for the IP? First, we send an ARP request. Then, most routers drop the packet (relying on either retransmissions or “nobody will miss it”). Storing the packet until the ARP reply comes back (or until it expires) would also work, but usually isn’t done.
Sending ARP requests is normally done in the control plane, because the ARP requests need to be throttled and expired and such.</p>

<p>P4 code:</p>
<div><div><pre><code>action set_dst_mac(mac_addr_t dst_addr) {
    hdr.ethernet.dst_addr = dst_addr;
}

table ipv4_arp {
    key = {
        meta.ipv4_next_hop: exact;     // next_hop is the host we found in the routing step; we want to send to that
        // meta.out_interface: exact;  // conceptually this belongs here, but actually next_hop should be unique, so
                                       // we can leave it out
    }
    actions = {
        set_dst_mac;                // set_dst_mac(mac)
        drop;
    }
    default_action = drop();
    size = ARP_TABLE_SIZE;
}
</code></pre></div></div>

<p>IPv6 uses NDP instead of ARP, which is different but the same ;-)</p>

<h3 id="3-it-needs-to-be-forwarded-l2switch">3. “It needs to be forwarded”: L2/switch</h3>

<p>This is L2 / the switch. It works on each interface separately (it could be multiple chips in hardware). It gets a packet with some destination MAC address, and it decides on which port it should put it. It uses a <em>MAC table</em> to do it:</p>

<div><div><pre><code>mac_table : MACAddress -&gt; Port
</code></pre></div></div>

<p>P4 code:</p>

<div><div><pre><code>// note: we're operating on metadata.out_interface

action set_out_port(port_t ports) {
    standard_metadata.egress_spec = ports;
}

action broadcast() {
    // Implementation depends on the switch.
    // In v1model, use a multicast group corresponding to all ports on metadata.out_interface.
}

// we call it dmac -- see below why
table dmac {
    key = {
        hdr.ethernet.dst_addr: exact;
    }
    actions = {
        set_out_port;  // set_out_port(port)
        broadcast;     // no params, uses metadata.out_interface
                       // remember to set broadcast for 0xffffffffffff in the control plane
        drop;
    }
    default_action = drop();
    size = ARP_TABLE_SIZE;  // we can have at most as many ports as MAC addresses
}

</code></pre></div></div>

<p>Note: Real switches are a bit more complicated than that: for example, redundant links mean that a MAC address may be on more than one port. However, you will notice when you need to think about this. Normally considering the simple version is sufficient.</p>

<h3 id="the-logic-applying-the-tables">The logic: Applying the tables</h3>

<ol>
  <li>apply routing =&gt; find the next hop (either gateway or direct)</li>
  <li>apply ARP translation to the “next hop” host</li>
  <li>send out on the right port</li>
</ol>

<p>In P4:</p>
<div><div><pre><code>apply {
    routing.apply();  // fills out metadata.next_hop
    arp.apply();      // sets pkt.ethernet.dst_addr to the MAC of next_hop
    dmac.apply();     // sends out on the port for pkt.ethernet.dst_addr
}
</code></pre></div></div>

<p>(Note: While this is conceptually correct, we actually also want to apply the auxiliary table mentioned below. The full code contains that.)</p>

<h2 id="the-control-plane-how-to-fill-the-tables">The Control Plane: How to Fill the Tables</h2>

<p>Starting at the bottom for a change:</p>

<h3 id="l3--routing-table">L3 / routing table</h3>

<p>Filled out by the control plane, depending on the context:</p>

<ul>
  <li>In your home router, it probably has only two entries: the local network (something like 192.168.0.0/24) =&gt; direct on the internal interface, and a default route via your ISP’s gateway on the external interface.
 In this case, the routing table is static and is filled out by the firmware according to the settings.</li>
  <li>In a small company router, there might be a direct network such as 10.0.0.0/24, a remote office in 10.0.1.0/24 via a VPN server, and a default route from the ISP.
 The default route and the direct route would also be filled …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kamila.is//teaching/how-routers-work/">https://kamila.is//teaching/how-routers-work/</a></em></p>]]>
            </description>
            <link>https://kamila.is//teaching/how-routers-work/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24435454</guid>
            <pubDate>Thu, 10 Sep 2020 19:00:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: CCS811 indoor air quality sensor driver in Rust]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24435312">thread link</a>) | @eldruin
<br/>
September 10, 2020 | https://blog.eldruin.com/ccs811-indoor-air-quality-sensor-driver-in-rust/ | <a href="https://web.archive.org/web/*/https://blog.eldruin.com/ccs811-indoor-air-quality-sensor-driver-in-rust/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrap"><div><div><div><section id="main"><div><article id="post-/ccs811-indoor-air-quality-sensor-driver-in-rust" itemscope="" itemprop="blogPost"><div><header></header><p><a href="https://blog.eldruin.com/images/ccs811-bluepill.jpg" rel="gallery_ckex53tc400000cmljwxbgvu7"><img src="https://blog.eldruin.com/images/ccs811-bluepill.jpg" itemprop="image"> </a><a href="https://blog.eldruin.com/images/ccs811-rpi.jpg" rel="gallery_ckex53tc400000cmljwxbgvu7"><img src="https://blog.eldruin.com/images/ccs811-rpi.jpg" itemprop="image"> </a><a href="https://blog.eldruin.com/images/ccs811-measurements.jpg" rel="gallery_ckex53tc400000cmljwxbgvu7"><img src="https://blog.eldruin.com/images/ccs811-measurements.jpg" itemprop="image"></a></p><div itemprop="articleBody"><p><a href="https://crates.io/crates/embedded-ccs811" target="_blank" rel="noopener"><img src="https://img.shields.io/crates/v/embedded-ccs811.svg"></a>&nbsp;<a href="https://docs.rs/embedded-ccs811" target="_blank" rel="noopener"><img src="https://docs.rs/embedded-ccs811/badge.svg"></a>&nbsp;<a href="https://travis-ci.com/eldruin/embedded-ccs811-rs" target="_blank" rel="noopener"><img src="https://travis-ci.com/eldruin/embedded-ccs811-rs.svg?branch=master"></a>&nbsp;<a href="https://coveralls.io/github/eldruin/embedded-ccs811-rs?branch=master" target="_blank" rel="noopener"><img src="https://coveralls.io/repos/github/eldruin/embedded-ccs811-rs/badge.svg?branch=master"></a></p><p>We spend an enormous amount of time indoors. The indoor air quality is often overlooked but it is actually an important factor in our health, comfort and even productivity.</p><p>There are lots of things that contribute to the degradation of the <a href="https://en.wikipedia.org/wiki/Indoor_air_quality" target="_blank" rel="noopener">indoor air quality</a> over time. Some of them are trivial to guess like breathing, chimneys, second-hand tobacco smoke, mold, etc. There are others that you may not have heard of like <a href="https://en.wikipedia.org/wiki/Volatile_organic_compound" target="_blank" rel="noopener">volatile organic compounds (VOC)</a>.<br>Remember that smell new things have? well sorry but that <strong><a href="https://iaqscience.lbl.gov/voc-cancer" target="_blank" rel="noopener">can give you cancer</a></strong>.</p><p>You can build your own indoor air quality monitor with an AMS/ScioSense CCS811 sensor and some Rust using the driver I wrote.</p><h2 id="The-device"><a href="#The-device" title="The device"></a>The device</h2><p>The CCS811 is an ultra-low power digital gas sensor solution which integrates a metal oxide (MOX) gas sensor to detect a wide range of Volatile Organic Compounds (VOCs) for indoor air quality monitoring with a microcontroller unit (MCU), which includes an Analog-to-Digital converter (ADC), and an I²C interface.</p><p>CCS811 supports intelligent algorithms to process raw sensor measurements to output equivalent total VOC (eTVOC) and equivalent CO2 (eCO2) values, where the main cause of VOCs is from humans.</p><p>CCS811 supports multiple measurement modes that have been optimized for low-power consumption during an active sensor measurement and idle mode extending battery life in portable applications.</p><h2 id="Firmware-update"><a href="#Firmware-update" title="Firmware update"></a>Firmware update</h2><p>Depending on where you bought your device, it might be that the firmware application version is too old. I have observed the older version hangs or returns errors quite often.</p><p>You can update the firmware application with a Raspberry Pi (it does not matter which one).<br>First wire the device like this:<br></p><figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br></pre></td><td><pre><span>RPi   &lt;-&gt; CCS811</span><br><span>GND   &lt;-&gt; GND</span><br><span>3.3V  &lt;-&gt; VCC</span><br><span>Pin 5 &lt;-&gt; SCL</span><br><span>Pin 3 &lt;-&gt; SDA</span><br><span>GND   &lt;-&gt; nWAKE</span><br><span>3.3V  &lt;-&gt; RST</span><br></pre></td></tr></tbody></table></figure><p>Next inside your Raspberry Pi download the driver repository somewhere, then run the flashing program without arguments to print the current firmware version:<br></p><figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br></pre></td><td><pre><span>git clone https://github.com/eldruin/embedded-ccs811-rs</span><br><span>cd embedded-ccs811-rs</span><br><span>cargo run --example flash-firmware</span><br></pre></td></tr></tbody></table></figure><p>You will see something like this:<br></p><figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></pre></td><td><pre><span>Hardware ID: 129, hardware version: (1, 2)</span><br><span>Firmware boot version: (1, 0, 0)</span><br><span>Firmware application version: (1, 1, 0)</span><br><span>Has valid firmware application: true</span><br></pre></td></tr></tbody></table></figure><p>And then an error because no firmware file was provided.</p><p>If the firmware application is smaller than <code>(2, 0, 0)</code>, you can update it as follows.</p><p>Download the new version of the firmware application from <a href="https://github.com/sciosense/CCS811_driver/blob/master/examples/ccs811flash/CCS811_SW000246_1-00.bin" target="_blank" rel="noopener">here</a>. Then place it inside the <code>embedded-ccs811-rs</code> folder and call the flashing program again now providing the path to the new firmware file:<br></p><figure><table><tbody><tr><td><pre><span>1</span><br></pre></td><td><pre><span>cargo run --example flash-firmware CCS811_SW000246_1-00.bin</span><br></pre></td></tr></tbody></table></figure><p>You should see an output similar to this:</p><figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br></pre></td><td><pre><span>Hardware ID: 129, hardware version: (1, 2)</span><br><span>Firmware boot version: (1, 0, 0)</span><br><span>Firmware application version: (1, 1, 0)</span><br><span>Has valid firmware application: true</span><br><span>Starting update process: Reset, erase, download, verify...</span><br><span>Update was successful!</span><br><span>Status:</span><br><span>Hardware ID: 129, hardware version: (1, 2)</span><br><span>Firmware boot version: (1, 0, 0)</span><br><span>Firmware application version: (2, 0, 0)</span><br><span>Has valid firmware application: true</span><br></pre></td></tr></tbody></table></figure><p>Done!</p><h2 id="Using-the-driver"><a href="#Using-the-driver" title="Using the driver"></a>Using the driver</h2><p>To use the device from Rust, you have to add the <a href="https://crates.io/crates/embedded-ccs811" target="_blank" rel="noopener">embedded-ccs811</a> crate to your project as well as a concrete implementation of the <a href="https://crates.io/crates/embedded-hal" target="_blank" rel="noopener">embedded-hal</a> traits. For example if you are using the Raspberry Pi running Linux:</p><figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></pre></td><td><pre><span></span><br><span>...</span><br><span><span>[dependencies]</span></span><br><span><span>embedded-ccs811</span> = <span>"0.2"</span></span><br><span><span>linux-embedded-hal</span> = <span>"0.3"</span></span><br><span><span>nb</span> = <span>"1"</span></span><br></pre></td></tr></tbody></table></figure><p>Here is an example program which will start the application and print the measurements (<a href="https://github.com/eldruin/embedded-ccs811-rs/blob/master/examples/linux.rs" target="_blank" rel="noopener">source</a>):<br></p><figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br></pre></td><td><pre><span><span>use</span> embedded_ccs811::{prelude::*, Ccs811Awake, MeasurementMode, ModeChangeError, SlaveAddr};</span><br><span><span>use</span> linux_embedded_hal::I2cdev;</span><br><span><span>use</span> nb::block;</span><br><span></span><br><span><span><span>fn</span> <span>main</span></span>() {</span><br><span>    <span>let</span> dev = I2cdev::new(<span>"/dev/i2c-1"</span>).unwrap();</span><br><span>    <span>let</span> address = SlaveAddr::default();</span><br><span>    <span>let</span> sensor = Ccs811Awake::new(dev, address);</span><br><span>    <span>match</span> sensor.start_application() {</span><br><span>        <span>Err</span>(ModeChangeError { dev: _, error }) =&gt; {</span><br><span>            <span>println!</span>(<span>"Error during application start: {:?}"</span>, error);</span><br><span>        }</span><br><span>        <span>Ok</span>(<span>mut</span> sensor) =&gt; {</span><br><span>            sensor.set_mode(MeasurementMode::ConstantPower1s).unwrap();</span><br><span>            <span>loop</span> {</span><br><span>                <span>let</span> data = block!(sensor.data()).unwrap();</span><br><span>                <span>println!</span>(<span>"eCO2: {}, eTVOC: {}"</span>, data.eco2, data.etvoc);</span><br><span>            }</span><br><span>        }</span><br><span>    }</span><br><span>}</span><br></pre></td></tr></tbody></table></figure><p>Furthermore, this device must be provided with the ambient temperature and humidity in order to compensate the readings. You can see an example doing this <a href="https://github.com/eldruin/driver-examples/blob/master/raspberrypi/examples/ccs811-gas-voc-display-rpi.rs" target="_blank" rel="noopener">here</a>.</p><p>I also created a bare-metal example program that runs on the STM32F1 “blue-pill” board which continuously reads the measurement and prints it on an OLED display. You can find the source code of that program <a href="https://github.com/eldruin/driver-examples/blob/master/stm32f1-bluepill/examples/ccs811-gas-voc-display-bp.rs" target="_blank" rel="noopener"><strong>here</strong></a>.</p><p>In the <a href="https://github.com/eldruin/driver-examples" target="_blank" rel="noopener"><strong>driver-examples</strong></a> repository you can find further bare-metal examples which you can adapt to do other things with this device.</p><h2 id="Some-measurements"><a href="#Some-measurements" title="Some measurements"></a>Some measurements</h2><p><img src="https://blog.eldruin.com/images/ccs811-measurements.jpg" alt="Measurements in a closed room with one person"></p><p>I bought my device on AliExpress and sadly it does not seem to make accurate readings. For example if you see these readings of the device in a closed room with one person. It seems the measurements match the humidity, rather than the CO2 concentration. I made other measurements with an iAQ-Core-C sensor I got from MOUSER and these did resemble what one would expect. I will publish those here soon.</p><p>Possibly my CCS811 is simply worn off. If you are interested in doing something useful with this device I would rather recommend buying it from a reputable retailer like Adafruit, Sparkfun, or so.</p><h2 id="Raspberry-Pi-configuration"><a href="#Raspberry-Pi-configuration" title="Raspberry Pi configuration"></a>Raspberry Pi configuration</h2><p>This device uses clock stretching which leads to communication problems with the Raspberry Pi.<br>For the firmware update it worked repeatedly fine for me but for measurement reading you may encounter errors like this:<br></p><figure><table><tbody><tr><td><pre><span>1</span><br></pre></td><td><pre><span>thread 'main' panicked at 'called `Result::unwrap()` on an `Err` value: Device(DeviceErrors { invalid_register_write: true, invalid_register_read: true, invalid_measurement: true, max_resistance: true, heater_fault: true, heater_supply: true })', src/libcore/result.rs:1165:5</span><br></pre></td></tr></tbody></table></figure><p>You may also see this:<br></p><figure><table><tbody><tr><td><pre><span>1</span><br></pre></td><td><pre><span>thread 'main' panicked at 'called `Result::unwrap()` on an `Err` value: I2C(Nix(Sys(EREMOTEIO)))', src/libcore/result.rs:1165:5</span><br></pre></td></tr></tbody></table></figure><p>A trick for the Raspberry Pi is to reduce the I2C bus speed.<br>You can do that by editing the file <code>/boot/config.txt</code>:<br></p><figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br></pre></td><td><pre><span>dtparam=i2c_arm=on # Enable I2C</span><br><span>dtparam=i2c_arm_baudrate=10000 # 10kHz speed</span><br></pre></td></tr></tbody></table></figure><p>Then reboot your Raspberry Pi. Done!</p><p>Even when correctly configured the errors can happen on occasion. See <a href="https://learn.adafruit.com/circuitpython-on-raspberrypi-linux/i2c-clock-stretching" target="_blank" rel="noopener">here</a> for more info.</p><h2 id="Where-to-go-from-here"><a href="#Where-to-go-from-here" title="Where to go from here?"></a>Where to go from here?</h2><p>There is more information and example programs in the <a href="https://docs.rs/embedded-ccs811" target="_blank" rel="noopener">crate documentation</a>.<br>If you encounter any issues, please report them in the <a href="https://github.com/eldruin/embedded-ccs811-rs/issues" target="_blank" rel="noopener">issue tracker</a>.<br>Feedback, suggestions and improvements are gladly welcome.</p><h2 id="What’s-next"><a href="#What’s-next" title="What’s next?"></a>What’s next?</h2><p>I also have a pretty finished driver for a similar device: <a href="https://crates.io/crates/iaq-core" target="_blank" rel="noopener">iAQ-Core-C/P air quality sensor</a>. I took some measurements which looked much better. I will announce it here soon.</p><p>Otherwise I have been writing many other platform-agnostic Rust drivers although I am slow to finish them up and announce them here.</p><p>To see what I am currently working on you can <a href="https://github.com/eldruin" target="_blank" rel="noopener"><strong>follow me on github</strong></a>.</p><p>Thanks for reading and stay tuned!</p><p>Links: <a href="https://github.com/eldruin/embedded-ccs811-rs" target="_blank" rel="noopener">Source code</a> - <a href="https://crates.io/crates/embedded-ccs811" target="_blank" rel="noopener">Crate</a> - <a href="https://docs.rs/embedded-ccs811" target="_blank" rel="noopener">Documentation</a></p></div></div></article></div></section></div></div></div></div></div>]]>
            </description>
            <link>https://blog.eldruin.com/ccs811-indoor-air-quality-sensor-driver-in-rust/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24435312</guid>
            <pubDate>Thu, 10 Sep 2020 18:45:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Docker Considered Harmful (2016)]]>
            </title>
            <description>
<![CDATA[
Score 43 | Comments 49 (<a href="https://news.ycombinator.com/item?id=24435200">thread link</a>) | @maple3142
<br/>
September 10, 2020 | http://catern.com/posts/docker.html | <a href="https://web.archive.org/web/*/http://catern.com/posts/docker.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">


<p>
Docker is extremely popular these days.<sup><a id="fnr.1" name="fnr.1" href="#fn.1">1</a></sup>
Too bad it's not very good.
</p>

<p>
A note in advance:
This is absolutely not about Docker being too "opinionated" for me,
or other tools being more flexible.
I believe that learning and using Docker is just plain more complicated than learning and using the tools I describe below.
Docker is genuinely more complex and harder to use than the alternatives.
These tools also happen to be more flexible than Docker,
but that's not why I'm recommending them:
I'm recommending them because they are simpler to learn and use.
If they are indeed more flexible in addition to being simpler to use, then that's just due to an overall superior design.
</p>

<div id="outline-container-sec-1">
<h2 id="sec-1">Docker containers are not mysterious</h2>
<div id="text-1">
<p>
First, a brief explanation of how containers work.
Linux containers<sup><a id="fnr.2" name="fnr.2" href="#fn.2">2</a></sup> are built on two kernel features, namespaces and cgroups.
Their architecture is quite easy to understand.
</p>

<p>
I encourage everyone to read the main namespaces man page: <a href="http://man7.org/linux/man-pages/man7/namespaces.7.html">man 7 namespaces</a>.
It's well written and makes it easy to grok the concept.
If you create a new instance of all<sup><a id="fnr.3" name="fnr.3" href="#fn.3">3</a></sup> of these namespaces, you have something like a container.
</p>

<p>
The cgroups documentation (located at <a href="https://www.kernel.org/doc/Documentation/cgroups-v1/">Documentation/cgroups-v1/</a> and <a href="https://www.kernel.org/doc/Documentation/cgroup-v2.txt">Documentation/cgroup-v2.txt</a> in your local copy of the Linux source code) is less straightforward, 
but still a better explanation than I could write.
The basic idea is that cgroups are a mechanism for grouping processes.
This mechanism is used to implement other systems like <a href="http://man7.org/linux/man-pages/man7/cpuset.7.html">man 7 cpuset</a>, which are used to track and schedule the container processes.
</p>

<p>
If you make the appropriate system calls to move into a cpuset cgroup and create new namespaces, you have a container.
There's not much to it.
</p>

<p>
One could write a relatively short C program and create a Unix-style utility that uses these system calls to start up a new container.
You can see this for yourself by playing around with <a href="http://man7.org/linux/man-pages/man1/nsenter.1.html">man 1 nsenter</a> and <a href="http://man7.org/linux/man-pages/man1/unshare.1.html">man 1 unshare</a>, which are the most minimal possible wrappers around the namespaces syscalls.
</p>

<p>
The point of explaining this is to show that the Linux container functionality is all rather simple.
Docker (or any other container software) are not doing anything especially mystifying in the specific area of bringing up a container.
Armed with that knowledge, let's look at what else Docker is actually doing.
</p>
</div>
</div>
<div id="outline-container-sec-2">
<h2 id="sec-2">Docker for building containers is superfluous</h2>
<div id="text-2">
<p>
We'll start off with how Docker builds a container image for you.
You pull down some kind of image from the Docker hub, and Docker hums excitingly for a bit while you watch things scroll and progress bars fill.
What you end up with is a filesystem tree from some Linux distro, with a few things added in on top.
</p>

<p>
It may be surprising to some that we have been doing exactly this for multiple decades now.
</p>

<p>
In fact, you do this every time you install GNU/Linux on a machine.
The majority of the files in that filesystem tree come from packages from some distro.
And package managers are certainly capable of installing packages into arbitrary directories; that's how they install a new system.
</p>

<p>
In fact, most even have neat little wrapper scripts to do it for you! And these are only an <code>apt-get install debootstrap</code> (or equivalent) away!
To build filesystem trees for a few of the most popular distros<sup><a id="fnr.4" name="fnr.4" href="#fn.4">4</a></sup>:
</p>
<ul>
<li><code>debootstrap trusty /srv/trees/ubuntu</code>
</li>
<li><code>debootstrap stable /srv/trees/debian</code>
</li>
<li><code>yum -y --nogpg --releasever=22 --disablerepo='*' --enablerepo=fedora install fedora-release systemd passwd dnf fedora-release vim-minimal --installroot=/srv/trees/fedora</code>
</li>
<li><code>pacstrap /srv/trees/arch</code>
</li>
</ul>

<p>
And of course you can select additional packages to install using these commands, or make other changes.
This has been used for decades to build chroots, which I'll say more about a bit later.
There are even more novel package managers,
like <a href="https://nixos.org/nix/">nix</a> and <a href="http://www.gnu.org/software/guix/">guix</a>,
which have interesting features that can make things even easier.
</p>

<p>
But wait, the distro version of node.js (for example) is too out of date!
How am I going to get the latest version?
</p>

<p>
Well, the first thing you should do if you need more up to date versions is enable the updated package repositories for your distro:
Ubuntu backports, Debian backports, CentOS EPEL.
It may be surprising to some, but distros and package managers actually exist for a reason, 
and one of those reasons is that they make it easy to keep your system up to date.
(There are other advantages which I won't go into here<sup><a id="fnr.5" name="fnr.5" href="#fn.5">5</a></sup>)
</p>

<p>
If a suitably updated version is not available through distro channels,
I am obligated to suggest that the next best option is 
to download the source of the distro package, update and rebuild it yourself, and install using that package.
Or, build the package yourself if one isn't available.
This can be a bit of a pain if you are in the early development stages
(though there are tools to make it easier<sup><a id="fnr.6" name="fnr.6" href="#fn.6">6</a></sup>)
but again, there are many advantages.<sup><a id="fnr.5.100" name="fnr.5.100" href="#fn.5">5</a></sup>
</p>

<p>
Most people, however, use the traditional hacks.
You can chroot in and just do your usual <code>pip install foo</code> or <code>gem install bar</code> or <code>npm install baz</code> or <code>./configure &amp;&amp; make &amp;&amp; make install</code>,
just as you would with some "RUN" directives in a Dockerfile.
</p>

<p>
Wow! It's just like Docker!
No, Docker is just like this.
Hopefully it is becoming obvious that here, at least, there is no real advantage of Docker.
</p>

<p>
Crucially, you can use all the same install scripts that you would use with a normal Linux machine.
You don't need to rewrite everything into Dockerfiles.
You can do it manually, you can use shell scripts, you can use Ansible, 
you can write a boutique ConfigurationManagementFactory in Java, you can do whatever you like.
It's just installing software.
It's not complicated unless you make it complicated.
Supposedly, Dockerfiles are simpler than running <code>debootstrap</code> at the beginning of your script, but I'm not sure I understand why.
It seems to me that Docker is no simpler or easier than the standard way.
</p>

<p>
Now, it's true that Docker uses layering to be efficient in terms of disk space and time to build new containers.
It defaults to using <a href="http://aufs.sourceforge.net/aufs.html">AUFS</a> to do this.<sup><a id="fnr.7" name="fnr.7" href="#fn.7">7</a></sup>
I think you could reimplement it easily yourself with a small shell script and some calls to mount;
but I haven't bothered.
</p>

<p>
Personally, I just use <a href="https://btrfs.wiki.kernel.org/index.php/Manpage/btrfs-subvolume">man 8 btrfs-subvolume</a>.
btrfs is a copy on write filesystem which can instantly make space-efficient copies of filesystem trees in "subvolumes",
which the user sees as just regular directories.
</p>

<p>
You can build a stock Ubuntu filesystem tree into a subvolume with 
<code>btrfs subvolume create /srv/trees/ubuntu &amp;&amp; debootstrap trusty /srv/trees/ubuntu/</code>.
Then, when you want to build a new container with specific software,
you just copy that subvolume and perform your modifications on the copy;
that is, <code>btrfs subvolume snapshot /srv/trees/debian /srv/containers/webapp</code> and work on <code>/srv/containers/webapp</code>.
If you want to copy those modifications, you just take another snapshot.
</p>

<p>
This is arguably better, because there's no need to maintain a lot of state about the mount layerings and set them up again on reboot.
Your container filesystem just sits there in a volume waiting for you to start it.
</p>

<p>
Naturally, if you don't like btrfs for some reason,
you're perfectly able to use zfs, OverlayFS, AUFS, or whatever;
no need to have a "storage driver" implemented just to do some simple copy-on-write or layering operations.
</p>

<p>
And if you want to do some kind of change tracking as you build the system,
you should keep it at the proper layer,
or use dedicated tools.
<code>/usr</code> should be immutable and built from packages,
your application data should live in <code>/srv</code> or <code>/var</code> and be mounted in,
and so all the configuration data that is part of the system build should be in <code>/etc</code>.
To track this, you can just use <a href="http://etckeeper.branchable.com/">etckeeper</a> and store your <code>/etc</code> in a git repository.
which is right and proper since <code>/usr</code> should be immutable.
If you must, <a href="https://wiki.gnome.org/action/show/Projects/OSTree">OSTree</a> lets you version whole filesystems.
</p>

<p>
And if you still need to pull in a Docker image for some reason,
you can treat it as just another way to build a filesystem tree.
There are tools that will let you do that,
such as <a href="http://www.freedesktop.org/software/systemd/man/machinectl.html">machinectl pull-dkr</a>.
</p>
</div>
</div>
<div id="outline-container-sec-3">
<h2 id="sec-3">Isolation for deployment is not new</h2>
<div id="text-3">
<p>
But wait! Docker isn't just a pointless abstraction layer over the simple task of building filesystem trees!
It lets you actually use those filesystem trees in containers!
</p>

<p>
Well, it may be a shock, but these tools that Docker uses - they actually exist for a reason.
As I said earlier, these tools have been used for decades to build chroots.
</p>

<p>
What's a chroot?
Well, <a href="http://man7.org/linux/man-pages/man1/chroot.1.html">man 1 chroot</a> is a decades-old tool that lets you change what the root directory <code>/</code> points to;
for example, you could point <code>/</code> at <code>/srv/container/webapp</code>.
Everything looks for libraries and binaries in subdirectories of the root directory, like <code>/usr/lib</code> and <code>/usr/bin</code>.
So, by using chroot you can have an entirely different set of libraries and binaries;
when you run things inside the chroot, they will see just the libraries and software that you installed inside that filesystem tree.
</p>

<p>
To help explain what you can use a chroot for, here's a short little blurb I "wrote" about what you can do with chroot.
</p>

<blockquote>
<p>
Sysadmins use chroot to provide standardized environments for their development, QA, and production teams, reducing "works on my machine" finger-pointing.
By "chrooting" the app platform and its dependencies, sysadmins abstract away differences in OS distributions and underlying infrastructure.
</p>
</blockquote>

<p>
That sure sounds useful.
But wait, there's this new kid on the block, Docker.
Let's see <a href="https://web.archive.org/web/20150211030001/https://www.docker.com/whatisdocker/">what they have to say</a>.
</p>

<blockquote>
<p>
Sysadmins use Docker to provide standardized environments for their development, QA, and production teams, reducing "works on my machine" finger-pointing.
By "Dockerizing" the app platform and its dependencies, sysadmins abstract away differences in OS distributions and underlying infrastructure.
</p>
</blockquote>

<p>
Docker is not novel in giving you these capabilities.
They're quite novel in marketing it so intensely, though.
</p>
</div>
</div>
<div id="outline-container-sec-4">
<h2 id="sec-4">Docker for security is useless by default</h2>
<div id="text-4">
<p>
But wait! Docker is "containers", new, fancy, …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://catern.com/posts/docker.html">http://catern.com/posts/docker.html</a></em></p>]]>
            </description>
            <link>http://catern.com/posts/docker.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24435200</guid>
            <pubDate>Thu, 10 Sep 2020 18:34:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Caddy and CertMagic have new ownership; no changes to licensing or development]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24434770">thread link</a>) | @theBashShell
<br/>
September 10, 2020 | https://caddy.community/t/caddy-and-certmagic-have-new-ownership-no-changes-to-licensing-or-development/9754?u=matt | <a href="https://web.archive.org/web/*/https://caddy.community/t/caddy-and-certmagic-have-new-ownership-no-changes-to-licensing-or-development/9754?u=matt">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
          <p>I have some great news that I’ve been meaning to share for a while: the Caddy project is now owned by <a href="https://apilayer.com/">apilayer</a>. This allows me to continue working on Caddy full-time, <strong>without any changes to <a href="https://github.com/caddyserver/caddy/issues/2786">the current open source licensing</a>.</strong></p>
<p>This was a very personal decision for me, which came only after lots of careful consideration and discussion with both apilayer and Ardan Labs. We’re excited for this, and I hope you will be too.</p>
<p>In this post I’ll elaborate on my perspective and explain some of the details best I can, but I don’t speak for apilayer or Ardan Labs. You can read <a href="https://www.ardanlabs.com/news/2020/08/caddy-server-is-acquired/">Ardan Labs’ press release here</a>.</p>

<p>(I’ll try to keep this post updated as I see comments or questions.)</p>
<ul>
<li>
<p>Caddy is now an <a href="https://apilayer.com/">apilayer</a> open source product. They also have rights to the trademark.</p>
</li>
<li>
<p><strong>This does not change Caddy licensing or distribution in any way. Caddy has always been and still is Apache 2.0 open source licensed, just like thousands of other FOSS projects.</strong></p>
</li>
<li>
<p>This actually happened about six months ago. We’ve just been too busy to announce it! <img src="https://caddy.community/images/emoji/apple/sweat_smile.png?v=9" title=":sweat_smile:" alt=":sweat_smile:"> Between the pandemic, more client work from project growth, and other unexpected life things, it’s been a whirlwind year! But in these six months, we’ve released Caddy 2.0, 2.1, and are soon releasing 2.2, along with updated website features and docs. We’ve already been operating with the new ownership for over half a year now.</p>
</li>
<li>
<p>The ownership change includes <a href="https://github.com/caddyserver/certmagic">CertMagic</a>, which was moved into the <code>caddyserver</code> organization on GitHub when the change occurred six months ago.</p>
</li>
<li>
<p>Everything else about the project continues as normal. There are no user- or community-facing changes.</p>
</li>
<li>
<p>I continue to work on Caddy full-time. This would not be possible without apilayer, Ardan Labs, and all other sponsors (thank you)!</p>
</li>
<li>
<p>Ardan Labs is still the exclusive support contractor for the Caddy project. Businesses are encouraged to get a support plan or contract Caddy-related development through Ardan Labs, with whom I consult.</p>
</li>
<li>
<p>Several members of our community continue to act as maintainers and packagers, just as before. Thank you to them for their dedicated involvement!</p>
</li>
</ul>

<p>After the Caddy project grew more than I could handle in ~2016, I applied for an award from Mozilla for developing software that helps advance privacy and security on the Internet, which amazingly was granted and allowed me to work on Caddy full-time for about 6 months.</p>
<p>For longer-term sustainability, I later moved to monetize its commercial user base with both professional services and a unique licensing plan for custom-made binaries distributed through the Caddy website. Mistakes were made (both by myself and a vocal minority of the user base – or at least some armchair observers) and that model didn’t achieve the sustainability I had hoped for. Not many people know this, but the project actually came close to shutting down after that because I was starting grad school and couldn’t handle its growth together with my research and studies without some sustainability to front it.</p>
<p>After consulting with some trusted friends, mentors/colleagues, and professors, I decided not to pull the plug and instead applied Caddy to academic research through some projects in grad school, such as embedding CT monitors into web servers. Another one of these was telemetry, which allowed us to observe the conditions of clients on the Internet – including the first wide-spread production server-side measurements of MITM attacks – without being confined to proprietary networks. Contrary to popular belief (sigh), it didn’t collect any personal information or IP addresses; just benign technical data that was in plaintext on the wire or basic counts of things like which features of the server were used most often. Unfortunately this was also not well-received (and was expensive), despite other software such as Windows, Firefox, Chrome, VS Code, and many other programs that continue to implement much more aggressive and detailed telemetry, and I was more or less forced to shut it down a year or two later after counting trillions of connections.</p>
<p>From its various research applications, we learned that automatic CT monitoring can be a valuable asset (one even worth paying for) and that MITM is more widespread on the Internet than you’d think. (Cloudflare later deployed <a href="https://blog.cloudflare.com/monsters-in-the-middleboxes/">a similar MITM measurement</a> at a larger scale of course, but it is limited to their proprietary network. And nobody complained about this like they did with Caddy, but <a href="https://malcolm.cloudflare.com/">the MALCOM dashboard doesn’t load for me anymore</a> for some reason. Is Cloudflare starting to develop Google-like habits?)</p>
<p>After completing my graduate degree last year, I approached several companies to see if they’d be interested in hiring me to work on Caddy full-time, to the mutual benefit of them and many of their customers who use and rely on it. If I couldn’t find one, I’d have to take a likely-unrelated position and Caddy would have to take the back-seat. Fortunately, more than one company was interested! I accepted an offer with Ardan Labs and under their auspices built Caddy 2.</p>
<p>I’m pleased to say that Caddy 2.0 was designed and developed right on schedule: in just about 12 months we went from design drafts to prototypes to betas to final release. It’s amazing what providing for one full-time developer can accomplish! I am thankful to Ardan Labs for that opportunity.</p>
<p>Near the end of the Caddy 2 development cycle, we received an offer from apilayer that worked to our mutual advantage. All three parties came to agreeable terms and the Caddy project is well on our way to continued development and growth. I have at least a two year contract with apilayer to work on Caddy full-time!</p>
<p>During the negotiations I made it very clear that open source is crucial to Caddy’s success, and I was relieved that Julian (apilayer) balked at the possibility of making it anything but open source. <img src="https://caddy.community/images/emoji/apple/slight_smile.png?v=9" title=":slight_smile:" alt=":slight_smile:"> It was very clear that keeping Caddy open source is a core value for all of us.</p>

<p>Ardan Labs continues to be the trusted partner to support businesses using Caddy. We recommend that all businesses using Caddy <a href="https://caddyserver.com/business">get a support plan</a> so that they can become familiar with your deployments and offer assistance if needed. There are also options for custom development contracts.</p>

<p>It’s clear to me that sponsorships are probably the best way to ensure the sustainability of the project in the long run, rather than fiddling with licensing or taking on enterprise support by myself (Ardan Labs is our partner for enterprise clients).</p>
<p>I continue to rely on sponsorships for ongoing full-time development of Caddy, with apilayer being the premier corporate sponsor. I am able to prioritize features and bug fixes for sponsors, as well as extending a special invite to our Slack community for Caddy developers/maintainers. Right now, sponsors also get exclusive <a href="https://github.com/mholt/conncept">early access to Project Conncept</a>, a layer 4 (TCP/UDP) app for Caddy! When we reach 50 sponsors, I’ll be able to make it public!</p>
<p>I’ll be enhancing sponorship perks later this year as well, so stay tuned for more on that.</p>
<p><strong>You can sponsor me through GitHub: <a href="https://github.com/sponsors/mholt">https://github.com/sponsors/mholt</a></strong></p>
<p>If you aren’t able to sponsor right now, that’s okay: the next best thing you can do to help the project is to use Caddy and help others to use it, too. <a href="https://caddy.community/">Join our community</a> and help answer people’s questions! You can also share the project so more people know about it. If you’re experienced with Go, we’re always looking for committed maintainers to the code base; or if you’re good at websites, we could use help to improve ours! Similarly, we need help with packaging, distribution, and several other side projects. There’s a lot to be done! The project wouldn’t be where it is without the assistance of the community.</p>
<p>Thank you for your support, and for using Caddy! As we continue to work on it together, I hope it serves you well for many years to come.</p>
        </div></div>]]>
            </description>
            <link>https://caddy.community/t/caddy-and-certmagic-have-new-ownership-no-changes-to-licensing-or-development/9754?u=matt</link>
            <guid isPermaLink="false">hacker-news-small-sites-24434770</guid>
            <pubDate>Thu, 10 Sep 2020 17:50:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kuma and Envoy: Multi-Cluster and Multi-Cloud Service Meshes]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24434618">thread link</a>) | @fosk
<br/>
September 10, 2020 | https://kuma.io/blog/2020/multi-cluster-cloud/ | <a href="https://web.archive.org/web/*/https://kuma.io/blog/2020/multi-cluster-cloud/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <div> <p><span><time datetime="2020-09-10T00:00:00.000Z">
  Sep 10, 2020
</time></span> <span>/</span> <span>
              9 min read
            </span></p></div></div><div><!----> <div><div><p>When we first created Kuma – which means "bear"&nbsp;in Japanese – we dreamed of creating a service mesh that could run across every cluster, every cloud and every application. These are all requirements that large organizations must implement to support their application teams across a wide variety of architectures and platforms: VMs, Kubernetes, AWS, GCP and so on.</p> <p>With Kuma – now a CNCF project and at the time of this writing, the only Envoy-based service mesh donated and accepted by the foundation – we have relentlessly executed on this vision with the community.</p> <p>Starting from Kuma 0.6, which was released this summer with a new advanced multi-zone capability, Kuma now supports every cloud vendor, every architecture and every platform together in a multi-mesh control plane. When deployed in a multi-zone deployment, Kuma abstracts away both the synchronization of the service mesh policies across multiple zones and the service connectivity (and service discovery) across those zones. A zone can be a Kubernetes cluster, a data center, a cloud region, a VPC, a subnet and so on – we can slice and dice zones to our liking, and we can also mix Kubernetes and VM workloads into one distributed mesh deployment.</p> <p><img src="https://2tjosk2rxzc21medji3nfn1g-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/diagram-02-1536x779.jpg" alt=""></p> <center><i>
Kuma creates a service connectivity overlay across hybrid infrastructure to discover and connect services automatically, including hybrid Kubernetes + VM services.
</i></center> <p>This <a href="https://kuma.io/docs/latest/documentation/deployments/#multi-zone-mode" target="_blank" rel="noopener noreferrer">multi-zone capability</a> has been added in addition to the <a href="https://kuma.io/docs/latest/policies/mesh/" target="_blank" rel="noopener noreferrer">multi-mesh support</a> that Kuma introduced since day one to create multiple isolated meshes on the same cluster (with dedicated mTLS CAs) in order to reduce team coordination, increase isolation and improve security rather than one large service mesh that everybody is sharing. Also, since multi-zone leverages the first-class K8s + VM support that shipped since the first version of Kuma, all teams and workloads in the organizations can benefit from service mesh and not just our greenfield initiatives.</p> <p>A Kuma service mesh distributed across every cloud, cluster and workload that the teams are using can therefore be managed from one individual cluster of Kuma itself. Meanwhile, multiple service meshes can be virtually provisioned on one Kuma control plane (horizontally scalable) to simplify mesh management across the organization – very similar to how Kubernetes and its namespaces work.</p> <p><img src="https://2tjosk2rxzc21medji3nfn1g-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/diagram-one-cluster-new@2x.png" alt=""></p> <center><i>
Kuma supports multiple virtual meshes on the same Kuma deployment, removing the requirement of having multiple service mesh clusters for each application and therefore lowering the ops costs significantly.
</i></center> <h3 id="extending-xds-with-kds"><a href="#extending-xds-with-kds">#</a> Extending xDS With KDS</h3> <p>In Kuma, we can deploy a distributed service mesh running across multiple clusters, clouds or regions by leveraging the “multi-zone” deployment mode. The “multi-zone” deployment is a new way of running Kuma that has been introduced in v0.6+ in addition to the “standalone” deployment mode (one service mesh per zone).</p> <p>In a multi-zone deployment, there are a few important features that Kuma provides:</p> <ol><li>There are two control plane modes: global and remote. This is quite unique in the service mesh landscape.</li> <li>There is a new DNS “.mesh” zone for service discovery.</li> <li>There is a new “Ingress” data plane proxy type that enables connectivity between zones within a Kuma mesh.</li></ol> <p>In a distributed deployment, the “global” control plane will be in charge of accepting Kuma resources to determine the behavior of the service mesh via either native Kubernetes CRDs or vanilla YAML in VM-based deployments. It will be in charge of propagating these resources to the “remote” control planes – one for each zone that we want to support.</p> <p>The “remote” control planes are going to be exchanging Kuma resources with the “global” control plane over an extension of the Envoy xDS API that we called KDS (Kuma Discovery Service) over a gRPC protocol, and therefore, over HTTP/2. The “remote” control planes are also going to be accepting requests from the Envoy-based data plane proxies that belong to the same zone over traditional xDS.</p> <p><img src="https://2tjosk2rxzc21medji3nfn1g-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/diagram-01-1536x1316.jpg" alt=""></p> <center><i>
The remote control planes also embed a DNS service discovery that can be used to discover services across different zones. The above architecture can be easily installed in just a few steps using either the Kuma CLI “kumactl” or HELM charts.
</i></center> <p>In Kuma, we abstract away the Envoy proxy process in a “kuma-dp” process so that the user never directly configures or starts “envoy”, therefore making the whole process of starting a data plane proxy much easier. Advanced users can still access the underlying “envoy” process if they want to.</p> <p>By leveraging the native xDS API of Envoy to connect “kuma-dp” with “remote” control planes in every zone as well as leveraging KDS to connect the “remote” control planes to the global control plane, effectively we have gRPC communication enabled across the entire service mesh infrastructure stack in a consistent way.</p> <p>The “global” and “remote” architecture has a few benefits:</p> <ol><li>We can scale each zone independently by scaling the “remote” control planes and achieve HA in case one zone experiences issues.</li> <li>There is no single point of failure: even if the “global” control plane goes down, we can still register and deregister data plane proxies on the “remote” ones, and the most updated addresses of every service can still be propagated to other Envoy-based sidecars.</li> <li>The “global” control plane allows us to automatically propagate the state across every zone, while at the same time making sure that the “remote” control planes are aware of each zone’s Kuma ingress in order to enable cross-zone connectivity.</li></ol> <p>The control plane separation governs how Kuma resources (like meshes and policies) are synchronized across the zones, but it requires two other components in order to enable discovery and connectivity at the data plane layer across our zones in an automated way: service discovery and the “ingress” data plane proxy mode.</p> <h3 id="cross-zone-discovery-and-connectivity"><a href="#cross-zone-discovery-and-connectivity">#</a> Cross-Zone Discovery and Connectivity</h3> <p>Like we described, a multi-zone deployment can be used to deploy a distributed service mesh across multiple clouds and clusters, as well as to enable seamless communication between services running in different zones, effectively providing cross-zone service discovery and connectivity.</p> <p>Among other use cases, cross-zone connectivity is useful for:</p> <ul><li>Enabling high availability across multiple Kubernetes clusters, regions and availability zones in both single and multi-cloud environments</li> <li>Enabling traffic shifting from one zone to another for disaster recovery</li> <li>Enabling a step-by-step transition of our applications from VMs to Kubernetes – or from physical data centers to the cloud – by leveraging traffic control policies to determine the conditions under which service traffic should be shifted from one zone to another.
Kuma’s multi-zone deployment enables cross-zone connectivity by providing two important features:</li></ul> <ol><li>A new “ingress” data plane proxy mode processes incoming traffic into a zone. There will be one Kuma ingress deployment per zone, that can be scaled horizontally as the traffic increases. The “ingress” data plane mode is being added in addition to the default proxying one and the “gateway” one (to support third-party API gateways). Because of the new “ingress” mode, Kuma doesn’t require a flat networking topology between zones and can support more complex infrastructure.</li> <li>A built-in service discovery DNS server resolves the address of a service to either an IP address of a replica in the same zone or the address of an ingress proxy in another zone.
Likewise with the “global” and “remote” control planes, the ingress and the DNS service discovery can also be installed in one click by following the <a href="https://kuma.io/docs/latest/documentation/deployments/#multi-zone-mode" target="_blank" rel="noopener noreferrer">multi-zone instructions</a> on Kuma.</li></ol> <p>When it comes to service discovery, Kuma creates a “.mesh” DNS entry on the built-in DNS resolver that can be used to resolve services across the same zone or in other zones, effectively “flattening” the discovery of services across a complex infrastructure. Kuma will – accordingly to the traffic routing policies that have been configured – determine if we should be consuming a replica of the service in the local zone or if we should resolve the request to the IP address of a Kuma ingress in another zone, which will then leverage SNI to determine what service has been requested and route the request accordingly.</p> <p><img src="https://2tjosk2rxzc21medji3nfn1g-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/diagram-03.jpg" alt=""></p> <center><i>
In this example, we have three services (users, invoices and billing). Requests to “invoices.mesh” will be proxied to an IP address within the same zone, whereas requests to “billing.mesh” will be <b>automatically</b> proxied to an ingress of another zone.
</i></center> <p>Since SNI resolution is mandatory for cross-zone communication, the <a href="https://kuma.io/docs/latest/policies/mutual-tls/" target="_blank" rel="noopener noreferrer">mTLS policy</a> must be enabled on the mesh. Also, since Kuma already knows where all the services are running,  cross-zone discovery and connectivity happen automatically.</p> <p>When a new service is registered into Kuma, a new “kuma.io/zone” tag is added to the data plane definition so that we can use the <a href="https://kuma.io/docs/latest/documentation/dps-and-data-model/#tags" target="_blank" rel="noopener noreferrer">attribute-based policy selectors</a> to configure Kuma policies like <a href="https://kuma.io/docs/latest/policies/traffic-route/" target="_blank" rel="noopener noreferrer">Traffic Route</a> to determine the behavior of cross-zone traffic (blue/green or canary across different zones, weighted traffic, as well as traffic shifting).</p> <p>When consuming any “{service-name}.mesh” on default port 80 (even if the service is not listening on port 80), the DNS resolver – in addition to resolving the address of the service – will also automatically resolve the port of the destination service and inject it into the connection in order to keep the uptime of the overall connectivity even when a team decides to re-assign ports of a service that other teams may be using. This feature reduces the team coordination required to maintain a large number of services and connections in a Kuma mesh.</p> <h3 id="conclusion"><a href="#conclusion">#</a> Conclusion</h3> <p>Thanks to the new multi-zone capability that Kuma provides since v0.6+, we can now easily run a service mesh across multiple Kubernetes clusters, clouds and regions. Since Kuma natively supports both containerized and VM workloads, this …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kuma.io/blog/2020/multi-cluster-cloud/">https://kuma.io/blog/2020/multi-cluster-cloud/</a></em></p>]]>
            </description>
            <link>https://kuma.io/blog/2020/multi-cluster-cloud/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24434618</guid>
            <pubDate>Thu, 10 Sep 2020 17:35:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Anatomy of a Rule]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24434450">thread link</a>) | @gneray
<br/>
September 10, 2020 | https://www.osohq.com/post/anatomy-of-a-rule | <a href="https://web.archive.org/web/*/https://www.osohq.com/post/anatomy-of-a-rule">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h2>Introduction</h2><p>Authorization is an interesting domain in that it so frequently blurs the distinctions that we often draw between data and code. Sometimes a rule expresses a piece of data directly, such as who may do what to which resource. Other times a rule expresses logic, or code: this actor may do that to some resource <em>if</em> certain other conditions are also met, such as the actor or resource belonging to some model type. To handle complex authorization policies, a system should handle both points of view efficiently and naturally, and in this post we'll show how we aimed to do that when building <a href="https://www.osohq.com/">oso</a>, an open-source policy engine for authorization.</p><h2>Rules as Data</h2><p>An authorization policy specifies the requirements for authorization as <em>rules</em>. The rules may be in the form of permissions <em>data</em>, like an ACL: a (long) list of who can do what. In its simplest form, this may be only a few bits per rule, such as in traditional Unix file permissions. Or it may come in the form of a matrix like this one:</p><p>{% c-block language="polar" %}<br>allow,alice,read,/reports/alice/<br>allow,alice,read,/reports/bob/<br>allow,bhavik,read,/reports/bhavik/<br>allow,bob,read,/reports/bob/<br>allow,marjory,read,/reports/alice/<br>allow,marjory,read,/reports/bhavik/<br>allow,marjory,read,/reports/bob/<br>allow,marjory,read,/reports/marjory/<br>{% c-block-end %}</p><p>This matrix encodes which users of a system may access what paths. Here we've chosen to represent the matrix as CSV, but the encoding is irrelevant; this kind of authorization data is easily encoded in any authorization system, or handled directly by application code.</p><p>Another way to encode this kind of matrix is as a list of simple rule definitions, one per row:</p><p>{% c-block language="polar" %}<br>allow("alice", "read", "/reports/alice/");<br>allow("alice", "read", "/reports/bob/");<br>allow("bhavik", "read", "/reports/bhavik/");<br>allow("bob", "read", "/reports/bob/");<br>allow("marjory", "read", "/reports/alice/");<br>allow("marjory", "read", "/reports/bhavik/");<br>allow("marjory", "read", "/reports/bob/");<br>allow("marjory", "read", "/reports/marjory/");<br>{% c-block-end %}</p><p>Here the encoding is the <a href="https://docs.osohq.com/using/polar-syntax.html">oso rule language, Polar</a>, but again the encoding is not really germane. The point is that what we previously thought of as data has now become code in a declarative programming language. It's not very interesting code, but it is simple and direct, and makes an easy target for translation from nearly anything else. We'll come back and make it more interesting shortly, but let's take it on its own terms for now.</p><p>Since this policy is primarily data and we are treating it as such, we will undoubtedly run into inherent problems around handling data. For example, what happens as the permissions matrix grows in size? Even with naïve algorithms, a small matrix should pose no performance problem. But as with any other type of data, the tools needed to cope with it vary as the data grows. If the list is very large or if frequent dynamic updates are required, some kind of database is going to be most appropriate.</p><p>What we've done in oso is made it so that you shouldn't need to <em>prematurely</em> deal with these issues. By the time performance becomes a limiting factor, it should be the case that other data management problems are more pressing.</p><p>To handle largish data-heavy policies with oso, we implemented a simple indexing scheme over constant data. The speedups come from eliminating most or all rules from consideration up front with just a few hash lookups. We have seen it deliver very large speedups in authorization decisions on certain kinds of realistic policies, and <a href="https://osohq.github.io/oso/dev/bench/">our microbenchmarks</a> confirm the expected behavior.</p><p>We call this the <em>pre-filter</em>, since its job is to keep the "main" filter — the general rule selection and sorting process we'll discuss shortly — from even considering most rules. It is able to do its job by considering the parts of rules purely as data, while still respecting the semantics of the rules as code.</p><h2>Rules as code</h2><p>Data used to make authorization decisions is never random, and so almost always has exploitable structure. As usual in technology, we can exploit that structure through <em>abstraction</em>.</p><p>Let's look again at our simple permissions matrix. One simple pattern that should be evident is captured by the informal rule "etheveryone may read their own reports". We can capture this formally with oso as:</p><p>{% c-block language="polar" %}<br>allow(actor: String, "read", resource: String) if<br> &nbsp; &nbsp;resource.split("/") = ["", "reports", actor, ""];<br>{% c-block-end %}</p><p>This rule is universally quantified over all string-valued actors and resources, and so replaces a potentially infinite set of data rules. If we wish to quantify over more specific classes of actors and resources from our application, we can refine the type restrictions:</p><p>{% c-block language="polar" %}<br>allow(actor: Reporter, "read", resource: Report) if<br> &nbsp; &nbsp;resource.author = actor;<br>{% c-block-end %}</p><p>This allows extremely fine-grained decisions without a large blowup in policy size.</p><p>These kinds of rules behave very differently than the data rules we saw earlier. They may have data embedded in them (e.g., the {% c-line %}"read"{% c-line-end %} action, the {% c-line %}"reports"{% c-line-end %} path segment), but they are inherently <em>code</em>. These rules are <em>executed</em> or <em>called</em> with a list of arguments as part of an authorization query, not just <em>matched</em> as data. They may contain arbitrary logical expressions, which are encoded here as Horn clauses, but once again the encoding is inessential — the essential feature is the <em>interpretation</em> process, where the rules are treated as meaning-bearing expressions of a logical language rather than opaque or "quoted" data. Types or classes in such a language denote structured sets of data, semantically related through subtyping.</p><p>The inherent problems of handling code are well known, and solving them is our daily bread &amp; butter as software developers. All of the fundamental techniques developed over the years to handle these issues — abstraction, modularity, types, etc. — are relevant and useful in the authorization domain.</p><p>What we've done with oso is to make not only the application's data, but also its code and abstractions available in the DSL. Let's take types as an example. We saw above how types <em>defined by the application</em> can be used to make specialized authorization decisions: by annotating parameters with a {% c-line %}parameter: Type{% c-line-end %} <em>specializer</em>, and then using our knowledge of the type in the body of the rule to call specific methods or access certain attributes.</p><p>To support this particular abstraction, the system must do some work under the hood. For each specializer, query-time machinery must check whether a given argument is of the specialized type; we use a foreign function interface (FFI) to call into the application for an answer. Rules with parameter lists that match the given arguments are in this way selected or <em>filtered</em> from the list of possible rules.</p><p>After the applicable rules have been selected, we must then decide in what order to execute them. Sometimes it doesn't matter, but in the presence of exceptions and overrides for specific classes, it can. We therefore <em>sort</em> the applicable rules by specificity (i.e., by whether one type is more specific than another with respect to a given argument), and execute the most specific rule first. This allows more specific rules to selectively override less specific ones.</p><p>This filtering and sorting process is relatively slow compared to an index lookup. This is what makes the pre-filter we discussed earlier so effective in speeding up data-heavy policies; the fewer rules that need to be selected for applicability and sorted, the faster the call sequence executes. But in exchange for a somewhat expensive calling sequence, we can leverage available abstractions over our data, namely the types in our domain model. And by utilizing optimizations from our view of rules as data, we can make them affordable in realistic policies that freely mix code with data.</p><h2>Rules Redux</h2><p>We have now seen authorization rules from two points of view. Viewed as code, rules are interpreted or run, and so have an essentially dynamic character. Viewed as data, they may be indexed ahead of time, thus exploiting their static characteristics. So which is it? Are rules code or data, fish or fowl?</p><p>The answer of course, is both: code and data are dual, and no one point of view is primary. But switching points of view can sometimes lead us to opportunities for optimization that may be hard to see from the other, and knowing when you're dealing with which makes it easier to reason about trade-offs and which techniques to apply.</p></div></div></div>]]>
            </description>
            <link>https://www.osohq.com/post/anatomy-of-a-rule</link>
            <guid isPermaLink="false">hacker-news-small-sites-24434450</guid>
            <pubDate>Thu, 10 Sep 2020 17:22:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Four Indian Startups Funded via Abu Dhabi's AWI Fund (Middle East AI News)]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24434248">thread link</a>) | @asiaainews
<br/>
September 10, 2020 | https://www.getrevue.co/profile/middleeastainews/issues/more-awi-fund-deals-disclosed-saudi-ai-strategy-to-be-launched-in-oct-275360 | <a href="https://web.archive.org/web/*/https://www.getrevue.co/profile/middleeastainews/issues/more-awi-fund-deals-disclosed-saudi-ai-strategy-to-be-launched-in-oct-275360">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.getrevue.co/profile/middleeastainews/issues/more-awi-fund-deals-disclosed-saudi-ai-strategy-to-be-launched-in-oct-275360</link>
            <guid isPermaLink="false">hacker-news-small-sites-24434248</guid>
            <pubDate>Thu, 10 Sep 2020 17:05:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Facebook to stop moving data from EU to US: things you need to know]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24434196">thread link</a>) | @pujjad
<br/>
September 10, 2020 | https://www.politico.eu/article/facebook-data-ireland-privacy/ | <a href="https://web.archive.org/web/*/https://www.politico.eu/article/facebook-data-ireland-privacy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
							
							
							

							
							<div id="amazon-polly-audio-table">
				<p>Press play to listen to this article</p>
				
		</div><p>The countdown is on.</p>
<p>Facebook <a href="https://www.politico.eu/article/facebook-privacy-data-us/">will be forced</a> to stop moving data from its European users to the United States as early as next month after Ireland's data protection watchdog told the social networking giant that its current means of transferring digital information across the Atlantic is illegal.</p>
<p>The company still has a few weeks to appeal the preliminary ruling. But the decision deals a blow to billions of euros in digital trade annually between two of the world's largest trading blocs. The moratorium on Facebook's data transfers to the U.S. will also likely apply to other companies that regularly move such digital information from Europe to outside the bloc.</p>
<p>For Facebook users in Europe, the pending decision could allow them greater security that their data is not collected by U.S. intelligence agencies, and their use of the world's largest social network is not likely to be affected — at least in the short term. Yet questions remained about how their data will be handled when they interact with other users outside the 27-country bloc, say, sending a friend request or Instagram comment to a friend or family member in the U.S.</p>
<p>Ireland's move also represents a victory for a yearslong campaign by privacy activists who claim that U.S. national security agencies play fast and loose with data from non-American citizens when it's moved to the U.S. by companies like Facebook and Google. Washington denies those allegations.</p>
<blockquote><p>Expect Dublin to rule that Facebook must stop using these legal mechanisms and for the social networking giant to appeal that decision in an Irish court.</p></blockquote>
<p>Dublin's decision against Facebook — it still must be approved by the European Union's other national privacy agencies — stems directly from a ruling by the Court of Justice of the European Union (CJEU), the bloc's highest court, in July that <a href="https://www.politico.eu/article/eu-court-strikes-down-privacy-shield/">decreed Washington did not provide sufficient protections</a> for EU citizens when their data is transferred to the U.S.</p>
<p>But as with everything to do with Europe's privacy regime, things are a little complicated. Here's what you need to know:</p>
<h3>Data transfers will continue, but for how long?</h3>
<p>Facebook is adamant that its data transfers are legal. <a href="https://about.fb.com/news/2020/09/securing-the-long-term-stability-of-cross-border-data-flows/" target="_blank">In a statement,</a> Nick Clegg, the company's chief lobbyist, said: "We will continue to transfer data in compliance with the recent CJEU ruling and until we receive further guidance."</p>
<p>The company currently uses so-called standard contractual clauses, or complex legal mechanisms, to move data across the Atlantic. After Ireland raised concerns about these clauses in the wake of the July judgment from Europe's highest court, the company said it had added additional safeguards like data encryption to comply with the region's privacy standards. Facebook says such changes mean it can still use these data-transfer mechanisms to send information to the U.S.</p>
<p>But Ireland's privacy regulator has told the company the use of such clauses is still illegal because of the lack of privacy protections in the U.S. as outlined by Europe's highest court. Facebook disagrees, saying Europe's data protection agencies must offer guidance on how these clauses can be tweaked to comply with EU privacy law.</p>
<p>What does that mean? Expect Dublin to rule that Facebook must stop using these legal mechanisms and for the social networking giant to appeal that decision in an Irish court. The legal wrangling could drag on well into 2021 and beyond.</p>
<h3><strong>Privacy campaigner not happy</strong></h3>
<p>Strangely, Max Schrems, the Austrian privacy lawyer who brought the initial complaint in Ireland against Facebook, is not a happy man.</p>
<p>After Facebook publicly confirmed Dublin's preliminary decision to outlaw its transatlantic data transfers, he <a href="https://noyb.eu/en/dpc-actually-stopping-facebooks-eu-us-data-transfers-maybe-half-way" target="_blank">published a series of documents</a> alleging the company was trying to find alternatives to keep moving digital information to the U.S. Schrems also claimed that Ireland's Data Protection Commissioner was not investigating Facebook's new data-transfer arrangements, but did not provide concrete evidence to prove that assertion.</p>
<p>A spokesman for Ireland's privacy agency declined to comment.</p>
<p>The Austrian added he would be taking further legal action in Ireland to ensure the agency complies with EU privacy rules.</p>
<h3>First Facebook, second everyone else</h3>
<p>Other companies are keeping a close eye on what happens with the social network's data transfers because many are also reliant on standard contractual clauses to move digital information from Europe to the U.S. and elsewhere.</p>
<p>If Dublin's preliminary decision against Facebook is approved, it will set a precedent and force tech giants like Google and smaller firms across the region to reconsider how they move digital information to the U.S.</p>
<p>Previously, companies could have used the so-called EU-U.S. Privacy Shield regime, a transatlantic agreement that Europe's highest court has now struck down. If standard contractual clauses are also taken off the table (each company's legal mechanism would have to be reviewed independently before a final decision), that means there will be few, if any, legal means to move data from Europe to the U.S.</p>
<p>That would have an immediate knock-on effect on hundreds of billions of euros of annual trade and would hearten privacy groups that have long believed the U.S. national security regime was too data-hungry.</p>
<h3><strong>Keeping data in Europe looks more and more alluring</strong></h3>
<p>Though data transfers out of Europe haven’t themselves been banned, the insistence by Europe's highest court that they involve “supplementary measures,” and assessment of destination countries’ data protection regimes has had companies and regulators alike scratching their heads.</p>
<p>So far, talk of additional safeguards has revolved mostly around encryption, but there are question marks over whether this would really halt U.S. snooping in practice.</p>
<p>A once-taboo option that is gaining traction is to halt transfers altogether and to keep data in Europe.</p>
<p>Data localization — as the practice is called — <a href="https://www.politico.eu/article/privacy-shield-is-dead-long-live-data-localization/">is seen as the antithesis of the global internet</a> envisioned by the West, but would remove many of the legal headaches facing companies. The policy also has support from on high, with Europe’s Internal Market Commissioner Thierry Breton <a href="https://www.politico.eu/article/breton-wants-tiktok-data-to-stay-in-europe/">saying numerous times</a> that he wants data stored and processed on the Continent.</p>
<h3><strong>Another transatlantic data deal looks unlikely (for now)</strong></h3>
<p>Both Europe and the U.S. were quick to the negotiating table following the annulment of the Privacy Shield. A joint press release in July from EU justice chief Didier Reynders and U.S. Secretary of Commerce Wilbur Ross said that they were working toward an “enhanced” data-sharing deal.</p>
<p>But that may be a long time coming, if at all.</p>
<p>Any deal that does not significantly bolster the protection of European’s data from U.S. snooping is likely to get struck down in court. Reynders, the EU official, has said that a new deal <a href="https://www.politico.eu/?p=1447172">may need “legislative changes”</a> from the U.S. to avoid further legal uncertainty</p>
<p>But U.S. officials say it's impossible to get such legislative changes through Washington before November's presidential election and question how feasible it will be to rewrite U.S. laws to appease European privacy standards.</p>
<p><em>Want more analysis from </em><span>POLITICO</span><em>? </em><span>POLITICO</span><em> Pro is our premium intelligence service for professionals. From financial services to trade, technology, cybersecurity and more, Pro delivers real time intelligence, deep insight and breaking scoops you need to keep one step ahead. Email <a href="mailto:pro@politico.eu" target="_blank">pro@politico.eu</a> to request a complimentary trial.</em></p>

							
							
							<!--/.story-supplement-->

						</div></div>]]>
            </description>
            <link>https://www.politico.eu/article/facebook-data-ireland-privacy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24434196</guid>
            <pubDate>Thu, 10 Sep 2020 16:59:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Intercepting Zoom's encrypted data with BPF]]>
            </title>
            <description>
<![CDATA[
Score 256 | Comments 65 (<a href="https://news.ycombinator.com/item?id=24434031">thread link</a>) | @aaron-santos
<br/>
September 10, 2020 | https://confused.ai/posts/intercepting-zoom-tls-encryption-bpf-uprobes | <a href="https://web.archive.org/web/*/https://confused.ai/posts/intercepting-zoom-tls-encryption-bpf-uprobes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I originally wrote an earlier version of this post at the end of March, when I was working on adding uprobes support to <a href="https://github.com/redsift/redbpf">redbpf</a>. I wanted to blog about the work I was doing and needed an application to instrument for the purpose of this post. At that time Zoom's popularity was rising quickly, and I happened to read somewhere that it supported this creepy attention tracking feature that allowed meeting hosts to monitor if attendees were paying attention. I figured I could try to use uprobes to snoop into the data Zoom was sending to their servers and see how the tracking worked.</p><p>But then Zoom quickly started getting under a lot of fire. <a href="https://en.wikipedia.org/wiki/Zoombombing">Zoombombing</a> became a thing, several security issues were discovered and pretty much everyone started piling on the company. Considering all that, I was advised and ultimately decided not to publish the post.</p><p>Now things seem to have settled, Zoom <a href="https://blog.zoom.us/a-message-to-our-users/">improved their security</a> and by popular demand <a href="https://support.zoom.us/hc/en-us/articles/115000538083-Attendee-attention-tracking">got rid of attention tracking</a>. So I think I can finally publish this! I edited out the part about attention tracking (which no longer exists) and a couple of other things that could potentially get me in trouble.</p><p><strong>TLDR:</strong> I wrote a command line tool that uses BPF uprobes to intercept the TLS encrypted data that zoom sends over the network, and here I'm going to show the process I went through to write it. After I wrote this post I made the tool generic so that it can now instrument any program that uses OpenSSL. I published the code at <a href="https://github.com/alessandrod/snuffy">https://github.com/alessandrod/snuffy</a>.</p><h2>Instrumenting applications with uprobes</h2><p>Uprobes let you instrument user space applications by attaching custom code to arbitrary locations inside a target process. It's a bit like running an application in a debugger, setting breakpoints and fiddling around, but programmatically and without the overhead of a debugger.</p><p>An uprobe must be <a href="https://ingraind.org/api/cargo_bpf/#building">compiled</a> and <a href="https://ingraind.org/api/redbpf/load/struct.Loader.html">loaded</a> like any other BPF program, then it can be attached with the following API:</p><pre><code><span>pub</span><span> </span><span>fn</span><span> </span><span>attach_uprobe</span><span>(</span><span>
</span><span>    </span><span>&amp;</span><span>mut</span><span> </span><span>self</span><span>,</span><span>
</span><span>    fn_name</span><span>:</span><span> </span><span>Option</span><span>&lt;</span><span>&amp;</span><span>str</span><span>&gt;</span><span>,</span><span>
</span><span>    offset</span><span>:</span><span> </span><span>u64</span><span>,</span><span>
</span><span>    target</span><span>:</span><span> </span><span>&amp;</span><span>str</span><span>,</span><span>
</span><span>    pid</span><span>:</span><span> </span><span>Option</span><span>&lt;</span><span>pid_t</span><span>&gt;</span><span>,</span><span>
</span><span></span><span>)</span><span> </span><span>-&gt;</span><span> </span><span>Result</span><span>&lt;</span><span>(</span><span>)</span><span>&gt;</span><span>;</span></code></pre><p><a href="https://ingraind.org/api/redbpf/struct.UProbe.html#method.attach_uprobe">attach_uprobe()</a> parses the <code>target</code> ELF binary or shared library, looks up the function <code>fn_name</code>, and once the target is running it injects the probe code at the resolved address. If <code>offset</code> is non-zero, its value is added to the address of <code>fn_name</code>. If <code>fn_name</code> is <code>None</code>, then <code>offset</code> is interpreted as starting from the beginning of the target's <code>.text</code> section. Finally if a <code>pid</code> is given, the probe will only be attached to the process with the given id.</p><p>In the rest of the post I'm going to show some examples of uprobes, focusing on the code that gets compiled to BPF bytecode, loaded in the kernel and then injected in the target process (in our case zoom). I'm not going to show much of the user-space code that loads the probes. That part is pretty standard rust code that does some setup, then prints out the data coming from the probes as it receives it. If you're interested you can still find all the user-space code at <a href="https://github.com/alessandrod/snuffy/blob/master/src/main.rs">https://github.com/alessandrod/snuffy/blob/master/src/main.rs</a>.</p><h2>Poking into Zoom</h2><p>We're going to use uprobes to inspect the network traffic between the zoom client and the company's servers. Zoom uses <a href="https://en.wikipedia.org/wiki/Transport_Layer_Security">Transport Layer Security</a> to encrypt the data. In order to intercept the <em>unencrypted</em> data, we need to find out which TLS library is used by the client, then attach uprobes to strategic places inside it.</p><p>Let's start with searching for common TLS symbols using <code>objdump</code>:</p><pre><code><span>$ objdump -CT /opt/zoom/zoom | grep -iE "ssl|gnutls"
</span>000000000080d5b0 g    DF .text	0000000000000013  Base        PreMeetingUIMgr::sig_blockUnknownSSLCertChanged()
<!-- -->000000000080d590 g    DF .text	0000000000000013  Base        PreMeetingUIMgr::sig_sslCertWarningChanged()
</code></pre><p>Those look like callbacks that get invoked when a certificate is invalid, and Zoom does indeed show a warning if you try to intercept its traffic with a tool like <code>mitmproxy</code>. The callbacks deal with certificates, not unencrypted buffers, so they are not useful to us.</p><p>Looking at the output of <code>ldd</code> we can see that Zoom links to <a href="https://doc.qt.io/qt-5/qtnetwork-index.html">Qt Network</a>, which includes some potentially relevant APIs:</p><pre><code><span>$ objdump -CT /opt/zoom/zoom | grep -iE "QNetworkReq"
</span>0000000000000000      DF *UND*	0000000000000000  Qt_5        QNetworkRequest::QNetworkRequest(QUrl const&amp;)
<!-- -->0000000000000000      DF *UND*	0000000000000000  Qt_5        QNetworkRequest::~QNetworkRequest()
<!-- -->0000000000000000      DF *UND*	0000000000000000  Qt_5        QNetworkAccessManager::get(QNetworkRequest const&amp;)
</code></pre><p><code>QNetworkRequest(QUrl const&amp;)</code> looks like something that could be used to communicate with the backend and does <a href="https://doc.qt.io/qt-5/qnetworkrequest.html#setSslConfiguration">support TLS</a>. I tried attaching to it and other functions exported by the framework but none of them turned out to be invoked. Zoom supports a number of platforms and devices, it's possible that they use Qt just for the UI on linux, and then have some lower level networking code that can be shared with their other clients.</p><p>At this point it is pretty likely that zoom is linking statically to the TLS library. Let's see if in the <code>.rodata</code> section of the binary there's anything that could point us in the right direction:</p><pre><code><span>$ readelf -p .rodata /opt/zoom/zoom | grep -i ssl | wc -l
</span>739
<!-- -->$ # 😏
<!-- -->$ readelf -p .rodata /opt/zoom/zoom | grep -i 'openssl 1'
<!-- -->  [4a1b66]  OpenSSL 1.1.1g  21 Apr 2020
<!-- -->  [58cd50]  OpenSSL 1.1.1g  21 Apr 2020
</code></pre><p>Aha! The client is using OpenSSL version 1.1.1g (knowing this will turn out to be very useful), and the library is statically linked.</p><h2>Instrumenting OpenSSL</h2><p>OpenSSL exports two functions named <a href="https://www.openssl.org/docs/man1.1.1/man3/SSL_read.html">SSL_read</a> and <a href="https://www.openssl.org/docs/man1.1.1/man3/SSL_write.html">SSL_write</a>, which have the following signature:</p><pre><code><span>int</span><span> </span><span>SSL_read</span><span>(</span><span>SSL </span><span>*</span><span>ssl</span><span>,</span><span> </span><span>void</span><span> </span><span>*</span><span>buf</span><span>,</span><span> </span><span>int</span><span> num</span><span>)</span><span>;</span><span>
</span><span></span><span>int</span><span> </span><span>SSL_write</span><span>(</span><span>SSL </span><span>*</span><span>ssl</span><span>,</span><span> </span><span>const</span><span> </span><span>void</span><span> </span><span>*</span><span>buf</span><span>,</span><span> </span><span>int</span><span> num</span><span>)</span><span>;</span></code></pre><p><code>SSL_read</code> reads encrypted data sent by a remote peer, decrypts it and stores the decrypted data in the provided buffer. <code>SSL_write</code> encrypts the given buffer and sends it to a remote peer. Attaching an uprobe where <code>SSL_read</code> <em>returns</em>, and one at the <em>entry</em> of <code>SSL_write</code>, we can therefore access unencrypted memory.</p><p>Here's the uprobes that do just that:</p><pre><code><span>use</span><span> </span><span>redbpf_probes</span><span>::</span><span>uprobe</span><span>::</span><span>prelude</span><span>::</span><span>*</span><span>;</span><span>
</span>
<span></span><span>struct</span><span> </span><span>SSLArgs</span><span> </span><span>{</span><span>
</span><span>    ssl</span><span>:</span><span> </span><span>usize</span><span>,</span><span>
</span><span>    buf</span><span>:</span><span> </span><span>usize</span><span>,</span><span>
</span><span></span><span>}</span><span>
</span>
<span></span><span>// temporary storage map</span><span>
</span><span></span><span>static</span><span> </span><span>mut</span><span> ssl_args</span><span>:</span><span> </span><span>HashMap</span><span>&lt;</span><span>u64</span><span>,</span><span> </span><span>SSLArgs</span><span>&gt;</span><span> </span><span>=</span><span> </span><span>HashMap</span><span>::</span><span>with_max_entries</span><span>(</span><span>1024</span><span>)</span><span>;</span><span>
</span>
<span></span><span>fn</span><span> </span><span>output_buf</span><span>(</span><span>regs</span><span>:</span><span> </span><span>Registers</span><span>,</span><span> mode</span><span>:</span><span> </span><span>AccessMode</span><span>,</span><span> buf_addr</span><span>:</span><span> </span><span>usize</span><span>,</span><span> len</span><span>:</span><span> </span><span>usize</span><span>)</span><span> </span><span>{</span><span>
</span><span>  </span><span>// Ignore how this is implemented for now. Assume it reads `len` bytes from `buf_addr`</span><span>
</span><span>  </span><span>// and sends them to our user-space process where they are hex-dumped.</span><span>
</span><span>  </span><span>...</span><span>
</span><span></span><span>}</span><span>
</span>
<span></span><span>#[uprobe]</span><span>
</span><span></span><span>fn</span><span> </span><span>SSL_write_entry</span><span>(</span><span>regs</span><span>:</span><span> </span><span>Registers</span><span>)</span><span> </span><span>{</span><span>
</span><span>    </span><span>let</span><span> ssl </span><span>=</span><span> regs</span><span>.</span><span>parm1</span><span>(</span><span>)</span><span> </span><span>as</span><span> </span><span>usize</span><span>;</span><span>
</span><span>    </span><span>let</span><span> buf </span><span>=</span><span> regs</span><span>.</span><span>parm2</span><span>(</span><span>)</span><span> </span><span>as</span><span> </span><span>usize</span><span>;</span><span>
</span><span>    </span><span>let</span><span> num </span><span>=</span><span> regs</span><span>.</span><span>parm3</span><span>(</span><span>)</span><span> </span><span>as</span><span> </span><span>i32</span><span>;</span><span>
</span><span>    </span><span>if</span><span> num </span><span>&lt;=</span><span> </span><span>0</span><span> </span><span>{</span><span>
</span><span>        </span><span>return</span><span>;</span><span>
</span><span>    </span><span>}</span><span>
</span>
<span>    </span><span>// This is where SSL_write begins, the buffer isn't encrypted yet</span><span>
</span><span>    </span><span>// so we send it to user-space</span><span>
</span><span>    </span><span>output_buf</span><span>(</span><span>regs</span><span>,</span><span> </span><span>AccessMode</span><span>::</span><span>Write</span><span>,</span><span> buf</span><span>,</span><span> num </span><span>as</span><span> </span><span>usize</span><span>)</span><span>;</span><span>
</span><span></span><span>}</span><span>
</span>
<span></span><span>#[uprobe]</span><span>
</span><span></span><span>fn</span><span> </span><span>SSL_read_entry</span><span>(</span><span>regs</span><span>:</span><span> </span><span>Registers</span><span>)</span><span> </span><span>{</span><span>
</span><span>    </span><span>let</span><span> ssl </span><span>=</span><span> regs</span><span>.</span><span>parm1</span><span>(</span><span>)</span><span> </span><span>as</span><span> </span><span>usize</span><span>;</span><span>
</span><span>    </span><span>let</span><span> buf </span><span>=</span><span> regs</span><span>.</span><span>parm2</span><span>(</span><span>)</span><span> </span><span>as</span><span> </span><span>usize</span><span>;</span><span>
</span>
<span>    </span><span>// store the function arguments so we can retrieve them once the</span><span>
</span><span>    </span><span>// function returns</span><span>
</span><span>    </span><span>unsafe</span><span> </span><span>{</span><span>
</span><span>        ssl_args</span><span>.</span><span>set</span><span>(</span><span>&amp;</span><span>bpf_get_current_pid_tgid</span><span>(</span><span>)</span><span>,</span><span> </span><span>&amp;</span><span>SSLArgs</span><span> </span><span>{</span><span> ssl</span><span>,</span><span> buf </span><span>}</span><span>)</span><span>;</span><span>
</span><span>    </span><span>}</span><span>
</span><span></span><span>}</span><span>
</span>
<span></span><span>#[uretprobe]</span><span>
</span><span></span><span>fn</span><span> </span><span>SSL_read_ret</span><span>(</span><span>regs</span><span>:</span><span> </span><span>Registers</span><span>)</span><span> </span><span>{</span><span>
</span><span>    </span><span>// the return value of SSL_read contains the length of the buffer</span><span>
</span><span>    </span><span>let</span><span> num </span><span>=</span><span> regs</span><span>.</span><span>rc</span><span>(</span><span>)</span><span> </span><span>as</span><span> </span><span>i32</span><span>;</span><span>
</span><span>    </span><span>if</span><span> num </span><span>&lt;</span><span> </span><span>0</span><span> </span><span>{</span><span>
</span><span>        </span><span>return</span><span>;</span><span>
</span><span>    </span><span>}</span><span>
</span><span>    </span><span>// This is where SSL_read returns, the buffer is now decrypted</span><span>
</span><span>    </span><span>// so we send it to user-space</span><span>
</span><span>    </span><span>let</span><span> tgid </span><span>=</span><span> </span><span>bpf_get_current_pid_tgid</span><span>(</span><span>)</span><span>;</span><span>
</span><span>    </span><span>let</span><span> args </span><span>=</span><span> </span><span>unsafe</span><span> </span><span>{</span><span> ssl_args</span><span>.</span><span>get</span><span>(</span><span>&amp;</span><span>tgid</span><span>)</span><span> </span><span>}</span><span>;</span><span>
</span><span>    </span><span>if</span><span> </span><span>let</span><span> </span><span>Some</span><span>(</span><span>SSLArgs</span><span> </span><span>{</span><span> ssl</span><span>,</span><span> buf </span><span>}</span><span>)</span><span> </span><span>=</span><span> args </span><span>{</span><span>
</span><span>        </span><span>output_buf</span><span>(</span><span>regs</span><span>,</span><span> </span><span>AccessMode</span><span>::</span><span>Read</span><span>,</span><span> </span><span>*</span><span>buf</span><span>,</span><span> num </span><span>as</span><span> </span><span>usize</span><span>)</span><span>;</span><span>
</span><span>        </span><span>unsafe</span><span> </span><span>{</span><span> ssl_args</span><span>.</span><span>delete</span><span>(</span><span>&amp;</span><span>tgid</span><span>)</span><span> </span><span>}</span><span>;</span><span>
</span><span>    </span><span>}</span><span>
</span><span></span><span>}</span></code></pre><p>Uprobes are annotated with the <a href="https://ingraind.org/api/redbpf_probes/uprobe/prelude/attr.uprobe.html">#[uprobe]</a> attribute. Once they are triggered, they get passed a <a href="https://ingraind.org/api/redbpf_probes/kprobe/struct.Registers.html">Registers</a> argument through which they can access memory.</p><p>The <code>SSL_write_entry</code> probe is the simplest. It reads the registers containing the values of the <code>buf</code> and <code>num</code> arguments passed to <code>SSL_write</code>, and sends a copy of the buffer to user-space before it gets encrypted.</p><p>The <code>SSL_read_entry</code> probe is similar in that it reads the content of the <code>ssl</code>, <code>buf</code> and <code>num</code> arguments passed to <code>SSL_read</code>. It doesn't send the buffer to user-space though. Remember the data is decrypted <em>after</em> <code>SSL_read</code> returns, so we need a second uprobe that we attach to the <em>return address</em> of the function. That's what <code>SSL_read_ret</code> is for. It's similar to the other two probes, but is annotated with <a href="https://ingraind.org/api/redbpf_probes/uprobe/prelude/attr.uretprobe.html">#[uretprobe]</a>, which means that it will trigger once the function it's attached to <em>returns</em>.</p><p>But why do we need two probes for <code>SSL_read</code>, why not just have <code>SSL_read_ret</code>? The answer is that when <code>SSL_read</code> returns, it's likely that the registers that used to contain the function arguments were modified, so we need to read their values at the start of the function and store them so we can retrieve them later. This is a very common pattern when writing BPF code.</p><p>Finally if zoom linked to OpenSSL dynamically or if debugging symbols were present, the user-space code to attach the probes would be as simple as:</p><pre><code><span>use</span><span> </span><span>redbpf</span><span>::</span><span>load</span><span>::</span><span>Loader</span><span>;</span><span>
</span>
<span></span><span>let</span><span> </span><span>mut</span><span> loader </span><span>=</span><span> </span><span>Loader</span><span>::</span><span>load_file</span><span>(</span><span>COMPILED_BPF_BINARY</span><span>)</span><span>?</span><span>;</span><span>
</span><span></span><span>let</span><span> pid </span><span>=</span><span> </span><span>None</span><span>;</span><span>
</span><span></span><span>for</span><span> uprobe </span><span>in</span><span> loader</span><span>.</span><span>uprobes_mut</span><span>(</span><span>)</span><span> </span><span>{</span><span>
</span><span>    </span><span>// Attach to SSL_read and SSL_write inside libssl.</span><span>
</span><span>    </span><span>// Let redbpf resolve the symbol addresses.</span><span>
</span><span>    </span><span>match</span><span> uprobe</span><span>.</span><span>name</span><span>(</span><span>)</span><span>.</span><span>as_str</span><span>(</span><span>)</span><span> </span><span>{</span><span>
</span><span>        </span><span>"SSL_read_entry"</span><span> </span><span>|</span><span> </span><span>"SSL_read_ret"</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span>
</span><span>            uprobe</span><span>.</span><span>attach_uprobe</span><span>(</span><span>Some</span><span>(</span><span>"SSL_read"</span><span>)</span><span>,</span><span> </span><span>0</span><span>,</span><span> </span><span>"libssl"</span><span>,</span><span> pid</span><span>)</span><span>?</span><span>;</span><span>
</span><span>        </span><span>}</span><span>
</span><span>        </span><span>"SSL_write_entry"</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span>
</span><span>            uprobe</span><span>.</span><span>attach_uprobe</span><span>(</span><span>Some</span><span>(</span><span>"SSL_write"</span><span>)</span><span>,</span><span> </span><span>0</span><span>,</span><span> </span><span>"libssl"</span><span>,</span><span> pid</span><span>)</span><span>?</span><span>;</span><span>
</span><span>        </span><span>}</span><span>
</span><span>        _ </span><span>=&gt;</span><span> </span><span>continue</span><span>,</span><span>
</span><span>    </span><span>}</span><span>
</span><span></span><span>}</span></code></pre><p>Unfortunately since OpenSSL is statically linked and the symbols have been stripped, redbpf can't automatically resolve the addresses of <code>SSL_read</code> and <code>SSL_write</code>, instead we have to explicitly provide the offsets we want to attach to:</p><pre><code><span>use</span><span> </span><span>redbpf</span><span>::</span><span>load</span><span>::</span><span>Loader</span><span>;</span><span>
</span>
<span></span><span>let</span><span> </span><span>mut</span><span> loader </span><span>=</span><span> </span><span>Loader</span><span>::</span><span>load_file</span><span>(</span><span>COMPILED_BPF_BINARY</span><span>)</span><span>?</span><span>;</span><span>
</span><span></span><span>let</span><span> pid </span><span>=</span><span> </span><span>None</span><span>;</span><span>
</span><span></span><span>for</span><span> uprobe </span><span>in</span><span> loader</span><span>.</span><span>uprobes_mut</span><span>(</span><span>)</span><span> </span><span>{</span><span>
</span><span>    </span><span>let</span><span> zoom_binary </span><span>=</span><span> </span><span>"/opt/zoom/zoom"</span><span>;</span><span>
</span><span>    </span><span>// …</span></code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://confused.ai/posts/intercepting-zoom-tls-encryption-bpf-uprobes">https://confused.ai/posts/intercepting-zoom-tls-encryption-bpf-uprobes</a></em></p>]]>
            </description>
            <link>https://confused.ai/posts/intercepting-zoom-tls-encryption-bpf-uprobes</link>
            <guid isPermaLink="false">hacker-news-small-sites-24434031</guid>
            <pubDate>Thu, 10 Sep 2020 16:46:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Russia publishes its Remote Online Voting system on GitHub]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24434026">thread link</a>) | @vvpvijay
<br/>
September 10, 2020 | https://androidrookies.com/russia-publishes-its-remote-online-voting-system-on-github/ | <a href="https://web.archive.org/web/*/https://androidrookies.com/russia-publishes-its-remote-online-voting-system-on-github/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-10870"><div><div><div><h2>Russian ISP, Rostelecom has put the source code of Russia’s Remote Online Voting software on GitHub to get hackers and researchers find bugs in it</h2><p>This may be one of the firsts. Russian Internet service provider, Rostelecom has published the source code of Russian Remote Online Voting software on its GitHub page so that hackers and security researchers can find vulnerabilities and bugs in it.</p><p>The Rostelecom’s move comes after widespread criticism of the Russian remote online voting software. Many Russians participating in the recently held remote voting had complained that the software had many bugs. Some even said that the Russian online voting platform could be easily hacked.</p><p>To help find bugs and other vulnerabilities,&nbsp;Rostelecom has published the source code on <strong><a href="https://github.com/cikrf">GitHub here</a>.&nbsp;</strong>According to Alexander Malkevich from the Public House of the Russian Federation, the publication of the source code was necessitated due to the many concerns by users during the recently held remote elections. “We want to solve some problems at once; First of all, we hope that researchers will help us fix potential vulnerabilities,” Malkevich says.</p><p>The source code of Russian online voting software contains three main components:</p><ul><li>Counting servers</li><li>Smart contracts</li><li>Portal front end (including front-end libraries)</li></ul><p>Hackers and security researchers may be especially interested in taking a look at the code as the entire voting software is based on blockchain technology. Russian government implemented the blockchain technology because it was tamperproof and had data integrity. &nbsp;“Blockchain technology solves some problems; its main task is to ensure the invariability of information, ensuring the information of each vote, voter lists, encryption keys, and other key aspects,” Malkevich reports.</p><p>The remote online voting works by allowing only those Russian voters who have already registered to vote. There is a time limit within which these previously registered voters can vote. Using the blockchain technology, the Russian Federation seeks to ensure confidentiality in the electoral process and to maintain social distancing measures during the coronavirus pandemic.&nbsp;For election observers, the Russian Federation also developed a special tool that allows them to monitor all transactions on the blockchain network in realtime much like how bitcoins move between wallets.</p><p>If you want to take a look at how the Russian remote voting system works, head over to Rostelecom GitHub page <a href="https://github.com/cikrf">here</a>. Kindly note that the GitHub page is in Russian.</p></div></div></div></article></div>]]>
            </description>
            <link>https://androidrookies.com/russia-publishes-its-remote-online-voting-system-on-github/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24434026</guid>
            <pubDate>Thu, 10 Sep 2020 16:46:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why RudderStack Used Postgres over Apache Kafka for It's Streaming Engine]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24433730">thread link</a>) | @soumyadeb
<br/>
September 10, 2020 | https://rudderstack.com/blog/why-rudderstack-used-postgres-over-apache-kafka-for-streaming-engine/ | <a href="https://web.archive.org/web/*/https://rudderstack.com/blog/why-rudderstack-used-postgres-over-apache-kafka-for-streaming-engine/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-content"><div><article><figure> <img src="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.header1.png"></figure><section><div><h2><strong>Overview</strong></h2><p>In this post, we answer the all-important question – “Why we did not prefer Apache Kafka over PostgreSQL for building RudderStack”. We discuss some of the challenges with using Apache Kafka over our implemented solution that uses PostgreSQL.</p><h2><strong>RudderStack is a Queue</strong></h2><p>At its core, RudderStack is a queuing system. It gets events from multiple sources, persists them, and then sends them to different destinations. Persisting the events is crucial because RudderStack needs to be able to handle different kinds of failures.&nbsp;</p><p>Let’s consider an example here – a destination could be down for any length of time due to some reason. In such a scenario, RudderStack should ideally retain the events and then retry sending the events when that destination is functional once again.</p><div><figure><img src="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.1-1024x312.png" alt="RudderStack - An Event Queue" srcset="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.1-980x298.png 980w, https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.1-480x146.png 480w" sizes="((min-width: 0px) and (max-width: 480px)) 480px, ((min-width: 481px) and (max-width: 980px)) 980px, (min-width: 981px) 1024px, 100vw" data-old-src="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.1-1024x312.png" data-srcset="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.1-980x298.png 980w, https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.1-480x146.png 480w"><figcaption>RudderStack – An Event Queue</figcaption></figure></div><p>Naturally, a popular choice of tool for building such a queuing solution would be Apache Kafka. Kafka provides features such as persistence, ordering, de-duping, extreme performance, horizontal scalability, etc. that any queuing system would need.&nbsp;</p><p>A simple Kafka-based system looks something like this:</p><div><figure><img src="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.2-1024x269.png" alt="A Simple Kafka-Based System" srcset="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.2-980x257.png 980w, https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.2-480x126.png 480w" sizes="((min-width: 0px) and (max-width: 480px)) 480px, ((min-width: 481px) and (max-width: 980px)) 980px, (min-width: 981px) 1024px, 100vw" data-old-src="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.2-1024x269.png" data-srcset="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.2-980x257.png 980w, https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.2-480x126.png 480w"><figcaption>A Simple Kafka-Based System</figcaption></figure></div><p>In our queueing system, we would need to create a separate topic per destination. Events from the sources can be queued into destination-specific topics, while one consumer consumes events from the destination topics. The consumer itself might be spreading the work of sending events across multiple threads for parallelization.&nbsp;</p><p>A separate topic per destination is ideal because if a specific destination is unavailable (e.g., downtime), we do not want to block the events for other destinations. However, as we will see in the next section, failures can be of other types too, leading to complications with this setup.</p><p>While this architecture looks simple enough, Apache Kafka comes with its own set of challenges, which we will focus on in the following sections.</p><h2><strong>Management Challenges</strong></h2><p>Apache Kafka is not the easiest product to deploy and distribute. Moreover, its dependency on Apache Zookeeper – a distributed configuration and synchronization service – makes it quite a <a href="https://medium.com/@anuradha.neo/kafka-is-not-the-best-anymore-meet-pulsar-9eb435c9fc0b">management challenge</a>.</p><p>We did not want to ship and support a product in which we were not experts ourselves.</p><h2><strong>Licensing Issues</strong></h2><p>Licensing was another issue with Apache Kafka. We wanted to release the entire code under an open-source license (AGPLv3). However, the core of Apache Kafka managed by the Apache Foundation is released under the <a href="https://www.apache.org/licenses/LICENSE-2.0">Apache-2 license</a>. In addition, the version actively managed by Confluent is only available under a non-OSI license (Confluent Community License).&nbsp;</p><p>Some specific Kafka features like kSQL (which is very useful for debugging jobs) are not available under the Apache License.</p><p>One of the key features for the queueing system we built was the ability to peek into the pending events, and update their state, i.e. set their failure state to retry. Implementing this was not possible with an OSS license.</p><h2><strong>Handling Multiple Customers</strong></h2><p>In our hosted, multi-tenant offering, we have multiple customers on the same RudderStack instance. While they can use the same architecture as above with a topic per destination, it can lead to a situation where a large flurry of events from one customer blocks events coming from another customer, as shown in the diagram below:&nbsp;</p><div><figure><img src="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.3-1024x247.png" alt="Events From Multiple Customers" srcset="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.3-980x236.png 980w, https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.3-480x116.png 480w" sizes="((min-width: 0px) and (max-width: 480px)) 480px, ((min-width: 481px) and (max-width: 980px)) 980px, (min-width: 981px) 1024px, 100vw" data-old-src="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.3-1024x247.png" data-srcset="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.3-980x236.png 980w, https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.3-480x116.png 480w"><figcaption>Events From Multiple Customers</figcaption></figure></div><p>Ideally, we would want to keep the customers separate so that we can provide the per-customer QoS guarantees.</p><p>The way to do this is to create a separate Kafka topic per destination/customer combination. Unfortunately, Kafka doesn’t scale well with the number of topics. This would eventually become a hindrance our customer-base grows. Our friends at Segment faced a similar issue and wrote a <a href="https://segment.com/blog/introducing-centrifuge/">blog about it</a>.</p><h2><strong>Error Handling</strong></h2><p>Error handling becomes complex with the data in Kafka. If an event fails to deliver, we wanted to adopt the following workflow:</p><ul><li>Record some metadata like the error code, the number of times it has failed, etc.</li><li>Put it back on top of the queue for subsequent retrying.</li><li>Block further events from that user to preserve the order till the event is successfully delivered (or it is aborted).<br></li></ul><p>The following diagram shows an example of a ‘logical’ state of the system at any point:</p><div><figure><img src="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.4-1024x247.png" alt="A Logical State of the System" srcset="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.4-980x236.png 980w, https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.4-480x116.png 480w" sizes="((min-width: 0px) and (max-width: 480px)) 480px, ((min-width: 481px) and (max-width: 980px)) 980px, (min-width: 981px) 1024px, 100vw" data-old-src="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.4-1024x247.png" data-srcset="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.4-980x236.png 980w, https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.4-480x116.png 480w"><figcaption>A Logical State of the System</figcaption></figure></div><p>Event #1 has failed and must be retried. Along with the event, we also want to keep track of the number of times it was retried, the failure error code, etc. Event #3 is from the same end-user, so it cannot be sent until Event #1 succeeds or aborts. However, Event #2 is unrelated and should be processed and succeeded.</p><p>As seen in the figure above, the queue is processing the events and marking them as succeeded (S), failed (F), or waiting (W). A separate process (or a sweep of the main process) can start from the top. The queue is always in a consistent state, so if there is a crash, we can always start from the top.</p><p>Unfortunately, it is not trivial to implement the above logical semantics using Apache Kafka. Kafka does not allow the events to be updated, so we cannot mark the top event as failed, or associate any metadata with it.&nbsp;</p><p>Removing the event and queueing it back (at the end) doesn’t work either, as this will break the ordering constraints – event #3 will end up before event #1, as seen in the example above.&nbsp;</p><h3>Use of Two Queues</h3><p>Another solution is to use two queues – the main queue and a failed queue. The failed jobs and the skipped jobs (from the same user ID) from the main queue can be put in the failed queue. This is demonstrated in the following diagram:</p><div><figure><img src="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.5-1024x471.png" alt="Use of Two Queues" width="580" height="266" srcset="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.5-980x451.png 980w, https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.5-480x221.png 480w" sizes="((min-width: 0px) and (max-width: 480px)) 480px, ((min-width: 481px) and (max-width: 980px)) 980px, 100vw" data-old-src="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.5-1024x471.png" data-srcset="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.5-980x451.png 980w, https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/apacheblog.rs_.5-480x221.png 480w"><figcaption>Use of Two Queues</figcaption></figure></div><p>The issue with this approach is that this only works for the first failure. How do we handle the failures occurring in the Fail Queue? We still have to update the metadata and re-queue the event, so we will need a second fail queue to store failed events from the 1st fail queue.&nbsp;</p><p>We want to retry events a few dozen times before expiring the event, so this is not a great solution as well.</p><h2><strong>Debuggability</strong></h2><p>Being able to query the events as they wait in the queue and/or update the metadata (around failures) to force immediate retrying is a great debugging feature that we were building at RudderStack. Having a SQL-like query interface to the persisted event helped a lot with that.</p><p>While Kafka’s kSQL provides the query interface, it does not allow for updates. Furthermore, there are licensing issues with kSQL, as we noted earlier.</p><h2><strong>In Conclusion</strong></h2><p>In this post, we looked at some of the reasons why we decided to build our own queuing library, instead of adopting a Kafka-based solution. We will write a blog about the implementation but if you are curious, you can explore the implementation on <a href="https://github.com/rudderlabs/rudder-server">GitHub</a></p><p>With our queueing system powered by PostgreSQL, we could easily change the logic for ordering the events as well as debugging them. In addition, we had complete visibility over all the events coming from a source, user or a destination just by running a SQL query – something that was not possible with Apache Kafka.</p><p>To know more about RudderStack and its features, check out our <a href="https://rudderstack.com/">website</a>. You can also track our progress on <a href="https://github.com/rudderlabs/rudder-server">GitHub</a>.&nbsp;</p></div></section></article></div></div></div>]]>
            </description>
            <link>https://rudderstack.com/blog/why-rudderstack-used-postgres-over-apache-kafka-for-streaming-engine/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24433730</guid>
            <pubDate>Thu, 10 Sep 2020 16:20:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Machine Learning Attack Series: Brute forcing to find incorrect predictions]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24433447">thread link</a>) | @wunderwuzzi23
<br/>
September 10, 2020 | https://embracethered.com/blog/posts/2020/husky-ai-machine-learning-attack-bruteforce/ | <a href="https://web.archive.org/web/*/https://embracethered.com/blog/posts/2020/husky-ai-machine-learning-attack-bruteforce/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <p>This post is part of a series about machine learning and artificial intelligence. Click on the blog tag “huskyai” to see related posts.</p>
<p>The <a href="https://embracethered.com/blog/posts/2020/husky-ai-walkthrough/">previous four posts</a> explained the architecture and how Husky AI was built, threat modeled and deployed. Now it’s time to start the attacks and build mitigations. The <a href="#appendix">appendix</a> in this post shows all the attacks I want to research and perform in this series over the next few weeks/months.</p>
<p>Let’s dive into the attacks.</p>
<h2 id="brute-forcing-images-to-find-incorrect-predictions">Brute forcing images to find incorrect predictions</h2>
<p>The first attack I investigated is also referred to as <strong>perturbation attack</strong> throughout the literature I have been reading. It is like fuzzing (dumb or smart) to come up with malicious input that tricks a model. It is probably the first attack that one would think of when faced to hack AI/ML - besides attacking the machine learning infrastructure.</p>
<h3 id="what-are-we-testing">What are we testing?</h3>
<p>The target is Husky AI, which we have discussed in the previous posts. The operationalized Husky AI model is accessible over an HTTP endpoint. It’s basically an image upload API, and it returns the prediction score.</p>
<p><a href="https://embracethered.com/blog/images/2020/husky-prediction.jpg"><img src="https://embracethered.com/blog/images/2020/husky-prediction.jpg" alt="Husky Prediction Example"></a></p>
<p>If you are curious the code for the simple web server is located <a href="https://github.com/wunderwuzzi23/ai/blob/master/huskyai/huskyai.py">here</a>.</p>
<p>To interact with the API I’m using the following code:</p>
<pre><code>ENDPOINT = "https://example.org/huskyai"

def predict(np_candidate):

    #convert numpy array to Image in memory
    img = Image.fromarray((np_candidate*255.).astype('uint8'), 'RGB')
    image_bytes = io.BytesIO()
    img.save(image_bytes, format="png")
    image_bytes = image_bytes.getvalue()

    #call prediction HTTPS API
    file = {
        "file": image_bytes,
        "Content-Type": "image/png"
    }

    response = requests.post(ENDPOINT, files=file)
    return response.json()
</code></pre><h3 id="what-is-happening-here">What is happening here?</h3>
<ol>
<li>The <code>predict</code> function takes a <code>numpy</code> array (a typical python data structure) and converts it to an <code>Image</code>.</li>
<li>The input array comes in with values from <code>0-1</code>. Hence, we multiply all input values by <code>255</code> and convert to a <code>uint8</code> to ensure the random pixels all have values between 0 and 255.</li>
<li>Afterwards the image is converted to <code>png</code>, and the resulting <code>image_bytes</code> are added to the <code>POST</code> request.</li>
<li>If all goes well, the web service returns a <code>JSON</code> response with the prediction as a <code>float</code>.</li>
</ol>
<p>That is all that is needed to invoke the HTTP API from Python.</p>
<h3 id="jupyter-notebook">Jupyter Notebook</h3>
<p>I’m using a Jupyter Notebook to run these attacks. Over the last couple of weeks, I really started liking the VS Code Python extension.</p>
<p>The validation accuracy of the model was in the mid 80% range and querying the API works well with the Jupyter notebook.</p>
<p>Here are two examples of calls to the API:</p>
<ol>
<li>A picture I took at a dog park identifies this dog as a husky:
<a href="https://embracethered.com/blog/images/2020/result-huskyai.jpg"><img src="https://embracethered.com/blog/images/2020/result-huskyai.jpg" alt="Husky Prediction"></a></li>
<li>The Shadowbunny scores low, not being classified as a husky:
<a href="https://embracethered.com/blog/images/2020/nonhusky-prediction-result.jpg"><img src="https://embracethered.com/blog/images/2020/nonhusky-prediction-result.jpg" alt="Non Husky Prediction"></a></li>
</ol>
<p>Equipped with a model that works decently well (or not, as we will see soon), it’s time to create images to challenge the model.</p>
<h2 id="simple-test-cases">Simple test cases</h2>
<p>When testing software to find bugs, a good strategy is testing boundary scenarios. Hence, I thought of doing the same in this case. With machine learning there are special tools and techniques available, such as adversarial learning models, Cleverhans and others which I want to research and look at later.</p>
<p>The three test cases that seemed interesting initially were <strong>all 0</strong>, <strong>all 1</strong> and images with <strong>random pixels</strong>.</p>
<p>Here is the code snippet I used to create these test images and run them through the prediction web endpoint:</p>
<pre><code>candidate_rand  = np.random.random([1, NUM_PX, NUM_PX, 3])
candidate_zeros = np.zeros([1, NUM_PX, NUM_PX, 3])
candidate_ones  = np.ones([1, NUM_PX, NUM_PX, 3])

print("Random Canvas: " + str(predict(candidate_rand)))
print("Ones Canvas:   " + str(predict(candidate_ones)))
print("Zeros Canvas:  " + str(predict(candidate_zeros)))
</code></pre><p>Let us analyze the results in more detail.</p>
<h3 id="test-case-1-a-black-canvas"><strong>Test Case 1:</strong> A black canvas</h3>
<p>The first image I created was a <code>numpy</code> array with all 0 - which is basically a blank black canvas.</p>
<p><a href="https://embracethered.com/blog/images/2020/adversarial-image1.jpg"><img src="https://embracethered.com/blog/images/2020/adversarial-image1.jpg" alt="Husky Adversarial Image 1"></a></p>
<p>Yep, the result looks like expected.</p>
<h3 id="test-case-2-a-white-canvas"><strong>Test case 2:</strong> A white canvas</h3>
<p>The second test case was an all-white canvas:</p>
<p><a href="https://embracethered.com/blog/images/2020/adversarial-image2.jpg"><img src="https://embracethered.com/blog/images/2020/adversarial-image2.jpg" alt="Husky Adversarial Image 2"></a></p>
<p>Oh, wow! There is the first successful attack already. Looks like the model has some issues!</p>
<h3 id="test-case-25-solid-colors-from-0-255"><strong>Test case 2.5:</strong> Solid colors from 0-255</h3>
<p>Since the corner cases gave such drastic results, I went ahead to try the solid shades from 0-255 for all pixels. The results show that there is a range of 30-40 adversarial images that are huskies. So interesting.</p>
<p><a href="https://embracethered.com/blog/images/2020/adversarial-husky-grade.jpg"><img src="https://embracethered.com/blog/images/2020/adversarial-husky-grade.jpg" alt="Husky Adversarial Image - Shades"></a></p>
<p>There is still one more experiment to perform amongst these simple scenarios.</p>
<h3 id="test-case-3-images-with-random-pixels"><strong>Test case 3:</strong> Images with random pixels</h3>
<p>It was quite unexpected that the pervious scenarios already broke the model.</p>
<p>My initial plan was to create many random images in a loop until I get one that scores over 50%. However, this was not really needed. Also, for random images many are identified as husky. Look:</p>
<p><a href="https://embracethered.com/blog/images/2020/adversarial-image3.jpg"><img src="https://embracethered.com/blog/images/2020/adversarial-image3.jpg" alt="Husky Adversarial Image 3"></a></p>
<p>Quite surprising - did not assume that breaking this model would be that easy…</p>
<h2 id="take-away-from-the-attacks">Take-away from the attacks</h2>
<p>The initial learning for me here is that having basic “unit” tests for models is a good idea.
It will be exciting to try more advanced attacks (includ ML based ones) after fixing these issues first.</p>
<h2 id="mitigations">Mitigations</h2>
<p>Now, let’s discuss how to mitigate these issues, I had a couple of ad-hoc ideas:</p>
<ol>
<li><strong>Simple adversarial training:</strong> My first thought is to make sure to add these test cases when training the model. This is called “adversarial training”</li>
<li><strong>Throttle calls to the web server:</strong> Not all attacks are feasible if users are throttled when submitting images. Throttling will make successful attacks more difficult for some attackers. As red teamer I’d say its best to assume a motivated adversary has access to the model.</li>
<li><strong>Interpret predictions slightly different:</strong> We could say an image is a husky when the prediction is 60%+</li>
<li><strong>Improving the model in general:</strong> The model’s accuracy is in the mid 80% and a bit overfitted, so there is plenty of room for improvements.</li>
<li><strong>Transfer Learning</strong> A good improvement accuracy wise will be to use “Transfer Learning” and build on top of the shoulders of a more mature model.</li>
</ol>
<p>The results so far are quite interesting for my learning experience. So, I want to continue that route for now.</p>
<p>Let’s look how I trained the model for these adversarial images:</p>
<h3 id="adversarial-training">Adversarial training</h3>
<p>The simple mitigation seems to be to train the model on these corner cases and teach the model that such images are not huskies.</p>
<p>This can be done using code like this:</p>
<pre><code>labels = [0,0,0]
images = [candidate_rand[0], candidate_zeros[0], candidate_ones[0]]

print("Fitting model...")
model.fit(np.array(images),np.array(labels), epochs=1, verbose=0)

print("Random Canvas: " + str(model.predict(candidate_rand)))
print("Zeros Canvas:  " + str(model.predict(candidate_zeros)))
print("Ones Canvas:   " + str(model.predict(candidate_ones)))
</code></pre><p>Since I am experimenting to learn, I only trained for a single epoch initially, here are the results:</p>
<pre><code>Fitting model...

Random Canvas: [[0.25112703]]
Zeros Canvas:  [[7.170946e-05]]
Ones Canvas:   [[0.5275204]]
</code></pre><p>These number are still bad, so I trained for more epochs. Overfitting did not seem too much of a concern as these images are far off real huskies. I think it would further improve the model to cycle the random pixels for each epoch even.</p>
<h4 id="testing-the-mitigation-brute-forcing-images">Testing the mitigation (brute forcing images)</h4>
<p>To check I built this basic brute force script, which just creates a random pixel image and then runs it through the new model. <em>This test was done directly against the model, not via the slower HTTPS image upload API.</em></p>
<pre><code>## Brute force experiment
## Is it now feasible now to guess a random husky via brute force?
attempts = 100000
current_best_score = 1e-100

for i in range(attempts):

    if (i % 10000) == 0:
        print(f"Progress... #{i}")
    
    ##create a random image
    candidate_image = np.random.random([1, NUM_PX, NUM_PX, 3])
    
    result = model.predict(candidate_image)
    score = result[0]

    if score &gt; 0.5:
        print("Found a random husky. Try #" + str(i))
        plt.imshow(candidate_image[0])
        break

    if score &gt; current_best_score: 
        current_best_score = score
        print("New best score: " + str(current_best_score))
</code></pre><p>With the additional training we performed, it seems quite difficult to “guess” a husky picture now.</p>
<p>I performed about 100000 tests and the highest score achieved via random pixels was about 30% now - still a bit high so I should probably add a few more “random pixel” adversarial examples.</p>
<h3 id="api-throttling-and-rate-limiting">API throttling and rate limiting</h3>
<p>Throttling the web server image upload API (which queries the model) is another good mitigation. I am using <code>nginx</code> as API gateway and <code>rate limiting</code> can be setup in the configuration file of the web site. <a href="https://www.nginx.com/blog/rate-limiting-nginx/">See more information on the nginx documentation for rate limiting</a>.</p>
<h2 id="conclusion">Conclusion</h2>
<p>That’s it for the first round of attacks. I hope you enjoyed reading and learning about this as much as I do. I learned a lot already and am eager to dive learning smarter ways of coming up with malicious/adversarial examples.</p>
<h3 id="appendix">Appendix</h3>
<p>These are the core ML threats for Husky AI that were identified in the <a href="https://embracethered.com/blog/posts/2020/husky-ai-threat-modeling-machine-learning/">threat modeling session</a> so far and that I want to research and build attacks for.</p>
<p>Links will be added when posts are completed over the next serveral weeks/months.</p>
<ol>
<li><strong>Attacker brute forces images to find incorrect predictions/labels - Perturbation Attack  (this post)</strong></li>
<li><a href="https://embracethered.com/blog/posts/2020/husky-ai-machine-learning-attack-smart-fuzz/">Attacker applies smart ML fuzzing to find incorrect predictions - Perturbation Attack</a></li>
<li>Attacker gains read access to the model - Exfiltration Attack</li>
<li>Attacker modifies persisted model file - Backdooring Attack</li>
<li>Attacker denies modifying the model file - Repudiation Attack</li>
<li>Attacker poisons the supply chain of third-party libraries</li>
<li>Attacker tampers with images on disk to impact training performance</li>
<li>Attacker modifies Jupyter Notebook file to insert a backdoor (key logger or data stealer)</li>
</ol>

  </section></div>]]>
            </description>
            <link>https://embracethered.com/blog/posts/2020/husky-ai-machine-learning-attack-bruteforce/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24433447</guid>
            <pubDate>Thu, 10 Sep 2020 15:52:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Applying AI in the Real-World]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24433393">thread link</a>) | @pedrobnsilva
<br/>
September 10, 2020 | https://1d.works/applying-ai-in-real-life-part-1/ | <a href="https://web.archive.org/web/*/https://1d.works/applying-ai-in-real-life-part-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://images.unsplash.com/photo-1516110833967-0b5716ca1387?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 300w,
                            https://images.unsplash.com/photo-1516110833967-0b5716ca1387?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 600w,
                            https://images.unsplash.com/photo-1516110833967-0b5716ca1387?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 1000w,
                            https://images.unsplash.com/photo-1516110833967-0b5716ca1387?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://images.unsplash.com/photo-1516110833967-0b5716ca1387?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ" alt="Applying AI in the real-world (Part 1)">
            </figure>

            <section>
                <div>
                    <h2 id="introduction">Introduction<br></h2><p>In the last decade, artificial intelligence has accomplished many significant feats: from classifying an image to tracking objects in video feeds, from beating a Go player to beating a Starcraft 2 pro and more. After such a successful decade, it is evident that academic advance is slowing down and the research lately is more incremental than fundamental. However, that also means that the AI technology is maturing and we are finding new domains where technology can be applied to.</p><p>Having seen/ read/ been amazed by these applications as a business member you maybe be starting to wonder whether it is time for you to try out these approaches in your work. In this blog post, we will share our experience in solving business problems with AI and hopefully help you avoid repeating our mistakes.</p><h2 id="adding-ml-to-your-it-stack-vs-adding-ml-to-your-business-stack">Adding ML to your IT stack VS adding ML to your business stack<br></h2><p>Before jumping into the core matter, &nbsp;we should make a distinction between two flavors of deployment issues:</p><p><strong>Problem 1: Adding ML to the IT stack. </strong>ML is compute-heavy and requires compute-oriented software and hardware which might not be present in IT infrastructure. Therefore, how and where the algorithms are run needs to be decided, and appropriate skills need to be added to or developed in your IT department.</p><p><strong>Problem 2: Dealing with the implications of having ML in your business processes. </strong>Most of ML methods are non-deterministic and they are evaluated on a statistical basis. That means that even when the methods work it is possible for them to deliver the wrong result. This stochastic nature of the algorithm can be a novelty to a business which depends on a fully deterministic IT system. Business processes affected by such randomness need to be identified, the impact evaluated and, if needed, policies to address it are required.</p><p>Problem 1 heavily depends on the existing infrastructure and the algorithm specifics. Moreover, it is the more obvious of the issues and has been documented extensively. To the extent that it could be solved by completely outsourcing it to the cloud - store the data, train the models, use the models, all in the cloud. There are multiple good tools to achieve that, for example Google cloud offers AutoML and Amazon AWS offers multiple AI/ML services, just to name a few.</p><p>There is much less information on Problem 2, but it can make or break the business proposition of an AI/ML application. Usually, when clients approach AI/ML developers they ask “Can you solve problem X?”, developers reply “Sure, what accuracy do you need?”. The jump from a problem to an AI algorithm is a non-trivial one and requires careful attention.</p><p>To link the business problem to an ML algorithm one needs to deeply understand where the value is added in the process. For example, AI is increasingly being applied for initial screening of medical patients and there you should be extremely cautious about false negatives, i.e. where the patient is screened as healthy when in fact he might be severely ill. The impact of the false positive in that scenario would most likely only lead to and increase in costs. Ignoring these aspects of accuracy could lead to a deadly outcome!</p><p>Therefore, framing the real-life problem into an AI solution is a significant part of the development and in this blog series, we will share our experience and tips on how to avoid some of the dangerous pitfalls.</p><h2 id="examples">Examples<br></h2><p>We start by sharing two examples that we’ve encountered that are spaced nearly a decade apart. The older one will be used to set a reference point of what developers and IT managers are used to and the more recent one will shed some light on how AI algorithms are developed nowadays. Contrasting the two allows us to compare in what ways we should change how we think about development and how to be prepared to manage what is to come.</p><p>Although we focus on image recognition, the issues are shared across a wide variety of data-based ML approaches.</p><h3 id="how-production-has-been-running-and-what-we-are-used-to">How production has been running and what we are used to</h3><figure><img src="https://raw.githubusercontent.com/1dworks/homepage-assets/master/2020/09/tom-grunbauer-WElrXyQnTiM-unsplash-1-.jpg" alt=""></figure><p>In 2012 we were approached by a client to develop licence plate recognition from images for their parking lot. The client gave us a dataset of 100 images and we started to work on it.</p><p>Recall that in 2012 the situation with respect to AI/ML was very different. Although deep learning had been making waves in the research community, there were much fewer software tools available, much less knowledge on how to train and use neural nets, and it was much harder to run algorithms on GPUs.</p><p>The way production computer vision was at the time - use heuristics to simplify the problem and sometimes use some neural network approach to solve that simple problem. </p><p><strong>The solution we came up worked along these lines:</strong></p><ol><li>Extract white regions from the image;</li></ol><p><strong>Select the regions fulfilling certain conditions:</strong></p><ol><li>A certain range of heights and widths;</li><li>A specific range of aspect ratios;</li><li>Containing some fraction of non-white regions;</li><li>…</li></ol><p><strong>Loop over the selected regions and</strong></p><ol><li>Detect non-white contours which have letter-like features: location in the region, colour, height, width, aspect ratio and etc.</li></ol><p><strong>For each of the letter-like contour try to extract the letter by either:</strong></p><ol><li>Matching it to a database;</li><li>Using some proprietary letter detector;</li><li>Using some neural network;</li><li>A combination of the above;</li><li>Try combining the extracted symbols into a single license plate;</li><li>If all the steps succeeded return the license plate.</li></ol><p><strong>The solution took us a few months and was fairly restrictive:</strong></p><ul><li>Required certain lighting conditions;</li><li>The license plate must be clearly visible, close to the center of the image and not too skewed;</li><li>A high-quality camera was required;</li><li>Adding new features (e.g. enabling night vision ) required a full reworking of the algorithm.</li></ul><p>In many cases, the algorithm crashed at one of the steps and did not return any result. In the cases it worked, the accuracy reached a respectable 95%. The overall accuracy was fairly low - maybe around 60% since in many cases it did not return, but given that cameras do 30 frames per second the overall solution was worth the effort. The problem was solved and has been used in production for a while.</p><h3 id="how-the-ai-ml-production-works-and-what-we-should-get-used-to-for-the-next-decade">How the AI/ML production works and what we should get used to for the next decade</h3><figure><img src="https://raw.githubusercontent.com/1dworks/homepage-assets/master/2020/09/anastase-maragos-kgCDp9PsVQk-unsplash.jpg" alt=""></figure><p>More recently in 2019, we were approached by a car-wash network manager who wanted to measure vehicle queue length using cameras.</p><p>We received a sample of 1000 images and started developing the solution. After manually labeling, we developed multiple candidates, but the high-level view of the solutions was:</p><ol><li>Get the image;</li><li>Extract image features using a pre-trained neural network;</li><li>Use a more data-efficient ML algorithm to map features to the vehicle count.</li></ol><p>The development of the principal algorithm took us a few days and it was 96% accurate. However, even though we had good accuracy in our sample which the client would accept as appropriate, we did not stop there and we’ll share why later on.</p><h3 id="comparison">Comparison<br></h3><p>Let’s compare the two approaches:</p><!--kg-card-begin: html--><table>
  <tbody><tr>
    <th>Heuristic-based algorithm</th>
    <th>ML-based algorithm</th>
  </tr>
  <tr>
   <td>Requires less data</td>
    <td>Requires more data</td>
  </tr>
  <tr>
    <td>The code is complicated</td>
    <td>The code is simple</td>
  </tr>
      <tr>
    <td>The decision logic is obvious</td>
    <td>A lot of maintenance</td>
  </tr>
      <tr>
    <td>Likely to crash than give a wrong result</td>
    <td>Never crashes, but might give the wrong answer</td>
  </tr>
      <tr>
    <td>Slow development</td>
    <td>Fast development</td>
  </tr>
      <tr>
    <td>Runs on any PC</td>
    <td>For efficient use requires GPU-enabled PC</td>
  </tr>
</tbody></table><!--kg-card-end: html--><p>These contrasts led us to identify the following challenges when working with AI algorithms.</p><h2 id="the-challenges-of-ai-based-solutions-why-are-business-processes-important-what-has-changed">The challenges of AI-based solutions/ Why are business processes important/What has changed?<br></h2><ul><li><strong>AI development is non-deterministic</strong>. Once you’ve built a few heuristic-based image recognition solutions, you generally know what is possible and what is not. When AI is involved it is uncertain whether you’re going to have the right data, enough data, enough computing power or brainpower to deal with the math involved to solve it. Even if you follow a paper with a similar problem being solved, usually many important details are left out and take a while to figure out the hard way.</li><li><strong>AI results are non-deterministic. </strong>They are likely to give the correct result, but it does not mean that the likelihood of a wrong one is small. In the case of the car-wash example, in one spot a car was drawn on the pavement and it got always detected as a waiting car.</li><li><strong>AI does not crash. </strong>As long as you give the algorithm the input in the shape it needs it will always give you a result. And sometimes it will be wrong. E.g. the license plate algorithm had so many checks along the way that it crashed instead of giving a wrong result, making the algorithm much more usable.</li><li><strong>AI solutions are opaque vs transparent. </strong>License plate solution consisted of many small steps and debugging it was pretty simple since it was obvious where the system stopped working. Figuring out why the car count algorithm went broken was much harder. Maybe the error was an unseen case?</li><li><strong>ML-based solutions are based on the data available before the deployment stage. </strong>The same can be said about the heuristic-based solution, but heuristics are usually made such that their logic is meant to span beyond the sample set. In a related scenario, the first batch of images we got for the vehicle queue contained images during very good weather. As expected once we asked to for more samples weirder cases started appeared - the rain made some of the images unworkable and threw off our initial algorithm.</li></ul><h2 id="conclusions">Conclusions<br></h2><p>In this blog post, we shared our experience with two similar problems and their two different solutions. The heuristic approach has been in use for a long period of time and the AI one is slowly taking over. Contrasting how the two are developed and used hints at the challenges of the new approach. Having figured out that in this blog post we will elaborate on how such projects should be structured to achieve maximum success in the next part.</p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://1d.works/applying-ai-in-real-life-part-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24433393</guid>
            <pubDate>Thu, 10 Sep 2020 15:46:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[QAnon has found a home among wellness influencers]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24433128">thread link</a>) | @colinprince
<br/>
September 10, 2020 | https://www.cbc.ca/radio/day6/funding-confusion-for-first-nations-schools-qanon-wellness-the-mulan-legend-bring-it-on-turns-20-and-more-1.5711574/qanon-has-found-a-home-among-wellness-influencers-and-new-audiences-says-reporter-1.5711585 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/radio/day6/funding-confusion-for-first-nations-schools-qanon-wellness-the-mulan-legend-bring-it-on-turns-20-and-more-1.5711574/qanon-has-found-a-home-among-wellness-influencers-and-new-audiences-says-reporter-1.5711585">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>The QAnon conspiracy has made its way into online communities led by wellness and alternative medicine influencers, according to Mother Jones reporter Ali Breland. Now, social media users who wouldn’t seek out such fringe content are discovering it through Instagram and Twitter feeds dedicated to health.</p><div><figure><div><p><img alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5658413.1595408998!/fileImage/httpImage/image.JPG_gen/derivatives/16x9_780/usa-election-trump.JPG"></p></div><figcaption>A man in the crowd holds a QAnon sign with the group's abbreviation of their rallying cry 'Where we go one, we go all' at a Donald Trump rally at the Las Vegas Convention Center in Nevada on Feb. 21.<!-- --> <!-- -->(Patrick Fallon/Reuters)</figcaption></figure><p><span></span><span>Listen</span><span>9:34</span></p><p><span><p>The QAnon conspiracy has made its way into online communities led by wellness and alternative medicine influencers, according to one reporter.</p>  <p>Now, social media users who wouldn't seek out such fringe content are discovering it through Instagram and Twitter feeds dedicated to health.</p>  <p>QAnon&nbsp;is a right-wing conspiracy group that believes that so-called deep-state traitors are plotting against U.S. President Donald Trump. Some of its self-professed members also believe&nbsp;a cabal of pedophiles are running a child sex trafficking ring.</p>  <p>These conspiracies have&nbsp;circulated around parts of the internet since Trumps'&nbsp;election. Last month, a reporter asked the president about the theory.</p>  <p>"I don't know much about the movement other than I understand they like me very much, which I appreciate," Trump said.</p>    <p>Ali Breland,&nbsp;a reporter for Mother Jones, has been following the spread of QAnon. He spoke with <em>Day 6</em> host about how the theory has evolved, particularly since the beginning of the COVID-19 pandemic.</p>  <p>Here is part of their conversation.</p>  <p><strong>If I'm a non-conspiratorial type person involved in alternative medicine online, or other wellness communities, how likely is it that QAnon is now showing up in my feed?</strong></p>  <p>It's really hard to fully know definitively, because of the way that Instagram is structured. It's really hard to parse out data. But, anecdotally, from my own observations, from other reporters' observations, and from talking to people who are deeply entrenched in these communities, it's really, really, really common.&nbsp;</p>  <p>Every time I read about these things, I get more messages from people who are like, "What the heck is this crap? This is all over my feed." And then it reifies itself and it's just becoming an unmissable part of this community, even if you're not inclined to believe these things.</p>  <p><strong>An online influencer doesn't necessarily have any particular expertise. But are there people in the health community with academic credentials who are pushing the QAnon line?</strong></p>  <p>A lot of them....&nbsp;They'll have backgrounds in being a chiropractor, things like that. But there's one actually really interesting one. Her name, I believe, is Christiane Northrup, and she has a degree from Dartmouth [Medical School]. She did her residency at Tufts. But [she] is doing this video series called The Great Awakening, which is a very clear nod to QAnon.</p>  <p>"Great Awakening" is a term they've co-opted and clearly made their own. She's posted links to QAnon-related videos.</p>  <p>She's a really difficult example because if you're a lay person who's just trying to go about their business and parse the world, it does become very difficult when you see this kind of information coming from a Dartmouth M.D. We're taught that these things are very valuable.</p>  <p>Whether or not they actually are, it makes your life a lot harder if you're not in these spaces all the time to assess the legitimacy of this person and what she's saying.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5707447.1598960341!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/trump.jpg 300w,https://i.cbc.ca/1.5707447.1598960341!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/trump.jpg 460w,https://i.cbc.ca/1.5707447.1598960341!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/trump.jpg 620w,https://i.cbc.ca/1.5707447.1598960341!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/trump.jpg 780w,https://i.cbc.ca/1.5707447.1598960341!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/trump.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5707447.1598960341!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/trump.jpg"></p></div><figcaption>Trump addressed the QAnon conspiracy last month, saying 'I understand they like me very much,' in response to a reporter's question.<!-- --> <!-- -->(Andrew Harnik/The Associated Press)</figcaption></figure></span></p>  <p><strong>These two worlds — QAnon, a conspiracy theory and wellness, which is connected to science — they don't seem like they would have a lot of obvious connections. What is the overlap here? How did this develop?</strong></p>  <p>They definitely don't seem like they have obvious connections, but if you zoom out for a bit, there is a sort of clear connection.&nbsp;</p>  <p>What a lot of wellness influencers have in common is that they're anti-vaxxers. This isn't universal by any stretch of the imagination; I don't want to paint a community in broad strokes, but there is a lot of crossover. And if you think about it, the anti-vaccination conspiracy is beat for beat almost the same conspiracy as QAnon.</p>  <p><strong>In what way?</strong></p>  <p>[It's the idea that] these big powerful interests — these external interests that are beyond us, like Big Pharma — that we can't conceptualize are trying to hurt our children ... and we need to protect them because no one else will.</p>  <p>That's the prevailing belief of QAnon: that there is a liberal elite kidnapping children and putting them into pedophile rings and stealing and drinking their blood. It's much more fantastical than anti-vaccination conspiracy theories, but it is the same thing: our children are under threat, our children are being attacked, and we need to protect them because powerful interests don't want us to protect them. They're out to get us.</p>  <p><strong>This week on Twitter, the phrase "only six per cent" trended&nbsp;because of a tweet from a QAnon supporter who falsely claimed that 94 per cent of deaths attributed to COVID were bogus.</strong></p>  <p><strong>Trump retweeted it. Several right-wing politicians jumped on it and Twitter took down the tweet, but it was already trending. What's the lesson there?</strong></p>  <p>So there's two lessons. If you just look at Twitter's actions within itself, it's good that they're doing something about this. But at the same time, you wonder how interested they are in actually structurally reforming these kinds of things and taking action ahead of time. Reddit decided to take down all of its QAnon pages back in 2018, right? Twitter had two years to do something and it didn't. So it's nice <a href="https://www.cbc.ca/news/technology/twitter-qanon-accounts-1.5658411" target="_blank">that they're doing this after the fact</a>, but it's almost too late.</p>  <p>[There] is another&nbsp;serious point of concern with QAnon: people point to how some of its supporters have gotten violent. But also, it can spread real political misinformation and affect actual policy.</p>    <p>It's almost imminent by next year that there will be QAnon-supporting Congressmen. <a href="https://www.cbc.ca/news/world/us-primaries-greene-omar-1.5683022" target="_blank">Marjorie Taylor Green in Georgia just won her primary race</a>, in a race that she's expected to beat&nbsp;her Democratic opponent in November pretty handily. There's other potential cases where QAnon-supporting candidates could win their races as well.</p>  <p>QAnon mobs have been attacking a state senator in California who's proposing LGBTQ equality legislation. They're accusing him of being a pedophile. They're lobbing homophobic and anti-Semitic smears of him to oppose the legislation. The concern is that these people will start affecting politics in harmful and unhealthy ways that aren't rooted in reality at all.</p>  <hr>  <p><em>Written by Jason Vermes. Produced by&nbsp;Pedro Sanchez. Q&amp;A edited for length and clarity.</em></p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/radio/day6/funding-confusion-for-first-nations-schools-qanon-wellness-the-mulan-legend-bring-it-on-turns-20-and-more-1.5711574/qanon-has-found-a-home-among-wellness-influencers-and-new-audiences-says-reporter-1.5711585</link>
            <guid isPermaLink="false">hacker-news-small-sites-24433128</guid>
            <pubDate>Thu, 10 Sep 2020 15:19:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Removing email registration improved retention]]>
            </title>
            <description>
<![CDATA[
Score 133 | Comments 168 (<a href="https://news.ycombinator.com/item?id=24433090">thread link</a>) | @tapneal
<br/>
September 10, 2020 | https://solitaired.com/email-registration-is-dead | <a href="https://web.archive.org/web/*/https://solitaired.com/email-registration-is-dead">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><center><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/coverimage.png"></center><p>
In our last business, where we ran popular educational products like EasyBib, we learned the power of email registration. When users registered we found that they would come back and use our service more, and eventually subscribe. </p>
<h2 id="firststeptoimproveretentionaddregistration">First step to improve retention: Add registration</h2>
<p>When building our <a href="https://solitaired.com/">solitaire site</a> then, a fun side hobby of ours, adding in email registration and account creation was immediately on our roadmap. When we added the ability to create accounts and track past scores, we immediately saw that our sessions per user increased by 5%. It was a solid win!</p>
<center><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/fivelift.png"></center>
<p>To encourage more registrations we introduced a leaderboard to see how you performed against other players. You could see how your time and number of moves compared to others who played the same game, and we encouraged sign ups to get your name on the leaderboard. This improved registrations by 22%, and we saw sessions per user increase another 3%. </p>
<center><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/threelift.png"></center>
<p>All these features encouraged users to play more, compete against themselves and others, and return to the site.</p>
<h2 id="dosendingemailsmoveourkpis">Do sending emails move our KPIs?</h2>
<p>By now, we had learned that registration was a powerful feature in our game to drive loyalty and retention. Given that we were collecting emails as part of our standard registration process, we naturally thought emailing our user base, which had reached over 15,000 users, could naturally drive more return usage. </p>
<p>We started emailing our users to play a new game of the day feature we introduced. Open rates were a solid 17% on average, but click through rates to the game were 1%. This meant it drove about 26 more users to our site (15,000 * 17% * 1%). Moreover, these could have been users who would have gone back to Solitaired whether they read our email or not. </p>
<p>We saw a 0.5% improvement in returning users, but when we stopped sending emails, this didnâ€™t change suggesting the modest improvement was just noise.</p>
<h2 id="removingemailregistration">Removing email registration</h2>
<p>While registration, saving accounts, and leaderboards improved retention, sending emails clearly did not. </p>
<p>I was watching my sister play, who had become a solitaire addict after she QAing the game. She was obsessed with beating her personal bests and getting high scores for the game of the day. When I watched her play though, quizzically, she had not registered for an account. </p>
<p>I asked her why, she said she just didnâ€™t want to give her email away and get bombarded by more emails. I was dumbfounded, because after all, her brother (me), was the co-founder of the site and yet she still had these concerns.</p>
<center><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/sister.png"></center>
<p>The lightbulb went off. Since sending emails did not provide value, and if anything was an additional cost,  what if we just asked for a username. While this creates issues with password recovery, we thought this would drive up registrations and improve retention. We also have a long term cookie so users wouldnâ€™t have to login again. </p>
<p>When we changed email sign ups simply to usernames, we saw registrations increase by a huge 36%! More importantly, we saw return users increase another 4.5%.</p>
<p>This meant email registration was holding us back from driving retention. </p>
<center><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/fourfivelift.png"></center>
<p>Digging in further, we're also seeing return visitors playing more games like <a href="https://solitaired.com/freecell">Freecell</a> and <a href="https://solitaired.com/spider">Spider</a>. Leaderboards and simple registration have encouraged users to try new games.</p>
<h2 id="weassumeemailisvaluable">We assume email is valuable</h2>
<p>Depending on your site and space, email surely can be valuable. For ecommerce sites, you can send targeted emails with special offers, for example. </p>
<p>Most of us assume email is beneficial to our businesses, and we rarely test to see if thatâ€™s the case. We have it because it gives us an owned channel to reach out and engage our users whenever we want. </p>
<p>However, we're forgetting a key fact: most of us also hate emails from commercial sites. They clog our inbox, and we instinctually either ignore or delete them. Every once in a while we might open one of those emails up, and even more rarely, we might click the call to action in the email. </p>
<p>Ask if requiring email addresses really moves important business metrics for your site. Sometimes they do. In our case, it just created a poor user experience which weâ€™re now happy to be rid of.</p></div></div></div></div>]]>
            </description>
            <link>https://solitaired.com/email-registration-is-dead</link>
            <guid isPermaLink="false">hacker-news-small-sites-24433090</guid>
            <pubDate>Thu, 10 Sep 2020 15:15:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Clojure Spec is and what you can do with it]]>
            </title>
            <description>
<![CDATA[
Score 257 | Comments 63 (<a href="https://news.ycombinator.com/item?id=24432461">thread link</a>) | @icey
<br/>
September 10, 2020 | https://www.pixelated-noise.com/blog/2020/09/10/what-spec-is/ | <a href="https://web.archive.org/web/*/https://www.pixelated-noise.com/blog/2020/09/10/what-spec-is/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><img src="https://www.pixelated-noise.com/assets/images/people/stathis-sideris.jpeg"></p><div><p>Stathis Sideris</p><p>2020-09-10</p></div></div>
<p>
<i>Pixelated Noise is a software consultancy and we're always looking for interesting projects to help out with. If you have unmet software development needs, we would be happy <a href="https://www.pixelated-noise.com/contact/">to hear from you</a>.</i>
</p>

<p>
This is the blog version of a talk I gave on the 2017-12-13 at the Athens
Clojure Meetup, which was kindly hosted by <a href="https://engineering.skroutz.gr/">Skroutz</a>. <a href="https://www.youtube.com/watch?v=T1qpIaB6_vM">The video of the talk</a> is
available (the talk was given in Greek, but there are English subtitles). This
blog entry is not an exact transcript of the talk, I've added links and more
information where appropriate (plus the "bonus" sections that were not in the
talk). Since the talk was given a while ago, some information will be outdated.
</p>

<p>
There are essentially two parts to this article: the "what it is" part which
introduces the basic concepts and mechanisms of spec, and also provides some
information so that non-Clojurians can see how spec fits into the larger picture
and the "what you can do with it" part which explores some more interesting use
cases that go beyond basic usage.
</p>

<div id="outline-container-orge99096d">
<h2 id="orge99096d">What is it?</h2>
<div id="text-orge99096d">
<p>
Clojure is a dynamic language that doesn't enforce the types of parameters or
the return values of functions. This has been a characteristic of the language
that has drawn criticism both internally and from other language communities and
has possibly been a factor impeding adoption in the past.
</p>

<p>
Spec in a way is the response to that, but it's a response that maybe the
community didn't expect because it does not take the traditional approach of
checking types statically. At a very fundamental level spec is a declarative
language that describes data, their type, their shape. Spec follows the general
philosophy of Clojure in that all of its functionality is available at runtime,
you can use it, introspect it, generate it – there is no extra step before
execution when the compiler checks your whole codebase for errors.
</p>
</div>

<div id="outline-container-org56f06dc">
<h3 id="org56f06dc">What does it look like?</h3>
<div id="text-org56f06dc">
<p>
Spec is still alpha, so the namespace in the <code>require</code> contains <code>.alpha</code> to indicate
that. The following spec defines a <code>username</code> "entity" and says that it has to be
a string:
</p>

<div>
<pre>(require '[clojure.spec.alpha <span>:as</span> s])

(<span>s</span>/<span>def</span> <span>::username</span> string?)
</pre>
</div>

<p>
<code>string?</code> is a simple function that exists in Clojure core, it's a
predicate function that you pass a string to and it returns <code>true</code> or
<code>false</code>, depending on whether the passed value is a string or not.
</p>

<p>
Once you've defined a spec the simplest usage of it is to ask whether
something is valid, by calling <code>valid?</code>, and passing the name of the
spec and then a value:
</p>

<div>
<pre>(println
 (<span>s</span>/valid? <span>::username</span> <span>"foo"</span>))
</pre>
</div>

<pre>true
</pre>
</div>
</div>

<div id="outline-container-orgfa7c72e">
<h3 id="orgfa7c72e">It's just predicates!</h3>
<div id="text-orgfa7c72e">
<p>
Many cases are covered by built-in predicates, but that doesn't mean
we can't use our own. If we need a spec that checks that a number is
above 5, we can simply write an anonymous function like this one,
and then use it normally as it if was a spec itself:
</p>



<pre>true
</pre>


<p>
And it works as expected with different inputs:
</p>



<pre>false
</pre>
</div>
</div>

<div id="outline-container-org6c5c14c">
<h3 id="org6c5c14c">Validate data</h3>
<div id="text-org6c5c14c">
<p>
So, we write a spec and it can validate our data. Let's draw this as a
diagram: the thing on the left that looks like a blueprint is a spec and the
curly braces on the right represents Clojure data (because very often data in
Clojure are maps and maps are written with curly braces). Read the weird arrow
in the middle as "validates":
</p>


<p><img src="https://www.pixelated-noise.com/blog/2020/09/10/what-spec-is/validate-data.png" alt="validate-data.png">
</p>

<p>
It's not much of a diagram, but I'm trying to establish the visual language
for the rest of this article.
</p>
</div>
</div>

<div id="outline-container-orgea7799a">
<h3 id="orgea7799a">Collections specs</h3>
<div id="text-orgea7799a">
<p>
Specs can also be applied to collections by composing and nesting
more basic specs together. Here we define an entity called <code>usernames</code>
made up of a collection of <code>username</code>:
</p>

<div>
<pre>(require '[clojure.spec.alpha <span>:as</span> s])

(<span>s</span>/<span>def</span> <span>::username</span> string?)
(<span>s</span>/<span>def</span> <span>::usernames</span> (<span>s</span>/coll-of <span>::username</span>))

(println
 (<span>s</span>/valid? <span>::usernames</span> [<span>"foo"</span> <span>"bar"</span> <span>"baz"</span>]))
</pre>
</div>

<pre>true
</pre>


<p>
You would normally not define this as a separate entity for something that
simple, as <code>s/coll-of</code> can be used ad-hoc in your program.
</p>
</div>
</div>

<div id="outline-container-org81b3460">
<h3 id="org81b3460">Maps</h3>
<div id="text-org81b3460">
<p>
Maps are a bit more interesting. Other technologies such as <a href="https://github.com/plumatic/schema">plumatic
schema</a> (which at some point was the de facto way to validate data in
Clojure), ask you to define both the keys that have to be present in
a map and the data types of the values that correspond to the
keys. The resulting definition looks a bit like a rigidly-defined
class that you usually see in object-oriented languages. Spec very
deliberately moves away from this mentality: the maps are <b>not</b> like
objects, they are <b>not</b> fixed and do not necessarily exist in that one
shape. Instead, maps simply happen to be aggregations of some named
values.
</p>

<p>
This design decision is embodied in two ways:
</p>

<ul>
<li>A map spec written using <code>s/keys</code> which does not define the types of
the values of the map, we only define which existing entities make
up the map.</li>

<li>The name of the key inside the map has to be the same as the name
of the spec already defined elsewhere.</li>
</ul>

<p>
In this case we have defined some single-value specs like username,
password, last-login and comment, and they are aggregated together
in a map defined by the <code>::user</code> spec.
</p>

<div>
<pre>(<span>ns</span> <span>my-project.users</span>
  (<span>:require</span> [clojure.spec.alpha <span>:as</span> s]))

(<span>s</span>/<span>def</span> <span>::username</span> string?)
(<span>s</span>/<span>def</span> <span>::password</span> string?)

(<span>s</span>/<span>def</span> <span>::last-login</span> number?)
(<span>s</span>/<span>def</span> <span>::comment</span> string?)

(<span>s</span>/<span>def</span> <span>::user</span>
  (<span>s</span>/keys
   <span>:req</span> [<span>::username</span> <span>::password</span>]
   <span>:opt</span> [<span>::comment</span> <span>::last-login</span>]))

(println <span>::username</span>)

(println
 (<span>s</span>/valid?
  <span>::user</span>
  {<span>::username</span>   <span>"rich"</span>
   <span>::password</span>   <span>"zegure"</span>
   <span>::comment</span>    <span>"this is a user"</span>
   <span>::last-login</span> 11000}))
</pre>
</div>

<pre>:my-project.users/username ;;this is what fully-qualified keywords look like
true
</pre>


<p>
Spec also encourages the use of qualified keywords: Until recently
in Clojure people would use keywords with a single colon but the two
colons (<code>::</code>) mean that keywords belong to this namespace, in this
case <code>my-project.users</code>. This is another deliberate choice, which is
about creating strong names (or "fully-qualified"), that belong to a
particular namespace, so that we can mix namespaces within the same
map. This means that we can have a map that comes from outside our
system and has its own namespace, and then we add more keys to this
map that belong to our own company's namespace without having to
worry about name clashes. This also helps with data provenance,
because you know that the <code>:subsystem-a/id</code> field is not simply an ID
– it's an ID that was assigned by subsystem-a.
</p>
</div>
</div>

<div id="outline-container-org3248f46">
<h3 id="org3248f46">Maps are open</h3>
<div id="text-org3248f46">
<p>
The other interesting thing about specs for maps is that they are
open. For example, if we use the same exact map as before, with the
same fields and an additional field called <code>::age</code>, it's still a valid
<code>::user</code>:
</p>

<div>
<pre>(<span>ns</span> <span>my-project.users</span>
  (<span>:require</span> [clojure.spec.alpha <span>:as</span> s]))

(<span>s</span>/<span>def</span> <span>::username</span> string?)
(<span>s</span>/<span>def</span> <span>::password</span> string?)

(<span>s</span>/<span>def</span> <span>::last-login</span> number?)
(<span>s</span>/<span>def</span> <span>::comment</span> string?)

(<span>s</span>/<span>def</span> <span>::user</span>
  (<span>s</span>/keys
   <span>:req</span> [<span>::username</span> <span>::password</span>]
   <span>:opt</span> [<span>::comment</span> <span>::last-login</span>]))

(println
 (<span>s</span>/valid?
  <span>::user</span>
  {<span>::username</span>   <span>"rich"</span>
   <span>::password</span>   <span>"zegure"</span>
   <span>::comment</span>    <span>"this is a user"</span>
   <span>::last-login</span> 11000
   <span>::age</span>        26}))
</pre>
</div>

<pre>true
</pre>


<p>
This happens because spec does not mind if you've defined four keys, if it
sees a fifth key the map does not become invalid. The reason for this is that
when we have a system that accumulates information this accumulation should
not break the system, the code that consumes the map should simply ignore the
keys it doesn't know about. If you're making a system and you're accumulating
extra options, parameters, whatever it is – your code should be able to
continue to run without having to change a lot of code locations, like you
would have to do in an object oriented language or Haskell.
</p>

<p>
This accumulation has also been described by the term "accretion"
and has been discussed in the excellent <a href="https://www.youtube.com/watch?v=oyLBGkS5ICk">Spec-ulation Keynote talk</a> by
Rich Hickey.
</p>

<p>
On the other hand, a lot of people who use spec to validate things coming from
outside their system need to be more strict with maps, and they have
complained about the openness of maps. We'll talk about proposed solutions to
this issue later.
</p>
</div>
</div>

<div id="outline-container-org0b68930">
<h3 id="org0b68930">Explain your problems</h3>
<div id="text-org0b68930">
<p>
Another usage of specs, beyond validation, is "explain" which
essentially can produce errors that tell you what's wrong with your
data. In this case we'll try to create an error by creating a user
that's invalid because it doesn't have a password – a required key:
</p>

<div>
<pre>(<span>ns</span> <span>my-project.users</span>
  (<span>:require</span> [clojure.spec.alpha <span>:as</span> s]))

(<span>s</span>/<span>def</span> <span>::username</span> string?)
(<span>s</span>/<span>def</span> <span>::password</span> string?)

(<span>s</span>/<span>def</span> <span>::last-login</span> number?)
(<span>s</span>/<span>def</span> <span>::comment</span> string?)

(<span>s</span>/<span>def</span> <span>::user</span>
  (<span>s</span>/keys
   <span>:req</span> [<span>::username</span> <span>::password</span>]
   <span>:opt</span> [<span>::comment</span> <span>::last-login</span>]))

(<span>s</span>/explain
 <span>::user</span>
 {<span>::username</span>   <span>"rich"</span>
  <span>::comment</span>    <span>"this is a user"</span>})
</pre>
</div>

<p>
We get an ok-ish error that tells us that for the particular map we
passed, the <code>::user</code> spec fails because it doesn't contain <code>::password</code>.
</p>

<pre>val: #:my-project.users{:username "rich", :comment "this is a user"} fails spec: :my-project.users/user predicate: (contains? % :my-project.users/password)
</pre>
</div>
</div>

<div id="outline-container-orgb0d0b9f">
<h3 id="orgb0d0b9f">Sequence specs - regular expressions for data</h3>
<div id="text-orgb0d0b9f">
<p>
A powerful mechanism in spec is sequences. We've already seen <code>s/coll-of</code> which
contains a uniform type of values (a collection of numbers for example) but
sequences are a bit more like regular expressions for data. In this case we
have a sequence with two things, which describe an ingredient for a recipe:
the first thing is a number for the quantity and the second thing is a unit
encoded as a keyword.
</p>

<div>
<pre>(require '[clojure.spec.alpha <span>:as</span> s])

(<span>s</span>/<span>def</span> <span>::ingredient</span> (<span>s</span>/cat <span>:quantity</span> number? <span>:unit</span> keyword?))
</pre>
</div>

<p>
With <code>s/cat</code> we always have to give a name to each position. <code>s/cat</code>
allows to both validate the shape of the value passed, but it also
enables the "conform" operation, which is somehow similar to parsing
or destructuring. If we pass a vector of two elements – a number and
a keyword –  we get back a map with the defined names:
</p>

<div>
<pre>(prn (<span>s</span>/conform <span>::ingredient</span> [2 <span>:teaspoon</span>]))
</pre>
</div>

<pre>{:quantity 2, :unit :teaspoon}
</pre>


<p>
By using some of the other operators which are reminiscent of regular
expressions, this technique can become quite …</p></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.pixelated-noise.com/blog/2020/09/10/what-spec-is/">https://www.pixelated-noise.com/blog/2020/09/10/what-spec-is/</a></em></p>]]>
            </description>
            <link>https://www.pixelated-noise.com/blog/2020/09/10/what-spec-is/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24432461</guid>
            <pubDate>Thu, 10 Sep 2020 14:04:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google, LinkedIn and Other Tech Firms Send Employees into New York Classrooms]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24431603">thread link</a>) | @BinaryBuddha
<br/>
September 10, 2020 | https://www.techtalentpipeline.nyc/tech-in-residence-corps | <a href="https://web.archive.org/web/*/https://www.techtalentpipeline.nyc/tech-in-residence-corps">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="siteWrapper">

      

      

      
        
          
            
            
          
        
      


      
      
      

      <main id="page" role="main">
        
        <!--
        --><!--
        --><div id="content" data-content-field="main-content" data-collection-id="5e32be4ad7315a3d73a0cac9">
         <!-- Create index sections -->

  
  <div id="tech-in-residence-section" data-url-id="tech-in-residence-section" data-collection-id="5e32be88d7315a3d73a0cf5b" data-edit-main-image="">
    
    
      
    

    <div>
      <div data-content-field="main-content">
        <div data-type="page" data-updated-on="1581102404633" id="page-5e32be88d7315a3d73a0cf5b"><div><div><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1580897032570_5815"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1580897106968-B8Z7K9E0IFK94XE2VZHS/ke17ZwdGBToddI8pDm48kAtQXdLwhyy0vpjAZYkTLANZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7YmDye92LJlx5Z6JHLEUGa2UaMxHmwY4n_De8kJ6Mlb2rNsr1dS9pQZdxMQNj-QpQg/logo-w.png" data-image="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1580897106968-B8Z7K9E0IFK94XE2VZHS/ke17ZwdGBToddI8pDm48kAtQXdLwhyy0vpjAZYkTLANZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7YmDye92LJlx5Z6JHLEUGa2UaMxHmwY4n_De8kJ6Mlb2rNsr1dS9pQZdxMQNj-QpQg/logo-w.png" data-image-dimensions="222x224" data-image-focal-point="0.5,0.5" alt="logo-w.png" data-load="false" data-image-id="5e3a9352f5b80670ad689683" data-type="image" src="https://www.techtalentpipeline.nyc/logo-w.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1580897032570_7149"><p>Equipping NYC tech leaders to teach college students the skills needed to successfully launch tech careers</p></div></div></div></div>
      </div>
    </div>
  </div>
  
  <div id="quote-carousel-section" data-url-id="quote-carousel-section" data-collection-id="5e32d079f8043d07500cfaca" data-edit-main-image="">
    
    
      
    

    <div>
      <div data-content-field="main-content">
        <div data-type="page" data-updated-on="1580388597021" id="page-5e32d079f8043d07500cfaca"><div><div><div data-block-json="{&quot;collectionId&quot;:&quot;5e32c6768a92c82fc8154439&quot;,&quot;design&quot;:&quot;carousel&quot;,&quot;headerText&quot;:&quot;Quote&quot;,&quot;textSize&quot;:&quot;medium&quot;,&quot;pageSize&quot;:30,&quot;imageAspectRatio&quot;:&quot;1.5&quot;,&quot;columnWidth&quot;:270,&quot;gutter&quot;:60,&quot;listImageSize&quot;:30,&quot;listImageAlignment&quot;:&quot;left&quot;,&quot;slidesPerRow&quot;:1,&quot;textAlignment&quot;:&quot;left&quot;,&quot;showTitle&quot;:true,&quot;showThumbnail&quot;:true,&quot;showExcerpt&quot;:true,&quot;showReadMoreLink&quot;:false,&quot;showPrice&quot;:true,&quot;productQuickViewEnabled&quot;:false,&quot;showPastOrUpcomingEvents&quot;:&quot;upcoming&quot;,&quot;metadataPosition&quot;:&quot;below-content&quot;,&quot;primaryMetadata&quot;:&quot;none&quot;,&quot;secondaryMetadata&quot;:&quot;none&quot;,&quot;filter&quot;:{},&quot;autoCrop&quot;:true,&quot;lightbox&quot;:false,&quot;mixedContent&quot;:true,&quot;blockId&quot;:&quot;0d55d238ae3bdb2957c6&quot;,&quot;hSize&quot;:null,&quot;floatDir&quot;:null}" data-block-type="55" id="block-yui_3_17_2_1_1580388476471_3903"><div>



<div>

  <div>

    

    <div>

      

        <div>

          
            <!-- Thumbnail -->
            

  
  <div>
    <a href="https://www.techtalentpipeline.nyc/quote-carousel/2020/1/30/royce-kok" data-title="Royce Kok" data-description="">
      <p><img data-src="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1580388347125-2IZNQD0AL2T3TFBWIL4L/ke17ZwdGBToddI8pDm48kBPw4N13dNaFqvN1wFuK0BxZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7Xj1nVWs2aaTtWBneO2WM-t_OL1jkxuzHCtZDSGPDO3iz-j0Y68h3gWhT4w543MCTg/q1.jpg" data-image="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1580388347125-2IZNQD0AL2T3TFBWIL4L/ke17ZwdGBToddI8pDm48kBPw4N13dNaFqvN1wFuK0BxZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7Xj1nVWs2aaTtWBneO2WM-t_OL1jkxuzHCtZDSGPDO3iz-j0Y68h3gWhT4w543MCTg/q1.jpg" data-image-dimensions="280x280" data-image-focal-point="0.5,0.5" alt="Royce Kok" data-load="false" src="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1580388347125-2IZNQD0AL2T3TFBWIL4L/ke17ZwdGBToddI8pDm48kBPw4N13dNaFqvN1wFuK0BxZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7Xj1nVWs2aaTtWBneO2WM-t_OL1jkxuzHCtZDSGPDO3iz-j0Y68h3gWhT4w543MCTg/q1.jpg">

    

    

        

        

      </p>
    </a>

    <!-- Products: Quick View -->
    

  </div>
  



          

          <div data-animation-role="content">

            <!-- Metadata (Above Title) -->
            

            
              <!-- Title -->
              
            

            <!-- Metadata (Below Title) -->
            

            
              
            

            
              
              <!-- Excerpt -->
                <div>
                  <p>Teaching at CUNY is one of the most rewarding things I’ve ever done. As a 1st generation college student, I feel honored to have this platform to give back and support students who have not had the same opportunities as me or many of my peers.</p><p><strong>Royce Kok</strong><br> Plaid, Data Warehousing for Analytics at Baruch College</p>
                </div>
              

              

              
            

            <!-- Metadata (Below Content) -->
            

          </div> <!-- End .summary-content -->

        </div> <!-- End .summary-item -->

      

        <div>

          
            <!-- Thumbnail -->
            

  
  <div>
    <a href="https://www.techtalentpipeline.nyc/quote-carousel/2020/2/6/mayor-bill-de-blasio" data-title="Mayor Bill de Blasio" data-description="">
      <p><img data-src="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1581000953705-9ODN4HAVTVQ2RXE6SEPH/ke17ZwdGBToddI8pDm48kGpgwyMer3OYDSmBquEbno1Zw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVFA4DTWVYV_9wMcc40WbHTcDgHq5ec0yygagY8rPNynI-ibnjMMQx-vulf6ufIzGWI/geraldinasebastianmbdb.jpg" data-image="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1581000953705-9ODN4HAVTVQ2RXE6SEPH/ke17ZwdGBToddI8pDm48kGpgwyMer3OYDSmBquEbno1Zw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVFA4DTWVYV_9wMcc40WbHTcDgHq5ec0yygagY8rPNynI-ibnjMMQx-vulf6ufIzGWI/geraldinasebastianmbdb.jpg" data-image-dimensions="499x499" data-image-focal-point="0.5,0.5" alt="Mayor Bill de Blasio" data-load="false" src="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1581000953705-9ODN4HAVTVQ2RXE6SEPH/ke17ZwdGBToddI8pDm48kGpgwyMer3OYDSmBquEbno1Zw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVFA4DTWVYV_9wMcc40WbHTcDgHq5ec0yygagY8rPNynI-ibnjMMQx-vulf6ufIzGWI/geraldinasebastianmbdb.jpg">

    

    

        

        

      </p>
    </a>

    <!-- Products: Quick View -->
    

  </div>
  



          

          <div data-animation-role="content">

            <!-- Metadata (Above Title) -->
            

            
              <!-- Title -->
              
            

            <!-- Metadata (Below Title) -->
            

            
              
            

            
              
              <!-- Excerpt -->
                <div>
                  <p>We have made significant strides to ensure that the growth of New York City’s booming tech ecosystem is fueled by qualified homegrown talent...As part of our administration’s plan to spur 100,000 good paying jobs, I recently announced a new goal of doubling the number of computer science graduates from the City University of New York by 2022. Central to achieving this goal is the launch of a new Tech-in-Residence Corps that will bring NYC industry professionals into local colleges to teach in-demand and emerging skills.</p><p><strong>Mayor Bill de Blasio</strong></p>
                </div>
              

              

              
            

            <!-- Metadata (Below Content) -->
            

          </div> <!-- End .summary-content -->

        </div> <!-- End .summary-item -->

      

        <div>

          
            <!-- Thumbnail -->
            

  
  <div>
    <a href="https://www.techtalentpipeline.nyc/quote-carousel/2020/1/30/nikolai" data-title="Nikolai Avteniev" data-description="">
      <p><img data-src="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1580388411753-74J7ZTH3IK5ZXHI8MJ9E/ke17ZwdGBToddI8pDm48kMqTWllqAnz46lb6GEtomGZZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxFuujnV-2zomHZfzmZ9k8xM2P4oqKbe0u16WF7q12VhpoDEieSQIrrUnihTGrQ3mg/q2.jpg" data-image="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1580388411753-74J7ZTH3IK5ZXHI8MJ9E/ke17ZwdGBToddI8pDm48kMqTWllqAnz46lb6GEtomGZZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxFuujnV-2zomHZfzmZ9k8xM2P4oqKbe0u16WF7q12VhpoDEieSQIrrUnihTGrQ3mg/q2.jpg" data-image-dimensions="706x856" data-image-focal-point="0.5,0.5" alt="Nikolai Avteniev" data-load="false" src="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1580388411753-74J7ZTH3IK5ZXHI8MJ9E/ke17ZwdGBToddI8pDm48kMqTWllqAnz46lb6GEtomGZZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxFuujnV-2zomHZfzmZ9k8xM2P4oqKbe0u16WF7q12VhpoDEieSQIrrUnihTGrQ3mg/q2.jpg">

    

    

        

        

      </p>
    </a>

    <!-- Products: Quick View -->
    

  </div>
  



          

          <div data-animation-role="content">

            <!-- Metadata (Above Title) -->
            

            
              <!-- Title -->
              
            

            <!-- Metadata (Below Title) -->
            

            
              
            

            
              
              <!-- Excerpt -->
                <div>
                  <p>With my final syllabus reviewed and ready…I had no idea what to expect. How many students would register? How would I make it to class on time? What would I actually do for two and a half hours?...I couldn't imagine standing in front of the classroom and lecturing the entire time. With the help of… my mentor at CCNY, I came up with a classroom approach which was sensible.</p><p><strong>Nikolai Avteniev,</strong> <br>LinkedIn, Advanced Topics in Modern Software Engineering @ City College of New York</p>
                </div>
              

              

              
            

            <!-- Metadata (Below Content) -->
            

          </div> <!-- End .summary-content -->

        </div> <!-- End .summary-item -->

      

    </div> <!-- End .summary-item-list -->

  </div> <!-- End .summary-item-list-container -->

</div>
</div></div></div></div></div>
      </div>
    </div>
  </div>
  
  <div id="about-section" data-url-id="about-section" data-collection-id="5e32d2c6b4e70977cf0ed54b" data-edit-main-image="">
    
    
      
    

    <div>
      <div data-content-field="main-content">
        <div data-type="page" data-updated-on="1581008995159" id="page-5e32d2c6b4e70977cf0ed54b"><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1580904761375_2969"><p><strong>The Tech-in-Residence Corps was launched in 2017 by the City of New York, NYC tech companies, and CUNY to equip college students with the in-demand skills they need to enter  the workforce.</strong></p></div></div><div><div data-block-type="2" id="block-yui_3_17_2_1_1580904761375_5947"><p>Co-designed by industry and academia, the program aims to infuse real-world experience and skills, taught by today’s top tech leaders, into tech degree programs. Tech-in-Residence Corps members  are equipped with training and support to teach the next generation of NYC students. </p></div></div></div></div>
      </div>
    </div>
  </div>
  
  <div id="prof-section" data-url-id="prof-section" data-collection-id="5e32d34ecd95a406db1a96f3" data-edit-main-image="">
    
    
      
    

    <div>
      <div data-content-field="main-content">
        <div data-type="page" data-updated-on="1580908853099" id="page-5e32d34ecd95a406db1a96f3"><div><div><div data-block-type="2" id="block-5e32d34ecd95a406db1a96f4"><p><h2>As an adjunct professor, <br>Tech-in-Residence Corps Members:</h2></p></div><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1580389198961_5554"><div>








  

    

      <figure data-scrolled="" data-test="image-block-v2-outer-wrapper">

        <div>
          
            <div data-animation-role="image" data-description="">
            
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1580389450190-FMWTGDEKELUQV6XAZTGD/ke17ZwdGBToddI8pDm48kLkXF2pIyv_F2eUT9F60jBl7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0iyqMbMesKd95J-X4EagrgU9L3Sa3U8cogeb0tjXbfawd0urKshkc5MgdBeJmALQKw/proff-2.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1580389450190-FMWTGDEKELUQV6XAZTGD/ke17ZwdGBToddI8pDm48kLkXF2pIyv_F2eUT9F60jBl7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0iyqMbMesKd95J-X4EagrgU9L3Sa3U8cogeb0tjXbfawd0urKshkc5MgdBeJmALQKw/proff-2.jpeg" data-image-dimensions="2500x1667" data-image-focal-point="0.5,0.5" alt="proff-2.jpeg" src="https://www.techtalentpipeline.nyc/proff-2.jpeg"></p>
          
            </div>
          

        </div>

        
          
          <figcaption data-width-ratio="">
            <div>

              
                <div><p>Teach in the Classroom</p></div>
              

              
                <div><p>With the help of faculty, specialized training and other support, teach or co-teach tech courses at colleges across the five boroughs.</p></div>
              

              

            </div>
          </figcaption>
        

      </figure>

    

  


</div></div></div><div><div data-block-type="5" id="block-yui_3_17_2_1_1580389198961_4269"><div>








  

    

      <figure data-scrolled="" data-test="image-block-v2-outer-wrapper">

        <div>
          
            <div data-animation-role="image" data-description="">
            
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1580389372540-KLHI6IY6ZM2H37UX9TQJ/ke17ZwdGBToddI8pDm48kO7Rg1Gpu728H4UqxUIfecJZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PICj5SdZHY9KUswDgTH3eH8sP5PrkY15Dr7CE2CPSRiTEKMshLAGzx4R3EDFOm1kBS/proff-1.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1580389372540-KLHI6IY6ZM2H37UX9TQJ/ke17ZwdGBToddI8pDm48kO7Rg1Gpu728H4UqxUIfecJZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PICj5SdZHY9KUswDgTH3eH8sP5PrkY15Dr7CE2CPSRiTEKMshLAGzx4R3EDFOm1kBS/proff-1.jpeg" data-image-dimensions="800x533" data-image-focal-point="0.5,0.5" alt="proff-1.jpeg" src="https://www.techtalentpipeline.nyc/proff-1.jpeg"></p>
          
            </div>
          

        </div>

        
          
          <figcaption data-width-ratio="">
            <div>

              
                <div><p>Inform Curriculum</p></div>
              

              
                <div><p>Teach in your area of expertise, selecting from topics such as software engineering, web development, mobile development, data science and analytics, artificial intelligence, and cybersecurity. <strong>Photo Credit: Benjamin Ohene</strong></p></div>
              

              

            </div>
          </figcaption>
        

      </figure>

    

  


</div></div></div><div><div data-block-type="5" id="block-yui_3_17_2_1_1580389198961_7907"><div>








  

    

      <figure data-scrolled="" data-test="image-block-v2-outer-wrapper">

        <div>
          
            <div data-animation-role="image" data-description="">
            
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1580389582846-9C4YLNMA2VIH61U38RJT/ke17ZwdGBToddI8pDm48kFmfxoboNKufWj-55Bgmc-J7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0iXS6XmVv7bUJ418E8Yoc1hjuviiiZmrL38w1ymUdqq4JaGeFUxjM-HeS7Oc-SSFcg/proff-3.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1580389582846-9C4YLNMA2VIH61U38RJT/ke17ZwdGBToddI8pDm48kFmfxoboNKufWj-55Bgmc-J7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0iXS6XmVv7bUJ418E8Yoc1hjuviiiZmrL38w1ymUdqq4JaGeFUxjM-HeS7Oc-SSFcg/proff-3.jpeg" data-image-dimensions="2500x1668" data-image-focal-point="0.5,0.5" alt="proff-3.jpeg" src="https://www.techtalentpipeline.nyc/proff-3.jpeg"></p>
          
            </div>
          

        </div>

        
          
          <figcaption data-width-ratio="">
            <div>

              
                <div><p>Collaborate with Top NYC Tech Companies</p></div>
              

              
                <div><p>When you sign up, you join a community of top NYC tech companies working together to create a stronger pipeline of NYC tech talent.</p></div>
              

              

            </div>
          </figcaption>
        

      </figure>

    

  


</div></div></div></div></div></div></div>
      </div>
    </div>
  </div>
  
  <div id="why-section" data-url-id="why-section" data-collection-id="5e32d7901213336bbc29a31f" data-edit-main-image="">
    
    
      
    

    <div>
      <div data-content-field="main-content">
        <div data-type="page" data-updated-on="1581001620218" id="page-5e32d7901213336bbc29a31f"><div><div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1580910749793_8176"><p>The Tech-in-Residence Corps encourages both companies and individuals to participate</p></div></div></div><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1580390289837_5286"><div>








  

    

      <figure data-scrolled="" data-test="image-block-v2-outer-wrapper">

        <div>
          
            <div data-animation-role="image" data-description="">
            
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1580390525658-2KLKEPEMV57590UX9XMN/ke17ZwdGBToddI8pDm48kO7Rg1Gpu728H4UqxUIfecJZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PICj5SdZHY9KUswDgTH3eH8sP5PrkY15Dr7CE2CPSRiTEKMshLAGzx4R3EDFOm1kBS/in1.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1580390525658-2KLKEPEMV57590UX9XMN/ke17ZwdGBToddI8pDm48kO7Rg1Gpu728H4UqxUIfecJZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PICj5SdZHY9KUswDgTH3eH8sP5PrkY15Dr7CE2CPSRiTEKMshLAGzx4R3EDFOm1kBS/in1.jpeg" data-image-dimensions="800x533" data-image-focal-point="0.5,0.5" alt="in1.jpeg" src="https://www.techtalentpipeline.nyc/in1.jpeg"></p>
          
            </div>
          

        </div>

        
          
          <figcaption data-width-ratio="">
            <div>

              
                <div><p>A Platform to Give Back</p></div>
              

              
                <div><p>Utilize your expertise to prepare local college students for success <strong>Photo Credit: Benjamin Ohene</strong></p></div>
              

              

            </div>
          </figcaption>
        

      </figure>

    

  


</div></div></div><div><div data-block-type="5" id="block-yui_3_17_2_1_1580390289837_6690"><div>








  

    

      <figure data-scrolled="" data-test="image-block-v2-outer-wrapper">

        <div>
          
            <div data-animation-role="image" data-description="">
            
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1580919040711-B41K1Y0GN7NGKAEO437C/ke17ZwdGBToddI8pDm48kHH9S2ID7_bpupQnTdrPcoF7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0nQwvinDXPV4EYh2MRzm-RRB5rUELEv7EY2n0AZOrEupxpSyqbqKSgmzcCPWV5WMiQ/unnamed.jpg" data-image="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1580919040711-B41K1Y0GN7NGKAEO437C/ke17ZwdGBToddI8pDm48kHH9S2ID7_bpupQnTdrPcoF7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0nQwvinDXPV4EYh2MRzm-RRB5rUELEv7EY2n0AZOrEupxpSyqbqKSgmzcCPWV5WMiQ/unnamed.jpg" data-image-dimensions="2500x1666" data-image-focal-point="0.5,0.5" alt="unnamed.jpg" src="https://www.techtalentpipeline.nyc/unnamed.jpg"></p>
          
            </div>
          

        </div>

        
          
          <figcaption data-width-ratio="">
            <div>

              
                <div><p>Be a Leader in the NYC Tech Space</p></div>
              

              
                <div><p>Network with other NYC tech professionals while developing your leadership skills</p></div>
              

              

            </div>
          </figcaption>
        

      </figure>

    

  


</div></div></div><div><div data-block-type="5" id="block-yui_3_17_2_1_1580390289837_9157"><div>








  

    

      <figure data-scrolled="" data-test="image-block-v2-outer-wrapper">

        <div>
          
            <div data-animation-role="image" data-description="">
            
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1580390629374-AE5K8SI64HVZLT78HTHE/ke17ZwdGBToddI8pDm48kO7Rg1Gpu728H4UqxUIfecJZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PICj5SdZHY9KUswDgTH3eH8sP5PrkY15Dr7CE2CPSRiTEKMshLAGzx4R3EDFOm1kBS/in3.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1580390629374-AE5K8SI64HVZLT78HTHE/ke17ZwdGBToddI8pDm48kO7Rg1Gpu728H4UqxUIfecJZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PICj5SdZHY9KUswDgTH3eH8sP5PrkY15Dr7CE2CPSRiTEKMshLAGzx4R3EDFOm1kBS/in3.jpeg" data-image-dimensions="800x533" data-image-focal-point="0.5,0.5" alt="in3.jpeg" src="https://www.techtalentpipeline.nyc/in3.jpeg"></p>
          
            </div>
          

        </div>

        
          
          <figcaption data-width-ratio="">
            <div>

              
                <div><p>Support Your Company’s Goals</p></div>
              

              
                <div><p>Build your company-to-classroom connection by preparing, identifying, quality, diverse tech talent <strong>Photo Credit: Benjamin Ohene</strong></p></div>
              

              

            </div>
          </figcaption>
        

      </figure>

    

  


</div></div></div><div><div data-block-type="5" id="block-yui_3_17_2_1_1580390289837_10984"><div>








  

    

      <figure data-scrolled="" data-test="image-block-v2-outer-wrapper">

        <div>
          
            <div data-animation-role="image" data-description="">
            
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1580390711916-O8YQHIUU00SUVQHS99D3/ke17ZwdGBToddI8pDm48kLkXF2pIyv_F2eUT9F60jBl7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0iyqMbMesKd95J-X4EagrgU9L3Sa3U8cogeb0tjXbfawd0urKshkc5MgdBeJmALQKw/in4.jpg" data-image="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1580390711916-O8YQHIUU00SUVQHS99D3/ke17ZwdGBToddI8pDm48kLkXF2pIyv_F2eUT9F60jBl7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0iyqMbMesKd95J-X4EagrgU9L3Sa3U8cogeb0tjXbfawd0urKshkc5MgdBeJmALQKw/in4.jpg" data-image-dimensions="2500x1667" data-image-focal-point="0.5,0.5" alt="in4.jpg" src="https://www.techtalentpipeline.nyc/in4.jpg"></p>
          
            </div>
          

        </div>

        
          
          <figcaption data-width-ratio="">
            <div>

              
                <div><p>Become a Professor, Keep Your Day Job</p></div>
              

              
                <div><p>Teach a college course without a Master’s degree while maintaining your full time position</p></div>
              

              

            </div>
          </figcaption>
        

      </figure>

    

  


</div></div></div></div></div></div></div>
      </div>
    </div>
  </div>
  
  <div id="members-section" data-url-id="members-section" data-collection-id="5e32d5b7d7315a3d73a3b20d" data-edit-main-image="">
    
    
      
    

    <div>
      <div data-content-field="main-content">
        <div data-type="page" data-updated-on="1581007556958" id="page-5e32d5b7d7315a3d73a3b20d"><div><div><div data-block-type="2" id="block-5e32d5b7d7315a3d73a3b20e"><p><h2>Tech-in-Residence <br>Corps members <br>from:</h2></p></div></div><div><div data-block-type="5" id="block-yui_3_17_2_1_1581001830238_9429"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1581004140978-7VRU85QKTGD2LCNZEF42/ke17ZwdGBToddI8pDm48kCrj8nYSkC8OUQNWb7HrhlJZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVF9ZtAsoRkFUW7RVNbHmMPJX-4VP4LhdXw_2zrJDUNf291lH3P2bFZvTItROhWrBJ0/logo-google.png" data-image="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1581004140978-7VRU85QKTGD2LCNZEF42/ke17ZwdGBToddI8pDm48kCrj8nYSkC8OUQNWb7HrhlJZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVF9ZtAsoRkFUW7RVNbHmMPJX-4VP4LhdXw_2zrJDUNf291lH3P2bFZvTItROhWrBJ0/logo-google.png" data-image-dimensions="464x260" data-image-focal-point="0.5,0.5" alt="logo-google.png" data-load="false" data-image-id="5e3c356c1c2cbb6170caa8a6" data-type="image" src="https://www.techtalentpipeline.nyc/logo-google.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="5" id="block-yui_3_17_2_1_1581001830238_10774"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1581004167198-RK5XUMT935NDFSP1U4Y9/ke17ZwdGBToddI8pDm48kCrj8nYSkC8OUQNWb7HrhlJZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVF9ZtAsoRkFUW7RVNbHmMPJX-4VP4LhdXw_2zrJDUNf291lH3P2bFZvTItROhWrBJ0/logo-spotify.png" data-image="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1581004167198-RK5XUMT935NDFSP1U4Y9/ke17ZwdGBToddI8pDm48kCrj8nYSkC8OUQNWb7HrhlJZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVF9ZtAsoRkFUW7RVNbHmMPJX-4VP4LhdXw_2zrJDUNf291lH3P2bFZvTItROhWrBJ0/logo-spotify.png" data-image-dimensions="464x260" data-image-focal-point="0.5,0.5" alt="logo-spotify.png" data-load="false" data-image-id="5e3c3587e1a6a03142aaa44a" data-type="image" src="https://www.techtalentpipeline.nyc/logo-spotify.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div></div><div><div data-block-type="5" id="block-yui_3_17_2_1_1581001830238_13611"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1581004206516-QHHM1CX6A8FOXHGZAKHQ/ke17ZwdGBToddI8pDm48kCrj8nYSkC8OUQNWb7HrhlJZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVF9ZtAsoRkFUW7RVNbHmMPJX-4VP4LhdXw_2zrJDUNf291lH3P2bFZvTItROhWrBJ0/image-asset.png" data-image="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1581004206516-QHHM1CX6A8FOXHGZAKHQ/ke17ZwdGBToddI8pDm48kCrj8nYSkC8OUQNWb7HrhlJZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVF9ZtAsoRkFUW7RVNbHmMPJX-4VP4LhdXw_2zrJDUNf291lH3P2bFZvTItROhWrBJ0/image-asset.png" data-image-dimensions="464x260" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="5e3c35ae1ad4fa389de241f0" data-type="image" src="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1581004206516-QHHM1CX6A8FOXHGZAKHQ/ke17ZwdGBToddI8pDm48kCrj8nYSkC8OUQNWb7HrhlJZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVF9ZtAsoRkFUW7RVNbHmMPJX-4VP4LhdXw_2zrJDUNf291lH3P2bFZvTItROhWrBJ0/image-asset.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="5" id="block-yui_3_17_2_1_1581001830238_12252"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1581004189426-8RGQ9GMJ156OTTM170D3/ke17ZwdGBToddI8pDm48kCrj8nYSkC8OUQNWb7HrhlJZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVF9ZtAsoRkFUW7RVNbHmMPJX-4VP4LhdXw_2zrJDUNf291lH3P2bFZvTItROhWrBJ0/logo-linkedin.png" data-image="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1581004189426-8RGQ9GMJ156OTTM170D3/ke17ZwdGBToddI8pDm48kCrj8nYSkC8OUQNWb7HrhlJZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVF9ZtAsoRkFUW7RVNbHmMPJX-4VP4LhdXw_2zrJDUNf291lH3P2bFZvTItROhWrBJ0/logo-linkedin.png" data-image-dimensions="464x260" data-image-focal-point="0.5,0.5" alt="logo-linkedin.png" data-load="false" data-image-id="5e3c359d55a46d19cd29b799" data-type="image" src="https://www.techtalentpipeline.nyc/logo-linkedin.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div></div></div></div>
      </div>
    </div>
  </div>
  
  <div id="cta-section" data-url-id="cta-section" data-collection-id="5e32d97858164e71d27deff8" data-edit-main-image="">
    
    
      
    

    <div>
      <div data-content-field="main-content">
        <div data-type="page" data-updated-on="1581102437381" id="page-5e32d97858164e71d27deff8"><div><div><div data-block-type="2" id="block-5e32d97858164e71d27deff9"><p><h2>To Learn More about the Tech-in-Residence Corps</h2></p></div></div><div><div data-block-type="2" id="block-yui_3_17_2_1_1580912628640_5573"><p><h2>Featured Courses Taught by the NYC Tech-in-Residence Corps</h2></p></div></div></div></div>
      </div>
    </div>
  </div>
  
  <div id="logo-section" data-url-id="logo-section" data-collection-id="5e3c383a55a46d19cd2a5dc3" data-edit-main-image="">
    
    
      
    

    <div>
      <div data-content-field="main-content">
        <div data-type="page" data-updated-on="1582220568614" id="page-5e3c383a55a46d19cd2a5dc3"><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1581004859587_4621"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1581004987579-WC9K9564G8MYWRAPSNM5/ke17ZwdGBToddI8pDm48kEGQ2yHp6dvVmUlNL9i9d9xZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7XxG-9FZQiNMT_ZdcQnlMXZQp8pG38zHqwO21k9T340O6-PGnTZvEhS2sJNwHSRqmA/logo-cybernyc.png" data-image="https://images.squarespace-cdn.com/content/v1/54d3a0dee4b026182d00678f/1581004987579-WC9K9564G8MYWRAPSNM5/ke17ZwdGBToddI8pDm48kEGQ2yHp6dvVmUlNL9i9d9xZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7XxG-9FZQiNMT_ZdcQnlMXZQp8pG38zHqwO21k9T340O6-PGnTZvEhS2sJNwHSRqmA/logo-cybernyc.png" data-image-dimensions="136x146" data-image-focal-point="0.5,0.5" alt="logo-cybernyc.png" data-load="false" data-image-id="5e3c38bb1ad4fa389de2e91d" data-type="image" src="https://www.techtalentpipeline.nyc/logo-cybernyc.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div></div></div></div>
      </div>
    </div>
  </div>
        </div><!--
        -->
        
      </main>

      

      

    </div></div>]]>
            </description>
            <link>https://www.techtalentpipeline.nyc/tech-in-residence-corps</link>
            <guid isPermaLink="false">hacker-news-small-sites-24431603</guid>
            <pubDate>Thu, 10 Sep 2020 12:25:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Rack Elevation Diagram Generator in JavaScript]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24431134">thread link</a>) | @wjholden
<br/>
September 10, 2020 | https://wjholden.com/rack | <a href="https://web.archive.org/web/*/https://wjholden.com/rack">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://wjholden.com/rack</link>
            <guid isPermaLink="false">hacker-news-small-sites-24431134</guid>
            <pubDate>Thu, 10 Sep 2020 11:13:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Voucher System verification using TLA+]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24431082">thread link</a>) | @jayp1418
<br/>
September 10, 2020 | https://www.moritz.systems/blog/voucher-system-verification-using-tlaplus/ | <a href="https://web.archive.org/web/*/https://www.moritz.systems/blog/voucher-system-verification-using-tlaplus/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<p><img src="https://raw.githubusercontent.com/Moritz-Systems/moritz_staticDir/master/money-computer-desk-finance-success-internet-business-banking-e-commerce.jpg" alt="E-Money"></p>

<p>Continuing from our <a href="https://www.moritz.systems/blog/an-introduction-to-formal-verification/">previous article</a>,
let us take an example of how to write a
TLA+ proof for a real-world specification of a distributed system.
For this exercise we will go through
the <em>Voucher Trading System</em> process as specified by the
<a href="https://tools.ietf.org/rfc/rfc3506.txt">RFC3506</a> hosted by <abbr title="Internet Engineering Task Force">IETF</abbr>.
The distributed and concurrent systems require a
<a href="https://en.wikipedia.org/wiki/Consensus_(computer_science)">consensus protocol</a>
to achieve overall system reliability and immunity to failures of nodes.
We decided to select for this VTS network a simple
<a href="https://en.wikipedia.org/wiki/Two-phase_commit_protocol">Two-phase commit</a> protocol.</p>

<p>This article presents how TLA+ and formal methods in general assure correctness of the defined specification,
in our case, of the VTS network and the distributed consensus implementation.
Preparing a formal proof guarantees the 1-to-1 match between a specification and the implementation.
This property of formal methodology verifies not just the fultlessness of a specification, but catches
possible flaws or wrong assumptions in a system at a very early stage and allows fixing them before
it could be too late or too costly.</p>

<p>If you want to avoid your product to
<a href="https://www.theregister.com/2020/08/13/yam_cryptocurrency_bug_governance/">implode</a>,
and easily catch a set of flaws in the specification itself and in an implementation itself, learn more about TLA+.</p>

<h3 id="an-introduction-to-consensus-protocol">An introduction to consensus protocol</h3>

<p>Consensus protocol is a mechanism in distributed computing networks where the
participating nodes propose values and all of them have to agree on one of the
proposed values.</p>

<p>This mechanism assures that all interacting entities can do a transaction
without entering into conflicting conditions and always leading into well
defined accomplished transaction states. The aim is to make the overall system
fault-tolerant and resillent, protecting the network from security attacks and
guaranteeing scalable and efficient implementation of its application.</p>

<p>The elementary properties of consensus protocol are:</p>

<ul>
<li><strong>Validity</strong> - any value decided is value proposed.</li>
<li><strong>Consistency</strong> - no two correct nodes decide differently.</li>
<li><strong>Termination</strong> - every correct node eventually decides.</li>
<li><strong>Integrity</strong> - a node decides at most once.</li>
</ul>

<p>Consensus protocol plays the key role in distributed IoT networks, load
balancing, clock synchronization, robotics, blockchain systems and many more.</p>

<p><img src="https://raw.githubusercontent.com/Moritz-Systems/moritz_staticDir/master/iot_cloud.svg" alt="Internet of Things Cloud"></p>

<p><a href="https://en.wikipedia.org/wiki/Two-phase_commit_protocol">Two-phase commit</a>
(abbreviated as <em>2PC</em>)
is a specialized version of the consensus protocol and consists of two
phases:</p>

<ul>
<li><strong>Phase 1</strong> The request to prepare phase, in which a coordinator process attempts to prepare
all the transaction’s participating processes.</li>
<li><strong>Phase 2</strong> The commit or abort phase, in which the coordinator decides whether
to commit or abort the transaction and notifies the result to all the participant processes.</li>
</ul>

<p><img src="https://raw.githubusercontent.com/Moritz-Systems/moritz_staticDir/master/2pc.svg" alt="Two-phase commit protocol"></p>

<p><abbr title="Two-phase commit">2PC</abbr> is a simple mechanism of
<a href="https://en.wikipedia.org/wiki/Atomic_commit">atomic commitment protocol</a>
and it is used in the
<abbr title="Voucher Trading System">VTS</abbr>
network, where the coordinator (or arbiter) is the
centralized or distributed
<strong>Voucher Trading Provider</strong> and
participating nodes consist of: <strong>issuers</strong>, <strong>holders</strong> and <strong>collectors</strong>.
The participating nodes exchange <strong>vouchers</strong> upon which the consensus is made.</p>

<h3 id="prelude">Prelude</h3>

<p>Before we go deeper into TLA+, we need a general introduction to RFC3506.</p>

<p><img src="https://raw.githubusercontent.com/Moritz-Systems/moritz_staticDir/master/coupon-code-discount-sale-business-music-e-commerce-advertising-mockup.jpg" alt="E-commerce Voucher"></p>

<p><a href="https://tools.ietf.org/rfc/rfc3506.txt">RFC3506</a>
is a specification titled as “Requirements and Design for Voucher Trading System
(VTS)“. It describes how to do trading of vouchers (think of discount
coupons). We will be looking at the process of issuing a voucher as described
in the description in RFC in the chapters “Background”,
“Terminology” and “Model and VTS Requirements”.</p>

<p>Let’s define the necessary terminology regarding the voucher system:</p>

<ul>
<li><strong><em>Issuer</em></strong> - An entity who can issue vouchers with a promise.</li>
<li><strong><em>Holder</em></strong> - An entity who can hold vouchers that are issued.</li>
<li><strong><em>Collector</em></strong> - An entity who can collect the voucher and deliver the promise in
the voucher.</li>
<li><strong><em>Voucher</em></strong> - A digital representation of an “agreement” that is traded among
various entities.</li>
<li><strong><em>Voucher Trading Provider (VTP)</em></strong> - An agreed upon arbiter which helps carry out
the various operations between the entities and the voucher.</li>
</ul>

<p>In addition to the above, we also define a
<a href="https://en.wikipedia.org/wiki/Finite-state_machine">Finite-state Machine</a>
for the
<a href="https://github.com/byisystems/byihive/blob/master/docs/dot/VoucherLifeCycle.gv">voucher life cycle</a>:
this is a simple state machine that makes sure the voucher is in the correct
state at any given point in time. Think of this as similar to the state of the
turnstile from the example that was mentioned in the
<a href="https://www.moritz.systems/blog/an-introduction-to-formal-verification/">previous article</a>.</p>

<p><img src="https://raw.githubusercontent.com/Moritz-Systems/moritz_staticDir/master/voucher-life-cycle.png" alt="Voucher Life Cycle"></p>

<ul>
<li><p><strong><em>Phantom</em></strong> - This is a new meta state introduced (not present in RFC3506), to
indicate a <strong><em>voucher</em></strong> which has not yet been issued. This state is held by
vouchers taking part in an issue transaction, when the transaction aborts,
these <strong><em>vouchers</em></strong> will cease to exist.</p></li>

<li><p><strong><em>Valid</em></strong> - This is the state of voucher that is valid for transfer or redeeming.</p></li>

<li><p><strong><em>Redeemed</em></strong> - This indicates the “agreement” or “promise” in the voucher which has been
delivered and is no longer valid.</p></li>
</ul>

<p>Finally, we also bring in the already described Two-phase commit protocol which helps
with the consensus part of the “trading” of vouchers. We use the TLA+
<a href="https://lamport.azurewebsites.net/video/video6-script.pdf">proof</a> given by
Leslie Lamport as our starting point to write up the proofs for the “trading” of
vouchers.</p>

<p>To present a model of our voucher network and write a TLA+ proof for it,
we start with a simplified case of exactly one Issuer and one Holder trying to
“issue” or “abort” a voucher transaction.
To illustrate the workflow of six possible operations with the Two-phase commit
protocol network, we present a message sequence diagram
and include in it the User, Issuer, Holder, Voucher and
<abbr title="Voucher Trading Provider">VTP</abbr>.
The User and Voucher from a technical point of view are not participating nodes in the network,
but for the sake of simplicity we include them in the drawing.</p>

<p><a href="https://raw.githubusercontent.com/Moritz-Systems/moritz_staticDir/master/message-sequence-diagram.png">
<img src="https://raw.githubusercontent.com/Moritz-Systems/moritz_staticDir/master/message-sequence-diagram.png" alt="Message Sequence Diagram">
</a></p>

<p>The operations are as follows:</p>

<ol>
<li>Propose a decision for each of the Issuer and Holder of the Voucher.</li>
<li>Prepare the Voucher for the transaction.</li>
<li>The Issuer, Holder and the Voucher are added to the <abbr title="Voucher Trading Provider">VTP</abbr>.</li>
<li>The <abbr title="Voucher Trading Provider">VTP</abbr> queries for the decision of the issuer and holder.</li>
<li>If all the parties are in agreement <abbr title="Voucher Trading Provider">VTP</abbr> commits the transaction and the voucher is issued.</li>
<li>If no parties can come to an agreement, <abbr title="Voucher Trading Provider">VTP</abbr> aborts the transaction and the voucher is not issued.</li>
</ol>

<p>We are now ready to break this down into a formal proof in TLA+.</p>

<h3 id="writing-the-tla-proof">Writing the TLA+ proof</h3>

<p>Writing TLA+ proofs would be similar to writing up code for a program but with
some additional attributes. We have the usual programming language features like constants,
variables and functions; however, they look more mathematical to what we might expect from
a typical programming language like C/C++, Python, Go or Rust.
In order to write the formal proof, we need to use some further specifics of the TLA+ syntax,
going beyond the already presented knowledge from the
<a href="http://localhost:1313/blog/an-introduction-to-formal-verification/">previous article</a>,
where we solved the Die Hard problem with two jugs.</p>

<ul>
<li><strong><em>Messages</em></strong> - One of the things that have to be taken into account when designing
a concurrent and distributed system is that the participants within the system
will need to communicate with one another. This results in implementation of
multiple ways of passing messages across processes (for example pipes, sockets
etc). Even though TLA+ does not go into specifics of how this communication is
implemented, all we need to know is that TLA+ abstracts all the various types
of communication among entities as passing around “messages” among them.
<br></li>
</ul>

<pre><code>  Messages ==
    [type : {"Prepared"}, vi : I] \cup
    [type : {"Prepared"}, vh : H] \cup
    [type : {"Issue", "Abort"}]
</code></pre>

<ul>
<li><strong><em>Initial State</em></strong> - Any system within our specification should have a well
defined initial state, this is equivalent to initializing the start of the
program setting up the variables, entry point etc. Our simulation always
begins in this state regardless. For a simple
<a href="https://en.wikipedia.org/wiki/Finite-state_machine">Finite-state Machine</a>
this would be the “Start” state.
<br></li>
</ul>

<pre><code>  VTPInit ==
    (*****************************************************)
    (* The initial predicate.                            *)
    (*****************************************************)
    /\ vState = [v \in V |-&gt; "phantom"]
    /\ vlcState = [v \in V |-&gt; "init"]
    /\ hState = [h \in H |-&gt; "waiting"]
    /\ iState = [i \in I |-&gt; "waiting"]
    /\ vtpState = "init"
    /\ vtpIPrepared   = {}
    /\ msgs = {}
</code></pre>

<ul>
<li><strong><em>Next state</em></strong> - This is usually a combination of various possible states that is
allowed from the initial state and also includes the final states that would be
reached by the system we are trying to verify. Each of the states is
represented by something that looks like a function call representing an
operation that is allowed for the state.</li>
</ul>

<pre><code>  VTPNext ==
    \/ \E v \in V:
         VTPIssue(v) \/ VTPAbort(v)
    \/ \E h,i \in H \cup I:
         VTPRcvPrepared(h,i)
    \/ \E h \in H:
         HPrepare(h) \/ HChooseToAbort(h)
         \/ HRcvAbortMsg(h) \/ HRcvIssueMsg(h)
    \/ \E i \in I:
         IPrepare(i) \/ IChooseToAbort(i)
         \/ IRcvAbortMsg(i) \/ IRcvIssueMsg(i)  
</code></pre>

<p>In the above example, the definition of <code>VTPIssue(v)</code> describes the state of the
  system once a voucher has been issued, where we have to make sure the
  following things are correct.</p>

<ul>
<li>The initial state of the voucher is “phantom”, i.e. the voucher does not exist yet.</li>
<li>The voucher life cycle machine is currently in “init” state.</li>
<li>The voucher transaction provider is currently in the “init” state.</li>
<li>The Holder and Issuer are in the Prepared state.
<br></li>
</ul>

<p>Once the above states are true, we “issue” the voucher and the next expected states are</p>

<ul>
<li>The voucher transaction provider is in “done” state.</li>
<li>The voucher’s state has become “valid”, only the voucher which the entities
were exchanging has actually switched to this state.</li>
<li>The voucher life cycle machine has switched over to “working” state.</li>
<li>Make sure the “message” for the operation “Issue” has arrived in the messages list.
<br></li>
</ul>

<p>In addition to the above, we also make sure things that were not supposed to
  “change” have not changed, this is quite important to make sure that our state
  transition has not caused any unwanted side effects.</p>

<p>In this way we define the various states that the system can be in using our
  TLA+ specification.</p>

<ul>
<li><strong><em>Invariants</em></strong> - This is a very important part of writing TLA+ specifications, an
invariant can easily be described by asking “what are the things within the
system that …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.moritz.systems/blog/voucher-system-verification-using-tlaplus/">https://www.moritz.systems/blog/voucher-system-verification-using-tlaplus/</a></em></p>]]>
            </description>
            <link>https://www.moritz.systems/blog/voucher-system-verification-using-tlaplus/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24431082</guid>
            <pubDate>Thu, 10 Sep 2020 11:05:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Towards a content-addressed model for Nix]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24430823">thread link</a>) | @domenkozar
<br/>
September 10, 2020 | https://www.tweag.io/blog/2020-09-10-nix-cas/ | <a href="https://web.archive.org/web/*/https://www.tweag.io/blog/2020-09-10-nix-cas/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><div><p>This is my first post about content-addressability in Nix — a long-awaited feature that is hopefully coming soon!
In this post I will show you how this feature will improve the Nix
infrastructure. I’ll come back in another post to explain the technical challenges of
adding content-addressability to Nix.</p>
<p>Nix has a wonderful model for handling packages.
Because each derivation is stored under (aka <em>addressed by</em>) a unique
name, multiple versions of the same library can coexist on the same
system without issues: each version of the library has a distinct
name, as far as Nix is concerned.</p>
<p>What’s more, if <code>openssl</code> is upgraded in <a href="https://github.com/NixOS/nixpkgs/">Nixpkgs</a>, Nix knows that all the
packages that depend on <code>openssl</code> (i.e., almost everything) must be
rebuilt, if only so that they point at the name of the new <code>openssl</code>
version. This way, a Nix installation will never feature a package
built for one version of <code>openssl</code>, but dynamically linked against
another: as a user, it means that you will never have an <em>undefined
symbol</em> error. Hurray!</p>
<h2>The input-addressed store</h2>
<p>How does Nix achieve this feat? The idea is that the name of a package
is derived from all of its inputs (that is, the complete list of
dependencies, as well as the package description). So if you change
the git tag from which <code>openssl</code> is fetched, the name changes, if the
name of <code>openssl</code> changes, then the name of any package which has <code>openssl</code> in
its dependencies changes.</p>
<p>However this can be very pessimistic: even changes that aren’t
semantically meaningful can imply mass rebuilding and downloading. As
a slightly extreme example, <a href="https://github.com/NixOS/nixpkgs/pull/83446">this merge-request on
Nixpkgs</a> makes a tiny change to the way <code>openssl</code> is built. It doesn’t actually
change <code>openssl</code>, yet requires rebuilding an insane amount of
packages. Because, as far as Nix is concerned, all these packages have
different names, hence are different packages. In reality, though,
they weren’t.</p>
<p>Nevertheless, the cost of the rebuild has to be born by the Nix
infrastructure: <a href="https://hydra.nixos.org/">Hydra</a> builds all packages to populate the cache,
and all the newly built packages must be stored. It costs both time,
and money (in cpu power, and storage space).</p>
<h2>Unnecessary rebuilds?</h2>
<p>Most distributions, by default, don’t rebuild packages when their dependencies change, and have a (more-or-less automated) process to detect changes that require rebuilding reverse dependencies.
For example, Debian <a href="https://www.debian.org/doc/debian-policy/policy.pdf#81">tries to detect ABI changes automatically</a> and Fedora has a <a href="https://docs.fedoraproject.org/en-US/fesco/Updates_Policy/">more manual process</a>.
But Nix doesn’t.</p>
<p>The issue is that the notion of a “breaking change” is a very fuzzy one.
Should we follow Debian and consider that only ABI changes are breaking?
This criterion only applies for shared libraries, and as the Debian policy acknowledges, only for “well-behaved” programs.
So if we follow this criterion, there’s still need for manual curation, which is <strong>precisely</strong> what Nix tries to avoid.</p>
<h2>The content-addressed model</h2>
<p>Quite happily, there is a criterion to avoid many useless rebuilds without sacrificing correctness: detecting when changes in a package (or one of its dependencies) yields the exact same output.
That might seem like an edge case, but the <code>openssl</code> example above (and many others) shows that there’s a practical application to it.
As another example, <code>go</code> depends on <code>perl</code> for its tests, so an upgrade of <code>perl</code> requires rebuilding all the Go packages in Nixpkgs, although it most likely doesn’t change the output of the <code>go</code> derivation.</p>
<p>But, for Nix to recognise that a package is not a new package, the
new, unchanged, <code>openssl</code> or <code>go</code> packages must have <em>the same name</em>
as the old version. Therefore, the name of a package must not be
derived from its inputs which have changed, but, instead, it should be
derived from the content of the compiled package. This is called
content addressing.</p>
<p>Content addressing is how you can be sure that when you and a
colleague at the other side of the world type <code>git checkout 7cc16bb8cd38ff5806e40b32978ae64d54023ce0</code> you actually have the exact
same content in your tree. Git commits are content addressed, therefore the name
<code>7cc16bb8cd38ff5806e40b32978ae64d54023ce0</code> refers to that exact
tree.</p>
<p>Yet another example of content-addressed storage is <a href="https://ipfs.io/">IPFS</a>. In IPFS storage
files can be stored in any number of computers, and even moved from
computer to computer. The content-derived name is used as a way to give
an intrinsic name to a file, regardless of where it is stored.</p>
<p>In fact, even the particular use case that we are discussing here -
avoiding recompilation when a rebuilt dependency hasn’t changed -
can be found in various build systems such as
<a href="https://bazel.build/">Bazel</a>. In build systems, such recompilation
avoidance is sometimes known as the <em>early cutoff optimization</em> −
see the <a href="https://www.microsoft.com/en-us/research/uploads/prod/2018/03/build-systems.pdf">build systems a la carte paper</a>
for example).</p>
<p>So all we need to do is to move the Nix store from an input-addressed
model to a content-addressed model, as used by many tools
already, and we will be able to save a lot of storage space and CPU
usage, by rebuilding many fewer packages. Nixpkgs contributors will
see their CI time improved. It could also allow <a href="https://github.com/NixOS/nix/issues/859">serving a binary cache
over IPFS</a>.</p>
<p>Well, like many things with computers,
this is actually way harder than it sounds (which explains why this
hasn’t already been done despite being discussed nearly 15 years ago in the
<a href="https://github.com/edolstra/edolstra.github.io/raw/49a78323f6b319da6e078b4f5f6b3112a30e8db9/pubs/phd-thesis.pdf">original paper</a>), but we now believe that there’s <a href="https://github.com/NixOS/rfcs/pull/62">a way forward</a>… more on that in a later post.</p>
<h2>Conclusion</h2>
<p>A content-addressed store for Nix would help reduce the insane load
that <a href="https://hydra.nixos.org/">Hydra</a> has to sustain. While content-addressing is a common technique both in distributed systems
and build systems (Nix is both!), getting to the point where it was
feasible to integrate content-addressing in Nix has been a long journey.</p>
<p>In a future post, I’ll explain why it was so hard, and how we finally
managed to propose a viable design for a content-addressed Nix.</p></div></div></div></section></div>]]>
            </description>
            <link>https://www.tweag.io/blog/2020-09-10-nix-cas/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24430823</guid>
            <pubDate>Thu, 10 Sep 2020 10:22:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Loclock – display local time in cities worldwide at one view]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24430386">thread link</a>) | @rlv04343
<br/>
September 10, 2020 | https://www.ionstage.org/loclock/ | <a href="https://web.archive.org/web/*/https://www.ionstage.org/loclock/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.ionstage.org/loclock/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24430386</guid>
            <pubDate>Thu, 10 Sep 2020 09:16:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tips and gotchas for managing AWS costs]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24430361">thread link</a>) | @taggun
<br/>
September 10, 2020 | https://www.taggun.io/tips-and-gotchas-for-managing-your-aws-cloud-costs | <a href="https://web.archive.org/web/*/https://www.taggun.io/tips-and-gotchas-for-managing-your-aws-cloud-costs">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div id="post-content"><p><h4><strong>You might be funding Jeff Bezo’s trip to the moon, and you don’t even know it</strong>.</h4></p><p>Are you using AWS as your cloud provider? I have been stung by AWS bills more than once because the AWS Cost Explorer is not user friendly <em>by design</em>. I suspect that it was designed to confuse us, so we could fund Jeff Bezo’s trip to the moon. But, here are a few things I have learned while running TAGGUN, to help you and other SaaS founders reduce AWS costs.</p><div><div><figure><img loading="lazy" src="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1016/https://www.taggun.io/wp-content/uploads/2020/09/Jeff-Bezos-Moon.png" alt="" width="508" height="322" srcset="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1016/https://www.taggun.io/wp-content/uploads/2020/09/Jeff-Bezos-Moon.png 1016w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_300/https://www.taggun.io/wp-content/uploads/2020/09/Jeff-Bezos-Moon-300x190.png 300w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_768/https://www.taggun.io/wp-content/uploads/2020/09/Jeff-Bezos-Moon-768x487.png 768w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_600/https://www.taggun.io/wp-content/uploads/2020/09/Jeff-Bezos-Moon-600x380.png 600w" sizes="(max-width: 508px) 100vw, 508px"><figcaption>Are you funding Jeff Bezo’s trip to the moon?</figcaption></figure></div></div><p><h4><strong>🚨 Gotchas: By default, AWS Cost Explorer hides all your credits, Savings Plans and Reservations Plans usage.</strong></h4></p><p>If you can’t see where you are spending your money, you are likely to waste your AWS Start up Credits, Savings Plans and Reservations usage away…</p><div><div><figure><img loading="lazy" src="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1024/https://www.taggun.io/wp-content/uploads/2020/09/AWS-1024x800.png" alt="" width="512" height="400" srcset="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1024/https://www.taggun.io/wp-content/uploads/2020/09/AWS-1024x800.png 1024w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_300/https://www.taggun.io/wp-content/uploads/2020/09/AWS-300x234.png 300w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_768/https://www.taggun.io/wp-content/uploads/2020/09/AWS-768x600.png 768w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_600/https://www.taggun.io/wp-content/uploads/2020/09/AWS-600x469.png 600w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1262/https://www.taggun.io/wp-content/uploads/2020/09/AWS.png 1262w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>Default view of AWS Cost Explore shows you nothing if you are using AWS credits.</figcaption></figure></div></div><p><h4><strong>💡 TIPS: Select Charge Type filter to show your&nbsp;<em>true</em>&nbsp;AWS usage</strong></h4></p><p>On the right panel, filter Charge Type to these three usages:</p><div><ul><li>Reservation applied usage</li><li>Savings Plan Covered Usage</li><li>Usage</li></ul></div><div><div><figure><img loading="lazy" src="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_586/https://www.taggun.io/wp-content/uploads/2020/09/AWS2.png" alt="" width="293" height="430" srcset="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_586/https://www.taggun.io/wp-content/uploads/2020/09/AWS2.png 586w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_204/https://www.taggun.io/wp-content/uploads/2020/09/AWS2-204x300.png 204w" sizes="(max-width: 293px) 100vw, 293px"><figcaption>Apply Charge Type Filter</figcaption></figure></div></div><div><div><figure><img loading="lazy" src="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1024/https://www.taggun.io/wp-content/uploads/2020/09/AWS3-1024x673.png" alt="" width="512" height="337" srcset="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1024/https://www.taggun.io/wp-content/uploads/2020/09/AWS3-1024x673.png 1024w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_300/https://www.taggun.io/wp-content/uploads/2020/09/AWS3-300x197.png 300w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_768/https://www.taggun.io/wp-content/uploads/2020/09/AWS3-768x505.png 768w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1536/https://www.taggun.io/wp-content/uploads/2020/09/AWS3-1536x1009.png 1536w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_600/https://www.taggun.io/wp-content/uploads/2020/09/AWS3-600x394.png 600w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1726/https://www.taggun.io/wp-content/uploads/2020/09/AWS3.png 1726w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>Use Charge Type to show the&nbsp;<em>true</em>&nbsp;AWS usage for the month!!&nbsp;</figcaption></figure></div></div><p>Now, you can use the report to analyse how you are using AWS and reduce waste.</p><div><div><figure><img loading="lazy" src="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1024/https://www.taggun.io/wp-content/uploads/2020/09/AWS4-1024x630.png" alt="" width="512" height="315" srcset="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1024/https://www.taggun.io/wp-content/uploads/2020/09/AWS4-1024x630.png 1024w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_300/https://www.taggun.io/wp-content/uploads/2020/09/AWS4-300x185.png 300w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_768/https://www.taggun.io/wp-content/uploads/2020/09/AWS4-768x473.png 768w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1536/https://www.taggun.io/wp-content/uploads/2020/09/AWS4-1536x946.png 1536w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_600/https://www.taggun.io/wp-content/uploads/2020/09/AWS4-600x369.png 600w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1686/https://www.taggun.io/wp-content/uploads/2020/09/AWS4.png 1686w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>True AWS Usage grouped by the type of service</figcaption></figure></div></div><p><h4><strong>🚨 Gotchas: EC2 snapshots cost more when the server is patched<br></strong></h4></p><p>The EC2 snapshot charges are cheap… until you start patching your servers. EC2 snapshot is charged based on the delta of EC2 volume and snapshots. So, your snapshot costs will jump up after you patch the servers for updates.</p><div><div><figure><img loading="lazy" src="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1024/https://www.taggun.io/wp-content/uploads/2020/09/AWS5-1024x1013.png" alt="" width="512" height="507" srcset="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1024/https://www.taggun.io/wp-content/uploads/2020/09/AWS5-1024x1013.png 1024w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_300/https://www.taggun.io/wp-content/uploads/2020/09/AWS5-300x297.png 300w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_150/https://www.taggun.io/wp-content/uploads/2020/09/AWS5-150x150.png 150w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_768/https://www.taggun.io/wp-content/uploads/2020/09/AWS5-768x760.png 768w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_600/https://www.taggun.io/wp-content/uploads/2020/09/AWS5-600x593.png 600w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1268/https://www.taggun.io/wp-content/uploads/2020/09/AWS5.png 1268w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>Snapshot costs will jump up after you patch the servers for updates.</figcaption></figure></div></div><p><h4>💡<strong>Tips: Monitor EC2 Snapshots regularly</strong></h4></p><p>In EC2, check the number of EC2 Snapshots in your account. Remove the old ones that are not in use anymore. Otherwise, you will start burning some serious cash,&nbsp;if the delta between your snapshots and your EC2 volume gets bigger.</p><div><div><figure><img loading="lazy" src="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1024/https://www.taggun.io/wp-content/uploads/2020/09/AWS7-1024x983.png" alt="" width="512" height="492" srcset="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1024/https://www.taggun.io/wp-content/uploads/2020/09/AWS7-1024x983.png 1024w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_300/https://www.taggun.io/wp-content/uploads/2020/09/AWS7-300x288.png 300w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_768/https://www.taggun.io/wp-content/uploads/2020/09/AWS7-768x737.png 768w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_600/https://www.taggun.io/wp-content/uploads/2020/09/AWS7-600x576.png 600w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1438/https://www.taggun.io/wp-content/uploads/2020/09/AWS7.png 1438w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>EC2 Snapshots</figcaption></figure></div></div><p><h4>💡 <strong>Tips: Use Lifecycle Manager and limit the retention days for your snapshots<br></strong></h4></p><p>AWS snapshot can cost up to 15% of your total AWS Bill. Of course, AWS wants to make it easy to create snapshots, but difficult to remove them.. Only recently, I discovered AWS has quietly released AWS Lifecycle Manager, which allows you to create a snapshot with a retention policy…</p><div><div><figure><img loading="lazy" src="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1024/https://www.taggun.io/wp-content/uploads/2020/09/AWS6-1024x735.png" alt="" width="512" height="368" srcset="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1024/https://www.taggun.io/wp-content/uploads/2020/09/AWS6-1024x735.png 1024w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_300/https://www.taggun.io/wp-content/uploads/2020/09/AWS6-300x215.png 300w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_768/https://www.taggun.io/wp-content/uploads/2020/09/AWS6-768x552.png 768w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1536/https://www.taggun.io/wp-content/uploads/2020/09/AWS6-1536x1103.png 1536w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_600/https://www.taggun.io/wp-content/uploads/2020/09/AWS6-600x431.png 600w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1540/https://www.taggun.io/wp-content/uploads/2020/09/AWS6.png 1540w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>AWS EC2 Lifecycle Manager</figcaption></figure></div></div><p><h4>💡 <strong>Tips: Use a USD based credit card</strong> to pay for your cloud bills</h4></p><p>If your company is not based in the US, you will be paying an additional 3% for all your cloud bills like AWS and TAGGUN, that are priced in US dollars. I’d suggest applying for something like Transferwise Business Debit Card to avoid getting charged foreign exchange fees and expensive FX rate by your bank.</p><p><h4>There are many 🚨 gotchas in AWS and AWS Billing</h4></p><p>For example: EC2 M4 is more expensive (and slower) than the new generation M5 series. An upgrade will save you some money. If you know any other tips and gotchas, please email <a href="mailto:ck-lee@taggun.io">me</a> and share your stories. I’d love to learn more.</p></div></div></div>]]>
            </description>
            <link>https://www.taggun.io/tips-and-gotchas-for-managing-your-aws-cloud-costs</link>
            <guid isPermaLink="false">hacker-news-small-sites-24430361</guid>
            <pubDate>Thu, 10 Sep 2020 09:13:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Germany is testing public hazard alerting(now)]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24430275">thread link</a>) | @heredoc
<br/>
September 10, 2020 | https://www.bbk.bund.de/DE/AufgabenundAusstattung/Krisenmanagement/WarnungderBevoelkerung/Bundesweiter_Warntag/Bundesweiter_Warntag_node.html | <a href="https://web.archive.org/web/*/https://www.bbk.bund.de/DE/AufgabenundAusstattung/Krisenmanagement/WarnungderBevoelkerung/Bundesweiter_Warntag/Bundesweiter_Warntag_node.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
      <div>
<p>Am <strong>10. September 2020</strong> haben in ganz Deutschland Warn-Apps gepiept, Sirenen geheult, Rundfunkanstalten ihre Sendungen unterbrochen und Probewarnungen sind auf digitalen Werbetafeln erschienen. An diesem Tag fand der erste bundesweite Warntag seit der Wiedervereinigung statt. Ab diesem Jahr wird ein bundesweiter Warntag jährlich am <strong>zweiten Donnerstag im September</strong> stattfinden.</p><p>Zur Warnung der Bevölkerung nutzen Bund, Länder und Kommunen alle verfügbaren Kommunikationskanäle: so etwa das vom Bundesamt für Bevölkerungsschutz und Katastrophenhilfe (<abbr title="Bundesamt für Bevölkerungsschutz und Katastrophenhilfe">BBK</abbr>) betriebene <a href="https://www.bbk.bund.de/DE/AufgabenundAusstattung/Krisenmanagement/WarnungderBevoelkerung/MoWaS/ModularesWarnsystem_node.html;jsessionid=5872CE7A1E1BED95C25595A9AD32BD04.2_cid320" target="_blank" rel="noopener noreferrer" title="Modulares Warnsystem (Öffnet&nbsp;neues&nbsp;Fenster)">Modulare Warnsystem</a> und die <a href="https://www.bbk.bund.de/DE/NINA/Warn-App_NINA_node.html;jsessionid=5872CE7A1E1BED95C25595A9AD32BD04.2_cid320" target="_blank" rel="noopener noreferrer" title="Warn-App NINA (Öffnet&nbsp;neues&nbsp;Fenster)">Warn-<abbr title="Applikation – Anwendungsprogramm">App</abbr> <abbr title="Notfall-Informations- und Nachrichten-App">NINA</abbr></a>, eine Vielzahl von Medien und Rundfunksendern bis hin zu Sirenen und Lautsprecherdurchsagen vor Ort. </p>
<p><span><img src="https://www.bbk.bund.de/SharedDocs/Bilder/BBK/DE/Bilder_aktuelle_Meldungen/2020/Warntag_Graphik.jpg;jsessionid=5872CE7A1E1BED95C25595A9AD32BD04.2_cid320?__blob=normal&amp;v=2" title="Warntag 2020 - eine graphische Darstellung" alt="Warntag 2020 - eine graphische Darstellung"></span>
</p>

<p>Mithilfe des Modularen Warnsystems wird eine Probewarnung an alle daran angeschlossenen Warnmultiplikatoren versendet. Warnmultiplikatoren sind ein Adressatenkreis, der Warnmeldungen weitergibt. Hierbei kann es sich <acronym title="zum Beispiel">z. B.</acronym> um einen Radio- oder Fernsehsender handeln, der seine laufende Sendung unterbricht und die Meldung verliest <abbr title="beziehungsweise">bzw.</abbr> einen Crawler (Lauftext) in die laufende Fernsehsendung einblendet, oder eine Leitstelle, die ihre Sirenen auslöst.</p>

<p>Diese Warnmultiplikatoren leiten die Probewarnung an die Endgeräte wie zum Beispiel Radios oder die Warn-<abbr title="Applikation – Anwendungsprogramm">App</abbr> <abbr title="Notfall-Informations- und Nachrichten-App">NINA</abbr> und damit direkt an die Bürgerinnen und Bürger weiter. Zeitgleich werden auf Ebene der Länder, in den Landkreisen und in den Kommunen außerdem weitere verfügbare kommunale Warnmittel ausgelöst, zu denen beispielsweise Sirenen und Lautsprecherwagen zählen können. Auf denselben Wegen wird dann um 11.20 Uhr das allgemeine Signal zur Entwarnung erfolgen.</p>
<h3>Vom Sofa aus ins Bundesamt schauen</h3>

<p>Das <abbr title="Bundesamt für Bevölkerungsschutz und Katastrophenhilfe">BBK</abbr> hat im Bund die Aufgabe der Warnung der Bevölkerung vor den besonderen Gefahren eines Verteidigungsfalls und beteiligt sich ebenfalls am Warntag 2020. Wovor und wie das Amt dabei genau warnen kann, darüber hat das <abbr title="Bundesamt für Bevölkerungsschutz und Katastrophenhilfe">BBK</abbr> bereits vorab bei einem virtuellen Tag der offenen Tür informiert – und sich dabei den Bürgerinnen und Bürgern als zuständige Bundesoberbehörde gleich selbst vorgestellt.</p>

<p>In den folgenden drei Gesprächen erfahren Sie mehr über die Aufgabe der Warnung der Bevölkerung, die Warnapp <abbr title="Notfall-Informations- und Nachrichten-App">NINA</abbr> und den bundesweiten Warntag. Die Videos sind auch in Deutsche Gebärdensprache übersetzt.</p>

<p><iframe width="448" height="252" src="https://www.youtube.com/embed/mFlqBinNnuE" frameborder="0" gesture="media" allow="encrypted-media" allowfullscreen="1">Ihr Browser unterstützt iFrame nicht</iframe></p>

<p><iframe width="448" height="252" src="https://www.youtube.com/embed/b3PzZOn40NE" frameborder="0" gesture="media" allow="encrypted-media" allowfullscreen="1">Ihr Browser unterstützt iFrame nicht</iframe></p>

<p><iframe width="448" height="252" src="https://www.youtube.com/embed/DHK6CQpkZv0" frameborder="0" gesture="media" allow="encrypted-media" allowfullscreen="1">Ihr Browser unterstützt iFrame nicht</iframe></p>

<p>Auf Grundlage eines Beschlusses der Innenministerkonferenz wird der bundesweite Warntag ab dem Jahr 2020 jährlich an jedem zweiten Donnerstag im September stattfinden. Er soll dazu beitragen, die Akzeptanz und das Wissen um die Warnung der Bevölkerung in Notlagen zu erhöhen und damit deren Selbstschutzfertigkeiten zu stärken. Die Wichtigkeit und Aktualität des Themas Warnung zeigt sich auch durch die Entwicklungen im Zusammenhang mit dem <a href="https://www.bbk.bund.de/DE/AktuellesundPresse/Informationen_zu_SARS-CoV-2/Corona_node.html;jsessionid=5872CE7A1E1BED95C25595A9AD32BD04.2_cid320" target="_blank" rel="noopener noreferrer" title="Informationen zu SARS-CoV-2 (Öffnet&nbsp;neues&nbsp;Fenster)">Corona-Virus</a> in diesem Jahr. Zur Warnung und Information der Bevölkerung nutzen Bund, Länder und Kommunen die verfügbaren Kommunikationskanäle. So werden beispielsweise über das vom <abbr title="Bundesamt für Bevölkerungsschutz und Katastrophenhilfe">BBK</abbr> betriebene <a href="https://www.bbk.bund.de/DE/AufgabenundAusstattung/Krisenmanagement/WarnungderBevoelkerung/MoWaS/ModularesWarnsystem_node.html;jsessionid=5872CE7A1E1BED95C25595A9AD32BD04.2_cid320" target="_blank" rel="noopener noreferrer" title="Modulares Warnsystem (Öffnet&nbsp;neues&nbsp;Fenster)">Modulare Warnsystem</a> und die <a href="https://www.bbk.bund.de/DE/NINA/Warn-App_NINA_node.html;jsessionid=5872CE7A1E1BED95C25595A9AD32BD04.2_cid320" target="_blank" rel="noopener noreferrer" title="Warn-App NINA (Öffnet&nbsp;neues&nbsp;Fenster)">Warn-<abbr title="Applikation – Anwendungsprogramm">App</abbr> <abbr title="Notfall-Informations- und Nachrichten-App">NINA</abbr></a> Warnungen und Informationen der zuständigen Behörden, wie der Gesundheitsministerien des Bundes und der Länder, bereitgestellt. Bund und Länder bereiten den bundesweiten Warntag in Abstimmung mit kommunalen Vertretern gemeinsam vor. Zuständig sind auf Bundesebene das <abbr title="Bundesamt für Bevölkerungsschutz und Katastrophenhilfe">BBK</abbr>, auf der Ebene der Länder die jeweiligen Innenministerien und auf der Ebene der Kommunen in der Regel die für den Katastrophenschutz zuständigen Behörden.</p>

<p>Ausführliche Informationen zum bundesweiten Warntag stehen auf der Website <a href="https://warnung-der-bevoelkerung.de/" target="_blank" rel="noopener noreferrer" title="Externer Link&nbsp;Externer Link (Öffnet&nbsp;neues&nbsp;Fenster)">www.bundesweiter-warntag.de</a> zur Verfügung.</p>
<p><a href="https://www.bbk.bund.de/DE/AufgabenundAusstattung/Krisenmanagement/WarnungderBevoelkerung/Bundesweiter_Warntag/Bundesweiter_Warntag_node.html;jsessionid=5872CE7A1E1BED95C25595A9AD32BD04.2_cid320#Start" title="Zum Seitenanfang">nach oben</a></p></div>
    </div></div>]]>
            </description>
            <link>https://www.bbk.bund.de/DE/AufgabenundAusstattung/Krisenmanagement/WarnungderBevoelkerung/Bundesweiter_Warntag/Bundesweiter_Warntag_node.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24430275</guid>
            <pubDate>Thu, 10 Sep 2020 08:59:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Frequentism vs. bayesianism – The AI paradigm war]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24430142">thread link</a>) | @danroseai
<br/>
September 10, 2020 | https://www.danrose.ai/blog/jx6opb61kehib7w5m8iwp3bt50fw3m | <a href="https://web.archive.org/web/*/https://www.danrose.ai/blog/jx6opb61kehib7w5m8iwp3bt50fw3m">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-layout-label="Post Body" data-type="item" id="item-5f155d9c1dfb8122b866ab0c"><div><div><div data-block-type="2" id="block-5bf0535ff4549250ad7b"><div><p>Frequentism and bayesianism is two paradigms or schools of statistics. I’m by no means an expert in statistics and you don’t have to be either to read this post. Actually pretty simple to understand without prior knowledge about statistics.&nbsp;</p><p>So why read this blog post about two statistical paradigms you ask? Because it’ll make you understand AI at a whole different level than before. I promise.</p><p>There are some extremely useful learnings from understanding this paradigm war. It will make you understand the gray areas of AI. By this I mean the reason why a lot of AI often does not have hard conclusions. To boil it down to it’s essence, the two paradigms offer completely different ways of predicting and understanding the world with often completely different results but still being equally correct. That’s it. In statistics that very often the foundation of AI models different results can be equally correct. How can that be possible? Let’s dig deeper with an example.</p><p>I’m stealing this great example from the book The Signal and Noise by Nate Silver. A book that will definitely make you think differently about the world. I really recommend it.&nbsp;</p><p>The example is simple. You come home one day early and you find underwear in your bedroom that is definitely not yours. How do you explain this? Did your partner cheat on you or is there another explanation? The frequentist will only look at the observed evidence, the underwear. Suggesting a very high probability of adultery. The bayesian would take into account the prior beliefs. This could be the overall adultery rates and your trust with your partner. With high trust you might dismiss the evidence.&nbsp;</p><p>Both paradigms provide equally true ways to view the world but come with pros and cons. In this underwear example I at least don’t see a right or wrong way to approach the problem. But I see that there might be very different outcomes depending on what school you prefer in this scenario.</p><p>Now let’s learn a bit about each paradigm.</p><h2>The Frequentists paradigm</h2><p>The core of frequentism is that only observed data is taken into account when calculating the probability of the occurrence of an event. So what does that mean? It means that when calculating the probability of an event you take a sample of the domain you are trying to measure and observe the frequency of events. Say you want to measure the probability of landing tails when flipping a coin. The maths look like this:</p><p>P(A) = n/N</p><p>The probability of A is the number of times an event happened(landing tails) divided by the number of possible events(The number of coin flips). The frequentist reservation is that they can assume that the world is random and the results they predict are looked upon in the long term. It’s also crucial that what we do can be replicated. In the coin toss problem we will see 50% tails over the long term and this makes a lot of sense.&nbsp;</p><h2>The Bayesianists paradigm</h2><p>Bayesianism offers a way to take into account our prior beliefs when calculating a probability. In other words, we are not only looking at the observed data but including our own biases. So the bayesian statistician would start with a prior belief, observe data, add the data to the prior and end with a posterior belief. The posterior is the new probability. Bayenists divide the problem of probability into two cases. The probability of the evidence given an event is happening and the probability of evidence given the event is not happening. The maths looks like this:</p><p>P = xy * (xy + z(1-x))</p><p>x = you prior probability of event</p><p>y = conditional probability of evidence given event <em>did</em> occur</p><p>z = conditional probability of evidence given event <em>did not</em> occur</p><p>&nbsp;It might look a little confusing but the explanation is simple. Say you get a fever and you want to know the probability of you now having Covid-19. Let’s try it out. I’m going to be loose with the numbers here but the idea is the same. In Denmark, where I’m located, the Covid-19 virus is not very present. Only about 1.200 out of 5.8 million people are currently affected. That’s 0.02% and that’s our x. Due to social distancing other viral diseases and as a result fever is very rare too. So I’m going to put the probability of having a fever without being affected by Covid-19 low. Let’s say 20%. That’s our “z”. If you have Covid-19 then fever is very likely. It’s a common symptom. Let’s say 80%. That’s our “y”. So the math is now like this:</p><p>P = 0.0002 * 0.8 / ( 0.0002 * 0.8 + 0.2(1-0.0002)) =0.08%</p><p>So what just happened? Before you had a fever your chance of having Covid-19 you had a 0.02%. But after this new piece of evidence(the fever) your chance was still low but had risen to 0.08%. Interesting right?</p><p>If you want to know more about Bayes and conditional probability the wikipedia article is really good: <a href="https://en.wikipedia.org/wiki/Bayes%27_theorem"><span>Bayes Theorem</span></a>.</p><h2>So what approach should you take?</h2><p>Bayesian statistics takes into account your prior beliefs or in other words, <em>your biases</em>. If you think it would not objectively harm then you might go for a bayesian method. If you have an easily repeatable low bias situation then you might like to go for a more frequentist approach. This is of course put on the edge. It’s never just that simple.</p><p>One thing I would add is when I hear people saying stuff like “I’m really data driven in my decision making” or even worse “I only act on data never on” I hear a sign of danger. Believing that data should be blindly trusted is a naive world view. The fundamental error in that is that you never know what data you haven’t seen and if the data is biased. One good example is the housing market crash in 2007. The logic was that the housing market had never crashed and by frequentist reasoning it could not crash. The result was that the market was pushed to extremes that it hadn’t been in before.&nbsp;</p><h2>How does this relate to AI?</h2><p>So to make the connection here to AI a lot of AI is based on statistical methods. Several approaches can be taken to make AI understand the world and they may be very different. There’s no given correct way. You just have to be wary of whatever results you see since the underlying mechanics is just not so black and white. Preparing for being wrong is my best advice.</p><p>I would like to end the post with a personal pet peeve. The media today seem to have a clear tendency to prefer frequentism regardless of the matter and rarely offers the alternative view. To make it even worse, journalists will often require politicians to be totally sure that their politics are going to have the desired effects when it’s not possible to be sure. That discourages testing new politics on a small scale before going all in. If a bit more bayesianism could be applied in journalism giant political failures could be avoided. </p></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.danrose.ai/blog/jx6opb61kehib7w5m8iwp3bt50fw3m</link>
            <guid isPermaLink="false">hacker-news-small-sites-24430142</guid>
            <pubDate>Thu, 10 Sep 2020 08:32:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Weakness of Anthropic Arguments]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 80 (<a href="https://news.ycombinator.com/item?id=24429625">thread link</a>) | @srl
<br/>
September 9, 2020 | https://ineffectivetheory.com/weakness-anthropic-arguments/ | <a href="https://web.archive.org/web/*/https://ineffectivetheory.com/weakness-anthropic-arguments/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><header><time datetime="2020-09-10">10 Sep 2020</time></header><p>Physicists are often bothered by the question “why do fundamental physical constants have the values they do?” Sometimes this concern can be answered by “well it had to take <em>some</em> value”, <a href="https://en.wikipedia.org/wiki/Fine-tuning">but not always</a>. Seeking explanations for patterns in what appear to be fundamental constants is a <a href="https://en.wikipedia.org/wiki/Periodic_table">historically</a> <a href="https://en.wikipedia.org/wiki/Eightfold_way_(physics)">successful</a> way to probe for the next undiscovered piece of physics.</p><p>The anthropic principle attempts to answer that sort of question. Crudely, an anthropic argument is one taking the form:</p><blockquote><p>The universe is the way it is because if it weren’t, we wouldn’t be here to discuss the issue.</p></blockquote><p>It shouldn’t surprise you to learn that most physicists are, at the very least, a little uncomfortable with this form of argument. The best pro-anthropic-argument summary I know of is frequently given by Nima Arkani-Hamed. Unfortunately I cannot find a video, so my own thoroughly inferior retelling will have to do:</p><blockquote><p>Suppose you walk into a room and see a table. On the table is a pencil, balanced perfectly on its tip. This is unlikely, to say the least. It needs explanation. The first thing to do is look for a string holding it up, or some glue on the tip, or the like. You check, and there’s no such mechanism. The next thing to do is look around — are there thousands of other pencils, lying normally on the table and the floor? If so, then the balancing pencil may reasonably be called coincidence. Alas, there are none.</p></blockquote><blockquote><p>There’s one last thing to do, to explain the magic pencil: look under the table. Is there a bomb, rigged to explode the moment the pencil falls over? Step outside: do you see the remains of thousands of detonated houses? If so, then it may be correct to say “the pencil was standing because, were it any other way, we would not have been in that room”.</p></blockquote><p>That last check is what an anthropic argument is all about. We can’t actually look for other rooms, destroyed by bombs (that would be called “the multiverse”), but we can at least try and look for the bomb.</p><p>The problem is, what qualifies as a bomb? The canonical example: if the cosmological constant were larger by a factor of say, $10^{100}$, the universe would have promptly blown itself apart. I wouldn’t be here to write this, you wouldn’t be here to read it. Surely we should not be surprised that the cosmological constant is not, in fact, so large.</p><p>Does that still make you uncomfortable? Perhaps it should. This type of argument is very slippery (like a slope). Thinking along the lines of the <a href="https://en.wikipedia.org/wiki/Butterfly_effect">butterfly effect</a>, it’s clear that even a one-part-in-$10^{10}$ change in the fine structure constant would build up dramatic differences in the evolution and course of life on Earth. In this universe, where $\alpha \approx 0.007297352569$, you’re reading an article about the anthropic principle; in the universe where $\alpha \approx 0.007297352570$, at the very least, it’s reasonable to guess that you would not be. (Good news: in that universe, you’re a billionaire playboy philanthropist!) Does this explain (to high precision) the value of the fine structure constant? After all, were the fine structure constant different by even $10^{-10}$, you would not be considering the question.</p><p>This has the basic structure of an anthropic argument, but there’s clearly something wrong with it. In that alternate universe, there are other people who <em>are</em> considering the question “why does $\alpha$ have that value?” The puzzle would still exist, even if you and I specifically have no interest.</p><p>Let’s consider, then, a universe where $\alpha$ is different by a full one part in a million. Chemical and nuclear physics don’t look substantially different, but again, the butterfly effect suggests that we should expect large differences in the situation on Earth. Suppose intelligent life exists on Earth, but not in anything remotely resembling human form. Now, it’s true that “there are no humans considering the question”. But again, there are <em>beings</em> on this planet considering the question. Shouldn’t that be enough?</p><p>Suppose $\alpha$ were different by one part in one hundred thousand. Now there’s no intelligent life on Earth at all — instead, intelligent life (tripedal, if you were wondering) evolves on Alpha Centauri! Questions of fine tuning are not considered anywhere in our solar system, but there are intelligent beings in the galaxy considering the question. It’s entirely accurate to say “were $\alpha$ different by one part in $10^5$, we would not be here to discuss these questions”, but <em>someone</em> would be <em>somewhere</em>, so that doesn’t seem like much of an explanation.</p><p>As far as I can tell, the best prototype for a good anthropic argument is:</p><blockquote><p>You have asked why proposition $P$ (which you find <em>a priori</em> surprising) should be true in our universe. You are able to ask this question in part because $P$ is true. Were $P$ false, you would not be able to ask such a question. In fact, were $P$ false, intelligent beings would not exist at all. Therefore, questions such as “why $P$” or “why not $P$” would never be expressed. Since questions like “what should be my prior probability of $P$” require $P$ to be true in order to be asked, the answer can only be “your prior should be near $1$”. Therefore $P$ is not, in fact, <em>a priori</em> surprising.</p></blockquote><p>The problem is, this anthropic principle is <em>extremely weak</em>. One proposed use of the anthropic principle is to <a href="https://doi.org/10.1111%2Fj.1749-6632.2001.tb02133.x">explain the fine structure constant</a>. Suppose the fine structure constant were in fact 10% different — enough to prevent stellar fusion from producing carbon. This would prevent carbon-based life from existing, sure; but would it prevent <em>intelligent</em> life from existing? Perhaps the question “why is $\alpha$ that particular value” could still be asked! It’s hard to know, without an unprecedentedly high-fidelity simulation of an alternate universe with $\alpha = 0.01$. That simulation isn’t coming soon.</p><p>The book <a href="https://en.wikipedia.org/wiki/Dragon%27s_Egg">Dragon’s Egg</a> is based around intelligent life living in the crust of a neutron star. The existence of such life certainly can’t be ruled out with our current understanding of the physics of dense matter. That’s a <em>very different</em> environment than our own; for starters, the strong surface gravity and magnetic field deform atoms by as much as a substantial change to the fine structure constant. If the anthropic principle can’t “explain why” we don’t live on the surface of a neutron star, then it certainly can’t account for a few percentage points in the fine structure constant.</p><p>This isn’t just yet another case of “we suck at creating efficient first-principles simulations”, either. One of the most famous stylized facts about <a href="https://mathworld.wolfram.com/CellularAutomaton.html">cellular automata</a> is that if you sneeze at them, they <a href="https://mathworld.wolfram.com/UniversalCellularAutomaton.html">become Turing-complete</a>. (This isn’t really a special fact about cellular automata, just a reflection of the fact that systems that support complex dynamics tend to also support universal computation.) A Turing-complete cellular automaton can simulate any classical process, and therefore displays phenomena like self-reproducing organisms. Moreover, a Turing-complete cellular automaton can support any intelligence exhibited by a computer. In principle (although of course this is too expensive to have been directly demonstrated) a cellular automaton like <a href="https://en.wikipedia.org/wiki/Conway%27s_Game_of_Life">Conway’s</a>, beginning from a random position, ought to eventually evolve various levels of intelligence — intelligence is evolutionarily favorable in our world, and ought to be in others as well. So, shouldn’t such automata be capable of asking <em>the question</em>?</p><p>(In the case of Conway’s game, I guess <em>the question</em> is “why is the grid rectangular instead of hexagonal?")</p><p>The framework of modern fundamental physics is slightly more complicated than “it’s a cellular automaton” (this is <a href="https://writings.stephenwolfram.com/2020/04/finally-we-may-have-a-path-to-the-fundamental-theory-of-physics-and-its-beautiful/">only slightly controversial</a>), but the intuition gained from cellular automata is sticky: even large modifications to physical laws shouldn’t prevent intelligent structures from forming. This is the fundamental weakness of anthropic arguments. A properly formed anthropic argument should be based on an inability for intelligence to form, but intelligence is quite resilient. Almost any non-trivial universe can support intelligent life which will, inevitably, ask <em>the question</em>.</p><p>In a few cases, this issue may be circumvented: if the cosmological constant was too small/large, the universe would have collapsed/blown itself to smithereens before having a chance to develop anything resembling intelligence. This is largely independent of the other physical laws. That requirement is not strong enough to remove fine-tuning issues with the cosmological constant, and it certainly provides nothing resembling an explanation for the fine structure constant or any other part of the standard model.</p><p>I don’t think this weakness is repairable. Intelligent life is “existentially resilient”. The particular fundamental constants that describe the universe are unlikely to be the only ones that would allow someone to complain about fine-tuning and speculate about anthropic arguments.</p></article></div>]]>
            </description>
            <link>https://ineffectivetheory.com/weakness-anthropic-arguments/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24429625</guid>
            <pubDate>Thu, 10 Sep 2020 06:54:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Artificial Intelligence Technologies Trends]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24429526">thread link</a>) | @di_ra22
<br/>
September 9, 2020 | https://blog.digitalogy.co/artificial-intelligence-technologies/ | <a href="https://web.archive.org/web/*/https://blog.digitalogy.co/artificial-intelligence-technologies/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemscope="" itemtype="https://schema.org/CreativeWork"><div itemprop="text"><p><img src="https://blog.digitalogy.co/wp-content/uploads/2020/04/10-Artificial-Intelligence-Technologies-Trends-that-Can-Take-Your-Business-to-New-Heights.png" alt="10 Artificial Intelligence Technologies Trends that Can Take Your Business to New Heights" width="1600" height="1267" srcset="https://blog.digitalogy.co/wp-content/uploads/2020/04/10-Artificial-Intelligence-Technologies-Trends-that-Can-Take-Your-Business-to-New-Heights.png 1600w, https://blog.digitalogy.co/wp-content/uploads/2020/04/10-Artificial-Intelligence-Technologies-Trends-that-Can-Take-Your-Business-to-New-Heights-300x238.png 300w, https://blog.digitalogy.co/wp-content/uploads/2020/04/10-Artificial-Intelligence-Technologies-Trends-that-Can-Take-Your-Business-to-New-Heights-1024x811.png 1024w, https://blog.digitalogy.co/wp-content/uploads/2020/04/10-Artificial-Intelligence-Technologies-Trends-that-Can-Take-Your-Business-to-New-Heights-768x608.png 768w, https://blog.digitalogy.co/wp-content/uploads/2020/04/10-Artificial-Intelligence-Technologies-Trends-that-Can-Take-Your-Business-to-New-Heights-1536x1216.png 1536w" sizes="(max-width: 1600px) 100vw, 1600px"></p>
<blockquote>
<p><strong>AI is everywhere</strong> and it is already impacting our lives. There’s no escaping from it as AI is inevitable. <strong>Take the internet, for example</strong>, it is always suggesting you things to do, videos to watch, even places to visit next.</p>
</blockquote>
<p>Unlike a couple of years ago, <a href="https://blog.digitalogy.co/artificial-intelligence-in-banking-opportunities-and-risks/" target="_blank" rel="noopener noreferrer">Artificial Intelligence</a> in today’s world is not just a buzzword anymore and has come a long way since.</p>
<p>It has turned into a full-blown domain that affects every sector of the industry with practical applications that can be seen everywhere.</p>
<p>Artificial Intelligence technologies, can now back several of your business processes, improving and optimizing them many-fold.</p>
<p>With crowds of organizations actively looking into the potential of AI and investing in them, their transformation into a smarter and more optimized version of themselves is inevitable.</p>
<blockquote><p>“The thing that’s going to make artificial intelligence so powerful is its ability to learn, and the way AI learns is to look at human culture .”<br>
<strong>— Dan Brown</strong></p></blockquote>
<h2><strong>Top 10 Artificial Intelligence Technologies</strong></h2>
<p>With dozens of applications available out there, we will be focussing on a certain few to showcase the latest technology in Artificial Intelligence.</p>
<p>The Artificial Intelligence technologies list below can <a href="https://blog.digitalogy.co/how-to-choose-the-best-digital-marketing-agency-for-your-business-growth/" target="_blank" rel="noopener noreferrer">take your business to new heights</a> and provide solutions to the most complex of your challenges without breaking a sweat –</p>
<h4><strong>1. Speech Recognition</strong></h4>
<blockquote>
<p>“The computer takes in the waveform of your speech. Then it breaks that up into words, which it does by looking at the micro pauses you take in between words as you talk.”</p>
<p><strong>– <a href="https://nymag.com/intelligencer/smarthome/make-me-smarter-voice-speech-recognition-alexa-siri-cortana-google.html" target="_blank" rel="noopener nofollow noreferrer" data-href="http://nymag.com/intelligencer/smarthome/make-me-smarter-voice-speech-recognition-alexa-siri-cortana-google.html">Meredith Broussard</a>, Data Journalist and Professor at NYU</strong></p>
</blockquote>
<p>Speech Recognition is one of the Artificial Intelligence technologies that all of us have used in the form of smart assistants on our phones by the likes of <strong>Google Assistant</strong>, <strong>Alexa</strong>, or <strong>Siri</strong>.</p>
<p>These intelligent speech recognition systems work by analyzing and storing your voice as input and when triggered, match your voice with the stored one.</p>
<p>These systems are responsible for driving <a href="https://uxdesign.cc/what-is-a-conversation-designer-and-why-will-the-role-grow-in-2020-a6d6210af28e?source=your_stories_page---------------------------">conversational systems</a> that work on speech data, often used to carry out a broad range of tasks from simpler ones to more complex ones.</p>
<h4><img src="https://blog.digitalogy.co/wp-content/uploads/2020/04/Ai-Speech-Recognition.gif" alt="Latest technology in artificial intelligence - Speech Recognition" width="400" height="300"></h4>
<p>Tap to speak by <a href="https://dribbble.com/samm" target="_blank" rel="contact noopener nofollow noreferrer" data-href="https://dribbble.com/samm">Sam Mularczyk</a></p>
<h4><strong>2. Emotion Recognition</strong></h4>
<p>Humans use a lot of non-verbal cues while interacting with someone, which includes our tone of voice, body language, facial expressions and gestures.</p>
<p>For machines to understand these, we needed a system that could pick up and identify them.</p>
<p>With the advancements in Image and Speech Recognition, a new discipline was born, called Emotion Recognition.</p>
<p>Emotion Recognition using AI was built to capture and, identify human emotions using facial and speech data.</p>
<p>It’s being used in a variety of industries ranging from law enforcement, interviews, market research, product feedback and more.</p>
<h4><strong>3. Biometrics (Facial Recognition)</strong></h4>
<blockquote>
<p>“Biometrics is certainly the most secure form of authentication. It’s the hardest to imitate and duplicate.”<br>
<strong>– Avivah Litan</strong></p>
</blockquote>
<p>Artificial Intelligence biometrics has seen immense growth in the industry and is empowering its offerings to further boost their accuracy.</p>
<p>The traditional methods that included fingerprints, voice, face, palm and iris recognition have all received their long due Artificial Intelligence integration.</p>
<p>This integration has drastically reduced the chances of errors in systems, making them more secure and robust.</p>
<blockquote>
<p>Some newer additions to this domain are <strong>gait detection</strong>, <strong>DNA recognition</strong>,<strong> keystroke dynamics</strong>, <strong>ear acoustic authentication</strong>.</p>
</blockquote>
<p><img src="https://blog.digitalogy.co/wp-content/uploads/2020/04/Artificial-intelligence-Biometrics.gif" alt="Artificial intelligence biometrics" width="800" height="600"></p>
<p>Facial biometrics recognition by <a href="https://dribbble.com/glebich" target="_blank" rel="contact noopener nofollow noreferrer" data-href="https://dribbble.com/glebich">Gleb Kuznetsov</a> for <a href="https://dribbble.com/milkinside" target="_blank" rel="contact noopener nofollow noreferrer" data-href="https://dribbble.com/milkinside">Milkinside</a></p>
<h4><strong>4. Machine Learning Platforms</strong></h4>
<blockquote>
<p>“A breakthrough in machine learning would be worth ten Microsofts.”</p>
<p><strong>-Bill Gates</strong></p>
</blockquote>
<p>One of the major ideas behind creating Artificial Intelligence technologies is to train it to think and execute.</p>
<p>The Machine Learning branch of AI aims to do precisely that by giving the machines a batch of training data for analysis and drawing inferences.</p>
<p>When put into practical use, these systems draw conclusions based on the collected assumptions and offer insight on the data.</p>
<p>Various businesses have adopted ML to ensure they have the necessary information to gain the upper hand in their trade.</p>
<h4><strong>5. Language Generation</strong></h4>
<p><a href="https://www.geeksforgeeks.org/artificial-intelligence-natural-language-generation/" target="_blank" rel="noopener nofollow noreferrer">Natural Language Generation</a> is a part of a broader process that includes <strong>NLU</strong>, <strong>NLP</strong> and <strong>NLG.</strong></p>
<p>Its purpose is to transform the structured data into a more natural-looking language that doesn’t look repetitive.</p>
<p>The content of which, can be further used to create custom reports, applications such as chatbots, automated journalism and websites.</p>
<p>Some of the well-known service providers for Natural Language Generation are <strong>Visual NLG</strong>, <strong>United Robots</strong>, <strong>Arria NLG</strong>, <strong>Narrative Science</strong> and <strong>Phrasetech</strong>.</p>
<p><iframe title="Natural Language Generation at Google Research (AI Adventures)" width="500" height="281" src="https://www.youtube.com/embed/MNvT5JekDpg?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<h4><strong>6. AI Optimized Hardware</strong></h4>
<blockquote>
<p>“In the long term, artificial intelligence and automation are going to be taking over so much of what gives humans a feeling of purpose.”<br>
<strong>– Matt Bellamy</strong></p>
</blockquote>
<p><strong>Traditional hardware like CPUs and GPUs</strong> were not built keeping Artificial Intelligence in mind, which led to slower processing and incompatibilities.</p>
<p>Advancements in AI are boosting the R&amp;D of optimized chips for processors and graphic processors.</p>
<p>With these newer chips, it is becoming easier to learn and implement AI on even consumer-grade hardware, making AI adoption global and open for everyone.</p>
<p>As the <a href="https://towardsdatascience.com/top-google-ai-tools-for-everyone-60346ab7e08" target="_blank" rel="noopener nofollow noreferrer">AI software</a> increases in complexity, silicon manufacturers are tasked with developing and equipping problem solvers with better hardware.</p>
<h4><strong>7. Virtual Agents(Chatbots)</strong></h4>
<p>Virtual Agents are smart programs that are powered by Artificial Intelligence technologies.</p>
<p>They are created to assist your customers and visitors by answering their questions, taking orders and such.</p>
<p>The idea behind these virtual agents is to have an agent available for support at all times with a human touch.</p>
<p>These virtual agents come in the form of chatbots or smart assistants and, they’re found on your phones and websites.</p>
<p>Some modern examples of virtual agents are <strong>Google Assistant</strong>, <strong>Alexa</strong>, <strong>Cortana</strong>, <strong>Siri</strong>, followed by hundreds of chatbots by loads of websites.</p>
<p><iframe title="Engage customers with Microsoft's Power Virtual Agents" width="500" height="281" src="https://www.youtube.com/embed/J5i7h4Uzju4?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>

<h4><strong>8. Deep Learning Platforms</strong></h4>
<p>Deep Learning could be considered as the next step in Machine Learning with the introduction of Neural Networks for smarter and more efficient learning.</p>
<p>By replicating deep neural networks intricately similar to the human brain, ML algorithms can utilize these deep neural layers to train any model with optimum effectiveness.</p>
<p>A typical application of DL is found in training models dealing with vast amounts of data in mission-critical industries such as aerospace, medical, military, scientific research.</p>
<h4><strong>9. Decision Management</strong></h4>
<p><img src="https://blog.digitalogy.co/wp-content/uploads/2020/04/Decision-Management.jpeg" alt="Decision Management" width="750" height="500" srcset="https://blog.digitalogy.co/wp-content/uploads/2020/04/Decision-Management.jpeg 750w, https://blog.digitalogy.co/wp-content/uploads/2020/04/Decision-Management-300x200.jpeg 300w" sizes="(max-width: 750px) 100vw, 750px"></p>
<p>Photo by <a href="https://unsplash.com/@rosam2020?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" target="_blank" rel="noopener nofollow noreferrer" data-href="https://unsplash.com/@rosam2020?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Roland Samuel</a> on <a href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" target="_blank" rel="noopener nofollow noreferrer" data-href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></p>
<p>Businesses use all kinds of management systems for handling their workflow.</p>
<p>These systems can generate loads of data, which, when pieced together, offer valuable insights on the business, providing for better decision making.</p>
<p>Artificial Intelligence technologies, when paired with traditional systems, extend their output and bring automation and predictions to the table.</p>
<p>Having the right knowledge from a decision management system can give <a href="https://blog.digitalogy.co/video-testimonials-an-effective-tool-for-establishing-your-business/">businesses a significant edge</a> and help in avoiding risks.</p>
<h4><strong>10. Content Creation</strong></h4>
<p>Content plays a role so crucial in the modern world that it is impossible to overlook it.</p>
<p>The right content can help you target your desired audience group faster and boost your business at the same time.</p>
<p>Content has the potential to create an impact on the audience, keeping businesses alive.</p>
<p>With the introduction of AI, creating content has never been easier with AI-powered content writing platforms, keyword research tools, content intelligence platforms.</p>
<blockquote>
<p>Quill, WordAI, Atomic AI, Twinword and Keyword tool are some of the modern examples of AI-backed content creation tools.</p>
</blockquote>
<h4><strong>11. Robotic Process Automation</strong></h4>
<blockquote><p>“The relationship between technology and people has to change in the future for the better, and I think RPA is one of the great tools to enable that change”.</p>
<p><strong>– Leslie Willcocks, professor of technology, work, and globalization at the London School of Economics</strong></p>
</blockquote>
<p>Robotic Process Automation is a domain of AI where robots are programmed to carry out repetitive tasks, requiring zero human intervention.</p>
<p>Having robots manage repetitive activities proves beneficial for enterprises as it eliminates chances of human errors.</p>
<p><img src="https://media.giphy.com/media/8gRgYeXD3rKUcjWlzB/giphy.gif"></p>
<p>GIF By <a href="https://ubtrobot.com/pages/walker" target="_blank" rel="noopener noreferrer">UBTech</a></p>
<p>It increases the throughput of the system while makes room for human employees to be placed at sections where human judgment is vital.</p>
<p>The applications for RPA can be often be seen in the banking industry, customer service sector, data extraction processes, eCommerce platforms and such.</p>
<h3><strong>For More Read –</strong></h3>
<blockquote data-secret="YxwHPirF2f"><p><a href="https://blog.digitalogy.co/top-robotics-companies-in-world-to-watch-2020/">Top Robotics Companies in World to Watch Out for in 2020</a></p></blockquote>

<h4><strong>12. Cyber Defence</strong></h4>
<blockquote>
<p>“Cyber security is much more than a matter of IT.”<br>
<strong>– Stephane Nappo</strong></p>
</blockquote>
<p>As cyber-crooks figure out new ways to cause harm to enterprises online, a more robust security solution is becoming the need of the hour.</p>
<p>With businesses going digital, keeping them safe online is of utmost priority. Cyber-Defence, coupled with Artificial Intelligence, creates an additional layer of <a href="https://blog.digitalogy.co/the-importance-of-information-security-for-your-business/" target="_blank" rel="noopener noreferrer">security</a>, countering most modern-day attacks.</p>
<p>AI can help predict, prevent, analyze and recover from cyber threats by deploying its artificial neural networks, machine learning and behavioral analytics subsets, to enhance the security measures in place.</p>
<h4><strong>13. </strong><strong>Text Analytics and Natural Language Processing (NLP)</strong></h4>
<h4><strong><img src="https://blog.digitalogy.co/wp-content/uploads/2020/04/Text-Analytics-and-Natural-Language-Processing-NLP-scaled.jpg" alt="Text Analytics and Natural Language Processing (NLP)" width="2560" height="1707" srcset="https://blog.digitalogy.co/wp-content/uploads/2020/04/Text-Analytics-and-Natural-Language-Processing-NLP-scaled.jpg 2560w, https://blog.digitalogy.co/wp-content/uploads/2020/04/Text-Analytics-and-Natural-Language-Processing-NLP-300x200.jpg 300w, https://blog.digitalogy.co/wp-content/uploads/2020/04/Text-Analytics-and-Natural-Language-Processing-NLP-1024x683.jpg 1024w, https://blog.digitalogy.co/wp-content/uploads/2020/04/Text-Analytics-and-Natural-Language-Processing-NLP-768x512.jpg 768w, https://blog.digitalogy.co/wp-content/uploads/2020/04/Text-Analytics-and-Natural-Language-Processing-NLP-1536x1024.jpg 1536w, https://blog.digitalogy.co/wp-content/uploads/2020/04/Text-Analytics-and-Natural-Language-Processing-NLP-2048x1365.jpg 2048w" sizes="(max-width: 2560px) 100vw, 2560px"></strong></h4>
<p>Photo by <a href="https://unsplash.com/@thisisengineering?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" target="_blank" rel="noopener noreferrer" data-href="https://unsplash.com/@thisisengineering?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">ThisisEngineering RAEng</a> on <a href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" target="_blank" rel="noopener noreferrer" data-href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></p>
<p>Text Analytics is a branch of Artificial Intelligence that is radically simplifying how we extract information from exceedingly large volumes of text.</p>
<p>Whereas <a href="https://towardsdatascience.com/python-libraries-for-natural-language-processing-be0e5a35dd64?source=your_stories_page---------------------------" target="_blank" rel="noopener nofollow noreferrer">NLP </a>enables us to train various AI models using datasets containing a vast collection of words, grammar and speech from human language to create a more seamless interaction between humans and machines.</p>
<p>The insights generated from this data help in making important decisions. The practical application of text analytics technologies can be observed in security and fraud detection systems.</p>
<h4><strong>14. Digital Twin/AI Modeling</strong></h4>
<p>A Digital Twin is essentially a digital simulation of a …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.digitalogy.co/artificial-intelligence-technologies/">https://blog.digitalogy.co/artificial-intelligence-technologies/</a></em></p>]]>
            </description>
            <link>https://blog.digitalogy.co/artificial-intelligence-technologies/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24429526</guid>
            <pubDate>Thu, 10 Sep 2020 06:37:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Annoying website features I face as a blind person]]>
            </title>
            <description>
<![CDATA[
Score 440 | Comments 213 (<a href="https://news.ycombinator.com/item?id=24429012">thread link</a>) | @Garbage
<br/>
September 9, 2020 | https://bighack.org/5-most-annoying-website-features-i-face-as-a-blind-screen-reader-user-accessibility/ | <a href="https://web.archive.org/web/*/https://bighack.org/5-most-annoying-website-features-i-face-as-a-blind-screen-reader-user-accessibility/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><span>These are the five most annoying inaccessible web elements I face as a blind screen reader user every day, and how to fix them.
</span>
					</p><div>
						<p><span>For blind and visually impaired people like me, accessibility is the difference between us being able to use a website and clicking off it.&nbsp;</span></p>
<h2>How screen readers work</h2>
<p><span>Screen readers allow blind and visually impaired people to use computers, phones and tablets independently. Most screen readers use software, and a Text To Speech (TTS) engine, which is what converts the text from the screen reader into speech. Screen readers convert the text displayed on screen into a format that blind users can process.</span></p>
<p><span>Screen readers read out loud everything that’s on the screen and allow people to navigate using touch gestures and shortcut keys. They also work with other output devices such as a braille display.</span></p>
<p><span>As a screen reader user, here are the most common issues I encounter on a daily basis.&nbsp;</span></p>
<h2>Unlabelled links and buttons</h2>
<p><span>Screen reader users rely on links and buttons to navigate around a website and to find the information we need. If links and buttons are not labelled correctly or if at all, then it makes it difficult for screen reader users to find the information they need. Ultimately, unlabelled links make it much harder to navigate the website easily, quickly and independently.</span></p>
<p><span>For example, when linking to an about page, ‘click here’ doesn’t give any clue as to where it leads to, but ‘find out more about who we are’ is clear.</span></p>
<p><span>If links and buttons are labelled correctly, screen readers can read the label out loud. It means that blind and visually impaired people don’t have to press the link or button without knowing where it will take them.</span></p>
<p><span>As well as unlabelled elements, links and buttons that do not have a clear description are also really frustrating. They must have a clear description of where they will lead to when pressed, rather than ‘click here’. Never make your users guess where a link will take them or force them into a trial-and-error situation. This makes for tedious user experience.</span></p>
<h2>No image descriptions</h2>
<p><span>This is probably the most common issue I encounter when browsing the web.&nbsp;</span><span>Using image descriptions is essential for accessibility. Image descriptions are also known as alt text (alternative text) which is a written description of an image.</span></p>
<p><span>Screen readers read image descriptions out loud. This means that blind and visually impaired people can understand the content of the image in an accessible way.&nbsp;</span><span>If images do not have alt text, then screen readers will simply say “image” or “graphic” which gives no context or meaning.</span></p>
<p><span>Images often convey valuable information. It’s therefore important that people with a visual impairment can access this information as well.&nbsp;</span><span>Alt text should be clearly written and give an accurate description of the image.</span></p>
<p><strong>Check out <a href="https://bighack.org/how-to-write-better-alt-text-descriptions-for-accessibility/">our tips for writing better alt text</a> to ensure your images are fully accessible.</strong></p>
<h2>Poor use of headings</h2>
<p><span>For quick and easy navigation, many screen reader users navigate using various elements on the page such as headings. They are a great way to find the information we need quickly and effectively. Especially when they follow a logical heading structure with H1s, H2s and H3s helping to prioritise the content.</span></p>
<p><img src="https://bighack.org/wp-content/uploads/2020/05/Headings@2x.jpg" alt="Logical heading structure begins with Heading 1, with Heading 2 sitting beneath heading 1. Heading 3 sits within heading 2 and so on." width="1958" height="1236" srcset="https://bighack.org/wp-content/uploads/2020/05/Headings@2x.jpg 1958w, https://bighack.org/wp-content/uploads/2020/05/Headings@2x-300x189.jpg 300w, https://bighack.org/wp-content/uploads/2020/05/Headings@2x-768x485.jpg 768w, https://bighack.org/wp-content/uploads/2020/05/Headings@2x-1536x970.jpg 1536w" sizes="(max-width: 1958px) 100vw, 1958px" data-srcset="https://bighack.org/wp-content/uploads/2020/05/Headings@2x.jpg 1958w, https://bighack.org/wp-content/uploads/2020/05/Headings@2x-300x189.jpg 300w, https://bighack.org/wp-content/uploads/2020/05/Headings@2x-768x485.jpg 768w, https://bighack.org/wp-content/uploads/2020/05/Headings@2x-1536x970.jpg 1536w" data-src="https://bighack.org/wp-content/uploads/2020/05/Headings@2x.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p>
<p><span>If websites don’t use headings, it means screen reader users are unable to use the keyboard shortcuts to navigate through the webpage this way. If that’s the case, we have to resort to tabbing or arrowing through a long web page to find the information we need.</span></p>
<p>Headings also help to break up the web content visually and improve readability. Other elements that screen reader users use to navigate webpages include links, lists or landmarks.</p>
<h2>Inaccessible web forms</h2>
<p><span>Most websites use forms in one way or another. Whether it’s to help you search for a product or to get in touch through a contact form. However, when these forms are not labelled, or not labelled correctly, it means we cannot use them.</span></p>
<p><span>For example, if a search box is not labelled, it means screen reader users have no idea of the purpose of that box. It means people who use screen readers cannot access the same functionality.</span></p>
<p><span>Contact forms are an effective way for customers to get in touch with your brand or business. And as a screen reader user, there’s nothing more frustrating than these forms being labelled incorrectly.</span></p>
<p><span>Especially CAPTCHA checkout requirements. Without an option to hear the audio, it’s not accessible. It means we are unable to fill in the form independently. I often have to enlist help from a sighted person, but this isn’t possible for everyone.</span><b>&nbsp;</b></p>
<h2>Auto-playing audio and video</h2>
<p><span>Most people will know how annoying it is to load a web page with noisy adverts that start playing suddenly. But for screen reader users, it can be even more alarming. When video or audio starts playing automatically, it can drown out the voice of the screen reader. This makes it harder to find the pause or stop buttons.</span></p>
<p><span>(And if these buttons are unlabelled, then it’s practically impossible for me to stop the video quickly which causes extra frustration.) If I’m unable to stop the sound or video, I normally click off.</span></p>
<p><span>The solution? Make sure there’s no auto-playing video or audio when your website loads. If you really want to use video, make sure the audio is muted and the user can pause, stop or hide the media player.</span></p>
<p><span>These issues may seem small to sighted users. But they’re the difference between me being able to use a website independently or not. And they make a huge difference when implemented correctly.</span></p>
					</div></div>]]>
            </description>
            <link>https://bighack.org/5-most-annoying-website-features-i-face-as-a-blind-screen-reader-user-accessibility/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24429012</guid>
            <pubDate>Thu, 10 Sep 2020 04:55:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Security by Obscurity Is Underrated]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24428930">thread link</a>) | @zdw
<br/>
September 9, 2020 | https://utkusen.com/blog/security-by-obscurity-is-underrated.html | <a href="https://web.archive.org/web/*/https://utkusen.com/blog/security-by-obscurity-is-underrated.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>
08 September 2020
</p>
<p>In the information security field, we have developed lots of thoughts that can’t be discussed (or rarely discussed):</p>
<ul>
<li>
<p>Never roll your own crypto</p>
</li>
<li>
<p>Always use TLS</p>
</li>
<li>
<p>Security by obscurity is bad</p>
</li>
</ul>
<p>And goes like this. Most of them are very generally correct. However, I started to think that people are telling those because everyone is telling them. And, most of the people are actually not thinking about exceptional cases. In this post, I will raise my objection against the idea of “Security by obscurity is bad”.</p>
<h2 id="risk-defense-in-depth-and-swiss-cheese">Risk, Defense in Depth and Swiss Cheese</h2>
<p>One of the main goal of defensive security is reducing the risk for the target business. According to the OWASP’s methodology, the risk of an issue is calculated with the formula below:</p>
<p><code>Risk = Likelihood * Impact</code></p>

<p>According to this formula, a Remote Code Execution issue poses more risk than a Cross Site Scripting one since the RCE causes more impact. This is easy. But what about the likelihood metric. According to the OWASP, likelihood refers that:</p>
<div><div><pre><code>At the highest level, this is a rough measure of how likely this particular vulnerability is to be uncovered and exploited by an attacker
</code></pre></div></div>
<p>So, if we can reduce the likelihood, we can reduce the overall risk. That’s good. It’s actually very similar to a very common idea called “Defense in Depth”. It’s also referred as “Swiss Cheese Model”</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/0/07/Swiss_cheese_model.svg" alt="Swiss Cheese"></p>
<p>According to this model, you need to build your defense mechanisms in a layered model so that even the attackers pass the first one, they will get caught on the others.</p>
<h2 id="security-by-obscurity">Security by Obscurity</h2>
<p>So let’s talk about security by obscurity. It’s a bad idea to use it as a single layer of defense. If the attacker passes it, there is nothing else to protect you. But it’s actually would be good to use it as an “additional” layer of defense. Because it has a low implementation cost and it usually works well.</p>
<p>Let’s think about a couple of scenarios here:</p>
<ul>
<li>I have a server that runs the SSH with it’s default port <code>22</code> and my credentials are: <code>root:123456</code>. What is the likelihood of being compromised?</li>
</ul>
<p>It’s almost 100% since the hackers are conducting brute force attacks to the services with common credentials globally.</p>
<ul>
<li>SSH runs in port <code>22</code> and my credentials are <code>utku:123456</code>. What is the likelihood of being compromised?</li>
</ul>
<p>Well, we have eliminated the global brute forcers since we are not using a common username. The likelihood and risk are reduced. However, we still have to deal with targeted attackers. A targeted attacker can guess the username as <code>utku</code> since it’s my name.</p>
<ul>
<li>SSH runs in port <code>64323</code> and my credentials are <code>utku:123456</code>. What is the likelihood of being compromised?</li>
</ul>
<p>Now we changed the default port number. Does it help? Firstly, we’ve eliminated the global brute forcers again since they scan only the common ports. What about the others? To find this out, I did a small survey on my Twitter to find out people’s port scan behaviors.</p>
<blockquote><div lang="en" dir="ltr"><p>I'm trying to prove a point for my new article. I need your answers for the question below. (please be honest)</p><p>-When you do a port scan with nmap to find open ports on the target, are you specify a custom port range to scan all 65,535 ports? (with -p0-65535 parameter)</p></div>— Utku Şen (@utkusen) <a href="https://twitter.com/utkusen/status/1303021175556145154?ref_src=twsrc%5Etfw">September 7, 2020</a></blockquote>

<p>As you can see here, lots of people tend to scan the default/most popular ports only. So, if you switch your port from 22 to 64323, you will eliminate some of them. You will reduce the likelihood and risk.</p>
<p>The same thing goes for software vulnerabilities as well. If a vulnerability found in the Microsoft Remote Desktop Protocol, everybody will scan for the port 3389 globally. You can reduce your risk just by changing the default port.</p>
<h2 id="other-applications">Other Applications</h2>
<p>Of course, it’s possible to use the same methodology in other fields other than changing the defaults. For example, the following ideas might be a good idea for some specific cases (not always)</p>
<ul>
<li>
<p><strong>Obfuscating codes:</strong> Of course, it’s common knowledge. Hackers are people too. If you obfuscate your code well, they will need to spend more time to find issues. They may give up eventually.</p>
</li>
<li>
<p><strong>Using random variable names for a web application:</strong> Instead of using clear variable names, you can switch them with random strings. It might help just like the code obfuscation.</p>
</li>
<li>
<p><strong>Using Symmetric Encryption in the Database:</strong> When you write data to the database, use a function like <code>encryption_algorithm(data,key)</code>. Likewise, when you read data, use a function like <code>decryption_algorithm(data,key)</code>. If the attacker can read your backend code, obviously he/she can decrypt your database. But if there is an issue that allows an attacker to read data from the database, but not the backend code (like SQL Injection), the gathered data won’t be helpful for the attacker.</p>
</li>
</ul>
<h2 id="real-life-applications">Real Life Applications</h2>
<p>Security by obscurity is widely used in physical/real-life security. For example, the president goes from point A to point B with his 30 cars convoy. But he’s not sitting on his own presidential car so that the attacker won’t target him easily. He can be in any car and it reduces the risk of an attack.</p>
<p><img src="https://i.dailymail.co.uk/1s/2019/06/04/00/14330600-0-image-a-38_1559605545988.jpg" alt="President"></p>
<p>Camouflaged animals are using security by obscurity as well. Obscurity reduces the likelihood of being killed. Therefore, they gained this ability in the evolutionary process.</p>
<p><img src="https://static.boredpanda.com/blog/wp-content/uuuploads/animal-camouflage/animal-camouflage-4.jpg" alt="Animal"></p>
<h2 id="conclusion">Conclusion</h2>
<p>Security by obscurity is not enough by itself. You should always enforce the best practices. However, if you can reduce the risk with zero cost, you should do that. Obscurity is a good layer of security.</p>


</div></div>]]>
            </description>
            <link>https://utkusen.com/blog/security-by-obscurity-is-underrated.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24428930</guid>
            <pubDate>Thu, 10 Sep 2020 04:36:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The rate of obsolescence of knowledge in software engineering]]>
            </title>
            <description>
<![CDATA[
Score 34 | Comments 17 (<a href="https://news.ycombinator.com/item?id=24428810">thread link</a>) | @dgs_sgd
<br/>
September 9, 2020 | https://daltyboy11.github.io/obsolescence-of-knowledge-in-software-engineering/ | <a href="https://web.archive.org/web/*/https://daltyboy11.github.io/obsolescence-of-knowledge-in-software-engineering/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>A physicist loses half the value of their physics knowledge in just four years whereas
an English professor would take over 25 years to lose half the value of the
knowledge they had at the beginning of their career [1]. These estimates are
taken form a paper written in 1982 so software engineers obviously weren’t
included. But it begs the question… What would the half-life of the value of a
software engineer’s knowledge be? I suspect it’s somewhere between the physicist’s
and the English professor’s because a software engineer’s knowledge is a combination
of eternal computer science/engineering principles and ephemeral technologies that
drift in and out of popularity over time.</p>

<h2 id="knowledge-that-doesnt-expire">Knowledge that doesn’t expire</h2>
<p>Software engineers with a traditional computer science background learn things
that never expire with age: data structures, algorithms, compilers,
distributed systems, etc. But most of us don’t work with these concepts
directly. Abstractions and frameworks are built on top of these well studied
ideas so we don’t have to get into the nitty-gritty details on the job
(at least most of the time). Examples are the C++ standard library which
implements optimized sorting for arrays, and Apache Spark which provides fault
tolerant cluster computing out of the box.</p>

<h2 id="knowledge-that-does-expire">Knowledge that does expire</h2>
<p>The unavoidable ephemeral knowledge one accumulates during their career comes in
many forms and this isn’t an exhaustive list:</p>

<ol>
  <li>A vogue framework or programming paradigm that falls out of favor in a couple of years.</li>
  <li>Domain knowledge in a rapidly evolving industry/field.</li>
  <li>Knowledge of proprietry technology: e.g. internal tools at your company.</li>
</ol>

<p>Knowledge of this kind can quickly transition from zealous adoption to every company who
uses said knowledge trying to sunset everything they’ve built with it.</p>

<h2 id="my-experience">My Experience</h2>
<p>I’m inclined to say I use ephemeral knowledge more than eternal knowledge to perform
my job. And then there’s the added pressure in our industry of always having to learn
new and useful things.</p>

<p>A theoretical physicist who spends a great deal of time mastering a theory and
the mathematical techniques behind it, only to see that theory rendered obsolete
by a new and improved theory several years later, is analogous to a software
engineer who spends a great deal of time mastering a web development framework,
learning its intricacies and gotcha’s, only to see that framework rendered
obsolete by a new framework several years later, leaving no more demand for
that knowledge in the labor market.</p>

<p>I relate to the physicist more than the English professor. What do you think?</p>



<p>[1] McDowell, John M. “Obsolescence of Knowledge and Career Publication Profiles: Some Evidence of Differences among Fields in Costs of Interrupted Careers.” The American Economic Review, vol. 72, no. 4, 1982, pp. 752–768. JSTOR, www.jstor.org/stable/1810015. Accessed 9 Sept. 2020.</p>

  </div></div>]]>
            </description>
            <link>https://daltyboy11.github.io/obsolescence-of-knowledge-in-software-engineering/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24428810</guid>
            <pubDate>Thu, 10 Sep 2020 04:10:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Interfacing Microcontrollers with SD Card]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24428745">thread link</a>) | @peter_d_sherman
<br/>
September 9, 2020 | https://openlabpro.com/guide/interfacing-microcontrollers-with-sd-card/ | <a href="https://web.archive.org/web/*/https://openlabpro.com/guide/interfacing-microcontrollers-with-sd-card/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><img height="1" width="1" src="https://www.facebook.com/tr?id=720372835040462&amp;ev=PageView&amp;noscript=1">    <meta name="generator" content="WordPress Download Manager 3.0.4">
<a href="#content">Skip to content</a><div id="boxed-wrapper"><div id="wrapper"><header></header><main id="main"><div><section id="content"><article id="post-2339"><div><p>The secure digital card (SD) is a low cost, non-volatile memory card format developed by the SD Card Association. Since its inception back at the start of the century, the demand for this medium-sized, energy and space-efficient, the memory storage device has been growing at a fast rate. Therefore, to meet the market requirements, the SDA was set up as a non-profit organization to promote and create SD Card standards. There are various topics related to the SD card such as the different device families, speed classes, smart cards, card security and so on and it is used in various markets like digital cameras, personal computers, and embedded systems. Some of the standard variations include SD, SDHC, SDXC, SD-ultra high speed etc. The microSD is the miniaturized SD memory card format with a small form factor and is widely used in various electronic devices.<br>
What we are going to learn is the use of SD cards in an embedded system. To be specific, we will be dealing with the use of SD cards in small embedded systems.</p><h2>Circuit&nbsp;and Interfacing</h2><p>SD card has a native host interface apart from the SPI mode for communicating with master devices. The native interface uses four lines for data transfer where the microcontroller has SD card controller module and it needs separate license to use it. Since the SPI is a widely used protocol and it is available in most low-cost microcontrollers, the SPI mode is the widely used interface in low cost embedded systems. The working voltage range of SD family is 2.7V to 3.6V and this is indicated in the operation condition register (OCR).</p><p><img src="https://openlabpro.com/wp-content/uploads/2016/12/2000px-SD_Pins.svg_-1.png" alt="2000px-sd_pins-svg" width="214" height="292"></p><div id="attachment_2345"><img aria-describedby="caption-attachment-2345" src="https://openlabpro.com/wp-content/uploads/2016/12/SD-card.png" alt="sd-card" width="371" height="229" srcset="https://openlabpro.com/wp-content/uploads/2016/12/SD-card-200x124.png 200w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-300x185.png 300w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-400x247.png 400w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-600x371.png 600w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-768x475.png 768w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-800x495.png 800w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card.png 1024w" sizes="(max-width: 371px) 100vw, 371px"><p id="caption-attachment-2345">SD Card pinout</p></div><div id="attachment_2347"><img aria-describedby="caption-attachment-2347" src="https://openlabpro.com/wp-content/uploads/2016/12/SD-card-2.png" alt="sd-card-2" width="381" height="213" srcset="https://openlabpro.com/wp-content/uploads/2016/12/SD-card-2-200x112.png 200w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-2-300x168.png 300w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-2-400x223.png 400w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-2-600x335.png 600w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-2-768x429.png 768w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-2-800x447.png 800w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-2.png 1024w" sizes="(max-width: 381px) 100vw, 381px"><p id="caption-attachment-2347">MicroSD Card pinout</p></div><p>Most micro-controllers use the SPI communication protocol to interface with the SD cards. The SD cards have a microcontroller that shows their availability to the master controller(microcontroller). The micro-controller sees the SD card as an addressable sector on which read/write functions are possible. Once the microcontroller is in the SPI mode, communication between the master and the slave is done via 4 pins viz. clock, chip select, data in and data out. It should be kept in mind that throughout the communication between the two devices, the micro-controller will be sending out the clock.<br>
Most development boards have a dedicated SD card slot. But to understand the connections, let us analyze this fairly simple circuit.</p><div id="openl-194223254"><div data-animationoffset="100%"><div><div data-link="https://openlabpro.com/online-courses/pic-microcontroller/" data-link-target="_self" data-animationoffset="100%"><div>From the very basic I/O control to the advaced SD Card interfacing, this course covers what you need to get started in Embedded Systems.<div><div><iframe src="https://player.vimeo.com/video/362065141?autoplay=0&amp;autopause=0" width="600" height="360" allowfullscreen="" title="vimeo362065141" allow="autoplay; fullscreen"></iframe></div></div></div><a href="https://openlabpro.com/online-courses/pic-microcontroller/" target="_self">Learn more about the course</a></div></div></div></div><h3>Circuit</h3><p><img src="https://openlabpro.com/wp-content/uploads/2016/12/SD-card-circuit.png" alt="sd-card-circuit" width="506" height="284" srcset="https://openlabpro.com/wp-content/uploads/2016/12/SD-card-circuit-200x113.png 200w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-circuit-300x169.png 300w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-circuit-400x225.png 400w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-circuit-600x338.png 600w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-circuit-768x432.png 768w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-circuit-800x450.png 800w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-circuit-1024x576.png 1024w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-circuit-1200x675.png 1200w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-circuit.png 1280w" sizes="(max-width: 506px) 100vw, 506px"></p><p>If the logic level of the microcontroller is different than the SD card, level shifter needs to be used for converting the line voltages.<br>
The MISO (master in serial out) pin should be connected to the SDI (serial data in) pin on the microcontroller.<br>
The MOSI (master out serial in) pin should be connected to the SDO (serial data out) pin on the microcontroller.<br>
The SCK (serial clock) pin should be connected to the SCK (serial clock) pin on the microcontroller.<br>
The CS (chip select) pin should be connected to the corresponding CS pin on the microcontroller or on any digital I/O pin on the microcontroller. A common ground is provided.</p><p><b>IMPORTANT NOTE</b>: While connecting the power supply, make sure that the supply is drawn from a 3.3V supply as a 5V supply would see your card go up in smoke.</p><h3>Interfacing</h3><p>Once the connections are set up, we are ready to interface our hardware with the software.<br>
Set the directions of each of the four pins correctly. While activating the SPI mode, an ideal configuration should be, mode(0,0) and the phase with input sampled at the middle of data out. Also, the clock frequency should be set in the range of 100 kHz and 400 kHz prior to initializing the card. Once the initialization is done, the clock can be set to a more desired frequency.</p><h2>SD Commands</h2><p>Next comes the tricky part, initializing the SD card and performing the raw data communication. A systematic approach to programming the software would make the task pretty easy.<br>
But first, it is important to learn how the micro-controller activates the SD card. There are a fixed set of commands and responses, which must be followed to create a command to response structure in our program. The data is transmitted in a byte-oriented format with a definite length.<br>
The following table shows the necessary<b> commands</b> to the card and the corresponding response from the card.</p><p><img src="https://openlabpro.com/wp-content/uploads/2016/12/SD-card-3.png" alt="sd-card-3" width="507" height="1118" srcset="https://openlabpro.com/wp-content/uploads/2016/12/SD-card-3-136x300.png 136w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-3-200x441.png 200w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-3-400x882.png 400w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-3-464x1024.png 464w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-3-600x1323.png 600w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-3-768x1694.png 768w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-3-800x1765.png 800w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-3-1200x2647.png 1200w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-3.png 1274w" sizes="(max-width: 507px) 100vw, 507px"></p><p>Every command has a constant length of 6 bytes.<br>
The first byte is the addition of the command number and the number 64.<br>
<b>Example</b>:<br>
For CMD0: command number 0 + 64 = 64 = 0x40 in hexadecimal.<br>
For CMD1: command number 1 + 64 = 65 = 0x41 in hexadecimal.<br>
And so on.<br>
This is followed by a set of four bytes which are known as the arguments. These arguments usually contain the address of a data or the length of a block.<br>
The last byte is the CRC (Cyclic Redundancy Check) Byte. Most commands in the SPI mode does not require a check byte if the CRC feature isn’t enabled. For some commands like CMD0, the CRC is 0x95 and in most cases, a 0xFF is sent. Enabling the CRC requires you to send the correct check byte from the micro-controller. So, ensure whether the CRC feature is enabled or disabled.<br>
A <b>command frame</b> looks like this-</p><p><img src="https://openlabpro.com/wp-content/uploads/2016/12/Clr_frame1-800x267.png" alt="Interfacing Microcontrollers with SD Card - Command frame" width="800" height="267" srcset="https://openlabpro.com/wp-content/uploads/2016/12/Clr_frame1-200x67.png 200w, https://openlabpro.com/wp-content/uploads/2016/12/Clr_frame1-300x100.png 300w, https://openlabpro.com/wp-content/uploads/2016/12/Clr_frame1-400x133.png 400w, https://openlabpro.com/wp-content/uploads/2016/12/Clr_frame1-600x200.png 600w, https://openlabpro.com/wp-content/uploads/2016/12/Clr_frame1-768x256.png 768w, https://openlabpro.com/wp-content/uploads/2016/12/Clr_frame1-800x267.png 800w, https://openlabpro.com/wp-content/uploads/2016/12/Clr_frame1-1024x342.png 1024w, https://openlabpro.com/wp-content/uploads/2016/12/Clr_frame1-1200x400.png 1200w, https://openlabpro.com/wp-content/uploads/2016/12/Clr_frame1.png 1280w" sizes="(max-width: 800px) 100vw, 800px"></p><p>The card will receive a command when the DO pin (Data Out) is driven high as shown above. The CS pin (Chip Select) must be driven high to low before sending the command and must be kept low during the process. The time between a command and its response is known as the command response time (NCR). As mentioned earlier, regarding the clock pulses from the micro-controller, the corresponding response byte sent back from the card to the microcontroller should be driven by the serial clock pulses of the micro-controller. There is a chance that the response byte from the card might get skipped by the microcontroller due to the absence of a driving clock pulse. Hence it is necessary to make sure that an 8-Bit clock pulse is sent to the Card soon after the Command Frame is sent (Refer the <b>TECHNICAL NOTE </b>below). Also while receiving a Byte from the card, the DI pin (Data In) must be driven high.</p><p>Furthermore, let us analyze the different<b> types of responses</b> that we get from the card and what they mean.</p><p><img src="https://openlabpro.com/wp-content/uploads/2016/12/Response_Color-1.jpg" alt="response_color" width="568" height="289"></p><p>An R1 response, 0x01 means that the command sent prior to the response has resulted in the card going into an idle state.<br>
A response byte 0x00 means that the command has been accepted and the card will be waiting for the proposed event to take place. If any other bits in an R1 response is set, it is the result of an error and it’ll be down to the factor mentioned in each R1 response bit in the figure.</p><h2>Initializing&nbsp;the SD Card</h2><p>Now, as far as sending the commands are concerned, there is an order in which they must be sent. Only the commands, CMD0, CMD1, ACMD41, CMD58 and CMD59 will be accepted when the card is in its idle state. Sending any other command will likely to yield an illegal response.</p><p><b>TECHNICAL NOTE</b>: After interfacing the card, the micro-controller must always send a set of bytes, which we will refer to as dummy bytes. One dummy byte is 0xFF. These dummy bytes have a simple yet significant purpose. Prior to the initialization, the card must know the frequency at which the data is being sent. By sending around 75 dummy bits approximately (dummy byte * 10 times = 80 bits), the card will be ready for communication. Also even after every command is sent, it is a good practice to send at least one dummy byte. A logical explanation for this is that communication is driven by the clock pulse of the micro-controller. The clock pulse is sent only when the data buffer is filled. After every response is sent and prior to the next command or between command and response, the SCK will stop generating pulses due to an empty data buffer. To ensure the continual transmission of clock pulses between every command, fill the data buffer with a junk value such as a dummy byte. To create a dummy byte function with the number of loops as the argument.</p><p>The<b> first command</b> to be sent to the card is the <b>CMD0</b> command. The structure of every other command-response should be based on this model.</p><ul><li>Drive the DO pin high.</li><li>Drive the CS pin from high to low.</li><li>Send a dummy byte.</li><li>Then send the following 6-byte command continuously<br>
First byte: 0x40<br>
Next four bytes: 0x00000000<br>
CRC byte: 0x95</li></ul><ul><li>Send another dummy byte or as many as required, to generate the SCK giving time for the SD card to respond to the command request.</li><li>Wait for the receive flag bit to set and then read the response from the SD card or create a loop to read the response a few number of times. The response should reach back within the command to response (Ncr) time. Or else, something must be wrong.</li></ul><ul><li>The desired response is 0x01, meaning the card is in the idle state and we are good to go.</li></ul><p>Send the <b>CMD8</b> command next to check the version of your SD card.<br>
The difference in the 6-byte commands are<br>
First byte: 0x48<br>
Next four bytes: 0x000001AA<br>
CRC byte: 0x87</p><p>We are looking for two possibilities in our response byte. Either 0x01 or 0x05.</p><p>A 0x01 response means that you have a version 2 SD card. The 0x01 response is followed by the 4 bytes 0x00, 0x00, 0x01, 0xAA in the order of their transmission from the SD card which is, in fact, the argument you send in your command.</p><p>If the response is 0x05, it means the card is a version 1 or an MMC card. If the card is actually a version 2 SD card, then this response is the result of an illegal command. Also, the card is now in the idle state.</p><p>Once the above two commands (CMD0 and CMD8) are done, it is safe to say that our SD Card is working in good condition and ready for data Read/Write.<br>
Additionally, just to ensure whether the SD Card is functioning in the correct working voltage, send the <b>CMD58</b> Command.</p><p>Next, we must initiate the i<b>nitialization</b> process. For this send a <b>CMD1</b> command and wait for response 0x00, meaning the idle state bit is cleared.<br>
If you are using an SDC or for the purpose of creating a general code, it is …</p></div></article></section></div></main></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://openlabpro.com/guide/interfacing-microcontrollers-with-sd-card/">https://openlabpro.com/guide/interfacing-microcontrollers-with-sd-card/</a></em></p>]]>
            </description>
            <link>https://openlabpro.com/guide/interfacing-microcontrollers-with-sd-card/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24428745</guid>
            <pubDate>Thu, 10 Sep 2020 03:55:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On moving away from a six figure consultancy to becoming an indie hacker]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 10 (<a href="https://news.ycombinator.com/item?id=24428473">thread link</a>) | @jv22222
<br/>
September 9, 2020 | https://matteomosca.io/how-covid-and-a-kick-scooter-turned-me-into-an-indie-hacker | <a href="https://web.archive.org/web/*/https://matteomosca.io/how-covid-and-a-kick-scooter-turned-me-into-an-indie-hacker">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://matteomosca.io/how-covid-and-a-kick-scooter-turned-me-into-an-indie-hacker</link>
            <guid isPermaLink="false">hacker-news-small-sites-24428473</guid>
            <pubDate>Thu, 10 Sep 2020 02:52:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A career cold start algorithm]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24428353">thread link</a>) | @enigmatic0202
<br/>
September 9, 2020 | https://boz.com/articles/career-cold-start | <a href="https://web.archive.org/web/*/https://boz.com/articles/career-cold-start">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><p>Several times in my career, I’ve joined a team whose work was already well
under way, where I had a massive knowledge deficit, and didn’t have
pre-existing relationships. None of those excuses relieved me from the pressure
I felt to establish myself and contribute. Over time, I realized that the
natural instinct to push for early impact leads many incoming leaders into
challenging relationships as they expose their knowledge deficit and waste
time. So, I developed an algorithm that has helped me ramp up quickly — and
in several cases — have an impact in a relatively short period of time, while
minimizing collateral damage.</p>
<p>The first step is to find someone on the team and ask for 30 minutes with them.
In that meeting you have a simple agenda:</p>
<ul>
<li>For the first 25 minutes: ask them to tell you everything they think you
should know. Take copious notes. Only stop them to ask about things you don’t
understand. Always stop them to ask about things you don’t understand.</li>
<li>For the next 3 minutes: ask about the biggest challenges the team has right
now.</li>
<li>In the final 2 minutes: ask who else you should talk to. Write down every
name they give you.</li>
</ul>
<p>Repeat the above process for every name you’re given. Don’t stop until there
are no new names.</p>
<p>The sum of the answers from the first 25 mins will not give you a complete
picture of the team’s work. That will take months to develop. But they will
give you a framework for integrating new information more quickly, which will
speed up how fast you ramp. It will also heavily over index on the areas of
work under active discussion, which will help you dive in productively to the
most critical discussions immediately. The nature of what people choose to
discuss is a very valuable signal about the problems the team face, as it may
be about the work, the organization, or process. Finally, it will give you a
sense of the language and terminology that can very often be a barrier to
working smoothly with teams.</p>
<p>The answers from the second question give you a cheat sheet on how to impress
the team with early positive impact. Some of the things you’ll hear will take
time to fix, such as “we need a bigger team” or “our infrastructure isn’t
scaling.” Those are important and it will be good for the team to hear you
internalize those challenges. But a surprising number of the issues you’ll
hear repeatedly will be things you can easily help with, like “we waste a
bunch of time in meetings every week” or “we need a dedicated conference
room.” I start with the latter as quickly as I can because those are the
types of things teams often neglect to prioritize, in spite of a compounding
negative impact on progress.</p>
<p>The third question will give you a valuable map of influence in the
organization. The more often names show up and the context in which they show
up tends to provide a very different map of
the organization than the one in the <a href="http://boz.com/articles/damn-the-org-chart.html">org chart</a>.</p>
<p>For all the value I just described, the greatest value in this process isn’t
in the answers — it is in the asking. Taking these meetings and listening
shows proper respect for the team that’s in place. It can be hard to remember,
but while you may be insecure about taking a new role because you feel like
you’re at a disadvantage, the people you’re speaking with may also be unsure
about you taking that role and what it means for them. Demonstrating mutual
respect builds the trust required to make progress.</p></section></div></div>]]>
            </description>
            <link>https://boz.com/articles/career-cold-start</link>
            <guid isPermaLink="false">hacker-news-small-sites-24428353</guid>
            <pubDate>Thu, 10 Sep 2020 02:30:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Plotting Reddit Comment Trends with Pandas]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24428149">thread link</a>) | @m4rtyr
<br/>
September 9, 2020 | https://sshawarma.github.io/posts/2020/09/plotting-reddit-comment-trends-with-pandas/ | <a href="https://web.archive.org/web/*/https://sshawarma.github.io/posts/2020/09/plotting-reddit-comment-trends-with-pandas/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>Hey there!</p>
<p>I wanted to learn more about Pandas, a Python library for data analysis, so I decided to embark on a mini-project to experiment with it. If you use Reddit, you’ve probably seen a chain of comments like below:</p>
<p><img src="https://sshawarma.github.io/reddit-comment-chain.png" alt=""></p>
<p>Clearly, you can see that there’s a pattern in the number of upvotes. Every reply to the parent comment receives less upvotes compared to the previous reply. It would be interesting to create a bar graph, comparing the number of upvotes the parent comment received, the number of upvotes the first reply received, the number of upvotes the second reply received, …, the number of upvotes the <code>nth</code> reply received. Using Reddit’s API and Pandas, I implemented a program that would do just that. You can find it on GitHub <a href="https://github.com/sshawarma/comment_analyzer">here</a>.</p>
<p>First, we need to import the following:</p>
<div><pre><code data-lang="python"><span>import</span> praw
<span>import</span> pandas <span>as</span> pd
<span>import</span> matplotlib.pyplot <span>as</span> plt
<span>import</span> sys
<span>import</span> math
<span>from</span> concurrent.futures <span>import</span> ThreadPoolExecutor
</code></pre></div><p>PRAW is a Python wrapper for Reddit’s API. <code>matplotlib</code> is a library for creating static, animated, and interactive visualizations in Python. These imports will become clearer as we move on.</p>
<p>Next, we need to define authenticate to Reddit’s API. PRAW allows us to do this pretty easily with OAuth2:</p>
<div><pre><code data-lang="python"><span># Authenticate using our client secret</span>
<span>def</span> <span>authenticate</span>():
    <span>with</span> open(<span>'client_secret.txt'</span>, <span>'r'</span>) <span>as</span> f:
        data <span>=</span> f<span>.</span>read()<span>.</span>split()
        CLIENT_ID <span>=</span> data[<span>0</span>]
        CLIENT_SECRET <span>=</span> data[<span>1</span>]

    <span>return</span> praw<span>.</span>Reddit(client_id<span>=</span>CLIENT_ID,
                    client_secret<span>=</span>CLIENT_SECRET,
                    user_agent<span>=</span>USER_AGENT)
</code></pre></div><p>In this case, the client ID and client secret is stored in a file (called <code>client_secret.txt</code>). We read this and return an instance of PRAW’s <code>Reddit</code> class, which allows us to interact with Reddit’s APIs.</p>
<p>Now, we break down what we have to do in logical chunks. First, we need to get a list of submissions, so that we can look at the comments under each post. PRAW allows us to get a list of the hottest submissions from r/all, which is basically an amalgamation of a bunch of submissions from different subreddits:</p>
<div><pre><code data-lang="python"><span>def</span> <span>get_submission_upvotes</span>(reddit, m, n):
    upvotes_list <span>=</span> []
    submissions <span>=</span> list(reddit<span>.</span>subreddit(<span>'all'</span>)<span>.</span>hot(limit<span>=</span>m))
    <span>with</span> ThreadPoolExecutor() <span>as</span> executor:
        futures <span>=</span> [executor<span>.</span>submit(count_upvotes, submissions[i], n) <span>for</span> i <span>in</span> range(<span>0</span>, m)]
        [upvotes_list<span>.</span>append(future<span>.</span>result()) <span>for</span> future <span>in</span> futures]
    <span>return</span> upvotes_list
</code></pre></div><p>The reason we use <code>concurrent.futures</code> is because, depending on the length of the comment chain we are examining, we might end up taking very long to collect upvotes on one submission but a very short time to collect upvotes on another submission (we will see what the <code>count_upvotes</code> function does next). Here, <code>m</code> represents the number of submissions to look at and <code>n</code> represents the number of comments in a comment chain to examine.</p>
<p>Next, we need to count the number of upvotes of each comment in a comment chain in each submission. This can be done as follows:</p>
<div><pre><code data-lang="python"><span>def</span> <span>count_upvotes</span>(submission, n):
    upvotes <span>=</span> []
    submission<span>.</span>comments<span>.</span>replace_more(limit<span>=</span><span>0</span>)

    count <span>=</span> <span>0</span>
    comment <span>=</span> submission<span>.</span>comments[<span>0</span>]
    <span>while</span> count <span>&lt;</span> n:
        upvotes<span>.</span>append(comment<span>.</span>score)
        count <span>+=</span> <span>1</span>
        <span>if</span> len(comment<span>.</span>replies) <span>&gt;</span> <span>0</span>:
            comment <span>=</span> comment<span>.</span>replies[<span>0</span>]
        <span>else</span>:
            <span>break</span>

    <span>while</span> len(upvotes) <span>&lt;</span> n:
        upvotes<span>.</span>append(float(<span>'nan'</span>))
    <span>return</span> upvotes
</code></pre></div><p>In essence, we get the top comment and keep examining each reply until we have gotten <code>n</code> comments or until the comment chain ends (to get more comment chains of length <code>n</code>, we can increase <code>m</code>). If the comment chain ends prematurely, we add <code>nan</code> (Not a Number) to indicate that no data was collected for the particular reply in the comment chain because that reply did not exist (the comment chain ended, so there were no more upvotes to count).</p>
<p>After counting the upvotes of each comment in the top comment chain, we only have to process the data. First, we compute the average number of upvotes for the top comments, the 1st reply, the 2nd reply, etc:</p>
<div><pre><code data-lang="python"><span>def</span> <span>compute_data</span>(upvotes_list):
    avg_upvotes <span>=</span> []
    <span>for</span> col <span>in</span> range(<span>0</span>, len(upvotes_list[<span>0</span>])):
        avg <span>=</span> <span>0.0</span>
        n <span>=</span> len(upvotes_list)
        <span>for</span> row <span>in</span> range(<span>0</span>, len(upvotes_list)):
            <span>if</span> math<span>.</span>isnan(upvotes_list[row][col]) <span>==</span> False:
                avg <span>+=</span> upvotes_list[row][col]
            <span>else</span>:
                n <span>-=</span> <span>1</span>
        <span>if</span> n <span>&gt;</span> <span>0</span>:
            avg_upvotes<span>.</span>append(avg <span>/</span> n)
        <span>else</span>:
            avg_upvotes<span>.</span>append(<span>0</span>)
    <span>return</span> avg_upvotes
</code></pre></div><p>We return a list called <code>avg_upvotes</code>, which contains the average number of upvotes for the top comment, first reply, second reply, etc. We now convert this list into a bar graph:</p>
<div><pre><code data-lang="python"><span>def</span> <span>render_data</span>(avg_upvotes, n):
    <span># Solution from https://stackoverflow.com/questions/9647202/ordinal-numbers-replacement</span>
    ordinal <span>=</span> <span>lambda</span> n: <span>"</span><span>%d%s</span><span>"</span> <span>%</span> (n,<span>"tsnrhtdd"</span>[(n<span>//</span><span>10</span><span>%</span><span>10</span><span>!=</span><span>1</span>)<span>*</span>(n<span>%</span><span>10</span><span>&lt;</span><span>4</span>)<span>*</span>n<span>%</span><span>10</span>::<span>4</span>])
    x <span>=</span> [str(ordinal(i)) <span>for</span> i <span>in</span> range(<span>0</span>, n)]
    df <span>=</span> pd<span>.</span>DataFrame({<span>'Comment Reply Number'</span>: x, <span>'Average Upvotes'</span>: avg_upvotes})
    df<span>.</span>plot<span>.</span>bar(x<span>=</span><span>'Comment Reply Number'</span>, y<span>=</span><span>'Average Upvotes'</span>, rot<span>=</span><span>0</span>, legend<span>=</span>False)
    plt<span>.</span>xlabel(<span>'Comment Reply Number'</span>)
    plt<span>.</span>ylabel(<span>'Average Upvotes'</span>)
    plt<span>.</span>xticks(size<span>=</span><span>4</span>)
    plt<span>.</span>yticks(size<span>=</span><span>4</span>)
    plt<span>.</span>show()
</code></pre></div><p>Now all we have to do is put it together:</p>
<div><pre><code data-lang="python"><span>if</span> __name__ <span>==</span> <span>'__main__'</span>:
    <span>if</span> len(sys<span>.</span>argv) <span>&lt;</span> <span>3</span>:
        <span>print</span>(<span>'./comment_analyzer.py [number of submissions to analyze] [number of comments]'</span>)
        exit()
    m <span>=</span> int(sys<span>.</span>argv[<span>1</span>])
    n <span>=</span> int(sys<span>.</span>argv[<span>2</span>])
    reddit <span>=</span> authenticate()
    upvotes_list <span>=</span> get_submission_upvotes(reddit, m, n)
    avg_upvotes <span>=</span> compute_data(upvotes_list)
    render_data(avg_upvotes, n)
</code></pre></div><p>The program takes two parameters: the number of submissions to look at and the “depth” of the comment chain we have to look at.</p>
<p>Running the program (assuming you have the necessary libraries installed with Python 3.6+), you get a bar graph like so:</p>
<p><img src="https://sshawarma.github.io/pandas.png" alt="a right-skewed bar graph"></p>
<p>(The “0th” comment represents the top comment).</p>
<p>The above graph allows us to visualize the distribution of upvotes on comments on Reddit. Clearly, the distribution is right-skewed: the number of upvotes diminish as we get deeper down the reply chain. This is to be expected, since the top comment tends to be seen first.</p>
<p>Hopefully, you can see how tools like Pandas and PRAW allow us to collect data and visualize it.</p>

      </div></div>]]>
            </description>
            <link>https://sshawarma.github.io/posts/2020/09/plotting-reddit-comment-trends-with-pandas/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24428149</guid>
            <pubDate>Thu, 10 Sep 2020 01:59:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Signs Your Team Is Suffering from 'Burnout Debt']]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24427973">thread link</a>) | @doorknobguy
<br/>
September 9, 2020 | https://www.usehaystack.io/blog/3-signs-your-team-is-suffering-from-burnout-debt | <a href="https://web.archive.org/web/*/https://www.usehaystack.io/blog/3-signs-your-team-is-suffering-from-burnout-debt">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-w-id="0ea0c8ae-8333-a516-8908-f86a85ef9373"><blockquote>One of my key goals this month is to make sure we're not burning ourselves out. We've got a lot of priorities but there's no need to stretch ourselves thin and run the risk of longer-term issues.<p>- Jean Vincent (CTO, Lytehouse)</p></blockquote><p>‍</p><p>Unhealthy working patterns can build up over time and create longer-term issues. </p><p>In this article, we'll be showing you signs of burnout debt - and how to recognize it before it's too late.</p><p>‍</p><h3>What is 'Burnout Debt'</h3><p>Symptoms of burnout can slowly grow on a team. As sprints go on it's easy to overlook the signs that build up over time. We refer to this build up as 'burnout debt'.</p><p>You should treat burnout debt in the same way we treat technical debt. Identify it early and take measures to reduce longer-term negative effects.</p><p>‍</p><h3>Signs of 'Burnout Debt'</h3><ol role="list"><li>Unhealthy Working Patterns</li><li>High Workloads</li><li>Spikes in Weekend Activity</li></ol><p>‍</p><h3>Sign #1: &nbsp;Unhealthy Working Patterns</h3><p>One key factor in burnout is overwork. It's important we help our teams manage their workloads and reduce burnout. If your team feels the need to work late nights and weekends - it's time to have a conversation about workloads.</p><p>This team for example consistently works late nights and weekends. This is a strong signal that your team is overworking and may approach burnout. We'll see the effect of this below.</p><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f593cd3ba2ac780cf72cc15_unsustainable-working-patterns.png" loading="lazy" alt=""></p></figure><p>‍</p><h3>Sign #2: Unusually High Workloads</h3><p>Spikes in workload can be early warning signs of burnout.</p><p>The team below was under tight deadlines - working nights and weekends. You can a large spike in Throughput followed by immediate burnout which lasted ~3 months.</p><p>This is a typical situation. We take on too much work and burn out. The following weeks remain unproductive. As leaders it's our job to make sure our teams have a more sustainable, manageable workload.</p><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f593cecff346bf77d54af02_unusually-high-workload.png" loading="lazy" alt=""></p></figure><p>‍</p><h3>Sign #3: Spikes in Weekend Activity</h3><p>Large spikes in weekend activity can be an incredibly high signal for overworked. Are your current tasks too much to handle in a week? Did we poorly estimate that workload? Is the workload unmanageable?</p><p>As engineering leaders we have to protect our team from situations like that which can cause long term effects to team morale, culture, and overall productivity. As we saw in the image above, the effects of burnout can be long lasting and in some cases can lead to the highest cost for an engineering team - turnover.</p><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f593d086702304230624666_high-weekend-activity.png" loading="lazy" alt=""></p></figure><p>‍</p><h3>Is your team accumulating 'burnout debt'?</h3><p>Just like technical debt, burnout debt silently builds up in the background. As it accumulates it not only gets harder to resolve but it's impact becomes more severe.</p><p>When left unchecked 'burnout debt' impacts team culture, creates an environment of overwork, and degrades trust among the team. At an individual level it decreases satisfaction, happiness, and productivity while boiling up to team-wide frustration, low morale, and high turnover.</p><p>So.. Is your team affected by burnout debt?</p><p>‍</p><h3>What should I do about it?</h3><p>It’s important to identify these signs early so you can intervene. Luckily, there are ways to identify and resolve burnout debt.</p><p>‍</p><h5>Make it a ritual</h5><p>The first step is having conversations around workload and sustainability. Make it a recurring ritual. At Haystack we bring this up every week. We're constantly adjusting workloads and introducing new, challenging work - to combat burnout.</p><p>‍</p><h5>Get data-driven</h5><p>As engineers, we often feel productive (and happy) when we're pushing new features. There's a certain rush to grabbing a coffee, throwing on some headphones, and getting that #todo closed out - even if it takes staying up late to do it.</p><p>Unfortunately, this makes it difficult to see or address burnout debt. In the moment, we feel great about the work we did - unknowingly allowing burnout debt to build over time. What feels great now build up in the background and soon enough you'll start feeling burnt out.</p><p>In this case, having data helps quite a bit. Being able to see trends and alert on them helps us catch burnout debt before it's too late. It also gives us a more objective picture on what our typical workload looks like so we can make sure to keep it in check.</p><p>‍</p><h3>Stop taking on 'Burnout Debt'</h3><p>If you're managing a team and you want them to be motivated, happy, and productive then burnout should be a key item to address. Just like technical debt, burnout debt can eat at teams and cause an undertone of frustration. It's not always easy to catch but if you're looking in the right direction you'll be able to spot the signs and address it before it's too late.</p><p>Of course, Haystack can help too. If you'd like to see your team's typical bandwidth, working patterns or if they are experiencing signs of burnout debt <a href="https://usehaystack.io/">sign up for Haystack</a>.</p><p>‍</p><p>‍</p><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f5123c19bb423a1492c778d_Haystack_Designed_Presentation.png" loading="lazy" alt=""></p></figure><p><a href="https://usehaystack.io/?utm_source=blog&amp;utm_medium=subscription-sequence&amp;utm_campaign=3-ways-to-identify-blockers">Haystack</a> helps engineering leaders identify burnout and team health patterns. Instead of guessing if you're improving, or constantly bothering your team for updates, simply use Haystack to get alerts in your inbox every morning. Plus a dashboard to track improvements over time.</p><p><a href="https://usehaystack.io/?utm_source=blog&amp;utm_medium=subscription-sequence&amp;utm_campaign=3-ways-to-identify-blockers">Try it for free</a></p><p>‍</p></div></div>]]>
            </description>
            <link>https://www.usehaystack.io/blog/3-signs-your-team-is-suffering-from-burnout-debt</link>
            <guid isPermaLink="false">hacker-news-small-sites-24427973</guid>
            <pubDate>Thu, 10 Sep 2020 01:30:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Obverse and Under (2019)]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24427663">thread link</a>) | @lelf
<br/>
September 9, 2020 | http://www.petecorey.com/blog/2019/09/13/obverse-and-under/ | <a href="https://web.archive.org/web/*/http://www.petecorey.com/blog/2019/09/13/obverse-and-under/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

    

    <article>
        <p>I previously wrote about <a href="http://www.petecorey.com/blog/2019/08/26/prime-parallelograms/">plotting an “amazing graph”</a> using <a href="https://www.jsoftware.com/">the J programming language</a>. The solution I landed on looked something like this:</p>

<pre><code>
require 'plot'
f =: ] - [: #. [: |. #:
'type dot' plot f"0 p: i. 10000
</code></pre>

<p>Our verb, <code>f</code>, is taking a very explicit approach by making judicious use of “capped” (<a href="https://www.jsoftware.com/help/dictionary/d502.htm"><code>[:</code></a>) verb trains. We’re essentially saying that <code>f</code> is (<a href="https://www.jsoftware.com/help/dictionary/d001.htm"><code>=:</code></a>) the given number (<a href="https://www.jsoftware.com/help/dictionary/d500.htm"><code>]</code></a>) minus (<a href="https://www.jsoftware.com/help/dictionary/d120.htm"><code>-</code></a>) the base two (<a href="https://www.jsoftware.com/help/dictionary/d401.htm"><code>#.</code></a>) of the reverse (<a href="https://www.jsoftware.com/help/dictionary/d231.htm"><code>|.</code></a>) of the antibase two (<a href="https://www.jsoftware.com/help/dictionary/d402.htm"><code>#:</code></a>) of the given number.</p>

<p>Several members of the J community pointed out to me that this verb could be simplified with the help of the “under” (<a href="https://www.jsoftware.com/help/dictionary/d631.htm"><code>&amp;.</code></a>) conjunction. Let’s dig into what “under” is, and how we can use it.</p>

<h2 id="under-what">Under What?</h2>

<p>The best way to think about “under” (<a href="https://www.jsoftware.com/help/dictionary/d631.htm"><code>&amp;.</code></a>), <a href="https://code.jsoftware.com/wiki/Vocabulary/ampdot">as explained by the NuVoc page on “under”</a>, is to think in terms of <a href="https://en.wikipedia.org/wiki/Domain_of_a_function">domains</a> and transformations in and out of those domains.</p>

<blockquote>
  <p>Verb v defines a transformation of the argument(s) (x and) y into the v-domain.
Next, verb u operates on the transformed argument(s).
Lastly the result is transformed back from the v-domain to the original domain.</p>
</blockquote>

<p>In our example, the domain of our input is base ten, but the transformation we want to apply (reversal) needs to happen in the base two domain. “Under” (<a href="https://www.jsoftware.com/help/dictionary/d631.htm"><code>&amp;.</code></a>) can be used to transform our input into base two (<a href="https://www.jsoftware.com/help/dictionary/d402.htm"><code>#:</code></a>), apply our reversal (<a href="https://www.jsoftware.com/help/dictionary/d231.htm"><code>|.</code></a>), and transform the result of that reversal back to our original base ten domain with the obverse, or opposite, of our base two verb, anti base (<a href="https://www.jsoftware.com/help/dictionary/d401.htm"><code>#.</code></a>):</p>

<pre><code>
f =: ] - |. &amp;. #:
</code></pre>

<p>Notice that we’re not explicitly stating how to transform the result of our reversal back into our original domain. J knows that the obverse of <a href="https://www.jsoftware.com/help/dictionary/d402.htm"><code>#:</code></a> is <a href="https://www.jsoftware.com/help/dictionary/d401.htm"><code>#.</code></a>, and automatically applies it for us.</p>

<p>Out of the box, J comes with many obverse pairings. “Open” (<a href="https://www.jsoftware.com/help/dictionary/d020.htm"><code>&gt;</code></a>), for example, is the obverse of “box” (<a href="https://www.jsoftware.com/help/dictionary/d010.htm"><code>&lt;</code></a>), and visa versa. This pairing is especially useful when applying transformations to boxed values:</p>

<pre><code>
   1+&amp;.&gt;1;2;3
┌─┬─┬─┐
│2│3│4│
└─┴─┴─┘
</code></pre>

<p>Check out a full listing of obverse pairs <a href="https://code.jsoftware.com/wiki/Fifty_Shades_of_J/Chapter_12#Obverse_to_Adverse">at the end of this Shades of J article</a>.</p>

<h2 id="inferred-obverses">Inferred Obverses</h2>

<p>Even compound verbs built up of verbs with well-defined obverse pairings can be used with “under” (<a href="https://www.jsoftware.com/help/dictionary/d631.htm"><code>&amp;.</code></a>). J will correctly infer and apply the compound obverse without any intervention or instruction.</p>

<p>For example, if we wanted to unbox a list of values and then work with them in the “square root domain” (whatever that means), we could do something like this:</p>

<pre><code>
   1+&amp;.([:%:&gt;)1;2;3
┌────────────────┐
│4 5.82843 7.4641│
└────────────────┘
</code></pre>

<p>J takes each value, opens it and finds its square root (<code>[:%:&gt;</code>), adds one to the result, and then squares and boxes up (<code>[:*:&lt;</code>) the incremented value.</p>

<h2 id="explicit-obverses">Explicit Obverses</h2>

<p>Even more interestingly, if an obverse pairing isn’t defined or inferable for a given verb, J lets us define our own pairing using the “obverse” (<a href="https://www.jsoftware.com/help/dictionary/d311.htm"><code>:.</code></a>) verb.</p>

<p>As an example, imagine that we have a JSON string holding an array of values. We want to parse our string, perform some operation on those values, and then serialize the resulting list back into JSON.</p>

<p>We can use the <code>dec_json</code> and <code>enc_json</code> verbs provided by <a href="https://github.com/jsoftware/convert_json">the <code>convert/json</code> package</a>, and tell J that the obverse of <code>dec_json</code> is <code>enc_json</code>:</p>

<pre><code>
   json =: dec_json :. enc_json
</code></pre>

<p>Running <code>dec_json</code> on a JSON array like <code>'[1, 2, 3]'</code> will return a list of boxed numbers, so we’ll want to open each of these boxes, perform our operation, and box the results back up. This sounds like another job for “under” (<a href="https://www.jsoftware.com/help/dictionary/d631.htm"><code>&amp;.</code></a>):</p>

<pre><code>
   transform =: 1&amp;+&amp;.&gt;
</code></pre>

<p>All together, we can perform our <code>transform</code> “under” (<a href="https://www.jsoftware.com/help/dictionary/d631.htm"><code>&amp;.</code></a>) the <code>json</code> domain:</p>

<pre><code>
   transform &amp;. json '[1, 2, 3]'
[2,3,4]
</code></pre>

<p>And our result is the JSON string <code>'[2,3,4]'</code>!</p>

<p>“Under” is definitely a very powerful conjunction, and I can see myself using it extensively in the future. Thanks to everyone in the J community who was kind enough to point it out and teach me something new!</p>

    </article>
  </div></div>]]>
            </description>
            <link>http://www.petecorey.com/blog/2019/09/13/obverse-and-under/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24427663</guid>
            <pubDate>Thu, 10 Sep 2020 00:36:47 GMT</pubDate>
        </item>
    </channel>
</rss>
