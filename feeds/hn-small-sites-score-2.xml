<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Tue, 29 Dec 2020 08:46:10 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Tue, 29 Dec 2020 08:46:10 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Rust in a KDE Project]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25549727">thread link</a>) | @lukastyrychtr
<br/>
December 27, 2020 | https://jbbgameich.github.io/misc/2020/12/21/rust-in-a-kde-project.html | <a href="https://web.archive.org/web/*/https://jbbgameich.github.io/misc/2020/12/21/rust-in-a-kde-project.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<p>While trying to implement a long planned feature, an ad block in Angelfish, the Plasma Mobile webbrowser,
I was looking for a mostly complete and performant library that provides this functionality.</p>

<p>First I found libadblockplus, which is a C++ library providing the AdblockPlus core functionality.
Sounds great, right? Well, not quite. It includes it’s own v8 java script engine,
and since we are talking about a webbrowser with a QML interface here,
including a third java script engine and a second copy of v8 was absolutely not an option.
Even if this wasn’t a webbrowser,
running a java script engine as implementation detail of a library is at least … problematic.</p>

<p>The other option I found is <a href="https://github.com/brave/adblock-rust">adblock-rust</a>,
which is the built-in ad block of the Brave browser. As the name tells, it is written in Rust,
and I was originally looking for a C++ library. But it turned out this was not much of a problem,
since Rust features excellent C interoperability, just like C++.
Based on this common ground, bindings can be created to use Rust code from C++ (and the other way around if needed).</p>

<h2 id="approach-1">Approach 1</h2>
<p>My first approach was to use raw ffi. That means essentially building a C API featuring the typical C primitive types in rust,
and telling the rust compiler to represent structs in memory the same way that C would do.
Thanks to cbindgen, which automatically generates a header file with the information for the C compiler to know which fields a struct has and were they are,
we directly get something we can include in our C++ project.</p>

<p>The rust build system cargo is capable of running custom code at build time, and we can use that to run cbindgen on our rust code, by adding a file named <code>build.rs</code>:</p>
<pre><code>extern crate cbindgen;

use std::env;

fn main() {
    let crate_dir = env::var("CARGO_MANIFEST_DIR").unwrap();

    cbindgen::generate(&amp;crate_dir)
        .unwrap()
        .write_to_file("bindings.h");
}
</code></pre>

<p>Our core data structure for the ad block looks like this:</p>
<pre><code>#[repr(C)]
pub struct Adblock {
    blocker: *mut Engine,
}
</code></pre>
<p>It stores a pointer to the rust Engine type in a C compatible struct.
The struct can not be created directly from C / C++, since we don’t know anything about the Engine type there.</p>

<p>So we need a function on the rust side that creates and initializes the Engine for us and packs it into an <code>Adblock</code> struct.
Since the code in angelfish is doing a bit more than only that, the function takes two C string arguments, and returns a pointer to a mutable (non-const) Adblock object.</p>
<pre><code>#[no_mangle]
pub extern "C" fn new_adblock(
    list_dir: *const c_char,
    public_domain_suffix_file: *const c_char,
) -&gt; *mut Adblock
</code></pre>
<p>A few more thigs in this function signature are unusual, but they are all related to the FFI / C compatibility we need here:</p>
<ul>
  <li><code>#[no_mangle]</code> tells the rust compiler not to apply its rust specific function name mangling</li>
  <li><code>extern "C"</code> tells that this function should use the C calling conventions.</li>
</ul>

<p>Every time we interact with data from C, the rust compiler is unable to run its usual safety checks.
For that reason we need unsafe blocks around those lines of code.
If anything unexpectedly segfaults, it’s likely to be in our unsafe blocks.
To get a string that we can feed into a usual rust API, we can use <code>unsafe { CStr::from_ptr(public_domain_suffix_file).to_str() }</code>.</p>

<p>For more examples of how to interact with the C / C++ side, feel free to have a look at <a href="https://invent.kde.org/plasma-mobile/plasma-angelfish/-/blob/20e166c0fe2e38be63824b957c02fa58865ac67c/src/rs/adblock/src/adblock.rs">some real code in Angelfish</a>.
I’m by no means an expert on this, but it should help you get started.</p>

<p>Using this approach, the ad block could successfully be implemented in about 140 lines of rust code, of which only half is FFI code, and the rest actual logic.</p>

<h2 id="approach-2">Approach 2</h2>
<p>The second approach is to use the cxx crate (library), which can generate most of the boilerplate FFI code automatically, and provides a modern API on the C++ side.
To do that, it implements its own wrapper types, each wrapping the functionality of one type of one of the languages. Those wrapper types are implemented in both languages, and allow easily passing more advanced types than pointers and number types through the FFI boundary.
On the rust side, the wrapper types are not really visible, because a macro generates everything for us.</p>

<p>The only unusual thing on the rust side will be a small ffi module, declaring which types and functions we want to expose to C++:</p>
<pre><code>#[cxx::bridge]
mod ffi {
    extern "Rust" {
        type Adblock;
        type AdblockResult;

        fn new_adblock(list_dir: &amp;str, suffix_file: &amp;str) -&gt; Box&lt;Adblock&gt;;
        fn should_block(
            self: &amp;Adblock,
            url: &amp;str,
            source_url: &amp;str,
            request_type: &amp;str,
        ) -&gt; Box&lt;AdblockResult&gt;;
    }
}
</code></pre>

<p>All objects are returned as smart pointers, like <code>Box</code>.
On the C++ side, this will result in a <code>rust::Box&lt;Adblock&gt;</code>, which is a type generated by the cxx_build crate, which is doing something slightly similar to cbindgen.</p>

<p>With the cxx crate, our build.rs will look like this:</p>
<pre><code>extern crate cxx_build;

fn main() {
    cxx_build::bridge("src/adblock.rs").compile("angelfish-adblock")
}
</code></pre>

<p>You may wonder, if the cxx crate makes everything so easy, why did I start with approach 1 at all?
I had had a look at the cxx crate a few month ago, when it was still too minimal to do what I needed. Luckily I had another look, since it has become really useful in the meantime.
However learning the raw ffi way was important to understand what actually happens in the background, and I’d almost recommend everyone to have a look at that first before using the cxx crate. Using <code>cargo expand</code> you can then understand what cxx generated for you.</p>

<p>Given the cxx crate makes this so much easier, I initially feared it might add tons of new dependencies and increase the build time, but to my surprise it actually has a lot less dependencies than cbindgen. Even though cbindgen only uses those at build time (they don’t end up in the binary), they take some time to build.</p>

<p>Angelfish has recently switched to using the cxx crate, so you find usage examples in the <a href="https://invent.kde.org/plasma-mobile/plasma-angelfish/-/blob/d92e48e392303deda6cf3c1552f9f7b5189e2953/src/rs/adblock/src/adblock.rs">current version of the ad block code</a>.</p>

<h2 id="build-system">Build system</h2>
<p>After we have written the FFI, we need to build the Rust code as part of our project, most likely using CMake. This could be very annoying and complicated, but luckily <a href="https://github.com/AndrewGaspar/corrosion">Corrosion</a> exists to make this very easy for us.
It can build our rust code using the cargo build system, and create CMake targets for the library we built, so its easy to link against it.</p>

<h2 id="usage-in-kde">Usage in KDE</h2>
<p>Now that the implementation part is explained,
it makes sense to look into where this can be useful and where not.
Unfortunately the truth is that some distros are still not fully happy with having to package rust code,
because the rust community has a different approach to sharing code than known from the C / C++ world.
While Qt re-implements some functionality also found in other C++ libraries, to only make it necessary to package Qt and not one library for json, one for xml, for http and so on, the rust community likes to split everything into small packages, so no unnecessary code is included.</p>

<p>In Angelfish, all the rust code is optional, and Angelfish can of course still be built without Rust.</p>

<p>Possible areas in KDE that could profit from using Rust are icon and SVG theme rendering code, which could profit from using rsvg or resvg.
I can imagine it could also be useful for document thumbnailers, when a rust implementation of the file type already exists. A similar case could be KIO workers, and pretty much any other project that can profit from optional plugins.</p>

<h2 id="conclusion">Conclusion</h2>
<p>This approach to using Rust in KDE allows to make use of the many libraries and language features the ecosystem provides, without running into the infamous “rewrite it in Rust” reflex. It avoids having to create rust bindings for all KDE Frameworks and Qt only to make use of Rust, and still produces readable code.</p>



	</div><p>The comment feature is still experimental! Comments may be deleted at any time.</p></div>]]>
            </description>
            <link>https://jbbgameich.github.io/misc/2020/12/21/rust-in-a-kde-project.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25549727</guid>
            <pubDate>Sun, 27 Dec 2020 08:34:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using GNU Stow to manage your dotfiles (2012)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25549462">thread link</a>) | @matthberg
<br/>
December 26, 2020 | http://brandon.invergo.net/news/2012-05-26-using-gnu-stow-to-manage-your-dotfiles.html | <a href="https://web.archive.org/web/*/http://brandon.invergo.net/news/2012-05-26-using-gnu-stow-to-manage-your-dotfiles.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
	   

<p>I accidentally stumbled upon something yesterday that I felt like
sharing, which fell squarely into the "why the hell didn’t I know about this
before?" category. In this post, I’ll describe how to manage
the various configuration files in your GNU/Linux home directory (aka
"dotfiles" like <code>.bashrc</code>) using GNU Stow.</p>

<p>The difficulty is that it would be helpful to manage one’s
configuration files with a version control system like Git, Mercurial
or Bazaar, but many/most dotfiles reside at the top-level of your home
directory, where it wouldn’t be a good idea to initialize a VCS
repository. Over time I’ve come across various programs which aim to
manage this for you by keeping all the files in a subdirectory and
then installing or linking them into their appropriate places. None of
those programs ever really appealed to me.  They would require a ton
of dependencies (like Ruby and a ton of libraries for it) or they
would require me to remember how to use them, which is difficult when
really for such a task you rarely use the program.</p>

<p>Lately I’ve been using <a href="http://www.gnu.org/software/stow">GNU Stow</a> to manage
programs I install from source to <code>/usr/local/</code>. Basically, in this typical
usage, you install locally built packages to
<code>/usr/local/stow/${PKGNAME}-{PKGVERSION}</code> and then from <code>/usr/local/stow/</code> you run
<code># stow ${PKGNAME}-${PKGVERSION}</code> and the program generates symbolic links to
all the programs' files into the appropriate places under <code>/usr/local/</code>. Then,
when you uninstall a program via Stow, you don’t have to worry about any stray
files that you or a provide Makefile may have missed. It also makes handling
alternate versions of a program quite easy (i.e. when I’m experimenting with
different configurations of <a href="http://dwm.suckless.org/">dwm</a> or
<a href="http://st.suckless.org/">st</a>).</p>

<p>Some time ago I happened across a mailing list posting where someone described
using Stow to manage the installation of their dotfiles. I didn’t pay much
attention to it but my brain must have filed it away for later. Yesterday I
decided to give it a try and I have to say that it is so much more convenient
than those other dedicated dotfile-management programs, even if it wasn’t an
immediately obvious option.</p>

<p>The procedure is simple. I created the <code>${HOME}/dotfiles</code> directory and then
inside it I made subdirectories for all the programs whose cofigurations I
wanted to manage. Inside each of those directories, I moved in all the
appropriate files, maintaining the directory structure of my home directory. So,
if a file normally resides at the top level of your home directory, it would go
into the top level of the program’s subdirectory. If a file normally goes in the
default <code>${XDG_CONFIG_HOME}/${PKGNAME}</code> location (<code>${HOME}/.config/${PKGNAME}</code>),
then it would instead go in <code>${HOME}/dotfiles/${PKGNAME}/.config/${PKGNAME}</code> and
so on. Finally, from the <code>dotfiles</code> directory, you just run <code>$ stow $PKGNAME</code>
and Stow will symlink all the package’s configuration files to the appropriate
locations. It’s then easy to make the <code>dotfiles</code> a VCS repository so you can
keep track of changes you make (plus it makes it so much easier to share
configurations between different computers, which was my main reason to do it).</p>

<p>For example, let’s say you want to manage the configuration for Bash, VIM and
Uzbl. Bash has a couple files in the top-level directory; VIM typically has your
.vimrc file on the top-level and a .vim directory; and Uzbl has files in
<code>${XDG_CONFIG_HOME}/uzbl</code> and <code>${XDG_DATA_HOME}/uzbl</code>. So, your home directory
looks like this:</p>

<pre><code>home/
    brandon/
        .config/
            uzbl/
                [...some files]
        .local/
            share/
                uzbl/
                    [...some files]
        .vim/
            [...some files]
        .bashrc
        .bash_profile
        .bash_logout
        .vimrc
</code></pre>

<p>You would then create a <code>dotfiles</code> subdirectory and move all the files there:</p>

<pre><code>home/
    /brandon/
        .config/
        .local/
            .share/
        dotfiles/
            bash/
                .bashrc
                .bash_profile
                .bash_logout
            uzbl/
                .config/
                    uzbl/
                        [...some files]
                .local/
                    share/
                        uzbl/
                            [...some files]
            vim/
                .vim/
                    [...some files]
                .vimrc
</code></pre>

<p>Then, perform the following commands:</p>

<pre><code>$ cd ~/dotfiles
$ stow bash
$ stow uzbl
$ stow vim
</code></pre>

<p>And, voila, all your config files (well, symbolic links to them) are
all in the correct place, however disorganized that might be, while
the actual files are all neatly organized in your <code>dotfiles</code>
directory, which is easily turned into a VCS repo. One handy thing is
that if you use multiple computers, which may not have the same
software installed on them, you can pick and choose which
configurations to install when you need them. All of your dotfiles are
always available in your <code>dotfiles</code> directory, but if you don’t need
the configuration for one program, you simply don’t Stow it and thus
it does not clutter your home directory.</p>

<p>Well, that’s all there is to it. Hopefully someone else out there
finds this useful! I know I’ve found it to be a huge help.</p>

<p><a rel="license" href="http://creativecommons.org/licenses/by-sa/3.0/deed.en_US"><img alt="Creative Commons License" src="http://i.creativecommons.org/l/by-sa/3.0/88x31.png"></a><br><span xmlns:dct="http://purl.org/dc/terms/" property="dct:title">Using GNU Stow to Manage Your Dotfiles</span> by <a xmlns:cc="http://creativecommons.org/ns#" href="http://brandon.invergo.net/" property="cc:attributionName" rel="cc:attributionURL">Brandon Invergo</a> is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/3.0/deed.en_US">Creative Commons Attribution-ShareAlike 3.0 Unported License</a>.</p>


             
	   </article></div>]]>
            </description>
            <link>http://brandon.invergo.net/news/2012-05-26-using-gnu-stow-to-manage-your-dotfiles.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25549462</guid>
            <pubDate>Sun, 27 Dec 2020 07:19:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Not Being Bullish Enough on Bitcoin Is a Mistake]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25549230">thread link</a>) | @alwillis
<br/>
December 26, 2020 | https://www.ministryofnodes.com.au/2020/12/19/not-being-bullish-enough-on-bitcoin-is-a-mistake/ | <a href="https://web.archive.org/web/*/https://www.ministryofnodes.com.au/2020/12/19/not-being-bullish-enough-on-bitcoin-is-a-mistake/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<figure><img loading="lazy" width="1024" height="731" src="https://www.ministryofnodes.com.au/wp-content/uploads/2020/12/Not-being-bullish-enough-1024x731.png" alt="" srcset="https://www.ministryofnodes.com.au/wp-content/uploads/2020/12/Not-being-bullish-enough-1024x731.png 1024w, https://www.ministryofnodes.com.au/wp-content/uploads/2020/12/Not-being-bullish-enough-300x214.png 300w, https://www.ministryofnodes.com.au/wp-content/uploads/2020/12/Not-being-bullish-enough-768x548.png 768w, https://www.ministryofnodes.com.au/wp-content/uploads/2020/12/Not-being-bullish-enough-1536x1097.png 1536w, https://www.ministryofnodes.com.au/wp-content/uploads/2020/12/Not-being-bullish-enough-1200x857.png 1200w, https://www.ministryofnodes.com.au/wp-content/uploads/2020/12/Not-being-bullish-enough-1980x1414.png 1980w, https://www.ministryofnodes.com.au/wp-content/uploads/2020/12/Not-being-bullish-enough-600x428.png 600w, https://www.ministryofnodes.com.au/wp-content/uploads/2020/12/Not-being-bullish-enough.png 2000w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>Not Being Bullish Enough on Bitcoin is a big mistake. Why? You’ll sell too early, and not grasp Bitcoin well enough to get the big picture here. You might not secure the coins well enough, and you might not actually realise the societal implications of Bitcoin. </p>



<h2>Not Being Bullish Enough On Bitcoin Means Selling too early</h2>



<p>Fundamentally, a lot of people did not truly peer into <a href="http://stephanlivera.com/185">what Bitcoin is</a>, and this made them not bullish enough. This is a big error, as it pushes them to sell bitcoin too early. While they think they’re being clever timing a top, Bitcoin proceeds to humble them a few years later after another cycle. </p>



<p>Lopp has a great example here: </p>



<figure></figure>



<p>At time of writing in Dec 2020, Bitcoin is now around $23,000 USD. Selling early is penny wise, pound foolish. </p>



<p>Many people wish they had bought bitcoin earlier, but truth be told: that’s only half the challenge. The other half is actually HODLing it through the long term and not selling it out. </p>



<p>As bitcoin old-timers in the space will tell you, you could have bought early… but then you probably would have also sold early. It takes understanding and conviction.</p>



<h2>Not Being Bullish Enough On Bitcoin Means Not Securing it Correctly</h2>



<p>It’s a wild roller-coaster. Bitcoin can 10x in the space of a few months, and you can be left <em>very</em> exposed if you’re not careful. A $10k bitcoin stack can quickly become $100k, a $100k stack can quickly become $1M and so on. </p>



<p>Consider the worth of your stack currently, and think about if Bitcoin were to 10x or 20x over a few months or a year. Would you be comfortable with the level of security you have? </p>



<p>If you aren’t bullish enough, and you’re only looking for a 2x and then flip for fiat profits, you aren’t thinking big enough. You should be looking to learn about bitcoin security by listening to SLP such as <a href="http://stephanlivera.com/97">SLP97</a> and <a href="http://stephanlivera.com/215">SLP215</a> with Michael Flaxman. You should be looking at ways to: </p>



<ul><li>Ensure appropriate entropy in your bitcoin seed generation </li><li>Minimise single points of failure</li><li>Consider multi signature</li><li>In the ideal case, use open source hardware and software that has been vetted from a security perspective</li><li>Learn about how to verify signatures for software you use</li><li>Learn hardware wallet best practices</li></ul>



<h2>Not learning enough about how to use Bitcoin the right way</h2>



<p>When we talk about using Bitcoin, we mean using it in a self sovereign way. You shouldn’t be in a situation where you are exclusively trusting or relying on your service provider to give you your bitcoins. </p>



<p>This is not stocks or dollars in your bank account. This is Bitcoin. Use it the self sovereign way. </p>



<p>In practice this means: </p>



<ul><li>Don’t leave your coins in custodial accounts. Use sovereign bitcoin wallets where you hold the private keys. Or at least, a quorum of private keys (e.g. you hold 2 of 3 keys, or 4 of 5 keys). </li><li>Ideally, perform your own validation by running your own underlying bitcoin node. This is easy with <a href="https://www.ministryofnodes.com.au/2020/09/28/cost-effective-bitcoin-use-hardware-wallet-own-node/">Specter Desktop + Bitcoin Core</a>, or with <a href="https://www.ministryofnodes.com.au/2020/03/26/mynode-video-tutorials/">myNode</a>, or other projects e.g. Umbrel, <a href="http://raspiblitz.com/">RaspiBlitz</a>, <a href="http://ronindojo.io/">Ronin Dojo</a>, <a href="http://btcpayserver.org/">BTCPay Server</a>, <a href="http://nodl.it/">nodl</a> etc. </li></ul>



<h2>Not realising the societal implications of Bitcoin</h2>



<p>Fiat money has cultural consequences that many simply do not understand right now. It’s like we’re fish swimming in the water without realising what we’re swimming in. We’ve grown up in an environment of cheap debt, facing incentives to go into debt or lose. </p>



<p>This drives all kinds of changes in our society that weren’t so obvious pre-1971. Increased welfare statism, increased debt, higher time preference, increased centralisation into managerial superstates, to name a few. </p>



<p>As Bitcoin becomes more widely adopted, society’s return to hard money will drive significant cultural shifts that align with the return to hard money. Listen to <a href="http://stephanlivera.com/51">SLP51 with Guido Hulsmann</a> to know more.</p>



<h2>Conclusion</h2>



<p>Fundamentally, it takes knowledge, conviction, and dedication to do this. There are many pitfalls along the way, and it takes work from the HODLer to methodically and skilfully avoid these pitfalls. Of course, we can lament the difficulty and push it off til the future when it’ll be easier. But that is also giving up the huge return potential, and also the freedom and moral imperative of bringing about a Bitcoin Standard. </p>



<p>Do your research and learning, be methodical in your approach, and you’ll be in with a good shot. </p>



<h2>Help With Being Bullish Enough</h2>



<p>See our <a href="https://www.ministryofnodes.com.au/store/">web store</a> for guides and products. For many readers of this blog, you’d probably benefit from using Coldcard + Specter Desktop + Bitcoin Core, for which we offer an in depth video guide <a href="https://www.ministryofnodes.com.au/product/bitcoin-starter-guide-how-to-hold-intermediate/">here</a>. </p>



<p>Or otherwise, if you’re not sure where to start, or want other assistance, we offer zoom call consulting <a href="https://www.ministryofnodes.com.au/consulting/">here</a>. Zoom consults are offered on a ‘pay what you think it was worth’ basis. Book a call, then <a href="https://www.ministryofnodes.com.au/support/">pay us here afterwards</a>.</p>

		</div><!-- .entry-content -->

	</div></div>]]>
            </description>
            <link>https://www.ministryofnodes.com.au/2020/12/19/not-being-bullish-enough-on-bitcoin-is-a-mistake/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25549230</guid>
            <pubDate>Sun, 27 Dec 2020 06:07:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DiamonDie's ASCII Art Tutorial]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25549054">thread link</a>) | @thedookmaster
<br/>
December 26, 2020 | https://www.ludd.ltu.se/~vk/q/asciitutorials/Maija_Haavisto.html#:~:text=ASCII%20art%20is%20always%20done,programs%20for%20making%20ASCII%20art. | <a href="https://web.archive.org/web/*/https://www.ludd.ltu.se/~vk/q/asciitutorials/Maija_Haavisto.html#:~:text=ASCII%20art%20is%20always%20done,programs%20for%20making%20ASCII%20art.">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><i>This tutorial is written by Maija Haavisto (<a href="http://www.angelfire.com/mn/Maija/asciiart.html">old homepage</a>, and <a href="http://diamondie.deviantart.com/">another homepage</a>)</i></p>
<hr>




<h2>Table of contents</h2>
<p>
1 Introduction<br>
2 Types of ASCII art<br>
&nbsp; 2.1 Lineart<br>

&nbsp; 2.2 Solid<br>
&nbsp; 2.3 Grayscale<br>
&nbsp; 2.4 Camelized<br>
&nbsp; 2.5 Others<br>
3 Drawing ASCII art<br>
&nbsp; 3.1 Starting out<br>

&nbsp; 3.2 Lineart<br>
&nbsp; 3.3 Solid art<br>
&nbsp; 3.4 Grayscale<br>
&nbsp; 3.5 Antialiasing<br>
&nbsp; 3.6 Tracing<br>
&nbsp; 3.7 Aspect ratio<br>

&nbsp; 3.8 Difficulties and limitations<br>
&nbsp; 3.9 Perspective, 3D and isometric ASCII<br>
&nbsp; 3.10 Textures and materials<br>
&nbsp; 3.11 Lighting and shadow<br>
&nbsp; 3.12 Uses for different characters<br>
4 Fixed-width fonts<br>

&nbsp;&nbsp;&nbsp; 4.1 Courier New<br>
&nbsp;&nbsp;&nbsp; 4.2 DOS font<br>
&nbsp;&nbsp;&nbsp; 4.3 Topaz New<br>
&nbsp;&nbsp;&nbsp; 4.4 Lucida Console<br>
&nbsp;&nbsp;&nbsp; 4.5 Fixedsys<br>
&nbsp;&nbsp;&nbsp; 4.6 Arial Alternative<br>

&nbsp;&nbsp;&nbsp; 4.7 MS Gothic<br>
&nbsp;&nbsp;&nbsp; 4.8 Andale Mono (aka Monotype.com)<br>
5 ASCII art software<br>
&nbsp;&nbsp; 5.1 JavE<br>
&nbsp;&nbsp; 5.2 FIGlet<br>
&nbsp;&nbsp; 5.3 TheDraw/Aciddraw<br>

&nbsp;&nbsp; 5.4 Acidview<br>
&nbsp;&nbsp; 5.5 PabloDraw<br>
6 Other stuff<br>
&nbsp; 6.1 ASCII map<br>
&nbsp; 6.2 Displaying ASCII art on web pages<br>
&nbsp; 6.3 Coloring ASCII art<br>

&nbsp; 6.4 Demoscene ASCII art<br>
&nbsp; 6.5 ASCII art culture and etiquette

</p><h2>1 Introduction</h2>

<p>ASCII is an acronym of "American Standard Code for Information
Interchange". ASCII art means art made out of different characters in
the ASCII map and can thus be represented in plain text format. It
cannot include extended characters or text formatting such as bold or
italics. ASCII art is always done on a fixed-width font like Courier
New or Fixedsys, never on a proportional font like Arial or Times New
Roman. It can be made in Notepad or MS-DOS Edit, but there are also
some specific programs for making ASCII art. And no, I'm not talking
about ASCII converters.</p><p>
People often comment on ASCII art by saying "Wow, that is so amazing,
I'd never have the patience to make something like that". I don't get
it. Why do they think ASCII art requires so much patience? I can make a
decent fullscreen ASCII in an hour (even if it sometimes takes ten
hours). It takes me at least fifteen hours to draw a decent fullscreen
CG picture.</p><p>
ASCII art isn't easy and it does require skill, but you don't have to
care about things like brush strokes or colors and usually not about
shading either. In a way it is a lot like pixel art. When I started
pixeling it felt very familiar due to my ASCII and ANSI experience.
Pixel artists will probably experience a similar reaction when they
start drawing ASCII. You don't have to have great drawing skills to be
a good ASCII artist. I, for instance, suck at drawing, I can paint but
I can't do the sketch like thing at all. ASCII sketching is practically
something non-existant, but if this interests you, nothing stops you
from trying this new style.</p><p>
Some people wonder what's the point. What's the point in making art in
general? I think limitations are what makes art interesting and feeds
the creative mind. ASCII art probably isn't something that you
encounter in an art museum (which is regrettable), it's more like
everyday art. I guess it has something in common with pop art. ASCII
art can be sent via email or to Usenet newsgroups, it can be
used on IRC and many chatrooms (do that with caution, though). You can
include ASCII art in your signature or login screen or print it out
with your old matrix printer. It can be used for representing game
situations, graphs or molecular models.</p><p>
I've heard opinions of ASCII art not being art but graphical design,
but I disagree with that. Design is usually considered to be something
functional, such as advertisements or interfaces, while visual art is
something you can hang on your walls. ASCII art usually isn't
functional but aesthetical. I know people who have ASCII pictures
hanging on their walls.</p><p>

There are other ASCII tutorials, but I decided there's still room
for another one. Many of the others are outdated, some are even more
than 10 years old. They also feature slightly different techniques and
lack some of the parts that my tutorial focuses on. This turned out
perhaps more like a ASCII drawing/culture FAQ than an actual tutorial,
but I hope it will still be useful.

</p><h2>2 Types of ASCII art</h2>

<h4>2.1 Lineart</h4>

<div><p>Lineart is just what its name implies, things are represented with
(usually thin) outlines, sometimes dotty, sometimes consisting mostly
of slashes, underscores and pipes. Lineart also includes most FIGlet
fonts and demoscene logos. Suitable for both huge images and tiny
pictures.</p></div><pre>            .-"""-.
           '       \
          |,.  ,-.  |
          |()L( ()| |
          |,'  `".| |
          |.___.',| `
         .j `--"' `  `.
        / '        '   \
       / /          `   `.
      / /            `    .
     / /              l   |
    . ,               |   |
    ,"`.             .|   |
 _.'   ``.          | `..-'l
|       `.`,        |      `.
|         `.    __.j         )
|__        |--""___|      ,-'
   `"--...,+""""   `._,.-' mh

Penguin by DiamonDie (2002?)</pre>

<h4>2.2 Solid</h4>

<div><p>Solid art is the "opposite" of lineart, it's not outlined but filled
and flat-shaded.
It's often best fit on mid-sized and large pictures, though it can also
work for small pieces, such as the heart here. Often it looks better
than lineart, simply for the fact that it's not as "thin". Solid art is
often used for logos, ornament designs and text, but it fits almost any
kind of subject. It's not very well suited for faces though.</p></div><pre>  ,o8o, ,o8o,
,888888,888888,
888888888888888
888888888888888
`8888888888888'
  `888888888'
    `88888'
      `8'

Heart by DiamonDie (1997)</pre>

<h4>2.3 Grayscale</h4>

<div><p>Grayscale is like solid art, but it consists of many different
characters that are used to portrays lighter and darker areas, making
it the most suitable kind of ASCII for picturing faces. It is usually
best viewed white on black, such as the example below (people using
most graphical browsers can select it with a mouse or press Ctrl-A to
see it in inverse color). Most converters create grayscale art, though
rather messy kind with often no antialiasing. Grayscale could be
considered the most difficult of all ASCII techniques.</p></div><pre>                           .,,,yyyy@@yyyyy,,,                                  
                      ,ytS$$CCCCCCCCCCCCCCC?III;,.                             
                   .yt$$$$$$$$CCCCCCCCCCCCCCCCIIIIII;.                         
                 ,4$$$$$$$$$$$$$$SCCCCCCCCCCCCCCC?IIIII;                       
               y$$$$$$$$$$$$$$$$$$$$CCCCCCCCCCCCCCCIIII,                       
             ,$$$$$$$$$$$$$$$$$$$$$$$$CCCCCCCCCCCCCCIIII:                      
            l$$$$$$$$$$$$$$$$$$$$$$$$$$$CCCCCCCCCCCCIIIIi                      
           t$$$$$$$$$$$$$$$$$$$$$$$$$$$$CCCCCCCCCCCCIIII:                      
         .l$$$$$$$$$$$$$$$$$$$$$$$$$$$SCCCCCCCCCCCCCIIII,  i                   
         d$$$$$$$$$$$$$$$$$$$$$$$$$$$SCCCCCCCCCCCCCIIIII. ;I,                  
         $$$$$$$$$$$$$$$$$$$$$$$$$$SSCCCCCCCCCCCCCIIIIIII .III                 
        j$$$$$$$$$$$$$$$$$$$$$$$$$SSCCCCCCCCCCCCCCIIIIIIIi.II;                 
        ]$$$$$$$$$$$$$$$$$$$$P"'   `"^?CCCCCCCCCCIIIIIIIIIIIII                 
        l$$$$$$$$$$$$$$$$P"''    .,..   `;?CCCCCCC?IIIIIIIIII;     .y%*        
        l$$$$$$$$$$$$SP"     ,yS$$$$$$Shy..`"IICCCCCCII:  ::      4C7;  \      
        $$$$$$$$$$$SP.   .;;$$$SCCCCCSSCCCCSb: ICCCCCCCII; ''  liC$ClCC;;l     
        $$$$$$$$$$$$I::lIIIICCSSSSSSCCCCCCCCCCIICCCCCCCI       ICCC$lCC??;b    
        P"^^^48$$$$$$SSIII' `Ii :   y,"ICCCS$SCCCCCCCCCCI      ICl"l "7SSbl.   
       :        l$$8888II66 ,?$b,yySIIICC$$$$$$$$SCCCCCCCI     ?CCb l JCC$il   
       :  .    ,$$$$$$CCCC$$$$$$$$$$$$$$$$$$$$$$$$$CCCCCCI     ICS$li$$SCC?l   
        `SS",+.$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CCCCCCI     !?S$ ;I$$SCCP   
         "' : S$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CCCCCCI      ICSCS$$$$$I    
          ;:6$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$CCCCCCI        `?C$$$$P     
            `$$$$$$$$$$S$$$$$$$$$$$$$$$$$$$$$$$$$$$CCCCCCI         `""""'      
            j$$$$$$$$$SCCS$$$$$$$$$$$$$$$$$$$$$$$$$CCCCCI                      
            $$$$$$$$$$$$$CI$$$$$$$$$$$$$$$$$$$$$$$SCCCCCI;                     
           j$$$$$$$$$$SS$CI$$$$$$$$$$$$$$$$$$$$$$SSCCCCCIi                     
           7$$$$T7"`,yyiIIC$$$$$$$$$$$$$$$$$$$$$SSSSCCCC?i                     
            "4$SC**7"""-:47$$$$$$$$$$$$$$$$$$$$$SSSSCCCCCI                     
              7I       . ,';' ";7ICS$$$$$$$$$C$S$$$$$CCCCl                     
              : jy.,jyyjCCCCi ..i."7C$$$$$$C$CS$S$$$SCCC?'      ;              
             : d$$$$CCC7?"""""?7CiiCS$$$$SCCCC$S$$$$CCCC;       i,             
              .CC,]CCSSSCCSCCCIiIiICS$$$SSCCCCS$$$$SCC?        .|              
              :`j$$$$$$$$SCCCC$$$CICS$$SCCCCCCCC$CC?;          iI.             
               :l$$$$$$$CCCCCS$$$$C?iCCCCCCCCC7"'.,          .iII,             
                :C?"~~    ,CCC$$$IiIiCCCCCCC?   '           ,IIIII             
                 :$7  ,_,jS$$$$CIiIi?iCCC??                iI?CCCII            
                .;  :;i:;;?S???iiIiIi?i'                iII?CCCCCII.           
                ;  ';'    ?lCi??i;i;;                  iI?CCCCCCCCIIi          
               :            ;? ;I"                  iIIICCSCCCCCCCCIIl         
                ;                             .,iiI?CCCC$$$$$SSCCCCCCIi I, II; 
                 '.                 _,.   ,i,IIII?CCCCCS$$$$$$SSSCCCCIIIIIIIII'
                   ' ~  + =- - ' ~ ` SCCIIIIII???CCCCS$$$$$$$$$$$SCCCCCCC?I"   
                                     l$$CCCCCCCCCCCCS$$$$$$$$$$$$$$$$SCCC"`    

It Figures by `nemoorange</pre>

<h4>2.4 Camelized</h4>

<p>Camelized ASCII art isn't very popular, even though it already appeared
in
the book Alice in Wonderland. It is usually poetry (sometimes prose)
made into the shape of an object, often an animal. There are a couple
of different techniques for making the shapes. Some people use extra
spacing to achieve lines of required length, others wrap words from the
middle or use extra characters. JavE has a feature for camelized ASCII.

</p><h4>2.5 Others</h4>

<p>There are variations of the previously listed styles, such as</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.ludd.ltu.se/~vk/q/asciitutorials/Maija_Haavisto.html#:~:text=ASCII%20art%20is%20always%20done,programs%20for%20making%20ASCII%20art.">https://www.ludd.ltu.se/~vk/q/asciitutorials/Maija_Haavisto.html#:~:text=ASCII%20art%20is%20always%20done,programs%20for%20making%20ASCII%20art.</a></em></p>]]>
            </description>
            <link>https://www.ludd.ltu.se/~vk/q/asciitutorials/Maija_Haavisto.html#:~:text=ASCII%20art%20is%20always%20done,programs%20for%20making%20ASCII%20art.</link>
            <guid isPermaLink="false">hacker-news-small-sites-25549054</guid>
            <pubDate>Sun, 27 Dec 2020 05:17:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google’s API Design Standard]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25548258">thread link</a>) | @dkharrat
<br/>
December 26, 2020 | https://google.aip.dev/general | <a href="https://web.archive.org/web/*/https://google.aip.dev/general">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="jump-content">
          


<section id="aip-main">
  
  <h3 id="meta">Meta</h3>
  <table>
    <thead>
      <tr>
        <th>Number</th>
        <th>Title</th>
      </tr>
    </thead>
    <tbody>
    <tr>
        <td>1</td>
        <td>
          <a href="https://google.aip.dev/1">AIP Purpose and Guidelines</a>
          </td>
      </tr>
      <tr>
        <td>2</td>
        <td>
          <a href="https://google.aip.dev/2">AIP Numbering</a>
          </td>
      </tr>
      <tr>
        <td>200</td>
        <td>
          <a href="https://google.aip.dev/200">Precedent</a>
          </td>
      </tr>
      <tr>
        <td>8</td>
        <td>
          <a href="https://google.aip.dev/8">AIP Style guide</a>
          </td>
      </tr>
      <tr>
        <td>9</td>
        <td>
          <a href="https://google.aip.dev/9">Glossary</a>
          </td>
      </tr>
      </tbody>
  </table>
  <h3 id="process">Process</h3>
  <table>
    <thead>
      <tr>
        <th>Number</th>
        <th>Title</th>
      </tr>
    </thead>
    <tbody>
    <tr>
        <td>100</td>
        <td>
          <a href="https://google.aip.dev/100">API Design Review FAQ</a>
          </td>
      </tr>
      <tr>
        <td>205</td>
        <td>
          <a href="https://google.aip.dev/205">Beta-blocking changes</a>
          </td>
      </tr>
      </tbody>
  </table>
  <h3 id="resource-design">Resource Design</h3>
  <table>
    <thead>
      <tr>
        <th>Number</th>
        <th>Title</th>
      </tr>
    </thead>
    <tbody>
    <tr>
        <td>121</td>
        <td>
          <a href="https://google.aip.dev/121">Resource-oriented design</a>
          </td>
      </tr>
      <tr>
        <td>122</td>
        <td>
          <a href="https://google.aip.dev/122">Resource names</a>
          </td>
      </tr>
      <tr>
        <td>123</td>
        <td>
          <a href="https://google.aip.dev/123">Resource types</a>
          </td>
      </tr>
      <tr>
        <td>124</td>
        <td>
          <a href="https://google.aip.dev/124">Resource association</a>
          </td>
      </tr>
      <tr>
        <td>126</td>
        <td>
          <a href="https://google.aip.dev/126">Enumerations</a>
          </td>
      </tr>
      <tr>
        <td>128</td>
        <td>
          <a href="https://google.aip.dev/128">Declarative-friendly interfaces</a>
          <span>
            Reviewing
          </span>
          </td>
      </tr>
      <tr>
        <td>156</td>
        <td>
          <a href="https://google.aip.dev/156">Singleton resources</a>
          </td>
      </tr>
      </tbody>
  </table>
  <h3 id="operations">Operations</h3>
  <table>
    <thead>
      <tr>
        <th>Number</th>
        <th>Title</th>
      </tr>
    </thead>
    <tbody>
    <tr>
        <td>131</td>
        <td>
          <a href="https://google.aip.dev/131">Standard methods: Get</a>
          </td>
      </tr>
      <tr>
        <td>132</td>
        <td>
          <a href="https://google.aip.dev/132">Standard methods: List</a>
          </td>
      </tr>
      <tr>
        <td>133</td>
        <td>
          <a href="https://google.aip.dev/133">Standard methods: Create</a>
          </td>
      </tr>
      <tr>
        <td>134</td>
        <td>
          <a href="https://google.aip.dev/134">Standard methods: Update</a>
          </td>
      </tr>
      <tr>
        <td>135</td>
        <td>
          <a href="https://google.aip.dev/135">Standard methods: Delete</a>
          </td>
      </tr>
      <tr>
        <td>136</td>
        <td>
          <a href="https://google.aip.dev/136">Custom methods</a>
          </td>
      </tr>
      <tr>
        <td>151</td>
        <td>
          <a href="https://google.aip.dev/151">Long-running operations</a>
          </td>
      </tr>
      <tr>
        <td>231</td>
        <td>
          <a href="https://google.aip.dev/231">Batch methods: Get</a>
          </td>
      </tr>
      <tr>
        <td>233</td>
        <td>
          <a href="https://google.aip.dev/233">Batch methods: Create</a>
          </td>
      </tr>
      <tr>
        <td>234</td>
        <td>
          <a href="https://google.aip.dev/234">Batch methods: Update</a>
          </td>
      </tr>
      <tr>
        <td>235</td>
        <td>
          <a href="https://google.aip.dev/235">Batch methods: Delete</a>
          </td>
      </tr>
      </tbody>
  </table>
  <h3 id="fields">Fields</h3>
  <table>
    <thead>
      <tr>
        <th>Number</th>
        <th>Title</th>
      </tr>
    </thead>
    <tbody>
    <tr>
        <td>140</td>
        <td>
          <a href="https://google.aip.dev/140">Field names</a>
          </td>
      </tr>
      <tr>
        <td>203</td>
        <td>
          <a href="https://google.aip.dev/203">Field behavior documentation</a>
          </td>
      </tr>
      <tr>
        <td>141</td>
        <td>
          <a href="https://google.aip.dev/141">Quantities</a>
          </td>
      </tr>
      <tr>
        <td>142</td>
        <td>
          <a href="https://google.aip.dev/142">Time and duration</a>
          </td>
      </tr>
      <tr>
        <td>143</td>
        <td>
          <a href="https://google.aip.dev/143">Standardized codes</a>
          </td>
      </tr>
      <tr>
        <td>144</td>
        <td>
          <a href="https://google.aip.dev/144">Repeated fields</a>
          </td>
      </tr>
      <tr>
        <td>145</td>
        <td>
          <a href="https://google.aip.dev/145">Ranges</a>
          </td>
      </tr>
      <tr>
        <td>146</td>
        <td>
          <a href="https://google.aip.dev/146">Generic fields</a>
          </td>
      </tr>
      <tr>
        <td>147</td>
        <td>
          <a href="https://google.aip.dev/147">Sensitive fields</a>
          </td>
      </tr>
      <tr>
        <td>148</td>
        <td>
          <a href="https://google.aip.dev/148">Standard fields</a>
          <span>
            Reviewing
          </span>
          </td>
      </tr>
      <tr>
        <td>216</td>
        <td>
          <a href="https://google.aip.dev/216">States</a>
          </td>
      </tr>
      </tbody>
  </table>
  <h3 id="design-patterns">Design Patterns</h3>
  <table>
    <thead>
      <tr>
        <th>Number</th>
        <th>Title</th>
      </tr>
    </thead>
    <tbody>
    <tr>
        <td>152</td>
        <td>
          <a href="https://google.aip.dev/152">Jobs</a>
          </td>
      </tr>
      <tr>
        <td>153</td>
        <td>
          <a href="https://google.aip.dev/153">Import and export</a>
          </td>
      </tr>
      <tr>
        <td>154</td>
        <td>
          <a href="https://google.aip.dev/154">Resource freshness validation</a>
          </td>
      </tr>
      <tr>
        <td>155</td>
        <td>
          <a href="https://google.aip.dev/155">Request identification</a>
          </td>
      </tr>
      <tr>
        <td>157</td>
        <td>
          <a href="https://google.aip.dev/157">Partial responses</a>
          </td>
      </tr>
      <tr>
        <td>158</td>
        <td>
          <a href="https://google.aip.dev/158">Pagination</a>
          </td>
      </tr>
      <tr>
        <td>159</td>
        <td>
          <a href="https://google.aip.dev/159">Reading across collections</a>
          </td>
      </tr>
      <tr>
        <td>160</td>
        <td>
          <a href="https://google.aip.dev/160">Filtering</a>
          </td>
      </tr>
      <tr>
        <td>162</td>
        <td>
          <a href="https://google.aip.dev/162">Resource Revisions</a>
          </td>
      </tr>
      <tr>
        <td>163</td>
        <td>
          <a href="https://google.aip.dev/163">Change validation</a>
          </td>
      </tr>
      <tr>
        <td>164</td>
        <td>
          <a href="https://google.aip.dev/164">Soft delete</a>
          <span>
            Reviewing
          </span>
          </td>
      </tr>
      <tr>
        <td>165</td>
        <td>
          <a href="https://google.aip.dev/165">Criteria-based delete</a>
          </td>
      </tr>
      <tr>
        <td>210</td>
        <td>
          <a href="https://google.aip.dev/210">Unicode</a>
          </td>
      </tr>
      <tr>
        <td>214</td>
        <td>
          <a href="https://google.aip.dev/214">Resource expiration</a>
          </td>
      </tr>
      <tr>
        <td>217</td>
        <td>
          <a href="https://google.aip.dev/217">Unreachable resources</a>
          </td>
      </tr>
      </tbody>
  </table>
  <h3 id="compatibility">Compatibility</h3>
  <table>
    <thead>
      <tr>
        <th>Number</th>
        <th>Title</th>
      </tr>
    </thead>
    <tbody>
    <tr>
        <td>180</td>
        <td>
          <a href="https://google.aip.dev/180">Backwards compatibility</a>
          </td>
      </tr>
      <tr>
        <td>181</td>
        <td>
          <a href="https://google.aip.dev/181">Stability levels</a>
          </td>
      </tr>
      </tbody>
  </table>
  <h3 id="polish">Polish</h3>
  <table>
    <thead>
      <tr>
        <th>Number</th>
        <th>Title</th>
      </tr>
    </thead>
    <tbody>
    <tr>
        <td>191</td>
        <td>
          <a href="https://google.aip.dev/191">File and directory structure</a>
          </td>
      </tr>
      <tr>
        <td>192</td>
        <td>
          <a href="https://google.aip.dev/192">Documentation</a>
          </td>
      </tr>
      <tr>
        <td>193</td>
        <td>
          <a href="https://google.aip.dev/193">Errors</a>
          </td>
      </tr>
      <tr>
        <td>194</td>
        <td>
          <a href="https://google.aip.dev/194">Automatic retry configuration</a>
          </td>
      </tr>
      </tbody>
  </table>
  <h3 id="protobuf">Protocol buffers</h3>
  <table>
    <thead>
      <tr>
        <th>Number</th>
        <th>Title</th>
      </tr>
    </thead>
    <tbody>
    <tr>
        <td>127</td>
        <td>
          <a href="https://google.aip.dev/127">HTTP and gRPC Transcoding</a>
          </td>
      </tr>
      <tr>
        <td>213</td>
        <td>
          <a href="https://google.aip.dev/213">Common components</a>
          </td>
      </tr>
      <tr>
        <td>215</td>
        <td>
          <a href="https://google.aip.dev/215">Common component versions</a>
          </td>
      </tr>
      </tbody>
  </table>
  
</section>

        </section></div>]]>
            </description>
            <link>https://google.aip.dev/general</link>
            <guid isPermaLink="false">hacker-news-small-sites-25548258</guid>
            <pubDate>Sun, 27 Dec 2020 02:19:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reflecting on London Underground's Overheating]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25548128">thread link</a>) | @CalvinBarrows
<br/>
December 26, 2020 | https://www.railbusinessdaily.com/a-reflective-perspective-the-whys-and-wherefores-of-metro-overheating/ | <a href="https://web.archive.org/web/*/https://www.railbusinessdaily.com/a-reflective-perspective-the-whys-and-wherefores-of-metro-overheating/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="content" role="main">
	
<article id="post-32595">

<section>
	<img width="1000" height="580" src="https://mk0railbusinessipb4k.kinstacdn.com/wp-content/uploads/2020/08/RB-Calvin-1000x580.jpg" alt="Calvin Barrows">	     
<section>
<span>3rd August 2020</span>
</section>   
	
            <!-- Share buttons by mashshare.net - Version: 3.7.2--><p>Calvin Barrows has written an article for railbusinessdaily.com about the root cause(s) of overheating in certain metro systems, using London Underground’s ‘Tube’ Network as an example.</p>
<p>Calvin is a Chartered Engineer, latterly retired. His work focused on forensic engineering, to establish the mechanisms of structural and mechanical failures; then continuing as an engineering manager, within the rail industry.</p>
<p>Sylvia Telatycka is co-author and linguist, who with Calvin runs a small but successful property development and rental business.</p>
<p>“This guest article aims to encourage a wider discussion around our hypothesis as to the root cause(s) of overheating in certain metro systems, using London Underground’s ‘Tube’ Network as an example.</p>
<p>Rather than go into complicated thermodynamic formulae to demonstrate the credible science upon which this theory is based, we have described in simple terms the comparable heat generation and heat exchange processes at work, to clarify how these affect this historic Tube network. This is important because, in the earliest days of the London Tube, overheating was simply not an issue…. but WHY….?</p>
<p>In the first instance, we need to understand clearly what the problem is. Paraphrasing Charles Kettering: a problem well defined is half solved and mindful of that, we took the basic premise of the Tube overheating and framed a series of questions to help identify the problem.</p>
<p>1. When does overheating happen?</p>
<p>2. Do ALL metros/subways overheat?</p>
<p>3. Why might some metros/subways overheat, and some might not?</p>
<p>4. And why are these questions relevant to London’s network?</p>
<p>5. How can this overheating be mitigated?</p>
<p>Few would disagree that the Tube overheats but understanding WHEN and WHERE it happens is most revealing. In winter passengers mainly travel bundled up in their winter coats and the saloons are heated. In summer, heavy clothing is shed – indeed some passengers have been known to travel in swimwear.</p>
<p><img src="https://mk0railbusinessipb4k.kinstacdn.com/wp-content/uploads/2020/08/Screenshot-2020-08-03-at-14.20.35.png" alt="" width="598" height="320" srcset="https://mk0railbusinessipb4k.kinstacdn.com/wp-content/uploads/2020/08/Screenshot-2020-08-03-at-14.20.35.png 598w, https://mk0railbusinessipb4k.kinstacdn.com/wp-content/uploads/2020/08/Screenshot-2020-08-03-at-14.20.35-300x161.png 300w" sizes="(max-width: 598px) 100vw, 598px"></p>
<p>In the above graph i, London’s mean surface ambient air temperatures, averaged over a 30 year period, show a clear increase from approximately -5°C in the winter to around +30°C in the summer.</p>
<p>Interestingly, the following graph ii represents the results of TfL’s temperature monitoring within the underground network, for both the deep tube and sub-surface lines. The TfL temperature variations not only confirm passengers’ subjective perception, they also mimic the curve of temperature data above and demonstrate conclusively that underground network temperatures align with the external seasonal temperatures.</p>
<p><img src="https://mk0railbusinessipb4k.kinstacdn.com/wp-content/uploads/2020/08/Screenshot-2020-08-03-at-14.22.17.png" alt="" width="587" height="298" srcset="https://mk0railbusinessipb4k.kinstacdn.com/wp-content/uploads/2020/08/Screenshot-2020-08-03-at-14.22.17.png 587w, https://mk0railbusinessipb4k.kinstacdn.com/wp-content/uploads/2020/08/Screenshot-2020-08-03-at-14.22.17-300x152.png 300w" sizes="(max-width: 587px) 100vw, 587px"></p>
<p>In the course of our research we looked at different types of rail networks, categorising them as follows because they all perform differently in relation to overheating:-</p>
<p>1. Metro train networks – which run ONLY underground.</p>
<p>2. Trains networks – which run predominately overground.</p>
<p>3. Metro train networks – which run both overground and underground.</p>
<p>Underground-only networks like Glasgow’s or Warsaw’s are not affected by the overground conditions, so there is little seasonal variation in train and network temperatures. Their ambient underground temperature remains about 16°C – unlike the wide temperature range the TfL data above show for London’s Tube network. Underground-only networks irrefutably demonstrate that operational heat such as braking, being generated year-round, is NOT a significant cause of metro networks overheating. Furthermore, since passengers are not being exposed to overheating they remain comfortable and safe.</p>
<p>Overground-only trains are cool in winter and therefore heated. However, in summer they will overheat, unless they are proactively cooled, usually by air-conditioning, though AC deals with the symptoms, not underlying causes, and it is environmentally unfriendly. Whilst AC is technically sound as long as it can discharge the exhaust heat to free air, if it does not work for some reason…. What then? There have been at least three incidents over the last 15 years where power failures compromised the AC, triggering saloon temperature rises to 46°C; with distressed passengers fainting from heat exhaustion, and others desperate enough to smash windows and even to try and break through emergency doors.</p>
<p>Which brings us neatly to MIXED metro networks like London’s Tube, which run both overground and underground, to see why this overheating is NOT restricted to the overground areas of these networks. The reason behind this apparent contradiction is that these mixed networks are, thermodynamically speaking, open systems – ones that freely exchange energy and matter with their surroundings – where:-</p>
<p>1. The free exchange of energy is a regular transfer of air in and out of the tunnels; and</p>
<p>2. The free exchange of mass is a regular travel of hot, loaded trains in and out of the tunnel.</p>
<p>TfL engineers continue to focus on ‘base load’, aka the operational heat, which by definition is year-round, so this can never explain the seasonal nature of the problem. Saloon AC is not a viable solution here, expelling more heat into an already overheated tunnel. We need to be thinking more holistically: rather than the ‘Cooling the Tube Project’ it should be the ‘Cooling the Whole Tube Network in the Summer Project’.</p>
<p>Clearly the root cause of this 100+ year old seasonal problem is the SUN. However, its sheer power to affect every aspect of a network like London’s Tube has been significantly underestimated. In a thermodynamic nutshell:-</p>
<p>1. Radiation from the sun is short wave energy in the form of light, which on striking the earth or a solid object increases their internal energy.</p>
<p>2. This internal energy is in the form of heat and is then re-radiated from the surface of the earth (and solid objects) as long wave heat energy, which in turn warms the ambient air.</p>
<p>The unintentional consequence of the above process in a thermodynamically open system is that hot ambient air plus heat from solar irradiated trains travelling on the surface is carried into the tunnels.</p>
<p>In the context of mixed metro networks, when overground, all external surfaces of the train exposed to the sun, including wheels and bogies, are being directly irradiated. Like any heat conductive surface, the irradiated train body get hot. The sun’s shortwave radiation readily shines through the window glass; then striking the internal surfaces is converted into heat within those materials. However, heat being longwave radiation and, struggling to pass back out through the window glass, is trapped – an unintended ‘greenhouse’ effect. Finally, the undercarriage components consist of massive chunks of metal – usually black – with the ability to absorb immense amounts of heat.</p>
<p>Furthermore, while rail buckling is a familiar problem, the knock-on effects of the sun on the track beds have never really figured in the context of the network overheating. The whole of the track bed including the rails is absorbing and reflecting heat. So, when trains pass over it, this heat is then reflected outwards and upwards into the wheels, bogies, underside of the carriages, the brakes and traction motors. These get super-heated, not so much through operation, but principally because they are in an overheated environment.</p>
<p><img src="https://mk0railbusinessipb4k.kinstacdn.com/wp-content/uploads/2020/08/Screenshot-2020-08-03-at-14.22.34.png" alt="" width="548" height="282" srcset="https://mk0railbusinessipb4k.kinstacdn.com/wp-content/uploads/2020/08/Screenshot-2020-08-03-at-14.22.34.png 548w, https://mk0railbusinessipb4k.kinstacdn.com/wp-content/uploads/2020/08/Screenshot-2020-08-03-at-14.22.34-300x154.png 300w" sizes="(max-width: 548px) 100vw, 548px"></p>
<p>The above concept graph predicts the build-up of solar irradiation acting on a train, starting early in the day and repeatedly travelling (in this example) the length of the Central Line. The train is irradiated when overground and dissipates a large proportion of that heat load during the underground sections of the journey. However, each irradiated train movement passing throughout the entire network compounds the effect of previous trains, elevating tunnel temperatures even more as the day progresses – rudimentary monitoring has shown saloon temperatures overground typically increase by up to 6°C in 30 mins between Leyton and Epping around 4.30-5.00pm on a summer afternoon.</p>
<p>While the piston-drag effect as the train passes in and out of the tunnel portals will draw in hot ambient air, probably contributing a small amount of heat to the underground sections, compared to the storage-radiator capacity of the train itself, cumulatively dissipating within the tunnel, it is unlikely to be that significant.</p>
<p>Having identified the root causes of overheating and the contributing factors, the task of managing the overheating in the tunnels is actually quite simple – deal with the overheating of the trains on the surface BEFORE THEY ENTER THE TUNNELS.</p>
<p>There are four obvious radiant barrier measures. These are solar-reflective paints (typical surface temperature reductions of 20⁰C) and Low E glass (absorbing some 80% less solar radiation than standard glass), both of which could be easily retroactively applied to existing trains and become the standard for new rolling stock. Then there is green planting on tracks, with its low heat absorption properties compared to ballast and rails. Once in place maintenance costs should be minimal and the benefits considerable. Lastly effective stabling of off-peak trains, providing appropriate solar shade AND ventilation, is imperative.</p>
<p>In conclusion, and most importantly, it should not be forgotten that overheating saloons will adversely affect passenger health and safety. In London’s Tube, this problem would be exacerbated in a ‘stalled-train event’ underground. Passengers overheated in a carriage, within an overheated tunnel, is a potentially fatal matter, especially when temperatures rise, as they often do in summer, to 40°C or higher and where passengers can do nothing but wait until LU staff can direct their escape.”</p>
<p>i Meteoblue (2020) Climate London Basel Switzerland www.meteoblue.com https://www.meteoblue.com/en/weather/historyclimate/climatemodelled/london_united-kingdom_2643743</p>
<p>ii Transport for London (July 2018) Average monthly evening peak temperatures by line London: Transport for London …</p></section></article></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.railbusinessdaily.com/a-reflective-perspective-the-whys-and-wherefores-of-metro-overheating/">https://www.railbusinessdaily.com/a-reflective-perspective-the-whys-and-wherefores-of-metro-overheating/</a></em></p>]]>
            </description>
            <link>https://www.railbusinessdaily.com/a-reflective-perspective-the-whys-and-wherefores-of-metro-overheating/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25548128</guid>
            <pubDate>Sun, 27 Dec 2020 01:49:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Start Contributing to Open Source Software]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25547724">thread link</a>) | @fagnerbrack
<br/>
December 26, 2020 | https://markushatvan.com/blog/why-you-should-start-contributing-to-open-source-software-right-now | <a href="https://web.archive.org/web/*/https://markushatvan.com/blog/why-you-should-start-contributing-to-open-source-software-right-now">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><figure> <figcaption>I know you want to. - Photo by Author </figcaption></figure> <p>You might not be aware of it, but you use some form of open source software every single day.</p> <p>Every time you start an app on your phone or launch a program on your computer, you profit from the code that someone has written for free.</p> <p>WordPress, the largest and most well-known content management system, is used by <a href="https://w3techs.com/technologies/details/cm-wordpress" rel="nofollow">38% of all websites</a> worldwide. It is open source and free to use.</p> <p>Linux is powering <a href="https://w3techs.com/technologies/details/os-linux" rel="nofollow">30% of all websites</a> globally. It is open source and free to use.</p> <p>These are just two examples out of a myriad of projects which were created to solve a problem or serve a use case.</p> <p>These projects became highly popular as communities formed around them. They tried to deliver the best product possible in terms of user experience, stability, security, and more.</p> <p>But not only the usage of open source projects is rising. The participation in the open source movement as a whole is growing as well.</p> <p>According to the <a href="https://octoverse.github.com/" rel="nofollow">State of the Octoverse report</a> by GitHub, out of more than 40 million developers on GitHub, 10 million new&nbsp;users joined in 2019 alone!</p> <p>The open source movement is growing quickly and you should become a part of it too.</p> <p>Whenever I see a new update for my operating system or new software releases of tools that I actively use every day, it makes me smile. I enjoy the thought of products continuously getting better and more sophisticated.</p> <p>Do you feel the same way?</p> <p>Here is why I am convinced that you should start contributing to open source software right now.</p> <h2>You can learn a lot from the source code</h2> <p>Since the source code in open source projects is available for anyone to read, that means that a large number of developers can battle-test and improve a project.</p> <p>Developers point out privacy or security issues, update the documentation, and improve source code to the newest web development standards all the time.</p> <p>Especially when you go through the code of projects with hundreds or even thousands of contributors, you can gain immense knowledge about best practices and code quality.</p> <p>Not only is reviewing the code itself a learning experience, but also the structure and folder hierarchy in larger projects is well thought-out and works well in the long run.</p> <h2>You will work with the smartest people</h2> <p>Compared to a company that has a limited number of employees to work on feature requests and bug fixes, you have the brightest minds working in open source development.</p> <p>In my imagination, I see it as swarm intelligence, which can solve every problem that arises.</p> <p>The more people that join a community, the better a project can scale. It can be like a buzzing beehive, where you could have pull requests to a codebase from users all around the world 24/7, non-stop.</p> <p>A good example is the well-known code editor <a href="https://github.com/microsoft/vscode" rel="nofollow">Visual Studio Code</a> which got very popular with a total of 1,200+ contributors on GitHub.</p> <p>You won’t see a single day without any pull requests on GitHub and the monthly release cycles always bring out new amazing features.</p> <p>When you participate in a project and submit a pull request, you will receive extremely helpful feedback from highly experienced maintainers. You can then implement that feedback to grow as a developer.</p> <h2>Your own code could be used globally</h2> <p>Since some software development projects are used by millions of users daily, it can be very rewarding to see your own code helping so many people.</p> <p>I wrote lint rules for the JavaScript projects called <a href="https://github.com/sindresorhus/eslint-plugin-unicorn" rel="nofollow">eslint-plugin-unicorn</a> and <a href="https://github.com/sveltejs/svelte" rel="nofollow">svelte</a>. It’s a great feeling knowing that my pull request will improve the code quality of many developers all around the world.</p> <p>From my personal experience, it is also motivating to get positive feedback in the form of a thankful comment.</p> <h2>Open source projects are inclusive</h2> <p>A great advantage of free open source software is that no one is excluded from using the product because they can’t afford it.</p> <p>While some open source projects cost money to use, most do not.</p> <p>Also, when you’re contributing to a project on GitHub, many of the bigger repositories have a code of conduct. These make sure that every contributor feels welcome and accepted in a project.</p> <h2>Projects are starting to become sustainable</h2> <p>The main goal of a company is to become profitable - which often leads to questionable decisions. But open source software focuses on solving the needs of its users as the highest priority.</p> <p>Most projects are entirely volunteer-supported, and project maintainers will unfortunately never see any financial reward. But there are great ways nowadays that you can help make these projects sustainable.</p> <p>With websites like <a href="https://opencollective.com/" rel="nofollow">OpenCollective</a>&nbsp;or <a href="https://github.com/sponsors" rel="nofollow">GitHub Sponsors</a>, you can donate to speed up the development of projects that you like.</p> <p>Personally, I think that it would be great if every company donated at least a small sum to open source software projects because they profit from these tools daily. Such support would reduce the stress for a lot of maintainers and some could even take up the work full-time.</p> <h2>How to contribute to open source</h2> <p>Contributing to open source development sounds more scary than it really is. There are plenty of projects out there on GitHub which encourage first time contributors and newbies to take action by labeling issues as “Good first issue”, “Beginner friendly” or “Help wanted”.</p> <p>Don’t know where to start?</p> <p>Ask yourself: what is an application that you enjoy using every day and where you would want to give back?</p> <p>It can be as simple as searching for that application on GitHub and looking through the open issues.</p> <p>It doesn’t have to be a code contribution, either - you can also help out by creating a pull request to update the documentation, fix typos that you find, or by doing a thorough code review.</p> <p>The <code>README.md</code> file of a project usually includes a passage of how to contribute.</p> <p>If you decide to contribute to a project, I recommend reading my article about&nbsp;<a href="https://markushatvan.com/blog/contributing-to-open-source-projects-the-right-way">Contributing To Open Source Projects The Right Way</a>. It’s a detailed step-by-step guide about the contribution workflow.</p> <p>I wrote it to be very beginner friendly, so don’t worry about becoming overwhelmed. You will be able to find your first project and submit a contribution in no time!</p> <h2>Wrapping up</h2> <p>It always impressed me that everyone in the world can join an open source software project and work on it.</p> <p>And open source software only works as a collaborative effort. The goal is to produce the best product or service without compromising on important factors like stability, security, or user privacy.</p> <p>I hope you understand the importance of open source software and that you value its benefits. No matter what your reasons are for giving back to the open source community, just know that you are highly appreciated!</p> <p>Many projects can only thrive with support and contributions from developers like you.</p> <h2>Helpful resources</h2> <ul><li><a href="https://octoverse.github.com/" rel="nofollow">The State of the Octoverse</a></li> <li><a href="https://opensource.com/resources/what-open-source" rel="nofollow">What is open source?</a></li> <li><a href="https://clearcode.cc/blog/why-developers-contribute-open-source-software/" rel="nofollow">What Motivates a Developer to Contribute to Open-Source Software?</a></li></ul> <div><p><b>If you liked this post, share it:</b></p> <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fmarkushatvan.com%2Fblog%2Fwhy-you-should-start-contributing-to-open-source-software-right-now" rel="noopener noreferrer" target="_blank" title="Share on Facebook"><svg height="24" role="presentation" style="font-size:1.5em" version="1.1" viewBox="0 0 512 512" width="24"> <path d="M504 256C504 119 393 8 256 8S8 119 8 256c0 123.78 90.69 226.38 209.25 245V327.69h-63V256h63v-54.64c0-62.15 37-96.48 93.67-96.48 27.14 0 55.52 4.84 55.52 4.84v61h-31.28c-30.8 0-40.41 19.12-40.41 38.73V256h68.78l-11 71.69h-57.78V501C413.31 482.38 504 379.78 504 256z" key="path-0"></path> </svg></a> <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3A%2F%2Fmarkushatvan.com%2Fblog%2Fwhy-you-should-start-contributing-to-open-source-software-right-now&amp;title=Why%20You%20Should%20Start%20Contributing%20to%20Open%20Source%20Software%20Right%20Now&amp;summary=The%20open%20source%20movement%20is%20growing%20quickly%20and%20you%20should%20become%20a%20part%20of%20it%20too.&amp;source=LinkedIn" rel="noopener noreferrer" target="_blank" title="Share on LinkedIn"><svg height="24" role="presentation" style="font-size:1.5em" version="1.1" viewBox="0 0 448 512" width="21"> <path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z" key="path-0"></path> </svg></a> <a href="https://twitter.com/intent/tweet?text=Why%20You%20Should%20Start%20Contributing%20to%20Open%20Source%20Software%20Right%20Now&amp;url=https%3A%2F%2Fmarkushatvan.com%2Fblog%2Fwhy-you-should-start-contributing-to-open-source-software-right-now" rel="noopener noreferrer" target="_blank" title="Share on Twitter"><svg height="24" role="presentation" style="font-size:1.5em" version="1.1" viewBox="0 0 512 512" width="24"> <path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z" key="path-0"></path> </svg></a> <a href="https://www.reddit.com/submit?url=https%3A%2F%2Fmarkushatvan.com%2Fblog%2Fwhy-you-should-start-contributing-to-open-source-software-right-now&amp;title=Why%20You%20Should%20Start%20Contributing%20to%20Open%20Source%20Software%20Right%20Now" rel="noopener noreferrer" target="_blank" title="Share on Reddit"><svg height="24" role="presentation" style="font-size:1.5em" version="1.1" viewBox="0 0 512 512" width="24"> <path d="M201.5 305.5c-13.8 0-24.9-11.1-24.9-24.6 0-13.8 11.1-24.9 24.9-24.9 13.6 0 24.6 11.1 24.6 24.9 0 13.6-11.1 24.6-24.6 24.6zM504 256c0 137-111 248-248 248S8 393 8 256 119 8 256 8s248 111 248 248zm-132.3-41.2c-9.4 0-17.7 3.9-23.8 10-22.4-15.5-52.6-25.5-86.1-26.6l17.4-78.3 55.4 12.5c0 13.6 11.1 24.6 24.6 24.6 13.8 0 24.9-11.3 24.9-24.9s-11.1-24.9-24.9-24.9c-9.7 0-18 5.8-22.1 13.8l-61.2-13.6c-3-.8-6.1 1.4-6.9 4.4l-19.1 86.4c-33.2 1.4-63.1 11.3-85.5 26.8-6.1-6.4-14.7-10.2-24.1-10.2-34.9 0-46.3 46.9-14.4 62.8-1.1 5-1.7 10.2-1.7 15.5 0 52.6 59.2 95.2 132 95.2 73.1 0 132.3-42.6 132.3-95.2 0-5.3-.6-10.8-1.9-15.8 31.3-16 19.8-62.5-14.9-62.5zM302.8 331c-18.2 18.2-76.1 17.9-93.6 0-2.2-2.2-6.1-2.2-8.3 0-2.5 2.5-2.5 6.4 0 8.6 22.8 22.8 87.3 22.8 110.2 0 2.5-2.2 2.5-6.1 0-8.6-2.2-2.2-6.1-2.2-8.3 0zm7.7-75c-13.6 0-24.6 11.1-24.6 24.9 0 13.6 11.1 24.6 24.6 24.6 13.8 0 24.9-11.1 24.9-24.6 0-13.8-11-24.9-24.9-24.9z" key="path-0"></path> </svg></a> <a href="https://pinterest.com/pin/create/button/?url=https%3A%2F%2Fmarkushatvan.com%2Fblog%2Fwhy-you-should-start-contributing-to-open-source-software-right-now" rel="noopener noreferrer" target="_blank" title="Share on Pinterest"><svg height="24" role="presentation" style="font-size:1.5em" version="1.1" viewBox="0 0 496 512" width="23.25"> <path d="M496 256c0 137-111 248-248 248-25.6 0-50.2-3.9-73.4-11.1 10.1-16.5 25.2-43.5 30.8-65 3-11.6 15.4-59 15.4-59 8.1 15.4 31.7 28.5 56.8 28.5 74.8 0 128.7-68.8 128.7-154.3 0-81.9-66.9-143.2-152.9-143.2-107 0-163.9 71.8-163.9 150.1 0 36.4 19.4 81.7 50.3 96.1 4.7 2.2 7.2 1.2 8.3-3.3.8-3.4 5-20.3 6.9-28.1.6-2.5.3-4.7-1.7-7.1-10.1-12.5-18.3-35.3-18.3-56.6 0-54.7 41.4-107.6 112-107.6 60.9 0 103.6 41.5 103.6 100.9 0 67.1-33.9 113.6-78 113.6-24.3 0-42.6-20.1-36.7-44.8 7-29.5 20.5-61.3 20.5-82.6 0-19-10.2-34.9-31.4-34.9-24.9 0-44.9 25.7-44.9 60.2 0 22 7.4 36.8 7.4 36.8s-24.5 103.8-29 123.2c-5 21.4-3 51.6-.9 71.2C65.4 450.9 0 361.1 0 256 0 119 111 8 248 8s248 111 248 248z" key="path-0"></path> </svg></a></div>   </article></div>]]>
            </description>
            <link>https://markushatvan.com/blog/why-you-should-start-contributing-to-open-source-software-right-now</link>
            <guid isPermaLink="false">hacker-news-small-sites-25547724</guid>
            <pubDate>Sun, 27 Dec 2020 00:40:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[API pagination design]]>
            </title>
            <description>
<![CDATA[
Score 208 | Comments 61 (<a href="https://news.ycombinator.com/item?id=25547716">thread link</a>) | @fagnerbrack
<br/>
December 26, 2020 | https://solovyov.net/blog/2020/api-pagination-design/ | <a href="https://web.archive.org/web/*/https://solovyov.net/blog/2020/api-pagination-design/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><p>Returning all results for a given query could be a challenge for an API, especially if there are thousands of results. It puts a load on a server, on a client, on a network, and often is unnecessary. Thus people invented pagination.</p>
<p>The usual way to paginate is an offset or a page number. So you make a request like that:</p>
<pre><code>GET /api/products?page=10
{"items": [...100 products]}
</code></pre>
<p>and to continue you make a request like that:</p>
<pre><code>GET /api/products?page=11
{"items": [...another 100 products]}
</code></pre>
<p>In case of a simple offset it’ll look like <code>?offset=1000</code> and <code>?offset=1100</code> — it’s the same old soup, just reheated. It’ll either go straight into SQL query like <code>OFFSET 1000 LIMIT 100</code> or will be multiplied by page size (that <code>LIMIT</code> value). In any case, it’s a suboptimal solution, since every database has to skip that 1000 rows. And to skip them it needs to identify them. It does not matter if it’s PostgreSQL, or ElasticSearch, or MongoDB, it’ll have to order them, count them, and throw them away.</p>
<p>This is a kind of work which no one needs. But it repeats over and over again since it’s <em>easy</em> to implement — you directly map your API onto your query to a database.</p>
<p>What do you do then? We could look at what databases do! They have this concept, called <a href="https://en.wikipedia.org/wiki/Cursor_(databases)">cursor</a> — it’s a pointer to a row. So you can say to a database “return me 100 rows after <strong>that</strong> one”. And it’s much easier for a database to do since there is a good chance that you’ll identify the row by a field with an index. And suddenly you don’t need to fetch and skip those rows, you’ll go directly past them.</p>
<p>An example:</p>
<pre><code>GET /api/products
{"items": [...100 products],
 "cursor": "qWe"}
</code></pre>
<p>API returns an (opaque) string, which you can use then to retrieve the next page:</p>
<pre><code>GET /api/products?cursor=qWe
{"items": [...100 products],
 "cursor": "qWr"}
</code></pre>
<p>Implementation-wise there are many options. Generally, you have some ordering criteria, for example, product id. In this case, you’ll encode your product id with some reversible algorithm (let’s say <a href="https://hashids.org/">hashids</a>). And on receiving a request with the cursor you decode it and generate a query like <code>WHERE id &gt; :cursor LIMIT 100</code>.</p>
<p>Just a little performance comparison, look at how offsets work:</p>
<pre><code>=# explain analyze select id from product offset 10000 limit 100;
                                                           QUERY PLAN                                                            
---------------------------------------------------------------------------------------------------------------------------------
 Limit  (cost=1114.26..1125.40 rows=100 width=4) (actual time=39.431..39.561 rows=100 loops=1)
   -&gt;  Seq Scan on product  (cost=0.00..1274406.22 rows=11437243 width=4) (actual time=0.015..39.123 rows=10100 loops=1)
 Planning Time: 0.117 ms
 Execution Time: 39.589 ms
</code></pre>
<p>And how where works:</p>
<pre><code>=# explain analyze select id from product where id &gt; 10000 limit 100;
                                                          QUERY PLAN                                                          
------------------------------------------------------------------------------------------------------------------------------
 Limit  (cost=0.00..11.40 rows=100 width=4) (actual time=0.016..0.067 rows=100 loops=1)
   -&gt;  Seq Scan on product  (cost=0.00..1302999.32 rows=11429082 width=4) (actual time=0.015..0.052 rows=100 loops=1)
         Filter: (id &gt; 10000)
 Planning Time: 0.164 ms
 Execution Time: 0.094 ms
</code></pre>
<p>That is a difference of several orders of magnitude! Of course, the actual numbers depend on a size of a table, on your filters and on a store implementation. There <a href="https://use-the-index-luke.com/no-offset">a great article</a> with more technical information - there are slides embedded, see slide 42 for performance comparison.</p>
<p>Of course, nobody orders products by an id — you usually order them by some relevancy (and then by id as a <a href="https://stackoverflow.com/a/17330992/46854">tie breaker</a>). In the real world, you’ll have to look at your data to determine what to do. Orders can be ordered by id (as it’s monotonically increasing). Wishlist items can be ordered like that as well — by wishlisting time. In our case products come from ElasticSearch, which naturally supports this cursor stuff.</p>
<p>One deficiency you can see is that it’s impossible to generate a “previous page” link with a stateless API. So in case of a user-facing pagination, if it’s important to have prev/next and “go directly to page 10” buttons there is no way around this offset/limit stuff. But in other cases using cursor-based pagination can greatly improve performance, especially on really big tables with really deep pagination.</p>
</div></div>]]>
            </description>
            <link>https://solovyov.net/blog/2020/api-pagination-design/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25547716</guid>
            <pubDate>Sun, 27 Dec 2020 00:38:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to backup and decrypt Signal for iPhone message history]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25547699">thread link</a>) | @jonnytran
<br/>
December 26, 2020 | https://cight.co/backup-signal-ios-jailbreak/ | <a href="https://web.archive.org/web/*/https://cight.co/backup-signal-ios-jailbreak/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <p>I started using Signal 5 years ago as I became increasingly conscious of my data footprint. Around the same time, I closed my Facebook and Instagram accounts, and later, my Google Account.</p><h2 id="the-problem-with-signal">The problem with Signal</h2><p>Signal makes it very difficult, and in most cases, impossible, for one to back up, export, or migrate message data. The Signal team insists these restrictions are meant to protect users’ privacy. However, backup and migration policies differ for each official Signal client and sometimes contradict each other.</p><p>For example, while iOS offers no official backups process, Android backups are built into the app. At the same time, iOS users can migrate their data to a new device (as long as their phone number hasn’t changed), but this is impossible on Android. Meanwhile, decrypting messages from the desktop client is trivial, but linking one’s phone and desktop client only syncs messages forward in time.</p><h2 id="why-export-signal-s-message-history">Why export Signal's message history</h2><p>Because it’s my fucking data.</p><p>The road to exporting my data was long, frustrating and filled with dead ends – it took over a year to get here. What's paradoxical is that someone else's phone turned out to be the key to my data. </p><p>In recent years, I moved most of my conversations to Signal, including those with family and close friends. Shortly after we started dating, I asked my partner to switch to Signal, and we’ve used it exclusively ever since. At some point, I thought it would be nice to export our conversation history – a sort of time capsule of our relationship. “Easy,” I thought. I was wrong.</p><p>Since we started dating, I had switched from a OnePlus 2 to an iPhone XS Max. And since migrating from Android to iOS isn’t possible, part of our conversation history was locked on my old phone. Jailbreaking the iPhone was out of the question since my version of iOS had not been jailbreaken. The Signal Desktop client could have offered an easy avenue to decrypt our chat history, but there was a period of several months during which I had not linked my iPhone to the Signal desktop client.</p><p>I opened a <a href="https://community.signalusers.org/t/ios-backups-through-the-desktop-client/8123">thread about this in the Signal Community Forum</a> in June of 2019. It quickly became apparent that backing up my Signal data would be an uphill battle. </p><p>Luckily, my partner had an iPhone 7, which she recently replaced with a company phone. Her old iPhone contained our entire message history in one place and was easy to jailbreak. Jackpot.</p><p>One important lesson I learned during this process:<strong> to ensure access to your conversation history, install the Desktop client and link it to your mobile device as soon as you start using Signal. </strong>The Signal database and encryption key are both accessible on your computer, allowing for easy decryption. Linking the desktop client later will only sync messages forward in time from the moment the devices are linked.</p><h2 id="tips-to-increase-your-chances-of-exporting-your-signal-database">Tips to increase your chances of exporting your Signal database</h2><p>If you haven’t linked the desktop client and extracting the iOS database is your only option, this guide is for you. If you've decided to embark upon this journey, here's some advice. </p><h3 id="stop-updating-ios">Stop updating iOS</h3><p>Your best chance of jailbreaking iOS is on older firmware versions. Turn off automatic updates and decline prompts to update iOS.</p><h3 id="backup-shsh-blobs-with-every-new-ios-update">Backup SHSH blobs with every new iOS update</h3><p><a href="https://en.wikipedia.org/wiki/SHSH_blob">SHSH blobs</a> are the digital signatures that Apple generates and uses to personalize iOS firmware files for each iOS device. Apple only signs firmware updates for a limited time after release. Having these signatures handy allows one to install versions of iOS after Apple stops signing them – like when a jailbreak becomes available for that version. In some cases, you may be able to downgrade iOS to a previous version.</p><p>Backup SHSH blobs every time Apple releases a new version of iOS (e.g., 14.0, 14.1, 14.1.1). I personally use the <a href="https://github.com/airsquared/blobsaver">blobsaver</a> app, but <a href="https://tsssaver.1conan.com/v2/">TSS Saver</a> is a popular alternative.</p><h3 id="learn-about-jailbreaking-and-stay-up-to-date-on-developments">Learn about jailbreaking and stay up to date on developments</h3><p>Developers and hackers are constantly working to break the security of iOS, and new methods to jailbreak iPhones are frequently made public. Stay informed on jailbreak releases by following the <a href="https://www.reddit.com/r/jailbreak/">/r/jailbreak subreddit</a>.</p><p>This <a href="https://docs.google.com/spreadsheets/d/11DABHIIqwYQKj1L83AK9ywk_hYMjEkcaxpIg6phbTf0/edit#gid=1014970938">exhaustive list of jailbreak compatibility</a> by device and iOS version is also a great resource.</p><p>It's also useful to understand the difference between <a href="https://www.theiphonewiki.com/wiki/Untethered_jailbreak">untethered</a>, <a href="https://www.theiphonewiki.com/wiki/Semi-untethered_jailbreak">semi-untethered</a>, <a href="https://www.theiphonewiki.com/wiki/Semi-tethered_jailbreak">semi-tethered</a>, and <a href="https://www.theiphonewiki.com/wiki/Tethered_jailbreak">tethered</a> jailbreaks.</p><h3 id="recognize-that-this-may-not-work">Recognize that this may not work</h3><p>Depending on your iPhone, you might never be able to jailbreak it or extract Signals decryption key from the iOS Keychain. Apple is making it increasingly difficult to jailbreak iOS devices – improvements to hardware and software are leaving fewer cracks for hackers to exploit.</p><p>Ok, let's get our hands dirty. </p><h2 id="how-to-maybe-backup-signal-for-iphone">How to (maybe) backup Signal for iPhone </h2><p>This guide explains how I was able to backup and extract data from Signal's encrypted SQLite database on an iPhone 7 with iOS 13.6.1. </p><h3 id="prerequisites">Prerequisites </h3><ul><li>Physical access to the iPhone with Signal still installed</li><li>An original iPhone cable</li><li>A Mac or Linux computer</li><li>Patience and a bit of luck</li></ul><p>Shell environments will be differentiated as such. </p><pre><code>// Host machine
$ &lt;command&gt;

// iPhone 
root# &lt;command&gt;</code></pre><h3 id="step-1-jailbreak-ios">Step 1: Jailbreak iOS</h3><p>For iOS 13.6.1 on an iPhone 7, I used <strong>checkra1n</strong> which offers a straight forward semi-tethered jailbreak. Depending on the iPhone device and version of iOS, a jailbreak may or may not be available. </p><p>See this <a href="https://docs.google.com/spreadsheets/d/11DABHIIqwYQKj1L83AK9ywk_hYMjEkcaxpIg6phbTf0/edit#gid=1014970938">updated list of iOS jailbreaks</a> for device compatibility and instructions. </p><h3 id="step-2-ssh-into-the-iphone">Step 2: SSH into the iPhone </h3><p>Cydia usually comes with OpenSSH installed and enabled, allowing shell access over IP or USB. If SSH access isn't activated, launch Cydia and install OpenSSH. </p><p><strong>As always, the root password on iOS is <code>alpine</code>.</strong></p><p>If the iPhone and the host machine are on the same network, SSH into the phone using its IP address. It may be found in the phone's WiFi settings. </p><pre><code>$ ssh root@[iphone ip] -p 22</code></pre><p>If SSH over the air isn't possible, USB may be an alternative. However, this involves enabling a proxy service on the host machine.</p><p>First, install <em><em>libimobiledevice</em></em> on the host machine. </p><pre><code>$ brew install libimobiledevice</code></pre><p>Then, edit <em><em>com.usbmux.iproxy.plist</em></em> and append the following XML to the file. </p><pre><code>$ nano ~/Library/LaunchAgents/com.usbmux.iproxy.plist</code></pre><pre><code>&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd"&gt;
&lt;plist version="1.0"&gt;
&lt;dict&gt;
&lt;key&gt;Label&lt;/key&gt;
&lt;string&gt;com.usbmux.iproxy&lt;/string&gt;
&lt;key&gt;ProgramArguments&lt;/key&gt;
&lt;array&gt;
&lt;string&gt;/usr/local/bin/iproxy&lt;/string&gt;
&lt;string&gt;2222&lt;/string&gt;
&lt;string&gt;22&lt;/string&gt;
&lt;/array&gt;
&lt;key&gt;RunAtLoad&lt;/key&gt;
&lt;true/&gt;
&lt;key&gt;KeepAlive&lt;/key&gt;
&lt;true/&gt;
&lt;/dict&gt;</code></pre><p>And finally, launch the proxy on the host machine. </p><pre><code>$ launchctl load ~/Library/LaunchAgents/com.usbmux.iproxy.plist</code></pre><p>It should now be possible to SSH into the iPhone over USB on port <code>2222</code>.</p><pre><code>$ ssh root@localhost -p 2222</code></pre><h3 id="step-3-install-required-packages">Step 3: Install required packages </h3><p>Once logged into to the iPhone's shell, install the following packages as they will come in handy. </p><pre><code>root# apt install zip unzip nano wget</code></pre><h3 id="step-4-backup-the-signal-data-directory">Step 4: Backup the Signal data directory</h3><p><strong>Locate Signal's data directory</strong></p><p>Much like macOS, iOS stores application data in a <em>Library</em>-like directory. In iOS&nbsp;13, its located here <code>/private/var/mobile/Containers/Shared/AppGroup/</code>. </p><p>Signal's data directory contains the encrypted SQLite database file in <code>./grdb/signal.sqilte</code> and attachments, such as images and videos in <code>./Attachments</code>.</p><p>The data directory may be found by searching the filesystem for Signal's encrypted database file, <code>signal.sqlite</code>.</p><pre><code>root# find / -type f -iname "signal.sqlite"</code></pre><p>That should return something which looks like this:<br><code>/private/var/mobile/Containers/Shared/AppGroup/01484069-3446-4CC0-8BE7-7464E7D08FDF/grdb/signal.sqlite</code> </p><p>The Signal directory is: <code>/private/var/mobile/Containers/Shared/AppGroup/01484069-3446-4CC0-8BE7-7464E7D08FDF/</code></p><p><strong>Zip the Signal directory</strong></p><p>It is recommended to zip the entire directory, not only the database file, as it also contains images and other message attachments. This archive can reach several gigabytes.</p><pre><code>root# cd /private/var/mobile/Containers/Shared/AppGroup/
root# zip -r signal-backup.zip &lt;Signal directory&gt;

# ex: zip -r signal-backup.zip /private/var/mobile/Containers/Shared/AppGroup/01484069-3446-4CC0-8BE7-7464E7D08FDF/</code></pre><p><strong>Retrieve the backup on the host machine</strong></p><p>In a new terminal session on the host machine, use <code>scp</code> to copy the backup. </p><pre><code>$ scp -P 22 root@localhost:/private/var/mobile/Containers/Shared/AppGroup/signal-backup.zip ~/</code></pre><p>Once complete, verify that the backup has fully transferred by unpacking it.</p><p>This is the most complex part of this operation and it helps to have a basic understanding of core iOS development concepts.</p><p><strong>Understanding iOS Entitlements </strong></p><p>From the <a href="https://developer.apple.com/documentation/bundleresources/entitlements">Apple Developer Documentation</a>: </p><blockquote>An entitlement is a right or privilege that grants an executable particular capabilities. For example, an app needs the HomeKit Entitlement — along with explicit user consent — to access a user’s home automation network. An app stores its entitlements as key-value pairs embedded in the code signature of its binary executable.</blockquote><p><strong>Enter Keychain Dumper</strong></p><p>We will use <a href="https://github.com/ptoomey3/Keychain-Dumper"><strong>Keychain-Dumper</strong></a> to attempt extracting the Signal encryption key. It requires entitlements to access Keychain data for any particular app. </p><p>Reading through Keychain-Dumper's GitHub issues, I learned that entitlements changed in iOS 13.5 – prior to this version, an application <a href="https://github.com/ptoomey3/Keychain-Dumper/issues/52#issuecomment-638174691">could be given wildcard entitlements</a>. Changes in 13.5 made it such that apps need specific entitlements. Thankfully, it's possible to update an executable's entitlements, even as a binary.</p><p>The <code>keychain_dumper</code> binary included in its <a href="https://github.com/ptoomey3/Keychain-Dumper">GitHub repo</a> has wildcard entitlements. We'll need to update them in order to give it permission to decrypt the Signal key.</p><p><strong>Install Keychain Dumper on the iPhone</strong></p><p>Back on the iPhone, download and extract the <a href="https://github.com/ptoomey3/Keychain-Dumper/releases/tag/1.0.0">keychain_dumper binary</a>, and move it to <code>/usr/bin</code>.</p><pre><code>root# wget https://github.com/ptoomey3/Keychain-Dumper/releases/download/1.0.0/keychain_dumper-1.0.0.zip
root# unzip keychain_dumper-1.0.0.zip
root# mv keychain_dumper /usr/bin</code></pre><p><strong>Update <em>keychain_dumper</em>'s …</strong></p></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cight.co/backup-signal-ios-jailbreak/">https://cight.co/backup-signal-ios-jailbreak/</a></em></p>]]>
            </description>
            <link>https://cight.co/backup-signal-ios-jailbreak/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25547699</guid>
            <pubDate>Sun, 27 Dec 2020 00:36:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Data Is Lying to You and You're Listening]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25547602">thread link</a>) | @haltingproblem
<br/>
December 26, 2020 | https://www.younglingfeynman.com/essays/misleadingdata | <a href="https://web.archive.org/web/*/https://www.younglingfeynman.com/essays/misleadingdata">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-d54917c3f4c66758a8bd"><div><p>I really believe you have to be careful with data.</p><p>There’s this assumption that if you split test, the data tells you what’s better.</p><p>But that’s clearly not always the case.</p><p>Why?</p><p>This is actually a bigger idea than it seems.</p><p>Many companies that have a data-first approach don’t realize they’re reasoning off of an assumption and treat it like an axiom. [1]</p><p>But optimize long enough and everything becomes the equivalent of BuzzFeed or porn.</p><p>Clickbait, sex, drama, and superficialness. Being everything to everyone and nothing to no one.</p><p>Groupon’s quality went down the drain because Mason’s employees told him sending more emails per day increased revenue.</p><p>The deals became ever lower in quality and users got annoyed.</p><p>There was a time where people<strong> could not wait</strong> to get an email from Groupon. They had killer deals. They had hilarious copywriters. Even if you didn’t buy, getting an email was a treat. But now that it has been properly sterilized to please spineless, risk-averse shareholders, and optimized for maximum quarterly revenue, can you think of a single person that feels that way anymore? Not one person? Groupon clearly has lost its soul, its essence. Mason said in an interview (can’t recall the source) that he wondered if Groupon was meant to be an extraordinary company, just for a smaller market. It certainly would have made it easier to build the company according to his vision rather than something that needed to please the shareholders that needed an IPO to get a return.</p><p>In the early days you had the GOATS like Reid Hoffman (founder LinkedIn), Max Levchin (Paypal and Affirm), and the likes answering questions. Now it’s some 14yr old telling you about the opportunity of a lifetime: screencasting stories from Reddit, having the speech to text tool read them, turn it into a video and put it on YouTube. And then…? Millions I guess?</p><p>It went from THE place to get high-quality courses from knowledgeable instructors to the flea-market of cheap knock-offs and fake guru business opportunity courses. While you can find quality courses there, the overall quality has badly degraded. The best instructors aren’t incentivized to create a course because your $1000 course containing 3 decades of experience will sell for $9.99 of which you’ll get $2.50. So if you actually have something to offer, you’ll go somewhere else, leaving mainly the type of people that game the system in order to make a quick buck.</p><p>People used to LOVE Facebook with a vengeance. Now I have 80 notifications, 40 of which are new friend suggestions of people I’ve never met, 20 are strangers that sent out a blast to get likes for their new page, 17 are events, and 3 are birthdays. [2]</p><p>Oh yeah… and not 1 is actually relevant to me.&nbsp;You can fool a user only so many times before you’ve essentially trained them to ignore you.</p><p><em>They started implementing the same dark patterns with their DM. You get notifications for being friends for a certain time and when you accept a new friend.</em></p><p>In its search for endless optimization, the platform has become bloated and just plain annoying. I can’t think of a single person in my cohort (and younger cohorts) that use FB as much or more as 10 years ago.&nbsp;</p><p>The current demographic appears to be the same type of people that use Bing over Google, or Explorer over Chrome. Late adopters that are sticky to defaults.</p><p>So be careful when optimizing. Remember the quantification bias! </p><p><em>Discussed in </em><a href="https://www.younglingfeynman.com/essays/paradigm"><em>Paradigm Shift: Drastically Increase The Odds of Success</em></a></p><p>Just because something is easy to measure doesn’t mean it’s insightful. Just because something can’t be measured easily doesn’t mean it isn’t.</p><p>Remember that business is part art part science: <a href="https://www.younglingfeynman.com/essays/artofbusiness" target="_blank">The Art Of Business, Where Science And Business Depart</a>.</p><p>[1]  I <a href="https://www.younglingfeynman.com/essays/comedy">made the point before</a> when it comes to certain areas that are sufficiently complex (e.g. statistics, data science, economics), you either want no one or a person with extraordinarily deep expertise. </p><p>Interesting piece on the fraud that’s going on in Data Science: <a href="https://logicmag.io/intelligence/interview-with-an-anonymous-data-scientist/"><em>The Smart, the Stupid, and the Catastrophically Scary: An Interview with an Anonymous Data Scientist</em></a></p><p>What you don’t want is someone that knows enough to bullshit you but not enough to get it right. An indicator that you might have the right person is the phrase: ‘‘I’m not sure’’ or ‘‘ it depends on…’’. In these fields, the vast majority of so-called experts add no value at best or negative value at worst.</p><p>[2] This is what I admired so much about Systrom’s and Krieger’s Instagram. Their almost zen-like essentialism. No bloating, no fluff, trying very hard to take away things as they did about adding things. How many new features did they launch in a month before their Facebook acquisition? How many new features does IG launch now per month? </p><p>I’m not saying adding new features is bad. I’m also not saying that a company shouldn’t scale. The point I’m making is that entropy is real. It’s much easier for your product to become worse, than it is to become better. So if that’s not a core focus, it probably won’t happen by accident.</p><p>But scale and improvements in user love (which follow from a better service/product) are not mutually exclusive. Apple provides a data point. Especially during the Jobs reign. </p><p><em>More on this in the essay series: </em><a href="https://www.younglingfeynman.com/essays/deeplove"><em>Do You Have Customers Who Deeply Love You?</em></a><em> </em></p></div></div></div>]]>
            </description>
            <link>https://www.younglingfeynman.com/essays/misleadingdata</link>
            <guid isPermaLink="false">hacker-news-small-sites-25547602</guid>
            <pubDate>Sun, 27 Dec 2020 00:20:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The cost of a Ruby threads leakage]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25547555">thread link</a>) | @mooreds
<br/>
December 26, 2020 | https://mensfeld.pl/2020/12/the-hidden-cost-of-a-ruby-threads-leakage/ | <a href="https://web.archive.org/web/*/https://mensfeld.pl/2020/12/the-hidden-cost-of-a-ruby-threads-leakage/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://mensfeld.pl/2020/12/the-hidden-cost-of-a-ruby-threads-leakage/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25547555</guid>
            <pubDate>Sun, 27 Dec 2020 00:10:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kit FUI – User interfaces found in films]]>
            </title>
            <description>
<![CDATA[
Score 96 | Comments 17 (<a href="https://news.ycombinator.com/item?id=25547352">thread link</a>) | @ChrisArchitect
<br/>
December 26, 2020 | https://www.saji8k.com/kit-fui/ | <a href="https://web.archive.org/web/*/https://www.saji8k.com/kit-fui/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<div>
				
				<p>User interfaces from film, television, video games and the designers that created them.</p>
				<p>Keep track of updates to Kit FUI on my <a href="https://www.saji8k.com/blog/">blog</a> or by following me on <a href="https://twitter.com/saji8k">Twitter</a> or <a href="https://www.facebook.com/saji8k">Facebook</a>.</p>
				<p>If you have suggestions for the site or would like to submit your work, send me a <a href="https://twitter.com/saji8k">tweet</a>.</p>
			</div>
		</div><div>
			<div>
				<h3>What is FUI?</h3>
				<p>Fantasy User Interfaces, Fictional User Interfaces, Fake User Interfaces, Futuristic User Interfaces, Film User Interfaces, Future User Interfaces. Regardless of what the F stands for, they all represent the same thing, the user interfaces (UIs) and heads up displays (HUDs) found in many popular movies and television shows.</p>
				<p>Most FUIs are not actual computer programs but simply animations being played back at the correct time or added in post production. These graphics and animations are designed in applications like Adobe Illustrator, Adobe After Effects and Maxon Cinema 4D.</p>
			</div>
		</div></div>]]>
            </description>
            <link>https://www.saji8k.com/kit-fui/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25547352</guid>
            <pubDate>Sat, 26 Dec 2020 23:34:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Run More Stuff in Docker]]>
            </title>
            <description>
<![CDATA[
Score 139 | Comments 178 (<a href="https://news.ycombinator.com/item?id=25547205">thread link</a>) | @psxuaw
<br/>
December 26, 2020 | https://jonathan.bergknoff.com/journal/run-more-stuff-in-docker/ | <a href="https://web.archive.org/web/*/https://jonathan.bergknoff.com/journal/run-more-stuff-in-docker/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<div>
	
	<h6>
		<span>2020-03-10</span>

		
		<span>
			
			<a href="https://jonathan.bergknoff.com/tags/tech/">tech</a>
			
			<a href="https://jonathan.bergknoff.com/tags/programming/">programming</a>
			
		</span>
		
	</h6>
	<hr>
	<p>In 2020, <strong>Docker is the best medium for distributing and running most developer-facing software</strong>. It’s widely accepted that Docker is great for building and deploying the artifacts for your enterprise web app, but this is less well known when it comes to things like developer tools. However, running tools in containers has many benefits over installing and running them in the conventional way, and we should all start doing it more.</p>
<h2 id="why">Why?</h2>
<p>I install very few things on either my personal or work computer. I don’t have <code>terraform</code>, <code>aws</code>, <code>node</code>, or <code>pip</code> installed, but I use them all the time. I have a Docker image for each, and I run them in containers with minimal privileges. I’m definitely <a href="https://github.com/jessfraz/dockerfiles">not the only one</a>, but it’s not as popular as it should be. None of these tools actually need full access to my computer to do their work, but that is normally how they’re run.</p>
<p>Here are some benefits of running these tools in Docker.</p>
<h4 id="cross-platform">Cross-platform</h4>
<p>At this point in time, Docker is ubiquitous and you get cross-platform support for free, thanks to Docker Inc’s investments in that area (Docker for Mac &amp; Windows). This is useful both for people developing/distributing tools, and for people working on a team that needs to share tooling. You have one Docker image and it will run pretty much everywhere. OS package managers can be great, but they’re very much not cross-platform. Things like <code>pip install</code> will sometimes work cross-platform, but have other serious drawbacks.</p>
<p>While every platform has its own sandboxing mechanisms, running with Docker lets you specify runtime context and enforce a sandbox in a cross-platform way, which is useful when you expect anybody else to run the same command as you.</p>
<h4 id="sandboxed">Sandboxed</h4>
<p>When you <code>docker run</code>, you have to be explicit about privileges. A container is mostly sandboxed and unprivileged by default. It doesn’t have access to ambient environment variables. It doesn’t have access to the host system’s disk. A tool like <code>jq</code> just needs to read stdin and print to stdout. It doesn’t need access to my shell’s environment variables (or, if it does, I explicitly pass those through to the container). <code>yarn</code> should be fine operating on just the working directory, and maybe a cache directory. I don’t want it to have access to my ~/.aws directory (for <a href="https://securityboulevard.com/2020/01/malicious-npm-package-exfiltrating-data-from-unix-systems/">obvious reasons</a>).</p>
<p>Some tools do need access to things. I want my <code>aws</code> CLI to be able to read ~/.aws, so I grant that explicitly. This makes running the tool more verbose but less magical.</p>
<h4 id="simple-uniform-interface">Simple, uniform interface</h4>
<p>Running a program in a container is a lot like running it normally, but the user doesn’t need to jump through hoops to configure the system, build and install. The developer of the image jumps through those hoops and produces a runnable artifact with a simple interface. That interface is the same whether the tool was written in Python or Rust or C or anything else.</p>
<p>Downloading a pre-compiled binary is almost like this, except with worse odds. Maybe there’s a build for your architecture. If it was statically linked, you’re golden. Otherwise, use <code>ldd</code> to reverse engineer the fact that you need to install <code>libjpeg</code>.</p>
<p>A Docker image “just works”. It comes bundled with what it needs to run.</p>
<p>If you think about it, it’s pretty strange to execute <a href="https://github.com/aws/aws-cli/tree/0b3d9a4260fdda5c6a8b736439e0776bc2252f41#installation"><code>pip install awscli</code></a>. It’s immaterial to an end user that the tool is written in Python, and requiring him or her to set up and use Python tooling doesn’t make sense. I don’t mean to pick on <code>pip</code> or <code>awscli</code> in particular, but this is a poor mechanism for distributing non-library software. It leaves <a href="https://github.com/aws/aws-cli/issues?q=is%3Aissue+pip">far too much to chance</a>. It’s a clumsy and leaky interface for tool distribution. So is <code>npm install</code>. So is telling somebody to install your tool by installing golang, and then running <code>go build</code>. No, thanks. If I’m hacking on the project, then by all means. But don’t foist that on end users.</p>
<h4 id="facilitates-version-pinning">Facilitates version pinning</h4>
<p>When collaborating, it’s important that people run the same versions of software to get consistent results. Version pinning is essential to that. Pinning dependency manifests is good, but it’s not enough: it only covers the one situation of installing things with a language package manager. It may not cover using the same linter version, or the same version of <code>node</code>, <code>aws</code>, <code>ansible</code>, <code>terraform</code>, or any libraries installed at the OS level. Invoking <code>docker run node:13.10.1</code>, instead of whatever the user happens to have installed as <code>node</code>, solves this problem in general. Having the ability to specify the versions at the point of use, rather than out-of-band as part of some other installation process, is also convenient and tidy.</p>
<p>It’s easy to run different versions of a tool side by side with Docker. Docker solves this more generally than things like virtualenv for Python, rvm for Ruby, etc. You specify what version of the tool to use when you’re invoking it, and it pins a whole lot of context more than just the tool’s version, which is always preferable for reproducibility.</p>
<p>In one recent situation at work, we had a test case start failing when we upgraded our runtime from Python 3.6.5 to Python 3.6.8. Having the ability to easily run the tests with any version of Python made it easy to bisect and identify a change in 3.6.7 as the cause. This could have been debugged without Docker, but it was particularly natural and easy with Docker.</p>
<h4 id="reproducible">Reproducible</h4>
<p>Invoking a tool with <code>docker run</code> should specify everything needed to reproducibly run it somewhere else. It’s running some specific version of the tool? Okay. It needs my AWS credentials? Okay. It needs some specific combination of environment variables set? Okay.</p>
<p>I cringe when I see a Makefile or build instructions saying to run <code>yarn</code> or <code>terraform</code> or <code>go</code>. What version? What’s being assumed about my environment? Maybe this worked on your <a href="https://martinfowler.com/bliki/SnowflakeServer.html">unique snowflake of a machine</a> 18 months ago, but good luck with it now. (My laptop is a unique snowflake too. Everyone’s is, until we all figure out how to use NixOS.)</p>
<p>Running tools in Docker, there are few expectations of the runtime environment beyond having Docker installed. All the other requirements should be made explicit in the <code>docker run</code> command. The command that you’re running locally will work the same on your colleague’s machine, and in any CI with minimal configuration (or none). This is absolutely critical, especially when working on a team. This is a far more robust approach than expecting (requiring) anybody’s system, or a CI slave, to be set up “just so”.</p>
<h4 id="minimizes-global-state">Minimizes global state</h4>
<p>I have very few things installed on my host system beyond the base OS. There’s less to remember when setting up a new machine, fewer things to go wrong during upgrades, and fewer opportunities for conflicts over shared libraries.</p>
<h2 id="examples">Examples</h2>
<h4 id="one-offs">One-offs</h4>
<p>I have bash aliases for a bunch of tools that I run all the time. These are just for my own convenience. For anything shared with other people, I’d use a project’s Makefile (see below).</p>
<ul>
<li>
<p><strong>Some basics</strong></p>
<pre><code>alias aws='docker run --rm -v ~/.aws:/.aws -v "$(pwd)":"$(pwd)" -w "$(pwd)" -u 1000:1000 -e AWS_PROFILE mikesir87/aws-cli:1.18.11 aws'
alias jq='docker run -i --rm jess/jq jq'
alias terraform='docker run -it --rm -v ~/.aws:/.aws -v "$(pwd)":"$(pwd)" -w "$(pwd)" -u 1000:1000 hashicorp/terraform:0.12.23'
</code></pre><p>With these aliases, I can <code>AWS_PROFILE=... aws sts get-caller-identity | jq -r .Arn</code> as if they were “really” installed.</p>
</li>
<li>
<p><strong>zoom</strong></p>
<p>Here’s zoom (video conferencing):</p>
<pre><code>alias zoom='xhost +local:docker \
    &amp;&amp; docker run -it --rm -v /tmp/.X11-unix:/tmp/.X11-unix -e DISPLAY \
    --device /dev/video0 --device /dev/snd:/dev/snd --device /dev/dri -v /dev/shm:/dev/shm \
    -v ~/.config/zoom/.zoom:/root/.zoom -v ~/.config/zoom/.config/zoomus.conf:/root/.config/zoomus.conf \
    jess/zoom-us'
</code></pre><p>Notice that <a href="https://medium.com/bugbountywriteup/zoom-zero-day-4-million-webcams-maybe-an-rce-just-get-them-to-visit-your-website-ac75c83f4ef5">port 19421</a> remains stubbornly closed unless we explicitly let the container claim it on the host.</p>
</li>
<li>
<p><strong>Snes9x</strong></p>
<p>I do this with other stuff, too. Here’s Snes9x (can you imagine <a href="http://www.snes9x.com/phpbb3/viewtopic.php?t=23603">installing it</a>?):</p>
<pre><code>alias snes9x='docker run -it --rm -u 1000:1000 -v /tmp/.X11-unix:/tmp/.X11-unix -e DISPLAY \
    -v /run/dbus:/run/dbus -v /dev/shm:/dev/shm \
    --device /dev/snd --device /dev/dri --device /dev/input/js0 \
    -e PULSE_SERVER=unix:$XDG_RUNTIME_DIR/pulse/native -v $XDG_RUNTIME_DIR/pulse/native:$XDG_RUNTIME_DIR/pulse/native \
    --group-add $(getent group audio | cut -d: -f3) \
    -v ~/.config/snes9x:/.snes9x/ -v ~/Games/SNES:/SNES -v ~/.local/share:/.local/share \
    danniel/snes9x'
</code></pre></li>
</ul>
<h4 id="projects">Projects</h4>
<p>For things that are project-specific, or in a team setting, all useful commands should be codified in something like a Makefile. This wraps the complexity and verbosity of the <code>docker run</code> incantations, makes it possible to share them easily, and makes them passably ergonomic.</p>
<ul>
<li>
<p><strong>hugo</strong></p>
<p>When I’m writing an article for this site, I run <code>make hugo-watch</code> and load http://localhost:1313 in a web browser:</p>
<pre><code>hugo = docker run --rm -u $$(id -u):$$(id -g) -v "$$(pwd)":/src -v "$$(pwd)"/output:/target $(2) klakegg/hugo:0.54.0-ext-alpine $(1)

hugo-watch:
    mkdir -p output
    $(call hugo, server, -it -p 1313:1313)
</code></pre></li>
<li>
<p><strong>prettier</strong></p>
<p>To format a JavaScript project, we might have the make targets</p>
<pre><code>prettier = docker run -i --rm -v "$$(pwd)":"$$(pwd)" -w "$$(pwd)" elnebuloso/prettier:1.19.1 $(1) "src/**/*.js"

format:
    $(call prettier)

format-check:
    $(call prettier, --check)
</code></pre><p>We would run <code>make format</code> to format the code and <code>make format-check</code> to check the style. It runs on my Linux box, it runs on my colleague’s Mac, and it runs in any Docker-equipped CI. None of those machines need to have <code>node</code>, <code>npm</code>, or <code>prettier</code> installed. We completely trivialize the issues of versioning and of synchronizing our environments: the version is specified once, here in the Makefile, and it’s obeyed everywhere.</p>
<p>In a language like Python, where libraries are forced to fight to the death for control of transitive dependency versions, lifting a tool like <code>black</code> or <code>flake8</code> out of the project’s requirements.txt, and into a self-contained Docker image, can be a big …</p></li></ul></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jonathan.bergknoff.com/journal/run-more-stuff-in-docker/">https://jonathan.bergknoff.com/journal/run-more-stuff-in-docker/</a></em></p>]]>
            </description>
            <link>https://jonathan.bergknoff.com/journal/run-more-stuff-in-docker/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25547205</guid>
            <pubDate>Sat, 26 Dec 2020 23:10:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lost nuclear device atop of Nanda Devi]]>
            </title>
            <description>
<![CDATA[
Score 164 | Comments 75 (<a href="https://news.ycombinator.com/item?id=25547123">thread link</a>) | @hudvin
<br/>
December 26, 2020 | https://www.livehistoryindia.com/cover-story/2020/09/18/nanda-devi-nuclear-device | <a href="https://web.archive.org/web/*/https://www.livehistoryindia.com/cover-story/2020/09/18/nanda-devi-nuclear-device">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    <section>
                        <div id="container">
                          
  <div>
    


<div id="story-f889b712-c891-4d7d-b740-a08c112f512d" data-public-preview="">
  <article data-story-url="" data-story-content-id="f889b712-c891-4d7d-b740-a08c112f512d" data-story-version-id="f2394ab5-e6e4-492d-a5d0-8de23eb757bc" data-story-headline="Nanda Deviâ€™s Nuclear Secret and a Botched CIA Operation" data-loader="story">
    
          <div>
    <figure>
        <img src="https://images.assettype.com/indynetwork%2F2020-09%2Fde00724b-9ea2-4f38-82dc-ca78b3e6dee0%2FImage_9.jpg?w=1500">
    </figure>
</div>
<div>
  <div>
    
    <div itemprop="articleBody" data-story-content-id="f889b712-c891-4d7d-b740-a08c112f512d" data-story-version-id="f2394ab5-e6e4-492d-a5d0-8de23eb757bc">
      
                        
              <div data-card-content-id="efdfb573-ba3e-4852-b9ee-0486b7498411" data-card-version-id="49dda451-df77-4ea6-9f9b-3d28a0f6cf13">
        
      <div id="inf-card-b26a2f55-462c-4ea2-bbd2-fa63429051da" data-story-element-id="b26a2f55-462c-4ea2-bbd2-fa63429051da" data-story-element-type="text">
          <div>
    <p>The past few months have seen a rise in volatility along the Indo-Tibetan border, with the forces of both India and China coming to blows. While these events are extraordinary in present times, the border has witnessed far more heated exchanges, most notably during the 1962 <a href="https://www.livehistoryindia.com/in-the-news/2020/06/21/across-the-karakorams">Indo-China</a> War.</p><p>The unforgiving terrain that marks the frontier creates an additional dimension to the already complex nature of these clashes, whether in regard to more conventional manoeuvres, or other irregular military activity which is far more frequent. This is the story of the latter kind of action, that of daring espionage against Communist China, played for the highest stakes with the greatest risks.</p>
  </div>
</div>



      <div id="inf-card-33d483b8-2c77-4958-ae3b-52863623292b" data-story-element-id="33d483b8-2c77-4958-ae3b-52863623292b" data-story-element-type="text">
          <div>
    <p>Cold, harsh, inviolate. Straddling between the <a href="https://www.livehistoryindia.com/snapshort-histories/2017/06/21/kumaon-echoes-of-the-past">Kumaon</a> and Garhwal districts of Uttarakhand, deep in the Himalayas, stands Nanda Devi. The second-highest mountain in India, towering at an astonishing 25,646 feet, it is named after the patron goddess of Uttarakhandâ€” the mountain being her temporal manifestation.</p><p>Its unique topographical environment makes it one of the most inaccessible places on Earth. Surrounded on three sides by massive mountain rampartsâ€”its natural fortifications measuring at no point below 17,000 feetâ€” only the narrow and dangerously steep Rishi Ganga river gorge allows access to it. The mountain in itself is a citadel of rock and ice, with steep, angled faces and avalanche-prone ridges guarding its summit. Its immense proportions make it far tougher to climb than Everest. It is at once a supremely magnificent and terrifyingly intimidating mountain.</p>
  </div>
</div>



      <div id="inf-card-67773953-dcf2-46a7-97f1-a20310e389b8" data-story-element-id="67773953-dcf2-46a7-97f1-a20310e389b8" data-story-element-type="image">
  <div>
  <figure>
    <img alt="Map of the Nanda Devi Sanctuary, the thick hachures marking the semi-circular natural fortifications in the form of mountains that surround most of the Nanda Devi" src="https://images.assettype.com/indynetwork%2F2020-09%2F65d1a1da-2c67-4059-aeb0-c5437f7f191d%2FImage_3.jpg?w=1170">
  </figure>
              
  
</div></div>



      <div id="inf-card-ec4beaa1-a291-4fc9-9b8c-2d33f3d21e38" data-story-element-id="ec4beaa1-a291-4fc9-9b8c-2d33f3d21e38" data-story-element-type="text">
          <div>
    <p>For much of the 19th and early 20th century, before it was finally summited in 1936, it was considered to be the third pole â€“ a point of virtual inaccessibility. However, this awe-inspiring creation of nature shelters a device, abhorrent to nature, manufactured by man. Somewhere high on the harrowing slopes of Nanda Devi, buried deep in snow, lies a lost nuclear listening device slowly depleting its plutonium cores. Containing 5kg of plutonium â€“ 1 kg less than the nuclear bomb dropped on Nagasaki â€“ with a predicted lifespan of 900 years, this nuclear trespasser has been forfeited to the mountain forever.</p><p>This is the story behind one of the most audacious acts of espionage in the 20th century.</p>
  </div>
</div>



  </div>

              <div data-card-content-id="5350a04d-7e5b-48a5-9ccc-0c0b06771394" data-card-version-id="b82a93e5-a227-4175-b91c-b1fe616b5c7c">
        
      <div id="inf-card-d8876be2-71a7-431c-833b-2d0c39d14b6e" data-story-element-id="d8876be2-71a7-431c-833b-2d0c39d14b6e" data-story-element-type="text">
          <div>
    <p><strong>Cold War In High Places</strong></p><p>The year was 1965, and the Cold War was reaching its apogee, with America stretching its geopolitical reach to all corners of the world in order to counter the communist influence. Closer to home, the War of â€™62 had left India intensely wary of its neighbour, China. To add fuel to simmering embers, China carried out its first nuclear test in 1964 in Xinjiang, a province that borders the northern tip of India. In this atmosphere of intense mutual suspicion and paranoia, the Pentagon began concocting a plan that would help both India and America keep a closer eye on China, especially with regard to its nuclear programme.</p><p>With satellites that could gather useful photographic intelligence still a few years away, Americaâ€™s Central Intelligence Agency (CIA) along with the Indian Intelligence Bureau (IB) planned on placing a powerful listening device at a point of extreme prominence along the Indo-Tibetan border. The site where the device would be placed was key as it would need to have uninterrupted access in order to intercept Chinese radio signals. This meant it would have to be positioned on a mountain that was high as well as close to the Tibetan plateau. With an unparalleled height advantage and an unobstructed view of China from its summit, there was no better choice than Nanda Devi.</p>
  </div>
</div>



      <div id="inf-card-21631012-ab2e-4940-a233-267421b9382d" data-story-element-id="21631012-ab2e-4940-a233-267421b9382d" data-story-element-type="text">
        <div>
     <hr>
  <div>
    <blockquote>To ensure the longevity and endurance of the device, which was supposed to work at an altitude of nearly 26,000 feet, it was decided that it would be nuclear-powered. </blockquote>
  </div>
  <hr>
</div>
  </div>



      <div id="inf-card-ac913b24-39b9-4cc4-9553-78b1b163d63d" data-story-element-id="ac913b24-39b9-4cc4-9553-78b1b163d63d" data-story-element-type="text">
          <div>
    <p>A System for Nuclear Auxiliary Power (SNAP) generator was designed so that it would power the telemetry functions of the device, a power unit similar to the ones being used in space at the time.</p><p>It was within the SNAP that seven plutonium fuel rods would be stored, made from a compound of Pu-238 and Pu-239. Once activated, the SNAP would constantly be converting radioactive heat energy created by the rods into electricity, which would power the multiple-sensor device as well as its six-foot-long antenna.</p><p>With the technical aspect settled, the question of who would carry and set up all this equipment remained. Only two expeditions had summited the mountain up until then, and more than a few climbers had died. There was no doubt that only the very best mountaineers could be trusted to carry a nuclear payload up one of the most difficult mountains in the world.</p>
  </div>
</div>



  </div>

              <div data-card-content-id="5aeaa671-5f93-450a-971d-b5690e92888f" data-card-version-id="58f0cfc2-71cc-46c3-a836-d90e638e4071">
        
      <div id="inf-card-a3cc2b9a-78bd-4006-bf8a-64632fc034d2" data-story-element-id="a3cc2b9a-78bd-4006-bf8a-64632fc034d2" data-story-element-type="text">
          <p><strong>League of Extraordinary Climbers</strong></p>
</div>



      <div id="inf-card-44cd66b4-c4c0-4956-b7f2-a5354b09a54c" data-story-element-id="44cd66b4-c4c0-4956-b7f2-a5354b09a54c" data-story-element-type="image">
  <div>
  <figure>
    <img alt="Captain MS Kohli AVSM, leader of the covert climbing expeditions, now at the ripe old age of 88. " src="https://images.assettype.com/indynetwork%2F2020-09%2Faea6959e-2270-436f-bbd2-426467f4f81b%2FImage_8.jpg?w=1170">
  </figure>
              
  
</div></div>



      <div id="inf-card-9a85c853-4586-48c3-95f7-70072afd02f2" data-story-element-id="9a85c853-4586-48c3-95f7-70072afd02f2" data-story-element-type="text">
          <div>
    <p>A group of 14 American and four Indian mountaineers was assembled. In totality, they represented the cream of a mountaineering generation. Among the Americans, some of the more famous climbers were Dr Robert Schaller, Tom Frost and Jim McCarthy. The Indian contingent consisted of Captain M S Kohli, Sonam Wangyal, H C S Rawat and G S Bhangu. All four had been members of the successful 1965 Indian Everest Expedition, which had put a record nine climbers on the summit. They were in fact enlisted for this covert expedition just a few days after returning from Everest. Together, the entire group was no less than a mountaineering dream team.</p><p>After having sworn their respective oaths of secrecy, the climbing team was flown to Mount McKinley in Alaska, the highest mountain in North America, to prepare for the arduous expedition ahead. While all of them were without doubt among the most experienced climbers at the time, they were rather new to the more idiosyncratic aspect of the expedition â€“ that of dealing with nuclear material.</p><p>American climber Jim McCarthy was appointed as the designated member of the team who would handle the plutonium rods. Through the summer of 1965, officials from Americaâ€™s Atomic Energy Commission trained McCarthy to load and unload the device without disturbing its deadly occupant. Other team members were briefed on the dangers of their special load as well, and ways to ensure minimum exposure to the deadly radioactive isotopes.</p><p>All climbers were going to be paid $1,000 per month, a hefty amount in the 1960s. While there would be personal gratification from having been of service to their respective nations, they were on no account to tell anyone about the nature of their expedition. The cover for the entire team was that they were a joint Indo-American mountaineering team conducting research for high-altitude flight for the American Air Force. Before departing for India, the covert operation was finally given its official codename: Operation Hat.</p>
  </div>
</div>



      <div id="inf-card-368b8863-5e90-4a6b-8a7e-47a26beda04f" data-story-element-id="368b8863-5e90-4a6b-8a7e-47a26beda04f" data-story-element-type="image">
  <div>
  <figure>
    <img alt="A Nanda Devi Temple at Munsiyari. This particular temple, and itâ€™s idol inside, is among the oldest of Uttarakhand" src="https://images.assettype.com/indynetwork%2F2020-09%2F49dfca8c-132b-43f5-b063-81b86f25e855%2FImage_5.jpg?w=1170">
  </figure>
              
  
</div></div>



      <div id="inf-card-5a316079-59a0-4a73-9dd2-5edab677f0f6" data-story-element-id="5a316079-59a0-4a73-9dd2-5edab677f0f6" data-story-element-type="text">
          <div>
    <p><strong>Into the Sanctuary of the Goddess</strong></p><p>In an effort to attract minimal attention, most of the mountaineers were flown into base camp by helicopter in September 1965. However, the climbing equipment, rations, and of course the listening device itself â€” stored inside a solid lead casket â€” were transported in the time-honoured fashion, carried by nearly 150 <em>dotial</em> porters through the Rishi Ganga gorge. The special load did not go unnoticed among the porters, and apart from its unusual weight, many of them alleged to have felt heat emanating from the casket. Mounted on poles, some climbers later noted its uncanny resemblance to the Biblical Ark of the Covenant, in the manner it was transported as well as the supreme power it possessed.</p><p>After having established themselves at the base of the mountain, the mountaineers methodically began making their way up Nanda Devi. Establishing a series of camps along the climbing route, the team was finally positioned to make an attempt on the summit in the middle of October. It was then that catastrophe struck.</p><p>A violent storm hit the mountain and made it impossible to continue. The summit team, along with the device, was encamped just 2,000 feet below their objective. The extreme conditions, however, greatly endangered their position. Keeping in mind the extreme volatility of such storms, Captain Kohli â€” the leader of the climbing team â€” called for an immediate retreat.</p>
  </div>
</div>



  </div>

              <div data-card-content-id="65e7e1e4-a3b0-4ec4-9aaa-c4696502703a" data-card-version-id="344b6037-e7b7-4181-b199-8bea1745da05">
        
      <div id="inf-card-6d7e221c-28e2-4bd3-ac8f-475267b102e9" data-story-element-id="6d7e221c-28e2-4bd3-ac8f-475267b102e9" data-story-element-type="text">
          <div>
    <p>Carrying the 56 kg listening device in deteriorating weather conditions at 23,000 feet was going to be a Herculean task. Prioritising the need for a quick descent to minimise the risk to the lives of his fellow climbers, Kohli decided to ditch the equipment in the high camp. He reasoned that another expedition could always be mounted when weather conditions improved, in order to retrieve the device. On the other hand, the life of a fellow climber was irreplaceable.</p><p>Thus, with all the climbers having safely descended, the expedition came to an end. Being late in the year, the weather window to climb Nanda Devi was now closed. Any new expedition would have to bide their time till the following year. The nuclear device too, abandoned on a high precipice of the mountain, would have to wait.</p><p><strong>Plan B</strong></p><p>With the arrival of spring in 1966, a second expedition was launched to locate the equipment, and most importantly the nuclear device, that had been left the previous autumn. The composition of the climbing team was more or less the same, and soon they were scouring the slopes of Nanda Devi, trying to find their highly valuable and potentially dangerous belongings. But it was all …</p></div></div></div></div></div></div></article></div></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.livehistoryindia.com/cover-story/2020/09/18/nanda-devi-nuclear-device">https://www.livehistoryindia.com/cover-story/2020/09/18/nanda-devi-nuclear-device</a></em></p>]]>
            </description>
            <link>https://www.livehistoryindia.com/cover-story/2020/09/18/nanda-devi-nuclear-device</link>
            <guid isPermaLink="false">hacker-news-small-sites-25547123</guid>
            <pubDate>Sat, 26 Dec 2020 22:58:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A New Google]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25547085">thread link</a>) | @tosh
<br/>
December 26, 2020 | https://dcgross.com/a-new-google?src=t | <a href="https://web.archive.org/web/*/https://dcgross.com/a-new-google?src=t">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>   <p>[TL;DR: Google has gotten bad; we all know it; ideas for a startup making a better Google.]</p> <p>In 2000, Google got popular because hackers realized it was better than Lycos or Excite. This effect is happening again. Early adopters aren’t using Google anymore.</p> <p>They aren’t using DuckDuckGo either. They’re still using Google.com, but differently. To make Google usable, users are adding faux-query modifiers that to supress the “garbage Internet”.</p> <p>You see this in the typeahead logs.</p> <p><img src="https://dcgross.com/assets/new-google/image6.png" alt=""> <em></em></p><center><em>Products (Reddit)</em></center> <p><img src="https://dcgross.com/assets/new-google/image4.png" alt=""> <em></em></p><center><em>Services (Reddit, Yelp)</em></center> <p><img src="https://dcgross.com/assets/new-google/image1.png" alt=""> <em></em></p><center><em>Movies (Rotten Tomatoes)</em></center> <p><img src="https://dcgross.com/assets/new-google/image5.png" alt=""> <em></em></p><center><em>Even code (Github)</em></center> <p>Interestingly, this doesn’t work for all categories. <img src="https://dcgross.com/assets/new-google/image3.png" alt=""> <img src="https://dcgross.com/assets/new-google/image2.png" alt=""> <em></em></p><center><em>Recipes don’t have a “Reddit” equivalent</em></center> <h3 id="query-operators-mean-somethings-broken">Query Operators Mean Something’s Broken</h3> <p>More advanced users use modifiers like <code>site: filetype: intitle:</code> because adding “reddit” isn’t strict enough, as spammy websites often manipulate content to win SEO.</p> <p>How about those websites that stuff the year in the title? “Reviews UPDATED JANUARY 2020” are exploiting the fact that customers suffix queries with the year. What those people are trying to command is freshness, not a title match.</p> <p>Something’s broken, and a tiny share of Google is open for the taking. Obviously attacking incumbents head-on doesn’t work. Here are two alternative ideas for bootstrapping next-generation search:</p> <h3 id="1-boogle-a-query-reformulator">#1 Boogle, A Query Reformulator</h3> <p>Introducing Boogle, a proxy for Google that’s just Better Google Search. It’s a query expander. We predict the correct operators for your query, proxy Google’s results, and serve. For example:</p> <p><code>query("stripe.js example") -&gt; query("stripe.js example (site:github.com OR site:gitlab.com OR site:..."))</code></p> <p><code>query("is anker charger") -&gt; query("is anker charger (inurl:forum OR site:reddit.com OR ...))"</code></p> <p>Query topic modeling is a rich science with plenty of examples.</p> <p>You’d almost as fast as Google, never worse, and occasionally better. This will help build the reflex to use you instead. This approach isn’t that hard to get started with, and might work for the high-end users.</p>  <p>You could go after this vertical by vertical – build the <em>best</em> site for electric product search, for travel, for code, etc. A key question is how to build habitual recall to use your product over Google. Amazon and Airbnb both enjoy a huge amount of direct traffic. Some learnings from those:</p> <ul> <li><strong>Stellar mobile destination.</strong> Using Airbnb directly feels more fluid and fun than using Google for Airbnb.</li> <li><strong>The 90% Rule.</strong> To build reflex you need to give me what I want most of the time.** **With Prime, Amazon made it such that we stopped price comparing across other sites; Amazon would get it to us fastest, and that turns out to matter more than price. Most of the time you open Amazon.app, it satisfies.</li> <li><strong>Come for search, stay for something else.</strong> I don’t think of Airbnb or Amazon as search apps. They help me get things or book homes. You might want to your search app to be a destination for something else. This is where I think community comes in.</li> </ul> <p>Picking a vertical that <em>doesn’t</em> have strong typeahead completions[1] would help you build community around your search engine. Recipes, fitness, fashion, etc. don’t have decacorn conglomerates like Github or Reddit. That might mean it’s easier to build community around them, and put your flagship search engine on top.</p> <hr> <p>If you’re working on this kind of stuff, try out <a href="https://pioneer.app/">Pioneer</a> or just shoot me an email – daniel@pioneer.app.</p> <hr> <p>[1] In reality I’d pick the vertical _I _love most. If you’re a guitar player start with music; a movie buff should build better Rotten Tomatos. Etc.</p> </article></div>]]>
            </description>
            <link>https://dcgross.com/a-new-google?src=t</link>
            <guid isPermaLink="false">hacker-news-small-sites-25547085</guid>
            <pubDate>Sat, 26 Dec 2020 22:51:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You're Allowed to Make Your Own Tools]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25547008">thread link</a>) | @janniks
<br/>
December 26, 2020 | https://www.swyx.io/make-your-own-tools/ | <a href="https://web.archive.org/web/*/https://www.swyx.io/make-your-own-tools/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>I read a list of <a href="https://milan.cvitkovic.net/writing/things_youre_allowed_to_do/">Things You're Allowed To Do</a> on Hacker News recently. These are useful reminders for a well paid, technical audience, but one thing stuck out to me: <strong>It didn't mention making your own tools</strong>. Not even once.</p>
<p>Even the greatest software has parts that aren't so great for you. But the difference between you and everyone else is that you can code.</p>
<p>Here's a list of tools (<em>that you don't need anyone's permission</em>) to code for yourself:</p>
<ul>
  <li><strong>You can make your own Stylesheet</strong>: Long before <a href="https://twitter.com/swyx/status/1336363173838909441">GitHub got Dark Mode</a>, developers had been making their own with the <a href="https://github.com/openstyles/stylus">Stylus Userstyles Manager</a>.</li>
  <li>
    <strong>You can make your own Query Generator</strong>: Most platforms have advanced features that are poorly documented and don't have good UIs. You can make your own. I made my own <a href="https://twitter.com/swyx/status/1328086859356913664?s=20">Advanced Twitter Search UI</a> embedding all the little tips and tricks that people pass around by word of mouth. I know of two ongoing attempts to <a href="https://twitter.com/swyx/status/1335627133956153344">do the same for Google's advanced operators</a>.
    
    <img src="https://dev-to-uploads.s3.amazonaws.com/i/jntu0l1zk2o3xz8bu5fz.png" alt="Alt Text">
  </li>
  <li><strong>You can make an Inspo Generator</strong>: Projects like <a href="https://whattotweet.com/">What to Tweet</a>, <a href="https://components.ai/">Components.ai</a> and <a href="https://www.doodlestrudel.com/">Doodle Strudel</a> get ridiculously popular compared to their technical complexity - because inspiration loves combinatorial explosions!</li>
  <li><strong>You can make your own scripts</strong>: <a href="https://github.com/NARKOZ/hacker-scripts#hacker-scripts">Like this guy</a>. Developers have apparently been automating coffee machines for so long that I recently learned that the infamous <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/418">HTTP Error 418</a> was inspired by an actual real life situation.</li>
  <li><strong>You can make your own CLIs</strong>: CLIs are essentially interactive scripts. If you do JavaScript, I made a course on Egghead about <a href="https://egghead.io/courses/build-custom-command-line-interface-cli-tooling-with-oclif-and-typescript?af=95qfq1">building custom CLIs with oclif and TypeScript</a>!</li>
  <li>
    <strong>You can make personal proxies</strong>: Frustrated with slow searches (I am often on mobile 3G), <a href="https://news.ycombinator.com/item?id=25538586">gamed search results</a>, and <a href="https://twitter.com/shanselman/status/1341583883947544578?s=20">assorted crap in my URLs</a>, I recently <a href="https://twitter.com/swyx/status/1342625544320339969">made my own Google Search proxy</a>. A proxy is different from "just the UI", because it involves setting up a server or serverless function to process data for you. Because you have total control of server data, you have the ability to postprocess, combine, persist, and optimize it for your specific preferences. <a href="https://www.reuters.com/article/dataprivacy-linkedin-datascraping-idUSL2N2GM1ZV">Scraping public data is probably legal</a>, but personal means personal - Be careful about sharing it with others and definitely do not sell it. But this is ethically no different than setting up your own <a href="https://pi-hole.net/">Pi-hole</a>.
    <img src="https://dev-to-uploads.s3.amazonaws.com/i/56r2dhdtgq8qw3qsi3jo.png" alt="Alt Text">
    <blockquote>
      <p>My personal <a href="https://github.com/sw-yx/automation/">cheatsheet of automation resources is available here</a>.</p>
    </blockquote>
  </li>
</ul>
<p>These ideas are great, scoped projects that let you try out new languages and frameworks and improve your quality of life as a side effect. Always wanted to <a href="https://www.swyx.io/svelte-why/">try Svelte</a>? Make a query generator! Want a new CLI? <a href="https://deno.land/posts/v1.6">Deno ships binaries now!</a> <a href="https://supabase.io/">Supabase</a> claims to be an Open Source Firebase Alternative? Put it to the test!</p>
<p>And there's a compounding effect to these as you make them. More often than not, the lessons you learn from making a tool for yourself will find their way into your work. If you get <em>really</em> lucky - <a href="https://medium.com/who-what-why/how-side-projects-saved-our-startup-a83a80f3b3ae">your side projects might even become your life's work</a>.</p>
<p>Don't take it from me. Here's <a href="https://twitter.com/dan_abramov/status/1140259247680315393?s=20">Dan Abramov</a>:</p>
<blockquote>
  <p>Here’s a thing that I learned at FB that I wish I knew much earlier. Invest in building custom tools!</p>
</blockquote>
<blockquote>
  <p>You might think only bigcos make custom tools. But a tool doesn’t have to be sophisticated. It can be a script you could write in a day. And at small and medium companies, even a little effort can yield a huge return. Because <strong>nobody optimized anything yet</strong>.</p>
</blockquote>
<p>The beauty of specializing in moving bits instead of atoms is that we can iterate in minutes, rather than months. That's a skill that customers pay us handsomely for, and we should remember that we can simply be our own customers too.</p>
<blockquote>
  <p>Author's Note: I wrote a longer treatment of the benefits of, and ideas for, Side Projects in <a href="https://www.learninpublic.org/">The Coding Career Handbook</a>. I also commented in <a href="https://www.thekeycuts.com/dear-analyst-50-walking-through-a-vba-script-for-trading-billions-of-dollars-worth-of-derivatives-with-shawn-wang/">the KeyCuts podcast</a> on how all young finance traders make their own pricing tools as a rite of passage — like how <a href="https://starwars.fandom.com/wiki/Knighting_ceremony/Legends#New_Jedi_Order">Jedi make their own lightsabers</a> before becoming Jedi Knights.</p>
</blockquote>
<blockquote>
  <p>If you are making a DevTools startup, I am <a href="https://codingcareer.circle.so/c/devtools">incubating a small community in DX Circle</a>, my proto-blog for investing in Developer Tools and Developer Communities.</p>
</blockquote>
</div></div>]]>
            </description>
            <link>https://www.swyx.io/make-your-own-tools/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25547008</guid>
            <pubDate>Sat, 26 Dec 2020 22:41:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Made a Covid-19 Vaccine in My Kitchen and It Worked – Science Still Sucks]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 28 (<a href="https://news.ycombinator.com/item?id=25546796">thread link</a>) | @emre
<br/>
December 26, 2020 | http://www.josiahzayner.com/2020/12/i-made-covid-19-vaccine-in-my-kitchen.html | <a href="https://web.archive.org/web/*/http://www.josiahzayner.com/2020/12/i-made-covid-19-vaccine-in-my-kitchen.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-9192139371851934751" itemprop="description articleBody">
<p><b><span><p><a href="https://1.bp.blogspot.com/-LHnH4HuYWBY/X9OyNLp5gfI/AAAAAAAAhjE/vuWyJAJ93qw38EegX5RH5_IaFtAXABxLgCLcBGAsYHQ/s2048/logo1.png"><img data-original-height="1809" data-original-width="2048" height="283" src="https://1.bp.blogspot.com/-LHnH4HuYWBY/X9OyNLp5gfI/AAAAAAAAhjE/vuWyJAJ93qw38EegX5RH5_IaFtAXABxLgCLcBGAsYHQ/w320-h283/logo1.png" title="Central Dogma Collective" width="320"></a></p><br>I hate science. It's so elitist.&nbsp;</span></b></p><p>I have an internal dialogue going all the time trying to convince myself that I don't want my work to be called science. What I do is completely different, more sacred, honest and open and yes sometimes flawed. Sometimes I hide the fact that I have a Ph.D. because I don’t want it to be a symbol of authority or intelligence for myself. It also feels douchey to tell people I have a Ph.D. I want to be judged by my actions, not where I went to school, which can be primarily determined by your parents financial status and education level. I grew up on a farm in rural Indiana. We ate eggs from our chickens and drank dehydrated milk. Up until even high school my family was dirt poor. We had our electricity shut-off and had to take cold showers. When we couldn't afford the phone bill, I walked to 7-11 and used the payphone to call my friends. Violence, evictions, car repossessions — you name it, I’ve lived it. Starting undergrad at SIU I was homeless and lived out of my car and slept on the dorm room floors of people I knew.&nbsp;</p><p>When I was in graduate school, 99% of my peers did not come from a similar background. It was abundantly clear that the practice of science and medicine is only accessible to the upper crust. That’s an issue in itself, but the <b><i>f</i></b><i><b>ucking humongous gigantic bigger problem</b></i> is that cutting-edge medicines are also only available to the societal elite. Time and time again throughout this pandemic, we’ve watched as the wealthy and powerful get all the unapproved drugs to treat their covid, while all of us peasants sit back and do our best not to die without them. The 108 Regeneron antibody cocktails all went to Washington DC.</p><p>That’s why I left academia. Why I quit my job at NASA and started doing science as a biohacker. I want everyone to be able to do science without any gatekeepers. The single greatest impediment to diversity in science is access to knowledge and information that is being held tighter than Ric Flair’s Figure Four Leg Lock.</p><p><b><span>Biohackers are setting knowledge free.</span></b></p><p>In May 2020, an article came out in <a href="https://science.sciencemag.org/content/369/6505/806">science magazine</a> where researchers showed that by using a DNA vaccine that codes for the SARS-COV2 spike protein, they could create antibodies that provide protection from covid-19 in macaque monkeys without harmful side-effects. Getting good monkey data is basically the best pre-human data you can ever hope to get. Most people only have experimental data from mouse tests. When I see a paper like this the gears in my brain begin to spin because there is a good chance the FDA would approve this for human testing.</p><p>So, I decided to test it myself. The project perfectly fit a niche where biohackers have an experimental advantage over academia and industry. With enough knowledge and skill, we could perform quick but data-laden experiments to show whether the same DNA vaccine tested on monkeys would be promising in humans. And instead of taking months or years we could have results in as little as a few weeks.&nbsp;</p><p>I brought up the idea with David Ishee and Dariia Dantseva, fellow members of the biohacking group the <a href="http://the-cdc.com/" target="_blank">Central Dogma Collective (CDC)</a>. They also thought that based on the data this would be a fucking crazy project. We decided <a href="https://youtube.com/playlist?list=PLNAhY1w2w78rSeNQo_e0dQ2w8mmGEg7Mr">we would live-stream</a> every step so that people could learn how to do advanced biomedical research like this in their own home. If one were to replicate the experiment from scratch, the total individual cost would end up being around $3500, the major costs being $1600 for DNA synthesis and $1200 for the kits to measure coronavirus spike protein antibodies.</p><p>What I really wanted was to show people how to do the science. I didn't really care if it worked or not but I tend to be pessimistic about my own experiments anyway. While testing and creating a successful coronavirus vaccine would send a powerful message to the world, teaching people how to do advanced biomedical research will change it.&nbsp;</p><p>In the end, the experiment worked. All three of us developed SARS-CoV2 spike protein neutralizing antibodies. I still can't fucking believe it. Not only did we create and test a successful vaccine, we showed that we could get a gene therapy to work (a DNA vaccine changes the DNA in your cells and so is a gene therapy also). <a href="https://docs.google.com/document/d/1WTuRBuy74KlaBzLrd0aTZl852nhPNCWL06aB7wY1JKk/edit?usp=sharing" target="_blank">Here is a summary of the experimental details and results</a> if you are interested. We didn't create the vaccine to sell it. We made the <a href="https://drive.google.com/drive/folders/1SracILuRbiZt4f7EVH2JBvefaHmsOUsC?usp=sharing" target="_blank">nucleotide sequence and genetic design data open and free</a> so that anyone can easily recreate it. All in a state-of-the-art lab. I'm kidding, my lab is a tiny bedroom in a house in West Oakland, David's is in a shed in rural Mississippi and Dariia's is an old building she converted in Ukraine. If your mind isn't blown, you either already knew about the project or you don't understand what I just told you.&nbsp;</p><p><b><span>If you want to know why I created and tested a coronavirus vaccine on myself, it’s because I am at War.&nbsp;</span></b></p><p>I know it sounds a bit dramatic but there really is a class war going on. There is a group of people who are actively making choices that cause a disproportionate amount of deaths among those in lower social classes. New gene therapies cost over a million dollars. That’s right. Your life, your child’s life, your mother, your loved one depends on how much money you make. The government and Pharma companies aren’t going to help you when you can’t afford it either. Most of these gene therapies aren't even available outside the US either because most countries with socialized medicine won't pay for them. So don't tell me how your country's healthcare is better.</p><p>Considering that if you are reading this there is a 99% chance you are not part of the top 1%, let me ask you this — why are we letting the wealthy and powerful get away with this?&nbsp;</p><p>Those who have a monopoly on the understanding and use of biotechnology have all the power. If I, if we can teach people how do it themselves then we win back power.</p><p>This is why biohackers are needed in society.&nbsp;</p><p>Now in Dec. 2020, many people are still holed up waiting for a vaccine. The problem is when a vaccine for covid comes around it won't be the 99% that receive it first. Your life isn't worth that much. You're not important or wealthy or powerful. The people who will receive it first are the same people who can sit out a pandemic in the comfort of their home and have their necessities delivered by the working class. They tell everyone else to social distance and wear a mask but won’t do it themselves. Fucking Gavin Newsom.</p><p>Still, we are losing this class war as people continue to fight against their best interest. They believe lying politicians, lying scientists, and are manipulated by the news media. We are told to wait and trust while hundreds of thousands of people in the US die. While small businesses close at an unprecedented rate, but large corporations make billions.</p><p>What the fuck. They are killing us and taken what we own. Why are we still putting up with this?</p><p><b><span>We can take back what belongs to us by creating for ourselves.&nbsp;</span></b></p><p><b><span>Science and medicine belong to us not them.&nbsp;</span></b><b><span>Biohack the fucking planet</span></b></p>

</div></div>]]>
            </description>
            <link>http://www.josiahzayner.com/2020/12/i-made-covid-19-vaccine-in-my-kitchen.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25546796</guid>
            <pubDate>Sat, 26 Dec 2020 22:03:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Dunning-Kruger Effect Is Probably Not Real]]>
            </title>
            <description>
<![CDATA[
Score 63 | Comments 61 (<a href="https://news.ycombinator.com/item?id=25546787">thread link</a>) | @ingve
<br/>
December 26, 2020 | https://www.mcgill.ca/oss/article/critical-thinking/dunning-kruger-effect-probably-not-real | <a href="https://web.archive.org/web/*/https://www.mcgill.ca/oss/article/critical-thinking/dunning-kruger-effect-probably-not-real">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>I want the Dunning-Kruger effect to be real. First described in<a href="https://doi.apa.org/doiLanding?doi=10.1037%2F0022-3514.77.6.1121"> a seminal 1999 paper</a> by David Dunning and Justin Kruger, this effect has been the darling of journalists who want to explain why dumb people don’t know they’re dumb. There’s even<a href="https://youtu.be/BdnH19KsVVc"> video of a fantastic pastiche</a> of Turandot’s famous aria, <i>Nessun dorma,</i> explaining the Dunning-Kruger effect. “They don’t know,” the opera singer belts out at the climax, “that they don’t know.”</p>

<p>I was planning on writing a very short article about the Dunning-Kruger effect and it felt like shooting fish in a barrel. Here’s the effect, how it was discovered, what it means. End of story.</p>

<p>But as I double-checked the academic literature, doubt started to creep in. While trying to understand the criticism that had been leveled at the original study, I fell down a rabbit hole, spoke to a few statistics-minded people, corresponded with Dr. Dunning himself, and tried to understand if our brain really was biased to overstate our competence in activities at which we suck... or if the celebrated effect was just a mirage brought about by the peculiar way in which we can play with numbers.</p>

<p>Have we been overstating our confidence in the Dunning-Kruger effect?</p>

<h5><b>A misunderstood effect</b></h5>

<p>The most important mistake people make about the Dunning-Kruger effect, according to Dr. Dunning, has to do with who falls victim to it. “The effect is about us, not them,” he wrote to me. “The lesson of the effect was always about how we should be humble and cautious about ourselves.” The Dunning-Kruger effect is not about dumb people. It’s mostly about all of us when it comes to things we are not very competent at.</p>

<p>In a nutshell, the Dunning-Kruger effect was originally defined as a bias in our thinking. If I am terrible at English grammar and am told to answer a quiz testing my knowledge of English grammar, this bias in my thinking would lead me, according to the theory, to believe I would get a higher score than I actually would. And if I excel at English grammar, the effect dictates I would be likely to slightly underestimate how well I would do. I might predict I would get a 70% score while my actual score would be 90%. But if my actual score was 15% (because I’m terrible at grammar), I might think more highly of myself and predict a score of 60%. This discrepancy is the effect, and it is thought to be due to a specific problem with our brain’s ability to assess its skills.</p>

<p>This is what student participants went through for Dunning and Kruger’s research project in the late 1990s. There were assessments of grammar, of humour, and of logical reasoning. Everyone was asked how well they thought they did and everyone was also graded objectively, and the two were compared.</p>

<p>Since then, many studies have been done that have reported this effect in other domains of knowledge. Dr. Dunning tells me he believes the effect “has more to do with being <i>misinformed</i> rather than uninformed.” If I am asked the boiling point of mercury, it is clear my brain does not hold the answer. But if I am asked what is the capital of Scotland, I may think I know enough to say Glasgow, but it turns out it’s Edinburgh. That’s misinformation and it’s pushing down on that confidence button in my brain.</p>

<p>So case closed, right? On the contrary. In 2016 and 2017, two papers were published in a mathematics journal called <i>Numeracy</i>. In them, the authors argued that the Dunning-Kruger effect was a mirage. And I tend to agree.</p>

<h5><b>The effect is in the noise</b></h5>

<p>The<a href="https://scholarcommons.usf.edu/numeracy/vol9/iss1/art4/"> two</a><a href="https://scholarcommons.usf.edu/numeracy/vol10/iss1/art4/"> papers</a>, by Dr. Ed Nuhfer and colleagues, argued that the Dunning-Kruger effect could be replicated by using random data. “We all then believed the [1999] paper was valid,” Dr. Nuhfer told me via email. “The reasoning and argument just made so much sense. We never set out to disprove it; we were even fans of that paper.” In Dr. Nuhfer’s own papers, which used both computer-generated data and results from actual people undergoing a science literacy test, his team disproved the claim that most people that are unskilled are unaware of it (“a small number are: we saw about 5-6% that fit that in our data”) and instead showed that both experts and novices underestimate and overestimate their skills with the same frequency. “It’s just that experts do that over a narrower range,” he wrote to me.</p>

<p>Wrapping my brain around all this took weeks. I recruited a husband-and-wife team, Dr. Patrick E. McKnight (from the Department of Psychology at George Mason University, also on the advisory board of Sense About Science and STATS.org) and Dr. Simone C. McKnight (from Global Systems Technologies, Inc.), to help me understand what was going on. Patrick McKnight not only believed in the existence of the Dunning-Kruger effect: he was teaching it to warn his students to be mindful of what they actually knew versus what they thought they knew. But after replicating Dr. Nuhfer’s findings using a different platform (the statistical computing language R instead of Nuhfer’s Microsoft Excel), he became convinced the effect was just an artefact of how the thing that was being measured was indeed measured.</p>

<p>We had long conversations over this as I kept pushing back. As a skeptic, I am easily enticed by stories of the sort “everything you know about this is wrong.” That’s my bias. To overcome it, I kept playing devil’s advocate with the McKnights to make sure we were not forgetting something. Every time I felt my understanding crystallize, doubt would creep in the next day and my discussion with the McKnights would resume.</p>

<p>I finally reached a point where I was fairly certain the Dunning-Kruger effect had not been shown to be a bias in our thinking but was just an artefact. Here then is the simplest explanation I have for why the effect appears to be real.</p>

<p>For an effect of human psychology to be real, it cannot be rigorously replicated using random noise. If the human brain was predisposed to choose heads when a coin is flipped, you could compare this to random predictions (heads or tails) made by a computer and see the bias. A human would call more heads than the computer would because the computer is making random bets whereas the human is biased toward heads. With the Dunning-Kruger effect, this is not the case. Random data actually mimics the effect really well.</p>

<p>The effect as originally described in 1999 makes use of a very peculiar type of graph. “This graph, to my knowledge, is quite unusual for most areas of science,” Patrick McKnight told me. In the original experiment, students took a test and were asked to guess their score. Therefore, each student had two data points: the score they thought they got (self-assessment) and the score they actually got (performance). In order to visualize these results, Dunning and Kruger separated everybody into quartiles: those who performed in the bottom 25%, those who scored in the top 25%, and the two quartiles in the middle. For each quartile, the average performance score and the average self-assessed score was plotted. This resulted in the famous Dunning-Kruger graph.</p>

<p><img height="627" width="725" src="https://www.mcgill.ca/oss/files/oss/figure_1_3.png" alt=""></p>

<p>Plotted this way, it looks like those in the bottom 25% thought they did much better than they did, and those in the top 25% underestimated their performance. This observation was thought to be due to the human brain: the unskilled are unaware of it. But if we remove the human brain from the equation, we get this:</p>

<p><img height="451" width="1086" src="https://www.mcgill.ca/oss/files/oss/figure_2_1.png" alt=""></p>

<p>The above Dunning-Kruger graph was created by Patrick McKnight using computer-generated results for both self-assessment and performance. The numbers were random. There was no bias in the coding that would lead these fictitious students to guess they had done really well when their actual score was very low. And yet we can see that the two lines look eerily similar to those of Dunning and Kruger’s seminal experiment. A<a href="https://www.sciencedirect.com/science/article/pii/S019188690100174X"> similar simulation</a> was done by Dr. Phillip Ackerman and colleagues three years after the original Dunning-Kruger paper, and the results were similar.</p>

<p>Measuring someone’s perception of anything, including their own skills, is fraught with difficulties. How well I think I did on my test today could change if the whole thing was done tomorrow, when my mood might differ and my self-confidence may waver. This measurement of self-assessment is thus, to a degree, unreliable. This unreliability--sometimes massive, sometimes not--means that any true psychological effect that does exist will be measured as smaller in the context of an experiment. This is called attenuation due to unreliability. “Scores of books, articles, and chapters highlight the problem with measurement error and attenuated effects,” Patrick McKnight wrote to me. In his simulation with random measurements, the so-called Dunning-Kruger effect actually becomes <i>more</i> visible as the measurement error increases. “We have no instance in the history of scientific discovery,” he continued, “where a finding improves by increasing measurement error. None.”</p>

<h5><b>Breaking the spell</b></h5>

<p>When I plug “Dunning-Kruger effect” into Google News, I get over 8,500 hits from media outlets like <i>The New York Times</i>, <i>New Scientist</i>, and the CBC. So many simply endorse the effect as a real bias of the brain, so it’s no wonder that people are not aware of the academic criticism that has existed since the effect was first published. It’s not just Dr. Nuhfer and his <i>Numeracy </i>papers. Other academic critics have pointed the finger, for example, at regression to the mean.</p>

<p>But as Patrick McKnight points out, regression to the mean occurs when the same measure is taken over time and we track its evolution. If I take my temperature every morning and one day spike a fever, that same measure will (hopefully) go down the next day and return to its mean value as my fever abates. That’s regression to the mean. But in the context of the Dunning-Kruger effect, nothing is measured over time, and self-assessment and performance are different measures entirely, so regression to the mean should not apply. The unreliability of the self-assessment …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.mcgill.ca/oss/article/critical-thinking/dunning-kruger-effect-probably-not-real">https://www.mcgill.ca/oss/article/critical-thinking/dunning-kruger-effect-probably-not-real</a></em></p>]]>
            </description>
            <link>https://www.mcgill.ca/oss/article/critical-thinking/dunning-kruger-effect-probably-not-real</link>
            <guid isPermaLink="false">hacker-news-small-sites-25546787</guid>
            <pubDate>Sat, 26 Dec 2020 22:02:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Interview with David Harris: I've never been a businessman]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25546626">thread link</a>) | @lhoff
<br/>
December 26, 2020 | https://www.golem.de/news/interview-with-david-harris-i-ve-never-been-a-businessman-2012-152533.html | <a href="https://web.archive.org/web/*/https://www.golem.de/news/interview-with-david-harris-i-ve-never-been-a-businessman-2012-152533.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="screen">

<div>
<div>
    
    <section>
        <h2>Mit Werbung weiterlesen</h2>
        <p>Besuchen Sie Golem.de wie gewohnt mit Werbung und Tracking, indem Sie der Nutzung aller Cookies zustimmen.
            Details zum Tracking finden Sie
            <!-- in der <a target="_blank" href="https://www.golem.de/sonstiges/Datenschutz.html">Datenschutz&shy;erkl&auml;rung</a> und -->
            im <span id="gsptextpc1">Privacy Center</span>.
        </p>
        <p id="loadhint">
                Skript wurde nicht geladen. Informationen zur Problembehandlung finden Sie
                <a href="https://www.golem.de/sonstiges/techinfo.html" target="_blank">hier</a>.
        </p>
        <div>
            
            <p id="gspcookiehint">Um der Nutzung von Golem.de mit Werbung zustimmen zu können,
                müssen Cookies in Ihrem Browser aktiviert sein. Weitere Informationen finden Sie
                <a href="https://www.golem.de/sonstiges/techinfo.html" target="_blank">hier</a>.
            </p>
            <p id="gspiframehint">Die Zustimmung in einem iFrame ist nicht möglich.<br>
                <a href="#" onclick="GolemConsent.redirectBack(true);">Seite in eigenem Fenster öffnen</a>.
            </p>
            <p id="fallbackhint">Der Zustimmungs-Dialog konnte nicht korrekt geladen werden,
                eine Zustimmung gilt nur vorläufig. Informationen zur Problem­behandlung finden Sie
                <a href="https://www.golem.de/sonstiges/techinfo.html" target="_blank">hier</a>.
            </p>
        </div>
        <p>
            Die Möglichkeit zum Widerruf finden Sie
            in unserer <a target="_blank" href="https://www.golem.de/sonstiges/Datenschutz.html#Widerruf">Datenschutz­erklärung</a>
            oder über den Link <span id="gsptextpc2">Cookies &amp; Tracking</span> am Ende jeder Seite.
        </p>
    </section>
    
    <section>
        <h2>… oder Golem pur bestellen</h2>
        <p>Mit Golem pur ab 3 Euro pro Monat können Sie Golem.de ohne Analyse- und
            Werbe­cookies nutzen, es kommen nur für unser Angebot erforderliche Cookies zum Einsatz.
        </p>
        <a target="_blank" href="https://redirect.golem.de/nl.php?id=account_cta_cmp">Zu Golem pur</a>
        <p id="loginhint">
        Bereits Pur-Leser?
        <a href="https://account.golem.de/user/login?redirect=https://www.golem.de/news/interview-with-david-harris-i-ve-never-been-a-businessman-2012-152533.html">Hier anmelden</a>.            <span id="nosubhint">Kein aktives Abo vorhanden.</span>
        </p>
    </section>
    <div>
        
        <div>
            <details>
                <summary>Informationen auf einem Gerät speichern und/oder abrufen</summary>
                <p>Für die Ihnen angezeigten Verarbeitungszwecke können Cookies, Geräte-Kennungen
                    oder andere Informationen auf Ihrem Gerät gespeichert oder abgerufen werden.
                </p>
            </details>
            <details>
                <summary>Personalisierte Anzeigen und Inhalte, Anzeigen- und Inhaltsmessungen, Erkenntnisse über Zielgruppen und Produktentwicklungen</summary>
                <p>Anzeigen und Inhalte können basierend auf einem Profil personalisiert werden.
                    Es können mehr Daten hinzugefügt werden, um Anzeigen und Inhalte besser zu personalisieren.
                    Die Performance von Anzeigen und Inhalten kann gemessen werden.
                    Erkenntnisse über Zielgruppen, die die Anzeigen und Inhalte betrachtet haben, können abgeleitet werden.
                    Daten können verwendet werden, um Benutzerfreundlichkeit, Systeme und Software aufzubauen oder zu verbessern.
                </p>
            </details>
            <details>
                <summary>Genaue Standortdaten verwenden</summary>
                <p>Es können genaue Standortdaten verarbeitet werden,
                    um sie für einen oder mehrere Verarbeitungszwecke zu nutzen.
                </p>
            </details>
        </div>
    </div>
    
</div><!-- c2_content -->
</div><!-- c2_wrapper -->

</div></div>]]>
            </description>
            <link>https://www.golem.de/news/interview-with-david-harris-i-ve-never-been-a-businessman-2012-152533.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25546626</guid>
            <pubDate>Sat, 26 Dec 2020 21:35:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Quantifying the self – Why I track 80 metrics about my life every day]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25546516">thread link</a>) | @thefedoration
<br/>
December 26, 2020 | https://dailyvis.com/posts/quantified-self-why-i-track-my-life-in-data/ | <a href="https://web.archive.org/web/*/https://dailyvis.com/posts/quantified-self-why-i-track-my-life-in-data/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><h2>Self-tracking is an investment.</h2><p>Every day since April 2017, I spend a couple of minutes before I go to sleep to log the day's activities. </p><p>Until today, I haven't really thought of the time that it takes to do this. Some back of the napkin math brings that time spent (at 5 minutes a day) to 6675 minutes, which is 11.25 hours, or <strong>4.64 whole days</strong> of me looking at a screen and doing manual data entry.</p><p>That's <em>absolutely insane</em>, you could do so much else with that amount of time! Why would someone choose to spend their precious time in that fashion?</p><p>I'll tell you why I do it, and why I don't see myself stopping this evening ritual anytime soon.</p><h2>How I began quantifying my life</h2><p>It started out with trying to build a good habit, meditation in particular. I wanted to make sure that I met my goals, and it's like they say - you can't improve what you don't track.</p><p>So like any good data nerd, I started a spreadsheet. That spreadsheet contained a cell for every day where I would indicate if I meditated or not.</p><p>Pretty simple, right?</p><p>Maybe for the first couple of weeks. What started out as an innocent little spreadsheet eventually turned into something that had 80 columns, all kinds of values (numbers, letters, time durations), formula calculations, and yes even <em>conditional formatting</em>. If you looked over my shoulder and saw it you'd probably think I was some sort of genius hedge fund guy making millions in the stock market. Nope, making zero money, and if you subscribe to the idea that time is money, making negative money in fact.</p><p><span>
      <a href="https://dailyvis.com/static/73a617e1031f7ac13e15d4a863e4726d/8126d/spreadsheet-screenshot.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Self Tracking Spreadsheet" title="Self Tracking Spreadsheet" src="https://dailyvis.com/static/73a617e1031f7ac13e15d4a863e4726d/c1b63/spreadsheet-screenshot.png" srcset="https://dailyvis.com/static/73a617e1031f7ac13e15d4a863e4726d/5a46d/spreadsheet-screenshot.png 300w,https://dailyvis.com/static/73a617e1031f7ac13e15d4a863e4726d/0a47e/spreadsheet-screenshot.png 600w,https://dailyvis.com/static/73a617e1031f7ac13e15d4a863e4726d/c1b63/spreadsheet-screenshot.png 1200w,https://dailyvis.com/static/73a617e1031f7ac13e15d4a863e4726d/d61c2/spreadsheet-screenshot.png 1800w,https://dailyvis.com/static/73a617e1031f7ac13e15d4a863e4726d/8126d/spreadsheet-screenshot.png 2316w" sizes="(max-width: 1200px) 100vw, 1200px" loading="lazy">
  </a>
    </span>
<em>What my spreadsheet looked like at some point (before I stepped up my tech game)</em></p><h2>The aspects of my life that I keep track of</h2><h3>Fitness, Diet, Sleep</h3><p>The basic things to track, and I do it for obvious reasons like seeing my progress towards fitness goals and making sure that I'm not telling lies when my mom asks if I've been eating my veggies. </p><p>Health data is a big focus of the quantified self community (the online society of folks that track, share, and analyze their personal data), but even if you've never heard the term "Quantified Self" you're probably automatically tracking some sort of health data if you have a modern cell phone or electronic watch.</p><h3>Good habits &amp; things I want to learn</h3><p>Anything I want to improve on actively, I try to keep track of. I find that I get motivated by streaks and especially if it's a new habit, I'm more likely to keep it going when I visually see the momentum I have.</p><p>When I'm trying to get better at something new, I track it. It's been interesting to see the habits that stick around, and those that fizzle out. Sadly, my meditation practice that started this all isn't doing so well these days. Ironically though, I've found that the actual process of self-tracking has been a meditation of sorts, and a time for me to check in with myself.</p><h3>Bad habits</h3><p>Most people just celebrate good habits and try to brush their bad ones under the rug. I've found that tracking bad habits can be eye-opening, insightful, and opens the door to changing those habits if you wish to.</p><p>Like most people my age, "I don't have a drinking problem, but I could probably drink less". Sound familiar?</p><p>Humans are really bad at estimating, and most life decisions more than a day old are bundled up into the past and forgotten. It's one thing to know that you could drink less, and a completely other one to know exactly how many drinks you had this week, how that affects your sleep, mood, productivity and all of the other positive ambitions you have for your life.</p><p>There's also the reverse effect of the good habit streak. When you see that you've drank the past 2 nights, you're more likely to be a bit more conscious of taking today off from the sauce.</p><p><strong>Your memory will lie to you, but your data won't.</strong></p><h3>Time spend</h3><p>Time is the most precious resource, so it makes sense to keep track of it. Not that we need to be productive for every second of every day, but it does help to have a general idea of what you're spending your time on, and how that affects the other parts of your life that you care about.</p><p>I'm always working on a couple of different projects at the same time, and think of my time as an investment as there's always something else I could be doing. It helps to be able to zoom out and really see how I'm choosing to spend my time and compare that with what I'm getting out of it. I also find it fascinating to see the impact of what I'm working on and my mood, sleep, diet, and overall life choices.</p><p>Another time-related thing I track is who I spend my time with. Nothing too precise, just if I see a particular friend that day or not. This one is more just for curiosity (both myself and my friends), they always get a kick out of seeing the correlations between the days that we hang out and the rest of my tracked metrics.</p><h3>How I feel</h3><p>This one's big, as how we feel about ourselves is often times the key driver behind our life choices and day to day actions.</p><p>Call me crazy, but I want to be happy. I want to start my day in a good mood, and even more, I want to end my day in a good mood. I want to feel worry-free, confident, kind, decisive, and humble.</p><p>Unfortunately, I was born the old fashioned way and not in some sort of human positivity lab. I don't get to feel those things every single day. That's fine, I've accepted the human condition.</p><p>However, the daily actions I take do impact my mood (and the reverse is also true), and I'd like to be in touch with that. So I keep track of both, and every once in a while look at the relationships. I want to be able to answer questions like "What can I do to feel less anxious today?" or "Will eating this ice cream actually make me happy?"</p><p>These tracked metrics I keep close to myself, and the insights I get from them are my gold bars in the bank for a future rainy day.</p><h2>Datapoints tracked over time</h2><h2>So why bother doing all of this?</h2><p>The million dollar question, and the answer has evolved over time. To sum it up though:</p><ul><li><strong>Goals</strong> - Keeping myself accountable and reinforcing good habits</li><li><strong>Awareness</strong> - Not hiding from my bad habits, but acknowledging them in order to make decisions with data when it makes sense</li><li><strong>Mindfulness</strong> - This daily check-in lets me reflect on the day and set goals for tomorrow</li><li><strong>Insights</strong> - What starts as a one-way street of putting data in, turns into a two-way highway that gives me information about my life that goes beyond the obvious and has the potential to even surprise me</li><li><strong>I can't stop...</strong> - A joke but also not really. Is there a name for this type of addiction?</li></ul><h2>Is it worth it?</h2><p>I can only speak for myself, but I'd say absolutely. Those 5 minutes every night are not only not a "waste" because I reap the benefits of the data at some future point in time, but the forced moment of self-reflection is one that can be quite valuable.</p><p><em>The human lifespan is an adventure that can't simply be reduced to numbers, but I've found that using quantified self data about the day to day can enrich your life experience, answer interesting questions, and provide confidence in the actions that are taken every day.</em></p><p>What I will say though is that it doesn't need to be this extreme. For those interested in quantifying certain aspects of their life, it's easy to start small &amp; focused to help yourself with your goals. I'll warn you though, it can be addictive. </p><h2>The Quantified Self movement</h2><p>This concept of self-tracking is not one that I made up. There is a set of <a href="https://quantifiedself.com/">awesome</a> <a href="https://www.reddit.com/r/QuantifiedSelf/">online</a> <a href="https://www.openhumans.org/">communities</a> of people who quantify aspects of their life in different ways, and share their methods, reasons, conclusions, and insights with others.</p><p>However robust those communities are though, I think that QS is only getting started. Every year more and more wearables, devices, applications, and services that track personal data are coming out for a variety of use cases (health, wellness, financial, and medical are just the initial ones). This data needs to be handled in an ethical manner and with the upmost respect for what it stands for, in order for humans to fully trust &amp; adopt this technology. But if that can happen, our day to day data can be used for some incredible applications to really enhance the human experience.</p><h2>What I learned about myself</h2><p>Thanks for getting this far, but I think it's time for a break. In my next post I'll share the top insights that I've learned about myself from tracking all of this data every day.</p><p>If you enjoyed this post and want to get notified of the next one, feel free to <a href="https://dailyvis.com/subscribe/">subscribe</a></p></section></div>]]>
            </description>
            <link>https://dailyvis.com/posts/quantified-self-why-i-track-my-life-in-data/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25546516</guid>
            <pubDate>Sat, 26 Dec 2020 21:18:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting rid of NPM scripts]]>
            </title>
            <description>
<![CDATA[
Score 65 | Comments 38 (<a href="https://news.ycombinator.com/item?id=25546460">thread link</a>) | @efortis
<br/>
December 26, 2020 | https://blog.uidrafter.com/engineering/getting-rid-of-npm-scripts | <a href="https://web.archive.org/web/*/https://blog.uidrafter.com/engineering/getting-rid-of-npm-scripts">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">

<article>
<header>


</header>
<p>
In 2016, Sam Saccone <a rel="noopener" target="_blank" href="https://www.kb.cert.org/vuls/id/319816">discovered a vulnerability</a> that
allows adversaries to run arbitrary scripts when installing an NPM package of
theirs. As mitigation, NPM co-founder Laurie Voss <a rel="noopener" target="_blank" href="https://blog.npmjs.org/post/141702881055/package-install-scripts-vulnerability">
suggests</a>:
</p>
<ul>
<li>
<b>Option 1</b>: adding <code>--ignore-scripts</code> when running <code><span>npm</span>
install</code>
</li>
<li>
<b>Option 2</b>: permanently adding <code>ignore-scripts=true</code> to <code>.npmrc</code>
</li>
</ul>
<p>
UI Drafter uses the latter because it avoids having to
remember the flag everytime. But that option disables NPM
<code>"scripts"</code>. Therefore, we end up with two alternatives:
</p>
<ul>
<li>
<b>Option A</b>: overriding: <code><span>npm</span> run --ignore-scripts=false
<b>test</b></code>
</li>
<li>
<b>Option B</b>: using this shell script or a <a href="#-Makefile">Makefile</a>:
</li>
</ul>
<pre><span>#!/bin/sh</span>

<span>case</span> <span>$1</span> <span>in</span>
  <b>dev</b>)   ./make-dev.js <span>;;</span>
  <b>test</b>)  mocha <span>"src/**/*.test.js"</span><span></span> <span>;;</span>
  <b>lint</b>)  eslint src <span>;;</span>
  <b>slint</b>) stylelint <span>"src/**/*.css"</span><span></span> <span>;;</span>

  <b>prod</b>)  <span>time</span> ./make-production.js <span>;;</span>
  <b>all</b>)   <span>$0</span> <b>test</b> &amp;&amp; <span>$0</span> <b>lint</b> &amp;&amp; <span>$0</span> <b>slint</b> &amp;&amp; <span>$0</span> <b>prod</b> <span>;;</span>

  *)     <span>echo</span> <span>"Invalid task: <span>$1</span>"</span><span>;</span> <span>exit</span> <span>1</span> <span>;;</span>
<span>esac</span>
</pre>
<p>Which can be ran as:</p>
<pre>./<span>make</span> <b>test</b>
</pre>
<p>
If the package is not globally installed, prefix the path. For example:
</p>
<pre><b>lint</b>) <span>node_modules/.bin/</span>eslint src <span>;;</span>
</pre>
<h3>Overriding at installation</h3>
<p>
If you need to install packages that install binary dependencies, or rely
on running an NPM script, override the <code>.npmrc</code>:
</p>
<pre><span>npm</span> install <span>--ignore-scripts=false</span> <i>package-name</i>
</pre>

<p>
EDIT: (Dec/27/2020) As suggested in the <a rel="noopener" target="_blank" href="https://news.ycombinator.com/item?id=25546460">Hacker News thread</a>:
</p>
<a id="-Makefile"></a>
<details>
<summary>
<h3>
Makefile
</h3>
</summary>
<pre><b>dev</b>:
	./make-dev.js
<b>test</b>:
	mocha <span>"src/**/*.test.js"</span>
<b>lint</b>:
	eslint src
<b>slint</b>:
	stylelint <span>"src/**/*.css"</span>

<b>prod</b>:
	sh -c 'time ./make-production.js'

<b>all</b>: test lint slint prod

<span>.PHONY: dev test lint slint prod all</span>
</pre>
<pre><span>make</span> <b>test</b>
</pre>
</details>
</article>
<article>
<hr>
<h2>Engineering Blog</h2>
<ul>
<li><a rel="noopener" href="https://blog.uidrafter.com/engineering/isolated-tls-certificate-creation">Isolated Creation of Let's Encrypt TLS Certificates</a></li>
<li><a rel="noopener" href="https://blog.uidrafter.com/engineering/bitwise-table-lookup">Bitwise Table Lookup</a></li>
<li><a rel="noopener" href="https://blog.uidrafter.com/engineering">More…</a></li>
</ul>
</article>
</div></div>]]>
            </description>
            <link>https://blog.uidrafter.com/engineering/getting-rid-of-npm-scripts</link>
            <guid isPermaLink="false">hacker-news-small-sites-25546460</guid>
            <pubDate>Sat, 26 Dec 2020 21:06:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mastering Pinterest SEO: An insider's guide]]>
            </title>
            <description>
<![CDATA[
Score 92 | Comments 46 (<a href="https://news.ycombinator.com/item?id=25546430">thread link</a>) | @jmilinovich
<br/>
December 26, 2020 | https://blog.aesthetic.com/blog/pinterest-guide/ | <a href="https://web.archive.org/web/*/https://blog.aesthetic.com/blog/pinterest-guide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="__next"><div><div><div><div><p>Pinterest is an extraordinarily powerful tool for consumers, but is still misunderstood by marketers. I worked at Pinterest for 2 years helping build their core content understanding technology, and learned a lot about what makes for a successful Pinterest marketing strategy. I hope this guide helps demystify how marketers can get the most from Pinterest as a marketing channel. </p><p>If you have any questions, please <a href="https://twitter.com/intent/tweet?text=Hey%20@jmilinovich">Tweet @jmilinovich</a>! </p><ol><li><a href="#Why-is-Pinterest-marketing-important">Why is Pinterest marketing important?</a></li><li><a href="#How-does-Pinterest-marketing-work">How does Pinterest marketing work?</a></li><li><a href="#How-to-create-a-Pinterest-marketing-plan">How to create a Pinterest marketing plan?</a></li><li><a href="#How-to-make-Pinterest-pins">How to make Pinterest pins?</a></li><li><a href="#How-to-make-Pinterest-Pins-popular">How to make Pinterest Pins popular?</a></li><li><a href="#Conclusion">Conclusion</a></li></ol><h2>Pinterest as a distribution channel</h2><p>Pinterest is a powerful tool that helps people all over the world discover ideas for things to do in their lives. Whether it’s finding recipes, figuring out what to wear, finding new beauty tips or literally any other use case imaginable… people are doing it on Pinterest.</p><p>While search engines like Google focus on the bottom of the purchase funnel (ie, once someone knows that they have a need and are actively looking for it) and social networks like Facebook and Instagram focus on the top of the funnel (ie, when customers are passively looking to consume content with no intent), Pinterest is the only place on the internet that lets marketers reach consumer in the consideration phase. </p><p><img src="https://d33wubrfki0l68.cloudfront.net/2514c6be4877df4b7599580c5af4d1c3c2f54f86/453eb/img/posts/pinterest-guide/consideration.png" alt="The marketing consideration funnel"></p><p>This creates a big opportunity for businesses to get their products, goods and services in front of potential buyers while they’re deciding what they want to buy, but haven’t made the decision yet. That’s one of the most powerful things about Pinterest- people go there to find ideas, not just to make purchasing decisions. This means that marketers are able to reach consumers before they’ve made up their mind on what they’re looking to do.</p><h2>Pinterest as a source of inbound links</h2><p>While the most clear first-order effect to a strong Pinterest presence is creating a powerful new referral traffic source, there’s also a misunderstood but very powerful second-order effect: creating more inbound links to your website. </p><p>Have you noticed how no matter what you search for, it seems that you almost always see Pinterest results on the first page of Google? Pinterest’s core growth strategy has been about getting excellent at SEO, or search engine optimization. Practically speaking this means that the company has spent a lot of effort creating millions of high quality landing pages with the explicit purpose of being indexed by Google. Each of these landing pages shows dozens of Pins, and each contains a link to that Pin’s page on Pinterest. </p><p>As your content becomes more popular, it will begin showing up on more of Pinterest’s SEO pages, which means that it will be more readily indexed by Google. Since Google gives Pinterest’s domain a high authority and quality score, this means that over time you will start to accumulate some of this authority if your Pins are shown in prominent places. So, getting good at Pinterest doesn’t just help improve your Pinterest referral traffic, it can also improve your traffic from places like Google! </p><p><img src="https://d33wubrfki0l68.cloudfront.net/bbc3082cbd708936207fcc8fed30415b5077ee03/32add/img/posts/pinterest-guide/pinterest-results.png" alt="Example of Pinterest landing pages"></p><h2>Pinterest is a search engine</h2><p>The most important thing to understand about Pinterest is that at its core it’s a search engine, not a social network.  People don’t use Pinterest to “follow” specific brands but rather to follow interests and search for ideas. A “Pin” is simply a visual bookmark to a webpage, and under the hood Pinterest’s technology stack is focused on figuring out what interests a Pin is about, and which users are interested in which interests. Content on Pinterest isn’t temporal like other social networks, but evergreen like on Google.</p><h2>Help Pinterest understand your content</h2><p>This means that the most important thing to get right for Pinterest marketing is helping Pinterest understand what interests your Pins are about. This means that the key underlying concept for Pinterest marketing is to create Pins for all of your web content, and then make sure that Pinterest has a clear understanding of what interests they align to. </p><p>Once Pinterest understands what a given Pin is about, it can start showing it to users to see how they interact with it. If they engage with it (ie, Save it to one of their boards or Click on it to see the underlying content), Pinterest uses this as a positive sign that this is quality content and will begin showing it to more people. </p><p>As such, one of the most important things to get right is having a clear strategy for how to communicate to Pinterest what your Pins are about and getting engagement signals on the Pins early. </p><p><img src="https://d33wubrfki0l68.cloudfront.net/db6e047a9650880cd7f0be4c4718c0791790c2e0/18ef8/img/posts/pinterest-guide/pinterest-interests.png" alt="Example of Pinterest interests"></p><h2>Choose your Interests</h2><p>The most critical thing to get right in your Pinterest marketing plan is determining what Interests are most important to your business. There are <a href="https://docs.google.com/spreadsheets/d/1HxL-0Z3p2fgxis9YBP2HWC3tvPrs1hAuHDRtH-NJTIM/edit#gid=118370875">over 10,000 interests on Pinterest today</a>, ranging from highly broad to highly specific. Start by brainstorming what interests your target audience has today, as well as what interests your content is actually about. Look for the overlap of these two sets and choose the 10-15 that have the most promise to focus in on first. </p><h2>Create your Boards</h2><p>Once you’ve chosen the interests that you want to focus on, the next step is to decide on the architecture of your Pinterest for Business account. Pinterest accounts for users and businesses alike are defined by the boards that they create and post Pins to. You can think of a board as a folder of visual bookmarks that are public by default. When someone looks at your Pinterest account, the fastest way that they will understand what you’re about is by the names of the boards that you create. </p><p>Start by creating boards whose names are the same as the 10-15 interests you chose to focus on. It’s OK if they have more words in them as well, but make sure that the Interest name itself is very prominent. Make sure that each board has a very specific description that explains the core ideas that you’ll be pinning to the board.</p><p><img src="https://d33wubrfki0l68.cloudfront.net/dadf2e2890dde22bbff64a7ded8e0dcf6b592fe9/31afa/img/posts/pinterest-guide/boards.png" alt="Example of Pinterest boards"></p><p>Next, you need to decide what content to start posting onto these boards. </p><h2>Pinning existing content</h2><p>There are only two kinds of Pins on Pinterest: Pins from your own website, and Pins from other people’s websites. Both are equally important to a strong Pinterest strategy. The first thing you should do is to fill your boards with Pins that are already on Pinterest and were created by other people. Spend some time saving 20-30 Pins to each of your boards. As you do this, Pinterest will also begin recommending new Pins in your homefeed that are related to what you’ve been Pinning. </p><p>The reason you’re seeing the Pins that Pinterest is recommending to you is because Pinterest already knows a lot about them and has a high confidence that users like you will find them interesting. When you save them to your boards, you’re giving Pinterest even more signal about what your board is about. This is extremely important, because Pinterest learns a lot about new Pins based on the other Pins that it shows up on boards with. </p><p><img src="https://d33wubrfki0l68.cloudfront.net/a3580f834d291668bd22cae46f7854ddb0106853/de8da/img/posts/pinterest-guide/existing-pin.png" alt="Example of Pinterest pins"></p><p>Each week you should also continue to save new, existing content to your boards to keep giving Pinterest more signal and context for what your Pins are about. </p><h2>Pinning your own content</h2><p>Once you create a good base of existing Pins on your boards, you can start to plan your strategy for getting your own original content into Pinterest. First, go through all of your existing website content and map out what content would be relevant for the Pinterest audience. Generally speaking, the best content will be things like blog posts or eCommerce product landing pages. You should skip things like your homepage, about page, contact us page or other informational pages that don’t provide highly specific and useful content about a specific concept. </p><p>On social networks, it’s important that you have a steady pace of posting content into your feed so that you stay top of mind and also don’t inundate followers by posting 100 things at once. Pinterest is much more like Google, however, where you want them to know about your content upfront and all at once. </p><p>You should post all of your existing, relevant content to Pinterest upfront and then consistently add new content as it’s published online. Save it to the most relevant board to give Pinterest a clear understanding of what your content’s about. You can also post it to more than one board if it’s relevant to multiple categories. </p><p>The Pins that perform best on Pinterest have been created specifically for Pinterest following their <a href="https://business.pinterest.com/en-gb/content/creative-best-practices/">creative best practices</a>. Practically speaking this means that each Pin will require some editing work within a graphics editor tool. Generally speaking, each Pin can take anywhere from 5-20 minutes to create by hand if using a tool like Photoshop, Canva or Adobe Spark. This can be quite burdensome, especially if you’re trying to create dozens or hundreds of Pins for your site. </p><p><a href="https://www.aesthetic.com/?utm_source=blog&amp;utm_medium=post&amp;utm_campaign=pinterest-guide">Aesthetic’s software</a> is able to generate on-brand Pinterest Pins from a company’s website automatically. Simply enter a URL, and our app will create dozens of variations of graphics to promote that webpage, including several that follow Pinterest’s best practices guide. We’ve seen our users cut down the time it takes to create a Pin by 95% using our tool. </p><p>Once you’ve created your Pin graphics, you can upload them into the Pinterest system. Add the URL for each Pin along with a detailed description that touches upon what the Pins about and ideally mentions the specific interests that it’s related to. Post these to the right boards, and you’re off to the races! </p><p><img src="https://d33wubrfki0l68.cloudfront.net/4ab1dd02738de6695f0118fd169a78c4e10d21bb/09e8b/img/posts/pinterest-guide/aesthetic-pins.png" alt="Example of Pinterest pins made with Aesthetic"></p><p>Once you’ve uploaded your content to Pinterest, you will see the impressions slowly start to trickle in as the system understands more about what your content’s about. Generally speaking it can take months for new content on Pinterest to get enough exposure for Pinterest to determine whether it’s sufficiently interesting enough for it to be promoted more widely within the system.</p><p>Another option to fast track the distribution of your Pins is to run small budget ads for your own Pins, targeting the Interests that they’re related …</p></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.aesthetic.com/blog/pinterest-guide/">https://blog.aesthetic.com/blog/pinterest-guide/</a></em></p>]]>
            </description>
            <link>https://blog.aesthetic.com/blog/pinterest-guide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25546430</guid>
            <pubDate>Sat, 26 Dec 2020 21:01:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fun with IP address parsing]]>
            </title>
            <description>
<![CDATA[
Score 424 | Comments 113 (<a href="https://news.ycombinator.com/item?id=25545967">thread link</a>) | @mr_tyzic
<br/>
December 26, 2020 | https://blog.dave.tf/post/ip-addr-parsing/ | <a href="https://web.archive.org/web/*/https://blog.dave.tf/post/ip-addr-parsing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<div>
		<p><span>Written by</span>
        David Anderson
        <br>
        <span>on&nbsp;</span><time datetime="2020-12-25 00:00:00 +0000 UTC">December 25, 2020</time>
</p>
		


		

		<p>In my quest to write a fast IPv4+6 parser, I wrote a
slow-but-I-think-correct parser, to use as a base of comparison. In
doing so, I discovered more cursed IP address representations that I
was previously unaware of. Let’s explore together!</p>

<p>We start out simple, with IPv4 and IPv6 in what I’ll call their
“canonical form”: <code>192.168.0.1</code> and <code>1:2:3:4:5:6:7:8</code>. Various specs
call these “dotted quad” (more specifically, “dotted decimal”),
dot-separated fields each representing 1 byte; and “colon-hex”,
colon-separated fields each representing 2 bytes.</p>

<p>The first bits of complexity come from IPv6. In canonical form, common
addresses would end up with long runs of zeros in the middle. So, <code>::</code>
allows you to elide 1 or more 16-bit blocks of zeros: <code>1:2::3:4</code> means
<code>1:2:0:0:0:0:3:4</code></p>

<p>Next up, for cursed historical reasons, IPv6 permits you to write the
final 32 bits of the address in dotted quad form. Effectively, you can
splat an IPv4 address onto the end of IPv6 addresses!
<code>1:2:3:4:5:6:77.77.88.88</code> means <code>1:2:3:4:5:6:4d4d:5858</code>.</p>

<p>And of course, you can combine the two! <code>fe80::1.2.3.4</code> means <code>fe80:0:0:0:0:0:102:304</code></p>

<p>The existence of <code>::</code> introduces an annoying edge case in parsing: the
<code>::</code> can be at the start or end of the address, and the “empty” side
of the address is not one of the 16-bit fields. <code>::1</code> means
<code>0:0:0:0:0:0:0:1</code>, <code>1::</code> means <code>1:0:0:0:0:0:0:0</code>, and <code>::</code> means
<code>0:0:0:0:0:0:0:0</code>. This is a natural consequence of the <code>::</code> rule, but
it makes the parser slightly more annoying to write.</p>

<p>One final rule for IPv6: technically, each colon-hex field is 4 hex
digits, but you can elide leading zeros, as I’ve been doing so
far. Fully canonically, <code>::</code> is
<code>0000:0000:0000:0000:0000:0000:0000:0000</code>. My apologies to trypophobic
readers.</p>

<p>That’s it for IPv6, mostly. Now, on to IPv4!</p>

<p>Fun fact, the textual representation of IPv4 was never standardized in
any document before IPv6 needed a grammar for its weirdo “trailing
dotted quad” notation. So, it’s a de-facto standard that boils down to
mostly “what did 4.2BSD understand?”, and “what did other OSes keep
when they copied 4.2BSD?”</p>

<p>And hoo boy, strap yourselves in, because 4.2BSD sure had some whacky
opinions! Let’s use <code>192.168.140.255</code> as an example. That’s an IPv4
address that people would look at and go “yes, that sure is an IPv4
address.” How else can we write that exact same address?</p>

<p>This is the same IP address: <code>3232271615</code>. You get that by
interpreting the 4 bytes of the IP address as a big-endian unsigned
32-bit integer, and print that. This leads to a classic parlor trick:
if you try to visit <a href="http://192.168.140.255/">http://3232271615</a> , Chrome will load
<a href="http://192.168.140.255/">http://192.168.140.255</a>.</p>

<p>Okay, but that’s sort-of sensible, right? An IPv4 address is 4 bytes,
so printing it as a single number is a bit human-unfriendly, but
broadly plausible, right?</p>

<p>How about <code>0300.0250.0214.0377</code> ? That’s still the same
address. Dotted quad, except each field is written out in octal.</p>

<p>And if octal is supported, you might be wondering about hex. And you’d
be right! <code>192.168.140.255</code> is also <code>0xc0.0xa8.0x8c.0xff</code>, according
to 4.2BSD.</p>

<p>Now, remember before we had CIDR (Classless Inter-Domain Routing) ?
IPv4 addresses were Class A, Class B or Class C. It was a weird time.</p>

<p>And that weird time made it into IP addresses! The familiar
<code>192.168.140.255</code> notation is technically the “Class C” notation. You
can also write that address in “class B” notation as <code>192.168.36095</code>,
or in “Class A” notation as <code>192.11046143</code>. What we’re doing is
coalescing the final bytes of the address into either a 16-bit or a
24-bit integer field.</p>

<p>This, by the way, is why utilities like <code>ping</code> will accept weird
looking addresses like <code>127.1</code> for <code>127.0.0.1</code>. Unlike IPv6, it’s not
doing some kind of “missing fields are zero” expansion. <code>127.1</code> is the
Class A notation for “host 1 of network 127”, where the 1 is a 24-bit
number.</p>

<p>And finally, we come to one last bit of unspecified behavior: do IPv4
addresses permit an unlimited number of leading zeros in each quad? Or
is there a maximum of 3 digits? <code>001.002.003.004</code> is universally
recognized as valid. What about
<code>0000000001.0000000002.0000000003.000000004</code>?</p>

<p>You might also be wondering if either of these numbers should be read
in as octal, since we said earlier that a leading zero might be
interpreted as octal. It depends! There are implementations that do
both, but <em>most</em> modern implementations have abandoned the octal and
hex notation, and treat leading 0s as decimal.</p>

<p>The leading zero debate also infects IPv6, to some extent. Is
<code>000001::00001.00002.00003.00004</code> is a valid IPv6 address (“common”
form <code>1::1.2.3.4</code>, or <code>1::102:304</code>)? Most modern parsers seem to allow
an unlimited amount of leading zeros in their representations,
probably because they’re leaning on some “parse integer” library that
implements that behavior.</p>

<p>And so, we reach the bitter end. If you want to <em>truly</em> parse IP
addresses, this is the bullshit you have to put up with.</p>

<p>Currently, my slow reference parser jettisons a lot of old baggage,
and sticks to what I think is a sensible subset of these
possibilities. It understands:</p>

<ul>
<li>Classic v4 dotted decimal, with any number of leading zeros.</li>
<li>It does not process Class A/B notation, or hex or octal notation.</li>
<li>It does not process the “uint32 to the knee” representation.</li>
<li>For IPv6, it understands canonical colon-hex form, as well as ::
and trailing-IPv4 style (where the trailing IPv4 follows the same
rules as the previous tweet). Each field is allowed any number of
leading zeros.</li>
</ul>

<p>I’m on the fence about that last one, the “IPv6 with an embedded
dotted decimal” form. My reference parser (Go’s <code>net.ParseIP</code>)
understands it, but it’s not really that useful any more in the real
world. At the dawn of IPv6, the idea was that you could upgrade an
address to IPv6 by prepending a pair of colons, as in <code>::1.2.3.4</code>, but
modern transition mechanisms no longer offer anything as clear-cut as
this, so the notation doesn’t really show up in the wild.</p>

		
	</div>

	
</div></div>]]>
            </description>
            <link>https://blog.dave.tf/post/ip-addr-parsing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25545967</guid>
            <pubDate>Sat, 26 Dec 2020 19:56:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Partial order and non-Boolean logic]]>
            </title>
            <description>
<![CDATA[
Score 46 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25545543">thread link</a>) | @okaleniuk
<br/>
December 26, 2020 | https://wordsandbuttons.online/partial_order_and_non_boolean_logic.html | <a href="https://web.archive.org/web/*/https://wordsandbuttons.online/partial_order_and_non_boolean_logic.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	

	<p>
Numbers. Numbers are easy. All you need to know to sort them out is that
	</p>
	<ul>
	<li>
if 1 ≤ 2 and 2 ≤ 3 then 1 ≤ 3;
	</li>
	<li>
either 4 ≤ 5 or 5 ≤ 4...
	</li>
	<li>
...or both, but if 6 ≤ 6 and 6 ≤ 6 then 6 = 6.
	</li>
	</ul>
	<p>
Oh, shit! I forgot to put a smart face on. Let's start over.
	</p>
	<p>
A <b><span id="index_total_order">total order</span></b>, also known as <b><span id="index_linear_order">linear order</span></b> is a relation “≤” on a set <span>S</span>. For <span>a, b, c ∈ S</span>, the three properties hold.
	</p>
	<p>
The first one is called <b><span id="index_transitivity">transitivity</span></b>.
	</p>
	<p>
a ≤ b ∧ b ≤ c ⇒ a ≤ c.
	</p>
	<p>
The second one is <b><span id="index_connexity">connexity</span></b>.
	</p>
	<p>
a ≤ b ∨ b ≤ a
	</p>
	<p>
And the third one is <b><span id="index_antisymmetry">antisymmetry</span></b>.
	</p>
	<p>
a ≤ b ∧ b ≤ a ⇒ a = b
	</p>
	<p>
With rules established for <span>≤</span>, we can also tell either <span>a &lt; b</span> or <span>a &gt; b</span> or <span>a = b</span> for every <span>a</span> and <span>b</span>.
	</p>
	
	
<br>

<table>
<tbody><tr><th>Predicate</th><th>Result</th></tr>
<tr><td>a = b</td>		<td id="e"></td></tr>
<tr><td>a &lt; b</td>	<td id="l"></td></tr>
<tr><td>a &gt; b</td>	<td id="g"></td></tr>
<tr><td>a ≠ b</td>	<td id="ne"></td></tr>
<tr><td>a ≤ b</td>	<td id="le"></td></tr>
<tr><td>a ≥ b</td>	<td id="ge"></td></tr>
</tbody></table>
	<p>
Real numbers are comparable. That implies that you can sort them. Of course, not only numbers are comparable. Names are comparable and sortable in alphabetical order. Skyscrapers are comparable and sortable by height. A lot of things are comparable and sortable.
	</p>
	<p>
But a few things aren't. Like the <a href="https://wordsandbuttons.online/yet_another_alternative_to_floating_point_numbers.html">intervals, we use to represent numbers with errors</a>. We use them when we don't know the exact number <span>x</span> but we know its error <span>ε</span> and therefore have all the reasons to believe that it's jammed somewhere between <span>x<sub>1</sub></span> and <span>x<sub>2</sub></span> where
	</p>
	<p>
x<sub>1</sub> = x − ε
<br>
x<sub>2</sub> = x + ε
	</p>
	<p>
These intervals are helpful when we want to measure a computational error of some calculation or to see if some algorithm is stable enough. They aren't comparable or truly sortable though.
	</p>
	<p>
Consider two overlapping intervals. Let's say, <span>[3, 6]</span> and <span>[5, 8]</span>. We know that the fist interval actually means a number between  <span>3</span> and  <span>6</span>. The second — another number between <span>5</span> and <span>8</span>. Intuitively, the latter should be greater than the former. But what if it is  <span>5</span> and the former is  <span>6</span>? Then it's obviously less. There is a chance they are even equal. 
	</p>
	<p>
So there is some kind of order, for instance, <span>[6, 8]</span> is definitely greater than  <span>[3, 5]</span>. But this order doesn't hold for every possible pair of intervals.
	</p>
	<p>
This makes things unpleasant. For the very least, we can't now use binary logic since all the comparisons now return three states. E. g. <span>a ≤ b</span> can now be <span>true</span>, <span>false</span> or <span>none of the above</span>.
	</p>
	<p>
Consequently, this means the conventional <span>if... else</span> statement now has to be redesigned. And all the algorithms that use it.
	</p>
	<p>
We wouldn't have to give up binary logic completely if we agree to “split” the semantics of the predicates into two. For every predicate on the two intervals, we can still say whether the numbers they represent definitely suffice the predicate, or whether they possibly do so.
	</p>
	<p>
For instance, <span>[3, 5]</span> is definitely less than <span>[6, 8]</span>, and <span>[3, 6]</span> is possibly less than <span>[5, 8]</span>. The most unpleasant case for us is when intervals overlap. Everything is indefinite, and everything is possible then.
	</p>
<br>
	
	
<br>

<table>
<tbody><tr><th>Predicate</th><th>Deffinitely</th><th>Possibly</th></tr>
<tr><td>a = b</td>		<td id="de"></td>		<td id="pe"></td></tr>
<tr><td>a &lt; b</td>	<td id="dl"></td>		<td id="pl"></td></tr>
<tr><td>a &gt; b</td>	<td id="dg"></td>		<td id="pg"></td></tr>
<tr><td>a ≠ b</td>	<td id="dne"></td>	<td id="pne"></td></tr>
<tr><td>a ≤ b</td>	<td id="dle"></td>	<td id="ple"></td></tr>
<tr><td>a ≥ b</td>	<td id="dge"></td>	<td id="pge"></td></tr>
</tbody></table>

	<p>
Still, every <span>if... else</span> works. Within its semantics that is. However, the algebra behind the logic isn't yet Boolean. Now <span>¬ (a &lt; b) ≢ a ≥ b</span>. Computational algorithms may be technically built using the same building blocks as if the intervals were numbers but that's it.
	</p>

	<p>
Speaking of building stuff. Let's talk about programming. Programming non-Boolean interval logic in C++ or Python is fairly easy. You have to reimplement every predicate for the interval type — and you're golden!
	</p>
	<pre id="code_1">struct Interval {
    Number lb; // lower bound
    Number ub; // upper bound
}

// Interval-specific predicates.
bool coincide(const Interval&amp; l, const Interval&amp; r){
    return l.lb == r.lb &amp;&amp; l.ub == r.ub;
}

bool intersect(const Interval&amp; l, const Interval&amp; r){
    return (l.ub &gt;= r.lb &amp;&amp; l.lb &lt;= r.ub)
        || (r.ub &gt;= l.lb &amp;&amp; r.lb &lt;= l.ub);
}

// The "definite" interval logic.
// The relation should keep for every number in l and in r.
bool operator==(const Interval&amp; l, const Interval&amp; r){
    return l.lb == l.ub &amp;&amp; coincide(l, r);
}

bool operator&lt;(const Interval&amp; l, const Interval&amp; r){
    return l.ub &lt; r.lb;
}

bool operator&gt;(const Interval&amp; l, const Interval&amp; r){
    return r &lt; l;
}

bool operator&lt;=(const Interval&amp; l, const Interval&amp; r){
    return l.lb &lt; r.ub &amp;&amp; l.ub == r.lb;
}

bool operator&gt;=(const Interval&amp; l, const Interval&amp; r){
    return r &lt;= l;
}

bool operator!=(const Interval&amp; l, const Interval&amp; r){
    return r &lt; l || l &lt; r;
}</pre>
	<p>
Nobody cares about the relationship between predicates being Boolean-ish. They are all just some arbitrary functions so with them, you can easily define either the “definite” logic or the “possible” one. You can have both if you define them for different but interchangeable types. It's all a little verbose but doable.
	</p>
	<p>
It gets a little bit more tricky in Rust which relies on the notion of order pretty much.
	</p>
	<p>
The comparison operators for a custom type are usually introduced using an <a href="https://doc.rust-lang.org/std/cmp/trait.Ord.html">std::cmp::Ord</a> trait. It requires that:
	</p>
	<p>
∀ a, b: (a &lt; b) ⊕ (a = b) ⊕ (a &gt; b)
<br>
a ≤ b ∧ b ≤ c ⇒ a ≤ c.
	</p>
	<p>
The first reads as for every <span>a</span> and <span>b</span>, one and only one is true: either <span>(a &lt; b)</span> or <span>(a = b)</span> or <span>(a &gt; b)</span>. This doesn't work for us. When intervals intersect, in “definite” logic none of the predicates are true. And in the “possible” logic, they all are.
	</p>
	<p>
Luckily, there is another more relaxed trait that represents not total order, but <span id="index_partial_order">partial order</span>: <a href="https://doc.rust-lang.org/std/cmp/trait.PartialOrd.html">std::cmp::PartialOrd</a>. Which only requires <b><span id="index_asymmetry">asymmetry</span></b> (not even antisymmetry) and transitivity (we've seen it before):
	</p>
	<p>
a &lt; b ⇒ ¬(a &gt; b)
<br>
a ≤ b ∧ b ≤ c ⇒ a ≤ c.
	</p>
	<p>
Аnd for the “definite” logic, this works.
	</p>
	<pre id="code_2">impl std::cmp::PartialEq for RB32{
    // the same as operator == in C++ or __eq__(self, other) in Python
    fn eq(&amp;self, other: &amp;Self) -&gt; bool {
        self.lb == other.lb &amp;&amp; self.ub == other.ub
    }
}

impl std::cmp::PartialOrd for RB32{
    // this is usually enough to replace all the rest
    fn partial_cmp(&amp;self, other: &amp;Self) -&gt; Option&lt;std::cmp::Ordering&gt; {
        if self.ub &lt; other.lb {
            Some(std::cmp::Ordering::Less)
        } else if self.lb &gt; other.ub {
            Some(std::cmp::Ordering::Greater)
        } else if self.lb == other.lb &amp;&amp; self.ub == other.ub {
            Some(std::cmp::Ordering::Equal)
        } else {
            None // this is what differentiates Ord and PartialOrd
        }
    }

    // but since in out logic, (a &lt; b) ∨ (a = b) ≢ a ≤ b,
    // we have to define ≤ and ≥ explicitly.
    fn le(&amp;self, other: &amp;Self) -&gt; bool {
        (self.lb == other.lb &amp;&amp; self.lb == self.ub) ||
        (self.ub == other.ub &amp;&amp; other.lb == other.ub)
    }
    fn ge(&amp;self, other: &amp;Self) -&gt; bool {
        (self.ub == other.ub &amp;&amp; self.lb == self.ub) ||
        (self.lb == other.lb &amp;&amp; other.lb == other.ub)
    }
}</pre>

	<p>
The code is less verbose than in C++ or Python, and it would have been even less so if we were relying on Boolean algebra. With it, you don't even have to write <span>le</span> or <span>ge</span> methods explicitly, <span>cmp</span> is enough. With Boolean algebra, Rust can deduce the rest for you.
	</p>
	<p>
Ok, but that was the “definite” logic. But what about the “possible”?
	</p>
	<p>
I'm afraid, for this particular task, Rust comes short. In the “possible” interval logic, the intersecting intervals may be <span>a &lt; b</span>, and <span>a = b</span>, and <span>a &gt; b</span>, all at the same time. Every predicate is true since everything is possible. You can't program that with Rust <a href="https://doc.rust-lang.org/std/cmp/enum.Ordering.html">Ordering</a>. However, this is not a flaw, this is a design choice.
	</p>
	<p>
Non-Boolean logics are rare, and relations more general than partial order are almost never useful. If you really really want this kind of logic, you can still implement it using functions and not operators. At the same time, you can expect that if a class implements the <span>std::cmp::Ord</span> trait, then all the sorting algorithms will work with it correctly. While in C++, a sorting algorithm will run on anything with the <span>operator&lt;</span> reloaded with no correctness guaranteed or even pinky-promised.
	</p>
	<h2>
Conclusion
	</h2>
	<p>
Non-Boolean logics are rare but not extinct. Interval logic is one example. Sometimes, you can implement a logic you want within total order or partial order but sometimes even that isn't enough and you need an even more general relation. With operator overloading, you have the freedom to go there but you also have less assurance when working within the total order.
	</p>

	


	
	</div></div>]]>
            </description>
            <link>https://wordsandbuttons.online/partial_order_and_non_boolean_logic.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25545543</guid>
            <pubDate>Sat, 26 Dec 2020 19:02:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thermopolium found intact with food residues, animal bones]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25545160">thread link</a>) | @jdright
<br/>
December 26, 2020 | https://weirditaly.com/2020/12/26/extraordinary-discovery-in-pompeii-thermopolium-found-intact-with-food-residues-animal-bones/ | <a href="https://web.archive.org/web/*/https://weirditaly.com/2020/12/26/extraordinary-discovery-in-pompeii-thermopolium-found-intact-with-food-residues-animal-bones/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p><strong>The skeleton of a small dog and human remains were also found in the street food shop.</strong></p><p><strong>The Thermopolium of Regio V, one of the snack bars at Pompeii,&nbsp;&nbsp;</strong>complete with an image of a Nereid riding a sea-horse, which had previously been partially excavated in 2019,&nbsp;<strong>re-emerges in its entirety, with other rich decorative still lifes, food residues, animal bones and victims of the eruption.</strong></p><p><strong>Related articles:</strong> <a href="https://weirditaly.com/2014/03/13/30-amazing-pictures-of-pompeii/" data-type="post" data-id="35">30 Amazing pictures of Pompeii</a>, <a href="https://weirditaly.com/2018/05/30/archaeologists-found-in-pompeii-the-skeleton-of-a-man-fleeing-from-the-fury-of-the-volcano/" data-type="post" data-id="2824">Archaeologists found in Pompeii the skeleton of a man fleeing from the fury of the Volcano</a></p><p>According to the Massimo Osanna, director of the Archaeological Park Of Pompeii, the discovery “provides an incredible snapshot of the day of the eruption”.</p><div><figure><img title="Thermopolium-found-intact-with-food-residues-animal-bones-intro-1024x784 Extraordinary discovery in Pompeii: Thermopolium found intact with food residues, animal bones " src="https://weirditaly.com/wp-content/plugins/lazy-load/images/1x1.trans.gif" data-lazy-src="https://weirditaly.com/wp-content/uploads/2020/12/Thermopolium-found-intact-with-food-residues-animal-bones-intro-1024x784.jpg" loading="lazy" width="1024" height="784" alt="Weird Italy Thermopolium-found-intact-with-food-residues-animal-bones-intro-1024x784 Extraordinary discovery in Pompeii: Thermopolium found intact with food residues, animal bones Featured Italian History  Pompeii  " srcset="https://weirditaly.com/wp-content/uploads/2020/12/Thermopolium-found-intact-with-food-residues-animal-bones-intro-1024x784.jpg 1024w, https://weirditaly.com/wp-content/uploads/2020/12/Thermopolium-found-intact-with-food-residues-animal-bones-intro-300x230.jpg 300w, https://weirditaly.com/wp-content/uploads/2020/12/Thermopolium-found-intact-with-food-residues-animal-bones-intro-768x588.jpg 768w, https://weirditaly.com/wp-content/uploads/2020/12/Thermopolium-found-intact-with-food-residues-animal-bones-intro.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></div><p>The commercial structure had only been partially studied in 2019, during the interventions of the Great Pompeii Project aimed at stabilizing and consolidating the historic excavation fronts.</p><p>Considering the exceptional nature of the decorations, and to restore the complete layout of the restaurant, which is located in the clearing between Vicolo delle Nozze d’Argento and Vicolo dei Balconi, it was decided to broaden the project and complete the excavation of the entire area.</p><div><figure><img title="Thermopolium-found-intact-with-food-residues-animal-bones-10 Extraordinary discovery in Pompeii: Thermopolium found intact with food residues, animal bones " src="https://weirditaly.com/wp-content/plugins/lazy-load/images/1x1.trans.gif" data-lazy-src="https://weirditaly.com/wp-content/uploads/2020/12/Thermopolium-found-intact-with-food-residues-animal-bones-10.jpg" loading="lazy" width="623" height="666" alt="Weird Italy Thermopolium-found-intact-with-food-residues-animal-bones-10 Extraordinary discovery in Pompeii: Thermopolium found intact with food residues, animal bones Featured Italian History  Pompeii  " srcset="https://weirditaly.com/wp-content/uploads/2020/12/Thermopolium-found-intact-with-food-residues-animal-bones-10.jpg 623w, https://weirditaly.com/wp-content/uploads/2020/12/Thermopolium-found-intact-with-food-residues-animal-bones-10-281x300.jpg 281w" sizes="(max-width: 623px) 100vw, 623px"></figure></div><p>In the small square in front of the&nbsp;<em>Thermopolium</em>,works had already revealed a cistern, a fountain and a water tower, which were all located a short distance from the shop which features the famed fresco of gladiators in combat.</p><figure><p> <iframe id="_ytid_55959" width="877.5" height="493" data-origwidth="877.5" data-origheight="493" src="https://www.youtube.com/embed/gg-DypTyY4M?enablejsapi=1&amp;autoplay=0&amp;cc_load_policy=0&amp;cc_lang_pref=&amp;iv_load_policy=1&amp;loop=0&amp;modestbranding=0&amp;rel=1&amp;fs=1&amp;playsinline=0&amp;autohide=2&amp;theme=dark&amp;color=red&amp;controls=1&amp;" title="YouTube player" allow="autoplay; encrypted-media" allowfullscreen="" data-no-lazy="1" data-skipgform_ajax_framebjll=""></iframe></p></figure><p>The decorations on the counter – which were the first to emerge during the excavation&nbsp; – comprise the image of a Nereid riding a sea-horse in a marine setting on the front, while the shorter side features an illustration which is probably of the shop itself, like a kind of trademark. It was not by chance that the discovery during the excavation of amphorae, located in front of the counter, reflected the painted image.</p><div><figure><img title="Thermopolium-found-intact-with-food-residues-animal-bones-3 Extraordinary discovery in Pompeii: Thermopolium found intact with food residues, animal bones " src="https://weirditaly.com/wp-content/plugins/lazy-load/images/1x1.trans.gif" data-lazy-src="https://weirditaly.com/wp-content/uploads/2020/12/Thermopolium-found-intact-with-food-residues-animal-bones-3.jpg" loading="lazy" width="498" height="543" alt="Weird Italy Thermopolium-found-intact-with-food-residues-animal-bones-3 Extraordinary discovery in Pompeii: Thermopolium found intact with food residues, animal bones Featured Italian History  Pompeii  " srcset="https://weirditaly.com/wp-content/uploads/2020/12/Thermopolium-found-intact-with-food-residues-animal-bones-3.jpg 498w, https://weirditaly.com/wp-content/uploads/2020/12/Thermopolium-found-intact-with-food-residues-animal-bones-3-275x300.jpg 275w" sizes="(max-width: 498px) 100vw, 498px"></figure></div><p>In this new phase of excavation, the last section of the counter to be unearthed revealed other exquisite scenes of still life, with depictions of animals which were likely butchered and sold here. Bone fragments belonging to the same animals were also discovered inside containers embedded in the counter, which held foodstuffs intended for sale, such as in the case of the&nbsp;<strong>two mallard ducks shown upside down</strong>, ready to be cooked and eaten;&nbsp;<strong>a rooster</strong>; and&nbsp;<strong>a dog on a lead</strong>, the latter serving almost as a warning in the manner of the famed&nbsp;<em>Cave Canem</em>.</p><p><strong>A mocking inscription can be found scratched&nbsp;</strong>onto the frame which surrounds the painting of the dog:&nbsp;<strong>NICIA CINAEDE CACATOR –&nbsp;</strong>literally<strong>&nbsp;“<em>Nicias</em></strong>(probably a freedman from Greece)&nbsp;<strong><em>Shameless Shitter!”&nbsp;</em></strong>This was probably left by a prankster who sought to poke fun at the owner, or by someone who worked in the&nbsp;<em>Thermopolium</em>.</p><div><figure><img title="Thermopolium-found-intact-with-food-residues-animal-bones-2 Extraordinary discovery in Pompeii: Thermopolium found intact with food residues, animal bones " src="https://weirditaly.com/wp-content/plugins/lazy-load/images/1x1.trans.gif" data-lazy-src="https://weirditaly.com/wp-content/uploads/2020/12/Thermopolium-found-intact-with-food-residues-animal-bones-2.jpg" loading="lazy" width="780" height="519" alt="Weird Italy Thermopolium-found-intact-with-food-residues-animal-bones-2 Extraordinary discovery in Pompeii: Thermopolium found intact with food residues, animal bones Featured Italian History  Pompeii  " srcset="https://weirditaly.com/wp-content/uploads/2020/12/Thermopolium-found-intact-with-food-residues-animal-bones-2.jpg 780w, https://weirditaly.com/wp-content/uploads/2020/12/Thermopolium-found-intact-with-food-residues-animal-bones-2-300x200.jpg 300w, https://weirditaly.com/wp-content/uploads/2020/12/Thermopolium-found-intact-with-food-residues-animal-bones-2-768x511.jpg 768w" sizes="(max-width: 780px) 100vw, 780px"></figure></div><p>“<em>As well as being another insight into daily life at Pompeii, the possibilities for study of this&nbsp;</em>Thermopolium&nbsp;<em>are exceptional, because for the first time an area of this type has been excavated in its entirety, and it has been possible to carry out all the analyses that today’s technology permits,”</em>&nbsp;–&nbsp;<strong>declares Massimo Osanna, Interim Director General of the Archaeological Park of Pompeii</strong>&nbsp;– “<em>the materials which have been discovered have indeed been excavated and studied from all points of view by an interdisciplinary team composed of professionals in the fields of physical anthropology, archaeology, archaeobotany, archaeozoology, geology and vulcanology. The finds will be further analysed in the laboratory, and in particular those remains found in the&nbsp;</em>dolia<em>&nbsp;(terracotta containers) of the counter are expected to yield exceptional data for informing an understanding of what was sold and what the diet was like”.</em></p><p>Another observation of note is the discovery of&nbsp;<strong>human bones</strong>, albeit found sadly dispersed as a result of the tunnels which were dug in the 17th century by illegal excavators, who were searching for precious objects.</p><div><figure><img title="Thermopolium-found-intact-with-food-residues-animal-bones Extraordinary discovery in Pompeii: Thermopolium found intact with food residues, animal bones " src="https://weirditaly.com/wp-content/plugins/lazy-load/images/1x1.trans.gif" data-lazy-src="https://weirditaly.com/wp-content/uploads/2020/12/Thermopolium-found-intact-with-food-residues-animal-bones.jpg" loading="lazy" width="713" height="402" alt="Weird Italy Thermopolium-found-intact-with-food-residues-animal-bones Extraordinary discovery in Pompeii: Thermopolium found intact with food residues, animal bones Featured Italian History  Pompeii  " srcset="https://weirditaly.com/wp-content/uploads/2020/12/Thermopolium-found-intact-with-food-residues-animal-bones.jpg 713w, https://weirditaly.com/wp-content/uploads/2020/12/Thermopolium-found-intact-with-food-residues-animal-bones-300x169.jpg 300w" sizes="(max-width: 713px) 100vw, 713px"></figure></div><p>Several belong to an individual of at least fifty years of age, who at the moment when the pyroclastic current arrived, was most likely on some kind of bed, as evidenced by the space set aside for storing the bed, and a series of nails and wood residues found under the body.</p><p>Other bones, which are yet to be investigated, belong to another individual, and were found inside a large&nbsp;<em>dolium,&nbsp;</em>possibly where they were placed by the first excavators.</p><p>Furthermore, in the&nbsp;<em>Thermopolium</em>,&nbsp;<strong>various pantry and transport materials&nbsp;</strong>were discovered, including:&nbsp;<strong>nine amphorae, a bronze patera, two flasks and a common ceramic table olla.&nbsp;</strong>The flooring of the entire room consisted of a layer of&nbsp;<em>cocciopesto&nbsp;</em>(a waterproof covering made of terracotta fragments), into which fragments of polychrome marble (alabaster,&nbsp;<em>portasanta</em>, green brecciaand bardiglio) were inserted in several areas.</p><p>The&nbsp;<em>Thermopolia</em>, where drinks and hot foods were served, (as indicated by the name of Greek origin), and stored in large&nbsp;<em>dolia&nbsp;</em>(jars) embedded in the masonry counter, were widespread in the Roman world, where it was typical to consume the&nbsp;<em>prandium</em>&nbsp;(the meal)outside the house. In Pompeii alone there are eighty of them.</p><div><figure><img title="Thermopolium-found-intact-with-food-residues-animal-bones-intro-400 Extraordinary discovery in Pompeii: Thermopolium found intact with food residues, animal bones " src="https://weirditaly.com/wp-content/plugins/lazy-load/images/1x1.trans.gif" data-lazy-src="https://weirditaly.com/wp-content/uploads/2020/12/Thermopolium-found-intact-with-food-residues-animal-bones-intro-400.jpg" loading="lazy" width="600" height="451" alt="Weird Italy Thermopolium-found-intact-with-food-residues-animal-bones-intro-400 Extraordinary discovery in Pompeii: Thermopolium found intact with food residues, animal bones Featured Italian History  Pompeii  " srcset="https://weirditaly.com/wp-content/uploads/2020/12/Thermopolium-found-intact-with-food-residues-animal-bones-intro-400.jpg 600w, https://weirditaly.com/wp-content/uploads/2020/12/Thermopolium-found-intact-with-food-residues-animal-bones-intro-400-300x226.jpg 300w" sizes="(max-width: 600px) 100vw, 600px"></figure></div><p><strong><em>THE INITIAL LABORATORY ANALYSIS</em></strong><strong><em>&nbsp;(Valeria Amoretti –&nbsp;</em></strong><strong><em>Anthropologist</em></strong><strong><em>)</em></strong></p><div><p>The first analyses confirm that the paintings on the counter depict, at least in part, the foodstuffs and drinks which were actually sold inside the&nbsp;<em>Thermopolium</em>. The paintings on the counter include two mallard ducks, and indeed a fragment of duck bone was in fact found inside one of the containers, alongside swine, goats, fish and land snails, indicating the great variety of products of animal origin used in the preparation of the dishes.</p><p>On the other hand, the first archaeobotanical analyses have allowed us to identify fragments of deciduous oak, which probably belonged to structural elements of the counter. At the bottom of a&nbsp;<em>dolium</em>&nbsp;– which has been identified as a container for wine on the basis of the bottle for drawing the liquid that was found inside it – the presence of beans was detected, which had been intentionally broken apart or ground. In his&nbsp;<em>De re Coquinaria&nbsp;</em>(I,5), Apicius explains the reason for this, asserting that they were used in order to modify the taste and colour of the wine, bleaching it.</p></div><p>The complete skeleton of a dog was found in the corner between the two doors of the&nbsp;<em>Thermopolium&nbsp;</em>(in the northwestern corner of the room). It was not a large and muscular dog like the one depicted on the counter, but an extremely small specimen, about 20-25cm high at the shoulder despite being an adult dog. Although quite rare, dogs of such small size indicate that intentional selection took place in the Roman age in order to obtain such a result.</p><p>Inside the room – and particularly behind the counter where they were dragged by the first excavators – a significant number of human bones were found, belonging to a mature-senescent individual, of at least 50 years of age. An initial analysis made it possible to link these dispersed bones with what remained of an individual who was discovered in the innermost corner of the shop, and who, at the time the pyroclastic current arrived, was most likely on top of some kind of bed, as evidenced by the space set aside for storing the bed, and a series of nails and wood residues found under the body.</p><p>The bones belonging to at least one other individual, which were discovered inside a large&nbsp;<em>dolium</em>, and were probably positioned in this way by the first excavators, are still to be investigated.</p><p>This is merely the initial macroscopic data yielded by the ongoing excavation, but it will surely not be the last. Indeed, the finds collected and brought to the laboratory will be analysed further, through specific studies in departments and universities with whom we have an agreement, which will allow us to further refine the data at our disposal, and therefore also our knowledge of the&nbsp;<em>Thermopolium&nbsp;</em>and the site.</p><p><a href="http://pompeiisites.org/" target="_blank" rel="noreferrer noopener">SOURCE</a></p></div></div>]]>
            </description>
            <link>https://weirditaly.com/2020/12/26/extraordinary-discovery-in-pompeii-thermopolium-found-intact-with-food-residues-animal-bones/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25545160</guid>
            <pubDate>Sat, 26 Dec 2020 18:08:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Adding BPF target support to the Rust compiler]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25545048">thread link</a>) | @lukastyrychtr
<br/>
December 26, 2020 | https://confused.ai/posts/rust-bpf-target | <a href="https://web.archive.org/web/*/https://confused.ai/posts/rust-bpf-target">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="__next"><section><div><article><div><p>When I created this blog back in September my goal was to post at least once
a month. It's December now and you're reading my second post, so I'm not exactly
off to a great start. 🤔</p><p>Things have been busy on the Rust BPF front though! At the end of October I
began working on a blog about the current state of things, exactly one year
after I started getting involved. While doing that I finally started feeling
inspired enough to try and add a BPF target to rustc, something that had been
on my todo list for a very long time but never managed to find the time to work
on.  (<em>Aah... if only someone wanted to sponsor all this work... wink wink!</em>)</p><p>A couple of weeks ago I finally sent a <a href="https://github.com/rust-lang/rust/pull/79608">pull request</a>
to get the new target(s) merged. The changes were pretty straightforward, with the
only unexpected thing being that I ended up having to write
<a href="https://github.com/alessandrod/bpf-linker">https://github.com/alessandrod/bpf-linker</a> - a partial linker needed to enable
rustc to output BPF bytecode.</p><p>I'm going to tell you why I had to write the linker in a moment, but first,
let's start with looking at how clang - the de facto standard BPF compiler -
compiles C code to BPF.</p><h2>How BPF projects are compiled with clang</h2><p>BPF doesn't have things like shared libraries and executables. Programs are
compiled as object files, then at run-time they're relocated and loaded in the
kernel where they get JIT-ted and executed.</p><p>Because of that, and because for a long time function calls were not allowed so
everything had to be inlined, BPF programs written in C are typically compiled
as a <strong>single compilation unit</strong>, with library code written in <a href="https://github.com/cilium/cilium/tree/master/bpf/lib">header
files</a> and included with
<code>#include</code> directives.</p><p><img alt="clang BPF compilation model" src="https://confused.ai/static/bpf-linker-clang.svg"></p><p>This compilation model is simple and effective: <strong>one compilation unit</strong> goes
in, <strong>one object file</strong> comes out. Because BPF programs tend to be small,
recompiling the whole source code on every change is generally not an issue.
Since everything gets compiled together, there's <strong>no need for linking</strong>
separate compilation artifacts. <em>(You see where this is going?)</em></p><h2>How Rust projects are compiled</h2><p>Rust uses a different compilation model. Code is split into crates. Crates
can't be lumped together with <code>#include</code> directives, they are always compiled
independently as <strong>one or more compilation units</strong>.</p><p>Consider the following example:</p><pre><code><span>alessandro@ubvm:~/src/app$ cargo tree
</span>app v0.1.0 (/home/alessandro/src/app)
<!-- -->└── dep v0.1.0 (/home/alessandro/src/dep)
<!-- -->
<!-- -->alessandro@ubvm:~/src/app$ cargo build
<!-- -->   Compiling dep v0.1.0 (/home/alessandro/src/dep)
<!-- -->   Compiling app v0.1.0 (/home/alessandro/src/app)
<!-- -->    Finished dev [unoptimized + debuginfo] target(s) in 0.19s
</code></pre><p><code>app</code> is an application crate that depends on a library <code>dep</code>. When building,
the following happens:</p><p><img alt="Rust compilation model" src="https://confused.ai/static/bpf-linker-rustc.svg"></p><p>The rust compiler is invoked twice: first to compile the <code>dep</code> crate as a rust
library, then to compile the <code>app</code> crate as an executable. When the <code>app</code> crate
is compiled, the <strong>pre-compiled</strong> <code>dep</code> crate is provided as input to the
compiler via the <code>--extern</code> option.</p><p>This compilation model always produces <strong>multiple object files</strong>, which then
must be <strong>linked</strong> together to produce the final output. The rust compiler uses an
internal linker abstraction, whose implementations spawn to external linkers
like <code>ld</code>, <code>lld</code>, <code>link.exe</code> and
<a href="https://doc.rust-lang.org/rustc/codegen-options/index.html#linker-flavor">others</a>.</p><p>Therefore, to add a new target with this model we need a linker for the target.
Since clang never links anything when targeting BPF though, it turns out that <code>lld</code> -
the LLVM linker - can't link BPF at all. So I wrote a new linker.</p><h2>A new (partial) BPF linker</h2><p><a href="https://github.com/alessandrod/bpf-linker">bpf-linker</a> takes LLVM bitcode as
input, optionally applies target-specific optimizations, and outputs a single
BPF object file. The inputs can be bitcode files (<code>.bc</code>), object files
with embedded bitcode (eg <code>.o</code> files produced compiling with
<a href="https://doc.rust-lang.org/rustc/codegen-options/index.html#embed-bitcode">-C embed-bitcode=yes</a>),
or archive files (<code>.a</code> or <code>.rlib</code>).</p><p>The linker works with anything that can output LLVM bitcode, including clang.
There are a couple of reasons for taking bitcode as input instead of object
files.</p><p>Only a subset of Rust (just like only a subset of C) can be compiled to BPF
bytecode. Therefore bpf-linker tries to push code generation as late as
possible in the compilation process, after link-time optimizations have been
applied and dead code has been eliminated. This avoids hitting potential
failures generating bytecode for unsupported Rust code that is actually
unused (eg, parts of the <code>core</code> crate that are never used in a BPF context).</p><p>Another reason is that the linker might need to apply extra optimizations like
<a href="https://github.com/alessandrod/bpf-linker/blob/d890b113ffe612dcba51cc7d23a14fabd8198318/src/bin/bpf-linker.rs#L104">--unroll-loops</a>
and
<a href="https://github.com/alessandrod/bpf-linker/blob/d890b113ffe612dcba51cc7d23a14fabd8198318/src/bin/bpf-linker.rs#L108">--ignore-inline-never</a>
when targeting older kernel versions that don't support loops and calls.</p><h2>Not one but two BPF targets!</h2><p>The rustc fork at <a href="https://github.com/alessandrod/rust/tree/bpf">https://github.com/alessandrod/rust/tree/bpf</a> includes two new
targets, <code>bpfel-unknown-none</code> and <code>bpfeb-unknown-none</code> which generate little
endian and big endian BPF respectively. The targets automatically invoke
bpf-linker so with that fork, compiling a BPF project with Rust is finally as
easy as:</p><pre><code><span>alessandro@ubvm:~/src/app$ cargo build --target=bpfel-unknown-none
</span>   Compiling dep v0.1.0 (/home/alessandro/src/dep)
<!-- -->   Compiling app v0.1.0 (/home/alessandro/src/app)
<!-- -->    Finished dev [unoptimized + debuginfo] target(s) in 1.98s
<!-- -->alessandro@ubvm:~/src/app$ file target/bpfel-unknown-none/debug/app
<!-- -->target/bpfel-unknown-none/debug/app: ELF 64-bit LSB relocatable, eBPF, version 1 (SYSV), not stripped
</code></pre><p>Getting the targets merged will probably take a while, but worry not! With a
little trick, you can use the linker to <em>compile BPF code with stable Rust
already today!</em></p><p>I made bpf-linker implement a <code>wasm-ld</code> compatible command line. Since rustc
already knows how to invoke <code>wasm-ld</code> when targeting webassembly, it can be
made to use <code>bpf-linker</code> with the following options:</p><pre><code><span>alessandro@ubvm:~/src/app$ cargo rustc -- \
</span>        -C linker-flavor=wasm-ld \
<!-- -->        -C linker=bpf-linker \
<!-- -->        -C linker-plugin-lto 
<!-- -->   Compiling dep v0.1.0 (/home/alessandro/src/dep)
<!-- -->   Compiling app v0.1.0 (/home/alessandro/src/app)
<!-- -->    Finished dev [unoptimized + debuginfo] target(s) in 0.68s
<!-- -->alessandro@ubvm:~/src/app$ file target/debug/app
<!-- -->target/debug/app: ELF 64-bit LSB relocatable, eBPF, version 1 (SYSV), not stripped
</code></pre><p>Let's see what those options do:</p><ul><li><a href="https://doc.rust-lang.org/rustc/codegen-options/index.html#linker-flavor">-C linker-flavor=wasm-ld</a>
tells the compiler that the linker supports the same command line options as <code>wasm-ld</code></li><li><a href="https://doc.rust-lang.org/rustc/codegen-options/index.html#linker">-C linker=bpf-linker</a>
configures bpf-linker as the linker to spawn</li><li><a href="https://doc.rust-lang.org/rustc/linker-plugin-lto.html#linker-plugin-lto">-C linker-plugin-lto</a>
tells rustc to pass LLVM bitcode to the linker</li></ul><p>And voilà! Go compile some BPF with stable rust now 🎉</p><h2>What's next</h2><p>bpf-linker is obviously new and needs more testing. Over the next few weeks I'm
going to add more unit tests and try it on more Rust code. I'm also thinking of
trying to link the whole Cilium BPF code with it just to test with a large,
complex code base.</p><p>While working on the rustc target, at some point I went off on a bit of a
tangent and ended up making some changes to LLVM and the kernel so I'm going to
try and finish those off. They are needed to implement the
<a href="https://llvm.org/docs/LangRef.html#llvm-trap-intrinsic">llvm.trap</a> intrinsic
so <code>panic!()</code> can be implemented in a generic way, instead of having to resort
to program-specific hacks like jumping to an empty program with
<code>bpf_tail_call()</code>. I'll probably do a whole separate post about that.</p><p>Finally, after my <a href="https://confused.ai/posts/intercepting-zoom-tls-encryption-bpf-uprobes">last post</a> I
received some truly great feedback! I was especially pleased to hear from a
couple of companies that are using BPF and that are considering using it with
Rust.</p><p>I was equally pleased to see that there's a group of people developing BPF in C
that feel strongly that I'm wasting my time and that Rust brings nothing over
C, being BPF statically verified, not needing the borrow checker etc.  They gave
me inspiration for a post I'm hoping to publish soon, which will cover why I
think that Rust has the potential to become as central to the BPF ecosystem as it
is central to WebAssembly development today. Until next time!</p></div></article></div></section></div></div>]]>
            </description>
            <link>https://confused.ai/posts/rust-bpf-target</link>
            <guid isPermaLink="false">hacker-news-small-sites-25545048</guid>
            <pubDate>Sat, 26 Dec 2020 17:53:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What’s the best non-smart TV sold today?]]>
            </title>
            <description>
<![CDATA[
Score 208 | Comments 241 (<a href="https://news.ycombinator.com/item?id=25544831">thread link</a>) | @thomas
<br/>
December 26, 2020 | https://helpatmyhome.com/best-non-smart-tv/ | <a href="https://web.archive.org/web/*/https://helpatmyhome.com/best-non-smart-tv/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><main id="genesis-content"><article aria-label="What’s The Best Non-Smart TV Sold Today?"><div itemprop="text">
<p>With the industry-wide transition to smart TVs many of us have felt like there is no option but to get one. And the walls are closing in — it seems like almost every TV sold today is a smart one, which means a lack of control of what’s happening on our device, the possibility of the company deciding one day to show us ads (as Samsung as done), and the certainty that our viewing and usage data is being sent off to all sorts of third parties. </p>



<p>The solution? Buy a dumb TV!</p>



<h2><span id="What_Is_A_Dumb_TV">What Is A Dumb TV?</span></h2>



<p>The alternative to Smart TVs are, of course, non-smart TVs or, as people have taken to calling them, dumb TVs. These are televisions without an internet connection, without built-in HBO Max or Disney, without Amazon Alexa, and lacking apps of any kind. A dumb TV is the television equivalent of a flip phone. </p>



<p>Just because your TV is dumb doesn’t mean you can’t use Roku or Apple TV, etc. In this case you are simply opting to plug those devices into your TV via HDMI rather than having them built in. In almost all cases the plugged in device is better than having the software version built into your TV, so you are making your TV be smart instead of being forced to have one. </p>



<h2><span id="Why_Not_Buy_An_Old_TV">Why Not Buy An Old TV?</span></h2>



<p>You can definitely buy an old TV to solve this problem instead of hunting around for an increasingly rare non-smart in 2021. Televisions age pretty well, so as long as you can find something relatively high quality and made in the last 8 (or so) years you are good to go. </p>



<p>You’ll mainly need to ensure that your older model is in good physical condition, has enough HDMI ports to suit a current user, has no burn-in or wear issues, has a working remote, doesn’t have cracked or wrecked speakers, and that the color hasn’t gone crazy over time. You’ll also want to make sure your TV is an LED TV, so it’s power efficient and looks great, instead of using an outdated technology (like plasma). </p>



<p>For example, I have a Samsung dumb TV from 2012 (or so) that works perfectly well, has sufficient volume, and completely gets the job done. It was a good TV when I bought it, and it’s a great TV now, because it doesn’t have any of the features that I don’t want — and can’t avoid — today. </p>



<h2><span id="Just_Dont_Connect_It_To_the_Internet">Just Don’t Connect It To the Internet</span></h2>



<p>A smart TV can’ the smart without an internet connection so one thing you can do to get a dumb TV is to simply not connect it to your WiFi network. Your TV will will work since it’s connect through coax but the rest of the data cannot flow because the television doesn’t have an internet connection!</p>



<p>You can then go ahead and add a Nvidia Shield or Apple TV and connect that to the internet. This way the auxiliary devices will have internet connection <em>while you are using them</em>, but the TV itself (the hypervisor in this scenario) stays blissfully unaware of that internet connection. </p>



<p>Note, there have been scattered reports of some TVs, including those from Samsung, simply searching for open WiFi signals and attempting to connect to them, but this is an extreme and user-hostile example that hopefully won’t be repeated (assuming its true in the first place).</p>



<p>Some smart TV will force you to connect them to the internet for firmware updates and will resort to frequent nagging to get you to do this, but very few will force you to do it or not work entirely without the connection (yet). </p>



<h2><span id="Best_Dumb_TVs">Best Dumb TVs</span></h2>



<p>Here are some intelligent picks in non-smart TVs. </p>



<figure><img loading="lazy" src="https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/scapter-1024x606.jpg" alt="" width="433" height="256" srcset="https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/scapter-1024x606.jpg 1024w, https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/scapter-350x207.jpg 350w, https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/scapter-768x454.jpg 768w, https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/scapter-1536x908.jpg 1536w, https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/scapter.jpg 1782w" sizes="(max-width: 433px) 100vw, 433px"></figure><h2><span id="Sceptre_50-inch_4K_LED_TV">Sceptre 50-inch 4K LED TV</span></h2>



<p>Sceptre has generally been considered a mid-tier TV company, but they have done a good job of not transitioning entirely to Smart TVs. The <a href="https://amzn.to/3mZUDAp" target="_blank" rel="noreferrer noopener nofollow external" title="https://amzn.to/3mZUDAp" data-wpel-link="external">Sceptre U518CV-UM</a> is a 50-inch 4K that’s completely non-smart TV that is from the 2019 model year, so you are getting recent tech without the connectivity features that you don’t want.</p>



<ul><li>4K Television (3840×2160, UHD resolution)</li><li>Dimensions: 44.6 x 28.5 x 10.8 inches</li><li>Weight: 29.3 pounds</li></ul><p>Sceptre has the same non-smart TV in larger sizes as well, <a href="https://amzn.to/2VGHSyD" target="_blank" rel="noreferrer noopener nofollow external" title="https://amzn.to/2VGHSyD" data-wpel-link="external">up to 65-inches</a> if you need the extra size or have a big room to fill. </p>



<div><figure><img loading="lazy" src="https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/insing-1024x622.jpg" alt="" width="341" height="207" srcset="https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/insing-1024x622.jpg 1024w, https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/insing-350x213.jpg 350w, https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/insing-768x466.jpg 768w, https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/insing.jpg 1258w" sizes="(max-width: 341px) 100vw, 341px"></figure></div>



<h3><span id="Insignia_55-inch_Class_LED">Insignia 55-inch Class LED</span></h3>



<p>If you live near a Best Buy then you will have access to their house brand, Insignia. The Insignia 55-inch (NS-55D420NA20) is a LED-lit 1080p television that sells for about $300. It’s devoid of smart features but it has three HDMI ports and was first released in 2019. </p>



<p>This line of Insignia dumb TVs is sold from 19 inches up to 58 inches so there will be a TV for every room size. </p>



<div><figure><img loading="lazy" src="https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/smasungbuns-1024x625.jpg" alt="" width="451" height="275" srcset="https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/smasungbuns-1024x625.jpg 1024w, https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/smasungbuns-350x214.jpg 350w, https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/smasungbuns-768x469.jpg 768w, https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/smasungbuns.jpg 1170w" sizes="(max-width: 451px) 100vw, 451px"></figure></div>



<h2><span id="Samsung_Business_BER_43-Inch">Samsung Business BER 43-Inch </span></h2>



<p>This <a href="https://amzn.to/2VFc4di" target="_blank" rel="noreferrer noopener nofollow external" title="https://amzn.to/2VFc4di" data-wpel-link="external">Samsung Business line TV</a> (model BE43R) is a full HD (1080p) LED TV that is part of Samsung’s commercial line, but doesn’t have the crazy price tag to reflect it. Commercial TV’s can get super experience for what seems like a normal TV — and for what will function like a normal TV if you are simply using it like one! The smartest feature this TV has is the ability to play images from a USB stick.</p>



<p>This TV has all the features you’d expect from a normal television, like HDMI input, and isn’t missing anything obvious. For example it still has integrated speakers and 1080p (1920×1080) resolution.</p>



<p>If you are open to commercial TVs there <a href="https://amzn.to/3gdIm8R" target="_blank" rel="noreferrer noopener nofollow external" title="https://amzn.to/3gdIm8R" data-wpel-link="external">are a huge number to explore</a>.</p>



<h2><span id="Dumb_TV_Alternatives">Dumb TV Alternatives</span></h2>



<p>Of course there are other ways to avoid a smart TV. Here are some bright ideas…</p>



<ul><li><strong>Projector:</strong> The smart device revolution has really come to projectors yet, so you can watch your TV and movies through a projector without having to worry about your privacy or ads</li><li><strong>Monitor:</strong> Computer monitors haven’t gotten smart (since they are connected to something smart) so if you watch television on a computer monitor you’ll have no need to worry about built-in Alexa or Google Home</li><li><strong>Business TV (aka Commercial Display):</strong> A <a href="https://www.neweggbusiness.com/s/commercial-tvs/id-3672" target="_blank" rel="noreferrer noopener nofollow external" title="https://www.neweggbusiness.com/s/commercial-tvs/id-3672" data-wpel-link="external">business-focused TV</a> (something you’d see hung in an office or airport and playing CNN all day on mute) is designed for simplicity and long-lasting performance. These haven’t yet gotten smart and will likely stay dumb for years as they need to have error- and update-free operation for years on end</li><li><strong>Outdoor TV:</strong> For some reason outdoor and weatherproof televisions have yet to go smart. Here is a <a href="https://amzn.to/3lMr0B0" target="_blank" rel="noreferrer noopener nofollow external" title="https://amzn.to/3lMr0B0" data-wpel-link="external">good example of one from Furrion</a>.</li></ul><h2><span id="FAQs">FAQs</span></h2>


<div><ol><li><strong>Can I use PiHole or a similar device to block the ads and privacy leaks from my smart TV?</strong><p>You'd think this would work, but manufacturers have gotten wise to the PiHole and other methods of blocking tracking and advertising injection so, no, you really can't. At this point many manufacturers will take measures like building ads into the core technology of their software so blocking ads will break other features. Also many manufacturers will hardcode their DNS to their preferred vendor, not allowing you to override their option with your PiHole. </p></li></ol></div></div></article></main></div></div></div>]]>
            </description>
            <link>https://helpatmyhome.com/best-non-smart-tv/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25544831</guid>
            <pubDate>Sat, 26 Dec 2020 17:26:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is PHP still relevant in 2021?]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25544627">thread link</a>) | @karakanb
<br/>
December 26, 2020 | https://saasstarterkit.app/blog/is-php-still-relevant-2021 | <a href="https://web.archive.org/web/*/https://saasstarterkit.app/blog/is-php-still-relevant-2021">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main" role="main">
<div>
<article>

<figure>
</figure>
<section>
<div>
<p>As one of the poster childs for bad programming languages, PHP has always been in the top 5 “worst programming languages”; however, as of 2021, is that still a thing?</p>

<p>PHP was developed by <a href="https://en.wikipedia.org/wiki/Rasmus_Lerdorf">Rasmus Lerdorf</a> in 1994. Lerdorf developed a bunch of scripts to track the visits to his online resume, and named them as “Personal Home Page Tools”, which then evolved into being called as “PHP Tools”. He kept adding more tools to this suite, and at some point pulled off a rewrite of the tools, including added functionality for database interactions and more, turning it into a more complete framework. From that point on, the tools have evolved into a more complex primitives and kept gaining more users after it is <a href="https://groups.google.com/g/comp.infosystems.www.authoring.cgi/c/PyJ25gZ6z7A/m/M9FkTUVDfcwJ?pli=1">open-sourced</a> in 1995. A more detailed history of the language can be found in <a href="https://www.php.net/manual/en/history.php.php">the official PHP website</a>.</p>
<p>As of now, the latest version of the PHP language is 8.0.</p>

<p>The language has had a target on its back for years now, and people are rightfully calling out the bad taste they have with the language, especially with the older versions. The language has been developed with the intention of being a templating language, rather than being a full-blown programming language; therefore, there are some downsides with it that made it especially harder to maintain larger apps.</p>
<h2 id="weak-typing">Weak Typing</h2>
<p>One part of the language that I personally dislike is the weak typing that allows combining different types and casts them implicitly. Consider the following example:</p>
<div><div><pre><code><span>echo</span> <span>"1"</span> <span>+</span> <span>3</span><span>;</span>
<span>echo</span> <span>1</span> <span>+</span> <span>"3"</span><span>;</span>
<span>echo</span> <span>"1"</span> <span>+</span> <span>"3"</span><span>;</span>
</code></pre></div></div>
<p>The results of all these operations are <code>4</code>, which means the language casts the numbers in the string to integers in the context of the addition operator. This might be desirable in some cases or it might save a few lines of code here and there, but the larger a project gets, the harder it becomes to maintain it.</p>
<p>The more recent versions of the language have started introducing warnings for these kinds of weird and invalid operations, which means that they are either deprecated or already on their way to be deprecated.</p>
<h2 id="lack-of-namespaces">Lack of Namespaces</h2>
<p>The support for namespaces has been introduced in PHP by the version 5.3, which means that all the older projects have had to build their own kind of namespacing, which usually relied on adding namespaces to the class and method names, requiring absurdly long names everywhere. For projects that were developed with the prior versions, it is very common to see classes named like <code>Payments_Provider_ProcessorProvider_SomeExternalServiceProvider</code> whereas it could have been named like <code>SomeExternalServiceProvider</code> simply. This results in very verbose code in most of the cases, and it makes it harder to read and skim through the code.</p>
<p>The more recent versions of the language doesn’t have this problem though.</p>
<h2 id="inconsistent-standard-library-functions">Inconsistent Standard Library Functions</h2>
<p>I am not saying the standard library of the language is bad, but one could argue that it could have been better. To be fair, the language has been improving quite a lot, but the early versions of the standard library, which is already being used, referenced and supported due to backwards compatibility results, were lacking consistency. Although a small disturbance, this meant that many of the standard library functions had different naming conventions, argument names and ordering, making it harder to assume the defaults and the behavior.</p>
<p>Here are some naming inconsistencies with the string methods:</p>
<ul>
<li><a href="https://www.php.net/manual/en/function.strpos.php"><code>strpos(string $haystack, string $needle, int $offset = 0): int|false</code></a>: Find the position of the first occurrence of a substring in a string.</li>
<li><a href="https://www.php.net/manual/en/function.str-split.php"><code>str_split(string $string, int $length = 1): array</code></a>: Convert a string to an array.</li>
<li><a href="https://www.php.net/manual/en/function.explode.php"><code> explode(string $separator, string $string, int $limit = PHP_INT_MAX): array</code></a>: Split a string by a string.</li>
</ul>
<p>Three different functions, one with a <code>str</code> prefix, another with <code>str_</code> prefix, and the third with no prefix. The <code>$string</code> argument is the first argument for <code>str_split</code>, but the second one for the <code>explode</code> one. You can check out all the string methods <a href="https://www.php.net/manual/en/ref.strings.php">in the documentation</a>, and each of these patterns have many functions following similar patterns, meaning that there is not much of a consistency with these functions.</p>
<h2 id="superglobals">Superglobals</h2>
<p>More of personal choice, but I hate the use of the globals, and consequently <a href="https://www.php.net/manual/en/language.variables.superglobals.php">superglobals</a>. Especially if you run into some home-baked old projects, it is highly likely that you’ll run into the famous variables like <code>$_SERVER</code> or <code>$_REQUEST</code>. Don’t get me wrong, these are very helpful sometimes and will need to be used eventually; however, encapsulating these into reusable classes should be done as one of the first steps in order to be able to use these values safely. If not, touching these values or doing any change in a slightly larger project gets a very complicated experience where there are many hidden dependencies on these values.</p>

<p>Even though it had left a bad taste in many people’s mouth, the language itself has been improving quite a lot in the last few years. With the release of PHP 7, the language has gone through a modernization process where many nice features were introduced to the language basics, the speed was improved, and the usability has increased quite a lot.</p>
<h2 id="type-hints">Type-hints</h2>
<p>This is one of my favorite ways of modernizing legacy PHP code: using non-enforced type-hints that handle type casting as well as providing documentation for the code. Check out the following simple function:</p>
<div><div><pre><code><span>function</span> <span>isValueSomething</span><span>(</span><span>$value</span><span>)</span> <span>{}</span>
</code></pre></div></div>
<p>If you include the type hints, it becomes something like this:</p>
<div><div><pre><code><span>function</span> <span>isValueSomething</span><span>(</span><span>string</span> <span>$value</span><span>)</span><span>:</span> <span>bool</span> <span>{}</span>
</code></pre></div></div>
<p>Just by looking at the signature, we are able to tell it expects a string value, and it will return a boolean result. One could claim that the naming convention could have been useful here as well, but these type-hints reassure that the values will be of those types, as well as giving the IDE a lot of power for auto-complete and static analysis with warnings and stuff.</p>
<p>Since PHP 7.4, PHP allows defining typed properties for classes as well:</p>
<div><div><pre><code><span>class</span> <span>Person</span> <span>{</span>
    <span>public</span> <span>string</span> <span>$firstName</span><span>;</span>

    <span>public</span> <span>string</span> <span>$lastName</span><span>;</span> 

    <span>public</span> <span>int</span> <span>$age</span><span>;</span>

    <span>public</span> <span>?</span><span>string</span> <span>$job</span><span>;</span>
<span>}</span>
</code></pre></div></div>
<p>This means your <code>Person</code> objects will have string first and last names, an integer age, and a nullable string value for the job. Being able to define this becomes very useful the more classes you have.</p>
<h2 id="syntax-improvements">Syntax Improvements</h2>
<p>PHP now has bunch of syntactical improvements:</p>
<ul>
<li><a href="https://www.php.net/manual/en/functions.arrow.php">Arrow functions</a>: <code>fn ($x, $y) =&gt; $x + $y;</code></li>
<li>Null coalescing operator: <code>$value = $array['key'] ?? 'default value';</code></li>
<li>Null coalescing assignment: <code>return $cache['key'] ??= computeSomeValue('key')</code>;</li>
<li>Array spreading: <code>$first = ['a', 'b']; $second = ['c', 'd']; $final = [...$first, ...$second];</code></li>
<li><a href="https://www.php.net/manual/en/functions.arguments.php#functions.named-arguments">Named arguments</a>: <code>array_fill(start_index: 0, num: 100, value: 50);</code></li>
<li>Numeric literal separator: <code>299_792_458</code></li>
</ul>
<p>In addition to these syntactical improvements, it also includes stuff for more complex improvements.</p>
<h3 id="constructor-promotion"><a href="https://www.php.net/manual/en/language.oop5.decon.php#language.oop5.decon.constructor.promotion">Constructor Promotion</a></h3>
<p>Look at the following Person class:</p>
<div><div><pre><code><span>class</span> <span>Person</span> <span>{</span>
    <span>private</span> <span>string</span> <span>$firstName</span><span>;</span>

    <span>private</span> <span>string</span> <span>$lastName</span><span>;</span> 

    <span>protected</span> <span>int</span> <span>$age</span><span>;</span>

    <span>public</span> <span>?</span><span>string</span> <span>$job</span><span>;</span>

    <span>public</span> <span>function</span> <span>__construct</span><span>(</span>
        <span>string</span> <span>$firstName</span><span>,</span>
        <span>string</span> <span>$lastName</span><span>,</span>
        <span>int</span> <span>$age</span><span>,</span>
        <span>?</span><span>string</span> <span>$job</span>
    <span>){</span>
        <span>$this</span><span>-&gt;</span><span>firstName</span> <span>=</span> <span>$firstName</span><span>;</span>
        <span>$this</span><span>-&gt;</span><span>lastName</span> <span>=</span> <span>$lastName</span><span>;</span>
        <span>$this</span><span>-&gt;</span><span>age</span> <span>=</span> <span>$age</span><span>;</span>
        <span>$this</span><span>-&gt;</span><span>job</span> <span>=</span> <span>$job</span><span>;</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>
<p>Instead of having this unnecessarily verbose code, PHP 8 supports writing the following code:</p>
<div><div><pre><code><span>class</span> <span>Person</span> <span>{</span>
    <span>public</span> <span>function</span> <span>__construct</span><span>(</span>
        <span>private</span> <span>string</span> <span>$firstName</span><span>,</span>
        <span>private</span> <span>string</span> <span>$lastName</span><span>,</span>
        <span>protected</span> <span>int</span> <span>$age</span><span>,</span>
        <span>public</span> <span>?</span><span>string</span> <span>$job</span>
    <span>){}</span>
<span>}</span>
</code></pre></div></div>
<h3 id="nullsafe-operator"><a href="https://www.php.net/manual/en/language.oop5.basic.php#language.oop5.basic.nullsafe">Nullsafe Operator</a></h3>
<p>This is something that had existed in some other languages like Javascript but PHP didn’t have the support for this. Take a look at the following code which I grabbed from the PHP docs:</p>
<div><div><pre><code><span>if</span> <span>(</span><span>is_null</span><span>(</span><span>$repository</span><span>))</span> <span>{</span>
    <span>$result</span> <span>=</span> <span>null</span><span>;</span>
<span>}</span> <span>else</span> <span>{</span>
    <span>$user</span> <span>=</span> <span>$repository</span><span>-&gt;</span><span>getUser</span><span>(</span><span>5</span><span>);</span>
    <span>if</span> <span>(</span><span>is_null</span><span>(</span><span>$user</span><span>))</span> <span>{</span>
        <span>$result</span> <span>=</span> <span>null</span><span>;</span>
    <span>}</span> <span>else</span> <span>{</span>
        <span>$result</span> <span>=</span> <span>$user</span><span>-&gt;</span><span>name</span><span>;</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>
<p>This was how the logic would be written with the older PHP versions with respect to null-checks. The new nullsafe operator allows converting this to simply:</p>
<div><div><pre><code><span>$result</span> <span>=</span> <span>$repository</span><span>?-&gt;</span><span>getUser</span><span>(</span><span>5</span><span>)</span><span>?-&gt;</span><span>name</span><span>;</span>
</code></pre></div></div>
<p>Isn’t it gorgeous?</p>
<h3 id="union-types"><a href="https://www.php.net/manual/en/language.types.declarations.php#language.types.declarations.union">Union Types</a></h3>
<p>Even though this is a less favorite feature of mine, it is still valuable for the cases where there is already multiple possible types and we don’t type-hint anything. Union types simply allow defining multiple types for a value as options. Thanks to the union types, the following code becomes valid:</p>
<div><div><pre><code><span>function</span> <span>doSomething</span><span>(</span><span>int</span><span>|</span><span>string</span> <span>$value</span><span>)</span><span>:</span> <span>bool</span><span>|</span><span>array</span> <span>{}</span>
</code></pre></div></div>
<p>Usually having multiple return types indicate an opportunity for improvement, but previous versions of PHP didn’t allow us to define types for cases like these at all, so having this is still an improvement.</p>
<h2 id="performance">Performance</h2>
<p>I don’t have any hard numbers compared to other languages, but PHP has improved significantly over time compared to the previous versions. In addition to the jump PHP 7 brought over PHP 5.6, all the consecutive releases have brought several percent-point improvements at least and the trend is continuing. Some benchmarks <a href="https://www.phoronix.com/scan.php?page=article&amp;item=php-74-benchmarks&amp;num=2">done by Phoronix</a> show that the latest PHP 8 is more than 3x faster than PHP 5.6. There are more detailed tests in the original posts, make sure to give it a look.</p>
<p><img src="https://saasstarterkit.app/blog/assets/images/posts/is-php-still-relevant/php-benchmark-1.png" alt="PHP Benchmark 1"></p>
<p>In addition to those benchmarks, Kinsta has also conducted some real-world benchmarks with tools like Wordpress, <a href="https://kinsta.com/blog/php-benchmarks/#">full article here</a>. Here’s the result for Wordpress 5.3:</p>
<p><img src="https://saasstarterkit.app/blog/assets/images/posts/is-php-still-relevant/php-benchmark-2.png" alt="PHP Benchmark 2"></p>
<p>The numeric results they have shared are:</p>
<ul>
<li>WordPress 5.3 PHP 5.6 benchmark: <code>97.71 req/sec</code></li>
<li>WordPress 5.3 PHP 7.0 benchmark results: <code>256.81 req/sec</code></li>
<li>WordPress 5.3 PHP 7.1 benchmark results: <code>256.99 req/sec</code></li>
<li>WordPress 5.3 PHP 7.2 benchmark results: <code>273.07 req/sec</code></li>
<li>WordPress 5.3 PHP 7.3 benchmark results: <code>305.59 req/sec</code></li>
<li>WordPress 5.3 PHP 7.4 benchmark results: <code>313.42 req/sec</code></li>
</ul>
<p>These benchmarks do not include PHP 8 yet, but the 7.4 is capable of handling 3x requests of 5.6, which is a pretty significant improvement.</p>

<p>Overall, PHP has improved quite a lot over …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://saasstarterkit.app/blog/is-php-still-relevant-2021">https://saasstarterkit.app/blog/is-php-still-relevant-2021</a></em></p>]]>
            </description>
            <link>https://saasstarterkit.app/blog/is-php-still-relevant-2021</link>
            <guid isPermaLink="false">hacker-news-small-sites-25544627</guid>
            <pubDate>Sat, 26 Dec 2020 16:59:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Turbo Pascal Internals]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25544567">thread link</a>) | @lelf
<br/>
December 26, 2020 | http://direct.turbopascal.org/turbo-pascal-internals | <a href="https://web.archive.org/web/*/http://direct.turbopascal.org/turbo-pascal-internals">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div width="100%">
<tbody><tr>
	<td colspan="2">
				<p>Turbo Pascal compiler functions are grouped into several categories/units according to their role in the compiler. This grouping is done only to have a better overview on the individual parts of the compiler. On the other hand, functions from one group usually share common types and variables and therefore it makes sense to place them in separate units.</p>
<h2>Basic facts about Turbo Pascal</h2>
<div><p>Unit files in Turbo Pascal (tpu extension) are actually <a href="http://direct.turbopascal.org/symbol-tables">symbol tables</a> that are <a href="http://direct.turbopascal.org/compacting-symbol-tables">compacted</a> and <a href="http://direct.turbopascal.org/creating-unit-file">saved</a> as individual files. The <a href="http://direct.turbopascal.org/system-unit">System unit</a> is implicitly used in every program or unit. It contains the boot-strap symbol table and compiler procedures. The definition order of these compiler procedures is important because compiler calls them by id number. To compile <a href="http://direct.turbopascal.org/system-unit">System unit</a> you need bootstrap symbol table (SYSTEM.TPS).</p></div>
<p>Boot-strap symbol table contains <a href="http://direct.turbopascal.org/system-type-definitions">system types</a> like Byte, Char, Boolean, port identifiers, memory identifiers, system functions and system procedures.</p>
<div><p>Turbo Pascal library (extension tpl) is simple binary concatenation of one or more units. It is loaded at the compiler start. It should contain at least the system unit. You can create unit with console command copy:</p></div>
<div><pre>copy /b  system.tpu  unit1.tpu  unit2.tpu  turbo.tpl
</pre></div>
<div><p>Turbo Pascal uses low-level <a href="http://direct.turbopascal.org/intermediate-code">intermediate code</a>. Each record can contain target instruction with reference data,  intermediate code instruction for  subroutines or special meta instruction.</p><p>Turbo Pascal relies heavily on the <a href="http://en.wikipedia.org/wiki/Intel_8086#Segmentation" target="_blank">segment:offset</a> architecture of the x86 family in the real mode. In many cases this is a limiting factor because many data structures are limited to 64 KB. But on the other hand this comes very convenient when dealing with addresses and offsets.</p></div>		</td>
</tr>
<tr>
	<td colspan="2">
		<ul>
					<li>
      <a href="http://direct.turbopascal.org/compiler">
        Compiler</a>
									<br>
			<div>
<div><p>Here is located the main program, common variables, and everything else that does not belong into other categories.</p></div>
</div>					</li>
					<li>
      <a href="http://direct.turbopascal.org/scanner">
        Scanner</a>
									<br>
			<div><p>Scanner contains functions that processes source files, <a href="http://direct.turbopascal.org/extracting-tokens">extracts tokens</a> and processes compiler directives.</p></div>					</li>
					<li>
      <a href="http://direct.turbopascal.org/symbol-tables">
        Symbol Tables</a>
									<br>
			<div><p>Symbol tables are core part of every compiler. Turbo Pascal uses linked lists and hasing to effectively store and retrieve identifiers. Functions in this unit take care for data storing, identifier searching and various symbol table management.</p></div>					</li>
					<li>
      <a href="http://direct.turbopascal.org/parser">
        Parser</a>
									
			<p>Parser processes main program and units, checks syntax, processes stream of tokens and generates intermediate code. This is where the core compiler functions are located.</p>
<br>					</li>
					<li>
      <a href="http://direct.turbopascal.org/expressions">
        Expressions</a>
									<br>
			<div><p>Expression in Turbo Pascal is everything from constant, variable, calculation or just identifier. This unit contains over 100 functions to process every possible Turbo Pascal expression.</p></div>					</li>
					<li>
      <a href="http://direct.turbopascal.org/calculator">
        Calculator</a>
									
			<p>This unit is used by the Expressions unit and contains functions that process calculations with one or two operands and calculation operation. This unit actually generates code for addition, subtraction, multiplication, division, shifts, etc.</p>
<br>					</li>
					<li>
      <a href="http://direct.turbopascal.org/statements">
        Statements</a>
									<br>
			<div><p>This unit contains files that process each Pascal statement: If, While, For, Repeat, Case, With, GoTo, Inline, Asm block, or system procedure.</p></div>					</li>
					<li>
      <a href="http://direct.turbopascal.org/assembler">
        Assembler</a>
									
			<p>Assembler unit processes assembly instuctions in the Asm-end block and generates code for them.</p>
<br>					</li>
					<li>
      <a href="http://direct.turbopascal.org/system-functions">
        System Functions</a>
									
			<p>This is another unit that is used by the Expressions unit which processes system functions like <a href="http://direct.turbopascal.org/system-function-abs">Abs</a>, <a href="http://direct.turbopascal.org/system-function-upcase">UpCase</a>, <a href="http://direct.turbopascal.org/system-function-sqr">Sqr</a>, <a href="http://direct.turbopascal.org/system-functions-succ-and-pred">Succ</a>, <a href="http://direct.turbopascal.org/system-functions-succ-and-pred">Pred</a>, etc.</p>
<br>					</li>
					<li>
      <a href="http://direct.turbopascal.org/system-procedures">
        System Procedures</a>
									
			<p>This unit contains functions to process system procedures like Write, Writeln, Assign, Dispose, Delete, etc.</p>
<br>					</li>
					<li>
      <a href="http://direct.turbopascal.org/type-definitions">
        Type Definitions</a>
									<br>
			<div><p>Type definitions unit defines data structures for basic types and contains few functions to process type&nbsp;<span>definitions.</span></p></div>					</li>
					<li>
      <a href="http://direct.turbopascal.org/object-files">
        Object Files</a>
									<br>
			<div>
<div><p>This unit imports and processes object files and generates intermediate code for OMF records.</p></div>
</div>					</li>
					<li>
      <a href="http://direct.turbopascal.org/code-generator">
        Code Generator</a>
									<br>
			<div><p>This unit processes intermediate code and generates executable code and reference records for Linker.</p></div>					</li>
					<li>
      <a href="http://direct.turbopascal.org/linker">
        Linker</a>
									<br>
			<div><p>Linker joins code from all used units, determines addresses of variables, functions and procedures, resolves references and generates executable file.</p></div>					</li>
					<li>
      <a href="http://direct.turbopascal.org/io-utilities">
        I/O Utilities</a>
									<br>
			<div><p>Turbo Pascal contains many functions that read or write files, handle error messages and take care for compiler operation.</p></div>					</li>
		</ul>
		</td>
</tr>
</tbody></div></div>]]>
            </description>
            <link>http://direct.turbopascal.org/turbo-pascal-internals</link>
            <guid isPermaLink="false">hacker-news-small-sites-25544567</guid>
            <pubDate>Sat, 26 Dec 2020 16:51:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An open letter to my friends with fuck you money]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25544168">thread link</a>) | @rishabhd
<br/>
December 26, 2020 | https://www.spakhm.com/p/an-open-letter-to-my-friends-with | <a href="https://web.archive.org/web/*/https://www.spakhm.com/p/an-open-letter-to-my-friends-with">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I've been living in Silicon Valley for ten years. During this time I've had the privilege to meet many gifted, benevolent, indefatigable people. You've always graciously offered me your time and resources, for no reason other than your love of the startup world. Thank you for paying it forward and sorry I was a pain in the ass.</p><p>We need to talk. Something's rotten in the state of tech. I know it, you know it, everyone who has any sense at all knows it. Facebook, Twitter and YouTube are quasi-monopolies programming our brains, and we have no access to the source code. Our institutions are captured by agents who do not share our values, and will not stop until they remake the world in their gruesome image. No one is coming to fix this. No one is in control.</p><p>The turbulence has spilled over onto the national arena. In June, Chairman of the Joint Chiefs of Staff Mark Milley wrote a <a href="https://www.jcs.mil/Portals/36/Documents/CJCS%20Memo%20to%20the%20Joint%20Force%20(02JUN2020).pdf">memo</a> to the troops reminding them to uphold the constitution. This is not creative destruction as usual. Here be dragons. But to me the <em>human</em> aspect of this situation is woefully familiar. I try to avoid clichés, but in this case one is eminently appropriate. Social media quasi-monopolies and erosion of our institutions are two sides of the same coin.</p><p>So let's talk about coins. Many of you have house-in-san-francisco-live-off-capital-gains fuck you money. I feel your pain. I really do. You're capable of so much more. Are those take-my-jet-to-south-of-france-while-this-all-blows-over assholes really that much more talented than you? Ok, maybe Zuck is, but he's an exception. Maybe a couple of others, but they're exceptions too. But other than that? No way! Why do they get to sit at the secret tables, pull the secret strings, and live in the future while you're stuck in the present running into your employees at brunch as if you were an ordinary middle manager at Geek Squad?</p><p>I understand your reasoning. You should be at the secret tables! You should be in the South of France! Sit out this political kerfuffle. Live to fight another day. You'll make up for it later, when you finally get to one of those coveted seats. You're a good person. No reason to risk it all now. Better be patient and wait until your time finally comes— that's when you can do the most good.</p><p>This next part is awkward, but some of you <em>are</em> the take-my-jet-to-south-of-france-while-this-all-blows-over assholes. (Is South of France still where assholes with private jets go while everything is falling apart?) I don't understand your world nearly as well, but hey, we're all white males. How different can it be? I'm guessing you have many families depending on you. You plant seeds to improve the world every day— through your investments, your board seats, your philanthropy. You educate politicians and government officials. You coach your kids's middle school football team. Most of America’s taxes come from your pocket. Hell, you probably plant literal trees!</p><p>But between you and me, hanging out with university presidents and having authorized biographers is pretty cool too, isn't it? Some day, say, a century and a half from now, a young entrepreneur somewhere is going to pick up one of those biographies. Can anyone blame you for wanting to live a model life so this kid from the future is properly inspired by your example?</p><p>Let me tell you a less illustrious inspirational story. When I was a kid in Ukraine, I was taking a public bus to get to school. One time a mentally ill man got on. (In that distant world we had no dedicated school buses; this episode was surprising because severely mentally ill people were actually institutionalized.) He began walking up to people's seats and screaming obscenities. I must have been no more than twelve years old, but I vividly remember that scene as if it were yesterday. I can still feel the contrast of this man screaming and the otherwise deathly silence with everyone pretending to look out the window or read their newspapers as if nothing out of the ordinary was happening.</p><p>But Ukraine isn't America. An old babushka looked over the men on the bus and exclaimed: "Are you men or dogshit? Why do you avert your eyes like a bunch of cowards? Did you forget your balls in a jar when you walked out the door this morning the way I sometimes forget my dentures? There are women and children here! Do something!"</p><p>And that was the end of it. The bus driver pulled over, a couple of people forced the man out, and everyone went about their day, shaken, but with this particular problem out of their lives forever.</p><p>I don't mean to sound like an old babushka. I am on your side. I must unwittingly be using hundreds of pieces of software and hardware you've created, just to publish this post. I know the magic you're capable of. I want more of it! Much more! I want AR and VR and civil supersonic aviation and robots and AI and abundant energy and affordable trips to Mars and underwater cities and new physics and space elevators and organ regeneration and an antidote to aging and a thousand other innovations you're going to create that I can't begin to dream of.</p><p>None of that is going to happen without you. But it also isn’t going to happen if you keep hiding in dark corners, whispering your private thoughts when you think no one is listening. If America falls, it is the end. There will be no houses in San Francisco, no seats to covet, no strings to pull, no private jets, and no South of France. Not for you, anyway. And there will be no AR or VR or new physics or space elevators or organ regeneration for me. If she falls, it's back to the dark ages for all of us.</p><p>I don’t know what bewilders me more, your inaction or your performative over-intellectualization, as if reality were a Clubhouse cocktail party. Kuran’s <a href="https://www.amazon.com/Private-Truths-Public-Lies-Falsification/dp/0674707583/">book</a> (or more likely the <a href="https://en.wikipedia.org/wiki/Preference_falsification">wikipedia article</a>) isn’t a grimoire, and <em>preference cascade</em> isn’t a magic spell that absolves you of social responsibility every time you utter it. America has given you your houses and your jets, and has asked very little of you in return. It’s <em>still</em> asking very little— you can discharge your civic duty while eating cupcakes in your pajamas.</p><p>So pretty, please, with sugar on top. Make the announcements. Tweet the tweets. Pay off Jack's dealer to slip him placebo strips so he stops microdosing and pretending he's Steve Jobs. Use the photos you took of Zuck and Sundar at the shapeshifter brothel. Hire whoever you have to hire, fire whoever you have to fire, and do whatever you have to do to get this fucking thing off the bus. Make it your singular purpose. Because if you don't, it will be Dick Costolo's livestream <a href="https://www.forbes.com/sites/abrambrown/2020/10/01/some-business-leader-should-face-a-firing-squad-former-twitter-ceo-dick-costolo-suggests-in-angry-tweet/">commentary</a> all the way to the bitter end.</p><p>P.S. All you ordinary folks reading, don't come after me with pitchforks. I could maaaybe ask for a favor or two, but only if they're small and only on a good day and probably not after this post. It's not like we get tested for COVID with secret instantaneous diagnostics only accessible to the elites and go to the shapeshifter brothel together. I don't get invited to those parties. Which is ok by me because parties make me anxious and shapeshifters creep me out.</p></div></div>]]>
            </description>
            <link>https://www.spakhm.com/p/an-open-letter-to-my-friends-with</link>
            <guid isPermaLink="false">hacker-news-small-sites-25544168</guid>
            <pubDate>Sat, 26 Dec 2020 15:59:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Leader Election Best Practices]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25543923">thread link</a>) | @parsecs
<br/>
December 26, 2020 | https://robertovitillo.com/leader-election-best-practices/ | <a href="https://web.archive.org/web/*/https://robertovitillo.com/leader-election-best-practices/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><header><p>December 26, 2020</p></header><p>Sometimes a single process in a system needs to have special powers, like being the only one that can access a shared resource or assign work to others. To grant a process these powers, the system needs to elect a <em>leader</em> among a set of <em>candidate processes</em>, which remains in charge until it crashes or becomes otherwise unavailable. When that happens, the remaining processes detect that the leader is no longer available and elect a new one.</p><p>Leader election can be implemented without any external dependency like the <a href="https://raft.github.io/raft.pdf">Raft algorithm</a> does. Doing so is far from trivial, though, and it’s best avoided unless you have a very good reason to.</p><p>In practice, you can leverage an external <a href="https://robertovitillo.com/what-every-developer-should-know-about-database-consistency/#strong-consistency">linearizable</a> key-value store, like etcd or Zookeeper, which offer abstractions that make it easy to implement leader election. The abstractions span from basic primitives like compare-and-swap to fully-fledged distributed mutexes.</p><p>Ideally, the external store needs to offer atomic compare-and-swap and expiration times (TTL) for keys. A compare-and-swap operation updates the value of a key if and only if the value matches the expected one, while an expiration time defines the time to live for a key, after which the key expires and is removed from the store if the lease hasn’t been extended. Each process tries to acquire a “lease” by creating a new key with a specific TTL using compare-and-swap. The first process to succeed becomes the leader and remains such until it stops renewing the lease, after which another process can become the leader.</p><p>The TTL expiry logic can also be implemented on the client-side, like this <a href="https://aws.amazon.com/blogs/database/building-distributed-locks-with-the-dynamodb-lock-client/">locking library</a> for DynamoDB does, but the implementation is more complex, and it still requires the data store to offer a compare-and-swap operation.</p><p>You might think that’s enough to guarantee there can’t be more than one leader in your application. Unfortunately, that’s not the case.</p><p>To see why, suppose there are multiple processes that need to update a file on a shared blob store, and you want to guarantee that only a single process at a time can do so to avoid race conditions. To achieve that, you decide to use a distributed mutex - a form of leader election. Each process tries to acquire the lock, and the one that does so successfully reads the file, updates it in memory, and writes it back to the store:</p><div data-language="python"><pre><code><span>if</span> lock<span>.</span>acquire<span>(</span><span>)</span><span>:</span>
    <span>try</span><span>:</span>
        content <span>=</span> store<span>.</span>read<span>(</span>blob_name<span>)</span>
        new_content <span>=</span> update<span>(</span>content<span>)</span>
        store<span>.</span>write<span>(</span>blob_name<span>,</span> new_content<span>)</span>
    <span>except</span><span>:</span>
        lock<span>.</span>release<span>(</span><span>)</span></code></pre></div><p>The problem here is that by the time the process writes the content to the store, it might no longer be the leader - a lot might have happened since it was elected. For example, the operating system might have preempted and stopped the process, and several seconds will have passed by the time it’s running again. So how can the process ensure that it’s still the leader then? It could check one more time before writing to the store, but that doesn’t eliminate the race condition, it just makes it less likely.</p><p>To avoid this issue, the data store downstream needs to verify that the request has been sent by the current leader. One way to do that is by using a fencing token. A <a href="https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html">fencing token</a> is a number that increases every time that a distributed lock is acquired - in other words, it’s a logical clock. When the leader writes to the store, it passes down the fencing token to it. The store remembers the value of the last token and accepts only writes with a greater value:</p><div data-language="python"><pre><code>success<span>,</span> token <span>=</span> lock<span>.</span>acquire<span>(</span><span>)</span>
<span>if</span> success<span>:</span>
    <span>try</span><span>:</span>
        content <span>=</span> store<span>.</span>read<span>(</span>blob_name<span>)</span>
        new_content <span>=</span> update<span>(</span>content<span>)</span>
        store<span>.</span>write<span>(</span>blob_name<span>,</span> new_content<span>,</span> token<span>)</span>
    <span>except</span><span>:</span>
        lock<span>.</span>release<span>(</span><span>)</span></code></pre></div><p>This approach adds complexity as the downstream consumer - in our case, the blob store - needs to support fencing tokens. If it doesn’t, you are out of luck, and you will have to design your system around the fact that occasionally there will be more than one leader. For example, if there are momentarily two leaders and they both perform the same idempotent operation, no harm is done.</p><p>Although having a leader election can simplify the design of a system as it eliminates concurrency, it can become a scaling bottleneck if the number of operations performed by the leader increase to the point where it can no longer keep up. When that happens, you might be forced to re-design the whole system. </p><p>Also, having a leader introduces a single point of failure with a large blast radius - if the election process stops working or the leader isn’t working as expected, it can bring down the entire system with it.</p><p>You can mitigate some of these downsides by introducing partitions and assigning a different leader per partition, but that comes with additional complexity. This is the solution many distributed data stores use.</p><p>Before considering the use of a leader, check whether there other are ways of achieving the desired functionality without it. For example, optimistic locking is one way to guarantee mutual exclusion at the cost of wasting some computing power. Or perhaps high availability is not a requirement for your application, in which case having just a single process that occasionally is restarted after failure is not a big deal. </p><p>As a rule of thumb, if you must use leader election, you have to minimize the work it performs and be prepared to occasionally have more than one leader if you can’t support fencing tokens end-to-end.</p><hr></article></div>]]>
            </description>
            <link>https://robertovitillo.com/leader-election-best-practices/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25543923</guid>
            <pubDate>Sat, 26 Dec 2020 15:16:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lawyers automate this, so why don't airlines?]]>
            </title>
            <description>
<![CDATA[
Score 178 | Comments 145 (<a href="https://news.ycombinator.com/item?id=25543861">thread link</a>) | @leejo
<br/>
December 26, 2020 | https://leejo.github.io/2020/12/26/EZY1952/ | <a href="https://web.archive.org/web/*/https://leejo.github.io/2020/12/26/EZY1952/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<p>
				<center>Lawyers Automate This, So Why Don't Airlines?</center>
			</p>
			<div>
				<center>
				
				
				

				December 26, 2020 (
				
				
					<a href="https://leejo.github.io/2020/11/19/some_kind_of_paypal_refund_scam/">Prev</a>
				
				/
				
					Next
				
			)

			
				</center>
			</div>
			<p>My working title for this blog post was “Why I’ll Never Fly With easyJet Again”, but that was far too clickbaity. Also it’s probably worth prefixing this post with two things. The first being the caveat that whether or not i ever fly with easyJet again is immaterial to their business, given that the model of budget airlines is one of opportunistic sales. Their loyalty programmes are minimal to non-existent<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> (although that may change in the near future<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup>) because the nature of their passengers is not one of loyalty. When you’re looking for a short haul cheap flight you’re unlikely to be attracted to schemes that only benefit you after years, or hundreds of thousands of air miles, worth of loyalty.</p>

<p>The reality of the budget airlines is they don’t have to worry about losing future passengers, thousands of them even, because there will always be enough replacement passengers. Budget airlines’ flights average above a 90% occupancy rate<sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup>.</p>

<p>So the point of me never flying with easyJet again is not because i am under any illusion that it will be detrimental to their business, it won’t, but rather to protect <em>myself</em> should the situation happen again. They’re not the first airline to make my “list”, but the others have reasons that aren’t interesting enough to require a blog post.</p>

<p>What i am hoping with this post is that it gives the reader enough information that, should they find themselves in a similar situation, they are more informed as to their options and the potential ramifications of the choice they make. This is going to affect more travelers when the UK leaves the EU.</p>

<p>The second prefix is that easyJet recently posted their first year of losses<sup id="fnref:10" role="doc-noteref"><a href="#fn:10">4</a></sup>, due to the current global situation. I started writing this post sometime in 2019, way before the pandemic royally fucked the airline industry. It’s arguable that the airline industry being royally fucked was only a matter of time, and the consequences of <em>that</em> could mean the details here are now even more relevant - It may become even harder to claim refunds and compensation from them in the future. Airline companies will probably double down on their approach to handling compensation claims to avoid yet more financial loss.</p>

<p><strong>EZY1952</strong></p>

<p>On 23rd December 2018 my partner and I were due to fly from Geneva to Manchester on easyJet flight EZY1952, aircraft registration G-EZRU, which was scheduled to depart at 16:50 CET and arrive at 17:50 GMT. I had booked these flights a couple of months earlier, which combined with the date of our departure and return lead to a total cost of 619.38 CHF.</p>

<p>The 600+ CHF didn’t include any of the optional extras, priority boarding, seat choice, checked bags, etc. It was the “basic” cost of the “cheap” flights. This cost is four to five times more than the normal cost of this route, as I said due to the relatively late booking (two months in advance) and the dates of the flights. This route is normally far cheaper:</p>

<p><img width="625px" src="https://leejo.github.io/images/2020/EZY1952/typical_cost.png"></p>

<p>Anyway, given the alternatives and the limited options for our dates these were the flights we settled on and decide the cost was worth it to spend Xmas with the family. The flight was delayed by just a few minutes, which isn’t unusual for this route, but then took off as normal at 17:14:05 CET.</p>

<p>A few moments after take off, the literal wheels no longer being on the ground part of it, I felt my ears pop quite suddenly. That might not be taken as unusual either, but I live at altitude and my ears don’t normally pop on flights. The plane then spent several minutes in low cloud, another unusual thing given the cloud line is normally cut through quicker. I turned to my partner and suggested that something was off.</p>

<p>A couple of minutes later the pilot informed us that the flight would be returning to Geneva airport as the cabin pressure system, and its backup, had failed. Given the potentially catastrophic consequences of the cabin pressure system failing at cruising altitude, I considered that everyone on the plane had been very lucky.</p>

<p>The plane landed safely at Geneva airport at 17:41:00 CET, meaning a total flight time of about 25 minutes<sup id="fnref:4" role="doc-noteref"><a href="#fn:4">5</a></sup>. I contacted my parents to let them know we wouldn’t be arriving as planned and would keep them informed as to any updates:</p>

<p><img width="625px" src="https://leejo.github.io/images/2020/EZY1952/messages_to_mum.png"></p>

<p>We remained on the plane, after the pilot informed us that the technical crew were going to look into the issue. We were then told the parts would be replaced/fixed and this would take three to four hours. At this point I knew that we would not be flying until the next day as a) it was now 19:00 and Geneva airport has strict limitations on flights after 22:00, and b) it would be massively irresponsible of the airline to let this plane fly without a more comprehensive test that would probably take longer than the three to four hour estimate<sup id="fnref:6" role="doc-noteref"><a href="#fn:6">6</a></sup>.</p>

<p>Since it was going to take a few hours all passengers disembarked and returned to the departure gate. I’m not sure how long we were on the plane, while it was on the ground, but looking at the evidence I kept afterwards it appears that we were on it for approximately one hour fifteen minutes. This is from the time it landed to receiving a text message from easyJet apologising for the delay:</p>

<p><img width="625px" src="https://leejo.github.io/images/2020/EZY1952/sorry_for_delay.png"></p>

<p>As soon as we got back into the gate I sat down and checked to see if there were any other flights available. Sure enough there was: we could get a one way easyJet flight to Liverpool, so I booked two seats for a total of 189.26 CHF. This flight would depart at 21:25 CET and arrive at 22:20 GMT, four hours and thirty minutes after our original arrival time.</p>

<p>It should be said at this point I was reasonably confident of a few things:</p>

<ul>
  <li>It was highly unlikely the original fight was going to depart that night</li>
  <li>In fact, it would probably be delayed until the next afternoon</li>
  <li>We would have all the inconvenience of that, and lose one third of our time in the UK</li>
  <li>Given the original arrival time was delayed by more than three hours we were covered by EU Regulation 261/2004</li>
  <li>So the airline would have to compensate €250 for each of us, which would at least cover the alternate flights I had booked</li>
</ul>

<p>I was correct on four out of five of these:</p>

<p><img width="625px" src="https://leejo.github.io/images/2020/EZY1952/delayed_overnight.png"></p>

<p>Our flight to Liverpool went without issue, and we weren’t the only people to have rebooked from the delayed flight as we overheard some other passengers explaining their situation to the cabin crew<sup id="fnref:7" role="doc-noteref"><a href="#fn:7">7</a></sup>.</p>

<p><strong>Contacting easyJet Customer Service</strong></p>

<p>The next day I used easyJet’s contact form to submit a claim under EC261/2004 regulations. I knew this was going to take a long time so figured I may as well start the process as soon as possible. My claim was made on the basis that the original flight had been delayed overnight and I had booked alternate travel arrangements to get to my destination.</p>

<p>I considered the cost of the original flights a sunk cost. I wasn’t actually interested in compensation and I just wanted the cost of the alternate flights refunded, which came in at less than half the amount of compensation EC261/2004 would give considering the length of the delay to the original flight.</p>

<p>The response from easyJet came back quickly, the next day: <em>As you were a no show on the flight we would not be able t reimburse the costs for alternate transport.</em> - well that didn’t read like a response by someone/thing that had actually looked into the details. We had shown up for the flight, given we were on it when the pressure systems failed, and clearly we wouldn’t show up for the <em>rescheduled</em> flight if we arranged alternate transport as we can’t be in two places at once.</p>

<p>I assumed this was just a first level response of “refuse all claims, through a semantic dispute, because this will cause a not insignificant number of people to give up”<sup id="fnref:8" role="doc-noteref"><a href="#fn:8">8</a></sup>. The contact form doesn’t have a place to describe the reason for the claim in detail so I needed to call easyJet to explain.</p>

<p><strong>EU Regulation 261/2004</strong></p>

<p>I’ll spare you too much detail, as you can search for it if you want to (or read a summary on <a href="https://en.wikipedia.org/wiki/Flight_Compensation_Regulation">Wikipedia</a>). Essentially - EU 261/2004 allows compensation if your flight is from or to an EU/EAA area and is either delayed or cancelled [less than one week before the flight date]. The level of compensation depends on the distance of the flight.</p>

<p>In this particular case the delay was more than four hours, and the flight was less than 1,500km, so would qualify for €250 compensation (per passenger).</p>

<p>The regulation also says the passengers must be given assistance, and in this particular case of the flight being delayed overnight would mean hotel accommodation and transport between the airport and the hotel. This was Geneva two days from Xmas, so that would probably mean another €250.</p>

<p>So a reasonable estimate is easyJet would be paying in the region of €750 per passenger on this delayed flight. Given it was full (at least to my recollection) easyJet were looking at a bill of at least €100,000 for compensation + accommodation expenses<sup id="fnref:9" role="doc-noteref"><a href="#fn:9">9</a></sup>.</p>

<p>To go off on a tangent slightly - all of this is going to be up in the air when the UK leaves the EU. Of course that depends what the UK government <a href="https://en.wikipedia.org/wiki/Flight_Compensation_Regulation#Brexit_and_British_Consumers">decide to do about it</a>. Given everything else on their plate don’t be surprised if this one gets forgotten about until the claims start to appear.</p>

<p><strong>Contacting easyJet Customer Service Again</strong></p>

<p>As my claim, via easyJet’s web form, was rejected relatively quickly I decided to pick up the phone and see if speaking to someone would make a difference. I explained the situation and they agreed to pass this on to someone who would look at it in more detail, given the time of year this would take a few days at the least.</p>

<p>A couple of weeks later I received an email stating “Unfortunately as you were a no show on the transferred flight there is no reimbursement for EUC216 Compensation”. But also “As a goodwill gesture I have created a flight voucher to the value of the 51.90 GBP”.</p>

<p>Slightly odd - no …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://leejo.github.io/2020/12/26/EZY1952/">https://leejo.github.io/2020/12/26/EZY1952/</a></em></p>]]>
            </description>
            <link>https://leejo.github.io/2020/12/26/EZY1952/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25543861</guid>
            <pubDate>Sat, 26 Dec 2020 15:08:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[They want us to be compliant, not secure]]>
            </title>
            <description>
<![CDATA[
Score 191 | Comments 165 (<a href="https://news.ycombinator.com/item?id=25543818">thread link</a>) | @_wldu
<br/>
December 26, 2020 | https://www.go350.com/posts/they-want-us-to-be-compliant-not-secure/ | <a href="https://web.archive.org/web/*/https://www.go350.com/posts/they-want-us-to-be-compliant-not-secure/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Some years ago, I worked for an organization that was involved in federally funded research. Occasionally, government IT auditors (or contractors that they hired) would visit our facilities to audit our systems.</p><p>We used a wide variety of operating systems on several different hardware platforms. Windows, Mac, Linux and Unix systems were scattered throughout our buildings running on desktops, laptops, workstation, servers and embedded devices. We ran several different Linux distributions, multiple Unixes and had standardized on <a href="https://en.wikipedia.org/wiki/Bcrypt">bcrypt</a> hashes to store user passwords.</p><p>Bcrypt was released in 1999 and is based on <a href="https://www.schneier.com/academic/blowfish/">Blowfish</a>. Blowfish is a fast, unpatented block cipher that was developed by <a href="https://en.wikipedia.org/wiki/Bruce_Schneier">Bruce Schneier</a> in 1993. It’s been in the mainline Linux kernel since the 2.6 release.</p><p>Bcrypt is a fast and efficient password hash yet strong and hard to attack. At the time, it was the strongest password hash that we could use and as an added bonus, it worked on all of our Linux and Unix systems.</p><p>One particular year, the IT auditors realized that we were using bcrypt hashes to store user passwords. They said that it was not a <a href="https://csrc.nist.gov/publications/detail/fips/180/4/final">FIPS approved algorithm</a> and by using bcrypt hashes, we were noncompliant. They insisted that we switch to a SHA-2 based hash function right away.</p><p>We ran several tests that demonstrated how the SHA-2 hashes were much easier to crack than the bcrypt hashes (see below for a performance comparison on a semi-modern GPU). But the auditors were adamant. They did not care that the approved algorithms were weaker. Nothing would change their decision.</p><p>In their minds, it was a simple matter. Bcrypt was not on the list. It was not an approved hashing function. They would not discuss it further.</p><p>To satisfy the auditors, we switched all the systems to an approved SHA-2 hash function. This action probably made our systems more vulnerable to cyber attacks.</p><p>A colleague said, <em>“They want us to be compliant, not secure.”</em></p><div><pre><code data-lang="bash">$ hashcat -b -m <span>1800</span>
hashcat <span>(</span>v5.1.0<span>)</span> starting in benchmark mode...

OpenCL Platform <span>#1: NVIDIA Corporation</span>
<span>======================================</span>
* Device <span>#1: GeForce GTX 1060 6GB, 1519/6077 MB allocatable, 10MCU</span>

Benchmark relevant options:
<span>===========================</span>
* --optimized-kernel-enable

Hashmode: <span>1800</span> - sha512crypt $6$, SHA512 <span>(</span>Unix<span>)</span> <span>(</span>Iterations: 5000<span>)</span>

Speed.#1.........:    <span>78810</span> H/s <span>(</span>51.36ms<span>)</span> @ Accel:512 Loops:128 Thr:32 Vec:1
</code></pre></div><div><pre><code data-lang="bash">$ hashcat -b -m <span>3200</span>
hashcat <span>(</span>v5.1.0<span>)</span> starting in benchmark mode...

OpenCL Platform <span>#1: NVIDIA Corporation</span>
<span>======================================</span>
* Device <span>#1: GeForce GTX 1060 6GB, 1519/6077 MB allocatable, 10MCU</span>

Benchmark relevant options:
<span>===========================</span>
* --optimized-kernel-enable

Hashmode: <span>3200</span> - bcrypt $2*$, Blowfish <span>(</span>Unix<span>)</span> <span>(</span>Iterations: 32<span>)</span>

Speed.#1.........:     <span>7570</span> H/s <span>(</span>41.13ms<span>)</span> @ Accel:16 Loops:8 Thr:8 Vec:1
</code></pre></div><ul><li><a href="https://www.go350.com/tags/compliance">compliance</a></li><li><a href="https://www.go350.com/tags/passwords">passwords</a></li></ul></div></div>]]>
            </description>
            <link>https://www.go350.com/posts/they-want-us-to-be-compliant-not-secure/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25543818</guid>
            <pubDate>Sat, 26 Dec 2020 14:56:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Paying Medieval Taxes Using Eels]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25543802">thread link</a>) | @mkmk
<br/>
December 26, 2020 | https://historiacartarum.org/eel-rents-project/ | <a href="https://web.archive.org/web/*/https://historiacartarum.org/eel-rents-project/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="description">

		<p>Project Manager: <a href="https://www.jwgreenlee.net/" target="_blank" rel="noopener noreferrer">Dr. John Wyatt Greenlee, PhD</a><br>
Find on Twitter: <a href="https://twitter.com/greenleejw" target="_blank" rel="noopener">The Surprised Eel Historian</a></p>
<hr>
<div id="attachment_584"><p><img aria-describedby="caption-attachment-584" loading="lazy" src="https://historiacartarum.org/wp-content/uploads/2018/03/1325_Luttrell-Psalter-Eel-Weir-300x176.jpg" alt="" width="384" height="225"></p><p id="caption-attachment-584">Eel Weir from the 1325 Luttrell Psalter. BL Add MS 42130 fol. 181r.</p></div>
<p>One of the peculiar aspects of the Domesday register of 1086 are the range of taxes that the English paid in-kind. &nbsp;Domesday records payments in pigs, in fish, in ale, and in many other types of food. &nbsp;Of these in-kind payments, the one that stands out most to modern viewers is likely the eel-rents. &nbsp;This is in part because, in Europe and the Americas, we have generally moved away from eating eel on anything like a regular basis. Consequently, the idea of eels having any type of social or economic value appears less normal to us the thought of other animals or commodities having negotiable value. &nbsp;We still eat pigs and drink ale. &nbsp;But the eel-rents also stand out for the sometimes excessive numbers of animals at play — the village of Harmston, for example, owed the Earl Hugh 75,000 eels per year, and fishermen in Wisbech needed to pay various local monasteries a combined total of almost 35,000 per year.</p>
<p>Eel-rents usually only find passing mention in history books, and when they do it is these types of rents, with their eye-popping numbers,&nbsp; that dominate. It is worth noting, though, that these numbers, while high, are not out of the range of normal. &nbsp;Domesday and subsequent documents show that rents of multiple thousands of eels a year were common for single fisheries or mills. &nbsp;All told, at the time of the Great Survey in 1086 people living in England owed more than 500,000 eels in taxes each year to their landlords.</p>
<p>The purpose of this project is to map and present the role of eel-rents in the medieval and early modern English economy. From at least the tenth century onward, the English all across the island paid some taxes in eel (live and dead). English eel-rents have long been understudies and misunderstood, and this project demonstrates both the breadth, and the depth, of the rents in English history.</p>
<p>Most studies that discuss eel-rents tend to focus on their role only the economy of the Fens in East Anglia, but in truth renters all across the island paid their taxes in the fish. And while eel-rents did slowly vanish as coins became more common, they did not wholly vanish. Rather, eel-rents remained a wide-spread and viable part of the English economy into the fifteenth century, with scattered rents remaining active for another two hundred years after that.</p>
<hr>
<h4><span><strong>Project Contents</strong></span></h4>
<p><span><strong>〉</strong><a href="https://historiacartarum.org/eel-rents-project/english-eel-rents-10th-17th-centuries/"><strong>Interactive Map</strong></a></span></p>
<p>A map of England showing all known eel-rents from the 10th through the 17th centuries. Sortable by century, and including all relevant information including citations.</p>
<p><span><strong>〉<a href="https://historiacartarum.org/eel-rents-project/what-does-a-stick-of-eels-get-you/">The Value of a Stick of Eels</a></strong></span></p>
<p>Dried eels were often counted in sticks, with each stick being 25 eels. But what is the actual value of a stick of eels? This is an effort to find a rough equivalence in modern monetary terms. So what does a stick of eels get you these days? You might be surprised!</p>
<p><span><strong>〉<a href="https://historiacartarum.org/eel-rents-project/distances-traveled-by-eel-rents/">Eels on the Roads…How Far is too Far?</a></strong></span></p>
<p>So how far were eel-rents traveling around England? Here is a (highly caveated) attempted to work out just how many miles a stick of eels was likely to go between its point of capture and its destination.</p>
<p><span><strong>〉<a href="http://eels.historiacartarum.org/" target="_blank" rel="noopener noreferrer">More Eels and More Eel History</a></strong></span></p>
<p>It you’re really enjoying learning about eels and history, and you want even more, you can visit my site dedicated to the English history with the fish beyond eel-rents and maps.</p>
<p><span><strong>〉<a href="https://twitter.com/greenleejw" target="_blank" rel="noopener noreferrer">Eel History on Twitter</a></strong></span></p>
<p>For daily tidbits of eel history, complete with fun memes and bad eel puns, you can follow me at <a href="https://twitter.com/greenleejw" target="_blank" rel="noopener">The Surprised Eel Historian (@greenleejw)</a> on Twitter.</p>
<blockquote data-secret="FhHQZBeXLv"></blockquote>



    </div></div>]]>
            </description>
            <link>https://historiacartarum.org/eel-rents-project/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25543802</guid>
            <pubDate>Sat, 26 Dec 2020 14:53:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Emacs is the 2D Command-line Interface]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25543611">thread link</a>) | @susam
<br/>
December 26, 2020 | http://hongchao.me/cli-and-emacs/ | <a href="https://web.archive.org/web/*/http://hongchao.me/cli-and-emacs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>One of the most popular arguments against Emacs is that it is “a great
operating system, lacking only a decent editor”. The promotion of the
idea of “Living in Emacs” by some of the hardcore Emacs users only
make this argument more compelling. At the first glance, using a
single program for “everything” does seem to contradict the <a href="https://en.wikipedia.org/wiki/Unix_philosophy">Unix
philosophy</a>, which
favors single-purposed programs that compose really well instead of
monolithic systems that try to solve many complex problems at the same
time. In this article, I’d like to argue that Emacs largely follows
the Unix philosophy in its problem domain: <em>working with text</em>, and
can be seen as a two dimentional version of the <a href="https://en.wikipedia.org/wiki/Command-line_interface">command-line
interface</a>
(CLI).</p>

<blockquote>
  <p>This is the Unix philosophy: Write programs that do one thing and do
it well. Write programs to work together. Write programs to handle
text streams, because that is a universal interface.</p>

  <p>McIlroy, head of the Bell Labs Computing Sciences Research Center</p>
</blockquote>

<p>Many CLI tools stood the test of time. Programs like <em>find</em>, <em>grep</em>,
<em>awk</em>, etc have been indispensable for IT professionals for
decades. They are effective, sometimes more so than their GUI
counterparts, because command line interpreters such as
<a href="https://en.wikipedia.org/wiki/Bourne_shell">Bash</a> provides an
environment where they can be composed together to accomplish tasks
that the original designer of the individual program have never
thought about. For example, through the composition of <em>kubectl</em>,
<em>grep</em>, <em>awk</em> and <em>base64</em>, the following command displays the content
of the <em>tls.crt</em> certificate in a Kubernetes secret called
<em>nioctib-tech-it-tls</em>:</p>

<p><img src="http://hongchao.me/images/compose-cli.png" alt="compose cli"></p>

<p>The following two things are quintessential to the composibility and
extensibility of the CLI programs:</p>

<ul>
  <li>Text streams as the univeral interface</li>
  <li>Command line interpreter as a programming environment</li>
</ul>

<p>There are definitely disadvantages to use text streams as the
universal interface between programs due to its lack of structure. But
the timelessness of many of the programs following this pattern and
the prosperity that it brings to the CLI ecosystem proved its
effectiveness as a design choice. Text can be read by both human and
programs. It can be manipulated, printed, stored, trasferred, version
controlled with the tools of your choice. For programs that do not
inheritantly require structured data, using text streams as interface
provides the most flexibility and composibility.</p>

<p>However, the flip side is that for programs that do require structured
data, such as browsers, image viewers, music players, etc. Their text
based versions usually become the toys of the hobbyists with
neglectable impact.</p>

<p><img src="http://hongchao.me/images/lynx-browser.png" alt="lynx browser">
<span>Lynx: a text based browser with tiny user base</span></p>

<p>Another important contributor to the success of many of the CLI
programs is the fact that they live in a programmable environment. In
Bash, programs can be written from scratch or glued together using
Bash script. This makes the CLI environment infinitely extensible. By
enabling smaller programs that “do one thing and do it well” work
together to accomplish more complex tasks, it becomes an environment
that boosts synergy, productivity and creativity.</p>

<p>The word “line” in the CLI (Command-line interface) environment
indicates its one dimentional nature. For programs that potentially
need to interact with (two-dimentional) text files, Emacs offers an
environment with similiar characteristics that makes CLI enviornment
successful: A universal text interface and a programming environment
which enables infinite extensibility.</p>

<p>Self described as “an extensible, customizable, free/libre text
editor”, <a href="https://en.wikipedia.org/wiki/GNU_Emacs">GNU Emacs</a>’s
infinite extensibility is enabled by a Turing-complete language called
<a href="https://en.wikipedia.org/wiki/Emacs_Lisp">Elisp</a>, which also is used
to write most of Emacs itself. This is similiar to how for example
Bash achieves its extensibility through Bash script. Just like most of
the programs that thrives under the Bash environment are inheritantly
text focused, most of the popular Emacs programs are text focused as
well, such as <a href="https://magit.vc/">Magit</a> and
<a href="https://orgmode.org/">Org-mode</a>. They also tend to integrate very
well with other Emacs programs, creating synergy similiar to that of
the CLI programs. For example, you can look at the commit history of a
Git repository using Magit, jump directly to the diff of a commit, and
then jump straight to the source code in the diff. In the following
example, the source code is written in Scala, you can then edit the
code with Emacs’s exellent Scala support thanks to
<a href="https://github.com/emacs-lsp/lsp-mode">lsp-mode</a> and
<a href="https://github.com/emacs-lsp/lsp-metals">lsp-metals</a>, which are
programs in the Emacs ecosystem that Magit is not aware of at all.</p>

<p><img src="http://hongchao.me/images/magit-code.png" alt="magit">
<span>Magit: jumping from commit to diff to source code</span></p>

<p>If Emacs is an environment for programs that focus on two dimensional
text, it is also more than capable of running programs that deal with
one dimensional text. In fact, many CLI tools such as <em>grep</em>, <em>find</em>
and many file system management utilities
(<a href="https://en.wikipedia.org/wiki/Dired">Dired</a>) are implemented in
Elisp and thus integrated into the Emacs ecosystem as well. This is
one of the reasons that if your main workflow is text focused, “Living
in Emacs” is probably not a terrible idea due to the synergy many of
these Emacs programs produce.</p>

<p>However, that doesn’t mean that <em>everything</em> should be run in
Emacs. Emacs is probably not the best tool for browsing web
(<a href="https://www.gnu.org/software/emacs/manual/html_mono/eww.html">EWW</a>)
or listening to music
(<a href="https://en.wikipedia.org/wiki/EMMS_(media_player)">EMMS</a>), just like
CLI tools such as Lynx will never have significant impact because they
are fundamentally not text focused. The argument that Emacs is “a
great operating system, lacking only a decent editor” tries to paint
Emacs as a monolithic swiss army knife ambitious enough to run any
programs. In fact, Emacs is more like a two dimensional CLI
environment that embraces the same Unix philosophy: enable simple,
elegant programs interacting with each other using an univeral
interface.</p>

<hr>

<p>Edit: <a href="https://www.reddit.com/r/emacs/comments/kk1voo/emacs_is_the_two_dimensional_commandline_interface/">Reddit Discussion</a></p>

  </div></div>]]>
            </description>
            <link>http://hongchao.me/cli-and-emacs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25543611</guid>
            <pubDate>Sat, 26 Dec 2020 14:21:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Executable PNGs]]>
            </title>
            <description>
<![CDATA[
Score 219 | Comments 39 (<a href="https://news.ycombinator.com/item?id=25543191">thread link</a>) | @todsacerdoti
<br/>
December 26, 2020 | https://djharper.dev/post/2020/12/26/executable-pngs/ | <a href="https://web.archive.org/web/*/https://djharper.dev/post/2020/12/26/executable-pngs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<article>

<p>
<time datetime="2020-12-26">Saturday, December 26, 2020</time>
</p>
<figure>
<a href="https://djharper.dev/img/peek.webm"><video src="https://djharper.dev/img/peek.webm" loop="true" width="100%" title="The pixels have been adjusted in colour slightly." autoplay=""></video></a>
<figcaption><br>It's an image <i>and</i> a program</figcaption>
</figure>
<p>A few weeks ago I was reading about <a href="https://www.lexaloffle.com/pico-8.php">PICO-8</a>, a fantasy games console with limited constraints. What really piqued my interest about it was the novel way games are distributed, you encode them into a PNG image. This includes the game code, assets, everything. The image can be whatever you want, screenshots from the game, cool artwork or just text. To load them you pass the image as input to the PICO-8 program and start playing.</p>
<p>This got me thinking, wouldn’t it be cool if you could do that for programs on Linux? No! I hear you cry, that’s a dumb idea, but whatever, herein lies an overview of possibly the dumbest things I’ve worked on this year.</p>
<h2 id="encoding">Encoding</h2>
<p>I’m not entirely sure what PICO-8 is actually doing, but at a guess it’s probably use <a href="https://en.wikipedia.org/wiki/Steganography">Steganography</a> techniques to ‘hide’ the data within the raw bytes of the image. There are a lot of resources out there that explain how Steganography works, but the crux of it is quite simple, your image your want to hide data into is made up of bytes, an image is made up of pixels. Pixels are made up of 3 Red Green and Blue (RGB) values, represented as 3 bytes. To hide your data (the “payload”) you essentially “mix” the bytes from your payload with the bytes from the image.</p>
<p>If you just replaced each byte in your cover image with the bytes from your payload, you would end up with sections of the image looking distorted as the colours probably wouldn’t match with what your original image was. The trick is to be as subtle as possible, or <em>hide in plain sight</em>. This can be achieved by <em>spreading</em> your payload bytes over the bytes of the cover image by using the <em>least significant bits</em> to hide them in. In other words, make subtle adjustments to the byte values so the colour changes are not drastic enough to be perceptive by the human eye.</p>
<p>For example if your payload was the letter <code>H</code>, represented as <code>01001000</code> in binary (72), and your image contained a series of black pixels</p>
<figure>
<a href="https://djharper.dev/img/byte-replace1.png"><img src="https://djharper.dev/img/byte-replace1.png" title="The bits from the input bytes are spread across 8 output bytes by hiding them in the least significant bit"></a>
<figcaption><br>The bits from the input bytes are spread across 8 output bytes by hiding them in the least significant bit</figcaption>
</figure>
<p>The output is two-and-a-bit pixels that are slightly less black than before, but can you tell the difference?</p>
<figure>
<a href="https://djharper.dev/img/pixels1.png"><img src="https://djharper.dev/img/pixels1.png" title="The pixels have been adjusted in colour slightly."></a>
<figcaption><br>The pixels have been adjusted in colour slightly.</figcaption>
</figure>
<p>Well, an exceptionally trained colour connoisseur might be able to, but in reality these subtle shifts can really only be noticed by a machine. Retrieving your super secret <code>H</code> is just a matter of reading 8 bytes from the resulting image and re-assembling them back into 1 byte. Obviously hiding a single letter is lame, but this can scale to anything you want, a super secret sentence, a copy of <em>War and Peace</em>, a link to your soundcloud, the go compiler, the only limit is the amount of bytes available in your cover image as you’ll require at least 8x whatever your input is.</p>
<h2 id="hiding-programs">Hiding programs</h2>
<p>So, back to the whole linux-executables-in-an-image thing, that old chestnut. Well, seeing as executables are just bytes, they can be hidden in images. Just like in the PICO-8 thing.</p>
<p>Before I could achieve this I decided to write my own <a href="https://github.com/djhworld/steg">Steganography library</a> and <a href="https://github.com/djhworld/stegtool">tool</a> to support encoding and decoding data into PNGs. Yes, there are lots of steganography libraries and tools out there but I learn better by building.</p>
<figure>
<div><pre><code data-lang="bash">$ stegtool encode <span>\
</span><span></span>--cover-image htop-logo.png <span>\
</span><span></span>--input-data /usr/bin/htop <span>\
</span><span></span>--output-image htop.png
$
$ <span>echo</span> <span>"Super secret hidden message"</span> | stegtool encode <span>\ </span>
--cover-image image.png <span>\
</span><span></span>--output-image image-with-hidden-message.png
$ stegtool decode --image image-with-hidden-message.png
Super secret hidden message</code></pre></div>
</figure>
<p>As it’s all written in <a href="https://www.rust-lang.org/">Rust</a> it wasn’t that difficult to compile to WASM, so feel free to play with it here:</p>

<p>Anyway, now that can embed data, including executables into an image, how do we run them?</p>
<h2 id="get-it-running">Get it running</h2>
<p>The simple option would be to just run the tool above, <code>decode</code> the data into a new file, <code>chmod +x</code> it and then run it. It works but that’s not fun enough. What I wanted was something similar to the PICO-8 experience, you pass something a PNG image and it takes care of the rest.</p>
<p>However, as it turns out, you can’t just load some arbitrary set of bytes into memory and tell Linux to jump to it. Well, not in a direct way anyway, but you <em>can</em> use some cheap tricks to fudge it.</p>
<h2 id="memfd-create">memfd_create</h2>
<p>After reading <a href="https://magisterquis.github.io/2018/03/31/in-memory-only-elf-execution.html">this blogpost</a> it became apparent to me you can create an in-memory file and mark it as executable</p>
<blockquote>
<p>Wouldn’t it be cool to just grab a chunk of memory, put our binary in there, and run it without monkey-patching the kernel, rewriting execve(2) in userland, or loading a library into another process?</p>
</blockquote>
<p>This method uses the syscall <a href="https://man7.org/linux/man-pages/man2/memfd_create.2.html">memfd_create(2)</a> to create a file under the <code>/proc/self/fd</code> namespace of your process and load any data you want in it using <code>write</code>. I spent quite a while messing around with the <a href="https://crates.io/crates/libc">libc</a> bindings for Rust to get this to work, and had a lot of trouble understanding the data types you pass around, the documentation for these Rust bindings doesn’t help much.</p>
<p>I got something working eventually though</p>
<figure>
<div><pre><code data-lang="rust"><span>unsafe</span><span> </span>{<span>
</span><span>    </span><span>let</span><span> </span>write_mode<span> </span><span>=</span><span> </span><span>119</span>;<span> </span><span>// w
</span><span></span><span>    </span><span>// create executable in-memory file
</span><span></span><span>    </span><span>let</span><span> </span>fd<span> </span><span>=</span><span> </span>syscall(libc::SYS_memfd_create,<span> </span><span>&amp;</span>write_mode,<span> </span><span>1</span>);<span>
</span><span>    </span><span>if</span><span> </span>fd<span> </span><span>==</span><span> </span><span>-</span><span>1</span><span> </span>{<span>
</span><span>        </span><span>return</span><span> </span><span>Err</span>(<span>String</span>::from(<span>"memfd_create failed"</span>));<span>
</span><span>    </span>}<span>
</span><span>
</span><span>    </span><span>let</span><span> </span>file<span> </span><span>=</span><span> </span>libc::fdopen(fd,<span> </span><span>&amp;</span>write_mode);<span> 
</span><span>
</span><span>    </span><span>// write contents of our binary
</span><span></span><span>    </span>libc::fwrite(<span>
</span><span>        </span>data.as_ptr()<span> </span><span>as</span><span> </span><span>*</span><span>mut</span><span> </span>libc::c_void,<span> 
</span><span>        </span><span>8</span><span> </span><span>as</span><span> </span><span>usize</span>,<span>
</span><span>        </span>data.len()<span> </span><span>as</span><span> </span><span>usize</span>,<span>
</span><span>        </span>file,<span>
</span><span>    </span>);<span>
</span><span></span>}<span>
</span></code></pre></div>
</figure>
<p>Invoking <code>/proc/self/fd/&lt;fd&gt;</code> as a child process from the parent that created it is enough to run your binary.</p>
<figure>
<div><pre><code data-lang="rust"><span>let</span><span> </span>output<span> </span><span>=</span><span> </span>Command::new(format<span>!</span>(<span>"/proc/self/fd/{}"</span>,<span> </span>fd))<span>
</span><span>    </span>.args(args)<span>
</span><span>    </span>.stdin(std::process::Stdio::inherit())<span>
</span><span>    </span>.stdout(std::process::Stdio::inherit())<span>
</span><span>    </span>.stderr(std::process::Stdio::inherit())<span>
</span><span>    </span>.spawn();<span>
</span></code></pre></div>
</figure>
<p>Given these building blocks, I wrote <a href="https://github.com/djhworld/pngrun">pngrun</a> to run the images. It essentially…</p>
<ol>
<li>Accepts an image that has had our binary embedded in it from the steganography tool, and any arguments</li>
<li>Decodes it (i.e. extracts and re-assembles the bytes)</li>
<li>Creates an in-memory file using <code>memfd_create</code></li>
<li>Puts the bytes of the binary into the in-memory file</li>
<li>Invokes the file <code>/proc/self/fd/&lt;fd&gt;</code> as a child process, passing any arguments from the parent</li>
</ol>
<p>So you can run it like this</p>
<figure>
<div><pre><code data-lang="bash">$ pngrun htop.png
&lt;htop output&gt;
$ pngrun go.png run main.go
Hello world!</code></pre></div>
</figure>
<p>Once <code>pngrun</code> exits the in-memory file is destroyed.</p>
<h2 id="binfmt-misc">binfmt_misc</h2>
<p>It’s annoying having to type <code>pngrun</code> every time though, so my last cheap trick to this pointless gimmick was to use <a href="https://en.wikipedia.org/wiki/Binfmt_misc">binfmt_misc</a>, a system that allows you to “execute” files based on its file types. I think it was mainly designed for interpreters/virtual machines, like Java. So instead of typing <code>java -jar my-jar.jar</code> you can just type <code>./my-jar.jar</code> and it will invoke the <code>java</code> process to run your JAR. The caveat is your file <code>my-jar.jar</code> needs to be marked as executable first.</p>
<p>So adding an entry to binfmt_misc for <code>pngrun</code> to attempt to run any <code>png</code> files that have the <code>x</code> flag set was as simple as</p>
<figure>
<div><pre><code data-lang="bash">$ cat /etc/binfmt.d/pngrun.conf
:ExecutablePNG:E::png::/home/me/bin/pngrun:
$ sudo systemctl restart binfmt.d
$ chmod +x htop.png
$ ./htop.png
&lt;output&gt;</code></pre></div>
</figure>
<h2 id="what-s-the-point">What’s the point</h2>
<p>Well, there isn’t one really. I was seduced by the idea of making PNG images run programs and got a bit carried away with it, but it was fun none the less. There’s something amusing to me about distributing programs as an image, remember the ridiculous cardboard boxes PC software used to come in with artwork on the front, why not bring that back! (lets not)</p>
<p>It’s really dumb though and comes with a lot of caveats that make it completely pointless and impractical, the main one being needing the stupid <code>pngrun</code> program on your machine. But I also noticed some weird stuff around programs like <code>clang</code>. I encoded it into this fun LLVM logo and while it runs OK, it fails when you try to compile something.</p>
<figure>
<a href="https://djharper.dev/img/DragonMedium.png"><img src="https://djharper.dev/img/DragonMedium.png" title="Clang/LLVM logo"></a>
</figure>
<figure>
<div><pre><code data-lang="bash">$ ./clang.png --version
clang version <span>11</span>.0.0 <span>(</span>Fedora <span>11</span>.0.0-2.fc33<span>)</span>
Target: x86_64-unknown-linux-gnu
Thread model: posix
InstalledDir: /proc/self/fd
$ ./clang.png main.c
error: unable to execute command: Executable <span>""</span> doesn<span>'</span>t exist!</code></pre></div>
</figure>
<p>This is probably a product of the anonymous file thing, which can probably be overcome if I could be bothered to investigate.</p>
<h3 id="additional-reasons-why-this-is-dumb">Additional reasons why this is dumb</h3>
<p>A lot of binaries are quite large, and given the constraints of needing to fit them into an image, sometimes these need to be <em>big</em>, meaning you end up with comically large files.</p>
<p>Also most software isn’t just one executable so the dream of just distributing a PNG kinda falls flat for more complex software like games.</p>
<h2 id="conclusion">Conclusion</h2>
<p>This is probably the dumbest project I’ve worked on all year but it’s been fun, I’ve learned about Steganography, <code>memfd_create</code>, <code>binfmt_misc</code> and played a little more with Rust.</p>
</article>
</div></div>]]>
            </description>
            <link>https://djharper.dev/post/2020/12/26/executable-pngs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25543191</guid>
            <pubDate>Sat, 26 Dec 2020 13:04:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[China vs. Democracy: A Handbook for Democracies]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25542990">thread link</a>) | @tillulen
<br/>
December 26, 2020 | https://halifaxtheforum.org/china-handbook/en/ | <a href="https://web.archive.org/web/*/https://halifaxtheforum.org/china-handbook/en/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">

	<div id="content">





	<div id="fullwidth">
		<main id="main" role="main">

<article id="post-6532" class="page">
	<!-- .entry-header -->


<div>
<div>

<h3>A HANDBOOK FOR DEMOCRACIES</h3>

<p>Modern-day China has emerged as the most powerful authoritarian state in the history of the world.</p>
<p>The HFX Handbook for Democracies contributes to building a common understanding of the serious challenge that China poses.</p>
<p>The handbook features the <em><a href="https://hfxchinahandbook.s3.amazonaws.com/EN_HFX+China+Principles.pdf">HFX China Principles</a> </em>that defend the values that underpin democratic societies.</p>
<blockquote><p><strong><em>“THE REAL CHINA CHALLENGE FOR THE WORLD’S DEMOCRACIES IS HOW TO COOPERATE EFFECTIVELY WITH EACH OTHER.”</em></strong></p></blockquote>
<p><strong><a href="https://halifaxtheforum.org/china-handbook/cn/">点击这里查看中文</a> | <a href="https://halifaxtheforum.org/china-handbook/fr/">Cliquez ici pour le français</a></strong></p>
<h2>7/8 Campaign</h2>
<h3><b>Help HFX defend democratic values.</b></h3>
<p>Support the 7 HFX China Principles with a donation of $8 and together we will strengthen your government’s resolve to stand up to China.</p>
<p><a href="https://halifaxtheforum.org/china-handbook/donate-en">Donate $8</a></p>
</div>





</div></article></main></div>






	
	
	
					<!-- #main -->
	</div><!-- #primary -->
	
	


	</div></div>]]>
            </description>
            <link>https://halifaxtheforum.org/china-handbook/en/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25542990</guid>
            <pubDate>Sat, 26 Dec 2020 12:15:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Install Node.js]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25542906">thread link</a>) | @loige
<br/>
December 26, 2020 | https://www.nodejsdesignpatterns.com/blog/5-ways-to-install-node-js/ | <a href="https://web.archive.org/web/*/https://www.nodejsdesignpatterns.com/blog/5-ways-to-install-node-js/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><main><p>In this article, we will explore some of the most common ways to install Node.js in your development system. We will see how to install Node.js using the official installer for various platforms, how to use a Node.js version manager such as <code>n</code> or <code>nvm</code> and, finally, we will also see how to compile and install Node.js from source. Along the way, we will try to disclose one or two tips to get you even more productive with Node.js!</p><p>Let's get started!</p><h2 id="which-option-should-i-pick%3F">Which option should I pick?</h2><p>There are many different ways to install Node.js and every one of them comes with its own perks and drawbacks. In this article, we will try to explore the most common ones and by the end of it, you should have a good understanding of which ones should be more suitable for you.</p><h3 id="tldr%3B">TLDR;</h3><ul><li>Use <code>nvm</code> or <code>n</code> if you develop with Node.js frequently and you expect to be needing to switch Node.js version while moving from one project to another or to debug potential compatibility issues in your project or library.</li><li>Use the system package manager like <code>apt</code>, <code>brew</code> or <code>winget</code> if you tend to install all your software this way and if you don't expect to be needing to switch or upgrade Node.js version too often.</li><li>Install Node.js from source if you are an advanced user and if you want to contribute back to Node.js itself.</li><li>Use the official Node.js installer if you don't fall in any of the previous options...</li></ul><h3 id="what-other-people-seem-to-like">What other people seem to like</h3><p>Before writing this article, I was actually curious to find out what are the options that most folks in my network prefer. For this reason, I run a <a href="https://twitter.com/loige/status/1340999569807712257">poll on Twitter</a>. In this poll I asked how you prefer to install Node.js and provided 4 options:</p><ul><li>Official Installer</li><li>Version manager (<code>nvm</code> or <code>n</code>)</li><li>Package Manager (<code>apt</code>, <code>brew</code>, etc.)</li><li>From source</li></ul><p>The results are quite interesting:</p><a href="https://twitter.com/loige/status/1340999569807712257" rel="nofollow noreferrer"><span><picture><source type="image/png" srcset="https://www.nodejsdesignpatterns.com/img/poll-results-e006cbcf-64.png 64w, https://www.nodejsdesignpatterns.com/img/poll-results-e006cbcf-128.png 128w, https://www.nodejsdesignpatterns.com/img/poll-results-e006cbcf-256.png 256w, https://www.nodejsdesignpatterns.com/img/poll-results-e006cbcf-512.png 512w, https://www.nodejsdesignpatterns.com/img/poll-results-e006cbcf-593.png 593w" sizes="(max-width: 593px) 100vw, 593px"><source type="image/webp" srcset="https://www.nodejsdesignpatterns.com/img/poll-results-e006cbcf-64.webp 64w, https://www.nodejsdesignpatterns.com/img/poll-results-e006cbcf-128.webp 128w, https://www.nodejsdesignpatterns.com/img/poll-results-e006cbcf-256.webp 256w, https://www.nodejsdesignpatterns.com/img/poll-results-e006cbcf-512.webp 512w, https://www.nodejsdesignpatterns.com/img/poll-results-e006cbcf-593.webp 593w" sizes="(max-width: 593px) 100vw, 593px"><img loading="lazy" decoding="async" alt="Install Node.js Twitter poll results" src="https://www.nodejsdesignpatterns.com/img/poll-results-e006cbcf-64.png" width="64" height="37"></picture></span></a><p>It seems quite obvious that people in my network, mostly fellow software engineers, prefer to use version managers such as <code>nvm</code> or <code>n</code>.</p><p>The second place (actually very tight with the third one) is the official installer, followed by a system package manager and, last one, installing Node.js from source.</p><h3 id="lts-and-stable-releases">LTS and stable releases</h3><p>Before moving on and exploring all the different installation options, it is definitely worth spending few words to learn about the types of release the Node.js project maintains.</p><p>Node.js offers 2 main release lines:</p><ul><li><strong>Stable</strong> (or <em>Current</em>): every new major Node.js release is considered "Current" for the first 6 months after the publish date. The idea is to give library authors the time to test their compatibility with the new release and do any necessary change. After the 6 months period, all the odd release numbers (9, 11, 13, 15, etc.) move to the state of <em>Unsupported</em>, while even releases (10, 12, 14, etc.) are promoted to <em>Long Term Support</em> (or "LTS").</li><li><strong>LTS</strong>: releases marked as "Long Term Support" get critical bug fixes for a total of 30 months since the initial publish date. This makes LTS releases particularly suitable for production deployments. The most recent LTS is also called <em>Active LTS</em>, while previous LTS versions (still under the 30 months support timeframe) are called <em>Maintenance LTS</em>.</li></ul><p>Finally, the release coming from the current <em>master</em> branch is considered <strong>Unstable</strong>. This is generally a release dedicated to people maintaining Node.js or developers who want to explore new experimental features that haven't been yet included in any of the major releases.</p><p>Node.js publishes an <a href="https://nodejs.org/en/about/releases/">official timeline of current and future releases</a>. At the time of writing (December 2020), this how the timeline looks like:</p><a href="https://nodejs.org/en/about/releases/" target="_blank" rel="noreferrer noopener"><p><img loading="lazy" decoding="async" alt="Node.js release timeline" src="https://www.nodejsdesignpatterns.com/img/nodejs-release-schedule_9b4bf060.svg" width="760" height="396"></p></a><p>If you are still wondering which release should you use, going with the <em>Active LTS</em> is almost always the best choice, especially if you are building production applications.</p><h2 id="install-node.js-using-n">Install Node.js using n</h2><p>Since installing Node.js using a version manager seems to be the favourite option (and it's also my personal favourite!) let's start with it.</p><p>My favourite Node.js version manager is <a href="https://github.com/tj/n"><code>n</code> by TJ Holowaychuk</a>. The reason why I like it is because it is quite simple to install and use and it is generally up to date with the latest releases of Node.js. The main issue with it is that it does not support Windows, so if Windows is your operative system, this is not an option for you!</p><p>Let's see how to install <code>n</code>:</p><p>If you are on macOS and you have <code>brew</code> (Homebrew) installed, the simplest way to install <code>n</code> is to just do it with <code>brew</code>:</p><pre><code>brew <span>install</span> n</code></pre><p>Alternatively, you can use the custom install script:</p><pre><code><span>curl</span> -L https://git.io/n-install <span>|</span> <span>bash</span></code></pre><p>If all goes well, you should now be able to use the <code>n</code> executable from your shell.</p><p>These are some of the commands you can run:</p><pre><code><br>n --version<p><br>n lts</p><p><br>n list</p><p><br>n <span>&lt;</span>some_version<span>&gt;</span></p></code></pre><p>Or you can simply run:</p><pre><code>n</code></pre><p>For an interactive prompt that will show you all the available versions, highlight the ones you have already installed and let you pick the version you want to switch to.</p><p><img loading="lazy" decoding="async" alt="n Node.js version manager in action" src="https://www.nodejsdesignpatterns.com/img/n_ac172e26.gif" width="640" height="428"></p><p>In summary, this is where <code>n</code> shines or falls short:</p><ul><li>ðŸ‘Ž No official support for Windows</li><li>ðŸ‘� Very easy to install on macOS and unix systems</li><li>ðŸ‘� Very easy to keep your Node.js install up to date and switch version on demand</li><li>ðŸ‘� It keeps all the installed versions cached, so you can switch quickly between versions (no full re-install)</li><li>ðŸ‘� Allows to keep the setup local to the user so you don't have to use admin permission to install global packages</li></ul><h2 id="install-node.js-using-nvm">Install Node.js using nvm</h2><p>With more than 45 thousand stars on GitHub, <a href="https://github.com/nvm-sh/nvm"><code>nvm</code></a>, which stands for "Node.js Version Manager" (no surprises!), is probably the most famous Node.js version manager currently available.</p><p><code>nvm</code> works on any POSIX-compliant shell (<code>sh</code>, <code>dash</code>, <code>ksh</code>, <code>zsh</code>, <code>bash</code>, etc.) and it has been strongly tested against the following systems: unix, macOS, and windows WSL.</p><p>The easiest way to install <code>nvm</code> on your system is to use the official installer script:</p><pre><code><span>VERSION</span><span>=</span>v0.37.2<br><span>curl</span> -o- <span>"https://raw.githubusercontent.com/nvm-sh/nvm/<span>${VERSION}</span>/install.sh"</span> <span>|</span> <span>bash</span></code></pre><p><strong>Note</strong>: At the time of writing, version <code>v0.37.2</code> is the latest version available. Make sure to check out if there is any new version available if you are installing <code>nvm</code> following this tutorial.</p><p>Once <code>nvm</code> is installed in your system, here are some examples showing what you can do with it:</p><pre><code><br>nvm <span>install</span> node<p><br>nvm <span>install</span> --lts</p><p><br>nvm <span>install</span> <span>"10.10.0"</span></p><p><br>nvm use <span>"8.9.1"</span></p><p><br>nvm <span>exec</span> <span>"4.2"</span> node somescript.js</p><p><br>nvm <span>which</span> <span>"4.2"</span></p><p><br>nvm <span>ls</span></p></code></pre><p>One great thing about <code>nvm</code> is that it allows to specify the Node.js version you want to use for a given project.</p><p>For instance, if you are working on a project that requires you to use Node.js <code>10.10</code> you can do the following (in the root folder of the project):</p><pre><code><span>echo</span> <span>"10.10"</span> <span>&gt;</span> .nvmrc</code></pre><p>Then every time you work on that project, you only need to run:</p><pre><code>nvm use</code></pre><p>Which should print something like this:</p><pre><code>Found '/path/to/project/.nvmrc' with version &lt;10.10&gt;
Now using node v10.10.1 (npm v6.7.3)
</code></pre><p>At this point, you can be sure that you working using the correct Node.js version for your project.</p><p>If you don't want to do manually, you can enable <a href="https://github.com/nvm-sh/nvm#deeper-shell-integration">deeper shell integration</a> to make this happen automatically when you <code>cd</code> into a folder that has a <code>.nvmrc</code> file.</p><p><strong>PRO tip</strong>: You can also do that by using <a href="https://asdf-vm.com/"><code>asdf</code></a>, a <em>meta</em> version manager that offers a unified interface for various programming languages and version managers (including Node.js, of course).</p><p>Finally, here are some pros and cons of <code>nvm</code>:</p><ul><li>ðŸ‘� Most popular version manager for Node.js with a large community of users.</li><li>ðŸ‘� Very easy to install on POSIX systems.</li><li>ðŸ‘� It allows for easy (and even automated) switch of Node.js version based on the project you are working on.</li><li>ðŸ‘� It keeps all the installed versions cached, so you can switch quicly between versions (no full re-install)</li><li>ðŸ‘� You can run once off commands on a given version of Node.js without having to switch the entire system to that version.</li><li>ðŸ‘Ž You might have to take a bit of time to go through the documentation and make sure you install it and use it correctly.</li></ul><h2 id="install-node.js-using-the-official-installer">Install Node.js using the official installer</h2><p>The second most common way to install Node.js is through one of the official installers or the pre-compiled binaries.</p><p><a href="https://nodejs.org/en/download/">Official installers</a> are available on the official Node.js website for Windows and macOS and they cover the latest <em>Active LTS</em> release and the latest <em>Current</em> release.</p><p>The installer for Windows is an executable <em>.msi</em> installer, while the one for macOS is a <em>.pkg</em> one.</p><p>These installers behave and look like most of the installers you see while installing software on Windows or macOS. You will be presented with clickable UI which will allow you to customise and install Node.js into your system.</p><span><picture><source type="image/png" srcset="https://www.nodejsdesignpatterns.com/img/node-js-macos-installer-screenshot-477753f7-64.png 64w, https://www.nodejsdesignpatterns.com/img/node-js-macos-installer-screenshot-477753f7-128.png 128w, https://www.nodejsdesignpatterns.com/img/node-js-macos-installer-screenshot-477753f7-256.png 256w, https://www.nodejsdesignpatterns.com/img/node-js-macos-installer-screenshot-477753f7-512.png 512w, https://www.nodejsdesignpatterns.com/img/node-js-macos-installer-screenshot-477753f7-732.png 732w" sizes="(max-width: 732px) 100vw, 732px"><source type="image/webp" srcset="https://www.nodejsdesignpatterns.com/img/node-js-macos-installer-screenshot-477753f7-64.webp 64w, https://www.nodejsdesignpatterns.com/img/node-js-macos-installer-screenshot-477753f7-128.webp 128w, https://www.nodejsdesignpatterns.com/img/node-js-macos-installer-screenshot-477753f7-256.webp 256w, https://www.nodejsdesignpatterns.com/img/node-js-macos-installer-screenshot-477753f7-512.webp 512w, https://www.nodejsdesignpatterns.com/img/node-js-macos-installer-screenshot-477753f7-732.webp 732w" sizes="(max-width: 732px) 100vw, 732px"><img loading="lazy" decoding="async" alt="Install Node.js using the official macOS installer" src="https://www.nodejsdesignpatterns.com/img/node-js-macos-installer-screenshot-477753f7-64.png" width="64" height="48"></picture></span><p>This is probably the easiest way to install Node.js as you don't need to be a POSIX expert or do any kind of manual configuration. The installer will suggest sensible defaults to you and allow you to customise the main parameters (e.g. installation path).</p><p>If you are running a unix system, there is no official graphical installer available, but the <a href="https://nodejs.org/dist/">official Node.js download page</a> offers a set of pre-compiled binaries for most architectures (32-bit, 64-bit, ARMv7 and ARMv8) for Linux, Windows and macOS.</p><span><picture><source type="image/png" srcset="https://www.nodejsdesignpatterns.com/img/node-js-macos-precompiled-binary-bd4ce1d0-64.png 64w, https://www.nodejsdesignpatterns.com/img/node-js-macos-precompiled-binary-bd4ce1d0-128.png 128w, https://www.nodejsdesignpatterns.com/img/node-js-macos-precompiled-binary-bd4ce1d0-256.png 256w, https://www.nodejsdesignpatterns.com/img/node-js-macos-precompiled-binary-bd4ce1d0-512.png 512w, https://www.nodejsdesignpatterns.com/img/node-js-macos-precompiled-binary-bd4ce1d0-1077.png 1077w" sizes="(max-width: 700px) 100vw, 700px"><source type="image/webp" srcset="https://www.nodejsdesignpatterns.com/img/node-js-macos-precompiled-binary-bd4ce1d0-64.webp 64w, https://www.nodejsdesignpatterns.com/img/node-js-macos-precompiled-binary-bd4ce1d0-128.webp 128w, https://www.nodejsdesignpatterns.com/img/node-js-macos-precompiled-binary-bd4ce1d0-256.webp 256w, https://www.nodejsdesignpatterns.com/img/node-js-macos-precompiled-binary-bd4ce1d0-512.webp 512w, https://www.nodejsdesignpatterns.com/img/node-js-macos-precompiled-binary-bd4ce1d0-1077.webp 1077w" sizes="(max-width: 700px) 100vw, 700px"><img loading="lazy" decoding="async" alt="Install Node.js using the official macOS installer" src="https://www.nodejsdesignpatterns.com/img/node-js-macos-precompiled-binary-bd4ce1d0-64.png" width="64" height="26"></picture></span><p>With the binary distribution, it is up to you to copy the necessary files in the right place. A version manager tool such as <code>nvm</code> and <code>n</code> makes things simple, because it takes care of downloading the correct binary release for the desired version (and for your system), then it places the files in the correct folder as expected by your operative system. If you choose to download the binaries manually, all the wiring is up to you.</p><p>While installing Node.js using the official installers is probably the simplest option, doing it using the binaries is a lot more complicated and definitely more complicated than using a version manager.</p><p>If you still want to go down this path, make sure to check out the <a href="https://github.com/nodejs/help/wiki/Installation">official tutorial for installing from Node.js pre-compiled binaries</a>.</p><p>It is definitely worth mentioning that the official installer is not the only option. <a href="https://nodesource.com/">NodeSource</a> maintains alternative installers for Debian, Red Hat, macOS and Windows. If you are interested in this approach checkout <a href="https://node.dev/node-binary">NodeSource Node.js Binary distributions page</a>.</p><p>To summarise, these are the main pros and cons of Node.js installers and …</p></main></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.nodejsdesignpatterns.com/blog/5-ways-to-install-node-js/">https://www.nodejsdesignpatterns.com/blog/5-ways-to-install-node-js/</a></em></p>]]>
            </description>
            <link>https://www.nodejsdesignpatterns.com/blog/5-ways-to-install-node-js/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25542906</guid>
            <pubDate>Sat, 26 Dec 2020 11:56:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Embrace the Splinternet Without Flinching]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25542844">thread link</a>) | @URfejk
<br/>
December 26, 2020 | https://cheapskatesguide.org/articles/splinternet.html | <a href="https://web.archive.org/web/*/https://cheapskatesguide.org/articles/splinternet.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://cheapskatesguide.org/articles/splinternet.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25542844</guid>
            <pubDate>Sat, 26 Dec 2020 11:45:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Johnny Depp Titles Removed from Netflix US]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25542552">thread link</a>) | @smsm42
<br/>
December 26, 2020 | https://www.thegeekbuzz.com/the-basement/johnny-depp-titles-removed-from-netflix/ | <a href="https://web.archive.org/web/*/https://www.thegeekbuzz.com/the-basement/johnny-depp-titles-removed-from-netflix/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<div>

	
			<p>Netflix no longer has any Johnny Depp films streaming in their American library. Coincidence or reaction to his legal loss?</p>
	
					
	<p>Though there has been no official statement from <em>Netflix</em>, the streaming giant has apparently removed all <em>Johnny Depp</em> titles from its American library. This news comes on the heels of actor <strong>Shia LaBeouf</strong> being removed from Netflix’s award consideration website&nbsp;and publicity materials following&nbsp;recent allegations&nbsp;of&nbsp;physical, emotional, and mental abuse. As of this writing, several titles with LaBeouf were still on Netflix. Likewise, Depp titles can still be accessed on Netflix outside the United States.</p>
<p>Depp <a href="https://www.thegeekbuzz.com/the-basement/johnny-depp-loses-to-the-sun-amber-heard-in-gripping-uk-court-case/" target="_blank" rel="noopener noreferrer">lost a high-profile libel case</a> in the UK last month against the Sun who called the fading former A-lister a wifebeater. In his decision, <strong>Judge Nicol</strong> said, “taking all evidence together, I accept [<strong>Amber Heard</strong>] was the victim of sustained and multiple assaults by Depp. I accept her evidence of the nature of the assaults he committed against her. They must have been terrifying.”</p>
<p>This may have been a delayed reaction to the results of that trial, timed to correspond with their actions on LaBeouf, or it may just be part of Netflix’s standard cycling of titles in and out of their library.</p>
<p>The former Captain Jack Sparrow was also featured in a <a href="https://www.thegeekbuzz.com/the-basement/the-hollywood-reporters-devastating-expose-on-johnny-depp/" target="_blank" rel="noopener noreferrer">scathing article</a> by <em>The Hollywood Reporter</em> earlier this month in which several Hollywood insiders portrayed him as toxic.</p>
<p>According to satista.com, Netflix had 195.15 million paid subscribers worldwide as of the third quarter&nbsp;<b>of 2020</b>. Most Netflix subscribers are based in the United States, with the U.S. accounting for over&nbsp;<b>73 million</b> of Netflix’s total global subscriber base.&nbsp; They’re not likely to be intimidated by threats of boycotts from fans of Johnny Depp. Disney + still has several available to stream, but they’re under a boycott by Depp fans already.</p>
<p>RELATED: <a href="https://www.thegeekbuzz.com/rumors/see-leonardo-dicaprio-as-johnny-depps-replacement-in-pirates-of-the-caribbean-6/">See Leonardo DiCaprio as Johnny Depp’s Replacement</a> in Pirates of the Caribbean 6!</p>

	
	
				</div>			</div></div>]]>
            </description>
            <link>https://www.thegeekbuzz.com/the-basement/johnny-depp-titles-removed-from-netflix/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25542552</guid>
            <pubDate>Sat, 26 Dec 2020 10:28:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Still Rusting – One Year Later]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25542280">thread link</a>) | @lukastyrychtr
<br/>
December 26, 2020 | https://deislabs.io/posts/still-rusting-one-year-later/ | <a href="https://web.archive.org/web/*/https://deislabs.io/posts/still-rusting-one-year-later/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

<p>It has been about a year since the DeisLabs team starting using Rust in a “serious” project. About this time last year, we started work on what became the <a href="https://github.com/deislabs/krustlet">Krustlet</a> project. Since then, we have been using Rust extensively across our projects and have learned a ton more about the language’s strengths and weaknesses. As “Rust After the Honeymoon” posts currently seem to be all the rage, we thought we could contribute a little to the discussion with our experiences writing applications for the cloud world.</p>

<p>This post is organized using the classic (if not tired) good, bad, and ugly structure. In the bad and ugly sections, everything is stated as points of feedback and is not meant as a complaint. The whole point of this post is to go beyond the more superficial parts of the language and into things that really make a difference in our day-to-day programming work. Spoiler alert: We still <em>really</em> like Rust, so all of this is intended as helpful data for those working on the language, to give people new to the language a good idea of some of the things they might run into, and to help others evaluate Rust for their own use. We have tried to incorporate ideas of possible solutions, no matter how vague, to the problems we bring up.</p>

<p>At the very end, we also have a bonus feature about Go and Rust. Given the team’s background in many Go projects, we often hear something like this: “Well, what about Go? Do you regret moving to Rust? What do you miss from Go?” Addressing this in the context of our discussion of Rust felt like a smart decision. If you don’t care about that topic or it doesn’t interest you, feel free to skip it.</p>

<p>Now with that out of the way, let’s get going!</p>

<h2 id="the-good">The Good</h2>

<h3 id="traits">Traits</h3>

<p>First up, let’s talk about traits. We have absolutely loved the trait system in Rust. In particular, we really enjoy the conversion and reference traits (e.g. <code>TryFrom</code>/<code>From</code>, <code>AsRef</code>, <code>FromStr</code>, <code>Deref</code>, etc.). These are great examples of why traits are better than most other interface-style types – because the type itself doesn’t have to implement an interface to be used as another type. <code>FromStr</code> allows any type to implement a way to parse a bare string into a type (really useful for APIs). Another simple example can be found in the many types that implement <code>AsRef&lt;[u8]&gt;</code> or <code>Deref&lt;Type = [u8]&gt;</code>. Instead of having some sort of <code>Bytes</code> interface that all the types have to implement to be able to do operations as if it was a slice of bytes, you can just automatically pick up the methods from the underlying type. Yes, I know you could embed types or use inheritance, but the elegance of this is quite nice. This also allows me to write custom types and have easy/cheap conversions or references to them from other external types. It leads to generic parameters that look like this:</p>

<pre><code>// A function that can write anything that can be accessed as bytes:
// write_all("hello!")
// write_all(String::from("hello!"))
// write_all(b"hello!")
fn write_all&lt;T: AsRef&lt;[u8]&gt;&gt;(data: T)

// Or, I can take anything that can be converted to my custom type
fn do_something&lt;T: Into&lt;MyType&gt;&gt;(thing: T)
</code></pre>

<p>Basically, traits allow you to design flexible APIs for users that allow them to latch on to and/or extend the functionality of your code. This leads to my next point – <a href="https://serde.rs/">Serde</a>.</p>

<h3 id="a-love-letter-to-serde">A Love Letter to Serde</h3>

<p>Allow us to indulge in a brief love letter to Serde, the much-used serialization/deserialization library leveraged across the Rust ecosystem. To us, it is a first-rate product of Rust’s unique combination of features. It leverages macros, traits, and Rust’s emphasis on zero-cost abstractions to create a library that is powerful, easy to use, and performant. Developers can easily add serialization or deserialization with a simple <code>#[derive(Serialize, Deserialize)]</code> and then customize deserialization behaviors with attributes. Even if you have to implement it manually, there are plenty of docs to read. Once those traits are implemented, any serialization format that has a Serde implementation (like JSON, YAML, etc.) can then serialize or deserialize that data.</p>

<h3 id="error-handling-option-and-iter">Error handling, <code>Option</code>, and <code>Iter</code></h3>

<p>Another thing high on our “impressive Rust features” list is an amazing set of mapping, unwrapping, and iteration tools. The built in <code>Result</code> and <code>Option</code> types combined with their various mapping methods (and <code>if let</code> or <code>let thing = match {...}</code>) makes it easy to handle errors/missing data in an easy to read way. It also nudges you towards clean and readable error handling patterns (like the try <code>?</code> operator), which is helpful for people new to the language. On top of the error handling, we have the <code>Iterator</code> trait and its associated methods. There are a whole suite of chainable filters, maps, splitting, and zipping methods (similar to how LINQ and functional programming languages handle collections) along with the all-powerful <code>collect</code> method. Below is an example from Krustlet that shows unwrapping an optional value and then mapping and filtering from a collection of data:</p>

<pre><code>fn mount_setting_for(key: &amp;str, items_to_mount: &amp;Option&lt;Vec&lt;KeyToPath&gt;&gt;) -&gt; ItemMount {
    match items_to_mount {
        None =&gt; ItemMount::MountAt(key.to_string()),
        Some(items) =&gt; ItemMount::from(
            items
                .iter()
                .find(|kp| kp.key == key)
                .map(|kp| kp.path.to_string()),
        ),
    }
}
</code></pre>

<h3 id="enums">Enums</h3>

<p>We’ve found Rust enums really expressive and convenient. Rust enums aren’t just single values: they can carry associated data. What’s more, each variant can have a different data structure (like discriminated unions from other languages), and you can work with these different cases using pattern matching. They’re also full-blown types, so you can implement functions and traits on them.</p>

<p>The value of this is that you can bundle a bunch of possible cases into a single type to pass into (or return from) and function. Working with the cases is safe because you don’t need to have optional fields that only may apply to certain cases, and you can only access a case’s data when the enum matches that case. The case structure also encourages code that processes enums to adopt a clear, regular layout, making for some quite beautiful code:</p>

<pre><code>pub enum ClientError {
    /// The item already exists
    AlreadyExists,
    /// The error returned when the request is invalid. Contains the underlying HTTP status code and
    /// any message returned from the API
    InvalidRequest {
        status_code: reqwest::StatusCode,
        message: Option&lt;String&gt;,
    },
    /// A server error was encountered. Contains an optional message from the server
    ServerError(Option&lt;String&gt;),
}

pub fn handle_error(e: ClientError) {
    match e {
        ClientError::AlreadyExists =&gt; {
            println!("Item already exists")
        }
        ClientError::InvalidRequest { status_code, message } =&gt; {
            println!("Invalid request. HTTP code: {}, message: {}", status_code, message.unwrap_or_default())
        }
        ClientError::ServerError(Some(message)) =&gt; {
            println!("Server error: {}", message)
        },
        ClientError::ServerError(None) =&gt; {
            println!("Server error")
        },
        
    }
}
</code></pre>

<p>In this example, we created a simple error type and then unwrapped it according to the data contained inside of each variant. The Rust compiler makes sure we handle all variants of the enum, preventing programmer error (likely from getting distracted by a meme someone posted in chat).</p>

<h3 id="grab-bag">Grab Bag</h3>

<ul>
<li>Macros are awesome and allow you to do some powerful things (and clean up code)</li>
<li>Cargo still has our hearts. It is hands down one of the top dependency manager and build tools we’ve used</li>
<li>To quote a coworker: “NO DAMN NULL POINTERS” (emphasis theirs). You explicitly have to label code as <code>unsafe</code> to even get them</li>
</ul>

<h2 id="the-bad">The Bad</h2>

<h3 id="docs-and-clarity">Docs and Clarity</h3>

<p>As we have been using various crates across the ecosystem, we’ve found some interesting patterns in the documentation. Docs are sometimes unclear on what is happening in the actual code. They describe the functionality well, but we generally have to go digging through the code to find out whether it is truly a zero cost abstraction or if there are possible side effects to what we are doing. When you first start on projects, generally these kinds of details don’t matter. But as you start doing things that require more advanced usage, you end up digging under the hood to see what exactly is going on. For example, if we are using a library that writes data to disk, make sure to clarify which methods flush data or close things down.</p>

<p>Related to this, but slightly different, is trait documentation. As users, if we are trying to find out how we can customize behavior, we always end up jumping through a million functions, looking at all the trait bounds, before we can figure out what we need to implement (It also seems to always be a trait imported from <em>another</em> crate). An example of this from some recent work on Krustlet. We were using the <a href="https://docs.rs/tonic/0.3.1/tonic/"><code>tonic</code></a> crate and implementing a socket listener for the server. We ended up at one of the functions that allows for a custom handler, but that had 3-4 distinct bounds, 2 of which were traits from external crates. We eventually found an example in the crate repo and it wasn’t too difficult, but there was no clear documentation what needed to be implemented without digging more. This experience is <em>really really frustrating</em> for new Rust developers and we’ve seen this in multiple crates. The suggestion here would be to put a little more polish into describing what precisely needs to be implemented (even if just linking to an example) on functions with multiple trait bounds.</p>

<h3 id="missing-pieces">Missing Pieces</h3>

<p>Something to be aware of coming into the Rust ecosystem is that a lot of crates are still missing features. A recent example of this was finding out that there isn’t much support for <code>multipart</code> content types in HTTP requests except for <code>multipart/form-data</code>. This is not meant to be a complaint against any developer of any crate. We …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://deislabs.io/posts/still-rusting-one-year-later/">https://deislabs.io/posts/still-rusting-one-year-later/</a></em></p>]]>
            </description>
            <link>https://deislabs.io/posts/still-rusting-one-year-later/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25542280</guid>
            <pubDate>Sat, 26 Dec 2020 09:11:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Hacker News Daily – Lightweight glance over the past best stories]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25542226">thread link</a>) | @lopespm
<br/>
December 26, 2020 | https://lopespm.github.io/hackernews-daily | <a href="https://web.archive.org/web/*/https://lopespm.github.io/hackernews-daily">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					<div>
						<a href="https://news.ycombinator.com/item?id=25558587">
						
							
								<p>"Oakland relaxed a lot of zoning, and permitting regulations about 5 years ago, and so now you're starting to really see production sky rocket. This article [0] mentions 2019 was had 15x more units completed than 2018. And 3x the total units from 2013-2018 combined. Anecdotally, I have several friends who've all moved to Oakland in the last year or so. It will be interesting to see how this plays out, and maybe, hopefully, SF will take the hint.[0] - https://www.city-journal.org/oakland-rezoning-california-hou..."</p>
							
						
							
								<p>"Don't ask, Don't get.Everyone I know who has asked for a discount has got the discount.After several months of the pandemic, and noticing the adjacent apartment being relisted by my landlord at a discount I emailed my landlord and asked if I could have my rent adjusted by the same discount. They said yes, if I committed to another years lease.Saving 5% of rent, at the cost of a one year commitment didn't seem like a win, so I politely declined explaining my reasoning, and suggested we leave things as they are.A week or so later, out of the blue by my rent got adjusted by 10%+ instead of 5% with no need to commit to stay.Sufficed to say, if their intention was for me to stay put, it worked!"</p>
							
						
							
								<p>"&gt; the weighted average asking rent for an apartment in the city, which currently measures around 2.3 bedrooms when counting a studio as having one, has dropped to $3,100 a month.Still too high. Was checking into apartment prices earlier in the year and it is amazing the number of landlords that will try and sell you on a “kitchen” that is a mini-fridge, tiny sink, microwave and a hot plate whilst still charging you full rent.San Francisco’s rental market is a good lesson in how supply and demand informs pricing that the residents and the Board of Supervisors alike continuously and willfully ignore."</p>
							
						
						</a>
					</div>
				</div></div>]]>
            </description>
            <link>https://lopespm.github.io/hackernews-daily</link>
            <guid isPermaLink="false">hacker-news-small-sites-25542226</guid>
            <pubDate>Sat, 26 Dec 2020 08:51:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WebGL Shader Experiment]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25542101">thread link</a>) | @germanka
<br/>
December 26, 2020 | https://gyro851.github.io/webgl-shader-experiment/ | <a href="https://web.archive.org/web/*/https://gyro851.github.io/webgl-shader-experiment/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://gyro851.github.io/webgl-shader-experiment/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25542101</guid>
            <pubDate>Sat, 26 Dec 2020 08:08:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Curl Year 2020]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25542012">thread link</a>) | @sandebert
<br/>
December 25, 2020 | https://daniel.haxx.se/blog/2020/12/24/the-curl-year-2020/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2020/12/24/the-curl-year-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
		
	
	<!-- #masthead -->

	<div id="main">

	<div id="primary">
		<div id="content" role="main">
			
<article id="post-15375">
	
		<p><img width="672" height="372" src="https://daniel.haxx.se/blog/wp-content/uploads/2017/12/fireworks-180553_1920-672x372.jpg" alt="" loading="lazy" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2017/12/fireworks-180553_1920-672x372.jpg 672w, https://daniel.haxx.se/blog/wp-content/uploads/2017/12/fireworks-180553_1920-1038x576.jpg 1038w" sizes="(max-width: 672px) 100vw, 672px">		</p>

		
	<!-- .entry-header -->

		<div>
		
<p>As we’re approaching the end of the year, I just want to sum up the curl year with a few words.</p>



<p>2020 has been another glorious year in the curl project. We’ve seen a series of accomplishments and introductions of new things during this the year of the plague.</p>



<h2>Accomplishments</h2>



<p>I personally have done more commits in the git repository since any year after 2004 (890 so far).</p>



<p>The total number of commits done in git is the largest since 2014 (1445 plus some).</p>



<p>The number of published curl related CVEs is the lowest since 2013 (6). For the ones we announced, we could reward record amounts in our bug bounty program!</p>



<p>139 authors wrote commits that were merged (so far).</p>



<p>We did nine curl releases, out of which two unfortunately were quicker “panic releases” that patched up problems in the previous release.</p>



<h2>Seven changes to remember</h2>



<p>We’ve logged no less than <strong>905 bug-fixes</strong> and <strong>30 changes</strong> in the releases of this year, but the seven perhaps most memorable things we’ve introduced in 2020 are…</p>



<ul><li><a href="https://daniel.haxx.se/blog/2019/07/22/curl-goez-parallel/" data-type="post" data-id="12568">Parallel transfers</a> with curl</li><li><a href="https://daniel.haxx.se/blog/2020/04/14/curl-mqtt-true/" data-type="post" data-id="13836">MQTT</a>://</li><li><a href="https://daniel.haxx.se/blog/2020/11/03/hsts-your-curl/" data-type="post" data-id="11415">HSTS</a></li><li><a href="https://daniel.haxx.se/blog/2020/09/04/curl-help-remodeled/" data-type="post" data-id="14601"><code>--help</code> refined</a></li><li><a href="https://daniel.haxx.se/blog/2020/08/19/curl-7-72-0-more-compression/" data-type="post" data-id="14463">Zstd</a></li><li><a href="https://daniel.haxx.se/blog/2020/03/17/curl-write-out-json/" data-type="post" data-id="13740">JSON output</a> in -w</li><li><a href="https://daniel.haxx.se/blog/2020/01/12/curl-even-more-wolfed/" data-type="post" data-id="13130">wolfSSH backend</a></li></ul>



<h2>Videos</h2>



<p>This year I’ve introduced the concept of doing a “release presentation” for every release. Those are videos where I go through and discuss the changes, the security releases and some interesting bug-fixes. Each release links to those from <a href="https://curl.se/changes.html">the changelog page</a> on the website.</p>



<h2>New home</h2>



<p>This is the year when we finally got ourselves a curl domain. <a href="https://daniel.haxx.se/blog/2020/11/04/the-journey-to-a-curl-domain/" data-type="post" data-id="14930">curl.se is our new home</a>.</p>



<h2>What didn’t happen</h2>



<p>We cancelled curl up 2020 due to Covid-19. It was planned to happen in Berlin. We did it purely online instead. We’re not planning any new physical curl up for 2021 either. Let’s just wait and see what happens with the pandemic next year and hope that we might be able to go back and have a physical meetup in 2022…</p>



<h2>It is a curl world</h2>



<figure><a href="https://daniel.haxx.se/blog/wp-content/uploads/2020/12/slide-a-curl-world-2020.jpg"><img loading="lazy" width="2000" height="1125" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/12/slide-a-curl-world-2020.jpg" alt=""></a></figure>




	</div><!-- .entry-content -->
	
	</article><!-- #post-15375 -->
		<nav role="navigation">
		
		<!-- .nav-links -->
		</nav><!-- .navigation -->
		
<!-- #comments -->
		</div><!-- #content -->
	</div><!-- #primary -->

<!-- #content-sidebar -->
<div id="secondary">
		<h2>tech, open source and networking</h2>
	
	
		<!-- #primary-sidebar -->
	</div><!-- #secondary -->

		</div><!-- #main -->

		<!-- #colophon -->
	</div></div>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2020/12/24/the-curl-year-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25542012</guid>
            <pubDate>Sat, 26 Dec 2020 07:35:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Manga Guide to Lisp]]>
            </title>
            <description>
<![CDATA[
Score 131 | Comments 13 (<a href="https://news.ycombinator.com/item?id=25541919">thread link</a>) | @joubert
<br/>
December 25, 2020 | http://lambda.bugyo.tk/cdr/mwl/ | <a href="https://web.archive.org/web/*/http://lambda.bugyo.tk/cdr/mwl/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://lambda.bugyo.tk/cdr/mwl/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25541919</guid>
            <pubDate>Sat, 26 Dec 2020 06:57:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Japanese Sentence Structure Intro]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25541124">thread link</a>) | @sova
<br/>
December 25, 2020 | https://japanesecomplete.com/articles/?p=1265 | <a href="https://web.archive.org/web/*/https://japanesecomplete.com/articles/?p=1265">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-1265">

	

	
			<figure>
				<img width="1568" height="1045" src="https://japanesecomplete.com/articles/wp-content/uploads/2020/12/lanterns.jpg" alt="" loading="lazy">			</figure><!-- .post-thumbnail -->

		
	<div>
		
<p>Aside from always having a verb at the end, Japanese does not depend on sequence.  Japanese is a grammar defined by <em>grammar particles</em>, functional “words” that glue on to nouns to indicate what purpose the noun serves.</p>



<p>Here we highlight some common Japanese particles in a slice of the ひらがな [hiragana] syllabary.</p>



<figure><img loading="lazy" width="1069" height="834" src="https://japanesecomplete.com/articles/wp-content/uploads/2020/12/japanese-particles.png" alt=""></figure>



<p>You can practice your 🎵 listening comprehension👂 of the ひらがな 🎎 <a href="http://japanesecomplete.com/hiragana">here</a>.  But we digress, Japanese relies on <em>grammatical particles</em> to indicate the <strong>who, what, when,  where, and how</strong> of a sentence.</p>



<h2><strong>Who, what, when, where, and how</strong>.</h2>



<h2>で  (de) <strong>where and how</strong></h2>



<p>For example, で [“deh”] implies <em>manner of accomplishment</em> or <em>setting-locality where something takes place.</em> Mapping to English, we cover the <strong>where</strong> [setting] and <strong>how</strong> [means] with で。</p>



<figure><img loading="lazy" width="246" height="142" src="https://japanesecomplete.com/articles/wp-content/uploads/2020/12/Screen-Shot-2020-12-19-at-4.34.24-PM.png" alt=""></figure>



<hr>



<h2>に (ni) where and when</h2>



<p>For destinations, or specific times, or precise physical points of existence (being), Japanese relies on the use of the <em>grammatical particle</em> に [“ni” as in, <a href="https://www.youtube.com/watch?v=zIV4poUZAQo">“we are the knights who say…”</a>].  に [“knee!”] therefore covers <strong>where</strong> [destination] and <strong>when</strong> [moment].</p>



<figure><img loading="lazy" width="648" height="446" src="https://japanesecomplete.com/articles/wp-content/uploads/2020/12/Screen-Shot-2020-12-19-at-4.36.55-PM.png" alt=""></figure>



<hr>



<h2>が  (ga) who and what</h2>



<p>The <em>grammatical particle</em> が [“ga”] is used to explain <strong>who</strong> and <strong>what</strong> when used as the <strong>grammatical subjects</strong> of a sentence.  </p>



<p>For example: Vegetables are delicious.  Candy is sweet.<br>  (Veggies are <strong>what</strong> is delicious)<br>  (The candy is <strong>what</strong> is sweet)</p>



<figure><img loading="lazy" width="366" height="295" src="https://japanesecomplete.com/articles/wp-content/uploads/2020/12/Screen-Shot-2020-12-19-at-4.38.46-PM.png" alt=""></figure>



<hr>



<p>Finally, in this brief primer, we want to show the concept of <strong>bunsetsu jar</strong> which we have featured on our <a href="http://japanesecomplete.com/reverse-engineer/">“Reverse Engineer Some Japanese”</a> page.</p>



<figure><img loading="lazy" width="737" height="138" src="https://japanesecomplete.com/articles/wp-content/uploads/2020/12/Screen-Shot-2020-12-19-at-4.41.05-PM.png" alt=""></figure>



<p>Within a <strong>bunsetsu jar</strong>, we place a noun and cap off the <strong>jar</strong> with a <strong>lid</strong> containing a <em>grammatical particle</em> such as が、に、で or one of the many others.  </p>



<p>In total, there is an estimated 233 + particles (some are multi-mora, that is, multiple letters) and we teach them in a gradual and comprehensible way in <a href="https://japanesecomplete.com/articles/?p=83">Japanese Complete</a>.</p>



<p>Finally, a sentence-final verb is placed at the end of a sentence.  In English, this would be akin to moving the “is/are” or “be/exists” verb to the end of every sentence.  Japanese fun is.  Grammar easy is.  Japanese-about thinking = interesting is.</p>



<p>So that’s it. You pick your nouns, you pick the <em>grammatical particles</em> to match based on the meaning of <strong>who, what, when, where, and how</strong>, and you figure out the sentence-final verb element.  Now you’re thinking in Japanese.</p>



<p>Of course, developing the reflex and intuition around this takes some practice, which is why we devised quizzes for Japanese Complete that help train your intuition on the particles, one-by-one.  You can watch a brief video showing some of the quizzes in action on our <a href="https://japanesecomplete.com/guide">free guide page</a>.</p>



<hr>



<h2>Kanji in English Context</h2>



<p>In order to accelerate Kanji comprehension into English context, as you can see in a sonnet by Shakespeare on <a href="http://japanesecomplete.com/learning-to-read">this page</a>.  This pattern follows a similar pattern of adoption that native Japanese took: grab kanji from mainland Asia for their ideographic value and smash them together with your native syllabary to add helpful meaning, nuance, and context.</p>



<figure><img loading="lazy" width="496" height="177" src="https://japanesecomplete.com/articles/wp-content/uploads/2020/12/Screen-Shot-2020-12-19-at-4.46.27-PM.png" alt=""></figure>



<p><strong>Temple NI arrive.</strong> [unstated subjects arrive to the temple]</p>



<p><strong>Enter-before NI, hands OH let’s wash, NE.</strong> [before entering, let’s wash our hands, right?]</p>



<p>We’ve created a substack newsletter to share <em>Kanji in English Context </em>once or twice a month, you can <a href="https://japanesecomplete.substack.com/p/coming-soon">sign up for it here</a> if you’re interested in getting interesting <em>Kanji in English Context</em> lessons to your inbox.</p>



<hr>



<p>One great thing about Japanese grammar is that the <strong>bunsetsu jars</strong> can be arranged in any sequence before the final verb, provided each noun has its appropriately matching <em>grammar particle</em> glued on and intact.  This leads to great fun with parsing, as one can create a <a href="https://japanesecomplete.com/articles/?p=811">rudimentary Japanese grammar parser</a> from a 5-line EBNF grammar.</p>



<figure><img loading="lazy" width="1080" height="1349" src="https://japanesecomplete.com/articles/wp-content/uploads/2020/12/osaka-castle.jpg" alt=""></figure>



<p>Hopefully this post made the inner mechanics of Japanese more clear.  Developing intuition and unlocking the language takes study, practice, and determination!  If you’re looking for a program to break the language down logically <strong>and</strong> provide practice and training to help your newfound understanding become intuitive and fast, might we humbly suggest <a href="https://japanesecomplete.com/">Japanese Complete</a>.</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article><!-- #post-${ID} -->

	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
<!-- #comments -->

		</main><!-- #main -->
	</section><!-- #primary -->


	</div></div>]]>
            </description>
            <link>https://japanesecomplete.com/articles/?p=1265</link>
            <guid isPermaLink="false">hacker-news-small-sites-25541124</guid>
            <pubDate>Sat, 26 Dec 2020 03:25:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Disabled snap store in Linux Mint 20]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25540780">thread link</a>) | @backing
<br/>
December 25, 2020 | https://linuxmint-user-guide.readthedocs.io/en/latest/snap.html#disabled-snap-store-in-linux-mint-20 | <a href="https://web.archive.org/web/*/https://linuxmint-user-guide.readthedocs.io/en/latest/snap.html#disabled-snap-store-in-linux-mint-20">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div id="snap-store">

<p>The <a href="https://snapcraft.io/">Snap Store</a>, also known as the <cite>Ubuntu Store</cite>, is a commercial centralized software store operated by <a href="https://canonical.com/">Canonical</a>.</p>
<p>Similar to AppImage or Flatpak the Snap Store is able to provide up to date software no matter what version of Linux you are running and how old your libraries are.</p>
<div id="criticism">
<h2>Criticism<a href="#criticism" title="Permalink to this headline">¶</a></h2>
<div id="centralized-control">
<h3>Centralized control<a href="#centralized-control" title="Permalink to this headline">¶</a></h3>
<p>Anyone can create APT repositories and distribute software freely. Users can point to multiple repositories and define priorities. Thanks to the way APT works, if a bug isn’t fixed upstream, Debian can fix it with a patch. If Debian doesn’t, Ubuntu can. If Ubuntu doesn’t Linux Mint can. If Linux Mint doesn’t, anyone can, and not only can they fix it, they can distribute it with a PPA.</p>
<p>Flatpak isn’t as flexible. Still, anyone can distribute their own Flatpaks. If Flathub decides they don’t want to do this or that, anyone else can create another Flatpak repository. Flatpak itself can point to multiple sources and doesn’t depend on Flathub.</p>
<p>Although it is open-source, Snap on the other hand, only works with the Ubuntu Store. Nobody knows how to make a Snap Store and nobody can. The Snap client is designed to work with only one source, following a protocol which isn’t open, and using only one authentication system. Snapd is nothing on its own, it can only work with the Ubuntu Store.</p>
<p>This is a store we can’t audit, which contains software nobody can patch. If we can’t fix or modify software, open-source or not, it provides the same limitations as proprietary software.</p>
</div>
<div id="backdoor-via-apt">
<h3>Backdoor via APT<a href="#backdoor-via-apt" title="Permalink to this headline">¶</a></h3>
<p>When Snap was introduced Canonical promised it would never replace APT. This promise was broken. Some APT packages in the Ubuntu repositories not only install snap as a dependency but also run snap commands as root without your knowledge or consent and connect your computer to the remote proprietary store operated by Canonical.</p>
</div>
</div>
<div id="disabled-snap-store-in-linux-mint-20">
<h2>Disabled Snap Store in Linux Mint 20<a href="#disabled-snap-store-in-linux-mint-20" title="Permalink to this headline">¶</a></h2>
<p>Following the decision made by Canonical to replace parts of APT with Snap and have the Ubuntu Store install itself without users knowledge or consent, the Snap Store is forbidden to be installed by APT in Linux Mint 20.</p>

</div>
<div id="how-to-install-the-snap-store-in-linux-mint-20">
<h2>How to install the Snap Store in Linux Mint 20<a href="#how-to-install-the-snap-store-in-linux-mint-20" title="Permalink to this headline">¶</a></h2>
<p>Recommended or not, if you want to use the Snap Store, re-enabling and installing it is very easy.</p>
<div><div><pre><span></span>sudo rm /etc/apt/preferences.d/nosnap.pref
apt update
apt install snapd
</pre></div>
</div>
</div>
</div>


           </div>
           
          </div></div>]]>
            </description>
            <link>https://linuxmint-user-guide.readthedocs.io/en/latest/snap.html#disabled-snap-store-in-linux-mint-20</link>
            <guid isPermaLink="false">hacker-news-small-sites-25540780</guid>
            <pubDate>Sat, 26 Dec 2020 02:10:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[VPN – A Precarious Narrative]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25540314">thread link</a>) | @aminozuur
<br/>
December 25, 2020 | https://schub.wtf/blog/2019/04/08/very-precarious-narrative.html | <a href="https://web.archive.org/web/*/https://schub.wtf/blog/2019/04/08/very-precarious-narrative.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="content">
        
        <p>
  
  <span><i aria-label="This item was published on:"></i> 2019-04-08</span>
  <span><i aria-label="This item was updated on:"></i> 2019-04-22</span>
  <span><i aria-label="This item was tagged with:"></i> privacy, security</span>
</p>


        





        

        <section id="main_content">
          <p>I just watched a <em>great</em> YouTube video, touching technical, political, and philosophical questions around the whole “who controls the algorithm” topic, from one of those multi-million subscriber channels, spending lots and lots of time and resources on researching and producing. The video was perfect, but the end did upset me slightly. In the end, the sponsoring message was read, and the sponsor was one of those VPN companies, with their usual marketing lingo. You surely know what I am talking about, but let me quote the sponsoring message here for context:</p>

<blockquote>
  <p>Your internet connection, right now, is broadcasting your IP address, which is the way people track you online. Check this out [shows a screencap of a website displaying the IP and GeoLocation information], when I go to this website, it tests everything that my internet connection is leaking. You can see my IP address, but you can also see where I am. Your internet connection is doing this right now. Here is how [VPN company] works: It is a Virtual Private Network, you turn it on with one click. My internet traffic is now encrypted, and going through [VPN company]s servers located throughout the world, so people can no longer figure out where I am located. I protect myself online with [VPN company]. […] There is a 30-day money back guarantee which I am confident you are not going to use, because I feel comforted knowing that my personal information is protected on the internet.</p>
</blockquote>

<p>Here is another one, from a different channel:</p>

<blockquote>
  <p>With all the recent news about online security breaches, it is hard not to worry about where my data goes. Make an online purchase or simply accessing your email puts your private information at risk. You are being tracked online all the time by social media sites, marketing companies, and mobile internet providers. That is why you need to take your internet privacy back right now. Use [VPN company]! [VPN company] has the easiest apps that run seamlessly in the background of any computer, phone, and tablet. Turning on [VPN company] protection only takes one click. I am going to tell you what takes more than one click: getting your identity and data back after it’s been lost. Try getting back the money from your stolen credit cards. Do one click now. [VPN company] secures and anoymizes your internet browsing by encrypting your data and hiding your public IP address.</p>
</blockquote>

<p>The popularity of those services and the way they are recommended and promoted is bad. So bad that I feel impelled to write this article on it, to explain two problematic points. Those are:</p>

<ol>
  <li>In most circumstances, <strong>VPNs do very little to enhance your data security or privacy</strong> unless paired with other changes.</li>
  <li>Acting as they do, and <strong>promoting commercial VPN providers</strong> as a solution to potential issues <strong>does more harm than good</strong>.</li>
</ol>

<p>Just stick around for a bit, and I will explain everything. Before I start, though, let me clarify that I am writing this post with non-technical, but curious people in mind. This means that I will be using simplified terms and sometimes generalize a bit. However, I can assure you that all information is still very accurate. Sometimes, using technical words is necessary to avoid this post becoming inaccurate. If you do not understand something, just read on, the next paragraph might be more apparent.</p>

<h2 id="what-a-vpn-is-and-what-it-is-not">What a VPN is, and what it is not.</h2>

<blockquote>
  <p>[…] another worrying aspect of today’s market of VPN services is the large misinformation end users are exposed to, which makes it hard for them to properly tell apart vague and bold claims typical of product advertisement campaigns with actual facts.</p>

  <p>- <em>a <a href="https://www.degruyter.com/downloadpdf/j/popets.2015.1.issue-1/popets-2015-0006/popets-2015-0006.pdf" target="_blank" rel="noopener">paper published in 2015</a></em>.</p>
</blockquote>

<p><img src="https://schub.wtf/statics/blog/20190408/vpn-banner.png" alt="VPN - a Very Precarious Narrative"></p>

<p>To start, <a href="https://en.wikipedia.org/wiki/Virtual_private_network" target="_blank" rel="noopener">Wikipedia</a> has a very nice summary of what a VPN is:</p>

<blockquote>
  <p>A virtual private network (VPN) extends a private network across a public network, and enables users to send and receive data across shared or public networks as if their computing devices were directly connected to the private network.</p>
</blockquote>

<p>A VPN is a <em>tunnel</em> connecting two different networks. You throw traffic into one end of the tunnel, and it will come out somewhere else, even if the destination might not be reachable on the public internet. VPNs are popular in company environments: Imagine a large company running their servers with private sale data on them. The company does not want those servers to be reachable via the internet for security reasons, but at the same time, salespeople need to be able to access those datasets, even if they are on the road. The salesperson can use the company’s VPN to “move their laptop into the company network”, without the need to physically be there, so they have access to that information. In addition, network traffic sent over VPNs is generally encrypted, so even if the salesperson is using a maybe insecure network, the data is probably safe, if everything is configured correctly.</p>

<p>The VPNs that get advertised at the end of YouTube videos are different. They are not used to access protected, internal infrastructure. Instead, they are used to tunnel <em>all</em> network traffic into a datacenter you neither know nor can control in any way. To understand why this might be a bad idea and is absolutely not necessary in most cases, let’s look at the marketing claims.</p>

<h2 id="your-ip-is-used-for-tracking-and-leaks-private-information-you-should-hide-it">“Your IP is used for tracking and leaks private information. You should hide it.”</h2>

<p>One thing that most VPN advertisements have in common is some babble around IP addresses. Providers claim that your IP address leaks tons of private information, even your physical location, and they also claim that IP addresses are used for tracking. I call that fearmongering and deliberate misinformation.</p>

<p><img src="https://schub.wtf/statics/blog/20190408/vpn-check.jpg" alt="Two screenshots from VPN websites showing my &quot;unprotected&quot; IP address"></p>

<p>I am sure you have seen notices like these on VPN provider’s websites before. They claim that your IP can be used to track you, and they even show a map of where you are located to make it look scarier.</p>

<p>Before I address those two things, let me say something more generic. Notice how both sites show my IP, claim that my connection is “unprotected”, and one is even showing a map? Well. In reality, I am actually <em>using a VPN</em> in those screenshots, I just happened to use <a href="https://protonvpn.com/" target="_blank" rel="noopener">ProtonVPN</a> for this example, so I should be protected very well, right? How come they claim I am unprotected?</p>

<p>That is because those “tests” do not do anything useful. The only check these things are doing is a simple “is the user currently connected via one of our IPs, and thus is using our VPN? If yes, say the user is protected, otherwise, act like the world is on fire”. Not very productive.</p>

<h3 id="ip-addresses-for-user-identification">IP addresses for user identification</h3>

<p>One of the sponsor messages I quoted earlier explicitly claims that IP addresses are how you “are being tracked online all the time by social media sites and marketing companies”. But is that so? We all know that Facebook is pretty big in the whole “tracking people” business, so if you have an active subscription at one of those VPN providers and a Facebook account, let’s do a test together!</p>

<ol>
  <li>Open a new Private Window/Incognito Window in your favorite browser.</li>
  <li>In that window, open two tabs: Facebook, and the “What is my IP?” page of your VPN provider, like <a href="https://www.expressvpn.com/what-is-my-ip" target="_blank" rel="noopener">this one from ExpressVPN</a>.</li>
  <li>Log in to your Facebook account.</li>
  <li>With the VPN disabled, verify that the “test” site shows “you are unprotected”, like in my screenshots above.</li>
  <li>Connect to your VPN. Refresh the VPN test page, which should now say that your IP is hidden and your connection is protected. Right?</li>
  <li>Now, switch over to the Facebook tab, and hit reload.</li>
</ol>

<p>So, what happened? Did Facebook forget who you are, and boot you back out to the login form? No, of course not. Even though your IP address changed, Facebook still knew <em>exactly</em> who you are. So do marketing companies and other tracking parties.</p>

<p>The reality here is that your IP address is only a tiny piece of your trackable profile and a pretty unreliable one as such. Tracking companies are interested in tracking <em>you</em>, not a specific device or a specific browsing session. Your IP changes all the time, take your mobile phone as an example: You may be connected to your home WiFi, to your mobile connection, the network at work, … and you will have a different IP in each network. Moreover, these IPs are not even unique to you in most cases: most mobile phone networks share their public IPs to hundreds, sometimes thousands of mobile phones in a process called <a href="https://en.wikipedia.org/wiki/Network_address_translation" target="_blank" rel="noopener">NAT</a>. Tracking companies have to distinguish between all those people - their profiles would be useless otherwise.</p>

<p>Tracking companies have far more advanced methods. One well-known identification method is <em>Cookies</em>, little portions of data in your browser or mobile client. However, since Cookies can easily be altered or removed by users, trackers came up with far more advanced technologies like browser fingerprinting and even running behavioral pattern recognition to uniquely identify users. All these things cannot be influenced or altered in any way by a VPN.</p>

<p>If you are worried about these things, then use a browser with integrated tracking protection features. In Firefox, <a href="https://blog.mozilla.org/firefox/facebook-container-extension/" target="_blank" rel="noopener">Multi-Account Containers and the Facebook Container Extension</a> for example help by locking those tracking sites into their isolated sandbox, so they cannot track you when you are not actively using them. The whole “a VPN makes you browse anonymously” thing is just marketing.</p>

<h3 id="location-leaking">Location leaking</h3>

<p>Another very effective method these VPN marketing people are using is showing your location on their sites. This is very effective at scaring people since those sites hit either your actual hometown or a city nearby. Nobody wants to share their location publicly.</p>

<p>“Your IP address” is not leaking your home address.</p>

<p>You see, your modem is not connected to a cable that leads directly to your ISPs main router. Instead, your internet data is <em>merged together</em> with other peoples data on the way. ISPs split up their network into multiple segments to make their network more manageable, …</p></section></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://schub.wtf/blog/2019/04/08/very-precarious-narrative.html">https://schub.wtf/blog/2019/04/08/very-precarious-narrative.html</a></em></p>]]>
            </description>
            <link>https://schub.wtf/blog/2019/04/08/very-precarious-narrative.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25540314</guid>
            <pubDate>Sat, 26 Dec 2020 00:30:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[“A helpful (Python) cheat sheet, quite long.” ― Brian Kernighan]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25540171">thread link</a>) | @zombiemama
<br/>
December 25, 2020 | https://gto76.github.io/python-cheatsheet/ | <a href="https://web.archive.org/web/*/https://gto76.github.io/python-cheatsheet/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
  <header>
    
    
  </header>

  <span><i></i></span>
   <div><br><div><h2 id="toc"><a href="#toc" name="toc">#</a>Contents</h2><pre><code><strong>ToC</strong> = {
    <strong><span><span>'1. Collections'</span></span></strong>: [<a href="#list">List</a>, <a href="#dictionary">Dictionary</a>, <a href="#set">Set</a>, <a href="#tuple">Tuple</a>, <a href="#range">Range</a>, <a href="#enumerate">Enumerate</a>, <a href="#iterator">Iterator</a>, <a href="#generator">Generator</a>],
    <strong><span><span>'2. Types'</span></span></strong>:       [<a href="#type">Type</a>, <a href="#string">String</a>, <a href="#regex">Regular_Exp</a>, <a href="#format">Format</a>, <a href="#numbers">Numbers</a>, <a href="#combinatorics">Combinatorics</a>, <a href="#datetime">Datetime</a>],
    <strong><span><span>'3. Syntax'</span></span></strong>:      [<a href="#arguments">Args</a>, <a href="#inline">Inline</a>, <a href="#closure">Closure</a>, <a href="#decorator">Decorator</a>, <a href="#class">Class</a>, <a href="#ducktypes">Duck_Type</a>, <a href="#enum">Enum</a>, <a href="#exceptions">Exception</a>],
    <strong><span><span>'4. System'</span></span></strong>:      [<a href="#exit">Exit</a>, <a href="#print">Print</a>, <a href="#input">Input</a>, <a href="#commandlinearguments">Command_Line_Arguments</a>, <a href="#open">Open</a>, <a href="#path">Path</a>, <a href="#oscommands">OS_Commands</a>],
    <strong><span><span>'5. Data'</span></span></strong>:        [<a href="#json">JSON</a>, <a href="#pickle">Pickle</a>, <a href="#csv">CSV</a>, <a href="#sqlite">SQLite</a>, <a href="#bytes">Bytes</a>, <a href="#struct">Struct</a>, <a href="#array">Array</a>, <a href="#memoryview">Memory_View</a>, <a href="#deque">Deque</a>],
    <strong><span><span>'6. Advanced'</span></span></strong>:    [<a href="#threading">Threading</a>, <a href="#operator">Operator</a>, <a href="#introspection">Introspection</a>, <a href="#metaprograming">Metaprograming</a>, <a href="#eval">Eval</a>, <a href="#coroutines">Coroutine</a>],
    <strong><span><span>'7. Libraries'</span></span></strong>:   [<a href="#progressbar">Progress_Bar</a>, <a href="#plot">Plot</a>, <a href="#table">Table</a>, <a href="#curses">Curses</a>, <a href="#logging">Logging</a>, <a href="#scraping">Scraping</a>, <a href="#web">Web</a>, <a href="#profiling">Profile</a>,
                       <a href="#numpy">NumPy</a>, <a href="#image">Image</a>, <a href="#audio">Audio</a>, <a href="#pygame">Games</a>, <a href="#pandas">Data</a>, <a href="#pysimplegui">GUI</a>]
}
</code></pre></div></div>






<div><h2 id="main"><a href="#main" name="main">#</a>Main</h2><pre><code><span>if</span> __name__ == <span>'__main__'</span>:     
    main()
</code></pre></div>

<div><h2 id="list"><a href="#list" name="list">#</a>List</h2><pre><code>&lt;list&gt; = &lt;list&gt;[from_inclusive : to_exclusive : ±step_size]
</code></pre></div>

<pre><code>&lt;list&gt;.append(&lt;el&gt;)            
&lt;list&gt;.extend(&lt;collection&gt;)    
</code></pre>
<pre><code>&lt;list&gt;.sort()
&lt;list&gt;.reverse()
&lt;list&gt; = sorted(&lt;collection&gt;)
&lt;iter&gt; = reversed(&lt;list&gt;)
</code></pre>
<pre><code>sum_of_elements  = sum(&lt;collection&gt;)
elementwise_sum  = [sum(pair) <span>for</span> pair <span>in</span> zip(list_a, list_b)]
sorted_by_second = sorted(&lt;collection&gt;, key=<span>lambda</span> el: el[<span>1</span>])
sorted_by_both   = sorted(&lt;collection&gt;, key=<span>lambda</span> el: (el[<span>1</span>], el[<span>0</span>]))
flatter_list     = list(itertools.chain.from_iterable(&lt;list&gt;))
product_of_elems = functools.reduce(<span>lambda</span> out, el: out * el, &lt;collection&gt;)
list_of_chars    = list(&lt;str&gt;)
</code></pre>
<ul>
<li><strong>Module <a href="#operator">operator</a> provides functions itemgetter() and mul() that offer the same functionality as <a href="#lambda">lambda</a> expressions above.</strong></li>
</ul>
<pre><code>&lt;int&gt; = &lt;list&gt;.count(&lt;el&gt;)     
index = &lt;list&gt;.index(&lt;el&gt;)     
&lt;list&gt;.insert(index, &lt;el&gt;)     
&lt;el&gt; = &lt;list&gt;.pop([index])     
&lt;list&gt;.remove(&lt;el&gt;)            
&lt;list&gt;.clear()                 
</code></pre>
<div><h2 id="dictionary"><a href="#dictionary" name="dictionary">#</a>Dictionary</h2><pre><code>&lt;view&gt; = &lt;dict&gt;.keys()                          
&lt;view&gt; = &lt;dict&gt;.values()                        
&lt;view&gt; = &lt;dict&gt;.items()                         
</code></pre></div>

<pre><code>value  = &lt;dict&gt;.get(key, default=<span>None</span>)          
value  = &lt;dict&gt;.setdefault(key, default=<span>None</span>)   
&lt;dict&gt; = collections.defaultdict(&lt;type&gt;)        
&lt;dict&gt; = collections.defaultdict(<span>lambda</span>: <span>1</span>)     
</code></pre>
<pre><code>&lt;dict&gt; = dict(&lt;collection&gt;)                     
&lt;dict&gt; = dict(zip(keys, values))                
&lt;dict&gt; = dict.fromkeys(keys [, value])          
</code></pre>
<pre><code>&lt;dict&gt;.update(&lt;dict&gt;)                           
value = &lt;dict&gt;.pop(key)                         
{k <span>for</span> k, v <span>in</span> &lt;dict&gt;.items() <span>if</span> v == value}    
{k: v <span>for</span> k, v <span>in</span> &lt;dict&gt;.items() <span>if</span> k <span>in</span> keys}  
</code></pre>
<div><h3 id="counter">Counter</h3><pre><code><span>&gt;&gt;&gt; </span><span>from</span> collections <span>import</span> Counter
<span>&gt;&gt;&gt; </span>colors = [<span>'blue'</span>, <span>'blue'</span>, <span>'blue'</span>, <span>'red'</span>, <span>'red'</span>]
<span>&gt;&gt;&gt; </span>counter = Counter(colors)
<span>&gt;&gt;&gt; </span>counter[<span>'yellow'</span>] += <span>1</span>
Counter({<span>'blue'</span>: <span>3</span>, <span>'red'</span>: <span>2</span>, <span>'yellow'</span>: <span>1</span>})
<span>&gt;&gt;&gt; </span>counter.most_common()[<span>0</span>]
(<span>'blue'</span>, <span>3</span>)
</code></pre></div>



<pre><code>&lt;set&gt;.add(&lt;el&gt;)                                 
&lt;set&gt;.update(&lt;collection&gt; [, ...])              
</code></pre>
<pre><code>&lt;set&gt;  = &lt;set&gt;.union(&lt;coll.&gt;)                   
&lt;set&gt;  = &lt;set&gt;.intersection(&lt;coll.&gt;)            
&lt;set&gt;  = &lt;set&gt;.difference(&lt;coll.&gt;)              
&lt;set&gt;  = &lt;set&gt;.symmetric_difference(&lt;coll.&gt;)    
&lt;bool&gt; = &lt;set&gt;.issubset(&lt;coll.&gt;)                
&lt;bool&gt; = &lt;set&gt;.issuperset(&lt;coll.&gt;)              
</code></pre>
<pre><code>&lt;el&gt; = &lt;set&gt;.pop()                              
&lt;set&gt;.remove(&lt;el&gt;)                              
&lt;set&gt;.discard(&lt;el&gt;)                             
</code></pre>
<div><h3 id="frozenset">Frozen Set</h3><ul>
<li><strong>Is immutable and hashable.</strong></li>
<li><strong>That means it can be used as a key in a dictionary or as an element in a set.</strong></li>
</ul><pre><code>&lt;frozenset&gt; = frozenset(&lt;collection&gt;)
</code></pre></div>


<div><h2 id="tuple"><a href="#tuple" name="tuple">#</a>Tuple</h2><p><strong>Tuple is an immutable and hashable list.</strong></p><pre><code>&lt;tuple&gt; = ()
&lt;tuple&gt; = (&lt;el&gt;, )
&lt;tuple&gt; = (&lt;el_1&gt;, &lt;el_2&gt; [, ...])
</code></pre></div>


<div><h3 id="namedtuple">Named Tuple</h3><p><strong>Tuple's subclass with named elements.</strong></p><pre><code><span>&gt;&gt;&gt; </span><span>from</span> collections <span>import</span> namedtuple
<span>&gt;&gt;&gt; </span>Point = namedtuple(<span>'Point'</span>, <span>'x y'</span>)
<span>&gt;&gt;&gt; </span>p = Point(<span>1</span>, y=<span>2</span>)
Point(x=<span>1</span>, y=<span>2</span>)
<span>&gt;&gt;&gt; </span>p[<span>0</span>]
<span>1</span>
<span>&gt;&gt;&gt; </span>p.x
<span>1</span>
<span>&gt;&gt;&gt; </span>getattr(p, <span>'y'</span>)
<span>2</span>
<span>&gt;&gt;&gt; </span>p._fields  
(<span>'x'</span>, <span>'y'</span>)
</code></pre></div>


<div><h2 id="range"><a href="#range" name="range">#</a>Range</h2><pre><code>&lt;range&gt; = range(to_exclusive)
&lt;range&gt; = range(from_inclusive, to_exclusive)
&lt;range&gt; = range(from_inclusive, to_exclusive, ±step_size)
</code></pre></div>

<pre><code>from_inclusive = &lt;range&gt;.start
to_exclusive   = &lt;range&gt;.stop
</code></pre>
<div><h2 id="enumerate"><a href="#enumerate" name="enumerate">#</a>Enumerate</h2><pre><code><span>for</span> i, el <span>in</span> enumerate(&lt;collection&gt; [, i_start]):
    ...
</code></pre></div>

<div><h2 id="iterator"><a href="#iterator" name="iterator">#</a>Iterator</h2><pre><code>&lt;iter&gt; = iter(&lt;collection&gt;)                 
&lt;iter&gt; = iter(&lt;function&gt;, to_exclusive)     
&lt;el&gt;   = next(&lt;iter&gt; [, default])           
&lt;list&gt; = list(&lt;iter&gt;)                       
</code></pre></div>

<div><h3 id="itertools">Itertools</h3><pre><code><span>from</span> itertools <span>import</span> count, repeat, cycle, chain, islice
</code></pre></div>

<pre><code>&lt;iter&gt; = count(start=<span>0</span>, step=<span>1</span>)             
&lt;iter&gt; = repeat(&lt;el&gt; [, times])             
&lt;iter&gt; = cycle(&lt;collection&gt;)                
</code></pre>
<pre><code>&lt;iter&gt; = chain(&lt;coll_1&gt;, &lt;coll_2&gt; [, ...])  
&lt;iter&gt; = chain.from_iterable(&lt;collection&gt;)  
</code></pre>
<pre><code>&lt;iter&gt; = islice(&lt;coll&gt;, to_exclusive)       
&lt;iter&gt; = islice(&lt;coll&gt;, from_inclusive, …)  
</code></pre>
<div><h2 id="generator"><a href="#generator" name="generator">#</a>Generator</h2><ul>
<li><strong>Any function that contains a yield statement returns a generator.</strong></li>
<li><strong>Generators and iterators are interchangeable.</strong></li>
</ul><pre><code><span><span>def</span> <span>count</span><span>(start, step)</span>:</span>
    <span>while</span> <span>True</span>:
        <span>yield</span> start
        start += step
</code></pre></div>


<pre><code><span>&gt;&gt;&gt; </span>counter = count(<span>10</span>, <span>2</span>)
<span>&gt;&gt;&gt; </span>next(counter), next(counter), next(counter)
(<span>10</span>, <span>12</span>, <span>14</span>)
</code></pre>
<div><h2 id="type"><a href="#type" name="type">#</a>Type</h2><ul>
<li><strong>Everything is an object.</strong></li>
<li><strong>Every object has a type.</strong></li>
<li><strong>Type and class are synonymous.</strong></li>
</ul><pre><code>&lt;type&gt; = type(&lt;el&gt;)                          
&lt;bool&gt; = isinstance(&lt;el&gt;, &lt;type&gt;)            
</code></pre></div>


<pre><code><span>&gt;&gt;&gt; </span>type(<span>'a'</span>), <span>'a'</span>.__class__, str
(&lt;<span><span>class</span> '<span>str</span>'&gt;, &lt;<span>class</span> '<span>str</span>'&gt;, &lt;<span>class</span> '<span>str</span>'&gt;)
</span></code></pre>
<div><h4 id="sometypesdonothavebuiltinnamessotheymustbeimported">Some types do not have built-in names, so they must be imported:</h4><pre><code><span>from</span> types <span>import</span> FunctionType, MethodType, LambdaType, GeneratorType
</code></pre></div>

<div><h3 id="abstractbaseclasses">Abstract Base Classes</h3><p><strong>Each abstract base class specifies a set of virtual subclasses. These classes are then recognized by isinstance() and issubclass() as subclasses of the ABC, although they are really not. ABC can also manually decide whether or not a specific class is its virtual subclass, usually based on which methods the class has implemented (Collection, Iterable).</strong></p><pre><code><span>&gt;&gt;&gt; </span><span>from</span> collections.abc <span>import</span> Sequence, Collection, Iterable
<span>&gt;&gt;&gt; </span>isinstance([<span>1</span>, <span>2</span>, <span>3</span>], Iterable)
<span>True</span>
</code></pre></div>


<pre><code>┏━━━━━━━━━━━━━━━━━━┯━━━━━━━━━━━━┯━━━━━━━━━━━━┯━━━━━━━━━━━━┓
┃                  │  Sequence  │ Collection │  Iterable  ┃
┠──────────────────┼────────────┼────────────┼────────────┨
┃ list, range, str │     ✓      │     ✓      │     ✓      ┃
┃ dict, set        │            │     ✓      │     ✓      ┃
┃ iter             │            │            │     ✓      ┃
┗━━━━━━━━━━━━━━━━━━┷━━━━━━━━━━━━┷━━━━━━━━━━━━┷━━━━━━━━━━━━┛
</code></pre>
<pre><code><span>&gt;&gt;&gt; </span><span>from</span> numbers <span>import</span> Integral, Rational, Real, Complex, Number
<span>&gt;&gt;&gt; </span>isinstance(<span>123</span>, Number)
<span>True</span>
</code></pre>
<pre><code>┏━━━━━━━━━━━━━━━━━━━━┯━━━━━━━━━━┯━━━━━━━━━━┯━━━━━━━━━━┯━━━━━━━━━━┯━━━━━━━━━━┓
┃                    │ Integral │ Rational │   Real   │ Complex  │  Number  ┃
┠────────────────────┼──────────┼──────────┼──────────┼──────────┼──────────┨
┃ int                │    ✓     │    ✓     │    ✓     │    ✓     │    ✓     ┃
┃ fractions.Fraction │          │    ✓     │    ✓     │    ✓     │    ✓     ┃
┃ float              │          │          │    ✓     │    ✓     │    ✓     ┃
┃ complex            │          │          │          │    ✓     │    ✓     ┃
┃ decimal.Decimal    │          │          │          │          │    ✓     ┃
┗━━━━━━━━━━━━━━━━━━━━┷━━━━━━━━━━┷━━━━━━━━━━┷━━━━━━━━━━┷━━━━━━━━━━┷━━━━━━━━━━┛
</code></pre>
<div><h2 id="string"><a href="#string" name="string">#</a>String</h2><pre><code>&lt;str&gt;  = &lt;str&gt;.strip()                       
&lt;str&gt;  = &lt;str&gt;.strip(<span>'&lt;chars&gt;'</span>)              
</code></pre></div>

<pre><code>&lt;list&gt; = &lt;str&gt;.split()                       
&lt;list&gt; = &lt;str&gt;.split(sep=<span>None</span>, maxsplit=<span>-1</span>)  
&lt;list&gt; = &lt;str&gt;.splitlines(keepends=<span>False</span>)    
&lt;str&gt;  = &lt;str&gt;.join(&lt;coll_of_strings&gt;)       
</code></pre>
<pre><code>&lt;bool&gt; = &lt;sub_str&gt; <span>in</span> &lt;str&gt;                  
&lt;bool&gt; = &lt;str&gt;.startswith(&lt;sub_str&gt;)         
&lt;bool&gt; = &lt;str&gt;.endswith(&lt;sub_str&gt;)           
&lt;int&gt;  = &lt;str&gt;.find(&lt;sub_str&gt;)               
&lt;int&gt;  = &lt;str&gt;.index(&lt;sub_str&gt;)              
</code></pre>
<pre><code>&lt;str&gt;  = &lt;str&gt;.replace(old, new [, count])   
&lt;str&gt;  = &lt;str&gt;.translate(&lt;table&gt;)            
</code></pre>
<pre><code>&lt;str&gt;  = chr(&lt;int&gt;)                          
&lt;int&gt;  = ord(&lt;str&gt;)                          
</code></pre>
<ul>
<li><strong>Also: <code><span>'lstrip()'</span></code>, <code><span>'rstrip()'</span></code>.</strong></li>
<li><strong>Also: <code><span>'lower()'</span></code>, <code><span>'upper()'</span></code>, <code><span>'capitalize()'</span></code> and <code><span>'title()'</span></code>.</strong></li>
</ul>
<div><h3 id="propertymethods">Property Methods</h3><pre><code>┏━━━━━━━━━━━━━━━┯━━━━━━━━━━┯━━━━━━━━━━┯━━━━━━━━━━┯━━━━━━━━━━┯━━━━━━━━━━┓
┃               │ [ !#$%…] │ [a-zA-Z] │  [¼½¾]   │  [²³¹]   │  [0-9]   ┃
┠───────────────┼──────────┼──────────┼──────────┼──────────┼──────────┨
┃ isprintable() │    ✓     │    ✓     │    ✓     │    ✓     │    ✓     ┃
┃ isalnum()     │          │    ✓     │    ✓     │    ✓     │    ✓     ┃
┃ isnumeric()   │          │          │    ✓     │    ✓     │    ✓     ┃
┃ isdigit()     │          │          │          │    ✓     │    ✓     ┃
┃ isdecimal()   │          │          │          │          │    ✓     ┃
┗━━━━━━━━━━━━━━━┷━━━━━━━━━━┷━━━━━━━━━━┷━━━━━━━━━━┷━━━━━━━━━━┷━━━━━━━━━━┛
</code></pre></div>

<ul>
<li><strong>Also: <code><span>'isspace()'</span></code> checks for <code><span>'[ \t\n\r\f\v…]'</span></code>.</strong></li>
</ul>
<div><h2 id="regex"><a href="#regex" name="regex">#</a>Regex</h2><pre><code><span>import</span> re
&lt;str&gt;   = re.sub(&lt;regex&gt;, new, text, count=<span>0</span>)  
&lt;list&gt;  = re.findall(&lt;regex&gt;, text)            
&lt;list&gt;  = re.split(&lt;regex&gt;, text, maxsplit=<span>0</span>)  
&lt;Match&gt; = re.search(&lt;regex&gt;, text)             
&lt;Match&gt; = re.match(&lt;regex&gt;, text)              
&lt;iter&gt;  = re.finditer(&lt;regex&gt;, text)           
</code></pre></div>

<ul>
<li><strong>Search() and match() return None if they can't find a match.</strong></li>
<li><strong>Argument <code><span>'flags=re.IGNORECASE'</span></code> can be used with all functions.</strong></li>
<li><strong>Argument <code><span>'flags=re.MULTILINE'</span></code> makes <code><span>'^'</span></code> and <code><span>'$'</span></code> match the start/end of each line.</strong></li>
<li><strong>Argument <code><span>'flags=re.DOTALL'</span></code> makes dot also accept the <code><span>'\n'</span></code>.</strong></li>
<li><strong>Use <code><span>r'\1'</span></code> or <code><span>'\\1'</span></code> for backreference.</strong></li>
<li><strong>Add <code><span>'?'</span></code> after an operator to make it non-greedy.</strong></li>
</ul>
<div><h3 id="matchobject">Match Object</h3><pre><code>&lt;str&gt;   = &lt;Match&gt;.group()                      
&lt;str&gt;   = &lt;Match&gt;.group(<span>1</span>)                     
&lt;tuple&gt; = &lt;Match&gt;.groups()                     
&lt;int&gt;   = &lt;Match&gt;.start()                      
&lt;int&gt;   = &lt;Match&gt;.end()                        
</code></pre></div>

<div><h3 id="specialsequences">Special Sequences</h3><ul>
<li><strong>By default digits, alphanumerics and whitespaces from all alphabets are matched, unless <code><span>'flags=re.ASCII'</span></code> argument is used.</strong></li>
<li><strong>Use a capital letter for negation.</strong></li>
</ul><pre><code><span>'\d'</span> == <span>'[0-9]'</span>                                
<span>'\w'</span> == <span>'[a-zA-Z0-9_]'</span>                         
<span>'\s'</span> == <span>'[ \t\n\r\f\v]'</span>                        
</code></pre></div>


<div><h2 id="format"><a href="#format" name="format">#</a>Format</h2><pre><code>&lt;str&gt; = <span>f'<span>{&lt;el_1&gt;}</span>, <span>{&lt;el_2&gt;}</span>'</span>
&lt;str&gt; = <span>'{}, {}'</span>.format(&lt;el_1&gt;, &lt;el_2&gt;)
</code></pre></div>

<div><h3 id="attributes">Attributes</h3><pre><code><span>&gt;&gt;&gt; </span><span>from</span> collections <span>import</span> namedtuple
<span>&gt;&gt;&gt; </span>Person = namedtuple(<span>'Person'</span>, <span>'name height'</span>)
<span>&gt;&gt;&gt; </span>person = Person(<span>'Jean-Luc'</span>, <span>187</span>)
<span>&gt;&gt;&gt; </span><span>f'<span>{person.height}</span>'</span>
<span>'187'</span>
<span>&gt;&gt;&gt; </span><span>'{p.height}'</span>.format(p=pers…</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://gto76.github.io/python-cheatsheet/">https://gto76.github.io/python-cheatsheet/</a></em></p>]]>
            </description>
            <link>https://gto76.github.io/python-cheatsheet/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25540171</guid>
            <pubDate>Sat, 26 Dec 2020 00:03:30 GMT</pubDate>
        </item>
    </channel>
</rss>
