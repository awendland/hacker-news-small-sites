<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Tue, 01 Dec 2020 21:09:12 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Tue, 01 Dec 2020 21:09:12 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[The Most Unfashionable Form of Advertising?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25252447">thread link</a>) | @kervokian
<br/>
November 30, 2020 | https://davedye.com/2020/11/23/the-most-unfashionable-form-of-advertising/ | <a href="https://web.archive.org/web/*/https://davedye.com/2020/11/23/the-most-unfashionable-form-of-advertising/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-49165">
  <div>

    
    <div>

      <div>

        

        <div>
                      <p><span><strong>What was the last product demo you saw?<br>
Not on Facebook, Twitter or Instagram, they’re all over those, but on tv, billboards or press (does press still exist?).<br>
You just don’t see agencies doing them anymore.<br>
Odd, because, and I hope I’m not giving away any trade secrets here, the goal of most advertising is to persuade people that the product featured is good.<br>
Ideally, REALLY good.<br>
So showing it in action, performing well, seems like it might be a good way to go?<br>
Because most purchasing decisions are based on what a product does. But sometimes in ad agencies, we can get too distracted with our own fancy theories and philosophies.<br>
Not just in agencies, sometimes when I teach I’ll review work that, although clever, doesn’t feel like it’ll sell anything.<br>
It doesn’t feel like it’s trying to sell anything.<br>
Would you buy that cereal because you’re told it’s what the cool folks eat?<br>
Or a computer because the company that makes it has some very progressive social policies?<br>
Maybe.<br>
But most wouldn’t, they want to know what’s in it for them.<br>
My advice when such a situation arises is always the same; imagine you’re with a friend, face to face, how would you persuade them to buy this product?.<br>
They know they can’t waffle and bullshit friends, so they stop trying. Instead, they start thinking about why their friend may actually part with money for this product.<br>
Focussing on what it does.<br>
How it may help them.<br>
The ideas often become less grandiose and more like common-sense advice.<br>
Which is more persuasive.<br>
As the saying goes – Don’t tell me you’re funny, make me laugh.<br>
So why are we producing less product demos?<br>
Less products to warrant that type of advertising today?<br>
Would that kind of <em>‘hard sell’</em> advertising reflect badly on a brand today? Or that it would reflect badly on us?<br>
(Answers on a postcard, etc, etc.)</strong></span></p>
<p><span>p.s. &nbsp;I couldn’t help wondering if the British Government spent less money telling people what to do about Covid-19 and more on demonstrating the benefits of wearing masks and washing hands, the situation may be a bit better?</span></p>
<p><span>E.g. 1. Masks.</span></p>

<p><span><em>E.g. 2. Soap.<br>
</em></span></p>


<p><span>When I gathered together this bunch, I didn’t look through awards sites or annuals, I just tried to remember product demonstrations, ones that had stuck with me.</span><br>
<span>Consequently, there are some ads in here that I couldn’t tell you when or where they were done, like Tonka and the nail varnish ad.</span><br>
<span>But having collated all of this ‘unfashionable’ work, it dawned on me that most of it was created by the most fashionable agencies.<br>
At least, the most fashionable in their of the day.<br>
DDB, PKL, WRG, GGT, BBH, WCRS, DDB, AMV, APPLE.<br>
Written by the likes of George Lois, Roy Grace, Dave Trott, David Abbott, John Webster, Ron Collins.<br>
Maybe they knew something we don’t?</span></p>
<p><span><a href="https://davedye.com/2020/11/23/the-most-unfashionable-form-of-advertising/1-waterheinzddb/" rel="attachment wp-att-49166"><img data-attachment-id="49166" data-permalink="https://davedye.com/2020/11/23/the-most-unfashionable-form-of-advertising/1-waterheinzddb/" data-orig-file="https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/1.-WaterHeinzDDB.jpg?fit=1186%2C1653&amp;ssl=1" data-orig-size="1186,1653" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="1. Water:Heinz:DDB" data-image-description="" data-medium-file="https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/1.-WaterHeinzDDB.jpg?fit=215%2C300&amp;ssl=1" data-large-file="https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/1.-WaterHeinzDDB.jpg?fit=640%2C892&amp;ssl=1" loading="lazy" src="https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/1.-WaterHeinzDDB.jpg?resize=640%2C892&amp;ssl=1" alt="" width="640" height="892" srcset="https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/1.-WaterHeinzDDB.jpg?w=1186&amp;ssl=1 1186w, https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/1.-WaterHeinzDDB.jpg?resize=215%2C300&amp;ssl=1 215w, https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/1.-WaterHeinzDDB.jpg?resize=735%2C1024&amp;ssl=1 735w, https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/1.-WaterHeinzDDB.jpg?resize=768%2C1070&amp;ssl=1 768w, https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/1.-WaterHeinzDDB.jpg?resize=1102%2C1536&amp;ssl=1 1102w, https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/1.-WaterHeinzDDB.jpg?resize=287%2C400&amp;ssl=1 287w, https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/1.-WaterHeinzDDB.jpg?resize=750%2C1045&amp;ssl=1 750w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1"></a> <a href="https://davedye.com/2020/11/23/the-most-unfashionable-form-of-advertising/2-picasso-xerox-george-lois-01/" rel="attachment wp-att-49167"><img data-attachment-id="49167" data-permalink="https://davedye.com/2020/11/23/the-most-unfashionable-form-of-advertising/2-picasso-xerox-george-lois-01/" data-orig-file="https://i1.wp.com/davedye.com/wp-content/uploads/2020/11/2.-Picasso-Xerox-George-Lois-01.jpg?fit=2551%2C1616&amp;ssl=1" data-orig-size="2551,1616" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2. Picasso-Xerox-George Lois-01" data-image-description="" data-medium-file="https://i1.wp.com/davedye.com/wp-content/uploads/2020/11/2.-Picasso-Xerox-George-Lois-01.jpg?fit=300%2C190&amp;ssl=1" data-large-file="https://i1.wp.com/davedye.com/wp-content/uploads/2020/11/2.-Picasso-Xerox-George-Lois-01.jpg?fit=640%2C406&amp;ssl=1" loading="lazy" src="https://i1.wp.com/davedye.com/wp-content/uploads/2020/11/2.-Picasso-Xerox-George-Lois-01.jpg?resize=640%2C405&amp;ssl=1" alt="" width="640" height="405" srcset="https://i1.wp.com/davedye.com/wp-content/uploads/2020/11/2.-Picasso-Xerox-George-Lois-01.jpg?w=2551&amp;ssl=1 2551w, https://i1.wp.com/davedye.com/wp-content/uploads/2020/11/2.-Picasso-Xerox-George-Lois-01.jpg?resize=300%2C190&amp;ssl=1 300w, https://i1.wp.com/davedye.com/wp-content/uploads/2020/11/2.-Picasso-Xerox-George-Lois-01.jpg?resize=1024%2C649&amp;ssl=1 1024w, https://i1.wp.com/davedye.com/wp-content/uploads/2020/11/2.-Picasso-Xerox-George-Lois-01.jpg?resize=768%2C487&amp;ssl=1 768w, https://i1.wp.com/davedye.com/wp-content/uploads/2020/11/2.-Picasso-Xerox-George-Lois-01.jpg?resize=1536%2C973&amp;ssl=1 1536w, https://i1.wp.com/davedye.com/wp-content/uploads/2020/11/2.-Picasso-Xerox-George-Lois-01.jpg?resize=2048%2C1297&amp;ssl=1 2048w, https://i1.wp.com/davedye.com/wp-content/uploads/2020/11/2.-Picasso-Xerox-George-Lois-01.jpg?resize=631%2C400&amp;ssl=1 631w, https://i1.wp.com/davedye.com/wp-content/uploads/2020/11/2.-Picasso-Xerox-George-Lois-01.jpg?resize=750%2C475&amp;ssl=1 750w, https://i1.wp.com/davedye.com/wp-content/uploads/2020/11/2.-Picasso-Xerox-George-Lois-01.jpg?w=1280&amp;ssl=1 1280w, https://i1.wp.com/davedye.com/wp-content/uploads/2020/11/2.-Picasso-Xerox-George-Lois-01.jpg?w=1920&amp;ssl=1 1920w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1"></a><a href="https://davedye.com/2020/11/23/the-most-unfashionable-form-of-advertising/put-yourgreat-dayddb/" rel="attachment wp-att-49363"><img data-attachment-id="49363" data-permalink="https://davedye.com/2020/11/23/the-most-unfashionable-form-of-advertising/put-yourgreat-dayddb/" data-orig-file="https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/Put-YourGreat-DayDDB.jpg?fit=2311%2C1572&amp;ssl=1" data-orig-size="2311,1572" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="Put Your:Great Day:DDB" data-image-description="" data-medium-file="https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/Put-YourGreat-DayDDB.jpg?fit=300%2C204&amp;ssl=1" data-large-file="https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/Put-YourGreat-DayDDB.jpg?fit=640%2C436&amp;ssl=1" loading="lazy" src="https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/Put-YourGreat-DayDDB.jpg?resize=640%2C435&amp;ssl=1" alt="" width="640" height="435" srcset="https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/Put-YourGreat-DayDDB.jpg?w=2311&amp;ssl=1 2311w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/Put-YourGreat-DayDDB.jpg?resize=300%2C204&amp;ssl=1 300w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/Put-YourGreat-DayDDB.jpg?resize=1024%2C697&amp;ssl=1 1024w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/Put-YourGreat-DayDDB.jpg?resize=768%2C522&amp;ssl=1 768w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/Put-YourGreat-DayDDB.jpg?resize=1536%2C1045&amp;ssl=1 1536w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/Put-YourGreat-DayDDB.jpg?resize=2048%2C1393&amp;ssl=1 2048w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/Put-YourGreat-DayDDB.jpg?resize=588%2C400&amp;ssl=1 588w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/Put-YourGreat-DayDDB.jpg?resize=750%2C510&amp;ssl=1 750w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/Put-YourGreat-DayDDB.jpg?w=1280&amp;ssl=1 1280w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/Put-YourGreat-DayDDB.jpg?w=1920&amp;ssl=1 1920w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1"></a><a href="https://davedye.com/2020/11/23/the-most-unfashionable-form-of-advertising/dear-american-tourister-youll-never-american-tourister-ddb-ny/" rel="attachment wp-att-49364"><img data-attachment-id="49364" data-permalink="https://davedye.com/2020/11/23/the-most-unfashionable-form-of-advertising/dear-american-tourister-youll-never-american-tourister-ddb-ny/" data-orig-file="https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/Dear-American-Tourister-Youll-Never-American-Tourister-DDB-NY.png?fit=512%2C705&amp;ssl=1" data-orig-size="512,705" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="‘Dear American Tourister, You’ll Never’ American Tourister, DDB NY" data-image-description="" data-medium-file="https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/Dear-American-Tourister-Youll-Never-American-Tourister-DDB-NY.png?fit=218%2C300&amp;ssl=1" data-large-file="https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/Dear-American-Tourister-Youll-Never-American-Tourister-DDB-NY.png?fit=512%2C705&amp;ssl=1" loading="lazy" src="https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/Dear-American-Tourister-Youll-Never-American-Tourister-DDB-NY.png?resize=640%2C881&amp;ssl=1" alt="" width="640" height="881" srcset="https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/Dear-American-Tourister-Youll-Never-American-Tourister-DDB-NY.png?w=512&amp;ssl=1 512w, https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/Dear-American-Tourister-Youll-Never-American-Tourister-DDB-NY.png?resize=218%2C300&amp;ssl=1 218w, https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/Dear-American-Tourister-Youll-Never-American-Tourister-DDB-NY.png?resize=290%2C400&amp;ssl=1 290w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1"></a><a href="https://davedye.com/2020/11/23/the-most-unfashionable-form-of-advertising/4-this-penparkercdptony-brignull/" rel="attachment wp-att-49169"><img data-attachment-id="49169" data-permalink="https://davedye.com/2020/11/23/the-most-unfashionable-form-of-advertising/4-this-penparkercdptony-brignull/" data-orig-file="https://i1.wp.com/davedye.com/wp-content/uploads/2020/11/4.-This-PenParkerCDPTony-Brignull.jpg?fit=2809%2C3475&amp;ssl=1" data-orig-size="2809,3475" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="4. This Pen:Parker:CDPTony Brignull" data-image-description="" data-medium-file="https://i1.wp.com/davedye.com/wp-content/uploads/2020/11/4.-This-PenParkerCDPTony-Brignull.jpg?fit=243%2C300&amp;ssl=1" data-large-file="https://i1.wp.com/davedye.com/wp-content/uploads/2020/11/4.-This-PenParkerCDPTony-Brignull.jpg?fit=640%2C791&amp;ssl=1" loading="lazy" src="https://i1.wp.com/davedye.com/wp-content/uploads/2020/11/4.-This-PenParkerCDPTony-Brignull.jpg?resize=640%2C792&amp;ssl=1" alt="" width="640" height="792" srcset="https://i1.wp.com/davedye.com/wp-content/uploads/2020/11/4.-This-PenParkerCDPTony-Brignull.jpg?w=2809&amp;ssl=1 2809w, https://i1.wp.com/davedye.com/wp-content/uploads/2020/11/4.-This-PenParkerCDPTony-Brignull.jpg?resize=243%2C300&amp;ssl=1 243w, https://i1.wp.com/davedye.com/wp-content/uploads/2020/11/4.-This-PenParkerCDPTony-Brignull.jpg?resize=828%2C1024&amp;ssl=1 828w, https://i1.wp.com/davedye.com/wp-content/uploads/2020/11/4.-This-PenParkerCDPTony-Brignull.jpg?resize=768%2C950&amp;ssl=1 768w, https://i1.wp.com/davedye.com/wp-content/uploads/2020/11/4.-This-PenParkerCDPTony-Brignull.jpg?resize=1242%2C1536&amp;ssl=1 1242w, https://i1.wp.com/davedye.com/wp-content/uploads/2020/11/4.-This-PenParkerCDPTony-Brignull.jpg?resize=1655%2C2048&amp;ssl=1 1655w, https://i1.wp.com/davedye.com/wp-content/uploads/2020/11/4.-This-PenParkerCDPTony-Brignull.jpg?resize=323%2C400&amp;ssl=1 323w, https://i1.wp.com/davedye.com/wp-content/uploads/2020/11/4.-This-PenParkerCDPTony-Brignull.jpg?resize=750%2C928&amp;ssl=1 750w, https://i1.wp.com/davedye.com/wp-content/uploads/2020/11/4.-This-PenParkerCDPTony-Brignull.jpg?resize=2048%2C2534&amp;ssl=1 2048w, https://i1.wp.com/davedye.com/wp-content/uploads/2020/11/4.-This-PenParkerCDPTony-Brignull.jpg?w=1920&amp;ssl=1 1920w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1"></a> <a href="https://davedye.com/2020/11/23/the-most-unfashionable-form-of-advertising/5-to-be-onvolkswagenbarbara-nokesddb/" rel="attachment wp-att-49170"><img data-attachment-id="49170" data-permalink="https://davedye.com/2020/11/23/the-most-unfashionable-form-of-advertising/5-to-be-onvolkswagenbarbara-nokesddb/" data-orig-file="https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/5.-To-Be-OnVolkswagenBarbara-NokesDDB.jpg?fit=1961%2C2836&amp;ssl=1" data-orig-size="1961,2836" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="5. To Be On:Volkswagen:Barbara Nokes:DDB" data-image-description="" data-medium-file="https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/5.-To-Be-OnVolkswagenBarbara-NokesDDB.jpg?fit=207%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/5.-To-Be-OnVolkswagenBarbara-NokesDDB.jpg?fit=640%2C926&amp;ssl=1" loading="lazy" src="https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/5.-To-Be-OnVolkswagenBarbara-NokesDDB.jpg?resize=640%2C926&amp;ssl=1" alt="" width="640" height="926" srcset="https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/5.-To-Be-OnVolkswagenBarbara-NokesDDB.jpg?w=1961&amp;ssl=1 1961w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/5.-To-Be-OnVolkswagenBarbara-NokesDDB.jpg?resize=207%2C300&amp;ssl=1 207w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/5.-To-Be-OnVolkswagenBarbara-NokesDDB.jpg?resize=708%2C1024&amp;ssl=1 708w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/5.-To-Be-OnVolkswagenBarbara-NokesDDB.jpg?resize=768%2C1111&amp;ssl=1 768w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/5.-To-Be-OnVolkswagenBarbara-NokesDDB.jpg?resize=1062%2C1536&amp;ssl=1 1062w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/5.-To-Be-OnVolkswagenBarbara-NokesDDB.jpg?resize=1416%2C2048&amp;ssl=1 1416w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/5.-To-Be-OnVolkswagenBarbara-NokesDDB.jpg?resize=277%2C400&amp;ssl=1 277w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/5.-To-Be-OnVolkswagenBarbara-NokesDDB.jpg?resize=750%2C1085&amp;ssl=1 750w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/5.-To-Be-OnVolkswagenBarbara-NokesDDB.jpg?w=1280&amp;ssl=1 1280w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1"></a> <a href="https://davedye.com/2020/11/23/the-most-unfashionable-form-of-advertising/6-gold-cupduluxfcb/" rel="attachment wp-att-49171"><img data-attachment-id="49171" data-permalink="https://davedye.com/2020/11/23/the-most-unfashionable-form-of-advertising/6-gold-cupduluxfcb/" data-orig-file="https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/6.-Gold-CupDuluxFCB.jpg?fit=3570%2C2326&amp;ssl=1" data-orig-size="3570,2326" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="6. Gold Cup:Dulux:FCB" data-image-description="" data-medium-file="https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/6.-Gold-CupDuluxFCB.jpg?fit=300%2C195&amp;ssl=1" data-large-file="https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/6.-Gold-CupDuluxFCB.jpg?fit=640%2C417&amp;ssl=1" loading="lazy" src="https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/6.-Gold-CupDuluxFCB.jpg?resize=640%2C417&amp;ssl=1" alt="" width="640" height="417" srcset="https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/6.-Gold-CupDuluxFCB.jpg?w=3570&amp;ssl=1 3570w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/6.-Gold-CupDuluxFCB.jpg?resize=300%2C195&amp;ssl=1 300w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/6.-Gold-CupDuluxFCB.jpg?resize=1024%2C667&amp;ssl=1 1024w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/6.-Gold-CupDuluxFCB.jpg?resize=768%2C500&amp;ssl=1 768w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/6.-Gold-CupDuluxFCB.jpg?resize=1536%2C1001&amp;ssl=1 1536w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/6.-Gold-CupDuluxFCB.jpg?resize=2048%2C1334&amp;ssl=1 2048w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/6.-Gold-CupDuluxFCB.jpg?resize=614%2C400&amp;ssl=1 614w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/6.-Gold-CupDuluxFCB.jpg?resize=750%2C489&amp;ssl=1 750w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/6.-Gold-CupDuluxFCB.jpg?w=1280&amp;ssl=1 1280w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/6.-Gold-CupDuluxFCB.jpg?w=1920&amp;ssl=1 1920w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1"></a> <a href="https://davedye.com/2020/11/23/the-most-unfashionable-form-of-advertising/7-try-yourbritish-airwaysfcbbarry-smith/" rel="attachment wp-att-49172"><img data-attachment-id="49172" data-permalink="https://davedye.com/2020/11/23/the-most-unfashionable-form-of-advertising/7-try-yourbritish-airwaysfcbbarry-smith/" data-orig-file="https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/7.-Try-YourBritish-AirwaysFCBBarry-Smith.jpg?fit=2139%2C1561&amp;ssl=1" data-orig-size="2139,1561" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="7. Try Your:British Airways:FCB:Barry Smith*" data-image-description="" data-medium-file="https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/7.-Try-YourBritish-AirwaysFCBBarry-Smith.jpg?fit=300%2C219&amp;ssl=1" data-large-file="https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/7.-Try-YourBritish-AirwaysFCBBarry-Smith.jpg?fit=640%2C467&amp;ssl=1" loading="lazy" src="https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/7.-Try-YourBritish-AirwaysFCBBarry-Smith.jpg?resize=640%2C467&amp;ssl=1" alt="" width="640" height="467" srcset="https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/7.-Try-YourBritish-AirwaysFCBBarry-Smith.jpg?w=2139&amp;ssl=1 2139w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/7.-Try-YourBritish-AirwaysFCBBarry-Smith.jpg?resize=300%2C219&amp;ssl=1 300w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/7.-Try-YourBritish-AirwaysFCBBarry-Smith.jpg?resize=1024%2C747&amp;ssl=1 1024w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/7.-Try-YourBritish-AirwaysFCBBarry-Smith.jpg?resize=768%2C560&amp;ssl=1 768w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/7.-Try-YourBritish-AirwaysFCBBarry-Smith.jpg?resize=1536%2C1121&amp;ssl=1 1536w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/7.-Try-YourBritish-AirwaysFCBBarry-Smith.jpg?resize=2048%2C1495&amp;ssl=1 2048w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/7.-Try-YourBritish-AirwaysFCBBarry-Smith.jpg?resize=548%2C400&amp;ssl=1 548w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/7.-Try-YourBritish-AirwaysFCBBarry-Smith.jpg?resize=750%2C547&amp;ssl=1 750w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/7.-Try-YourBritish-AirwaysFCBBarry-Smith.jpg?w=1280&amp;ssl=1 1280w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/7.-Try-YourBritish-AirwaysFCBBarry-Smith.jpg?w=1920&amp;ssl=1 1920w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1"></a> <a href="https://davedye.com/2020/11/23/the-most-unfashionable-form-of-advertising/8-this-muchparkerrichard-fostercdp/" rel="attachment wp-att-49173"><img data-attachment-id="49173" data-permalink="https://davedye.com/2020/11/23/the-most-unfashionable-form-of-advertising/8-this-muchparkerrichard-fostercdp/" data-orig-file="https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/8.-This-MuchParkerRichard-FosterCDP.jpg?fit=8902%2C4471&amp;ssl=1" data-orig-size="8902,4471" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="8. This Much:Parker:Richard Foster:CDP" data-image-description="" data-medium-file="https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/8.-This-MuchParkerRichard-FosterCDP.jpg?fit=300%2C151&amp;ssl=1" data-large-file="https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/8.-This-MuchParkerRichard-FosterCDP.jpg?fit=640%2C321&amp;ssl=1" loading="lazy" src="https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/8.-This-MuchParkerRichard-FosterCDP.jpg?resize=640%2C321&amp;ssl=1" alt="" width="640" height="321" srcset="https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/8.-This-MuchParkerRichard-FosterCDP.jpg?w=8902&amp;ssl=1 8902w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/8.-This-MuchParkerRichard-FosterCDP.jpg?resize=300%2C151&amp;ssl=1 300w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/8.-This-MuchParkerRichard-FosterCDP.jpg?resize=1024%2C514&amp;ssl=1 1024w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/8.-This-MuchParkerRichard-FosterCDP.jpg?resize=768%2C386&amp;ssl=1 768w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/8.-This-MuchParkerRichard-FosterCDP.jpg?resize=1536%2C771&amp;ssl=1 1536w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/8.-This-MuchParkerRichard-FosterCDP.jpg?resize=2048%2C1029&amp;ssl=1 2048w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/8.-This-MuchParkerRichard-FosterCDP.jpg?resize=796%2C400&amp;ssl=1 796w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/8.-This-MuchParkerRichard-FosterCDP.jpg?resize=750%2C377&amp;ssl=1 750w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/8.-This-MuchParkerRichard-FosterCDP.jpg?w=1280&amp;ssl=1 1280w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/8.-This-MuchParkerRichard-FosterCDP.jpg?w=1920&amp;ssl=1 1920w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1"></a> <a href="https://davedye.com/2020/11/23/the-most-unfashionable-form-of-advertising/9-this-isthe-globebbdo/" rel="attachment wp-att-49174"><img data-attachment-id="49174" data-permalink="https://davedye.com/2020/11/23/the-most-unfashionable-form-of-advertising/9-this-isthe-globebbdo/" data-orig-file="https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/9.-This-IsThe-GlobeBBDO.jpg?fit=2082%2C1034&amp;ssl=1" data-orig-size="2082,1034" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="9. This Is:The Globe:BBDO" data-image-description="" data-medium-file="https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/9.-This-IsThe-GlobeBBDO.jpg?fit=300%2C149&amp;ssl=1" data-large-file="https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/9.-This-IsThe-GlobeBBDO.jpg?fit=640%2C318&amp;ssl=1" loading="lazy" src="https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/9.-This-IsThe-GlobeBBDO.jpg?resize=640%2C318&amp;ssl=1" alt="" width="640" height="318" srcset="https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/9.-This-IsThe-GlobeBBDO.jpg?w=2082&amp;ssl=1 2082w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/9.-This-IsThe-GlobeBBDO.jpg?resize=300%2C149&amp;ssl=1 300w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/9.-This-IsThe-GlobeBBDO.jpg?resize=1024%2C509&amp;ssl=1 1024w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/9.-This-IsThe-GlobeBBDO.jpg?resize=768%2C381&amp;ssl=1 768w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/9.-This-IsThe-GlobeBBDO.jpg?resize=1536%2C763&amp;ssl=1 1536w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/9.-This-IsThe-GlobeBBDO.jpg?resize=2048%2C1017&amp;ssl=1 2048w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/9.-This-IsThe-GlobeBBDO.jpg?resize=805%2C400&amp;ssl=1 805w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/9.-This-IsThe-GlobeBBDO.jpg?resize=750%2C372&amp;ssl=1 750w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/9.-This-IsThe-GlobeBBDO.jpg?w=1280&amp;ssl=1 1280w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/9.-This-IsThe-GlobeBBDO.jpg?w=1920&amp;ssl=1 1920w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1"></a> <a href="https://davedye.com/2020/11/23/the-most-unfashionable-form-of-advertising/10-slimvespretbwajohn-knight/" rel="attachment wp-att-49175"><img data-attachment-id="49175" data-permalink="https://davedye.com/2020/11/23/the-most-unfashionable-form-of-advertising/10-slimvespretbwajohn-knight/" data-orig-file="https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/10.-SlimVespreTBWAJohn-Knight.jpg?fit=2235%2C1482&amp;ssl=1" data-orig-size="2235,1482" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="10. Slim:Vespre:TBWA:John Knight" data-image-description="" data-medium-file="https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/10.-SlimVespreTBWAJohn-Knight.jpg?fit=300%2C199&amp;ssl=1" data-large-file="https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/10.-SlimVespreTBWAJohn-Knight.jpg?fit=640%2C424&amp;ssl=1" loading="lazy" src="https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/10.-SlimVespreTBWAJohn-Knight.jpg?resize=640%2C424&amp;ssl=1" alt="" width="640" height="424" srcset="https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/10.-SlimVespreTBWAJohn-Knight.jpg?w=2235&amp;ssl=1 2235w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/10.-SlimVespreTBWAJohn-Knight.jpg?resize=300%2C199&amp;ssl=1 300w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/10.-SlimVespreTBWAJohn-Knight.jpg?resize=1024%2C679&amp;ssl=1 1024w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/10.-SlimVespreTBWAJohn-Knight.jpg?resize=768%2C509&amp;ssl=1 768w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/10.-SlimVespreTBWAJohn-Knight.jpg?resize=1536%2C1019&amp;ssl=1 1536w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/10.-SlimVespreTBWAJohn-Knight.jpg?resize=2048%2C1358&amp;ssl=1 2048w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/10.-SlimVespreTBWAJohn-Knight.jpg?resize=603%2C400&amp;ssl=1 603w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/10.-SlimVespreTBWAJohn-Knight.jpg?resize=750%2C497&amp;ssl=1 750w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/10.-SlimVespreTBWAJohn-Knight.jpg?w=1280&amp;ssl=1 1280w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/10.-SlimVespreTBWAJohn-Knight.jpg?w=1920&amp;ssl=1 1920w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1"></a> <a href="https://davedye.com/2020/11/23/the-most-unfashionable-form-of-advertising/11-if-the-weldingvolvoamvdavid-abbott/" rel="attachment wp-att-49176"><img data-attachment-id="49176" data-permalink="https://davedye.com/2020/11/23/the-most-unfashionable-form-of-advertising/11-if-the-weldingvolvoamvdavid-abbott/" data-orig-file="https://i1.wp.com/davedye.com/wp-content/uploads/2020/11/11.-If-The-WeldingVolvoAMVDavid-Abbott.jpg?fit=5547%2C3382&amp;ssl=1" data-orig-size="5547,3382" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="11. If The Welding:Volvo:AMV:David Abbott" data-image-description="" data-medium-file="https://i1.wp.com/davedye.com/wp-content/uploads/2020/11/11.-If-The-WeldingVolvoAMVDavid-Abbott.jpg?fit=300%2C183&amp;ssl=1" data-large-file="https://i1.wp.com/davedye.com/wp-content/uploads/2020/11/11.-If-The-WeldingVolvoAMVDavid-Abbott.jpg?fit=640%2C390&amp;ssl=1" loading="lazy" src="https://i1.wp.com/davedye.com/wp-content/uploads/2020/11/11.-If-The-WeldingVolvoAMVDavid-Abbott.jpg?resize=640%2C390&amp;ssl=1" alt="" width="640" height="390" srcset="https://i1.wp.com/davedye.com/wp-content/uploads/2020/11/11.-If-The-WeldingVolvoAMVDavid-Abbott.jpg?w=5547&amp;ssl=1 5547w, https://i1.wp.com/davedye.com/wp-content/uploads/2020/11/11.-If-The-WeldingVolvoAMVDavid-Abbott.jpg?resize=300%2C183&amp;ssl=1 300w, https://i1.wp.com/davedye.com/wp-content/uploads/2020/11/11.-If-The-WeldingVolvoAMVDavid-Abbott.jpg?resize=1024%2C624&amp;ssl=1 1024w, https://i1.wp.com/davedye.com/wp-content/uploads/2020/11/11.-If-The-WeldingVolvoAMVDavid-Abbott.jpg?resize=768%2C468&amp;ssl=1 768w, https://i1.wp.com/davedye.com/wp-content/uploads/2020/11/11.-If-The-WeldingVolvoAMVDavid-Abbott.jpg?resize=1536%2C936&amp;ssl=1 1536w, https://i1.wp.com/davedye.com/wp-content/uploads/2020/11/11.-If-The-WeldingVolvoAMVDavid-Abbott.jpg?resize=2048%2C1249&amp;ssl=1 2048w, https://i1.wp.com/davedye.com/wp-content/uploads/2020/11/11.-If-The-WeldingVolvoAMVDavid-Abbott.jpg?resize=656%2C400&amp;ssl=1 656w, https://i1.wp.com/davedye.com/wp-content/uploads/2020/11/11.-If-The-WeldingVolvoAMVDavid-Abbott.jpg?resize=750%2C457&amp;ssl=1 750w, https://i1.wp.com/davedye.com/wp-content/uploads/2020/11/11.-If-The-WeldingVolvoAMVDavid-Abbott.jpg?w=1280&amp;ssl=1 1280w, https://i1.wp.com/davedye.com/wp-content/uploads/2020/11/11.-If-The-WeldingVolvoAMVDavid-Abbott.jpg?w=1920&amp;ssl=1 1920w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1"></a> <a href="https://davedye.com/2020/11/23/the-most-unfashionable-form-of-advertising/12-no-wondercitroencolmans/" rel="attachment wp-att-49177"><img data-attachment-id="49177" data-permalink="https://davedye.com/2020/11/23/the-most-unfashionable-form-of-advertising/12-no-wondercitroencolmans/" data-orig-file="https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/12.-No-WonderCitroenColmans.jpg?fit=2099%2C2943&amp;ssl=1" data-orig-size="2099,2943" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="12. No Wonder:Citroen:Colman’s" data-image-description="" data-medium-file="https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/12.-No-WonderCitroenColmans.jpg?fit=214%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/12.-No-WonderCitroenColmans.jpg?fit=640%2C898&amp;ssl=1" loading="lazy" src="https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/12.-No-WonderCitroenColmans.jpg?resize=640%2C897&amp;ssl=1" alt="" width="640" height="897" srcset="https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/12.-No-WonderCitroenColmans.jpg?w=2099&amp;ssl=1 2099w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/12.-No-WonderCitroenColmans.jpg?resize=214%2C300&amp;ssl=1 214w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/12.-No-WonderCitroenColmans.jpg?resize=730%2C1024&amp;ssl=1 730w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/12.-No-WonderCitroenColmans.jpg?resize=768%2C1077&amp;ssl=1 768w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/12.-No-WonderCitroenColmans.jpg?resize=1096%2C1536&amp;ssl=1 1096w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/12.-No-WonderCitroenColmans.jpg?resize=1461%2C2048&amp;ssl=1 1461w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/12.-No-WonderCitroenColmans.jpg?resize=285%2C400&amp;ssl=1 285w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/12.-No-WonderCitroenColmans.jpg?resize=750%2C1052&amp;ssl=1 750w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/12.-No-WonderCitroenColmans.jpg?resize=2048%2C2871&amp;ssl=1 2048w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/12.-No-WonderCitroenColmans.jpg?w=1280&amp;ssl=1 1280w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/12.-No-WonderCitroenColmans.jpg?w=1920&amp;ssl=1 1920w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1"></a> <a href="https://davedye.com/2020/11/23/the-most-unfashionable-form-of-advertising/13-cuts-longqualcastwcrs/" rel="attachment wp-att-49178"><img data-attachment-id="49178" data-permalink="https://davedye.com/2020/11/23/the-most-unfashionable-form-of-advertising/13-cuts-longqualcastwcrs/" data-orig-file="https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/13.-Cuts-LongQualcastWCRS.jpg?fit=1153%2C774&amp;ssl=1" data-orig-size="1153,774" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="13. Cuts Long:Qualcast:WCRS" data-image-description="" data-medium-file="https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/13.-Cuts-LongQualcastWCRS.jpg?fit=300%2C201&amp;ssl=1" data-large-file="https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/13.-Cuts-LongQualcastWCRS.jpg?fit=640%2C429&amp;ssl=1" loading="lazy" src="https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/13.-Cuts-LongQualcastWCRS.jpg?resize=640%2C430&amp;ssl=1" alt="" width="640" height="430" srcset="https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/13.-Cuts-LongQualcastWCRS.jpg?w=1153&amp;ssl=1 1153w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/13.-Cuts-LongQualcastWCRS.jpg?resize=300%2C201&amp;ssl=1 300w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/13.-Cuts-LongQualcastWCRS.jpg?resize=1024%2C687&amp;ssl=1 1024w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/13.-Cuts-LongQualcastWCRS.jpg?resize=768%2C516&amp;ssl=1 768w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/13.-Cuts-LongQualcastWCRS.jpg?resize=596%2C400&amp;ssl=1 596w, https://i0.wp.com/davedye.com/wp-content/uploads/2020/11/13.-Cuts-LongQualcastWCRS.jpg?resize=750%2C503&amp;ssl=1 750w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1"></a> <a href="https://davedye.com/2020/11/23/the-most-unfashionable-form-of-advertising/screen-shot-2020-11-18-at-15-20-53/" rel="attachment wp-att-49221"><img data-attachment-id="49221" data-permalink="https://davedye.com/2020/11/23/the-most-unfashionable-form-of-advertising/screen-shot-2020-11-18-at-15-20-53/" data-orig-file="https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/Screen-Shot-2020-11-18-at-15.20.53.png?fit=1080%2C760&amp;ssl=1" data-orig-size="1080,760" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screen Shot 2020-11-18 at 15.20.53" data-image-description="" data-medium-file="https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/Screen-Shot-2020-11-18-at-15.20.53.png?fit=300%2C211&amp;ssl=1" data-large-file="https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/Screen-Shot-2020-11-18-at-15.20.53.png?fit=640%2C451&amp;ssl=1" loading="lazy" src="https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/Screen-Shot-2020-11-18-at-15.20.53.png?resize=640%2C450&amp;ssl=1" alt="" width="640" height="450" srcset="https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/Screen-Shot-2020-11-18-at-15.20.53.png?w=1080&amp;ssl=1 1080w, https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/Screen-Shot-2020-11-18-at-15.20.53.png?resize=300%2C211&amp;ssl=1 300w, https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/Screen-Shot-2020-11-18-at-15.20.53.png?resize=1024%2C721&amp;ssl=1 1024w, https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/Screen-Shot-2020-11-18-at-15.20.53.png?resize=768%2C540&amp;ssl=1 768w, https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/Screen-Shot-2020-11-18-at-15.20.53.png?resize=568%2C400&amp;ssl=1 568w, https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/Screen-Shot-2020-11-18-at-15.20.53.png?resize=750%2C528&amp;ssl=1 750w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1"></a><a href="https://davedye.com/2020/11/23/the-most-unfashionable-form-of-advertising/15-try-thissiemensbbhwcrs/" rel="attachment wp-att-49180"><img data-attachment-id="49180" data-permalink="https://davedye.com/2020/11/23/the-most-unfashionable-form-of-advertising/15-try-thissiemensbbhwcrs/" data-orig-file="https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/15.-Try-ThisSiemensBBHWCRS.jpg?fit=5954%2C3689&amp;ssl=1" data-orig-size="5954,3689" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="15. Try This:Siemens:BBH:WCRS" data-image-description="" data-medium-file="https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/15.-Try-ThisSiemensBBHWCRS.jpg?fit=300%2C186&amp;ssl=1" data-large-file="https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/15.-Try-ThisSiemensBBHWCRS.jpg?fit=640%2C396&amp;ssl=1" loading="lazy" src="https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/15.-Try-ThisSiemensBBHWCRS.jpg?resize=640%2C397&amp;ssl=1" alt="" width="640" height="397" srcset="https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/15.-Try-ThisSiemensBBHWCRS.jpg?w=5954&amp;ssl=1 5954w, https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/15.-Try-ThisSiemensBBHWCRS.jpg?resize=300%2C186&amp;ssl=1 300w, https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/15.-Try-ThisSiemensBBHWCRS.jpg?resize=1024%2C634&amp;ssl=1 1024w, https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/15.-Try-ThisSiemensBBHWCRS.jpg?resize=768%2C476&amp;ssl=1 768w, https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/15.-Try-ThisSiemensBBHWCRS.jpg?resize=1536%2C952&amp;ssl=1 1536w, https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/15.-Try-ThisSiemensBBHWCRS.jpg?resize=2048%2C1269&amp;ssl=1 2048w, https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/15.-Try-ThisSiemensBBHWCRS.jpg?resize=646%2C400&amp;ssl=1 646w, https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/15.-Try-ThisSiemensBBHWCRS.jpg?resize=750%2C465&amp;ssl=1 750w, https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/15.-Try-ThisSiemensBBHWCRS.jpg?w=1280&amp;ssl=1 1280w, https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/15.-Try-ThisSiemensBBHWCRS.jpg?w=1920&amp;ssl=1 1920w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1"></a> <a href="https://davedye.com/2020/11/23/the-most-unfashionable-form-of-advertising/16-unscrewnational-cordlesscampaign-palace/" rel="attachment wp-att-49181"><img data-attachment-id="49181" data-permalink="https://davedye.com/2020/11/23/the-most-unfashionable-form-of-advertising/16-unscrewnational-cordlesscampaign-palace/" data-orig-file="https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/16.-UnscrewNational-CordlessCampaign-Palace.jpg?fit=1580%2C1025&amp;ssl=1" data-orig-size="1580,1025" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="16. Unscrew:National Cordless:Campaign Palace" data-image-description="" data-medium-file="https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/16.-UnscrewNational-CordlessCampaign-Palace.jpg?fit=300%2C195&amp;ssl=1" data-large-file="https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/16.-UnscrewNational-CordlessCampaign-Palace.jpg?fit=640%2C415&amp;ssl=1" loading="lazy" src="https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/16.-UnscrewNational-CordlessCampaign-Palace.jpg?resize=640%2C415&amp;ssl=1" alt="" width="640" height="415" srcset="https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/16.-UnscrewNational-CordlessCampaign-Palace.jpg?w=1580&amp;ssl=1 1580w, https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/16.-UnscrewNational-CordlessCampaign-Palace.jpg?resize=300%2C195&amp;ssl=1 300w, https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/16.-UnscrewNational-CordlessCampaign-Palace.jpg?resize=1024%2C664&amp;ssl=1 1024w, https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/16.-UnscrewNational-CordlessCampaign-Palace.jpg?resize=768%2C498&amp;ssl=1 768w, https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/16.-UnscrewNational-CordlessCampaign-Palace.jpg?resize=1536%2C996&amp;ssl=1 1536w, https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/16.-UnscrewNational-CordlessCampaign-Palace.jpg?resize=617%2C400&amp;ssl=1 617w, https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/16.-UnscrewNational-CordlessCampaign-Palace.jpg?resize=750%2C487&amp;ssl=1 750w, https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/16.-UnscrewNational-CordlessCampaign-Palace.jpg?w=1280&amp;ssl=1 1280w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1"></a> <a href="https://davedye.com/2020/11/23/the-most-unfashionable-form-of-advertising/18-fish-birds-eye-mark-reddy-bbh-01/" rel="attachment wp-att-49183"><img data-attachment-id="49183" data-permalink="https://davedye.com/2020/11/23/the-most-unfashionable-form-of-advertising/18-fish-birds-eye-mark-reddy-bbh-01/" data-orig-file="https://i1.wp.com/davedye.com/wp-content/uploads/2020/11/18.-Fish-Birds-Eye-Mark-Reddy-BBH-01.jpg?fit=3988%2C5963&amp;ssl=1" data-orig-size="3988,5963" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="18. Fish’ Bird’s Eye, Mark Reddy, BBH-01" data-image-description="" data-medium-file="https://i1.wp.com/davedye.com/wp-content/uploads/2020/11/18.-Fish-Birds-Eye-Mark-Reddy-BBH-01.jpg?fit=201%2C300&amp;ssl=1" data-large-file="https://i1.wp.com/davedye.com/wp-content/uploads/2020/11/18.-Fish-Birds-Eye-Mark-Reddy-BBH-01.jpg?fit=640%2C957&amp;ssl=1" loading="lazy" src="https://i1.wp.com/davedye.com/wp-content/uploads/2020/11/18.-Fish-Birds-Eye-Mark-Reddy-BBH-01.jpg?resize=640%2C957&amp;ssl=1" alt="" width="640" height="957" srcset="https://i1.wp.com/davedye.com/wp-content/uploads/2020/11/18.-Fish-Birds-Eye-Mark-Reddy-BBH-01.jpg?w=3988&amp;ssl=1 3988w, https://i1.wp.com/davedye.com/wp-content/uploads/2020/11/18.-Fish-Birds-Eye-Mark-Reddy-BBH-01.jpg?resize=201%2C300&amp;ssl=1 201w, https://i1.wp.com/davedye.com/wp-content/uploads/2020/11/18.-Fish-Birds-Eye-Mark-Reddy-BBH-01.jpg?resize=685%2C1024&amp;ssl=1 685w, https://i1.wp.com/davedye.com/wp-content/uploads/2020/11/18.-Fish-Birds-Eye-Mark-Reddy-BBH-01.jpg?resize=768%2C1148&amp;ssl=1 768w, https://i1.wp.com/davedye.com/wp-content/uploads/2020/11/18.-Fish-Birds-Eye-Mark-Reddy-BBH-01.jpg?resize=1027%2C1536&amp;ssl=1 1027w, https://i1.wp.com/davedye.com/wp-content/uploads/2020/11/18.-Fish-Birds-Eye-Mark-Reddy-BBH-01.jpg?resize=1370%2C2048&amp;ssl=1 1370w, https://i1.wp.com/davedye.com/wp-content/uploads/2020/11/18.-Fish-Birds-Eye-Mark-Reddy-BBH-01.jpg?resize=268%2C400&amp;ssl=1 268w, https://i1.wp.com/davedye.com/wp-content/uploads/2020/11/18.-Fish-Birds-Eye-Mark-Reddy-BBH-01.jpg?resize=750%2C1121&amp;ssl=1 750w, https://i1.wp.com/davedye.com/wp-content/uploads/2020/11/18.-Fish-Birds-Eye-Mark-Reddy-BBH-01.jpg?resize=2048%2C3062&amp;ssl=1 2048w, https://i1.wp.com/davedye.com/wp-content/uploads/2020/11/18.-Fish-Birds-Eye-Mark-Reddy-BBH-01.jpg?w=1280&amp;ssl=1 1280w, https://i1.wp.com/davedye.com/wp-content/uploads/2020/11/18.-Fish-Birds-Eye-Mark-Reddy-BBH-01.jpg?w=1920&amp;ssl=1 1920w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1"></a> <a href="https://davedye.com/2020/11/23/the-most-unfashionable-form-of-advertising/19-katherinestabilo/" rel="attachment wp-att-49184"><img data-attachment-id="49184" data-permalink="https://davedye.com/2020/11/23/the-most-unfashionable-form-of-advertising/19-katherinestabilo/" data-orig-file="https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/19.-KatherineStabilo.jpg?fit=1130%2C1600&amp;ssl=1" data-orig-size="1130,1600" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="19. Katherine:Stabilo" data-image-description="" data-medium-file="https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/19.-KatherineStabilo.jpg?fit=212%2C300&amp;ssl=1" data-large-file="https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/19.-KatherineStabilo.jpg?fit=640%2C906&amp;ssl=1" loading="lazy" src="https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/19.-KatherineStabilo.jpg?resize=640%2C906&amp;ssl=1" alt="" width="640" height="906" srcset="https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/19.-KatherineStabilo.jpg?w=1130&amp;ssl=1 1130w, https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/19.-KatherineStabilo.jpg?resize=212%2C300&amp;ssl=1 212w, https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/19.-KatherineStabilo.jpg?resize=723%2C1024&amp;ssl=1 723w, https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/19.-KatherineStabilo.jpg?resize=768%2C1087&amp;ssl=1 768w, https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/19.-KatherineStabilo.jpg?resize=1085%2C1536&amp;ssl=1 1085w, https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/19.-KatherineStabilo.jpg?resize=283%2C400&amp;ssl=1 283w, https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/19.-KatherineStabilo.jpg?resize=750%2C1062&amp;ssl=1 750w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1"></a><a href="https://davedye.com/2020/11/23/the-most-unfashionable-form-of-advertising/20-iphoneapple-jpg/" rel="attachment wp-att-49222"><img data-attachment-id="49222" data-permalink="https://davedye.com/2020/11/23/the-most-unfashionable-form-of-advertising/20-iphoneapple-jpg/" data-orig-file="https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/20.-iPhoneApple.jpg.jpg?fit=1280%2C868&amp;ssl=1" data-orig-size="1280,868" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="20. iPhone:Apple:.jpg" data-image-description="" data-medium-file="https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/20.-iPhoneApple.jpg.jpg?fit=300%2C203&amp;ssl=1" data-large-file="https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/20.-iPhoneApple.jpg.jpg?fit=640%2C434&amp;ssl=1" loading="lazy" src="https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/20.-iPhoneApple.jpg.jpg?resize=640%2C434&amp;ssl=1" alt="" width="640" height="434" srcset="https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/20.-iPhoneApple.jpg.jpg?w=1280&amp;ssl=1 1280w, https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/20.-iPhoneApple.jpg.jpg?resize=300%2C203&amp;ssl=1 300w, https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/20.-iPhoneApple.jpg.jpg?resize=1024%2C694&amp;ssl=1 1024w, https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/20.-iPhoneApple.jpg.jpg?resize=768%2C521&amp;ssl=1 768w, https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/20.-iPhoneApple.jpg.jpg?resize=590%2C400&amp;ssl=1 590w, https://i2.wp.com/davedye.com/wp-content/uploads/2020/11/20.-iPhoneApple.jpg.jpg?resize=750%2C509&amp;ssl=1 750w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1"></a></span></p>
<p><span><strong>TV.</strong></span></p>
























<p><span>Reader suggestions:</span></p>




          
                  </div>

      </div>

    </div>

  </div>

      
  </article></div>]]>
            </description>
            <link>https://davedye.com/2020/11/23/the-most-unfashionable-form-of-advertising/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25252447</guid>
            <pubDate>Mon, 30 Nov 2020 10:39:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Persistency Semantics of the Intel-x86 Architecture [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25252088">thread link</a>) | @blopeur
<br/>
November 30, 2020 | http://www.soundandcomplete.org/papers/POPL2020/Px86-POPL-2020.pdf | <a href="https://web.archive.org/web/*/http://www.soundandcomplete.org/papers/POPL2020/Px86-POPL-2020.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://www.soundandcomplete.org/papers/POPL2020/Px86-POPL-2020.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25252088</guid>
            <pubDate>Mon, 30 Nov 2020 09:19:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I am an 80 column purist]]>
            </title>
            <description>
<![CDATA[
Score 31 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25251494">thread link</a>) | @Spiritus
<br/>
November 29, 2020 | https://daniel.haxx.se/blog/2020/11/30/i-am-an-80-column-purist/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2020/11/30/i-am-an-80-column-purist/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>I write and prefer code that fits within 80 columns in <a href="https://curl.haxx.se/">curl</a> and other projects – and there are reasons for it. I’m a little bored by the people who respond and say that they have 400 inch monitors already and they can use them.</p>



<p>I too have multiple large high resolution screens – but writing wide code is still a bad idea! So I decided I’ll write down my reasoning once and for all!</p>



<h2>Narrower is easier to read</h2>



<p>There’s a reason newspapers and magazines have used narrow texts for centuries and in fact even books <a href="https://en.wikipedia.org/wiki/Line_length">aren’t using long lines</a>. For most humans, it is simply easier on the eyes and brain to read texts that aren’t using really long lines. This has been known for a very long time.</p>



<p>Easy-to-read code is easier to follow and understand which leads to fewer bugs and faster debugging.</p>



<h2>Side-by-side works better</h2>



<p>I <em>never</em> run windows full sized on my screens for anything except watching movies. I frequently have two or more editor windows next to each other, sometimes also with one or two extra terminal/debugger windows next to those. To make this feasible and still have the code readable, it needs to fit “wrapless” in those windows.</p>



<p>Sometimes reading a code diff is easier side-by-side and then too it is important that the two can fit next to each other nicely.</p>



<h2>Better diffs</h2>



<p>Having code grow vertically rather than horizontally is beneficial for diff, git and other tools that work on changes to files. It reduces the risk of merge conflicts and it makes the merge conflicts that still happen easier to deal with.</p>



<h2>It encourages shorter names</h2>



<p>A side effect by strictly not allowing anything beyond column 80 is that it becomes really hard to use those terribly annoying 30+ letters java-style names on functions and identifiers. A function name, and especially local ones, should be short. Having long names make them really hard to read and makes it really hard to spot the difference between the other functions with similarly long names where just a sub-word within is changed.</p>



<p>I know especially Java people object to this as they’re trained in a different culture and say that a method name should rather include a lot of details of the functionality “to help the user”, but to me that’s a weak argument as all non-trivial functions will have more functionality than what can be expressed in the name and thus the user needs to know how the function works <em>anyway.</em></p>



<p>I don’t mean 2-letter names. I mean long enough to make sense but not be ridiculous lengths. Usually within 15 letters or so.</p>



<h2>Just a few spaces per indent level</h2>



<p>To make this work, and yet allow a few indent levels, the code basically have to have small indent-levels, so I prefer to have it set to two spaces per level.</p>



<h2>Many indent levels is wrong anyway</h2>



<p>If you do a lot of indent levels it gets really hard to write code that still fits within the 80 column limit. That’s a subtle way to suggest that you should not write functions that needs or uses that many indent levels. It should then rather be split out into multiple smaller functions, where then each function won’t need that many levels!</p>



<h2>Why exactly 80?</h2>



<p>Once upon the time it was of course because terminals had that limit and these days the exact number 80 is not a must. I just happen to think that the limit has worked fine in the past and I haven’t found any compelling reason to change it since.</p>



<p>It also has to be a hard and fixed limit as if we allow a few places to go beyond the limit we end up on a slippery slope and code slowly grow wider over time – I’ve seen it happen in many projects with “soft enforcement” on code column limits.</p>



<h2>Enforced by a tool</h2>



<p>In <a href="https://curl.se/">curl</a>, we have ‘checksrc’ which will yell errors at any user trying to build code with a too long line present. This is good because then we don’t have to “waste” human efforts to point this out to contributors who offer pull requests. The tool will point out such mistakes with ruthless accuracy.</p>



<h2>Credits</h2>



<p>Image by <a href="https://pixabay.com/users/piotrarssale-15944391/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=5016297">piotr kurpaska</a> from <a href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=5016297">Pixabay</a></p>
	</div></div>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2020/11/30/i-am-an-80-column-purist/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25251494</guid>
            <pubDate>Mon, 30 Nov 2020 07:31:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Evolution of tree data structures for indexing: more than it sounds]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25251359">thread link</a>) | @MarkusWinand
<br/>
November 29, 2020 | https://erthalion.info/2020/11/28/evolution-of-btree-index-am/ | <a href="https://web.archive.org/web/*/https://erthalion.info/2020/11/28/evolution-of-btree-index-am/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p><span>28 Nov 2020</span></p><h2 id="0-how-to-read-me">0. How to read me?</h2>
<p>I have to admit, my research blog posts are getting longer and longer. From one
side I find it genuinely encouraging, because if one gets so much information
just by scratching the topic, imagine what’s hidden beneath the surface! One
university professor once said “what could be interesting in databases?”, and
it turns out freaking a lot! On the other side it certainly poses problems for
potential readers. To overcome them I would suggest an interesting approach:
print this blog post out, or open it on your tablet/e-reader, where you can
make notes with a pencil or markers. Now while reading it try to spot ideas
particularly exciting for you and mark them. Along the way there would be
definitely some obscure parts or questions, write them on the sides as well.
You can experiment with the diagrams, changing or extending them, or just
drawing funny faces. But do not read everything at once, have no fear of
putting it aside for a while, and read in chunks that are convenient for you.
Some parts could be skipped as the text is build out of relatively independent
topics. The table of contents can help and guide you. Having said that we’re
ready to embark on the journey.</p>
<ul>
<li>
<a href="#1-introduction">Introduction</a>
</li>
<li>
<a href="#2-rum-conjecture">RUM conjecture</a>
</li>
<li>
<a href="#3-b-tree-basics">B-tree basics</a>
</li>
<li>
<a href="#4-beyond-the-hard-leaves-of-basics">Beyond the hard leavers of
basics</a>
<ul>
<li>
<a href="#41-key-normalization">Key normalization</a>
</li>
<li>
<a href="#42-prefix-truncation">Prefix truncation</a>
</li>
<li>
<a href="#43-dynamic-prefix-truncation">Dynamic prefix truncation</a>
</li>
<li>
<a href="#44-suffix-truncation">Suffix truncation</a>
</li>
<li>
<a href="#45-indirection-vector">Indirection vector</a>
</li>
<li>
<a href="#46-sb-tree">SB-tree</a>
</li>
</ul>
</li>
<li>
<a href="#5-why-is-it-not-enough">Why is it not enough?</a>
<ul>
<li>
<a href="#51-partitioned-b-tree">Partitioned B-tree</a>
</li>
<li>
<a href="#52-hybrid-indexes">Hybrid indexes</a>
</li>
<li>
<a href="#53-bw-tree">Bw-Tree</a>
</li>
<li>
<a href="#54-dptree">DPTree</a>
</li>
</ul>
</li>
<li>
<a href="#6-trie">Trie</a>
</li>
<li>
<a href="#7-learned-indexes">Learned indexes</a>
</li>
<li>
<a href="#8-is-that-all">Is that all?</a>
</li>
<li>
<a href="#references">References</a>
</li>
</ul>
<h2 id="1-introduction">1. Introduction</h2>
<p>Whenever we speak about indexes, especially in PostgreSQL context, there is a
lot to talk about: B-tree, Hash, GiST, SP-GiST, GIN, BRIN, RUM. But what if I
tell you that even the first item in this list alone hiding astonishing number
of interesting details and years of research? In this blog post I’ll try to
prove this statement, and we will be concerned mostly with B-tree as a data
structure.</p>
<p><img src="https://erthalion.info/public/img/btree-joke.png" width="80%"></p>

<p>Let’s start systematically and take a look at the definition first:</p>
<blockquote>
<p>B-tree is a self-balancing tree data structure that maintains sorted data and
allows searches, sequential access, insertions, and deletions in logarithmic
time.</p>
</blockquote>
<p>What is your first association with the concept of B-tree? Mine is “old and
well researched, or in other words boring”. And indeed apparently it was first
introduced in <a href="https://infolab.usc.edu/csci585/Spring2010/den_ar/indexing.pdf">1970</a>! Not only that, already in 1979 they
were <a href="http://cgi.di.uoa.gr/~ad/M149/ubiquitous_btree.pdf">ubiquitous</a>. Does it mean there is nothing exciting left any
more? Once upon a time I came across a remarkable read called
<a href="https://dl.acm.org/doi/10.1561/1900000028">Modern B-Tree techniques</a> which inspired me to dig
deeper into the topic and read bunch of shiny new whitepapers. Afterwards
totally by chance I’ve stumbled upon a book “Database Internals: A Deep Dive
into How Distributed Data Systems Work”, which contains great sections on
B-tree design. Both works were the triggers to write this blog post. What was I
saying about nothing exciting left? At the end I couldn’t be more wrong.</p>
<p>It turns out that there are multitude of interesting ideas and techniques
around B-Trees. They’re all coming from the desire to satisfy different (often
incompatible) needs, as well as adapt to emerging hardware. To demonstrate how
many of those exist, lets play a game. Below you can find a table of names I’ve
found in various science papers, together with a couple of silly names I’ve
come up myself. Can you find out the fake ones?</p>
<table>
<tbody>
<tr>
<td>B-tree</td>
<td>B<sup>+</sup>-tree</td>
<td>B<sub>link</sub>-tree</td>
<td>DPTree</td>
</tr>
<tr>
<td>wB<sup>+</sup>-tree</td>
<td>NV Tree</td>
<td>FPTree</td>
<td>FASTFAIR</td>
</tr>
<tr>
<td>HiKV</td>
<td>Masstree</td>
<td>Skip List</td>
<td>ART</td>
</tr>
<tr>
<td>WORT</td>
<td>CDDS Tree</td>
<td>Bw Tree</td>
<td>HOT</td>
</tr>
<tr>
<td>KISS Tree</td>
<td>VAST Tree</td>
<td>FAST</td>
<td>HV Tree</td>
</tr>
<tr>
<td>UB Tree</td>
<td>LHAM</td>
<td>MDAM</td>
<td>Hybrid B<sup>+</sup> Tree</td>
</tr>
</tbody>
</table>

<p>Any ideas? Well, I have a confession to make – all of them are real, I just
don’t have enough imagination to come up with such names. Having this in mind
hopefully you understand that if we want to make a survey, the first step would
be to establish some classification. Not only this will help us to structure
the material, but also will explain why on earth anyone would need to invent so
many variations of what we though was so simple!</p>
<h2 id="2-rum-conjecture">2. RUM conjecture</h2>
<p>To classify different index access methods we need to think about the following
ambitious question – is there anything common between almost any index access
method? The authors of <a href="https://stratos.seas.harvard.edu/files/stratos/files/rum.pdf">RUM conjecture</a> provide an interesting
insight about this topic:</p>
<blockquote>
<p>The fundamental challenges that every researcher, systems architect, or
designer faces when designing a new access method are how to minimize, i)
read times, ii) update cost , and iii) memory (or storage) overhead.</p>
<p>In this paper, we conjecture that when optimizing the read-update-memory
overheads, optimizing in any two areas negatively impacts the third</p>
</blockquote>
<p>This essentially states that if an index access method could be specified as a
point inside “Read”, “Update” (on the Fig. 1 it’s called “Write” for
convenience of drawing), “Memory” space we can observe an interesting
invariant. Every time we modify one index access method to have less overhead
for reading or memory footprint (i.e. shift the corresponding point closer to
“Read”/”Memory” corners), we inevitably loose on the updating workload (i.e.
getting further away from “Write” corner).</p>
<figure>
<img src="https://erthalion.info/public/img/rum.png" width="50%">
<br>
<figcaption>
Fig 1. RUM space
</figcaption>
</figure>
<p>In fact as a non-scientist I would even speculate that there should be another
dimension called “Complexity”, but the idea is still clear. I will try to show
this invariant at work via examples in this blog post, but it already gives us
some ground under the feet and opportunity to visually represent different
versions of B-tree by moving point on the triangle back and forth. But first
let’s recall the basics.</p>
<h2 id="3-b-tree-basics">3. B-tree basics</h2>
<p>So what is B-tree? Well, it’s a tree data structure: a root node, some number
of branch nodes (marked grey) and a bunch of leaf nodes (marked green):</p>
<figure>
<img src="https://erthalion.info/public/img/btree.png" width="100%">
<br>
<figcaption>
Fig 2. B-tree nodes arrangement
</figcaption>
</figure>
<p>Every node of this tree is usually a page of some certain size and contains
keys (shaded slices of a node) and pointers to other nodes (empty slices with
arrows). Keys on page are kept in sorted order to facilitate fast search within
a page.</p>
<p>The original B-tree design assumed to have user data in all nodes,
branch and leaf. But nowadays the standard approach is a variation called
B<sup>+</sup>-tree, where user data is present only in leaf nodes and branch
nodes contains separator keys (pivot tuples in PostgreSQL terminology). In this
way separation between branch and leave nodes become more strict, allowing
better flexibility for choosing format of former and making deletion operations
can affect only latter. In fact the original B-tree design is barely worth
mentioning these days and I’m doing this just to be precise. Since
B<sup>+</sup>-tree is sort of default design, we’ll use B-tree and
B<sup>+</sup>-tree interchangeably in this text from now on. An interesting
thing to mention here is that the only requirements for separator keys is to
guide search algorithm to a correct leaf node. As long as they fulfil this
condition they can contain anything, no other requirements exist.</p>
<p>Strictly speaking, only child pointers are truly necessary in this design, but
quite often databases also maintain additional neighbour pointers, e.g. what you
can see on the Fig. 2 between the leaf nodes. It could be helpful for some
operations like index scan, but need to be taken into account for node
split/merge operations. PostgreSQL uses <a href="https://www.csd.uoc.gr/~hy460/pdf/p650-lehman.pdf">Lehman-Yao</a> version,
called B<sub>link</sub>-tree, with links to both left and right sibling nodes
(the left link one is actually not presented in the original
B<sub>link</sub>-tree design, and it makes backward scan somewhat interesting),
and there are even implementations like WiredTiger with
<a href="https://github.com/wiredtiger/wiredtiger/blob/f08bc4b18612ef95a39b12166abcccf207f91596/src/include/btmem.h#L550">parent pointers</a>.</p>
<p>Having all this in place one can perform a search query by following the path
marked red on the Fig. 2, first hitting the root, finding a proper separator
key, following a downlink and landing on a correct page where we deploy binary
search to find the resulting key.</p>
<p>Until now, we were talking only about static parts of B-tree design, but of
course there is more to it. For example there is one dynamic aspect of much
importance (quite often it even scares developers like a nightmare), namely
page splits. What do we need to do when there is a new value to insert, but the
target page does not have enough space like on the following diagram?</p>
<figure>
<img src="https://erthalion.info/public/img/page-split-1.png" width="60%">
<br>
<figcaption>
Fig 3. B-tree page split (a)
</figcaption>
</figure>
<p>What happens here is we’re trying to insert the new value (shaded box) into the
page with not enough space for it. To maintain the three balanced we need to
allocate another leaf page, distribute keys between old and new leaf, promote a
new separator key into the parent page and update all required links
(left/right siblings if present):</p>
<figure>
<img src="https://erthalion.info/public/img/page-split-2.png" width="60%">
<br>
<figcaption>
Fig 4. B-tree page split (b)
</figcaption>
</figure>
<p>Curiously enough the new separator key could be chosen freely, it could be any
value as long as it separates both pages. We can see what does it change in the
optimization section.</p>
<p>Locking is obviously an important part of a page split. No one wants to end up
with concurrency issues when pages get updated while in the middle of a split,
so a page to be split is write-locked as well as e.g. right sibling to update
left-link if present.</p>
<p>As you can see, page splits are introducing performance overhead. We need to
bring in a new page, move elements around and everything should be consistent
and correctly locked. And already at this pretty much basic point we already
can see some interesting trade-offs. For example B*-tree modification tries to
rebalance data between neighbouring nodes to postpone page split as long as
possible. In terms of trade-offs it looks like a balance between complexity and
insert overhead.</p>
<p>I didn’t tell you everything about B<sub>link</sub>-tree and it’s going to be our next
topic example in this section. Not only Lehman-Yao version adds a link to the
neighbour, it also introduces a “high key” to each page, which is an upper bound
on the keys that are allowed on page. While obviously introducing a bit memory
overhead those two changes make it possible to detect a concurrent page split
by checking the page high key, which allows the tree to be searched …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://erthalion.info/2020/11/28/evolution-of-btree-index-am/">https://erthalion.info/2020/11/28/evolution-of-btree-index-am/</a></em></p>]]>
            </description>
            <link>https://erthalion.info/2020/11/28/evolution-of-btree-index-am/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25251359</guid>
            <pubDate>Mon, 30 Nov 2020 07:01:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Am Not Fat]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 115 (<a href="https://news.ycombinator.com/item?id=25251082">thread link</a>) | @snow_mac
<br/>
November 29, 2020 | http://www.adambourg.com/fat/lifestyle/health/fitness/potato-diet/2020/11/28/I-am-not-fat.html | <a href="https://web.archive.org/web/*/http://www.adambourg.com/fat/lifestyle/health/fitness/potato-diet/2020/11/28/I-am-not-fat.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content" role="main">
      <p> <em>Published: </em> 11/28/2020</p>

      <p>I’m not fat. There I said it, I should feel better about myself, right? Size is just a number. Right? Come on you know it’s true, size, weight and all that jazz is just a BS figure on the scale. That’s what we tell ourselves to make us feel better.</p>

<p>I’m obese, my medical BMI is 42.0. I’m 335 pounds. As Penn Jillette would say, I’m a “fat fuck”. I’m tired of being a “fat fuck” or as my wife prefers a “big guy”.</p>



<p>I’m an audiobook guy. I’m in love with Audible, she is very wonderful service to have, she reads to me every day, all day. About two weeks ago, I was bored, and she suggested Presto, a book by Penn Jillette about how he lost 100 pounds. I was bored, lazy and waiting for someone so I bought the book. Oh my gosh, the language is obscene, but the author is hilarious and entertaining. I could not put the book down. It made me want to toss the skinny white peppermint mocha and bananas in the trash…</p>

<p>Basically, Penn is a obese guy like me, well he was, he was 330 pounds at his highest. He went to the hospital for heart issues and nearly died. On a fist full of pills to keep his blood pressure less than the voltage of an outlet in Europe he embarked on a crazy, all in diet consisting of potatoes for two weeks. I like his style, he’s an all or nothing guy like me. Either give me the steak, the ice cream and the sides or give me nothing. I want to eat big; I want to live big. Moderation is bullshit as Penn would say, I would agree! I don’t do anything in moderation. If I’m going to do something, it’s all-in baby. When in Vegas last summer, I was the dipshit who went all in with a pair of kings in my hand and straight on the table; that’s me baby, not the smartest guy but hey I like to live it big.</p>

<p>I don’t do keto, I don’t do paleo, but when I do diet, I go really big, I go to Costco and literally buy everything I need to be successful on that plan, I research, I plan. It’s just like thanksgiving this year; I researched, I planned, I went to Costco and planned out each and every ingredient. I was diligent. Every doctor, health coach and fitness instructor has told me that my relationship with food is fucked up. Well, not fucked up, but bad; unhealthy. As Penn would say your life sucks if you’re taking diet advice from a Las Vegas Magician, well, Penn, my life does suck. I can’t breathe outside very well, hell, I get windy walking to the park. I’m an obese guy, I have a CPAP machine, I’m 335 pounds, I can barely do the things I want to do, basic stuff; sleep and wake rested, eat and not feel sick, go for a walk and not get winded. I’m half Penn’s age and his same weight… It’s time for a change.</p>



<p>The plan according to Penn’s buddy, Cray Ray, aka “Ray Cronise” is to do the following:</p>

<ol>
  <li>Eat nothing but potatoes for two weeks. Boiled, baked, steamed, roasted; does not matter, just no salt, oil, or sugar. Plain, nothing added, no salt, no butter, no pepper, no olive oil, just a plain, boring potato. Sweet, red, yellow, gold, purple, do not be a racist pig about potatoes, eat the potato rainbow, but just potatoes. Feel free to pig out on potatoes; just no fries or chips, that’s the beautiful potato ruined by Americans</li>
  <li>Contrast showers: Humans have conquered winter &amp; cold. Therefore, in order to get back to the biologically true lifestyle we’ve grown as a species as, we need to bring back the cold. Turn down the thermostat and cycle 10 seconds hot; 30 seconds cold showers for 5 minutes. It’s brutal but the time goes by shockingly fast</li>
  <li>After two weeks on potatoes, you go to a plant based, vegan lifestyle until you hit your target weight</li>
</ol>



<p>One big thing with CrayRay and Penn is the need for a scale, the smartass of scales. On an impluse I plopped down $100 for the <a href="https://www.withings.com/us/en/body-plus">Withings Body + scale</a>. It’s been 10 days! 10 DAYS!!! I’m 326.4, on day 2 of the plan. In 10 days, 1 of which involving nothing but potatoes, I’ve lost 9 pounds. This is AMAZING.</p>

<p>On day 1, it’s black Friday, or sucker day of the year. Everyone piles in their car after a Thanksgiving Day hang over consisting of pie and turkey, to go buy more stuff to stuff into their garage in six months. It’s all American in style and glory. What am I do? Well, shopping for TVs on Amazon like every other fat guy scared out of his mind of COVID-19. I’m sitting on my couch waiting for the oven, 350 degrees for 45 minutes, to produce 9 potatoes. That’s right 9 potatoes, or about 1000 ish calories. Once done cooking, I scarf down one single sweet potato. It’s sweet (no shit sherlock), delicious and surprisingly moist. I like it, I chase it with 4 tiny petite potatoes and some black coffee. This diet is sure boring.</p>

<p>Lunch time rolls around and I make some food for the kiddo and thanksgiving dinner for lunch for the wife. What do I have? If you guessed potatoes, you’d win the prize! I had 2 potatoes, a red and white. It was bland, boring and good.</p>

<p>A car ride nap, so more black coffee and about 2 liters of water later, we’re sitting down to dinner. I made peanut noodles for the wife, mac and cheese with some TG leftovers for the baby. I have 3 more potatoes, a gold, a red and a sweet potato. 2 potatoes into the meal, I’m stuffed. STUFFED ON TWO POTATOES?!?!??! Yeah, I save the sweet potato for dessert and decide to count my potatoes.</p>

<p>A few days ago, while prepping for thanksgiving, I bought 10 pounds of potatoes. I thought that was a LOT of potatoes, but when I counted it out I had around 20 potatoes left. That’s enough to feed a family a four a potato a night for a week, but for a guy living on potatoes? It’s more like two days if I’m lucky, so I head to Costco.</p>

<p>I love Costco. Everything there is a deal, no matter what the idiots on Life Hacker tell you. I love their steak, their fruit and yes, I love their clothes and bedding. But potatoes, that’s where you really make off like bandits. The potatoes were on sale today too.</p>

<p>I knew to continue the diet I needed to account for 14 days of potatoes, less today and the 1.5 I had in revere; thus, I knew I need about 12 (rounding up) days of potatoes. I’m supposed to be on a calorie restricted diet of 1800 or less per day, which is helping, but to get 1800 calories a day eating just potatoes, I’d need to consume 5 POUNDS of potatoes. That’s right, every day on this thing to hit target calorie intake I’d need 5 POUNDS!?!?!? So, with 12 days needed to be shopped, a total of 60 pounds of potatoes, I headed to Costco.</p>



<table>
  <tbody>
    <tr>
      <td>Potato Type</td>
      <td>Per Unit Cost</td>
      <td>Units</td>
      <td>Total Cost</td>
    </tr>
    <tr>
      <td>Creamer Potatoes</td>
      <td>$3.99 / 5 lb</td>
      <td>4</td>
      <td>$16</td>
    </tr>
    <tr>
      <td>Organic Sweet Potatos</td>
      <td>$6.99 / 6.5 lbs</td>
      <td>2</td>
      <td>$14</td>
    </tr>
    <tr>
      <td>Russet Potatoes</td>
      <td>$7 / 15 lbs</td>
      <td>1</td>
      <td>$7</td>
    </tr>
    <tr>
      <td>Gold Potatoes</td>
      <td>$6 / 10 lbs</td>
      <td>2</td>
      <td>$12</td>
    </tr>
  </tbody>
</table>

<p>68 pounds of potatoes for a whopping $49!</p>

<p>Here’s what my shopping chart looked like:</p>

<p><img src="http://www.adambourg.com/assets/img/potato-diet-posts/costco-potatoes.png" alt="Costco cart"></p>

<p>That’s a lot of potatoes! The berries are for my son, Luke, for him to eat with yogurt and breakfast for the next two weeks. Not pictured is the bottles of the sparkling water I got to enhance my diet this week.</p>



<p>If you don’t want to see me shirtless, it’s time to close the page. My starting stats on 11/20/2020 are: 335 LBS, but the offical, diet starting stats are: 333.4 lbs, BMI of 41.7. I’ll be updating this blog with progress, but here’s to my weightloss and success.</p>

<p>I’m off to eat more potatoes!</p>

<p><img src="http://www.adambourg.com/assets/img/potato-diet-posts/11272020-front.png" alt="front"> 
<img src="http://www.adambourg.com/assets/img/potato-diet-posts/11272020-side.png" alt="side"></p>



      
    </div></div>]]>
            </description>
            <link>http://www.adambourg.com/fat/lifestyle/health/fitness/potato-diet/2020/11/28/I-am-not-fat.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25251082</guid>
            <pubDate>Mon, 30 Nov 2020 05:49:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[And this world’s a fickle measure]]>
            </title>
            <description>
<![CDATA[
Score 67 | Comments 21 (<a href="https://news.ycombinator.com/item?id=25250968">thread link</a>) | @jseliger
<br/>
November 29, 2020 | https://quidplura.com/2020/11/29/and-this-worlds-a-fickle-measure/ | <a href="https://web.archive.org/web/*/https://quidplura.com/2020/11/29/and-this-worlds-a-fickle-measure/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-12060">
	<!-- .entry-header -->

	<div>
		
<p>They told me, “You have to watch <a href="https://www.youtube.com/watch?v=rhThso-PE_o">this interview where Mike Tyson talks about medieval history</a>,” and so I did, and there he was at the New York Public Library in 2013 being interviewed by curator Paul Holdengräber, whose German accent strikes the American ear as both effortlessly intellectual and lightly amusing, and who would seem to have nothing in common with the face-tattooed boxer.</p>



<p><img data-attachment-id="12067" data-permalink="https://quidplura.com/2020/11/29/and-this-worlds-a-fickle-measure/screen-shot-2020-11-28-at-11-57-11-pm-copy/" data-orig-file="https://quidplurablog.files.wordpress.com/2020/11/screen-shot-2020-11-28-at-11.57.11-pm-copy.jpg" data-orig-size="1816,934" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="Screen Shot 2020-11-28 at 11.57.11 PM copy" data-image-description="" data-medium-file="https://quidplurablog.files.wordpress.com/2020/11/screen-shot-2020-11-28-at-11.57.11-pm-copy.jpg?w=300" data-large-file="https://quidplurablog.files.wordpress.com/2020/11/screen-shot-2020-11-28-at-11.57.11-pm-copy.jpg?w=863" src="https://quidplurablog.files.wordpress.com/2020/11/screen-shot-2020-11-28-at-11.57.11-pm-copy.jpg" alt=""></p>



<p>The two men do, in fact, find much to talk about. Their discussion is mesmerizing, because to most of us Mike Tyson is nothing but a face and fists, not a man who reflects aloud and at length about his inner life. Holdengräber prompts a reticent Tyson to narrate clips of his greatest moments in the ring, and newcomers to boxing will easily see why Tyson was such a sensation, but Iron Mike grows more animated when other matters arise.</p>



<p>Half an hour into the interview, Holdengräber says that their mutual friend, eccentric German filmmaker Werner Herzog, urged him to ask Tyson why he’s so fascinated by Clovis, the founder of the Merovingian Frankish dynasty, and Pepin the Short, the first Carolingian king of the Franks. Tyson’s answer, however halting, makes him come alive: </p>



<blockquote><p>I don’t know—it all comes from my insecurity from being poor, and not having enough—to be insecure, and being—yeah, that’s what it is: obscure. I never wanted to be obscure. I was born in obscurity and I never wanted to deal with that again, never wanted to be that. And they came from obscurity.</p></blockquote>



<p>Tyson then narrates a capsule history of the Frankish kings. He rambles, he doesn’t get all the details right, and his mispronunciation of names marks him as an autodidact, but it’s a shame to hear the audience laugh when Holdengräber asks, “Mike, how do you know all this shit?” Whether Tyson is mapping his own experiences onto medieval history or hearing echoes of the Franks in his troubled life, the credentialed, status-conscious audience is uncomfortable with his sincere interest in a past they find trivial.</p>



<p>Yet Tyson is the real deal, a book lover not because his peer group yaks about whichever author the <em>New York Times</em> has dubbed fame’s latest love child, but because he’s hungry for ideas, for meaning, for connections across time. He speaks with undisguised emotion about Cus D’Amato, the trainer and manager who turned him into a lethal boxer. Obsessed with Nietzsche and Clausewitz, D’Amato taught Tyson to see boxing as war and war as the key to decoding the world. “That is just what I do,” Tyson explains, an attentive pupil and dutiful son. “I love war. I love the act of war. I love the players in war, the philosophy of war.”</p>



<p>Tyson is searching for more than war on the pages of the past. Having grown up amid crime and chaos and founded his life on violence, he now relies on books to make moral and ethical sense of the world:</p>



<blockquote><p>Yeah—they’re our most priceless possessions, because if you think about it, you know, a room without a book is like a body without a soul. It’s the only way that we can connect the future with the past. Without that, there’s no way that we can know about the future, and know about particularly the past, or the present, you know, that when you think about history, the value of history is not necessarily scientific but moral. By liberating our minds and deepening our sympathies and fortifying our will, we can control—pretty much history allows us to control not society but ourselves, which is a much more important thing to do, you know what I mean? And it would allow us to pretty much meet the future more so than foretell it, and for that reason alone, in order to predict the future we always have to look through the past, because very rarely does time not repeat itself, and it always will repeat itself. </p><p>I’ve heard a quote before in a book that we would be fools to think historically that the past is us in funny clothes, but the past <em><span>is</span></em> us in funny clothes, and that’s truly what it is. That’s from somebody who really said a really profound statement but he misquoted what he was saying, he must have been saying it backwards, because that’s really what the past was, it’s just us in funny clothes, in different times, that’s really what it is.</p></blockquote>



<p>Of course, to hear Tyson cite <a href="http://thecampvs.com/2011/08/03/cicero-on-books-and-the-soul/">a quip inaccurately attributed to Cicero</a>, “a room without books is like a body without a soul,” is to wonder if he’s putting us on. Late in the interview, he jokes that if you quote books, you fool people into thinking you’re smart—but Tyson, for all his malapropisms and mispronunciations and odd mannerisms, <em>is</em> intelligent. He’s going round after round with big questions that  many of the ostensibly educated attendees at his book-talk don’t bother to ask.</p>



<p>When Holdengräber suggests that Tyson’s knowledge of history didn’t improve his behavior, Tyson calmly disagrees. He compares himself to the fictional Ben-Hur, a fellow athlete and celebrity who achieved glory but was doomed to be unfree until he set his priorities in order: “He may not have been famous again,” Tyson points out, “but he got his family, and that was his success.” </p>



<p>After listening to Mike Tyson—childhood criminal, devastating fighter, struggling alcoholic and recovering drug addict, convicted rapist, pop-culture eidolon—speak for an hour and a half, I still don’t quite know who he is. He may be the closest thing 21st-century America has to <a href="https://quidplura.com/2011/11/03/but-the-answers-you-seek-will-never-be-found-at-home/">a Robert E. Howard character</a>, a born barbarian who’s ignorant of social niceties but possesses earned wisdom that the civilization around him disdains. I don’t know whether he’s all in on his bookish pursuits or one slight away from again gnawing off someone’s ear. Whether he’s a good man or a bad man feels foolish to ask about a professional punch-thrower who reads Nietzsche, but Tyson looks like a <em>better</em> man, one who has perhaps searched harder for his humanity than the onlookers snickering from the safety of their library seats. What has their pride gained them? Tyson’s, by contrast, has brought him perspective, and with it the humility to admit that his story is still being written—and has been before.</p>




			</div><!-- .entry-content -->

	
	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://quidplura.com/2020/11/29/and-this-worlds-a-fickle-measure/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25250968</guid>
            <pubDate>Mon, 30 Nov 2020 05:24:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Victoria to fine drivers blocking EV chargers]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 18 (<a href="https://news.ycombinator.com/item?id=25250936">thread link</a>) | @oxplot
<br/>
November 29, 2020 | https://www.carexpert.com.au/car-news/victoria-to-fine-drivers-blocking-ev-chargers | <a href="https://web.archive.org/web/*/https://www.carexpert.com.au/car-news/victoria-to-fine-drivers-blocking-ev-chargers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Drivers who block electric vehicle chargers in Victoria will be fined under new road rules. </p>
<p>Non-electric vehicles, or electric cars that aren’t plugged in to the charger, face fines of $330.44 for “stopping in a parking area for electric-powered vehicles”. </p>
<p>The rules are designed to stop electric vehicle chargers, which are sparse in some parts of Australia, from being blocked by drivers looking for a convenient spot to park their internal-combustion vehicle. </p>
<p>Similar rules have been implemented in American states such as Colorado to prevent what’s known as ICEing. </p>
<div><figure><ul><li><div><figure><a data-fancybox="gallery" href="https://images.carexpert.com.au/resize/3000/-/app/uploads/2020/03/electric-charging-ev-charge-electric-3.jpg" data-thumb="https://images.carexpert.com.au/resize/180/-/app/uploads/2020/03/electric-charging-ev-charge-electric-3.jpg"><img alt="Victoria to fine drivers blocking EV chargers" srcset="https://images.carexpert.com.au/resize/1600/-/app/uploads/2020/03/electric-charging-ev-charge-electric-3.jpg 2x, https://images.carexpert.com.au/resize/800/-/app/uploads/2020/03/electric-charging-ev-charge-electric-3.jpg 1x" loading="lazy"></a></figure></div></li></ul></figure></div>
<p>Although it has brought in new rules to protect electric vehicle drivers, Victoria has also made news for <a href="https://www.carexpert.com.au/car-news/victoria-aiming-to-raise-30-million-per-year-from-ev-road-tax">trying to tax them</a>. </p>
<p>The state has followed <a href="https://www.carexpert.com.au/car-news/south-australia-plans-ev-road-user-levy-but-also-pledges-to-buy-more-electric-cars-for-its-own-fleet">South Australia</a> in committing to a&nbsp;<strong>road tax for electric vehicle</strong>&nbsp;and&nbsp;<strong>plug-in hybrid vehicle</strong>&nbsp;owners.</p>
<p>The tax of&nbsp;<strong>2.5 cents per kilometre</strong>&nbsp;for pure electric vehicles and&nbsp;<strong>2.0 cents per kilometre</strong>&nbsp;for plug-in hybrid vehicles was announced by the Victorian Treasurer ahead of this week’s state budget, and will come into force in July 2021.</p>
<p>An electric vehicle owner who travels&nbsp;<strong>15,000km</strong>&nbsp;per year will be charged&nbsp;<strong>$375</strong>&nbsp;on top of their annual registration fee, while plug-in hybrid owners will pay an extra&nbsp;<strong>$300</strong>&nbsp;per year.</p>
<p>Although the estimated $30 million the tax will raise annually won’t be funnelled directly into electric vehicle infrastructure, the Treasurer said $45 million will be set aside in the budget to boost take-up of hybrid, plug-in hybrid, and electric vehicles.</p>
<div><figure><ul><li><div><figure><a data-fancybox="gallery" href="https://images.carexpert.com.au/resize/3000/-/app/uploads/2020/10/mercedes-benz-EQC-charging-electric.jpg" data-thumb="https://images.carexpert.com.au/resize/180/-/app/uploads/2020/10/mercedes-benz-EQC-charging-electric.jpg"><img alt="Victoria to fine drivers blocking EV chargers" srcset="https://images.carexpert.com.au/resize/1600/-/app/uploads/2020/10/mercedes-benz-EQC-charging-electric.jpg 2x, https://images.carexpert.com.au/resize/800/-/app/uploads/2020/10/mercedes-benz-EQC-charging-electric.jpg 1x" loading="lazy"></a></figure></div></li></ul></figure></div>
<p>Chairman of the Electric Vehicle Council of Australia, Behyad Jafari, described Victoria’s tax as a “shameful abdication of Victoria’s intention to reduce emissions”.</p>
<p>South Australia’s proposed charge will include a fixed component, similar to current registration charging, and a variable charge based on distance travelled.</p>
<p>The proposal has been widely criticised, with chief executive of the peak body for carmakers in Australia, Tony Weber, describing it as “beyond belief”.</p>
<p>“We believe this charge will make South Australia the only jurisdiction in the world that actually opposes the uptake of low and zero emission vehicles,” Mr Weber added.</p>
<p>As state governments in Victoria, South Australia, and New South Wales have moved to tax electric vehicle owners, the Australian Capital Territory (ACT) has positioned itself as the friendliest jurisdiction in the nation for EV buyers.</p>
<p>It recently announced an ambitious target to&nbsp;<a href="https://www.carexpert.com.au/car-news/all-act-new-car-sales-to-be-zero-emissions-by-2030-under-ambitious-plan">sell only zero-emissions new vehicles</a>&nbsp;by 2030.</p>
</div></div>]]>
            </description>
            <link>https://www.carexpert.com.au/car-news/victoria-to-fine-drivers-blocking-ev-chargers</link>
            <guid isPermaLink="false">hacker-news-small-sites-25250936</guid>
            <pubDate>Mon, 30 Nov 2020 05:15:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Uncertainty Principle in software R&D]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25250916">thread link</a>) | @behnamoh
<br/>
November 29, 2020 | https://andersource.dev/2019/09/21/rnd-uncertainty-principle.html | <a href="https://web.archive.org/web/*/https://andersource.dev/2019/09/21/rnd-uncertainty-principle.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><a href="https://en.wikipedia.org/wiki/Uncertainty_principle">Heisenberg’s Uncertainty Principle</a> is an important result in physics, expressing a limit regarding the measurement of certain pairs of particles’ physical properties. In essence, it states that the uncertainty of any measurement of these pairs of properties at the same time has a lower bound. For example, if we’re measuring a particle’s position and velocity, and want to be more certain about the particle’s <em>position</em> (measure the position more precisely),
at some point we would inevitably start becoming less certain about the particle’s <em>velocity</em>, regardless of the measurement tools we use. This limitation doesn’t come from any technical
properties of how we measure those properties. Rather, it points to a loss of mathematical meaning as the measurements get “too precise”.</p>

<p>I believe a similar phenomenon exists in the world of research and development. It seems trivial, but too many times I’ve seen it forgotten (or ignored) when it was inconvenient.</p>

<p>Pick a random project management book or article, and you’ll probably see projects depicted as triangles representing the projects’ constraints in some form. Two of the primary constraints
would be equivalents of <em>time</em> and <em>result</em>: we know what we want, and we know when we want it. In practice we are usually not overly concerned with calculating confidence intervals
for those variables.</p>

<p>But the more <em>novel</em> a project (or subtask) is, the more inherent uncertainty it has. This means that if we’re trying to take on something that no-one in-house has experience with
(and we’re not consulting someone with experience), the error bars on <em>both</em> time and result should be quite large. And if we’re tackling something entirely new (as far as we can tell
from preliminary research), it’s almost meaningless to assign an expected value to both the project’s duration and the result. This is important because after a certain threshold, a change of scope is warranted: as a manager, at some point you stop framing the project as “I want X by Y”, and start framing it as one of either:</p>
<ul>
  <li>“I want X and I don’t care how long it takes.”</li>
  <li>“I’m willing to give this project until Y, no matter the results.”</li>
</ul>

<p>Of course both of these framings are problematic from the business perspective. But the way I see it, assigning too-small error bars just to make a project’s premise feasible
business-wise is a risky endeavor at best.</p>

<p>Note that even when a project is not very novel, <a href="https://erikbern.com/2019/04/15/why-software-projects-take-longer-than-you-think-a-statistical-model.html">we are not great at making practical estimates</a>. Even when we would expect uncertainty to be controlled it comes back to bite us - all the more reason to be extra-careful of underestimating it.</p>

  </div>
</article>


      </div>
    </div></div>]]>
            </description>
            <link>https://andersource.dev/2019/09/21/rnd-uncertainty-principle.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25250916</guid>
            <pubDate>Mon, 30 Nov 2020 05:11:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Recruiters and Human Traffickers]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 23 (<a href="https://news.ycombinator.com/item?id=25249818">thread link</a>) | @Danieru
<br/>
November 29, 2020 | https://www.tokyodev.com/2020/10/01/recruiting-in-japan/ | <a href="https://web.archive.org/web/*/https://www.tokyodev.com/2020/10/01/recruiting-in-japan/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

<p>Japan's <a href="http://www.japaneselawtranslation.go.jp/law/detail_main?id=10&amp;vm=2&amp;re=">Employment Security Act</a> requires a recruitment business to obtain a license. Failure to do so can result in imprisonment of up to a year. While I've met sleazy recruiters, sending them to prison seems a tad excessive to me. Curious about why the industry is so harshly regulated, I started digging. This took me into the seemingly dry but surprisingly interesting topic of the history of recruitment in Japan. As virtually nothing about this is written in English, I'm sharing what I found.</p>

<h2 id="japans-first-employment-agency">Japan’s first employment agency</h2>

<p>The earliest account of an employment agency in Japan comes from the mid-Seventeenth century. <a href="http://shokugyo-kyokai.or.jp/shiryou/gyouseishi/01-1.html">Keian Yamato</a> was a doctor who was sometimes asked by his patients to introduce servants or help arrange marriages. He was compensated for these introductions, and eventually this side business grew so successful that it overtook his medical practice. In 1652, he quit his job as a doctor to focus on his introduction business instead. So much so was his early fame, that early employment agencies were called “Keian” after him.</p>

<p>Keian’s agency and others got started at that point in Japanese history because the economic conditions were right for them. For an employment agency to be a viable business, there needs to be both a large supply of people seeking employment, and employers seeking labor. By mid-Seventeenth century Japan, such a market for labor was flourishing in response to a shift in Japanese society that had started with the dawn of the Edo Period, fifty years earlier.</p>

<h2 id="the-labour-market-in-the-edo-period">The labour market in the Edo Period</h2>

<p>The Edo period started in 1603 when <a href="https://en.wikipedia.org/wiki/Tokugawa_Ieyasu">Ieyasu Tokugawa</a> officially assumed control of Japan. Before he came to power, for the last century and a half, Japan had been in a state of near-constant civil war, leading to much of the country struggling to recover from the ongoing conflict.</p>

<p>Ieyasu chose Edo, modern day Tokyo, to be the center of his government and country. Previous to this, the political and cultural center was located in western Japan, and Edo and the surrounding region had been economically underdeveloped. But Ieyasu enacted policies that encouraged the urbanization of Edo, transforming it from a small castle town with only one hundred houses to a bustling metropolis of over 250,000 people by 1650.</p>

<p>Not only did Ieyasu pursue urbanization of Edo, but his policies encouraged it throughout Japan. The government divided all of Japan into specific regions, granting each to a local Daimyo, a powerful feudal lord, who built their own castles surrounded by Samurai residences. This lead to a growth in the number of artisans and merchants, who in turn needed staff, creating new employment opportunities.</p>

<p>Further driving demand for labour was the government policy of <a href="https://en.wikipedia.org/wiki/Sankin-k%C5%8Dtai">Sankin-kōtai</a>, which required Daimyo to alternate living between their holdings and Edo on a yearly basis, in an attempt to prevent them from gaining too much power. As it was infeasible for Daimyos to relocate their entire household to Edo, this led to a demand for temporary staff.</p>

<p>Simultaneously, Edo saw a large influx of job seekers. Traditionally in Japan, the eldest son inherited everything: the family name, business, and any assets. Other children were seen as a burden, particularly for poor families. Struggling families practiced “Kuchi-berashi”, literally translated as reducing the number of mouths, where they would place their children to work elsewhere. As Edo flourished, many second sons and daughters of poor rural families journeyed there in search of employment.</p>

<p>Not only did children seek employment in Edo, but so did adults. Often these were people from farming villages who were cast out by their family, or samurai who became masterless after their leader fell in battle.</p>

<p>As these job seekers didn’t have local connections, they sought out someone who could make introductions. With the burgeoning employment market, recruiting as a profession was born in Japan.</p>

<h2 id="employment-in-the-edo-period">Employment in the Edo period</h2>

<p>Employment is a relationship where an employer pays an employee for work. While this has been one type of relationship, there are others where people perform work without receiving compensation, such as slavery or indentured servitude. In the Edo Period, the division between compensated and forced labor was ambiguous, with the term <a href="https://ja.wikipedia.org/wiki/%E5%A5%89%E5%85%AC">Hōkō</a>, roughly translated as “service” or “apprenticeship”, used to refer to a wide range of employment-like relationships.</p>

<p>The most straightforward kind of Hōkō was temporary labor, where a person tended to be paid daily. Another form was a long term contract of a year or more to work for a samurai house. With this contract, they were usually paid on a monthly or yearly basis, however the salary itself was low as they were also provided room and board while working for the family.</p>

<p>Unpaid apprenticeships also fall under the term Hōkō, whereby a person would work for an artisan or merchant to learn the business. While they usually wouldn’t be directly paid for their work, the expectation was that their previous employer would sponsor their new business.</p>

<p>Children could also be placed out to work under a Hōkō agreement, where they would often learn a craft while being given food, clothes, and a place to live, but not be directly financially compensated. The parents of the children would be given what was effectively an interest free loan: they’d get a lump sum payment when the child started the apprenticeship, which they’d need to pay back when it ended.</p>

<p>While Hōkō tended to refer to agreements of fixed duration, it also encompasses a slavery-like relationship, whereby a whole family was born to serve a wealthy family for their entire life. Near the beginning of the Edo period, this form of permanent Hōkō was banned, and restricted to a fixed period instead (a maximum of 3 years in 1616, but extended it to 10 years in 1625).</p>

<h2 id="recruiter-or-human-trafficker">Recruiter or human trafficker?</h2>

<p>In modern parlance, just like there is a clear divide between employment and forced labour, there is also a clear divide between recruiters who perform employment matchmaking, and human traffickers who provide uncompensated labourers to employers. In the Edo period, the difference between these two professions was murkier than it is today.</p>

<p>For instance, when children ventured into Edo in search of employment and didn’t have any local connections, they would sometimes make use of a local recruiter. These recruiters would sign a contract on behalf of the parents with an employer. While some of these were benevolent, it was easy for them to be exploitative, and force the children to take jobs with poor working conditions.</p>

<p>During this period, the government also established special regions called <a href="https://en.wikipedia.org/wiki/Y%C5%ABkaku">Yukaku</a>, which became the only legal area to practice prostitution. The government saw Yukaku as a way of maintaining public order and collecting taxes. To ensure a steady stream of new prostitutes, the government allowed the “apprenticing” of young girls into prostitution. Unlike normal apprenticeships though, where the parents needed to pay back the “loan” that they received, the girl herself became responsible for paying it back. The amount the parents received was so much though, that even if the girl worked her entire life as a prostitute, she could never pay off the debt. The only way out was to have a wealthy man buy out her remaining debt, and become his mistress. Some recruiters took advantage of Yukaku, and effectively bought young girls from poor families in rural areas and sold them to brothels.</p>

<h2 id="first-steps-towards-regulation-of-recruitment">First steps towards regulation of recruitment</h2>

<p>In 1867, the Tokugawa shogunate was finally toppled, ushering in a new era in Japanese history, referred to as <a href="https://en.wikipedia.org/wiki/Meiji_(era)">the Meiji period</a>. Whereas the previous government had maintained an isolationist stance, the new government embraced western technology and culture, seeking to modernize the country before it was subjugated by western powers.</p>

<p>As part of this modernization, the government abolished the strict class system that divided Japanese into Samurai, peasants, artisans, and merchants, declaring that everyone who had been peasants, artisans, and merchants to be equal. People who were formerly Samurai and Daimyo however were still granted a status as nobles.</p>

<p>With this move modernity, the government sought to regulate the recruiting industry. In 1872, they introduced a requirement that recruiters be licensed and have a guarantor. They also limited the fee a recruiter could receive to be a maximum of 5% of the salary of the introduced employee. This fee was paid by both the employee and employer.</p>

<h2 id="international-attempts-to-ban-private-employment-agencies">International attempts to ban private employment agencies</h2>

<p>As part of the Treaty of Versailles that ended World War I, <a href="https://www.ilo.org/global/about-the-ilo/history/lang--en/index.htm">the International Labour Organization (ILO)</a> was founded to advance social and economic justice through setting international labour standards.</p>

<p>At their very first meeting in 1919, the ILO called on its members to establish free public employment agencies and move towards banning fee charging agencies. As a member of the ILO, Japan created a new law, which required municipal governments to establish public employment agencies and introduced stricter requirements for private employment agencies. While there had been 9,712 private agencies in 1926, the number dwindled to 2,541 by 1934.</p>

<p>The new regulation of the industry also saw stronger controls against unethical recruitment, such as using exaggerated or false claims to recruit people, forcing applications, recruiting women to be prostitutes, blocking applicants’ freedom, and so on.</p>

<p>In April 1938, the public employment agencies that had been operated at a local level were nationalized with a new law. This law also banned private agencies, except for some of the existing agencies, which were allowed to continue while facing even stricter regulations. Many of the private agencies who were banned merged into the national agency. The driving factor for this nationalization was not human rights though, but rather a response to a rapid increase in …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.tokyodev.com/2020/10/01/recruiting-in-japan/">https://www.tokyodev.com/2020/10/01/recruiting-in-japan/</a></em></p>]]>
            </description>
            <link>https://www.tokyodev.com/2020/10/01/recruiting-in-japan/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25249818</guid>
            <pubDate>Mon, 30 Nov 2020 01:19:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How To Research Public Companies (part 1)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25249676">thread link</a>) | @itslogotime
<br/>
November 29, 2020 | https://multipleexpansion.com/2020/11/25/standalone-model-public-market-overview/ | <a href="https://web.archive.org/web/*/https://multipleexpansion.com/2020/11/25/standalone-model-public-market-overview/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
      
        <h2 id="Introduction"><a href="#Introduction" title="Introduction"></a>Introduction</h2><p>This will be the first in a series of articles showing you how to model a public company.</p>
<p>We’re going to build a <strong>standalone model</strong> for Slack Technologies, Inc. (NYSE: WORK). A standalone model is exactly what it sounds like: a financial model for a given company without any assumed transactions (e.g., acquisition, dividend recap, etc.). Oftentimes, a standalone model is the first building block in a larger financial analysis exercise. For example, if a bank is hired to help a company review its strategic alternatives, one of the first steps is working with management to build a standalone model. The standalone model serves as the company’s <em>base case</em>, which all strategic alternatives are then compared to.</p>
<p>Likewise, public markets investors model public companies in order to project financial results and evaluate investment opportunities. For private equity investors, building a rigorously tested operating model is one of the key workstreams in any deal. Knowing how to build rock-solid standalone models is a foundational skill for investment banking, private equity, and hedge fund professionals.</p>
<p>This article will walk you through building a public market overview (PMO), which is the first step in any standalone model for a public company. A public market overview calculates a company’s equity value and enterprise value, along with basic trading multiples.</p>
<p>Future articles in this series will walk you through building the full standalone model and accompanying operating cases. This is step one.</p>
<h2 id="Getting-Started"><a href="#Getting-Started" title="Getting Started"></a>Getting Started</h2><p>We recommend you start from a blank Excel workbook and try to follow the steps below. But if you prefer, here’s the <a href="https://multipleexpansion.com/excel/Slack-PMO.xlsx">completed Excel file</a>.</p>
<h2 id="1-Create-Cover-Tab"><a href="#1-Create-Cover-Tab" title="1) Create Cover Tab"></a>1) Create Cover Tab</h2><p>First, we’re going to create a cover tab. Our cover tab looks like this:</p>
<p><img src="https://multipleexpansion.com/2020/11/25/standalone-model-public-market-overview/1-cover-tab.png"></p><p>A few things to point out:</p>
<ul>
<li>Below the cover area, we wrote our project code name (“WORK”) in cell F47. We’re naming this cell <code>PROJECT</code>.<blockquote>
<p>To name a cell, you press <strong>CNTL</strong> + <strong>F3</strong>. When you name a cell, you can then refer to it anywhere in the workbook using its new name (in this case, <code>PROJECT</code>).</p>
<p>Word to the wise: don’t overuse this functionality. If you have more than 10 named cells in your model, you’re doing too much.</p>
</blockquote>
</li>
<li>The title in the cover area is actually a formula using our project code name. The formula is:<blockquote>
<p>=”Project “&amp;PROJECT</p>
</blockquote>
</li>
<li>Similarly, the date / timestamp below the title is created using the formula:<blockquote>
<p>=now()</p>
</blockquote>
</li>
</ul>
<h2 id="2-Create-PMO-Tab"><a href="#2-Create-PMO-Tab" title="2) Create PMO Tab"></a>2) Create PMO Tab</h2><p>Next, we’re going to create a new tab for our <strong>p</strong>ublic <strong>m</strong>arket <strong>o</strong>verview (PMO). Again, a public market overview calculates a company’s equity value, enterprise value, and implied trading multiples. This might sound simple, but calculating equity and enterprise values can involve a surprising degree of nuance.</p>
<ul>
<li>Okay, let’s create a new tab. The shortcut to create a new Excel tab is <strong>SHIFT</strong> + <strong>F11</strong>.</li>
<li>Now, let’s rename the new tab <code>PMO</code>. The shortcut to rename an Excel tab is: <strong>ALT</strong> &gt; <strong>H</strong> &gt; <strong>O</strong> &gt; <strong>R</strong>.</li>
<li>Let’s apply some basic formatting to our new tab. In the upper leftmost cell, we’ll reference the project name again.<blockquote>
<p>= “Project “&amp;PROJECT</p>
</blockquote>
</li>
<li>Below the project name, let’s put a page header - in this case, “Public Market Overview (PMO)”</li>
</ul>
<p>Your new PMO tab should look like this: </p>
<p><img src="https://multipleexpansion.com/2020/11/25/standalone-model-public-market-overview/2-blank-pmo-tab.png"></p><h2 id="3-Add-PMO-Layout"><a href="#3-Add-PMO-Layout" title="3) Add PMO Layout"></a>3) Add PMO Layout</h2><p>Let’s add the basic structure of our PMO. Remember - we’ll be calculating equity value, enterprise value, and trading multiples for Slack. </p>
<p><strong>How do we calculate equity value for a public company?</strong> Pretty simple, we multiply the number of shares by the stock price. We’ll need (i) the stock price and (ii) the fully diluted share count.</p>
<p><strong>How do we calculate enterprise value for a public company?</strong> We take the equity value, and we add net debt. We’re already calculating the equity value (above), but we’ll need to look at Slack’s latest filings in order to determine the net debt.</p>
<p><strong>How do we calculate trading multiples?</strong> (If you really have no idea, this is not the right tutorial series for you.) We’re going to divide equity value and enterprise value, respectively, by various financial metrics for Slack, such as revenue, EBITDA, and net income. The exact metrics and multiples we use will depend on the company’s financials.</p>
<p>Here’s what the outline of your PMO should look like:</p>
<p><img src="https://multipleexpansion.com/2020/11/25/standalone-model-public-market-overview/3-pmo-layout.png"></p><h3 id="Stock-Based-Compensation"><a href="#Stock-Based-Compensation" title="Stock-Based Compensation"></a>Stock-Based Compensation</h3><p>You’ll notice that we’re adding options &amp; RSUs to basic shares in order to calculate the <strong>f</strong>ully <strong>d</strong>iluted <strong>s</strong>hares <strong>o</strong>utstanding (FDSO). Most public companies offer some form of stock-based compensation to employees, and options and RSUs are two common varieties. When we go through Slack’s financial statements, we may discover additional share awards, or we may find out that Slack doesn’t have options or RSUs. Ultimately, we need the fully diluted share count, so that we can calculate accurate equity and enterprise values.</p>
<blockquote>
<p><strong>Some theory - why we’re focused on counting every last share…</strong><br>A company’s stock price gives us the implied equity value per share. We must assume that the market is relatively efficient. Therefore, the market is doing the same basic math as us, and knows exactly how many outstanding shares there are, including from stock-based compensation. Armed with this knowledge, the market is then giving us a price, which implicitly is the <em>most diluted</em> (lowest) value. If we don’t include all shares in our equity value calculation, we’re undervaluing the given company, because we’re multiplying the market price (reduced by share awards) by a half-baked share count.</p>
</blockquote>
<h3 id="Noncontrolling-Interest"><a href="#Noncontrolling-Interest" title="Noncontrolling Interest"></a>Noncontrolling Interest</h3><p>Noncontrolling interest represents the portion of any subsidiaries not owned by Slack. For example, if Slack bought 80% of XYZ Co three years ago, all of XYZ Co’s assets, liabilities, revenues, expenses, and cash flows would be included in Slack’s consolidated financials. The outstanding 20% of XYZ Co - not owned by Slack - would be included in Slack’s balance sheet as noncontrolling interest. </p>
<p>Noncontrolling interest is included as a debt-like item in the build from equity to enterprise value. It’s treated like debt, because it represents a claim on Slack’s consolidated net operating assets that is not included in Slack’s equity value. Remember, the noncontrolling interest is the portion <strong>NOT</strong> owned by Slack and, therefore, not indirectly owned by Slack’s shareholders.</p>
<blockquote>
<p><strong>More theory - what does enterprise value represent?</strong><br>This concept is often poorly explained. I’ll try to do a better job here. Enterprise value represents the aggregate value of a business, or collection of assets, irrespective of capital structure.</p>
<p>For example, when you buy a house, you fund the purchase using some combination of debt and down payment. The enterprise value for the house is the total amount of money transferred to the seller. Enterprise value ignores capital structure - it is purely a measure of aggregate value.</p>
</blockquote>
<h2 id="4-Searching-the-Financials"><a href="#4-Searching-the-Financials" title="4) Searching the Financials"></a>4) Searching the Financials</h2><p>Now the fun begins. Reading and searching a company’s financials deserves its own (lengthy) article series. We’ll do our best to cover the essentials below.</p>
<h3 id="SEC-Filings"><a href="#SEC-Filings" title="SEC Filings"></a>SEC Filings</h3><p>Since we’re evaluating a US-listed company (Slack), we’ll go to the SEC’s website to pull the filings. A lot of people are intimidated by the SEC website, due to its slightly clunky interface, but once you get the hang of it, it’s fast and easy. Personally, I feel more comfortable pulling filings directly from the source - and in the US, that’s EDGAR, the SEC’s filings website.</p>
<p>I never remember the website URL, so I always just google “SEC EDGAR.” The first result is the <a href="https://www.sec.gov/edgar/searchedgar/companysearch.html" target="_blank" rel="noopener">correct link</a>. On the left side of the EDGAR webpage, you should see a search box labeled <strong>Company and Person Lookup</strong>. That’s where you enter the ticker. So let’s type in Slack’s ticker, <strong>WORK</strong>, and we’ll get going.</p>
<p>You should now be on Slack’s EDGAR page, and you should see “Slack Technologies, Inc.” at the top (here’s <a href="https://www.sec.gov/cgi-bin/browse-edgar?CIK=1764925&amp;owner=exclude" target="_blank" rel="noopener">the link</a> in case you want to double-check).</p>
<p>Filings are listed in reverse chronological order (most recent filings at the top), and the number-and-letter symbols in the leftmost column represent filing types. You’ll mainly be interested in <strong>10-K</strong>s (annual financials), <strong>10-Q</strong>s (quarterly financials), and <strong>8-K</strong>s (periodic investor updates), but here’s a <a href="https://www.sec.gov/info/edgar/forms/edgform.pdf" target="_blank" rel="noopener">complete list of filing types</a>. I wouldn’t recommend reading this list, unless you have an unanswered question. For example, if you see an unusual form code and want to know what it is, try google first. If you can’t find a succinct answer quickly, then pop open <a href="https://www.sec.gov/info/edgar/forms/edgform.pdf" target="_blank" rel="noopener">this list</a> and <strong>CNTL</strong> + <strong>F</strong>.</p>
<p>As I mentioned, 10-Ks, 10-Qs, and 8-Ks are where you’ll spend most of your time. 10-Ks provide the most comprehensive information, and they’re filed annually. You can think of 10-Qs as leaner, less filling versions of the 10-K. 10-Qs are filed quarterly. <a href="https://www.sec.gov/fast-answers/answersreada10khtm.html" target="_blank" rel="noopener">This guide on how to read a 10-K</a>, provided by the SEC, is pretty thorough without making your eyes bleed (at least mine didn’t). If you’re new to filings research, it’s a good place to start.</p>
<p>When building a PMO, you want to locate the latest 10-Q or 10-K, which should have all of the information you need. Ideally, the latest 10-Q or 10-K will be one of the first filings listed, as is the case here (as of November 25, 2020). See below:</p>
<p><img src="https://multipleexpansion.com/2020/11/25/standalone-model-public-market-overview/4-first-10-q.png"></p><p>It’s better (for you) if the latest 10-Q / 10-K is near the top of the list, because then you have to check fewer filings to ensure nothing material has changed. Remember - 8-Ks contain investor updates, so sometimes you can run into situations, in which an important 8-K is released <em>after</em> the latest 10-Q / 10-K. By default, you should check every filing above the latest 10-Q / 10-K, and it’s also a good idea to check any 8-Ks directly below the latest 10-Q / 10-K. You don’t want to miss something important. Anyways, we’re in luck. No subsequent 8-Ks, and the latest 10-Q should have everything we need.</p>
<h3 id="10-Q-and-Exhibits"><a href="#10-Q-and-Exhibits" title="10-Q and Exhibits"></a>10-Q and Exhibits</h3><p>Let’s click on that top <a href="https://www.sec.gov/Archives/edgar/data/1764925/000176492520000570/0001764925-20-000570-index.htm" target="_blank" rel="noopener">10-Q</a>. You should see this menu:</p>
<p><img src="https://multipleexpansion.com/2020/11/25/standalone-model-public-market-overview/5-latest-10-q-menu.png"></p><p>The first link in the table (here, it says “10-Q”) is the main filing. We’ll go to that in a second.</p>
<p>The exhibits listed below the filing contain various legal documents. You can ignore these unless you’re hunting for something specific. For example, the first …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://multipleexpansion.com/2020/11/25/standalone-model-public-market-overview/">https://multipleexpansion.com/2020/11/25/standalone-model-public-market-overview/</a></em></p>]]>
            </description>
            <link>https://multipleexpansion.com/2020/11/25/standalone-model-public-market-overview/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25249676</guid>
            <pubDate>Mon, 30 Nov 2020 00:55:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[It’s time to remove news from Facebook and Google]]>
            </title>
            <description>
<![CDATA[
Score 46 | Comments 34 (<a href="https://news.ycombinator.com/item?id=25249414">thread link</a>) | @anaxana
<br/>
November 29, 2020 | https://blog.nillium.com/its-time-to-remove-news-from-facebook-and-google/ | <a href="https://web.archive.org/web/*/https://blog.nillium.com/its-time-to-remove-news-from-facebook-and-google/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <p>Pay up -- or we’re pulling the plug. </p><p>That’s the approach the news industry should take when it comes to Google and Facebook: Pay for our journalism or we’re banning it from your platforms. </p><p>For too long, journalists have given away their stories for free in exchange for distribution by the duopoly. At best, a story may go viral (rare) or hit the SEO lottery and experience a one-off traffic surge (unsustainable). </p><p>And for that, newsrooms have willingly handed over <a href="https://www.nytimes.com/2019/06/09/business/media/google-news-industry-antitrust.html?smid=nytcore-ios-share">billions of dollars</a> in ad revenue to the tech giants that <a href="https://techcrunch.com/2018/02/03/facebooks-siren-call/">threaten</a> their very existence. (Google and Facebook are No. 1 and No. 2 <a href="https://www.foxbusiness.com/technology/facebook-ad-revenue-2019-2020">ad platforms</a> in the U.S., respectively).</p><p>The news industry as a whole needs to come together and demand to be fairly compensated for their contributions. Until Facebook and Google agree to pay up, they are simply exploiting journalism under the pretext of democratizing information. </p><p>News drives habit. Habit drives frequency. And frequency drives time spent. In the attention economy (read: ad-driven), news content entices people to come back and stay in platforms’ carefully crafted ecosystems. </p><p>In short, platforms need news. </p><p>Mark Zuckerberg said it himself when Facebook launched its news tab in 2019 (its most recent olive branch to publishers). In a <a href="https://www.nytimes.com/2019/10/25/opinion/sunday/mark-zuckerberg-facebook-news.html">piece for the<em> New York Times</em></a>, the Facebook founder pledged to “support the news industry” and said that journalism today is “more important than ever.” But only <a href="https://www.washingtonpost.com/technology/2019/10/23/facebook-offer-news-tab-users-pay-some-publishers-their-work/">some of the 200+ publishers</a> involved in the news tab were actually paid for their contributions. &nbsp;</p><p>These platforms are simply using their high-minded mission statements (e.g. Facebook: To “give people the power to build community and bring the world closer together” and Google: To “organize the world’s information”) as a thuggish pretext for exploiting journalism. </p><p>Instead, they should pay a licencing fee or provide a sizable cut of ad revenue to newsrooms that are populating the platforms (Murdoch analogized this to a <a href="https://www.theguardian.com/technology/2018/jan/22/rupert-murdoch-facebook-should-pay-news-publishers">carriage fee</a>). &nbsp;</p><p>It’s not enough for them to attempt damage control by <a href="https://www.niemanlab.org/2020/06/google-paying-publishers-is-more-about-pr-than-the-needs-of-the-news-industry/">spinning up funds</a> claiming to help journalism or offering some – but not all – publishers fees for their contributions. (If you want to know how Google really feels about paying for news, see <a href="https://www.reuters.com/article/google-news/google-to-shut-down-news-site-in-spain-over-copyright-fees-idUSL1N0TV0S520141211">how they treated publishers</a> in Spain).</p><p>That’s why we’re building <a href="https://www.forthapp.com/?utm_source=nillium&amp;utm_medium=web&amp;utm_campaign=frontpage">Forth</a>, a news-first platform that pays journalists for their work and offers the audience concise updates with context -- from the reporters they trust. All revenue generated on Forth is shared with our news partners. </p><p>We only allow trusted and credible journalists (vetted by our editorial team) to publish to the platform. It's a one-stop shop for accurate information about what's happening right now. &nbsp;</p><p>It’s one thing for Facebook and Google to out-innovate a slow-to-adapt industry -- it’s another to profit off of the same industry's work with impunity. </p><p>Newsrooms should be mad as hell -- and they don’t have to take it anymore. </p><p>Let’s Go Forth, </p><p>-- Xana</p><p><br><em>Xana O'Neill is the Co-Founder of Forth, a platform for concise updates with context from the reporters you trust.</em></p>
                </div>
            </section></div>]]>
            </description>
            <link>https://blog.nillium.com/its-time-to-remove-news-from-facebook-and-google/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25249414</guid>
            <pubDate>Mon, 30 Nov 2020 00:14:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Coup-Proofing the Startup]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25249332">thread link</a>) | @harporoeder
<br/>
November 29, 2020 | https://abe-winter.github.io/book/review/2020/06/04/dictators-army.html | <a href="https://web.archive.org/web/*/https://abe-winter.github.io/book/review/2020/06/04/dictators-army.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>In the middle of an actual, like, actual workplace coup with secret meetings, purges, puppetmasters, frame-ups, leak investigations, and (rumored) slack DM surveillance, I was listening to the bombshell podcast and heard about this book about coup-proofing, and how it ruins teams.
I picked up a copy, and this year I read it.</p>

<p>The book (Caitlin Talmadge / <a href="https://www.cornellpress.cornell.edu/book/9781501700293/the-dictators-army">The Dictator’s Army</a>) is about how coup fears hamstrung management in two wars:
Saddam Hussein’s 8-year failed invasion of Iran, and South Vietnam’s final defense against the North.
This article is about private sector leadership lessons I took from the book.</p>

<p>Writing about private sector leadership on the eve of a plausible military coup seems like peeing into the ocean, but it’s this or doomscrolling and holding in your pee can kill you.</p>

<p>Most management books are aspirational and map out success.
This one is about repeated failure, despite great funding, first-mover advantage and better equipment, through repeated mistakes, and in the public eye.
Nothing that I would know anything about cough.</p>

<p>Startups sub 30 people have a hard time accessing experienced hires who combine domain skill and the ability to work on a team.
There are real reasons for this, and some boil down to something like Saddam’s coup fears.
But if our society plans to continue airlifting cash into small companies, onboarding good middle managers earlier can make more of these bets pay off.</p>

<p>If you prefer a soundtrack, play this <a href="https://www.youtube.com/watch?v=thbICk05yPk">masterclass on management</a> (from GI Joe’s Cobra Commander) in the background.
It sometimes gets me through the week.</p>

<ol id="markdown-toc">
  <li><a href="#despots-meddle" id="markdown-toc-despots-meddle">Despots meddle</a></li>
  <li><a href="#managing-up" id="markdown-toc-managing-up">Managing up</a></li>
  <li><a href="#demotions-temporary-and-permanent" id="markdown-toc-demotions-temporary-and-permanent">Demotions, temporary and permanent</a></li>
  <li><a href="#combined-arms" id="markdown-toc-combined-arms">Combined arms</a></li>
  <li><a href="#some-people-out-there-dont-have-maps" id="markdown-toc-some-people-out-there-dont-have-maps">Some people out there don’t <em>have</em> maps</a></li>
  <li><a href="#the-butchers-bill" id="markdown-toc-the-butchers-bill">The butcher’s bill</a></li>
  <li><a href="#professional-silence" id="markdown-toc-professional-silence">Professional silence</a></li>
</ol>

<h2 id="despots-meddle">Despots meddle</h2>

<blockquote>
  <p>Despotism is a legitimate mode of government in dealing with barbarians, provided the end be their improvement, and the means justified by actually effecting that end.</p>
</blockquote>

<blockquote>
  <p>Liberty, as a principle, has no application to any state of things anterior to the time when mankind have become capable of being improved by free and equal discussion.
– JS Mill</p>
</blockquote>

<p>By inference, if you’re not hiring barbarians and / or they don’t need improvement, or your team is capable of discussion, consider a lighter-weight leadership style.</p>

<p>‘Despot’ also means bronze age feudal landowners or the heir apparent of Byzantium, but we haven’t had those for a while.
Adaptive reuse of the term in revolutionary France gave the term its modern meaning:
an absolute ruler who governs without restraint by the law.
See also ‘frondeur’.</p>

<p>When growing teams take on more complex goals but don’t update their management, they encounter pathologies of delegation –
senior leadership who isn’t sure how to solve problems using middle managers, who give them the wrong length leash.
This is the 10 person to 30 person growth spurt.
Good companies outgrow it this <em>if</em> they survive.</p>

<p>Here’s what that looked like in Iraq:</p>

<blockquote>
  <p>decision-making at the senior levels of the Iraqi military revolved more around the fear of what Saddam might do than what the Iranians might do.<sup id="fnref:senior-fear" role="doc-noteref"><a href="#fn:senior-fear">1</a></sup></p>
</blockquote>

<blockquote>
  <p>by the middle of the war, Saddam was making a serious effort to inform himself about military matters in order to understand what was happening. However, Saddam was the only decision maker,<sup id="fnref:educate" role="doc-noteref"><a href="#fn:educate">2</a></sup></p>
</blockquote>

<p>Technocratic middle managers were spending most of their energy undoing their leader’s bad decisions, rather than fighting and winning.
There’s a spectrum between ‘own worst enemy’ and ‘annoying bandwidth bottleneck’, but new managers generally are on it somewhere.</p>

<p>Over-centralization of authority sends a message that people shouldn’t act on their own, which paralyzes your org.
Note that I’m not arguing against hierarchical authority or a clear chain of command, but rather against authority all concentrating at the top, making it impossible for middle managers to do their jobs.
In Vietnam:</p>

<blockquote>
  <p>few officers who had come up in the Diem system were willing to do anything “in the absence of detailed orders.”<sup id="fnref:detailed" role="doc-noteref"><a href="#fn:detailed">3</a></sup></p>
</blockquote>

<p>Centralization also hamstrings the flexibility of a large team to adapt to new information.
Top leaders, often lacking domain skill or up-to-date information, are best at ‘do nothing without asking me’ orders that trap middle managers in bad positions.
In one case:</p>

<blockquote>
  <p>Because Saddam had decreed that units were not allowed to cede any ground, the Iraqi defense was poorly coordinated and ineffective, eventually inducing panic.<sup id="fnref:panic" role="doc-noteref"><a href="#fn:panic">4</a></sup> …
Iraqi officers in the field lacked the authority to redeploy forward troops or to call on reserves.</p>
</blockquote>

<p>And because the dictators aren’t an expert in any part of the organization, lack the attention to focus on everything at once, and aren’t accountable to anyone, they have zero memory.
In one case in Vietnam, President Thieu’s personal intervention not only disrupted the existing strategy, but he had forgotten by the next day that he’d given the order.</p>

<blockquote>
  <p>sudden change in orders from an uninformed Thieu was a disaster, resulting in neither a robust defense of the city nor a clean withdrawal.<sup id="fnref:sudden-change" role="doc-noteref"><a href="#fn:sudden-change">6</a></sup> … Amazingly … Hue’s abandonment apparently came as a surprise to President Thieu<sup id="fnref:abandonment" role="doc-noteref"><a href="#fn:abandonment">7</a></sup></p>
</blockquote>

<p>Unaccountable, illogical plans from inexpert leaders create hills to die on, in some cases literally.
They also come through unusual channels (because hands-on leaders prioritize fast action).
Unusual channels = coordination and preparation impossible for middle managers.
In one case in South Vietnam, a general:</p>

<blockquote>
  <p>personally interceded at all levels, sometimes going so far as to personally issue orders by radio to individual brigade commanders without notifying the division operations center. Both Giai and his division advisers often learned of new orders only as they were being carried out.<sup id="fnref:all-levels" role="doc-noteref"><a href="#fn:all-levels">8</a></sup></p>
</blockquote>

<p>By comparison, the North Vietnamese had good delegation and sane command structures in place.
From an internal document, they valued:</p>

<blockquote>
  <p>“unanimity of thought from the top to the bottom regarding the opportunity we faced and the tactics to be employed” but significant room for commanders to execute their plans<sup id="fnref:unanimity" role="doc-noteref"><a href="#fn:unanimity">9</a></sup></p>
</blockquote>

<p>After the American revolution, George III was having a conversation with his American portraitist Benjamin West; he heard Washington was going to resign his commission and ‘return to his farm’.
The King was like ‘ha pull the other one’, recognizing that giving up power is very hard, and said something like ‘<em>if</em> he does it I take back everything I said about the guy.’
The point is that accepting the limits to authority is hard, but also critical for good leaders.</p>

<h2 id="managing-up">Managing up</h2>

<p>One of the lessons of 2020 is probably that sometimes the only person in the room who can stop a bad outcome is a middle manager,
and often they can only do it by managing up, not through direct action.</p>

<p>Middle managers are frequently in situations where their domain skills are better than senior leadership –
either because they’re technocrats with domain skills,
or because they’re dealing with the problem day-to-day and have better information, or both.</p>

<p>We still get shouted down a lot, resulting in waste:
of money, of time, of resources, of opportunities, of morale.
In a war it can be lives.</p>

<p>We speak out a few times but eventually converge to inaction as your <a href="https://danluu.com/wat/">wtfs trail off</a>.
We give up because we’re tired, but that’s not all of it:
We stop arguing because when a leader experiences argument as dissent, their reactions are unpredictable and poison the team.</p>

<p>The way around this way of thinking is to
(1) make very sure that you’re very right when you pick a fight with your boss,
(2) fight for better delegation, not just a correct decision this one time.
And (3) remember that if you succeed, things get permanently better; these are hard fights but companies need them to grow.</p>

<p>Middle managers are the only people who have the authority and connections to fight these fights.
That’s why they leak, that’s why they manage up.
The organization will fail if we don’t.
Employees depend on companies to put food on the table; you do have a moral obligation to help your employer not fail (if you can) (barring circumstances like if <a href="https://www.youtube.com/watch?v=hn1VxaMEjRU">you’ve looked at these caps recently</a>).</p>

<p>I saw a <a href="https://twitter.com/FutureDocs/status/938173926953443328">JAMA article</a> about ‘professional silence’ by doctors.
Silence is not golden when an important argument is being suppressed.</p>

<p>Senior technocrats have a surprising amount of power when they align their story and band together. For Saddam, years into the war:</p>

<blockquote>
  <p>Iraqi generals blamed Saddam’s military organizational practices for both sets of losses, raising a serious danger of overthrow from within<sup id="fnref:blame" role="doc-noteref"><a href="#fn:blame">10</a></sup></p>
</blockquote>

<p>Because his leadership style was in conflict with their technical skills.
He punished losses in ways that deterred ground commanders from requesting backup, creating a losing cycle:</p>

<blockquote>
  <p>Saddam put great pressure on Iraqi commanders on the ground to avoid losses, which led them not to report failures. Withholding losses from reports and thus not receiving reinforcements or other support left commanders in impossible combat conditions. However, this was better than reporting their failures and suffering execution.<sup id="fnref:pressure" role="doc-noteref"><a href="#fn:pressure">11</a></sup></p>
</blockquote>

<blockquote>
  <p>The command-and-control system was incapable of transmitting the true tactical situation. Senior Iraqi officers later noted that they often got more timely information from the media than they did from their own commanders at the front.<sup id="fnref:media" role="doc-noteref"><a href="#fn:media">12</a></sup></p>
</blockquote>

<p>In Vietnam, General Phu, a technocrat middle manager who had been brought in to fix the South Vietnamese army’s problems, tried to use his authority to salvage a bad campaign and was talked down.</p>

<blockquote>
  <p>Phu, who previously had enjoyed an excellent reputation as commander of the 1st Division, expressed grave reservations about the operation to those around him, complaining that he had done it only because of Thieu’s order<sup id="fnref:reservations" role="doc-noteref"><a href="#fn:reservations">13</a></sup></p>
</blockquote>

<p>President Thieu’s realtime intervention, leading to a bad loss, demoralized him and he was never able to lead again:</p>

<blockquote>
  <p>Thieu’s absurd order to withdraw immediately from the Central Highlands essentially caused another corps commander, General Phu, …</p></blockquote></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://abe-winter.github.io/book/review/2020/06/04/dictators-army.html">https://abe-winter.github.io/book/review/2020/06/04/dictators-army.html</a></em></p>]]>
            </description>
            <link>https://abe-winter.github.io/book/review/2020/06/04/dictators-army.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25249332</guid>
            <pubDate>Mon, 30 Nov 2020 00:03:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Keep Data Consistency During Database Migration]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25249208">thread link</a>) | @wb14123
<br/>
November 29, 2020 | https://www.binwang.me/2020-11-29-Keep-Data-Consistency-During-Database-Migration.html | <a href="https://web.archive.org/web/*/https://www.binwang.me/2020-11-29-Keep-Data-Consistency-During-Database-Migration.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="article_content">
<article id="post">
  <header>
    
    
      <p>Posted on 29 Nov 2020, tagged <code>database</code><code>distributed system</code><code>consistency</code></p>
    
  </header>

  <p>When a system has been live for a long time, it’s not rare to use newer technologies to improve performance, maintainability, or add new features. One of such changes can be which database to use. This can be the most difficult kind of change. During the migration, there are two data sources, which makes it a distributed system. Make data consistent under a distributed system is very hard and can easily go wrong. In this article, we will explore a way to keep the data consistent during the migration, and maintain a low downtime at the same time.</p>

<h2 id="requirements">Requirements</h2>

<p>There are some requirements in order to use the way described in this article:</p>

<ul>
  <li>The source database support capture data change (CDC) method like MySQL bin log.</li>
  <li>The source database can be dumped with a consistent view and mark the position in data change logs.</li>
  <li>The target database support ACID transactions.</li>
  <li>Both source and target database support read and write permission control.</li>
</ul>

<h2 id="steps">Steps</h2>

<p>There are two basic ideas behind the steps:</p>

<ol>
  <li>The clients only write to one of the databases at a given time. So we can avoid distributed transaction which is error prone and slow.</li>
  <li>We make the switch of database by setup the database permissions. It’s faster than switch from client code and easier to make sure to switch all the clients.</li>
</ol>

<p>Here are the detailed steps:</p>

<h3 id="1-dump-the-source-database-to-target-database">1. Dump the source database to target database</h3>

<p>First, we need to dump the source database with a consistent view. And mark the position we’ve dumped. For example, in MySQL, you can use <code>mysqldump</code> with <code>--master-data</code> to dump the database with a bin log position. (<a href="https://dev.mysql.com/doc/refman/8.0/en/mysqldump.html#option_mysqldump_master-data">Document about the usage</a>). After we get all the data from source database, we can insert them into the target database.</p>

<p>Since this is the first step, it’s very easy to handle failure: just start again from beginning. So it’s very important to capture any error while import the dumped data.</p>

<h3 id="2-capture-changes-from-source-to-target">2. Capture changes from source to target</h3>

<p>The next step is to use the capture data changes from the source database. For example, in MySQL, you can use <a href="https://dev.mysql.com/doc/refman/8.0/en/binary-log.html">bin log</a> to capture the changes and insert them to the target database. Since we have the start position from last step, we know where to start parse and import the changes.</p>

<p>It’s very important to keep order of the changes while importing. So it’s better to use only one process to parse and import the changes. This part is challenging: the performance matters here. <strong>The time to sync all the changes is the downtime we need for migration</strong>.</p>

<p>We also need to make sure we don’t miss any changes or import any changes multiple times even there are system failures. So it’s very important to record the change log position. It’s convenience to write the position into the target database with the same transaction that imports the data. So the position will be synced with the data we imported.</p>

<h3 id="3-deny-writes-to-the-target-database-from-clients">3. Deny writes to the target database from clients</h3>

<p>The easy way to keep data consistency is to have a single source of truth. Until now, we are using the source database as the source of truth and sync changes to the target database. We don’t want to mess up the target database with other writes. So we need to setup the target database permission to deny all the writes from clients. For example, in MySQL, you can grant only <code>select</code> permission to the table for the clients and deny other operations. We allow the read permission so that we can compare the read results at the next step.</p>

<h3 id="4-modify-the-clients-to-read-and-write-both-databases">4. Modify the clients to read and write both databases</h3>

<p>The next step is to make the clients to read and write both source and target databases.</p>

<p>We want to read/write source database first. Use this result if there is no permission error, use the read/write result from target database otherwise.</p>

<p>The read/write to target database has two purposes:</p>

<ol>
  <li>Before switch to the target database, we can verify the target database works as expected by compare read results and write operations. Note that the target database may have lag to sync up, so the results may not always the same. But we can have an understanding of the correctness based on the percentage of same results.</li>
  <li>After we switch to the target database, the read/write results will be used as the real results.</li>
</ol>

<p><strong>If you want to make sure the target database can handle the load, it’s a good idea to allow read/write to the target database for a while .But it’s just as a verification, the data in the target database will not be consistent after that. So after we verify the target database can handle the traffic, we need to cleanup the target database and start from step 1 again.</strong> (We don’t need to modify the client code during the steps).</p>

<p>For the error handling, there are two key points:</p>

<ol>
  <li>Only use target database result if there is permission error from source database. Throw other errors from source database.</li>
  <li>Ignore errors for the target database if the result is not used but make sure to log them, so that it will not affect the current operation while also make sure we don’t have errors before the switch.</li>
</ol>

<p>The client code would be like this:</p>

<div><div>
  <div><pre><span> <a href="#n1" name="n1">1</a></span>db_operation() {
<span> <a href="#n2" name="n2">2</a></span>  try {
<span> <a href="#n3" name="n3">3</a></span>    source_result = source_db_operation()
<span> <a href="#n4" name="n4">4</a></span>  } catch (PermissionException e) {
<span> <a href="#n5" name="n5">5</a></span>    return target_db_operation()
<span> <a href="#n6" name="n6">6</a></span>  }
<span> <a href="#n7" name="n7">7</a></span>  async {
<span> <a href="#n8" name="n8">8</a></span>    // do the following things async so it will not impact the performance
<span> <a href="#n9" name="n9">9</a></span>    try {
<span><strong><a href="#n10" name="n10">10</a></strong></span>      target_result = target_db_operation()
<span><a href="#n11" name="n11">11</a></span>      compare_result(source_result, target_result)
<span><a href="#n12" name="n12">12</a></span>    } catch (Exception e) {
<span><a href="#n13" name="n13">13</a></span>      log_error(e)
<span><a href="#n14" name="n14">14</a></span>    }
<span><a href="#n15" name="n15">15</a></span>  }
<span><a href="#n16" name="n16">16</a></span>  return source_result
<span><a href="#n17" name="n17">17</a></span>}
</pre></div>
</div>
</div>

<h3 id="5-deny-access-to-the-source-database-from-clients-and-wait-for-changes-to-by-synced">5. Deny access to the source database from clients and wait for changes to by synced</h3>

<p>After we are confident with the read and write to the target database, we can make the switch. We switch the database by change the database permissions. First, we deny all the access to the source database from clients. Then we wait for the changes to be full synced to the target database. During this time, the system is down. So how fast the changes are synced from source database to target database determines how much down time it will be.</p>

<h3 id="6-allow-write-to-target-database">6. Allow write to target database</h3>

<p>After the target database is fully synced, we can enable the target database permission for all the clients. After this, the system should be online again and the database is fully switched over.</p>

<h3 id="7-optional-fallback-to-source-database-if-anything-goes-wrong">7. Optional: Fallback to source database if anything goes wrong</h3>

<p>It’s good if everything works well so far. But that may not always the case. Maybe the target database cannot handle the new traffic (that’s why it’s important to test it in step 4). In this case, we need fallback to the source database.</p>

<p>If it’s fine to lost committed data during the migration time, it would be relatively easy to fallback:</p>

<ol>
  <li>Allow access to the source database. After this, the clients should be using the source database again.</li>
  <li>Cleanup the target database and start from the beginning.</li>
</ol>

<p>If it’s critical to save the committed data and make sure they are consistent, then before step 5, we should setup a mechanism to capture changes from target database to source database, and mark the change position after step 6. Then the fallback steps would be:</p>

<ol>
  <li>Deny all the writes to target database.</li>
  <li>Sync from target database to source database (make sure to stop it after fully synced).</li>
  <li>Allow access to the source database.</li>
  <li>Cleanup the target database and start from the beginning again.</li>
</ol>

<p>The sync from target database to source database is very dangerous and hard to test, so it’s really important to test the target database can handle the operations in step 4.</p>

<h3 id="8-cleanup-client-code">8. Cleanup client code</h3>

<p>Once the database is switched to the target database, we can cleanup the code that access the source database. Then the database is fully migrated and you can enjoin it!</p>

</article>







<!-- MathJax -->




</div></div>]]>
            </description>
            <link>https://www.binwang.me/2020-11-29-Keep-Data-Consistency-During-Database-Migration.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25249208</guid>
            <pubDate>Sun, 29 Nov 2020 23:43:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Making Playstation 1 Modchips (2018)]]>
            </title>
            <description>
<![CDATA[
Score 91 | Comments 36 (<a href="https://news.ycombinator.com/item?id=25248660">thread link</a>) | @cwaffles
<br/>
November 29, 2020 | https://blog.kchung.co/making-playstation-modchips/ | <a href="https://web.archive.org/web/*/https://blog.kchung.co/making-playstation-modchips/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
    <article>

        

        <section>
            <p>When I was young I owned a PlayStation 1 (PS1). It was one of the first, if not the first, game consoles I owned and it had a profound effect on my future. </p>

<p>I can trace the history of how I got involved in computers back to playing and modding video games. While I wasn't smart enough to mod game consoles when I was young, my dad wasn't bad at it. He modded my PS1 to have a little switch in the back that would allow it to play burnt games. They say the apple doesn't fall far from the tree. </p>

<p>Fast-forward to today and I no longer have my original PS1. I remember some games wouldn't load anymore and I had gotten a PS2. So why keep an old console? Turns out the answer is nostalgia and memories. You miss what you don't have anymore.</p>

<p>Recently a friend gifted me a PS1. And so then the journey begins, how do I mod this thing? </p>

<blockquote>
  <p>If you are looking for them I am selling <a href="http://rover.ebay.com/rover/1/711-53200-19255-0/1?icep_ff3=2&amp;pub=5575378759&amp;campid=5338273189&amp;customid=&amp;icep_item=223024408143&amp;ipn=psmain&amp;icep_vectorid=229466&amp;kwid=902099&amp;mtid=824&amp;kw=lg&amp;toolid=11111">flashed, prewired modchips</a>. </p>
</blockquote>



<p>Very simply, the principles behind PS1 DRM work as follows:</p>

<ol>
<li>Sony baked (not the technical term) strings (i.e. <code>SCEA</code>, <code>SCEI</code>, <code>SCEE</code>, or in rare cases <code>SCEW</code>) into official PS1 games in locations which cannot be replicated by a regular reader. <a href="https://www.youtube.com/watch?v=XUwSOfQ1D3c">This video</a> and <a href="http://www.psxdev.net/forum/viewtopic.php?t=128">this post</a> discuss it reasonably well.  </li>
<li>The CD drive controller looks for those strings to identify a disc as official. Once the controller decides that the disc is/isn't official, the main CPU reads this decision and acts accordingly.  </li>
<li>If the string can't be found or is garbled, the PS1 knows the disc isn't an <strong>authentic</strong> PS1 game. However, because the PS1 needs to account for disc read errors, there's a good amount of leeway in what passes the authenticity check.  </li>
<li>Because region <small>(<strong>A</strong> for America, <strong>I</strong> for Japan, <strong>E</strong> for Europe, and <strong>W</strong> for <a href="https://en.wikipedia.org/wiki/Net_Yaroze">Net Yaroze</a>)</small> as well as authenticity are rolled into one string, Sony kills two birds with one stone here and achieves region locking as well as copy protection. </li>
</ol>

<blockquote>
  <p>If you want a real in-depth discussion you can read <a href="http://www.oldcrows.net/mcc2.html">the original posts by The Old Crow</a> or the <a href="https://problemkaputt.de/psx-spx.htm#cdromprotectionmodchips">No$PSX documentation page</a> or this <a href="http://psx-scene.com/forums/f10/psx-modchip-faq-64110/">Modchip FAQ</a></p>
</blockquote>

<p>PSX modchips work by electrically stifling the output originally generated by whatever CD is inside the drive and then injecting a new, faked signal into the CD microcontroller. This causes the PS1 to believe that whatever disc is inside is legitimate and proceed to boot up. </p>

<p>Later on Sony added more complicated checks like:</p>

<ul>
<li>Checking for the magic strings during the game instead of at boot </li>
<li>Changing the overall process to make it more difficult to bypass by simply emitting the correct strings.</li>
</ul>

<p>However, modern modchips already deal with this. Modchips that work under these updated circumstances are known as "stealth modchips" because the console shouldn't be able to detect them at all. </p>



<p>The first "open source" modchip was reverse engineered by a guy named "The Old Crow". Surprisingly, The Old Crow specializes in electronic music synthesizers, not hacking video game consoles. It's from his modchip that most other modchips are derived from in some sense. He originally reverse engineered a commercial PS1 modchip that was designed by a western engineer working for a Chinese company. </p>

<p>Today, there are three main modchips which are still used by the community today.</p>

<p>The modchips include:</p>

<ul>
<li><a href="https://quade.co/ps1-modchip-guide/mm3/">Multimode 3 (MM3)</a></li>
<li><a href="https://quade.co/ps1-modchip-guide/mayumi-v4/">Mayumi v4</a></li>
<li><a href="https://github.com/kalymos/PsNee">PSNee</a></li>
</ul>

<p>The three have their pros and cons but generally they can be summarized as follows:</p>

<ul>
<li><p>MM3 is the most common PS1 modchip seen/used today. Its only real downside is that it uses an internal oscillator which can become out of sync with the oscillator used by the CD drive. If this happens you simply need to reboot your console to try reading again.  </p></li>
<li><p>Mayumi v4 attempts to use the oscillator used by the CD drive. This reduces the chance of the oscillator sync issue from happening; however, Mayumi v4 is considered a bit difficult to install. </p></li>
<li><p><a href="https://github.com/kalymos/PsNee">PSNee</a> is an open source modchip originally written by <a href="https://assemblergames.com/threads/psnee-a-stealth-modchip-for-all-ps1-models.57907/">TheFrietMan</a>. Development on it was <a href="http://www.psxdev.net/forum/viewtopic.php?t=1262">later continued by others</a> and it appears to work rather well on all Playstation 1/PSOne models. Based on the code I believe it attempts to infer where the PS1 is in the boot process to begin injecting fake <code>SCEX</code> strings. Unfortunately PSNee is complicated to install. The provided diagrams are atrocious and nowhere near as simple as the available diagrams for MM3 and Mayumi. I worked out <a href="https://gist.github.com/ColdHeat/be633b7eb6e25758ec80ae0115c1887a">the pinout for the Attiny45</a> but I ended up going with MM3 and Mayumi because it's easier. </p></li>
</ul>



<blockquote>
  <p>If you want them I am selling <a href="http://rover.ebay.com/rover/1/711-53200-19255-0/1?icep_ff3=2&amp;pub=5575378759&amp;campid=5338273189&amp;customid=&amp;icep_item=223024408143&amp;ipn=psmain&amp;icep_vectorid=229466&amp;kwid=902099&amp;mtid=824&amp;kw=lg&amp;toolid=11111">flashed, prewired modchips</a>. </p>
</blockquote>

<p>It's generally pretty easy to make a PS1 modchip provided you have the right tools. In this tutorial we will focus on making MM3 or Mayumi v4 modchips.</p>

<blockquote>
  <p>While I do have an Arduino, I prefer to use the MM3 and Mayumi chips over PSNee. If you want to make a PSNee modchip, you can follow the <a href="http://www.instructables.com/id/Program-an-ATtiny-with-Arduino/">instructions here</a> to flash the <a href="https://github.com/kalymos/PsNee/blob/master/PsNee.ino">.ino file</a> to your Attiny. </p>
</blockquote>

<p>You will need:</p>

<ul>
<li><a href="https://www.ebay.com/sch/i.html?_nkw=PIC12F508+DIP">Microchip PIC12F508</a></li>
<li><a href="https://amzn.to/2tfdeP0">PICkit 3</a>
<ul><li>Also download and install <a href="http://www.microchip.com/mplab/mplab-x-ide">MPLAB IPE</a> from the MPLAB X IDE package. </li></ul></li>
<li>Some kind of <a href="https://amzn.to/2llKUG7">wiring &amp; breadboard</a> to connect the PIC to to the PICkit.</li>
<li>HEX codes for the modchip of your choice (provided below).</li>
</ul>

<blockquote>
  <p>Many tutorials call for the PIC12C508. This is an old model and continuing to use them is unnecessary unless you have them stockpiled. HEX codes that work for the 12C will work for the 12F. </p>
</blockquote>

<p>To begin you should first look your IC and determine which leg is which. The leg nearest the imprinted circle is Pin 1. The leg opposite it is Pin 8. </p>

<p><img src="https://blog.kchung.co/content/images/2018/06/pic12f508-2.JPG" alt="This is a DIP chip. I accidentally got SOIC-8 (i.e. surface mount) and had to solder my chip to a breadboard but generally you can avoid that"></p>

<p>You can plug this into a bread board and then wire it into the Pickit according to the following diagrams. You want to match the following (the rest are unused for now):</p>

<ul>
<li>PICKit 1 ⟷ IC 4 (V<sub>PP</sub>)</li>
<li>PICKit 2 ⟷ IC 1 (V<sub>DD</sub>)</li>
<li>PICKit 3 ⟷ IC 8 (V<sub>SS</sub>)</li>
<li>PICKit 4 ⟷ IC 7 (ICSPDAT)</li>
<li>PICKit 5 ⟷ IC 6 (ICSPCLK)</li>
</ul>

<p><img src="https://blog.kchung.co/content/images/2018/06/pickit-12f508-1.jpg" alt="PICKit 3 on the left, PIC12F508 on the right"></p>

<p>Once you've properly wired up the chip, connect the PICKit to your computer and start MPLAB IPE. Under <code>Device</code> select <code>PIC12F508</code>. </p>

<p>Go into <code>Settings &gt; Advanced Mode</code>. The default password for <code>Advanced Mode</code> is <code>microchip</code>. I don't recommend changing it, not sure why the option is even available. </p>

<p>Go into the <code>Power</code> tab on the left and enable <code>Power Target Circuit from Tool</code>.</p>

<p><img src="https://blog.kchung.co/content/images/2018/06/Screen-Shot-2018-06-20-at-8.39.15-PM.png" alt=""></p>

<p>Go back to the <code>Operate</code> tab and hit <code>Connect</code>.</p>

<p><img src="https://blog.kchung.co/content/images/2018/06/Screen-Shot-2018-06-20-at-8.40.54-PM.png" alt=""></p>

<p>From here download the appropriate HEX code for your chip and console. They are different per console region. </p>

<ul>
<li><a href="https://raw.githubusercontent.com/wiki/ColdHeat/PsNeePy/hexcodes/mm3/MM3USA.HEX">MM3 for American Consoles</a></li>
<li><a href="https://raw.githubusercontent.com/wiki/ColdHeat/PsNeePy/hexcodes/mm3/MM3EUR.HEX">MM3 for European Consoles</a></li>
<li><a href="https://raw.githubusercontent.com/wiki/ColdHeat/PsNeePy/hexcodes/mm3/MM3JAP.HEX">MM3 for Japanese Consoles</a></li>
</ul>

<p>You can also use Mayumi v4 on the PIC12F508 if you choose.</p>

<ul>
<li><a href="https://raw.githubusercontent.com/wiki/ColdHeat/PsNeePy/hexcodes/mayumiv4/mayumi-usa4.hex">MayumiV4 for American Consoles</a></li>
<li><a href="https://raw.githubusercontent.com/wiki/ColdHeat/PsNeePy/hexcodes/mayumiv4/mayumi-eu4.hex">MayumiV4 for European Consoles</a></li>
<li><a href="https://raw.githubusercontent.com/wiki/ColdHeat/PsNeePy/hexcodes/mayumiv4/mayumi-jap4.hex">MayumiV4 for Japanese Consoles</a></li>
</ul>

<p>In the <code>Source</code> file, select your hex code. </p>

<p>Hit the big <code>Program</code> button. </p>

<p>You should see something similar to the following text:</p>

<pre><code>2018-06-20 20:48:02 -0400 - Loading hex file. Please wait...  
Loading code from /Users/kchung/Repositories/PsNeePy.wiki/hexcodes/mm3/MM3USA.HEX...  
2018-06-20 20:48:03 -0400 - Hex file loaded successfully.

2018-06-20 20:48:20 -0400 - Programming...

Device Erased...

Programming...

The following memory area(s) will be programmed:  
program memory: start address = 0x0, end address = 0x1e7  
configuration memory  
Programming/Verify complete  
2018-06-20 20:48:25 -0400 - Programming complete  
</code></pre>

<p>If you'd like, you can hit the <code>Verify</code> button to make sure that your flash was correct. Your output should look something like the following:</p>

<pre><code>2018-06-20 20:50:10 -0400 - Verifying...

Verifying...

The following memory areas(s) will be verified:  
program memory: start address = 0x0, end address = 0x1ff  
configuration memory  
User Id Memory

Verification successful.  
2018-06-20 20:50:13 -0400 - Verify complete  
</code></pre>

<p>From here you can follow online diagrams for soldering your chip to the PSX that you own. I personally used <a href="https://quade.co/ps1-modchip-guide">William Quade's excellent diagrams</a> and think you should as well.   </p>



<p>While looking at all these modchips, I figured it would be nice to read and write Python code instead of Assembly and C code so I started working on porting PSNee to Python. </p>

<p>By using <a href="https://micropython.org/">MicroPython</a> and an <a href="https://amzn.to/2K4HdTq">ESP8266</a> we can actually create a modchip that we can remotely update and modify through the <a href="https://amzn.to/2K4HdTq">ESP8266</a>'s WiFi.  </p>

<p><img src="https://blog.kchung.co/content/images/2018/06/IMG_1084.jpg" alt="Effectively the very first WiFi enabled PS1!"></p>

<p>In the above photo (SCPH-7501), the ESP8266 is on the top left with the headers face up. The wires connect to the headers and route under the CD drive to a breadboard on the bottom right. </p>

<blockquote>
  <p>The breadboard has wires that are soldered to the correct MM3 points and then labeled with the corresponding pin number. By using this breadboard I can test modchips that I make much faster than soldering to the board over and over again. </p>
</blockquote>

<p>My modchip (named PsNeePy) is available on Github: <br>
<a href="https://github.com/ColdHeat/PsNeePy">https://github.com/ColdHeat/PsNeePy</a></p>

<p>While my test console is quite bad at reading discs and the console rarely boots into games, the modchip does work. </p>

<blockquote>
  <p>For the most part (ignoring stealth functionality), modchips are known to be working once you reach the black Playstation logo screen as this indicates that the CPU considers the game authentic. </p>
</blockquote>

<p>However, because the code is based off an older version of PSNee, stealth functionality does not seem to work on some newer PS1 revisions.</p>

<p>I mostly created this as a proof of concept and I'm unlikely to maintain it very much. While I don't recommend using my modchip, I hope that the community adopts it and helps improve it. Despite being a dead console, the PSX community is fairly active. </p>

<p>With <a href="https://github.com/ColdHeat/PsNeePy">PsNeePy</a>, you can remotely update the ESP8266 over WiFi, debug remotely, and also reset the chip easily. Having spent many hours working on the PS1 at this point, a more modern experience is quite refreshing. </p>

<p><img src="https://blog.kchung.co/content/images/2018/06/Screen-Shot-2018-06-21-at-2.47.33-AM.png" alt="Remotely controlling the modchip"></p>

<p>Thanks to an anonymous friend for my PS1, Sharan for fixing my PS1, <a href="https://quade.co/">William Quade</a> for the excellent diagrams, AssemblerGames for having good information despite not accepting me into the forum, and PSXDEV for answering some of my questions.</p>
        </section>

        

    </article>
</div></div>]]>
            </description>
            <link>https://blog.kchung.co/making-playstation-modchips/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25248660</guid>
            <pubDate>Sun, 29 Nov 2020 22:24:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A layered approach to testing microservices]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25248627">thread link</a>) | @karlhughes
<br/>
November 29, 2020 | https://www.karllhughes.com/posts/testing-layers | <a href="https://web.archive.org/web/*/https://www.karllhughes.com/posts/testing-layers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
<article>
<div>
<p><img src="https://www.karllhughes.com/assets/img/testing-microservices.png" alt="Testing Microservices: A Layered Testing Strategy">
</p> 

<p>
2020, Nov 29&nbsp;&nbsp;&nbsp;—&nbsp;
9 minute read
</p>
<section id="mc_embed_signup">

</section>
<p>We made some <a href="http://www.thegraidenetwork.com/blog-all/2017/1/16/tech-accomplishments">considerable improvements to the tech stack</a> at The Graide Network during my years at the company, but one of the things I’m most proud of is our automated testing system. In this post, <strong>I’ll outline our strategy for testing microservices using layers of unit, integration, acceptance, and end-to-end tests.</strong></p>
<p>We used tests to deploy our microservices faster and with very few defects. Along the way, I’ll offer some other resources that we found helpful as we designed a robust testing system for our microservices.</p>
<h2 id="the-importance-of-software-testing">The Importance of Software Testing</h2>
<p>First, why do we care about testing our software anyway?</p>
<p><img src="https://www.karllhughes.com/assets/img/cost-of-tests-over-time.png" alt="The cost of automated software tests over time"></p>
<p>While testing adds time to the software development life cycle, it <a href="https://www.karllhughes.com/posts/testing-matters">pays dividends in the long run</a>. I’m not going to harp on this topic here, but in my experience, automated tests:</p>
<ul>
<li>Help prevent defects from reaching production</li>
<li>Lower the risk of regressions</li>
<li>Push developers to use better architectural patterns</li>
<li>Enhance your documentation</li>
<li>Guide code reviewers</li>
<li>Make it easier to add new features later</li>
<li>Help developers debug tricky edge cases</li>
</ul>
<p>When using microservices, these factors are all important, but as you’ll see, the distributed nature of this pattern adds an extra challenge.</p>
<h2 id="our-architecture-and-testing-strategy">Our Architecture and Testing Strategy</h2>
<p>When I joined The Graide Network in the fall of 2016, there were no tests; no way to tell if something was wrong on the site; no way to catch bugs before they went into production. Needless to say, we couldn’t ship much code in the first few weeks.</p>
<p>So, we started to invest in a test suite by writing some Behat tests in <a href="http://mink.behat.org/en/latest/">Mink</a>. Our application wasn’t written to be tested, so unit tests were initially next to impossible, but behavior-driven tests gave us at least a little confidence to start refactoring to microservices.</p>
<p>Over the next few months, we’ve built out six microservices on the backend, an <a href="https://angular.io/">Angular</a> frontend application, and made some major improvements to slim down the legacy application. At a high level, our architecture looks something like this:</p>
<p><img src="https://i.imgur.com/kQrADqw.png" alt="Our microservices architecture"></p>
<h2 id="microservice-testing-resources">Microservice Testing Resources</h2>
<p><strong>One of our biggest challenges in managing a microservice architecture is testing.</strong></p>
<p>This seems to be a common problem for architects who choose microservices; we’re far from the first company to encounter and solve this problem. One of the most helpful resources I’ve found is Martin Fowler’s <a href="https://martinfowler.com/articles/microservice-testing/">Testing Strategies in a Microservice Architecture</a>, which I would strongly recommend.</p>
<p>I’d also recommend picking up <a href="https://amzn.to/2K4UDQL">Microservices in Action</a> by Morgan Bruce and Paulo Pareira. While they don’t talk about testing specifically much, they do offer some tips for monitoring, tracing, and continuous delivery of your microservices.</p>
<p>Finally, take a look at <a href="https://amzn.to/2IJES1b">Susan Fowler’s Production-Ready Microservices</a>. I liked her perspective based on Uber’s massive microservice architecture as they deal with a level of scale and fault tolerance I can only imagine.</p>
<p>While all of the resources above offer great general advice, I will focus on the details of our microservices testing strategy in the remainder of this post. I hope this gives you a better handle on what this might look like in practice.</p>
<h2 id="our-layered-microservice-testing-strategy">Our Layered Microservice Testing Strategy</h2>
<p>Each of our microservices and each frontend application lives in its own repository and on its own server, so everything is highly decoupled. The great thing about this is that we can switch components out and upgrade individual APIs without taking the whole system down. The challenge with this architecture is figuring out how to test each service without standing up all the services it depends on.</p>
<p>Our testing strategy is broken down into several layers within each application and integration layers around multiple components of the application. These layers are based on the well-known <a href="https://automationpanda.com/2018/08/01/the-testing-pyramid/">testing pyramid</a> concept.</p>
<p><img src="https://i.imgur.com/Tyryn3G.png" alt="Software testing pyramid"></p>
<h3 id="layer-1-api-tests">Layer 1: API tests</h3>
<p>Each API (or microservice) is written in <a href="https://laravel.com/">Laravel</a>, and communicates with internal APIs, external APIs, and a database over an HTTP or TCP connection. These are pretty typical PHP applications, but they return JSON responses instead of serving up user views.</p>
<p>As for testing, we use a mix of unit, integration, and acceptance tests as seen here:</p>
<p><img src="https://i.imgur.com/R5KyCsC.png" alt="A single microservices tests broken out by class"></p>
<h4 id="a-unit-tests">A. Unit tests</h4>
<p><img src="https://i.imgur.com/zGYeTJe.png" alt="unit tests"></p>
<p>Since we rely on a well-tested framework, we choose not to test some components which are already adequately tested in Laravel. While a lot of developers put application logic in their controllers, we keep our controllers slim and instead pass off most of the business logic to Jobs, Repositories, and Models, but pretty much every custom layer in the application is unit tested.</p>
<h4 id="b-integration-tests">B. Integration tests</h4>
<p><img src="https://i.imgur.com/uWsqseu.png" alt="integration tests"></p>
<p>Some pieces of the application lend themselves especially well to integration tests. For example, the <a href="https://laravel.com/docs/5.4/eloquent">Eloquent Models</a> we write are so tightly bound to the database that it’s convenient - and more productive - to integration test them with a real database connection rather than try to mock it.</p>
<p>We keep our models slim, so our integration tests just verify that they retrieve data from the data as we would expect. For example, here’s a typical model in our Assignments API:</p>
<div><div><pre><code><span>&lt;?php</span> <span>namespace</span> <span>GraideNetwork\Assignments\Models</span><span>;</span>

<span>use</span> <span>GraideNetwork\Base\Models\AbstractModel</span><span>;</span>
<span>use</span> <span>Illuminate\Database\Eloquent\SoftDeletes</span><span>;</span>

<span>class</span> <span>Inquiry</span> <span>extends</span> <span>AbstractModel</span>
<span>{</span>
    <span>use</span> <span>SoftDeletes</span><span>;</span>

    <span>protected</span> <span>$dates</span> <span>=</span> <span>[</span><span>'deleted_at'</span><span>];</span>

    <span>protected</span> <span>$guarded</span> <span>=</span> <span>[</span>
        <span>'created_at'</span><span>,</span>
        <span>'updated_at'</span><span>,</span>
        <span>'deleted_at'</span>
    <span>];</span>

    <span>public</span> <span>function</span> <span>assignment</span><span>()</span>
    <span>{</span>
        <span>return</span> <span>$this</span><span>-&gt;</span><span>belongsTo</span><span>(</span><span>'GraideNetwork\Assignments\Models\Assignment'</span><span>);</span>
    <span>}</span>

    <span>public</span> <span>function</span> <span>scopeGraiderRequest</span><span>(</span><span>$query</span><span>,</span> <span>$userId</span> <span>=</span> <span>null</span><span>)</span>
    <span>{</span>
        <span>return</span> <span>$query</span><span>-&gt;</span><span>where</span><span>(</span><span>'type'</span><span>,</span> <span>config</span><span>(</span><span>'enums.inquiry_types.REQUEST'</span><span>))</span>
            <span>-&gt;</span><span>where</span><span>(</span><span>'graider_id'</span><span>,</span> <span>$userId</span><span>);</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>
<p>Our integration tests for this model just need to check two things:</p>
<ul>
<li>If we query this model using <code>with('assignment')</code>, does it return its parent assignment?</li>
<li>If we query this model using the <code>graiderRequest($userId)</code> scope, will it find all Inquiries that are of the <code>type</code> <code>Request</code> and where the <code>graider_id</code> matches the <code>$userId</code> passed in.</li>
</ul>
<p>We try to test the unhappy cases as well (eg: if we query without the <code>with('assignment')</code> argument, it should <em>not</em> retrieve the parent assignment).</p>
<h4 id="c-acceptance-tests">C. Acceptance tests</h4>
<p><img src="https://i.imgur.com/53jOK7E.png" alt="acceptance tests"></p>
<p>Let me make a distinction here: <strong>we call any tests that test a single microservice or frontend application “acceptance” tests, while tests that test the entire network of services and applications are called “end-to-end” tests</strong>. Your terminology may vary, but the distinction is important.</p>
<p>In order to run an acceptance test on an API, we test each microservice and its database connection <em>without</em> testing the other APIs in our system. We do this by mocking the HTTP Client at runtime and binding the mocked version of the client to Laravel’s application service provider. When we write each acceptance test, we just need to let the test know which mocked API calls will be made and what they will return. This effectively decouples our microservices for testing purposes.</p>
<h3 id="layer-2-http-client-library-tests">Layer 2: HTTP Client library tests</h3>
<p>We don’t test our internal API clients within each microservice because they are used in multiple places. So, we <a href="https://bitbucket.org/thegraidenetwork/tgn-clients">released a Composer Package</a> for our microservice HTTP clients and wrote unit and integration tests there.</p>
<p><img src="https://i.imgur.com/u0F1RAS.png" alt="Http client package tests"></p>
<h4 id="a-unit-tests-1">A. Unit tests</h4>
<p>The unit tests within our HTTP client package are pretty simple since our internal HTTP clients are just wrappers around <a href="http://docs.guzzlephp.org/en/latest/">Guzzle</a>. They ensure that parameters are passed in, transformed, and sent Guzzle and that the expected response is passed back to the caller.</p>
<h4 id="b-integration-tests-1">B. Integration tests</h4>
<p>Our HTTP client integration tests actually make calls to the microservices. These are still a work in progress, but the idea here is that these integration tests (in addition to each API’s internal acceptance tests) will help ensure that the APIs are responding as we expect.</p>
<h3 id="layer-3-frontend-tests">Layer 3: Frontend tests</h3>
<p>We have two frontend systems: our legacy application, which sits in front of all the microservices, and our Angular frontend app, which will eventually replace the legacy application. Since we’re moving away from the legacy frontend, I’ll omit it, although we do currently unit and end-to-end test that application as well.</p>
<p>As for the Angular frontend application, the testing layers look like this:</p>
<p><img src="https://i.imgur.com/qEyLDWs.png" alt="Angular frontend testing layers"></p>
<h4 id="a-unit-tests-2">A. Unit tests</h4>
<p>Just like with our backend code, we unit test each sub-layer within the Angular application by mocking any dependencies (<a href="https://angular.io/docs/ts/latest/guide/dependency-injection.html">Angular’s dependency injection makes this easy</a>) and using <a href="https://github.com/angular/angular-cli">Angular CLI</a> to wrap the Karma tests. As with any testable code, the key is to keep components lean, but I’m admittedly still learning a lot about the best way to structure an Angular app.</p>
<h4 id="b-integration-tests-2">B. Integration tests</h4>
<p>We don’t run end-to-end tests directly within our Angular app, but we do run integration tests with mocked API responses. This ensures that the entire Angular application is transforming and presenting data as we would expect, but it allows us to avoid requiring all of our backend microservices to be running just to run the test suite.</p>
<h3 id="layer-4-end-to-end-tests">Layer 4: End-to-End tests</h3>
<p><img src="https://i.imgur.com/ZXPhKa3.png" alt="end-to-end tests"></p>
<p>While <a href="https://testing.googleblog.com/2015/04/just-say-no-to-more-end-to-end-tests.html">some developers eschew comprehensive end-to-end test suites</a>, I do find that they hold some value, especially in preventing regression when your company is small and does not have dedicated testing resources (eg: our team at the Graide Network). But, I also realize that end-to-end tests are probably the least helpful in a microservice architecture as they don’t tell you on their own where something went wrong, just that it did.</p>
<p>So rather than build an end-to-end testing suite in our code (which application would it even “live” in?), we decided to use a third-party service called <a href="https://ghostinspector.com/">Ghost Inspector</a>, which automatically runs our end-to-end test suite twice per day on our dev server. Ghost inspector lets you record tests by simply clicking around your web app, so an intern or <a href="https://www.karllhughes.com/posts/product-management-process">even a product manager</a> can create tests in a pinch. Once recorded, Ghost will run the tests automatically at a specific time (or when triggered by your CI server) and report …</p></div></article></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.karllhughes.com/posts/testing-layers">https://www.karllhughes.com/posts/testing-layers</a></em></p>]]>
            </description>
            <link>https://www.karllhughes.com/posts/testing-layers</link>
            <guid isPermaLink="false">hacker-news-small-sites-25248627</guid>
            <pubDate>Sun, 29 Nov 2020 22:20:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Not Quite Nostalgia for the 1980s]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25248587">thread link</a>) | @vegadw
<br/>
November 29, 2020 | https://opinionatedguide.github.io/posts/xx80/ | <a href="https://web.archive.org/web/*/https://opinionatedguide.github.io/posts/xx80/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  
  
  <h5>September 27, 2020</h5>



  

  


  
<p>I stare at my amber terminal. Hexadecimal fills my screen and my mind has become lost in the flow of 6502 assembly, as I hand optimize the code flow.</p>
<p>I’m interupted when I recieve a message from my friend, _Maverik, he’s excited about the ground breaking CGI in Tron.</p>
<hr>
<p><strong>Nostalgia is a weird feeling.</strong> We can forget when things happened, and misttribute things to entirely different decades. But, I think there’s something even more interesting going on with the now-sorta-fading nostalgia for the 80’s that could be seen when 2014’s Guardian’s of the Galaxy (or Vol. 2 in 2017) or 2011’s Ready Player One book (and 2018 movie) were a huge deal. These movies aren’t just appealing to a generation of Millennials that are pissed off that the world is going to shit because of the mistakes of their parents and grandparents- they’re appealing to a generation of people that has only ever known that mess. The kids, like me, that are in the awkward spot of being told just how awful it was to watch the news on September 11th, 2001 but not actually directly rembering it.</p>
<p>So, why would we be nostalgic for a time that we were never alive for? I think it’s because we’re hopeful.</p>
<p>The 1980’s were not a better time really. The Cold War was still a thing, being publically LGBT was crazy, Chernobyl happened, Computers were still mostly 8-bit, Asbestos was still being used, and, despite the numbers declining already, cigaretts were still way more common.</p>
<p>All that aside, the was something the 80’s had that we don’t have now. I’m hesitent to call it ‘hope’ or ‘vision’, and honestly, I’m not sure there even is a good word for it. Regardless, I wasn’t even around to experiance it first hand given I wasn’t born until 1998. But, from what I’ve seen of the remnants, the parts that people try to remember- the good stuff that people drink as heavily sweetend, carbonanted nostalgia - there was an <em>atmosphere of possibility</em>. The Demo Scene was in full swing, as people pushed the 8-bit hardware of the time to it’s absolute limits. Computers were progressively being used to do more, impressive things. Culture from that era is portrayed in a way that gives you a mental image of crackin' a cold one and just enjoying life. Movies from the era- Back to The Future, Footloose, Weird Science - all told stories that were hopeful and fun and made a point of how the future is going to be better.</p>
<p>It took me a while to realize all of this, but I’m not nostalgic for the 1980’s. I’m nostalgic for the xx80’s. A time that only exists in the minds of people like me, nostalgic for something they never experienced. The next cultural revolution where we can band together under a banner of making things better. Where technological advancements have postivie cultural impact instead of negitive. Where the talk of the year isn’t about how damn partisan we are but is about the power of humanity to do amazing things. It just happens that having some sort of outlet to map that nostalgia to is helpful, and that the 1980’s that kids from that era remember is the best analogy that people of my generation have. So when I wear a shirt with Rocket Raccon or put up art of the Comodore 64, I’m not showing my admiration for those things themselves. I know the <em>real</em> 1980’s weren’t that. Instead I’m giving myself physical reminders of a place and time that only exists in my own mind and making that much more concrete my dreams for a better future.</p>
<p>Instead, for now, I’m stuck in real world. I’m in 2020 where my student loan debt is piling up, there’s a raging pandemic, and I fear that I’m watching the not-so-perfect union around me crumble. But, then I look around my room, and I see the ‘retro’ tech and art, and for a little while I feel like it might be possible that we’ll do better, that maybe I’ll live to see the xx80’s come.</p>
<p>So for those that are older than me, please don’t mistake our hope for blind romanticism or a warped-sense of nostalgia. We know. I don’t think I was born in the worng generation because I didn’t experiance the 1980’s. I’m pissed that the time I did get to experiance as a kid and that I’m living in now has been ruined by giant media conglomerates, corrupt politicians, broken social values, and people that have resigened themsevles to an attidude of “it’s going to hell anyway, so why bother?”. You got IRC, I get spyed on and manipulated by Facebook. You got real movies, I got sequels. I’m not going to pretend my generation is unique in dealing with the mistakes of the last, but instead of having hope we have record rates of suicide and depression. It’s just that it’s easier to have physical attachment and hope mentally assigned to something that’s already happened than it is to have blind faith in the future.</p>
<p><img src="https://opinionatedguide.github.io/c64art.jpg" alt="c64"></p>
<blockquote>
<p>The following response is from Nicole Replogle, born in 1984.</p>
</blockquote>
<p>The 80s represented a time when the future had limitless potential. When everyone was excited to see what the next decade held in store. The boomers had the opportunity to realize that future, and instead of making something good and beautiful and exciting, they made sure they had the distinction of being the first –and <em>last</em>– generation to ever have that kind of opportunity. There’s so much 80s stuff right now… thinking about Stranger Things, and then stuff like I Am Not Okay With This which is like, present time with the serial numbers filed off in an “80s but make it gayer” kind of way… Even a lot of the “present day but with the numbers filed off” stuff feels like “present day but the future is open and maybe isn’t full of possibilities, but it’s not empty of it and that’s the best we can imagine”.</p>
<p>God, the future was so fucking <em>BRIGHT</em> in the 80s and I think a big part of why millennials are harder to fire up than gen Z is that we knew what life was like before and nobody knows how to process the loss of countless futures that they <em>witnessed</em> as children and young adults. We’re living with grief we can’t even begin to communicate and we’re going to live with it until we die.</p>
<p>Like, you know what’s had me fucked up for a couple weeks? I work so hard trying to live inflicting as little harm as possible on people and the environment, knowing it’s a losing battle, and come to find out that the whole plastic recycling movement was a giant fraud, that it only existed as an anaesthetic to the guilt of our parents so they’d fuel the rise of single use plastics. And because millennials on down are recycling their waste at high levels, it’s easier to drop the act rather than put in the work because society would grind to a halt without single use plastics now.</p>
<blockquote>
<p>The following response is from Krista Carlson, born in 1980.</p>
</blockquote>
<p>Actually, the 80’s themselves were more hopeful.  We had some problems with depression and suicide, but not like today, and the enxiety almost everyone feels today was very rare.  There was still poverty, but less pressure.  There was less crime, and more freedom.  Kids could be kids, and overall, there was a feeling of innocence about the 1980’s.  The early 1990’s was when we as a nation became teenagers.  We had boomboxes and were rebelious. We were loud and colorful. Then came the sobering reality of watching the twin towers crumble in 2001, and I think that, more than anything else, changed American culture.  We lost our security and innocence and faced a whole new era of sobering reality.  Now, we know the politicians are all corrupt.  Now, we know we live in a society that is crumbling.  Kids deal with adult problems.  I’m not sure you can put the genie back in the bottle, but I suppose it is nice to keep the bottle around to remember the days when there was still magic in the world.</p>

</article></div>]]>
            </description>
            <link>https://opinionatedguide.github.io/posts/xx80/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25248587</guid>
            <pubDate>Sun, 29 Nov 2020 22:15:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Run a Ponzi Scheme for Tech People]]>
            </title>
            <description>
<![CDATA[
Score 382 | Comments 187 (<a href="https://news.ycombinator.com/item?id=25248563">thread link</a>) | @nish1500
<br/>
November 29, 2020 | https://callmenish.com/how-to-run-a-tech-ponzi-scheme/ | <a href="https://web.archive.org/web/*/https://callmenish.com/how-to-run-a-tech-ponzi-scheme/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article role="article" itemscope="" itemprop="blogPost" itemtype="http://schema.org/BlogPosting">
<center>
<header>


</header>
</center>
<p>More people are online than ever before. More people are desperate than ever before. Learn how to use that 👇</p>
<h2>Is this the right course for me?</h2>
<p>Good question. My courses are NOT for everyone. You need to be a good fit. This is the prefect course for you if you check any of the following boxes:</p>
<ol><li>You like having a business card that says <strong>I’m CEO bitch</strong></li><li>You dream of petting elephants in a Southeast asian monarchy with a questionable human rights record</li><li>doTerra didn’t work out</li><li>You have $100 to spare</li></ol>
<h2>Basics first. What is a Ponzi scheme?</h2>
<p>Say I managed to save $500 from my day job. I find 5 people who begrudgingly agree to give me $100 because I told them I can turn it into $200 in a month. I give them $200 each at the end of the month.</p>
<p>Now, I am <strong>out of savings</strong> but I have 5 people who doubled their money in a month with no hard work at all.</p>
<p>I use their story as an example to show people that my idea works. Now it’s easier to find people who pay me. I take $100 from 10 more people, wait for a month, and use the proceeds ($1,000) to give $200 each to 5 of those people.</p>
<p>Now I have a <strong>proven business model</strong>, and a good number of people who will vouch for my method. I use the proceeds from each successive group to pay the previous cohort of people.</p>
<h2>But this is a tech community. Not Wall Street.</h2>
<p>A Ponzi scheme can be used in any part of your life. Let’s see how we can use this around us today:</p>
<h3>Example 1: Sell a Course</h3>
<p>Create a twitter account and manage to get 100 followers through a combination of spamming famous people, dad jokes, and paid followers. Write this blog post and share it:</p>
<blockquote><p>How I got 100 followers in my first week with no hard work at all.</p></blockquote>
<p>Over the next week 50 people will read your tweet / post and start following you. These people are curious, and it costs them nothing to follow you. 50 followers isn’t much but you get to write another exciting post:</p>
<blockquote><p>How I increased my twitter following by 50% in less than 3 days.</p></blockquote>
<p>Now people are intrigued, and you have 500 more followers. Write another post.</p>
<blockquote><p>How I got 500 followers overnight</p></blockquote>
<p>Does it remind you of something – like a <strong>for</strong> loop? When iteration = 5, <strong>sell a course</strong> on Gumroad.</p>
<h3>Example 2: Become a Digital Nomad</h3>
<p>Quit your job in Colorado and move to Thailand because a long-haired guy and his hot girlfriend shared a beach selfie telling you how they are living the digital nomad life, and how you can do it too. Best $100 you ever spent.</p>
<p>Except, it didn’t work out (teaching English in Thailand only pays so much), and now you’re stuck in Koh Samui running out of money and ideas. Go to the nearest beach, take a picture of your laptop with sunset in the background and write this blog post:</p>
<blockquote><p>How quitting my 9-5 job and moving to Thailand was the best thing I ever did.</p></blockquote>
<p>Congrats, now people are listening. Create a course, somehow manage to make $1,000. Now use that $1,000 to buy some food, rent a moped, and share more selfies about your perfect life. It’s a massive market – these regular folks working boring jobs in rich white countries who believe in the good intentions of strangers on the internet. Exploit them.</p>
<h3>Example 3: No Code, Only Money</h3>
<p>Aren’t you sick of all these I’m-so-smart programmers with their statically-typed-languages-are-fast on HackerNews? When you came across this priceless <strong>No Code</strong> directory of tools you realized it was the next big thing. You spend $100 on the site, and use the knowledge to create a form (using a form builder) and a Zapier hook that emails people on new responses. Genius idea. You try to sell it for $500. No buyers. It’s all your fault.</p>
<p>Time to pivot. You create a <strong>No Code</strong> website to teach people how to make money using No Code tools (like you did, haha) such as <strong>Airtable</strong> and <strong>Zapier</strong>.</p>
<p><em>Note: the lesson here is NOT that you can make money by creating a valuable tool like Airtable using code. No.</em></p>
<p>Between your <strong>No Code website</strong> and <strong>No Code podcast</strong> you manage to make $500. You take a screenshot of your Stripe dashboard and share it with the world. Now you are hot shit. Going from 0 to $500 was the hard bit; going from $500 to $5,000 is easier.</p>
<h2>FAQ</h2>
<h4>Are places like Indiehacker and Gumroad and just enablers of Ponzi schemes?</h4>
<p>Of course not. There are some amazing people there working on cool new ideas. They write comments here and there, and make a post once in a while, but mostly it’s busy work building something. Most such communities are started by a group of well-intentioned people, who slowly become the minority.</p>
<p>Not all courses are scams. I bought one on Gumroad yesterday. Except it wasn’t teaching me how to grow my twitter following; it was teaching me a cool programming language that I’ve been meaning to learn for a while.</p>
<h4>Will I be sharing fake milestones and fake Stripe dashboards?</h4>
<p>You didn’t read anything, did you? No, you will actually get 500 new followers, and actually make $5,000. The ones who won’t are the suckers who buy your course.</p>
<h4>Won’t people call me out when they buy my course and fail to become rich?</h4>
<p>That is the best part – they will blame <strong>themselves</strong>. You made money. The people who gave you Twitter testimonials apparently made money. If people fail they will think it’s them. In fact, sell them your <strong>Advanced Course</strong>.</p>
<h4>How do I convince people I am legit?</h4>
<p>Tell people you are open to <strong>speaking engagements</strong>. Talk about the number of <strong>trees you planted</strong> this month. Tell them someone else forced you to post on IH or HN because of how great your content is. Talk about <strong>failure</strong> so you seem relatable. Act <strong>quirky</strong> on Twitter.</p>
<h4>Wait, are you writing this just to make me a part of your Ponzi scheme?</h4>
<p>Do you really think I am going to spend half a Sunday writing and formatting this long-ass post (instead of using my magic formula to make money for myself) for any reason other than the goodness of my heart?</p>
<p>Of course not. I swear. I just want to share my success with the world, help the little guy, Build in Public™, like every other ‘How I Made $5,000’ post. Pinky promise.</p>
<h4>I am sold. So, how DO I run a Ponzi scheme?</h4>
<p>You see, my goal in sharing my success here is to see <strong>YOU grow</strong>. Just like the guy who sold me into his Ponzi scheme – I am only paying it forward 🙏🏼.</p>
<p>I do like to charge <strong>$100</strong> JUST to ensure that only serious people become a part of my Ponzi-family. We call it an investment.</p>
<p>Enough talk. Signup here:</p>
<p><a href="https://nish.formcrafts.com/ponzi-scheme" target="_blank" rel="noreferrer noopener">https://nish.formcrafts.com/ponzi-scheme</a></p>
<h4>How do I NOT run a Ponzi scheme?</h4>
<ol><li>Look around you for problems people would pay to resolve.</li><li>Create something of value.</li><li>Have fun while you do it.</li></ol>
<p>Discuss on <a rel="noreferrer noopener" href="https://news.ycombinator.com/item?id=25248563" target="_blank">HN</a>.</p>
<p><a href="https://twitter.com/nish_crafts" target="_blank" rel="noreferrer noopener">@nish_crafts</a></p>

</article></div>]]>
            </description>
            <link>https://callmenish.com/how-to-run-a-tech-ponzi-scheme/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25248563</guid>
            <pubDate>Sun, 29 Nov 2020 22:10:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Haskell runtime is what sets it apart from the competition]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25248522">thread link</a>) | @harporoeder
<br/>
November 29, 2020 | https://harporoeder.com/posts/haskell-runtime/ | <a href="https://web.archive.org/web/*/https://harporoeder.com/posts/haskell-runtime/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>This post is substantially directed to non Haskellers. Haskell frequently appears on <a href="https://news.ycombinator.com/news">hackernews</a>, or <a href="https://www.reddit.com/r/programming/">/r/programming</a> but the content is commonly evangelizing some aspect of functional programming, strong types, and purity.</p>
<p>Haskell embodies all those things, but the practicality does not come from strongly typed functional programming. Other strongly typed functional languages such as <a href="https://ocaml.org/">OCaml</a> exist, but many aspects are <a href="https://github.com/ocaml-multicore/ocaml-multicore">not nearly as mature</a>. Here I explore some of the lesser talked about features that greatly contribute to the Haskells power, performance, and convenience.</p>
<p>Numerous Haskell implementation exist (<a href="https://github.com/IntelLabs/flrc">FLRC</a>, <a href="https://github.com/UU-ComputerScience/uhc">UHC</a>, <a href="http://repetae.net/computer/jhc/">JHC</a>) however we will specifically go over <a href="https://www.haskell.org/ghc/">GHC</a> which is by far the most used, and powerful.</p>
<h2 id="asynchronous-exceptions">Asynchronous exceptions</h2>
<p>In almost all languages exceptions are thrown by the executing thread. In <a href="https://www.cplusplus.com/">C++</a> throwing an exception would look something like this:</p>
<div><pre><code data-lang="c++"><span>void</span> <span>doAction</span>() {
    <span>if</span> (<span>1</span> <span>==</span> <span>0</span>) {
        <span>throw</span> std<span>::</span>runtime_error(<span>"the impossible happened"</span>);
    }
}

<span>try</span> {
    doAction();
} <span>catch</span> (<span>const</span> std<span>::</span>exception<span>&amp;</span> err) {
    cout <span>&lt;&lt;</span> err.what() <span>&lt;&lt;</span> std<span>::</span>endl;
}
</code></pre></div><p>In Haskell <em>any</em> thread can throw an exception to another thread. Let’s spawn a thread and then immediately kill it by throwing an exception from outside of it. No modification of the thread or function itself is required.</p>
<div><pre><code data-lang="haskell"><span>threadId</span> <span>&lt;-</span> forkIO myLongRunningAction
<span>throwTo</span> threadId <span>MyException</span>
</code></pre></div><p>This capability ends of being incredibly powerful. All of the sudden features that might normally be implemented as fundamental properties of the language can now be expressed within it.</p>
<p>An example of this is <code>timeout :: Int -&gt; IO a -&gt; IO (Maybe a)</code>. Timeout takes a timeout in microseconds, an action to run, and may or may not return a result depending on if the action completes in time. Internally it spawns a thread with a timer, and should a deadline be hit issues an exception to the other threads computation.</p>
<p>In a language like <a href="https://golang.org/">Go</a> a goroutine cannot be killed externally. A common pattern emerges where authors manually wait on channels to ensure can be controlled:</p>
<div><pre><code data-lang="go"><span>stop</span> <span>:=</span> make(<span>chan</span> <span>bool</span>)

<span>go</span> <span>func</span>() {
    <span>for</span> {
        <span>select</span> {
        <span>case</span> <span>&lt;-</span> <span>stop</span>:
            <span>return</span>
        }
    }
}()

<span>stop</span> <span>&lt;-</span> <span>true</span>
</code></pre></div><p>Should a mistake be made resources will leak, and more complicated control flows must be continually duplicated. Even killing a thread utilizing owned resources such as sockets is safe in Haskell because of constructs built on <code>bracket</code> that automatically cleanup resources.</p>
<h2 id="automatic-detection-of-failure-cases">Automatic detection of failure cases</h2>
<p><a href="https://blog.rust-lang.org/2015/04/10/Fearless-Concurrency.html">Fearless concurrency</a> is hard. Language features to make screwing up harder <a href="https://www.tweag.io/blog/2020-06-19-linear-types-merged/">are in the works</a>. While Haskell will not stop you from deadlocking your program, the runtime has tooling to detect when this happens and throw an exception such as <code>BlockedIndefinitelyOnMVar</code> in the deadlocked code.</p>
<p>Haskell is <a href="https://en.wikipedia.org/wiki/Lazy_evaluation">lazy</a> so while less common, if an unproductive infinite loop is detected a <code>NonTermination</code> exception may be thrown. This is however <a href="https://en.wikipedia.org/wiki/Halting_problem">not perfect</a>.</p>
<p>Haskell has <a href="https://wiki.c2.com/?TailCallOptimization">tail call optimization</a> limiting required stack size however a recoverable <code>StackOverflow</code> can be thrown. Various arithmetic exceptions exist for numeric errors such as <code>Overflow</code>, or <code>DivideByZero</code>.</p>
<p>Each thread can have independently set allocation limits via <code>setAllocationCounter</code> which causes an <code>AllocationLimitExceeded</code> exception. This can be useful for handling <a href="https://en.wikipedia.org/wiki/Multitenancy">multitenancy</a>.</p>
<h2 id="green-threads-and-asynchronous-networking">Green threads and asynchronous networking</h2>
<p>Most languages have some implementation of <a href="https://en.wikipedia.org/wiki/Green_threads">green threads</a>, but few have it as the primary mode of computation. The success of <a href="https://golang.org/">Go</a>, and <a href="https://www.erlang.org/">Erlang</a> for writing networked applications is heavily tied to this model of concurrency. Languages such as <a href="https://www.rust-lang.org/">Rust</a> that implement the functionality as a <a href="https://tokio.rs/">library</a>, have <a href="http://journal.stuffwithstuff.com/2015/02/01/what-color-is-your-function/">substantial ergonomics implications</a>.</p>
<p>Standard POSIX <a href="https://man7.org/linux/man-pages/man7/pthreads.7.html">pthreads</a> consume substantially more resources than green threads, and utilize the operating systems scheduler. On my system:</p>
<div><pre><code data-lang="bash">&gt; ulimit -a | grep stack
stack size <span>(</span>kbytes, -s<span>)</span> <span>8192</span>
</code></pre></div><p>the default thread stack size as 8 megabytes. Technically Linux does lazy allocation via virtual memory, however even <em>spawning and killing</em> a thread can take <a href="https://lemire.me/blog/2020/01/30/cost-of-a-thread-in-c-under-linux/">thousands of CPU cycles</a>.</p>
<p>Scaling to a large number of concurrent users (generally known as the <a href="http://www.kegel.com/c10k.html">C10K problem</a>), is usually accomplished via asynchronous IO operations. Asynchronous IO multiplexing combined with a low level of parallelism is how services such as <a href="https://nginx.org/">NGINX</a> attain such high performance.</p>
<p>GHC internally utilizes <a href="https://man7.org/linux/man-pages/man7/epoll.7.html">epoll</a>, or <a href="https://www.freebsd.org/cgi/man.cgi?query=kqueue&amp;sektion=2">kqueue</a> depending on platform. And support for the new <a href="https://kernel.dk/io_uring.pdf">io_uring</a> Linux API is being <a href="http://wjwh.eu/posts/2020-07-26-haskell-iouring-manager.html">experimented with already</a>, which can bring <a href="https://thenewstack.io/how-io_uring-and-ebpf-will-revolutionize-programming-in-linux/">substantial performance gains</a>.</p>
<p>Of green thread implementations Haskells is among the most powerful. For example with <code>threadStatus :: ThreadId -&gt; IO ThreadStatus</code> you can inspect the status of a thread, and if blocked even see <em>why</em>:</p>
<div><pre><code data-lang="haskell"><span>data</span> <span>BlockReason</span>
  <span>=</span> <span>BlockedOnMVar</span>
        <span>-- ^blocked on 'MVar'</span>
  <span>|</span> <span>BlockedOnBlackHole</span>
        <span>-- ^blocked on a computation in progress by another thread</span>
  <span>|</span> <span>BlockedOnException</span>
        <span>-- ^blocked in 'throwTo'</span>
  <span>|</span> <span>BlockedOnSTM</span>
        <span>-- ^blocked in 'retry' in an STM transaction</span>
  <span>|</span> <span>BlockedOnForeignCall</span>
        <span>-- ^currently in a foreign call</span>
  <span>|</span> <span>BlockedOnOther</span>
</code></pre></div><h2 id="performance-tuning-and-gc">Performance tuning and GC</h2>
<p>Some languages such as Java are famous for the <a href="https://docs.oracle.com/javase/10/gctuning/introduction-garbage-collection-tuning.htm">tuning capabilities</a>. A garbage collector cannot be perfect for every workload. There exist <a href="https://engineering.linkedin.com/garbage-collection/garbage-collection-optimization-high-throughput-and-low-latency-java-applications">throughput and latency trade offs</a> among others.</p>
<p>By default a generational copying collector is used by the runtime. GHC has a wide variety of <a href="https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/runtime_control.html">flags to flip, and knobs to turn</a>. One of particular interest is <code>--numa</code> to enable optimizations for high core count multi CPU servers which have <a href="https://en.wikipedia.org/wiki/Non-uniform_memory_access">higher communication overhead</a>.</p>

<p>Haskell has a full range of tooling to support debugging and building complex applications:</p>
<ul>
<li>Code coverage reporting via <a href="https://ku-fpg.github.io/software/hpc/">HCP</a>.</li>
<li><a href="https://www.fpcomplete.com/blog/2015/04/ghc-prof-flamegraph/">Time profiling flamegraphs</a> via <a href="https://github.com/fpco/ghc-prof-flamegraph">ghc-prof-flamegraph</a></li>
<li><a href="http://book.realworldhaskell.org/read/profiling-and-optimization.html#id678078">Space profiling graphs</a> via <a href="https://downloads.haskell.org/~ghc/6.12.1/docs/html/users_guide/hp2ps.html">hp2ps</a></li>
</ul>
</div></div>]]>
            </description>
            <link>https://harporoeder.com/posts/haskell-runtime/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25248522</guid>
            <pubDate>Sun, 29 Nov 2020 22:05:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Murder of Wilbur Wright]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25248073">thread link</a>) | @tacon
<br/>
November 29, 2020 | https://applieddivinitystudies.com/murder-of-wilbur | <a href="https://web.archive.org/web/*/https://applieddivinitystudies.com/murder-of-wilbur">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
       <p>How many of our greatest minds have we lost?</p>
<p>From The Dream Machine (p50) on John Atanasoff:</p>
<blockquote>
<p><strong>He was determined to build a computing machine… But with all his teaching responsibilities, he’d had very little time to focus on the problem.</strong> Finally, however, on a bitterly cold winter night in late 1937, he just couldn’t take it anymore; he had to get away to concentrate. So he jumped into his car in Ames, Iowa, and drove east through the subzero temperature at more than eighty miles per hour. Almost three hours later, after he crossed the Mississippi River into Illinois, he stopped at a roadhouse to warm up. And there, somewhere between his first and second bourbons, he conceived four crucial ideas to make him computer work.”</p>
</blockquote>
<p>Incredible! Atanasoff was busy, but finally got down to doing the thing he really loved, the world recognized his genius, and he was given all the resources he needed to complete his work.</p>
<p>At least, that’s what would have happened in any reasonable society. Instead, we’re told:</p>
<blockquote>
<p>Atanasoff didn’t develop his invention any further, as it happened. Soon after the United States entered the war, in December 1941, he went to the Naval Ordinance Laboratory in Washington, D.C., where he supervised the counting testing of mines. <strong>He never returned to computing.</strong></p>
</blockquote>
<p>Who knows what else he could have given us? Instead, his entire lifetime produces one brief period of real scientific producitivity, bookended by teaching responsibilities and war.</p>
<p>Once you start looking, these stories are everwhere. Here’s <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/History_of_Unix">The Daemon, the Gnu and the Penguin</a> on the invention of Unix:</p>
<blockquote>
<p>In August 1969, Ken Thompson’s wife Bonnie took their year-old son on a trip to California to show off to their families. As a temporary bachelor, Ken had time to work. “I allocated a week each to the operating system, the shell, the editor and the assembler [he told me]… and during the month she was gone, it was totally rewritten in a form that looked like an operating system”</p>
</blockquote>
<p>Maybe this is a greatly exaggerated myth, but how terrifying would it be if that was true? Is it possible that Thompson was burdened by responsibilities his entire life, and then in a brief moment of freedom did some of the most important work anyone has ever done?</p>
<p>And then from <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Wright_brothers#Wilbur">Wikipedia</a>, on Wilbur Wright:</p>
<blockquote>
<p>…Wilbur never flew again. He gradually became occupied with business matters for the Wright Company and dealing with different lawsuits. Upon dealing with the patent lawsuits, which had put great strain on both brothers, Wilbur had written in a letter to a French friend, “<strong>When we think what we might have accomplished if we had been able to devote this time to experiments, we feel very sad</strong>, but it is always easier to deal with things than with men, and no one can direct his life entirely as he would choose.”</p>
</blockquote>
<p>But why on earth not? Why couldn’t Wilbur Wright, now admired as one of history’s greatest investors, find time to continue his most important work? The story continues:</p>
<blockquote>
<p>Wilbur spent the next year before his death traveling, where he spent a full six months in Europe attending to various business and legal matters… He was also constantly back and forth between New York, Washington and Dayton. All of the stresses were taking a toll on Wilbur physically. Orville would remark that he would “come home white”.</p>
</blockquote>
<p>Then finally:</p>
<blockquote>
<p>After returning to Dayton in early May 1912, worn down in mind and body, he fell ill again and was diagnosed with typhoid fever. He lingered on, his symptoms relapsing and remitting for many days. Wilbur died, at age 45, at the Wright family home on May 30.</p>
</blockquote>
<p>These were some of the most brilliant minds we had, and they were each nearly unable to fulfil even a tiny fraction of their potential. We should ask how much more each of them could have accomplished, but also how much we’ve lost from would-be inventors unable to find even a month of genuine free time with which to pursue their dreams. And of course, how many have been effectively barred from research by poverty or discrimination.</p>
<p>What hits me hardest is not the material loss, but the squandering of human spirit. As <a target="_blank" rel="noopener" href="https://vimeo.com/115154289">Bret Victor once explained</a>:</p>
<blockquote>
<p>We recognize that a dog has to be allowed the full free expression of its entire range of capabilities. Sticking him in a cage or constraining his range of experience, you’re not letting him do all the things that dogs can do. And this is exactly what we’ve done to ourselves.</p>
</blockquote>
<p>And so the stories above strike me not even as tragedies, but as something more inhumane.</p>
<p>My greatest fear is that intelligent life will arrive on earth. It won’t be an invasion, or colonization, or anything horrible. They’ll just sit us down, and ask about the lives of our heroes.</p>
<p>We’ll proudly tell them about this guy Wilbur Wright. How he and his brother invented a machine to fly in the sky as gods. We’ll tell them about our culture of research and innovation, and how Wilbur, self-taught engineer from Ohio, changed the entire world.</p>
<p>And then we’ll have to explain how gruesomely we murdered him.</p>
<p>Not with sticks and stones, but with a barrage of patent lawsuits. We will have to tell the aliens how we used this great system of socially legitimate torture to slowly wear him down over the years.</p>
<p>We will tell them how in the end, poor brilliant Wilbur became old and tired and incapable of producing anything beautiful ever again.</p>
<p>I do not think they will forgive us. I am not sure we should forgive ourselves.</p>
<hr>
<p><strong>See Also</strong><br><a target="_blank" rel="noopener" href="https://guzey.com/patronage-and-research-labs/">Reviving Patronage and Revolutionary Industrial Research</a></p>
<hr>
<p><em>Yes, I understand that Wilbur also sued people. I’m not claiming that he was a good person. My point is that in a humane world, no part of this story would even be possible.</em></p>
 
    </div></div>]]>
            </description>
            <link>https://applieddivinitystudies.com/murder-of-wilbur</link>
            <guid isPermaLink="false">hacker-news-small-sites-25248073</guid>
            <pubDate>Sun, 29 Nov 2020 21:04:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introduction to gRPC – Part 1]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25248045">thread link</a>) | @bswamina
<br/>
November 29, 2020 | https://www.polarsparc.com/xhtml/gRPC-1.html | <a href="https://web.archive.org/web/*/https://www.polarsparc.com/xhtml/gRPC-1.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <br>
    
    <br>
    
    
    <hr>
    
    <p>Overview</p>
    <p><a href="https://grpc.io/" target="_blank"><span>gRPC</span></a> is a distributed, heterogeneous, high
        performance, high throughput, modern, open source, remote procedure call (<span>RPC</span>) framework from
        Google with the following features:</p>
    <div id="para-div">
      <ul id="blue-ol">
        <li>
          <p>Is platform neutral</p>
        </li>
        <li>
          <p>Is language neutral with official support for <span>C++</span>, <span>C#</span>,
            <span>Go</span>, <span>Java</span>, <span>JavaScript</span>, <span>
            Python</span>, <span>Ruby</span>, etc</p>
        </li>
        <li>
          <p>Uses <a href="https://www.polarsparc.com/xhtml/Protobuf3.html" target="_blank"><span>ProtoBuf</span></a>
            for defining message formats and service interfaces</p>
        </li>
        <li>
          <p>Leverages <a href="https://en.wikipedia.org/wiki/HTTP/2" target="_blank"><span>HTTP/2</span></a> for
            efficient network communication</p>
        </li>
        <li>
          <p>Provides support for both synchronous and asynchronous styles of communication</p>
        </li>
        <li>
          <p>Has pluggable support for load balancing, health checking, and authentication</p>
        </li>
      </ul>
    </div>
    <p>In short, with <span>gRPC</span>, services deployed on distributed systems can communicate with each other in
        an efficient and secure manner.</p>
    <p>The following diagram illustrates the high-level architecture of <span>gRPC</span> (along with some circled
        number annotations):</p>
    <div id="img-outer-div"> <p><img src="https://www.polarsparc.com/xhtml/images/grpc-01.png" alt="gRPC Architecture"></p><p>Figure-1</p>
    </div>
    
    <p>The circled number annotations indicate the steps to implement, build, and deploy a <span>gRPC</span> based
        service and are as follows:</p>
    <div id="para-div">
      <ol id="blue-ol">
        <li>
          <p>Create a <span>.proto</span> file with the definitions for the request message <span>
            Req</span>, the response message <span>Res</span>, and the service interface <span>
            Service</span></p>
        </li>
        <li>
          <p>Compile the <span>.proto</span> file to generate the <span>gRPC</span> code for the server
            <span>gRPC Server</span> and the <span>gRPC</span> code for the client <span>
            gRPC Stub</span> for the chosen language</p>
        </li>
        <li>
          <p>Extend the <span>gRPC Server</span> code to implement and build the server side or the service provider</p>
        </li>
        <li>
          <p>Extend the <span>gRPC Stub</span> code to implement and build the cide side or the service consumer</p>
        </li>
      </ol>
    </div>
    <p>We will demonstrate <span>gRPC</span> using the <span>Go</span> and the <span>
        Java 11</span> programming languages.</p>
    <p>Installation and Setup</p>
    <div id="para-div">
      <p>The installation is on a <span>Ubuntu 20.04 LTS</span> based Linux desktop.</p>
      <p>We will also assume that the logged in user-id is <span>alice</span> with the home directory located at
        <span>/home/alice</span>.</p>
      <p>We need to install the packages for the <span>Go</span> programming language called <span>
        golang</span>, the <span>Java 11</span> programming language called <span>openjdk-11-jdk</span>,
        the <span>Maven</span> build management tool for Java called <span>maven</span>, and the
        protobuf compiler called <span>protobuf-compiler</span> from the Ubuntu repository.</p>
    </div>
    <p>To install the mentioned packages, execute the following commands:</p>
    <div id="cmd-div">
      <p>$ sudo apt-get update</p>
      <p>$ sudo apt-get install golang openjdk-11-jdk maven protobuf-compiler -y</p>
    </div>
    <p>For the Go language, we will create a directory called <span>go</span> under the home directory of the
        logged in user and set the <span>GOPATH</span> environment variable by executing the following commands:</p>
    <div id="cmd-div">
      <p>$ cd $HOME</p>
      <p>$ mkdir go</p>
      <p>$ export GOPATH=$HOME/go</p>
    </div>
    <p>To setup the directory structure and Go dependencies for the demonstrations, execute the following commands:</p>
    <div id="cmd-div">
      <p>$ cd $GOPATH</p>
      <p>$ mkdir -p src/polarsparc.com/grpc</p>
      <p>$ cd $GOPATH/src/polarsparc.com/grpc</p>
      <p>$ go mod init polarsparc.com/grpc</p>
      <p>$ GO111MODULE=on go get -u google.golang.org/grpc</p>
      <p>$ GO111MODULE=on go get github.com/golang/protobuf/protoc-gen-go</p>
    </div>
    <p>To setup the Java directory structure for the demonstrations, execute the following commands:</p>
    <div id="cmd-div">
      <p>$ cd $HOME</p>
      <p>$ mkdir -p java/grpc</p>
      <p>$ cd $HOME/java/grpc</p>
      <p>$ mkdir -p src/main/java src/main/proto src/test/java target</p>
      <p>$ mkdir -p src/main/java/com/polarsparc src/test/java/com/polarsparc</p>
    </div>
    <p>For the Java language, we will leverage Maven to manage the build as well as the package dependencies.</p>
    <p>The following is the Maven <span>pom.xml</span> file located in the directory <span>
        $HOME/java/grpc</span>:</p>
    <fieldset id="sc-fieldset">
      <legend>pom.xml</legend>
<pre>&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;project xmlns="http://maven.apache.org/POM/4.0.0"
          xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
          xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;

    &lt;groupId&gt;com.polarsparc.grpc&lt;/groupId&gt;
    &lt;artifactId&gt;gRPC&lt;/artifactId&gt;
    &lt;version&gt;1.0&lt;/version&gt;

    &lt;properties&gt;
        &lt;java.version&gt;1.8&lt;/java.version&gt;
        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;
    &lt;/properties&gt;

    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;io.grpc&lt;/groupId&gt;
            &lt;artifactId&gt;grpc-protobuf&lt;/artifactId&gt;
            &lt;version&gt;1.33.1&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;io.grpc&lt;/groupId&gt;
            &lt;artifactId&gt;grpc-netty-shaded&lt;/artifactId&gt;
            &lt;version&gt;1.33.1&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;io.grpc&lt;/groupId&gt;
            &lt;artifactId&gt;grpc-stub&lt;/artifactId&gt;
            &lt;version&gt;1.33.1&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;!-- Needed for Java 9 and above --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.tomcat&lt;/groupId&gt;
            &lt;artifactId&gt;annotations-api&lt;/artifactId&gt;
            &lt;version&gt;6.0.53&lt;/version&gt;
            &lt;scope&gt;provided&lt;/scope&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.junit.jupiter&lt;/groupId&gt;
            &lt;artifactId&gt;junit-jupiter-engine&lt;/artifactId&gt;
            &lt;version&gt;5.6.3&lt;/version&gt;
            &lt;scope&gt;test&lt;/scope&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;

    &lt;build&gt;
        &lt;extensions&gt;
            &lt;extension&gt;
                &lt;groupId&gt;kr.motd.maven&lt;/groupId&gt;
                &lt;artifactId&gt;os-maven-plugin&lt;/artifactId&gt;
                &lt;version&gt;1.6.2&lt;/version&gt;
            &lt;/extension&gt;
        &lt;/extensions&gt;
        &lt;plugins&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;
                &lt;version&gt;3.8.1&lt;/version&gt;
                &lt;configuration&gt;
                    &lt;source&gt;1.8&lt;/source&gt;
                    &lt;target&gt;1.8&lt;/target&gt;
                &lt;/configuration&gt;
            &lt;/plugin&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt;
                &lt;version&gt;2.22.2&lt;/version&gt;
            &lt;/plugin&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.xolstice.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;protobuf-maven-plugin&lt;/artifactId&gt;
                &lt;version&gt;0.6.1&lt;/version&gt;
                &lt;configuration&gt;
                    &lt;protocArtifact&gt;com.google.protobuf:protoc:3.14.0:exe:${os.detected.classifier}&lt;/protocArtifact&gt;
                    &lt;pluginId&gt;grpc-java&lt;/pluginId&gt;
                    &lt;pluginArtifact&gt;io.grpc:protoc-gen-grpc-java:1.33.1:exe:${os.detected.classifier}&lt;/pluginArtifact&gt;
                    &lt;protoSourceRoot&gt;${basedir}/src/main/proto&lt;/protoSourceRoot&gt;
                &lt;/configuration&gt;
                &lt;executions&gt;
                    &lt;execution&gt;
                        &lt;goals&gt;
                            &lt;goal&gt;compile&lt;/goal&gt;
                            &lt;goal&gt;compile-custom&lt;/goal&gt;
                        &lt;/goals&gt;
                    &lt;/execution&gt;
                &lt;/executions&gt;
            &lt;/plugin&gt;
        &lt;/plugins&gt;
    &lt;/build&gt;
&lt;/project&gt;</pre>
    </fieldset>
    
    <p>Hands-on with gRPC</p>
    <p>One of the prerequisites for <span>gRPC</span> is have a fundamental understanding of
        <a href="https://www.polarsparc.com/xhtml/Protobuf3.html" target="_blank"><span>Protocol Buffers</span></a>.</p>
    <p><span>gRPC</span> supports four types of communication patterns which are as follows:</p>
    <div id="para-div">
      <ul id="blue-ol">
        <li>
          <p><span>Unary</span> :: the client sends a single request to the server and the server responds with a
            single response</p>
        </li>
        <li>
          <p><span>Server Streaming</span> :: the client sends a single request to the server and the server
            responds with a sequence of responses</p>
        </li>
        <li>
          <p><span>Client Streaming</span> :: the client sends a sequence of requests to the server and the server
            responds with a single response</p>
        </li>
        <li>
          <p><span>Bidirectional Streaming</span> :: the client sends a sequence of requests to the server and the
            server with a sequence of responses (with the requests and responses operating independently)</p>
        </li>
      </ul>
    </div>
    <p>Unary RPC</p>
    <p>The following diagram illustrates the high-level architecture of <span>Unary</span> communication pattern:</p>
    <div id="img-outer-div"> <p><img src="https://www.polarsparc.com/xhtml/images/grpc-02.png" alt="Unary Architecture"></p><p>Figure-2</p>
    </div>
    
    <p>For the Unary RPC demonstration, we will implement a simple Greet service, where the client sends a name in the request and
        the server responds back with an appropriate greeting message based on the time of the day.</p>
    <div id="para-div">
      <p>We will first demonstrate the Greet service using the Go programming language.</p>
      <p>In the <span>$GOPATH</span> directory, create the project directory hierarchy by executing the following
        commands:</p>
    </div>
    <div id="cmd-div">
      <p>$ cd $GOPATH/src/polarsparc.com/grpc</p>
      <p>$ mkdir -p unary unary/greetpb unary/server unary/client</p>
    </div>
    <p>The following are the contents of the file <span>greet.proto</span> located in the directory <span>
        $GOPATH/src/polarsparc.com/grpc/unary/greetpb</span> as shown below:</p>
    <fieldset id="sc-fieldset">
      <legend>greet.proto</legend>
      <pre>/*
    @Author: Bhaskar S
    @Blog:   https://www.polarsparc.com
    @Date:   28 Nov 2020
*/

syntax = "proto3";

package unary;

option go_package = "polarsparc.com/grpc/unary/greetpb";

message GreetRequest {
  string name = 1;
}

message GreetResponse {
  string message = 1;
}

service GreetService {
  rpc greet(GreetRequest) returns (GreetResponse);
}</pre>
    </fieldset>
    <p>The request message is defined as <span>GreetRequest</span> and the response message is defined as
        <span>GreetResponse</span>. The service interface is defined as <span>GreetService</span>
        with an RPC method <span>greet</span> that takes in a <span>GreetRequest</span> as an input
        and returns a <span>GreetResponse</span>.</p>
    <p>To compile the <span>greet.proto</span> file, execute the following commands:</p>
    <div id="cmd-div">
      <p>$ cd $GOPATH/src/polarsparc.com/grpc/unary</p>
      <p>$ protoc greetpb/greet.proto --go_out=plugins=grpc:$GOPATH/src</p>
    </div>
    <p>On success, this will generate the Go code file called <span>greet.pb.go</span> located in the directory
        <span>$GOPATH/src/polarsparc.com/grpc/unary/greetpb</span>.</p>
  …</div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.polarsparc.com/xhtml/gRPC-1.html">https://www.polarsparc.com/xhtml/gRPC-1.html</a></em></p>]]>
            </description>
            <link>https://www.polarsparc.com/xhtml/gRPC-1.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25248045</guid>
            <pubDate>Sun, 29 Nov 2020 21:01:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elasticsearch 7.10.0 Released]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25247962">thread link</a>) | @k-rus
<br/>
November 29, 2020 | https://www.elastic.co/blog/whats-new-elasticsearch-7-10-0-searchable-snapshots-store-more-for-less | <a href="https://web.archive.org/web/*/https://www.elastic.co/blog/whats-new-elasticsearch-7-10-0-searchable-snapshots-store-more-for-less">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><p>We're pleased to announce the release of Elasticsearch 7.10.0, based on Apache Lucene 8.7.0. Version 7.10 is the latest stable release of Elasticsearch and is now available for deployment via <a href="https://www.elastic.co/elasticsearch/service">Elasticsearch Service</a> on <a href="https://www.elastic.co/cloud">Elastic Cloud</a> or via <a href="https://www.elastic.co/downloads/elasticsearch">download</a> for use in your own environment(s).
</p><p>If you're ready to roll up your sleeves and get started, we have the links you need:
</p><ul><li><a href="https://www.elastic.co/cloud/">Start Elasticsearch on Elastic Cloud</a></li><li><a href="https://www.elastic.co/downloads/elasticsearch">Download Elasticsearch</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.10/release-notes-7.10.0.html">Elasticsearch 7.10.0 release notes</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.10/breaking-changes-7.0.html">Elasticsearch 7.10.0 breaking changes</a></li></ul><p>With today's release, our <a href="https://www.elastic.co/enterprise-search">Elastic Enterprise Search</a>, <a href="https://www.elastic.co/observability">Elastic Observability</a>, and <a href="https://www.elastic.co/security">Elastic Security</a> solutions also received significant updates. To learn more about these updates&nbsp;you might consider giving our main<a href="https://www.elastic.co/blog/whats-new-elastic-7-10-0-searchable-snapshots-lens-user-experience-monitoring"> Elastic 7.10 release</a> blog a read.
</p><h2>Store more and spend less with searchable snapshots</h2><p>Data is growing at an exponential rate across many organizations. This is especially true for time series data like logs, metrics, traces, and security events used to observe and protect your systems. In time-series data, the most recent data ingested into Elasticsearch is what's valuable. This data drives alerting, machine learning detection, devops workflows, and monitoring security events. But keeping all of this data on high-performance instances can become very expensive if not economically feasible.
</p><p>To address this, we began looking at the lifecycle of data. Using features like <a href="https://www.elastic.co/blog/elastic-stack-6-6-0-released">index lifecycle management</a> helped move data from high-performance, high-cost <a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.10/data-tiers.html">“hot” nodes to lower cost “warm” nodes</a> with less performant disks. But what if your organization asked you to keep years of data? Could you answer the question of how many unique visitors visited your site year over year on Cyber Monday? Or how many systems a user accessed over a 5 year period for a security forensic investigation? To keep this much data on warm nodes still requires a significant financial investment. This has prompted many organizations to store some data as&nbsp;<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/snapshots-take-snapshot.html">snapshots</a>. This isn't a perfect solution, as you still need to take the time to restore the data from a snapshot whenever you need to search.
</p><p>Introducing... <a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.10/searchable-snapshots.html">searchable snapshots</a>, a new beta feature which allows you to directly search your snapshots without a restore, on low cost object stores such as AWS S3, Microsoft Azure Storage, or Google Cloud Storage without a significant impact to search performance. Balance the cost, performance and capabilities to meet your storage and search needs.&nbsp;
</p><p><img src="https://play.vidyard.com/ZsDF2rsBhcof1LcdsmZBth.jpg" data-uuid="ZsDF2rsBhcof1LcdsmZBth" data-v="4" data-type="inline" data-autoplay="1" data-loop="1" data-disable_analytics="1" data-hidden_controls="1" data-muted="1"></p><p>Searchable snapshots power a new data tier called the&nbsp;<a href="https://www.elastic.co/guide/en/elasticsearch/reference/master/data-tiers.html#cold-tier">cold tier</a>. The cold tier, also in beta, is designed to dramatically reduce storage costs for your read-only data by reducing your cluster storage by up to 50% without a significant impact to performance. It maintains the same level of reliability and redundancy as your hot and warm tiers, with full support for the automatic recovery you have come to expect from Elasticsearch. Are you craving more information? Check out this <a href="https://www.elastic.co/blog/introducing-elasticsearch-searchable-snapshots">searchable snapshots introduction</a> blog for more information.
</p><h2>Bolstering Elasticsearch's security chops with EQL</h2><p>In 7.9, we <a href="https://www.elastic.co/blog/whats-new-elasticsearch-7-9-0">announced</a> Event Query Language (EQL), a new experimental query language. <a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.x/eql-search-api.html">EQL</a>&nbsp;has been used for years within Endgame to help you get a holistic view of a system for threat investigation, identification, and prevention. These same unique capabilities used within the security space have now been brought to Elasticsearch, and in 7.10, EQL in Elasticsearch is now in beta for use cases such as observability and other time-series data.
</p><p><img src="https://images.contentstack.io/v3/assets/bltefdd0b53724fa2ce/blt7b3c6e098bd9c247/5fa9b95342256d5ffdf419bd/eql-final.gif" data-sys-asset-uid="blt7b3c6e098bd9c247" alt="eql-final.gif"></p><p>A great way to understand EQL is to consider a home security analogy. Entering the house through any doorway to the home is not considered suspicious even if it's late at night. However, a person entering the house from the front door and from the back door at the same time raises questions because it would be impossible to be in two places at once. It may also be suspicious if someone enters the house after failing to use 90 different keys to open the front door in under a minute &lt;wink&gt;.
</p><p>EQL is designed to easily take an event (front door opening) and correlate other events or sequence of events (entering through the back door or window, forced entry, etc), to draw conclusions on the state of the system. These events can be correlated over a span of time to find new insights such as 90 previously failed attempts before gaining entry to the home. You can read an introduction to EQL&nbsp;<a href="https://www.elastic.co/blog/introducing-event-query-language">here</a>.
</p><h2>Elasticsearch 7.10 will be smaller, in a big way</h2><p>Our initial benchmarks have reported space reductions of up to 10% using a new stored field compression! This is big news, especially for organizations paying for storing and maintaining petabytes of data. Indices created by our <a href="https://www.elastic.co/observability">Elastic Observability</a> and <a href="https://www.elastic.co/security">Elastic Security</a> solutions will see the greatest savings due to the repetitive nature of the data they typically hold. To learn more about stored field compression and how you can save up to 10% on index size, be on the look out for stored field compression blog overview being released shortly.</p><h2>Elasticsearch performance improvements</h2><p>Elastic has been on a mission to continually improve search aggregation performance and memory efficiencies. In <a href="https://www.elastic.co/blog/elasticsearch-7-8-0-released">7.8</a>, we reduced aggregation memory consumption by maintaining serialized results, and in <a href="https://www.elastic.co/blog/whats-new-elasticsearch-7-9-0">7.9</a> we increased the <a href="https://www.elastic.co/guide/en/elasticsearch/reference/master/search-settings.html#search-settings-max-buckets">search.max_buckets</a> limit to 65,535. The Elasticsearch team has continued this work in 7.10, specifically targeting the coordinator node and the request-level circuit breaker to improve performance and memory tracking of <a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.10/search-aggregations-metrics-cardinality-aggregation.html">cardinality</a> and <a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.10/search-aggregations-bucket.html">bucket aggregation</a>. <a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.10/search-aggregations-bucket-datehistogram-aggregation.html">Date histogram aggregation</a> performance has also been improved by 50% by precomputing date ranges.
</p><h2>Elasticsearch functional and usability enhancements&nbsp;</h2><p><img src="https://images.contentstack.io/v3/assets/bltefdd0b53724fa2ce/blt94e1cb58b5fbb532/5fa9b9ef42256d5ffdf419c9/quote-heraclitus-no-person-ever-steps-in-the-same-river-twice.png" data-sys-asset-uid="blt94e1cb58b5fbb532" alt="quote-heraclitus-no-person-ever-steps-in-the-same-river-twice.png"></p><h3>Point in time reader</h3><p>No person ever steps in the same river twice, since it's not the same river and it's not the same person... unless you have <a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.10/point-in-time-api.html">point in time reader</a>. When querying an index in Elasticsearch, you are essentially searching for data at a given point of time. If your query returns the top 10% results, how do you query the other 90%? With an index that is constantly changing as in most observability and security use cases, sending another query will return a different result because the index or data has already changed. Point in time reader gives you the ability to repeatedly query an index at the state it was at at a given point in time. The point in time reader already serves the EQL query language, and we expect to use it for many other use cases in the future.<br></p><h3>Case insensitivity in wildcard field type</h3><p>In Elasticsearch 7.9 we introduced the new&nbsp;<a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.10/keyword.html#wildcard-field-type">wildcard field type</a>. Before the introduction of this new field type, using wildcards within your query was resource intensive and typically resulted in slower than expected search times despite the learned human behavior of how we search on web browsers. The wildcard field type provides additional flexibility and an easy way to assemble queries. In 7.10,&nbsp; support for case insensitivity queries have been added. This enables case insensitivity by default for term-level queries (such as term, terms, prefix, wildcard and regexp), simply by setting the optional case_insensitive flag to true. This should greatly benefit security and observability use cases.
</p><h3>Unsigned 64 bits integer</h3><p>The time for <a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.10/number.html#number">64 bit integers</a> is now! Elasticsearch now supports unsigned 64 bit integers. This new numeric type supports very large positive integers from 0 to 264-1. This is particularly useful for system-generated data, such as counters from routers or Windows registry events. Note that aggregations will still work on the nearest double. This is great news if you work with finance, security and network performance data.
</p><h3>Version data type</h3><p>How can you search across software versions where the numeric value is semantic? <a href="https://www.elastic.co/guide/en/elasticsearch/reference/master/version.html">Version datatype</a> is a specialization of the keyword field to handle software version values and to support specialized precedence rules for them based on semantic versioning. For example, major, minor, and patch versions are sorted numerically (“2.1.0” &lt; “2.4.1” &lt; “2.11.2”), and pre-release versions are sorted before releases (“1.0.0-alpha &lt; “1.0.0”).
</p><h3>New aggregations</h3><p>In addition to the aggregations we added in <a href="https://www.elastic.co/blog/elasticsearch-7-8-0-released">7.8</a>, we are introducing two new aggregations! Histograms: <a href="https://www.elastic.co/guide/en/elasticsearch/reference/master/search-aggregations-metrics-max-aggregation.html#search-aggregations-metrics-max-aggregation-histogram-fields">min/max aggregations on histogram fields</a>, and hard bounds for histogram aggregations. The histogram datatype is useful for handling high volume numeric data, which is frequently aggregated where it is produced, allowing for a more space-efficient Elasticsearch index. For example, Elastic APM could roll up histogram data or sum it up in one structure to reduce the amount of data being sent from the APM agent into Elasticsearch. Being able to aggregate on the histogram enables supports new scenarios.
</p><p>The 2nd aggregation is <a href="https://www.elastic.co/guide/en/elasticsearch///reference/master/search-aggregations-metrics-rate-aggregation.html">rate metrics aggregation</a>, which is used inside a date_histogram and calculates the rate of occurrences of a specified field within a bucket of a date_histogram aggregation. Previously, it was harder to calculate the rate, but since rate is a basic piece of information when analyzing time series data, we thought it would be valuable to make it easier. This is one of many such adaptations we are making to verify that it is easy and intuitive to use the Elasticsearch generic search and analytics engine on time series data.
</p><h3>New ingest node pipeline UI</h3><p><img src="https://images.contentstack.io/v3/assets/bltefdd0b53724fa2ce/bltc1155c42dc8e2f74/5fa9ba656f82405d9a4aaa81/ingest_node_pipelines_demo.gif" data-sys-asset-uid="bltc1155c42dc8e2f74" alt="ingest_node_pipelines_demo.gif"></p><p>It is easier to debug your ingest flow with the new ingest node pipeline UI. Added visual cues and pipeline tests allow you to easily step through the execution flow. Viewing error messages from the output can help you identify what actions are needed to ensure your documents will work properly with your ingest processors.&nbsp;
</p><h2>Machine Learning</h2><h3>AUC ROC metric for evaluating your classification machine learning models</h3><p>We have added area under the curve of receiver operating characteristic (AUC ROC) as an evaluation metric for classification analysis. This is a common evaluation metric to know how well your models perform.
</p><h3>Custom feature processor in data frame analytics</h3><p>New field in data frame analytics allows you to …</p></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.elastic.co/blog/whats-new-elasticsearch-7-10-0-searchable-snapshots-store-more-for-less">https://www.elastic.co/blog/whats-new-elasticsearch-7-10-0-searchable-snapshots-store-more-for-less</a></em></p>]]>
            </description>
            <link>https://www.elastic.co/blog/whats-new-elasticsearch-7-10-0-searchable-snapshots-store-more-for-less</link>
            <guid isPermaLink="false">hacker-news-small-sites-25247962</guid>
            <pubDate>Sun, 29 Nov 2020 20:50:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vancouver's empty home tax is increasing to 3% next year]]>
            </title>
            <description>
<![CDATA[
Score 85 | Comments 21 (<a href="https://news.ycombinator.com/item?id=25247904">thread link</a>) | @synack
<br/>
November 29, 2020 | https://bc.ctvnews.ca/vancouver-s-empty-home-tax-is-increasing-to-3-next-year-1.5204533 | <a href="https://web.archive.org/web/*/https://bc.ctvnews.ca/vancouver-s-empty-home-tax-is-increasing-to-3-next-year-1.5204533">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>VANCOUVER -- 
	The empty homes tax in Vancouver will more than double next year, the city announced Wednesday.</p>
<p>
	Council voted in favour of increasing the tax from 1.25 per cent to three per cent for 2021. The current rate still applies for 2020 declarations, which are due by Feb. 2.&nbsp;</p>
<p>
	"I'm so glad that council backed my plan to stand up for renters and raise the empty homes tax to three per cent," said Mayor Kennedy Stewart in a news release.&nbsp;</p>
<p>
	"This groundbreaking tool has helped move thousands of homes back onto the rental market to help house our neighbours, but there are still too many homes that remain empty."</p>
<p>
	When the tax was first introduced in 2017, it started at one per cent. Then council voted to increase it for the first time in 2019, to 1.25 per cent.</p>
<p>
	"By tripling the tax from one to three per cent since the tax launched, we're sending an even stronger message that homes are for people, not speculation," Stewart said.</p>
<p>
	According to the city, $61.3 million in net revenues from the tax has been used to support affordable housing initiatives. Vacant property has decreased by 25 per cent since the tax was introduced in 2017, the city says.&nbsp;&nbsp;</p>
                                              </div></div>]]>
            </description>
            <link>https://bc.ctvnews.ca/vancouver-s-empty-home-tax-is-increasing-to-3-next-year-1.5204533</link>
            <guid isPermaLink="false">hacker-news-small-sites-25247904</guid>
            <pubDate>Sun, 29 Nov 2020 20:43:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Radio Frequencies for Space Communication]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25247885">thread link</a>) | @peter_d_sherman
<br/>
November 29, 2020 | https://www.spaceacademy.net.au/spacelink/radiospace.htm | <a href="https://web.archive.org/web/*/https://www.spaceacademy.net.au/spacelink/radiospace.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<h3>RADIO FREQUENCIES FOR SPACE COMMUNICATION</h3>
<p>
<br>
<span color="red">INTRODUCTION</span>
</p><p>
To be useful satellites and spacecraft must communicate, sometimes to relay communications between two points, sometimes to transmit data they have collected.  Although there have been some experiments in optical communications using lasers, most satellite communication is accomplished by radio, one part of the electromagnetic spectrum.  Radio frequencies must be shared with terrestrial radio services, and international frequency assignment is essential to avoid interference between all the different uses made of the radio spectrum.
</p><p>
The International Telecommunications Union (ITU) is the global body that assigns radio frequency allocations.  In doing this they divide the world into three regions, regions I, II and III.  Australian lies in region III.  The general frequency assignments may be found at the <a href="http://www.itu.int/">ITU</a> web site, and Australian allocations may be seen at the <a href="http://www.acma.gov.au/">ACMA</a> web site.  The ITU unfortunately, charges horrendous prices for any of its publications.  However, the Australian Communications and Media Authority (ACMA) makes all spectral allocation information available for free download.  This includes a book, an attractive wall poster and a simplified spectrum graphic.
</p><p>
This note discusses the frequencies that are used for space communications.
</p><p><br>
<span color="red">THE ELECTROMAGNETIC SPECTRUM</span>
</p><p>
There are four, and only four known forces in the universe (although the so-called dark energy hints at another).  These are, in order of strength, the nuclear strong force, the electromagnetic force, the nuclear weak force and the gravitational force.  The two nuclear forces exert their influence over only very very short (nuclear) distances, and apart from holding all matter together do not directly influence us in everyday life.  It is gravity and particularly electromagnetism that are of direct concern to us in our daily interactions.
</p><p>
<img alt="Electromagnetic fields" src="https://www.spaceacademy.net.au/spacelink/emgen.gif">
Gravity springs from the property of matter we call mass, while electromagnetic effects derive from the property we call charge.  When a charge is stationary, it has around it an electrostatic field.  If it moves with a constant velocity it
produces a magnetic field, and when it accelerates or declerates it generates electromagnetic radiation.
</p><p>
Electromagnetic radiation is a coupled oscillation of electric and magnetic fields that propagates through space with a velocity of about 3 x 10<sup>8</sup> metres per second.  The properties of this electromagnetic radiation vary markedly depending on the frequency of the oscillation.  This gives rise to what we know as the electromagnetic spectrum.
</p><p>
The chart below shows the major divisions of the electromagnetic spectrum. An electromagnetic wave may be characterised by its frequency f (the number of times per second the signal undergoes a complete oscillation at a specified point in space) or its wavelength λ (the distance between successive extremal values of the wave at a specified time).
</p><center>
<img alt="EM radiation bands" src="https://www.spaceacademy.net.au/spacelink/emspec.gif">
</center>
<p><small>
Note:</small></p><ul><small>
1  For clarity the bands are not shown with uniform frequency or wavelength spacing<br>
2  The visible spectrum occupies only a very small part of the total EM spectrum<br>
3  Bands also have subdivisions (this is particularly true of the radio spectrum)<br>
4  The band divisions are not as sharp as shown, but rather fuzzy, merging into one another<br>
5  In the frequency scale T=10<sup>12</sup>, P=10<sup>15</sup>, E=10<sup>18</sup><br>
6  In the wavelength scale μ=10<sup>-6</sup>, n=10<sup>-9</sup>, p=10<sup>-12</sup>
</small></ul>
<p>
<br>
<span color="red">THE RADIO SPECTRUM</span>
</p><p>
The radio spectrum is a subset of the electromagnetic spectrum.  It extends from frequencies below 1 Hz up to around 3000 GHz or 3 THz, where it gives way to the infrared spectrum.  Different frequencies have different uses because of different propagation, generation and general properties. The radio spectrum is divided into many different bands.
</p><p>
<img alt="Radio spectral bands" src="https://www.spaceacademy.net.au/spacelink/radiospec.gif">
This table shows the usually accepted division of the radio spectrum.  The left hand column lists the frequency (f), the centre column the band designator and the right column the wavelength (λ).  The relationship between frequency and wavelength is given by the expression:
</p><ul> f = c / λ</ul>
where c = 3 x 10<sup>8</sup> metres per second is the speed of light (and other EM radiation) in free space.
<p>In the above relation, frequency is given in Hertz (Hz) when wavelength is specified in metres (m).
</p><p>
Note that the designated band qualifiers are not in the same order going toward lower frequencies as they are going toward higher frequencies.  Also note that the division between ELF and ULF is not universally agreed.  It can be placed anywhere from 1 Hz to 100 Hz.  The one shown (1 Hz) is that employed by geophysicists.
</p><p>
There is no lower limit to the ULF band and magnetic signals with periods of years can be identified.
</p><p>
Microwave is a term that was historically applied to signals with wavelengths less than one foot (30 cm), and this region has been subdivided into letter bands.  However, there are several schemes of designation for microwave bands.  Two of these, which we shall call traditional and new, are given below.  Despite the efforts of many engineers to have the 'new' division adopted, the 'traditional' scheme seems to be firmly entrenched among space communicators.
</p><center>
<img alt="Microwave sub-bands" src="https://www.spaceacademy.net.au/spacelink/uwavebands.gif">
</center><p>
<br><span color="red">WINDOWS TO SPACE</span>
</p><p>
Not all of the electromagnetic spectrum can pass through the Earth's atmosphere.  Obviously, visible light can - we can see the stars at night, at least when there is no cloud.  However, ultraviolet and higher frequencies are mostly absorbed by different components of the atmosphere.
</p><p>
There are in fact only two main windows of the EM spectrum that are open to space.  One is the visible spectrum, as mentioned above, and the other is the radio spectrum.  However, not all of the radio spectrum is useable for space communication.  The available window spans from about 30 MHz to 30 GHz, although these are not absolute end frequencies.
</p><p>
Below 30 MHz, the ionosphere, at altitudes from around 100 to 500 km, absorbs and reflects signals.  Above 30 GHz, the lower atmosphere or troposphere, below 10 km, absorbs radio signals due to oxygen and water vapour.  Even between 20 and 30 GHz, there are some absorption bands that must be avoided.
</p><center><img alt="Atmospheric windows" src="https://www.spaceacademy.net.au/spacelink/atwin.gif"></center>
<p>
<br><span color="red">HISTORICAL SPACE FREQUENCIES</span>
</p><p>
The first satellite to orbit the Earth was Sputnik 1, launched by the Soviets in October 1957.  It carried two radio beacons on frequencies of 20.005 and 40.01  MHz.
</p><p>
The Soviets continued to use frequencies around 20 MHz and even some around 15 MHz for many subsequent missions.
</p><p>
The first satellite launched by the USA (Explorer 1) carried  beacons on 108.00 and 108.03 MHz.  This lay just above the terrestrial FM broadcast band (from 88 to 108 MHz) and just inside the civil aviation band which extends from 108 to 136 MHz.  This frequency had been specified by an international committee for the International Geophysical Year (IGY - 1957/8) as the one to be used for all scientific satellites launched in pursuit of IGY objectives.  The Soviets had chosen to ignore this recommendation and use the much lower frequencies previously mentioned.
</p><p>
<br><span color="red">SPACE COMMUNICATION BANDS</span>
</p><p>
The following is a list of some of the more heavily used frequency bands for space communication. Specific frequencies may be found in the links provided at the end of this note.
</p><ul type="square">
  <li>VHF Band<br>
	<ul type="disc"><li><span color="blue">136 - 138 	MHz</span><br>
	This band was used heavily by many different types of
	satellites in the past.  Today (2012), most activity
	is restricted to 137-138 MHz (which is the current
	allocation) and consists of meteorological satellites
	transmitting data and low resolution images, together
	with low data rate mobile satellite downlinks (eg 
	Orbcomm)</li></ul>
	<ul type="disc"><li><span color="blue">144 - 146 		MHz</span><br>
	One of the most popular bands for amateur satellite
	activity.  Most of the links are found in the upper 	half of the band (145 - 146 MHz). </li></ul>
	<ul type="disc"><li><span color="blue">148 - 
	150 MHz</span><br>
	This tends to be used for uplinks of the satellites
	that downlink in the 137 - 138 MHz band. </li></ul>
	<ul type="disc"><li><span color="blue">149.95 - 	
	150.05 MHz</span><br>
	This is used by satellites providing positioning, time
	and frequency services, by ionospheric research 
	and other satellites.  Before the advent of GPS it was
        home to large constellations of US and Russian 
	satellites that provided positioning information 
	(mainly to marine vessels) by use of the Doppler
	effect).  Many satellites transmitting on this band 
	also transmit a signal on 400 MHz.</li></ul>
	<ul type="disc"><li><span color="blue">240 - 270 MHz
	 </span><br>
	Military satellites, communications.  This band lies 
	in the wider frequency allocation (225 - 380 MHz)    	assigned for military aviation.</li></ul>
   </li><li>UHF Band</li>
	<ul type="disc"><li><span color="blue">399.9 - 403 MHz
	</span><br>
	This band includes navigation, positioning, time
	and frequency standard, mobile communication, and
	meteorological satellites.  Around 400 MHz is a 
	companion band for satellites transmitting on 150 MHz. 	</li></ul>
	<ul type="disc"><li><span color="blue">432 - 438 MHz
	</span><br>
	This range includes a popular amateur satellite band
	as well as a few Earth resources satellites.
	</li></ul>
	<ul type="disc"><li><span color="blue">460 - 470 MHz   	</span><br>
	Meteorological and environmental satellites, includes
	uplink frequencies for remote environmental data
	sensors.</li></ul>
   <li>L Band<br>
	<ul type="disc"><li><span color="blue">1.2 - 1.8 GHz   	</span><br>
	This frequency range includes a very diverse range
	of satellites and encompasses many sub-allocations.
	This range includes the GPS and other GNSS (Global
	Navigation Satellite Systems - Russian Glonass,
	European Galileo, Chinese Beidou).  It also hosts
	SARSAT/COSPAS search and rescue satellites which are
	carried on board US and Russian meteorological 
	satellites. It also includes a mobile satellite
	communication band.</li></ul>
	<ul type="disc"><li><span color="blue">1.67 - 1.71 GHz
	</span><br>
	This is one of the primary bands for high resolution
	meteorological satellite downlinks of data and
	imagery.  </li></ul>
   </li><li>S Band<br>
	<ul type="disc"><li><span color="blue">2.025 - 2.3 GHz   	</span><br>
	Space operations and research, including 'deep space'
	links from beyond Earth orbit.  This encompasses the
	Unified S-band (USB) plan which is used by many
	spacecraft, and which was also used by the Apollo
	lunar missions.  It also includes military space links
	including the US Defense Meteorological Satellite 
	Program (DMSP).  Many Earth resources (remote sensing)
	satellites downlink in this band.</li></ul>
	<ul type="disc"><li><span color="blue">2.5 - 2.67 GHz
	</span><br>
	Fixed (point-to-point) communication and broadcast</li></ul></li></ul></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.spaceacademy.net.au/spacelink/radiospace.htm">https://www.spaceacademy.net.au/spacelink/radiospace.htm</a></em></p>]]>
            </description>
            <link>https://www.spaceacademy.net.au/spacelink/radiospace.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-25247885</guid>
            <pubDate>Sun, 29 Nov 2020 20:39:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Back That ‘S’ Up: Moving to RISC-V’s Supervisor Mode]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25247759">thread link</a>) | @azhenley
<br/>
November 29, 2020 | https://blog.stephenmarz.com/2020/11/23/back-that-s-up/ | <a href="https://web.archive.org/web/*/https://blog.stephenmarz.com/2020/11/23/back-that-s-up/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
								
								<div>
									
<p>This is a continuation of an ongoing theme which is started here: <a href="https://osblog.stephenmarz.com/">https://osblog.stephenmarz.com</a>.</p>



<h2>Contents</h2>



<ol><li><a href="#s1">What is Supervisor Mode?</a></li><li><a href="#s2">Why Supervisor Mode?</a></li><li><a href="#s3">Complications while in Supervisor Mode</a></li><li><a href="#s4">Complications with Interrupts</a></li><li><a href="#s5">Conclusion</a></li></ol>



<hr>



<figure><p>
<iframe title="Adventures of OS: Going to Supervisor Mode" width="900" height="506" src="https://www.youtube.com/embed/U6M_hjYZPII?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>



<hr>



<h2 id="s1">What is Supervisor Mode?</h2>



<p>My original OS Blog (see here: <a href="https://osblog.stephenmarz.com/">https://osblog.stephenmarz.com</a>) ran the operating system in RISC-V’s <em>machine mode</em>, which is the most privileged mode in the RISC-V architecture. It has access to all control and status registers, runs in physical memory only, and has no restrictions placed upon it by the CPU.</p>



<p>I recently ran across the OpenSBI (Open Supervisor Binary Interface), listed on Github here: <a href="https://github.com/riscv/opensbi">https://github.com/riscv/opensbi</a>. It’s been around a little while, but it seeks to be an interface between the operating system and the machine–the low-level system. </p>



<p>Currently, OpenSBI has a legacy interface that abstracts the UART device for you, as well as a HART (hardware thread–RISC-V’s name for a CPU core) management system–start a hart at a given address, stop a hart, get the status of a hart, etc.</p>



<p>The supervisor mode, known as S mode in RISC-V, is two layers below Machine mode, as shown in the RISC-V specification below. This means that our operating system uses the OpenSBI set of utilities for very low level things, in which the OpenSBI abstracts away. This makes designing an operating system for the myriad of boards a bit easier.</p>



<div><figure><img loading="lazy" src="https://blog.stephenmarz.com/wp-content/uploads/2020/11/image-1024x292.png" alt="" width="512" height="146" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/11/image-1024x292.png 1024w, https://blog.stephenmarz.com/wp-content/uploads/2020/11/image-300x85.png 300w, https://blog.stephenmarz.com/wp-content/uploads/2020/11/image-768x219.png 768w, https://blog.stephenmarz.com/wp-content/uploads/2020/11/image.png 1243w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>RISC-V Privilege Levels</figcaption></figure></div>



<hr>



<h2 id="s2">Why Supervisor Mode?</h2>



<p>Why run the operating system at S mode? Well, whereas a high-level language as the application binary interface, or ABI, the operating system can rely on a certain set of utilities given by a RISC-V “bios” for a lack of a better term.</p>



<p>This allows our operating system to abstract much of the machine architecture away. Instead of relying on the actual system’s specification, we can program the operating system using more or less the RISC-V specification only.</p>



<p>To understand what’s going on, let’s take a look at the user level. This is where applications live. Whenever a user application runs afoul of the “rules”, such as dereferencing an invalid memory location or executing an illegal instruction, the CPU will trap to the machine mode, unless the trap is delegated lower. Luckily for us, OpenSBI delegates user traps to the supervisor mode, so our operating system can handle it.</p>



<p>Now, let’s move up one level. What happens when the operating system runs afoul of the rules? In most respects, the system crashes. An illegal instruction in machine mode will trap into machine mode. This can potentially cause a loop of traps in machine mode, as one compounds another.</p>



<p>So, as U-mode is to S-mode, S-mode is to M-mode, meaning that if the operating system runs at S-mode and messes with the CPU, then the OpenSBI will handle the trap. Usually, this means trying to load the hart into a stable, known state.</p>



<hr>



<h2 id="s3">Complications while in Supervisor Mode</h2>



<p>I wrote my operating system in machine mode to make it easier to understand the RISC-V architecture. Now, switching to S-mode has complicated some things. One of the major issues I have found is that the hart’s unique id is in the <em>mhartid</em> register. That little <em>m</em> in front of it means that it is a machine-mode register. Since we’re at a lower level, we’re not allowed to access any of the machine mode registers. If we try, we will get an <em>illegal instruction</em>.</p>



<p>This means that we have to keep track of our own core id. This makes context switching and putting applications on a different core slightly more complicated. We can’t just read the mhartid register and know our hart id. Instead, we have to follow the OpenSBI interface. This is easier said than done!</p>



<p>Now that we don’t have access to any of the machine mode registers, we have to use the supervisor levels. Luckily, RISC-V gives us “views” of the same register with an s in front of it. For example, mstatus becomes sstatus. The neat thing is that if we write to sstatus, the machine-only bits are masked, and we can only set the supervisor bits. This means we can’t switch ourselves into machine mode while in supervisor mode by simply setting the mstatus bits (bits 12 and 11).</p>



<div><figure><img loading="lazy" src="https://blog.stephenmarz.com/wp-content/uploads/2020/11/image-1-1024x202.png" alt="" width="512" height="101" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/11/image-1-1024x202.png 1024w, https://blog.stephenmarz.com/wp-content/uploads/2020/11/image-1-300x59.png 300w, https://blog.stephenmarz.com/wp-content/uploads/2020/11/image-1-768x152.png 768w, https://blog.stephenmarz.com/wp-content/uploads/2020/11/image-1-1536x303.png 1536w, https://blog.stephenmarz.com/wp-content/uploads/2020/11/image-1.png 1997w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>Machine Status Register Bits</figcaption></figure></div>



<p>The sstatus register is the exact same register as the mstatus register, but when we make writes to it, the CPU will not change any machine-only bits. This is called a “view” of the machine status register. Here’s the supervisor status register. Take note of the machine bits that are masked.</p>



<div><figure><img loading="lazy" src="https://blog.stephenmarz.com/wp-content/uploads/2020/11/image-2-1024x238.png" alt="" width="512" height="119" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/11/image-2-1024x238.png 1024w, https://blog.stephenmarz.com/wp-content/uploads/2020/11/image-2-300x70.png 300w, https://blog.stephenmarz.com/wp-content/uploads/2020/11/image-2-768x178.png 768w, https://blog.stephenmarz.com/wp-content/uploads/2020/11/image-2-1536x356.png 1536w, https://blog.stephenmarz.com/wp-content/uploads/2020/11/image-2.png 1603w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>Supervisor Status Register Bits</figcaption></figure></div>



<p>Notice that bits 12 and 11 (Machine Previous Privilege Mode [MPP]) are WPRI, which stands for Write-Preserve, Read-Ignore. Write-preserve means that if we write to bits 12 and 11, it will preserve their original value, which essentially prevents us from writing to MPP in supervisor mode. Read-ignore means that if we try to read bits 12 and 11, we won’t get the actual data. Instead, it ignores the data and usually will give us 0.</p>



<p>This changes the way we switch from supervisor mode into user mode. So, if we put 1 into SPP (bit 8 of sstatus), then when we execute the <em>sret</em> (supervisor return), then this bit will become the privilege level. Recall that level 1 is supervisor mode. If we put 0 in bit 8, then after an sret, we will be in user mode. Recall that user mode is level 0.</p>



<hr>



<h2 id="s4">Complications with Interrupts</h2>



<p>Interrupts trigger a pin on the CPU to cause a trap. This is usually in response to something, such as a timer, a software interrupt, or an external, platform-level interrupt, such as a keyboard input or wifi notification.</p>



<p>The interrupts I’m concerned about are at the platform level. RISC-V has a specification for the platform-level interrupt controller, or PLIC. In this, we can configure the PLIC to trap in supervisor mode or even in machine mode. Since the PLIC is directly connected to the CPU, we, at supervisor mode, can tell the PLIC where to send interrupts. This makes our job a little bit harder since there are many different configurations of multiple-harts, different hart configurations and so on.</p>



<p>To demonstrate this, here’s the memory map of the PLIC on a 5-hart CPU where the 0-hart only has M mode, and harts 1, 2, 3, and 4 have both M and S mode.</p>



<div><figure><img loading="lazy" src="https://blog.stephenmarz.com/wp-content/uploads/2020/11/image-4-1024x869.png" alt="" width="512" height="435" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/11/image-4-1024x869.png 1024w, https://blog.stephenmarz.com/wp-content/uploads/2020/11/image-4-300x255.png 300w, https://blog.stephenmarz.com/wp-content/uploads/2020/11/image-4-768x652.png 768w, https://blog.stephenmarz.com/wp-content/uploads/2020/11/image-4-1536x1303.png 1536w, https://blog.stephenmarz.com/wp-content/uploads/2020/11/image-4.png 1630w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>FU540 PLIC Memory Map</figcaption></figure></div>



<p>As you can see, our stride isn’t the same for every hart, so we will have to configure our operating system nearly at machine-level. If you take a look at the <em>virt</em> cpu in QEMU (see <a href="https://github.com/qemu/qemu/blob/master/include/hw/riscv/virt.h#L73">qemu/virt.h at master · qemu/qemu (github.com)</a>). So, I can’t go off of just configuring each hart to enable an interrupt, I have to specify the mode where I want the interrupt to be trapped. Furthermore, each hart is not necessarily the same, as you can see with the diagram above. the FU540 has hart 0 (called the “monitor core”) to supervise the other cores, which runs in machine mode only.</p>



<p>Traps also require us to context switch, by saving the current set of registers into the context running on the hart, scheduling the next context, and loading that context onto the hart. This was fairly simple in machine mode for one reason–the MMU is turned off automatically in machine mode. This is not the case in supervisor mode. Furthermore, the MMU register, called supervisor address translation and protection (SATP), is immediate. Meaning, if I set the mode, the MMU immediately turns on. This can be a problem because I have to juggle certain registers. Take a look at the trap handler written in RISC-V assembly below.</p>



<div><figure><img loading="lazy" src="https://blog.stephenmarz.com/wp-content/uploads/2020/11/image-6-1024x654.png" alt="" width="512" height="327" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/11/image-6-1024x654.png 1024w, https://blog.stephenmarz.com/wp-content/uploads/2020/11/image-6-300x192.png 300w, https://blog.stephenmarz.com/wp-content/uploads/2020/11/image-6-768x490.png 768w, https://blog.stephenmarz.com/wp-content/uploads/2020/11/image-6-1536x981.png 1536w, https://blog.stephenmarz.com/wp-content/uploads/2020/11/image-6.png 1563w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>Supervisor Address Translation and Protection Register Handler</figcaption></figure></div>



<p><em>(Updated screenshot): I originally had sstatus instead of sscratch. The point of csrrw is to make an atomic swap of sscratch into t6 and the old value of t6 into sscratch. This allows us to keep both values.</em> <em>As a side note, this is actually the second time I’ve done this. My typing fingers just like sstatus better than sscratch.</em></p>



<p>As you can see, we have to be careful not destroy a register in our context. I usually use the t6 register since it is register number 31, which is the last register for an ascending loop. In the code above, I’m making sure that no memory accesses are made after the SATP register is written to. Remember, it’s immediate. As soon as I write to the SATP register and set the mode, it is up and running since we’re in supervisor mode.</p>



<p>This leads us to a little bit of a problem. Unless we map this handler, it will not be able to execute–and we still need to get to <code data-enlighter-language="asm">sret</code>. Recall that X (execute) is one of our bits and so is the U (user) bit. So, how do we handle this? We will see in the next post. Stay tuned.</p>



<hr>



<h2 id="s5">Conclusion</h2>



<p>I’m still working on migrating my machine-mode operating system into a supervisor-mode operating system. This is a work in progress, so I encourage you to keep up to date on this blog!</p>



<p>Thanks for reading!</p>
								</div>
							</div></div>]]>
            </description>
            <link>https://blog.stephenmarz.com/2020/11/23/back-that-s-up/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25247759</guid>
            <pubDate>Sun, 29 Nov 2020 20:24:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Baricitinib treatment linked to reduced mortality in Covid-19 patients]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25247544">thread link</a>) | @draugadrotten
<br/>
November 29, 2020 | https://news.ki.se/baricitinib-treatment-linked-to-reduced-mortality-in-covid-19-patients | <a href="https://web.archive.org/web/*/https://news.ki.se/baricitinib-treatment-linked-to-reduced-mortality-in-covid-19-patients">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <a id="main-content" tabindex="-1"></a>      
  




  




<section id="RSID">

  

  <article>
    <div>
      
      <div>
        <p><span></span>Published:  2020-11-13 20:00 | Updated:  2020-11-17 09:25
        </p>
      </div>
      
      
      
      
  

                      <div>
          <p><img src="https://news.ki.se/sites/default/files/styles/slideshow_article/public/qbank/GettyImages-1035411158-custom20201113183820.jpg?h=b82b5380" alt="Pink pills on blue background"></p>
        </div>
            
            <p>The rheumatoid arthritis drug baricitinib can block viral entry and reduce mortality in patients with moderate to severe COVID-19, according to translational research by an international team coordinated by researchers from Karolinska Institutet in Sweden. The findings, published in the journal Science Advances, support the continuation of ongoing randomized clinical trials.</p>
      
      
                

  <div>
                  <div>
          <p><img src="https://news.ki.se/sites/default/files/styles/article_full_width/public/qbank/Volker%2520Lauschke-custom20201113183952.jpg" alt=""></p><p>Volker Lauschke, associate professor at the Department of Physiology and Pharmacology.
Photo: Jannis Politidis</p>
                  </div>
            <div>
        
            <p>“We are pleased to report a 71 percent reduction in mortality for the group receiving baricitinib in addition to standard care,” says <a href="https://staff.ki.se/people/vollau">Volker Lauschke</a>, corresponding author and associate professor of personalized medicine and drug development at the <a href="https://ki.se/en/fyfa/department-of-physiology-and-pharmacology">Department of Physiology and Pharmacology</a>, Karolinska Institutet. “These results are especially encouraging seeing as the study included a large cohort of elderly patients, a group that is often excluded in other trials.”</p>

<p>In the study, 83 patients hospitalized with COVID-19 pneumonia in Italy and Spain were treated with baricitinib in addition to standard care. Of these, 17 percent suffered an adverse outcome that resulted in death or invasive mechanical ventilation. This compared to 35 percent in the matched control group of 83 patients who received standard care only. The patients had a median age of 81 years.</p>

<h2>Well tolerated</h2>

<p>The drug was generally well tolerated with a reduction in inflammation from the first treatment days, according to the researchers. Previously reported side-effects of long-term baricitinib use, including coagulopathy and thrombosis, were not evident in any of the patients, possibly due to treatment with anti-coagulating medicine. However, some adverse events including bacterial infections and gastrointestinal and cardiovascular complications were noted, although these were also observed in the control group so it is unclear what, if anything, can be ascribed to baricitinib.</p>

<p>In a <a href="https://news.ki.se/rheumatoid-arthritis-drug-shows-promise-against-covid-19-study-finds">prior study</a>, the same team of researchers reported how they used artificial intelligence (AI) to identify baricitinib as a promising repurposing candidate for COVID-19. That study also showed how the drug inhibited inflammation and reduced the viral load of SARS-CoV-2.</p>

<h2>3D mini livers</h2>

<p>In the current study, the researchers elaborated on those findings by demonstrating that interferons, cytokines made and released by host cells in response to viruses, significantly increases the expression of the ACE2 receptor, which acts as an entry point for SARS-CoV-2 into human cells. While liver injury is commonly observed in severe COVID-19, mechanisms and dynamics of SARS-CoV-2 infections had not been investigated in this organ.</p>

<p>By combining 3D mini organs of human liver cells, RNA sequencing and super-resolution microscopy, the scientists were able to show that barcitinib reversed ACE2 gene expression changes triggered by interferons and reduced SARS-CoV-2 infectivity. Interestingly, interferons did not have the same effect on the ACE2 receptor in lung organoids, suggesting that these signaling proteins affect pulmonary and liver organs differently.</p>

<h2>Dual actions</h2>
      
      </div>
      </div>

              

  <div>
                  <div>
          <p><img src="https://news.ki.se/sites/default/files/styles/article_full_width/public/qbank/ali_mirazimi_1_foto_Martin_Stenmark-custom20201113182802.jpg" alt="Portrait of Ali Mirazimi outdoors in a park."></p><p>Ali Mirazimi, adjunct professor at the Department of Laboratory Medicine.
Photo: Martin Stenmark</p>
                  </div>
            <div>
        
            <p>“Our findings explain the dual anti-cytokine and anti-viral actions of baricitinib and support further evaluation in randomized control trials,” says <a href="https://staff.ki.se/people/alimir">Ali Mirazimi</a>, adjunct professor at the <a href="https://ki.se/en/labmed/department-of-laboratory-medicine">Department of Laboratory Medicine</a>, Karolinska Institutet, and co-author of the study.</p>

<p>The researchers note that a limitation of the study was the lack of a placebo control group, which is included in industry-sponsored randomized controlled trials that are currently ongoing.</p>

<p>The clinical study was led by researchers at Imperial College London, U.K., Complejo Hospitalario Universitario de Albacete, Spain, and the University of Pisa, Italy, while the mechanistic investigations on 3D human tissue models were conducted at Karolinska Institutet.</p>

<p>The research was funded by the Swedish Research Council, the Strategic Research Programmes in Diabetes and Stem Cells and Regenerative Medicine, EU/EFPIA/OICR/McGill/KTH/Diamond Innovative Medicines Initiative, Ricerca Corrente Linea 1 and 3, the National Science Foundation, the National Institutes of Health, the Department of Energy, CIBERFES, Instituto de Salud Carlos III, Ministerio de Economía y Competitividad, España. Ayuda cofinanciada por el Fondo Europeo de Desarrollo Regional FEDER Una Manera de hacer Europa, Imperial BRC, ECMC, the NIHR and AAC.</p>

<p>The authors of the paper have reported several conflicts of interest, including lecture fees and research grants from pharmaceutical companies that own baricitinib. Some of the authors have founded companies that feature technologies mentioned in this study. For a complete list of disclosures, please see the full article.</p>
      
      </div>
      </div>

              
  <div>
    <div>
                      <div>
          <h2>Facts about baricitinib</h2>

<ul><li>Baricitinib is a once-daily oral drug used for treatment of adult patients with moderate to severe rheumatoid arthritis.</li>
	<li>It acts as an inhibitor of janus kinase, a type of enzyme that acts as an “on” or “off” switch in many cellular functions.</li>
	<li>The drug has dual functions and acts by interfering with the inflammatory processes of the immune system as well as by directly inhibiting viral entry. It is seen as a potential treatment candidate for COVID-19.</li>
</ul>
        </div>
          </div>
  </div>

              

  <div>
                <div>
        
            <h2>Publication</h2>

<p>“<a href="https://advances.sciencemag.org/lookup/doi/10.1126/sciadv.abe4724">JAK inhibition reduces SARS-CoV-2 liver infectivity and modulates inflammatory responses to reduce morbidity and mortality</a>,” Justin Stebbing, Ginés Sánchez Nievas, Marco Falcone, Sonia Youhanna, Peter Richardson, Silvia Ottaviani, Joanne X. Shen, Christian Sommerauer, Giusy Tiseo, Lorenzo Ghiadoni, Agostino Virdis, Fabio Monzani, Luis Romero Rizos, Francesco Forfori, Almudena Avendaño Céspedes, Salvatore De Marco, Laura Carrozzi, Fabio Lena, Pedro Manuel Sánchez-Jurado, Leonardo Gianluca Lacerenza, Nencioni Cesira, David Caldevilla Bernardo, Antonio Perrella, Laura Niccoli, Lourdes Sáez Méndez, Daniela Matarrese, Delia Goletti, Yee-Joo Tan, Vanessa Monteil, George Dranitsaris, Fabrizio Cantini, Alessio Farcomeni, Shuchismita Dutta, Stephen K. Burley, Haibo Zhang, Mauro Pistello, William Li, Marta Mas Romero, Fernando Andrés Pretel, Rafaela Sánchez Simón-Talero, Rafael García-Molina, Claudia Kutter, James H. Felce, Zehra F. Nizami, Andras G. Miklosi, Josef M. Penninger,Francesco Menichetti, Ali Mirazimi, Pedro Abizanda and Volker M. Lauschke, Science Advances, online November 13, 2020, doi: 10.1126/sciadv.abe4724</p>
      
      </div>
      </div>

        
          </div>

    
  </article>

  

</section>



  </div></div>]]>
            </description>
            <link>https://news.ki.se/baricitinib-treatment-linked-to-reduced-mortality-in-covid-19-patients</link>
            <guid isPermaLink="false">hacker-news-small-sites-25247544</guid>
            <pubDate>Sun, 29 Nov 2020 19:53:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Software and Hardware for General Robots]]>
            </title>
            <description>
<![CDATA[
Score 36 | Comments 22 (<a href="https://news.ycombinator.com/item?id=25247499">thread link</a>) | @ericjang
<br/>
November 29, 2020 | https://blog.evjang.com/2020/11/moravec-bots.html | <a href="https://web.archive.org/web/*/https://blog.evjang.com/2020/11/moravec-bots.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-6885150399029037702" itemprop="description articleBody">
<p><i>Disclaimer, these are just my opinions and not necessarily those of my employer or robotics colleagues.</i></p><p><a href="https://news.ycombinator.com/item?id=25247499">Hacker News Discussion</a></p><p><a href="https://en.wikipedia.org/wiki/Moravec%27s_paradox">Moravec's Paradox</a> describes the observation that our AI systems can solve "adult-level cognitive" tasks like <a href="https://en.wikipedia.org/wiki/MuZero">chess-playing</a> or passing <a href="https://en.wikipedia.org/wiki/GPT-3">text-based intelligence tests</a> fairly easily, while accomplishing basic sensorimotor skills like crawling around or grasping objects - things one-year old children can do - are very difficult.</p><p>Anyone who has tried to build a robot to do anything<span>&nbsp;</span>will realize that Moravec's Paradox is not a paradox at all, but rather a direct corollary of our physical reality being so&nbsp;<i>irredeemably complex&nbsp;</i>and <i>constantly demanding</i><i>. </i>Modern humans traverse <i>millions </i>of square kilometers in their lifetime, a labyrinth full of dangers and opportunities. If&nbsp;we had to consciously process and deliberate all the survival-critical sensory inputs and motor decisions like we do moves in a game of chess, we would have probably been selected out of the gene pool by Darwinian evolution. Evolution has optimized our biology to perform sensorimotor skills in a&nbsp;split second and make it feel easy.&nbsp;</p><p>Another way to appreciate this complexity is to adjust your daily life&nbsp;to a major motor disability, like losing fingers or trying to get around San Francisco without legs.</p><p><b>Software for General Robots</b></p><p>The difficulty of&nbsp;sensorimotor&nbsp;problems is especially apparent to people who work in robotics and get their hands dirty with the messiness of "the real world". What are the consequences of an irredeemably complex reality on how we build software abstractions for controlling robots?&nbsp;</p><p>One of my pet peeves is when people who do not have sufficient respect for Moravec's Paradox propose a programming model where high-level robotic tasks ("make me dinner") can be divided into sequential or parallel computations with clearly defined logical boundaries: wash rice, de-frost meat, get the plates, set the table, etc. These sub-tasks can be in turn broken down further. When a task cannot be decomposed further because there are too many edge cases for conventional software to handle ("does the image contain a cat?"), we can attempt to invoke a Machine Learning model as "magic software" for that capability.</p><p>This way of thinking - symbolic logic that calls upon ML code - arises from engineers who are used to clinging to the tidiness of <a href="https://medium.com/@karpathy/software-2-0-a64152b37c35">Software 1.0 abstractions</a>&nbsp;and&nbsp;<a href="https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/concepts/async/">programming tutorials</a>&nbsp;that use cooking analogies.&nbsp;</p><p>Do you have any idea how much intelligence goes into a task like "fetching me a snack", at the very lowest levels of motor skill? Allow me to illustrate. I recorded a short video of me opening a package of dates and annotated it with all the motor sub-tasks I performed in the process.</p><p><iframe allowfullscreen="" height="416" src="https://www.youtube.com/embed/b1lysnGFpqI" width="501" youtube-src-id="b1lysnGFpqI"></iframe></p><p>In the span of 36 seconds, I counted about 14 motor and cognitive skills. They happened so quickly that I didn't consciously notice them until I went back and analyzed the video, frame by frame.&nbsp;</p><p>Here are some of the things I did:</p><div><ul><li>Leverage past experience opening this sort of package to understand material properties and how much force to apply.</li><li>Constantly adapt my strategy in response to unforeseen circumstances (Ziploc not giving)</li><li>Adjusting grasp when slippage occurs</li><li>Devising an ad-hoc Weitlaner Retractor with thumb knuckles to increase force on the Ziploc.</li></ul></div><p>As a roboticist, it's humbling to watch&nbsp;<a href="https://twitter.com/ericjang11/status/1315537835630358530?s=20">videos of animals</a>&nbsp;making decisions so quickly and then watch our own robots struggle to do the simplest things. We even have to&nbsp;<a href="https://www.youtube.com/watch?v=QzlI_ny4l8s">speed up the robot video 4x-8x&nbsp;</a>to prevent the human watcher from getting bored!&nbsp;</p><div><div><p>With this video in mind, let's consider where we currently are in the state of robotic manipulation. In the last decade or so, multiple research labs have used deep learning to develop robotic systems that can perform any-object robotic grasping from vision. Grasping is an important problem because in order to manipulate objects, one must usually first grasp them. It took the Google Robotics and X teams&nbsp;<a href="https://www.blogger.com/blog/post/edit/842965756326639856/6885150399029037702#">2-3 years</a>&nbsp;to develop our own system, QT-Opt. This was a huge research achievement because it was a general method that worked on pretty much any object and, in principle, could be used to learn other tasks.&nbsp;</p></div><p>Some people think that this capability to pick up objects can be wrapped in a simple programmatic API and then used to bootstrap us to human-level manipulation. After all, hard problems are just composed of simpler problems, right?&nbsp;</p></div><p>I don't think it's quite so simple. The high-level API call&nbsp;"<span>pick_up_object()</span>" implies a clear semantic boundary between when the robot grasping begins and when it ends. If you re-watch the above video above, how many times do I perform a grasp? It's not clear to me at all where you would slot those function calls. Here is&nbsp;<a href="https://forms.gle/1GLHrf4PcBdHKXNS6">a survey</a>&nbsp;if you are interested in participating in a poll of "how many grasps do you see in this video", whose results I will update in this blog post.&nbsp;</p><p>If we need to solve 13 additional manipulation skills just to open a package of dates, and each one of these capabilities take 2-3 years to build, then we are a long, long way from making robots that match the capabilities of humans. Never mind that there isn't a clear strategy for how to integrate all these behaviors together into a single algorithmic routine. Believe me, I wish reality was simple enough that complex robotic manipulation could be done mostly&nbsp;in Software 1.0. However, as we move beyond pick-and-place towards dexterous and complex tasks, I think we will need to completely rethink how we integrate different capabilities in robotics.</p><p>As you might note from the video, the meaning of a "grasp" is somewhat blurry. Biological intelligence was not specifically evolved for grasping - rather, hands and their behaviors emerged from a few core drives:&nbsp; regulate internal and external conditions, find snacks, replicate.</p><div><div><p>None of this is to say that our current robot platforms and the Software 1.0 programming models are useless for robotics research or applications. A general purpose function&nbsp;<span>pick_up_object()&nbsp;</span>can still be combined with "Software 1.0 code" into a reliable system worth billions of dollars in value to Amazon warehouses and other logistics fulfillment centers. General pick-and-place for any object in any unstructured environment remains an unsolved, valuable, and&nbsp;<i>hard</i>&nbsp;research problem.</p></div><p><b>Hardware for General Robots</b></p><p>What robotic hardware do we require in order to "open a package of dates"?</p><p>Willow Garage was one of the pioneers in home robots, showing that a teleoperated PR2 robot could be used to tidy up a room (note that two arms are needed here for more precise placement of pillows). These are made up of many pick-and-place operations.</p><p><iframe allowfullscreen="" height="374" src="https://www.youtube.com/embed/o7JH3UWO6I0" width="450" youtube-src-id="o7JH3UWO6I0"></iframe></p><p>This video was made in 2008. That was 12 years ago! It's sobering to think of how much time has passed and how little the needle has seemingly moved. Reality is hard.&nbsp;</p><p>The <a href="https://hello-robot.com/product">Stretch</a>&nbsp;is&nbsp;a simple telescoping arm attached to a vertical gantry. It can do things like pick up objects, wipe planar surfaces, and open drawers.</p><div><p><iframe allowfullscreen="" height="373" src="https://www.youtube.com/embed/2msVU0ygrqM" width="449" youtube-src-id="2msVU0ygrqM"></iframe></p><p>However, futurist beware! A common source of hype for people who don't think enough about physical reality is to watch demos of robots doing useful things in one home, and then conclude that the same robots are ready to do those tasks in <i>any home</i>.</p><div><p>The Stretch video shows the&nbsp;<a href="https://youtu.be/2msVU0ygrqM?t=41">robot pulling open a dryer door</a>&nbsp;(left-swinging) and retrieving clothes from it. The video is a bit deceptive - I think the camera&nbsp; physically cannot see the interior of the dryer, so even though a human can teleoperate the robot to do the task, it would run into serious difficulty when ensuring that the dryer has been completely emptied.</p><p>Here is a picture of my own dryer, which features a dryer with a <i>right-swinging</i>&nbsp;door close to a wall. I'm not sure if the Stretch actually can fit in this tight space, but the PR2 definitely would not be able to open this door without the base getting in the way.&nbsp;</p></div><div><p><a href="https://1.bp.blogspot.com/-n8U9MC3ww-Q/X8MEUSH03jI/AAAAAAAAepg/JkqUn4xiirU2wiJ76aEC4av5ukvVqNtkACNcBGAsYHQ/s2048/128546115_197081455371161_5776583945816761781_n.jpg"><img data-original-height="2048" data-original-width="1536" height="320" src="https://1.bp.blogspot.com/-n8U9MC3ww-Q/X8MEUSH03jI/AAAAAAAAepg/JkqUn4xiirU2wiJ76aEC4av5ukvVqNtkACNcBGAsYHQ/s320/128546115_197081455371161_5776583945816761781_n.jpg"></a><a href="https://1.bp.blogspot.com/-Wxb4M30Yk3A/X8MEhN4mcvI/AAAAAAAAepo/Pv7jQZ_NXPU19mjwdHnZGQKf2FHcbrAmQCNcBGAsYHQ/s1920/128903470_992029601279712_5029308404263396832_n.png"><img data-original-height="1920" data-original-width="1080" height="400" src="https://1.bp.blogspot.com/-Wxb4M30Yk3A/X8MEhN4mcvI/AAAAAAAAepo/Pv7jQZ_NXPU19mjwdHnZGQKf2FHcbrAmQCNcBGAsYHQ/w225-h400/128903470_992029601279712_5029308404263396832_n.png" width="225"></a></p></div><div><p>Reality's edge cases are often swept under the rug when making robot demo videos, which usually show the robot operating in an optimal environment that the robot is well-suited for. But the full range of tasks humans do in the home is&nbsp;<i>vast</i>.&nbsp; Neither the PR2 nor the Stretch can crouch under a table to pick up lint off the floor, change a lightbulb while standing on a chair, fix caulking in a bathroom, open mail with a letter opener, move dishes from the dishwasher to the high cabinets, break down cardboard boxes for the recycle bin, go outside and retrieve the mail.&nbsp;</p><div><p>And of course, they can't even open a Ziploc package of dates. If you think <i>that </i>was&nbsp;complex, here is a first-person video of me chopping strawberries, washing utensils, and decorating a cheesecake. This was recorded with a GoPro strapped to my head. Watch each time my fingers twitch - each one is a separate manipulation task!</p></div><p><iframe allowfullscreen="" height="400" src="https://www.youtube.com/embed/_Hd7JkOo0B8" width="482" youtube-src-id="_Hd7JkOo0B8"></iframe></p><br></div><p>We often talk about a future where robots do our cooking for us, but I don't think it's possible with any hardware on the market today. The only viable hardware for a robot meant to do <i>any task</i> in human spaces is an adult-sized humanoid, with two-arms, two-legs, and five fingers on each hand.&nbsp;</p><p>Just like I discussed about Software 1.0 in robotics, there is still an enormous space of robot morphologies that can still provide value to research and commercial applications. That doesn't change the fact that any alternative hardware can't do all the things a humanoid can in a human-centric space. Agility Robotics is one of the companies <a href="https://www.youtube.com/watch?v=BKjRVlzKEMI">that gets it</a>&nbsp;on the hardware design front. People who build physical robots use their hands a lot -&nbsp;could you imagine the robot you are building assembling a copy of itself?&nbsp;</p><p><b>Why Don't We Just Design Environments to be More Robot-Friendly?</b></p><p>A compromise is to co-design the environment with the robot to avoid infeasible tasks like above. This can simplify both the hardware and software problems. Common examples I hear <i>incessantly </i>go like this:</p><div><ol><li>Washing machines are better than a bimanual robot washing dishes in the sink, and a dryer is a more efficient machine than a human hanging out clothes to air-dry.</li><li>Airplanes are better at …</li></ol></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.evjang.com/2020/11/moravec-bots.html">https://blog.evjang.com/2020/11/moravec-bots.html</a></em></p>]]>
            </description>
            <link>https://blog.evjang.com/2020/11/moravec-bots.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25247499</guid>
            <pubDate>Sun, 29 Nov 2020 19:47:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Q&A with the Creator of the Pijul Version Control System]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25247489">thread link</a>) | @gbrown_
<br/>
November 29, 2020 | https://initialcommit.com/blog/pijul-creator | <a href="https://web.archive.org/web/*/https://initialcommit.com/blog/pijul-creator">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
			                <div>
			                    <p><img src="https://initialcommit.com/img/initialcommit/pijul-creator.png" title="Q&amp;A with the Creator of the Pijul Version Control System" alt="Image of Q&amp;A with the Creator of the Pijul Version Control System">
			                    </p>
			                    
			                    
			                    	
			                    
			                    
			                    
			                    <h2>Introduction</h2>
<p>This article is a Q&amp;A format with Pierre-Ã‰tienne Meunier, the creator and lead developer of the Pijul VCS (version control system).</p>
<h2>Q: What is your background in computer science and software development?</h2>
<p><strong>A:</strong> I've been an academic researcher for about 10 years, and I've recently left academia to found a science company working on issues related to energy savings and decentralised energy production. I'm the only computer scientist, and we work with sociologists and energy engineers.</p>
<p>While I was in academia, my main area of work was asynchronous and geometric computing, whose goal is to understand how systems with lots of simple components can interact in a geometric space to make computation happen. My current work is also somewhat related to this, although in a different way.</p>
<p>My favourite simple components differ from man-made "silicon cores", in that they happen in nature or at least in the real world, and are not made for the specific purpose of computation. For many years, I've worked on getting molecules to self-organise in a test tube to form meaningful shapes. And I've also worked on Pijul, where different authors edit a document in a disorderly way, without necessarily agreeing on "good practices" beforehand.</p>
<p>The idea of Pijul came while Florent Becker and myself were writing a paper on self-assembly. At some point we started thinking about the shortcomings of Darcs (Florent was one of the core contributors of Darcs at the time). We decided that we had to do something about it, to keep the "mathematically designed" family of version-controlled systems alive.</p>
<h2>Q: What is your approach to learning, furthering your knowledge and understanding on a topic?  What resources do you use?</h2>
<p><strong>A:</strong> The thing I love the most about computer science is that it can be used to think about a wide variety of subjects of human knowledge, and yet you can get a very concrete and very cheap experience of it by programming a computer. In all disciplines, the main way for virtually anyone to learn technical and scientific things is to play with them.</p>
<p>For example you can read a book about economics, and then immediately write little simulations of games from game theories, or a basic simulator of macroeconomics. You can read the Wikipedia page about wave functions, and then start writing code to simulate a quantum computer. These simulations will not be efficient or realistic, but they will allow their authors to formalise their ideas in a concrete and precise way.</p>
<p>By following this route, you not only get a door into the subject you wanted to understand initially, you also get access to philosophical questions that seemed very abstract before, since computer science is a gateway between the entire world of "pure reason" (logic and mathematics), as Kant would say, and the physical world. What can we know for a fact? Is there a reality beyond language? And suddenly you get a glimpse of what Hume, Kant, Wittgensteinâ€¦ were after.</p>
<h2>Q: What was the first programming language you learned and how did you get into it?</h2>
<p><strong>A:</strong> I think I started with C when I was around 12. My uncle had left France to take an administrative position high up at the Vatican, and left most of his things with his brothers and sisters. My mother got his computer, a Victor v286, which was already pretty old when we got it (especially in the days where Moore's law was at its peak). Almost nothing was supplied with it: MS-DOS, a text processor, and a C IDE. So if I wanted to use it, I had little choice. I don't remember playing much with the text processor.</p>
<h2>Q: Why did you decide to start a Version Control System? What is it about VCS that interests you?</h2>
<p><strong>A:</strong> My first contact with version control systems was with SVN at university, and I remember being impressed when I first started using it for the toy project we were working on.</p>
<p>Then, when I did my PhD, my friends and colleagues convinced me to switch to Darcs. As the aspirant mathematician I was, the idea of a rigorous patch theory, where detecting conflicts was done entirely by patch commutation, was appealing. As everybody else, I ran every now and then into Darcs' issues with conflicts, until Florent and I noticed that (1) it had become nearly impossible to convince our skeptical colleagues to install and use it and (2) this particular corner of version control systems was surprisingly close to the rest of our research interests, and that's how we got started.</p>
<h2>Q: How do you decide what projects to work on?</h2>
<p><strong>A:</strong> This is one of my biggest problems in life. I'm generally interested in a large number of things, and I have little time to explore all of them in the depth they deserve. When I have to choose, I try to do what I think will teach me (and hopefully others) the most, or what will change things the most.</p>
<h2>Q: Why did you choose to write Pijul in Rust?</h2>
<p><strong>A:</strong> We didn't really choose, Rust was the only language at the time that ticked all the boxes:</p>
<ul>
<li>
<p>Statically typed with automatic memory management, because we were writing mathematical code, and we were just two coders, so we needed as much help from compilers as we could get. That essentially meant one of OCaml, Haskell, Scala, Rust, Idris.</p>
</li>
<li>
<p>Fast, because we knew we would be benchmarked against Git. That ruled out Scala (because of startup times) and Idris, which was experimental at the time. Also, Haskell can be super fast, but the performance is hard to guarantee deterministically.</p>
</li>
<li>
<p>Could call C functions on Windows. That ruled out OCaml (this might have been fixed since then), and was a strong argument for Rust, since the absence of a GC makes this particularly easy.</p>
</li>
<li>
<p>An additional argument for Rust is that compiling stuff is super easy. Sure, there are system dependencies, but most of the time, things "just work". It works so well that most things that people are encouraged to split their work into multiple crates rather than bundling it up into a large monolithic library. As a consequence, even very simple programs can easily have dozens of dependencies.</p>
</li>
</ul>
<h2>Q: When you encounter a tough development problem, what is your process to solve it? Especially if the problem is theoretical in nature?</h2>
<p><strong>A:</strong> It really depends on the problem, but I tend to start all my projects by playing with toy examples, until I understand something new. I take notes about the playing, and then try to harden the reasoning by making the intuitive parts rigorous. This is often where bugs (both in mathematical proofs and in software) are hidden. Often, this needs a new iteration of playing, and sometimes many more. I usually find that coding is a good way to play with a problem, even though it isn't always possible, especially in later iterations of the project.</p>
<p>Of course, for things like Pijul, code is needed all the way to the end, but it is a different sort of code, not the "prototype" kind used to understand a problem.</p>
<p>Apart from that, I find that taking a break to walk outside, without forcing myself to stay too focused on the problem, is very useful. I also do other, more intensive sports, but they rarely help solve my problems.</p>
<h2>Q: How big is the Pijul team? Who is it made up of?</h2>
<p><strong>A:</strong> For quite a while there was just Florent and myself, then a few enthusiasts joined us to work on the previous version: we had about 10 contributors, including Thomas Letan who, in addition to his technical contributions, organised the community, welcomed people, etc. And Tae Sandoval, who wrote a popular tutorial (Pijul for Git users), and has been convincing people on social media at an impressive rate for a few years.</p>
<p>Now that we have a candidate version that seems applicable to real-life projects, the team has started growing again, and the early alpha releases of version 1.0.0, even though they still have a few bugs, are attracting new contributors and testers.</p>
<h2>Q: What are your goals for Pijul capabilities, growth, and adoption?</h2>
<p><strong>A:</strong> When Pijul becomes stable, it will be usable for very large projects, and bring more sanity to source code management, by making things more deterministic.</p>
<p>This has the potential to save a large number of engineering hours globally, and to use continuous integration tools more wisely: indeed, on large repositories, millions of CPU-hours are wasted each year just to check that Git and others didn't shuffle lines around during a merge.</p>
<p>Smaller projects, beginners and non-technical people could also benefit from version control, but they aren't using it now, or at least not enough, because the barrier is just too high. Moreover, in some fields of industry and administration, people are doing version control manually, which seems like a giant waste of human time to me, but I also know that no current tool can do that job.</p>
<p>About growth and adoption, I also want to mention that Pijul started as an open source project, and that we are strongly committed to keeping it
open source. Since there is a large amount of tooling to be developed around it to encourage adoption (such as text editor plugins, CI/CD
toolingâ€¦), we are currently trying to build a commercial side as well, in order to fund these developments. This could be in the form of support, hosting, or maybe specialised applications of Pijul, or all that at the same time.</p>
<h2>Q: Do you think Pijul (or any other VCS) could ever overtake Git?</h2>
<p><strong>A:</strong> I think there could be a space for both. Git is meant as a content-addressable storage engine, and is extraordinarily efficient at that. One thing that is particularly cool with focusing on versions is that diffs can be computed after the fact, and I can see how this is desirable sometimes. For example, for cases where only trivial merges happen (for example adding a file), such as scientific data, this models the reality quite well, as there is no …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://initialcommit.com/blog/pijul-creator">https://initialcommit.com/blog/pijul-creator</a></em></p>]]>
            </description>
            <link>https://initialcommit.com/blog/pijul-creator</link>
            <guid isPermaLink="false">hacker-news-small-sites-25247489</guid>
            <pubDate>Sun, 29 Nov 2020 19:45:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ten Problems for Silicon Valley in the 2020s]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 22 (<a href="https://news.ycombinator.com/item?id=25247429">thread link</a>) | @DrNuke
<br/>
November 29, 2020 | https://www.tenproblems.com/2020/11/29/ten-problems-for-silicon-valley-in-the-2020s/ | <a href="https://web.archive.org/web/*/https://www.tenproblems.com/2020/11/29/ten-problems-for-silicon-valley-in-the-2020s/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<p><strong>Literature Review: Silicon Valley Problems for the 2020s</strong></p>



<p>Over the last 20 years, Silicon Valley has benefited from a once-in-a-lifetime alignment of advantages. American primacy, the ubiquity of cheap capital, the arrival of the smartphone (among other widely adopted tech innovations), and, perhaps most significantly, a benign regulatory environment, have all conspired to create a historic concentration of wealth and power. That might not be true for much longer, however. There are signs that the gilded age for consumer internet businesses may be drawing to a close [1].</p>



<p>In addition to Google’s dominant role in digital advertising and its alleged practice of steering users to search results beneficial to itself, U.S. lawmakers are eyeing Facebook’s overwhelming control of social media, Amazon’s mounting command of retail markets, and potential privacy violations by all the major platforms. But Big Tech’s most pernicious effects on economic growth and consumer welfare may stem less from “anticompetitive and exclusionary practices” than from its role in directing technological change more broadly [2].</p>



<p>As Facebook, Twitter, and YouTube have devoured the online world, they have undermined traditional media, empowered propagandists, and widened America’s political divides. The smartphone, for all its wonder and utility, has also proved to be a narcotizing agent. But what if, instead of focusing on Big Tech’s sins of commission, we paid equal attention to its sins of omission—the failures, the busts, the promises unfulfilled [3]?</p>



<p>The Valley’s most valuable product is the contrarian thinking that fuels its innovation culture. World-famous companies that have never turned a profit. A sprawling homeless epidemic cheek by jowl with some of the wealthiest zip codes in the world. Techies who are more likely to bond at Burning Man than at golf courses. Silicon Valley seems to make little sense from the outside. Silicon Valley start-ups have received the lion’s share of US-based venture capital funding over the past 10 years. Yet, many visiting executives struggle to find a foothold because they can’t seem to find the magic formula that makes Silicon Valley tick [4].</p>



<p>Why do tech elites believe they are the world’s greatest do-gooders and why does it matter what they say and (claim to) think? Solutionist ideas have become central to the (self-)image of today’s tech companies. Solutionism refers to the idea that the use of technologies – by inventive and cunning entrepreneurs – is the royal road to fixing social problems. Solutionist ideas are indeed central to the worldview of tech elites, and that they are also gaining ground in the broader tech milieu, although not yet in the normative discourse of capitalism at large [5].</p>



<p>Starting from such general references, this booklet identifies ten relevant areas from very recent contributions put forward at academic level in the form journal articles, conference proceedings and students’ theses. Ten freely accessible internet references have been selected for each area and direct links are provided at the end of each chapter for own consultation. Our selected references do not intend to mirror ranking indexes nor establish novel classifications. On the contrary, they are meant to represent peer-reviewed, diverse and scientifically-sound case studies for vertical dissemination aimed at non-specialist readers. They will also be able to scoop even more references through the bibliography that is reported at the end of each selected reference.</p>



<p>Without further ado, these are the “<a href="https://www.tenproblems.com/">Ten Problems for Silicon Valley in the 2020s</a>” that we are going to introduce in this booklet:</p>



<ol type="1"><li>solutionism,</li><li>monopolies,</li><li>diversity,</li><li>outsiders,</li><li>gig economy,</li><li>misuse,</li><li>narrowness,</li><li>obsolescence,</li><li>manipulation,</li><li>public mood.</li></ol>



<p>Each problem has its own dedicated chapter made of an introductory section, a short presentation of the ten selected references and a conclusions section.</p>



<p>The final chapter of this booklet will report the conclusions from each chapter again in order to provide a complete executive summary.</p>



<p><strong>GENERAL REFERENCES CITED</strong></p>



<p>[1] M. Gavet, “What’s Next for Silicon Valley?”, 30 Sep 2020, Harvard Business Review, online at <a href="https://hbr.org/2020/09/whats-next-for-silicon-valley" target="_blank" rel="noreferrer noopener">https://hbr.org/2020/09/whats-next-for-silicon-valley</a> , accessed on 23 Nov 2020</p>



<p>[2] D. Acemoglu, “Antitrust Alone Won’t Fix the Innovation Problem”, 31 Oct 2020, CGTN, online at <a href="https://news.cgtn.com/news/2020-10-31/Antitrust-alone-won-t-fix-the-innovation-problem-V2wpoN4Y7K/index.html" target="_blank" rel="noreferrer noopener">https://news.cgtn.com/news/2020-10-31/Antitrust-alone-won-t-fix-the-innovation-problem-V2wpoN4Y7K/index.html</a> , accessed on 23 Nov 2020</p>



<p>[3] D. Thompson, “The Real Trouble With Silicon Valley”, Jan/Feb 2020, The Atlantic, online at <a href="https://www.theatlantic.com/magazine/archive/2020/01/wheres-my-flying-car/603025/" target="_blank" rel="noreferrer noopener">https://www.theatlantic.com/magazine/archive/2020/01/wheres-my-flying-car/603025/</a> , accessed on 23 Nov 2020</p>



<p>[4] G. Rangan et al., “Illogical Truths: The Paradoxes of Silicon Valley”, 27 Oct 2020, INSEAD Knowledge, online at <a href="https://knowledge.insead.edu/blog/insead-blog/illogical-truths-the-paradoxes-of-silicon-valley-15451" target="_blank" rel="noreferrer noopener">https://knowledge.insead.edu/blog/insead-blog/illogical-truths-the-paradoxes-of-silicon-valley-15451</a> , accessed on 23 Nov 2020 </p>



<p>[5] O. Nachtwey et al., “The Solutionist Ethic and the Spirit of Digital Capitalism”, 13 March 2020, University of Basel and European University Institute, SocArXiv, doi:10.31235/osf.io/sgjzq , online at <a href="https://edoc.unibas.ch/76426/1/Nachtwey%2C%20Seidl_The%20Solutionist%20Ethic%20and%20the%20Spirit%20of%20Digital%20Capitalism.pdf" target="_blank" rel="noreferrer noopener">https://edoc.unibas.ch/76426/1/Nachtwey%2C%20Seidl_The%20Solutionist%20Ethic%20and%20the%20Spirit%20of%20Digital%20Capitalism.pdf</a></p>



<hr>



<figure><a href="https://www.amazon.com/dp/B08P9TWKWV/" target="_blank" rel="noopener noreferrer"><img loading="lazy" width="512" height="800" src="https://www.tenproblems.com/wp-content/uploads/2020/11/23.jpg" alt="Silicon Valley Problems" srcset="https://www.tenproblems.com/wp-content/uploads/2020/11/23.jpg 512w, https://www.tenproblems.com/wp-content/uploads/2020/11/23-192x300.jpg 192w" sizes="(max-width: 512px) 100vw, 512px"></a><figcaption><em>“Ten Problems for Silicon Valley in the 2020s” booklet for Amazon Kindle, 2020; click on the cover to go to the dedicated Amazon listing page</em></figcaption></figure>



<hr>



<figure><p>
<iframe title="Ten Problems for Silicon Valley in the 2020s" width="580" height="326" src="https://www.youtube.com/embed/8LIrsUsLb08?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>

		</div><!-- .entry-content -->

	</div></div>]]>
            </description>
            <link>https://www.tenproblems.com/2020/11/29/ten-problems-for-silicon-valley-in-the-2020s/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25247429</guid>
            <pubDate>Sun, 29 Nov 2020 19:38:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Canadian and American leaders battle in video game for charity]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25247242">thread link</a>) | @emptybits
<br/>
November 29, 2020 | https://www.cbc.ca/news/politics/among-us-singh-ocasio-cortez-200k-donations-1.5820831 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/politics/among-us-singh-ocasio-cortez-200k-donations-1.5820831">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>A video game livestream session between federal NDP Leader Jagmeet Singh and a U.S. lawmaker has raised more than $200,000 US in donations.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5820843.1606598686!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/singh-ocasio-cortez-among-us.jpg"></p></div><figcaption>A video game livestream session between federal NDP Leader Jagmeet Singh, left, and U.S. Rep. Alexandria Ocasio-Cortez has raised more than $200,000 US in donations to help reduce food and housing insecurity in the U.S.<!-- --> <!-- -->(@theJagmeetSingh/Twitter, Samuel Corum/Getty Images)</figcaption></figure><p><span><p>A video game livestream session between federal NDP Leader Jagmeet Singh and a U.S. lawmaker&nbsp;has raised more than $200,000 US in donations.</p>  <p>New York City Rep.&nbsp;Alexandria Ocasio-Cortez&nbsp;said on Saturday the funds raised during <a href="http://cbc.ca/1.5818907">her battle with Singh </a>on the popular online multiplayer game <em>Among Us</em>&nbsp;went toward a number of initiatives aimed at reducing food and housing insecurity in the United States.</p>  <p>"Grateful to all who joined us last night! Wonderful learning from you&nbsp;@theJagmeetSingh," the firebrand Democrat said on Twitter.</p>  <p>"Thank you for reminding us that another world is not only possible, but just a few hours' drive from NYC," she added,&nbsp;referring to affordable&nbsp;health care and more generous employment insurance north of the border.</p>  <p>Singh responded: "It was awesome chatting with you about how we can build a better world. In Canada, things aren't perfect and we face many of the same challenges. But, together we can do better."</p>  <p><strong><em>WATCH |&nbsp;Singh, Ocazio-Cortez square off in Among Us:</em></strong></p>  <p><span><span><div><div title="'There's no way I'm going after AOC': Singh, Ocazio-Cortez square off" role="button" tabindex="0"><div><div aria-labelledby="1825153603625-metadata-" title="'There's no way I'm going after AOC': Singh, Ocazio-Cortez square off"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/827/119/MPX_SINGH_GAMES.jpg" alt="" loading="lazy"></p></div></div></div></div></div><span>NDP Leader Jagmeet Singh and U.S. Rep. Alexandria Ocasio-Cortez talked politics while playing Among Us on Twitch.<!-- --> <!-- -->0:47</span></span></span></p>  <p>The New Democrat&nbsp;leader, who challenged Ocasio-Cortez on Thursday, said the aim of the friendly head-to-head was&nbsp;to connect with young people.</p>  <p>He told The Canadian Press that the two politicians&nbsp;share progressive values on health care, economic equality and climate change — views that align with a growing slice of younger voters.</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/politics/among-us-singh-ocasio-cortez-200k-donations-1.5820831</link>
            <guid isPermaLink="false">hacker-news-small-sites-25247242</guid>
            <pubDate>Sun, 29 Nov 2020 19:15:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Simple Password Management with GPG]]>
            </title>
            <description>
<![CDATA[
Score 84 | Comments 68 (<a href="https://news.ycombinator.com/item?id=25247211">thread link</a>) | @todsacerdoti
<br/>
November 29, 2020 | https://tylerlmz1.github.io/tools/2020/05/15/Password-management.html | <a href="https://web.archive.org/web/*/https://tylerlmz1.github.io/tools/2020/05/15/Password-management.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <!--**This is a post about a password management system where you GPG encrypt markdown files on Linux and Syncthing them to Android.**-->

<!--Want to use GPG encrypted files to manage your passwords?-->

<!-- use the word `markdown files` instead of `plain-text files` is because people who care enough to read on are tech savvy people that knows markdown anyway, but then 会make it too 复杂吗, 再看吧, 感觉 say plain-text might 也比较好的 -->

<!--I'm not too fond of using password management tools like `Dashlane` or `1Password`, I've never really tried them, because there's no guarantee that they will live forever, nor that their security perfect.-->

<!--Even though some of them are open-source, they are still at the mercy of their developers unless I'm willing to modify it myself,-->
<!--so it is harder to modify it to fit my needs better.-->

<!--I just want a password management system that is simple, extensible and will live forever, this is my setup:-->
<p>If you want a password management system that is plain-text based, let me introduce to you my setup which utilizes GPG encrypted files to do that.</p>

<p>It uses GPG to encrypt markdown files containing my login credentials, and Syncthing to synchronize them to my Android phone to realize cross-device availability.</p>


<!--To be more exact, I create markdown files and store my login credentials plain-text, then-->

<ul>
  <li>On my computer, I use
    <ul>
      <li><code>gpg</code> to encrypt the markdown files</li>
      <li><a href="https://vimawesome.com/plugin/gnupg-vim">jamessan/vim-gnupg</a> Vim plugin to easily decrypt and edit the files</li>
      <li><code>Git</code> to version control the folder so I have full history of my login credentials</li>
    </ul>
  </li>
  <li>To access them from my phone, I use
    <ul>
      <li><a href="https://syncthing.net/">Syncthing</a> to synchronize the folder to my phone</li>
      <li><a href="https://play.google.com/store/apps/details?id=org.sufficientlysecure.keychain&amp;hl=en">OpenKeychain</a> app to decrypt and read the encrypted files</li>
    </ul>
  </li>
</ul>

<p>I could just Syncthing the markdown files <em>without encryption</em> to my phone, but on the off chance that my phone is stolen / lost / hacked, I don’t want my passwords to go down with it, so it is safer to have it gpg encrypted.</p>

<p><del>I’m aware of <a href="https://www.passwordstore.org/">pass</a> and tried it before I came to this setup, but I want to put more info than just a password string in my files, so that’s why <code>pass</code> doesn’t fit my need.</del>
As many have pointed out in this <a href="https://news.ycombinator.com/item?id=25247211">HackerNews thread</a>, pass allows multi-line edit, so this paragraph is incorrect.</p>

<h3 id="how-to-replicate-this-setup">How to replicate this setup</h3>

<p><strong>1. Generate a PGP keypair with GPG</strong></p>

<p>you can skip this if you already have a keypair.</p>

<p>$ <code>gpg --full-gen-key</code></p>

<p><strong>2. Install the Vim plugin and put in corresponding config</strong></p>

<p>Assuming you’re using VimPlug ( a vim plugin manager ),
put this into your ~/.vimrc and run <code>:PlugInstall</code> in Vim.</p>

<div><div><pre><code>Plug 'jamessan/vim-gnupg'
" Armor files
let g:GPGPreferArmor=1
" Set the default option
let g:GPGDefaultRecipients=["youremail@provider.com"]"
</code></pre></div></div>
<p>NOTE: remember to modify the <code>youremail@provider.com</code> to the email associated with your PGP key</p>

<!--This plugin will auto decrypt encrypted files when you open them with Vim, making the only difference with opening a normal unencrypted file a slight delay of opening the file due to the decryption process.-->
<!--有点啰嗦 this ^ line, comment it out first-->

<p><strong>3. Create a markdown file</strong></p>

<p>$ <code>touch mygmail.md</code></p>

<p><strong>4. Encrypt the markdown file</strong></p>

<!--$ `gpg --recipient youremail@provider.com --armor --output %f.asc --encrypt %f`-->
<p>$ <code>gpg -e -r youremail@provider.com path/to/file</code></p>

<p>if you use <a href="https://github.com/ranger/ranger">Ranger</a>, you can put this mapping into your rc.conf to encrypt it easily by pressing <code>te</code> when the selection is hovering on the file:</p>

<div><div><pre><code>map te shell gpg --recipient youremail@provider.com --armor --output %f.asc --encrypt %f &amp;&amp; rm %f
</code></pre></div></div>

<p>Open the file with Vim to make sure it can auto decrypt and open up the file.</p>


<p><strong>5. Setup Syncthing</strong></p>

<p><a href="https://syncthing.net/downloads/">Install Syncthing</a> on Linux and Android, then set it up to sync your password folder to your phone.</p>

<p><strong>6. Setup OpenKeychain</strong></p>

<ol>
  <li>
    <p>Install <a href="https://play.google.com/store/apps/details?id=org.sufficientlysecure.keychain&amp;hl=en">OpenKeychain</a> Android app on your phone</p>
  </li>
  <li>export your PGP private key from Linux
    <div><div><pre><code>  $ gpg --export-secret-keys --armor youremail@provider.com &gt; privkey.asc
</code></pre></div>    </div>
  </li>
  <li>Transfer the file to your Android phone (for example through wire)</li>
  <li>Import the key file into <code>OpenKeychain</code> app</li>
</ol>

<p><strong>7. Try decrypting your files on Android</strong></p>

<p>To decrypt and view your password file:</p>

<ol>
  <li>Open the <code>OpenKeychain</code> app</li>
  <li>
    <p>Press the hamburger menu icon on the top left</p>
  </li>
  <li>Press <code>Encrypt/Decrypt</code></li>
</ol>

<p><img src="https://tylerlmz1.github.io/assets/decrypt.png" width="200px"></p>

<ol>
  <li>Press <code>Select input file</code> and browse to the encrypted password file</li>
  <li>Enter your PGP key passphrase</li>
</ol>

<p><strong>8. Done</strong></p>

<p><img src="https://tylerlmz1.github.io/assets/view_decrypted_pw_file.png" width="200px"></p>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://tylerlmz1.github.io/tools/2020/05/15/Password-management.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25247211</guid>
            <pubDate>Sun, 29 Nov 2020 19:13:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Only distributed fact-checking can keep up with democratized distribution]]>
            </title>
            <description>
<![CDATA[
Score 120 | Comments 164 (<a href="https://news.ycombinator.com/item?id=25246733">thread link</a>) | @awinter-py
<br/>
November 29, 2020 | https://abe-winter.github.io/only/fans/2020/11/29/everything-in-moderation.html | <a href="https://web.archive.org/web/*/https://abe-winter.github.io/only/fans/2020/11/29/everything-in-moderation.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><img src="https://abe-winter.github.io/assets/swift-ftl.png" alt="tweet: the problem with being faster than light is that you always live in darkness"></p>

<p>Has social media democratized reporting as promised?
We’ve democratized <em>writing and publishing</em> but this year has made the point that there’s more to journalism than hitting send.
The rest of the stuff that happens in the newsroom has stayed in the newsroom:
cultivating sources, editing for quality, and most importantly, fact-checking.</p>

<p>Lacking checks, social media is amplifying or at least fertilizing false beliefs,
and then people cross state lines to shoot up pizza joints.
If the newsroom’s adversarial functions can’t make the jump to social media,
life will continue to be this weird.</p>

<p>We’re starting to address fact-checking, and will do more.
<a href="https://arstechnica.com/tech-policy/2019/11/why-cant-internet-companies-stop-awful-content/">Failing to curb antisocial behavior kills companies</a>, as well as communities.</p>

<p>Facebook has the technology to filter out the worst-quality content that their users think is ‘P(bad for the world)’ – <a href="https://twitter.com/kevinroose/status/1331257332538359810">but only at the cost of lower engagement</a>.
Given these incentives, nobody benefits if we leave this to platforms to solve.
Users should bring their own moderation to the web.</p>

<ul id="markdown-toc">
  <li><a href="#private-groups-will-decamp-if-they-dont-like-the-fact-bubbles" id="markdown-toc-private-groups-will-decamp-if-they-dont-like-the-fact-bubbles">Private groups will decamp if they don’t like the fact bubbles</a></li>
  <li><a href="#conspiracies-are-topics-too" id="markdown-toc-conspiracies-are-topics-too">Conspiracies are topics too</a></li>
  <li><a href="#cranky-boomers-r-us" id="markdown-toc-cranky-boomers-r-us">Cranky boomers R us</a></li>
  <li><a href="#byo-vs-centralized-moderation" id="markdown-toc-byo-vs-centralized-moderation">BYO vs centralized moderation</a></li>
  <li><a href="#information-also-has-professional-customers" id="markdown-toc-information-also-has-professional-customers">Information also has professional customers</a></li>
  <li><a href="#conclusions" id="markdown-toc-conclusions">Conclusions</a></li>
</ul>

<h2 id="private-groups-will-decamp-if-they-dont-like-the-fact-bubbles">Private groups will decamp if they don’t like the fact bubbles</h2>

<p>Filter bubbles don’t have to put up with fact bubbles.
By filter bubbles, I mean clique groups that see mostly content that supports their priors.
By fact bubbles, I mean those blue exclamation marks that say ‘official sources have called the election differently’.</p>

<p>Private groups have the power to resist centralized moderation if they don’t like it.
Private groups are sticky which is why facebook <a href="https://www.theverge.com/2019/4/30/18524188/facebook-f8-keynote-mark-zuckerberg-privacy-future-2019">bet their future on them</a>,
but this stickiness makes them hard to control.
Yes, their internal cohesion leads to engagement on FB, but it also allows them to move off the platform if they’re unhappy.
They own their slice of the network; their moat has a drawbridge.</p>

<p>A heavy hand will drive private groups to dark corners of the web –
not <em>un</em>-moderated exactly, because trust me, nobody wants that.
But ‘differently moderated’.
Reality is a participation sport and groups which don’t want to participate, won’t.</p>

<p>That said, deplatforming isn’t zero-cost for groups:
they recruit in public spaces, and are helped by ‘suggested groups’ features (which FB <a href="https://www.buzzfeednews.com/article/ryanmac/facebook-suspended-group-recommendations-election">partially disabled</a> for the election).
Standalone forums can’t grow like that.
The fickle graces of <a href="https://www.theverge.com/2019/8/5/20754943/8chan-epik-offline-voxility-service-cutoff-hate-speech-ban">hosts</a> and <a href="https://www.theverge.com/2019/8/4/20754310/cloudflare-8chan-fredrick-brennan-ddos-attack">DDOS-protection companies</a> also make it hard to go solo.</p>

<p>But it’s not like IRL networks will stop feeding online groups.
The counterargument to ‘social media gives bad politicians a voice’ is that once someone has been elected, they’ll probably <a href="https://www.youtube.com/watch?v=f7131IkiSCg">have a voice anyway</a>.
FB’s design gives eyeballs to demagogues but <a href="https://en.wikipedia.org/wiki/Triumph_des_Willens">so did Leni Riefenstahl</a>.</p>

<p>As I drafted this in early november, twitter was fact-bubbling multiple tweets in a row from the president,
the ‘uncensored’ social media app parler <a href="https://twitter.com/yashar/status/1325229370126991363">trended to #1</a> in apple’s store,
and local hero <a href="https://twitter.com/WilliamShatner/status/1326223481646665728">Bill Shatner took up the cause of moderation</a> to oppose them.
The ‘moderation drives exodus’ hypothesis is plausible.</p>

<p>But parler can’t really want to be unmoderated.
Their debut came with a quick correction that despite the sales pitch, <a href="https://twitter.com/viaCristiano/status/1277941967402553345">your username can’t be cumdumpster</a>.
(<a href="https://twitter.com/cumdumpster">Twitter has allowed this</a> since at least 2013).</p>

<p>My point: nobody wants to live in a trash can.
Every community has some kind of semi-official management.
I think even 8kun revoked someone’s access to the Q account after they had a falling out (admittedly, not over content I think, and also I don’t really understand this world).
But the <em>forms</em> of moderation we invent have to be trusted or at least tolerated, or people will ditch.</p>

<p>Fact-checking, if it’s trustworthy and useful, will be embraced IMO. But it can’t be imposed.</p>

<h2 id="conspiracies-are-topics-too">Conspiracies are topics too</h2>

<p>A swedish friend, trying to explain why their <a href="https://en.wikipedia.org/wiki/Sweden_Democrats">far-right party</a> gained power in the Riksdag,
said something like ‘It’s not that we’re all nazis, but nobody else would even talk about immigration, and it’s a real problem’.</p>

<p>I like the ‘marketplace of ideas’ as a concept.<sup id="fnref:marketplace" role="doc-noteref"><a href="#fn:marketplace">1</a></sup>
Markets are an interesting model for public discourse.
Like goods on markets, there are a limited number of explanations or ideologies available (assuming most people can’t coin our own – for various reasons, I believe we can’t).
Also, like a real market, it’s two-sided, in that in addition to the ideas on offer, there are buyers:
people looking for an action, belief, or political party that suits them.</p>

<p>The marketplace model explains why political parties get to lie out loud, be revealed for hypocrisy, and admit their strategy is disingenuous.
They’re <em>still</em> the only rallying point for ‘critical idea X’ that their buyers need.
It may not matter to the fighting faithful if the center is hollow.
They’re willing to ignore the cognitive dissonance.</p>

<p>I wonder if there’s a similar effect in the antivax movement –
autism seems to really be on the rise (0.7 to 1.5% in this century),
and if your family is affected by this, and there’s no other explanation, you ‘buy’ the idea that comes with a clear cause and a solution.</p>

<h2 id="cranky-boomers-r-us">Cranky boomers R us</h2>

<p>People are seeking answers that are plausible to them,
but may not be able or willing to dig deeply, and may not be ready to hear the truth if it means abandoning their hope, identity, or <a href="https://phys.org/news/2020-11-beliefs-world-filter.html">existing opinions</a>.
I suspect if someone is at the bottom of a rabbit hole and sees a fact bubble saying ‘this is stupid’, that’s the same as saying ‘you’re stupid’, and they won’t listen.
The challenge here is matching them with a well-meaning authority whom they’ll trust and find useful.</p>

<p>There was a measles outbreak in Minnesota enabled by high vaccine refusal rate in a single immigrant community.
Parents noticed a lot of their kids in special autism education<sup id="fnref:stat-antivax" role="doc-noteref"><a href="#fn:stat-antivax">2</a></sup>, then fell prey to antivax lecturers or something.
But the parents had access to doctors.
And presumably they had access to other experts at the autism schools.
They ignored the fact bubble.
They chose who to trust.</p>

<p>On the flip side, community-owned moderation sometimes works rather well.
I’m thinking about subreddits, who tend to have very specific rules about what to post, and their users accept that these communities are actively moderated for the benefit of the community.
(Given that the community is a result of moderation, this is a little circular and feedback loop-y, but that may not be a bad thing).</p>

<p>I asked a friend who mods a small subbredit what it’s like:
“In six years, no one has ever said anything mean on my subreddit. I’ve never had to ban anyone and submitters and subscribers are respectful.”</p>

<p>Cranky boomers got us into this mess by believing everything they read on facebook.
Maybe Cranky-Boomers-R-Us™️ is the right branding for a community fact check to filter out some fast-spreading egregious claims.</p>

<p>We train people to consider the source, but mainstream mastheads like NYT feel ideologically hostile to readers who aren’t centrists over 55.
Their news coverage can be accurate without being neutral – factual claims in articles are fact-checked, but that’s mixed with interpretive conclusions.
The op-eds are <a href="https://www.cjr.org/the_media_today/james_bennet_tom_cotton_objectivity.php">far stranger</a>.</p>

<p>I don’t blame people for switching to ideologically comfortable news.
I just wish they had a fact-check that was ideologically comfortable, but also competent and reputation-bound, to go along with it.</p>

<p>Repentant neocon Francis Fukuyama writes about social trust now and is <a href="https://www.project-syndicate.org/onpoint/the-emergence-of-a-post-fact-world-by-francis-fukuyama-2017-01">worried about post-fact world</a> where
“all authoritative information sources are challenged by contrary facts of dubious quality and provenance”.
Readers have reasons for straying from reality.
Let’s give people an ideologically comfortable way to come back.</p>

<p><a href="https://en.wikipedia.org/wiki/Harm_reduction">Gentler public health messaging</a> that accepts people’s lifestyles can have higher efficacy;
I suspect the same is true of fact-checks.
Our goal isn’t to change minds; it’s to improve outcomes.</p>

<h2 id="byo-vs-centralized-moderation">BYO vs centralized moderation</h2>

<p>We need a market ecosystem of moderation vendors who provide different kinds of value to different kinds of users.
A moderation marketplace is good for platforms because they don’t want to be the arbiter of truth, they just want users to have a good experience.
(Platforms will still have some policing to do on their own).</p>

<p>It’s good for users because they’re not forced into anything; they can pick which web they want to dwell on.
This may sound like a filter bubble, where ‘everyone has their own truth’,
but moderation vendors will still need to maintain their reputation for being right –
whatever their ideological alignment.
Moderation vendors, unlike cable news channels, don’t produce content;
they just react to it and grade it.
BYO moderation isn’t BYO newspaper, it’s BYO snopes / politifact.</p>

<p>Centralized moderation has problems:</p>

<ul>
  <li>The costs are asymmetric, meaning it’s too expensive to do widely, well, and fast (see lego point below). Jimmy Wales of wikipedia describes the economics here leading to a <a href="https://medium.com/conversations-with-tyler/jimmy-wales-tyler-cowen-wikipedia-610b6e931d20">sweatshop model</a>.</li>
  <li>It’s susceptible to abuse by platforms and institutions and therefore will be less trusted by users, especially the more conspiracy-minded ones whom we want to deradicalize. Note I’m not saying ‘prone to abuse’ or ‘untrustworthy’. Just less trust-<em>ed</em>, and less able to balance minority viewpoints in a way that feels authentic to minorities.</li>
  <li>Private groups will turn off mod systems if not effective / ergonomic / trustable, or else deplatform.</li>
  <li>For messy issues, cookie-cutter moderation can <a href="https://www.eff.org/wp/caught-net-impact-extremist-speech-regulations-human-rights-content">support violence by hiding its proof</a>. Or like <a href="https://twitter.com/KatMurti/status/1276183164109697028">where’s the parler for breastfeeding</a>?</li>
</ul>

<p>Every community needs moderation.
Some get away without it because they moderate membership rather than content –
small workplaces, for example, have relatively informal content moderation processes, but can fire you.</p>

<p>This isn’t just a facebook / twitter issue anymore – it’s a problem for anyone with a supply of eyeballs and UGC or DM features, like <a href="https://www.washingtonpost.com/technology/2020/11/07/pinterest-linkedin-election-disinfo/">pinterest and linkedin</a>.
The older and funnier version of this is the <a href="https://www.managingcommunities.com/2015/06/04/lego-universes-penis-problem-and-why-moderation-efforts-arent-hopeless/">lego MMO’s penis problem</a> –
they …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://abe-winter.github.io/only/fans/2020/11/29/everything-in-moderation.html">https://abe-winter.github.io/only/fans/2020/11/29/everything-in-moderation.html</a></em></p>]]>
            </description>
            <link>https://abe-winter.github.io/only/fans/2020/11/29/everything-in-moderation.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25246733</guid>
            <pubDate>Sun, 29 Nov 2020 18:01:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why we're not building an aggregator]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25246603">thread link</a>) | @nillium
<br/>
November 29, 2020 | https://blog.nillium.com/were-not-an-aggregator/ | <a href="https://web.archive.org/web/*/https://blog.nillium.com/were-not-an-aggregator/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://images.unsplash.com/photo-1510137221422-879a9f7d2ba0?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 300w,
                            https://images.unsplash.com/photo-1510137221422-879a9f7d2ba0?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 600w,
                            https://images.unsplash.com/photo-1510137221422-879a9f7d2ba0?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 1000w,
                            https://images.unsplash.com/photo-1510137221422-879a9f7d2ba0?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://images.unsplash.com/photo-1510137221422-879a9f7d2ba0?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ" alt="We’re not an aggregator.">
            </figure>

            <section>
                <div>
                    <p>How did you end up on this page? &nbsp;If I were a betting man, I would guess that you clicked on a link posted on an &nbsp;aggregator or social media.</p><p>While I appreciate the &nbsp;click (it's always nice to see you) is this the best way to read news?</p><p>Social media and aggregators work in favor of blog posts like this. &nbsp;(And please upvote us.) &nbsp;But for news, they incentivize the wrong things. &nbsp;We know what most people want to share and what gets the most eyeballs and hard news generally is not it. (Outrage porn, anyone?) This is especially true if it is local news and only of interest to a small area.</p><p>Aggregators can give the illusion of informing: you can simply scan the headlines and go on with your day. &nbsp;After all, you just caught up on the news! &nbsp;But this is unsustainable -- smaller organizations that cover local areas are left out of lucrative licensing deals, and without click-throughs to articles, reporters and news organizations have no opportunity to display ads; leading to several generally hated internet phenomena: clickbait, overloading pages with ads, and paywalls to compensate for lost revenue.</p><p>We’re turning the current incentive structure on its head by rewarding original reporting. &nbsp; We publish concise updates from reporters you trust. We make <a href="https://www.nillium.com/newsrooms">tools for newsrooms</a> that syndicate dispatches to a consumer app instantly. (We like to think of ourselves as being to news what OpenTable is to restaurants.) And through rev-shares, our partners succeed when we do.</p><p>We also hope that this surfaces up and coming journalists. &nbsp;Local news reporters are incredibly talented, and know their communities well; even if the communities do not always know them. &nbsp;Rather than require the name recognition as a barrier to entry for a paid newsletter, we want to help them make a name for themselves, while also sharing revenue back to them. &nbsp;</p><p>This is where the news industry should be headed. We need your help -- please <a href="https://www.forthapp.com/list.html">sign up for our waiting list</a> so we can alert you when we’re live in your area, and help us bring on local publishers.</p><p>Let’s Go Forth.</p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.nillium.com/were-not-an-aggregator/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25246603</guid>
            <pubDate>Sun, 29 Nov 2020 17:42:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Grok Normalization]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25246537">thread link</a>) | @panda17
<br/>
November 29, 2020 | https://www.damirsystems.com/grok-normalization/ | <a href="https://web.archive.org/web/*/https://www.damirsystems.com/grok-normalization/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-2059">

<div>
<p>Which normal form (NF) is my table in? How do I normalize? How to decompose to 3NF? BCNF? How to understand the 5th normal form? Mess, confusion, chaos, conflicting advice, endless arguing on StackOverflow. Misleading advice, even in books.</p>
<h2>In Short</h2>
<blockquote>
<p>Normalization is a process for removing and preventing logical errors in a relational database.</p>
</blockquote>
<p>Most of the time this involves implementing proper constraints and reducing — eliminating when possible — redundancy by decomposition into projections.</p>
<h2>Fun Example</h2>
<p>A group of ten J-named people: Jane, Jack, Jill, Joe, James, Janet, Jackie, Jacob, Joan, and Jim, decide to make a SQL DB about themselves. One of tables in the DB is named <em>smoker</em>, stating who smokes.</p>
<h3>Case 1</h3>
<pre>smoker
+-------------+
| NME    (PK) |
+-------------+
| Jack        |
| James, Jill |
| Joan        |
+-------------+
</pre>
<ol>
<li>Comment on the current NF.</li>
<li>Is it possible to fix and how?</li>
<li>Comment on the NF after the fix.</li>
<li>How to prevent the error for any future data changes?</li>
</ol>
<h3>Case 2</h3>
<p>Same scenario, but this time the table is empty.</p>
<pre>smoker {NME}
    PK {NME}
</pre>
<ul>
<li>Consider the same four questions as in the previous case.</li>
</ul>
<h3>Case 3</h3>
<p>Again the table is empty. This time is has a foreign key (FK) to a table named <em>person</em>, which lists all ten people in the group.</p>
<pre>smoker {NME}
    PK {NME}
    FK {NME} REFERENCES person {NME}
</pre>
<ul>
<li>The same four questions.</li>
</ul>
<h2>Notes</h2>
<p><a href="https://en.wiktionary.org/wiki/grok" rel="noopener noreferrer" target="_blank">Grok</a> the example and you will grok normalization. You will also understand what is wrong with the myriad of normalization procedures found all over the web. Many are simply misleading, although may be considered technically correct.</p>
<p>Grokking something is a very personal thing, so it may be best if do not provide answers. Well, <a href="https://www.damirsystems.com/static/txt/grok_normalization_a.txt" rel="noopener noreferrer" target="_blank">try not to look</a>.</p>
<p>Is this all there is to it? No, but understanding this will make you <em>immune</em> to misleading examples. Once you get this, it is easy to read about this-and-that NF examples, problems, and fixes.</p>
<p>If I had to recommend only one book, it would be a tossup between <a href="https://www.damirsystems.com/references/#[Hal08]" rel="noopener noreferrer" target="_blank">Hal08</a> and <a href="https://www.damirsystems.com/references/#[Dat05]" rel="noopener noreferrer" target="_blank">Dat05</a>. Both require study. However, as a <em>developer</em> you do not need to obsess about NFs. Stick to a <a href="https://www.damirsystems.com/forgotten-simplicity/" rel="noopener noreferrer" target="_blank">simple design method</a> and your tables will be in a high NF as a <em>natural consequence</em> of the design. Use predicates and constraints, everything else will fall in place.</p>
<hr>
<pre>All attributes (columns) NOT NULL

PK = Primary Key
FK = Foreign Key
</pre>
</div>

</article></div>]]>
            </description>
            <link>https://www.damirsystems.com/grok-normalization/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25246537</guid>
            <pubDate>Sun, 29 Nov 2020 17:33:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to turn $2M into $2T, by Charlie Munger]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25246241">thread link</a>) | @dvoloschik
<br/>
November 29, 2020 | https://vasilishynkarenka.com/2trillion/ | <a href="https://web.archive.org/web/*/https://vasilishynkarenka.com/2trillion/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://vasilishynkarenka.com/content/images/size/w300/2020/11/1_ALh_-F82X7BHOfPWw0XehA.jpeg 300w,
                            https://vasilishynkarenka.com/content/images/size/w600/2020/11/1_ALh_-F82X7BHOfPWw0XehA.jpeg 600w,
                            https://vasilishynkarenka.com/content/images/size/w1000/2020/11/1_ALh_-F82X7BHOfPWw0XehA.jpeg 1000w,
                            https://vasilishynkarenka.com/content/images/size/w2000/2020/11/1_ALh_-F82X7BHOfPWw0XehA.jpeg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://vasilishynkarenka.com/content/images/size/w2000/2020/11/1_ALh_-F82X7BHOfPWw0XehA.jpeg" alt="How to turn $2 million into $2 trillion, by Charlie Munger">
            </figure>

            <section>
                <div>
                    <p>In four years, I’ve only <a href="https://vasilishynkarenka.com/competition-is-for-losers/">once</a> published someone’s work on my site. </p><p>Today, I break the rule again.</p><p>Charlie Munger gave this talk 24 years ago, and it’s still the best example of business thinking you can read online. </p><p>Enter Charlie.</p><p><em>An Informal Talk, July 20, 1996</em></p><p>The title of my talk is “Practical Thought About Practical Thought?” – with a question mark at the end.</p><p>In a long career, I have assimilated various ultra-simple general notions that I find helpful in solving problems. Five of these helpful notions I will now describe. After that, I will present to you a problem of extreme scale. Indeed, the problem will involve turning start-up capital of $2 million into $2 trillion, a sum large enough to represent a practical achievement. Then I will try to solve the problem, assisted by my helpful general notions. Following that, I will suggest that there are important educational implications in my demonstration. I will so finish because my objective is educational, my game today being a search for better methods of thought.</p><p>The first helpful notion is that it is usually best to simplify problems by deciding big “no-brainer” questions first.</p><p>The second helpful notion mimics Galileo’s conclusion that scientific reality is often revealed only by math as if math was the language of God [1]. Galileo’s attitude also works well in messy, practical life. Without numerical fluency, in the part of life most of us inhabit, you are like a one-legged man in an ass-kicking contest.</p><p>The third helpful notion is that it is not enough to think problems through forward. You must also think in reverse, much like the rustic who wanted to know where he was going to die so that he’d never go there. Indeed, many problems can’t be solved forward. And that is why the great algebraist Carl Jacobi so often said, “Invert, always invert.” And why the Pythagoreans [2] thought in reverse to prove that the square root of two was an irrational number.</p><p>The fourth helpful notion is that the best and most practical wisdom is elementary academic wisdom. But there is one extremely important qualification: You must think in a multidisciplinary manner. You must routinely use all the easy-to-learn concepts from the freshman course in every basic subject. Where elementary ideas will serve, your problem solving must not be limited, as academia and many business bureaucracies are limited, by extreme balkanization into disciplines and subdisciplines, with strong taboos against any venture outside assigned territory. Instead, you must do your multi-disciplinary thinking in accord with Ben Franklin’s prescription in Poor Richard: “If you want it done, go. If not, send.”</p><p>If, in your thinking, you rely entirely on others, often through purchase of professional advice, whenever outside a small territory of your own, you will suffer much calamity. And it is not just difficulties in complex coordination that will do you in. You will also suffer from the reality evoked by the Savian character who said, “In the last analysis, every profession is a conspiracy against the laity.” Indeed, a Shavian character, for once, understated the horrors of something Shaw didn’t like. It is not usually the conscious malfeasance of your narrow professional adviser that does you in. Instead, your troubles come from his subconscious bias. His cognition will often be impaired, for your purposed, by financial incentives different from yours. And he will also suffer from the psychological defect caused by the proverb: “To a man with a hammer, every problem looks like a nail.”</p><p>The fifth helpful notion is that really big effects, lollapalooza effects, will often come only from large combinations of factors. For instance, tuberculosis was tamed, at least for a long time, only by routine, combined use in each case of three different drugs. Another lollapalooza effects, like the flight of an airplane, follow a similar pattern.</p><p>It is now time to present my practical problem. And here is the problem: It is 1884 in Atlanta, Ga. You are brought, along with twenty others like you, before a rich and eccentric Atlanta citizen named Glotz. Both you and Glotz share two characteristics: First, you routinely use in problem solving the five helpful notions, and, second, you know all the elementary ideas in all the basic college courses, as taught in 1996. However, all discoverers, and all examples demonstrating these elementary ideas come from dates before 1884. </p><p>Neither you nor Glotz know anything about anything that has happened after 1884. Glotz offers to invest two million 1884 dollars, yet take only half the equity, for a Glotz Charitable Foundation, in a new corporation organized to go into the non-alcoholic beverage business and remain in that business only, forever. Glotz wants to use a name that has somehow charmed him: Coca-Cola. </p><p>The other half of the new corporation’s equity will go to the man who most plausibly demonstrates that his business plan will cause Glotz’s foundation to be worth a trillion dollars 150 years later, in the money of that later time, 2034, despite paying out a large part of its earnings each year as a dividend. This will make the whole new corporation worth $2 trillion, even after paying out many billions of dollars in dividends.</p><p>You have fifteen minutes to make your pitch. What do you say to Glotz?</p><p>Here is my solution, my pitch to Glotz, using only the helpful notions and what every bright college sophomore should know.</p><p>Well, Glotz, the big “no-brainer” decisions that, to simplify our problem, should be made first are as follows: </p><p>First, we are never going to create something worth $2 trillion by selling some generic beverage. Therefore, we must make your name, “Coca-Cola,” into a strong, legally protected trademark. </p><p>Second, we can get to $2 trillion only by starting in Atlanta, then succeeding in the rest of the United States, then rapidly succeeding with our new beverage all over the world. This will require developing a product having universal appeal because it harnesses powerful elemental forces. And the right place to find such powerful elemental forces is in the subject matter of elementary academic courses.</p><p>We will next use numerical fluency to ascertain what our target implies. We can guess reasonably that by 2034 there will be about eight billion beverage consumers in the world. On average, each of these consumers will be much more prosperous in real terms than the average consumer of 1884. Each consumer is composed mostly of water and must ingest about sixty four ounces of water per day. This is eight, eight-ounce servings. Thus, if our new beverage, and other imitative beverages in our market, can flavor and otherwise improve only twenty-five percent of ingested water worldwide, and we can occupy half of the new world market, we can sell 2.92 trillion eight ounce servings in 2034. And if we can then net four cents per serving, we will earn $117 billion. This will be enough, if our business is still growing at a good rate, to make it easily worth $2 trillion.</p><p>A big question, of course, is whether four cents per serving is a reasonable profit target for 2034. And the answer is yes if we can create a beverage with strong universal appeal. One hundred and fifty years is a long time. The dollar, like the Roman drachma, will almost surely suffer monetary depreciation. Concurrently, real purchasing power of the average beverage consumer in the world will go way up. His proclivity to inexpensively improve his experience while ingesting water will go up considerably faster. Meanwhile, as technology improves, the cost of our simple product, in units of constant purchasing power, will go down. All four factors will work together in favor of our four-cents-per-serving profit target. Worldwide beverage purchasing power in dollars will probably multiply by a factor of at least forty over 150 years. Thinking in reverse, this makes our profits-per-serving large, under 1884 conditions, a mere one fortieth of four cents or one tenth of a cent per serving. This is an easy-to-exceed target as we start out if our new product has universal appeal.</p><p>That decided, we must next solve the problem of invention to create universal appeal. There are two intertwined challenges of large scale: First, over 150 years, we must cause a new beverage market to assimilate about one-fourth of the world’s water ingestion. </p><blockquote>“I want a can of Coke within arm’s reach of every American serviceman – something to remind him of home.” – Dwight D. Eisenhower, Supreme Allied Commander, World War II.</blockquote><p>Second, we must so operate that half the new market is ours while all our competitors combined are left to share the remaining half. These results are lollapalooza results. Accordingly, we must attack our problem by causing every favorable factor we can think of to work for us. Plainly, only a powerful combination of many factors is likely to cause the lollapalooza consequences we desire. Fortunately, the solution to these intertwined problems turns out to be fairly easy if one has stayed awake in all the freshman courses. </p><p>Let us start by exploring the consequences of our simplifying “no-brainer” decision that we must rely on a strong trademark. This conclusion automatically leads to an understanding of the essence of our business in proper elementary academic terms. We can see from the introductory course in psychology that, in essence, we are going into the business of creating and maintaining conditioned reflexes. The “Coca-Cola” trade name and trade dress will act as the stimuli, l and the purchase and ingestion of our beverage will be the desired responses.</p><p>And how does one create and maintain conditioned reflexes? Well, the psychology text gives two answers: (1) by operant conditioning and (2) by classical conditioning, often called Pavlovian [3] conditioning to honor the great Russian scientist. And, …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vasilishynkarenka.com/2trillion/">https://vasilishynkarenka.com/2trillion/</a></em></p>]]>
            </description>
            <link>https://vasilishynkarenka.com/2trillion/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25246241</guid>
            <pubDate>Sun, 29 Nov 2020 16:47:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Invite HN: Come Live at the Launch House]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25245865">thread link</a>) | @anonymous_ch
<br/>
November 29, 2020 | https://launchhouse.co/lh3 | <a href="https://web.archive.org/web/*/https://launchhouse.co/lh3">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>Come 🚀🚀🚀🚀🚀 with the best</h2><p>‍</p><p>Here's a little more on what to expect when you join Launch House.</p><p>‍</p><h4>🏠 Live in an epic house</h4><p>We have a huge mansion in beautiful, sunny Los Angeles – home of palm trees, movie stars, and obnoxiously picture-perfect sunsets. You'll have a plenty of workspace, super fast wifi and everything else you need to do what you do.</p><p>‍</p><h4>🤯 Work with crazy smart people</h4><p>With so many applicants, we have the luxury of selecting the best of the best to join each Launch House cohort. You'll spend your month collaborating with engineers, designers, and product people who have worked at (or even founded) some of the most successful tech companies in the world. Many of these collaborations have lead to residents becoming co-founders of venture-backed startups.</p><p>‍</p><h4>🤩&nbsp;Meet incredible guests</h4><p>One room in the house will be reserved for guest residents. Not randos that need a place to crash, but a curated group of top investors, startup founders, and social media influencers to live and work alongside you during your stay. Past guests included Ryan Hoover, Nathan Latka, Courtland Allen, and Greg Isenberg.</p><p>‍</p><h4>📚 Access amazing resources</h4><p>We've partnered with dozens of top brands in tech like Airtable and Magic Mind to hook you up during your stay and when you become an alumni. We also work with many of the top VCs, angel investors, and operators to help you with everything from go-to-market to fundraising.</p><p>‍</p><h4>📈 Learn and grow</h4><p>You'll have programming each day to help you become a better founder — poolstorms, community dinners, workshops, poolside chats, hackathons, and more. </p><p>‍</p><h4>🎥 Build in public</h4><p>We'll have a videographer and social media influencers floating around the house to film everything from big events to one-off TikTok videos. This isn't a reality show, but we expect everyone to help create a little content of their choosing each week.</p><p>‍</p><h4>🚀 LAUNCH</h4><p>Weekly launch weekends plus ongoing work means someone from the house will be launching almost every day. This is what we came here to do after all.</p><p>‍</p><h4>♥️ Build life-long bonds</h4><p>Launch House residents wind up becoming incredibly close friends (and even co-founders). After your cohort ends, you become an alumni member for life. You'll get access to the community, perks and alumni-organized events (and satellite houses)&nbsp;around the world.</p><p>‍</p><p>‍</p></div></div>]]>
            </description>
            <link>https://launchhouse.co/lh3</link>
            <guid isPermaLink="false">hacker-news-small-sites-25245865</guid>
            <pubDate>Sun, 29 Nov 2020 15:56:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Advanced Programming Challenges]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25245810">thread link</a>) | @rohitpaulk
<br/>
November 29, 2020 | https://codecrafters.io/challenges | <a href="https://web.archive.org/web/*/https://codecrafters.io/challenges">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
        

        <a href="https://codecrafters.io/challenges/redis">
          <!-- Top Border -->
          
          <!-- Card Background -->
          <div>
            <!-- Name, Description, Logo -->
            <div>
              <div>
                <div>
                  <p>
                    Build your own Redis
                  </p>

                  <div>
                    <!-- languages -->
                    <p><img src="https://codecrafters.io/images/python-teal-500.svg" title="Python">
                      
                        
                        <img src="https://codecrafters.io/images/ruby-teal-500.svg" title="Ruby">
                      
                        
                        <img src="https://codecrafters.io/images/gopher-teal-500.svg" title="Go">
                      
                        
                        <img src="https://codecrafters.io/images/haskell-teal-500.svg" title="Haskell">
                      
                        
                        <img src="https://codecrafters.io/images/rust-teal-500.svg" title="Rust">
                      
                        
                        <img src="https://codecrafters.io/images/c-teal-500.svg" title="C">
                      
                        
                        <img src="https://codecrafters.io/images/elixir-teal-500.svg" title="Elixir">
                      
                    </p>
                  </div>
                </div>
                <p>
                  Learn about TCP servers, events loops, the Redis protocol and more

                </p>
              </div>
              <div>
                <div>
                  <p><img src="https://codecrafters.io/images/challenge-logo-redis.png">
                  </p>
                </div>
              </div>
            </div>
            <!-- Meta + Label -->
            <div>
              
              <!-- avatars -->
              <div>
                
                <div>
                  <p><img src="https://codecrafters.io/images/sample-avatar-1.png">
                  </p>
                </div>
                
                <div>
                  <p><img src="https://codecrafters.io/images/sample-avatar-2.png">
                  </p>
                </div>
                
                <div>
                  <p><img src="https://codecrafters.io/images/sample-avatar-3.png">
                  </p>
                </div>
                
              </div>

              <!-- online indicator -->
              

              <p>
                149 players
              </p>
              

              <!-- Label -->
              <div>
                  
                      <p>
                          Early Access
                      </p>
                  
                  
              </div>
            </div>
          </div>
        </a>
      
        

        <a href="https://codecrafters.io/challenges/docker">
          <!-- Top Border -->
          
          <!-- Card Background -->
          <div>
            <!-- Name, Description, Logo -->
            <div>
              <div>
                <div>
                  <p>
                    Build your own Docker
                  </p>

                  <div>
                    <!-- languages -->
                    <p><img src="https://codecrafters.io/images/gopher-teal-500.svg" title="Go">
                      
                        
                        <img src="https://codecrafters.io/images/nim-teal-500.svg" title="Nim">
                      
                        
                        <img src="https://codecrafters.io/images/c-teal-500.svg" title="C">
                      
                    </p>
                  </div>
                </div>
                <p>
                  Learn about chroot, kernel namespaces, the docker registry API and more

                </p>
              </div>
              <div>
                <div>
                  <p><img src="https://codecrafters.io/images/challenge-logo-docker.png">
                  </p>
                </div>
              </div>
            </div>
            <!-- Meta + Label -->
            <div>
              
              <!-- avatars -->
              <div>
                
                <div>
                  <p><img src="https://codecrafters.io/images/sample-avatar-1.png">
                  </p>
                </div>
                
                <div>
                  <p><img src="https://codecrafters.io/images/sample-avatar-2.png">
                  </p>
                </div>
                
                <div>
                  <p><img src="https://codecrafters.io/images/sample-avatar-3.png">
                  </p>
                </div>
                
              </div>

              <!-- online indicator -->
              

              <p>
                68 players
              </p>
              

              <!-- Label -->
              <div>
                  
                      <p>
                          Early Access
                      </p>
                  
                  
              </div>
            </div>
          </div>
        </a>
      
        

        <a href="https://codecrafters.io/challenges/git">
          <!-- Top Border -->
          
          <!-- Card Background -->
          <div>
            <!-- Name, Description, Logo -->
            <div>
              <div>
                <div>
                  <p>
                    Build your own Git
                  </p>

                  <div>
                    <!-- languages -->
                    <p><img src="https://codecrafters.io/images/python-teal-500.svg" title="Python">
                      
                        
                        <img src="https://codecrafters.io/images/ruby-teal-500.svg" title="Ruby">
                      
                        
                        <img src="https://codecrafters.io/images/gopher-teal-500.svg" title="Go">
                      
                        
                        <img src="https://codecrafters.io/images/rust-teal-500.svg" title="Rust">
                      
                        
                        <img src="https://codecrafters.io/images/kotlin-teal-500.svg" title="Kotlin">
                      
                    </p>
                  </div>
                </div>
                <p>
                  Learn about git objects, plumbing commands, git transfer protocols and more

                </p>
              </div>
              <div>
                <div>
                  <p><img src="https://codecrafters.io/images/challenge-logo-git.png">
                  </p>
                </div>
              </div>
            </div>
            <!-- Meta + Label -->
            <div>
              
              <!-- avatars -->
              <div>
                
                <div>
                  <p><img src="https://codecrafters.io/images/sample-avatar-1.png">
                  </p>
                </div>
                
                <div>
                  <p><img src="https://codecrafters.io/images/sample-avatar-2.png">
                  </p>
                </div>
                
                <div>
                  <p><img src="https://codecrafters.io/images/sample-avatar-3.png">
                  </p>
                </div>
                
              </div>

              <!-- online indicator -->
              

              <p>
                51 players
              </p>
              

              <!-- Label -->
              <div>
                  
                      <p>
                          Early Access
                      </p>
                  
                  
              </div>
            </div>
          </div>
        </a>
      
        

        <a href="https://codecrafters.io/challenges/react">
          <!-- Top Border -->
          
          <!-- Card Background -->
          <div>
            <!-- Name, Description, Logo -->
            <div>
              <div>
                <div>
                  <p>
                    Build your own React
                  </p>

                  <div>
                    <!-- languages -->
                    
                  </div>
                </div>
                <p>
                  Learn about React's createElement API, function components, DOM-diffing algorithm, hooks and more

                </p>
              </div>
              <div>
                <div>
                  <p><img src="https://codecrafters.io/images/challenge-logo-react.png">
                  </p>
                </div>
              </div>
            </div>
            <!-- Meta + Label -->
            <div>
              

              <!-- Label -->
              <div>
                  
                  
                      <p>
                          Coming Soon
                      </p>
                  
              </div>
            </div>
          </div>
        </a>
      
    </div></div>]]>
            </description>
            <link>https://codecrafters.io/challenges</link>
            <guid isPermaLink="false">hacker-news-small-sites-25245810</guid>
            <pubDate>Sun, 29 Nov 2020 15:50:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[2Q: The Postgres Caching Algorithm]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25245675">thread link</a>) | @arpitbbhayani
<br/>
November 29, 2020 | https://arpitbhayani.me/blogs/2q-cache?ref=hn | <a href="https://web.archive.org/web/*/https://arpitbhayani.me/blogs/2q-cache?ref=hn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>LRU is one of the most widely used cache eviction algorithms that span its utility across multiple database systems. Although popular, it suffers from a bunch of limitations especially when it is used for managing caches in disk-backed databases like MySQL and Postgres.</p>
<p>In this essay, we take a detailed look into the sub-optimality of LRU and how one of its variants called 2Q addresses and improves upon it. 2Q algorithm was first introduced in the paper - <a href="https://www.semanticscholar.org/paper/2Q%3A-A-Low-Overhead-High-Performance-Buffer-Johnson-Shasha/5fa357b43c8351a5d8e7124429e538ad7d687abc">2Q: A low overhead high-performance buffer management replacement algorithm</a> by Theodore Johnson and Dennis Shasha.</p>

<p>The <a href="https://en.wikipedia.org/wiki/Cache_replacement_policies#Least_recently_used_(LRU)">LRU eviction algorithm</a> evicts the page from the buffer which has not been accessed for the longest. LRU is typically implemented using a <a href="https://en.wikipedia.org/wiki/Doubly_linked_list">Doubly Linked List</a> and a <a href="https://en.wikipedia.org/wiki/Hash_table">Hash Table</a>. The intuition of this algorithm is so strong and implementation is so simple that until the early '80s, LRU was the algorithm of choice in nearly all the systems. But as stated above, there are certain situations where LRU performs sub-optimal.</p>
<p><img src="https://user-images.githubusercontent.com/4745789/100534745-43ae8400-3238-11eb-8855-752a6ef2f3c6.png" alt="https://user-images.githubusercontent.com/4745789/100534745-43ae8400-3238-11eb-8855-752a6ef2f3c6.png"></p>
<h2>Sub-optimality during DB scans</h2>
<p>If the database table is bigger than the LRU cache, the DB process, upon scanning the table will wipe out the entire LRU cache and fill it with the pages from just one scanned table. If these pages are not referenced again, this is a total loss and the performance of the database takes a massive hit. The performance will pickup once these pages are evicted from the cache and other pages make an entry.</p>
<h2>Sub-optimality in evictions</h2>
<p>LRU algorithm works with a single dimension - recency - as it removes the pages from the buffer on the basis of recent accesses. Since it does not really consider any other factor, it can actually evict a warmer page and replace it with a colder one - a page that could and would be accessed just once.</p>

<p>2Q addresses the above-illustrated issues by introducing parallel buffers and supporting queues. Instead of considering just recency as a factor, 2Q also considers access frequency while making the decision to ensure the page that is really warm gets a place in the LRU cache. It admits only hot pages to the main buffer and tests every page for a second reference.</p>
<p>The golden rule that 2Q is based on is - <em>Just because a page is accessed once does not entitle it to stay in the buffer. Instead, it should be decided if it is accessed again then only keep it in the buffer.</em></p>
<p>Below we take a detailed look into two versions of the 2Q algorithm - simplified and improved.</p>
<h2>Simplified 2Q</h2>
<p>Simplified 2Q algorithm works with two buffers: the primary LRU buffer - <code>Am</code>  and a secondary FIFO buffer - <code>A1</code>. New faulted pages first go to the secondary buffer <code>A1</code> and then when the page is referenced again, it moves to the primary LRU buffer <code>Am</code>. This ensures that the page that moves to the primary LRU buffer is hot and indeed requires to be cached.</p>
<p><img src="https://user-images.githubusercontent.com/4745789/100536835-41a0f100-3249-11eb-920b-0bcaff905906.png" alt="https://user-images.githubusercontent.com/4745789/100536835-41a0f100-3249-11eb-920b-0bcaff905906.png"></p>
<p>If the page residing in <code>A1</code> is never referenced again, it eventually gets discarded, implying the page was indeed cold and did not deserve to be cached. Thus this simplified 2Q provides protection against the two listed sub-optimality of the simple LRU scheme by adding a secondary buffer and testing pages for a second reference. The pseudocode for the Simplified 2Q algorithm is as follows:</p>
<pre><code><span><span>def</span> <span>access_page</span><span>(X: page)</span>:</span>
    
    
    <span>if</span> X <span>in</span> Am:
         Am.move_front(X)

    
    
    
    
    <span>elif</span> X <span>in</span> A1:
         A1.remove(X)
         Am.add_front(X)

    
    <span>else</span>:
         
         <span>if</span> A1.is_full():
             A1.pop()

         
         A1.add_front(X)
</code></pre>
<p>Tuning Simplified 2Q buffer is difficult - if the maximum size of <code>A1</code> is too small, the test for hotness becomes too strong and if it is too large then due to memory constraint <code>Am</code> will get relatively smaller memory making the primary LRU cache smaller, eventually degrading the database performance.</p>
<p>The full version 2Q algorithm remediates this limitation and eliminates tuning to a massive extent without taking any hit in performance.</p>
<h2>2Q Full Version</h2>
<p>Although Simplified 2Q algorithm does a decent job there is still scope of improvement when it comes to handling common database access pattern, that suggests, a page generally receives a lot of references for a short period of time and then no reference for a long time. If a page truly needs to be cached then after it receives a lot (not just one) of references in a short span it continues to receive references and hits on regular intervals.</p>
<p>To handle this common database access pattern, the 2Q algorithm splits the secondary buffer <code>A1</code> into two buffers <code>A1-In</code> and <code>A1-Out</code>, where the new element always enters <code>A1-In</code> and continues to stay in <code>A1-In</code> till it gets accesses ensuring that the most recent first accesses happen in the memory.</p>
<p>Once the page gets old, it gets thrown off the memory but its disk reference is stored in the <code>A1-Out</code> buffer. If the page, whose reference is, residing in <code>A1-Out</code> is accessed again the page is promoted to <code>Am</code> LRU implying it indeed is a hot page that will be accessed again and hence required to be cached.</p>
<p><img src="https://user-images.githubusercontent.com/4745789/100538168-0bb53a00-3254-11eb-8f69-ddcaf8d33a84.png" alt="https://user-images.githubusercontent.com/4745789/100538168-0bb53a00-3254-11eb-8f69-ddcaf8d33a84.png"></p>
<p>The <code>Am</code> buffer continues to be the usual LRU which means when any page residing in <code>Am</code> is accessed it is moved to the head and when a page is needed to be discarded the eviction happens from the tail end.</p>

<p>Postgres uses 2Q as its cache management algorithm due to <a href="http://www.varlena.com/GeneralBits/96.php">patent issues</a> with IBM. Postgres used to have <a href="https://en.wikipedia.org/wiki/Adaptive_replacement_cache">ARC</a> as its caching algorithm but with IBM getting a patent over it, Postgres moved to 2Q. Postgres also claims that the performance of 2Q is similar to ARC.</p>

<ul>
<li><a href="https://en.wikipedia.org/wiki/Cache_replacement_policies#Least_recently_used_(LRU)">LRU - Wikipedia</a></li>
<li><a href="http://www.varlena.com/GeneralBits/96.php">The Saga of the ARC Algorithm and Patent</a></li>
<li><a href="https://www.semanticscholar.org/paper/2Q%3A-A-Low-Overhead-High-Performance-Buffer-Johnson-Shasha/5fa357b43c8351a5d8e7124429e538ad7d687abc">2Q: A low overhead high-performance buffer management replacement algorithm</a></li>
</ul>
</div></div><div><p>
          If my work adds value, consider supporting me
        </p>  <p><a href="https://www.buymeacoffee.com/arpitbhayani" target="_blank"><img src="https://cdn.buymeacoffee.com/buttons/v2/default-yellow.png" alt="Buy Me A Coffee"></a></p> <br></div><section><div><div><p><img src="https://arpitbhayani.me/static/img/arpit.jpg"></p>  <h2>
              700+ Signups
            </h2> <p>
              If you like what you read subscribe you can always subscribe to
              my newsletter and get the post delivered straight to your inbox.
              I write
              <a href="https://arpitbhayani.me/blogs">essays</a> on various
              engineering topics and share it through my weekly
              <a href="https://arpitbhayani.me/newsletter">newsletter</a> 👇
            </p> <br> </div></div></section></div>]]>
            </description>
            <link>https://arpitbhayani.me/blogs/2q-cache?ref=hn</link>
            <guid isPermaLink="false">hacker-news-small-sites-25245675</guid>
            <pubDate>Sun, 29 Nov 2020 15:34:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Study links mindfulness and meditation to narcissism and “spiritual superiority”]]>
            </title>
            <description>
<![CDATA[
Score 58 | Comments 54 (<a href="https://news.ycombinator.com/item?id=25245512">thread link</a>) | @Bologo
<br/>
November 29, 2020 | https://www.psychnewsdaily.com/study-links-mindfulness-meditation-to-narcissism-and-spiritual-superiority/ | <a href="https://web.archive.org/web/*/https://www.psychnewsdaily.com/study-links-mindfulness-meditation-to-narcissism-and-spiritual-superiority/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-5234" role="main"><div><div><div><p><strong>A <a rel="noreferrer noopener" href="https://onlinelibrary.wiley.com/doi/abs/10.1002/ejsp.2721" target="_blank">new study</a> has found that some popular forms of spiritual training — such as energy healing, aura reading, and, to a lesser degree, mindfulness and meditation — correlate with both narcissism and “spiritual superiority.”</strong></p><p>An implicit feature of spiritual training is that it allows its adherents to distance themselves from their egos, and thereby from things such as the need for social approval or success. By encouraging self-compassion and non-judgmental self-acceptance, spiritual training should presumably make people less concerned with such things.</p><p>But as a new paper explains, spiritual training may have the opposite effect. Namely, spiritual training might in fact enhance people’s need to feel “more successful, more respected or more loved,” as the authors Roos Vonk and Anouk Visser write.</p><h2>The first study to measure spiritual superiority</h2><p>No previous studies had specifically examined topic, which prompted Roos Vonk and Anouk Visser to investigate. Their <a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/ejsp.2721" target="_blank" rel="noreferrer noopener">new paper</a>, “An Exploration of Spiritual Superiority: The Paradox of Self‐Enhancement,” appears in the <em><a href="https://onlinelibrary.wiley.com/journal/10990992" target="_blank" rel="noreferrer noopener">European Journal of Social Psychology</a></em>.</p><p>The authors developed a new measure they call “spiritual superiority.” It measures whether people feel superior to those “who lack the spiritual wisdom they ascribe to themselves.”<span data-ez-name="psychnewsdaily_com-medrectangle-4"></span></p><p>The measure’s questionnaires ask people to respond on a scale of 1 to 7 to a series of statements. Example statements include “I am more in touch with my senses than most others,” “I am more aware of what is between heaven and earth than most people,” and “The world would be a better place if others too had the insights that I have now.”</p><h2>Spiritual guidance, supernatural overconfidence, and self-worth</h2><p>The authors also created three scales that they hypothesized would correlate with spiritual superiority.</p><p>The first scale, “spiritual guidance,” relates to how much people try to help others acquire the same wisdom they have acquired. It includes statements such as “I help others whenever possible on their path to greater wisdom and insight,” “I gladly help others to acquire my insights too,” and “I am patient with others, because I understand it takes time to gain the insights that I gained in my life and my education.”</p><p>The second scale is “supernatural overconfidence,” and it encompasses self-ascribed abilities in the paranormal domain. Example statements include “I can send positive energy to others from a distance,” “I can get in touch with people who are deceased,” and “I can influence the world around me with my thoughts.”</p><p>The third scale, “spiritual contingency of self-worth,” measures how much a person’s self-esteem is derived from their spirituality. Sample statements include “My faith in myself increases when I acquire more spiritual wisdom” and “When I gain new spiritual insights, this increases my self-worth.”</p><p>In the three studies described below, the researchers found that their scale of spiritual superiority is a valid instrument. Moreover, it correlates significantly with the other three scales. It also correlates significantly with narcissism, self‐esteem, and other psychological variables. Finally, it also correlates, to varying degrees, with diverse forms of spiritual training.</p><h2><strong>Assessing spiritual superiority</strong></h2><p>For the first of the three studies included in the current paper, Vonk and Visser recruited 533 participants. They found them by contacting schools and spiritual centers that offer courses in subjects such as mindfulness and <a href="https://en.wikipedia.org/wiki/Energy_medicine" target="_blank" rel="noreferrer noopener">energetic training</a>.</p><p>The participants in this first study were about 75% female, with an average age of 51. They indicated that they were currently following some form of spiritual training. The types mentioned included <a href="https://www.psychnewsdaily.com/category/mental-health/mindfulness/" target="_blank" rel="noreferrer noopener">mindfulness</a>, meditation, energetic therapy, reading/healing aura, haptotherapy, reiki, and others.</p><p>The respondents filled in the questionnaires described above, and also answered questions about their age, sex, education, religion, and spiritual training.</p><p>The researchers found that “spiritual superiority” correlated significantly with self-esteem, mindfulness, supernatural overconfidence, and spiritual guidance.</p><p>As the authors predicted, these correlations were strongest for participants following forms of “energetic” training. These participants rated higher than the <a href="https://amzn.to/36jmlSH" target="_blank" rel="noreferrer noopener sponsored nofollow">mindfulness/meditation</a> students on all of the superiority-related scales, especially on the scale of supernatural overconfidence.</p><p>This makes sense, the authors write, as energetic training is meant to develop supernatural skills. This likely attracts students who already believe they have talents in this area.</p><p>Likewise, the training itself might further enhance their confidence. This is because no objective performance standards can conclusively demonstrate they are not in fact paranormally gifted.</p><h2><strong>What about people who don’t follow spiritual training</strong>?</h2><p>The second study broadened the pool of respondents to include people who are not currently undergoing spiritual training. The goal was to compare their results on the spiritual superiority scale to those of the spiritual training students.</p><p>For this study, the researchers recruited 2,223 participants via a Dutch popular psychology magazine. Of these, 1960 were women. Their ages ranged from 15 to 82, with an average age of 41.</p><p>About a third had never followed any spiritual training; another third had followed mindfulness or meditation training. About 10% had followed some form of energetic training (including aura healing/reading). Another 10% had followed other kinds of spiritual training.</p><p>The result of this second study also showed that “spiritual superiority” significantly correlates with all the other measures. Furthermore, it also found the same pattern in Study 1. Namely there was a gradual increase in spiritual superiority as one moved from the “no spiritual training” group to the “mindfulness training” group to the “energetic training” group. And again, the results for the “energetic” group were much higher than for both the “mindfulness” and the “no-training” groups.</p><h2>Correlations with <strong>narcissism</strong></h2><p>Study 3 tested the hypothesis that spiritual superiority is related to narcissism. As the researchers explain, past research has used the term “spiritual narcissism,” but none those studies empirically measured it.</p><p>For this study, the authors did not measure “agentic narcissism” (for example, “I am more special than others and deserve special privileges”), but rather “<a href="https://www.psychologytoday.com/us/blog/tech-support/201605/the-communal-narcissist-another-wolf-wearing-sheep-outfit">communal narcissism</a>,” which describes people who think of themselves as more nurturing and empathic than others. Example statements that characterize this trait include “I have a very positive influence on others” and “I am generally the most understanding person.”</p><p>This study recruited 965 participants via various channels. These included a Facebook page about psychology, spiritual schools, and participants who were not able to participate in the previous two studies due to a lack of space. The final sample included about 88% women, aged 19-79, with an average age of 46.</p><p>The participants answered the questionnaires for spiritual superiority and spiritual guidance, as well as several existing scales related to humility and overconfidence, a short 7-item version of the <a href="https://pubmed.ncbi.nlm.nih.gov/22889074/" target="_blank" rel="noreferrer noopener">Communal Narcissism scale</a>, and a three-item self-esteem scale.</p><p>The researchers found that the correlation between spiritual superiority and narcissism was 0.47. This is significantly stronger than the correlation with self-esteem. And once again, the same pattern emerged in terms of the type of spiritual training that the participants followed. The weakest correlations were among subjects with no spiritual training, and the highest for those who practiced energetic training. The mindfulness/meditation group was in between, though it was considerably closer to the “no-training” group than to the “energetic” group.</p><h2><strong>Why t</strong>he link between <strong>spiritual superiority and narcissism</strong>?</h2><p>The authors argue that the lack of objectivity in the spiritual domain plays a role here. “Like religiosity, spirituality is a domain that seems like a safe and secure investment for self-worth,” they write. “One’s spiritual attainments allow lots of room for wishful thinking, thus easily lending themselves to the grip of the self-enhancement motive.”</p><p>And because spiritual matters are generally “elusive to external objective standards,” that makes them a “suitable domain for illusory beliefs about one’s superiority.”</p><p>The results of these three studies do not imply any casual direction; the authors suggest the causal arrow may work in both directions. On one hand, people may use spirituality as a self-esteem booster: it allows them to see themselves as special, and they can achieve progress in the spiritual domain relatively easily, as there are no objectively measurable outcomes (in contrast to, for example, sports, academic success, or wealth accumulation).</p><p>On the other hand, spiritual training may attract people who already feel superior. And the “extensive exploration of one’s personal thoughts and feelings” that spiritual training encourages “may be particularly appealing” to <a href="https://amzn.to/3lhtAhZ" target="_blank" rel="noreferrer noopener sponsored nofollow">narcissists</a>, the authors write.</p><h2>Towards genuine spiritual growth</h2><p>The people who agreed to take part in this research might not represent spirituality students in general. “The question is whether a truly enlightened person would even participate in our studies,” the authors write. “Would such a person be interested in or even capable of answering all these ‘me’ questions?”</p><p>GIn any case, the researchers hope that future research can “reveal more insights into the effects of spiritual training, and possibly the conditions and personality characteristics that facilitate genuine spiritual growth.”</p><hr><p><strong>Study:</strong> “<a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/ejsp.2721">An Exploration of Spiritual Superiority: The Paradox of Self‐Enhancement</a>“<br><strong>Authors: </strong>Roos Vonk and Anouk Visser<br><strong>Published in:</strong> <em><a href="https://onlinelibrary.wiley.com/journal/10990992" target="_blank" rel="noreferrer noopener">European Journal of Social Psychology</a></em><br><strong>Publication date:</strong> October 1, 2020<br><strong>DOI:</strong> <a href="https://doi.org/10.1002/ejsp.2721">https://doi.org/10.1002/ejsp.2721</a><br><strong>Photo: </strong>by <a href="https://pixabay.com/users/kalyanayahaluwo-1767926/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=5353620">Bhikku Amitha</a>&nbsp;via&nbsp;<a href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=5353620">Pixabay</a>&nbsp;</p><p>For a weekly summary of the latest psychology news, subscribe to our <a href="https://www.psychnewsdaily.com/the-psych-news-weekly-newsletter/" target="_blank" rel="noreferrer noopener">Psych News Weekly …</a></p></div></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.psychnewsdaily.com/study-links-mindfulness-meditation-to-narcissism-and-spiritual-superiority/">https://www.psychnewsdaily.com/study-links-mindfulness-meditation-to-narcissism-and-spiritual-superiority/</a></em></p>]]>
            </description>
            <link>https://www.psychnewsdaily.com/study-links-mindfulness-meditation-to-narcissism-and-spiritual-superiority/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25245512</guid>
            <pubDate>Sun, 29 Nov 2020 15:09:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA['Leave shaming' employees needs to stop]]>
            </title>
            <description>
<![CDATA[
Score 29 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25245244">thread link</a>) | @rustoo
<br/>
November 29, 2020 | https://m.dailyhunt.in/news/india/english/money+control+english-epaper-mconten/leave+shaming+employees+needs+to+stop+in+india-newsid-n232431602 | <a href="https://web.archive.org/web/*/https://m.dailyhunt.in/news/india/english/money+control+english-epaper-mconten/leave+shaming+employees+needs+to+stop+in+india-newsid-n232431602">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			 <p>Mumbai-based IT sector employee Shravan Manikandan had been working close to 14 hours a day since the Coronavirus (COVID-19) lockdown. Clubbing the Diwali holiday, he decided to take a week-leave in November, his first in 2020. But throughout the next two weeks, his team members and his reporting manager taunted for his leave.</p> <p>Manikandan felt humiliated because his colleagues made him feel guilty for taking leave that he was entitled to. They questioned him on why he needed to take this leave when nobody else took leave this year in his 7-member team.</p> <p>"It wasn't as if I took off without informing my team.                <!-- <div class="PT10 TAC PB10"><div id="crt_728x90a"></div></div> -->
                 It was a well-deserved vacation and I simply needed time off. Why should I be shamed for it," he says.</p> <p>Amidst the Coronavirus (COVID-19) outbreak where long working hours at home is the new-normal, the culture of 'leave shaming' among corporates has cropped out. This involves the practice of singling out colleagues who take leave/vacations and shaming them, making them feel guilty for taking time off.</p> <p>Corporates may go great lengths to talk about how 'work-life balance' is the key mantra at their workplace. Look beyond that and you will find an inherent culture of overworking and leave shaming.</p> <p>Remote working means that work hours are inevitably extended on a daily basis. Rather than a 9-6 day, the working hours begin as early as 7am and end as late as 11pm. Mental health helplines are also seeing a rise in stress-related calls from working professionals primarily due to working without breaks.</p> <p>Amidst this, the basic perk of taking a vacation at least once or twice a year is being seen as a luxury. Worst still, organisations are even reprimanding younger colleagues seeking 'personal time off' once in three or four months.</p> <p>Bengaluru's Lakshmi Ray who works in the IT operations team of a global bank was discouraged from taking leaves even when she explicitly stated that she was facing anxiety issues.</p> <p>"I am already taking professional help for my anxiety. All I asked was for a day leave after four months. But I was discouraged saying that the senior management team hasn't taken even one day leave. Why should I take inspiration from this?" she added.</p> <p>Ray is also of the view that romanticising the concept of working without breaks is also a reason why corporates portray it as an achievement.</p> <p>Tesla's Elon Musk, for instance, publicly stated that he doesn't believe in taking time off or taking vacations and also gave instances of key projects failing when he went on a one-off leave.</p> <p>But remember that Musk is a billionaire and will be able to afford crores in treatment or medication for stress and anxiety. You and I may be sacked for long leaves of absence due to overworking-related stress and don't have the luxury to sit at home.</p> <p>Human resource officials are also of the view that such practices by the top management in a company sets unreasonable expectations from the staff.</p> <p>"If the CEO of a company says hey, I have never taken a day off in my life or I don't believe in vacations, what is the message that goes across to his/her team? It is unhealthy to work 365 days without a break," says Pune-based HR consultant Pradipta Satam.</p> <p>Satam also suggests that irrespective of what colleagues think, professionals must set aside time for themselves and family. She says that when it is part of the HR policy, every employee has the right to take their sanctioned leaves irrespective of the pandemic.</p> <p>The Japanese work culture is also cited commonly at Indian workplaces to show how long working hours without breaks will pay off. However, these corporations fail to mention that <a href="https://www.theguardian.com/world/2017/oct/05/japanese-woman-dies-overwork-159-hours-overtime" rel="nofollow">death due to overworking</a> (called Karoshi in Japanese) isn't uncommon in that country.</p> <!--NH-END--><p><span color="#B5B5B5" face="sans-serif" size="0.6">Dailyhunt</span></p><!--NH-END--><!--DH-Disclaimer--><div><p><span><i>Disclaimer</i>: This story is auto-aggregated by a computer program and has not been created or edited by Dailyhunt. Publisher: Money Control English</span></p></div><!--DH-Disclaimer-->		</div></div>]]>
            </description>
            <link>https://m.dailyhunt.in/news/india/english/money+control+english-epaper-mconten/leave+shaming+employees+needs+to+stop+in+india-newsid-n232431602</link>
            <guid isPermaLink="false">hacker-news-small-sites-25245244</guid>
            <pubDate>Sun, 29 Nov 2020 14:22:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Little Things That Made Amiga Great]]>
            </title>
            <description>
<![CDATA[
Score 213 | Comments 172 (<a href="https://news.ycombinator.com/item?id=25245206">thread link</a>) | @eitland
<br/>
November 29, 2020 | https://datagubbe.se/ltmag/ | <a href="https://web.archive.org/web/*/https://datagubbe.se/ltmag/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>



<p><b>A deep dive into a selection of ingenious AmigaOS features.</b></p>

<p><i>Autumn 2020</i></p>

<h2 id="toc">Table of Contents</h2>

<ul>
  <li><a href="#intro">Introduction</a></li>
  <li><a href="#jargon">Jargon buster</a></li>
  <li>
    <a href="#littlethings">The Little Things</a>
    <ul>
      <li><a href="#ramdisk">The RAM Disk</a></li>
      <li><a href="#raddisk">The RAD Disk</a></li>
      <li><a href="#propscroll">Proportional scroll bars</a></li>
      <li><a href="#editors">The Text Editors</a></li>
      <li><a href="#arexx">ARexx</a></li>
      <li><a href="#nocd">No CD</a></li>
      <li><a href="#filesys">File Systems</a></li>
      <li><a href="#assigns">Assigns</a></li>
      <li><a href="#libs">Libraries</a></li>
      <li><a href="#asl">ASL</a></li>
      <li><a href="#datatypes">Datatypes</a></li>
      <li><a href="#readargs">ReadArgs</a></li>
      <li><a href="#guide">AmigaGuide</a></li>
      <li><a href="#installer">Installer</a></li>
      <li><a href="#filestruct">Standardized File Structure</a></li>
      <li><a href="#resident">Resident Programs</a></li>
      <li><a href="#reqchoice">RequestChoice</a></li>
      <li><a href="#infofiles">.info Files</a></li>
    </ul>
  </li>
  <li><a href="#closing">Closing words</a></li>
</ul>

<h3 id="intro">Introduction</h3>

<p>
To most people, the Amiga is probably synonymous with the Amiga 500 and that 
machine was, above all, a video game: something into which you plonked 
3.5" floppy disks that transported you to strange, wonderful worlds and 
hours of fun. To this group, the gamers, the operating system wasn't 
important. They probably booted Workbench 1.3 
only once, took a good look at the garish blue and orange interface,
and decided that enough was enough, before going back to blasting enemies 
in Silkworm.
</p>

<p>
And why not? The machine was great for games. There are tons of great 
texts about the groundbreaking audio and video capabilities of the 
Amiga.
</p>

<p>
This text is not one of those.
</p>

<p>
This text is about the later versions of AmigaOS produced by Commodore, 
from 2.0 to 3.1. While these newer versions (with majors released in 1990 
and 1992, respectively) certainly carried the Amiga heritage with pride 
and were - mostly - backwards compatible, the advent of AmigaOS 2.0 
marked a paradigm shift. The shift is best symbolized by the fact that 
AmigaBASIC - the ubiquitous and mandatory language of any 
self-respecting eighties home computer - was ditched and replaced by 
ARexx, a professional scripting language without any kind of graphics or 
sound features whatsoever.
</p>

<p>
This paradigm shift is also why so many of us who had the good fortune 
to come across those versions clung to the Amiga so desperately. A lot
of us stuck with it
well into the late nineties, years after Commodore's demise. And we were
fierce: if 
you think Apple fanboys are annoying today, be very happy you didn't meet an 
Amiga zealot in 1995. Things got personal quickly. It was downright ugly.
</p>

<p>
I still think there were some grounds for our fanaticism, though.
</p>

<p>
In a time when home PC:s were single tasking DOS boxes with 8 character 
file names and Ataris and Macs were single tasking GUI boxes, hampering
any hacker  with their glaring lack of a CLI, the Amiga was a champion of both 
worlds: It combined the CLI and GUI, leveraging both their strengths.
But there was more to it than that, something that's hard to convey
in so many words.
</p>

<p>
Many a time have I come across exasperated Amiga users who, on some 
online forum, tries to explain the greatness of the Amiga's operating 
system in a few short sentences. It often, quite understandably, boils 
down to something akin to "It's like UNIX", which I always think is 
unfair to both of the systems.
</p>

<p>
Sure, it was an early multitasking system with a capable command line. 
At the same time, it was also a mature and coherent desktop environment 
with levels of user friendliness much more like today's MacOS X than any 
traditional UNIX. But, contrary to today's MacOS, it never mollycoddled the
end user. It opened the machine up, rather than closing certain parts off.
</p>

<p>
Unlike UNIX, AmigaOS is a system designed for home computer use, lacking a 
lot of what makes UNIX so popular: memory protection, multi user 
support, source code portability and built in networking support.
</p>

<p>
They're very much alike in one aspect, though. Like UNIX, the Amiga's 
operating system is a collection of a lot of little strokes of genius 
that come together to make it bigger than the sum of its parts.
</p>

<p>
I invite you to explore this ingenuity with me. But first, let's get the 
terminology sorted.
</p>

<h3 id="jargon">Jargon buster</h3>

<p>
The Amiga's operating system has been called a lot of things by a lot of 
people, because it consists of many components that different types of 
users interacted more or less with. Let me try to clear things up a bit:
</p>


<dl>
<dt>AmigaOS</dt>

<dd>
This was never an official name during the Commodore days, but it's a 
handy way of describing all of the components below as a whole.
</dd>

<dt>Kickstart</dt>

<dd>
This is basically the firmware of the Amiga, residing in the ROM chip. 
On version 2.0 and up, the ROM chip was 512 kB large and contained not 
only code for self tests and bootstrapping but also quite sizable 
portions of the other parts of AmigaOS.
</dd>

<dt>AmigaDOS</dt>

<dd>
This is, roughly speaking, the command line interface, device drivers, 
file system management and so on. It was originally based on TRIPOS, a 
heritage that still shows to this day. (There are newer versions of AmigaOS
than 3.1, but this text will only cover the ones released by Commodore.)
</dd>

<dt>Intuition</dt>

<dd>
Best likened to a modern desktop compositor, Intuition handles screen 
updates and manages windows. The custom sound and video chips in the 
Amiga had mostly female names (Paula, Denise and later Alice), so I 
suppose Intuition is a fitting name for an abstraction layer that lets 
the OS interface with them.
</dd>

<dt>Workbench</dt>

<dd>
This is often used interchangeably with "AmigaOS" but it's really the 
name of just the desktop environment - which is a workbench, not a 
desktop: Programs are called tools, folders a called drawers and data 
files are called projects.
</dd>

</dl>

<h4>Other terminology</h4>

<dl>

<dt>Requesters</dt>

<dd>
Not really a major part of the OS per se, a requester is the Amiga's 
name for a dialog box. A "file requester" is a file selection dialog, 
for example. I still often use this term to describe any dialog on any 
platform, much to the confusion of friends and colleagues. Old habits 
die hard.
</dd>

<dt>Devices</dt>

<dd>
Devices, much like in UNIX, usually represent peripherals attached to the 
computer, such as storage media, printers, etc. The Amiga has a number 
of built-in devices that are automatically mounted,
for example the internal floppy drive, <code>DF0:</code>
and  the serial and parallel ports, <code>SER:</code> and <code>PAR:</code>
respectively. Other 
common devices are <code>DF1:</code>, the first external floppy drive,
<code>DH0:</code>, the 
common device name given to the bootable hard drive partition, and 
<code>CON:</code>, the text console.
There are also devices that can't
be mounted but only
be accessed using programming languages, such as <code>timer.device</code>
which is used to interface with hardware clocks.
</dd>

<dt>Volumes</dt>

<dd>
Mounted devices (such as <code>DF0</code>, <code>DF1</code>, <code>DH0</code>)
can contain a volume. In the 
case of <code>DH0:</code>, a bootable hard drive partition,
the volume is fixed and 
is represented by the name of the partition, such as <code>System:</code> or 
<code>Boot:</code>.
If you insert the Deluxe Paint program disk into the internal 
floppy drive, the current volume in device <code>DF0:</code>
will be <code>DPaint:</code>.
</dd>

</dl>


<h2 id="littlethings">The Little Things</h2>

<p>
<a href="https://datagubbe.se/ltmag/gfxs/cleanboot.png">
<img src="https://datagubbe.se/ltmag/gfxs/cleanboot.png" alt="The Amiga Workbench after a clean boot.">
</a>
</p>
<p>
<i>The Amiga Workbench after a clean boot. To the left are device icons,
for the RAM disk and hard drive partitions. The other icons represent various
applications, placed on the desktop for easy access.
Click the image for full resolution.</i>
</p>

<h3 id="ramdisk">The RAM Disk</h3>

<p>
The Amiga always has a RAM disk ready for use and the device name is 
always <code>RAM:</code>. No mounting, no third party software - it just sits 
there, waiting. That's clever in its own right, but the really ingenious 
part about it is that it's dynamically allocated. That means the size of the 
RAM disk corresponds to the amount of free memory currently available on 
the system, and that it never takes up more memory than is needed to
accommodate the files currently stored on it.
</p>

<p>
A RAM disk might sound esoteric today, but in the days of slow 
mechanical hard drives and floppy disks, it was a godsend for unpacking 
archives, running test compiles and storing temporary working documents.
</p>

<p>
The downside is that every time you reboot your computer, all the 
contents of the RAM disk are lost. Which brings us to...
</p>

<h3 id="raddisk">The RAD Disk</h3>

<p>
RAD, which (somehow) stands for Recoverable Ram Disk, is another 
testament to the flexibility and ingenuity of AmigaOS. The RAD disk is a 
fixed size RAM disk that can not only survive reboots but also itself
be booted from. It can be used as a small but extremely fast mini hard
drive, or  for extracting disk images to, for checking out their contents.
</p>

<h3 id="propscroll">Proportional scroll bars</h3>

<p>
A proportional scroll bar is a scroll bar that grows and shrinks to 
reflect the size of the scrollable content it represents:
</p>

<p>
<a href="https://datagubbe.se/ltmag/gfxs/propscroll.png">
<img src="https://datagubbe.se/ltmag/gfxs/propscroll.png" alt="Screenshot of proportional scroll bars">
</a>
</p>
<p>
<i>Click the image for full resolution.</i>
</p>

<p>
Highlighting a feature like this might 
seem like a silly point to make, because today all scroll bars are 
proportional. Not so in the bad old days: Microsoft 
didn't implement them until Windows 95 and Apple, as far as I know,
didn't make the move until MacOS 9 in 1999. In a time when computer mice 
had no scroll wheels, this was a nifty feature indeed.
</p>

<h3 id="editors">The Text Editors</h3>

<p>
<a href="https://datagubbe.se/ltmag/gfxs/ed.png">
<img src="https://datagubbe.se/ltmag/gfxs/ed.png" alt="Screenshot of Ed in full screen mode.">
</a>
</p>
<p>
<i>
Above, Ed is used to edit S:Shell-Startup, the equivalent of .bashrc for
AmigaShell. The editor is currently in command mode, getting ready to delete
a line of text.
Click the image for full resolution.</i>
</p>

<p>
AmigaOS shipped with three different text editors: Ed, Edit and MEmacs. 
The latter is a port of, you guessed it, Micro Emacs, and will of course 
appeal to Emacs fans. The other two are sort of curiously named: Edit is 
a line editor mostly resembling ed on UNIX. The Amiga's Ed, on the other 
hand, is a full screen editor with both mouse support and an 
extensive command language. Amiga Ed is probably best likened with vi.
</p>

<p>
All three of them are capable and powerful editors. Both MEmacs and Ed 
make use of the Amiga's drop down GUI menus and feature support for 
macros and extensive configuration.
</p>

<p>
Ed's command mode is, as mentioned earlier, somewhat reminiscent of vi. 
Consider the following examples:
</p>

<p>
Change the next three occurrences of "data" to "gubbe":<br>
<code>3 E/data/gubbe/</code>
</p>

<p>
Move to top of file, repeat (RP) replace of "data" with "gubbe" until 
end of file:<br>
<code>T; RP E/data/gubbe/</code>
</p>

<p>
Move to top of file, find all occurrences of "gubbe" and insert three 
blank lines after every occurrence, repeat until end of file:<br>
<code>T; RP (F /gubbe/; 3A//)</code>
</p>

<p>
Ed also has something called an ARexx port, which completely </p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://datagubbe.se/ltmag/">https://datagubbe.se/ltmag/</a></em></p>]]>
            </description>
            <link>https://datagubbe.se/ltmag/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25245206</guid>
            <pubDate>Sun, 29 Nov 2020 14:14:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pijul – The Mathematically Sound Version Control System Written in Rust]]>
            </title>
            <description>
<![CDATA[
Score 88 | Comments 58 (<a href="https://news.ycombinator.com/item?id=25245129">thread link</a>) | @initialcommit
<br/>
November 29, 2020 | https://initialcommit.com/blog/pijul-version-control-system | <a href="https://web.archive.org/web/*/https://initialcommit.com/blog/pijul-version-control-system">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
			                <div>
			                    <p><img src="https://initialcommit.com/img/initialcommit/pijul-version-control-system.png" title="Pijul - The Mathematically Sound Version Control System Written in Rust" alt="Image of Pijul - The Mathematically Sound Version Control System Written in Rust">
			                    </p>
			                    
			                    
			                    	
			                    
			                    
			                    
			                    <h2>Introduction</h2>
<p>In our <a href="https://initialcommit.com/blog/Technical-Guide-VCS-Internals">Evolution of Version Control System Internals</a> post, we covered the inner workings of many version control systems, both historical and current. However, we haven't really covered <em>the possible future</em> of version control.  How will this field evolve going forward?</p>
<p>Although Git is dominant now and will certainly remain a strong player for years to come, will better tools be created? Pijul could be a strong contender.</p>
<p>In this article, we'll discuss Pijul - an alpha stage version control system that is gaining attention in the community.</p>
<h2>Background</h2>
<p><a href="https://pijul.org/">Pijul</a> is a VCS written by Pierre-Ã‰tienne Meunier and Florent Becker. After releasing a number of experimental prototypes between 2015 and 2020, the first alpha version was released in November 2020. By operating on diffs <em>and</em> on versions at the same time, Pijul combines aspects of third-generation VCS such as <a href="https://initialcommit.com/blog/Technical-Guide-VCS-Internals#git">Git</a> and <a href="https://initialcommit.com/blog/Evolution-of-VCS-Internals-2/#darcs">Darcs</a>.</p>
<p>Pijul is written in <a href="https://www.rust-lang.org/">Rust</a> and is currently in alpha stage development. The algorithms and formats underlying Pijul's design were recently overhauled for performance and robustness of the system, and the team is working on making it as stable as possible after these updates.</p>
<p>Pijul's architecture and design methodology was influenced by the <a href="http://darcs.net/">Darcs</a> project, which we <a href="https://initialcommit.com/blog/Evolution-of-VCS-Internals-2/#darcs">covered in detail here</a>.</p>
<p>One distinctive feature of Pijul (shared with Darcs) is <strong>change commutation</strong>, whereby changes that could be recorded independently can be applied in any order, without affecting the result.</p>
<p>However, unlike Darcs, which operates on changes only, Pijul applies changes to an abstract data structure representing generalized files, allowing it to maintain a notion of version as well as a notion of change between versions. This has a number of advantages, in particular in terms of performance and in terms of mathematical soundness.</p>
<p>The source code for Pijul can be found at <a href="https://nest.pijul.com/pijul/pijul">https://nest.pijul.com/pijul/pijul</a>. The <a href="https://nest.pijul.com/">Pijul Nest</a> is a remote hosting platform for Pijul repositories. Think of it as Pijul's version of GitHub or BitBucket.</p>
<h2>Purpose</h2>
<p>We already have <a href="https://git-scm.com/">Git</a>, the most popular and functional VCS on Earth. Git handles all of the features we could expect from a solid VCS (in fact it sets the benchmark for these features), including:</p>
<ul>
<li>Intuitive method and interface for version tracking</li>
<li>Easily sharing work and collaborating remotely</li>
<li>Lightweight branching and merging</li>
<li>Fast performance and security features</li>
<li>A long list of tools for conveniently managing repositories depending on desired workflow and personal style</li>
</ul>
<p>We also have Darcs, a patch-centric perspective on version control with the following advantages:</p>
<ul>
<li>In Darcs, a repository can be better thought of as a "set of patches" - applied as needed - as opposed to a linear history of dependent changesets.</li>
<li>The Darcs model preserves the <strong>identity</strong> of patches during operations like rebasing and cherry-picking, whereas Git sometimes needs to rewrite history due to chained identifiers that depend on the order of application. Preserving a change's ID can be considered a more natural approach.</li>
<li>Darcs has a very well designed interface and command set that provides verbose output to help speed up the learning curve for users and clarify what actions the users are taking.</li>
<li>Patch bundles can be easily transmitted via email to be applied by the remote repository owner.</li>
</ul>
<p>So since we have Git and Darcs, why do we need Pijul? Pijul was created to solve unrelated problems that exist in Git and Darcs.</p>
<p>Pijul uses a patch-centric model similar to Darcs, which doesn't require history to be re-written when reordering, cherry-picking, or otherwise reorganizing patches. All patches retain their identities permanently regardless of their context, order, operations performed, or team workflow. This is a very elegant solution and arguably a more natural way to create such a system. This is in contrast to Git in which certain operations such as rebases and cherry-picks can change commit ID's (and other identifiers), even if the content itself doesn't change.</p>
<p>Furthermore, subsequent cherry-picks from a remote branch in Git can lead to unnatural conflicts due to the rewriting of the initial cherry-picked commit's ID. Pijul avoids this problem completely as patches always retain their identity, regardless of their location in a branch.</p>
<p>So what about Darcs? In certain scenarios, Darcs runs into performance issues such as the <a href="http://darcs.net/FAQ/Performance#is-the-exponential-merge-problem-fixed-yet">exponential merge problem</a>. This issue causes certain merges to increase exponentially in difficulty, effectively preventing these merges from being performed. Pijul has solved this problem.</p>
<p>As is summed up nicely in <a href="https://pijul.org/posts/2020-11-07-towards-1.0#are-edge-labels-minimal">Pierre Meunier's recent post <strong>Toward's 1.0</strong></a>: "Our goals are to find the smallest possible system, both for reasons of mathematical aesthetics (why store useless stuff?) and the other one for performance."</p>
<p>Pijul's main purpose is to be an efficient VCS based on a sound mathematical theory, guaranteeing that basic properties of changes are always maintained. This consistency bolsters peace of mind in the software development process. With Pijul, developers can be 100% confident that the code they reviewed is the code that gets merged, which is not necessarily the case in Git and Mercurial. Even though file reshuffles do not seem to happen very often in these existing VCS, (and some of them are caught by tests), there are a few statistical studies highlighting their occurrence, and the security implications are huge.</p>
<p>One particular goal of Pijul is to model conflicts as normal states of collaboration, so that conflicts are resolved by normal changes, valid even for the same conflicts in any other context.</p>
<h2>Architecture</h2>
<p>A Pijul repository has a <code>pristine</code> directory, containing a number of <strong>channels</strong>. At any given time, a channel contains a set of unordered <strong>changes</strong>, which can also be seen as a version, since the order of independent changes does not matter in Pijul.</p>
<p>The "working copy" is simply the set of files directly editable by the user, and the correspondence between the working copy and the pristine is done by a <strong>file tracking tree</strong>, which is just a mapping between working copy files and files as stored in the pristine.</p>
<p>Moreover, changes <strong>can</strong> (but don't need to) depend on each other, and do so explicitly (see the section about the "sample change" below), in the sense that each change is uniquely identified by its cryptographic hash, and dependencies are explicit hashes of other changes. The <strong>minimal dependencies</strong> are enforced by Pijul to make sure that text edits make sense. For example, a change editing a file or a paragraph depends on the change that introduced that file or paragraph. This is because it doesn't make sense to change a piece of content that was never added in the first place, so the patch that added the content must be present for the patch that changed it to have meaning. Additionally, the user may specify extra, language-specific dependencies to model the edits more accurately, for example the dependency between introducing a function and using it in another file or another part of the same file. This is an extremely powerful feature.</p>
<p>If desired, this scheme of dependencies between changes allows Pijul to mimic the strict sequential ordering of commits used by Git and Mercurial, turning Pijul into a sort of "Git, but with mathematically sound merges". The downside of using Pijul like this is that changes relative to independent features of the project might need to be more carefully split between different channels, like Git branches. The "plain", or "standard" Pijul way is to try and record changes that are as independent as possible, and keep them on the same channel, since independent changes can always be split later on without changing their identity (i.e. their hash). Channels are useful for different "flavors" of the project, and one can push the same changes to multiple channels without modifying these changes.</p>
<h2>Q&amp;A with the Creator</h2>
<p>We wanted to get inside the head of Pierre-Ã‰tienne Meunier, the creator and lead developer of Pijul, so we <a href="https://initialcommit.com/blog/pijul-creator">asked him a series of questions related to his background and the creation of Pijul, and the direction of the version control field</a>. His answers were <strong>extremely</strong> interesting and worth a read (we split them into a separate post since they were fairly lengthy).</p>
<h2>Basic Commands</h2>
<p>One of Pijul's goals is to minimize the number of commands, so as to allow users to get a full understanding of the system as quickly as possible.</p>
<p>The commands are:</p>
<p><code>pijul init</code>: Creates a directory named <code>.pijul</code>, containing the following structure:</p>
<div>
    <pre><code>.pijul/
    changes
    config
    pristine
        db0
        db.lock</code></pre>
</div>
<p>Here, the meaningful things that get created are <code>db0</code>, which contains the pristine, in binary format, and a sample <code>config</code> file, editable in <a href="https://en.wikipedia.org/wiki/TOML">TOML format</a>.</p>
<p><code>pijul add &lt;filename.ext&gt;</code>: Adds a file to the repository's tracking list.<br>
<code>pijul remove &lt;filename.ext&gt;</code>:  Remove a file from the tracking list.<br>
<code>pijul mv &lt;filename1.ext&gt; &lt;filename2.ext&gt;</code>: Move and/or rename a file in the tracking list.<br>
<code>pijul ls</code>: Displays a list of currently tracked files.<br>
<code>pijul record</code> (or <code>pijul rec</code>): Creates a change and applies it to the pristine. Once we do that, the <code>.pijul/changes</code> gets populated with one change:</p>
<div>
    <pre><code>./
    file
    .pijul/
        changes
            ZN
                PGE4DJNVY4JAQABNSQYVF5LBFWNO6FRJI3LXX7E7EB4Y3NGGGQC.change
        config
        pristine
            db0
            db.lock</code></pre>
</div>
<p><code>pijul unrecord &lt;hash&gt;</code>: If no change depends on a change <code>hash</code>, we can also "undo" or "unapply" it using the <code>unrecord</code> command. For example, here our change's hash is <code>ZNPGE4DJNVY4JAQABNSQ...</code>, and we can use any unambiguous prefix of that hash, for example <code>pijul unrecord ZNPG</code>, or even <code>pijul unrecord Z</code> to undo it.<br>
<code>pijul reset</code>: Resets the repository to the state of a channel. Without any …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://initialcommit.com/blog/pijul-version-control-system">https://initialcommit.com/blog/pijul-version-control-system</a></em></p>]]>
            </description>
            <link>https://initialcommit.com/blog/pijul-version-control-system</link>
            <guid isPermaLink="false">hacker-news-small-sites-25245129</guid>
            <pubDate>Sun, 29 Nov 2020 14:01:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why sharing files/folders across devices is still messy in 2020?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25245046">thread link</a>) | @harish095
<br/>
November 29, 2020 | https://hkandala.dev/fileshare-mess-in-2020 | <a href="https://web.archive.org/web/*/https://hkandala.dev/fileshare-mess-in-2020">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1606656251998/nydbYJK0M.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format&amp;q=60"><div><div><div><div><p>Subscribe to <!-- -->my<!-- --> newsletter and never miss <!-- -->my<!-- --> upcoming articles</p></div></div></div><div itemprop="text"><p>This article is going to be a long rant on the problems I faced when I wanted to transfer a large number of files between two devices. I bet many of you would have faced a similar issue at one time or another. I will also try to state the problem better by defining the requirements of an ideal file sharing app and what technologies can plausibly help in building it. </p>
<p>So, recently I bought a new phone and I wanted to transfer all the files and folders (around 40GB) from my old phone to my windows laptop. Anyone would immediately think of connecting a USB cable and copying files. But my old phone has USB port issues, leaving me with the only wireless transfer. Well, with all the advancements in wireless technology it should be straightforward, right? I am not sure if I did it correctly, at least my experience was horrible.</p>
<p>I started searching for different options I have available to transfer wirelessly. These are what I came up with:</p>
<ul>
<li><strong>Cloud Drives</strong>: But it doesn't make sense for me to buy a subscription just for transferring 40GB of data. I want a way to transfer not to backup. So I discarded this option.</li>
<li><strong>Wi-Fi Direct:</strong> I installed  <a target="_blank" href="https://superbe.am/">Superbeam </a> - a popular Wi-Fi Direct app, and tried to transfer from my phone to my laptop. But transfer rates are very slow and connection keeps breaking, I have to start from the beginning every time. After many failed retries and after trying out other Wi-Fi Direct apps with the same problems, I gave up.</li>
<li><strong>FTP</strong>: I got fed up with all these apps and relied back on the standard FTP. Started an FTP server on my phone using  <a target="_blank" href="https://play.google.com/store/apps/details?id=pl.solidexplorer2">Solid File Explorer</a>  and downloaded the files from my laptop. Even with this, transfer rates are slow but better than Wi-Fi Direct. And I faced similar connection drop issues. After a few tries somehow managed to transfer all the files.</li>
</ul>
<p>After all this struggle, I started researching more to see if this is a real issue faced by everyone or just me. And I was surprised by the number of results I found on Hackernews, Reddit, and Quora. I found many queries where people kept asking "What are the best ways to transfer files from platform X to platform Y?" and many questions similar to that. It is quite clear that I am not alone. But the bad part is there is no standard solution. There are different apps available to solve this on different platforms but I failed to find a universal solution.  <a target="_blank" href="https://syncthing.net/">Syncthing</a>  is the best solution that comes very close to my requirements. Haven't tested the transfer rates but I presume it should be equivalent to network bandwidth.</p>
<p>But I was not able to digest the fact that even in 2020 where all devices are wireless, I still need to install app or software on different devices to transfer files between them. Isn't transferring files or documents across devices is the primary reason why LAN/Internet is invented? Why do I need to fiddle with different software to achieve that? And, any non-technical person wouldn't be interested in installing software and setting them up, they will just go grab the USB cables and transfer.</p>
<p>Disappointed me started listing down the requirements of an ideal file/data transfer app, and it goes like this:</p>
<ol>
<li>Ubiquitous and available on all platforms.</li>
<li>Requires minimal or no setup/installation. If I want to transfer a file to a friend who doesn't have it set up, we shouldn't be wasting more time in setting up than transferring the actual file.</li>
<li>Use the internet only when needed, if transferring between devices on the same network, my transfer speeds shouldn't be dependent on my internet bandwidth.</li>
<li>Be fast, like really fast, utilize the entire bandwidth.</li>
<li>Able to transfer any file, directory, or just a simple text message (like clipboard data).</li>
<li>Option to pause or resume when transferring large files, Handle connection issues reliably, and auto-retry on network failure without human intervention.</li>
<li>Transfer via a secure channel. At least it shouldn't be like anyone can easily sniff the data that is being transferred.</li>
<li>Simple and intuitive. No bloat. No account setup. Any layman should be able to use the app without any trouble.</li>
<li>And last but not the least, it should be free and open-source, which means no intermediate servers, preferably peer to peer.</li>
<li>Bonus: Transfer to multiple devices at once. An option to broadcast to all devices in the network.</li>
</ol>
<p>After noting down the requirements, especially the first two points, I quickly realized, this is possible if it is a web app, right? Browsers are available on every device, and web apps do not require any setup. And I am not the only one who realized this, many developers have already tried to solve this through a web app (<a target="_blank" href="https://snapdrop.net/">Snapdrop</a>,  <a target="_blank" href="https://www.sharedrop.io/">ShareDrop</a>), but they don't meet other requirements quite well, specifically directory sharing and pause/resume option which are deal-breakers when transferring large files.</p>
<p>I started exploring how these existing apps work in the hope to extend them. The underlying technology that makes it possible to transfer files via browsers is  <a target="_blank" href="https://webrtc.org/">WebRTC</a>. It is a p2p protocol and an API that is available in all modern browsers. With my current understanding and research, I believe one can build a web app that satisfies the above-mentioned requirements using WebRTC. Transfer rates might not be super fast but we can achieve decent rates. I began to learn how WebRTC works and working on how feasible it is to build this app. Will keep posting my updates and progress in this blog.</p>
<p>Do let me know in the comments if there is an existing app that satisfies the requirements mentioned so that I am not reinventing the wheel. Also, let me know your opinion on having WebRTC as a base technology, Do you think we can solve this never-ending problem of wireless file transfer with WebRTC? If not which technology/protocol do you think fits this problem well?</p>
</div></div></section></div></div>]]>
            </description>
            <link>https://hkandala.dev/fileshare-mess-in-2020</link>
            <guid isPermaLink="false">hacker-news-small-sites-25245046</guid>
            <pubDate>Sun, 29 Nov 2020 13:40:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I Made a Self-Quoting Tweet]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25244872">thread link</a>) | @OisinMoran
<br/>
November 29, 2020 | https://oisinmoran.com/quinetweet | <a href="https://web.archive.org/web/*/https://oisinmoran.com/quinetweet">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<p><em>Or the real reason Twitter doesn't want you to have an edit button.</em></p>

<p>
I'll try to leave the pulp in here and keep this as chronological as I can. In that spirit, no tweets were harmed in the making of this post.
</p>

<p>
The original idea to make a tweet that quote tweets itself is from the 28<sup>th</sup> of May 2020—as recorded in Evernote—but I think had likely occurred to me earlier when considering what ramifications Twitter having an edit button would have—most notably being able to mislead, being able to vandalize someone's timeline post-retweet, and of course being able to edit your tweet to refer to itself.
</p>

<p>
Fundamentally the challenge is just correctly guessing what ID a given tweet is going to get, then appending that onto the URL for our profile and tweeting it.</p>

<p>
This initial note already had some background research done into determining how tweet IDs were generated, with a link to <a href="https://ws-dl.blogspot.com/2019/08/2019-08-03-tweetedat-finding-tweet.html">this article containing a useful breakdown of Twitter's Snowflake IDs</a>, so thanks to the author of that, Nauman Siddique.
</p>

<h3>Anatomy of a tweet ID</h3>
<p>
Twitter used to use sequential IDs but no longer do.
Public-facing sequential IDs have the drawback of making usage of your platform easy to estimate.
They are also hard to generate in a distributed fashion while preserving order.
</p>

<p>
From the link above we find that the new Twitter IDs (used for more than just tweets—for example, lists) are composed of three parts: a timestamp, a machine ID, and a sequence number, arranged like so:
</p>

<code><pre>TIMESTAMP MACHINE ID SEQUENCE NUM
41 BITS   10 BITS    12 BITS
000...000 0000000000 000000000000 
</pre></code>

<p>
These are then just stuck together and interpreted as a decimal number and look something like 1320553050730340354.
</p>

<p>
Brute-forcing the whole thing is not going to work here as there are so many possibilities, but thankfully the largest section is the timestamp, which should be easy enough to guess correctly.
This will likely just involve finding the delay between my program guessing an ID and Twitter assigning an ID to the generated tweet.
There will always be fluctuations here as we're dealing in milliseconds and both my computer and all of Twitter's system will be under varying loads.
However, it should be somewhat consistent, at least within a given timeframe.
Hopefully then we can just figure the other two out as they are much smaller—having only 1024 and 4096 possibilities, compared to the timestamp's over 2 trillion (that's a lot of milliseconds).
</p>

<p>
I knew I'd likely have to do <em>some</em> spamming as I was not going to get it right on the first go, so I created a new account to spare my few but wonderful followers.
</p>

<h3>Why the name?</h3>
<p>
From Wikipedia:<br>
<em>
A quine is a computer program which takes no input and produces a copy of its own source code as its only output.
</em></p>
<p>
So it's only natural that a quinetweet would print its own URL, and thus hopefully quote tweet or retweet itself.
And naturally I set the profile photo to one of Quine himself, and the banner to a relevant Escher lithograph.
</p>


<h3>Tweeting with the API</h3>
<p>
I signed the new profile up for a <a href="https://developer.twitter.com/">developer account</a> to start tweeting programatically using Twitter's API. And began with their examples using <a href="https://github.com/twitter/twurl">twurl</a>.
</p>

<p>The first step is authorization with my shiny new API keys:</p>
<code><pre>twurl authorize --consumer-key CONSUMER_KEY \
                --consumer-secret CONSUMER_SECRET
</pre></code>

<p>And now we can get straight into tweeting:</p>
<code><pre>twurl -d 'status=Test tweet using the POST statuses/update endpoint' /1.1/statuses/update.json
</pre></code>
<p>Resulting in our beautiful first tweet:</p>
<blockquote><p lang="en" dir="ltr">Test tweet using the POST statuses/update endpoint</p>— quinetweet (@quinetweet) <a href="https://twitter.com/quinetweet/status/1308911113229209601?ref_src=twsrc%5Etfw">September 23, 2020</a></blockquote> 

<p>In the returned response there is quite a lot of information, but we only really care about the ID, in this case 1308911113229209601 which thankfully matches up with what shows up on Twitter's website—they're not lying!</p>

<p>Okay, so now let's quote tweet the previous tweet:</p>

<code><pre>twurl -d 'status=https://twitter.com/quinetweet/status/1308911113229209601' /1.1/statuses/update.json
</pre></code>

<p>Beautiful! I can almost taste the recursion already.</p>
<blockquote><p lang="und" dir="ltr"><a href="https://t.co/FXps7y4yMw">https://t.co/FXps7y4yMw</a></p>— quinetweet (@quinetweet) <a href="https://twitter.com/quinetweet/status/1308912279853903872?ref_src=twsrc%5Etfw">September 23, 2020</a></blockquote> 

<p>Now to investigate the behaviour of the various components of the ID, let's do two tweets in quick succession, using a simple Bash loop:</p>

<code><pre>for i in {1..2}; do twurl -d 'status=Quick succession test' /1.1/statuses/update.json; done
</pre></code>

<p>
To which we're met with a warning from Twitter about the second attempt being a duplicate—so apparently Twitter do have <em>some</em> protection against unoriginality.
</p>

<p>
No worries, simply adding a variable should fix this:
</p>

<code><pre>for i in {1..2}; do twurl -d 'status=Quick succession test <span>$i</span>' /1.1/statuses/update.json; done
</pre></code>

<p>
Oh no! This is also getting the same duplicate warning, what's going on?
Let's check Twitter:
</p>

<blockquote><p lang="en" dir="ltr">Quick succession test <a href="https://twitter.com/search?q=%24i&amp;src=ctag&amp;ref_src=twsrc%5Etfw">$i</a></p>— quinetweet (@quinetweet) <a href="https://twitter.com/quinetweet/status/1309237764035051520?ref_src=twsrc%5Etfw">September 24, 2020</a></blockquote> 

<p>
How embarrassing—we've accidentally linked to <a href="https://en.wikipedia.org/wiki/Intelsat">Intelsat</a>'s stock ticker!
We should have used double quotes:
</p>

<code><pre>for i in {1..2}; do twurl -d <span>"</span>status=Quick succession test $i<span>"</span> /1.1/statuses/update.json; done
</pre></code>

<blockquote><p lang="en" dir="ltr">Quick succession test 1</p>— quinetweet (@quinetweet) <a href="https://twitter.com/quinetweet/status/1309237975868469248?ref_src=twsrc%5Etfw">September 24, 2020</a></blockquote> 
<blockquote><p lang="en" dir="ltr">Quick succession test 2</p>— quinetweet (@quinetweet) <a href="https://twitter.com/quinetweet/status/1309237977982345216?ref_src=twsrc%5Etfw">September 24, 2020</a></blockquote> 

<p>Finally! Now we can say we're programatically tweeting without completely lying.</p>

<p>
Okay now let's take a look at these last two IDs, splitting them into timestamp, machine ID, and sequence number:
</p>

<code><pre>1309237975868469248 -&gt; (312146657912, 375, 0)
1309237977982345216 -&gt; (312146658416, 362, 0)
</pre></code>

<p>
We see the second was posted 504&nbsp;ms after the first (from Twitter's point of view), the machine IDs differ by 13, and both the sequence numbers are 0. We might be able to get away with assuming the sequence number is most commonly 0. This is great news because it was the larger of the two non-timestamp components so greatly reduces the number of checks we'll have to make. The range for our brute forcing looks like it might be small enough after all!</p>

<p>While Bash was great to start off with, I'm more comfortable with Python, so...</p>

<h2>Let's start guessing some IDs</h2>
<p>I'm just going to post the final code here with a brief description of each function. I'm sure there are numerous ways the code could be improved (for one it should probably take the machine ID and other guesswork bits as arguments).</p>

<h3>tweet_id_from_timestamp</h3>
<p>This does roughly what it says on the tin, and was created by simply reversing the get_tweet_timestamp function that was helpfully shared in <a href="https://ws-dl.blogspot.com/2019/08/2019-08-03-tweetedat-finding-tweet.html">the article mentioned in the intro</a>, including Twitter's timestamp OFFSET that they had already worked out.</p>

<h3>tweet_id_to_parts</h3>
<p>This gets a tweet id and splits it up into the parts described above: the timestamp, machine ID, and sequence number.

</p><h3>compare_ids</h3>
<p>To see how badly off our guesses are, we'll need a function to compare the ID we guessed to the one Twitter actually assigned. While it might seem like a tweet ID is just one number and you might think you could just subtract the two to compare them, due to the nature of how they are created simply being off by one millisecond and getting everything else right would be lead your guess to be off by several million. For this reason it makes more sense to compare the individual parts so that is what we do here.</p>

<h3>guess_tweet_id</h3>
<p>Again, a simply named function that guesses a tweet ID based on the time it is called and another time offset and machine ID. Note here that we don't do anything about the sequence number as it was usually zero so there's not much point guessing anything else.</p>

<h3>guess</h3>
<p>This function actually does the posting of the tweets and will guess N different tweets in quick succession with the same time offset and machine ID. I kept N low enough so I could manually change the offsets and if they were very far off I wouldn't eat into the rate limit too much.</p>



<p>A non-gist version of the code is on Github <a href="https://github.com/OisinMoran/quinetweet/blob/main/quinetweet.py">here</a>.</p>

<h2>An idea that didn't work</h2>
<p>While manually adjustment of the offsets and machine ID was getting me kind of close, I thought it could be even better to do that automatically. If these values were time-sensitive, a program would be able to update them much faster than I could. I tried to do this by updating based on the mean error of the previous several responses, but this ended up not really working (maybe the median or mode would fare better here). It ended up being easier to just eyeball the differences and pick something reasonable, though I'm not entirely sure if I explicitly know—even now—what I was doing.</p>


<h2>Shit gets weird</h2>
<p>With that all done, I began the sport of just letting it run in short bursts until the rate limit (300 tweets per 3 hour window) forced me to go do something else. Who knew rate limits could be such an effective public health measure?</p>

<p>A strange and completely unexpected thing began to happen. In these quiet hours of the internet, some of the attempted self-quotes started linking to tweets from other accounts, mostly in South America and Japan! What was going on? All of the guessed URLs had the quinetweet account name hardcoded into them, so why and how were they linking to other tweets?</p>

<blockquote><p lang="und" dir="ltr"><a href="https://t.co/OOUKS9dwCp">https://t.co/OOUKS9dwCp</a></p>— quinetweet (@quinetweet) <a href="https://twitter.com/quinetweet/status/1309684115017527297?ref_src=twsrc%5Etfw">September 26, 2020</a></blockquote> 

<p>That is most certainly not my account. So what did we actually <em>try</em> to tweet here and what did it link to? Conveniently both of our accounts have ten character names so the URLs line up nicely in a monospaced font which makes visually comparing them even easier than normal.</p>

<code><pre>https://twitter.com/quinetweet/status/1309684114073808896
https://twitter.com/gzhdigital/status/1309684114073808896
</pre></code>

<p>Okay, wild! We guessed someone else's tweet ID! And as the IDs are time-dependent that means they were met with an instantaneous retweet—creepy. Also, it seems like Twitter doesn't actually care about the username and just resolves URLs based on the tweet ID. I'm sure lots of people already knew that but it's new to me.</p>

<p>Let's try another, this time from the Pope: <a href="https://twitter.com/Pontifex/status/1107421599333007362">https://twitter.com/Pontifex/status/1107421599333007362</a></p>
<p>Okay this is pretty interesting, but back to the task at …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://oisinmoran.com/quinetweet">https://oisinmoran.com/quinetweet</a></em></p>]]>
            </description>
            <link>https://oisinmoran.com/quinetweet</link>
            <guid isPermaLink="false">hacker-news-small-sites-25244872</guid>
            <pubDate>Sun, 29 Nov 2020 12:53:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Poisson distribution is a special case of the Binomial]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25244724">thread link</a>) | @lordgrenville
<br/>
November 29, 2020 | https://www.andrewchamberlain.com/field-notes/simple-math-of-poisson-and-binomial-distributions | <a href="https://web.archive.org/web/*/https://www.andrewchamberlain.com/field-notes/simple-math-of-poisson-and-binomial-distributions">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-nc-base="header" data-controller="AncillaryLayout">
      

      

      <div>

        

        <div>
          

          <main>
            
              <section data-content-field="main-content">
                <article id="post-5f2dca629a534f6ff99a8a66" data-item-id="5f2dca629a534f6ff99a8a66">

    
      
    

    <div data-layout-label="Post Body" data-type="item" data-updated-on="1596836450041" id="item-5f2dca629a534f6ff99a8a66"><div><div><div data-block-type="2" id="block-308a2399fefae0cb076a"><div><p>The binomial and Poisson distributions are two of the most commonly used in applied data science. And they are integrally linked. The Poisson distribution is really just a special case of the binomial — where the number of trials is large, and the probability of success in any given one is small.</p><p>In  this post I’ll walk through a simple proof showing that the Poisson distribution is really just the binomial with n approaching infinity and p approaching zero.</p><p><strong>The Proof</strong></p><p>The binomial distribution works when we have a fixed number of events n, each with a constant probability of success p. Imagine we don’t know the number of trials that will happen. Instead, we only  know the average number of successes per time period. So we know the  rate of successes per day, but not the number of trials n or the probability of success p that led to that rate.</p><p>Define a number lamba = np.</p><p>Let this be the rate of successes per day. It’s equal to np. That’s the number of trials n — however many there are — times the chance of success p for each of those trials. Think  of it like this: if the chance of success is p and we run n trials per day, we’ll observe np successes per day on average. That’s our observed success rate lambda.</p><p>Recall that the binomial distribution looks like this:</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1597066285615_61920"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f176107ca4673614d503f89/1597087586802-21QRYF1Q4VK5IFZ82NBM/ke17ZwdGBToddI8pDm48kJnLJdM8l6BQFYojWP5ahkvlfiSMXz2YNBs8ylwAJx2qLijIv1YpVq4N1RMuCCrb3iJz4vYg48fcPCuGX417dnb-Xs857K_cPy1IuVCwF9Ynf7s95dhI51bYhESwT0hj4AoyyEsAbPHhHcQMU6bWQFI/image-asset.gif" data-image="https://images.squarespace-cdn.com/content/v1/5f176107ca4673614d503f89/1597087586802-21QRYF1Q4VK5IFZ82NBM/ke17ZwdGBToddI8pDm48kJnLJdM8l6BQFYojWP5ahkvlfiSMXz2YNBs8ylwAJx2qLijIv1YpVq4N1RMuCCrb3iJz4vYg48fcPCuGX417dnb-Xs857K_cPy1IuVCwF9Ynf7s95dhI51bYhESwT0hj4AoyyEsAbPHhHcQMU6bWQFI/image-asset.gif" data-image-dimensions="316x45" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="5f319f629a996b6a4f4afa29" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1597066285615_76429"><p>As mentioned above, let’s define lambda = np. Solving for p, we get p = lamda / n. What  we’re going to do here is substitute this expression for p into the  binomial distribution above, and take the limit as n goes to infinity, and try to come up with something useful. That is,</p></div><div data-block-type="5" id="block-yui_3_17_2_1_1597066285615_77125"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f176107ca4673614d503f89/1597087677711-6LJNKVE9PCSHEKA4O2EU/ke17ZwdGBToddI8pDm48kH4AXBgIedTA1gdPQR3I4bTlfiSMXz2YNBs8ylwAJx2qLijIv1YpVq4N1RMuCCrb3iJz4vYg48fcPCuGX417dnZ42qoJEQyw5ws8PHQ_0PYG3KA-xefyJOo79wFHgybI7QoyyEsAbPHhHcQMU6bWQFI/image-asset.gif" data-image="https://images.squarespace-cdn.com/content/v1/5f176107ca4673614d503f89/1597087677711-6LJNKVE9PCSHEKA4O2EU/ke17ZwdGBToddI8pDm48kH4AXBgIedTA1gdPQR3I4bTlfiSMXz2YNBs8ylwAJx2qLijIv1YpVq4N1RMuCCrb3iJz4vYg48fcPCuGX417dnZ42qoJEQyw5ws8PHQ_0PYG3KA-xefyJOo79wFHgybI7QoyyEsAbPHhHcQMU6bWQFI/image-asset.gif" data-image-dimensions="409x49" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="5f319fbd5350e646da17dcde" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1597066285615_80865"><p>Pulling out the constants and splitting the term on the right that’s to the power of (n-k) into a term to the power of n and one to the power of -k, we get,</p></div><div data-block-type="5" id="block-yui_3_17_2_1_1597066285615_81399"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f176107ca4673614d503f89/1597087743410-3W7Q1CG0ZVAA1GI77RXL/ke17ZwdGBToddI8pDm48kMzDxksFjHBgZHUcTgpaEQrlfiSMXz2YNBs8ylwAJx2qLijIv1YpVq4N1RMuCCrb3iJz4vYg48fcPCuGX417dnZ_AVdRRj0qh6vKJyEZyc08doPF8w5AIjIzQU6ickmlQQoyyEsAbPHhHcQMU6bWQFI/image-asset.gif" data-image="https://images.squarespace-cdn.com/content/v1/5f176107ca4673614d503f89/1597087743410-3W7Q1CG0ZVAA1GI77RXL/ke17ZwdGBToddI8pDm48kMzDxksFjHBgZHUcTgpaEQrlfiSMXz2YNBs8ylwAJx2qLijIv1YpVq4N1RMuCCrb3iJz4vYg48fcPCuGX417dnZ_AVdRRj0qh6vKJyEZyc08doPF8w5AIjIzQU6ickmlQQoyyEsAbPHhHcQMU6bWQFI/image-asset.gif" data-image-dimensions="380x49" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="5f319fffb9ba4944b7972f08" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1597066285615_85076"><p>Now let’s take the limit of this right-hand side one term at a time.  We’ll do this in three steps. The first step is to find the limit of:</p></div><div data-block-type="5" id="block-yui_3_17_2_1_1597066285615_85539"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f176107ca4673614d503f89/1597087792224-LSUII3YL0GGLZMW7XUST/ke17ZwdGBToddI8pDm48kA7RhMLX9Rbx8mfiBW4kka7lfiSMXz2YNBs8ylwAJx2qrCLSIWAQvdC7iWmC9HNtRbmqciHjXi_oMmEa9t4p0PJPajQOtspepRBkH48-lMYL12cBNoFd1dM2xsSC9c80Wg/image-asset.gif" data-image="https://images.squarespace-cdn.com/content/v1/5f176107ca4673614d503f89/1597087792224-LSUII3YL0GGLZMW7XUST/ke17ZwdGBToddI8pDm48kA7RhMLX9Rbx8mfiBW4kka7lfiSMXz2YNBs8ylwAJx2qrCLSIWAQvdC7iWmC9HNtRbmqciHjXi_oMmEa9t4p0PJPajQOtspepRBkH48-lMYL12cBNoFd1dM2xsSC9c80Wg/image-asset.gif" data-image-dimensions="151x45" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="5f31a030f5cb9c0f2d04bce6" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1597066285615_89143"><p>In  the numerator, we can expand n! into n terms of (n)(n-1)(n-2)…(1). And  in the denominator, we can expand (n-k) into n-k terms of  (n-k)(n-k-1)(n-k-2)…(1). That is,</p></div><div data-block-type="5" id="block-yui_3_17_2_1_1597066285615_89598"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f176107ca4673614d503f89/1597087816803-WIH8KAAIRMLHBKS2GLO5/ke17ZwdGBToddI8pDm48kP66QxYrW1rWDoX3taGYNDPlfiSMXz2YNBs8ylwAJx2qLijIv1YpVq4N1RMuCCrb3iJz4vYg48fcPCuGX417dnaUDTkcLiIObv4Az51GL1TM7EX_s6w27CqphmP_QXTpQQoyyEsAbPHhHcQMU6bWQFI/image-asset.gif" data-image="https://images.squarespace-cdn.com/content/v1/5f176107ca4673614d503f89/1597087816803-WIH8KAAIRMLHBKS2GLO5/ke17ZwdGBToddI8pDm48kP66QxYrW1rWDoX3taGYNDPlfiSMXz2YNBs8ylwAJx2qLijIv1YpVq4N1RMuCCrb3iJz4vYg48fcPCuGX417dnaUDTkcLiIObv4Az51GL1TM7EX_s6w27CqphmP_QXTpQQoyyEsAbPHhHcQMU6bWQFI/image-asset.gif" data-image-dimensions="409x45" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="5f31a04897beb327b1a98d58" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1597066285615_93270"><p>Written  this way, it’s clear that many of terms on the top and bottom cancel  out. The (n-k)(n-k-1)…(1) terms cancel from both the numerator and  denominator, leaving the following:</p></div><div data-block-type="5" id="block-yui_3_17_2_1_1597066285615_93724"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f176107ca4673614d503f89/1597087883073-7WH745RAYAMOELT9OU04/ke17ZwdGBToddI8pDm48kCFKX-8fwr5EArakrmiO1lzlfiSMXz2YNBs8ylwAJx2qrCLSIWAQvdC7iWmC9HNtRQEb4qUtj5NnpBvQ-YpvJYdKZHvlKAM8wPBo-PIXawxsfTuGUP4aUF-8cu_6QKX6SQ/image-asset.gif" data-image="https://images.squarespace-cdn.com/content/v1/5f176107ca4673614d503f89/1597087883073-7WH745RAYAMOELT9OU04/ke17ZwdGBToddI8pDm48kCFKX-8fwr5EArakrmiO1lzlfiSMXz2YNBs8ylwAJx2qrCLSIWAQvdC7iWmC9HNtRQEb4qUtj5NnpBvQ-YpvJYdKZHvlKAM8wPBo-PIXawxsfTuGUP4aUF-8cu_6QKX6SQ/image-asset.gif" data-image-dimensions="265x39" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="5f31a08bdd4ff01d8bea5de4" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1597066285615_97328"><p>Since  we canceled out n-k terms, the numerator here is left with k terms,  from n to n-k+1. So this has k terms in the numerator, and k terms in the denominator since n is to the power of k. Expanding out the numerator and denominator we can rewrite this as:</p></div><div data-block-type="5" id="block-yui_3_17_2_1_1597066285615_97805"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f176107ca4673614d503f89/1597087933323-WM8WBQQ4RMN16PZ8HBFF/ke17ZwdGBToddI8pDm48kIO_OAMJXD1inhMLhdG-LevlfiSMXz2YNBs8ylwAJx2qLijIv1YpVq4N1RMuCCrb3iJz4vYg48fcPCuGX417dnYYT6QRR55m_Oszg5M7jY35qExCVbJCnnK3GVBw9MGJugoyyEsAbPHhHcQMU6bWQFI/image-asset.gif" data-image="https://images.squarespace-cdn.com/content/v1/5f176107ca4673614d503f89/1597087933323-WM8WBQQ4RMN16PZ8HBFF/ke17ZwdGBToddI8pDm48kIO_OAMJXD1inhMLhdG-LevlfiSMXz2YNBs8ylwAJx2qLijIv1YpVq4N1RMuCCrb3iJz4vYg48fcPCuGX417dnYYT6QRR55m_Oszg5M7jY35qExCVbJCnnK3GVBw9MGJugoyyEsAbPHhHcQMU6bWQFI/image-asset.gif" data-image-dimensions="346x45" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="5f31a0bd115f6d75cb9efe2d" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1597066285615_120084"><div><p>This  has k terms. Clearly, every one of these k terms approaches 1 as n  approaches infinity. So we know this portion of the problem just simplifies to one. So we’re done with the first step.</p><p>The second step is to find the limit of the term in the middle of our equation, which is</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1597066285615_120556"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f176107ca4673614d503f89/1597087987320-BKU0E2HTCJBRCYHM3MKI/ke17ZwdGBToddI8pDm48kGv3dMzNj9HI_xS5MVUt6cDlfiSMXz2YNBs8ylwAJx2qrCLSIWAQvdC7iWmC9HNtRcmWYEP8QnDdzp7XEe63rVZ5BnCvfD2Ub1Px6-nBGoCkA62_2X8WX2SRxlD0L7r-UQ/image-asset.gif" data-image="https://images.squarespace-cdn.com/content/v1/5f176107ca4673614d503f89/1597087987320-BKU0E2HTCJBRCYHM3MKI/ke17ZwdGBToddI8pDm48kGv3dMzNj9HI_xS5MVUt6cDlfiSMXz2YNBs8ylwAJx2qrCLSIWAQvdC7iWmC9HNtRcmWYEP8QnDdzp7XEe63rVZ5BnCvfD2Ub1Px6-nBGoCkA62_2X8WX2SRxlD0L7r-UQ/image-asset.gif" data-image-dimensions="117x46" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="5f31a0f30d9770770a617365" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1597066285615_124191"><p>That looks a lot like the definition of e. Letting x = -n/lambda, we can substitute that into the above expression and take the limit as follows:</p></div><div data-block-type="5" id="block-yui_3_17_2_1_1597066285615_124912"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f176107ca4673614d503f89/1597088109094-HD5XVQE3IRL307YNIAZE/ke17ZwdGBToddI8pDm48kIgTw2_yHAWgGA-FHXZkj6TlfiSMXz2YNBs8ylwAJx2qLijIv1YpVq4N1RMuCCrb3iJz4vYg48fcPCuGX417dnYbOH6c0ntmvpX1VXBOQ9EcLYrGlml14Us4Xr9s9fEnCAoyyEsAbPHhHcQMU6bWQFI/image-asset.gif" data-image="https://images.squarespace-cdn.com/content/v1/5f176107ca4673614d503f89/1597088109094-HD5XVQE3IRL307YNIAZE/ke17ZwdGBToddI8pDm48kIgTw2_yHAWgGA-FHXZkj6TlfiSMXz2YNBs8ylwAJx2qLijIv1YpVq4N1RMuCCrb3iJz4vYg48fcPCuGX417dnYbOH6c0ntmvpX1VXBOQ9EcLYrGlml14Us4Xr9s9fEnCAoyyEsAbPHhHcQMU6bWQFI/image-asset.gif" data-image-dimensions="336x51" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="5f31a16dacb31f23dbc7c33b" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1597066285615_128517"><p>Our third and final step is to find the limit of the last term on the right. As n approaches infinity, this term just becomes 1^(-k) which is equal to one. And that takes care of our last term. Putting these three results together, we can rewrite our original limit as</p></div><div data-block-type="5" id="block-yui_3_17_2_1_1597066285615_129027"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f176107ca4673614d503f89/1597088183709-QTX59AZL10T41WLTFVSC/ke17ZwdGBToddI8pDm48kECzhidq9Op-f6v7y2YsdmXlfiSMXz2YNBs8ylwAJx2qgRUppHe6ToX8uSOdETM-XldvY_sAIyUlfjhoEMtv77EE6DaWbNfF-Ujv1VqX_3Xls60_yeCJw5hnrNhQaJeSeinVsJ7BK-csjQOiHsycAYY/image-asset.gif" data-image="https://images.squarespace-cdn.com/content/v1/5f176107ca4673614d503f89/1597088183709-QTX59AZL10T41WLTFVSC/ke17ZwdGBToddI8pDm48kECzhidq9Op-f6v7y2YsdmXlfiSMXz2YNBs8ylwAJx2qgRUppHe6ToX8uSOdETM-XldvY_sAIyUlfjhoEMtv77EE6DaWbNfF-Ujv1VqX_3Xls60_yeCJw5hnrNhQaJeSeinVsJ7BK-csjQOiHsycAYY/image-asset.gif" data-image-dimensions="551x49" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="5f31a1b772b09257edf83f5c" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1597066285615_132636"><p>Which just simplifies to the following:</p></div><div data-block-type="5" id="block-yui_3_17_2_1_1597066285615_133109"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f176107ca4673614d503f89/1597088219140-KGU35ZDEE71Z04A44XUZ/ke17ZwdGBToddI8pDm48kEyUvvPLBbuY9CyyTt06y9rlfiSMXz2YNBs8ylwAJx2qrCLSIWAQvdC7iWmC9HNtRQUl7UjFU1HWO2Ysc5szOxbUH9DsgjSytpf-oaWdL_OiewQNTizxVCmf3LH3k3ugIA/image-asset.gif" data-image="https://images.squarespace-cdn.com/content/v1/5f176107ca4673614d503f89/1597088219140-KGU35ZDEE71Z04A44XUZ/ke17ZwdGBToddI8pDm48kEyUvvPLBbuY9CyyTt06y9rlfiSMXz2YNBs8ylwAJx2qrCLSIWAQvdC7iWmC9HNtRQUl7UjFU1HWO2Ysc5szOxbUH9DsgjSytpf-oaWdL_OiewQNTizxVCmf3LH3k3ugIA/image-asset.gif" data-image-dimensions="153x46" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="5f31a1db68ee975f4d92875c" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1597066285615_136716"><div><p>That’s the familiar probability density function for the Poisson distribution, which gives us the probability of k successes per period given our parameter lambda.</p><p>So we’ve shown that the Poisson distribution is just a special case of the binomial, in which the number of n trials grows to infinity and the chance of success in any particular trial approaches zero. And that completes the proof!</p></div></div></div></div></div>

    

    

    

  </article>





  
              </section>
            
          </main>

        </div>
      </div>

      


    </div></div>]]>
            </description>
            <link>https://www.andrewchamberlain.com/field-notes/simple-math-of-poisson-and-binomial-distributions</link>
            <guid isPermaLink="false">hacker-news-small-sites-25244724</guid>
            <pubDate>Sun, 29 Nov 2020 12:16:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[2Q Cache Management Algorithm]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25244333">thread link</a>) | @arpitbbhayani
<br/>
November 29, 2020 | https://arpitbhayani.me/blogs/2q-cache | <a href="https://web.archive.org/web/*/https://arpitbhayani.me/blogs/2q-cache">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>LRU is one of the most widely used cache eviction algorithms that span its utility across multiple database systems. Although popular, it suffers from a bunch of limitations especially when it is used for managing caches in disk-backed databases like MySQL and Postgres.</p>
<p>In this essay, we take a detailed look into the sub-optimality of LRU and how one of its variants called 2Q addresses and improves upon it. 2Q algorithm was first introduced in the paper - <a href="https://www.semanticscholar.org/paper/2Q%3A-A-Low-Overhead-High-Performance-Buffer-Johnson-Shasha/5fa357b43c8351a5d8e7124429e538ad7d687abc">2Q: A low overhead high-performance buffer management replacement algorithm</a> by Theodore Johnson and Dennis Shasha.</p>

<p>The <a href="https://en.wikipedia.org/wiki/Cache_replacement_policies#Least_recently_used_(LRU)">LRU eviction algorithm</a> evicts the page from the buffer which has not been accessed for the longest. LRU is typically implemented using a <a href="https://en.wikipedia.org/wiki/Doubly_linked_list">Doubly Linked List</a> and a <a href="https://en.wikipedia.org/wiki/Hash_table">Hash Table</a>. The intuition of this algorithm is so strong and implementation is so simple that until the early '80s, LRU was the algorithm of choice in nearly all the systems. But as stated above, there are certain situations where LRU performs sub-optimal.</p>
<p><img src="https://user-images.githubusercontent.com/4745789/100534745-43ae8400-3238-11eb-8855-752a6ef2f3c6.png" alt="https://user-images.githubusercontent.com/4745789/100534745-43ae8400-3238-11eb-8855-752a6ef2f3c6.png"></p>
<h2>Sub-optimality during DB scans</h2>
<p>If the database table is bigger than the LRU cache, the DB process, upon scanning the table will wipe out the entire LRU cache and fill it with the pages from just one scanned table. If these pages are not referenced again, this is a total loss and the performance of the database takes a massive hit. The performance will pickup once these pages are evicted from the cache and other pages make an entry.</p>
<h2>Sub-optimality in evictions</h2>
<p>LRU algorithm works with a single dimension - recency - as it removes the pages from the buffer on the basis of recent accesses. Since it does not really consider any other factor, it can actually evict a warmer page and replace it with a colder one - a page that could and would be accessed just once.</p>

<p>2Q addresses the above-illustrated issues by introducing parallel buffers and supporting queues. Instead of considering just recency as a factor, 2Q also considers access frequency while making the decision to ensure the page that is really warm gets a place in the LRU cache. It admits only hot pages to the main buffer and tests every page for a second reference.</p>
<p>The golden rule that 2Q is based on is - <em>Just because a page is accessed once does not entitle it to stay in the buffer. Instead, it should be decided if it is accessed again then only keep it in the buffer.</em></p>
<p>Below we take a detailed look into two versions of the 2Q algorithm - simplified and improved.</p>
<h2>Simplified 2Q</h2>
<p>Simplified 2Q algorithm works with two buffers: the primary LRU buffer - <code>Am</code>  and a secondary FIFO buffer - <code>A1</code>. New faulted pages first go to the secondary buffer <code>A1</code> and then when the page is referenced again, it moves to the primary LRU buffer <code>Am</code>. This ensures that the page that moves to the primary LRU buffer is hot and indeed requires to be cached.</p>
<p><img src="https://user-images.githubusercontent.com/4745789/100536835-41a0f100-3249-11eb-920b-0bcaff905906.png" alt="https://user-images.githubusercontent.com/4745789/100536835-41a0f100-3249-11eb-920b-0bcaff905906.png"></p>
<p>If the page residing in <code>A1</code> is never referenced again, it eventually gets discarded, implying the page was indeed cold and did not deserve to be cached. Thus this simplified 2Q provides protection against the two listed sub-optimality of the simple LRU scheme by adding a secondary buffer and testing pages for a second reference. The pseudocode for the Simplified 2Q algorithm is as follows:</p>
<pre><code><span><span>def</span> <span>access_page</span><span>(X: page)</span>:</span>
    
    
    <span>if</span> X <span>in</span> Am:
         Am.move_front(X)

    
    
    
    
    <span>elif</span> X <span>in</span> A1:
         A1.remove(X)
         Am.add_front(X)

    
    <span>else</span>:
         
         <span>if</span> A1.is_full():
             A1.pop()

         
         A1.add_front(X)
</code></pre>
<p>Tuning Simplified 2Q buffer is difficult - if the maximum size of <code>A1</code> is too small, the test for hotness becomes too strong and if it is too large then due to memory constraint <code>Am</code> will get relatively smaller memory making the primary LRU cache smaller, eventually degrading the database performance.</p>
<p>The full version 2Q algorithm remediates this limitation and eliminates tuning to a massive extent without taking any hit in performance.</p>
<h2>2Q Full Version</h2>
<p>Although Simplified 2Q algorithm does a decent job there is still scope of improvement when it comes to handling common database access pattern, that suggests, a page generally receives a lot of references for a short period of time and then no reference for a long time. If a page truly needs to be cached then after it receives a lot (not just one) of references in a short span it continues to receive references and hits on regular intervals.</p>
<p>To handle this common database access pattern, the 2Q algorithm splits the secondary buffer <code>A1</code> into two buffers <code>A1-In</code> and <code>A1-Out</code>, where the new element always enters <code>A1-In</code> and continues to stay in <code>A1-In</code> till it gets accesses ensuring that the most recent first accesses happen in the memory.</p>
<p>Once the page gets old, it gets thrown off the memory but its disk reference is stored in the <code>A1-Out</code> buffer. If the page, whose reference is, residing in <code>A1-Out</code> is accessed again the page is promoted to <code>Am</code> LRU implying it indeed is a hot page that will be accessed again and hence required to be cached.</p>
<p><img src="https://user-images.githubusercontent.com/4745789/100538168-0bb53a00-3254-11eb-8f69-ddcaf8d33a84.png" alt="https://user-images.githubusercontent.com/4745789/100538168-0bb53a00-3254-11eb-8f69-ddcaf8d33a84.png"></p>
<p>The <code>Am</code> buffer continues to be the usual LRU which means when any page residing in <code>Am</code> is accessed it is moved to the head and when a page is needed to be discarded the eviction happens from the tail end.</p>

<p>Postgres uses 2Q as its cache management algorithm due to <a href="http://www.varlena.com/GeneralBits/96.php">patent issues</a> with IBM. Postgres used to have <a href="https://en.wikipedia.org/wiki/Adaptive_replacement_cache">ARC</a> as its caching algorithm but with IBM getting a patent over it, Postgres moved to 2Q. Postgres also claims that the performance of 2Q is similar to ARC.</p>

<ul>
<li><a href="https://en.wikipedia.org/wiki/Cache_replacement_policies#Least_recently_used_(LRU)">LRU - Wikipedia</a></li>
<li><a href="http://www.varlena.com/GeneralBits/96.php">The Saga of the ARC Algorithm and Patent</a></li>
<li><a href="https://www.semanticscholar.org/paper/2Q%3A-A-Low-Overhead-High-Performance-Buffer-Johnson-Shasha/5fa357b43c8351a5d8e7124429e538ad7d687abc">2Q: A low overhead high-performance buffer management replacement algorithm</a></li>
</ul>
</div></div><div><p>
          If my work adds value, consider supporting me
        </p>  <p><a href="https://www.buymeacoffee.com/arpitbhayani" target="_blank"><img src="https://cdn.buymeacoffee.com/buttons/v2/default-yellow.png" alt="Buy Me A Coffee"></a></p> <br></div><section><div><div><p><img src="https://arpitbhayani.me/static/img/arpit.jpg"></p>  <h2>
              700+ Signups
            </h2> <p>
              If you like what you read subscribe you can always subscribe to
              my newsletter and get the post delivered straight to your inbox.
              I write
              <a href="https://arpitbhayani.me/blogs">essays</a> on various
              engineering topics and share it through my weekly
              <a href="https://arpitbhayani.me/newsletter">newsletter</a> 👇
            </p> <br> </div></div></section></div>]]>
            </description>
            <link>https://arpitbhayani.me/blogs/2q-cache</link>
            <guid isPermaLink="false">hacker-news-small-sites-25244333</guid>
            <pubDate>Sun, 29 Nov 2020 10:49:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Testing webhooks using netcat and ngrok]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25243963">thread link</a>) | @root993
<br/>
November 29, 2020 | https://www.sankalpjonna.com/posts/testing-webhooks-using-netcat-and-ngrok | <a href="https://web.archive.org/web/*/https://www.sankalpjonna.com/posts/testing-webhooks-using-netcat-and-ngrok">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><figure id="w-node-184f6be698e4-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5fc36150f7e15501838a699f_3C877AnDdlSJbqfxjZakSrkuQ6NuM0CNdqLoQvUNkeH3u3ScA-BmwT0Qbkb0NsFSDoElP6iR-iS4zhQ-QNa_cEMzBQ0XbHk6xsMTaU1EypUH-XFO7m_sywyykBR2iA_6wc4QMQHL.png" alt=""></p></figure><p>A very common challenge faced by many software products is the need for the application server to communicate with other third party application servers. To be more specific, my application server needs to be notified when a particular event takes place in a 3rd party application server.<br></p><p>For instance, I am currently building a <a href="https://www.delightchat.io/" target="_blank">customer support software</a> in which customer queries can come from various channels of communication including Facebook, Instagram and WhatsApp. This means that if someone sends a message on Facebook messenger, that message has to ultimately reach my application server in some way so I can perform the necessary operations.<br></p><p>The most common way to solve this problem is with the use of webhooks.<br></p><h3><strong>What is a webhook?</strong><br></h3><p>A webhook is nothing but an API end point that is created in your own application server which is made public and it is called by other applications to provide your application with real time updates for various events.<br></p><p>The product that I am currently building integrates with Shopify and every time somebody places an order on a merchants Shopify store, my application needs to be notified in real time so that the order can be indexed in my database and my application then has the capability to query all orders placed by a particular user.<br></p><p>To solve this, I would have to create an API end point on my server in the form of <em>/webhooks/shopify/orders/create</em> and register this URL with Shopify. Whenever Shopify receives a new order in their system, their server will fire this URL along with the order data.<br></p><h3><strong>How to inspect a webhook?</strong><br></h3><p>Since a webhook is called from a 3rd party server that is out of your control, you have no way of knowing what kind of data will be sent in the webhook unless you actually create an API, host it somewhere that is public and register the endpoint with the 3rd party software. <br></p><p>If this seems like a lot of work just to view the contents of a webhook, products like <a href="https://requestbin.com/" target="_blank">requestbin</a> and <a href="https://beeceptor.com/" target="_blank">beecepter</a> were built exactly for this purpose. You can get a free endpoint from these products and register it in the 3rd party software after which you can trigger the event you are looking for and view the contents of the request on their dashboard.<br></p><p>However I believe in simplicity and these services come with their own set of constraints. So after a little bit of research I found that the netcat utility that is installed by default In most UNIX based machines solves this problem quite elegantly.<br></p><h5>Using netcat to inspect a webhook<br></h5><p>In the most simplest form, you can set up a webhook listener with a simple terminal command<br></p><p>&lt;p&gt;CODE:&nbsp;https://gist.github.com/sankalpjonn/b0a8efaad418feeae02e4285582e2ce5.js&lt;/p&gt;<br></p><p>This command will listen for any requests coming on the port 3000 and display it on the terminal itself. Let us try it out by entering <a href="http://localhost:8000/my/webhook/path" target="_blank">http://localhost:3000/my/webhook/path</a> on the browser and see what happens.<br></p><figure id="w-node-060a8fc15179-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5fc34225f58539412e8fad89_gN3PHr5rIsoV-eU02OEnVfFRqw10WcvJV73B2eTxDnL1IanCGiOyMGuomBwxTo7LJV2QmqfyFgSYRT5cNlIIK-YsdFC3Pt8k4U_vmrVt65rlvqVDok1o44yR-_rKqVr0YGLXKV8U.png" alt=""></p><figcaption>Inspecting the contents of a http request<br></figcaption></figure><p>The output on the terminal contains the entire http request that was received by localhost:3000 including the http method, headers and content. But there are two clear problems here:<br></p><ul role="list"><li>The browser keeps waiting for a response from the netcat server which is never received, so it eventually times out.</li><li>The netcat server displays the webhook request and then shuts down after which it will no longer accept any more requests unless you re-run the command.<br></li></ul><p>Both of these problems have simple solutions. Let’s go through them in order.<br></p><h5><strong>Returning a response</strong> <br></h5><p>One can easily create a simple HTTP message and return that as the response to the requests made to this netcat server. Here is how you do it:<br></p><p>Create a file called response.txt with these contents.<br></p><p>&lt;p&gt; CODE:&nbsp;https://gist.github.com/sankalpjonn/0753a1ac3a4442eedb3c0f811740e4ec.js &lt;/p&gt;<br></p><p>Echo the contents of this file and pipe the netcat command to it.<br></p><p>&lt;p&gt; CODE:&nbsp;https://gist.github.com/sankalpjonn/5fffa3d857bab441dd85fad1061da384.js &lt;/p&gt;<br></p><p>Now upon hitting localhost:3000 on your browser, you will receive a response in the browser.</p><figure id="w-node-7c8443ed0138-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5fc342e7f19477bb7649ae48_Wxi5VFUp0fleE1u1NrVneah1s_TxVNEXXKaXw092dB-lfc3M7ljNOgoTIp0uvn8WiEZT071uf0P4vNbTQcrknLXckCJGsShTHzmMEoxUJ39O9rvCIfqbbUDtXnBSH67vAy2-X6wv.png" alt=""></p><figcaption>netcat server with response</figcaption></figure><p>‍</p><h5>Running the netcat server in a loop<br></h5><p>To prevent the netcat server from shutting down after a request is received, all we have to do is run the commands in a loop. This can be done with a small modification to the above command.</p><p>‍<br>&lt;p&gt; CODE:&nbsp;https://gist.github.com/sankalpjonn/eb8413365d91e566c66e456adffbf6c3.js &lt;/p&gt;</p><p>Now when you make a request to localhost:3000, the request content will be displayed on the terminal and a response will be sent to the client making the request but the netcat server will continue to run and accept new requests.<br></p><p>To demonstrate the fact that you can inspect any http request using this setup, let us make another request to localhost:3000 but this time use a PUT method with some query parameters, some headers and some data using cURL.</p><p>&lt;p&gt;&nbsp;CODE:&nbsp;https://gist.github.com/sankalpjonn/1468715b5fbe8c97bae095e874200cef.js &lt;/p&gt;<br></p><figure id="w-node-e056beb644f0-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5fc343941c29737cf9f65b15_hq7ITM8kEJRvb5wm5yDYvA-sno9OUgLRFw_tb3r3OKuL1PpeAfl68wPSHrhu4YTTmI79qNO_viY6rGyqoLk5c15mO5J6syZOBRCG1WUCyHs2-QHyP-a0e4KIxEpaiNsa80HJ9_TX.png" alt=""></p><figcaption>Viewing the contents of a PUT request with headers, query params and body</figcaption></figure><p>‍</p><p>Great! we can now inspect any type of webhook that is made to localhost:3000.<br></p><h3>Making your webhook public using ngrok<br></h3><p>Now that we have a fake server setup using netcat that is capable of accepting requests, displaying their content and sending back a valid response, all we need is a method to expose this server to the public internet. <br></p><p>This is because, we need to register this webhook on some third party software like Shopify and that cannot be done unless the URL is publicly accessible. <br></p><p>Fortunately, this can be done with a single command using ngrok. Ngrok is a very nifty tool that lets you expose a service running on localhost to the public internet by generating a temporary URL that is made public. You can also get a permanent URL by signing up for their paid plan.<br></p><p>After installing ngrok from <a href="https://ngrok.com/download" target="_blank">here</a> and unzipping it as shown in the description, all you have to do is run this command on a new terminal window while your netcat server is still running.</p><p>&lt;p&gt; CODE:&nbsp;https://gist.github.com/sankalpjonn/4c4018e45ed36130521bcfd63a89b0c3.js &lt;p&gt;<br></p><p>You instantly get a http and https endpoint that routes traffic from the public internet to localhost:3000. You can try it out by coping the generated URL and pasting it in your browser.<br></p><figure id="w-node-c3deabacf619-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5fc3644d77f60530b57eb061_dsKbmpkfNStyhz9XbENYJpmZrvkI76nl6XvFPiSQ_3fxKmgjrKEwbuf3rIpBySPTELVe6G8DD1Jfoe55tz9WyrIp0tXvT-z1xF1S1IZY24UbahJfeQ7W6cQMlQzkcYSUTqJv0XcT.png" alt=""></p><figcaption>get the public URL&nbsp;from here</figcaption></figure><figure id="w-node-e545581c77d3-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5fc344670af890c127167066_2yKt6iyvATWXH1MMlAHioMB_5aCTs6yjWKvas0cBdjEr01JKWQUSKVW37o9pUZY2Fw1oCYWbFm-2qhJaoU1wtefBvQ84u9cJBqNzyZTH8onY3_Lnn0h3kPKDvMP4UOS_UtmJmOoD.png" alt=""></p><figcaption>Making a request using the public URL</figcaption></figure><p>‍</p><p>And it works!<br></p><h3>Summary</h3><p>A webhook can be tested by running just two simple terminal commands on separate terminal windows. </p><p>&lt;p&gt; CODE:&nbsp;https://gist.github.com/sankalpjonn/a3f41a14f7ea1d386423fdb73193f65f.js&lt;/p&gt;</p><p>You can now test your webhooks with the public URL&nbsp;derived from ngrok and registering this URL&nbsp;in the 3rd party software that will be calling the webhook.</p><h3>Closing notes<br></h3><p>As I mentioned before, for those of you who believe that using an existing service that was built for this very purpose is better, I would highly recommend <a href="https://beeceptor.com/" target="_blank">beeceptor</a>. <br></p><p>You can view all your requests on a dashboard like this.</p><figure id="w-node-4211e4369e4b-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5fc344ae3677d6cf3746c74d_Vj0hedFYlVuj06uI7RCNsm38rnBwc4TGHw-A8ovEoPNGrysxauEJhIJq98e7Nn0oh8Wa_1WQmKRDGK7c8ib226ZWSwZYdzLrGRnfWZr_P6QWkfsaS9LI7FMEjhdOKA81aJIrkeBm.png" alt=""></p><figcaption>Beecepter dashboard</figcaption></figure><p>‍</p><p>The downside is that if you don’t want to pay for this service, the free plan has many constraints, once of which is that if you refresh this page, your previous request data is lost, so you can use this only as a one time thing.<br></p><p>The reason I like to go with the netcat + ngrok method is because the whole thing is completely in my control and it always feels good to hack something together of your own rather than use an existing service.</p></div></div>]]>
            </description>
            <link>https://www.sankalpjonna.com/posts/testing-webhooks-using-netcat-and-ngrok</link>
            <guid isPermaLink="false">hacker-news-small-sites-25243963</guid>
            <pubDate>Sun, 29 Nov 2020 09:13:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Convert Markdown to HTML with Pandoc]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25243905">thread link</a>) | @arthurk
<br/>
November 29, 2020 | https://www.arthurkoziel.com/convert-md-to-html-pandoc/ | <a href="https://web.archive.org/web/*/https://www.arthurkoziel.com/convert-md-to-html-pandoc/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        
        <time datetime="2020-11-29">November 29, 2020</time>
<p>In this post I’ll describe how to use <a href="">Pandoc</a> to convert Markdown to a full HTML page (including header/footer).</p>
<p>The Pandoc version used for the examples below is 2.11.2.</p>
<h2 id="what-is-pandoc">What is Pandoc?</h2>
<p>Pandoc is an open-source document converter that is written in Haskell. It was initially released in 2006 and has been under active development since then.</p>
<p>The goal of Pandoc is to convert a document from one markup format to another. It distinguishes between input formats and output formats. As of writing this it supports <a href="https://pandoc.org/MANUAL.html#input-formats">38 input formats</a> and <a href="https://pandoc.org/MANUAL.html#output-formats">59 output formats</a>.</p>
<p>In this post we’ll use Markdown as an input format and HTML as an output format.</p>
<h2 id="preparing-the-html-template">Preparing the HTML template</h2>
<p>To generate a full HTML page we have to use Pandoc’s standalone mode which will use a <a href="https://pandoc.org/MANUAL.html#templates">template</a> to add header and footer.</p>
<p>Pandoc ships with a default template, if you wish to use that skip this section and omit the <code>--template</code> argument.</p>
<p>The template we’ll use is this (save it to <code>template.html</code>):</p>
<pre><code>&lt;!doctype html&gt;
&lt;html lang="en"&gt;
  &lt;head&gt;
    &lt;meta charset="utf-8"&gt;
    &lt;meta name="date" content='$date-meta$'&gt;
    &lt;title&gt;$title$&lt;/title&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;p&gt;Date: $date$&lt;/p&gt;
$body$
  &lt;/body&gt;
&lt;/html&gt;</code></pre>
<p>Pandoc’s template variables can have <a href="https://pandoc.org/MANUAL.html#interpolated-variables">different formats</a>, the one we’re using here start and end with a dollar sign:</p>
<ul>
<li><code>$date$</code>: A date in a parsable format. See the <a href="https://pandoc.org/MANUAL.html#variables-set-automatically">date-meta docs</a> for a list of recognized formats for the <code>date</code> variable. We use this to show when the document was created</li>
<li><code>$date-meta$</code>: The <code>date</code> parsed to ISO 8601 format. This is automatically done</li>
<li><code>$title$</code>: The document title</li>
<li><code>$body$</code>: The document body in HTML (the converted Markdown)</li>
</ul>
<p>We only need to set the <code>date</code> and <code>title</code> in the Markdown document via a metadata block.</p>
<h2 id="writing-the-markdown-file">Writing the Markdown file</h2>
<p>Create a Markdown file <code>doc.md</code> with the following content:</p>
<pre><code>---
title: My Document
date: September 22, 2020
---

## Test
some text</code></pre>
<p>The beginning of the document is the metadata block with required <code>date</code> and <code>title</code> variables mentioned above.</p>
<p>Several Markdown variants are <a href="https://pandoc.org/MANUAL.html#Markdown-variants">supported</a> such as GitHub-Flavored markdown. This example uses <a href="https://pandoc.org/MANUAL.html#pandocs-markdown">Pandoc’s extended markdown</a> which is the default input for files with the <code>md</code> extension.</p>
<h2 id="converting-the-document">Converting the document</h2>
<p>Run the following command to generate the HTML page:</p>
<pre><code>pandoc --standalone --template template.html doc.md</code></pre>
<p>Pandoc will try to guess the input format from the file extension (<code>.md</code> will use the Markdown input format) and output it to HTML (the default output format).</p>
<p>The output will be printed to the terminal:</p>
<pre><code>&lt;!doctype html&gt;
&lt;html lang="en"&gt;
  &lt;head&gt;
    &lt;meta charset="utf-8"&gt;
    &lt;meta name="date" content='2020-09-22'&gt;
    &lt;title&gt;My Document&lt;/title&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;p&gt;Date: September 22, 2020&lt;/p&gt;
&lt;h2 id="test"&gt;Test&lt;/h2&gt;
&lt;p&gt;some text&lt;/p&gt;
  &lt;/body&gt;
&lt;/html&gt;</code></pre>
<p>To save the document to a file we can either redirect stdout or use the <code>-o</code> argument:</p>
<pre><code>pandoc --standalone --template template.html doc.md -o doc.html</code></pre>
<h2 id="conclusion">Conclusion</h2>
<p>In this example we’ve converted Markdown to a standalone HTML page that is using a custom template.</p>
<p>This was just a simple example of what Pandoc is capable to do. The standalone mode coupled with the bundled default templates makes it easy to generate a wide variety of outputs such as HTML presentations, Jupyter notebooks or PDF documents.</p>
    </article></div>]]>
            </description>
            <link>https://www.arthurkoziel.com/convert-md-to-html-pandoc/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25243905</guid>
            <pubDate>Sun, 29 Nov 2020 08:55:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Flat is not the opposite of skeuomorphic (2013)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25243240">thread link</a>) | @panic
<br/>
November 28, 2020 | https://interuserface.net/2013/05/flat-is-not-the-opposite-of-skeuomorphic/ | <a href="https://web.archive.org/web/*/https://interuserface.net/2013/05/flat-is-not-the-opposite-of-skeuomorphic/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
          <!-- <style>
        body.single {
          background-color: #;
        }
      </style> -->
      <h3>May 31, 2013</h3>
      
      
      <p><img loading="lazy" alt="Skeuo-flat-ic design" src="http://interuserface.net/wp-content/uploads/2013/05/skeuflat.jpg" width="1279" height="461" srcset="https://interuserface.net/wp-content/uploads/2013/05/skeuflat.jpg 1279w, https://interuserface.net/wp-content/uploads/2013/05/skeuflat-300x108.jpg 300w, https://interuserface.net/wp-content/uploads/2013/05/skeuflat-554x200.jpg 554w" sizes="(max-width: 1279px) 100vw, 1279px"></p>
<p>I don’t remember exactly where I first encountered it. But at some point in the past three years, I, along with a large contingent of user interface designers, fans, and industry followers, learned a new word: Skeuomorphic. A skeuomorph in the UI world, so the popular definition goes (even if the rigorous scientific definition of the word <a href="http://www.themachinestarts.com/read/2012-11-how-we-started-calling-visual-metaphors-skeuomorphs-why-apple-design-debate-mess">makes “skeuomorphic design” an oxymoron</a>) is&nbsp;a GUI or elements of a GUI that borrow from a physical analog of their functionality. It seemed like a useful concept in defining the execution of user interfaces, with an added benefit of sounding exotic in conversation – but I think we may have outgrown it.</p>
<h3>Everyone loves a feud</h3>
<p>Somewhere along the way, this newly-popularized concept gained that one thing critical to capturing our collective imagination: a foil. Where skeuomorphism was tied to the familiar, the tactile, the rich, the warm, this dark horse was divorced of the familiar, lived in platonic ideals, was simple, cold, mathematic. Despite drawing most of its theory from the 20th Century’s signature design movement, <a href="http://www.citrinitas.com/history_of_viscom/modernists.html">Modernism</a>, it was nonetheless given its own, rather less impressive (and more prescriptive) name, “<a href="http://designmodo.com/flat-design-principles/">flat design</a>.”</p>
<p>As the story goes, each of these poles had its champion, with Apple raising the varnished-oak banner of its increasingly unified mobile and desktop design language, and Microsoft carrying the solid, rectilinear flag of what was briefly but indelibly called its Metro design language. A war was brewing in the UI design world between flat and skeu: Apple’s <a href="http://techcrunch.com/2013/05/24/jony-ives-ios-7-flat-design-overhaul-reportedly-features-a-lot-of-black-and-white/">rumored “move to flat”</a> would stir more design-office conversation than a betrayal in Game of Thrones.</p>
<h3>Not so flat</h3>
<p>There is a problem with this narrative. Much of the interaction that users have with iOS devices is with UI elements having no physical analogs apart from the most basic, localized physical metaphor, the button – most of these are even just <a href="http://i.imgur.com/kIFUHwM.png">black Helvetica on a white background</a>. And for all of Microsoft’s eschewing of texture, shading, and object references, one cannot escape that its many boxes and encircled icons ultimately draw affordance from our associations with a physical object, the humble pushbutton.</p>
<p>So if much of iOS is “flat,” and Windows Phone is loaded with a thousand tiny skeuomorphs, what are we left with? An important realization: “Flat design” is not nearly as flat as it looks. Skeuomorphism is a critical part of interaction design, and is everywhere.</p>
<p>How, then, do we verbalize the many clear differences between the examples of iOS and Windows Phone? The answer is to build a more nuanced framework than “flat” versus “skeuomorphism.”</p>
<h3>Building a more useful vocabulary</h3>
<p>Instead of imagining a fun-to-follow, yet ultimately empty battle between the forces of skeuomorphism and flat design, a more productive pursuit would be to construct a vocabulary around the toolset these concepts offer. Here are a few tools I see:</p>
<h4>Functional object reference (“skeuomorphism”)</h4>
<div id="attachment_413"><p><img aria-describedby="caption-attachment-413" loading="lazy" alt="object" src="http://interuserface.net/wp-content/uploads/2013/05/object.jpg" width="768" height="215" srcset="https://interuserface.net/wp-content/uploads/2013/05/object.jpg 768w, https://interuserface.net/wp-content/uploads/2013/05/object-300x83.jpg 300w, https://interuserface.net/wp-content/uploads/2013/05/object-614x171.jpg 614w" sizes="(max-width: 768px) 100vw, 768px"></p><p id="caption-attachment-413">Propellerhead Reason, Apple Calendar, Microsoft Windows Phone 8 dialer</p></div>
<p>This is the sort of visual metaphor that ties an object from the physical world to a virtual tool. Ideally it is for purposes of building affordance from familiarity (turning pages in iBooks), but it can easily be misused (non-functional pages in iOS Address Book). Regardless of how realistically it’s rendered, a physical object can be useful as a reference so long as it is recognizable by the user and responds in the same way.</p>
<h4>Material/texture reference</h4>
<div id="attachment_414"><p><img aria-describedby="caption-attachment-414" loading="lazy" alt="texture" src="http://interuserface.net/wp-content/uploads/2013/05/texture.jpg" width="768" height="215" srcset="https://interuserface.net/wp-content/uploads/2013/05/texture.jpg 768w, https://interuserface.net/wp-content/uploads/2013/05/texture-300x83.jpg 300w, https://interuserface.net/wp-content/uploads/2013/05/texture-614x171.jpg 614w" sizes="(max-width: 768px) 100vw, 768px"></p><p id="caption-attachment-414">Apple Game Center, Quantum WordPress theme from Themesorter, artist’s rendition of 1990s CD-ROM menu</p></div>
<p>The difference between this (which you may call skeuomorphism as well; I won’t stop you) and the previous example is that the metaphor is implicit, if present at all. Ideally, there is some implied metaphor: Apple’s Game Center may not actually play backgammon, but its material references to a vintage board game case can put the user’s mind in a conceptual space for gaming. Often, this tool is simply used for decoration, but tasteful decoration can still aid user experience.</p>
<h4>Depth cues</h4>
<div id="attachment_415"><p><img aria-describedby="caption-attachment-415" loading="lazy" alt="depth" src="http://interuserface.net/wp-content/uploads/2013/05/depth.jpg" width="768" height="215" srcset="https://interuserface.net/wp-content/uploads/2013/05/depth.jpg 768w, https://interuserface.net/wp-content/uploads/2013/05/depth-300x83.jpg 300w, https://interuserface.net/wp-content/uploads/2013/05/depth-614x171.jpg 614w" sizes="(max-width: 768px) 100vw, 768px"></p><p id="caption-attachment-415">Apple Notification Center settings, Apple Maps, GitHub for Mac</p></div>
<p>Whereas the previous two tools always use concrete references, depth cues may or may not have such a clear analog. Their primary purpose is to imply what can be done if the user interacts with the controls they adorn, not referencing real objects themselves, but rather mechanical aspects of them.</p>
<h4>Shape / color cues</h4>
<div id="attachment_428"><p><img aria-describedby="caption-attachment-428" loading="lazy" alt="Calvetica settings, Android lock screen, Solve for iOS" src="http://interuserface.net/wp-content/uploads/2013/05/color-shape1.jpg" width="768" height="215" srcset="https://interuserface.net/wp-content/uploads/2013/05/color-shape1.jpg 768w, https://interuserface.net/wp-content/uploads/2013/05/color-shape1-300x83.jpg 300w, https://interuserface.net/wp-content/uploads/2013/05/color-shape1-614x171.jpg 614w" sizes="(max-width: 768px) 100vw, 768px"></p><p id="caption-attachment-428">Calvetica settings, Android lock screen, Solve for iOS</p></div>
<p>Contrasts in shape and color are often used in conjunction with depth cues to further increase contrast and create visual hierarchy. The trend of “flat design” is to use them with minimal application of the other aforementioned tools, which can be successful so long as the application of shape and color contrasts are sufficient to create an affordance of user action.</p>
<h3>Addition and subtraction</h3>
<p>My current one-liner for when the subject comes up is <a href="https://twitter.com/claymill/status/328995618523578371">“‘flat design’ is approximately as useful a term for user interfaces as ‘red design’ or ’round design.'”</a> Far from being a shot at the popular aesthetic of relying heavily on it, though, it’s meant to provoke thought: Flatness and depth are tools, just like color and shape, affordances and analogs.</p>
<p>Don’t just practice flat design or skeuomorphic design. Use the tools that are right for the interface that’s right for your users.</p>
      <!-- <p class="metadata">
        Clayton Miller&ensp;&bull;&ensp;      </p> -->
      </article></div>]]>
            </description>
            <link>https://interuserface.net/2013/05/flat-is-not-the-opposite-of-skeuomorphic/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25243240</guid>
            <pubDate>Sun, 29 Nov 2020 05:59:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A better Kubernetes from the ground up]]>
            </title>
            <description>
<![CDATA[
Score 249 | Comments 147 (<a href="https://news.ycombinator.com/item?id=25243159">thread link</a>) | @mr-karan
<br/>
November 28, 2020 | https://blog.dave.tf/post/new-kubernetes/ | <a href="https://web.archive.org/web/*/https://blog.dave.tf/post/new-kubernetes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<div>
		<p><span>Written by</span>
        David Anderson
        <br>
        <span>on&nbsp;</span><time datetime="2020-11-28 00:00:00 +0000 UTC">November 28, 2020</time>
</p>
		


		

		<p>Recently I had a chat with the excellent <a href="https://timewitch.net/">Vallery Lancey</a>, about Kubernetes. Specifically, what we would do differently if we built something new, from the ground up, with no regard for compatibility with Kubernetes. I found that conversation so stimulating that I feel the need to write things down, so here we are.</p>

<p>Before we get started, I want to stress a few things.</p>

<ul>
<li>This is not a fully formed design. Some of these things may not work at all, or require significant redesign. Each section is one random piece of the entire puzzle.</li>
<li>These are not solely my ideas. Some I <em>think</em> are original, but like many things in the Kubernetes community it’s the product of collective thinking. I know at least <a href="https://timewitch.net/">Vallery</a> and <a href="https://twitter.com/maisem_ali">Maisem Ali</a> have influenced my thinking at one time or another, and I’m forgetting many more. If you like an idea, it was a group effort. If you hate it, it’s entirely mine.</li>
<li>Some of these things are polarizing. I’m designing something that makes <em>me</em> happy.</li>
</ul>

<h2 id="guiding-principles">Guiding principles</h2>

<p>My experience of Kubernetes comes from two very different places: authoring <a href="https://www.metallb.org/">MetalLB</a> for bare metal clusters, and operating a large fleet of clusters-as-a-service in <a href="https://cloud.google.com/kubernetes-engine">GKE SRE</a>. Both of these taught me that Kubernetes is extremely complex, and that most people who are trying to use it are not prepared for the sheer amount of work that lies between the marketing brochure and the system those brochures promise.</p>

<p>MetalLB taught me that it’s not possible to build robust software that integrates with Kubernetes. I think MetalLB makes a damn good go of it, but Kubernetes still makes it far too easy to construct broken configurations, and far too hard to debug them. GKE SRE taught me that even the foremost Kubernetes experts cannot safely operate Kubernetes at scale. (Although GKE SRE does a spectacular job with the tools they’re given.)</p>

<p>Kubernetes is the C++ of orchestration software. Immensely powerful, includes all the features, looks deceptively simple, and <em>will</em> hurt you repeatedly until you join its priesthood and devote your life to its mysteries. And even then, the matrix of possible ways to configure and deploy it is so large that you’re never on firm footing.</p>

<p>Continuing that analogy, my guide star is Go. If Kubernetes is C++, what would the Go of orchestration systems look like? Aggressively simple, opinionated, grown slowly and warily, and you can learn it in under a week and get on with what you were actually trying to accomplish.</p>

<p>With that, let’s get going. Starting with Kubernetes, and with a license to completely and utterly break compatibility, what would I do?</p>

<h2 id="mutable-pods">Mutable pods</h2>

<p>In Kubernetes, pods are mostly (but not entirely) immutable after creation. If you want to change a pod, you don’t. Make a new one and delete the old one. This is unlike most other things in Kubernetes, which are mostly mutable and gracefully reconcile towards the new spec.</p>

<p>So, I’m going to make pods be not special. Make them entirely read-write, and reconcile them like you would any other object.</p>

<p>The immediately useful thing I get from that is in-place restarts. If scheduling constraints and resource allocations haven’t changed, guess what? SIGTERM runc, restart runc with different parameters, and you’re done. Now pods look like regular old systemd services, that can move between machines <em>if necessary</em>.</p>

<p>Note that this doesn’t require doing mutability at the runtime layer. If you change a pod definition, it’s still mostly fine to terminate the container and restart it with a new configuration. The pod is still holding onto the resource reservation that got it scheduled onto this machine, so conceptually it’s equivalent to <code>systemctl restart blah.service</code>. You could try to be fancy and make some operations actually update in place at the runtime level as well, but don’t have to. The main benefit is decoupling scheduling, pod lifetime, and lifetime at the runtime layer.</p>

<h2 id="version-control-all-the-things">Version control all the things</h2>

<p>Sticking at the pod layer for a bit longer: now that they’re mutable, the next obvious thing I want is rollbacks. For that, let’s keep old versions of pod definitions around, and make it trivial to “go back to version N”.</p>

<p>Now, a pod update looks like: write an updated definition of the pod, and it updates to match. Update broken? Write back version N-1, and you’re done.</p>

<p>Bonus things you get from this: a diffable history of what happened to your cluster, without needing GitOps nonsense. By all means keep the GitOps nonsense if you want, it has benefits, but you can answer a basic “what changed?” question using only data in the cluster.</p>

<p>This needs a bit more design. In particular, I want to separate out external changes (human submits a new pod) from mechanical changes (some internals of k8s alter a pod definition). I haven’t thought through how to encode both those histories and make both accessible to operators and automation. Maybe it could also be completely generic, wherein a “changer” identifies itself when submitting a new version, and you can then query for changes by or excluding particular changers (think similar to how label queries work at the minute). Again, more design needed there, I just know that I want versioned objects with an accessible history.</p>

<p>We’ll need garbage collection eventually. That said, changes to single pods should delta-compress really well, so my default would be to just keep everything until it becomes a truly dumb amount of data, and figure something out at that point. Keeping everything also acts as a useful mild pressure to avoid “death by a thousand changes” in the rest of the system. Prefer to have fewer, more meaningful changes over a flurry of control loops each changing one field in pursuit of convergence.</p>

<p>Once we have this history, we can do some neat minor things too. For example, the node software could keep container images for the last N versions pinned to the machine, so that rollbacks are as fast as they can possibly be. With an accessible history, you can do this more precisely than “GC older than 30 days and hope”. Generalizing, all the orchestration software can use older versions as GC roots for various resources, to make rollbacks faster. Rollbacks being the primary way of ending outages, this is a very valuable thing to have.</p>

<h2 id="replace-deployment-with-pinneddeployment">Replace Deployment with PinnedDeployment</h2>

<p>This is a short section to basically say that <a href="https://timewitch.net/">Vallery</a> knocked it out of the park with her <a href="https://timewitch.net/post/2019-12-30-pinneddeployments/">PinnedDeployment</a> resource, which lets operators explicitly control a rollout by tracking 2 versions of the deployment state. It’s a deployment object designed by an SRE, with a crisp understanding of what SREs want in a deployment. I love it.</p>

<p>This combines super well with the versioned, in-place pod updates above, and I really don’t have anything to add. It’s clearly how multi-pod things should work. There’s probably some tweaking required to adapt from the Kubernetes-constrained world to this new wonderful unconstrained universe, but the general design is perfect.</p>

<h2 id="explicit-orchestration-workflows">Explicit orchestration workflows</h2>

<p>The biggest issue I have with the “API machinery” bits of Kubernetes is the idea of orchestration as a loose choreography of independent control loops. On the surface, this seems like a nice idea: you have dozens of little control loops, each focused on doing one small thing. When combined in a cluster, they indirectly cooperate with each other to push the state forward and converge on the desired end state. So, what’s the problem?</p>

<p>The problem is that it’s entirely impossible to debug when it goes wrong. A typical failure mode in Kubernetes is that you submit a change to the cluster, then repeatedly refresh waiting for stuff to converge. When it doesn’t… Well, you’re screwed. Kubernetes doesn’t know the difference between “the system has converged successfully” and “a control loop is wedged and is blocking everything else.” You can hope that the offending control loop posted some events to the object to help you, but by and large they don’t.</p>

<p>At which point your only option is to cat the logs of every control loop that might be involved, looking for the one that was wedged. You can make this a bit faster if you have intimate knowledge of all the control loops and what each one does, because that lets you infer from the object’s current state which loop might be trying to run right now.</p>

<p>The key thing to notice here is that the complexity has been shifted from the designer of the control loop to the cluster operator. It’s easy (though not trivial) to make a control loop that does a dinky little thing in isolation. But to operate a cluster with dozens of these control loops requires the operator to assimilate the behavior of all of them, their interactions with each other, and try to reason about an extremely loosely coupled system. This is a problem because you have to write and test the control loop once, but work with it and its bugs many more times. And yet, the bias is to simplify the thing you only do once.</p>

<p>To fix this, I would look to systemd. It solves for a similar lifecycle problem: given a current state and a target, how do you get from A to B? The difference is that in systemd, the steps and their dependencies are made explicit. You <em>tell</em> systemd that your unit is a required part of <code>multi-user.target</code> (aka “normally-booted happy system”), that it must run after filesystems have been mounted, but before networking it brought up, and so forth. You can also depend on other concrete parts of the system, for example to say that your thing needs to run whenever sshd is running (sounds like a sidecar, right?).</p>

<p>The net result of this is that systemd can tell you precisely what piece of the system malfunctioned, or is still working on its thing, or failed a precondition. It can also print you a graph of the system’s boot process, and analyze it for things like “what’s the long pole of bootup?”</p>

<p>I want to steal all this wholesale, and plop it into my cluster orchestration …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.dave.tf/post/new-kubernetes/">https://blog.dave.tf/post/new-kubernetes/</a></em></p>]]>
            </description>
            <link>https://blog.dave.tf/post/new-kubernetes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25243159</guid>
            <pubDate>Sun, 29 Nov 2020 05:35:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Futures Explained in 200 Lines of Rust]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25242849">thread link</a>) | @rustshellscript
<br/>
November 28, 2020 | https://cfsamson.github.io/books-futures-explained/introduction.html | <a href="https://web.archive.org/web/*/https://cfsamson.github.io/books-futures-explained/introduction.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
        <!-- Provide site root to javascript -->
        

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        

        <!-- Set the theme before any content is loaded, prevents flash -->
        

        <!-- Hide / unhide sidebar before it is displayed -->
        

        <nav id="sidebar" aria-label="Table of contents">
            
            
        </nav>

        <div id="page-wrapper">

            <div class="page">
                
                
                

                
                
                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                

                <div id="content">
                    <main>
                        
<p>This book aims to explain Futures in Rust using an example driven approach,
exploring why they're designed the way they are, and how they work. We'll also
take a look at some of the alternatives we have when dealing with concurrency
in programming.</p>
<p>Going into the level of detail I do in this book is not needed to use futures
or async/await in Rust. It's for the curious out there that want to know <em>how</em>
it all works.</p>
<h2><a href="#what-this-book-covers" id="what-this-book-covers">What this book covers</a></h2>
<p>This book will try to explain everything you might wonder about up until the
topic of different types of executors and runtimes. We'll just implement a very
simple runtime in this book introducing some concepts but it's enough to get
started.</p>
<p><a href="https://github.com/stjepang">Stjepan Glavina</a> has made an excellent series of
articles about async runtimes and executors, and if the rumors are right there
is more to come from him in the near future.</p>
<p>The way you should go about it is to read this book first, then continue
reading the <a href="https://stjepang.github.io/">articles from stejpang</a> to learn more
about runtimes and how they work, especially:</p>
<ol>
<li><a href="https://stjepang.github.io/2020/01/25/build-your-own-block-on.html">Build your own block_on()</a></li>
<li><a href="https://stjepang.github.io/2020/01/31/build-your-own-executor.html">Build your own executor</a></li>
</ol>
<p>I've limited myself to a 200 line main example (hence the title) to limit the
scope and introduce an example that can easily be explored further.</p>
<p>However, there is a lot to digest and it's not what I would call easy, but we'll
take everything step by step so get a cup of tea and relax.</p>
<p>I hope you enjoy the ride.</p>
<blockquote>
<p>This book is developed in the open, and contributions are welcome. You'll find
<a href="https://github.com/cfsamson/books-futures-explained">the repository for the book itself here</a>. The final example which
you can clone, fork or copy <a href="https://github.com/cfsamson/examples-futures">can be found here</a>. Any suggestions
or improvements can be filed as a PR or in the issue tracker for the book.</p>
<p>As always, all kinds of feedback is welcome.</p>
</blockquote>
<h2><a href="#reader-exercises-and-further-reading" id="reader-exercises-and-further-reading">Reader exercises and further reading</a></h2>
<p>In the last <a href="https://cfsamson.github.io/books-futures-explained/conclusion.html">chapter</a> I've taken the liberty to suggest some
small exercises if you want to explore a little further.</p>
<p>This book is also the fourth book I have written about concurrent programming
in Rust. If you like it, you might want to check out the others as well:</p>
<ul>
<li><a href="https://cfsamson.gitbook.io/green-threads-explained-in-200-lines-of-rust/">Green Threads Explained in 200 lines of rust</a></li>
<li><a href="https://cfsamson.github.io/book-exploring-async-basics/">The Node Experiment - Exploring Async Basics with Rust</a></li>
<li><a href="https://cfsamsonbooks.gitbook.io/epoll-kqueue-iocp-explained/">Epoll, Kqueue and IOCP Explained with Rust</a></li>
</ul>
<h2><a href="#credits-and-thanks" id="credits-and-thanks">Credits and thanks</a></h2>
<p>I'd like to take this chance to thank the people behind <code>mio</code>, <code>tokio</code>,
<code>async_std</code>, <code>futures</code>, <code>libc</code>, <code>crossbeam</code> which underpins so much of the
async ecosystem and and rarely gets enough praise in my eyes.</p>
<p>A special thanks to <a href="https://twitter.com/jonhoo">jonhoo</a> who was kind enough to
give me some valuable feedback on a very early draft of this book. He has not
read the finished product, but a big thanks is definitely due.</p>
<h2><a href="#translations" id="translations">Translations</a></h2>
<p><a href="https://stevenbai.top/rust/futures_explained_in_200_lines_of_rust/">This book has been translated to Chinese</a> by <a href="https://github.com/nkbai">nkbai</a>.</p>

                    </main>

                    <nav aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        

                        
                            <a rel="next" href="https://cfsamson.github.io/books-futures-explained/0_background_information.html" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i></i>
                            </a>
                        

                        
                    </nav>
                </div>
            </div>

            <nav aria-label="Page navigation">
                

                
                    <a rel="next" href="https://cfsamson.github.io/books-futures-explained/0_background_information.html" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i></i>
                    </a>
                
            </nav>

        </div>

        

        
        <!-- Google Analytics Tag -->
        
        

        
        
        

        
        
        

        
        
        
        
        
        
        

        
        
        
        
        

        
        
        

        <!-- Custom JS scripts -->
        

        

    

</div>]]>
            </description>
            <link>https://cfsamson.github.io/books-futures-explained/introduction.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25242849</guid>
            <pubDate>Sun, 29 Nov 2020 04:06:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PyTorch Static Quantization]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25242804">thread link</a>) | @keyboardman
<br/>
November 28, 2020 | https://leimao.github.io/blog/PyTorch-Static-Quantization/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/blog/PyTorch-Static-Quantization/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>Static quantization quantizes the weights and activations of the model. It allows the user to fuse activations into preceding layers where possible. Unlike <a href="https://leimao.github.io/blog/PyTorch-Dynamic-Quantization/">dynamic quantization</a>, where the scales and zero points were collected during inference, the scales and zero points for static quantization were determined prior to inference using a representative dataset. Therefore, static quantization is theoretically faster than dynamic quantization while the model size and memory bandwidth consumptions remain to be the same. Therefore, statically quantized models are more favorable for inference than dynamic quantization models.</p>



<p>In this blog post, I would like to show how to use PyTorch to do static quantizations. More details about the mathematical foundations of quantization for neural networks could be found in my article <a href="https://leimao.github.io/article/Neural-Networks-Quantization/">“Quantization for Neural Networks”</a>.</p>

<h3 id="pytorch-static-quantization">PyTorch Static Quantization</h3>

<p>Unlike TensorFlow 2.3.0 which supports integer quantization using arbitrary bitwidth from 2 to 16, PyTorch 1.7.0 only supports 8-bit integer quantization. The workflow could be as easy as loading a pre-trained floating point model and apply a static quantization wrapper. However, without doing layer fusion, sometimes such kind of easy manipulation would not result in good model performances.</p>



<p>In this case, I would like to use the ResNet18 from <a href="https://pytorch.org/docs/stable/torchvision/models.html">TorchVision models</a> as an example. I will do post-training quantization with and without layer fusion and compare their performances. The source code could also be downloaded from <a href="https://github.com/leimao/PyTorch-Static-Quantization">GitHub</a>.</p>



<p>Because ResNet has skip connections addition and this addition in the TorchVision implementation uses <code>+</code>. We would have to replace this <code>+</code> (<code>torch.add</code> equivalence) with <a href="https://pytorch.org/docs/1.7.0/torch.nn.quantized.html?highlight=floatfunctional#torch.nn.quantized.FloatFunctional"><code>FloatFunctional.add</code></a> (<code>torch.add</code> + <code>torch.nn.Identity</code> equivalence) in the model definition. This is because <code>torch.nn.Identity</code> serves as a flag for activation quantization. Without it, there will be no activation quantization for skip connection additions, resulting in erroneous quantization calibration.</p>



<p>In addition, we would like to test layer fusions, such as fusing <code>Conv2D</code>, <code>BatchNorm</code>, and <code>ReLU</code>. To do layer fusion, the <code>torch.nn.Module</code> name could not overlap. Otherwise it will cause erroneous quantization calibration. For example, in ordinary FP32 model, we could define one parameter-free <code>relu = torch.nn.ReLU()</code> and reuse this <code>relu</code> module everywhere. However, if we want to fuse some specific <code>ReLU</code>s, the <code>ReLU</code> modules have to be explicitly separated. So in this case, we will have to define <code>relu1 = torch.nn.ReLU()</code>, <code>relu2 = torch.nn.ReLU()</code>, etc. Sometimes, layer fusion is compulsory, since there are no quantized layer implementations corresponding to some floating point layers, such as <code>BatchNorm</code>.</p>



<p>Taken together, the modified ResNet module definition <code>resnet.py</code> is as follows.</p>

<div><div><pre><code><span># resnet.py
# Modified from
# https://github.com/pytorch/vision/blob/release/0.8.0/torchvision/models/resnet.py
</span>
<span>import</span> <span>torch</span>
<span>from</span> <span>torch</span> <span>import</span> <span>Tensor</span>
<span>import</span> <span>torch.nn</span> <span>as</span> <span>nn</span>
<span>from</span> <span>torchvision.models.utils</span> <span>import</span> <span>load_state_dict_from_url</span>
<span>from</span> <span>typing</span> <span>import</span> <span>Type</span><span>,</span> <span>Any</span><span>,</span> <span>Callable</span><span>,</span> <span>Union</span><span>,</span> <span>List</span><span>,</span> <span>Optional</span>


<span>__all__</span> <span>=</span> <span>[</span><span>'ResNet'</span><span>,</span> <span>'resnet18'</span><span>,</span> <span>'resnet34'</span><span>,</span> <span>'resnet50'</span><span>,</span> <span>'resnet101'</span><span>,</span>
           <span>'resnet152'</span><span>,</span> <span>'resnext50_32x4d'</span><span>,</span> <span>'resnext101_32x8d'</span><span>,</span>
           <span>'wide_resnet50_2'</span><span>,</span> <span>'wide_resnet101_2'</span><span>]</span>


<span>model_urls</span> <span>=</span> <span>{</span>
    <span>'resnet18'</span><span>:</span> <span>'https://download.pytorch.org/models/resnet18-5c106cde.pth'</span><span>,</span>
    <span>'resnet34'</span><span>:</span> <span>'https://download.pytorch.org/models/resnet34-333f7ec4.pth'</span><span>,</span>
    <span>'resnet50'</span><span>:</span> <span>'https://download.pytorch.org/models/resnet50-19c8e357.pth'</span><span>,</span>
    <span>'resnet101'</span><span>:</span> <span>'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth'</span><span>,</span>
    <span>'resnet152'</span><span>:</span> <span>'https://download.pytorch.org/models/resnet152-b121ed2d.pth'</span><span>,</span>
    <span>'resnext50_32x4d'</span><span>:</span> <span>'https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth'</span><span>,</span>
    <span>'resnext101_32x8d'</span><span>:</span> <span>'https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth'</span><span>,</span>
    <span>'wide_resnet50_2'</span><span>:</span> <span>'https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth'</span><span>,</span>
    <span>'wide_resnet101_2'</span><span>:</span> <span>'https://download.pytorch.org/models/wide_resnet101_2-32ee1156.pth'</span><span>,</span>
<span>}</span>


<span>def</span> <span>conv3x3</span><span>(</span><span>in_planes</span><span>:</span> <span>int</span><span>,</span> <span>out_planes</span><span>:</span> <span>int</span><span>,</span> <span>stride</span><span>:</span> <span>int</span> <span>=</span> <span>1</span><span>,</span> <span>groups</span><span>:</span> <span>int</span> <span>=</span> <span>1</span><span>,</span> <span>dilation</span><span>:</span> <span>int</span> <span>=</span> <span>1</span><span>)</span> <span>-&gt;</span> <span>nn</span><span>.</span><span>Conv2d</span><span>:</span>
    <span>"""3x3 convolution with padding"""</span>
    <span>return</span> <span>nn</span><span>.</span><span>Conv2d</span><span>(</span><span>in_planes</span><span>,</span> <span>out_planes</span><span>,</span> <span>kernel_size</span><span>=</span><span>3</span><span>,</span> <span>stride</span><span>=</span><span>stride</span><span>,</span>
                     <span>padding</span><span>=</span><span>dilation</span><span>,</span> <span>groups</span><span>=</span><span>groups</span><span>,</span> <span>bias</span><span>=</span><span>False</span><span>,</span> <span>dilation</span><span>=</span><span>dilation</span><span>)</span>


<span>def</span> <span>conv1x1</span><span>(</span><span>in_planes</span><span>:</span> <span>int</span><span>,</span> <span>out_planes</span><span>:</span> <span>int</span><span>,</span> <span>stride</span><span>:</span> <span>int</span> <span>=</span> <span>1</span><span>)</span> <span>-&gt;</span> <span>nn</span><span>.</span><span>Conv2d</span><span>:</span>
    <span>"""1x1 convolution"""</span>
    <span>return</span> <span>nn</span><span>.</span><span>Conv2d</span><span>(</span><span>in_planes</span><span>,</span> <span>out_planes</span><span>,</span> <span>kernel_size</span><span>=</span><span>1</span><span>,</span> <span>stride</span><span>=</span><span>stride</span><span>,</span> <span>bias</span><span>=</span><span>False</span><span>)</span>


<span>class</span> <span>BasicBlock</span><span>(</span><span>nn</span><span>.</span><span>Module</span><span>):</span>
    <span>expansion</span><span>:</span> <span>int</span> <span>=</span> <span>1</span>

    <span>def</span> <span>__init__</span><span>(</span>
        <span>self</span><span>,</span>
        <span>inplanes</span><span>:</span> <span>int</span><span>,</span>
        <span>planes</span><span>:</span> <span>int</span><span>,</span>
        <span>stride</span><span>:</span> <span>int</span> <span>=</span> <span>1</span><span>,</span>
        <span>downsample</span><span>:</span> <span>Optional</span><span>[</span><span>nn</span><span>.</span><span>Module</span><span>]</span> <span>=</span> <span>None</span><span>,</span>
        <span>groups</span><span>:</span> <span>int</span> <span>=</span> <span>1</span><span>,</span>
        <span>base_width</span><span>:</span> <span>int</span> <span>=</span> <span>64</span><span>,</span>
        <span>dilation</span><span>:</span> <span>int</span> <span>=</span> <span>1</span><span>,</span>
        <span>norm_layer</span><span>:</span> <span>Optional</span><span>[</span><span>Callable</span><span>[...,</span> <span>nn</span><span>.</span><span>Module</span><span>]]</span> <span>=</span> <span>None</span>
    <span>)</span> <span>-&gt;</span> <span>None</span><span>:</span>
        <span>super</span><span>(</span><span>BasicBlock</span><span>,</span> <span>self</span><span>).</span><span>__init__</span><span>()</span>
        <span>if</span> <span>norm_layer</span> <span>is</span> <span>None</span><span>:</span>
            <span>norm_layer</span> <span>=</span> <span>nn</span><span>.</span><span>BatchNorm2d</span>
        <span>if</span> <span>groups</span> <span>!=</span> <span>1</span> <span>or</span> <span>base_width</span> <span>!=</span> <span>64</span><span>:</span>
            <span>raise</span> <span>ValueError</span><span>(</span><span>'BasicBlock only supports groups=1 and base_width=64'</span><span>)</span>
        <span>if</span> <span>dilation</span> <span>&gt;</span> <span>1</span><span>:</span>
            <span>raise</span> <span>NotImplementedError</span><span>(</span><span>"Dilation &gt; 1 not supported in BasicBlock"</span><span>)</span>
        <span># Both self.conv1 and self.downsample layers downsample the input when stride != 1
</span>        <span>self</span><span>.</span><span>conv1</span> <span>=</span> <span>conv3x3</span><span>(</span><span>inplanes</span><span>,</span> <span>planes</span><span>,</span> <span>stride</span><span>)</span>
        <span>self</span><span>.</span><span>bn1</span> <span>=</span> <span>norm_layer</span><span>(</span><span>planes</span><span>)</span>
        <span># Rename relu to relu1
</span>        <span>self</span><span>.</span><span>relu1</span> <span>=</span> <span>nn</span><span>.</span><span>ReLU</span><span>(</span><span>inplace</span><span>=</span><span>True</span><span>)</span>
        <span>self</span><span>.</span><span>conv2</span> <span>=</span> <span>conv3x3</span><span>(</span><span>planes</span><span>,</span> <span>planes</span><span>)</span>
        <span>self</span><span>.</span><span>bn2</span> <span>=</span> <span>norm_layer</span><span>(</span><span>planes</span><span>)</span>
        <span>self</span><span>.</span><span>downsample</span> <span>=</span> <span>downsample</span>
        <span>self</span><span>.</span><span>stride</span> <span>=</span> <span>stride</span>
        <span>self</span><span>.</span><span>skip_add</span> <span>=</span> <span>nn</span><span>.</span><span>quantized</span><span>.</span><span>FloatFunctional</span><span>()</span>
        <span># Remember to use two independent ReLU for layer fusion.
</span>        <span>self</span><span>.</span><span>relu2</span> <span>=</span> <span>nn</span><span>.</span><span>ReLU</span><span>(</span><span>inplace</span><span>=</span><span>True</span><span>)</span>

    <span>def</span> <span>forward</span><span>(</span><span>self</span><span>,</span> <span>x</span><span>:</span> <span>Tensor</span><span>)</span> <span>-&gt;</span> <span>Tensor</span><span>:</span>
        <span>identity</span> <span>=</span> <span>x</span>

        <span>out</span> <span>=</span> <span>self</span><span>.</span><span>conv1</span><span>(</span><span>x</span><span>)</span>
        <span>out</span> <span>=</span> <span>self</span><span>.</span><span>bn1</span><span>(</span><span>out</span><span>)</span>
        <span>out</span> <span>=</span> <span>self</span><span>.</span><span>relu1</span><span>(</span><span>out</span><span>)</span>

        <span>out</span> <span>=</span> <span>self</span><span>.</span><span>conv2</span><span>(</span><span>out</span><span>)</span>
        <span>out</span> <span>=</span> <span>self</span><span>.</span><span>bn2</span><span>(</span><span>out</span><span>)</span>

        <span>if</span> <span>self</span><span>.</span><span>downsample</span> <span>is</span> <span>not</span> <span>None</span><span>:</span>
            <span>identity</span> <span>=</span> <span>self</span><span>.</span><span>downsample</span><span>(</span><span>x</span><span>)</span>
        
        <span># Use FloatFunctional for addition for quantization compatibility
</span>        <span># out += identity
</span>        <span>out</span> <span>=</span> <span>self</span><span>.</span><span>skip_add</span><span>.</span><span>add</span><span>(</span><span>identity</span><span>,</span> <span>out</span><span>)</span>
        <span>out</span> <span>=</span> <span>self</span><span>.</span><span>relu2</span><span>(</span><span>out</span><span>)</span>

        <span>return</span> <span>out</span>


<span>class</span> <span>Bottleneck</span><span>(</span><span>nn</span><span>.</span><span>Module</span><span>):</span>
    <span># Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)
</span>    <span># while original implementation places the stride at the first 1x1 convolution(self.conv1)
</span>    <span># according to "Deep residual learning for image recognition"https://arxiv.org/abs/1512.03385.
</span>    <span># This variant is also known as ResNet V1.5 and improves accuracy according to
</span>    <span># https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.
</span>
    <span>expansion</span><span>:</span> <span>int</span> <span>=</span> <span>4</span>

    <span>def</span> <span>__init__</span><span>(</span>
        <span>self</span><span>,</span>
        <span>inplanes</span><span>:</span> <span>int</span><span>,</span>
        <span>planes</span><span>:</span> <span>int</span><span>,</span>
        <span>stride</span><span>:</span> <span>int</span> <span>=</span> <span>1</span><span>,</span>
        <span>downsample</span><span>:</span> <span>Optional</span><span>[</span><span>nn</span><span>.</span><span>Module</span><span>]</span> <span>=</span> <span>None</span><span>,</span>
        <span>groups</span><span>:</span> <span>int</span> <span>=</span> <span>1</span><span>,</span>
        <span>base_width</span><span>:</span> <span>int</span> <span>=</span> <span>64</span><span>,</span>
        <span>dilation</span><span>:</span> <span>int</span> <span>=</span> <span>1</span><span>,</span>
        <span>norm_layer</span><span>:</span> <span>Optional</span><span>[</span><span>Callable</span><span>[...,</span> <span>nn</span><span>.</span><span>Module</span><span>]]</span> <span>=</span> <span>None</span>
    <span>)</span> <span>-&gt;</span> <span>None</span><span>:</span>
        <span>super</span><span>(</span><span>Bottleneck</span><span>,</span> <span>self</span><span>).</span><span>__init__</span><span>()</span>
        <span>if</span> <span>norm_layer</span> <span>is</span> <span>None</span><span>:</span>
            <span>norm_layer</span> <span>=</span> <span>nn</span><span>.</span><span>BatchNorm2d</span>
        <span>width</span> <span>=</span> <span>int</span><span>(</span><span>planes</span> <span>*</span> <span>(</span><span>base_width</span> <span>/</span> <span>64.</span><span>))</span> <span>*</span> <span>groups</span>
        <span># Both self.conv2 and self.downsample layers downsample the input when stride != 1
</span>        <span>self</span><span>.</span><span>conv1</span> <span>=</span> <span>conv1x1</span><span>(</span><span>inplanes</span><span>,</span> <span>width</span><span>)</span>
        <span>self</span><span>.</span><span>bn1</span> <span>=</span> <span>norm_layer</span><span>(</span><span>width</span><span>)</span>
        <span>self</span><span>.</span><span>conv2</span> <span>=</span> <span>conv3x3</span><span>(</span><span>width</span><span>,</span> <span>width</span><span>,</span> <span>stride</span><span>,</span> <span>groups</span><span>,</span> <span>dilation</span><span>)</span>
        <span>self</span><span>.</span><span>bn2</span> <span>=</span> <span>norm_layer</span><span>(</span><span>width</span><span>)</span>
        <span>self</span><span>.</span><span>conv3</span> <span>=</span> <span>conv1x1</span><span>(</span><span>width</span><span>,</span> <span>planes</span> <span>*</span> <span>self</span><span>.</span><span>expansion</span><span>)</span>
        <span>self</span><span>.</span><span>bn3</span> <span>=</span> <span>norm_layer</span><span>(</span><span>planes</span> <span>*</span> <span>self</span><span>.</span><span>expansion</span><span>)</span>
        <span>self</span><span>.</span><span>relu1</span> <span>=</span> <span>nn</span><span>.</span><span>ReLU</span><span>(</span><span>inplace</span><span>=</span><span>True</span><span>)</span>
        <span>self</span><span>.</span><span>downsample</span> <span>=</span> <span>downsample</span>
        <span>self</span><span>.</span><span>stride</span> <span>=</span> <span>stride</span>
        <span>self</span><span>.</span><span>skip_add</span> <span>=</span> <span>nn</span><span>.</span><span>quantized</span><span>.</span><span>FloatFunctional</span><span>()</span>
        <span>self</span><span>.</span><span>relu2</span> <span>=</span> <span>nn</span><span>.</span><span>ReLU</span><span>(</span><span>inplace</span><span>=</span><span>True</span><span>)</span>

    <span>def</span> <span>forward</span><span>(</span><span>self</span><span>,</span> <span>x</span><span>:</span> <span>Tensor</span><span>)</span> <span>-&gt;</span> <span>Tensor</span><span>:</span>
        <span>identity</span> <span>=</span> <span>x</span>

        <span>out</span> <span>=</span> <span>self</span><span>.</span><span>conv1</span><span>(</span><span>x</span><span>)</span>
        <span>out</span> <span>=</span> <span>self</span><span>.</span><span>bn1</span><span>(</span><span>out</span><span>)</span>
        <span>out</span> <span>=</span> <span>self</span><span>.</span><span>relu1</span><span>(</span><span>out</span><span>)</span>

        <span>out</span> <span>=</span> <span>self</span><span>.</span><span>conv2</span><span>(</span><span>out</span><span>)</span>
        <span>out</span> <span>=</span> <span>self</span><span>.</span><span>bn2</span><span>(</span><span>out</span><span>)</span>
        <span>out</span> <span>=</span> <span>self</span><span>.</span><span>relu</span><span>(</span><span>out</span><span>)</span>

        <span>out</span> <span>=</span> <span>self</span><span>.</span><span>conv3</span><span>(</span><span>out</span><span>)</span>
        <span>out</span> <span>=</span> <span>self</span><span>.</span><span>bn3</span><span>(</span><span>out</span><span>)</span>

        <span>if</span> <span>self</span><span>.</span><span>downsample</span> <span>is</span> <span>not</span> <span>None</span><span>:</span>
            <span>identity</span> <span>=</span> <span>self</span><span>.</span><span>downsample</span><span>(</span><span>x</span><span>)</span>

        <span># out += identity
</span>        <span>out</span> <span>=</span> <span>self</span><span>.</span><span>skip_add</span><span>.</span><span>add</span><span>(</span><span>identity</span><span>,</span> <span>out</span><span>)</span>
        <span>out</span> <span>=</span> <span>self</span><span>.</span><span>relu2</span><span>(</span><span>out</span><span>)</span>

        <span>return</span> <span>out</span>


<span>class</span> <span>ResNet</span><span>(</span><span>nn</span><span>.</span><span>Module</span><span>):</span>

    <span>def</span> <span>__init__</span><span>(</span>
        <span>self</span><span>,</span>
        <span>block</span><span>:</span> <span>Type</span><span>[</span><span>Union</span><span>[</span><span>BasicBlock</span><span>,</span> <span>Bottleneck</span><span>]],</span>
        <span>layers</span><span>:</span> <span>List</span><span>[</span><span>int</span><span>],</span>
        <span>num_classes</span><span>:</span> <span>int</span> <span>=</span> <span>1000</span><span>,</span>
        <span>zero_init_residual</span><span>:</span> <span>bool</span> <span>=</span> <span>False</span><span>,</span>
        <span>groups</span><span>:</span> <span>int</span> <span>=</span> <span>1</span><span>,</span>
        <span>width_per_group</span><span>:</span> <span>int</span> <span>=</span> <span>64</span><span>,</span>
        <span>replace_stride_with_dilation</span><span>:</span> <span>Optional</span><span>[</span><span>List</span><span>[</span><span>bool</span><span>]]</span> <span>=</span> <span>None</span><span>,</span>
        <span>norm_layer</span><span>:</span> <span>Optional</span><span>[</span><span>Callable</span><span>[...,</span> <span>nn</span><span>.</span><span>Module</span><span>]]</span> <span>=</span> <span>None</span>
    <span>)</span> <span>-&gt;</span> <span>None</span><span>:</span>
        <span>super</span><span>(</span><span>ResNet</span><span>,</span> <span>self</span><span>).</span><span>__init__</span><span>()</span>
        <span>if</span> <span>norm_layer</span> <span>is</span> <span>None</span><span>:</span>
            <span>norm_layer</span> <span>=</span> <span>nn</span><span>.</span><span>BatchNorm2d</span>
        <span>self</span><span>.</span><span>_norm_layer</span> <span>=</span> <span>norm_layer</span>

        <span>self</span><span>.</span><span>inplanes</span> <span>=</span> <span>64</span>
        <span>self</span><span>.</span><span>dilation</span> <span>=</span> <span>1</span>
        <span>if</span> <span>replace_stride_with_dilation</span> <span>is</span> <span>None</span><span>:</span>
            <span># each element in the tuple indicates if we should replace
</span>            <span># the 2x2 stride with a dilated convolution instead
</span>            <span>replace_stride_with_dilation</span> <span>=</span> <span>[</span><span>False</span><span>,</span> <span>False</span><span>,</span> <span>False</span><span>]</span>
        <span>if</span> <span>len</span><span>(</span><span>replace_stride_with_dilation</span><span>)</span> <span>!=</span> <span>3</span><span>:</span>
            <span>raise</span> <span>ValueError</span><span>(</span><span>"replace_stride_with_dilation should be None "</span>
                             <span>"or a 3-element tuple, got {}"</span><span>.</span><span>format</span><span>(</span><span>replace_stride_with_dilation</span><span>))</span>
        <span>self</span><span>.</span><span>groups</span> <span>=</span> <span>groups</span>
        <span>self</span><span>.</span><span>base_width</span> <span>=</span> <span>width_per_group</span>
        <span>self</span><span>.</span><span>conv1</span> <span>=</span> <span>nn</span><span>.</span><span>Conv2d</span><span>(</span><span>3</span><span>,</span> <span>self</span><span>.</span><span>inplanes</span><span>,</span> <span>kernel_size</span><span>=</span><span>7</span><span>,</span> <span>stride</span><span>=</span><span>2</span><span>,</span> <span>padding</span><span>=</span><span>3</span><span>,</span>
                               <span>bias</span><span>=</span><span>False</span><span>)</span>
        <span>self</span><span>.</span><span>bn1</span> <span>=</span> <span>norm_layer</span><span>(</span><span>self</span><span>.</span><span>inplanes</span><span>)</span>
        <span>self</span><span>.</span><span>relu</span> <span>=</span> <span>nn</span><span>.</span><span>ReLU</span><span>(</span><span>inplace</span><span>=</span><span>True</span><span>)</span>
        <span>self</span><span>.</span><span>maxpool</span> <span>=</span> <span>nn</span><span>.</span><span>MaxPool2d</span><span>(</span><span>kernel_size</span><span>=</span><span>3</span><span>,</span> <span>stride</span><span>=</span><span>2</span><span>,</span> <span>padding</span><span>=</span><span>1</span><span>)</span>
        <span>self</span><span>.</span><span>layer1</span> <span>=</span> <span>self</span><span>.</span><span>_make_layer</span><span>(</span><span>block</span><span>,</span> <span>64</span><span>,</span> <span>layers</span><span>[</span><span>0</span><span>])</span>
        <span>self</span><span>.</span><span>layer2</span> <span>=</span> <span>sel…</span></code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://leimao.github.io/blog/PyTorch-Static-Quantization/">https://leimao.github.io/blog/PyTorch-Static-Quantization/</a></em></p>]]>
            </description>
            <link>https://leimao.github.io/blog/PyTorch-Static-Quantization/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25242804</guid>
            <pubDate>Sun, 29 Nov 2020 03:51:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Undeleting a file overwritten with mv]]>
            </title>
            <description>
<![CDATA[
Score 262 | Comments 81 (<a href="https://news.ycombinator.com/item?id=25242444">thread link</a>) | @todsacerdoti
<br/>
November 28, 2020 | https://behind.pretix.eu/2020/11/28/undelete-flv-file/ | <a href="https://web.archive.org/web/*/https://behind.pretix.eu/2020/11/28/undelete-flv-file/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">

    <article>

        

<!--         <header class="post-header">
            <a id="blog-logo" href="https://behind.pretix.eu">
                
                    <span class="blog-title">pretix – behind the scenes</span>
                
            </a>
        </header> -->

        <!-- <span class="post-meta">
            <time datetime="2020-11-28">28 Nov 2020</time>
            
                on Technology, Forensics, and Linux
            
        </span> -->

        <!-- <h1 class="post-title">Undeleting a file overwritten with mv</h1> -->

        <section>
            <p>It’s been a while since we shared the story of an incident with you, and that’s probably a good thing –
most operational incidents we had in the past year were “boring” enough in nature to fix them easily.
This time, we’ve got a story of a data loss, caused by pure and simple human error – and the story of
how we recovered the data.</p>

<p>Even though it is quite embarrassing how the data loss happened, we think it’s worth sharing the story
of its recovery, as it might allow you to learn a few useful things in case you ever end up in a
similar situation.</p>

<p>As you might have seen, over the last 7 months we’ve extended our offerings beyond ticketing to allow
our customers to transform their events into the digital space as long as the global pandemic makes
traditional event formats impossible. The result of our effort is a joint venture called 
<a href="https://venueless.org/">Venueless</a> that you should absolutely check out if you haven’t yet.</p>

<p>One component of the virtual events we run on venueless is <strong>live video streaming</strong>. In this process,
our customers use a tool like <a href="https://obsproject.com/">OBS</a> or <a href="https://streamyard.com/">StreamYard</a>
to create a live video stream. The stream is then sent to an <strong>encoding server</strong> of ours via RTMP.
On the encoding server, we re-encode the stream into different quality levels and then distribute
it to our very own tiny streaming CDN.</p>

<p>Venueless currently does <strong>not yet</strong> include a video-on-demand component and usually, our customers record
their content at the source, e.g. with OBS or StreamYard, and process or publish them on their own.
However, just to be safe, we keep a recording of the incoming stream as well. This isn’t currently
part of our promoted service offering, we rather see it as a free backup service to our clients in case they
lose their recording. Given that we already consider it to just be a backup, we currently don’t make any
further backups of this data.</p>

<h4 id="data-loss">Data loss</h4>

<p>Usually, we delete these recordings after a while, but in some cases, our customers ask us to get them, e.g.
because their own recording failed, or because StreamYard only records the first 8 hours of every
stream. Since this doesn’t happen a lot, it’s not yet an automated process in our system. Whenever a customer
requests a recording we SSH into the respective encoding server and move the recording file to a
directory that’s accessible through HTTP, like this:</p>

<pre><code>/var/recordings $ mv recording-12345.flv public/
</code></pre>

<p>That’s it, we share the link with the customer, and the process is done. One of the simplest steps possible
in all this. Yesterday, a customer asked us for the recordings of the two last streams of their event. Just
before finishing up for the week, I wanted to supply them with the required file, SSH’d into the server,
looked for the correct files and typed…</p>

<pre><code>/var/recordings $ mv recording-16678.flv recording-16679.flv
</code></pre>

<p><strong>Oops.</strong> I hit return before typing out <code>public/</code>, and therefore replaced the last stream with the
second-last, losing one of the videos.</p>

<h4 id="damage-control">Damage control</h4>

<p>Having a very naive understanding of how file systems work, I knew that the <code>mv</code> command has only
changed the directory listing of the file system, but hasn’t actually wiped the file from the disk,
so I knew there is likely still a chance to recover the file, if it’s not overwritten by something
else in the meantime.</p>

<p>Since I didn’t manage to re-mount the root partition as read-only to avoid further damage softly,
I used the <a href="https://www.kernel.org/doc/html/latest/admin-guide/sysrq.html">big hammer</a> to remount
everything read-only immediately:</p>

<pre><code># echo u &gt; /proc/sysrq-trigger
</code></pre>

<p>Uhm, okay, this worked, but how do I install any data recovery tools now? After some experiments,
I decided it would be easiest to reboot into the recovery system provided by our server provider
<a href="https://www.hetzner.com/">Hetzner</a>. So I configured the boot loader to boot their recovery system
from the network and forcefully rebooted the server.</p>

<p>To be able to perform disk dumps and have some operational flexibility without downloading a 2 TB
disk image to my local machine (which would take rougly a week), I also quickly purchased
a <a href="https://www.hetzner.com/storage/storage-box">Hetzner Storage Box</a> with 5 TB space.</p>

<h4 id="failed-attempts">Failed attempts</h4>

<p>Just before I executed my fatal <code>mv</code> command, I executed <code>ls -lisah</code> to get a directory listing
of the files:</p>

<pre><code>3146449 1.1G -rw-r--r-- 1 www-data www-data 1.1G Nov XX XX:XX recording-16678.flv
3146113 1.6G -rw-r--r-- 1 www-data www-data 1.6G Nov XX XX:XX recording-16679.flv
</code></pre>

<p>This meant I <strong>knew</strong> the inode number of the deleted file! As I mentioned before, my understanding
of file systems was (and is) rather naive, and I was pretty optimistic to be able to recover the
file using that information. Isn’t that sort of what a journaling file system is for?</p>

<p>Recovering the file this way hover appeared to be impossible. <a href="http://ext4magic.sourceforge.net/howto_en.html">ext4magic</a>
and <a href="http://extundelete.sourceforge.net/">extundelete</a> are powerful tools that did find some 
deleted files on my disk – but not the one I was looking for, even after trying different options
for over two hours.</p>

<p>I did not spend the time to really understand how ext4 works, but from what I gathered from various
blogs, I was pretty much out of luck since the inode did no longer contain the relevant information
and ext4magic also wasn’t able to <a href="http://ext4magic.sourceforge.net/howto_en.html#Recovery_process_5">recover the neccessary information from the journal</a>
either.</p>

<pre><code>debugfs:  inode_dump &lt;3146113&gt;
0000  a081 0000 8503 0000 e83a c15f e83a c15f  .........:._.:._
0020  e83a c15f 0000 0000 7200 0100 0800 0000  .:._....r.......
0040  0000 0800 0100 0000 0af3 0100 0400 0000  ................
0060  0000 0000 0000 0000 0100 0000 e6eb c000  ................
0100  0000 0000 0000 0000 0000 0000 0000 0000  ................
*
0140  0000 0000 92d0 2cf5 0000 0000 0000 0000  ......,.........
0160  0000 0000 0000 0000 0000 0000 6fb2 0000  ............o...
0200  2000 e3fb 208a 515b 7c65 5d5a 7c65 5d5a   ... .Q[|e]Z|e]Z
0220  e83a c15f 7c65 5d5a 0000 0000 0000 0000  .:._|e]Z........
0240  0000 0000 0000 0000 0000 0000 0000 0000  ................
*
</code></pre>

<p>However, if you’re in a similar situation – the ext4magic how-tos are really helpful and worth a try.</p>

<h4 id="successful-recovery">Successful recovery</h4>

<p>There is this one other approach to file recovery that is often recommended on the internet, usually
for “small text files”: Just <code>grep</code> your whole disk for known parts of its contents! So why wouldn’t
this work on larger non-text files as well?</p>

<p>The first problem is obviously what to grep for. The only thing I know about the missing file, apart
from its rough size, is that it’s a FLV video file. Luckily, <a href="https://en.wikipedia.org/wiki/Flash_Video#Flash_Video_Structure">all FLV files</a>
that contain video start with the byte sequence <code>FLV\x01\x05</code>. So let’s search our 2 TB disk for
that byte sequence and print out the byte offset of all occurences!</p>

<pre><code>cat /dev/md2 \
	| pv -s 1888127576000 \
	| grep -P --byte-offset --text 'FLV\x01\x05' \
	| tee -a /mnt/storagebox/grep-log.txt
</code></pre>

<p>This took roughly 7 hours. The <code>pv</code> command with the (rough) total size of the disk is optional, but gives you
a nice progress bar. Overall, this took a little over 6 hours on our server.</p>

<p><code>grep</code> works line-based, which in a binary file menas “any byte sequence between two ASCII line breaks”. The
log file therefore contained lots of lines like this:</p>

<pre><code>184473878409:&lt;some binary data&gt;FLV&lt;some binary data&gt;
</code></pre>

<p>In total, the search found 126 FLV file headers on our disk. This was pretty reassuring, since we had 122 FLV files
still known to the file system – so there are at least four FLV byte sequences without a filename!</p>

<pre><code># find /mnt/disk/var/recordings/ -name '*.flv' -not -empty -ls | wc -l
122
</code></pre>

<p>Now, I needed to find out which of the 126 byte sequences did not have a filename. Since I really didn’t want
to spend all weekend with a deep-dive into the ext4 disk layout, I went for an easier solution: For every file
still known in the file system, I computed a hash of the first 500 kilobytes of the file:</p>

<figure><pre><code data-lang="python"><span>#!/usr/bin/python3
</span><span>import</span> <span>glob</span>
<span>import</span> <span>hashlib</span>
<span>import</span> <span>os</span>

<span>hashsize</span> <span>=</span> <span>500</span> <span>*</span> <span>1024</span>
<span>known_hashes</span> <span>=</span> <span>{}</span>
<span>not_deleted_files</span> <span>=</span> <span>sorted</span><span>(</span>
    <span>glob</span><span>.</span><span>glob</span><span>(</span><span>'/mnt/disk/var/recordings/*.flv'</span><span>)</span> <span>+</span> 
    <span>glob</span><span>.</span><span>glob</span><span>(</span><span>'/mnt/disk/var/recordings/public/*.flv'</span><span>)</span>
<span>)</span>
<span># Ignore files shorter than our hash size
</span><span>not_deleted_files</span> <span>=</span> <span>[</span>
    <span>f</span> <span>for</span> <span>f</span> <span>in</span> <span>not_deleted_files</span>
    <span>if</span> <span>os</span><span>.</span><span>stat</span><span>(</span><span>f</span><span>).</span><span>st_size</span> <span>&gt;</span> <span>hashsize</span>
<span>]</span>

<span>for</span> <span>fname</span> <span>in</span> <span>not_deleted_files</span><span>:</span>
    <span>with</span> <span>open</span><span>(</span><span>fname</span><span>,</span> <span>'rb'</span><span>)</span> <span>as</span> <span>f</span><span>:</span>
        <span>h</span> <span>=</span> <span>hashlib</span><span>.</span><span>md5</span><span>(</span><span>f</span><span>.</span><span>read</span><span>(</span><span>hashsize</span><span>)).</span><span>hexdigest</span><span>()</span>
        <span>if</span> <span>h</span> <span>in</span> <span>known_hashes</span><span>:</span>
            <span>print</span><span>(</span><span>"duplicate hash found:"</span><span>)</span>
        <span>known_hashes</span><span>[</span><span>h</span><span>]</span> <span>=</span> <span>fname</span>
        <span>print</span><span>(</span><span>h</span><span>,</span> <span>fname</span><span>)</span>

<span>print</span><span>(</span>
    <span>len</span><span>(</span><span>not_deleted_files</span><span>),</span> <span>"files with"</span><span>,</span>
    <span>len</span><span>(</span><span>known_hashes</span><span>),</span> <span>"hashes"</span>
<span>)</span></code></pre></figure>

<p>Interestingly, two files from the completely different customers shared the same hash of the first 500 kilobytes.
I haven’t tested it yet, but my theory is that those were streams that just did not contain any audio or video
in their first minutes, but only empty frames. However, since I knew this isn’t the case for my missing file,
I felt confident in proceeding with this approach.</p>

<p>Next, I computed the same hash for every byte offest found by grep and compared it to the hashes found in the
previous step:</p>

<figure><pre><code data-lang="python"><span>grep_log</span> <span>=</span> <span>'/mnt/storagebox/grep-log.txt'</span>
<span>disk</span> <span>=</span> <span>'/dev/md2'</span>

<span>print</span><span>(</span><span>"Parsing grep log…"</span><span>)</span>
<span>positions</span> <span>=</span> <span>[]</span>
<span>with</span> <span>open</span><span>(</span><span>grep_log</span><span>,</span> <span>'rb'</span><span>)</span> <span>as</span> <span>f</span><span>:</span>
    <span>for</span> <span>line</span> <span>in</span> <span>f</span><span>.</span><span>read</span><span>().</span><span>split</span><span>(</span><span>b'</span><span>\n</span><span>'</span><span>):</span>
        <span>if</span> <span>not</span> <span>line</span><span>:</span>  <span># ignore empty line e.g. at end of file
</span>            <span>continue</span>
        <span>pos</span><span>,</span> <span>data</span> <span>=</span> <span>line</span><span>.</span><span>split</span><span>(</span><span>b':'</span><span>,</span> <span>1</span><span>)</span>
        <span>pos</span> <span>=</span> <span>int</span><span>(</span><span>pos</span><span>.</span><span>decode</span><span>())</span>
        <span># add offset of FLV within line
</span>        <span>binoffset</span> <span>=</span> <span>data</span><span>.</span><span>index</span><span>(</span><span>b"FLV</span><span>\x01</span><span>"</span><span>)</span>
        <span>pos</span> <span>+=</span> <span>binoffset</span> 
        <span>positions</span><span>.</span><span>append</span><span>(</span><span>pos</span><span>)</span>

<span>print</span><span>(</span><span>"Computing hashes of files on disk…"</span><span>)</span>
<span>found_hashes</span> <span>=</span> <span>{}</span>
<span>with</span> <span>open</span><span>(</span><span>disk</span><span>,</span> <span>'rb'</span><span>)</span> <span>as</span> <span>f</span><span>:</span>
    <span>for</span> <span>p</span> <span>in</span> <span>positions</span><span>:</span>
        <span>f</span><span>.</span><span>seek</span><span>(</span><span>p</span><span>)</span>
        <span>d</span> <span>=</span> <span>f</span><span>.</span><span>read</span><span>(</span><span>hashsize</span><span>)</span>
        <span>h</span> <span>=</span> <span>hashlib</span><span>.</span><span>md5</span><span>(</span><span>d</span><span>).</span><span>hexdigest</span><span>()</span>
        <span>if</span> <span>h</span> <span>in</span> <span>known_hashes</span><span>:</span>
            <span>print</span><span>(</span><span>"At offset"</span><span>,</span> <span>p</span><span>,</span> <span>"found known hash"</span><span>,</span> <span>h</span><span>,</span>
                  <span>"corresponding to"</span><span>,</span> <span>known_hashes</span><span>[</span><span>h</span><span>])</span>
        <span>else</span><span>:</span>
            <span>print</span><span>(</span><span>"At offset"</span><span>,</span> <span>p</span><span>,</span> <span>"found unknown hash"</span><span>,</span> <span>h</span><span>)</span>
        <span>found_hashes</span><span>[</span><span>h</span><span>]</span> <span>=</span> <span>p</span>

<span>unknown_hashes</span> <span>=</span> <span>{</span>
    <span>h</span><span>:</span> <span>p</span> <span>for</span> <span>h</span><span>,</span> <span>p</span> <span>in</span> <span>found_hashes</span><span>.</span><span>items</span><span>()</span>
    <span>if</span> <span>h</span> <span>not</span> <span>in</span> <span>known_hashes</span>
<span>}</span>
<span>files_not_found</span> <span>=</span> <span>[</span>
    <span>fname</span> <span>for</span> <span>h</span><span>,</span> <span>fname</span> <span>in</span> <span>known_hashes</span><span>.</span><span>items</span><span>()</span>
   …</code></pre></figure></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://behind.pretix.eu/2020/11/28/undelete-flv-file/">https://behind.pretix.eu/2020/11/28/undelete-flv-file/</a></em></p>]]>
            </description>
            <link>https://behind.pretix.eu/2020/11/28/undelete-flv-file/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25242444</guid>
            <pubDate>Sun, 29 Nov 2020 02:21:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Colour Science for Python – 0.3.16]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25242149">thread link</a>) | @kelsolaar
<br/>
November 28, 2020 | https://www.colour-science.org/posts/colour-0316-is-available/ | <a href="https://web.archive.org/web/*/https://www.colour-science.org/posts/colour-0316-is-available/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody text">
    <div>
<p><a href="https://github.com/colour-science/colour/releases/tag/v0.3.16">Colour 0.3.16</a>
has finally been released!</p>
<!-- TEASER_END -->
<p>This release integrates all the <a href="https://summerofcode.withgoogle.com/">GSoC</a>
work from Pawel (<a href="https://github.com/enneract">@enneract</a>), most of the code
from Nishant (<a href="https://github.com/njwardhan">@njwardhan</a>) and, the
optimizations from Omar (<a href="https://github.com/OmarWagih1">@OmarWagih1</a>).
We would like to thank them again for their great contributions!</p>
<p><img alt="/images/Blog_Colour_Rendition_Report.png" src="https://www.colour-science.org/images/Blog_Colour_Rendition_Report.png"></p><p>With this release, we stop testing for
<a href="https://www.python.org/downloads/release/python-350/">Python 3.5</a> and,
<a href="https://docs.scipy.org/doc/scipy/reference/release.1.1.0.html">Scipy&gt;=1.1.0</a>
becomes the minimum version. This is also the <strong>last feature release to
support</strong> <a href="https://www.python.org/downloads/release/python-270/">Python 2.7</a>.
We will also trim the deprecation code in the next version thus, please make
sure to update your code accordingly.</p>
<p>Besides the various minor changes and fixes, the highlights of this release are:</p>
<ul>
<li><p>Support for <em>Jakob and Hanika (2019)</em>, <em>Mallett and Yuksel (2019)</em> and,
<em>Otsu, Yamamoto and Hachisuka (2018)</em> spectral upsampling methods thanks to
Pawel's contributions as part of GSoC 2020.</p></li>
<li><p>Support for the computation of the <em>CIE 2017 Colour Fidelity Index</em> and
<em>ANSI/IES TM-30-18 Colour Fidelity Index</em> colour quality metrics thanks to
Pawel's contributions as part of GSoC 2020.</p></li>
<li><p>Support for generation of the <em>ANSI/IES TM-30-18 Colour Rendition Report</em>
thanks to Pawel's contributions as part of GSoC 2020.</p></li>
<li><p>Improvements of the LUT IO support thanks to Nishant's contributions as
part of GSoC 2020.</p></li>
<li><p>Performance improvements thanks to Omar's contributions as part of GSoC
2020.</p></li>
<li><p>Support for <em>ACES Input Device Transform (IDT)</em> generation: The
implementation follows to some extent
<a href="https://github.com/ampas/rawtoaces">RAW to ACES v1</a> and
<a href="https://www.dropbox.com/s/ouwnid1aevqti5d/P-2013-001.pdf?dl=0">P-2013-001</a>
procedure.</p></li>
<li>
<p>New <em>ISO</em> spectral datasets:</p>
<ul>
<li><p>ISO 6728 Standard Lens</p></li>
<li><p>ISO 7589 Diffuser</p></li>
<li><p>ISO 7589 Photographic Daylight</p></li>
<li><p>ISO 7589 Sensitometric Daylight</p></li>
<li><p>ISO 7589 Studio Tungsten</p></li>
<li><p>ISO 7589 Sensitometric Studio Tungsten</p></li>
<li><p>ISO 7589 Photoflood</p></li>
<li><p>ISO 7589 Sensitometric Photoflood</p></li>
<li><p>ISO 7589 Sensitometric Printer</p></li>
</ul>
</li>
<li><p>Support for IGPGTG colourspace by <em>Hellwig and Fairchild (2020)</em>.</p></li>
<li><p>The <cite>colour.SpectralDistribution.interpolate</cite> and
<cite>colour.MultiSpectralDistributions.interpolate</cite> methods now honour class
instantiation time interpolation parameters instead of blindly applying
<em>CIE 167:2005</em> recommendation, this introduces minor numerical changes.</p></li>
<li><p>Many definitions, methods and module attributes have been renamed to
improve consistency and we are reaching a satisfactory point in that
regard, hopefully, the names will be much more stable from now on.</p></li>
</ul>
<p>Please visit the <a href="https://github.com/colour-science/colour/releases/tag/v0.3.16">releases page</a>
for complete details.</p>
<p>Our other dependent Python packages have also been updated accordingly:</p>
<ul>
<li><p><a href="https://github.com/colour-science/colour-demosaicing/releases/tag/v0.1.6">Colour - Demosaicing - 0.1.6</a></p></li>
<li><p><a href="https://github.com/colour-science/colour-hdri/releases/tag/v0.1.8">Colour - HDRI - 0.1.8</a></p></li>
<li><p><a href="https://github.com/colour-science/colour-checker-detection/releases/tag/v0.1.2">Colour - Checker Detection - 0.1.2</a></p></li>
<li>
<p><a href="https://github.com/colour-science/colour-datasets/releases/tag/v0.1.1">Colour - Datasets - 0.1.1</a></p>
<ul>
<li>
<p>The following new datasets have been added:</p>
<blockquote>
<ul>
<li><p>4050598 : Spectral Upsampling Coefficient Tables - Jakob and
Hanika (2019)</p></li>
<li><p>4051012 : Measured Commercial LED Spectra - Brendel (2020)</p></li>
</ul>
</blockquote>
</li>
</ul>
</li>
</ul>
</div>
    </div></div>]]>
            </description>
            <link>https://www.colour-science.org/posts/colour-0316-is-available/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25242149</guid>
            <pubDate>Sun, 29 Nov 2020 01:24:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How deadly is Covid-19?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25241663">thread link</a>) | @Malbolge
<br/>
November 28, 2020 | https://sebastianrushworth.com/2020/10/24/how-deadly-is-covid-19/ | <a href="https://web.archive.org/web/*/https://sebastianrushworth.com/2020/10/24/how-deadly-is-covid-19/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <amp-auto-ads type="adsense" data-ad-client="ca-pub-1298191191396779" i-amphtml-layout="container"></amp-auto-ads><p><a href="https://cornucopia.cornubot.se/2020/10/september-2020-den-minst-dodliga.html" target="_blank" rel="noreferrer noopener">September 2020 was the least deadly month in Swedish history</a>, in terms of number of deaths per 100,000 population. Ever. And I don’t mean the least deadly September, I mean the least deadly month. Ever. To me, this is pretty clear evidence of two things. First, that covid is not a very deadly disease. And second, that Sweden has herd immunity.</p><p><a href="https://twitter.com/sebrushworth/status/1319222055343185921" target="_blank" rel="noreferrer noopener">When I posted this information on my twitter feed</a>, the response from proponents of further lockdown was that the reason September was such an un-deadly month, was because everyone has already died earlier in the pandemic. To me, that seems like a pretty self-defeating argument. Why?</p><p>Because 6,000 people have died of covid in Sweden, a country with a population of 10,000,000 people. 6,000 people is 0,06% of the population. If it is enough for that tiny a fraction of a population to die of a pandemic for the pandemic to peter out so completely that a country can have its least deadly month ever, then the pandemic was never that deadly to begin with.</p><p>In August, <a href="https://sebastianrushworth.com/2020/08/04/how-bad-is-covid-really-a-swedish-doctors-perspective/" target="_blank" rel="noreferrer noopener">I wrote an article where I proposed that the mortality for covid is only 0,12%</a>, roughly the same as influenza. That number was based on a back-of-the-envelope calculation. I figured that, since the death rate had dropped continuously for months and was at very low levels, Sweden must have reached a point where it had herd immunity. And I figured that at least 50% of the population must have been infected for herd immunity to have been reached. 50% of Sweden’s population is five million people. 6,000 / 5,000,000 = 0,12%</p><p>At the beginning of October, one of the World Health Organisation’s executive directors, Mike Ryan, <a href="https://www.irishtimes.com/news/ireland/irish-news/covid-19-world-in-for-a-hell-of-a-ride-in-coming-months-dr-mike-ryan-says-1.4370626" target="_blank" rel="noreferrer noopener">said that the WHO estimated that 750 million people had so far been infected with covid</a>. At that point, one million people had died of the disease. That gives a death rate for covid of 0,13% . So the WHO said that the death rate is 0,13% . Not too far off my earlier back-of-envelope estimation. This of course begs the question why there are continued lockdowns for a disease that is no worse than the flu.</p><p>A short while later, the <a href="https://www.who.int/bulletin/online_first/BLT.20.265892.pdf" target="_blank" rel="noreferrer noopener">WHO released an analysis by professor John Ioannidis</a>, with his estimate of the covid death rate. This analysis was based on seroprevalance data, i.e. data on how many people were shown to have antibodies to covid in their bloodstream at different times in different countries, which was correlated with the number of deaths in those countries. Through this analysis, professor Ioannidis reached the conclusion that covid has an overall mortality rate of around 0,23% (in other words, one in 434 infected people die of the disease). For people under the age of seventy, the mortality rate was estimated at 0,05% (in other words, one in 2,000 infected people under the age of 70 die of the disease).</p><p><a href="https://sebastianrushworth.com/2020/09/28/herd-immunity-without-antibodies/" target="_blank" rel="noreferrer noopener">As I’ve discussed before, I don’t think antibody data gives a very complete picture</a>, since there are studies showing that a lot of people don’t produce measurable antibodies in their bloodstreams, but still have immunity, either thanks to a T-cell response, or thanks to local antibody production in the respiratory tract. So I think that the fatality rate is significantly lower than what the analysis by professory Ioannidis found, and more in line with what the WHO stated earlier in October.</p><p>But even if the antibody based number is the correct number, then covid still is not a very deadly disease. For comparison, the 1918 flu pandemic is thought to have had an infection fatality rate of 2,5%, i.e. one in forty infected people died. So the 1918 flu was 11 times more deadly than covid if you go by professor Ioannidis antibody based numbers, and 19 times more deadly than covid if you go by the fatality rate provided 12 days earlier by the WHO’s Mike Ryan.</p><p>And this is missing one big point about covid. The average person who dies from covid is over 80 years old and has multiple underlying health conditions. In other words, their life expectancy is very short. The average person who died in the 1918 pandemic was in their late 20’s. So each death in the 1918 pandemic actually meant around 50 years more of life lost per person than each death in the covid pandemic. Multiply that by the fact that it had a 19 times higher death rate, and the 1918 flu was in fact 950 times more deadly than covid, in terms its capacity to shorten people’s lives.</p><p>Ok, I’ve discussed the fatality rate of the 1918 flu pandemic, and compared that to covid. But what about the fatality rate of the common cold viruses that are constantly circulating in society? How does covid compare to them?</p><p>Many people think that the common cold viruses are harmless. But in fact, among elderly people with underlying health conditions, they are frequently deadly. <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5343795/" target="_blank" rel="noreferrer noopener">A study carried out in 2017</a> found that, among frail elderly people, rhinovirus is actually more deadly than regular influenza. In that study, the 30 day mortality for frail elderly people admitted to hospital due to a rhinovirus infection was 10% . For frail elderly people admitted to hospital due to influenza, 30 day mortality was 7% .</p><p>What is my point?  If you are old and frail, and have underlying health conditions, then even that most harmless of all infections, the so called “common cold”, can be deadly. In fact, it often is. Covid-19 is not a unique disease, and does not appear to have a noticeably higher mortality rate than the so called “common cold”.</p><p>There is one final aspect to all this that needs to be discussed. And that is the effect of covid on overall mortality. If it turns out that covid has no effect on overall mortality, then that really brings in to question why we are locking down, since we’re not actually preventing any deaths. So, what is the effect of covid on overall mortality?</p><p>Let’s look at Sweden, since that is perhaps the country that has taken the most relaxed approach of any to preventing spread, and which should therefore also reasonably be expected to have had the highest impact on its overall death rate. From January to September 2020, <a href="https://cornucopia.cornubot.se/2020/10/september-2020-least-deadly-month-ever.html" target="_blank" rel="noreferrer noopener">Sweden experienced 687 deaths per 100,000 population</a>. The last time Sweden had a deadlier year was 2015. Personally, I don’t remember any big deadly pandemic happening in 2015.</p><p>In fact, 2020 is so far one of the least deadly years in Swedish history, and is largely in line with the average for the preceding five years. To be precise, it is 2,7% higher than the average for the preceding five years, which is well within the margin of error. In 2019, mortality was 6% lower than the average, so it should be expected that 2020 would have a slightly higher mortality than average, even without covid.</p><p>What does this mean? It means that covid, a supposedly deadly viral pandemic, has not killed enough Swedes to have any noticeable impact on overall mortality.</p><p>How can this be explained, when we know that 6,000 Swedes have died of covid?</p><p>As I see it, there are two possible explanations. The first is that most people who died “of” covid actually died with covid. In other words, they had a positive covid test and were therefore characterized as covid deaths, when the actual cause of death was something else. The second is that most people who died of covid were so old, and so frail, and had so many underlying health conditions, that even without covid, they would have died by now. There are no other reasonable explanations.</p><p>I am not saying that covid is nothing, or that it doesn’t exist. I am saying that it is a virus with a marginal effect on longevity. And yet, public policy in most countries has been driven by doomsday scenarios based on completely unrealistic numbers.  To put it simply, we’ve acted like we’re dealing with a global ebola outbreak, when covid is much more like the common cold.</p><p>UPDATE (26th October 2020): After SCB updated their numbers it has become clear that September 2020 was in fact the second least deadly month in Swedish history, not the least deadly month. That award goes to June 2019.</p><p>You might also enjoy reading my article <a href="https://sebastianrushworth.com/2020/09/19/covid-19-does-sweden-have-herd-immunity/" target="_blank" rel="noreferrer noopener">about why I think Sweden has herd immunity</a>, or enjoy watching <a href="https://sebastianrushworth.com/2020/10/13/covid-podcast-with-ivor-cummins/" target="_blank" rel="noreferrer noopener">my conversation with Ivor Cummins of Fat Emperor about covid-19</a>.</p><section id="blog_subscription-17"></section><div><div><p> I am a practicing physician in Stockholm, Sweden. My main interests are evidence based medicine, medical ethics, and medical history. I frequently get asked questions by my patients about health, diet, exercise, supplements, and medications. The purpose of this blog is to try to understand what the science says and to translate it in to a format that non-scientists can understand. <a href="https://sebastianrushworth.com/author/doctorsebastian/" rel="author"> View all posts by Sebastian Rushworth, M.D. </a></p></div></div></div></div>]]>
            </description>
            <link>https://sebastianrushworth.com/2020/10/24/how-deadly-is-covid-19/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25241663</guid>
            <pubDate>Sat, 28 Nov 2020 23:55:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: SimpleLogin – protect online privacy using email alias]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25241372">thread link</a>) | @sonmicrosystems
<br/>
November 28, 2020 | https://simplelogin.io/blog/an-email-for-each-website/ | <a href="https://web.archive.org/web/*/https://simplelogin.io/blog/an-email-for-each-website/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="hello-bar" role="alert">
    <p>
    SimpleLogin is featured in
    <a href="https://lespepitestech.com/startup-de-la-french-tech/simplelogin" target="_blank" rel="noopener" data-toggle="tooltip" title="aka the French ProductHunt">Les PÃ©pites Tech â†—</a>
  </p></div><div id="content" role="main">
    <div>
        

        

        

        <blockquote>
<p>Why do I receive so many spams?</p>
</blockquote>

<p>When this question was asked by my girlfriend (now wife ðŸ˜…), my immediate answer was “Stop giving away your email” and I suggested creating a secondary email for “suspicious” websites. Also, using the same email everywhere is like leaving the same <strong>footprint</strong> on the Internet, allowing advertisers to <code>cross-reference</code> your online behavior.</p>



<p>
    <img src="https://simplelogin.io/blog/footprint.jpeg" alt="Fingerprint image">
</p>


<p>She followed the advice, created a second email and was happy at first. But now she doesn’t even check this mailbox as there are so many spams in it ðŸ’�ðŸ�»â€�â™€ï¸�.</p>

<p>So creating a second email is not a true solution. She needs more than 2, maybe hundreds. <strong>And why not an email for each website</strong>? But she cannot go to Gmail or Outlook to create hundreds of accounts, this is unmanageable. There must be a better way.</p>

<p>The solution is <code>email alias</code>. An alias is a normal email address but all emails sent to an alias will be <strong>forwarded</strong> to your real email address. Alias acts therefore as a <strong>shield</strong> (or a proxy) for your real email address. An alias can be disabled anytime, making the spams stop.</p>

<p>Nowadays, some websites allow to unsubscribe quickly but a lot of them still make unsubscribing a difficult process. Some wouldn’t even honor the request. And this doesn’t stop the websites from cross-referencing your data with your email being the common key.</p>

<p>Let’s make spammers’ life harder with email alias!</p>


        <p>
            Written by <img src="https://simplelogin.io/images/son.jpg" alt="Author Image">
            Son Nguyen Kim
            <a href="https://twitter.com/nguyenkims">
                [Follow on Twitter]
            </a>
        </p>


        
        <h3>Other posts</h3>
        
        


        <hr>
        <div>
            <p>Wonder why you received so many spams? Protect your email address with SimpleLogin alias. </p>
            <p><span>
                <a href="https://simplelogin.io/">Learn More</a>
            </span>
        </p></div>
    </div>
</div></div>]]>
            </description>
            <link>https://simplelogin.io/blog/an-email-for-each-website/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25241372</guid>
            <pubDate>Sat, 28 Nov 2020 23:11:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Isetta: Writing a Game Engine from Scratch]]>
            </title>
            <description>
<![CDATA[
Score 136 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25241361">thread link</a>) | @da_big_ghey
<br/>
November 28, 2020 | https://isetta.io/blogs/week-0/ | <a href="https://web.archive.org/web/*/https://isetta.io/blogs/week-0/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div data-md-component="container">
          
            
              
            
            
              
            
          
          <div>
            <article>
              
                
                
                
<h2 id="introduction">Introduction<a href="#introduction" title="Permanent link">¶</a></h2>
<p>The Isetta Engine is a student-driven project about demystifying game engine development and providing a roadmap and relevant knowledge for novice developers. To do so, <a href="https://isetta.io/team/">our team</a> will make a game engine by ourselves starting from a collection of base frameworks, and document the process, pitfalls, and advice for our audience with periodic blogs. Besides that, we will conduct interviews with experienced professionals to augment our novice perspective. We believe the novice perspective from our blogs and expert perspective from the interviews will nicely come together and form a complete document to help people get started. </p>
<p>The reason we think more work needs to be done in this field is that too many game engine developers wait until the completion of the engine, typically years, to talk about their development. For studios, this is because they consider the final product to be the game, not the engine. For others, it may be because the engine is what they see as valuable, not the writing. As a result, these talks typically lose the minutiae of the actual daily struggles that took place in the development process. There are others who document their development which has been going on for years, which makes it a daunting task for newcomers to start following along. </p>
<p>Although the project is aimed at helping novice developers, this is not to be used as a sole source of learning engine development. Being new engine developers ourselves, we can't guarantee the way we develop the engine will be correct, which is why interviews will help the project remain grounded. This means others who are learning can use what we've done as a guide and not necessarily the ground truth. The blogs won't be a walkthrough/tutorial/step-by-step instructions on how to develop an engine. We are learning as we go and think our journey is what can be valuable to you. </p>
<h3 id="about-the-project">About the Project<a href="#about-the-project" title="Permanent link">¶</a></h3>
<p>This project is being done as a student-pitched project at the <a href="https://www.etc.cmu.edu/">Entertainment Technology Center</a> (ETC). The ETC is an interdisciplinary Master's degree program at Carnegie Mellon University where students' main focus is working on small teams on a project each semester during a 3-month time period. Throughout the semester, a team's work will be presented to faculty and peers with feedback and critique being presented to help aid in the project development. Our particular project idea has gone through multiple iterations to do the following:</p>
<ol>
<li>Simplify the engine to be feasible within 3 months and</li>
<li>Deliver content that would be useful, and hopefully enjoyable, to consume.</li>
</ol>
<p>As of writing this, we've learned that creating content that will satisfy both is difficult and time-consuming, so we will be focusing on writing these milestone-type blogs as well as posting various types of content to test which is the best form of presenting our work. The short project duration also forces us to think clearly about our scope and be lean on the features we include before starting. </p>
<h3 id="schedule">Schedule<a href="#schedule" title="Permanent link">¶</a></h3>
<p>During the course of this project <strong>(08/26 - 12/16, 2018</strong>), a blog post will be published every week to share our thoughts and process, and an interview will be published every 1-2 weeks. The interview schedule depends on our progress on the engine itself, as each interview's topic will be themed around our current work.</p>
<p>For latest schedule, see our <a href="https://isetta.io/schedule/">schedule</a> page.</p>
<h3 id="prerequisites">Prerequisites<a href="#prerequisites" title="Permanent link">¶</a></h3>
<p>Although we will cover some basic features of engine development, it will profoundly help if you have experience in C++ programming and developing software, especially games, as our project won't provide step-by-step instructions on how to do everything. For a list of resources on how to gain related knowledge, please go to the <a href="#Readings">Readings</a> section. Additional resources will be posted on our <a href="https://isetta.io/resources/">resource page</a>.</p>
<p>Another prerequisite is passion for learning game engine development. As you are still reading this, we assume you are as excited about this as we are. This will be a bumpy ride, but you will have us on your side.</p>
<h2 id="research">Research<a href="#research" title="Permanent link">¶</a></h2>
<p>Being a student-pitched ETC project means that the project needed to pass through a pitch process of consulting and convincing faculty in the program. This allowed us to receive feedback about what could be considered a reasonable/manageable scope and where we might hit challenges for a general project. For this project to be a valid ETC project as well as accomplish our mission statement, there needs to be a fine balance between documentation and development. </p>
<p>Before confronting the big monster of engine development and documentation, we thought it would be a good idea to gear up by getting input from people who have actually done this. During our pitch process, we reached out and got the chance to talk to numerous industry professionals and got extremely helpful advice from them. All of these suggestions helped us shape our project into what it is now and provided invaluable knowledge on how to start a game engine. Thus we encourage you, too, to approach professionals and get advice if possible. We've compiled our notes from our conversations with them into a write-up, which will be published soon.</p>
<h3 id="why-another-engine">Why another engine?<a href="#why-another-engine" title="Permanent link">¶</a></h3>
<p>Using an existing game engine like <a href="https://unity3d.com/">Unity</a>, <a href="https://www.unrealengine.com/en-US/what-is-unreal-engine-4">Unreal</a> or <a href="https://www.panda3d.org/">Panda3D</a> is always a handy option to make a game. These well-established engines have a strong collection of tools and APIs so that developers can focus on making the game, not the wheels. However, there is the limitation of not having full control over all systems in the engine as well as not knowing how the engine is processing the game logic and assets. These can obstruct the complex systems of an engine, so although you may have an understanding of how a physics or graphics engine works, each engine operates differently and optimizes for different constraints. </p>
<p>In terms of learning about game engines and how to develop one, these established engines aren't a good source. Panda3D, originally developed by Disney and expanded by past ETC projects, has an older codebase in 2018 with limited community involvement. It is also not using the current industry standard language (C++). Unity and Unreal are both too massive and too cutting-edge to be suitable engine learning material for novices. In addition, Unity's source code isn't publicly available so you technically can't learn from it. The huge codebase sets a high threshold for any beginner to get started.</p>
<h2 id="roadmap">Roadmap<a href="#roadmap" title="Permanent link">¶</a></h2>
<p>The Isetta Engine will support the most primitive form of networked multiplayer twin-stick shooter game. Networked multiplayer was selected to be a part of the engine because it offers significant design and development challenge on every level of the project, and will help differentiate this engine from others being developed. We decided to create the engine in 3D for two reasons: Most AAA engines are 3D, and 3D requires more math and problem solving for us as developers to learn and grow from.</p>
<p>While planning, and before we knew too much about game engines, we had a basic idea of what a game engine would consist of. The image below displays the second/third iteration of what the Isetta engine would look like. We were initially naive thinking we may be able to do both networking as well as physics, however quickly came to grips that would balloon the scope too much. The audio and graphics were and are still planned to be imported from external libraries, and more of the discussion of what is imported and why will be included in a future blog. This diagram of the engine will soon be replaced with more in-depth explanations.</p>
<p><img alt="alt_text" src="https://isetta.io/images/blogs/week-0/pitch_architecture.png" title="Engine Architecture During Pitch"></p>
<h3 id="genre">Genre<a href="#genre" title="Permanent link">¶</a></h3>
<p>As for our choice of the twin-stick shooter genre, we came to the decision after lengthy consideration of the components required to build other game types as well as how that genre would utilize multiplayer. Twin-stick shooters can effectively have little to no physics, which is different from collisions (this will be explained in <a href="https://isetta.io/blogs/week-1/">week 1 blog</a>). Likewise, the information passed between networked sessions is relatively minimal and not too strict on latency. What's more, a twin-stick shooter specializes in simplistic gameplay that doesn't need a world editor or too much design. </p>
<p>In a Skype meeting, <a href="https://waltdestler.com/">Walt Destler</a> explained to us that each game -and more particularly, each genre- requires vastly different netcode solutions. This is also one of the reasons why we prefer netcode over physics, as it can greatly narrow down the genre options. For example, multiplayer shooters, specifically PvP shooters, require small amounts of information to be passed (i.e. bullet and player locations) from server to client with relatively low latency. PvP shooters can also feature client-side prediction <sup id="fnref:0"><a href="#fn:0" rel="footnote">1</a></sup> as well as the additional requirement of lobby/matchmaking with usually more than 2 players. On the other hand, genres like turn-based strategy require large amounts of information to be passed (all units, decisions, resources, etc.) to all users without too much concern for latency or prediction.</p>
<h3 id="building-with-an-example-game">Building with an Example Game<a href="#building-with-an-example-game" title="Permanent link">¶</a></h3>
<p>The other piece of advice we frequently heard from professionals and our faculty alike was the benefit of developing a game in conjunction with the engine. Doing so, they explained, allows you to prove and demonstrate your engine works as expected. The game can also test features to show immediate edge cases of the engine. </p>
<p>Another nicety of developing an engine is that feature creep can be prevented when you keep expanding certain features that won't be utilized in the final product. What the game built from this engine <em>won't</em> be is something original or necessarily fun. However, that's not to say a fun, original game couldn't be created from this engine. The idea of our sample game is to intentionally be derivative so features of a basic twin-stick shooter will be already included in the engine, rather than only specific …</p></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://isetta.io/blogs/week-0/">https://isetta.io/blogs/week-0/</a></em></p>]]>
            </description>
            <link>https://isetta.io/blogs/week-0/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25241361</guid>
            <pubDate>Sat, 28 Nov 2020 23:09:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Moronicities of Typography]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25241339">thread link</a>) | @justarandomq
<br/>
November 28, 2020 | http://wordyenglish.com/musing/typography.html | <a href="https://web.archive.org/web/*/http://wordyenglish.com/musing/typography.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>







<p>This article discusses some issues in typography, especially those related to the dash and quotation marks.</p>

<p>I've had some interest in typography since early 1990s of the Mac's Desktop publishing era. Basically, i avidly read books about fontography in libraries or Mac magazines such as MacUser and Macworld, and played with fonts and math typesetting in software such as Microsoft World and Mathematica, including reading Knuth's book on typography and using his TeX system, reading about font technology such as TrueType . So, i am generally acquainted with the concepts and issues of typography, though never worked in any professional area related to it.</p>

<p>I'll have to say, the entire typographical efforts and establishment is rather largely a waste of time, similar in the sense that some “artistic” circles chalk up photography as high art, or that grammarians and pedants have voluminous and vociferous writing style guides and guilds.</p>

<p>Some of the most fartful things the typography-sensitive crowd discuss
or distinguish are: hyphen, en-dash, em-dash,
ligature, kerning, font “design”.
</p>

<p>In general, the function of typography is mainly about issues in printing with respect to the facilitation of reading. So, the major issues involved are: line length, line spacing, serif and sans serif fonts, margin, font sizes, and these pretty much are about it. But since how things are rendered on paper does create differences in the sense of esthetics, sometimes rather pronounced difference, thus typography does indeed have some esthetical elements. However, this is blown out of proportion to stupendous profundity.</p>

<h2>Hyphen and Dash</h2>

<p>Look at these guilded morons go:</p>

<blockquote>

<p>Traditionally an em dash—like so—or spaced em dash — like so — has been used for a dash in running text. The Elements of Typographic Style recommends the more concise spaced en dash – like so – and argues that the length and visual magnitude of an em dash “belongs to the padded and corseted aesthetic of Victorian typography”. The spaced en dash is also the house style for certain major publishers (Penguin, Cambridge University Press, and Routledge among them). However, some longstanding typographical guides such as The Chicago Manual of Style still recommend unspaced em dashes for this purpose. The Oxford Guide to Style (2002, section 5.10.10) acknowledges that …</p>

</blockquote>

<p>The above is from Wikipedia <a target="_blank" href="https://en.wikipedia.org/wiki/Dash">Dash</a>.</p>

<p>Here's my own rule regarding the use of dash: There are 2 kinds: the short dash and the long dash.</p>

<p>For the short one, press the “-” key on your keyboard. For the long one — as a punctuation mark for embedded thought — press it twice. That's it. Simple and functional. And, always include a space around them. (personally, in my writings published on my site, i replace the double dash by a em-dash “—” only because it is prettier, but don't consider it important)</p>

<p>The character “-” you type on your keyboard is the
ASCII 45. (ASCII = American Standard Code for Information Interchange)
[see <a href="http://xahlee.info/comp/unicode_character_representation.html">ASCII Table</a>]
 The character is named “hyphen” in the ASCII standard, but is called “hyphen-minus” by <a href="http://xahlee.info/comp/unicode_index.html">Unicode</a>. (because Unicode has now proper symbols for hyphen, figure-dash, en-dash, em-dash, (math) minus, and quite a few others. Each differ slightly in position, thickness, length.)</p>

<ul>
<li><mark title="U+2D: HYPHEN-MINUS">-</mark> HYPHEN-MINUS</li>
<li><mark title="U+2014: EM DASH">—</mark> EM DASH</li>
<li><mark title="U+2013: EN DASH">–</mark> EN DASH</li>
<li><mark title="U+2012: FIGURE DASH">‒</mark> FIGURE DASH</li>
<li><mark title="U+2212: MINUS SIGN">−</mark> MINUS SIGN</li>
</ul>

<p>As to the typographer's senses and sensibilities about how figure-dash
should be used for numbers and en-dash is used for ranges and em-dash is
for punctuation and hyphen is for word-breaking … etc, i regard them pretty
much all as trifles produced by morons whose brain is inadequate to sense
or tackle the depth of logic and mathematics of languages and structures
but fell into a niche of diddling and went on to procure their efforts
to heighten themselfs among human animals.</p>

<h3>Hypen and Narrow Columns</h3>

<p>For hyphen, as in “breaking a word for words near the margin”, my general advice is to abolish such practice. But what to do in a narrow column of text? My general advice is to abolish the practice of layout using very narrow columns.</p>

<h3>Justification</h3>

<p>
A related concept here is Typographical Justification. My general advice here is to abolish the practice of justification entirely. (leave it jagged at one end; actually as esthetically superior. (and factually functionally superior with regards to reading-facilitation))
</p>

<h4>Ligature</h4>

<p>The typographic conventions of ligatures (as in adjoining certain letter combinations such as “fi” as a single glyph <mark title="U+FB01: LATIN SMALL LIGATURE FI">ﬁ</mark>) should also be abolished.</p>

<h2>Quotation Marks</h2>

<p>Related here is the quotation mark. If you read Wikipedia on
<a target="_blank" href="https://en.wikipedia.org/wiki/Quotation_mark#Summary_table" data-accessed="2020-11-14">Quotation mark#Summary table</a>
, you'll see that there are huge variations. Here's the characters used for quotation.</p>

<table>
<tbody><tr><th>glyph</th><th>Unicode name</th><th>common name</th></tr>
<tr><td><mark title="U+201C: LEFT DOUBLE QUOTATION MARK">“</mark> <mark title="U+201D: RIGHT DOUBLE QUOTATION MARK">”</mark></td><td>LEFT/RIGHT DOUBLE QUOTATION MARK</td><td>Curly double quote</td></tr>
<tr><td><mark title="U+2018: LEFT SINGLE QUOTATION MARK">‘</mark> <mark title="U+2019: RIGHT SINGLE QUOTATION MARK">’</mark></td><td>LEFT/RIGHT SINGLE QUOTATION MARK</td><td>curly single quote</td></tr>
<tr><td><mark title="U+AB: LEFT-POINTING DOUBLE ANGLE QUOTATION MARK">«</mark> <mark title="U+BB: RIGHT-POINTING DOUBLE ANGLE QUOTATION MARK">»</mark></td><td>LEFT/RIGHT-POINTING DOUBLE ANGLE QUOTATION</td><td>French double quote</td></tr>
<tr><td><mark title="U+2039: SINGLE LEFT-POINTING ANGLE QUOTATION MARK">‹</mark> <mark title="U+203A: SINGLE RIGHT-POINTING ANGLE QUOTATION MARK">›</mark></td><td>SINGLE LEFT/RIGHT-POINTING ANGLE QUOTATION</td><td>◇</td></tr>
<tr><td><mark title="U+300E: LEFT WHITE CORNER BRACKET">『</mark> <mark title="U+300F: RIGHT WHITE CORNER BRACKET">』</mark></td><td>LEFT/RIGHT WHITE CORNER BRACKET</td><td>Chinese double quote</td></tr>
<tr><td><mark title="U+300C: LEFT CORNER BRACKET">「</mark> <mark title="U+300D: RIGHT CORNER BRACKET">」</mark></td><td>LEFT/RIGHT CORNER BRACKET</td><td>◇</td></tr>
<tr><td><mark title="U+300A: LEFT DOUBLE ANGLE BRACKET">《</mark> <mark title="U+300B: RIGHT DOUBLE ANGLE BRACKET">》</mark></td><td>LEFT/RIGHT DOUBLE ANGLE BRACKET</td><td>Chinese title bracket</td></tr>
<tr><td><mark title="U+3008: LEFT ANGLE BRACKET">〈</mark> <mark title="U+3009: RIGHT ANGLE BRACKET">〉</mark></td><td>LEFT/RIGHT ANGLE BRACKET</td><td>◇</td></tr>
<tr><td><mark title="U+3016: LEFT WHITE LENTICULAR BRACKET">〖</mark> <mark title="U+3017: RIGHT WHITE LENTICULAR BRACKET">〗</mark></td><td>LEFT/RIGHT WHITE LENTICULAR BRACKET</td><td>Chinese brackets</td></tr>
<tr><td><mark title="U+3010: LEFT BLACK LENTICULAR BRACKET">【</mark> <mark title="U+3011: RIGHT BLACK LENTICULAR BRACKET">】</mark></td><td>LEFT/RIGHT BLACK LENTICULAR BRACKET</td><td>◇</td></tr>
<tr><td><mark title="U+201F: DOUBLE HIGH-REVERSED-9 QUOTATION MARK">‟</mark></td><td>DOUBLE HIGH-REVERSED-9 QUOTATION MARK</td><td>◇</td></tr>
<tr><td><mark title="U+201E: DOUBLE LOW-9 QUOTATION MARK">„</mark></td><td>DOUBLE LOW-9 QUOTATION MARK</td><td>◇</td></tr>
<tr><td><mark title="U+201A: SINGLE LOW-9 QUOTATION MARK">‚</mark></td><td>SINGLE LOW-9 QUOTATION MARK</td><td>◇</td></tr>
</tbody></table>

<p>Here's a list of conventions of using the double curly quotes:</p>

<ul>
<li><mark title="U+201C: LEFT DOUBLE QUOTATION MARK">“</mark> … <mark title="U+201D: RIGHT DOUBLE QUOTATION MARK">”</mark> UK, USA, Canada, Irish, …</li>
<li><mark title="U+201D: RIGHT DOUBLE QUOTATION MARK">”</mark> … <mark title="U+201D: RIGHT DOUBLE QUOTATION MARK">”</mark> Swedish, Finnish, …</li>
<li><mark title="U+201E: DOUBLE LOW-9 QUOTATION MARK">„</mark> … <mark title="U+201C: LEFT DOUBLE QUOTATION MARK">“</mark> German, Bulgarian, Croatian, Czech, Estonian, Icelandic, Lithuanian, Romanian, Serbian, Slovak, Slovene, Sorbian, …</li>
<li><mark title="U+201E: DOUBLE LOW-9 QUOTATION MARK">„</mark> … <mark title="U+201D: RIGHT DOUBLE QUOTATION MARK">”</mark> Dutch, Polish, Hungarian, …</li>
</ul>

<p>Ain't it bizarre?</p>

<p>For some languages, such as Chinese, it is rational how it
developed into using symbols (e.g. 『』「」《》〈〉【】〖〗) that are
different from European languages's curly quotation marks. However,
among European langs, there are extreme diversity in using the curly
quotation marks. Even the American and English reverse the purpose of
the single and double quotes. Some lang reverses the semantics of the
left/right pair, some lang positions the mark at the bottom instead of
top, some place them in opposite corners (as opposed to both on top),
some lang use the same symbol for both the opening and closing
marker.</p>

<p>One thing interesting about the curly double quotation mark pair is that the two symbols are not bilateral symmetric, but is rotational symmetric. That is, if you rotate the left one 180 degrees, you get the right one. Most other matching pair symbols ()[]{} are bilaterally symmetric (i.e. there is a horizontal line of mirror reflection, and the left/right symbols are vertical mirror reflection of each other.). The fact that the curly quotes have only rotational symmetry, must have contributed significantly the weird diversity in their role as the choice in the opening/closing mark and whether to position them level on a line or at opposite corners. (Note that the Chinese corner brackets 『』「」 also lack a bilateral symmetry, however, their box-corner shape intuitively and uniquely define their placements.)</p>

<h3>Combinatorial Possibilities</h3>

<p>This glyph <mark title="U+201C: LEFT DOUBLE QUOTATION MARK">“</mark> (U+201C) points upper-right. This glyph can be mirrored in a vertical line or horizontal line to create the matching variation, a total of 4 possibilities (think of p q b d).</p>

<p>Here are the different pointing curly quotes from Unicode: <mark title="U+201C: LEFT DOUBLE QUOTATION MARK">“</mark> <mark title="U+201D: RIGHT DOUBLE QUOTATION MARK">”</mark> <mark title="U+201F: DOUBLE HIGH-REVERSED-9 QUOTATION MARK">‟</mark>.</p>

<p>In Unicode, i couldn't find one that is pointing to upper-left. This is
somewhat curious. (If you look at the Wikipedia article on quotation
conventions, you see that actually no language use such a char.)
</p>

<p>I created one with
image here just for the illustration:
<img src="http://wordyenglish.com/musing/i/double_curly_quote_upleft.png" alt="double curly quote upleft.png"></p>

<p>The quotation mark can be placed on the upper line of the text (as in USA convention) or lower line (as in the beginning quotation mark in German convention), a total of 2 possibilities.</p>

<p>So, 4 choices of glyph orientation, 2 possible positions, that's 8 possibilities for the opening quote. Same for the closing quote. So, the total number of styles to use the quotation punctuation with double curly quote is 8×8=64.</p>

<p>It is a good thing that this hasn't been exploited.</p>

<h3>How it should be</h3>

<p>The function of quotation marks is to demarcate text, and as such delimiters, it should be a matching pair such as ( ) [ ] { }, and the pair should have no more than a bilateral symmetry to reflect the natural one-dimensional left/right flow of written text (or, up/down in Asian langs).</p>

<p>If we can rewrite convention, i'd say we all just use simple left/right pairs such as ()[]{}. Since these already have a purpose, then we could use ‹›«»〈〉《》【】〖〗. The French quotation marks « » ‹ › is actually the most sensible here among western langs. (though, other countries using French quotation mark also reverse direction or use the same glyph for both opening and ending. This is idiocy gone berserk.)</p>

<p>But since we cannot restart history nor do we want to break convention radically because we'd create confusion, what i do today personally of writings published on my website, is to use the most ubiquitous convention, the American convention “like this”. (I experimented in using the French convention of «like this», but that turns out to be too in-your-face for English readers)</p>

<h2>Problem of Non-matching Straight Quotation Marks</h2>

<p>It is unfortunate, thru the historical development of the typewriter and the computer keyboard and ASCII, that our keyboard doesn't have the proper matching curly quotes, but instead, has the straight quotes. Here's the symbols and their Unicode name:</p>

<!-- " -->

<ul>
<li>QUOTATION MARK (ASCII 34; U+0022):<mark title="U+22: QUOTATION MARK">"</mark> (double straight quote)</li>
<li>APOSTROPHE (ASCII 39; U+0027):<mark title="U+27: APOSTROPHE">'</mark> (single straight quote)</li>
<li>GRAVE ACCENT (ASCII 96; U+0060):<mark title="U+60: GRAVE ACCENT">`</mark> (backtick)</li>
</ul>

<p>This creates a problem because it forces us to use the same symbol
for a purpose that naturally calls for a matching pair. Using a
single symbol is harder to read. Further, it causes global damage when
one is missing (e.g. caused by typo or transmission error).</p>

<p>It would've been better, if the typewriter was designed with a matching single curly quote. That is, …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://wordyenglish.com/musing/typography.html">http://wordyenglish.com/musing/typography.html</a></em></p>]]>
            </description>
            <link>http://wordyenglish.com/musing/typography.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25241339</guid>
            <pubDate>Sat, 28 Nov 2020 23:06:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thank You, Tony]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25241102">thread link</a>) | @sethbannon
<br/>
November 28, 2020 | https://elizabethyin.com/2020/11/28/thank-you-tony/ | <a href="https://web.archive.org/web/*/https://elizabethyin.com/2020/11/28/thank-you-tony/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-4860">
	
	<!-- .entry-header -->

	<div>
		
<p>Coincidentally enough, I had decided that I wanted to write a letter to my mentor Tony this weekend, thanking him for the huge impact he’s had on my life. But I suppose that has now morphed into a more public letter. </p>



<p>Being in a zombie, half blurry-eyed state, it’s a little tough to articulate well what Tony has meant to me. We go through life, and a lot of people have an impact on us, and it’s often hard to say that a particular person caused you to take a particular path. But, Tony is one of the few people whom I can definitely say my life would not at all be what it is without him. </p>



<p>I first met him many years ago in Dec 1996 when I was just starting high school. My best friend Jennifer asked me what I was doing for winter break and if I wanted to help out her cousin Tony with his new internet startup. I had no idea what an internet startup was, but I had nothing going on, so I agreed to go. </p>



<p>On the first day of our holiday break, Jennifer and I hopped on the Caltrain from the peninsula (Silicon Valley) to head to his office in SOMA (San Francisco). It was exciting! We couldn’t drive, but we could go to a startup office all by ourselves! I followed Jennifer to the address. I think their office was actually someone’s apartment. And when we got there, there seemingly was no one there. We hung around for a while, and maybe about 10am or so some people started to trickle in – this was my introduction to startup life. </p>



<p>Tony had more or less just graduated from Harvard, as he had spent a few short months at Oracle after graduation, and then decided to quit to build his own company LinkExchange. Leaving a big employer so quickly was highly unusual back then, and he would go on to do many non-conforming things that he was right about. </p>



<p>LinkExchange was an ad network. If you had a website and hosted LinkExchange ad banners, for every 2 impressions you generated, you received 1 free impression of your banner. Back then because the internet was still new, people paid attention to banners and clicked on them like crazy, so this was incredibly effective in helping generate traffic for people. LinkExchange would then sell the remaining ad impressions. They had launched the service earlier that year, and by that December, they were already growing like crazy. </p>



<p>I definitely was *not helpful*. We put together some tables and chairs. And made ethernet cables from scratch. Yes, from scratch. We had to cut cables, splice the individual wires, and insert them into plastic tips and crimp them. I was terrible at this, and Jennifer largely fixed all of my mistakes (as always). Since I was so bad at the ethernet cable making process, they asked me to help them put together an internal webpage to keep all their meetings / schedule together. Great! I could put my basic HTML skills to use. I don’t think they liked the amateurish turquoise background that I chose, so someone at LinkExchange quickly fixed it. </p>



<p>I was more of a nuisance than help, but what I saw that day was super inspiring. Here were a bunch of friends who were getting together to build things. They could wear whatever they wanted, saunter in whenever they wanted, and eat all the pizza they wanted. And they all had varied tasks and were taking business meetings in what looked like a kitchen? There was never a dull moment. It was the dream. Neither of my parents worked in tech and certainly not startups, so this was incredibly eye-opening, and immediately, I knew that this was what I was going to do when I grew up – become an entrepreneur and start companies. Without this exposure to startups in 1996, I don’t think I would have made this realization (if at all) for many years.</p>



<p>Fast forward a few years later. Microsoft bought LinkExchange just 2 years later for a reported $265m. Tony and his college friend Alfred (who also was at LinkExchange) decided to start a startup incubator with their own money. (As a side note, the food at their restaurant in this incubator was fantastic!) This was bold and unique, because Idealab was really the only one doing something somewhat similar at the time. The concept of accelerators or incubators would not come in a big way until years later. </p>



<p>I don’t think Tony knew this, but while in high school, I cold-emailed almost every single one of his portfolio companies to ask them for an internship. I was determined to work at a startup as soon as possible in high school and start my startup career. I ended up working at one of his portfolio companies (probably unbeknownst to him) in the summer of 2000 which really help set me on my path to a career in startups. Often that first opportunity is the hardest to land, and each subsequent opportunity opens more and more doors.</p>



<p>By late 2000, the stock market had crashed and everyone was fleeing startups. Newspapers ran headlines saying that tech was dead and that all programming jobs would be outsourced. They couldn’t have been more wrong, but most people panicked and stopped investing in startups. Tony, was always a first-principles thinker, and he leaned into this and ended up co-leading one of his portfolio companies Zappos. As an e-commerce company that provided free shipping and free returns, Zappos’ margins were razor thin. This scared most VCs. (This would certainly scare me.) But, he believed that it could work if customers had a great experience and would become repeat customers. So, he poured a lot of his own capital into the business when no VC at the time would touch this company. While many VCs pontificate about high level things, he looked at problems from a bottom’s up approach which made his thinking often unique from others. </p>



<p>In order to make the Zappos model work, he needed customer service to be top notch, reliable, and have a lower cost. It was clear to him that this model wouldn’t work in pricey San Francisco. So, he made another bold decision to move the company to Henderson, NV, which could provide all of those things. This was at a time when certainly most people believed you can only build an internet business in the San Francisco Bay Area. In hindsight, when they ended up needing to hire tons of people, being the BEST internet company in the Las Vegas area allowed them to swoop up talent that would have been a huge war to win in San Francisco.  The other thing that was apparent to me, is that the Zappos family was incredibly diverse — and free to be themselves. Tony’s attention to culture and cultivating an open and welcoming work family left a lasting impact on me, and he started doing this well before it became a trend. Like so many of you, his book <em>Delivering Happiness</em> has affected my own thinking.</p>



<p>Fast forward many years, Jennifer and I were working on our own startup, and we were grappling with a particular challenge. We decided to consult Tony and get his advice. In a very Tony-like way, he basically told us to do what we thought was best. I remember feeling frustrated at the time, because…I didn’t know what was best! I had wanted him to tell me what he thought was best! But a good mentor helps you find your own answer – he/she doesn’t tell you the answer.  </p>



<p>In that meeting, he also pulled out a book and told me to read it. The book was <em>Start with Why</em> by Simon Sinek. So I read it. The gist of the book is that to build a great company, you need to go back to first principles. Most people start building a company by trying to sell their product details. “Buy my shoes! They are grey with stripes.” But customers, employees, and everyone want to rally around something much bigger — something inspirational that the company stands for. It actually took me many years to process this and actually figure out how to implement this — I didn’t get this right for LaunchBit, but after marinating on this advice for years, this is what we’ve been striving to do at Hustle Fund. We aren’t just capital deployers. We are trying to create a movement and a philosophy. That particular meeting with Tony is one that I play in my head over and over – I feel like I finally understand what he was getting at and that is what I most wanted to tell him this weekend. </p>



<p>If cynics believe that it’s impossible to get ahead in life without being an asshole, Tony Hsieh is a good example of someone who defies the norm. He was never flashy and always kind and generous to all. I could go on and on in writing this, but thank you, Tony, for helping me in so many ways that you may not have been aware. For your kindness, generosity, and inspiration.</p>



<p>Sending big hugs to the entire Hsieh family whom I consider to be my second family and who took me in during my formative years and had a huge impact on who I am today.</p>
	</div><!-- .entry-content -->

	
	<!-- .entry-footer -->

</article></div>]]>
            </description>
            <link>https://elizabethyin.com/2020/11/28/thank-you-tony/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25241102</guid>
            <pubDate>Sat, 28 Nov 2020 22:31:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Growl in Retirement]]>
            </title>
            <description>
<![CDATA[
Score 440 | Comments 228 (<a href="https://news.ycombinator.com/item?id=25241030">thread link</a>) | @flyingyeti
<br/>
November 28, 2020 | http://336699.org/GrowlRetirement | <a href="https://web.archive.org/web/*/http://336699.org/GrowlRetirement">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="container">
  <article id="8GugXoUrk4po3a8J7EZnDS">
	<time datetime="2020-11-28">November 28, 2020</time>
  
	<p>Growl is being retired after surviving for 17 years. With the announcement of Apple’s new hardware platform, a general shift of developers to Apple’s notification system, and a lack of obvious ways to improve Growl beyond what it is and has been, we’re announcing the retirement of Growl as of today.</p>

<p>It’s been a long time coming. Growl is the project I worked on for the longest period of my open source career. However at WWDC in 2012 everyone on the team saw the writing on the wall. This was my only WWDC. This is the WWDC where Notification Center was announced. Ironically Growl was called Global Notifications Center, before I renamed it to Growl because I thought the name was too geeky. There’s even a sourceforge project for Global Notifications Center still out there if you want to go find it.</p>

<p>We’ve had a lot of support over the years; from our hosting providers at <a href="http://www.networkredux.com/">Network Redux</a>, <a href="http://www.cachefly.com/">CacheFly</a> and others, to all of the apps using our framework, bindings, or any other integration. Special thanks go to <a href="https://adium.im/">Adium</a> and <a href="https://colloquy.app/">Colloquy</a>. Without these two projects having developers who wanted different types notifications, Growl wouldn’t have existed. Without Growl I do not know that we would have any sort of decent notification system in OS X, iOS, Android or who knows what else. </p>

<p>Special thanks goes to <a href="https://www.transifex.com/">Transifex</a> who made localizing into 24 languages a lot easier than anything else we tried. It’s a fantastic product, if you make software please try it. Our localizers were fantastic people and should all be commended for their work. </p>

<p>For developers we recommend transitioning away from Growl at this point. The apps themselves are gone from the app store, however the code itself still lives. Everything from our rake build system to our code is available for use on our <a href="https://github.com/growl/growl/">GitHub page</a></p>

  <figure id="kudo_8GugXoUrk4po3a8J7EZnDS">
    <a href="#kudo">
      
    </a>
    <p>1,802</p>
    <p>Kudos</p>
  </figure>
  <figure id="kudo_side_8GugXoUrk4po3a8J7EZnDS">
    <a href="#kudo">
      
    </a>
    <p>1,802</p>
    <p>Kudos</p>
  </figure>
</article>

</section></div>]]>
            </description>
            <link>http://336699.org/GrowlRetirement</link>
            <guid isPermaLink="false">hacker-news-small-sites-25241030</guid>
            <pubDate>Sat, 28 Nov 2020 22:19:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Blogging vs. Blog Setups]]>
            </title>
            <description>
<![CDATA[
Score 258 | Comments 105 (<a href="https://news.ycombinator.com/item?id=25240939">thread link</a>) | @Kye
<br/>
November 28, 2020 | https://rakhim.org/honestly-undefined/19/ | <a href="https://web.archive.org/web/*/https://rakhim.org/honestly-undefined/19/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Hi, I'm Rakhim. I teach, program, make podcasts, comics and videos on computer science at <a href="https://codexpanse.com/">Codexpanse.com</a>. You can learn more about <a href="https://rakhim.org/about">my work</a> and even <a href="https://www.patreon.com/rakhim">support me</a> via Patreon.</p><p><form action="https://buttondown.email/api/emails/embed-subscribe/rakhim" method="post" target="popupwindow" onsubmit="window.open('https://buttondown.email/rakhim','popupwindow')"><label for="bd-email">Oh, and I have a monthly non-spammy personal newsletter:</label><br>

</form></p><nav><p><a href="https://rakhim.org/">Home</a>
<span>|</span>
<a href="https://blog.rakhim.org/">Blog</a>
<span>|</span>
<a href="https://rakhim.org/about">About</a>
<span>|</span>
<a href="https://codexpanse.com/">Courses</a>
<span>|</span>
<a href="https://rakhim.org/talks">Talks</a>
<span>|</span>
<a href="https://rakhim.org/honestly-undefined">Comics</a>
<span>|</span>
<a href="https://rakhim.org/bookshelf">Bookshelf</a>
<span>|</span>
<a href="https://www.youtube.com/c/codexpanse">YT</a>
<span>|</span>
<a href="https://twitter.com/freetonik">TW</a>
<span>|</span>
<a href="https://rakhim.org/index.xml">RSS</a></p></nav><p>© Rakhim Davletkaliyev, 2020<br>Powered by <a href="https://gohugo.io/">Hugo</a>, <a href="https://www.netlify.com/">Netlify and the Everett interpretation of QM.</a></p></div></div>]]>
            </description>
            <link>https://rakhim.org/honestly-undefined/19/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25240939</guid>
            <pubDate>Sat, 28 Nov 2020 22:03:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Evolution of tree data structures for indexing: more exciting than it sounds]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25240883">thread link</a>) | @erthalion
<br/>
November 28, 2020 | https://erthalion.info/2020/11/28/evolution-of-btree-index-am/ | <a href="https://web.archive.org/web/*/https://erthalion.info/2020/11/28/evolution-of-btree-index-am/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p><span>28 Nov 2020</span></p><h2 id="0-how-to-read-me">0. How to read me?</h2>
<p>I have to admit, my research blog posts are getting longer and longer. From one
side I find it genuinely encouraging, because if one gets so much information
just by scratching the topic, imagine what’s hidden beneath the surface! One
university professor once said “what could be interesting in databases?”, and
it turns out freaking a lot! On the other side it certainly poses problems for
potential readers. To overcome them I would suggest an interesting approach:
print this blog post out, or open it on your tablet/e-reader, where you can
make notes with a pencil or markers. Now while reading it try to spot ideas
particularly exciting for you and mark them. Along the way there would be
definitely some obscure parts or questions, write them on the sides as well.
You can experiment with the diagrams, changing or extending them, or just
drawing funny faces. But do not read everything at once, have no fear of
putting it aside for a while, and read in chunks that are convenient for you.
Some parts could be skipped as the text is build out of relatively independent
topics. The table of contents can help and guide you. Having said that we’re
ready to embark on the journey.</p>
<ul>
<li>
<a href="#1-introduction">Introduction</a>
</li>
<li>
<a href="#2-rum-conjecture">RUM conjecture</a>
</li>
<li>
<a href="#3-b-tree-basics">B-tree basics</a>
</li>
<li>
<a href="#4-beyond-the-hard-leaves-of-basics">Beyond the hard leavers of
basics</a>
<ul>
<li>
<a href="#41-key-normalization">Key normalization</a>
</li>
<li>
<a href="#42-prefix-truncation">Prefix truncation</a>
</li>
<li>
<a href="#43-dynamic-prefix-truncation">Dynamic prefix truncation</a>
</li>
<li>
<a href="#44-suffix-truncation">Suffix truncation</a>
</li>
<li>
<a href="#45-indirection-vector">Indirection vector</a>
</li>
<li>
<a href="#46-sb-tree">SB-tree</a>
</li>
</ul>
</li>
<li>
<a href="#5-why-is-it-not-enough">Why is it not enough?</a>
<ul>
<li>
<a href="#51-partitioned-b-tree">Partitioned B-tree</a>
</li>
<li>
<a href="#52-hybrid-indexes">Hybrid indexes</a>
</li>
<li>
<a href="#53-bw-tree">Bw-Tree</a>
</li>
<li>
<a href="#54-dptree">DPTree</a>
</li>
</ul>
</li>
<li>
<a href="#6-trie">Trie</a>
</li>
<li>
<a href="#7-learned-indexes">Learned indexes</a>
</li>
<li>
<a href="#8-is-that-all">Is that all?</a>
</li>
<li>
<a href="#references">References</a>
</li>
</ul>
<h2 id="1-introduction">1. Introduction</h2>
<p>Whenever we speak about indexes, especially in PostgreSQL context, there is a
lot to talk about: B-tree, Hash, GiST, SP-GiST, GIN, BRIN, RUM. But what if I
tell you that even the first item in this list alone hiding astonishing number
of interesting details and years of research? In this blog post I’ll try to
prove this statement, and we will be concerned mostly with B-tree as a data
structure.</p>
<p><img src="https://erthalion.info/public/img/btree-joke.png" width="80%"></p>

<p>Let’s start systematically and take a look at the definition first:</p>
<blockquote>
<p>B-tree is a self-balancing tree data structure that maintains sorted data and
allows searches, sequential access, insertions, and deletions in logarithmic
time.</p>
</blockquote>
<p>What is your first association with the concept of B-tree? Mine is “old and
well researched, or in other words boring”. And indeed apparently it was first
introduced in <a href="https://infolab.usc.edu/csci585/Spring2010/den_ar/indexing.pdf">1970</a>! Not only that, already in 1979 they
were <a href="http://cgi.di.uoa.gr/~ad/M149/ubiquitous_btree.pdf">ubiquitous</a>. Does it mean there is nothing exciting left any
more? Once upon a time I came across a remarkable read called
<a href="https://dl.acm.org/doi/10.1561/1900000028">Modern B-Tree techniques</a> which inspired me to dig
deeper into the topic and read bunch of shiny new whitepapers. Afterwards
totally by chance I’ve stumbled upon a book “Database Internals: A Deep Dive
into How Distributed Data Systems Work”, which contains great sections on
B-tree design. Both works were the triggers to write this blog post. What was I
saying about nothing exciting left? At the end I couldn’t be more wrong.</p>
<p>It turns out that there are multitude of interesting ideas and techniques
around B-Trees. They’re all coming from the desire to satisfy different (often
incompatible) needs, as well as adapt to emerging hardware. To demonstrate how
many of those exist, lets play a game. Below you can find a table of names I’ve
found in various science papers, together with a couple of silly names I’ve
come up myself. Can you find out the fake ones?</p>
<table>
<tbody>
<tr>
<td>B-tree</td>
<td>B<sup>+</sup>-tree</td>
<td>B<sub>link</sub>-tree</td>
<td>DPTree</td>
</tr>
<tr>
<td>wB<sup>+</sup>-tree</td>
<td>NV Tree</td>
<td>FPTree</td>
<td>FASTFAIR</td>
</tr>
<tr>
<td>HiKV</td>
<td>Masstree</td>
<td>Skip List</td>
<td>ART</td>
</tr>
<tr>
<td>WORT</td>
<td>CDDS Tree</td>
<td>Bw Tree</td>
<td>HOT</td>
</tr>
<tr>
<td>KISS Tree</td>
<td>VAST Tree</td>
<td>FAST</td>
<td>HV Tree</td>
</tr>
<tr>
<td>UB Tree</td>
<td>LHAM</td>
<td>MDAM</td>
<td>Hybrid B<sup>+</sup> Tree</td>
</tr>
</tbody>
</table>

<p>Any ideas? Well, I have a confession to make – all of them are real, I just
don’t have enough imagination to come up with such names. Having this in mind
hopefully you understand that if we want to make a survey, the first step would
be to establish some classification. Not only this will help us to structure
the material, but also will explain why on earth anyone would need to invent so
many variations of what we though was so simple!</p>
<h2 id="2-rum-conjecture">2. RUM conjecture</h2>
<p>To classify different index access methods we need to think about the following
ambitious question – is there anything common between almost any index access
method? The authors of <a href="https://stratos.seas.harvard.edu/files/stratos/files/rum.pdf">RUM conjecture</a> provide an interesting
insight about this topic:</p>
<blockquote>
<p>The fundamental challenges that every researcher, systems architect, or
designer faces when designing a new access method are how to minimize, i)
read times, ii) update cost , and iii) memory (or storage) overhead.</p>
<p>In this paper, we conjecture that when optimizing the read-update-memory
overheads, optimizing in any two areas negatively impacts the third</p>
</blockquote>
<p>This essentially states that if an index access method could be specified as a
point inside “Read”, “Update” (on the Fig. 1 it’s called “Write” for
convenience of drawing), “Memory” space we can observe an interesting
invariant. Every time we modify one index access method to have less overhead
for reading or memory footprint (i.e. shift the corresponding point closer to
“Read”/”Memory” corners), we inevitably loose on the updating workload (i.e.
getting further away from “Write” corner).</p>
<figure>
<img src="https://erthalion.info/public/img/rum.png" width="50%">
<br>
<figcaption>
Fig 1. RUM space
</figcaption>
</figure>
<p>In fact as a non-scientist I would even speculate that there should be another
dimension called “Complexity”, but the idea is still clear. I will try to show
this invariant at work via examples in this blog post, but it already gives us
some ground under the feet and opportunity to visually represent different
versions of B-tree by moving point on the triangle back and forth. But first
let’s recall the basics.</p>
<h2 id="3-b-tree-basics">3. B-tree basics</h2>
<p>So what is B-tree? Well, it’s a tree data structure: a root node, some number
of branch nodes (marked grey) and a bunch of leaf nodes (marked green):</p>
<figure>
<img src="https://erthalion.info/public/img/btree.png" width="100%">
<br>
<figcaption>
Fig 2. B-tree nodes arrangement
</figcaption>
</figure>
<p>Every node of this tree is usually a page of some certain size and contains
keys (shaded slices of a node) and pointers to other nodes (empty slices with
arrows). Keys on page are kept in sorted order to facilitate fast search within
a page.</p>
<p>The original B-tree design assumed to have user data in all nodes,
branch and leaf. But nowadays the standard approach is a variation called
B<sup>+</sup>-tree, where user data is present only in leaf nodes and branch
nodes contains separator keys (pivot tuples in PostgreSQL terminology). In this
way separation between branch and leave nodes become more strict, allowing
better flexibility for choosing format of former and making deletion operations
can affect only latter. In fact the original B-tree design is barely worth
mentioning these days and I’m doing this just to be precise. Since
B<sup>+</sup>-tree is sort of default design, we’ll use B-tree and
B<sup>+</sup>-tree interchangeably in this text from now on. An interesting
thing to mention here is that the only requirements for separator keys is to
guide search algorithm to a correct leaf node. As long as they fulfil this
condition they can contain anything, no other requirements exist.</p>
<p>Strictly speaking, only child pointers are truly necessary in this design, but
quite often databases also maintain additional neighbour pointers, e.g. what you
can see on the Fig. 2 between the leaf nodes. It could be helpful for some
operations like index scan, but need to be taken into account for node
split/merge operations. PostgreSQL uses <a href="https://www.csd.uoc.gr/~hy460/pdf/p650-lehman.pdf">Lehman-Yao</a> version,
called B<sub>link</sub>-tree, with links to both left and right sibling nodes
(the left link one is actually not presented in the original
B<sub>link</sub>-tree design, and it makes backward scan somewhat interesting),
and there are even implementations like WiredTiger with
<a href="https://github.com/wiredtiger/wiredtiger/blob/f08bc4b18612ef95a39b12166abcccf207f91596/src/include/btmem.h#L550">parent pointers</a>.</p>
<p>Having all this in place one can perform a search query by following the path
marked red on the Fig. 2, first hitting the root, finding a proper separator
key, following a downlink and landing on a correct page where we deploy binary
search to find the resulting key.</p>
<p>Until now, we were talking only about static parts of B-tree design, but of
course there is more to it. For example there is one dynamic aspect of much
importance (quite often it even scares developers like a nightmare), namely
page splits. What do we need to do when there is a new value to insert, but the
target page does not have enough space like on the following diagram?</p>
<figure>
<img src="https://erthalion.info/public/img/page-split-1.png" width="60%">
<br>
<figcaption>
Fig 3. B-tree page split (a)
</figcaption>
</figure>
<p>What happens here is we’re trying to insert the new value (shaded box) into the
page with not enough space for it. To maintain the three balanced we need to
allocate another leaf page, distribute keys between old and new leaf, promote a
new separator key into the parent page and update all required links
(left/right siblings if present):</p>
<figure>
<img src="https://erthalion.info/public/img/page-split-2.png" width="60%">
<br>
<figcaption>
Fig 4. B-tree page split (b)
</figcaption>
</figure>
<p>Curiously enough the new separator key could be chosen freely, it could be any
value as long as it separates both pages. We can see what does it change in the
optimization section.</p>
<p>Locking is obviously an important part of a page split. No one wants to end up
with concurrency issues when pages get updated while in the middle of a split,
so a page to be split is write-locked as well as e.g. right sibling to update
left-link if present.</p>
<p>As you can see, page splits are introducing performance overhead. We need to
bring in a new page, move elements around and everything should be consistent
and correctly locked. And already at this pretty much basic point we already
can see some interesting trade-offs. For example B*-tree modification tries to
rebalance data between neighbouring nodes to postpone page split as long as
possible. In terms of trade-offs it looks like a balance between complexity and
insert overhead.</p>
<p>I didn’t tell you everything about B<sub>link</sub>-tree and it’s going to be our next
topic example in this section. Not only Lehman-Yao version adds a link to the
neighbour, it also introduces a “high key” to each page, which is an upper bound
on the keys that are allowed on page. While obviously introducing a bit memory
overhead those two changes make it possible to detect a concurrent page split
by checking the page high key, which allows the tree to be searched …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://erthalion.info/2020/11/28/evolution-of-btree-index-am/">https://erthalion.info/2020/11/28/evolution-of-btree-index-am/</a></em></p>]]>
            </description>
            <link>https://erthalion.info/2020/11/28/evolution-of-btree-index-am/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25240883</guid>
            <pubDate>Sat, 28 Nov 2020 21:54:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Kotlin (spring boot based) Microservices with Kubernetes and Linkerd]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25240556">thread link</a>) | @sendilkumarn
<br/>
November 28, 2020 | https://sendilkumarn.com/blog/khipster-microservices-k8s-linkerd | <a href="https://web.archive.org/web/*/https://sendilkumarn.com/blog/khipster-microservices-k8s-linkerd">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><blockquote>
<p>KHipster is a development platform to generate, develop and deploy Spring Boot + Angular/React/Vue Fullstack Web applications and Spring microservices. KHipster is built on top of JHipster.</p>
</blockquote>
<p>In this post, we will do the following:</p>
<ul>
<li>Generate microservices with KHipster using JHipster Description Language (JDL)</li>
<li>Generate Kubernetes configuration using JDL</li>
<li>Generate code using KHipster</li>
<li>Create a Kubernetes cluster in GCP</li>
<li>Install Linkerd CLI and deploy Linkerd in Kubernetes cluster</li>
<li>Deploy ingress controller in Kubernetes</li>
<li>Deploy applications in Kubernetes cluster</li>
<li>Configure traffic to application</li>
</ul>
<p>Let us get started.</p>
<h2 id="generate-microservices-with-khipster">Generate Microservices with KHipster</h2>
<h3 id="step-1-install-khipster">Step 1: Install KHipster</h3>
<p>KHipster is available as an NPM package. To install it run:</p>
<div><pre><code>λ npm i -g generator-jhipster-kotlin
</code></pre></div>
<blockquote>
<p>Do not have Node installed? Check out <code>nvm</code> (Node Version Manager) that makes it easy to setup Node - <a href="https://github.com/nvm-sh/nvm/blob/master/README.md" rel="nofollow noopener noreferrer" target="_blank">here</a>.</p>
</blockquote>
<p>Now, verify the installation by running:</p>

<h3 id="step-2-create-jdl-file">Step 2: Create JDL file</h3>
<blockquote>
<p>The JDL is a JHipster-specific domain language.</p>
</blockquote>
<p>JDL provides a DSL to describe the applications, deployments, entities and their relationships. <code>Applications</code> refer to the service as a whole, the application can be a monolith or microservice. The <code>deployments</code> refer to the way to deploy the application it can be <code>kubernetes</code>. The <code>entities</code> straightaway maps to the database table in your application. The <code>relationships</code> refers to the entity relationship <code>one-to-one</code>, <code>one-to-many</code>, etc.,. JDL simplifies the process of creating the microservices applications and entities.</p>
<div><pre><code>// Gateway application
application {
    config {
        applicationType         gateway
        authenticationType      jwt
        baseName                gateway
        buildTool               gradle
        clientFramework         react
        databaseType            sql
        devDatabaseType         h2Disk
        prodDatabaseType        mysql
        packageName             com.sendilkumarn
        serverPort              8080
        serviceDiscoveryType    no
    }
    entities *
} 

// Microservice application
application {
    config {
        applicationType         microservice
        authenticationType      jwt
        baseName                service
        buildTool               gradle
        databaseType            sql
        devDatabaseType         h2Disk
        prodDatabaseType        mysql
        packageName             com.sendilkumarn
        serverPort              8081
        serviceDiscoveryType    no
    }
    entities product
}

// Product entity 
entity product  {
    name    String  required
    price   Long    required
}
</code></pre></div>
<p>We have defined 2 applications: <code>gateway</code> and <code>service</code>, and an entity: <code>product</code>. The major difference between <code>gateway</code> and <code>service</code>:</p>
<ul>
<li><code>gateway</code> uses <code>clientFramework</code> as <code>react</code>, <code>applicationType</code> as <code>gateway</code></li>
<li><code>service</code> uses <code>applicationType</code> as <code>microservice</code></li>
</ul>
<blockquote>
<p>Refer we have used <code>serviceDiscoveryType no</code>, this implies that we are not using serviceDiscovery in the microservices. We will use Linkerd for servicediscovery.</p>
</blockquote>
<blockquote>
<p>Did you know? JHipster supports <code>sql</code> and <code>noSql</code> database and it has many configuration options for generating the applications. Check the entire list of application configuration options <a href="https://www.jhipster.tech/jdl/applications#available-application-configuration-options" rel="nofollow noopener noreferrer" target="_blank">here</a>.</p>
</blockquote>
<h2 id="generate-kubernetes-configuration">Generate Kubernetes configuration</h2>
<p>KHipster provides <code>kubernetes</code> option to generate the Kubernetes configuration file for the <code>JHipster</code> generated applications. Interested to explore more about Kubernetes check out <a href="https://sendilkumarn.com/blog/kubernetes-for-everyone" rel="nofollow noopener noreferrer" target="_blank">here</a>. The <code>jdl</code> accepts <code>deployment</code> block to define the Kubernetes deployment.</p>
<div><pre><code>deployment {
  deploymentType         kubernetes
  appsFolders            [gateway, service]
  dockerRepositoryName   "sendilkumarn"
  serviceDiscoveryType   no
  istio                  false
  kubernetesNamespace    khipster
  kubernetesServiceType  Ingress
}
</code></pre></div>
<blockquote>
<p>Note: It checks whether you have installed Docker since we need Docker for creating and pushing the images and use them later.</p>
</blockquote>
<p>The Kubernetes definition is made inside the <code>deployment</code> block with <code>deploymentType</code> as <code>kubernetes</code>. The <code>appsFolders</code> points to the folders of the generated applications. We define the <code>dockerRepositoryName</code>, this refers to docker user name here. Similar to applications, we define the <code>serviceDiscoveryType</code> as <code>no</code> (since we are going to use <code>Linkerd</code> for service discovery). KHipster provides <code>istio</code> out of the box, since we are going to use <code>Linkerd</code> for that. We define the Kubernetes namespace using <code>kubernetesNamespace</code> property. All the deployments &amp; services use <code>khipster</code> namespace to deploy the application.</p>
<p>Finally, We use <code>Ingress</code> as the <code>KubernetesServiceType</code> configuration. The smallest deployment unit of Kubernetes is a <code>pod</code>. A pod is a group of Docker containers. Refer here for more information about the <a href="https://sendilkumarn.com/blog/kubernetes-pods" rel="nofollow noopener noreferrer" target="_blank">pods</a>. Each pod gets IP address during its creation. If we have to access the application we have to connect to the pod's IP address (with port if applicable). In the Kubernetes cluster, pods are created and destroyed automatically based on various factors. So when a pod spawns newly, IP address referring them might change.In order to connect to running applications in the pods, we use services. Services define a set of pods and a way to access them. The services is like a loadbalancer or service discoverer that helps to identify the pods with a name to it.</p>
<p>Kubernetes provide three types of service type:</p>
<ul>
<li>Cluster IP  - This exposes service to an cluster internal IP</li>
<li>Nodeport  - This exposes the service to an port</li>
<li>Load Balancer - This exposes the service to an external IP</li>
</ul>
<p>With <a href="https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/" rel="nofollow noopener noreferrer" target="_blank">Kube-DNS</a>, Kubernetes also maps the service to an external name. Refer <a href="https://kubernetes.io/docs/concepts/services-networking/service/" rel="nofollow noopener noreferrer" target="_blank">here</a> for more infomration.</p>
<p>Ingress is not a service type, but with Ingress you can expose the service. The ingress acts as an entry point for your cluster. It is ideal for exposing multiple services under the same IP address.</p>
<blockquote>
<p>We need <code>ingress-controller</code> to expose services via ingress IP, we will set up ingress-controller below.</p>
</blockquote>
<h2 id="generate-code-using-khipster">Generate code using KHipster</h2>
<p>The <code>khipster import-jdl</code> imports the <code>JDL</code> file and generates the application and the deployment configuration files.</p>
<div><pre><code>λ khipster import-jdl app.jdl

Gateway application generated successfully.
Service application generated successfully.
Kubernetes configuration generated successfully.
</code></pre></div>
<p>Login the docker using <code>docker login</code>. Now go and build each services in their respective folders:</p>
<div><pre><code>λ ./gradlew bootJar -Pprod jib -Djib.to.image=&lt;docker-username&gt;:&lt;app-name&gt;
</code></pre></div>
<h2 id="create-a-kubernetes-cluster-in-gcp">Create a Kubernetes cluster in GCP</h2>
<blockquote>
<p>Install gcloud <a href="https://cloud.google.com/sdk/docs/install" rel="nofollow noopener noreferrer" target="_blank">here</a>.</p>
</blockquote>
<div><pre><code>λ gcloud beta container --project &lt;project-name&gt; clusters create "khipster-cluster" --machine-type "c2-standard-4" --num-nodes "2" --zone "us-central1-c"
</code></pre></div>
<p>We create a cluster named <code>khipster-cluster</code> in the given project. We define the <code>machine-type</code> with <code>c2-standard-4</code> with 2 nodes in the <code>us-central1-c</code> zone. This will take a while to complete, since it has to create a cluster from the scratch.</p>
<blockquote>
<p>Explore more about K8s installation in the GCP <a href="https://cloud.google.com/kubernetes-engine/docs/quickstart" rel="nofollow noopener noreferrer" target="_blank">here</a>.</p>
</blockquote>
<h2 id="install-linkerd-cli-and-deploy-linkerd-in-kubernetes-cluster">Install Linkerd CLI and deploy Linkerd in Kubernetes cluster</h2>
<blockquote>
<p>Linkerd is a <code>service mesh</code> for Kubernetes. Linkerd makes running services easier and safer by giving you runtime debugging, observability, reliability, and security—all without requiring any changes to your code. - <a href="https://linkerd.io/2/overview/" rel="nofollow noopener noreferrer" target="_blank">Linkerd website</a></p>
</blockquote>
<p>Install the CLI manually in your system and set up the path, run:</p>
<div><pre><code>λ curl -sL https://run.linkerd.io/install | sh
Linkerd stable-2.9.0 was successfully installed 🎉

λ export PATH=$PATH:$HOME/.linkerd2/bin
</code></pre></div>
<p>Check the installation by running:</p>
<div><pre><code>λ linkerd version
Client version: stable-2.9.0
Server version: unavailable
</code></pre></div>
<p>Once the installation is completed. Before installing the Linkerd in the Kubernetes cluster, we wil check whether the Kubernetes cluster is configured correctly. We run:</p>
<div><pre><code>λ linkerd check --pre
....
Status check results are √
</code></pre></div>
<blockquote>
<p>The above command checks whether the kubernetes cluster is configured correctly and ready to install the Linkerd control plane.</p>
</blockquote>
<p>Note: The bare Kubernetes configuration might not have the required cluster admin role. To create the <code>clusterrolebinding</code> with <code>cluster-admin</code> role for the selected account.</p>
<div><pre><code>λ kubectl create clusterrolebinding cluster-admin-binding \
  --clusterrole=cluster-admin \
  --user="$(gcloud config get-value core/account)"

clusterrolebinding.rbac.authorization.k8s.io/cluster-admin-binding created
</code></pre></div>
<p>To install the Linkerd on the Kubernetes cluster, run the following:</p>
<div><pre><code>λ linkerd install | kubectl apply -f -
</code></pre></div>
<p>The <code>linkerd install</code> command creates the kubernetes configuration files. We pipe the configuration files using <code>kubectl apply -f </code> command on those generated files. This will create the complete <code>linkerd</code> in the kubernetes cluster. Once the installation is complete refer the installation is complete using</p>

<h2 id="deploy-ingress-controller-in-kubernetes">Deploy ingress controller in Kubernetes</h2>
<blockquote>
<p>Ingress exposes <code>HTTP</code> and <code>HTTPS</code> routes from outside the cluster to services within the cluster. Traffic routing is controlled by rules defined on the Ingress resource.</p>
</blockquote>
<p>Ingress provides an external IP with which we connect to the services running inside the Kubernetes cluster. The Ingress also provides load balancing, SSL / TLS, and others. We will install a vanilla version Nginx ingress controller:</p>
<div><pre><code>λ kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v0.41.2/deploy/static/provider/cloud/deploy.yaml
</code></pre></div>
<p>Once the ingress-controller is installed in the Kubernetes cluster. Get the IP address by running the following command:</p>
<div><pre><code>λ kubectl get svc ingress-nginx-controller -n ingress-nginx -o jsonpath='{.status.loadBalancer.ingress[0].ip}'
xxx.xxx.xxx.xxx
</code></pre></div>
<p>Our application will be accessible via the above IP address.</p>
<h2 id="deploy-applications-in-kubernetes-cluster">Deploy applications in Kubernetes cluster</h2>
<p>To deploy applications in to the Kubernetes cluster, go into the Kubernetes folder and run the following command:</p>
<div><pre><code>λ ./kubectl-apply.sh apply -f
</code></pre></div>
<p>All the deployments and services will be installed in the K8s cluster. Now we need to auto inject Linkerd into the <code>khipster</code> namespace for all the services in that particular namespace.</p>
<p>Next, let's add Linkerd to <code>khipster</code> namespace by running:</p>
<div><pre><code>λ kubectl get -n khipster deploy -o yaml \
  | linkerd inject - \
  | …</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sendilkumarn.com/blog/khipster-microservices-k8s-linkerd">https://sendilkumarn.com/blog/khipster-microservices-k8s-linkerd</a></em></p>]]>
            </description>
            <link>https://sendilkumarn.com/blog/khipster-microservices-k8s-linkerd</link>
            <guid isPermaLink="false">hacker-news-small-sites-25240556</guid>
            <pubDate>Sat, 28 Nov 2020 21:08:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Second Swiss firm allegedly sold encrypted spying devices]]>
            </title>
            <description>
<![CDATA[
Score 247 | Comments 171 (<a href="https://news.ycombinator.com/item?id=25240179">thread link</a>) | @secfirstmd
<br/>
November 28, 2020 | https://www.swissinfo.ch/eng/second-swiss-firm-allegedly-sold-encrypted-spying-devices/46186432 | <a href="https://web.archive.org/web/*/https://www.swissinfo.ch/eng/second-swiss-firm-allegedly-sold-encrypted-spying-devices/46186432">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<section>
<div>
<div>
<figure>
<picture>
<source srcset="https://www.swissinfo.ch/resource/image/46186430/landscape_ratio3x2/880/587/a683e845a8c9bdb270a5b635dfc947ed/gO/omnisec.jpg" media="(min-width: 900px)">
<source srcset="https://www.swissinfo.ch/resource/image/46186430/landscape_ratio3x2/580/387/a683e845a8c9bdb270a5b635dfc947ed/Gx/omnisec.jpg" media="(min-width: 321px)">

</picture>
<figcaption>
Omnisec is the second Swiss company that allegedly sold manipulated encryption devices to US intelligence services. <span>Keystone / Walter Bieri</span>
</figcaption> </figure>
</div>
</div><p>Swiss public television, SRF, has found a second company besides Crypto AG&nbsp;was involved in manufacturing manipulated devices allegedly used for spying by foreign intelligence.</p>
<span>This content was published on November 26, 2020 - 11:34</span>
<time datetime="2020-11-26T11:34:28+01:00">

</time><p>According to <a rel="noopener" target="_blank" href="https://www.srf.ch/news/schweiz/verschluesselungsgeraete-geheimdienstaffaere-weitere-schweizer-firma-rueckt-in-den-fokus">SRF sources</a>, the Swiss company Omnisec AG had ties to US intelligence services. This follows revelations in February by SRF, German television ZDF and <em>The Washington Post</em> that Zug-based firm Crypto AG was at the heart of a huge international spying operation led by the CIA, and to a lesser extent by the German BND spy agency.&nbsp;Omnisec was one of the largest competitors of Crypto AG.</p><p>Swiss cryptologist and professor Ueli Maurer was a consultant for Omnisec for years and told SRF that in 1989 US intelligence services (National Security Agency) contacted Omnisec through him.</p><p>Of concern are the OC-500 series devices. Devices were sold to several Swiss federal agencies. However, Swiss&nbsp;authorities only noticed the devices weren't secure&nbsp;in the mid-2000s.</p><p>Several Swiss companies also received manipulated devices from Omnisec, including Switzerland’s largest bank, UBS. It is unclear whether the authorities informed UBS about the weak devices in the mid-2000s. UBS told SRF that it does not comment on security matters but that it had no indications that sensitive data were exposed at the time.</p>
<p>Omnisec, founded in 1987, manufactured voice, fax and data encryption equipment. It was dissolved a few years ago. The most recent head of the company, Clemens Kammer, told SRF that Omnisec customers “have and will continue to place great value on security, confidentiality, discretion and reliability in business relationships”.</p><p>Some politicians have called for further investigations into these latest allegations that may reveal who, if anyone, in the federal government knew of Omnisec’s business affairs with foreign intelligence.</p><h2>Crypto affair</h2><p>Earlier this month, a nine-month&nbsp;<a rel="noopener" target="_blank" href="https://web.archive.org/web/20201110183555/https:/www.parlament.ch/press-releases/Pages/mm-gpdel-2020-11-10.aspx">investigation</a>&nbsp;by the Swiss parliamentary audit committee (GPDel), found that the Swiss intelligence service knew that the US Central Intelligence Agency was behind the Swiss-based Crypto AG as far back as 1993. The report says that Swiss intelligence later collaborated with them to gather information from foreign sources.&nbsp;</p><p>More than 100 countries bought encryption devices from the Zug-based company, which did business under the guise of Swiss neutrality. In reality, the firm belonged to the CIA and Germany intelligence service, which could freely read what it encrypted. Information intercepted with the help of Crypto’s devices changed the course of events, including the Iran hostage crisis of 1979.</p> </section>
</div></div>]]>
            </description>
            <link>https://www.swissinfo.ch/eng/second-swiss-firm-allegedly-sold-encrypted-spying-devices/46186432</link>
            <guid isPermaLink="false">hacker-news-small-sites-25240179</guid>
            <pubDate>Sat, 28 Nov 2020 20:18:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Hacking Printers Wiki, an open approach to share knowledge on printr]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25239627">thread link</a>) | @rolph
<br/>
November 28, 2020 | http://hacking-printers.net/wiki/index.php/Main_Page | <a href="https://web.archive.org/web/*/http://hacking-printers.net/wiki/index.php/Main_Page">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="bodyContent">
									<p>From Hacking Printers</p>
								
												
				<div id="mw-content-text" lang="en" dir="ltr"><div>
<p>This is the <b>Hacking Printers Wiki</b>, an open approach to share knowledge on printer (in)security.
</p>
</div>
<table id="mp-upper">

<tbody><tr>
<td>

</td>
<td>
</td>
<td>
<table id="mp-right">
<tbody><tr>
<td> <h2 id="mp-otd-h2"><span id="Tools">Tools</span></h2>
</td></tr>
<tr>
<td>
<ul><li> <a href="http://hacking-printers.net/wiki/index.php/PRET" title="PRET">PRET</a>, <a href="http://hacking-printers.net/wiki/index.php/Praeda" title="Praeda">Praeda</a>, <a href="http://hacking-printers.net/wiki/index.php/PFT" title="PFT">PFT</a>, <a href="http://hacking-printers.net/wiki/index.php/BeEF" title="BeEF">BeEF</a></li></ul>
</td></tr>
<tr>
<td> <h2 id="mp-itn-h2"><span id="Fundamentials">Fundamentials</span></h2>
</td></tr>
<tr>
<td>
<ul><li> <b><a href="http://hacking-printers.net/wiki/index.php/Fundamentals#Printer_Control_Languages" title="Fundamentals">Printer languages</a></b>
<ul><li> <a href="http://hacking-printers.net/wiki/index.php/PJL" title="PJL">PJL</a>, <a href="http://hacking-printers.net/wiki/index.php/PCL" title="PCL">PCL</a>, <a href="http://hacking-printers.net/wiki/index.php/PostScript" title="PostScript">PostScript</a></li></ul></li>
<li> <b><a href="http://hacking-printers.net/wiki/index.php/Fundamentals#Network_printing_protocols" title="Fundamentals">Network protocols</a></b>
<ul><li> <a href="http://hacking-printers.net/wiki/index.php/LPD" title="LPD">LPD</a>, <a href="http://hacking-printers.net/wiki/index.php/IPP" title="IPP">IPP</a>, <a href="http://hacking-printers.net/wiki/index.php/Raw" title="Raw">Raw</a>, <a href="http://hacking-printers.net/wiki/index.php/SMB" title="SMB">SMB</a></li></ul></li></ul>
</td></tr>
<tr>
<td> <h2 id="mp-otd-h2"><span id="Attack_Carriers">Attack Carriers</span></h2>
</td></tr>
<tr>
<td>
<ul><li> <a href="http://hacking-printers.net/wiki/index.php/USB_drive_or_cable" title="USB drive or cable">USB drive or cable</a></li>
<li> <a href="http://hacking-printers.net/wiki/index.php/Port_9100_printing" title="Port 9100 printing">Port 9100 printing</a></li>
<li> <a href="http://hacking-printers.net/wiki/index.php/Cross-site_printing" title="Cross-site printing">Cross-site printing</a></li></ul>
</td></tr>
<tr>
<td> <h2 id="mp-otd-h2"><span id="Countermeasures">Countermeasures</span></h2>
</td></tr>
<tr>
<td>
<ul><li> <a href="http://hacking-printers.net/wiki/index.php/Countermeasures#Vendors" title="Countermeasures">Vendors</a>, <a href="http://hacking-printers.net/wiki/index.php/Countermeasures#Admins" title="Countermeasures">Admins</a>, <a href="http://hacking-printers.net/wiki/index.php/Countermeasures#Users" title="Countermeasures">Users</a></li></ul>
</td></tr>
<tr>
<td> <h2 id="mp-otd-h2"><span id="Bibliography">Bibliography</span></h2>
</td></tr>
<tr>
<td>
<ul><li> <a href="http://hacking-printers.net/wiki/index.php/Bibliography" title="Bibliography">Literature on printer security</a></li></ul>
</td></tr>
<tr>
<td> <h2 id="mp-otd-h2"><span id="References">References</span></h2>
</td></tr>
<tr>
<td>
<ul><li> <a href="http://hacking-printers.net/wiki/index.php/References" title="References">Printer language references</a></li></ul>
</td></tr></tbody></table>
</td></tr></tbody></table>
<div>
<table id="mp-center">
<tbody><tr>
<td><h2 id="mp-tfl-h2"><span id="Beyond_Printers">Beyond Printers</span></h2></td>
</tr><tr>
<td><p>Comming soon: <i>Hacking PostScript processing websites</i></p></td>
</tr>
</tbody></table>
</div>

<!-- 
NewPP limit report
Cached time: 20201201203828
Cache expiry: 86400
Dynamic content: false
CPU time usage: 0.052 seconds
Real time usage: 0.054 seconds
Preprocessor visited node count: 19/1000000
Preprocessor generated node count: 56/1000000
Post‐expand include size: 0/2097152 bytes
Template argument size: 0/2097152 bytes
Highest expansion depth: 1/40
Expensive parser function count: 0/100
-->

<!-- 
Transclusion expansion time report (%,ms,calls,template)
100.00%    0.000      1 - -total
-->

<!-- Saved in parser cache with key wiki:pcache:idhash:1-0!*!0!!*!*!* and timestamp 20201201203828 and revision id 648
 -->
</div>					
								
							</div></div>]]>
            </description>
            <link>http://hacking-printers.net/wiki/index.php/Main_Page</link>
            <guid isPermaLink="false">hacker-news-small-sites-25239627</guid>
            <pubDate>Sat, 28 Nov 2020 19:01:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA['Welcome to Toronto' sign altered to read 'Ontario's capital in overdose deaths']]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25239598">thread link</a>) | @app4soft
<br/>
November 28, 2020 | https://toronto.citynews.ca/2020/11/23/toronto-welcome-sign-altered-overdose-deaths/ | <a href="https://web.archive.org/web/*/https://toronto.citynews.ca/2020/11/23/toronto-welcome-sign-altered-overdose-deaths/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="article-meta">
        
    <p itemprop="datePublished">Posted Nov 23, 2020 1:09 pm EST</p>
    <p itemprop="dateModified">Last Updated Nov 23, 2020 at 10:07 pm EST</p>             
        
    </div><div id="main-article">
    <div>
	    					
	    
        

        <div id="article-body-content" itemprop="articleBody"> 
        	<p>An unofficial addition has been made to a sign welcoming drivers to Toronto that casts the province’s capital in a less than flattering light.</p>
<p>The sign, on the border with Mississauga along Burnamthorpe Road, used to read “Welcome to Toronto. Ontario’s capital.” With the unauthorized addendum, it now reads “Ontario’s capital in overdose deaths.”</p>
<p>The addition appears to be a plank covered in a vinyl sign, printed to mimic the original sign’s colours and font, attached below it with zip-ties.</p>
<p>CityNews viewers alerted us to the changes and say a few signs in the area have been altered in this manner.</p>

<p>According to the chief coroner’s office, an estimated 50 to 80 people per week are dying of overdoses in Ontario.</p>
<p>Across the country, the COVID-19 pandemic has exacerbated the opioid crisis. Opioid overdoses have risen sharply since March as the border closure and limited access to services raise fatal risks for drug users.</p>
<p>It is unclear who created the additional signage and whether it is in fact referring to this disturbing rise in numbers — a stark reversal of the 13 per cent decline in fatal opioid overdoses between 2018 and 2019.</p>
<p>The signs were addressed in the city’s daily COVID-19 briefing question and answer session on Monday.</p>
<p>Mayor John Tory said he has repeatedly expressed “deep concern” about the overdose rates and feels not enough attention has been given to the issue.</p>
<p>“While this isn’t necessarily the single best way to draw attention to this, it is something that’s got us talking about it and I think the more we talk about it the more we advocate for greater action on the part of all governments,” said Tory.</p>
<p>Tory said Toronto Public Health has a “significant harm reduction program,” but added that the city needs more provincial support.</p>
<p>The city said the signs have been addressed by city staff and have now been corrected.</p>
<p><em>With files from The Canadian Press</em></p>
        </div>
        
		        
		 
        
                    
        	</div><!--/ 16 -->     
</div></div>]]>
            </description>
            <link>https://toronto.citynews.ca/2020/11/23/toronto-welcome-sign-altered-overdose-deaths/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25239598</guid>
            <pubDate>Sat, 28 Nov 2020 18:56:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[30 years later, QBasic is still the best]]>
            </title>
            <description>
<![CDATA[
Score 312 | Comments 131 (<a href="https://news.ycombinator.com/item?id=25239424">thread link</a>) | @ohjeez
<br/>
November 28, 2020 | http://www.nicolasbize.com/blog/30-years-later-qbasic-is-still-the-best/ | <a href="https://web.archive.org/web/*/http://www.nicolasbize.com/blog/30-years-later-qbasic-is-still-the-best/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p><span><em>(5 minutes read)</em></span></p>
<p><span>My oldest son Noah turned 7 three months ago. If he could trade his family for a 2 hour session of playing minecraft, he would do it in a heartbeat. The other love of his life is Super Mario Maker, and&nbsp;it’s been a thrill to see him play the same game and levels that I played when I was his age. About 5 months ago, I left my family for my yearly pilgrimage of <a href="http://ludumdare.com/compo/">ludum dare</a>: a game dev competition during which I lock myself away with friends, return to a&nbsp;state of primitive caveman, not sleep for 48h, and create&nbsp;a full game from scratch (play it at the end of this post!) As I proudly showed my revolutionary AAA title to my wife, Noah was naturally intrigued and I introduced him to the world of code, showing him how simple&nbsp;words&nbsp;(he had just learned how to read) produced an actual game. Since&nbsp;that very day, Noah&nbsp;has been asking me repeatedly to teach him how to make&nbsp;his own video games. And for the past 5 months, I have been looking for the holy grail of language/IDE for kids in the hope of turning that spark of interest into a memorable experience…</span></p>
<p><span>My quest has led me to&nbsp;endless forums, through which I have tried countless suggestions: SmallBasic, Pico-8, Smalltalk, Scratch, etc. I have even inquired of the Great&nbsp;Oracles of StackOverflow,&nbsp;to&nbsp;no avail. After 5 months,&nbsp;I&nbsp;ended up with a disappointing conclusion: nothing is even close to what I had back in another era. 30 years later, QBasic is still the best when it comes to&nbsp;discovering programming.&nbsp;</span></p>
<blockquote>
<p><span>“OMG please don’t teach him GOTOs!!”</span></p>
</blockquote>
<pre><code>10 PRINT “OH NO, WHAT ARE YOU DOING?!!!”
20 GOTO 10</code></pre>
<p><span>Yes, QBasic is a terrible procedural language. It introduces one to concepts widely considered harmful, uses awkward syntax for implicit declarations, is not case sensitive, is non-zero-based, etc. the list goes on… When developing a skill, it is much better to acquire the right reflexes from the start rather than have to correct years of bad practice. Following this advice, I should have probably started off with&nbsp;the basics of the ruby language which I love. Yet, while most of those QBasic concepts are today generally considered&nbsp;as red flags by our peers, they each served a very specific&nbsp;purpose at the time: to keep the language simple and accessible, a notion that every other language has left behind in favor of flexibility, complexity and logic.</span></p>
<p><span>I installed QBasic on my son’s 11” HP Stream today, having to hack a DOSBox manual installation. He double clicked the icon on his desktop and in a split second, we were in the IDE, greeted with the introduction screen which brought back so many memories to my mind:</span></p>
<p><img src="https://upload.wikimedia.org/wikipedia/en/0/01/QBasic_Opening_Screen.png" alt="" width="640" height="400"></p>
<p><span>I then told Noah that there was a very sacred ritual, mandatory&nbsp;for anyone who enters the secret&nbsp;inner&nbsp;circle of programmers, to start off with a program that greets every other programmer out there. As I dictated the formula, he slowly&nbsp;searched for each&nbsp;key, carefully&nbsp;typing with his right finger&nbsp;the magic words: <code>PRINT “hello world”</code></span></p>
<p><span>He pressed F5 and looked amazed as he saw his code being compiled into text rendered on his black screen. He smiled, gave me a high-five, and then scribbled down the code in his little notebook so that he could remember later.</span></p>
<p><img src="http://nicolasbize.com/blog/images/noah_1.jpg" alt="" width="800" height="600"></p>
<p>We went on to a couple more commands: CLS, COLOR, PLAY, INPUT, and IF. There was nothing to explain: no complexity, no awkward operator, no abstract concepts, no documentation that needed to be read, no notion of objects/class/methods, no framework to install, no overwhelming menu/buttons in the IDE, no special keyword or parenthesis. It was code in its purest simplicity and form.</p>
<p><span>After less than an hour, he wrote his first program on his own – an interactive and incredibly subtle application which lets you know the computer’s feelings towards&nbsp;you as an individual and sensible human being:</span></p>
<p><img src="http://nicolasbize.com/blog/images/noah_3.jpg" alt="" width="800" height="600"></p>
<p><span>…which he ran with utmost pride for his cousin and best friend Christian:</span></p>
<p><img src="http://nicolasbize.com/blog/images/noah_4.jpg" alt="" width="800" height="600"></p>
<p><span>…after which he proceeded to easily explain him&nbsp;</span><span><b>how</b></span><span>&nbsp;it worked and what the code was doing!</span></p>
<p><img src="http://nicolasbize.com/blog/images/noah_5.jpg" alt="" width="800" height="600"></p>
<p><span>And so it was that in a single hour, my 7 year old was able to not only write his first text game, but also to experience the fun and thrill that comes from creating, compiling and executing his own little program. Bonus points, it all fit on a single notebook page:</span></p>
<p><img src="http://nicolasbize.com/blog/images/noah_2.jpg" alt="" width="600" height="800"></p>
<p><span>I was so glad that he was able to understand why I keep saying that I have the best job in the world.&nbsp;</span><span>My only regret today was to realize that in more than 30 years, we have not been able to come up with something&nbsp;better for our kids: Qbasic has a limited set of simple keywords (the entire help fits on a single F1 screen and is packed with simple examples!), does not distract the coder with any visual artifacts, has a very confined and cosy dev environment, shows errors as early as possible, compiles and executes the code in a heartbeat with a single key, and is extremely straightforward. &nbsp;We have built more robust and more complex languages/frameworks/IDEs (which are of course necessary for any real-life application), but we have never really made a simpler or more direct access to the thrill of programming than QBasic. Even running QBasic today has become dreadful&nbsp;to the novice that uses&nbsp;a modern Mac/PC/Linux machine, whereas it used to simply require inserting a 3,5” floppy in the A:\ disk drive…</span></p>
<p><span>Enough rant, today is all about the celebration of yet another person who discovered the excitement and beauty of programming!</span></p>
<p><span>Cheers!</span></p>
<p><span>(as promised, <a href="http://nicolasbize.com/ld34/">my AAA title</a> for which I await&nbsp;EA’s call to purchase copyrights)</span></p>
			</div></div>]]>
            </description>
            <link>http://www.nicolasbize.com/blog/30-years-later-qbasic-is-still-the-best/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25239424</guid>
            <pubDate>Sat, 28 Nov 2020 18:32:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Machine Learning for Art with Google’s Emil Wallner]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25239217">thread link</a>) | @andreyk
<br/>
November 28, 2020 | https://www.letstalkai.show/e/mlart-interview/ | <a href="https://web.archive.org/web/*/https://www.letstalkai.show/e/mlart-interview/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<div>


		
			<div id="post-15958234">
				<p><a href="https://www.letstalkai.show/">
										<img src="https://pbcdn1.podbean.com/imglogo/image-logo/7703921/Lets_Talk_Logo.jpg"></a></p><div>
				<div>
					
					<p>Nov 27th, 2020 by <a title="Posts by Skynet Today">Skynet Today</a> </p>
				</div>

				<div>
					 <div>
<p>An interview with <span>Emil Wallner, the creator of mlart.co . Emil is an internet-educated, independent machine learning researcher, and resident at the Google Arts &amp; Culture Lab. As a resident at Google he is using machine learning to explore art and culture. Part-time, he applies machine learning to logical tasks such as programming and mathematics.</span></p>
<p>Subscribe: <a href="https://feed.podbean.com/aitalk/feed.xml">RSS</a> | <a href="https://podcasts.apple.com/us/podcast/lets-talk-ai/id1502782720">iTunes</a> | <a href="https://open.spotify.com/show/17HiNdxcoKJLLNibIAyUch">Spotify</a> | <a href="https://www.youtube.com/channel/UCKARTq-t5SPMzwtft8FWwnA">YouTube</a></p>
<div>
<p>Check out coverage of similar topics at <a href="http://www.skynettoday.com/">www.skynettoday.com</a></p>
<p>Theme: Deliberate Thought Kevin MacLeod (incompetech.com)</p>
</div>
</div>
									</div>

				

   <p><span id="postbar_15958234"> <span> | </span><a href="https://www.podbean.com/site/EpisodeDownload/PBF380DAKYNN9" target="_blank">Download</a> </span></p>			</div>

		


	</div>
</div>
</div></div>]]>
            </description>
            <link>https://www.letstalkai.show/e/mlart-interview/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25239217</guid>
            <pubDate>Sat, 28 Nov 2020 18:08:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Garbage In, Garbage Out]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25239193">thread link</a>) | @iamacyborg
<br/>
November 28, 2020 | https://www.jacquescorbytuech.com/writing/garbage-in-garbage-out | <a href="https://web.archive.org/web/*/https://www.jacquescorbytuech.com/writing/garbage-in-garbage-out">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>It recently surfaced in a story by <a href="https://www.adexchanger.com/platforms/facebook-conversion-lift-measurement-issue-goes-undetected-for-12-months/">AdExchanger</a> and <a href="https://www.wsj.com/articles/facebooks-latest-error-shakes-advertisers-confidence-11606346927">The Wall Street Journal</a> that Facebook had, for <strong><em>a year</em></strong>, been feeding incorrect data to advertisers paying to display adverts across Facebook's network using their lift conversion tool.</p>
<blockquote>
<p>Specifically, the bug was caused by a data pipeline migration in August of last year that affected the way in which certain impressions were logged into Facebook’s conversion lift systems.</p>
<p>As a result, Facebook undercounted the number of conversions from people who were exposed to impressions on Facebook apps.</p>
<p>In other words, Facebook miscalculated the number of sales that came from people that saw an ad, which is a key ratio necessary to measure incrementality, because it’s used to calculate other metrics, including conversion lift percentage, which is the difference in conversions between the people who did and didn’t see ads during a test.</p>
</blockquote>
<p>In finding and fixing this issue, <em>they also surfaced two other bugs affecting data quality for a period of a few months</em>.</p>
<blockquote>
<p>During Facebook’s investigation into the original bug, it also came across and patched two additional, separate and, it says, “smaller” technical issues that affected conversion-based metrics for some lift tests.</p>
</blockquote>
<p>This follows not long after LinkedIn fessed up to <a href="https://www.wsj.com/articles/linkedin-finds-measurement-errors-that-inflated-video-and-ad-metrics-11605228577">their own measurement fuckup</a> that saw 418,000 advertisers served incorrect data over a period of <strong><em>two years</em></strong>.</p>
<blockquote>
<p>In a blog post, the Microsoft Corp.-owned company said its engineering team found and fixed two measurement issues in its ad products, which led to overreporting of video views and ad impressions on sponsored-content campaigns. The bugs affected more than 418,000 advertisers over the course of more than two years, it said.</p>
</blockquote>
<p>I recently wrote about the <a href="https://www.jacquescorbytuech.com/writing/marketers-addicted-bad-data">problem marketers have with bad data</a> and their inability to recognise and understand the data they're being presented from opaque third parties. Not necessarily through any real fault of their own, I hasten to add.</p>
<p>These most recent examples are particular pernicious. Marketers rely on data from Facebook, LinkedIn and similar to optimise campaigns and to assign limited budget. In both cases, incorrect data could have, and probably <em>did have</em>, a tangible effect on how marketers allocated their budget. This lead to Facebook and LinkedIn directly profiting from these fuck-ups.</p>
<p>I can't say this enough, but marketers without a healthy degree of scepticism are going to fall victim to this more and more frequently. If you let garbage data define your media strategy, you'll get garbage results.</p>
<p>Cheers,</p>
<p><img src="https://www.jacquescorbytuech.com/images/jacques.png">
</p></div></div>]]>
            </description>
            <link>https://www.jacquescorbytuech.com/writing/garbage-in-garbage-out</link>
            <guid isPermaLink="false">hacker-news-small-sites-25239193</guid>
            <pubDate>Sat, 28 Nov 2020 18:05:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Opinion: RMS Does Not See the Future of Emacs]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25239111">thread link</a>) | @ashton314
<br/>
November 28, 2020 | https://lambdaland.org/posts/2020-11-future-of-emacs/ | <a href="https://web.archive.org/web/*/https://lambdaland.org/posts/2020-11-future-of-emacs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

      <p>
        <h3>RMS Does Not See the Future of Emacs
        </h3>
        
        </p>

    <p>I am an avid <a href="https://emacs.org/">Emacs</a> user. I’m using it right now to compose this post. I use it every single day for everything from work to school to personal notes. Most of my activity on GitHub comes from me tweaking little things in my configuration files. I now have an editor that perfectly fits my hands. Emacs is a big part of my life.</p>
<p>I’m afraid it’s dying.</p>
<p>Richard Stallman, one of the principle creators of Emacs and the head of the GNU Project, has made several choice in the past several months that I consider to be detrimental to the Emacs community and harmful for Emacs' further growth. RMS doesn’t seem to care that much about making Emacs appealing to new users, and I think this is a mistake. Emacs derives its strength from being uniquely customizable and extensible; the more people we get using Emacs, the more good extensions, packages, tutorials, etc. will be available for Emacs. Some of the growth-hostile things include:</p>
<ul>
<li>Shutting down suggestions for making Emacs start with a sensible set of defaults that would make it significantly easier for beginners to get started<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></li>
<li>Purging links to the most popular (and most useful!) Emacs package repositories, Melpa and Marmalade, just because they <em>might</em> contain links to sites with non-free Javascript<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup></li>
<li>Ignoring community-driven development and exercising veto rule in cases where I personally think it was unwarranted<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup></li>
</ul>
<p>I can appreciate strong leadership; I think for creating most things, having a single leader drive the development of a product gives it focus and direction that otherwise might kill it off. (I think Python is a good example of this at work.) In this case with Emacs, however, I think RMS is badly out of touch and should focus on what we as a community can do to make Emacs more robust so that future generations of programmers will have a strong motivation to use Emacs—a desire to run free software motivates precious few people in their selection of their tools. We should make it more appealing for its features and performance as well.</p>
<p>Some areas where Emacs stands to improve are:</p>
<ul>
<li><strong>Beginner-friendliness</strong> The default Emacs theme looks awful. No computer user used to the comforts of macOS or Windows would want to go near that ugly beast. It should have a pretty-looking theme by default. One idea would be to make it so that a new user can select some pre-built themes.</li>
<li><strong>Performance</strong> There are some exciting things happening with gccemacs on this front. I’m not running that right now, as compiling Emacs master on macOS is a little persnickety. Improving its rendering engine would help too. I recognize that that is a big undertaking, and unfortunately I have little to offer in this regard.</li>
<li><strong>Ease of contribution</strong> Why not host Emacs development on a self-hosted GitLab instance? Or use some other issue tracker? I understand that there are some advantages for mailing lists, but the set of programmers who are a.) familiar with that work flow, and b.) prefer it, is dwindling. An issue/PR-style flow makes a lot more sense for most developers, and I think it would go a long way to enriching community involvement in Emacs' core development.</li>
</ul>
<p>These are just my thoughts, and will likely evolve over time. Unfortunately I cannot devote as much time as I would like to improving Emacs, though I do enjoy <a href="https://github.com/ashton314/gilded-select">learning to write packages</a> when I have the time.</p>
<p>Good luck, all you Emacs maintainers out there. You’re heroes.</p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p><a href="https://lwn.net/Articles/819452/">https://lwn.net/Articles/819452/</a> <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p><a href="https://github.com/emacs-mirror/emacs/commit/5daa7a5fd4aced33a2ae016bde5bb37d1d95edf6">https://github.com/emacs-mirror/emacs/commit/5daa7a5fd4aced33a2ae016bde5bb37d1d95edf6</a> <a href="#fnref:2" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p><a href="http://ergoemacs.org/misc/rms_emacs_tyrant_2018-03.html">http://ergoemacs.org/misc/rms_emacs_tyrant_2018-03.html</a> <a href="#fnref:3" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section>
    </div></div>]]>
            </description>
            <link>https://lambdaland.org/posts/2020-11-future-of-emacs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25239111</guid>
            <pubDate>Sat, 28 Nov 2020 17:56:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Artist built usable 40k Space Marine armor (video, swe)]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25239082">thread link</a>) | @m_eiman
<br/>
November 28, 2020 | https://www.svt.se/nyheter/lokalt/norrbotten/har-dundrar-han-fram-i-sin-2-7-meter-langa-warhammer-drakt | <a href="https://web.archive.org/web/*/https://www.svt.se/nyheter/lokalt/norrbotten/har-dundrar-han-fram-i-sin-2-7-meter-langa-warhammer-drakt">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><div><figure><div><div><div><div><div><p><img alt="" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></div></div></div><div><div><p>Javascript måste vara påslaget för att kunna spela video</p></div></div><div><div><p>SVT stödjer inte uppspelning i din webbläsare. Vi rekommenderar därför att du byter till en annan webbläsare.</p></div></div></div></div><figcaption><span>I klippet ser du Svjan Köppe när han intar soptippen i sin massiva Warhammer-dräkt. <span>Foto: <!-- -->Marcel Köppe/Privat</span></span></figcaption></figure></div><p><section><span title="28 november 2020 kl 06:49"><span>Publicerad</span> <time datetime="2020-11-28T06:49:43+01:00">28 november 2020</time></span></section></p><div><p>Han har byggt en monsterdrake och en pansarbjörn tidigare. Nu har Svjan Köppe i Älvsbyn slagit till med en 2,7 meter lång Warhammerkrigare.</p><p>– Jag skapade den på golvet i lägenheten, säger han.</p></div><div><div><p>Efter den uppmärksammade Game of Thrones-draken och den 150 kg tunga björnen väljer Svjan Köppe att satsa mer på höjd och rörlighet. Den nya skapelsen är en ”Space Marine” från spelet Warhammer 40&nbsp;000.</p><p>Det tog fyra månader att bygga jätten som mäter 2,7 meter och kan röra sig framåt. Verkstaden? Hemma på golvet i lägenheten och det är ingen lättviktare.</p><p>– Bara svärdet är väldigt tungt och maffigt att hålla i. Dessutom ska det bara hållas med en hand som figuren gör, säger han.</p><p><em>I klippet ser du Svjan iklädd Warhammer-dräkten och hör om hans framtida projekt</em></p><figure><div data-lpid="29247098"><div><p><img alt="" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></div></div><figcaption><span>Svjan Köppe, Älvsbyn, har byggt en GoT-drake och Pansarbjörn tidigare. Nu har han färdigställt en Warhammer-figur. <span>Foto: <!-- -->Jimmy Bäckström/SVT</span></span></figcaption></figure></div><section></section></div><section><p><span>SVT:s nyheter ska stå för saklighet och opartiskhet. Det vi publicerar ska vara sant och relevant. Vid akuta nyhetslägen kan det vara svårt att få alla fakta bekräftade, då ska vi berätta vad vi vet – och inte vet. </span><a href="https://www.svt.se/nyheter/sa-arbetar-vi-pa-svt-nyheter"><span>Läs mer</span></a></p></section></article></div></div>]]>
            </description>
            <link>https://www.svt.se/nyheter/lokalt/norrbotten/har-dundrar-han-fram-i-sin-2-7-meter-langa-warhammer-drakt</link>
            <guid isPermaLink="false">hacker-news-small-sites-25239082</guid>
            <pubDate>Sat, 28 Nov 2020 17:52:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Crispr- A Crack in the Creation book reading notes]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25238740">thread link</a>) | @orsenthil
<br/>
November 28, 2020 | http://xtoinfinity.com/posts/2020/11/27/a-crack-in-creation-by-jennifer-doudna-and-samuel-steinberg.html | <a href="https://web.archive.org/web/*/http://xtoinfinity.com/posts/2020/11/27/a-crack-in-creation-by-jennifer-doudna-and-samuel-steinberg.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody text">
    <div>
<p><strong>A Crack in Creation: Gene Editing and Unthinkable power to control evolution</strong>
by Jennifer Doudna and Samuel Steinberg is a book on gene-editing and a
technology called CRISPR.</p>
<p>The book is a personal narration of Jennifer Doudna as she explains the
development of CRISPR and it's discovery for use in gene editing.  Rather than a
review, this are notes while reading this book.  CRISPR is molecular structure
found in Bacteria, but now more popular term, commonly associated with a gene
editing technique.</p>
<p><em>Given the technical nature of this article, I must have used the text from the
sources only with slight modification for explanation. References should give
the materials I consulted to write this post. In you notice technical
inaccuracy, I aplogize, please point out, and I will correct it.</em></p>
<p><strong>Terms</strong></p>
<p>As I reader, I found reviewing biological terms helped me understand the
material better.</p>
<div>
<p><img alt="https://dl.dropbox.com/s/3cn83qir2ip3nso/Screenshot_2020-11-28-04-50.png" src="https://dl.dropbox.com/s/3cn83qir2ip3nso/Screenshot_2020-11-28-04-50.png"></p><p>DNA, the language of life. Figure from <em>A Crack in Creation</em> book.</p>
</div>
<p>Human Body is made of <strong>cells</strong>, in-fact trillions of cells. Each of these cells
contain something called DNA. <strong>DNA</strong> is like recipe, just like a food recipe,
but for building and maintaining living organisms.</p>
<p>Cells use DNA to make proteins. Proteins are the workhorses of the body, they do
all the stuff we need to do to survive, from digesting food to making other
proteins.  Proteins are molecules made up of cells.</p>
<p>DNA is made up of a long combination of some very basic organic components
called Adenine, Thymine, Guanine and Cytosine. Human DNA consists of about 3
billion of these. The sequence of these determines the information available for
building and maintaining an organism, similar to the way in which letters of the
alphabet appear in a certain order to form words and sentences.</p>
<p>In the nucleus of each cell, the DNA molecule is packaged into thread-like
structure called <strong>chromosomes</strong>. A <em>Chromosome</em> is a DNA containing structure.</p>
<p>RNA are like cousins of DNA, which has an oxygen atom with it. One type called
messager RNA, mRNA, act as carrier of information to different cells, carrying
information from DNA to those cells to produce proteins.</p>
<p>So far, in above definitions, we didn't emphasize on <em>heredity</em> , that is,
sending information from parent to child yet. As soon as we start talking about
<em>heredity</em>, we use the term, <strong>Genes</strong>.</p>
<p>A gene is the basic physical and functional unit of heredity. Each chromosome of
human body has many genes.</p>
<p>If we take a single cell from human body, and find out the entire set of
<em>genetic information</em> in the chromosomes of that cell, we call that a
<strong>Genome</strong>. A Genome, from <strong>Gen</strong> e and Chromos <strong>ome</strong>, is the entire set of
<em>genetic</em> instructions found inside a cell.</p>
<p><strong>CRISPR in bacteria</strong></p>
<p>Single celled organisms like Bacteria were using a technique to fight off some
diseases.  The term CRISPR was given to an identified characteristic in
Bacterial DNA sequence, which was used to produce a protein called CAS-9, which
in turn, helped to kill the enemy virus.</p>
<p>CRISPR stands for Clustered Regularly Interspaced Short Palindromic Repeats and
is a family of DNA Sequences found in genomes of bacteria. CAS9 stands for
CRISPR associated protein 9.</p>
<p>The bacteria were found to capture snippets of DNA from invading viruses and use
them to create DNA segments known as CRISPR arrays. The CRISPR arrays allow the
bacteria to "remember" the viruses. If the viruses attack again, the bacteria
produce RNA segments from the CRISPR arrays to target the viruses' DNA. The
bacteria then use Cas9 to cut the DNA apart and kill the virus.</p>
<div>
<p><img alt="https://dl.dropbox.com/s/staumxmyll7ypty/Screenshot_2020-11-27-19-41.png" src="https://dl.dropbox.com/s/staumxmyll7ypty/Screenshot_2020-11-27-19-41.png"></p><p>CRISPR in Bacteria. Figure from <em>Crack in the Creation</em>.</p>
</div>
<p><strong>CRISPR Shaping Human Genome</strong></p>
<p>The CRISPR-Cas9 system works similarly in the lab. Researchers create a small
piece of RNA with a short "guide" sequence that attaches (binds) to a specific
target sequence of DNA in a genome. The RNA also binds to the Cas9 enzyme. As in
bacteria, the modified RNA is used to recognize the DNA sequence, and the Cas9
enzyme cuts the DNA at the targeted location. Although Cas9 is the enzyme that
is used most often, other enzymes (for example Cpf1) can also be used. Once the
DNA is cut, researchers use the cell's own DNA repair machinery to add or delete
pieces of genetic material, or to make changes to the DNA by replacing an
existing segment with a customized DNA sequence</p>
<p>When CRISPR was determind that it could be used in lab on living organisms, the
potential for shaping the genome unfolded.</p>
<p>First time ever, in over 100,000 years, we have ability to shape the <em>Homo
Sapien</em> evolution by mechanisms other than random mutation and natural
selection.</p>
<p>In humans, CRISPR can be used to do a precise repair and produce a normal
protein from a non-functional gene.</p>
<p><img alt="https://dl.dropbox.com/s/zhew8671tk9dnx6/Screenshot_2020-11-28-04-04.png" src="https://dl.dropbox.com/s/zhew8671tk9dnx6/Screenshot_2020-11-28-04-04.png"></p><p>CRISPR enables scientists to edit and <em>fix</em> single incorrect letters of DNA from
3.2 billion letters that comprise the human genome. It can also be used to
perform even more complicated edits to Human DNA.</p>
<p>A relatively straightforward DNA editing has transformed every genetic disease,
at-least the diseases for which we know the underlying mutation(s) into a
potentially treatable disease.</p>
<p><strong>CRISPR on Animals</strong></p>
<p>CRISPR has been used to create gene edited mouse wherein the genome of the
embroyo was edited and introduced back into womb to have an offspring with
the desirable characteristics embedded at time of birth.</p>
<div>
<p><img alt="https://dl.dropbox.com/s/l0gxu7imj7v3pqa/Screenshot_2020-11-28-03-51.png" src="https://dl.dropbox.com/s/l0gxu7imj7v3pqa/Screenshot_2020-11-28-03-51.png"></p><p>Gene Edited Mouse. Figure from <em>A Crack in Creation</em>.</p>
</div>
<p>And we have used gene editing to create animals desirable characteristics</p>
<div>
<p><img alt="https://dl.dropbox.com/s/7hdtn904xxas57q/Screenshot_2020-11-28-04-01.png" src="https://dl.dropbox.com/s/7hdtn904xxas57q/Screenshot_2020-11-28-04-01.png"></p><p>Gene edited animals. Figure from <em>A crack in creation</em>.</p>
</div>
<p>This is currently used in practice. Like Recombinetics uses gene editing for
dehorning cattle, a safer method than physical dehorning using hot iron-rods.</p>
<p><a href="https://recombinetics.com/our-technology/"><img alt="https://dl.dropbox.com/s/r5op4mkkhju3s8p/Screenshot_2020-11-28-07-34.png" src="https://dl.dropbox.com/s/r5op4mkkhju3s8p/Screenshot_2020-11-28-07-34.png"></a></p><hr>
<p><strong>Pigs as Bio Reactors</strong></p>
<p>An important field of bio technology is regenerative medicine, desired by human
society who are fighting of some disease eithe naturally or have lost some
ability due an accident.</p>
<p>Many scientists see the pig itself as a source of medicine. It is seen
that we might be using pigs as bioreactors to produce valuable drugs like
therapeutic human proteins, which are too complex to synthesize from scratch and
can only be produced in living cells.</p>
<p><img alt="https://dl.dropbox.com/s/lw2lleanrept8qf/Screenshot_2020-11-28-04-07.png" src="https://dl.dropbox.com/s/lw2lleanrept8qf/Screenshot_2020-11-28-04-07.png"></p><p>Scientists have already been looking to
other transgenic animals to produce these biopharmaceutical drugs, or
farmaceuticals, as they’re colloquially called.</p>
<p><a href="https://www.revivicor.com/index.html">Revivicor</a> is a company that is using CRISPR to produce regenerative medicine,
following the process exactly outlined above. A workflow from their website
gives the details on how Pigs are used as Bio Reactors for regenerative
medicine.</p>
<p><a href="https://www.revivicor.com/"><img alt="https://www.revivicor.com/images/RevivicorTechPoster-04-2010.jpg" src="https://www.revivicor.com/images/RevivicorTechPoster-04-2010.jpg"></a></p><hr>
<p><strong>Malaria Resistant Mosquitos</strong></p>
<p>The deadliest animal on earth, Mosquito can also be killed using CRISPR. The
idea seems to create malaria resistant mosquitoes using gene editing so that
the entire family is disabled from being a carriers of malaria.</p>
<p><img alt="https://dl.dropbox.com/s/qwejig01w6zcyox/Screenshot_2020-11-28-04-23.png" src="https://dl.dropbox.com/s/qwejig01w6zcyox/Screenshot_2020-11-28-04-23.png"></p><hr>
<p><strong>CRISPR for Therapeutics</strong></p>
<p>CRISPR can be utilized to edit the germ cells outside the body.
The edited germ cells can be planted inside for beneficiary aspects.</p>
<div>
<p><img alt="https://dl.dropbox.com/s/8ekvzjzwupi63t7/Screenshot_2020-11-28-04-27.png" src="https://dl.dropbox.com/s/8ekvzjzwupi63t7/Screenshot_2020-11-28-04-27.png"></p><p>Ex-vivo CRISPR therapy. A Crack In The Creation.</p>
</div>
<p>For targeted drug delivery, like fixing the lung or particular muscle instead
of injecting the drug into blood stream.</p>
<div>
<p><img alt="https://dl.dropbox.com/s/7zaa0afr6gdipha/Screenshot_2020-11-28-04-31.png" src="https://dl.dropbox.com/s/7zaa0afr6gdipha/Screenshot_2020-11-28-04-31.png"></p><p>In-vivo CRISPR therapy. A Crack In the Creation.</p>
</div>
<p>Adult Homo sapiens are among the last animals to be treated with CRISPR, human
cell: have been subjected to more CRISPR gene editing than those of any other
organism.</p>
<p>Scientists have applied CRISPR in lung cells to correct the genetic mutation
that causes cystic fibrosis, in blood cells to correct the mutations that cause
sickle cell disease and beta-thalassemia, and in muscle cells to correct the
mutations that cause Duchenne muscular dystrophy.</p>
<p>Scientists have used CRISPR to edit and repair mutations in stem cells, which
can then be coaxed to transform into virtually any cell or tissue type in the
body.</p>
<p>Even as CRISPR continues to be useful, it's power as a technology and it's
potential misuse is a concern for everyone.</p>
<blockquote>
Whether we'll ever have the intellectual and moral capacity to
guide our own genetic destiny is an open question - one that has been in my
mind since I began to realize what CRISPR is capable of.
- Jennifer Doudna</blockquote>
<p>And Jennifer Doudna shares her stance as she says, that the nature will still be
our supreme master.</p>
<blockquote>
Any mutations that CRISPR might make—intentional or not—would almost certainly
pale in comparison to the genetic storm that rages inside each of us from
birth to death. As one writer put it, “Genetic editing would be a droplet in
the maelstrom of naturally churning genomes.” If CRISPR could eliminate a
disease-causing mutation in the embryo with high certainty and only a slight
risk of introducing a second off-target mutation elsewhere, the potential
payoffs might well outweigh the dangers.
- Jennifer Doudna</blockquote>

</div>
    </div></div>]]>
            </description>
            <link>http://xtoinfinity.com/posts/2020/11/27/a-crack-in-creation-by-jennifer-doudna-and-samuel-steinberg.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25238740</guid>
            <pubDate>Sat, 28 Nov 2020 17:06:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple Silicon M1: A Developer's Perspective]]>
            </title>
            <description>
<![CDATA[
Score 393 | Comments 485 (<a href="https://news.ycombinator.com/item?id=25238608">thread link</a>) | @steipete
<br/>
November 28, 2020 | https://steipete.com/posts/apple-silicon-m1-a-developer-perspective/ | <a href="https://web.archive.org/web/*/https://steipete.com/posts/apple-silicon-m1-a-developer-perspective/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p><img src="https://d33wubrfki0l68.cloudfront.net/7dbf04694dfeeec9985b2ebb27cc1faff153111b/75e93/assets/img/2020/m1/m1.jpg"></p><p>The excitement around Apple’s new M1 chip is <a href="https://www.singhkays.com/blog/apple-silicon-m1-black-magic/">everywhere</a>. I bought a MacBook Air 16GB M1 to see how viable it is as main development machine - here’s an early report after a week of testing.</p><h2 id="xcode">Xcode</h2><p>Xcode runs FAST on the M1. Compiling the <a href="https://pspdfkit.com/">PSPDFKit PDF SDK</a> (debug, arm64) can almost compete with the fastest Intel-based MacBook Pro Apple offers to date, with <a href="https://twitter.com/steipete/status/1332052251712614405?s=21">8:49 min vs 7:31 min</a>. For comparison, my Hackintosh builds the same in less than 5 minutes.</p><p>One can’t overstate how impressive this is for a fan-less machine. Apple’s last experiment with fan-less MacBooks was the 12-inch version from 2017, which builds the same project in 41 minutes.</p><p>Our tests mostly ran just fine, although I found <a href="https://github.com/Aloshi/dukglue/pull/27">a bug specific to arm64</a> that we missed before, as we don’t run our tests on actual hardware on CI. Moving the Simulator to the same architecture as shipping devices will be beneficial and will help find more bugs.</p><p>Testing iOS below 14 is problematic. It seems <a href="https://twitter.com/steipete/status/1332654247809257473?s=21">WebKit is crashing in a memory allocator</a>, throwing EXC_BAD_INSTRUCTION (code=EXC_I386_INVOP, subcode=0x0) (Apple folks: FB8920323). Performance also seems really bad, with Xcode periodically <a href="https://twitter.com/steipete/status/1332348616145563653?s=21">freezing</a> and the whole system becoming so <a href="https://twitter.com/steipete/status/1332648748158246922?s=21">slow</a> that the mouse cursor gets choppy. Some Simulators even make problems on iOS 14, <a href="https://twitter.com/steipete/status/1331628274783543297?s=21">such as the iPad Air (4th gen) which still emulates Intel</a>, so try to avoid that one.</p><p>We were extremely excited to be moving our CI to Mac Mini’s with M1 chip and are <a href="https://www.macstadium.com/m1-mini">waiting on MacStadium to release devices</a>, however it seems we will have to restrict tests to iOS 14 for that to work. With our current schedule, we plan to drop iOS 12 in Q3 2021 and iOS 13 in Q3 2022, so it will be a while until we can fully move to Apple Silicon.</p><p>There is a chance that Apple fixes these issues, however it’s not something to count on - given that this only affects older versions of iOS, the problem will at some point just “go away”.</p><p><strong>Update:</strong> We’re working around the WebKit crashes for now via detecting Rosetta2 translation at runtime and simply skipping the tests where WebKit is used. This isn’t great, but luckily we’re not using WebKit a lot in our current project. <a href="https://gist.github.com/steipete/e15b1fabffc7da7d49c92e3fbd06971a">See my Gist for details</a>. Performance seems acceptable if you restrict parallel testing to at most two instances - else the system simply runs out of RAM and swapping is just really slow.</p><h2 id="docker">Docker</h2><p>We use Docker to automate our Website and load environments for our <a href="https://pspdfkit.com/pdf-sdk/web/">Web and Server PDF SDKs</a>. Docker posted a <a href="https://www.docker.com/blog/apple-silicon-m1-chips-and-docker/">status update blog post</a> about the current state of things, admitting that it currently won’t work but that they’re <a href="https://github.com/docker/roadmap/issues/142">working on it</a>. There are more <a href="https://finestructure.co/blog/2020/11/27/running-docker-on-apple-silicon-m1-follow-up">hacky ways to use Apple’s Hypervisor to run Docker container manually</a>, however this needs arm-based containers.</p><p>I expect a solution in Q1 2021 that runs arm-based containers. We’ll have to do some work to add arm-support (something already on the roadmap) so this is only a transitional issue.</p><h2 id="virtualization-and-windows">Virtualization and Windows</h2><p>To test our <a href="https://pspdfkit.com/pdf-sdk/windows/">Windows PDF SDK</a>, most folks are using a VMware virtual machine with Windows 10 and Visual Studio. Currently none of the Mac virtualisation solutions support Apple Silicon, however both <a href="https://appleinsider.com/articles/20/11/11/parallels-confirms-apple-m1-support-amid-silence-from-other-virtualization-companies">VMware and Parallels</a> are working on it. I do not expect Virtualbox to be updated <a href="https://forums.virtualbox.org/viewtopic.php?f=8&amp;t=98742">anytime soon</a>.</p><p>I expect that eventually we’ll be able to run ARM-based Windows with commercial tooling. Various <a href="https://9to5mac.com/2020/11/27/arm-windows-virtualization-m1-mac/">proof-of-concepts</a> already exist, and performance seems <a href="https://twitter.com/imbushuo/status/1332772957609922561?s=21">extremely promising</a>. Microsoft currently doesn’t sell ARM-based Windows, so getting a license will be interesting.</p><p>ARM-Windows can emulate x86 applications, and Microsoft is working on <a href="https://www.neowin.net/news/it039s-official-x64-emulation-is-coming-to-windows-on-arm">x64 emulation</a>, which is already rolling out in Insider builds. In a few months, it should be possible to develop and test our Windows SDK with Visual Studio on M1 in reasonable performance.</p><p>Running older versions of macOS might be more problematic. We currently support macOS 10.14 with our <a href="https://pspdfkit.com/blog/2017/pspdfkit-for-macos/">AppKit PDF SDK</a> and macOS 10.15 with the <a href="https://pspdfkit.com/blog/2019/pspdfkit-for-mac-catalyst/">Catalyst PDF SDK</a>, both OS releases that require testing. It remains to be seen if VMWare or Parallels include a complete x64 emulation layer. This would likely be really slow, so I wouldn’t count on it.</p><p><img src="https://d33wubrfki0l68.cloudfront.net/bbf100981357e4bc26c49722d31253daf76d293d/5b456/assets/img/2020/m1/memory.png" alt=""></p><p>Lastly, 16 GB RAM just isn’t a lot. When running parallel tests, the machine starts to heavily swap and performance really goes down the drain. This will be even more problematic with virtual machines running. Future machines will offer 32 GB options to alleviate this issue.</p><p><strong>Update:</strong> <a href="https://gist.github.com/niw/e4313b9c14e968764a52375da41b4278#file-readme-md">How to run Windows 10 on ARM in Qemu with Hypervisor.framework patches on Apple Silicon Mac</a></p><h2 id="android-studio">Android Studio</h2><p>IntelliJ is working on porting the <a href="https://youtrack.jetbrains.com/issue/JBR-2526">JetBrains Runtime</a> to Apple Silicon. The apps currently work through Rosetta 2, however building via Gradle is <a href="https://www.reddit.com/r/androiddev/comments/jx4ntt/apple_macbook_air_m1_is_very_slow_in_gradle_builds/">extremely slow</a>. Gradle creates code at runtime, which seems a particular bad combination with the Rosetta 2 ahead-of-time translation logic.</p><p>I expect that most issues will be solved by Q1 2021, however it will likely be some more time until all Java versions run great on ARM. A lot of effort has been put into <a href="https://bell-sw.com/java/arm/performance/2019/01/15/the-status-of-java-on-arm/">loop unrolling and vectorisation</a>, not everything there is available on ARM just yet.</p><p><strong>Update:</strong> <a href="https://www.azul.com/press_release/azul-announces-support-of-java-builds-of-openjdk-for-apple-silicon/">Azul offers macOS JDKs for arm64</a>, including for <a href="https://www.azul.com/downloads/zulu-community/?os=macos&amp;architecture=arm-64-bit&amp;package=jdk">Java 8</a>.</p><h2 id="homebrew">Homebrew</h2><p><a href="https://brew.sh/">Homebrew</a> currently works via Rosetta 2. Just prefix everything with <code>arch -x86_64</code> and it’ll just work. It is possible to install an additional (arm-based) version of Homebrew <a href="https://soffes.blog/homebrew-on-apple-silicon">under <code>/opt/homebrew</code></a> and mix setup, as <a href="https://github.com/Homebrew/brew/issues/7857">more and more software</a> is adding support for arm.</p><p>This is not a problem currently (performance is good) and will eventually just work natively.</p><h2 id="applications">Applications</h2><p>Most applications just work, Rosetta is barely noticeable. Larger apps to take a longer initial performance hit (e.g. Microsoft Word takes <a href="https://www.zdnet.com/article/microsoft-office-will-be-about-20-second-slower-initially-on-apple-silicon-rosetta-2/">around 20 seconds</a> until everything is translated), but then these binaries are cached and subsequent runs are fast.</p><p>There’s the occasional app that can’t be translated and fails on startup (e.g. <a href="https://beamer-app.com/download">Beamer</a> or the <a href="https://www.google.com/intl/en_gh/drive/download/">Google Drive “Backup and Sync” client</a>), but this is rare. Some apps are confused about their place on disk and ask to be moved to the Applications directory, when really it’s just the translated binary that runs somewhere else. Most of these dialogs can be ignored. Some apps (e.g. Visual Studio Code) <a href="https://twitter.com/steipete/status/1331884524934995968?s=21">block auto-updating</a> as the translated app location is readonly. However, in case of VS Code, the Insider build is already updated to ARM and just works.</p><p>Electron-based apps are slow if they run on Rosetta. It seems the highly optimized V8 JavaScript compiler blocks ahead-of-time translation. The latest stable version of Electron (Version 11) already <a href="https://www.electronjs.org/blog/apple-silicon">fully supports Apple Silicon</a>, and companies like Slack already updated their beta version to run natively.</p><p>Google just shipped <a href="https://www.macworld.com/article/3597749/google-releases-chrome-87-with-support-for-apple-silicon-macs.html">Chrome that runs on ARM</a>, however there’s still quite a performance gap between it and Apple Safari, which just <em>flies</em> on Apple Silicon.</p><h2 id="conclusion">Conclusion</h2><p>The new M1 MacBooks are fast, beautiful and silent and the hype is absolutely justified. There’s still a lot to do on the software-front to catch up, and the bugs around older iOS Simulators are especially problematic.</p><p>All of that can be fixed in software and the whole industry is currently working on making the experience better, so by next year, when Apple updates the 16-inch MacBook Pro and releases the next generation of their M chip line, it should be absolutely possible to use a M1 Mac as main dev machine.</p><p>For the time being, the M1 will be my <del>travel</del> secondary laptop, and I’ll keep working on the 2,4 GHz 16-inch MacBook Pro with 32 GB RAM, which just is the faster machine. I’ll be much harder to accept the loud, always-on fans though, now that I know what soon will be possible.</p></div></div>]]>
            </description>
            <link>https://steipete.com/posts/apple-silicon-m1-a-developer-perspective/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25238608</guid>
            <pubDate>Sat, 28 Nov 2020 16:47:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No Config for Old Men]]>
            </title>
            <description>
<![CDATA[
Score 358 | Comments 285 (<a href="https://news.ycombinator.com/item?id=25238523">thread link</a>) | @zdw
<br/>
November 28, 2020 | https://datagubbe.se/noconf/ | <a href="https://web.archive.org/web/*/https://datagubbe.se/noconf/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<p><b>...or anyone else, for that matter.</b></p>

<p><i>Autumn 2020</i></p>

<p>Ask anyone who's really into cooking and they'll tell you how important it is to have a kitchen that's arranged just right. To someone who rarely cooks, a kitchen is probably just a place to store a few pots and a toaster, and the placement of such stuff doesn't matter much: canned soup and microwave dinners are designed for ease of preparation.</p>


<p>For the enthusiastic home cook, however, a lot of things can go wrong. Often there's only a second's notice to fix something that might ruin a perfect meal or set you back hours of hard toil. Hollandaise starting to split? Better bring out that ice cold water post haste! Garlic burning? Better chop some more right this instant, or the pasta will be overcooked and there goes the Aglio e Oglio.</p>


<p>To achieve speed, you have to know where your knives, pots, pans, spoons, whisks and other utensils are and you want to be able to arrange them so that they're easy to reach. Seasonings, spices, herbs and condiments should be within reach from the stove. Then there's the mise en place before the actual cooking begins: chopping all the vegetables, cubing the meat, slicing the bacon and so on.</p>


<p>All of this is, thankfully, easy to achieve. Even the most cramped kitchen will, after having been battle tested through a few meals, be as optimal as possible according to the cook's personal preference. The same goes for painters, carpenters, car mechanics and even office dwellers. Hammer missing from the hammer hook? For shame! Stapler not to the immediate right of the stack of post-its? Well it should be!</p>


<h3>The regulated kitchen</h3>


<p>Now imagine if you couldn't organize your kitchen to your heart's content. Not because you're lacking the funds or skills, but because some federally appointed clerk is constantly coming to inspect it.</p>


<p>"Nah," he says, adjusting his clip-on tie, "you can't put your spices there. Against regulations. All spices must be kept more than two yards from the stove at all times." He then goes on to explain that you'll have to call him every time you want to use the stove, just to make sure the pots you're using are compliance tested. Plus, they have to be stored in the government approved pot storage cabinet below the sink, otherwise they're not fit for kitchen use.</p>


<p>Want to change the color of the counter top? Sorry, no can do. Want to switch from glass bowls to stainless? Alas, you used to be able a few years ago, but nobody wants stainless anymore anyway, right? The salt <i>can</i> be put next to the stove, but it's not recommended and might change in the near future. Knives are now to be honed every Tuesday afternoon by a designated craftsman. Sure, you can postpone a few times, but eventually, you just have to live with that. Plus, there's going to be some dudes coming to inventory your pantry on a regular basis, most likely when you're in the middle of cooking something really complicated. There's no use in protesting - this is all for your own good.</p>

<p>And yes.


</p><p>Of course this is a metaphor for computers.</p>


<h3>The curious disappearance of configuration</h3>


<p>For the casual user, some of this can <i>maybe</i> be convenient - or at least not annoying. If someone who rarely uses the kitchen has decided to whip up a home cooked feast, it doesn't matter that the spices are kept strangely far from the stove: they're just happy they found them. And <i>maybe</i> there is, for the casual user, some "security" in lock-in efforts such as MacOS calling home<sup><a href="#footnote1">[1]</a></sup> to check if a program is allowed to run and that web browsers automatically block certain URLs.</p>


<p>Likewise, maybe a handful of confused beginners are helped by the fact that certain system settings are extremely hard to find, or that you're supposed to put all your photos in a specific directory, or that you can't decide what partition you want to install a program on, or that some indexing service starts running when you least expect it, or that not a single application gives a crap about the few color settings you're allowed to make.</p>


<p>For the power user, such things range from nuisances to something that seriously hampers productivity and creativity.</p>


<p>It used to be that whenever I got a new computer, I spent a day or two setting it up. I selected the fonts I wanted to use, I picked the colors I liked for window decorations and GUI elements, I installed my preferred tools and utilities and I organized the desktop icons and program launchers to my liking. It took a bit of time, but it was a labor of love. In times of trouble I was, if nothing else, at least the boss of my own desktop environment.</p>


<p>I don't know of any proprietary OS where I can do that anymore. Linux is, considering what's going on with the major distributions, desktop environments and UI toolkits, seemingly heading the same way. Sure, pick your own window manager, see if we care - we've got client side decorations! Want to theme your GUI? Yeah, but not in our Snap packages you won't! Want to turn off cursor blinking? Mmmmyyeeaahhh, not too sure about that. Oh, you started a GUI file manager? Hey, enjoy the ten new folders we've littered your home directory with! They all start with capital letters: designed for typing convenience in a case sensitive file system.</p>


<p>Of course I still spend a fair amount of time setting up a Windows machine, but these days it's not the joyful experience of configuring the best fonts and nicest colors and arranging the icons on the start menu in the correct order for my muscle memory. Instead it's usually a week of swearing over removed settings and working hard to find the ones that actually remain, or trying various registry hacks to circumvent seemingly unchangeable defaults. I'm working against the system instead of with it, and someone else is trying to boss me around.</p>


<h3>A better example</h3>


<p>All of this could be different. It used to be. On my <a href="https://datagubbe.se/ltmag/">Amiga</a>, I could configure <i>everything</i>. Apart from things like fonts and colors I could draw my own mouse pointer, tiling desktop backgrounds and icons. (Yes, the system really shipped with separate little paint programs just for pointers, desktop tiles and icons.) I could customize double click speed and key repeat rates on millisecond levels. I could even control the exact position of individual icons and the size and position of every individual directory window opened.</p>


<p>Most casual users didn't care about all that, but they didn't have to. The system came with a reasonable set of defaults and when or if they grew more proficient and wanted to change something about their daily working environment, they had the option to do so.</p>


<p>This was a great approach to users. Instead of being treated like an incompetent moron and placed in a walled garden, you were entrusted and empowered. Something as simple as drawing my own mouse pointer on the Amiga was a profound and formative experience for me. As corny as it sounds, it was as if the guys who built this amazing machine put it in my hands and said, "Hey kid, you're in charge. This computer is yours. Learn how to use it and you can make it do anything." It was a call for exploration and creativity.</p>


<p>Today, I can't even change the system font in Windows. I can select an "accent color", but most applications completely ignore it. Every program defaults to downloading into a Downloads folder and I've lost count of how many times I've changed its folder view from grouped to not grouped, only to discover it's been magically changed back the next time I browse it. Lots of settings have been removed completely while others are buried deep in strange places where a user clearly isn't really supposed to venture.</p>


<p>The problem is that there's no toggle for enabling "advanced mode". I'm just supposed to accept that I can no longer change simple things I've been able to configure for the past thirty years. Someone, somewhere just decided that all users have the same basic skill level and that the defaults are always acceptable.</p>


<h3>General purpose Instagram cameras</h3>


<p>I suppose the lack of configurability is a metaphor for personal computing in general: we're not buying our machines, we're renting them by way of bizarrely complex EULA:s for everything from the firmware to the OS and we're not supposed to be curious or creative, we're supposed to sit back and passively consume advertisements. The base level of creative computer use is no longer exploring programming or graphics or music, but photographing a meal someone else has prepared and then applying a predefined sepia filter to said photo. The base level of configuring a system is no longer picking some personal favorites among fonts and colors, but - maybe - selecting between dark and light mode.</p>


<p>
On the flip side, more and more people also need to use computers 
for actually producing stuff - not least programming all those ad 
delivery platforms and the curiously unconfigurable operating systems 
they run on. But there are also armies of innocents; office workers,
administrators, hotel clerks, librarians, teachers - those people now often 
have no choice but to strain their eyes staring at black text on bright 
white backgrounds, unable to select a font they find easier to read.
</p>

<p>Too bad they can no longer store their spices close to the stove, but hey, who cares? Let them take one for the team. We're all swimming in ad revenue and if people learn to configure things, maybe they'll suddenly realize that the presence of those ads should be configurable as well.</p>

<br>

<hr>



<p id="footnote1">
<sup>1</sup> In case my sarcasm isn't coming through here: No, it's not secure. The privacy and security problems this entails are huge.
</p>

</div></div>]]>
            </description>
            <link>https://datagubbe.se/noconf/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25238523</guid>
            <pubDate>Sat, 28 Nov 2020 16:35:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Parsing All of Wikipedia to an Offline Encyclopedia]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 10 (<a href="https://news.ycombinator.com/item?id=25238316">thread link</a>) | @kxrm
<br/>
November 28, 2020 | https://daveshap.github.io/DavidShapiroBlog/automation/2020/11/15/parsing-all-wikipedia.html | <a href="https://web.archive.org/web/*/https://daveshap.github.io/DavidShapiroBlog/automation/2020/11/15/parsing-all-wikipedia.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://daveshap.github.io/DavidShapiroBlog/automation/2020/11/15/parsing-all-wikipedia.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25238316</guid>
            <pubDate>Sat, 28 Nov 2020 16:01:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Emacs Conference 2020]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25238266">thread link</a>) | @dangom
<br/>
November 28, 2020 | https://emacsconf.org/2020/ | <a href="https://web.archive.org/web/*/https://emacsconf.org/2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div class="page">



<div id="pagebody">







<div id="content" role="main">
<p>EmacsConf 2020 | Online Conference | <strong>November 28 and 29, 2020</strong><br>
<a href="https://emacsconf.org/i/emacsconf-logo1-256.png"><img src="https://emacsconf.org/i/emacsconf-logo1-256.png" width="256" height="256" alt="EmacsConf logo"></a><br>
<a href="https://emacsconf.org/2020/schedule/"><strong>Schedule</strong></a> | <a href="https://emacsconf.org/2020/poster/"><strong>Poster</strong></a> | <a href="https://emacsconf.org/2020/planning/">Planning</a> |
<a href="https://emacsconf.org/conduct/">Code of Conduct</a></p>

<p>EmacsConf is the conference about the joy of Emacs, Emacs Lisp, and
memorizing key sequences.</p>

<p>EmacsConf 2020 was on November 28 (Sat) and November 29 (Sun),
2020 from 9am-5pm Toronto/EST time; equivalently, 6am-2pm PST,
2pm-10pm UTC, 3pm-11pm Zurich/CET.</p>

<p>It made sense to hold EmacsConf 2020 as a virtual (online) conference
again this year, especially now, given the current state of the world
with the ongoing global pandemic. We remain fully committed to
freedom, and we will continue using our infrastructure and streaming
setup consisting entirely of <a href="https://www.gnu.org/philosophy/free-sw.html">free software</a>, much like the
last EmacsConf. Check out the <a href="https://emacsconf.org/2020/schedule/"><strong>Schedule</strong></a> and
<a href="https://emacsconf.org/2020/poster/"><strong>Poster</strong></a> for more details.</p>

<h2>Watching</h2>

<p>Over the next few weeks, we'll split up the bulk video recordings into
individual talks. We'll post the videos and links on the individual
talk pages, and we'll send an update to the
<a href="https://lists.gnu.org/mailman/listinfo/emacsconf-discuss">emacsconf-discuss</a> mailing list. In the meantime,
please enjoy <a href="https://emacsconf.org/2019/talks/">last year's talks</a>.</p>

<h2>Participating</h2>

<p>For audience questions specifically, we experimented with using a
collaboratively-editable Etherpad as the primary means of collecting
audience questions. <a href="https://etherpad.wikimedia.org/p/emacsconf-2020">https://etherpad.wikimedia.org/p/emacsconf-2020</a>
We also took questions from our IRC channel (<code>#emacsconf</code> on
<code>chat.freenode.net</code>), with volunteers adding questions from that
channel to the pad on behalf of folks who were not able to or prefer
not to use the web-based questions pad.</p>

<p>Come hang out with us in <code>#emacsconf</code> on <code>chat.freenode.net</code>.  You can
join the chat using <a href="ircs://chat.freenode.net:6697/emacsconf">your favourite IRC client</a>, or by visiting
<a href="https://chat.emacsconf.org/">chat.emacsconf.org</a> in your web browser, a self-hosted instance
of <a href="https://thelounge.chat/">The Lounge</a> free software web IRC client for EmacsConf.</p>

<p>To follow up after the conference, please check the <a href="https://emacsconf.org/2020/schedule/">schedule</a> for
the link to the individual talk page. Over the next few weeks, we'll
add notes from the pad, other resources, and followup contact
information from speakers.</p>

<h2>Updates</h2>

<p>Be sure to subscribe to our mailing list
<a href="https://lists.gnu.org/mailman/listinfo/emacsconf-discuss">emacsconf-discuss</a> for discussion and
announcements about the conference.</p>

</div>







</div>



</div></div>]]>
            </description>
            <link>https://emacsconf.org/2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25238266</guid>
            <pubDate>Sat, 28 Nov 2020 15:54:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A minimal Android system for RISC-V]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25238101">thread link</a>) | @homarp
<br/>
November 28, 2020 | https://plctlab.github.io/aosp/create-a-minimal-android-system-for-riscv.html | <a href="https://web.archive.org/web/*/https://plctlab.github.io/aosp/create-a-minimal-android-system-for-riscv.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <section id="main_content">
        

<p>Chen Wang, 2020.11.24</p>

<p>After a period of hard work, we can now run an Android “minimal system” on QEMU of RISC-V.</p>

<p>The following is a brief summary of the current work. Although the road ahead is still long, there is something to have a look.</p>

<h2 id="1-requirement-analysis">1. Requirement analysis</h2>

<p>The full name of our project is “AOSP for RISC-V”, and all the source code is currently opened on github: <a href="https://github.com/aosp-riscv">https://github.com/aosp-riscv</a>. The ultimate goal of our project is to port Android on RISC-V. Of course, this goal is huge.</p>

<p>But in the short term, we still have a small goal, which is described in one sentence: <code>based on the RISC-V platform, realize the kernel part of Android running on QEMU, and run the Android Shell</code>.</p>

<p>Based on the above objectives, the specific analysis is to realize a minimal Android system. The meaning of “minimal system” here is the so-called “bootable unix-style command line operating system”. In the traditional sense, a complete “minimal system” is described on the left side of the figure below. From bottom to top, the bottom is the hardware (note: hardware is not part of our “minimal system”). The first layer of software running on the hardware is the “Operating System Kernel”, and upon the OS kernel is the <a href="https://en.wikipedia.org/wiki/C_standard_library">“C library”</a>. Based on the C Library, we can build a minimal file system, which is essentially a bunch of command-line tools. These command-line tools must include at least a <a href="https://en.wikipedia.org/wiki/Init">“init”</a>, which is used to start the basic login shell in cooperation with the kernel, and one <a href="https://en.wikipedia.org/wiki/Unix_shell">“Shell”</a> is used to interact with users and call other tools and programs. With this “minimal system”, our big goal has a foundation.</p>

<p><img src="https://plctlab.github.io/aosp/diagrams/mini-system.png" alt="a minimal unix-style os"></p>

<p>Through the investigation of AOSP, I roughly summarized the work we need to achieve as follows:</p>

<ul>
  <li>Hardware part: Here we first use QEMU for RISC-V to simulate.</li>
  <li>OS Kernel: The kernel of Android uses Linux, of course, it has some patches of its own.</li>
  <li>C Library: Android has its own C library, which is bionic. It differs from the GNU C library (glibc) in that it is designed for devices with low memory and processor capabilities and running on Linux. It is released under the BSD license, rather than using the GNU public license like glibc.</li>
  <li>Root filesystem: Android has its own complex file system organization. As the goal of our experiment, what we need is the most streamlined and smallest file system. There is no need to transplant the complete Android system over, so I chose toybox to implement our various kind of command line tool. Someone may ask why we don’t use the more famous busybox. The reason is still related to the software license. Busybox uses GPL, while toybox uses BSD, which is more in line with Android’s appetite. Therefore, toybox is included in the source tree of AOSP, but busybox is not. In addition, I need to mention, because the implementation of toybox is very simple, the shell that provided by toybox does not work properly. Fortunately, Android already has its own official Shell, which is mksh, so we use mksh directly.</li>
</ul>

<h2 id="2-introduction-to-porting-work">2. Introduction to porting work</h2>

<p>The above talked about what needs to be done in the overall porting work. In fact, there are still many details in the specific implementation. Since our final goal (to transplant AOSP as a whole to RISC-V) is far from being achieved, I will briefly sort out what I have achieved so far, just for memo:</p>

<ul>
  <li>Operating platform (hardware): currently adopt QEMU temporarily.</li>
  <li>AOSP version: tag based on <code>android-10.0.0_r39</code>.</li>
  <li>Toolchain environment: building of AOSP has been completely migrated to LLVM/CLANG, but GNU tools are still used in linking. Since the prebuild tool chain that comes with AOSP does not support RISC-V, I have to build my own LLVM/Clang and GNU-tools.</li>
  <li>Kernel porting: the kernel version I used tag <code>android-5.4-stable</code> for andorid common repository plus tag <code>android11-release</code> for configs repository.</li>
  <li>The porting of the BIONIC library, as mentioned earlier, is based on the tag <code>android-10.0.0_r39</code> too. Considering the requirements in first phase, only the static library of libc is implemented, the dynamic library of libc is not implemented, neither for libm/libdl/libstdc++/linker till now (but I will handle them soon later). In other words, the following executable programs such as toybox and mksh are statically linked. libc is the most important part of bionic, and the composition is quite complex. The main components and the dependencies between them are briefly summarized in following diagram:</li>
</ul>

<p><img src="https://plctlab.github.io/aosp/diagrams/bionic-libc.png" alt="bionic libc"></p>

<ul>
  <li>toybox: As mentioned earlier, it is based on tag <code>android-10.0.0_r39</code>, but with a lot of tailoring. Because the toybox in Android includes many Android-specific features, such as SELinux and encryption, etc. In order not to involve too much effort in current phase, I disabled these functions and only retain some basic common functions.</li>
  <li>mksh: The Shell looks relatively simple, just make sure there is no problem with the compilation.</li>
  <li>There is also a big work involved in the construction of the build system. I did not use the native Soong system that comes with AOSP, because in the pre-research process, I found that it is not easy to add a new ARCH from scrach in the existing AOSP build system (i.e. to use the traditional lunch + m). AOSP’s building system is too complicated and mature for existing ARCH that supported, but it is not friendly to latecomers. In order to reduce the risk and focus on the key areas in advance, I chose to use make and rewrite the makefiles for modules (bionic/toybox/mksh) that need to be ported. Of course, we still need to find a chance to move to AOSP Soong later, just let’s do it later.</li>
</ul>

<h2 id="3-steps-to-make-this-minimal-system">3. Steps to make this minimal system</h2>

<p>After some work, the above small goal has been initially completed, and at least one of the “minimal Android systems” we defined above can be launched on QEMU. The related porting and modification have been opened on github. Allow me brief following steps and you are welcomed to have a try and test, submit PR, or directly participate in our AOSP porting work.</p>

<h3 id="31-environmental-preparation">3.1 Environmental preparation</h3>

<p>The experiment is based on Ubuntu 20.04 LTS</p>

<div><div><pre><code>$ lsb_release -a
No LSB modules are available.
Distributor ID: Ubuntu
Description: Ubuntu 20.04 LTS
Release: 20.04
Codename: focal
</code></pre></div></div>

<p>The software that needs to be installed in advance is as follows:</p>

<div><div><pre><code>$ sudo apt install autoconf automake autotools-dev curl libmpc-dev libmpfr-dev libgmp-dev \
                  gawk build-essential bison flex texinfo gperf libtool patchutils bc \
                  zlib1g-dev libexpat-dev git \
                  libglib2.0-dev libfdt-dev libpixman-1-dev \
                  libncurses5-dev libncursesw5-dev
</code></pre></div></div>

<p>Then create a working directory <code>riscv64-linux</code>, the following operations are performed under this directory.</p>

<div><div><pre><code>$ mkdir riscv64-linux
$ cd riscv64-linux
</code></pre></div></div>

<h4 id="311-building-gnu-toolchain">3.1.1 Building GNU toolchain</h4>

<p>Download source code</p>

<div><div><pre><code>$ git clone https://github.com/riscv/riscv-gnu-toolchain
</code></pre></div></div>

<p>Enter the source directory:</p>



<p>Note that the main repository of clone above does not contain the contents of the sub-repositories, so you need to continue to update the sub-repositories. Note that the sub-repository of qemu is excluded first, because the complete download of qemu is too large; second, qemu is actually not needed for the toolchain compilation itself.</p>

<div><div><pre><code>$ git rm qemu
$ git submodule update --init --recursive
</code></pre></div></div>

<p>Wait patiently for the sub-repository download to complete.</p>

<p>Note that due to I want to install the tools to <code>/opt/riscv64</code>, so sudo is required for make.</p>

<div><div><pre><code>$ ./configure --prefix=/opt/riscv64
$ sudo make linux -j $(nproc)
</code></pre></div></div>

<p>Export the installation path of the toolchain. You can also write to the <code>.bashrc</code> file.</p>

<div><div><pre><code>export PATH="$PATH:/opt/riscv64/bin"
</code></pre></div></div>

<p>Test whether the toolchain is installed successfully.</p>

<div><div><pre><code>$ riscv64-unknown-linux-gnu-gcc -v
</code></pre></div></div>

<p>Output similar to the following shows that the toolchain is compiled and installed normally.</p>

<div><div><pre><code>Using built-in specs.
COLLECT_GCC=riscv64-unknown-linux-gnu-gcc
COLLECT_LTO_WRAPPER=/opt/riscv64/libexec/gcc/riscv64-unknown-linux-gnu/10.1.0/lto-wrapper
Target: riscv64-unknown-linux-gnu
Configured with: /home/u/ws/riscv64-linux/riscv-gnu-toolchain/riscv-gcc/configure --target=riscv64-unknown-linux-gnu --prefix=/opt/riscv64 --with-sysroot= /opt/riscv64/sysroot --with-system-zlib --enable-shared --enable-tls --enable-languages=c,c++,fortran --disable-libmudflap --disable-libssp --disable-libquadmath- -disable-libsanitizer --disable-nls --disable-bootstrap --src=.././riscv-gcc --disable-multilib --with-abi=lp64d --with-arch=rv64imafdc --with-tune =rocket'CFLAGS_FOR_TARGET=-O2 -mcmodel=medlow''CXXFLAGS_FOR_TARGET=-O2 -mcmodel=medlow'
Thread model: posix
Supported LTO compression algorithms: zlib
gcc version 10.1.0 (GCC)
</code></pre></div></div>

<h4 id="312-build-llvmclang-tool-chain">3.1.2 Build LLVM/Clang tool chain</h4>

<p>Make sure to return to the working directory <code>riscv64-linux</code> first.</p>

<p>After updating Ubuntu 20.04 LTS to the latest state, the software requirements for building llvm/clang should have been supported by default. Other tools needed in the compilation process are basically available on Ubuntu. If something is missed, please install it yourself.</p>

<p>Download the source code of llvm. The official source code repository is at github: <a href="https://github.com/llvm/llvm-project">https://github.com/llvm/llvm-project</a>.</p>

<div><div><pre><code>$ git clone https://github.com/llvm/llvm-project
</code></pre></div></div>

<p>After downloading, enter the root directory of the source code repository and check out the corresponding version. I choose thhe official release version <code>10.0.1-final</code> and switch to the <code>10.x</code> branch.</p>

<div><div><pre><code>$ cd llvm-project/
$ git checkout release/10.x
$ mkdir build
$ cd build
$ cmake -G "Unix Makefiles" \
-DCMAKE_BUILD_TYPE=Release \
-DCMAKE_INSTALL_PREFIX=../install \
-DLLVM_TARGETS_TO_BUILD="RISCV" \
-DLLVM_ENABLE_PROJECTS="clang;libcxx;libcxxabi" \
-DLLVM_DEFAULT_TARGET_TRIPLE="riscv64-unknown-linux-gnu" \
../llvm
$ make -j $(nproc)
$ make install
</code></pre></div></div>

<p>Simply check the results of the installation.</p>

<div><div><pre><code>$ ls ../install/ -l
total 20
drwxrwxr-x 2 u u 4096 October 9 11:37 bin
drwxrwxr-x 7 u u 4096 Oct 9 11:37 include
drwxrwxr-x 4 u u 4096 October 9 11:37 lib
drwxrwxr-x 2 u u 4096 October 9 11:37 …</code></pre></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://plctlab.github.io/aosp/create-a-minimal-android-system-for-riscv.html">https://plctlab.github.io/aosp/create-a-minimal-android-system-for-riscv.html</a></em></p>]]>
            </description>
            <link>https://plctlab.github.io/aosp/create-a-minimal-android-system-for-riscv.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25238101</guid>
            <pubDate>Sat, 28 Nov 2020 15:29:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dataframes and the proliferation of bad code in data science]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25237677">thread link</a>) | @soumendra
<br/>
November 28, 2020 | https://databiryani.com/dataframes/machine-learning/data-science/2020/11/28/dataframes-and-the-proliferation-of-bad-code-in-data-science.html | <a href="https://web.archive.org/web/*/https://databiryani.com/dataframes/machine-learning/data-science/2020/11/28/dataframes-and-the-proliferation-of-bad-code-in-data-science.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <ul>
<li><a href="#why-good-code-is-important">Why good code is important?</a></li>
<li><a href="#why-data-scientists-write-bad-code">Why data scientists write bad code?</a></li>
<li><a href="#cult-of-kaggle">Cult of Kaggle</a></li>
<li><a href="#state-mismanagement">State Mismanagement</a>
<ul>
<li><a href="#what-is-state-mismanagement">What is state mismanagement?</a></li>
<li><a href="#why-state-management-is-important">Why state management is important?</a></li>
<li><a href="#state-mismanagement-with-dataframes">State mismanagement with DataFrames</a></li>
</ul>
</li>
<li><a href="#poorly-abstracted-codebases">Poorly abstracted codebases</a>
<ul>
<li><a href="#consequences">Consequences</a></li>
</ul>
</li>
<li><a href="#how-to-do-better">How to do better?</a></li>
<li><a href="#acknowledgments">Acknowledgments</a></li>
<li><a href="#discuss-this-post">Discuss this post</a></li>
</ul>

<p>Developing a solution with machine learning is equal parts science and software engineering. The science of it is important, certainly, but your success will be equally dependant, if not more, on how you engineer your solution. Given the abundance of libraries that implement state-of-the-art algorithms for easy consumption and the data (and pre-trained models) to go with them, your ability to engineer your code well is the critical component for your success.</p>

<blockquote>
  <p>Between two somewhat comparable data scientists, the one with better software engineering skills is more likely to succeed in a machine learning project than the one with better machine learning skills.</p>
</blockquote>

<p>The reasons are twofold. First, the barrier to entry to build effective models is getting lower as many high-level libraries make it increasingly easier to solve a wide variety of problems in machine learning and deep learning. State-of-the-art results become available (as pre-trained models) in a matter of weeks after publication. There is always a tutorial around the corner showing you how to tackle your ml/dl problems with freely available tools.</p>

<p>Secondly, the data science culture is a mess, leading to a focus on model performance rather than real-life performance (which can be measured only after deployment). For data scientists, the impetus is more on getting the experiments right, quickly; whatever it takes to achieve that! But the value from data science/machine learning projects comes from their deployment, not modeling experiments.</p>

<blockquote>
  <p>A more effective data scientist is the one who deploys more often, not the one with better model scores.</p>
</blockquote>

<p>The culture around this is changing though, and we hope to be a part of that change.</p>



<p>In this issue, we focus on our perception of the core reasons coming from working with and educating a lot of data scientists over the years.</p>

<p>Primarily, we think the problem arises from how the <strong>Cult of Kaggle</strong> (not in the way you think) promoted a habit of <strong>State Mismanagement</strong>, which results in <strong>Poorly abstracted codebases</strong> hurting data science projects.</p>



<p>Kaggle is a competition platform for machine learning and deep learning, and a lot of people complain that Kaggle is not real data science. That it sets up wrong expectations with its super-clean datasets neatly divided into train/test-sets, freeing the data scientist to focus only on the modeling problem and not have to worry about data issues.</p>

<p>While this is a valid criticism, we believe that there is a place and utility for such a platform. Given the fantastic community that has come up around Kaggle, it is now one of the most popular platforms for new (and old) data scientists to hone their craft.</p>

<p>The problem is the outsized role Kaggle plays in the education of data scientists. Given a new problem, most will try to get to those train/test-sets (and possibly a validation-set thrown in) and try to get a model that “works” in the <a href="https://en.wikipedia.org/wiki/Empirical_risk_minimization">empirical risk management</a> sense (on the test-set, of course).</p>

<blockquote>
  <p>For data scientists, the impetus is more on getting the experiments right, quickly; whatever it takes to achieve that! But the value from data science/machine learning projects comes from their deployment, not modelling experiments.</p>
</blockquote>

<p>This results in code that has bad abstractions. This code is usually propped up with all sorts of hacky engineering practices and put into production.</p>

<p>But if we have to put our finger on one bad abstraction that is pervasive in the data science (engineering) universe and responsible for much of the bad code, it will be state mismanagement.</p>



<p>DataFrames are one of the most ubiquitous and useful data structures, no matter what stack you are using, and they are also very useful to see if a codebase is likely to be bad.</p>

<blockquote>
  <p>If most of the functions in your codebase accept dataframes as input and return dataframes as output, you are likely not modelling the entities correctly and writing hacky code to patch things.</p>
</blockquote>

<h2 id="what-is-state-mismanagement">
What is state mismanagement?</h2>

<p>If you are coming from a traditional programming background, having done webapps or backends or any of the myriad things we do when we code, you’ll be used to creating some kind of abstraction to model the entities involved in your code. A customer, a purchase, a geographic location - any of these could be an entity of interest given the problem we have.</p>

<p>With <a href="https://en.wikipedia.org/wiki/Object-oriented_programming">OOP</a>, you may have created classes to represent and model the state/behaviour of those entities. With <a href="https://en.wikipedia.org/wiki/Functional_programming">FP</a>, you may have focussed more on the state and the transitions those entities go through.</p>

<p>By <strong>state mismanagement</strong>, we refer to the situation when we don’t create these abstractions.</p>

<h2 id="why-state-management-is-important">
Why state management is important?</h2>

<p>These abstractions are very useful. We can write tests against them. We can use them to debug our code. We can persist them and inspect them later when something goes wrong. These abstractions also make code readable - we can follow the state and transitions of entities to understand what is happening. We can also use the <a href="https://en.wikipedia.org/wiki/Type_system">type of these abstractions</a> to debug/reason about our code <a href="https://en.wikipedia.org/wiki/Strong_and_weak_typing">if it is possible</a>.</p>

<h2 id="state-mismanagement-with-dataframes">
State mismanagement with DataFrames</h2>

<p>DataFrames list all observations of an experiment as rows and attributes of those observations as columns. They are similar to the tables in databases we are used to, but most dataframes in a data science project will typically combine many tables (each table typically represents an entity) into a single object (which will represent/hide states of many entities together).</p>

<p>When we don’t explicitly model different entities, our ability to reason about and debug/inspect them gets diminished significantly. We can’t write tests against functions that do things with those entities and their states. Most of our functions will accept dataframes as input and return dataframes as output, and will typically be in violation of the <a href="https://en.wikipedia.org/wiki/SOLID">SOLID principle</a>.</p>

<p>There are, of course, situations where dataframes are the correct solution. But someone not used to thinking about hidden entities and their states may not use them optimally.</p>

<blockquote>
  <p>The habit of including the states of many entities together in a single dataframe is the most prevalent reason for bad code that we have seen.</p>
</blockquote>

<p>When <a href="https://www.thoughtworks.com/insights/blog/coding-practices-data-scientists">we talk about the poor standard of software engineering</a> in data science, we talk a lot about peripheral issues, but incorrect and <a href="https://medium.com/@karpathy/yes-you-should-understand-backprop-e2f06eab496b">leaky abstractions</a> are the main reason why most of the codebase we have seen suck. If you don’t even model your data adequately, how do you become <a href="http://karpathy.github.io/2019/04/25/recipe/#1-become-one-with-the-data">one with the data</a>?</p>

<p>Models doing well in training and poorly in production, whether due to <a href="https://en.wikipedia.org/wiki/Concept_drift">drift</a> or <a href="https://twitter.com/araffin2/status/1329382226421837825">underspecification</a>, is a <a href="https://arxiv.org/abs/2011.03395">real problem</a>. Without the necessary abstractions in place, it becomes very difficult to monitor, detect, and debug issues when they arise.</p>

<div><p>
If you like what you have read so far, you may consider subscribing to our newsletter.
</p>
</div>



<p>When we say poor abstractions result in poor code, lack of <a href="https://en.wikipedia.org/wiki/SOLID">SOLID</a>-ness is mostly what we mean. A lot of the hacky software engineering practices we have seen in the wild arise as a consequence.</p>

<h2 id="consequences">
Consequences</h2>

<ul>
  <li>
<strong>Deploying models</strong>: The pattern for consuming data in production is different compared to training. Abstractions created to explore/test/validate data in training can be mostly reused in deployment, and the lack of them hurts greatly.</li>
  <li>
<strong>Writing tests</strong>: It is hard to write meaningful tests if models (datastructures) for the entities in data are not available. This is why we are not seeing more tests in ML even though everyone is talking about them.</li>
  <li>
<strong>Monitoring models</strong>: So your credit default model is starting to perform poorly. Is this across the board, or only for a certain segment for certain entities (geocode, user-acquisition-channel cohort, or month)? Hard to answer this quickly in real-time while your deployed models are falling apart (and losing money) if you have not spent the time and effort to model the data and set up appropriate tests/monitoring.</li>
  <li>
<strong>Reproducibility</strong>: Reproducibility can come in many forms. You may be unable to reproduce the older models during monthly updates (data and hyperparameter versioning is another issue entirely), or the same deep learning-based model may produce different embeddings in a cpu-based deployment server when moved from a gpu-based training server. Without correct abstractions to debug with, you’ll be left wondering what is going wrong.</li>
  <li>
<strong>Commenting and reading code</strong>: Poorly written code with a lot of dataframe needs a lot of documentation, and anyone who has worked in a live codebase knows that good comment coverage is a moving goalpost (moving as the code changes).</li>
</ul>

<p>(Note: If you are working with a Python stack, type-annotation is your friend. If you have to use a lot of <em>any</em> or <em>DataFrame</em> types, you are probably doing it wrong. In a correctly architected codebase, type-annotation can completely replace all forms of commenting and still make reading the codebase a breeze.)</p>



<p>As @seanjtaylor said, <em>there are no hard problems, only slow iterations</em>.</p>

<p>If you have an existing codebase that you think suffers from the issues we outline, start by refactoring small chunks of it (larger chunks will mean slower iterations and you’ll learn slower). If you are starting a new codebase, you can identify and model your entities and <a href="http://karpathy.github.io/2019/04/25/recipe/">be one with your data</a> before you start modeling.</p>

<p>And if you already kaggle, don’t stop. Just recognize that the things in Kaggle that give you dopamine hits should not be the same things that give you dopamine hits when you work on a production system. Hack that dopamine!</p>



<p>We are heavily indebted to our colleagues at Difference Engine for the thoughtful conversations and prompts. Particularly, this essay would not have been possible without the insightful …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://databiryani.com/dataframes/machine-learning/data-science/2020/11/28/dataframes-and-the-proliferation-of-bad-code-in-data-science.html">https://databiryani.com/dataframes/machine-learning/data-science/2020/11/28/dataframes-and-the-proliferation-of-bad-code-in-data-science.html</a></em></p>]]>
            </description>
            <link>https://databiryani.com/dataframes/machine-learning/data-science/2020/11/28/dataframes-and-the-proliferation-of-bad-code-in-data-science.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25237677</guid>
            <pubDate>Sat, 28 Nov 2020 14:27:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cloud Native Computing Foundation Announces Etcd Graduation]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25237523">thread link</a>) | @talonx
<br/>
November 28, 2020 | https://www.cncf.io/announcements/2020/11/24/cloud-native-computing-foundation-announces-etcd-graduation/ | <a href="https://web.archive.org/web/*/https://www.cncf.io/announcements/2020/11/24/cloud-native-computing-foundation-announces-etcd-graduation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<article>
		
						

		<div>
			
<figure><img loading="lazy" width="1024" height="506" src="https://www.cncf.io/wp-content/uploads/2020/11/CNCF_Grad_Cards_etcd-1024x506.jpg" alt="" srcset="https://www.cncf.io/wp-content/uploads/2020/11/CNCF_Grad_Cards_etcd-1024x506.jpg 1024w, https://www.cncf.io/wp-content/uploads/2020/11/CNCF_Grad_Cards_etcd-300x148.jpg 300w, https://www.cncf.io/wp-content/uploads/2020/11/CNCF_Grad_Cards_etcd-768x380.jpg 768w, https://www.cncf.io/wp-content/uploads/2020/11/CNCF_Grad_Cards_etcd-1536x759.jpg 1536w, https://www.cncf.io/wp-content/uploads/2020/11/CNCF_Grad_Cards_etcd-325x161.jpg 325w, https://www.cncf.io/wp-content/uploads/2020/11/CNCF_Grad_Cards_etcd-700x346.jpg 700w, https://www.cncf.io/wp-content/uploads/2020/11/CNCF_Grad_Cards_etcd-320x158.jpg 320w, https://www.cncf.io/wp-content/uploads/2020/11/CNCF_Grad_Cards_etcd-515x255.jpg 515w, https://www.cncf.io/wp-content/uploads/2020/11/CNCF_Grad_Cards_etcd-640x316.jpg 640w, https://www.cncf.io/wp-content/uploads/2020/11/CNCF_Grad_Cards_etcd-1280x633.jpg 1280w, https://www.cncf.io/wp-content/uploads/2020/11/CNCF_Grad_Cards_etcd.jpg 2001w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p><em>Widely used data store solution for orchestrators has seen </em><em>200 distinct contributors in the past 12 months</em></p>



<p><strong>SAN FRANCISCO, Calif. – November 24, 2020 – </strong><a href="https://www.cncf.io/">The Cloud Native Computing Foundation</a>® (CNCF®), which builds sustainable ecosystems for cloud native software, today announced the graduation of etcd. To move from the maturity level of <a href="https://github.com/cncf/toc/blob/master/process/graduation_criteria.adoc">incubation to graduation</a> etcd has demonstrated growing adoption, an open governance process, feature maturity, and a strong commitment to community, sustainability, and inclusivity.</p>



<p><a href="https://etcd.io/">etcd</a> is a distributed, reliable key-value store and provides a reliable way to store data that needs to be accessed by a distributed system or cluster of machines. Applications of any complexity, from a simple web app to Kubernetes, can read data from and write data into etcd. The project was created at CoreOS in 2013 and joined CNCF in December 2018 as an incubating project.&nbsp;</p>



<p>“The etcd project is a key component inside Kubernetes along with many other projects that depend on etcd for reliable distributed data storage,” said Chris Aniszczyk, CTO of the Cloud Native Computing Foundation. “We remain impressed by the milestones that etcd continues to reach in scale and mature handling of its recent security audit, we look forward to cultivating its community as a graduated project.”</p>



<p>etcd is used in production by <a href="https://github.com/etcd-io/etcd/blob/master/ADOPTERS.md">many companies</a>, including Alibaba, Amazon, Baidu, Cisco, EMC, Google, Huawei, IBM, Red Hat, Uber, Verizon, and more, and projects including Kubernetes, CoreDNS, M3, Rook, and TiKV.</p>



<p>“Having etcd as our meta-store in Placement Driver and our inspiration for Raft implementation in production has proven to be a great choice for TiKV and TiDB, ensuring data consistency and high availability across TiDB clusters,” said Ed Huang, co-founder and CTO at PingCAP. “We are proud and glad to be part of its graduation journey, and we’d love to be involved in its ecosystem development more in the future.”</p>



<p>The <a href="https://github.com/etcd-io/etcd/blob/master/MAINTAINERS">maintainer</a> team currently consists of 10 members, with a healthy distribution of corporations represented, including Alibaba, Amazon, Cockroach Labs, Google Cloud, IBM, Indeed, and Red Hat. Three new maintainers have been added since etcd became an incubating project. Over the last 12 months, 200 distinct contributors have authored pull requests.</p>



<p>“After seven years of development, etcd has reached maturity and become the cornerstone of many distributed systems. The most important decision for its success was joining the CNCF community and growing its maintainers across many organizations,” said Xiang, etcd maintainer, CNCT TOC member, and engineering director at Alibaba Cloud. “We are excited to see its graduation at CNCF. etcd is the centerpiece powering the container service and many other critical services at Alibaba Cloud. We are looking forward to improving its stability, reliability, and performance with the community in the future.”</p>



<p>A third-party <a href="https://www.cncf.io/blog/2020/08/05/etcd-security-audit/">security audit</a> sponsored by CNCF was performed in July 2020 for the latest major release of etcd, v3.4 by Trail of Bits. According to the <a href="https://github.com/etcd-io/etcd/blob/master/security/SECURITY_AUDIT.pdf">report</a>, the etcd codebase represents a mature and heavily adopted product, and there were no significant issues found in the core components of etcd. One high severity issue was found in the etcd gateway, which the team addressed with fixes and backported into etcd supported releases.&nbsp;</p>



<p>The project also went through Jepsen testing, which analyzes open source distributed systems to check if they fulfill their consistency guarantees, in January 2020. The <a href="https://etcd.io/blog/jepsen-343-results/">results</a> showed maturity in the project functionality. The Jepsen team also pointed out a few areas for improvements, which were implemented by the etcd team.&nbsp;</p>



<p>“From the beginning, etcd was designed to ease consensus store operations, making it attractive for use with container orchestration systems like Kubernetes. etcd’s selection as the control plane storage for Kubernetes proved a great fit, and two projects have grown and matured together,” said Joe Betz, etcd maintainer and software engineer at Google Cloud. “We are excited to see etcd’s dedication toward reliability, scalability, and quality recognized by the CNCF with this graduation. Today’s announcement is a testament to the maturity of etcd and its readiness for production workloads.”&nbsp;</p>



<p>“Today’s major milestone of the graduation of etcd, could not have been accomplished without the work of the community and the support from the CNCF,” said Sahdev Zala, senior software engineer, open technology, IBM and etcd maintainer. “etcd is playing a critical role providing a distributed key-value store that is highly available and meets the strong consistency requirements demanded by large scale Kubernetes clusters.”</p>



<p>“Open source software powers our lives in so many ways,” said Bob Wise, General Manager of Kubernetes at AWS. “From Linux to Kubernetes, open communities of builders from all sizes of organizations and walks of life spend considerable time creating and maintaining projects that underpin much of the internet, telecommunications, finance, transportation, gaming, retail, and healthcare systems we use every day.&nbsp; etcd is one of these critical projects, and we’re proud to have etcd as a core part of Amazon EKS and to be involved in helping the project grow and thrive. We are fervent supporters of etcd’s graduation and look forward to collaborating with etcd and other CNCF projects to build secure, reliable, powerful, and scalable open source software.”</p>



<p>To officially graduate from incubating status, the project was certified for <a href="https://bestpractices.coreinfrastructure.org/en/projects/3192">CII Best Practices Badge</a>, completed security audits and addressed vulnerabilities, defined its own <a href="https://github.com/etcd-io/etcd/blob/master/GOVERNANCE.md">governance</a>, and adopted the <a href="https://github.com/etcd-io/etcd/blob/master/code-of-conduct.md">CNCF Code of Conduct</a>.</p>



<p><strong>etcd Background</strong></p>



<p>etcd is a distributed, reliable key-value store for the most critical data of a distributed system, with a focus on being:</p>



<ul><li>Simple: well-defined, user-facing API (gRPC)</li><li>Secure: automatic TLS with optional client cert authentication</li><li>Fast: benchmarked 10,000 writes/sec</li><li>Reliable: properly distributed using Raft</li></ul>



<p>To learn more about etcd, visit <a href="https://etcd.io/">etcd.io</a>.&nbsp;</p>



<p><strong>Additional Resources</strong></p>



<ul><li><a href="https://www.cncf.io/newsroom/newsletter/">CNCF Newsletter</a></li><li><a href="https://twitter.com/cloudnativefdn/">CNCF Twitter</a></li><li><a href="https://cncf.io/">CNCF Website</a></li><li><a href="https://cncf.io/join">Learn About CNCF Membership</a></li><li><a href="http://www.cncf.io/people/end-user-community.">Learn About the CNCF End User Community</a></li></ul>



<p><strong>About Cloud Native Computing Foundation</strong></p>



<p>Cloud native computing empowers organizations to build and run scalable applications with an open source software stack in public, private, and hybrid clouds. The Cloud Native Computing Foundation (CNCF) hosts critical components of the global technology infrastructure, including Kubernetes, Prometheus, and Envoy. CNCF brings together the industry’s top developers, end users, and vendors, and runs the largest open source developer conferences in the world. Supported by more than 500 members, including the world’s largest cloud computing and software companies, as well as over 200 innovative startups, CNCF is part of the nonprofit Linux Foundation. For more information, please visit www.cncf.io.</p>



<p><em>###</em></p>



<p><em>The Linux Foundation has registered trademarks and uses trademarks. For a list of trademarks of The Linux Foundation, please see our trademark usage page. Linux is a registered trademark of Linus Torvalds.</em></p>



<p><strong>Media Contact</strong></p>



<p>Katie Meinders</p>



<p>The Linux Foundation</p>



<p><a href="mailto:PR@CNCF.io">PR@CNCF.io</a></p>


			<hr>
			
		</div>
				</article>
</div></div>]]>
            </description>
            <link>https://www.cncf.io/announcements/2020/11/24/cloud-native-computing-foundation-announces-etcd-graduation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25237523</guid>
            <pubDate>Sat, 28 Nov 2020 13:56:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is Probability Real?]]>
            </title>
            <description>
<![CDATA[
Score 215 | Comments 191 (<a href="https://news.ycombinator.com/item?id=25237356">thread link</a>) | @EbTech
<br/>
November 28, 2020 | https://www.arameb.com/blog/2020/11/22/probability | <a href="https://web.archive.org/web/*/https://www.arameb.com/blog/2020/11/22/probability">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Today, I want to address an issue with statements involving chance. To demonstrate, let’s first consider a statement that doesn’t involve chance:</p>

<p>“<em>A cubic die tossed onto a flat surface will come to rest on one of its six sides.</em>”</p>

<p>This claim can be empirically tested, with various dice and surfaces. If any one of our experiments results in the die spinning endlessly on a corner, we will have disproven the claim. We may have to refine the claim’s conditions; for instance, by requiring the presence of gravity. Nonetheless, it’s fairly clear what it means for the statement to be true or false. Now let’s try to make a claim involving probability:</p>

<p>“<em>If a pair of standard dice are thrown, the probability of their face-up sides summing to nine will be one in nine (about 0.11 or 11%).</em>”</p>

<p>What does it mean for this statement to be true? Unlike the first statement, this one doesn’t specify which result we’ll actually see. How can we possibly hope to test it, or to make use of its information?</p>



<p>Within the realm of abstract mathematics, we’re free to model probability in a way that fits our intuitions. Imagine a multiverse containing an infinity of possible worlds, whose total <em>measure</em> is 100%. Define the probability of an <em>event</em>, such as that of rolling a nine, to be the measure assigned to the subset of worlds in which the event actually occurs.</p>

<p>In the abstract formalism, we’re allowed to assign the measure however we like, subject to Kolmogorov’s axioms: the measure must be non-negative, countably additive, and total to 100%. By respecting the symmetry of an idealized die,<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> we might argue that only one such assignment makes sense; from it, we can calculate the probability of any event involving dice rolls.</p>

<p>There are two shortcomings to this approach. Firstly, we won’t always deal with nicely symmetrical objects for which direct a priori arguments are possible. Thus, we still need a means of testing probabilistic claims using real-life observations. Secondly, such arguments can never be airtight: after all, how can we hope to infer the measure on a hypothetical multiverse, when we only ever experience <em>one</em> world? Indeed, a realist might question if it makes any sense to discuss the chances of an event happening: either it happens or it doesn’t!</p>



<p>You might be more trusting of someone who puts their money where their mouth is. To back up a definite claim, not involving chance, I can simply agree to pay a penalty if it turns out I’m wrong.</p>

<p>This idea can be extended to probabilistic claims in the following manner: consider a lottery that pays a $90 jackpot if the next roll of a pair of dice yields a nine. If the maximum that I’m willing to pay to play is $10, this indicates that I believe a not-nine roll is eight times more likely than a nine roll. This approach is appealing because, after all, the <em>raison d’être</em> of probability theory is to explain the decision-making of individuals facing uncertainty.</p>

<p>If another gambler’s view conflicts with mine, you may aggregate our beliefs by creating a market on which we buy and sell predictions. Consider a contract that pays $100 (plus interest) when a specified event occurs. Its price on the market can be interpreted as the percentage probability of that event. Thus, to say an event is twice as “likely” as another, simply means its market price is double.</p>

<p>Unlike your typical gambler, a frictionless market offers transparent near-identical buy and sell prices. As a result, any violations of Kolmogorov’s axioms become money-making arbitrage opportunities. Arbitrage activity acts as an enforcer of the axioms, creating what economists call the <em>risk-neutral probability measure</em>.</p>

<p>In real markets, however, this probability measure exhibits several inconsistenties. Firstly, it depends on which currency is used: as an extreme example, we wouldn’t buy a dollar-denominated wager that only pays out if the dollar collapses, no matter how likely we imagine the collapse to be. Secondly, this measure is sensitive to (non-diversifiable) risk: if a widely-believed prophecy held that rolling a nine would induce a catastrophic famine, the market would value this outcome a lot more, because everyone wants to buy insurance against such a catastrophe. Thirdly, markets can be misinformed: indeed, one motivation for participating in a market is to try to beat it! And finally, liquid markets are hard to set up.</p>

<p>For these reasons, we abandon this approach. We’ll seek to define probability in terms of actual outcomes instead of human bets. Nonetheless, human bets are what inspired the creation of probability theory: it’s hard to think of any other practical application! Therefore, we should remember to revisit the matter once we’ve found an appealing probability concept. Ultimately, we must be able to explain <em>how</em> individuals and markets behave with respect to our concept, and answer <em>why</em> they should care about it at all.</p>

<p>These questions are incredibly subtle: the theory of evolution by natural selection tells us that individuals are wired to use strategies that enabled their ancestors’ survival; however, the nature of probabilistic beliefs is that a wide range of outcomes are plausible. Indeed, while a coin will always land heads or tails, it’s considered unwise to bet your life savings on either heads or tails. Intuitively speaking, the rationale is that you’re almost certain to lose <em>eventually</em>, if you keep playing this way. This idea of repeated trials inspires our next interpretation, which happens to be the most popular among scientists.</p>



<p>According to the frequentist school of thought, a probabilistic statement is not to be taken literally. Although it refers to a single event, the statement should be taken as shorthand for a claim involving a very large collection of similar events. Imagine rolling the dice over and over. The probabilistic claim that we started with is converted into the following:</p>

<p>“<em>If a pair of standard dice are thrown repeatedly, then in the limit as the number of throws goes to infinity, the proportion of nines converges to one in nine (about 0.11 or 11%).</em>”</p>

<p>The short-run probability is replaced by a long-run proportion. Given an infinite sequence of rolls, this statement unambiguously reveals itself to be true or false. In light of the frequentist interpretation, we can even make more sense of our earlier interpretations. While we only experience one world, repeating an experiment under similar conditions is like observing the experiment in a parallel universe: whether we count trials or worlds, the math is virtually identical. In the limit of infinitely many bets, we can make some unambiguous conclusions about the quality of a gambler’s strategy, too: this is how casinos ensure that the house always wins!</p>

<p>Testing our claim is a simple matter: we roll the dice, over and over, and over and over… infinity times. Oops. Of course, there is no such thing as an experiment with infinity trials. Our arms will get tired, the dice will wear out, the Sun will explode, and all the free energy in the universe will be consumed. At best, we can do a very large number of trials. Let’s say we roll dice 9,000 times; one in nine of these would be 1,000. Perhaps we won’t roll exactly 1,000 nines, so let’s interpret our claim with a suitable margin of error, called a <em>confidence interval</em>:</p>

<p>“<em>If a pair of standard dice are thrown 9,000 times, then the face-up sides will sum to nine for between 920 and 1,080 of the throws.</em>”</p>

<p>The probability of obtaining between 920 and 1,080 nines can be calculated to be 99.3%.<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup> Thus, we’ve turned a probabilitic statement into a much more certain but still probabilistic statement. If we observe 1,100 nines, we should be able to dismiss the probabilistic claim as false. And yet, if every household on Earth were to independently perform this 9,000-throw experiment, we should expect that a great many of their results would fall outside the confidence interval. They would disagree on the truth of our statement!</p>

<p>There’s no getting around it: despite its intuitive appeal, the frequentist definition of probability is circular, reducing probability claims to probability claims.<sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup> To end the cycle, the frequentist chooses a threshold (say, 99%) beyond which to treat events as objective truths. This grants the claim an empirically observable meaning. And yet, the frequentist must take care not to consider too many such events, for otherwise the probability of <em>at least one</em> of the events failing may ALSO exceed the threshold of certainty: a logical contradiction.</p>

<p>Things only work out nicely in the limit of infinite sample size. Statisticians mainly deal with experiments which can be repeated so many times that, for most practical purposes, their conclusions can be treated as definite. Non-philosophers are usually happy to ignore a sub-1% chance of error; and if that’s not good enough, make it 0.0001%! Confidence can be increased by gathering more data, i.e., increasing the sample size.</p>

<p>This approach turns out to be very powerful. By designing more complex hypotheses in which probabilities vary as a function of context variables, even some phenomena that aren’t easily repeatable can be statistically analyzed. For example, weather forecasts are based on well-tested models that use measurements of variables such as temperature, pressure, humidity, and wind.</p>

<p>On the other hand, statistical models of sports games, democratic elections, or company stocks tend to be less testable: the interactions are very complex and there are too few outcomes from which to extrapolate. Similarly, when you try to predict which colleges will admit you or which of your friends will start a business, you don’t make your case using repeatable tests. Clearly, the frequentist interpretation cannot apply. One may argue that no conclusions in these cases would hold up to a scientific standard; nonetheless, if we seek a theory of decision-making under uncertainty, there’s no …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.arameb.com/blog/2020/11/22/probability">https://www.arameb.com/blog/2020/11/22/probability</a></em></p>]]>
            </description>
            <link>https://www.arameb.com/blog/2020/11/22/probability</link>
            <guid isPermaLink="false">hacker-news-small-sites-25237356</guid>
            <pubDate>Sat, 28 Nov 2020 13:23:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Always leave the code better than you found it]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 70 (<a href="https://news.ycombinator.com/item?id=25237341">thread link</a>) | @hans1729
<br/>
November 28, 2020 | https://letterstoanewdeveloper.com/2020/11/23/always-leave-the-code-better-than-you-found-it/ | <a href="https://web.archive.org/web/*/https://letterstoanewdeveloper.com/2020/11/23/always-leave-the-code-better-than-you-found-it/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Dear new developer,</p>



<p>I’ve spent a lot of my time maintaining working code. I think that is more typical of software developers than working in greenfield development. Yes, there are definitely jobs where you are writing more new code than maintaining, upgrading, bug fixing and improving old code (startups without product market fit being one, consulting being another) but in general code is expensive and folks want to run it for a long time. </p>



<p>Often you’ll jump into code to fix a bug, investigate an issue or answer a question.</p>



<p>When you do so, improve it. This doesn’t mean you rewrite it, or upgrade all the libraries it depends on, or rename all the variables. </p>



<p>You don’t need to transform it. </p>



<p>But you should make it better. Just clean it up a bit. Doing so makes everyone’s lives just a bit better, helps the codebase in a sustainable way, and assists the business by making its supporting infrastructure more flexible.</p>



<p>What are some ways to improve the code when you are in it?</p>



<p><strong>Document</strong></p>



<p>Whether that is a comment that explains something tricky, a larger piece of documentation external to the code which explains how to interact with it, or fixing a typo, trustworthy documentation is key to interacting with code. This is a good way to start improving a codebase because it has minimal impact on the actual code. Therefore it is low risk. But if you’ve ever had a great comment explain a confusing bit of code, you’ll appreciate the time this effort can save.</p>



<p>You can also help documentation by removing old, crufty docs. If you see a comment that doesn’t apply, remove it. If there’s cut and paste documentation which doesn’t apply, get rid of it. That cleans up the code for the next person to come along (who might be you).</p>



<p><strong>Write a test or improve a test</strong> </p>



<p>Tests help you write maintainable, extensible code that others can change fearlessly. If you run across code that isn’t tested and you have time and the supporting framework to write one, do so. </p>



<p>Even if it tests simple functionality such as “can I instantiate this object” or “how does this function react when I pass it two null values”, an additional test will help the robustness of the code. </p>



<p><strong>Refactor it</strong></p>



<p>This is one of the most flexible improvements. Refactoring code can range from renaming a variable to be more true to its nature to an overhaul of an entire module. Start small and don’t get wrapped up in perfection. Make the code clearer in intent. </p>



<p>It’s easy with refactoring to get wound around an axle and make too many changes and end up with broken things. Timeboxing is one technique I use to avoid, or at least minimize, my tendencies toward this when refactoring. If all I have is 30 minutes, I’ll make my changes smaller in scope.</p>



<p>A warning about refactoring. Don’t refactor what you don’t understand. Don’t drive by refactor. Discuss your plan with someone more familiar with the code; <code>git blame</code> is your friend. Especially if the code is not well tested, you want to make sure you don’t do more harm than good.</p>



<p><strong>Upgrade a dependency</strong></p>



<p>It’s sometimes a winding path, but upgrading your dependencies regularly is a good way to maintain the code. I remember working in a fork of struts. It was an important application for the company, but we didn’t spend the time upgrading the dependencies, because it was too painful. Eventually, parts of the code became harder to update. The entire application couldn’t benefit from newer technologies and paradigms because of the older dependencies holding it back. </p>



<p>It never feels good to spend time updating a dependency; to me this always feels like running in place. But if you don’t do so, eventually dependencies will end of life and you’ll be forced to update. That’ll be even less pleasant. </p>



<p><strong>How to do it</strong></p>



<p><em>Based on feedback (<a href="https://www.reddit.com/r/programming/comments/k2cbtb/always_leave_the_code_better_than_you_found_it/gdv0kg9/?utm_source=reddit&amp;utm_medium=web2x&amp;context=3">this comment</a>, among others), I added this section on Nov 28.</em></p>



<p>When you are making these changes to improve the code, you’ll help out code reviewers and your future self by making changes that are improving the code separate from changes that add functionality. Whether you do this in separate pull requests, tickets, or commits depends on your team culture. Ask about that. But such separation will make it easier for people who aren’t familiar with the changes to understand them and give feedback on them, whether that is a code review this week or someone reviewing this component two years from now.</p>



<p><strong>Why do it</strong></p>



<p>All of these actions not only help others because they improve the quality of the code, they also provide examples to other developers on how to do so. For example, it is far easier to write the second test in a suite than the first. You can cut and paste a lot of the setup code and tweak only what is different. The first bit of documentation will inspire more.</p>



<p>Code isn’t everything, but it is an important work output. Whenever you touch it, you should strive to leave it in a better place that it was before you did so.</p>



<p>Sincerely,</p>



<p>Dan</p>
	</div></div>]]>
            </description>
            <link>https://letterstoanewdeveloper.com/2020/11/23/always-leave-the-code-better-than-you-found-it/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25237341</guid>
            <pubDate>Sat, 28 Nov 2020 13:19:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Grep.app, a GitHub code search engine to search for code patterns and examples]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25237338">thread link</a>) | @hackerpain
<br/>
November 28, 2020 | https://grep.app/search?q=pattern | <a href="https://web.archive.org/web/*/https://grep.app/search?q=pattern">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://grep.app/search?q=pattern</link>
            <guid isPermaLink="false">hacker-news-small-sites-25237338</guid>
            <pubDate>Sat, 28 Nov 2020 13:19:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What were these Roman objects used for?]]>
            </title>
            <description>
<![CDATA[
Score 52 | Comments 37 (<a href="https://news.ycombinator.com/item?id=25237271">thread link</a>) | @jd115
<br/>
November 28, 2020 | http://www.celticnz.co.nz/Dodecahedron/Decoding%20the%20Druidic%20Dodecahedron1.html | <a href="https://web.archive.org/web/*/http://www.celticnz.co.nz/Dodecahedron/Decoding%20the%20Druidic%20Dodecahedron1.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<p><strong>DECODING THE DRUIDIC DODECAHEDRON </strong></p>

<p><img src="http://www.celticnz.co.nz/OrgImages/Dodecahedron/Dodecahedron%20Types.jpg" width="900" height="438"></p>
<p><strong>These bronze artefacts are so-called <em>Roman</em> dodecahedra (plural of dodecahedron)  of which about 120 have been found in the Celtic countries of Europe. Strangely, none of these have been found in Italy, home turf of the Romans.</strong> <strong>To the left is seen a dodecahedron from the Römermuseum Schwarzenacker, Homburg, Germany collection. To the right is seen another pristine example from the Hunt Museum in Limerick Ireland </strong></p>

<p><img src="http://www.celticnz.co.nz/OrgImages/Dodecahedron/Dodecahedron%20Types3.jpg" width="935" height="438"></p>
<p><strong>To the left is a dodecahedron from Archaeological  Service Canton Aargau, Brugg, Switzerland (Vindonissa Museum). To the right is a dodecahedron from the Gallo-Roman Museum, Tongeren, Belgium. </strong></p>
<p>The basic design of these artefacts remains relatively constant (12 pentagonal faces with knop-shaped legs), however, there can be a range of different  incised designs in the layout of the faces<strong>. </strong></p>
<p>The actual function of these artefacts cannot be explained by our historians or archaeologists, although many theories abound,  none of which seem particularly convincing. Also, there is no  mention of these items in old historical records of the Romans or those of anyone else for that matter. They are such an enigma that academics have pretty-much come to the defeatist conclusion that <em><strong>"we will never know what these dodecahedrons were used for". </strong></em></p>
<p>In reviewing the academic literature, one begins to see why the mystery will probably never be solved within that community. Here are some of the impediments and pitfalls our experts create for themselves:</p>
<p>All archaeological measurements are given in metric increments (centimetres or millimetres), which is a modern system that was created as much as 2000-years after some of these dodecahedra were cast in bronze. Earlier exemplars in stone or wood could predate the latter, more refined ones, by yet another thousand years or more. This  metric measurement preoccupation renders the  encoded numbers invisible or unrecognisable. Our academics know a large swathe of the ancient measurements that were in use two thousand years ago or before, so why not apply them to this study? </p>
<p>Most assuredly, the various sized holes in the 12-faces, the concentric circles that circumnavigate them, as well as the additional incised lines or dotted circles, etc, infer that there is something vividly measurable going on and it's evident that each hole or ring  has been very purposely fabricated to represent a known, precise and sought-after measurement.</p>
<p><img src="http://www.celticnz.co.nz/OrgImages/Dodecahedron/Calibrated.jpg" width="900" height="476"> </p>
<p><strong>A number of dodecahedra have calibration marks along their edges or around the holes in their faces. To the left is seen a calibrated dodecahedron from Hereford Museum, Kenchester and to the right is seen another from Goodrich Castle. Yet another one found in Wales shows etched calibration marks. </strong></p>
<p>In their reports,  archaeologists will often round out measurements of the holes in the dodecahedron faces to the nearest millimetre only, which is grossly insufficient. It's much appreciated by researchers when measurements can be supplied to 1/10th  of a millimetre, but  it is nigh on impossible  to acquire more refined measurements undertaken with electronic vernier callipers. Precise measurements and scaling must precede any serious analysis of these artefacts, but our experts don't seem to think there would be anything significant to find anyway, so don't subject the dodecahedra to rigorous measurement analysis.</p>
<p>Despite the fact that 25.4 millimetres (1 British Standard Inch) or fraction expressions of the same will recur repeatedly in the faces of dodecahedra, no-one seems to have arrived at the conclusion that the enigmatic<em><strong> "inch"</strong></em> recurrence is worthy of serious investigation. </p>
<p>Almost anything considered high-art, technically advanced or an engineering feat within ancient European civilisations seems to be automatically attributed to the Romans, which is certainly the case for these dodecahedra artefacts. This  is a hangover of biased, classicist-isolationist historical  interpretations of  European history where, first came the  Roman conquerors, who finally retreated after centuries of domination, only to be replaced by Rome's State church. With the pedigree of the church being Greco-Roman it was in their interests to push the concept that the Roman armies had found everything in the regions they invaded to be backwards, rudimentary or crude until Rome delivered the great-unwashed masses out of their depravity and into  enlightenment and high-civilisation. </p>
<p>This general process of misattribution further hobbles or seriously limits proper investigation into the purpose and function of dodecahedra artefacts, inasmuch as focus is  directed, almost exclusively, to what Roman armies might have used them for as range-finders or other battle related paraphernalia, including club-heads. The druids or others don't get  any serious consideration, despite the fact that they are historically recorded as having been  advanced mathematicians and astronomers.</p>
<p>Within controlled academia the ability to do open-ended, ground-breaking research can be severely curtailed by the requirements of <em><strong>"peer review"</strong></em> by colleagues.  This is largely a racket that ensures one doesn't move too far from the protected consensus opinion upon which academic reputations are built and anyone venturing too far out into left field is considered a maverick who threatens the insulated central body.</p>
<p>By the same token academia, these days, is lumbered with deep-set social responsibilities and crippling political agendas. When it comes to European history, especially, the requirement is to be self-effacing, while lauding and applauding the (often meager) accomplishments of other ethnicities. Under  guises of political correctness and racial sensitivity, the door is opened for antagonistic non-European, prejudiced individuals, to write and interpret  our history for us, while pushing their own  cultural-Marxist or similar wheel-barrows.  All one has to do is sit through lectures in our western universities to see just how far out of kilter the abysmal problem of  European history-misrepresentation has become.</p>
<p>But, with regards to the dodecahedra artefacts,what one person can build, another can generally duplicate or back-engineer, sufficient to make sense of what's going on. </p>
<p>So, let's cut to the chase, bypass all the  confusion of modern-day naysayers and source testimony directly from an observer who lived contemporary to the druids, before they fell under Roman domination </p>
<p>Julius Caesar, who was a very thorough historian, writes the       following regarding the late era druids of his time (circa 55 BC) and        practices within their many universities in Britain, where students from Gaul       and elsewhere, including Rome, went for training:</p>
<p><strong>'They hold aloof from war and do not pay war taxes; they       are excused from military service and exempt from all liabilities. Tempted       by these great advantages, many young men assemble of their own motion to       receive their training, many are sent by parents and relatives. Report says       that in the schools of the Druids they learn by heart a great number of verses,       and therefore some persons remain twenty years under training'. </strong></p>
<p><strong>'They do not think it proper to commit these utterances to       writing, although in all other matters and in their public and private accounts       they make use of Greek characters. I believe that they have adopted the practice       for two reasons- that they do not wish the rule to become common property,       nor those who learn the rule to rely on writing and so neglect the cultivation       of memory; and, in fact, it does usually happen that the assistance of writing       tends to relax the diligence of the student and the action of memory...They       also lecture on the stars in their motion, the magnitude       of the Earth and its divisions, on natural history, on the power and       government of God; and instruct the youth in these subjects' <em>(see De Ballo       Gallico, VII, 15, 16.).</em></strong></p>
<p>Historian, Isabel Hill Elder  writes, <strong>'The students at these       colleges numbered at times sixty thousand of the youth and young nobility       of Britain and Gaul. Caesar comments on the fact that the Gauls sent their       youth to Britain to be educated...It required twenty years to master the complete       circle of Druidic knowledge. Natural philosophy, astronomy,       mathematics, geometry, medicine, jurisprudence, poetry and oratory       were all proposed and taught-natural philosophy and       astronomy with severe exactitude' (Elder refers to <em>Strabo I IV,       page 197. Caesars Comm. Lib V. Sueotonius, V Calegula. E. Campion, Accounts       of Ireland, pg. 18.).</em></strong></p>
<p>Isabel Hill Elder further writes,<strong> 'The education system       adopted by the Druids is traced to about 1800 BC when Hu Gardarn Hysicion       (Isaacson), or Hu the Mighty, led the first colony of Cymri into Britain from       Defrobane, where Constantinople now stands'.</strong> </p>
<p>Further commenting on Hu       Gardarn Hysicion, Isabel Hill Elder writes that he, <strong>'is commemorated in       Welsh archaeology as having made poetry the vehicle of memory'.</strong> Elsewhere       she writes, he <strong>'is said to have mnemonically systematized the wisdom of       the ancients...'.</strong> She goes on to say,<strong> 'The published compositions of       the Druids and Bards form but a very small portion of the extant remains of       their works. The Myvyrian MSS. alone, now in the British Museum, amount to       47 volumes of poetry, in 1600 pages, besides about 2000 epigrammatic stanzas.       Also in the same collection are 53 volumes of prose, in about 15,300 pages,       containing many curious documents on various subjects...' <em>(see Celt, Druid       and Culdee, pages 54 &amp; 55).</em></strong></p>
<p>With the testimony of Julius Caesar ringing in our ears, lets see how the druids would have used the dodecahedron artefacts as <em><strong>"memory"</strong></em>devices for mathematically encoding astronomical cycles,<em><strong> ("the stars in their motion")</strong></em>, navigation systems <em><strong>("the …</strong></em></p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.celticnz.co.nz/Dodecahedron/Decoding%20the%20Druidic%20Dodecahedron1.html">http://www.celticnz.co.nz/Dodecahedron/Decoding%20the%20Druidic%20Dodecahedron1.html</a></em></p>]]>
            </description>
            <link>http://www.celticnz.co.nz/Dodecahedron/Decoding%20the%20Druidic%20Dodecahedron1.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25237271</guid>
            <pubDate>Sat, 28 Nov 2020 13:03:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Top Linux (command line interface) CLI tools]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25236863">thread link</a>) | @Vlad81b
<br/>
November 28, 2020 | https://www.vladimircicovic.com/2020/11/top-linux-command-line-interface-cli-tools | <a href="https://web.archive.org/web/*/https://www.vladimircicovic.com/2020/11/top-linux-command-line-interface-cli-tools">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Working in a Linux environment requires knowledge of Linux cli tools and troubleshooting. In this article, it would
be presented CLI tools that are most important for troubleshooting.
Short story
Let say you are working with Linux and your work would be: 1% once-time setup and 99% troubleshooting. So as we can see from these homemade statistics you going to spend most of your time in CLI and finding “why does not work”. This is not a trivial task. It requires knowledge of how Linux works, how subsystems of Linux works,
how complete “line” from typing command up to running, delivering some results works, logs. 
Yes, logs are the most important.
So let me start with naming tools and then a short description of some of them.
fs2chk
du/dh
strace/ltrace
lsof
ldd
tcpdump
netstat
mailq/showq
traceroute/tracepath
ping/telnet/nc
dig
curl
nmap
top
ps
pkg manager(rpm, yum, apt, others)
lsmod
awk
sed
vim</p>
<h3>fs2chk</h3>
<p>Used for file system integrity check. Not all time you will have regular shutdown or reboot –
sometimes it happens power goes off and your server gets back with a file system issue. Usually, in that
case is best to use fs2chk</p>
<h3>du/dh</h3>
<p>Command du is used to show space usage per partition. Sometimes happen your partition are used with
some dumb files/logs (crash files) and you need to see what is happening because application or service you try to run report free space issue. Command dh is used to check directory with sub-
directories and discover what file occupied most of the space.</p>
<h3>strace/ltrace</h3>
<p>Running application it just stops at some point. You don’t have logs. Nothing. And there is no debug switch (for example ssh -vvv, where you can see all steps that are done) or any other way to see what is hell going on. So strace is for functions that is used and ltrace are library that are used at some point.
We mostly need trace tool to see details of operation for some applications. Example: we run applications or services and we see an issue and we are not sure why.</p>
<h3>lsof</h3>
<p>You have an issue removing files/files because they are used by some unknown application. Or you want to see how much is open files so you can see if the maximum limit for open files is reached.</p>
<h3>ldd</h3>
<p>When the application does not run at all – the usual suspect is missing the library. This tool is handy to discover which library missing.</p>
<h3>tcpdump</h3>
<p>Connection to server sometimes has issues. So the best way to check what is going on and to troubleshooting is tcpdump. You can pick up the interface, type of protocol, from/to IP, or any low level for all TCP/IP layers.</p>
<h3>netstat</h3>
<p>Simple to see the status of open ports, connection state, and other information that we need to see if services running properly on a given port.</p>
<h3>mailq/showq</h3>
<p>The most vital service in each company is email. And sometimes you need to see what is happening with email (sending or recv). Best tool for this is mailq/showq (it is the same tool, showq is a new one that replace
mailq on older Linux)</p>
<h3>ethtool</h3>
<p>On a low level could happen issue with our ethernet connection and we want to review our cable/port on Linux. So the tool is best for this job. Beside this, you can review other specific ethernet things (auto-negotiation etc)</p>
<h3>traceroute/tracepath</h3>
<p>Ideal to see between server and client if there is a network path issue as also a delay between them.</p>
<h3>ping/telnet/nc</h3>
<p>The very handy tool on the first step to see if is server up as also services.</p>
<h3>dig</h3>
<p>With this tool, you can perform all DNS troubleshooting. Review MX records, A, NS, etc.</p>
<h3>curl</h3>
<p>One of the best tools for troubleshooting different protocols: HTTP, RTMP, FTP, etc. It also has a benchmark integrated for a view of response (DNS, first byte, etc).</p>
<h3>nmap</h3>
<p>A very good tool for discovering services, open ports, and other useful information. Also, you can use on your servers to check if there is some unusual thing and secure them.</p>
<h3>top</h3>
<p>Active process list with memory, CPU, parent/child connection, and other information that helps to see where the issue starts.</p>
<h3>ps</h3>
<p>Process list, you can check and see what is currently running (very quick, the first step for troubleshooting)
pkg manager(rpm, yum, apt, others)
In troubleshooting we need to verify or to find some library or application – so this tool is best for that
operation.</p>
<h3>lsmod</h3>
<p>People who never have issues with kernel modules would never use this tool or get this tool seriously.
The tool provides information about loaded kernel modules as also usage, memory, etc.</p>
<h3>awk/sed/grep</h3>
<p>In a bunch of logs sometimes is a need to find proper information. All these tools are swiss knives for bash scripting and handy for parsing logs for specific information.</p>
<h3>vim</h3>
<p>The best editor in the world. Learn so you can answer on an interview how to quit vim.</p>
</div></div>]]>
            </description>
            <link>https://www.vladimircicovic.com/2020/11/top-linux-command-line-interface-cli-tools</link>
            <guid isPermaLink="false">hacker-news-small-sites-25236863</guid>
            <pubDate>Sat, 28 Nov 2020 10:52:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[First made-in-China nuclear reactor online]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25236824">thread link</a>) | @chefkoch
<br/>
November 28, 2020 | https://www.bangkokpost.com/world/2026891/first-made-in-china-nuclear-reactor-online | <a href="https://web.archive.org/web/*/https://www.bangkokpost.com/world/2026891/first-made-in-china-nuclear-reactor-online">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
							<!-- article-news detail -->
							<div>
								<article>
									
									<div>
										<h2>
											First made-in-China nuclear reactor online										</h2>
										<p>Hualong One debut seen as milestone in drive to reduce dependence on Western technology</p>									</div>
																		<div id="position-set">
										<div>
											<p>published :
													28 Nov 2020 at 16:03												</p>
											
										</div>
									</div>
									
									<!-- show ipad and mobile only -->
									
									<!-- /show ipad and mobile only -->

									<div>
																					<div>
												<figure>
													<img data-img-highlight="1" src="https://static.bangkokpost.com/media/content/20201128/c1_2026891.jpg" alt="The Taishan complex in Guangdong is one of 47 nuclear power plants in China, where another 13 are under construction. (Photo: EDF Energy via Wikimedia Commons)" title="The Taishan complex in Guangdong is one of 47 nuclear power plants in China, where another 13 are under construction. (Photo: EDF Energy via Wikimedia Commons)">
												</figure>
																								<figcaption>
													The Taishan complex in Guangdong is one of 47 nuclear power plants in China, where another 13 are under construction. (Photo: EDF Energy via Wikimedia Commons)												</figcaption>
												
											</div>
																				<p>BEIJING: China has powered up its first domestically developed nuclear reactor — Hualong One — a significant step in Beijing’s attempts to become less dependent on Western countries for energy security and critical technology.</p>
<p>The reactor, which was connected to the national grid on Friday, can generate 10 billion kilowatt-hours of electricity each year and cut carbon emissions by 8.16 million tonnes, according to China National Nuclear Corporation (CNNC).</p>
<p>“This marks China breaking the monopoly of foreign nuclear power technology and officially entering the technology’s first batch of advanced countries,” CNNC said in a statement.</p>
<p>Nuclear plants supplied less than 5% of China’s annual electricity needs in 2019, according to the National Energy Administration, but this share is expected to grow as Beijing attempts to become carbon-neutral by 2060.</p>
<p>Reducing its dependence on Western allies in critical high-tech sectors such as power generation is a key goal in Beijing’s “Made in China 2025” plan.</p>
<p>Billions of dollars in state subsidies have been given to Chinese companies to speed the process — a move that has angered China’s trade partners and sparked a protracted trade row with Washington.</p>
<p>Work on the Hualong One reactor started in 2015 and there are currently six other reactors under construction at home and abroad, the state-owned plant operator CNNC said.</p>
<p>The Hualong One, deployed at a plant in the eastern province of Fujian, will be put into commercial use by the end of the year after undergoing tests.</p>
<p>China has 47 nuclear plants with a total generating capacity of 48.75 Gigawatts — the world’s third highest after the United States and France.</p>
<p>Beijing has invested billions of dollars to develop its nuclear energy sector in recent years as it struggles to wean its economy from coal.</p>
<p>Thirteen nuclear plants are under construction, more than in any other country, despite environmental and safety concerns.</p>
<p>In August 2016, officials were forced to shelve plans for a nuclear waste facility in Lianyungang, a city in eastern Jiangsu province, after a rare public protest by thousands of residents.</p>									</div>

									
									

																			
										<hr>
																			<div><p>
											Do you like the content of this article?
											</p>
										</div>
																		
																	</article>

							</div>
							<!-- /article-news detail -->
						</div></div>]]>
            </description>
            <link>https://www.bangkokpost.com/world/2026891/first-made-in-china-nuclear-reactor-online</link>
            <guid isPermaLink="false">hacker-news-small-sites-25236824</guid>
            <pubDate>Sat, 28 Nov 2020 10:43:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Beating the Markets with Artificial Intelligence Driven Portfolios]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25236677">thread link</a>) | @hydershykh
<br/>
November 28, 2020 | https://tradytics.com/blog/beating-the-market-with-ai-driven-portfolios | <a href="https://web.archive.org/web/*/https://tradytics.com/blog/beating-the-market-with-ai-driven-portfolios">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <div>
                    <div>
                        <article>
                            <div>
                                
                                <p>

Quantitative finance is an inherently secretive field where people who become profitable never reveal their secret formulas of success. However, this has started to change in recent years thanks to the likes of <a href="https://www.amazon.com/Advances-Financial-Machine-Learning-Marcos/dp/1119482089">Marcos Lopez de Prado</a>, <a href="https://www.amazon.com/Algorithmic-Trading-Winning-Strategies-Rationale/dp/1118460146">Ernest Chan</a>, and others. Although algorithmic trading remains a difficult problem to solve, the knowledge that these people have given to the public is invaluable. At Tradytics, we are continuously reading the latest research and trying new ideas to create profitable trading algorithms. <b>Today, we are going to talk about one such AI system that has resulted in us beating the market by 20% in the last 1 month</b>. Although this time period is very short, we want to give others a taste of how things work at Tradytics and how we go about solving different problems. We are also going to continue creating automated systems with an intent to consistently beat the market. <b>Let us now talk about how we created 5 AI driven portfolios that each gained over 30% returns in the last 30 days.</b>

</p>





<h3> A Million Portfolios </h3>

<p>

Let's start with a basic idea of what we do before diving into the details. 

</p><blockquote>

	<p>We generate millions of random portfolios, optimize their allocation using existing and proprietary portfolio optimization algorithms, and rank them using our AI engine.</p></blockquote>



<p>There has been thousands of papers on portfolio optimization in the last three decades. Starting with <a href="https://www.investopedia.com/terms/m/modernportfoliotheory.asp">markowitz portfolio optimization theory</a> to the more recent <a href="https://www.coursera.org/learn/trading-strategies-reinforcement-learning">reinforcement learning based optimization</a> methods, there are countless research papers to read and implement. However, as is the case with the majority of proposed methods in literature, the portfolios are created based on historical returns. If there is one thing we know about the stock market, it's that historical returns are not always representatives of future returns. This is a major problem that one needs to solve in order to create effective portfolios. As market regimes change, algorithms that were based on historical data suddenly become ineffective. Therefore, we need a way to combine the literature with a novel mechanism of adding some predictive power to our portfolio optimization strategies.</p>





<h4> Portfolio Optimization Strategies at Tradytics </h4>

<p>

	At Tradytics, we use 3 strategies from literature and two proprietary ones based on genetic algorithms. These strategies are:

	</p><ul>

		<li><a href="https://www.thebalance.com/minimum-variance-portfolio-overview-4155796">Minimum Variance Portfolio (MVP)</a></li>

		<li><a href="https://logical-invest.com/app/portfolio/maxsharpe/max-sharpe-portfolio">Maximum Sharpe Portfolio (MSR)</a></li>

		<li><a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3070416">Eigen Portfolios</a></li>

		<li>Genetic Portfolios (GA)</li>

		<li>Exponential Genetic Portfolios</li>

	</ul>

	<p>MVP, MSR, Eigen, and GA based portfolio optimizations have been studied in the literature in depth and many trading firms still use them. This is where we start as well but we add something important on top to make these strategies work well. As we said in the start of this section, our basic idea is to generate millions of random portfolios and rank them using our custom AI algorithms. The ranking system is where our novelty comes in. The following image visually explains our portfolio selection process.</p>

	<p> 

	<img src="https://i.ibb.co/m4N3gB4/block-diagram.png"></p><p>After generating millions of portfolios and optimizing their weights with the aforementioned strategies, we use our proprietary ranking system that ranks all these portfolios in terms of their future predicted returns. We keep the best portfolio for each of the five strategies which goes to our website at <a href="https://tradytics.com/ai-portfolios.">Tradytics AI Portfolios</a>. Let us now dive a bit deep into the portfolio generation and selection process.</p>





<h4> Portfolio Generation: A Case of 25 Random Portfolios </h4>

<div><p>

	The image below shows 25 random portfolios from a collection of millions of portfolios we generated on October 31st. We start with selecting 5 random stocks for every portfolio and optimize the portfolio on 1 year of historical data up till October 23rd. After optimization, we backtest the portfolios to look at their historical returns. Since optimization is being done on historical data, the backtested returns are expected to be high which is what we can see in the image below.

	</p><p> 

	<img src="https://i.ibb.co/gVM2VrD/backtest-returns.png"></p><p> 

	However, there is a huge problem here. Our optimization procedure only looks at historical data and has no inherent predictive power. It implicitly makes an assumption that historical returns are predictive of future returns. This is not always true and solely relying on this assumption can lead to huge losses. We can see this if we forward test our 25 portfolios from October 23rd to October 31st, 2020. 

	</p><p> 

	<img src="https://i.ibb.co/CQmyFQY/forward-returns.png"></p><p> 

	Although profitable on historical data, the portfolios are all at loss when ran live - some are down 20% in a week. This illustrates the problem at hand with portfolio optimization methods. Let us try to solve it.

</p></div>





<h3> Portfolio Selection: Tradytics AI Ranking </h3>



<p>

At Tradytics, we go one step further from portfolio optimization. Once we get these millions of optimized portfolios, we use our proprietary AI ranking algorithm to rank them based on what the AI thinks will be their future returns. The ranking procedure is basically a predictive model that predicts the returns of portfolios based on their allocation by the optimization method, their spreads with each other, and their historical returns. Once the ranking is done, we simply pick the best portfolio from each of the five strategies noted above, thus giving us 5 portfolios every month. Our main goal with these portfolios is to generate large returns and consistently beat the market. In order to preserve our alpha, we will not give any technical details away regarding our ranking system.

</p>



<div><p>

The first set of portfolios we generated was on October 31st. Our top 5 portfolios had the following allocations and stocks in them. The green weights indicate longing the stock while the red weights suggest shorting.

</p><p> 

<img src="https://i.ibb.co/kqn36Gv/allocation.png"></p></div><p>

At the time of creating these portfolios, the weights did not make much sense by simply looking at each individual stock. However, since the ranking engine has been trained on a large amount of data and has high predictive power, it extracted certain patterns that made it confident that these portfolios would end up being profitable. Let us take a look at the returns of each individual stock as well as the entire portfolio.</p>





<h4> Portfolio Results: Top 5 Portfolios from October </h4>

<div><p>When looking at the backtest results of the top portfolios, it is easy to see that the historical returns are quite volatile would yield a low sharpe ratio. However, since history is not always the future and our ranking engine is tasked to predict the future returns, these portfolios were selected because of high AI confidence in larger returns.

</p><p> 

	<img src="https://i.ibb.co/Mcgj8HV/picked-backtest-returns.png"></p><p> 



When these 5 portfolios were run live for the month of November, these yielded very high returns as compared to the market. The <b>$SPY</b> index gained about <b>10%</b> in the month of November. The following image shows the gains of each of our portfolios.</p><p> 

<img src="https://i.ibb.co/PTPnqcj/portfolio-returns.png"></p></div><p>The results are quite impressive. All portfolios have garnered gains of above <b>30% in just 30 days</b> with some of them touching about <b>40%</b> cumulative returns. Now, we admit that there is a bias in the results here because of the strong bull market in the month of November. However, when the AI was ranking these portfolios, the bull market was not very strong - <b>$SPY</b> was down <b>2%</b> in October. It was the ranking engine that was able to find predictive patterns in the portfolios which would eventually result in large profits. This demonstrates the effectiveness of using machine learning and artificial intelligence in portfolio selection.</p>





<h3> What's Next </h3>

<p>

Tradytics is a fairly new company in the quantitative finance game. We realize that these are short term results and we need to show consistency before we can make any claims about the AI capabilities of our toolkits. Our plan is to keep adding these portfolios every month and record the performance for atleast one year. The hope here is to consistently beat the market with significantly high returns. We will keep you updated. If you have any questions, please do not hesitate to reach out to us at our <a href="https://discord.gg/QuvE2Z8">Discord</a>.

</p>


                            </div>
                        </article>
                    </div>
                    <!-- end of single card col-->
                </div>
                <!-- end of blog post row -->
            </div></div>]]>
            </description>
            <link>https://tradytics.com/blog/beating-the-market-with-ai-driven-portfolios</link>
            <guid isPermaLink="false">hacker-news-small-sites-25236677</guid>
            <pubDate>Sat, 28 Nov 2020 10:09:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Interpretable Machine Learning]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25236675">thread link</a>) | @e2e4
<br/>
November 28, 2020 | https://christophm.github.io/interpretable-ml-book/ | <a href="https://web.archive.org/web/*/https://christophm.github.io/interpretable-ml-book/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        

        <div tabindex="-1" role="main">
          <div>

            <section id="section-">

<div id="summary">

<p><img src="https://christophm.github.io/interpretable-ml-book/images/title_page.jpg" width="500"></p>
<p>Machine learning has great potential for improving products, processes and research. But <strong>computers usually do not explain their predictions</strong> which is a barrier to the adoption of machine learning. This book is about making machine learning models and their decisions interpretable.</p>
<p>After exploring the concepts of interpretability, you will learn about simple, <strong>interpretable models</strong> such as decision trees, decision rules and linear regression. Later chapters focus on general model-agnostic methods for <strong>interpreting black box models</strong> like feature importance and accumulated local effects and explaining individual predictions with Shapley values and LIME.</p>
<p>All interpretation methods are explained in depth and discussed critically. How do they work under the hood? What are their strengths and weaknesses? How can their outputs be interpreted? This book will enable you to select and correctly apply the interpretation method that is most suitable for your machine learning project.</p>
<p>The book focuses on machine learning models for tabular data (also called relational or structured data) and less on computer vision and natural language processing tasks. Reading the book is recommended for machine learning practitioners, data scientists, statisticians, and anyone else interested in making machine learning models interpretable.</p>
<p>You can buy the PDF and e-book version (epub, mobi) <a href="https://leanpub.com/interpretable-machine-learning">on leanpub.com</a>.</p>
<p>You can buy the print version <a href="http://www.lulu.com/shop/christoph-molnar/interpretable-machine-learning/paperback/product-24036234.html">on lulu.com</a>.</p>
<p><strong>About me:</strong> My name is Christoph Molnar, I'm a statistician and a machine learner. My goal is to make machine learning interpretable.</p>
<p>Mail: <a href="mailto:christoph.molnar.ai@gmail.com">christoph.molnar.ai@gmail.com</a></p>
<p>Website: <a href="https://christophm.github.io/">https://christophm.github.io/</a></p>
<p>Follow me on Twitter! <a href="https://twitter.com/ChristophMolnar">@ChristophMolnar</a></p>
<p>Cover by <a href="https://twitter.com/YvonneDoinel">@YvonneDoinel</a></p>
<div>
<p><img src="https://christophm.github.io/interpretable-ml-book/images/by-nc-sa.png" alt="Creative Commons License"></p><p>Creative Commons License</p>
</div>
<p>This book is licensed under the <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.</p>
</div>
            </section>

          </div>
        </div>
      </div></div>]]>
            </description>
            <link>https://christophm.github.io/interpretable-ml-book/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25236675</guid>
            <pubDate>Sat, 28 Nov 2020 10:08:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Permissionless Apprenticeship]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25236350">thread link</a>) | @vitabenes
<br/>
November 28, 2020 | https://www.value.app/feed/permissionless-apprenticeship-ryan-doyle | <a href="https://web.archive.org/web/*/https://www.value.app/feed/permissionless-apprenticeship-ryan-doyle">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><em>Guest author: </em><a href="https://twitter.com/ryan___doyle"><em>Ryan Doyle</em></a><em>.<br></em></p><p>I grew up on a crop farm in the Finger Lakes of New York. When I was eighteen, I had the opportunity to go to school in Los Angeles. For the first time since my great grandmother came here from Ireland, a Doyle left the “middle finger” of NY.<br></p><p>For four years, I studied “business.” For someone used to working with their hands, it was an uncomfortable amount of theory. Outside of my classes, I was tinkering. Projects like a bitcoin brokerage, seeking a patent for a garden tool, and a few ecommerce shops became my bridge between theory and action.<br></p><figure id="w-node-301981ba2eb8-f921d246"><p><img src="https://uploads-ssl.webflow.com/5f4c1c4bc17267761b21d253/5fbec1e09b509d00db535009_Zenb_bZC0Ru9U1T6r_e18Btl3jkmLftJ5wgKpgveNW5hxfeWyNreW-f9lDxexy1XCN_Q-RJ5LmUxnsx1QJTPUOIRdHby5cpAnQQO_rxLyoF89Ns5ZhBqe2pX3vLwY4u9Sw.jpeg" alt=""></p></figure><p>Quickly, building became my passion. As I graduated, I joined a software startup in Palo Alto to smile-and-dial as an entry-level sales person. I figured I’d see how these companies were built from the inside out so I could emulate it someday.<br></p><p>Hustle and elbow grease took me from that role, to another startup in NYC, where I helped build the sales team. I went from phone jockey to deal-closer. On my nights and weekends, I was teaching myself to code.</p><p><br>One of those nights, I found Visualize Value on Twitter. The simple theories resonated with my action-oriented mindset. In particular, the idea of a <strong>Permissionless Apprenticeship</strong>. (<a href="https://twitter.com/jackbutcher/status/1261139777061113858?lang=en">link to tweet thread</a>)<br></p><p>This was something I was already doing in sales. I’d see a company that might be worth a few million dollars to the company. I’d live their brand for a few days, experiencing everything I could. Then I’d compile it and send it to the highest executive I could find, showing the gap we could fill.<br></p><h3>It had the highest return on time of anything I did. <br></h3><p>In the VV community of designers and makers, I accidentally found out that this was valued by anybody in business, not just Fortune 500 companies. I started doing “Free Sales Advice Friday,” and business owners would share what they were working on. I would reply with scrappy tactics to go out and find new customers, specifically for their business. </p><figure id="w-node-1ed3a476e59c-f921d246"><p><img src="https://uploads-ssl.webflow.com/5f4c1c4bc17267761b21d253/5fbec238bc87551cc41f9091_SBYXJoLLf8A93EpVRlXUzHAg9WB-jV66ry6jmT-imj15yB8FWSyI0I30xN_Vt3e7QVL4i0yxUoIDuQ_3pjeU_-buVwkKgWt-IVLB_ZmEOlzI91RTg3W6cdmATD8V6XMqsA.png" alt=""></p></figure><p>‍</p><p><em>"Some of the best help I've received online, thank you."&nbsp;—&nbsp;Jordan Godbey</em></p><p><em>"That is superb advice." —&nbsp;Andy Whyte</em></p><p><em>"Ryan, this thread is gold!"&nbsp;—&nbsp;Ben Ford<br>‍</em></p><p>I didn’t think too much of the feedback and kept working on my sales job. But I knew, mentally and emotionally, I was ready to make the leap into something of my own. I could code. I could sell. The pandemic provided the perfect reason to hide away for a year and hustle, nobody was hanging out without me anyhow.<br></p><p>In August, I quit my job, moved back to the farm to extend my runway, and committed myself to building. I felt like I had the skills I needed. The community was there through my sales work. I hadn’t realized it yet, but the community was there through Visualize Value as well.</p><p>I hoped salespeople would care about what I was building. <strong>As I applied my sales advice to my own software project, I found that more builders cared about how I approached sales. </strong>In months of Free Sales Advice Fridays, I advised 100+ business owners and explored so many different angles they could take.<br></p><p>There was already sales advice out on the internet. But the message didn’t matter to these people, the medium did. And I was the medium. To tap into that I built a small guide on pre-selling your product to customers and tested the offer of a premium newsletter. Then this happened:<br></p><figure id="w-node-b130da7c6edb-f921d246"><p><img src="https://uploads-ssl.webflow.com/5f4c1c4bc17267761b21d253/5fbec29f91c0ddef19a5840c_vO6r4tsysvvlePHfASruxWYEHU110pu8Z7TTAT-rcyVbeRxEeKK0YK0RFG3nqC-uqzIJA39A8_2JPvM3foisdyBXsYbgPiWzhz8M4AdWzt52IJ_F8zh6uK8xqSiwiZCEDw.png" alt=""></p></figure><p>On day 1, I hit $170 MRR. More revenue than I was making from my software project. Almost entirely profit. From what was already in my head. It was astonishing to me, that something so innate to me was worthy of an individual’s money.<br></p><h3>By sharing that innate knowledge through Free Sales Advice Friday, I was really embodying the permissionless apprenticeship. Every week I was able to hone my message in a zero-stakes, zero-permission environment. <br></h3><p>If I hadn’t sought out ways to provide free value, I wouldn’t have realize what people would pay me for. By the time I discovered what people wanted to pay for, I had built up enough “brand equity” for early adopters to trust me.<br></p><p>I’m still building my software projects. But my early adopters for my sales guides will allow me to do so with an audience who will test and support me, while paying me for the opportunity to do so.<br></p><p>I still do Free Sales Advice Fridays and stay active in the <a href="https://shop.visualizevalue.com/products/membership">Visualize Value Community</a>. When you join, look out for the weekly post in #general. Looking forward to giving you sales advice, too :)</p></div></div></div>]]>
            </description>
            <link>https://www.value.app/feed/permissionless-apprenticeship-ryan-doyle</link>
            <guid isPermaLink="false">hacker-news-small-sites-25236350</guid>
            <pubDate>Sat, 28 Nov 2020 08:54:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Generalized f-Mean]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25236328">thread link</a>) | @goldenkey
<br/>
November 28, 2020 | https://churchofthought.org/blog/2017/03/26/the-generalized-mean-an-algorithmic-approach/ | <a href="https://web.archive.org/web/*/https://churchofthought.org/blog/2017/03/26/the-generalized-mean-an-algorithmic-approach/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			<p>In school, we are first taught the arithmetic mean, then later the geometric mean, and maybe one or two others like the harmonic/contraharmonic mean.</p>
<p>But most teachers do not teach the logic or derivation behind these means. They merely provide the formulas and perhaps provide some scenarios where each mean would be more useful than the others.</p>
<p>I’d like to illustrate the definition of a mean, in the most abstract sense, from a programmer’s perspective, an algorithmic point of view.</p>
<h2>A Balancing Act</h2>
<hr>
<p>Suppose we have a list of N numbers, and a binary operation $f(a,b)$</p>
<p>If we apply that binary operation to one number from the list, we must&nbsp;apply its inverse operation to another number from the list.</p>
<p>We can continue applying $f$ to one element then $f^{-1}$ to another element as many times as we need to, until every number in the list is equal. That number that all elements are equal to…is the mean!</p>
<p>Means are just balancing acts!</p>
<p>** I am aware we haven’t specified the most&nbsp;optimized way to perform this algorithm to ensure it halts.</p>

<h2>Example</h2>
<hr>
<p>let our list be $(2,4,6)$ and our $f(a,b)=a+b$</p>
<p>then we apply the operation and its inverse to two elements respectively:</p>
<p>$(f(2,2), 4 ,f^{-1}(6,2)) = (2+2, 4 ,6-2) =&nbsp;(4,4,4)$</p>
<p>So our mean is 4.&nbsp;We just performed the&nbsp;<em>arithmetic mean</em>!</p>

<h2>What is it good for?</h2>
<hr>
<p>Well, given ANY invertible&nbsp;symmetric binary function, we can define a mean and derive its “shortcut” formula!</p>
<p>Here are the functions that define the means we usually come across:</p>
<p>arithmetic mean: $f(a,b) = a+b$<br>
geometric mean: $f(a,b) = ab$<br>
geometric mean (alternative definition): $f(a,b) = ln(a) + ln(b)$<br>
harmonic mean: $f(a,b) = 1/(1/a + 1/b)$</p>

<h2>Favoring Large or Small Numbers</h2>
<hr>
<p>Now, most of us learn that geometric mean tends to favor smaller&nbsp;numbers.</p>
<p>For example, the arithmetic mean of 1&nbsp;and 100 is $50\frac{1}{2}$. But the geometric mean of 1 and 100 is 10.</p>
<p>Knowing what we do now, can we create a mean that favors smaller numbers&nbsp;even more?</p>
<p>I don’t know if these already exist in the formal mathematics universe, ie. books or published papers. So let me know if you find a previous name for them!</p>
<p>Franken-mean: $f(a,b) = a^b b^a$</p>
<p>Franken-mean v2: $f(a,b) = a^b + b^a$</p>
<p>You might ask if we can skew our mean toward smaller numbers&nbsp;even more than our above exponential mean. We sure can. Using something called Tetration, simply put – it is iterated exponentiation. There are even operations that encompass iterated tetration and so on…these kind of operations are called&nbsp;hyperoperations. So we can make a mean skewed toward lows or highs as much as we want, and it’s beautiful isn’t it? Before different means are taught, the theory of what defines a mean should really be taught.</p>
<p>But before I forget,&nbsp;you must be saying: “Where’s my shortcut formulas?!!”</p>
<p>Okay okay.</p>

<h2>Deriving the Closed Formulas</h2>
<hr>
<p>Let’s derive the arithmetic mean first. Assume we have a list of 4 elements, ${x,y,z,t}$</p>
<p>Given the binary symmetric&nbsp;function that defines the arithmetic mean $f(a,b)=a+b$,</p>
<p>we let $g(a) = f(a,f(a,f(a,a))) = a + a + a + a = 4a$</p>
<p>Our formula for the mean of the 4 numbers in our list will be:</p>
<p>$g^{-1}(f(x,f(y,f(z,t))))$</p>
<p>We know $g(a) = 4a$, so $g^{-1}(a) = a/4$</p>
<p>That means our mean is $(x+y+z+t)/4$, which is what we expected from the arithmetic mean</p>
<p>Above was just a demonstration for a fixed size list of 4 elements. The concept is the same for any sized list. We can use induction to extrapolate what the formula will be for a list of n&nbsp;elements, $(x+y+z+t…….+w)/n$</p>

<h2>Mathematica code for the generalized mean</h2>
<hr>
<pre id=""><code>GeneralizedMean[l_List, f_Function] := (
InverseFunction[
(Fold[f, ConstantArray[#, Length[l]]]) &amp;
] [Fold[f, l]]
);
</code></pre>
<ul>
<li>Arithmetic Mean
<pre id=""><code>In:= GeneralizedMean[{x,y,z,t},(#+#2)&amp;]
Out= 1/4 (t+x+y+z)</code></pre>
</li>
<li>Geometric Mean
<pre id=""><code>In:= GeneralizedMean[{x, y, z, t}, (#*#2) &amp;]
Out= (t x y z)^(1/4)
</code></pre>
</li>
<li>Harmonic Mean
<pre id=""><code>In:= GeneralizedMean[{x, y, z, t}, (1/(1/# + 1/#2)) &amp;]
Out= 4/(1/t + 1/x + 1/y + 1/z)
</code></pre>
</li>
<li>Franken Mean v1
<pre id=""><code>In:= GeneralizedMean[{x, y}, (#^#2 * #2^#) &amp;]
Out= Log[x^y y^x]/(2 ProductLog[1/2 Log[x^y y^x]])
</code></pre>
</li>
</ul>
<p>I had to use 2 variables for the above, because Mathematica’s symbolic inverses aren’t strong enough.<br>
Franken Mean v2 does not even compute with symbolics or even numbers.<br>
I will eventually work on this to hopefully get at least numerics to work nomatter what.</p>
<h2>Alternative Implementation</h2>
<hr>
<p>This is an alternative implementation which seems to yield better results in some cases:</p>
<pre id=""><code>GeneralizedMean[l_List, f_Function] := (
Module[{x},
Solve[Fold[f, l] == Fold[f, ConstantArray[x, Length[l]]], x][[-1,
1, 2]]
]);
</code></pre>

<h2>Create your own means!</h2>
<hr>
<p>Enjoy creating your own means! Number theoretic means on lists of primes and that sort of stuff should be very interesting to explore, cheers!</p>
<h3><strong>Continued in:</strong></h3>

<h3><a href="https://churchofthought.org/means-of-infinite-sets-and-more/"><strong>Part Two: Means of Infinite Sets</strong></a></h3>
<p><em>P.S.</em></p>
<p>Kolmogorov actually did something similar and came up with what’s called the <a href="https://en.wikipedia.org/wiki/Quasi-arithmetic_mean">Generalized f-mean</a></p>
<p>But he restricted his construct to only functions of the form $f(a,b) = g(a) + g(b)$, where g is the function that determines the mean and is to be specified.</p>


		</div><!-- .entry-content -->

	</div></div>]]>
            </description>
            <link>https://churchofthought.org/blog/2017/03/26/the-generalized-mean-an-algorithmic-approach/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25236328</guid>
            <pubDate>Sat, 28 Nov 2020 08:51:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Made my personal site into a desktop environment influenced by Windows and macOS]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25235800">thread link</a>) | @DustinBrett
<br/>
November 27, 2020 | https://dustinbrett.github.io/x/ | <a href="https://web.archive.org/web/*/https://dustinbrett.github.io/x/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://dustinbrett.github.io/x/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25235800</guid>
            <pubDate>Sat, 28 Nov 2020 06:45:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bill Gates is wrong about education]]>
            </title>
            <description>
<![CDATA[
Score 31 | Comments 64 (<a href="https://news.ycombinator.com/item?id=25235672">thread link</a>) | @rajlego
<br/>
November 27, 2020 | https://supermemo.guru/wiki/Bill_Gates_is_wrong_about_education | <a href="https://web.archive.org/web/*/https://supermemo.guru/wiki/Bill_Gates_is_wrong_about_education">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="mw-content-text" lang="en" dir="ltr"><p><small>This text is part of: "<i><a href="https://supermemo.guru/wiki/Problem_of_Schooling" title="Problem of Schooling">I would never send my kids to school</a></i>" by <a href="https://supermemo.guru/wiki/Piotr_Wozniak" title="Piotr Wozniak">Piotr Wozniak</a> (2017)</small>
</p>


<h2><span id="Bill_Gates_is_my_hero">Bill Gates is my hero</span></h2>
<p>Bill Gates was an early guiding light and <a href="https://supermemo.guru/wiki/SuperMemo_World" title="SuperMemo World">our</a> inspiration. When <a href="https://supermemo.guru/wiki/Krzysztof_Biedalak" title="Krzysztof Biedalak">Krzysztof Biedalak</a> and I made our first $3 investment in a corporate rubber stamp, which was a post-communist obligation for all companies in Poland in 1991, Microsoft was a multibillion-dollar company. How could we not have been blinded by inspiration? We wanted to write a universally useful piece of software and the world would be ours - we thought. Bill Gates's software philosophy, based on respect for backward compatibility, sheltered <a href="https://supermemo.guru/wiki/SuperMemo" title="SuperMemo">SuperMemo</a> on its path to its painfully slow adoption. Software and database compatibility have been preserved for 30 years now. My first pieces of knowledge in medical sciences, typed in on Dec 13, 1987, are still there in my collection, well-memorized and useful. Without Gates and his stance on compatibility, I would have lost all that knowledge to some upgrade hiccup long ago. When Gates moved to philanthropy, he has secured his place on my list of the greatest people who ever walked this planet. Perhaps as many as <a href="https://supermemo.guru/wiki/Bill_Gates_saved_over_100_million_children" title="Bill Gates saved over 100 million children">30-120 million kids have been saved by Bill's foundation</a>. This begs a vital question: Why is Gates so awfully wrong about education? Why does he fall for the same old myth that <a href="https://supermemo.guru/wiki/Myth:_You_can_improve_education_by_throwing_more_money_in_it" title="Myth: You can improve education by throwing more money in it">investing in education will produce better outcomes</a>? The education system is wrong and it must be redesigned. <a href="https://supermemo.guru/wiki/Compulsory_schooling_must_end" title="Compulsory schooling must end">Compulsory schooling must end</a>. See: <a href="https://supermemo.guru/wiki/Grand_Education_Reform" title="Grand Education Reform">Grand Education Reform</a>
</p>
<h2><span id="Could_Bill.27s_great_mind_be_wrong.3F">Could Bill's great mind be wrong?</span></h2>
<p>Everyone who disagrees with a great mind needs to pause and re-examine. Gates got sensational credentials. He sports a genius mind. He has seen more places that I could possibly ever manage to visit in Google Maps. He has spoken to more great people than I have had a chance to read about. He has visited more schools that I have seen on pictures. He started his forays into education in 1999. In contrast, I started thinking about "the system" only in 2016 when getting ready to write this <a href="https://supermemo.guru/wiki/Problem_of_Schooling" title="Problem of Schooling">book</a>. This makes me into a fledgling with an immature point of view. Gates himself is a great example of a brisk student who has turned his skills and talents into a monumental achievement. His credentials are so much better than mine!
</p>
<h2><span id="Bill_Gates.27s_perspective">Bill Gates's perspective</span></h2>
<p>Could this just be that Gates's perspective is so much different than mine?
</p><p>He looks at the education system like at the operating system. Measure the performance, look for bottlenecks in the system, fix the parameter here and there, videotape a great teacher, and make others copy the method, and manufacture greatness.
</p><p>He looks at education like a philanthropic job. Like he treats health problems with mass vaccinations, he looks for a simple formula which could improve the education of the masses with some industrial move? He seems less focused on letting the brightest thrive, and more focused on preventing the weakest from dropping out. He wants to bring up the average using some <a href="https://supermemo.guru/wiki/Testing" title="Testing">standardized testing</a> approach.
</p><p>He looks at education like a big company that needs to be managed effectively with departments, and sub-departments. With a clear division of responsibility. <a href="https://supermemo.guru/wiki/Modern_schooling_is_like_Soviet_economy#Schooling_is_like_Soviet_Economy" title="Modern schooling is like Soviet economy">With an industrial goal in mind?</a>
</p><p>Could this be that this great capitalist shows more socialist thinking than a little well-indoctrinated ex-communist like myself?
</p><p>There is a different perspective of an employer and an employee, esp. in a creative position. Gates looks at the number of college graduates. I look for specific skills and creative powers. Actual degrees do not matter much if you take time to get into a particular brain.
</p><p>He looks at students like productive workers. The heretic idea of a longer school day must have come from the factory model thinking. Longer days, more production, more manufacturing.
</p><p>He looks at education from a societal point of view, while I look at the brain of an individual. He wants to move the masses to high achievement, while I want to produce more little Bill Gateses.
</p><p>Unlike myself, Bill Gates does not focus on having more Bill Gateses. He focuses on helping the poor, in boosting qualifications of the middle class, and adds "<i>you can't run a society on top 5%</i>". He is right, however, that top 5% can forge a path in education that would inspire all the rest. They cannot be run through a compulsory system set on pushing through the remaining 95%.
</p><p>Gates's approach would be great for some poorer countries (e.g. in Africa). Where there are no schools, industrial approach and good management could quickly improve health, eliminate poverty, and provide basic education.
</p><p>My approach is probably more suited to well-developed nations where the industrial approach makes people sick of schooling. With social awareness and education on the rise, we look for more little future Noble Prize winners and future Bill Gateses.
</p><p>His own kids get the best kind of learning. During his trips around the world, they get to visit places like the Large Hadron Collider at CERN. This could spark a life-long passion that could turn them into future particle physicists or another incarnation of <a href="https://supermemo.guru/wiki/Tim_Berners-Lee" title="Tim Berners-Lee">Tim Berners-Lee</a>.  
</p><p>Where Gates optimizes for improving the average, I am looking for the optimum of peak intellectual performance.
</p><p>Last but not least, could Gates's approach be an afterglow of his dropping out from Harvard. I see that over and over again, dropouts seem to suffer from this life-long hangover about what could have been? They tend to over-appreciate the power of schooling or the power of college. In the same way, I might be under-appreciating my own degrees. Gates is <a href="https://supermemo.guru/wiki/Thiel_on_competition_for_degrees" title="Thiel on competition for degrees">the opposite of Peter Thiel</a> who studiously climbed the educational ladder until he stumbled to see the light. Thiel is now one of the staunchest critics of college.
</p>
<h2><span id="Bill_Gates.27s_formula_for_success">Bill Gates's formula for success</span></h2>
<p>I see Gates's own life as a simple formula for success in science, engineering, or life in general:
</p>
<ul><li> healthy childhood of few concerns (preferably without the relegation to <a href="https://supermemo.guru/wiki/Daycare_misery" title="Daycare misery">daycare</a>)</li>
<li> healthy approach to schooling with pranks, rebellions, disobedience, and freedom </li>
<li> minor trajectory nudges within the <a href="https://supermemo.guru/wiki/Push_zone" title="Push zone">push zone</a> by inspirational tutors. If tutors are not parents, this might be the most expensive part of the formula</li>
<li> breakthrough passion, e.g. for tinkering with computers or software</li>
<li> healthy education, possibly interrupted by some breakthrough decision (e.g. <i>Let me drop out from Harvard to set up the greatest software company in the world</i>)</li>
<li> relentless lifelong pursuit of goals born from that <a href="https://supermemo.guru/wiki/Passion_and_memory" title="Passion and memory">youthful passion</a></li>
<li> voracious reading (see: <a href="https://supermemo.guru/wiki/Bill_Gates_and_his_non-incremental_reading" title="Bill Gates and his non-incremental reading">Bill Gates and his non-incremental reading</a>)</li></ul>
<p>Only Bill Gates truly knows it, but my understanding of his life story is that his future was determined by just one major factor: getting his hands on a computer. He was good at math and programming. So are dozens of kids in my neighborhood. My thinking comes from the fact that I was also strongly affected by my first contact with computers.
</p>

<p>When <a href="https://supermemo.guru/wiki/First_steps_of_SuperMemo" title="First steps of SuperMemo">I got my first computer in 1986</a>, ZX Spectrum, I was 24 and experienced wild elation with computer's obedience in executing my commands. I told the computer what to do, and it did it perfectly without asking questions. That was wonderful. I started writing my <a href="https://supermemo.guru/wiki/Plan" title="Plan">program for planning my day</a> on paper long before I got the computer on my desk. I was eager to see it work! As ZX Spectrum would load programs from a cassette tape, I could not easily dream of having <a href="https://supermemo.guru/wiki/SuperMemo" title="SuperMemo">SuperMemo</a>. It needed access to some disk drive. I got my first PC with a 360 KB <a href="https://en.wikipedia.org/wiki/Floppy_disk">floppy disk</a> drive only <a href="https://supermemo.guru/wiki/SuperMemo_1.0_for_DOS_(1987)" title="SuperMemo 1.0 for DOS (1987)">in 1987</a></p>
<p>The above hypothetical formula for educational success is simple and effective. Only a few might ever dream to replicate the scope of Bill's success. If that formula does not bring serial Nobel Prize winners, it should at least bring up a great deal of happy and fulfilled individuals. Freedom to explore the world is essential and it is denied to a great deal of kids in the modern world. When Peter Thiel pays kids to drop out from college, he looks for this type of free thinking experience that can change one life and then can change the world.
</p>
<h2><span id="My_attempt_at_employing_Gates.27s_formula">My attempt at employing Gates's formula</span></h2>

<p>I am happy with <a href="https://supermemo.guru/wiki/Exponential_adoption_of_spaced_repetition" title="Exponential adoption of spaced repetition">my achievements in life</a>. I have followed the formula employed by Gates. However, there were some exceptions. Perhaps I could use them as an excuse for not being as wildly successful as Bill? I was sent to <a href="https://supermemo.guru/wiki/Daycare_misery" title="Daycare misery">daycare</a>, and I am sure this slowed down my development. The time I spent with my brother was more intellectual and inspirational by two orders of magnitude. However, he was a student and could not babysit the little me for ever. In later years, I was forced into a degree of conformity by an ever-present threat of being enlisted by the army in service of the Warsaw Pact. In 1986, I was finally free of the army service, and could finally drop out, however, I was not ready. There was no market economics culture in Poland of the 1980s. I read about entrepreneurial science in Science in 1989 (Oct 31, 1989). This was the first time when it occurred to me that my research into memory might actually be a seed of a business. Initially, though, my passions led me in the direction of a PhD. Schooling told me that science done by entrepreneurs is inferior to science done in academia. I thought of <a href="https://supermemo.guru/wiki/SuperMemo" title="SuperMemo">SuperMemo</a> as an opportunity to earn money for a trip to America. It seems that while Gates was fast to mature as a little entrepreneur, I needed 28 long years to even start thinking of my <a href="https://supermemo.guru/wiki/SuperMemo_World" title="SuperMemo World">own business</a>.</p>
<h2><span id="Reconciling_Gates_and_Woz">Reconciling Gates and Woz</span></h2>
<p>Gates wants better teachers, better education, verification, <a href="https://supermemo.guru/wiki/Testing" title="Testing">testing</a>, measuring, carrot-and-stick for teachers, etc. In contrast, I stand with Steve Jobs. Jobs told the kids to <a href="https://supermemo.guru/wiki/Fundamental_law_of_learning" title="Fundamental law of learning">rebel</a>!
</p><p>Gates believes that the key to the <a href="https://supermemo.guru/wiki/Reform" title="Reform">great future education system</a> is the teacher. He is almost right. If we could populate present schools with great teachers, I wouldn't ever need to write <a href="https://supermemo.guru/wiki/Problem_of_Schooling" title="Problem of Schooling">this book</a>. The problem is that <a href="https://supermemo.guru/wiki/Progressive_education" title="Progressive education">a great teacher is simply a truly great man</a>. Great teaching requires a degree of genius. We need millions of those great people. How can we possibly hope to produce hundreds of thousands …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://supermemo.guru/wiki/Bill_Gates_is_wrong_about_education">https://supermemo.guru/wiki/Bill_Gates_is_wrong_about_education</a></em></p>]]>
            </description>
            <link>https://supermemo.guru/wiki/Bill_Gates_is_wrong_about_education</link>
            <guid isPermaLink="false">hacker-news-small-sites-25235672</guid>
            <pubDate>Sat, 28 Nov 2020 06:12:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Considerations Before Graduating as an Engineer]]>
            </title>
            <description>
<![CDATA[
Score 45 | Comments 29 (<a href="https://news.ycombinator.com/item?id=25235665">thread link</a>) | @Ninroot
<br/>
November 27, 2020 | https://reflexio.debec.eu/considerations-before-graduating-engineer | <a href="https://web.archive.org/web/*/https://reflexio.debec.eu/considerations-before-graduating-engineer">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        
        <figure>
            <img alt="cover" src="https://reflexio.debec.eu/assets/piano.svg">
            <figcaption><a href="https://www.pinterest.de/pin/521995413033512913/" target="_blank">credit</a></figcaption>
            
        </figure>
        
        <p>In 2018, I graduated from <a href="https://en.wikipedia.org/wiki/%C3%89cole_pour_l%27informatique_et_les_techniques_avanc%C3%A9es">EPITA</a>, a french engineering “Grande École” specialized in computer science. The subjects I had treated there were very technical: from the implementation of an ISO file reader to a <a href="https://www.lrde.epita.fr/~tiger/tiger.html">Tiger compiler</a>.</p>

<p>The technical focus, taught in technical programs such as my engineering school, has led me to some small surprises during my first steps in the business world. The following list outlines what I would have liked to have learned before graduation. The article is obviously influenced by computer science, which is the specialty of my school. Nevertheless, I hope that the students will find some teaching in it, whatever the technical field they are targeting.</p>



<h2 id="human-is-the-new-challenge">Human is the New Challenge</h2>

<p>Coming from a school whose implicit motto was “the more technical, the better”, I had to quickly get used to the idea that the new technicality coming out of school was primarily human. Don’t make me wrong: having technical knowledge is as necessary as expected by the business world. But if many of us have been trained to take up technical challenges, we have been much less prepared for the strangeness of human behavior.</p>

<blockquote>
  <p>Technical skills should no longer be your challenge, your challenge should now be human.</p>
</blockquote>

<p>Schopenhauer said in The Art of Being Right “<em>A man may be objectively in the right, and nevertheless in the eyes of bystanders, and sometimes in his own, he may come off worst</em>” which in our case could be perfectly translated as “<em>You may be technically right and yet not be supported by others.</em>”. Sometimes engaging technical decisions are taken on the basis of very non-technical arguments, for example:</p>
<ul>
  <li>you were sick on the day of an important meeting;</li>
  <li>your level in English is not good enough to argue well enough;</li>
  <li>your manager used to work at XYZ, therefore XYZ technology is chosen for the project;</li>
  <li>your ambition to change a design frightens the rest of the team, despite the little amount effort it actually requires;</li>
  <li>your colleague X doesn’t like you, therefore it doesn’t like your design;</li>
  <li>etc.</li>
</ul>

<p>The list is endless. Just keep in mind that if you want technical decisions to be accepted, you will have to arm yourself with skills that go well beyond technique, starting with <em>negotiation</em> for example.</p>



<p>The school doesn’t just train engineers in languages or tools, it establishes a culture and a discipline that becomes stronger or weaker by joining a firm. Depending on the business sector, company, project or team, not everyone gives the same attention to software engineering. It is very unlikely that this discipline is the core business of your company, nor even the academic background of your colleagues. The good practices, taken for granted, can then be violently disrupted: no code review, no unit tests, sometimes even no version-control tool.</p>

<p>The intuitive reflex of a young engineer is to bring a purely technical solution: no version-control tool? let’s install git! No code review? Let’s protect the master branch! No unit tests? Install the right testing library! Etc. But here we are, the problem is <em>not</em> technical, the problem is primarily human, more particularly cultural. Changing the corporate culture, or more modestly, <em>the culture of a team is far more difficult to change than any tool</em>.</p>

<p>I will always remember the long struggle to get GitLab for an old project. This was the kind of indispensable work tool for a software engineer. The battle was long, not because the tool did not exist (it just had to be downloaded and installed) but because the required culture was not ready.</p>

<p>It takes time and effort to change a culture, but it is well worth the effort. A tool can always be dropped, a <code>git push</code> can always be forced, but a disciplined team is hardly swindled. So when choosing between a very well equipped team and a very disciplined team, <em>choose discipline without hesitation</em>!</p>

<h2 id="professional--genius">Professional &gt; Genius</h2>

<p>In university, a lot of credit was given to geniuses who, alone, could compile a few thousand lines of complicated code in a single night’s work. When I entered the business world, my vision changed a lot from that kind of profile, capable of doing a lot of work in record time. Their confidence (or arrogance) leads to an extra commitment, which makes it difficult to meet delivery deadlines. And because geniuses understand complex things, they <a href="https://reflexio.debec.eu/principles-for-better-design#keep-it-simple-stupid">design complex systems</a> that no one understands. Their loneliness makes them unique masters of their subjects, thereby nurturing their self-esteem. Knowledge remains in their heads and their presence becomes necessary for every decision.</p>

<p><a href="https://armament.solutions/tactics/single-points-of-failure.html"><img src="https://reflexio.debec.eu/assets/single_point_of_failure.svg" alt="Single point of failure"></a></p>

<p>But geniuses also have 24-hour days and quickly turn out to be the <em>bottleneck</em> of everything, slowing down everyone else. You don’t need to be a software architecture expert to agree that it is not desirable to over-commit and underestimate a single resource: apart from the inability to scale, the resource is the single point of failure. <a href="https://en.wikipedia.org/wiki/Single_point_of_failure">The design of a single point of failure is unforgivable</a>. Once the engineer gets sick, goes on vacation, or leaves the company, the entire team will have to pay back months or even years of unprofessionalism.</p>

<p>It is a black and exaggerated portrait that I paint here. I can nevertheless bet that you will encounter this kind of profile in your career which, in addition to having a negative impact on entire projects (and on people’s health), will sometimes be claimed as a hero by the organization. <em>Real geniuses are the geniuses also capable of <a href="https://reflexio.debec.eu/principles-for-better-design#keep-it-simple-stupid">designing simplicity</a>, taking people on board while humble towards humanity and their workload</em>. These are called great professionals. They spread knowledge and responsibility in order to become not the single point of failure or the bottle neck.</p>

<blockquote>
  <p>Geniuses build scalable services, professionals are scalable geniuses. - <a href="https://twitter.com/arnaud_debec/status/1327584444849524736">Twitter</a></p>
</blockquote>

<!--
## Read Through What Is Ask From You

If you asked your manager if you had to do unit tests, he would tell you not to waste time with it.

> If I had asked people what they wanted, they would have said faster horses. - [Henry Ford](https://hbr.org/2011/08/henry-ford-never-said-the-fast)

 -->

<h2 id="side-note">Side note</h2>

<p>Do you think there’s a principle missing? Send me your comments! This list will certainly be extended and refined, subscribe to the <a data-formkit-toggle="78a863d4eb" href="https://reflexio-debec.ck.page/78a863d4eb">newsletter</a> if you wish to be notified about it.</p>

    </div></div>]]>
            </description>
            <link>https://reflexio.debec.eu/considerations-before-graduating-engineer</link>
            <guid isPermaLink="false">hacker-news-small-sites-25235665</guid>
            <pubDate>Sat, 28 Nov 2020 06:09:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Supermassive Lens on the Constants of Nature]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25235211">thread link</a>) | @CapitalistCartr
<br/>
November 27, 2020 | http://m.nautil.us/issue/93/forerunners/a-supermassive-lens-on-the-constants-of-nature | <a href="https://web.archive.org/web/*/http://m.nautil.us/issue/93/forerunners/a-supermassive-lens-on-the-constants-of-nature">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
			<p><span>T</span>he 2020 Nobel Prize in Physics went to three researchers who confirmed that Einstein’s general relativity predicts black holes, and established that the center of our own galaxy houses a supermassive black hole with the equivalent of 4 million suns packed into a relatively small space. Besides expanding our understanding of black holes, the strong gravitational field around the supermassive black hole is a lab to study nature under extreme conditions. Researchers, including one of the new Nobel Laureates, <a href="http://alliance.nautil.us/article/199/opening-a-new-window-into-the-universe" target="_blank">Andrea Ghez</a> at UCLA, have measured how the intense gravity changes the fine structure constant, one of the constants of nature that defines the physical universe, and in this case, life within it. This research extends other ongoing efforts to understand the constants and whether they vary in space and time.&nbsp;The hope is to find clues to resolve issues in the Standard Model of elementary particles and in current cosmology.</p><figure data-alt="Perkowitz_BREAKER-1"><img src="http://static.nautil.us/17968_916cbd6f20415c2214d441deaefedf75.png" width="733" alt=""><figcaption><span><strong>NOBEL LAUREATE:</strong> Andrea Ghez won science’s biggest prize for her co-discovery of a supermassive black hole in the center of our galaxy. She has also precisely defined the elliptical paths of stars orbiting the galactic center.</span><span>Wikimedia Commons</span></figcaption></figure> <p>Besides Ghez, the other Nobel Laureates honored in 2020 are Roger Penrose at Cambridge University, who deepened our theoretical understanding of black holes; and Reinhard Genzel, of the Max Planck Institute for Extraterrestrial Physics in Garching, Germany. Ghez and Genzel carried out parallel but separate observations and analysis that led each to deduce the presence of our galactic supermassive black hole. At 27,000 light-years away, obtaining good data required huge telescopes. Ghez worked with the Keck Observatory on Mauna Kea in Hawaii, and Genzel used the Very Large Telescope in Chile. Each researcher found that the motion of the stars they observed arose from an enormous mass at the center of the galaxy. They obtained the same value, 4 million times the mass of our sun, in a region only as big as our solar system—definitive evidence of a supermassive black hole.</p><p>Ghez’s research at Keck made her a co-author <a href="https://arxiv.org/abs/2002.11567" target="_blank">in a paper</a> published this year, in which Aurélien Hees of the Paris Observatory and 13 international colleagues presented results for the fine structure constant near our galactic supermassive black hole. Remarkably, Ghez’s Nobel Prize-winning results supporting this research combined today’s theories and astronomical techniques with ideas dating back to Johannes Kepler and Isaac Newton to examine the motion of stars near the supermassive black hole. This is another example of Newton’s insight about how science advances when he wrote in 1675, “If I have seen further it is by standing on the shoulders of giants.”</p><blockquote><p>The constant in the strong gravity near the black hole could be a clue to modifying the Standard Model.</p> </blockquote><p>German astronomer Kepler is one such giant who changed science when he presented his laws of planetary motion in 1609. He was the first to show that the planets do not orbit the sun in divinely inspired perfect circles, as had been assumed. The orbits are ellipses with the sun at a focus of the ellipse, one of the two points symmetrically offset from the center that define how to construct an ellipse. Kepler also found a mathematical relation between the size of a planetary orbit and how long it takes the planet to complete a circuit.<br></p><p>In 1687 Newton gave Kepler’s laws a deeper, more coherent physical basis. Newton’s law of gravitation, based on mutual attraction between bodies, showed that a celestial object in a closed orbit around a mass follows an elliptical path that depends on that mass. This result, which today is taught in introductory astronomy, is the heart of how Ghez found the mass of the supermassive black hole. Her years of careful observations precisely defined the elliptical paths of stars orbiting the galactic center; then she used Newton’s theory to calculate the mass at the center (general relativity, which replaces Newton’s law, predicts black holes but Newton’s approach is sufficiently accurate for the stellar orbits around the supermassive black hole). Knowledge of these orbits would be crucial for measuring the fine structure constant in the strong gravity near the supermassive black hole. How that constant depends on gravity could be a clue to modifying the Standard Model or general relativity to deal with dark matter and dark energy, the two great puzzles of contemporary physics.</p> <p><span>T</span>his particular examination fits into a bigger, long-term examination of the fundamental constants of nature, each of which tells us something about the scope or scale of our deepest theories. Along with other constants, the fine structure constant (denoted by the Greek letter α), appears in the Standard Model, the quantum field theory of elementary particles. The numerical value of α defines how strongly photons and electrically charged particles interact through the electromagnetic force, which controls the universe along with gravity and the strong and weak nuclear forces. Among its effects, electromagnetism determines the degree of repulsion between protons and how electrons behave in an atom. If the value of α were much different from the one we know, that would affect whether nuclear fusion within stars produces the element carbon or whether atoms can form stable complex molecules. Both are necessary for life, another reason α is significant.</p><p>Other constants represent other major physical theories: <i>c</i>, the speed of light in vacuum, is crucial in relativity; <i>h</i>, the constant derived by Max Planck (now taken as “h-bar,” or <i>ħ</i> = <i>h</i>/2<i>π</i>), sets the tiny size of quantum effects; and <i>G</i>, the gravitational constant in Newton’s theory and general relativity, determines how astronomical bodies interact. In 1899 Planck used just these three to define a universal measurement system based on natural properties and not on any human artifacts. This system, he wrote, would be the same “for all times and all civilizations, extraterrestrial and non-human ones.”</p><blockquote><p>It raises the notion that out of many multiverses, the one where we exist is the one with the winning value.</p> </blockquote><p>Planck derived natural units of length, time, and mass from <i>c</i>, <i>ħ</i>, and <i>G</i>: <i>L<sub>P</sub></i> = 1.6 x 10<sup>-35</sup> meters, <i>T<sub>P</sub></i> = 5.4 x 10<sup>-44</sup> seconds, and <i>M<sub>P</sub></i> = 2.2 x 10<sup>-8</sup> kilograms. Too small to be practical, they have conceptual weight. In today’s universe the gravitational interaction between elementary particles is too weak to affect their quantum behavior. But place the bodies a tiny Planck length <i>L<sub>P</sub></i> apart, less than the diameter of an elementary particle, and their gravitational interaction becomes strong enough to rival quantum effects. This defines the “Planck era” 10<sup>-44</sup> seconds after the Big Bang, when gravitational and quantum effects were of similar strength and would require a combined theory of quantum gravity instead of the two separate theories we have today.<br></p><p>Nevertheless, to some physicists, <i>c</i>, <i>ħ</i>, and <i>G</i> are not truly fundamental because they depend on units of measurement. Consider for instance that <i>c</i> is 299,792 km/sec in metric units but 186,282 miles/sec in English units, This shows that physical units are cultural constructs rather than inherent in nature (in 1999, NASA’s Mars Climate Orbiter fatally crashed because two scientific teams forgot to check which measurement system the other had used). Constants that are pure numbers, however, would translate perfectly between cultures and even between us and aliens with unimaginably different units of measurement.</p><p>The fine structure constant α stands out as carrying this favored purity. In 1916 it appeared in calculations for the wavelengths of light emitted or absorbed as the single electron in hydrogen atoms jumps between quantum levels. Niels Bohr’s early quantum theory predicted the main wavelengths but spectra showed additional features. To explain these, the German theorist Arnold Sommerfeld added relativity to the quantum theory of the hydrogen atom. His calculations depended on a quantity he called the fine structure constant. It includes <i>ħ</i>, <i>c</i>, and the charge on the electron <i>e</i>, another constant of nature; and the permittivity <i>ε</i><sub>0</sub>&nbsp; that represents the electrical properties of vacuum. Remarkably, the physical units in this odd collection cancel out, leaving only the pure number 0.0072973525693.</p> <figure data-alt="Perkowitz_BREAKER-2"><img src="http://static.nautil.us/17967_a52357f1ce8160dee6563b6a3391ffa8.png" width="733" alt=""><figcaption><span><strong>GIANT SHOULDERS:</strong> This year’s Nobel winners drew on astronomical techniques dating back to Isaac Newton, who wrote of scientific advances, “If I have seen further it is by standing on the shoulders of giants.”</span><span>Nicku / Shutterstock</span></figcaption></figure><p>Sommerfeld used α just as a parameter, but it gained fame in the late 1920s when it reappeared in advanced work on relativistic quantum mechanics by the French physicist Paul Dirac, and then in what the English astronomer Arthur Eddington hoped would be a Theory of Everything. He planned to merge quantum theory and relativity to derive the properties of the universe such as the number of elementary particles in it, and its constants, α among them.</p><p>One twist in Eddington’s approach was that he considered the quantity 1/α rather than α, because his analysis showed that it must be an integer as well as a pure number. This was consistent with a contemporary measurement that yielded 1/α = 137.1, tantalizingly near 137 exactly. Eddington’s calculations gave instead 136, close enough to raise interest. Further measurements however confirmed that 1/α = 137.036. Eddington’s attempts to justify his different result were unconvincing and for this and other reasons his theory has not survived.</p><p>But α and “137” remain linked, which is why Richard Feynman called 137 a “magic number.” What he meant has nothing to do with numerology. Rather it is that we know how to measure the value of α but not how to derive it from any theories we know. This is true also for the other fundamental constants, including pure numbers such as the ratio of the proton and electron masses, and is a lack in the Standard Model. Nevertheless, the value of α is critical in …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://m.nautil.us/issue/93/forerunners/a-supermassive-lens-on-the-constants-of-nature">http://m.nautil.us/issue/93/forerunners/a-supermassive-lens-on-the-constants-of-nature</a></em></p>]]>
            </description>
            <link>http://m.nautil.us/issue/93/forerunners/a-supermassive-lens-on-the-constants-of-nature</link>
            <guid isPermaLink="false">hacker-news-small-sites-25235211</guid>
            <pubDate>Sat, 28 Nov 2020 04:13:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Design of Diskprices.com]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25235018">thread link</a>) | @neilpanchal
<br/>
November 27, 2020 | https://neil.computer/notes/the-design-of-diskprices-com/ | <a href="https://web.archive.org/web/*/https://neil.computer/notes/the-design-of-diskprices-com/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <article>
        
        <p>I was browsing the interwebs and came across this beauty: <a href="https://diskprices.com/">https://diskprices.com/</a></p><figure><img src="https://neil.computer/content/images/2020/11/Screen-Shot-2020-11-27-at-7.15.01-PM.png" alt="Diskprices.com" srcset="https://neil.computer/content/images/size/w600/2020/11/Screen-Shot-2020-11-27-at-7.15.01-PM.png 600w, https://neil.computer/content/images/size/w1000/2020/11/Screen-Shot-2020-11-27-at-7.15.01-PM.png 1000w, https://neil.computer/content/images/size/w1600/2020/11/Screen-Shot-2020-11-27-at-7.15.01-PM.png 1600w, https://neil.computer/content/images/size/w2400/2020/11/Screen-Shot-2020-11-27-at-7.15.01-PM.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Diskprices.com</figcaption></figure><p>There is a distinct absense of a header, branding, anything that takes away screen real-estate. The design of Diskprices.com orients towards what the user came to the website to do - to look at the list of available harddrives and compare their prices. It's in the domain name!</p><p>Furthermore, the performance of this website is stellar. It loads almost instantly. And the list (although its not sortable) gets the job done, it is sorted by price already which is the most important attribute.</p><p>Diskprices.com deserves the UI/UX award of the decade. We've lost our ability to design user interfaces laser focused towards the <em>user</em>. Instead, we have purple gradients, scroll jacking, responsive bullshit, emojis, animations and many other things designers do today. The utilitarian approach of Diskprices.com is refreshing, although the contemporary designers cast it off as 'brutalist design', thereby marking it as a statement of fashion.</p><p>The creators of Diskprices.com didn't just do this by chance, it is a deliberate attempt as stated in the FAQ:</p><figure><img src="https://neil.computer/content/images/2020/11/Screen-Shot-2020-11-27-at-7.24.17-PM.png" alt="Diskprices.com FAQ" srcset="https://neil.computer/content/images/size/w600/2020/11/Screen-Shot-2020-11-27-at-7.24.17-PM.png 600w, https://neil.computer/content/images/size/w1000/2020/11/Screen-Shot-2020-11-27-at-7.24.17-PM.png 1000w, https://neil.computer/content/images/2020/11/Screen-Shot-2020-11-27-at-7.24.17-PM.png 1210w" sizes="(min-width: 720px) 720px"><figcaption>Diskprices.com FAQ</figcaption></figure><p>Quoting:</p><blockquote>Do you need a graphic designer?<br>No. This site is designed to maximize information density, accessibility, and performance. More whitespace, colors, and icons won't help.</blockquote><p>If the design of the object, service or product is to enable the user, why is it shameful to keep it undecorated?</p><p>Folks at Diskprices.com, if you're reading this, beer is on me if we ever meet.</p>
        </article>
</div></div>]]>
            </description>
            <link>https://neil.computer/notes/the-design-of-diskprices-com/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25235018</guid>
            <pubDate>Sat, 28 Nov 2020 03:31:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Running Python on .NET 5]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25234986">thread link</a>) | @gilad
<br/>
November 27, 2020 | https://tonybaloney.github.io/posts/running-python-on-dotnet-5-with-pyjion.html | <a href="https://web.archive.org/web/*/https://tonybaloney.github.io/posts/running-python-on-dotnet-5-with-pyjion.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
                <p><em>This post is an update on the Pyjion project to plug the .NET 5 CLR JIT compiler into Python 3.9.</em></p>
<p>.NET 5 was released on November 10, 2020. It is the cross-platform and open-source replacement of the <a href="https://github.com/dotnet/core"><strong>.NET Core</strong></a> project and the <strong>.NET</strong> project that ran exclusively on Windows since the late 90’s.</p>
<p>.NET is formed of many components:</p>
<ul>
<li>3 builtin languages, C#, F# and VB.NET, each with its own compiler</li>
<li>A standard library</li>
<li>A common intermediate language to abstract the high level languages from the core runtime. This is a standard known as <a href="https://github.com/tonybaloney/ecma-335/tree/master/docs">ECMA 335 CIL</a>.</li>
<li>A common language runtime (CLR) that compiles CIL into native machine code so that it can be executed and packages executables into .exe formats.</li>
</ul>
<p><img alt=".NET architecture" src="https://tonybaloney.github.io/img/posts/Common_Language_Infrastructure.png"></p>
<p>.NET 5 CLR comes bundled with a performant JIT compiler (codenamed RyuJIT) that will compile .NETs CIL into native machine instructions on Intel x86, x86-64, and ARM CPU architectures.</p>
<p>You can write code in a number of languages, like C++, C#, F# and compile those into CIL and then into native machine code (as a binary executable) on macOS, Linux, and Windows. Pretty neat.</p>
<p>But this is a blog about Python. So what does this have to do with Python?</p>
<p>Pyjion is a project to replace the core execution loop of CPython by transpiling CPython bytecode to ECMA CIL and then using the .NET 5 CLR to compile that into machine code. It then executes the machine-code compiled JIT frames at runtime instead of using the native execution loop of CPython.</p>
<h2>Very-quick overview of Python’s compiler</h2>
<p>When CPython compiles Python code, it compiles it into an intermediate format, similar to .NET, called Python bytecode. This bytecode is cached on disk so that when you import a module that hasn’t changed, it doesn’t compile it every time. You can see the bytecode by disassembling any Python function:</p>
<pre><code>&gt;&gt;&gt; import dis
&gt;&gt;&gt; def half(x):
...    return x/2
... 
&gt;&gt;&gt; dis.dis(half)
  2           0 LOAD_FAST                0 (x)
              2 LOAD_CONST               1 (2)
              4 BINARY_TRUE_DIVIDE
              6 RETURN_VALUE
</code></pre>

<p>To execute anything on a CPU, you have to provide the OS with machine-code instructions. This can be accomplished by compiling them up-front using a compiled like the C or C++ compilers. They compile code into executable formats as either shared libraries or standalone executables. <a href="https://tonybaloney.github.io/posts/extending-python-with-assembly.html"><em>See my post on Python/assembly for a bit more info on this topic</em></a>.</p>
<p>CPython converts the bytecode into machine code instructions like looping over them in a precompiled function, called the evaluation loop. This is essentially a big for loop with a switch statement. The compiled version of CPython that you’re running already has the instructions required. This is why CPython’s evaluation loop is an “AOT”, or “Ahead of Time” compiled library:</p>
<p><img alt="diagram 1" src="https://tonybaloney.github.io/img/posts/Slide1.png"></p>
<p><strong>Note: There is a lot more to CPython’s compiler. I’ve written a <a href="https://realpython.com/products/cpython-internals-book/">whole book on the CPython compiler and the internals of CPython</a> if you want to learn more.</strong></p>
<p>There are a few issues with this approach. The biggest is speed. A series of inline machine-code instructions is very performant. CPython has to make judgements at runtime for which code branch to follow every time your function is run. This leads to CPython being 100x slower in “tight-loop” problems where its executing the same thing again and again. The machine-code is compiled ahead of time and it has to loop around to get to the right instructions. Checkout my PyCon talk for a more in-depth explanation:</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/I4nkgJdVZFA" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<p>The most common way around this performance barrier is to compile Python extensions from C. This produces a custom binary with inline machine-code instructions for the task at hand. This is how most machine-learning and data science libraries like numpy, pandas, SKL are put together. This approach is still AOT compiling the code. It also requires a lot of knowledge of C. This approach has worked really well for the data science community, where algorithms can be performant and leverage low-level platforms <a href="https://numba.pydata.org/numba-doc/latest/cuda/index.html">like GPUs or specialised AI chipsets</a>.</p>
<p>There are a few issues with the AOT extension module approach. One is that it still uses the evaluation loop. C extension modules are a set of functions. Once you call the C-compiled function, its in the performant code, but your Python code that’s calling it still lives inside Python’s loop. If you want to leverage a compiled library and your Python code is doing some heavy number crunching, you end up having to use an API of functions, like numpy, instead of a more fluent Python API:</p>
<pre><code>&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; a = np.ones([9, 5, 7, 4])
&gt;&gt;&gt; c = np.ones([9, 5, 4, 3])
&gt;&gt;&gt; np.dot(a, c).shape
(9, 5, 7, 9, 5, 3)
&gt;&gt;&gt; np.matmul(a, c).shape
(9, 5, 7, 3)
</code></pre>

<h2>What Pyjion does to solve this issue</h2>
<p>A few releases of Python ago (CPython specifically, the most commonly used version of Python) in 3.7 a new API was added to be able to swap out “frame execution” with a replacement implementation. This is otherwise known as <a href="https://www.python.org/dev/peps/pep-0523/">PEP 523</a>. PEP 523 also added the capability to store additional attributes in <em>code objects</em> (compiled Python code.</p>
<p>Pyjion does not compile Python code. It compiles Python frames (code objects, like blocks, functions, methods, classes) into machine-code at runtime using a performant JIT:</p>
<p><img alt="diagram 2" src="https://tonybaloney.github.io/img/posts/Slide2.png"></p>
<p>CPython compiles the Python code, so whatever language features and behaviours there are in CPython 3.9, like the walrus operator, <a href="https://www.python.org/dev/peps/pep-0584">the dictionary union operator</a>, will all work exactly the same with this extension enabled. This also means that this extension uses the same standard library as Python 3.9.</p>
<p>Pyjion is a “pip installable” package for standard CPython that JIT compiles all Python code at runtime using the .NET 5 JIT compiler. You can use off-the-shelf CPython 3.9 on macOS, Linux or Windows. After installing this package you just import the module and enable the JIT.</p>
<p>Once a frame has been compiled, the binary code is cached in memory and reused every time the function is called:</p>
<p><img alt="diagram 3" src="https://tonybaloney.github.io/img/posts/Slide3.png"></p>
<h2>Using Pyjion</h2>
<p>To get started, you need to have .NET 5 installed, with Python 3.9 and the Pyjion package (I also recommend using a virtual environment).</p>
<p>After importing pyjion, enable it by calling <code>pyjion.enable()</code> which sets a compilation threshold to 0 (the code only needs to be run once to be compiled by the JIT):</p>
<pre><code>&gt;&gt;&gt; import pyjion
&gt;&gt;&gt; pyjion.enable()
</code></pre>

<p>Any Python code you define or import after enabling pyjion will be JIT compiled. You don’t need to execute functions in any special API, its completely transparent:</p>
<pre><code>&gt;&gt;&gt; def half(x):
...    return x/2
&gt;&gt;&gt; half(2)
1.0
</code></pre>

<p>Pyjion will have compiled the <code>half</code> function into machine code on-the-fly and stored a cached version of that compiled function inside the function object.
You can see some basic stats by running <code>pyjion.info(f)</code>, where <code>f</code> is the function object:</p>
<pre><code>&gt;&gt;&gt; pyjion.info(half)
{'failed': False, 'compiled': True, 'run_count': 1}
</code></pre>

<p>You can see the machine code for the compiled function by disassembling it in the Python REPL.
Pyjion has essentially compiled your small Python function into a small, standalone application.
Install <code>distorm3</code> first to disassemble x86-64 assembly and run <code>pyjion.dis.dis_native(f)</code>:</p>
<pre><code>&gt;&gt;&gt; import pyjion.dis
&gt;&gt;&gt; pyjion.dis.dis_native(half)
00000000: PUSH RBP
00000001: MOV RBP, RSP
00000004: PUSH R14
00000006: PUSH RBX
00000007: MOV RBX, RSI
0000000a: MOV R14, [RDI+0x40]
0000000e: CALL 0x1b34
00000013: CMP DWORD [RAX+0x30], 0x0
00000017: JZ 0x31
00000019: CMP QWORD [RAX+0x40], 0x0
0000001e: JZ 0x31
00000020: MOV RDI, RAX
00000023: MOV RSI, RBX
00000026: XOR EDX, EDX
00000028: POP RBX
00000029: POP R14
...
</code></pre>

<p>The complex logic of converting a portable instruction set into low-level machine instructions is done by .NET’s CLR JIT compiler.</p>
<p>All Python code executed after the JIT is enabled will be compiled into native machine code at runtime and cached on disk. For example, to enable the JIT on a simple <code>app.py</code> for a Flask web app:</p>
<pre><code>import pyjion
pyjion.enable()

from flask import Flask
app = Flask(__name__)

@app.route('/')
def hello_world():
    return 'Hello, World!'

app.run()
</code></pre>

<p>That’s it.</p>
<h2>Will this be compatible with my existing Python code? What about C Extensions?</h2>
<p>The short answer is- if your existing Python code runs on CPython 3.9 – <strong>yes</strong> it will be compatible. To make sure, Pyjion has been tested against the full CPython “test suite” on all platforms. In fact, it was the first JIT ever to pass the test suite.</p>
<p>Thats because this isn’t a Python runtime, it uses the existing Python compiler to compile your code into Python bytecode (low level instructions).</p>
<p>Pyjion uses the same dynamic module loader as CPython, so if you import a Python extension from your virtual environment, it will work just the same in Pyjion.</p>
<h2>Project History</h2>
<p>Pyjion isn’t new. Brett Cannon and Dino Viehland started the Pyjion project 4 years ago. This was the first JIT to pass the full CPython test suite.
There were some limitations to the original proof-of-concept:</p>
<ul>
<li>Written against an old version of .NET Core</li>
<li>Required custom patches of .NET and compiling from source</li>
<li>Required custom patches of CPython and compiling from source</li>
<li>Only worked on Windows</li>
<li>It was written for Python 3.6 before PEP 523 was agreed and merged</li>
</ul>
<p>Has much changed since Python 3.6? To the average user, not really. But under the hood, the implementation of a few things has completely changed:</p>
<ul>
<li>Function calls</li>
<li>Iterators</li>
<li>Exception Handling</li>
<li>Dictionary, list and set comprehensions</li>
<li>Generators and coroutines</li>
</ul>
<p>Actually, a <strong>lot</strong> has changed in the last few releases of CPython. The new fork to get Pyjion working with the latest version of everything was a big undertaking…</p>
<p><img alt="not-much-has-changed" src="https://tonybaloney.github.io/img/posts-original/not-much-has-changed.png"></p>
<p>The goal with the latest patch was to get the project up to the condition of:</p>
<ul>
<li>Using the release binaries of .NET 5 and CPython 3.9</li>
<li>Making it work across all platforms</li>
<li>Implement the PEP523 interface</li>
<li>Implement all the new features of Python 3.9</li>
<li>Making the package “pip installable” from PyPi</li>
<li>Improving the test coverage</li>
<li>Adding a disassembler (both machine-code and CIL) to aid development</li>
</ul>
<h2>Is this faster?</h2>
<p>The short answer a little, but not by much (yet).</p>
<p>JIT compiling something …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tonybaloney.github.io/posts/running-python-on-dotnet-5-with-pyjion.html">https://tonybaloney.github.io/posts/running-python-on-dotnet-5-with-pyjion.html</a></em></p>]]>
            </description>
            <link>https://tonybaloney.github.io/posts/running-python-on-dotnet-5-with-pyjion.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25234986</guid>
            <pubDate>Sat, 28 Nov 2020 03:25:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Be Resilient]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25234941">thread link</a>) | @Brajeshwar
<br/>
November 27, 2020 | https://psyche.co/guides/resilience-is-like-a-muscle-build-it-up-when-life-pulls-down | <a href="https://web.archive.org/web/*/https://psyche.co/guides/resilience-is-like-a-muscle-build-it-up-when-life-pulls-down">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><h2 data-guide-section-number="1"><span>Need to know</span></h2><div><p>Adversity is everywhere. It can strike when youâ€™re least expecting it, and it might be accompanied by unpleasant, albeit normal, reactions such as anxiety, excessive worry, disappointment, grief, shame, frustration and sadness. Moving on from, and even growing through, a difficult or traumatic experience can be hard, but it <em>is</em> possible.</p>
<p>Iâ€™m sure youâ€™ve already heard, read or witnessed many inspiring stories of people who have bounced back from adversity, such as the death of a loved one, losing a job, serious physical illnesses, accidents, disasters or wars. But what should we do when weâ€™re faced with hardship ourselves? How will we deal with our pain? Can we prepare ourselves for this inevitable experience?</p>
<p>The answers to these questions are not straightforward, but the psychological concept of â€˜resilienceâ€™ can help. Given that weâ€™re all currently in the midst of an adverse situation â€“ the COVID-19 pandemic â€“ understanding resilience is especially pertinent. Resilience is defined as the ability to navigate successfully through, and recover from, stressful circumstances or crisis situations, and to do so in a way that leads to healthy functioning over time. That is, resilience is not only about bouncing back, but also about experiencing some sort of growth, such as finding meaning and purpose, self-awareness or experiencing improvement in interpersonal relationships.</p>
<p>Defining resilience might sound easy, but itâ€™s a more complex concept than you might think. First, many people display resilience immediately following exposure to a hardship or potentially traumatic event. And in the long term, most people who have gone through traumatic experiences donâ€™t show signs of depression or anxiety problems later in life. Consider the <a href="https://journals.sagepub.com/doi/10.1111/j.1467-9280.2006.01682.x" rel="nofollow noreferrer noopener">study</a> of New York residents in the wake of the terrorist attack of <span>11 September</span> 2001: the researchers found that <span>65 per cent</span> of those questioned had returned to their normal level of functioning within six months. You too might be capable of more resilience than you realise.</p>
<p>Second, although some people seem disposed to deal more effectively with stress and anxiety, and to better regulate their emotions, resilience is not a single trait that you either possess or you donâ€™t. Rather, itâ€™s a set of skills, including behaviours and thoughts that can be improved through learning and exposure to new experiences.</p>
<p>Third, although individual characteristics matter for resilience, <a href="https://pubmed.ncbi.nlm.nih.gov/11202047/" rel="nofollow noreferrer noopener">contextual</a> factors also have an influence, such as the social, health and economic resources available to you. For instance, you might be predisposed for resilience but, if you were brought up in an unsupportive and stressful environment by abusive parents, you might not develop it. In fact, as well as being inaccurate, it is unfair and harmful to see resilience purely as an individual trait â€“ people who struggle to recover from a negative life event might think that thereâ€™s something inherently wrong with them, which isnâ€™t true. Access to certain external resources is a major factor in anyoneâ€™s ability to display resilience.</p>
<p>Fourth, resilience is <a href="https://pubmed.ncbi.nlm.nih.gov/22559117/" rel="nofollow noreferrer noopener">dynamic</a>. You can be resilient in one context but then your capacity for resilience, or your ability to draw on available resources, might not be enough for another, possibly more demanding or difficult, situation. All of us can be more resilient at one stage in our lives but less so in another.</p>
<p>Fifth, being resilient doesnâ€™t mean that you wonâ€™t have a wound or a scar. For example, in one <a href="https://pubmed.ncbi.nlm.nih.gov/12416919/" rel="nofollow noreferrer noopener">study</a> of more than 200 people who had experienced the death of their spouse, even those identified as the most resilient reported having at least some grief symptoms. Almost everyone suffers some negative effects, such as emotional strain, throughout the journey of adversity but resilient individuals manage to recover well.</p>
<p>Lastly, it might sound paradoxical, but resilience comes from being in touch with adversity, not from trying to stay positive all the time, or from always running away from difficulties in life. Many of us are taught from an early age that we should avoid difficulties or stress, and itâ€™s true that toxic chronic stress is a <a href="https://pubmed.ncbi.nlm.nih.gov/27417486/" rel="nofollow noreferrer noopener">risk</a> factor for mental health problems. But exposure to some level of stress provides you with the necessary challenge to become stronger in the face of hardship, as long as you learn to cope successfully. By contrast, if youâ€™re overly avoidant of challenges in life then, when an unavoidable hardship arises, you wonâ€™t have developed the necessary skills to cope.</p>
<p>Understanding the complex, dynamic nature of resilience is important because it shows that there is no magic pill or a recipe that will make you resilient. Each individual will have their own way of coping with distress, their own pace of recovery, and levels of learning from a crisis. It is also totally fine to fail to recover quickly or entirely from a particular adversity. Itâ€™s okay to get hurt or lost during a difficult time.</p></div></div></section><section><div><h2 data-guide-section-number="2"><span>What to do</span></h2><div><p>Science doesnâ€™t have all the answers on how one becomes resilient, but what we do know is that it requires learning to tap into both inner and external resources. Iâ€™ll touch on some of the most fundamental ones.</p>
<p><strong>Connect with others</strong></p>
<p>During difficult times, it is common to want to withdraw from the world. This can be for varied reasons, such as feelings of shame, the fear of being judged, or not wishing to be a drain on others. Although there is nothing wrong with wanting solitude during difficult times, it is also important that you stay in touch with people, at least to an extent. <a href="https://pubmed.ncbi.nlm.nih.gov/12555794/" rel="nofollow noreferrer noopener">Research</a> shows that the risk of developing post-traumatic stress disorder is higher for people who lack post-trauma social support (bear in mind that, even if you have friends and family, if you avoid seeing or talking to them entirely, then it will be impossible for them to help you).</p>
<p>People who choose to connect with others and nurture their relationships, as opposed to isolating themselves, tend to become better at coping with a hardship and growing through their experience. The emotional and instrumental social support you get from your intimate relationships, and from your communities, can also give you the motivation to handle stress in a healthy way.</p>
<p>So, when difficulties are overwhelming, try reaching out to others who can provide support. There are a few different ways you could do this. One is simply by talking about what youâ€™re going through. It can be frustrating to talk to someone who just pretends that theyâ€™re listening or who is judgmental, so try to find someone who is accepting and good at listening. You could also try letting them know in advance that all you need is to be listened to. Another approach is to ask specifically for instrumental help, such as information, advice or help with daily tasks. More resilient people are usually aware that they canâ€™t solve every problem on their own. You might find it especially difficult to ask for help if youâ€™re used to handling problems on your own, or if you see relying on others as a sign of weakness. Try to remember that it takes courage to ask for help, and being in need simply means that youâ€™re human.</p>
<p>Here are a few more ideas for how to connect with others and get support: if you exercise or go for a walk, try inviting someone else along. Make a commitment to call or email loved ones regularly. Make use of the power of play â€“ laugh with friends or get silly. If there are social groups that share a common interest or hobby of yours, join them to exchange ideas or to get to know new people. Support others informally or through volunteer organisations; helping others makes us feel happy and valued.</p>
<p>Most importantly, donâ€™t wait for a disaster to occur to connect; make sure you have supportive relationships that nurture your sense of self-worth and need for intimacy, which in turn can contribute to resilience. If youâ€™re physically distant from your loved ones, look for ways to socially connect on a regular basis. Even the presence and support of a small number of people you can rely on can make a huge difference when adversity strikes.</p>
<p><strong>Accept and focus on what you can control</strong></p>
<p>About seven years ago, I was diagnosed with peripheral neuropathy, which is a type of nerve damage. For me, this chronic condition manifests itself as a constant sharp pain and burning sensation on my feet. My life was miserable for six months before the diagnosis, and the pain was unbearable. I could barely walk for five minutes at a time. Upon the diagnosis, I was prescribed medication that eased my pain. Although itâ€™s manageable now, the pain is always there, and Iâ€™ll probably be on medication for the rest of my life. For the first few months, I had difficulty accepting this. Back then, I <span>was 35</span> and had been physically very active before developing this illness. At least a hundred times I asked myself how it was possible. Rejecting and blaming myself, others or the world seemed to provide some relief but it didnâ€™t get me anywhere.</p>
<p>Then one day I decided to stop wrestling with my pain and to start acknowledging it. This didnâ€™t mean that I liked the situation â€“ I hated it â€“ but it provided me with the space to start being proactive and to find effective coping strategies. The more I accepted my situation and my pain, the less pain I felt. A <a href="https://pubmed.ncbi.nlm.nih.gov/16139188/" rel="nofollow noreferrer noopener">study</a> that involved experimentally inducing pain in <span>62 men and</span> women showed the effectiveness of acceptance â€“ those taught acceptance experienced less sensory pain compared with a control group who used simple distraction.</p>
<p>Note that acceptance is not about giving up or quitting. Itâ€™s about gently noticing whatâ€™s going on, and allowing unpleasant experiences to exist, without attempting to change or deny them. With acceptance, you can choose to do what really matters to you and follow your values more easily. In his <a href="https://stevenchayes.com/a-liberated-mind/" rel="nofollow noreferrer noopener">book</a> <em>A Liberated Mind</em> (2019), the American psychologist <a href="https://aeon.co/essays/how-to-live-a-values-driven-life-in-the-face-of-dark-emotions" rel="noopener">Steven Hayes</a>, the founder of <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3635495/" rel="nofollow noreferrer noopener">ACT</a> (acceptance and …</p></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://psyche.co/guides/resilience-is-like-a-muscle-build-it-up-when-life-pulls-down">https://psyche.co/guides/resilience-is-like-a-muscle-build-it-up-when-life-pulls-down</a></em></p>]]>
            </description>
            <link>https://psyche.co/guides/resilience-is-like-a-muscle-build-it-up-when-life-pulls-down</link>
            <guid isPermaLink="false">hacker-news-small-sites-25234941</guid>
            <pubDate>Sat, 28 Nov 2020 03:16:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Type Theory and Applications [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25234780">thread link</a>) | @azhenley
<br/>
November 27, 2020 | https://metatheorem.org/includes/pubs/comp.pdf | <a href="https://web.archive.org/web/*/https://metatheorem.org/includes/pubs/comp.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://metatheorem.org/includes/pubs/comp.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25234780</guid>
            <pubDate>Sat, 28 Nov 2020 02:47:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Link Between Curiosity and Creativity]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25234758">thread link</a>) | @dbustac
<br/>
November 27, 2020 | https://danielbusta.com/link/ | <a href="https://web.archive.org/web/*/https://danielbusta.com/link/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-177">

	
<!-- .entry-header -->

	<div>

		<div>

			
<figure><img loading="lazy" width="580" height="387" src="https://i1.wp.com/danielbusta.com/wp-content/uploads/2020/11/photo-1585986675915-8291caac4f03_ixlibrb-1.2.jpg?resize=580%2C387&amp;ssl=1" alt="" srcset="https://i1.wp.com/danielbusta.com/wp-content/uploads/2020/11/photo-1585986675915-8291caac4f03_ixlibrb-1.2.jpg?resize=1024%2C683&amp;ssl=1 1024w, https://i1.wp.com/danielbusta.com/wp-content/uploads/2020/11/photo-1585986675915-8291caac4f03_ixlibrb-1.2.jpg?resize=300%2C200&amp;ssl=1 300w, https://i1.wp.com/danielbusta.com/wp-content/uploads/2020/11/photo-1585986675915-8291caac4f03_ixlibrb-1.2.jpg?resize=768%2C512&amp;ssl=1 768w, https://i1.wp.com/danielbusta.com/wp-content/uploads/2020/11/photo-1585986675915-8291caac4f03_ixlibrb-1.2.jpg?w=1051&amp;ssl=1 1051w" sizes="(max-width: 580px) 100vw, 580px" data-recalc-dims="1"><figcaption><em>Picture by <a href="https://unsplash.com/@markusspiske" target="_blank" rel="noreferrer noopener">@markusspiske</a></em></figcaption></figure>



<p>There seems to be a strong, almost causal relationship between curiosity and creativity.</p>



<p>My hypothesis is that curious people constantly do three things that are essential for the creative process: exploring, observing and asking questions.</p>



<p><strong>Curious individuals are interested in nearly everything.</strong></p>



<p>They’re always learning about and exploring new subjects. As a result, they hold in their heads a wide-ranging reservoir of information and mental models. This allows them to cross-pollinate ideas, extrapolate concepts and make unexpected connections.</p>



<p><strong>Another thing they’re very good at is observing.&nbsp;</strong></p>



<p>Curious people tend to go through life at a different pace than everyone else. They move relatively slowly. And whenever something catches their attention, they stop to contemplate it. Their ability to look extensively at and into things allows them to unveil patterns that most people are too busy to see.</p>



<p><strong>Finally, curious people like to ask tons of questions.</strong></p>



<p>As everything else, questions are subject to probabilities — the more questions you ask, the higher your chances of asking a good question. Good questions, in turn, help them find things that don’t work or don’t make sense. Thus, opening the doors for breakthroughs and innovation.</p>



<p>By giving yourself permission to cultivate curiosity, you’re also laying the foundation for a prolific, creative life.</p>


<p><em>This piece is part of a series of 30 atomic essays where I explore what it means to be a&nbsp;<a href="https://rationalcreatives.substack.com/" target="_blank" rel="noreferrer noopener">rational creative</a>&nbsp;and the different aspects of being a creator online. You can read all the others essays&nbsp;<a href="https://twitter.com/dbustac/status/1328419048070279174?s=20" target="_blank" rel="noreferrer noopener">here</a>.</em></p>
		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
		<!-- .comments-wrapper -->

		
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://danielbusta.com/link/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25234758</guid>
            <pubDate>Sat, 28 Nov 2020 02:44:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Parsing All of Wikipedia to an Offline Encyclopedia]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25234490">thread link</a>) | @miles
<br/>
November 27, 2020 | https://daveshap.github.io/DavidShapiroBlog/automation/2020/11/15/parsing-all-wikipedia.html | <a href="https://web.archive.org/web/*/https://daveshap.github.io/DavidShapiroBlog/automation/2020/11/15/parsing-all-wikipedia.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://daveshap.github.io/DavidShapiroBlog/automation/2020/11/15/parsing-all-wikipedia.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25234490</guid>
            <pubDate>Sat, 28 Nov 2020 02:03:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Secure, Redundant DNS Using CoreDNS]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25234382">thread link</a>) | @m_sahaf
<br/>
November 27, 2020 | https://www.caffeinatedwonders.com/2020/11/27/secure-dns-proxy/ | <a href="https://web.archive.org/web/*/https://www.caffeinatedwonders.com/2020/11/27/secure-dns-proxy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
        


    
    <p><time>November 27, 2020</time></p><div>
        <p>Although <a href="https://transparencyreport.google.com/https/overview?hl=en&amp;time_os_region=chrome-usage:1;series:time;groupby:os&amp;lu=load_os_region&amp;load_os_region=chrome-usage:1;series:page-load;groupby:os">an increasing portion of the web is adopting HTTPS</a>, a core part of the web infrastrcture lags behind in the form of plaintext DNS. The authentication problem of DNS is resolved by DNSSEC, but the queries are still plaintext. There’s currently a number of competing solutions that offer both authenticity and privacy concerns, namely DNS-over-TLS, DNS-over-HTTPS, and <a href="https://dnscrypt.info/">DNSCrypt</a>. I’ll leave it to Cloudflare’s blog to explain DNS, DoT and DoH, and the work towards both: <a href="https://blog.cloudflare.com/dns-encryption-explained/">DNS Encryption Explained</a>. Due to operating systems not yet supporting encrypted DNS resolvers, some work needs to be done by the user, and this post describes part of the work using <a href="https://coredns.io/">CoreDNS</a>.</p>
<p>CoreDNS is pluggable DNS and service discovery server written in Go and the blessed DNS resolver of Kubernetes. Configuring CoreDNS is handled via setting up a series of <a href="https://coredns.io/plugins/">middlewares</a> in the Corefile, which is what its config file is called. The <a href="https://coredns.io/manual/toc/">CoreDNS Manual</a> page does a brilliant job describing what CoreDNS is, how it works, how to install it, the structure of the configuration file, and more. To build our secure resolver, let’s pick up one of the examples off that page and gradually build the enhanced version.</p>
<p>Start by creating a file named <code>Corefile</code> containing the following, which is lifted verbatim from CoreDNS website:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span></code></pre></td>
<td>
<pre><code data-lang="caddyfile"><span>.</span> <span>{</span>
    <span>forward</span> <span>.</span> <span>8</span><span>.8.8.8</span> <span>9</span><span>.9.9.9</span>
    <span>log</span>
<span>}</span>
</code></pre></td></tr></tbody></table>
</div>
</div><p>This is very simple, but let’s break it apart. The <code>.</code> means listen on port 53, the default port for UDP DNS, and across all interfaces. The configuration instructs CoreDNS to forward all requests to either <code>8.8.8.8</code> (Google DNS) or <code>9.9.9.9</code> (Quad9), picking either of them at random, and logs everything to stdout. This is not secure yet. This setup will forward all DNS queries in plaintext UDP packets. Let’s start by forwarding everything to <a href="https://developers.google.com/speed/public-dns/docs/dns-over-tls">Google DNS over TLS</a> resolvers without fallback:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span><span>7
</span><span>8
</span></code></pre></td>
<td>
<pre><code data-lang="caddyfile"><span>.</span> <span>{</span>
    <span>forward</span> <span>.</span> <span>tls://8.8.8.8</span> <span>tls://8.8.4.4</span> <span>{</span><span>
</span><span>		# This tells CoreDNS the subject name
</span><span>		# on the certificate is: dns.google
</span><span></span>		<span>tls_servername</span> <span>dns.google</span>
	<span>}</span>
    <span>log</span>
<span>}</span>
</code></pre></td></tr></tbody></table>
</div>
</div><p>At this point the setup has redundancy against Google’s services only. What if Google DNS service is down? The possibiity of a service going down is not far fetched, and we must account for it. However, note how the <code>tls_servername</code> directive can only be defined once, so it is bound to whatever upstream IP address we’re using. We can get around this by breaking the upstream into more local resolvers. I’ll add Cloudflare DNS as backup:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span></code></pre></td>
<td>
<pre><code data-lang="caddyfile"><span>.:53</span> <span>{</span>
	<span>forward</span> <span>.</span> <span>127.0.0.1</span><span>:</span><span>5301</span> <span>127.0.0.1</span><span>:</span><span>5302</span> <span>[</span><span>::1</span><span>]</span><span>:5301</span> <span>[</span><span>::1</span><span>]</span><span>:5302</span>
	<span>log</span>
<span>}</span>
<span>.:5301</span> <span>{</span>
	<span>forward</span> <span>.</span> <span>tls://8.8.8.8</span> <span>tls://8.8.4.4</span> <span>{</span>
		<span>tls_servername</span> <span>dns.google</span>
	<span>}</span>
<span>}</span>
<span>.:5302</span> <span>{</span>
	<span>forward</span> <span>.</span> <span>tls://1.1.1.1</span> <span>tls://1.0.0.1</span> <span>{</span>
		<span>tls_servername</span> <span>cloudflare-dns.com</span>
	<span>}</span>
<span>}</span>
</code></pre></td></tr></tbody></table>
</div>
</div><p>Now we have established the pattern. To add more backups, add more server blocks where the upstream is defined and the respective <code>tls_servername</code> is configured, and add the localhost IP address to the main server of <code>.:53</code>. This can be further enhanced by adding caching, prefetching, and loading the <code>hosts</code> file. The final setup will look like this:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span><span>16
</span><span>17
</span><span>18
</span><span>19
</span><span>20
</span><span>21
</span><span>22
</span><span>23
</span><span>24
</span><span>25
</span><span>26
</span><span>27
</span><span>28
</span></code></pre></td>
<td>
<pre><code data-lang="caddyfile"><span>.:53</span> <span>{</span>
	<span>hosts</span> <span>/path/to/hosts</span> <span>{</span>
		<span>fallthrough</span>
	<span>}</span>
	<span>cache</span> <span>{</span>
		<span>prefetch</span> <span>2</span> <span>30m</span>
	<span>}</span>
	<span>forward</span> <span>.</span> <span>127.0.0.1</span><span>:</span><span>5301</span> <span>127.0.0.1</span><span>:</span><span>5302</span> <span>[</span><span>::1</span><span>]</span><span>:5301</span> <span>[</span><span>::1</span><span>]</span><span>:5302</span> <span>127.0.0.1</span><span>:</span><span>5303</span> <span>[</span><span>::1</span><span>]</span><span>:5303</span> <span>{</span>
		<span>policy</span> <span>random</span>
	<span>}</span>
<span>}</span>
<span>.:5301</span> <span>{</span>
	<span>forward</span> <span>.</span> <span>tls://8.8.8.8</span> <span>tls://8.8.4.4</span> <span>{</span>
		<span>tls_servername</span> <span>dns.google</span>
	<span>}</span>
<span>}</span>
<span>.:5302</span> <span>{</span>
	<span>forward</span> <span>.</span> <span>tls://1.1.1.1</span> <span>tls://1.0.0.1</span> <span>{</span>
		<span>tls_servername</span> <span>cloudflare-dns.com</span>
	<span>}</span>
<span>}</span>
<span>.:5303</span> <span>{</span>
	<span>cache</span>
	<span>forward</span> <span>.</span> <span>tls://9.9.9.9</span> <span>{</span>
		<span>tls_servername</span> <span>dns.quad9.net</span>
	<span>}</span>
<span>}</span>

</code></pre></td></tr></tbody></table>
</div>
</div><p>Note that <code>policy</code> directive added in the first server block. Using <code>random</code> is superfluous because it is the default policy. The other policies available are <code>sequential</code> and <code>round_robin</code>. Regardless of the configured policy, CoreDNS will still perform health-checks and use a healthy upstream, so your queries are still answered even if one Google and/or Cloudflare are down. Configure your operating system to use your loopback address as the DNS server, set up CoreDNS service to start at boot, and your DNS queries are secure going forward.</p>

        
    </div>
    

    

    


        
        </div></div>]]>
            </description>
            <link>https://www.caffeinatedwonders.com/2020/11/27/secure-dns-proxy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25234382</guid>
            <pubDate>Sat, 28 Nov 2020 01:44:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Textbook Recommendations for Software Engineers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25234227">thread link</a>) | @victorbreder
<br/>
November 27, 2020 | https://breder.org/5/ | <a href="https://web.archive.org/web/*/https://breder.org/5/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://breder.org/5/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25234227</guid>
            <pubDate>Sat, 28 Nov 2020 01:16:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MmWave vs. Sub-6 GHz 5G – What’s the Difference?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25233982">thread link</a>) | @elephd
<br/>
November 27, 2020 | https://www.onesdr.com/2020/11/19/mmwave-vs-sub-6-ghz-5g-whats-the-difference/#more-1996 | <a href="https://web.archive.org/web/*/https://www.onesdr.com/2020/11/19/mmwave-vs-sub-6-ghz-5g-whats-the-difference/#more-1996">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
			
<p>For the past few years we’ve been hearing about mmWave 5G and now, in 2020 it’s finally here! mmWave 5G promises amazing speeds of 10 Gigabits/second, very low latency of around 1 millisecond, and many other amazing features. It currently operates in the frequency range between 24 GHz and 40 GHz. </p>



<p>Verizon has deployed this technology in many major cities across the USA. Here is a map that shows Verizon’s mmWave or <a rel="noreferrer noopener" href="https://www.verizon.com/about/news/fastest-5g-network-world-just-got-bigger-and-better" target="_blank">Ultra Wideband 5G</a> deployments.  </p>







<figure><img loading="lazy" width="1024" height="399" src="https://www.onesdr.com/wp-content/uploads/2020/11/Verizon-5G-1024x399.png" alt="" srcset="https://www.onesdr.com/wp-content/uploads/2020/11/Verizon-5G-1024x399.png 1024w, https://www.onesdr.com/wp-content/uploads/2020/11/Verizon-5G-300x117.png 300w, https://www.onesdr.com/wp-content/uploads/2020/11/Verizon-5G-768x299.png 768w, https://www.onesdr.com/wp-content/uploads/2020/11/Verizon-5G-1536x598.png 1536w, https://www.onesdr.com/wp-content/uploads/2020/11/Verizon-5G.png 2031w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>mmWave 5G or 5G Ultra Wideband deployments in USA</figcaption></figure>



<p>While mmWave 5G deployments have been limited to date, they will grow over time. Verizon will also be deploying Sub-6 GHz 5G networks this year. As the name suggests these networks will be deployed at frequencies below 6 GHz. </p>



<p>In 2020 we have also seen many new 5G phones – some of which <a href="https://amzn.to/3ffJ30C">support mmWave</a> and <a href="https://amzn.to/3923Cwy">others that don’t</a>.</p>



<h4><strong>The biggest differences between mmWave 5G and all other wireless systems</strong></h4>



<p>As the name suggests, mmWave 5G operates at mmWave frequencies starting at 24 GHz. Why do we need to move to mmWave frequencies? To support higher upload and download speeds we need more bandwidth. A single channel of mmWave 5G can be 400 MHz wide. That large amount of contiguous bandwidth is simply not available at lower frequencies as almost all the spectrum has already been allocated for other applications. </p>



<p>The picture below shows the bandwidth of 5G systems relative to other cellular technologies. </p>



<div><figure><img loading="lazy" src="https://www.onesdr.com/wp-content/uploads/2020/11/2g3g4g5g-bandwidths-1024x236.png" alt="" width="690" height="159" srcset="https://www.onesdr.com/wp-content/uploads/2020/11/2g3g4g5g-bandwidths-1024x236.png 1024w, https://www.onesdr.com/wp-content/uploads/2020/11/2g3g4g5g-bandwidths-300x69.png 300w, https://www.onesdr.com/wp-content/uploads/2020/11/2g3g4g5g-bandwidths-768x177.png 768w, https://www.onesdr.com/wp-content/uploads/2020/11/2g3g4g5g-bandwidths.png 1446w" sizes="(max-width: 690px) 100vw, 690px"><figcaption>Bandwidths of cellular technologies</figcaption></figure></div>



<p>The maximum bandwidth of 5G is 20 times larger than the maximum bandwidth of a 4G signal. That makes sense when you compare the theoretical maximum achievable speed of a 4G network at 300 Mbps with that of a 5G network at 10,000 Mbps.  </p>



<h4><strong><span>Let’s now take a look at some of the major RF related challenges with mmWave 5G relative to previous generations of wireless systems</span></strong></h4>



<h3><strong>Radio Signals in the Real World</strong></h3>



<p>To put things in context, we have never operated our cellular communication systems at mmWave frequencies. The highest we have operated at is around 2 GHz for 4G systems and 6 GHz for Wi-Fi systems.</p>



<div><figure><img loading="lazy" src="https://www.onesdr.com/wp-content/uploads/2020/11/frequency-ranges-1024x576.png" alt="" width="669" height="376" srcset="https://www.onesdr.com/wp-content/uploads/2020/11/frequency-ranges-1024x576.png 1024w, https://www.onesdr.com/wp-content/uploads/2020/11/frequency-ranges-300x169.png 300w, https://www.onesdr.com/wp-content/uploads/2020/11/frequency-ranges-768x432.png 768w, https://www.onesdr.com/wp-content/uploads/2020/11/frequency-ranges-1536x864.png 1536w, https://www.onesdr.com/wp-content/uploads/2020/11/frequency-ranges.png 1600w" sizes="(max-width: 669px) 100vw, 669px"><figcaption>Frequency ranges for different wireless technologies</figcaption></figure></div>



<p>The only wireless systems we have implemented at mmWave frequencies are point-to-point, line-of-sight links. We will, for the first time ever, have to deal with operating in challenging mmWave RF environments. </p>



<p>What does that mean?</p>



<p>mmWave signals don’t propagate very far. They are in fact obstructed by even the smallest of objects on account of their small wavelength. Trees, buildings, moisture – all affect mmWave signal propagation. As a result, cities and suburbs are very challenging environments from a mmWave perspective. </p>



<div><figure><img loading="lazy" width="1024" height="576" src="https://www.onesdr.com/wp-content/uploads/2020/11/objects-that-affect-5G-1024x576.png" alt="" srcset="https://www.onesdr.com/wp-content/uploads/2020/11/objects-that-affect-5G-1024x576.png 1024w, https://www.onesdr.com/wp-content/uploads/2020/11/objects-that-affect-5G-300x169.png 300w, https://www.onesdr.com/wp-content/uploads/2020/11/objects-that-affect-5G-768x432.png 768w, https://www.onesdr.com/wp-content/uploads/2020/11/objects-that-affect-5G-1536x864.png 1536w, https://www.onesdr.com/wp-content/uploads/2020/11/objects-that-affect-5G.png 1600w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Things that affect mmWave 5G signals</figcaption></figure></div>



<p>So how do we propose to solve the problem? The plan is to deploy about five times as many 5G base stations as with 4G and to use a technology called beamforming. As the name suggests this focuses RF energy beams in specific directions – toward users in particular. </p>



<p>However there still remains the fact that we have a relatively poor understanding of how exactly RF behaves at these frequencies in city environments where things change fast. Buildings and other structures appear relatively quickly and sometimes unexpectedly. The behavior of RF signals will then change accordingly and often unpredictably.</p>



<p>Unlike with previous systems operating at 2 GHz, we have not had the benefit of four decades of research and development. We have barely had two years to develop an understanding of how mmWave will work.</p>



<h3><strong>Complex Phone Development</strong></h3>



<p>The average phone today has multiple wireless sub-systems operating in it. Everything from 2G to 4G with Wi-Fi, Bluetooth, NFC and sometimes even FM. In small cell phone dimensions this is potentially chaos from an RF standpoint with signals interfering with one another. Increased power consumption of mmWave components is another significant issue as it results in more heat dissipation and lower battery life.</p>



<div><figure><img loading="lazy" src="https://www.onesdr.com/wp-content/uploads/2020/11/phone-with-multiple-standards.png" alt="" width="332" height="373" srcset="https://www.onesdr.com/wp-content/uploads/2020/11/phone-with-multiple-standards.png 703w, https://www.onesdr.com/wp-content/uploads/2020/11/phone-with-multiple-standards-267x300.png 267w" sizes="(max-width: 332px) 100vw, 332px"><figcaption>Different wireless technologies in a phone today</figcaption></figure></div>



<h3><strong>Higher Build and Development Costs</strong></h3>



<p>mmWave phones have multiple RF antenna modules designed to improve signal reception – a complex task without a doubt. Each of these has its own amplification, power management and transceiver. This complexity adds to the cost of hardware and results in a factor of <a href="https://benchmarking.ihsmarkit.com/614670/the-first-5g-phone-in-the-united-states-is-a-compromise-of-cost-and-design-ihs-markit-says" target="_blank" rel="noreferrer noopener">three times higher</a> relative to the average 4G smartphone.</p>



<p><a href=""></a>What about testing mmWave phones on the manufacturing floor? As mentioned earlier, most of our wireless communication systems have been operating below 2 GHz. Even when you consider Wi-Fi, we don’t get any higher than 6 GHz. There are a number of RF testing products such as <a href="https://amzn.to/3fg0luz">spectrum analyzers </a>and <a href="https://amzn.to/2UFEG5N">signal generators</a> that operate up to 6 GHz. They are not very expensive. 5G mmWave however requires test equipment that has to cover 40 GHz at least. Such equipment can cost as much as $100,000 or more. Not very affordable at all.</p>



<h2><strong>Summary</strong></h2>



<p>In this post we have talked about some of the RF challenges that we need to overcome to make mmWave 5G a success. We provided an overview of about three broad areas: RF propagation, Phone hardware and Development costs. The challenges in each of these areas are very daunting but exciting at the same time.</p>



<p><a href="https://www.onesdr.com/2020/09/27/how-to-measure-5g-radiation/">Read our post on how to measure 5G radiation</a></p>



<figure><img loading="lazy" width="1024" height="146" src="https://www.onesdr.com/wp-content/uploads/2020/02/mailing-list-2-1024x146.png" alt="Mailing List" srcset="https://www.onesdr.com/wp-content/uploads/2020/02/mailing-list-2-1024x146.png 1024w, https://www.onesdr.com/wp-content/uploads/2020/02/mailing-list-2-300x43.png 300w, https://www.onesdr.com/wp-content/uploads/2020/02/mailing-list-2-768x110.png 768w, https://www.onesdr.com/wp-content/uploads/2020/02/mailing-list-2-1536x220.png 1536w, https://www.onesdr.com/wp-content/uploads/2020/02/mailing-list-2.png 2000w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



	<div data-blog-id="171021735">
		<div>
			<form aria-describedby="wp-block-jetpack-mailchimp_consent-text">
				
												

				<p id="wp-block-jetpack-mailchimp_consent-text">
					<br>_________________________________________________<br>Icons made by&nbsp;<a href="https://www.flaticon.com/authors/freepik" target="_blank" rel="noreferrer noopener">Freepik</a>&nbsp;from&nbsp;<a href="https://www.flaticon.com/" target="_blank" rel="noreferrer noopener">www.flaticon.com</a> 				</p>

				
			</form>
			
				<p>
					Processing…				</p>
				<p>
					Success! You're on the list.				</p>
				<p>
					Whoops! There was an error and we couldn't process your subscription. Please reload the page and try again.				</p>

					</div>
	</div>
	











		</div></div>]]>
            </description>
            <link>https://www.onesdr.com/2020/11/19/mmwave-vs-sub-6-ghz-5g-whats-the-difference/#more-1996</link>
            <guid isPermaLink="false">hacker-news-small-sites-25233982</guid>
            <pubDate>Sat, 28 Nov 2020 00:38:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bullshit Release Notes]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25233944">thread link</a>) | @neilpanchal
<br/>
November 27, 2020 | https://neil.computer/notes/bullshit-release-notes/ | <a href="https://web.archive.org/web/*/https://neil.computer/notes/bullshit-release-notes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    
<header>
    
</header>
        <!--Display single note. This template is dispatched by post.hbs-->
<main>
        <article>
        <h2>Bullshit Release Notes</h2>
        <figure><img src="https://neil.computer/content/images/2020/11/slack-update.png" alt="Recent Slack Update - Release Notes" srcset="https://neil.computer/content/images/size/w600/2020/11/slack-update.png 600w, https://neil.computer/content/images/size/w1000/2020/11/slack-update.png 1000w, https://neil.computer/content/images/size/w1600/2020/11/slack-update.png 1600w, https://neil.computer/content/images/2020/11/slack-update.png 1844w" sizes="(min-width: 720px) 720px"><figcaption>Recent Slack Update - Release Notes</figcaption></figure><blockquote>We've tinkered with the internal workings and polished some rough edges. The app is now better than it was.</blockquote><p>How about actually telling us what changed? This is a common practice in already hostile iOS and macOS App stores.</p><p>One or more of the following is true:</p><ul><li>Developers who build these apps are lazy and negligent</li><li>Lawyers have advised not to publish release notes with updates as a way to protect the company from liability</li><li>We must &nbsp;hide "technical" information that might overwhelm our users</li></ul><p>First one, I do not believe can be true. Developers generally want to keep track of what they did and they would already have this information in their PRs/repos. </p><p>Second, I think this is plausible but then again, the EULA says you can't sue the company for breaking something.</p><p>Third - this is the most likely reason. Why are we treating the general public like they're too afraid of complexity? It's not like the release notes make people nervous or fatigued. It is <em>optional</em> to read. It's tucked away.</p><p>I've had a number of paid apps that have gone downhill since and are no longer usable. They've incrementally degraded the experience <em>without informing the user. </em>I am left with a tough choice - never update the app or take a chance.</p><p>This practice needs to stop, I don't see why release notes cannot be part of a massive publicly traded company and the software being used by millions of people.</p>
        </article>
</main>
<p>
    <a href="https://neil.computer/">← Back to Home</a>
</p>

    


    

</div>]]>
            </description>
            <link>https://neil.computer/notes/bullshit-release-notes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25233944</guid>
            <pubDate>Sat, 28 Nov 2020 00:31:13 GMT</pubDate>
        </item>
    </channel>
</rss>
