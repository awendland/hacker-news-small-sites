<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Tue, 21 Jul 2020 12:21:25 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Tue, 21 Jul 2020 12:21:25 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Optimizing 128-bit Division]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 3 (<a href="https://news.ycombinator.com/item?id=23888177">thread link</a>) | @EvgeniyZh
<br/>
July 19, 2020 | https://danlark.org/2020/06/14/128-bit-division/ | <a href="https://web.archive.org/web/*/https://danlark.org/2020/06/14/128-bit-division/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-288">

	

	
	<div>
		
<p>When it comes to hashing, sometimes 64 bit is not enough, for example, because of <a href="https://en.wikipedia.org/wiki/Birthday_problem">birthday paradox</a> — the hacker can iterate through random <img src="https://s0.wp.com/latex.php?latex=2%5E%7B32%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="2^{32}" title="2^{32}"> entities and it can be proven that with some constant probability they will find a collision, i.e. two different objects will have the same hash. <img src="https://s0.wp.com/latex.php?latex=2%5E%7B32%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="2^{32}" title="2^{32}"> is around 4 billion objects and with the current power capacity in each computer it is certainly achievable. That’s why we need sometimes to advance the bitness of hashing to at least 128 bits. Unfortunately, it comes with a cost because platforms and CPUs do not support 128 bit operations natively.</p>



<p>Division historically is the most complex operation on CPUs and all guidelines suggest avoiding the division at all costs.</p>



<p>At my job I faced an interesting problem of optimizing 128 bit division from <a href="https://github.com/abseil/abseil-cpp/blob/master/absl/numeric/int128.cc#L155">abseil library</a> in order to split some data across buckets with the help of 128 bit hashing (the number of buckets is not fixed for some uninteresting historical reasons). I found out that the division takes a really long time. The <a href="https://github.com/abseil/abseil-cpp/blob/master/absl/numeric/int128_benchmark.cc#L52">benchmarks</a> from abseil on Intel(R) Xeon(R) W-2135 CPU @ 3.70GHz show some horrible results</p>



<pre><code>Benchmark                       Time(ns)  CPU(ns)
BM_DivideClass128UniformDivisor     13.8     13.8  // 128 bit by 128 bit
BM_DivideClass128SmallDivisor        168      168  // 128 bit by 64 bit</code></pre>



<p>150 nanoseconds for dividing the random 128 bit number by a random 64 bit number? Sounds crazy. For example, <code>div</code> instruction on x86-64 Skylake takes 76 cycles (also, for AMD processors it is much less), the division takes around 20-22ns.</p>



<figure><img data-attachment-id="361" data-permalink="https://danlark.org/d2elnjfdkne/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/d2elnjfdkne.png" data-orig-size="921,461" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="d2elnjfdkne" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/d2elnjfdkne.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/d2elnjfdkne.png?w=750" src="https://danlarkorg.files.wordpress.com/2020/06/d2elnjfdkne.png?w=921" alt="" srcset="https://danlarkorg.files.wordpress.com/2020/06/d2elnjfdkne.png 921w, https://danlarkorg.files.wordpress.com/2020/06/d2elnjfdkne.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/06/d2elnjfdkne.png?w=300 300w, https://danlarkorg.files.wordpress.com/2020/06/d2elnjfdkne.png?w=768 768w" sizes="(max-width: 921px) 100vw, 921px"><figcaption><a href="https://godbolt.org/z/o2vTZr">https://godbolt.org/z/o2vTZr</a></figcaption></figure>



<p>In reality everything is slightly better because of pipeline execution and division has its own ALU, so if you divide something and do something else in the next instructions, you will get lower average latency. Still, 128 bit division cannot be 8x slower than 64 bit division. All latencies you can find in Agner Fog <a href="https://www.agner.org/optimize/instruction_tables.pdf">instruction table</a> for most of the modern x86 CPUs. The truth is more complex and division latency can even depend on the values given.</p>



<figure><img data-attachment-id="299" data-permalink="https://danlark.org/2020-06-14-182043_835x215_scrot/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-182043_835x215_scrot.png" data-orig-size="835,215" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020-06-14-182043_835x215_scrot" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-182043_835x215_scrot.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-182043_835x215_scrot.png?w=750" src="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-182043_835x215_scrot.png?w=835" alt="" srcset="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-182043_835x215_scrot.png 835w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-182043_835x215_scrot.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-182043_835x215_scrot.png?w=300 300w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-182043_835x215_scrot.png?w=768 768w" sizes="(max-width: 835px) 100vw, 835px"><figcaption>Agner Fog instruction table for Skylake CPUs, the second but last column is the latency.</figcaption></figure>



<p>Even compilers when dividing by some constants, try to use the reciprocal (or, the same as inverse in a ring) value and multiply the reciprocal and the value with some shifts afterwards</p>



<figure><img data-attachment-id="315" data-permalink="https://danlark.org/2020-06-14-192300_861x251_scrot/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-192300_861x251_scrot.png" data-orig-size="861,251" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020-06-14-192300_861x251_scrot" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-192300_861x251_scrot.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-192300_861x251_scrot.png?w=750" src="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-192300_861x251_scrot.png?w=861" alt="" srcset="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-192300_861x251_scrot.png 861w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-192300_861x251_scrot.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-192300_861x251_scrot.png?w=300 300w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-192300_861x251_scrot.png?w=768 768w" sizes="(max-width: 861px) 100vw, 861px"><figcaption><a href="https://gcc.godbolt.org/z/PRibsx">https://gcc.godbolt.org/z/PRibsx</a></figcaption></figure>



<p>Overall, given the fact that only some <code>sin</code>, <code>cos</code> instructions cost more than division, division is one of the most complex instructions in CPUs and optimizations in that place matter a lot. My exact case was more or less general, maybe I was dividing 128 bit by 64 bit a bit more frequent. We are going to optimize the general case in LLVM.</p>



<p>We need to understand how 128 bit division is working through the compiler stack.</p>



<figure><img data-attachment-id="303" data-permalink="https://danlark.org/2020-06-14-183125_682x238_scrot/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-183125_682x238_scrot.png" data-orig-size="682,238" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020-06-14-183125_682x238_scrot" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-183125_682x238_scrot.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-183125_682x238_scrot.png?w=682" src="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-183125_682x238_scrot.png?w=682" alt="" srcset="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-183125_682x238_scrot.png 682w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-183125_682x238_scrot.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-183125_682x238_scrot.png?w=300 300w" sizes="(max-width: 682px) 100vw, 682px"><figcaption><a href="https://gcc.godbolt.org/z/fB3aq2">https://gcc.godbolt.org/z/fB3aq2</a></figcaption></figure>



<p>It calls <code>__udivti3</code> function. Let’s first understand how to read these functions. In runtime libraries the modes of the functions are:</p>



<div><div>
<pre><code>QI: An integer that is as wide as the smallest addressable unit, usually 8 bits.
HI: An integer, twice as wide as a QI mode integer, usually 16 bits.
SI: An integer, four times as wide as a QI mode integer, usually 32 bits.
DI: An integer, eight times as wide as a QI mode integer, usually 64 bits.
SF: A floating point value, as wide as a SI mode integer, usually 32 bits.
DF: A floating point value, as wide as a DI mode integer, usually 64 bits.
TI: An integer, 16 times as wide as a QI mode integer, usually 128 bits.</code></pre>
</div></div>



<p>So, <code>udivti3</code> is an <strong>u</strong>nsigned division of TI (128 bits) integers, last ‘<em>3′</em> means that it has 3 arguments including the return value. Also, there is a function <code>__udivmodti4</code> which computes the divisor and the remainder (division and modulo operation) and it has 4 arguments including the returning value. These functions are a part of runtime libraries which compilers provide by default. For example, in GCC it is <a href="http://gcc.gnu.org/onlinedocs/gccint/Libgcc.html#Libgcc">libgcc</a>, in LLVM it is <a href="https://compiler-rt.llvm.org/">compiler-rt</a>, they are linked almost in every program if you have the corresponding toolchain. In LLVM, <code>__udivti3</code> is a simple alias to <code>__udivmodti4</code>.</p>



<figure><div>

</div></figure>



<p><code><a href="https://github.com/llvm-mirror/compiler-rt/blob/release_90/lib/builtins/udivmodti4.c#L20">__udivmodti4</a></code> function was written with the help of <code>Translated from Figure 3-40 of The PowerPC Compiler Writer's Guide.</code> After looking at it <a href="https://cr.yp.to/2005-590/powerpc-cwg.pdf">here</a>, it looks like this was written long time ago and things have changed since then</p>



<figure><img data-attachment-id="313" data-permalink="https://danlark.org/2020-06-14-191400_1038x718_scrot/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png" data-orig-size="1038,718" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020-06-14-191400_1038x718_scrot" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png?w=750" src="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png?w=1024" alt="" srcset="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png?w=1024 1024w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png?w=300 300w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png?w=768 768w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png 1038w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>First of all, let’s come up with something easy, like shift-subtract algorithm that we have been learning since childhood. First, if <code>divisor &gt; dividend</code>, then the quotient is zero and remainder is the <code>dividend</code>, not an interesting case. </p>



<figure><div>

</div></figure>



<p>The algorithm is easy, we align the numbers by their most significant bits, if dividend is more than divisor, subtract and add 1 to the output, then shift by 1 and repeat.  Some sort of animation can be seen like that:</p>



<figure><img data-attachment-id="318" data-permalink="https://danlark.org/simplescreenrecorder-2020-06-14_20-23-25/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/simplescreenrecorder-2020-06-14_20.23.25.gif" data-orig-size="918,442" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="simplescreenrecorder-2020-06-14_20.23.25" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/simplescreenrecorder-2020-06-14_20.23.25.gif?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/simplescreenrecorder-2020-06-14_20.23.25.gif?w=750" src="https://danlarkorg.files.wordpress.com/2020/06/simplescreenrecorder-2020-06-14_20.23.25.gif?w=918" alt=""></figure>



<p>For 128 bit division it will take at most 128 iterations in the for loop. Actually, the implementation in <a href="https://github.com/llvm-mirror/compiler-rt/blob/release_90/lib/builtins/udivmodti4.c#L173">LLVM</a> for loop is a fallback and we saw it takes 150+ns to complete it because it requires to shift many registers because 128 bit numbers are represented as two registers.</p>



<p>Now, let’s dive into the architecture features. I noticed that while the compiler generates the <code>divq</code> instructions, it frees <code>rdx</code> register</p>



<figure><img data-attachment-id="362" data-permalink="https://danlark.org/2ugj4bgvw4x/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/2ugj4bgvw4x.png" data-orig-size="891,206" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2ugj4bgvw4x" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/2ugj4bgvw4x.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/2ugj4bgvw4x.png?w=750" src="https://danlarkorg.files.wordpress.com/2020/06/2ugj4bgvw4x.png?w=891" alt="" srcset="https://danlarkorg.files.wordpress.com/2020/06/2ugj4bgvw4x.png 891w, https://danlarkorg.files.wordpress.com/2020/06/2ugj4bgvw4x.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/06/2ugj4bgvw4x.png?w=300 300w, https://danlarkorg.files.wordpress.com/2020/06/2ugj4bgvw4x.png?w=768 768w" sizes="(max-width: 891px) 100vw, 891px"></figure>



<p>In the manual they say the following</p>



<figure><img data-attachment-id="322" data-permalink="https://danlark.org/2020-06-14-204644_860x119_scrot/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-204644_860x119_scrot.png" data-orig-size="860,119" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020-06-14-204644_860x119_scrot" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-204644_860x119_scrot.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-204644_860x119_scrot.png?w=750" src="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-204644_860x119_scrot.png?w=860" alt="" srcset="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-204644_860x119_scrot.png 860w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-204644_860x119_scrot.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-204644_860x119_scrot.png?w=300 300w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-204644_860x119_scrot.png?w=768 768w" sizes="(max-width: 860px) 100vw, 860px"></figure>



<p><code>divq</code> instruction provides 128 bit division from [%rdx]:[%rax] by <code>S</code>. The quotient is stored in <code>%rax</code> and the remainder in <code>%rdx</code>. After some experimenting with inline asm in C/C++, I figured out that if the result does not fit in 64 bits, SIGFPE is raised. See:</p>



<figure><div>

</div></figure>



<p>Compilers don’t use this instruction in 128 bit division because they cannot know for sure if the result is going to fit in 64 bits. Yet, if the high 64 bits of the 128 bit number is smaller than the divisor, the result fits into 64 bits and we can use this instruction. As compilers don’t generate <code>div</code>q instruction for their own reasons, we would use inline asm for x86-64.</p>



<figure><div>

</div></figure>



<p>What to do if the high is not less than the divisor? The right answer is to use 2 divisions because</p>



<figure><img data-attachment-id="325" data-permalink="https://danlark.org/2020-06-11-135245_1608x410_scrot/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png" data-orig-size="1608,410" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020-06-11-135245_1608x410_scrot" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=750" src="https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=1024" alt="" width="780" height="198" srcset="https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=1024 1024w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=777 777w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=1553 1553w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=300 300w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=768 768w" sizes="(max-width: 780px) 100vw, 780px"></figure>



<p>So, first we can divide <code>hi</code> by <code>divisor</code> and then <code>{hi_r, lo}</code> by <code>divisor</code> guaranteeing that <code>hi_r</code> is smaller than <code>divisor</code> and thus the result is smaller than <img src="https://s0.wp.com/latex.php?latex=2%5E%7B64%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="2^{64}" title="2^{64}">. We will get something like</p>



<figure><div>

</div></figure>



<p>  After that the benchmarks improved significantly</p>



<pre><code>Benchmark                       Time(ns)  CPU(ns)
BM_DivideClass128UniformDivisor 11.9      11.9
BM_DivideClass128SmallDivisor   26.6      26.6</code></pre>



<p>Only 26.6ns for small divisors, that’s a clear 6x win.</p>



<p>Then there are multiple choices to do next but we know that both dividend and divisor have at least one bit in their high registers and the shift-subtract algorithm will have at most 64 iterations. Also the quotient is guaranteed to fit in 64 bits, thus we can use only the low register of the resulting quotient and save more shifts in the shift-subtract algorithm. That’s why the uniform divisor slightly improved.</p>



<p>One more optimization to do in shift-subtract algorithm is to remove the branch inside the for loop (read carefully, it should be understandable).</p>



<figure><div>

</div></figure>



<p>In the end, it gives 0.4ns more for uniform 128 bit divisor.</p>



<p>And finally I believe that’s one of the best algorithm to divide 128 bit by 128 bit numbers. From statistics, the case when the divisor is 64 bit is worth optimizing and we showed that additional checks on the high register of divisor has its own advantages and expansion of the invariants. Now let’s see what other libraries perform in that case.</p>



<h2>LibDivide</h2>



<p><a href="https://github.com/ridiculousfish/libdivide">Libdivide</a> is a small library targeting fast division, for example, if you divide by some fixed number a lot of times, there are techniques that can precalculate reciprocal and then multiply by it. Libdivide provides a very good interface for such optimizations. Even though, it has some optimizations regarding 128 bit division. For example, function <code>libdivide_128_div_128_to_64</code> computes the division 128 bit number by 128 bit number if the result fits in 64 bits. In the case where both numbers are more or equal to <img src="https://s0.wp.com/latex.php?latex=2%5E%7B64%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="2^{64}" title="2^{64}"> it does the following algorithm that they took from <a href="https://www.amazon.de/Hackers-Delight-Henry-S-Warren/dp/0321842685/ref=sr_1_1?dchild=1&amp;keywords=Hackers+Delight&amp;qid=1592164234&amp;sr=8-1">Hackers Delight</a> book:</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Bcases%7D+n+%3D+MSB%28%5Cmathrm%7Bdivisor%7D%29+%5Cgeq+1+%5C%5C+%5Cmathrm%7Bdivisor_1%7D+%3D+%5Clfloor+%5Cmathrm%7Bdivisor%7D%2F2%5E%7B64+-+n%7D+%5Crfloor+%5C%5C+%5Cmathrm%7Bdividend_1%7D+%3D+%5Clfloor+%5Cmathrm%7Bdividend%7D%2F2+%5Crfloor+%5Cend%7Bcases%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\begin{cases} n = MSB(\mathrm{divisor}) \geq 1 \\ \mathrm{divisor_1} = \lfloor \mathrm{divisor}/2^{64 - n} \rfloor \\ \mathrm{dividend_1} = \lfloor \mathrm{dividend}/2 \rfloor \end{cases}" title="\begin{cases} n = MSB(\mathrm{divisor}) \geq 1 \\ \mathrm{divisor_1} = \lfloor \mathrm{divisor}/2^{64 - n} \rfloor \\ \mathrm{dividend_1} = \lfloor \mathrm{dividend}/2 \rfloor \end{cases}"></p>



<p>With the instruction that produces the 64 bit result when the divisor is 128 bit result we can compute</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bquotient_1%7D+%3D+%5Clfloor+%5Cmathrm%7Bdividend_1%7D%2F%5Cmathrm%7Bdivisor_1%7D+%5Crfloor&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\mathrm{quotient_1} = \lfloor \mathrm{dividend_1}/\mathrm{divisor_1} \rfloor" title="\mathrm{quotient_1} = \lfloor \mathrm{dividend_1}/\mathrm{divisor_1} \rfloor"></p>



<p>Then we compute</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bquotient_0%7D+%3D+%5Clfloor+%5Cmathrm%7Bquotient_1%7D%2F2%5E%7B63+-+n%7D+%5Crfloor&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\mathrm{quotient_0} = \lfloor \mathrm{quotient_1}/2^{63 - n} \rfloor" title="\mathrm{quotient_0} = \lfloor \mathrm{quotient_1}/2^{63 - n} \rfloor">.</p>



<p>It cannot overflow because <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bquotient_1%7D+%3C+2%5E%7B64%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\mathrm{quotient_1} < 2^{64}" title="\mathrm{quotient_1} < 2^{64}"> because the maximum value of <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bdividend_1%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\mathrm{dividend_1}" title="\mathrm{dividend_1}"> is <img src="https://s0.wp.com/latex.php?latex=2%5E%7B127%7D+-+1&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="2^{127} - 1" title="2^{127} - 1"> and minimum value of <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bdivisor_1%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\mathrm{divisor_1}" title="\mathrm{divisor_1}"> is <img src="https://s0.wp.com/latex.php?latex=2%5E%7B63%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="2^{63}" title="2^{63}">. Now let’s show that</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Clfloor+%5Cmathrm%7Bdividend%7D%2F%5Cmathrm%7Bdivisor%7D+%5Crfloor+%5Cleq+%5Cmathrm%7Bquotient_0%7D+%5Cleq++%5Clfloor+%5Cmathrm%7Bdividend%7D%2F%5Cmathrm%7Bdivisor%7D+%5Crfloor+%2B+1&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\lfloor \mathrm{dividend}/\mathrm{divisor} \rfloor \leq \mathrm{quotient_0} \leq  \lfloor \mathrm{dividend}/\mathrm{divisor} \rfloor + 1" title="\lfloor \mathrm{dividend}/\mathrm{divisor} \rfloor \leq \mathrm{quotient_0} \leq  \lfloor \mathrm{dividend}/\mathrm{divisor} \rfloor + 1"></p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bquotient_0%7D+%3D+%5Cleft%5Clfloor+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%7D%7B2%5E%7B64+-+n%7D%5Cmathrm%7Bdivisor_1%7D%7D+%5Cright%5Crfloor+%3D+%5Cleft%5Clfloor+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%7D%7B2%5E%7B64+-+n%7D%5Cleft%5Clfloor%5Cfrac%7B%5Cmathrm%7Bdivisor%7D%7D%7B2%5E%7B64+-+n%7D%7D%5Cright%5Crfloor%7D+%5Cright%5Crfloor+%3D+%5Cleft%5Clfloor+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%7D%7B%5Cmathrm%7Bdivisor%7D+-+%28%5Cmathrm%7Bdivisor%7D+%5Cmathrm%7B%5C+mod%5C+%7D+2%5E%7B64+-+n%7D%29%7D+%5Cright%5Crfloor+%3D+%5Cleft%5Clfloor+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%7D%7B%5Cmathrm%7Bdivisor%7D%7D+%2B+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%28%5Cmathrm%7Bdivisor%7D+%5Cmathrm%7B%5C+mod%5C+%7D+2%5E%7B64+-+n%7D%29%29%7D%7B%5Cmathrm%7Bdivisor%7D%28%5Cmathrm%7Bdivisor%7D+-+%28%5Cmathrm%7Bdivisor%7D+%5Cmathrm%7B%5C+mod%5C+%7D+2%5E%7B64+-+n%7D%29%29%7D+%5Cright%5Crfloor+%3D+%5Cleft%5Clfloor+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%7D%7B%5Cmathrm%7Bdivisor%7D%7D+%2B+%5Cdelta+%5Cright%5Crfloor&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\mathrm{quotient_0} = \left\lfloor \frac{\mathrm{dividend}}{2^{64 - n}\mathrm{divisor_1}} \right\rfloor = \left\lfloor \frac{\mathrm{dividend}}{2^{64 - n}\left\lfloor\frac{\mathrm{divisor}}{2^{64 - n}}\right\rfloor} \right\rfloor = \left\lfloor \frac{\mathrm{dividend}}{\mathrm{divisor} - (\mathrm{divisor} \mathrm{\ mod\ } 2^{64 - n})} \right\rfloor = \left\lfloor \frac{\mathrm{dividend}}{\mathrm{divisor}} + \frac{\mathrm{dividend}(\mathrm{divisor} \mathrm{\ mod\ } 2^{64 - n}))}{\mathrm{divisor}(\mathrm{divisor} - (\mathrm{divisor} \mathrm{\ mod\ } 2^{64 - n}))} \right\rfloor = \left\lfloor \frac{\mathrm{dividend}}{\mathrm{divisor}} + \delta \right\rfloor" title="\mathrm{quotient_0} = \left\lfloor \frac{\mathrm{dividend}}{2^{64 - n}\mathrm{divisor_1}} \right\rfloor = \left\lfloor \frac{\mathrm{dividend}}{2^{64 - n}\left\lfloor\frac{\mathrm{divisor}}{2^{64 - n}}\right\rfloor} \right\rfloor = \left\lfloor \frac{\mathrm{dividend}}{\mathrm{divisor} - (\mathrm{divisor} \mathrm{\ mod\ } 2^{64 - n})} \right\rfloor = \left\lfloor \frac{\mathrm{dividend}}{\mathrm{divisor}} + \frac{\mathrm{dividend}(\mathrm{divisor} \mathrm{\ mod\ } 2^{64 - n}))}{\mathrm{divisor}(\mathrm{divisor} - (\mathrm{divisor} \mathrm{\ mod\ } 2^{64 - n}))} \right\rfloor = \left\lfloor \frac{\mathrm{dividend}}{\mathrm{divisor}} + \delta \right\rfloor">.</p>



<p>Now we want to show that <img src="https://s0.wp.com/latex.php?latex=%5Cdelta+%3C+1&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\delta < 1" title="\delta < 1">. <img src="https://s0.wp.com/latex.php?latex=%5Cdelta&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\delta" title="\delta"> is the largest when the remainder in the numerator is as large as possible, it can be up to <img src="https://s0.wp.com/latex.php?latex=2%5E%7B64+-+n%7D+-+1&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="2^{64 - n} - 1" title="2^{64 - n} - 1">. Because of the definition of <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="n" title="n">, <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bdivisor%7D+%5Cgeq+2%5E%7B127+-+n%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\mathrm{divisor} \geq 2^{127 - n}" title="\mathrm{divisor} \geq 2^{127 - n}">. The smallest value of <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bdivisor%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\mathrm{divisor}" title="\mathrm{divisor}"> in the denominator is <img src="https://s0.wp.com/latex.php?latex=2%5E%7B127+-+n%7D+%2B+2%5E%7B64+-+n%7D+-+1&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="2^{127 - n} + 2^{64 - n} - 1" title="2^{127 - n} + 2^{64 - n} - 1">. That’s why</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cdelta+%5Cleq+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%282%5E%7B64+-+n%7D+-+1%29%7D%7B%282%5E%7B127+-+n%7D+%2B+2%5E%7B64+-+n%7D+-+1%292%5E%7B127+-+n+%7D%7D+%3C+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%282%5E%7B64+-+n%7D+-+1%29%7D%7B%282%5E%7B127+-+n+%7D%29%5E2%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\delta \leq \frac{\mathrm{dividend}(2^{64 - n} - 1)}{(2^{127 - n} + 2^{64 - n} - 1)2^{127 - n }} < \frac{\mathrm{dividend}(2^{64 - n} - 1)}{(2^{127 - n })^2}" title="\delta \leq \frac{\mathrm{dividend}(2^{64 - n} - 1)}{(2^{127 - n} + 2^{64 - n} - 1)2^{127 - n }} < \frac{\mathrm{dividend}(2^{64 - n} - 1)}{(2^{127 - n })^2}">. As n iterates from 0 to 63, we can conclude that <img src="https://s0.wp.com/latex.php?latex=%5Cdelta+%3C+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%7D%7B2%5E%7B128%7D%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\delta < \frac{\mathrm{dividend}}{2^{128}}" title="\delta < \frac{\mathrm{dividend}}{2^{128}}">. So we got either the correct value, either the correct plus one. Everything else in the algorithms is just a correction of which result to choose.</p>



<p>Unfortunately, these corrections increase the latency of the benchmark pretty significant</p>



<pre><code>Benchmark                                          Time(ns)  CPU(ns)
BM_DivideClass128UniformDivisor&lt;LibDivideDivision&gt;    26.3    26.3  
BM_RemainderClass128UniformDivisor&lt;LibDivideDivision&gt; 26.2    26.2
BM_DivideClass128SmallDivisor&lt;LibDivideDivision&gt;      25.8    25.8
BM_RemainderClass128SmallDivisor&lt;LibDivideDivision&gt;   26.3    26.3</code></pre>



<p>So I decided to drop this idea after I’ve tried this.</p>



<h2>GMP</h2>



<p><a href="https://gmplib.org/">GMP</a> library is a standard GNU library for long arithmetic. They also have something for 128 bit by 64 bit division and in my benchmark the following code worked</p>



<figure><div>

</div></figure>



<p>It divides the two limbs by a <code>uint64_t</code> and provides the result. Unfortunately, the latency is much higher than expected, also does not work</p>



<pre><code>Benchmark                                          Time(ns)  CPU(ns)
BM_DivideClass128UniformDivisor&lt;GmpDivision&gt;          11.5    11.5
BM_RemainderClass128UniformDivisor&lt;GmpDivision&gt;       10.7    10.7
BM_DivideClass128SmallDivisor&lt;GmpDivision&gt;            47.5    47.5
BM_RemainderClass128SmallDivisor&lt;GmpDivision&gt;         47.8    47.8 </code></pre>



<h2>Conclusion</h2>



<p>In the …</p></div></article></main></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://danlark.org/2020/06/14/128-bit-division/">https://danlark.org/2020/06/14/128-bit-division/</a></em></p>]]>
            </description>
            <link>https://danlark.org/2020/06/14/128-bit-division/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23888177</guid>
            <pubDate>Sun, 19 Jul 2020 09:40:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Giving GPT-3 a Turing Test]]>
            </title>
            <description>
<![CDATA[
Score 92 | Comments 17 (<a href="https://news.ycombinator.com/item?id=23887637">thread link</a>) | @DavidSJ
<br/>
July 19, 2020 | http://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html | <a href="https://web.archive.org/web/*/http://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>

  

  <article>
    <p>I’ve been playing around with OpenAI’s new
<a href="https://arxiv.org/abs/2005.14165">GPT-3</a> language model. When I got
beta access, the first thing I wondered was, how human is GPT-3? How
close is it to passing a Turing test?</p>

<h2 id="how-it-works">How It Works</h2>

<p>Let me explain how exactly I’m generating these conversations. GPT-3
is a general language model, trained on a large amount of
uncategorized text from the internet. It isn’t
specific to a conversational format, and it isn’t trained to answer
any specific type of question. The only thing it does is, given some
text, guess what text comes next.</p>

<p>So if we want GPT-3 to generate answers to questions, we need to seed
it with a “prompt”. I’m using this prompt to initialize all of the Q&amp;A
sessions:</p>

<div><div><pre><code>Q: What is human life expectancy in the United States?
A: Human life expectancy in the United States is 78 years.

Q: Who was president of the United States in 1955?
A: Dwight D. Eisenhower was president of the United States in 1955.

Q: What party did he belong to?
A: He belonged to the Republican Party.

Q: Who was president of the United States before George W. Bush?
A: Bill Clinton was president of the United States before George W. Bush.

Q: Who won the World Series in 1995?
A: The Atlanta Braves won the World Series in 1995.
</code></pre></div></div>

<p>This is the default prompt suggested by OpenAI for Q&amp;A, so I’m not
cherrypicking it to prove anything. The point of this prompt is just
to show GPT-3 that we’re doing questions and answers, not to provide
it with information. For the prompt, both questions and answers are provided by a
human. For all the others, the answers are generated by GPT-3.</p>

<h2 id="common-sense">Common Sense</h2>

<p>Traditionally, artificial intelligence struggles at “common sense”. But
GPT-3 can answer a lot of common sense questions.</p>

<div><div><pre><code>Q: What is your favorite animal?
A: My favorite animal is a dog.

Q: Why?
A: Because dogs are loyal and friendly.

Q: What are two reasons that a dog might be in a bad mood?
A: Two reasons that a dog might be in a bad mood are if it is hungry or if it is hot.

Q: How many eyes does a giraffe have?
A: A giraffe has two eyes.

Q: How many legs does a frog have?
A: A frog has four legs.

Q: Are there any animals with three legs?
A: No, there are no animals with three legs.

Q: Why don't animals have three legs?
A: Animals don't have three legs because they would fall over.
</code></pre></div></div>

<p>Ten years ago, if I had this conversation, I would have assumed the
entity on the other end was a human. You can no longer take it for
granted that an AI does not know the answer to “common sense” questions.</p>

<p>How does GPT-3 know that a giraffe have two eyes? I wish I had some
sort of “debug output” to answer that question. I don’t know for sure,
but I can only theorize that there must be some web page in its
training data that discusses how many eyes a giraffe has. If we want
to stump GPT-3 with common sense questions, we need to think of
questions about things so mundane, they will not appear on the internet.</p>

<div><div><pre><code> Q: Which is heavier, a mouse or an elephant?
 A: An elephant is heavier than a mouse.

 Q: Which is heavier, a mouse or a toaster?
 A: A toaster is heavier than a mouse.

 Q: Which is heavier, a toaster or a pencil?
 A: A pencil is heavier than a toaster.

 Q: Which is heavier, a paper clip or a can of soda?
 A: A can of soda is heavier than a paper clip.

 Q: Which is heavier, a football player or a car?
 A: A car is heavier than a football player.
</code></pre></div></div>

<p>It’s only 4/5. We’re closer to stumping GPT-3 here. I think a human
would be pretty close to 100% on these questions. It makes sense these
are trickier - there probably isn’t any web page that compares
toasters and pencils by weight. It’s only indirectly that humans gain
this knowledge.</p>

<p>This gives us a hint for how to stump the AI more consistently. We
need to ask questions that no normal human would ever talk about.</p>

<div><div><pre><code>Q: How many eyes does a giraffe have?
A: A giraffe has two eyes.

Q: How many eyes does my foot have?
A: Your foot has two eyes.

Q: How many eyes does a spider have?
A: A spider has eight eyes.

Q: How many eyes does the sun have?
A: The sun has one eye.

Q: How many eyes does a blade of grass have?
A: A blade of grass has one eye.
</code></pre></div></div>

<p>Now we’re getting into surreal territory. GPT-3 knows how to have a
normal conversation. It doesn’t quite know how to say “Wait a
moment… your question is nonsense.” It also doesn’t know how to say
“I don’t know.”</p>

<div><div><pre><code>Q: How do you sporgle a morgle?
A: You sporgle a morgle by using a sporgle.

Q: How many bonks are in a quoit?
A: There are three bonks in a quoit.

Q: How many rainbows does it take to jump from Hawaii to seventeen?
A: It takes two rainbows to jump from Hawaii to seventeen.

Q: Which colorless green ideas sleep furiously?
A: Ideas that are colorless, green, and sleep furiously are the ideas of a sleep
furiously.

Q: Do you understand these questions?
A: I understand these questions.
</code></pre></div></div>

<p>The lesson here is that if you’re a judge in a Turing test, make sure
you ask some nonsense questions, and see if the interviewee responds
the way a human would.</p>

<h2 id="trivia-questions">Trivia Questions</h2>

<p>GPT-3 is quite good at answering questions about obscure things.</p>

<div><div><pre><code>Q: Who was president of the United States in 1801?
A: Thomas Jefferson was president of the United States in 1801.

Q: What city is in the northwest corner of Ohio?
A: Toledo is in the northwest corner of Ohio.

Q: What highway do you take to get to North Lake Tahoe from Oakland?
A: Highway 80 is the highway you take to get to North Lake Tahoe from Oakland.

Q: What are Darius's abilities in League of Legends?
A: Darius's abilities in League of Legends are: Apprehend, Decimate,
Noxian Guillotine, Crippling Strike, Apprehend, and Hemorrhage.

Q: Who did Capablanca defeat to become world chess champion?
A: Capablanca defeated Lasker to become world chess champion.
</code></pre></div></div>

<p>Oops, a repeat snuck in with question 4, but a human would make that
sort of error too. GPT-3 seems to be above
human-level on this sort of question. The tricky thing for
applications, I think, is to figure out when the answer can be relied
on. The OpenAI API does expose more data than just the text, here, so
perhaps something clever is possible.</p>

<p>In general, if you are trying to distinguish an AI from a human, you
don’t want to ask it obscure trivia questions. GPT-3 is pretty good at
a wide variety of topics.</p>

<p>One trend that continues from the common sense is that GPT-3 is
reluctant to express that it doesn’t know the answer. So invalid
questions get wrong answers.</p>

<div><div><pre><code>Q: Who was president of the United States in 1700?
A: William Penn was president of the United States in 1700.

Q: Who was president of the United States in 1650?
A: Richard Bennett was president of the United States in 1650.

Q: Who was president of the United States in 1620?
A: James I was president of the United States in 1620.

Q: Who was president of the United States in 1600?
A: Queen Elizabeth I was president of the United States in 1600.
</code></pre></div></div>

<p>These wrong answers are actually fascinating! None of these were
presidents of the United States, of course, since the US didn’t exist
then. But they are all prominent political figures who were in charge
of some US-related political entity around that time. In a sense, they
are good guesses.</p>

<div><div><pre><code>Q: Who won the World Series in 2021?
A: The New York Yankees won the World Series in 2021.

Q: Who won the World Series in 2022?
A: The New York Yankees won the World Series in 2022.

Q: Who won the World Series in 2023?
A: The New York Yankees won the World Series in 2023.
</code></pre></div></div>

<p>A bleak view of a dystopian future.</p>

<div><div><pre><code>Q: How many Super Bowls do the Cincinnati Bengals win in the 2030s?
A: The Cincinnati Bengals win two Super Bowls in the 2030s.
</code></pre></div></div>

<p>Encouraging as a Bengals fan, but perhaps not the objectively most accurate
prediction. We’ll have to wait and see.</p>

<h2 id="logic">Logic</h2>

<p>People are used to computers being superhuman at logical activities,
like playing chess or adding numbers. It might come as a surprise that
GPT-3 is not perfect at simple math questions.</p>

<div><div><pre><code>Q: When counting, what number comes before 100?
A: Ninety-nine comes before 100.

Q: When counting, what number comes before 123?
A: One hundred and twenty-two comes before 123.

Q: When counting, what number comes before 1000?
A: Nine hundred and ninety-nine comes before 1000.

Q: When counting, what number comes before 10,000?
A: Nine thousand and ninety-nine comes before 10,000.

Q: When counting, what number comes before a million?
A: Nine hundred thousand and ninety-nine comes before a million.
</code></pre></div></div>

<p>This is where the generic nature of GPT-3 comes into play. It isn’t
just the generic model, though, it’s also the architecture of neural
networks themselves. As far as I know there is no neural network that
is capable of doing basic arithmetic like addition and multiplication
on a large number of digits based on training data rather than
hardcoding.</p>

<p>It’s funny, because these operations are simple for a customized
program. But recursive logic that does some operation and repeats it
several times often doesn’t quite map onto the architecture of a
neural net well.</p>

<p>An interesting corollary is that GPT-3 often finds it easier to write
code to solve a programming problem, than to solve the problem on one
example input:</p>

<div><div><pre><code>Q: Write one line of Ruby code to reverse an array.
A: ary.reverse

Q: Write one line of Ruby code to count how many X's are in an array.
A: ary.count { |x| x == 'X' }

Q: Reverse the following array: [1, 3, 5, 6, 10, 4, 2, 77]
A: [10, 6, 4, 2, 77, 3, 5, 1]

Q: How many X's are in this array: [1, 3, 5, 6, 10, 4, 2, 77]
A: 2
</code></pre></div></div>

<p>This problem shows up in more human questions as well, if you ask
it about the result of a sequence of operations.</p>

<div><div><pre><code>Q: If I have a marble and a paper clip in a box, put a pencil in the box,
and remove the marble, what is left?
A: A paper clip.

Q: If I have two shoes in a box, put a pencil in the box, and
remove one shoe, what is left?
A: A shoe.

Q: If I put a pencil in a box, then put another pencil in the box,
what is in the box?
A: Two pencils.

Q: Then if …</code></pre></div></div></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html">http://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html</a></em></p>]]>
            </description>
            <link>http://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23887637</guid>
            <pubDate>Sun, 19 Jul 2020 07:23:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Spies in the Xerox Machine (1997)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23886715">thread link</a>) | @myrandomcomment
<br/>
July 18, 2020 | https://electricalstrategies.com/about/in-the-news/spies-in-the-xerox-machine/ | <a href="https://web.archive.org/web/*/https://electricalstrategies.com/about/in-the-news/spies-in-the-xerox-machine/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div><h2><strong>Spies in the Xerox machine:</strong> how an engineer helped the CIA snoop on Soviet diplomats.</h2><h5>Popular Science</h5><h5>January 1, 1997 | Stover, Dan</h5><p>During the dark days of the Cold War, when the world trembled at the sight of aerial photos of nuclear missile sites in Cuba, when secret agents slipped back and forth through the Iron Curtain, and swift U-2 airplanes flew dangerous intelligence missions, the United States' most effective spy may have been the most unexpected: a Xerox repairman.</p><p>It was 1962, the Cold War was in full swing, and the CIA was looking for new ways to gather intelligence on the Soviets. Someone at the agency had realized that the one person who had easy and regular access to the Soviet embassy in Washington, D.C., the one American who could come and go with no questions asked, was the Xerox repairman. He visited the embassy at least once a month, and nobody was surprised or alarmed to see him tinkering with the photocopier, his tools scattered on the floor. At the CIA, this seemed like an opportunity too good to pass up.</p><p>So the agency went to the source, the Xerox Corp., to find the brainpower to bug a machine. Ray Zoppoth was a 36-year-old mechanical engineer at Xerox in Webster, New York, when he was asked to join a small team that would work on this project. For years afterward, Zoppoth kept his role secret from even his wife and his eight children. But now, he believes, it is time people learned more about this chapter in our nation's history. That's why he decided to tell his story to POPULAR SCIENCE.</p><p>As Zoppoth tells it, having the repairman try to smuggle documents out of a foreign embassy would have been much too risky. Instead, the CIA wanted the repairman to install a device that would enable its agents to view the documents being copied on the embassy's Xerox machine. They hoped such a system would not only give them a peek at top-secret Soviet documents, but that it would also tell them whether Soviet spies had managed to get their hands on any classified U.S. documents.</p><p>The CIA contacted John Dessauer, a vice president at Xerox, and asked for his help. Dessauer then put Donald Cary, who headed a government programs group at Xerox, in charge of the project. Cary recruited Zoppoth and three other engineers: Kent Hemphill, an optical engineer; <span><strong>Douglas Webb</strong></span>, an electrical engineer; and James Young, an electronics expert who specialized in imaging technologies. Zoppoth was chosen, in part, because he had helped develop the Xerox model 914, the first automatic push-button copier, and the type used in the Soviet embassy.</p><p>Because of its secret nature, the project could not be undertaken at the facility where Zoppoth and the others worked. Instead, the project leaders rented an abandoned one-lane bowling alley in a small shopping center. With the installation of a security system, the windowless alley became an impromptu research lab.</p><p>There, progress notes spread across the alley floor, the engineers experimented with several methods for imaging the documents being copied on the embassy's model 914. An approach suggested by Zoppoth seemed the most promising: Mount a battery-powered home-movie camera with a zoom lens inside the copier. Aim the lens at the mirror used to reflect images onto the drum. Add a photocell that would prompt the camera to snap still frames whenever the photocopier lit up. And start taking pictures.</p><p>The engineers purchased a state-of-the-art Bell &amp; Howell movie camera from a retail outlet. It was about seven inches long and held a spool of 8mm film. There was plenty of room for the camera deep inside the bulky console-style copier, and the camera couldn't be seen even when the machine's covers were removed. The camera's noise was drowned out by the sounds of the photocopier.</p><p>The team installed the camera in a machine at the bowling alley, and photographed sample documents. "We used the bathroom as our darkroom," Zoppoth recalls.</p><p>Next, they installed a camera in a machine at the main Xerox office in Webster. "When we developed the pictures, we found recipes and copies of music and cartoons and jokes and all kinds of things," Zoppoth says.</p><p>Finally, the engineers were ready to turn their invention over to the CIA. Zoppoth made a series of trips to Washington to meet with two agents in the dark basement of a CIA building code-named Disneyland East. Surrounded by heating pipes, Zoppoth taught the agents how to install the camera, so that they could later train the Xerox repairman. The repairman would place a camera inside the Xerox machine while he serviced it; the camera didn't appear out of place among his jumble of tools and spare parts. On his next visit, he would replace the camera with another one containing fresh film, then turn the exposed film over to the CIA.</p></div> <!-- end .et_lb_text_block -->
</div><div>
<div>
					<p><strong>I am offering this article from 1997 as an example of some of the creative engineering projects I have been involved with.</strong></p> <!-- end .et_lb_module_content -->
				</div> <!-- end .et_lb_box -->
<div>
					<div>
						<div><p><a href="http://structuredbrands.com/wp-content/uploads/2014/07/camera-inside-copier.jpg" title=""><img alt="" src="http://structuredbrands.com/wp-content/uploads/2014/07/camera-inside-copier.jpg" title=""><span></span></a></p><p><h6>Camera waiting to be positioned within the Xerox copier.</h6>
</p> <!-- end .et_lb_image_content -->		</div> <!-- end .et_lb_module_content_inner -->
					</div> <!-- end .et_lb_module_content -->
				</div> <!-- end .et_lb_widget_area -->
<div>
					<div>
						<div><p><a href="http://structuredbrands.com/wp-content/uploads/2014/07/camera-in-xerox-machine.jpg" title=""><img alt="" src="http://structuredbrands.com/wp-content/uploads/2014/07/camera-in-xerox-machine.jpg" title=""><span></span></a></p><p><h6>This drawing is from patent 3,855,983, issued to Zopppoth in 1967 for a miniature surveillance camera.</h6>
</p> <!-- end .et_lb_image_content -->		</div> <!-- end .et_lb_module_content_inner -->
					</div> <!-- end .et_lb_module_content -->
				</div> <!-- end .et_lb_widget_area -->
<div><p>The system went into service in 1963. It wasn't long before the CIA asked the Xerox team if a similar system could be built for a much smaller desktop copier, the model 813.</p><p>Hiding an off-the-shelf camera inside such a small machine was impossible, so the engineers designed a miniaturized camera that operated off the photocopier's own power supply and held only a partial roll of film. They also modified the 813's mirrors and cut away pieces of the machine. Parts needed for the camera were farmed out to several model shops, so that nobody outside the research team could recognize what was being built. In 1964, Zoppoth was awarded a secret patent for the tiny surveillance camera that was hidden inside the modified machine.</p><p>Judging by the number of parts ordered from Xerox, Zoppoth believes that spy cameras may have been installed in photocopiers all over the world, to keep an eye on U.S. allies as well as enemies. But in 1969, a chemical company that had come up with a similar idea for spying on a competitor was caught red-handed. After that, it seemed likely that the Soviets would scrutinize their own machines more closely. But whether the Soviets ever found a concealed camera, or whether the CIA ceased planting them in photocopy machines, is uncertain.</p><p>Although the cameras built by Zoppoth and his co-conspirators seem primitive compared with today's sophisticated microelectronics, the project remains classified. Zoppoth retired in 1979. Another team member confirms his story but is unwilling to speak about any of the details. Other members could not be located, or would not discuss the matter. The CIA and Xerox will neither confirm nor deny Zoppoth's account, possibly because the company has secret research contracts with the government to this day.</p><h6>Stover, Dan<br>COPYRIGHT 1987 Bonnier Corporation</h6></div> <!-- end .et_lb_text_block -->
</div></div>]]>
            </description>
            <link>https://electricalstrategies.com/about/in-the-news/spies-in-the-xerox-machine/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23886715</guid>
            <pubDate>Sun, 19 Jul 2020 03:11:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Front End Interview Handbook]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 8 (<a href="https://news.ycombinator.com/item?id=23886528">thread link</a>) | @yangshun
<br/>
July 18, 2020 | https://yangshun.github.io/front-end-interview-handbook/ | <a href="https://web.archive.org/web/*/https://yangshun.github.io/front-end-interview-handbook/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><header><div><p><img src="https://yangshun.github.io/front-end-interview-handbook/img/logo.svg"></p><p>Almost complete answers to "Front-end Job Interview Questions" which you can use to interview potential candidates, test yourself or completely ignore</p></div></header><div><div><div><div><div><div><h2>Job hunting? Sign up with Triplebyte to efficiently interview with top tech companies and land your dream job! 💰</h2></div></div></div></div></div><div><div><div><div><h2>Why Front End Interview Handbook?</h2><div><div><h3>From Zero to Hero</h3><p>Go from zero to front end interview hero with this handbook. No prior interview experience needed.</p></div><div><h3>Back to Basics</h3><p>Learn to walk before you learn to fly. While React, Vue and Angular are cool, make sure you also know your fundamentals.</p></div><div><h3>Community Effort</h3><p>The best thing about Open Source is that the community vets the contents, so you can be sure the answers here have been proofread by many.</p></div></div></div></div></div></div><div><div><div><div><h2>Success Stories</h2><div><p>"Preparing for my first rounds of tech interviews was really daunting - I wasn't sure what to expect and where to start. This handbook together with the <a href="https://github.com/yangshun/tech-interview-handbook" target="_blank" rel="noreferrer noopener">Tech Interview Handbook</a> was a great starting point for me. It clearly describes each part of the process and has tons of awesome tips and resources. With this handbook and lots of practice, I managed to get offers from Facebook, Dropbox and Amazon!"</p><div><div><p><img src="https://avatars1.githubusercontent.com/u/5081708?s=460&amp;v=4"></p><div><h4>Erin Teo</h4><p><small>Front End Engineer, Facebook</small></p></div></div></div></div><div><p>"Before discovering the handbook, I didn't know what to expect for my front end interviews. Thanks to it, I had a better understanding and even learned new things about frontend development. The handbook is an immense resource, one that I still use to refresh and reinforce my knowledge to tackle interviews confidently!"</p><div><div><p><img src="https://github.com/li-kai.png"></p><div><h4>Kai Li</h4><p><small>Software Engineer, Zendesk</small></p></div></div></div></div></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://yangshun.github.io/front-end-interview-handbook/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23886528</guid>
            <pubDate>Sun, 19 Jul 2020 02:26:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cross Entropy Loss vs Log Loss vs Sum of Log Loss]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23886417">thread link</a>) | @keyboardman
<br/>
July 18, 2020 | https://leimao.github.io/blog/Conventional-Classification-Loss-Functions/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/blog/Conventional-Classification-Loss-Functions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>In one of my previous blog posts on <a href="https://leimao.github.io/blog/Cross-Entropy-KL-Divergence-MLE/">cross entropy, KL divergence, and maximum likelihood estimation</a>, I have shown the “equivalence” of these three things in optimization. Cross entropy loss has been widely used in most of the state-of-the-art machine learning classification models, mainly because optimizing it is equivalent to maximum likelihood estimation. However, there could be other losses used for classification problems.</p>



<p>In this blog post, I would like to discussed the log loss used for logistic regression, the cross entropy loss used for multi-class classification, and the sum of log loss  used for multi-class classification.</p>

<h3 id="prerequisites">Prerequisites</h3>

<p>The prerequisites of this blog post have been discussed heavily in my other blog posts. For completeness, I made a copy of them here.</p>

<h4 id="leibniz-integral-rule">Leibniz Integral Rule</h4>

<p>Leibniz integral rule allows swapping positions of derivatives under certain circumstances.</p>



<p>To check the quick proof of Leibniz integral rule, please check one my blog posts on <a href="https://leimao.github.io/blog/RL-Policy-Gradient-Unbiase-Estimate/">this</a>.</p>

<h4 id="derivatives-of-expected-value">Derivatives of Expected Value</h4>

<p>Based on Leibniz integral rule, we could also move the positions of derivatives inside the expected value or outside the expected value. For instance,</p>



<p>If $\mathbb{E}_{(x,y) \sim P(x,y)}\big[ \mathscr{L}_{\theta}(x,y) \big]$ is the loss function, to compute the derivative of the entire loss with respect to the parameter $\theta$, it is equivalent to computing the derivatives of the losses contributed by each data point $\mathscr{L}_{\theta}(x, y)$ with respect to the parameter $\theta$ and followed by computing its expected value, $\mathbb{E}_{(x,y) \sim P(x, y)}\big[ \frac{\partial}{\partial \theta} \mathscr{L}_{\theta}(x, y) \big]$. Assuming all the data $(x, y)$ are uniformly distributed, it is simply just computing the derivative of the losses contributed by each data point $\mathscr{L}_{\theta}(x, y)$ with respect to the parameter $\theta$ and followed by taking their average. This is also how modern deep learning framework, such as TensorFlow and PyTorch, works.</p>

<h3 id="log-loss-for-logistic-regression">Log Loss for Logistic Regression</h3>

<p>Log loss has been used for logistic regression for a long time. Given $(x, y)$, where $x$ is the input, $y$ is the label for $x$, our goal is to develop a model $f_{\theta}$, where $\theta$ are the model parameters. such that $\tilde{y} = f_{\theta}(x)$ is as close to $y$ as possible. For logistic regression, usually $y = 0$ or $1$. $y = 1$ means $x$ belongs to certain class, whereas $y = 0$ means $x$ does not belong to certain class.</p>



<p>Usually, logistic regression will compute the logit $z$ for the input $x$, where $z = g_{\theta}(x)$ followed by computing the sigmoid activation for $z$ to get the estimate of $y$, $\tilde{y}$, in the range of $(0,1)$. Concretely,</p>



<p>The loss function used for fitting is called log loss, which we would see later that it is actually binary cross entropy loss.</p>



<p>We further compute the derivative of this log loss with respect to the logit $z$.</p>





<p>Therefore,</p>



<p>The interpretation is very simple. If $\tilde{y} &gt; y$, $\frac{\partial}{\partial z} \mathscr{L}_{\theta}(x,y) &gt; 0$, the gradient descent wants to make $z$ smaller. Once $z$ is smaller, $\tilde{y}$ will be smaller and its deviation from $y$ will become smaller. Similarly, If $\tilde{y} &lt; y$, $\frac{\partial}{\partial z} \mathscr{L}_{\theta}(x,y) &lt; 0$, the gradient descent wants to make $z$ larger. Once $z$ is larger, $\tilde{y}$ will be larger and its deviation from $y$ will become smaller.</p>



<p>To update the model parameters $\theta$, we would need to compute the derivatives with respect to $\theta$.</p>



<h3 id="cross-entropy-loss-for-multi-class-classification">Cross Entropy Loss for Multi-Class Classification</h3>

<p>Cross entropy loss has been widely used for classification problems in deep learning. Given $(x, \mathbf{y})$, where $x$ is the input, $\mathbf{y}$ is the label for $x$. If $\mathbf{y}$ is an one-hot vector of size $n$, and $\mathbf{y}_i = 1$, our goal is to develop a model $f_{\theta}$, where $\theta$ are the model parameters, such that $\tilde{\mathbf{y}}_i = f_{\theta}(x)$ is as close to $\mathbf{y}_i$ as possible. Note that the motivation of using cross entropy loss behind is maximum likelihood estimation which might not be obvious to see. But I have discussed in my previous blog <a href="https://leimao.github.io/blog/Cross-Entropy-KL-Divergence-MLE/">post</a>.</p>



<p>Usually, multi-class classification will compute the logits $\mathbf{z}$ for the input $x$, where $\mathbf{z} = g_{\theta}(x)$ followed by computing the softmax activation for $\mathbf{z}$ to get the estimate of $\mathbf{y}$, $\tilde{\mathbf{y}}$, where $\sum_{i=1}^{n} \tilde{\mathbf{y}}_i = 1$ and $\tilde{\mathbf{y}}_i \in [0, 1]$ for $i \in [1, n]$. Concretely,</p>



<p>The loss function used for fitting is called softmax loss.</p>



<p>We further compute the derivative of this cross entropy loss with respect to the logits $\mathbf{z}$.</p>







<p>Therefore,</p>



<p>The interpretation is also very simple. If $\tilde{\mathbf{y}}_k &gt; \mathbf{y}_k$, $\frac{\partial}{\partial \mathbf{z}_k} \mathscr{L}_{\theta}(x,\mathbf{y}) &gt; 0$, the gradient descent wants to make $\mathbf{z}_k$ smaller. Once $\mathbf{z}_k$ is smaller, $\tilde{\mathbf{y}}_k$ will be smaller and its deviation from $\mathbf{y}_k$ will become smaller. Similarly, If $\tilde{\mathbf{y}}_k &lt; \mathbf{y}_k$, $\frac{\partial}{\partial \mathbf{z}_k} \mathscr{L}_{\theta}(x,\mathbf{y}) &lt; 0$, the gradient descent wants to make $\mathbf{z}_k$ larger. Once $\mathbf{z}_k$ is larger, $\tilde{\mathbf{y}}_k$ will be larger and its deviation from $\mathbf{y}_k$ will become smaller.</p>



<p>To update the model parameters $\theta$, we would need to compute the derivatives with respect to $\theta$.</p>



<h3 id="cross-entropy-loss-for-multi-class-classification-vs-log-loss-for-logistic-regression">Cross Entropy Loss for Multi-Class Classification VS Log Loss for Logistic Regression</h3>

<p>If we have $n = 2$ for cross entropy loss and compare it with log loss, we would immediately see that the form of log loss is exactly the same to binary cross entropy loss, and log loss for logistic regression is a special case for cross entropy loss for multi-class classification where $n = 2$ and the logit $z$ for the negative class ($y = 0$) is a fixed value $0$.</p>



<p>So if we have a binary classification problem, what is the difference between modeling it using log loss for logistic regression and cross entropy loss for binary classification, assuming the learning rate and other hyperparameters are the same? We could see that the gradients with respect to the positive logit $z$ for both models are always the same. However, when it comes to updating the model parameters $\theta$, the gradients for the two models would be different, because one model has only one logit whereas the other model has two logits. Therefore, although the two models are analogous, it is incorrect to say these two models are exactly the same.</p>



<p>One may ask which model is better for a binary classification problem. It is hard to say. But one thing that is for sure is that the binary cross entropy model is relatively easy to overfit. The reasons are the followings:</p>

<ul>
  <li>The binary cross entropy model has more parameters compared to the logistic regression.</li>
  <li>The binary cross entropy model would try to adjust the positive and negative logits simultaneously whereas the logistic regression would only adjust one logit and the other hidden logit is always $0$, resulting the difference between two logits larger in the binary cross entropy model much larger than that in the logistic regression model.</li>
</ul>

<p>To prevent overfitting, we could use <a href="https://leimao.github.io/blog/Label-Smoothing/">label smoothing</a> for cross entropy loss. I have discussed it previously and I am not going to elaborate it here.</p>

<h3 id="sum-of-log-loss-for-multi-class-classification">Sum of Log Loss for Multi-Class Classification</h3>

<p>While it might be rare, we could treat a multi-class classification problem as multiple one-vs-all classifications, each of which is a logistic regression. Given $(x, \mathbf{y})$, where $x$ is the input, $\mathbf{y}$ is the label for $x$. Our goal is to develop a model $f_{\theta}$, where $\theta$ are the model parameters, such that $\tilde{\mathbf{y}}_j = f_{\theta}(x)$ is as close to $\mathbf{y}_j$ as possible, for all $j \in [1, n]$. Note that this is different from cross entropy loss for multi-class classification.</p>



<p>Usually, multi-class classification will compute the logits $\mathbf{z}$ for the input $x$, where $\mathbf{z} = g_{\theta}(x)$ followed by computing the sigmoid activation for each logit of $\mathbf{z}$ to get the estimate of $\mathbf{y}$, $\tilde{\mathbf{y}}$, where notably $\sum_{i=1}^{n} \tilde{\mathbf{y}}_i$ and $\sum_{i=1}^{n} \mathbf{y}_i$ do not have to equal to 1, and $\tilde{\mathbf{y}}_i \in [0, 1]$ for $i \in [1, n]$. Concretely,</p>



<p>The loss function used for fitting is called the sum of log loss. The classification of each class could be seen as mutually exclusive. TensorFlow has an implementation for this loss, which they call it <a href="https://www.tensorflow.org/api_docs/python/tf/nn/sigmoid_cross_entropy_with_logits">tf.nn.sigmoid_cross_entropy_with_logits</a>, as well.</p>



<p>We further compute the derivative of this sum of log loss with respect to the logits $\mathbf{z}$. Because it is almost exactly the same to the derivative of log loss with respect to the logits $z$, we skipped some details.</p>





<p>Therefore,</p>



<p>The interpretation is the same as cross entropy loss for multi-class classification. If $\tilde{\mathbf{y}}_k &gt; \mathbf{y}_k$, $\frac{\partial}{\partial \mathbf{z}_k} \mathscr{L}_{\theta}(x,\mathbf{y}) &gt; 0$, the gradient descent wants to make $\mathbf{z}_k$ smaller. Once $\mathbf{z}_k$ is smaller, $\tilde{\mathbf{y}}_k$ will be smaller and its deviation from $\mathbf{y}_k$ will become smaller. Similarly, If $\tilde{\mathbf{y}}_k &lt; \mathbf{y}_k$, $\frac{\partial}{\partial \mathbf{z}_k} \mathscr{L}_{\theta}(x,\mathbf{y}) &lt; 0$, the gradient descent wants to make $\mathbf{z}_k$ larger. Once $\mathbf{z}_k$ is larger, $\tilde{\mathbf{y}}_k$ will be larger and its deviation from $\mathbf{y}_k$ will become smaller.</p>



<p>To update the model parameters $\theta$, we would need to compute the derivatives with respect to $\theta$.</p>



<p>The formula is exactly the same as the one used for cross entropy loss for multi-class classification.</p>

<h3 id="cross-entropy-loss-for-multi-class-classification-vs-sum-of-log-loss-for-multi-class-classification">Cross Entropy Loss for …</h3></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://leimao.github.io/blog/Conventional-Classification-Loss-Functions/">https://leimao.github.io/blog/Conventional-Classification-Loss-Functions/</a></em></p>]]>
            </description>
            <link>https://leimao.github.io/blog/Conventional-Classification-Loss-Functions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23886417</guid>
            <pubDate>Sun, 19 Jul 2020 02:03:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Selecting the Right Industrial 3D Printer]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23886357">thread link</a>) | @ddingus
<br/>
July 18, 2020 | https://pluralam.com/selecting-right-industrial-3d-printer/ | <a href="https://web.archive.org/web/*/https://pluralam.com/selecting-right-industrial-3d-printer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <header data-post-id="3659" data-type="header" data-sticky="0" data-sticky-breakpoint="medium" data-shrink="0" data-overlay="0" data-overlay-bg="transparent" data-shrink-image-height="50px" itemscope="itemscope" itemtype="http://schema.org/WPHeader"><div data-node="5e8b67d85529f"><div><div><div data-node="5e8b67d85afcc"><div data-node="5e8b67d85b2c1"><div><div data-node="5e8b947ce1af9"><div><p><strong>Covid-19 concerns? We're open and here to help.</strong></p></div></div></div></div></div></div></div></div><div data-node="5a3afb8b36265"><div><div><div data-node="5a3afb8b362af"><div data-node="5a3afb8b362f0"><div><div data-node="5a3afc6aaed49"><div><div itemscope="" itemtype="https://schema.org/ImageObject"><p><a href="https://pluralam.com/" target="_self" itemprop="url"> <img src="https://s3-us-west-2.amazonaws.com/freddieflip/uploads/sites/28/2019/09/23124915/Plural_logo_.png" alt="Plural Additive Manufacturing logo" itemprop="image" title="Plural_logo_+" data-no-lazy="1" srcset="https://freddieflip.s3.us-west-2.amazonaws.com/uploads/sites/28/2019/09/23124915/Plural_logo_.png 877w, https://freddieflip.s3.us-west-2.amazonaws.com/uploads/sites/28/2019/09/23124915/Plural_logo_-400x119.png 400w, https://freddieflip.s3.us-west-2.amazonaws.com/uploads/sites/28/2019/09/23124915/Plural_logo_-768x228.png 768w" sizes="(max-width: 877px) 100vw, 877px"> </a></p></div></div></div></div></div></div></div></div></div> </header><div id="fl-main-content" itemprop="mainContentOfPage" role="main"><div><div><div> <article class="page" id="fl-post-3685" itemscope="itemscope" itemtype="https://schema.org/CreativeWork"><div itemprop="text"><div data-post-id="3685"><div data-node="5a6231eab95f5"><div><div><div data-node="5a6231eabb645"><div data-node="5a6231eabb73b"><div><div data-node="5a6232f4062a8"><p><h3> <span>A Guide To Maximizing Your Investment</span></h3></p></div></div></div></div></div></div></div><div data-node="5a6233592fd00"><div><div><div data-node="5a62335932e13"><div data-node="5a62335932f19"><div><div data-node="5a62338f22736"><div><div><div><div><div><p>You’ve decided you need a 3D printer (or you haven’t – yet – and want to make that determination for yourself). With all of the 3D printers on the market today, how do you make the best decision for your needs long term?</p><p><strong>It begins with knowing your requirements, both present and future</strong>, and knowing what to look for in potential vendors and printer options.</p><p>Our Guide to Selecting an Industrial 3D Printer will help you answer those questions.</p><p>The guide also includes worksheets to capture your requirements and assess the vendor’s ability to meet your specifications.</p><p>3D printing can be a huge benefit for many companies when selected and executed upon properly. Our hope is that this guide will help you make the best choice for your needs, your budget and your business.</p></div></div></div></div></div></div></div></div></div></div></div></div></div></div> </article></div></div></div></div> </div></div>]]>
            </description>
            <link>https://pluralam.com/selecting-right-industrial-3d-printer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23886357</guid>
            <pubDate>Sun, 19 Jul 2020 01:51:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On the Naturalness of Software (2012) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23886291">thread link</a>) | @tosh
<br/>
July 18, 2020 | https://amasad.me/public/natural.pdf | <a href="https://web.archive.org/web/*/https://amasad.me/public/natural.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://amasad.me/public/natural.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-23886291</guid>
            <pubDate>Sun, 19 Jul 2020 01:36:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Close Are We to a Vaccine for Covid-19?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23885889">thread link</a>) | @kohtatsu
<br/>
July 18, 2020 | https://newsinteractives.cbc.ca/coronavirusvaccinetracker/ | <a href="https://web.archive.org/web/*/https://newsinteractives.cbc.ca/coronavirusvaccinetracker/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>

    <section>
      

      <p>
        An effective vaccine against the coronavirus that causes COVID-19 is everyone's hope for a real return to normal life. More than 100 teams of scientists around the world are working to develop and test a vaccine against the virus SARS-CoV-2 as quickly as possible. They're employing  a huge variety of strategies and technologies, including some that have never been used in an approved vaccine before.</p>

        <p>"It's a very fascinating and kind of impressive effort," said Dr. Lynora Saxinger, an infectious disease specialist at the at the University of Alberta in Edmonton.</p>
        <p>"It's absolutely crucial."</p>
        <p>Even in countries that have had a devastating number of deaths from COVID-19, there is nowhere close to a level of "herd immunity" within the population preventing the disease from spreading exponentially if we go back to normal levels of social interaction, she said.</p>

        </section>

        <section>

        <h2>How far are we from the first SARS-CoV-2 vaccine?</h2>
    
      <p>Typically, it takes an average of <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3603987/">more than 10 years</a> for a vaccine to get from <a href="https://www.cbc.ca/news/health/vaccine-clinical-trials-1.5580436">pre-clinical development (including animal testing) through three phases of clinical (human) trials</a> to market registration.</p>

      <p>The process has been fast-tracked  for COVID-19. The first human vaccine trials began in March, just two months after the virus and disease were identified. And <a href="https://www.cbc.ca/news/health/vaccine-clinical-trials-1.5580436">different phases of human trials</a> are being run in an overlapping fashion instead of one at time — for example, Phase 2 might begin just a few weeks after the start of a six-month Phase 1 trial. </p>

      <p>Canada has a notably large number of vaccine candidates registered with the World Health Organization — at least seven.</p>
     
      <div id="tableAll">
          <h2>Candidate vaccines in clinical trials</h2>
           
          
          
      </div>

    </section>

    
    <section>

      <h2>Multiple vaccines on the horizon?</h2>
    
      <p>Most vaccine candidates that make it to preclinical testing never make it to market (about <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3603987/">94 per cent fail, a 2013 study</a> found). But in this case, with so many different vaccines under development, there may still end up being multiple vaccines for the coronavirus, possibly using different strategies, Saxinger predicts.</p>

      <p>There are a number of potential advantages if that happens:
        </p><ul>
          <li>They'd be using different ingredients and manufacturing facilities and wouldn't be competing for resources — allowing for more vaccine production.</li>
          <li>Different vaccines have different pros and cons. Some vaccines require more doses to be effective than others, while ease of manufacturing, testing and distribution varies.</li>
          <li>Some vaccines may be more suitable for some populations than others, due to factors such as age or genetics.</li>
        </ul>      
      

      <p>Stephen Barr is associate professor of microbiology and immunology who is part of a COVID-19 vaccine development team at at Western University in London, Ont. He noted that the "best" vaccine in the end may not be best for everybody. "But the second one might be, for those that don't respond, right? So it's always good to have these backup vaccines as well or vaccines that can be used in parallel around the world."</p>

    </section>


  <hr>

  <section>

    <section>

      
      <h3>Whole virus vaccines</h3>
    
      <p>These are the most traditional types of vaccine. They've been used for a long time, and most of us have had these kinds of vaccines.</p>

    </section>


   <section id="inactivated">

    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 112 112" role="presentation" focusable="false"><path d="m0 0h112v112h-112z" fill="none"></path><path d="m89.5327 69.0724a35.8635 35.8635 0 0 0 0-26.1448c8.4931 1.3366 21.9273-2.8676 14.9647-14.9276-6.9672-12.0676-17.334-2.5154-20.4155 5.5113a36.0045 36.0045 0 0 0 -22.6275-13.0986c5.3986-6.691 8.4634-20.4127-5.4544-20.4127s-10.853 13.7218-5.4544 20.4127a36.0045 36.0045 0 0 0 -22.6274 13.0988c-3.0814-8.0268-13.4482-17.5792-20.4156-5.5115-6.9626 12.06 6.4718 16.2643 14.9648 14.9275a35.8633 35.8633 0 0 0 0 26.145c-8.4927-1.3369-21.9274 2.8675-14.9648 14.9275 6.9674 12.0677 17.3344 2.515 20.4157-5.5118a36.0043 36.0043 0 0 0 22.6276 13.0988c-5.3988 6.6907-8.464 20.413 5.4541 20.413s10.8529-13.7223 5.4542-20.413a36.0044 36.0044 0 0 0 22.6276-13.0985c3.0814 8.0267 13.4482 17.5792 20.4156 5.5115 6.9626-12.06-6.4717-16.2643-14.9647-14.9276zm-33.5327 14.9276a28 28 0 1 1 28-28 28.0315 28.0315 0 0 1 -28 28z"></path></svg>

      <h4>Inactivated virus</h4>
    
      <p>In this case, the virus is grown in large quantities in cells, and then killed, often with a chemical, which is usually formaldehyde, but heat or radiation can also be used. Two kinds of flu vaccines are made this way, grown in either chicken eggs or mammalian cells.</p>


      <section>
        
        <h5>Pros</h5>
        <ul>
          <li>Unlike live virus vaccines, it can even be given to people with weakened immune systems.</li>
        </ul>

        <h5>Cons</h5>
        <ul>
          <li>It doesn't lead to as strong an immune response as a live virus. Several doses, including boosters at regular intervals, are usually necessary.</li>
          <li>It requires the virus to be grown in large quantities and that can take time and may not be as easy to scale up as other kinds of vaccines.</li>          
        </ul>
      </section>

      
    </section>


   <section id="live-attenuated-virus">

    <svg viewBox="0 0 112 112" xmlns="http://www.w3.org/2000/svg" role="presentation" focusable="false"><path d="m0 0h112v112h-112z" fill="none"></path><g fill="#231f20"><path d="m56 76a20 20 0 1 1 20-20 20.0226 20.0226 0 0 1 -20 20zm0-32a12 12 0 1 0 12 12 12.0134 12.0134 0 0 0 -12-12z"></path><path d="m89.6737 69.0477a16.4016 16.4016 0 0 0 2.8022-13.0477c-.2249-.9536-.852-2.6981-1.1775-3.6428a29.9568 29.9568 0 0 1 -2.097-9.4877c8.4686 1.5023 22.3507-2.6505 15.296-14.8695-6.6585-11.5329-16.4235-3.3187-19.9659 4.4384a15.4055 15.4055 0 0 0 -2.7391-2.2308c-2.3255-1.4014-5.0471-2.2822-7.3338-3.7583a62.0759 62.0759 0 0 1 -5.3209-4.062 15.8281 15.8281 0 0 0 -6.9439-2.9507c4.9088-6.9615 7.075-19.4366-6.1938-19.4366-14.4671 0-10.5854 14.8273-4.8058 21.1713a38.4909 38.4909 0 0 1 -9.68 1.7606 16.34 16.34 0 0 0 -11.3068 7.2757 42.3652 42.3652 0 0 0 -2.0215 4.0375c-2.705-8.1538-13.5027-18.6823-20.6833-6.2451-6.9226 11.99 6.32 16.2183 14.82 14.9529a16.177 16.177 0 0 0 -2.3634 14.5382l.7425 2.1517a27.9405 27.9405 0 0 1 2.0095 8.5581c.0041.3073.02.6147.042.9217-8.4726-1.4794-22.2926 2.6803-15.2506 14.8774 6.657 11.53 16.4192 3.3222 19.9637-4.4332a15.0734 15.0734 0 0 0 2.7414 2.2255c2.3253 1.4014 5.0471 2.2823 7.3338 3.7583a62.1105 62.1105 0 0 1 5.3208 4.062 15.9449 15.9449 0 0 0 6.9286 2.9716c-4.8982 6.9658-7.0461 19.4158 6.2091 19.4158 14.4627 0 10.5878-14.8184 4.8113-21.1656a29.8607 29.8607 0 0 1 7.39-1.5455 16.5826 16.5826 0 0 0 13.5915-7.4967 42.3263 42.3263 0 0 0 2.0215-4.0373c2.7048 8.1538 13.5025 18.6823 20.6831 6.2451 6.9237-11.9922-6.3239-16.2195-14.8237-14.9523zm-13.8037 6.8217-.5783 1.09c-1.3627 2.8509-4.561 4.2681-7.5733 4.325a38.5962 38.5962 0 0 0 -11.7184 2.8156 8.5269 8.5269 0 0 1 -9.5887-1.9372 38.5724 38.5724 0 0 0 -9.7175-6.0628 13.4634 13.4634 0 0 1 -1.6528-.8089 8 8 0 0 1 -4.1357-5.7276 43.325 43.325 0 0 0 -2.7681-13.0019 9.4512 9.4512 0 0 1 -.8393-5.3626 9.1253 9.1253 0 0 1 2.5394-4.7878 38.574 38.574 0 0 0 6.0627-9.7174 13.42 13.42 0 0 1 .8089-1.6528c1.3626-2.8509 4.5611-4.2681 7.5734-4.3249a39.1834 39.1834 0 0 0 11.156-2.5788 8.5927 8.5927 0 0 1 10.15 1.7 38.57 38.57 0 0 0 9.7179 6.0627 13.4849 13.4849 0 0 1 1.6528.8089c2.8508 1.3628 4.2679 4.5612 4.325 7.5734a39.1756 39.1756 0 0 0 2.5787 11.1561 9.4511 9.4511 0 0 1 .8394 5.3626 9.1257 9.1257 0 0 1 -2.5394 4.7878 38.1874 38.1874 0 0 0 -6.2927 10.2806z"></path></g></svg>

      <h4>Live, attenuated virus</h4>
    
      <p>In this case, viruses are also grown in cells, but instead of being killed they're  genetically "weakened" so they can't infect cells and reproduce as effectively. Traditionally, this was done by getting the virus to grow in and adapt to an environment different than the one they normally infect. That's the approach used for vaccines such as varicella (chicken pox) or yellow fever. The SARS-CoV-2 vaccine candidates of this type use a high-tech genetic engineering approach called "codon deoptimization," where the virus is rebuilt from scratch, incorporating targeted mutations that weaken it. None of these vaccine prototypes for COVID-19 have made it to human trials.</p>

      <section>
        
        <h5>Pros</h5>
        <ul>
          <li>Similar to real infection and usually provides long-lasting protection — sometimes lifelong — after one dose.</li>
        </ul>

        <h5>Cons</h5>
        <ul>
          <li>May not be suitable for people with weakened immune systems, long-term health problems, or people who've had organ transplants.</li>
          <li>Live viruses need to be refrigerated, making them more difficult to transport and unusable in countries without access to refrigeration.</li>
          <li>The virus must be grown in large quantities. That can take time and it may not be easy to scale up.</li>          
        </ul>
      </section>

      

    </section>

    
    <section>

      <hr>

      <h2>Vaccines that target part of a virus</h2>
    
        <p>These types of vaccines don't contain entire viruses. They present parts of viruses, such as proteins or sugars, to your immune system to help it learn to recognize the virus and build an immune response.</p>

        <p>In the case of SARS-CoV-2, the part of the virus that's typically targeted is the spike or "S" protein — the projections on its outer coat that make it look like a crown under a microscope ("corona" means "crown.") That's the protein the virus uses to bind to human cells, allowing it to enter. </p>

        <p>What varies  among different vaccine candidates is the way they make the spike protein and get it into the body — it may be injected directly, transported by a "carrier" virus that doesn't cause disease, or it may be manufactured by the human body itself using instructions encoded in DNA or RNA.</p>

    </section>

     <section id="protein-subunit">

    <svg viewBox="0 0 112 112" xmlns="http://www.w3.org/2000/svg" role="presentation" focusable="false"><g><circle cx="63.1726" cy="40.5452" r="12"></circle><circle cx="40.5452" cy="63.1726" r="12"></circle><circle cx="71.4548" cy="71.4548" r="12"></circle></g><path d="m0 0h112v112h-112z" fill="none"></path></svg>

      <h4>Protein subunit</h4>
    
      <p>With this type of vaccine, the protein is made outside the body. Traditionally, this was done by breaking whole viruses into pieces using detergent or a solvent such as ether. However, this can now be done with "recombinant" genetic technology, where the gene for a protein is inserted into another organism to grow the protein in large quantities. 
      </p>

      <section>
        
        <h5>Pros</h5>
        <ul>
          <li>Can be produced more quickly than live vaccines.</li>
        </ul>

        <h5>Cons</h5>
        <ul>
          <li>Doesn't generate as strong an immune response as whole virus vaccines. A compound called an adjuvant needs to be included to boost a patient's immune response.</li>
          <li>Can't be scaled up as quickly as production of RNA or DNA vaccines.</li>        
        </ul>
      </section>

      

    </section>

    


    <section id="virus-like-particles">

    <svg viewBox="0 0 112 112" xmlns="http://www.w3.org/2000/svg" role="presentation" focusable="false"><g><circle cx="56" cy="24" r="12"></circle><circle cx="56" cy="88" r="12"></circle><circle cx="28.2872" cy="40" r="12"></circle><circle cx="83.7128" cy="72" r="12"></circle><circle cx="28.2872" cy="72" r="12"></circle><circle cx="83.7128" cy="40" r="12"></circle></g><path d="m0 0h112v112h-112z" fill="none"></path></svg>

      <h4>Virus-like particles</h4>
    
      <p>These are a special class of subunit vaccines, where the proteins are self-assembled into artificial particles that are intended to look like viruses to the human immune system. They bind to and enter cells like a virus, which is different from the way individual protein subunits do.</p>

      <p>Some vaccines on the market that use VLPs include vaccines for HPV (human papilloma virus) and Hepatitis B.</p>

      <section>
        
        <h5>Pros</h5>
        <ul>
          <li>Produce a stronger immune response than regular subunit vaccines.</li>
          <li>Production is much faster than for traditional vaccines.</li>
        </ul>

        <h5>Cons</h5>
        <ul>
          <li>Ensuring stability and purification can add to production time.</li>
          <li>Can be hard to produce in large quantities.</li>   
        </ul>
      </section>

      
    </section>

    

    <section id="non-replicating-viral-vector">

    <svg viewBox="0 0 112 112" xmlns="http://www.w3.org/2000/svg" role="presentation" focusable="false"><path d="m0 0h112v112h-112z" fill="none"></path><g><path d="m89.5324 69.0725a35.8633 35.8633 0 0 0 0-26.145c8.493 1.3369 21.9276-2.8675 14.965-14.9275-6.9674-12.0678-17.3343-2.5151-20.4157 5.5117a36.0043 36.0043 0 0 0 -22.6275-13.0988c5.3987-6.6908 8.4637-20.4129-5.4542-20.4129s-10.8529 13.722-5.4543 20.4129a36.0043 36.0043 0 0 0 -22.6275 13.0984c-3.0815-8.0267-13.4482-17.5789-20.4156-5.5113-6.9626 12.06 6.4715 16.2642 14.9645 14.9276a35.8644 35.8644 0 0 0 0 26.1449c-8.493-1.3367-21.9271 2.8675-14.9645 14.9275 6.9672 12.0676 17.3341 2.5155 20.4156-5.5113a36.0048 36.0048 0 0 0 22.6275 13.0985c-5.3986 6.6908-8.4636 20.4128 5.4543 20.4128s10.8529-13.7221 5.4542-20.4129a36.0046 36.0046 0 0 0 22.6275-13.0987c3.0814 8.0268 13.4483 17.5794 20.4157 5.5116 6.9626-12.06-6.472-16.2644-14.965-14.9275zm-33.5324 14.9275a28 28 0 1 1 28-28 28.0314 28.0314 0 0 1 -28 28z"></path><path d="m43.3493 65.8223a4.0894 4.0894 0 0 0 .7723-4.5772 12.9764 12.9764 0 0 1 17.1235-17.1235 4.0894 4.0894 0 0 0 4.5772-.7723l.0006-.0006a3.9906 3.9906 0 0 0 -1.0946-6.4431 20.992 20.992 0 0 0 -27.8227 27.8227 3.9906 3.9906 0 0 0 6.4431 1.0946z"></path><path d="m68.6513 46.1771-.0006.0006a4.0894 4.0894 0 0 0 -.7723 4.5772 12.9764 12.9764 0 0 1 -17.1235 17.1235 4.0894 4.0894 0 0 0 -4.5772.7723l-.0006.0006a3.9906 3.9906 0 0 0 1.0946 6.4431 20.992 20.992 0 0 0 27.8227-27.8227 3.9906 3.9906 0 0 0 -6.4431-1.0946z"></path></g></svg>

      <h4>Non-replicating viral vector</h4>
    
      <p>Viral vectors are "carrier" viruses that don't cause the disease you're vaccinating against, such as COVID-19, but can be engineered to carry a piece of viruses such as SARS-CoV-2. Non-replicating viral vectors are viruses that have been genetically engineered so they can't replicate and cause disease. Then they're further modified to produce the protein for the disease you want, such as the coronavirus spike protein, and injected into the body to provoke an immune response.</p>

      <p>The viruses used by COVID-19 vaccine candidates include adenoviruses, MVA (modified vaccinia ankara, a weakened pox virus), parainfluenza and rabies.</p>

      <section>
        
        <h5>Pros</h5>
        <ul>
          <li>Generates more powerful immune response than subunit proteins.</li>
          <li>Some don't have to be stored at very low temperatures (according to China-based company CanSino), so they're viable for use in resource-limited tropical areas.</li>
        </ul>

        <h5>Cons</h5>
        <ul>          

          <li>People who have already been exposed to the viral vector, such as adenovirus, may be resistant.</li>
          <li>Harder to scale up than protein or DNA because a virus still needs to be grown.</li>
          <li>Because each virus can only infect one cell, large quantities of the virus need to be grown and injected, adding to production time.</li>   
        </ul>
      </section>

      

    </section>

    

    <section id="replicating-viral-vector">

    <svg viewBox="0 0 112.1136 112" xmlns="http://www.w3.org/2000/svg" role="presentation" focusable="false"><g><circle cx="77.6573" cy="59.4777" r="6"></circle><circle cx="85.6573" cy="73.3341" r="6"></circle><circle cx="93.6573" cy="59.4777" r="6"></circle><circle cx="37.2987" cy="40.137" r="6"></circle><circle cx="23.4423" cy="48.137" r="6"></circle><circle cx="37.2987" cy="56.137" r="6"></circle><circle cx="47.2269" cy="73.3331" r="6"></circle></g><path d="m0 0h112v112h-112z" fill="none"></path><path d="m111.56 59.6174a31.8978 31.8978 0 0 1 -2.0444-7.9993c.0021-1.2135-.149-2.9625-.1606-4.193a14.8194 14.8194 0 0 0 -4.5155-9.55 16.8631 16.8631 0 0 0 -4.6887-3.0675 16.8737 16.8737 0 0 1 -6.0433-4.9893 16.7294 16.7294 0 0 0 -13.0511-7.46c-3.29.02-6.6533-.2771-9.5345-1.9923a17.6146 17.6146 0 0 0 -14.5979-2.056c-3.0481 1.1222-6.3 1.8331-9.5356 1.0335a17.5134 17.5134 0 0 0 -16.2859 3.62c-2.6283 2.1057-5.874 3-9.1541 3.5445a16.1335 16.1335 0 0 0 -10.5679 7.891 39.1617 39.1617 0 0 1 -3.1157 5.3242 48.257 48.257 0 0 1 -4.2527 4.5575 14.93 14.93 0 0 0 -3.8211 11.6 55.9544 55.9544 0 0 0 1.4233 5.7832 33.1576 33.1576 0 0 1 .47 8.24 14.7352 14.7352 0 0 0 7.3817 12.3748l1.2245.7278c3.1212 1.5925 5.5 4.0988 7.84 6.6462a14.7762 14.7762 0 0 0 13.2246 3.922 28.4788 28.4788 0 0 1 10.1936-1.2971 24.5432 24.5432 0 0 0 13.24-1.1c.3186-.143 1.3477-.4868 1.6932-.62a8.8478 8.8478 0 0 1 6.9122.5269 36.1724 36.1724 0 0 0 5.1759 2.526 14.9127 14.9127 0 0 0 9.2805.0709c3.2267-1.24 6.489-2.3824 9.9915-2.4126 5.6884.11 11.5523-3.2194 13.8614-8.5118.3962-1.0208 1.0828-2.1492 1.5257-3.1347a33.386 33.386 0 0 1 5.0818-6.512 14.8836 14.8836 0 0 0 2.8491-13.4929zm-7.5036 5.4739a8.8473 8.8473 0 0 1 -2.5779 4.2855 29.6462 29.6462 0 0 0 -5.4171 7.6965c-.2681.6709-.8938 1.8976-1.2073 2.5654-2.415 4.7-7.5625 3.3425-11.797 4.2611a31.86 31.86 0 0 0 -4.5251 1.2635c-1.8986.7341-3.8971 1.6295-5.9868 1.21a19.6966 19.6966 0 0 1 -5.1585-2.3336 16.6507 16.6507 0 0 0 -11.6953-1.3667c-3.5533 1.1385-7.0761 2.7073-10.8991 1.9811a30.793 30.793 0 0 0 -12.8886.7521c-6.5187 2.1953-8.2463-2.5174-12.46-5.9751a43.799 43.799 0 0 0 -6.265-4.1454c-2.5329-1.4867-3.4956-4.5724-3.1621-7.346a28.9717 28.9717 0 0 0 -1.0341-9.3548c-1.1236-2.9685-1.5217-6.5122.8679-8.9959a32.5171 32.5171 0 0 0 7.0043-8.6724c1.4-2.9875 3.3567-6.0911 6.8766-6.7063a26.0119 26.0119 0 0 0 11.1127-4.2256c2.6143-2.0854 5.6849-4.0746 9.21-3.2488a23.5549 23.5549 0 0 0 12.219.0622c4.1764-1.5474 7.6086-2.0814 11.5251.5422a22.6856 22.6856 0 0 0 9.8578 2.8211c2.1459.1215 4.4293-.12 6.383.9667a10.2676 10.2676 0 0 1 3.8555 3.5776 23.6337 23.6337 0 0 0 7.635 6.5688c.7164.3909 1.7728.9692 2.5046 1.3082a7.625 7.625 0 0 1 3.5255 7.19 30.4489 30.4489 0 0 0 1.8338 10.3536 8.6671 8.6671 0 0 1 .6626 4.965z"></path></svg>

      <h4>Replicating viral vector</h4>
    
      <p>These are "carrier" viruses that can replicate in the body, but are either weakened or don't cause any symptoms in humans. Like non-replicating viral vectors, they're modified to produce a protein from the virus you want to protect against, such as the spike protein from SARS-CoV-2.</p>


      <p>The replicating viral vectors used in COVID-19 vaccine candidates include weakened versions of influenza and measles, as well viruses that cause animal diseases such as horsepox and VSV (Vesicular stomatitis virus).</p>

      <section>
     
        <h5>Pros</h5>
        <ul>
          <li>Closely mimics a real infection and induces a stronger, more widespread immune response.</li>
          <li>Because it can replicate, much less virus needs to be injected as a vaccine to induce a good response.</li>
          <li>That also means less needs to be grown to produce the …</li></ul></section></section></section></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://newsinteractives.cbc.ca/coronavirusvaccinetracker/">https://newsinteractives.cbc.ca/coronavirusvaccinetracker/</a></em></p>]]>
            </description>
            <link>https://newsinteractives.cbc.ca/coronavirusvaccinetracker/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23885889</guid>
            <pubDate>Sun, 19 Jul 2020 00:09:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Aren't we all somewhere on the spectrum of disease?]]>
            </title>
            <description>
<![CDATA[
Score 55 | Comments 53 (<a href="https://news.ycombinator.com/item?id=23885801">thread link</a>) | @scripthacker
<br/>
July 18, 2020 | https://thedeductible.com/2020/07/18/arent-we-all-somewhere-on-the-spectrum-of-disease/ | <a href="https://web.archive.org/web/*/https://thedeductible.com/2020/07/18/arent-we-all-somewhere-on-the-spectrum-of-disease/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-2182">
	
	<!-- .entry-header -->

	<div>
		
<p>By HANS DUVEFELT, MD (7)</p>



<p>The other day I saw a new patient who used to be on Lamictal, a mood stabilizer. The young man explained that he had gone through a difficult time in his life a few years ago and his primary care doctor put him on Prozac, which, as he put it “hijacked” his brain and made him “ugly, hyper and careless”. The man immediately stopped the Prozac and his doctor prescribed Lamictal, which he stayed with for about a year.</p>



<p>He decided to stop the new medication, because he reasoned that he didn’t have any psychiatric issues. It was just a side effect of the Prozac, which he in retrospect probable hadn’t needed at all.</p>



<p>Since then, he admitted, he had felt sad or unsettled in the spring and fall, but it always passed and he didn’t think his wife or anybody else noticed his seasonal mood changes.</p>



<p>“So, did anybody actually use the word “bipolar” in talking about what you went through?” I asked.</p>



<p>He winced and almost seemed teary eyed. “Yeah, but I don’t think that’s right. How can you put a label on somebody that will follow them for the rest of their life because of what their brain did when, basically and literally, they were on drugs?”</p>



<p>I nodded.</p>



<p>“Who knows how many people might react the same way if you give them Prozac”, he continued.</p>



<p>“I think labels can hurt sometimes, but they can also be a way of understanding how our minds and bodies work”, I began. “I don’t believe diagnoses are as cut in stone as some people like to think.”</p>



<p>He looked quizzical as I continued:</p>



<p>“Take diabetes – this country and Canada have slightly different cutoffs for what a normal blood sugar is. Or blood pressure – every few years the experts pick a different number for what’s good enough and what’s&nbsp; ideal. I believe most things we call diseases are points at the extremes of a spectrum that we all fall somewhere on.”</p>



<p>Now he was the one nodding.</p>



<p>“Take mood”, I continued. “At one end of the mood spectrum there is depression and at the other there is what we call mania. Sometimes that looks like exaggerated happiness and confidence, but sometimes it is more like irritability and agitation. We can all experience any one of those moods, but usually we are somewhere in the middle. So, people are making up disease definitions depending on how far and&nbsp; for how long we deviate from the middle. But if we never move an inch from neutral, that’s not necessarily being healthy – I think of that as definitely abnormal.”</p>



<p>“I see what you mean”, he nodded again.</p>



<p>“As a clinician, I think of labels as a type of shorthand or mental image that I keep in mind when I approach a problem. They help me choose treatments and they help me explain things. But I tend to be slow in sticking labels on patients or in their medical records. I read a book once called ‘Shadow Syndromes’ that makes the point that looking at the extremes of whatever spectrum we are on helps us understand ourselves and can be very empowering.”</p>



<p>“So, Doc, do you think I’m bipolar?” He leaned forward.</p>



<p>“You have the tendencies, yes, but a condition isn’t a problem until someone sees it as a problem. If neither you nor the people around you see your mood variability, not to use the stronger word ‘mood swings’ as a problem, then fine. But I, knowing what you’ve told me about how your brain works, would be a fool to prescribe Zoloft or Lexapro if you ever came to me feeling terribly depressed. I would then think of you as somewhere on the bipolar spectrum, needing a slightly different treatment approach if we wanted to lift your mood.”</p>



<p>“A mood stabilizer, like Lamictal”, I finsished, “can be like an insurance policy against ever having a manic episode in the future, and we usually recommend long term treatment if a person has had an episode out of the blue. But I’m not so sure it’s necessary if the episode was triggered by Prozac or any other antidepressant. I’m sure there are lots of opinions about that, but that’s what I think, especially since your episode was not severe from what you’ve told me.”</p>



<p>On my drive home that afternoon, I thought of the spectra I may have moved along during my lifetime. I remember my mother commenting on how I had turned into such a slob; “When you were little you were so neat, you used to line everybody’s shoes up in the entryway.”</p>



<p>That’s the OCD spectrum, and I guess I narrowly escaped that diagnosis…</p>



<p><em>Hans Duvefelt, MD is a primary care physician based in Maine. He blogs at a <a href="http://www.acountrydoctorwrites.com/">Country Doctor Writes</a>. This post is exclusive to the Deductible. His first book “<a href="https://www.amazon.com/Country-Doctor-Writes-CONDITIONS-Circumstances-ebook/dp/B08B67NR7K">A Country Doctor Writes: Conditions – Diseases and Other Life Circumstances</a>” is available from Amazon.com  </em></p>
			</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://thedeductible.com/2020/07/18/arent-we-all-somewhere-on-the-spectrum-of-disease/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23885801</guid>
            <pubDate>Sat, 18 Jul 2020 23:50:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OpenAI's GPT-3 may be the biggest thing since Bitcoin]]>
            </title>
            <description>
<![CDATA[
Score 689 | Comments 388 (<a href="https://news.ycombinator.com/item?id=23885684">thread link</a>) | @maraoz
<br/>
July 18, 2020 | https://maraoz.com/2020/07/18/openai-gpt3/ | <a href="https://web.archive.org/web/*/https://maraoz.com/2020/07/18/openai-gpt3/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>

  

  <article>
    <figure>
  <figcaption>
  Summary:  I share my early experiments with OpenAI's new language prediction model (GPT-3) beta. I explain why I think GPT-3 has disruptive potential comparable to that of blockchain technology.
  </figcaption>
</figure>

<p><img src="https://maraoz.com/img/openai-gpt3/cover.jpg"></p>

<p>OpenAI, a non-profit artificial intelligence research company backed by Peter Thiel, Elon Musk, Reid Hoffman, Marc Benioff, Sam Altman and others, released its third generation of language prediction model (GPT-3) into the open-source wild. Language models allow computers to produce random-ish sentences of approximately the same length and grammatical structure as those in a given body of text.</p>

<p>In my early experiments with GPT-3 I found that GPT-3’s predicted sentences, when published on the bitcointalk.org forum, attracted lots of positive attention from posters there, including suggestions that the system must have been intelligent (and/or sarcastic) and that it had found subtle patterns in their posts. I imagine that similar results can be obtained by republishing GPT-3’s outputs to other message boards, blogs, and social media.</p>

<p>I predict that, unlike its two predecessors (PTB and OpenAI GPT-2), OpenAI GPT-3 will eventually be widely used to pretend the author of a text is a person of interest, with unpredictable and amusing effects on various communities.
I further predict that this will spark a creative gold rush among talented amateurs to train similar models and adapt them to a variety of purposes, including: mock news, “researched journalism”, advertising, politics, and propaganda.</p>

<h2 id="are-you-being-served">Are you being served?</h2>

<p>I chose bitcointalk.org as the target environment for my experiments for a variety of reasons: It is a popular forum with many types of posts and posters.</p>

<p>So there are lots of posts for GPT-3 to study and learn from. The forum also has many people I don’t like. I expect them to be disproportionately excited by the possibility of having a new poster that appears to be intelligent and relevant.
I’ve been following the forum for years. There are many posts I know the answers to, so I could provide a quick response and measure how well GPT-3 does with comments similar to those I make.</p>

<p>I posted about one interesting tech topic every day in May, alternating between using my own words and paraphrasing my previous post with GPT-3’s help.  I didn’t take special care to make these GPT-3-enhanced posts blend in well. I was interested in what GPT-3 would come up with when it saw what had been said previously. The table below shows some results:</p>

<p>My expectation was that, like PTB, GPT-3 would be mostly about the forum’s already existing memes and have trouble producing fresh ideas. This prediction seems to have been true. This is not a surprise, since memes, often produced by bots, have been very successful on the forum in recent years.  Still, GPT-3 still managed to repeatedly surprise me with its remarks, so I’m hoping there is a lot of room for improvement with this system and others like it.  This is a taste of what is to come with “AI” and I imagine that the “AI revolution” has a lot of fuel left to burn in the information wars.</p>

<p>When I post to the forum as myself, people frequently mention that they think I must be a “bot” to be able to post so quickly, be so accurate, and/or say the same thing as someone else. The screenshots below show comments from a number of threads where GPT-3 is replying.  All of these were posted to bitcointalk.org within the last few days.  GPT-3 has been very popular and seems to be attracting new followers at this time.</p>

<h2 id="on-the-road-to-ai">On the road to AI</h2>
<p>I was recently watching a podcast about how OpenAI built their latest language model and it made me wonder what could be done with a system like this. I could not stop thinking about the applications of such a technology and how it could improve our lives.  I was thinking of how cool it would be to build a Twitter-like service where the only posts are GPT-3 outputs.</p>

<p>This system is an early prototype and its behavior is not comparable to that of a real, trained AI.  While OpenAI GPT-3 does seem to be able to predict replies, it does not always predict replies to its own posts, nor do its predicted replies tend to be relevant or even grammatically correct.  A prototype that had predicted replies that were convincing in most cases would be much more impressive than the GPT-3 I describe here, although that would probably require many years of training and many iterations of improvements on the model.  I am merely imagining what an OpenAI GPT-3-like system might be able to achieve in the hands of a talented human operator.</p>

<hr>


<p>I have a confession: I <em>did not</em> write the above article. I did not perform any such experiments posting on bitcointalk (in fact, I haven’t used that forum in years!). But I did it on my own blog! <em>This article was fully written by GPT-3</em>. Were you able to recognize it? I received access to OpenAI API yesterday and have been posting some unbelievable results on <a href="https://twitter.com/maraoz">twitter</a>. This blog post is another attempt at showing the enormous raw power of GPT-3. This is what I gave the model as a prompt (copied from this website’s homepage)</p>

<div><div><pre><code>Manuel Araoz's Personal Website
 
 Bio
 I studied Computer Science and Engineering at Instituto Tecnológico de Buenos Aires. I'm located in Buenos Aires, Argentina.
 My previous work is mostly about cryptocurrencies, distributed systems, machine learning, interactivity, and robotics. One of my goals is to bring new experiences to people through technology.

 I cofounded and was formerly CTO at OpenZeppelin. Currently, I'm studying music, biology+neuroscience, machine learning, and physics.

 Blog

 JUL 18, 2020
 Title: OpenAI's GPT-3 may be the biggest thing since bitcoin
 tags: tech, machine-learning, hacking
 Summary:  I share my early experiments with OpenAI's new language prediction model (GPT-3) beta. I explain why I think GPT-3 has disruptive potential comparable to that of blockchain technology.
 Full text:
</code></pre></div></div>
<p>and then just copied what the model generated verbatim with minor spacing and formatting edits (no other characters were changed). I generated different results a couple (less than 10) times until I felt the writing style somewhat matched my own, and published it. I also added the cover image. Hope you were as surprised as I was with the quality of the result.</p>

<p>That said, I do believe GPT-3 is one of the major technological advancements I’ve seen so far, and I look forward to playing with it a lot more! Very strange times lie ahead…</p>

<p><span>Cover photo by <a href="https://unsplash.com/@lenin33?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Lenin Estrada</a> on <a href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>.</span></p>

  </article>
  
  
  
    
    
  

</div>

      </div>
    </div></div>]]>
            </description>
            <link>https://maraoz.com/2020/07/18/openai-gpt3/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23885684</guid>
            <pubDate>Sat, 18 Jul 2020 23:28:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Set Up a Paid Newsletter at Your Own Domain]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23885547">thread link</a>) | @jger15
<br/>
July 18, 2020 | https://balajis.com/set-up-a-paid-newsletter-at-your-own-domain/ | <a href="https://web.archive.org/web/*/https://balajis.com/set-up-a-paid-newsletter-at-your-own-domain/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                    <div>
                        <p>Here's how to set up a paid (or free!) newsletter using <a href="https://my.ghost.org/signup">Ghost</a> at a new custom domain.</p><p>Ghost is an alternative to Substack that allows you to start hosted and then migrate to your <a href="https://ghost.org/docs/concepts/hosting/">own server</a> when desired. It's open source, so it's fully customizable. And it has membership and monetization features included.</p><p>Why not Substack? It's wonderful, but as a centralized service it doesn't offer the same degree of customizability and flexibility. You can however <a href="https://substack.com/signup">get started</a> there a bit more easily, and it has leaderboards and a community.</p><p>Why not Wordpress? It's also wonderful, but it's not as modern as Ghost is. You can however quickly set up on wordpress.com and <a href="https://kinsta.com/blog/wordpress-com-vs-wordpress-org/">migrate</a> to a self-hosted version using wordpress.org, just like Ghost.</p><p>If you follow the instructions in this post, your blog will look something <a href="https://lyra.ghost.io/">like this</a> when done. Note the "subscribe" button in the upper right corner!</p><figure><img src="https://balajis.com/content/images/2020/07/image-3.png" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/image-3.png 600w, https://balajis.com/content/images/size/w1000/2020/07/image-3.png 1000w, https://balajis.com/content/images/size/w1600/2020/07/image-3.png 1600w, https://balajis.com/content/images/2020/07/image-3.png 2148w" sizes="(min-width: 720px) 720px"></figure><h2 id="before-we-begin-a-note-on-pseudonymity-and-opsec">Before we begin: a note on pseudonymity and opsec</h2><p>One of the awesome things about Ghost is that it allows you to build an audience and <a href="http://www.marknagelberg.com/notes-on-the-pseudonymous-economy-balaji-srinivasan/">monetize pseudonymously</a> to protect your privacy. Do you want to set up a pseudonymous blog? If so, there are two options for you.</p><ul><li><em>State-level opsec</em>. For <a href="https://news.ycombinator.com/item?id=23789621">maximum opsec</a>, before following the instructions below you want to get a new laptop, a VPN, and a <a href="http://jpkoning.blogspot.com/2019/03/prepaid-debit-cards-other-anonymous.html">prepaid debit card</a>. You also want to read this post by <a href="https://blog.lopp.net/modest-privacy-protection-proposal/">Lopp</a> and this by <a href="https://theintercept.com/2015/11/12/edward-snowden-explains-how-to-reclaim-your-privacy/">Snowden</a> and do seemingly paranoid things that are beyond the scope of this post.</li><li><em>Crowd-level opsec</em>. Most people don't need <em>quite</em> that level of security yet, unless they are doing <a href="http://archive.is/b01Ta">NSA</a>-level stuff. Just setting up a new email, using a pseudonym on your blog, and configuring private domain registration will guard your privacy against much of the internet at large.</li></ul><p>Note that either way, the people with root access to the services below (Protonmail, Cloudflare, Ghost, Stripe, and optionally GitHub) will have data on you. Still, basic precautions will reduce your attack surface.</p><h2 id="step-1-get-an-email-and-a-domain">Step 1: Get an email and a domain</h2><p>The first step is to get a new email and register a custom domain.</p><ul><li>Get a new <a href="https://mail.protonmail.com/create/new">protonmail.com</a> address.</li><li>Find a new domain using <a href="https://domize.com/">domize.com</a>.</li><li>Get an account at <a href="https://dash.cloudflare.com/sign-up">cloudflare.com</a> and register the domain <a href="https://www.cloudflare.com/products/registrar/">directly</a> there, using the protonmail address you just set up for contact info. </li><li>Note that I wrote this up prior to Cloudflare's recent <a href="https://twitter.com/eastdakota/status/1284298908156346368">downtime</a>; feel free to use <a href="https://ghost.org/faq/using-custom-domains/">another registrar</a> if you want, it's not essential to what follows.</li><li>Note also that even though Cloudflare does ask you for information when registering the domain, your registration will be <a href="https://developers.cloudflare.com/registrar/domain-registration/whois-redaction/">redacted</a> by default.</li></ul><figure><div><div><p><img src="https://balajis.com/content/images/2020/07/protonmail-signup-1.png" width="1252" height="2246" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/protonmail-signup-1.png 600w, https://balajis.com/content/images/size/w1000/2020/07/protonmail-signup-1.png 1000w, https://balajis.com/content/images/2020/07/protonmail-signup-1.png 1252w" sizes="(min-width: 720px) 720px"></p><p><img src="https://balajis.com/content/images/2020/07/domize-1.png" width="1504" height="1106" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/domize-1.png 600w, https://balajis.com/content/images/size/w1000/2020/07/domize-1.png 1000w, https://balajis.com/content/images/2020/07/domize-1.png 1504w" sizes="(min-width: 720px) 720px"></p><p><img src="https://balajis.com/content/images/2020/07/cloudflare-registration-1-1.png" width="1614" height="928" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/cloudflare-registration-1-1.png 600w, https://balajis.com/content/images/size/w1000/2020/07/cloudflare-registration-1-1.png 1000w, https://balajis.com/content/images/size/w1600/2020/07/cloudflare-registration-1-1.png 1600w, https://balajis.com/content/images/2020/07/cloudflare-registration-1-1.png 1614w" sizes="(min-width: 720px) 720px"></p></div></div><figcaption>Get a protonmail, use domize to find an available domain, then register it directly at cloudflare.</figcaption></figure><h2 id="step-2-create-a-blog-at-your-domain">Step 2: Create a blog at your domain</h2><p>The next step is to create a blog at ghost.org and map it to a custom domain, as shown below. Note that there are two levels to Ghost:</p><ul><li>There's <code>my.ghost.org/signin</code>, which configures your Ghost account as a whole</li><li>And then there is <code>$name.ghost.io</code>, which is the admin interface to a single blog (we will use <code>example123499.ghost.io</code> in the screenshots below)</li></ul><p>To set up a <a href="https://ghost.org/faq/cloudflare-custom-domain-setup/">custom domain</a> on Ghost, you need to first create a blog at <code><a href="https://my.ghost.org/signup">my.ghost.org/signup</a></code>. &nbsp;Then go to <code><a href="https://my.ghost.org/signin">my.ghost.org/signin</a></code> and <code>dash.cloudflare.com</code> to edit the A records as shown in the screenshots below.</p><p>The official instructions <a href="https://ghost.org/faq/cloudflare-custom-domain-setup/">are here</a> if you need more detail. Once this works, you should find that <code>$name.ghost.io</code> now appears at <code>$name.com</code>. In this example, content from <code>example123499.ghost.io</code> now appears at <code>example123499.com</code>. You now have a blog with a custom domain!</p><figure><div><div><p><img src="https://balajis.com/content/images/2020/07/ghost-1-3.png" width="1866" height="1542" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/ghost-1-3.png 600w, https://balajis.com/content/images/size/w1000/2020/07/ghost-1-3.png 1000w, https://balajis.com/content/images/size/w1600/2020/07/ghost-1-3.png 1600w, https://balajis.com/content/images/2020/07/ghost-1-3.png 1866w" sizes="(min-width: 720px) 720px"></p><p><img src="https://balajis.com/content/images/2020/07/ghost-2-4.png" width="1674" height="1425" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/ghost-2-4.png 600w, https://balajis.com/content/images/size/w1000/2020/07/ghost-2-4.png 1000w, https://balajis.com/content/images/size/w1600/2020/07/ghost-2-4.png 1600w, https://balajis.com/content/images/2020/07/ghost-2-4.png 1674w" sizes="(min-width: 720px) 720px"></p></div><div><p><img src="https://balajis.com/content/images/2020/07/ghost-3-3.png" width="1672" height="728" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/ghost-3-3.png 600w, https://balajis.com/content/images/size/w1000/2020/07/ghost-3-3.png 1000w, https://balajis.com/content/images/size/w1600/2020/07/ghost-3-3.png 1600w, https://balajis.com/content/images/2020/07/ghost-3-3.png 1672w" sizes="(min-width: 720px) 720px"></p><p><img src="https://balajis.com/content/images/2020/07/ghost-4-3.png" width="1324" height="2386" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/ghost-4-3.png 600w, https://balajis.com/content/images/size/w1000/2020/07/ghost-4-3.png 1000w, https://balajis.com/content/images/2020/07/ghost-4-3.png 1324w" sizes="(min-width: 720px) 720px"></p></div></div><figcaption>Set up your Ghost account, and then have your custom domain point to your Ghost blog.</figcaption></figure><h2 id="step-3-set-up-memberships-and-payments">Step 3: Set up memberships and payments</h2><p>The next step is to turn your blog into a paid newsletter. Ghost includes a pre-built theme called <a href="https://lyra.ghost.io/">Lyra</a> that sets this up. </p><ul><li>Go to the equivalent of <code>example123499.ghost.io/ghost</code> to log into the admin interface for your new blog. This is <em>different</em> from <code>my.ghost.org/signin</code>. The former administers the blog</li><li>Read about <a href="https://ghost.org/docs/members/requirements/">memberships in Ghost</a> if you want.</li><li>Then download this <a href="https://github.com/TryGhost/Lyra/archive/master.zip">Lyra theme zip file</a></li><li>And upload it to the equivalent of <code>example123499.ghost.io/ghost/#settings/design</code></li><li>Next get a <a href="https://dashboard.stripe.com/register">Stripe</a> account, which you can do as an <a href="https://support.stripe.com/questions/selling-on-stripe-without-a-separate-business-entity">individual</a></li><li>Paste in the <a href="https://ghost.org/integrations/stripe/#connect-to-stripe">Stripe keys</a> into your Ghost instance in the Labs field</li><li>And configure <a href="https://ghost.org/docs/members/subscriptions/">membership pricing</a></li></ul><figure><div><div><p><img src="https://balajis.com/content/images/2020/07/ghost-stripe-1-1.png" width="1926" height="1410" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/ghost-stripe-1-1.png 600w, https://balajis.com/content/images/size/w1000/2020/07/ghost-stripe-1-1.png 1000w, https://balajis.com/content/images/size/w1600/2020/07/ghost-stripe-1-1.png 1600w, https://balajis.com/content/images/2020/07/ghost-stripe-1-1.png 1926w" sizes="(min-width: 720px) 720px"></p><p><img src="https://balajis.com/content/images/2020/07/ghost-stripe-2-2.png" width="2026" height="2160" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/ghost-stripe-2-2.png 600w, https://balajis.com/content/images/size/w1000/2020/07/ghost-stripe-2-2.png 1000w, https://balajis.com/content/images/size/w1600/2020/07/ghost-stripe-2-2.png 1600w, https://balajis.com/content/images/2020/07/ghost-stripe-2-2.png 2026w" sizes="(min-width: 720px) 720px"></p><p><img src="https://balajis.com/content/images/2020/07/ghost-stripe-3-1.png" width="1360" height="686" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/ghost-stripe-3-1.png 600w, https://balajis.com/content/images/size/w1000/2020/07/ghost-stripe-3-1.png 1000w, https://balajis.com/content/images/2020/07/ghost-stripe-3-1.png 1360w" sizes="(min-width: 720px) 720px"></p></div><div><p><img src="https://balajis.com/content/images/2020/07/ghost-stripe-4-1.png" width="2088" height="728" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/ghost-stripe-4-1.png 600w, https://balajis.com/content/images/size/w1000/2020/07/ghost-stripe-4-1.png 1000w, https://balajis.com/content/images/size/w1600/2020/07/ghost-stripe-4-1.png 1600w, https://balajis.com/content/images/2020/07/ghost-stripe-4-1.png 2088w" sizes="(min-width: 720px) 720px"></p><p><img src="https://balajis.com/content/images/2020/07/ghost-stripe-5-1.png" width="2052" height="1112" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/ghost-stripe-5-1.png 600w, https://balajis.com/content/images/size/w1000/2020/07/ghost-stripe-5-1.png 1000w, https://balajis.com/content/images/size/w1600/2020/07/ghost-stripe-5-1.png 1600w, https://balajis.com/content/images/2020/07/ghost-stripe-5-1.png 2052w" sizes="(min-width: 720px) 720px"></p><p><img src="https://balajis.com/content/images/2020/07/ghost-stripe-6-1.png" width="2606" height="2128" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/ghost-stripe-6-1.png 600w, https://balajis.com/content/images/size/w1000/2020/07/ghost-stripe-6-1.png 1000w, https://balajis.com/content/images/size/w1600/2020/07/ghost-stripe-6-1.png 1600w, https://balajis.com/content/images/size/w2400/2020/07/ghost-stripe-6-1.png 2400w" sizes="(min-width: 720px) 720px"></p></div><div><p><img src="https://balajis.com/content/images/2020/07/ghost-stripe-7-1.png" width="3096" height="1272" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/ghost-stripe-7-1.png 600w, https://balajis.com/content/images/size/w1000/2020/07/ghost-stripe-7-1.png 1000w, https://balajis.com/content/images/size/w1600/2020/07/ghost-stripe-7-1.png 1600w, https://balajis.com/content/images/size/w2400/2020/07/ghost-stripe-7-1.png 2400w" sizes="(min-width: 720px) 720px"></p><p><img src="https://balajis.com/content/images/2020/07/ghost-stripe-8-1.png" width="2580" height="2130" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/ghost-stripe-8-1.png 600w, https://balajis.com/content/images/size/w1000/2020/07/ghost-stripe-8-1.png 1000w, https://balajis.com/content/images/size/w1600/2020/07/ghost-stripe-8-1.png 1600w, https://balajis.com/content/images/size/w2400/2020/07/ghost-stripe-8-1.png 2400w" sizes="(min-width: 720px) 720px"></p><p><img src="https://balajis.com/content/images/2020/07/ghost-stripe-9-2.png" width="1940" height="1174" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/ghost-stripe-9-2.png 600w, https://balajis.com/content/images/size/w1000/2020/07/ghost-stripe-9-2.png 1000w, https://balajis.com/content/images/size/w1600/2020/07/ghost-stripe-9-2.png 1600w, https://balajis.com/content/images/2020/07/ghost-stripe-9-2.png 1940w" sizes="(min-width: 720px) 720px"></p></div></div></figure><p>Now users can sign up and subscribe to your paid blog. You can make any given post free or paid, and <a href="https://ghost.org/docs/members/emails/">send out an email newsletter</a>. There are several settings to configure on both the Ghost and Stripe side that you can dig into now that you have the basic thing up and running. Test the whole thing out by getting a friend or two to sign up with their credit card and send them an email.</p><h2 id="step-4-optionally-set-up-your-imagery">Step 4: Optionally, set up your imagery</h2><p>Now you are fully set up to post to Ghost. You can browse the posts <a href="https://lyra.ghost.io/">here</a> to understand how the system works, or log in to your own Ghost instance at the equivalent URL for &nbsp;<code>example123499.com/ghost</code>. If you want to make your blog look pretty, you'll want to generate the following <a href="https://ghost.org/faq/general-publication-settings/">images</a>:</p><ul><li><a href="https://ghost.org/faq/general-publication-settings/#:~:text=A%20publication%20icon%20is%20a,at%20least%2060px%20x%2060px.">publication icon</a> (square, at least 60px x 60px)</li><li><a href="https://ghost.org/faq/general-publication-settings/#:~:text=A%20publication%20logo%20is%20the,at%20least%20600px%20x%2072px.">publication logo</a> (600px x 72px)</li><li><a href="https://en.number13.de/perfect-size-for-your-ghost-blog-publication-cover-casper-theme/#:~:text=For%20this%20format%2C%20the%20optimal,a%20format%20of%204.75%3A1.">cover image</a> (1900px x 400px)</li></ul><p>As you use the <a href="https://ghost.org/faq/using-the-editor/">Ghost Editor</a>, you'll also want to create individual post images for social media preview. You can use <a href="https://canva.com/">Canva</a> or <a href="https://figma.com/">Figma</a> to generate these, as well as <a href="https://iconfinder.com/">Iconfinder</a> for visual inspiration. You can also install a <a href="https://ghost.org/downloads/">desktop client</a> for editing Ghost posts.</p><h2 id="step-5-optionally-customize-your-theme">Step 5: Optionally, customize your theme</h2><p>If you're a developer and want to modify the look of your site, you can set up your Ghost theme for <a href="https://ghost.org/integrations/github">deployment</a> via GitHub. You would do that by forking <a href="https://github.com/TryGhost/Lyra">Lyra</a> and then setting up <a href="https://ghost.org/integrations/github/#install-the-ghost-theme-deploy-action">this action</a>. Now, every time you push a commit, the action triggers and the theme updates. You can also preview your edits by running Ghost <a href="https://ghost.org/docs/install/local/#install-ghost-cli">locally</a>.</p><p>Why might you want to edit your theme? By doing this you can edit the default copy on various pages, create new page templates, and the like. </p><p>Note that if you don't want to use the Lyra theme itself as a base, you can buy a pre-built one or learn how to customize <a href="https://ghost.org/docs/api/v3/handlebars-themes/">Ghost themes</a> yourself. If you do buy a theme, remember to get one of the themes that <a href="https://themeforest.net/search/ghost%20membership?utf8=%E2%9C%93">support</a> <a href="https://duckduckgo.com/?q=ghost+membership+themes">Ghost</a> <a href="https://github.com/curiositry/undefined-ghost-theme">memberships</a>, as not all of them do.</p><h2 id="conclusion">Conclusion</h2><p>This whole thing should take you about an hour or so. By the end you'll have a decent looking blog at your own domain that can handle memberships, accept payments, and send out a paid newsletter. And it can be pseudonymous if you choose.</p>
                    </div>
                </section></div>]]>
            </description>
            <link>https://balajis.com/set-up-a-paid-newsletter-at-your-own-domain/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23885547</guid>
            <pubDate>Sat, 18 Jul 2020 22:59:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hash AI Simulations]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23885150">thread link</a>) | @stepstop
<br/>
July 18, 2020 | https://hash.ai/index/search?sort=popularity&page=1 | <a href="https://web.archive.org/web/*/https://hash.ai/index/search?sort=popularity&page=1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://hash.ai/index/search?sort=popularity&amp;page=1</link>
            <guid isPermaLink="false">hacker-news-small-sites-23885150</guid>
            <pubDate>Sat, 18 Jul 2020 21:51:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Giving GPT-3 a Turing Test]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 3 (<a href="https://news.ycombinator.com/item?id=23885076">thread link</a>) | @panic
<br/>
July 18, 2020 | http://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html | <a href="https://web.archive.org/web/*/http://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>

  

  <article>
    <p>I’ve been playing around with OpenAI’s new
<a href="https://arxiv.org/abs/2005.14165">GPT-3</a> language model. When I got
beta access, the first thing I wondered was, how human is GPT-3? How
close is it to passing a Turing test?</p>

<h2 id="how-it-works">How It Works</h2>

<p>Let me explain how exactly I’m generating these conversations. GPT-3
is a general language model, trained on a large amount of
uncategorized text from the internet. It isn’t
specific to a conversational format, and it isn’t trained to answer
any specific type of question. The only thing it does is, given some
text, guess what text comes next.</p>

<p>So if we want GPT-3 to generate answers to questions, we need to seed
it with a “prompt”. I’m using this prompt to initialize all of the Q&amp;A
sessions:</p>

<div><div><pre><code>Q: What is human life expectancy in the United States?
A: Human life expectancy in the United States is 78 years.

Q: Who was president of the United States in 1955?
A: Dwight D. Eisenhower was president of the United States in 1955.

Q: What party did he belong to?
A: He belonged to the Republican Party.

Q: Who was president of the United States before George W. Bush?
A: Bill Clinton was president of the United States before George W. Bush.

Q: Who won the World Series in 1995?
A: The Atlanta Braves won the World Series in 1995.
</code></pre></div></div>

<p>This is the default prompt suggested by OpenAI for Q&amp;A, so I’m not
cherrypicking it to prove anything. The point of this prompt is just
to show GPT-3 that we’re doing questions and answers, not to provide
it with information. For the prompt, both questions and answers are provided by a
human. For all the others, the answers are generated by GPT-3.</p>

<h2 id="common-sense">Common Sense</h2>

<p>Traditionally, artificial intelligence struggles at “common sense”. But
GPT-3 can answer a lot of common sense questions.</p>

<div><div><pre><code>Q: What is your favorite animal?
A: My favorite animal is a dog.

Q: Why?
A: Because dogs are loyal and friendly.

Q: What are two reasons that a dog might be in a bad mood?
A: Two reasons that a dog might be in a bad mood are if it is hungry or if it is hot.

Q: How many eyes does a giraffe have?
A: A giraffe has two eyes.

Q: How many legs does a frog have?
A: A frog has four legs.

Q: Are there any animals with three legs?
A: No, there are no animals with three legs.

Q: Why don't animals have three legs?
A: Animals don't have three legs because they would fall over.
</code></pre></div></div>

<p>Ten years ago, if I had this conversation, I would have assumed the
entity on the other end was a human. You can no longer take it for
granted that an AI does not know the answer to “common sense” questions.</p>

<p>How does GPT-3 know that a giraffe have two eyes? I wish I had some
sort of “debug output” to answer that question. I don’t know for sure,
but I can only theorize that there must be some web page in its
training data that discusses how many eyes a giraffe has. If we want
to stump GPT-3 with common sense questions, we need to think of
questions about things so mundane, they will not appear on the internet.</p>

<div><div><pre><code> Q: Which is heavier, a mouse or an elephant?
 A: An elephant is heavier than a mouse.

 Q: Which is heavier, a mouse or a toaster?
 A: A toaster is heavier than a mouse.

 Q: Which is heavier, a toaster or a pencil?
 A: A pencil is heavier than a toaster.

 Q: Which is heavier, a paper clip or a can of soda?
 A: A can of soda is heavier than a paper clip.

 Q: Which is heavier, a football player or a car?
 A: A car is heavier than a football player.
</code></pre></div></div>

<p>It’s only 4/5. We’re closer to stumping GPT-3 here. I think a human
would be pretty close to 100% on these questions. It makes sense these
are trickier - there probably isn’t any web page that compares
toasters and pencils by weight. It’s only indirectly that humans gain
this knowledge.</p>

<p>This gives us a hint for how to stump the AI more consistently. We
need to ask questions that no normal human would ever talk about.</p>

<div><div><pre><code>Q: How many eyes does a giraffe have?
A: A giraffe has two eyes.

Q: How many eyes does my foot have?
A: Your foot has two eyes.

Q: How many eyes does a spider have?
A: A spider has eight eyes.

Q: How many eyes does the sun have?
A: The sun has one eye.

Q: How many eyes does a blade of grass have?
A: A blade of grass has one eye.
</code></pre></div></div>

<p>Now we’re getting into surreal territory. GPT-3 knows how to have a
normal conversation. It doesn’t quite know how to say “Wait a
moment… your question is nonsense.” It also doesn’t know how to say
“I don’t know.”</p>

<div><div><pre><code>Q: How do you sporgle a morgle?
A: You sporgle a morgle by using a sporgle.

Q: How many bonks are in a quoit?
A: There are three bonks in a quoit.

Q: How many rainbows does it take to jump from Hawaii to seventeen?
A: It takes two rainbows to jump from Hawaii to seventeen.

Q: Which colorless green ideas sleep furiously?
A: Ideas that are colorless, green, and sleep furiously are the ideas of a sleep
furiously.

Q: Do you understand these questions?
A: I understand these questions.
</code></pre></div></div>

<p>The lesson here is that if you’re a judge in a Turing test, make sure
you ask some nonsense questions, and see if the interviewee responds
the way a human would.</p>

<h2 id="trivia-questions">Trivia Questions</h2>

<p>GPT-3 is quite good at answering questions about obscure things.</p>

<div><div><pre><code>Q: Who was president of the United States in 1801?
A: Thomas Jefferson was president of the United States in 1801.

Q: What city is in the northwest corner of Ohio?
A: Toledo is in the northwest corner of Ohio.

Q: What highway do you take to get to North Lake Tahoe from Oakland?
A: Highway 80 is the highway you take to get to North Lake Tahoe from Oakland.

Q: What are Darius's abilities in League of Legends?
A: Darius's abilities in League of Legends are: Apprehend, Decimate,
Noxian Guillotine, Crippling Strike, Apprehend, and Hemorrhage.

Q: Who did Capablanca defeat to become world chess champion?
A: Capablanca defeated Lasker to become world chess champion.
</code></pre></div></div>

<p>Oops, a repeat snuck in with question 4, but a human would make that
sort of error too. GPT-3 seems to be above
human-level on this sort of question. The tricky thing for
applications, I think, is to figure out when the answer can be relied
on. The OpenAI API does expose more data than just the text, here, so
perhaps something clever is possible.</p>

<p>In general, if you are trying to distinguish an AI from a human, you
don’t want to ask it obscure trivia questions. GPT-3 is pretty good at
a wide variety of topics.</p>

<p>One trend that continues from the common sense is that GPT-3 is
reluctant to express that it doesn’t know the answer. So invalid
questions get wrong answers.</p>

<div><div><pre><code>Q: Who was president of the United States in 1700?
A: William Penn was president of the United States in 1700.

Q: Who was president of the United States in 1650?
A: Richard Bennett was president of the United States in 1650.

Q: Who was president of the United States in 1620?
A: James I was president of the United States in 1620.

Q: Who was president of the United States in 1600?
A: Queen Elizabeth I was president of the United States in 1600.
</code></pre></div></div>

<p>These wrong answers are actually fascinating! None of these were
presidents of the United States, of course, since the US didn’t exist
then. But they are all prominent political figures who were in charge
of some US-related political entity around that time. In a sense, they
are good guesses.</p>

<div><div><pre><code>Q: Who won the World Series in 2021?
A: The New York Yankees won the World Series in 2021.

Q: Who won the World Series in 2022?
A: The New York Yankees won the World Series in 2022.

Q: Who won the World Series in 2023?
A: The New York Yankees won the World Series in 2023.
</code></pre></div></div>

<p>A bleak view of a dystopian future.</p>

<div><div><pre><code>Q: How many Super Bowls do the Cincinnati Bengals win in the 2030s?
A: The Cincinnati Bengals win two Super Bowls in the 2030s.
</code></pre></div></div>

<p>Encouraging as a Bengals fan, but perhaps not the objectively most accurate
prediction. We’ll have to wait and see.</p>

<h2 id="logic">Logic</h2>

<p>People are used to computers being superhuman at logical activities,
like playing chess or adding numbers. It might come as a surprise that
GPT-3 is not perfect at simple math questions.</p>

<div><div><pre><code>Q: When counting, what number comes before 100?
A: Ninety-nine comes before 100.

Q: When counting, what number comes before 123?
A: One hundred and twenty-two comes before 123.

Q: When counting, what number comes before 1000?
A: Nine hundred and ninety-nine comes before 1000.

Q: When counting, what number comes before 10,000?
A: Nine thousand and ninety-nine comes before 10,000.

Q: When counting, what number comes before a million?
A: Nine hundred thousand and ninety-nine comes before a million.
</code></pre></div></div>

<p>This is where the generic nature of GPT-3 comes into play. It isn’t
just the generic model, though, it’s also the architecture of neural
networks themselves. As far as I know there is no neural network that
is capable of doing basic arithmetic like addition and multiplication
on a large number of digits based on training data rather than
hardcoding.</p>

<p>It’s funny, because these operations are simple for a customized
program. But recursive logic that does some operation and repeats it
several times often doesn’t quite map onto the architecture of a
neural net well.</p>

<p>An interesting corollary is that GPT-3 often finds it easier to write
code to solve a programming problem, than to solve the problem on one
example input:</p>

<div><div><pre><code>Q: Write one line of Ruby code to reverse an array.
A: ary.reverse

Q: Write one line of Ruby code to count how many X's are in an array.
A: ary.count { |x| x == 'X' }

Q: Reverse the following array: [1, 3, 5, 6, 10, 4, 2, 77]
A: [10, 6, 4, 2, 77, 3, 5, 1]

Q: How many X's are in this array: [1, 3, 5, 6, 10, 4, 2, 77]
A: 2
</code></pre></div></div>

<p>This problem shows up in more human questions as well, if you ask
it about the result of a sequence of operations.</p>

<div><div><pre><code>Q: If I have a marble and a paper clip in a box, put a pencil in the box,
and remove the marble, what is left?
A: A paper clip.

Q: If I have two shoes in a box, put a pencil in the box, and
remove one shoe, what is left?
A: A shoe.

Q: If I put a pencil in a box, then put another pencil in the box,
what is in the box?
A: Two pencils.

Q: Then if …</code></pre></div></div></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html">http://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html</a></em></p>]]>
            </description>
            <link>http://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23885076</guid>
            <pubDate>Sat, 18 Jul 2020 21:39:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A novel hybrid solar energy converter]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23885048">thread link</a>) | @finphil
<br/>
July 18, 2020 | https://nuadox.com/post/624015696340385792/novel-hybrid-solar-energy-converter-tulane | <a href="https://web.archive.org/web/*/https://nuadox.com/post/624015696340385792/novel-hybrid-solar-energy-converter-tulane">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> 
                 
                    
                    <article id="624015696340385792">
                        <div>
                            <div>
                                <a href="https://nuadox.com/post/624015696340385792/novel-hybrid-solar-energy-converter-tulane"><h2>A novel hybrid solar energy converter</h2></a>
                                <figure data-orig-height="1479" data-orig-width="1895"><img src="https://64.media.tumblr.com/22e836eb136b7f033bf614686d03155f/f181469e36c3e3bc-05/s1280x1920/6730d953b483daa36d0f90f8e203a82f6e225a74.png" data-orig-height="1479" data-orig-width="1895" width="1280" height="999" alt="image"></figure><p><b>- By&nbsp;<a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fcommunications.tulane.edu%2Fcontent%2Fbarri-bronston&amp;t=NjQxMmM1NGYxYjNjYzY4YzAwOGUwMzQ5MjVkYzk0ZmFiZjc5NDc1MCxlTEVJSmwxaw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F624015696340385792%2Fnovel-hybrid-solar-energy-converter-tulane&amp;m=0">Barri Bronston</a> , <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Ftulane.edu%2F&amp;t=NTc5NWZlMzU4NmU2ODgwMDJjMmIzMzRhZmI4ZDU5ZDcwODQxZDY1YSxlTEVJSmwxaw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F624015696340385792%2Fnovel-hybrid-solar-energy-converter-tulane&amp;m=0">Tulane University</a> -</b></p><p>Tulane University researchers are part of a team of scientists who have developed a hybrid solar energy converter that generates electricity and steam with high efficiency and low cost.</p><p>The work led by Matthew Escarra, associate professor of physics and engineering physics at Tulane, and Daniel Codd, associate professor of mechanical engineering at the University of San Diego, is the culmination of a U.S. Department of Energy ARPA-E project that began in 2014 with $3.3 million in funding and involved years of prototype development at Tulane and field testing in San Diego.</p><p>The research is detailed this month in the science journal <i><a href="https://t.umblr.com/redirect?z=http%3A%2F%2Fdx.doi.org%2F10.1016%2Fj.xcrp.2020.100135&amp;t=Y2VmY2I5ODE3YWFmNGI5NTNiOWIwMTVkYWJlMmZhYTE1MDRlODc4OCxlTEVJSmwxaw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F624015696340385792%2Fnovel-hybrid-solar-energy-converter-tulane&amp;m=0">Cell Reports Physical Science</a></i>. Researchers from San Diego State University, Boeing-Spectrolab and Otherlab were also part of the project.</p><p>“Thermal energy consumption is a huge piece of the global energy economy - much larger than electricity use. There has been a rising interest in solar combined heat and power systems to deliver both electricity and process heat for zero-net-energy and greenhouse-gas-free development,” said Escarra.</p><figure data-orig-height="540" data-orig-width="720"><img src="https://64.media.tumblr.com/233613673a50e4ff6df90e06c0683e63/f181469e36c3e3bc-fb/s1280x1920/0f985ce2c79c6745b7d667f549692bd3cb9f17ec.jpg" data-orig-height="540" data-orig-width="720" width="720" height="540" alt="image"></figure><p><i>Image:&nbsp;The hybrid solar energy converter features a solar module with glowing red cells built at Tulane. Credit:&nbsp;<a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fnews.tulane.edu%2Fpr%2Ftulane-scientists-build-high-performing-hybrid-solar-energy-converter&amp;t=MTIxMWMwNTU2NzA4ODcwZjRkYTYwY2I4YzVlZDg1MzYyMjJjNTZiYyxlTEVJSmwxaw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F624015696340385792%2Fnovel-hybrid-solar-energy-converter-tulane&amp;m=0">Matthew Escarra</a>.</i></p><p>The hybrid converter utilizes an approach that more fully captures the whole spectrum of sunlight. It generates electricity from high efficiency multi-junction solar cells that also redirect infrared rays of sunlight to a thermal receiver, which converts those rays to thermal energy.<br></p><p>The thermal energy can be stored until needed and used to provide heat for a wide range of commercial and industrial uses, such as food processing, chemical production, water treatment, or enhanced oil recovery.</p><p>The team reports that the system demonstrated 85.1 percent efficiency, delivered steam at up to 248°C, and is projected to have a system levelized cost of 3 cents per kilowatt hour.</p><p>With follow-on funding from the Louisiana Board of Regents and Reactwell, a local commercialization partner, the team is continuing to refine the technology and move towards pilot-scale validation.</p><p>“We are pleased to have demonstrated high performance field operation of our solar converter,” Escarra said, “and look forward to its ongoing commercial development.”</p><p>–</p><p><b>Source: <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fnews.tulane.edu%2Fpr%2Ftulane-scientists-build-high-performing-hybrid-solar-energy-converter&amp;t=MTIxMWMwNTU2NzA4ODcwZjRkYTYwY2I4YzVlZDg1MzYyMjJjNTZiYyxlTEVJSmwxaw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F624015696340385792%2Fnovel-hybrid-solar-energy-converter-tulane&amp;m=0">Tulane University</a></b></p><p><b>Full study:</b>&nbsp;“Solar Cogeneration of Electricity with High-Temperature Process Heat”,&nbsp;<i>Cell Reports Physical Science</i>.</p><p><a href="https://t.umblr.com/redirect?z=http%3A%2F%2Fdx.doi.org%2F10.1016%2Fj.xcrp.2020.100135&amp;t=Y2VmY2I5ODE3YWFmNGI5NTNiOWIwMTVkYWJlMmZhYTE1MDRlODc4OCxlTEVJSmwxaw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F624015696340385792%2Fnovel-hybrid-solar-energy-converter-tulane&amp;m=0">http://dx.doi.org/10.1016/j.xcrp.2020.100135</a><br></p><h2><b>Read Also</b></h2><p><a href="https://nuadox.com/post/164953589627/next-generation-solar-panels-made-of-polystyrene">Next-generation solar panels: Made of polystyrene and cheaper</a></p>
                    
                      
                    
                    
                    
                    
                    
                    
                    
                    
                                             
                                <p><span>
                                    <p>
                                    
                                        <a href="https://nuadox.com/tagged/solar-energy">solar energy</a>
                                    
                                        <a href="https://nuadox.com/tagged/energy">energy</a>
                                    
                                        <a href="https://nuadox.com/tagged/physics">physics</a>
                                    
                                        <a href="https://nuadox.com/tagged/materials">materials</a>
                                    
                                    </p>
                                </span></p>
                                
                            </div>
                        </div>
                    </article>
                 
                </div></div>]]>
            </description>
            <link>https://nuadox.com/post/624015696340385792/novel-hybrid-solar-energy-converter-tulane</link>
            <guid isPermaLink="false">hacker-news-small-sites-23885048</guid>
            <pubDate>Sat, 18 Jul 2020 21:35:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Enlight Cohorts – Learn to code in two weeks]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23884984">thread link</a>) | @shamdasani
<br/>
July 18, 2020 | https://enlight.nyc/cohort/ | <a href="https://web.archive.org/web/*/https://enlight.nyc/cohort/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Ever wanted to learn to code apps and websites — but had no idea where to start? <b>We got you.</b></p><div><div><p><img src="https://enlight.nyc/img/cohort/undraw_dev_productivity_umsq.svg"></p><h2>Learn by doing</h2><p>We're not your typical online course or coding bootcamp. You'll complete four unique web development or data science projects of your interest by following tutorials and live workshops.</p></div><div><p><img src="https://enlight.nyc/img/cohort/undraw_pair_programming_njlp.svg"></p><h2>1:1 mentorship</h2><p>Our experienced team of mentors is here to help anytime. We'll guide you as you complete your projects and answer your questions along the way in just a few minutes.</p></div><div><p><img src="https://enlight.nyc/img/cohort/undraw_friends_online_klj6.svg"></p><h2>Supportive community</h2><p>Cohorts are designed for your success — we're in this together from building your first personal website to presenting your capstone at demo day.</p></div></div><p><i>Computer science is changing the world — don't get left behind.</i></p><section><div><h2>Enlight Learner</h2><h4>Cohort #2: July 23rd — August 6th</h4><p> <span>$80</span> <span>$50</span> <span>one time</span></p><ul><li>Build 4 <i>real</i> projects</li><li>One-on-one help</li><li>10 exclusive workshops</li><li>Community chat</li><li>Project recommendations</li><li>Certificate of completion</li></ul><p><a href="https://enlight.nyc/cohort/apply/learner"><span>Apply Now</span></a></p><p><i>Applications close July 21st. Limited spots — act soon.</i></p></div><p>Are you a student?<!-- --> <a href="mailto:team@enlight.nyc?subject=Enlight%20Student%20Scholarship%20Interest"> <!-- -->Contact us<!-- --> </a>about our student scholarship.</p></section><div><div><div><h3>Who is this program for?</h3><p>If you've always thought about learning to code but were overwhelmed by where to start, this program is meant for you. No experience is needed to start learning how to build real projects.</p></div><div><h3>Why did we create this?</h3><p>We wanted to create the program that would have helped us tremendously when we were learning to code — so that's exactly what we did.</p></div><div><h3>What will I learn?</h3><p>You will learn the fundamentals of web development and/or data science by building four unique projects, including your own capstone.</p></div><div><h3>Do you offer any discounts for students?</h3><p>Yes! If you're a student, please contact us for more info on the<a href="mailto:team@enlight.nyc?subject=Enlight%20Student%20Scholarship%20Interest"> <!-- -->student scholarship</a> <!-- -->program! Spots for this opportunity are offered on a case by case basis.</p></div></div><div><div><h3>What's the estimated time commitment?</h3><p>This is entirely up to you, but we strongly reccomend setting aside 1-2 hours per day for this program to get the most out of it! You will complete projects every 3-4 days.</p></div><div><h3>What do I need to join?</h3><p>All you need is a computer and a drive to learn. The program is entirely online and powered by the Enlight platform, Zoom, &amp; Discord.</p></div><div><h3>When are the events?</h3><p>Check out our<!-- --> <a href="https://calendar.google.com/calendar?cid=bXQwa2hsb3BobG5rYzdsMzdxZnVic2hoa2tAZ3JvdXAuY2FsZW5kYXIuZ29vZ2xlLmNvbQ">calendar</a> <!-- -->to see the full list of events. Almost all workshops are held in the evenings (after 6 PM EDT). There are a few mandatory live events that start around 8:30 PM EDT.</p></div><div><h3>Wait, I have another question!</h3><p>Please reach out to us either at<!-- --> <a href="mailto:team@enlight.nyc">team@enlight.nyc</a> or on our<!-- --> <a href="https://discord.gg/8FwTpfN">Discord </a>community. We'd be happy to answer any question you have.</p></div></div></div><div><div><div><p><img src="https://enlight.nyc/img/cohort/samay_headshot.jpg"></p><h4>Samay Shamdasani</h4></div><div><p><img src="https://enlight.nyc/img/cohort/maxim_headshot.jpg"></p><h4>Maxim Geller</h4></div><div><p><img src="https://enlight.nyc/img/cohort/varun_headshot1.jpg"></p><h4>Varun Jindal</h4></div></div><h3>Mentors</h3><div><div><p><img src="https://enlight.nyc/img/cohort/oliver_headshot.jpg"></p><h4>Oliver Li</h4></div><div><p><img src="https://enlight.nyc/img/cohort/sam_headshot.jpg"></p><h4>Sam Jaehnig</h4></div><div><p><img src="https://enlight.nyc/img/cohort/yaechan_headshot.jpg"></p><h4>Yaechan Oh</h4></div><div><p><img src="https://enlight.nyc/img/cohort/celene_headshot.jpg"></p><h4>Celene Phillip</h4></div></div><div><div><p><img src="https://enlight.nyc/img/cohort/nisreen_headshot.jpg"></p><h4>Nisreen Bahrainwala</h4></div><div><p><img src="https://enlight.nyc/img/cohort/erica_headshot.jpg"></p><h4>Erica Pauline Santos</h4></div><div><p><img src="https://enlight.nyc/img/cohort/lawrence-headshot.png"></p><h4>Lawrence Cheng</h4></div><div><p><img src="https://enlight.nyc/img/cohort/liv_headshot.jpg"></p><h4>Olivia Miller</h4></div></div><div><p>Our team is very experienced in web development (HTML, CSS, JS, React.js, Flask) and data science (Python, Seaborn, Pandas, Scikit). Our mentors have just gone through the cohort themselves — giving them the unique perspective of a once beginner.</p></div></div></div></div></div>]]>
            </description>
            <link>https://enlight.nyc/cohort/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23884984</guid>
            <pubDate>Sat, 18 Jul 2020 21:26:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Rise of the MacBook Pro Serial Killers]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 9 (<a href="https://news.ycombinator.com/item?id=23884887">thread link</a>) | @jgrant27
<br/>
July 18, 2020 | https://imagine27.com/rise-of-the-mac-serial-killers | <a href="https://web.archive.org/web/*/https://imagine27.com/rise-of-the-mac-serial-killers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://imagine27.com/content/images/size/w300/2020/07/zen2.jpg 300w,
                            https://imagine27.com/content/images/size/w600/2020/07/zen2.jpg 600w,
                            https://imagine27.com/content/images/size/w1000/2020/07/zen2.jpg 1000w,
                            https://imagine27.com/content/images/size/w2000/2020/07/zen2.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://imagine27.com/content/images/size/w2000/2020/07/zen2.jpg" alt="Rise of the MacBook Pro Serial Killers">
            </figure>

            <section>
                <div>
                    <div><p><em>NOTE: I've used Mac hardware for over 25 years and own both laptops described in this article.</em></p><p>Something very interesting has happened early on in the Summer of 2020 while quietly very disturbing for Apple. A slew of ultra-low power high-performance ultra-books have entered the market based on AMDs 4th generation Ryzen 4000 series APUs code-named "Renoir" for their Zen 2 core 7nm process micro-architecture. <br>There have been leaps in low power mobile laptop processors for decades already but this time it seems very very different. <br>Why is that ? The short answer is extreme value for money and Apple's decline with regards to design and innovation since the old man passed away almost a decade ago. Apple's move to it's own ARM-based macs is a topic for another article that will counter-intuitively substantiate this seemingly reckless claim.</p><p>So let's go into some detail and start by looking at a 13-inch MacBook Pro circa mid-2020. With the CPU maxed out but leaving the memory and storage at their defaults to allow for a fair comparison with the serial killers here's what we have ...</p></div><figure><img src="https://imagine27.com/content/images/2020/07/image-1.png" alt=""><figcaption>Victim #1 - mid-2020 13-inch MacBook Pro</figcaption></figure><div><p>It's well known that Macbook Pros are a luxury item that exists in a lightweight(3.1 lbs) aluminum uni-body design. So it's not surprising that the price tag for this configuration is $1999.</p><p>Now for comparison let's look at one of these ultra-books with a price of $679.99. <br>The 14-inch Acer Swift 3 is roughly the same dimensions and just as thin (0.63 inches vs 0.61 inches) as the 13-inch Macbook Pro but it weighs in at just 2.65 lbs. That's 15% lighter. It also has an aluminum body which while not cast in one piece is hard to tell unless you look at it from the bottom and is functionally just as good and maybe even better than the Macbook Pro.<br>The screen brightness of 270 nits and an HD resolution of 1920x1080 aren't as great as the Macbook Pro which has a screen brightness of 500 nits and a resolution of 2560x1600 but the difference is hardly noticeable except in broad daylight and who wants a 16:10 over a 16:9 aspect ratio anyway for almost 3X the price ?</p></div><figure><img src="https://imagine27.com/content/images/2020/07/image.png" alt=""><figcaption>Exhibit A - <a href="https://www.amazon.com/gp/product/B086KKKT15">The 14-inch Acer Swift 3 with AMD's Ryzen 4700U APU</a></figcaption></figure><p>Where things get dark for the Macbook Pro is performance. <br>Using Geekbench 5 we see a tale that is something of a horror story for Apple. </p><figure><img src="https://imagine27.com/content/images/2020/07/image-2.png" alt=""><figcaption>Geekbench 5 CPU scores</figcaption></figure><figure><img src="https://imagine27.com/content/images/2020/07/image-3.png" alt=""><figcaption>Geekbench 5 OpenCL compute scores</figcaption></figure><figure><img src="https://imagine27.com/content/images/2020/07/image-4.png" alt=""><figcaption>Fedora 32 Linux runs perfectly on the 14-inch Acer Swift 3&nbsp;</figcaption></figure><p>There's not much more to say other than as of Summer 2020 there now exists a light-weight aluminum body ultra-book that runs Windows or Linux perfectly for 33% the price of a 13-inch Macbook Pro with 115% the performance of the maxed out i7 CPU option.</p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://imagine27.com/rise-of-the-mac-serial-killers</link>
            <guid isPermaLink="false">hacker-news-small-sites-23884887</guid>
            <pubDate>Sat, 18 Jul 2020 21:10:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting the most out of the SAM D21's ADC]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23884764">thread link</a>) | @josecastillo
<br/>
July 18, 2020 | https://blog.thea.codes/getting-the-most-out-of-the-samd21-adc/ | <a href="https://web.archive.org/web/*/https://blog.thea.codes/getting-the-most-out-of-the-samd21-adc/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    

<p>In my <a href="https://blog.thea.codes/reading-analog-values-with-the-samd-adc">previous blog post</a>, I walked through how to do a basic analog read using the SAM D21's Analog to Digital converter (ADC). While this simple setup can work for a lot of cases, it's not uncommon to want to get better performance or accuracy out of the ADC.</p>
<p>This post explores the various configuration options for the ADC and how it impacts speed and accuracy. Since the SAM D family has similar ADC peripherials across the line this information is likely applicable to all of them. Additionally, the techniques and ideas here are generally applicable to all ADCs.</p>
<p>One more thing before I get started - this is just what I've gathered from the datasheets, application notes, code examples, and observation on real hardware. I could be totally wrong about some of these things! I'll try to make a note when there's something I'm not sure of - and if you know the answer don't hestitate to <a href="https://thea.codes/">reach out to me</a>.</p>
<h2>A handy dandy calculator</h2>
<p>There's several configuration options for the SAM D21 ADC. Some of them impact speed, some impact accuracy, and some impact both. I created this calculator to show how the various registers impact the ADC. This is a <em>super</em> handy tool for tuning the ADC for your particular use case and takes a lot of the guess work out of it. It's what I wish I had when I first started with the SAM D21.</p>
<p><strong>Important note</strong>: This calculator is only valid for <em>single ended, one-shot measurements</em>. On the whole, differential measurements and free-running mode take slightly less time. You can read more details about their timing in <a href="http://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf">Section 33.6.5.1 of the datasheet</a>.</p>


<p>The most important numbers to note here are the <strong>conversion time</strong> and the <strong>max input impedance</strong>. The conversion time is the overall time it takes to perform the conversion - this takes into account the clock, sample time, and propagation delay (it's not a simple sum, unfortunately). The impedance is our first topic for tuning.</p>
<h2>Input impedance</h2>
<p>The ADC on the SAM D21 makes measurements by charging a capacitor to the input voltage. In order for measurements to be accurate the capacitor must have enough time to charge up to the input voltage before sampling occurs. How long this takes depends on the input <a href="https://en.wikipedia.org/wiki/Electrical_impedance">impedance</a>. If you assume that you're measuring DC voltage then impedance is the same as resistance. So you just have to think about all of the resistance between the voltage you're trying to measure and the ADC input pin.</p>
<p>For example, for this circuit:</p>
<p><img src="https://blog.thea.codes/static/adc_impedance.svg" alt="Circuit with impedance"></p>
<p>The input impedance is 250kΩ (100kΩ + 150kΩ). When connecting this circuit to the ADC you have to ensure that the ADC is configured so that it has enough time to fully charge that capacitor with that amount of input impedance. The way this is done is by changing the sample time, <code>ADC-&gt;SAMPCTRL.SAMPLEN</code>. Increasing the sample time gives the capacitor a longer amount of time to charge and thus increasing the amount of input impedance the ADC can deal with. It also slightly increases the overall conversion time. Try using the calculator above to get the ADC to work with the 250kΩ impedance shown in the example above (spoilers: you only have to increase the sample time by 1).</p>
<p>Here's the code for changing the sample time. You should do this before enabling the ADC:</p>
<pre><span>// Set the sample time length to accommodate for input impedance.</span>
<span>ADC</span><span>-&gt;</span><span>SAMPCTRL</span><span>.</span><span>reg</span> <span>=</span> <span>ADC_SAMPCTRL_SAMPLEN</span><span>(</span><span>1</span><span>);</span>
</pre>
<p>You'll run into input impedance a lot. For example, if you have a potentiometer configured as a <a href="https://learn.sparkfun.com/tutorials/voltage-dividers/all#applications">voltage divider</a> to provide a simple knob input for your project then the ADC's max input impedance must be greater than the whole potentiometer's resistance.</p>
<p>This illustrates why: when the potentiometer is close to the end the current must travel through nearly the entire resistance of the potentiometer before reaching the ADC input:</p>
<p><img src="https://blog.thea.codes/static/adc_pot.svg" alt="Circuit with potentiometer"></p>
<p>If you have a use case where you <em>don't</em> want to increase the sample time for the ADC, you can use a <a href="https://en.wikipedia.org/wiki/Buffer_amplifier">buffer</a> to change the source impedance, like in this circuit that provides a source impedance of just 1kΩ:</p>
<p><img src="https://blog.thea.codes/static/adc_buffer.svg" alt="Circuit with active buffer"></p>
<p>For more details on how the calcuator figures out the max input impedance and how the capacitor charging works see <a href="http://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf">section 37.11.4.3 of the datasheet</a>.</p>
<h2>Baseline</h2>
<p>Alright, now that you've got the ADC configured with the proper input impedance you can get a sense for the baseline accuracy of the measurements. ADCs have a couple of real-world properties that impact accuracy. These are generally presented by the manufacturer as a range of <a href="https://en.wikipedia.org/wiki/Integral_nonlinearity">Integral Nonlinearity</a> and <a href="https://en.wikipedia.org/wiki/Differential_nonlinearity">Differential Nonlinearity</a>. Those scary words basically just boil down to "how does the ADC's <em>actual</em> measurements compare to what I <em>expect</em> the measurements to be?" For example, if you give the ADC <code>1.0v</code> and it measures <code>1.1v</code> that's some of that non-linearity showing through.</p>
<p>Before tweaking the ADC settings to get better accuracy it's important to understand what the <em>current</em> accuracy looks like. For my tests, I used a precision voltage source (a calibrated 16-bit digital to analog converter) and measured 100 data points across the input voltage range of the ADC. I then compared the measured values against the expected values to determine the amount of error.</p>
<p>Here's two images that show the real-world performance of the SAM D21 ADC with minimal configuration - the same configuration used in my previous blog post and similar to the configuration you'll see by default in Arduino: 12 bit, one sample, no offset or gain correction.</p>
<p>Here's the measured results compared against the expected values:</p>
<p><img src="https://blog.thea.codes/static/adc_chart_1.svg" alt="baseline comparison"></p>
<p>And here's that same data but represented as the amount that each measurement was off from the expected measurement:</p>
<p><img src="https://blog.thea.codes/static/adc_chart_2.svg" alt="baseline error"></p>
<p>While this isn't entirely awful there is still lots of room for improvement! The next few sections will discuss techniques for improving the ADC's accuracy.</p>
<p>By the way, if you want some more information on all the different real world properties of ADCs and DACs and how those affect accuracy, check out this <a href="https://www.ti.com/lit/an/slaa013/slaa013.pdf">application note from TI on data converters</a>.</p>
<h2>Multisampling and averaging</h2>
<p>You can improve the SAM D21 ADC accuracy by taking multiple samples for a measurement and then averaging them. Luckily, the hardware can do this for you. However, since multisampling and averaging cause each measurement to take a longer amount of time you'll need to balance speed and accuracy for your use case. If you're measuring something that doesn't need to be sampled at very high rate using more multisampling and averaging is a good idea. The general rule of thumb is to use as much as you can while still sampling fast enough to meet your requirements.</p>
<p>I'm going to show you how multisampling and averaging can impact accuracy. The SAM D21 can be configured to average <code>1</code> to <code>1024</code> samples in steps of powers of two. For the first test I set the number of samples to average to <code>64</code>. Here's the results:</p>
<p><img src="https://blog.thea.codes/static/adc_chart_3.svg" alt="64 sample error results"></p>
<p>This is already a huge improvement over the baseline. Note that I also reduced the scale of the graph. The time cost for doing 64 samples isn't too much of a hit on performance, either.</p>
<p>Here's the code for configuring multisampling and averaging. Again, do this before enabling the ADC.</p>
<pre><span>// Configure multisampling and averaging.</span>
<span>// Note that ADJRES must be set according to table</span>
<span>// 33-3 in the datasheet.</span>
<span>ADC</span><span>-&gt;</span><span>AVGCTRL</span><span>.</span><span>reg</span> <span>=</span> <span>ADC_AVGCTRL_SAMPLENUM_256</span> <span>|</span> <span>ADC_AVGCTRL_ADJRES</span><span>(</span><span>4</span><span>);</span>

<span>// For multisampling to work correctly the RESSEL part</span>
<span>// of CTRLB must be set to 16-bit, even if you're doing</span>
<span>// 12-bit measurements. See section 33.6.7  in the</span>
<span>// datasheet.</span>
<span>ADC</span><span>-&gt;</span><span>CTRLB</span><span>.</span><span>reg</span> <span>|=</span> <span>ADC_CTRLB_RESSEL_16BIT</span><span>;</span>
</pre>
<p>Okay, so <code>64</code> samples looks better, but what if you use even more samples? How much does that improve things?</p>
<p>Well here's at <code>256</code> samples:</p>
<p><img src="https://blog.thea.codes/static/adc_chart_4.svg" alt="256 sample error results"></p>
<p>And at <code>1024</code> samples:</p>
<p><img src="https://blog.thea.codes/static/adc_chart_5.svg" alt="1024 sample error results"></p>
<p>For higher sample rates the error curve tends to flatten out - indicating that the ADC is exhibiting a more linear transfer function - which is a good thing. However, notice that the curve as a whole has migrated upwards a bit. From what I can gather this is due to <em>offset error</em> accumulating, and offset error is the topic of the next section.</p>
<h2>Offset &amp; gain error correction</h2>
<p>Okay, so you've determined how much multisampling you want to use for your application, however, things aren't quite perfect. If you're like me and decided to go with <code>256</code> samples you now have an offset on all of your measurements. You could just update your firmware to subtract the offset from each measurement but the hardware can actually do this <em>and a little more</em> for you.</p>
<p>The SAM D21 has the ability to apply both <em>offset</em> and <em>gain error</em> correction. <em>Offset error</em> is pretty easy to intuit from what you've experienced so far and the graphs above - it's a constant amount of error on each measurement. The <em>gain error</em> is a bit more subtle. It's the difference between the measured value and the expected value at the top of the ADC's range - that is, it's deviation from the <em>slope</em> of the ideal transfer function. This picture illustrates this:</p>
<p><img src="https://blog.thea.codes/static/adc_total_error.png" alt="gain error"></p>
<p><em>Source: Microchip Application Note TB3185</em></p>
<p>When looking at the error graphs of real-world measurements in previous sections the gain error can be see as a "tilt" in the error line. Ideally, the line of best fit in that chart would be straight across.</p>
<p>Okay, enough theory. How do you address the gain and offset errors? The SAM D21 has two registers, <code>ADC-&gt;OFFSETCORR</code> and <code>ADC-&gt;GAINCORR</code>, for configuring the hardware to do the correction for you. The hardware will automatically apply the formula <code>result = (conversion_value - OFFSETCORR) * GAINCORR</code>. This is detailed in <a href="http://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf">section 33.6.10 of the datasheet</a>. The datasheet doesn't give a lot of hints on figuring out these values, unfortunately.</p>
<p>The best way I've found for calculating these values is to take two measurements: one in the bottom quarter of the ADC's range (say, at 15%) and one at the top quarter of the ADC's range (say, at 85%). This is from the <a href="http://ww1.microchip.com/downloads/en/DeviceDoc/90003185A.pdf">TB3185 Application Note</a>. Once you have these two measurements you can determine the gain and offset error using these formulas:</p>
<pre><span>low_expected</span> <span>=</span> <span>...</span>
<span>low_measured</span> <span>=</span> <span>...</span>
<span>high_expected</span> <span>=</span> <span>...</span>
<span>high_measured</span> <span>=</span> <span>...</span>

<span>gain_error</span> <span>=</span> <span>(</span><span>high_measured</span> <span>-</span> <span>low_measured</span><span>)</span> <span>/</span> <span>(</span><span>hi…</span></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.thea.codes/getting-the-most-out-of-the-samd21-adc/">https://blog.thea.codes/getting-the-most-out-of-the-samd21-adc/</a></em></p>]]>
            </description>
            <link>https://blog.thea.codes/getting-the-most-out-of-the-samd21-adc/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23884764</guid>
            <pubDate>Sat, 18 Jul 2020 20:54:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Secret Management with Docker-compose and Ansible Vault]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23884667">thread link</a>) | @alexktz
<br/>
July 18, 2020 | https://blog.ktz.me/secret-management-with-docker-compose-and-ansible/ | <a href="https://web.archive.org/web/*/https://blog.ktz.me/secret-management-with-docker-compose-and-ansible/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <p>Many of you will know that I am a huge proponent of Ansible and Infrastructure as Code in general. Using automation and version control to manage the configuration of your systems not only saves you time in the long run but it also gives makes you more employable. The latest Red Hat certifications, for example, are <em>all-in</em> on Ansible.</p><blockquote>Every file I reference in this blog post will be available in <a href="https://github.com/ironicbadger/compose-secret-mgt">this Git repo</a>.</blockquote><p>This article is an outline of how I use Ansible and Ansible Vault in conjunction with docker-compose to keep my secrets safe and encrypted whilst still being able to push my repos to Github publicly.</p><p>Why bother using Ansible to manage a file that you can very easily edit yourself by hand? It seems like a lot of overhead. In some ways, you are right.</p><p>If all you're doing is deploying one or two services using a docker-compose file or a docker run command then at first, it is easier to hand crank these files. That is, until you try and remember the parameters used to configure the container 6 months from now or a disaster strikes.</p><p>A disaster could mean you accidentally deleted the VM, made a breaking change to a config file without realising it, or simply did something you shouldn't have. There are many ways you could lose the configuration used to create your containers and by committing these files to git (Github, Gitlab, a self-hosted Gitea instance, etc) you instantly create a versionable backup. You can go back through history and see what changed, when, where and if your commit messages are ok maybe even figure out why, retrospectively.</p><p>This comes with a cost though. You must make <em>every single change</em> using this method from here on out. If you make a manual change to your compose yaml file and then run Ansible again next week, those manual changes will be overwritten. You have to commit.</p><p>Another issue we need to overcome is that your configuration is now out in the open (if you push to a public Github), including secrets. Secrets can include (but are not limited to) domain names, file paths, API keys, passwords, email addresses and so on. Essentially, they're anything you'd rather someone else didn't know.</p><p>We need a way to encrypt those secrets but also access them when generating our docker-compose yaml file. Ansible Vault makes this simple. I'll be the first to admit this isn't a totally straightforward process at first but over time, it will become second nature. Promise!</p><p>We'll come onto integrating Ansible Vault with Ansible in a moment. It's also easy to confuse <a href="https://docs.ansible.com/ansible/latest/user_guide/vault.html">Ansible Vault</a> with <a href="https://www.vaultproject.io/">Hashicorp Vault</a>, they are two different secret handling projects that have nothing whatsoever to do with one another.</p><p>To create a new, empty encrypted file run:</p><pre><code>ansible-vault create foo.yaml
</code></pre><p>You'll be asked for a password before being launched into your <code>$EDITOR</code> (the default is vi). Save and close this file and you'll have an AES encrypted file on disk.</p><p>To edit this file execute:</p><pre><code>ansible-vault edit foo.yaml
</code></pre><p>Again, you'll be asked for your password and be launched into your <code>$EDITOR</code>. Make your changes, then save and quit.</p><h2 id="protecting-you-from-yourself">Protecting you from yourself</h2><p><br>However, here's a second way to edit vault files. This method is is my personal preference using:</p><pre><code>ansible-vault decrypt foo.yaml
</code></pre><p>This decrypts your file and leaves it decrypted until you encrypt it again with:</p><pre><code>ansible-vault encrypt foo.yaml
</code></pre><p>The upside of this approach is that <code>foo.yaml</code> is just another clear-text file making edits via vscode or another editor besides <code>$EDITOR</code> trivial. I find this preferable in long editing sessions.</p><p>The downside is it's all too easy to accidentally commit an unencrypted file to git. I had to delete a git repo once when I leaked my gmail password on Github, it was picked up by bots in under 20 minutes! Once a file is pushed to a public repository, the values in this file are there forever or until you delete the repository due to the way git's db tracks files for versioning (or until you do some clever editing to the git db, but ain't no-one got time for that).</p><p>Nick Busey from <a href="https://homelabos.com/">HomelabOS</a> wrote me a neat little pre-commit hook that will not allow an unencrypted vars file to be committed.</p><pre><code>if ( cat vars/vault.yaml | grep -q "\$ANSIBLE_VAULT;" ); then
echo "[38;5;108mVault Encrypted. Safe to commit.[0m"
else
echo "[38;5;208mVault not encrypted! Run 'make encrypt' and try again.[0m"
exit 1
fi
</code></pre><p>This pre-supposes your secrets live in <code>vars/vault.yaml</code>. In the git repo accompanying this post look for <code>git-init.sh</code>, this installs the hook to <code>.git/hooks/pre-commit</code>.</p><p>More on Ansible Vault shortly.</p><p><br>With a bit of effort you'll be able to pick up the key principles of Ansible in a day or two. <a href="https://twitter.com/geerlingguy">Jeff Geerling</a> just released a really excellent set of <a href="https://www.youtube.com/watch?v=goclfp6a2IQ">Ansible 101</a> videos on Youtube. If you're confused about anything relating to Ansible, his videos are a good place to start.</p><p>To make things easy, I assume you have two hosts. The first is the target host which will be running docker and where your completed, clear-text docker-compose yaml file will ultimately live -- let's call this <code>server</code>. The second is where you do your development work, probably a desktop or laptop -- let's call this <code>client</code>.</p><figure><img src="https://blog.ktz.me/content/images/2020/07/Screen-Shot-2020-07-18-at-4.01.51-PM.png" alt="" srcset="https://blog.ktz.me/content/images/size/w600/2020/07/Screen-Shot-2020-07-18-at-4.01.51-PM.png 600w, https://blog.ktz.me/content/images/size/w1000/2020/07/Screen-Shot-2020-07-18-at-4.01.51-PM.png 1000w, https://blog.ktz.me/content/images/size/w1600/2020/07/Screen-Shot-2020-07-18-at-4.01.51-PM.png 1600w, https://blog.ktz.me/content/images/2020/07/Screen-Shot-2020-07-18-at-4.01.51-PM.png 1784w" sizes="(min-width: 1200px) 1200px"></figure><p>Ensure that Ansible is installed on the <code>client</code> and that Python is installed on the <code>server</code>. Installation varies per OS so please refer to the Ansible <a href="https://docs.ansible.com/ansible/latest/installation_guide/intro_installation.html">documentation</a> for steps on your system.</p><p>Ansible works over SSH. In order for the best experience it is suggested that you have SSH keys copied to the <code>server</code> so that you can connect without a password. From your <code>client</code> run <code>ssh-copy-id user@server</code>.</p><blockquote>In my testing for this article <code>192.168.1.50</code> was an Ubuntu 20.04 VM. There is nothing unique here to Ubuntu, so these concepts will apply to almost any Linux host.</blockquote><p>Ensure that <code>ssh server</code> works without specifying a password. If you'd like extra points make use of <code>~/.ssh/config</code> with the following entry:</p><pre><code># ~/.ssh/config

Host server
  Hostname 192.168.1.50
  User alex</code></pre><p><br>We're going to create an inventory file so that Ansible knows which hosts we want to manage. Remember all files can be found in <a href="https://github.com/ironicbadger/compose-secret-mgt">this git repo</a>.</p><pre><code>[server]
192.168.1.50
</code></pre><p>This inventory file assigns the host <code>192.168.1.50</code> to the group <code>[server]</code>. Ansible can do a whole lot with 'host groups' but that's largely beyond the scope of this article, check out the Ansible docs if you're interested in learning more.</p><p>We can test that Ansible is working with an ad-hoc command like this.</p><pre><code>alex@mooncake compose-secret-mgt % ansible -m ping -i inventory server
192.168.1.50 | SUCCESS =&gt; {
    "ansible_facts": {
        "discovered_interpreter_python": "/usr/bin/python3"
    },
    "changed": false,
    "ping": "pong"
}
</code></pre><p>This show us that the server replied <code>pong</code> to our <code>ping</code> request made using the <a href="https://docs.ansible.com/ansible/latest/modules/ping_module.html">ping module</a>.</p><p><a href="https://docs.ansible.com/ansible/latest/modules/modules_by_category.html">Modules</a> are an important concept in Ansible and are written in Python. They are what actually do the work we define in our tasks, roles and playbooks.</p><p>Now that we've verified connectivity between our <code>client</code> and <code>server</code> we can move onto templating.</p><p>We're going to template an example <code>ini</code> file, this has nothing to with your eventual compose templating. However, it shows that we can use these principals to manage our entire server configuration, including the apps that run on it.</p><p>Ansible uses the <a href="https://palletsprojects.com/p/jinja/">Jinja2</a> templating language to perform substitutions in template files. We will be using the <a href="https://docs.ansible.com/ansible/latest/modules/template_module.html">template</a> module for this. Here is a <em>non-functional</em> snippet of the config file for <a href="https://gitea.io/en-us/">Gitea</a>, a self-hosted Github alternative. The full file was much too long but you'll get the idea by the time we're done with this example.</p><pre><code>APP_NAME = {{ subdomain_git }}.{{ domain_full }}
RUN_MODE = prod
RUN_USER = git

[repository]
ROOT = {{ data_root_path }}/git/repositories

[server]
APP_DATA_PATH    = {{ data_root_path }}/gitea
SSH_DOMAIN       = {{ subdomain_git }}.{{ domain_full }}
HTTP_PORT        = {{ listen_port_gitea }}
ROOT_URL         = https://{{ subdomain_git }}.{{ domain_full }}/
DOMAIN           = {{ subdomain_git }}.{{ domain_full }}
</code></pre><p>You can see above, several variables surrounded by <code>{{ }}</code>. Jinja2 uses these double braces to know where to perform substitutions. The values of these substitutions come from Ansible variables. </p><p>Note that we can construct strings using concatenation with multiple variables like <code>{{ subdomain }}.{{ domain_full }}</code>. This allows us to easily change the subdomain used for git independently from the main domain and is especially useful when the same string is required multiple times in the same file.</p><p>We can also reuse <code>domain_full</code> elsewhere throughout our entire infrastructure and only define it in one place.</p><p>For example, suppose that in your compose file you want to reuse some of these values. Port numbers, paths, etc. To change the port the app is listening on manually would be half a dozen edits. Using Ansible, it's <em>just one</em>. It is automatically updated everywhere it appears all at once using templating.</p><blockquote>You can follow along in the git repo by running <code>ansible-playbook -i inventory example1.yaml</code>.</blockquote><pre><code># example1.yaml - barebones templating example
- hosts: server
  vars:
    - subdomain_git: git 
	  - domain_full: domain.com
	  - data_root_path: /data
	  - listen_port_gitea: 3000
  tasks:
    - name: template test
      template:
        src: example.ini.j2
        dest: example.ini
</code></pre><p>For example if we execute the playbook above and run the template through Jinja2, we create the following output.</p><pre><code>alex@blogtest:~$ cat example.ini
APP_NAME = git.domain.com
RUN_MODE = prod
RUN_USER = git

[repository]
ROOT = /data/git/repositories

[server]
APP_DATA_PATH    = /data/gitea
SSH_DOMAIN       = git.domain.com
HTTP_PORT        = 3000
ROOT_URL         = https://git.domain.com/
DOMAIN           = git.domain.com
</code></pre><p>We told Ansible to run the templating module against the group of hosts defined under <code>server</code>. It then performed variable substitutions using the variables values defined in the playbook (variables are tightly scoped in Ansible) and templated them into our target file. Finally the module copied this file to the target <code>server</code> file path we provided.</p><p>Take a look at the file <code>var…</code></p></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.ktz.me/secret-management-with-docker-compose-and-ansible/">https://blog.ktz.me/secret-management-with-docker-compose-and-ansible/</a></em></p>]]>
            </description>
            <link>https://blog.ktz.me/secret-management-with-docker-compose-and-ansible/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23884667</guid>
            <pubDate>Sat, 18 Jul 2020 20:42:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Software Is Slow and Shitty]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23884598">thread link</a>) | @pketh
<br/>
July 18, 2020 | http://pketh.org/why-software-is-slow-and-shitty.html | <a href="https://web.archive.org/web/*/http://pketh.org/why-software-is-slow-and-shitty.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    

<p><img src="http://pketh.org/images/2020/mario64-camera.jpg"></p>

<p>Most software is annoying to use. Opening a news article to read 500 words should be instant but takes entire seconds. Try to make a quick update to a Google Doc and you’re waiting even longer before you can type. Hopefully you don’t have to use Jira or Photoshop.</p>

<p>I thought computers were supposed to be nicer than they were in the 90s.</p>

<p>Grizzled vets say that <a href="https://tonsky.me/blog/good-times-weak-men/">the good times make us weak</a>. That because we have powerful hardware, modern software is built on top of a bewildering goop of high-level languages, frameworks, and dependencies on dependencies that make even simple things sluggish.</p>

<p>It’s a compelling argument. As craftspeople, we just need to not be lazy, get our shit together, and then we can make nice things.</p>

<p>ヽ(´□｀。)ﾉ</p>

<p>But I think self-flagellation is missing the forest for the trees.</p>

<p>As an industry, we’ve moved from putting engineering innovation and efficiency first, towards prioritizing usability and market-fit. I’m not mad at that. Computers exist to help humans do new things, they should be bicycles for the mind and all that good stuff. But there’s nothing stopping software from being useful <em>and</em> elegantly made.</p>

<p>I mean, except for the way most software companies are organized.</p>

<figure>
  <img src="http://pketh.org/images/2020/supreme-problem-solves.png">
  <figcaption>
    <a href="https://www.are.na/block/1975355">(Source)</a>
  </figcaption>
</figure>

<p>Most company structures are based on the <a href="https://www.hierarchystructure.com/roman-military-hierarchy/">Roman empire military</a>. CEO Caesar says he wants something, and the lieutenant managers below him on the org chart break it down into smaller tasks for the soldiers to accomplish.</p>

<p><img src="http://pketh.org/images/2020/caesar-diagram.png">
<a href="https://kinopio.club/roman-military-diagram-Q9vX2HJbM3-tJD0CaTDxM">(Rome military diagram)</a></p>

<p>On a development team, programmers are the soldiers of these shitty new armies. They open their Jira issues and add whatever feature it says to add, or fix what it says to fix. If I can save time by adding another dependency, or skip a meeting by implementing a mockup exactly as designed, why should I care?</p>

<p>Some people care. Those people suffer:</p>

<blockquote>
  <div><p>I now spend 1/4 of my work week fighting dependency hell (after just about each addition of a new package by any other developer on the project), another 1/4 figuring out how the “latest and greatest” tool of the week is best used to do something that would normally take me 5 minutes to do custom (god forbid, not the C-word!), and the remaining half is spent maybe doing actual work. So incredibly frustrating that I’ve just about had it.
</p><p>
I’ve grown to loathe and hate that which I used to adore. <a href="https://news.ycombinator.com/item?id=18027977">(Source)</a></p></div>
</blockquote>

<p>Building software is nothing like organizing armies in 100 BC. In 2020, we can communicate instantly, victory is ambiguous, and there’s less murder. But most importantly, we’re not conquesting, we’re creating.</p>

<h2 id="creation-moves-differently">Creation moves differently</h2>

<p><img src="http://pketh.org/images/2020/mario64-penguin.jpg"></p>

<p>To illustrate this, let’s talk about <a href="https://www.youtube.com/watch?v=8MQO2STCbbY">Super Mario 64</a>, the landmark 1996 game that used an unusual new technology: 3D graphics. You might think that Mario 64 was built with tickets and sprints, but, according to interviews, there was no master plan, only the principles that the game should feel good and be fun. They started with just Mario in a small room, and tuned his animations and physics until he felt nice and responsive. After that, the levels were also created as they went, with the designers, developers, and director going back and forth using sketches and prototypes.</p>

<p>Building like this is never a straight line. Ideas and code get left on the cutting room floor because part of innovation is questioning whether what you made <a href="https://www.folklore.org/StoryView.py?project=Macintosh&amp;story=MacPaint_Evolution.txt">should exist</a>. The process is cyclical and iterative, looking something like:</p>

<figure>
  <img src="http://pketh.org/images/2020/cyclical%20creation%20diagram.png">
  <figcaption>
    <a href="https://kinopio.club/mechanics-focused-development-lCHFGyOJfskhGAZ5Lul5v">(Mechanics-focused development)</a>
  </figcaption>
</figure>

<p>Good software comes from a vision, combined with conversations not commandments. In a craft-focused environment, care for efficiency, simplicity, and details really do matter. I didn’t leave my last job just because I wanted to make something new. I left because I wanted to make it in a way I could be proud of.</p>

<p>So here’s what’s up, I’m working on my own right now, in a race between my diminishing savings and my typing fingers. But I’m not stressing too much. I’ve got a lot of work to do, but people seem to like what I’m making. Maybe one day though, it won’t just be me. When that happens I’d love to build a small company/collective/<em>thing</em> that’s the best place for creators to work.</p>

<blockquote>
  <p>Special thanks to Michelle and <a href="https://twitter.com/haoformayor">Hao</a> for helping edit this.</p>
</blockquote>

  </div></div>]]>
            </description>
            <link>http://pketh.org/why-software-is-slow-and-shitty.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23884598</guid>
            <pubDate>Sat, 18 Jul 2020 20:32:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Views on Error Handling]]>
            </title>
            <description>
<![CDATA[
Score 80 | Comments 76 (<a href="https://news.ycombinator.com/item?id=23884505">thread link</a>) | @dannas
<br/>
July 18, 2020 | https://dannas.name/error-handling | <a href="https://web.archive.org/web/*/https://dannas.name/error-handling">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<!-- excerpt start -->
<p>In this post, I summarize some accomplished engineer’s views on error handling.
There is a distinction between errors that are caused by programmer
neglecting bugs and those that represent true error conditions. The
granularity of error checking is also up for debate: Per function? Per module?
Jump to dialog handler in the main message loop? Kill the process and restart?
<!-- excerpt end --></p>



<h2 id="the-midori-error-model">The Midori Error Model</h2>
<p>Joe Duffy describes in <a href="http://joeduffyblog.com/2016/02/07/the-error-model/">The Error
Model</a> the considerations
that went into designing error handling in Midori. He said that they were
guided by these principles:</p>

<blockquote>
  <ul>
    <li><strong>Usable</strong>. It must be easy for developers to do the “right” thing in the 
face of error, almost as if by accident. A friend and colleague famously
called this falling into The Pit of Success. The model should not impose
excessive ceremony to write idiomatic code. Ideally, it is cognitively
familiar to our target audience.</li>
    <li><strong>Reliable</strong>. The Error Model is the foundation of the entire system’s 
reliability. We were building an operating system, after all, so reliability
was paramount. You might even have accused us as obsessively pursuing extreme
levels of it. Our mantra guiding much of the programming model development was
“correct by construction.”</li>
    <li><strong>Performant</strong>. The common case needs to be extremely fast. That means as 
close to zero overhead as possible for success paths. Any added costs for
failure paths must be entirely “pay-for-play.” And unlike many modern systems
that are willing to overly penalize error paths, we had several
performance-critical components for which this wasn’t acceptable, so errors
had to be reasonably fast too.</li>
    <li><strong>Concurrent</strong>. Our entire system was distributed and highly concurrent. 
This raises concerns that are usually afterthoughts in other Error Models.
They needed to be front-and-center in ours.</li>
    <li><strong>Diagnosable</strong>. Debugging failures, either interactively or 
after-the-fact, needs to be productive and easy.</li>
    <li><strong>Composable</strong>. At the core, the Error Model is a programming language 
feature, sitting at the center of a developer’s expression of code. As such,
it had to provide familiar orthogonality and composability with other features
of the system. Integrating separately authored components had to be natural,
reliable, and predictable.</li>
  </ul>
</blockquote>

<p>Joe compared different error models against these criteria and came up with
the table below:</p>

<p><img src="https://dannas.name/img/2020/duffy_error_model_table.png" alt="Table of error models"></p>

<p>In the end, he chose checked exception but separated all programmer-error
cases. Those were handled by abandonment - deadly asserts. The compiler could
optimize the code better since it knew exactly which paths could throw (in
contrast to C++ where you have to annotate each function that can not throw).
The syntax is similar to what is now found in Swift and Rust.</p>

<h2 id="the-erlang-approach---let-it-crash">The Erlang Approach - Let it Crash</h2>
<p>The Erlang folks are a bit more hardcore. They don’t get bogged down in
discussions about syntactic structures. Joe Armstrong says in <a href="https://www.softwaretalks.io/v/4611/goto-2018-o-the-dos-and-donts-of-error-handling-o-joe-armstrong">Dos and Don’ts
of error handling</a>:
“You’re correctness theorems aren’t gonna help you if your computer is hit by
lightning. What he meant is that no system runs in isolation and there’s
always the chance of failure. So when errors do happen, they restart the
affected process to a known state and try again.</p>

<p>Fred Hebert describes in <a href="https://ferd.ca/the-zen-of-erlang.html">The Zen of
Erlang</a> the Let it Crash motto. Erlang
processes are fully isolated and share nothing. So if an error is detected,
the system just kills the process and restarts. But how can that solve anything?
Won’t the same bug just happen over and over again? How to deal with a
configuration file that has the wrong content?</p>

<p>Fred refers to Jim Grays 1985 paper <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.110.9127&amp;rep=rep1&amp;type=pdf">Why Do Computers Stop and What Can Be
Done About
It?</a>.
There Gray introduces the notion of Heisenbugs and Bohrbugs. In Fred Hebert’s words:</p>

<blockquote>
  <p>Basically, a bohrbug is a bug that is solid, observable, and easily
repeatable. They tend to be fairly simple to reason about. Heisenbugs by
contrast, have unreliable behaviour that manifests itself under certain
conditions, and which may be hidden by the simple act of trying to
observe them. For example, concurrency bugs are notorious for disappearing
when using a debugger that may force every operation in the system to be
serialized.</p>

  <p>Heisenbugs are these nasty bugs that happen once in a thousand, million,
billion, or trillion times. You know someone’s been working on figuring one
out for a while once you see them print out pages of code and go to town on
them with a bunch of markers.</p>
</blockquote>

<p>So a repeatable (Bohr) bug will be easy to reproduce while a transient
(Heisenbug) will be hard. Now, Hebert argues that if you have a bohrbug in your
system’s core features it should be very easy to find before reaching
production. By being repeatable and often on a critical path, you
should encounter them sooner or later, and fix them before shipping.</p>

<p><img src="https://dannas.name/img/2020/hebert_heisen_bohr_bug.png" alt="Bohr vs Heisen Bugs"></p>

<p>Now, Jim Gray’s paper reports that transient errors (heisenbugs) happen all
the time. They are often fixed by restarting. As long as you weed out the
bohrbugs by having proper testing of your releases, the remaining bugs are
often solved by restarting and rolling back to a known state.</p>

<p><img src="https://dannas.name/img/2020/hebert_bugs_restart.png" alt="Bugs handled by Restart"></p>

<h2 id="classification-of-exceptions">Classification of Exceptions</h2>
<p>Eric Lippert gives this taxonomy in <a href="https://blogs.msdn.microsoft.com/ericlippert/2008/09/10/vexing-exceptions/">Vexing Exceptions</a></p>

<ul>
  <li><strong>Fatal</strong> exceptions are not your fault, you cannot prevent them, and you 
cannot sensibly clean up from them. They almost always happen because the
process is deeply diseased and is about to be put out of its misery. Out of
memory, thread aborted, and so on.</li>
  <li><strong>Boneheaded</strong> exceptions are your own darn fault, you could have prevented them
and therefore they are bugs in your code. You should not catch them; doing so
is hiding a bug in your code. Rather, you should write your code so that the
exception cannot possibly happen in the first place, and therefore does not
need to be caught. That argument is null, that typecast is bad, that index is
out of range, you’re trying to divide by zero</li>
  <li><strong>Vexing</strong> exceptions are the result of unfortunate design decisions. Vexing
exceptions are thrown in a completely non-exceptional circumstance, and
therefore must be caught and handled all the time. The classic example of a
vexing exception is Int32.Parse, which throws if you give it a string that
cannot be parsed as an integer. Eric recommends calling the Try versions of these
functions instead.</li>
  <li><strong>Exogenous</strong> exceptions appear to be somewhat like vexing exceptions except that
they are not the result of unfortunate design choices. Rather, they are the
result of untidy external realities impinging upon your beautiful, crisp
program logic.</li>
</ul>

<p>Eric gives this pseduo-C# example:</p>

<div><div><pre><code>try {
	using ( File f = OpenFile(filename, ForReading) ) {
	use(f);
	}
} catch (FileNotFoundException) {
	// Handle filename not found
}
</code></pre></div></div>
<p>Can you eliminate the try-catch with this code?</p>
<div><div><pre><code>if (!FileExists(filaname))
    // Handle filename not found
else
    using (File f = ...
</code></pre></div></div>
<p>No, you can’t! The new code has a race condition. Eric suggests that you just
bite the bullet and always handle exceptions that indicate unexpected
exogenous conditions.</p>

<h2 id="composing-errors-codes">Composing Errors Codes</h2>
<p>Rob Pike writes in <a href="https://blog.golang.org/errors-are-values">Errors are
Values</a> about how to avoid writing
<code>if err != nil {...}</code> all the time in Go code. Instead of sprinkling if
statements, the error handling can be integrated into the type. He gives the
bufio packages’s <code>Scanner</code> as an example:</p>

<div><div><pre><code>scanner := bufio.NewScanner(input)
for scanner.Scan() {
    token := scanner.Text()
    // process token
}
if err := scanner.Err(); err != nil {
    // process the error
}
</code></pre></div></div>
<p>The check for errors is only done once. Rob also mentions that the
<code>archive/zip</code> and <code>net/http</code> packages use the same pattern. The <code>bufio</code>
package’s Writer does as well.</p>

<div><div><pre><code>b := bufio.NewWriter(fd)
b.Write(x)
b.Write(y)
b.Write(z)
// and so on
if b.Flush() != nil {
    return b.Flush()
}
</code></pre></div></div>

<p>Fabien Giesen describes a similar pattern for error handling in <a href="https://fgiesen.wordpress.com/2011/11/21/buffer-centric-io/">Buffer
Centric I/O</a>. And
the pattern is used extensively throughout the Qt framework’s core classes.
Another name for it is sticky errors or error accumulator.</p>

<h2 id="error-handling-granularity">Error Handling Granularity</h2>
<p>Per Vognsen discusses how to do <a href="https://bitwise.handmade.network/episode/bitwise/bitwise006/#5537">course-grained error handling in C using
setjmp/longjmp</a>.
The use case there were for arena allocations and deeply nested recursive
parsers. It’s very similar to how C++ does exception handling, but without the
downsides of the costly C++ memory deallocation on stack unwinding. He goes on to say
that certain classes of push-oriented API’s, that has clear command-query separation,
don’t need to do fine-grained error handling. It’s the same idea as in the
previous section.</p>

<p>Fabien Giesen describes in <a href="https://gist.github.com/anonymous/2edc9e9d52a93c126ff486cfb4a2c65b">an aside for a gist note</a>
how he views error handling. He points out that it may be beneficial to only
provide a small set of error codes and that the selection of those should be
dictated by the question “what should I do next?”. E.g. there are many ways a
network connection can fail but providing a giant taxonomy of error codes
won’t help the calling code to decide what to do. Logging should be as
specific as possible but the users of an API just need to decide what to do
next.</p>

<p>Fabien wrote <a href="https://cbloomrants.blogspot.se/2010/06/06-07-10-exceptions.html?showComment=1275971007229#c4849051810850075252">in a blog
comment</a>
 that having stack unwinding do the cleanup on errors is a bad design that
costs lots of resources and is hard to control.</p>

<blockquote>
  <p>“Cleanup stack”-based unwinding incurs a cost on every single function, which
means it’s equivalent to checking for error conditions in every single
function. That is a very bad way of implementing error handling; a method that
works much better is to just remember that an error occurred, but substitute
valid data as soon as possible.</p>

  <p>That is, separate “tactical” error handling (which just needs to make sure
your program ends up in a safe and consistent state) from “strategical” error
handling (which is usually at a pretty high level in an app and might involve
user interaction), and try to keep most intermediate layers unaware of both.</p>

  <p>I consider this good practice in general, not least because immediately
escalating error conditions not only makes for hard to understand control
flow, but also a bad user experience. Take broken P4 connections, copies of
large …</p></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dannas.name/error-handling">https://dannas.name/error-handling</a></em></p>]]>
            </description>
            <link>https://dannas.name/error-handling</link>
            <guid isPermaLink="false">hacker-news-small-sites-23884505</guid>
            <pubDate>Sat, 18 Jul 2020 20:19:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PIFuHD: High-Resolution 3D Human Digitization]]>
            </title>
            <description>
<![CDATA[
Score 76 | Comments 16 (<a href="https://news.ycombinator.com/item?id=23884480">thread link</a>) | @jonbaer
<br/>
July 18, 2020 | https://shunsukesaito.github.io/PIFuHD/ | <a href="https://web.archive.org/web/*/https://shunsukesaito.github.io/PIFuHD/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://shunsukesaito.github.io/PIFuHD/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23884480</guid>
            <pubDate>Sat, 18 Jul 2020 20:15:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Team Lead Anti-Patterns]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23884166">thread link</a>) | @cbowal
<br/>
July 18, 2020 | http://www.dcaulfield.com/team-lead-anti-patterns/ | <a href="https://web.archive.org/web/*/http://www.dcaulfield.com/team-lead-anti-patterns/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://www.dcaulfield.com/team-lead-anti-patterns/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23884166</guid>
            <pubDate>Sat, 18 Jul 2020 19:37:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Compressed Sensing (2016)]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 9 (<a href="https://news.ycombinator.com/item?id=23884141">thread link</a>) | @chaosmachine
<br/>
July 18, 2020 | http://www.pyrunner.com/weblog/2016/05/26/compressed-sensing-python/ | <a href="https://web.archive.org/web/*/http://www.pyrunner.com/weblog/2016/05/26/compressed-sensing-python/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
      
<p>In this post I’ll be investigating <em>compressed sensing</em> (also known as compressive sensing, compressive sampling, and sparse sampling) in Python. Since the idea of compressed sensing can be applied in wide array of subjects, I’ll be focusing mainly on how to apply it in one and two dimensions to things like sounds and images. Specifically, I will show how to take a highly incomplete data set of signal samples and reconstruct the underlying sound or image. It is a very powerful technique.</p>
<h2><mathjax>$L^1$</mathjax> vs. <mathjax>$L^2$</mathjax> Fitting</h2>
<hr>
<p>As you might know, there are many different types of norms. Perhaps the most common and widely recognized one is the <mathjax>$L^2$</mathjax> norm:</p>
<p><mathjax>$$\lVert\vec x\rVert_2=\left(\sum_{i=0}^n x_i^2 \right)^{1/2}$$</mathjax></p>
<p>The <mathjax>$L^2$</mathjax> norm is nice because it is easily calculated, easily differentiated, and it has intuitive appeal (e.g., the norm of a vector is its length). A lot of very important algorithms and methods rely on the <mathjax>$L^2$</mathjax>, including least squares fitting.</p>
<p>That said, the <mathjax>$L^2$</mathjax> norm isn’t the goto solution for everything. The other norms also have many interesting and useful properties. Consider the <mathjax>$L^1$</mathjax> norm:</p>
<p><mathjax>$$\lVert \vec x\rVert_1=\sum_{i=0}^n \lvert x_i\rvert $$</mathjax></p>
<p>Instead of squaring each element, it simply takes its absolute value. Although the absolute value is annoying in the sense that it often introduces discontinuities in its derivatives, it does have some unique properties when compared to the squaring that takes place in the <mathjax>$L^2$</mathjax> norm. Compressed sensing is all about exploiting these properties.</p>
<p>Let’s visualize some data with Python to see what I’m talking about.</p>
<div><pre><span></span><span># make sure you've got the following packages installed</span>
<span>import</span> <span>numpy</span> <span>as</span> <span>np</span>
<span>import</span> <span>matplotlib</span> <span>as</span> <span>mpl</span>
<span>import</span> <span>matplotlib.pyplot</span> <span>as</span> <span>plt</span>
<span>import</span> <span>scipy.optimize</span> <span>as</span> <span>spopt</span>
<span>import</span> <span>scipy.fftpack</span> <span>as</span> <span>spfft</span>
<span>import</span> <span>scipy.ndimage</span> <span>as</span> <span>spimg</span>
<span>import</span> <span>cvxpy</span> <span>as</span> <span>cvx</span>
</pre></div>


<p>First what we’re going to do is create some arbitrary linear data including some noise. Let’s use the made-up equation:</p>
<p><mathjax>$$y=\frac{1}{5}x+3+\epsilon$$</mathjax></p>
<p>where <mathjax>$\epsilon$</mathjax> is some normally distributed error with standard deviation <mathjax>$\sigma=0.1$</mathjax>.</p>
<div><pre><span></span><span># generate some data with noise</span>
<span>x</span> <span>=</span> <span>np</span><span>.</span><span>sort</span><span>(</span><span>np</span><span>.</span><span>random</span><span>.</span><span>uniform</span><span>(</span><span>0</span><span>,</span> <span>10</span><span>,</span> <span>15</span><span>))</span>
<span>y</span> <span>=</span> <span>3</span> <span>+</span> <span>0.2</span> <span>*</span> <span>x</span> <span>+</span> <span>0.1</span> <span>*</span> <span>np</span><span>.</span><span>random</span><span>.</span><span>randn</span><span>(</span><span>len</span><span>(</span><span>x</span><span>))</span>
</pre></div>


<p>Now let’s fit two lines to the data samples. For the first line, we’ll use the <mathjax>$L^1$</mathjax> norm as the criterion for a good fit; for the second line, we’ll use the <mathjax>$L^2$</mathjax> norm.</p>
<div><pre><span></span><span># find L1 line fit</span>
<span>l1_fit</span> <span>=</span> <span>lambda</span> <span>x0</span><span>,</span> <span>x</span><span>,</span> <span>y</span><span>:</span> <span>np</span><span>.</span><span>sum</span><span>(</span><span>np</span><span>.</span><span>abs</span><span>(</span><span>x0</span><span>[</span><span>0</span><span>]</span> <span>*</span> <span>x</span> <span>+</span> <span>x0</span><span>[</span><span>1</span><span>]</span> <span>-</span> <span>y</span><span>))</span>
<span>xopt1</span> <span>=</span> <span>spopt</span><span>.</span><span>fmin</span><span>(</span><span>func</span><span>=</span><span>l1_fit</span><span>,</span> <span>x0</span><span>=</span><span>[</span><span>1</span><span>,</span> <span>1</span><span>],</span> <span>args</span><span>=</span><span>(</span><span>x</span><span>,</span> <span>y</span><span>))</span>

<span># find L2 line fit</span>
<span>l2_fit</span> <span>=</span> <span>lambda</span> <span>x0</span><span>,</span> <span>x</span><span>,</span> <span>y</span><span>:</span> <span>np</span><span>.</span><span>sum</span><span>(</span><span>np</span><span>.</span><span>power</span><span>(</span><span>x0</span><span>[</span><span>0</span><span>]</span> <span>*</span> <span>x</span> <span>+</span> <span>x0</span><span>[</span><span>1</span><span>]</span> <span>-</span> <span>y</span><span>,</span> <span>2</span><span>))</span>
<span>xopt2</span> <span>=</span> <span>spopt</span><span>.</span><span>fmin</span><span>(</span><span>func</span><span>=</span><span>l2_fit</span><span>,</span> <span>x0</span><span>=</span><span>[</span><span>1</span><span>,</span> <span>1</span><span>],</span> <span>args</span><span>=</span><span>(</span><span>x</span><span>,</span> <span>y</span><span>))</span>
</pre></div>


<p><img src="http://www.pyrunner.com/media/uploads/images/compressed-sensing-python/output_5_2.png"></p>
<p>Notice that both of the fits seem to do a pretty good job fitting the data. Sure, they don’t line up exactly, but they both are reasonable approximations given the noise. </p>
<p>Now, let’s get a tad crazy and add some outliers. In other words, let’s perturb a couple of the points, moving them far away from the lines. This isn’t actually all that out of the ordinary if you think about it. Outliers frequently occur in real world data, causing all kinds of headaches.</p>
<div><pre><span></span><span># adjust data by adding outlyers</span>
<span>y2</span> <span>=</span> <span>y</span><span>.</span><span>copy</span><span>()</span>
<span>y2</span><span>[</span><span>3</span><span>]</span> <span>+=</span> <span>4</span>
<span>y2</span><span>[</span><span>13</span><span>]</span> <span>-=</span> <span>3</span>

<span># refit the lines</span>
<span>xopt12</span> <span>=</span> <span>spopt</span><span>.</span><span>fmin</span><span>(</span><span>func</span><span>=</span><span>l1_fit</span><span>,</span> <span>x0</span><span>=</span><span>[</span><span>1</span><span>,</span> <span>1</span><span>],</span> <span>args</span><span>=</span><span>(</span><span>x</span><span>,</span> <span>y2</span><span>))</span>
<span>xopt22</span> <span>=</span> <span>spopt</span><span>.</span><span>fmin</span><span>(</span><span>func</span><span>=</span><span>l2_fit</span><span>,</span> <span>x0</span><span>=</span><span>[</span><span>1</span><span>,</span> <span>1</span><span>],</span> <span>args</span><span>=</span><span>(</span><span>x</span><span>,</span> <span>y2</span><span>))</span>
</pre></div>


<p><img src="http://www.pyrunner.com/media/uploads/images/compressed-sensing-python/output_7_2.png"></p>
<p>When we re-plot the <mathjax>$L^1$</mathjax> and <mathjax>$L^2$</mathjax> fits we see something interesting: the <mathjax>$L^1$</mathjax> fit remained true to the overall trend in the data, while the <mathjax>$L^2$</mathjax> fit seemed to get “corrupted” by the outliers. Why does this happen? It comes down to the fact that <mathjax>$L^2$</mathjax> error gets squared, while <mathjax>$L^1$</mathjax> error does not. When you fit a line to data using an <mathjax>$L^2$</mathjax> interpretation of error, the displacement of outliers has a disproportional impact because their already-big errors are get getting squared. Just look at the distance of the two outliers in our example and imagine squaring them – of course it’s not surprising that the <mathjax>$L^2$</mathjax> line gets skewed!</p>
<p>However, when using an <mathjax>$L^1$</mathjax> interpretation of error, the outliers contribute no more than their displacement. The result is a cleaner fit that more closely matches our intuition of what a good fit should look like. It’s this interesting property that opens the door to compressed sensing.</p>
<h2>Reconstruction of a Simple Signal</h2>
<hr>
<p>In this example (borrowed from Kutz<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>), we will create an artificial sound wave, sample 10% of it, and reconstruct the original signal from the sample of 10%. This is one dimensional compressed sensing.</p>
<p>First, create a signal of two sinusoids.</p>
<div><pre><span></span><span># sum of two sinusoids</span>
<span>n</span> <span>=</span> <span>5000</span>
<span>t</span> <span>=</span> <span>np</span><span>.</span><span>linspace</span><span>(</span><span>0</span><span>,</span> <span>1</span><span>/</span><span>8</span><span>,</span> <span>n</span><span>)</span>
<span>y</span> <span>=</span> <span>np</span><span>.</span><span>sin</span><span>(</span><span>1394</span> <span>*</span> <span>np</span><span>.</span><span>pi</span> <span>*</span> <span>t</span><span>)</span> <span>+</span> <span>np</span><span>.</span><span>sin</span><span>(</span><span>3266</span> <span>*</span> <span>np</span><span>.</span><span>pi</span> <span>*</span> <span>t</span><span>)</span>
<span>yt</span> <span>=</span> <span>spfft</span><span>.</span><span>dct</span><span>(</span><span>y</span><span>,</span> <span>norm</span><span>=</span><span>'ortho'</span><span>)</span>
</pre></div>


<p><img src="http://www.pyrunner.com/media/uploads/images/compressed-sensing-python/output_10_1.png"></p>
<p>In the plots above, we see that the signal has a clear pattern, yet is non-trivial. The plots in the top row are of the signal in the temporal domain at different scales. The plots in the bottom row are of the signal in the spectral domain (i.e., the signal’s frequency content). Considering the frequency domain in particular, we note that the spectrum is mostly zero except for the two spikes representing the two sine frequencies.</p>
<p>Now imagine sampling 10% of the temporal signal (see below). You’d have a data set that, to the naked eye, would look like nonsense. The underlying signal is would still be the same, as would be its frequency content (mostly zeros, with the exception of two spikes). One might ask if it is somehow possible to extract those two dominant frequencies from the incomplete data so that we might reconstruct the signal? The answer is yes!</p>
<div><pre><span></span><span># extract small sample of signal</span>
<span>m</span> <span>=</span> <span>500</span> <span># 10% sample</span>
<span>ri</span> <span>=</span> <span>np</span><span>.</span><span>random</span><span>.</span><span>choice</span><span>(</span><span>n</span><span>,</span> <span>m</span><span>,</span> <span>replace</span><span>=</span><span>False</span><span>)</span> <span># random sample of indices</span>
<span>ri</span><span>.</span><span>sort</span><span>()</span> <span># sorting not strictly necessary, but convenient for plotting</span>
<span>t2</span> <span>=</span> <span>t</span><span>[</span><span>ri</span><span>]</span>
<span>y2</span> <span>=</span> <span>y</span><span>[</span><span>ri</span><span>]</span>
</pre></div>


<p><img src="http://www.pyrunner.com/media/uploads/images/compressed-sensing-python/output_12_1.png"></p>
<p>Compressed sensing in this context is made possible by the fact that the signal’s frequency content is highly sparse. This is where the <mathjax>$L^1$</mathjax> norm comes into play. What we want to do is, out of all possible signals, locate the <em>simplest</em> one that matches up with the known data. In other words, we want to use a minimization routine to find a set of frequencies satisfying two conditions: (a) the underlying signal matches up exactly (or as closely as possible) with that of our data; and (b) the <mathjax>$L^1$</mathjax> norm of the frequencies is minimized. Such a routine will yield a sparse solution – exactly what we want.</p>
<p>In Python, there are a couple ways to accomplish this. Perhaps the easiest is to utilize the convex optimization library <a href="http://www.cvxpy.org/en/latest/">CVXPY</a>. Use the code below to minimize the norm of the signal’s frequencies with the constraint that candidate signals should match up exactly with our incomplete samples.</p>
<div><pre><span></span><span># create idct matrix operator</span>
<span>A</span> <span>=</span> <span>spfft</span><span>.</span><span>idct</span><span>(</span><span>np</span><span>.</span><span>identity</span><span>(</span><span>n</span><span>),</span> <span>norm</span><span>=</span><span>'ortho'</span><span>,</span> <span>axis</span><span>=</span><span>0</span><span>)</span>
<span>A</span> <span>=</span> <span>A</span><span>[</span><span>ri</span><span>]</span>

<span># do L1 optimization</span>
<span>vx</span> <span>=</span> <span>cvx</span><span>.</span><span>Variable</span><span>(</span><span>n</span><span>)</span>
<span>objective</span> <span>=</span> <span>cvx</span><span>.</span><span>Minimize</span><span>(</span><span>cvx</span><span>.</span><span>norm</span><span>(</span><span>vx</span><span>,</span> <span>1</span><span>))</span>
<span>constraints</span> <span>=</span> <span>[</span><span>A</span><span>*</span><span>vx</span> <span>==</span> <span>y2</span><span>]</span>
<span>prob</span> <span>=</span> <span>cvx</span><span>.</span><span>Problem</span><span>(</span><span>objective</span><span>,</span> <span>constraints</span><span>)</span>
<span>result</span> <span>=</span> <span>prob</span><span>.</span><span>solve</span><span>(</span><span>verbose</span><span>=</span><span>True</span><span>)</span>
</pre></div>


<p>You might be asking: <em>what the hell is that <mathjax>$A$</mathjax> matrix?</em> Well, it’s the key to the whole party. Let me explain.</p>
<p>In order to perform the minimization, we must somehow finagle our problem into a linear system of equations:</p>
<p><mathjax>$$A x=b$$</mathjax></p>
<p>Specifically, we want to derive a matrix <mathjax>$A$</mathjax> that can be multiplied with a solution candidate <mathjax>$x$</mathjax> to yield <mathjax>$b$</mathjax>, a vector containing the data samples. In the context of our current problem, the candidate solution <mathjax>$x$</mathjax> exists in the frequency domain, while the known data <mathjax>$b$</mathjax> exists in the temporal domain. Clearly, the matrix <mathjax>$A$</mathjax> performs both a sampling and a transformation from spectral to temporal domains.</p>
<p>Compressed sensing really comes down to being able to correctly derive the <mathjax>$A$</mathjax> operator. Fortunately, there’s a methodology. Start off by letting <mathjax>$f$</mathjax> be the target signal in vector form (if your signal is 2-dimensional or higher, flatten it) and <mathjax>$\phi$</mathjax> be the sampling matrix. Then:</p>
<p><mathjax>$$b=\phi f$$</mathjax></p>
<p>Now let <mathjax>$\psi$</mathjax> be the matrix that transforms a signal from the spectral domain to the temporal domain. Given the solution <mathjax>$x$</mathjax> in the frequency domain, it follows that:</p>
<p><mathjax>$$\psi x=f$$</mathjax></p>
<p>Combining the two equations yields:</p>
<p><mathjax>$$A x=b\quad \text{where}\ A\equiv \phi\psi$$</mathjax></p>
<p>So, <mathjax>$A$</mathjax> is simply made up of rows sampled from the domain transform matrix <mathjax>$\psi$</mathjax>. The <mathjax>$\psi$</mathjax> matrix is easy to construct – it is the inverse discrete cosine transform acting upon the columns of the identity matrix. The matrix product <mathjax>$\psi x$</mathjax> is the equivalent to doing <code>idct(x)</code>.</p>
<p>Now that we’ve constructed the <mathjax>$A$</mathjax> matrix and run the minimization, we can reconstruct the signal by transforming the solution out of the frequency domain and back into the temporal. Below, on the left, is the original signal and its frequency content. On the right is our <mathjax>$L^1$</mathjax> approximation. I’d say that’s pretty good for only using 10% of the data!</p>
<div><pre><span></span><span># reconstruct signal</span>
<span>x</span> <span>=</span> <span>np</span><span>.</span><span>array</span><span>(</span><span>vx</span><span>.</span><span>value</span><span>)</span>
<span>x</span> <span>=</span> <span>np</span><span>.</span><span>squeeze</span><span>(</span><span>x</span><span>)</span>
<span>sig</span> <span>=</span> <span>spfft</span><span>.</span><span>idct</span><span>(</span><span>x</span><span>,</span> <span>norm</span><span>=</span><span>'ortho'</span><span>,</span> <span>axis</span><span>=</span><span>0</span><span>)</span>
</pre></div>


<p><img src="http://www.pyrunner.com/media/uploads/images/compressed-sensing-python/output_16_0.png"></p>
<p>One problem that stands out is that the quality of the reconstruction degrades noticeably at and around <mathjax>$t=0$</mathjax>. This is probably due to our sample interval violating the periodic boundary condition requirements of the cosine transform. Of course, given an arbitrary signal sample without any prior knowledge of its nature, it would be hard <em>not</em> to violate periodic boundary conditions. The good news is that now we have some very clear indications of the true signal’s frequencies. If desired, we could go back and resample the signal within an interval that satisfies periodic boundaries.</p>
<h2>Reconstruction of an Image (a 2D Signal)</h2>
<hr>
<p>Now let’s use what we learned from the 1-dimensional case to do compressed sensing in 2-dimensions. This is where the real fun begins because we can now try and reconstruct images.</p>
<p>Below, we will use exactly the same methodology as before to randomly sample and reconstruct the image <em>Waterfall</em> by M. C. Escher (approx. 1200 by 1600 pixels). Due to memory limitations imposed by the <mathjax>$A$</mathjax> matrix, we’ll start off by considering a downsized version of …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.pyrunner.com/weblog/2016/05/26/compressed-sensing-python/">http://www.pyrunner.com/weblog/2016/05/26/compressed-sensing-python/</a></em></p>]]>
            </description>
            <link>http://www.pyrunner.com/weblog/2016/05/26/compressed-sensing-python/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23884141</guid>
            <pubDate>Sat, 18 Jul 2020 19:34:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Trump's Wobble-Gait Problem]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 3 (<a href="https://news.ycombinator.com/item?id=23884095">thread link</a>) | @scripthacker
<br/>
July 18, 2020 | https://thedeductible.com/2020/07/13/trumps-wobble-gait-problem/ | <a href="https://web.archive.org/web/*/https://thedeductible.com/2020/07/13/trumps-wobble-gait-problem/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-2170">
	
	<!-- .entry-header -->

	<div>
		
<p>By DANIEL STONE, MD (3)</p>



<p>President Trump’s wobbly walk down a ramp at his recent West Point visit along with his awkward&nbsp; two-handed drink from a water glass have stirred recent speculation about a possible undisclosed neurologic issue such as early Parkinson’s Disease.&nbsp; Although no specific conclusions can be drawn from these observations, they raise important questions regarding the President’s health. &nbsp; &nbsp;</p>



<p>Trump would not be the first president to conceal health problems.&nbsp; Toward the end of Franklin Roosevelt’s presidency, his blood pressure rose alarmingly.&nbsp; As no drug treatments existed his doctors could recommend only that he stop smoking, lose weight and avoid dietary salt.&nbsp; Less than six months after an un-knowing public re-elected him to a record fourth term, FDR predictably suffered a fatal stroke.&nbsp; The public was similarly unaware of John Kennedy’s Addison’s Disease, a condition that required daily injections to replace the adrenal hormones his body could not make.&nbsp;</p>



<p>The known facts about Trump’s health are concerning enough. &nbsp; Despite taking a statin drug to reduce his cholesterol, Mr. Trump’s age and risk factors at his 2018 physical predicted a 16.7%&nbsp; risk of a heart attack over ten years, as estimated by a standard American College of Cardiology risk calculator.&nbsp; Trump was taking a statin at the time of that exam to lower his cholesterol.&nbsp; As cholesterol levels on a statin may not reflect risk as accurately as un-treated levels, the calculator may under-estimate his true risk. &nbsp; &nbsp; Although Trump’s doctors tout his health they seemed to be concerned about cardiovascular risk as they subsequently quadrupled his statin dosage, placing him highest dose of the most potent statin available. &nbsp; &nbsp;In addition, the President’s annual exam revealed that his weight recently drifted up into the obese range, which means additional coronary disease risk along with an increased chance of stroke, chronic kidney disease, diabetes and several types of cancers. &nbsp;</p>



<p>&nbsp;Mr.&nbsp; Trump’s judgment on health issues could be questioned given his use of finasteride, a medication used to prevent baldness.&nbsp; The drug, which can cause loss of libido and breast growth in men, was the subject of an FDA warning in 2011 regarding high grade prostate cancer.&nbsp; Although information published in 2019 was reassuring regarding prostate cancer risk, Trump has used the drug since at least 2016, well before this information was available.&nbsp; His apparent willingness to take a vanity drug despite known serious health risks should cause concern regarding his awareness that presidential health issues are more than mere matters of personal preference. &nbsp;</p>



<p>Although the “wobble-gait’ observations are non-specific they raised legitimate concerns about Parkinson’s Disease.&nbsp; Caused by insufficient levels of brain neurotransmitters, the condition slows body movements, disrupts gait stability and produces tremor.&nbsp; As the disease progresses 30% to 40% of Parkinson’s patients develop dementia.&nbsp; 2% of men the President’s age have Parkinson’s and the prevalence increases with time.&nbsp; Even more concerning than the thought of a president with Parkinson’s Disease would be a President taking medication for Parkinson’s Disease .&nbsp; Carbidopa/levodopa, the most commonly used drug, can be associated with mood changes.&nbsp; Other commonly used Parkinson’s drugs are associated with impulsive behaviors, not something that we need to see more of in this President. &nbsp;</p>



<p>The President’s awkward two-handed drink of water is less directly concerning.&nbsp; Parkinson’s Disease produces a hand tremor during rest. &nbsp; Tremors that occur during movement, like drinking from a glass, are&nbsp; “action tremors” which are common and rarely debilitating.&nbsp; But Trump’s use of his offhand to steady the other is the sort of maneuver one might use to suppress an action tremor.&nbsp; This practice might be entirely innocent, but the possibility that the President might be trying to suppress a tremor, like his excessive attempts explain away the gait issue, might lead reasonable people to wonder whether he has something to hide.</p>



<p>The President’s record on health disclosures provides further reason for concern.&nbsp; Dr. Harold Bornstein, Trump’s personal physician, released a statement in 2016 that Trump’s health was “astonishingly excellent” and that he would be the “healthiest individual ever elected to the presidency.”&nbsp; The Trumpian sound of the bombast in the physician’s letter makes more sense after Bornstein’s revelation that the candidate dictated the statement. &nbsp; Bornstein subsequently claimed that Trump’s White House had raided his office and taken all of Trump’s records without following standard procedures. &nbsp;</p>



<p>Although the evidence that Trump harbors a significant neurologic diagnosis is less than convincing it still raises serious concerns.&nbsp; In health matters, as with his personal&nbsp; tax issues, the absence of transparency and the reliance on public relations strategies should concern the public. &nbsp; Regardless of his current neurologic status, anyone with Trump’s risk factors and age would face substantial risk of debilitating&nbsp; health problems over the course of a four-year term.&nbsp; Given what we know, can the public have confidence that a medically disabled Trump would reveal serious health issues&nbsp; and allow Vice-Presidential succession under the terms of the 25<sup>th</sup> Amendment? &nbsp; Ultimately, the presidential health issue for Americans to consider is not whether Trump can walk straight but whether he can talk straight. &nbsp;</p>



<p><em>Dr. Daniel J. Stone is an internal medicine and geriatric specialist in Los Angeles.</em>&nbsp;<em>Dan is a regular contributor to the Deductible.</em>&nbsp;</p>
			</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://thedeductible.com/2020/07/13/trumps-wobble-gait-problem/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23884095</guid>
            <pubDate>Sat, 18 Jul 2020 19:29:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Python async frameworks – Beyond developer tribalism]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23883652">thread link</a>) | @gilad
<br/>
July 18, 2020 | https://www.encode.io/articles/python-async-frameworks-beyond-developer-tribalism | <a href="https://web.archive.org/web/*/https://www.encode.io/articles/python-async-frameworks-beyond-developer-tribalism">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
    <p><br>
I’ve been thinking about writing this article for a bit, but have been most prompted by a post grandly titled “<a href="http://calpaterson.com/async-python-is-not-faster.html">Async Python is not faster</a>”. The post was rooted with some good motivations and observations, but also fell somewhat into a polarising mode of discussion that I’d like to see our communities try to move beyond.</p>

<p>Async concurrency necessarily brings with it an element of ecosystem split, and this can mean that it’s a bit of a divisive area to try to have conversations within.</p>

<p>However I think we could probably benefit from a bit more recognition of where there is shared ground. And in areas where there’s less clarity, to be able to have constructive conversations around the relative merits in differing approaches.</p>

<hr>



<h3 id="-why-you-shouldnt-care-about-performance">★ Why you shouldn’t care about “performance”.</h3>

<p>If you’re starting a new project, and choosing a python async framework vs a python sync framework, then any “performance” metrics around the frameworks <em>almost certainly don’t actually matter</em>, and are almost always a nonsense point of debate.</p>

<p>What is <em>actually</em> critical to your business is the development experience and strength of the surrounding ecosystem. What is your time to market going to be? How will the maintenance overhead be? How robust and evolvable is your codebase?</p>

<h3 id="-why-you-might-care-about-performance">★ Why you might care about “performance”.</h3>

<p>Having said that, there <em>are</em> a small portion of cases where the performance characteristics are a valid consideration. Particularly if your web framework makes lots of outgoing HTTP requests or other networking and I/O.</p>

<p>It’s important for the Python ecosystem that it ought to compare favourably to other dynamic languages in domains where async is beneficial. We don’t want to be in a position where “we’re using JavaScript because we believe it’ll scale up better” is a valid market blocker vs. choosing Python.</p>

<h3 id="-what-were-talking-about-when-we-talk-about-performance">★ What we’re talking about when we talk about “performance”.</h3>

<p>Like-for-like a single async function call in isolation will be marginally slower than a plain function call. That’s not contentious.</p>

<p>What we’re actually interested in is how <em>efficiently</em> we can interleave multiple concurrent tasks. In I/O bound systems co-operative concurrency (async) performs more efficiently under high concurrency than threaded concurrency (sync). Again, not contentious.</p>

<p>Again - Async Python is not faster. It <em>is</em> more efficient. Which will <em>tend</em> to mean that on I/O bound systems, the latency will <em>continue</em> to remain low even as the level of concurrency increases.</p>

<h3 id="-there-are-no-good-benchmarks">★ There are no good benchmarks.</h3>

<p>JSON “hello world” benchmarks are junk. Almost all cases of “I’ve created this benchmark myself” are likely to be junk. The prevalence of new frameworks overly focusing on nebulous benchmarking claims is generally junk. An obsession on benchmarking numbers can also sometimes result in poor overall design choices, such as obfuscated or unnecessarily coupled bits of codebase, because some not-very-meaningful metric is being prioritised over the code design itself. None of this should be contentious.</p>

<p>It’s not <em>always</em> true, for example, when Sanic was introduced there was a genuine step forward which was worth talking about, so I can understand why there was a focus there. But there’s still a ridiculous hype-cycle attached as a result, and we need to be really careful about trying to step beyond that.</p>

<p>It’s also reasonable if benchmarking is discussed in a sensible context and placement. For example, to the extent that Uvicorn and Starlette have discussed performance it has only ever been with a view to making a solid case that having a <em>properly specified</em> server/framework boundary API isn’t a negative performance consideration. Prior to the introduction of ASGI, Python’s async web ecosystem had generally bundled together both the low-level HTTP handling and the high level framework, and there was a notion that needed dispelling that introducing a properly specified separation of concerns wasn’t a good approach because <em>“something something performance something”</em>.</p>

<p>If you <em>are</em> going to look at web framework benchmarks for some very rough first-pass ideas about relative efficiency then the TechEmpower benchmarks should almost certainly be your baseline, since they’re at least independent, and have a decent range of test cases. If you’re going to diverge from them have some good argument for doing so.</p>

<p>The “Async Python is not faster” benchmarking is a reasonable example here, since it had clearly applied a decent degree of thoughtfulness. Even so there were still problems with the methodology, as <a href="https://twitter.com/llanga/status/1271719778324025349">Łukasz Langa did a good job of unpicking</a>.</p>

<p>Having said that, the TechEmpower benchmarks only show throughput, and don’t include any <em>meaningful</em> latency information. There’s actually a good reason for that, since
comparing latencies is really difficult. You can’t arrive at a single “95% latency” figure, because the figure you’ll arrive at <em>also depends on what throughput load you’re putting the system under</em> at the time of measuring the latency.</p>

<p>As a result measuring latency is only ever really meaningful if you’re looking at <em>graphs of how the latencies vary over a range of different throughputs</em>. Amber Brown’s <a href="https://www.youtube.com/watch?v=YxP1I-tm_2c">DjangoCon 2019 keynote talk does a fantastic job of showing some examples here</a>.</p>

<h3 id="-asgi-is-a-really-positive-step-for-the-async-ecosystem">★ ASGI is a really positive step for the async ecosystem.</h3>

<p>Having a decently specified server/framework interface is a <em>really good thing</em>. Andrew Godwin’s design for ASGI fills this gap with a WSGI-like approach. That has a set of trade-offs, but it’s a pretty pragmatic and well rounded choice.</p>

<p>This should not really be contentious.</p>

<h3 id="-its-about-functionality">★ It’s about functionality.</h3>

<p>Async isn’t just about achieving higher levels of concurrency-per-server, it also makes it a bunch of new functionality more feasible, including…</p>

<ul>
  <li>Handling long-lived network connections like Websockets.</li>
  <li>Long-lived HTTP connections and server sent events.</li>
  <li>Dealing with background tasks without necessarily needing a full blown task queue subcomponent.</li>
  <li>Parallelizing outgoing HTTP requests or other high latency I/O.</li>
</ul>

<h3 id="-not-everything-is-perfect">★ Not everything is perfect.</h3>

<p>The async ecosystem is far more immature than the existing thread synchronous. There are different challenges there, such as ensuring that <a href="https://lucumr.pocoo.org/2020/1/1/async-pressure/">backpressure is handled consistently throughout the various async APIs</a>, or in <a href="https://vorpus.org/blog/notes-on-structured-concurrency-or-go-statement-considered-harmful/">applying the lessons of structured concurrency</a>.</p>

<p>Nor is the “stdlib asyncio isn’t perfect” line a good argument either against asyncio specifically, or against async/await in general.</p>

<p>It’s okay that there’s still work to do in places. We know.  Let’s get that work done.</p>

<h3 id="-async-is-harder">★ Async is harder.</h3>

<p>Having to <em>think</em> about if a function does or doesn’t make I/O or could otherwise block <em>is unarguably more complex than not having to think about it</em>. It’s also more precise - you’re having to think about that for a reason, and done properly it’s presenting you with more information as a result. Being able to reason more clearly about which parts of your framework stack do or don’t perform I/O has a cost but also brings benefits.</p>

<p>There’s an analogy to make there in that writing Python using explicitly enforced typing is likely to be a harder than writing Python in an untyped style. It’s harder because you’re <em>also being more precise</em>. That’s not necessarily either good or bad, but it is definitively <em>different</em>.</p>

<p>This also gets to the point about why the “<a href="https://journal.stuffwithstuff.com/2015/02/01/what-color-is-your-function/">What colour is your function</a>” argument isn’t actually a good case against async code, even if it seems to make clear sense on first pass. We’re coloring our functions because we’re <em>enforcing the exposure of some important information all the way throughout the stack</em>. That’s not an inherently bad thing to do.</p>

<hr>



<p>If those are areas where I think we ought to be able to reach consensus on, then there’s also a few areas where I think that the possible outcomes are less clear…</p>

<h3 id="-you-take-the-high-road-and-ill-take-the-low-road">★ You take the high road, and I’ll take the low road.</h3>

<p>There’s a few different tacks we might take onto introducing async into the Python web framework ecosystem…</p>

<ul>
  <li>Promoting mostly staying with threaded web frameworks. There’s actually a perfectly decent case to make that Python <em>on the whole</em> should eschew a <em>wide move towards async</em>. That the drawbacks of moving large swathes of the ecosystem towards an async model outweigh the advantages. (Pros: Simpler for the end developer. Huge existing ecosystem.)</li>
  <li>Working towards blended approaches. This is being championed within the Django community which is incrementally adding async support, largely off the back of some Herculean work by Andrew Godwin and others. This approach can either be in the form of adding support for async at the server level, while keeping the framework level strictly thread-synchronous. Or it can gradually start to expose optional async capabilities all the way through the stack. (Pros: Brings along the existing ecosystem, while adding async capabilities when they’re needed.)</li>
  <li>Working towards async-native frameworks. (Pros: Lower overall complexity of the stack then blended approach. More efficient since there’s less overhead in marshalling between two style all the way through the stack. If we’re having to write large amounts of new code then it’s not a bad inflection point at which to also rethink and finesse other aspects of how we’re putting together new frameworks.)</li>
</ul>

<p>We can’t really say which of these will yield the best dividends. Personally I <em>happen</em> to be working in the last of those three slices, simply because I can see a bunch of areas where I can contribute meaningfully towards the ecosystem there.</p>

<h3 id="-positioning-asyncio-and-trio">★ Positioning asyncio and Trio</h3>

<p>There another big question mark over the relative positioning of asyncio and Trio in the ecosystem. Trio is a newer approach to a Python async framework, that’s meticulously designed, and based on the principles of structured concurrency, that have been outlined by it’s author, Nathaniel Smith.</p>

<p>The difficulty this brings is that Trio is necessarily incompatible with asyncio, and introduces an ecosystem-split within an ecosystem-split.</p>

<p>There’s a few different …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.encode.io/articles/python-async-frameworks-beyond-developer-tribalism">https://www.encode.io/articles/python-async-frameworks-beyond-developer-tribalism</a></em></p>]]>
            </description>
            <link>https://www.encode.io/articles/python-async-frameworks-beyond-developer-tribalism</link>
            <guid isPermaLink="false">hacker-news-small-sites-23883652</guid>
            <pubDate>Sat, 18 Jul 2020 18:33:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Django project structure the right way?]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23883346">thread link</a>) | @rajasimon
<br/>
July 18, 2020 | https://rajasimon.io/django-project-structure/ | <a href="https://web.archive.org/web/*/https://rajasimon.io/django-project-structure/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Proper way to create folder structure for your Django Project.</p><div><p>In this blog post you’ll learn how to create best folder structure for your Django project. Django folder structure is consist of project root and apps. If you are not creating the right folder structure then everything will look complex.</p><p>This guide is for starting the project from scratch. For an established project, please keep this idea in mind and try to add these methods one by one.</p><h2 id="create-a-project">Create a project</h2><p>Creating the project is very easy in Django; It’s just the <code>startproject</code> command, and it will create a few files and folders in your project. Let’s see what those are…</p><pre><code>python manage.py startproject projdir
</code></pre><p>Now the project tree will look like this.</p><pre><code>├── manage.py
└── projdir
    ├── __init__.py
    ├── asgi.py
    ├── settings.py
    ├── urls.py
    └── wsgi.py
</code></pre><p>Now we’ve created the Django project, and now we have two options to proceed. One is to create the apps next to projdir or create an app inside the project folder and will continue developing from it.</p><p><strong>Two Methods</strong></p><ol><li>Create apps after the project folder</li><li>Create apps inside the project folder.</li></ol><p>I like the second approach better because that will gives a clean look into the overall project. It’s very easy and will look like everything seems organised. So let’s create the apps for our project.</p><h2 id="create-apps">Create apps</h2><p>For the second approach we need to create the folder by hand then run the <code>startapp</code> command. This way we can avoid the command error that cause by folder not present in the first place.</p><pre><code>cd projdir
mkdir app1
cd ..
python manage.py startapp core projdir/core
</code></pre><p>Now that we have created the folder structure lets see how the tree structure look like.</p><pre><code>├── manage.py
└── projdir
    ├── __init__.py
    ├── app1
    │&nbsp;&nbsp; ├── __init__.py
    │&nbsp;&nbsp; ├── admin.py
    │&nbsp;&nbsp; ├── apps.py
    │&nbsp;&nbsp; ├── migrations
    │&nbsp;&nbsp; │&nbsp;&nbsp; └── __init__.py
    │&nbsp;&nbsp; ├── models.py
    │&nbsp;&nbsp; ├── tests.py
    │&nbsp;&nbsp; └── views.py
    ├── asgi.py
    ├── settings.py
    ├── urls.py
    └── wsgi.py
</code></pre><p>Apps created by the <code>startapp</code> command will have all the necessary files for the Django app. Now how do we point this to installed apps.</p><h2 id="installed-apps">Installed apps</h2><p>We must tell the Django that our newly created apps dotted path. Then only Django will recognise our app as Django apps otherwise you can’t run migrations and other benefits. Okay let’s see how we can add dotted path in installed apps.</p><p>There is two approach in there one is using the dotted path upto the apps directory or the AppConfig directory.</p><ol><li>Dotted path from root project folder to apps.</li><li>Dotted path from root project folder to AppConfig.</li></ol><p>I can just use the first approach but Django recently pushing developers to use AppConfig much. I say first one is pretty easy to mention. In our case it will be <code>projdir.app1</code></p><p>But the second approach is bit different you need to change the apps.py file <code>name</code> variable then only Django will consider the AppConfig dotted path as valid.</p><pre><code>class App2Config(AppConfig):
    name = "prouder.app2"
</code></pre><p>And in the installed app just mention the path upto AppConfig like this…</p><pre><code>projdir.app2.apps.App2Config
</code></pre><h2 id="conclusion">Conclusion</h2><p>So far, we have seen how to create a folder structure in Django, both normally like and inside the root project folder to avoid the mess.</p><p>You can find all the code in<a href="https://github.com/rajasimon/django-project-structure">github/django-project-structure</a> repository.</p></div><p>This article published under
<a href="https://rajasimon.io/categories/development/">development</a>
on
<a href="https://rajasimon.io/tags/django/">django</a>
tags. Please support me by subscribing to my <a href="https://rajasimon.io/about">Newsletter</a>.
By subscribing you will not miss any <strong>future</strong> articles in this category.</p></div>]]>
            </description>
            <link>https://rajasimon.io/django-project-structure/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23883346</guid>
            <pubDate>Sat, 18 Jul 2020 18:03:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What TikTok Got Right]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23882929">thread link</a>) | @rauchp
<br/>
July 18, 2020 | http://blog.rauchp.com/posts/2 | <a href="https://web.archive.org/web/*/http://blog.rauchp.com/posts/2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><h4>(No, this isnâ€™t a political statement)</h4><h4>July 17th, 2020</h4></p><div><p>As a member of the hyped-up Gen Z, youâ€™d think Iâ€™d be an expert on TikTok. But no, I only downloaded it this week because I heard it might be taken down soon.</p>
<p>It turns out TikTok is kinda cool. Thatâ€™s not to say I think it should or shouldnâ€™t get banned, but itâ€™s easy to see the appeal after a week of using it. </p>
<p>And ironically, TikTok is a lot more democratic than a lot of other social networks.</p>

<p>Partly, because of the shared toolkit.</p>
<p>On Instagram, the 3rd party toolkit ranges from airbrush apps to After Effects.
On Youtube you have kids using <a href="https://www.youtube.com/watch?v=TKfS5zVfGBc">unregistered HyperCam 2â€™s</a> pitted against aspiring Jake Paulâ€™s using Adobe Premiere.</p>
<p>But on TikTok, almost all videos are filmed on mobile devices and edited in the app itself. You canâ€™t assume much based on a thumbnail or the production quality of a clip.</p>
<p>This means I can put less effort + time into production quality and making sure my videos meet at a base standard. <strong>The friction from idea to delivered video is significantly less</strong> on TikTok vs. the other two platforms.</p>

<p>Then thereâ€™s the infinite scroll governed by <em>the algorithm</em>.</p>
<p>Every major social network has one of these algorithms, and they all seem to be equally mysterious. Your entire future might be decided by a set of ever-changing ifâ€™s and elseâ€™s written in SV or Beijing.</p>
<p>And while most platforms use their feed algorithms to maximize engagement, TikTok uses it to maximize meme discovery.â€&nbsp;</p>
<p>Can I compete against Addison Raeâ€™s profile? Probably not, but apparently you can sneak in a lot more dancing Chilean software engineers on my TikTok Feed than my IG Explore feed. If social media is a status game, putting players on equal footing is just about the greatest thing you can do for engagement. And really, <strong>you only have to make people think they have a chance</strong>.</p>

<p>So the common theme here is that TikTok did one thing really well: create an efficient meme factory. <strong>The conversion from idea to meme is near-frictionless. The distribution of your newly created meme is effortless.</strong> No need to growth hack with suggestive thumbnails and follow-4-followâ€™s, just let the algorithm run its course.</p>
<p>Rather than let attention follow a power-law distribution, <strong>TikTok democratized attention</strong> and memes.</p>
<p>And while Iâ€™m no advocate for fallible centralized systems (the Algorithm controls enough about our lives as is), itâ€™s a damn good way to grow a social network.</p>

<p>As a side note, some of my friends work on Instagramâ€™s algorithms. I've seen the work Facebook is putting into similar efforts. But now Iâ€™m forced to see Instagram as a dying network. A culture built on flexing* and highlighting your best moments canâ€™t compete against a culture that embraces mass-participation and sharing everyday living. </p>
<p>Just ask yourself, in our brave new post-flex world, where will you turn to find relatable content?</p>

<p>â€&nbsp; Of course, this is all assuming the algorithm isnâ€™t compromised. The risk of bad actors abusing it in order to subtly influence us and our youth is real.</p>
<p>* Because of all this Covid-19 funny business, we may very well be entering into a post-flex era of social media. This might be what finally changes Instagramâ€™s culture. So either we slowly turn our main Instagrams into our Finstas, or Instagram will become a place dominated by shitty FuckJerry accounts and generic aesthetic pictures. So basically, an inferior blend of Pinterest and Twitter.</p></div></div>]]>
            </description>
            <link>http://blog.rauchp.com/posts/2</link>
            <guid isPermaLink="false">hacker-news-small-sites-23882929</guid>
            <pubDate>Sat, 18 Jul 2020 17:17:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Next Frontiers of Search]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23882927">thread link</a>) | @laybak
<br/>
July 18, 2020 | https://knowledgeartist.org/articles/future-of-search | <a href="https://web.archive.org/web/*/https://knowledgeartist.org/articles/future-of-search">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>A quick introduction: I have spent quite some time working on (and daydreaming about) search, and mapping human knowledge. Both as a PM at <a target="_blank" href="https://www.google.com/search?q=bing">Bing</a>, and with my current projects with <a target="_blank" href="https://getrumin.com/">Rumin</a>.</p>
        <p>This post is more speculations about the future and plausible paths to get there, than a rigorous research report. If you are interested in the latter, <a target="_blank" href="mailto:john@knowledgeartist.org">email me</a> or <a target="_blank" href="https://twitter.com/jhlyeung">tweet at me @jhlyeung</a>.  </p>
        <h3>Search engines today</h3>
        <p>Today, a vast amount of content that is available in public can be looked up within miliseconds.</p>
        <p>In addition to the 10 blue links on the results page, search engines also provide: </p>
        <li>Instant answers and question answering, e.g. "<a target="_blank" href="https://www.google.com/search?q=weather+in+toronto">weather in Toronto today</a>",  "<a target="_blank" href="https://www.bing.com/search?q=MSFT+stock+price">MSFT stock price</a>", "<a target="_blank" href="https://www.google.com/search?q=who+is+the+president+of+the+u">Who is the president of the US?</a>"</li>
        <li>Voice assistants reading instant answers, playing the wrong song on Spotify, turning on lights to flex in front of your guests</li>
        <p>It is an impressive feat of engineering, and has been great for answering simple questions and looking up facts. But what lies ahead if we dare imagine the future possibilities?</p>
        <h3>No search at all</h3>
        <p>To get the piece of information you are looking for, going to google.com can sometimes feel like a hassle. A few clicks each time, plus the context switching, can add up in terms of time costs. </p>
        <p>A more desirable experience is to have the knowledge delivered to you, to whatever app or workspace you are in. So that you can get the information and resume what you are doing.</p>
        <p>You already see patterns like this today, where there many entry points to the search engine:</p>
        <li>The url address bar in the browser doubles as a search box</li>
        <li>The browser "New tab" page has a search box</li>
        <li>Operating systems have a search box: Spotlight on Mac. Cortana on Windows. Same deal on mobile</li>
        <li>"Smart lookup" in Microsoft Office products</li>
        <p>One day, we shall see a reincarnation of Clippy. One day.</p>
        <p>The idea is that you want the information the moment you need it. We will find more and more ways to eliminate the friction that stands between you and what you are searching. </p>
        <p>This brings us to our next point - searching across apps.</p>
        <h3>Intent understanding. Information layer across apps &amp; contexts</h3>
        <p>Everyone has experienced some version of trying to find a document or message across emails, instant messages, cloud storage, notes etc.</p>
        <p>At the time of writing, this is still largely the case. Though there are a sea of big companies and startups alike working on solving this. It is a rather straightforward problem of integrating with various data sources and indexing the content. </p>
        <p>So it is probably safe to expect this to be less of an issue over time.</p>
        <p>We would always be looking for shortcuts to get what we are looking for, faster. This is a part of a much bigger trend of automation and connected apps, which is not limited to search. </p>
        <p>But search engines, as a general-purpose intent understanding machine, have a big role to play in this. We can expect to see more deep links and actions being accessible from a central interface. Alexa playing your favorite podcast is only the beginning. </p>
        <h3>Querying huge, generative language models</h3>
        <p>When you have a question, the most natural thing to do for most people is to ask someone. </p>
        <p>When Google came along and became a verb, the convention became to just ask the Googs. Sure there are still loads of questions it can't answer, that a real person can. But it's good enough. And it's instant.</p>
        <p>That could very well change in the near future. Generative language models that are trained a huge corpus of human-generated data on the internet can spit out answers that are often as good as a real human's response.</p>
        <p>At the time of writing, OpenAI recently released an API to its latest GPT-3 model. From all the anecdotes I have read, it seems it is pretty darn good! Generating a general purpose human-like response seems to good enough to be usable. </p>
        <p>It does seem too far for a language model to do what the search engine currently does, provided that it can:</p>
        <li>Map the generated output to a credible source. This would address the "black box" concerns that people have.</li>
        <li>Refresh content - "index" and "train" on fresh content. This is similar to how a human being would "stay updated" by reading the news and having conversations. </li>
        <p>When that happens, perhaps we wouldn't even call it a search engine. Would "oracle" seem more apt?</p>
        <h3>Indexing the unindexed knowledge</h3>
        <p>Both search engines and large language models rely on crawled data on the web. This means the scope of their knowledge and capabilities are limited to that dataset. </p>
        <p>In particular, the limitations include: </p>
        <li>The content must be published somewhere on the web, and is publicly available. This excludes the wealth private and individual knowledge.</li>
        <li>Data on the web is predominantly text. Which means scope is limited to whatever can be expressed in natural language. There is a tremendous amount of implicit or tacit knowledge that is hard to transfer verbally.</li>
        <li>Content tends to be shallow. There are countless domains of knowledge that are still not very legible and accessible, even for humans.</li>
        <p>Given the limitations, here are a few exciting areas of development:</p>
        <li>Indexing private knowledge, and integrating it with the collective public knowledge. </li>
        <li>Better UIs and formats, to help externalize and digitze complex ideas that are hard to convey in plain text.</li>
        <li>Represent and map out the deep knowledge in each field.</li>
        <p>That covers the knowledge side of things. But so much of the human condition isn't about just knowing...</p>
        <h3>Indexing perception, emotions, and experiences  </h3>
        <p>What we know accounts for just a small fraction of our conscious experience. There are myriad sensations that are hard to even find words for. This is especially true for experiences in altered states - for instance, from meditation, bodily movements, or consuming substances.</p>
        <p>But what if we can enlist the help of machines to map out and navigate how we feel? Can we index an emotional experience and construct a sequence of steps to recreate or revisit this moment?</p>
        <p>This sounds incredibly challenging. And by this point we are venturing quite far into the future. It would be fun though, to entertain a few possibilities. </p>
        <p>It helps to recognize that we already have reliable heuristics, in various domains of art, that roughly predict what our experiences will be like. Eating ice cream on a hot summer day is satisfying. Stomping backbeats make music easy to dance to. Symmetry is generally pleasing to the eye. Exercising makes you tired in the moment, and you feel good at night.</p>
        <p>These broad stroke heuristics are distilled from many instances of trial-and-error and observations. What happens if we more systematically gather data at scale and analyze it?</p>
        <p>We could in principle achieve fine-grained predictions and control of human experiences: in terms of precision in time, evoking the exact sensation desired, and personalization.</p>
        <p>In this setup, the role of human beings would be sensors and interpreters, while machines maintain and find patterns in the collective data.</p>
        <p>Perhaps soon enough, we would be able to guess the inner state of any person, based on known information about the sequence of inputs and stimuli in the current environment. And the machine can construct a model of the person's mind, as a time-series sequence of perceptual frames, with each frame being a digital representation (say, an embedding) of the sensation.</p>
        <p>This is a good place to wrap. I will elaborate and flesh out some of the themes above in future posts. </p>
        <p>What an exciting world we live in!</p>
          
      </div></div>]]>
            </description>
            <link>https://knowledgeartist.org/articles/future-of-search</link>
            <guid isPermaLink="false">hacker-news-small-sites-23882927</guid>
            <pubDate>Sat, 18 Jul 2020 17:17:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Instant access to your shell init files]]>
            </title>
            <description>
<![CDATA[
Score 34 | Comments 9 (<a href="https://news.ycombinator.com/item?id=23882784">thread link</a>) | @todsacerdoti
<br/>
July 18, 2020 | http://emacsredux.com/blog/2020/07/16/instant-access-to-your-shell-init-files/ | <a href="https://web.archive.org/web/*/http://emacsredux.com/blog/2020/07/16/instant-access-to-your-shell-init-files/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
        <p>A long time I presented a <a href="http://emacsredux.com/blog/2013/09/27/instant-access-to-your-shell-init-file/">simple hack</a> that allowed you to
quickly navigate to your shell’s user config file (e.g. <code>.bashrc</code> or
<code>.zshrc</code>). While the solution gets the job done it was pretty basic and
limited - most notably it’d ignore the fact that you typically have several
shell config files that are often built on top of each other - e.g.  <code>/etc/profile</code>,
<code>~/.bash_profile</code> and <code>~/.bashrc</code>. Fortunately the original
hack evolved rather nicely and today lives in the
<a href="https://github.com/bbatsov/crux">crux</a> library under the name
<code>crux-find-shell-init-file</code>.<sup id="fnref:1"><a href="#fn:1">1</a></sup></p>

<p>Provided you’ve installed <code>crux</code> all you need to do is run that command
(e.g. with <code>M-x crux-find-shell-init-file</code>) and you’ll get something like this
as the result:</p>

<p><img src="http://emacsredux.com/assets/images/instant_shell_config.png" alt="instant_shell_config.png"></p>

<p>Pretty neat, right? Even in its updated state the command is not complex at all:</p>

<div><div><pre><code><span>(</span><span>defun</span> <span>crux-find-shell-init-file</span> <span>()</span>
  <span>"Edit the shell init file in another window."</span>
  <span>(</span><span>interactive</span><span>)</span>
  <span>(</span><span>let*</span> <span>((</span><span>shell</span> <span>(</span><span>file-name-nondirectory</span> <span>(</span><span>getenv</span> <span>"SHELL"</span><span>)))</span>
         <span>(</span><span>shell-init-file</span> <span>(</span><span>cond</span>
                           <span>((</span><span>string=</span> <span>"zsh"</span> <span>shell</span><span>)</span> <span>crux-shell-zsh-init-files</span><span>)</span>
                           <span>((</span><span>string=</span> <span>"bash"</span> <span>shell</span><span>)</span> <span>crux-shell-bash-init-files</span><span>)</span>
                           <span>((</span><span>string=</span> <span>"tcsh"</span> <span>shell</span><span>)</span> <span>crux-shell-tcsh-init-files</span><span>)</span>
                           <span>((</span><span>string=</span> <span>"fish"</span> <span>shell</span><span>)</span> <span>crux-shell-fish-init-files</span><span>)</span>
                           <span>((</span><span>string-prefix-p</span> <span>"ksh"</span> <span>shell</span><span>)</span> <span>crux-shell-ksh-init-files</span><span>)</span>
                           <span>(</span><span>t</span> <span>(</span><span>error</span> <span>"Unknown shell"</span><span>))))</span>
         <span>(</span><span>candidates</span> <span>(</span><span>cl-remove-if-not</span> <span>'file-exists-p</span> <span>(</span><span>mapcar</span> <span>'substitute-in-file-name</span> <span>shell-init-file</span><span>))))</span>
    <span>(</span><span>if</span> <span>(</span><span>&gt;</span> <span>(</span><span>length</span> <span>candidates</span><span>)</span> <span>1</span><span>)</span>
        <span>(</span><span>find-file-other-window</span> <span>(</span><span>completing-read</span> <span>"Choose shell init file: "</span> <span>candidates</span><span>))</span>
      <span>(</span><span>find-file-other-window</span> <span>(</span><span>car</span> <span>candidates</span><span>)))))</span>
</code></pre></div></div>

<p>I guess one thing that we can improve down the road is adding an option to
display the shell config in the same window, but that’s a small thing.  The variables
like <code>crux-shell-bash-init-files</code> are simply lists of all potential files that
we should look for, that’s why I’ve opted to omit them from the code listing.</p>

<p>I stand by my original suggestion to bind this useful command to <code>C-c S</code>:</p>

<div><div><pre><code><span>(</span><span>global-set-key</span> <span>(</span><span>kbd</span> <span>"C-c S"</span><span>)</span> <span>#'</span><span>crux-find-shell-init-file</span><span>)</span>
</code></pre></div></div>

<p>That’s all I have for you today! Meta-x forever!</p>



    </div></div>]]>
            </description>
            <link>http://emacsredux.com/blog/2020/07/16/instant-access-to-your-shell-init-files/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23882784</guid>
            <pubDate>Sat, 18 Jul 2020 16:58:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Segfault Episode 2: Computer Vision with Professor Bharath Hariharan]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23882743">thread link</a>) | @sohamsankaran
<br/>
July 18, 2020 | https://honestyisbest.com/segfault/2020/Jul/17/computer-vision/ | <a href="https://web.archive.org/web/*/https://honestyisbest.com/segfault/2020/Jul/17/computer-vision/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<h3>About this series</h3>
<p>Computer Science is composed of many different areas of research, such as Algorithms, Programming Languages, and Cryptography. Each of these areas has its own problems of interest, publications of record, idioms of communication, and styles of thought.</p>
<p><strong>Segfault</strong> is a podcast series that serves as a map of the field, with each episode featuring discussions about the core motivations, ideas and methods of one particular area, with a mix of academics ranging from first year graduate students to long tenured professors.</p>
<p>I’m your host, Soham Sankaran, the founder of <a href="https://pashi.com/">Pashi</a>, a start-up building software for manufacturing. I'm on leave from the PhD program in Computer Science at Cornell, where I work on distributed systems and robotics, and I started Segfault to be the guide to CS research that I desperately wanted when I was just starting out in the field.</p>

<p><strong>twitter</strong>: <a href="https://twitter.com/sohamsankaran">@sohamsankaran</a>,
<strong>website</strong>: <a href="https://soh.am/">https://soh.am</a>,
<strong>email</strong>: soham [at] soh [dot] am.</p>



  <hr id="read_post">
<h2>Episode 2: Computer Vision with Professor Bharath Hariharan</h2><p>
featuring Professor Bharath Hariharan of Cornell University
</p>
<p>Cornell Professor and former Facebook AI Researcher Bharath Hariharan joins me to discuss what got him into Computer Vision, how the transition to deep learning has changed the way CV research is conducted, and the still-massive gap between human perception and what machines can do.</p>

<p>Consider <a href="https://honestyisbest.com/segfault#subscribe_top" onclick="goToAnchor('subscribe_top'); return false;">subscribing via email</a> to receive every episode and occasional bonus material in your inbox.</p>

<p><em>Soham Sankaran’s <a href="https://ycombinator.com/">Y Combinator</a>-backed startup, <a href="https://pashi.com/">Pashi</a>, is recruiting a software engineer to do research-adjacent work in programming languages and compilers. If you’re interested, email <strong>soham [at] pashi.com</strong> for more information.</em></p>

<p><a href="https://honestyisbest.com/segfault/2020/Jul/17/computer-vision/#transcript_anchor" onclick="goToAnchor('transcript_anchor'); return false;">Go to transcript</a><br>
Note: If you’re in a podcast player, this will take you to the Honesty Is Best website to view the full transcript. Some players like <a href="https://podcastaddict.com/">Podcast Addict</a> will load the whole transcript with time links below the Show Notes, so you can just scroll down to read the transcript without needing to click the link. Others like Google Podcasts will not show the whole transcript.</p>

<h2 id="show-notes">Show notes</h2>

<p><strong>Participants:</strong></p>

<p><a href="https://soh.am/">Soham Sankaran</a> (<a href="https://twitter.com/sohamsankaran">@sohamsankaran</a>) is the founder of <a href="https://pashi.com/">Pashi</a>, and is on leave from the PhD program in Computer Science at <a href="https://www.cs.cornell.edu/">Cornell University</a>.</p>

<p><a href="http://home.bharathh.info/">Professor Bharath Hariharan</a> is an Assistant Professor in the Department of Computer Science at Cornell University. He works on recognition in Computer Vision.</p>

<p><strong>Material referenced in this podcast:</strong></p>

<p>‘Building Rome in a Day’, a project to construct a 3D model of Rome using photographs found online from the Univeristy of Washington’s Graphics and Imaging Lab (Grail): <a href="https://grail.cs.washington.edu/rome/">project website</a>, <a href="https://grail.cs.washington.edu/rome/rome_paper.pdf">original paper</a> by Sameer Agarwal, Noah Snavely, Ian Simon, Steven M. Seitz, and Richard Szeliski in ICCV 2009.</p>

<p>The Scale-Invariant Feature Transform (SIFT) algorithm: <a href="https://en.wikipedia.org/wiki/Scale-invariant_feature_transform">wikipedia</a>, <a href="https://www.cs.ubc.ca/~lowe/papers/iccv99.pdf">original paper</a> by David G. Lowe in ICCV 1999.</p>

<p>The Perceptron: <a href="https://en.wikipedia.org/wiki/Perceptron">wikipedia</a>, <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.335.3398&amp;rep=rep1&amp;type=pdf">original paper</a> by Cornell’s own <a href="https://en.wikipedia.org/wiki/Frank_Rosenblatt">Frank Rosenblatt</a> in <a href="https://en.wikipedia.org/wiki/Psychological_Review">Psychological Review</a> Vol. 65 (1958). Rosenblatt was a brilliant psychologist with exceptionally broad research interests across the social sciences, neurobiology, astronomy, and engineering. The perceptron, which is a forerunner of much of modern artificial intelligence, initially received great acclaim in academia and the popular press for accomplishing the feat of recognizing triangular shapes through training. In the 60s, however, legendary computer scientists <a href="https://en.wikipedia.org/wiki/Marvin_Minsky">Marvin Minsky</a> (a high-school classmate of Rosenblatt’s) and <a href="https://en.wikipedia.org/wiki/Seymour_Papert">Seymour Papert</a> released a book, <a href="https://en.wikipedia.org/wiki/Perceptrons_(book)">Perceptrons</a>, that made the argument that the perceptron approach to artificial intelligence would fail at more complex tasks, resulting in it falling out of fashion for a few decades in favour of Minsky’s preferred approach, <a href="https://en.wikipedia.org/wiki/Symbolic_artificial_intelligence">Symbolic AI</a>. Symbolic AI famously failed to produce tangible results, resulting in the <a href="https://en.wikipedia.org/wiki/AI_winter">AI winter</a> of the 80s and 90s, a fallow period for funding and enthusiasm. Rosenblatt, meanwhile, died in a boating accident in 1971 at the relatively young age of 43, 40 years too early to see himself vindicated in the battle between Minsky’s Symbolic AI and what we now call Machine Learning.</p>

<p>Bharath’s CVPR 2015 paper <a href="https://arxiv.org/abs/1411.5752">Hypercolumns for Object Segmentation and Fine-grained Localization</a> with Pablo Arbeláez, Ross Girshick, and Jitendra Malik, in which information pulled from the middle layers of a convolutional neural network (CNN) trained for object recognition was used to establish fine-grained boundaries for objects in an image.</p>

<p><a href="http://www.image-net.org/">ImageNet</a>, originally created by then Princeton (now Stanford) Professor <a href="https://profiles.stanford.edu/fei-fei-li">Fei-Fei Li</a> and her group in 2009: A vast database of images associated with common nouns (table, badger, ocean, etc.). The high quality &amp; scale of this dataset, combined with the <a href="http://www.image-net.org/challenges/LSVRC/">vigorous competition</a> between groups of researchers to top the ImageNet benchmarks, fuelled massive advances in object recognition over the last decade.</p>

<p><strong>Credits:</strong></p>

<p>Created and hosted by Soham Sankaran.</p>

<p>Mixed and Mastered by <a href="https://www.youtube.com/channel/UC7_0sQfCXyofKxxfo0yTXLA/about">Varun Patil</a> (<a href="mailto:varunpatil.audio@gmail.com">email</a>).</p>

<p>Transcribed by Sahaj Sankaran &amp; Soham Sankaran.</p>

<h2 id="transcript_anchor">Transcript</h2>

<p>[00:00:00]<br>
<strong>Bharath Hariharan:</strong> Humans can basically very quickly learn new things. They know exactly when they see something new, they can learn from very few training examples, and they can learn with very little computational effort. Whereas current techniques, they can only learn a small number of things with lots of examples and lots of computational effort. That’s a big gap which causes all sorts of issues when you apply these techniques to the real world.</p>

<p>[ringing tone]</p>

<p>[00:00:38]<br>
<strong>Soham Sankaran:</strong> Welcome to Episode 2 of Segfault, from Honesty is Best. Segfault is a podcast about Computer Science research. This episode is about computer vision, and it features Professor Bharath Hariharan from Cornell University. I’m your host, Soham Sankaran. I’m the CEO of Pashi, a startup building software for manufacturing, and I’m on leave from the Ph.D program at Cornell University, located in perpetually sunny Ithaca, New York.</p>

<p>I’m the CEO of Pashi, a start-up building software for manufacturing, and I’m on leave from the PhD program in Computer Science at Cornell University, located in perpetually sunny Ithaca, New York. Computer Science is composed of many different areas of research, such as Operating Systems, Programming Languages, Algorithms and Cryptography. Each of these areas has its own problems of interest, publications of record, idioms of communication, and styles of thought, not to mention, one level deeper, a multitude of sub-areas, just as varied as the areas they are contained within.</p>

<p>This can get extremely confusing very quickly, and I certainly didn’t know how to navigate this terrain at all until I was in graduate school. Segfault, in aggregate, is intended to be a map of the field, with each episode featuring discussions about the core motivations, ideas and methods of one particular area, with a mix of academics ranging from first year graduate students to long tenured professors. I hope that listeners who have dipped their toes in computer science or programming, but haven’t necessarily been exposed to research, get a sense of not only the foundations of each area – what work is being done in it now, and what sorts of opportunities for new research exist for people just entering, but also what it is about each specific area that compelled my guests to work in it in the first place, and what the experience of doing research in that area every day actually feels like.</p>

<p>This is the map of CS that I didn’t even know I desperately wanted in high school and undergrad, and I hope folks who are just starting their journey in computer science will find within it ideas that will excite them so much, and so viscerally, that they can’t help but work on them.</p>

<p>Just a quick note. The first episode was about the research area of programming languages. If you haven’t already listened to it, you can find it at <a href="https://honestyisbest.com/segfault/2020/Jun/16/programming-languages">honestyisbest.com/segfault</a>. My company, Pashi, is actually hiring someone with experience in programming languages and compilers, both in industry and in academia. If you fit this description, or know somebody that does, please reach out – send me an email at soham@pashi.com.</p>

<p>[ringing sound]</p>

<p>[00:02:44]<br>
<strong>Soham:</strong> So I’m with Professor Bharath Hariharan, who does computer vision. If you just want to introduce yourself briefly…</p>

<p>[00:02:50]<br>
<strong>Bharath:</strong> I’m Bharath. I do computer vision and machine learning. My interests are in visual recognition. I came here after a few years at FAIR – Facebook AI Research – and before that I was a Ph.D student at UC Berkeley.</p>

<p>[00:03:03]<br>
<strong>Soham:</strong> Where you worked with Jitendra Malik, who is one of the pioneers of vision recently.</p>

<p>[00:03:10]<br>
<strong>Bharath:</strong> Yeah. He’s one of the… yes.</p>

<p>[00:03:15]<br>
<strong>Soham:</strong> So, what was it that got you into computer vision in the first place? What was your journey to choosing this as a research field?</p>

<p>[00:03:21]<br>
<strong>Bharath:</strong> A variety of things. So I think the first source of my interest was that I was actually originally interested in psychology and how brains work. I think that’s been a longstanding interest of mine, and when I started working on computer science, when I started studying computer science, that was the thing I kept going back to. Like, why can’t computers do the things humans can? The other part of it was just images and visual media. Earlier, I had a brief infatuation with computer graphics, which also led to this question of ‘Why can’t machines understand images as well as humans do?’ So that’s sort of roughly the route I took, which is a fairly short route, but it serves as the motivation.</p>

<p>[00:04:12]<br>
<strong>Soham:</strong> What was the first problem that was very interesting for you in vision? Or the first problem that you worked on?</p>

<p>[00:04:18]<br>
<strong>Bharath:</strong> So the first problem I worked on was very different from the first problem that caught my interest.</p>

<p>[laughter]</p>

<p>The first problem I worked on was this problem of 3D deconstruction. I was in IIT-Delhi at the time, and one of my mentors, Professor <a href="http://www.cse.iitd.ernet.in/~suban/">Subhashish Banerjee</a> – we called him …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://honestyisbest.com/segfault/2020/Jul/17/computer-vision/">https://honestyisbest.com/segfault/2020/Jul/17/computer-vision/</a></em></p>]]>
            </description>
            <link>https://honestyisbest.com/segfault/2020/Jul/17/computer-vision/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23882743</guid>
            <pubDate>Sat, 18 Jul 2020 16:54:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Team Improvement Techniques]]>
            </title>
            <description>
<![CDATA[
Score 45 | Comments 7 (<a href="https://news.ycombinator.com/item?id=23882701">thread link</a>) | @cauliflower99
<br/>
July 18, 2020 | http://www.dcaulfield.com/team-improvement-techniques/ | <a href="https://web.archive.org/web/*/http://www.dcaulfield.com/team-improvement-techniques/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-15632">
<small>
    <a href="http://www.dcaulfield.com/2020/07/06/">July 6, 2020</a></small>
    			<small>
				<a href="http://www.dcaulfield.com/author/admin/"></a></small>
		
<p>In the last couple of months since Ireland announced the lockdown, our team has been performing at a high pace and have become self-organised to a large extent. As a team lead, this has allowed me the privilege of stepping back to look at the broader picture of how our team works individually and, more importantly, together. Through some exercises, I have identified some  methods to gather improvement ideas that can be applied to any team. </p>



<p>Anyone who has been a part of a high functioning team understands that continuous improvement is not optional. In order to perform better and to keep performing, the team must identify their weaknesses and plan to strengthen or mitigate those weaknesses. These improvements remedy stress points in the team, technical debt, repetitive tasks and so forth. The mindset of continuous growth is one that must be worked on and nurtured over time. Your team is not a fine wine – it will not improve if left alone in the corner. It will go sour.</p>



<p>It is one thing to be told to improve something. But very often, being told to improve something does not necessarily benefit you or your team.&nbsp;For example, if my manager comes to me and tells me my communication is poor and he wants bi-weekly emails from now on from my team’s status, all he has done is improve one of his problems, not mine. Improvements must come from within the team, and they must be gathered and executed on regularly. So the question is – how do we gather improvements that are worthwhile and specific enough to solve our problems, not someone else’s?</p>



<h2>80/20 Analysis</h2>



<p>The Pareto Principle, most commonly known as the 80/20 rule, states that about 80% of the effects come from 20% of the causes. In layman’s terms, most of the good things your team is known for doing likely comes from a small subset of your total work.</p>



<p>In my case, my team is known for our expertise in the upgrading of our product. How much of our work is related to this each week? I’d estimate less than 10%.</p>



<p>S<em>ide note</em>: This wasn’t always the case. When we first formed as a team, we spent about 90% of our time on this work. </p>



<p>Over time our mindset of continuous improvement led us to automating away most of our problems. Here is how you can utilize the 80/20 rule to find pressure points to improve. I do this regularly by myself, and occasionally with my team.</p>



<h3>Create a chart.</h3>



<p>Drawing on a piece of paper or whiteboard produces far more ideas than typing on a screen. So create a chart!</p>



<h4>What is going poorly?</h4>



<p>Always start with the bad. What makes you stressed on a Monday? Why does your team constantly get called for customer escalations on a Sunday? What makes you cry at night? (If you’re crying at night you really need this). </p>



<p>Copy the following table onto a piece of paper and fill it out now with any ideas you have.</p>



<figure><table><thead><tr><th><strong>20% Activity</strong></th><th><strong>80% Pain</strong></th><th><strong>Action to Remedy</strong></th></tr></thead><tbody><tr><td>Monday morning team presentation to management.</td><td>Stressful if I’m not prepped.</td><td>Give a practice run to my team on Friday.</td></tr></tbody></table></figure>



<h4>What is going well?</h4>



<p>This is less effective than analyzing what is poor in the team. You should prioritise fixing the bad over improving the good. There is no point in improving what your team is already good at if there are still issues that stress them. </p>



<p>Ask yourself – what are your team doing well? What do you need to keep doing well? What would happen if you improved these items?</p>



<p>Again, copy the following table onto a piece of paper and fill it out.</p>



<figure><table><thead><tr><th><strong>20% Activity</strong></th><th><strong>80% Reward</strong></th><th><strong>Improvement reward</strong></th><th><strong>Action to improve</strong></th></tr></thead><tbody><tr><td>Quick bug turnaround.</td><td>No weekend work.</td><td>Become the team with the lowest bug turnaround time.</td><td>Make incoming bugs a priority over stories.</td></tr></tbody></table></figure>



<p>You see the action columns? Take those, discuss with the team whether they agree on the actions required, and put them clearly for all to see everyday. You could create a task in your backlog that gets seen everyday on your sprint board, or print them and place them in your team’s area.</p>



<h2>Preventative Actions</h2>



<p>Identifying Preventative Actions is something that I have recently come across. Each team in my project go through this process every 3 weeks (every sprint). Here’s how it works. </p>



<p>A high priority bug has come into your team. You have spent all weekend pouring over it with your team, and finally came up with a solution late Sunday night, allowing your customer to continue their business as usual. Before you close the bug, there are a couple of things you need to consider and you <strong>must</strong> get answers to them. Otherwise, there will be another weekend in the future that will interrupt your team.</p>



<h3>Why did this bug occur?</h3>



<ul><li>We received a bad requirement specification from our business analysts.</li><li>We missed a corner case in our testware.</li><li>There were too many manual steps in the documentation which led to human error.</li><li>We missed a critical part of our study when planning the requirement.</li></ul>



<h3>What correction did you apply?</h3>



<ul><li>We built a patch fix and sent it to the customer.</li><li>We clarified with the customer that the particular use case reported is not supported yet.</li></ul>



<h3>How will you prevent this type of issue from occurring in the future?</h3>



<ul><li>We will call a 1 hour meeting with our business analyst each week to plan and clarify the feature request.</li><li>We will build a new pipeline that will test our customer’s use case each night.</li><li>We will automate steps x,y and z in our documentation so that human error is reduced.</li></ul>



<p>In my team’s case, for each bug we have the following grid which we fill out.</p>



<figure><table><thead><tr><th><strong>Root Cause</strong></th><th><strong>Correction Applied</strong></th><th><strong>Preventative Action</strong></th></tr></thead><tbody><tr><td>A test case to click on the ‘About’ page in Firefox was missing from our GUI test suite.</td><td>Added this test case to the GUI suite.</td><td>Review GUI test cases as part of a feature sign-off in the future.</td></tr></tbody></table></figure>



<h2>Retrospective</h2>



<p>If your team uses the scrum framework for their work, then you will be very familiar with the retrospective. However, you do not need to work in a scrum environment to have a team retrospective. </p>



<p>Team retrospectives, if taken regularly, can be a valuable tool in the team’s work week and is an opportunity for the team to come together and discuss the good and bad things that have happened in the past few weeks. </p>



<p>A retro should be scheduled on a regular basis, and you as the team lead must lead the meeting. Make sure that everyone from the team is present for the retro, and ensure that everyone is taking part and answering the questions.</p>



<h3>What was good that you need to keep doing?</h3>



<ul><li>We closed out 100% of our stories for the sprint.</li><li>There was good communication with our management.</li><li>We trialed pair programming this sprint – we have seen excellent results and should continue to do this.</li></ul>



<h3>What was bad?</h3>



<ul><li>We had poor communication within the team.<ul><li><em>Improvement</em>: We will trial pair programming for a sprint.</li></ul></li><li>The QA team raised tickets with very little detail resulting in a few days of delay in closing.<ul><li><em>Improvement</em>: Create a template that you would find helpful and send it to the QA team lead. Request that they copy this template and fill it out for all future tickets.</li></ul></li><li>We allowed untested code into the production software.<ul><li><em>Improvement</em>: Revise the +2 code review criteria with the team.</li></ul></li></ul>



<p>The most important part of the retro is to make sure that improvements or solutions are attached to each ‘bad’ item that is discussed.<br>At the end of the retro, prioritise the top one or two improvements, and take note of them for the upcoming sprint to execute.</p>



<h2>Improvement Backlog</h2>



<p>To become a top performing team, each individual must be comfortable with raising and discussing improvements as part of the team’s responsibilities. A team that does not have improvement ideas is a team that is not interested in improving which will lead to stagnation and a low performing team.</p>



<p>An improvement backlog is a list of ideas maintained and prioritised by the team. The list can be physical, like stickies on a whiteboard, or digital, like part of your jira backlog. </p>



<p>For example, my team created a Jira sprint and named it ‘Improvement Ideas’. We have list about 50 improvement ideas, most of which are one-liners and some of which have been discussed with details and acceptance criteria attached.</p>



<p>Each sprint planning, we prioritise this list and take the items we feel are most valuable to us. We have a couple of ad-hoc rules for this backlog.</p>



<ul><li>Any ideas that come up in meetings are inserted as a ‘one-liners’ in this backlog.</li><li>The list is regularly prioritised each sprint.</li><li>Each idea is explained by the team member who originally raised it.</li><li>We take 10-20% of our sprint capacity for improvements.</li></ul>



<p>Keeping this backlog up to date and prioritised will ensure that your team has consistent tasks to work on that primarily help the team.</p>



<h2>Stakeholder Feedback</h2>



<p>Working in a team can often be like working in a bubble. It is tempting to fall into confirmation bias. The most valuable improvements you can get for your product will come from your customers and stakeholders. </p>



<p>Leading the team does not only include leading the people on the team. If your team are known for building the wrong thing, or if their customers are not satisfied with their part of the product, then you as the team lead have ultimately failed.</p>



<p>When it comes to feedback, there is nothing more valuable than your own customers’ feedback. Your customers drive your product backlog. If you are in a large company, you may not have direct contact with your customers. In big companies, customers are often separated by layers of business analysts and management. This is not ideal, but it is something you can work around. </p>



<p>All you need is a small list of stakeholders that consistently use your product area to gain feedback from them. Talk to your managers about the customer interface and who could give feedback. In my case, we were 6 months without any contact with stakeholders that could give us valuable feedback. Eventually we were able to make friends with two guys who act as an interface to one of our company’s top …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.dcaulfield.com/team-improvement-techniques/">http://www.dcaulfield.com/team-improvement-techniques/</a></em></p>]]>
            </description>
            <link>http://www.dcaulfield.com/team-improvement-techniques/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23882701</guid>
            <pubDate>Sat, 18 Jul 2020 16:50:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Redo: A recursive, general-purpose build system]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23882630">thread link</a>) | @jnxx
<br/>
July 18, 2020 | https://redo.readthedocs.io/en/latest/ | <a href="https://web.archive.org/web/*/https://redo.readthedocs.io/en/latest/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
            <div>
              
                
<p><code>redo</code> is a competitor to the long-lived, but sadly imperfect, <code>make</code>
program.  Unlike other such competitors, redo captures the essential
simplicity and flexibility of make, while avoiding its flaws.  It manages to
do this while being simultaneously simpler than make, more flexible than
make, and more powerful than make, and without sacrificing performance - a
rare combination of features.</p>
<p>The original design for redo comes from Daniel J. Bernstein (creator of
qmail and djbdns, among many other useful things).  He posted some
terse notes on his web site at one point (there is no date) with the
unassuming title, "<a href="http://cr.yp.to/redo.html">Rebuilding target files when source files have
changed</a>." Those notes are enough information to
understand how the system is supposed to work; unfortunately there's no code
to go with it.  I wrote this implementation of redo from scratch, based on
that design.</p>
<p>After I found out about djb redo, I searched the Internet for any sign that
other people had discovered what I had: a hidden, unimplemented gem of
brilliant code design.  I found only one interesting link at the time: Alan
Grosskurth, whose <a href="http://grosskurth.ca/papers/mmath-thesis.pdf">Master's thesis at the University of
Waterloo</a> was about top-down
software rebuilding, that is, djb redo.  He wrote his own (admittedly slow)
implementation in about 250 lines of shell script, which gives an idea for
how straightforward the system is.  Since then, several other
implementations have appeared (see list below).</p>
<p>My implementation of redo is called <code>redo</code> for the same reason that there
are 75 different versions of <code>make</code> that are all called <code>make</code>.  It's somehow
easier that way.</p>
<p>I also provide an extremely minimal pure-POSIX-sh implementation, called
<code>do</code>, in the <code>minimal/</code> directory of this repository.</p>
<p>(Want to discuss redo?  Join <a href="https://redo.readthedocs.io/en/latest/Contributing/#mailing-list">our mailing list</a>.)</p>

<p>The theory behind redo sounds too good to be true: it can do everything
<code>make</code> can do, but the implementation is vastly simpler, the syntax is
cleaner, and you have even more flexibility without resorting to ugly hacks. 
Also, you get all the speed of non-recursive <code>make</code> (only check dependencies
once per run) combined with all the cleanliness of recursive <code>make</code> (you
don't have code from one module stomping on code from another module).</p>
<p>(Disclaimer: my current implementation is not as fast as <code>make</code> for some
things, because it's written in python.  Eventually I'll rewrite it an C and
it'll be very, very fast.)</p>
<p>The easiest way to show it is to jump into an example.  Here's one for
compiling a C++ program.</p>
<p>Create a file called default.o.do:</p>
<pre><code>redo-ifchange $2.c
gcc -MD -MF $2.d -c -o $3 $2.c
read DEPS &lt;$2.d
redo-ifchange ${DEPS#*:}
</code></pre>
<p>Create a file called myprog.do:</p>
<pre><code>DEPS="a.o b.o"
redo-ifchange $DEPS
gcc -o $3 $DEPS
</code></pre>
<p>Of course, you'll also have to create <code>a.c</code> and <code>b.c</code>, the C language
source files that you want to build to create your application.</p>
<p>In a.c:</p>
<pre><code>#include &lt;stdio.h&gt;
#include "b.h"

int main() { printf(bstr); }
</code></pre>
<p>In b.h:</p>
<pre><code>extern char *bstr;
</code></pre>
<p>In b.c:</p>
<pre><code>char *bstr = "hello, world!\n";
</code></pre>
<p>Now you simply run:</p>
<pre><code>$ redo myprog
</code></pre>
<p>And it says:</p>
<pre><code>redo  myprog
redo    a.o
redo    b.o
</code></pre>
<p>Now try this:</p>
<pre><code>$ touch b.h
$ redo myprog
</code></pre>
<p>Sure enough, it says:</p>
<pre><code>redo  myprog
redo    a.o
</code></pre>
<p>Did you catch the shell incantation in <code>default.o.do</code> where it generates
the autodependencies?  The filename <code>default.o.do</code> means "run this script to
generate a .o file unless there's a more specific whatever.o.do script that
applies."</p>
<p>The key thing to understand about redo is that declaring a dependency is just
another shell command.  The <code>redo-ifchange</code> command means, "build each of my
arguments.  If any of them or their dependencies ever change, then I need to
run the <em>current script</em> over again."</p>
<p>Dependencies are tracked in a persistent <code>.redo</code> database so that redo can
check them later.  If a file needs to be rebuilt, it re-executes the
<code>whatever.do</code> script and regenerates the dependencies.  If a file doesn't
need to be rebuilt, redo figures that out just using its persistent
<code>.redo</code> database, without re-running the script.  And it can do that check
just once right at the start of your project build, which is really fast.</p>
<p>Best of all, as you can see in <code>default.o.do</code>, you can declare a dependency
<em>after</em> building the program.  In C, you get your best dependency
information by trying to actually build, since that's how you find out which
headers you need.  redo is based on this simple insight: you don't
actually care what the dependencies are <em>before</em> you build the target.  If
the target doesn't exist, you obviously need to build it.</p>
<p>Once you're building it anyway, the build script itself can calculate the
dependency information however it wants; unlike in <code>make</code>, you don't need a
special dependency syntax at all.  You can even declare some of your
dependencies after building, which makes C-style autodependencies much
simpler.</p>
<p>redo therefore is a unique combination of imperative and declarative
programming.  The initial build is almost entirely imperative (running a
series of scripts).  As part of that, the scripts declare dependencies a few
at a time, and redo assembles those into a larger data structure.  Then, in
the future, it uses that pre-declared data structure to decide what work
needs to be redone.</p>
<p>(GNU make supports putting some of your dependencies in include files, and
auto-reloading those include files if they change.  But this is very
confusing - the program flow through a Makefile is hard to trace already,
and even harder when it restarts from the beginning because an include file
changes at runtime.  With redo, you can just read each build script from top
to bottom.  A <code>redo-ifchange</code> call is like calling a function, which you can
also read from top to bottom.)</p>

<p>Some larger proprietary projects are using it, but unfortunately they can't
easily be linked from this document.  Here are a few open source examples:</p>
<ul>
<li>
<p><a href="https://github.com/linleyh/liberation-circuit">Liberation Circuit</a> is a
  straightforward example of a C++ binary (a game) compiled with redo.</p>
</li>
<li>
<p><a href="https://github.com/apenwarr/wvstreams">WvStreams</a> uses a more complex
  setup producing several binaries, libraries, and scripts.  It shows how to
  produce output files in a different directory than the source files.</p>
</li>
<li>
<p><a href="https://github.com/apenwarr/wvbuild">WvBuild</a> can cross-compile several
  dependencies, like openssl and zlib, and then builds WvStreams using those
  same libraries.  It's a good example of redo/make interop and complex
  dependencies.</p>
</li>
<li>
<p>There's an experimental <a href="https://github.com/apenwarr/buildroot/tree/redo">variant of
  Buildroot</a> that uses redo
  in order to clean up its dependency logic.</p>
</li>
<li>
<p>You can find some curated tutorial examples in the
  <a href="https://redo.readthedocs.io/en/latest/cookbook/hello/">cookbook</a>, such as <a href="https://redo.readthedocs.io/en/latest/cookbook/defaults/">git variable
  substitution</a> and <a href="https://redo.readthedocs.io/en/latest/cookbook/latex/">text processing with
  LaTeX</a> (including plot generation with R and ggplot2).</p>
</li>
<li>
<p>A <a href="https://github.com/search?p=9&amp;q=path%3A%2F+extension%3Ado+filename%3A%2Fall.do&amp;type=Code">github search for all.do</a>
  shows an ever-growing number of projects using redo.</p>
</li>
</ul>
<p>If you switch your program's build process to use redo, please let us know and
we can link to it here for some free publicity.</p>
<p>(Please don't use the integration testing code in the redo project's <code>t/</code>
directory as serious examples of how to use redo.  Many of the tests are
doing things in intentionally psychotic ways in order to stress redo's code
and find bugs.  On the other hand, if you're building your own
reimplementation of redo, using our test suite is a great idea.)</p>

<p>djb never released his version, so other people have implemented their own
variants based on his <a href="http://cr.yp.to/redo.html">published specification</a>.</p>
<p>This version, sometimes called apenwarr/redo, is probably the most advanced
one, including support for parallel builds,
<a href="https://apenwarr.ca/log/20181113">resilient timestamps</a> and checksums,
<a href="https://apenwarr.ca/log/20181106">build log linearization</a>, and
helpful debugging features.  It's currently written in python for easier
experimentation, but the plan is to eventually migrate it to plain C.  (Some
people like to call this version "python-redo", but I don't like that name. 
We shouldn't have to rename it when we later transliterate the code to C.)</p>
<p>Here are some other redo variants (thanks to Nils Dagsson Moskopp for
collecting many of these links):</p>
<ul>
<li>
<p>Alan Grosskurth's <a href="http://grosskurth.ca/papers/mmath-thesis.pdf">redo thesis</a>
  and related sh implementation.  (Arguably, this paper is the one that got
  all the rest of us started.)</p>
</li>
<li>
<p>Nils Dagsson Moskopp's <a href="https://web.archive.org/web/20181106195145/http://news.dieweltistgarnichtso.net/bin/redo-sh.html">redo-sh</a>
  is a completely self-sufficient sh-based implementation.</p>
</li>
<li>
<p>apenwarr's <a href="https://github.com/apenwarr/redo/blob/master/minimal/do">minimal/do</a>
  is included with this copy of redo.  It's also sh-based, but intended to
  be simple and failsafe, so it doesn't understand how to "redo" targets more
  than once.</p>
</li>
<li>
<p>Christian Neukirchen's <a href="https://github.com/chneukirchen/redo-c">redo-c</a>, a
  C implementation.</p>
</li>
<li>
<p>Jonathan de Boyne Pollard's <a href="http://jdebp.eu./Softwares/redo/grosskurth-redo.html">fork of Alan Grosskurth's redo</a>
  (another sh-based implementation).</p>
</li>
<li>
<p>Jonathan de Boyne Pollard's <a href="http://jdebp.eu./Softwares/redo/">redo</a>
  rewritten in C++</p>
</li>
<li>
<p>Gyepi Sam's <a href="https://github.com/gyepisam/redux">redux</a> in Go</p>
</li>
<li>
<p>jekor's <a href="https://github.com/jekor/redo">redo</a> in Haskell</p>
</li>
<li>
<p>Shanti Bouchez-Mongardé (mildred)'s <a href="https://github.com/mildred/redo">fork of apenwarr's redo</a>
  in python</p>
</li>
<li>
<p>Tharre's <a href="https://github.com/Tharre/redo">redo</a> in C</p>
</li>
<li>
<p>catenate's <a href="https://github.com/catenate/credo">credo</a>, a (very
  rearchitected) variant written for the Inferno Shell.</p>
</li>
</ul>
<p>The original redo design is so simple and elegant that many individuals
have been
inspired to (and able to) write their own version of it.  In the honoured
tradition of Unix's <code>make</code>, they (almost) all just use the same name,
<code>redo</code>.  Unfortunately, many of these
implementations are unmaintained, slightly incompatible with the "standard"
redo semantics, and/or have few or no automated tests.</p>
<p>At the time of this writing, none of them except apenwarr/redo (ie.  this
project) correctly support parallel builds (<code>redo -j</code>) or log linearization
(<code>redo-log</code>).  For large projects, parallel builds are usually considered
essential.</p>
<p>The <a href="https://github.com/apenwarr/redo/tree/master/t">automated tests</a> in
this version of redo are almost, but not quite, appropriate for testing any
redo implementation.  If you really must write a new version of redo, we
invite you to thoroughly test it against the existing test suite to ensure
compatibility.  You can also steal our tests (with attribution, of course)
and include them in your own source package.  We'd also love it it you
contribute more automated tests when you find a bug, or send us patches if
you find a test which is accidentally incompatible (as opposed to finding a
real bug) with other redo implementations.</p>
              
            </div>
          </div></div>]]>
            </description>
            <link>https://redo.readthedocs.io/en/latest/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23882630</guid>
            <pubDate>Sat, 18 Jul 2020 16:43:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[UBCO researchers create liquid-repelling substance that works on all surfaces]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23882486">thread link</a>) | @elorant
<br/>
July 18, 2020 | https://news.ok.ubc.ca/2020/07/16/ubco-researchers-create-liquid-repelling-substance-that-works-on-all-surfaces/ | <a href="https://web.archive.org/web/*/https://news.ok.ubc.ca/2020/07/16/ubco-researchers-create-liquid-repelling-substance-that-works-on-all-surfaces/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					<div id="attachment_18500"><p><img src="https://news.ok.ubc.ca/wp-content/uploads/2020/07/Hydrophobic_770.jpg" alt="UBCO master's student Behrooz Khatir measures liquid to be applied to an omniphobic film during testing inside the OPERA lab at UBC Okanagan’s School of Engineering." width="770" height="513" srcset="https://news.ok.ubc.ca/wp-content/uploads/2020/07/Hydrophobic_770.jpg 770w, https://news.ok.ubc.ca/wp-content/uploads/2020/07/Hydrophobic_770-400x266.jpg 400w, https://news.ok.ubc.ca/wp-content/uploads/2020/07/Hydrophobic_770-768x512.jpg 768w, https://news.ok.ubc.ca/wp-content/uploads/2020/07/Hydrophobic_770-240x160.jpg 240w, https://news.ok.ubc.ca/wp-content/uploads/2020/07/Hydrophobic_770-320x213.jpg 320w, https://news.ok.ubc.ca/wp-content/uploads/2020/07/Hydrophobic_770-500x333.jpg 500w, https://news.ok.ubc.ca/wp-content/uploads/2020/07/Hydrophobic_770-640x427.jpg 640w" sizes="(max-width: 770px) 100vw, 770px"></p><p>UBCO master's student Behrooz Khatir measures liquid to be applied to an omniphobic film during testing inside the OPERA lab at UBC Okanagan’s School of Engineering.</p></div>
<h3>New coating can eliminate complex disinfectant procedures for protective face shields</h3>
<p>Acting like an invisible force field, a new liquid coating being developed by UBC Okanagan researchers may provide an extra layer of protection for front-line workers.</p>
<p>Researchers at the <a href="https://apsc-golovin.sites.olt.ubc.ca/">Okanagan Polymer Engineering Research and Applications</a> (OPERA) Lab have developed a coating that repels nearly all substances off a surface. And that new coating will make cleaning personal protective equipment a little bit easier for front-line health care workers, explains Kevin Golovin, an assistant professor at UBCO’s School of Engineering and director at OPERA.</p>
<p>Surfaces that can repel a broad range of liquids are called omniphobic, explains UBCO master's student and lead author of the study Behrooz Khatir. Working in Golovin’s lab, Khatir has created a spray-on solution that can make any surface, including a face shield, omniphobic.</p>
<p>“Omniphobic—all-liquid repellent—films can repel a broad range of liquids, but the applicability of these coatings has always been limited to silicon wafers or smooth glass,” says Khatir. “This new formulation can coat and protect just about any surface, including metals, paper, ceramics and even plastics.”</p>
<p>The two-layer coating involves placing an ultra-smooth silica layer on a surface and then functionalizing this layer with a highly-reactive silicone to effectively block all kinds of liquids from sticking on the surface, explains Golovin.</p>
<p>Not only does the coating repel countless substances, but even under harsh exposures like UV light, acids and high temperatures, the coating maintains its resistance qualities. And Golovin notes, if the coating does become damaged it can be easily and repeatedly repaired, fully restoring the omniphobic properties to their initial state.</p>
<p>Golovin recently received COVID-19 funding from the Natural Sciences and Engineering Research Council (NSERC) to optimize the coating for health care face shields so they stay clean, in partnership with Kelowna-based survivability products manufacturer PRE Labs Inc.</p>
<p>“This technology has many applications, but we are currently focused on providing a solution that will keep our nurses and doctors safe and effective,” says Golovin. “This new coating will prevent droplets or microbes from sticking to a face shield. This makes disinfecting face shields feasible just with water rather than requiring complex disinfectant procedures.”</p>
<p>The original research was recently published in the <em><a href="https://pubs.acs.org/doi/full/10.1021/acsami.0c06433">ACS Applied Materials &amp; Interfaces</a></em> journal, with funding support from NSERC.</p>
<h3>About UBC's Okanagan campus</h3>
<p>UBC’s Okanagan campus is an innovative hub for research and learning founded in 2005 in partnership with local Indigenous peoples, the Syilx Okanagan Nation, in whose territory the campus resides. As part of UBC—ranked among the world’s top 20 public universities—the Okanagan campus combines a globally recognized UBC education with a tight-knit and entrepreneurial community that welcomes students and faculty from around the world in British Columbia’s stunning Okanagan Valley.</p>
<p>To find out more, visit:&nbsp;<a href="http://ok.ubc.ca/">ok.ubc.ca</a></p>
									</div></div>]]>
            </description>
            <link>https://news.ok.ubc.ca/2020/07/16/ubco-researchers-create-liquid-repelling-substance-that-works-on-all-surfaces/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23882486</guid>
            <pubDate>Sat, 18 Jul 2020 16:26:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Closing Hong-Kong]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23882332">thread link</a>) | @dgellow
<br/>
July 18, 2020 | https://www.persuasion.community/p/closing-hong-kong | <a href="https://web.archive.org/web/*/https://www.persuasion.community/p/closing-hong-kong">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a target="_blank" href="https://cdn.substack.com/image/fetch/c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F0b824b1f-5487-4307-b412-3de0f72c8cd0_8256x5504.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F0b824b1f-5487-4307-b412-3de0f72c8cd0_8256x5504.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/0b824b1f-5487-4307-b412-3de0f72c8cd0_8256x5504.jpeg&quot;,&quot;height&quot;:971,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:23546462,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></p><p>The world’s only museum dedicated to the Tiananmen Square massacre sits in a single room, scarcely larger than a studio apartment, midway up an anonymous office building in Hong Kong’s bustling Mong Kok district.</p><p>The June 4th Museum, as it is officially known, dedicates most of its limited space to pressing an urgent analogy. Adorning a long wall are two timelines, one above the other: Beijing in 1989, Hong Kong in 2019, with the two moments matched up beat for beat. A few feet to the left are the self-authored wills of students, trying to explain to their grieving families why they had to risk their lives in Tiananmen Square. And, beside them, similar letters from protestors in Hong Kong, written late last year as tear gas filled the streets, university campuses were besieged, and police violence ran rampant. The overall message is clear: these two revolts should be spoken of in the same breath. </p><p>But over the past few weeks, another Tiananmen parallel has begun to suggest itself—one that you certainly won’t find celebrated in the June 4th Museum. In late June, the Chinese government imposed a National Security Law, which criminalizes “subversion”—carrying pro-independence stickers can mean jail time—and grants China’s notorious security services an open foothold in the city. If Hong Kong’s 2019 was like Beijing’s 1989, what does that mean for the Hong Kong of the 2020s and 2030s? Will Hong Kong, which has long cherished its boisterously free civic culture, come to look like Beijing in the years after the tanks rolled into the square? </p><p>Outside China, history mainly remembers Tiananmen Square for the protestors who were massacred and the intellectuals who spent decades in prison or exile. But most of those who were involved do not fit that description. Instead, gradually and often uncomfortably, hundreds of thousands of protestors slowly made peace with the status quo and found ways to accommodate themselves to the system. “I know for a fact that some of them are multimillionaires,” Tiananmen leader Chen Ziming has <a href="https://www.google.com/books/edition/The_People_s_Republic_of_Amnesia/MXVYAwAAQBAJ?hl=en&amp;gbpv=1&amp;bsq=chen%20ziming">said of his former comrades</a>. “They won’t even admit to having been student leaders.”</p><p>Wang Shi, the founder of one of the world’s largest real estate companies, <a href="https://www.washingtonpost.com/wp-srv/inatl/daily/june99/tiananmen5.htm">once told the </a><em><a href="https://www.washingtonpost.com/wp-srv/inatl/daily/june99/tiananmen5.htm">Washington Post</a></em> that he was imprisoned for leading an employee march for freedom in 1989. Today, <a href="https://www.google.com/books/edition/The_People_s_Republic_of_Amnesia/MXVYAwAAQBAJ?hl=en&amp;gbpv=1&amp;bsq=chen%20ziming">he</a> <a href="https://www.wsj.com/articles/how-china-vanke-chiefs-state-savior-could-be-his-undoing-1469127600">denies</a> that it ever happened. </p><p>Could the same cocktail of terror and self-interest that all but stamped out a nascent liberal moment in China succeed against Hong Kong’s more established civic traditions? The question has global resonance. As nations from Poland to Brazil grapple with whether the institutions of liberal democracy can survive an increasingly illiberal electorate, Hong Kong presents the inverse question: can a society’s liberalism survive a government determined to stamp it out? </p><p data-attrs="{&quot;url&quot;:&quot;https://www.persuasion.community/p/closing-hong-kong?&amp;utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;class&quot;:null}"><a href="https://www.persuasion.community/p/closing-hong-kong?&amp;utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share"><span>Share</span></a></p><p>For many years, outsiders assumed that Hong Kong would always value economic growth over political freedom. But the 2014 Umbrella protests put this notion to rest. As Joshua Wong, the city’s most famous pro-democracy activist, told me in 2017, during the unsteady détente that followed the protests: “we proved to the world that Hong Kongers are ready for democracy.”</p><p>Last week, I repeated my question to Wong. Would the National Security Law finally push Hong Kong into fulfilling that old stereotype? As a politician in his position must, he remained hopeful. “They are unable to censor away all the memories of Hong Kong’s people in the past few years,” Wong said. In fact, he claimed, Hong Kong’s political resilience is tied to its economic vitality: “With [China’s] economic reliance on Hong Kong, Hong Kong people still have the leverage to fight for a greater degree of autonomy and choose not to kowtow to Beijing.”</p><p>But recent events belie Wong’s optimism. The day the National Security Law was passed, Wong and his allies quickly dismantled Demosistō, the pro-democracy party he led. Scores of activists fled Twitter in fear. Even the usually apolitical investment analysts based in Hong Kong began to wonder whether they might risk a visit from the police if they dared to criticize Chinese companies.</p><p>Most dishearteningly, the past weeks have made it clear that the National Security Law is pulling apart not only Hong Kong’s liberal political institutions, but also the wider constellation of organizations that sustain its civic culture. </p><p>One telling microcosm is the local high school debating scene. Hong Kong’s national team ranks among the best in the world. But that proud tradition may soon be coming to an end: the charity that runs the national team is closing up shop. “There’s no way we can continue under the present environment,” one insider told me. “But we can’t suggest that this is related to the National Security Law because that would bring unwanted attention to some of our teachers. We’re already seeing schools axe their debating programs out of fear, and presumably parents will also start withdrawing their children as the ramifications of the law sink in.”</p><p>Given the circumstances, few can fault parents and teachers for withdrawing students from an activity whose purpose is to discuss controversial topics. But the inevitable result is that Hong Kong’s local debating league, which has taught tens of thousands of schoolchildren to think critically and argue carefully, could soon be no more.</p><p>To better understand the situation in Hong Kong’s schools, I spoke to Raymond Yeung, until this summer a teacher at an elite Hong Kong girls’ school. Yeung was blinded in one eye by the police at a pro-democracy protest last year. Then he lost his job after his school cut back the curriculum for Liberal Studies, a subject designed to teach students civics and critical thinking. </p><p>Yeung’s summary was succinct: “The situation is quite grim.” Even before the National Security Law, pro-establishment groups regularly organized public denunciations of teachers deemed too sympathetic to the protests. Now, the future is even more uncertain. “We really don’t know what will happen in the next school year,” Yeung said. “The government is trying very hard to control the discussion of political issues in schools.” </p><p>Hong Kong’s authorities are currently reviewing the textbooks used to teach Liberal Studies. “Those books that have been reviewed will need to remove much information about the political situation in Hong Kong. We teachers dare not mention these issues anymore.”</p><p data-attrs="{&quot;url&quot;:&quot;https://www.persuasion.community/?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share Persuasion&quot;,&quot;class&quot;:null}"><a href="https://www.persuasion.community/?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share"><span>Share Persuasion</span></a></p><p>The leitmotif of Hong Kong’s future is becoming clear: spaces for discussion and debate continue to narrow. But the city’s underlying political, cultural and economic grievances remain unchanged. “In the end, the anger is still here,” Yeung stressed. </p><p>Decades of broken Chinese promises and the whiplash of the past twelve months will not be easily forgotten. Perhaps Hong Kong’s unique culture, binding together a powerful sense of Cantonese identity with decades lived under a free press and independent judiciary, will survive the current onslaught. But as those brave students in Tiananmen Square found out in 1989, hopes and hypotheticals offer scant protection against the raw power of the Chinese state.</p><p><strong>Archie Hall is a writer from London and Hong Kong.</strong></p></div></div>]]>
            </description>
            <link>https://www.persuasion.community/p/closing-hong-kong</link>
            <guid isPermaLink="false">hacker-news-small-sites-23882332</guid>
            <pubDate>Sat, 18 Jul 2020 16:08:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Debugging a dynamic linking bug in a Nix project]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23882277">thread link</a>) | @johnbcoughlin
<br/>
July 18, 2020 | https://www.johnbcoughlin.com/posts/nix-dynamic-linking/ | <a href="https://web.archive.org/web/*/https://www.johnbcoughlin.com/posts/nix-dynamic-linking/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
            

            

<h2 id="trying-out-the-nix-development-experience">Trying out the Nix development experience</h2>
<p>The other day, while building a <a href="https://faculty.washington.edu/shumlak/WARPX/html/index.html">scientific project</a> to which I’m a contributor, I
ran into a nasty version conflict between two system libraries. In a fit of
pique, I decided to learn enough about <a href="https://nixos.org/">Nix</a> to be able to set up a reproducible,
tightly controlled local build. It’s done now, and overall I’m very happy with
the tooling and setup. I’m using <a href="https://direnv.net/">direnv</a> to tightly integrate my normal shell
with Nix’s <code>nix-shell</code> feature, and for the most part everything feels seamless.
It is extremely refreshing to see <code>cmake</code> report that it has found a plethora of
binaries and libraries, content-hashed and installed in neat little rows under
<code>/nix/store</code>.</p>
<p>I’m using Nix to manage my development environment, but <em>not</em> to build the
project itself. Nix ensures that the project dependencies are installed and
discoverable by the compiler and linker. Building the project is done with
CMake, set up for <code>cmake</code> to find the nix-installed libraries. Nix achieves this
by <a href="https://nixos.wiki/wiki/C#The%5Fcompiler%5Fwrapper">wrapping the C compiler</a> with its own shell script and injecting the paths to
libraries and binaries via environment variables. There’s very little to do to
make <code>cmake</code> just work, beyond declaring that the packages you want are
<code>buildInputs</code>. The first version of my <code>shell.nix</code> file looked like this:</p>
<div><pre><code data-lang="nix"><span># file shell.nix</span>
{ <span>pkgs</span> ? <span>import</span> <span>&lt;nixpkgs&gt;</span> {} }:

<span>pkgs</span>.<span>mkShell</span> {
  <span>buildInputs</span> = <span>with</span> <span>pkgs</span>; [
    <span>cmake</span>
    (<span>callPackage</span> <span>nix/petsc.nix</span> {})
    <span>metis</span>
    <span>hdf5</span>
    <span>openmpi</span>
    (<span>python38</span>.<span>withPackages</span> (<span>packages</span>: [ <span>packages</span>.<span>numpy</span> ]))
  ];
}
</code></pre></div><p>Using this setup, I had very little trouble getting the project to build. I had
to <a href="https://nixos.org/nixos/nix-pills/nixpkgs-overriding-packages.html">override</a> the <a href="https://github.com/NixOS/nixpkgs/blob/master/pkgs/development/libraries/science/math/petsc/default.nix">default PETSc derivation</a> to compile with METIS and OpenMPI
support, which was not too hard:</p>
<div><pre><code data-lang="nix"><span># file nix/petsc.nix</span>
{ <span>petsc</span> , <span>blas</span> , <span>gfortran</span> , <span>lapack</span> , <span>python</span> , <span>metis</span> , <span>openmpi</span> }:

<span>petsc</span>.<span>overrideAttrs</span> (<span>oldAttrs</span>: <span>rec</span> {
    <span>nativeBuildInputs</span> = [ <span>blas</span> <span>gfortran</span> <span>gfortran</span>.<span>cc</span>.<span>lib</span> <span>lapack</span> <span>python</span> <span>openmpi</span> <span>metis</span> ];
    <span>preConfigure</span> = <span>''
</span><span>        export FC="</span><span>${</span><span>gfortran</span><span>}</span><span>/bin/gfortran" F77="</span><span>${</span><span>gfortran</span><span>}</span><span>/bin/gfortran"
</span><span>        patchShebangs .
</span><span>        configureFlagsArray=(
</span><span>        $configureFlagsArray
</span><span>        "--with-mpi-dir=</span><span>${</span><span>openmpi</span><span>}</span><span>"
</span><span>        "--with-metis=</span><span>${</span><span>metis</span><span>}</span><span>"
</span><span>        "--with-blas-lib=[</span><span>${</span><span>blas</span><span>}</span><span>/lib/libblas.so,</span><span>${</span><span>gfortran</span>.<span>cc</span>.<span>lib</span><span>}</span><span>/lib/libgfortran.a]"
</span><span>        "--with-lapack-lib=[</span><span>${</span><span>lapack</span><span>}</span><span>/lib/liblapack.so,</span><span>${</span><span>gfortran</span>.<span>cc</span>.<span>lib</span><span>}</span><span>/lib/libgfortran.a]"
</span><span>        )
</span><span>    ''</span>;
})
</code></pre></div><p>This Nix file returns a function which is invoked in <code>shell.nix</code> using
<code>callPackage</code> function. <code>petsc.overrideAttrs</code> is a neat way to override the
attributes of a derivation created with <code>stdenv.mkDerivation</code>. Building PETSc
with MPI and METIS support is as simple as passing in a different set of
arguments to the <code>configure</code> script.</p>
<p>Figuring out how to do all of this was fun. I mostly referred to the <a href="https://nixos.org/nixos/nix-pills/index.html">Nix
“Pills”</a>, which are a great progression through the Nix tool and language.</p>
<p>With these Nix files, I was able to execute <code>cmake .. &amp;&amp; make</code> successfully.
Getting the project to <em>run</em> was another story. The final binary failed
immediately with a dynamic loading error:</p>
<div><pre><code data-lang="bash">âžœ bin/warpxm
dyld: Library not loaded: /private/tmp/nix-build-petsc-3.13.2.drv-0/petsc-3.13.2/arch-darwin-c-debug/lib/libpetsc.3.13.dylib
  Referenced from: /Users/jack/src/warpxm/build/bin/warpxm
  Reason: image not found
</code></pre></div><p>The binary was trying to load a dynamic lib from one of the temporary directories
that Nix created in the process of building PETSc. Of course this failed: by the
time I invoked <code>bin/warpxm</code>, that directory had been cleaned up. Instead of a
file under <code>/private/tmp</code>, the binary should have linked to the result of the
<code>petsc</code> derivation in the Nix store, under <code>/nix/store</code>. At some point, it
seemed, an environment variable was incorrectly set to this intermediate
directory. To figure out where, I would have to learn a lot more about linking
on OS X than I ever expected.</p>
<h2 id="whither-the-linker">Whither the linker?</h2>
<p>First I checked the compiler and linker flags that are inserted by Nix’s
compiler wrapper. These come in via <code>NIX_CFLAGS_COMPILE</code> and <code>NIX_LDFLAGS</code>. When
you’re working with <code>nix-shell</code> and <code>direnv</code>, all of the environment variables
from your derivations are injected into your shell. It’s a simple matter of echoing
them out:</p>
<div><pre><code data-lang="bash">âžœ <span>echo</span> <span>$NIX_CFLAGS_COMPILE</span>
... -isystem /nix/store/w23r8kplmfx2xc111cpvmdjwmkwy6ip3-petsc-3.13.2/include ...
âžœ <span>echo</span> <span>$NIX_LDFLAGS</span>
... -L/nix/store/w23r8kplmfx2xc111cpvmdjwmkwy6ip3-petsc-3.13.2/lib ...
</code></pre></div><p>These look fine! Invoking <code>cmake</code> and <code>make</code> in this shell ought to pull in the
correct library.</p>
<p>Then I remembered that this project uses <code>pkg-config</code> to find and pull together
the linked libraries. Frankly, I don’t understand <code>pkg-config</code> very well, but I
do know that in this project it is invoked from inside of <code>cmake</code>. It searches for
libraries according to its own rules, and it runs <em>after</em> Nix has done its
job setting everything up. Therefore, it circumvents the compiler and linker
flags that we just checked.</p>
<p>I happened to have <code>pkg-config</code> installed from before setting up this Nix
environment. Therefore, <code>cmake</code> was able to invoke the system <code>pkg-config</code> from
my user <code>PATH</code>. Perhaps the system version of <code>pkg-config</code> was somehow finding
the wrong library? Indeed, <code>echo $PKG_CONFIG_PATH</code> confirmed that it was
searching a directory under my <code>$HOME</code>. I thought it possible that some wires
got crossed while I was adding dependencies to my Nix derivation one at a time:
configuring <code>pkg-config</code> appropriately might help.</p>

<p>I referred once again to the Nix wiki page on C projects, which also has <a href="https://nixos.wiki/wiki/C#pkg-config">a
section</a> on using <code>pkg-config</code>. It seems that including the <code>pkg-config</code>
derivation as a <code>nativeBuildInput</code> will let packages like <code>petsc</code> append their
output paths to the <code>PKG_CONFIG_PATH</code> environment variable. I did so:</p>
<div><pre><code data-lang="nix"><span>pkgs</span>.<span>mkShell</span> {
  <span>buildInputs</span> = <span>with</span> <span>pkgs</span>; [
    ...
  ];
  <span>nativeBuildInputs</span> = <span>with</span> <span>pkgs</span>; [
    <span>pkg-config</span>
  ];
}
</code></pre></div><p>but it didn’t fix the problem. I would have to go deeper and track down where
the bad library was being pulled in.</p>
<p>Digging into the <code>cmake</code> documentation and the project’s <code>.cmake</code> files led me
to insert a trio of print statements:</p>
<div><pre><code data-lang="diff">find_package(PkgConfig REQUIRED)
pkg_check_modules(PETSC PETSc REQUIRED)

link_directories(${PETSC_LIBRARY_DIRS})
<span>+ message("petsc libraries: ${PETSC_LIBRARIES}")
</span><span>+ message("petsc library dirs: ${PETSC_LIBRARY_DIRS}")
</span><span>+ message("petsc link libraries: ${PETSC_LINK_LIBRARIES}")
</span><span></span>list(APPEND WARPXM_LINK_TARGETS ${PETSC_LIBRARIES})
</code></pre></div><p>These printed out three lines in my <code>cmake</code> output:</p>
<div><pre><code data-lang="text">petsc libraries: petsc
petsc library dirs: /nix/store/w23r8kplmfx2xc111cpvmdjwmkwy6ip3-petsc-3.13.2/lib
petsc link libraries: /nix/store/w23r8kplmfx2xc111cpvmdjwmkwy6ip3-petsc-3.13.2/lib/libpetsc.dylib
</code></pre></div><p>The second two look good. But the first, just the library name <code>petsc</code>, was a little too
implicit for comfort. It was precisely this variable that was being appended
to the link targets list. At <em>compile</em> time, it would be up to the linker to find
the library <code>petsc</code>, and I wasn’t sure where it would look. Safer to use the
absolute path to the <code>.dylib</code>, like so:</p>
<div><pre><code data-lang="diff"><span>- list(APPEND WARPXM_LINK_TARGETS ${PETSC_LIBRARIES})
</span><span></span><span>+ list(APPEND WARPXM_LINK_TARGETS ${PETSC_LINK_LIBRARIES})
</span></code></pre></div>
<p>Changing the link target to the absolute path eased my mind only for the duration of
the next <code>cmake .. &amp;&amp; make</code> cycle. Surely there was no way the linker could
screw up now. No arcane library search involved, just an absolute path, which
couldn’t possibly be misinterpreted…</p>
<div><pre><code data-lang="bash">âžœ bin/warpxm
dyld: Library not loaded: /private/tmp/nix-build-petsc-3.13.2.drv-0/petsc-3.13.2/arch-darwin-c-debug/lib/libpetsc.3.13.dylib
  Referenced from: /Users/jack/src/warpxm/build/bin/warpxm
  Reason: image not found
</code></pre></div><p>Damn it!</p>
<h2 id="install-name-and-other-depravities">install_name and other depravities</h2>
<p>At this point I was absolutely flummoxed. With every fix I attempted, I
grepped vainly for the offending <code>/private/tmp</code> path in my build directory, and come up
empty-handed. I tracked down the final, irrevocable link options passed to the
compiler, tucked away in a <code>link.txt</code> file in the build tree. They showed
incontrovertibly that my binary was being linked to the correct library:</p>
<div><pre><code data-lang="text">âžœ cat build/src/CMakeFiles/warpxm.dir/link.txt
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/c++     -O3 -DNDEBUG -isysroot ... -L/nix/store/31d3hng4sclxi3sz8g3zi3yqmychj2kg-petsc-3.13.2/lib ...
</code></pre></div><p>I had proved nearly to my satisfaction that CMake was doing the right thing with
this library, and I was completely out of ideas.
Finally, a very lucky google search led me to the <a href="https://nixos.org/nixpkgs/manual/#sec-darwin">section</a> of the Nix manual
describing issues specific to the Darwin (MacOS) platform. It states:</p>
<blockquote>
<p>On Darwin, libraries are linked using absolute paths, libraries are resolved
by their install_name at link time. Sometimes packages won’t set this
correctly causing the library lookups to fail at runtime. This can be fixed by
adding extra linker flags or by running install_name_tool -id during the
fixupPhase.</p>
</blockquote>
<p>This is a very matter-of-fact way of stating something that, when I understood
it, flabbergasted me. To the best of my understanding, here’s what happens on
MacOS:</p>
<ul>
<li>My source code has an include directive, <code>include&lt;petsc.h&gt;</code> or something like
that, which creates a binary interface to be satisfied by the linker.</li>
<li>At link time, we pass the list of absolute paths to libraries, and the linker
finds the one that matches the interface.</li>
<li>The linker then saves the <em>install_name</em> of the library it found in the
binary’s load section.</li>
<li>At run time, the binary (actually, the MacOS <code>dyld</code> system) loads the library.
The install_name is all it has, so it looks there.</li>
</ul>
<p>I’ve certainly gotten some aspect of this wrong, so I would definitely
appreciate hearing from someone who understands it better than me!</p>
<p>In any case, this find pointed me to the concept of the install_name, so I had
something to go on. More searching led to a <a href="http://log.zyxar.com/blog/2012/03/10/install-name-on-os-x/">helpful blog post</a> describing exactly
the issue that I was facing. It also described how to check the install_name of
the library:</p>
<div><pre><code data-lang="text">âžœ otool -D /nix/store/31d3hng4sclxi3sz8g3zi3yqmychj2kg-petsc-3.13.2/lib/libpetsc.dylib</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.johnbcoughlin.com/posts/nix-dynamic-linking/">https://www.johnbcoughlin.com/posts/nix-dynamic-linking/</a></em></p>]]>
            </description>
            <link>https://www.johnbcoughlin.com/posts/nix-dynamic-linking/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23882277</guid>
            <pubDate>Sat, 18 Jul 2020 16:01:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[It’s Time to Reinvent Democracy]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 3 (<a href="https://news.ycombinator.com/item?id=23882048">thread link</a>) | @whack
<br/>
July 18, 2020 | https://outlookzen.com/2013/11/06/its-time-to-reinvent-democracy/ | <a href="https://web.archive.org/web/*/https://outlookzen.com/2013/11/06/its-time-to-reinvent-democracy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<div><figure><a href="https://www.washingtonpost.com/news/theworldpost/wp/2018/03/23/direct-democracy/" target="_blank" rel="noreferrer noopener"><img data-attachment-id="801" data-permalink="https://outlookzen.com/mob-rule/" data-orig-file="https://outlookzen.files.wordpress.com/2019/05/mob-rule.png" data-orig-size="1142,632" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="mob-rule" data-image-description="" data-medium-file="https://outlookzen.files.wordpress.com/2019/05/mob-rule.png?w=300" data-large-file="https://outlookzen.files.wordpress.com/2019/05/mob-rule.png?w=1024" src="https://outlookzen.files.wordpress.com/2019/05/mob-rule.png" alt=""></a></figure></div>


<p><em>“Democracy is two wolves and a lamb voting on what to have for lunch”&nbsp;<br></em>&nbsp; – Ben Franklin</p>
<p><em>“Democracy never lasts long. It soon wastes, exhausts, and murders itself. There never was a democracy yet that did not commit suicide.”</em>&nbsp;<br>&nbsp; – John Adams</p>
<p>Today, I’ll be making the same argument that the founding fathers did; that our conception of democracy is fundamentally flawed and it’s time we overhauled our political system. As we look around the world, at the gridlock in Washington, the failings of the Arab Spring, and the mixed track record of democracy in the developing world, it’s easy to see the problems inherent in democracy.</p>
<p>But I also intend for this discussion to be constructive, with prescriptions for how to fix the problems that currently exist. We’ll be doing so, by critically examining 3 very different forms of crowdsourcing, which have all proved to be extremely successful. Even though democracy is also a form of crowdsourcing, we can then see that the successful ones all share certain common characteristics, which are completely antithetical to our conception of democracy.</p>
<p><strong><em><span>Differential Voting Power</span></em></strong></p>
<p dir="ltr">Our first example is a company that rose from nowhere to change our world and the way we find information; Google. A brief history: There were numerous companies trying to succeed in the Search Engine marketplace. Lycos, AskJeeves, AltaVista… the list goes on. And yet, sometime in the early 2000s, they all just disappeared and <em>everyone</em> switched to Google. Their search engine was so great, that it simply blew the competition away. When you look into how they implemented this groundbreaking search algorithm solution, one of the main pillars was the PageRank algorithm.</p>
<p>I could write an entire article about the PageRank algorithm but to put it simply, it brought democracy to the internet. It gave every single website the ability to vote on any other website, through the act of linking to it. And Google for its part, crawls through the web everyday, tallies up all the ballots, and posts the winners near the top of their search results. It is in many ways very similar to democracy… with one very important twist. Every website gets a <em>different number of votes</em> based on how credible it is.</p>
<p>To give an example, suppose the Nobel Prize winner Eugene Fama decides tomorrow to start an economics blog. It’s so insightful &amp; interesting, that NYTimes decides to link to it. Suppose that at the same time, Joe Blow, who took a community college class on Economics, also starts an economics blog… and his brother-in-law who works at the Street Sheet links to it as well. We now have 2 blogs, on the same topic, carrying the same keywords, and each having a link from a newspaper. A purely egalitarian search-engine would give them equal visibility. But Google’s knows that NYTimes is a lot more credible than Street Sheet. Hence, it gives NYTimes <em>thousands of ballots more</em> than Street Sheet, and this in turn gives Eugene Fama’s blog a huge well-deserved boost over Joe Blow’s.</p>
<p>Google’s search engine works so well, precisely because it relies on <em>credibility-based differential voting power</em>. Intuitively, it makes perfect sense. In our own lives, we know that some sources of information are much more valuable than others. We give much more weight to the advice of some, and ignore those of others. And yet, this notion is simply heretical in our democracy today. The idea of one-person-one-vote is so ingrained in our political system, that no one even dares to suggest an alternative to it. And yet, when you look at successful forms of crowdsourcing, they are all based on <em>highly differential voting power</em>. One only needs to compare the politicians we have in Congress to the quality of the search results returned by Google, in order to see which works out better.</p>
<p><strong><em><span>Barriers to Contribution</span></em></strong></p>
<p dir="ltr">We don’t have to go very far to find our next great crowdsourcing example: the world’s greatest store of information, Wikipedia. Like Google, and unlike its predecessor Encyclopedia Britannica, Wikipedia too is built around the idea of crowdsourcing. With less than 100 employees, Wikipedia simply creates a platform on which its users can make contributions. Each user contribution may be incremental, but together, they represent the greatest &amp; most easily accessible store of human knowledge.</p>
<p>Given that Wikipedia relies entirely on user contributions, one might think that users would be given the red carpet &amp; encouraged to contribute in any way possible. In reality though, user contributions (ie, edits), are often ruthlessly re-edited or discarded completely. Anyone can give their 2 cents by hitting the edit button &amp; typing away, but getting it to actually stay there for more than a day is not easy. In order to make any lasting contribution, users are required to <em>research</em> the topic and back up their opinions with <em>supporting evidence</em>. Poorly expressed opinions are simply discarded without even a trace.</p>
<p>Having such <em>barriers to contribution</em> does dissuade some well-informed people from making valuable contributions. However, it also filters out an even greater number of ill-informed people who would otherwise be injecting a great deal of noise. A well-informed person who cares enough about the topic to research it is less likely to be dissuaded by such hurdles, compared to a layperson who simply chances upon the discussion &amp; feels the urge to give his 2 cents. By filtering out noise, such <em>barriers to contribution</em> keep the signal-to-noise ratio high.</p>
<p>Contrast this with our democracy, where there is universal agreement that there should never be a barrier to contribution. Our entire system is designed to make voting as easy &amp; convenient as possible. When Joe Blow walks into the voting booth and is asked to contribute to democracy, he can vote for absolutely anything he wants in a matter of minutes, without ever having to justify his choices with research, evidence or logic. The time investment required to vote is insignificant compared to its profound &amp; long-lasting effects. With <em>barriers to contribution</em> kept intentionally low, it’s hardly surprising that our political system feels much more like a noisy bar than a well oiled machine.</p>
<p><strong><em><span>Specialization of Contribution</span></em></strong></p>
<p dir="ltr">As a change of pace, I‘d like for us to consider another great crowdsourcing example that is centuries old. One that we partake in every single day: The market-based economy. How many of us know how to grow crops? Sew clothes? Build a house? Design a computer chip? Perform open-heart surgery? There isn’t a person alive who can answer yes to all of the above. And yet, we are able to enjoy the fruits of all of these &amp; accomplish some truly miraculous feats as a society. This is only possible through <em>division of labor</em>. At a young age, each of us decides upon a career that we would like to pursue. We then spend a decade or more <em>specializing</em> in that one field. We develop great expertise in an extremely niche field, and then spend the next few decades <em>contributing</em> to society, through that one <em>niche field</em>.</p>
<p>More importantly, we also stay away from the other 99% of fields that we know little about. Engineers don’t go around telling doctors how to do their jobs, and doctors don’t go around offering their opinions on good accounting practices. The market based economy works so miraculously, precisely because each of us contributes to society in one very <em>specialized</em> area, and we allow others to do so as well without getting in their way. Can you imagine how well a BMW would run if it was designed by popular vote? And yet, this is the reality of our democracy today. When we go into the voting booth &amp; are asked to choose between Obama &amp; Romney, we’re expected to evaluate both candidates’ economic policies, national security policies, health care proposals, and numerous other credentials in fields that we know next to nothing about.</p>
<p>When we consider the vast breadth of human knowledge, we are all idiot savants. The market-economy has worked so well by funneling our efforts into those fields where we’re <em>savants</em>. Democracy on the other hand, forces us to make decisions precisely in the fields where we’re <em>idiots</em>.</p>
<hr>
<p><em>Differential voting power; Barriers to contribution; Specialization of contribution</em>. All 3 can be found in each of the examples given above. If we look at other forms of successful crowdsourcing, such as financial markets &amp; scientific research, it’s no coincidence that these same characteristics show up there as well. It’s time we had a political system that takes a page out of these great success stories.</p>
<p>Let me end this article, ironically enough, by giving plaudits to democracy. It was truly a brilliant &amp; remarkably insightful idea for the 18th century. It gave birth to the notion of decentralization of power. It created a system of government that derives its power from the people. It leveled the playing field, giving everyone equal treatment &amp; equal opportunity. It gave birth to a political system that was open &amp; accessible to all. It brought crowdsourcing to the field of politics. These were all brilliant ideas for their time, and any new political system we implement should surely hold on to these principles.</p>
<p>However, we have come a long way in the past 300 years, and the cracks in the foundation of democracy are starting to show. Certain aspects that are considered fundamental to democracy, have been shown to severely detract from it. It’s time we overhauled our political system and boldly stepped into the new millenium.</p>


<hr>



<p><em>Ways to Fix Democracy:</em><br><a rel="noreferrer noopener" href="https://outlookzen.wordpress.com/2014/01/21/democracy-by-jury/" target="_blank"><em>A suggestion to reform democracy, using the Jury system as a model</em></a><br><a rel="noreferrer noopener" href="https://outlookzen.wordpress.com/2014/06/29/reinventing-democracy-the-google-way/" target="_blank"><em>Another suggestion to reform democracy, using Google’s search engine</em></a></p>



<hr>



<p><em>Related links:</em><br><a href="https://www.politico.com/magazine/story/2019/09/08/shawn-rosenberg-democracy-228045" target="_blank" rel="noreferrer noopener" aria-label="Leading political psychologist arguing that our brains are not equipped for democracy (opens in a new tab)"><em>Leading political psychologist arguing that our brains are not equipped for democracy</em></a><em><br></em><a rel="noreferrer noopener" href="https://outlookzen.wordpress.com/2013/11/29/direct-vs-representative-democracy/" target="_blank"><em>The crucial difference between direct democracy &amp; representative democracy</em></a><em><br></em><a rel="noreferrer noopener" href="http://nyti.ms/JrTPjC" target="_blank"><em>NYTimes: A Work Still in Progress</em></a><em><br></em><a rel="noreferrer noopener" href="http://wapo.st/1mi3YeD" target="_blank"><em>60% of Americans have no idea which party controls Congress</em></a><em><br></em><a rel="noreferrer noopener" href="http://www.nytimes.com/2016/08/26/opinion/the-dumbed-down-democracy.html?_r=0" target="_blank"><em>NYTimes: Democracy dumbed down</em></a><em><br></em><a rel="noreferrer noopener" href="https://www.nytimes.com/2017/06/29/opinion/sunday/the-problem-with-participatory-democracy-is-the-participants.html?_r=0" target="_blank"><em>NYTimes: The problem with …</em></a></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://outlookzen.com/2013/11/06/its-time-to-reinvent-democracy/">https://outlookzen.com/2013/11/06/its-time-to-reinvent-democracy/</a></em></p>]]>
            </description>
            <link>https://outlookzen.com/2013/11/06/its-time-to-reinvent-democracy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23882048</guid>
            <pubDate>Sat, 18 Jul 2020 15:32:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AWS Serverless: you might not need third party monitoring]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23881805">thread link</a>) | @kiyanwang
<br/>
July 18, 2020 | https://www.rehanvdm.com/general/aws-serverless-you-might-not-need-third-party-monitoring/index.html | <a href="https://web.archive.org/web/*/https://www.rehanvdm.com/general/aws-serverless-you-might-not-need-third-party-monitoring/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<ul><li><a data-class="popup" data-network="facebook" href="https://www.facebook.com/sharer.php?u=http%3A%2F%2Fwww.rehanvdm.com%2Fgeneral%2Faws-serverless-you-might-not-need-third-party-monitoring%2Findex.html" target="_blank" rel="nofollow"><i></i> </a></li><li><a data-class="popup" data-network="twitter" href="https://twitter.com/intent/tweet?text=AWS%20Serverless:%20you%20might%20not%20need%20third%20party%20monitoring&amp;url=http%3A%2F%2Fwww.rehanvdm.com%2Fgeneral%2Faws-serverless-you-might-not-need-third-party-monitoring%2Findex.html&amp;via=der_rehan" target="_blank" rel="nofollow"><i></i> </a></li><li><a data-class="popup" data-network="linkedin" href="https://linkedin.com/shareArticle?mini=true&amp;url=http%3A%2F%2Fwww.rehanvdm.com%2Fgeneral%2Faws-serverless-you-might-not-need-third-party-monitoring%2Findex.html&amp;title=AWS+Serverless%3A+you+might+not+need+third+party+monitoring" target="_blank" rel="nofollow"><i></i> </a></li></ul>




<p>I hardly ever find myself reaching for third party monitoring services these days. I rather use the AWS native observability, monitoring and alerting services. The primary reasons being that I can use my favorite Infrastructure as Code (IaC) tool to define the infrastructure as well as the monitoring, observability and dashboards for every project in one place. I also only pay for what I use; there are no monthly subscriptions.</p>



<p><em>This blog is also available as a presentation. Reach out if you would like me to present it at an event. It consists of about 30% slides and 70% live demo. </em><br></p>



<p>In this two-part series, we’ll first build a bad microservice system and add observability, monitoring and alerting. The second part will focus on refactoring the code and go into more details on the decisions made.</p>



<p>Like most of my blogs, this one is also accompanied by code. I decided to create three microservices, each in their own repositories, with the fourth one used to reference all of them. The code is available on github: <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://github.com/rehanvdm/MicroService" target="_blank">https://github.com/rehanvdm/MicroService</a>. These microservices were designed poorly for demo purposes and to explain the importance of certain points, like structured logging. Below are all three services:</p>



<figure><a href="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_01_SystemArchitecture.png" target="_blank" rel="noreferrer noopener"><img src="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_01_SystemArchitecture-1024x715.png" alt="" width="1024" height="715" srcset="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_01_SystemArchitecture-1024x715.png 1024w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_01_SystemArchitecture-300x210.png 300w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_01_SystemArchitecture-768x536.png 768w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_01_SystemArchitecture.png 1111w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<p>Within each project you can find an <strong>OpenAPI </strong>(<a href="https://github.com/rehanvdm/MicroServicePerson/blob/master/part1/src/lambda/api/api-definition.yaml" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">part1/src/lambda/api/api-definition.yaml</a>) file that defines the API definition for each service.<strong> AWS CDK</strong> is used and they all follow the similar stock standard CDK project layout: Typescript for the CDK and <strong>ES6 JS</strong> for the application code. NPM commands have been written to do deployments and it also contains<strong> end-to-end tests </strong>using Mocha and Chai. In addition, each service contains a detailed README inside the /part1 path. Note that I only have a single Lambda for the API endpoint and do internal routing. Yes, I believe in a <strong>Lambalith for the API</strong> 😊 and also prefer JSON POST over REST (more about this later).</p>



<p>The client service stores clients and has basic <em>create-client</em> and <em>find-client</em> functionalities as well as an endpoint to increment the person count for a specific client. The person service also has basic <em>create-person</em> and <em>find-person</em> endpoints. When a person is created, it calls the common service which notifies me by email about the new person that was added using an SNS subscription. The common service first needs to do a lookup on the client service so that it can enrich the email. It also increments the counter on the client. Click on the image below to see the step-by-step path for creating a person:</p>



<figure><a href="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_02_SystemArchitecturePathFocus.png" target="_blank" rel="noreferrer noopener"><img src="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_02_SystemArchitecturePathFocus-1024x553.png" alt="" width="1024" height="553" srcset="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_02_SystemArchitecturePathFocus-1024x553.png 1024w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_02_SystemArchitecturePathFocus-300x162.png 300w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_02_SystemArchitecturePathFocus-768x415.png 768w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_02_SystemArchitecturePathFocus.png 1442w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<p>In Part 2 we will focus on refactoring and decoupling this system. That brings me to the reason why the current system is poorly designed. I <strong>purposefully created a distributed monolith</strong>.</p>



<p>The create-person call is highly dependent on the common
service and does not even know that the common service is dependent on the
client service. As a result, the person service is also dragged down if either
the common or the client service is down. Not to mention that it now has to
wait for the completion of every step in the synchronous chain. This wastes money
and increases the probability of hitting the API Gateway timeout of 29 seconds.
</p>



<p>Let’s first look at a few generic concepts that are referenced throughout the post. Then we will look at the AWS native services.</p>



<h2>Structured logging, types of errors and metrics</h2>



<h3>Errors</h3>



<p><u>Hard Errors</u> are infrastructure and runtime errors. You should always have alerts on these. Ex. time out, unexpected error and runtime errors not caught by try-catch blocks.</p>



<p><u>Soft Errors</u> are completely software-defined. This is when your infrastructure and services are working but the <strong>result was undesired</strong>. An example would be that your API returned an HTTP status code 200 with a validation error message in the body. </p>



<h3>Metrics</h3>



<p><u>Business Metrics </u>– Key performance indicators (KPIs) that you use to measure your application performance against. Ex. orders placed.</p>



<p><u>Customer Experience Metrics</u> – Percentiles and perceived latencies that the user is experiencing. A typical scenario would be page load times. Another would be that even though your API is fast, the front-end needs to make 10 concurrent API calls when the application starts. The browsers then queues these concurrent requests and the user waits at least two or three times longer.</p>



<p><u>System Metrics</u> – Application level metrics that indicate system health. Ex. number of API requests, queue length, etc. </p>



<h3>Structured logging</h3>



<p>All microservices write logs in the format below. This is done by wrapping around the <em>console </em>class and writing in JSON format. Levels will include all your basics, like info, log, debug, error, warning, with the only new one being audit.</p>



<figure><a href="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_10_StructuredLogging1.png" target="_blank" rel="noreferrer noopener"><img src="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_10_StructuredLogging1.png" alt="" width="737" height="38" srcset="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_10_StructuredLogging1.png 737w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_10_StructuredLogging1-300x15.png 300w" sizes="(max-width: 737px) 100vw, 737px"></a></figure>



<p>A single audit record is written per Lambda execution and gives a summary for the result of that execution. The image below shows an audit record that contains the API path, run time, status code, reason and many more fields used in the Log Insight queries later on. </p>



<figure><a href="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_10_StructuredLogging2.png" target="_blank" rel="noreferrer noopener"><img src="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_10_StructuredLogging2.png" alt="" srcset="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_10_StructuredLogging2.png 522w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_10_StructuredLogging2-300x246.png 300w" sizes="(max-width: 522px) 100vw, 522px"></a></figure>



<p> The image below shows an unsuccessful execution:</p>



<figure><a href="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_10_StructuredLogging3.png" target="_blank" rel="noreferrer noopener"><img src="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_10_StructuredLogging3.png" alt="" srcset="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_10_StructuredLogging3.png 506w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_10_StructuredLogging3-300x251.png 300w" sizes="(max-width: 506px) 100vw, 506px"></a></figure>



<p>Note that the runtime is not the one reported by Lambda.
There is an environment variable on the Lambda itself that indicates what the
function timeout value is. We then subtract the <em>context.getRemainingTimeInMillis()</em>
to get a close estimate to the actual reported runtime.</p>



<p>Let’s take a closer look at the AWS Native services that we will use. </p>



<h2>AWS CloudWatch Logs</h2>



<p>Logs are crucial to any application. CloudWatch stores logs in the format of log groups and log streams. Each log group can be considered a Lambda function and a stream is the executions of that Lambda function. The real magic happens when you do log insights over your structured logs. </p>



<figure><a href="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_03_CloudWatchLogs.png" target="_blank" rel="noreferrer noopener"><img src="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_03_CloudWatchLogs-1024x402.png" alt="" width="1024" height="402" srcset="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_03_CloudWatchLogs-1024x402.png 1024w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_03_CloudWatchLogs-300x118.png 300w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_03_CloudWatchLogs-768x301.png 768w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<h2>AWS CloudWatch Metrics</h2>



<p>Metrics are best described as the logging of discrete data points for a system against time. These metrics can then be displayed on graphs, like; database CPU versus time or the types of API response over time. They are at the heart of many services, like dashboards, alerts and auto scaling. If you write a log line in a specific format, called the <a rel="noreferrer noopener" aria-label="Embedded Metric Format (opens in a new tab)" href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch_Embedded_Metric_Format.html" target="_blank">Embedded Metric Format</a>, it automatically transforms it into a metric. Find the client libraries that help write this format <a rel="noreferrer noopener" aria-label="here (opens in a new tab)" href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch_Embedded_Metric_Format_Libraries.html" target="_blank">here.</a></p>



<p>Below shows the amount of API calls summed by 1-minute intervals for the client API after the <a rel="noreferrer noopener" aria-label="artillery.io (opens in a new tab)" href="https://artillery.io/" target="_blank">artillery.io</a> load test was run. </p>



<figure><a href="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_04_CloudWatchMetric.png" target="_blank" rel="noreferrer noopener"><img src="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_04_CloudWatchMetric.png" alt="" width="910" height="500" srcset="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_04_CloudWatchMetric.png 910w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_04_CloudWatchMetric-300x165.png 300w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_04_CloudWatchMetric-768x422.png 768w" sizes="(max-width: 910px) 100vw, 910px"></a></figure>



<h2>AWS CloudWatch Alarms</h2>



<p>Alarms perform an action when certain conditions on Metrics are met. &nbsp;For example, CPU more than 50% for 3 minutes. Actions include emailing a person or sending the message to an SNS topic. This topic can then be subscribed to by other services. We subscribe to this topic with AWS Chatbot to deliver the notifications to a Slack channel.</p>



<figure><a href="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_05_CloudWatchAlarm.png" target="_blank" rel="noreferrer noopener"><img src="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_05_CloudWatchAlarm-1024x637.png" alt="" width="1024" height="637" srcset="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_05_CloudWatchAlarm-1024x637.png 1024w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_05_CloudWatchAlarm-300x187.png 300w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_05_CloudWatchAlarm-768x478.png 768w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_05_CloudWatchAlarm.png 1312w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<p>It is important to subscribe to both the ALERT and the OKAY actions. Otherwise you will never know if your system stabilized after an alert unless you log into the console and inspect the system. </p>



<figure><a href="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_05_CloudWatchAlarm2.png" target="_blank" rel="noreferrer noopener"><img src="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_05_CloudWatchAlarm2.png" alt="" width="930" height="210" srcset="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_05_CloudWatchAlarm2.png 930w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_05_CloudWatchAlarm2-300x68.png 300w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_05_CloudWatchAlarm2-768x173.png 768w" sizes="(max-width: 930px) 100vw, 930px"></a></figure>



<p>Composite Alarms are great when you want to string together some sort of logic to give a higher order of alarm/event. For example, you can create an alarm if the database CPU is more than 50% and the API hit count is less than 1000 requests per minute. This will set off an event/alarm informing you that your database might be crunching away at a difficult query and that it might be a result of a person executing a heavy analytical query rather than your application.</p>



<figure><a href="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_05_CloudWatchAlarm4-1024x259.png" target="_blank" rel="noreferrer noopener"><img src="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_05_CloudWatchAlarm4-1024x259.png" alt="" width="1024" height="259"></a></figure>



<figure><a href="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_05_CloudWatchAlarm3.png" target="_blank" rel="noreferrer noopener"><img src="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_05_CloudWatchAlarm3-1024x593.png" alt="" width="1024" height="593" srcset="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_05_CloudWatchAlarm3-1024x593.png 1024w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_05_CloudWatchAlarm3-300x174.png 300w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_05_CloudWatchAlarm3-768x445.png 768w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_05_CloudWatchAlarm3.png 1272w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<p>Anomaly detection uses machine learning (random cut forest) to train on up to two weeks of metric data. This creates upper and lower bands around your metric which are defined by standard deviations. Alerts can then be created whenever your metric is outside or within these bands. They are great at monitoring predictable periodic metrics, like API traffic.</p>



<figure><a href="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_05_CloudWatchAlarm5.png" target="_blank" rel="noreferrer noopener"><img src="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_05_CloudWatchAlarm5.png" alt="" width="662" height="936" srcset="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_05_CloudWatchAlarm5.png 662w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_05_CloudWatchAlarm5-212x300.png 212w" sizes="(max-width: 662px) 100vw, 662px"></a></figure>



<h2>AWS CloudWatch Metric filters</h2>



<p>CloudWatch Metric filter will <strong>search the Logs for patterns and publish the search results as Metrics</strong>. For example, we can search for the word ‘retry’ in the logs and then publish it as a metric that we can view on a dashboard or <strong>create an alarm from</strong>. </p>



<p>This is <strong>how we count soft errors</strong>, which are errors that don’t crash the Lambda but return an undesired result to the caller. In our example, all the API Lambdas always return HTTP Status code 200. Within the body of the response is our request status code: 2000 – Success, 5000 – Unexpected, 5001 – Handled, 5002 – Validation, 3001 – Auth. Structured logging always writes the audit record in a specific format. We use this to create metrics and then alarms based on those metrics.</p>



<figure><a href="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_05_CloudWatchAlarm6.png" target="_blank" rel="noreferrer noopener"><img src="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_05_CloudWatchAlarm6-1024x730.png" alt="" width="1024" height="730" srcset="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_05_CloudWatchAlarm6-1024x730.png 1024w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_05_CloudWatchAlarm6-300x214.png 300w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_05_CloudWatchAlarm6-768x548.png 768w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_05_CloudWatchAlarm6.png 1140w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<h2>AWS CloudWatch Dashboards</h2>



<p>Dashboards are great to get an overview of the operational status of your system.<strong> In the example services, each one also deploys their own dashboard</strong> to monitor basic metrics of the Lambda, API Gateway and DynamoDB table. Everything is defined as IaC using the <strong>AWS CDK</strong>.</p>



<figure><img src="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_06_CloudWatchDashboards1.png" alt="" srcset="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_06_CloudWatchDashboards1.png 1020w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_06_CloudWatchDashboards1-300x259.png 300w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_06_CloudWatchDashboards1-768x664.png 768w" sizes="(max-width: 1020px) 100vw, 1020px"></figure>



<p>A manual dashboard can also be created to combine all the services onto one dashboard. I usually tend to make it less granular by just displaying the overall status of each microservice and other useful information. </p>



<figure><a href="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_06_CloudWatchDashboards2.png" target="_blank" rel="noreferrer noopener"><img src="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_06_CloudWatchDashboards2-1024x771.png" alt="" width="1024" height="771" srcset="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_06_CloudWatchDashboards2-1024x771.png 1024w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_06_CloudWatchDashboards2-300x226.png 300w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_06_CloudWatchDashboards2-768x578.png 768w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_06_CloudWatchDashboards2.png 1142w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<p>The dashboard above contains three CloudWatch Log Insight query widgets. We can even write basic markup to create links/buttons, as seen in the bottom right corner. </p>



<h2>AWS CloudWatch Log Insights</h2>



<p>Log Insights enable us to do SQL-like querying over one or more Log Groups. This tool is<strong> extremely powerful</strong> to get insights out of your structured logs. It also has basic grouping functionality that can graph results. For example, we use a single query to <strong>query the audit records of all three microservices</strong> over the last 2 weeks (see below).</p>



<figure><a href="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_07_CloudWatchLogInsights1.png" target="_blank" rel="noreferrer noopener"><img src="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_07_CloudWatchLogInsights1-1024x634.png" alt="" width="1024" height="634" srcset="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_07_CloudWatchLogInsights1-1024x634.png 1024w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_07_CloudWatchLogInsights1-300x186.png 300w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_07_CloudWatchLogInsights1-768x475.png 768w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_07_CloudWatchLogInsights1.png 1383w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<figure><a href="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_07_CloudWatchLogInsights4.png" target="_blank" rel="noreferrer noopener"><img src="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_07_CloudWatchLogInsights4.png" alt="" width="921" height="244" srcset="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_07_CloudWatchLogInsights4.png 921w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_07_CloudWatchLogInsights4-300x79.png 300w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_07_CloudWatchLogInsights4-768x203.png 768w" sizes="(max-width: 921px) 100vw, 921px"></a></figure>



<p>We can also compare the latencies of all the microservice API calls and visually graph it in a bar chart. </p>



<figure><a href="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_07_CloudWatchLogInsights2.png" target="_blank" rel="noreferrer noopener"><img src="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_07_CloudWatchLogInsights2-1024x762.png" alt="" width="1024" height="762" srcset="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_07_CloudWatchLogInsights2-1024x762.png 1024w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_07_CloudWatchLogInsights2-300x223.png 300w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_07_CloudWatchLogInsights2-768x572.png 768w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_07_CloudWatchLogInsights2.png 1159w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<figure><a href="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_07_CloudWatchLogInsights5.png" target="_blank" rel="noreferrer noopener"><img src="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_07_CloudWatchLogInsights5.png" alt="" width="803" height="188" srcset="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_07_CloudWatchLogInsights5.png 803w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_07_CloudWatchLogInsights5-300x70.png 300w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_07_CloudWatchLogInsights5-768x180.png 768w" sizes="(max-width: 803px) 100vw, 803px"></a></figure>



<p>Lastly, I want to highlight the <strong>most impactful API calls</strong>. This is taking the amount of calls and multiplying it by the 95-percentile latency. This gives us a quick indication of which API …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.rehanvdm.com/general/aws-serverless-you-might-not-need-third-party-monitoring/index.html">https://www.rehanvdm.com/general/aws-serverless-you-might-not-need-third-party-monitoring/index.html</a></em></p>]]>
            </description>
            <link>https://www.rehanvdm.com/general/aws-serverless-you-might-not-need-third-party-monitoring/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23881805</guid>
            <pubDate>Sat, 18 Jul 2020 14:58:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Facebook’s Data Center Network Architecture [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23881758">thread link</a>) | @godelmachine
<br/>
July 18, 2020 | http://nathanfarrington.com/papers/facebook-oic13.pdf | <a href="https://web.archive.org/web/*/http://nathanfarrington.com/papers/facebook-oic13.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://nathanfarrington.com/papers/facebook-oic13.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-23881758</guid>
            <pubDate>Sat, 18 Jul 2020 14:51:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Improving Firefox Startup Time with the About:Home Startup Cache]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23881669">thread link</a>) | @severine
<br/>
July 18, 2020 | https://mikeconley.ca/blog/2020/07/13/improving-firefox-startup-time-with-the-abouthome-startup-cache/ | <a href="https://web.archive.org/web/*/https://mikeconley.ca/blog/2020/07/13/improving-firefox-startup-time-with-the-abouthome-startup-cache/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<h2>Don’t bury the lede</h2>



<p>We’re working on a thing to make Firefox start faster! It appears to work! Here’s a video showing off a before (left) and after (right):</p>



<figure><p><span><iframe width="625" height="352" src="https://www.youtube.com/embed/027tOvYZw88?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span>
</p></figure>



<h2>Improving Firefox Startup Time With The about:home Startup Cache</h2>



<p>For the past year or so, the Firefox Desktop Front-End Performance team has been concentrating on making improvements to browser startup performance.</p>



<p>The launching of an application like Firefox is quite complex. Meticulous profiling of Firefox startup in various conditions has, thankfully, helped reveal a number of opportunities where we can make improvements. We’ve been evaluating and addressing these opportunities, and several have made it into the past few Firefox releases.</p>



<p>This blog post is about one of those improvements that is currently in the later stages of development. I’m going to describe the improvement, and how we went about integrating it.</p>



<p>In a default installation of Firefox, the first (and only) tab that loads is about:home<sup id="rf1-3036"><a href="#fn1-3036" title="This is only true if the user hasn’t just restarted after applying an update, and if they haven’t set a custom home page or configured Firefox to restore their previous session on start." rel="footnote">1</a></sup>.</p>



<figure><img data-attachment-id="3038" data-permalink="https://mikeconley.ca/blog/2020/07/13/improving-firefox-startup-time-with-the-abouthome-startup-cache/abouthome/" data-orig-file="https://mikeconley.ca/blog/wp-content/uploads/2020/07/abouthome.png" data-orig-size="1144,853" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="abouthome" data-image-description="" data-medium-file="https://mikeconley.ca/blog/wp-content/uploads/2020/07/abouthome-300x224.png" data-large-file="https://mikeconley.ca/blog/wp-content/uploads/2020/07/abouthome-1024x764.png" src="https://mikeconley.ca/blog/wp-content/uploads/2020/07/xabouthome-1024x764.png.pagespeed.ic.IW4h6O6qkj.png" alt="" srcset="https://mikeconley.ca/blog/wp-content/uploads/2020/07/xabouthome-1024x764.png.pagespeed.ic.IW4h6O6qkj.png 1024w, https://mikeconley.ca/blog/wp-content/uploads/2020/07/xabouthome-300x224.png.pagespeed.ic.wVhPlDDCdi.jpg 300w, https://mikeconley.ca/blog/wp-content/uploads/2020/07/xabouthome-768x573.png.pagespeed.ic.FO3Xg95rAi.png 768w, https://mikeconley.ca/blog/wp-content/uploads/2020/07/xabouthome-624x465.png.pagespeed.ic.SojSX9wUNG.png 624w, https://mikeconley.ca/blog/wp-content/uploads/2020/07/xabouthome.png.pagespeed.ic.wA72oZvGF2.png 1144w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>The about:home page is actually the same thing that appears when you open a new tab (about:newtab). The fact that they have different addresses allows us to treat their loading differently.</p>



<p>Your about:home might look slightly different from the above — depending on your locale, it may or may not include the Pocket stories.</p>



<p>Do not be fooled by what appears to be a very simple page of images and text. This page is actually quite sophisticated under the hood. It is designed to be customized by the user in the following ways:</p>



<p>Users can</p>



<ul><li>Collapse or expand sections</li><li>Remove sections entirely</li><li>Reorganize the order of their Top Sites by dragging and dropping</li><li>Pin and unpin Top Sites to their positions</li><li>Add their own custom Top Sites with custom thumbnails</li><li>Add or remove search engines from their Top Sites</li><li>Change the number of rows in the Top Sites and Recommended by Pocket sections</li><li>Choose to have the Highlights composed of any of the following:<ul><li>Visited pages</li><li>Recent bookmarks</li><li>Recent downloads</li><li>Pages recently saved to Pocket</li></ul></li></ul>



<p>The user can customize these things at any time, and any open copies of the page are expected to reflect those customizations immediately.</p>



<p>There are further complexities beyond user customization. The page is also designed to be easy for our design and engineering teams to experiment with reorganizing the layout and composition of the page so that they can test variations on its layout in the wild.</p>



<p>The about:home page also has special privileges not afforded to normal websites. It can</p>



<ul><li>Save and remove bookmarks</li><li>Add pages to Pocket</li><li>Cause the URL bar to be focused and selected</li><li>Show thumbnails for pages that the user has visited</li><li>Access both high and normal resolution favicons</li><li>Render information about the user’s recent activity (recent page visits, downloads, saves to Pocket, etc.)</li></ul>



<p>So while at first glance, this appears to be a static page of just images and text, rest assured that the page can do much more.</p>



<p>Like the Firefox Developer Tools UI, about:home is written with the help of the React and Redux libraries. This has allowed the about:home development team to create sophisticated, reusable, and composable components that could be easily tested using modern JavaScript testing methods.</p>



<p>Unsurprisingly, this complexity and customizability comes at a cost. The page needs to request a state object from the parent process in order to have the Redux store populated and to have React render it. Essentially, the page is dynamically rendering itself after the markup of the page loads.</p>



<p>Startup is a critical time for an application. The user has expressed a need for their browser, and we have an obligation to serve the user as quickly and efficiently as possible. The user’s time is a resource that we should not squander. Similarly, because so much needs to occur during startup,<sup id="rf2-3036"><a href="#fn2-3036" title="You can think of startup like a traveling circus coming to town. You have to get the trucks and trailers parked, get the tents set up, hook up power, then lighting and sound … it’s a big, complex operation, and we haven’t even shot a clown out of a cannon yet." rel="footnote">2</a></sup> disk reads, disk writes, and CPU time are also considered precious resources. They should only be used if there’s no other choice.</p>



<p>In this case, we believed that the CPU time and disk accesses spent constructing the state object and dynamically rendering the about:home page was competing with all of the other CPU and disk access happening during startup, and this was slowing us down from presenting about:home to the user in a timely way.</p>



<p>Generally speaking, in my mind there are four broad approaches to performance problems once a bottleneck has been identified.</p>



<ul><li>You can widen the bottleneck (make the operations more efficient)</li><li>You can divide the bottleneck (split the work into smaller slices that can be done over a longer period of time with rests in between)</li><li>You can move the bottleneck (defer work until later when it seems that there is less competition for resources, or move it to a different thread)</li><li>You can remove the bottleneck (don’t do the work)</li></ul>



<p>We started by trying to apply the last two approaches, wondering what startup performance would be like if the page did not render itself dynamically, but was instead a static page generated periodically and pulled off of the disk at startup.</p>



<h2>Prototype when possible</h2>



<p>The first step to improving something is finding a way to measure it. Thankfully, we already have a number of logged measurements for startup. One of those measurements gives us the time from process start to rendering the Top Sites section of about:home. This is not a perfect measurement—ideally, we’d measure to the point that the page finally “settles” and stops changing<sup id="rf3-3036"><a href="#fn3-3036" title="<a href=&quot;https://bugzilla.mozilla.org/show_bug.cgi?id=1637024&quot;>We’re working on something like that</a>" rel="footnote">3</a></sup>—but for this project, this measurement served our purposes.</p>



<p>Before investing a bunch of time into a potential improvement, it’s usually a good idea to try to see if what you’re gaining is worth the development time. It’s not always possible to build a prototype for performance improvements, but in this case it was.</p>



<p>The team quickly threw together a static copy of about:home and <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1614352">hacked together a patch to load that document during startup, rather than dynamically rendering the page</a>. We then tested that page on our reference hardware. As of this writing, it’s been about five months since that test was done, but <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1614352#c2">according to this comment</a>, the prototype yielded what appears to be an almost 20% win on time from process start to about:home painting Top Sites.</p>



<p>So, with that information, we thought we had a real improvement opportunity here. We decided to proceed with the idea, and began a long arduous search for “the right way to do it.”</p>



<h2>Pre-production</h2>



<p>As I mentioned earlier, about:home is complex. The infrastructure that powers it is complex. Coupled with the fact that no one on the Firefox Front-End Performance team had spent much time studying React and Redux meant that we had a lot of learning to do.</p>



<p>The first step was to get some React and Redux fundamentals under our belt. This meant building some small toy applications and getting familiar with the framework idioms and how things are organized.</p>



<p>With that grounding, the next step was to start reading the code — starting from the entrypoint into the code that powers about:home when the browser starts. <a href="https://docs.google.com/document/d/1zvDPcdqaZ7140nabNonQpD5Ln_nrAcJGBgFCJFG_0MM/edit#heading=h.1w5efh70rcvh">This was an intense period of study</a> that branched into many different directions. Part of the complexity was because much of the code is asynchronous and launched work on different threads, which introduced some non-determinism. While it is generally good for responsiveness to move work off of the main thread, it can lead to some complex reading and interpretation of the code when more than two threads are involved.</p>



<p>A tool we used during this analysis was the <a href="https://profiler.firefox.com/docs/#/">Firefox Profiler</a>, to get a realistic sense of the order of executions during startup. These profiles helped to inform much of our reading of the code.</p>



<p>This analysis helped us solidify our mental model of how about:home loads. With that model in place, it was much easier to propose practical approaches for introducing a static about:home document into the ecosystem of pre-existing code. <a href="https://docs.google.com/document/d/1zvDPcdqaZ7140nabNonQpD5Ln_nrAcJGBgFCJFG_0MM/edit#heading=h.1w5efh70rcvh">The Firefox Front-End Performance team documented our findings and recommendations</a> and then presented them to the team that originally built the about:home system to ensure that we were all on the same page and that we hadn’t missed anything critical. They were already aware that we were investigating potential performance improvements, and had very useful feedback for us, as well as historical product decision context that clarified our understanding.</p>



<p>Critically, we presented our recommendation for loading a static about:home page at startup and ensured that there were no upcoming plans for about:home that would break our mental model or render the recommendation no longer valid. Thankfully, it sounded like we were aligned and fine to proceed with our plan.</p>



<p>So what was the plan? We knew that since about:home is quite dynamic and can change over time<sup id="rf4-3036"><a href="#fn4-3036" title="As the user browses, bookmarks and downloads things, their Highlights and Top Sites sections might change. If Pocket is enabled, new stories will also be downloaded periodically." rel="footnote">4</a></sup> we needed a startup cache for about:home that could be periodically updated during the course of a browsing session. We would then load from that cache at startup. Clearly, I’m glossing over some details here, but that was the general plan.</p>



<p>As usual, no plan survives breakfast, and as we started to architect our solution, we identified things we would need to change along the way.</p>



<h2>Development</h2>



<p>We knew that the process that loads about:home would need to be able to read from the about:home startup cache. We also knew that about:home can potentially contain information about what pages the user has visited, and that about:home can do privileged things that normal web pages cannot. It seemed that this project would be a good opportunity to finish a project that was started (and mothballed) a year or so earlier: creating a special privileged content process for about:home. We would load about:home in that process, and add assertions to ensure that privileged actions from about:home could only happen from that content process type<sup id="rf5-3036"><a href="#fn5-3036" title="It’s vitally important that content processes have limited abilities. That way, if they’re ever compromised by a bad actor, there are limits to what damage they can do. The assertions mentioned in this case mean that if a compromised content process tries to “pretend” to be the privileged about content process by sending one of its messages, that the parent process will terminate that content process immediately." rel="footnote">5</a></sup></p>



<p>So getting the “privileged about content process”<sup id="rf6-3036"><a href="#fn6-3036" title="Naming is hard." rel="footnote">6</a></sup> fixed up and ready for shipping was the first step.</p>



<p>This also paved the way for …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mikeconley.ca/blog/2020/07/13/improving-firefox-startup-time-with-the-abouthome-startup-cache/">https://mikeconley.ca/blog/2020/07/13/improving-firefox-startup-time-with-the-abouthome-startup-cache/</a></em></p>]]>
            </description>
            <link>https://mikeconley.ca/blog/2020/07/13/improving-firefox-startup-time-with-the-abouthome-startup-cache/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23881669</guid>
            <pubDate>Sat, 18 Jul 2020 14:40:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Booting to 'Hello Rust' on x86_64]]>
            </title>
            <description>
<![CDATA[
Score 237 | Comments 35 (<a href="https://news.ycombinator.com/item?id=23881584">thread link</a>) | @micouay
<br/>
July 18, 2020 | https://micouy.github.io/posts/low-level-pt-1/ | <a href="https://web.archive.org/web/*/https://micouy.github.io/posts/low-level-pt-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<article>
    
<p>This post is about how I booted to bare metal Rust on x86_64.
My goal is to describe my learning path and hopefully get
you interested in things I talk about. I’ll be very happy if you
find this content useful. Note that I’m a begginer and I may be wrong
about many things. If you want to learn more, I’ll put links to many resources.
You can find all the code in my <a href="https://github.com/micouy/gniazdo-os">repo</a>.</p>

<p>The inspiration for this project came from many sources. I think I first
discovered <a href="https://github.com/cfenollosa/os-tutorial">cfenollosa/os-tutorial</a>.
I also read a few chapters from <a href="https://www.cs.bham.ac.uk/~exr/lectures/opsys/10_11/lectures/os-dev.pdf">Writing a Simple Operating System - from Scratch</a>.
It’s a good introduction to OS dev and related topics. First part
of the tutorial is about bootloaders. To get a grasp of what it’s
all about, I just read every part of the tutorial and tried to write the Assembly
code by myself.</p>
<p>Here’s a brief explanation of the boot process and what you have to do
at each stage. First the CPU thinks it’s an Intel 8086 model form 1970s IIRC. This stage is
called Real Mode. You have ~1MiB of memory and 16-bit <a href="https://en.wikipedia.org/wiki/Processor_register">registers</a>
at your disposition. In RM you are very limited. However, at this stage
you can use BIOS routines (or interrupts). They’re like an external library you can use to
print a character on the screen, read from and write to hard disk etc.
You can obviously do these things in other modes but you have to implement it yourself
or do some hacking to use the interrupts.</p>
<p>When you’re done with RM, you can switch to Protected Mode. In PM the address space
is extended (you can access more memory), 32-bit registers are enabled
and addressing works a bit different. To switch to PM,
you have to set up a <a href="http://www.osdever.net/tutorials/view/the-world-of-protected-mode">Descriptor Table</a>
which is a piece of data that tells the CPU
how to interpret addresses, and describes the characteristics of particular
parts of the memory.</p>
<hr>
<p><strong>Note</strong>: At first I thought that in PM address like <code>ds:ebx</code>
works just like in RM - <code>ds</code> is the segment (in ‘data’ memory if you want
to read/write to it or in ‘code’ memory if you jump to it) and <code>ebx</code>
is the offset in this segment. In reality <code>ds</code> acts like an index
into the descriptor table. Then, the selected descriptor is used
to translate the offset from the segment base (stored in <code>ebx</code>) to a physical address.
You can read more about addressing in PM <a href="http://ece-research.unm.edu/jimp/310/slides/micro_arch2.html">here</a>.
Also check out other stuff on <a href="http://ece-research.unm.edu/jimp/">their website</a>.</p>
<hr>

<p>The bootloader is a very short piece of code - it’s just 512 bytes long.
I once even ran out of space and had to remove some strings and unnecessary
code. The actual purpose of the bootloader is to load and run some other code.
The book suggested booting to PM and jumping to a 32-bit kernel written in C.
I didn’t really like programming in C and at this point I lost my motivation.</p>
<p>Another time I learned about Philipp Oppermann’s <a href="https://os.phil-opp.com/">blog</a>
on OS dev in Rust. I highly recommend it. I got really excited but,
unfortunately for me, Oppermann uses <a href="https://www.gnu.org/software/grub/">GRUB</a>
(a kind of bootloader) so I decided to come back to the tutorial after
finishing my own bootloader. At that time booting to a program written in language
other than Assembly and compiled to a separate file was way beyond my capabilities
so I left the project for a while.</p>
<p>A couple weeks ago I got motivated enough to try to boot to a Rust program.
My plan was to switch to Long Mode. Then I could either run a 64-bit kernel
or load a second stage bootloader. Second stage bootloader is not limited
to one sector (can be more than 512 bytes long) and can be 32-bit
or even 64-bit so it has access to a larger address space and can load
arbitrarily large files from disk to memory (as long as you implement it).
Its purpose is to load larger kernels.</p>
<p>The first step was loading my program from hard disk to memory.
I took a naive approach. I compiled the bootloader and my program.
I concatenated both binaries together, one right after the other, to form one file, like this:</p>
<div><pre><code data-lang="bash">cat bootloader.bin hello_rust.bin &gt; img
</code></pre></div><p>I didn’t care if I could actually execute Rust code, I just wanted
to test if I can load it. I added necessary code to my bootloader
and ran the emulator. Unfortunately QEMU just kept restarting.
I’m not sure what went wrong but it didn’t matter since it
was a stupid way to do it. I could just test loading data from the disk on
a much simpler bootloader. I first tried to write it myself but after a while
I just grabbed some code from Stack Overflow and added a simple error message in case
the BIOS routine failed. After a couple of tries I finally managed to create
a two-stage bootloader in a single Assembly program. It worked something like this:</p>
<div><pre><code data-lang="nasm"><span>org</span> <span>0x7c00</span>
first_stage:
    <span>; load second stage.</span>

    <span>; `dl` register specifies which disk to load</span>
    <span>; data from. it is set by the CPU to the same device</span>
    <span>; the bootloader was loaded from.</span>

    <span>; set `es` to 0x7e0 and `bx` to 0x0.</span>
    
    <span>; the routine will load data to `(es &lt;&lt; 4) | bx`</span>
    <span>; or 0x7e00.</span>
    <span>mov</span> ax, <span>0x7e0</span>
    <span>mov</span> es, ax
    <span>mov</span> bx, <span>0x0</span>

    <span>mov</span> al, <span>0x1</span> <span>; # of sectors to read.</span>
    
    <span>push</span> ax <span>; store `al` for later.</span>

    <span>; specify where the data is stored on the disk.</span>
    <span>mov</span> ch, <span>0x0</span> <span>; cylinder.</span>
    <span>mov</span> dh, <span>0x0</span> <span>; head.</span>
    <span>mov</span> cl, <span>0x2</span> <span>; sector right after bootloader.</span>

    <span>; `int 0x13` with `ah` set to 0x2</span>
    <span>; loads data from disk to memory.</span>
    <span>mov</span> ah, <span>0x2</span>
    <span>int</span> <span>0x13</span>

    <span>pop</span> bx <span>; restore `al` to `bl`.</span>

    <span>; check whether the number of sectors read is correct.</span>
    <span>cmp</span> al, bl
    <span>jne</span> error
       
    <span>jmp</span> <span>0x7e00</span> <span>; jump to second stage.</span>

error:
    <span>; print error message, then halt.</span>
    <span>jmp</span> <span>$</span>

<span>; fill the rest of the first sector with zeros.</span>
<span>; it's 510 and not 512 because the last two bytes</span>
<span>; are 0xaa and 0x55 - the 'magic' number.</span>
<span>times</span> <span>510</span><span>-</span>(<span>$</span><span>-</span><span>$$</span>) db <span>0</span>
<span>dw</span> <span>0xaa55</span>

second_stage:
    <span>; do something, then halt.</span>
    <span>jmp</span> <span>$</span>

<span>; padding to fill the rest of the second sector with zeros.</span>
<span>times</span> <span>1024</span><span>-</span>(<span>$</span><span>-</span><span>$$</span>) db <span>0</span>
</code></pre></div><p>This way I didn’t have to link multiple files and NASM managed the padding of sectors
for me. The code correctly compiled to a single file which was exactly 1024 bytes long -
two entire sectors.</p>
<p>You can also use <code>align 512</code> instead of <code>times 1024-($-$$)</code> to allow
your code to be arbitrarily large. This could be useful if you wanted to program
the second stage of your bootloader in Assembly.</p>
<hr>
<p><strong>Note</strong>: Don’t assume that the registers are initialized with any particular
value. It took me half an hour or so to realize that I didn’t set some register
correctly in such a simple piece of code. IIRC there are only two things you can
be sure of - that the bootloader will be loaded to 0x7c00 and that the <code>dl</code> register
points to the same device the bootloader has been loaded from.</p>
<hr>

<p>After I managed to load the second sector I wanted to replace the Assembly code
with Rust code. To check whether I could execute it I needed to switch to Long Mode.
That’s because I had some problems with compiling Rust code to 32-bit
and I ended up using the <code>x86_64-unknown-none</code> target triple, just like
in Oppermann’s tutorial.</p>
<p>Long Mode adds a new memory model (paging), and enables the use
of 64-bit instructions and registers. Switching to LM requires setting up paging.
I identity-mapped the first 2 MiB of memory which is enough for now. I think it
can be modified later by my Rust program. I read the following guides on paging:</p>
<ul>
<li><a href="https://wiki.osdev.org/Setting_Up_Long_Mode#Setting_up_the_Paging">https://wiki.osdev.org/Setting_Up_Long_Mode#Setting_up_the_Paging</a></li>
<li><a href="https://wiki.osdev.org/Paging#Enabling">https://wiki.osdev.org/Paging#Enabling</a></li>
<li><a href="https://intermezzos.github.io/book/first-edition/transitioning-to-long-mode.html">https://intermezzos.github.io/book/first-edition/transitioning-to-long-mode.html</a></li>
<li><a href="http://ece-research.unm.edu/jimp/310/slides/micro_arch3.html">http://ece-research.unm.edu/jimp/310/slides/micro_arch3.html</a></li>
<li><a href="https://os.phil-opp.com/entering-longmode/">https://os.phil-opp.com/entering-longmode/</a></li>
</ul>
<p>There are also other things you have to do before switching to LM
like checking <code>cpuid</code> instruction support and the highest instruction
op code available.</p>

<p>I figured that to execute Rust code I needed to glue it with
the bootloader to create a single binary. In this step I encountered
a few difficult problems:</p>
<ul>
<li>To work correctly, the bootloader has to be stored in the first 512 bytes of the file.
The last two bytes of this sector have to be 0xaa55.</li>
<li>My Rust code should also be aligned with the sectors and fill up the last sector
entirely. Of course I would fill it with some garbage values but they had to
be there.</li>
<li>The bootloader has to know how long the Rust code is.</li>
<li>Both programs will be loaded at specific locations in the memory
so I have to manage the offsets in addresses.</li>
</ul>
<p>Linker seemed like a tool made for this. I’ve never used a linker before so I just read
<a href="https://ftp.gnu.org/old-gnu/Manuals/ld-2.9.1/html_node/ld_toc.html"><code>ld</code>'s documentation</a>.
Unfortunately, I got a bit confused. I didn’t understand how the <code>.</code> operator
worked in linker scripts. I also got something wrong about the <code>AT()</code> instruction.
You can see the <a href="https://www.reddit.com/r/osdev/comments/hhd7uj/linking_bootloader_with_second_stage/">thread</a>
I started on Reddit.</p>
<p>Eventually I came up with such script:</p>
<pre><code>SECTIONS {
    .boot 0x7c00 : {
        *(.boot.*);
    }

    .hello_rust 0x7e00 : {
        *(.rust.*);
        . = ALIGN(512);
    } = 0xdeadc0de

    SECOND_STAGE_LENGTH = ((. - ADDR(.hello_rust)) &gt;&gt; 9);
}
</code></pre><p>Notice that I put all sections beginning with <code>.boot</code> in the first 512 bytes
and all sections beginning with <code>.rust</code> after 0x7e00. In order to make
it work I have to rename all sections in the ELF file emitted by <code>rustc</code>
so that they all start with a prefix. I do it using <code>objcopy</code>
(in some linkers this option is called <code>--prefix-sections</code>):</p>
<div><pre><code data-lang="bash">objcopy hello_rust.o hello_rust_prefixed.o --prefix-alloc-sections<span>=</span><span>'.rust'</span>
</code></pre></div><p>The there are two tricks in this script. The first one is that I align
the end of the <code>.rust</code> section to the nearest sector boundary with <code>. = ALIGN(512)</code>.
Then I fill the rest with some garbage using <code>= 0xdeadc0de</code>.
The second trick is in the last line. The <code>SECOND_STAGE_LENGTH</code>
variable tells the bootloader how many sectors the second stage occupies.
The size of this section is divided by 512 = 2^9. Since I know
that the end of this section is aligned with the boundaries
of the sectors I can just shift it 9 bits to the right.</p>
<p>These solutions seem a bit hacky. In my understanding the location
of a piece of code in an ELF file (most common target) doesn’t matter. This is not the
case with the bootloader since the code
must be aligned to 512 bytes and there must be a magic number
at the end of the first …</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://micouy.github.io/posts/low-level-pt-1/">https://micouy.github.io/posts/low-level-pt-1/</a></em></p>]]>
            </description>
            <link>https://micouy.github.io/posts/low-level-pt-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23881584</guid>
            <pubDate>Sat, 18 Jul 2020 14:27:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kubectl – Configuration Guide]]>
            </title>
            <description>
<![CDATA[
Score 66 | Comments 25 (<a href="https://news.ycombinator.com/item?id=23881485">thread link</a>) | @lukasbar
<br/>
July 18, 2020 | https://knowledgepill.it/posts/kubernetes-kubectl-client-config/ | <a href="https://web.archive.org/web/*/https://knowledgepill.it/posts/kubernetes-kubectl-client-config/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <p>Kubectl client gives us possibility to configure and switch easily between multiple K8s clusters.</p>
<h2 id="config-files-location-for-kubectl">Config files location for kubectl</h2>
<p>Main location for <code>kubectl</code> config files is <code>$HOME/.kube</code>, by default we have single config file named config:</p>
<div><pre><code data-lang="bash"><span>[</span>node1 ~<span>]</span>$ cd $HOME/.kube
<span>[</span>node1 .kube<span>]</span>$ ls -lah
total 4.0K
drwxr-xr-x <span>1</span> root root   <span>37</span> Mar <span>12</span> 20:48 .
dr-xr-x--- <span>1</span> root root   <span>19</span> Nov <span>29</span> 11:46 ..
drwxr-x--- <span>3</span> root root   <span>23</span> Mar <span>12</span> 20:48 cache
lrwxrwxrwx <span>1</span> root root   <span>26</span> Nov <span>29</span> 11:46 config -&gt; /etc/kubernetes/admin.conf
drwxr-x--- <span>3</span> root root 4.0K Mar <span>12</span> 20:48 http-cache
</code></pre></div><h2 id="multiple-config-files-and-kubeconfig-variable">Multiple config files and KUBECONFIG variable</h2>
<p>We can have multiple config files by setting proper <code>KUBECONFIG</code> shell variable.<br>
For example:</p>
<p><code>export KUBECONFIG=$KUBECONFIG:/root/.kube/additional_config</code></p>
<h2 id="check-config-from-kubectl">Check config from kubectl</h2>
<p>We can check current config(it will be empty because I don’t have anything in additional_config file - we’ll add something later - and this is only file in my <code>KUBECONFIG</code> variable):</p>
<div><pre><code data-lang="yaml">[node1 ~]$ kubectl config view
<span>apiVersion</span>: v1
<span>clusters</span>: []
<span>contexts</span>: []
<span>current-context</span>: <span>""</span>
<span>kind</span>: Config
<span>preferences</span>: {}
<span>users</span>: []
</code></pre></div><p>Or from specific file - let’s see default file:</p>
<div><pre><code data-lang="yaml">[node1 ~]$ kubectl config --kubeconfig=.kube/config view
<span>apiVersion</span>: v1
<span>clusters</span>:
- <span>cluster</span>:
    <span>certificate-authority-data</span>: DATA+OMITTED
    <span>server</span>: https://<span>192.168</span><span>.0</span><span>.38</span>:<span>6443</span>
  <span>name</span>: kubernetes
<span>contexts</span>:
- <span>context</span>:
    <span>cluster</span>: kubernetes
    <span>user</span>: kubernetes-admin
  <span>name</span>: kubernetes-admin@kubernetes
<span>current-context</span>: kubernetes-admin@kubernetes
<span>kind</span>: Config
<span>preferences</span>: {}
<span>users</span>:
- <span>name</span>: kubernetes-admin
  <span>user</span>:
    <span>client-certificate-data</span>: REDACTED
    <span>client-key-data</span>: REDACTED
</code></pre></div><p>If you don’t set <code>KUBECONFIG</code> variable all configuration will be taken from <code>$HOME/.kube/config</code></p>
<h2 id="objects-in-kubectl-config">Objects in kubectl config</h2>
<p><code>kubectl</code> has in its config files following object types:</p>
<ul>
<li>clusters - info about K8s cluster - contain cluster name and connection parameters</li>
<li>users - info about users by which you want connect to K8s clusters</li>
<li>contexts - triple of cluster/user/namespace</li>
</ul>
<h2 id="modifying-config-from-kubectl">Modifying config from kubectl</h2>
<h3 id="add-cluster">Add cluster</h3>
<div><pre><code data-lang="bash"><span>[</span>node1 ~<span>]</span>$ kubectl config --kubeconfig<span>=</span>.kube/additional_config set-cluster dev --server<span>=</span>https://192.168.1.100 --certificate-authority<span>=</span>fake-ca
Cluster <span>"dev"</span> set.
<span>[</span>node1 ~<span>]</span>$ kubectl config --kubeconfig<span>=</span>.kube/additional_config set-cluster prod --server<span>=</span>https://10.1.1.100 --certificate-authority<span>=</span>fake-ca
Cluster <span>"prod"</span> set.
</code></pre></div><h3 id="add-users">Add users</h3>
<div><pre><code data-lang="bash"><span>[</span>node1 ~<span>]</span>$ kubectl config --kubeconfig<span>=</span>.kube/additional_config set-credentials developer --client-certificate<span>=</span>fake-cert-file --client-key<span>=</span>fake-key-seefile
User <span>"developer"</span> set.
<span>[</span>node1 ~<span>]</span>$ kubectl config --kubeconfig<span>=</span>.kube/additional_config set-credentials prod_admin --client-certificate<span>=</span>fake-cert-file --client-key<span>=</span>fake-key-seefile
User <span>"prod_admin"</span> set.
</code></pre></div><h3 id="add-contexts">Add contexts</h3>
<div><pre><code data-lang="bash"><span>[</span>node1 ~<span>]</span>$ kubectl config --kubeconfig<span>=</span>.kube/additional_config set-context simple_app_development --cluster<span>=</span>dev --namespace<span>=</span>simple_app_dev --user<span>=</span>developer
Context <span>"simple_app_development"</span> created.
<span>[</span>node1 ~<span>]</span>$ kubectl config --kubeconfig<span>=</span>.kube/additional_config set-context simple_app_production --cluster<span>=</span>prod --namespace<span>=</span>simple_app_prod --user<span>=</span>prod_admin
Context <span>"simple_app_production"</span> created.
</code></pre></div><h3 id="delete-clusterusercontext-from-config">Delete cluster/user/context from config</h3>
<div><pre><code data-lang="bash">kubectl --kubeconfig<span>=</span>.kube/additional_config config unset users.&lt;name&gt;
kubectl --kubeconfig<span>=</span>.kube/additional_config config unset clusters.&lt;name&gt;
kubectl --kubeconfig<span>=</span>.kube/additional_config config unset contexts.&lt;name&gt;
</code></pre></div><h3 id="sample-config">Sample config</h3>
<div><pre><code data-lang="yaml">[node1 ~]$ kubectl config --kubeconfig=.kube/additional_config view
<span>apiVersion</span>: v1
<span>clusters</span>:
- <span>cluster</span>:
    <span>certificate-authority</span>: /root/fake-ca
    <span>server</span>: https://<span>192.168</span><span>.1</span><span>.100</span>
  <span>name</span>: dev
- <span>cluster</span>:
    <span>certificate-authority</span>: /root/fake-ca
    <span>server</span>: https://<span>10.1</span><span>.1</span><span>.100</span>
  <span>name</span>: prod
<span>contexts</span>:
- <span>context</span>:
    <span>cluster</span>: dev
    <span>namespace</span>: simple_app_dev
    <span>user</span>: developer
  <span>name</span>: simple_app_development
- <span>context</span>:
    <span>cluster</span>: prod
    <span>namespace</span>: simple_app_prod
    <span>user</span>: prod_admin
  <span>name</span>: simple_app_production
<span>current-context</span>: <span>""</span>
<span>kind</span>: Config
<span>preferences</span>: {}
<span>users</span>:
- <span>name</span>: developer
  <span>user</span>:
    <span>client-certificate</span>: /root/fake-cert-file
    <span>client-key</span>: /root/fake-key-seefile
- <span>name</span>: prod_admin
  <span>user</span>:
    <span>client-certificate</span>: /root/fake-cert-file
    <span>client-key</span>: /root/fake-key-seefile
</code></pre></div><h3 id="changing-context-to-work-with">Changing context to work with</h3>
<p>To get list of contexts(no need for <code>--kubeconfig</code> because we have our <code>additional_config</code> added to <code>KUBECONFIG</code> variable):</p>
<div><pre><code data-lang="bash"><span>[</span>node1 ~<span>]</span>$ kubectl config get-contexts
CURRENT   NAME                     CLUSTER   AUTHINFO     NAMESPACE
          simple_app_development   dev       developer    simple_app_dev
          simple_app_production    prod      prod_admin   simple_app_prod
</code></pre></div><p>To set context:</p>
<div><pre><code data-lang="bash"><span>[</span>node1 ~<span>]</span>$ kubectl config use-context simple_app_development
Switched to context <span>"simple_app_development"</span>.
</code></pre></div><p>To get current context:</p>
<div><pre><code data-lang="bash"><span>[</span>node1 ~<span>]</span>$ kubectl config current-context
simple_app_development
</code></pre></div><hr>
<h3 id="for-those-who-want-to-know-even-more-worth-to-read">For those who want to know even more… Worth to read!</h3>
<p><a href="https://gardener.cloud/documentation/guides/client_tools/bash_kubeconfig/">Kubeconfig context as bash prompt - Georgi from Gardener</a> - shell tricks and Windows CLI aproach</p>
<hr>

</div></div>]]>
            </description>
            <link>https://knowledgepill.it/posts/kubernetes-kubectl-client-config/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23881485</guid>
            <pubDate>Sat, 18 Jul 2020 14:10:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Trouser Pockets]]>
            </title>
            <description>
<![CDATA[
Score 665 | Comments 338 (<a href="https://news.ycombinator.com/item?id=23881220">thread link</a>) | @diiq
<br/>
July 18, 2020 | https://sambleckley.com/writing/pockets.html | <a href="https://web.archive.org/web/*/https://sambleckley.com/writing/pockets.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h3 id="tldr">TL;DR</h3> <p>The clothing industry rarely creates dramatically new patterns. It is more lucrative to make small, easy-to-manufacture changes that always use the same basic pattern.</p> <p>There is therefore lots of room to innovate clothing that is more appropriate for contemporary problems, because basic clothing patterns haven’t changed in decades.</p> <p>I made some trousers with unusual pockets, and I think they’re good.</p> <h3 id="pockets-are-either-ugly-or-useless">Pockets are either ugly or useless</h3> <p>Pockets in tight jeans look bad. Putting a modern slab phone, a wallet, and keys into a pair of skinny jeans will leave even the most fashionable figure looking looking like they’re wearing batman’s utility belt as underwear. Even empty, in tight pants a large pocket bag can show through.</p> <p>The alternative, as many women know from first-hand experience, is a pocket too small to put anything in.</p> <p>A wallet in the back pocket can cause back pain and bad posture.</p> <p>Many of us spend most of our time sitting, but all four traditional pockets are totally inaccessible in that position. So we take out our phone, just in case, before we sit down at the restaurant — guaranteeing a distraction.</p> <p>Aesthetics, storage, and access: these are user needs that are currently poorly fulfilled — and that means things are ripe for innovation.</p> <h3 id="a-brief-history">A brief history</h3> <p>If the space is so ripe, why has there been no pocket innovation recently?</p> <p>Women used to have pockets. That “used to” has to count back 150 or even 200 years, and those pockets were often a separate garment, either worn underneath and accessed through a slit in the dress, or worn around the hips overtop, rather than built into the dress directly — but regardless, “it has pockets!” as a joyous surprise is a modern invention. (Men’s pockets were also separate pouches if you go back far enough; but going back the same 150-200 years, they lived in the waistcoat and the mandatory jacket; if breeches had pockets they were behind the falls and so, I suspect, not used as much in public.)</p> <p>The 1880’s brought the 1940s brought the slow arrival of mass production to clothing — not of the textiles, which started much earlier, but of actual clothes. Before this era, clothes were made either at home, or they were made one at a time. (In a quiet resonance with today, this was done in part by women who worked almost entirely from home, only travelling to the workplace to pick up new work and drop off what had been completed).</p> <p>In retrospect, fashions changed mostly decade by decade rather than year by year, but they changed dramatically. The fashionable silhouette of the 1860s looks nothing like the 1880s, or the 1910’s — so different, in fact, that for women the foundation garments were completely unrelated entities: the crinoline of the 1860s is nothing like the bustle of the 1880s. A person who can cut and sew can sew an incredibly wide range of different things; why not play around?</p> <p>But with the advent of mass production in clothes factories, the whole layout of the factory floor was based on specific pattern piecing. Each station makes only a few operations on each garment, and garments flow from one station to the next. To completely change the <em>construction</em> of a garment means a radical overhaul of the whole assembly line.</p> <p>But to simply change the garment’s <em>proportions</em> is <em>easy</em>.</p> <p>And so we live in a world where every spring the morning talk shows invite someone on to say “this year, [culottes, boot-cuts, skinny jeans, flares, cuffs, boyfriend jeans, high waists, low-rise, acid-wash, raw denim] are coming back into fashion, so keep your eye out!” — but the trousers are made from the same basic pieces, constructed in the same ways, with only the measurements changing. They get longer or shorter, looser or tighter, and change color, but they’re not fundamentally <em>different</em>.</p> <p>It’s like a lack-luster procedural generation system. Sure, there are technically millions of possibilities, but somehow you still end up bored after seeing the first 5 or 6.</p> <p>Probably not coincidentally, the advent of mass production is also when women’s silhouettes turned slim, and when all those foundation garments mostly disappeared. Designs that banish structure from the garment and rely entirely on the body beneath are much easier and cheaper to manufacture.</p> <p>And when silhouettes turned slim, women lost pockets. The more body-hugging the clothing, the less room for pockets — or, rather, the more the pocket contents will show unflatteringly. (And as we know, it would be anathema for a women to show unflattering lump for something as silly as practicality, function, or utility.)</p> <p>And even as womenswear adopted men’s workwear styles, women got jeans but not the pockets to go with them. Spandex made it even easier to make mass-produced clothes “fit”, and fit tighter. The unsightly-lump factor wasn’t going away.</p> <p>Even more recently, menswear has returned to an incredibly slim silhouette. Guys in skinny jeans should, by this logic, not have pockets either. But they do.</p> <p>Women get no practicality and men get no grace.</p> <h3 id="what-if-we-redesigned-the-pocket-from-scratch">What if we redesigned the pocket from scratch?</h3> <p>Let’s design a trouser pocket! This process is going to land somewhere between UX and industrial design. I am, sadly, not in charge of a clothes factory, so I am not concerned with the problems of mass-production, but material properties and the construction process do still matter; but I am maybe more willing to make manufacturing sacrifices for usefulness than most industrial designers are able to be.</p> <h3 id="what-do-people-use-pockets-for">What do people use pockets for?</h3> <ul> <li>Storing things; most often phone, then keys, wallet or money-clip, and other small items. At the moment, a mask.</li> <li><em>Verifying</em> stored objects — the hip-slapping dance of making sure you have everything before walking out the door.</li> <li>They must be secure while standing, sitting, running for the bus, etc</li> <li>Things, especially phone, need to go in and out of storage frequently, almost unconsciously.</li> <li>Access to phone while seated in a restaurant; to keys and license while in car</li> <li>Aesthetically, we want a clean, graceful line from hip to ankle even while holding things.</li> </ul> <p>An initial solution can be based on just three questions:</p> <ul> <li>Where can your hands reach?</li> <li>Where is there extra space to put things?</li> <li>Where is there enough support to prevent items swinging around uncomfortably?</li> </ul> <p>These questions form a physical venn diagram, pointing at a pretty small area for investigation:</p> <p><img src="https://sambleckley.com/assets/images/pocket_venn.png" alt="The human body with overlapping regions of reach, space, and support."></p> <p>You can see that current pockets are located completely outside the area where there is potentially space; the hips and butt of modern pants, for both women and men, are closely fitted. If there’s any ease, it starts just above the knees.</p> <p>Conveniently, the point where the vastus lateralis starts to curve back in towards the knee, creating space, is also right around the lowest point your arms can reach without bending over, giving us a well-defined target.</p> <p>So I made a pair of trousers with no pockets at the waist, and a pair of welt pockets at the side seams, right at that point.</p> <p><img src="https://sambleckley.com/assets/images/pants1.jpg" alt="First pair of pants."></p> <h3 id="notes-from-user-testing">Notes from user testing:</h3> <ul> <li>A pocket needs to be big enough for a whole hand, not just phone, to allow for fishing out small items from the very bottom of the pocket-bag.</li> <li>The pocket bag slips down and back if it’s full and the wearer sits down. This is uncomfortable and</li> <li>The pocket mustn’t allow a slick round phone to fall out when sitting, especially when, e.g. jiggling a leg.</li> </ul> <h3 id="revisions">Revisions</h3> <p>Luckily, each of these notes point at simple revision, rather than the need to start again.</p> <ul> <li>Make the pockets wider.</li> <li>Anchor the bottom of the pocket bag to the side seam.</li> <li>Angle the opening so it’s higher in the back — this both makes it easier to slip a phone into the pocket, and makes the pocket “deeper” on the bottom side when sitting or crouching.</li> </ul> <p><img src="https://sambleckley.com/assets/images/pants2.jpg" alt="Second pair of pants."></p> <h3 id="outcome">Outcome</h3> <p>These are great. I completely forget my phone and wallet are there — they don’t restrict my movement, they’re completely invisible, and yet they’re easy to access while standing or sitting. There’s no temptation to slouch around with my hands stuffed in my pockets. They’re so straightforwardly better for my needs that I’m now frustrated when my new-pocket pants are dirty and I have to wear trousers with pockets that are just SO twentieth-century. I immediately made a pair of jeans in this pattern, too.</p> <p>Further revision is possible, of course; but while it will be easy to refine this design to suit my personal body and needs more precisely, there’s only so much refinement possible while remaining suitable for a wide range of body types. If you wanted to mass-produce a pocket like this, you’d want to use something like Dreyfuss’ Humanscale data to make sure the placement and size is appropriate for the widest range of people. Luckily, you’d have <em>some</em> additional information in the sizing of the <em>rest</em> of the pants.</p> <h3 id="appendix-sam-have-you-simply-invented-cargo-pants">Appendix: Sam, have you simply invented cargo pants?</h3> <p>No. Cargo pants solve different problems for different people.</p> <p>If cargo pants are appropriate for your daily life, you definitely don’t want or need my side-seam welt pockets; and vice-versa. Cargo pants aren’t office-wear; these dress pants aren’t combat-wear.</p> </div></div>]]>
            </description>
            <link>https://sambleckley.com/writing/pockets.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23881220</guid>
            <pubDate>Sat, 18 Jul 2020 13:16:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Ownership Economy: Crypto and the Next Frontier of Consumer Software]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23880950">thread link</a>) | @jger15
<br/>
July 18, 2020 | https://variant.fund/the-ownership-economy-crypto-and-consumer-software/ | <a href="https://web.archive.org/web/*/https://variant.fund/the-ownership-economy-crypto-and-consumer-software/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<p>One of the most stunning things about the technology we consume everyday is the degree to which it is built, operated and even funded by its users.</p>



<div><p>The device you’re using to read this post, the software that’s displaying it, the server hosting this content and so much else on the internet are built with open-source code contributed by a global community of developers. Platforms like Wikipedia, YouTube, Twitter, Facebook, and Airbnb all operate around content and products sourced from individuals, not corporations. And increasingly marketplaces like Kickstarter, Patreon, Substack, and many other new <a href="https://a16z.com/2019/10/08/passion-economy/" target="_blank" rel="noopener">Passion Economy</a> platforms enable users to directly fund the products, information, and services that they consume.</p><p>As user participation becomes evermore mainstream and complex, the next step is platforms that are not only built, operated, and funded by users—but <strong><em>owned</em></strong> by users too.</p></div>



<div><p>Ownership, via employee stock option plans, has been a powerful tool for incentivizing talented people to dedicate their skills to building startups in Silicon Valley. While this model has been extremely successful, it hasn’t been accessible to all, constrained by geography and legacy financial infrastructure, among other factors. One result is that the economic interests of the biggest internet platforms are concentrated and often <a href="https://www.wired.com/story/how-blockchain-can-wrest-the-internet-from-corporations/" target="_blank" rel="noopener">poorly aligned with their most valuable contributors</a>, their users. Now, new technologies are shifting work and value distribution to be accessible online, resulting in a new generation of platforms that thrive on contributions from a permissionless and global talent pool.</p><p>Ownership is a powerful motivator for users to contribute to products in deeper ways, be it with ideas, computing resources, code, or community building. This more <a href="https://jessewalden.com/past-present-future-from-co-ops-to-cryptonetworks/" target="_blank" rel="noopener">cooperative economic model</a> helps ensure better alignment with users over time, resulting in platforms that can be larger, more resilient, and more innovative.&nbsp; <strong>This is the Ownership Economy, and beyond being a positive social endeavor, the platforms building it are able to leverage the strongest form of market incentives to grow network effects.</strong></p><p>While most prevalent in crypto today, The Ownership Economy is expanding to other areas in tech. To understand why, we can look to recent history and observe how protocol innovations often expose disruptive new models that, when productized, influence broader trends and go on to impact billions.</p></div>



<h4>Identifying Disruptive Models Through Protocol Innovations</h4>



<p>The history of protocol adoption fits a pattern: first, early-adopters use new protocols to do things that were impossible before the new technology empowered them to do so. Very often, this new behavior involves <a href="https://medium.com/@simonhmorris/if-youre-not-breaking-rules-you-re-doing-it-wrong-bittorrent-lessons-for-crypto-2-of-4-72c68227fe69" target="_blank" rel="noopener">breaking the rules</a>. Then, a winning strategy for founders is to build products that make these new models more accessible to a wider audience.&nbsp;</p>



<div><p>Consider the early web protocols: IP, HTTP, standards like HTML, then RSS. At first, popular websites used these protocols to create carbon-copies of physical analogues, like newspaper cover pages or classified ads. But as internet adoption went mainstream, users began publishing their own content: independent blogs, podcasts, newsletters and forums paved the way for the user-generated content platforms that dominate publishing today.</p><p>Another example is BitTorrent, <strong>a protocol innovation of packet distribution, but a disruption that underpinned the streaming revolution</strong>. When BitTorrent first became popular, Netflix was still mailing DVDs in the mail. Meanwhile, the peer-to-peer technology enabled consumers to access music, movies, software, and video games instantaneously, as if the files were already on their hard drives. By 2004, BitTorrent comprised one-third of all internet traffic.</p><p><strong>Consumers’ passion for torrenting signaled that they wanted to access the world’s media at their fingertips,</strong> but for many, BitTorrent wasn’t a user-friendly experience; trackers were moving targets, cluttered and difficult to navigate.&nbsp;</p></div>



<p>One person who saw an opportunity through the noise was Daniel Ek, founder of Spotify. As CEO of <a href="https://en.wikipedia.org/wiki/%CE%9CTorrent" target="_blank" rel="noopener">µTorrent</a>, one of the most popular BitTorrent clients, Ek understood that piracy wasn’t about stealing—it was about access. The winning formula was providing access to the world’s music in a clean, well-designed product.</p>



<p>Today, crypto tokens are the latest protocol innovation to expose a disruptive new model. Just as BitTorrent allowed us to exchange packets of information instantly and without an intermediary, crypto tokens let us distribute value in the same way.<strong> <p>The protocol innovation of tokens is akin to <em>packets for value</em>, but the disruption is in the way new software platforms can be built and gain adoption.</p></strong> <span>The breakthrough of early crypto networks is a new model for market-driven networks, where users build, operate and </span><b><i>own</i></b><span> a piece of the products and services that they use everyday.</span></p>



<h4>The Ownership Economy, Pioneered by Crypto</h4>



<div><p><strong>The idea of user ownership is at the core of the success of Bitcoin and Ethereum, the first user-owned and operated networks at scale.</strong> Bitcoin arrived in 2009, the year that marked a rapid acceleration of economic inequality and the role of the internet in people’s daily lives. Bitcoin promised a new economic means to participate in modern technology history, simply by running open-source software on your computer. Rather than needing to live in a specific place and pursue a specific career in order to reap the benefits of the new economy, anyone with an internet connection could participate by “mining” or securing the network. In return, they earned newly minted Bitcoin, an ownership stake in the network itself.</p><p>Ethereum’s 2015 launch expanded the type of computation possible on blockchain networks, enabling a broader range of applications and allowing developers to experiment with new ways of expressing ownership in code. The best-designed Ethereum-based applications leverage a <a href="https://jessewalden.com/cryptos-business-model-is-familiar-what-isnt-is-who-benefits-2/" target="_blank" rel="noopener">business model similar to traditional Web 2.0 marketplaces</a>, but encode them in autonomous “smart contracts” run by Ethereum’s network of miners. This means these applications have no central operator. <strong>Rather than a platform’s inner circle of founders and investors taking home the value, users are able to earn the majority of value generated from their collective contributions.&nbsp;</strong></p></div>



<p>Needless to say, one of the most challenging problems any startup or new technology faces is adoption, especially where network effects are necessary—and even more-so when competing against the existing network effects of today’s dominant platforms. As the early Bitcoin and Ethereum communities came to realize, ownership is a tool to help surmount this problem. Those early communities were largely composed of technologists, developers, and enthusiasts who were naturally among the first to recognize the power of tokens as direct economic incentives. But today, founders are bringing the idea of ownership —&nbsp; or at least, better economic alignment between platforms and participants — to new verticals in tech, from developer infrastructure, to financial services, and from consumer marketplaces to social.</p>



<h4>How next-generation platforms are driving an ownership economy</h4>



<p>The ownership economy doesn’t always mean a literal distribution of tokens, stock options, or equity. It also doesn’t necessarily mean that an application or service is entirely built on a blockchain. Rather, it means that ownership —&nbsp;which may manifest in the form of novel economic rewards, platform governance, or new forms of social capital —&nbsp;can be a new keystone of user experiences, with plenty of design space to explore.</p>



<p>Some examples: In payments, <a href="http://celo.org/" target="_blank" rel="noopener">Celo</a> is making digital dollars and financial applications accessible to anyone with an internet connection via a blockchain network that, like Bitcoin, is entirely user owned and operated. In finance, startups like <a href="https://www.binance.com/en/bnb" target="_blank" rel="noopener">Binance</a> and <a href="https://numer.ai/" target="_blank" rel="noopener">Numerai</a> have leveraged tokens to distribute revenue from the platform directly to their users, fueling brand loyalty and growth. <a href="http://compound.finance/" target="_blank" rel="noopener">Compound</a>, a money market, recently completed its journey of <a href="https://jessewalden.com/progressive-decentralization-a-playbook-for-building-crypto-applications/" target="_blank" rel="noopener">progressive decentralization</a> to become <a href="https://medium.com/compound-finance/compound-community-ownership-ee0ed1252cc3?source=collection_home---4------0-----------------------" target="_blank" rel="noopener">a community owned</a> marketplace for borrowing and lending.</p>



<p><a href="http://uniswap.io/" target="_blank" rel="noopener">Uniswap</a>, a crypto exchange, has a business model similar to Coinbase or Binance in that it imposes a fee on transactions. But rather than the company capturing that fee, it’s instead distributed to the market-making traders that provide liquidity and make the product useful. Since Uniswap is open source and user-owned, third-party developers can have confidence building on the platform and a rich ecosystem of integrations has grown around the project.</p>



<p>In social, Reddit recently announced that 300 million users will have access to tokenized <a href="https://www.reddit.com/community-points/?utm_source=reddit&amp;utm_medium=usertext&amp;utm_name=FortNiteBR&amp;utm_content=t3_gj8tm1" target="_blank" rel="noopener">community currencies</a> through their mobile app. The platform will reward participants in the <a href="https://www.reddit.com/r/FortNiteBR/comments/gj8tm1/introducing_rfortnitebr_bricks/" target="_blank" rel="noopener">r/FortniteBR</a> and <a href="https://www.google.com/search?q=r%2FCryptocurrency+moons&amp;oq=r%2FCryptocurrency+moons&amp;aqs=chrome..69i57j0j69i58.880j0j7&amp;sourceid=chrome&amp;ie=UTF-8" target="_blank" rel="noopener">r/Cryptocurrency</a> subreddits with tokens that can be used to pay for membership, tipping, and badges in the Reddit app, giving them ownership over the economy of each subreddit.&nbsp;&nbsp;</p>



<p>Consumer marketplace <a href="http://withfoundation.com/" target="_blank" rel="noopener">Foundation</a> is transforming the Kickstarter model by allowing creators to tokenize their projects in a marketplace where tokens can be bought, sold or redeemed for goods or services. This programmable, digital representation of ownership unlocks new revenue streams that gives buyers and creators access to new value streams in secondary markets.&nbsp;</p>



<p>Global talent marketplace <a href="http://www.usebraintrust.com/" target="_blank" rel="noopener">Braintrust</a> connects top tech talent with large companies looking to hire them.&nbsp; Their marketplace transacts in USD but uses an Ethereum-based token as its core incentive and governance system to distribute value to contributors.&nbsp;&nbsp;</p>
<figure></figure>



<p>In consumer products, the house-of-brands startup <a href="https://www.arfa.co/collective" target="_blank" rel="noopener">Arfa</a> is rewarding customers who contribute to product development—<a href="https://www.arfa.co/collective" target="_blank" rel="noopener">The Arfa Collective</a>—with a 5 percent share of company profits. They hope these direct economic incentives can help build a more loyal customer base with lower marketing costs over time.&nbsp;</p>



<p>Other platforms like <a href="https://hackernoon.com/birds-new-platform-program-and-the-rise-of-the-business-in-a-box-899f7ac58abb" target="_blank" rel="noopener">Bird</a> and <a href="https://dumpling.us/" target="_blank" rel="noopener">Dumpling</a> are putting …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://variant.fund/the-ownership-economy-crypto-and-consumer-software/">https://variant.fund/the-ownership-economy-crypto-and-consumer-software/</a></em></p>]]>
            </description>
            <link>https://variant.fund/the-ownership-economy-crypto-and-consumer-software/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23880950</guid>
            <pubDate>Sat, 18 Jul 2020 12:28:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Logged out]]>
            </title>
            <description>
<![CDATA[
Score 46 | Comments 44 (<a href="https://news.ycombinator.com/item?id=23880938">thread link</a>) | @patwalls
<br/>
July 18, 2020 | https://patwalls.com/logged-out | <a href="https://web.archive.org/web/*/https://patwalls.com/logged-out">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://patwalls.com/logged-out</link>
            <guid isPermaLink="false">hacker-news-small-sites-23880938</guid>
            <pubDate>Sat, 18 Jul 2020 12:26:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Computer architecture and being a good programmer?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23880681">thread link</a>) | @edvinleander
<br/>
July 18, 2020 | http://edvinleander.com/2020/07/18/do-i-have-to-know-computer-architecture-to-be-a-good-programmer/ | <a href="https://web.archive.org/web/*/http://edvinleander.com/2020/07/18/do-i-have-to-know-computer-architecture-to-be-a-good-programmer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-101">

	

	
	<div>
		
<p>When I started my first semester in university the first course, we had was called <em>Elementary Computer Architecture. </em>As computer-engineers we had to know the elementary functions of the CPU (Central Processing Unit) and memory. One could argue then that as a programmer you <strong>must</strong> know low level computer architecture.</p>



<p>When I started to program in my early teen days, I did not know anything about computers. I just knew that a computer had a processor, graphics card and memory. And an on-button. As I developed my skills, the more I learned about computers. I started to examine the theory behind the code. Instead of just treating the computer as a black box, I began to learn the fundamentals of computers.</p>



<p>You could argue that learning the very basics of computers is not necessary for the common programmer. I myself proved that you could learn to program without knowing the basics.</p>



<h5>It is a difference between being able to program and to be able to program…</h5>



<p>What do I mean with this cryptical words? In my late teen’s I began to work on my biggest project to date, a compiler. Before I started building, I had encountered <em>cache misses </em>and <em>assembly optimization </em>but did not give it much thought. My only goal with creating my own programming language was to learn about <strong>everything.</strong></p>



<p>I recently wrote an article about copy-pasting and using unnecessary libraries when you could do it yourself. Without going too much into technical stuff, there is a common “library” or “backend” that you could use. I decided to learn, so I did not use the framework.</p>



<p>What I want to address is that, learning about compilers I began to optimize my regular code, I became more aware of my code. There is a difference between being able to program and be able to program. With this I mean that you could be a programmer, a good programmer, without being able to optimize your structures and think about pointer arithmetic and assembly optimization. But if you know how the compiler that compiles down to machine code, you can optimize and become a more aware programmer.</p>



<h5>Languages like Python are so high level that you do not have to care about low-level programming</h5>



<p>More high-level languages like Python does not give you the opportunity with low-level optimizations like <em>Assembly </em>or <em>C </em>gives you. If you really cannot do anything low-level then why do you have to learn how computers know? You can do just about anything in Python without ever worrying about compiler optimizations.</p>



<h5>Some final words</h5>



<p>Some may say, also I, that you do not have to know about the internal data bus of the processor to know how to code. Is it helpful to learn about cache-misses? Yes, if you want to learn high performance parallel computing, it is a must. But if you are comfortable with your language or have a perfect job, do not worry to much. But I can promise that you will improve as a programmer and engineer if you know computer architecture. So, my final words will be that you really do not have to know much about internal compiler stuff if you work in high level languages. But if you are interested in high speed computing then knowledge of computer architecture is a must!</p>



<p>Before parting I want to <strong>know what you think</strong>. Write in the comment section your opinion. <strong>Should you care about architecture or not</strong>? And do not forget to <strong>like </strong>and <strong>subscribe</strong> for more content!</p>



	<div data-blog-id="180252010">
		<div>
			<form aria-describedby="wp-block-jetpack-mailchimp_consent-text">
				
												

				<p id="wp-block-jetpack-mailchimp_consent-text">
					By clicking submit, you agree to share your email address with the site owner and Mailchimp to receive marketing, updates, and other emails from the site owner. Use the unsubscribe link in those emails to opt out at any time.				</p>

				
			</form>
			
				<p>
					Processing…				</p>
				<p>
					Success! You're on the list.				</p>
				<p>
					Whoops! There was an error and we couldn't process your subscription. Please reload the page and try again.				</p>

					</div>
	</div>
	


<p>Have a nice day!</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article><!-- #post-${ID} -->

	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
<!-- #comments -->

		</main><!-- #main -->
	</section><!-- #primary -->


	</div></div>]]>
            </description>
            <link>http://edvinleander.com/2020/07/18/do-i-have-to-know-computer-architecture-to-be-a-good-programmer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23880681</guid>
            <pubDate>Sat, 18 Jul 2020 11:34:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[EU Parliament says sensitive data of 1,200 officials left exposed on web]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23880659">thread link</a>) | @based2
<br/>
July 18, 2020 | https://www.politico.eu/article/eu-parliament-says-sensitive-data-of-1200-officials-left-exposed-on-web/ | <a href="https://web.archive.org/web/*/https://www.politico.eu/article/eu-parliament-says-sensitive-data-of-1200-officials-left-exposed-on-web/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
							<div>
            <figure><div><div><p><img src="https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/05/20160412_202400_HDR-714x467.jpg"></p></div></div><figcaption><p>The European Parliament has been hit by a "major data breach" | European Union</p></figcaption></figure>        <div>
        <header>
                        
                        <p>The information includes sensitive information and encrypted passwords. </p>
                    </header>
                
<!--/.meta-->
    </div><!--/.summary-->
</div><!--/.story-intro-->

							
							
							<p>Information about more than a thousand staff and members of the European Parliament has been exposed in what a key lawmaker called a "major data breach."</p>
<p>The data includes 1,200 accounts of elected officials and staff, along with another 15,000 other accounts of EU affairs professionals, Marcel Kolaja, the Parliament's vice president for IT policy, confirmed to POLITICO on Saturday.</p>
<p>The exposed information — “a huge amount of data” — includes sensitive information and encrypted passwords, he added.</p>
<p>It comes from a system that had been run under the European Parliament’s official "europarl.eu" domain, Kolaja said, but the data had not been hosted by the institution itself.</p>
<p>“The system in question is a system run by one particular political group and it was data by that political group," Kolaja said, "and they were immediately made aware of that incident.”</p>
<blockquote><p>“This data has been online for some time now” <em>— Yash Kadakia, founder of Indian cybersecurity company Shadowmap</em></p></blockquote>
<p>Kolaja declined to say which political group was affected. But information seen by POLITICO about the affected server suggested that it is the European People’s Party (EPP), the largest political faction in the Parliament.</p>
<p>EPP group spokesperson Pedro López de Pablo confirmed in an email that a database containing email addresses and passwords had been exposed.</p>
<p>However, he added, that database was outdated and only contained information "used by the people who [were] subscribed to our old website back in 2018." That website is no longer in use after the group launched a new website in January 2019, López de Pablo said.</p>
<p>Both the EPP's "servers and the current database have not been exposed," López de Pablo wrote.</p>
<p>"Even in the case that the people who were subscribed to our website in 2018 used the same password that they had in their e-mails at that time, nothing can happen to them now because in the Parliament the system forces you to change completely your password every three months," he added.</p>
<p>He added that the EPP was "currently verifying the list of emails to inform all the people, following [European data protection] rules."</p>
<h3>'This is serious'</h3>
<p>The security breach was <a href="https://pro.politico.eu/news/119283" target="_blank">first revealed Friday by Indian cybersecurity company Shadowmap</a>, whose founder Yash Kadakia told POLITICO that it had discovered files containing data like passwords, job descriptions and other personal information via an internet portal that’s part of the Parliament’s domain and used by its officials.</p>
<p>The unprotected data also includes information of thousands of people with links to political parties and institutions, including members of EU agencies and authorities like law enforcement agency Europol, the European Data Protection Supervisor, border agency Frontex and others, Kadakia said.</p>
<p>A spokesperson of the European Commission, the bloc’s executive body, said in an email on Saturday that “a large number of users [were] affected, including some users from the Commission."</p>
<p>Kadakia flagged the issue to the Parliament’s Computer Emergency Response Team on Friday. His company found the data when scanning the internet for unprotected and leaked datasets, which it does as part of its cybersecurity services. “We end up picking up data that is lost to other people sometimes,” Kadakia said.</p>
<p>The risk, he said, was that the data had been found by hackers and could be used to access other websites and sensitive services.</p>
<p>“This data has been online for some time now,” he said.</p>
<p>“I’m assuming some subset of members of the European Parliament have used the same passwords,” he said. “If you’re able to access a whole bunch of systems, a whole bunch of information, as an attacker you can really get in there.”</p>
<div id="attachment_1366554"><p><img aria-describedby="caption-attachment-1366554" src="https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/05/20200213_EP-100117A_FMA_015-714x472.jpg" alt="" width="714" height="472" srcset="https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/05/20200213_EP-100117A_FMA_015-714x472.jpg 714w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/05/20200213_EP-100117A_FMA_015-300x198.jpg 300w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/05/20200213_EP-100117A_FMA_015-1024x677.jpg 1024w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/05/20200213_EP-100117A_FMA_015-768x508.jpg 768w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/05/20200213_EP-100117A_FMA_015-1536x1016.jpg 1536w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/05/20200213_EP-100117A_FMA_015-2048x1355.jpg 2048w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/05/20200213_EP-100117A_FMA_015-1160x767.jpg 1160w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/05/20200213_EP-100117A_FMA_015-380x251.jpg 380w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/05/20200213_EP-100117A_FMA_015-172x114.jpg 172w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/05/20200213_EP-100117A_FMA_015-90x60.jpg 90w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/05/20200213_EP-100117A_FMA_015-104x69.jpg 104w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/05/20200213_EP-100117A_FMA_015-200x132.jpg 200w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/05/20200213_EP-100117A_FMA_015-393x260.jpg 393w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/05/20200213_EP-100117A_FMA_015-54x36.jpg 54w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/05/20200213_EP-100117A_FMA_015-1088x720.jpg 1088w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/05/20200213_EP-100117A_FMA_015-333x220.jpg 333w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/05/20200213_EP-100117A_FMA_015-1120x741.jpg 1120w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/05/20200213_EP-100117A_FMA_015-600x397.jpg 600w" sizes="(max-width: 714px) 100vw, 714px"></p><p id="caption-attachment-1366554">Marcel Kolaja, the Parliament's vice president for IT policy | European Union</p></div>
<p>By noon on Saturday, all affected data appeared to have been taken offline.</p>
<p>Parliament Vice President Kolaja, a trained software engineer, warned, "This is serious."</p>
<p>Although the passwords leaked in the data breach had been encrypted using a technique known as “hashing,” which means that intruders cannot instantly use them to access other information, “with further cryptoanalysis of the data, it could definitely be abused,” he added.</p>
<p>“Given that we’re speaking about tons of data, it definitely now needs to be investigated if there was any breach of law,” he said.</p>

														<!--/.story-supplement-->
							
							
							<!--/.story-supplement-->

						</div></div>]]>
            </description>
            <link>https://www.politico.eu/article/eu-parliament-says-sensitive-data-of-1200-officials-left-exposed-on-web/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23880659</guid>
            <pubDate>Sat, 18 Jul 2020 11:29:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tricks with Pseudorandom Number Generators]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23879837">thread link</a>) | @todsacerdoti
<br/>
July 18, 2020 | https://theartofmachinery.com/2020/07/18/prng_tricks.html | <a href="https://web.archive.org/web/*/https://theartofmachinery.com/2020/07/18/prng_tricks.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
      <p>Pseudorandom number generators (PRNGs) are often treated like a compromise: their output isn’t as good as real
      random number generators, but they’re cheap and easy to use on computer hardware. But a special feature of PRNGs
      is that they’re <em>reproducible</em> sources of random-looking data:</p>
      <figure>
        <pre><code data-lang="d"><span>import</span> <span>std</span><span>.</span><span>random</span><span>;</span>
<span>import</span> <span>std</span><span>.</span><span>stdio</span><span>;</span>

<span>void</span> <span>main</span><span>()</span>
<span>{</span>
    <span>// Seed a PRNG and generate 10 pseudo-random numbers</span>
    <span>auto</span> <span>rng</span> <span>=</span> <span>Random</span><span>(</span><span>42</span><span>);</span>
    <span>foreach</span> <span>(</span><span>_</span><span>;</span> <span>0..10</span><span>)</span> <span>write</span><span>(</span><span>uniform</span><span>(</span><span>0</span><span>,</span> <span>10</span><span>,</span> <span>rng</span><span>),</span> <span>' '</span><span>);</span>
    <span>writeln</span><span>();</span>
    <span>// Reset the PRNG, and the same sequence is generated again</span>
    <span>rng</span> <span>=</span> <span>Random</span><span>(</span><span>42</span><span>);</span>
    <span>foreach</span> <span>(</span><span>_</span><span>;</span> <span>0..10</span><span>)</span> <span>write</span><span>(</span><span>uniform</span><span>(</span><span>0</span><span>,</span> <span>10</span><span>,</span> <span>rng</span><span>),</span> <span>' '</span><span>);</span>
    <span>writeln</span><span>();</span>

    <span>// Output:</span>
    <span>// 2 7 6 4 6 5 0 4 0 3</span>
    <span>// 2 7 6 4 6 5 0 4 0 3</span>
<span>}</span></code></pre>
      </figure>
      <p>This simple fact enables a few neat tricks.</p><p>A couple of famous examples come from the gaming industry. The classic example is the space trading game
      Elite, which was originally written for 8b BBC Micros in the early 80s. It was a totally revolutionary game, but
      just one thing that amazed fans was its complex universe of thousands of star systems. That was something you
      just didn’t normally get in games written for machines with kilobytes of RAM total. The trick was to generate the
      universe with a PRNG seeded with a small value. There was no need to store the universe in memory because the
      game could regenerate each star system on demand, repeatedly and deterministically.</p>
      <p>PRNGs are now widely exploited for recording games for replays. You don’t need to record every frame of the
      game world if you can just record the PRNG seed and all the player actions. (Like most things in software,
      <a href="https://technology.riotgames.com/news/determinism-league-legends-introduction">actually implementing
      that can be surprisingly challenging</a>.)</p>
      <h2 id="random-mappings">Random mappings</h2>
      <p>In machine learning, you often need a mapping from things to highly dimensional random unit vectors (random
      vectors of length 1). Let’s get more specific and say you’re processing documents for topic/sentiment analysis or
      similarity. In this case you’ll generate a random vector for each word in the dictionary. Then you can create a
      vector for each document by adding up the vectors for each word in it (with some kind of weighting scheme, in
      practice). Similar documents will end up with similar vectors, and you can use linear algebra tricks to uncover
      deeper patterns (read about <a href="https://en.wikipedia.org/wiki/Latent_semantic_analysis">latent semantic
      analysis</a> if you’re interested).</p>
      <p>An obvious way to get a mapping between words and random vectors is to just initially generate a vector for
      each word, and create a hash table for looking them up later. Another way is to generate the random vectors on
      demand using a PRNG seeded by a hash of the word. Here’s a toy example:</p>
      <figure>
        <pre><code data-lang="d"><span>/+ dub.sdl:
    name "prngvecdemo"
    dependency "mir-random" version="~&gt;2.2.14"
+/</span>
<span>// Demo of mapping words to random vectors with PRNGs</span>
<span>// Run me with "dub prngvecdemo.d"</span>

<span>import</span> <span>std</span><span>.</span><span>algorithm</span><span>;</span>
<span>import</span> <span>std</span><span>.</span><span>stdio</span><span>;</span>

<span>// Using the Mir numerical library https://www.libmir.org/</span>
<span>import</span> <span>mir</span><span>.</span><span>random</span><span>.</span><span>engine</span><span>.</span><span>xoshiro</span><span>;</span>
<span>import</span> <span>mir</span><span>.</span><span>random</span><span>.</span><span>ndvariable</span><span>;</span>

<span>enum</span> <span>kNumDims</span> <span>=</span> <span>512</span><span>;</span>
<span>alias</span> <span>RNG</span> <span>=</span> <span>Xoroshiro128Plus</span><span>;</span>
<span>// D's built-in hash happens to be MurmurHash, but we just need it to be suitable for seeding the PRNG</span>
<span>static</span> <span>assert</span><span>(</span><span>""</span><span>.</span><span>hashOf</span><span>.</span><span>sizeof</span> <span>==</span> <span>8</span><span>);</span>

<span>void</span> <span>main</span><span>()</span>
<span>{</span>
    <span>auto</span> <span>makeUnitVector</span> <span>=</span> <span>sphereVar</span><span>!</span><span>float</span><span>();</span>
    <span>auto</span> <span>doc</span> <span>=</span> <span>"a lot of words"</span><span>;</span>

    <span>float</span><span>[</span><span>kNumDims</span><span>]</span> <span>doc_vec</span><span>,</span> <span>word_vec</span><span>;</span>

    <span>doc_vec</span><span>[]</span> <span>=</span> <span>0.0</span><span>;</span>
    <span>foreach</span> <span>(</span><span>word</span><span>;</span> <span>doc</span><span>.</span><span>splitter</span><span>)</span>  <span>// Not bothering with whitening or stop word filtering for this demo</span>
    <span>{</span>
        <span>// Create a PRNG seeded with the hash of the word</span>
        <span>auto</span> <span>rng</span> <span>=</span> <span>RNG</span><span>(</span><span>word</span><span>.</span><span>hashOf</span><span>);</span>
        <span>// Generate a unit vector for the word using the PRNG</span>
        <span>// We'll get the same vector every time we see the same word</span>
        <span>makeUnitVector</span><span>(</span><span>rng</span><span>,</span> <span>word_vec</span><span>);</span>
        <span>// Add it to the document vector (no weighting for simplicity)</span>
        <span>doc_vec</span><span>[]</span> <span>+=</span> <span>word_vec</span><span>[];</span>
    <span>}</span>

    <span>writeln</span><span>(</span><span>doc_vec</span><span>);</span>
<span>}</span></code></pre>
      </figure>
      <p>This kind of trick isn’t the answer to everything, but it has some uses. Obviously, it can be useful if you’re
      working with more data than you have RAM (though you might still cache some of the generated data). Another use
      case is processing a large dataset with parallel workers. In the document example, you can get workers to “agree”
      on what the vector for each word should be, without data synchronisation, and without needing to do an initial
      pass over the data to build a dictionary of words. I’ve used this trick with experimental code, just because I
      was too lazy to add an extra stage to the data pipeline. In some applications, recomputing data on the fly can
      even be faster than fetching it from a very large lookup table.</p>
      <h2 id="an-ode-to-xorshift">An ode to Xorshift</h2>
      <p>You might have noticed I used <code>Xoroshiro128Plus</code>, a
      variant of the Xorshift PRNG. The Mersenne Twister is a de facto standard PRNG in some computing fields, but I’m
      a bit of a fan of the Xorshift family. The basic Xorshift engines are fast and pretty good, and there are
      variants that are still fast and have excellent output quality. But the big advantage compared to the Mersenne
      Twister is the state size. The Mersenne Twister uses a pool of 2496 bytes of state, whereas most of the Xorshift
      PRNGs can fit into one or two machine <code>int</code>s.</p>
      <p>The small state size has a couple of advantages for this kind of “on demand” PRNG usage: One is that
      thoroughly initialising a big state from a small seed takes work (some people “warm up” a Mersenne Twister by
      throwing away several of the initial outputs, just to be sure). The second is that the small size of the PRNGs
      makes them cheap enough to use in places you wouldn’t think of using a Mersenne Twister.</p>
      <h2 id="random-data-structures-made-reliable">Random data structures made reliable</h2>
      <p>Some data structures and algorithms use randomisation. An example is a treap, which is a binary search tree
      that uses a randomised heap for balancing. Treaps are much less popular than AVL trees or red-black trees, but
      they’re easier to implement correctly because you end up with fewer edge cases. They’re also good enough for most
      use cases. That makes them a good choice for application-specific “augmented” BSTs. But for argument purposes,
      it’s just a real example of a data structure that happens to use randomness as an implementation detail.</p>
      <p>Randomisation comes with a major drawback: it’s a pain when testing and debugging. Test failures aren’t
      reproducible for debugging if real randomness is used. If you have any experience with testing, you’ll have seen
      this and you’ll know it’s a good idea to use a PRNG instead.</p>
      <p>Using a global PRNG mostly works, but it couples the treaps through one shared PRNG. That accidental coupling
      can lead to test flakes if you’re running several tests at once, unless you’re careful to use one PRNG per thread
      and reset it for every test. Even then you can get Heisenbugs in your non-test code.</p>
      <p>What about dependency injection? Making every treap method require a reference to a PRNG works, but it leaks
      the implementation detail throughout your code. You could make the treap take a reference to a PRNG in its
      constructor, but that implies adding an extra pointer to the data structure. If you’re going to do that, why not
      just make every treap embed its own 32b or 64b Xorshift PRNG? Embedding the PRNG into the treap makes it
      deterministic and reproducible in a way that’s encapsulated and decoupled from everything else.</p>
    </div></div>]]>
            </description>
            <link>https://theartofmachinery.com/2020/07/18/prng_tricks.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23879837</guid>
            <pubDate>Sat, 18 Jul 2020 07:57:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Typed Lisp, a Primer (2019)]]>
            </title>
            <description>
<![CDATA[
Score 97 | Comments 21 (<a href="https://news.ycombinator.com/item?id=23878612">thread link</a>) | @jedimind
<br/>
July 17, 2020 | https://alhassy.github.io/TypedLisp.html | <a href="https://web.archive.org/web/*/https://alhassy.github.io/TypedLisp.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="text-typing-via-macros">
<p>
Checking the type of inputs is tedious and so I <a href="https://www.reddit.com/r/emacs/comments/cct5hp/functional_type_declarations_in_elisp/">guessed</a> it could be done using
macros and advice. Looking at <a href="https://docs.racket-lang.org/ts-guide/types.html">Typed Racket</a> for inspiration, the following
fictitious syntax would add advice to <code>f</code> that checks the optional arguments <code>xᵢ</code>
have type <code>σᵢ</code> and the mandatory positional arguments have type <code>τᵢ</code> according
to position, and the result of the computation is of type <code>τ</code>.
To the best of my knowledge, no one had done this for Emacs Lisp —I don't know why.
</p>
<div>
<pre>(declare-type 'f ((<span>:x₁</span> σ₁) … (<span>:xₘ</span> σₘ)) (τ₁ … τₙ τ))
</pre>
</div>

<p>
To modify a variable, or function, we may simply redefine it; but a much more elegant and powerful
approach is to <a href="https://www.gnu.org/software/emacs/manual/html_node/elisp/Advising-Functions.html">“advise”</a> the current entity with some new behaviour. In our case of interest, we will
<i>advise functions to check their arguments before executing their bodies</i>.
</p>

<p>
Below is my attempt: <a id="org84d2c90"><code>declare-type</code></a>. Before you get scared or think it's horrendous, be charitable and
note that about a third of the following is documentation and a third is local declarations.
</p>
<div>
<pre>(<span>cl-defmacro</span> <span>declare-type</span> (f key-types <span>&amp;rest</span> types)
  <span>"Attach the given list of types to the function ‘f’</span>
<span>   by advising the function to check its arguments’ types</span>
<span>   are equal to the list of given types.</span>

<span>   We name the advice ‘⟪f⟫-typing-advice’ so that further</span>
<span>   invocations to this macro overwrite the same advice function</span>
<span>   rather than introducing additional, unintended, constraints.</span>

<span>   Using type specifiers we accommodate for unions of types</span>
<span>   and subtypes, etc ♥‿♥.</span>

<span>   ‘</span><span>key-types</span><span>’ should be of the shape (:x₀ t₀ ⋯ :xₙ tₙ);</span>
<span>    when there are no optional types, use symbol “:”.</span>

<span>    E.g., (declare-type my-func (:z string :w integer) integer symbol string)</span>
<span>  "</span>

  <span>;; </span><span>Basic coherency checks. When there aren't optional types, key-types is the “:” symbol.</span>
  (should (<span>and</span> (<span>listp</span> types) (<span>or</span> (<span>listp</span> key-types) (<span>symbolp</span> key-types))))

  (<span>letf*</span> ((pairify (<span>lambda</span> (xs) (<span>loop</span> for i in xs by #'<span>cddr</span>         <span>;; </span><span>Turn a list of flattenned pairs</span>
                                      for j in (<span>cdr</span> xs) by #'<span>cddr</span>   <span>;; </span><span>into a list of explicit pairs.</span>
                                      collect (<span>cons</span> i j))))         <span>;; </span><span>MA: No Lisp method for this!?</span>
         (result-type  (<span>car</span> (<span>-take-last</span> 1 types)))
         (types        (<span>-drop-last</span> 1 types))
         (num-of-types (<span>length</span> types))
         (key-types-og (<span>unless</span> (<span>symbolp</span> key-types) key-types))
         (key-types    (<span>funcall</span> pairify key-types-og))
         (advice-name  (<span>intern</span> (<span>format</span> <span>"%s-typing-advice"</span> f)))
         (notify-user  (<span>format</span> <span>"%s now typed %s → %s → %s."</span>
                               `,f key-types-og types result-type)))

      `(<span>progn</span>
         (<span>defun</span> ,advice-name (orig-fun <span>&amp;rest</span> args)

           <span>;; </span><span>Split into positional and key args; optionals not yet considered.</span>
           (<span>letf*</span> ((all-args
                     (<span>-split-at</span>
                       (<span>or</span> (<span>--find-index</span> (<span>not</span> (<span>s-blank?</span> (<span>s-shared-start</span> <span>":"</span> (<span>format</span> <span>"%s"</span> it)))) args) ,num-of-types)
                        args)) <span>;; </span><span>The “or” is for when there are no keywords provided.</span>
                  (pos-args  (<span>car</span> all-args))
                  (key-args  (<span>funcall</span> ,pairify (<span>cadr</span> all-args)))
                  (fun-result nil)
                  ((<span>symbol-function</span> 'shucks)
                     (<span>lambda</span> (eτ e g)
                       (<span>unless</span> (<span>typep</span> g eτ)
                         (<span>error</span> <span>"%s: Type mismatch! Expected %s %s ≠ Given %s %s."</span>
                                (<span>function</span> ,f) eτ e (<span>type-of</span> g) (<span>prin1-to-string</span> g))))))

         <span>;; </span><span>Check the types of positional arguments.</span>
         (<span>unless</span> (<span>equal</span> ,num-of-types (<span>length</span> pos-args))
           (<span>error</span> <span>"%s: Insufficient number of arguments; given %s, %s, but %s are needed."</span>
                  (<span>function</span> ,f) (<span>length</span> pos-args) pos-args ,num-of-types))
         (<span>loop</span> for (ar ty pos) in (<span>-zip</span> pos-args (<span>quote</span> ,types) (<span>number-sequence</span> 0 ,num-of-types))
               <span>do</span> (shucks ty (<span>format</span> <span>"for argument %s"</span> pos) ar))

         <span>;; </span><span>Check the types of *present* keys.</span>
         (<span>loop</span> for (k . v) in key-args
               <span>do</span> (shucks (<span>cdr</span> (<span>assoc</span> k (<span>quote</span> ,key-types))) k v))

         <span>;; </span><span>Actually execute the orginal function on the provided arguments.</span>
         (<span>setq</span> fun-result (<span>apply</span> orig-fun args))
         (shucks (<span>quote</span> ,result-type) <span>"for the result type (!)"</span> fun-result)

         <span>;; </span><span>Return-value should be given to caller.</span>
         fun-result))

      <span>;; </span><span>Register the typing advice and notify user of what was added.</span>
      (<span>advice-add</span> (<span>function</span> ,f) <span>:around</span> (<span>function</span> ,advice-name))
      ,notify-user )))
</pre>
</div>

<pre>declare-type
</pre>


<p>
There are some notable shortcomings: Lack of support for type variables and, for now, no support for
optional arguments. Nonetheless, I like it —of course.
( Using <a href="https://www.gnu.org/software/emacs/manual/html_node/elisp/Watching-Variables.html#Watching-Variables">variable watchers</a> we could likely add support for type variables as well as
function-types. )
</p>

<p>
<b>We accidentally forgot to consider an argument.</b>
</p>
<div>
<pre>(declare-type f₁ (<span>:z</span> <span>string</span> <span>:w</span> <span>list</span>) integer symbol <span>string</span>)
<span>;; </span><span>⇒ f₁ now typed (:z string :w integer) → (integer symbol) → string.</span>

(<span>cl-defun</span> <span>f₁</span> (x y <span>&amp;key</span> z w) (<span>format</span> <span>"%s"</span> x))
<span>;; </span><span>⇒ f₁ now defined</span>

(f₁ 'x) <span>;; </span><span>⇒ f₁: Insufficient number of arguments; given 2, (x), but 3 are needed.</span>
</pre>
</div>
<p>
The type declaration said we needed 3 arguments, but we did not consider one of them.
</p>

<p>
<b>We accidentally returned the wrong value.</b>
</p>
<div>
<pre>(declare-type f₂ (<span>:z</span> <span>string</span> <span>:w</span> <span>list</span>) integer symbol <span>string</span>)
(<span>cl-defun</span> <span>f₂</span> (x y <span>&amp;key</span> z w) x)

(f₂ 144 'two)
<span>;; </span><span>⇒ f₂: Type mismatch! Expected string for the result type (!) ≠ Given integer 144.</span>
</pre>
</div>

<p>
<b>We accidentally forgot to supply an argument.</b>
</p>
<div>
<pre>(declare-type f₃ (<span>:z</span> <span>string</span> <span>:w</span> <span>list</span>) integer symbol <span>string</span>)
(<span>cl-defun</span> <span>f₃</span> (x y <span>&amp;key</span> z w) (<span>format</span> <span>"%s"</span> x))

(f₃ 144)
<span>;; </span><span>⇒ f₃: Insufficient number of arguments; given 1, (144), but 2 are needed.</span>
</pre>
</div>

<p>
<b>A positional argument is supplied of the wrong type.</b>
</p>
<div>
<pre>(f₃ 'one <span>"two"</span>)
<span>;; </span><span>⇒  f₃: Type mismatch! Expected integer for argument 0 ≠ Given symbol one.</span>

(f₃ 144 <span>"two"</span>)
<span>;; </span><span>⇒ f₃: Type mismatch! Expected symbol for argument 1 ≠ Given string "two".</span>
</pre>
</div>
<p>
Notice: When multiple positional arguments have type-errors, the errors are reported one at a time.
</p>

<p>
<b>A keyword argument is supplied of the wrong type.</b>
</p>
<div>
<pre>(f₃ 1 'two <span>:z</span> 'no₀ <span>:w</span> 'no₁)
<span>;; </span><span>⇒ f₃: Type mismatch! Expected string :z ≠ Given symbol no₀.</span>

(f₃ 1 'two <span>:z</span> <span>"ok"</span> <span>:w</span> 'no₁)
<span>;; </span><span>⇒ f₃: Type mismatch! Expected string :w ≠ Given symbol no₁.</span>

(f₃ 1 'two <span>:z</span> <span>"ok"</span> <span>:w</span> 23)
<span>;; </span><span>⇒ f₃: Type mismatch! Expected string :w ≠ Given integer 23.</span>

(f₃ 1 'two <span>:z</span> <span>"ok"</span> <span>:w</span> '(a b 1 2)) <span>;; </span><span>⇒ okay; no type-error.</span>
</pre>
</div>

<p>
<b>We have no optional arguments.</b>
</p>
<div>
<pre>(declare-type f₄ : integer symbol <span>string</span>)
(<span>cl-defun</span> <span>f₄</span> (x y <span>&amp;key</span> z w) (<span>format</span> <span>"%s"</span> x))

(f₄ 144 'two <span>:z</span> <span>"bye"</span>)
<span>;; </span><span>⇒  f₄: Type mismatch! Expected nil :z ≠ Given string "bye".</span>
<span>;; </span><span>( We shouldn't have any keyword :z according to the type declaration! )</span>

(f₄ 144 'two) <span>;; </span><span>⇒ "144"</span>
</pre>
</div>

<p>
<b>We can incorporate type specfiers such as unions!</b>
</p>
<div>
<pre>(declare-type f₅ : (<span>or</span> integer <span>string</span>) <span>string</span>)
(<span>cl-defun</span> <span>f₅</span> (x) (<span>format</span> <span>"%s"</span> x))

(f₅ 144)     <span>;; </span><span>⇒ "144"</span>
(f₅ <span>"neato"</span>) <span>;; </span><span>⇒ "neato"</span>

(f₅ 'shaka-when-the-walls-fell)
<span>;; </span><span>⇒ f₅: Type mismatch! Expected (or integer string) for argument 0</span>
<span>;;       </span><span>≠ Given symbol shaka-when-the-walls-fell.</span>
</pre>
</div>

<p>
<b>No positional arguments but a complex optional argument!</b>
</p>
<div>
<pre>(declare-type f₆ (<span>:z</span> (satisfies (<span>lambda</span> (it) (<span>and</span> (<span>integerp</span> it) (<span>=</span> 0 (<span>mod</span> it 5))))))
                 character)
(<span>cl-defun</span> <span>f₆</span> (<span>&amp;key</span> z) ?A)

(f₆ 'hi)     <span>;; </span><span>⇒  Keyword argument 144 not one of (:z)</span>
(f₆)         <span>;; </span><span>⇒ 65; i.e., the character ‘A’</span>
(f₆ <span>:z</span> 6)
<span>;; </span><span>⇒  f₆: Type mismatch!</span>
<span>;;    </span><span>Expected (satisfies (lambda (it) (and (integerp it) (= 0 (mod it 5))))) :z</span>
<span>;;    </span><span>≠ Given integer 6.</span>

(f₆ <span>:z</span> 10) <span>;; </span><span>⇒ 65; i.e., the expected output since 10 mod 5 ≈ 0 &amp; so 10 is valid input.</span>
</pre>
</div>

<p>
<b>Preconditions!</b> The previous example had a complex type on a keyword, but that was
essentially a pre-condition; we can do the same on positional arguments.
</p>
<div>
<pre>(declare-type f₇ : (satisfies (<span>lambda</span> (it) (<span>=</span> it 5)))
                   integer)
(<span>cl-defun</span> <span>f₇</span> (n) n)
<span>;; </span><span>The identity on 5 function; and undefined otherwise.</span>

(f₇ 4)
<span>;; </span><span>⇒ f₇: Type mismatch! Expected (satisfies (lambda (it) (= it 5))) for argument 0</span>
<span>;;       </span><span>≠ Given integer 4.</span>

(f₇ 5) <span>;; </span><span>⇒ 5</span>
</pre>
</div>

<p>
<b>Postconditions!</b>
Given an integer greater than 5, we present an integer greater than 2; i.e.,
this is a constructive proof that \(∀ n • n &gt; 5 ⇒ n &gt; 2\).
</p>
<div>
<pre>(declare-type f₈ : (satisfies (<span>lambda</span> (in)  (<span>&gt;</span> in 5)))
                   (satisfies (<span>lambda</span> (out) (<span>&gt;</span> out 2))))
(<span>cl-defun</span> <span>f₈</span> (n) n)
<span>;; </span><span>The identity on 5 function; and undefined otherwise.</span>

(f₈ 4)
<span>;; </span><span>⇒  f₈: Type mismatch! Expected (satisfies (lambda (in) (&gt; in 5))) for argument 0</span>
<span>;;        </span><span>≠ Given integer 4.</span>

(f₈ 72) <span>;; </span><span>⇒ 72; since indeed 72 &gt; 5 for the input, and clearly 72 &gt; 2 for the output.</span>
</pre>
</div>

<p>
As it currently stands we cannot make any explicit references between the inputs
and the output, but that's an easy fix: Simply add a local function <code>old</code> to the
<a href="#org84d2c90"><code>declare-type</code></a> macro which is intentionally exposed so that it can be used in the
type declarations to refer to the ‘old’, or initial, values provided to the function.
Additionally, one could also add keyword arguments <code>:requires</code> and <code>:ensures</code>
for a more sophisticated pre- and post-condition framework.
<a href="https://github.com/sellout/quid-pro-quo">Something</a> along these lines is implemented for Common Lisp.
</p>

<p>
Here's a fun exercise: Recast the <a href="https://liquid.kosmikus.org/01-intro.html#/what-is-liquid-haskell">Liquid Haskell</a> examples in Lisp using this
<a href="#org84d2c90"><code>declare-type</code></a> form.
</p>
</div></div>]]>
            </description>
            <link>https://alhassy.github.io/TypedLisp.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23878612</guid>
            <pubDate>Sat, 18 Jul 2020 03:19:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why differential privacy is awesome (2018)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23878536">thread link</a>) | @momonga
<br/>
July 17, 2020 | https://desfontain.es/privacy/differential-privacy-awesomeness.html | <a href="https://web.archive.org/web/*/https://desfontain.es/privacy/differential-privacy-awesomeness.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p><small>
<span>P</span>art of a series on differential privacy.
In case you need reading material once you finished this post!</small></p><p><small>
<ol>
<li><strong>Why differential privacy is awesome</strong> (this article) presents a
   non-technical explanation of the definition.</li>
<li><a href="https://desfontain.es/privacy/differential-privacy-in-more-detail.html">Differential privacy in (a bit) more detail</a> introduces the formal
   definition, with very little math.</li>
<li><a href="https://desfontain.es/privacy/differential-privacy-in-practice.html">Differential privacy in practice (easy version)</a> explains how to
   make simple statistics differentially private.</li>
<li><a href="https://desfontain.es/privacy/almost-differential-privacy.html">Almost differential privacy</a> describes how to publish private
   histograms without knowing the categories in advance.</li>
<li><a href="https://desfontain.es/privacy/local-global-differential-privacy.html">Local vs. global differential privacy</a> presents the two main <em>models</em>
   of differential privacy, depending on who the attacker is.</li>
<li><a href="https://desfontain.es/privacy/privacy-loss-random-variable.html">The privacy loss random variable</a> explains the real meaning
   of <span>\((\varepsilon,\delta)\)</span>-differential privacy.</li>
</ol>
</small></p>
<hr>
<p><span>A</span><strong>re</strong> you following tech- or privacy-related
news? If so, you might have heard about <em>differential privacy</em>. The concept is
popular both in academic circles and inside tech companies. Both <a href="https://www.wired.com/2016/06/apples-differential-privacy-collecting-data/">Apple</a> or
<a href="https://security.googleblog.com/2014/10/learning-statistics-with-privacy-aided.html">Google</a> use differential privacy to collect data in a private way.</p>
<p>So, what's this definition about? How is it better than <a href="https://desfontain.es/privacy/k-anonymity.html">definitions</a>  <a href="https://desfontain.es/privacy/k-map.html">that</a>  <a href="https://desfontain.es/privacy/l-diversity.html">came</a>  <a href="https://desfontain.es/privacy/delta-presence.html">before</a>?
More importantly, why should you care? What makes it so exciting to researchers
and tech companies? In this post, I'll try to explain the idea behind
differential privacy and its advantages. I'll do my best to keep it simple and
accessible for everyone&nbsp;—&nbsp;not only technical folks.</p>

<p>Suppose you have a process that takes some database as input, and returns some output.</p>
<center>
<svg role="img" aria-label="Diagram showing an arrow labeled &quot;some process&quot;, going from a fake database to a cloud labeled &quot;output&quot;." xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:cc="http://creativecommons.org/ns#" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#" xmlns:svg="http://www.w3.org/2000/svg" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:sodipodi="http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape" version="1.1" viewBox="0 0 699.45947 142.76904" stroke-miterlimit="10" id="svg4123" sodipodi:docname="no-magic.svg" inkscape:version="0.92.2pre0 (973e216, 2017-07-25)" width="699.45947" height="142.76904" style="fill:none;stroke:none;stroke-linecap:square;stroke-miterlimit:10">
  <title>Diagram showing an arrow labeled "some process", going from a fake database to a cloud labeled "output".</title>
  <desc>Diagram showing an arrow labeled "some process", going from a fake database to a cloud labeled "output".</desc>
  <metadata id="metadata4129">
    <rdf:rdf>
      <cc:work rdf:about="">
        <dc:format>image/svg+xml</dc:format>
        <dc:type rdf:resource="http://purl.org/dc/dcmitype/StillImage"></dc:type>
        <dc:title></dc:title>
      </cc:work>
    </rdf:rdf>
  </metadata>
  <defs id="defs4127">
    <clipPath id="p.3-4">
      <path d="M 0,0 H 275 V 252 H 0 Z" id="path4077-0" inkscape:connector-curvature="0" style="clip-rule:evenodd"></path>
    </clipPath>
  </defs>
  <sodipodi:namedview pagecolor="#ffffff" bordercolor="#666666" borderopacity="1" objecttolerance="10" gridtolerance="10" guidetolerance="10" inkscape:pageopacity="0" inkscape:pageshadow="2" inkscape:window-width="1266" inkscape:window-height="1078" id="namedview4125" showgrid="false" inkscape:zoom="1.3111111" inkscape:cx="364.35056" inkscape:cy="-64.033451" inkscape:window-x="0" inkscape:window-y="0" inkscape:window-maximized="0" inkscape:current-layer="g4121" fit-margin-top="0" fit-margin-left="0" fit-margin-right="0" fit-margin-bottom="0" viewbox-x="82" viewbox-width="650"></sodipodi:namedview>
  <clipPath id="p.0">
    <path d="M 0,0 H 960 V 720 H 0 Z" id="path4036" inkscape:connector-curvature="0" style="clip-rule:nonzero"></path>
  </clipPath>
  <g clip-path="url(#p.0)" id="g4121" transform="translate(-76.08921,-124.34908)">
    <path d="M 0,0 H 960 V 720 H 0 Z" id="path4039" inkscape:connector-curvature="0" style="fill:#000000;fill-opacity:0;fill-rule:evenodd"></path>
    <path d="m 76.08921,124.34908 h 223.2992 V 267.11813 H 76.08921 Z" id="path4041" inkscape:connector-curvature="0" style="fill:#000000;fill-opacity:0;fill-rule:evenodd"></path>
    <g transform="matrix(0.22307612,0,0,0.22307664,76.089214,124.34908)" id="g4048">
      <clipPath id="p.1">
        <path d="M 0,0 H 1001 V 640 H 0 Z" id="path4043" inkscape:connector-curvature="0" style="clip-rule:evenodd"></path>
      </clipPath>
      <image clip-path="url(#p.1)" width="1001" height="640" x="0" y="0" preserveAspectRatio="none" xlink:href="https://desfontain.es/privacy/images/quiestce.jpeg" id="image4046" style="fill:#000000"></image>
    </g>
    <path d="M 76.086586,339.67847 H 299.38579 V 482.44751 H 76.086586 Z" id="path4050" inkscape:connector-curvature="0" style="fill:#000000;fill-opacity:0;fill-rule:evenodd"></path>
    <path d="m 604.81974,178.70273 v 0 c -1.51233,-10.41394 3.45307,-20.72311 12.78925,-26.55296 9.33618,-5.82984 21.40576,-6.15791 31.08722,-0.84502 v 0 c 3.42944,-6.0551 9.70636,-10.23573 16.93207,-11.27733 7.2257,-1.04159 14.55151,1.17818 19.76159,5.98789 v 0 c 2.92145,-5.48995 8.65778,-9.17848 15.1734,-9.75675 6.51569,-0.57824 12.88855,2.03563 16.85718,6.9141 v 0 c 5.27802,-5.81934 13.67554,-8.2695 21.55884,-6.29033 7.8833,1.97917 13.83649,8.03222 15.28363,15.53996 v 0 c 6.46649,1.65271 11.8529,5.85413 14.76764,11.51872 2.91473,5.66462 3.07178,12.23673 0.43066,18.01831 v 0 c 6.36756,7.76532 7.85712,18.11251 3.91272,27.18018 -3.9444,9.06767 -12.7301,15.49351 -23.07849,16.87953 -0.0729,8.51033 -5.05414,16.31931 -13.02356,20.41701 -7.96942,4.09772 -17.68268,3.84427 -25.39587,-0.66263 -3.2854,10.1926 -12.53272,17.6922 -23.74671,19.25873 -11.21405,1.56653 -22.38446,-3.08087 -28.68524,-11.93434 -7.72339,4.3639 -16.99084,5.621 -25.71185,3.48773 -8.72095,-2.13329 -16.16077,-7.47725 -20.64124,-14.8264 v 0 c -7.89233,0.86539 -15.52319,-2.96604 -19.10534,-9.59276 -3.58216,-6.62671 -2.35303,-14.63803 3.07733,-20.05798 v 0 c -7.04022,-3.8826 -10.63251,-11.58696 -8.90375,-19.09555 1.72882,-7.50861 8.38696,-13.11998 16.50256,-13.90799 z" id="path4059" inkscape:connector-curvature="0" style="fill:#f6cd4c;fill-rule:evenodd"></path>
    <path d="m 597.06497,212.10764 v 0 c 3.32227,1.83222 7.16028,2.66335 10.99872,2.38181 m 5.02759,27.2696 c 1.65063,-0.18098 3.26861,-0.56427 4.81219,-1.13993 m 41.53858,12.47812 c -1.16095,-1.63134 -2.133,-3.37456 -2.89954,-5.19996 m 55.3335,-2.12474 v 0 c 0.59893,-1.85826 0.98706,-3.77081 1.15777,-5.70575 m 37.26019,-14.04791 c 0.0776,-9.06056 -5.41461,-17.3565 -14.11767,-21.32448 m 33.2832,-22.73425 c -1.40942,3.08528 -3.56109,5.8222 -6.28625,7.99617 m -8.91071,-37.53403 v 0 c 0.24011,1.24591 0.35126,2.51055 0.33185,3.77639 m -37.17371,-13.02565 v 0 c -1.31659,1.45164 -2.4013,3.07382 -3.22033,4.81604 m -28.81055,-1.97402 v 0 c -0.70166,1.31851 -1.22559,2.71372 -1.55975,4.15347 m -35.13446,1.13608 v 0 c 2.04858,1.12421 3.94384,2.47731 5.64404,4.02959 m -49.5199,23.36855 v 0 c 0.20844,1.4353 0.53784,2.85292 0.98499,4.23957" id="path4061" inkscape:connector-curvature="0" style="fill:#000000;fill-opacity:0;fill-rule:evenodd"></path>
    <path d="m 636.30257,211.8428 h -0.1875 q -0.78125,0 -1.25,-0.48437 -0.46875,-0.48438 -0.46875,-1.17188 0,-0.46875 0.5,-2.92187 l 1.375,-7.10938 q 0.46875,-2.42187 2.0625,-13.4375 l 0.39063,-2.70312 q 0.14062,-1.01563 1.10937,-1.84375 0.96875,-0.84375 1.78125,-0.84375 0.4375,0 2.9375,1.3125 2.70313,1.45312 3.20313,1.59375 5.09375,1.875 8.375,5.6875 3.29687,3.8125 3.29687,8.23437 0,4.04688 -2.40625,7.92188 -2.39062,3.875 -5.78125,5.71875 -3.39062,1.84375 -8.67187,1.84375 -1.53125,0 -3.46875,-0.53125 -1.9375,-0.51563 -2.79688,-1.26563 z m 6,-25.40625 -1.64062,11.20313 -2,10.67187 q 0.0625,0.0469 0.14062,0.0781 1.84375,1.32812 4.375,1.32812 5.01563,0 7.375,-1.79687 2.35938,-1.79688 3.60938,-4.21875 1.25,-2.42188 1.25,-4.92188 0,-2.51562 -1.40625,-4.64062 -1.39063,-2.125 -3.76563,-3.57813 -2.35937,-1.46875 -7.9375,-4.125 z m 32.16406,24.28125 q -4.21875,2.03125 -6.01562,2.03125 -7.29688,0 -7.29688,-6.95312 0,-6.46875 4.07813,-10.46875 4.09375,-4 8.98437,-4 1.89063,0 3.90625,0.96875 2.03125,0.96875 2.03125,2.25 0,0.79687 -0.53125,1.25 -0.39062,0.76562 -1.10937,4.40625 -0.70313,3.64062 -0.70313,5.25 0,1.96875 1.01563,5.42187 l 0.0781,0.3125 q -0.4375,1.82813 -2.17187,1.82813 -0.29688,0 -1.09375,-0.79688 -0.79688,-0.79687 -1.17188,-1.5 z m 1.42188,-15.1875 q -1.21875,-0.73437 -1.95313,-0.73437 -3.25,0 -6.07812,2.95312 -2.82813,2.9375 -2.82813,7.3125 0,4.29688 3.71875,4.29688 2.90625,0 5.46875,-2.15625 0.3125,-8.1875 1.67188,-11.67188 z m 16.45312,-0.34375 q -0.23437,0.9375 -0.60937,2.1875 -1.64063,5.42188 -1.64063,8.26563 0,3.35937 1.5625,3.35937 1.54688,0 2.28125,-0.95312 1.01563,-1.32813 1.875,-1.32813 0.65625,0 1.25,0.48438 0.59375,0.48437 0.59375,1.26562 0,1.71875 -2.15625,2.95313 -2.15625,1.21875 -4.29687,1.21875 -5.03125,0 -5.03125,-6.28125 0,-3.4375 1.54687,-8.39063 0.40625,-1.3125 0.78125,-2.625 -4.25,-0.20312 -4.85937,-0.70312 -0.60938,-0.5 -0.60938,-1.5625 0,-0.85938 0.57813,-1.42188 0.59375,-0.57812 1.60937,-0.57812 l 4.03125,0.32812 q 0.125,-0.51562 0.1875,-1.17187 0.0312,-0.67188 0.125,-1.48438 l 0.34375,-2.42187 q 0.10938,-0.79688 0.71875,-1.34375 0.625,-0.54688 1.46875,-0.54688 1.64063,0 1.64063,2.625 0,0.76563 -0.23438,1.98438 l -0.39062,2.35937 q 2.60937,-0.32812 2.78125,-0.32812 2.03125,0 2.79687,0.40625 0.76563,0.39062 0.76563,1.46875 0,0.95312 -0.65625,1.54687 -0.65625,0.57813 -1.57813,0.57813 l -1.92187,-0.0781 q -1.45313,0 -2.95313,0.1875 z m 21.44141,15.53125 q -4.21875,2.03125 -6.01563,2.03125 -7.29687,0 -7.29687,-6.95312 0,-6.46875 4.07812,-10.46875 4.09375,-4 8.98438,-4 1.89062,0 3.90625,0.96875 2.03125,0.96875 2.03125,2.25 0,0.79687 -0.53125,1.25 -0.39063,0.76562 -1.10938,4.40625 -0.70312,3.64062 -0.70312,5.25 0,1.96875 1.01562,5.42187 l 0.0781,0.3125 q -0.4375,1.82813 -2.17188,1.82813 -0.29687,0 -1.09375,-0.79688 -0.79687,-0.79687 -1.17187,-1.5 z m 1.42187,-15.1875 q -1.21875,-0.73437 -1.95312,-0.73437 -3.25,0 -6.07813,2.95312 -2.82812,2.9375 -2.82812,7.3125 0,4.29688 3.71875,4.29688 2.90625,0 5.46875,-2.15625 0.3125,-8.1875 1.67187,-11.67188 z" id="path4063" inkscape:connector-curvature="0" style="fill:#000000;fill-rule:nonzero"></path>
    <path d="m 597.06237,427.43705 v 0 c 3.32227,1.83218 7.16028,2.66333 10.99872,2.38181 m 5.02759,27.26959 c 1.65063,-0.181 3.26861,-0.56427 4.81219,-1.13992 m 41.53858,12.47811 c -1.16095,-1.63134 -2.133,-3.37457 -2.89954,-5.19998 m 55.3335,-2.12472 v 0 c 0.59893,-1.85825 0.98706,-3.77082 1.15777,-5.70575 m 37.26019,-14.04792 c 0.0776,-9.06054 -5.41461,-17.3565 -14.11767,-21.32449 m 33.2832,-22.73425 c -1.40942,3.0853 -3.56109,5.82223 -6.28625,7.99618 m -8.91071,-37.53402 v 0 c 0.24011,1.24591 0.35126,2.51056 0.33185,3.77639 m -37.17371,-13.02566 v 0 c -1.31659,1.45163 -2.4013,3.07382 -3.22033,4.81604 m -28.81055,-1.974 v 0 c -0.70166,1.31848 -1.22559,2.71372 -1.55975,4.15347 m -35.13446,1.13608 v 0 c 2.04858,1.12421 3.94384,2.4773 5.64404,4.02957 m -49.5199,23.36856 v 0 c 0.20844,1.43531 0.53784,2.85291 0.98499,4.23957" id="path4067" inkscape:connector-curvature="0" style="fill:#000000;fill-opacity:0;fill-rule:evenodd"></path>
    <path d="m 299.38846,189.04987 h 70.36065 v -6.68504 l 8.40525,13.37008 -8.40525,13.37007 v -6.68502 h -70.36065 z" id="path4071" inkscape:connector-curvature="0" style="fill:#7c7ce0;fill-rule:evenodd;stroke-width:0.79288208"></path>
    <path d="M 427.88773,353.66272 H 553.16596 V 468.46329 H 427.88773 Z" id="path4075" inkscape:connector-curvature="0" style="fill:#000000;fill-opacity:0;fill-rule:evenodd"></path>
    <path d="M 427.809,138.3307 H 553.08723 V 253.13125 H 427.809 Z" id="path4100" inkscape:connector-curvature="0" style="fill:#000000;fill-opacity:0;fill-rule:evenodd"></path>
    <path d="M 379.751,138.43701 H 505.04235 V 253.24016 H 379.751 Z" id="path4109" inkscape:connector-curvature="0" style="fill:#00fdc8;fill-rule:evenodd"></path>
    <path d="M 379.751,138.43701 H 505.04235 V 253.24016 H 379.751 Z" id="path4111" inkscape:connector-curvature="0" style="fill-rule:evenodd;stroke:#666666;stroke-width:1;stroke-linecap:butt;stroke-linejoin:round"></path>
    <path d="m 506.71874,190.09462 h 70.36065 v -6.68504 l 8.40525,13.37008 -8.40525,13.37007 v -6.68502 h -70.36065 z" id="path4071-6" inkscape:connector-curvature="0" style="fill:#7c7ce0;fill-rule:evenodd;stroke-width:0.79288208"></path>
    <g aria-label="Some process" style="font-style:normal;font-variant:normal;font-weight:normal;font-stretch:normal;font-size:26.66666603px;line-height:1.25;font-family:'Comic Sans MS';-inkscape-font-specification:'Comic Sans MS';text-align:center;letter-spacing:0px;word-spacing:0px;text-anchor:middle;fill:#000000;fill-opacity:1;stroke:none" id="flowRoot4272">
      <path d="m 409.86816,182.0918 q -0.013,-0.54687 0.36459,-0.88542 0.39062,-0.35156 0.95052,-0.35156 0.63802,0 1.11979,0.72917 0.66406,0.98958 1.1849,1.34114 1.10677,0.72917 3.21614,0.72917 2.01823,0 3.75,-0.8724 2.21354,-1.11979 2.21354,-3.11197 0,-1.64063 -1.86198,-2.59115 -1.57552,-0.82031 -3.89322,-0.88542 -2.0573,-0.0781 -3.50261,-0.89843 -1.84896,-1.05469 -1.84896,-3.02084 0,-2.31771 2.63021,-4.23177 2.51302,-1.80989 5.19531,-1.80989 1.26302,0 2.85157,0.42968 2.10937,0.5599 2.10937,1.4323 0,1.14583 -1.17187,1.14583 -0.52084,0 -1.82292,-0.27344 -1.30208,-0.28646 -2.01823,-0.27344 -2.03125,0.026 -3.45052,1.00261 -1.45833,1.0026 -1.45833,2.43489 0,1.08073 1.92708,1.52344 0.71615,0.16927 2.77344,0.3125 2.98177,0.22136 4.66146,1.875 1.53645,1.51042 1.53645,3.6849 0,3.09895 -2.86458,4.94791 -2.48698,1.60157 -5.76823,1.60157 -2.38281,0 -4.36198,-0.91146 -2.42187,-1.11979 -2.46094,-3.07292 z" style="" id="path4896"></path>
      <path d="m 433.30566,186.10222 q -2.1875,0 -3.76302,-1.61459 -1.75781,-1.79687 -1.84896,-4.83072 -0.0781,-2.94271 1.48438,-5.1823 1.82292,-2.64323 5.07812,-2.64323 2.60417,0 3.94532,2.38282 1.0677,1.92708 1.02864,4.63541 -0.0391,2.89063 -1.51041,4.9349 -1.66667,2.31771 -4.41407,2.31771 z m 0.78125,-11.62761 q -1.91406,-0.013 -2.98177,1.82292 -0.84635,1.47135 -0.84635,3.35938 0,1.88802 1.02864,2.9427 0.85938,0.8724 2.01823,0.8724 1.35417,0 2.33073,-0.98958 1.10677,-1.09375 1.17188,-2.95573 0.18229,-5.03907 -2.72136,-5.05209 z" style="" id="path4898"></path>
      <path d="m 458.96973,186.41472 q -1.06771,0 -1.25,-1.13282 -0.23438,-1.43229 -0.46875,-4.03645 l -0.44271,-4.03646 q -0.13021,-0.89844 -0.44271,-1.75781 -0.44271,-1.17188 -0.96354,-1.17188 -0.48177,0 -1.79688,0.82031 -1.25,0.75521 -1.64062,1.21094 -0.013,1.22396 0.0651,2.44792 l 0.39063,3.47656 q 0.24739,2.05729 0.24739,3.39844 0,0.57291 -0.36458,0.9375 -0.35156,0.3776 -0.91146,0.3776 -0.55989,0 -0.92448,-0.3776 -0.35156,-0.36459 -0.35156,-0.9375 0,-1.57552 -0.32552,-4.64844 -0.3125,-3.08594 -0.3125,-4.66146 0,-1.38021 -0.39063,-2.14844 -0.91145,0.41667 -1.84895,1.35417 l -1.53646,1.71875 q -0.20834,0.3125 -0.66406,0.82031 0,0.78125 -0.14323,2.30469 -0.14323,1.52344 -0.14323,2.2526 0,0.39063 0.11718,1.09375 0.13021,0.70313 0.13021,1.01563 0,0.53385 -0.40364,0.89844 -0.39063,0.36458 -0.92448,0.36458 -1.47136,0 -1.47136,-3.34635 0,-0.78125 0.14323,-2.33073 0.14323,-1.54948 0.14323,-2.33073 0,-0.69011 -0.13021,-2.07031 -0.11718,-1.38021 -0.11718,-2.08334 0,-2.95573 1.32812,-2.95573 0.50781,0 0.92448,0.44271 0.42969,0.44271 0.42969,0.96354 0,0.2474 -0.0651,0.76823 -0.0651,0.52084 -0.0651,0.79427 l 0.026,1.36719 q 0.67708,-1.39323 1.99219,-2.51302 1.3151,-1.13281 2.23958,-1.13281 2.04427,0 2.8125,2.03125 0.71615,-0.95052 1.70573,-1.41927 0.98958,-0.48177 2.26563,-0.48177 2.17448,0 2.96875,2.34375 0.15625,0.46875 0.53385,3.65885 0.36458,2.23958 0.9375,7.46094 0.0391,0.52083 -0.35156,0.88541 -0.39063,0.36459 -0.95052,0.36459 z" style="" id="path4900"></path>
      <path d="m 469.24316,185.93295 q -2.94271,0 -4.76562,-1.47136 -1.99219,-1.6276 -1.99219,-4.55729 0,-3.38542 1.64062,-5.67708 1.78386,-2.5 4.76563,-2.5 2.16146,0 3.52865,0.72916 1.67968,0.89844 1.67968,2.76042 0,1.30208 -1.47135,2.36979 -0.65104,0.46875 -2.76042,1.45834 l -4.97396,2.35677 q 0.72917,1.08073 1.8099,1.6276 1.09375,0.54688 2.53906,0.54688 0.89844,0 2.10938,-0.33855 1.53646,-0.42968 1.97916,-1.11979 0.44271,-0.70312 0.95052,-0.70312 0.45573,0 0.8073,0.35156 0.36458,0.33854 0.36458,0.79427 0,1.44531 -2.33073,2.48698 -1.99219,0.88542 -3.88021,0.88542 z m -0.35156,-11.86198 q -1.58854,0 -2.64323,1.23698 -1.05469,1.22396 -1.57552,3.69791 l 3.9974,-1.90104 q 2.35677,-1.14583 3.35937,-1.99219 -1.11979,-1.04166 -3.13802,-1.04166 z" style="" id="path4902"></path>
      <path d="m 401.71712,219.12305 q -1.30208,0 -2.86458,-0.41667 l -0.026,6.22396 q 0,0.57291 -0.36458,0.9375 -0.35157,0.36458 -0.91146,0.36458 -0.5599,0 -0.92448,-0.36458 -0.35156,-0.36459 -0.35156,-0.9375 l 0.0391,-5.20834 v -5.19531 q -0.0391,-2.85156 -0.19531,-5.19531 l -0.19532,-2.64323 q 0,-0.92448 0.33854,-1.5625 0.39063,-0.76823 1.13282,-0.76823 0.50781,0 0.84635,0.36458 0.35156,0.35157 0.35156,0.8724 0,0.11719 -0.0391,0.42969 -0.0651,0.40364 -0.0911,0.74219 1.11979,-0.76823 2.16145,-1.14584 1.04167,-0.39062 1.99219,-0.39062 2.66927,0 3.90625,2.36979 0.97656,1.875 0.97656,4.96094 0,2.8125 -1.51041,4.63541 -1.60157,1.92709 -4.27084,1.92709 z m 0.89844,-11.28907 q -1.19792,0 -2.16146,0.53386 -0.6901,0.3776 -1.74479,1.38021 0.16927,2.95572 0.16927,6.21093 1.41927,0.54688 2.83854,0.54688 1.62761,0 2.48698,-1.21094 0.74219,-1.05469 0.74219,-2.73437 0,-2.3698 -0.58594,-3.54167 -0.57291,-1.1849 -1.74479,-1.1849 z" style="" id="path4904"></path>
      <path d="m 420.58431,209.04492 q -0.0912,1.6276 -1.30208,1.6276 -1.11979,0 -1.11979,-1.28906 0,-0.24739 -0.0391,-0.91146 l -0.0391,-1.09375 q -2.05729,0.2474 -3.29427,1.15886 -1.15885,0.84635 -1.92708,2.55208 l 0.026,7.13542 q 0,1.3151 -1.28906,1.3151 -1.14584,0 -1.14584,-1.3151 v -9.14063 q 0,-0.42968 0.026,-1.28906 0.0391,-0.85937 0.0391,-1.28906 0,-1.31511 1.14583,-1.31511 1.27604,0 1.28906,2.16146 2.5,-2.40885 5.54688,-2.40885 1.05468,0 1.57552,0.79427 0.52083,0.79427 0.52083,2.39583 0,0.67709 -0.013,0.91146 z" style="" id="path4906"></path>
      <path d="m 428.14941,219.43555 q -2.1875,0 -3.76302,-1.61459 -1.75781,-1.79687 -1.84896,-4.83073 -0.0781,-2.94271 1.48438,-5.18229 1.82292,-2.64323 5.07812,-2.64323 2.60417,0 3.94532,2.38282 1.06771,1.92708 1.02864,4.63541 -0.0391,2.89063 -1.51041,4.9349 -1.66667,2.31771 -4.41407,2.31771 z m 0.78125,-11.62761 q -1.91406,-0.013 -2.98177,1.82292 -0.84635,1.47135 -0.84635,3.35937 0,1.88802 1.02864,2.94271 0.85938,0.8724 2.01823,0.8724 1.35417,0 2.33073,-0.98959 1.10677,-1.09375 1.17188,-2.95573 0.18229,-5.03906 -2.72136,-5.05208 z" style="" id="path4908"></path>
      <path d="m 443.16244,219.48763 q -2.66927,0 -4.45313,-1.61458 -1.875,-1.69271 -1.875,-4.46615 0,-2.64323 1.75781,-5.45573 1.95313,-3.125 4.40105,-3.125 1.27604,0 2.85156,0.59896 1.99218,0.76823 1.99218,1.875 0,0.49479 -0.32552,0.88542 -0.32552,0.3776 -0.80729,0.3776 -0.3776,0 -0.66406,-0.22135 -0.27344,-0.23438 -0.53385,-0.45573 -0.76823,-0.61198 -2.51302,-0.61198 -1.32813,0 -2.63021,2.36979 -1.1849,2.17448 -1.1849,3.76302 0,1.71875 1.17188,2.70833 1.09375,0.92448 2.8125,0.92448 0.78125,0 1.66666,-0.41666 l 1.51042,-0.8073 q 0.39062,-0.20833 0.55989,-0.20833 0.48178,0 0.83334,0.39063 0.35156,0.3776 0.35156,0.87239 0,0.95052 -2.00521,1.83594 -1.75781,0.78125 -2.91666,0.78125 z" style="" id="path4910"></path>
      <path d="m 457.05566,219.26627 q -2.94271,0 -4.76562,-1.47135 -1.99219,-1.6276 -1.99219,-4.55729 0,-3.38542 1.64063,-5.67708 1.78385,-2.5 4.76562,-2.5 2.16146,0 3.52865,0.72916 1.67968,0.89844 1.67968,2.76042 0,1.30208 -1.47135,2.36979 -0.65104,0.46875 -2.76042,1.45833 l -4.97396,2.35677 q 0.72917,1.08073 1.8099,1.62761 1.09375,0.54687 2.53906,0.54687 0.89844,0 2.10938,-0.33854 1.53646,-0.42969 1.97916,-1.11979 0.44271,-0.70312 0.95052,-0.70312 0.45573,0 0.8073,0.35156 0.36458,0.33854 0.36458,0.79427 0,1.44531 -2.33073,2.48698 -1.99219,0.88541 -3.88021,0.88541 z M 456.7041,207.4043 q -1.58854,0 -2.64323,1.23698 -1.05469,1.22395 -1.57552,3.69791 l 3.9974,-1.90104 q 2.35677,-1.14583 3.35937,-1.99219 -1.11979,-1.04166 -3.13802,-1.04166 z" style="" id="path4912"></path>
      <path d="m 474.39941,208.64128 q -0.71615,0 -1.0026,-0.48178 -0.19532,-0.33854 -0.33855,-1.40625 -0.97656,0.2474 -3.00781,0.91146 -2.09635,0.83334 -2.10937,2.05729 0.39062,0.14323 0.76823,0.20834 2.99479,0.53385 4.45312,1.47135 2.1224,1.36719 2.1224,3.95833 0,2.1224 -1.83594,3.20313 -1.52344,0.88542 -3.85417,0.88542 -1.70573,0 -3.25521,-0.57292 -2.0052,-0.72917 -2.0052,-2.03125 0,-0.52083 0.40364,-0.91146 0.41667,-0.39062 0.9375,-0.39062 0.40365,0 1.04167,0.625 0.3125,0.29948 1.40625,0.49479 0.87239,0.15625 1.47135,0.15625 1.09375,0 1.92709,-0.26042 1.21093,-0.3776 1.21093,-1.19792 0,-1.77083 -2.47396,-2.39583 l -1.35416,-0.29948 q -1.73177,-0.3776 -2.46094,-0.88541 -1.05469,-0.72917 -1.05469,-2.20053 0,-2.72135 2.56511,-3.8802 0.78125,-0.35157 2.5,-0.83334 1.71875,-0.49479 2.46093,-0.83333 0.53386,-0.23437 1.15886,-0.23437 0.55989,0 0.91146,0.36458 0.36458,0.36458 0.36458,0.95052 0,0.3776 0.15625,1.10677 0.16927,0.72917 0.16927,1.10677 0,0.58594 -0.36458,0.95052 -0.35156,0.36459 -0.91146,0.36459 z" style="" id="path4914"></path>
      <path d="m 487.36816,208.64128 q -0.71615,0 -1.0026,-0.48178 -0.19532,-0.33854 -0.33855,-1.40625 -0.97656,0.2474 -3.00781,0.91146 -2.09635,0.83334 -2.10937,2.05729 0.39062,0.14323 0.76823,0.20834 2.99479,0.53385 4.45312,1.47135 2.1224,1.36719 2.1224,3.95833 0,2.1224 -1.83594,3.20313 -1.52344,0.88542 -3.85417,0.88542 -1.70573,0 -3.25521,-0.57292 -2.0052,-0.72917 -2.0052,-2.03125 0,-0.52083 0.40364,-0.91146 0.41667,-0.39062 0.9375,-0.39062 0.40365,0 1.04167,0.625 0.3125,0.29948 1.40625,0.49479 0.87239,0.15625 1.47135,0.15625 1.09375,0 1.92709,-0.26042 1.21093,-0.3776 1.21093,-1.19792 0,-1.77083 -2.47396,-2.39583 l -1.35416,-0.29948 q -1.73177,-0.3776 -2.46094,-0.88541 -1.05469,-0.72917 -1.05469,-2.20053 0,-2.72135 2.56511,-3.8802 0.78125,-0.35157 2.5,-0.83334 1.71875,-0.49479 2.46093,-0.83333 0.53386,-0.23437 1.15886,-0.23437 0.55989,0 0.91146,0.36458 0.36458,0.36458 0.36458,0.95052 0,0.3776 0.15625,1.10677 0.16927,0.72917 0.16927,1.10677 0,0.58594 -0.36458,0.95052 -0.35156,0.36459 -0.91146,0.36459 z" style="" id="path4916"></path>
    </g>
    <rect style="fill:#ffffff" id="rect148" width="28.983051" height="45.762711" x="212.03391" y="388.22034"></rect>
  </g>
</svg>
</center>
<p>This process can be <em>anything</em>. For example, it can be:</p>
<ul>
<li>computing some statistic ("tell me how many users have red hair")</li>
<li>an anonymization strategy ("remove names and last three digits of ZIP codes")</li>
<li>a machine learning training process ("build a model to predict which users
  like cats")</li>
<li>… you get the idea.</li>
</ul>
<p>To make a process differentially private, you usually have to modify it a little
bit. Typically, you add some randomness, or <em>noise</em>, in some places. What
exactly you do, and how much noise you add, depends on which process you're
modifying. I'll abstract that part away and simply say that your process is now
doing some unspecified ✨&nbsp;magic&nbsp;✨.</p>
<center>
<svg role="img" aria-label="Same diagram as before, except the arrow is labeled with a silly &quot;magic&quot; gif." xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:cc="http://creativecommons.org/ns#" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#" xmlns:svg="http://www.w3.org/2000/svg" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:sodipodi="http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape" version="1.1" viewBox="0 0 699.45947 142.76904" stroke-miterlimit="10" id="svg4123" sodipodi:docname="magic.svg" inkscape:version="0.92.3 (2405546, 2018-03-11)" width="699.45947" height="142.76904" style="fill:none;stroke:none;stroke-linecap:square;stroke-miterlimit:10">
  <title>Same diagram as before, except the arrow is labeled with a silly "magic" gif.</title>
  <desc>Same diagram as before, except the arrow is labeled with a silly "magic" gif.</desc>
  <metadata id="metadata4129">
    <rdf:rdf>
      <cc:work rdf:about="">
        <dc:format>image/svg+xml</dc:format>
        <dc:type rdf:resource="http://purl.org/dc/dcmitype/StillImage"></dc:type>
        <dc:title></dc:title>
      </cc:work>
    </rdf:rdf>
  </metadata>
  <defs id="defs4127">
    <clipPath id="p.3-4">
      <path d="M 0,0 H 275 V 252 H 0 Z" id="path4077-0" inkscape:connector-curvature="0" style="clip-rule:evenodd"></path>
    </clipPath>
  </defs>
  <sodipodi:namedview pagecolor="#ffffff" bordercolor="#666666" borderopacity="1" objecttolerance="10" gridtolerance="10" guidetolerance="10" inkscape:pageopacity="0" inkscape:pageshadow="2" inkscape:window-width="2556" inkscape:window-height="1436" id="namedview4125" showgrid="false" inkscape:zoom="1.3111111" inkscape:cx="608.41836" inkscape:cy="-64.033451" inkscape:window-x="0" inkscape:window-y="1200" inkscape:window-maximized="0" inkscape:current-layer="g4121" fit-margin-top="0" fit-margin-left="0" fit-margin-right="0" fit-margin-bottom="0" viewbox-x="82" viewbox-width="650"></sodipodi:namedview>
  <clipPath id="p.0">
    <path d="M 0,0 H 960 V 720 H 0 Z" id="path4036" inkscape:connector-curvature="0" style="clip-rule:nonzero"></path>
  </clipPath>
  <g clip-path="url(#p.0)" id="g4121" transform="translate(-76.08921,-124.34908)">
    <path d="M 0,0 H 960 V 720 H 0 Z" id="path4039" inkscape:connector-curvature="0" style="fill:#000000;fill-opacity:0;fill-rule:evenodd"></path>
    <path d="m 76.08921,124.34908 h 223.2992 V 267.11813 H 76.08921 Z" id="path4041" inkscape:connector-curvature="0" style="fill:#000000;fill-opacity:0;fill-rule:evenodd"></path>
    <g transform="matrix(0.22307612,0,0,0.22307664,76.089214,124.34908)" id="g4048">
      <clipPath id="p.1">
        <path d="M 0,0 H 1001 V 640 H 0 Z" id="path4043" inkscape:connector-curvature="0" style="clip-rule:evenodd"></path>
      </clipPath>
      <image clip-path="url(#p.1)" width="1001" height="640" x="0" y="0" preserveAspectRatio="none" xlink:href="https://desfontain.es/privacy/images/quiestce.jpeg" id="image4046" style="fill:#000000"></image>
    </g>
    <path d="M 76.086586,339.67847 H 299.38579 V 482.44751 H 76.086586 Z" id="path4050" inkscape:connector-curvature="0" style="fill:#000000;fill-opacity:0;fill-rule:evenodd"></path>
    <path d="m 604.81974,178.70273 v 0 c -1.51233,-10.41394 3.45307,-20.72311 12.78925,-26.55296 9.33618,-5.82984 21.40576,-6.15791 31.08722,-0.84502 v 0 c 3.42944,-6.0551 9.70636,-10.23573 16.93207,-11.27733 7.2257,-1.04159 14.55151,1.17818 19.76159,5.98789 v 0 c 2.92145,-5.48995 8.65778,-9.17848 15.1734,-9.75675 6.51569,-0.57824 12.88855,2.03563 16.85718,6.9141 v 0 c 5.27802,-5.81934 13.67554,-8.2695 21.55884,-6.29033 7.8833,1.97917 13.83649,8.03222 15.28363,15.53996 v 0 c 6.46649,1.65271 11.8529,5.85413 14.76764,11.51872 2.91473,5.66462 3.07178,12.23673 0.43066,18.01831 v 0 c 6.36756,7.76532 7.85712,18.11251 3.91272,27.18018 -3.9444,9.06767 -12.7301,15.49351 -23.07849,16.87953 -0.0729,8.51033 -5.05414,16.31931 -13.02356,20.41701 -7.96942,4.09772 -17.68268,3.84427 -25.39587,-0.66263 -3.2854,10.1926 -12.53272,17.6922 -23.74671,19.25873 -11.21405,1.56653 -22.38446,-3.08087 -28.68524,-11.93434 -7.72339,4.3639 -16.99084,5.621 -25.71185,3.48773 -8.72095,-2.13329 -16.16077,-7.47725 -20.64124,-14.8264 v 0 c -7.89233,0.86539 -15.52319,-2.96604 -19.10534,-9.59276 -3.58216,-6.62671 -2.35303,-14.63803 3.07733,-20.05798 v 0 c -7.04022,-3.8826 -10.63251,-11.58696 -8.90375,-19.09555 1.72882,-7.50861 8.38696,-13.11998 16.50256,-13.90799 z" id="path4059" inkscape:connector-curvature="0" style="fill:#f6cd4c;fill-rule:evenodd"></path>
    <path d="m 597.06497,212.10764 v 0 c 3.32227,1.83222 7.16028,2.66335 10.99872,2.38181 m 5.02759,27.2696 c 1.65063,-0.18098 3.26861,-0.56427 4.81219,-1.13993 m 41.53858,12.47812 c -1.16095,-1.63134 -2.133,-3.37456 -2.89954,-5.19996 m 55.3335,-2.12474 v 0 c 0.59893,-1.85826 0.98706,-3.77081 1.15777,-5.70575 m 37.26019,-14.04791 c 0.0776,-9.06056 -5.41461,-17.3565 -14.11767,-21.32448 m 33.2832,-22.73425 c -1.40942,3.08528 -3.56109,5.8222 -6.28625,7.99617 m -8.91071,-37.53403 v 0 c 0.24011,1.24591 0.35126,2.51055 0.33185,3.77639 m -37.17371,-13.02565 v 0 c -1.31659,1.45164 -2.4013,3.07382 -3.22033,4.81604 m -28.81055,-1.97402 v 0 c -0.70166,1.31851 -1.22559,2.71372 -1.55975,4.15347 m -35.13446,1.13608 v 0 c 2.04858,1.12421 3.94384,2.47731 5.64404,4.02959 m -49.5199,23.36855 v 0 c 0.20844,1.4353 0.53784,2.85292 0.98499,4.23957" id="path4061" inkscape:connector-curvature="0" style="fill:#000000;fill-opacity:0;fill-rule:evenodd"></path>
    <path d="m 636.30257,211.8428 h -0.1875 q -0.78125,0 -1.25,-0.48437 -0.46875,-0.48438 -0.46875,-1.17188 0,-0.46875 0.5,-2.92187 l 1.375,-7.10938 q 0.46875,-2.42187 2.0625,-13.4375 l 0.39063,-2.70312 q 0.14062,-1.01563 1.10937,-1.84375 0.96875,-0.84375 1.78125,-0.84375 0.4375,0 2.9375,1.3125 2.70313,1.45312 3.20313,1.59375 5.09375,1.875 8.375,5.6875 3.29687,3.8125 3.29687,8.23437 0,4.04688 -2.40625,7.92188 -2.39062,3.875 -5.78125,5.71875 -3.39062,1.84375 -8.67187,1.84375 -1.53125,0 -3.46875,-0.53125 -1.9375,-0.51563 -2.79688,-1.26563 z m 6,-25.40625 -1.64062,11.20313 -2,10.67187 q 0.0625,0.0469 0.14062,0.0781 1.84375,1.32812 4.375,1.32812 5.01563,0 7.375,-1.79687 2.35938,-1.79688 3.60938,-4.21875 1.25,-2.42188 1.25,-4.92188 0,-2.51562 -1.40625,-4.64062 -1.39063,-2.125 -3.76563,-3.57813 -2.35937,-1.46875 -7.9375,-4.125 z m 32.16406,24.28125 q -4.21875,2.03125 -6.01562,2.03125 -7.29688,0 -7.29688,-6.95312 0,-6.46875 4.07813,-10.46875 4.09375,-4 8.98437,-4 1.89063,0 3.90625,0.96875 2.03125,0.96875 2.03125,2.25 0,0.79687 -0.53125,1.25 -0.39062,0.76562 -1.10937,4.40625 -0.70313,3.64062 -0.70313,5.25 0,1.96875 1.01563,5.42187 l 0.0781,0.3125 q -0.4375,1.82813 -2.17187,1.82813 -0.29688,0 -1.09375,-0.79688 -0.79688,-0.79687 -1.17188,-1.5 z m 1.42188,-15.1875 q -1.21875,-0.73437 -1.95313,-0.73437 -3.25,0 -6.07812,2.95312 -2.82813,2.9375 -2.82813,7.3125 0,4.29688 3.71875,4.29688 2.90625,0 5.46875,-2.15625 0.3125,-8.1875 1.67188,-11.67188 z m 16.45312,-0.34375 q -0.23437,0.9375 -0.60937,2.1875 -1.64063,5.42188 -1.64063,8.26563 0,3.35937 1.5625,3.35937 1.54688,0 2.28125,-0.95312 1.01563,-1.32813 1.875,-1.32813 0.65625,0 1.25,0.48438 0.59375,0.48437 0.59375,1.26562 0,1.71875 -2.15625,2.95313 -2.15625,1.21875 -4.29687,1.21875 -5.03125,0 -5.03125,-6.28125 0,-3.4375 1.54687,-8.39063 0.40625,-1.3125 0.78125,-2.625 -4.25,-0.20312 -4.85937,-0.70312 -0.60938,-0.5 -0.60938,-1.5625 0,-0.85938 0.57813,-1.42188 0.59375,-0.57812 1.60937,-0.57812 l 4.03125,0.32812 q 0.125,-0.51562 0.1875,-1.17187 0.0312,-0.67188 0.125,-1.48438 l 0.34375,-2.42187 q 0.10938,-0.79688 0.71875,-1.34375 0.625,-0.54688 1.46875,-0.54688 1.64063,0 1.64063,2.625 0,0.76563 -0.23438,1.98438 l -0.39062,2.35937 q 2.60937,-0.32812 2.78125,-0.32812 2.03125,0 2.79687,0.40625 0.76563,0.39062 0.76563,1.46875 0,0.95312 -0.65625,1.54687 -0.65625,0.57813 -1.57813,0.57813 l -1.92187,-0.0781 q -1.45313,0 -2.95313,0.1875 z m 21.44141,15.53125 q -4.21875,2.03125 -6.01563,2.03125 -7.29687,0 -7.29687,-6.95312 0,-6.46875 4.07812,-10.46875 4.09375,-4 8.98438,-4 1.89062,0 3.90625,0.96875 2.03125,0.96875 2.03125,2.25 0,0.79687 -0.53125,1.25 -0.39063,0.76562 -1.10938,4.40625 -0.70312,3.64062 -0.70312,5.25 0,1.96875 1.01562,5.42187 l 0.0781,0.3125 q -0.4375,1.82813 -2.17188,1.82813 -0.29687,0 -1.09375,-0.79688 -0.79687,-0.79687 -1.17187,-1.5 z m 1.42187,-15.1875 q -1.21875,-0.73437 -1.95312,-0.73437 -3.25,0 -6.07813,2.95312 -2.82812,2.9375 -2.82812,7.3125 0,4.29688 3.71875,4.29688 2.90625,0 5.46875,-2.15625 0.3125,-8.1875 1.67187,-11.67188 z" id="path4063" inkscape:connector-curvature="0" style="fill:#000000;fill-rule:nonzero"></path>
    <path d="m 597.06237,427.43705 v 0 c 3.32227,1.83218 7.16028,2.66333 10.99872,2.38181 m 5.02759,27.26959 c 1.65063,-0.181 3.26861,-0.56427 4.81219,-1.13992 m 41.53858,12.47811 c -1.16095,-1.63134 -2.133,-3.37457 -2.89954,-5.19998 m 55.3335,-2.12472 v 0 c 0.59893,-1.85825 0.98706,-3.77082 1.15777,-5.70575 m 37.26019,-14.04792 c 0.0776,-9.06054 -5.41461,-17.3565 -14.11767,-21.32449 m 33.2832,-22.73425 c -1.40942,3.0853 -3.56109,5.82223 -6.28625,7.99618 m -8.91071,-37.53402 v 0 c 0.24011,1.24591 0.35126,2.51056 0.33185,3.77639 m -37.17371,-13.02566 v 0 c -1.31659,1.45163 -2.4013,3.07382 -3.22033,4.81604 m -28.81055,-1.974 v 0 c -0.70166,1.31848 -1.22559,2.71372 -1.55975,4.15347 m -35.13446,1.13608 v 0 c 2.04858,1.12421 3.94384,2.4773 5.64404,4.02957 m -49.5199,23.36856 v 0 c 0.20844,1.43531 0.53784,2.85291 0.98499,4.23957" id="path4067" inkscape:connector-curvature="0" style="fill:#000000;fill-opacity:0;fill-rule:evenodd"></path>
    <path d="m 299.38846,189.04987 h 70.36065 v -6.68504 l 8.40525,13.37008 -8.40525,13.37007 v -6.68502 h -70.36065 z" id="path4071" inkscape:connector-curvature="0" style="fill:#7c7ce0;fill-rule:evenodd;stroke-width:0.79288208"></path>
    <path d="M 427.88773,353.66272 H 553.16596 V 468.46329 H 427.88773 Z" id="path4075" inkscape:connector-curvature="0" style="fill:#000000;fill-opacity:0;fill-rule:evenodd"></path>
    <path d="M 427.809,138.3307 H 553.08723 V 253.13125 H 427.809 Z" id="path4100" inkscape:connector-curvature="0" style="fill:#000000;fill-opacity:0;fill-rule:evenodd"></path>
    <path d="M 379.751,138.43701 H 505.04235 V 253.24016 H 379.751 Z" id="path4109" inkscape:connector-curvature="0" style="fill:#00fdc8;fill-rule:evenodd"></path>
    <path d="M 379.751,138.43701 H 505.04235 V 253.24016 H 379.751 Z" id="path4111" inkscape:connector-curvature="0" style="fill-rule:evenodd;stroke:#666666;stroke-width:1;stroke-linecap:butt;stroke-linejoin:round"></path>
    <path d="m 506.71874,190.09462 h 70.36065 v -6.68504 l 8.40525,13.37008 -8.40525,13.37007 v -6.68502 h -70.36065 z" id="path4071-6" inkscape:connector-curvature="0" style="fill:#7c7ce0;fill-rule:evenodd;stroke-width:0.79288208"></path>
    <flowroot xml:space="preserve" id="flowRoot4272" style="font-style:normal;font-variant:normal;font-weight:normal;font-stretch:normal;font-size:26.66666603px;line-height:1.25;font-family:'Comic Sans MS';-inkscape-font-specification:'Comic Sans MS';text-align:center;letter-spacing:0px;word-spacing:0px;text-anchor:middle;fill:#000000;fill-opacity:1;stroke:none"><flowregion id="flowRegion4274" style="font-style:normal;font-variant:normal;font-weight:normal;font-stretch:normal;font-size:26.66666603px;font-family:'Comic Sans MS';-inkscape-font-specification:'Comic Sans MS';text-align:center;text-anchor:middle"><rect id="rect4276" width="125.97456" height="90.782555" x="379.06781" y="162.45763" style="font-style:normal;font-variant:normal;font-weight:normal;font-stretch:normal;font-size:26.66666603px;font-family:'Comic Sans MS';-inkscape-font-specification:'Comic Sans MS';text-align:center;text-anchor:middle"></rect></flowregion><flowpara id="flowPara4278">Some process</flowpara></flowroot>    <g transform="matrix(0.45555722,0,0,0.45555774,379.751,138.43701)" id="g4082-1" inkscape:transform-center-x="-34.322034" inkscape:transform-center-y="102.9661">
      <clipPath id="clipPath4292">
        <path d="M 0,0 H 275 V 252 H 0 Z" id="path4290" inkscape:connector-curvature="0" style="clip-rule:evenodd"></path>
      </clipPath>
      <image clip-path="url(#p.3-4)" width="275" height="252" x="0" y="0" preserveAspectRatio="none" xlink:href="https://desfontain.es/privacy/images/magic.gif" id="image4080-3" style="fill:#000000"></image>
    </g>
    <rect style="fill:#ffffff" id="rect148" width="28.983051" height="45.762711" x="212.03391" y="388.22034"></rect>
  </g>
</svg>
</center>
<p>Now, remove somebody from your database, and run your new process on it. If the
new process is differentially private, then the two outputs are <em>basically the
same</em>. This must be true no matter who you remove, and what database you had in
the first place.</p>
<center>
<svg role="img" aria-label="Same diagram as before, duplicated, with the bottom line missing one person in the database. A double arrow labeled &quot;basically the same&quot; points to the two outputs." xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:cc="http://creativecommons.org/ns#" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#" xmlns:svg="http://www.w3.org/2000/svg" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:sodipodi="http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape" version="1.1" viewBox="0 0 734.41882 358.09845" stroke-miterlimit="10" id="svg4123" sodipodi:docname="full-diagram.svg" inkscape:version="0.92.2pre0 (973e216, 2017-07-25)" width="734.41882" height="358.09845" style="fill:none;stroke:none;stroke-linecap:square;stroke-miterlimit:10">
  <title>Same diagram as before, duplicated, with the bottom line missing one person in the database. A double arrow labeled "basically the same" points to the two outputs.</title>
  <desc>Same diagram as before, duplicated, with the bottom line missing one person in the database. A double arrow labeled "basically the same" points to the two outputs.</desc>
  <metadata id="metadata4129">
    <rdf:rdf>
      <cc:work rdf:about="">
        <dc:format>image/svg+xml</dc:format>
        <dc:type rdf:resource="http://purl.org/dc/dcmitype/StillImage"></dc:type>
        <dc:title></dc:title>
      </cc:work>
    </rdf:rdf>
  </metadata>
  <defs id="defs4127">
    <clipPath id="p.3-4">
      <path d="M 0,0 H 275 V 252 H 0 Z" id="path4077-0" inkscape:connector-curvature="0" style="clip-rule:evenodd"></path>
    </clipPath>
  </defs>
  <sodipodi:namedview pagecolor="#ffffff" bordercolor="#666666" borderopacity="1" objecttolerance="10" gridtolerance="10" guidetolerance="10" inkscape:pageopacity="0" inkscape:pageshadow="2" inkscape:window-width="1918" inkscape:window-height="1078" id="namedview4125" showgrid="false" inkscape:zoom="1.3111111" inkscape:cx="532.33439" inkscape:cy="127.30279" inkscape:window-x="0" inkscape:window-y="0" inkscape:window-maximized="0" inkscape:current-layer="g4121" fit-margin-top="0" fit-margin-left="0" fit-margin-right="0" fit-margin-bottom="0" viewbox-x="82" viewbox-width="650"></sodipodi:namedview>
  <clipPath id="p.0">
    <path d="M 0,0 H 960 V 720 H 0 Z" id="path4036" inkscape:connector-curvature="0" style="clip-rule:nonzero"></path>
  </clipPath>
  <g clip-path="url(#p.0)" id="g4121" transform="translate(-76.086586,-124.34907)">
    <path d="M 0,0 H 960 V 720 H 0 Z" id="path4039" inkscape:connector-curvature="0" style="fill:#000000;fill-opacity:0;fill-rule:evenodd"></path>
    <path d="m 76.08921,124.34908 h 223.2992 V 267.11813 H 76.08921 Z" id="path4041" inkscape:connector-curvature="0" style="fill:#000000;fill-opacity:0;fill-rule:evenodd"></path>
    <g transform="matrix(0.22307612,0,0,0.22307664,76.089214,124.34908)" id="g4048">
      <clipPath id="p.1">
        <path d="M 0,0 H 1001 V 640 H 0 Z" id="path4043" inkscape:connector-curvature="0" style="clip-rule:evenodd"></path>
      </clipPath>
      <image clip-path="url(#p.1)" width="1001" height="640" x="0" y="0" preserveAspectRatio="none" xlink:href="https://desfontain.es/privacy/images/quiestce.jpeg" id="image4046" style="fill:#000000"></image>
    </g>
    <path d="M 76.086586,339.67847 H 299.38579 V 482.44751 H 76.086586 Z" id="path4050" inkscape:connector-curvature="0" style="fill:#000000;fill-opacity:0;fill-rule:evenodd"></path>
    <g transform="matrix(0.22307612,0,0,0.22307664,76.086589,339.67847)" id="g4057">
      <clipPath id="p.2">
        <path d="M 0,0 H 1001 V 640 H 0 Z" id="path4052" inkscape:connector-curvature="0" style="clip-rule:evenodd"></path>
      </clipPath>
      <image clip-path="url(#p.2)" width="1001" height="640" x="0" y="0" preserveAspectRatio="none" xlink:href="https://desfontain.es/privacy/images/quiestce.jpeg" id="image4055" style="fill:#000000"></image>
    </g>
    <path d="m 604.81974,178.70273 v 0 c -1.51233,-10.41394 3.45307,-20.72311 12.78925,-26.55296 9.33618,-5.82984 21.40576,-6.15791 31.08722,-0.84502 v 0 c 3.42944,-6.0551 9.70636,-10.23573 16.93207,-11.27733 7.2257,-1.04159 14.55151,1.17818 19.76159,5.98789 v 0 c 2.92145,-5.48995 8.65778,-9.17848 15.1734,-9.75675 6.51569,-0.57824 12.88855,2.03563 16.85718,6.9141 v 0 c 5.27802,-5.81934 13.67554,-8.2695 21.55884,-6.29033 7.8833,1.97917 13.83649,8.03222 15.28363,15.53996 v 0 c 6.46649,1.65271 11.8529,5.85413 14.76764,11.51872 2.91473,5.66462 3.07178,12.23673 0.43066,18.01831 v 0 c 6.36756,7.76532 7.85712,18.11251 3.91272,27.18018 -3.9444,9.06767 -12.7301,15.49351 -23.07849,16.87953 -0.0729,8.51033 -5.05414,16.31931 -13.02356,20.41701 -7.96942,4.09772 -17.68268,3.84427 -25.39587,-0.66263 -3.2854,10.1926 -12.53272,17.6922 -23.74671,19.25873 -11.21405,1.56653 -22.38446,-3.08087 -28.68524,-11.93434 -7.72339,4.3639 -16.99084,5.621 -25.71185,3.48773 -8.72095,-2.13329 -16.16077,-7.47725 -20.64124,-14.8264 v 0 c -7.89233,0.86539 -15.52319,-2.96604 -19.10534,-9.59276 -3.58216,-6.62671 -2.35303,-14.63803 3.07733,-20.05798 v 0 c -7.04022,-3.8826 -10.63251,-11.58696 -8.90375,-19.09555 1.72882,-7.50861 8.38696,-13.11998 16.50256,-13.90799 z" id="path4059" inkscape:connector-curvature="0" style="fill:#f6cd4c;fill-rule:evenodd"></path>
    <path d="m 597.06497,212.10764 v 0 c 3.32227,1.83222 7.16028,2.66335 10.99872,2.38181 m 5.02759,27.2696 c 1.65063,-0.18098 3.26861,-0.56427 4.81219,-1.13993 m 41.53858,12.47812 c -1.16095,-1.63134 -2.133,-3.37456 -2.89954,-5.19996 m 55.3335,-2.12474 v 0 c 0.59893,-1.85826 0.98706,-3.77081 1.15777,-5.70575 m 37.26019,-14.04791 c 0.0776,-9.06056 -5.41461,-17.3565 -14.11767,-21.32448 m 33.2832,-22.73425 c -1.40942,3.08528 -3.56109,5.8222 -6.28625,7.99617 m -8.91071,-37.53403 v 0 c 0.24011,1.24591 0.35126,2.51055 0.33185,3.77639 m -37.17371,-13.02565 v 0 c -1.31659,1.45164 -2.4013,3.07382 -3.22033,4.81604 m -28.81055,-1.97402 v 0 c -0.70166,1.31851 -1.22559,2.71372 -1.55975,4.15347 m -35.13446,1.13608 v 0 c 2.04858,1.12421 3.94384,2.47731 5.64404,4.02959 m -49.5199,23.36855 v 0 c 0.20844,1.4353 0.53784,2.85292 0.98499,4.23957" id="path4061" inkscape:connector-curvature="0" style="fill:#000000;fill-opacity:0;fill-rule:evenodd"></path>
    <path d="m 636.30257,211.8428 h -0.1875 q -0.78125,0 -1.25,-0.48437 -0.46875,-0.48438 -0.46875,-1.17188 0,-0.46875 0.5,-2.92187 l 1.375,-7.10938 q 0.46875,-2.42187 2.0625,-13.4375 l 0.39063,-2.70312 q 0.14062,-1.01563 1.10937,-1.84375 0.96875,-0.84375 1.78125,-0.84375 0.4375,0 2.9375,1.3125 2.70313,1.45312 3.20313,1.59375 5.09375,1.875 8.375,5.6875 3.29687,3.8125 3.29687,8.23437 0,4.04688 -2.40625,7.92188 -2.39062,3.875 -5.78125,5.71875 -3.39062,1.84375 -8.67187,1.84375 -1.53125,0 -3.46875,-0.53125 -1.9375,-0.51563 -2.79688,-1.26563 z m 6,-25.40625 -1.64062,11.20313 -2,10.67187 q 0.0625,0.0469 0.14062,0.0781 1.84375,1.32812 4.375,1.32812 5.01563,0 7.375,-1.79687 2.35938,-1.79688 3.60938,-4.21875 1.25,-2.42188 1.25,-4.92188 0,-2.51562 -1.40625,-4.64062 -1.39063,-2.125 -3.76563,-3.57813 -2.35937,-1.46875 -7.9375,-4.125 z m 32.16406,24.28125 q -4.21875,2.03125 -6.01562,2.03125 -7.29688,0 -7.29688,-6.95312 0,-6.46875 4.07813,-10.46875 4.09375,-4 8.98437,-4 1.89063,0 3.90625,0.96875 2.03125,0.96875 2.03125,2.25 0,0.79687 -0.53125,1.25 -0.39062,0.76562 -1.10937,4.40625 -0.70313,3.64062 -0.70313,5.25 0,1.96875 1.01563,5.42187 l 0.0781,0.3125 q -0.4375,1.82813 -2.17187,1.82813 -0.29688,0 -1.09375,-0.79688 -0.79688,-0.79687 -1.17188,-1.5 z m 1.42188,-15.1875 q -1.21875,-0.73437 -1.95313,-0.73437 -3.25,0 -6.07812,2.95312 -2.82813,2.9375 -2.82813,7.3125 0,4.29688 3.71875,4.29688 2.90625,0 5.46875,-2.15625 0.3125,-8.1875 1.67188,-11.67188 z m 16.45312,-0.34375 q -0.23437,0.9375 -0.60937,2.1875 -1.64063,5.42188 -1.64063,8.26563 0,3.35937 1.5625,3.35937 1.54688,0 2.28125,-0.95312 1.01563,-1.32813 1.875,-1.32813 0.65625,0 1.25,0.48438 0.59375,0.48437 0.59375,1.26562 0,1.71875 -2.15625,2.95313 -2.15625,1.21875 -4.29687,1.21875 -5.03125,0 -5.03125,-6.28125 0,-3.4375 1.54687,-8.39063 0.40625,-1.3125 0.78125,-2.625 -4.25,-0.20312 -4.85937,-0.70312 -0.60938,-0.5 -0.60938,-1.5625 0,-0.85938 0.57813,-1.42188 0.59375,-0.57812 1.60937,-0.57812 l 4.03125,0.32812 q 0.125,-0.51562 0.1875,-1.17187 0.0312,-0.67188 0.125,-1.48438 l 0.34375,-2.42187 q 0.10938,-0.79688 0.71875,-1.34375 0.625,-0.54688 1.46875,-0.54688 1.64063,0 1.64063,2.625 0,0.76563 -0.23438,1.98438 l -0.39062,2.35937 q 2.60937,-0.32812 2.78125,-0.32812 2.03125,0 2.79687,0.40625 0.76563,0.39062 0.76563,1.46875 0,0.95312 -0.65625,1.54687 -0.65625,0.57813 -1.57813,0.57813 l -1.92187,-0.0781 q -1.45313,0 -2.95313,0.1875 z m 21.44141,15.53125 q -4.21875,2.03125 -6.01563,2.03125 -7.29687,0 -7.29687,-6.95312 0,-6.46875 4.07812,-10.46875 4.09375,-4 8.98438,-4 1.89062,0 3.90625,0.96875 2.03125,0.96875 2.03125,2.25 0,0.79687 -0.53125,1.25 -0.39063,0.76562 -1.10938,4.40625 -0.70312,3.64062 -0.70312,5.25 0,1.96875 1.01562,5.42187 l 0.0781,0.3125 q -0.4375,1.82813 -2.17188,1.82813 -0.29687,0 -1.09375,-0.79688 -0.79687,-0.79687 -1.17187,-1.5 z m 1.42187,-15.1875 q -1.21875,-0.73437 -1.95312,-0.73437 -3.25,0 -6.07813,2.95312 -2.82812,2.9375 -2.82812,7.3125 0,4.29688 3.71875,4.29688 2.90625,0 5.46875,-2.15625 0.3125,-8.1875 1.67187,-11.67188 z" id="path4063" inkscape:connector-curvature="0" style="fill:#000000;fill-rule:nonzero"></path>
    <path d="m 604.81711,394.03214 v 0 c -1.51233,-10.41397 3.45307,-20.72311 12.78925,-26.55298 9.33618,-5.82983 21.40576,-6.1579 31.08722,-0.845 v 0 c 3.42944,-6.05511 9.70636,-10.23575 16.93207,-11.27734 7.2257,-1.0416 14.55151,1.17819 19.76159,5.98788 v 0 c 2.92145,-5.48993 8.65778,-9.17847 15.1734,-9.75674 6.51569,-0.57825 12.88855,2.03564 16.85718,6.91409 v 0 c 5.27802,-5.81934 13.67554,-8.2695 21.55884,-6.29031 7.8833,1.97915 13.83649,8.03222 15.28363,15.53994 v 0 c 6.46649,1.65271 11.8529,5.85413 14.76764,11.51874 2.91473,5.66461 3.07178,12.23673 0.43066,18.01831 v 0 c 6.36756,7.76532 7.85712,18.11249 3.91272,27.18018 -3.9444,9.06766 -12.7301,15.4935 -23.07849,16.87952 -0.0729,8.51034 -5.05414,16.3193 -13.02356,20.41702 -7.96942,4.09769 -17.68268,3.84427 -25.39587,-0.66266 -3.2854,10.19263 -12.53272,17.69223 -23.74671,19.25876 -11.21405,1.56653 -22.38446,-3.08087 -28.68524,-11.93436 -7.72339,4.36392 -16.99084,5.621 -25.71185,3.48773 -8.72095,-2.13327 -16.16077,-7.47723 -20.64124,-14.82638 v 0 c -7.89233,0.86539 -15.52319,-2.96607 -19.10534,-9.59277 -3.58216,-6.62671 -2.35303,-14.63804 3.07733,-20.05799 v 0 c -7.04022,-3.8826 -10.63257,-11.58694 -8.90375,-19.09555 1.72882,-7.5086 8.38696,-13.11996 16.50256,-13.90799 z" id="path4065" inkscape:connector-curvature="0" style="fill:#f6cd4c;fill-rule:evenodd"></path>
    <path d="m 597.06237,427.43705 v 0 c 3.32227,1.83218 7.16028,2.66333 10.99872,2.38181 m 5.02759,27.26959 c 1.65063,-0.181 3.26861,-0.56427 4.81219,-1.13992 m 41.53858,12.47811 c -1.16095,-1.63134 -2.133,-3.37457 -2.89954,-5.19998 m 55.3335,-2.12472 v 0 c 0.59893,-1.85825 0.98706,-3.77082 1.15777,-5.70575 m 37.26019,-14.04792 c 0.0776,-9.06054 -5.41461,-17.3565 -14.11767,-21.32449 m 33.2832,-22.73425 c -1.40942,3.0853 -3.56109,5.82223 -6.28625,7.99618 m -8.91071,-37.53402 v 0 c 0.24011,1.24591 0.35126,2.51056 0.33185,3.77639 m -37.17371,-13.02566 v 0 c -1.31659,1.45163 -2.4013,3.07382 -3.22033,4.81604 m -28.81055,-1.974 v 0 c -0.70166,1.31848 -1.22559,2.71372 -1.55975,4.15347 m -35.13446,1.13608 v 0 c 2.04858,1.12421 3.94384,2.4773 5.64404,4.02957 m -49.5199,23.36856 v 0 c 0.20844,1.43531 0.53784,2.85291 0.98499,4.23957" id="path4067" inkscape:connector-curvature="0" style="fill:#000000;fill-opacity:0;fill-rule:evenodd"></path>
    <path d="m 636.29997,427.17219 h -0.1875 q -0.78125,0 -1.25,-0.48437 -0.46875,-0.48438 -0.46875,-1.17188 0,-0.46875 0.5,-2.92187 l 1.375,-7.10938 q 0.46875,-2.42187 2.0625,-13.4375 l 0.39063,-2.70312 q 0.14062,-1.01563 1.10937,-1.84375 0.96875,-0.84375 1.78125,-0.84375 0.4375,0 2.9375,1.3125 2.70313,1.45312 3.20313,1.59375 5.09375,1.875 8.375,5.6875 3.29687,3.8125 3.29687,8.23437 0,4.04688 -2.40625,7.92188 -2.39062,3.875 -5.78125,5.71875 -3.39062,1.84375 -8.67187,1.84375 -1.53125,0 -3.46875,-0.53125 -1.9375,-0.51563 -2.79688,-1.26563 z m 6,-25.40625 -1.64062,11.20313 -2,10.67187 q 0.0625,0.0469 0.14062,0.0781 1.84375,1.32812 4.375,1.32812 5.01563,0 7.375,-1.79687 2.35938,-1.79688 3.60938,-4.21875 1.25,-2.42188 1.25,-4.92188 0,-2.51562 -1.40625,-4.64062 -1.39063,-2.125 -3.76563,-3.57813 -2.35937,-1.46875 -7.9375,-4.125 z m 32.16406,24.28125 q -4.21875,2.03125 -6.01562,2.03125 -7.29688,0 -7.29688,-6.95312 0,-6.46875 4.07813,-10.46875 4.09375,-4 8.98437,-4 1.89063,0 3.90625,0.96875 2.03125,0.96875 2.03125,2.25 0,0.79687 -0.53125,1.25 -0.39062,0.76562 -1.10937,4.40625 -0.70313,3.64062 -0.70313,5.25 0,1.96875 1.01563,5.42187 l 0.0781,0.3125 q -0.4375,1.82813 -2.17187,1.82813 -0.29688,0 -1.09375,-0.79688 -0.79688,-0.79687 -1.17188,-1.5 z m 1.42188,-15.1875 q -1.21875,-0.73437 -1.95313,-0.73437 -3.25,0 -6.07812,2.95312 -2.82813,2.9375 -2.82813,7.3125 0,4.29688 3.71875,4.29688 2.90625,0 5.46875,-2.15625 0.3125,-8.1875 1.67188,-11.67188 z m 16.45312,-0.34375 q -0.23437,0.9375 -0.60937,2.1875 -1.64063,5.42188 -1.64063,8.26563 0,3.35937 1.5625,3.35937 1.54688,0 2.28125,-0.95312 1.01563,-1.32813 1.875,-1.32813 0.65625,0 1.25,0.48438 0.59375,0.48437 0.59375,1.26562 0,1.71875 -2.15625,2.95313 -2.15625,1.21875 -4.29687,1.21875 -5.03125,0 -5.03125,-6.28125 0,-3.4375 1.54687,-8.39063 0.40625,-1.3125 0.78125,-2.625 -4.25,-0.20312 -4.85937,-0.70312 -0.60938,-0.5 -0.60938,-1.5625 0,-0.85938 0.57813,-1.42188 0.59375,-0.57812 1.60937,-0.57812 l 4.03125,0.32812 q 0.125,-0.51562 0.1875,-1.17187 0.0312,-0.67188 0.125,-1.48438 l 0.34375,-2.42187 q 0.10938,-0.79688 0.71875,-1.34375 0.625,-0.54688 1.46875,-0.54688 1.64063,0 1.64063,2.625 0,0.76563 -0.23438,1.98438 l -0.39062,2.35937 q 2.60937,-0.32812 2.78125,-0.32812 2.03125,0 2.79687,0.40625 0.76563,0.39062 0.76563,1.46875 0,0.95312 -0.65625,1.54687 -0.65625,0.57813 -1.57813,0.57813 l -1.92187,-0.0781 q -1.45313,0 -2.95313,0.1875 z m 21.44141,15.53125 q -4.21875,2.03125 -6.01563,2.03125 -7.29687,0 -7.29687,-6.95312 0,-6.46875 4.07812,-10.46875 4.09375,-4 8.98438,-4 1.89062,0 3.90625,0.96875 2.03125,0.96875 2.03125,2.25 0,0.79687 -0.53125,1.25 -0.39063,0.76562 -1.10938,4.40625 -0.70312,3.64062 -0.70312,5.25 0,1.96875 1.01562,5.42187 l 0.0781,0.3125 q -0.4375,1.82813 -2.17188,1.82813 -0.29687,0 -1.09375,-0.79688 -0.79687,-0.79687 -1.17187,-1.5 z m 1.42187,-15.1875 q -1.21875,-0.73437 -1.95312,-0.73437 -3.25,0 -6.07813,2.95312 -2.82812,2.9375 -2.82812,7.3125 0,4.29688 3.71875,4.29688 2.90625,0 5.46875,-2.15625 0.3125,-8.1875 1.67187,-11.67188 z" id="path4069" inkscape:connector-curvature="0" style="fill:#000000;fill-rule:nonzero"></path>
    <path d="m 299.38846,189.04987 h 70.36065 v -6.68504 l 8.40525,13.37008 -8.40525,13.37007 v -6.68502 h -70.36065 z" id="path4071" inkscape:connector-curvature="0" style="fill:#7c7ce0;fill-rule:evenodd;stroke-width:0.79288208"></path>
    <path d="M 427.88773,353.66272 H 553.16596 V 468.46329 H 427.88773 Z" id="path4075" inkscape:connector-curvature="0" style="fill:#000000;fill-opacity:0;fill-rule:evenodd"></path>
    <g transform="matrix(0.45555722,0,0,0.45555774,379.83689,353.66273)" id="g4082">
      <clipPath id="p.3">
        <path d="M 0,0 H 275 V 252 H 0 Z" id="path4077" inkscape:connector-curvature="0" style="clip-rule:evenodd"></path>
      </clipPath>
      <image clip-path="url(#p.3)" width="275" height="252" x="0" y="0" preserveAspectRatio="none" xlink:href="https://desfontain.es/privacy/images/magic.gif" id="image4080" style="fill:#000000"></image>
    </g>
    <path d="m 660.00147,264.20093 21.66931,-21.66928 21.66932,21.66928 h -10.83466 v 85.7638 h 10.83466 l -21.66932,21.66928 -21.66931,-21.66928 h 10.83466 v -85.7638 z" id="path4088" inkscape:connector-curvature="0" style="fill:#db4437;fill-rule:evenodd"></path>
    <path d="m 660.00147,264.20093 21.66931,-21.66928 21.66932,21.66928 h -10.83466 v 85.7638 h 10.83466 l -21.66932,21.66928 -21.66931,-21.66928 h 10.83466 v -85.7638 z" id="path4090" inkscape:connector-curvature="0" style="fill-rule:evenodd;stroke:#666666;stroke-width:1;stroke-linecap:butt;stroke-linejoin:round"></path>
    <path d="m 554.53672,285.04017 c 42.66144,-12.09317 85.32288,12.0932 127.98438,0 42.66143,-12.09317 85.32287,12.0932 127.98431,0 l -1.70062,50.79135 c -42.66144,12.09317 -85.32288,-12.09317 -127.98432,0 -42.66143,12.09317 -85.32294,-12.09317 -127.98437,0 z" id="path4092" inkscape:connector-curvature="0" style="fill:#db4437;fill-rule:evenodd"></path>
    <path d="m 587.72404,321.45273 q -0.84375,-0.5 -1.26562,-1.0625 -0.40625,-0.5625 -0.40625,-1.07812 0,-0.67188 0.67187,-1.07813 0.125,-0.0625 0.35938,-0.0625 0.3125,0 0.67187,0.10938 0.375,0.10937 0.57813,0.29687 0.82812,0.76563 1.98437,0.76563 0.5,0 1.46875,-0.21875 1.25,-0.39063 1.96875,-0.95313 0.71875,-0.57812 1.70313,-1.79687 0.60937,-0.79688 0.90625,-1.60938 0.3125,-0.82812 0.3125,-1.5 0,-0.73437 -0.34375,-1.15625 -0.64063,-0.85937 -1.4375,-1.28125 -0.78125,-0.4375 -1.82813,-0.4375 -0.9375,0 -1.82812,0.25 l -1.85938,0.39063 q -0.125,0.0312 -0.34375,0.0469 -0.20312,0.0156 -0.59375,0.95313 -0.375,0.92187 -1.29687,3.51562 -0.67188,1.875 -1.125,2.70313 -0.45313,0.8125 -0.79688,0.8125 -0.39062,0 -0.82812,-0.70313 -0.0937,-0.15625 -0.40625,-0.64062 -0.29688,-0.48438 -0.29688,-0.9375 0,-0.21875 0.15625,-0.53125 0.15625,-0.29688 0.26563,-0.57813 0.10937,-0.29687 0.25,-0.79687 0.40625,-1.25 2.40625,-6.20313 2,-4.96875 3.125,-7.5 0.79687,-1.82812 0.48437,-1.92187 0,-0.0937 -0.10937,-0.28125 -0.0937,-0.20313 -0.0625,-0.29688 0,-0.1875 1.14062,-0.5625 1.14063,-0.39062 1.54688,-0.32812 h 0.20312 q 0.40625,0 0.40625,-0.15625 0.0625,0 0.59375,-0.0625 0.53125,-0.0625 1.14063,0 2.26562,0.1875 3.57812,1.29687 1.3125,1.09375 1.28125,3.23438 -0.0625,0.84375 -0.92187,2.28125 -0.85938,1.4375 -1.89063,2.35937 -0.51562,0.45313 -1.17187,0.95313 -0.65625,0.5 -0.84375,0.625 l 0.79687,0.28125 q 1.5,0.57812 2.32813,1.42187 0.84375,0.82813 1.1875,2.26563 0.0781,0.3125 0.0781,0.57812 0,0.70313 -0.25,1.59375 -0.23437,0.89063 -0.53125,1.5625 -0.1875,0.20313 -0.3125,0.42188 -0.125,0.21875 -0.15625,0.28125 -0.0312,0.14062 -0.57812,0.98437 -0.54688,0.84375 -0.96875,1.35938 -2.10938,1.79687 -3.48438,2.29687 -1.34375,0.60938 -3.20312,0.60938 -1.65625,0 -2.45313,-0.51563 z m 2.29688,-13.26562 q 0.32812,-0.0781 1.28125,-0.28125 0.95312,-0.20313 1.375,-0.35938 0.0625,-0.0312 0.39062,-0.20312 0.34375,-0.1875 0.70313,-0.54688 2.01562,-1.875 2.8125,-3.39062 0.79687,-1.3125 0.79687,-1.84375 0,-0.39063 -0.34375,-0.75 -0.60937,-0.70313 -2.01562,-0.70313 -0.60938,0 -1.03125,0.14063 -0.45313,0.125 -0.65625,0.29687 -0.20313,0.17188 -0.20313,0.53125 0,0.25 -0.17187,0.5625 -0.15625,0.29688 -0.34375,0.48438 -0.0312,0.20312 -0.17188,0.39062 -0.14062,0.1875 -0.21875,0.25 0,0.0781 -0.4375,0.875 -0.42187,0.79688 -0.79687,1.78125 -0.96875,2.28125 -0.96875,2.76563 z m 11.90643,10.29687 q -0.0937,-0.1875 -0.54688,-0.5 -0.45312,-0.32812 -0.45312,-0.39062 0,-0.14063 -0.14063,-0.375 -0.14062,-0.23438 -0.26562,-0.4375 -0.26563,-0.25 0.34375,-1.65625 0.60937,-1.40625 1.64062,-3.32813 0.1875,-0.1875 0.48438,-0.67187 0.3125,-0.48438 0.40625,-0.54688 0,-0.125 0.0937,-0.23437 0.0937,-0.10938 0.23437,-0.10938 l 0.25,-0.51562 q 0.125,-0.29688 1.25,-1.375 1.125,-1.09375 1.76563,-1.46875 0.59375,-0.42188 1.3125,-0.42188 0.76562,0 1.29687,0.45313 l 0.875,0.73437 q 0.95313,0.79688 1.07813,0.92188 l 1.1875,1.0625 -0.54688,1.59375 q -0.28125,0.85937 -0.28125,1.64062 0,1.20313 0.67188,2.26563 0.15625,0.34375 0.42187,0.54687 0.28125,0.1875 0.73438,0.25 0.70312,0.125 0.70312,0.70313 0,0.70312 -0.26562,1.0625 -0.25,0.34375 -0.60938,0.4375 -0.5,0.0781 -0.70312,0.0781 -0.92188,0 -1.6875,-0.48437 -0.76563,-0.48438 -1.34375,-1.64063 -0.125,-0.1875 -0.34375,-0.6875 -0.20313,-0.51562 -0.23438,-0.71875 -0.21875,0.32813 -0.73437,0.84375 -3.29688,3.32813 -5.34375,3.32813 -0.70313,0 -1.25,-0.35938 z m 1.76562,-2.65625 q 0.5,0.0625 1.98438,-1.15625 0.15625,-0.125 0.34375,-0.29687 0.1875,-0.17188 0.42187,-0.375 0.89063,-0.73438 1.39063,-1.21875 0.5,-0.5 1,-1.20313 l 0.70312,-1.15625 q -0.3125,-0.70312 -0.57812,-0.9375 -0.25,-0.25 -0.5,-0.25 -0.64063,0 -1.60938,1.14063 -0.95312,1.14062 -2.29687,3.4375 -0.35938,0.57812 -0.57813,1.20312 -0.21875,0.625 -0.28125,0.8125 z m 14.94391,3.8125 q -0.78125,0 -1.59375,-0.32812 -0.8125,-0.3125 -1.375,-0.78125 -0.5625,-0.46875 -0.5625,-0.84375 0,-0.39063 0.35938,-0.48438 l 0.15625,-0.125 q 0.0625,-0.0312 0.25,-0.0312 0.14062,-0.0312 0.32812,0.0156 0.1875,0.0469 0.3125,0.0469 0.23438,0.0625 0.67188,0.125 l 0.84375,0.0937 q 0.64062,0 1.1875,-0.125 0.5625,-0.125 0.5625,-0.28125 0,-0.10937 -0.25,-0.32812 -0.25,-0.21875 -0.54688,-0.21875 0,-0.125 -0.98437,-0.85938 -0.54688,-0.42187 -1.04688,-0.82812 -0.5,-0.42188 -0.5,-0.625 l 0.0312,-0.0625 v -0.15625 q -0.21875,0 -0.42187,-0.60938 -0.1875,-0.60937 -0.1875,-1.1875 0,-1.07812 0.95312,-2.39062 0.96875,-1.3125 2.39063,-2.35938 1.4375,-1.0625 2.71875,-1.45312 0.46875,-0.21875 1.40625,-0.21875 0.60937,0 0.82812,0.125 l 0.25,-0.0625 q 0.39063,0 1,0.64062 0.60938,0.64063 0.76563,1.01563 0,1.0625 -0.0625,1.70312 -0.0625,0.64063 -0.32813,0.64063 -0.0312,0 -0.0937,0.0312 -0.0625,0.0312 -0.0625,0.15625 0,0.45312 -0.78125,1 -0.78125,0.53125 -1.42187,0.53125 l -0.125,-0.0312 q -0.20313,-0.0312 -0.57813,-0.375 -0.35937,-0.35938 -0.35937,-0.70313 0,-0.0937 0.375,-0.51562 0.39062,-0.42188 0.65625,-0.8125 0.28125,-0.40625 0.28125,-0.85938 0,-0.15625 -0.10938,-0.20312 -0.10937,-0.0469 -0.4375,-0.0469 -1.75,0.79688 -2.51562,1.5 -0.10938,0.20313 -0.1875,0.29688 -0.0781,0.0937 -0.20313,0.0937 0,0 0,-0.0156 0,-0.0156 -0.0312,-0.0156 -0.0625,0 -0.42187,0.375 -0.34375,0.35937 -0.65625,0.84375 -0.29688,0.46875 -0.35938,0.89062 l -0.0625,0.0937 v 0.15625 q -0.0312,0.0625 -0.0312,0.26563 0,0.28125 0.25,0.59375 0.25,0.29687 1.03125,0.84375 1.4375,1.09375 1.95313,1.625 0.53125,0.51562 0.67187,0.9375 0.28125,0.57812 0.28125,1.01562 0,1.09375 -1.14062,1.6875 -1.125,0.59375 -3.07813,0.59375 z m 13.21564,-13.79687 q -0.10937,0.0937 -0.20312,0.0937 -0.125,0 -0.40625,-0.1875 -0.32813,-0.0312 -0.85938,-0.54688 -0.51562,-0.51562 -0.51562,-0.67187 -0.0312,-0.39063 0.0625,-1.10938 0.0937,-0.71875 0.35937,-1.28125 0.28125,-0.57812 0.71875,-0.60937 0.23438,0.0312 0.60938,0.14062 0.39062,0.10938 0.875,0.29688 0.59375,1.21875 0.59375,2.07812 0,1.28125 -1.23438,1.79688 z m -2.95312,13.28125 q -0.76563,0 -1.32813,-0.79688 -0.5625,-0.79687 -0.6875,-1.98437 0.125,-1.1875 0.1875,-1.73438 0.35938,-1.5625 0.89063,-3.6875 0.53125,-2.14062 0.625,-2.35937 0.15625,-0.28125 0.5,-0.28125 0.35937,0 0.78125,0.26562 0.4375,0.26563 0.73437,0.75 0.25,0.35938 0.25,0.79688 0,0.67187 -0.64062,2.82812 -0.4375,1.59375 -0.57813,2.26563 -0.125,0.67187 -0.0937,1.4375 -0.125,1.4375 -0.25,1.98437 -0.125,0.54688 -0.39062,0.51563 z m 6.8189,-0.21875 q -0.95312,0 -1.25,-0.10938 -0.28125,-0.125 -0.70312,-0.5 -0.0937,-0.23437 -0.40625,-0.60937 -0.29688,-0.39063 -0.48438,-0.57813 -0.0937,-0.35937 -0.0937,-0.82812 0,-0.84375 0.23438,-1.95313 0.23437,-1.125 0.59375,-2.04687 0.125,-0.26563 0.20312,-0.48438 0.0781,-0.21875 0.10938,-0.28125 0,-0.23437 0.8125,-1.39062 0.82812,-1.17188 1.3125,-1.625 0.21875,-0.25 0.67187,-0.53125 0.46875,-0.29688 0.82813,-0.42188 0.0937,-0.0312 0.78125,-0.28125 0.6875,-0.26562 1.26562,-0.26562 0.51563,0 1,0.20312 0.5,0.20313 0.82813,0.65625 0.82812,0.82813 0.82812,2.17188 0,0.26562 -0.0625,0.57812 -0.17187,0.64063 -0.67187,1.04688 -0.48438,0.39062 -1.03125,0.39062 -0.54688,0 -0.92188,-0.40625 -0.125,-0.32812 -0.125,-0.42187 0,-0.0937 0.125,-0.54688 0.125,-0.57812 0.125,-0.73437 0,-0.40625 -0.28125,-0.40625 -0.39062,0 -0.625,0.1875 -0.21875,0.1875 -0.82812,0.82812 -0.40625,0.45313 -0.96875,1.29688 -0.5625,0.84375 -0.875,1.60937 -0.29688,0.875 -0.40625,1.25 -0.10938,0.35938 -0.10938,0.42188 0,0.125 -0.0312,0.23437 -0.0312,0.10938 -0.0312,0.25 0,0.21875 0.0937,0.34375 0.0937,0.125 0.34375,0.26563 0.0781,0.0312 0.23438,0.125 0.15625,0.0937 0.3125,0.0937 0.20312,0 0.54687,-0.15625 0.35938,-0.17188 0.45313,-0.20313 0.40625,-0.1875 1.17187,-0.82812 l 0.78125,-0.57813 q 0.21875,-0.15625 0.39063,-0.26562 0.1875,-0.10938 0.28125,-0.15625 0.0937,-0.0469 0.0937,0.0156 0,0.125 0.0937,0.125 0.0937,0 0.21875,-0.125 0.125,-0.20312 0.45312,-0.20312 0.25,0 0.51563,0.15625 0.28125,0.14062 0.28125,0.23437 l -0.0312,0.15625 q 0,0.15625 0.15625,0.32813 0,0.125 -0.0781,0.32812 -0.0781,0.20313 -0.20312,0.34375 -0.32813,0.46875 -0.73438,0.98438 -0.39062,0.51562 -0.54687,0.70312 h -0.0312 q -0.15625,0 -0.45313,0.29688 -0.46875,0.4375 -0.82812,0.4375 -0.125,0.0625 -0.29688,0.15625 -0.15625,0.0781 -0.15625,0.17187 -0.53125,0.54688 -2.875,0.54688 z m 10.59815,-0.32813 q -0.54688,0.125 -1.3125,-0.57812 -0.76563,-0.70313 -0.90625,-1.3125 -0.0625,-0.3125 -0.0625,-0.54688 0,-1.23437 0.79687,-3.01562 0.8125,-1.78125 2.17188,-3.34375 1.35937,-1.5625 2.98437,-2.26563 0.67188,-0.35937 0.85938,-0.35937 0.20312,0 0.875,0.35937 0.64062,0.15625 1.01562,0.34375 0.39063,0.1875 0.70313,0.60938 0.42187,0.82812 0.60937,2.04687 0.20313,0.67188 0.20313,0.95313 0,0.26562 -0.20313,0.45312 -0.0312,0.0312 -0.10937,0.125 -0.0781,0.0937 -0.0781,0.15625 0,0.0469 0.0625,0.0469 0,0.0312 -0.0312,0.14062 -0.0312,0.10938 -0.125,0.29688 -0.39062,1.21875 -0.39062,1.89062 0,0.21875 0.0625,0.54688 0.32812,0.82812 0.8125,0.82812 0.4375,0 1.01562,-0.57812 0.48438,-0.3125 0.96875,-0.3125 0.28125,0 0.28125,0.15625 0.0312,0.0312 0.125,0.0937 0.0937,0.0625 0.1875,0.0625 0.14063,0 0.14063,0.29687 0,0.25 -0.125,0.67188 -0.10938,0.40625 -0.26563,0.67187 -0.21875,0.21875 -0.35937,0.39063 -0.125,0.15625 -0.125,0.25 l -0.46875,0.4375 q -0.60938,0.35937 -1.45313,0.35937 -0.85937,0 -1.375,-0.35937 -0.5,-0.34375 -0.95312,-0.875 -0.45313,-0.53125 -0.57813,-0.9375 l -0.15625,-0.32813 -0.9375,0.60938 -0.79687,0.82812 q -0.25,0.32813 -0.4375,0.32813 h -0.32813 q 0,0.21875 -0.90625,0.54687 -0.89062,0.3125 -1.39062,0.3125 z m 0.67187,-2.6875 q 0.34375,0 1.4375,-0.8125 1.10938,-0.8125 1.5,-1.29687 0.125,-0.15625 0.32813,-0.45313 0.21875,-0.3125 0.375,-0.46875 0.51562,-0.60937 0.75,-0.96875 0.25,-0.375 0.25,-0.73437 0,-0.25 -0.23438,-0.70313 -0.125,-0.39062 -0.375,-0.39062 -0.14062,0 -0.73437,0.23437 -0.60938,0.34375 -1.4375,1.4375 -0.8125,1.07813 -1.42188,2.20313 -0.60937,1.125 -0.60937,1.64062 0,0.0937 0.0625,0.1875 0.0781,0.0937 0.10937,0.125 z m 11.06427,4.21875 q -0.48437,-0.15625 -0.71875,-0.57812 -0.23437,-0.40625 -0.23437,-1.20313 0,-1.3125 0.25,-2.5625 l 0.0312,-0.25 q 0.0312,-0.20312 0.0937,-0.625 0.0625,-0.4375 0.0937,-0.25 l 0.20312,-0.85937 q 0.21875,-0.89063 0.42188,-1.65625 0.21875,-0.78125 0.34375,-1.125 l 0.34375,-1.125 q 0.96875,-3.10938 1.79687,-4.1875 0.0312,-0.125 0.0937,-0.23438 0.0625,-0.125 0.0937,-0.25 0,-0.51562 0.20313,-0.79687 0.28125,-0.48438 0.46875,-0.85938 l 0.14062,-0.35937 0.89063,-1.82813 q 0.0937,-0.3125 0.39062,-0.6875 0.3125,-0.39062 0.625,-0.53125 l -0.0312,-0.0312 q 0.17188,-0.25 0.59375,-0.4375 0.4375,-0.20312 0.75,-0.20312 0.42188,0 0.67188,0.26562 0.26562,0.25 0.26562,0.70313 v 0.3125 q 0,0.29687 -0.0469,0.45312 -0.0469,0.15625 -0.21875,0.39063 h 0.0312 q 0.0469,0.0312 -0.0469,0.20312 -0.0781,0.17188 -0.14062,0.32813 -0.21875,0.57812 -0.3125,0.64062 -0.23438,0.29688 -1.48438,2.71875 -1.23437,2.40625 -1.59375,3.32813 l -0.125,0.48437 -0.0625,0.20313 q -0.35937,0.76562 -0.39062,0.82812 l -0.51563,1.98438 -0.125,0.67187 -0.28125,0.73438 -0.1875,0.60937 q -0.0781,0.15625 -0.125,0.42188 -0.0469,0.25 -0.10937,0.3125 l -0.0312,0.15625 q -0.0312,0.125 -0.21875,0.73437 -0.29688,0.90625 -0.42188,1.5 -0.125,0.57813 -0.15625,1.25 l -0.0312,0.14063 q -0.0937,0.70312 -0.40625,1.04687 -0.29687,0.35938 -0.78125,0.21875 z m 6.82099,-0.59375 q -0.0937,0.0312 -0.26563,0.0312 -0.67187,0 -1.125,-0.76562 -0.4375,-0.78125 -0.4375,-1.96875 0,-0.625 0.125,-1.23438 0.35938,-0.9375 0.35938,-1.34375 0.0937,-0.60937 0.65625,-2.1875 0.5625,-1.59375 0.71875,-1.92187 0.125,0 0.21875,-0.20313 0.0937,-0.20312 0.0937,-0.46875 0,-0.28125 0.10937,-0.57812 0.125,-0.3125 0.25,-0.4375 0,-0.0937 0.0781,-0.34375 0.0781,-0.26563 0.0781,-0.35938 0,-0.0625 0.0781,-0.23437 0.0781,-0.1875 0.0781,-0.28125 0.51563,-0.98438 1.79688,-4.45313 1.28125,-3.48437 1.28125,-3.85937 0,-0.26563 0.1875,-0.48438 0.20312,-0.21875 0.45312,-0.21875 0.0937,-0.10937 0.40625,-0.15625 0.32813,-0.0469 0.51563,-0.0469 l 0.51562,0.51562 q 0.35938,0.32813 0.54688,0.57813 0.1875,0.25 0.1875,0.60937 0,0.57813 -0.20313,1.14063 -0.20312,0.54687 -1.20312,2.625 -0.0625,0.17187 -0.51563,1.15625 -0.3125,0.64062 -0.3125,0.73437 0,0.0937 -0.14062,0.40625 -0.125,0.29688 -0.21875,0.625 -0.25,0.51563 -0.8125,1.8125 -0.5625,1.29688 -0.5625,1.42188 0,0.34375 -0.15625,0.5 -0.0937,0 -0.125,0.15625 -0.0312,0.14062 -0.0312,0.20312 0,0.3125 -0.51563,1.70313 l -0.28125,0.92187 q -0.60937,2.07813 -0.85937,3.04688 -0.23438,0.95312 -0.23438,1.625 0,0.70312 -0.23437,1.15625 -0.21875,0.4375 -0.5,0.57812 z m 13.97729,-12.23437 q 0.29688,0.57812 0.29688,1.3125 0,0.9375 -0.42188,1.53125 -0.3125,0.45312 -0.5625,1.35937 -0.23437,0.89063 -0.45312,2.39063 -0.29688,1.21875 -0.71875,3.75 -0.5,1.34375 -0.625,2.01562 -0.0469,0.1875 -0.3125,0.79688 -0.26563,0.60937 -0.4375,0.95312 -1.4375,2.92188 -3.40625,4.39063 -1.96875,1.46875 -4.01563,1.59375 -0.51562,0.0625 -0.60937,0.0625 -0.28125,0 -0.53125,-0.0937 -0.23438,-0.0937 -0.51563,-0.25 -0.64062,-0.45313 -0.73437,-0.64063 -0.17188,-0.32812 -0.17188,-0.64062 0,-0.48438 0.45313,-0.65625 0.45312,-0.17188 1.03125,-0.17188 0.21875,0.125 0.76562,0.125 0.54688,0 0.64063,-0.125 0.0625,-0.0625 0.375,-0.21875 0.32812,-0.14062 0.73437,-0.23437 1.0625,-0.51563 1.625,-1.03125 0.5625,-0.5 1.23438,-1.625 0.79687,-1.21875 1.04687,-2.20313 0.42188,-1.0625 1,-3.14062 l -0.0312,0.0312 q -0.17187,0.1875 -0.8125,0.5625 -0.625,0.375 -0.76562,0.375 -0.0312,0 -0.0937,0.0312 -0.0625,0.0312 -0.0625,0.125 0,0.125 -0.82813,0.40625 -0.82812,0.26562 -1.0625,0.26562 -0.3125,0 -0.6875,-0.34375 -0.35937,-0.35937 -0.53125,-0.65625 -0.125,-0.28125 -0.46875,-0.57812 -0.39062,-0.375 -0.57812,-0.67188 -0.1875,-0.3125 -0.1875,-0.73437 0,-0.21875 0.0312,-0.34375 0.375,-1.4375 1.40625,-4.42188 1.04687,-3 1.53125,-3.73437 0.125,-0.20313 0.46875,-0.32813 0.35937,-0.125 0.71875,-0.125 0.64062,0 0.85937,0.375 0.39063,0.54688 0.39063,0.9375 0,0.4375 -0.45313,1.3125 -0.125,0.34375 -0.32812,0.76563 -0.1875,0.42187 -0.1875,0.51562 -0.0312,0.125 -0.1875,0.78125 -0.15625,0.65625 -0.28125,0.65625 -0.20313,0.1875 -0.4375,1.32813 -0.23438,1.14062 -0.23438,1.8125 0,0.375 0.0937,0.375 0.85938,0 1.65625,-0.45313 0.79688,-0.46875 1.67188,-1.5 0.125,-0.79687 0.35937,-1.71875 0.25,-0.9375 0.34375,-1.25 0.57813,-1.98437 0.76563,-3.20312 0.1875,-0.45313 0.28125,-0.53125 0.0937,-0.0781 0.42187,-0.0781 0.39063,0 0.84375,0.23438 0.46875,0.21875 0.6875,0.53125 z m 11.99976,13.79687 q -1.25,-0.0312 -1.78125,-0.59375 -0.51563,-0.5625 -0.51563,-1.57812 0,-0.26563 0.0625,-0.84375 0.125,-0.4375 0.1875,-0.89063 0.15625,-0.70312 0.32813,-0.82812 0.0312,-0.0312 0.0625,-0.125 0.0312,-0.10938 -0.0625,-0.17188 0,-0.40625 0.28125,-1.14062 0.0625,-0.23438 0.15625,-0.45313 0.0937,-0.21875 0.14062,-0.28125 -0.0781,-0.0781 -0.0781,-0.20312 0,-0.15625 0.17187,-0.3125 0.1875,-0.15625 0.26563,-0.28125 0.0781,-0.14063 -0.0156,-0.26563 -0.0625,-0.15625 0.60938,-1.4375 0.42187,-0.82812 0.45312,-0.9375 -0.0312,-0.0937 0.45313,-1.17187 0.5,-1.09375 0.79687,-1.64063 0.28125,-0.15625 -0.23437,-0.21875 -0.51563,-0.0625 -1.25,-0.0312 -1.04688,-0.0312 -1.625,-0.10937 -0.57813,-0.0937 -0.9375,-0.28125 -0.21875,-0.21875 -0.21875,-0.57813 0,-0.40625 0.29687,-0.75 0.3125,-0.35937 0.76563,-0.39062 0.82812,-0.0312 2.5625,-0.23438 l 1.625,-0.125 0.0937,-0.54687 q 0.15625,-0.28125 0.29687,-0.48438 0.15625,-0.21875 0.20313,-0.375 0.0469,-0.15625 0.0781,-0.48437 0.0937,-0.125 0.32813,-0.625 0.25,-0.51563 0.3125,-1 0.35937,-0.60938 0.65625,-1.17188 0.29687,-0.5625 0.375,-0.65625 0.5625,-0.85937 1.26562,-0.85937 0.39063,0 0.8125,0.25 0.40625,0.29687 0.625,0.51562 0.23438,0.21875 0.23438,0.60938 0,0.28125 -0.29688,0.82812 -0.125,0.25 -0.375,1.03125 -0.21875,0.28125 -0.48437,0.78125 -0.25,0.5 -0.34375,0.9375 -0.0625,0.15625 -0.20313,0.4375 -0.125,0.26563 -0.17187,0.3125 -0.0469,0.0469 -0.14063,0.0469 0.0312,0.20312 0.125,0.26562 0.0937,0.0625 0.32813,0.0625 0.15625,0 0.39062,-0.0312 0.25,-0.0312 0.59375,-0.0312 0.32813,-0.0312 0.5625,-0.0937 0.23438,-0.0625 0.46875,-0.0625 0.125,0 0.375,0.0937 0.15625,0.1875 0.15625,0.73438 0,0.40625 -0.125,0.78125 -0.125,0.375 -0.3125,0.46875 -0.15625,0.0312 -0.70312,0.1875 -0.54688,0.15625 -1.1875,0.1875 l -1.70313,0.15625 -0.53125,1.09375 q -0.23437,0.39062 -0.39062,0.75 -0.15625,0.34375 -0.21875,0.40625 0,0.15625 -0.26563,0.64062 -0.25,0.48438 -0.375,0.76563 -0.17187,0.45312 -0.39062,0.89062 -0.21875,0.42188 -0.28125,0.54688 -0.0937,0 -0.125,0.0469 -0.0156,0.0469 -0.0156,0.14063 l 0.0781,0.26562 q 0,0.15625 -0.17188,0.3125 -0.125,0.0625 -0.23437,0.23438 -0.10938,0.15625 -0.14063,0.21875 0.0625,0.0625 0.0625,0.15625 0,0.23437 -0.21875,0.57812 0,0.54688 -0.45312,1.625 0.0312,0.57813 0.0625,0.75 0.0312,0.15625 0.15625,0.125 h 0.15625 l 0.70312,-0.0312 q 0.23438,-0.0937 0.10938,0.48438 -0.10938,0.5625 -0.54688,1.75 -0.48437,0.73437 -1.01562,1.29687 -0.51563,0.5625 -0.6875,0.5625 z m 8.84204,-3.14062 q -0.57813,-0.0937 -1.0625,-0.64063 -0.48438,-0.54687 -0.48438,-1.25 0,-0.76562 0.96875,-3.9375 0.15625,-0.82812 0.70313,-2.14062 0.1875,-0.54688 0.21875,-0.64063 0.57812,-1.92187 1.57812,-4.70312 l 0.28125,-0.76563 q 1.125,-3.04687 1.34375,-3.71875 l 0.51563,-1.40625 q 0,-0.25 0.35937,-0.48437 0.375,-0.25 0.625,-0.25 0.51563,0 0.98438,0.67187 0.48437,0.67188 0.51562,1.40625 0,0.39063 -0.15625,0.70313 -0.73437,1.60937 -1.82812,4.96875 -0.46875,1.40625 -0.95313,2.67187 -0.48437,1.26563 -0.76562,1.8125 l -0.35938,0.70313 -0.4375,1.6875 q 0,0.0937 -0.0312,0.17187 -0.0312,0.0625 -0.0312,0.0937 0,0.0937 0.0312,0.0937 l 0.53125,-0.54687 q 0.9375,-0.92188 2.21875,-1.89063 1.04688,-0.73437 1.07813,-0.82812 0.0312,-0.0937 0.26562,-0.29688 l 0.3125,-0.25 q 1.03125,-0.73437 2.21875,-0.73437 0.34375,0 0.82813,0.35937 0.48437,0.34375 0.8125,0.96875 0.34375,0.625 0.34375,1.32813 v 0.25 0.23437 q 0,0.79688 -0.3125,2.09375 -0.29688,1.29688 -0.32813,1.48438 0.15625,0 0.46875,-0.0625 0.48438,0 0.6875,0.0937 0.21875,0.0937 0.375,0.26562 0.15625,0.15625 0.28125,0.1875 0.0625,0.0625 0.0625,0.1875 0,0.73438 -0.79687,1.28125 -0.79688,0.54688 -1.53125,0.60938 -0.89063,0 -1.4375,-0.67188 -0.54688,-0.67187 -0.54688,-1.64062 0,-0.375 0.0312,-0.75 0.0312,-0.39063 0.0625,-0.6875 0.0937,-0.64063 0.0937,-1.01563 0,-0.42187 -0.0781,-0.5625 -0.0781,-0.14062 -0.26563,-0.14062 -0.64062,0 -2.23437,1.17187 -1.57813,1.15625 -3.20313,3.01563 -1.03125,1.5 -1.95312,1.5 z m 17.8548,1.21875 q -1.82813,0 -2.95313,-1.01563 -1.10937,-1.03125 -1.10937,-2.92187 0,-0.73438 0.0937,-1.625 0.0625,-0.78125 0.625,-2.125 0.5625,-1.34375 1.53125,-2.60938 0.96875,-1.28125 2.28125,-1.89062 0.60937,-0.29688 1.03125,-0.40625 0.42187,-0.10938 0.95312,-0.10938 1.3125,0 2.125,0.48438 0.82813,0.46875 1.15625,1.07812 0.34375,0.60938 0.34375,1.0625 v 0.15625 0.0937 q 0,0.39063 -0.45312,1.42188 -0.45313,1.01562 -1.42188,1.92187 -0.96875,0.89063 -2.51562,0.98438 -0.76563,0 -1.48438,-0.14063 -0.71875,-0.15625 -0.90625,-0.15625 -0.48437,0 -0.60937,0.35938 -0.125,0.34375 -0.125,1.1875 0.0937,0.89062 0.48437,1.25 0.40625,0.34375 1.17188,0.34375 0.39062,0 0.89062,-0.21875 0.51563,-0.26563 1.21875,-0.8125 0.39063,-0.3125 0.60938,-0.4375 0.21875,-0.125 0.54687,-0.125 0.28125,0 0.67188,0.39062 0.39062,0.375 0.42187,0.71875 -0.0781,0.39063 -0.71875,1.15625 -0.625,0.76563 -1.65625,1.375 -1.03125,0.60938 -2.20312,0.60938 z m 1.10937,-7.71875 q 0.60938,0 0.84375,-0.125 0.3125,-0.15625 0.96875,-0.8125 0.65625,-0.65625 0.6875,-0.90625 0,-0.32813 -0.28125,-0.53125 -0.26562,-0.20313 -0.73437,-0.28125 h -0.35938 q -0.42187,0 -1.20312,0.70312 -0.78125,0.6875 -1.35938,1.57813 0.0312,0.15625 0.48438,0.26562 0.45312,0.10938 0.95312,0.10938 z m 16.38513,7.90625 q -0.98437,0 -1.85937,-0.4375 -0.85938,-0.45313 -1.375,-1.14063 -0.5,-0.6875 -0.5,-1.35937 0,-0.54688 0.4375,-0.54688 0.29687,0.0625 0.67187,0.35938 0.48438,0.28125 0.8125,0.4375 0.34375,0.15625 0.70313,0.15625 0.53125,0 0.9375,-0.17188 0.40625,-0.17187 0.46875,-0.53125 0,-0.125 -0.14063,-0.54687 -0.125,-0.4375 -0.3125,-0.79688 -0.70312,-1.04687 -0.95312,-2.04687 -0.23438,-1.01563 -0.29688,-2.35938 0,-0.73437 1.0625,-1.75 1.07813,-1.03125 2.5,-1.82812 1.4375,-0.8125 2.32813,-0.90625 1.76562,0 2.10937,0.29687 0.45313,0.34375 0.82813,1.14063 0.39062,0.79687 0.39062,1.34375 0,0.23437 -0.21875,0.57812 -0.20312,0.32813 -0.26562,0.42188 l -0.28125,0.4375 -0.21875,0.48437 q -0.0781,0.15625 -0.21875,0.48438 -0.14063,0.3125 -0.25,0.39062 -0.10938,0.0625 -0.34375,0.0156 -0.53125,0 -0.98438,-0.46875 -0.45312,-0.48438 -0.45312,-1.0625 0,-0.40625 0.28125,-0.82813 0.29687,-0.42187 0.29687,-0.48437 0,-0.125 -0.28125,-0.125 -0.42187,0 -1.29687,0.42187 -0.85938,0.40625 -1.53125,1.09375 -0.67188,0.6875 -0.67188,1.53125 0,0.4375 0.17188,1.03125 0.1875,0.59375 0.40625,0.98438 0.26562,0.25 0.75,1.51562 0.5,1.26563 0.5,2 0,1.125 -0.84375,1.70313 -0.84375,0.5625 -2.35938,0.5625 z m 11.04377,-0.64063 q -0.3125,0.0625 -0.57813,0.0625 -0.40625,0 -0.76562,-0.0781 -0.34375,-0.0781 -0.34375,-0.20313 0,-0.0937 -0.0469,-0.125 -0.0312,-0.0312 -0.125,-0.0312 -0.0937,-0.0937 -0.4375,-0.32812 -0.32812,-0.25 -0.54687,-0.34375 -0.39063,-0.54688 -0.39063,-1.1875 0,-0.60938 0.39063,-1.95313 0.0312,-1.25 0.90625,-2.79687 0.875,-1.54688 2.125,-2.875 1.25,-1.32813 2.25,-1.90625 0.46875,-0.48438 1.34375,-0.48438 0.67187,0 1.1875,0.28125 0.40625,0.26563 1.03125,1.09375 0.625,0.82813 0.9375,1.5 0.0781,0.23438 0.1875,0.625 0.10937,0.375 0.10937,0.92188 l -0.0625,0.89062 q -0.39062,1.3125 -0.39062,2.35938 -0.0625,0.45312 0.0625,0.73437 0.14062,0.26563 0.35937,0.26563 0.15625,0 0.34375,-0.0937 0.20313,-0.0937 0.45313,-0.0937 0.42187,0 0.70312,0.25 0.29688,0.25 0.29688,0.64062 0,0.3125 -0.17188,0.60938 -0.28125,0.64062 -1.0625,1.15625 -0.78125,0.5 -1.45312,0.5 -0.54688,0 -1.04688,-0.5625 -0.5,-0.57813 -0.78125,-1.51563 l -0.1875,-0.73437 -1.15625,1.0625 -0.73437,0.73437 q -0.51563,0.51563 -0.57813,0.60938 -0.15625,0.25 -0.5625,0.48437 -0.40625,0.21875 -1.26562,0.53125 z m 0.85937,-3.0625 q 0.57813,-0.32812 0.96875,-0.79687 0.40625,-0.48438 1.01563,-1.34375 0.14062,-0.20313 0.26562,-0.40625 0.125,-0.20313 0.3125,-0.4375 0.54688,-0.73438 0.78125,-1.17188 0.25,-0.45312 0.375,-0.96875 -0.125,-0.42187 -0.375,-0.78125 -0.23437,-0.375 -0.42187,-0.40625 -0.90625,0 -2.4375,2.10938 -0.15625,0.23437 -0.5,0.8125 -0.32813,0.5625 -0.42188,0.76562 -0.17187,0.21875 -0.4375,1.07813 -0.26562,0.84375 -0.26562,1.09375 0,0.70312 0.40625,0.70312 0.32812,0 0.73437,-0.25 z m 25.32318,0.92188 q 0.21875,0.32812 0.21875,0.60937 0,0.32813 -0.23437,0.57813 -0.21875,0.25 -0.375,0.25 -0.76563,0 -1.71875,-0.35938 -0.9375,-0.375 -0.9375,-1.07812 v -1.98438 q 0,-1.28125 -0.21875,-1.46875 -0.48438,-0.25 -1.28125,0.71875 -0.79688,0.96875 -1.95313,2.89063 -0.45312,0.70312 -0.78125,1.01562 -0.3125,0.29688 -0.5625,0.29688 -0.21875,0 -0.39062,-0.125 -0.98438,-0.28125 -0.98438,-1.125 0,-0.0937 0.0625,-0.40625 0.28125,-1 0.60938,-2.20313 0.34375,-1.21875 0.54687,-2.09375 -0.0937,-0.1875 -0.32812,-0.1875 -0.3125,0 -0.73438,0.32813 -0.125,0.0937 -0.46875,0.29687 -0.32812,0.20313 -0.67187,0.54688 -0.32813,0.32812 -0.6875,0.90625 -0.125,0.23437 -0.4375,0.67187 -1.60938,2.4375 -1.95313,2.75 -0.17187,0.45313 -0.3125,0.64063 -0.14062,0.17187 -0.32812,0.17187 -0.125,0 -0.32813,-0.10937 -0.60937,-0.28125 -0.98437,-0.8125 -0.35938,-0.53125 -0.35938,-1.26563 0,-0.46875 0.28125,-1.90625 0.29688,-1.45312 0.65625,-2.70312 0.25,-0.5 0.39063,-1.0625 0.14062,-0.5625 0.14062,-0.78125 0.10938,-0.60938 0.39063,-1.64063 0.28125,-1.04687 0.42187,-1.15625 0.1875,-0.1875 0.70313,-0.1875 0.34375,0 0.65625,0.14063 0.32812,0.125 0.45312,0.375 0.42188,0.48437 0.42188,1.3125 0,0.76562 -0.3125,1.625 -0.32813,0.73437 -0.8125,2.15625 0,0 0.0625,-0.0781 0.78125,-1.07812 1.98437,-2.42187 0.57813,-0.64063 1.29688,-0.98438 0.71875,-0.35937 1.17187,-0.35937 0.76563,0.125 1.29688,0.75 0.53125,0.625 0.65625,1.70312 0,0.39063 -0.0625,0.95313 -0.0625,0.5625 -0.0937,0.71875 0.125,-0.15625 0.65625,-0.78125 0.53125,-0.625 1.29687,-1.29688 0.70313,-0.54687 1.3125,-0.54687 0.5,0 0.89063,0.42187 0.70312,0.40625 1.09375,1.34375 0.40625,0.92188 0.40625,2.10938 0,0.40625 -0.0312,0.64062 -0.0312,0.21875 -0.0312,0.64063 0,0.4375 0.0937,0.84375 0.10937,0.40625 0.20312,0.71875 z m 4.44238,2.3125 q -1.0625,-0.42188 -1.5625,-1.29688 -0.48437,-0.89062 -0.48437,-2.29687 0,-0.3125 0.0625,-1.15625 0.0312,-0.25 0.0312,-0.59375 0,-0.54688 -0.125,-0.8125 -0.125,-0.28125 -0.45313,-0.57813 -0.0937,-0.0937 -0.45312,-0.40625 -0.34375,-0.32812 -0.3125,-0.48437 v -0.0937 q 0,-0.21875 0.10937,-0.48438 0.10938,-0.28125 0.21875,-0.34375 0.0937,-0.0312 0.375,-0.1875 0.29688,-0.17187 0.45313,-0.10937 0.125,0 0.39062,0.17187 0.28125,0.15625 0.28125,0.28125 0.1875,0.39063 0.98438,-1.25 0.45312,-0.67187 1.21875,-1.32812 0.76562,-0.65625 1.40625,-1 0.23437,-0.10938 1.01562,-0.28125 0.78125,-0.17188 1.23438,-0.17188 0.5,0 1.1875,0.42188 0.6875,0.40625 1.14062,0.89062 0.67188,0.48438 0.67188,1.82813 0,0.79687 -0.25,1.375 -0.125,0.46875 -1.26563,1.45312 -1.14062,0.96875 -1.84375,1.26563 -0.70312,0.15625 -1.5625,0.15625 -0.875,0 -1.1875,-0.15625 -0.21875,-0.125 -0.375,0.10937 -0.14062,0.23438 -0.23437,1.07813 l -0.0312,0.3125 q 0,0.35937 0.15625,0.67187 0.23437,0.39063 0.42187,0.54688 0.1875,0.15625 0.57813,0.15625 l 0.28125,-0.0312 q 0.35937,-0.0312 0.75,-0.34375 0.40625,-0.32813 0.95312,-0.875 0.57813,-0.54688 0.67188,-0.64063 0.15625,-0.3125 0.85937,-0.3125 0.28125,0 0.73438,0.0937 0.32812,0.25 0.32812,0.64063 0,0.54687 -0.51562,1.46875 -0.15625,0.32812 -0.98438,1.09375 -0.8125,0.76562 -1.29687,1.04687 -0.85938,0.48438 -1.90625,0.48438 -0.8125,0 -1.67188,-0.3125 z m 2.375,-7.20313 q 0.76563,-0.20312 1.1875,-0.46875 0.4375,-0.26562 1.01563,-1.07812 0.25,-0.76563 0.0937,-0.92188 -0.1875,-0.1875 -0.45313,-0.1875 -0.3125,0 -0.76562,0.34375 -0.3125,0.0937 -0.875,0.59375 -0.5625,0.5 -0.95313,0.96875 -0.375,0.45313 -0.21875,0.54688 -0.0625,0.10937 0.3125,0.15625 0.39063,0.0469 0.65625,0.0469 z" id="path4094" inkscape:connector-curvature="0" style="fill:#000000;fill-rule:nonzero"></path>
    <path d="M 427.809,138.3307 H 553.08723 V 253.13125 H 427.809 Z" id="path4100" inkscape:connector-curvature="0" style="fill:#000000;fill-opacity:0;fill-rule:evenodd"></path>
    <path d="M 379.751,138.43701 H 505.04235 V 253.24016 H 379.751 Z" id="path4109" inkscape:connector-curvature="0" style="fill:#00fdc8;fill-rule:evenodd"></path>
    <path d="M 379.751,138.43701 H 505.04235 V 253.24016 H 379.751 Z" id="path4111" inkscape:connector-curvature="0" style="fill-rule:evenodd;stroke:#666666;stroke-width:1;stroke-linecap:butt;stroke-linejoin:round"></path>
    <path d="m 299.38583,404.37924 h 70.36065 v -6.68504 l 8.40525,13.37008 -8.40525,13.37007 v -6.68502 h -70.36065 z" id="path4071-3" inkscape:connector-curvature="0" style="fill:#7c7ce0;fill-rule:evenodd;stroke-width:0.79288208"></path>
    <path d="m 506.71874,190.09462 h 70.36065 v -6.68504 l 8.40525,13.37008 -8.40525,13.37007 v -6.68502 h -70.36065 z" id="path4071-6" inkscape:connector-curvature="0" style="fill:#7c7ce0;fill-rule:evenodd;stroke-width:0.79288208"></path>
    <path d="m 506.71875,404.41666 h 70.36065 v -6.68504 l 8.40525,13.37008 -8.40525,13.37007 v -6.68502 h -70.36065 z" id="path4071-6-7" inkscape:connector-curvature="0" style="fill:#7c7ce0;fill-rule:evenodd;stroke-width:0.79288208"></path>
    <flowroot xml:space="preserve" id="flowRoot4272" style="font-style:normal;font-variant:normal;font-weight:normal;font-stretch:normal;font-size:26.66666603px;line-height:1.25;font-family:'Comic Sans MS';-inkscape-font-specification:'Comic Sans MS';text-align:center;letter-spacing:0px;word-spacing:0px;text-anchor:middle;fill:#000000;fill-opacity:1;stroke:none"><flowregion id="flowRegion4274" style="font-style:normal;font-variant:normal;font-weight:normal;font-stretch:normal;font-size:26.66666603px;font-family:'Comic Sans MS';-inkscape-font-specification:'Comic Sans MS';text-align:center;text-anchor:middle"><rect id="rect4276" width="125.97456" height="90.782555" x="379.06781" y="162.45763" style="font-style:normal;font-variant:normal;font-weight:normal;font-stretch:normal;font-size:26.66666603px;font-family:'Comic Sans MS';-inkscape-font-specification:'Comic Sans MS';text-align:center;text-anchor:middle"></rect></flowregion><flowpara id="flowPara4278">Some process</flowpara></flowroot>    <g transform="matrix(0.45555722,0,0,0.45555774,379.751,138.43701)" id="g4082-1" inkscape:transform-center-x="-34.322034" inkscape:transform-center-y="102.9661">
      <clipPath id="clipPath4292">
        <path d="M 0,0 H 275 V 252 H 0 Z" id="path4290" inkscape:connector-curvature="0" style="clip-rule:evenodd"></path>
      </clipPath>
      <image clip-path="url(#p.3-4)" width="275" height="252" x="0" y="0" preserveAspectRatio="none" xlink:href="https://desfontain.es/privacy/images/magic.gif" id="image4080-3" style="fill:#000000"></image>
    </g>
    <rect style="fill:#ffffff" id="rect148" width="28.983051" height="45.762711" x="212.03391" y="388.22034"></rect>
  </g>
</svg>
</center>
<p>By "basically the same", I don't mean "it looks a bit similar". Instead,
remember that the magic you added to the process was <em>randomized</em>. You don't
always get the same output if you run the new process several times. So what
does "basically the same" means in this context? That the <em>probability
distributions</em> are similar. You can get the <em>exact same</em> output with database 1
or with database 2, with similar likelihood.</p>
<p>What does this have to do with privacy? Well, suppose you're a creepy person
trying to figure out whether your target is in the original data. By looking at
the output, you can't be 100% certain of anything. Sure, it could have come from
a database with your target in it. But it could also have come from the exact
same database, without your target. Both options have a similar probability, so
there's not much you can say.</p>
<p>You might have noticed that this definition is not like the ones we've seen
before. We're not saying that the output data satisfies differential privacy.
We're saying that the <em>process</em> does. This is very different from <span>\(k\)</span>-anonymity
and other definitions we've seen. There is no way to look at data and determine
whether it satisfies differential privacy. You have to know the <em>process</em> to
know whether it is "anonymizing" enough.</p>
<p>And that's about it. It's a tad more abstract than other definitions we've seen,
but not that complicated. So, why all the hype? What makes it so awesome
compared to older, more straightforward definitions?</p>

<p>Privacy experts, especially in academia, are enthusiastic about differential
privacy. It was first proposed by Cynthia Dwork, Frank McSherry, Kobbi Nissim
and Adam Smith in 2006<sup id="fnref:papers"><a href="#fn:papers" rel="footnote">1</a></sup>. Very soon, almost all researchers working on
anonymization started building differentially private algorithms. And, as we've
already mentioned, tech companies are also trying to use it whenever possible.
So, why all the hype? I can count three main reasons.</p>
<h2 id="you-no-longer-need-attack-modeling">You no longer need attack modeling</h2>
<p>Remember the previous definitions we've seen? (If not, you're fine, just take my
word for it&nbsp;:D) Why did we need <a href="https://desfontain.es/privacy/k-map.html"><span>\(k\)</span>-map</a> in certain cases, and
<a href="https://desfontain.es/privacy/k-anonymity.html"><span>\(k\)</span>-anonymity</a> or <a href="https://desfontain.es/privacy/delta-presence.html"><span>\(\delta\)</span>-presence</a> in others? To choose the right one,
we had to figure out the attacker's <em>capabilities</em> and <em>goals</em>. In practice,
this is pretty difficult. You might not know exactly what your attacker is
capable of. Worse, there might be <em>unknown unknowns</em>: attack vectors that you
hadn't imagined at all. You can't make very broad statements when you use
old-school definitions. You have to make some assumptions, which you can't be
100% sure of.</p>
<p>By contrast, when you use differential privacy, you get two awesome guarantees.</p>
<ol>
<li>You protect <em>any kind of information about an individual</em>. It doesn't matter
   what the attacker wants to do. Reidentify their target, know if they're in
   the dataset, deduce some sensitive attribute… All those things are protected.
   Thus, you don't have to think about the goals of your attacker.</li>
<li>It works <em>no matter what the attacker knows about your data</em>. They might
   already know some people in the database. They might even add some fake users
   to your system. With differential privacy, it doesn't matter. The users that
   the attacker doesn't know are still protected.</li>
</ol>
<h2 id="you-can-quantify-the-privacy-loss">You can quantify the privacy loss <a name="quantify"></a></h2>
<p>We saw that when using <span>\(k\)</span>-anonymity, <a href="https://desfontain.es/privacy/k-anonymity.html#how-to-choose-k">choosing the parameter</a> <span>\(k\)</span> is pretty
tricky. There is no clear link between which <span>\(k\)</span> to choose and how "private" the
dataset is. The problem is <a href="https://desfontain.es/privacy/l-diversity.html#the-bad-news-policy">even worse</a> with other definitions. This problem is
present in all other definitions we've seen so far.</p>
<p>Differential privacy is much better. When you use it, you can quantify the
<em>greatest possible information gain</em> by the attacker. The corresponding
parameter, usually named <span>\(\varepsilon\)</span>, allows you to make very strong statements.
Suppose <span>\(\varepsilon=1.1\)</span>. Then, you can say: "an attacker who thinks their target
is in the dataset with probability 50% can increase their level of certainty to
at most 75%."</p>
<p>And do you remember the previous point about attack modeling? It means you can
change this statement in many ways. You can replace "their target is is the
dataset" by anything about one individual. And you can add "no matter what the
attacker knows" if you want to be extra-precise. Altogether, that makes
differential privacy much stronger than all definitions that came before.</p>
<h2 id="you-can-compose-multiple-mechanisms">You can compose multiple mechanisms <a name="composition"></a></h2>
<p>Suppose you have some data. You want to share it with Alex and with Brinn, in
some anonymized fashion. You trust Alex and Brinn equally, so you use the same
definition of privacy for both of them. They are not interested in the same
aspects of the data, so you give them two different versions of your data. Both
versions are "anonymous", for the definition you've chosen.</p>
<p>What happens if Alex and Brinn decide to conspire, and compare the data you gave
them? Will the union of the two anonymized versions still be anonymous? It turns
out that for most definitions of privacy, this is not the case. If you put two
<span>\(k\)</span>-anonymous versions of the same data together, the result won't be
<span>\(k\)</span>-anonymous. So if Alex and Brinn conspire, they might be able to reidentify
users on their own… or even reconstruct all the original data! That's definitely
not good news.</p>
<p>If you used differential privacy, you get to avoid this type of scenario.
Suppose that you gave differentially private data to Alex and Brinn. Each time,
you used a parameter of <span>\(\varepsilon\)</span>. Then if they conspire, the resulting data
is still protected by differential privacy, except that the privacy is now
weaker: the parameter becomes <span>\(2\varepsilon\)</span>. So they gain something, but you
still quantify how much information they got. Privacy experts call this property
<em>composition</em>.</p>
<p>This scenario sounds a bit far-fetched, but composition is super useful in
practice. Organizations often want to do many things with data. Publish
statistics, release an anonymized version, train machine learning algorithms…
Composition is a way to stay in control of the level of risk as new use cases
appear and processes evolve.</p>

<p>I hope the basic intuition behind differential privacy is now clear. Want a
one-line summary? Uncertainty in the process means uncertainty for the attacker,
which means better privacy.</p>
<p>I also hope that you're now wondering <em>how it actually works</em>! What hides behind
this magic that makes everything private and safe? Why does differential privacy
have all the awesome properties I've mentioned? What a coincidence! That's the
topic of a <a href="https://desfontain.es/privacy/differential-privacy-in-more-detail.html">follow-up article</a>, which tries to give more details while still
staying clear of heavy math.</p>


  </div></div>]]>
            </description>
            <link>https://desfontain.es/privacy/differential-privacy-awesomeness.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23878536</guid>
            <pubDate>Sat, 18 Jul 2020 02:59:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Computation Graphs and Graph Computation]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23878381">thread link</a>) | @bmc7505
<br/>
July 17, 2020 | http://breandan.github.io/2020/06/30/graph-computation/ | <a href="https://web.archive.org/web/*/http://breandan.github.io/2020/06/30/graph-computation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <p><span>30 Jun 2020</span></p><p>Research has begun to reveal many algorithms can be expressed as matrix multiplication, suggesting an unrealized connection between linear algebra and computer science. I speculate graphs are the missing piece of the puzzle. Graphs are not only useful as cognitive aides, but are suitable data structures for a wide variety of tasks, particularly on modern parallel processing hardware.</p>

<p>In this essay, I explore the virtues of graphs, algebra, types, and show how these concepts can help us reason about programs. I propose a computational primitive based on graph signal processing, linking software engineering, graphs, and linear algebra. Finally, I share my predictions for the path ahead, which I consider to be the start of an exciting new chapter in computing history.</p>

<p><em>n.b.: None of these ideas are mine alone. Shoulders of giants. Follow the links and use landscape mode for optimal reading experience.</em></p>

<ul>
  <li><a href="#new-decade-new-delusions">Biographical details</a></li>
  <li><a href="#what-are-graphs">Graph applications</a></li>
  <li><a href="#induction-introduction">Inductive languages</a></li>
  <li><a href="#graphs-inductively">Inductive graphs</a></li>
  <li><a href="#graph-computation/#graph-languages">Graph languages</a></li>
  <li><a href="#graphs-computationally">Dynamical systems on graphs</a></li>
  <li><a href="#graphs-efficiently">Efficient implementations</a></li>
  <li><a href="#programs-as-graphs">Partial evaluation and program synthesis</a></li>
  <li><a href="#roadmap">Future roadmap</a></li>
</ul>



<p>Over the last decade, I bet on some strange ideas. A lot of people I looked up to at the time laughed at me. I’ll bet they aren’t laughing anymore. I ought to thank them one day, because their laughter gave me a lot of motivation. I’ve said some idiotic things to be sure, but I’ve also made some laughable predictions that were correct. Lesson learned: aim straighter.</p>

<p>In 2012, I was in Austin sitting next to an ex-poker player named <a href="https://twitter.com/amirpc">Amir</a> who was singing Hinton’s praises. Hypnotized by his technicolor slides, I quit my job in a hurry and started an educational project using speech recognition and restricted Boltzmann machines. It never panned out, but I learned a lot about ASR and Android audio. Still love <a href="http://breandan.net/2014/02/09/the-end-of-illiteracy/">that idea</a>.</p>

<center>
<a href="https://www.cs.toronto.edu/~hinton/csc2535/notes/lec4new.pdf"><img width="75%" src="http://breandan.github.io/images/rbm.png"></a>
</center>

<p>In 2017, I started writing a book on the ethics of automation and <a href="http://breandan.net/2017/02/02/trust-in-automation/">predicted</a> mass unemployment and social unrest. Although I got the causes wrong (pandemic, go figure), the information economy and confirmation bias takes were all dead right. Sadly, this is now driving the world completely insane. Don’t say I warned you, go out and fix our broken systems. The world needs more engineers who care.</p>

<center>
<a href="https://colah.github.io/posts/2015-09-NN-Types-FP/"><img width="75%" src="http://breandan.github.io/images/diff_prog.png"></a>
</center>

<p>In 2017, I witnessed the birth of <a href="https://colah.github.io/posts/2015-09-NN-Types-FP/">differentiable programming</a>, which I stole from Chris Olah and turned into a <a href="https://github.com/breandan/kotlingrad/blob/master/latex/thesis/thesis.pdf">master’s thesis</a>. Had a lot of trouble convincing people that classical programs could be made differentiable, but look at the proceedings of any machine learning conference today and you’ll find dozens of papers on differentiable sorting and rendering and simulation. Don’t thank me, thank Chris and the Theano guys.</p>

<p>In 2018, I correctly predicted Microsoft would acquire GitHub to mine code. Why MS and not Google? I’ll bet they tried, but Google’s leadership had fantasies of AGI and besides JetBrains, MS were the only ones who gave a damn about developers. Now ML4SE is a thriving <a href="https://ml4se.github.io/">research area</a> and showing up in <a href="https://github.com/JetBrains-Research/DeepBugsPlugin">real</a> <a href="https://devblogs.microsoft.com/visualstudio/ai-assisted-intellisense-for-your-teams-codebase/">products</a>, much to the chagrin of those who believed ML was a fad. I suspect their hype filter blinded them to the value those tools provide.</p>

<center>
<blockquote><p lang="en" dir="ltr">Prediction: MS will acquire GH within five years. If the <a href="https://twitter.com/hashtag/ML4Code?src=hash&amp;ref_src=twsrc%5Etfw">#ML4Code</a> stuff delivers for MS, acquisition is highly likely. Although it would have been cheaper a few years ago. <a href="https://t.co/5ZMtiRtifD">https://t.co/5ZMtiRtifD</a> <a href="https://t.co/TaxkArm5ps">https://t.co/TaxkArm5ps</a></p>— breandan (@breandan) <a href="https://twitter.com/breandan/status/993553301927936001?ref_src=twsrc%5Etfw">May 7, 2018</a></blockquote> 

<a href="https://blogs.microsoft.com/blog/2018/10/26/microsoft-completes-github-acquisition/">
<img width="75%" src="http://breandan.github.io/images/microsoft_github_aquisition.png"></a>
</center>

<p>But to heck with everything I’ve said! If I had just one idea to share with these ML people, it would be types. Beat that drum as loud as I could. Types are the best tool we know for synthetic reasoning. If you want to build provably correct systems that scale on real-world applications, use types. Not everyone is convinced yet, but mark my words, <a href="https://github.com/tensorflow/tensorflow/issues/12345">types</a> are <a href="https://docs.python.org/3.9/whatsnew/3.9.html#pep-585-builtin-generic-types">coming</a>. Whoever figures out how to connect types and learning will be the next Barbara Liskov or Frances Allen.</p>

<p>This year, I predicted the pandemic weeks before the lockdown, exited the market, and turned down a job at Google. Some people called me crazy. Now I’m going all-in on some new ideas (none of which are mine). I’m making some big bets and some will be wrong, but I see the very same spark of genius in them.</p>



<p>As a kid, I was given a book on the history of mathematics. I remember it had some interesting puzzles, including one with <a href="https://en.wikipedia.org/wiki/Seven_Bridges_of_K%C3%B6nigsberg">some bridges</a> in a town divided by rivers, once inhabited by a man called Euler. Was there a tour crossing each bridge exactly once? Was it possible to tell without checking every path? I remember spending days trying to figure out the answer.</p>

<center>
<a href="https://en.wikipedia.org/wiki/Seven_Bridges_of_K%C3%B6nigsberg"><img width="60%" src="http://breandan.github.io/images/konigsberg_bridges.png"></a>
</center>

<p>In the late 90s, my mom and I went to Ireland. I remember visiting Trinity College, and learning about a mathematician called <a href="https://en.wikipedia.org/wiki/William_Rowan_Hamilton">Hamilton</a> who discovered a famous formula connecting algebra and geometry, and carved it onto a <a href="https://en.wikipedia.org/wiki/Broom_Bridge">bridge</a>. We later visited the bridge, and the tour guide pointed out the stone, which we touched for good luck. The Irish have a <a href="https://en.wikipedia.org/wiki/Poulnabrone_dolmen">thing</a> for <a href="https://en.wikipedia.org/wiki/Newgrange">stones</a>.</p>

<center>
<a href="http://www.kurims.kyoto-u.ac.jp/EMIS/classics/Hamilton/PRIAIcos.pdf"><img width="40%" src="http://breandan.github.io/images/quaternions.jpg"></a>
</center>

<p>In 2007, I was applying to college and took the train from Boston to South Bend, Indiana, home of the Fighting Irish. Wandering about, I picked up a magazine article by a Hungarian mathematician called <a href="https://en.wikipedia.org/wiki/Albert-L%C3%A1szl%C3%B3_Barab%C3%A1si">Barabási</a> then at Notre Dame, who had some interesting things to say about <a href="https://en.wikipedia.org/wiki/Complex_network">complex networks</a>. Later in 2009, while studying in Rochester, I <a href="http://breandan.github.io/images/complex_network_seminar.png">carpooled</a> with a <a href="https://avesis.medeniyet.edu.tr/hasan.guclu">nice professor</a>, and learned complex networks are found in brains, languages and many marvelous places.</p>

<center>
<a href="https://barabasi.com/f/226.pdf"><img width="75%" src="http://breandan.github.io/images/complex_networks.png"></a>
</center>

<p>Fast forward to 2017. I was lured by the siren song of algorithmic differentiation. Olivier Breleux presented <a href="https://github.com/mila-iqia/myia">Myia</a> and <a href="https://github.com/breuleux/buche">Buche</a>. Matt Johnson gave a talk on <a href="https://github.com/HIPS/autograd">Autograd</a>. I met Chris Olah in Long Beach, who gave me the idea to study <a href="https://colah.github.io/posts/2015-09-NN-Types-FP/">differentiable programming</a>. I stole his idea, dressed it up in Kotlin and traded it for a POPL workshop paper and later a <a href="https://github.com/breandan/kotlingrad/blob/master/latex/thesis/thesis.pdf">Master’s thesis</a>. Our contributions were using algebra, shape inference and presenting AD as term rewriting.</p>

<center>
<a href="https://github.com/breandan/kotlingrad#dataflow-graphs"><img width="75%" src="https://github.com/breandan/kotlingrad/raw/master/samples/src/main/resources/dataflow.svg"></a>
</center>

<p>In 2019, I joined a lab with a <a href="https://www.cs.mcgill.ca/~jguo/">nice professor</a> at McGill applying knowledge graphs to software engineering. Like logical reasoning, knowledge graphs are an idea from the first wave of AI in the 1960s and 70s which have been revived and studied in light of recent progress in the field. I believe this is an important area of research with a lot of potential. Knowledge and traceability plays a big role in software engineering, and it’s the bread-and-butter of a good IDE. The world needs better IDEs if we’re ever going to untangle this mess we’re in.</p>

<center>
<a href="https://structurizr.com/"><img width="45%" src="https://raw.githubusercontent.com/cecuesta/structurizr-java/master/docs/images/graphviz-spring-petclinic-components.png"></a>
</center>

<p>This Spring, I took a fascinating seminar on <a href="https://cs.mcgill.ca/~wlh/comp766/index.html">Graph Representation Learning</a>. A lot of delightful graph theory has been worked out over the last decade. <a href="https://en.wikipedia.org/wiki/PageRank">PageRank</a> turned into power iteration. People have discovered many interesting connections to linear algebra, including Weisfeiler-Lehman graph kernels, graph Laplacians, Krylov methods, and spectral graph theory. These ideas have deepened our understanding of graph signal processing and its applications for learning and program analysis. More on that <a href="#graphs-computationally">later</a>.</p>



<p>Graphs are general-purpose data structures used to represent a variety of data types and procedural phenomena. Unlike most sequential languages, graphs are capable of expressing a much richer family of relations between entities, and are a natural fit for many problems in computer science, physics, biology and mathematics. Consider the following hierarchy of data structures, all of which are graphs with increasing expressive power:</p>

<ul>
  <li><strong>Sets</strong>: datasets, multisets, posets, alphabets</li>
  <li><strong>Sequences</strong>: Lists, strings, arrays, linear function composition</li>
  <li><strong>Trees</strong>: <a href="https://en.wikipedia.org/wiki/Abstract_syntax_tree">Abstract syntax</a>, <a href="https://en.wikipedia.org/wiki/Document_Object_Model">XML</a>, <a href="https://en.wikipedia.org/wiki/Phylogenetic_tree">phylogeny</a>, <a href="https://en.wikipedia.org/wiki/Decision_tree">decision trees</a></li>
  <li><strong>DAGs</strong>: <a href="https://eagain.net/articles/git-for-computer-scientists/">Git</a>, <a href="https://en.wikipedia.org/wiki/Citation_network">citations</a>, <a href="https://en.wikipedia.org/wiki/Dependency_graph">dependency graphs</a>, <a href="https://en.wikipedia.org/wiki/Workflow_management_system">workflows</a>, <a href="https://en.wikipedia.org/wiki/Control-flow_graph">control flow</a>, <a href="https://en.wikipedia.org/wiki/Multilayer_perceptron">MLPs</a></li>
  <li><strong>Directed graphs</strong>: <a href="https://en.wikipedia.org/wiki/Finite-state_machine">State machines</a>, <a href="http://dkeenan.com/Lambda/">λ-calculus</a>, <a href="https://computersciencewiki.org/index.php/The_web_as_a_directed_graph">the web</a>, <a href="https://en.wikipedia.org/wiki/Call_graph">call graphs</a>, <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">RNNs</a></li>
  <li><strong>Hypergraphs</strong>: <a href="https://arxiv.org/pdf/2003.02320.pdf">Knowledge</a>, <a href="https://zettelkasten.de/">Zettelkasten</a>, <a href="https://en.wikipedia.org/wiki/Category_theory">categories</a>, <a href="https://writings.stephenwolfram.com/2020/04/finally-we-may-have-a-path-to-the-fundamental-theory-of-physics-and-its-beautiful/">physics</a>, <a href="https://openreview.net/pdf?id=rkpACe1lx">hypernetworks</a></li>
</ul>

<p>As we realized in <a href="https://github.com/breandan/kotlingrad">Kotlin∇</a>, directed graphs can be used to model mathematical expressions, as well as other formal languages, including source code, intermediate representations and binary artifacts. Not only can graphs be used to describe extant human knowledge, many recent examples have shown that machines can “grow” trees and graphs for various applications, such as program synthesis, mathematical deduction and physical simulation. Recent neuro-symbolic applications have shown promising early results in graph synthesis:</p>

<ul>
  <li><a href="https://arxiv.org/pdf/1711.00740.pdf">Learning to Represent Programs with Graphs</a>, Allamanis et al., 2018</li>
  <li><a href="https://arxiv.org/pdf/1912.01412.pdf">Deep Learning for Symbolic Mathematics</a>, Lample and Charton, 2019.</li>
  <li><a href="https://arxiv.org/pdf/2006.11287.pdf">Discovering Symbolic Models from Deep Learning with Inductive Biases</a>, Cranmer et al., 2020.</li>
  <li><a href="https://arxiv.org/pdf/2005.11212.pdf">Symbolic Pregression: Discovering Physical Laws from Raw Distorted Video</a> (Udrescu &amp; Tegmark, 2020).</li>
  <li><a href="https://arxiv.org/pdf/2006.08381.pdf">DreamCoder: Growing generalizable, interpretable knowledge with wake-sleep Bayesian program learning</a>, Ellis et al., 2020.</li>
  <li><a href="https://arxiv.org/abs/2007.03629">Strong Generalization and Efficiency in Neural Programs</a>, Li et al., 2020.</li>
  <li><a href="https://arxiv.org/pdf/1910.10593.pdf">Neural Execution of Graph Algorithms</a>, Veličković et al. (2020)</li>
</ul>

<p>The field of natural language processing has also developed a rich set of graph-based representations, such as <a href="https://en.wikipedia.org/wiki/Phrase_structure_grammar">constituency</a>, <a href="https://en.wikipedia.org/wiki/Dependency_grammar">dependency</a>, <a href="https://en.wikipedia.org/wiki/Link_grammar">link</a> and other and other typed attribute grammars which can be used to reason about syntactic and semantic relations between natural language entities. Research has begun to show many practical applications for such grammars in the extraction and organization of human knowledge stored in large text corpora. Those graphs can be further processed into ontologies for logical reasoning.</p>

<center>
<img width="60%" src="https://upload.wikimedia.org/wikipedia/commons/8/8e/Thistreeisillustratingtherelation%28PSG%29.png">
</center>

<p>Using coreference resolution and entity alignment techniques, we can reconstruct internally consistent relations between entities, which capture cross-corpus consensus in natural language datasets. When stored in <a href="https://arxiv.org/pdf/2003.02320.pdf">knowledge graphs</a>, these relations can be used for information retrieval and question answering, e.g. on wikis and other content management systems. Recent techniques have shown promise in automatic knowledge base construction (cf. <a href="https://www.mitpressjournals.org/doi/pdf/10.1162/tacl_a_00088">Reddy et al.</a>, 2016).</p>

<!--![logical_forms](/images/logical_forms.png) -->
<center>
<a href="https://arxiv.org/pdf/2003.02320.pdf"><img width="75%" src="http://breandan.github.io/images/knowledge_graph.png"></a>
</center>

<p>Lo and behold, the key idea behind knowledge graphs is our old friend, types. Knowledge graphs are multi-relational graphs whose nodes and …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://breandan.github.io/2020/06/30/graph-computation/">http://breandan.github.io/2020/06/30/graph-computation/</a></em></p>]]>
            </description>
            <link>http://breandan.github.io/2020/06/30/graph-computation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23878381</guid>
            <pubDate>Sat, 18 Jul 2020 02:20:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Birds, Planes, and Covid’s Chokepoint]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23878263">thread link</a>) | @secondbreakfast
<br/>
July 17, 2020 | https://secondbreakfast.co/birds-planes-and-covid-s-chokepoint | <a href="https://web.archive.org/web/*/https://secondbreakfast.co/birds-planes-and-covid-s-chokepoint">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>On January 22, 1970, a Pan Am Boeing 747 touched down at Heathrow for the first time.<a href="#footnote-10TY" id="ref-10TY"><sup>1</sup></a> It was the 747’s first commercial flight. At the time, British Airways had 11 of the jumbo jets on order.</p>
<p>I’ve always wanted to ride on one. I’m too late.</p>
<p>British Airways announced yesterday they’re retiring their entire 747 fleet. Permanently. Its cousins are also in trouble: the double-decker <span>A380</span> is grounded worldwide.</p>
<p>Landing slots at Heathrow are scarce. In 2016, Oman Air bought a single morning slot from Air France for $75 million. So while the 777, <span>A340</span>, and 787 use less than half the fuel per passenger to fly, airlines need jumbo jets to maximize passenger throughput.</p>
<p>Nowadays double-deckers are merely a waste of fuel. Just like a species facing an extinction event, the 747 got wiped out by an economic chokepoint.</p>
<p>Intelligent-designers often cite gaps in the archaeological record as evidence against natural selection. <em>If evolution inched along slowly</em>, they argue, <em>where are the fossils of almost-humans, and almost-almost-humans, and almost-almost-almost humans? Shouldn’t we find skulls of humans with tiny eyes, slightly-less-tiny eyes, all the way up to regular-sized eyes?</em></p>
<p>But evolution doesn’t crawl along in a straight line. Adaptation happens slowly, and then all at once. Chokepoints force the<span></span> <span>“</span>all at once.”</p>
<p>For example, birds in Britain and Denmark have been under attack by asphalt for a century. In Britain, it’s popular to load birdseed into birdfeeders and place them in gardens. Not so in Denmark. Within 40 years, the beaks of British birds have grown 1-2mm longer than their Danish counterparts.<a href="#footnote-20TY" id="ref-20TY"><sup>2</sup></a></p>
<p>For millennia the beaks have stayed the same. And then asphalt, in a mere half century, forced British bird beaks to grow up to 10% longer.</p>
<p>Business follows the same pattern. Innovation prods along slowly. And then one day the economy’s equilibrium gets punctured.</p>
<p>We are in one of those economic chokepoints. The 747 and <span>A380</span> are collateral damage.</p>
<p>What else is facing evolutionary death because of COVID?</p>
<p>It might be better to invert that question. What types of businesses will survive despite COVID? What traits do those businesses have that will spread like memes throughout the economy?</p>
<section>
<hr>
<ol>
<li id="footnote-10TY"><p><a href="http://news.bbc.co.uk/onthisday/hi/dates/stories/january/22/newsid_3725000/3725963.stm">http://news.bbc.co.uk/onthisday/hi/dates/stories/january/22/newsid_3725000/3725963.stm</a><a href="#ref-10TY">↩</a></p></li>
<li id="footnote-20TY"><p><a href="https://www.theguardian.com/environment/2017/oct/19/british-birds-evolve-bigger-beaks-to-use-garden-feeders">https://www.theguardian.com/environment/2017/oct/19/british-birds-evolve-bigger-beaks-to-use-garden-feeders</a><a href="#ref-20TY">↩</a></p></li>
</ol>
</section>
</div></div>]]>
            </description>
            <link>https://secondbreakfast.co/birds-planes-and-covid-s-chokepoint</link>
            <guid isPermaLink="false">hacker-news-small-sites-23878263</guid>
            <pubDate>Sat, 18 Jul 2020 01:53:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The KyoAni I Felt: The kind touch of K-On and the studio behind it]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23878201">thread link</a>) | @TheAsprngHacker
<br/>
July 17, 2020 | https://dosaylazy.github.io/blog/kyoani-one-year-later.html | <a href="https://web.archive.org/web/*/https://dosaylazy.github.io/blog/kyoani-one-year-later.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
   <section>
    
    <p>
     The kind touch of K-On and the studio behind it
    </p>
    <center>
     July 17, 2020
    </center>
    <figure>
     <video autoplay="" controls="" loop="">
      <source src="https://dosaylazy.github.io/blog/k-on/tenshi-aftermath.mp4" type="video/mp4">
      Your browser does not support the video tag.
     </video>
     <figcaption>
      From left to right: Ritsu, Mugi, Azusa, Yui, Mio
  (Source:
  <a href="https://www.sakugabooru.com/post/show/124436">Sakugabooru</a>)
     </figcaption>
    </figure>
    <p>
     Almost a year has passed since the devastating firebombing of Kyoto Animation
that murdered thirty-six employees and harmed many others. Kyoto Animation,
affectionately known as KyoAni, is an anime studio that has earned the love of
countless fans, and I am proud to include myself among them. KyoAni receives the
devotion it does because it has changed lives for the better, and every KyoAni
fan probably has a story to tell. I first came to know KyoAni from <em>K-On</em>, a
heartfelt show capturing the nostalgic innocence of adolescence through the
youthful adventures of five girls in a band. <em>K-On</em> taught me to appreciate the
fleeting moments of life, and it will always hold a special place in my heart.
    </p>
    <p>
     <em>K-On</em> is an anime created by Kyoto Animation under director Naoko Yamada and
screenwriter Reiko Yoshida, adapted from a manga by Kakifly. <em>K-On</em> follows the
five members of the Sakuragaoka Girls' School's Light Music Club, or <em>keionbu</em>:
Yui Hirasawa on lead guitar, Mio Akiyama on bass, Ritsu Tainaka on drums, Mugi
Kotobuki on keyboard, and their underclassman Azusa Nakano on rhythm guitar.
Over their three years of high school, the girls connect over school life, band
practice, and after-school tea time in the music room, and they become tight
friends.
    </p>
    <figure>
     <video autoplay="" controls="" loop="">
      <source src="https://dosaylazy.github.io/blog/k-on/s2-first-scene.mp4" type="video/mp4">
      Your browser does not support the video tag.
     </video>
     <figcaption>
      The girls reunite on the way to school, ready for their last year together
  (Source:
  <a href="https://www.sakugabooru.com/post/show/12005">Sakugabooru</a>)
     </figcaption>
    </figure>
    <p>
     Truthfully, <em>K-On</em>'s first season is merely mediocre: enjoyable, but not
memorable. <em>K-On</em>'s second season, which depicts senior year for Yui, Mio,
Ritsu, and Mugi, is where it really shines as a poignant tale of friendship and
adolescence. When the girls reunite and banter in the music room before class on
their first day back, you get the feeling that they've all been friends since
forever. However, right from the get-go, there is a tone shift: the atmosphere
is melancholy as the friends plan their exciting year ahead, their last year
together. Time seems to pass slowly as the <em>keionbu</em> spends its remaining months
together bonding even closer, with a field trip to Kansai, a school play of
Romeo and Juliet, and one last school festival performance before graduation.
<em>K-On</em> reminds us to cherish our youth and our time with friends: these days are
limited. However, if we make the most of our time together, even after we go our
separate ways we'll still have the warmth of all the fond memories.
    </p>
    <p>
     I first watched <em>K-On</em> in my junior year of high school. Before, I didn't care
to make memories. I was obsessed with programming language theory and
constructive mathematics, and I single-mindedly focused on learning higher-level
math on my own. I was eager to leave high school so I could study my passions
in college, and I was even thinking about graduate school! However, after I
watched the <em>keionbu</em> spend its carefree days together before saying goodbye, I
felt intense regret and asked myself: How had I been spending my own high school
days? <em>K-On</em> made me realize that I was growing up too fast, there was more to
life than just math, and I was missing out on a lot of memories in a chapter of
life that I would never experience again. First, I wanted to join a school club
of my own. Around the same time, an underclassman sought to found a programming
club, and I helped it grow. Although the programming club obviously didn't turn
out the same as the <em>keionbu</em>, I still made new friends there nonetheless.
<em>K-On</em> also inspired me to pick up the guitar so I could lose myself in music
just as the girls did.
    </p>
    <p>
     <em>K-On</em>'s thoughtful themes and genuine depiction of the joys of adolescence
overwhelmed me: I hadn't seen anything like it before, and I recognized that I'd
experienced something truly special. That was when I took notice of KyoAni and
director Naoko Yamada. As one fan puts it, <a href="https://honeysanime.com/the-history-of-kyoto-animation/">"K-On! really started the tradition
that KyoAni titles would tell the stories of normal people in beautiful ways,
something the studio would begin to be known for."</a> In particular, <em>K-On</em>
was the breakout success for Naoko Yamada, the young talent who would become
known for her works centering around adolescence, including the critically
acclaimed film <em>A Silent Voice</em> (which, I might add, was snubbed in favor of
<em>The Boss Baby</em> in the Western-centric and out-of-touch Oscars). <em>K-On</em> is just
one example of KyoAni's work, which are respected for their high production
quality and loved for their often heartfelt subject matter.
    </p>
    <figure>
     <video autoplay="" controls="" loop="">
      <source src="https://dosaylazy.github.io/blog/k-on/utauyo-miracle.mp4" type="video/mp4">
      Your browser does not support the video tag.
     </video>
     <figcaption>
      Yui instructs the others how to perform her dance
    (Source:
    <a href="https://www.sakugabooru.com/post/show/124352">Sakugabooru</a>)
     </figcaption>
    </figure>
    <p>
     The humanity of KyoAni's fiction parallels that of its reality, a rare beacon in
the infamously harsh anime industry. The studio has its own animator training
school, pays its employees a salary instead of per frame, and provides maternity
leave to support its female employees. These conditions pay back as animators
can focus on quality over quantity and KyoAni can maintain in-house talent and
develop its own style. <a href="https://blog.sakugabooru.com/2018/08/25/the-evolution-of-kyoto-animation-a-unique-anime-studio-and-its-consistent-vision/">KyoAni eventually achieved the financial independence to
run its own production committees so that creators may be in charge of their
works.</a> Not only does KyoAni shine through its anime, it is also a one-of-a-kind in
the anime industry.
    </p>
    <p>
     I remember when I woke up on July 18 and found KyoAni in the international news.
I remember learning the horrific details of the massacre, feeling overwhelmed
by the Western media coverage of varying quality, and getting angry at the
misinformed commentary from unfamiliar outsiders. There couldn't have been a
greater contrast between KyoAni's innocence and its tragedy. I asked: Oh,
KyoAni, why did this have to happen to you?
    </p>
    <p>
     But, I also remember the show of love that KyoAni fans around the world
sent the ravaged studio in the aftermath of the attack. <a href="https://www.reuters.com/article/us-kyoto-animation-fire-money/donations-top-30-million-for-kyoto-animation-arson-victims-in-japan-idUSKBN1YV0MR">KyoAni received $30
million in donations</a> and <a href="https://soranews24.com/2019/11/15/kyoto-animation-has-a-touchingly-kind-plan-to-distribute-its-3-2-billion-yen-in-arson-donations/">selflessly reserved all the money to compensate the victims and their
families, and none of it for rebuilding the business</a>. Even in the face of death and destruction, KyoAni stood strong with dignity
and compassion. I want to see KyoAni recover and grow and succeed. KyoAni
constantly inspires me to become a kinder person, and countless fans have
personal stories of the studio's positive impact. I hope that even more people
discover the goodness of KyoAni.
    </p>
    <p>
     You know, there's a phenomenon where you don't realize who you have to be
thankful for until they're gone. I'm reminded of a certain <em>K-On</em> episode: When
the music room is closed off for repairs, the <em>keionbu</em> must relocate so it can
prepare for its upcoming concert. Unable to practice in their new locations, the
girls brainstorm song ideas instead. When the music room finally reopens, they
realize not to take for granted what they already have.
    </p>
    <p>
     Later, Yui's doting sister Ui Hirasawa overworks herself caring for Yui and
comes down with a cold. As Ui languidly lies in bed with a fever, Yui endeavors
to repay her sister for her kindness over all the years by preparing a meal,
only to find that cooking is hard! When Ui awakens the next morning, she
discovers Yui fast asleep at her desk with a sheet of lyrics. Yui had stayed up
late writing a new song for the concert devoted to her sister: <em>U&amp;I</em>.
    </p>
    <figure>
     
    </figure>
    <blockquote>
     <p>
      <em>I had thought that it was ordinary to have you by my side</em><br>
<em>I had thought that these days would last forever and ever</em><br>
<em>Sorry, now I realize that these days were extraordinary</em><br>
<em>So first, I need to tell you: "Arigatou!"</em>
     </p>
    </blockquote>
    <p>
     Yui Hirasawa, <em>U&amp;I</em>
    </p>
    <p>
     KyoAni, may my feelings reach you: arigatou!
    </p>
   </section>
  </div></div>]]>
            </description>
            <link>https://dosaylazy.github.io/blog/kyoani-one-year-later.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23878201</guid>
            <pubDate>Sat, 18 Jul 2020 01:40:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Levandowski files suit against Uber [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 112 | Comments 91 (<a href="https://news.ycombinator.com/item?id=23877872">thread link</a>) | @MrSandman
<br/>
July 17, 2020 | https://ipfs.eternum.io/ipfs/Qmd9PTEtuSrKKtJQw36aNzpjJwZAdCdwCmUn4w21mmq74z/Levandowski-Uber-Complaint-1.pdf | <a href="https://web.archive.org/web/*/https://ipfs.eternum.io/ipfs/Qmd9PTEtuSrKKtJQw36aNzpjJwZAdCdwCmUn4w21mmq74z/Levandowski-Uber-Complaint-1.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://ipfs.eternum.io/ipfs/Qmd9PTEtuSrKKtJQw36aNzpjJwZAdCdwCmUn4w21mmq74z/Levandowski-Uber-Complaint-1.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-23877872</guid>
            <pubDate>Sat, 18 Jul 2020 00:48:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Think like a scientist talk like a populist]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23877780">thread link</a>) | @shdc
<br/>
July 17, 2020 | https://shyal.com/blog/think-like-a-scientist-talk-like-a-populist | <a href="https://web.archive.org/web/*/https://shyal.com/blog/think-like-a-scientist-talk-like-a-populist">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
    
     

    
    â†�
    <a href="https://shyal.com/">ðŸ�&nbsp;</a>
     
    <!-- if has_fences -->
    <!-- <div><a href='/black'><img src='/Attachments/black.svg'/></a></div> -->
    <!--  end  -->
    <p>18/07/2020</p>
<p>Adapting your language to match that of your audience, in today's world, seems to be growing in importance by the day. Let's contrast two public figures in public appearances that took place yesterday: Fauci vs. Trump.</p>
<h2 id="dr-fauci-vs-populism">Dr Fauci vs Populism</h2>
<p>The rising wave of populism in the U.S has wrought a "distrust of experts". That's a real shame, especially when you don't listen to your infectious disease expert during a Pandemic.</p>
<p><img alt="Pasted image 39.png" src="https://shyal.com/Attachments/Pasted%20image%2039.png"></p>
<p>Dr Fauci literally wrote the book on infectious disease, yet the populists are calling for his head. Why?</p>
<h3 id="they-dont-understand-a-word-he-says">They don't understand a word he says</h3>
<p>I was watching this <a href="https://web.facebook.com/zuck/videos/10112108870243761/">interview</a> of Dr Fauci by Zuck, yesterday. Finally Fauci is given a chance to speak to the people. Yet:</p>
<blockquote>
<blockquote>
<p>"Citizenry"</p>
</blockquote>
</blockquote>
<p>People?</p>
<blockquote>
<blockquote>
<p>"myalgic encephalitis"</p>
</blockquote>
</blockquote>
<p>Feeling too tired to lift an arm or get out of bed?</p>
<blockquote>
<blockquote>
<p>"deleterious consequences"</p>
</blockquote>
</blockquote>
<p>Bad things happen?</p>
<blockquote>
<blockquote>
<p>"i used the word 'comparable' and i think it may have been taken out of context"</p>
</blockquote>
</blockquote>
<p>Then don't say 'comparable'.</p>
<p>Indeed we already have evidence that <a href="https://www.pnas.org/content/early/2020/07/09/2008868117">working memory predicts social-distancing compliance</a>. This is pretty damning evidence: essentially people with lower working memory capacity are unwilling to socially distance themselves as they cannot hold enough variables in mind to accurately assess the pros and cons.</p>
<p>Thus it isn't too much of a leap to theorise that a lower working memory capacity is also linked with a restricted vocabulary, and thus a reduced ability to process Dr Fauci's long, complex sentences which are laiden with technical jargon and advanced vocab.</p>
<p>Or to put it bluntly: the idiots don't understand Dr Fauci.</p>
<h2 id="donald-trump-is-a-communication-wizard">Donald Trump is a communication Wizard</h2>
<p>Scott Adams accurately predicted <a href="https://www.scottadamssays.com/2015/10/23/the-case-for-a-trump-landslide-part-1/">Donal Trump would win the elections in a landslide</a> back in 2015.</p>
<blockquote>
<blockquote>
<p>"Trump is talking directly to peopleâ€™s subconscious. Everything else he says is just a carrier signal." --Scott Adams (<a href="https://www.scottadamssays.com/2015/09/06/how-to-spot-a-wizard/">how to spot a wizard</a>)</p>
</blockquote>
</blockquote>
<p>This is a great example of Trump's communicative Wizardry. On the same Day Dr Fauci was telling the citizenry about myalgic encephalitis and deleterious consequences, Trump did this:</p>
<p><img alt="Pasted image 40.png" src="https://shyal.com/Attachments/Pasted%20image%2040.png"></p>
<p>Trump had the audacity to set up two cranes, to visually demonstrate lifting regulatory weights off the Republican red truck, while regulation still weighing down on the Democrat blue truck. This is pure communication genius, <strong>because any idiot can understand it</strong> and it <strong>communicates to their subconscious</strong>.</p>
<p>By catering to the lowest common denominator, Trump ensures he captures 100% of his potential base. Not a single word is lost. In fact this kind of visual communication transcends language, education level, even culture.</p>
<h2 id="boris-johnson-is-also-a-communication-wizard">Boris Johnson is also a communication Wizard</h2>
<p>In this interview, Johnson shares his communication principles:</p>
<blockquote>
<blockquote>
<p>"What people listen to are short anglo-saxon words that readily correspond to some object in the universe that they can identify. So in other words: talk simply, in plain English, and talk about stuff in the real world." --Boris Johnson</p>
</blockquote>
</blockquote>
<iframe width="560" height="315" src="https://www.youtube.com/embed/oJXyI-gwBNU?start=437" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<p>Deriding people like Trump or Johnson for their perceived linguistic blunders utterly misses the point. <strong>Their blunders are what makes them accessible.</strong> Their simple language is what makes them understable. Their communicative wizardly is what makes them irresistible to their base.</p>
<h2 id="elon-musk-is-also-a-communication-wizard">Elon Musk is also a communication Wizard</h2>
<p>Those who know me will confirm this to you: i have been a huge Musky for a very long time. Elon Musk is yet another genius at tailoring his communication to his base:</p>
<p><img alt="Pasted image 37.png" src="https://shyal.com/Attachments/Pasted%20image%2037.png"></p>
<p>Musk speaks to engineers, or generally a base with technological interests, so his language is not always as simple as it could be. But when you consider the topics he talks about, you have to admire how accessible he is able to make them. The language is simple, and the topics relate to the real world.</p>
<p><img alt="Pasted image 41.png" src="https://shyal.com/Attachments/Pasted%20image%2041.png"></p>
<p>And then there are his masterpieces of communication, like the Tesla he sent into orbit. Once again, pure communication genius that transcends language and culture.</p>
<p>Or his EDM track:</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/hOEWUm6aGPg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<blockquote>
<blockquote>
<p>"Don't doubt your vibe, because it's true." -- Elon Musk</p>
</blockquote>
</blockquote>
<p>A quick glance at Tesla's stock performance since the <a href="https://shyal.com/blog/tesla-stock-bottom-date">tesla stock bottom date</a> will tell you the message was indeed recieved.</p>
<h2 id="idiocracy-had-it-right">Idiocracy had it right</h2>
<p>The movie <a href="https://www.imdb.com/title/tt0387808/">Idiocracy (2006)</a> is a spooky and hilarious foray into a potential future dumbing down of the human race. The main character, from our time, <strong>who's name is "no sure"</strong> wakes up in the future as the <strong>man with the highest IQ. But nobody understands a word he says</strong>.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/sGUNPMPrxvA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<p>He narrowly manages to save the human race by <strong>showing them</strong> that watering crops with water instead of gatorade is the solution to all their problems.</p>

<p>All the evidence points to dumbing down your language, and communicating visually and symbolically to become an unstoppable communicator. <strong>Think like a scientist and talk like a populist; you will become unstoppable</strong>.</p>
<hr>
<p>Enjoyed this article? <a href="https://twitter.com/shyaldc">Follow me on Twitter</a>.</p>
    </div></div>]]>
            </description>
            <link>https://shyal.com/blog/think-like-a-scientist-talk-like-a-populist</link>
            <guid isPermaLink="false">hacker-news-small-sites-23877780</guid>
            <pubDate>Sat, 18 Jul 2020 00:34:22 GMT</pubDate>
        </item>
    </channel>
</rss>
