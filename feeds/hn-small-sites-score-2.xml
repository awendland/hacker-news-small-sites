<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Tue, 30 Jun 2020 20:16:31 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Tue, 30 Jun 2020 20:16:31 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Has GitHub been down more since its acquisition by Microsoft?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23676199">thread link</a>) | @tdrnd
<br/>
June 29, 2020 | https://nimbleindustries.io/2020/06/04/has-github-been-down-more-since-its-acquisition-by-microsoft/ | <a href="https://web.archive.org/web/*/https://nimbleindustries.io/2020/06/04/has-github-been-down-more-since-its-acquisition-by-microsoft/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<div>
				    
				<div>
    <article id="post-775">
	
	            
            

                
        <div>
                        
            
            
<p>Two years ago, on June 4th of 2018, Microsoft announced its acquisition of GitHub, unicorn darling of the developer tools startup ecosystem, <a rel="noreferrer noopener nofollow" href="https://techcrunch.com/2018/06/04/microsoft-has-acquired-github-for-7-5b-in-microsoft-stock/" target="_blank" data-wpel-link="external">for $7.5B in stock</a>. The announcement unearthed a wide range of <a href="https://news.ycombinator.com/item?id=17221527" data-wpel-link="external" target="_blank" rel="nofollow">opinions and pontifications</a>, ranging from “GitHub is doomed” to “Microsoft is smart”, with many predictions about GitHub’s future. Some thought Microsoft’s growing investments in its cloud offering, Azure, might help GitHub. Could an investment by Microsoft improve GitHub’s reliability or harden them against outages like <a href="https://www.wired.com/story/github-ddos-memcached/" data-wpel-link="external" target="_blank" rel="nofollow">DDOSes</a>? Have any of these predictions come true?</p>



<p>We set out to analyze one angle of the GitHub acquisition: Has GitHub become more reliable since its acquisition by Microsoft? Our service, <a href="https://statusgator.com/" data-wpel-link="internal" rel="follow">StatusGator</a>, monitors more than 700 status pages of cloud providers and SaaS companies large and small. We aggregate and normalize status page data and make it available to our subscribers however they need: in notifications by email, Slack, Teams, or webhook, and in a <a href="https://nimbleindustries.io/2020/01/24/how-to-save-precious-minutes-during-incident-response/" data-wpel-link="internal" rel="follow">unified status dashboard</a> for all service dependencies.</p>



<figure><img src="https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-header-1-1024x613.png" alt="" srcset="https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-header-1-1024x613.png 1024w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-header-1-300x180.png 300w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-header-1-768x460.png 768w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-header-1-1536x919.png 1536w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-header-1-720x431.png 720w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-header-1-580x347.png 580w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-header-1-320x192.png 320w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-header-1.png 1920w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>For more than 5 years, we have analyzed the <a href="https://www.githubstatus.com/" data-wpel-link="external" target="_blank" rel="nofollow">GitHub status page</a> constantly. Every 5 minutes, StatusGator takes a screenshot and <a href="https://statusgator.com/services/github" data-wpel-link="internal" rel="follow">collects relevant data</a> about their service status. That means we are uniquely positioned to offer analysis of the downtime that GitHub themselves announce via their status page.</p>



<p>What does the data tell us? In the two years since the acquisition announcement, GitHub has reported a 41% increase in status page incidents. Furthermore, there has been a 97% increase in incident minutes, compared to the two years prior to the announcement. Does this actually point to a decrease in reliability? We can’t say. This could simply mean GitHub has increased its transparency, publishing to their status page more frequently.</p>



<h2>Incident Counts</h2>



<p>We calculated an incident count in the 24 months preceding the announcement and the 24 months after. We <a href="https://nimbleindustries.io/2019/12/26/under-the-hood-inside-a-status-page-aggregator/" data-wpel-link="internal" rel="follow">classify status pages</a> into four states: <em>up</em>, <em>warn</em>, and <em>down</em>, and <em>maintenance</em>. GitHub does not expose scheduled maintenance on their status page. For these calculations we consider an incident to be any change in status between <em>up</em> and <em>warn</em> or <em>down</em>.</p>



<p>Before the acquisition, there were 89 incidents published on the GitHub status page. After, there were 126 incidents. A 41% increase:</p>



<figure><img src="https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-incident-counts-1-1024x422.png" alt="89 Incidents before the acquisition, 126 incidents after, a 41% increase." srcset="https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-incident-counts-1-1024x422.png 1024w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-incident-counts-1-300x124.png 300w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-incident-counts-1-768x316.png 768w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-incident-counts-1-1536x633.png 1536w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-incident-counts-1-2048x844.png 2048w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-incident-counts-1-1920x791.png 1920w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-incident-counts-1-720x297.png 720w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-incident-counts-1-580x239.png 580w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-incident-counts-1-320x132.png 320w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>In the graph below, we’ve charted the incident counts by month. The left side shows the 24 months before and the right side shows the 24 months after:</p>



<figure><img src="https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-incident-graph-1024x533.png" alt="Graph showing GitHub incidents by month, before and after their acquisition by Microsoft." srcset="https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-incident-graph-1024x533.png 1024w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-incident-graph-300x156.png 300w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-incident-graph-768x400.png 768w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-incident-graph-1536x799.png 1536w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-incident-graph-720x375.png 720w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-incident-graph-580x302.png 580w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-incident-graph-320x167.png 320w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-incident-graph.png 1920w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>







<h2>Incident Minutes</h2>



<p>We calculated incident minutes by subtracting the start and end time of time of incidents. Although not 100% realtime, StatusGator checks frequently: every 5 minutes, so status page changes are detected quickly. We counted time where the page was not in an overall <em>up</em> state.</p>



<p>In the 24 months prior to the acquisition announcement, there were 6,110 minutes of downtime. During the 24 months after, there were 12,074 minutes of downtime, a 97% increase:</p>



<figure><img src="https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-minute-counts-1-1024x420.png" alt="6,110 Incidents before the acquisition, 12,074 incidents after, a 97% increase." srcset="https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-minute-counts-1-1024x420.png 1024w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-minute-counts-1-300x123.png 300w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-minute-counts-1-768x315.png 768w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-minute-counts-1-1536x630.png 1536w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-minute-counts-1-2048x840.png 2048w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-minute-counts-1-1920x788.png 1920w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-minute-counts-1-720x295.png 720w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-minute-counts-1-580x238.png 580w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-minute-counts-1-320x131.png 320w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>In the graph below, we’ve charted the incident minutes by month. The left side shows the 24 months before and the right side shows the 24 months after:</p>



<figure><img src="https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-minute-graph-1-1024x531.png" alt="Graph showing GitHub downtime minutes by month, before and after their acquisition by Microsoft." srcset="https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-minute-graph-1-1024x531.png 1024w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-minute-graph-1-300x156.png 300w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-minute-graph-1-768x399.png 768w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-minute-graph-1-1536x797.png 1536w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-minute-graph-1-2048x1063.png 2048w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-minute-graph-1-1920x997.png 1920w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-minute-graph-1-720x374.png 720w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-minute-graph-1-580x301.png 580w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-minute-graph-1-320x166.png 320w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<h2>Status Page Evolution</h2>



<p>During these four years, GitHub has made enormous improvements in their status page information granularity and design. In December 2018, they switched from a home grown status page to one operated by Atlassian’s StatusPage service, <a href="https://nimbleindustries.io/2019/03/11/2019-statusgator-status-page-awards/" data-wpel-link="internal" rel="follow">the most popular status page provider</a>. In doing so, they added numerous <a href="https://nimbleindustries.io/2019/11/22/component-status-filtering-is-here/" data-wpel-link="internal" rel="follow">individual component statuses</a>. Here’s what GitHub’s status page looked like before their switch to Atlassian StatusPage:</p>



<h3>GitHub’s Old Status Page</h3>



<figure><img src="https://nimbleindustries.io/wp-content/uploads/2020/05/github-status-page-old.png" alt="GitHub status page showing only a single status across all GitHub services." srcset="https://nimbleindustries.io/wp-content/uploads/2020/05/github-status-page-old.png 645w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-status-page-old-300x187.png 300w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-status-page-old-580x361.png 580w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-status-page-old-320x199.png 320w" sizes="(max-width: 645px) 100vw, 645px"><figcaption>GitHub status page showing only a single status across all GitHub services.</figcaption></figure>



<p>When they switched to their new status page format, GitHub took a huge step towards increased accountability and transparency by detailing the following individual service components:</p>



<ul><li>Git Operations</li><li>API Requests</li><li>Issues, PRs, Dashboard, Projects</li><li>Notifications</li><li>Gists</li><li>GitHub Pages</li></ul>



<p>Overtime, they have expanded and refined their component statuses. They also started showing historical data right on their status page. As you can see in their newest and most detailed status page format, it shows the following service component statuses:</p>



<ul><li>Git Operations</li><li>API Requests</li><li>Webhooks</li><li>Issues, PRs, Projects</li><li>GitHub Actions</li><li>GitHub Packages</li><li>GitHub Pages</li></ul>



<h3>GitHub’s New Status Page</h3>



<figure><img src="https://nimbleindustries.io/wp-content/uploads/2020/05/github-satus-page-new-944x1024.png" alt="GitHub status page showing detailed statuses of each of the major components of their service." srcset="https://nimbleindustries.io/wp-content/uploads/2020/05/github-satus-page-new-944x1024.png 944w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-satus-page-new-277x300.png 277w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-satus-page-new-768x833.png 768w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-satus-page-new-720x781.png 720w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-satus-page-new-580x629.png 580w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-satus-page-new-320x347.png 320w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-satus-page-new.png 1280w" sizes="(max-width: 944px) 100vw, 944px"><figcaption>GitHub status page showing detailed statuses of each of the major components of their service.</figcaption></figure>



<p>They also moved their status page to a dedicated domain, <a href="https://www.githubstatus.com/" data-wpel-link="external" target="_blank" rel="nofollow">githubstatus.com</a>, <a href="https://nimbleindustries.io/2020/04/21/your-status-page-deserves-its-own-domain/" data-wpel-link="internal" rel="follow">which follows a best practice we recommend</a> to anyone who hosts a status page. All of this additional transparency, details, and historical data is a commendable effort to relay the most up-to-date information about the status of all GitHub systems. More providers of critical cloud infrastructure should emulate what GitHub has done. <a href="https://nimbleindustries.io/2019/12/07/your-status-page-is-useless-if-you-dont-use-it/" data-wpel-link="internal" rel="follow">Your status page is useless if you don’t use it.</a></p>



<h2>Conclusion</h2>



<p>What can we conclude from all of this data? Objectively, we can conclude that GitHub has published to their status page more frequently in the two years after their acquisition announcement. They have posted more incidents of disruption and downtime. Those incidents have been longer in duration. According to the data they provided, GitHub has been down more since the acquisition by Microsoft. </p>



<p>But that could be all a part of coordinated effort to be more transparent about their service status, an effort that should be applauded.</p>



<p>Our goal at StatusGator is not to shame anyone for disruptions and outages. Everyone experiences unexpected downtime. We simply strive to make status page data available and accessible in more useful ways. From Slack and <a href="https://nimbleindustries.io/2020/04/03/status-page-monitoring-in-microsoft-teams/" data-wpel-link="internal" rel="follow">Microsoft Teams</a>, to <a href="https://nimbleindustries.io/2020/04/30/status-page-webhooks-new-and-improved/" data-wpel-link="internal" rel="follow">webhooks</a>, an API, and more. StatusGator aggregates status page data and empowers you to keep your team informed. </p>



<h2>Try StatusGator</h2>



<figure><img src="https://nimbleindustries.io/wp-content/uploads/2019/03/logo-large-1024x175.png" alt="StatusGator logo" srcset="https://nimbleindustries.io/wp-content/uploads/2019/03/logo-large-1024x175.png 1024w, https://nimbleindustries.io/wp-content/uploads/2019/03/logo-large-300x51.png 300w, https://nimbleindustries.io/wp-content/uploads/2019/03/logo-large-768x131.png 768w, https://nimbleindustries.io/wp-content/uploads/2019/03/logo-large-1920x329.png 1920w, https://nimbleindustries.io/wp-content/uploads/2019/03/logo-large-720x123.png 720w, https://nimbleindustries.io/wp-content/uploads/2019/03/logo-large-580x99.png 580w, https://nimbleindustries.io/wp-content/uploads/2019/03/logo-large-320x55.png 320w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>Is your team dependent on GitHub? Consider trying out <a href="https://statusgator.com/" data-wpel-link="internal" rel="follow">StatusGator</a>,&nbsp;free for 30 days. You can get notifications about GitHub and more than 670 other services with status pages we monitor. You can receive notifications in Microsoft Teams, Slack, by email, SMS, or webhook. Our favorite feature is a Slack integration with a <code>/statuscheck</code> slash command that allows querying the status of any service, right from where your team hangs out.</p>



<p><a href="https://statusgator.com/" data-wpel-link="internal" rel="follow">Try a 30 day free trial</a>&nbsp;of StatusGator and let us know what you think.</p>

                        
                            
            
        </div>
        
                             
    </article>
</div>
				
								
							</div>

		
	



			

		</div></div>]]>
            </description>
            <link>https://nimbleindustries.io/2020/06/04/has-github-been-down-more-since-its-acquisition-by-microsoft/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23676199</guid>
            <pubDate>Mon, 29 Jun 2020 10:31:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Zooming on Zoom's Privacy Controversies]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23676180">thread link</a>) | @oczek
<br/>
June 29, 2020 | https://blog.graphqleditor.com/zoom-security-controversies/ | <a href="https://web.archive.org/web/*/https://blog.graphqleditor.com/zoom-security-controversies/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Coronavirus and the lockdowns it forced has probably sped up the transition to working from home in many jobs by at least a decade. Workers who previously spend time sitting in cubicles or offices found out they could have just as well worked from home. Millions started looking for software that would help them do that. </p>
<p>Enter Zoom, a somewhat popular video-conferencing program made all the way back in 2011. It was already fairly popular before the pandemic, but this year it’s popularity has exploded. The daily average user numbers went from around 10 million in December to over 300 million in April. </p>
<h2>The Good</h2>
<p>Zoom became the go-to choice for many mainly because it’s really easy to use and free (well at least the basic version is) The usually highlighted advantages of Zoom are:</p>
<ul>
<li>simple and easy to use interface</li>
<li>good audio and video quality</li>
<li>smooth and easy to set up conference calls even for large groups up to 100 people</li>
<li>compatibility with various systems: Windows, macOS, Linux, Android, and iOS</li>
<li>ability to share slides and content</li>
<li>scheduling conferences via a calendar that can be shared with others</li>
<li>virtual backgrounds</li>
</ul>
<p><span>
      <a href="https://blog.graphqleditor.com/static/e43be73ccb423041c1831db1af7d359e/00d43/video_call.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Leading video-call platfrom" title="Leading video-call platfrom" src="https://blog.graphqleditor.com/static/e43be73ccb423041c1831db1af7d359e/fcda8/video_call.png" srcset="https://blog.graphqleditor.com/static/e43be73ccb423041c1831db1af7d359e/12f09/video_call.png 148w,
https://blog.graphqleditor.com/static/e43be73ccb423041c1831db1af7d359e/e4a3f/video_call.png 295w,
https://blog.graphqleditor.com/static/e43be73ccb423041c1831db1af7d359e/fcda8/video_call.png 590w,
https://blog.graphqleditor.com/static/e43be73ccb423041c1831db1af7d359e/efc66/video_call.png 885w,
https://blog.graphqleditor.com/static/e43be73ccb423041c1831db1af7d359e/00d43/video_call.png 1000w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h5>Credits: <a href="https://undraw.co/">undraw.co</a></h5>
<p>Zoom also helped itself by making the program free to use for K-12 schools in the US since early March, just as the lockdowns were starting. It also received a lot of free publicity from famous users, even the UK government used it to host sessions.</p>
<h2>The Bad</h2>
<p>Well, it’s not all as rosy as it sounds. Zoom has been involved in some controversies that have become more and more apparent as it gained popularity. The main point of criticism has been lackluster security. </p>
<ul>
<li>In 2019 Apple was forced to remove Zoom from Macs after it turned out a security flaw could let websites hijack users’ cameras. Although the company quickly addressed this with fixes and a lengthy blog post, it wasn’t a good look.</li>
<li>Zoom has no end-to-end encryption, despite some advertising materials claiming otherwise. It stores all the keys involved in user data encryption in its own cloud infrastructure. Which means it can access user data at will.</li>
<li>Zoom calls have random generated IDs consisting between 9 and 11 digits and these can apparently be brute-forced or even randomly guessed which means hackers can get into meetings.</li>
</ul>
<p><span>
      <a href="https://blog.graphqleditor.com/static/ba9ad700d29dd977b436329ae4999a98/00d43/hack.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Security controversies" title="Security controversies" src="https://blog.graphqleditor.com/static/ba9ad700d29dd977b436329ae4999a98/fcda8/hack.png" srcset="https://blog.graphqleditor.com/static/ba9ad700d29dd977b436329ae4999a98/12f09/hack.png 148w,
https://blog.graphqleditor.com/static/ba9ad700d29dd977b436329ae4999a98/e4a3f/hack.png 295w,
https://blog.graphqleditor.com/static/ba9ad700d29dd977b436329ae4999a98/fcda8/hack.png 590w,
https://blog.graphqleditor.com/static/ba9ad700d29dd977b436329ae4999a98/efc66/hack.png 885w,
https://blog.graphqleditor.com/static/ba9ad700d29dd977b436329ae4999a98/00d43/hack.png 1000w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h5>Credits: <a href="https://undraw.co/">undraw.co</a></h5>
<p>The flaws were pretty notorious and led to a phenomenon called <em>zoom bombing</em> where pranksters would join meetings to broadcast inappropriate content. It got so bad the FBI had to officially warn schools.</p>
<h2>The Ugly</h2>
<p>Remember that thing about Zoom having access to user data? Well, it turns out that’s not an accident.</p>
<ul>
<li>This month Zoom admitted to closing three meetings commemorating the Tiananmen Square crackdown and suspended the accounts of activists who organized them. This led to teachers voicing concerns about how they’re supposed to cover such topics in classes hosted on the platform.</li>
<li>In April the New York Times found out Zoom’s data mining feature was automatically sending user’s names and emails to LinkedIn allowing participants to access other users’ profile data.</li>
<li>In March Motherboard found out Zoom’s iOS app was automatically sending device analytics to Facebook without informing the user and did it even if the user did not have a Facebook account. There was no mention of this in the privacy policy either.</li>
</ul>
<p><span>
      <a href="https://blog.graphqleditor.com/static/8b6995e982001e92861e97dd1e4ab908/00d43/privacy.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Privacy concerns" title="Privacy concerns" src="https://blog.graphqleditor.com/static/8b6995e982001e92861e97dd1e4ab908/fcda8/privacy.png" srcset="https://blog.graphqleditor.com/static/8b6995e982001e92861e97dd1e4ab908/12f09/privacy.png 148w,
https://blog.graphqleditor.com/static/8b6995e982001e92861e97dd1e4ab908/e4a3f/privacy.png 295w,
https://blog.graphqleditor.com/static/8b6995e982001e92861e97dd1e4ab908/fcda8/privacy.png 590w,
https://blog.graphqleditor.com/static/8b6995e982001e92861e97dd1e4ab908/efc66/privacy.png 885w,
https://blog.graphqleditor.com/static/8b6995e982001e92861e97dd1e4ab908/00d43/privacy.png 1000w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h5>Credits: <a href="https://undraw.co/">undraw.co</a></h5>
<p>So far this has led to a couple of lawsuits, an inquiry by the Federal Trade Commission and outright bans from some tech companies and the UK’s ministry of defense. Not good news for the company to put it mildly. Yet despite all that Zoom is still hugely popular and looks like it will stay that way despite its flaws. To be fair it’s not like it’s main competitors like Microsoft Teams and Google Hangouts don’t have any either, so pick your poison.</p></div><p>The GraphQL Editor is a supportive tool for both advanced GraphQL users as well as those taking their first steps with GraphQL APIs. Our all-in-one development environment for GraphQL will help you build, manage &amp; deploy your GraphQL API much faster thanks to dozens of built-in micro features. Its graphical interface will also fix communication within your product team. Visualization is the key!</p></div>]]>
            </description>
            <link>https://blog.graphqleditor.com/zoom-security-controversies/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23676180</guid>
            <pubDate>Mon, 29 Jun 2020 10:27:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Arduino FIDO2 Authenticator]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23676006">thread link</a>) | @snakeye
<br/>
June 29, 2020 | https://en.ovcharov.me/2020/06/29/uru-card-arduino-fido2-authenticator/ | <a href="https://web.archive.org/web/*/https://en.ovcharov.me/2020/06/29/uru-card-arduino-fido2-authenticator/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<section>
<div>
<div>
<section>



<article>
<p>After publishing the URU Key project people keep asking me to make it open source. I have tried to organize sources in a more readable way but I still think that plain C and ESP IDF are too difficult for the broad audience. And, unfortunately, the biometrics part is covered by NDA and can not be published.</p>
<p>Therefore I am starting a new project to address these and other issues.</p>
<h2 id="size-and-form-factor">Size and form factor</h2>
<p>A few months ago I have finalized the <a href="https://en.ovcharov.me/2020/04/06/uru-key-final-hardware-design/">URU Key hardware design</a> and started working on housing for it. Yes, it is very small and lightweight but carrying it around is a kind of a problem. The device is too fragile to be worn on the keyring and a bit thick to put in the pocket. The necklace is not my style.</p>
<figure>
<img src="https://d33wubrfki0l68.cloudfront.net/31ed3b469871b100ae43a0dbae4930d2f3fb272b/61808/uploads/resized/uru-key-w800.jpg" data-src="https://d33wubrfki0l68.cloudfront.net/31ed3b469871b100ae43a0dbae4930d2f3fb272b/61808/uploads/resized/uru-key-w800.jpg" data-srcset="/uploads%2Fresized%2Furu-key-w150.jpg 150w, /uploads%2Fresized%2Furu-key-w300.jpg 300w, /uploads%2Fresized%2Furu-key-w600.jpg 600w, /uploads%2Fresized%2Furu-key-w800.jpg 800w, /uploads%2F2020%2F06%2F29%2Furu-key.jpg 1200w" sizes="(max-width: 230px) 150px, (max-width: 380px) 300px, (max-width: 680px) 600px, (max-width: 880px) 800px, 1200px" alt="URU Key with the battery" title="URU Key with the battery" srcset="https://en.ovcharov.me/uploads%2Fresized%2Furu-key-w150.jpg 150w, https://en.ovcharov.me/uploads%2Fresized%2Furu-key-w300.jpg 300w, https://en.ovcharov.me/uploads%2Fresized%2Furu-key-w600.jpg 600w, https://en.ovcharov.me/uploads%2Fresized%2Furu-key-w800.jpg 800w, https://en.ovcharov.me/uploads%2F2020%2F06%2F29%2Furu-key.jpg 1200w"><figcaption>URU Key with the battery</figcaption></figure>
<p>However, my wallet is always with me. The PCB sized as a standard credit card should perfectly fit there. The power source becomes a problem, that’s true. But, wait, is it difficult to find a charger or power bank with Micro USB nowadays?</p>
<figure>
<img src="https://d33wubrfki0l68.cloudfront.net/1218f869b13f89ff97edd4cf56c554a12caa4e77/36a93/uploads/resized/uru-card-wallet-w800.jpg" data-src="https://d33wubrfki0l68.cloudfront.net/1218f869b13f89ff97edd4cf56c554a12caa4e77/36a93/uploads/resized/uru-card-wallet-w800.jpg" data-srcset="/uploads%2Fresized%2Furu-card-wallet-w150.jpg 150w, /uploads%2Fresized%2Furu-card-wallet-w300.jpg 300w, /uploads%2Fresized%2Furu-card-wallet-w600.jpg 600w, /uploads%2Fresized%2Furu-card-wallet-w800.jpg 800w, /uploads%2F2020%2F06%2F29%2Furu-card-wallet.jpg 1200w" sizes="(max-width: 230px) 150px, (max-width: 380px) 300px, (max-width: 680px) 600px, (max-width: 880px) 800px, 1200px" alt="URU Card in the wallet" title="URU Card in the wallet" srcset="https://en.ovcharov.me/uploads%2Fresized%2Furu-card-wallet-w150.jpg 150w, https://en.ovcharov.me/uploads%2Fresized%2Furu-card-wallet-w300.jpg 300w, https://en.ovcharov.me/uploads%2Fresized%2Furu-card-wallet-w600.jpg 600w, https://en.ovcharov.me/uploads%2Fresized%2Furu-card-wallet-w800.jpg 800w, https://en.ovcharov.me/uploads%2F2020%2F06%2F29%2Furu-card-wallet.jpg 1200w"><figcaption>URU Card in the wallet</figcaption></figure>
<p>The name <strong>URU Card</strong> makes a lot of sense for this project, isn’t it?</p>
<h2 id="user-interface">User interface</h2>
<p>As on one hand, I can not use biometrics for open source project and on other hand, I do not want to omit the authentication completely leaving the device insecure there is a need for some form of user verification. Simple touch keyboard and OLED screen should allow people to enter pin code or password.</p>
<figure>
<img src="https://d33wubrfki0l68.cloudfront.net/421c686c17665f43cfbb25fd3059190a055e4ae5/b0f7c/uploads/resized/uru-card-2-w800.jpg" data-src="https://d33wubrfki0l68.cloudfront.net/421c686c17665f43cfbb25fd3059190a055e4ae5/b0f7c/uploads/resized/uru-card-2-w800.jpg" data-srcset="/uploads%2Fresized%2Furu-card-2-w150.jpg 150w, /uploads%2Fresized%2Furu-card-2-w300.jpg 300w, /uploads%2Fresized%2Furu-card-2-w600.jpg 600w, /uploads%2Fresized%2Furu-card-2-w800.jpg 800w, /uploads%2F2020%2F06%2F29%2Furu-card-2.jpg 1200w" sizes="(max-width: 230px) 150px, (max-width: 380px) 300px, (max-width: 680px) 600px, (max-width: 880px) 800px, 1200px" alt="URU Card - touch keyboard and OLED screen" title="URU Card - touch keyboard and OLED screen" srcset="https://en.ovcharov.me/uploads%2Fresized%2Furu-card-2-w150.jpg 150w, https://en.ovcharov.me/uploads%2Fresized%2Furu-card-2-w300.jpg 300w, https://en.ovcharov.me/uploads%2Fresized%2Furu-card-2-w600.jpg 600w, https://en.ovcharov.me/uploads%2Fresized%2Furu-card-2-w800.jpg 800w, https://en.ovcharov.me/uploads%2F2020%2F06%2F29%2Furu-card-2.jpg 1200w"><figcaption>URU Card - touch keyboard and OLED screen</figcaption></figure>
<p>The keyboard should be implemented with the <strong>MPR121</strong> I2C touch-sensor controller, and the screen is a widely available <strong>OLED</strong> screen with the <strong>SSD1306</strong> controller. The screen is placed in the special cut in the PCB keeping the device thickness below 2 millimetres.</p>
<h2 id="framework-for-the-development">Framework for the development</h2>
<p>Fortunately, the <strong>Arduino</strong> framework is ported to the <strong>ESP32</strong> platform. There are hundreds of libraries for almost every use case and this factor should significantly simplify the project. There are libraries for <strong>ATECC508A</strong>, <strong>MPR121</strong> and <strong>SSD1306</strong> already. All that is needed is to wire everything together.</p>
<p>However, the Arduino IDE will be hardly usable for a project complex like this one. I am going to use Visual Studio Code + <strong>PlatformIO</strong> for the development and recommend others to do the same.</p>
<h2 id="the-current-state-of-the-project">The current state of the project</h2>
<p>At the moment the working <strong>BLE server</strong> with <strong>FIDO2</strong> endpoints is implemented. The device is “visible” and the computer connects to it in order to perform an authentication procedure. However, the commands are not implemented yet - it’s going to be the next step.</p>
<figure>
<img src="https://d33wubrfki0l68.cloudfront.net/42cf03f71cfe1940cec7bbce89f7b7689bcdc96f/5b9eb/uploads/resized/uru-card-3-w800.jpg" data-src="https://d33wubrfki0l68.cloudfront.net/42cf03f71cfe1940cec7bbce89f7b7689bcdc96f/5b9eb/uploads/resized/uru-card-3-w800.jpg" data-srcset="/uploads%2Fresized%2Furu-card-3-w150.jpg 150w, /uploads%2Fresized%2Furu-card-3-w300.jpg 300w, /uploads%2Fresized%2Furu-card-3-w600.jpg 600w, /uploads%2Fresized%2Furu-card-3-w800.jpg 800w, /uploads%2F2020%2F06%2F29%2Furu-card-3.jpg 1200w" sizes="(max-width: 230px) 150px, (max-width: 380px) 300px, (max-width: 680px) 600px, (max-width: 880px) 800px, 1200px" alt="URU Card - the components" title="URU Card - the components" srcset="https://en.ovcharov.me/uploads%2Fresized%2Furu-card-3-w150.jpg 150w, https://en.ovcharov.me/uploads%2Fresized%2Furu-card-3-w300.jpg 300w, https://en.ovcharov.me/uploads%2Fresized%2Furu-card-3-w600.jpg 600w, https://en.ovcharov.me/uploads%2Fresized%2Furu-card-3-w800.jpg 800w, https://en.ovcharov.me/uploads%2F2020%2F06%2F29%2Furu-card-3.jpg 1200w"><figcaption>URU Card - the components</figcaption></figure>
<p>There is a PCB design as well and you can try to build the device, but do it on your own risk - it’s in a very early stage now.</p>
<h2 id="joining-the-project">Joining the project</h2>
<p>Sweetest part. The project is free to join for everyone. The minimal requirement is just an ESP32 development board like the one below.</p>
<figure>
<img src="https://d33wubrfki0l68.cloudfront.net/69b040b8cb4968124bd224f9590788e74ac50f1d/f2b5c/uploads/resized/esp32-dev-board-w800.jpg" data-src="https://d33wubrfki0l68.cloudfront.net/69b040b8cb4968124bd224f9590788e74ac50f1d/f2b5c/uploads/resized/esp32-dev-board-w800.jpg" data-srcset="/uploads%2Fresized%2Fesp32-dev-board-w150.jpg 150w, /uploads%2Fresized%2Fesp32-dev-board-w300.jpg 300w, /uploads%2Fresized%2Fesp32-dev-board-w600.jpg 600w, /uploads%2Fresized%2Fesp32-dev-board-w800.jpg 800w, /uploads%2F2020%2F06%2F29%2Fesp32-dev-board.jpg 1200w" sizes="(max-width: 230px) 150px, (max-width: 380px) 300px, (max-width: 680px) 600px, (max-width: 880px) 800px, 1200px" alt="ESP32 development board" title="ESP32 development board" srcset="https://en.ovcharov.me/uploads%2Fresized%2Fesp32-dev-board-w150.jpg 150w, https://en.ovcharov.me/uploads%2Fresized%2Fesp32-dev-board-w300.jpg 300w, https://en.ovcharov.me/uploads%2Fresized%2Fesp32-dev-board-w600.jpg 600w, https://en.ovcharov.me/uploads%2Fresized%2Fesp32-dev-board-w800.jpg 800w, https://en.ovcharov.me/uploads%2F2020%2F06%2F29%2Fesp32-dev-board.jpg 1200w"><figcaption>ESP32 development board</figcaption></figure>
<p>The security element, screen and keyboard can be purchased separately and attached as external modules.</p>
<p>The links to the GitHub repository and other useful resources are given below.</p>
<p>I will be really thankful if consider sharing the project and leave comments with your thoughts and suggestions.</p>
<h2 id="references">References</h2>
<ul>
<li><a rel="nofollow noopener noreferrer" target="_blank" href="https://github.com/uru-card/uru-card">GitHub repository</a></li>
<li><a rel="nofollow noopener noreferrer" target="_blank" href="https://hackaday.io/project/173443-uru-card">Project on Hackaday.io</a></li>
<li><a rel="nofollow noopener noreferrer" target="_blank" href="https://platformio.org/">PlatformIO</a></li>
</ul>
</article>
</section>
</div>
</div>
</section>
</div></div>]]>
            </description>
            <link>https://en.ovcharov.me/2020/06/29/uru-card-arduino-fido2-authenticator/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23676006</guid>
            <pubDate>Mon, 29 Jun 2020 09:57:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: The Importance of Logging – Introducing Logality]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23675078">thread link</a>) | @thanpolas
<br/>
June 28, 2020 | https://thanpol.as/nodejs/why-logs-are-important-introducing-logality | <a href="https://web.archive.org/web/*/https://thanpol.as/nodejs/why-logs-are-important-introducing-logality">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <div>
    <div>

      
      <p><time datetime="2020-06-27 00:00:00 +0000">27 Jun 2020</time></p><p>Having your application produce the right amount and quality of logs will help you debug faster, optimize better and keep your data safe and secure. I was always fascinated with logging and tried to figure out the best ways to log and create telemetry for my applications.</p>

<p>Having the opportunity to work with multiple startups, I came into close contact with all of Node.js’ major logging packages. Lately, I had the luck to work with highly security aware businesses, for whom security is an existential threat. When tasked with the challenge of creating secure applications for them, I knew without hesitation that I had to create a new library to meet all the new requirements that were at play.</p>

<p>I want to introduce you to <a href="https://github.com/thanpolas/logality">Logality</a>, a versatile and powerful logger for Node.js.</p>

<p><img src="https://thanpol.as/assets/blogimg/planning.jpg" alt="Logging Flow"></p>

<h2 id="the-logging-requirements">The Logging Requirements</h2>

<p>These are the logging requirements that were on the drawing board when Logality was first implemented. I could find some of them in some packages, but not all of them in one package:</p>

<ul>
  <li><a href="#a-common-logging-schema"><strong>Complete Flexibility on Properties</strong></a>. In order for my organization to have a common logging schema, it is required of the logging library to allow the definition of properties from scratch. A lot of the packages make those decisions for you leaving you with no options to normalize the logging schema. The most common example for this is the date field, you can find it as <code>dt</code>, <code>date</code>, <code>timestamp</code> or any other variance, without any option to change the name.</li>
  <li><a href="#serializers-of-data-objects"><strong>Serializers of Data Objects</strong></a>. As <a href="https://github.com/thanpolas/logality">Logality</a> is primarily a JSON logger, dealing with data is the most common operation. Being able to serialize known data structures is key in this case. Just drop your user data object to logality and the built-in or your custom serializer will make sure to transform the object so only what you want will be logged.</li>
  <li><a href="#custom-output-and-pretty-print"><strong>Support Custom Outputs</strong></a>. Logality’s Default output is JSON but the library should not limit you as to the kind of output you want, for instance print human readable logs while on development. Custom outputs also allow you to filter log messages so you can suppress dynamically certain types or log levels of messages.</li>
  <li><a href="#logging-metadata"><strong>Logging Metadata</strong></a>. Have the logger automatically log the location of the file that the log originated from. As well as other useful system information (OS version, runtime info, etc).</li>
  <li><a href="#the-power-of-middleware"><strong>Middleware Support</strong></a>. Supporting middleware is a very powerful way to transform and augment each one of your log messages. The options that this feature opens up are endless.</li>
  <li><a href="#linking-multiple-logality-instances"><strong>Logging for Libraries</strong></a>. All open source contributors must have faced this challenge at least once: How do I output logs from my library? This is no easy task, Logality provides an eloquent and powerful solution to this problem.</li>
</ul>

<p>With these requirements in place, <a href="https://github.com/thanpolas/logality">Logality</a> was created on May 18, 2018. Ever since then the library has been iteratively improving and bug fixed. Today, the current Version is 3.0.0, which was released on April of 2020. In the following sections, we will go through a more detailed analysis of the features and powerful capabilities of Logality.</p>

<h2 id="a-common-logging-schema">A Common Logging Schema</h2>

<p>The more standardized your log messages are, the easier it will be to query, parse and subsequently analyze them. Consequently, your log messages need to have a schema. As we all know, the most ubiquitous format for text based serialization today, is JSON.</p>

<p>Logality is a JSON logger that provides an initial recommendation of a logging schema but allows you to define your own schemas down to the last property.</p>

<p>This is a very important feature. When you are trying to have a common logging schema across multiple operating systems, platforms and programming languages, it is essential that your tooling allows you to be flexible and versatile.</p>

<p>Schema mutation in Logality happens through <a href="#the-power-of-middleware">Middleware</a> and <a href="#serializers-of-data-objects">Serializers</a>, both of which we touch on below.</p>



<p>Logality will take care of all your metadata needs so you won’t need to log any additional information. In particular, Logality will automatically resolve and log for you:</p>

<ul>
  <li>The location of the file where the log originated from.</li>
  <li>The hostname of the machine that runs the application.</li>
  <li>The process id.</li>
  <li>The process name.</li>
</ul>

<p>A simple <code>log.info('hello world')</code> log will produce the following log message (expanded):</p>

<div><div><pre><code><span>{</span><span>
    </span><span>"severity"</span><span>:</span><span> </span><span>6</span><span>,</span><span>
    </span><span>"level"</span><span>:</span><span> </span><span>"info"</span><span>,</span><span>
    </span><span>"dt"</span><span>:</span><span> </span><span>"2018-05-18T16:25:57.815Z"</span><span>,</span><span>
    </span><span>"message"</span><span>:</span><span> </span><span>"hello world"</span><span>,</span><span>
    </span><span>"event"</span><span>:</span><span> </span><span>{},</span><span>
    </span><span>"context"</span><span>:</span><span> </span><span>{</span><span>
        </span><span>"runtime"</span><span>:</span><span> </span><span>{</span><span>
            </span><span>"application"</span><span>:</span><span> </span><span>"testLogality"</span><span>
        </span><span>},</span><span>
        </span><span>"source"</span><span>:</span><span> </span><span>{</span><span>
          </span><span>"file_name"</span><span>:</span><span> </span><span>"/test/spec/surface.test.js"</span><span>
        </span><span>},</span><span>
        </span><span>"system"</span><span>:</span><span> </span><span>{</span><span>
            </span><span>"hostname"</span><span>:</span><span> </span><span>"localhost"</span><span>,</span><span>
            </span><span>"pid"</span><span>:</span><span> </span><span>36255</span><span>,</span><span>
            </span><span>"process_name"</span><span>:</span><span> </span><span>"node ."</span><span>
        </span><span>}</span><span>
    </span><span>}</span><span>
</span><span>}</span><span>
</span></code></pre></div></div>

<p>With the use of <a href="#the-power-of-middleware">Middleware</a> you can create and attach your own metadata on each one of your log messages.</p>

<h2 id="serializers-of-data-objects">Serializers of Data Objects</h2>

<p>As standardization of logging data is a primary requirement for Logality, serializers were introduced to solve the problem of consistently logging known data objects.</p>

<p>Let’s take for example the User Data Object (UDO) and the action of logging in, you could log the event as:</p>

<div><div><pre><code><span>log</span><span>.</span><span>info</span><span>(</span><span>`User </span><span>${</span><span>user</span><span>.</span><span>email</span><span>}</span><span> logged in`</span><span>);</span>
</code></pre></div></div>

<p>But that is not a JSON log message, that is a string log message and it is not easily query-able. Let’s try this again with Logality’s JSON logging feature:</p>

<div><div><pre><code><span>log</span><span>.</span><span>info</span><span>(</span><span>'</span><span>User logged in</span><span>'</span><span>,</span> <span>{</span><span>user</span><span>});</span>
</code></pre></div></div>

<p>Now we passed the UDO to logality, however, Logality has no instruction of what portions of the UDO we want logged and here is where serializers come in. Serializers are simple functions that take the objects that you pass as input and output the properties that you want to have logged.</p>

<p>This way, you standardize how your models are logged across your infrastructure and protect your system from logging sensitive fields like a user’s password or unnecessary information like meta data of a product.</p>

<h2 id="the-power-of-middleware">The Power of Middleware</h2>

<p>Logality introduces middleware which allows you to manipulate and mutate the logging messages as you see fit:</p>

<div><div><pre><code><span>logality</span><span>.</span><span>use</span><span>((</span><span>context</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>// Remove user data object from logging</span>
    <span>delete</span> <span>context</span><span>.</span><span>user</span><span>;</span>

    <span>// Add debugging flag on all messages</span>
    <span>context</span><span>.</span><span>debug</span> <span>=</span> <span>1</span><span>;</span>
<span>});</span>
</code></pre></div></div>

<p>With Middleware, you can create powerful data flows, augmenting log messages as they come in with rich metadata information collected from the environment and runtime.</p>

<p>You can also have conditional transformations of the data that pass through logality for absolute control over the data flows and your compliance requirements.</p>

<h2 id="linking-multiple-logality-instances">Linking Multiple Logality Instances</h2>

<p>As an open source contributor, one of the biggest problems I have been challenged with is how to log on open source libraries. If you want to have logging on your library you are challenged with quite a few problems:</p>

<ul>
  <li>Provide an option to turn off logging.</li>
  <li>Provide a way to filter the logging level.</li>
  <li>How do you format the logs according to your downstream application’s standards?</li>
  <li>Should you log to stdout, an event or a function?</li>
</ul>

<p>These are very challenging problems, to the point where no practical solution exists. Until today that is, as Logality introduces piping. You can pipe one Logality instance into another and have all the middleware functions handle the piped logality’s log messages. When Logality is piped, the log messages get passed as pure data objects so that the downstream consuming function can properly parse and manipulate them.</p>

<p>This is huge as it enables your application to granularly control how much information is logged from the libraries you are using. And at the same time have your third-party libraries log in the exact same format-schema that your entire infrastructure is logging. Isn’t that great?</p>

<p>Piping happens simply by providing the child Logality instance to the parent’s <code>pipe()</code> method:</p>

<div><div><pre><code><span>const</span> <span>thirdPartyLibrary</span> <span>=</span> <span>require</span><span>(</span><span>'</span><span>thirdparty</span><span>'</span><span>);</span>

<span>/* ... */</span>

<span>applicationLogality</span><span>.</span><span>pipe</span><span>(</span><span>thirdPartyLibrary</span><span>.</span><span>logality</span><span>);</span>
</code></pre></div></div>

<h2 id="custom-output-and-pretty-print">Custom Output and Pretty Print</h2>

<p>Finally, after all the processing the log message has gone through, you can control how the final serialization and output is handled. By default Logality will JSON serialize and output to stdout but you may have other plans.</p>

<p>This operation also enables you to filter certain log messages based on your custom criteria. This is particularly useful when managing multiple log streams from various upstreams (third-party libraries) that are piping their logs to your main application Logality logger.</p>

<p>Logality also offers a built-in pretty print functionality that, as the word suggests, will print the log messages in a human readable format, with nice colors, emojis and all. This is particularly useful when you are developing the application and don’t want to see JSON serialized log messages.</p>

<h3 id="outline-of-logalitys-lifecycle-and-piping">Outline of Logality’s Lifecycle and Piping</h3>

<p><img src="https://thanpol.as/assets/blogimg/logality-lifecycle-outline.svg" alt="Logality Lifecycle Outline"></p>

<h2 id="synchronous-or-asynchronous">Synchronous or Asynchronous?</h2>

<p>With a flick of a switch you can have Logality become asynchronous and reveal its Promise API. When in async mode, Logality’s Middleware and Custom Output functions will be able to handle a promise and allow you to capture log messages en-route.</p>

<p>Say you want to push all log messages to a queue, or for any reason, you want to store some, or all, of the log messages into your database. By enabling async mode on Logality you can easily and safely perform those tasks:</p>

<div><div><pre><code><span>// Security middleware for logality, store the log message</span>
<span>// in our database as well and send it to our queue for</span>
<span>// further processing and alerting</span>
<span>logality</span><span>.</span><span>use</span><span>(</span><span>async</span> <span>(</span><span>context</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>if</span> <span>(</span><span>context</span><span>.</span><span>security</span><span>)</span> <span>{</span>
        <span>await</span> <span>db</span><span>.</span><span>store</span><span>(</span><span>context</span><span>);</span>
        <span>await</span> <span>queue</span><span>.</span><span>send</span><span>(</span><span>context</span><span>);</span>
    <span>}</span>
<span>});</span>

<span>/* ... */</span>

<span>// login failed, log it</span>
<span>await</span> <span>log</span><span>.</span><span>warn</span><span>(</span><span>'</span><span>Login Failed</span><span>'</span><span>,</span> <span>{</span><span>security</span><span>:</span> <span>true</span><span>});</span>
</code></pre></div></div>

<p>As you rightfully observed, when async mode is enabled Logality’s logging is, well, async, and thus returns a promise that needs to be resolved. Therefore, that is why you see the <code>await</code> before the <code>log.warn()</code> invocation.</p>

<p>Personally, my use case for using async mode and secondary data stores <a href="https://srop.co/" title="SROP The Secure Drop">at SROP</a> was for auditing log trails. When an audit log event occurred, …</p></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thanpol.as/nodejs/why-logs-are-important-introducing-logality">https://thanpol.as/nodejs/why-logs-are-important-introducing-logality</a></em></p>]]>
            </description>
            <link>https://thanpol.as/nodejs/why-logs-are-important-introducing-logality</link>
            <guid isPermaLink="false">hacker-news-small-sites-23675078</guid>
            <pubDate>Mon, 29 Jun 2020 06:57:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Write Once, Build Anywhere]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23674501">thread link</a>) | @todsacerdoti
<br/>
June 28, 2020 | https://dave.autonoma.ca/blog/2020/06/29/write-once-build-anywhere/ | <a href="https://web.archive.org/web/*/https://dave.autonoma.ca/blog/2020/06/29/write-once-build-anywhere/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>Cross-compiling self-contained Java desktop application launchers.</p><h2 id="backstory">Backstory</h2><p>Java’s promise of <em>write once, run anywhere</em> still resonates with me, perhaps because I cut my teeth on JDK 1.0.2b. It was amazing to write cross-platform networking applications without concern for variations in POSIX implementations, or having to worry about nuances between C compilers, or even needing to grok <code>htons</code>. Someone else could wrestle with <code>#ifdef</code>s, shielding others by high-level, standard abstractions. Although Smalltalk had concocted platform-independence punch in 1983, it wasn’t until 1996 that Java’s virtual machine (VM) and subsequent OEM distributions made drinking the mantra of cross-platform development an easy reality.</p><p>Strategically—and selfishly—Microsoft smote that future with a sledgehammer: it moved to <em>embrace and extend</em> Java to achieve vendor lock-in, splintering the platform.</p><p>Developers can no longer rely on systems having a Java VM available. This implies that end-users must download (and install) two independent programs: a suitable VM and a Java archive. It also means that developers now have choices ahead of them that were once bygone worries. Choices that burden end-users and developers alike. Asking people to download a VM for their operating system and CPU architecture is a barrier to product adoption. What’s worse is that some VMs now support “full” Java while others don’t support JavaFX modules at all.</p><p>We’ll address that last point later.</p><p>In late 2019, <a href="https://github.com/kevinrushforth">Kevin Rushforth</a>, of Oracle’s Java Team, <a href="https://youtu.be/ZGW9AalZLN4?t=504">presented</a> a solution to the packaging problem: <code>jpackage</code> and <code>jlink</code>. During the presentation he listed some of the tooling’s shortcomings, which include:</p><ul><li>No cross-platform deployment</li><li>No cross-compilation (must run on MacOS to produce <code>.dmg</code>)</li></ul><p>Let’s not mince words: Java developers could once build applications on their preferred operating system and deploy anywhere; now, they must build installers for every individual platform they intend to target on those very systems.</p><p>Was that the <em>punch-line</em> to a two-decade lead up?</p><p>Requiring developers to have at least two commercial operating systems (Windows, MacOS X), even if emulated inside of a virtualized container—as opposed to using physical hardware—for a platform-independent programming language is an ironic barrier to entry. <em>Especially</em> for people bereft of bankroll.</p><p>Yes, those tools—alongside modules—help produce minimal executables. Who cares? What they don’t do is make it possible to create a set of native, standalone launcher binaries from a single build machine. Let’s fix that by pouring over the big splashes of how to cross-compile application launchers for Java on one build machine. We’ll use Linux because it’s free.</p><h2 id="software-requirements">Software Requirements</h2><p>You will need:</p><ul><li><a href="https://github.com/dgiagio/warp">Warp Packer</a>, a tool for building native application launchers</li><li><a href="https://git-scm.com/">git</a>, a source code management tool</li><li><a href="https://www.gnu.org/software/wget/">wget</a>, a tool for fetching files</li><li><a href="https://gradle.org/">gradle</a> version 6.4.1, a build system</li><li><a href="https://dave.autonoma.ca/blog/2020/06/29/write-once-build-anywhere/build-template">build-template</a>, my own starter shell script (MIT licensed)</li></ul><p>Install <code>git</code> and <code>wget</code> using the package manager for your Linux distro.</p><h3 id="install-warp-packer">Install Warp Packer</h3><p>The installation instructions for Warp Packer are a bit buried. Install the software on a Linux system as follows (change the version number to suit):</p><pre><code>mkdir -p $HOME/bin
cd $HOME/bin
wget -O warp-packer \
  https://github.com/dgiagio/warp/releases/download/v0.3.0/linux-x64.warp-packer
chmod +x warp-packer</code></pre><p>If needed, include <code>$HOME/bin</code> in the <code>PATH</code> environment variable by adding the following line to <code>$HOME/.bashrc</code>:</p><pre><code>export PATH="$PATH:$HOME/bin"</code></pre><p>Apply the new environment settings by opening a new terminal or <code>source</code>’ing the <code>.bashrc</code> file directly.</p><p>Warp Packer is installed.</p><h3 id="install-build-template">Install Build Template</h3><p>Copy, move, or download <code>build-template</code> into <code>$HOME/bin</code>.</p><p>The build template is installed.</p><h2 id="javafx">JavaFX</h2><p>Before we get into building a Java application, a little more history is warranted. Originally, the Abstract Window Toolkit (AWT) came bundled with Java, for the same reasons that having a bundled networking API was useful. The AWT lacked aesthetic, both in appearance and as a library. Swing, the AWT’s successor, made strides to address both, but fell short. JavaFX, which was also initially bundled with Java (versions 8 to 10), is a modern graphical user interface (GUI) library for developing desktop applications, as well as a superb replacement for Swing.</p><p>It has been argued that JavaFX should never have been bundled with Java. Nevertheless, the decision to un-bundle JavaFX from Java 11 onwards has led to Java projects that will be stuck with old Java versions for years to come—possibly leading to their abandonment—because it takes <em>a lot</em> of effort to migrate a build process to support these new, un-bundled Java Development Kits (JDKs).</p><p>Part of that effort entails re-bundling JavaFX. There are a few ways this can be accomplished:</p><ul><li>Create a single <em><a href="https://stackoverflow.com/a/11947093/59087">überjar</a></em> that contains native libraries for all intended platform targets.</li><li>Create separate <em>überjars</em>, with each JAR containing native libraries specific to its target platform.</li></ul><p>It’s almost a <a href="https://en.wikipedia.org/wiki/Hobson%27s_choice">Hobson’s choice</a> because we have to create launcher binaries for each target platform anyway. Meaning bundling all of the target platform libraries into each native launcher is wasteful; however, bundling them in a single JAR file for those who have a Java VM installed already may be somewhat useful.</p><p>Java has introduced the concept of modules, looking to simplify the build process. Sometimes, though, modules cannot be included because of outdated dependencies. Problems can arise when running <code>jlink</code> against old dependencies. Compounding the issue is when the projects have been sundowned or have long release schedules. Nevertheless, for our purposes, we’ll want to download a version of OpenJDK that supports JavaFX.</p><p>With that background in mind, let’s go cross-compile some binaries.</p><h2 id="java-application">Java Application</h2><p>We’ll create native application launchers for <a href="https://github.com/DaveJarvis/scrivenvar/">Scrivenvar</a>, a JavaFX-based text editor that I’ve been developing.</p><p>Dive in by cloning the latest version as follows:</p><pre><code>mkdir -p $HOME/dev
cd $HOME/dev
git clone https://github.com/DaveJarvis/scrivenvar.git
cd scrivenvar</code></pre><p>The application is downloaded.</p><h2 id="build-scripts">Build Scripts</h2><p>Let’s review the scripts that help build the application, which include:</p><ul><li><code>build.gradle</code> — builds application Java Archive (JAR) files</li><li><code>installer</code> — builds native, standalone binaries</li></ul><p>Separating the <code>installer</code> script’s responsibilities from <code>build.gradle</code> is not necessary, technically. When running third-party executables (e.g., <code>warp-packer</code>), my first inclination is to use a shell script, rather than gradle’s <code>exec</code>.</p><p>The <code>installer</code> script invokes <code>gradle</code> when requested.</p><h2 id="gradle-script">Gradle Script</h2><p>Open up <code>build.gradle</code> to review a few pertinent code blocks.</p><h3 id="target-operating-system">Target Operating System</h3><p>The first snippet determines what native JavaFX libraries (i.e., target platform code) to include within the JAR file:</p><pre><code>String[] os = ["win", "mac", "linux"]

if (project.hasProperty('targetOs')) {
  if ("windows".equals(targetOs)) {
    os = ["win"]
  }
  else {
    os = [targetOs]
  }
}</code></pre><p>Unless instructed otherwise, the build script will create a JAR file that includes JavaFX binaries for Windows, Linux, and MacOS embedded. We can target a specific platform by using the <code>-P</code> command line option when building, such as:</p><pre><code>gradle clean build jar -PtargetOs=linux</code></pre><p>There’s a catch here in that <code>win</code> and <code>windows</code> are different names. The <code>installer</code> script needs to use <code>windows</code> because that’s part of the JDK file name being downloaded. Arguably, we could move that logic into the <code>installer</code> script, but the point is that the JDK filename and JavaFX refer to Windows using different terminology. The difference must be captured somwhere.</p><h3 id="javafx-dependencies">JavaFX Dependencies</h3><p>The second snippet tells the build system to include JavaFX for a given set of operating systems, as follows:</p><pre><code>def fx = ['controls', 'graphics', 'fxml', 'swing']

fx.each { fxitem -&gt;
  os.each { ositem -&gt;
    runtimeOnly "org.openjfx:javafx-${fxitem}:${javafx.version}:${ositem}"
  }
}</code></pre><p>The application uses JavaFX controls, graphics, fxml, and notice that it also lists a JavaFX-Swing integration. Using <code>.each</code> is a tidy way of not having to maintain a list of JavaFX-specific imports for each operating system, should either or both need to change.</p><h3 id="javafx-exclusions">JavaFX Exclusions</h3><p>Of lesser importance are exclude groups:</p><pre><code>implementation('de.jensd:fontawesomefx-fontawesome:4.7.0-11') {
  exclude group: 'org.openjfx'
}</code></pre><p>Without excluding JavaFX from certain JavaFX-related dependencies, the build will fail. Unfortunately, the build fails in such a way that the developer must investigate what package caused the conflict. Ideally, the build failure would pinpoint any collisions for the developer.</p><h3 id="run-application">Run Application</h3><p>The last point of note are the following lines:</p><pre><code>applicationDefaultJvmArgs = [
    "--add-opens=javafx.controls/javafx.scene.control=ALL-UNNAMED",
    "--add-opens=javafx.controls/javafx.scene.control.skin=ALL-UNNAMED",
    "--add-opens=javafx.graphics/com.sun.javafx.css=ALL-UNNAMED",
]</code></pre><p>These lines address permissions issues encountered when running the application using gradle, such as:</p><pre><code>gradle clean build run</code></pre><p>Now that we understand how this build script works, let’s move on to the <code>installer</code> shell script.</p><h2 id="installer-script">Installer Script</h2><p>Looking at the big picture, the <code>installer</code> script performs the following steps to create a native launcher binary:</p><ol type="1"><li>Configure platform-specific parameters for extraction.</li><li>Rebuild the <em>überjar</em> for the target platform.</li><li>Clean out the distribution directory for a fresh build.</li><li>Extract the target JDK into the distribution directory.</li><li>Create a platform-dependent launch script to run the application.</li><li>Copy the <em>überjar</em> into the distribution directory.</li><li>Wrap the distribution into a standalone binary.</li></ol><p>These high-level steps can be found in the <code>execute()</code> function.</p><p>Let’s take a closer look at how the script works.</p><h3 id="build-template">Build Template</h3><p>The <code>build-template</code> script is described in depth in the first three parts of my Typesetting Markdown series. We reuse the script here because it simplifies writing user-friendly shell scripts.</p><p>Downloading and extracting a requisite JDK is pivotal. JDKs can be downloaded from a few places, but most of them have …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dave.autonoma.ca/blog/2020/06/29/write-once-build-anywhere/">https://dave.autonoma.ca/blog/2020/06/29/write-once-build-anywhere/</a></em></p>]]>
            </description>
            <link>https://dave.autonoma.ca/blog/2020/06/29/write-once-build-anywhere/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23674501</guid>
            <pubDate>Mon, 29 Jun 2020 05:00:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Use Unix Pipes to Improve Chromecast Playback]]>
            </title>
            <description>
<![CDATA[
Score 84 | Comments 15 (<a href="https://news.ycombinator.com/item?id=23673825">thread link</a>) | @lowmemcpu
<br/>
June 28, 2020 | https://alexdelorenzo.dev/linux/2020/03/14/pipes | <a href="https://web.archive.org/web/*/https://alexdelorenzo.dev/linux/2020/03/14/pipes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">  <p>When casting from YouTube to a Chromecast, sometimes the audio playback will <a href="https://support.google.com/chromecast/thread/13807879?hl=en">skip</a> and <a href="https://support.google.com/youtube/thread/17251626?hl=en">stutter</a>. This issue is independent of the quality of the video, the FPS, or the internet connection. Trying to watch certain videos will reliably cause playback issues on the Chromecast.</p> <p>According to <a href="https://support.google.com/chromecast/thread/13807879">this thread</a>, the playback issue only appeared in the latest and final firmware update for the Chromecast. Successful playback of the videos was possible in the past, and casting the downloaded YouTube videos eliminates the problem entirely. The problem exists solely when casting certain videos using the YouTube app.</p>  <p>Given that the problem only occurs with the YouTube app, you can download a video and cast it via <a href="https://github.com/xat/castnow"><code>castnow</code></a> or <a href="https://github.com/skorokithakis/catt"><code>catt</code></a>, skipping the YouTube app entirely.</p> <p>You could do something like:</p> <div><div><pre><code><span>#!/usr/bin/env bash</span>

<span>export </span><span>url</span><span>=</span><span>"https://youtu.be/Kas0tIxDvrg"</span>

<span>function </span>cast<span>()</span> <span>{</span>
    <span>url</span><span>=</span><span>"</span><span>$1</span><span>"</span>
    
    <span>filename</span><span>=</span><span>$(</span>youtube-dl <span>--get-filename</span> <span>"</span><span>$url</span><span>"</span><span>)</span>
    youtube-dl <span>"</span><span>$url</span><span>"</span>
    
    <span># wait a bit to download the file</span>
    castnow <span>"</span><span>$filename</span><span>"</span>
    <span>rm</span> <span>"</span><span>$filename</span><span>"</span>
<span>}</span>

cast <span>"</span><span>$url</span><span>"</span>
</code></pre></div></div> <p>But having to skip using the YouTube app to cast is already a clunky solution, and downloading every video before playing them is an even worse user experience. Instant playback and ephemeral streams are what make for a pleasant video streaming experience in 2020, and this solution implements neither of them</p>  <p><a href="https://github.com/ytdl-org/youtube-dl/blob/master/README.md">Since <code>youtube-dl</code> allows us to output to <code>stdout</code></a>, if we can hook its <code>stdout</code> to a casting app, we could emulate the instant playback and ephemeral videos we expect because we don’t have to wait for an entire file to download.</p> <p>Unfortunately, <code>castnow</code> and <code>catt</code> won’t cast from <code>stdin</code>. You’re expected to pass it file locations to cast from.</p> <p>This is where one of my favorite shell features really shines: <a href="https://tldp.org/LDP/abs/html/process-sub.html">process substitution</a>.</p> <p>With process substitution, Bash gives us a convenient way to make ephemeral <a href="https://en.wikipedia.org/wiki/Anonymous_pipe">anonymous pipes</a>. This method is both efficient and concurrent, making this primitive an apt choice to build a solution to the problem at hand. A process reading the <a href="https://en.wikipedia.org/wiki/Pipeline_(Unix)">pipe</a> blocks until the pipe is opened by another process for writing. A process writing to the pipe will suspend until the pipe’s buffer is read by another process. The anonymous pipe will automatically remove itself, and when it is manually removed, its dependent processes will be terminated.</p> <p>When using process substitution, a process’ <code>stdout</code> is hooked up to an anonymous pipe. That pipe can be accessed from a file descriptor, and the location of the pipe is given to the calling process.</p> <div><div><pre><code><span>$ </span><span>echo</span> &lt;<span>(</span><span>echo</span> <span>"Content sent to pipe"</span><span>)</span>
/dev/fd/63

<span>$ </span><span>cat</span> &lt;<span>(</span><span>echo</span> <span>"Content sent to pipe"</span><span>)</span>
Content sent to pipe
</code></pre></div></div> <p>In the example above, the <code>&lt;(command)</code> syntax is how we invoke process substitution in Bash. The output of <code>command</code> is written to an anonymous pipe, and the calling process is given the location of the file descriptor to access that pipe.</p> <p>Using that example, we can take advantage of process substitution:</p> <div><div><pre><code>vlc &lt;<span>(</span>youtube-dl <span>-q</span> <span>-o</span> - <span>"</span><span>$url</span><span>"</span><span>)</span>
</code></pre></div></div> <p>The command above will play the YouTube video locally with <a href="https://www.videolan.org/vlc/index.html">VLC</a>, and illustrates that process substitution can work for our use case.</p> <p>However, when we try to use <code>castnow</code>, we can’t cast from the pipe:</p> <div><div><pre><code><span>$ </span>castnow &lt;<span>(</span>youtube-dl <span>-q</span> <span>-o</span> - <span>"</span><span>$url</span><span>"</span><span>)</span>
Error: Load failed
</code></pre></div></div> <p>Nor can we cast with <code>catt</code>:</p> <div><div><pre><code><span>$ </span>catt cast &lt;<span>(</span>youtube-dl <span>-q</span> <span>-o</span> - <span>"</span><span>$url</span><span>"</span><span>)</span>
Error: The chosen file does not exist.
</code></pre></div></div> <p>We know we can use VLC locally, and VLC also lets you cast to a Chromecast using its IP address.</p> <p>Let’s try that again using VLC:</p> <div><div><pre><code><span>function </span>cast_vlc<span>()</span> <span>{</span>
    <span>path</span><span>=</span><span>"</span><span>$1</span><span>"</span>

    <span># get the ip address for chromecast.lan host</span>
    <span>ip</span><span>=</span><span>$(</span>dig +short chromecast.lan | <span>tail</span> <span>-n</span> 1<span>)</span>

    vlc <span>-I</span> ncurses <span>\</span>
      <span>--sout</span> <span>'#chromecast'</span> <span>\</span>
      <span>--sout-chromecast-ip</span><span>=</span><span>"</span><span>$ip</span><span>"</span> <span>\</span>
      <span>--demux-filter</span><span>=</span>demux_chromecast <span>\</span>
      <span>"</span><span>$path</span><span>"</span> &lt; /dev/tty
<span>}</span>

cast_vlc &lt;<span>(</span>youtube-dl <span>-q</span> <span>-o</span> - <span>"</span><span>$url</span><span>"</span><span>)</span>
</code></pre></div></div> <p>That works.</p> <p>As an aside, we hook VLC’s <code>stdin</code> to <code>/dev/tty</code> so that we can use the ncurses interface even if we invoke the function from a script.</p> <p>Let’s look at the <a href="https://wiki.videolan.org/Documentation:Modules/ncurses/">ncurses interface</a>.</p> <div> <p><img src="https://d33wubrfki0l68.cloudfront.net/d0822203c304db88f3cbec618e94a3d9f55cd269/c5939/assets/imgs/converted/vlc-fs8.webp" loading="lazy"> </p> </div> <p>It only displays the file descriptor, and very little about the video itself. I’m not a fan of that.</p>  <p>Instead of using anonymous pipes, we can use <a href="https://en.wikipedia.org/wiki/Named_pipe">named pipes</a>. Named pipes are like anonymous pipes, except they are not anonymous (they have a name) nor are they ephemeral. Named pipes still give us the efficiency and concurrency benefits that anonymous pipes give us, but Bash lacks the syntactic sugar it has for process substitution when it comes to named pipes.</p> <p>This is how we create named pipes, write to them, read from them and remove them.</p> <div><div><pre><code><span>$ </span><span>mkfifo </span>ourpipe
<span>$ </span><span>echo</span> <span>"Content in pipe"</span> <span>&gt;</span> ourpipe &amp;
<span>$ </span><span>cat </span>ourpipe
Content <span>in </span>pipe
<span>$ </span><span>rm </span>ourpipe
</code></pre></div></div> <p>Not as pretty as <code>&lt;(command)</code>, but it gets the job done.</p> <p>We can give a named pipe the same name as our YouTube video, and that way, the VLC interface will show the name of what we’re watching.</p> <div><div><pre><code><span>function </span>cast_ytdl<span>()</span> <span>{</span>
  <span>url</span><span>=</span><span>"</span><span>$1</span><span>"</span>

  <span># create a temporary named pipe</span>
  <span># why? because vlc will show the file descriptor path if we just use process substitution</span>
  <span>filename</span><span>=</span><span>$(</span>youtube-dl <span>--get-filename</span> <span>"</span><span>$url</span><span>"</span><span>)</span>
  <span>path</span><span>=</span><span>"/tmp/</span><span>$filename</span><span>"</span>
  <span>mkfifo</span> <span>"</span><span>$path</span><span>"</span>

  <span># download in background, push to named pipe</span>
  youtube-dl <span>-q</span> <span>-o</span> - <span>"</span><span>$url</span><span>"</span> <span>&gt;</span> <span>"</span><span>$path</span><span>"</span> &amp;
  <span>pid</span><span>=</span><span>"</span><span>$!</span><span>"</span>
  <span>disown</span> <span>$pid</span>

  <span># cast from named pipe</span>
  cast_vlc <span>"</span><span>$path</span><span>"</span>

  <span># cleanup process and named pipe</span>
  <span>kill</span> <span>-9</span> <span>"</span><span>$pid</span><span>"</span> &amp;&gt; /dev/null
<span>}</span>

cast_ytdl <span>"</span><span>$url</span><span>"</span>
</code></pre></div></div> <p>This works, too.</p> <p>We need to manually create a named pipe with <a href="https://linux.die.net/man/1/mkfifo"><code>mkfifo</code></a>, redirect <code>youtube-dl</code>’s <code>stdout</code> to the named pipe while running the process in the background, and then cleanup the process after casting from it via VLC, otherwise it might linger in the background. Each of those tasks would have been handled for us automatically using process substitution.</p> <p>But it does look a bit better:</p> <div> <p><img src="https://d33wubrfki0l68.cloudfront.net/25d68fb2085191adb26bb931e9bb31c638e5a634/f664c/assets/imgs/converted/vlc3-fs8.webp" loading="lazy"> </p> </div>  <p>Pipes, anonymous pipes and named pipes are also known by another name because of the way they behave: <a href="https://en.wikipedia.org/wiki/FIFO_(computing_and_electronics)#Pipes">FIFOs</a>, or <strong>f</strong>irst <strong>i</strong>n, <strong>f</strong>irst <strong>o</strong>ut. What’s written to the pipe is read from the pipe in first in, first out order. This behavior maps well to video streaming.</p> <p>While you can interact with anonymous and named pipes like you would a file, the interface isn’t 1:1 with a <a href="https://en.wikipedia.org/wiki/Unix_file_types#Regular_file">standard file</a>. You cannot <code>seek()</code> forward or backward in pipe, you can just read the next forward values. For our use case, that means we cannot skip forward or backward in our streaming videos. We can only play, pause or stop the video.</p> <p>That’s not a problem for me, however it’s something that can be mitigated if it’s a problem for you. The first solution I can think of would be to write to a temporary file via <code>youtube-dl</code> and read from it. Or <a href="https://alexdelorenzo.dev/programming/2019/04/14/buffer">perhaps a temporary spooled file can act as a buffer for the pipe</a>, such that you can <code>seek()</code> through the buffer, but the buffer itself is ephemeral unlike a normal file.</p> </div></div>]]>
            </description>
            <link>https://alexdelorenzo.dev/linux/2020/03/14/pipes</link>
            <guid isPermaLink="false">hacker-news-small-sites-23673825</guid>
            <pubDate>Mon, 29 Jun 2020 02:27:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Redash Is Joining Databricks]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23673728">thread link</a>) | @weitingliu
<br/>
June 28, 2020 | https://blog.redash.io/redash-joins-databricks/ | <a href="https://web.archive.org/web/*/https://blog.redash.io/redash-joins-databricks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <section>
                <div>
                    <p>We’re happy to announce that Redash is joining Databricks. We’ve been an open-source company grounded in helping our community of users make sense of their data. We found this same culture and values in Databricks, and we’re excited to be able to carry on our vision to democratize access to data — now in a larger home where we can bring this to even more people.</p><p>We’re excited to be one of the many open-source projects that Databricks supports. They’re the original creators of Apache Spark™, the standard for large-scale data processing, as well as Delta Lake for reliable data lakes, MLflow for the machine learning lifecycle, Koalas for data science productivity on Spark. Now, Redash joins this community of open source projects for collaborative SQL queries and dashboarding. We look forward to growing the Redash engineering team and have a lot of plans in our road map to deliver an even better experience with Redash, with more functionality, security and support. Open Source Redash remains in its current code repo, and we will be releasing a new v9 shortly so stay tuned for more details.</p><p>As part of this acquisition, we will be offering a new way to use Redash from directly within Databricks. For our current Redash SaaS paid customers, your service will continue unchanged, and we will be sharing more details in the coming months on how we’re planning to expand the service. You can learn more in our <a href="https://redash.io/help/faq/databricks">customer FAQ</a>.</p>
                </div>
            </section>

            


        </article>


    </div>
</div></div>]]>
            </description>
            <link>https://blog.redash.io/redash-joins-databricks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23673728</guid>
            <pubDate>Mon, 29 Jun 2020 02:09:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rant about new Windows console]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23673694">thread link</a>) | @xiaodai
<br/>
June 28, 2020 | https://clips.twitch.tv/TalentedSparklyDoveVoHiYo | <a href="https://web.archive.org/web/*/https://clips.twitch.tv/TalentedSparklyDoveVoHiYo">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://clips.twitch.tv/TalentedSparklyDoveVoHiYo</link>
            <guid isPermaLink="false">hacker-news-small-sites-23673694</guid>
            <pubDate>Mon, 29 Jun 2020 02:01:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My venture in hacking a fake vintage radio]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23673673">thread link</a>) | @ca98am79
<br/>
June 28, 2020 | https://www.tnhh.net/posts/adventures-hacking-fake-vivitar-vintage-radio.html | <a href="https://web.archive.org/web/*/https://www.tnhh.net/posts/adventures-hacking-fake-vivitar-vintage-radio.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><img src="https://media0.giphy.com/media/dCcLQ5TLFANMj0p3Uh/giphy.gif" alt="Press F to pay respects"></p>
<p>For a year or so I have owned a nice fake-vintage radio/bluetooth speaker that originally caught my eye for sale in a FedEx office. The front has a quite nice VFD-style LED to show the status, a volume knob and four hard buttons. It has Bluetooth, USB, AUX and FM input. The radio and bluetooth was not bad, but there was nothing to be impressed about. It was definitely not "smart."</p>
<p>I decided to hack it to make it a bit smarter: to do AirPlay and be a smart alarm clock and whatever else I could think of. Since it was inexpensive, I had nothing to lose and everything to win. I thought putting a Raspberry Pi 0 or something in it would be nice.</p>
<p>My original plan was to somehow figure out how to hijack all the external components and control them to make the front and back of the radio as neat-looking as possible. At least I hoped to hijack the speaker, the volume knob, and the buttons. The problem I foresaw was that those components are often not documented and there was little chance that I could get a datasheet for them. I was very worried that I might have to give up the fake-VFD LED screen.</p>
<p>It turns out that I had to spend a year hacking it on and off. Here goes.</p>
<p><img src="https://www.tnhh.net/assets/posts-images/fake-radio-hack/fedex-sale.jpg" alt="FedEx sale"></p>
<p>First, I gutted the radio and saw that it has a main PCB with the LED panel directly soldered to it.</p>
<p><img src="https://www.tnhh.net/assets/posts-images/fake-radio-hack/radio-disassembled.jpg" alt="Disassembled radio"></p>
<p>The chip on the PCB isn't something I recognized. Luckily, the knob and the hard buttons are on a separate breakout board and are connected to the mainboard via a connector.</p>
<p><img src="https://www.tnhh.net/assets/posts-images/fake-radio-hack/main-pcb.jpg" alt="Main PCB"></p>
<h2 id="the-speaker">The speaker</h2>
<p>The speaker is also easy to deal with, as it is completely ordinary. It only required me to desolder it from the mainboard. As the Pi 0 has no built-in soundcard, I had to get a separate sound card for it.</p>
<h3 id="audio-injector-zero">Audio Injector Zero</h3>
<p>Initially, I used the Audio Injector Zero that I have no use for normally. To save space, I decided to permanently sandwich the Audio Injector to the Pi 0. I also had to buy a cheap amp for it, as the sound card can't directly drive the speaker.</p>
<p>One little issue was that the sound card produces stereo input, and the amp is also stereo, but I only have one speaker. I needed to mix both channels left and right to that speaker somehow. To that end, I am sure a Linux guru could make it work with configuring the sound card in software. However, I am not extremely well-versed with how ALSA or Pulse Audio works. I just wired both channels left and right of the amp to one channel input of the amp to mix the channels. For power, the amp needs 5V input, so I siphoned the two power pins from the Raspberry Pi.</p>
<p>I was surprised when the amp produced a very annoying hum. The hum was extremely noticeable when the Pi is under load. I don't know exactly why this happens, but I spent way too much time on this with no significant improvement. Ultimately, I decided it's the cheap amp that was giving me a hard time, because it was way too noisy. I know the Audio Injector itself was okay because the headphones output was clean.</p>
<h3 id="google-aiy-voice-hat">Google AIY voice hat</h3>
<p>After giving up on the Audio Injector Zero + Amp solution, I tried a different route: Drive the speaker directly with the Google AIY voice bonnet hat. Because the Google AIY sound card doesn't provide an easy way to set up on a plain raspbian, I just got their distro and started from there.</p>
<p>The speaker was hum-free after switching to the Google AIY soundcard. The tradeoff was that the Google Voice Bonnet V2 sound card made the stack quite a bit thicker. It has a female row of pins soldered on it, so I couldn't solder it directly on top of the Pi Zero.</p>
<p><img src="https://www.tnhh.net/assets/posts-images/fake-radio-hack/sound-cards.jpg" alt="Sound cards"></p>

<p>The front panel of the radio has two sets of elements: A knob of some sort to control the volume and four hard buttons. It has four wires hanging out of it. After I inspected the traces on the PCB, it was apparent that there is one common ground. The three other pins are for the buttons and the knob. All of the buttons are connected to a single pin, and the volume knob is connected to the other two.</p>
<p><img src="https://www.tnhh.net/assets/posts-images/fake-radio-hack/buttons-knob.jpg" alt="Buttons and knobs"></p>
<p>As a software person, I didn't know what the knob is called. <a href="http://dbindner.freeshell.org/">Dr. Don Bindner</a> suggested that the button might be a rotary encoder, and that turned out to be true. It seemed <a href="http://www.learningaboutelectronics.com/Articles/Rotary-encoder-circuit.php">trivial enough to read the knob</a>.</p>
<p>The buttons are more interesting. After poking around with a multimeter, it turned out that the buttons were tactile but each of them is connected in series to a different resistor. Then they all connect out to the same pin. The software in the chip scans the pin and figures out what button was pressed by sampling from an Analog-to-Digital (ADC) Converter reading. As the Pi has no ADC, we need something else that has an ADC to figure out what the button was pressed. Of course, I could as well hijack the tactile buttons and not have to deal with the ADC stuff but that seemed too aesthetically unpleasant for me.</p>
<p>I decided to pull out anArduino Pro Micro clone that I bought from China years ago. My reasoning for using the Pro Micro:</p>
<ol>
<li>The Arduino Pro Micro is super cheap: $2 cheap.</li>
<li>Even if I could add an ADC to the Pi, I need to continuously read the ADC from the Pi. That is a pain in the neck. I can't guarantee the timings on the Pi without going to a lot of care.</li>
<li>The Pro Micro can emulate a keyboard over USB, so the Pi can use triggerhappy to catch it.</li>
</ol>
<p>So with that, I made my arduino sketch and it worked out. I wanted to emulate the Winamp-style buttons ZXCV for multimedia keys and UD for volume up/down. Later on, I was quite annoyed with it because the keyboard dumps the keystrokes to the terminal, and <a href="https://androidcommunity.com/very-odd-bug-found-in-jailbreaking-process-20081109/">it could be bad</a>. I decided to implement the keys as multimedia keys. Unfortunately, you need a HID library to implement multimedia keys. Luckily, there is a library called <a href="https://github.com/NicoHood/HID">HID-Project</a> to achieve exactly what I wanted. After some tweakings for debounce, I could get the volume knob and the buttons to work exactly as I expected:</p>
<div><div><pre><code><span>void</span> <span>pressKey</span><span>(</span><span>uint16_t</span> <span>k</span><span>,</span> <span>int</span> <span>d</span><span>)</span> <span>{</span>
  <span>Consumer</span><span>.</span><span>write</span><span>(</span><span>k</span><span>);</span>
  <span>if</span> <span>(</span><span>d</span><span>)</span> <span>{</span>
    <span>delay</span><span>(</span><span>d</span><span>);</span>
  <span>}</span>
<span>}</span>

<span>void</span> <span>kbd_loop</span><span>()</span> <span>{</span>
  <span>if</span> <span>(</span> <span>millis</span><span>()</span> <span>&lt;</span> <span>debounce</span> <span>+</span> <span>debouncerMs</span><span>)</span> <span>{</span>
    <span>return</span><span>;</span>
  <span>}</span>
  
  <span>// Volume rotary handling</span>
  <span>boolean</span> <span>encoderA</span> <span>=</span> <span>digitalRead</span><span>(</span><span>encoderPinA</span><span>);</span>
  <span>boolean</span> <span>encoderB</span> <span>=</span> <span>digitalRead</span><span>(</span><span>encoderPinB</span><span>);</span>

  <span>if</span> <span>((</span><span>encoderA</span> <span>==</span> <span>HIGH</span><span>)</span> <span>&amp;&amp;</span> <span>(</span><span>encoderB</span> <span>==</span> <span>HIGH</span><span>))</span> <span>{</span>
    <span>if</span> <span>((</span><span>encoderALast</span> <span>==</span> <span>LOW</span><span>)</span> <span>&amp;&amp;</span> <span>(</span><span>encoderBLast</span> <span>==</span> <span>HIGH</span><span>))</span> <span>{</span>
      <span>pressKey</span><span>(</span><span>MEDIA_VOL_UP</span><span>,</span> <span>0</span><span>);</span>
    <span>}</span> <span>else</span> <span>if</span> <span>((</span><span>encoderBLast</span> <span>==</span> <span>LOW</span><span>)</span> <span>&amp;&amp;</span> <span>(</span><span>encoderALast</span> <span>==</span> <span>HIGH</span><span>))</span> <span>{</span>
      <span>pressKey</span><span>(</span><span>MEDIA_VOL_DOWN</span><span>,</span> <span>0</span><span>);</span>
    <span>}</span>
  <span>}</span>
  
  <span>encoderALast</span> <span>=</span> <span>encoderA</span><span>;</span>
  <span>encoderBLast</span> <span>=</span> <span>encoderB</span><span>;</span>

  <span>// Multimedia buttons</span>
  <span>int</span> <span>pushBtnRead</span> <span>=</span> <span>analogRead</span><span>(</span><span>pushBtnPin</span><span>);</span>
  <span>if</span> <span>(</span><span>pushBtnRead</span> <span>&gt;</span> <span>900</span> <span>&amp;&amp;</span> <span>debounce</span> <span>!=</span> <span>0</span><span>)</span> <span>{</span>
    <span>debounce</span> <span>=</span> <span>0</span><span>;</span>
  <span>}</span> <span>else</span> <span>if</span> <span>(</span><span>pushBtnRead</span> <span>&lt;=</span> <span>264</span><span>)</span> <span>{</span>
    <span>if</span> <span>(</span><span>pushBtnRead</span> <span>&gt;</span> <span>200</span><span>)</span> <span>{</span>
      <span>pressKey</span><span>(</span><span>MEDIA_NEXT</span><span>,</span> <span>delayMultimediaKeyMs</span><span>);</span> <span>// Next</span>
    <span>}</span> <span>else</span> <span>if</span> <span>(</span><span>pushBtnRead</span> <span>&gt;</span> <span>150</span><span>)</span> <span>{</span>
      <span>pressKey</span><span>(</span><span>MEDIA_PREVIOUS</span><span>,</span> <span>delayMultimediaKeyMs</span><span>);</span> <span>// Prev</span>
    <span>}</span> <span>else</span> <span>if</span> <span>(</span><span>pushBtnRead</span> <span>&gt;</span> <span>115</span><span>)</span> <span>{</span>
      <span>pressKey</span><span>(</span><span>MEDIA_STOP</span><span>,</span> <span>delayMultimediaKeyMs</span><span>);</span> <span>// Stop/M</span>
    <span>}</span> <span>else</span> <span>{</span>
      <span>pressKey</span><span>(</span><span>MEDIA_PLAY_PAUSE</span><span>,</span> <span>delayMultimediaKeyMs</span><span>);</span> <span>// Play pause</span>
    <span>}</span>
  <span>}</span>
  
  <span>debounce</span> <span>=</span> <span>millis</span><span>();</span>
<span>}</span>
</code></pre></div></div>
<p>I could test the Arduino implementation right on my development computer with <code>xev</code> so that was really nice.</p>
<h2 id="the-fake-vfd-led-screen">The fake VFD LED screen</h2>
<p>The screen was the part that I had the most doubt about being able to control, because I have never worked with such a device before. Before trying to reverse-engineer it, I tried to look up similar 7-segment LED screens online hoping to find something similar. Those screens often have more than 8 pins (1 for the ground, 7 for each segment, and some more to select the digit. This one is nothing like that: It has only 7 pins. I wanted to give it up and just buy another screen that has a datasheet to save myself from trouble but I couldn't find anything that would fit into the original cutout for the screen. So I had to bite the bullet and hack the LED screen (I had nothing better to do in the craziness of the pandemic).</p>
<h3 id="general-workings">General workings</h3>
<p>There was no giveaway from the PCB what the ground pin for the display might be. I only had a multimeter in hand so what I did was set it to the diode tester mode. Then I probed pairs of pins to see what lights up. As luck would have it, I found out that each pair of pins lit up a different segment on the screen. So there was no common ground at all! I drew the screen and noted what pin pair light up each segment (excuse my nasty draft paper):</p>
<p><img src="https://www.tnhh.net/assets/posts-images/fake-radio-hack/matrix-draft.jpg" alt="Draft Matrix"></p>
<p>First, I was really annoyed because the screen is yet another custom device I had to reverse engineer. Then, it really impressed me that this screen is quite well designed for such a cheap device. There were exactly 42 segments on this LED screen! The number of different segments is exactly the maximum number of permutations between any 2 pins: P(7,2) = 42. After some more digging, I found out that this wiring scheme is called <a href="https://hackaday.com/tag/charlieplexing/">Charlieplexing</a>. So each LED segment has a voltage drop of 1.860V, and my Arduino is 5V. I assumed a 20mA current and used a LED calculator and to figure out that I need to connect a 150K resistor to the LED. Because of the charlieplexing setup, I actually need half of that resistance for each pin (it will be apparent as you read on), so I soldered a 68K resistor to each pin.</p>
<h3 id="control-the-led-screen-programmatically">Control the LED screen programmatically</h3>
<p>The question then became how to control this LED screen programmatically. It was clear to me I can't possibly draw every segment by toggling the pins on and off in one whole sweep. Then I realized that I need to think of the LED screen like an <a href="https://www.youtube.com/watch?v=r38nVmxBfvM">analog TV screen</a>. Thus, each of the pins can be thought of as a horizontal scanline – except they are not on the same “line”! This might be quite obvious to those who have dealt with CRTs in the past (which I have not), but it might be hard to imagine for those who grew up with LCDs.</p>
<p>Let's say I want to draw the screen with segment 17, 18, and 11 lit up. That means I have to do two sweeps. First, pull pin 1 to GND and pull pin 2 to V_LED to light up segment 18. Then, pull pin 4 to GND and pull pin 1 and 7 to V_LED to light up segment 17 and 11 at once. Do it fast enough, and my eyes won't be able to tell we are flashing them!</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.tnhh.net/posts/adventures-hacking-fake-vivitar-vintage-radio.html">https://www.tnhh.net/posts/adventures-hacking-fake-vivitar-vintage-radio.html</a></em></p>]]>
            </description>
            <link>https://www.tnhh.net/posts/adventures-hacking-fake-vivitar-vintage-radio.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23673673</guid>
            <pubDate>Mon, 29 Jun 2020 01:56:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Yelp: Local Economic Impact Report]]>
            </title>
            <description>
<![CDATA[
Score 41 | Comments 21 (<a href="https://news.ycombinator.com/item?id=23673286">thread link</a>) | @yasp
<br/>
June 28, 2020 | https://www.yelpeconomicaverage.com/yelp-coronavirus-economic-impact-report.html | <a href="https://web.archive.org/web/*/https://www.yelpeconomicaverage.com/yelp-coronavirus-economic-impact-report.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
      
    
    
    <section>
        <p>Local economies around the U.S. have continued to change quickly and dramatically – states and cities are slowly reopening, unemployment rates are starting to decline from the recent all-time high, COVID-19 cases are increasing in some states while decreasing in others, and communities are responding to the social unrest and George Floyd protests with city-wide curfews having impacted many businesses that were just able to reopen.</p>
        <p>Yelp last reported on the state of the local economy in <a target="_blank" href="https://www.yelpeconomicaverage.com/yea-q1-2020.html">our quarterly Yelp Economic Average report on April 28</a>, showing how much consumer activity in major swathes of Main Street had dropped off in just a couple of weeks in March. Now as states start to reopen and the nation responds to anti-Black racism and police brutality, a new set of challenges lay ahead for local economies.</p>
    </section>
    
    <section>
      <h2>Some Businesses Slowly Reopen, While Many Permanently Close</h2>
        <p>As of June 15, there were nearly 140,000 total business closures on Yelp since March 1. In April we reported more than 175,000 business closures, indicating that more than 20% of businesses closed in April have reopened. Las Vegas, NV, endured the highest number of closures relative to the number of businesses in the city (1,921 total closures), while Los Angeles, CA, had the largest total number of closures (11,774 total closures).</p>
    </section>
    
    <section>
    	<h3>Some Businesses are Slowly Reopening, Many Remain Closed</h3>
      <h4>Number of businesses marked closed on Yelp that were open March 1</h4>
    
    	<p><img src="https://www.yelpeconomicaverage.com/assets/img/coronavirus/Closures_Desktop.png">
    		<img src="https://www.yelpeconomicaverage.com/assets/img/coronavirus/Closures_Desktop.png">
    		<img src="https://www.yelpeconomicaverage.com/assets/img/coronavirus/Closures_Mobile.png">
    	</p>
    </section>
    
    <section>
        <p>Of all business closures on Yelp since March 1, 41% are permanent closures. Our data shows the largest spikes of permanent closures occurred in March, followed by May and June, indicating that the businesses that were already struggling had to permanently close right away and the businesses that were trying to hold on, but unable to weather the COVID-19 storm, were forced to shutter in recent months.</p>
    </section>
    
    <section>
      <h2>Retail and Restaurant Businesses Continue Innovating Amid High Closure Rates</h2>
        <p>While many business sectors have struggled during COVID-19 there are a few industries that have endured especially high closure rates. Among those with the highest rate of business closures are shopping and retail (27,663 closed businesses), restaurants (23,981 closed businesses), beauty (15,348 closed businesses) and fitness (5,589 closed businesses).</p>
        <p>Retail was by far the hardest hit, experiencing the highest number of total closures, with the average daily rate continuing to increase since March. Of all closures on Yelp since March 1, 20% are for retail businesses and 35% of closed retail businesses are indicated as permanent on Yelp.</p>
        <p>In March, Restaurants had the highest number of business closures, compared to other industries, and have continued to close at high rates. Of the businesses that closed, 17% are restaurants, and 53% of those restaurant closures are indicated as permanent on Yelp. Restaurants run on thin margins and can sometimes take months or even years to break even, resulting in this higher rate of permanent closures.</p>
    </section>
    
    <section>
    	<h3>Restaurants and Retail have been Hit Hardest</h3>
    	<h4>Number of businesses marked temporarily or permanently closed on Yelp that were open on March 1</h4>
    
    	<p><img src="https://www.yelpeconomicaverage.com/assets/img/coronavirus/Category_Closures_Desktop.png">
    		<img src="https://www.yelpeconomicaverage.com/assets/img/coronavirus/Category_Closures_Desktop.png">
    		<img src="https://www.yelpeconomicaverage.com/assets/img/coronavirus/Category_Closures_Mobile.png">
    	</p>
    </section>
    
    <section>
        <p>Though some businesses have shut down permanently, many have found <a target="_blank" href="https://blog.yelp.com/2020/04/businesses-creatively-adapt-coronavirus-response?utm_source=biz_blog&amp;utm_medium=yelp_blog&amp;utm_content=blog_text_link">innovative ways</a> to weather the storm and continue serving consumers. Many restaurants pivoted to offering takeout and delivery, while some experimented with take home meal and drink kits, and even virtual cooking classes. Some are finding new ways to use existing technology, like <a target="_blank" href="https://blog.yelp.com/2020/04/use-waitlist-online-takeout-restaurants?utm_source=biz_blog&amp;utm_medium=yelp_blog&amp;utm_content=blog_text_link">Yelp Waitlist to manage curbside pickup</a>. Servicing food to-go produces high margins for restaurants, and we’ve seen a 10X increase in searches for takeout since March 10.</p>
        <p>With many retail businesses shifting to curbside pickup, we’ve seen consumer interest spike in obtaining their goods in this way with a 20% increase in searches for curbside pickup. In the beauty industry we’ve seen hair stylists offering video hair cutting tutorials, estheticians offering virtual consultations, and small shops shifting their focus to ecommerce. Fitness in particular has seen a significant shift in their business model with gyms and studios offering virtual classes and personal trainers offering one-on-one virtual training sessions. If nothing else, local businesses owners have proven themselves to be resilient and creative during these trying times.</p>
    </section>
    
    <section>
      <h2>The Desire to Support Black-Owned Businesses Continues to Grow</h2>
        <p>As acknowledgement of anti-Black racism and police brutality become more wide-spread across the nation people are continuing to look for ways to support the Black community. Since May 25, we’ve seen a 1785% relative increase in searches for Black-owned businesses, compared to the three weeks prior. Review mentions of “Black-owned” (and related terms) also skyrocketed, up 426%, as people look to support and surface these businesses to the community.</p>
        <p>D.C. had the highest number of Black-owned searches, accounting for nearly 1% of all searches on Yelp, followed by Minnesota, Maryland, Michigan and Georgia. In fact, every state has shown an increase in searches for Black-owned businesses. Looking at metros, Ann Arbor, MI has the highest increase in searches for Black-owned, up 105X (accounting for 3% of all searches), followed by Denver (up 27X), Minneapolis (up 23X) and Baltimore (up 19X).</p>
    </section>
    
    <section>
    	<h3>Interest Increased in Supporting Black-Owned Businesses</h3>
    	<h4>Percent of Yelp searches for Black-owned businesses by state</h4>
    
    	<p><img src="https://www.yelpeconomicaverage.com/assets/img/coronavirus/Searches_Desktop.png">
    		<img src="https://www.yelpeconomicaverage.com/assets/img/coronavirus/Searches_Desktop.png">
    		<img src="https://www.yelpeconomicaverage.com/assets/img/coronavirus/Searches_Mobile.png">
    	</p>
    </section>
    
    <section>
        <p>While searches for Black-owned businesses have increased across all categories, there has been a particular increase in review content for Black-owned restaurants and food businesses (up 9X), beauty businesses (up 3X), nightlife (up 13X) and shopping (up 3X).</p>
    </section>
    
    <section>
      <h2>The Recovering Economy May Look Different Than the Old Economy</h2>
        <p>While some normal activity is starting to bounce back, due to the many changes impacting local economies — state rules, consumer behavior, and social unrest — many of the consumer interest shifts we saw in March and April started to rebound in May, with dramatic shifts in June.</p>
        <p>Outdoor activities that became popular at the height of the pandemic as people were finding ways to stay active while social distancing – such as mountain biking (down 40%), lakes (down 34%), golf (down 33%) and hiking (down 28%) – have dropped in consumer interest since May 1 relative to other active activities. People are starting to feel more comfortable participating in indoor activities, with increased consumer interest for escape games (up 182%), Go Karts (up 147%), axe throwing (up 113%), gyms (up 81%), bowling (up 63%) and yoga (42%). That said, in some instances people are still finding ways to stay outdoors while social distancing with an increased interest in mini golf (up 132%), amusement parks (up 28%) and horseback riding (up 21%).</p>
        <p>The previous spike in community supported agriculture and grocery has started to dip (down 54% and 26%, respectively) as people start heading back into restaurants. In fact, Yelp’s diners seated data shows significantly more people are dining-in at restaurants. During the peak of the pandemic, the number of diners seated across Yelp Reservations and Waitlist dropped essentially to zero. In early June, we've seen diners seated come back substantially – now down 57% compared to pre-pandemic levels. Restaurants that cater to group dining are among those making a comeback – fondue (up 123%), tapas bars (up 98%), hot pot (up 49%) and surprisingly, even buffets (up 17%) – as foods that gained increased interest through takeout and delivery have started to fall – pizza (down 28%), chinese (down 26%), fast food (down 18%). That said, takeout and delivery has continued to sustain interest on Yelp, still up 148% based on consumer interest relative to pre-pandemic levels, indicating this could be a trend that’s here to stay.</p>
        <p>People are also headed back into malls with outlet stores, shopping centers and thrift stores all up (up 84%, 81%, 72%, respectively), as well as hosting or attending formal events with increased interest in bridal (up 70%) and formal wear (up 102%). The previous increase in cannabis dispensaries, head shops and tobacco shops has declined (down 40%, 35% and 32%, respectively). There have also been significant shifts in consumer interest for health and wellness businesses with an increased interest in saunas (up 75%), reflexology (up 69%) and dentists (up 28%), while skilled nursing (down 46%) and hospitals (down 37%) decline.</p>
    </section>
    
    <section>
      
    </section>
    
    <section>
      <h3>How Business Categories are Faring</h3>
      <h4>Change in share of relative consumer interest on Yelp for select business types</h4>
    	
      <!--<p class='q12020-footer'>Read about the methodology <a href='./yea-q1-2020.html#methodology' class=underline>here</a></p>-->
    </section>
    
    <section>
        <p>As economies reopen, warm summer months arrive and consumers start spending more time out of their homes, we expect these shifts to continue changing at a dramatic rate. We'll continue to measure and report on these changes in local economies in our upcoming Q2 Yelp Economic Average.</p>
        <p>—Daniel Gole and Amy Shapiro contributed to this report</p>
    </section>
    
    <section>
        <p><em>If you'd like additional detail on how the economy is shifting, please contact us at <a href="https://www.yelpeconomicaverage.com/cdn-cgi/l/email-protection#0e7e7c6b7d7d4e776b627e206d6163"><span data-cfemail="2c5c5e495f5f6c5549405c024f4341">[email&nbsp;protected]</span></a> or <a href="http://eepurl.com/cMFvGL" target="_blank">join our mailing list</a> to receive an email when new reports are released.</em></p>
        <p><em>Interested in learning how Yelp data can assist you in developing market insights for your business? Yelp Knowledge can help, learn more <a href="https://www.yelp.com/knowledge" target="_blank">here</a>.</em></p>
        <p><em>Want to work with Yelp data yourself? We make a sample of our data available for academic use, and we’ve just added a <a href="https://engineeringblog.yelp.com/2020/06/how-businesses-have-reacted-to-covid-19-using-yelp-features.html" target="_blank">new batch of data</a> that reflects how businesses have reacted to the pandemic. Read more …</em></p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.yelpeconomicaverage.com/yelp-coronavirus-economic-impact-report.html">https://www.yelpeconomicaverage.com/yelp-coronavirus-economic-impact-report.html</a></em></p>]]>
            </description>
            <link>https://www.yelpeconomicaverage.com/yelp-coronavirus-economic-impact-report.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23673286</guid>
            <pubDate>Mon, 29 Jun 2020 00:46:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Financial Statements: A Beginner's Guide]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23673053">thread link</a>) | @Lukas1994
<br/>
June 28, 2020 | https://www.causal.app/blog/whats-a-financial-statement | <a href="https://web.archive.org/web/*/https://www.causal.app/blog/whats-a-financial-statement">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The finance world is quickly entering the mainstream —</p><p>Every month a notable company goes public. Every week a hot startup raises millions of dollars. And every day moms, pops, and teens check on their stocks. </p><p>Whether a company builds rocket engines or mobile apps, they tell their story using the same language —&nbsp;financial statements. Here's how they work.</p><p>Let's say you run a subscription t-shirt business.</p><p>It's going well — you have happy customers and healthy profit. You're thinking of buying your own factory to make more t-shirts, more quickly, and more cheaply.</p><p>There's just one problem — you can't afford a factory.</p><p>So, you ask the bank for a loan. Your company is profitable and the factory will pay for itself in 3 years, so you know you'll be able to pay it back. But while you know this, the bank doesn't — you'll need to convince them. The bank, however, doesn't know anything about the subscription clothing business.</p><p>To get on the same page, you need a shared language for talking about your business.</p><p><h4 id="heading-1">Double-entry Bookkeeping: The birth of accounting</h4></p><p>Double-entry bookkeeping was the first formalism in finance. The Middle East had it in the <a href="https://www.jstor.org/stable/40697986" target="_blank">first century AD</a>, Korea independently got it in the <a href="https://www.worldcat.org/issn/1598-2661" target="_blank">11th century</a>, and by the <a href="https://web.archive.org/web/20170627232023/http://130.74.92.202:82/record=b1000778" target="_blank">1500s</a>, it had been well-documented across Europe.</p><p>It's a simple concept designed to reduce errors when documenting transactions: every entry to an "account" requires an equal and opposite entry to another "account".</p><p>If you bought some cotton to turn into t-shirts, you might record the transaction like this:</p><p>‍</p><figure id="w-node-371c827e421c-51d2da99"><p><img src="https://uploads-ssl.webflow.com/5e8a043bfbc2c035b4d8e5b5/5eefde0379b53032713cde77_bookkeeping.png" alt=""></p></figure><p>‍</p><p>When you spend $100 on cotton, your "Cash" account gets debited (loses) $100, and your "Materials" account gets credited (gains) $100. The underlying principle is that <em>you can't create something out of nothing</em>.</p><p>This might seem contrived, but with more and more transactions, it can help you spot errors. Since every entry has an equal and opposite entry, the sum of all the debits should always equal the sum of all the credits. If not, you know you made a mistake, and you can look back through your transactions to find it.</p><p>A list of transactions is pretty interesting — it tells a very detailed story about what your company's been up to. Certainly enough to answer the bank's questions when you ask for loan.</p><p>But just as the bank doesn't have time to learn about subscription t-shirts businesses, they don't have time to go through thousands of transactions. To understand what's going on, they need a shorter summary.</p><p><h4 id="heading-2">Financial Statement #1: The Balance Sheet</h4></p><p>If you went through all your transactions and worked out the net value of each account, you'd be able to see things like</p><ul role="list"><li>How much cash you have in the bank</li><li>The total value of the cotton in your inventory</li><li>How much money you owe to your cotton suppliers</li></ul><p>This will give you a snapshot of the current state of your company, split up into "everything you own" (<strong>Assets</strong>) and "everything you owe" (<strong>Liabilities</strong>) — a <strong>Balance Sheet</strong>. These generally won't be equal — ideally your assets will be worth more than your liabilities.</p><p>The difference between the assets and the liabilities is what you, the owner of the company, can rightfully stake a claim to. Crudely, if you sold all your assets today and used that money to pay off all your debts, you'd be left with a pile of cash all to yourself.</p><p>This idea is usually expressed by the "accounting equation":</p><p><strong>Assets - Liabilities = Shareholders Equity</strong></p><p>This is where the "balance" comes in: both sides of the equation are equal. Note that this equation is actually a definition — it asserts that the value of the <strong>Shareholders Equity</strong> is the difference between <strong>Assets</strong> and <strong>Liabilities</strong>. This is the same equation that underpins double-entry bookkeeping.</p><p>Here's what your balance sheet might look like:</p><p>‍</p><figure id="w-node-89b5b437bd58-51d2da99"><p><img src="https://uploads-ssl.webflow.com/5e8a043bfbc2c035b4d8e5b5/5eefde1a11602b68a068a079_balance-sheet.png" alt=""></p></figure><p>‍</p><p>The bank will be interested in seeing this before giving you a loan. It's a quick 'n' dirty way for them to understand the big picture:</p><ul role="list"><li>The orders of magnitude involved — does this company operate in the thousands, millions, or billions?</li><li>An estimate for how much the company is "worth", based on the shareholders equity</li><li>An indication of company health — is the company drowning in debt?</li></ul><p>Financiers often calculate metrics based on the balance sheet, to further summarise the information and to compare numbers across companies.</p><p>The <strong>Debt/Equity Ratio</strong> is a big one, telling you how much a company relies on borrowing money. If it's too high then the company might be too dependent on loans, but if it's too low, this might indicate an inefficiency, since borrowing money to spend on growth can be quicker than earning it the hard way.</p><p>So — the balance sheet summarises a lot about your company, in a way that the bank can understand.</p><p>Unfortunately, it doesn't answer a crucial question — "Do you make money?"</p><p><h4 id="heading-3">Financial Statement #2: The Income Statement (P&amp;L)</h4></p><p>The balance sheet is a snapshot of a single point in time. To understand whether a company makes money, you need see how things change over a period of time (e.g. every month).</p><p>The first thing you need to know is how much money you receive — your <strong>Revenue</strong>. You don't keep all of it — there are costs and expenses along the way — so you need to subtract these. The final number you end up with is your <strong>Profit</strong> — the money you've made at the end of the day.</p><p>Here's how you might do the calculation:</p><p>‍</p><figure id="w-node-a4e76259fbb4-51d2da99"><p><img src="https://uploads-ssl.webflow.com/5e8a043bfbc2c035b4d8e5b5/5eefe0c6c8f0be2b6743533b_p%26l.png" alt=""></p></figure><p>‍</p><p>You start at Revenue (the top line), subtract your costs, and end up at Profit (the "bottom line" — get it?). This is a simple <strong>Profit &amp; Loss (P&amp;L)</strong>, or <strong>Income Statement</strong>. Most companies make one every month, to keep an eye on things. </p><p>‍</p><figure id="w-node-fec0fade16bf-51d2da99"><p><img src="https://uploads-ssl.webflow.com/5e8a043bfbc2c035b4d8e5b5/5eefe17879b5309ce33ce18b_35274025-14536291245349646_origin.png" alt=""></p></figure><p>‍</p><p>With a P&amp;L, you and the bank can understand what's going in and out of your business. If your P&amp;L consistently shows a profit, then the bank will be happy, and so will you.</p><p>In theory, this is very simple. But in practice, each P&amp;L item has hidden nuances to address.</p><p>Let's take just the top line — what does <strong>Revenue</strong> actually mean?</p><p><strong>What is revenue?</strong></p><p>When you started selling shirts, it was a simpler time — you bought them in bulk from China and sold them at the local market.</p><p>Revenue, too, was simple — it was the cold hard cash in your hand.</p><p>But things changed. You started taking bulk orders from shops, who pay you 1 month after you deliver the shirts. And when you went online, your customers started paying you for 12 month subscriptions, all in one go.</p><p>It turns out that if you keep thinking of revenue as "cash in your hand", then things get a little weird —</p><ul role="list"><li>When you get a bulk order, your expenses shoot up. But since you don't get paid until next month, your profit goes way down this month.</li><li>When someone buys a 12-month subscription, your revenue spikes up. But for the next 11 months you have to keep delivering on the order (non-zero cost) without further payments (zero revenue) — your bottom line takes a hit.</li></ul><p>Bulk orders and upfront payments are great for your business, but if revenue means "cash in hand", then your P&amp;L might tell the opposite story.</p><p>A better way to think about revenue is as "the value of products delivered or service provided".</p><p>In each month of a subscription, you do 1 month of work. So even with 12 months' payment upfront, you only recognise 1/12th of that payment as revenue each month. The remaining 11/12th becomes <strong>Deferred Revenue.</strong> This is actually a liability on your balance sheet — your customers have essentially given you a loan which you must pay back each month, in the form of t-shirts.</p><p>The same principle applies for bulk orders — you recognise the revenue when you deliver the product, <em>not</em> when you get paid.</p><p>This is called <strong>Accrual Accounting</strong>, and it more accurately answers the question "Do you make money?".</p><p>So — you've got a balance sheet, showing your current financial state, and you've got a P&amp;L, showing how things change over time. The bank, however, remains unsatisfied.</p><p>Sadly, consistent profits, measured with accrual accounting, can still leave you penniless on payday.</p><p><h4 id="heading-4">Financial Statement #3: The Cashflow Statement</h4></p><p>In 1863, the Dowlais Iron Company had a dilemma.</p><p>On paper, things were great — they'd recovered from a downturn and were posting healthy profits. To smelt more iron, they set out to buy a new blast furnace. But despite their promising P&amp;L, it turned out that they had no cash to buy it.</p><p>What gives?</p><p>Their problem was in spending cash too quickly — as soon as they got some, they'd use it on inventory (iron ore, etc). The profits were rolling in, but the cash wasn't sticking around.</p><p>The company needed a way to understand how cash was coming in and out — the cashflow. Their solution was the origin of the modern <strong>Cashflow Statement</strong>.</p><p>Like the P&amp;L, the cashflow statement shows how things change over each month, but crucially, it only focuses on cash — how much you started with, what you spent it on, where you got more of it, and how much you ended up with. In short, the cashflow statement explains the difference between one balance sheet and the next.</p><figure id="w-node-508193268673-51d2da99"><p><img src="https://uploads-ssl.webflow.com/5e8a043bfbc2c035b4d8e5b5/5eefe644e9cf27ec56e99c29_Untitled-3.png" alt=""></p></figure><p>The bank should now have enough information to decide whether to give you a loan:</p><ul role="list"><li>Balance Sheet — shows everything that you own, and everything that you owe</li><li>P&amp;L/Income Statement — shows how your business operates</li><li>Cashflow Statement — shows how you spend and earn cash</li></ul><p>These financial statements are a shared language, letting businesses communicate across industries and borders. They also "flatten" a business' evolving operations — new business models, delivery methods, and products — to give a coherent view of a company through time.</p><p>Investors use financials to judge performance, lenders use them to assess credit-worthiness, and governments use them to make sure that taxes are correctly paid.</p><p>But the whole system only works if every company follows the same rules when compiling their financials. These rules require years of study to fully understand (this is why accountants exist) and include:</p><ul role="list"><li>How to recognise revenue —&nbsp;accrual accounting</li><li>How to "amortise" costs — spreading upfront expenses over time</li><li>How to "capitalise"&nbsp;costs —&nbsp;turning big purchases into assets on the balance sheet</li></ul><p>Who made these rules?</p><p><h4 id="heading-5">Accounting Standards: Mind the GAAP</h4></p><p>The Industrial Revolution …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.causal.app/blog/whats-a-financial-statement">https://www.causal.app/blog/whats-a-financial-statement</a></em></p>]]>
            </description>
            <link>https://www.causal.app/blog/whats-a-financial-statement</link>
            <guid isPermaLink="false">hacker-news-small-sites-23673053</guid>
            <pubDate>Mon, 29 Jun 2020 00:00:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Finishing a side project]]>
            </title>
            <description>
<![CDATA[
Score 298 | Comments 118 (<a href="https://news.ycombinator.com/item?id=23672686">thread link</a>) | @hugozap
<br/>
June 28, 2020 | https://hugozap.com/posts/how-to-finish-your-side-project/ | <a href="https://web.archive.org/web/*/https://hugozap.com/posts/how-to-finish-your-side-project/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

      

<p><img src="https://hugozap.com/img/hands.jpg" alt="Illustration by Angélica Delvalle IG: ylikdelvalle"></p>
<p>It's no secret that finishing a side project is hard.</p>
<p>I've struggled with some side projects and had success with others. In this post, I'll focus on the actions and adjustments that have worked for me.</p>
<p>It's possible to work on and finish side projects even with a busy schedule, the key is to optimize for interruptability. You will be interrupted so instead of counting on having hours of deep work available, it's better to be realistic and make some adjustments to use available time in a better way and reducing the cost of interruptions by having tricks to switch context fast.</p>
<h2 id="a-failed-side-project-story">A failed side project story <a href="#a-failed-side-project-story">#</a></h2>
<p>Maybe you are familiar with a similar situation</p>
<p>At the beginning:</p>
<ul>
<li>High motivation.</li>
<li>Priority over other tasks.</li>
<li>Working long hours because it's fun.</li>
<li>Desire to work with a new technology</li>
<li>No problem working on weekends.</li>
</ul>
<p>After some time:</p>
<ul>
<li>Motivation decreases.</li>
<li>Feels overwheelming.</li>
<li>Harder to justify working on the project when there are other responsibilities.</li>
<li>Other stuff seems more interesting now.</li>
<li>Forgot how to set things up to continue working on the project.</li>
<li>Not sure what I was working on.</li>
<li>Forgetting about the project and archiving it.</li>
</ul>
<h2 id="the-challenges-with-side-projects">The challenges with side projects <a href="#the-challenges-with-side-projects">#</a></h2>
<ul>
<li>Context switching and high cognitive load is exhausting.</li>
<li><strong>Losing interest/ motivation</strong>.</li>
<li>Perfectionism - never ending projects.</li>
<li>Impostor syndrome.</li>
<li>Lack of focus.</li>
<li>Lack of time.</li>
<li>Unexpected life events.</li>
</ul>
<h2 id="re-framing-the-goal">Re framing the goal <a href="#re-framing-the-goal">#</a></h2>
<p>I believe you can set yourself for failure from the start if the goal is not clear.</p>
<p>I've been excited about ideas but later found that I was not really invested in the idea and just wanted to explore a cool feature/tool. It's good to go deeper to your true motivation.</p>
<p>Feeling overwhelmed can also contribute to abandoning the project, I'll talk about <strong>small steps</strong> and why it's key.</p>
<p>If your track record includes lots of ambitious projects and none of them finished, then starting with something smaller seems like the logical approach.</p>
<p>Pick a small battle, maybe just the key feature first, maybe support for just one platform. Cut off features for the first version, remember that there's a lot of forces against you completing your project so reducing load is important.</p>
<h2 id="the-approach">The approach <a href="#the-approach">#</a></h2>
<p>Now that you have a clear idea of what you want to finish, there's some actions and adjustments to your process that will increase the chance of winning the battle (shipping).</p>
<ul>
<li>Preparing your environment (painless context switch)</li>
<li>Work in <strong>Small steps</strong></li>
<li>Mental warm-up before each session.</li>
<li>Anticipate and expect interruptions.</li>
<li>Changing your physical location.</li>
<li>Writting down the ideas on your mind at the end of the session.</li>
</ul>
<h2 id="small-steps-are-key">Small steps are key <a href="#small-steps-are-key">#</a></h2>
<p>I like the idea of not having too many open boxes at the same time, where each box is a task/feature or something that you  started but haven't finished yet.</p>
<p>It's demoralizing to wait weeks or months for a win. Small steps give you small wins, it keeps the journey fun. There's less change of feeling stuck.</p>
<p><a href="https://www.geepawhill.org/2020/06/26/more-on-small-steps/">Geepaw Hill</a> shares excellent resources on the topic of small steps in software.</p>
<h2 id="warming-up-before-each-session-to-reduce-cognitive-exhaustion">Warming up before each session to reduce cognitive exhaustion <a href="#warming-up-before-each-session-to-reduce-cognitive-exhaustion">#</a></h2>
<p>Before starting actual work, write about what would be good to achieve in the session. I find this ritual valuable as it helps me figure out the next small step. Writing the project goal (high level) every session is also a good way to switch context and reminding yourself what's it all about.</p>
<p>I'll talk about having a "context" log, where you write the current progress, and what to do next. If you have this file, reading the previous session log let's you resume your work faster.</p>
<h2 id="immediate-context-switching">Immediate context switching <a href="#immediate-context-switching">#</a></h2>
<p>With the limited amount of mental energy, is crucial to reduce the number of setup tasks required to do a working session on your project. The goal here is reducing the number of small decisions you have to make to have a working environment.</p>
<p>This is one of the most important things for me, and the way I approach it is:</p>
<ul>
<li>Creating a separated system User on my laptop.</li>
<li>Having an email address only for my project.</li>
<li>Having a "context" file where I log what's currently happening with my project, usually at the end of a work session.</li>
</ul>
<p>These have been valuable tools for me, let me explain why:</p>
<h3 id="a-separate-system-user-for-your-side-project">A separate system user for your side project <a href="#a-separate-system-user-for-your-side-project">#</a></h3>
<p>By creating a separate user, you automatically have all the operative system tools (calendar/notes/reminders , etc.) available ONLY for your project.</p>
<p>All the files on your desktop will have a relation to your project. This may not seem impressive but think about all the small distractions you find if you use the same user for your personal/work tasks:</p>
<ul>
<li>Time to find a file (filtering unrelated stuff will bring memories of other things)</li>
<li>Reminders/calendar notifications not related to your project</li>
<li>Dealing with other project setups can be stressful.</li>
</ul>
<p>I think it was Seth Godin who recommended having a separate laptop for a side project like writing a book. This is an alternative too.</p>
<p>You can add more extreme measures like redirecting distracting sites like news or reddit. If you need to login to one of those sites, it's better to switch user accounts. Try to keep your project user clean.</p>
<h3 id="having-an-separate-email-for-your-project">Having an separate email for your project <a href="#having-an-separate-email-for-your-project">#</a></h3>
<p><a href="https://hugozap.com/posts/ultimate-info-capturing-tool/">I'm a fan of email</a> as a note taking tool, it's available everywhere, the UI is simple. Having a separate email account lets you capture related notes/ideas/links from any device. This has been useful for me when I'm doing something else and have an idea, or find a resource that can be used to do something I want to incorporate into the project.</p>
<p>Later, when I log in to my project environment I'll get the emails with relevant information, no chance of getting distracted with other stuff.</p>
<h3 id="the-context-file%2C-(brain-dump).">The context file, (brain dump). <a href="#the-context-file%2C-(brain-dump).">#</a></h3>
<p>A context file is just a text file where you add a short summary of the current project status and what's on your mind at the time.</p>
<p>This has been valuable to me, because the act of writing it down helps me have a clear idea of things I could do next and next time I have time to work on my project I'll have a starting point and it reduces the cognitive load which maximizes the session efficiency.</p>
<h2 id="location">Location <a href="#location">#</a></h2>
<p>Going to a library or café (when possible) or event to another room and have a dedicated space for your current side project will make a difference.</p>
<p>Not sure about why, but using the same desk for different work and side projects is not ideal for me. If you can I recommend having a different place that helps you switch context quickly.</p>
<h2 id="abandoned-projects-may-not-be-a-failure-after-all.">Abandoned projects may not be a failure after all. <a href="#abandoned-projects-may-not-be-a-failure-after-all.">#</a></h2>
<p>Some abandoned projects end up being an inspiration to create something else years later. Maybe you learned something new, explored an idea, or found a problem not possible to solve with the knowledge and resources you had at the time.</p>
<p>It's good to have an open mind and be ok with finding dead-ends, they are powerful teachers.</p>
<p>However, shipping projects <strong>is awesome</strong> and by reducing scope and anticipating interruptions you will be able to complete your project and release it to the world.</p>
<h2 id="resources">Resources <a href="#resources">#</a></h2>
<p>For more information about the benefits of a "small step" approach to software development check the excellent resources from <a href="https://www.geepawhill.org/2020/06/26/more-on-small-steps/">Geepaw Hill</a></p>
<h2 id="credits">Credits <a href="#credits">#</a></h2>
<p>Illustration by <a href="https://www.instagram.com/ylikdelvalle/">Angelica Delvalle</a> (In case you need art for your company products contact her, she does awesome stuff!)</p>


<p><a href="https://hugozap.com/">← Home</a></p>

    </div></div>]]>
            </description>
            <link>https://hugozap.com/posts/how-to-finish-your-side-project/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23672686</guid>
            <pubDate>Sun, 28 Jun 2020 22:48:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lessons learned from my first three years of freelancing]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23672532">thread link</a>) | @JayClouse
<br/>
June 28, 2020 | https://jayclouse.com/reflecting-on-three-years-of-running-a-freelance-business/ | <a href="https://web.archive.org/web/*/https://jayclouse.com/reflecting-on-three-years-of-running-a-freelance-business/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wtr-content" data-bg="#FFFFFF" data-fg="#00aeff" data-width="10" data-mute="" data-fgopacity="1.00" data-mutedopacity="0.80" data-placement="bottom" data-placement-offset="0" data-content-offset="0" data-placement-touch="bottom" data-placement-offset-touch="0" data-transparent="" data-touch="1" data-non-touch="1" data-comments="0" data-commentsbg="#ffcece" data-location="page" data-mutedfg="#00aeff" data-rtl=""><p>It’s safe to say that we’ll all remember 2020.</p><p>There are a lot of reasons that we’ll look back on 2020 and cringe. As of this writing, we’re still in the middle of a global pandemic that the United States seems to have just given up on.</p><p>We’re in seeing a renewed fight for social justice, with more of us fighting against centuries of racial inequality than ever before.</p><p>The first two quarters of 2020 have taken an emotional toll on me just like they probably have on you. Everyone is hurting – individuals and business owners included.</p><p>But for the last two years, I’ve written an annual reflection on my own business.</p><p>To be honest, the anniversary snuck up on me this year!</p><p>But I wanted to go a little deeper on this year’s reflection. I wanted to bring you some <strong>real numbers</strong>, some <strong>behind-the-scenes</strong>, and the <strong>lessons learned</strong>.</p><p>And it’s important to note – <strong>I do not equate earnings with success</strong>. I certainly don’t equate them with happiness. If you look at earnings alone, my 2019 would look like a&nbsp;<em>huge&nbsp;</em>step backwards. But in reality, I believe 2019 to be far more impactful than 2018.</p><p>I’m optimizing for flexibility, fulfillment, and long-term vision. So as you’ll see in my 2019 breakdown, I accepted a short-term earnings compromise to get there.</p><p>If you want the tl;dr version, here’s a visual overview of my P&amp;L every year from 2017. It includes the my actual figures for January through June of 2020, as well as a projection for the full year based upon those numbers.</p><p><picture><source data-lazy-srcset="https://jayclouse.com/wp-content/uploads/2020/06/PL2020-2.webp 822w,https://jayclouse.com/wp-content/uploads/2020/06/PL2020-2-300x169.webp 300w,https://jayclouse.com/wp-content/uploads/2020/06/PL2020-2-768x432.webp 768w,https://jayclouse.com/wp-content/uploads/2020/06/PL2020-2-100x56.webp 100w" sizes="(max-width: 822px) 100vw, 822px" type="image/webp"><source data-lazy-srcset="https://jayclouse.com/wp-content/uploads/2020/06/PL2020-2.png 822w, https://jayclouse.com/wp-content/uploads/2020/06/PL2020-2-300x169.png 300w, https://jayclouse.com/wp-content/uploads/2020/06/PL2020-2-768x432.png 768w, https://jayclouse.com/wp-content/uploads/2020/06/PL2020-2-100x56.png 100w" sizes="(max-width: 822px) 100vw, 822px"><img src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20822%20462'%3E%3C/svg%3E" height="462" width="822" data-lazy-srcset="https://jayclouse.com/wp-content/uploads/2020/06/PL2020-2.png 822w, https://jayclouse.com/wp-content/uploads/2020/06/PL2020-2-300x169.png 300w, https://jayclouse.com/wp-content/uploads/2020/06/PL2020-2-768x432.png 768w, https://jayclouse.com/wp-content/uploads/2020/06/PL2020-2-100x56.png 100w" data-lazy-sizes="(max-width: 822px) 100vw, 822px" data-lazy-src="https://jayclouse.com/wp-content/uploads/2020/06/PL2020-2.png"></picture></p><p>If you’re ready to dig into what happened each of those years and why those trends look the way they do, let’s get started.</p><h2><strong>Year One: 2017</strong></h2><p>I spent the first four months of 2017 gainfully employed! Those earnings are <em>not</em> reflected in the numbers above or below, but it does mean that I had four fewer months to work with.</p><p>I quit my job in late April 2017. It came about a month sooner than I anticipated, but the timing seemed right for both me and the company I was leaving.</p><p>You can read more detail about that decision <a href="https://jayclouse.com/chapter-three/" target="_blank" rel="noopener noreferrer">here</a>, but it was a pretty half-baked move, truth be told.</p><p>I didn’t really have much of a plan, and I don’t recommend jumping into the deep end like I did!</p><p>The biggest victory was getting my first 15-member paid cohort of the Unreal Collective Accelerator off the ground.</p><p>Here’s my cringe-worthy first promotional video for Unreal Collective:</p><p>Pulling that first cohort together wasn’t<em>&nbsp;</em>easy. I ran a beta group of five members for a couple of months prior, and I was able to turn their stories into testimonials.</p><p>But I was still coming in with very little credibility.</p><p>The model behind the Unreal Collective Accelerator is pretty straightforward, and it’s similar to a typical mastermind program.</p><p>You take a small number of great people with ambitious goals, you force them into meeting once per week, and magic happens. <strong>Progress</strong> is made, <strong>goals</strong> are met, <strong>transformation</strong> is experienced.</p><p>Getting the right number of people, who mesh together well, ready to start the program at the same time is where you find the challenge.</p><p>But I’ve always been good at logistics and timelines, so I’m able to make it work – even if it was through brute force of a <em>lot </em>of conversations.</p><p>I wasn’t even calling it an accelerator at the time! I wasn’t sure what it was going to be – I <a href="https://jayclouse.com/on-unreal-collective/" target="_blank" rel="noopener noreferrer">thought</a> it might be a live events company.</p><p>After that first program ended, it was October. And I realized I wasn’t going to be able to pull another group together before the end of the year due to Thanksgiving, Christmas, and the new year.</p><p>So my financial engine was put on pause until 2018.</p><p>And I was broke.</p><p>To scrape by, I picked up a couple of freelance gigs building simple WordPress websites, writing email sequences, and helping a friend launch his podcast.</p><p>Then in late December, I got a surprise email: an opportunity to become a LinkedIn Learning instructor. I walked through the application process and was accepted shortly thereafter.</p><h3><strong>Lessons Learned</strong></h3><ul><li>👍&nbsp; Creating a budget was absolutely critical</li><li>👍&nbsp; Investing in mentorship and my own education was well worth it</li><li>👍&nbsp; When I’m in a bind, I look for work from the people close to me</li><li>👎&nbsp; I need to learn how to predict my cash flow</li><li>👎&nbsp; Things take longer to get started than I expect</li><li>👎&nbsp; When I underprice myself, it’s problematic through the project and for months afterward</li></ul><h3><strong>By the Numbers</strong></h3><ul><li><strong>Gross income</strong>: $29,468</li><li><strong>Expenses</strong>: $18,289</li><li><strong>Net income</strong>: $11,179</li></ul><h2><strong>Year Two: 2018</strong></h2><p>The start of the new year couldn’t come soon enough. When the year began, I was still working on a freelance marketing contract that saved my butt at the end of 2017.</p><p>But I wanted to start a new cohort of the Unreal Collective Accelerator.</p><p>And actually, 2018 was the first time I started calling it an Accelerator. I put a lot of thought into Unreal Collective as a business, because I wanted it to be a brand that meant more than just the 12-week program.</p><p>In February, I pulled my thoughts together and decided Unreal would split into three core product offerings:</p><ol><li>The 12-week program (Unreal Collective Accelerator)</li><li>A community membership (Unreal Collective)</li><li>Digital products and courses (called Guides at the time)</li></ol><p>I broke it all down in this 24-minute monologue called “Unreal Collective 2.0” that I shared with the community (then about 35 people):</p><p>To start the year, I brought together another cohort of 15 people. At the same time, I began writing my first LinkedIn Learning course and even accepted a part-time Entrepreneur In Residence position with Columbus’s Smart City team.</p><p>So things got off to a strong start.</p><p>But I burned myself out. Outside of my business, I was:</p><ul><li>Serving as Entrepreneur in Residence for Smart Columbus</li><li>Helping organize a track of events for Columbus Startup Week</li><li>Organizing a hackathon for Smart Columbus</li><li>Serving as Vice Chair of a nonprofit organization</li><li>Organizing a 6-month outdoor music series</li></ul><p>…and most of that was a volunteer effort.</p><p>The Smart Columbus role was fantastic – I was able to make an impact for the team and we put on an incredible event.</p><p>And somehow I also wrote 4 courses for LinkedIn Learning, ran two cohorts of the Unreal Collective Accelerator, and launched our podcast, <a href="https://upside.fm/" target="_blank" rel="noopener noreferrer">upside</a>.</p><p><a href="https://jayclouse.com/two-years-into-the-journey/" target="_blank" rel="noopener noreferrer">You can read my full 2018 reflection here</a></p><p>It was a strong year of earnings, but I really wanted to focus and devote more time to my core business. So I stepped away from the Smart Columbus role, the Vice Chair role, and the music series.</p><h3><strong>Lessons Learned</strong></h3><ul><li>👍&nbsp; Creating LinkedIn courses were great for cash flow and creating my own content</li><li>👍&nbsp; Coaching others was a viable service that people benefitted from</li><li>👍&nbsp; Freelance work can pay pretty well</li><li>👍&nbsp; I can pick up freelance work pretty easily</li><li>👎&nbsp; Freelancing can also be a diversion from my core business goals</li><li>👎&nbsp; Volunteering a lot of my time was hurting my business</li><li>👎&nbsp; Earning more doesn’t matter if my costs increase</li><li>👎&nbsp; Earning close to my previous salary doesn’t matter if I’m saving far less</li></ul><h3><strong>By the Numbers</strong></h3><ul><li><strong>Gross income</strong>: $72,713 (<strong><span>147% increase</span></strong>)</li><li><strong>Expenses</strong>: $45,834 (<strong><span>151% increase</span></strong>)</li><li><strong>Net income</strong>: $26,879 (<strong><span>140% increase</span></strong>)</li></ul><h2><strong>Year Three: 2019</strong></h2><p>In 2019, I resolved to do <em>less </em>so that I could do <em>more</em>. I <a href="https://jayclouse.com/doing-fewer-doing-more/" target="_blank" rel="noopener noreferrer">wrote</a> in January 2019:</p><blockquote><p>This year is all about doing fewer so that I can do more. Fewer projects, fewer opportunities that are outside of my core intention, in order to do more with the things I am focusing on.</p><p><strong>It’s not unlikely that I actually earn less this year</strong> than I did last year. A large part of my income in 2018 was from contracting and ad hoc projects, and those take time away from building my core business.</p></blockquote><p>Turns out, I was right. My income dropped 25% percent in 2019.</p><p>I decided to take on less freelance work – including courses from LinkedIn.</p><p>Instead, I focused on more Unreal Collective Accelerator cohorts and developing my own proprietary content.</p><p>That content took a few forms:</p><ul><li>Freelancing School courses</li><li>More episodes of upside</li><li>Planning for the launch of a new podcast (Creative Elements)</li><li>My weekly newsletter, Work In Progress</li></ul><p>I spent most of the first six months of 2019 producing the <a href="https://freelancing.school/" target="_blank" rel="noopener noreferrer">three courses within Freelancing School.</a> It was a <em>massive </em>effort and the courses get really great reviews from students.</p><p><iframe loading="lazy" src="about:blank" frameborder="0" allowfullscreen="allowfullscreen" data-rocket-lazyload="fitvidscompatible" data-lazy-src="https://player.vimeo.com/video/419356632?color=109aa1&amp;byline=0&amp;portrait=0"></iframe></p><p>And all the while, I facilitated three sessions of the Unreal Collective Accelerator – welcoming 50 new members across three cohorts.</p><p>…and that was exhausting. The program itself is 12 weeks long with about 4 weeks of marketing and onboarding required up front.</p><p>Some quick math will show you that 16 weeks across 3 sessions equals 48 weeks out of the year…and I wanted to finish before Thanksgiving!</p><p>I ended up staggering the second and third cohorts a bit, with two sessions overlapping for two weeks. And it was intense.</p><p>But, at the same time, my courses were published and beginning to sell.</p><p>Our podcast, upside, even earned more than $20,000 in gross income through sponsorships and partnerships (not reflected in the numbers below).</p><p>Over the summer, that podcast business produced a full-length documentary about the startup ecosystem in Columbus, Ohio, called <em>Test City, USA.</em></p><p>The film is 94 minutes long, features prominent voices in Columbus’s tech scene, and was shot <em>beautifully</em>.</p><p><picture><source data-lazy-srcset="https://jayclouse.com/wp-content/uploads/2019/09/3R5A0389_compressed.webp 1000w,https://jayclouse.com/wp-content/uploads/2019/09/3R5A0389_compressed-300x169.webp 300w,https://jayclouse.com/wp-content/uploads/2019/09/3R5A0389_compressed-768x432.webp 768w,https://jayclouse.com/wp-content/uploads/2019/09/3R5A0389_compressed-100x56.webp 100w" sizes="(max-width: 1000px) 100vw, 1000px" type="image/webp"><source data-lazy-srcset="https://jayclouse.com/wp-content/uploads/2019/09/3R5A0389_compressed.jpg 1000w, https://jayclouse.com/wp-content/uploads/2019/09/3R5A0389_compressed-300x169.jpg 300w, https://jayclouse.com/wp-content/uploads/2019/09/3R5A0389_compressed-768x432.jpg 768w, https://jayclouse.com/wp-content/uploads/2019/09/3R5A0389_compressed-100x56.jpg 100w" sizes="(max-width: 1000px) 100vw, 1000px"><img src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201000%20563'%3E%3C/svg%3E" alt="Mallory and I at the Test City, USA Premiere" height="563" width="1000" data-lazy-srcset="https://jayclouse.com/wp-content/uploads/2019/09/3R5A0389_compressed.jpg 1000w, https://jayclouse.com/wp-content/uploads/2019/09/3R5A0389_compressed-300x169.jpg 300w, https://jayclouse.com/wp-content/uploads/2019/09/3R5A0389_compressed-768x432.jpg 768w, https://jayclouse.com/wp-content/uploads/2019/09/3R5A0389_compressed-100x56.jpg 100w" data-lazy-sizes="(max-width: 1000px) 100vw, 1000px" data-lazy-src="https://jayclouse.com/wp-content/uploads/2019/09/3R5A0389_compressed.jpg"></picture></p><p>We spent the entire summer filming and editing, and due to some lucky timing, we premiered the film at the Film Festival of Columbus in September where it won Best Ohio Feature. It was also accepted into the Columbus International Film Festival in April 2020.</p><p>I don’t know if I’ll ever produce another film in my life, but I’m so glad that <em>Test City, USA </em>exists. <a href="https://upside.fm/test-city-usa/" target="_blank" rel="noopener noreferrer">You can watch it here</a>.</p><p>To finish out the year, I created another course for LinkedIn Learning and signed an agreement with the Podglomerate, the network that I’ve partnered with for Creative Elements.</p><p>So while my overall income took a hit, I <em>really </em>put a lot of pieces in place to begin to build a larger, more scalable business through content and digital products.</p><p>And by cutting expenses, my net income was still up 24% from the year before! After a 2018 where I saved very little, I was able to dedicate money consistently to savings and retirement in 2019 as well.</p><h3><strong>Lessons Learned</strong></h3><ul><li>👍&nbsp; There is power in focus</li><li>👍&nbsp; It’s worth living cheaply while I still can to …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jayclouse.com/reflecting-on-three-years-of-running-a-freelance-business/">https://jayclouse.com/reflecting-on-three-years-of-running-a-freelance-business/</a></em></p>]]>
            </description>
            <link>https://jayclouse.com/reflecting-on-three-years-of-running-a-freelance-business/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23672532</guid>
            <pubDate>Sun, 28 Jun 2020 22:18:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Life is 90% of my use cases for org-mode]]>
            </title>
            <description>
<![CDATA[
Score 243 | Comments 155 (<a href="https://news.ycombinator.com/item?id=23672473">thread link</a>) | @billwear
<br/>
June 28, 2020 | http://stormrider.io/ninety-pct.html | <a href="https://web.archive.org/web/*/http://stormrider.io/ninety-pct.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <h2>
      life is 90% of my use cases for org-mode
      <br>
      <small>
	<em>so what's the other 10%?</em><br>
      </small>
    </h2>
    <hr>
    <a href="http://stormrider.io/index.html">blog index</a><br>
    <hr>
    <p>
      To really explain why I use org-mode for <bold>everything</bold>, I probably first have to explain my rules, which also requires a backstory.  I'll keep it short, no problem.
    </p>
    <p>
      I jacked into Unix the first time at Calhoun Community College, in Decatur, Alabama, during the summer of 1974.  I was 15, and my dad was a part-time programming instructor.  Having been an avid reader since the age of 6 (I read the entire elementary school library before the middle of second grade), text and text-processing was much on my mind.
    </p>
    <p>So when I encountered a system where plain text is the raw material flowing through the pipes, I was hooked.
    </p>
    <blockquote>
      <br>
      ...what I really learned was that the rules of Unix could be adapted to life.
      </blockquote>
    
    <p>
      This led me to undertake an informal study of Unix, all the way back to the Tech Model Railroad Club and all the hackers that came from there.  Yeah, I read the story about Margaret and the groceries and the Volkswagen; I understand his pain.
    </p>
    <p>
      But what I really learned was that the rules of Unix could be adapted to life.
    </p>
    <p>
      After about 30 years as a tech writer and frequent programmer, I finally settled on a set that works for me.  Little did I know that these very principles would lead me to org-mode, which would later lead me to find my people.
    </p>
    <hr>
    <h3>
      <center>
	Unix rules for life
      </center>
    </h3>
    <ul>
      <li>Keep it simple: It's cheaper and easier to carry around.</li>
      <li>Do one thing at a time: Multitasking is a lie.</li>
      <li>Network: You were born to connect.</li>
      <li>Say what you mean; nothing is truer than the truth.</li>
      <li>Hack: Trial and error is the only way we learn anything</li>
      <li>Be who you are: Even a bent wire can carry a great light.</li>
      <li>Use leverage; a bigger hammer isn't always the answer.</li>
      <li>Use what you have: never dig diamonds with a brick of gold.</li>
      <li>Have faith; all's possible, except maybe skiing through a revolving door.</li>
      <li>Think ahead, but don't worship your plans; remember today is the first day of the rest of your learning experience.</li>
    </ul>
    <hr>

<h3>
  a vi convert
</h3>
<p>
  I didn't start with org-mode, actually, but with plain journal files labeled YYYYMMDD, in a special directory in <code>/var/log</code>.  I still have those going back to sometime in the 90's.  The format was simple, but using the files soon became complex:
  </p><pre>	  
    *** personal journal of stormrider
    tue, aug 04, 1992 / 712904400
    sweetmorn, confusion 70, 3158 YOLD
    
    *** fortune -s
    Cold hands, no gloves.
    
    *** appts
    09:00  staff meeting, conf rm
    18:30  dinner with amit &amp; bonnie
    
    *** to do
    finish revisions on x-windows book
    do syllabus for advanced C class
    read some in Stevens &amp; Rago
    shower
    shave
    dress
    take out the trash otw to work
    .
    .
    .
    
    *** daily journal
    06:43 - man, didn't sleep well
    last night; i think i'm overdoing
    it on the coffee at work; maybe i
    should cut back some?
    .
    .
    .
  </pre>
  The unwieldy part came with all the repeated tasks, and tasks that got carried over from one day to the next (or didn't get finished). I had to copy yesterday's file, change all the key info, sort out the todo list, erase yesterday's journal, and generally do far too much work to keep my journal up.

<blockquote>
  <br>
  I got turned onto emacs sometime in the mid-nineties, when I moved to Atlanta to work for HP.  A fellow writer there used it, and suggested it might help me write and code up examples more effectively.  He was right, and it stuck....
  </blockquote>
<p>
  I did it, but intermittently, supplanting it with post-it notes, pads, planners galore, palm pilots, palmtop computers, etc.  It seemed like every day I was badly copying tasks from one day to the next. Meanwhile, my unwillingness to use Windows didn't give the the luxury of Outlook, when it came along.
</p>
<p>
  I got turned onto emacs sometime in the mid-nineties, when I moved to Atlanta to work for HP.  A fellow writer there used it, and suggested it might help me write and code up examples more effectively.  He was right, and it stuck as my editing platform of choice.
</p>
<p>
But I hadn't discovered org-mode yet. Either he didn't use it, or it hadn't been invented yet.  And to be honest, I kinda went back and forth between vi and emacs, depending on my "mood of the month."
</p>
<h3>
  a modem in the woods
</h3>
<p>
  Eventually, my HP job became a telecommuting-type arrangment, and I moved home to the farm, about an hour outside New Orleans, in the woods.  At that time, Internet was still modem-driven out here, so having command-line Linux with emacs on my laptop was a real lifesaver.
</p>
<p>
  Sometime not long before Katrina hit, I stumbled across org-mode.  I'd already used outline mode for some period of time (can't remember how long), and org-mode seemed like a logical follow-on from there.
      </p>
      <p>
	From there, org-mode just grew, and I grew with it.  All the features made it easy for me to both do what seemed natural for me, and do things in a way that felt like they supported my principles.  Gradually, my other methods of keeping track of things faded away, except for my alarm clock.  </p>
<p>
  Even when smart-phones took off, I was always trying to find some way to send org files over to my phone and use them there.  I think I even wrote some lua code in an iPhone wiki app to emulate org-mode with my files, though it was not fully satisfactory.
</p>
<h3>
  an org-mode resume
</h3>
      <p>
	Fast-forward to last May.  I'd been wanting to get on with Canonical for a long time, but hadn't found the right position, one that really matched my skills.  Then one Saturday, while I was waiting for my wife to meet me for some community event we were hosting, I saw a position that virtually described me.  I started to write a resume, but then decided that I would just take the job description elements, one-by-one, put them in an org file, and send them to the hiring manager.
      </p>
<p>
  Long-story short, almost everyone on this team used emacs, and org-mode, and lots of other .el packages that I also used every day.  I got the job, and so far, I'm very happy and feel like I fit in very well.
      </p>
      <h3>
	org-mode and my principles
      </h3>
      <p>
	Here's how I feel about using org-mode for everything: email, git, irc, web-browsing, organization, time-keeping, and so on.  And yes, I do use org-mode to connect with my email and the web, even though I use other packages (rmail, eww, magit, erc) to do the heavy lifing.  Let me walk it down, principle by principle:
	</p><ul>
	  <li><strong>Keep it simple:</strong> Granted, emacs isn't the simplest user interface, that is, until it becomes second nature.  After that, you'll find yourself accidentally erasing cells in your Google spreadsheet when you hit "C-x C-s" to try to save (good thing there's an undo). But the fact that you can use the same text for multiple functions: appointments, task states, task notes, clocking time, building an agenda, sending email, project planning, percentage completion, ....  The list is too long to quote, but just a simple statement, like "Get the discourse publishing tool working," can become the nucleus for a whole cycle's work and all the actions that go with it.</li><br>
	  <li><strong>Do one thing at a time:</strong> The window-driven nature of emacs makes it easy to switch tasks when you have to (just open another buffer) and then switch back later, and more quickly link back to where you were; not to mention that, if you become adept at using the agenda, you can keep yourself on track and move other things around with ease, and without any fear that they'll get lost.</li><br>
	  <li><strong>Network:</strong> Since I'm set up to send email, IRC, Mattermost, etc., directly from my org-mode tasks, it's easy to track where I am.  But even if I used another app, it's still really easy to just cut and paste a note next to a task and then set a follow-up time to prod, all without breaking your train of thought.  You're literally still looking at the work you're doing while you're messaging about it, so there's that.</li><br>
	  <li><strong>Say what you mean:</strong> You have the entire outline in front of you for whatever you're working on, so presentations, show-and-tell sessions, and status reports are really simple to give, whether verbally or in writing.</li><br>
	  <li><strong>Hack...:</strong> If it doesn't do what you want, you've got customizable variables, a huge library of packages, strong macro capability, and push-come-to-shove, emacs lisp, though I rarely have to go there, TBH.</li><br>
	  <li><strong>Be who you are:</strong> Org-mode matches my thinking style. Not true for everyone, but I tend to outline or mindmap (which you can do with org-mode, with the right .el package).</li><br>
	  <li><strong>Use leverage:</strong> Org-mode seriously leverages the power of plain text, in that you can either use the shortcuts to add an appointment, add tags, search tags -- or you can just do it by hand, because all of the special notation is plain text.  Leveraging human language in this way is helpful to me.</li><br>
	  <li><strong>Use what you have:</strong> Org-mode and emacs give me a stable platform that works everywhere, even on a printout.  I don't need license fees, special extensions, subscriptions, add-on tools, or constant updates to keep my life humming.</li><br>
	  <li><strong>Have faith:</strong> Org-mode has justified my faith, as has emacs.  Lots of tools I've used break, crash, or get killed by absorption (I once liked Astrid, e.g., but it suddenly got sold and went away).  Org-mode and emacs are pretty much here to stay, especially since there is no license fee, and I can keep a self-contained version backed up at home, should it ever stop being distributed.</li><br>
	  <li><strong>Think ahead:</strong> This is where org-mode, and especially the agenda, shine.  If I'm busy, I don't have to worry about keeping my outline clean.  I can stop in the middle of notes for another project, hit return, enter a to do for later (and tag it and schedule it to pop up later), and then move that to someplace more suitable later.  The agenda will clean it up and put it in perspective for me.  Or I can search for it, or pull up all open to-do items …</li></ul></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://stormrider.io/ninety-pct.html">http://stormrider.io/ninety-pct.html</a></em></p>]]>
            </description>
            <link>http://stormrider.io/ninety-pct.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23672473</guid>
            <pubDate>Sun, 28 Jun 2020 22:07:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PostgreSQL installation on Linux – with database creation]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23672367">thread link</a>) | @lukasbar
<br/>
June 28, 2020 | https://knowledgepill.it/posts/postgresql_installation/ | <a href="https://web.archive.org/web/*/https://knowledgepill.it/posts/postgresql_installation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <p>PostgreSQL is open source software so we can install it wthout any limitation, including our personal code changes. It is distributed under own The PostgreSQL License(TPL).</p>
<p>Installation of PostgreSQL is easy on Linux Distributions.<br>
For purpose of tutorial we use CentOS 8.</p>
<p>We shuold get newest PostgreSQL from official repo - version in OS repos are mostly old - like for now when we get with CentOS 8 PostgreSQL 9.6 :)</p>

<hr>
<p>Newest links for repos:
<a href="https://www.postgresql.org/download/">PostgreSQL Official Repos</a></p>
<hr>
<div><pre><code data-lang="bash"><span>[</span>root@postgres-lab ~<span>]</span><span># dnf install https://download.postgresql.org/pub/repos/yum/reporpms/EL-8-x86_64/pgdg-redhat-repo-latest.noarch.rpm</span>
Last metadata expiration check: 0:27:00 ago on Sun <span>28</span> Jun <span>2020</span> 09:01:23 PM UTC.
pgdg-redhat-repo-latest.noarch.rpm                                                                                             <span>15</span> kB/s |  <span>11</span> kB     00:00    
Dependencies resolved.
<span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span>
 Package                                    Architecture                     Version                             Repository                              Size
<span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span>
Installing:
 pgdg-redhat-repo                           noarch                           42.0-11                             @commandline                            <span>11</span> k

Transaction Summary
<span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span>
Install  <span>1</span> Package

Total size: <span>11</span> k
Installed size: <span>11</span> k
Is this ok <span>[</span>y/N<span>]</span>: y
Downloading Packages:
Running transaction check
Transaction check succeeded.
Running transaction test
Transaction test succeeded.
Running transaction
  Preparing        :                                                                                                                                      1/1
  Installing       : pgdg-redhat-repo-42.0-11.noarch                                                                                                      1/1
  Verifying        : pgdg-redhat-repo-42.0-11.noarch                                                                                                      1/1

Installed:
  pgdg-redhat-repo-42.0-11.noarch                                                                                                                             

Complete!
<span>[</span>root@postgres-lab ~<span>]</span>#
</code></pre></div>
<p>As mentioned earlier CentOS 8 has got build in module for PostgreSQL easy install. Despite that version of RDBMS is too old so we will disable it.</p>
<div><pre><code data-lang="bash"><span>[</span>root@postgres-lab ~<span>]</span><span># dnf -qy module disable postgresql</span>
</code></pre></div>
<div><pre><code data-lang="bash"><span>[</span>root@postgres-lab ~<span>]</span><span># dnf install postgresql12-server postgresql12</span>
Last metadata expiration check: 0:02:58 ago on Sun <span>28</span> Jun <span>2020</span> 09:30:47 PM UTC.
Dependencies resolved.
<span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span>
 Package                                      Architecture                    Version                                   Repository                       Size
<span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span>
Installing:
 postgresql12                                 x86_64                          12.3-5PGDG.rhel8                          pgdg12                          1.6 M
 postgresql12-server                          x86_64                          12.3-5PGDG.rhel8                          pgdg12                          5.1 M
Installing dependencies:
 postgresql12-libs                            x86_64                          12.3-5PGDG.rhel8                          pgdg12                          <span>395</span> k

Transaction Summary
<span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span>
Install  <span>3</span> Packages

Total download size: 7.1 M
Installed size: <span>30</span> M
Is this ok <span>[</span>y/N<span>]</span>: y
Downloading Packages:
<span>(</span>1/3<span>)</span>: postgresql12-libs-12.3-5PGDG.rhel8.x86_64.rpm                                                                          <span>365</span> kB/s | <span>395</span> kB     00:01    
<span>(</span>2/3<span>)</span>: postgresql12-12.3-5PGDG.rhel8.x86_64.rpm                                                                               1.2 MB/s | 1.6 MB     00:01    
<span>(</span>3/3<span>)</span>: postgresql12-server-12.3-5PGDG.rhel8.x86_64.rpm                                                                        3.0 MB/s | 5.1 MB     00:01    
--------------------------------------------------------------------------------------------------------------------------------------------------------------
Total                                                                                                                         4.1 MB/s | 7.1 MB     00:01     
Running transaction check
Transaction check succeeded.
Running transaction test
Transaction test succeeded.
Running transaction
  Preparing        :                                                                                                                                      1/1
  Installing       : postgresql12-libs-12.3-5PGDG.rhel8.x86_64                                                                                            1/3
  Running scriptlet: postgresql12-libs-12.3-5PGDG.rhel8.x86_64                                                                                            1/3
  Installing       : postgresql12-12.3-5PGDG.rhel8.x86_64                                                                                                 2/3
  Running scriptlet: postgresql12-12.3-5PGDG.rhel8.x86_64                                                                                                 2/3
  Running scriptlet: postgresql12-server-12.3-5PGDG.rhel8.x86_64                                                                                          3/3
  Installing       : postgresql12-server-12.3-5PGDG.rhel8.x86_64                                                                                          3/3
  Running scriptlet: postgresql12-server-12.3-5PGDG.rhel8.x86_64                                                                                          3/3
  Verifying        : postgresql12-12.3-5PGDG.rhel8.x86_64                                                                                                 1/3
  Verifying        : postgresql12-libs-12.3-5PGDG.rhel8.x86_64                                                                                            2/3
  Verifying        : postgresql12-server-12.3-5PGDG.rhel8.x86_64                                                                                          3/3

Installed:
  postgresql12-12.3-5PGDG.rhel8.x86_64            postgresql12-server-12.3-5PGDG.rhel8.x86_64            postgresql12-libs-12.3-5PGDG.rhel8.x86_64           

Complete!
<span>[</span>root@postgres-lab ~<span>]</span>#
</code></pre></div>
<p>We will create sample data cluster.<br>
First we create directory for all PostgreSQL data:</p>
<div><pre><code data-lang="bash"><span>[</span>root@postgres-lab ~<span>]</span><span># mkdir -p /postgresql/data</span>
<span>[</span>root@postgres-lab ~<span>]</span><span># chown postgres:postgres /postgresql -R</span>
</code></pre></div><p>Now from <code>postgres</code> OS user we can create data cluster:</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ /usr/pgsql-12/bin/initdb -D /postgresql/data
The files belonging to this database system will be owned by user <span>"postgres"</span>.
This user must also own the server process.

The database cluster will be initialized with locale <span>"en_US.UTF-8"</span>.
The default database encoding has accordingly been set to <span>"UTF8"</span>.
The default text search configuration will be set to <span>"english"</span>.

Data page checksums are disabled.

fixing permissions on existing directory /postgresql/data ... ok
creating subdirectories ... ok
selecting dynamic shared memory implementation ... posix
selecting default max_connections ... <span>100</span>
selecting default shared_buffers ... 128MB
selecting default time zone ... UTC
creating configuration files ... ok
running bootstrap script ... ok
performing post-bootstrap initialization ... ok
syncing data to disk ... ok

initdb: warning: enabling <span>"trust"</span> authentication <span>for</span> local connections
You can change this by editing pg_hba.conf or using the option -A, or
--auth-local and --auth-host, the next time you run initdb.

Success. You can now start the database server using:

    /usr/pgsql-12/bin/pg_ctl -D /postgresql/data -l logfile start
</code></pre></div>
<p>Firt we will enable PostgreSQL service:</p>
<div><pre><code data-lang="bash"><span>[</span>root@postgres-lab ~<span>]</span><span># systemctl enable postgresql-12</span>
Created symlink /etc/systemd/system/multi-user.target.wants/postgresql-12.service → /usr/lib/systemd/system/postgresql-12.service
</code></pre></div><p>Now we have to modify service to reflect our PostgreSQL directory:</p>
<div><pre><code data-lang="bash"><span>[</span>root@postgres-lab ~<span>]</span><span># vi /usr/lib/systemd/system/postgresql-12.service</span>
<span>[</span>...<span>]</span>
<span>[</span>Service<span>]</span>
Type<span>=</span>notify

User<span>=</span>postgres
Group<span>=</span>postgres


Environment<span>=</span>PGDATA<span>=</span>/postgresql/data

<span>[</span>...<span>]</span>
</code></pre></div><p>Reload daemon after service chnages:</p>
<div><pre><code data-lang="bash"><span>[</span>root@postgres-lab ~<span>]</span><span># systemctl daemon-reload</span>
</code></pre></div>
<div><pre><code data-lang="bash"><span>[</span>root@postgres-lab ~<span>]</span><span># systemctl start postgresql-12</span>
<span>[</span>root@postgres-lab ~<span>]</span><span># systemctl status postgresql-12</span>
● postgresql-12.service - PostgreSQL <span>12</span> database server
   Loaded: loaded <span>(</span>/usr/lib/systemd/system/postgresql-12.service; enabled; vendor preset: disabled<span>)</span>
   Active: active <span>(</span>running<span>)</span> since Sun 2020-06-28 21:46:29 UTC; 47s ago
     Docs: https://www.postgresql.org/docs/12/static/
  Process: <span>1972</span> ExecStartPre<span>=</span>/usr/pgsql-12/bin/postgresql-12-check-db-dir <span>${</span>PGDATA<span>}</span> <span>(</span>code<span>=</span>exited, status<span>=</span>0/SUCCESS<span>)</span>
 Main PID: <span>1977</span> <span>(</span>postmaster<span>)</span>
    Tasks: <span>8</span> <span>(</span>limit: 3248<span>)</span>
   Memory: 22.8M
   CGroup: /system.slice/postgresql-12.service
           ├─1977 /usr/pgsql-12/bin/postmaster -D /postgresql/data
           ├─1979 postgres: logger   
           ├─1981 postgres: checkpointer   
           ├─1982 postgres: background writer   
           ├─1983 postgres: walwriter   
           ├─1984 postgres: …</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://knowledgepill.it/posts/postgresql_installation/">https://knowledgepill.it/posts/postgresql_installation/</a></em></p>]]>
            </description>
            <link>https://knowledgepill.it/posts/postgresql_installation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23672367</guid>
            <pubDate>Sun, 28 Jun 2020 21:50:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Hardest Part of Working at a Growth Startup]]>
            </title>
            <description>
<![CDATA[
Score 49 | Comments 33 (<a href="https://news.ycombinator.com/item?id=23671824">thread link</a>) | @svmanager
<br/>
June 28, 2020 | https://staysaasy.com/scaling/2020/06/27/hardest-part-of-startup-scale-yourself.html | <a href="https://web.archive.org/web/*/https://staysaasy.com/scaling/2020/06/27/hardest-part-of-startup-scale-yourself.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p><img src="https://staysaasy.com/assets/hardest_part_of_startup/office-space.jpeg" alt="The hardest part of working at a growth startup is having to re-interview for your job every year">
Growth startups require both personal and business scaling.</p>

<p>The hardest part of working at a growth startup is having to re-interview for your job every year.</p>

<h3 id="the-challenge-of-scaling">The challenge of scaling</h3>

<p>You’re heading a key function at your 25-person startup. Maybe you’re head of engineering; maybe you run marketing. Hell, maybe you’re the CEO. You kick ass and your startup grows fast – and with that growth, the needs of the company evolve. Things in the new world are now going okay, but perhaps not optimally. Eventually, the CEO and board of directors get in a room to discuss what to do.</p>

<p>I can tell you what will happen in this room. The board will discuss your performance, and compare it to the performance of other, hypothetical executives – just as if you were interviewing for your own job. In your favor: you are a known quantity, presumably viewed as talented, and perhaps even a close friend. Against you: you haven’t done this before, and we need results now.</p>

<p>In many cases this conversation will lead to you being demoted or asked to leave. In extra cruel circumstances, you can literally get fired for having done a great job. This is normal, semi-expected, and sucks. And this happens to everyone – even founding CEOs are not immune.</p>

<p>The hardest part of this situation? These hard truths often go unspoken. Sometimes it’s just too awkward to tell someone who’s been there through thick and thin that they’re expected to be a stand-in for a future big league exec. And if you have a first-time management team, they might not even realize what’s going on – they may also be in the process of not scaling fast enough, either. At least when you’re interviewing, you’re explicitly given the chance to shine; such opportunities may not be spoon-fed to you during hectic growth.</p>

<h3 id="how-to-scale-yourself">How to scale yourself</h3>

<p>To avoid this situation you need to become a self-scaling machine. Read voraciously, and find opportunities to put new skills into practice – during growth mode there’s always too much to do, so take advantage and gain actual battlefield experience. You should constantly have an image in your mind of where you expect your team to be in 6 months and steer towards that future world. Learning to see around corners allows you to scale independently, and independence is a key leadership trait since <a href="https://staysaasy.com/scaling/2020/05/07/startup-is-this-normal.html">startups are constantly on fire</a>. Finding mentors who are at least 2-3 years ahead of you in terms of their own careers is another great way to build these instincts.</p>

<p>And most importantly, <em>ask questions</em>. Ask your manager how they expect your job will be different in 6 months (if you’re the CEO, this advice will be slightly different –&nbsp;a trusted advisor and/or executive coach can help). Ask them what they see as your current trajectory in the role. In my experience people are way too shy about asking direct questions in general, especially to their managers – it is literally your manager’s job to provide high-quality answers to your career questions. If you nail this, it’s a fast track towards increasing responsibility and growth.</p>

<h3 id="this-isnt-a-bad-thing">This isn’t a bad thing!</h3>

<p>From the other perspective, well-run growth startups give you the regular opportunity to interview for roles that are a level higher (or two!). <a href="https://www.linkedin.com/in/marissamayer/">This</a> is a <a href="https://www.linkedin.com/in/marcbenioff/">proven way</a> to <a href="https://www.linkedin.com/in/ericsyuan/">accelerate</a> your <a href="https://en.wikipedia.org/wiki/Sundar_Pichai#Career">career</a>. If you scale with a growing organization, you can pack decades of experience into years.</p>

    




  </div></div>]]>
            </description>
            <link>https://staysaasy.com/scaling/2020/06/27/hardest-part-of-startup-scale-yourself.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23671824</guid>
            <pubDate>Sun, 28 Jun 2020 20:34:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: 360º panoramic render using my 3D engine]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 5 (<a href="https://news.ycombinator.com/item?id=23671310">thread link</a>) | @atum47
<br/>
June 28, 2020 | https://victorribeiro.com/3Dsphere/ | <a href="https://web.archive.org/web/*/https://victorribeiro.com/3Dsphere/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://victorribeiro.com/3Dsphere/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23671310</guid>
            <pubDate>Sun, 28 Jun 2020 19:20:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Implementing the Exponential Function]]>
            </title>
            <description>
<![CDATA[
Score 195 | Comments 50 (<a href="https://news.ycombinator.com/item?id=23671262">thread link</a>) | @hackernewsn00b
<br/>
June 28, 2020 | https://www.pseudorandom.com/implementing-exp | <a href="https://web.archive.org/web/*/https://www.pseudorandom.com/implementing-exp">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p><em>I explore several sophisticated approximation techniques for implementing the exponential function, $f(x) = e^x$, including Taylor series approximation, Lagrange interpolation, Chebyshev interpolation, Carathéodory-Fejer approximation and MiniMax approximation. This also serves as a more general introduction to the use of these methods for approximating other functions. In the process I walk through the relevant theory for each method and apply numerical analysis to navigate various forms of error. I also include my own Python and C++ implementations of each algorithm in double precision<label for="cb-1"><sup id="footnote-1"><span>1</span></sup></label><span><p>1:  Note that the implementations included here will both output <strong>and</strong> calculate in double precision. We can still apply sophisticated methods in this setting, but as a general rule you’ll need higher intermediate precision to obtain an approximation which is indistinguishable from the true value in double precision. This is one (but not the only) reason why it’s generally advisable to use an optimized <code>exp(x)</code> function provided by your platform rather than write one from scratch.</p></span> with heavy commentary. Finally, I analyze each implementation’s performance and accuracy characteristics using the hyper-optimized, platform-provided <code>exp(x)</code> function as a benchmark.<label for="cb-2"><sup id="footnote-2"><span>2</span></sup></label><span><p>2:  In most cases, whichever numerical library you’re using will map to the platform-provided <code>exp(x)</code> function. For example, this is what <code>numpy.exp</code> does <a href="https://github.com/numpy/numpy/blob/master/numpy/core/src/npymath/npy_math_internal.h.src#L451-L471">under the hood</a>.</p></span> The Background section opens with the motivating properties of $e^x$ and the basics of floating point systems. The code for each technique is included under the corresponding Implementation heading.</em></p>

<h2 id="section-0"><a href="#section-0">Background</a></h2>

<h3 id="section-1"><a href="#section-1">Taylor series</a></h3>

<p>To motivate the definition of $e$, we will recall some calculus. Let $f$ be a <a href="https://mathworld.wolfram.com/SmoothFunction.html">smooth</a> function at $a$. This is to say that $f$ is infinitely <a href="https://mathworld.wolfram.com/Differentiable.html">differentiable</a> at some real value $a$: for every $k^{\text{th}}$ derivative $f^{(k)}$, we can differentiate $f^{(k)}$ again to obtain the $(k + 1)^{\text{th}}$ derivative $f^{(k + 1)}$. By definition, any function with this property which can also be uniquely represented as a <a href="https://mathworld.wolfram.com/TaylorSeries.html">Taylor series</a> expansion “centered” at $a$ is called <a href="https://mathworld.wolfram.com/RealAnalyticFunction.html">analytic</a>. The Taylor series of $f$ centered at $a$ and evaluated at $x$ is defined to be</p>

<p>$$
f(x) = \frac{f(a)}{0!}(x - a)^0 + \frac{f’(a)}{1!}(x - a)^1 + \ldots + \frac{f^{(k)}(a)}{k!}(x - a)^k + \ldots
$$</p>

<p>This is a <a href="https://mathworld.wolfram.com/PowerSeries.html">power series</a>, or infinite polynomial with one variable. The center of expansion determines a neighborhood of values returned by the Taylor series, and the coefficient of each <em>Taylor term</em> is determined by repeatedly differentiating the function $f$ and evaluating it at $a$. A common center of expansion is $a$ = 0, in which case the Taylor series is also called a <a href="https://mathworld.wolfram.com/MaclaurinSeries.html">Maclaurin series</a> and the series is centered around the origin. This can be considered the “default” setting. If you cut off all terms of the Taylor expansion after some term $k$, you obtain a polynomial with degree $k$. The coefficient of the $k^{\text{th}}$ term of the series (or polynomial, if truncated) is given by</p>

<p>$$
a_{k} = \frac{f^{(k)}(a)}{k!}
$$</p>

<p>where 0! = 1.</p>

<p>For a concrete example, consider the Taylor series expansion of the <a href="https://mathworld.wolfram.com/Sine.html">sine</a> function. The sine function is not only infinitely differentiable, but cyclic.</p>

<p>$$
\begin{aligned}
\sin^{(1)}(x) &amp;= \cos(x), \\
\sin^{(2)}(x) &amp;= \cos^{(1)}(x) = -\sin(x), \\
\sin^{(3)}(x) &amp;= -\sin^{(1)}(x) = -\cos(x), \\
\sin^{(4)}(x) &amp;= -\cos^{(1)}(x) = \sin(x)
\end{aligned}
$$</p>

<p>We determine each $k^{\text{th}}$ coefficient of the Taylor series by evaluating $f^{(k)}$ at $a$ and dividing it by the factorial of $k$. If we want to expand the sine function around the origin ($a$ = 0), we obtain the cyclic coefficients</p>

<p>$$
\begin{aligned}
\sin(0) &amp;= 0, \\
\sin^{(1)}(0) &amp;= \cos(0) = 1, \\
\sin^{(2)}(0) &amp;= \cos^{(1)}(0) = -\sin(0) = 0, \\
\sin^{(3)}(0) &amp;= -\sin^{(1)}(0) = -\cos(0) = -1, \\
\sin^{(4)}(0) &amp;= -\cos^{(1)}(0) = \sin(0) = 0
\end{aligned}
$$</p>

<p>Since $(x - 0)^{k} = x^{k}$, we have the Taylor series expansion</p>

<p>$$
\sin(x) = x - \frac{x^3}{3!} + \frac{x^5}{5!} - \frac{x^7}{7!} + \frac{x^9}{9!} - \ldots
$$</p>

<p>Truncating the Taylor expansion of a function $f$ at any term $k$ gives a finite approximation of $f$ using the $k$ degree <em>Taylor polynomial</em>. A Taylor polynomial of $f$ centered at $a$ produces very accurate approximations of $f(x)$ when $x$ is relatively close to $a$. As the absolute value of $x$ increases away from $a$, the accuracy of the Taylor polynomial rapidly decreases, which means it requires more terms of the Taylor series (i.e. a higher degree polynomial) for accurate approximation. Consider the following plot, which shows the values of $\sin(x)$ over the interval $[-20, 20]$ compared to its Taylor polynomials of degree 1, 3, 5, 7 and 9 centered at $a$ = 0.</p>

<figure>
  <p><a href="https://www.pseudorandom.com/assets/images/articles/implementing-exp/sin_taylor_series.svg"><img src="https://www.pseudorandom.com/assets/images/articles/implementing-exp/sin_taylor_series.svg"></a></p>
  <figcaption>$T_{n}$ denotes the degree $n$ Taylor polynomial of $\sin$</figcaption>
</figure>

<p>Observe that the Taylor approximation of $\sin(x)$ is more accurate when $x$ is near $a$ = 0, but quickly flies away from the true value of $\sin(x)$ further away from 0. The degree 1 Taylor polynomial is only an accurate approximation for $\sin(x)$ for a very small interval near the origin, whereas the degree 9 Taylor polynomial is very accurate within $[-5, 5]$. How long the approximation holds until it becomes extremely inaccurate depends on the number of terms of the Taylor polynomial. A higher degree polynomial will maintain a better approximation of $\sin(x)$ for longer, but any finite polynomial will eventually become extremely inaccurate.</p>

<h3 id="section-2"><a href="#section-2">Defining $e$</a></h3>

<p>The <a href="https://mathworld.wolfram.com/e.html">mathematical constant</a> $e$ is (almost) entirely motivated by the very nice properties it exhibits under exponentiation. In particular, the definition of $e$ was born out of the desire to find a continuous function which is its own derivative and which maps the additive identity 0 to the multiplicative identity 1. This is because solving difficult integration and differentiation problems is vastly more expedient with such a function. By extension a significant fraction of problems in applied mathematics and physics reduce to solving differential equations, for which such a function is fundamental.</p>

<p>As it happens, $f(x) = e^x$ uniquely satisfies this property. We can show this, and define $e$ directly in the process, by starting from the Taylor series representation of an arbitrary function $f$ infinitely differentiable at $a$ = 0. Suppose $a_0, a_1, \ldots$ are the coefficients of the Taylor series of $f$ centered at $a$. Then we have the Taylor series</p>

<p>$$
f(x) = a_0 + a_1 x + a_2 x^2 + a_3 x^3 + \ldots
$$</p>

<p>It follows from the linearity of differentiation that the Taylor series expansion of the first derivative $f’$ is</p>

<p>$$
f’(x) = a_1 + 2a_2 x + 3a_3 x^2 + \ldots
$$</p>

<p>To determine a function which is its own derivative, we solve for the coefficients $a_0, a_1, \ldots$ which satisfy $f = f’$:</p>

<p>$$
a_0 + a_1 x + a_2 x^2 + \ldots = a_1 + 2a_2 x + 3a_3 x^2 + \ldots
$$</p>

<p>From here we can see the pattern</p>

<p>$$
\begin{aligned}
a_0 &amp;= a_1, \\
a_1 &amp;= 2a_2, \\
a_2 &amp;= 3a_3
\end{aligned}
$$</p>

<p>and so on, which is equivalent to</p>

<p>$$
\begin{aligned}
a_1 &amp;= a_0, \\
a_2 &amp;= \frac{a_1}{2}, \\
a_3 &amp;= \frac{a_2}{3}
\end{aligned}
$$</p>

<p>By induction we have a <a href="https://mathworld.wolfram.com/RecurrenceEquation.html">recurrence relation</a> which defines the $k^{\text{th}}$ coefficient $a_k$</p>

<p>$$
a_k = \frac{a_{k - 1}}{k}
$$</p>

<p>Given $a_0$ = 1, we find that the Taylor series of a function which is its own derivative is</p>

<p>$$
f(x) = 1 + x + \frac{x^2}{2!} + \frac{x^3}{3!} + \ldots.
$$</p>

<p>We denote this function with $e^x$, where $e$ is defined to be the value of this function at $x$ = 1.</p>

<p>$$
e = f(1) = \sum_{k = 0}^{\infty}\frac{1}{k!} = 2.7183\ldots
$$</p>

<p>A more intuitive illustration of why $e^x$ is special is given by the following graph, in which exponential functions with various bases are plotted alongside their derivatives. An exponential function with a base less than $e$, like $b$ = 2, grows more quickly than its derivative. But when the base is greater than $e$, like $b$ = 4, it grows less quickly than its derivative.</p>

<figure>
  <p><a href="https://www.pseudorandom.com/assets/images/articles/implementing-exp/exp_comp.svg"><img src="https://www.pseudorandom.com/assets/images/articles/implementing-exp/exp_comp.svg"></a></p>
  <figcaption>When $b &lt; e$, we have $f'(x) &lt; f(x)$. When $b &gt; e$, we have $f'(x) &gt; f(x)$. But $b = e$ is the "goldilocks" base at which $f'(x) = f(x)$.</figcaption>
</figure>

<h3 id="section-3"><a href="#section-3">Floating point</a></h3>

<p>There is an intrinsic tension in that we want to determine accurate values of $e^x$ without doing too much work. Before we can consider the efficiency of an algorithm, we need to consider its accuracy. This leads us to define a variety of types of error, the most important of which comes from the way we approximate real numbers. It’s often impossible to calculate the exact value of $f(x)$ for an arbitrary function $f$, because computers can’t work with arbitrary real numbers.<label for="cb-3"><sup id="footnote-3"><span>3</span></sup></label><span><p>3:  <a href="https://en.wikipedia.org/wiki/Almost_all">Almost all</a> real numbers are not <a href="https://mathworld.wolfram.com/ComputableNumber.html">computable</a>. The reals which are computable are frequently not exactly representable to a desirable level of accuracy because they’re either irrational (and therefore have infinite decimal expansions) or rational with very long decimal expansions.</p></span> The best we can do is approximate the value to some acceptable accuracy.</p>

<p>The <a href="https://en.wikipedia.org/wiki/IEEE_754">IEEE 754</a> <em>floating point</em> standard discretizes real intervals into a computable form by mapping all nearby real values in given neighborhoods to a single rounded value. Internally, an IEEE 754 binary floating point number $N$ is represented using the normalized form</p>

<p>$$
N = \pm b_1.b_2b_3 \ldots b_p \times 2^{E_{k}}
$$</p>

<p>where the first bit is allocated for the sign (the <em>sign bit</em>), the $p$ bits $b_1.b_2b_3 \ldots b_p$ comprise the <em>mantissa</em>, or <em>significand</em>, and $E_{k}$ is an integer exponent consisting of $k$ bits. Note that since this form is normalized, $b_1 = 1$, while each of $b_2, \ldots b_p$ may equal 0 or 1. IEEE 754 single precision binary floating point numbers have a total size of $32$ bits: $8$ are allocated for the exponent $E \in [-126, 127]$ and $23$ are allocated for the mantissa (with $p$ = 24 accounting for the normalized bit). Thus you can represent $2^{32}$ different values in single precision floating point, with underflow and overflow limits of $2^{127} \approx 3.4 \times 10^{38}$ and $2^{-126} …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.pseudorandom.com/implementing-exp">https://www.pseudorandom.com/implementing-exp</a></em></p>]]>
            </description>
            <link>https://www.pseudorandom.com/implementing-exp</link>
            <guid isPermaLink="false">hacker-news-small-sites-23671262</guid>
            <pubDate>Sun, 28 Jun 2020 19:14:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Visual Paper Summary: Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23671183">thread link</a>) | @mpaepper
<br/>
June 28, 2020 | https://www.paepper.com/blog/posts/accurate-large-minibatch-sgd-training-image-net-in-1-hour/ | <a href="https://web.archive.org/web/*/https://www.paepper.com/blog/posts/accurate-large-minibatch-sgd-training-image-net-in-1-hour/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h2 id="new-blog-series-deep-learning-papers-visualized">New blog series: Deep Learning Papers visualized</h2>
<p>This is the first post of a new series I am starting where I explain the content of a paper in a visual picture-based way.
To me, this helps tremendously to better grasp the ideas and remember them and I hope this will be the same for many of you as well.</p>
<h2 id="todays-paper-accurate-large-minibatch-sgd-training-imagenet-in-1-hour-by-goyal-et-al">Today’s paper: Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour by Goyal et al.</h2>
<p>The first paper I’ve chosen is well-known when it comes to training deep learning models on multiple GPUs. Here is the link to the <a href="https://arxiv.org/abs/1706.02677">paper of Goyal et al.</a> on arxiv.
The basic idea of the paper is this: when you are doing deep learning research today, you are using more and more data and more complex models. As the complexity and size rises, of course also the computational needs rise tremendously. This means that you typically need much longer to train a model to convergence.
But if you need longer to train a model, your feedback loop is long which is frustrating as you already get many other ideas in the mean time, but as it takes so long to train, you cannot try them all out.
So what can you do?</p>
<p>You can train on multiple GPUs at the same time and in theory get results faster the more GPUs you use. Assume you need 1 week to train your model on a single GPU, then with 2 GPUs in parallel, you should be able to achieve the same training in about 3.5 days and when using 7 GPUs you only need a day.</p>
<p>So how does it work to train your model on multiple GPUs? Typically, data parallelization is used which simply means that when you have your epoch, you send some distinct data to each distinct GPU. But then how do you get a model that benefits from all the data? Basically, you always synchronize the gradients, so after each batch, you collect the gradients from each GPU, calculate the average of the gradients over all GPUs and then adjust the model weights.</p>
<p>Let’s take a visual look at this:</p>

  <figure>
    <img src="https://www.paepper.com/blog/posts/accurate-large-minibatch-sgd-training-image-net-in-1-hour/multi_gpu_training_batch_sizes.png" alt="Training the same amount of data on 1 vs 2 vs 4 GPUs">
    
      <figcaption>Training the same amount of data on 1 vs 2 vs 4 GPUs</figcaption>
    
  </figure>


<h3 id="increasing-the-batch-size---increasing-the-learning-rate">Increasing the batch size -&gt; increasing the learning rate</h3>
<p>Note what happens when you do this: your batch size is rising!
Let’s say you have 200 images per epoch and your batch size is 10. Then for a single GPU, you have 20 batches per epoch à 10 images. If you train on 2 GPUs, then your batch size is twice the size: 20. That’s because each of your two GPUs gets 10 images and calculates the gradients of those 10 and then you take the average of the gradients of those 2 GPUs, so your gradients are averaged over 20 images. This means that your epoch now only has 10 batches per epoch à 20 images. So by increasing the batch size, your are also reducing the number of batches per epoch and this in turn is exactly why it’s almost (except for the synchronization overhead) twice as fast to train.
Similarly, if you were to use 4 GPUs, then each GPU receives 10 images per batch, so your effective batch size is 40. Thus, you only need 5 batches per epoch to train your 200 images.</p>
<p>But in turn, if you only use 5 batches per epoch instead of 20, that also means that you are only taking 5 gradient descent steps instead of 20 on a single GPU.
We need to take a look what that means:</p>

  <figure>
    <img src="https://www.paepper.com/blog/posts/accurate-large-minibatch-sgd-training-image-net-in-1-hour/formula_3_and_4.png" alt="Equations 3 and 4 from the paper">
    
      <figcaption>Equations 3 and 4 from the paper</figcaption>
    
  </figure>


<p>Equation 3 represents the single GPU case after k iterations, in our case let’s take k = 4, so after 4 batches. This means we were updating our weights 4 times which is the first sum with j &lt; k, so j=0, j=1, j=2 and j=3. The second sum is the loop over the images in the corresponding batch and we calculate the gradient ($\nabla l$) determined by our weights at that time t+j and the image example x. We divide everything by n which is just the batch size, so n=10 in our example case and multiply by the learning rate $\eta$.</p>
<p>In contrast, equation 4 represents the multi GPU case for 4 GPUs (as we had k = 4). The 4 GPUs only take a single gradient descent step as the batch size is 4 times as large ($kn=4*10=40$). In this case, the first sum with j &lt; k is over our 4 GPUs and the seconds sum over the batch of each individual GPU. As we take the average of all of these, we divide by $kn=40$. This means that our step is k times smaller.</p>
<p>Now, the main idea of the paper is that we can make sure that the step size is roughly the same by scaling up our learning rate by the number of GPUs we are using: $\hat{\eta}=k * \eta$.
By doing so, equations 3 and 4 become roughly the same, because $\hat{\eta} * \frac{1}{kn} = k*\eta * \frac{1}{kn} = \eta * \frac{k}{kn} = \eta * \frac{1}{n}$.</p>
<p>Or to visualize:</p>

  <figure>
    <img src="https://www.paepper.com/blog/posts/accurate-large-minibatch-sgd-training-image-net-in-1-hour/four_steps_is_one_step.png" alt="Four SGD steps on a single GPU is a single step with four GPUs">
    
      <figcaption>Four SGD steps on a single GPU is a single step with four GPUs</figcaption>
    
  </figure>


<h3 id="intuition">Intuition</h3>
<p>To summarize so far: when we increase the number of GPUs to train with, we are increasing the effective batch size which leads to less batches per epoch and thus less SGD training steps. To compensate for less steps, we need to scale the learning rate linearly. This is simple: multiply the original single GPU learning rate by the number of GPUs you are using to train now. For example if your learning rate was 1e-3 before with a single GPU and now you train with 4 GPUs, then simply increase it to 4e-3.</p>
<p>Why does it intuitively make sense to scale the learning rate?</p>
<p>When your batch size is larger you will get a better estimate of the direction of the gradient in the right direction -&gt; your gradients are less fuzzy. Thus, when you have a more representative gradient, it makes sense to be able to take a larger step as the likelihood of walking in the wrong direction is reduced by the larger sample of examples.</p>
<p>Here is an illustration with the single GPU model taking 4 small steps (yellow) and the 4 GPU model taking 1 larger step (blue; the learning rate is multiplied by 4, so the step is four times as large):</p>

  <figure>
    <img src="https://www.paepper.com/blog/posts/accurate-large-minibatch-sgd-training-image-net-in-1-hour/gradients.png" alt="Illustration of gradient steps in the weight space. Red circle is the target / optimal weight configuration. Starting from a weight initialization in the left of the image, the single GPU model (yellow) takes 4 noisy steps. In contrast, the 4 GPU model (blue) takes a single larger step in a better approximated direction.">
    
      <figcaption>Illustration of gradient steps in the weight space. Red circle is the target / optimal weight configuration. Starting from a weight initialization in the left of the image, the single GPU model (yellow) takes 4 noisy steps. In contrast, the 4 GPU model (blue) takes a single larger step in a better approximated direction.</figcaption>
    
  </figure>


<h3 id="problem-initial-large-learning-rates">Problem: initial large learning rates</h3>
<p>The authors note that the learning process is most vulnerable in the beginning, because the weights are initialized at random and steps in the wrong direction can lead to a suboptimal space. Thus, they argue that the learning rate should not be immediately set to the higher value, but rather a learning rate annealing schedule should be used, so it starts low and then increases over time.</p>
<p>They try out different warm-up schedules and conclude that it works best to warm-up over 5 epochs, so that after 5 epochs the maximal learning rate is reached. However, I already observed machine learning models where a longer warm-up period is required, so you should try it out for your own problem.</p>
<p>How does this look like in practice? Assume your learning rate for single GPU training is 1e-3. So you want to end up at 4e-3 when training with 4 GPUs. So you need to add the learning rate (4-1) times to itself over 5 epochs: $lr_{epoch} = lr_{single-gpu} + lr_{single-gpu} * (n-1) * (epoch / 5)$. Here, $lr_{epoch}$ is the learning rate to use in a given epoch, $lr_{single-gpu}$ is the initial learning rate, n is the number of GPUs and epoch is your epoch.</p>
<p>And this is how this warm-up looks like over epochs:</p>

  <figure>
    <img src="https://www.paepper.com/blog/posts/accurate-large-minibatch-sgd-training-image-net-in-1-hour/learning_rate_gradual_warmup.png" alt="Learning rate gradual warmup (orange) for 4 GPUs vs. constant learning rate for a single GPU (blue).">
    
      <figcaption>Learning rate gradual warmup (orange) for 4 GPUs vs. constant learning rate for a single GPU (blue).</figcaption>
    
  </figure>


<h3 id="summary">Summary</h3>
<p>While the paper goes into more details, I discussed the most practical aspects of it and tried to visualize the key parts.</p>
<p>In particular, when training your machine learning model with multiple GPUs, you should scale your learning rate linearly with the number of GPUs you are using.
However, due to initial instability, use a learning rate warmup period which scales the learning rate linearly over the first couple of epochs.
By doing so, you are able to achieve similar loss curves as in the single GPU training.</p>
<p>The authors were able to train a ResNet-50 on ImageNet with a batch size of 8192 (!) on 256 GPUs at the same time and thus needing only 1 hour to train ImageNet. When the increased the batch size further than this, however, the accuracy got worse than the single GPU training, so there is still a (high) limit to how much you can reduce the training time by using more GPUs.</p>
<p>If you want to see how to implement this in PyTorch, check out <a href="https://www.paepper.com/blog/posts/pytorch-multi-gpu-training-for-faster-machine-learning-results/">my article PyTorch multi-GPU training for faster machine learning results</a>.</p>

    </div></div>]]>
            </description>
            <link>https://www.paepper.com/blog/posts/accurate-large-minibatch-sgd-training-image-net-in-1-hour/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23671183</guid>
            <pubDate>Sun, 28 Jun 2020 19:03:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I Designed the Perfect Startup Logo for $20]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23671160">thread link</a>) | @colinkeeley
<br/>
June 28, 2020 | https://colinkeeley.com/blog/how-i-designed-the-perfect-startup-logo-for-20 | <a href="https://web.archive.org/web/*/https://colinkeeley.com/blog/how-i-designed-the-perfect-startup-logo-for-20">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site">

      

      <main id="page" role="main" data-content-field="main-content" data-controller="FadeInContent">

        <div data-content-field="main-content" data-item-id="5ef8a8243895911144cbe029">
  
  <div>
    <p><time datetime="2020-06-28" pubdate="">
      <p><span>Jun </span><span>28</span>
      </p>
    </time></p><h2 data-content-field="title"><time datetime="2020-06-28" pubdate="">Jun 28 </time>How I Designed the Perfect Startup Logo for $20</h2>

    
  </div>
  

  <div>
    <article id="article-5ef8a8243895911144cbe029">
      
      
      <div data-controller="BlogProgressBar">
        
        
        <div><div data-layout-label="Post Body" data-type="item" data-updated-on="1593354946896" id="item-5ef8a8243895911144cbe029"><div><div><div data-block-type="2" id="block-669bf59b698de3db9753"><div><p>You can engage a fancy design agency and pay tens of thousands of dollars (or more!) for a nice logo or you can follow what I do.&nbsp;The results are similar. </p><p>With a design agency, you are really paying for their creativity. The technical skills of making a logo are cheap with global labor.&nbsp;</p><p>Here is how I made the <a href="http://avocadoaudio.com/">Avocado</a> logo in under an hour and for less than $20. </p><p><strong>Step 1: Browse Dribbble for inspiration</strong></p><p><a href="https://dribbble.com/">Dribbble</a>&nbsp;is a community for the world’s best designers to post their work. It is the place to go for design inspiration.&nbsp;</p><p>I like to search for related keywords and heart the designs I like to save them for later.&nbsp;</p><p><a href="http://avocadoaudio.com/">Avocado</a> is a platform for the world’s best audio courses and I wanted our design to reflect that. </p><p>For the logo, I wanted to combine an avocado design with an audio design.&nbsp;</p><p>Here are some Avocado designs I liked. </p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1593355161879_14665"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5d6548b6c5343d00018167dc/1593356024485-NDRC1C9QJLS52U932JNI/ke17ZwdGBToddI8pDm48kF4jcSjPem6tm7qw-KiYknZ7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UfDl4lOmv_lcnZlzQZYIkWYqhkHxkNQ79Tfxn9mftvcAZDqXZYzu2fuaodM4POSZ4w/Screen+Shot+2020-06-28+at+9.53.17+AM.png" data-image="https://images.squarespace-cdn.com/content/v1/5d6548b6c5343d00018167dc/1593356024485-NDRC1C9QJLS52U932JNI/ke17ZwdGBToddI8pDm48kF4jcSjPem6tm7qw-KiYknZ7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UfDl4lOmv_lcnZlzQZYIkWYqhkHxkNQ79Tfxn9mftvcAZDqXZYzu2fuaodM4POSZ4w/Screen+Shot+2020-06-28+at+9.53.17+AM.png" data-image-dimensions="2436x1366" data-image-focal-point="0.5,0.5" alt="Screen Shot 2020-06-28 at 9.53.17 AM.png" data-load="false" data-image-id="5ef8aef13895911144cc9f7d" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5d6548b6c5343d00018167dc/1593356024485-NDRC1C9QJLS52U932JNI/ke17ZwdGBToddI8pDm48kF4jcSjPem6tm7qw-KiYknZ7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UfDl4lOmv_lcnZlzQZYIkWYqhkHxkNQ79Tfxn9mftvcAZDqXZYzu2fuaodM4POSZ4w/Screen+Shot+2020-06-28+at+9.53.17+AM.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1593355161879_14955"><p>And some audio sound waves designs I liked.&nbsp;</p></div><div data-block-type="5" id="block-yui_3_17_2_1_1593354253719_30245"><div>








  

    

      <figure data-scrolled="" data-test="image-block-v2-outer-wrapper">

        <div>
          
            <div data-animation-role="image" data-description="">
            
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/5d6548b6c5343d00018167dc/1593354993618-9N2NELPHVHCHXK4ISRJ3/ke17ZwdGBToddI8pDm48kLUv7-PsjUbiVM-forBaZ4B7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UfX4EixnL6uTsBw9neJ_EVYu1KP8FQDOkVWurveTQ4SHoRwB-dUGsSquCnVTFQcaRg/Screen+Shot+2020-06-28+at+8.47.28+AM.png" data-image="https://images.squarespace-cdn.com/content/v1/5d6548b6c5343d00018167dc/1593354993618-9N2NELPHVHCHXK4ISRJ3/ke17ZwdGBToddI8pDm48kLUv7-PsjUbiVM-forBaZ4B7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UfX4EixnL6uTsBw9neJ_EVYu1KP8FQDOkVWurveTQ4SHoRwB-dUGsSquCnVTFQcaRg/Screen+Shot+2020-06-28+at+8.47.28+AM.png" data-image-dimensions="2446x1374" data-image-focal-point="0.5,0.5" alt="Screen Shot 2020-06-28 at 8.47.28 AM.png" src="https://images.squarespace-cdn.com/content/v1/5d6548b6c5343d00018167dc/1593354993618-9N2NELPHVHCHXK4ISRJ3/ke17ZwdGBToddI8pDm48kLUv7-PsjUbiVM-forBaZ4B7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UfX4EixnL6uTsBw9neJ_EVYu1KP8FQDOkVWurveTQ4SHoRwB-dUGsSquCnVTFQcaRg/Screen+Shot+2020-06-28+at+8.47.28+AM.png"></p>
          
            </div>
          

        </div>

        

      </figure>

    

  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1593354253719_35584"><div><p><strong>Step 2: Sketch out ideas on paper yourself</strong></p><p>I sketched out some ideas I had and got feedback from friends in the office.</p><p>I put the sound wave in the avocado as a seed and played around with what the sound wave could look like.&nbsp;</p><p>Unfortunately, I only had an orange marker for this.&nbsp;</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1593354253719_36753"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5d6548b6c5343d00018167dc/1593355142059-AFU85Q1ZI3JF90UV7FMI/ke17ZwdGBToddI8pDm48kNJUD_Xf508KnMqMAKvVaDd7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0s1LK8gu64hle203mIYOUnpbdT6-oIN-TUtU8fTm8cncKnzEUP5xgLKmtvxj_vUGDA/EV5ITlPWoAAqzlP.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5d6548b6c5343d00018167dc/1593355142059-AFU85Q1ZI3JF90UV7FMI/ke17ZwdGBToddI8pDm48kNJUD_Xf508KnMqMAKvVaDd7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0s1LK8gu64hle203mIYOUnpbdT6-oIN-TUtU8fTm8cncKnzEUP5xgLKmtvxj_vUGDA/EV5ITlPWoAAqzlP.jpeg" data-image-dimensions="2500x2015" data-image-focal-point="0.5,0.5" alt="EV5ITlPWoAAqzlP.jpeg" data-load="false" data-image-id="5ef8ab84b23df673eaa46eb7" data-type="image" src="https://colinkeeley.com/blog/EV5ITlPWoAAqzlP.jpeg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1593354253719_37052"><div><p><strong>Step 3: Iterate yourself</strong></p><p>This is a creative process and it takes time to arrive at something you’re happy with. </p><p>Try out different sketches and give it a few days of background thinking before you pay money to actually get it digitized.&nbsp;</p><p>Trying to iterate with a designer is what will cost you money. </p><p><strong>Step 4: Pay a Fiverr designer to digitize</strong></p><p>Share your sketch and your inspirations with a Fivver designer.&nbsp;<a href="https://track.fiverr.com/visit/?bta=122081&amp;brand=fiverrcpa">Fivver</a>&nbsp;is one of the largest online marketplaces for global talent.&nbsp;</p><p>Finding a quality designer can be hard. Just use&nbsp;<a href="https://track.fiverr.com/visit/?bta=122081&amp;brand=fiverrcpa&amp;landingPage=https%3A%2F%2Fwww.fiverr.com%2Flogo_star40%2Fdesign-simple-logo-for-your-brand%3Fsource%3Dorder_page_summary_gig_link_title%26funnel%3D00e4ecef-7686-40d4-969c-99979a3ef769">the designer I use</a>. I’ve used him for a few different logos and highly recommend him. He does excellent work and will make iterations until you’re happy.&nbsp;</p><p>The first versions won’t be perfect. Feel free to ask for small changes.&nbsp;</p><p>Here were some early versions for Avocado. </p></div></div><div data-aspect-ratio="100" data-block-type="5" id="block-yui_3_17_2_1_1593355161879_18569"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5d6548b6c5343d00018167dc/1593356437258-1K6YUYN7PA4712E0Q6KJ/ke17ZwdGBToddI8pDm48kDaNRrNi77yKIgWxrt8GYAFZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7WT60LcluGrsDtzPCYop9hMAtVe_QtwQD93aIXqwqJR_bmnO89YJVTj9tmrodtnPlQ/Avocado2.png" data-image="https://images.squarespace-cdn.com/content/v1/5d6548b6c5343d00018167dc/1593356437258-1K6YUYN7PA4712E0Q6KJ/ke17ZwdGBToddI8pDm48kDaNRrNi77yKIgWxrt8GYAFZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7WT60LcluGrsDtzPCYop9hMAtVe_QtwQD93aIXqwqJR_bmnO89YJVTj9tmrodtnPlQ/Avocado2.png" data-image-dimensions="255x255" data-image-focal-point="0.5,0.5" alt="Avocado2.png" data-load="false" data-image-id="5ef8b095f6302b5d71e5059b" data-type="image" src="https://colinkeeley.com/blog/Avocado2.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="5" id="block-yui_3_17_2_1_1593355161879_21999"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5d6548b6c5343d00018167dc/1593356497385-UWXN8PPDOQMTID8Y4GB0/ke17ZwdGBToddI8pDm48kOWyE5OVYnQHUXmTlJzahLdZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7R6SWOyAW0y1cpSTASaRj-wpFjVvAVgB0Fbm05Sc9zeDJmvI9K9QhjOgiAXjkI4xEw/Avocado.png" data-image="https://images.squarespace-cdn.com/content/v1/5d6548b6c5343d00018167dc/1593356497385-UWXN8PPDOQMTID8Y4GB0/ke17ZwdGBToddI8pDm48kOWyE5OVYnQHUXmTlJzahLdZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7R6SWOyAW0y1cpSTASaRj-wpFjVvAVgB0Fbm05Sc9zeDJmvI9K9QhjOgiAXjkI4xEw/Avocado.png" data-image-dimensions="241x254" data-image-focal-point="0.5,0.5" alt="Avocado.png" data-load="false" data-image-id="5ef8b0d1d960e626a1e17a57" data-type="image" src="https://colinkeeley.com/blog/Avocado.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1593355161879_18858"><div><p>We iterated on the shape and quantity of the sound waves until we found a happy medium with more seed-like sound waves. </p><p>The final result for <a href="http://avocadoaudio.com/">Avocado</a>. I’d put up against $100,000+ designs from any major agency. </p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1593355161879_16521"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5d6548b6c5343d00018167dc/1593356303883-BAS7KMBXRXBW1G4SDCR7/ke17ZwdGBToddI8pDm48kIIWdAnyBSrZ5E6Gv7JXlDh7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0k9kZPbuygN4RSDPe_G5PO_pbVb0jdkjHmk-MhSr8npod9fyhKaF6iH64GfT8sX2GQ/large+avocado+logo+on+rectangle+compressed.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5d6548b6c5343d00018167dc/1593356303883-BAS7KMBXRXBW1G4SDCR7/ke17ZwdGBToddI8pDm48kIIWdAnyBSrZ5E6Gv7JXlDh7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0k9kZPbuygN4RSDPe_G5PO_pbVb0jdkjHmk-MhSr8npod9fyhKaF6iH64GfT8sX2GQ/large+avocado+logo+on+rectangle+compressed.jpg" data-image-dimensions="2500x1563" data-image-focal-point="0.5,0.5" alt="large avocado logo on rectangle compressed.jpg" data-load="false" data-image-id="5ef8b00f3895911144ccc04c" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5d6548b6c5343d00018167dc/1593356303883-BAS7KMBXRXBW1G4SDCR7/ke17ZwdGBToddI8pDm48kIIWdAnyBSrZ5E6Gv7JXlDh7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0k9kZPbuygN4RSDPe_G5PO_pbVb0jdkjHmk-MhSr8npod9fyhKaF6iH64GfT8sX2GQ/large+avocado+logo+on+rectangle+compressed.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div></div></div></div></div>

        

        

        
      </div>
      

    </article>
  </div>







  
</div>

      </main>

      

    </div></div>]]>
            </description>
            <link>https://colinkeeley.com/blog/how-i-designed-the-perfect-startup-logo-for-20</link>
            <guid isPermaLink="false">hacker-news-small-sites-23671160</guid>
            <pubDate>Sun, 28 Jun 2020 19:00:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Better Geometry Through Graph Theory (2018)]]>
            </title>
            <description>
<![CDATA[
Score 69 | Comments 11 (<a href="https://news.ycombinator.com/item?id=23671130">thread link</a>) | @prospero
<br/>
June 28, 2020 | http://ideolalia.com/2018/08/28/artifex.html | <a href="https://web.archive.org/web/*/http://ideolalia.com/2018/08/28/artifex.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

	

	<div>
		<article>
			<p><img src="http://ideolalia.com/images/artifex-set-operations.png" alt=""></p>

<h3 id="how-i-spent-my-summer">how I spent my summer</h3>

<p>A few months ago, I decided to implement set operations on curved regions.  I had the <a href="https://www.springer.com/us/book/9783540779735">the canonical textbook on computational geometry</a>, which described approaches for polygons comprised of straight lines, and it seemed like <a href="http://paperjs.org/">other projects</a> had extended these techniques to <a href="https://en.wikipedia.org/wiki/B%C3%A9zier_curve">parametric curves</a>.  I figured it would take a couple of weeks.</p>

<p>Unfortunately, the field of computational geometry embodies a fundamental contradiction.  In geometry, the angles of a triangle add up to exactly π radians, and if <em>u</em> is clockwise from <em>v</em> then <em>v</em> must be counter-clockwise from <em>u</em>.  Computers, on the other hand, use floating point representations which make a mockery of these simple Euclidean truths.</p>

<p>The academic literature largely ignores this.  Algorithms are proven to be geometrically sound, and robust implementations are left as an exercise for the reader.  This is akin to a world in which hash collisions caused unavoidable data loss, and the academic response was to implicitly assume the existence of a perfect hash function.  If a paper is predicated on unrealistic assumptions, we cannot evaluate it on its own terms; we must understand, empirically, how well it functions when these assumptions are broken.</p>

<p>With this in mind, we can now look at the existing algorithms for <a href="https://en.wikipedia.org/wiki/Clipping_(computer_graphics)">polygon clipping</a>, which is the term of art for polygon set operations.  Every technique is a variation on a common theme:</p>

<p><img src="http://ideolalia.com/images/artifex-clipping.png" alt=""></p>

<ul>
  <li>Given two or more rings, find every point of intersection</li>
  <li>Segment the rings at the points of intersection</li>
  <li>Decide whether each segment should be included, based on the operation being performed</li>
</ul>

<p>The dozen or so papers on this subject differ only in the third step.  Since our decision to include a segment typically inverts at an intersection point, they describe a variety of approaches for using our decision to about one segment to inform our decision about adjacent segments.</p>

<p>My textbook described a method using <a href="https://en.wikipedia.org/wiki/Doubly_connected_edge_list">doubly-connected edge lists</a>, which is a generic geometric data structure.  I assumed that meant it could be reused for other problems, so I started my implementation.</p>

<p>A month went by.</p>

<p>I had finished the implementation my first week, but it wasn’t reliable.  A DCEL is a collection of linked loops, which can be incrementally updated.  When performing a set operation, we incrementally bisect the original set of loops, and then determine which should and shouldn’t be included.  Despite my best efforts, I kept finding new shapes that caused adjacent faces to get tangled together, creating a Möbius strip that is simultaneously inside and outside the expected result.</p>

<p>Slowly, I realized the problem wasn’t the data structure, it was the first step that every paper glossed over: finding all the intersections.  The DCEL assumes the edges at a vertex have a total ordering: the previous edge is directly clockwise, and the next one is directly counter-clockwise.  If we miss an intersection, we might conclude two curves are both clockwise relative to the other, causing everything to fall apart.</p>

<p>I began to look for better ways to find intersections, hoping that if I found an approach that was sufficiently accurate, my work on the DCEL could be salvaged.  Unfortunately, the approaches I found in the literature and implemented in the wild were no better than what I had been using.  My data structure demanded precise inputs, without internal contradictions, and I couldn’t deliver.</p>

<p>At that point, I began to wonder if I had missed something fundamental.  I thought maybe if I dissected how other, more mature, libraries handled my pathological shapes, I could work backwards to see where I had gone wrong.  But when I began to feed these shapes into well-established projects like paper.js, I found they failed just as badly.</p>

<p>To find my pathological inputs, I had been using property-based testing.  Given a random combination of shapes, I would perform a point-in-region test and compare it to a reference result, generated by querying each shape individually and combining the results according to the operation.  Most inputs worked fine, but after a few hundred thousand inputs it would inevitably find some failure.</p>

<p>Other projects, it turned out, had been a little less eager to find their own failure modes.  Some only had a handful of example-based tests, others had a static suite of a few thousand inputs they used to validate their changes.  If I had missed something, it appeared to be that no one else expected these operations to be particularly robust.</p>

<hr>

<h3 id="why-is-this-so-hard">why is this so hard?</h3>

<p>Floating point arithmetic is best understood through a simple, maddening fact: <code>a + (b - a)</code> does not necessarily equal <code>b</code>.  It might be equal, or it might be off by just a little, where “little” is relative to the larger of the two numbers.  This means that when we compare two floating point numbers, we cannot do a precise comparison, we have to ask whether they differ by less than some <em>epsilon</em> value.</p>

<p>This epsilon represents the level of numerical uncertainty to which we’ve resigned ourselves.  There is vast folk wisdom around how to minimize this uncertainty, but the fact remains that every arithmetic operation injects a bit of uncertainty, and it grows cumulatively with each successive operation.  When dealing with small numbers, this uncertainty may dwarf the values themselves.</p>

<p>An intersection, in a precise mathematical sense, occurs wherever the distance between the curves is exactly zero:</p>

<p><img src="http://ideolalia.com/images/artifex-precise-intersection.png" alt=""></p>

<p>But in a practical sense, it is wherever the distance between the curves is close enough to zero:</p>

<p><img src="http://ideolalia.com/images/artifex-fuzzy-intersection.png" alt=""></p>

<p>This has at least one intersection, but we could just as easily return three or ten within that overlapping range.  This uncertainty is anathema to the published techniques, which rely on counting these intersections to determine whether we’re inside or outside the other shape.  A single spurious intersection may cause the entire result to vanish.  If two objects with similar curvature move across each other, the result will tend to flicker in and out of existence.</p>

<p>These techniques may suffice for straight lines, which require smaller epsilons, but they are wholly unsuited to the relative imprecision of parametric curves.</p>

<hr>

<h3 id="embracing-the-uncertainty">embracing the uncertainty</h3>

<p>As the weeks passed, the errors uncovered by my tests went from feeling random to feeling malicious.  Floating point arithmetic may be deterministic, but as I watched my screen, waiting for the tests to fail, I imagined a demon in the FPU nudging the values as they flowed past, trying to move them beyond the threshold of self-consistency.</p>

<p>One day, I realized this was exactly the narrative behind <a href="https://en.wikipedia.org/wiki/Error_detection_and_correction">error-correcting codes</a>; we assume our data has been randomly altered en route, and we want to return it to a consistent state.  It didn’t seem like I could get it right the first time, so why not just fix it afterwards?</p>

<p>Consider the union of two ellipses:</p>

<p><img src="http://ideolalia.com/images/artifex-two-ellipses.png" alt=""></p>

<p>Ostensibly, there should only be three points of intersection, one on the left and two on the right.  But for the reasons described above, any intersection routine will likely find multiple points of intersection on the left as the curves converge on each other:</p>

<p><img src="http://ideolalia.com/images/artifex-ellipses-intersections.png" alt=""></p>

<p>The segments on the left are small enough, and thus imprecise enough, that our spatial intuition for the problem will just mislead us.  For this reason, it’s better to think of it as a graph:</p>

<p><img src="http://ideolalia.com/images/artifex-ellipses-graph.png" alt=""></p>

<p>Now we have to decide which edges to include, and which to exclude.  Since we’re trying to find the union, we want to keep any segments that are outside the other shape:</p>

<p><img src="http://ideolalia.com/images/artifex-ellipses-valid-result.png" alt=""></p>

<p>This is a well-formed result; there is a single cycle, and once we remove that cycle there are no leftover edges.  But we can’t rely on getting this lucky; the edges on the left might have succumbed to floating point error and believed they were both inside the other:</p>

<p><img src="http://ideolalia.com/images/artifex-ellipses-incomplete.png" alt=""></p>

<p>This is not a well-formed result; there are no cycles, and a bunch of leftover edges.  To make this consistent, we need to either close the loop, or remove the leftovers.  The cost of these changes is measured by the aggregate length of the edges we are adding or removing.</p>

<p>The minimal set of changes is equivalent to the shortest path between the dangling vertices.  Having found the path, we then invert the inclusion of every edge it passes through.  In this case, it passes through one of the edges we originally excluded, so we add that edge back in, and return the cycle we just created.</p>

<p>Alternately, both edges might think they are outside the other:</p>

<p><img src="http://ideolalia.com/images/artifex-ellipses-redundant.png" alt=""></p>

<p>In this case, we have a complete cycle, but once we’ve extracted it there’s a single leftover edge:</p>

<p><img src="http://ideolalia.com/images/artifex-ellipses-leftover.png" alt=""></p>

<p>Here again, we search through all the remaining edges for the shortest path between the two dangling vertices.  Since it passes through our leftover edge, we remove it.</p>

<p>Every floating point inconsistency will surface as one of these two cases, or some combination thereof.  By searching for the shortest path between the dangling edges, we find the smallest possible edit that will yield a consistent result.  Of course, a consistent result is not necessarily the <em>correct</em> one, but the fact that floating point errors tend to cluster around the smallest edges makes this a reasonable heuristic.  More importantly, it has weathered tens of millions of generative test cases without any issues.</p>

<p>A complete implementation of this algorithm can be found <a href="https://github.com/lacuna/artifex/blob/master/src/io/lacuna/artifex/utils/regions/Clip.java">here</a>.</p>

<hr>

<p>I’m not sure if this is a novel approach, but at the very least it represents a meaningful improvement on the state of the art in open source.  Intuitively, it feels like this might be a means to avoid epsilon hell in a wide range of geometric and numerical algorithms.  If anyone is aware of prior art in this vein, I’d be very interested to see it.</p>

<p>My work on the <a href="https://github.com/lacuna/artifex">Artifex</a> library is ongoing, but I hope it proves useful to others, and look forward to sharing my own projects that it will enable in the near future.</p>

<hr>

<p><em>Thanks to Alex Engelberg, Elana Hashman, Angus Fletcher, Reid McKenzie, and Zack Maril for feedback on early drafts of this post.</em></p>

		</article>
	</div>

</div></div>]]>
            </description>
            <link>http://ideolalia.com/2018/08/28/artifex.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23671130</guid>
            <pubDate>Sun, 28 Jun 2020 18:56:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Podaero/alpha-3 – a social network of small groups]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23670859">thread link</a>) | @newman8r
<br/>
June 28, 2020 | https://podaero.com/info/show-hn | <a href="https://web.archive.org/web/*/https://podaero.com/info/show-hn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://podaero.com/info/show-hn</link>
            <guid isPermaLink="false">hacker-news-small-sites-23670859</guid>
            <pubDate>Sun, 28 Jun 2020 18:20:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Does DARPA Work?]]>
            </title>
            <description>
<![CDATA[
Score 321 | Comments 82 (<a href="https://news.ycombinator.com/item?id=23670246">thread link</a>) | @MKais
<br/>
June 28, 2020 | https://benjaminreinhardt.com/wddw | <a href="https://web.archive.org/web/*/https://benjaminreinhardt.com/wddw">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="EssayContents">
<div id="EssayContentsInner">
<div>
  <div id="abstract-ish">
  <p>How can we enable more science fiction to become reality?</p>
  <p><span>If you want to do something, it usually pays to study those who have done that thing successfully in the past. Asking </span><span>‘what is this outlier’s production function?’
    </span><span>can provide a starting point. </span></p>
  <p><span>DARPA is an outlier organization in the world of turning science fiction into reality. Since 1958, it has been a driving force in the creation of weather satellites, GPS, personal computers, modern robotics, the
      Internet, autonomous cars, and voice interfaces, to name a few. However, it is primarily limited to the domain of defense technology – there are DARPA-style ideas that are out of its scope. &nbsp;Which emulatable attributes contributed to
      DARPA’s outlier results? </span><span>What does a</span>&nbsp;domain-independent&nbsp;“ARPA Model” look like? <span>Is it possible to
      build other organizations that generate equally huge results in other domains by riffing on that model?</span></p>
  <p>Gallons of ink have been spilled describing <span>how</span><span>&nbsp;DARPA works</span><a id="footnote_source_1" href="#footnote_1"><sup>1</sup></a><span>,
      but </span><span>in a nutshell here is</span><span>&nbsp;</span><span>how DARPA works.</span><span>&nbsp;Around 100 </span><span>program managers (PMs)</span><span>&nbsp;with ~5 year appointments create and run <span>programs</span> to pursue high-level visions like “actualize the idea of man-comp</span><span>uter symbiosis.” In these programs they fund researchers at universities and both
      big and small companies to do research </span><span>projects</span><span>&nbsp;of different sizes. Collectively, groups working on projects are called </span><span>performers</span>.&nbsp;Top-level
      authority lies with a <span>Director </span>who ultimately reports to the Secretary of Defense. </p>
  <p><span>DARPA has an incredibly powerful model for innovation in defense research, and I believe an abstract ‘<span>ARPA Model</span>’ could yield similar results in other domains. In this piece I’ll explain in detail why
      DARPA works. I’ll use that description to feel out and describe to the best of my ability a platonic ARPA Model. &nbsp;I’ll also distill some of the model’s implications for potential riffs on the model. Incidentally,
      I’m working on just such an imitator, and in future essays, I’ll explain why this model could be incredibly powerful when executed in a privately-funded context.</span></p>
  <h4>How to use this document</h4>
  
  <p>This document acts more like a collection of atomic notes than a tight essay – a DARPA-themed tapas if you will. The order of the sections is more of a guideline than a law so feel free to skip around. Throughout you will come across internal links that <a id="self-link" href="#self-link">look like this</a>.
    These links are an attempt to illustrate the interconnectedness of the ARPA Model.</p>
  <p><span>There are two stand-alone pieces to accomodate your time and interest:</span><span> a
    </span><span><a href="#distillation">distillation</a></span><span>, and the </span><span><a href="#h.nbyw8g2b67uk">full work</a></span><span>. </span><span>The
      distillation is meant to capture and compress the main points of the full work. Each section of the distillation internally links to the corresponding section one level deeper so if you want more info and nuance you can get it. </span></p>
      <p><span>I would rather this be read by a few people motivated to take action than by a broad audience who will find it merely interesting. In that vein, if you find yourself wanting to share this on Twitter or Hacker News, consider instead sharing it with one or two friends who will take action on it. Thank you for indulging me!</span></p>
      </div>
  
  <h2 id="program_managers_mini"><span>Program Managers</span></h2><p><span><a href="#at_the_end_of_the_day_the_arpa_model_depends_on_badass_program_managers_which_mirrors_the_obsession_with_“talent”_in_other_disciplines">At the end of the day the ARPA Model depends on badass program managers.</a></span><span>&nbsp;</span><span>Why is this the case? PMs need to
      think for themselves and go up and down the ladder of abstraction in an unstructured environment. On top of that they need to be effective communicators and coordinators because so much of their jobs is building networks. There’s a
      pattern that the abstract qualities that make “great talent” in different high-variance industries boils down to the ability to successfully make things happen under a lot of uncertainty. Given that pattern, the people who would
      make good DARPA PMs would <span>also</span> make good hedge fund analysts, first employees at startups, etc. so digging into </span><span><a href="#why_do_people_become_darpa_program_managers?">people’s motivations for becoming a PM</a></span><span>&nbsp;is important. More precise details about what makes a PM good prevent you from going after the exact same people as every other high-variance industry. When ‘talent’ isn’t code for ‘specialized
      training’ it means the role or industry has not been systematized. Therefore, despite all the talk here and elsewhere about ‘the ARPA Model’ we must keep in mind that we may be attributing more structure to the process than
      actually exists.</span></p><p><span><a href="#darpa_program_managers_pull_control_and_risk_away_from_both_researchers_and_directors">DARPA program managers pull control and risk away from both researchers and directors</a></span><span>.</span><span>&nbsp;PMs pull control away
      from directors by having only one official checkpoint before launching programs and pull control away from performers through their ability to move money around quickly. PMs design programs to be high-risk aggregations of lower-risk projects.
      Only 5–10 out of every 100 programs successfully produce transformative research, while only 10% of projects are terminated early. Shifting the risk from the performers to the program managers enables DARPA to tackle </span><span>systemic </span><span>problems where other models cannot.</span></p><p><span><a href="#the_best_darpa_program_managers_notice_systemic_biases">The best program managers notice systemic biases and attack them. </a></span><span>For example, noticing that all of the finite element modeling literature
      assumes a locally static situation and asking ‘what if it was dynamic?’ </span><span>“The best program managers can get into the trees and still see the forest.”</span><span> Obviously, this
      quality is rather fuzzy but leads to two precise questions:</span></p>
  <ol ="1"="">
    <li><span>How do you find people who can uncover systemic biases in a discipline? </span></li>
    <li><span>How could you systematize finding systemic biases in a discipline?</span></li>
  </ol>
  <p><span>The first question suggests that you should seek out heretics and people with expertise who are not experts. The second question suggests building structured frameworks for mapping a discipline and its assumptions.
    </span></p><p><span><a href="#a_large_part_of_a_darpa_program_manager’s_job_is_focused_network_building">A large part of a DARPA program manager’s job is focused network building</a></span><span>. </span><span>DARPA PMs network in the literal
      sense of creating networks, not just plugging into them. PMs meet disparate people working on ideas adjacent to the area in which they want to have an impact and bring them together in small workshops to dig into which possibilities are not
      impossible and what it would take to make them possible. The PMs host </span><span>performer days</span><span>&nbsp;— small private conferences for all the people working on different pieces of the program where
      performers can exchange ideas on what is working, what isn’t working, and build connections that don’t depend on the PM. </span><span><a href="https://en.wikipedia.org/wiki/J._C._R._Licklider">J.C.R. Licklider</a></span><a id="footnote_source_2" href="#footnote_2"><sup>2</sup></a><span>&nbsp;is a
      paragon here. He brought together all the crazy people interested in human-focused computing. On top of that, &nbsp;he also helped create the first computer science lab groups. PMs also build networks of people in different classes of organizations –
      government, academia, startups, and large companies. These connections smooth the path for technologies to go from the lab to the shelf. </span></p><p><span><a href="#darpa_pms_need_to_think_for_themselves,_be_curious,_and_have_low_ego">DARPA PMs need to think for themselves, be curious, and have low ego.</a></span><span>&nbsp;</span><span>Why does this matter? When you are
      surrounded by smart, opinionated people the easy option is to either 100% accept what they’re saying because it’s eloquent and well-thought through or reject it outright because it sounds crazy or goes against your priors. Thinking
      for yourself allows you to avoid these traps. PMs need to be curious because building a complete picture of a discipline requires genuine curiosity to ask questions nobody else is asking. A large ego would lead to a program manager imposing
      their will on every piece of the program, killing curiosity and the benefits of top down problems and bottom up solutions.</span></p><p><span><a href="#darpa_is_incredibly_flexible_with_who_it_hires_to_be_program_managers">DARPA is incredibly flexible with who it hires to be program managers.</a></span><span>&nbsp;</span><span>There are legal provisions in place that
      let DARPA bypass normal government hiring rules and procedures. Hiring flexibility is important because PMs are the sort of people who are in high demand, so they may be unwilling to jump through hoops. Bureaucracies ensure consistency through
      rules – minimal bureaucracy means there are no safeguards against hiring a terrible program manager so the principle that ‘A players hire A players and B players hire C players’ is incredibly important. &nbsp;</span></p><p><span><a href="#darpa_program_managers_have_a_tenure_of_four_to_five_years">DARPA Program managers have a tenure of four to five years.</a></span><span>&nbsp;</span><span>This transience is important for many reasons.
      Transience can inculcate PMs against the temptation to play it safe or play power games because there’s only one clear objective – make the program work. You’re out regardless of success or failure. Explicitly temporary roles can
      incentivize people with many options to join because they can have a huge impact, and then do something else. There’s no implicit tension between the knowledge that most people will leave eventually and the uncertainty about when that
      will be. Regular program manager turnover means that there is also turnover in ideas.</span></p><p><span><a href="#why_do_people_become_darpa_program_managers?">Why do people become DARPA Program managers? </a></span>From a career and money standpoint, being a program manager seems pretty rough.<span>&nbsp;There are unique benefits though. It offers an outlet for people frustrated with the conservative nature of academia. The prospect of getting to control a lot of money without a ton of oversight appeals to some people.
      Patriotism is definitely a factor, and hard to replicate outside of a government. Being a PM can gain you the respect of a small, elite group of peers who will know what you did. Finally, there may be a particular technological vision they want
      to see out in the world and DARPA gives them the agency to make it happen in unique ways.</span></p>
  <h2 id="incentives_and_structure_mini"><span>Incentives and Structure</span></h2><p><span><a href="#opacity_is_important_to_darpa’s_outlier_success">Opacity is important to DARPA’s outlier success.</a></span><span>&nbsp;</span><span>Congress and the DoD have little default oversight
      into how a PM is spending money and running a program. </span><span>Opacity removes incentives to go for easy wins or to avoid being criticized by external forces. Of course, opacity can also be abused in too many ways to list,
      so it’s important to ask: How does DARPA incentivize people not to abuse opacity? DARPA’s small size and flat structure enable peer pressure to work in …</span></p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://benjaminreinhardt.com/wddw">https://benjaminreinhardt.com/wddw</a></em></p>]]>
            </description>
            <link>https://benjaminreinhardt.com/wddw</link>
            <guid isPermaLink="false">hacker-news-small-sites-23670246</guid>
            <pubDate>Sun, 28 Jun 2020 17:07:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Hacker News front page in the style of a print newspaper]]>
            </title>
            <description>
<![CDATA[
Score 579 | Comments 127 (<a href="https://news.ycombinator.com/item?id=23669650">thread link</a>) | @wolfgang42
<br/>
June 28, 2020 | https://www.wolfgangfaust.com/project/paper-hn/ | <a href="https://web.archive.org/web/*/https://www.wolfgangfaust.com/project/paper-hn/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>This looks much nicer if you enable JavaScript.</p><div><section><h2><a href="http://antirez.com/news/133">The End of the Redis Adventure</a></h2><p><code>antirez.com</code> —  The end of the Redis adventureantirez 6 hours ago. 91827 views. When I started the Redis project more than ten years ago I was in one of the most exciting moments of my career. My co-founder and I had successfully launched two of the major web 2.0 services of the Italian web. In order to make them scalable we had to invent many new concepts, that were already known in the field most of the times, but we didn’t know, nor we cared to check. Problem? Let’s figure out a solution. We wanted to solve problems but we wanted, even more, to have fun. This was the playful environment where Redis was born. But now Redis is, incredibly, one of the main parts of so many things. And year after year my work changed from building this thing to making sure that it was also as useful as possible, as reliab... <strong><a href="https://news.ycombinator.com/item?id=23689549">ADVENTURE</a>,&nbsp;1</strong></p></section><section><img src="https://linear.app/static/metaImage4.jpg"><h2><a href="http://linear.app/">Linear – A fast issue tracker</a></h2><p><code>linear.app</code> — Linear helps streamline software projects, sprints, tasks, and bug tracking. It's built for high-performance teams. <strong><a href="https://news.ycombinator.com/item?id=23693029">TRACKER</a>,&nbsp;2</strong></p></section><section><img src="https://research.fb.com/wp-content/uploads/2020/06/Holographic-optics_1.jpg"><h2><a href="https://research.fb.com/blog/2020/06/holographic-optics-for-thin-and-lightweight-virtual-reality/">Holographic optics for thin and lightweight virtual reality</a></h2><p><code>fb.com</code> — Facebook Reality Labs (FRL) is always exploring new optical architectures to improve form factor, comfort, and optical performance. Last fall, at Oculus Connect 6, FRL Chief Scientist Michael Abrash introduced new miniaturization progress in VR with Half Dome 2 and 3, two prototypes that examine how varifocal displays can improve visual and physical comfort. This year, at the virtual SIGGRAPH conference, we’re presenting another research milestone on this path: a new optical architecture that is significantly more compact and offers the potential for better visual performance. <strong><a href="https://news.ycombinator.com/item?id=23692442">HOLOGRAPHIC</a>,&nbsp;3</strong></p></section><section><img src="https://marcobonvini.com/images/posts/hybrid-car-scheme.png"><h2><a href="https://marcobonvini.com/modelica/2020/06/29/all-about-modelica.html">All about Modelica: An equation-based language for modeling physical systems</a></h2><p><code>marcobonvini.com</code> —  by Marco Bonvini on Monday June 29, 2020  <strong><a href="https://news.ycombinator.com/item?id=23690788">MODELICA</a>,&nbsp;4</strong></p></section><section><img src="http://2.bp.blogspot.com/-7bZ5EziliZQ/VynIS9F7OAI/AAAAAAAASQ0/BJFntXCAntstZe6hQuo5KTrhi5Dyz9yHgCK4B/s1600/googlelogo_color_200x200.png"><h2><a href="https://security.googleblog.com/2020/06/system-hardening-in-android-11.html">System Hardening in Android 11</a></h2><p><code>googleblog.com</code> — In Android 11 we continue to increase the security of the Android platform. We have moved to safer default settings, migrated to a hardened memory allocator, and expanded the use of compiler mitigations that defend against classes of vulnerabilities and frustrate exploitation techniques.  <strong><a href="https://news.ycombinator.com/item?id=23692257">HARDENING</a>,&nbsp;5</strong></p></section><section><img src="https://avatars1.githubusercontent.com/u/66284975?s=400&amp;v=4"><h2><a href="https://github.com/2020PB/police-brutality#hn">Git Repo of Police Brutality During the 2020 George Floyd Protests</a></h2><p><code>github.com</code> —  Repository containing evidence of police brutality during the 2020 George Floyd protests  <strong><a href="https://news.ycombinator.com/item?id=23693650">BRUTALITY</a>,&nbsp;6</strong></p></section><section><h2><a href="https://lapcatsoftware.com/articles/disclosure2.html">Disclosure: Another macOS privacy protections bypass</a></h2><p><code>lapcatsoftware.com</code> — Today I'm disclosing a macOS privacy protections bypass. (You may recall that I disclosed another one last year.) The privacy protections system (also known as TCC: Transparency, Consent, and Control) was introduced in macOS Mojave, and one of its purposes is to protect certain files on your Mac from access by unauthorized apps. I've discovered a way for an unauthorized app to read the contents of protected files, thus bypassing the privacy protections. This issue exists in Mojave, Catalina, and the Big Sur beta. It remains unaddressed and is therefore, in one sense, a zero-day. Here's the timeline leading to my disclosure: <strong><a href="https://news.ycombinator.com/item?id=23689364">DISCLOSURE</a>,&nbsp;7</strong></p></section><section><img src="https://hyperapp.dev/card.b7cfd6ff.png"><h2><a href="https://hyperapp.dev/">Hyperapp – A tiny framework for building web interfaces</a></h2><p><code>hyperapp.dev</code> —  <strong><a href="https://news.ycombinator.com/item?id=23688798">HYPERAPP</a>,&nbsp;8</strong></p></section><section><h2><a href="https://danluu.com/car-safety/">How well do cars do in crash tests they're not optimized for?</a></h2><p><code>danluu.com</code> —  <strong><a href="https://news.ycombinator.com/item?id=23689538">CARS</a>,&nbsp;9</strong></p></section><section><img src="https://images.anandtech.com/doci/15888/12_678x452.jpg"><h2><a href="https://www.anandtech.com/show/15888/400-tb-storage-drives-in-our-future-fujifilm">400 TB Storage Drives in Our Future: Fujifilm</a></h2><p><code>anandtech.com</code> — One of the two leading manufacturers of tape cartridge storage, FujiFilm, claims that they have a technology roadmap through to 2030 which builds on the current magnetic tape paradigm to enable 400 TB per tape. <strong><a href="https://news.ycombinator.com/item?id=23690461">DRIVES</a>,&nbsp;10</strong></p></section><section><img src="https://torrentfreak.com/images/books-large.jpg"><h2><a href="https://torrentfreak.com/eff-heavyweight-legal-team-will-defend-internet-archives-digital-library-against-publishers-200626/">EFF and Heavyweight Legal Team Will Defend Internet Archive Against Publishers</a></h2><p><code>torrentfreak.com</code> — In March and faced with the chaos caused by the coronavirus pandemic, the Internet Archive (IA) launched its National Emergency Library (NEL)  <strong><a href="https://news.ycombinator.com/item?id=23691297">EFF</a>,&nbsp;11</strong></p></section><section><h2><a href="https://news.ycombinator.com/item?id=23675370">Ask HN: How to improve my abstract thinking?</a></h2><p><code>news.ycombinator.com</code> — A few days ago I got into Mathematical Logic[0] and learned how to reason about problems through using various branches of mathematical ideas like proof theory, model theory e.t.c. <strong><a href="https://news.ycombinator.com/item?id=23675370">ABSTRACT</a>,&nbsp;12</strong></p></section><section><h2><a href="http://kvark.github.io/tech/arguments/2020/06/30/technical-discussions.html">Missing Structure in Technical Discussions</a></h2><p><code>kvark.github.io</code> — People are amazing creatures. When discussing a complex issue, they are able to keep multiple independent arguments in their heads, the pieces of supporting and disproving evidence, and can collapse this system into a concrete solution. We can spend hours navigating through the issue comments on Github, reconstructing the points of view, and making sense of the discussion. Problem is: we don’t actually want to apply this superpower and waste time nearly as often. <strong><a href="https://news.ycombinator.com/item?id=23691701">STRUCTURE</a>,&nbsp;13</strong></p></section><section><img src="https://www.notion.so/images/meta/default.png"><h2><a href="https://nova.chat/">NovaChat: Multi-Network Chat</a></h2><p><code>nova.chat</code> —  <strong><a href="https://news.ycombinator.com/item?id=23693371">NOVACHAT</a>,&nbsp;14</strong></p></section><section><img src="https://www.deepsouthventures.com/wp-content/uploads/yellowstone-roughriders-3.jpg"><h2><a href="https://www.deepsouthventures.com/must-ride-mule-to-from-work-location/">Must ride mule to and from work location</a></h2><p><code>deepsouthventures.com</code> — “David, this one, tell me about it …” <strong><a href="https://news.ycombinator.com/item?id=23690922">MULE</a>,&nbsp;15</strong></p></section><section><h2><a href="https://blog.c0nrad.io/hydrogen/">3D Electron Orbitals of Hydrogen</a></h2><p><code>c0nrad.io</code> —  Made with ♥ by c0nrad. code     <strong><a href="https://news.ycombinator.com/item?id=23691547">ELECTRON</a>,&nbsp;16</strong></p></section><section><img src="https://blog.google/static/blogv2/images/google-1000x1000.png"><h2><a href="https://blog.google/products/hardware/focus-helpful-devices-google-acquires-north/">Google Acquires North</a></h2><p><code>blog.google</code> — Today we're announcing that Google has acquired North, a pioneer in human computer interfaces and smart glasses. They've built a strong technology foundation, and we're excited to have North join us in our broader efforts to build helpful devices and services. <strong><a href="https://news.ycombinator.com/item?id=23690967">ACQUIRES</a>,&nbsp;17</strong></p></section><section><h2><a href="https://www.reuters.com/article/us-usa-judges-misconduct-specialreport/special-report-thousands-of-us-judges-who-broke-laws-oaths-remained-on-the-bench-idUSKBN2411WG">Thousands of U.S. judges who broke laws, oaths remained on the bench</a></h2><p><code>reuters.com</code> — MONTGOMERY, Alabama (Reuters) - Judge Les Hayes once sentenced a single mother to 496 days behind bars for failing to pay traffic tickets. The sentence was so stiff it exceeded the jail time Alabama allows for negligent homicide.  <strong><a href="https://news.ycombinator.com/item?id=23693023">JUDGES</a>,&nbsp;18</strong></p></section><section><img src="https://pdmethods.com/wp-content/uploads/2019/02/PDmethods-logo.png"><h2><a href="https://pdmethods.com/">Product Discovery Methods</a></h2><p><code>pdmethods.com</code> — Why conducting interviews? People usually do not know exactly what they want therefore you need to observe what they do and listen their frustration. Understanding of your customers’ frustration and needs are the main reasons Read more… <strong><a href="https://news.ycombinator.com/item?id=23675279">DISCOVERY</a>,&nbsp;19</strong></p></section><section><img src="https://www.stavros.io/static/images/favicons/og-image.jpg?h=3375145f"><h2><a href="https://www.stavros.io/posts/u2f-fido2-with-ssh/">How to use FIDO2 USB keys with SSH</a></h2><p><code>stavros.io</code> — I recently installed Ubuntu Wacky Whatever, the latest version, and I’m very excited about it shipping with SSH 8.2, which means that I can finally use hardware USB keys for secure, easy to use authentication. If securing your devices has been something you’ve wanted to easily do yourself, read on, because it’s finally happening. <strong><a href="https://news.ycombinator.com/item?id=23689499">FIDO2</a>,&nbsp;20</strong></p></section><section><img src="https://nas-national-prod.s3.amazonaws.com/styles/nas_bird_teaser_illustration/s3/765_Sibl_9780307957900_art_r1.jpg?itok=1E_Ba6d3"><h2><a href="https://www.audubon.org/news/mallards-ferry-fish-eggs-between-waterbodies-through-their-poop">Mallards ferry fish eggs between waterbodies</a></h2><p><code>audubon.org</code> — Membership benefits include one year of Audubon magazine&nbsp;and the latest on birds and their habitats. Your support helps secure a future for birds at risk. <strong><a href="https://news.ycombinator.com/item?id=23688748">MALLARDS</a>,&nbsp;21</strong></p></section><section><img src="http://static1.squarespace.com/static/53dd6676e4b0fedfbc26ea91/54b6c509e4b062126976d942/5eda72edd52aa53cd29dfd42/1593450277161/ricardo-velasquez-7K5szrmSYnY-unsplash.jpg?format=1500w"><h2><a href="https://www.strongtowns.org/journal/2020/6/5/inefficient-but-smart">Inefficient, but Smart</a></h2><p><code>strongtowns.org</code> — Quita, Ecuador. Image via Unsplash. <strong><a href="https://news.ycombinator.com/item?id=23690419">INEFFICIENT</a>,&nbsp;22</strong></p></section><section><img src="https://ichef.bbci.co.uk/news/1024/branded_news/1128E/production/_112268207_0242ce77-39ad-423d-a4ed-828b51e45196.jpg"><h2><a href="https://www.bbc.com/news/world-europe-53237685">Germany far right: Elite KSK commando force 'to be partially disbanded'</a></h2><p><code>bbc.com</code> — Germany's defence minister says she has ordered the partial dissolution of the elite KSK commando force, which has come under growing criticism over right-wing extremism in its ranks.  <strong><a href="https://news.ycombinator.com/item?id=23693851">FAR</a>,&nbsp;23</strong></p></section><section><img src="https://www.sciencealert.com/images/2020-06/processed/aphantasiaMessyMemoriesToo_1024.jpg"><h2><a href="https://www.sciencealert.com/some-people-can-t-picture-things-in-their-mind-and-it-might-make-it-hard-for-them-to-remember">People who can't see things in their mind could have memory trouble too: study</a></h2><p><code>sciencealert.com</code> — Not everyone can see pictures in their minds when they close their eyes and summon thoughts - an ability many of us take for granted. <strong><a href="https://news.ycombinator.com/item?id=23689667">MIND</a>,&nbsp;24</strong></p></section><section><img src="https://wicg.github.io/portals/portals-state-transitions.svg"><h2><a href="https://wicg.github.io/portals/">Portals API</a></h2><p><code>wicg.github.io</code> — This specification document has not yet been updated to reflect the 2020-04 updates to the explainer. We’ll fix that as soon as we can, but please be aware that there are probably contradictions, and the explainer should be taken as more authoritative for the time being. <strong><a href="https://news.ycombinator.com/item?id=23688699">PORTALS</a>,&nbsp;25</strong></p></section><section><img src="https://i.cbc.ca/1.5628640.1593198689!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_620/germany.jpg"><h2><a href="https://www.cbc.ca/news/business/zoom-trust-business-pandemic-1.5628638?cmp=rss">Video chats short-circuit a brain function essential for trust?</a></h2><p><code>cbc.ca</code> — Ever get the sense there is something vital missing on those Zoom meetings? If so, you're not alone — and there is Canadian science to back you up. <strong><a href="https://news.ycombinator.com/item?id=23689614">CHATS</a>,&nbsp;26</strong></p></section><section><img src="https://magazine.atavist.com/data/files/organization/1/image/derivative/scale~1200x1200~webcover214-1454482807-64.jpg"><h2><a href="https://magazine.atavist.com/a-thousand-pounds-of-dynamite">A Thousand Pounds of Dynamite (2014)</a></h2><p><code>atavist.com</code> —  The helicopter thundered over the darkened forest, heading west, rising into the mountains beneath an almost full moon. Even for FBI special agent Dell Rowley, a slight five foot nine, the narrow cargo space behind the two front seats was a tight fit. The helmet and Kevlar vest he wore over his black fatigues, and the weapons he carried, did not make it any more comfortable. But the pilot was supposed to be alone, so Rowley had to stay where he was. Besides, the copilot’s seat was occupied by three canvas money bags, stuffed with cut-and-bound bundles of newsprint calculated to match the weight and volume of almost $3 million in $100 bills—and $1,000 in cash, to complete the effect. <strong><a href="https://news.ycombinator.com/item?id=23686830">THOUSAND</a>,&nbsp;27</strong></p></section><section><img src="https://images.macrumors.com/article-new/2020/06/tiktokclipboard.jpg"><h2><a href="https://www.macrumors.com/2020/06/25/tiktok-clipboard-access-ios-14-caught/">TikTok App to Stop Accessing User Clipboards After Being Caught in the Act</a></h2><p><code>macrumors.com</code> — A new feature in iOS 14 alerts users when apps read the clipboard, and it turns out some apps have been reading clipboard data excessively. <strong><a href="https://news.ycombinator.com/item?id=23691190">CLIPBOARDS</a>,&nbsp;28</strong></p></section><section><img src="https://images.anandtech.com/doci/15871/2_678x452.jpg"><h2><a href="https://www.anandtech.com/show/15871/amperes-product-list-80-cores-up-to-33-ghz-at-250-w-128-core-in-q4">Ampere’s Product List: 80 Cores, up to 3.3 GHz at 250 W; 128 Core in Q4</a></h2><p><code>anandtech.com</code> — With the advent of higher performance Arm based cloud computing, a lot of focus is being put on what the various competitors can do in this space. We’ve covered Ampere Computing’s previous eMag products, which actually came from the acquisition of Applied Micro, but the next generation hardware is called Altra, and after a few months of teasing some high performance compute, the company is finally announcing its product list, as well as an upcoming product due for sampling this year. <strong><a href="https://news.ycombinator.com/item?id=23689419">CORES</a>,&nbsp;29</strong></p></section><section><p><a href="https://repl.it/jobs"><strong>Repl.it is hiring</strong> front end, fullstack, and designers to revolutionize computing</a> <code>repl.it</code></p></section><section><p><a href="https://draftbit.com/jobs/product-manager"><strong>Draftbit (YC W18) Is Hiring</strong> a Technical Product Lead – Build Apps Visually</a> <code>draftbit.com</code></p></section><section><p><a href="https://jobs.lever.co/buildzoom"><strong>BuildZoom (GC marketplace) is hiring</strong> sales, engineers and construction experts</a> <code>lever.co</code></p></section></div></div>]]>
            </description>
            <link>https://www.wolfgangfaust.com/project/paper-hn/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23669650</guid>
            <pubDate>Sun, 28 Jun 2020 16:00:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Laptop Buying Guide: Workstation Laptop versus Gaming Laptop]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23669441">thread link</a>) | @sirkarthik
<br/>
June 28, 2020 | https://blog.codonomics.com/2020/06/workstation-laptop-versus-gaming-laptop.html | <a href="https://web.archive.org/web/*/https://blog.codonomics.com/2020/06/workstation-laptop-versus-gaming-laptop.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-4156024826229998353" itemprop="description articleBody">
<h3>My Backdrop</h3><p>As geeky entrepreneur I dabble on many things tech and look for opportunities to see how tech can be leveraged to solve a business problem. I got really dirty learning and hacking Machine Learning problems and dabbled a bit on Deep Learning a couple of years back.&nbsp;</p><p>I always wanted to get back to learning more on the Deep Learning side of things when possible. "Deep Learning" is the key word.</p><p>I haven't played Games after my college days.</p><p>Since the time I started my consulting venture, I end-up working either full-stack or some part of it depending on my consulting gig that I end-up signing for.</p><p>So when I wanted to purchase a laptop, I ended up ordering a <b>Gaming Laptop</b> with Intel -7 processor and RTX 2070 GPU, based on advice of <a href="https://blog.codonomics.com/2020/06/A%20Full%20Hardware%20Guide%20to%20Deep%20Learning" target="_blank">Tim Dettmers</a>. I know very many companies that procure a Gaming Laptop for their ML/DL engineers. Also, you will see almost all ML/DL web-sites advising its readers to go for Gaming Laptops.&nbsp;</p><p>I'm not used to settling down easy and in my quest to understand the world of hardware to see what marries what and solves what kind problems, I stumbled upon <b>Workstation Laptops</b>, and was left wondering how this is both similar to and different from Gaming Laptops.&nbsp;</p><p>The section below summarizes my understanding of the key differences between the two kinds of beasts.</p><h3>Gaming Vs Workstation Laptops</h3><p>I'd drawing a quick comparison table with the metrics that should help you decide the right pick for you.</p><div><table bordercolor="#888"><tbody><tr><td>&nbsp;<b>Metric<span>&nbsp;&nbsp; &nbsp;</span><span>&nbsp;</span></b></td><td><b>&nbsp;Gaming Laptop</b></td><td><b>Workstation Laptop&nbsp;</b></td><td><b>&nbsp;Comments</b></td></tr><tr><td>&nbsp;Cost</td><td>&nbsp;Cheaper<span>&nbsp;</span></td><td>&nbsp;Expensive</td><td>&nbsp;<span>&nbsp;What is your budget?</span><br></td></tr><tr><td>&nbsp;Built</td><td>&nbsp;Depends on brand and model</td><td>&nbsp;Relatively Sturdier. <br>&nbsp;Typically server/military grade with some certification like ISV to prove it.&nbsp;&nbsp;</td><td>&nbsp;One of the key reasons for price difference.&nbsp;</td></tr><tr><td>&nbsp;Portability</td><td>&nbsp;Relatively less portable because of its size, weight&nbsp;and/or fragility.</td><td>&nbsp;Better portability.&nbsp;</td><td>&nbsp;</td></tr><tr><td>&nbsp;Default Windows OS Type</td><td>&nbsp;Home edition<span>&nbsp;</span></td><td>&nbsp;Pro edition</td><td>&nbsp;You can always install your choice of OS later, though!</td></tr><tr><td>&nbsp;Looks</td><td>&nbsp;Usually more jazzy and less professional</td><td>&nbsp;Usually bland and professional</td><td>&nbsp;Looks do matter!</td></tr><tr><td>&nbsp;Longevity<span>&nbsp;</span></td><td>&nbsp;Comparatively lesser</td><td>&nbsp;Comparatively better</td><td>&nbsp;What is the ROI (bang for the bucks)?</td></tr><tr><td>&nbsp;Audio</td><td>&nbsp;Superior</td><td>&nbsp;Relatively inferior</td><td>&nbsp;</td></tr><tr><td>&nbsp;Display</td><td>&nbsp;Superior<br>&nbsp;The Refresh Rate is key differentiator for smooth AAA game play experience.</td><td>&nbsp;Inferior in terms of Refresh Rate.<br>&nbsp;Usually 60 FPS.</td><td>&nbsp;High refresh rate prevents screen tearing, stuttering, motion blur and ghosting.</td></tr><tr><td>&nbsp;Heat Dissipation</td><td>&nbsp;Better</td><td>&nbsp;Relatively poorer</td><td>&nbsp;</td></tr><tr><td>&nbsp;Control of hardwares</td><td>&nbsp;Depending on the brand and model, you can control/configure Fan speed, CPU under-volting, etc with the help of factory software that gets installed in your OS.</td><td>&nbsp;Absent!</td><td>&nbsp;</td></tr><tr><td>&nbsp;Nvidia GPUs</td><td>&nbsp;Typically comes with GTX or RTX GPUs.<br>&nbsp;(RTX is more performant than GTX.)</td><td>&nbsp; Typically comes with Quadro P series, T series and RTX series GPU processors.<br>&nbsp;(P &lt; T &lt; RTX in terms of performance)</td><td><ul><li>Nvidia Quadro P1000 is a mobile entry-level workstation graphics card for notebooks.&nbsp;</li><li>Nvidia Quadro T1000 for laptops is a professional mobile graphics card that is based on the Turing architecture (TU117 chip).</li><li>Nvidia Quadro RTX 5000 for laptops is a professional high-end graphics card for big and powerful laptops and mobile workstations.&nbsp;</li><li>ProTips: Buy atleast Quadro RTX 3000. Don't go for P/T series, if ML/DL is your primary purpose.</li><li>NVIDIA GeForce and AMD Radeon are graphics cards meant for gaming.</li></ul></td></tr><tr><td>&nbsp;Intel CPUs</td><td>&nbsp;Typically comes with i7 processors for AAA titled gamers play.</td><td>&nbsp;Typically comes with Intel XEON processors as base model these days</td><td>&nbsp;</td></tr><tr><td>&nbsp;ECC Memory</td><td>&nbsp;Not required and so is absent.</td><td>&nbsp;Required and thus present.</td><td><ul><li>Error-correcting code memory (ECC memory) is a type of computer data storage that can detect and correct the most-common kinds of internal data corruption. ECC memory is used in most computers where data corruption cannot be tolerated under any circumstances, such as for scientific or financial computing.</li><li>ProTip: For most gamers and general home office users, ECC RAM will not be worth the additional expense.&nbsp;</li></ul></td></tr></tbody></table><br></div><p>A Gaming Laptop can match your Workstation in performance with right specs. You Workstation Laptop cannot match the gaming and multi-media experience delivered by its Gaming Laptop counterpart. Also you pay more for the workstation models for its improved life-span and sturdier built that relieves you from handling with delicate care every single time.&nbsp;</p><p>If you are someone like me, you should go with Workstation laptop but can opt for Gaming laptop provided you understand the Cons of it.</p><p><b>Bonus :</b> The other things that you shouldn't miss irrespective of the laptop kind you buy, is the maximum years of warranty (preferably onsite) that the company provides and also include ADP cover for maximum number of years. This is an insurance that is often overlooked by buyers only to regret later.&nbsp;</p><p>Hope it serves you well to make an informed decision in your buying the right laptop.&nbsp;</p><h4>References</h4>

</div></div>]]>
            </description>
            <link>https://blog.codonomics.com/2020/06/workstation-laptop-versus-gaming-laptop.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23669441</guid>
            <pubDate>Sun, 28 Jun 2020 15:33:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Speeding up function calls with lru_cache in Python]]>
            </title>
            <description>
<![CDATA[
Score 122 | Comments 79 (<a href="https://news.ycombinator.com/item?id=23668914">thread link</a>) | @Immortal333
<br/>
June 28, 2020 | https://hackeregg.github.io/2020/06/03/Speeding-up-function-calls-with-just-one-line-in-Python.html | <a href="https://web.archive.org/web/*/https://hackeregg.github.io/2020/06/03/Speeding-up-function-calls-with-just-one-line-in-Python.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

      <section itemprop="text">
        
          
        
        <p>One line summary: Use <a href="https://docs.python.org/3/library/functools.html#functools.lru_cache">lru_cache decorator</a></p>

<h3 id="caching">Caching</h3>

<p>If we’re calling expensive functions in the program very frequently, It’s best to save the result of a function call and use it for future purposes rather than calling function every time. This will generally speed up the execution of the program.</p>
<blockquote>
  <p>The expensiveness of function can be in terms of computational (CPU usage) or latency (disk read, fetching a resource from the network).</p>
</blockquote>

<p>The saving result of function calls is generally referred to as caching. The naive way to do caching is to store every function calls. But, this doesn’t scale very well with the number of parameters of function and range of each parameter.</p>

<p>So, we need a smart way to do caching with a fixed amount of memory. And, there are plenty of <a href="https://en.wikipedia.org/wiki/Cache_replacement_policies">caching strategies available</a> depending upon what type of information is available to us.</p>

<blockquote>
  <p>Caching is heavily used in plenty of areas from low-level (hardware/CPU) to high level (network/CDNs).</p>
</blockquote>

<p>In most of the languages, We will choose caching strategies of our choice and implement them using a few data structures (hashmap, priority queue). Depending upon the language, It might take as little as few minutes to few hours to implement the generic solution of our need.</p>

<p>But, Python’s standard library <a href="https://docs.python.org/3/library/functools.html">functools</a> already comes with one strategy of caching called <a href="https://docs.python.org/3/library/functools.html#functools.lru_cache">LRU(Least Recently Used)</a>. Thanks to <a href="https://wiki.python.org/moin/PythonDecorators">decorators</a> in python, It only takes one line to integrate into the existing codebase</p>

<h3 id="basic-recursive-implementation-of-fibonacci-numbers">Basic Recursive Implementation of <a href="https://en.wikipedia.org/wiki/Fibonacci_number">Fibonacci numbers</a></h3>

<div><div><pre><code><span>import</span> <span>time</span> <span>as</span> <span>tt</span>

<span>def</span> <span>fib</span><span>(</span><span>n</span><span>):</span>
  <span>if</span> <span>n</span> <span>&lt;=</span> <span>1</span><span>:</span>
    <span>return</span> <span>n</span>
  <span>return</span> <span>fib</span><span>(</span><span>n</span><span>-</span><span>1</span><span>)</span> <span>+</span> <span>fib</span><span>(</span><span>n</span><span>-</span><span>2</span><span>)</span>

<span>t1</span> <span>=</span> <span>tt</span><span>.</span><span>time</span><span>()</span>
<span>fib</span><span>(</span><span>30</span><span>)</span>
<span>print</span> <span>(</span><span>f"Time taken: </span><span>{</span><span>tt</span><span>.</span><span>time</span><span>()</span> <span>-</span> <span>t1</span><span>}</span><span>"</span><span>)</span>

<span># Output : 
# Time taken: 0.3209421634674072
</span></code></pre></div></div>

<h3 id="speeding-up-recursive-implementation-with-lru">Speeding Up Recursive Implementation with LRU</h3>
<div><div><pre><code><span>import</span> <span>time</span> <span>as</span> <span>tt</span>
<span>import</span> <span>functools</span>

<span># saving all function calls
</span><span>@</span><span>functools</span><span>.</span><span>lru_cache</span><span>(</span><span>maxsize</span><span>=</span><span>31</span><span>)</span>
<span>def</span> <span>fib</span><span>(</span><span>n</span><span>):</span>
  <span>if</span> <span>n</span> <span>&lt;=</span> <span>1</span><span>:</span>
    <span>return</span> <span>n</span>
  <span>return</span> <span>fib</span><span>(</span><span>n</span><span>-</span><span>1</span><span>)</span> <span>+</span> <span>fib</span><span>(</span><span>n</span><span>-</span><span>2</span><span>)</span>

<span>t1</span> <span>=</span> <span>tt</span><span>.</span><span>time</span><span>()</span>
<span>fib</span><span>(</span><span>30</span><span>)</span>
<span>print</span> <span>(</span><span>f"Time taken: </span><span>{</span><span>tt</span><span>.</span><span>time</span><span>()</span> <span>-</span> <span>t1</span><span>}</span><span>"</span><span>)</span>
<span>print</span> <span>(</span><span>fib</span><span>.</span><span>cache_info</span><span>())</span>


<span># Output :
# Time taken: 1.7881393432617188e-05
# CacheInfo(hits=28, misses=31, maxsize=31, currsize=31)
</span></code></pre></div></div>

<p>In this example, we have saved all function calls. But, We know that Fibonacci can be implemented using <a href="https://en.wikipedia.org/wiki/Dynamic_programming">DP</a>.</p>

<h3 id="iterative-implementation-of-fibonacci">Iterative implementation of Fibonacci</h3>

<div><div><pre><code><span>import</span> <span>time</span> <span>as</span> <span>tt</span>

<span>def</span> <span>fib_iterative</span><span>(</span><span>n</span><span>):</span>
  <span>if</span> <span>n</span> <span>&lt;=</span> <span>1</span><span>:</span>
    <span>return</span> <span>n</span>
  <span>f</span><span>,</span> <span>s</span> <span>=</span> <span>0</span><span>,</span> <span>1</span>
  <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>n</span><span>-</span><span>1</span><span>):</span>
    <span>t</span> <span>=</span> <span>f</span> <span>+</span> <span>s</span>
    <span>f</span><span>,</span> <span>s</span> <span>=</span> <span>s</span><span>,</span> <span>t</span>
  <span>return</span> <span>t</span>

<span>t1</span> <span>=</span> <span>tt</span><span>.</span><span>time</span><span>()</span>
<span>fib_iterative</span><span>(</span><span>30</span><span>)</span>
<span>print</span> <span>(</span><span>f"Time taken: </span><span>{</span><span>tt</span><span>.</span><span>time</span><span>()</span> <span>-</span> <span>t1</span><span>}</span><span>"</span><span>)</span>

<span># Output:
# Time taken: 5.0067901611328125e-06
</span></code></pre></div></div>

<h3 id="different-cache-size">Different Cache size</h3>

<div><div><pre><code><span>import</span> <span>time</span> <span>as</span> <span>tt</span>
<span>import</span> <span>functools</span>

<span>def</span> <span>lru_size</span><span>(</span><span>max_lru</span><span>):</span>
    <span>@</span><span>functools</span><span>.</span><span>lru_cache</span><span>(</span><span>maxsize</span><span>=</span><span>max_lru</span><span>,</span> <span>typed</span><span>=</span><span>False</span><span>)</span>
    <span>def</span> <span>fib_lru</span><span>(</span><span>n</span><span>):</span>
        <span>if</span> <span>n</span> <span>&lt;=</span> <span>1</span><span>:</span>
            <span>return</span> <span>n</span>
        <span>return</span> <span>fib_lru</span><span>(</span><span>n</span><span>-</span><span>1</span><span>)</span> <span>+</span> <span>fib_lru</span><span>(</span><span>n</span><span>-</span><span>2</span><span>)</span>
    <span>return</span> <span>fib_lru</span>

<span>for</span> <span>i</span> <span>in</span> <span>[</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>5</span><span>,</span> <span>10</span><span>,</span> <span>31</span><span>]:</span>
    <span>t1</span> <span>=</span> <span>tt</span><span>.</span><span>time</span><span>()</span>
    <span>fib</span> <span>=</span> <span>lru_size</span><span>(</span><span>i</span><span>)</span>
    <span>fib</span><span>(</span><span>10</span><span>)</span>
    <span>print</span> <span>(</span><span>f"LRU size: </span><span>{</span><span>i</span><span>}</span><span> Time taken: </span><span>{</span><span>tt</span><span>.</span><span>time</span><span>()</span> <span>-</span> <span>t1</span><span>}</span><span>"</span><span>)</span>
    <span>print</span> <span>(</span><span>fib</span><span>.</span><span>cache_info</span><span>())</span>

<span># Output:
# LRU size: 1 Time taken: 0.6930997371673584
# CacheInfo(hits=0, misses=2692537, maxsize=1, currsize=1)
# LRU size: 2 Time taken: 0.012731075286865234
# CacheInfo(hits=8656, misses=41641, maxsize=2, currsize=2)
# LRU size: 5 Time taken: 5.817413330078125e-05
# CacheInfo(hits=28, misses=31, maxsize=5, currsize=5)
# LRU size: 10 Time taken: 3.9577484130859375e-05
# CacheInfo(hits=28, misses=31, maxsize=10, currsize=10)
# LRU size: 31 Time taken: 3.504753112792969e-05
# CacheInfo(hits=28, misses=31, maxsize=31, currsize=31)
</span></code></pre></div></div>

<p>As, <strong>we can see the optimal cache size of fib function is 5</strong>. Increasing cache size will not result in much gain in terms of speedup.</p>

<h3 id="important-note">Important Note</h3>

<p>I strictly suggest to use lru decorator in only deterministic functions.</p>

<h4 id="deterministic-functions">Deterministic Functions</h4>
<blockquote>
  <p>In computer science, a deterministic algorithm is an algorithm which, given a particular input, will always produce the same output, with the underlying machine always passing through the same sequence of states. Deterministic algorithms are by far the most studied and familiar kind of algorithm, as well as one of the most practical, since they can be run on real machines efficiently.</p>

  <p>– Wikipedia</p>
</blockquote>

<p>Because,</p>

<blockquote>
  <p>There are only two hard things in Computer Science: cache invalidation and naming things.</p>

  <p>– Phil Karlton</p>
</blockquote>

        
      </section>

      

      


      
  

    </div></div>]]>
            </description>
            <link>https://hackeregg.github.io/2020/06/03/Speeding-up-function-calls-with-just-one-line-in-Python.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23668914</guid>
            <pubDate>Sun, 28 Jun 2020 14:29:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Promnesia – an attempt to fix broken web history]]>
            </title>
            <description>
<![CDATA[
Score 212 | Comments 52 (<a href="https://news.ycombinator.com/item?id=23668507">thread link</a>) | @karlicoss
<br/>
June 28, 2020 | https://beepb00p.xyz/promnesia.html | <a href="https://web.archive.org/web/*/https://beepb00p.xyz/promnesia.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    
    <section>
    
    <p>A journey in fixing browser history
    </p></section>
    <!-- are sections appropriate for that? -->

    <section>
    <p>
Promnesia is a browser extension (Chrome/Firefox/Firefox mobile) that serves as a web surfing copilot
by enhancing your browsing history, improving your web exploration experience, and integrating with your knowledge base.
</p>
<p>
<a href="https://github.com/karlicoss/promnesia#readme">The repository</a> contains more information about the project and the setup guide, this post is more about the motivation and the story of what led me to work on it.
</p>
<p>
Also, you can quickly skim through the <a href="https://github.com/karlicoss/promnesia#demos">demos</a> first before reading, if you prefer!
</p>

<div>
<h2 id="singularity_when"><a href="#singularity_when">¶</a><span>1</span> I want my singularity!</h2>
<div id="text-singularity_when">
<p>
I was raised on science fiction and grew up dreaming about technology drastically changing our lives.
Artificial intelligence, augmenting the brain with a math co-processor, head-up displays, neural interfaces, having perfect reaction and memory – many of you are on the same page and know the drill.
</p>
<p>
Years passed, I became a software engineer, and realized just how far we are from all these fancy technologies I wanted.
So my aspirations have become more modest, and I've chosen a more realistic and plausible target:
using my digital trace (such as browser history, webpage annotations and my <a href="https://beepb00p.xyz/tags.html#exobrain">personal wiki</a>) to make up for my limited memory.
</p>
<p>
I'm exploring lots of information on the Internet, and it feels wasteful to use my <a href="https://beepb00p.xyz/tags.html#meatsack">meat resources</a> to keep track of it.
Meanwhile, web browsers keep a record automatically, without any manual and conscious effort.
Surely we can benefit from the immense computing power and memory capabilities of computers?
</p>
<p>
So I figured that I wanted:
</p>
</div>
</div>
<div>
<h2 id="what_i_want"><a href="#what_i_want">¶</a><span>2</span> Ok, maybe a web assistant at least?</h2>
<div id="text-what_i_want">
<p>
A web surfing companion. A copilot.
A <a href="https://en.wikipedia.org/wiki/Memex">Memex</a>.
A <a href="http://alumni.media.mit.edu/~rhodes/Papers/remembrance.html">Remembrance Agent</a>?
</p>
<p>
Call it whatever you like, I <i>wish</i> it were a concept with a widely accepted name. Something that will sit in my browser and:
</p>
<ul>
<li><p>
aid me with <b>information processing</b>
</p>
<p>
Keep track of what I've read, when, on which device, and for how long.
</p></li>
<li><p>
show me my <b>annotations and highlights</b>, within the original page
</p>
<p>
I don't want to keep wondering whether I have my notes and thoughts stashed in some app, I want the computer to let me know instead.
</p></li>
<li><p>
unify my <b>scattered and siloed bookmarks</b>
</p>
<p>
Firefox bookmarks; Reddit/Hackernews saves; "Watch later" on Youtube, saved links in my instant messenger.
</p>
<p>
These are the same damn thing, yet there is no way to oversee and process them through a single interface.
</p>
<p>
<a href="https://jborichevskiy.com/posts/digital-tools/#queue-management-for-inbound-digital-content">"Queue management for inbound digital content"</a>:
a post expanding further on this idea.
</p></li>
<li><p>
connect with my online presence: chats and social networks
</p>
<p>
If I tweeted about a page, surely this should be somehow recorded in the browsing history?
</p>
<p>
In fact, the page that I bothered to tweet about is <b>much</b> more important than a page I merely visited in the browser.
</p></li>
<li><p>
help me explore new information and <b>prioritize</b> it
</p>
<p>
There is so much awesome stuff on the Internet! The biggest problem I have is picking the next cool link to dig into.
</p>
<p>
Imagine if in one click, I could see which of my friends, or the people I follow have read a certain link.
What did they think? Have they posted about it, annotated, or something else? Do they follow the author, perhaps I should too?
</p></li>
<li><p>
bridge the gap between the browser and my <a href="https://beepb00p.xyz/tags.html#exobrain">personal wiki</a>
</p>
<p>
Whatever product I choose for managing my notes: Google Keep, Evernote, Roam Research, or even org-mode files on my disk,
they always end up <b>isolated and disconnected</b> from my web browsing.
</p></li>
</ul>
<p>
I searched for a system like this <a href="https://twitter.com/karlicoss/status/767412935316611072">for</a> several <a href="https://twitter.com/karlicoss/status/896313846159298560">years</a>.
</p>
<p>
After enough failed attempts at finding an <a href="#prior_art">existing solution</a>, I figured it was going to be yet another thing I'd have to implement myself.
</p>
<p>
The journey of building it took longer than I expected, led me through a rabbit hole of <a href="https://beepb00p.xyz/tags.html#dataliberation">data liberation</a>, lots of <a href="https://en.wiktionary.org/wiki/yak_shaving">yak shaving</a>,
and made me realize: <b>browser history is very, very broken</b>.
</p>
<p>
Note: the next two sections are (somewhat technical) rants. If you prefer a more positive/less boring agenda, feel free to skip them straight to <a href="#prior_art">"Existing solutions"</a>
, and you can return back later if you feel like it.
</p>
</div>
</div>
<div>
<h2 id="history_broken"><a href="#history_broken">¶</a><span>3</span> Browser history is broken</h2>
<div id="text-history_broken">
<p>
To a large extent, URLs express <b>relationships and hierarchy</b> between the bits of information. For example:  <code>blog &lt;-&gt; post &lt;-&gt; comment</code>, <code>person &lt;-&gt; tweet</code>, <code>playlist &lt;-&gt; video</code>.
</p>
<p>
With this information you should be easily able to find everything relevant to the current page and trace your jumps through past websites.
Merely by looking at URLs, without "AI" or some dubious machine learning algorithm!
Seems like a low hanging fruit to harvest, right?
</p>
<p>
Web browser history is a rich source of potentially useful information.
Just think about it: it's zero effort <a href="https://beepb00p.xyz/tags.html#lifelogging">lifelogging</a>.
It contains exact timestamps and links which <i>basically</i> address information.
</p>
<p>
Now think about the experience you actually have. What was the last time you used the browser history in any nontrivial way, for something other than reopening an accidentally closed tab?
</p>
<p>
Besides:
</p>
</div>
<div>
<h3 id="not_just_browser"><a href="#not_just_browser">¶</a>it's not just about web browsers</h3>
<div id="text-not_just_browser">
<div><p><span>
When you're using a native phone app (say, for Reddit or Twitter), your history either isn't logged anywhere or if it is, it's only stored locally on your phone.

</span></p></div>
<div><p><span>
On Android, it's likely to be in an Sqlite database in <code>/data/data/app.name</code>.
This directory is not accessible to normal users <b>unless your phone is rooted</b>.
Just think about how ridiculous this is. It's <b>your own data</b>, yet your OS babysits you, preventing access to it.

And yes, I know sandboxing and security are important, but locking my data inside the app is hardly an acceptable tradeoff.
</span></p></div>
<p>
As a specific example, the <a href="https://github.com/ccrama/Slide">Reddit Slide</a> app keeps your view history in <code>/data/data/me.ccrama.redditslide/SEEN</code>.
Okay, say you root your phone and access the database. Turns out the the app isn't persisting the data forever, it's merely keeping a few weeks' cache.
And I can hardly blame the developer for this: because of the data model, no one expects regular users to access this database.
</p>
<p>
So if you want your complete history, you have to backup this database regularly, keep the snapshots and <a href="https://beepb00p.xyz/exports.html#synthetic">somehow</a>
reconstruct it.
</p>
<p>
You may dismiss this as nitpicking and obsession over every last bit of my data.
But when <b>all</b> of your phone apps are doing this you're missing out on quite a lot of useful information.
</p>
</div>
</div>
<div>
<h3 id="siloed"><a href="#siloed">¶</a>it's scattered and siloed</h3>
<div id="text-siloed">
<p>
Building on the previous point:
</p>
<ul>
<li>for the most part, you can't access history in your phone apps</li>
<li>lots of data which <i>ought</i> to be counted as web history is scattered across silos

<ul>
<li><div><p><span>in the cloud: behind APIs (best case), GDPR and manual exports (worst case)

It is never easy to get hands on, <i>even</i> if you're an experienced software engineer.</span></p></div></li>
<li><p>
on the filesystem, for example in markdown/org-mode files
</p>
<p>
A slightly better scenario, but as far as the web browser is concerned, it doesn't make any difference.
</p></li>
</ul></li>
</ul>
<p>
Even <i>regular</i> browser history is not easy to get:
</p>
<ul>
<li>Firefox <a href="https://support.mozilla.org/en-US/questions/1080942">used to</a> silently 'expire' your browser history</li>
<li><p>
Chrome deletes history older than <a href="https://superuser.com/a/364475/300795">90 days</a>
</p>
<p>
The only way to access older history I'm aware of is <a href="https://myactivity.google.com/">Google Activity</a> and Takeout.
</p></li>
<li>Google Takeout <a href="https://beepb00p.xyz/takeout-data-gone.html">quietly recycles your history</a></li>
<li><p>
Migration is limited to the most popular browsers
</p>
<p>
The retention limits the migration as well.
E.g. if you migrate from Chrome to Firefox, history older than 90 days is locked and siloed in your Google Account.
</p></li>
<li><p>
You're going to have a hard time if you're not using Google/Mozilla sync
</p>
<p>
Your history will be scattered across devices and lost on OS reinstalls.
</p>
<p>
There are ways of self-hosting Firefox sync, and (<a href="https://superuser.com/questions/614744/how-to-set-up-a-own-chrome-sync-server">allegedly</a>) even Chrome sync,
but as you can imagine, is quite tedious.
</p></li>
</ul>
</div>
</div>
<div>
<h3 id="significance"><a href="#significance">¶</a>it's got varying significance</h3>
<div id="text-significance">
<p>
Not all links in your history are equally important:
</p>
<ul>
<li>some are clicked on by accident</li>
<li>some you've just skimmed</li>
<li>some are on your reading list</li>
<li>some you've been reading for hours and are full of your highlights and annotations</li>
<li>some you reference in your knowledge base/personal wiki</li>
<li>some of them you've shared with others on social media</li>
</ul>
<p>
The current browser history experience makes no distinction between these scenarios.
</p>
</div>
</div>
</div>
<div>
<h2 id="urls_broken"><a href="#urls_broken">¶</a><span>4</span> URLs are broken</h2>
<div id="text-urls_broken">
<p>
This topic probably deserves a separate post, but I'll keep it section-sized for now.
</p>
<p>
URLs might seem great because they mostly address content and are semi-descriptive: people <i>try</i> to keep URLs somewhat reasonable, tidy and working.
But in the real world:
</p>
<ul>
<li><p>
links <b>rot</b>
</p>
<p>
Many URLs are <a href="https://www.gwern.net/Archiving-URLs#link-rot"><b>literally</b> broken</a>.
We're lucky to have <a href="https://web.archive.org/">archive.org</a>, so you can at least access dead pages.
</p>
<p>
But there is no way to migrate your browser history, e.g. point old URLs to their respective archive.org entries or a new domain.
Similarly if you had the page annotated, your annotations become orphans without an easy way to relink them.
</p></li>
<li><p>
links are <b>obfuscated</b> by shortening and redirects
</p>
<div><p><span>
What happens to all the <code>t.co</code> links when Twitter as a service dies?

</span></p></div></li>
<li><p>
links are <b>obscured</b>
</p>
<p>
There is no easy way to know what's behind <code>https://www.instapaper.com/read/1265139707</code> without querying the Instapaper API.
</p>
<p>
Relations between data are often obscured as well. For example:
</p>
<ul>
<li><code>https://news.ycombinator.com/item?id=22918980</code> is a submission link</li>
<li><code>https://news.ycombinator.com/item?id=22919718</code> is a comment to that submission</li>
</ul>
<p>
These links are clearly related, but there is no way to tell it just from <samp>id</samp>.
</p>
<p>
Compare this to Reddit links:
</p>
<ul>
<li><code>https://reddit.com/r/orgmode/comments/g6ejwe/is_there_an_orgmode_workbook_tutorial_that_is</code> is a post link</li>
<li><code>https://reddit.com/r/orgmode/comments/g6ejwe/is_there_an_orgmode_workbook_tutorial_that_is/fo9qnen</code> is a comment to that post</li>
</ul>
<p>
The ids are obscure, but at least we can clearly see the <code>post &lt;-&gt; comment</code> relation merely by looking at the URLs.
Alas, browsers are just ignoring this useful information.
</p></li>
<li><p>
links are <b>unstandardized</b>
</p>
<p>
For example, <a href="https://en.wikipedia.org/wiki/Query_string">queries</a>
</p>
<ul>
<li>typically don't point to anything persistent and are used for querying (duh)</li>
<li>but other times they are used to address information: <code>http://wiki.c2.com/?LispLanguage</code> or <code>https://www.scottaaronson.com/blog/?p=2694</code></li>
<li>and in many cases are utter garbage used for <a href="https://en.wikipedia.org/wiki/Query_string#Tracking">tracking</a></li>
</ul>
<p>
The worst part is that these use cases overlap. For example, take a look at <code>youtube.com/watch?v=wHrCkyoe72U&amp;feature=share&amp;t…</code></p></li></ul></div></div></section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://beepb00p.xyz/promnesia.html">https://beepb00p.xyz/promnesia.html</a></em></p>]]>
            </description>
            <link>https://beepb00p.xyz/promnesia.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23668507</guid>
            <pubDate>Sun, 28 Jun 2020 13:18:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Producing a deepfake – a faceswap workflow on AWS]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23668404">thread link</a>) | @botoxparty
<br/>
June 28, 2020 | https://adamham.dev/posts/producing-a-deepfake-on-aws/ | <a href="https://web.archive.org/web/*/https://adamham.dev/posts/producing-a-deepfake-on-aws/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>For a music video project I worked on we had to produce a deep fake. I had previously made some attempts at deepfakes using a local machine with an NVIDIA GeForce GTX 1080. Now I'll be using a MacBook Pro and an AWS account with a generous credit (the running cost of the server only ended up being about $30 per 24 hours).</p>
<p>If you want to understand more about how machine learning works I would recommend <a href="https://www.youtube.com/watch?v=R9OHn5ZF4Uo">this video</a>.</p>
<h2>Setting up</h2>
<p>The first thing was to choose a library, the two main players in the open-source deepfake space are <a href="https://github.com/deepfakes/faceswap">Faceswap</a> and <a href="https://github.com/iperov/DeepFaceLab">DeepFaceLab</a>. I chose to go with Faceswap because the GUI and the CLI seemed more user-friendly to me, it supports multiple GPUs, has a solid workflow and great community and support.</p>
<p>I had originally planned to do the inital tests on my local machine but my MacBook Pro has an ATI graphics card 🥺. So straight to the cloud I go... I used a <a href="https://aws.amazon.com/ec2/instance-types/g4/">g4dn.xlarge EC2 instance</a> and loaded it with the <a href="https://aws.amazon.com/machine-learning/amis/">AWS Deep Learning AMI</a>. After wrestling with the <a href="https://github.com/deepfakes/faceswap/blob/master/INSTALL.md">installation of faceswap</a> (had some dependancy issues that may have been related to using the deep learning AMI) I managed to get it up and running on the remote instance.</p>
<h3>Preliminary tests</h3>
<p>To start we did a test run first to see what kind of results we could get using mostly default settings and with minimal intervention, just to get an idea of what was really possible with our material. For this I used the same footage for Face A from the target video that I wanted to convert, and for Face B I recorded 60 seconds of the subject performing basic facial movements from different angles.</p>
<p>From the preliminary results I could identify what the parameters that I was working within were. I noticed that a lot of my faces are a profile view, deepfakes work much better with a frontal view. Also my source material is a very low resolution (480p YouTube rip of an 80s video). This makes faces harder to detect, particularly smaller faces.</p>
<p>I would highly suggest doing a few tests before fully training your model. It'll also help you to tell which angles and expressions are lacking from your source footage.</p>
<h3>Project structure</h3>
<p>My initial tests also encouraged me to define a folder structure, I found this to be an efficient structure for deepfake projects</p>

        <deckgo-highlight-code>
          <code slot="code">/my-project
/my-project/src
/my-project/src/faceA/              // - Source footage/images for Face A
/my-project/src/faceB/              // - "                       " Face B
/my-project/src/target/             // - Footage to convert
/my-project/extract/faceA           // - Extracted faces from Face A
/my-project/extract/faceB           // - "                  " Face B
/my-project/model/                  // - Trained model
/my-project/output/                 // - Converted media (final exports)</code>
        </deckgo-highlight-code>
      
<h2>1. Extract</h2>
<h3>Face A - 6586 faces extracted</h3>
<p>I used 3 video clips of Robin Gibb that I could find from that era and cut out the footage that was worth extracting.</p>
<p><a href="https://www.youtube.com/watch?v=A-U058BIAGo">https://www.youtube.com/watch?v=A-U058BIAGo</a> <strong>(This is also the target video)</strong></p>
<p><a href="https://www.youtube.com/watch?v=oMvRLLPd8Ak">https://www.youtube.com/watch?v=oMvRLLPd8Ak</a></p>
<p><a href="https://www.youtube.com/watch?v=W_Nykcs7Zhg">https://www.youtube.com/watch?v=W_Nykcs7Zhg</a></p>
<h3>Face B - 7382 faces extracted</h3>
<p>I recorded 5 minutes of footage of the subject replicating the facial movements from the target source.</p>
<p>To prepare the extracted faces for training they need to be cleaned up. The better your source material is the better your result will be. This part of the process took about 10 hours.</p>
<ul>
<li>Remove any extracted faces that are of poor quality</li>
<li>Remove any bad detected faces</li>
<li>Regenerate alignments file to remove the deleted faces</li>
<li>Manually go through each face and clean up the alignment</li>
<li>Generate new masks</li>
</ul>
<p>After extracting the faces to use for training I cleaned and sorted the faces to remove any poor quality faces or things that were detected by error. Faceswap actually has a tool to allow you to sort the extracted faces by relevance to help you filter them out. After deleting the bad faces you'll also need to remove them from your alignments file using the alignments tool.</p>
<h2>2. Train</h2>
<p>There are a few different types of models you can train it all depends on what material you have and the results you want to achieve. I had time and computing power on my side so I decided to launch 3 instances and train variations of models to 20,000 iterations and then select the best one from there. I chose to go with Dfaker using a VCC-Clear mask.</p>
<p>Note: I made an error and accidentally deleted the full timelapse permanently but I have a few captures here for demo purposes. The final model was much more defined than shown in this timelapse.</p>
<p>My final model was trained for 75,000 iterations. I started it again and ran it for another 10,000 where I could see that the loss level was not improving, therefore the model was no longer learning and I could conclude that my model was trained.</p>
<p><img src="https://adamham.dev/posts/producing-a-deepfake-on-aws/training.gif" alt="Timelapse of model being trained in faceswap"></p>
<h2>3. Convert</h2>
<p>To prepare the target footage to be converted we need to repeat step 1 (extract) again being as meticulous as possible with the alignments. I spent about 4 hours on ~4,100 frames to achieve my result.</p>
<p>I definitely ran into difficulties with the face detection because of the low resolution of my source footage.</p>
<h2>Result</h2>
<h3>Converted Video</h3>
<p> <iframe src="https://www.youtube.com/embed/Sqc8EvnyyBM?rel=0&amp;showinfo=0" allowfullscreen=""></iframe>  </p>
<h3>Original Video</h3>
<p> <iframe src="https://www.youtube.com/embed/A-U058BIAGo?rel=0&amp;showinfo=0" allowfullscreen=""></iframe>  </p>
<h2>Final thoughts</h2>
<p>The abilities of the technology is really hyped up in the media. To achieve an undetectable result you really do need source footage that fits into the parameters of what a deepfake can work with.</p>
<p>For this project the aim wasn't to have a perfectly undetectable deepfake, the limitations weren't a problem but infact contributed to the concept. The song is a cover and seeing artifacts from the deepfake reinforces this idea.</p>
<p>The cost of processing the deepfake on AWS comes at about $30 per day. If you were doing a couple of renders a year then it's an amazing option rather than using your own hardware. However, things like manual alignments are really tricky using a remote machine so ideally you would want to have a CUDA capable graphics card in your local. A dedicated graphics machine with comparable specs would start at about $1400 (about 46 days of AWS EC2 usage) plus electricity bills.</p></div></div>]]>
            </description>
            <link>https://adamham.dev/posts/producing-a-deepfake-on-aws/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23668404</guid>
            <pubDate>Sun, 28 Jun 2020 12:55:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Controversies and Challenges in fMRI (2018)]]>
            </title>
            <description>
<![CDATA[
Score 35 | Comments 10 (<a href="https://news.ycombinator.com/item?id=23668279">thread link</a>) | @saadalem
<br/>
June 28, 2020 | http://www.thebrainblog.org/2018/12/23/twenty-six-controversies-and-challenges-in-fmri/ | <a href="https://web.archive.org/web/*/http://www.thebrainblog.org/2018/12/23/twenty-six-controversies-and-challenges-in-fmri/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-294">
	<!-- .entry-header -->

	
	
	<div>
		<h2><em><strong>•Neurovascular Coupling</strong></em><em><strong>•Draining Veins</strong></em><em><strong>•Linearity</strong></em><em><strong>•Pre-undershoot</strong></em><em><strong>•Post-undershoot</strong></em><em><strong>•Long duration</strong></em><em><strong>•Mental Chronometry</strong></em><em><strong>•Negative Signal Changes</strong></em><em><strong>•Resting state source</strong></em><em><strong>•Dead fish activation</strong></em><em><strong>•Voodoo correlations</strong></em><em><strong>•Global signal regression</strong></em><em><strong>•Motion artifacts</strong></em><em><strong>•The decoding signal</strong></em><em><strong>•non-neuronal BOLD</strong></em><em><strong>•relationship to other measures</strong></em><em><strong>•contrast: spin-echo vs gradient-echo</strong></em><em><strong>•contrast: SEEP contrast</strong></em><em><strong>•contrast: diffusion changes</strong></em><em><strong>•contrast: neuronal currents</strong></em><em><strong>•contrast: NMR phase imaging</strong></em><em><strong>•lie detection</strong></em><em><strong>•correlation ≠ connection</strong></em><em><strong>•clustering conundrum</strong></em><em><strong>•reproducibility</strong></em><em><strong>•dynamic connectivity changes</strong></em></h2>
<hr>
<h4><em><strong>This will be a chapter in my upcoming book “Functional MRI” </strong><strong>in the MIT Press Essential Knowledge Series&nbsp;</strong></em></h4>
<hr>
<p>Functional MRI is unique in that, in spite of being almost 30 years old as a method, it continues to progress in terms of sophistication of acquisition, hardware, processing, in our understanding of the signal itself. There has been no plateau in any of these areas. In fact, by looking at the literature, one gets the impression that this advancement is accelerating. Every new advance opens the potential range where it might have an impact, allowing new questions about the brain to be addressed.</p>
<p>In spite of its success – perhaps as a result of its success – it has had its share of controversies coincident with methods advancements, new observations, and novel applications. Some controversies have been more contentious than others. Over the years, I’ve been following these controversies and have at times performed research to resolve them or at least better understand them. A good controversy can help to move the field forward as it can focus and motivate groups of people to work on the issue itself, shedding a broader light on the field as these are overcome.</p>
<p>While a few of the controversies or issues of contention have been fully resolved, most remain to some degree unresolved. Understanding fMRI through its controversies allows a deeper appreciation for how the field advances as a whole – and how science really works – the false starts, the corrections, and the various claims made by those with potentially useful pulse sequences, processing methods, or applications. Below is the list of twenty-six major controversies in fMRI – in approximately chronological order.</p>
<h2>#1: The Neurovascular coupling debate.</h2>
<p>Since the late 1800’s, the general consensus, hypothesized by Roy and Sherrington in 1890 (1), was that activation-induced cerebral flow changes were driven by local changes in metabolic demand. In 1986, a publication by Fox et al. (2)challenged that view, demonstrating that with activation, localized blood flow seemingly increased beyond oxidative metabolic demand, suggesting an “uncoupling” of the hemodynamic response from metabolic demand during activation. Many, including Louis Sokolof, a well-established neurophysiologist at the National Institutes of Health, strongly debated the results. Fox nicely describes this period in history from his perspective in “The coupling controversy” (3).</p>
<p>I remember well, in the early days of fMRI, Dr. Sokolof standing up from the audience to debate Fox on several circumstances, arguing that the flow response should match the metabolic need and there should be no change in oxygenation. He argued that what we are seeing in fMRI is something other than an oxygenation change.</p>
<p>In the pre-fMRI days, I recall not knowing what direction the signal should go – as when I first laid eyes on the impactful video presented by Tom Brady during his plenary lecture on the future of MRI at the Society for Magnetic Resonance (SMR) Meeting in August of 1991, it was not clear from these time series movies of subtracted images the direction he performed the subtraction operation. Was it task minus rest or rest minus task? Did the signal go up or down with activation? I also remember very well, analyzing my first fMRI experiments, expecting to see a decrease in BOLD signal – as Ogawa, in an earlier paper(4), hypothesized that metabolic rate increases would lead to a decrease blood oxygenation thus a darkening of the BOLD signal during brain activation. Instead, all I saw were signal increases. It was Fox’s work that helped me to understand why the BOLD signal should <em>increase</em>with activation. Flow goes up and oxygen delivery exceeds metabolic need, leading to an increase in blood oxygenation.</p>
<p>While models of neurovascular coupling have improved, we still do not understand the precise need for flow increases. First, we had the “watering the whole garden to feed one thirsty flower” hypothesis which suggested that flow increases matched metabolic need for one area but since vascular control was coarse, the abundant oxygenation was delivered to a wider area than was needed, causing the increase in oxygenation. We also had the “diffusion limited” model, where it was hypothesized that in order to deliver enough oxygen to the furthest neurons from the oxygen supplying vessels, an overabundance of oxygen was needed at the vessel itself since the decrease of oxygen as it diffused from the vessel to the furthest cell was described as an exponential. &nbsp;This theory has fallen a bit from favor as the increases in CMRO<sub>2</sub>or the degree to which the diffusion of oxygen to tissue from blood is limited tend to be higher than physiologic measures. The alternative to the metabolic need hypothesis involves neurogenic “feed-forward” hypotheses – which still doesn’t get at the “why” of the flow response.</p>
<p>Currently, this is where the field stands. We know that the flow response is robust and consistent. We know that in active areas, oxygenation in healthy brains always increases, however we just don’t understand specifically why it’s necessary. Is it a neurogenic, metabolic, or some other mechanism to satisfy some evolutionary critical need that extends beyond simple need for more oxygen? We are still figuring that out. Nevertheless, it can be said that whatever the reason for this increase in flow, it is fundamentally important, as the BOLD response is stunningly consistent.</p>
<h2>#2: The Draining Vein Effect</h2>
<p>The question: “what about the draining veins?” I think was first posited at an early fMRI conference by Kamil Ugurbil of the University of Minnesota. Here and for the next several years he alerted the community to the observation that, especially at low field, draining veins are a problem as they smear and distort the fMRI signal change such that it’s hard to know specifically where the underlying neuronal activation is with a high degree of certainty. In the “20 years of fMRI: the science and the stories” special issue of NeuroImage, Ravi Menon writes a thorough narrative of the “Great brain vs vein” debate (5). &nbsp;When the first fMRI papers were published, only one, by Ogawa et al. (6), was at high field – 4 Tesla – and relatively high resolution. In Ogawa’s paper, it was shown that there was a differentiation between veins (very hot spots) and capillaries (more diffuse weaker activation in grey matter). Ravi followed this up with another paper (7)using multi-echo imaging, to show that blood in veins had an intrinsically shorter T2* decay than gray matter at 4T and appeared as dark dots in T2* weighted structural images yet appeared as bright functional hot spots in the 4T functional images. Because of the low SNR and CNR at 1.5T, allowing only the strongest BOLD effects to be seen, and because models suggested that at low field strengths, large vessels contributed the most to the signal, the field worried that all fMRI was looking at was veins – at least at 1.5T.</p>
<p>The problem of large vein effects is prevalent using standard gradient-echo EPI – even at high fields. Simply put, the BOLD signal is directly proportional to the venous blood volume contribution in each voxel. If the venous blood volume is high – as with the case of a vein filling a voxel – then the potential for high BOLD changes is high if there is a blood oxygenation change in the area. At high field, indeed, there is not much intravascular signal left in T2* weighted Gradient-echo sequences, however, the extravascular effect of large vessels still exists.&nbsp; Spin-echo sequences (sensitive to small compartments) still are sensitive to the susceptibility effects around intravascular red blood cells within large vessels – even at 7T where intravascular contribution is reduced. Even with some vein sensitivity, promising high resolution orientation column results have been produced at 7T using gradient-echo and spin-echo sequences (8). The use of arterial spin labeling has potential as a method insensitive to large veins, although the temporal efficiency, intrinsic sensitivity, and brain coverage limitations blunt its utility. Vascular Space Occupancy (VASO), a method sensitive to blood volume changes, has been shown to be exquisitely sensitive to blood volume changes in small vessels and capillaries. Preliminary results have shown clear layer dependent activation using VASO where other approaches have provided less clear delineation(9).</p>
<p>Methods have arisen to identify and mask large vein effects – including thresholding based on percent signal change (large veins tend to fill voxels and thus exhibit a larger fractional signal change), as well as temporal fluctuations (large veins are pulsatile thus exhibit more magnitude and phase noise). While these seem to be workable solutions, they have not been picked up and used extensively. With regard to using the phase variations as a regressor to eliminate pulsatile blood and tissue, perhaps the primary reason for this not being adopted is because standard scanners do not produce these images readily, thus users do not have easy access to this information.</p>
<p>The draining vein issue is least problematic at voxel sizes larger than 2mm, as at these resolutions, mostly the region of activation- as defined as &gt;1 cm “blob” is used and interpreted. Other than enhancing the magnitude of activation, vein effects do not distort these “blobs” thus are typically of no …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.thebrainblog.org/2018/12/23/twenty-six-controversies-and-challenges-in-fmri/">http://www.thebrainblog.org/2018/12/23/twenty-six-controversies-and-challenges-in-fmri/</a></em></p>]]>
            </description>
            <link>http://www.thebrainblog.org/2018/12/23/twenty-six-controversies-and-challenges-in-fmri/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23668279</guid>
            <pubDate>Sun, 28 Jun 2020 12:27:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Server-Side Tracking Without Cookies in Go]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 22 (<a href="https://news.ycombinator.com/item?id=23668212">thread link</a>) | @marvinblum
<br/>
June 28, 2020 | https://marvinblum.de/blog/server-side-tracking-without-cookies-in-go-OxdzmGZ1Bl | <a href="https://web.archive.org/web/*/https://marvinblum.de/blog/server-side-tracking-without-cookies-in-go-OxdzmGZ1Bl">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    
    <small>Published on 22. June 2020</small>
    <p>I was looking for an alternative to Google Analytics to track visitors on a website. Analytics (and most of its competitors) provide detailed information and real-time data at the cost of privacy. Google can track you across sites using a bunch of different techniques and through their Chrome browser. Combined, this can be assembled to a detailed profile that can not only be used for tracking, but for marketing too.</p><p>I found some (open source) alternatives like <a href="https://www.goatcounter.com/" target="_blank" rel="noreferrer">GoatCounter</a>, which anonymously collect data without invading the user's privacy. But all of the tools I found either rely on cookies, which the visitor needs to opt-in for or cost money for the server-side only tracking solution. While I'm willing to pay for good software, especially when it comes from a small team or just one developer, I was wondering if I could build something that I can integrate into my Go applications.</p><p>This post is about my solution called <em>Pirsch</em>, an open-source Go library that can be integrated into your applications to tracks visitors on the server-side, without setting cookies. I will write about the technique used and what the advantages and disadvantages are.</p><blockquote><h2>TL;DR</h2><p>Invading the privacy of your website visitors is evil. Pirsch is a privacy-focused tracking library for Go that can be integrated into your applications. Check it out on <a href="https://github.com/emvi/pirsch" target="_blank" rel="noreferrer">GitHub</a>!</p><p>You can find a live demo <a href="https://marvinblum.de/tracking" target="_blank" rel="noreferrer">here</a> on my website and the whole thing on GitHub as a <a href="https://github.com/Kugelschieber/marvinblum" target="_blank" rel="noreferrer">sample application</a>.</p></blockquote><h2>What's With the Name?</h2><p>Pirsch is German and refers to a special kind of hunt:&nbsp;<em>the hunter carefully and quietly enters the area to be hunted, he stalks against the wind in order to get as close as possible to the prey without being noticed.</em></p><p>I found this quite fitting for a tracking library that cannot be blocked by the visitor. Even though it sounds a little sneaky. Here is the Gopher for it create by <a href="https://github.com/Motorschpocht" target="_blank" rel="noreferrer">Daniel</a>.</p><img src="https://marvinblum.de/static/blog/OxdzmGZ1Bl/0wV4YBIYaCm9JiteSaa3.svg" alt="https://api.emvi.com/api/v1/content/0wV4YBIYaCm9JiteSaa3.svg"><h2>How Does It Work?</h2><p>I will go over each step in more detail later, but here is a high-level overview of how Pirsch tracks visitors.</p><img src="https://marvinblum.de/static/blog/OxdzmGZ1Bl/vuvopEa9M7yGpKWgwXht.svg" alt="https://api.emvi.com/api/v1/content/vuvopEa9M7yGpKWgwXht.svg"><p>Once someone visits your website, the HTTP handler calls Pirsch to store a new hit and goes on with whatever it intends to do. Pirsch will do its best to filter out bots, calculate a fingerprint, and stores the page hit. You can analyze the data and generate statistics from it later.</p><p>The process must be triggered manually by calling the <code>Hit</code> method and passing the <code>http.Request</code>. This enables you to decide which traffic is tracked and which is not. I'm usually just interested in page visits, so I'll add a call to Pirsch inside my page handlers. Resources are served on a different endpoint and won't be tracked that way.</p><h3>Fingerprinting</h3><p>Fingerprinting is a technique to identify individual devices by combing some parameters. The parameters are typically things like the graphics card ID and other variables that are unique to a device. As we are interested in tracking website traffic, we won't have access to this kind of information. Instead, we can make use of the IP and HTTP protocol. Here are the parameters used by Pirsch to generate a fingerprint:</p><ul><li><p>the IP is the most obvious choice. It might change, as ISPs only have a limited pool of IPs available to them, but that shouldn't happen too frequently</p></li><li><p>the User-Agent HTTP header contains information about the browser and device used by the visitor. It might not be filled though, but it usually is</p></li></ul><p>To generate a unique fingerprint from this information, we can calculate a hash. Pirsch will add the current day to prevent tracking users across days and calculate an MD5 hash. I found this to be the fastest algorithm available in the Go standard library. This will also make the visitor anonymous at the same time as we do not store IPs or other identifiable information.</p><p>This method is called <em>passive</em> fingerprinting, as we're only using data that we have access to anyways. The alternative is called <em>active</em> fingerprinting, which makes use of JavaScript to collect additional information on the client-side and sends it to the backend. But as we're trying to build a privacy-focus tracking solution, passive fingerprinting is the way to go.</p><p>We will use the fingerprint later to count unique visitors.</p><h3>Filtering Bots</h3><p>Filtering out bot traffic is hard, as there is no complete list of all bots and they won't send any special kind of information, like an <em>I'm a bot</em> header. All we can do is to process the IP and the User-Agent header send and make some assumptions. Pirsch will look for terms often used by bots within the User-Agent header. Should it contain words like <em>bot</em> or <em>crawler</em> or an URL, the hit will be dropped. Filtering for IP ranges is not implemented (yet), but you can filter hits that are coming from popular IP ranges, like AWS.</p><h3>Hits</h3><p>Each page request is stored as a <em>Hit</em>. A hit is a data point that can later be analyzed. Here is the definition of a hit:</p><pre><code language="text/x-go">// I removed some details to make it more readable for this blog post
type Hit struct {
	Fingerprint string
	Path        string
	URL         string
	Language    string
	UserAgent   string
	Ref         string
	Time        time.Time
}</code></pre><p>A hit contains the full request URL, the path extracted from the URL, the language, user-agent and reference passed by the client in their corresponding headers and the time the request was made.</p><h3>Analyze</h3><p>Pirsch provides an <em>Analyzer</em> that can be used to extract some basic statistics:</p><ul><li><p>total visitor count</p></li><li><p>visitors by page on each day</p></li><li><p>visitors by hour on each day</p></li><li><p>languages used by visitors</p></li><li><p>active visitors within a time frame</p></li></ul><p>Most of these functions accept a filter to specify a time frame. The data can then be plotted like on my <a href="https://marvinblum.de/tracking" target="_blank" rel="noreferrer">tracking page</a>.</p><img src="https://marvinblum.de/static/blog/OxdzmGZ1Bl/QOeMcMKi8yS2p4WB2Xlu.png" alt="https://api.emvi.com/api/v1/content/QOeMcMKi8yS2p4WB2Xlu.png"><p>To reduce the amount of data that needs to be processed the hits get aggregated each night and hits are cleaned up afterward.</p><p>Postgres is used as the storage backend at the moment as it is a fantastic open-source database and provides all features needed to read these statistics easily. You can extract more statistics, like the visitor page flow, from the database if you care.</p><h3>Tracking From JavaScript</h3><p>While it is simple to integrate tracking into your backend, you might also want to have some way to track from your frontend as well, in case you're running a single page application for example. In that case, you can add an endpoint to your router and call it using Ajax. The path can manually be overwritten in Pirsch by calling <em>HitPage</em> instead of <em>Hit</em>.</p><h2>How Well Does It Work?</h2><p>As far as I can tell right now, it works pretty well. I still need to collect more sample data and a way to compare it to something like Google Analytics in order to make a more precise statement. Keep in mind that while Analytics and other tools provide more detailed statistics, like the location, age, gender, and so on, they can be blocked by tools like uBlock. Pirsch cannot be blocked by the client and therefore it can track visitors you won't even notice with a client-side solution.</p><p>Bots are probably the weak spot of Pirsch right now, as filtering for them requires adding a whole bunch of keywords to the filter list.</p><p>Another disadvantage of server-side tracking depending on your use-case  might be that you cannot track your marketing campaigns. In case you're using Adsense for marketing, you can track how well your campaigns perform through Analytics. This won't work with Pirsch.</p><h2>Conclusion</h2><p>Tracking on the server-side isn't too hard to archive and all in all, I think it's worth the effort. I hope you gained some insight into how you can use fingerprinting and Pirsch to your advantage. I will continue improving Pirsch and implement it into <a href="https://emvi.com/" target="_blank" rel="noreferrer">Emvi</a> and compare the output to Analytics. I might also add a user interface for Pirsch so that you can host it without integrating it into your application and without the need to generate the charts yourself. In case you would like to send me feedback, have a question, or would like to contribute you can contact me.</p>
</section></div>]]>
            </description>
            <link>https://marvinblum.de/blog/server-side-tracking-without-cookies-in-go-OxdzmGZ1Bl</link>
            <guid isPermaLink="false">hacker-news-small-sites-23668212</guid>
            <pubDate>Sun, 28 Jun 2020 12:06:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Guide to Linux System Calls (2016)]]>
            </title>
            <description>
<![CDATA[
Score 139 | Comments 30 (<a href="https://news.ycombinator.com/item?id=23668186">thread link</a>) | @crunchbang123
<br/>
June 28, 2020 | https://blog.packagecloud.io/eng/2016/04/05/the-definitive-guide-to-linux-system-calls/ | <a href="https://web.archive.org/web/*/https://blog.packagecloud.io/eng/2016/04/05/the-definitive-guide-to-linux-system-calls/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>This blog post explains how Linux programs call functions in the Linux kernel.</p><p>It will outline several different methods of making systems calls, how to handcraft your own assembly to make system calls (examples included), kernel entry points into system calls, kernel exit points from system calls, glibc wrappers, bugs, and much, much more. </p><div><p>Create a package repository in less than 10 seconds, free.</p></div><ul id="markdown-toc"><li><a href="#tldr" id="markdown-toc-tldr">TL;DR</a></li><li><a href="#what-is-a-system-call" id="markdown-toc-what-is-a-system-call">What is a system call?</a></li><li><a href="#prerequisite-information" id="markdown-toc-prerequisite-information">Prerequisite information</a><ul><li><a href="#hardware-and-software" id="markdown-toc-hardware-and-software">Hardware and software</a></li><li><a href="#user-programs-the-kernel-and-cpu-privilege-levels" id="markdown-toc-user-programs-the-kernel-and-cpu-privilege-levels">User programs, the kernel, and CPU privilege levels</a></li><li><a href="#interrupts" id="markdown-toc-interrupts">Interrupts</a></li><li><a href="#model-specific-registers-msrs" id="markdown-toc-model-specific-registers-msrs">Model Specific Registers (MSRs)</a></li><li><a href="#calling-system-calls-with-assembly-is-a-bad-idea" id="markdown-toc-calling-system-calls-with-assembly-is-a-bad-idea">Calling system calls with assembly is a bad idea</a></li></ul></li><li><a href="#legacy-system-calls" id="markdown-toc-legacy-system-calls">Legacy system calls</a><ul><li><a href="#using-legacy-system-calls-with-your-own-assembly" id="markdown-toc-using-legacy-system-calls-with-your-own-assembly">Using legacy system calls with your own assembly</a></li><li><a href="#kernel-side-int-0x80-entry-point" id="markdown-toc-kernel-side-int-0x80-entry-point">Kernel-side: <code>int $0x80</code> entry point</a></li><li><a href="#returning-from-a-legacy-system-call-with-iret" id="markdown-toc-returning-from-a-legacy-system-call-with-iret">Returning from a legacy system call with <code>iret</code></a></li></ul></li><li><a href="#fast-system-calls" id="markdown-toc-fast-system-calls">Fast system calls</a><ul><li><a href="#32-bit-fast-system-calls" id="markdown-toc-32-bit-fast-system-calls">32-bit fast system calls</a><ul><li><a href="#sysentersysexit" id="markdown-toc-sysentersysexit"><code>sysenter</code>/<code>sysexit</code></a></li><li><a href="#__kernel_vsyscall-internals" id="markdown-toc-__kernel_vsyscall-internals"><code>__kernel_vsyscall</code> internals</a></li><li><a href="#using-sysenter-system-calls-with-your-own-assembly" id="markdown-toc-using-sysenter-system-calls-with-your-own-assembly">Using <code>sysenter</code> system calls with your own assembly</a></li><li><a href="#kernel-side-sysenter-entry-point" id="markdown-toc-kernel-side-sysenter-entry-point">Kernel-side: <code>sysenter</code> entry point</a></li><li><a href="#returning-from-a-sysenter-system-call-with-sysexit" id="markdown-toc-returning-from-a-sysenter-system-call-with-sysexit">Returning from a <code>sysenter</code> system call with <code>sysexit</code></a></li></ul></li><li><a href="#64-bit-fast-system-calls" id="markdown-toc-64-bit-fast-system-calls">64-bit fast system calls</a><ul><li><a href="#syscallsysret" id="markdown-toc-syscallsysret"><code>syscall</code>/<code>sysret</code></a></li><li><a href="#using-syscall-system-calls-with-your-own-assembly" id="markdown-toc-using-syscall-system-calls-with-your-own-assembly">Using <code>syscall</code> system calls with your own assembly</a></li><li><a href="#kernel-side-syscall-entry-point" id="markdown-toc-kernel-side-syscall-entry-point">Kernel-side: syscall entry point</a></li><li><a href="#returning-from-a-syscall-system-call-with-sysret" id="markdown-toc-returning-from-a-syscall-system-call-with-sysret">Returning from a <code>syscall</code> system call with <code>sysret</code></a></li></ul></li></ul></li><li><a href="#calling-a-syscall-semi-manually-with-syscall2" id="markdown-toc-calling-a-syscall-semi-manually-with-syscall2">Calling a syscall semi-manually with syscall(2)</a><ul><li><a href="#glibc-syscall-wrapper-internals" id="markdown-toc-glibc-syscall-wrapper-internals">glibc <code>syscall</code> wrapper internals</a></li></ul></li><li><a href="#virtual-system-calls" id="markdown-toc-virtual-system-calls">Virtual system calls</a><ul><li><a href="#vdso-in-the-kernel" id="markdown-toc-vdso-in-the-kernel">vDSO in the kernel</a></li><li><a href="#locating-the-vdso-in-memory" id="markdown-toc-locating-the-vdso-in-memory">Locating the vDSO in memory</a></li><li><a href="#vdso-in-glibc" id="markdown-toc-vdso-in-glibc">vDSO in glibc</a></li></ul></li><li><a href="#glibc-system-call-wrappers" id="markdown-toc-glibc-system-call-wrappers"><code>glibc</code> system call wrappers</a></li><li><a href="#interesting-syscall-related-bugs" id="markdown-toc-interesting-syscall-related-bugs">Interesting syscall related bugs</a><ul><li><a href="#cve-2010-3301" id="markdown-toc-cve-2010-3301">CVE-2010-3301</a></li><li><a href="#android-sysenter-abi-breakage" id="markdown-toc-android-sysenter-abi-breakage">Android <code>sysenter</code> ABI breakage</a></li></ul></li><li><a href="#conclusion" id="markdown-toc-conclusion">Conclusion</a></li><li><a href="#related-posts" id="markdown-toc-related-posts">Related Posts</a></li></ul><p>When you run a program which calls <code>open</code>, <code>fork</code>, <code>read</code>, <code>write</code> (and many others) you are making a system call.</p><p>System calls are how a program enters the kernel to perform some task. Programs use system calls to perform a variety of operations such as: creating processes, doing network and file IO, and much more.</p><p>You can find a list of system calls by checking the <a href="http://man7.org/linux/man-pages/man2/syscalls.2.html">man page for syscalls(2)</a>.</p><p>There are several different ways for user programs to make system calls and the low-level instructions for making a system call vary among CPU architectures.</p><p>As an application developer, you don’t typically need to think about how exactly a system call is made. You simply include the appropriate header file and make the call as if it were a normal function.</p><p><code>glibc</code> provides wrapper code which abstracts you away from the underlying code which arranges the arguments you’ve passed and enters the kernel.</p><p>Before we can dive into the details of how system calls are made, we’ll need to define some terms and examine some core ideas that will appear later.</p><h2 id="hardware-and-software">Hardware and software</h2><p>This blog post makes the following assumptions that:</p><ul><li>You are using a 32-bit or 64-bit Intel or AMD CPU. The discussion about the methods may be useful for people using other systems, but the code samples below contain CPU-specific code.</li><li>You are interested in the Linux kernel, version 3.13.0. Other kernel versions will be similar, but the exact line numbers, organization of code, and file paths will vary. Links to the 3.13.0 kernel source tree on GitHub are provided.</li><li>You are interested in <code>glibc</code> or <code>glibc</code> derived libc implementations (e.g., <code>eglibc</code>).</li></ul><p>x86-64 in this blog post will refer to 64bit Intel and AMD CPUs that are based on the x86 architecture.</p><h2 id="user-programs-the-kernel-and-cpu-privilege-levels">User programs, the kernel, and CPU privilege levels</h2><p>User programs (like your editor, terminal, ssh daemon, etc) need to interact with the Linux kernel so that the kernel can perform a set of operations on behalf of your user programs that they can’t perform themselves.</p><p>For example, if a user program needs to do some sort of IO (<code>open</code>, <code>read</code>, <code>write</code>, etc) or modify its address space (<code>mmap</code>, <code>sbrk</code>, etc) it must trigger the kernel to run to complete those actions on its behalf.</p><p>What prevents user programs from performing these actions themselves?</p><p>It turns out that the x86-64 CPUs have a concept called <a href="https://en.wikipedia.org/wiki/Privilege_level">privilege levels</a>. Privilege levels are a complex topic suitable for their own blog post. For the purposes of this post, we can (greatly) simplify the concept of privilege levels by saying:</p><ol><li>Privilege levels are a means of access control. The current privilege level determines which CPU instructions and IO may be performed.</li><li>The kernel runs at the most privileged level, called “Ring 0”. User programs run at a lesser level, typically “Ring 3”.</li></ol><p>In order for a user program to perform some privileged operation, it must cause a privilege level change (from “Ring 3” to “Ring 0”) so that the kernel can execute.</p><p>There are several ways to cause a privilege level change and trigger the kernel to perform some action.</p><p>Let’s start with a common way to cause the kernel to execute: interrupts.</p><h2 id="interrupts">Interrupts</h2><p>You can think of an interrupt as an event that is generated (or “raised”) by hardware or software.</p><p>A hardware interrupt is raised by a hardware device to notify the kernel that a particular event has occurred. A common example of this type of interrupt is an interrupt generated when a NIC receives a packet.</p><p>A software interrupt is raised by executing a piece of code. On x86-64 systems, a software interrupt can be raised by executing the <code>int</code> instruction.</p><p>Interrupts usually have numbers assigned to them. Some of these interrupt numbers have a special meaning.</p><p>You can imagine an array that lives in memory on the CPU. Each entry in this array maps to an interrupt number. Each entry contains the address of a function that the CPU will begin executing when that interrupt is received along with some options, like what privilege level the interrupt handler function should be executed in.</p><p>Here’s a photo from the Intel CPU manual showing the layout of an entry in this array:</p><p><img src="https://blog.packagecloud.io/images/idt.png" alt="Screenshot of Interrupt Descriptor Table entry diagram for x86_64 CPUs"></p><p>If you look closely at the diagram, you can see a 2-bit field labeled DPL (Descriptor Privilege Level). The value in this field determines the minimum privilege level the CPU will be in when the handler function is executed.</p><p>This is how the CPU knows which address it should execute when a particular type of event is received and what privilege level the handler for that event should execute in.</p><p>In practice, there are lots of different ways to deal with interrupts on x86-64 systems. If you are interested in learning more read about the <a href="http://wiki.osdev.org/8259_PIC">8259 Programmable Interrupt Controller</a>, <a href="http://wiki.osdev.org/APIC">Advanced Interrupt Controllers</a>, and <a href="http://wiki.osdev.org/IOAPIC">IO Advanced Interrupt Controllers</a>.</p><p>There are other complexities involved with dealing with both hardware and software interrupts, such as interrupt number collisions and remapping.</p><p>We don’t need to concern ourselves with these details for this discussion about system calls.</p><h2 id="model-specific-registers-msrs">Model Specific Registers (MSRs)</h2><p>Model Specific Registers (also known as MSRs) are control registers that have a specific purpose to control certain features of the CPU. The CPU documentation lists the addresses of each of the MSRs.</p><p>You can use the CPU instructions <code>rdmsr</code> to <code>wrmsr</code> to read and write MSRs, respectively.</p><p>There are also command line tools which allow you to read and write MSRs, but doing this is <em>not recommended</em> as changing these values (especially while a system is running) is dangerous unless you are really careful.</p><p>If you don’t mind potentially destabilizing your system or irreversibly corrupting your data, you can read and write MSRs by installing <code>msr-tools</code> and loading the <code>msr</code> kernel module:</p><figure><pre><code data-lang="sh">% <span>sudo </span>apt-get install msr-tools
% <span>sudo </span>modprobe msr
% <span>sudo </span>rdmsr</code></pre></figure><p>Some of the system call methods we’ll see later make use of MSRs, as we’ll see soon.</p><h2 id="calling-system-calls-with-assembly-is-a-bad-idea">Calling system calls with assembly is a bad idea</h2><p>It’s not a great idea to call system calls by writing your own assembly code.</p><p>One big reason for this is that some system calls have additional code that runs in glibc before or after the system call runs.</p><p>In the examples below, we’ll be using the <code>exit</code> system call. It turns out that you can register functions to run when <code>exit</code> is called by a program by using <a href="http://man7.org/linux/man-pages/man3/atexit.3.html"><code>atexit</code></a>.</p><p>Those functions are called from glibc, not the kernel. So, if you write your own assembly to call <code>exit</code> as we show below, your registered handler functions won’t be executed since you are bypassing glibc.</p><p>Nevertheless, manually making system calls with assembly is a good learning experience.</p><div><p>Create a package repository in less than 10 seconds, free.</p></div><p>Using our prerequisite knowledge we know two things:</p><ol><li>We know that we can trigger the kernel to execute by generating a software interrupt.</li><li>We can generate a software interrupt with the <code>int</code> assembly instruction.</li></ol><p>Combining these two concepts leads us to the legacy system call interface on Linux.</p><p>The Linux kernel sets aside a specific software interrupt number that can be used by user space programs to enter the kernel and execute a system call.</p><p>The Linux kernel registers an interrupt handler named <code>ia32_syscall</code> for the interrupt number: 128 (0x80). Let’s take a look at the code that actually does this.</p><p>From the <code>trap_init</code> function in the kernel 3.13.0 source in <a href="https://github.com/torvalds/linux/blob/v3.13/arch/x86/kernel/traps.c#L770"><code>arch/x86/kernel/traps.c</code></a>:</p><figure><pre><code data-lang="c"><span>void</span> <span>__init</span> <span>trap_init</span><span>(</span><span>void</span><span>)</span>
<span>{</span>
        <span>/* ..... other code ... */</span>

        <span>set_system_intr_gate</span><span>(</span><span>IA32_SYSCALL_VECTOR</span><span>,</span> <span>ia32_syscall</span><span>);</span></code></pre></figure><p>Where <code>IA32_SYSCALL_VECTOR</code> is a defined as <code>0x80</code> in <a href="https://github.com/torvalds/linux/blob/v3.13/arch/x86/kernel/traps.c#L770"><code>arch/x86/include/asm/irq_vectors.h</code></a>.</p><p>But, if the kernel reserves a single software interrupt that userland programs can raise to trigger the kernel, how does the kernel know which of the many system calls it should execute?</p><p>The userland program is expected to put the system call number in the <code>eax</code> register. The arguments for the syscall itself are to be placed in the remaining general purpose registers.</p><p>One place this is documented is in a comment in <a href="https://github.com/torvalds/linux/blob/v3.13/arch/x86/ia32/ia32entry.S#L378-L397"><code>arch/x86/ia32/ia32entry.S</code></a>:</p><figure><pre><code data-lang="c"> <span>*</span> <span>Emulated</span> <span>IA32</span> <span>system</span> <span>calls</span> <span>via</span> <span>int</span> <span>0x80</span><span>.</span>
 <span>*</span>
 <span>*</span> <span>Arguments</span><span>:</span>
 <span>*</span> <span>%</span><span>eax</span> <span>System</span> <span>call</span> <span>number</span><span>.</span>
 <span>*</span> <span>%</span><span>ebx</span> <span>Arg1</span>
 <span>*</span> <span>%</span><span>ecx</span> <span>Arg2</span>
 <span>*</span> <span>%</span><span>edx</span> <span>Arg3</span>
 <span>*</span> <span>%</span><span>esi</span> <span>Arg4</span>
 <span>*</span> <span>%</span><span>edi</span> <span>Arg5</span>
 <span>*</span> <span>%</span><span>ebp</span> <span>Arg6</span>    <span>[</span><span>note</span><span>:</span> <span>not</span> <span>saved</span> <span>in</span> <span>the</span> <span>stack</span> <span>frame</span><span>,</span> <span>should</span> <span>not</span> <span>be</span> <span>touched</span><span>]</span>
 <span>*</span></code></pre></figure><p>Now that we know how to make a system call and where the arguments should live, let’s try to make one by writing some inline assembly.</p><h2 id="using-legacy-system-calls-with-your-own-assembly">Using legacy system calls with your own assembly</h2><p>To make a legacy system call, you can write a small bit of inline assembly. While this is interesting from a learning perspective, I encourage readers to never make system calls by crafting their own assembly.</p><p>In this example, we’ll try calling …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.packagecloud.io/eng/2016/04/05/the-definitive-guide-to-linux-system-calls/">https://blog.packagecloud.io/eng/2016/04/05/the-definitive-guide-to-linux-system-calls/</a></em></p>]]>
            </description>
            <link>https://blog.packagecloud.io/eng/2016/04/05/the-definitive-guide-to-linux-system-calls/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23668186</guid>
            <pubDate>Sun, 28 Jun 2020 11:56:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Asymptomatic Covid-19 finding dim hopes for herd immunity and immunity passports]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23667904">thread link</a>) | @pseudolus
<br/>
June 28, 2020 | https://www.cbc.ca/news/health/asymptomatic-covid-19-1.5629172 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/health/asymptomatic-covid-19-1.5629172">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>A closer look at people who tested positive for COVID-19 but never developed symptoms has found that such asymptomatic carriers have few to no detectable antibodies just weeks after infection, suggesting they may not develop lasting immunity.</p><div><p><span><span><span></span><span>A new study on COVID-19 immunity has found that people who were asymptomatic or mildly symptomatic had their antibodies diminish within two to three months. Though larger studies are needed, the findings cast doubt on antibody testing and herd immunity.<!-- --> <!-- -->2:01</span></span></span></p><p><span><p>A closer look at people who tested positive for COVID-19 but never developed symptoms has found that such asymptomatic carriers&nbsp;have few to no detectable antibodies just weeks after infection, suggesting&nbsp;they may not develop lasting immunity.</p>  <p>There's growing evidence that a significant proportion of people who test positive for COVID-19 never show symptoms, although it's <a href="https://www.cbc.ca/news/health/asymptomatic-testing-1.5585699"><u>not clear what percentage </u></a>of people that is&nbsp;and <a href="https://www.cbc.ca/news/health/who-covid-19-asymptomatic-spread-1.5604353"><u>what role they play</u></a> in spreading the disease.</p>  <p>A Chinese study <a href="https://www.nature.com/articles/s41591-020-0965-6#Sec8">published this&nbsp;week in Nature</a> followed 37 people in Wanzhou District in China who did not show any outward signs of the disease, despite testing positive when their respiratory tracts were swabbed and being kept in hospital for observation.</p>  <p>Some key findings include:</p>  <ul>   <li> <p>Levels of antibodies against COVID-19 were significantly lower in asymptomatic carriers&nbsp;than those with symptoms during active infection.</p> </li>   <li> <p>Antibody levels also dropped off far more quickly in people who never showed symptoms, and 40 per cent of them had no detectable antibodies eight weeks after recovery, compared with&nbsp;13 per cent of symptomatic patients.</p> </li>   <li> <p>Those with asymptomatic infections tested positive for an average of five&nbsp;days longer than people with symptomatic infections — 19 days compared with&nbsp;14 days — suggesting that they were shedding the virus longer.</p> </li>  </ul>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5535927.1587138217!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/antibody-test.jpg 300w,https://i.cbc.ca/1.5535927.1587138217!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/antibody-test.jpg 460w,https://i.cbc.ca/1.5535927.1587138217!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/antibody-test.jpg 620w,https://i.cbc.ca/1.5535927.1587138217!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/antibody-test.jpg 780w,https://i.cbc.ca/1.5535927.1587138217!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/antibody-test.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5535927.1587138217!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/antibody-test.jpg"></p></div><figcaption>Unlike nasal swab tests that can only detect an active infection, antibody tests can detect previous infections. But a new study suggests antibodies often don't stick around for long after an infection.<!-- --> <!-- -->(Zuleika Chan)</figcaption></figure></span></p>  <p>The study also found that despite having no outward symptoms, 70 per cent had lung abnormalities detectable in X-rays at some point during infection — mostly spots called "ground-glass opacities," which can indicate inflammation or other signs of disease.</p>  <h2>No antibodies could mean no immunity, but not necessarily</h2>  <p>Dr. Samir Gupta, a clinician-scientist at St. Michael's Hospital in Toronto and assistant professor of medicine at the University of Toronto, noted in an interview with CBC News Network earlier this week that the study was very small.</p>  <p>Gupta, who wasn't involved in the study, added that it wasn't surprising that antibody levels fell a few months after infection. He said that's normal, since it's energy intensive for the body to maintain antibodies it doesn't need.</p>  <p>What was "a little bit surprising," he said, was the fact that 40 per cent of people with asymptomatic infections had no detectable antibodies at all.</p>  <p><em><strong>WATCH | Dr. Samir Gupta on Alberta's testing plans:</strong></em></p>  <p><span><span><span></span><span>Dr. Samir Gupta says Alberta's testing may help to understand how far the coronavirus spread but he's doubtful we've reached herd immunity.<!-- --> <!-- -->8:35</span></span></span></p>  <p>However, Gupta&nbsp;said,&nbsp;people have immunity to coronaviruses that cause common colds for only a few months, and that may also be the case for the coronavirus that causes COVID-19.</p>  <p>On the other hand, he said, "antibodies aren't the whole story."</p>  <p>There are other components of the immune system that play a role, such as memory cells. They remember a pathogen&nbsp;and begin releasing antibodies when they encounter it again, but they are hard to detect, Gupta said.</p>  <h2>What this means for herd immunity and vaccines</h2>  <p>Still, Tania Watts, a professor of immunology at the University of Toronto who was not involved in the study, expressed concern about the implications.</p>  <p>"This suggests that natural infection may not give long-lasting immunity, which is what people have been worried about," she said.</p>  <p>Some countries <a href="https://www.bmj.com/content/369/bmj.m2376"><u>such as Sweden</u></a> and <a href="https://www.cbc.ca/news/politics/herd-immunity-should-not-be-supported-tam-says-1.5545332"><u>at least one Canadian province</u></a> have previously suggested that one way to control the spread of COVID-19 is to allow most of the population to get infected in a controlled fashion to generate <a href="https://www.cbc.ca/news/politics/herd-immunity-should-not-be-supported-tam-says-1.5545332"><u>"herd immunity."</u></a>&nbsp;Once the population reaches a certain threshold of previous infection, there won't be enough susceptible people to spread the virus, and it can't spread exponentially as an epidemic.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5574385.1589816270!/cpImage/httpImage/image.jpg_gen/derivatives/original_300/virus-outbreak-vaccine-race.jpg 300w,https://i.cbc.ca/1.5574385.1589816270!/cpImage/httpImage/image.jpg_gen/derivatives/original_460/virus-outbreak-vaccine-race.jpg 460w,https://i.cbc.ca/1.5574385.1589816270!/cpImage/httpImage/image.jpg_gen/derivatives/original_620/virus-outbreak-vaccine-race.jpg 620w,https://i.cbc.ca/1.5574385.1589816270!/cpImage/httpImage/image.jpg_gen/derivatives/original_780/virus-outbreak-vaccine-race.jpg 780w,https://i.cbc.ca/1.5574385.1589816270!/cpImage/httpImage/image.jpg_gen/derivatives/original_1180/virus-outbreak-vaccine-race.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5574385.1589816270!/cpImage/httpImage/image.jpg_gen/derivatives/original_780/virus-outbreak-vaccine-race.jpg"></p></div><figcaption>A patient receives a shot in the first-stage safety study clinical trial of a potential vaccine for COVID-19 in March. A vaccine will need to produce a strong and long-lasting immune response, something that natural infection may not always do.<!-- --> <!-- -->(Ted S. Warren/The Associated Press)</figcaption></figure></span></p>  <p>But Watts said the low and short-lived levels of antibodies in asymptomatic infections in this study suggest we can't rely on herd immunity being induced for long enough a period of time to have an impact.</p>  <p>That means we may need to wait for a vaccine that induces a stronger, longer-lived response than many natural infections, she said.&nbsp;"I think this puts even more pressure on vaccine development."</p>  <h2>What this means for antibody tests,&nbsp;'immunity passports'</h2>  <p>Watts said another implication of the study is that serological (blood) or antibody tests — which have been touted as a way to get an idea of who has been previously infected, how much of the population that represents&nbsp;and how close that is to herd immunity —&nbsp;may not work as hoped.</p>  <p>And it throws cold water on the idea of controversial "<a href="https://www.cbc.ca/radio/thehouse/immunity-passes-could-be-an-interim-measure-on-the-way-to-reopening-society-physician-says-1.5544368"><u>immunity passports</u></a>," the idea of allowing more social interactions, such as work, travel&nbsp;and mass gatherings, for people who have previously been infected and therefore are immune and can't spread the virus — which would be based on serological testing.&nbsp;</p>  <p>"Until we know what part of the immune system is protective," Watts said, "it's difficult to be able to do a test and tell someone you're safe or not."</p>  <h2>What this&nbsp;means for disease transmission</h2>  <p>While it's known that presymptomatic people can transmit COVID-19, it's not really known whether people who remain asymptomatic through the course of the disease can.</p>  <p>Watts said she thinks the finding in this study that people without symptoms shed the virus longer than people with&nbsp;symptoms is "shocking" and suggests we need to worry about transmission from asymptomatic people.</p>  <p>"Until we have a vaccine, I think we should have very clear recommendations that everybody wears masks."</p>    <p>She said the longer period of viral shedding is probably because a lack of symptoms indicate a weaker immune response, resulting in a longer time to clear the infection.</p>  <p>On the other hand, too intense an immune response is what puts patients in the ICU struggling to breathe.</p>  <p>The ideal is somewhere in between&nbsp;and what we'd like in a vaccine, Watts&nbsp;said.</p>  <p>"We really need that Goldilocks immune response."</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/health/asymptomatic-covid-19-1.5629172</link>
            <guid isPermaLink="false">hacker-news-small-sites-23667904</guid>
            <pubDate>Sun, 28 Jun 2020 10:36:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: BungoSearch – Search free e-books by time-to-read]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23667702">thread link</a>) | @tomomichi
<br/>
June 28, 2020 | https://search.bungomail.com/en | <a href="https://web.archive.org/web/*/https://search.bungomail.com/en">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/68/categories/longnovel/books/1342">Pride and Prejudice
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/68/categories/all/books">Jane Austen
</a><br>
<small>(1775-1817)</small>
</td>
<td>
<a href="https://search.bungomail.com/en/authors/68/categories/longnovel/books"><p>over 3h</p>
</a>&nbsp;
<small>
113,166
Words
</small>
</td>
<td>
<span><i></i><i></i><i></i></span>
</td>
<td>
<small>
Chapter 1   It is a truth universally acknowledged, that a single man in possession of a good for...
</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/68/categories/longnovel/books/1342">Pride and Prejudice
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/68/categories/all/books">Jane Austen
</a></td>
<td>

</td>
</tr>
<tr>
<td colspan="3">
<small>Chapter 1   It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife.</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/326/categories/short/books/1080">A Modest Proposal For preventing the children of poor people in Ireland, from being a burden on t...
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/326/categories/all/books">Jonathan Swift
</a><br>
<small>(1667-1745)</small>
</td>
<td>
<a href="https://search.bungomail.com/en/authors/326/categories/short/books"><p>30min</p>
</a>&nbsp;
<small>
3,153
Words
</small>
</td>
<td>
<span><i></i><i></i><i></i></span>
</td>
<td>
<small>
1729    It is a melancholy object to those, who walk through this great town, or travel in the co...
</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/326/categories/short/books/1080">A Modest Proposal For preventing the children of poor people in Ireland,...
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/326/categories/all/books">Jonathan Swift
</a></td>
<td>

</td>
</tr>
<tr>
<td colspan="3">
<small>1729    It is a melancholy object to those, who walk through this great town, or travel in the country, when they see the streets, the roads and cabbin-doors crowded with beggars of the female sex,...</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/61/categories/longnovel/books/84">Frankenstein; Or, The Modern Prometheus
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/61/categories/all/books">Mary Wollstonecraft Shelley
</a><br>
<small>(1797-1851)</small>
</td>
<td>
<a href="https://search.bungomail.com/en/authors/61/categories/longnovel/books"><p>over 3h</p>
</a>&nbsp;
<small>
69,388
Words
</small>
</td>
<td>
<span><i></i><i></i><i></i></span>
</td>
<td>
<small>
Letter 1   St. Petersburgh, Dec. 11th, 17--  TO Mrs. Saville, England  You will rejoice to hear t...
</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/61/categories/longnovel/books/84">Frankenstein; Or, The Modern Prometheus
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/61/categories/all/books">Mary Wollstonecraft Shelley
</a></td>
<td>

</td>
</tr>
<tr>
<td colspan="3">
<small>Letter 1   St. Petersburgh, Dec. 11th, 17--  TO Mrs. Saville, England  You will rejoice to hear that no disaster has accompanied the commencement of an enterprise which you have regarded with such ...</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/9/categories/longnovel/books/2701">Moby Dick; Or, The Whale
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/9/categories/all/books">Herman Melville
</a><br>
<small>(1819-1891)</small>
</td>
<td>
<a href="https://search.bungomail.com/en/authors/9/categories/longnovel/books"><p>over 3h</p>
</a>&nbsp;
<small>
197,269
Words
</small>
</td>
<td>
<span><i></i><i></i><i></i></span>
</td>
<td>
<small>
Original Transcriber's Notes:  This text is a combination of etexts, one from the now-defunct ERI...
</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/9/categories/longnovel/books/2701">Moby Dick; Or, The Whale
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/9/categories/all/books">Herman Melville
</a></td>
<td>

</td>
</tr>
<tr>
<td colspan="3">
<small>Original Transcriber's Notes:  This text is a combination of etexts, one from the now-defunct ERIS project at Virginia Tech and one from Project Gutenberg's archives.</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/35/categories/shortnovel/books/43">The Strange Case of Dr. Jekyll and Mr. Hyde
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/35/categories/all/books">Robert Louis Stevenson
</a><br>
<small>(1850-1894)</small>
</td>
<td>
<a href="https://search.bungomail.com/en/authors/35/categories/shortnovel/books"><p>2h</p>
</a>&nbsp;
<small>
23,888
Words
</small>
</td>
<td>
<span><i></i><i></i><i></i></span>
</td>
<td>
<small>
STORY OF THE DOOR   Mr. Utterson the lawyer was a man of a rugged countenance that was never ligh...
</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/35/categories/shortnovel/books/43">The Strange Case of Dr. Jekyll and Mr. Hyde
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/35/categories/all/books">Robert Louis Stevenson
</a></td>
<td>

</td>
</tr>
<tr>
<td colspan="3">
<small>STORY OF THE DOOR   Mr. Utterson the lawyer was a man of a rugged countenance that was never lighted by a smile; cold, scanty and embarrassed in discourse; backward in sentiment; lean, long, dusty,...</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/37/categories/longnovel/books/98">A Tale of Two Cities
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/37/categories/all/books">Charles Dickens
</a><br>
<small>(1812-1870)</small>
</td>
<td>
<a href="https://search.bungomail.com/en/authors/37/categories/longnovel/books"><p>over 3h</p>
</a>&nbsp;
<small>
127,234
Words
</small>
</td>
<td>
<span><i></i><i></i><i></i></span>
</td>
<td>
<small>
Book the First--Recalled to Life     I. The Period   It was the best of times, it was the worst o...
</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/37/categories/longnovel/books/98">A Tale of Two Cities
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/37/categories/all/books">Charles Dickens
</a></td>
<td>

</td>
</tr>
<tr>
<td colspan="3">
<small>Book the First--Recalled to Life     I. The Period   It was the best of times, it was the worst of times, it was the age of wisdom, it was the age of foolishness, it was the epoch of belief, it was...</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/861/categories/shortnovel/books/2542">A Doll's House : a play
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/861/categories/all/books">Henrik Ibsen
</a><br>
<small>(1828-1906)</small>
</td>
<td>
<a href="https://search.bungomail.com/en/authors/861/categories/shortnovel/books"><p>2h</p>
</a>&nbsp;
<small>
24,806
Words
</small>
</td>
<td>
<span><i></i><i></i><i></i></span>
</td>
<td>
<small>
DRAMATIS PERSONAE       Torvald Helmer.
</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/861/categories/shortnovel/books/2542">A Doll's House : a play
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/861/categories/all/books">Henrik Ibsen
</a></td>
<td>

</td>
</tr>
<tr>
<td colspan="3">
<small>DRAMATIS PERSONAE       Torvald Helmer.</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/69/categories/longnovel/books/1661">The Adventures of Sherlock Holmes
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/69/categories/all/books">Arthur Conan Doyle
</a><br>
<small>(1859-1930)</small>
</td>
<td>
<a href="https://search.bungomail.com/en/authors/69/categories/longnovel/books"><p>over 3h</p>
</a>&nbsp;
<small>
97,696
Words
</small>
</td>
<td>
<span><i></i><i></i><i></i></span>
</td>
<td>
<small>
ADVENTURE I. A SCANDAL IN BOHEMIA  I.  To Sherlock Holmes she is always THE woman.
</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/69/categories/longnovel/books/1661">The Adventures of Sherlock Holmes
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/69/categories/all/books">Arthur Conan Doyle
</a></td>
<td>

</td>
</tr>
<tr>
<td colspan="3">
<small>ADVENTURE I. A SCANDAL IN BOHEMIA  I.  To Sherlock Holmes she is always THE woman.</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/190/categories/longnovel/books/345">Dracula
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/190/categories/all/books">Bram Stoker
</a><br>
<small>(1847-1912)</small>
</td>
<td>
<a href="https://search.bungomail.com/en/authors/190/categories/longnovel/books"><p>over 3h</p>
</a>&nbsp;
<small>
150,214
Words
</small>
</td>
<td>
<span><i></i><i></i><i></i></span>
</td>
<td>
<small>
CHAPTER I  JONATHAN HARKER'S JOURNAL  (_Kept in shorthand._)   _3 May. Bistritz._--Left Munich at...
</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/190/categories/longnovel/books/345">Dracula
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/190/categories/all/books">Bram Stoker
</a></td>
<td>

</td>
</tr>
<tr>
<td colspan="3">
<small>CHAPTER I  JONATHAN HARKER'S JOURNAL  (_Kept in shorthand._)   _3 May. Bistritz._--Left Munich at 8:35 P. M., on 1st May, arriving at Vienna early next morning; should have arrived at 6:46, but tra...</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/7/categories/shortnovel/books/11">Alice's Adventures in Wonderland
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/7/categories/all/books">Lewis Carroll
</a><br>
<small>(1832-1898)</small>
</td>
<td>
<a href="https://search.bungomail.com/en/authors/7/categories/shortnovel/books"><p>2h</p>
</a>&nbsp;
<small>
25,176
Words
</small>
</td>
<td>
<span><i></i><i></i><i></i></span>
</td>
<td>
<small>
CHAPTER I. Down the Rabbit-Hole  Alice was beginning to get very tired of sitting by her sister o...
</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/7/categories/shortnovel/books/11">Alice's Adventures in Wonderland
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/7/categories/all/books">Lewis Carroll
</a></td>
<td>

</td>
</tr>
<tr>
<td colspan="3">
<small>CHAPTER I. Down the Rabbit-Hole  Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she had peeped into the book her sister was r...</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/27/categories/short/books/1952">The Yellow Wallpaper
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/27/categories/all/books">Charlotte Perkins Gilman
</a><br>
<small>(1860-1935)</small>
</td>
<td>
<a href="https://search.bungomail.com/en/authors/27/categories/short/books"><p>30min</p>
</a>&nbsp;
<small>
5,621
Words
</small>
</td>
<td>
<span><i></i><i></i><i></i></span>
</td>
<td>
<small>
It is very seldom that mere ordinary people like John and myself secure ancestral halls for the s...
</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/27/categories/short/books/1952">The Yellow Wallpaper
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/27/categories/all/books">Charlotte Perkins Gilman
</a></td>
<td>

</td>
</tr>
<tr>
<td colspan="3">
<small>It is very seldom that mere ordinary people like John and myself secure ancestral halls for the summer.</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/37/categories/shortnovel/books/46">A Christmas Carol in Prose; Being a Ghost Story of Christmas
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/37/categories/all/books">Charles Dickens
</a><br>
<small>(1812-1870)</small>
</td>
<td>
<a href="https://search.bungomail.com/en/authors/37/categories/shortnovel/books"><p>2h</p>
</a>&nbsp;
<small>
26,327
Words
</small>
</td>
<td>
<span><i></i><i></i><i></i></span>
</td>
<td>
<small>
PREFACE  I HAVE endeavoured in this Ghostly little book, to raise the Ghost of an Idea, which sha...
</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/37/categories/shortnovel/books/46">A Christmas Carol in Prose; Being a Ghost Story of Christmas
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/37/categories/all/books">Charles Dickens
</a></td>
<td>

</td>
</tr>
<tr>
<td colspan="3">
<small>PREFACE  I HAVE endeavoured in this Ghostly little book, to raise the Ghost of an Idea, which shall not put my readers out of humour with themselves, with each other, with the season, or with me.</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/705/categories/longnovel/books/6130">The Iliad
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/705/categories/all/books">Homer
</a><br>
<small>(-750--650)</small>
</td>
<td>
<a href="https://search.bungomail.com/en/authors/705/categories/longnovel/books"><p>over 3h</p>
</a>&nbsp;
<small>
188,032
Words
</small>
</td>
<td>
<span><i></i><i></i><i></i></span>
</td>
<td>
<small>
The Iliad of Homer   Translated by Alexander Pope,  with notes by the Rev.
</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/705/categories/longnovel/books/6130">The Iliad
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/705/categories/all/books">Homer
</a></td>
<td>

</td>
</tr>
<tr>
<td colspan="3">
<small>The Iliad of Homer   Translated by Alexander Pope,  with notes by the Rev.</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/34/categories/novelette/books/41">The Legend of Sleepy Hollow
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/34/categories/all/books">Washington Irving
</a><br>
<small>(1783-1859)</small>
</td>
<td>
<a href="https://search.bungomail.com/en/authors/34/categories/novelette/books"><p>1h</p>
</a>&nbsp;
<small>
11,327
Words
</small>
</td>
<td>
<span><i></i><i></i><i></i></span>
</td>
<td>
<small>
A pleasing land of drowsy head it was,           Of dreams that wave before the half-shut eye;   ...
</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/34/categories/novelette/books/41">The Legend of Sleepy Hollow
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/34/categories/all/books">Washington Irving
</a></td>
<td>

</td>
</tr>
<tr>
<td colspan="3">
<small>A pleasing land of drowsy head it was,           Of dreams that wave before the half-shut eye;         And of gay castles in the clouds that pass,           Forever flushing round a summer sky.</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/28/categories/longnovel/books/25344">The Scarlet Letter
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/28/categories/all/books">Nathaniel Hawthorne
</a><br>
<small>(1804-1864)</small>
</td>
<td>
<a href="https://search.bungomail.com/en/authors/28/categories/longnovel/books"><p>over 3h</p>
</a>&nbsp;
<small>
78,087
Words
</small>
</td>
<td>
<span><i></i><i></i><i></i></span>
</td>
<td>
<small>
[Illustration]                             LIST OF ILLUSTRATIONS.
</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/28/categories/longnovel/books/25344">The Scarlet Letter
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/28/categories/all/books">Nathaniel Hawthorne
</a></td>
<td>

</td>
</tr>
<tr>
<td colspan="3">
<small>[Illustration]                             LIST OF ILLUSTRATIONS.</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/54/categories/longnovel/books/205">Walden, and On The Duty Of Civil Disobedience
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/54/categories/all/books">Henry David Thoreau
</a><br>
<small>(1817-1862)</small>
</td>
<td>
<a href="https://search.bungomail.com/en/authors/54/categories/longnovel/books"><p>over 3h</p>
</a>&nbsp;
<small>
107,527
Words
</small>
</td>
<td>
<span><i></i><i></i><i></i></span>
</td>
<td>
<small>
Contents   =WALDEN=  Economy  Where I Lived, and What I Lived For  Reading  Sounds  Solitude  Vis...
</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/54/categories/longnovel/books/205">Walden, and On The Duty Of Civil Disobedience
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/54/categories/all/books">Henry David Thoreau
</a></td>
<td>

</td>
</tr>
<tr>
<td colspan="3">
<small>Contents   =WALDEN=  Economy  Where I Lived, and What I Lived For  Reading  Sounds  Solitude  Visitors  The Bean-Field  The Village  The Ponds  Baker Farm  Higher Laws  Brute Neighbors  House-Warmi...</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/125/categories/shortnovel/books/219">Heart of Darkness
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/125/categories/all/books">Joseph Conrad
</a><br>
<small>(1857-1924)</small>
</td>
<td>
<a href="https://search.bungomail.com/en/authors/125/categories/shortnovel/books"><p>2h</p>
</a>&nbsp;
<small>
35,525
Words
</small>
</td>
<td>
<span><i></i><i></i><i></i></span>
</td>
<td>
<small>
I   The Nellie, a cruising yawl, swung to her anchor without a flutter of the sails, and was at r...
</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/125/categories/shortnovel/books/219">Heart of Darkness
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/125/categories/all/books">Joseph Conrad
</a></td>
<td>

</td>
</tr>
<tr>
<td colspan="3">
<small>I   The Nellie, a cruising yawl, swung to her anchor without a flutter of the sails, and was at rest.</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/53/categories/longnovel/books/76">Adventures of Huckleberry Finn
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/53/categories/all/books">Mark Twain
</a><br>
<small>(1835-1910)</small>
</td>
<td>
<a href="https://search.bungomail.com/en/authors/53/categories/longnovel/books"><p>over 3h</p>
</a>&nbsp;
<small>
104,419
Words
</small>
</td>
<td>
<span><i></i><i></i><i></i></span>
</td>
<td>
<small>
CHAPTER I. Civilizing Huck.--Miss Watson.--Tom Sawyer Waits.
</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/53/categories/longnovel/books/76">Adventures of Huckleberry Finn
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/53/categories/all/books">Mark Twain
</a></td>
<td>

</td>
</tr>
<tr>
<td colspan="3">
<small>CHAPTER I. Civilizing Huck.--Miss Watson.--Tom Sawyer Waits.</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/408/categories/longnovel/books/1260">Jane Eyre: An Autobiography
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/408/categories/all/books">Charlotte Brontë
</a><br>
<small>(1816-1855)</small>
</td>
<td>
<a href="https://search.bungomail.com/en/authors/408/categories/longnovel/books"><p>over 3h</p>
</a>&nbsp;
<small>
173,902
Words
</small>
</td>
<td>
<span><i></i><i></i><i></i></span>
</td>
<td>
<small>
Transcribed from the 1897 Service &amp; Paton edition by David Price, email ccx074@pglaf.org      JAN...
</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/408/categories/longnovel/books/1260">Jane Eyre: An Autobiography
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/408/categories/all/books">Charlotte Brontë
</a></td>
<td>

</td>
</tr>
<tr>
<td colspan="3">
<small>Transcribed from the 1897 Service &amp; Paton edition by David Price, email ccx074@pglaf.org      JANE EYRE AN AUTOBIOGRAPHY   BY CHARLOTTE BRONTE  _ILLUSTRATED BY F. H. TOWNSEND_  London SERVICE &amp; PAT...</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/971/categories/longnovel/books/2591">Grimms' Fairy Tales
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/971/categories/all/books">Jacob Grimm
</a><br>
<small>(1785-1863)</small>
</td>
<td>
<a href="https://search.bungomail.com/en/authors/971/categories/longnovel/books"><p>over 3h</p>
</a>&nbsp;
<small>
95,267
Words
</small>
</td>
<td>
<span><i></i><i></i><i></i></span>
</td>
<td>
<small>
FAIRY TALES  By The Brothers Grimm    PREPARER'S NOTE       The text is based on translations fro...
</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/971/categories/longnovel/books/2591">Grimms' Fairy Tales
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/971/categories/all/books">Jacob Grimm
</a></td>
<td>

</td>
</tr>
<tr>
<td colspan="3">
<small>FAIRY TALES  By The Brothers Grimm    PREPARER'S NOTE       The text is based on translations from      the Grimms' Kinder und Hausmarchen by      Edgar Taylor and Marian Edwardes.</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/572/categories/novelette/books/1250">Anthem
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/572/categories/all/books">Ayn Rand
</a><br>
<small>(1905-1982)</small>
</td>
<td>
<a href="https://search.bungomail.com/en/authors/572/categories/novelette/books"><p>1h</p>
</a>&nbsp;
<small>
17,819
Words
</small>
</td>
<td>
<span><i></i><i></i><i></i></span>
</td>
<td>
<small>
PART ONE   It is a sin to write this.
</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/572/categories/novelette/books/1250">Anthem
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/572/categories/all/books">Ayn Rand
</a></td>
<td>

</td>
</tr>
<tr>
<td colspan="3">
<small>PART ONE   It is a sin to write this.</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/226/categories/longnovel/books/408">The Souls of Black Folk
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/226/categories/all/books">W. E. B. (William Edward Burghardt) Du Bois
</a><br>
<small>(1868-1963)</small>
</td>
<td>
<a href="https://search.bungomail.com/en/authors/226/categories/longnovel/books"><p>over 3h</p>
</a>&nbsp;
<small>
63,731
Words
</small>
</td>
<td>
<span><i></i><i></i><i></i></span>
</td>
<td>
<small>
chapter I have pointed out the slow rise of personal leadership, and criticized candidly the lead...
</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/226/categories/longnovel/books/408">The Souls of Black Folk
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/226/categories/all/books">W. E. B. (William Edward Burghardt) Du Bois
</a></td>
<td>

</td>
</tr>
<tr>
<td colspan="3">
<small>chapter I have pointed out the slow rise of personal leadership, and criticized candidly the leader who bears the chief burden of his race to-day.</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/1735/categories/shortnovel/books/5200">Metamorphosis
<small>
<i></i>
</small>
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/1735/categories/all/books">Franz Kafka
</a><br>
<small>(1883-1924)</small>
</td>
<td>
<a href="https://search.bungomail.com/en/authors/1735/categories/shortnovel/books"><p>2h</p>
</a>&nbsp;
<small>
20,419
Words
</small>
</td>
<td>
<span><i></i><i></i><i></i></span>
</td>
<td>
<small>
Franz Kafka  Translated by David Wyllie    I   One morning, when Gregor Samsa woke from troubled ...
</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/1735/categories/shortnovel/books/5200">Metamorphosis
<small>
<i></i>
</small>
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/1735/categories/all/books">Franz Kafka
</a></td>
<td>

</td>
</tr>
<tr>
<td colspan="3">
<small>Franz Kafka  Translated by David Wyllie    I   One morning, when Gregor Samsa woke from troubled dreams, he found himself transformed in his bed into a horrible vermin.</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/111/categories/shortnovel/books/844">The Importance of Being Earnest: A Trivial Comedy for Serious People
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/111/categories/all/books">Oscar Wilde
</a><br>
<small>(1854-1900)</small>
</td>
<td>
<a href="https://search.bungomail.com/en/authors/111/categories/shortnovel/books"><p>2h</p>
</a>&nbsp;
<small>
19,113
Words
</small>
</td>
<td>
<span><i></i><i></i><i></i></span>
</td>
<td>
<small>
Transcribed from the 1915 Methuen &amp; Co.
</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/111/categories/shortnovel/books/844">The Importance of Being Earnest: A Trivial Comedy for Serious People
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/111/categories/all/books">Oscar Wilde
</a></td>
<td>

</td>
</tr>
<tr>
<td colspan="3">
<small>Transcribed from the 1915 Methuen &amp; Co.</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/53/categories/longnovel/books/74">The Adventures of Tom Sawyer
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/53/categories/all/books">Mark Twain
</a><br>
<small>(1835-1910)</small>
</td>
<td>
<a href="https://search.bungomail.com/en/authors/53/categories/longnovel/books"><p>over 3h</p>
</a>&nbsp;
<small>
66,208
Words
</small>
</td>
<td>
<span><i></i><i></i><i></i></span>
</td>
<td>
<small>
CHAPTER I. Y-o-u-u Tom-Aunt Polly Decides Upon her Duty--Tom Practices Music--The Challenge--A Pr...
</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/53/categories/longnovel/books/74">The Adventures of Tom Sawyer
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/53/categories/all/books">Mark Twain
</a></td>
<td>

</td>
</tr>
<tr>
<td colspan="3">
<small>CHAPTER I. Y-o-u-u Tom-Aunt Polly Decides Upon her Duty--Tom Practices Music--The Challenge--A Private Entrance  CHAPTER II. Strong Temptations--Strategic Movements--The Innocents Beguiled  CHAPTER...</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/563/categories/novel/books/1232">The Prince
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/563/categories/all/books">Niccolò Machiavelli
</a><br>
<small>(1469-1527)</small>
</td>
<td>
<a href="https://search.bungomail.com/en/authors/563/categories/novel/books"><p>3h</p>
</a>&nbsp;
<small>
45,973
Words
</small>
</td>
<td>
<span><i></i><i></i><i></i></span>
</td>
<td>
<small>
by Nicolo Machiavelli  Translated by W. K. Marriott   Nicolo Machiavelli, born at Florence on 3rd...
</small>
</td>
</tr>
<tr>
<td>
<a href="https://search.bungomail.com/en/authors/563/categories/novel/books/1232">The Prince
</a></td>
<td>
<a href="https://search.bungomail.com/en/authors/563/categories/all/books">Niccolò …</a></td></tr></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://search.bungomail.com/en">https://search.bungomail.com/en</a></em></p>]]>
            </description>
            <link>https://search.bungomail.com/en</link>
            <guid isPermaLink="false">hacker-news-small-sites-23667702</guid>
            <pubDate>Sun, 28 Jun 2020 09:44:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A primer on the cruel, tacit laws of type-level programming in Haskell]]>
            </title>
            <description>
<![CDATA[
Score 115 | Comments 62 (<a href="https://news.ycombinator.com/item?id=23667675">thread link</a>) | @tenslisi
<br/>
June 28, 2020 | https://www.aymannadeem.com/haskell/2020/05/15/Kindness-for-Mean-Girls.html | <a href="https://web.archive.org/web/*/https://www.aymannadeem.com/haskell/2020/05/15/Kindness-for-Mean-Girls.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    
<h4 id="a-primer-on-the-cruel-tacit-laws-of-type-level-programming-in-haskell"><em>A primer on the cruel, tacit laws of type-level programming in Haskell</em></h4>

<p>Haskell programs are constructed at the junction of two worlds: one of types, and the other of values. Values are operational run-time entities that are denoted syntactically by <em>terms</em> in the code. To this end, types classify terms. They provide a powerful abstraction to organize data, determine how it should be stored in memory, passed through various operations, and more. On a superficial level, the difference between these worlds is simple: <em>types</em> refer to datatypes, which are either built-in (such as <code>Integer</code> and <code>String</code>), or user-declared, for example:</p>

<pre><code>data SpringFlingQueen = Cady | Regina
</code></pre>

<p>By comparison, <em>values</em> are denoted by <em>terms</em> those types categorize (such as <code>1</code> and <code>"abc"</code> described by the standard library’s <code>Integer</code> and <code>String</code> types, or <code>Cady</code> and <code>Regina</code> in the case of our user-declared type, <code>SpringFlingQueen</code>). Thus, the term <code>1</code> denotes a value that exists in memory only when the program is run.</p>

<p>In addition to these two worlds, a third, darker, and more elusive underworld of <em>kinds</em> also lurks in the shadows of Haskell programs. Haskell kinds can be as unpredictable and insidious as the soulless alpha-female of an elite high school clique. While daunting, understanding the coaction between these three worlds lays the foundation for type-level programming, a topic worth learning as it strengthens overall Haskell intuition.</p>

<p><img src="https://user-images.githubusercontent.com/875834/81239044-afe24580-8fd1-11ea-96b0-274cf839e834.png" alt="the haskell type system: a machine of constant, unforgiving judgement and rigid classification"></p>

<h3 id="kindness-is-a-virtue">Kindness is a virtue</h3>

<p>Much like counter-intuitive adolescent social dynamics, mastery of Haskell bears a steep learning curve because of its underlying complexity. It is difficult to wrap one’s head around the language’s typeclass hierarchies, category-theoretic roots, or the intricacies of compiler behavior. However, an intimate understanding of the type system lets programmers look beyond the chaos of code and apply a recognizable template by which to understand it.</p>

<h3 id="kindness-takes-patience">Kindness takes patience</h3>

<p>This topic is also difficult to master because it is both vast and subtle. Ideas underlying type-level programming are scattered across many disconnected resources focused on several corners of the Haskell ecosystem. Authoritative references on the topic (such as relevant library documentation) tend to assume familiarity with domain-specific terminology that may be unknown to non-experts. Due to the paucity of approachable materials on the subject, I’ve attempted to break down type-level programming into explanations of its constituent parts. While I don’t go into extensive depth on any individual section below, I hope to provide a valuable starting point with which readers can explore ideas in greater detail.</p>

<table>
  <thead>
    <tr>
      <th>Table of contents</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><a href="#Types-vs-Values">Types vs. Values</a></td>
    </tr>
    <tr>
      <td><a href="#Kinds">Kinds</a></td>
    </tr>
    <tr>
      <td><a href="#higher-kinded-types">Higher-kinded types</a></td>
    </tr>
    <tr>
      <td><a href="#constraint-kinds">Constraint kinds</a></td>
    </tr>
    <tr>
      <td><a href="#PolyKinds">Kind polymorphism</a></td>
    </tr>
    <tr>
      <td><a href="#DataKinds">DataKinds and type-level literals</a></td>
    </tr>
    <tr>
      <td><a href="#Datatype-promotion">Datatype promotion</a></td>
    </tr>
    <tr>
      <td><a href="#Relationship-between-values-terms-types-and-kinds">Relationship between values, terms, types, and kinds</a></td>
    </tr>
    <tr>
      <td><a href="#The-difference-between-type-and-type-level">The difference between “type” and “type-level”</a></td>
    </tr>
    <tr>
      <td><a href="#type-families">Type families</a></td>
    </tr>
    <tr>
      <td><a href="#associated-types">Associated types</a></td>
    </tr>
    <tr>
      <td><a href="#TypeLits">GHC.TypeLits</a></td>
    </tr>
    <tr>
      <td><a href="#Distinguishing-between-DataKinds-and-TypeLits">Distinguishing between DataKinds and GHC.TypeLits</a></td>
    </tr>
    <tr>
      <td><a href="#use-case-Marshaling-ASTs">Use-case: Marshaling ASTs</a></td>
    </tr>
    <tr>
      <td><a href="#The-hype-of-dependently-typed-langs">The hype of dependently-typed languages</a></td>
    </tr>
  </tbody>
</table>

<hr>

<h3 id="types-vs-values">Types vs. Values</h3>

<p>As mentioned above, Haskell programs are divided into two worlds: the <em>type-level</em> and the <em>value-level</em>. The <em>type-level</em> refers to the part of a program analyzed by the static type-checking phase during compilation. Since every expression is assigned a type, code is checked against Haskell’s type system to ensure it fits <a href="https://www.haskell.org/ghc/">GHC</a>’s specified correctness criteria.</p>

<p><img src="https://user-images.githubusercontent.com/875834/84704534-fce9fd80-af27-11ea-9544-13961a56c444.png" alt="types classify terms, just like hostile teens with identity crises classify one another"></p>

<p>If the program is well-typed, the program will compile. However, this type-information evaporates once the compilation process terminates, leaving only <em>values</em> behind at run-time. In this way, types and values can be better distinguished by the phasing distinction, with types being compile-time entities and values being run-time entities.</p>

<p>For example, if a function takes a <code>String</code>, the type-checker doesn’t care if the <code>String</code> has a value denoted by <code>"abc"</code> or <code>"123"</code> or <code>"get in loser"</code>—so long as it’s a <code>String</code>. Type information gets discarded at run-time, leaving only the string’s value (ex.,<code>"get in loser"</code>). In some cases, however, we want the type system to care about what those values are and distinguish between them. The <code>DataKinds</code> extension, which we’ll explore below, lets us do that by allowing us to shove more information about our program into the type system. This lets us add meaning to the value of a <code>String</code> at the type-level, moving them from their usual, strictly run-time existence, into the compile-time phase. The technique allows us to use more information statically in the logical development and abstraction of the program’s behavior. We’re also able to add consequences that can halt compilation if the specific value of <code>String</code> doesn’t conform to the rules we’ve specified, or define classes over them.</p>

<h4 id="distinguishing-types-and-values-in-ghci">Distinguishing types and values in GHCi</h4>

<p>Let’s examine our aforementioned <code>SpringFlingQueen</code> datatype in GHCi. When we query the type of one of its constructors using <code>:t</code> (a handy shorthand for <code>:type</code>), we see that it is indeed of type <code>SpringFlingQueen</code>:</p>

<div><div><pre><code>λ data SpringFlingQueen = Cady | Regina
λ :t Cady
Cady :: SpringFlingQueen
</code></pre></div></div>

<p>Now consider literals <code>1</code>, <code>2</code>, <code>3</code>. These are <em>values</em> of a type that parameterizes the <code>Num</code> class:</p>



<p>Typing <code>:t 1</code> into GHCi gives us <code>Num p =&gt; p</code>, indicating that a literal such as <code>1</code> can be of any polymorphic type <code>p</code> as long as the <code>Num</code> type class has instances for that type (for example, <code>Integer</code> and <code>Float</code> both have <code>Num</code> instances and therefore are valid types that <code>p</code> could be instantiated with). This is possible due to <a href="https://wiki.haskell.org/Type_inference">type inference</a>.</p>

<p><img src="https://user-images.githubusercontent.com/875834/84704346-ae3c6380-af27-11ea-8078-6f1ddfc7b238.png" alt="type inference can be used to deduce concrete types wherever they're obvious. If a type looks like a mouse, it's a mouse—duh!"></p>

<h3 id="kinds">Kinds</h3>

<p>Just like types classify terms, <a href="https://www.haskell.org/onlinereport/decls.html#sect4.1.1">kinds</a> classify types, and therefore are frequently described as “types of types”, or referred to be “one level up.” The “star” syntax (i.e., <code>*</code>) denotes kinds. It is defiantly used in this post despite <a href="https://github.com/ghc-proposals/ghc-proposals/blob/master/proposals/0143-remove-star-kind.rst">recent syntactic changes</a>. A prerequisite for understanding the kind system necessitates comprehending the differences between three pairs of ideas:</p>

<ol>
  <li>
    <p><strong>Data constructors vs. type constructors:</strong> data constructors create values, whereas type constructors create types. Type constructors take one or more type arguments and produce a datatype when enough arguments are provided. This means that through <a href="https://wiki.haskell.org/Currying">currying</a>, a type constructor can be <a href="https://wiki.haskell.org/Partial_application">partially applied</a>. For example, the list type constructor <code>[]</code> may take a single type argument (ex. <code>String</code>) to denote the elements of the list (i.e., <code>[String]</code>). <code>[String]</code> is simply syntactic sugar for <code>[] String</code>, where the type <code>[]</code> is applied to <code>String</code>.</p>
  </li>
  <li>
    <p><strong>Full vs. partial application</strong> A partially-applied type, like a <a href="https://wiki.haskell.org/Partial_application">partially-applied function</a>, is one that is missing some of its data constructors. For instance, consider the list type <code>[]</code>. The kind of <code>[]</code> is <code>* -&gt; *</code>. A fully-applied list has data constructors, such as <code>[Int]</code>, and its kind is <code>*</code>.</p>
  </li>
  <li>
    <p><strong>Inhabited types vs. uninhabited types:</strong> An inhabitant of a type is precisely a value of that type. This means that <em>inhabited</em> types refer to the types that contain concrete values, such as the value denoted by the term <code>1 :: Int</code>. This suggests that the type <code>Int</code> is inhabited by value denoted by <code>1</code>. By contrast, <em>uninhabited</em> types refer to type constructors to which no values are abstracted. For instance, <code>Void</code> is uninhabited because it has no data constructors, and thus can not be used to construct a valid term. While <code>Void</code> may seem pointless at first, it can be a useful way to represent that a container is empty (ex., <code>[Void]</code>, which <em>is</em> inhabited by the term <code>[]</code> and the value this term denotes).</p>
  </li>
</ol>

<p>How do these ideas relate to the kind system? Well, all fully-applied runtime values are of kind <code>*</code> <em>and</em> they are inhabited. You can confirm this by typing <code>:k Int</code> and <code>:k String</code> in GHCi. However, this doesn’t work the other way around—just because a type is inhabited, doesn’t necessarily mean it’s fully-applied (ex., <code>[]</code> is not fully-applied but it <em>is</em> inhabited, and its kind signature is <code>* -&gt; *</code>). Conversely, all partially-applied types are uninhabited (since they don’t correspond to a value), but not all uninhabited types are partially applied. <code>Void</code> for instance is not partially-applied, but it is uninhabited.</p>

<p>To get the hang of this idea, consider the following examples:</p>

<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Inhabited?</th>
      <th>Fully-applied?</th>
      <th>Kind</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Int</code></td>
      <td>Yes</td>
      <td>Yes</td>
      <td><code>*</code></td>
    </tr>
    <tr>
      <td><code>String</code></td>
      <td>Yes</td>
      <td>Yes</td>
      <td><code>*</code></td>
    </tr>
    <tr>
      <td><code>[]</code></td>
      <td>Yes</td>
      <td>No</td>
      <td><code>* -&gt; *</code></td>
    </tr>
    <tr>
      <td><code>[Int]</code></td>
      <td>Yes</td>
      <td>Yes</td>
      <td><code>*</code></td>
    </tr>
    <tr>
      <td><code>(,)</code></td>
      <td>Yes</td>
      <td>No</td>
      <td><code>* -&gt; * -&gt; *</code></td>
    </tr>
    <tr>
      <td><code>Either</code></td>
      <td>Yes</td>
      <td>No</td>
      <td><code>* -&gt; * -&gt; *</code></td>
    </tr>
    <tr>
      <td><code>Void</code></td>
      <td>No</td>
      <td>N/A</td>
      <td><code>*</code></td>
    </tr>
    <tr>
      <td><code>Either Void Void</code></td>
      <td>Yes</td>
      <td>Yes</td>
      <td><code>*</code></td>
    </tr>
  </tbody>
</table>

<p>Kind signatures can be specified manually in GHCi using the <a href="https://downloads.haskell.org/~ghc/8.0.1/docs/html/users_guide/glasgow_exts.html#ghc-flag--XKindSignatures"><code>XKindSignatures</code></a> extension. Try extending the above table by investigating the kind signatures of various types.</p>

<h3 id="higher-kinded-types">Higher-kinded types</h3>

<p>Just like there are higher-order functions (functions that take other functions as arguments), there are higher-kinded types (types constructors that take other type constructors as arguments). Type constructors such as <code>[]</code> are a first-class type, but also a higher-kinded type, given they take another type constructor to be reified:</p>



<p>Let’s consider <code>Functor</code>:</p>

<div><div><pre><code>λ :k Functor
Functor :: (* -&gt; *) -&gt; Constraint
</code></pre></div></div>

<p>We see that <code>Functor</code> takes a type constructor <code>* -&gt; *</code> and returns a <code>Constraint</code>. Let’s use <code>:info</code> to examine <code>Functor</code> a bit more closely:</p>

<div><div><pre><code>λ :info Functor
class Functor (f :: * -&gt; *) where
  fmap :: (a -&gt; b) -&gt; f a -&gt; f b
  (&lt;$) :: a -&gt; f b -&gt; f a
  {-# MINIMAL fmap #-}
  	-- Defined in ‘GHC.Base’
instance Functor (Either a) -- Defined in ‘Data.Either’
instance Functor ((,,,) a b c) -- Defined in ‘Data.Orphans’
instance Functor ((,,) a b) -- Defined in ‘Data.Orphans’
instance Functor [] -- Defined in ‘GHC.Base’
instance Functor Maybe -- Defined in ‘GHC.Base’
instance Functor IO -- Defined in ‘GHC.Base’
instance Functor ((-&gt;) r) -- Defined in ‘GHC.Base’
instance Functor ((,) a) -- Defined in ‘GHC.Base’
</code></pre></div></div>

<p>We see that <code>Functor</code> allows type constructors like <code>Maybe</code> and <code>[]</code> to have <code>Functor</code> instances, but not <code>Int</code> or <code>String</code>. This is because <code>Maybe</code> and <code>[]</code> are <code>* -&gt; *</code>, while <code>Int</code> has kind <code>*</code>. Similarly, <code>Either</code> has <code>* -&gt; * -&gt; *</code>, which is why its instance above is parameterized with a type parameter denoting something of kind <code>* -&gt; *</code>: <code>Either a</code>.</p>

<h3 id="constraint-kinds">Constraint kinds</h3>

<p>We got a glimpse of constraint kinds …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.aymannadeem.com/haskell/2020/05/15/Kindness-for-Mean-Girls.html">https://www.aymannadeem.com/haskell/2020/05/15/Kindness-for-Mean-Girls.html</a></em></p>]]>
            </description>
            <link>https://www.aymannadeem.com/haskell/2020/05/15/Kindness-for-Mean-Girls.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23667675</guid>
            <pubDate>Sun, 28 Jun 2020 09:34:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ELF: Better Symbol Lookup via Dt_gnu_hash (2017)]]>
            </title>
            <description>
<![CDATA[
Score 40 | Comments 5 (<a href="https://news.ycombinator.com/item?id=23667520">thread link</a>) | @fanf2
<br/>
June 28, 2020 | https://flapenguin.me/elf-dt-gnu-hash | <a href="https://web.archive.org/web/*/https://flapenguin.me/elf-dt-gnu-hash">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><time datetime="2017-05-10">2017-05-10</time> |<p><code>DT_GNU_HASH</code> is a better hash table for the <a href="https://refspecs.linuxfoundation.org/elf/gabi4+/contents.html">ELF</a> used by GNU systems in GNU-compatible software, i.e. in almost every program compiled with gcc or clang for almost any Linux distribution.</p><p>The problem with it is that <code>DT_GNU_HASH</code> is not documented anywhere other than in <a href="https://www.gnu.org/software/binutils/">GNU binutils</a> and <a href="https://www.gnu.org/software/libc/">glibc</a> source code. You can either read source code to get some intel, or read emails with patches in mail list archives (<a href="https://sourceware.org/ml/binutils/2006-10/msg00377.html">Re: GNU_HASH section format</a> is a pretty good one). Those are the only places you can try to find the truth on the matter.</p><p>Of course, there're some articles on the web where people try to break it down. Like this one.</p><p>This article does not aspire to be the ultimate truth either. But I'll try to cover everything about GNU Hash Table and explain all aspects of its work.</p><p>Before reading any further please ensure that you understand what <a href="https://refspecs.linuxfoundation.org/elf/gabi4+/ch4.symtab.html">Symbol Table</a> and <a href="https://refspecs.linuxfoundation.org/elf/gabi4+/ch4.strtab.html">String Table</a> are in the <a href="https://refspecs.linuxfoundation.org/elf/gabi4+/contents.html">ELF</a>. Also you may want to read my previous article <a href="https://flapenguin.me/2017/04/24/elf-lookup-dt-hash">ELF: symbol lookup via DT_HASH</a> to know the standard (90s-ish) way of doing symbol lookup.</p><p><code>DT_GNU_HASH</code> has nothing in common with standard <code>DT_HASH</code>, apart from serving the same purpose. It has its own hashing function, its own layout, it adds restrictions for the symbol table and contains an additional <a href="https://en.wikipedia.org/wiki/Bloom_filter">bloom filter</a> to stop lookup for missing symbols early.</p><h2>Hashing function</h2><p>Let's start with the hashing function. It can be found in <a href="https://sourceware.org/git/gitweb.cgi?p=binutils-gdb.git;a=blob;f=bfd/elf.c;h=a08e0f8ea6197f103908364665ec6e5f6c89927d;hb=HEAD#l222">bfd_elf_gnu_hash</a> or in <a href="https://sourceware.org/git/?p=glibc.git;a=blob;f=elf/dl-lookup.c;h=3d2369dbf2b7ca219eaf80a820e2a8e1329fbf50;hb=HEAD#l569">dl_new_hash</a>.</p><pre><span>#<span>include</span> <span>&lt;stdint.h&gt;</span></span>

<span><span>uint32_t</span> <span>gnu_hash</span><span>(<span>const</span> <span>uint8_t</span>* name)</span> </span>{
    <span>uint32_t</span> h = <span>5381</span>;

    <span>for</span> (; *name; name++) {
        h = (h &lt;&lt; <span>5</span>) + h + *name;
    }

    <span>return</span> h;
}

gnu_hash(<span>""</span>)                == <span>0x00001505</span>
gnu_hash(<span>"printf"</span>)          == <span>0x156b2bb8</span>
gnu_hash(<span>"exit"</span>)            == <span>0x7c967e3f</span>
gnu_hash(<span>"syscall"</span>)         == <span>0xbac212a0</span>
gnu_hash(<span>"flapenguin.me"</span>)   == <span>0x8ae9f18e</span>
</pre><h2>Layout</h2><p>Not a valid C code, but gives an idea:</p><pre><span><span>struct</span> <span>gnu_hash_table</span> {</span>
    <span>uint32_t</span> nbuckets;
    <span>uint32_t</span> symoffset;
    <span>uint32_t</span> bloom_size;
    <span>uint32_t</span> bloom_shift;
    <span>uint64_t</span> bloom[bloom_size]; 
    <span>uint32_t</span> buckets[nbuckets];
    <span>uint32_t</span> chain[];
};
</pre><h2>Bloom filter</h2><p><a href="https://en.wikipedia.org/wiki/Bloom_filter">Bloom filter</a> is used to stop the lookup for missing symbols early. <code>bloom_size</code>, <code>bloom_shift</code>, and <code>bloom</code> are parts of the structure, as their names suggest.</p><p>Bloom filter behaves slightly differently for various <code>ELFCLASS</code> binaries (defined by <code>EI_CLASS</code> field in <a href="https://refspecs.linuxfoundation.org/elf/gabi4+/ch4.eheader.html#elfid">ELF Identification</a>). Let's define <code>ELFCLASS_BITS</code> to be <code>64</code> for 64-bit binaries (<code>ELFCLASS64</code>) and <code>32</code> for 32-bit binaries (<code>ELFCLASS32</code>).</p><p>Before doing symbol lookup, take <code>bloom[(hash / ELFCLASS_BITS) % bloom_size]</code>. If bits <code>hash % ELFCLASS_BITS</code> and <code>(hash &gt;&gt; bloom_shift) % ELFCLASS_BITS</code> are set then a symbol <strong>may or may not</strong> be in the hash table, and you should proceed with a regular lookup through buckets and chains. But if at least one bit is not set then a symbol is <strong>certainly</strong> absent from the hash table.</p><h2>Buckets and chains</h2><p><code>DT_HASH</code> contains an element per symbol table's element. This leads to a waste of space because <code>STN_UNDEF</code> and some other symbols are in the hash table but are never looked up. GNU hash table allows to skip first <code>symoffset</code> symbols at the beginning of the symbol table.</p><p>Same as in <code>DT_HASH</code>, symbols are put in one of <code>nbuckets</code> buckets depending on their hashes. To be specific, each symbol should be placed into <code>hash % nbuckets</code> bucket.</p><p>Chains in the GNU hash table are nothing like strange linked lists in <code>DT_HASH</code>, they are contiguous sequences of hashes for symbols with the same index (remember that chains' indexes are shifted by <code>symoffset</code> relatively to the symbol table). The last bit in chains' element is discarded and instead used for indicating the chain's end. If it is set then the element is the last one in the chain.</p><p><code>bucket</code> array holds indexes of the first symbols in the chains. Note that those are not indexes for the <code>chain</code> array. Indexes for it will be <code>bucket[foobar] - symoffset</code>.</p><p>Chains being contiguous sequences imply that symbols within the same bucket must be stored contiguously. Order of buckets in the symbol table does not really matter but usually they're stored in an ascending order.</p><p>While looking extraneous, creating such restriction over the symbol table gives great advantage: a hash table now can store almost full hash (without the lowest bit) of a symbol within the same 32 bits. This allows linkers to compare hashes before comparing strings. Also, because <code>DT_GNU_HASH</code> requires symbol table ordering and <code>DT_HASH</code> doesn't, you can fit both into a single binary. This way both standard and GNU linkers can look up symbols in it.</p><h2>Example</h2><p>Nothing is better than a visual representation of the rules. So, let's create one.</p><p>I took the same symbols as in <a href="https://flapenguin.me/2017/04/24/elf-lookup-dt-hash">ELF: symbol lookup via DT_HASH</a> and created <code>DT_GNU_HASH</code> table from them. The example is for 64-bit ELF binaries, for 32-bit you'll need to recalculate bloom word and bits.</p><pre>nbuckets = 4      (because I decided that there will be four buckets)
symoffset = 1    (STN_UNDEF is not a part of the hash table)
bloom_size = 2   (because I decided that 16 byte bloom filter is sufficient)
bloom_shift = 5  (again, just because I can)

ix  bucket[ix]  name of first symbol in chain
--  ----------  -----------------------------
 0  1           cfsetispeed
 1  5           uselib
 2  8           freelocal
 3  13          getspen

Note that:
- symbol table is sorted by bucket
- chain[ix] is the same as hash but with set/cleared lowest bit

       SYMBOL TABLE              |              GNU HASH TABLE
                                 |
    name =                       |    hash %              bloom  bloom bits
ix  symtab[ix].st_name    hash   | ix nbuckets chain[ix]  word   #0    #1
--  ------------------  -------- | -- -------  ---------- -----  ---   ---
 0  &lt;STN_UNDEF&gt;                  |
 1  cfsetispeed         830acc54 |  0    0      830acc54    1    20    34
 2  strsigna            90f1e4b0 |  1    0      90f1e4b0    0    48    37
 3  hcreate_            4c7e3240 |  2    0      4c7e3240    1     0    18
 4  endrpcen            b6c44714 |  3    0      b6c44715    0    20    56
 5  uselib              2124d3e9 |  4    1      2124d3e8    1    41    31
 6  getttyen            fff51839 |  5    1      fff51838    0    57     1
 7  umoun               1081e019 |  6    1      1081e019    0    25     0
 8  freelocal           e3364372 |  7    2      e3364372    1    50    27
 9  listxatt            ced3d862 |  8    2      ced3d862    1    34     3
10  isnan               0fabfd7e |  9    2      0fabfd7e    1    62    43
11  isinf               0fabe9de | 10    2      0fabe9de    1    30    14
12  setrlimi            12e23bae | 11    2      12e23baf    0    46    29
13  getspen             f07b2a7b | 12    3      f07b2a7a    1    59    19
14  pthread_mutex_lock  4f152227 | 13    3      4f152226    0    39    17
15  getopt_long_onl     57b1584f | 14    3      57b1584f    1    15     2

Bloom filter:
   bit #      56       48       40       32       24       16        8        0
        xx..x.xx ...xxx.x xx...... x.x.xx.x ..x...x. ...x..x. ........ ......xx
        .x..x... .....x.. ....x.x. .....x.. xx..x.xx ...xxx.x xx...... x.x.xx.x

Or as two `uint64_t` values:
    cb1dc0ad22120003
    48040a04cb1dc0ad
</pre><p>Knowing the rules and having a built table, let's try to find some symbols by hand.</p><p>Note that when comparing hashes the lowest bit is set on both left and right hand sides.</p><ol><li><p>Existing symbol. <code>strsigna</code>:</p><pre>looking for "strsigna" (hash = 0x90f1e4b0)
checking word 0 in bloom filter for bits 48 and 37
        hash table may contain symbol
starting at ix = 1

compare hashes: (chain) 0x830acc55 == 0x90f1e4b1
wrong hash definitely not "strsigna"
moving to the next symbol

compare hashes: (chain) 0x90f1e4b1 == 0x90f1e4b1
hash matches. compare strings: "strsigna" == "strsigna"
found at index 2
</pre></li><li><p>Missing symbol. <code>foobar</code>:</p><pre>looking for "foobar" (hash = 0xfde460be)
checking word 0 in bloom filter for bits 62 and 5
        not in bloom filter
not found
</pre></li><li><p>Missing symbol with hash collision. <code>vLoun</code>:</p><pre>looking for "vLoun" (hash = 0x1081e019)
checking word 0 in bloom filter for bits 25 and 0
        hash table may contain symbol
starting at ix = 5

compare hashes: (chain) 0x2124d3e9 == 0x1081e019
wrong hash definitely not "vLoun"
moving to the next symbol

compare hashes: (chain) 0xfff51839 == 0x1081e019
wrong hash definitely not "vLoun"
moving to the next symbol

compare hashes: (chain) 0x1081e019 == 0x1081e019
hash matches. compare strings: "umoun" == "vLoun"
just hash collision
that was last symbol in this bucket
not found
</pre></li></ol><h2>Code</h2><p>Original algorithm is implemented in <a href="https://sourceware.org/git/?p=glibc.git;a=blob;f=elf/dl-lookup.c;h=3d2369dbf2b7ca219eaf80a820e2a8e1329fbf50;hb=HEAD#l350">do_lookup_x</a> in <code>ld.so</code> source code.</p><p>Implementation is a little trickier than <code>DT_HASH</code>'s one, but with the example above it should be self-explanatory.</p><pre>
<span>typedef</span> Elf64_Sym Elf_Sym;
<span>typedef</span> <span>bloom_el_t</span> <span>uint64_t</span>;
<span>#<span>define</span> ELFCLASS_BITS 64</span>


<span><span>const</span> Elf_Sym* <span>gnu_lookup</span><span>(
    <span>const</span> <span>char</span>* strtab,      
    <span>const</span> Elf_Sym* symtab,   
    <span>const</span> <span>uint32_t</span>* hashtab, 
    <span>const</span> <span>char</span>* name         
)</span> </span>{
    <span>const</span> <span>uint32_t</span> namehash = gnu_hash(name);

    <span>const</span> <span>uint32_t</span> nbuckets = hashtab[<span>0</span>];
    <span>const</span> <span>uint32_t</span> symoffset = hashtab[<span>1</span>];
    <span>const</span> <span>uint32_t</span> bloom_size = hashtab[<span>2</span>];
    <span>const</span> <span>uint32_t</span> bloom_shift = hashtab[<span>3</span>];
    <span>const</span> <span>bloom_el_t</span>* bloom = (<span>void</span>*)&amp;hashtab[<span>4</span>];
    <span>const</span> <span>uint32_t</span>* buckets = (<span>void</span>*)&amp;bloom[bloom_size];
    <span>const</span> <span>uint32_t</span>* chain = &amp;buckets[nbuckets];

    <span>bloom_el_t</span> <span>word</span> = bloom[(namehash / ELFCLASS_BITS) % bloom_size];
    <span>bloom_el_t</span> mask = <span>0</span>
        | (<span>bloom_el_t</span>)<span>1</span> &lt;&lt; (namehash % ELFCLASS_BITS)
        | (<span>bloom_el_t</span>)<span>1</span> &lt;&lt; ((namehash &gt;&gt; bloom_shift) % ELFCLASS_BITS);

    
    <span>if</span> ((<span>word</span> &amp; mask) != mask) {
        <span>return</span> <span>NULL</span>;
    }

    <span>uint32_t</span> symix = buckets[namehash % nbuckets];
    <span>if</span> (symix &lt; symoffset) {
        <span>return</span> <span>NULL</span>;
    }

    
    <span>while</span> (<span>true</span>) {
        <span>const</span> <span>char</span>* symname = strtab + symtab[symix].st_name;
        <span>const</span> <span>uint32_t</span> hash = chain[symix - symoffset];

        <span>if</span> ((namehash|<span>1</span>) == (hash|<span>1</span>) &amp;&amp; <span>strcmp</span>(name, symname) == <span>0</span>) {
            <span>return</span> &amp;symtab[symix];
        }

        
        <span>if</span> (hash &amp; <span>1</span>) {
            <span>break</span>;
        }

        symix++;
    }

    <span>return</span> <span>NULL</span>;
}
</pre><h2>Total …</h2></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://flapenguin.me/elf-dt-gnu-hash">https://flapenguin.me/elf-dt-gnu-hash</a></em></p>]]>
            </description>
            <link>https://flapenguin.me/elf-dt-gnu-hash</link>
            <guid isPermaLink="false">hacker-news-small-sites-23667520</guid>
            <pubDate>Sun, 28 Jun 2020 08:43:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Twister OS for Raspberry Pi 4]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 5 (<a href="https://news.ycombinator.com/item?id=23667310">thread link</a>) | @jordybg
<br/>
June 28, 2020 | https://raspberrypiprojects.com/twister-os-raspberry-pi-4-get-that-osx-and-windows-10-look/ | <a href="https://web.archive.org/web/*/https://raspberrypiprojects.com/twister-os-raspberry-pi-4-get-that-osx-and-windows-10-look/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-content">
		<div>
		<div id="content-area">
			<div id="left-area">
											<article id="post-814">
											 <!-- .et_post_meta_wrapper -->
				
					<div>
					<p>In this video, we take alike at Twister Os for the Raspberry Pi 4!</p>
<p>This is a new Linux distro from the creators of iRaspbian and RaspbianX and it allows you to swap between the Windows 10 look of Raspbian X nighthawk or the OSX look of iRaspbian!</p>
<p>This version does support Box86, Steam, Android mirroring on the desktop, Box86, Chromium Media edition for watching Netflix, HULU, and Disney Plus!</p>
<p>This Project is Mind-Blowing and works amazingly on The Raspberry Pi4!</p>
<p>Download it here: <a href="https://raspbian-x.com/" target="_blank" rel="noopener noreferrer">https://raspbian-x.com/</a><br>Pilabs YouTube channel: PiLabs Channel: <a href="https://www.youtube.com/channel/UCgfQjdc5RceRlTGfuthBs7g" target="_blank" rel="noopener noreferrer">https://www.youtube.com/channel/UCgfQjdc5RceRlTGfuthBs7g</a><br>PiLabs Discord: <a href="https://discord.com/invite/Fh8sjmu" target="_blank" rel="noopener noreferrer">https://discord.com/invite/Fh8sjmu</a></p>
<p><strong>Need a Pi4?</strong><br><a href="https://geni.us/jTs6jg">Raspberry Pi 4</a><br><a href="https://geni.us/sWKS">SD Cards</a><br><a href="https://geni.us/rPFYi">Ice Tower cooler</a></p>
<p><a href="https://twitter.com/ProjectsPi">Follow Me On Twitter</a></p>
<p><strong>Equipment I Use:</strong><br><a href="https://geni.us/JkNt">Screen Capture Device</a><br><a href="https://geni.us/BQ5nyKn">Tool Kit</a><br><a href="https://geni.us/wOtA">Soldering Station</a><br><a href="https://geni.us/vxAxn">Camera</a><br><a href="https://geni.us/Utll">Tripod</a><br><a href="https://geni.us/jTs6jg">Raspberry Pi 4</a><br><a href="https://geni.us/xqMj">Flirc Case</a></p>
<p>DISCLAIMER: This video and description contains affiliate links, which means that if you click on one of the product links, I’ll receive a small commission at no extra cost to you!</p>
<p>This video and Channel and Video are for viewers 14 years older and up. This video is not made for viewers under the age of 14. If you are under 14 years of age, you do not have permission to view this video.</p>
<p>THIS VIDEO IS FOR EDUCATIONAL PURPOSES ONLY!</p>
<p>#RaspberryPi #Pi4 #TwisterOS</p>


<figure><p><span><iframe width="1080" height="608" src="https://www.youtube.com/embed/TX7tArVdf80?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span>
</p></figure><figure><p><span><iframe width="1080" height="608" src="https://www.youtube.com/embed/x4dX7mc9zI4?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span>
</p></figure><figure><p><span><iframe width="1080" height="608" src="https://www.youtube.com/embed/La67o7aodJY?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span>
</p></figure>
<!-- AI CONTENT END 1 -->
					</div> <!-- .entry-content -->
					 <!-- .et_post_meta_wrapper -->
				</article> <!-- .et_pb_post -->

						</div> <!-- #left-area -->

				 <!-- end #sidebar -->
		</div> <!-- #content-area -->
	</div> <!-- .container -->
	</div></div>]]>
            </description>
            <link>https://raspberrypiprojects.com/twister-os-raspberry-pi-4-get-that-osx-and-windows-10-look/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23667310</guid>
            <pubDate>Sun, 28 Jun 2020 07:42:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Half of Canadians would support 30-hour work week: poll]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23667134">thread link</a>) | @chewdatgenie
<br/>
June 27, 2020 | https://www.rcinet.ca/en/2020/06/26/half-of-canadians-would-support-30-hour-work-week-poll/ | <a href="https://web.archive.org/web/*/https://www.rcinet.ca/en/2020/06/26/half-of-canadians-would-support-30-hour-work-week-poll/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Workers get set to pour cement from a truck at the GO train station in Oakville, Ont., Tuesday, Jan.28, 2020. A new report by the Angus Reid Institute suggests the majority of Canadians support the idea of a shorter work week. (Richard Buchan/THE CANADIAN PRESS)</p><div>
                    <p>Support for the idea of a shorter work week is growing in popularity in Canada as the COVID-19 pandemic continues to upend the working lives of Canadians, according to a <a href="http://angusreid.org/four-day-work-week/" target="_blank" rel="noopener noreferrer">new study by the Angus Reid Institute</a>.</p>
<p>More than half of Canadians (53 per cent) surveyed by the non-profit research centre said it would be a good idea to make a new 30-hour work week standard in Canada, the study found.</p>
<p>That’s a six-point increase compared to 2018 and more than twice the number of people who feel the present 40-hour workweek is just fine, the survey said.</p>
<p>Researchers at the institute speculate that the increase in support for a shorter workweek is perhaps driven in part by the COVID-19 pandemic and difficulties it has presented for many out of work Canadians.</p>
<p>The proportion of supporters of a 30-hour workweek rises to 58 per cent among those who have applied for the Canada Emergency Response Benefit. This is eight-points higher than those who have not applied for the program, the study found.</p>
<p>Support for a shorter workweek is highest at the lowest levels of household income (64 per cent) and lowest among those with incomes over $150,000 per year (47 per cent).</p>
<p>Past Conservative voters are the most fervent in their opposition to the idea of a shorter workweek.</p>
<p>This group is most likely to say that shortening the work week is an ill-conceived idea, 40 per cent feel this way, while two-thirds of past Liberal and New Democratic Party voters voice support for the measure.</p>
<h5>‘An interesting notion’</h5>
<p>Ricardo Tranjan, senior researcher at the Canadian Centre for Policy Alternatives, said “30 for 40”, thirty hours work for forty hours pay, is an interesting notion, and one that should be widely discussed, even beyond the COVID-19 context.</p>
<p>Shorter working weeks would allow workers to participate more actively in their children’s education, spend more time caring for their own parents and engage in leisure and physical activities that would have a positive impact on their health, Tranjan said.</p>
<p>Ten additional hours at home could go a long way in alleviating “double shifts,” which burden women disproportionately more than men, he said.</p>
<p>“But I have two critical concerns,” Tranjan said. “First, this can’t happen unless wages are adequate. We would absolutely need to maintain the same wage levels for shorter weeks, but for some workers, that wouldn’t be enough.”</p>
<p>People who work 40 hours a week at the minimum wage are very likely to have household incomes close to the poverty line, he said.</p>
<p>“If we reduce hours for these workers, they’re likely to pick up extra shifts, hoping that will allow them to afford things like new winter jackets for the kids or more and healthier food for the family,” Tranjan said.</p>
<p>“Meantime, higher-wage workers will be enjoying all the benefits of shorter weeks, so we’ll be just exacerbating social inequalities.”</p>
<p>Tranjan said his second concern has to do with eligibility for income supports, which is often tied to working hours.</p>
<p>“For example, will employment insurance eligibility be reduced if weeks are reduced? Or will we end up with even fewer people qualifying for EI benefits?” Tranjan said. “We need to tackle these questions heads on, but we should continue to have this conversation.”</p>
<h5>Business owners not buying it</h5>
<p>Dan Kelly, president of the Canadian Federation of Independent Business (CFIB), which has more than 100,000 members, said it should surprise no one that the majority of Canadians like the idea of a four-day work week.</p>
<p>“The only people who would say no to such an idea are those that immediately recognize that this would likely require a 20 per cent reduction in their weekly pay or the massive unemployment that would occur if businesses were required to pay the same for fewer working hours,” Kelly said. “I would like six months of vacation and double my salary – that doesn’t mean it would be a reasonable request.”</p>
<p>Half of small Canadian businesses remain fully or partially closed due to the pandemic and most of those open now will be losing money every week they are open for months and months ahead, Kelly said.</p>
<p>Businesses have been hit with multiple months of lost productivity, rising debt and the costs of the personal protective equipment they now have to procure, Kelly said.</p>
<p>“Shorter work weeks at the same rate of pay for their staff would be an impossibility for nearly every business at this time,” Kelly said.</p>
<p>Twelve per cent of independent businesses report they are considering winding down or going bankrupt, he added.</p>
<p>“There could be 100,000 fewer small businesses before this is over,” Kelly said. “Let’s not push that number even higher.”</p>
                    
                                        
                                    </div></div>]]>
            </description>
            <link>https://www.rcinet.ca/en/2020/06/26/half-of-canadians-would-support-30-hour-work-week-poll/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23667134</guid>
            <pubDate>Sun, 28 Jun 2020 06:44:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Taking Up Animation as a Hobby]]>
            </title>
            <description>
<![CDATA[
Score 105 | Comments 15 (<a href="https://news.ycombinator.com/item?id=23667083">thread link</a>) | @luu
<br/>
June 27, 2020 | http://yosefk.com/blog/a-better-future-animated-post.html | <a href="https://web.archive.org/web/*/http://yosefk.com/blog/a-better-future-animated-post.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<p><em>Whatever else happens, you made a movie… Nobody can take that away. A hundred years from now, when we're all dead and gone, people will be watching this fucking thing.</em></p>
<p><em>– <a href="http://en.wikipedia.org/wiki/Tony_Soprano">Tony Soprano</a> to his nephew (whom he murders over this movie in a few episodes)</em></p>
<p>So I made a 90-second animated, um, I guess it's a blog post. I don't know about a hundred years from now, but I proudly invite you to watch the fucking thing right now:</p>
<p><iframe src="//www.youtube.com/embed/xTOHyWphzFc" width="480" height="270" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p>
<p>I hear that it's considered classy for animators, filmmakers and such to let their work stand on its own, either refraining from commentary or making it vague. However, anxious to secure my spot in eternity, I decided to rush my immortal masterpiece out the door, so I cut everything I could.</p>
<p>I then realized that I left out a delicate point which, despite my embarrassment, I must mention. Luckily, typing is much easier than animating, so the following afterthought was quick to put down [1]. Here goes.</p>
<p>The short isn't exactly a documentary, but real-life me did switch to a part-time job to free some time for animating, drawing, etc. I figured this mundane little step was a good topic for a starting filmmaker because it turned out to be surprisingly controversial. Here are some of the reactions I received:</p>
<ul>
<li>"So you finally got fed up with the job?"</li>
<li>"Part-time? But everyone here <em>needs</em> you!"</li>
<li>"Wow, I'm jealous! I want to work less, too. They pay you the same, right?" No, they pay less, I said. "Oh. Ha-ha. Work less, get less. Interesting!"</li>
<li>"You should really work more, not less, while you're young. Futurists predict a huge global pension crisis, so save for your retirement!"</li>
<li>"I doubt this will fly with the big deadline coming. Who's gonna do all the work? Not me!" (This guy works part-time himself – very productively.)</li>
<li>"Doesn't your wife object?" (Actually, my light table is Rachel's gift. I don't know when/if I'd ever get one on my own.)</li>
</ul>
<p>These comments suggest that many people want to work less, but something is keeping them from doing it. I can certainly relate to that. It took me 10 years to decide to work part-time – and then <em>5 more years to actually do it</em>.</p>
<p>Why is it so hard?</p>
<p>My own reasons mostly revolve around money. Where I live, money is much easier to make programming than animating (good luck even finding a half-stable job working on animated features.)</p>
<p>Hence "I went into programming for the money", as I said in the short – as I always say. And initially I figured I'd work all I can and retire early – the opposite of working part-time and animating in my spare time ("settling for a fraction of the dream"). And you've just seen how I changed my mind.</p>
<p>But there's another thing, which I usually<em> don't </em>say and which I must reluctantly admit. You see, I came for the money, and then I started liking the <em>getting paid</em> part.</p>
<p>What's the difference between money and getting paid? There's a world of difference!</p>
<p>Winning a lottery is a way to obtain money without getting paid for a service. And spending your wage on designer clothes is a way to get paid without having any money left. The difference is this:</p>
<ul>
<li><strong>Money</strong> lets you buy things – food, living space, spare time, etc. It's about <strong>options</strong>.</li>
<li><strong>Getting paid</strong> tells you the value of your service to whoever paid you. It's about <strong>achievement</strong>.</li>
</ul>
<p>I like getting paid, I must admit despite the embarrassment.</p>
<p>Note that I'm not ashamed in the slightest to like money (options) and to have chosen a profession with the sole purpose of maximizing income.</p>
<p>Some people believe that you can't be happy doing something you don't love – and that you can't be any good at it, hence you won't make that much money, either. I disagree.</p>
<p>I'll tell you who my role model is, as a computer programmer. It's neither Bill Gates nor <a href="http://en.wikipedia.org/wiki/Richard_stallman">Richard Stallman</a>. My role model is <a href="http://en.wikipedia.org/wiki/Alec_Guinness">Alec Guinness</a>, whom you probably remember as Obi-Wan Kenobi from Star Wars. Wikipedia says:</p>
<blockquote><p>In letters to his friends, Guinness described the film as "fairy tale rubbish" &lt;…&gt;</p>
<p>He was one of the few cast members who believed that the film would be a box office hit;&nbsp; he negotiated a deal for 2% of the gross royalties &lt;…&gt;</p>
<p>Lucas and fellow cast members … have spoken highly of his courtesy and professionalism, both on and off the set. Lucas &lt;said&gt; that Guinness contributed significantly to achieving completion of the filming.</p></blockquote>
<p>Here's a man working on something he disliked because it paid – and delighting his target audience and colleagues alike. To me it shows that "extrinsic motivation" – money – is a perfectly good primary motivation, contrary to <a href="http://lemire.me/blog/archives/2014/07/09/extrinsic-motivations-are-harmful/">some researchers' conclusions</a>.</p>
<p>I'm in it for the money – hence, I'll never get bored and lose interest, as long as there's money to be made. I'll dutifully work on the unpleasant parts necessary to get things actually done (and get paid). Not liking programming that much, I try to keep my programs short and easy to maintain and extend – so I can program less.</p>
<p>These are all desirable traits – and not everyone genuinely loving programming has them. Think about it. Who's the better henchman – the psychopath murdering for the thrill, or the coldblooded killer who's in it for an early retirement? Same thing here.</p>
<p>I'm your perfect henchman. Pay me, give me some time alone with your computers, and when you come back, you'll find them doing your bidding. Of this I am not ashamed.</p>
<p>Recently, however, I noticed that I'm no longer the coldblooded henchman I used to be, that I started to enjoy the thrill of the kill for its own sake. And this I cannot admit without blushing.</p>
<p>That's what getting paid does to the weak-minded. It warped my value system. The phases of my transition – or should I say my moral decay – went something like this:</p>
<ol>
<li>I program because they pay me.</li>
<li>Programming is good because they pay me.</li>
<li>Programming is good.</li>
<li>Programming is good! I think I'll go program right now. Or read about it. Or write something about it. All in my spare time.</li>
</ol>
<p>And there you have it. <strong>"Achievement" has been redefined to mean "that thing you get paid for".</strong></p>
<p>This is how I ended up with a website dedicated largely to programming. Then a programming blog on the site and&nbsp;<a href="http://www.embeddedrelated.com/blogs-1/nf/Yossi_Kreinin.php">a similar blog elsewhere</a>. Then came the ultimate downfall: <a href="https://github.com/yosefk">open-source programs on GitHub</a>, written during evenings and weekends.</p>
<p>And I don't regret the writing. Keeping readers' attention on my very dry programming-related subjects is a worthy challenge for any starting storyteller.</p>
<p>But <em>programming for free? Me?</em> <a href="http://www.imdb.com/title/tt0468569/quotes">If you're good at something, never do it for free!</a> Oh, how the weak-minded have fallen.</p>
<p>Sometimes you need to hit rock bottom to begin rising. So it was with me. Realizing that I've just programmed for free for several weekends in a row made me think. Hard.</p>
<p>"I can't believe you," I said to myself. "All this money-chasing at least made some sense. But programming for free? Why not <em>draw</em> in your spare time instead? What's <em>wrong </em>with you?"</p>
<p>"Not so fast," said self. "For free or not, at least here you are doing something you're good at. You know you're good – you get paid for it! Would they pay you for drawing? Not so soon. Maybe never. Even if you're any good. <strong>In fact you'll never know if you're any good. </strong>Not if you're never paid. Nor if you're paid badly, which happens all the time in those arty parts of the world, even to the best. Why not stick to things you're <em>good</em> at – that you <em>know </em>you're good at?"</p>
<p>Could you believe this guy? Well, I wouldn't have any of that.</p>
<p>"You shameless, hypocritical, baiting-and-switching COWARD," I screamed at self at the top of my lungs. "You always said programming was for the money – to buy time, to buy that bloody creative freedom you kept chattering about! And now you say I should keep programming because I got good at it? But of course I got good – I've been doing it all this time! I could have gotten just as good at drawing – <strong>I still can</strong> – if I have the time!"</p>
<p>"And you say that now when I can afford some spare time," I went on, "I should regardless stick to what I'm good at, which by now is programming? Are you hinting that I won't ever draw very well? Is <em>that </em>why you suggested a career in programming in the first place – because you didn't believe I could draw? Was that chanting about needing money one big lie all along? Tell me, you lying bastard! I'm gonna -"</p>
<p>"OK, OK, chill, man, CHILL!" Self looked scared and unsettled. He clearly didn't see it coming. Now he was looking for some way to appease me. "You know," said self, "maybe you're right. Remember how you're always proud of taking a long-term view? Of how you care today about things 5, even 10 years ahead?"</p>
<p>I smiled smugly. Indeed I was proud of my long-term-centered, strategic thinking. <a href="http://en.wikipedia.org/wiki/Bob_Colwell">Bob Colwell</a> – the legendary computer architect – once said that it's the architect's duty to think about the long term, because nobody else will. I <em>so</em> identified with that. (Colwell and I are both computer architects, you see – just, um, of different calibers.)</p>
<p>"Well," said self, "you <em>should</em> be proud. Too many lose sight of the future because of today's small but pressing worries!"</p>
<p>"Yeah, yeah, yeah." I was losing my patience. "Thanks but no thanks for your brown-nosing. Listen, are you playing bait and switch on me again? What does this have to do with drawing?"</p>
<p>"But that's the point – it's the same thing," self exclaimed, "it's about long-term thinking! Sure, in the short term, maybe you're better at programming than drawing. But keep practicing and yes, of course you'll get good at drawing! Use your favorite superpower – your ability to imagine the future vividly, to practically live there – to overcome the temptation to stick to your comfort zone! Secure a better future today! Be the shrewd guy investing in a little unknown startup – yourself the would-be animator – to reap great benefits down the road! Be -"</p>
<p>"I get it. That's what I said though, isn't it? Let's practice – let's draw in the spare time."</p>
<p>"Sure. Sure! You're right," said self submissively. "I'm actually helping you, see? I'm telling you how to use your strengths to take the plunge!"</p>
<p>"Thaaaanks. You know what? We'll …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://yosefk.com/blog/a-better-future-animated-post.html">http://yosefk.com/blog/a-better-future-animated-post.html</a></em></p>]]>
            </description>
            <link>http://yosefk.com/blog/a-better-future-animated-post.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23667083</guid>
            <pubDate>Sun, 28 Jun 2020 06:26:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How we got our AWS bill to around 2% of revenue]]>
            </title>
            <description>
<![CDATA[
Score 292 | Comments 219 (<a href="https://news.ycombinator.com/item?id=23666999">thread link</a>) | @grwthckrmstr
<br/>
June 27, 2020 | https://www.sankalpjonna.com/posts/our-aws-bill-is-2-of-revenue-heres-how-we-did-it | <a href="https://web.archive.org/web/*/https://www.sankalpjonna.com/posts/our-aws-bill-is-2-of-revenue-heres-how-we-did-it">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Server cost is usually not a concern for most funded startups, but for a boot strapped SaaS product like ours,&nbsp; it was important to have an AWS bill that is easy on the pocket and a little more proportional to the MRR.</p><p>‍</p><p>To that end when we started<a href="http://superlemon.xyz/" target="_blank"> superlemon.xyz</a> one of the first things I did was to find ways to consume the least amount of resources on the cloud. We currently serve a traffic of ~ 250 requests per second with our AWS setup.</p><p>‍<br></p><p>Most applications require certain common cloud resources and these include</p><p>‍<br></p><ul role="list"><li>Compute instances</li><li>Database instances</li><li>Caching instances</li><li>CDN&nbsp;</li><li>A web server that acts as a reverse proxy and load balancer</li></ul><p>‍<br></p><div><p>I will now go through each of these resources and talk about both the expensive way and the cheap way to implement them</p></div><p><strong>Compute instances</strong></p><p><strong>‍</strong><br></p><p>When it comes to compute instances, most people go with AWS EC2 instances. EC2 instances are the safest choice to make for running server applications as they are highly configurable, scalable and you can change the configuration on demand according to your needs. However, sometimes you do not really need this level of control on your compute instances and that brings us to <a href="https://aws.amazon.com/free/compute/lightsail/" target="_blank">AWS Lightsail</a>.</p><p>‍<br></p><p>Lightsail as the name suggests is a lightweight version of EC2. Under the hood Lightsail instances are actually EC2 instances, but this is not apparent to the user and unlike the highly configurable EC2, Lightsail comes with a fixed configuration that once you provision cannot be changed. The billing is also a fixed amount per month as opposed to EC2 which is billed by the hour.&nbsp;</p><p>‍<br></p><p>To give you a sense of how much less complicated Lightsail is, please take a look at these screenshots of the EC2 dashboard and Lightsail dashboard.</p><figure id="w-node-7afe1c2bdee3-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5ef82a451ea3cd05dfd4c146_x93boOZlEeQGL9kcVSXPZyGOX3SNQJfDNyRC0qG3jNDCYeySdZpIgBzYgkVDZqq3DhR92f_Eqdp8sG-vIgkwltIW9ExWhshfDSsb-gd2qCah6E5VjydVhGxO4QFRA5qCR2KXqhP5.png" alt=""></p></figure><p>‍</p><p>‍</p><p>‍</p><figure id="w-node-2074947a61a8-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5ef737f4a33047deb1c0a4a6_ZMr0t2QqxGgPZ-Grg-TIHjpok_ujhoYzyHLQnsGzlSfLJj0wRrKWFMKNnVDwCoOorYJHs6j4aqKz_NgztOFGNSNc9Fw4nKGrwSRVK7E4hQtDkzE7OXIVaQp0lDjXxwjiKkHN1e3c.png" alt=""></p><figcaption>EC2 dashboard</figcaption></figure><p>‍</p><p>‍</p><p>But we are not here to debate the complexity of EC2 vs Lightsail, so let’s let us talk about the cost.</p><p>An EC2 instance with 2 virtual cores, 4GB RAM and a storage of 80GB costs roughly 37$ a month and a Lightsail instance with the exact same configuration costs 20$ a month which is almost half the cost!</p><p>‍<br></p><p>The only drawback here as previously mentioned is that the instance is fixed and neither the storage nor the compute power can be tweaked later according to spikes in traffic and usage.&nbsp;</p><p>‍<br></p><p>In our case we do not have a need for too much storage on the compute instance, and as for the computing power it was easy for us to simply provision another Lightsail instance when there is an increase in traffic and set it up behind a load balancer. This way our system is still scalable.</p><p><strong>Database instances</strong></p><p><strong>‍</strong><br></p><p>Choosing a database provider for your application can be a tricky decision, but on a high level there is just one thing that is absolutely required for any database provider - the ability to take regular backups of the DB automatically and the ability to restore the database from one of the backups.</p><p>‍<br></p><p>All of this functionality is provided by AWS RDS along with an array of other capabilities like autoscaling of storage, multiple availability zones, etc. However we did not not really need this level of control over the DB for our simple SaaS product, not to mention the fact that RDS would cost us a minimum of 200$ a month with the lowest acceptable configuration.&nbsp;</p><p>‍<br></p><p>Once again our saviour was Lightsail which provides managed Databases with a fixed storage at very cheap prices. Only MySQL and PostgreSQL are available though which was fine with us since I am quite comfortable with MySQL. We have currently provisioned one MySQL DB with 2 vCPUS, 4GB RAM and 120GB SSD and it costs us 60$ a month.</p><p>‍<br></p><p>And as mentioned before Lightsail provides the basic capabilities of backups and restoration.</p><figure id="w-node-e1f43dee380f-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5ef731c812136072299e133c_Q2n6wprxbcqgh5vI97YqjWYkOYV52HGzRtHXIQFfpgxwlHkGaO8YDv3aO3V-PwM2SI4qxPty6ZMlK0siv1-lAizSl9hf_6RASDqzNrSfEmIeMdu8UeSTsRhu4Sk1Ofg6Uw8CPPuK.png" alt=""></p><figcaption>Database restoration from recent backup</figcaption></figure><p>‍</p><div><p>The drawback here is that the DB will not scale automatically so your will have to make sure that your application does not use storage beyond what is available in the instance you select. We do this by regularly purging our Database of data that is older than X days and data that belongs to users who churned from our app more than X days ago and haven’t come back since.&nbsp;</p></div><p><strong>Caching instances</strong></p><p><strong>‍</strong><br></p><p>For our application we needed a Caching layer as well as the ability to queue up jobs that can be executed asynchronously. The seasoned folks here might have realised that the best tool to use for this is Redis and AWS has a service called ElastiCache which is Redis under the hood.&nbsp;</p><p>‍<br></p><p>Once again this would be a very safe choice to make because it is completely managed and scalable. Our need was a Redis instance with at least 6GB of memory and 2vCPUs and if we went with ElastiCache our cost would roughly come out to be 112$ a month, not to mention the additional cost of running our async workers somewhere else.</p><p>‍<br></p><p>I might sound like a broken record at this point but what we ended up doing was to provision a Lightsail instance with 2vCPUs and 8GB of memory for the cost of 40$ a month and installed an open source version of Redis on this instance. We also use the same instance to run our asynchronous workers which read from the Redis queue and execute jobs.&nbsp;</p><p>‍<br></p><p>So what is the drawback? Well since it is not a managed service, you would have to monitor the Redis server yourself. There are many tools out there that help you do this and the one I would recommend is<a href="http://prometheus.io/" target="_blank"> prometheus.io</a>.</p><p>‍<br></p><p>This means that you have to do a little bit of extra work to setup metrics collection from your Redis instance and use a grafana dashboard where you can view these metrics, but this extra work saves a lot of money in the long run and you get to look at a super cool dashboard like this one</p><figure id="w-node-ed9ef23d383f-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5ef71b6832df460f9189c1ef_8fAYGJqB0CXvglSTkg-wXPXqpKi2e3fusNyMcOaiepfnZ-dC1kjn2Do44sILw5lbKOSISB1CMTEdCzyqBcyggDwK4tJcDEA17xkWXb2J1tUjLHBJgtMa_t3ekfIUfOiImx5IaZd6.png" alt=""></p><figcaption>Grafana dashboard for monitoring redis instance</figcaption></figure><p><strong>CDN</strong></p><p><strong>‍</strong><br></p><p>Our application requires a javascript file to be loaded into the websites of our customers. This JS file gets a ton of traffic because this traffic scales according to how many visitors our customers get. Now this can be scary because it means we really had no idea how many requests the JS file might actually end up receiving so we hesitated to go with CloudFront which is the goto solution for a CDN on AWS.&nbsp;</p><p>‍<br></p><p>So we ended up taking an entirely different approach for this. Our application is a Shopify app and during the process of building the application we created a Shopify store. Every Shopify store gets its own personal CDN where you can manually upload anything and it will be served over the Shopify CDN. So we minified and uploaded our JS file to the CDN of our Shopify store and now we serve 20000 Shopify stores using this method at zero cost.</p><figure id="w-node-78b80f124ebd-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5ef71b68374cfd3932d127f5_z2vfALB6_5FJXMp4al-65PIczwKOE-wUb0TubqBXAFMiu0rnqPEKGAOl12Saf0Xn-Ay1DjWL7wIj7Vby1sNPfLHkpuXzHf17ytoJ5gQvql13DZl1BsIV2rJPeHgfnCnIdezWiddG.png" alt=""></p><figcaption>Shopify CDN&nbsp;that is free of cost</figcaption></figure><p>There is a glaring drawback to this approach. The Shopify store CDN does not provide an API that you can use to programmatically upload files and it has to be done manually. Also unlike CloudFront, there is no option of invalidating a file once it is uploaded. So If you have to make updates to your file you would have to upload a new file and migrate all of your existing users to this new file.&nbsp;<br></p><p>‍</p><p>This might sound like a big drawback, but it actually took me an hour to whip up a script that updates the JS file for all our existing 20000 stores to the updated JS file that I provide. So whenever I make a new release to this JS file, I simply upload a new file manually to the CDN, then take that file as the input and run this script and we re live! This approach works for us because we do not make too many releases to the JS&nbsp;file to begin with.</p><p><strong>Web server + load balancer</strong></p><p><strong>‍</strong><br></p><p>Every application requires the ability to route requests coming to their domain or subdomain to various applications running under the hood. The best way to do this is to use AWS ELB which can be used to automatically distribute incoming application traffic across multiple targets, such as Amazon EC2 instances, containers, IP addresses, and Lambda functions.&nbsp;</p><p>‍<br></p><p>This sounds quite fancy, but all we needed for our product was 4 things</p><p>‍</p><ul role="list"><li>Serving static files for our application dashboard</li><li>Distribute traffic among different Lightsail instances based on the path of the incoming URL</li><li>Load balance traffic that comes from our Merchants Shopify stores amongst N identical Lightsail instances.</li><li>Rate limiting of requests to prevent DDOS attacks.</li></ul><p>‍<br></p><p>All of this can be done using NGINX which is a great piece of software and is quite robust even with the default settings that it comes with.&nbsp;<br></p><p>So we simply installed a stable version of NGINX on one of our existing Lightsail instances which was already being used to host one of our server applications. We also use<a href="http://amplify.nginx.com/" target="_blank"> amplify.nginx.com</a> for monitoring it. This setup is pretty much equivalent to using a managed service at zero cost.</p><p>‍</p><figure id="w-node-26b2c44e15ee-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5ef730c34b26677e785fa7ea_w67-tKkFsy_LekSEhO_PXqnHGxDiREqENBgMBaEAOqotyjEDJoKXRk6Wpd5K86OOv2z_S-ejGOnL37l6lj6MWqE_x2ZvrIZ4FCQraAC1uDWMne7yi0Fme4Jap2sp2uH2zrKdvpTz.png" alt=""></p><figcaption>Amplify dashboard for monitoring health of the NGINX server</figcaption></figure><p>‍</p><p><strong>Summary</strong></p><p>‍</p><ul role="list"><li>Use lightsail instances (20$ per instance) instead of EC2 instances (37$ per instance)</li><li>Use a lightsail database (60$ per DB) instead of RDS (200$ per DB)</li><li>Use a self hosted redis server on a compute instance (40$) instead of ElastiCache (112$)&nbsp;</li><li>If feasible, use a free CDN (cost savings depends on traffic size)</li><li>Use a self hosted NGINX server (20$ fixed cost) instead of ELB (cost depends on traffic and usage)</li></ul><p><strong>Closing notes</strong></p><p><strong>‍</strong><br></p><p>I would like to put emphasis on the fact that we are a micro-SaaS product that solves a small and specific use case and therefore this kind of AWS setup worked for us. This may not work for big organisations or products where the traffic is erratic.&nbsp;</p><p>This setup will also not work for folks who have a ton of stuff to do already and would prefer to use managed services and not take the additional headache of monitoring, maintaining and provisioning hardware resources on a regular basis because this has a time cost to it.</p><p>We are a team of 2 people with a product that is not computation heavy and has cloud requirements that are quite straightforward. We have been running this product for a little over 1 year with this AWS setup and so far we have not encountered any problems.</p></div></div>]]>
            </description>
            <link>https://www.sankalpjonna.com/posts/our-aws-bill-is-2-of-revenue-heres-how-we-did-it</link>
            <guid isPermaLink="false">hacker-news-small-sites-23666999</guid>
            <pubDate>Sun, 28 Jun 2020 05:58:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Should I learn UIKit or SwiftUI?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23666923">thread link</a>) | @sarunw
<br/>
June 27, 2020 | https://sarunw.com/posts/should-i-learn-uikit-or-swiftui/ | <a href="https://web.archive.org/web/*/https://sarunw.com/posts/should-i-learn-uikit-or-swiftui/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>            
      
<section>
<div>
    <div>        

      

      <hr>

      
        
        
      

      
            

      <p>SwiftUI feels very young when it first announced last year in WWDC19. It shows a promising future, but it has a rough edge here and there, and it quite hard to predict what it will be like in a year. The year has passed, and here is my thought on Apple's new declarative UI framework SwiftUI.</p>
<h2 id="the-gap-is-getting-closer">The gap is getting closer <a href="#the-gap-is-getting-closer">#</a></h2>
<p>My arguments around SwiftUI are always like, "You can't do x (UIKit features) in SwiftUI". This year, Apple show an incredible pace of SwiftUI development. The missing UI elements from last year already have a SwiftUI counterpart, e.g., <code>UIColelctionView</code> and <code>UITextField</code> already have a SwiftUI counterpart of <code>LazyH/VGrid</code> and <code>TextEditor</code>.</p>
<h2 id="first-class-citizen">First-class citizen <a href="#first-class-citizen">#</a></h2>
<p>It looks like SwiftUI doesn't want to be just a view for UIKit anymore. Now, you can write an entire app using pure SwiftUI.</p>
<p>The following is a working SwiftUI app code.</p>
<pre><code><span><span>import</span> <span>SwiftUI</span></span><br><span></span><br><span>@main</span><br><span><span>struct</span> <span>SwiftUIApp</span><span>:</span> <span>App</span> <span>{</span></span><br><span>    <span>var</span> body<span>:</span> some <span>Scene</span> <span>{</span></span><br><span>        <span>WindowGroup</span> <span>{</span></span><br><span>            <span>Text</span><span>(</span><span>"Hello! SwiftUI"</span><span>)</span></span><br><span>        <span>}</span></span><br><span>    <span>}</span></span><br><span><span>}</span></span></code></pre>
<p>And the code above not just works on iOS, but the same code can make an iPad and Mac app. You can write a multiplatform app entirely with SwiftUI. Seem like the concepts of SwiftUI are far more powerful than I first thought.</p>
<h2 id="exclusive-deal">Exclusive Deal <a href="#exclusive-deal">#</a></h2>
<p><a href="https://developer.apple.com/documentation/widgetkit" target="_blank" rel="nofollow noopener">WidgetKit</a>, a new framework in iOS 14 for writing a Widget can only write using SwiftUI. This means you can't run away from it, even you love UIKit, it seems like you have no choice, but to also learn SwiftUI.</p>
<figure>
  <img src="https://d33wubrfki0l68.cloudfront.net/29ba6373e9bf92bbbc301e0f6fb491f3cf51920a/819cd/images/swiftui-2-widget.png" alt="Widget">
  <figcaption>Widget</figcaption>
</figure>
<h2 id="is-uikit-going-to-die%3F">Is UIKit going to die? <a href="#is-uikit-going-to-die%3F">#</a></h2>
<p>Nope, it is far from over. I don't think Apple has a plan to drop UIKit in the foreseeable future. As working on UIKit for years, SwiftUI feels like magic to me. It can replicate UIKit function with a single line of code (or no line of code since it builds right into SwiftUI). The bad thing about magic is that when things are not going as you want, it is hard to figure out what's wrong, and it might not be possible to fix it. That's when you need to go back to UIKit. UIKit is a foundation of iOS, and Apple still keeps adding new features to it (UICollectionView and UISplitViewController got a lot of cool features this year, you should check it out).</p>
<p>I see UIKit as a secret sauce behind all SwiftUI magic. Both UIKit and SwiftUI have their strength, and Apple picks the right tool for the right job (they use SwiftUI for WidgetKit because it suits the constraint that Widget has right now). I think these two will coexist for a very long time.</p>
<p>Apple put years of experience in their UIKit and tools into SwiftUI. It is enjoyable to work with, and the outcome is phenomenal. Apple can do this because they set up a way to bridge SwiftUI to UIKit, so they know that even when SwiftUI fails to do some tasks, there will always have UIKit there.</p>
<h2 id="conclusion">Conclusion <a href="#conclusion">#</a></h2>
<p>Here comes the important question. Should you learn UIKit or SwiftUI?</p>
<p>My short answer would be <strong>SwiftUI</strong>.</p>
<p>And here is my long answer. From all the facts I point out in this article, SwiftUI is ready now. I think in the end you would end up learning both of them.</p>
<p>If you know UIKit, you are forced to learn SwiftUI since it is exclusive to a new framework like WidgetKit. Even not for that reason, I think you probably the one who appreciates SwiftUI the most. SwiftUI can do many great things right out of the box, things that we always want to do in UIKit, but don't have the opportunity and time to do it.</p>
<p>If you know SwiftUI, there would be a time that you want extra customization or hit some roadblock. When the time comes, UIKit will always there for you.</p>



      <hr>
      
      <p>Feel free to follow me on <a rel="nofollow noopener" href="https://twitter.com/sarunw" target="_blank">Twitter</a> and ask your questions related to this post. Thanks for reading and see you next time.</p>
      
      

      

      

      

      



      <p><a href="https://sarunw.com/">← Home</a></p>


      
  </div>
</div>
</section>            
    </div></div>]]>
            </description>
            <link>https://sarunw.com/posts/should-i-learn-uikit-or-swiftui/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23666923</guid>
            <pubDate>Sun, 28 Jun 2020 05:30:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Adventures in booting Linux on Raspberry Pi 4]]>
            </title>
            <description>
<![CDATA[
Score 81 | Comments 39 (<a href="https://news.ycombinator.com/item?id=23666564">thread link</a>) | @todsacerdoti
<br/>
June 27, 2020 | https://blog.mostlypointless.dev/posts/net-boot-rpi/ | <a href="https://web.archive.org/web/*/https://blog.mostlypointless.dev/posts/net-boot-rpi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <article>
        
        
            <span> Jun 26, 2020</span>
            
                <a href="https://blog.mostlypointless.dev/tags/linux">linux</a>
            
                <a href="https://blog.mostlypointless.dev/tags/raspberry-pi">raspberry pi</a>
            
        
        <p>Almost two months ago, I started building a four node Raspberry Pi 4 cluster for a project I’m working on. Figuring out the best way to get Linux on each node lead me down a rabbit hole and I spent the next four weeks <a href="http://www.catb.org/~esr/jargon/html/Y/yak-shaving.html">yak shaving</a>.</p>
<p>The most common way to boot a Pi is from an SD card. But they are slow and unreliable - I don’t like them. Certain models of Pi 2 and Pi 3 support <a href="https://www.raspberrypi.org/documentation/hardware/raspberrypi/bootmodes/msd.md">booting from USB storage</a>, but Pi 4 cannot do that yet. So, I’m stuck with using an SD card for each Pi. Or so I thought.</p>
<h3 id="enter-pxe-boot">Enter PXE boot</h3>
<p>Turns out, Raspberry Pi 2 and 3 also <a href="https://www.raspberrypi.org/documentation/hardware/raspberrypi/bootmodes/net.md">support network booting</a>. A beta firmware was released late last year that enables <a href="https://en.wikipedia.org/wiki/Preboot_Execution_Environment">PXE</a> for Pi 4. I found <a href="https://linuxhit.com/raspberry-pi-pxe-boot-netbooting-a-pi-4-without-an-sd-card">an article on LinuxHit</a> detailing the process of installing the firmware and setting up network boot.</p>
<p>Just to test this out, I updated the firmware and configured PXE server on one of the Pis. I tried booting another Pi over the network and…it worked!
Here is the gist of PXE server setup process:</p>
<ol>
<li>Copy the contents of <code>/boot</code> and the rest of <code>/</code> into separate folders on your local filesystem. I copied mine to <code>/tftp/raspbian-boot</code> and <code>/nfs/raspbian-root</code> respectively.</li>
<li>Install and configure <code>dnsmasq</code> to enable TFTP and use <code>/tftp</code> as <code>tftp-root</code></li>
<li>Install and configure NFS server to share <code>/tftp/raspbian-boot</code> and <code>/nfs/raspbian-root</code></li>
<li>Edit the contents of <code>/nfs/raspbian-root/fstab</code> to mount the boot partition.</li>
<li>Edit <code>/nfs/raspbian-boot/cmdline.txt</code> to</li>
</ol>
<div><pre><code data-lang="bash">console<span>=</span>serial0,115200 console<span>=</span>tty1 root<span>=</span>/dev/nfs nfsroot<span>=</span>&lt;IP addr&gt;:/nfs/raspbian-root,vers<span>=</span>4.1,proto<span>=</span>tcp rw ip<span>=</span>dhcp rootwait elevator<span>=</span>deadline
</code></pre></div><h3 id="pxe-booting-3-nodes-using-overlayfs">PXE booting 3 nodes using OverlayFS</h3>
<p>I cannot just boot all three nodes from the same boot and root filesystems since they are not read-only. And I don’t want to maintain a copy of these for each node. But this is a solved problem - Docker already lets you spin up multiple containers from a single base image. So I’ll just do <a href="https://docs.docker.com/storage/storagedriver/overlayfs-driver/#how-the-overlay2-driver-works">what Docker does</a> - create <a href="https://www.kernel.org/doc/html/latest/filesystems/overlayfs.html">OverlayFS</a> for each node using raspbian-root and raspbian-boot as my lower directories. I’ll share them over NFS like before.</p>
<p>Configuration for one of the nodes is below. Other two nodes follow the same pattern. Note that I moved raspbian-root and raspbian-boot to a USB hard drive (mounted at <code>/mnt</code>) to get better r/w performance. dc-a6-32-XX-XX-XX is the MAC address of the node. I’m using <code>tftp-unique-root=mac</code> option in <code>dnsmasq</code> to maintain a separate boot environment for each node based on its MAC address.</p>
<div><pre><code data-lang="bash">$ mount -t overlay nog-boot -o lowerdir<span>=</span>/mnt/raspbian-boot,upperdir<span>=</span>/mnt/upper/nog-boot,workdir<span>=</span>/mnt/work/nog-boot -o nfs_export<span>=</span>on -o index<span>=</span>on -o redirect_dir<span>=</span>nofollow /tftpboot/dc-a6-32-XX-XX-XX

$ mount -t overlay nog-root -o lowerdir<span>=</span>/mnt/raspbian-root,upperdir<span>=</span>/mnt/work/nog-root,workdir<span>=</span>/mnt/work/nog-root -o nfs_export<span>=</span>on -o index<span>=</span>on -o redirect_dir<span>=</span>nofollow /nfs/nog

$ cat /tftpboot/dc-a6-32-XX-XX-XX/cmdline.txt
console<span>=</span>serial0,115200 console<span>=</span>tty1 root<span>=</span>/dev/nfs nfsroot<span>=</span>&lt;IP addr&gt;:/nfs/nog,vers<span>=</span>4.1,proto<span>=</span>tcp rw ip<span>=</span>dhcp rootwait elevator<span>=</span>deadline
</code></pre></div><p>(In case you are wondering what <code>nog</code> is: I name my servers after planets from the Star Wars universe. Following this tradition, I’ve named the Pis Mandalore (PXE server), Nog, Ordo and Werda)</p>
<p>You are probably thinking that this worked. It did not.</p>
<p>NFS and OverlayFS did not play nice with each other. After a weekend trying to work around some weird issues, I gave up.</p>
<p>But OverlayFS is not the only copy-on-write filesystem in existence, is it? ZFS and BTRFS offer <a href="https://btrfs.wiki.kernel.org/index.php/Manpage/btrfs-subvolume">subvolumes and snapshots</a> that I can use instead. But not before I <del>procrastinate</del> spend 2 weeks deciding which one to use.</p>
<h3 id="moving-to-btrfs">Moving to BTRFS</h3>
<p>The plan is simple: I’ll create a subvolume each for raspbian-root and raspbian-boot. I’ll then create three snapshots of each subvolume - one for every node. I created a <a href="https://en.wikipedia.org/wiki/RAS_syndrome">btrfs file system</a> on my external drive and ran the following commands</p>
<div><pre><code data-lang="bash">$ btrfs subvolume create raspbian-root
$ btrfs subvolume create raspbian-boot

<span># Repeat the following for each node changing folder names as necessary</span>
$ btrfs subvolume snapshot raspbian-boot nog-boot
$ btrfs subvolume snapshot raspbian-root nog-root
$ mount --bind /mnt/nog-boot /tftpboot/dc-a6-32-XX-XX-XX
$ mount --bind /mnt/nog-root /nfs/nog

<span># Don’t forget to edit cmdline.txt for each node</span>
$ cat /tftpboot/dc-a6-32-XX-XX-XX/cmdline.txt
console<span>=</span>serial0,115200 console<span>=</span>tty1 root<span>=</span>/dev/nfs nfsroot<span>=</span>&lt;IP addr&gt;:/nfs/nog,vers<span>=</span>4.1,proto<span>=</span>tcp rw ip<span>=</span>dhcp rootwait elevator<span>=</span>deadline
</code></pre></div><p>Well, this worked! I have a Pi running without an SD card!! Now all I have to do is create systemd unit files to start all required services and mount snapshots. I can finally start working on my project.</p>
<p>Wait a minute. Take a closer look at the output of <code>cat /tftpboot/dc-a6-32-XX-XX-XX/cmdline.txt</code>.
If you are like me, you will realize for the first time that <code>root=</code> in this file defines where the root filesystem will be mounted from. Right now, we are telling it to mount from <code>/dev/nfs</code>. What if I attach an external drive and set <code>root=</code> to point to the external drive?</p>
<h3 id="network-booting-into-a-usb-hard-drive">Network booting into a USB hard drive</h3>
<p>RPi 4 cannot directly boot from a USB drive. As in - it cannot find <code>/boot</code> on a USB drive when powering on. But what if we provide <code>/boot</code> with network boot and mount <code>/</code> from a USB drive using <code>cmdline.txt</code>? Time to test.</p>
<p>I copied raspbian-root to a USB drive, edited <code>fstab</code> to mount <code>/</code> using the partition’s PARTUUID and connected it to Nog. I then updated the contents of <code>/tftpboot/dc-a6-32-XX-XX-XX/cmdline.txt</code>.</p>
<div><pre><code data-lang="bash">$ cat /tftpboot/dc-a6-32-XX-XX-XX/cmdline.txt
 console<span>=</span>serial0,115200 console<span>=</span>tty1 root<span>=</span>PARTUUID<span>=</span>c1f95d14-01 rootfstype<span>=</span>ext4 elevator<span>=</span>deadline fsck.repair<span>=</span>yes rootwait
</code></pre></div><p>After a couple of reboots, it worked! I now have a RPi 4 running off a USB hard drive!</p>
<h3 id="what-did-i-gain">What did I gain?</h3>
<p>Let’s start with what I was looking for. All I wanted was to not deal with SD cards because they are slow and unreliable. Reliability is relative - everything fails at some point. But a decent quality USB hard drive will likely outlive an SD card. So let’s just look at some read/write performance numbers and see how they compare.</p>
<div><pre><code data-lang="bash">$ sync; dd <span>if</span><span>=</span>/dev/zero of<span>=</span>twogeefile bs<span>=</span>1M count<span>=</span>2048; sync  <span># Write performance</span>
$ sudo sh -c <span>"sync &amp;&amp; echo 3 &gt; /proc/sys/vm/drop_caches"</span>
$ dd <span>if</span><span>=</span>twogeefile of<span>=</span>/dev/null bs<span>=</span>1M count<span>=</span><span>2048</span>              <span># Read performance</span>
</code></pre></div><table>
<thead>
<tr>
<th>Storage</th>
<th>Read (MB/s)</th>
<th>Write (MB/s)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Sandisk Ultra MicroSDXC Class 10</td>
<td>45.7</td>
<td>20.2</td>
</tr>
<tr>
<td>Network Boot with BTRFS</td>
<td>63.3</td>
<td>18.8</td>
</tr>
<tr>
<td>/ mounted from USB hard drive</td>
<td>113.0</td>
<td>92.7</td>
</tr>
</tbody>
</table>
<p>With network boot, I was able to get read and write speeds similar to a class 10 SD card. Note that the boot images are hosted on a USB hard drive connected to Mandalore (PXE server). NFS seems to be the bottleneck here - raw r/w speeds of the hard drive are much better than this. All Pis are connected to Netgear’s 8 port gigabit ethernet switch.</p>
<p>To no one’s surprise, things improve considerably when Pis are running off a USB hard disk. Note that the external drives I used are 5400RPM hard disks repurposed from very old MacBooks. I bought them on eBay for $10 a pop. YMMV.</p>
<h3 id="current-setup">Current setup</h3>
<p>Right now, I have Mandalore booting from an SD card and <code>/</code> mounted from a USB hard disk. Nog, Ordo and Werda fetch <code>/boot</code> from Mandalore over the network and <code>/</code> mounted from a USB hard disk.</p>
<p><img src="https://blog.mostlypointless.dev/img/pi-cluster.jpg" alt="from top to bottom - Mandalore, Nog, Ordo, Werda"></p>
<p>I can finally start working on my proj… wait, what?</p>
<p><a href="https://www.tomshardware.com/how-to/boot-raspberry-pi-4-usb">A new beta firmware is out for RPi 4 that lets you boot from USB drives directly.</a></p>
<p>Oh well…</p>
<p>¯\_(ツ)_/¯</p>
<p><em><strong>Update:</strong> This post was discussed on <a href="https://news.ycombinator.com/item?id=23666564">Hacker News</a>. As jordybg <a href="https://news.ycombinator.com/item?id=23667247">points out</a>, USB boot is no longer “beta” and is available in the latest (2020-06-15) “stable” firmware release.</em></p>

        
    </article>
</div></div>]]>
            </description>
            <link>https://blog.mostlypointless.dev/posts/net-boot-rpi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23666564</guid>
            <pubDate>Sun, 28 Jun 2020 03:28:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WebTransport API]]>
            </title>
            <description>
<![CDATA[
Score 111 | Comments 62 (<a href="https://news.ycombinator.com/item?id=23666364">thread link</a>) | @Jarred
<br/>
June 27, 2020 | https://wicg.github.io/web-transport/ | <a href="https://web.archive.org/web/*/https://wicg.github.io/web-transport/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
   <h2 data-level="1" id="introduction"><span>1. </span><span>Introduction</span><a href="#introduction"></a></h2>
   <p><em>This section is non-normative.</em></p>
   <p>This specification uses pluggable protocols, with QUIC <a data-link-type="biblio" href="#biblio-quic-transport">[QUIC-TRANSPORT]</a> as
one such protocol, to send data to and receive data from servers. It can be
used like WebSockets but with support for multiple streams, unidirectional
streams, out-of-order delivery, and reliable as well as unreliable transport.</p>
   <p role="note"><span>Note:</span> The API presented in this specification represents a preliminary proposal
based on work-in-progress within the IETF QUIC WG. Since the QUIC transport
specification is a work-in-progress, both the protocol and API are likely to
change significantly going forward.</p>
   <h2 data-level="2" id="conformance"><span>2. </span><span>Conformance</span><a href="#conformance"></a></h2>
   <p>As well as sections marked as non-normative, all authoring guidelines,
diagrams, examples, and notes in this specification are non-normative.
Everything else in this specification is normative.</p>
   <p>The key words <em>MUST</em> and <em>SHOULD</em> are to be interpreted as described in <a data-link-type="biblio" href="#biblio-rfc2119">[RFC2119]</a>.</p>
   <p>This specification defines conformance criteria that apply to a single product:
the user agent that implements the interfaces that it contains.</p>
   <p>Conformance requirements phrased as algorithms or specific steps may be
implemented in any manner, so long as the end result is equivalent. (In
particular, the algorithms defined in this specification are intended to be
easy to follow, and not intended to be performant.)</p>
   <p>Implementations that use ECMAScript to implement the APIs defined in this
specification MUST implement them in a manner consistent with the ECMAScript
Bindings defined in the Web IDL specification <a data-link-type="biblio" href="#biblio-webidl">[WEBIDL]</a>, as this
specification uses that specification and terminology.</p>
   <h2 data-level="3" id="terminology"><span>3. </span><span>Terminology</span><a href="#terminology"></a></h2>
   <p>The <code><a data-link-type="idl" href="https://html.spec.whatwg.org/multipage/webappapis.html#eventhandler" id="ref-for-eventhandler">EventHandler</a></code> interface, representing a callback used for event
handlers, and the <code><a data-link-type="idl" href="https://html.spec.whatwg.org/multipage/webappapis.html#errorevent" id="ref-for-errorevent">ErrorEvent</a></code> interface are defined in <a data-link-type="biblio" href="#biblio-html">[HTML]</a>.</p>
   <p>The concepts <a data-link-type="dfn" href="https://html.spec.whatwg.org/multipage/webappapis.html#queue-a-task" id="ref-for-queue-a-task">queue a task</a> and <a data-link-type="dfn" href="https://html.spec.whatwg.org/multipage/webappapis.html#networking-task-source" id="ref-for-networking-task-source">networking task source</a> are defined in <a data-link-type="biblio" href="#biblio-html">[HTML]</a>.</p>
   <p>The terms <a data-link-type="dfn" href="https://dom.spec.whatwg.org/#concept-event" id="ref-for-concept-event">event</a>, <a data-link-type="dfn" href="https://html.spec.whatwg.org/multipage/webappapis.html#event-handlers" id="ref-for-event-handlers">event handlers</a> and <a data-link-type="dfn" href="https://html.spec.whatwg.org/multipage/webappapis.html#event-handler-event-type" id="ref-for-event-handler-event-type">event handler event types</a> are
defined in <a data-link-type="biblio" href="#biblio-html">[HTML]</a>.</p>
   <p>When referring to exceptions, the terms <a data-link-type="dfn" href="https://heycam.github.io/webidl/#dfn-throw" id="ref-for-dfn-throw">throw</a> and <a data-link-type="dfn" href="https://heycam.github.io/webidl/#dfn-create-exception" id="ref-for-dfn-create-exception">create</a> are defined in <a data-link-type="biblio" href="#biblio-webidl">[WEBIDL]</a>.</p>
   <p>The terms <a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects">fulfilled</a>, <a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects①">rejected</a>, <a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects②">resolved</a>, <a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects③">pending</a> and <a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects④">settled</a> used in the context of Promises are defined in <a data-link-type="biblio" href="#biblio-ecmascript-60">[ECMASCRIPT-6.0]</a>.</p>
   <p>The terms <code><a data-link-type="idl" href="https://streams.spec.whatwg.org/#readablestream" id="ref-for-readablestream">ReadableStream</a></code> and <code><a data-link-type="idl" href="https://streams.spec.whatwg.org/#writablestream" id="ref-for-writablestream">WritableStream</a></code> are defined in <a data-link-type="biblio" href="#biblio-whatwg-streams">[WHATWG-STREAMS]</a>.  Note that despite sharing the name "stream", these are
distinct from the IncomingStream, OutgoingStream, and BidirectionalStream
defined here. The IncomingStream, OutgoingStream, and BidirectionalStream
defined here correspend to a higher level of abstraction that contain and
depend on the lower-level concepts of "streams" defined in <a data-link-type="biblio" href="#biblio-whatwg-streams">[WHATWG-STREAMS]</a>.</p>
   <h2 data-level="4" id="unidirectional-streams-transport"><span>4. </span><span><code>UnidirectionalStreamsTransport</code> Mixin</span><a href="#unidirectional-streams-transport"></a></h2>
   <p>A <dfn data-dfn-type="interface" data-export="" id="unidirectionalstreamstransport"><code>UnidirectionalStreamsTransport</code></dfn> can send and receive
unidirectional streams.  Data within a stream is delivered in order, but data
between streams may be delivered out of order.  Data is generally sent
reliably, but retransmissions may be disabled or the stream may aborted to
produce a form of unreliability.  All stream data is encrypted and
congestion-controlled.</p>
<pre><c- b="">interface</c-> <c- b="">mixin</c-> <a data-link-type="interface" href="#unidirectionalstreamstransport" id="ref-for-unidirectionalstreamstransport"><c- g="">UnidirectionalStreamsTransport</c-></a> {
  <c- b="">Promise</c->&lt;<a data-link-type="idl-name" href="#sendstream" id="ref-for-sendstream"><c- n="">SendStream</c-></a>&gt; <a data-link-type="method" href="#dom-unidirectionalstreamstransport-createsendstream" id="ref-for-dom-unidirectionalstreamstransport-createsendstream"><c- g="">createSendStream</c-></a>(<c- b="">optional</c-> <a data-link-type="idl-name" href="#dictdef-sendstreamparameters" id="ref-for-dictdef-sendstreamparameters"><c- n="">SendStreamParameters</c-></a> <dfn data-dfn-for="UnidirectionalStreamsTransport/createSendStream(parameters), UnidirectionalStreamsTransport/createSendStream()" data-dfn-type="argument" data-export="" id="dom-unidirectionalstreamstransport-createsendstream-parameters-parameters"><code><c- g="">parameters</c-></code><a href="#dom-unidirectionalstreamstransport-createsendstream-parameters-parameters"></a></dfn> = {});
  <a data-link-type="idl-name" href="https://streams.spec.whatwg.org/#readablestream" id="ref-for-readablestream①"><c- n="">ReadableStream</c-></a> <a data-link-type="method" href="#dom-unidirectionalstreamstransport-receivestreams" id="ref-for-dom-unidirectionalstreamstransport-receivestreams"><c- g="">receiveStreams</c-></a>();
};
</pre>
   <h3 data-level="4.1" id="#unidirectional-streams-transport-methods"><span>4.1. </span><span>Methods</span><a href="#%23unidirectional-streams-transport-methods"></a></h3>
   <dl>
    <dt data-md=""><dfn data-dfn-for="UnidirectionalStreamsTransport" data-dfn-type="method" data-export="" data-lt="createSendStream(parameters)|createSendStream()" id="dom-unidirectionalstreamstransport-createsendstream"><code>createSendStream()</code></dfn>
    </dt><dd data-md="">
     <p>Creates a <code><a data-link-type="idl" href="#sendstream" id="ref-for-sendstream①">SendStream</a></code> object.</p>
     <p>When <code>createSendStream()</code> method is called, the user agent MUST run the
 following steps:</p>
     <ol>
      <li data-md="">
       <p>Let <var>transport</var> be the <code>UnidirectionalStreamsTransport</code> on which <code>createSendStream</code> is invoked.</p>
      </li><li data-md="">
       <p>If <var>transport</var>’s <code><a data-link-type="idl" href="#dom-webtransport-state" id="ref-for-dom-webtransport-state">state</a></code> is <code>"closed"</code> or <code>"failed"</code>,
  immediately return a new <a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects⑤">rejected</a> promise with a newly created <code><a data-link-type="idl" href="https://heycam.github.io/webidl/#invalidstateerror" id="ref-for-invalidstateerror">InvalidStateError</a></code> and abort these steps.</p>
      </li><li data-md="">
       <p>Let <var>p</var> be a new promise.</p>
      </li><li data-md="">
       <p>Return <var>p</var> and continue the following steps in background.</p>
      </li><li data-md="">
       <p><a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects⑥">Resolve</a> <var>p</var> with a newly created <code><a data-link-type="idl" href="#sendstream" id="ref-for-sendstream②">SendStream</a></code> object and <a data-link-type="dfn" href="#add-the-sendstream" id="ref-for-add-the-sendstream">add the
  SendStream</a> to <var>transport</var> when all of the following conditions are met:</p>
       <ol>
        <li data-md="">
         <p>The <var>transport</var>’s <code><a data-link-type="idl" href="#dom-webtransport-state" id="ref-for-dom-webtransport-state①">state</a></code> has transitioned to <code>"connected"</code>.</p>
        </li><li data-md="">
         <p>Stream creation flow control is not being violated by exceeding the
  max stream limit set by the remote endpoint.  For QUIC, this is
  specified in <a data-link-type="biblio" href="#biblio-quic-transport">[QUIC-TRANSPORT]</a>.</p>
        </li><li data-md="">
         <p><var>p</var> has not been <a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects⑦">settled</a>.</p>
       </li></ol>
      </li><li data-md="">
       <p><a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects⑧">Reject</a> <var>p</var> with a newly created <code><a data-link-type="idl" href="https://heycam.github.io/webidl/#invalidstateerror" id="ref-for-invalidstateerror①">InvalidStateError</a></code> when all of
  the following conditions are met:</p>
       <ol>
        <li data-md="">
         <p>The <var>transport</var>’s state transitions to <code>"closed"</code> or <code>"failed"</code>.</p>
        </li><li data-md="">
         <p><var>p</var> has not been <a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects⑨">settled</a>.</p>
       </li></ol>
     </li></ol>
    </dd><dt data-md=""><dfn data-dfn-for="UnidirectionalStreamsTransport" data-dfn-type="method" data-export="" id="dom-unidirectionalstreamstransport-receivestreams"><code>receiveStreams()</code></dfn>
    </dt><dd data-md="">
     <p>Returns a <code><a data-link-type="idl" href="https://streams.spec.whatwg.org/#readablestream" id="ref-for-readablestream②">ReadableStream</a></code> of <code><a data-link-type="idl" href="#receivestream" id="ref-for-receivestream">ReceiveStream</a></code>s that have been received
 from the remote host.</p>
     <p>When <code>receiveStreams</code> is called, the user agent MUST run the following
 steps:</p>
     <ol>
      <li data-md="">
       <p>Let <var>transport</var> be the <code>UnidirectionalStreamsTransport</code> on which <code>receiveStreams</code> is invoked.</p>
      </li><li data-md="">
       <p>Return the value of the <code><a data-link-type="idl" href="#dom-quictransport-receivedstreams-slot" id="ref-for-dom-quictransport-receivedstreams-slot">[[ReceivedStreams]]</a></code> internal slot.</p>
      </li><li data-md="">
       <p>For each unidirectional stream received, create a corresponding <code><a data-link-type="idl" href="#incomingstream" id="ref-for-incomingstream">IncomingStream</a></code> and insert it into <code><a data-link-type="idl" href="#dom-quictransport-receivedstreams-slot" id="ref-for-dom-quictransport-receivedstreams-slot①">[[ReceivedStreams]]</a></code>. As data
  is received over the unidirectional stream, insert that data into the
  corresponding <code>IncomingStream</code>.  When the remote side closes or aborts
  the stream, close or abort the corresponding <code>IncomingStream</code>.</p>
     </li></ol>
   </dd></dl>
   <h3 data-level="4.2" id="#unidirectional-streams-transport-procedures"><span>4.2. </span><span>Procedures</span><a href="#%23unidirectional-streams-transport-procedures"></a></h3>
   <h4 data-level="4.2.1" id="add-sendstream"><span>4.2.1. </span><span>Add SendStream to UnidirectionalStreamsTransport</span><a href="#add-sendstream"></a></h4>
   
   <h3 data-level="4.3" id="send-stream-parameters"><span>4.3. </span><span>SendStreamParameters Dictionary</span><a href="#send-stream-parameters"></a></h3>
   <p>The <dfn data-dfn-type="dictionary" data-export="" id="dictdef-sendstreamparameters"><code>SendStreamParameters</code></dfn> dictionary includes information
relating to stream configuration.</p>
<pre><c- b="">dictionary</c-> <a data-link-type="dictionary" href="#dictdef-sendstreamparameters" id="ref-for-dictdef-sendstreamparameters①"><c- g="">SendStreamParameters</c-></a> {
};
</pre>
   <h2 data-level="5" id="bidirectional-streams-transport"><span>5. </span><span><code>BidirectionalStreamsTransport</code> Mixin</span><a href="#bidirectional-streams-transport"></a></h2>
   <p>A <dfn data-dfn-type="interface" data-export="" id="bidirectionalstreamstransport"><code>BidirectionalStreamsTransport</code></dfn> can send and receive
bidirectional streams.  Data within a stream is delivered in order, but data
between streams may be delivered out of order. Data is generally sent reliably,
but retransmissions may be disabled or the stream may aborted to produce a form
of unreliability.  All stream data is encrypted and congestion-controlled.</p>
<pre><c- b="">interface</c-> <c- b="">mixin</c-> <a data-link-type="interface" href="#bidirectionalstreamstransport" id="ref-for-bidirectionalstreamstransport"><c- g="">BidirectionalStreamsTransport</c-></a> {
    <c- b="">Promise</c->&lt;<a data-link-type="idl-name" href="#bidirectionalstream" id="ref-for-bidirectionalstream"><c- n="">BidirectionalStream</c-></a>&gt; <a data-link-type="method" href="#dom-bidirectionalstreamstransport-createbidirectionalstream" id="ref-for-dom-bidirectionalstreamstransport-createbidirectionalstream"><c- g="">createBidirectionalStream</c-></a>();
    <a data-link-type="idl-name" href="https://streams.spec.whatwg.org/#readablestream" id="ref-for-readablestream③"><c- n="">ReadableStream</c-></a> <a data-link-type="method" href="#dom-bidirectionalstreamstransport-receivebidirectionalstreams" id="ref-for-dom-bidirectionalstreamstransport-receivebidirectionalstreams"><c- g="">receiveBidirectionalStreams</c-></a>();
};
</pre>
   <h3 data-level="5.1" id="#bidirectional-streams-transport-methods"><span>5.1. </span><span>Methods</span><a href="#%23bidirectional-streams-transport-methods"></a></h3>
   <dl>
    <dt data-md=""><dfn data-dfn-for="BidirectionalStreamsTransport" data-dfn-type="method" data-export="" id="dom-bidirectionalstreamstransport-createbidirectionalstream"><code>createBidirectionalStream()</code></dfn>
    </dt><dd data-md="">
     <p>Creates a <code><a data-link-type="idl" href="#bidirectionalstream" id="ref-for-bidirectionalstream①">BidirectionalStream</a></code> object.</p>
     <p>When <code>createBidirectionalStream</code> is called, the user agent MUST run the
 following steps:</p>
     <ol>
      <li data-md="">
       <p>Let <var>transport</var> be the <code><a data-link-type="idl" href="#bidirectionalstreamstransport" id="ref-for-bidirectionalstreamstransport①">BidirectionalStreamsTransport</a></code> on which <code><a data-link-type="idl" href="#dom-bidirectionalstreamstransport-createbidirectionalstream" id="ref-for-dom-bidirectionalstreamstransport-createbidirectionalstream①">createBidirectionalStream</a></code> is invoked.</p>
      </li><li data-md="">
       <p>If <var>transport</var>’s <code><a data-link-type="idl" href="#dom-webtransport-state" id="ref-for-dom-webtransport-state②">state</a></code> is <code>"closed"</code> or <code>"failed"</code>,
  immediately return a new <a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects①⓪">rejected</a> promise with a newly created <code><a data-link-type="idl" href="https://heycam.github.io/webidl/#invalidstateerror" id="ref-for-invalidstateerror②">InvalidStateError</a></code> and abort these steps.</p>
      </li><li data-md="">
       <p>If <var>transport</var>’s <code><a data-link-type="idl" href="#dom-webtransport-state" id="ref-for-dom-webtransport-state③">state</a></code> is <code>"connected"</code>, immediately
  return a new <a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects①①">fulfilled</a> promise with a newly created <code><a data-link-type="idl" href="#bidirectionalstream" id="ref-for-bidirectionalstream②">BidirectionalStream</a></code> object, <a data-link-type="dfn" href="#add-the-bidirectionalstream" id="ref-for-add-the-bidirectionalstream">add the BidirectionalStream</a> to the
  transport and abort these steps.</p>
      </li><li data-md="">
       <p>Let <var>p</var> be a new promise.</p>
      </li><li data-md="">
       <p>Return <var>p</var> and continue the following steps in background.</p>
      </li><li data-md="">
       <p><a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects①②">Resolve</a> <var>p</var> with a newly created <code><a data-link-type="idl" href="#bidirectionalstream" id="ref-for-bidirectionalstream③">BidirectionalStream</a></code> object and <a data-link-type="dfn" href="#add-the-bidirectionalstream" id="ref-for-add-the-bidirectionalstream①">add the BidirectionalStream</a> to <var>transport</var> when all of the following
  conditions are met:</p>
       <ol>
        <li data-md="">
         <p>The <var>transport</var>’s <code><a data-link-type="idl" href="#dom-webtransport-state" id="ref-for-dom-webtransport-state④">state</a></code> has transitioned to <code>"connected"</code>.</p>
        </li><li data-md="">
         <p>Stream creation flow control is not being violated by exceeding the
  max stream limit set by the remote endpoint. For QUIC, this is
  specified in <a data-link-type="biblio" href="#biblio-quic-transport">[QUIC-TRANSPORT]</a>.</p>
        </li><li data-md="">
         <p><var>p</var> has not been <a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects①③">settled</a>.</p>
       </li></ol>
      </li><li data-md="">
       <p><a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects①④">Reject</a> <var>p</var> with a newly created <code><a data-link-type="idl" href="https://heycam.github.io/webidl/#invalidstateerror" id="ref-for-invalidstateerror③">InvalidStateError</a></code> when all of
  the following conditions are met:</p>
       <ol>
        <li data-md="">
         <p>The <var>transport</var>’s state transitions to <code>"closed"</code> or <code>"failed"</code>.</p>
        </li><li data-md="">
         <p><var>p</var> has not been <a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects①⑤">settled</a>.</p>
       </li></ol>
     </li></ol>
    </dd><dt data-md=""><dfn data-dfn-for="BidirectionalStreamsTransport" data-dfn-type="method" data-export="" id="dom-bidirectionalstreamstransport-receivebidirectionalstreams"><code>receiveBidirectionalStreams()</code></dfn>
    </dt><dd data-md="">
     <p>Returns a <code><a data-link-type="idl" href="https://streams.spec.whatwg.org/#readablestream" id="ref-for-readablestream④">ReadableStream</a></code> of <code><a data-link-type="idl" href="#bidirectionalstream" id="ref-for-bidirectionalstream④">BidirectionalStream</a></code>s that have been
 received from the remote host.</p>
     <p>When <code>receiveBidirectionalStreams</code> method is called, the user agent MUST run
 the following steps:</p>
     <ol>
      <li data-md="">
       <p>Let <var>transport</var> be the <code>BidirectionalStreamsTransport</code> on which <code>receiveBidirectionalStreams</code> is invoked.</p>
      </li><li data-md="">
       <p>Return the value of the <code><a data-link-type="idl" href="#dom-quictransport-receivedbidirectionalstreams-slot" id="ref-for-dom-quictransport-receivedbidirectionalstreams-slot">[[ReceivedBidirectionalStreams]]</a></code> internal slot.</p>
      </li><li data-md="">
       <p>For each bidirectional stream received, create a corresponding <code><a data-link-type="idl" href="#bidirectionalstream" id="ref-for-bidirectionalstream⑤">BidirectionalStream</a></code> and insert it into <code><a data-link-type="idl" href="#dom-quictransport-receivedbidirectionalstreams-slot" id="ref-for-dom-quictransport-receivedbidirectionalstreams-slot①">[[ReceivedBidirectionalStreams]]</a></code>.
  As data is received over the bidirectional stream, insert that data into the
  corresponding <code><a data-link-type="idl" href="#bidirectionalstream" id="ref-for-bidirectionalstream⑥">BidirectionalStream</a></code>.  When the remote side closes or aborts
  the stream, close or abort the corresponding <code><a data-link-type="idl" href="#bidirectionalstream" id="ref-for-bidirectionalstream⑦">BidirectionalStream</a></code>.</p>
     </li></ol>
   </dd></dl>
   <h3 data-level="5.2" id="#bidirectional-streams-transport-procedures"><span>5.2. </span><span>Procedures</span><a href="#%23bidirectional-streams-transport-procedures"></a></h3>
   <h4 data-level="5.2.1" id="add-bidirectionalstream"><span>5.2.1. </span><span>Add BidirectionalStream to BidirectionalStreamsTransport</span><a href="#add-bidirectionalstream"></a></h4>
   
   <h2 data-level="6" id="datagram-transport"><span>6. </span><span><code>DatagramTransport</code> Mixin</span><a href="#datagram-transport"></a></h2>
   <p>A <dfn data-dfn-type="interface" data-export="" id="datagramtransport"><code>DatagramTransport</code></dfn> can send and receive datagrams.
Datagrams are sent out of order, unreliably, and have a limited maximum size.
Datagrams are encrypted and congestion controlled.</p>
<pre><c- b="">interface</c-> <c- b="">mixin</c-> <a data-link-type="interface" href="#datagramtransport" id="ref-for-datagramtransport"><c- g="">DatagramTransport</c-></a> {
    <c- b="">readonly</c-> <c- b="">attribute</c-> <a data-link-type="interface" href="https://heycam.github.io/webidl/#idl-unsigned-short" id="ref-for-idl-unsigned-short"><c- b="">unsigned</c-> <c- b="">short</c-></a> <a data-link-type="attribute" data-readonly="" data-type="unsigned short" href="#dom-datagramtransport-maxdatagramsize" id="ref-for-dom-datagramtransport-maxdatagramsize"><c- g="">maxDatagramSize</c-></a>;
    <a data-link-type="idl-name" href="https://streams.spec.whatwg.org/#writablestream" id="ref-for-writablestream①"><c- n="">WritableStream</c-></a> <a data-link-type="method" href="#dom-datagramtransport-senddatagrams" id="ref-for-dom-datagramtransport-senddatagrams"><c- g="">sendDatagrams</c-></a>();
    <a data-link-type="idl-name" href="https://streams.spec.whatwg.org/#readablestream" id="ref-for-readablestream⑤"><c- n="">ReadableStream</c-></a> <a data-link-type="method" href="#dom-datagramtransport-receivedatagrams" id="ref-for-dom-datagramtransport-receivedatagrams"><c- g="">receiveDatagrams</c-></a>();
};
</pre>
   <h3 data-level="6.1" id="datagram-transport-attributes"><span>6.1. </span><span>Attributes</span><a href="#datagram-transport-attributes"></a></h3>
   <dl>
    <dt data-md=""><dfn data-dfn-for="DatagramTransport" data-dfn-type="attribute" data-export="" id="dom-datagramtransport-maxdatagramsize"><code>maxDatagramSize</code></dfn>, <span> of type <a data-link-type="idl-name" href="https://heycam.github.io/webidl/#idl-unsigned-short" id="ref-for-idl-unsigned-short①">unsigned short</a>, readonly</span>
    </dt><dd data-md="">
     <p>The maximum size data that may be passed to <code><a data-link-type="idl" href="#dom-datagramtransport-senddatagrams" id="ref-for-dom-datagramtransport-senddatagrams①">sendDatagrams</a></code>.</p>
   </dd></dl>
   <h3 data-level="6.2" id="datagram-transport-methods"><span>6.2. </span><span>Methods</span><a href="#datagram-transport-methods"></a></h3>
   <dl>
    <dt data-md=""><dfn data-dfn-for="DatagramTransport" data-dfn-type="method" data-export="" id="dom-datagramtransport-senddatagrams"><code>sendDatagrams()</code></dfn>
    </dt><dd data-md="">
     <p>Sends datagrams that are written to the returned <code><a data-link-type="idl" href="https://streams.spec.whatwg.org/#writablestream" id="ref-for-writablestream②">WritableStream</a></code>.</p>
     <p>When <code>sendDatagrams</code> is called, the user agent MUST run the following steps:</p>
     <ol>
      <li data-md="">
       <p>Let <var>transport</var> be the <code><a data-link-type="idl" href="#datagramtransport" id="ref-for-datagramtransport①">DatagramTransport</a></code> on which <code>sendDatagram</code> is
  invoked.</p>
      </li><li data-md="">
       <p>Return the value of the <code><a data-link-type="idl" href="#dom-quictransport-sentdatagrams-slot" id="ref-for-dom-quictransport-sentdatagrams-slot">[[SentDatagrams]]</a></code> internal slot.</p>
     </li></ol>
    </dd><dt data-md=""><dfn data-dfn-for="DatagramTransport" data-dfn-type="method" data-export="" id="dom-datagramtransport-receivedatagrams"><code>receiveDatagrams()</code></dfn>
    </dt><dd data-md="">
     <p>Return the value of the <code><a data-link-type="idl" href="#dom-quictransport-receiveddatagrams-slot" id="ref-for-dom-quictransport-receiveddatagrams-slot">[[ReceivedDatagrams]]</a></code> internal slot.</p>
     <p>For each datagram received, insert it into <code><a data-link-type="idl" href="#dom-quictransport-receiveddatagrams-slot" id="ref-for-dom-quictransport-receiveddatagrams-slot①">[[ReceivedDatagrams]]</a></code>. If too
 many datagrams are queued because the stream is not being read quickly
 enough, drop datagrams to avoid queueing. Implementations should drop older
 datagrams in favor of newer datagrams. The number of datagrams to queue
 should be kept small enough to avoid adding significant latency to packet
 delivery when the stream is being read slowly (due to the reader being slow)
 but large enough to avoid dropping packets when for the stream is not read
 for short periods of time (due to the reader being paused).</p>
   </dd></dl>
   <h2 data-level="7" id="web-transport"><span>7…</span></h2></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://wicg.github.io/web-transport/">https://wicg.github.io/web-transport/</a></em></p>]]>
            </description>
            <link>https://wicg.github.io/web-transport/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23666364</guid>
            <pubDate>Sun, 28 Jun 2020 02:26:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What I learned about writing software in music school]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23665651">thread link</a>) | @while1malloc0
<br/>
June 27, 2020 | https://breaking.computer/blog/what-i-learned-about-writing-software-in-music-school | <a href="https://web.archive.org/web/*/https://breaking.computer/blog/what-i-learned-about-writing-software-in-music-school">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-layout-label="Post Body" data-type="item" id="item-5ef7bc76e6aaf04d0e009f94"><div><div><div data-block-type="44" id="block-af03afdb075005d5c151"><div><p>Like many software engineers in the industry, I don't have a Computer Science degree.
I spent my college years in music school, doing an undergraduate degree in jazz guitar performance and most of a graduate degree in music technology.
I've had the conversation about how music is like software a few times, and recently <a href="https://twitter.com/CatMcGeeCode/status/1272097365764300802?s=20">this tweet</a> got me reflecting about the things I apply in my technology career that I learned in music school.
While I might not have gone on to be a professional musician, it turns out that music school taught me many things that I still find valuable today.</p>
<p><strong>Focus on the (important) fundamentals</strong></p>
<p>Few classes in the traditional music school curriculum are as polarizing as the pair of music theory and ear training.
In a music theory class, you study the structural underpinnings of what most people refer to as Classical Music¹, and ear training is where you teach your brain to put names to the sounds that your ears hear.
I personally loved music theory and wasn't fond of ear training, and in hindsight I should have worked harder on the latter and less on the former.
Music theory tickled the same part of my brain that programming does because it's all about breaking down structures into understandable units, giving names to abstract concepts, categorization, and analysis.
In short, it's a puzzle, and it almost certainly didn't make me a better musician².
At no point when creating improvised music do you have time to think "haha, I know, I'll use an altered dominant chord here, that'll be great," and if you do you're likely not listening to the people you're playing with very closely.
Instead, you hear a sound in your head, and at the best of times your brain knows exactly how to translate that into notes on your instrument.
As you probably guessed, the class that teaches that is the one that I wasn't particularly fond of.</p>
<p>There's a similar split in usefulness when dealing with the fundamentals of programming and Compute Science.
Is it important that the average programmer can rattle off the finer points of Von Neumman architecture?
Probably not.
But it's infinitely useful to be able to pattern match problems against known-good patterns for solving them.
If I can see that a problem models well as a finite state machine in a funny hat, then a good portion of solving the problem is already done for me.
The useful fundamentals are the ones that build your ability to pattern match a problem against a solution.</p>
<p><strong>Practice what you don't know</strong></p>
<p>There's a not-so-fine line between practicing and playing what you already know is going to sound good on your instrument.
The former involves meticulously working on making new musical concepts familiar, and the latter generally sounds good.
"Noodling" on one's instrument is fun, but it's not likely to make you much better³.
In contrast, practicing new songs, scales, etc. will almost certainly make you a better musician overall.
It will just as certainly sound terrible until you've worked on it for far longer than is likely comfortable.
A little-known fact about being a professional musician is that you spend most of it sounding terrible in private so that you sound good in public.</p>
<p>There's a particular type of musician⁴ who spends all of their time running scales that they already know at faster and faster speeds.
When they play on stage you can tell what they've practiced, because their music consists of scales played really really fast.
There's a certain physicality to that that's impressive, but I've never particularly found it musically interesting.
Likewise, if I spend my career going company to company building the same application, I'm likely not to grow much as an engineer after a certain point.
It's totally reasonable to become a master at building a particular kind of thing, and I'd never begrudge anyone the economic security that can come with being able to build something that companies need really fast because you've done it a hundred times, but it's important to recognize that that's likely <em>not</em> a path towards building one's technical chops.
If you want to get better, sometimes you have to do something new.</p>
<p><strong>Listen to others</strong></p>
<p>One of the things I look back on most fondly about music school is its culture of sharing influences.
A frequent topic of conversation is what you and your friends are listening to, and what ideas you're taking from them.
The best musicians I know take in a wide variety of influences and find things to appreciate about music they don't necessarily like.
Most programmers--myself included--could stand to do more of that.
Explore outside of your own ecosystem, and if you find yourself less-than-enamored with a language or tool, try to find some good ideas in it.</p>
<p><strong>Learn your history</strong></p>
<p>From talking with people who have done them, one thing that music school does better than CS programs is the study of the history of the field⁵.
Every music school student is required to take a certain number of music history courses, and composition students--the Enterprise Architects of the music world--generally have a pretty firm understanding of when they're being imitative vs innovative.
And even in the most basic history classes--the kind that non-majors take when they think it's going to be an easy elective, not realizing that the tests are basically a game of music trivia where you've just heard all of the songs for the first time this week--there's at least an attempt to contextualize innovation even if it sounds old to us now.</p>
<p>I took a history of opera class as a sophomore, and at no point was Verdi referred to as "legacy" or "deprecated"⁶.
Contrast that with how history is viewed in tech, if it's learned at all.
Chapters in a history book written by the comments sections of popular tech industry sites would contain passages like "HTTP was originally developed by Tim Berners Lee at CERN in 1989, but no one uses that anymore because Google came out with gRPC and it's much more performant."
Taking the time to learn and contextualize the history of programming languages and tools will almost always make you better at assessing new technologies and techniques.</p>
<p><strong>There's no substitute for learning from an expert</strong></p>
<p>I was mostly a self taught guitar player until my first semester of music school, and I'm pretty sure that I improved more in those first few months than at any other point.
Experts who are good teachers will be able to watch you play and pick out the one thing that you need to do right now to improve, and then give you a bunch of other things to work on that will keep you improving for months.
You can teach yourself a lot of things, both in music and in programming, but there's no substitute for sitting down one on one with an expert and learning from them, even if you don't do it regularly.</p>
<p>If you have the chance to pair program with an expert, do it, and ask for feedback.
One of the best pairing experiences that I've ever had was with my former colleague <a href="https://twitter.com/jmileham">John Mileham</a>, who at the time was the head of architecture and interim lead of the security team at the company that we worked for.
He was working on some security code written in Go, and because I had a burgeoning interest in the language he was nice enough to invite me to pair on it together.
I was "driving", and after we implemented the feature I went through my normal process of interactively adding chunks to the git diff with <code>git add -p</code>.
After I added the second or third diff, he stopped me and said something to the effect of "Can I make an observation? You go way too fast when you code."
It was feedback that I'd never received before, and it was exactly what I needed to hear to get better.
I'd gotten to the point where I was a relatively competent programmer, but made mistakes often enough because I didn't slow down to consider code before committing it, and nobody had sat with me to watch me code so it just seemed like I was careless.
If I hadn't gotten that one on one time with an expert, I likely would have kept making the same mistakes.</p>
<p><strong>Teaching others makes you better</strong></p>
<p>One of the hardest things I've ever tried to do is teach the difference between major and minor to a child learning to play the guitar.
While programming as a career tends to be a fairly applied discipline, its foundations are largely mathematical, and that shows when you're able to explain things with relatively precise language without too many exceptions.
In contrast, major and minor are labels that were applied to patterns of sounds long after they were in common use, and as such basically every explanation has some sort of exception to it.
Major is happy, except that "happy" isn't really a universal reaction, and some "major modes" are more "floaty" or "bluesy," and the sound of a chord is all contextual anyway so major after minor might be interpreted as "triumphant" or "ironic" instead of happy, and so on.
Every explanation besides the technical one is squishy and filled with squishy exceptions, and the technical one is both likely to be uninteresting to a child--and most adults--and won't help them be a better musician.</p>
<p>Having to come up with these explanations gave me a much better understanding of the thing I was explaining, and the same is true of programming.
When you learn something, one of the barometers for how well you've learned it is how well you can teach it to others.
If you really want to learn something well, schedule a talk about it some number of weeks in the future.
It doesn't have to be a high-stakes speaking engagement; a lunch and learn with your team arguably works better.
During the course of practicing your talk, act out audience questions and regularly check in with yourself as to whether you're parroting phrases or really understand them.
By the time you give your talk, you'll either know the topic well, or be able to identify where you need more study.</p>
<p><strong>Know your audience</strong></p>
<p>Ask any working musician to play a "wedding gig," and they'll know exactly what you mean: show up early, dress nicely, …</p></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://breaking.computer/blog/what-i-learned-about-writing-software-in-music-school">https://breaking.computer/blog/what-i-learned-about-writing-software-in-music-school</a></em></p>]]>
            </description>
            <link>https://breaking.computer/blog/what-i-learned-about-writing-software-in-music-school</link>
            <guid isPermaLink="false">hacker-news-small-sites-23665651</guid>
            <pubDate>Sat, 27 Jun 2020 23:51:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Full Deno Tutorial]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 4 (<a href="https://news.ycombinator.com/item?id=23665348">thread link</a>) | @Software202
<br/>
June 27, 2020 | https://lyty.dev/deno/deno-tutorial.html | <a href="https://web.archive.org/web/*/https://lyty.dev/deno/deno-tutorial.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <p>Deno is a JavaScript/TypeScript runtime with security by default. Deno tends to substitute Node.js with a simpler, modern, and more secure runtime.</p>
<p>Deno is built on V8, Rust, and <a href="https://tokio.rs/" rel="noopener" target="_blank" title="Tokio homepage">Tokio</a>, a Rust asynchronous runtime environment. It aims to be a productive and secure scripting environment for the modern world of programming, Deno is for you!</p>
<p>If you want to learn Deno you are in the right section.</p>
<p>Our Deno tutorial is designed for simplicity. We also have tons of examples to get you in the game.</p>
<h2>Deno Example Code</h2>
<pre><code>function generateRandom(max_number) {
  return Math.ceil(Math.random() * max_number);
}

console.log(generateRandom(5));</code></pre>
<p><a href="https://lyty.dev/diy/deno-typescript-random-number-example.html" target="_blank"><i>launch</i>&nbsp; Do It Yourself</a></p>
<h2>What Can Deno Do?</h2>
<p>Deno is a JavaScript/TypeScript runtime environment, this means that you can use Deno to process server-side actions by writing JavaScript or TypeScript. Think of anything that other server-side programming languages can do.</p>
<ul>
<li>Deno can <strong>serve</strong> web pages dynamically (like PHP, NodeJS, ASP, and other server-side languages).</li>
<li>Deno can <strong>create</strong>, <strong>open</strong>, <strong>read</strong>, <strong>write</strong>, <strong>delete</strong>, and <strong>close</strong> files on the server</li>
<li>Deno can be used to <strong>build</strong> command-line based applications</li>
<li>Deno can <strong>interact</strong> with any kind of database</li>
</ul>
<h2>Why Use Deno?</h2>
<p>Think of anything other server-side programming languages can do, then think <strong>security</strong>, <strong>simplicity</strong>, and <strong>modernization </strong>with Deno.</p>
<ul>
<li>Security by default. No file, network, or environment access (unless explicitly enabled).</li>
<li>It is a TypeScript runtime, which means it supports TypeScript out of the box.</li>
<li>Comes with a single executable (<code>deno</code>).</li>
<li>Ships with built-in tools that make code inspection and formatting easy,&nbsp; the <code>deno info</code> and <code>deno fmt</code>.</li>
<li>You can bundle scripts into a single JavaScript file and more.</li>
</ul>
<h2>Who Can Learn Deno?</h2>
<p>Deno can be learned by anyone, provided that you have the basic knowledge of <strong>JavaScript </strong>especially about <code>async</code>/<code>await</code>.</p>
<h2>Comparisons to Node.js</h2>
<div><table>
<tbody>
<tr>
<td>Deno</td>
<td>NodeJS</td>
</tr>
<tr>
<td>No package manager. Uses modules referenced as URLs or file paths</td>
<td>Has a package manager called <code>npm</code></td>
</tr>
<tr>
<td>Deno does not use <code>package.json</code> in its module resolution algorithm</td>
<td>Uses <code>package.json</code></td>
</tr>
<tr>
<td>All async actions in Deno return a promise. Thus Deno provides different APIs than Node.</td>
<td>In Node.js, async can be promise or function-based</td>
</tr>
<tr>
<td>Deno requires explicit permissions for file, network, and environment access (for security purposes).</td>
<td>Node.js does not require this.</td>
</tr>
<tr>
<td>Deno always dies (exits) on uncaught errors</td>
<td>Node.js may not die.</td>
</tr>
<tr>
<td>Uses "ES Modules" and does not support <code>require()</code>. Third-party modules are imported via URLs: <code>import * as log from "https://deno.land/std/log/mod.ts";</code></td>
<td>Node.js uses both <code>require()</code> and the ES <code>import</code>.</td>
</tr>
</tbody>
</table></div>
<p>You can start our Deno Tutorial by clicking the 'Next Chapter' button below.</p>
<h2>What You Should Know at the End of This Lesson</h2>
<ul>
<li>You should understand when <strong>Deno</strong> is.</li>
<li>You should understand the core value of <strong>Deno </strong>(security, speed, and modern).</li>
<li>You should know that <strong>Deno </strong>is TypeScript-code and the standard file extensions are <code>.js</code> and&nbsp;<code>.ts</code></li>
</ul>
  
</div></div>]]>
            </description>
            <link>https://lyty.dev/deno/deno-tutorial.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23665348</guid>
            <pubDate>Sat, 27 Jun 2020 22:55:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[“Fast Startup Growth” Is Killing Innovation Softly]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23664871">thread link</a>) | @utkarsh_apoorva
<br/>
June 27, 2020 | https://blog.lightcat.io/fast-startup-growth/ | <a href="https://web.archive.org/web/*/https://blog.lightcat.io/fast-startup-growth/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <p>It's a bit of a counterpoint.</p><p>I am a tech entrepreneur. I am supposed to dream Hypergrowth.</p><p>But lately, disturbed as I am with 2020 itself, I started to think - why are things the way they are. </p><h2 id="two-types-of-companies">Two Types of Companies</h2><p>There are two types of companies. Those that are designed to create wealth for founders and employees, and the others designed to create wealth for a Fund. Don't get me wrong - most companies end up doing neither - and some will do both. But every company is <em>designed</em> to do ONE and ONLY ONE of those things.</p><p>This is not just my opinion.</p><p>Paul Graham wrote in "Startup = Growth" that a startup is a company <em>designed</em> to grow very fast. One question to ask is - to what destination exactly? And why should a company <em>want</em> to grow so fast?</p><p>Let's try to unpack Hypergrowth. And let's borrow the framework from Daniel Kahneman, to do so.</p><h2 id="hypergrowth-tickles-the-market-s-fast-thinking-brain">Hypergrowth Tickles the Market's Fast Thinking Brain</h2><p>Hypergrowth is the business equivalent of your fast brain - the market reacts as if by instinct. Growing &nbsp;fast helps the company cover a good market share before competitors take note and 'copy-cats' come into the picture. Growing fast leads to a new behaviour (or a slight modification in the old one) getting adopted by a very large number of people, in a pretty short time. </p><h3 id="just-f-g-download-the-app-stop-thinking">Just F*****G Download The App, Stop Thinking</h3><p>The slow brain of the market would pause, think, analyse, and might decide NOT to adopt the new behaviour. It might ask questions about privacy, addiction, security, safety, life ... the fast brain of the market does not analyse. </p><p>It jumps instinctively to the shiny new app because it's trendy to do so. From a business perspective, you do not want the market to critique what you have built, you want them to adopt it.</p><p>What happens when the slow brain does kick in and start asking questions later? By that time, the behaviour is so well set, that it is hard to break. So it is likely to stick. Think about people criticising, and then using Facebook. As if they're addicted.</p><blockquote>Without hypergrowth and it's related behavioural sciences, we would still have Facebook, Instagram and Whatsapp, but probably with lesser adoption, and in slightly different avatars.</blockquote><h2 id="hypergrowth-leads-to-winner-take-all-markets">Hypergrowth Leads to Winner Take All Markets</h2><p>Another thing that hypergrowth helps do is make money. To understand what speed has got to do with capital, we need to understand <em>Extrapolation</em>.</p><p>We love to extrapolate. From debates about race, to forest fires to climate change - everywhere you can see this happening. An easy way to detect careless extrapolation is the phrase "at this rate ... X will happen" - assuming that "the rate" is a universal constant.</p><p>We love extrapolation so much, that with took this word and created a special symbol to represent it. And then we made it the most important symbol of modern times. That symbol, of course is "@" or "at the rate of.." . Yeah yeah. I know, it was meant for some other purpose - but even in the old definition, the rate is implied to be a constant - even if for a small duration. But I digress.</p><p>So extrapolation.</p><p>This is how it works - you grow fast - say 8x a year. That growth 'activates' a multiplier to your valuation in the private markets. That multiplier is super handy because as larger and larger funds get in on the action, smaller investors are able to exit at a profit.</p><p>And it's all great except for one thing - it creates Winner Take All markets.</p><h3 id="stop-minding-your-business-and-come-work-for-me">Stop Minding Your Business and Come Work For Me</h3><p>Hypergrowth, when adopted at large scale, creates 'Winner Take All' markets. In these markets, every small company that does something similar to the big guy, tends to die out. This leads to a large number of people, who were literally minding their own businesses, to crash, burn and work for the large corporations. </p><p>Do a few cycles of this, over a few decades, and you get an economy that is seriously debt ridden, afraid that even the remaining jobs will be taken away in the name of innovation. This society responds with mass scale knee-jerk reactions, even if for the right causes. This society gets divided into "Heroes" and "Zeroes". And when there are enough Zeroes and they are unhappy enough, it's easy for chaos to ensue. An incompetent leadership is just an icing on the cake.</p><blockquote><strong>This society responds with mass scale knee-jerk reactions, even if for the right causes. This society gets divided into "Heroes" and "Zeroes". And when there are enough Zeroes and they are unhappy enough, it's easy for chaos to ensue. An incompetent leadership is just the icing on the cake.</strong></blockquote><h2 id="hypergrowth-einstein-works-3-jobs">Hypergrowth = Einstein Works 3 Jobs</h2><p>Hypergrowth is a great concept, intellectually. But, if it is force fed to a society, it kills innovation. Because in these economies, Einstein does not work at a Patent Office. He works 3 jobs to pay his debts, and never has a moment to think about "light, energy and matter".</p><p>Other than large scale internet companies helping us take selfies, we haven't innovated much. The situation is so bad that it takes a crazy right wing billionaire (another one of my heroes) to build a battery powered car mainstream. Ford built his MVP in a f****ing garage.</p><h3 id="a-world-without-winner-take-all-markets">A World Without Winner Take All Markets</h3><p>There isn't a quick fix solution to this. But if fixed, here's what the world would look like.</p><p>There would be 10-15 Facebooks, for different niches. Most subreddits would be dedicated communities, and companies, of their own. Most markets won't be winner take all. There will be way way way more entrepreneurs than today - mostly small, and mostly "businesspeople" not innovative. Lesser debt, more healthcare. Less stress, more time. Less "me too" disruption, more real innovation. &nbsp;Less noise, more signal. But also, way lesser companies for VCs to invest in, way lesser organised Funds, way lesser ways for rich people to invest in and make even more money.</p><p>Consequently, many smart people will fill these gaps, start new funds. Invest in "me too disruptive" companies. And in a few decades, the world will be back to "let's grow fast".</p><p>But in those decades, Einstein would happen, again.</p><!--kg-card-begin: html--><div>
    <p><b>If you liked this ..</b></p><p>
    .. and would like to stay in the loop, <a href="https://mailchi.mp/c65448641adc/newsletter" target="_blank">subscribe here</a>

</p></div><!--kg-card-end: html-->
                </div>
            </section>


            


        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.lightcat.io/fast-startup-growth/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23664871</guid>
            <pubDate>Sat, 27 Jun 2020 21:36:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[$8B tree wall to stop Sahara deserting]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23664331">thread link</a>) | @miohtama
<br/>
June 27, 2020 | https://kindling.xyz/good-news/21-african-countries-are-joining-together-to-build-a-4750-mile-wall-of-trees/ | <a href="https://web.archive.org/web/*/https://kindling.xyz/good-news/21-african-countries-are-joining-together-to-build-a-4750-mile-wall-of-trees/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Nearly two dozen African nations are now committed to build and maintain the “Great Green Wall,” a chain of forests and woodlands spreading across the entire continent at the southern edge of the Sahara Desert, in the region known as the Sahel. Initially launched in 2007 by 11 countries, the initiative has now been joined by ten more. It is considered the world’s largest ecosystem restoration project by the <a href="https://www.unenvironment.org/news-and-stories/story/worlds-biggest-ecosystem-restoration-project" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">UN Environment Programme<span></span></a>.</p>
<figure></figure>
<p>The project aims to address many of the continent’s core challenges at once. Most directly, it provides a physical barrier to ward off the spread of the Sahara. The Sahara has been moving gradually south for millennia, encroaching on and disrupting local livelihoods. However <a href="https://kindling.xyz/tag/climate-change/" data-wpel-link="internal">climate change</a> has accelerated this process, creating a major economic and environmental threat to the nations of the Sahel, many of which are already among the world’s poorest and least developed. </p>
<figure><img src="https://797230.smushcdn.com/1547441/wp-content/uploads/2020/05/Least-Developed-Nations.jpg?lossy=0&amp;strip=1&amp;webp=1" alt="" srcset="https://797230.smushcdn.com/1547441/wp-content/uploads/2020/05/Least-Developed-Nations-150x84.jpg?lossy=0&amp;strip=1&amp;webp=1 150w, https://797230.smushcdn.com/1547441/wp-content/uploads/2020/05/Least-Developed-Nations.jpg?size=234x132&amp;lossy=0&amp;strip=1&amp;webp=1 234w, https://797230.smushcdn.com/1547441/wp-content/uploads/2020/05/Least-Developed-Nations.jpg?size=468x263&amp;lossy=0&amp;strip=1&amp;webp=1 468w, https://797230.smushcdn.com/1547441/wp-content/uploads/2020/05/Least-Developed-Nations.jpg?lossy=0&amp;strip=1&amp;webp=1 700w" sizes="(max-width: 700px) 100vw, 700px"><figcaption>Source: <a href="https://www.dw.com/en/to-prosper-poorest-countries-need-avenues-to-electricity/a-41472049" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">DW<span></span></a></figcaption></figure>
<p>The wall will reclaim 247 million acres of land by the year 2030, which can then be used for more economically productive purposes like agriculture and livestock. More trees will result in more rainfall being diverted back into the land, and therefore more water available to communities and ecosystems. The new trees will capture around <a href="https://time.com/5669033/great-green-wall-africa/" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">250 million metric tons of carbon ever year<span></span></a>, roughly equivalent to removing all of California’s cars from the road for more than three year. The process of planting and maintaining the wall will also create hundreds of thousands of jobs over the course of the next several years.</p>
<p>It’s a win-win-win-win!</p>
<p>The effort is estimated to cost $8 billion USD and be completed by 2030. It is currently about 15% complete.</p>
<p>I love projects like these. They just make so much sense. They provide incredible economic bang for their buck, ensuring the <a href="https://kindling.xyz/tag/sustainability/" data-wpel-link="internal">sustainability</a> of livelihoods for decades, while also employing people in the process and offering a critical solution to the <a href="https://kindling.xyz/tag/climate-crisis/" data-wpel-link="internal">climate crisis</a>. But more than that, they demonstrate the importance and viability of international cooperation at a time when nearly all of humanity’s deepest challenges are trans-boundary, requiring us to collaborate with one another, even to re-envision ourselves as all part of the same team.</p>
<p>What other major development projects might we be able to make a reality if more countries acknowledged their shared challenges and pooled their resources together toward a common goal?</p>
<div><div><div><div>
<h2>
↯ NEWSLETTER
</h2>
<p><span>News of social progress from around the world. Once a week. It's free!</span></p>





</div></div></div></div><div><div><div><div>
<h2>♥ BECOME A PATRON
</h2>
<p>Get exclusive content. Help us grow the Kindling community and deepen our impact. </p><p>Your contribution makes Kindling possible!</p>

</div></div></div></div>
</div></div>]]>
            </description>
            <link>https://kindling.xyz/good-news/21-african-countries-are-joining-together-to-build-a-4750-mile-wall-of-trees/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23664331</guid>
            <pubDate>Sat, 27 Jun 2020 20:16:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Higher Mathematics in 106 Terms]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23664235">thread link</a>) | @R3G1R
<br/>
June 27, 2020 | https://mathvault.ca/math-glossary/ | <a href="https://web.archive.org/web/*/https://mathvault.ca/math-glossary/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The language of mathematics is distinct from natural languages in that it aims to communicate abstract, logical ideas with precision and unambiguity. As a result, it is equipped with a system of specialized <strong><a aria-label="symbols (opens in a new tab)" href="https://mathvault.ca/hub/higher-math/math-symbols/" target="_blank" rel="noreferrer noopener">symbols</a></strong> and <strong>vocabularies</strong> — each with its own level of generality and formality.</p><p>Among these, there’s a particular subset of terms that is uniquely foundational and appropriate to our pursuit: the <strong>higher mathematical jargon</strong>. Loosely speaking, these are a set of specialized terms that fall into most — if not all — of the following categories:</p><ul><li>Specific to <strong>higher mathematics</strong></li><li><strong>English-looking</strong> (with a near-technical meaning)</li><li><strong>Frequently-occurring</strong></li><li><strong>Cross-disciplinary</strong> (i.e., not field-specific)</li></ul><p>In brief, these are terms that are generally accessible to most, yet still provide us with a glimpse of the world of non-miniaturized mathematics — and the way their practitioners act and think. In fact, in what follows, we’ve compiled a list of 106 such terms — along with some in-depth exploration of their <strong>definitions</strong>, <strong>examples</strong>, <strong>relevance</strong> and <strong>implications</strong>.</p><p>So if you’re ready to dive into this fascinating world that is known as mathematics, then let’s get started!</p><p>(and if you’re looking for a concise rendition of all the 106 terms featured in this glossary, then you might find the following <strong>higher math jargon mindmap</strong> both interesting and useful.)</p> <p><span><a href="#" target="_self"><span><strong>Download the 4-Page Higher Mathematical Jargon Mindmap</strong></span></a></span></p><p><img src="https://mathvault.ca/wp-content/uploads/Math-Glossary-Header-Image.png" alt="The Definitive Glossary of Higher Mathematical Jargons" width="1366" height="702" srcset="https://mathvault.ca/wp-content/uploads/Math-Glossary-Header-Image.png 1130w, https://mathvault.ca/wp-content/uploads/Math-Glossary-Header-Image-600x308.png 600w, https://mathvault.ca/wp-content/uploads/Math-Glossary-Header-Image-768x395.png 768w, https://mathvault.ca/wp-content/uploads/Math-Glossary-Header-Image-1024x526.png 1024w, https://mathvault.ca/wp-content/uploads/Math-Glossary-Header-Image-300x154.png 300w" sizes="(max-width: 1366px) 100vw, 1366px" title="Math Glossary Header Image" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201366%20702'%3E%3C/svg%3E" data-lazy-srcset="https://mathvault.ca/wp-content/uploads/Math-Glossary-Header-Image.png 1130w, https://mathvault.ca/wp-content/uploads/Math-Glossary-Header-Image-600x308.png 600w, https://mathvault.ca/wp-content/uploads/Math-Glossary-Header-Image-768x395.png 768w, https://mathvault.ca/wp-content/uploads/Math-Glossary-Header-Image-1024x526.png 1024w, https://mathvault.ca/wp-content/uploads/Math-Glossary-Header-Image-300x154.png 300w" data-lazy-src="https://mathvault.ca/wp-content/uploads/Math-Glossary-Header-Image.png"></p><h2 id="toc">Higher Mathematical Jargon — The Definitive List (106 Terms)</h2><p><span> The definitive glossary of higher mathematical jargon — from abstract nonsense, elementary proof to singularity and 101+ more. </span> <span><span>Click to Tweet</span><i></i></span></p><h2 id="abstraction"><a href="#toc">Abstraction</a></h2><p>The process of extracting the underlying <strong>structures</strong>, <strong>patterns</strong>, or <strong>properties</strong> of some mathematical objects, with the intention of generalizing these findings to a broader class of objects. These include, for example:</p><ul><li>Finding the <strong>shared properties</strong> of similar polynomials</li><li>Formalizing the <strong>general pattern</strong> of a sequence</li><li>Establishing a <a href="#otoc"><strong>one-to-one correspondence</strong></a> between two sets</li><li>Constructing an alternate <a href="#axiom"><strong>axiomatic system</strong></a> for Euclidean geometry</li></ul><p>At first, abstraction can seem a bit unappealing due to its higher cognitive demand and lack of connection to real-world phenomena. However, it can often turn out to be an integral force in bringing about a <strong>broaden applicability</strong> to a field — along with some <strong>unification</strong> in between the fields.</p><div id=""><p>Did You Know?</p><p>While abstraction is involved in pretty much all subfields of mathematics, it is particularly well-represented in fields such as <strong>abstract algebra</strong>, <strong>model theory</strong>, <strong>axiomatic set theory</strong> and <a href="#nonsense"><strong>category theory</strong></a>.</p></div><h2 id="nonsense"><a href="#toc">Abstract Nonsense</a></h2><div id="attachment_18333"><p><img aria-describedby="caption-attachment-18333" src="https://mathvault.ca/wp-content/uploads/Category-Theory-Diagram.png" alt="Category Theory: A Category with Objects and Morphisms" width="325" height="325" srcset="https://mathvault.ca/wp-content/uploads/Category-Theory-Diagram.png 800w, https://mathvault.ca/wp-content/uploads/Category-Theory-Diagram-150x150.png 150w, https://mathvault.ca/wp-content/uploads/Category-Theory-Diagram-400x400.png 400w, https://mathvault.ca/wp-content/uploads/Category-Theory-Diagram-768x768.png 768w, https://mathvault.ca/wp-content/uploads/Category-Theory-Diagram-100x100.png 100w, https://mathvault.ca/wp-content/uploads/Category-Theory-Diagram-220x220.png 220w, https://mathvault.ca/wp-content/uploads/Category-Theory-Diagram-300x300.png 300w, https://mathvault.ca/wp-content/uploads/Category-Theory-Diagram-600x600.png 600w" sizes="(max-width: 325px) 100vw, 325px" title="Category Theory Diagram" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20325%20325'%3E%3C/svg%3E" data-lazy-srcset="https://mathvault.ca/wp-content/uploads/Category-Theory-Diagram.png 800w, https://mathvault.ca/wp-content/uploads/Category-Theory-Diagram-150x150.png 150w, https://mathvault.ca/wp-content/uploads/Category-Theory-Diagram-400x400.png 400w, https://mathvault.ca/wp-content/uploads/Category-Theory-Diagram-768x768.png 768w, https://mathvault.ca/wp-content/uploads/Category-Theory-Diagram-100x100.png 100w, https://mathvault.ca/wp-content/uploads/Category-Theory-Diagram-220x220.png 220w, https://mathvault.ca/wp-content/uploads/Category-Theory-Diagram-300x300.png 300w, https://mathvault.ca/wp-content/uploads/Category-Theory-Diagram-600x600.png 600w" data-lazy-src="https://mathvault.ca/wp-content/uploads/Category-Theory-Diagram.png"></p><p id="caption-attachment-18333">A category with objects $A$, $B$, $C$ and a series of morphisms.</p></div><p>A colloquial term for <strong><a href="https://en.wikipedia.org/wiki/Category_theory" target="_blank" rel="noopener noreferrer">category theory</a></strong> (a mathematical subject dedicated to the notion of category and the formalization of <a href="#structure">mathematical structures</a>), or the methods and arguments that are related to it.</p><p><span>Since different branches of mathematics deal with different mathematical structures satisfying the definition of a category, category theory can be regarded as a <strong>unifying theory</strong> of mathematics — whose results are applicable to a wide range of disciplines.</span></p><p>In particular, if a proposition follows from abstract nonsense, then it means that its argument has more to do with the underlying categorical structure of its objects — rather than the field where it’s found. And since such arguments are often highly abstract and long-winded by nature, they are also alternatively referred to as “<strong>general abstract nonsense</strong>” or “<strong>generalized abstract nonsense</strong>“.</p><h2 id="aon"><a href="#toc">Abuse of notation</a></h2><p>The act of inadvertently or deliberately using notations in a way that’s not entirely<strong> syntactically correct</strong> — but which simplifies the exposition and makes the passage easier to understand. For example, one might say that:</p><ul><li>“$\mathbb{R}$ is distributive” — rather than “$(\mathbb{R}, +, \times)$ is distributive.”</li><li>“$3$ is differentiable” — rather than “the function defined by the rule $x \mapsto 3$ for all real $x$, is differentiable.”</li><li>“$a+b+c = c+b+a$” — rather than “$(a+b) + c = (c+b) + a$”.</li></ul><p>In the cases where the context and the assumptions are made clear and well understood, abuses of notation are usually harmless (if not actually desirable). In other cases, however, the same might not be true, and can amount to a <strong>misuse of notation</strong> — which is a faux-pas in mathematics (such as the case of $\frac{\mathrm{d}y}{\mathrm{d}x}=\frac{y}{x}$).</p><h2 id="algo"><a href="#toc">Algorithm</a></h2><p>A finite series of <a href="#welldefined">well-defined</a>, <strong>computer-implementable instructions</strong> to solve a specific set of computable problems. It takes a finite amount of initial input(s), processes them unambiguously at each operation, before returning its outputs within a finite amount of time. Some examples of algorithm in mathematics include:</p><ul><li>The <strong>Euclidean algorithm</strong> (for finding the greatest common factor of two natural numbers)</li><li><a href="https://mathvault.ca/long-division">The <strong>long division algorithm</strong> (and its variants)</a></li><li>The <strong>simplex algorithm</strong> (for finding the optimal solution under a set of linear constraints)</li></ul><p>In essence, algorithms are created to streamline the solution-finding process for a specific set of problems, though it can also remove the necessity of thinking and understanding in the process. For a a series of instructions that are quasi-algorithmic and broader in nature, the term “<strong>general procedure</strong>” is sometimes used (which, like an algorithm, could also involve some element of <a href="#heuristics">heuristics</a> or <a href="#recursion">recursion</a>).</p><h2 id="almost"><a href="#toc">Almost</a></h2><div id="attachment_18414"><p><img aria-describedby="caption-attachment-18414" src="https://mathvault.ca/wp-content/uploads/Dart-and-Board.png" alt="Dart and Board" width="225" height="225" srcset="https://mathvault.ca/wp-content/uploads/Dart-and-Board.png 225w, https://mathvault.ca/wp-content/uploads/Dart-and-Board-150x150.png 150w, https://mathvault.ca/wp-content/uploads/Dart-and-Board-100x100.png 100w, https://mathvault.ca/wp-content/uploads/Dart-and-Board-220x220.png 220w" sizes="(max-width: 225px) 100vw, 225px" title="Dart and Board" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20225%20225'%3E%3C/svg%3E" data-lazy-srcset="https://mathvault.ca/wp-content/uploads/Dart-and-Board.png 225w, https://mathvault.ca/wp-content/uploads/Dart-and-Board-150x150.png 150w, https://mathvault.ca/wp-content/uploads/Dart-and-Board-100x100.png 100w, https://mathvault.ca/wp-content/uploads/Dart-and-Board-220x220.png 220w" data-lazy-src="https://mathvault.ca/wp-content/uploads/Dart-and-Board.png"></p><p id="caption-attachment-18414">Since the actual circumference of the board has area 0, the probability of hitting it is also 0 as well (i.e., almost never).</p></div><p>A handy adverb similar to its usage in English, but can take on specific meanings depending on the context. For example:</p><ul><li>“<strong>Almost all</strong> elements in a set” usually means “all but a finite/countable amount of negligible elements in the set.”</li><li>“<strong>Almost no</strong> integer” usually means “only a finite subset of integers.”</li><li>“A property holds <strong>almost everywhere</strong> (in a measure space)” usually means “everywhere in a set except a subset of<a href="http://mathworld.wolfram.com/MeasureZero.html" target="_blank" rel="noopener noreferrer"> measure zero</a>.”</li><li>“An event occurs <strong>almost surely</strong>” usually means that “the event has a probability of 1, even though it does not include all of the possible outcomes.”</li><li>“An event occurs <strong>almost never</strong>” usually means that “the event has a probability of 0, even though it does contain some of the possible outcomes.”</li></ul><p>Here, notice that “almost” doesn’t necessarily mean that the <strong>exceptional cases</strong> are “small”, and hence one is perfectly well-justified in making claims such as “almost all real numbers are transcendental” — or that “the dart almost never lands on the circumference of the board.”</p><h2 id="ansatz"><a href="#toc">Ansatz</a></h2><p>A term of German origin meaning “initial placement of a tool at a work piece” (<a href="https://en.wikipedia.org/wiki/Ansatz" target="_blank" rel="noopener noreferrer">Wikipedia</a>), and is used in mathematics to refer to the initial, additional <strong>mathematical assumptions</strong> made to kick start the problem solving process — but which are later confirmed to be parts of the actual solution as well. Some examples of ansatz in mathematics include:</p><ul><li>The adoption of linear regression model to fit the data points (i.e., <strong>linear ansatz</strong>)</li><li>The assumption that the solutions to a differential/recurrent equation take an exponential form (<strong>exponential ansatz</strong>)</li><li>The assumption that the solution to a system of linear equations is expressible in terms of a particular vector (<strong>ansatz of particular solution</strong>).</li></ul><p>Metaphorically speaking, the use of ansatz can be liken to drawing a picture by first establishing a <strong>framework</strong>, in that if it succeeds, then the framework can be reused as an ansatz later on, but if it doesn’t, then it’s usually discarded and marked as an instance of failure.</p><h2 id="arbitrarily"><a href="#toc">Arbitrarily</a></h2><p>An adverb attached to a mathematical adjective X to make clear that something is “<strong>X with little limitation or restraint</strong>.” For example:</p><ul><li>An <strong>arbitrarily large</strong> function is a function capable of assuming values larger than any fixed choice of real number — regardless of the size of the latter.</li><li>An <strong>arbitrarily small</strong> positive sequence is a sequence capable of assuming values smaller than any fixed choice of positive real number — regardless of the “tininess” of the latter.</li><li>An <strong>arbitrarily long</strong> progression is a progression whose number of members can be made to exceed than any choice of natural number — regardless the size of the latter.</li></ul><p>In general, “arbitrarily” is a foundational term in number theory and mathematical analysis, and can also occur in other topics where some form of <strong>degree</strong> and <strong>ordering</strong> are involved (e.g., <a href="https://en.wikipedia.org/wiki/Polynomial_ring" target="_blank" rel="noopener noreferrer">polynomial ring</a>).</p><div><p><strong>Caution</strong></p><p>Don’t make the mistake in assuming that “arbitrarily” means “infinitely”! If anything, “arbitrarily” usually carries a sense of being “without bound within the finite realm.”</p></div><h2 id="arbitrary"><a href="#toc">Arbitrary</a></h2><p>An adjective used to refer to a choice made without any specific criterion or restraint (e.g., arbitrary integer, arbitrary division of a set, arbitrary permutation of a sequence). It corresponds to the term “<strong>any</strong>” and the <a href="https://mathvault.ca/hub/higher-math/math-symbols/logic-symbols/#Quantifiers" target="_blank" rel="noopener noreferrer">logical quantifier</a> $\forall$, and hints at an element of generality in the phrase where it’s found (e.g., statement $P$ holds for an arbitrary $n \in \mathbb{N}$).&nbsp;</p><div id=""><p>Arbitrary vs. Random</p><p>While “random” and “arbitrary” are often used interchangeably in informal discourses, in mathematics, “random” — unlike “arbitrary” — usually presupposes that the outcomes follow a <a href="https://mathvault.ca/hub/higher-math/math-symbols/probability-statistics-symbols/#Discrete_Probability_Distributions" target="_blank" rel="noopener noreferrer"><strong>probability distribution</strong></a>, and as such might have predictable probabilities even if the outcomes are subject to chance and unpredictability.</p></div><h2 id="axiom"><a href="#toc">Axiom</a></h2><div id="attachment_18546"><p><img aria-describedby="caption-attachment-18546" src="https://mathvault.ca/wp-content/uploads/Parallel-Postulate.png" alt="Illustration of Parallel Postulate" width="320" height="240" srcset="https://mathvault.ca/wp-content/uploads/Parallel-Postulate.png 320w, https://mathvault.ca/wp-content/uploads/Parallel-Postulate-300x225.png 300w" sizes="(max-width: 320px) 100vw, 320px" title="Parallel Postulate" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20320%20240'%3E%3C/svg%3E" data-lazy-srcset="https://mathvault.ca/wp-content/uploads/Parallel-Postulate.png 320w, https://mathvault.ca/wp-content/uploads/Parallel-Postulate-300x225.png 300w" data-lazy-src="https://mathvault.ca/wp-content/uploads/Parallel-Postulate.png"></p><p id="caption-attachment-18546">Pictorial representation of the parallel postulate</p></div><p>Axioms, also known as postulates, are mathematical premises which are assumed to be<strong>&nbsp;true</strong> and along with <a href="#def">definitions</a>, form the foundation of a <a href="#theory">mathematical <span>theory</span></a>.</p><p>In general, axioms can be divided into two types: <strong>logica</strong>l and <strong>non-logical</strong>. The logical axioms are the ones pertaining to the logical part of mathematics (e.g., $[A\rightarrow (B \wedge -B)] \rightarrow -A\,$), while the non-logical axioms are the ones pertaining to the <em>nature</em> of the theory itself (which might or might not be self-evident by nature).</p><p>For example, the <strong><a href="https://en.wikipedia.org/wiki/Parallel_postulate" target="_blank" rel="noopener noreferrer">parallel postulate</a></strong> — which stands as the most well-known (non-logical) axiom among the five in Euclidean geometry — states that:</p><blockquote><p>“If a line segment intersects two straight lines forming two interior angles on the same side that …</p></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mathvault.ca/math-glossary/">https://mathvault.ca/math-glossary/</a></em></p>]]>
            </description>
            <link>https://mathvault.ca/math-glossary/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23664235</guid>
            <pubDate>Sat, 27 Jun 2020 20:01:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lemmy, an open-source federated Reddit alternative, gets funding for development]]>
            </title>
            <description>
<![CDATA[
Score 917 | Comments 605 (<a href="https://news.ycombinator.com/item?id=23664067">thread link</a>) | @jasonbourne1901
<br/>
June 27, 2020 | https://dev.lemmy.ml/post/35293 | <a href="https://web.archive.org/web/*/https://dev.lemmy.ml/post/35293">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://dev.lemmy.ml/post/35293</link>
            <guid isPermaLink="false">hacker-news-small-sites-23664067</guid>
            <pubDate>Sat, 27 Jun 2020 19:36:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A look into bias in AI and how to combat it]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23664059">thread link</a>) | @sidjain1412
<br/>
June 27, 2020 | https://sigmoidal.io/how-to-build-inclusive-fair-ai-solutions/ | <a href="https://web.archive.org/web/*/https://sigmoidal.io/how-to-build-inclusive-fair-ai-solutions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						
						
						
						<blockquote><p>
Human history has an unfortunate record of discrimination and biases against each other that follow us from ancient times. A conscious effort towards developing inclusive and equal social systems is a necessity. In the increasingly automated world, where computers interact with humans, Artificial Intelligence gives us another shot at making the world a fairer place with equal opportunities.</p>
<p>However, machines are built by people. We are obliged to put conscious effort into making sure the AI solutions won’t carry over our mistakes.
</p></blockquote>
<p>The appeal of AI is tremendous: it can search through millions of pieces of data and use it to make forecasts that are often more accurate than ours. Automating processes with AI also seems more objective than relying on subjective (and slower) human analysis. After all, the AI  algorithm will not “dislike” your picture or assume anything based on it, especially when it is taught to ignore it completely.</p>
<p>The problem is, AI algorithms are not necessarily human-bias free. AI is designed and trained on human data, and human thinking is characterized by bias. Therefore bias is also a built-in byproduct of human-designed systems. These AI biases can echo problematic perceptions, such as the perceived superiority of certain groups. Even well-designed AI systems can still end up with a bias, entirely by accident.</p>
<p>The question is: can we prevent AI from being racist and sexist? And if we can, then could machines help us create a fairer society?</p>
<figure> <picture><source data-lazy-srcset="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/SR_HousingDiscrimination.webp 780w,https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/SR_HousingDiscrimination-300x167.webp 300w,https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/SR_HousingDiscrimination-768x428.webp 768w" sizes="(max-width: 780px) 100vw, 780px" type="image/webp"><source data-lazy-srcset="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/SR_HousingDiscrimination.jpg 780w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/SR_HousingDiscrimination-300x167.jpg 300w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/SR_HousingDiscrimination-768x428.jpg 768w" sizes="(max-width: 780px) 100vw, 780px"><img src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20780%20435'%3E%3C/svg%3E" height="435" width="780" data-lazy-srcset="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/SR_HousingDiscrimination.jpg 780w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/SR_HousingDiscrimination-300x167.jpg 300w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/SR_HousingDiscrimination-768x428.jpg 768w" data-lazy-sizes="(max-width: 780px) 100vw, 780px" data-lazy-src="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/SR_HousingDiscrimination.jpg"></picture><figcaption><strong>Source:</strong> Hyejin Kang, Shutterstock</figcaption></figure>
<h2> People and biases </h2>
<p>Let’s start from the beginning: before the machines were biased, people were. Why is that? According to the <a href="https://dictionary.cambridge.org/dictionary/english/bias" target="_blank" rel="noopener noreferrer">Cambridge Dictionary</a>, bias is <em>“the action of supporting or opposing a particular person or thing in an unfair way, because of allowing personal opinions to influence your judgment.”</em></p>
<p>Biases can be innate or learned. People may develop biases for or against an individual, a group, or a belief. It does not have to be limited to ethnicity and race; it is also gender, religion, sexual orientation, and many other characteristics that are subject to bias. </p>
<h3>Are all biases conscious?</h3>
<p>There are two types of bias: conscious (also known as explicit bias) and unconscious (also known as implicit bias). The <a href="http://perception.org/wp-content/uploads/2014/11/Transforming-Perception.pdf" target="_blank" rel="noopener noreferrer">conscious bias</a> refers to the attitude we have on a conscious level, and most of the time, it arises as to the direct result of a perceived threat.</p>
<p>The <a href="https://diversity.ucsf.edu/resources/unconscious-bias#:~:text=Unconscious%20bias%20is%20far%20more,or%20working%20under%20time%20pressure." target="_blank" rel="noopener noreferrer">unconscious bias</a> is a social stereotype about certain groups of people that a person form outside their conscious awareness. It is automatic, unintentional, deeply ingrained, and able to influence behavior. Unconscious bias is more prevalent than the conscious one. </p>
<p>According to the <a href="https://www.apa.org/research/action/speaking-of-psychology/understanding-biases" target="_blank" rel="noopener noreferrer">American Psychological Association</a>, <b>only a small proportion of Americans today are explicitly racist</b> and feel hatred towards other ethnicities and races.</p>
<p>But the majority of Americans, because they have grown up in a culture that has been historically racist in many ways and because they’re exposed to the media that are biased, associate violence, drugs, and poverty with specific groups. </p>
<figure> <picture><source data-lazy-srcset="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/shutterstock-img.webp 1537w,https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/shutterstock-img-300x200.webp 300w,https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/shutterstock-img-1024x682.webp 1024w,https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/shutterstock-img-768x512.webp 768w,https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/shutterstock-img-1536x1023.webp 1536w" sizes="(max-width: 1600px) 100vw, 1600px" type="image/webp"><source data-lazy-srcset="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/shutterstock-img.jpg 1537w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/shutterstock-img-300x200.jpg 300w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/shutterstock-img-1024x682.jpg 1024w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/shutterstock-img-768x512.jpg 768w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/shutterstock-img-1536x1023.jpg 1536w" sizes="(max-width: 1600px) 100vw, 1600px"><img src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201600%201066'%3E%3C/svg%3E" height="1066" width="1600" data-lazy-srcset="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/shutterstock-img.jpg 1537w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/shutterstock-img-300x200.jpg 300w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/shutterstock-img-1024x682.jpg 1024w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/shutterstock-img-768x512.jpg 768w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/shutterstock-img-1536x1023.jpg 1536w" data-lazy-sizes="(max-width: 1600px) 100vw, 1600px" data-lazy-src="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/shutterstock-img.jpg"></picture><figcaption><strong>Source:</strong> Hyejin Kang, Shutterstock</figcaption></figure>
<p>People will always be biased to some extent because their opinions are subjective and what is worse – humans tend to generalize. This is partly the fault of the way we are programmed, and partly the failure of the way we programmed our society and culture. Does it mean machines have to be programmed like this as well? </p>
<h2>Want to build a racist AI solution? Just hand it a newspaper</h2>
<p>Obviously, AI solutions have no political agenda of their own, right? It’s not going to be intentionally racist unless it has <em>explicitly</em> been trained to be. It is also not (most of the time, at least) a political agenda of their creators that is the issue. The problem is that it is very easy to train machines to be racist by accident and without even trying. </p>
<p>Here are a few examples of how algorithms can discriminate on different fields based on race: </p>
<ul>
<li> <strong> Image Recognition: </strong> Researchers from Georgia Institute of Technology tested eight image-recognition systems used in self-driving cars, after observing higher error rates for specific demographics. They <a href="https://www.independent.co.uk/life-style/gadgets-and-tech/news/self-driving-car-crash-racial-bias-black-people-study-a8810031.html" target="_blank" rel="noopener noreferrer">found their accuracy proving five percent less accurate</a> on average for people with darker skin. So a self-driving car is more likely to run over a black person than it is to run a white one. </li>
<li> <strong> Healthcare: </strong> An algorithm used in US hospitals to allocate healthcare for patients has been systematically discriminating against black people. A study concluded that the algorithm was <a href="https://www.nature.com/articles/d41586-019-03228-6#ref-CR1" target="_blank" rel="noopener noreferrer">less likely to refer black people than white people</a> who were equally sick to programs that aim to improve care for patients with complex medical needs. </li>
<figure> <picture><source data-lazy-srcset="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/iStock-971224314.webp 1200w,https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/iStock-971224314-300x175.webp 300w,https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/iStock-971224314-1024x596.webp 1024w,https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/iStock-971224314-768x447.webp 768w" sizes="(max-width: 1200px) 100vw, 1200px" type="image/webp"><source data-lazy-srcset="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/iStock-971224314.jpg 1200w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/iStock-971224314-300x175.jpg 300w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/iStock-971224314-1024x596.jpg 1024w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/iStock-971224314-768x447.jpg 768w" sizes="(max-width: 1200px) 100vw, 1200px"><img src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201200%20699'%3E%3C/svg%3E" alt="AI solutions" height="699" width="1200" data-lazy-srcset="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/iStock-971224314.jpg 1200w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/iStock-971224314-300x175.jpg 300w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/iStock-971224314-1024x596.jpg 1024w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/iStock-971224314-768x447.jpg 768w" data-lazy-sizes="(max-width: 1200px) 100vw, 1200px" data-lazy-src="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/iStock-971224314.jpg"></picture><figcaption><strong>Source:</strong> Hyejin Kang, Shutterstock</figcaption></figure>
<li> <strong> Criminal Cases: </strong> In 2016, <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing" target="_blank" rel="noopener noreferrer">ProPublica published</a> an investigation on an ML program that is used by courts to predict future criminals, and they found out that the system is biased against black people. The program learned about who is mostly to end up in jail from incarceration data. And historically, the criminal justice system has been unfair to black Americans. So when an AI program was fed with these historical data, it learned from biased decisions historically made by humans. </li>
<li> <strong> Natural Language Processing (<a href="https://sigmoidal.io/boosting-your-solutions-with-nlp/" target="_blank" rel="noopener noreferrer">NLP</a>): </strong> There is a broad spectrum of cases (for example, work/college admissions or even loan applications), where words can serve as an input – the so-called <em>word embeddings</em> represent words as inputs to machine learning. But there is a fairness problem when an algorithm learns the meaning of words from humans. Our opinions are often subjective and biased, so the meaning of the words (e.g., people names) is then biased. A <a href="http://science.sciencemag.org/content/356/6334/183.full" target="_blank" rel="noopener noreferrer"> paper in Science from 2017</a> found out that when a computer teaches itself English by crawling the internet, it becomes prejudiced against black Americans and women. For example, when <a href="http://blog.conceptnet.io/posts/2017/how-to-make-a-racist-ai-without-really-trying/http://blog.conceptnet.io/posts/2017/how-to-make-a-racist-ai-without-really-trying/" target="_blank" rel="noopener noreferrer">the GloVe news dataset is used</a>, the sentiment (how positive a given sentence is) of simple text starting with ‘My name is…’ is significantly lower when it ends with common names of black people than common names for white people.
 </li>
</ul>
<figure> <picture><source data-lazy-srcset="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/pasted-image-0-2.webp 496w,https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/pasted-image-0-2-300x133.webp 300w" sizes="(max-width: 496px) 100vw, 496px" type="image/webp"><source data-lazy-srcset="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/pasted-image-0-2.png 496w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/pasted-image-0-2-300x133.png 300w" sizes="(max-width: 496px) 100vw, 496px"><img src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20496%20220'%3E%3C/svg%3E" height="220" width="496" data-lazy-srcset="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/pasted-image-0-2.png 496w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/pasted-image-0-2-300x133.png 300w" data-lazy-sizes="(max-width: 496px) 100vw, 496px" data-lazy-src="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/pasted-image-0-2.png"></picture><figcaption> This is just a glimpse of how sentiment works for different sentences. A machine understands the meaning of these words due to word embeddings. </figcaption></figure>
<figure>
<picture><source data-lazy-srcset="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/unnamed-karolina.webp" type="image/webp"><source data-lazy-srcset="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/unnamed-karolina.png"><img src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20512%20429'%3E%3C/svg%3E" height="429" width="512" data-lazy-srcset="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/unnamed-karolina.png" data-lazy-src="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/unnamed-karolina.png"></picture><br>
<picture><source data-lazy-srcset="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/pasted-image-0-3.webp 364w,https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/pasted-image-0-3-255x300.webp 255w" sizes="(max-width: 364px) 100vw, 364px" type="image/webp"><source data-lazy-srcset="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/pasted-image-0-3.png 364w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/pasted-image-0-3-255x300.png 255w" sizes="(max-width: 364px) 100vw, 364px"><img src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20364%20429'%3E%3C/svg%3E" height="429" width="364" data-lazy-srcset="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/pasted-image-0-3.png 364w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/pasted-image-0-3-255x300.png 255w" data-lazy-sizes="(max-width: 364px) 100vw, 364px" data-lazy-src="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/pasted-image-0-3.png"></picture><figcaption> Sentiment values are more positive for stereotypically-white names, and more negative for stereotypically-black names. These examples show how word-embeddings can accidentally learn racist bias from us just by reading internet news. </figcaption></figure>
<h2> How can we fight it? </h2>
<blockquote>
<p>
Bias-free AI can soon be a powerful tool to tackle social issues – such as enhancing social mobility through fairer access to the financing/healthcare system, mitigating exclusion and poverty through making the judiciary systems more objective, bias-free testing in university admissions, and much more. We should expect fair AI solutions from both technology companies and authorities.
</p>
</blockquote>
<p>Military and tactics books say that weapons or tactics should always take into consideration the enemy strategy. That is also true for this particular fairness and human dignity fight. In the case of this war, there are also different ways to fight racial bias, depending on the domain (field) and the data used by the algorithm. </p>
<h3> Image Recognition </h3>
<p>In the case of image-recognition systems, the reason for bias is that training data that machines use for learning contain mostly samples gathered from white people. These AI solutions can have problems with recognizing people of different races because it simply did not see enough pictures of them. The effect is doubled when it comes to women of color.</p>
<p>Face recognition systems from the leading companies <a href="https://www.youtube.com/watch?v=QxuyfWoVV98" target="_blank" rel="noopener noreferrer">failed during the man/women classification</a> of Oprah Winfrey, Michelle Obama, and Serena Williams. </p>
<p>The biggest problem here is that face-recognition systems are widely used by law enforcement and border control. If the application has high false-positive rates for a specific group (and according to <a href="https://www.nist.gov/news-events/news/2019/12/nist-study-evaluates-effects-race-age-sex-face-recognition-software" target="_blank" rel="noopener noreferrer"> NIST study</a>, a majority of the face recognition algorithms used in the US had worse perform on nonwhite faces), it puts this population at the highest risk for being falsely accused of a crime. </p>
<figure> <picture><source data-lazy-srcset="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/1_6xQOFmzai_8ALH9UP8sQvw.webp 1024w,https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/1_6xQOFmzai_8ALH9UP8sQvw-300x169.webp 300w,https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/1_6xQOFmzai_8ALH9UP8sQvw-768x432.webp 768w" sizes="(max-width: 1024px) 100vw, 1024px" type="image/webp"><source data-lazy-srcset="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/1_6xQOFmzai_8ALH9UP8sQvw.jpeg 1024w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/1_6xQOFmzai_8ALH9UP8sQvw-300x169.jpeg 300w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/1_6xQOFmzai_8ALH9UP8sQvw-768x432.jpeg 768w" sizes="(max-width: 1024px) 100vw, 1024px"><img src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20576'%3E%3C/svg%3E" height="576" width="1024" data-lazy-srcset="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/1_6xQOFmzai_8ALH9UP8sQvw.jpeg 1024w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/1_6xQOFmzai_8ALH9UP8sQvw-300x169.jpeg 300w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/1_6xQOFmzai_8ALH9UP8sQvw-768x432.jpeg 768w" data-lazy-sizes="(max-width: 1024px) 100vw, 1024px" data-lazy-src="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/1_6xQOFmzai_8ALH9UP8sQvw.jpeg"></picture><figcaption><strong>Source:</strong> vpnsrus.com</figcaption></figure>
<p>The solution (our weapon) for this problem is quite simple. Still, it requires more attention during dataset preparation: the equal representation of people of color and gender in training datasets (e.g., face recognition) is crucial for algorithms (like face recognition ones) to work with the same precision regardless of race or gender.</p>
<p>Moreover, from the sociological point of view, those bias problems would be hard to overlook and natural to point out if minority representatives would be more encouraged to be a part of the artificial intelligence team.</p>
<h3> Biases in AI solutions for Healthcare </h3>
<p>The reason millions of black people were affected by racial bias in health-care algorithms? It was based on the historical cost of health care, where higher health-care costs are associated with greater needs. People who did have higher-cost treatment were assumed to need more extensive care, which seemed just about right – or did it?</p>
<figure> <picture><source data-lazy-srcset="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/gettyimages-971253984_1200xx2116-1195-0-219.webp 1200w,https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/gettyimages-971253984_1200xx2116-1195-0-219-300x169.webp 300w,https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/gettyimages-971253984_1200xx2116-1195-0-219-1024x578.webp 1024w,https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/gettyimages-971253984_1200xx2116-1195-0-219-768x433.webp 768w" sizes="(max-width: 1200px) 100vw, 1200px" type="image/webp"><source data-lazy-srcset="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/gettyimages-971253984_1200xx2116-1195-0-219.jpg 1200w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/gettyimages-971253984_1200xx2116-1195-0-219-300x169.jpg 300w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/gettyimages-971253984_1200xx2116-1195-0-219-1024x578.jpg 1024w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/gettyimages-971253984_1200xx2116-1195-0-219-768x433.jpg 768w" sizes="(max-width: 1200px) 100vw, 1200px"><img src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201200%20677'%3E%3C/svg%3E" height="677" width="1200" data-lazy-srcset="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/gettyimages-971253984_1200xx2116-1195-0-219.jpg 1200w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/gettyimages-971253984_1200xx2116-1195-0-219-300x169.jpg 300w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/gettyimages-971253984_1200xx2116-1195-0-219-1024x578.jpg 1024w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/gettyimages-971253984_1200xx2116-1195-0-219-768x433.jpg 768w" data-lazy-sizes="(max-width: 1200px) 100vw, 1200px" data-lazy-src="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/gettyimages-971253984_1200xx2116-1195-0-219.jpg"></picture><figcaption><strong>Source:</strong> Hyejin Kang, Shutterstock</figcaption></figure>
<p>The biggest problem with this approach was the fact that those less wealthy simply couldn’t afford more extensive treatment, so they chose less expensive options, while their actual needs remain the same as people in the same condition who could opt in the more expensive ones.</p>
<p>The approximation of the healthcare needs by the amount of money spent on treatment was actually an exclusive approach, biased towards more wealthy people. Finding other variables than the cost of treatment to estimate a person’s medical needs <a href="https://www.nature.com/articles/d41586-019-03228-6#ref-CR1" target="_blank" rel="noopener noreferrer">reduced bias by 84%</a>. </p>
<h3> College Admissions </h3>
<p>The problem here is often not testing actual skills but rather candidate background (e.g., childhood environment). If you have two candidates and one comes from the wealthy neighborhood and the other from a poor one, there is a possibility that the second one will …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sigmoidal.io/how-to-build-inclusive-fair-ai-solutions/">https://sigmoidal.io/how-to-build-inclusive-fair-ai-solutions/</a></em></p>]]>
            </description>
            <link>https://sigmoidal.io/how-to-build-inclusive-fair-ai-solutions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23664059</guid>
            <pubDate>Sat, 27 Jun 2020 19:35:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Xi-Editor Retrospective]]>
            </title>
            <description>
<![CDATA[
Score 518 | Comments 150 (<a href="https://news.ycombinator.com/item?id=23663878">thread link</a>) | @raphlinus
<br/>
June 27, 2020 | https://raphlinus.github.io/xi/2020/06/27/xi-retrospective.html | <a href="https://web.archive.org/web/*/https://raphlinus.github.io/xi/2020/06/27/xi-retrospective.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>A bit more than four years ago I started the <a href="https://github.com/xi-editor/xi-editor">xi-editor</a> project. Now I have placed it on the back burner (though there is still some activity from the open source community).</p>

<p>The original goal was to deliver a very high quality editing experience. To this end, the project spent a rather large number of “novelty points”:</p>

<ul>
  <li>Rust as the implementation language for the core.</li>
  <li>A rope data structure for text storage.</li>
  <li>A multiprocess architecture, with front-end and plug-ins each with their own process.</li>
  <li>Fully embracing async design.</li>
  <li><a href="https://en.wikipedia.org/wiki/Conflict-free_replicated_data_type">CRDT</a> as a mechanism for concurrent modification.</li>
</ul>

<p>I still believe it would be possible to build a high quality editor based on the original design. But I <em>also</em> believe that this would be quite a complex system, and require significantly more work than necessary.</p>

<p>I’ve written the <a href="https://github.com/xi-editor/xi-editor/issues/1187#issuecomment-491473599">CRDT part of this retrospective</a> already, as a comment in response to a Github issue. That prompted good <a href="https://news.ycombinator.com/item?id=19886883">discussion</a> on Hacker News. In this post, I will touch again on CRDT but will focus on the other aspects of the system design.</p>

<h2 id="origins">Origins</h2>

<p>The original motivation for xi came from working on the Android text stack, and confronting two problems in particular. One, text editing would become very slow as the text buffer got bigger. Two, there were a number of concurrency bugs in the interface between the EditText widget and the keyboard (input method editor).</p>

<p>The culprit of the first problem turned out to be the <a href="https://developer.android.com/reference/android/text/SpanWatcher">SpanWatcher</a> interface, combined with the fact that modern keyboards like to put a spelling correction span on each word. When you insert a character, all the successive spans bump their locations up by one, and then you have to send onSpanChanged for each of those spans to all the watchers. Combined with the fact that the spans data structure had a naive O(n) implementation, and the whole thing was quadratic or worse.</p>

<p>The concurrency bugs boil down to synchronizing edits across two different processes, because the keyboard is a different process than the application hosting the EditText widget. Thus, when you send an update (to move the cursor, for example) and the text on the other side is changing concurrently, it’s ambiguous whether it refers to the old or new location. This was handled in an “almost correct” style, with timeouts for housekeeping updates to minimize the chance of a race. A nice manifestation of that is that swiping the cursor slowly through text containing complex emoji could cause flashes of the emoji breaking.</p>

<p>These problems have a unifying thread: in both cases there are small diffs to the text, but then the data structures and protocols handled these diffs in a less than optimal way, leading to both performance and correctness bugs.</p>

<p>To a large extent, xi started as an exploration into the “right way” to handle text editing operations. In the case of the concurrency bugs, I was hoping to find a general, powerful technique to facilitate concurrent text editing in a distributed-ish system. While most of the Operational Transformation literature is focused on multiple users collaboratively editing a document, I was hoping that other text manipulations (like an application enforcing credit card formatting on a text input field) could fit into the general framework.</p>

<p>That was also the time I was starting to get heavily into Rust, so it made natural sense to start prototyping a new green-field text editing engine. How would you “solve text” if you were free of backwards compatibility constraints (a huge problem in Android)?</p>

<p>When I started, I knew that Operational Transformation was a solution for collaborative editing, but had a reputation for being complex and finicky. I had no idea how deep the rabbithole would be of OT and then CRDT. Much of that story is told in the <a href="https://news.ycombinator.com/item?id=19886883">CRDT discussion</a> previously linked.</p>

<h2 id="the-lure-of-modular-software">The lure of modular software</h2>

<p>There is an extremely long history of people trying to build software as composable modules connected by some kind of inter-module communication fabric. Historical examples include <a href="https://en.wikipedia.org/wiki/DCE/RPC">DCE/RPC</a>, <a href="https://en.wikipedia.org/wiki/Common_Object_Request_Broker_Architecture">Corba</a>, <a href="https://en.wikipedia.org/wiki/Bonobo_(GNOME)">Bonobo</a>, and more recently things like <a href="https://sandstorm.io/">Sandstorm</a> and <a href="https://fuchsia.dev/fuchsia-src/concepts/modular/module">Fuchsia Modular</a>. There are some partial successes, including <a href="https://developer.android.com/reference/android/os/Binder">Binder</a> on Android, but this is still mostly an unrealized vision. (Regarding Binder, it evolved from a much more idealistic vision, and I strongly recommend reading this 2006 interview about <a href="https://www.osnews.com/story/13674/introduction-to-openbinder-and-interview-with-dianne-hackborn/">OpenBinder</a>).</p>

<p>When I started xi, there were signs we were getting there. Microservices were becoming popular in the Internet world, and of course all Web apps have a client/server boundary. Within Google, <a href="https://grpc.io/">gRPC</a> was working fairly well, as was the internal process separation within Chrome. In Unix land, there’s a long history of the terminal itself presenting a GUI (if primitive, though gaining features such as color and mouse). There’s also the tradition of <a href="https://en.wikipedia.org/wiki/Blit_(computer_terminal)">Blit</a> and then, of course, <a href="https://en.wikipedia.org/wiki/NeWS">NeWS</a> and X11.</p>

<p>I think one of the strongest positive models was the database / business logic split, which is arguably the most successful example of process separation. In this model, the database is responsible for performance and integrity, and the business logic is in a separate process, so it can safely do things like crash and hang. I very much thought of xi-core as a database-like engine, capable of handling concurrent text modification much like a database handles transactions.</p>

<p>Building software in such a modular way requires two things: first, infrastructure to support remote procedure calls (including serialization of the requests and data), and second, well-defined interfaces. Towards the end of 2017, I saw the goal of xi-editor as <em>primarily</em> being about defining the interfaces needed for large scale text editing, and that this work could endure over a long period of time even as details of the implementation changed.</p>

<p>For the infrastructure, we chose JSON (about which more below) and hand-rolled our own xi-rpc layer (based on JSON-RPC). It turns out there are a lot of details to get right, including dealing with error conditions, negotiating when two ends of the protocol aren’t exactly on the same version, etc.</p>

<p>One of the bolder design decisions in xi was to have a process separation between front-end and core. This was inspired in part by <a href="https://neovim.io/">Neovim</a>, in which everything is a plugin, even GUI. But the main motivation was to build GUI applications using Rust, even though at the time Rust was nowhere near capable of native GUI. The idea is that you use the best GUI technology of the platform, and communicate via async pipes.</p>

<p>One argument for process separation is to improve overall system reliability. For example, Chrome has a process per tab, and if the process crashes, all you get is an “Aw, snap” without bringing the whole browser down. I think it’s worth asking the question: is it useful to have the front-end continue after the core crashes, or the other way around? I think probably not; in the latter case it might be able to safely save the file, but you can also do that by frequently checkpointing.</p>

<p>Looking back, I see much of the promise of modular software as addressing goals related to project management, not technical excellence. Ideally, once you’ve defined an inter-module architecture, then smaller teams can be responsible for their own module, and the cost of coordination goes down. I think this type of project management structure is especially appealing to large companies, who otherwise find it difficult to manage larger projects. And the tax of greater overall complexity is often manageable, as these big companies tend to have more resources.</p>

<h3 id="json">JSON</h3>

<p>The choice of JSON was controversial from the start. It did end up being a source of friction, but for surprising reasons.</p>

<p>The original vision was to write plug-ins in any language, especially for things like language servers that would be best developed in the language of that ecosystem. This is the main reason I chose JSON, because I expected there would be high quality implementations in every viable language.</p>

<p>Many people complained about the fact that JSON escapes strings, and suggested alternatives such as <a href="https://msgpack.org/index.html">MessagePack</a>. But I knew that the speed of raw JSON parsing was a solved problem, with a number of extremely high performance implementations (<a href="https://github.com/simdjson/simdjson">simdjson</a> is a good example).</p>

<p>Even so, aside from the general problems of modular software as described above, JSON was the source of two additional problems. For one, <a href="https://github.com/xi-editor/xi-mac/issues/102">JSON in Swift is shockingly slow</a>. There are <a href="https://forums.swift.org/t/rearchitecting-jsonencoder-to-be-much-faster/28139">discussions on improving it</a> but it’s still a problem. This is surprising to me considering how important it is in many workloads, and the fact that it’s clearly possible to write a high performance JSON implementation.</p>

<p>Second, on the Rust side, while <a href="https://serde.rs/">serde</a> is quite fast and very convenient (thanks to proc macros), when serializing a large number of complex structures, it bloats code size considerably. The xi core is 9.3 megabytes in a Linux release build (debug is an eye-watering 88MB), and a great deal of that bloat is serialization. There is work to reduce this, including <a href="https://github.com/dtolnay/miniserde">miniserde</a> and <a href="https://github.com/not-fl3/nanoserde">nanoserde</a>, but serde is still by far the most mainstream.</p>

<p>I believe it’s possible to do performant, clean JSON across most languages, but people should know, we’re not there yet.</p>

<h2 id="the-rope">The rope</h2>

<p>There are only a few data structures suitable for representation of text in a text editor. I would enumerate them as: contiguous string, gapped buffer, array of lines, piece table, and rope. I would consider the first unsuitable for the goals of xi-editor as it doesn’t scale well to large documents, though its simplicity is appealing, and memcpy is fast these days; if you know your document is always under a megabyte or so, it’s probably the best choice.</p>

<p>Array of lines has performance failure modes, most notably very long lines. Similarly, many good editors have been written using piece tables, but I’m not a huge fan; performance is very good when first opening the file, but degrades over time.</p>

<p>My favorite aspect of the rope as a data structure is its excellent …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://raphlinus.github.io/xi/2020/06/27/xi-retrospective.html">https://raphlinus.github.io/xi/2020/06/27/xi-retrospective.html</a></em></p>]]>
            </description>
            <link>https://raphlinus.github.io/xi/2020/06/27/xi-retrospective.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23663878</guid>
            <pubDate>Sat, 27 Jun 2020 19:06:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Spreading of Threading (2019)]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23663631">thread link</a>) | @jbarches
<br/>
June 27, 2020 | https://aaronzlewis.com/blog/2019/05/01/spreading-threading/ | <a href="https://web.archive.org/web/*/https://aaronzlewis.com/blog/2019/05/01/spreading-threading/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="article">
    <!-- START OF _includes/article.html -->
<article>
	
	
	
	<p>Aaron Z. Lewis / <time>May 1, 2019</time></p>
	
	<!--more-->


<p>My Twitter feels like a local library. Each one of my Twitter friends is tending to their own little corner of the internet, sharing their best material, and responding to my random research questions. There are a lot of knowledgable folks out there, but <a href="https://aaronzlewis.com/blog/2019/05/01/spreading-threading/[@visakanv](https://twitter.com/visakanv">Visakan Veerasamy</a> is the ultimate librarian. I like to think of him as the crown prince of Nerd Twitter —&nbsp;a writer, creator, and curator who’s so prolific he doesn’t recognize himself. Visa is playing the Twitter game on a whole new level. He’s constructing a digital version of his brain, and his curation style feels like an early iteration of something that might one day go mainstream. It’s a knowledge creation and exploration ethos that feels more true to the original “web” and more fit for how we think.</p>

<p><img src="https://aaronzlewis.com/images/visa.png">
<em>Visa’s Twitter profile, complete with his personal web of values.</em></p>

<p>Inspired by his huge web of knowledge, I sent out a tweet three months ago that said: “I think I would legit pay for @visakanv as a service. $10/mo for him to respond to all of my random musings with his own thoughts, content recommendations, and links to relevant threads. This service would be like Mario racing turbo boost for the mind!”</p>

<p>To my surprise, Visa responded within a few minutes. “Happy to do this,” he said, and shared a link to his <a href="https://www.patreon.com/visakanv">Patreon</a>.</p>

<h3>A brief history of tweetstorms</h3>

<p>Visa’s digital brain is made up of Twitter threads. He didn’t invent the medium, but he’s pushed it to its limits.</p>

<p>When Marc Andreessen started tweeting in 2014, he didn’t let the 140-character limit stop him from posting his thoughts at length. Instead of shortening his tweets, he started stringing them together by replying to himself. Thus was born the tweetstorm. At first, tweetstorms were a hack. And they were mildly <a href="http://expletiveinserted.com/2014/07/02/taming-tweetstorms/">controversial</a>. Gawker once <a href="http://valleywag.gawker.com/uber-ceo-posts-13-tweet-apology-without-answering-a-sin-1660229634">slammed</a> Travis Kalanick’s use of a tweetstorm, calling it “a series of thoughts that give the illusion of substance and circumspection because they are presented in a numerical order.” Tech blogger/investor M.G. Siegler raged against them in 2014:</p>

<blockquote><p>1/ In theory, 2/ I love Tweetstorms 3/ and have long wanted a feature like this myself. 4/ But in practice, 5/ I f*cking hate them. 6/ They flow in the tweet stream about as nicely as vomit out of an esophagus. 7/ They ruin the experience of the stream by breaking what Twitter is, 8/ a service to share short thoughts quickly 9/ and let others reply to those in some semblance of order.</p></blockquote>

<p>At first, creating tweetstorms was a <a href="https://readwrite.com/2014/08/21/twitter-jargon-illustrated-rt-mt-canoes-darth/">very manual process</a>, and they weren’t very easy to read or share. Fast-forward three years: in 2017, Twitter officially productized tweestorms and rebranded them as “threads.” Suddenly, it was much simpler to string tweets together and share the resulting thread as a unit. This product change created the infrastructure on which Visa and others are currently spinning their webs.</p>

<h3>Resurrecting the Memex</h3>

<p>I found Visa’s threads sometime last year, and I’ve been crawling across them ever since. Whereas Marc Andressen’s threads were mostly self-contained, Visa’s are linked together. They form a giant web of interconnected thoughts. There’s no beginning or ending or map or wayfinding or sense of where you are in his tapestry. There are just threads of threads of threads that seem to extend into infinity —&nbsp;an ever-expanding network of Visa’s ideas and discoveries. At each node, there’s usually a full-on discussion taking place between his followers. Visa has constructed what feels like a whole new medium on top of the bedrock of Twitter. Here’s a representative thread for you to explore:</p>

<blockquote data-lang="en"><div lang="en" dir="ltr"><p>I’ve been stewing this theory for 1 year +:</p><p>Just as how the WWE isn’t a wrestling show, but a show ABOUT a wrestling show,</p><p>mainstream media is less about the news than a participatory interactive tv show ABOUT the news</p><p>Cable News Network is really Cable News Entertainment <a href="https://t.co/QZO2t8I9fI">https://t.co/QZO2t8I9fI</a></p></div>— Visa is in SF until May 8! 🌉 (@visakanv) <a href="https://twitter.com/visakanv/status/1004190525270851584?ref_src=twsrc%5Etfw">June 6, 2018</a></blockquote>





<p>Visa’s threads are doing to Twitter what hyperlinks did to dead-tree text. They link things together across time and space. Without thread-webs, most tweets get left behind in the past. A web of tweets allows people to rediscover older thoughts and connect them with newer ones.</p>

<p>These threads bear a family resemblance to the vision of an early 20th-century computer pioneer named Vannevar Bush. In 1945, he wrote a now-famous article called <a href="https://www.theatlantic.com/magazine/archive/1945/07/as-we-may-think/303881/">As We May Think</a>, which described a knowledge device he called the Memex:</p>

<blockquote><p>Man cannot hope fully to duplicate [his] mental process artificially, but he certainly ought to be able to learn from it. In minor ways, he may even improve, for his records have relative permanency. The first idea, however, to be drawn from the analogy concerns selection. Selection by association, rather than indexing, may be mechanized. One cannot hope thus to equal the speed of flexibility with which the mind follows an associative trail, but it should be possible to beat the mind decisively in regard to the permanence an clarity of the items resurrected from storage … <strong>Wholly new forms of encyclopedias will appear, ready made with a mesh of associative trails running through them, ready to be dropped into the memex and there amplified.</strong></p></blockquote>

<p><img src="https://aaronzlewis.com/images/memex.jpg"></p>

<p>Bush’s vision of associative trails has been realized in some corners of the web, like Wikipedia. But most content is organized in the reverse-chronological stream (also known as the feed or the timeline). Social media sites have made information consumption a very linear process. We scroll down infinitely long pages that are (roughly) organized from newest to oldest. Content that’s more than a week old is fossilized under the endless dump of new posts, links, pictures. On social media, time is the main ordering principle. Creating new content feels like throwing a leaf into a roaring river. It’s not attached to anything — it just floats on by, doomed to be forgotten within a matter of seconds. We don’t really “surf” the web anymore. Unless we’re <a href="https://en.wikipedia.org/wiki/Wikipedia:Wikirace">Wiki-racing</a>, we’re not hopping from hyperlink to hyperlink on a surprising journey across  human knowledge. We scroll, click, scroll click.</p>

<p>I see Visa’s Twitter threads as a response to this boring linearity&nbsp;— an attempt to make things hang together. We’re associative beings. We make sense of things by relating them to other things. As Joshua Foer wrote in his book <em>Moonwalking With Einstein:</em> “It takes knowledge to gain knowledge. Memory is like a spiderweb that catches information. The more it catches, the bigger it grows. And the bigger it grows, the more it catches.”</p>

<h3>The spread of threads</h3>

<p>I’ve noticed that the threading impulse is beginning to expand beyond Twitter. It’s popping up in more and more corners of the web. At Ribbonfarm, Venkatesh Rao is experimenting with a new genre called “<a href="https://www.ribbonfarm.com/2019/03/21/constructions-in-magical-thinking/">blogchains</a>,” in which a bunch of blog posts are linked together around a single theme. It’s different than a traditional series because it’s “improvised rather than planned, is responsive to salient events in the environment, evolves at a certain tempo, is structurally a way to <em>build over time</em>, is suitable for multi-author collaboration, is capable of supporting an inter-process messaging protocol with adjacent blogchains, has no necessary or scripted ‘ending.’” The blogchain seems like a direct descendant of the Twitter thread — an attempt to experiment with the medium outside the confines of Twitter’s more rigid platform.</p>

<p>At Epsilon Theory, Ben Hunt created what he calls a <a href="https://www.epsilontheory.com/discovery-map-december-31-2018/">Discovery Map</a>. It’s an interactive visualization that displays all 300 of his blog posts as a network graph. The nodes of the network are organized in thematic clusters. Instead of scrolling down a reverse-chronological feed, you can surf across related posts and see connections across time. This feels like a genuinely new way of interacting with blog content, and it serves as an interesting answer to the question “Where should I start?”</p>

<p><img src="https://aaronzlewis.com/images/discovery-map.png"></p>

<p>The most interesting non-linear threading product I’ve discovered is called <a href="http://are.na/">Are.na</a>. It’s like Pinterest, but for nerds. Are.na lets you organize “Blocks” (text, links, photos) into thematic “Channels”. For example, I’m currently collecting material for channels called “<a href="https://www.are.na/aaron-lewis/deep-history-8mjcwnu9nia">Deep history</a>” and “<a href="https://www.are.na/aaron-lewis/culture-wars-2-0">Culture wars 2.0</a>”. Other people can easily add blocks to your channels, and you can include their channels inside your own. Channels can be rearranged, renamed, connected in novel ways. On Are.na, you’re a spider spinning a knowledge web alongside a bunch of other curious spiders. You never know how your webs might connect. I’ve started searching for things on Are.na (instead of Google) because every block lives inside a channel that’s connected to a lot of related content. Whereas a Google search result feels like a dead-end, an Arena block feels like an unexpected beginning.</p>

<p>What’s frustrating about blogging is that each post feels static and final. It’s not very alive as a medium. I wish it were easier for posts to evolve over time, sprout offshoots, find collaborators. The hyperlink is a pretty crude technology for connecting things together. Visa’s threads, Ribbonfarm’s blogchains, Epsilon Theory’s Discovery Map, and Are.na’s channels are all pointing to a model of content creation and consumption that’s more fit for the way our minds actually work. Threads are a more fluid and malleable medium. Finding someone’s thread-web feels like the digital equivalent of perusing the bookshelves in their home. You don’t have to know what you’re looking for, but you’re usually pleasantly surprised by what you find.</p>

<p>For the last few months, Visa has been replying to my tweets with links to his relevant thread-webs. Each random thought I tweet becomes a new entry point into the collection he’s been curating for years. He’d probably do this if I weren’t supporting him on Patreon, but I believe his threading experiment is an extremely valuable service. As the internet grows more complex, we’re going to need people who can string things together across time and …</p></article></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://aaronzlewis.com/blog/2019/05/01/spreading-threading/">https://aaronzlewis.com/blog/2019/05/01/spreading-threading/</a></em></p>]]>
            </description>
            <link>https://aaronzlewis.com/blog/2019/05/01/spreading-threading/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23663631</guid>
            <pubDate>Sat, 27 Jun 2020 18:30:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Commodore SX-64 keyboard restoration]]>
            </title>
            <description>
<![CDATA[
Score 89 | Comments 9 (<a href="https://news.ycombinator.com/item?id=23663298">thread link</a>) | @zdw
<br/>
June 27, 2020 | https://retrohax.net/commodore-sx-64-keyboard-restoration/ | <a href="https://web.archive.org/web/*/https://retrohax.net/commodore-sx-64-keyboard-restoration/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-11445">

<div>
<p>…or sculpturing is not that bad for health ;P</p>
<h4>Intro</h4>
<p>Well, it just had to be this pic:)</p>
<div><figure><img src="https://i1.wp.com/i.imgur.com/m346MsE.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/m346MsE.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>
<h4>The story</h4>
<p>Some time ago, <a href="https://csdb.dk/scener/?id=501">Carrion/Bonzai</a> asked me to fix his SX-64 keyboard. I was like … hell yeah! … I’ve never worked on SX-64 gear. The problem was, at that moment I didn’t know what was wrong with that keyboard … until pics arrived</p>
<p>By the way, <a href="https://csdb.dk/scener/?id=501">Carrion</a> and <a href="https://csdb.dk/scener/?id=29175">Yugorin</a> run an awesome website – <a href="https://c64portal.pl/">c64portal.pl</a> – The website is in Polish and contains lots of valuable info about Polish Commodore demoscene and Commodore in general. Both gentlemen are also the main guys behind the <a href="https://moonshinedragons.party/">Moonshine Dragons party – currently, the largest C64 party in Poland.</a></p>
<p>Since I already agreed that I’ll fix it, there was no excuse. Carrion sent me that keyboard and the party has begun 🙂</p>
<figure><img src="https://i2.wp.com/i.imgur.com/y0Ai3vi.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/y0Ai3vi.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/i.imgur.com/aG5HlaH.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/aG5HlaH.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i0.wp.com/i.imgur.com/ECulxga.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/i.imgur.com/ECulxga.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i0.wp.com/i.imgur.com/1TIBRD7.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/i.imgur.com/1TIBRD7.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<h4>Disassembly</h4>
<figure><img src="https://i0.wp.com/i.imgur.com/14z6NKo.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/i.imgur.com/14z6NKo.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/i.imgur.com/FP1o5XJ.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/FP1o5XJ.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i0.wp.com/i.imgur.com/68tWP5Q.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/i.imgur.com/68tWP5Q.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/i.imgur.com/tBEbYym.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/tBEbYym.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>I had to remove the original stickers. That was done using a hotair gun set to 100 degrees C</p>
<figure><img src="https://i2.wp.com/i.imgur.com/DJRH9q1.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/DJRH9q1.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i0.wp.com/i.imgur.com/m4IlS3w.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/i.imgur.com/m4IlS3w.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/i.imgur.com/gPEP4TS.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/gPEP4TS.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i0.wp.com/i.imgur.com/fLwpCOO.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/i.imgur.com/fLwpCOO.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/i.imgur.com/zC70ojc.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/zC70ojc.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<h4>Plastic welding and reinforcements</h4>
<p>As it turned out, after close inspection, there were way more cracks than I thought.</p>
<p>All these cracks had to be addressed and reinforced – <a href="https://retrohax.net/extreme-refurbishing-episode-2-atari-800-xl-part-one/">this is a lesson that I’ve learned after my Atari 800 XL refurb</a> where joints were not stable enough and resulted in tiny cracks over time.</p>
<p>To achieve a proper result, I’ve welded in a brass mesh to serve as a reinforcement of cracked spots and as a base for resin-based compounds used later to rebuild missing plastic. Obviously, the mesh had to be custom cut.</p>
<p>This is how the process looks.</p>
<div><figure><img src="https://i0.wp.com/i.imgur.com/CdCzrZR.png?resize=869%2C516&amp;ssl=1" alt="" width="869" height="516" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/i.imgur.com/CdCzrZR.png?resize=869%2C516&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>
<div><figure><img src="https://i1.wp.com/i.imgur.com/HO9QZa6.png?resize=873%2C642&amp;ssl=1" alt="" width="873" height="642" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/HO9QZa6.png?resize=873%2C642&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>
<figure><img src="https://i0.wp.com/i.imgur.com/j3XfeJN.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/i.imgur.com/j3XfeJN.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/i.imgur.com/GqsUcXE.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/GqsUcXE.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/i.imgur.com/ClMeI8M.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/ClMeI8M.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/i.imgur.com/xElRtff.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/xElRtff.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/i.imgur.com/eqGobQf.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/eqGobQf.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i0.wp.com/i.imgur.com/hWsvly1.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/i.imgur.com/hWsvly1.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/i.imgur.com/p2u3RUj.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/p2u3RUj.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/i.imgur.com/98w81bZ.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/98w81bZ.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/i.imgur.com/DYMxWxH.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/DYMxWxH.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/i.imgur.com/10rmKlI.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/10rmKlI.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<div><figure><img src="https://i1.wp.com/i.imgur.com/5QG745B.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/5QG745B.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>
<figure><img src="https://i2.wp.com/i.imgur.com/ErC3CEN.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/ErC3CEN.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/i.imgur.com/czOi7Rl.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/czOi7Rl.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i0.wp.com/i.imgur.com/iX9SiFR.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/i.imgur.com/iX9SiFR.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/i.imgur.com/ziuEJ1l.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/ziuEJ1l.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i0.wp.com/i.imgur.com/6j76Oqp.png?resize=857%2C470&amp;ssl=1" alt="" width="857" height="470" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/i.imgur.com/6j76Oqp.png?resize=857%2C470&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i0.wp.com/i.imgur.com/IgxKRUH.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/i.imgur.com/IgxKRUH.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i0.wp.com/i.imgur.com/J1KeYKv.png?resize=870%2C563&amp;ssl=1" alt="" width="870" height="563" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/i.imgur.com/J1KeYKv.png?resize=870%2C563&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/i.imgur.com/eMf7Tx5.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/eMf7Tx5.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>Once every piece was cut to a proper size, I’ve soldered them together. I’ve also added a thicker copper wire to make the mesh stiffer and less prone to bending.</p>
<figure><img src="https://i1.wp.com/i.imgur.com/l59jtyA.png?resize=869%2C645&amp;ssl=1" alt="" width="869" height="645" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/l59jtyA.png?resize=869%2C645&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/i.imgur.com/LGWN1DI.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/LGWN1DI.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/i.imgur.com/ng8t1TQ.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/ng8t1TQ.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/i.imgur.com/KLYBxfU.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/KLYBxfU.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/i.imgur.com/FJfq5V9.png?resize=869%2C699&amp;ssl=1" alt="" width="869" height="699" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/FJfq5V9.png?resize=869%2C699&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<h4>Rebuilding missing plastic</h4>
<p>At this stage, I was ready to apply fiber-glass putty. This is a quite messy process and looks kinda ugly. I’ve used some old PCB laminate to get every edge correctly positioned and as close to the original as possible. This part boils down to pretty much three things – putty application, sanding, laminate repositioning … putty application, sanding, laminate repositioning … etc. etc.</p>
<figure><img src="https://i2.wp.com/i.imgur.com/mm3taof.png?resize=873%2C672&amp;ssl=1" alt="" width="873" height="672" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/mm3taof.png?resize=873%2C672&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/i.imgur.com/sQtngW9.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/sQtngW9.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/i.imgur.com/d6ClqGJ.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/d6ClqGJ.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/i.imgur.com/wLBkEq9.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/wLBkEq9.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i0.wp.com/i.imgur.com/Hdg2Uh1.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/i.imgur.com/Hdg2Uh1.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/i.imgur.com/porpn8X.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/porpn8X.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i0.wp.com/i.imgur.com/1Jat3xm.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/i.imgur.com/1Jat3xm.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/i.imgur.com/S6l7X7N.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/S6l7X7N.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/i.imgur.com/IrpXMM7.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/IrpXMM7.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/i.imgur.com/RsLp2pv.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/RsLp2pv.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/i.imgur.com/fGqjs9Z.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/fGqjs9Z.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/i.imgur.com/HtbyV0G.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/HtbyV0G.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i0.wp.com/i.imgur.com/KtcAy1E.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/i.imgur.com/KtcAy1E.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/i.imgur.com/zvuCkiQ.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/zvuCkiQ.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/i.imgur.com/fH34XUd.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/fH34XUd.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i0.wp.com/i.imgur.com/i3Ki1jZ.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/i.imgur.com/i3Ki1jZ.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i0.wp.com/i.imgur.com/vVzHPyT.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/i.imgur.com/vVzHPyT.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/i.imgur.com/TyEk59s.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/TyEk59s.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/i.imgur.com/7TMVtTv.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/7TMVtTv.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>Some tools used during the process 🙂</p>
<figure><img src="https://i2.wp.com/i.imgur.com/J7y4KCH.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/J7y4KCH.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/i.imgur.com/p3bIknA.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/p3bIknA.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>The first corner was nearly ready for finishing touches. I only had to file it down to its original round shape. That was done with the help of a files 🙂</p>
<figure><img src="https://i2.wp.com/i.imgur.com/fEa5M9X.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/fEa5M9X.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/i.imgur.com/JoSSues.png?resize=876%2C951&amp;ssl=1" alt="" width="876" height="951" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/JoSSues.png?resize=876%2C951&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/i.imgur.com/mjc45oA.png?resize=873%2C786&amp;ssl=1" alt="" width="873" height="786" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/mjc45oA.png?resize=873%2C786&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>The second corner required even more work. I’ve used the same method again. </p>
<figure><img src="https://i1.wp.com/i.imgur.com/fSAKBbN.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/fSAKBbN.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/i.imgur.com/E13VOYl.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/E13VOYl.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/i.imgur.com/ZoqmNkN.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/ZoqmNkN.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/i.imgur.com/kvhREor.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/kvhREor.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/i.imgur.com/kicI2uF.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/kicI2uF.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/i.imgur.com/Hj4csmt.png?resize=872%2C706&amp;ssl=1" alt="" width="872" height="706" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/Hj4csmt.png?resize=872%2C706&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i0.wp.com/i.imgur.com/HK3tzeA.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/i.imgur.com/HK3tzeA.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/i.imgur.com/4qoJoXP.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/4qoJoXP.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>When I finally had a base rebuilt, I had to make a clip sockets in its original places. To do that, I had to cut down a Dremel tool to a proper size.</p>
<figure><img src="https://i0.wp.com/i.imgur.com/gOgOHst.png?resize=881%2C643&amp;ssl=1" alt="" width="881" height="643" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/i.imgur.com/gOgOHst.png?resize=881%2C643&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i0.wp.com/i.imgur.com/m6hgocU.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/i.imgur.com/m6hgocU.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/i.imgur.com/HFY1IMu.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/HFY1IMu.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>After making slots, I could start trying on the bottom part against the top. Unfortunately, one of the hooks snapped off during the process 🙁</p>
<p>I had to fix it first. I’ve made it out of a metal paper clip that was cut down to size and welded in a top case.</p>
<figure><img src="https://i1.wp.com/i.imgur.com/HyEPxOL.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/HyEPxOL.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/i.imgur.com/XusjNIJ.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/XusjNIJ.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/i.imgur.com/FyCKpAZ.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/FyCKpAZ.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/i.imgur.com/hfEJFJU.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/hfEJFJU.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/i.imgur.com/wR8xMYa.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/wR8xMYa.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/i.imgur.com/R4jRwln.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/R4jRwln.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<h4>Epoxy resin and finishing</h4>
<p>After all the above work was done, I’ve mixed a cup of thin epoxy resin to fill in hard to access gaps and spots. It also helped to smoothen all uneven surfaces. The resin was applied to all spots with brass mesh with a plastic pipette.</p>
<figure><img src="https://i1.wp.com/i.imgur.com/5sVppEV.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/5sVppEV.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/i.imgur.com/xY38EFl.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/xY38EFl.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>Once the resin cured, I’ve applied a layer of spray putty which helped me to spot all minor mistakes and correct them with finishing putty and 400 grit sandpaper.</p>
<figure><img src="https://i1.wp.com/i.imgur.com/sCHiBwg.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/sCHiBwg.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/i.imgur.com/3b3VxNv.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/3b3VxNv.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/i.imgur.com/FiuD55K.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/FiuD55K.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>After another round of putty and sanding, I’ve applied black undercoating which was then wet-sanded with 1000 grit this time.</p>
<figure><img src="https://i0.wp.com/i.imgur.com/P2hUrAS.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/i.imgur.com/P2hUrAS.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/i.imgur.com/6qijys4.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/6qijys4.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/i.imgur.com/BPXXWbF.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/BPXXWbF.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>Finally, I could apply the last two layers of custom made spray paint. This paint color exactly matches the original. These custom spray paints for various computers will be available in my <a href="https://retrohax.net/">webshop</a> soon. The first series of spray paints will include the following colors:</p>
<ul><li> Atari XL Beige</li><li> Atari XE/ST Gray</li><li> Commodore 64C Beige</li><li> Amiga 500 Beige </li></ul>
<figure><img src="https://i0.wp.com/i.imgur.com/CfseVnR.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/i.imgur.com/CfseVnR.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/i.imgur.com/pd4FK5C.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/pd4FK5C.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/i.imgur.com/QyrZm8K.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/QyrZm8K.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/i.imgur.com/ahvJZZc.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/ahvJZZc.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<h4>Badges and plastics</h4>
<p>Due to its age, paint from a badge chipped off during removal so I had to fix it. I’ve used a standard black marker to cover all these tiny spots. Later, I’ve removed old glue from the rubber base and applied fresh double-sided adhesive tape on both rubber and badge.</p>
<figure><img src="https://i2.wp.com/i.imgur.com/NOiDSnH.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/NOiDSnH.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/i.imgur.com/BNXCrRr.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/BNXCrRr.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/i.imgur.com/kV0LeZa.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/kV0LeZa.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/i.imgur.com/bCVCgCg.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/bCVCgCg.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>I also had to address other scratched plastic parts. That was easily fixed by applying a thin layer of silicone oil.</p>
<figure><img src="https://i0.wp.com/i.imgur.com/CtuCJqQ.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/i.imgur.com/CtuCJqQ.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i0.wp.com/i.imgur.com/ON39XuB.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/i.imgur.com/ON39XuB.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i0.wp.com/i.imgur.com/U7CtSql.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/i.imgur.com/U7CtSql.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/i.imgur.com/dNAZrE2.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/dNAZrE2.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<h4>Keyboard cleaning</h4>
<p>Obviously, all keycaps had to be clean. This time, I had to remove every single keycap and clean it individually. It took a while to get it done properly 🙂</p>
<figure><img src="https://i1.wp.com/i.imgur.com/ULA06Gc.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/ULA06Gc.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/i.imgur.com/mr5aHKZ.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/mr5aHKZ.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/i.imgur.com/XbtgfZR.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/XbtgfZR.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>Don’t ask me why so late but this is the moment when I’ve realized there is a major failure :/</p>
<p>I’ve no idea why I didn’t spot it earlier. After assembly, it turned out that there is a small gap between parts. It is barely visible and only from a side of the case but I was pissed off at myself that I didn’t spot it and fix it before the case was painted.</p>
<figure><img src="https://i1.wp.com/i.imgur.com/k6m1xzj.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/k6m1xzj.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>Obviously, I didn’t have any spray paint left.</p>
<h4>The grand finale</h4>
<p>This restoration was rather time-consuming. It took more or less 15 workdays. This is because I had to wait for chemistry to fully cure before moving on to the next step.</p>
<p>So here it is. Fully restored Commodore SX-64 keyboard for Carrion. Hopefully, he will like it 🙂</p>
<figure><img src="https://i1.wp.com/i.imgur.com/6CTg8m3.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/6CTg8m3.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/i.imgur.com/BQN52yb.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/BQN52yb.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i0.wp.com/i.imgur.com/hAVfC07.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/i.imgur.com/hAVfC07.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/i.imgur.com/2po2LWV.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/2po2LWV.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/i.imgur.com/GEBvMrK.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/GEBvMrK.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/i.imgur.com/mopmvRq.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/mopmvRq.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/i.imgur.com/ivrOPkq.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/ivrOPkq.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/i.imgur.com/5JaaVBL.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/5JaaVBL.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<div><figure><img src="https://i1.wp.com/i.imgur.com/niV3pdG.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/niV3pdG.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>
<p>See you next time 😉</p>
<div><figure><img src="https://i1.wp.com/i.imgur.com/Ft92WpK.png?resize=413%2C413&amp;ssl=1" alt="" width="413" height="413" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/Ft92WpK.png?resize=413%2C413&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>
 </div>

</article></div>]]>
            </description>
            <link>https://retrohax.net/commodore-sx-64-keyboard-restoration/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23663298</guid>
            <pubDate>Sat, 27 Jun 2020 17:49:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don't Build Magic Link]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23663211">thread link</a>) | @jbarches
<br/>
June 27, 2020 | https://snaphabit.app/blog/password-less-login/ | <a href="https://web.archive.org/web/*/https://snaphabit.app/blog/password-less-login/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://snaphabit.app/blog/content/images/size/w300/2020/06/MagicLink-3.png 300w,
                            https://snaphabit.app/blog/content/images/size/w600/2020/06/MagicLink-3.png 600w,
                            https://snaphabit.app/blog/content/images/size/w1000/2020/06/MagicLink-3.png 1000w,
                            https://snaphabit.app/blog/content/images/size/w2000/2020/06/MagicLink-3.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://snaphabit.app/blog/content/images/size/w2000/2020/06/MagicLink-3.png" alt="Don't build password-less login">
            </figure>

            <section>
                <div>
                    <h3 id="a-metrics-driven-take-on-how-password-less-login-wasted-weeks-of-development-time-and-hurt-our-signup-funnel-">A metrics-driven take on how password-less login wasted weeks of development time and hurt our signup funnel.</h3><p>"Magic Link", also know as password-less login, enables users to sign in by clicking a link. With no need to remember a password or prove email ownership, <a href="https://medium.com/@kelvinvanamstel/should-we-embrace-magic-links-and-leave-passwords-alone-c73db7007fc4">many</a> <a href="https://techbeacon.com/security/your-passwordless-future-make-it-sooner-rather-later">people</a> have hailed "Magic Link" as the perfect authentication solution.</p><p>How it works on SnapHabit? After a user enters their enter email address, we direct them to their inbox to tap a link to sign in. Before diving into what went wrong, here's a snapshot of our authentication funnel:</p><ul><li><strong>11% of users</strong> required at least 4 magic-link emails before completing signing up.</li><li><strong>18% of users never finished signup (clicked the magic link)</strong>. On average, these users attempted signup twice, with several users submitting &gt; 10 times.</li></ul><!--kg-card-begin: html--><!--kg-card-end: html--><h2 id="-why-would-you-use-magic-link-anyways">... why would you use magic link, anyways?</h2><p>Friends are core to SnapHabit, so the functionality to send a friend request is critical. Phone number or email felt like the cheapest way to support a unique identifier — as it could be used for both authentication and finding a friend.</p><p>Like most services, we first looked at using "Sign in with Google/Facebook". However, Apple recently adjusted App Store Guidelines... starting June 30, <strong>"apps that use a social login service ... must also offer Sign in with Apple"</strong></p><figure><img src="https://snaphabit.app/blog/content/images/2020/06/Screen-Shot-2020-06-17-at-3.47.00-PM-2.png"><figcaption>App Store Guidelines, June 17, 2020</figcaption></figure><p>Apple Sign In supports <a href="https://support.apple.com/en-us/HT210425">"Hide My Email"</a>, so many users who sign in with Apple would not have a meaningful email attached to their account. Asking for a user's email after they chose to "hide it" would be a poor user experience.</p><p>So in summary, we had 4 options for account creation:</p><ol><li><strong>Email + Password</strong> ... requires forgot password and users to prove email ownership</li><li><strong>Support all third-party (Apple, Google, Facebook)</strong> ... and add a new unique identifier to allow friends to find each other, given email will not be sufficient</li><li><strong>Phone number magic link</strong> ... we were relying on Expo (previously did not support phone-number auth), and we also felt emails would be a good/cheap tool for communication</li><li><strong>Email magic link</strong> </li></ol><p>Email magic link felt... perfect! &nbsp;We built the login flow, complete with a custom email, instructional webpage, and deep linking. <strong>Hurrah, we had cracked the authentication funnel!</strong></p><!--kg-card-begin: html--><iframe width="560" height="315" src="https://www.youtube.com/embed/QoS2-mIuOZw" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><!--kg-card-end: html--><h2 id="what-went-wrong-and-how-we-tried-to-solve">What went wrong and how we tried to solve</h2><p><em>If you're interested in the technical details of how we implemented some of these fixes, let me know and we'll consider publishing.</em></p><h3 id="1-users-clicking-the-link-on-another-device-">1. Users clicking the link on another device.</h3><p>Of 10 users we chatted with who had issues, 4 tried to click the link on another device. There are two routes to solving this:</p><ul><li>technical solution to support this behavior (clicking the link on desktop will authenticate the user on mobile)</li><li>better instructional text</li></ul><p><strong>The latter was simpler, so we started with that:</strong></p><figure><img src="https://snaphabit.app/blog/content/images/2020/06/firstattempt.png"></figure><p><strong>And again.</strong></p><figure><img src="https://snaphabit.app/blog/content/images/2020/06/email.png"></figure><p><strong>And more.</strong></p><figure><img src="https://snaphabit.app/blog/content/images/2020/06/landingpage.png"></figure><h3 id="2-user-confusion-about-clicking-a-link-to-login">2. User confusion about clicking a link to login</h3><p>At least 2 people mentioned they simply did not understand that they needed to authenticate with email. &nbsp;To solve this, we added</p><ul><li>call-to-action to open Apple Mail or Gmail</li><li>disabled the "resend" button for 10 seconds, to encourage users to tap the mail CTA before attempting login again</li></ul><figure><img src="https://snaphabit.app/blog/content/images/2020/06/buttons.png"></figure><h3 id="3-users-entering-the-wrong-email">3. Users entering the wrong email</h3><p>Many users who did not finish finish signing up (eg. did not click email link) had accounts with a ".con" domain. &nbsp;We added an notice to alert users of a possibly unintended typo:</p><figure><img src="https://snaphabit.app/blog/content/images/2020/06/dotcon.png"></figure><h2 id="-what-s-next">... What's next</h2><div><p>Despite attempting to solve 1, 2 and 3, our funnel drop-off is still larger than we'd like (~15% of users do not open the email correctly).</p><p>So after two months of solution hackery, we're cutting our losses and adding sign in with Google, Facebook and Apple options. If we still see users opting for email sign-in and failing to complete, we'll consider making the full-circle shift back to an email/password model.<br><strong><br>I hope our sharing this painful journey can save you from taking a similar path!</strong> &nbsp;Let me know if you have any questions or feedback at <a href="https://snaphabit.app/cdn-cgi/l/email-protection" data-cfemail="325853595772415c53425a53505b461c5342421c">[email&nbsp;protected]</a></p></div><hr><p><em>Don't have SnapHabit yet? You can download the app on iOS <a href="https://apps.apple.com/us/app/snaphabit-ai-healthy-habits/id1494552185" rel="noopener noreferrer">here</a> and Android <a href="https://play.google.com/store/apps/details?id=io.gravitech.habit.staging" rel="noopener noreferrer">here</a>.</em></p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://snaphabit.app/blog/password-less-login/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23663211</guid>
            <pubDate>Sat, 27 Jun 2020 17:37:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple Silicon Changes Macs Forever]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23663200">thread link</a>) | @billyrobinson4
<br/>
June 27, 2020 | https://heartbeat.fritz.ai/how-apple-silicon-changes-mac-forever-d2682a9722df | <a href="https://web.archive.org/web/*/https://heartbeat.fritz.ai/how-apple-silicon-changes-mac-forever-d2682a9722df">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><h2 id="cb2b">WWDC20</h2><h2 id="087c">Learn more about Apple’s ARM-based silicon chips for Mac, announced at WWDC20</h2><div><div><div><p><a href="https://heartbeat.fritz.ai/@vhanagwal?source=post_page-----d2682a9722df----------------------" rel="noopener"><img alt="Vardhan Agrawal" src="https://miro.medium.com/fit/c/96/96/1*ORFRUf6O2Tk4XbG3kElncQ.jpeg" width="48" height="48"></a></p></div></div></div></div></div><div><figure><div><div><div><p><img src="https://miro.medium.com/max/60/1*3RTZkevqc5ZvJpivlnc1mg.jpeg?q=20" width="2500" height="1599" role="presentation"></p><p><img src="https://miro.medium.com/max/5000/1*3RTZkevqc5ZvJpivlnc1mg.jpeg" width="2500" height="1599" srcset="https://miro.medium.com/max/552/1*3RTZkevqc5ZvJpivlnc1mg.jpeg 276w, https://miro.medium.com/max/1104/1*3RTZkevqc5ZvJpivlnc1mg.jpeg 552w, https://miro.medium.com/max/1280/1*3RTZkevqc5ZvJpivlnc1mg.jpeg 640w, https://miro.medium.com/max/1456/1*3RTZkevqc5ZvJpivlnc1mg.jpeg 728w, https://miro.medium.com/max/1632/1*3RTZkevqc5ZvJpivlnc1mg.jpeg 816w, https://miro.medium.com/max/1808/1*3RTZkevqc5ZvJpivlnc1mg.jpeg 904w, https://miro.medium.com/max/1984/1*3RTZkevqc5ZvJpivlnc1mg.jpeg 992w, https://miro.medium.com/max/2160/1*3RTZkevqc5ZvJpivlnc1mg.jpeg 1080w, https://miro.medium.com/max/2700/1*3RTZkevqc5ZvJpivlnc1mg.jpeg 1350w, https://miro.medium.com/max/3240/1*3RTZkevqc5ZvJpivlnc1mg.jpeg 1620w, https://miro.medium.com/max/3780/1*3RTZkevqc5ZvJpivlnc1mg.jpeg 1890w, https://miro.medium.com/max/4320/1*3RTZkevqc5ZvJpivlnc1mg.jpeg 2160w, https://miro.medium.com/max/4800/1*3RTZkevqc5ZvJpivlnc1mg.jpeg 2400w" sizes="100vw" role="presentation"></p></div></div></div></figure></div><div><div><p id="93b7">At the end of the WWDC20 Keynote, Apple announced that it’s switching from Intel processors to its own: Apple Silicon. The release of custom Apple chips, powered by ARM, comes after a long history of using Intel-based chips, for the greater part of the 21st century.</p><p id="0fc0">Modeled after Apple’s use of its own chips on the iPhone, iPad, and Apple Watch, the company is switching to its own chips to give the Mac more performance per watt and better GPU performance.</p><p id="ecaf">Though we won’t go in-depth into the specific implications for machine learning, there’s a lot to be excited about when it comes to the future of ML development on Mac. Inevitably, the enhanced GPU performance will be a boon to machine learning developers, with benefits ranging from faster model training to reduced reliance on transfer learning. It will be interesting to see how ML engineers capitalize on Apple Silicon over time.</p></div></div></section><hr><section><div><div><p id="10c8">The Mac, often considered Apple’s flagship lineup, has seen a couple changes in the past. Let’s look at what those changes were and how they’ve contributed to the evolution of the Mac.</p><h2 id="114e">Motorola 68K to PowerPC</h2><p id="d699">One of the earliest transitions in chip architecture was the transition from Motorola 68K chips to IBM and Motorola PowerPC chips. This was an incredible transition, which significantly improved the Mac and played an important role in understanding future transitions.</p><figure><div><div><div><div><p><img src="https://miro.medium.com/max/60/1*gf2Y6U112riltsrAmT6VaA.png?q=20" width="780" height="439" role="presentation"></p><p><img src="https://miro.medium.com/max/1560/1*gf2Y6U112riltsrAmT6VaA.png" width="780" height="439" srcset="https://miro.medium.com/max/552/1*gf2Y6U112riltsrAmT6VaA.png 276w, https://miro.medium.com/max/1104/1*gf2Y6U112riltsrAmT6VaA.png 552w, https://miro.medium.com/max/1280/1*gf2Y6U112riltsrAmT6VaA.png 640w, https://miro.medium.com/max/1400/1*gf2Y6U112riltsrAmT6VaA.png 700w" sizes="700px" role="presentation"></p></div></div></div></div><figcaption>The original iMac with a PowerPC processor.</figcaption></figure><h2 id="ed43">PowerPC to Intel x86</h2><p id="6ac1">The most notable transition was the move from PowerPC chips to Intel processors, which have been used for almost half of the Mac’s history so far. With this transition, Apple announced a developer kit to help with the transition, similar to what they announced in the switch to Apple Silicon.</p><figure><div><div><div><div><p><img src="https://miro.medium.com/max/60/1*YIIun0yR2job_s0MRzSINg.png?q=20" width="1200" height="675" role="presentation"></p><p><img src="https://miro.medium.com/max/2400/1*YIIun0yR2job_s0MRzSINg.png" width="1200" height="675" srcset="https://miro.medium.com/max/552/1*YIIun0yR2job_s0MRzSINg.png 276w, https://miro.medium.com/max/1104/1*YIIun0yR2job_s0MRzSINg.png 552w, https://miro.medium.com/max/1280/1*YIIun0yR2job_s0MRzSINg.png 640w, https://miro.medium.com/max/1400/1*YIIun0yR2job_s0MRzSINg.png 700w" sizes="700px" role="presentation"></p></div></div></div></div><figcaption>A recent, Intel-based MacBook Pro.</figcaption></figure></div></div></section><hr><section></section><hr><section><div><div><p id="4c63">Undoubtedly, a switch to ARM-based Macs has a huge advantage for the performance and usability of Macs. Let’s look at how Apple Silicon will improve the Mac’s experience.</p><h2 id="71ef">Performance per Watt</h2><p id="e98c">Apple Silicon promises a stark improvement in performance per watt, meaning that the Mac could potentially promise desktop-level performance with the power consumption of a notebook computer, as exemplified by Apple’s diagram:</p><figure><div><div><div><div><p><img src="https://miro.medium.com/max/60/1*485W2PItyV9fz4UiWem0eQ.png?q=20" width="1720" height="953" role="presentation"></p><p><img src="https://miro.medium.com/max/3440/1*485W2PItyV9fz4UiWem0eQ.png" width="1720" height="953" srcset="https://miro.medium.com/max/552/1*485W2PItyV9fz4UiWem0eQ.png 276w, https://miro.medium.com/max/1104/1*485W2PItyV9fz4UiWem0eQ.png 552w, https://miro.medium.com/max/1280/1*485W2PItyV9fz4UiWem0eQ.png 640w, https://miro.medium.com/max/1400/1*485W2PItyV9fz4UiWem0eQ.png 700w" sizes="700px" role="presentation"></p></div></div></div></div><figcaption>Performance per watt for Apple Silicon</figcaption></figure><h2 id="95f4">Native Apps</h2><p id="b37d">Apps that support Apple Silicon natively will perform best on the new ARM-based Macs. Out-of-the-box, Apple’s own apps, including pro apps like Final Cut Pro and Logic Pro, will have native support for Apple Silicon. In addition, through their collaboration with Adobe, the Creative Cloud Suite will also have native support from the get-go. Eventually, Microsoft Office and other widely used programs will be able to take advantage of Apple Silicon’s performance.</p><figure><div><div><div><div><p><img src="https://miro.medium.com/max/60/1*AkSiIGraS55x_sZV5vt6_A.png?q=20" width="1080" height="607" role="presentation"></p><p><img src="https://miro.medium.com/max/2160/1*AkSiIGraS55x_sZV5vt6_A.png" width="1080" height="607" srcset="https://miro.medium.com/max/552/1*AkSiIGraS55x_sZV5vt6_A.png 276w, https://miro.medium.com/max/1104/1*AkSiIGraS55x_sZV5vt6_A.png 552w, https://miro.medium.com/max/1280/1*AkSiIGraS55x_sZV5vt6_A.png 640w, https://miro.medium.com/max/1400/1*AkSiIGraS55x_sZV5vt6_A.png 700w" sizes="700px" role="presentation"></p></div></div></div></div><figcaption>Photoshop running natively on an ARM-based Mac.</figcaption></figure><h2 id="2e35">iOS Apps on Mac</h2><p id="3611">Another incredible benefit of using the ARM architecture across iOS, macOS, and watchOS is the ability to run iOS apps natively on Apple Silicon Macs. Without any additional work from the developer, most iOS apps can be installed from the Mac App Store.</p><figure><div><div><div><div><p><img src="https://miro.medium.com/max/60/1*SdaPx8Kn2Nw08JFB6XbDvw.png?q=20" width="3359" height="1891" role="presentation"></p><p><img src="https://miro.medium.com/max/6718/1*SdaPx8Kn2Nw08JFB6XbDvw.png" width="3359" height="1891" srcset="https://miro.medium.com/max/552/1*SdaPx8Kn2Nw08JFB6XbDvw.png 276w, https://miro.medium.com/max/1104/1*SdaPx8Kn2Nw08JFB6XbDvw.png 552w, https://miro.medium.com/max/1280/1*SdaPx8Kn2Nw08JFB6XbDvw.png 640w, https://miro.medium.com/max/1400/1*SdaPx8Kn2Nw08JFB6XbDvw.png 700w" sizes="700px" role="presentation"></p></div></div></div></div><figcaption>Running Monument Valley and Fender Play, two popular iOS apps, on a Mac.</figcaption></figure><p id="4f66">To help developers transition their apps to support Apple Silicon, Apple has announced a whole host of tools to make native and simulated support for Apple Silicon as smooth as possible for users.</p><h2 id="0ebc">Universal 2</h2><p id="8277">As the name suggests, Universal 2 allows developers to quickly compile their apps for Apple Silicon while retaining support for Intel-based Macs. By using Universal 2 in Xcode, developers will be able to use the same binary for both Intel-based Macs, while providing a native experience for those who are using a Mac with Apple Silicon.</p><figure><div><div><div><div><p><img src="https://miro.medium.com/max/60/1*4Krp5sFt3beXnXbpuenl9Q.png?q=20" width="3360" height="2100" role="presentation"></p><p><img src="https://miro.medium.com/max/6720/1*4Krp5sFt3beXnXbpuenl9Q.png" width="3360" height="2100" srcset="https://miro.medium.com/max/552/1*4Krp5sFt3beXnXbpuenl9Q.png 276w, https://miro.medium.com/max/1104/1*4Krp5sFt3beXnXbpuenl9Q.png 552w, https://miro.medium.com/max/1280/1*4Krp5sFt3beXnXbpuenl9Q.png 640w, https://miro.medium.com/max/1400/1*4Krp5sFt3beXnXbpuenl9Q.png 700w" sizes="700px" role="presentation"></p></div></div></div></div><figcaption>Universal 2 for the same binary for Intel and ARM-based Macs.</figcaption></figure><h2 id="38e9">Rosetta 2</h2><p id="49cb">An upgrade from their previous version of Rosetta (for the Intel transition), Rosetta 2 provides similar capabilities as its previous counterpart — allowing Intel-based apps to run on Apple Silicon Macs. So if app developers haven’t yet recompiled their apps with Universal 2, their users can still access legacy versions of the app through Rosetta 2.</p><figure><div><div><div><div><p><img src="https://miro.medium.com/max/60/1*2qVtb8FXZoJARJJa-Pq0IQ.png?q=20" width="3360" height="2100" role="presentation"></p><p><img src="https://miro.medium.com/max/6720/1*2qVtb8FXZoJARJJa-Pq0IQ.png" width="3360" height="2100" srcset="https://miro.medium.com/max/552/1*2qVtb8FXZoJARJJa-Pq0IQ.png 276w, https://miro.medium.com/max/1104/1*2qVtb8FXZoJARJJa-Pq0IQ.png 552w, https://miro.medium.com/max/1280/1*2qVtb8FXZoJARJJa-Pq0IQ.png 640w, https://miro.medium.com/max/1400/1*2qVtb8FXZoJARJJa-Pq0IQ.png 700w" sizes="700px" role="presentation"></p></div></div></div></div><figcaption>Rosetta 2 for install-time translation for Intel-based apps.</figcaption></figure><h2 id="b5ed">Virtualization</h2><p id="d298">For developers who need to use Linux, Docker, or similar tools, Apple has also announced virtualization tools for ARM Macs. These tools are expected to provide a seamless transition to Apple Silicon for developers who need server-side development tools.</p><figure><div><div><div><div><p><img src="https://miro.medium.com/max/60/1*z8L5KciHtXn7DOG5_HO8Ag.png?q=20" width="3359" height="1884" role="presentation"></p><p><img src="https://miro.medium.com/max/6718/1*z8L5KciHtXn7DOG5_HO8Ag.png" width="3359" height="1884" srcset="https://miro.medium.com/max/552/1*z8L5KciHtXn7DOG5_HO8Ag.png 276w, https://miro.medium.com/max/1104/1*z8L5KciHtXn7DOG5_HO8Ag.png 552w, https://miro.medium.com/max/1280/1*z8L5KciHtXn7DOG5_HO8Ag.png 640w, https://miro.medium.com/max/1400/1*z8L5KciHtXn7DOG5_HO8Ag.png 700w" sizes="700px" role="presentation"></p></div></div></div></div><figcaption>Running an Apache server on an ARM-based Mac.</figcaption></figure><h2 id="f765">Developer Transition Kit</h2><p id="81af">Similar to the Intel transition, developers will be able to purchase a Developer Transition Kit, which comprises a Mac Mini enclosure fitted with the A12Z SoC — used on the latest iPad lineup. The Mac Mini will have 16GB of memory and a 512GB SSD — plenty for development needs. Also, macOS Big Sur and Xcode 12 will come pre-installed on the machine, which will be available for $500 (half the price of the Intel transition kit).</p><figure><div><div><div><div><p><img src="https://miro.medium.com/max/60/1*hpX5lvJahDiZXZxjGDDLMQ.png?q=20" width="1080" height="607" role="presentation"></p><p><img src="https://miro.medium.com/max/2160/1*hpX5lvJahDiZXZxjGDDLMQ.png" width="1080" height="607" srcset="https://miro.medium.com/max/552/1*hpX5lvJahDiZXZxjGDDLMQ.png 276w, https://miro.medium.com/max/1104/1*hpX5lvJahDiZXZxjGDDLMQ.png 552w, https://miro.medium.com/max/1280/1*hpX5lvJahDiZXZxjGDDLMQ.png 640w, https://miro.medium.com/max/1400/1*hpX5lvJahDiZXZxjGDDLMQ.png 700w" sizes="700px" role="presentation"></p></div></div></div></div><figcaption>Apple’s Mac Mini Based Developer Transition Kit</figcaption></figure><p id="de05">While Apple isn’t completely transitioning to Apple Silicon just yet, the announcement of their ARM-based chip for Mac is a huge step in a two year process to change Mac for the better.</p><p id="04c2">Stay tuned for some great new tutorials on the latest frameworks this week, and get ahead of the crowd by taking use of them before they’re released to the public in the fall.</p><p id="3993">In case you missed it, here’s the Keynote in all its glory:</p><figure><div></div></figure><p id="6139">Be sure to <strong>smash that “clap” button</strong> as many times as you can, <strong>share this article</strong> on social media, and <strong>follow me on Twitter.</strong></p></div></div></section><hr><section><div><div><p id="d325"><em>Editor’s Note:</em><a href="http://heartbeat.fritz.ai/" target="_blank" rel="noopener"><em> </em><strong><em>Heartbeat</em></strong></a><strong><em> </em></strong><em>is a contributor-driven online publication and community dedicated to exploring the emerging intersection of mobile app development and machine learning. We’re committed to supporting and inspiring developers and engineers from all walks of life.</em></p><p id="cfac"><em>Editorially independent, Heartbeat is sponsored and published by</em><a href="http://fritz.ai/" target="_blank" rel="noopener"><em> </em><strong><em>Fritz AI</em></strong></a><em>, the machine learning platform that helps developers teach devices to see, hear, sense, and think. We pay our contributors, and we don’t sell ads.</em></p><p id="5eba"><em>If you’d like to contribute, head on over to our</em><a target="_blank" rel="noopener" href="https://heartbeat.fritz.ai/call-for-contributors-october-2018-update-fee7f5b80f3e"><em> </em><strong><em>call for contributors</em></strong></a><em>. You can also sign up to receive our weekly newsletters (</em><a href="https://www.deeplearningweekly.com/" target="_blank" rel="noopener"><strong><em>Deep Learning Weekly</em></strong></a><em> and</em><a href="https://www.fritz.ai/newsletter" target="_blank" rel="noopener"><em> </em></a><em>the </em><a href="https://www.fritz.ai/newsletter/?utm_campaign=fritzai-newsletter&amp;utm_source=heartbeat-statement" target="_blank" rel="noopener"><strong><em>Fritz AI Newsletter</em></strong></a><em>), join us on</em><a href="https://join.slack.com/t/fritz-ai-community/shared_invite/enQtNTY5NDM2MTQwMTgwLWU4ZDEwNTAxYWE2YjIxZDllMTcxMWE4MGFhNDk5Y2QwNTcxYzEyNWZmZWEwMzE4NTFkOWY2NTM0OGQwYjM5Y2U" target="_blank" rel="noopener"><em> </em></a><a href="http://fritz.ai/slack" target="_blank" rel="noopener"><strong><em>Slack</em></strong></a><em>, and follow Fritz AI on</em><a href="https://twitter.com/fritzlabs" target="_blank" rel="noopener"><em> </em><strong><em>Twitter</em></strong></a><em> for all the latest in mobile machine learning.</em></p></div></div></section></div></div>]]>
            </description>
            <link>https://heartbeat.fritz.ai/how-apple-silicon-changes-mac-forever-d2682a9722df</link>
            <guid isPermaLink="false">hacker-news-small-sites-23663200</guid>
            <pubDate>Sat, 27 Jun 2020 17:35:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Facebook’s community standards censorship has far-reaching consequences]]>
            </title>
            <description>
<![CDATA[
Score 73 | Comments 28 (<a href="https://news.ycombinator.com/item?id=23663155">thread link</a>) | @corywatilo
<br/>
June 27, 2020 | https://watilo.com/facebooks-community-standards-censorship-has-far-reaching-consequences | <a href="https://web.archive.org/web/*/https://watilo.com/facebooks-community-standards-censorship-has-far-reaching-consequences">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post_body_1565683">

    
      <div><p>Facebook censorship has effectively barred my business from their platform and is materially impacting the livelihood of my customers.</p>
<p>For the past decade, Iâ€™ve run an online portfolio business on the side called <a href="https://foliohd.com/" target="_blank">FolioHD</a>. (You get a subdomain on the platform to host your portfolio, like mine at <a href="http://watilo.foliohd.com/">watilo.foliohd.com</a>.)</p>
<p>Unfortunately I have no insight into the offending content, and the offending content can be anything from a nippleÂ&nbsp;to now apparently <a href="https://www.washingtontimes.com/news/2020/jun/23/project-veritas-facebook-sting-moderators-brag-abo/" target="_blank">even a MAGA hat</a>.</p>
<p>Now I am personally blocked on Instagram from liking photos or sending DMs. I canâ€™t sign into my company Instagram account. And Facebook has reached into my Pageâ€™s support inbox and removed private message between myself and customers.<br></p><p><b>How I noticed</b></p><p>A few weeks ago, I was scrolling through my personal Instagram and double-tapped a photo. Instead of seeing a red heart, I received this message.<br></p><p><img src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/3509ecd9-6aeb-4004-b042-0d782cec404c/Screenshot_20200620-0840172.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20200627%2Fus-west-2%2Fs3%2Faws4_request&amp;X-Amz-Date=20200627T171501Z&amp;X-Amz-Expires=86400&amp;X-Amz-Signature=534498c02cd6adf24abad8b4848915ab86e2fc90c2bc390e986a256de8d3e10f&amp;X-Amz-SignedHeaders=host&amp;response-content-disposition=filename%20%3D%22Screenshot_20200620-0840172.png%22" title="Image: https://s3.us-west-2.amazonaws.com/secure.notion-static.com/3509ecd9-6aeb-4004-b042-0d782cec404c/Screenshot_20200620-0840172.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20200627%2Fus-west-2%2Fs3%2Faws4_request&amp;X-Amz-Date=20200627T171501Z&amp;X-Amz-Expires=86400&amp;X-Amz-Signature=534498c02cd6adf24abad8b4848915ab86e2fc90c2bc390e986a256de8d3e10f&amp;X-Amz-SignedHeaders=host&amp;response-content-disposition=filename%20%3D%22Screenshot_20200620-0840172.png%22"><br></p><p>Tapping â€œTell usâ€� simply says, â€œThanks for reporting this issue.â€�</p>
<p>In my Instagram bio is a link to my personal portfolio, <a href="http://watilo.foliohd.com/">watilo.foliohd.com</a>. Because of this link, I effectively became completely blocked from interacting with anyone on Instagram.<br></p><p><img src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/9db49566-898e-4743-a776-f38d5d97de0f/Screenshot_20200603-071310.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20200627%2Fus-west-2%2Fs3%2Faws4_request&amp;X-Amz-Date=20200627T171521Z&amp;X-Amz-Expires=86400&amp;X-Amz-Signature=fe284180ac384a5fcc2a2e80620b1591f6591c68f53de08d85c8379d579c0332&amp;X-Amz-SignedHeaders=host&amp;response-content-disposition=filename%20%3D%22Screenshot_20200603-071310.png%22"><br></p><p>As the result of a single person sharing a link to a portfolio that Facebook deemed to have offensive content, they have now blocked the entire <a href="http://foliohd.com/">foliohd.com</a> domain.</p>
<p>It even prevented me from sending direct messages with ANY links.<br></p><p><img src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/e21b85f5-439c-4956-b8f1-5f3d7af98cc4/Screenshot_20200619-2203122.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20200627%2Fus-west-2%2Fs3%2Faws4_request&amp;X-Amz-Date=20200627T171544Z&amp;X-Amz-Expires=86400&amp;X-Amz-Signature=7871c844ed24cdd872248679c05a4d8f3839c5a86be8849fe1467fa70036467f&amp;X-Amz-SignedHeaders=host&amp;response-content-disposition=filename%20%3D%22Screenshot_20200619-2203122.png%22"><br></p><p>In order to restore my personal Instagram account, Iâ€™d have to remove the URL from my bio.</p>
<p>Using Facebookâ€™s Sharing Debugger confirms the URL was blocked on the entire Facebook ecosystem.<br></p><p><img src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/ad2152fc-2508-4d44-af6b-6919b7aa6879/7474EA49-DE9C-431B-AA3B-2FCFCB41C0D6.jpeg?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20200627%2Fus-west-2%2Fs3%2Faws4_request&amp;X-Amz-Date=20200627T171615Z&amp;X-Amz-Expires=86400&amp;X-Amz-Signature=b09b9fa953466ec52e76fe5e106c82fe45b016c76167b551bbc2ef98a7a6da40&amp;X-Amz-SignedHeaders=host&amp;response-content-disposition=filename%20%3D%227474EA49-DE9C-431B-AA3B-2FCFCB41C0D6.jpeg%22"><br></p><p>Of course Facebook has a way to report this issue on their developer site, but we know where those messages go. (A giant black hole.)<br></p><p><img src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/381da3b4-f1cc-43fa-9d47-8eac7fd20337/77F62DF6-5BFE-43BA-BC3D-5A21AC463B26.jpeg?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20200627%2Fus-west-2%2Fs3%2Faws4_request&amp;X-Amz-Date=20200627T171640Z&amp;X-Amz-Expires=86400&amp;X-Amz-Signature=84831d9fcbca7433e84e476e3d8df870cbd7f76029a8940b60466264e883cfeb&amp;X-Amz-SignedHeaders=host&amp;response-content-disposition=filename%20%3D%2277F62DF6-5BFE-43BA-BC3D-5A21AC463B26.jpeg%22"><br></p><p>But the problems donâ€™t end there. Since Instagram has been seamlessly integrated into the Facebook ecosystem, any account containing a blocked URL on Facebook has related consequences on Instagram.</p>
<p>I canâ€™t sign into the FolioHD Instagram account, because Facebook wonâ€™t send a security code by email, presumably because it has <a href="http://foliohd.com/">foliohd.com</a> in the email.<br></p><p><img src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/e202aab8-6473-434f-ae77-76d2d35af868/0AEC68F1-F197-4BE2-9DD7-2ECB093730AB.jpeg?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20200627%2Fus-west-2%2Fs3%2Faws4_request&amp;X-Amz-Date=20200627T171702Z&amp;X-Amz-Expires=86400&amp;X-Amz-Signature=604194c7fa9965b2b07f147e2f57aefa4f404cb93aa07187f1fae7bbf69e0f8c&amp;X-Amz-SignedHeaders=host&amp;response-content-disposition=filename%20%3D%220AEC68F1-F197-4BE2-9DD7-2ECB093730AB.jpeg%22"><br></p><p>But it gets worse: Visiting the FolioHD Facebook support inbox has led me to discover that Facebook is removing private messages between customers and myself, because they contain a link to <a href="http://foliohd.com/" target="_blank">foliohd.com</a> inside of them.<br></p><div id="posthaven_gallery[1591206]">
          <p>
          <img src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2472433/StzACkbdfFfmQIBG7llsgKEseAE/large_1988198B-3D14-42A7-8911-326740A1C1F4.jpeg" data-posthaven-state="processed" data-medium-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2472433/StzACkbdfFfmQIBG7llsgKEseAE/medium_1988198B-3D14-42A7-8911-326740A1C1F4.jpeg" data-medium-width="800" data-medium-height="638" data-large-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2472433/StzACkbdfFfmQIBG7llsgKEseAE/large_1988198B-3D14-42A7-8911-326740A1C1F4.jpeg" data-large-width="1200" data-large-height="957" data-thumb-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2472433/StzACkbdfFfmQIBG7llsgKEseAE/thumb_1988198B-3D14-42A7-8911-326740A1C1F4.jpeg" data-thumb-width="200" data-thumb-height="200" data-xlarge-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2472433/StzACkbdfFfmQIBG7llsgKEseAE/xlarge_1988198B-3D14-42A7-8911-326740A1C1F4.jpeg" data-xlarge-width="1273" data-xlarge-height="1015" data-orig-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2472433/StzACkbdfFfmQIBG7llsgKEseAE/1988198B-3D14-42A7-8911-326740A1C1F4.jpeg" data-orig-width="1273" data-orig-height="1015" data-posthaven-id="2472433">
        </p>
          
        </div>
<p>Iâ€™m thankful I donâ€™t rely on the Facebook support inbox, but I do have an auto-reply set up for anyone who sends a message there, directing them to contact support via <a href="http://foliohd.com/">foliohd.com</a>.</p>
<p>Since Facebook is blocking links, that auto-reply no longer gets sent.</p>
<p>Any social posts created through a Buffer-style service, even using a bitly link, gets posted briefly, then removed, with no notice.</p>
<p>And the worst part: there is no way to resolve this.</p>
<p>Now my customers can no longer share links to their websites within the Facebook ecosystem. They had nothing to do with this, and yet their businesses are being affected.<br></p><p><b>My ask</b></p><p>My request to Facebook would be to reconsider how they handle sites with user-generated content, in the same way Google handles it in their index. If a subdomain contains offending content, it shouldnâ€™t poison the root domain and every other subdomain.</p>
<p>And Facebook should probably never weasel their way into private company inboxes to remove content retroactively. You break the trust of any business by pulling these kind of moves. How can we rely on you for anything if your censorship is a moving target?</p>
<p>And if anyone knows how to get Facebook to fix this, please let me know. Short of filing a lawsuit, Iâ€™m not sure how to get this resolved.<br></p></div>
    
  </div></div>]]>
            </description>
            <link>https://watilo.com/facebooks-community-standards-censorship-has-far-reaching-consequences</link>
            <guid isPermaLink="false">hacker-news-small-sites-23663155</guid>
            <pubDate>Sat, 27 Jun 2020 17:29:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MiniBoss – Pixel Art Tutorials for Video Games]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23663148">thread link</a>) | @anarchyrucks
<br/>
June 27, 2020 | https://blog.studiominiboss.com/pixelart | <a href="https://web.archive.org/web/*/https://blog.studiominiboss.com/pixelart">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

      <!-- BEGIN POSTS -->
      
        <article id="post-">

          
            <div>
              <div>
                
                <p>Here are all the pixel art tutorials made by <strong>Pedro</strong> :D</p><div><p>More info on his <strong><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fsaint11&amp;t=ZGExZjUyNDc4Njk5MWU5ODIxODVhNjJmODQ4MTUwODExMmY1MmJjMSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0">Patreon</a></strong> page!</p><p><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2FbePatron%3Fu%3D2279992&amp;t=ZDI3OTAxZmNiNzI1N2VlOTJlMzU5YTVmYWIwNWZkZjczODM1NTljZSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" target="_blank"><img src="https://66.media.tumblr.com/acde232a22d6cb93bb34a149f8a0dd7e/tumblr_inline_ow8slwrGUs1qdiwz3_500.png"></a></p></div><p><strong>Article #8: <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmedium.com%2Fpixel-grimoire%2Fhow-to-start-making-pixel-art-8-eb218a4637dd&amp;t=MWEwZGYzNTQ1OWVkZjdmZGMzMjAxODMwM2Q0MDg2MjU2YjQ3ODc4NyxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" target="_blank">Saving and Exporting Pixel Art</a></strong></p><p><strong><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmedium.com%2Fpixel-grimoire%2Fhow-to-start-making-pixel-art-8-eb218a4637dd&amp;t=MWEwZGYzNTQ1OWVkZjdmZGMzMjAxODMwM2Q0MDg2MjU2YjQ3ODc4NyxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" target="_blank"><img src="https://66.media.tumblr.com/f2daa6f4716afcc541fc01e24f155f31/tumblr_inline_pswg3uhLHV1qdiwz3_500.png"></a></strong></p><p><strong>Article #7: <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmedium.com%2Fpixel-grimoire%2Fhow-to-start-making-pixel-art-7-e504bfa4ddf2&amp;t=NjVhNGI4ODNlMzY4OWQyZGE2Y2M0Mzc2ZTczNDUwZTA0ZjU2OGFhOCxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" target="_blank">Working with Lines</a></strong></p><p><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmedium.com%2Fpixel-grimoire%2Fhow-to-start-making-pixel-art-7-e504bfa4ddf2&amp;t=NjVhNGI4ODNlMzY4OWQyZGE2Y2M0Mzc2ZTczNDUwZTA0ZjU2OGFhOCxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" target="_blank"><strong><img src="https://66.media.tumblr.com/1ee38f820c573f34a2559e57745230f2/tumblr_inline_pr7haxEbfx1qdiwz3_500.png"></strong></a></p><p><strong>#79 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2F79-jumping-25803471&amp;t=ODAzZWQ3MzRhNTg5MjBhYjIyYzI3MWZlNmYwYmFiODA2YWE0YTY4OSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="jumping" target="_blank">Jumping</a></strong></p><p><strong><img src="https://66.media.tumblr.com/25529b9c829e9714231ebd716e020425/tumblr_inline_pqi15m2n8k1qdiwz3_1280.gif"></strong></p><p><strong>Article #6 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmedium.com%2Fpixel-grimoire%2Fhow-to-start-making-pixel-art-6-a74f562a4056&amp;t=YjM5MTM2MDdmNzI2OTk3NDk5NjEyYTAwODdkZjAzYzIxMjY3NmEyMSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" target="_blank">Basic Color Theory</a></strong></p><p><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmedium.com%2Fpixel-grimoire%2Fhow-to-start-making-pixel-art-4-f57f51dcfa02&amp;t=YmRkMzJjZTBjODJlYzFiMmU0OWY4ZDkzOGY3NDA0Y2U2NzQ0MWRhMCxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" target="_blank"><strong><img src="https://66.media.tumblr.com/9bbb85c753b861eaa63a7c0d39bb7236/tumblr_inline_pl3bsxXuy01qdiwz3_500.png"></strong></a></p><p><strong>#78 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fimpact-23417521&amp;t=ODZkODRlNzM0MzMzMGI5YmE4ZmU4ZDdjYzIxOTkxYzY4NGI4NmVjOSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="impact" target="_blank">Impact</a></strong></p><p><strong><img src="https://66.media.tumblr.com/1ba8ce6801f7d6463f7c70252f58ff30/tumblr_inline_pjzse8KjHX1qdiwz3_1280.gif"></strong></p><p><strong>Article #5 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmedium.com%2Fpixel-grimoire%2Fhow-to-start-making-pixel-art-4-f57f51dcfa02&amp;t=YmRkMzJjZTBjODJlYzFiMmU0OWY4ZDkzOGY3NDA0Y2U2NzQ0MWRhMCxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" target="_blank">Basic Shading</a></strong></p><p><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2F79-jumping-25803471&amp;t=ODAzZWQ3MzRhNTg5MjBhYjIyYzI3MWZlNmYwYmFiODA2YWE0YTY4OSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" target="_blank"><strong><img src="https://66.media.tumblr.com/c47a895719717aa7b2a27c44d85ace6a/tumblr_inline_pimb83kJlG1qdiwz3_500.png"></strong></a></p><p><strong>Article #4 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmedium.com%2Fpixel-grimoire%2Fhow-to-start-making-pixel-art-4-ff4bfcd2d085%3Ffbclid%3DIwAR1HjxwMVuR8lzLoserMAEmXSqtdLqRUDq_oXd084KTyv-FoIBtDOA5g8x4&amp;t=OWI3ZWE4MDI1MjUxNzc2NjdkNTk5MzliNTA5NzZkOGJmODU3MzJjOSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" target="_blank">Anti-alias and banding</a></strong></p><p><strong><img src="https://66.media.tumblr.com/ac1bf1b88440e61864410a0c3a3b97e2/tumblr_inline_phucif1mLB1qdiwz3_500.png"></strong></p><p><strong>#77 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Ftop-down-tricks-22246917&amp;t=Yjk5NDFkMzE0OWFkNmFlNDBhMTk4MDdlYzAxYmUzYzIyMGM3MjM5NSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="top_down_tricks" target="_blank">Top down tricks</a></strong></p><p><strong><img src="https://66.media.tumblr.com/4e9f3c7c258e6569e26dbc3a23fcef51/tumblr_inline_ph4cqpw5xa1qdiwz3_1280.gif"></strong></p><p><strong>#76 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2F21959820&amp;t=NTUxN2UwNTQ3MTQ3N2FjY2YxOGZiMzNjODY1MDMyZjM4ZDIyMTk0YixUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="top_down_attack_animation" target="_blank">Top down attack animation</a></strong></p><p><strong><img src="https://66.media.tumblr.com/426290d81fb4dffad6f8e90358fe907d/tumblr_inline_pggo4tPVXv1qdiwz3_1280.gif"></strong></p><p><strong>#75 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fisometric-part-1-21638316&amp;t=NWUxZjliNDEyZDYxZmVlMDU2ZjY0OWQyZTY5YTU5NjZlYmVmN2UyNCxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="isometric_part_1" target="_blank">Isometric - part 1</a><br></strong></p><p><strong><img src="https://66.media.tumblr.com/2e2ccd4e5e5601c8fbb907a39cb56448/tumblr_inline_pfor33qFKB1qdiwz3_1280.gif"></strong></p><p><strong>#74 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Ftop-down-walk-21353953&amp;t=ZTJiYjljNDQ4ODk1MDI2N2Q1MTZjZDQ3OWMwZjNkOTY4NmRiZjUxYixUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="top_down_walk_cycle" target="_blank">Top down walk cycle</a></strong></p><p><strong><img src="https://66.media.tumblr.com/09b50a78bbb170d52cd1d81b037d68a2/tumblr_inline_peywa8D48v1qdiwz3_1280.gif"></strong></p><p><strong>Article #3 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmedium.com%2Fpixel-grimoire%2Fhow-to-start-making-pixel-art-3-c9eb70270fa1&amp;t=NzU2MmZlYzU1YzdlODU4ZGZmOGUzMmI2ZTE2Mzk5Y2E3MGVhYjNkZixUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" target="_blank">A basic Aseprite animation</a><br></strong></p><p><strong><img src="https://66.media.tumblr.com/2e4ed4f930c901c5151da05541b2620d/tumblr_inline_peaaqoqXgr1qdiwz3_500.gif"></strong></p><p><strong>Article #2 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmedium.com%2Fpixel-grimoire%2Fhow-to-start-making-pixel-art-2-bcd705cb04d7&amp;t=MDM5YTFjYTU1MTQyYzE4ZDRkYTY4NjY1ODY4MzgzYTU5ODI5ZGU3ZixUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" target="_blank">Cluster sketching and paiting</a></strong></p><p><strong><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmedium.com%2Fpixel-grimoire%2Fhow-to-start-making-pixel-art-2-bcd705cb04d7&amp;t=MDM5YTFjYTU1MTQyYzE4ZDRkYTY4NjY1ODY4MzgzYTU5ODI5ZGU3ZixUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" target="_blank"><img src="https://66.media.tumblr.com/ea1002e97dc39c1e15794c1ce1cc59c5/tumblr_inline_pd7jynCMjf1qdiwz3_500.png"></a></strong></p><p><strong>Article #1&nbsp;<a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmedium.com%2F%40saintjust%2Fhow-to-start-making-pixel-art-2d1e31a5ceab&amp;t=OTVkOTBhNDJmYjViMzlhZTk2ZjhjYjk1NDAwMzUxYWQ3OWFlZTFjMCxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" target="_blank">How to start making pixel art</a></strong></p><p><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmedium.com%2F%40saintjust%2Fhow-to-start-making-pixel-art-2d1e31a5ceab&amp;t=OTVkOTBhNDJmYjViMzlhZTk2ZjhjYjk1NDAwMzUxYWQ3OWFlZTFjMCxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" target="_blank"><img src="https://cdn-images-1.medium.com/max/600/1*8hOSIYTOWBg6ZZ5U9AkNcg.png"></a></p><p><strong>#73 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fswords-19905632&amp;t=NWNjMmMzNjVmOGNmZDE5M2Q3YWZjZmE2ZDVhNDVmYWQzZTcyNmM2OSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="swords" target="_blank">Swords<br></a><br><img src="https://66.media.tumblr.com/b1a0f06232943a7d373039321060a535/tumblr_inline_pbo31aS4eR1qdiwz3_1280.gif"></strong></p><p><strong>#72 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fwood-textures-19566524&amp;t=NWUyZWVjMjdlYTcwY2FlYWU5NTFlMWU0NjRkYzA4NzhkMjc5Y2I2NSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="wood" target="_blank">Wood</a></strong></p><p><strong><img src="https://66.media.tumblr.com/c676c50bf84d3150940658ebedf33f7e/tumblr_inline_paour7pXDi1qdiwz3_1280.gif"></strong></p><p><strong>#71 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fresizing-pixel-19266474&amp;t=MzMwNzM3MWJlNzUxOTczMjI2YzMzYWQxZGQ1OTI3ZGZhMWJlODZmMCxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="resizing_pixel_art" target="_blank">Resizing Pixel Art</a></strong></p><p><strong><img src="https://66.media.tumblr.com/db58bece8b4bd868a158472f72a422a6/tumblr_inline_p9wpubzPrs1qdiwz3_1280.gif"></strong></p><p><strong>#70 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fillumination-18822379&amp;t=MTA3M2JiNDZkNGY0NjVmM2FjM2YxMTkyZGU2M2QzOTAxN2Y1ZDc3YSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="illumination_techniques" target="_blank">Illumination Techniques</a></strong></p><p><strong><img src="https://66.media.tumblr.com/4dac1bba410ed77d79107fa0e6bcff2b/tumblr_inline_p8u9cb3DfX1qdiwz3_1280.gif"></strong></p><p><strong>#69 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fgems-18529700&amp;t=ZjhmNGQwY2QxODMwOGFiZWZmN2VlNjAwZGI0MjU2NjZhNTZlOGIwNyxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="gems" target="_blank">Gems</a></strong></p><p><strong><img src="https://66.media.tumblr.com/185b9a56ca05956afc30e6adca78a7ae/tumblr_inline_p86aamjHgS1qdiwz3_1280.gif"></strong></p><p><strong>#68 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Ffirearm-design-18248148&amp;t=MGZhZjFmOTRiOGQ5NmYyNTBlMmIyODFiMDk3YzNmNDBjNzUyODlmNyxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="firearm design" target="_blank">Firearm Design</a></strong><strong></strong></p><p><strong><img src="https://66.media.tumblr.com/352bc588bcfbb25c2cffc4f57a42b302/tumblr_inline_p7e57s9VqK1qdiwz3_1280.gif"></strong></p><div><p><strong>#67 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fholograms-ghost-17955725&amp;t=ZGYzOGQyNWFkM2YxNWFiY2JhMDhjNWZhMjliNmFlMmZhZjRmY2MzMixUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="holograms_ghosts" target="_blank">Holograms/Ghosts</a></strong></p><p><img src="https://66.media.tumblr.com/7c9fd061bb05b75f0afdf4bf3a58b9d6/tumblr_inline_p6oy9pkPSh1qdiwz3_1280.gif"></p></div><p><strong>#66 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fholograms-ghost-17955725&amp;t=ZGYzOGQyNWFkM2YxNWFiY2JhMDhjNWZhMjliNmFlMmZhZjRmY2MzMixUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="defend_take hit" target="_blank">Defend/Take Hit</a></strong></p><p><strong><img src="https://66.media.tumblr.com/7e3c1dda61552bddce34cd271eca4bd7/tumblr_inline_p5z21ntJRV1qdiwz3_1280.gif"></strong></p><p><strong>#65 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Ftop-down-houses-17397188&amp;t=MGNkY2Y2ZjJhYzA0YjU4MDk5YjQ3ZmZhZTRjZTEyNDM2OTMwYWNmOSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="top_down_houses" target="_blank">Top Down Houses</a></strong></p><p><strong><img src="https://66.media.tumblr.com/446bc1174a502f308ba129373d10d8e4/tumblr_inline_p5cf1kOWo31qdiwz3_1280.gif"></strong></p><p><strong>#64 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fice-and-snow-17113157&amp;t=OWJkZGNlY2FiM2ZlODAxY2Y4YTU1NzA4MGJmMmQ2YjZiMDY2MjI3OCxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="ice" target="_blank">Ice</a></strong></p><p><strong><img src="https://66.media.tumblr.com/6717e8d14a5e39f02c7933835f9af992/tumblr_inline_p4ilt5P9Vl1qdiwz3_1280.gif"></strong></p><p><strong>#63 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fspaceship-design-16838125&amp;t=ODU0YTBkOGE3MmMxOTA2N2QwNTdmMDkwYmYxM2E0YWQzYjIyMjhlYyxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="spaceships" target="_blank">Spaceships</a></strong></p><p><strong><img src="https://66.media.tumblr.com/58ab0bfc18e1ffeed0fab0bff95e32fe/tumblr_inline_p3szrphVi41qdiwz3_1280.gif"></strong></p><p><strong>#62 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fslide-roll-dash-16562907&amp;t=MzljOWQ5YjhkYjViNDIzNWQ2MmI1MzI2NjAyNzFlZWYwYzJkODExMyxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="slide_roll_dash" target="_blank">Slide/Roll/Dash</a></strong></p><p><strong><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fslide-roll-dash-16562907&amp;t=MzljOWQ5YjhkYjViNDIzNWQ2MmI1MzI2NjAyNzFlZWYwYzJkODExMyxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="slide_roll_dash" target="_blank"><img src="https://66.media.tumblr.com/158a10c2f4e97122281be2abfd631010/tumblr_inline_p336l6aiMT1qdiwz3_1280.gif"></a></strong></p><p><strong>#61 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fwall-slide-wall-16310292&amp;t=ZWZiMGJhZWNjMDcyYjVjNzk4YjVmMDcwNGIzYTBiNDgzYzNjZjdjNixUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="wall_slide" target="_blank">Wall slide/kick</a></strong></p><p><strong><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fwall-slide-wall-16310292&amp;t=ZWZiMGJhZWNjMDcyYjVjNzk4YjVmMDcwNGIzYTBiNDgzYzNjZjdjNixUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="wall_slide" target="_blank"><img src="https://66.media.tumblr.com/8b81155cc8cd14668d5a152887aad295/tumblr_inline_p2eoqrzfHA1qdiwz3_1280.gif"></a></strong></p><p><strong>#60 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fmodern-indoors-16066669&amp;t=OWM3NzU3ZGQ1MDQ0ODgzMGM1Y2FlNmExMzliYjVmZDUxZmVkZjU2OSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="modern_indoors" target="_blank">Modern/indoors</a></strong></p><p><strong><img src="https://66.media.tumblr.com/ac73f2a15fd31defe34ac2f5d956b31d/tumblr_inline_p1orxgcJmD1qdiwz3_1280.gif"></strong></p><p><strong>#59 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fdeath-take-hit-15846738&amp;t=YjY2NGJiNDk5YTNkNjE4NDkxYWRiYjUyMzQ2NjdiNTQ1NTE1ZDE2ZSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="death_take_hit" target="_blank">Death/take hit</a></strong></p><p><strong><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fdeath-take-hit-15846738&amp;t=YjY2NGJiNDk5YTNkNjE4NDkxYWRiYjUyMzQ2NjdiNTQ1NTE1ZDE2ZSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="death_take_hit" target="_blank"><img src="https://66.media.tumblr.com/04f5810a3d0a53ed58c75c9ce6d82475/tumblr_inline_p0yqobOhwU1qdiwz3_1280.gif"></a></strong></p><p><strong>#58 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fsand-15587559&amp;t=NjMwYzllNDA4OTFhZDgzZDIxMmFjMWVlMmJhMjdjZDlkNjkzMGViZCxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="sand_desert" target="_blank">Sand/desert</a><br></strong><br><img src="https://66.media.tumblr.com/32aba2ba47850b9a6b85dcf5e19a99aa/tumblr_inline_p06zrg4DCB1qdiwz3_1280.gif"></p><p><strong>#57 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fvegetation-part-15480982&amp;t=Y2Y3MzVjNTcwMjE4NWE1NDNjMTQwODhlMjI0YzBjMWRkOTAyMGM5NixUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="vegetation_part_3" target="_blank">Vegetation (part 3)</a></strong></p><p><strong><img src="https://66.media.tumblr.com/acd7dbec5acc6aa3635ede99314b8391/tumblr_inline_oztzxuuvxS1qdiwz3_1280.gif"></strong></p><p><strong>#56 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fcuteness-15259004&amp;t=Y2ExZDMzNTczM2Q2ZWI3MTgxMTI4ZmRjNjA4MWYwOWFiNzJkMzc5MSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="cuteness" target="_blank">Cuteness</a></strong></p><p><strong><img src="https://66.media.tumblr.com/fcf215f45da76769402971bd6d60a315/tumblr_inline_oz408xixEC1qdiwz3_1280.gif"></strong></p><p><strong>#55 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fmodular-15160612&amp;t=YjcxNTE2ZTEwYjBjN2Q4Mzc0NDE5NzI3ZTZlODViMjBjNWQxZWUxOCxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="modular_animation" target="_blank">Modular animation</a></strong></p><p><strong><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fmodular-15160612&amp;t=YjcxNTE2ZTEwYjBjN2Q4Mzc0NDE5NzI3ZTZlODViMjBjNWQxZWUxOCxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="modular_animation" target="_blank"><img src="https://66.media.tumblr.com/c33e906894e5f1de8a68715a2b1a0d37/tumblr_inline_oyt1js58Q61qdiwz3_1280.gif"></a></strong></p><p><strong>#54 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fbreaking-objects-15022934&amp;t=ZTY2YmMwODEwZTA0YTQzMzhiMzVkNDM1Njc5ZGNjNWIxYTM0MWI2OSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="breaking_objects" target="_blank">Breaking objects<br></a><br><img src="https://66.media.tumblr.com/6564f44187d76bbcfb536fd26302bd69/tumblr_inline_oydxyzvL4n1qdiwz3_1280.gif"></strong></p><p><strong>#53 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fdarkness-14908368&amp;t=YzQ0NjVjMjI5OWE4MjUyMTE3MDQxZjM0NzQ1ZDExOGI5ZjE2NDFmOCxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="darkness" target="_blank">Darkness<br></a></strong><br><img src="https://66.media.tumblr.com/8f080ee4dca5a9df14cfb83cbb5ddd12/tumblr_inline_oy15kgYIxL1qdiwz3_1280.gif"></p><p><strong>#52 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fui-9-slice-14798512&amp;t=NGEwNWNjMDFlOGE0N2RiMWVmM2QyYzRmOTljMWY0NWE0MTA5ODZhNSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="ui_the_9_slice" target="_blank">UI: the 9-slice</a></strong></p><p><strong><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fui-9-slice-14798512&amp;t=NGEwNWNjMDFlOGE0N2RiMWVmM2QyYzRmOTljMWY0NWE0MTA5ODZhNSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" target="_blank"><img src="https://66.media.tumblr.com/1f3f84b2a0d216cc9a619591570af461/tumblr_inline_oxo0ss6cS51qdiwz3_1280.gif"></a></strong></p><p><strong>#51 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2F1-bit-14560658&amp;t=MjZmYzdlY2Y5OWU1YjFmZmE4OWRhYTRjODg2OWJjN2UwNGI2ZTRjNixUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="1_bit" target="_blank">1-Bit</a></strong></p><p><strong><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2F1-bit-14560658&amp;t=MjZmYzdlY2Y5OWU1YjFmZmE4OWRhYTRjODg2OWJjN2UwNGI2ZTRjNixUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="1_bit" target="_blank"><img src="https://66.media.tumblr.com/6f8116faee656165c4bb5e07c2d8b96f/tumblr_inline_owypd7zuGz1qdiwz3_1280.gif"></a></strong></p><p><strong>#50 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fwind-tornado-50-14452186&amp;t=NWI0ZThkZTZjYjNhMzQ1M2EwOTE3ODA1OTQ5MmM4OTU0YTI1MTc1ZixUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="wind" target="_blank">Wind</a></strong></p><p><strong><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fwind-tornado-50-14452186&amp;t=NWI0ZThkZTZjYjNhMzQ1M2EwOTE3ODA1OTQ5MmM4OTU0YTI1MTc1ZixUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="wind" target="_blank"><img src="https://66.media.tumblr.com/d457d93b485de7b10bd0b779a7a17160/tumblr_inline_owlmtk9ILF1qdiwz3_1280.gif"></a></strong></p><p><strong>#49 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2FbePatron%3Fu%3D2279992&amp;t=ZDI3OTAxZmNiNzI1N2VlOTJlMzU5YTVmYWIwNWZkZjczODM1NTljZSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="space_stars" target="_blank">Space/stars</a></strong></p><p><strong><img src="https://66.media.tumblr.com/1e016fc3490e95f76fdb552072cd4c1d/tumblr_inline_ow8o0d0AFc1qdiwz3_1280.gif"></strong></p><p><strong>#48 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fsimple-walk-14234033&amp;t=MmY0M2IyZDQ4NTRjY2UwNGI5NjZhNGE1MjMwOGVlZWMzMTU3OTQzMSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="walk_cycle" target="_blank">Walk cycle</a></strong></p><p><strong><img src="https://66.media.tumblr.com/6759dacdbc0f4dd6e69257629960713f/tumblr_inline_ovvd6rE4kC1qdiwz3_1280.gif"></strong></p><p><strong>#47 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Foutlines-14106192&amp;t=Y2VmZTZmZmFmZTRjMTcwOTg2ZjQxYWRkMzlhOTliZDhjMjM4ZGEyOSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="outlines" target="_blank">Outlines<br></a><br><img src="https://66.media.tumblr.com/b1a3e5b4957aa2f44f5e8b27cdcee0e4/tumblr_inline_ovisyu8VPn1qdiwz3_1280.gif"></strong></p><p><strong>#46 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fquadruped-walk-14012170&amp;t=MjgyNTg4NWFmZDc2ZDZiZDQxYjk3M2ZjYWE0ZmFlOTRjMTFlNDQyYixUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="quadrupeds_walk" target="_blank">Quadrupeds walk/trot</a></strong></p><p><strong><img src="https://66.media.tumblr.com/1b921bdc088dd7c34a82aaa2b825b1ba/tumblr_inline_ov7mlgD0Xy1qdiwz3_1280.gif"></strong></p><p><strong>#45 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fshading-13869731&amp;t=ZDMyZGE3ZjQ5M2UwMWNmYWNhYWY4YTUxYTc0NDAxYzkzN2YzZTVhMixUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="shading" target="_blank">Shading</a></strong></p><p><strong><img src="https://66.media.tumblr.com/dd0829f69076cd6dbb4a634187d91f33/tumblr_inline_ouuq70nKac1qdiwz3_1280.gif"></strong></p><p><strong>#44 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fclouds-13744795&amp;t=ZTFhYmRiYzI2N2E3NzdlYjExMmQ1NmJmNTcxNWM1MDVkMDlmODliNyxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="clouds" target="_blank">Clouds</a></strong></p><p><strong><img src="https://66.media.tumblr.com/c5cc799376bd29e27e2428287e07f157/tumblr_inline_oug2m7pJuF1qdiwz3_1280.gif"></strong></p><div><p><strong>#43 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fenvironmental-13569268&amp;t=YWMwMDFjNGIxNzE4ZjUwNjI4ZDVlNTViZjZjYzVhMTI0ZDgyY2ZkYSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="environmental_hazards" target="_blank">Environmental hazards</a></strong></p><p><img src="https://66.media.tumblr.com/0520c37e79b4cdeaefd44094ba9249ca/tumblr_inline_ou2cmw0eNy1qdiwz3_1280.gif"></p></div><p><strong>#42 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Ffabric-flags-13288135&amp;t=YmY3MTdjM2RjNzE4MDk0ZWZjNmRlYmJhYTAyMjJlZmEzYWEyMDg2NSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="fabric_flags" target="_blank">Fabric/Flags</a></strong></p><p><strong><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Ffabric-flags-13288135&amp;t=YmY3MTdjM2RjNzE4MDk0ZWZjNmRlYmJhYTAyMjJlZmEzYWEyMDg2NSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="fabric_flags" target="_blank"><img src="https://66.media.tumblr.com/12bae334cfc713751d430b2be205d783/tumblr_inline_otpupsodce1qdiwz3_1280.gif"></a></strong></p><p><strong>#41 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fblood-and-guts-13092502&amp;t=NmJhMWVlZDU2ZDFlOWE2ZTFiMTU4ZjllYmVmMGYxM2Y2YjA1NGYyMCxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="blood_and_guts" target="_blank">Blood and guts</a></strong></p><p><strong><img src="https://66.media.tumblr.com/16de890557bee9a6ddde41ecd7bff166/tumblr_inline_otchccuVi21qdiwz3_1280.gif"></strong></p><p><strong>#40 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fmaking-tiles-12881715&amp;t=YTlhM2FjZGM2NmEwYzZiNzgwN2I0NTkyMzI2MWEzNjg4YmRlYjViMyxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="making_tiles" target="_blank">Making tiles</a></strong></p><p><strong><img src="https://66.media.tumblr.com/81e7da5a93664746b2ab7d2f8ab86c7a/tumblr_inline_oszpmzEqqA1qdiwz3_1280.gif"></strong></p><p><strong>#39 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fcharacter-idle-12464240&amp;t=MzQ4MzUxYmM1YWMyZmJkNTUwMzZmNWMyMzkzNTY0MjE0NzM5YTMzNSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="character_idle" target="_blank">Character idle</a></strong></p><p><strong><img src="https://66.media.tumblr.com/ed4ce7ac0af70344aa71f6592dc52a1f/tumblr_inline_osoosucFqj1qdiwz3_1280.gif"></strong></p><p><strong>#38 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fbullets-12176568&amp;t=Y2UzYzE1NTk4ZDU4MzFmMmE4MTAyNWI5OTQyNTE2ZmRkYWQ4NThlNSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="bullets" target="_blank">Bullets</a></strong></p><p><strong><img src="https://66.media.tumblr.com/465c75a2dd8e00c8147ba8c34117a4a4/tumblr_inline_os9wwuenmW1qdiwz3_1280.gif"></strong></p><p><strong>#37 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fmetals-11859263&amp;t=OTBiMjQ3NmI1MjM1NGEzYjIxZjI3NGI0YmJhZWNlNTAxMTI0NWU0OSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="metals" target="_blank">Metals</a></strong></p><p><strong><img src="https://66.media.tumblr.com/4def0d40293de8e12e53eca02b9d856b/tumblr_inline_os0zezXKPr1qdiwz3_1280.gif"></strong></p><p><strong>#36 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fsquash-and-11713421&amp;t=YjU2NTBkYTg1M2IzYTZiMGFhNDA1ZGNkNzljY2FiNmJkMmI1NGIwOSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="squash_and_stretch" target="_blank">Squash and stretch</a></strong></p><p><img src="https://66.media.tumblr.com/febaa555f55d54b0116e758a5e6e33e9/tumblr_inline_orjleve9zU1qdiwz3_1280.gif"></p><p><strong>#35 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fmotion-blur-11596285&amp;t=YjA5YjM3MmNlMTU1MDM4ODZiYTYzMDgxZWRlMTYyNGU3NjM5MTAxMSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="motion_blur" target="_blank">Motion blur</a></strong></p><p><img src="http://i.imgur.com/WQ6WdOF.gif"></p><p><strong>#34 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fmotion-blur-11596285&amp;t=YjA5YjM3MmNlMTU1MDM4ODZiYTYzMDgxZWRlMTYyNGU3NjM5MTAxMSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="city_backgrounds" target="_blank">City backgrounds</a></strong></p><p><strong><img src="https://66.media.tumblr.com/b9a075aa4db065f5117e63e36f21b102/tumblr_inline_orlnm2ltXC1qdiwz3_1280.gif"></strong></p><p><strong>#33 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fpixel-art-part-2-11225146&amp;t=ZTYxMzRmZDhhODQ0NWQzZmNhYTE0MzE2MjMzYWUyNjYwNWE0YmM2OSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="pixel_art_fundamentals&quot;&quot;" target="_blank">Pixel art fundamentals - part 2</a></strong></p><p><img src="https://66.media.tumblr.com/07a35e4721111086107360f5dde30405/tumblr_inline_orlnp1zp5b1qdiwz3_1280.gif"></p><p><strong>#32 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fvegetation-part-10886532&amp;t=YTRlNzFmMGE0NDgxMDU2MTBlZmM5NGQxYjVlNTY1ZGQxMGY2NzRkYSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="vegetation_tutorial_part_2" target="_blank">Vegetation tutorial - part 2</a></strong></p><p><strong><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fvegetation-part-10886532&amp;t=YTRlNzFmMGE0NDgxMDU2MTBlZmM5NGQxYjVlNTY1ZGQxMGY2NzRkYSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="vegetation_tutorial_part_2" target="_blank"><img src="https://66.media.tumblr.com/6eee0221675fe00e7ef022e6974a73b7/tumblr_inline_orlnpnNUR91qdiwz3_1280.gif"></a></strong></p><p><strong>#31 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Frock-formations-9856719&amp;t=YjIzYTFlYThhMzgzMmUzM2YyNGVhOThlYzZmMmQ0YzQzYzc4MTFhYixUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="rock_formations" target="_blank">Rock formations</a></strong></p><p><img src="https://66.media.tumblr.com/8ecbf0419be33eacf34e0254f015a9cc/tumblr_inline_orlnq6xMOH1qdiwz3_1280.gif"></p><p><strong>#30 <a href="https://t.umblr.com/redirect?z=denied%3A%2522https%3A%2F%2Fwww.patreon.com%2Fposts%2Ffluids-slimes-929310&amp;t=ZjNiYzc3YTIxMGNkNGVhOWQxNTM5YjMwODVlMjQzMjU1MDc4NTc0YixUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="fluis_slime" target="_blank">Fluids/Slime</a></strong></p><p><img src="https://66.media.tumblr.com/bc2dae24ca515ded9e26742af77ae728/tumblr_inline_orlnrvmBLz1qdiwz3_1280.gif"></p><p><strong>#29 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fwings-flying-8869136&amp;t=OGNlYTVhMTI5Y2UwMjhkZjZlZTdkNTVmM2ZkMDdmZmQ0Mzc5ODZhOSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="wings_flying tutorial" target="_blank">Wings/Flying tutorial</a></strong></p><p><img src="https://66.media.tumblr.com/021149062db027e39b5a5895f6489c4d/tumblr_inline_orlnshpN511qdiwz3_1280.gif"></p><div><p><strong>#28 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Flight-magic-8781428&amp;t=NTAwNjBkMjNiYWU5MDM5MTllZTRhZDg4N2JlNjFiZTQ0ZmRiOWY3YyxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="light_magic_effects" target="_blank">Light Magic Effects</a></strong></p><p><img src="https://66.media.tumblr.com/4ec68347d9ca8883694db62edab08dab/tumblr_inline_orlnsytOD71qdiwz3_1280.gif"></p></div><div><p><strong>#27 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fportraits-8693396&amp;t=MmNkYzg0NjNmOWUxMTkwMmZhYmNiYmRiMWQxNWM4MzE4MTA2OWI1YyxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="portraits" target="_blank">Portraits</a></strong></p><p><img src="https://66.media.tumblr.com/5a2c87747dadf61ce6411d6ce62f68be/tumblr_inline_orlntjXTDN1qdiwz3_1280.gif"></p></div><p><strong>#26 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fdark-magic-8600078&amp;t=NGFmYTllMmE1Y2I0ZDJiMTRhM2Y0MzU2YmI4NDFmY2VmYWFlZTk0NCxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="dark_magic_effects" target="_blank">Dark Magic Effects</a></strong></p><p><img src="https://66.media.tumblr.com/c31c60c3a9bc6792dd6ae2f1a8417327/tumblr_inline_orlnu2Blmc1qdiwz3_1280.gif"></p><p><strong>#25 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fspaceship-8518887&amp;t=OGZjM2IzMGFiZGE1YTZkZWY3YTRmOWUyOTRiYzBmNjUyNzU1MmViZixUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="spaceship_propulsion_tutorial" target="_blank">Spaceship propulsion tutorial</a></strong></p><p><img src="https://66.media.tumblr.com/00e6aad68c668d65b067f2af736a8a80/tumblr_inline_orlnvr6vA11qdiwz3_1280.gif"></p><p><strong>#24 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fruins-tutorial-8183989&amp;t=ZmI3ZTFhM2E1ZTNmZWMyNTlhZTFlNTViODkxYjIwNzdhNTdmOTViZSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="ruins_tutorial" target="_blank">Ruins tutorial</a></strong></p><p><img src="https://66.media.tumblr.com/205888769a88fae746d9c7b448afbd68/tumblr_inline_orlnw86N3e1qdiwz3_1280.gif"></p><p><strong>#23 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fpixel-art-8107774&amp;t=MGE4MzU2ZjFlNmYxNjUzODJlMTQ2ZGRhMmYwYTNmNDhlZjhlZDE3MCxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="pixel_art_process" target="_blank">Pixel art process</a></strong></p><p><img src="https://66.media.tumblr.com/5946dc48dc257f65aa7e9f17a451df24/tumblr_inline_orlo18yAGa1qdiwz3_1280.gif"></p><p><em>Reading text with a timer is a bit stressful, so I added still frames of this tutorial:</em></p><p><img src="https://66.media.tumblr.com/62ba7558e5fedd68ef81cf347dde237e/tumblr_inline_ooxczkeRHC1qdiwz3_1280.png"></p><p><img src="https://66.media.tumblr.com/b6c46fb3f9fb83f39d429e7ab094e622/tumblr_inline_ooxd08TEod1qdiwz3_1280.png"></p><p><img src="https://66.media.tumblr.com/4e338c6a6207f15b3da9c6abb086b973/tumblr_inline_ooxd0cZmWm1qdiwz3_1280.png"></p><p><img src="https://66.media.tumblr.com/830a2f6a3082b8b31ed2610decb0c14d/tumblr_inline_ooxd0fI4rX1qdiwz3_1280.png"></p><p><img src="https://66.media.tumblr.com/ae28465631d7bd9768ad5471368110bf/tumblr_inline_ooxd0j6VT91qdiwz3_1280.png"></p><p><img src="https://66.media.tumblr.com/ffb990c7ca4a7b0b64c0817e04266cdb/tumblr_inline_ooxd0nVSNx1qdiwz3_1280.png"></p><p><img src="https://66.media.tumblr.com/391f1da109ac109c6e75a5f84112c229/tumblr_inline_ooxd11rnmR1qdiwz3_1280.png"></p><p><img src="https://66.media.tumblr.com/38499d507673bf66b12de08d68467545/tumblr_inline_ooxd15Ds031qdiwz3_1280.png"></p><p><img src="https://66.media.tumblr.com/f686c03f4ae745f22f9aafa03766b92a/tumblr_inline_ooxd1aEUYz1qdiwz3_1280.png"></p><p><strong>#22 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fanimation-easing-8030922&amp;t=ZjA2MTk5NTlhOGI3ZDU1YWUyMDEyMDg1ZWE3ZjNiYzQ4YjA3MzM1MyxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="animation_easings" target="_blank">Animation Easing</a></strong></p><p><img src="https://66.media.tumblr.com/aa1ee58decd2fb3100c47429ea61f31d/tumblr_inline_orlo2xZqfx1qdiwz3_1280.gif"></p><p><strong>#21 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Frender-tricks-7947098&amp;t=MDMxNjBkMmJhNDEyMTkwNWJjYjVhMDE5NGM1ZTMzMzhiNGQzNWVjMSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="render_tricks" target="_blank">Render Tricks</a></strong></p><p><img src="https://66.media.tumblr.com/9a7eb190e3c573c45b5872632d47c524/tumblr_inline_orlo3psQ0i1qdiwz3_1280.gif"></p><p><strong>#20 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fparallax-and-7863658&amp;t=ODBlZTE1MDViZjM2NzI0MDMwMTk1MGUxOTY1MTBmNTAxNTUzMjZmMSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="parallax_and_depths" target="_blank"> Parallax and Depth</a></strong></p><p><img src="https://66.media.tumblr.com/f5b88aef57c0b3fbed9f050d29476c8e/tumblr_inline_orlo42MjMu1qdiwz3_1280.gif"></p><p><strong>#19 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fmachines-and-7800465&amp;t=ZWEyMjRiN2RkYjhiZTkyMDljZDc2NGE4ZWYxODc1MDQzYmUzNmIyOSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="machines_and_weird_tech_tutorial" target="_blank">Machines and Weird Tech Tutorial</a></strong></p><p><img src="https://66.media.tumblr.com/ee67155fe94fad79fe1edae446679f9e/tumblr_inline_orlo4tzTNU1qdiwz3_1280.gif"></p><div><p><strong>#18 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fexplosions-part-7719254&amp;t=ZjQyMWRjZWM2Yzc2ZjU4NjAwM2FjM2NlODVhNDVlYWQ2YjI0YTZmMyxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="explosions_part_1" target="_blank">Explosions - part 1</a></strong></p><p><img src="https://66.media.tumblr.com/c108e82efee42056001fd1fcb415be5e/tumblr_inline_orlowlgPOa1qdiwz3_1280.gif"></p></div><p><strong>#17 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2F1-pixel-movement-7652033&amp;t=MTI5Yjk4MTMxZWMxMWJkOGVlOTIxYjZhODdjZWI5MTEwMTQ2NGJjOCxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="pixel_movement_tutorial" target="_blank">&lt;1 Pixel Movement Tutorial</a></strong></p><p><img src="https://66.media.tumblr.com/518be4ef8ac9ecc55cbffb8fa39244c4/tumblr_inline_orlow6mIGN1qdiwz3_1280.gif"></p><div><p><strong>#16 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fanimation-7585006&amp;t=MmU2NThkODc2Yzk3OGMzNjFmZGVhMTY0MWVmMDgwNmQ3OTIzZjY2ZixUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="animation_planning" target="_blank">Animation planning</a></strong></p><p><img src="https://66.media.tumblr.com/f708006f5b8c3466797f53e097842831/tumblr_inline_orlot4Lxqp1qdiwz3_1280.gif"></p></div><div><p><strong>#15 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fcharacter-design-7530899&amp;t=ZTgxYWZmNzcwMzQ3MDBiYWRhMjAxM2M2MGFhNjk5ZDJkNmU0NjQ0NCxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="character_desing" target="_blank">Character Desing 1</a></strong></p><p><img src="https://66.media.tumblr.com/1959e78c9b12d15931a3d64f3a82aeee/tumblr_inline_orlorl8LQ71qdiwz3_1280.gif"></p></div><div><p><strong>#14 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fskulls-and-bones-7475695&amp;t=M2IzYWNkMGVkZWU0YzUxZGVmMTRiMDI5MTFlMzNiMDRhN2FmNjcwNCxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="skull_and_bones_tutorial" target="_blank">Skull and bones tutorial</a></strong></p><p><img src="https://66.media.tumblr.com/12471723973d8df607799726db0cfaec/tumblr_inline_orlopmAovs1qdiwz3_1280.gif"></p></div><p><strong>#13 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fvegetation-part-7416630&amp;t=NzUxYmQwMDQ4ZjYxNzlhZmZmNTYzNzQxYmFiYTliN2QzYTc2YWRlYSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="vegetation_tutorial_part_1" target="_blank">Vegetation tutorial - part 1</a></strong></p><p><img src="https://66.media.tumblr.com/9ae1c51e0ff766a9ddb4fe32b1604a06/tumblr_inline_orlop1s4SE1qdiwz3_1280.gif"></p><p><strong>#12 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fseamless-7346998&amp;t=ZjliNDg4ZGM5OGQzNmFkODM5OWNhY2U5ZGQ0Y2ZmN2YxODcyYTdlNyxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="seamless_animation_tutorial" target="_blank">Seamless animation tutorial</a></strong></p><p><img src="https://66.media.tumblr.com/7c1606ece3701f0b31abc75c1fec3cf6/tumblr_inline_orlomdG0Dx1qdiwz3_1280.gif"></p><div><p><strong>#11 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Ffire-tutorial-7293859&amp;t=Y2JkNTQyNDZkMDEzZTlkMjRlMzk1NjlhYWRiMTI3OWUyYTIzYzZhMixUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="fire_tutorial" target="_blank">Fire tutorial</a></strong></p><p><img src="https://66.media.tumblr.com/29476fe99b2e2eb0ed3504b5740ac40f/tumblr_inline_orlohdk66v1qdiwz3_1280.gif"></p></div><p><strong>#10 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fwater-tutorial-7242348&amp;t=NDUwZDdiNmE4ZWI1NjVmY2I3NDY4Mjg5ZTA3MjQ2ZTgzNDVlMTVmOSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="water_tutorial" target="_blank">Water tutorial<br></a></strong><br><img src="https://66.media.tumblr.com/dc4c9898545bf7a2381ed9a3516833ed/tumblr_inline_orlogobyc71qdiwz3_1280.gif"></p><div><p><strong>#9 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Flevel-design-7190330&amp;t=YzY2NGYyYzJmOTQyNmM0MGYyYTU2NWMwZTViZGM1OGJmZTcwYWNiOCxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="level_design_progression" target="_blank">Level design progression</a></strong></p><p><img src="https://66.media.tumblr.com/8ba0dba7ef921d03ddc63d17f6f7cbab/tumblr_inline_orlog5ekZ11qdiwz3_1280.gif"></p></div><p><strong>#8 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fglitch-effect-7130333&amp;t=YWYwZTMyMzViZmRjOGY0YTAyMmVmMGVlMzYwZDNjNmE2YzhjNWM0OCxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="glitch_effect_tutorial" target="_blank"> Glitch effect tutorial</a></strong></p><p><img src="https://66.media.tumblr.com/ad5f9004f40554af1aa83f3d6d7513c6/tumblr_inline_orlof1K8R41qdiwz3_1280.gif"></p><p><strong>#7 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Felectricity-7075305&amp;t=MjViMzZkN2U0YmU5MDdlMmE2ODIyMDkyZGU3M2M2ODNkOTM3YjE5YixUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="electricity_tutorial" target="_blank">Electricity tutorial</a></strong></p><p><img src="https://i.imgur.com/cxz6GRE.gif"></p><p><strong>#6 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Ftop-down-run-7023263&amp;t=OGI0NWQzOTk1YTc4NGJhNDQyNWI0MzA5NjQ1NzkyOWQ4ZDhkN2VhZixUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="top_down_run_cycle" target="_blank">Top down run cycle</a></strong></p><p><img src="https://66.media.tumblr.com/68b72ba96ab4ea407320c56d43b6905a/tumblr_inline_orlp5ccduy1qdiwz3_1280.gif"></p><p><strong>#5</strong> <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fpixel-art-1-6971422&amp;t=OTc3YjBkNWFmOWEwYWE3OTljN2E1YWI1NzI1Mzk1N2JiNjUxYzI4MSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="pixel_art_fundamentals" target="_blank"><strong>Pixel art fundamentals</strong></a></p><p><img src="https://66.media.tumblr.com/b48321d1a3cd0a1b570dd2f696247353/tumblr_inline_orlo88y0i81qdiwz3_1280.gif"></p><p><strong>#4 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fsimple-run-6914055&amp;t=M2NhYmY2NGNiMzk1NDM3OTMyYTI4YjU5ZDhjY2MwN2MxYTYxODRmYixUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="simple_run_tutorial" target="_blank">Simple run tutorial</a></strong></p><p><img src="https://66.media.tumblr.com/f2658a4754e27310eec0ab058dd5110a/tumblr_inline_orlo7sMewo1qdiwz3_1280.gif"></p><p><strong>#3 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fsmoke-animation-6851636&amp;t=Y2I0NGVkNzk0MzI2ZDVhNTlkZDc0ZDIzNTgxMGI0NDk3Y2NhZDJmZCxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="smoke_animation" target="_blank">Smoke animation</a></strong></p><p><img src="https://66.media.tumblr.com/0a09c626ab6664aff9efaa399c279f9e/tumblr_inline_orlo74zaAn1qdiwz3_1280.gif"></p><p><strong>#2 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fsimple-attack-6837623&amp;t=MjJmZDY4M2ViNTY5NmI4NzE5ZDQ3OGRkOGJjNTNkNDZkYTM1ZjY3NyxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="simple_attack_animation" target="_blank">Simple attack animation</a></strong></p><p><img src="https://66.media.tumblr.com/f725cae9165d047c2f669ec4b204ccba/tumblr_inline_orlo6o5lyD1qdiwz3_1280.gif"></p><p><strong>#1 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fsimple-shine-6837557&amp;t=NjkzMmNlYzU4NWVhMDM1Nzg1ZGU2NjdkYTBmMjcwNjc4MTQzMWY0ZSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="simple_shine_tutorial" target="_blank">Simple shine Tutorial</a></strong></p><p><img src="https://66.media.tumblr.com/4fcef2a23bdcd59c03d432c7e3361b7e/tumblr_inline_orlo5uLdb71qdiwz3_1280.gif"></p>
              </div>
          

          

          

          

          

          

          

          

          

          

          

          
            

            
          

          </div><!-- /.post-panel -->
          
        </article><!-- /.post -->
      
      <!-- END POSTS -->

      

      

      

    </div></div>]]>
            </description>
            <link>https://blog.studiominiboss.com/pixelart</link>
            <guid isPermaLink="false">hacker-news-small-sites-23663148</guid>
            <pubDate>Sat, 27 Jun 2020 17:28:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ultrasound Networking (2014)]]>
            </title>
            <description>
<![CDATA[
Score 31 | Comments 16 (<a href="https://news.ycombinator.com/item?id=23663097">thread link</a>) | @funspectre
<br/>
June 27, 2020 | https://www.anfractuosity.com/projects/ultrasound-networking/ | <a href="https://web.archive.org/web/*/https://www.anfractuosity.com/projects/ultrasound-networking/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
                        




<p>We present a simple to use implementation of networking across ultrasonic frequencies, by making use of Gnuradio and a microphone and speakers. This allows you to use <strong>TCP/IP</strong>,<strong>UDP</strong> across an audio link.</p>



<p>In order to follow this tutorial we recommend you use the LiveDVD release of Gnuradio (which is basically a Ubuntu distribution, with gnuradio already installed). This is easily downloadable from <a href="https://gnuradio.org/redmine/news/31">http://gnuradio.org/redmine/news/31</a>. First of all you will need to download the patch we made to Gnuradio, to a USB stick. You can download the patch from <a href="https://github.com/anfractuosity/ultrasonicnetworking/archive/master.zip">https://github.com/anfractuosity/ultrasonicnetworking/archive/master.zip</a>. In order to use the patch, you need to be root, so type <strong>‘sudo bash’</strong>, then unzip the patch, and simply run setup.sh, by typing <strong>./setup.sh</strong>. The setup file simply patches the Gnuradio packet encoder and decoder, in order to support variable length packets.</p>



<p>After running <strong>setup.py</strong>, you can then initialise Gnuradio, which you need to run as root, so do <strong>sudo gnuradio-companion</strong>. And then load a.grc on your first laptop.</p>



<p><strong>Figure 1</strong> depicts our graph which enables us to perform the ultrasonic networking. We will now describe how the graph functions through each block. The first block in the top left, is the TUNTAP PDU, this allows you to create a virtual network interface, through which we can send and receive packets.</p>



<p>We use the “PDU to tagged Stream” block to convert the packets received from the virtual NIC, into a byte stream for the packet encoder to process. We can’t directly attach the output of the tagged stream to the GFSK modulator, as we need to add a checksum, through the use of CRC and also we need to add a preamble and header onto the packet – this is all achieved through the use of the packet encoder.</p>



<p>A preamble is essentially a series of bits, which can be detected at the receiver end, in order to correctly align bits, to the correct byte boundaries. The packet encoder, also adds a header after the preamble, which states how long the packet is, in bytes.</p>



<figure><a href="https://www.anfractuosity.com/wp-content/uploads/2014/02/screen1.png"><img src="https://www.anfractuosity.com/wp-content/uploads/2014/02/screen1-1024x558.png" alt="Screenshot" srcset="https://www.anfractuosity.com/wp-content/uploads/2014/02/screen1-1024x558.png 1024w, https://www.anfractuosity.com/wp-content/uploads/2014/02/screen1-300x163.png 300w, https://www.anfractuosity.com/wp-content/uploads/2014/02/screen1.png 1920w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<p><strong>Fig. 1</strong><br></p>



<p>The GFSK modulator essentially performs Frequency Shift Keying modulation. As you can see in <strong>Figure 2</strong>, the frequency of the modulated signal is lower, when a ‘0’ is being sent, than a ‘1’ being sent. We found that in the context of ultrasonic networking using laptops and microphones, that FSK performed better than PSK (Phase Shift Keying – which uses phase changes, to communicate bits), which is another modulation technique.</p>



<figure><a href="https://www.anfractuosity.com/wp-content/uploads/2014/02/fsk.png"><img src="https://www.anfractuosity.com/wp-content/uploads/2014/02/fsk.png" alt="fsk" srcset="https://www.anfractuosity.com/wp-content/uploads/2014/02/fsk.png 533w, https://www.anfractuosity.com/wp-content/uploads/2014/02/fsk-266x300.png 266w" sizes="(max-width: 533px) 100vw, 533px"></a></figure>



<p><strong>Fig. 2 (courtesy <a href="https://en.wikipedia.org/wiki/File:Fsk.svg">wikipedia</a>)</strong></p>



<p>A very important aspect of the GFSK block is the number of Samples/Symbol. We set this to a value of 9. This means that for each symbol received by the modulator, 9 samples are generated. The higher this number the more resilient the signal is to noise, but consequentially the lower the baud rate (which essentially means the longer it takes to send packets).<br>Baud rate refers to the number of symbols which are transferred per second.</p>



<p>We then use the rational resampler block, to make the signal further resilient. For every sample in, it generates 320 out.</p>



<p>We use a frequency-translating FIR filter, to translate the frequency of the incoming signal. We shift the signal by -carrier_tx, which is -19kHz in this example. This is so that the signal is just outside of the human range of hearing.</p>



<p>As we have been working with complex signals at this point, we need to convert the complex output into a floating point output for the audio card, we achieve this through the use of a ‘Complex to Real’ block.</p>



<p>The bottom part of the graph, depicts the receiver section of the program. It essentially performs the same functions, but in reverse.<br>However there are two additional blocks after the ‘Float to complex’ block. The multiply const block, allows you to multiply the output from the microphone by a fixed number. The block after this is a bandpass filter, to only allow a small range of frequencies to pass through to the demodulator, this helps remove a large amount of noise which is present from the microphone’s output.</p>



<p>In <strong>Figure 3</strong>, you will see that there are two graphs. The top graph, depicts the output sent to the transmitter and the bottom graph depicts the input received from the microphone (after a bandpass filter has mean applied to it). There is also a slider present at the top which allows you to multiply the signal from the microphone by a specific value. This is useful when using 2 laptops which are a greater distance away from each other.</p>



<figure><a href="https://www.anfractuosity.com/wp-content/uploads/2014/02/fft.png"><img src="https://www.anfractuosity.com/wp-content/uploads/2014/02/fft.png" alt="fft" srcset="https://www.anfractuosity.com/wp-content/uploads/2014/02/fft.png 762w, https://www.anfractuosity.com/wp-content/uploads/2014/02/fft-150x150.png 150w, https://www.anfractuosity.com/wp-content/uploads/2014/02/fft-300x298.png 300w" sizes="(max-width: 762px) 100vw, 762px"></a></figure>



<p><strong>Fig. 3</strong><br></p>







<p>Figure 4 depicts the full duplex signalling we use. You can see that we transmit in this example at two different frequencies, 19kHz and 18kHz. This allows both laptops to send their own signal simultaneously.</p>



<figure><a href="https://www.anfractuosity.com/wp-content/uploads/2014/02/clip.png"><img src="https://www.anfractuosity.com/wp-content/uploads/2014/02/clip.png" alt="clip"></a></figure>



<p><strong>Fig. 4</strong><br></p>







<p>In Gnuradio-companion, you will need to go to Build &gt; Execute, in order to execute the graph. You then need to assign an IP address to the tap0 interface it creates for you. You need to do this through a terminal, typing <strong>sudo ifconfig tap0 192.168.1.10</strong> for instance.</p>



<p>You need to perform the same steps on your second laptop, B, but instead this time loading b.grc, and using <strong>sudo ifconfig tap0 192.168.1.20</strong>.</p>



<p>We found it was best to assign ARP entries manually to each laptop. In order to assign an ARP entry, on laptop A, <strong>arp -s 192.168.1.20 &lt;Laptop B’s MAC address for tap0&gt; -i tap0</strong></p>



<p>The setup script, which you have initialised on both laptops copied the patched files to Gnuradio, as well as modifying TCP options, in order to allow TCP/IP to work across a very laggy network.</p>


<pre title="">echo 100 &gt; /proc/sys/net/ipv4/tcp_syn_retries
echo 0 &gt; /proc/sys/net/ipv4/tcp_syncookies
echo 100 &gt; /proc/sys/net/ipv4/tcp_synack_retries
</pre>


<p>The first line is necessary in order to enable a client side TCP connection to stay open longer than the default of 20 seconds, before closing.</p>







<p>In order to test the network is functioning correctly we recommend using netcat. To test out TCP/IP connectivity Use <strong>netcat -vv -l 10000</strong> on Laptop A, and connect to it from Laptop B, using <strong>netcat -vv 192.168.1.10 10000</strong>. Because we are using the verbose options, netcat will inform you when a connection to Laptop A has been established, you can then send text from either laptop to the other one.</p>







<p>As the packet encoder and decoder provided by Gnuradio only work with fixed amounts of data, it was necessary to modify them to support the reading of stream tags. The “PDU to tagged stream” tags packets from the tap interface with their size. The packet encoder/decoder can’t process these tags normally, so we altered the packet encoder, to read these tags, and generate the appropriate sized packet from the tap0 frame. The packet decoder, then unencapsulates the packet, and tags the resulting data, with its size.</p>







<p>To give you an idea of the latencies involved please click on the image below, which shows you a wireshark screenshot, showing the server side of a TCP/IP connection. You’ll see it’s slow!</p>



<figure><a href="https://www.anfractuosity.com/wp-content/uploads/2014/02/pcap.png"><img src="https://www.anfractuosity.com/wp-content/uploads/2014/02/pcap-300x163.png" alt="pcap" srcset="https://www.anfractuosity.com/wp-content/uploads/2014/02/pcap-300x163.png 300w, https://www.anfractuosity.com/wp-content/uploads/2014/02/pcap-1024x558.png 1024w, https://www.anfractuosity.com/wp-content/uploads/2014/02/pcap.png 1920w" sizes="(max-width: 300px) 100vw, 300px"></a></figure>







<p><a href="https://github.com/anfractuosity/ultrasonicnetworking">https://github.com/anfractuosity/ultrasonicnetworking</a></p>



<p>If anyone’s got any suggestions for improvements to the Gnuradio patch I’d be most appreciative (the patch itself was done very quickly).</p>







<p>The following video is from a previous experiment I did to simply test whether we could send data at 23kHz .</p>



<figure><iframe src="//www.youtube.com/embed/H0DKRl8XIcU" allowfullscreen="allowfullscreen" width="560" height="315" frameborder="0"></iframe></figure>







<p>Minimodem looks like a great program, but as far as I’m aware it supports only FSK. I was keen to try different modulation schemes, which Gnuradio provides many of; I originally tried the setup with PSK.</p>



<p>Also this provided me with an introduction into how some of the techniques used for Software Defined Radio work.</p>



<p><strong>With thanks to the folks on #gnuradio for their help</strong></p>
                        <br>


			
                                
                
                                
                 <!-- END #comments -->    
                	                                
                
                
                                      
                 <!-- END #leave_comment -->
                
 
                </article></div>]]>
            </description>
            <link>https://www.anfractuosity.com/projects/ultrasound-networking/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23663097</guid>
            <pubDate>Sat, 27 Jun 2020 17:20:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Take control over your feeds to regain mindfulness]]>
            </title>
            <description>
<![CDATA[
Score 134 | Comments 48 (<a href="https://news.ycombinator.com/item?id=23662874">thread link</a>) | @hosolmaz
<br/>
June 27, 2020 | https://solmaz.io/thoughts/digital-hygiene-feeds/ | <a href="https://web.archive.org/web/*/https://solmaz.io/thoughts/digital-hygiene-feeds/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<p>A digital feed is an online stream of content which gets updated as new content is pushed by the feed’s sources. Generally, content is created by users on the social media platform, to be consumed by their followers.</p>
<p>All popular social media platforms feature some type of feed: Twitter, Instagram, Reddit, Facebook. Operators of these platforms benefit from increased engagement by their users, so they employ techniques designed to achieve that end. Unfortunately, they often do so at the expense of their users’ well-being. Below are 7 rules to help you retain control over your screen time, without having to leave social media for good, ordered from most important to least important.</p>
<h2 id="rule-1-avoid-non-chronological-feeds">Rule #1: Avoid non-chronological feeds</h2>
<p>On most online platforms, the order of content is determined by an algorithm designed to maximize user engagement, i.e. addict you and keep you looking at ads for as long as possible. Examples: Facebook news feed, Twitter “top tweets”, Instagram explore tab, Tiktok.</p>

<p>Your phone is always within your reach. Access feeds only on your laptop, in order not to condition yourself to constantly check it. Don’t install social media or video apps on your phone.</p>
<h2 id="rule-3-follow-with-purpose">Rule #3: Follow with purpose</h2>
<p>Your digital experience changes with each new person/source you follow. Be mindful about the utility of the information you would obtain before following a new source.</p>
<h2 id="rule-4-limit-the-number-of-peoplethings-you-follow">Rule #4: Limit the number of people/things you follow</h2>
<p>The amount of content you will have to go through increases roughly linearly with the number of sources you follow. You probably won’t see everything your 500 followees share—maybe it’s time to unfollow some of them.</p>
<h2 id="rule-5-schedule-and-limit-your-exposure">Rule #5: Schedule and limit your exposure</h2>
<p>Your brain has a limited capacity to process and hold information. Schedule a certain hour of the day to receive it, and don’t surpass it. Example: No more than 30 minutes of social media, restricted to 10–11 am.</p>
<h2 id="rule-6-block-generously-and-ruthlessly">Rule #6: Block generously and ruthlessly</h2>
<p>If you don’t like what you’re seeing, block or unfollow <em>immediately</em>. This is the hardest when someone posts content that is sometimes useful, but otherwise annoying too. Generally, we put up with it for too long until we block someone.</p>
<h2 id="rule-7-mute-words">Rule #7: Mute words</h2>
<p>Avoid toxic memes by muting related words, e.g. Trump, ISIS. This will filter out any post that contains that word. Click <a href="https://twitter.com/settings/muted_keywords">here</a> to do it on Twitter now—it’s easy.</p>
<p>Follow these simple set of rules, and restore your control over social media and your digital experience in no time.</p>
<p><em>This post made it to the Hacker News <a href="https://news.ycombinator.com/item?id=23662874">front page</a>. Also posted as <a href="https://twitter.com/onurhsolmaz/status/1276858849446813696">a Twitter thread</a>.</em></p>
</article></div>]]>
            </description>
            <link>https://solmaz.io/thoughts/digital-hygiene-feeds/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23662874</guid>
            <pubDate>Sat, 27 Jun 2020 16:46:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[FreeDVDBoot – Hacking the Playstation 2 through its DVD player]]>
            </title>
            <description>
<![CDATA[
Score 157 | Comments 15 (<a href="https://news.ycombinator.com/item?id=23662443">thread link</a>) | @farmerbb
<br/>
June 27, 2020 | https://cturt.github.io/freedvdboot.html | <a href="https://web.archive.org/web/*/https://cturt.github.io/freedvdboot.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div class="page">
			<div>
				


<p><span>Initial publication: June 27, 2020</span></p><hr>

<p>
	I've <a href="https://cturt.github.io/ps2-yabasic.html">previously discussed</a> how the PlayStation 2 doesn't have any good entry-point software exploits for launching homebrew. You need to either purchase a memory card with an exploit pre-installed (or a memory card to USB adapter), a HDD expansion bay (not available to slim consoles), open up the console to block the disc tray sensors, or install a modchip. For the best selling console of all time, it deserves better hacks.
</p>

<p>
	My initial attempt to solve this problem was to <a href="https://cturt.github.io/ps2-yabasic.html">exploit the BASIC interpreter</a> that came bundeld with early PAL region PS2s. Although I was successful at producing the first software based entry-point exploit that can be triggered using only hardware that came with the console, the attack was largely criticized due to the requirement of having to enter the payload manually through the controller or keyboard, and limitation of being PAL only. I decided to write-off that exploit as being impractical, and so the hunt continued for a better attack scenario for the PlayStation 2.
</p>

<p>
	The PlayStation 2 has other sources of untrusted input that we could attack; games which support online multiplayer or USB storage could almost definitely be exploited. But unlike say the Nintendo 64, where we don't really have any other choice but to resort to <a href="https://cturt.github.io/shogihax.html">exploiting games over interfaces like modems</a>, the PlayStation 2 has one key difference: its primary input is optical media (CD / DVD discs), a format which anyone can easily burn with readily available consumer hardware. This leaves an interesting question which I've wanted to solve since I was a child:
</p>

<p>
	Is it possible to just burn our own homebrew games and launch them on an unmodified console the same way we would launch official discs (without going through any user interaction like disc swapping or triggering a network exploit in a game)?
</p>



<p>
	Ultimately, I was successfully able to achieve my goal by exploiting the console's DVD player functionality. This blog post will describe the technical details and process of reversing and exploiting the DVD player. Loading <a href="#backup">backups of commercial games is also possible</a>. All of my code is <a href="https://github.com/CTurt/FreeDVDBoot">available on GitHub</a>.
</p>

<p>
	<iframe width="560" height="315" src="https://www.youtube.com/embed/ez0y-hz3VuM" frameborder="0" allowfullscreen=""></iframe>
</p>

<br>

<h2>DVD video player attack surface</h2>
<p>
	Obviously we can't just burn a disc containing an ELF file and expect the PS2 to boot it; we'll need to exploit some kind of software vulnerability related to parsing of controlled data. The console supports playing burned DVD video discs, which exposes significant attack surface we could potentially exploit to achieve our goal.
</p>

<p>
	If we think about what a DVD Video consists of there are quite a few main components, each with the potential for vulnerabilities:
</p>

<ul>
	<li>UDF filesystem</li>
	<li>DVD Video metadata / subtitles</li>
	<li>Audio and video decoding</li>
	<li>Interaction machine</li>
</ul>

<p>
	Whilst the complete DVD Video specification is unfortunately behind a paywall, it is comprised largely of <a href="https://en.wikipedia.org/wiki/DVD-Video#Video_data">open formats like MPEG</a>, just bundled together in a proprietary container format (VOB). For the proprietary aspects there are some freely accessible unofficial references.
</p>

<p>
	The <a href="http://dvd.sourceforge.net/dvdinfo/ifo.html">IFO</a> file format is probably the simplest format used, and is responsible for storing the metadata that links the video files together.
</p>

<p>
	The interaction machine is what allows for interactive menus and games in DVD Videos. It has <a href="https://en.wikibooks.org/wiki/Inside_DVD-Video/Instruction_Set_Details">32 groups of instructions</a>, and is interesting because it could potentially be used to dynamically manipulate internal memory state to prime an exploit, or it could be used to create a universal DVD with a menu which allows you to select your firmware version and trigger the appropriate exploit.
</p>

<br>

<h2>Setup</h2>
<p>
	Clearly it's not practical to do most of our testing on the real hardware since burning hundreds of test discs would be wasteful and time inefficient. We need an emulator with some debugger support, which is where we hit our first roadblock: the most popular emulator for PlayStation 2, PCSX2, <a href="https://github.com/PCSX2/pcsx2/issues/1981">does not support playing DVD Videos</a>, and no one is interested in adding support.
</p>

<p>
	I'd like to thank krHacken for helping me out with that first roadblock. It turns out that PCSX2 does support the DVD player; it just can't load it automatically since it's located in encrypted storage and PCSX2 does not support the decryption. There are public tools which can <a href="https://github.com/xfwcfw/kelftool">decrypt</a> and <a href="https://github.com/jimmikaelkael/eromdir">extract</a> the DVD player from EROM storage. It can then be repacked into an ELF for easy loading into PCSX2.
</p>

<p>
	Due to the large number of different PlayStation 2 models released, each with slightly different DVD player firmwares (&gt; 50...), I will focus on a single DVD player for the duration of this article: 3.10E (configured with English language in PS2 settings), as it happens to be the firmware for the console I own. Update: apparently the 3.10E exploit described here works on 3.10U console with no changes.
</p>

<p>
	I will continue to use Ghidra for decompilation as I've been using throughout my <a href="https://cturt.github.io/ps2-yabasic.html">previous</a> articles. The DVD player does not contain any symbols so all names in code snippets were assigned by me through reverse engineering.
</p>

<br>

<h2>Disc controlled data</h2>
<p>
	The first file a DVD player will attempt to read is <code>VIDEO_TS.IFO</code>. Searching memory for contents of the file and then setting memory write breakpoints there to track back where it was written we quickly locate the API that reads disc contents used by the IFO parsing code, <code>getDiscByte</code> at <code>0x25c920</code>. It's a stream reader which caches a number of sectors into a RAM buffer, and then automatically seeks more data once needed:
</p>

<pre><code>byte getDiscByte(void) {
	byte ret;
	
	if (currentDiscBytePointer &lt; endDiscBytePointer) {
		ret = *currentDiscBytePointer;
	}
	else {
		currentDiscBytePointer = &amp;buffer;
		setOffset = setOffset + numberOfSectorsRead;
		getDiscByteInternal();
		ret = *currentDiscBytePointer;
	}
	currentDiscBytePointer = currentDiscBytePointer + 1;
	return ret;
}
</code></pre>



<p>
	From searching calls to this, we can also quickly find wrappers that fetch data of larger sizes: <code>getDiscU16</code> (<code>0x25c980</code>), <code>getDiscU32</code> (<code>0x25c9b8</code>), and <code>getDiscData</code> (<code>0x25c9f0</code>), which is the most interesting as it reads an arbitrary length of data:
</p>

<pre><code>void getDiscData(uint size, byte *destination) {
	byte b;
	uint i;
	
	i = 0;
	if (size != 0) {
		do {
			i = i + 1;
			b = getDiscByte();
			*destination = b;
			destination = destination + 1;
		} while (i &lt; size);
	}
	return;
}
</code></pre>

<h2>Large reads</h2>
<p>
	The first thing I did was search for calls to <code>getDiscData</code> in the hope of finding one with controllable size, and no bounds checking.
</p>

<p>
	Sure enough, we very quickly identify about 4 blatant buffer overflow vulnerabilities of this nature. Relating back to the <a href="http://dvd.sourceforge.net/dvdinfo/ifo.html">IFO</a> file format, we can see that there are numerous 16-bit array lengths which are needed to parse the variably sized data structures in the file. The DVD player mistakenly only ever expects the maximum lengths allowed by the DVD specification, and so it is missing checks to reject discs with larger lengths. Since all of the copies are done on statically allocated memory buffers, specifying larger than allowed lengths will cause buffer overflows. For example, below is decompilation for the one at <code>0x25b3bc</code>:
</p>

<pre><code>		large1 = getDiscU16();
		large2 = getDiscU16();
		large3 = getDiscU16();
		ignored = getDiscU16();
		getDiscData(((uint)large1 + (uint)large2 + (uint)large3) * 8, &amp;DAT_0140bdd4);</code></pre>



<p>
	This one is the most interesting because it allows the largest possible copy size (<code>0xffff * 3 * 8 = 0x17FFE8</code> bytes) of all the <code>getDiscData</code> buffer overflows. It copies into the statically allocated buffer at <code>0x0140bdd4</code>, and so by specifying the maximum possible copy size we gain control over the address space from <code>0x140bdd4</code> to <code>0x158BDBC</code> (<code>0x140bdd4 + 0x17FFE8</code>).
</p>

<br>

<h2>Corruption from the large reads</h2>
<p>
	As you can see, we can control quite a large region of memory using the above vulnerability. However, scanning through that memory is initially very disappointing; there are very few pointers, and none of them look particularly interesting to corrupt!
</p>

<p>
	Although there are no interesting pointers in this region, there are some indexes, which if corrupted could lead to further out of bounds memory corruption.
</p>

<p>
	Note that large reads like this won't always copy contiguous data from the IFO file, as sectors will start repeating once we exceed the file size, but generally assume that all data written by a <code>getDiscData</code> call can be controlled as it originates from <i>somewhere</i> on the disc. Also, after writing a certain amount, we may overflow into internal state used by <code>getDiscByte</code> functions, but we will get to this later.
</p>

<br>

<h3>OOB call</h3>
<p>
	At <code>0x25e388</code> we have this call to an entry in a function pointer array, where we can control the 16-bit <code>fpIndex</code> at <code>0x141284a</code> from the overflow:
</p>

<pre><code>(*(code *)(&amp;PTR_LAB_005b9d40)[(uint)fpIndex])(puVar6 + ((uint)DAT_01412841 - 1) * 8);</code></pre>



<p>
	This allows us to jump to the address stored anywhere from <code>0x5b9d40</code> up to <code>0x5b9d40 + 0xffff * 4 = 0x5F9D3C</code>.
</p>

<br>

<h4>Exploiting OOB call</h4>
<p>
	This primitive is not quite ideal, as none of our overflow bugs allow us to control the memory where the jump targets are read from. Worse still, most of this memory region is mapped from a read-only section of the DVD Player, so it's unlikely that we can influence the contents of this memory region without another bug.
</p>

<p>
	After the function pointers, we do some see some addresses for <code>switch</code> <code>case</code> labels, which is slightly interesting because that allows us to jump into the middle of a function and execute its epilogue without having executed its prologue, allowing us to misalign the stack pointer and return to an unexpected value on the stack. I went through all of these and unfortunately I was only ever able to use that to jump to <code>0</code>.
</p>

<p>
	Finally after the code pointers, we see read only string data. Interestingly, this data can be changed by switching languages in the PS2 menu, which gives greater hope for finding at least 1 usable jump target in every firmware version, however it unfortunately comes at the cost of forcing the user to reconfigure their language.
</p>

<p>
	I decided to …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cturt.github.io/freedvdboot.html">https://cturt.github.io/freedvdboot.html</a></em></p>]]>
            </description>
            <link>https://cturt.github.io/freedvdboot.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23662443</guid>
            <pubDate>Sat, 27 Jun 2020 15:32:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cache Oblivious Algorithms]]>
            </title>
            <description>
<![CDATA[
Score 213 | Comments 18 (<a href="https://news.ycombinator.com/item?id=23662434">thread link</a>) | @tardygrade
<br/>
June 27, 2020 | https://jiahai-feng.github.io/posts/cache-oblivious-algorithms/ | <a href="https://web.archive.org/web/*/https://jiahai-feng.github.io/posts/cache-oblivious-algorithms/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

    

    
      

    

    
<p><a href="https://jiahai-feng.github.io/posts/cache-oblivious-algorithms/" title="Cache Oblivious Algorithms">
        <img src="">
    </a>
</p>



    
<p>Cache-oblivious algorithms seemed incredible to me when I first heard about it in 6.854 (Advanced Algorithms). It’s relatively straightforward to imagine algorithms that utilizes information about page size $B$ and cache size $M$ to create efficient data structures. However, cache-oblivious algorithms are algorithms that achieve similar efficiencies <em>without knowing $B$ or $M$</em>. That means the same cache-oblivious algorithm can be ran on computers with different cache or page sizes and still achieve the same asymptotic efficiency as one that is tailored to that specific cache. The key to many of these algorithms is a recursive, fractal-like idea. I’ll describe a cache-oblivious algorithm for searching in a list of integers.</p>

<p>Here’s the set up. (TLDR at bottom) A program executes on the processor, but the input data resides on the disk. We can think of a disk as a really long linear array of data, but accessing it is really expensive. So, we instead invent this notion of a cache - a layer of memory of $M$ bits that is much smaller, but a lot faster to read/write to. For performance reasons, we will divide the disk and cache into blocks of $B$ bits, called pages, and we will transfer data between cache and disk a page at a time.</p>
<p>This cache sits between the processor and the disk, and the processor will never directly read or write to the disk. When the processor wants to read a piece of data that is not on the cache (this is called a cache miss), it will trigger some mechanism that copies the relevant page from the disk to the cache first, <em>evicting another page if the cache is full</em>, and then read from the cache.</p>
<p>How might this help? Well, trivially, if the entire set of data that the program needs fits in the cache, conceivably the processor could have fetched it all in the cache, paid the one-off cost, and then for the rest of the program the processor will never have to pay the expensive cost of reading from disk. Of course most programs require more data than that, and so we want to design algorithms that minimize cache misses.</p>
<h2 id="cache-management">Cache management</h2>
<p>However, the way computers are set up restricts the tools we have to achieve this. Programs executing on the processor have no explicit control over the cache. Instead, conceptually, programs continue to send read and write requests to the disk as though there is no cache. The processor intercepts these requests, and performs the necessary cache operations to serve the information. In other words, the cache is transparent to programs.  Thus, the task of reducing cache misses decomposes into two orthogonal components: writing efficient algorithms by cleverly ordering or specifying memory accesses, and efficient cache management.</p>
<p>For example, an efficient algorithm might try to shuffle memory accesses around so that memory accesses to a particular memory address are clumped together, increasing the likelihood that there will be a cache hit. In fact, because of the paging system, it would doubly help if memory accesses to the same <em>spatial region</em> are clumped together, because there’s a chance they’ll be on the same page.</p>
<p>On the other hand, efficient cache management entails trying to predict which piece of data to evict from the cache when there is a cache miss and we want to load more data into an already full cache. Since we’re focusing on the algorithm this article, we assume that the cache manager has magic oracle powers that lets it discard <em>optimally</em>, so from the algorithm design standpoint, if there exists a sequence of cache loads/writes that achieves our desired performance, we assume that the cache manager will do it. It turns out that this is not unreasonable, because simple techniques such as the Least Recently Used algorithm work <em>really</em> well. (An exposition on this deserves its own article.)</p>
<p>To summarize, the components of the external memory model are:</p>
<ul>
<li>Disk, effectively unbounded in size, stores data in pages of size $B$</li>
<li>Cache, stores $M/B$ pages, each page has size $B$</li>
<li>Processor executes algorithm, also manages cache.</li>
<li>Algorithm runs on the processor. When data is needed, the processor transparently loads the required page into the cache if there’s a cache miss, or serve the cached data if there isn’t</li>
</ul>
<p>There are efficient algorithms that require explicit knowledge of $B$ and $M$, and there cache-oblivous algorithms that are just as efficient, but some how do not. That is to say, the algorithm performs the same actions and requests the same sequence of memory accesses, that works efficiently no matter what size $B$ and $M$ really are. We’ll take a close look at the latter here.</p>

<p>Let’s say we want to scan through a list of $N$ integers, to do some task, say finding the maximum. If the list occupy a contiguous block of memory on the disk, this can be done efficiently by loading pages one at a time, and scanning through the page before loading the next page. This thus takes $O(N/B)$ disk accesses, and is quite clearly optimal.</p>
<p>Suppose the algorithm does not know $B$. It can achieve the same efficiency by simply reading the elements of the list in order. The CPU will then fetch the first page to the cache, containing elements $0$ to $B-1$ and pass it to the program, and then when the program requires element $B$, it’ll read in the next page, which contains elements $B$ to $2B-1$, possibly overwriting the earlier page. This will just continue until all $N/B$ pages are read. This is cache-oblivious, because the algorithm of sequentially reading the elements is the same regardless of what $B$ is.</p>
<p>Note that in this example, it is essential that the list is stored in a contiguous block of memory. Had the elements been scattered around like in a linked-list, each access could potentially trigger a cache miss, since there’s no guarantee that neighboring elements will be on the same page. This may seem obvious, but this is the main mechanism by which we can write efficient algorithms - coming up with efficient layouts of data.</p>

<p>Now, let’s consider the problem of searching for an integer in a list. We’ll examine three ways of doing this.</p>
<h2 id="inefficient-cache-oblivious-algorithm-binary-search">Inefficient cache-oblivious algorithm: Binary search</h2>
<p>Let’s assume the data is sorted in a list, and packed contiguously on the disk. A possible algorithm is then to perform binary search, which typically takes $O(\log N)$ reads. The binary search can be viewed a successively narrowing an interval in which the query value may reside in. However, once the interval that the binary search is narrowing is $O(B)$, the entire interval may reside in a page, and no further page accesses are required. Thus, we require only $O(\log N - \log B)$ page accesses. Notice that this is a cache-oblivious algorithm because the algorithm doesn’t know what $B$ is - to the algorithm, it’s just running a standard binary search.</p>
<h2 id="efficient-but-not-cache-oblivious-b-trees">Efficient, but not cache-oblivious: B-trees</h2>
<p>Suppose we know $B$ ahead of time. We can achieve $O(\log_B N)$ page accesses. We arrange the list in the format of a B-tree, a generalized BST. Similar to a BST, each subtree of a B-tree corresponds to a contiguous subset of the elements of the list when sorted by value. However, each node $V$ of the tree contains not one, but $B$ elements, which splits the interval corresponding to the subtree rooted at node $V$ into not 2, but $B+1$ intervals. Then, we can traverse down the BST, and each time we go down one level we reduce the interval by a factor of $B$. This thus requires only $O(\log_B N) = O(\log N / \log B)$ page accesses. In reality of course, we have to store pointers and possibly other metadata in each node, so we can’t have exactly $B$ elements in each node, but we can definitely split by $\Theta(B)$ each level.</p>
<h2 id="efficient-cache-oblivious-algorithm-van-emde-boas-layout">Efficient cache-oblivious algorithm: van Emde Boas layout</h2>
<p>Now we come to the exciting part. We claim that we can achieve $O(\log_B N)$ page accesses, but without having to know $B$ ahead of time. The data structure we’re using is a good old balanced Binary Search Tree. However, the order in which we store the nodes in memory matters. If we pack the the BST in a regular fashion, say in breadth-first order, we could potentially have a situation where almost every vertex in a BST search path, except for the first few, lies in a different page, and thus we’ll have to use $O(\log N - \log B)$ page accesses. The van Embde Boas layout is basically a clever way of ordering the vertices of a binary search tree in a recursive, fractal-like manner such that each page access will fetch the next few vertices that will be queried, so that the next few accesses will be contained within that page.</p>
<h3 id="concise-definition">Concise definition</h3>
<figure>
    <img src="https://jiahai-feng.github.io/images/van-embde-boas-layout-labelled.PNG" alt="One application of the recursive van Embde Boas layout"> <figcaption>
            <p>One application of the recursive van Embde Boas layout</p>
        </figcaption>
</figure>

<p>For convenience, suppose the binary tree is complete and has height $H=2^K$. The layout is a permutation of the vertices of the binary tree. Denote $T(x, k)$ as the subtree of height $2^k$, rooted at vertex $x$. If the subtree at $x$ is deeper than $2^k$, then $T(x,k)$ will be the subtree truncated to the required depth. Denote $L(x, k)$ as the layout for that subtree. Then, for some root vertex $x$, of a (sub-)tree with height $h=2^k$, $L(x, k)$ is defined recursively as:</p>
<p>$$L(x, k) = L(x, k-1) \circ L(l_1, k-1) \circ L(l_2, k-1) \circ \dots \circ L(l_{n}, k-1)$$</p>
<p>Where, $l_1, \dots, l_{n}$ are the $n=2^{h/2}$ children of the leaves of $T(x, k-1)$, and $\circ$ is just concatenation. One application of this recursion is shown above.</p>
<h3 id="visual-sketch">Visual sketch</h3>
<p>If you didn’t catch that, don’t worry about it. Here’s a walkthrough. Suppose we’re given a complete binary tree of height $h=2^k$, rooted at $x$. We want to compute $L(x, k)$, which is a permutation of the vertices in this binary tree. Here’s how it’s done:</p>
<figure>
    <img src="https://jiahai-feng.github.io/images/veb-step0.PNG" alt="Initial tree"> <figcaption>
            <p>Initial tree</p>
        </figcaption>
</figure>

<ol>
<li>Cut all the edges between the $2^{k-1}$-th and $2^{k-1}+1$-th layer. This gives us:
<ul>
<li>$2^{h/2}$ smaller BSTs with height $2^{k-1}$. These are the children subtrees now disconnected from the main subtree, …</li></ul></li></ol></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jiahai-feng.github.io/posts/cache-oblivious-algorithms/">https://jiahai-feng.github.io/posts/cache-oblivious-algorithms/</a></em></p>]]>
            </description>
            <link>https://jiahai-feng.github.io/posts/cache-oblivious-algorithms/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23662434</guid>
            <pubDate>Sat, 27 Jun 2020 15:31:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New in iOS 14: Vision Contour Detection]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23662019">thread link</a>) | @austin_kodra
<br/>
June 27, 2020 | https://heartbeat.fritz.ai/new-in-ios-14-vision-contour-detection-68fd5849816e | <a href="https://web.archive.org/web/*/https://heartbeat.fritz.ai/new-in-ios-14-vision-contour-detection-68fd5849816e">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><h2 id="992e">WWDC20</h2><h2 id="667d">Apple boosts its computer vision ambitions with a bunch of new Vision requests</h2><div><div><div><div><a href="https://heartbeat.fritz.ai/@anupamchugh?source=post_page-----68fd5849816e----------------------" rel="noopener"><div><p><img alt="Anupam Chugh" src="https://miro.medium.com/fit/c/96/96/1*SdJ5BAJeHpGYxEoACvPnRQ@2x.jpeg" width="48" height="48"></p></div></a></div></div></div></div></div></div><div><div><p id="17ef">Apple’s WWDC 2020 (digital-only) event kickstarted with a bang. There were a lot of new surprises (read: <a target="_blank" rel="noopener" href="https://heartbeat.fritz.ai/how-apple-silicon-changes-mac-forever-d2682a9722df">Apple’s own silicon chips for Macs</a>) from the world of SwiftUI, <a target="_blank" rel="noopener" href="https://heartbeat.fritz.ai/arkit4-putting-the-reality-back-in-augmented-reality-cea4ab775b8">ARKit</a>, PencilKit, Create ML, and <a target="_blank" rel="noopener" href="https://heartbeat.fritz.ai/evolving-your-apps-intelligence-with-core-ml-model-deployment-165579ba0546">Core ML</a>. But the one that stood out for me was computer vision.</p><p id="bce9">Apple’s Vision framework got bolstered with a bunch of exciting new APIs that perform some complex and critical computer vision algorithms in a fairly straightforward way.</p><p id="718a">Starting with iOS 14, the Vision framework now supports Hand and Body Pose Estimation, Optical Flow, Trajectory Detection, and Contour Detection.</p><p id="078f">While we’ll provide an in-depth look at each of these some other time, right now, let’s dive deeper into one particularly interesting addition—the contour detection Vision request.</p><ul><li id="bcd1">Understanding Vision’s contour detection request.</li><li id="00c8">Running it in an iOS 14 SwiftUI application to detect contours along coins.</li><li id="63ab">Simplifying the contours by leveraging Core Image filters for pre-processing the images before passing them on to the Vision request. We’ll look to mask the images in order to reduce texture noise.</li></ul></div></div></section><hr><section><div><div><p id="d6a5">Contour detection detects outlines of the edges in an image. Essentially, it joins all the continuous points that have the same color or intensity.</p><p id="fb67">This computer vision task is useful for shape analysis, edge detection, and is helpful in scenarios where you need to find similar types of objects in an image.</p><p id="c5f4">Coin detection and segmentation is a fairly common use case in OpenCV, and now by using Vision’s new <code>VNDetectContoursRequest</code>, we can perform the same in our iOS applications easily (without the need for third-party libraries).</p><p id="3973">To process images or frames, the Vision framework requires a <code>VNRequest</code>, which is passed into an image request handler or a sequence request handler. What we get in return is a <code>VNObservation</code> class.</p><p id="4ad5">You can use the respective <code>VNObservation</code> subclass based on the type of request you’re running. In our case, we’ll use <code>VNContoursObservation</code>, which provides all the detected contours from the image.</p><p id="8298">We can inspect the following properties from the <code>VNContoursObservation</code>:</p><ul><li id="a70a"><code><a href="https://developer.apple.com/documentation/vision/vncontoursobservation/3548363-normalizedpath" target="_blank" rel="noopener">normalizedPath</a></code> — It returns the path of detected contours in normalized coordinates. We’d have to convert it into the UIKit coordinates, as we’ll see shortly.</li><li id="5ea7"><code>contourCount</code> — The number of detected contours returned by the Vision request.</li><li id="d7ad"><code>topLevelContours</code> — An array of <code>VNContours</code> that aren’t enclosed inside any contour.</li><li id="803a"><code>contour(at:)</code> — Using this function, we can access a child contour by passing its index or <code>IndexPath</code>.</li><li id="c47a"><code>confidence</code> — The level of confidence in the overall <code>VNContoursObservation</code>.</li></ul><blockquote><p id="b960">Note: Using <code>topLevelContours</code> and accessing child contours is handy when you need to modify/remove them from the final observation.</p></blockquote><p id="fcbd">Now that we’ve got an idea of Vision contour detection request, let’s explore how it might work it in an iOS 14 application.</p></div></div></section><hr><section></section><hr><section><div><div><p id="367c">To start off, you’ll need <a href="https://developer.apple.com/documentation/xcode-release-notes/xcode-12-beta-release-notes" target="_blank" rel="noopener">Xcode 12 beta</a> as the bare minimum. That’s about it, as you can directly run Vision image requests in your SwiftUI Previews.</p><p id="0bc8">Create a new SwiftUI application in the Xcode wizard and notice the new <code>SwiftUI App</code> lifecycle:</p><figure><div><div><div><div><p><img src="https://miro.medium.com/max/60/1*b-1INld9G6RyGdvKPBmlkg.png?q=20" width="719" height="519" role="presentation"></p><p><img src="https://miro.medium.com/max/1438/1*b-1INld9G6RyGdvKPBmlkg.png" width="719" height="519" srcset="https://miro.medium.com/max/552/1*b-1INld9G6RyGdvKPBmlkg.png 276w, https://miro.medium.com/max/1104/1*b-1INld9G6RyGdvKPBmlkg.png 552w, https://miro.medium.com/max/1280/1*b-1INld9G6RyGdvKPBmlkg.png 640w, https://miro.medium.com/max/1400/1*b-1INld9G6RyGdvKPBmlkg.png 700w" sizes="700px" role="presentation"></p></div></div></div></div></figure><p id="f24c">You’ll be greeted with the following code once you complete the project setup:</p><pre><span id="d4e5">@main<br>struct iOS14VisionContourDetection: App {<br>    var body: some Scene {<br>        WindowGroup {<br>            ContentView()<br>        }<br>    }<br>}</span></pre><blockquote><p id="4fb4">Note: Starting in iOS 14, <code>SceneDelegate</code> has been deprecated in favor of the SwiftUI <code>App</code> protocol, specifically for SwiftUI-based applications. The <code>@main</code> annotation on the top of the <code>struct</code> indicates it’s the starting point of the application.</p></blockquote></div></div></section><hr><section><div><div><p id="fc40">In order to perform our Vision request, let’s quickly set up a SwiftUI view, as shown below:</p><figure><div></div></figure><p id="cb81">In the above code, we’ve used the <code>if let</code> syntax that’s released with SwiftUI for iOS 14. Ignore the <code>preprocessImage</code> state; for now, let’s directly jump onto the <code>detectVisionContours</code> function that’ll update the <code>outputImage</code> state upon the completion of Vision request:</p><figure><div></div></figure><p id="fdf1">In the above code, we’ve set the <code>contrastAdjustment</code> (to enhance the image) and <code>detectDarkOnLight</code> (for better contour detection as our image has light background) properties on the <code>VNDetectContoursRequest</code>.</p><p id="bef8">Upon running the <code>VNImageRequestHandler</code> with the input image (present in the Assets folder ), we get back the <code>VNContoursObservation</code>.</p><p id="b3b6">Eventually, we’ll draw the <code>normalizedPoints</code> as an overlay on our input image.</p><p id="96a9">The code for the <code>drawContours</code> function is given below:</p><figure><div></div></figure><p id="a926">The <code>UIImage</code> returned by the above function is set to the <code>contouredImage</code> SwiftUI state, and subsequently our view gets updated:</p><figure><div><div><div><div><p><img src="https://miro.medium.com/max/60/1*UEijelLTwx_uS_bC6J_Qgw.png?q=20" width="1011" height="625" role="presentation"></p><p><img src="https://miro.medium.com/max/2022/1*UEijelLTwx_uS_bC6J_Qgw.png" width="1011" height="625" srcset="https://miro.medium.com/max/552/1*UEijelLTwx_uS_bC6J_Qgw.png 276w, https://miro.medium.com/max/1104/1*UEijelLTwx_uS_bC6J_Qgw.png 552w, https://miro.medium.com/max/1280/1*UEijelLTwx_uS_bC6J_Qgw.png 640w, https://miro.medium.com/max/1400/1*UEijelLTwx_uS_bC6J_Qgw.png 700w" sizes="700px" role="presentation"></p></div></div></div></div></figure><p id="a259">The results are pretty decent considering we ran this on a simulator, but they would certainly be better if we ran this on a device with iOS 14, with access to the Neural Engine.</p><p id="feb8">But still, there are far too many contours (mostly due to coin textures) for our liking. We can simplify (or rather reduce) them by pre-processing the image.</p></div></div></section><hr><section></section><hr><section><div><div><p id="066d"><a href="https://developer.apple.com/documentation/coreimage" target="_blank" rel="noopener">Core Image</a> is Apple’s image processing and analysis framework. Though it works fine for simple face and barcode detection tasks, it isn’t scalable for complex computer vision use cases.</p><p id="68da">The framework actually boasts of over 200 image filters and is handy in photography apps as well as for data augmentation in your machine learning model training.</p><p id="3f76">But more importantly, Core Image is a handy tool for pre-processing images that are then fed to the Vision framework for analysis.</p><p id="467b">Now, if you’ve watched the <a href="https://developer.apple.com/videos/play/wwdc2020/10673" target="_blank" rel="noopener">WWDC 2020 Computer Vision APIs</a> video, you’ve seen that Apple has leveraged Core Image’s monochrome filter for pre-processing, while demonstrating their punchcard contour detection example.</p><p id="49be">In our case, for coin masking, the monochrome effect would not give as good results. Specifically for coins that have a similar color intensity that’s different from the background, using the black and white color filter for masking coins is a better bet.</p><figure><div><div><div><div><p><img src="https://miro.medium.com/max/60/1*oycNP8qYvVZbONbJGnsLWw.png?q=20" width="949" height="768" role="presentation"></p><p><img src="https://miro.medium.com/max/1898/1*oycNP8qYvVZbONbJGnsLWw.png" width="949" height="768" srcset="https://miro.medium.com/max/552/1*oycNP8qYvVZbONbJGnsLWw.png 276w, https://miro.medium.com/max/1104/1*oycNP8qYvVZbONbJGnsLWw.png 552w, https://miro.medium.com/max/1280/1*oycNP8qYvVZbONbJGnsLWw.png 640w, https://miro.medium.com/max/1400/1*oycNP8qYvVZbONbJGnsLWw.png 700w" sizes="700px" role="presentation"></p></div></div></div></div></figure><p id="f4ed">For each of the above pre-processing types, we’ve also set a Gaussian filter to smoothen the image. Take note of how the monochrome pre-processing filter actually gives us significantly more contours.</p><p id="e3dc">Hence, it’s important to pay heed to the kinds of images you’re dealing with when doing pre-processing.</p><p id="c748">The <code>outputImage</code> obtained after the pre-processing is fed to the Vision image request. The block of code for creating and applying Core Image filters is available in this <a href="https://github.com/anupamchugh/iOS14VisionContourDetection" target="_blank" rel="noopener">GitHub Repository</a>, along with the full source code.</p></div></div></section><hr><section><div><div><p id="e6c5">By using the <code>VNGeometryUtils</code> class, we can observe properties like diameter, bounding circle, area perimeter, and aspect ratio of the contour. Simply pass the contour, as shown below:</p><pre><span id="994f">VNGeometryUtils.boundingCircle(for: VNContour)</span></pre><p id="2e4a">This can open up new computer vision possibilities in determining the different kinds of shapes available in an image.</p><p id="02b3">Additionally, by invoking the <code>polygonApproximation(withEpsilon:)</code> method on a <code>VNContour</code>, we can further simplify our contours by filtering out little noisy parts around an edge.</p></div></div></section><hr><section><div><div><p id="e09c">Computer vision plays a huge role in Apple’s mixed reality future. The introduction of hand and body Pose APIs, which were a part of the ARKit framework, will open up new kinds of opportunities for building intelligent computer vision applications.</p><p id="1e3a">There’s a lot of exciting stuff that came out of WWDC 2020. I’m excited about the new kinds of possibilities for machine learning on mobile. Stay tuned for more updates, and thanks for reading.</p></div></div></section><hr><section><div><div><p id="abb3"><em>Editor’s Note:</em><a href="http://heartbeat.fritz.ai/" target="_blank" rel="noopener"><em> </em><strong><em>Heartbeat</em></strong></a><strong><em> </em></strong><em>is a contributor-driven online publication and community dedicated to exploring the emerging intersection of mobile app development and machine learning. We’re committed to supporting and inspiring developers and engineers from all walks of life.</em></p><p id="af09"><em>Editorially independent, Heartbeat is sponsored and published by</em><a href="http://fritz.ai/" target="_blank" rel="noopener"><em> </em><strong><em>Fritz AI</em></strong></a><em>, the machine learning platform that helps developers teach devices to see, hear, sense, and think. We pay our contributors, and we don’t sell ads.</em></p><p id="6414"><em>If you’d like to contribute, head on over to our</em><a target="_blank" rel="noopener" href="https://heartbeat.fritz.ai/call-for-contributors-october-2018-update-fee7f5b80f3e"><em> </em><strong><em>call for contributors</em></strong></a><em>. You can also sign up to receive our weekly newsletters (</em><a href="https://www.deeplearningweekly.com/" target="_blank" rel="noopener"><strong><em>Deep Learning Weekly</em></strong></a><em> and the </em><a href="https://www.fritz.ai/newsletter/?utm_campaign=fritzai-newsletter&amp;utm_source=heartbeat-statement" target="_blank" rel="noopener"><strong><em>Fritz AI Newsletter</em></strong></a><em>), join us on</em><a href="https://join.slack.com/t/fritz-ai-community/shared_invite/enQtNTY5NDM2MTQwMTgwLWU4ZDEwNTAxYWE2YjIxZDllMTcxMWE4MGFhNDk5Y2QwNTcxYzEyNWZmZWEwMzE4NTFkOWY2NTM0OGQwYjM5Y2U" target="_blank" rel="noopener"><em> </em></a><a href="http://fritz.ai/slack" target="_blank" rel="noopener"><strong><em>Slack</em></strong></a><em>, and follow Fritz AI on</em><a href="https://twitter.com/fritzlabs" target="_blank" rel="noopener"><em> </em><strong><em>Twitter</em></strong></a><em> for all the latest in mobile machine learning.</em></p></div></div></section></div></div>]]>
            </description>
            <link>https://heartbeat.fritz.ai/new-in-ios-14-vision-contour-detection-68fd5849816e</link>
            <guid isPermaLink="false">hacker-news-small-sites-23662019</guid>
            <pubDate>Sat, 27 Jun 2020 14:26:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Common Web Developer Interview Questions And Answers]]>
            </title>
            <description>
<![CDATA[
Score 31 | Comments 17 (<a href="https://news.ycombinator.com/item?id=23661922">thread link</a>) | @spiderjako22
<br/>
June 27, 2020 | https://blog.codegiant.io/25-web-developer-interview-questions-and-answers-3030b21ae016 | <a href="https://web.archive.org/web/*/https://blog.codegiant.io/25-web-developer-interview-questions-and-answers-3030b21ae016">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><div><div><div><p><a href="https://blog.codegiant.io/@codegiant?source=post_page-----3030b21ae016----------------------" rel="noopener"><img alt="Team Codegiant" src="https://miro.medium.com/fit/c/96/96/2*iU0oAI5CSMp5LPuEKOqNuQ.png" width="48" height="48"></a></p></div></div></div></div><figure><div><div><div><div><p><img src="https://miro.medium.com/max/60/1*WnoJGHyKLF5tfS2cG5tavQ.png?q=20" width="1600" height="1200" role="presentation"></p><p><img src="https://miro.medium.com/max/3200/1*WnoJGHyKLF5tfS2cG5tavQ.png" width="1600" height="1200" srcset="https://miro.medium.com/max/552/1*WnoJGHyKLF5tfS2cG5tavQ.png 276w, https://miro.medium.com/max/1104/1*WnoJGHyKLF5tfS2cG5tavQ.png 552w, https://miro.medium.com/max/1280/1*WnoJGHyKLF5tfS2cG5tavQ.png 640w, https://miro.medium.com/max/1400/1*WnoJGHyKLF5tfS2cG5tavQ.png 700w" sizes="700px" role="presentation"></p></div></div></div></div></figure><p id="4cc5">You’ve set the alarm for 2:45pm.</p><p id="d056">The web developer interview is scheduled for 3:00pm.</p><p id="8433">You are patiently and nervously waiting, tension digging deeper in your chest, hands trembling without any tangible reason, for your mobile phone to ring. You’re wondering what web development interview questions the interviewer is going to fire off at you. Your mind is playing on your nerves. Tension rising notch by notch. “Am I really ready for that coding interview?” — you start beating yourself up.</p><p id="dd5e">You check your phone — it’s 3:05 pm. No missed calls. Nothing.</p><p id="f93c">You anxiously recheck your phone — 3:15 pm… still nothing.</p><p id="4c5c">You are already 30 minutes under pressure, sweating and silently moaning — your heart races. The latent impostor syndrome arises from the depths. You start freaking out… wondering whether or not you’ve given the wrong phone number… or if they might have forgotten about you.</p><p id="5e62">Your mind is leading a furious battle to overcome your anxious trains of thought. You, filled with a desperate hope, grab your phone with your sweaty pawl and look at it for one last time… and then… it rings.</p><p id="845c">You pick up and say, “Hello,” trying to hide the trembling notes in your voice, the anxious quiver of your lips and fingers, while battling the excruciating jittery inside your mind. You introduce each other and then… kinds of interview questions for web developers thrown at you, catching you off guard, that you can barely give an adequate answer to.</p><p id="d227">You realize that you are completely f*cked up. The overwhelming anxiety is growing deeper and deeper in you. You feel like you have a 200-kg bench press on your chest that you can’t lift. Vertigo comes along, and you suddenly forget. You forget your location, the person you are talking to… everything. Hands so sweaty that you just can’t hold your phone without it slipping through your fingers.</p><p id="a240">You know that the chances of making a good impression are so damn low that you’d have more luck if you were to bet on racing cockroaches.</p><p id="262a">To avoid that, you need strong preparation for the next coding interview. You need to have a grasp of the interview questions for web developers you are being asked. That will boost your confidence and diminish the anxiety before the phone or onsite interview.</p><p id="ab34">In this article, I’ll talk about the principles behind the developer interview process — the most common web developer questions you can expect from interviewers and how to answer them in a fascinating way that will put a WOW expression on their faces (even if they want to rip your head off, rearrange your face, or just clean their shoes ;-) ).</p><p id="a90c">To start off, you need to realize that the web dev interviewing process is more like a negotiation. You’ve been probably taught as a kid that you need to be flawless during interviews and answer every question accurately to make a good impression and get hired.</p><p id="b625">This couldn’t be further from the truth (coming from someone who got hired by sending out a cold message directly to their employer — no official nor traditional interview process).</p><p id="e763">Yes, of course, you need to make a good impression. But if you think that making a good impression comes down to awkwardly staring at your interviewer, frozen, while answering every developer interview question like a robot… you’re highly mistaken my friend.</p><p id="804e">You need to be able to communicate with your future employer freely while at the same time exuding confidence, knowledge, curiosity, and most importantly, enthusiasm.</p><p id="e9be">Here are the main things employers look for when hiring people:</p><ol><li id="c9d8"><a href="https://www.wikihow.com/Have-a-Great-Personality" target="_blank" rel="noopener">Personality</a>.</li><li id="bc1a"><a target="_blank" rel="noopener" href="https://blog.codegiant.io/whats-the-difference-between-a-programmer-coder-developer-and-engineer-bd315404de7">Basic qualifications</a>.</li><li id="5b8b"><a href="http://breathehr.com/blog/what-is-cultural-fit-and-why-is-it-important" target="_blank" rel="noopener">Culture fit</a>.</li><li id="e3a7"><a target="_blank" rel="noopener" href="https://blog.codegiant.io/how-to-become-a-10x-engineer-492fa3f57101">Enthusiasm</a>.</li></ol><p id="c68d">You need to have a fitting personality, meaning, you need to be able to easily communicate with your team without any hassle whatsoever. You need to ask clear and concise questions while at the same time, giving thorough and detailed answers.</p><p id="51b8">Of course, you also need to possess basic qualifications for the job you are applying for. Yet, many people seem to put tons of attention to that one (which is perfectly fine), but it’s just ¼ of the whole equation.</p><p id="61d9">Culture fit — this ties back into your personality. You have to be able to sync with your team and develop a culture that everyone enjoys working in.</p><p id="147b">And finally, have a burning passion and enthusiasm for your job. You’ll be surprised how helpful enthusiasm can be.</p><p id="eee3">For example, you may not have as good a resume as the guy in the next room that’s also being interviewed… but if you display a burning enthusiasm and willingness to go out of your way, you can beat other candidates and win the job. Of course, that may not always be the case. Still, it’s much more likely for an employer to hire you as a hyper enthusiastic person than as an average employee.</p><p id="2cb1">Alright, let’s take a look at some of the most common web developer interview questions (and answers) you may encounter. We’ll first start with professional software engineer behavioral questions and then switch over to more technical questions.</p><p id="6540">Whether you are a front-end, back-end, or full-stack software developer, these common computer science interview questions will help you in your preparation for the next coding interview.</p><p id="0f2d">NOTE: Some of the behavioral questions can also be noticed in web design interviews. So if you are a web designer, this article will highly prepare you for the next web design interview.</p><p id="53af">Most interviewers start off with introductory questions. Just follow the common sense when answering these software engineer interview questions. Try to be as transparent as possible. Tell them what really sparked your interest in coding and why you applied for this job.</p><p id="9720">If you are applying for an entry-level web developer job, interviewers won’t expect years of experience (they may even skip that question) as you’ve probably just graduated or finished a coding boot camp. Yet, if you are applying for a senior software engineer position, you need to have years of experience to back up your application for that web development job.</p><p id="ed12">You need to get familiar with Agile frameworks such as Kanban and Scrum because nowadays companies are adopting Agile practices and moving away from Waterfall methodologies. Interviewers may also ask you questions about the <a target="_blank" rel="noopener" href="https://blog.codegiant.io/software-development-life-cycle-the-ultimate-guide-2020-153d17bb20fb">SDLC (Software Development Life Cycle) process</a>.</p><p id="3aa1">As simple as that. You might want to focus on the specific languages that your web development job will require you to use most frequently.</p><p id="b2b4">Lately, having experience with multiple languages like C++, Java, and Python will definitely widen your interviewer’s eyes in astonishment.</p><p id="588b"><em>Credits to Andrew Mallonee, CEO at </em><a href="https://malloneemedia.com/" target="_blank" rel="noopener"><em>Mallonee Media</em></a><em>.</em></p><p id="0286">Be transparent and give a thorough explanation.. Sometimes, the interviewer might follow up with, “Do you get excited by using these languages?” but rarely. Obviously, reply with Yes and explain why you feel excited.</p><p id="fb59">It’s more of a soft skill interview question. Software engineering is a job in which you need to always thrive and sharpen your skills. Employers need to know that their developers are on the cutting edge using the latest technologies and constantly honing their skills. So, the answer to that software developer interview question would obviously be “Yes” — but expand further by telling them what interests you the most when it comes to learning new coding skills.</p><p id="14d6">Talk about projects similar to the projects you are going to be working on in the position you are applying for. If not, be genuine (always) and tell them what really sparks your passion for software development.</p><p id="e2fd">Here, interviewers particularly want to hear about severe problems, not many people on your team were able to solve, yet you were. Something important to remember is not to try to impress the interviewer — the scales will fall from his eyes immediately. Instead of making a good impression, you’ll make a desperate one. Be casual when talking about the problem that no one was able to solve except you. You, thus, exude confidence and knowledge. Being humble in the answer of this web dev interview question is key.</p><p id="6399">Another soft skill interview question. Life is about learning from your mistakes. Be as transparent as possible and openly admit the mistakes you’ve made in the past. Talk about the lessons you’ve learned. Basically, explain how you coped with your worst failures and came out stronger.</p><p id="bf9b">Research a lot prior to the interview. Go through all of their social media profiles to find little nuggets of information that would impress your interviewer. Show passion and enthusiasm for the company. Enthusiasm plays a huge role in the interview process.</p><p id="7b49">Same as previous — conduct thorough research and analysis before the interview. Show passion and enthusiasm. Tell the interviewer why you would love to work on those particular projects. They can thus see the reason behind that enthusiasm and wind out the thoughts of all that being a mere fluff.</p><p id="b2c0">These web development interview questions can happen over the phone or onsite.</p><p id="e12a">The following technical interview questions typically happen onsite, but sometimes they can take place remotely. If it’s remotely, the interviewer will ask you to share your screen to watch over your shoulder while you are coding and at the same time answering software development interview questions.</p><p id="c6ea">Keep in mind that the technical questions you are being asked highly depend on the position you are applying for. We’ll try to cover some of the most common software developer interview questions and give you reasonable answers that you can adjust to your situation easily.</p><p id="699b"><em>Credits to Michael Miller, CEO at </em><a href="https://vpnonline.com/" target="_blank" rel="noopener"><em>VPN Online</em></a><em>.</em></p><p id="fc04">There are lots of ways you can write your code, and all of them are correct. The company you want to join probably has a set standard for writing code and will perhaps compare your answer to that standard. Usually, most companies look for developers who take the simplest approach to code and try to weep out those who praise the sophisticated way of coding. That’s because companies want to easily maintain and document their code.</p><p id="3b99">Java developer interview questions are quite common. When interviewers ask you …</p></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.codegiant.io/25-web-developer-interview-questions-and-answers-3030b21ae016">https://blog.codegiant.io/25-web-developer-interview-questions-and-answers-3030b21ae016</a></em></p>]]>
            </description>
            <link>https://blog.codegiant.io/25-web-developer-interview-questions-and-answers-3030b21ae016</link>
            <guid isPermaLink="false">hacker-news-small-sites-23661922</guid>
            <pubDate>Sat, 27 Jun 2020 14:09:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Rainbow – an attempt to display colour on a B&W monitor]]>
            </title>
            <description>
<![CDATA[
Score 383 | Comments 58 (<a href="https://news.ycombinator.com/item?id=23661808">thread link</a>) | @anfractuosity
<br/>
June 27, 2020 | https://www.anfractuosity.com/projects/rainbow/ | <a href="https://web.archive.org/web/*/https://www.anfractuosity.com/projects/rainbow/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">



 <!-- END header -->


<section id="main">
	<div>
    
     	

        
        <article>
                        
<p>The aim of this project was to display a colour image on a black and white monitor, by overlaying an acetate bayer filter over the monitor and mosaicing a colour image.</p>



<p>I obtained an Eizo B&amp;W monitor from ebay, which I was intending for use viewing B&amp;W photos and was curious if I could replicate an effect similar to <strong>Autochrome Lumière</strong> ( see <a href="https://en.wikipedia.org/wiki/Autochrome_Lumi%C3%A8re">wikipedia</a> ) where they overlay colour filters over a B&amp;W photographic plate, using starch grains, which creates a colour image.</p>



<p>The following image shows a 500x microscope image of the pixels that make up the B&amp;W LCD display, taken using a very cheap USB microscope.  It looks to me as if each pixel, is represented by 4 sub-pixel elements, please correct me if this appears not be the case.</p>



<figure><img src="https://www.anfractuosity.com/wp-content/uploads/2020/06/mpv-shot0007.jpg" alt="" srcset="https://www.anfractuosity.com/wp-content/uploads/2020/06/mpv-shot0007.jpg 640w, https://www.anfractuosity.com/wp-content/uploads/2020/06/mpv-shot0007-300x225.jpg 300w" sizes="(max-width: 640px) 100vw, 640px"></figure>



<p>A pdf was created of the bayer display, with the dimensions 433.1mm x 324.8mm.  The monitor has a resolution of 2048×1536 and I assumed the pixels had the same width as height.</p>



<p>You can see an example of the pdf I created below, where for example a blue element, should be represented by 2×2 pixels from the B&amp;W monitor. </p>



<figure><img src="https://www.anfractuosity.com/wp-content/uploads/2020/06/bayer_pdf-1024x540.png" alt="" srcset="https://www.anfractuosity.com/wp-content/uploads/2020/06/bayer_pdf-1024x540.png 1024w, https://www.anfractuosity.com/wp-content/uploads/2020/06/bayer_pdf-300x158.png 300w, https://www.anfractuosity.com/wp-content/uploads/2020/06/bayer_pdf-768x405.png 768w, https://www.anfractuosity.com/wp-content/uploads/2020/06/bayer_pdf-1536x810.png 1536w, https://www.anfractuosity.com/wp-content/uploads/2020/06/bayer_pdf.png 1920w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>I created 3 pdfs:</p>



<ul><li>bayer_1.pdf  –  each element, is represented by 1 pixel from the display</li><li>bayer_2.pdf  –  each element, is represented by 2×2 pixels from the display (this is the acetate used in the video)</li><li>bayer_4.pdf – each element is represented by 4×4 pixels from the display</li></ul>



<p>The following image shows the printed acetate with the bayer pattern:</p>



<figure><img src="https://www.anfractuosity.com/wp-content/uploads/2020/06/IMG_7509-1024x683.jpg" alt="" srcset="https://www.anfractuosity.com/wp-content/uploads/2020/06/IMG_7509-1024x683.jpg 1024w, https://www.anfractuosity.com/wp-content/uploads/2020/06/IMG_7509-300x200.jpg 300w, https://www.anfractuosity.com/wp-content/uploads/2020/06/IMG_7509-768x512.jpg 768w, https://www.anfractuosity.com/wp-content/uploads/2020/06/IMG_7509-1536x1024.jpg 1536w, https://www.anfractuosity.com/wp-content/uploads/2020/06/IMG_7509-2048x1365.jpg 2048w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>The following, is a B&amp;W image with mosaicing applied from the colour image:</p>



<figure><a href="https://www.anfractuosity.com/wp-content/uploads/2020/06/out.png"><img src="https://www.anfractuosity.com/wp-content/uploads/2020/06/out-1024x768.png" alt="" srcset="https://www.anfractuosity.com/wp-content/uploads/2020/06/out-1024x768.png 1024w, https://www.anfractuosity.com/wp-content/uploads/2020/06/out-300x225.png 300w, https://www.anfractuosity.com/wp-content/uploads/2020/06/out-768x576.png 768w, https://www.anfractuosity.com/wp-content/uploads/2020/06/out-1536x1152.png 1536w, https://www.anfractuosity.com/wp-content/uploads/2020/06/out.png 2048w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<h2>How it works</h2>



<figure><img src="https://www.anfractuosity.com/wp-content/uploads/2020/06/fig-1-1024x616.png" alt="" srcset="https://www.anfractuosity.com/wp-content/uploads/2020/06/fig-1-1024x616.png 1024w, https://www.anfractuosity.com/wp-content/uploads/2020/06/fig-1-300x180.png 300w, https://www.anfractuosity.com/wp-content/uploads/2020/06/fig-1-768x462.png 768w, https://www.anfractuosity.com/wp-content/uploads/2020/06/fig-1-1536x923.png 1536w, https://www.anfractuosity.com/wp-content/uploads/2020/06/fig-1.png 1898w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>The monitor I am using seems to generally be used portrait, to make it landscape on linux:</p>


<pre title="">xrandr --output HDMI1 --rotate left
</pre>


<h2>Image of effect</h2>



<p>As you can see the effect of my attempt is quite slight, but you can see in the centre the different colours of the balloons.</p>



<figure><a href="https://www.anfractuosity.com/wp-content/uploads/2020/06/mpv-shot0001.jpg"><img src="https://www.anfractuosity.com/wp-content/uploads/2020/06/mpv-shot0001-1024x576.jpg" alt="" srcset="https://www.anfractuosity.com/wp-content/uploads/2020/06/mpv-shot0001-1024x576.jpg 1024w, https://www.anfractuosity.com/wp-content/uploads/2020/06/mpv-shot0001-300x169.jpg 300w, https://www.anfractuosity.com/wp-content/uploads/2020/06/mpv-shot0001-768x432.jpg 768w, https://www.anfractuosity.com/wp-content/uploads/2020/06/mpv-shot0001-1536x864.jpg 1536w, https://www.anfractuosity.com/wp-content/uploads/2020/06/mpv-shot0001.jpg 1920w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<h2>Video of effect</h2>



<p>The effect is also demonstrated in the following video, with the following parameters:</p>


<pre title=""> mpv out.mkv --fullscreen --loop --brightness=10 --contrast=20
</pre>


<figure><p>
<iframe title="Rainbow - using an acetate bayer filter over a B&amp;W monitor" width="940" height="529" src="https://www.youtube.com/embed/Sh2d9qAjYPo?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>



<h2>Microscope images of the bayer filter (2×2 scaling)</h2>



<p>2×2 bayer filter, I tried to design it so that for example the ‘red’ square covers 2×2 pixels on the monitor</p>



<figure><img src="https://www.anfractuosity.com/wp-content/uploads/2020/06/mpv-shot0001-1.jpg" alt="" srcset="https://www.anfractuosity.com/wp-content/uploads/2020/06/mpv-shot0001-1.jpg 640w, https://www.anfractuosity.com/wp-content/uploads/2020/06/mpv-shot0001-1-300x225.jpg 300w" sizes="(max-width: 640px) 100vw, 640px"></figure>



<h2>Chess board </h2>



<p>As suggested by Olivier, I’ve just created 2 chess board images.  Olivier was correct that a single pixel consists of 3 sub-pixels 🙂</p>



<p>1×1 (the white patch is 1 pixel), monitor in landscape, image in correct orientation from microscope (left, towards left monitor, top, towards top of monitor)</p>



<figure><img src="https://www.anfractuosity.com/wp-content/uploads/2020/06/mpv-shot0020.jpg" alt="" srcset="https://www.anfractuosity.com/wp-content/uploads/2020/06/mpv-shot0020.jpg 640w, https://www.anfractuosity.com/wp-content/uploads/2020/06/mpv-shot0020-300x225.jpg 300w" sizes="(max-width: 640px) 100vw, 640px"></figure>



<p>2×2 </p>



<figure><img src="https://www.anfractuosity.com/wp-content/uploads/2020/06/mpv-shot0002.jpg" alt="" srcset="https://www.anfractuosity.com/wp-content/uploads/2020/06/mpv-shot0002.jpg 640w, https://www.anfractuosity.com/wp-content/uploads/2020/06/mpv-shot0002-300x225.jpg 300w" sizes="(max-width: 640px) 100vw, 640px"></figure>



<h2>Possible improvements</h2>



<p>I wonder if by measuring the exact pixel width/height under a microscope, if the effect could possibly be improved somewhat, as that information could be used when creating the acetate filter.</p>



<p>Alignment is also a key issue, I need to think of ways to improve that possibly using a microscope while aligning the acetate.</p>



<p>I’d be interested in other improvements I could make too!</p>



<h2>Source</h2>



<p>The sourcecode to generate the PDFs for the acetate and the mosaiced images and videos is at:</p>



<p><a href="https://www.github.com/anfractuosity/rainbow">https://www.github.com/anfractuosity/rainbow</a></p>
                        <br>


			
                                
                
                                
                 <!-- END #comments -->    
                	                                
                
                
                                      
                 <!-- END #leave_comment -->
                
 
                </article> <!-- END article -->




	</div> <!-- END #main_inner -->     
</section> <!-- END #main -->       

 <!-- END #footer -->

</div></div>]]>
            </description>
            <link>https://www.anfractuosity.com/projects/rainbow/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23661808</guid>
            <pubDate>Sat, 27 Jun 2020 13:43:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Implementing Our Own Version of Rust's Non-Lexical Lifetimes in Bolt]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23661557">thread link</a>) | @mrathi12
<br/>
June 27, 2020 | https://mukulrathi.co.uk/create-your-own-programming-language/data-race-dataflow-analysis/ | <a href="https://web.archive.org/web/*/https://mukulrathi.co.uk/create-your-own-programming-language/data-race-dataflow-analysis/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><h3>Creating the Bolt Compiler: Part 5</h3><p><h3>June 27, 2020</h3><h3>7 min read</h3></p><nav><h2>Series: Creating the Bolt Compiler</h2><ul><li></li><li></li><li></li><li></li><li><strong>Part 5: A tutorial on liveness and alias dataflow analysis</strong></li><li><em>Part 6: Desugaring - taking our high-level language and simplifying it!*</em></li><li><em>Part 7: Protobuf serialisation - converting from OCaml to C++*</em></li><li><em>Part 8: LLVM's C++ API for the Uninitiated*</em></li><li><em>Part 9: Adding Concurrency to Bolt*</em></li><li><em>Part 10: Adding function and method overloading*</em></li><li><em>Part 11: Inheritance and method overriding in Bolt*</em></li><li><em>Part 12: Generics - adding polymorphism to Bolt*</em></li><p>*coming soon! </p></ul></nav><hr><h2 id="dataflow-analysis---the-big-picture"><a href="#dataflow-analysis---the-big-picture" aria-label="dataflow analysis   the big picture permalink"></a>Dataflow Analysis - the big picture</h2><p>In the previous post in the series, we looked at how type-checking the core language worked. This analysis is <em>flow-insensitive</em> - it does not depend on the flow of the execution of the program. If an expression is of type <code>int</code> then it will have type <code>int</code> regardless of what was executed before or after it.</p><p>Some program properties do however depend on the execution path taken by a program. Dataflow analysis tracks how a particular value might propagate as the program executes.</p><p>For example, a value might <em>alias</em> - you could have multiple references pointing to that value. Whether two references <code>x</code> and <code>y</code> alias can’t be determined by looking at their assignments in isolation - we need to track the execution to determine if they have the same value assigned to them.</p><div><p><span>alias_example</span></p><div><pre><p><span>let</span><span> x </span><span>=</span><span> someObject</span></p><p><span></span><span>...</span><span></span></p><p><span></span><span>let</span><span> y </span><span>=</span><span> someObject </span></p></pre></div></div><p>Another example is <strong>liveness analysis</strong> - we say a value is <em>live</em> if some point later in the program it could be used, and <em>dead</em> otherwise.</p><div><p><span>liveness_example</span></p><div><pre><p><span>let</span><span> x </span><span>=</span><span> someValue </span><span></span></p><p><span></span><span>...</span><span></span></p><p><span></span><span>print</span><span>(</span><span>x</span><span>)</span><span> </span><span></span></p><p><span>x </span><span>=</span><span> someOtherValue </span></p></pre></div></div><p>Why do we care about alias analysis and liveness analysis? Well it turns out that Rust’s <em>borrow-checker</em> uses a combination of these to determine when a reference is borrowed. Bolt has a <em>linear</em> capability in its type system which acts the same.</p><p>Both Rust’s borrow checker and Bolt’s capabilities prevent data races - an explanation why is in <a href="https://github.com/mukul-rathi/bolt-dissertation/blob/master/dissertation.pdf">my dissertation</a>.</p><p>In a nutshell, Rust works on the principle of <strong>ownership</strong>: you either have one reference (owner) that can read/write (a <em>mutable</em> reference) or you can <em>borrow</em> (aka alias) the reference.</p><p>To enforce this we care about 2 things:</p><ol><li>When is a reference borrowed? (alias analysis)</li><li>For how long is it borrowed? (liveness analysis)</li></ol><p>Let’s elaborate on that second point. When is a reference borrowed? The first version of Rust’s borrow checker said this was whilst an alias was in scope.</p><div><p><span>borrow_example</span></p><div><pre><p><span>let</span><span> x </span><span>=</span><span> something </span><span></span></p><p><span></span><span>{</span><span></span></p><p><span>  </span><span>let</span><span> y </span><span>=</span><span> x</span></p><p><span>  </span><span>...</span><span> </span><span></span></p><p><span>  </span><span>print</span><span>(</span><span>y</span><span>)</span><span></span></p><p><span>  x </span><span>=</span><span> somethingElse</span></p><p><span></span><span>}</span><span></span></p></pre></div></div><p>That means we cannot reassign <code>x</code> in the example until <code>y</code> is out of scope. This is a “lexical lifetime” - <code>y</code>’s borrow lifetime is determined by its lexical scope. So that means <code>x</code> can’t be reassigned, since it is borrowed at that point. But <code>y</code> isn’t being used so surely <code>x</code> isn’t still borrowed?</p><p>That’s the idea behind <strong>non-lexical lifetimes</strong> - the borrow ends when the value of <code>y</code> is dead - i.e. it is not being used.</p><p>In Bolt, we’ll be tracking the lifetimes of references to <em>objects</em>.</p><p>Let’s get implementing it!</p><h2 id="alias-analysis"><a href="#alias-analysis" aria-label="alias analysis permalink"></a>Alias Analysis</h2><p>The first step is to determine when two values alias. How do we know two references will point to the same object without actually executing the program?</p><p>We use <strong>abstract interpretation</strong>.</p><h3 id="abstract-interpretation"><a href="#abstract-interpretation" aria-label="abstract interpretation permalink"></a>Abstract Interpretation</h3><p>Abstract interpretation is the process of simulating the execution of the program but only storing the program properties we care about. So in our case, we don’t care about what the actual result of the program execution is, we’re just tracking the <em>set of aliases</em>.</p><div><p>Implicit in this is a set of rules for how the program will execute, we call this its <strong>operational semantics</strong>. We will not go into details here, but it’s things like:</p><ul><li>Do we evaluate expressions left-to-right or right-to-left?</li><li>When calling a function, do we fully evaluate the argument expression and then call the function with the value of that argument, or do we just plug in the unevaluated argument expression directly into the function and only evaluate it at the point it is used in the function body? The former is called <strong>call-by-value</strong> and is used in most mainstream languages like Java and Python, the latter is called <strong>call-by-name</strong> and is used in Haskell and Lisp.</li></ul><p>There’s a lot more to say about this - perhaps it’s worthy of its own blog post? Send me a tweet if you would like one!</p></div><p>When do we have aliasing? When a new variable is declared or when it is reassigned. For simplicity (and also because we don’t want the lifetime of the alias to be larger than the original value) we will not allow aliasing via reassigning an existing variable (e.g. <code>x := y</code>).</p><p>So we care about expressions of this form:</p><p>The expression <code>e</code> can <em>reduce</em> to a value when executing e.g. <code>1+2</code> reduces to <code>3</code>.</p><p>If when executing <code>e</code> it reduces to a reference <code>y</code>, then the overall expression would look like:</p><p>And so <code>x</code> would alias <code>y</code>. So let’s write a function that, given an expression, will return the list of identifiers that it could possible reduce to. That’ll tell us what <code>x</code> could possibly alias.</p><p>We’ll store this helper function in an “environment” of helper functions used in the data-race type-checking stage of the Bolt compiler: <code>data_race_checker_env.mli</code></p><p>The type signature of this OCaml function is as we’d expect:</p><p>A reminder of the type of <code>expr</code> defined in the <a href="https://mukulrathi.co.uk/create-your-own-programming-language/intro-to-type-checking/#annotating-our-ast-with-types">previous post</a> - <code>loc</code> encodes the line number and position of the expression - used for error messages.</p><div><p><span><a href="https://github.com/mukul-rathi/bolt/blob/simple-compiler-tutorial/src/frontend/typing/typed_ast.mli"> <!-- -->typed_ast.mli</a></span></p><div><pre><p><span>type</span><span> identifier </span><span>=</span><span></span></p><p><span>  </span><span>|</span><span> </span><span>Variable</span><span> </span><span>of</span><span> type</span><span>_</span><span>expr </span><span>*</span><span> </span><span>Var_name</span><span>.</span><span>t</span></p><p><span>  </span><span>|</span><span> </span><span>ObjField</span><span> </span><span>of</span><span> </span><span>Class_name</span><span>.</span><span>t </span><span>*</span><span> </span><span>Var_name</span><span>.</span><span>t </span><span>*</span><span> type</span><span>_</span><span>expr </span><span>*</span><span> </span><span>Field_name</span><span>.</span><span>t</span></p><p><span></span><span>type</span><span> expr </span><span>=</span><span></span></p><p><span>  </span><span>|</span><span> </span><span>Integer</span><span>     </span><span>of</span><span> loc </span><span>*</span><span> int</span></p><p><span>  </span><span>|</span><span> </span><span>Boolean</span><span>     </span><span>of</span><span> loc </span><span>*</span><span> bool</span></p><p><span>  </span><span>|</span><span> </span><span>Identifier</span><span>  </span><span>of</span><span> loc </span><span>*</span><span> identifier</span></p><p><span>  </span><span>|</span><span> </span><span>Constructor</span><span> </span><span>of</span><span> loc </span><span>*</span><span> type</span><span>_</span><span>expr </span><span>*</span><span> </span><span>Class_name</span><span>.</span><span>t </span><span>*</span><span> constructor</span><span>_</span><span>arg list</span></p><p><span>  </span><span>|</span><span> </span><span>Let</span><span>         </span><span>of</span><span> loc </span><span>*</span><span> type</span><span>_</span><span>expr </span><span>*</span><span> </span><span>Var_name</span><span>.</span><span>t </span><span>*</span><span> expr</span></p><p><span>  </span><span>|</span><span> </span><span>Assign</span><span>      </span><span>of</span><span> loc </span><span>*</span><span> type</span><span>_</span><span>expr </span><span>*</span><span> identifier </span><span>*</span><span> expr</span></p><p><span>  </span><span>|</span><span> </span><span>If</span><span>          </span><span>of</span><span> loc </span><span>*</span><span> type</span><span>_</span><span>expr </span><span>*</span><span> expr </span><span>*</span><span> block</span><span>_</span><span>expr </span><span>*</span><span> block</span><span>_</span><span>expr</span></p><p><span>  </span><span>.</span><span>.</span><span>.</span><span></span></p><p><span></span><span>and</span><span> block</span><span>_</span><span>expr </span><span>=</span><span></span></p><p><span>  </span><span>|</span><span> </span><span>Block</span><span> </span><span>of</span><span> loc </span><span>*</span><span> type</span><span>_</span><span>expr </span><span>*</span><span> expr list</span></p></pre></div></div><p>Starting off with the simple cases, it’s clear an integer or a boolean value doesn’t reduce to an identifier, and an identifier expression reduces to that identifier. A <code>new SomeClass()</code> constructor also doesn’t reduce to an identifier.</p><div><p><span><a href="https://github.com/mukul-rathi/bolt/blob/master/src/frontend/data_race_checker/data_race_checker_env.ml"> <!-- -->data_race_checker_env.ml</a></span></p><div><pre><p><span>let</span><span> </span><span>rec</span><span> reduce</span><span>_</span><span>expr</span><span>_</span><span>to</span><span>_</span><span>obj</span><span>_</span><span>ids expr </span><span>=</span><span></span></p><p><span>  </span><span>match</span><span> expr </span><span>with</span><span></span></p><p><span>  </span><span>|</span><span> </span><span>Integer</span><span> </span><span>_</span><span> </span><span>|</span><span> </span><span>Boolean</span><span> </span><span>_</span><span> </span><span>-&gt;</span><span> </span><span>[</span><span>]</span><span></span></p><p><span>  </span><span>|</span><span> </span><span>Identifier</span><span> </span><span>(</span><span>_</span><span>,</span><span> id</span><span>)</span><span> </span><span>-&gt;</span><span> </span><span>[</span><span>id</span><span>]</span><span></span></p><p><span>  </span><span>|</span><span> </span><span>Constructor</span><span> </span><span>(</span><span>_</span><span>,</span><span> </span><span>_</span><span>,</span><span> </span><span>_</span><span>,</span><span> </span><span>_</span><span>)</span><span> </span><span>-&gt;</span><span> </span><span>[</span><span>]</span></p></pre></div></div><p>If we have a let expression or assigning to an identifier, then it reduces to that identifier (e.g. <code>let x = ___</code> reduces to <code>x</code>, and <code>x.f:= __</code> reduces to <code>x.f</code>):</p><div><p><span><a href="https://github.com/mukul-rathi/bolt/blob/master/src/frontend/data_race_checker/data_race_checker_env.ml"> <!-- -->data_race_checker_env.ml</a></span></p><div><pre><p><span>.</span><span>.</span><span>.</span><span></span></p><p><span>  </span><span>|</span><span> </span><span>Let</span><span> </span><span>(</span><span>_</span><span>,</span><span> </span><span>_</span><span>,</span><span> </span><span>_</span><span>,</span><span> bound</span><span>_</span><span>expr</span><span>)</span><span> </span><span>-&gt;</span><span> reduce</span><span>_</span><span>expr</span><span>_</span><span>to</span><span>_</span><span>obj</span><span>_</span><span>ids bound</span><span>_</span><span>expr</span></p><p><span>  </span><span>|</span><span> </span><span>Assign</span><span> </span><span>(</span><span>_</span><span>,</span><span> </span><span>_</span><span>,</span><span> </span><span>_</span><span>,</span><span> assigned</span><span>_</span><span>expr</span><span>)</span><span> </span><span>-&gt;</span><span> reduce</span><span>_</span><span>expr</span><span>_</span><span>to</span><span>_</span><span>obj</span><span>_</span><span>ids assigned</span><span>_</span><span>expr</span></p></pre></div></div><p>We can continue doing this for other cases. But what about an <code>if</code> statement? Does this expression reduce to <code>x</code> or <code>y</code>?</p><div><div><pre><p><span>if</span><span> </span><span>(</span><span>someCondition</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>  x</span></p><p><span></span><span>}</span><span> </span><span>else</span><span> </span><span>{</span><span></span></p><p><span>  y</span></p><p><span></span><span>}</span></p></pre></div></div><p>In general, without actually executing the expression, we don’t know. So we’ll have to approximate.</p><p>Let’s remind ourselves of our goal - to mark a value as borrowed/not linear (Rust / Bolt equiv. terminology) if it is aliased. We’re trying to eliminate data races, so we have to be <em>conservative</em> - assume it might be aliased even if it isn’t. The worst thing would be to let a data race slip through. Abstract interpretation <em>always</em> errs on the side of soundness.</p><p>So we’ll <em>overapproximate</em> the list of possible identifiers the expression could reduce to - we don’t know which branch so we’ll count the identifiers from <em>both</em> branches.</p><div><p><span><a href="https://github.com/mukul-rathi/bolt/blob/master/src/frontend/data_race_checker/data_race_checker_env.ml"> <!-- -->data_race_checker_env.ml</a></span></p><div><pre><p><span>.</span><span>.</span><span>.</span><span></span></p><p><span>  </span><span>|</span><span> </span><span>If</span><span> </span><span>(</span><span>_</span><span>,</span><span> </span><span>_</span><span>,</span><span> </span><span>_</span><span>,</span><span> then</span><span>_</span><span>expr</span><span>,</span><span> else</span><span>_</span><span>expr</span><span>)</span><span> </span><span>-&gt;</span><span></span></p><p><span>      </span><span>let</span><span> then</span><span>_</span><span>ids </span><span>=</span><span> reduce</span><span>_</span><span>block</span><span>_</span><span>expr</span><span>_</span><span>to</span><span>_</span><span>obj</span><span>_</span><span>ids then</span><span>_</span><span>expr </span><span>in</span><span></span></p><p><span>      </span><span>let</span><span> else</span><span>_</span><span>ids </span><span>=</span><span> reduce</span><span>_</span><span>block</span><span>_</span><span>expr</span><span>_</span><span>to</span><span>_</span><span>obj</span><span>_</span><span>ids else</span><span>_</span><span>expr </span><span>in</span><span></span></p><p><span>      then</span><span>_</span><span>ids </span><span>@</span><span> else</span><span>_</span><span>ids</span></p></pre></div></div><p>So in the example above, we’d return a list <code>[x, y]</code>.</p><h3 id="computing-all-aliases"><a href="#computing-all-aliases" aria-label="computing all aliases permalink"></a>Computing all aliases</h3><p>So we know if we have an expression <code>let y = e</code> and <code>e</code> reduces to <code>x</code>, then we have <code>let y = x</code> and so <code>y</code> is an alias of <code>x</code>.</p><p>In the expression below, we would also run abstract interpretation (simple in this case) to find that <code>z</code> and <code>w</code> are aliases of <code>y</code>.</p><div><div><pre><p><span>let y = x</span></p><p><span>...</span></p><p><span>let z = y</span></p><p><span>if(y.f &gt; 1){</span></p><p><span>  ...</span></p><p><span>}</span></p><p><span>else {</span></p><p><span>}</span></p><p><span>...</span></p><p><span>let w = y</span></p></pre></div></div><p>By transitivity, <code>z</code> and <code>w</code> must also be aliases of <code>x</code>.</p><p>I like to think of this like a graph where each edge is a direct/immediate alias. We can find all aliases, by repeatedly applying abstract interpretation in a “breadth-first search” style - each iteration we’re expanding the frontier. And each iteration we try to find aliases of the aliases we’ve found - so the first iteration we find aliases of <code>x</code>, then the next iteration we find aliases of <code>x</code> and <code>y</code> and so on…</p><p><span>
      <a href="https://mukulrathi.co.uk/static/e996478c0eaa723fc8028caa72847284/191e2/alias-frontier.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Alias Frontier Diagram" title="Alias Frontier Diagram" src="https://mukulrathi.co.uk/static/e996478c0eaa723fc8028caa72847284/a6d36/alias-frontier.png" srcset="https://mukulrathi.co.uk/static/e996478c0eaa723fc8028caa72847284/222b7/alias-frontier.png 163w,https://mukulrathi.co.uk/static/e996478c0eaa723fc8028caa72847284/ff46a/alias-frontier.png 325w,https://mukulrathi.co.uk/static/e996478c0eaa723fc8028caa72847284/a6d36/alias-frontier.png 650w,https://mukulrathi.co.uk/static/e996478c0eaa723fc8028caa72847284/e548f/alias-frontier.png 975w,https://mukulrathi.co.uk/static/e996478c0eaa723fc8028caa72847284/3c492/alias-frontier.png 1300w,https://mukulrathi.co.uk/static/e996478c0eaa723fc8028caa72847284/191e2/alias-frontier.png 1836w" sizes="(max-width: 650px) 100vw, 650px" loading="lazy">
  </a>
    </span></p><p>So we repeat, until we find no more aliases. The full code is linked in the repo, and includes an option of matching fields (i.e. should we consider aliases of <code>x.f</code> as well as <code>x</code>?) We won’t in this case, but other aspects of Bolt’s data-race type-checker do use this.</p><p>But the beauty of functional programming is that the function says what we’re doing with no boilerplate:</p><div><p><span><a href="https://github.com/mukul-rathi/bolt/blob/master/src/frontend/data_race_checker/data_race_checker_env.ml"> <!-- -->data_race_checker_env.ml</a></span></p><div><pre><p><span>let</span><span> </span><span>rec</span><span> get</span><span>_</span><span>all</span><span>_</span><span>obj</span><span>_</span><span>aliases should</span><span>_</span><span>match</span><span>_</span><span>fields curr</span><span>_</span><span>aliases block</span><span>_</span><span>expr </span><span>=</span><span></span></p><p><span>    find</span><span>_</span><span>immediate</span><span>_</span><span>aliases</span><span>_</span><span>in</span><span>_</span><span>block</span><span>_</span><span>expr should</span><span>_</span><span>match</span><span>_</span><span>fields name</span><span>_</span><span>to</span><span>_</span><span>match curr</span><span>_</span><span>aliases</span></p><p><span>      block</span><span>_</span><span>expr</span></p><p><span>    </span><span>|&gt;</span><span> </span><span>fun</span><span> updated</span><span>_</span><span>aliases </span><span>-&gt;</span><span></span></p><p><span>    </span><span>if</span><span> var</span><span>_</span><span>lists</span><span>_</span><span>are</span><span>_</span><span>equal updated</span><span>_</span><span>aliases curr</span><span>_</span><span>aliases</span></p><p><span>       </span><span>then</span><span> curr</span><span>_</span><span>aliases </span><span></span></p><p><span>    </span><span>else</span><span> get</span><span>_</span><span>all</span><span>_</span><span>obj</span><span>_</span><span>aliases should</span><span>_</span><span>match</span><span>_</span><span>fields updated</span><span>_</span><span>aliases block</span><span>_</span><span>expr</span></p></pre></div></div><h2 id="liveness-analysis"><a href="#liveness-analysis" aria-label="liveness analysis permalink"></a>Liveness Analysis</h2><p>Alright, so we’re halfway there - we’ve identified our aliases, now we need to find out when they’re live. Remember a value is <em>live</em> if there’s some program execution path in the future it will be used on.</p><h3 id="control-flow-graph"><a href="#control-flow-graph" aria-label="control flow graph permalink"></a>Control Flow Graph</h3><p>To do this, let’s formalise the notion of “execution paths” in a program. We’re going to be representing a program as a graph of instructions, with edges representing the steps in the execution. We call this the <strong>Control Flow Graph</strong> of the program.</p><figure>
    <span>
      <a href="https://mukulrathi.co.uk/static/2f8d764b548afc2de1c14af61aee3c4e/776d3/control-flow-graph.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Control Flow Graph" title="Note how the control flow graph shows two different execution paths, corresponding to the if-else branch taken." src="https://mukulrathi.co.uk/static/2f8d764b548afc2de1c14af61aee3c4e/a6d36/control-flow-graph.png" srcset="https://mukulrathi.co.uk/static/2f8d764b548afc2de1c14af61aee3c4e/222b7/control-flow-graph.png 163w,https://mukulrathi.co.uk/static/2f8d764b548afc2de1c14af61aee3c4e/ff46a/control-flow-graph.png 325w,https://mukulrathi.co.uk/static/2f8d764b548afc2de1c14af61aee3c4e/a6d36/control-flow-graph.png 650w,https://mukulrathi.co.uk/static/2f8d764b548afc2de1c14af61aee3c4e/e548f/control-flow-graph.png 975w,https://mukulrathi.co.uk/static/2f8d764b548afc2de1c14af61aee3c4e/3c492/control-flow-graph.png 1300w,https://mukulrathi.co.uk/static/2f8d764b548afc2de1c14af61aee3c4e/776d3/control-flow-graph.png 1814w" sizes="(max-width: 650px) 100vw, 650px" loading="lazy">
  </a>
    </span>
    <figcaption>Note how the control flow graph shows two different execution paths, corresponding to the if-else branch taken.</figcaption>
  </figure><p>We’ll be coming back to this Control Flow Graph when we talk about LLVM later in the series! There’ll be more terminology then, but for now this’ll do.</p><p>In our graph, we can pick any …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mukulrathi.co.uk/create-your-own-programming-language/data-race-dataflow-analysis/">https://mukulrathi.co.uk/create-your-own-programming-language/data-race-dataflow-analysis/</a></em></p>]]>
            </description>
            <link>https://mukulrathi.co.uk/create-your-own-programming-language/data-race-dataflow-analysis/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23661557</guid>
            <pubDate>Sat, 27 Jun 2020 12:58:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Global sailing navigation simulator using real weather/ocean data]]>
            </title>
            <description>
<![CDATA[
Score 128 | Comments 45 (<a href="https://news.ycombinator.com/item?id=23661326">thread link</a>) | @ls65536
<br/>
June 27, 2020 | https://8bitbyte.ca/sailnavsim/ | <a href="https://web.archive.org/web/*/https://8bitbyte.ca/sailnavsim/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><td>Position sharing interval:</td><td> - how often boat positions are shared among members in race</td></div></div>]]>
            </description>
            <link>https://8bitbyte.ca/sailnavsim/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23661326</guid>
            <pubDate>Sat, 27 Jun 2020 12:17:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Personal OKRs for Success]]>
            </title>
            <description>
<![CDATA[
Score 118 | Comments 44 (<a href="https://news.ycombinator.com/item?id=23661067">thread link</a>) | @mkfeuhrer
<br/>
June 27, 2020 | https://mohitkhare.me/blog/personal-okrs/ | <a href="https://web.archive.org/web/*/https://mohitkhare.me/blog/personal-okrs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <!-- Toc if any -->
                
                <!-- End Toc -->
                <p>Last year as I kicked off my career entering the professional tech world, I came across the concept of <strong>Objective, Key and Results (OKRs)</strong> at work. I was quite intrigued by the whole concept of OKRs.</p>

<p>In very layman terms —</p>

<blockquote>
  <p>Main objective of OKR is to plan out qualitative goals with quantitative results for those with proper time tracking.</p>
</blockquote>

<p>People do use diary or todo apps for tracking there work. Todo apps usually work for tracking tasks over a shorter duration. You need a framework to plan out for your bigger goal and track your progress towards it.</p>

<p><img src="https://cdn-images-1.medium.com/max/1600/1*bX5Vy1OPJ3LImq9DHIgU5g.png" alt="Personal OKR Header Section"></p>

<p>In this blog, I will try to explain how you can plan and why it is important to have your Personal OKR. Let’s begin!</p>

<h2 id="what">What?</h2>

<p>OKRs is already a very popular term in business, most probably it is being used at your workplace too. It is a <strong>goal-setting framework</strong> that basically covers big and challenging goals with a set of defined measurable results for achieving these goals.</p>

<h3 id="objective">Objective — </h3>

<ul>
  <li>What do you want to achieve over a period of time?</li>
  <li>Objectives should be ambitious, more <strong>inspirational</strong> (which requires more effort of yours), bold and <strong>qualitative</strong></li>
  <li>Your targets should not be something very easily achievable.</li>
</ul>

<p><strong>Eg.</strong> Improve the financial condition, Get better at reading, etc</p>

<h3 id="key-results">Key Results</h3>

<ul>
  <li>KRs are steps you need to achieve the objective.</li>
  <li>KRs should be <strong>Quantitative</strong> i.e having defined metrics! This should not be vague. Add numbers, avoid terms like “more/less”.<br>
Google uses. a scale of 0–1 for tracking progress for each key result.</li>
  <li>Make KRs <strong>Time-bounded</strong>. This helps you tracking progress over the period and lets you recalibrate your tasks.</li>
  <li>KRs should be <strong>Binary</strong> i.e Complete / Incomplete</li>
</ul>

<p><strong>Eg.</strong> Read 3 books on investing, Read 1500 pages monthly, etc</p>

<hr>

<h3 id="personal-vs-work-okrs">Personal vs Work OKRs?</h3>

<p>OKRs are used by both teams and individuals, though mostly in work environments. The concept of OKR is simple and works pretty effectively for personal use as well. It is super important to have separate personal and work OKRs since your work goals are different from personal life and goals.</p>

<p>In personal OKRs, you would want to track things like —</p>

<ol>
  <li>Family time</li>
  <li>Personal finance</li>
  <li>Fitness</li>
  <li>Hobbies</li>
</ol>

<p>Personal OKRs are <strong>literally personal</strong>!<br>
It varies from person to person. It’s good to look for ideas on how people use OKRs, but you should align it for your goals and aspirations which you want to achieve.</p>

<hr>

<h2 id="why">Why?</h2>

<blockquote>
  <p>“Actions — and data — speak louder than words.”<br>
― <strong>John Doerr,</strong> <a href="https://www.goodreads.com/work/quotes/54960827"><strong>Measure What Matters</strong></a></p>
</blockquote>

<p>OKRs help you plan your goals in a structured and planned fashion, but there is more to it! Let me explain —</p>

<ul>
  <li>Better <strong>Focus</strong> and <strong>Alignment</strong> on what you want to achieve. Since OKRs are limited, you don’t want to waste time and do stuff that doesn’t really help you achieve what you want!</li>
  <li>These give the <strong>Motivation</strong> to work towards your objectives and a sense of urgency to finish them.</li>
  <li>OKRs help in building a <strong>Habit</strong> of planning things in general and following the path to achieving them. Eg. You have an objective of getting better at reading, you start reading 30 pages daily. Now, it slowly builds into your habit to read. Next year, even if you don’t have this objective, you’ll still read :)</li>
  <li><strong>Time Tracking</strong> is super useful and important since they give a timeline for you to work and align your tasks accordingly.</li>
  <li><strong>Metrics</strong> and Numbers help you visualize your progress. When you see 80% completion, you get a psychological motivation to make it 100%</li>
  <li>If you have a <strong>Public OKR</strong>, you get another source to actually work and complete your task.</li>
</ul>

<blockquote>
  <p>‘I’d rather have the objective be to go to Mars, and if we fall short, we’ll get to the moon. This is how you make moonshots. — Larry Page</p>
</blockquote>

<p><a href="https://www.whatmatters.com/faqs/benefits-of-okrs/">Measure what matters</a> brings a similar <strong>F.A.C.T.S</strong> showing the benefits of OKRs.</p>

<hr>

<h2 id="how">How?</h2>

<p>Now, that you understand the importance of Personal OKRs and are ready to create yours, I’ll show how I personally maintain my OKRs and share resources that might be useful for you!</p>

<h3 id="tools">Tools</h3>

<p>There are a lot of tools that you can use to start creating an OKR. I personally being a big fan of <a href="http://notion.so/">Notion</a>, use it to maintain my Personal OKRs. You can use anything from professional notes and trackers like <a href="https://evernote.com/">Evernote</a>, <a href="http://notion.so/">Notion</a>, <a href="https://todoist.com/">Todoist</a> to simple excel sheet template.</p>

<h3 id="process">Process</h3>

<p><img src="https://cdn-images-1.medium.com/max/2400/1*IOarq_FgPMWWVqohXAMvHg.png" alt="OKR Tracking with Notes"></p>

<p>I usually update my OKRs monthly since I maintain a yearly OKR tracker. You can adjust it according to the timeline you are planning for.</p>

<p>I maintain different tables for each of my Objectives. In the image below</p>

<p><strong>Objective</strong> — Boost Knowledge</p>

<p><strong>Key Results</strong> —</p>

<ol>
  <li>
    <p>Read 20 books</p>
  </li>
  <li>
    <p>Create 2 open source projects</p>
  </li>
</ol>

<p><strong>Time Tracking</strong> — <br>
I maintain time tracking based on which quarter of the year I want this to be completed. I do break these KRs into sub-tasks which are added to my Todolist with a specified timeline.<br>
I use <strong>EOY</strong> (End of Year) in cases when I want that KR to be worked on throughout the year.</p>

<p><strong>Status</strong>—</p>

<p>I set my KRs progress to one of the 5 stages. It helps me keep track of what to do next and what is already completed. I sometimes add <strong>At-Risk</strong> tag to denote that this KR is probably not happening. I already added <strong>At-Risk</strong> to my traveling KRs this year credits to corona :(</p>

<p><img src="https://cdn-images-1.medium.com/max/1600/1*HQJ56kvlk0-mDZiXBrptfw.png" alt="Quarter based timeframe and Status for tracking progress"></p>

<p><strong>Notes</strong>  — <br>
These are basically notes/links relevant to KR which I would want to revisit when I come back to this sometime later.</p>

<h2 id="tips-and-tricks">Tips and Tricks</h2>

<ul>
  <li><strong>Avoid changing OKRs</strong>! It is okay to update OKRs when you achieve something or want to divert. Do not remove OKRs just because you are doing something else now, at the end of the timeframe you should know that you failed at this due to XYZ reason, and was it worth it or not?</li>
  <li>You will fail in many Key results! <strong>It is okay to fail</strong>, now you get an idea on what did you miss, how can you improve and rework accordingly.</li>
  <li><strong>Regularly update your KRs status and notes</strong>, this gives you an idea of where you need to focus more in the next few days. A biweekly or monthly review is generally a good time to revisit OKRs. I set up a biweekly reminder in my calendar for this!</li>
  <li>You can <strong>add a score</strong> to each KR to make things more interesting. For the first time, I wanted to keep it simple. Do share if you use some interesting scoring :P</li>
  <li><strong>Avoid setting too many OKRs</strong> instead make the OKRs more challenging.</li>
  <li>Add links to your weekly tasks in notes sections. This helps you view how did you spend your week in the perspective of achieving your OKR results. Even add resources for specific KRs. This helps you increase your knowledge base over a period of time.</li>
  <li><strong>Keep it simple</strong>! Follow what you can maintain. Don’t overcomplicate :)</li>
</ul>

<h2 id="resources">Resources</h2>

<ul>
  <li>Wide-set of OKR examples — <a href="https://www.whatmatters.com/get-examples/">https://www.whatmatters.com/get-examples/</a></li>
  <li>Complete Guide — <a href="https://rework.withgoogle.com/guides/set-goals-with-okrs/steps/introduction/">https://rework.withgoogle.com/guides/set-goals-with-okrs/steps/introduction/</a></li>
  <li>How Google uses OKR — <a href="https://www.youtube.com/watch?v=mJB83EZtAjc">https://www.youtube.com/watch?v=mJB83EZtAjc</a></li>
  <li><a href="http://eleganthack.com/the-art-of-the-okr/">http://eleganthack.com/the-art-of-the-okr/</a></li>
  <li>Book — <a href="https://www.goodreads.com/book/show/39286958-measure-what-matters">Measure What Matters</a></li>
</ul>

<p>Do share how you maintain and keep track of your goals! But remember —</p>

<blockquote>
  <p>“Ideas are easy. Execution is everything.” — <strong>John Doerr</strong></p>
</blockquote>

<hr>

<p>I hope you learned something interesting and new. Don’t miss out on the latest blogs — <a href="https://mohitkhare.me/blog/personal-okrs/[http://eepurl.com/g2Mbc9](http://eepurl.com/g2Mbc9)">Subscribe now</a>. ✅</p>

<p>Interested in more technology, productivity and life stuff? I share updates/knowledge almost daily on <a href="https://twitter.com/mkfeuhrer">Twitter</a>.</p>

<p>Reach out to me at <a href="https://mohitkhare.me/">mohitkhare.me</a> ❤️️</p>

    
            </div></div>]]>
            </description>
            <link>https://mohitkhare.me/blog/personal-okrs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23661067</guid>
            <pubDate>Sat, 27 Jun 2020 11:15:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Treatise on Font Rasterisation (2010)]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23660701">thread link</a>) | @threeme3
<br/>
June 27, 2020 | https://freddie.witherden.org/pages/font-rasterisation/ | <a href="https://web.archive.org/web/*/https://freddie.witherden.org/pages/font-rasterisation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    
    
    <p>Font rasterisation is, in the author’s opinion, one of the most
    interesting fields of computer science. If music is the subjective
    application of physics, then font rasterisation is almost
    certainly the subjective application of computer science. The
    purpose of this article is threefold: firstly, to provide an
    introduction into the various methods available to aid in the
    rasterisation process; secondly, to provide a critical analysis of
    these methods against the needs of desktop applications; and
    finally, to relate this analysis to free software.</p>
    <p>Figures, in the form of bitmap images, are used extensively
    throughout. This is done to ensure consistent results across
    different platforms. Since some of the figures make use of
    sub-pixel rendering, this article is best viewed on an LCD
    screen.</p>
    <h2>Contents</h2>
    <ul>
      <li><a href="#introduction">Introduction</a></li>
      <li><a href="#font-hinting">Font Hinting</a></li>
      <li><a href="#anti-aliasing">Anti-aliasing</a></li>
      <li><a href="#anti-aliasing-with-hinting">Combining
      Anti-aliasing With Hinting</a></li>
      <li><a href="#sub-pixel-rendering">Sub-pixel Rendering</a></li>
      <li><a href="#sub-pixel-positioning">Sub-pixel
      Positioning</a></li>
      <li><a href="#application-requirements">Application
      Requirements</a></li>
      <li><a href="#windows-os-x">Windows &amp; Mac OS X</a></li>
      <li><a href="#summary-of-techniques">Summary of
      Techniques</a></li>
      <li><a href="#free-software">GNU/Linux &amp; Free
      Software</a></li>
      <li><a href="#advice-for-distributions">Advice For
      Distributions</a></li>
      <li><a href="#other-resources">Other Resources</a></li>
      <li><a href="#references">References</a></li>
      <li><a href="#figure-notes">Figure Notes</a></li>
      <li><a href="#revision-history">Revision History</a></li>
    </ul>
    <h2><a name="introduction">Introduction</a></h2>
    <p>Before we start exploring the various methods used in font
    rasterisation, it is important to first understand <em>why</em>
    rasterisation is so difficult. Why should rasterisation on a
    computer screen be any more complicated than on a printer? It all
    comes down to resolution. Or, more precisely, the number
    of <em>dots per inch</em> (DPI).</p>
    <p>Printers typically start at around 300 DPI, with 600 DPI not
    being uncommon. This means that for every inch (2.54cm), there are
    potentially 300+ individual dots. Fonts, however, are not measured
    in dots but instead in <em>points</em>: 1/72 of an inch. A direct
    consequence of this is that a specific font at 10pt will have the
    same <em>physical dimensions</em> irrespective of the DPI at which
    it is rasterised.</p>
    <p>Whereas printers have a relatively high DPI, computer screens
    are typically <em>assumed</em> to be at 96 DPI, over three times
    lower. Herein lies the difficulty with on-screen
    rasterisation. This is best illustrated with an example: Figure 1
    shows the letter ‘M’ in 10pt Times New Roman at 600, 300, and 96
    DPI, respectively. Looking at the figure, it is clear that 96 DPI
    is not sufficient to preserve the shape—or letter-form—of the
    glyph.</p>
    <div>
      <p><img width="137" height="55" alt="M at a low DPI" src="https://freddie.witherden.org/pages/font-rasterisation/images/m-various-dpi.png"></p><p>Figure 1: How 10pt Times Roman looks at 600, 300, and 96
      DPI.</p>
    </div>
    <p>This phenomenon can be explained using <em>information
    theory</em>. Since glyphs contain information it is possible to
    view them as a signal comprised of various frequencies. The
    Nyquist–Shannon sampling theorem states that in order to
    accurately reproduce a signal, the sampling rate needs to
    be <em>at least twice the maximum frequency of the
    signal</em>. Should the sampling rate be lower than this, then
    distortions—in the form of aliasing—will be introduced. In the
    case of rasterisation, the sampling rate corresponds directly to
    the DPI of the output device.</p>
    <p>An example of aliasing as a consequence of low DPI can be seen
    in Figure 2.</p>
    <div>
      <p><img width="249" height="12" alt="Aliasing at a low DPI" src="https://freddie.witherden.org/pages/font-rasterisation/images/aliasing.png"></p><p>Figure 2: 10pt Times New Roman at 96 DPI. Note how some stems
      are thicker than others, and how certain features are
      under-/over-emphasised.</p>
    </div>
    <p>Since it is clear that 96 DPI is insufficient for accurate
    rasterisation, we are left with two options. The first is to find
    a way of <em>increasing the effective sampling rate</em> of the
    device, while the second is to <em>reduce the frequency of the
    glyphs to allow the use of a lower sampling rate</em>. All of the
    methods presented in this article fall into one of these two
    categories.</p>
    <h2><a name="font-hinting">Font Hinting</a></h2>
    <p>One of the oldest and mostly widely used techniques for
    improving rasterisation quality is font hinting. Also known
    as <em>grid fitting</em>, hinting involves modifying the shape of
    glyphs in order to ensure they line up with the rasterisation
    grid. By distorting the glyph so that it is aligned with the pixel
    grid, the overall frequency is reduced. An example of font hinting
    can be seen in Figure 3.</p>
    <div>
      <p><img width="257" height="26" alt="Un-hinted vs hinted text" src="https://freddie.witherden.org/pages/font-rasterisation/images/hinting.png"></p><p>Figure 3: 10pt Times New Roman at 96 DPI with (bottom) and
      without (top) hinting. Also note the differing widths between
      the hinted and un-hinted text.</p>
    </div>
    <p>The hinted text is much more consistent than its un-hinted
    counterpart. However, this consistency comes at the price of
    accuracy. An unavoidable consequence of warping glyphs to the
    rasterisation grid is that their dimensions change slightly. These
    small differences quickly add up over a line of text resulting in
    a visible difference—such as that seen in Figure 3. The author
    refers to this phenomenon as <em>character drift</em>.</p>
    <p>The degree of hinting required to produce consistent output is
    dependent on the DPI of the output device; low resolution devices
    require more aggressive hinting than high resolution device. One
    of the consequences of aggressive hinting—necessary as it may
    be—is character drift. At resolutions in excess of 300 DPI, it is
    possible to forego font hinting entirely.</p>
    <h3>Implementation details</h3>
    <p>Font hinting is usually achieved through one of two
    approaches. The first of these puts the font designer in control
    of the hinting process. This is the approach taken by the TrueType
    font specification—without a doubt the most widespread font
    format. In the specification, a virtual machine is used to
    instruct the rasteriser on how to go about rendering a
    glyph. This, in theory, gives designers <em>pixel level</em>
    control over how glyphs are rasterised at various
    sizes <cite><a href="#tur01a">Tur01a</a></cite>. The second
    approach is to leave hinting up to the font rasteriser—so
    called <em>auto-hinting</em>. When rendering non-TrueType
    fonts—such as those in Adobe’s Type 1 format, or those that lack
    hinting instructions—this is often the only
    option <cite><a href="#tur01a">Tur01a</a></cite>.</p>
    <p>In order for a meaningful comparison to be made between these
    approaches, it is first necessary to have an understanding of some
    of the other techniques available for improving rasterisation
    quality.</p>
    <h2><a name="anti-aliasing">Anti-aliasing</a></h2>
    <p>So far, we have been assuming that pixels are bi-level, either
    on or off, black or white. However, modern computer screens are
    capable of displaying millions of colours, including shades of
    grey. Font rasterisers are able to take advantage of this by using
    a technique called <em>anti-aliasing</em>. As the name would
    suggest, anti-aliasing is a means of avoiding the unwanted effects
    of aliasing when sampling a high-frequency signal on a
    low-frequency device. This is done by blurring the signal; its
    effect is to reduce its maximal frequency.</p>
    <p>Pixels of anti-aliased text are multi-level. That is, they can
    be black, white, or a shade of grey. The shade of a pixel depends
    on the percentage of the pixel that is <em>masked</em> by the
    glyph. This concept is neatly demonstrated in Figure 4.</p>
    <div>
      <p><img width="92" height="63" alt="Primitive anti-aliasing" src="https://freddie.witherden.org/pages/font-rasterisation/images/g-anti-aliased.png"></p><p>Figure 4: The letter ‘g’ in 10pt Times New Roman at 672 DPI
      (left) and 96 DPI (right). The right glyph has been rendered
      with a (primitive) anti-aliasing algorithm and scaled by a
      factor of 7.</p>
    </div>
    <p>The effect of anti-aliasing on a line of text can be seen in
    Figure 5. Anti-aliasing does a very good job at preserving the
    shapes of glyphs. Moreover, the anti-aliased text does not suffer
    from character drift. However, this accuracy comes at the
    sacrifice of clarity—the anti-aliased text has a much lower
    contrast than its hinted counterpart.</p>
    <div>
      <p><img width="257" height="41" alt="A comparison of anti-aliased
      text" src="https://freddie.witherden.org/pages/font-rasterisation/images/anti-aliasing.png"></p><p>Figure 5: 10pt Times New Roman at 96 DPI; without
      anti-aliasing or hinting (top), with hinting (middle), with
      anti-aliasing (bottom).</p>
    </div>
    <h2><a name="anti-aliasing-with-hinting">Combining Anti-aliasing
    With Hinting</a></h2>
    <p>Both hinting and anti-aliasing improve the legibility of text
    at low resolutions by making it more consistent. Hinting does this
    at the cost of <em>accuracy</em>, while anti-aliasing does it at
    the cost of <em>contrast</em>. At this point, the logical question
    to ask is “can hinting and anti-aliasing be used in conjunction
    with each other?” The answer is yes—with the appropriate finesse,
    it is possible to hint anti-aliased text.</p>
    <p>In principle, hinting anti-aliased text is exactly the same as
    hinting monochromatic text. However, in practice, a different
    implementation is required in order to produce high-quality
    output <cite><a href="#tur01b">Tur01b</a></cite>. The practicality
    of this depends on the hinting approach taken; it is significantly
    easier when the hinting is performed by the font rasteriser
    instead of a virtual machine. Indeed, naïvely combining TrueType
    hinting with anti-aliasing can often result in a <em>reduction in
    overall consistency</em>! This is most readily observed when
    rendering sans-serif fonts, as can be seen in Figure 6.</p>
    <div>
      <p><img width="263" height="43" alt="Hinting and anti-aliasing
      combined" src="https://freddie.witherden.org/pages/font-rasterisation/images/bytecode-hinting-with-anti-aliasing.png"></p><p>Figure 6: 10pt Arial at 96 DPI; with TrueType hinting (top),
      with anti-aliasing (middle), with TrueType hinting and
      anti-aliasing (bottom).</p>
    </div>
    <p>While the output is legible, it lacks consistency—some
    characters, such as ‘w’ and ‘s’, are anti-aliased, while others,
    such as ‘l’, are not. This causes some characters to appear to be
    heavier than others. These heavier characters are often referred
    to as being <em>dirty</em>. The undesirable characteristics
    apparent in Figure 6 arise because the anti-aliased text is being
    hinted <em>as if it were regular monochromatic text</em>. (Which,
    incidentally, is why the application of anti-aliasing has no
    effect on the overall character drift.) But as was established in
    the previous section, anti-aliased text has a <em>lower
    frequency</em> than monochromatic text. The solution, therefore,
    is to use less aggressive hinting. This is quite difficult to
    accomplish when using TrueType hinting, as the virtual machine
    does not …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://freddie.witherden.org/pages/font-rasterisation/">https://freddie.witherden.org/pages/font-rasterisation/</a></em></p>]]>
            </description>
            <link>https://freddie.witherden.org/pages/font-rasterisation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23660701</guid>
            <pubDate>Sat, 27 Jun 2020 09:52:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Algorithmic View of Law]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23660114">thread link</a>) | @iciac
<br/>
June 27, 2020 | https://www.camerongordon.site/post/an-algorithmic-view-of-law | <a href="https://web.archive.org/web/*/https://www.camerongordon.site/post/an-algorithmic-view-of-law">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="7.10.5"><div dir="ltr"><div><p id="viewer-foo">In Western Australia it an offence to possess more than 50kg of potatoes, <a href="https://www.gotocourt.com.au/legal-news/weird-australian-laws/" target="_top" rel="noopener"><u>unless you are a member of the Potato Corporation</u></a>. Challenging someone to a duel in Tasmania carries a $6,000 fine. There's no law against <a href="http://www.gerties.com.au/weird-australian-laws-fact-or-fiction/" target="_top" rel="noopener"><u>wearing hot pink pants after midday</u></a> on a Sunday afternoon in Victoria, but flying a kite in public <a href="http://www8.austlii.edu.au/cgi-bin/viewdoc/au/legis/vic/consol_act/soa1966189/s4.html" target="_top" rel="noopener"><u>"to the annoyance of any person"</u></a> can put you back $800. Under the Rain-Making Control Act (1967) you are advised that it is an offence to <a href="http://www.legislation.vic.gov.au/Domino/Web_Notes/LDMS/LTObject_Store/ltobjst8.nsf/DDE300B846EED9C7CA257616000A3571/9D788B5BB4776F24CA257C3100008D44/$FILE/67-7637aa016%20authorised.pdf" target="_top" rel="noopener"><u>"carry out unauthorised rain-making operations"</u></a>. </p><p id="viewer-5hc95">Getting a measure of how many laws there are in Australia is not easy, but one practitioner's resource <a href="https://legal.thomsonreuters.com.au/products/the-laws-of-australia/" target="_top" rel="noopener"><em><u>The Laws of Australia</u></em></a> proudly lists over 40,000 legal propositions across 320 specific topics and 36 broad topic areas. Despite the legal maxim that ignorance of the law is no excuse, it is clear that it is impossible for even an interested reader to have a full and complete knowledge of the law - let alone a disinterested reader. </p><p id="viewer-eodrf">In the Design of Everyday Things, Donald Norman describes two crucial principles for a useful object: <em>Discoverability</em> and <em>Understanding</em>. It should be easy to learn how an object works, and clear to see how to use it. For the vast majority of laws, this is not the case: a typical Act may run for many hundreds of pages, define case-specific jargon, refer to rules set out in external pieces of legislation, involve ambiguities, internal inconsistencies, or simply poor writing (the 528 page <a href="https://www.legislation.qld.gov.au/view/html/inforce/current/act-2001-071" target="_top" rel="noopener"><u>Duties Act in Queensland</u></a> is a prime example).</p><p id="viewer-8n06i">In part, this is nature of the beast: the administrative structure for a law to be changed is a complicated and multi-staged affair, involving a parliament which will not seek to amend a law unless it serves for political capital. Repairing cracks in the sidewalk is necessary, but it's nothing you want to turn into a press statement. As a result law is updated only sporadically, and often in response to the most vocal and focal failures rather than being optimised. </p><p id="viewer-ekgl9">There are moves to improve this process. One of the more interesting is being led by the CSIRO <a href="https://data61.csiro.au/en/Our-Research/Our-Work/Future-Cities/Optimising-service-delivery/RaaP" target="_top" rel="noopener"><em><u>Regulation as a Platform</u></em></a><em> </em>project which recommends converting regulatory rules into machine readable logic which can be quickly checked for internal consistency, and clearer ways this may communicated to the public or automated for simple administrative tasks. Advances in natural language processing may additionally aid in users being able to ask for clarification for a legal rule, and receive general advice from a machine.</p><p id="viewer-ci8o1">The idea <a href="https://theconversation.com/csiro-wants-our-laws-turned-into-computer-code-heres-why-thats-a-bad-idea-130131" target="_top" rel="noopener"><u>has received pushback</u></a> due to concern that an algorithmic approach to law removes the human element and the role of discretion. Moreover the stink of Robodebt scandal makes some leery of outsourcing application of the law too far to machines. However the idea has some merit - not only in terms of directly using new tools for searching or interpreting the law; but also conceptually, using programming concepts to better understand how law may be better designed to run efficiently and user-friendly. </p><p id="viewer-dlmsk">In many ways a law is a program which runs on society rather than on circuits: wet, squishy humanware rather than hardware. It involves a system of logic and operation. Functions which are defined and acted upon in a systematic order, with constraints provided which restrict the operation of a system. The analogy is particularly clear for administrative law applied by rote. However, it also applies for laws which require the application of discretion or decision-making (the decision maker is simply a sub-operation requiring a person). </p><p id="viewer-6vdkf">In code, there is the concept of algorithmic efficiency - how resources (time and storage) vary with the size of an operation. This is measured by reference to the cost of a base operation (e.g. adding up two numbers, or plucking out an item from a list). The common measure is the worst case running time: a constant operation <em>O(1)</em> runs the same time no matter the size of the input; a linear operation <em>O(N) </em>runs as the sum of the base operations; and polynomial operations [e.g. <em>O(N^2)</em>],<em> </em>and exponential operations [e.g. <em>O(2^N)</em>] run increasingly less efficiently with the size of the input. Designing an efficient algorithm is understandably a goal for a good program that will run fast and easily with little overhead. </p><p id="viewer-dshb6">In principle the idea of algorithmic complexity also applies to law. Here we have additional forms of resources: costs of implementation (the cost of administrative public servants), costs of interpretation (the cost of understanding the law, e.g. employing external legal advice, reading legislation, or checking informal explainers), and costs in terms of error correction (the judicial system, including the many barriers to entry). While less tangible, these are similar to those borne by computers in algorithmic complexity: they represent the cost of resources required to run a particular process, which may be comprised of many smaller processes or required actions. </p><p id="viewer-4kiqo">As a result programming principles can be applied to make law more efficient and user-friendly. The aim is to minimise the total costs of operation while sufficiently achieving the desired legal aim. Looking at the regular individual operations involved in a procedure, including complex, expensive, or repeated operations, is the first step in improving the efficiency of a law. Beyond thinking about law in terms of algorithmic complexity, there are a number of core programming techniques that lend themselves to direct analogies in legal design. Many of the rules outlined in The Pragmatic Programmer (outline <a href="http://www.inf.fu-berlin.de/inst/ag-se/teaching/K-CCD-2014/Pragmatic-Programmer-summary.pdf" target="_top" rel="noopener"><u>here</u></a>) are directly applicable - particularly ideas around orthogonality (reducing cross-dependencies), maintaining single unambiguous definitions, and building in exception handling are all good concepts. </p><p id="viewer-1pb16">It's no coincidence that the authors of The Pragmatic Programmer turned to legal analogies when outlining concepts for programmers. As is often the case when two fields share conceptual links learnings from the two domains can flow in both directions, and legal professionals and policy designers would be advised to learn and take from design techniques in computer science where they can. </p></div></div></div></div></article></div></div>]]>
            </description>
            <link>https://www.camerongordon.site/post/an-algorithmic-view-of-law</link>
            <guid isPermaLink="false">hacker-news-small-sites-23660114</guid>
            <pubDate>Sat, 27 Jun 2020 07:26:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What IT Is]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23659998">thread link</a>) | @latchkey
<br/>
June 26, 2020 | https://xn--mp8hai.fm/statement | <a href="https://web.archive.org/web/*/https://xn--mp8hai.fm/statement">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article id="body"><h2>👁👄👁</h2><h2>WHAT IT REALLY IS</h2><p>JUNE 26TH, 2020</p><p>You’re probably wondering what this is. Well, it started off as just what it is.</p><p>A group of us changed our Twitter names to include <span>👁👄👁"</span> because we thought it was a funny trend from TikTok. People started noticing the change on their timelines, noting the creepiness of the emojis in particular. For a brief period of time, everyone who added the emojis to their name was added to a giant Twitter group conversation. From there, things unfolded.</p><p>What started out as a meme in our small group chat grew bigger than we ever imagined. So we thought about how to make use of the hype cycle we’d stumbled upon. But honestly, we didn’t have to think too hard: in this moment, there’s pretty much no greater issue to amplify than the systemic racism and anti-Blackness much of the world is only beginning to wake up to. We’re excited that we could use our newfound platform to drive action towards a few causes that are doing important work towards racial justice: <a href="https://thelovelandfoundation.org/loveland-therapy-fund/">Loveland Foundation Therapy Fund</a>,<a href="https://www.theokraproject.com/">The Okra Project</a>,<a href="https://www.innocenceproject.org/">The Innocence Project</a>, and others.</p><p>We’ve done pretty well for a non-existent product. <span>👁👄👁.fm</span> was the top product of the day on Product Hunt (Theranos who?). The website accumulated 20,000 email signups and thousands of tweets sharing the link. We were covered in <a href="https://www.independent.co.uk/life-style/gadgets-and-tech/news/face-emoji-twitter-it-is-what-it-is-promo-a9587351.html">The Independent</a> and <a href="https://www.forbes.com/sites/paularmstrongtech/2020/06/26/what-is--oh-it-is-what-it-is/amp/?__twitter_impression=true">Forbes</a>. We got shoutouts from <a href="https://constine.substack.com/p/what-does-mean-well">Josh Constine</a> and <a href="https://wfh.substack.com/p/the-6-builders-who-will-thrive-in">Brianne Kimmel</a>. Some folks on <a href="https://www.reddit.com/r/OutOfTheLoop/comments/hg26ip/whats_the_deal_with_this_it_is_what_it_is_app/">Reddit</a> puzzled over who we were. <a href="https://twitter.com/andrewchen/status/1276585276626726913?s=20">Andrew Chen</a> of Andreessen Horowitz, <a href="https://twitter.com/shannonpurser/status/1276631647157235712">Shannon Purser</a> of Stranger Things, and <a href="https://twitter.com/elonmusk/status/1276418907968925696">Elon Musk</a> may have subtweeted us? The <a href="https://twitter.com/itiseyemoutheye">@itiseyemoutheye</a> Twitter and accounts of our teammates were inundated with invite requests. Most importantly, we raised over $65,000 in donations from people who signed up for our email list. Two anonymous donors have agreed to match the first $60,000 and $75,000, bringing the total to $200,000. We would love to work with anyone else who wants to match. Please DM us! </p>In a strange way, this sort of became an anti-statement against what we’d all seen on tech Twitter. We’re a <a href="https://xn--mp8hai.fm/demographics.png">diverse</a>, ragtag group of young technologists tired of the status quo tech industry, and thought that we could make the industry think a bit more about its actions. Despite calls-to-action like that “<a href="https://a16z.com/2020/04/18/its-time-to-build/">It’s Time to Build</a>” essay we’ve all read, most of the industry (from product teams to VC) still stays obsessed with exclusive social apps that regularly ignore — or even silence — real needs faced by marginalized people all over the world, and exclude these folks from the building process. As an industry, we need to do better.<p>We sincerely thank you for spreading the word and donating to these important causes. In conclusion, it is what it is: a meme that leveraged the relentless hype of exclusive apps and redirected it towards a critical social need. Thank you, and remember that unlike <span>👁👄👁</span>, #BlackLivesMatter and other social movements aren't trends or hype cycles. Let’s keep giving back as best as we can.</p><p>Signed,</p><p><a href="https://twitter.com/itiseyemoutheye/following">The 👁👄👁 Team</a></p><p><a href="https://shop.itiswhatitis.fm/collections/stickers/products/thank-you-%F0%9F%91%81%F0%9F%91%84%F0%9F%91%81">We do have merch though.</a><br>All proceeds are donated to organizations that support Black lives.</p></article></div></div>]]>
            </description>
            <link>https://xn--mp8hai.fm/statement</link>
            <guid isPermaLink="false">hacker-news-small-sites-23659998</guid>
            <pubDate>Sat, 27 Jun 2020 06:52:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Live code music in GLSL shaders (Chrome & FF only)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23659859">thread link</a>) | @mv9
<br/>
June 26, 2020 | https://fms-cat.com/wavenerd/ | <a href="https://web.archive.org/web/*/https://fms-cat.com/wavenerd/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://fms-cat.com/wavenerd/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23659859</guid>
            <pubDate>Sat, 27 Jun 2020 06:09:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Indian railways gave time to India]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23659821">thread link</a>) | @indianhistoryy
<br/>
June 26, 2020 | http://worldhistoryinchunks.com/2020/06/27/who-gave-india-time/ | <a href="https://web.archive.org/web/*/http://worldhistoryinchunks.com/2020/06/27/who-gave-india-time/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<h2 id="783e">Railway time was the first joint element that united India. Madras/Chennai was the first place to transmit time to entire India.</h2>



<div><figure><img src="https://interestinghistoryforall.files.wordpress.com/2020/06/413ad-0wpivc8ss5r3ztwoj.jpg" alt=""><figcaption>Indian Railway.Source-Financial express</figcaption></figure></div>



<p>I’m always fascinated by the way my dad conveyed time. He prefers the 24 hours format. Many of his friends use the same, but in other walks of life in India, people stick to the 12hr time format. My dad worked in Indian railways, and in many parts of India, a 24 hours format came to be known as Railway Time. How did it the 24-hour format got the name railway time, and who gave India time? Let’s ponder on that question.</p>



<h2 id="c26f">Asia’s first-time zone:</h2>



<div><figure><img src="https://interestinghistoryforall.files.wordpress.com/2020/06/2fd24-0gbrmluypyr0km7jb.jpg" alt=""><figcaption>Madras Observatory.Source-Wikipedia</figcaption></figure></div>



<p>The need to have a standard time zone was the need due to Industrialisation. Prominent Astronomers across the world gathered in the USA for the World Meridian conference to conclude the center of the earth for timezone definition in 1884. The astronomers agreed that Greenwich, where British astronomical society is located will be the centerline for the time zone. Countries will calculate their time based on Greenwich meridian.</p>



<div><figure><img src="https://interestinghistoryforall.files.wordpress.com/2020/06/e08af-0h_a52u42pru5n1cy.jpg" alt=""><figcaption>John Goldingham working. Source-Wikipedia</figcaption></figure></div>



<p>British India set up a survey office in Nungambakkam, Madras to gather data on the landscape around Madras(Modern day Chennai). John Goldingham was the first Astronomer to land in Chennai and set up the first metrological station in Asia in Madras in 1742. He mapped the stars to set Madras at 80° 17’21 “E. He predicted India is 51/2 hours ahead of GMT. The time zone was fixed as Madras’s time probably the first Asian official timezone. His successor Thomas Glanville Taylor mapped 11,000 stars and published “Madras Catalog.”</p>



<p>As Industrialization gripped India, it was the need of the hour to keep uptime. Indian railways started to connect the nook and corner of India. Indian railways had three time zones, namely Bombay/Mumbai time zone, Calcutta/Kolkatta time zone, and Madras/Chennai time zone. After a few years, Madras’s time was adopted as Indian railways official time as Madras observatory had a telegraph office that can synchronize time across India. Also, Madras’s time was the closest to GMT. The Madras Merdian is marked by a granite pillar that stands to this day in the spot. The small telegraph office in Madras controlled the time of entire India until independence.</p>



<h2 id="b907">Railway time:</h2>



<p>Indian railways weaved across Indian culture and were part and parcel of everyday activity for millions of Indians. When Indian railways adopted standard time, it took the time with it throughout India. Divided by 567 princely states which even the British can’t penetrate, Indian railways brought them together at the same time. Most railway employees like my dad speak in 24 hours format as they are used to it. Madras’s time was the official time of India until independence.</p>



<p>Youtube:<a href="https://www.youtube.com/channel/UCu6Fe1D-UqBBSVcVk0O4n6g/featured?view_as=subscriber" target="_blank" rel="noreferrer noopener">https://www.youtube.com/channel/UCu6Fe1D-UqBBSVcVk0O4n6g/featured?view_as=subscriber</a></p>



<p>Twitter:<a href="https://twitter.com/indianhistoryyn" target="_blank" rel="noreferrer noopener">https://twitter.com/indianhistoryyn</a></p>



<p>Orginially published in <a href="https://medium.com/history-in-bytes/who-gave-india-time-90bd51f4b3d">https://medium.com/history-in-bytes/who-gave-india-time-90bd51f4b3d</a></p>
			
			
						</div></div>]]>
            </description>
            <link>http://worldhistoryinchunks.com/2020/06/27/who-gave-india-time/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23659821</guid>
            <pubDate>Sat, 27 Jun 2020 05:59:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Myths about Patents and Trademarks in startups]]>
            </title>
            <description>
<![CDATA[
Score 61 | Comments 33 (<a href="https://news.ycombinator.com/item?id=23659787">thread link</a>) | @samdung
<br/>
June 26, 2020 | https://hitstartup.com/myths-about-patents-and-trademarks-in-startups/ | <a href="https://web.archive.org/web/*/https://hitstartup.com/myths-about-patents-and-trademarks-in-startups/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>These are some of the common myths about Patents and Trademarks in startups.</p><h3 id="i-have-a-startup-idea-i-need-to-protect-it-with-a-patent">I have a startup idea, I need to protect it with a patent</h3><p>It’s natural to feel defensive about our <a href="https://hitstartup.com/startup-ideas-vs-problems/" target="_blank">startup idea</a>, but patents are for invention/innovation and not for a startup idea; even if we get nightmares about <a href="https://hitstartup.com/faang-will-steal-my-idea/" target="_blank">FAANG stealing our startup idea</a>.</p><h3 id="i-have-an-innovative-app-idea-i-need-to-protect-it-with-a-patent">I have an innovative app idea, I need to protect it with a patent</h3><p>Most countries don’t allow <a href="https://web.archive.org/web/20200213051434/https://www.wipo.int/sme/en/documents/software_patents_fulltext.html" target="_blank">patent for a software</a>. Economic theories, methods of doing business, mathematical methods or computer programs&nbsp;as such&nbsp;are not patentable inventions in several countries.</p><h3 id="my-patent-attorney-said-they-are-patentable">My patent attorney said they are patentable</h3><p>Did you read all the clauses in the agreement you signed with your patent attorney? The decision to award a patent to an invention/innovation lies solely with the patent examiner of the country. By the time a patent application is filed, till it comes to examination, several years and thousands of dollars would have been spent.</p><p>Although ethically, a patent attorney should explicitly convey their doubts on patentability of an invention, few rarely do. Even when Prior Art Search(Searching for conflicting patents) is conducted by the patent attorney, they are not always successful in bringing up the conflicting patents because our patent application is not drafted yet.</p><p>But, when the Govt. patent examiner does the Prior Art Search while examining our patent application, they will likely find conflicting patents if it exists.</p><h3 id="i-have-paid-my-patent-attorney-explained-my-invention-now-all-i-have-to-do-is-just-sit-tight-for-a-patent">I have paid my patent attorney, explained my invention, now all I have to do is just sit tight for a patent</h3><p>An average patent attorney drafts patent for anything from innovation in a <a href="https://en.wikipedia.org/wiki/Bidet" target="_blank">bidet</a> to quantum computers, so they are experts in using language to define an invention but they are rarely an expert in any field of invention.</p><p>So, this requires utmost care from the inventor to work along with the patent drafter to articulate their invention with appropriate vocabulary.</p><p>Unfortunately, patent attorneys tend to force the inventor to not to be specific in describing their invention in the patent application in order to exploit the loop holes in patent examination; This may help in getting the patent, but it also enables someone else to exploit the same loop holes to file a patent for the copy of our invention by just changing the grammar/vocabulary because our patent was too generic.</p><h3 id="i-have-filed-for-a-patent-no-one-would-copy-my-innovation-invention">I have filed for a patent, no one would copy my innovation/invention</h3><p>Examination of patent takes several years, although in the meantime we could use ‘patent-pending’ tag if our patent application gets published, finding someone who is copying our invention takes proactive approach. If the copied invention is being applied for patent, we need to detect it from published journal of the patent office and raise a concern.</p><p>All these takes extraordinarily focused effort and budget.</p><h3 id="i-have-applied-for-a-patent-via-pct-i-will-receive-patent-for-all-countries">I have applied for a patent via PCT, I will receive patent for all countries</h3><p><a href="https://www.wipo.int/pct/en/" target="_blank">PCT - Patent Cooperation Treaty</a> simplifies the process of applying for a patent in several countries who are part of the PCT treaty, but the process of obtaining a patent depends upon the individual country’s patent laws.</p><p>Even during filing PCT, the second phase i.e. national phase involves filing documents for patent application in the respective individual countries requiring working with the patent attorney’s of those countries resulting in thousands of dollars of expense for each country we wish to apply for via PCT.</p><p>We can extrapolate the same process for patent examination in each of those countries.</p><p>Then there are certain countries which even while being part of the PCT, doesn’t enforce patent protection for inventions of other countries in order to protect their local businesses which copies our invention.</p><h3 id="i-have-received-my-patent-it-would-prevent-someone-from-copying-my-invention">I have received my patent, it would prevent someone from copying my invention</h3><p>Like any law, existence of a law doesn’t prevent someone from violating it; enforcement and judicial process should uphold that law. Similarly, existence of patent doesn’t prevent someone from copying our invention.</p><p>We need to find the violator, pursue an often lengthy and expensive judicial process to claim our right to the invention protected by the patent.</p><h3 id="i-m-the-inventor-in-the-patent-i-can-do-anything-with-it">I’m the inventor in the patent, I can do anything with it</h3><p>Unless the inventor in the patent is the owner of the patent, the inventor has no right to the patent. This is often the case when businesses file patents, where the business is the owner in the patent and the employee is the inventor in the patent.</p><h3 id="patents-are-only-for-protecting-my-invention">Patents are only for protecting my invention</h3><p>The main reason to protect the invention is to reap the value of the invention if needed. Patents offer commercial and strategic value to businesses.</p><p>So, patents are often used for trading them for money or for other patents in organizations apart from using it for protecting their inventions.</p><h3 id="patents-make-me-look-cool">Patents make me look cool</h3><p>Not necessarily, <a href="https://www.eff.org/deeplinks/2020/05/new-low-bad-patent-patent-troll-sues-ventilator-company" target="_blank">patent trolls</a> have left a bad taste in the inventor/innovator community; so much so that many are <a href="https://www.youtube.com/watch?v=OsIihrcqJYA" target="_blank">choosing not to file patent for their invention</a>.</p><p>Expenses, effort, lengthy unfair judicial trials has made several startups to not pursue patent for their invention in favor of capital efficiency.</p><h3 id="open-source-projects-doesn-t-need-patents">Open-source projects doesn’t need patents</h3><p>Open-source projects might need patents to <a href="https://golang.org/PATENTS" target="_blank">protect itself from getting sued for patent infringement</a>. Open-source projects protected by patents can prevent large organizations from stealing our project <a href="https://keivan.io/the-day-appget-died/" target="_blank">without due credit</a>.</p><h3 id="i-have-a-startup-product-name-i-need-to-trademark-it">I have a startup/product name, I need to trademark it</h3><p>Unless the startup/product has created value for its customers, so that a counterfeiter is using that startup/product name for forgery; trademarks for startup/product names are useless. Besides, in most countries just <a href="https://hitstartup.com/when-to-register-our-startup/" target="_blank">incorporating/registering our startup as a company</a> would prevent anyone else from using the same name for their company.</p><h3 id="trademark-automatically-applies-to-the-name-and-the-logo">Trademark automatically applies to the name and the logo</h3><p>Trademarking the name and logo are separate process namely wordmark and device mark respectively. Device mark might include text when it’s alongside the logo.</p></div></div>]]>
            </description>
            <link>https://hitstartup.com/myths-about-patents-and-trademarks-in-startups/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23659787</guid>
            <pubDate>Sat, 27 Jun 2020 05:44:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Machine Learning Companies Revolutionizing Industries]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23659486">thread link</a>) | @nutellalover
<br/>
June 26, 2020 | https://www.confetti.ai/post/50-machine-learning-and-data-science-companies | <a href="https://web.archive.org/web/*/https://www.confetti.ai/post/50-machine-learning-and-data-science-companies">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="7.10.5"><div dir="ltr"><div><div id="viewer-1m9gi"><div><div data-hook="imageViewer"><div role="img"><p><img data-pin-url="https://www.confetti.ai/post/50-machine-learning-and-data-science-companies" data-pin-media="https://static.wixstatic.com/media/4feadc_12fbac4a7cc34e54999ddbd5f621d7e5~mv2.jpg/v1/fit/w_5000,h_4000,al_c,q_80/file.png" src="https://static.wixstatic.com/media/4feadc_12fbac4a7cc34e54999ddbd5f621d7e5~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p><svg viewBox="0 0 19 19"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 01-.283 0l-.374-.374a.2.2 0 010-.283l4.356-4.355h-3.786a.2.2 0 01-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 01-.2.2h-.529a.2.2 0 01-.2-.2zm-6.5 6.9v.529a.2.2 0 01-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 01.283 0l.374.374a.2.2 0 010 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z"></path></svg></div></div></div></div><p id="viewer-agmh1">Nowadays it's hard to find a single industry where machine learning and data science aren't being used to improve productivity and deliver results. Indeed that is why people are so excited about the promise of artificial intelligence: it can be applied to so many diverse problem spaces effectively and it works!</p><p id="viewer-82q81">In this post, we'll go over some impactful companies doing data science and machine learning today across various industries. This list has been aggregated after analyzing over 200 company descriptions, and we've broadly organized them by the problem domain being tackled and have included a brief description of their mission. </p><h3 id="viewer-8moqe"><strong>Infrastructure and Hardware</strong></h3><p id="viewer-15jm3"><a href="https://booklet.ai/" target="_blank" rel="noopener"><u>Booklet AI</u></a></p><p id="viewer-39ima">	TLDR: A framework for providing data integrations and web interfaces for trained machine learning models.</p><p id="viewer-uv8g"><a href="https://neptune.ai/" target="_blank" rel="noopener"><u>Neptune AI</u></a></p><p id="viewer-98oic">	TLDR: A lightweight experiment management tool that integrates into existing machine learning workflows</p><p id="viewer-6fgfd"><a href="https://determined.ai/" target="_blank" rel="noopener"><u>Determined AI</u></a></p><p id="viewer-aqcc8">	TLDR: A deep learning platform to help scale up training jobs and track experiments easily</p><p id="viewer-ci845"><a href="https://www.streamlit.io/" target="_blank" rel="noopener"><u>Streamlit</u></a></p><p id="viewer-bq68m">	TLDR: A tool for easily building web interfaces for data science and machine learning experiments in Python</p><p id="viewer-foeaa"><a href="https://www.factored.ai/" target="_blank" rel="noopener"><u>Factored AI</u></a></p><p id="viewer-dtbq8">	TLDR: Helps organizations build out entire data science teams by handling screening and training</p><p id="viewer-3cunr"><a href="https://www.datarobot.com/" target="_blank" rel="noopener"><u>DataRobot</u></a></p><p id="viewer-5em2g">	TLDR: An enterprise platform for helping companies automate the full machine learning pipeline starting with raw data all the way to production-level predictions.</p><p id="viewer-etf4q"><a href="https://www.cognitivescale.com/" target="_blank" rel="noopener"><u>Cognitive Scale</u></a></p><p id="viewer-2vg3f">	TLDR: Provides tools to build end-to-end workflows for models, using visual interfaces and emphasizing explainability</p><p id="viewer-8k1bm"><a href="https://www.h2o.ai/" target="_blank" rel="noopener"><u>H20 AI</u></a></p><p id="viewer-2kpd">	TLDR: Builds a suite of problem-agnostic tools and libraries for machine learning and data science experiments</p><p id="viewer-2r9eq"><a href="https://www.graphcore.ai/" target="_blank" rel="noopener"><u>GraphCore AI</u></a></p><p id="viewer-9lbf4">	TLDR: Developing a machine-learning specific processor that promises faster training times and lower inference latency than existing offerings such as GPUs</p><p id="viewer-c5dor"><span><u>Petuum</u></span></p><p id="viewer-2n4bj"><span>	TLDR: Building a general purpose suite of artificial intelligence building blocks that enable enterprises to build their own vertical solutions relying on machine learning</span></p><p id="viewer-5f1g8"><a href="https://www.dataiku.com/" target="_blank" rel="noopener"><u>Dataiku</u></a></p><p id="viewer-5e1s1">	TLDR: A fully-integrated and collaborative data studio that enables organizations to iterates on and develop date-driven solutions through tools for various stakeholders</p><p id="viewer-1b3s">
<a href="https://scale.com/" target="_blank" rel="noopener"><u>Scale AI</u></a></p><p id="viewer-45doc">	TLDR: Building a data platform for AI that helps companies build high quality training and validation datasets for their applications</p><h3 id="viewer-a08hm"><strong>Natural Language Processing</strong></h3><p id="viewer-9h598"><a href="https://narrativescience.com/" target="_blank" rel="noopener"><u>Narrative Science</u></a></p><p id="viewer-e9in1">	TLDR: Employs data storytelling to convert data analytics from structured formats to natural language output that can be more easily interpreted</p><p id="viewer-5l7a4"><a href="https://www.alpha-sense.com/" target="_blank" rel="noopener"><u>Alpha Sense</u></a></p><p id="viewer-e2cqn">	TLDR: An enterprise search engine for analyzing and understanding business and financial data</p><p id="viewer-adn0g"><a href="https://www.persado.com/" target="_blank" rel="noopener"><u>Persado</u></a></p><p id="viewer-asphb">	TLDR: A platform employing natural language understanding and generation to create more relevant and impactful marketing campaigns</p><p id="viewer-3vp77"><a href="https://casetext.com/" target="_blank" rel="noopener"><u>Casetext</u></a></p><p id="viewer-bbspe">	TLDR: A search engine optimized for litigation and legal document research</p><p id="viewer-3modk">
<a href="https://www.soundhound.com/" target="_blank" rel="noopener"><u>Soundhound</u></a></p><p id="viewer-8rajt">	TLDR: Develops voice recognition and natural language understanding tools used by enterprises</p><p id="viewer-cfrm"><a href="https://sherpa.ai/" target="_blank" rel="noopener"><u>Sherpa AI</u></a></p><p id="viewer-4b5gh">	TLDR: Building a suite of natural language processing SDKs for integrating recommendation systems, conversational managers, and user profiling into applications</p><p id="viewer-qsr6"><a href="https://www.meetcleo.com/" target="_blank" rel="noopener"><u>Cleo</u></a></p><p id="viewer-e8uvq">	TLDR: Leverages data science and natural language processing to build a chatbot for helping users with their personal finances</p><p id="viewer-6c94t">
<a href="https://lilt.com/" target="_blank" rel="noopener"><u>Lilt</u></a> </p><p id="viewer-7f91t">	TLDR: Helps enterprises with product localization through their efficient, AI-powered machine translation platform</p><h3 id="viewer-4i7p4"><strong>Computer Vision</strong></h3><p id="viewer-5e4uv"><a href="https://www.clarifai.com/" target="_blank" rel="noopener"><u>Clarifai</u></a></p><p id="viewer-ciu80">	TLDR: Provides an enterprise API for performing various computer vision tasks</p><p id="viewer-31h4l"><a href="https://orbitalinsight.com/" target="_blank" rel="noopener"><u>Orbital Insight</u></a></p><p id="viewer-1uu0l">	TLDR: A geospatial enterprise data platform that enables deriving insights in problems such as GIS mapping frequency, supply chain monitoring, and real estate due diligence</p><h3 id="viewer-4grsr"><strong>Healthcare and Medicine</strong></h3><p id="viewer-3ouup"><a href="https://www.tempus.com/" target="_blank" rel="noopener"><u>Tempus</u></a></p><p id="viewer-7jqh1">	TLDR: Applying machine learning and big data to precision medicine, thereby helping physicians make data-driven decisions for personalized healthcare</p><p id="viewer-6ern9"><a href="https://www.freenome.com/" target="_blank" rel="noopener"><u>Freenome</u></a></p><p id="viewer-flbmc">	TLDR: Employs machine learning and computational biology for early detection and precision intervention in cancer</p><p id="viewer-19egm"><a href="https://insilico.com/" target="_blank" rel="noopener"><u>Insilico Medicine</u></a></p><p id="viewer-c8gcd">	TLDR: Employs big data and statistical analyses for drug discovery, biomarker development, and aging research</p><p id="viewer-c1eae"><a href="https://insitro.com/about" target="_blank" rel="noopener"><u>Insitro</u></a></p><p id="viewer-9e62t">	TLDR: Developing a platform for accelerated drug discovery that leverages machine learning and big data</p><p id="viewer-kfrd"><a href="https://www.zebra-med.com/" target="_blank" rel="noopener"><u>Zebra Medical Vision</u></a></p><p id="viewer-bkq54">	TLDR: Develops medical imaging tools powered by AI to help improve the efficacy of radiologists in detecting illnesses.</p><p id="viewer-69b3c"><a href="https://www.benevolent.com/" target="_blank" rel="noopener"><u>Benevolent AI</u></a></p><p id="viewer-62a83">	TLDR: Leveraging machine learning and data science for various tasks like precision medicine, drug discovery, and molecular design</p><p id="viewer-dqttl"><a href="https://roamanalytics.com/" target="_blank" rel="noopener"><u>Roam Analytics</u></a></p><p id="viewer-165ij">	TLDR: Building a platform to help healthcare companies derive insights from structured medical language data</p><p id="viewer-b7v5j">
<a href="https://ablacon.com/" target="_blank" rel="noopener"><u>Ablacon</u></a></p><p id="viewer-ddcle">	TLDR: Developing technology to monitor in real-time what is going on inside someone's heart via the use of electrographic flows</p><p id="viewer-3a7fo"><a href="https://www.viz.ai/" target="_blank" rel="noopener"><u>Viz AI</u></a></p><p id="viewer-ah983">	TLDR: Uses images of CT scans to automatically detect stroke threats in patients and alert relevant health teams</p><p id="viewer-c2a8i"><a href="https://deep6.ai/" target="_blank" rel="noopener"><u>Deep 6</u></a></p><p id="viewer-5cmbl">	TLDR: Helps companies find appropriate candidates for patient trials by scanning and analyzing clinical records</p><h3 id="viewer-edo9j"><strong>Robotics</strong></h3><p id="viewer-131d7"><a href="https://www.neurala.com/" target="_blank" rel="noopener"><u>Neurala</u></a></p><p id="viewer-fijjq">	TLDR: Provides a framework for quicker tagging and training of AI models for industrial and robotics applications</p><p id="viewer-3rso5"><a href="https://www.bossanova.com/" target="_blank" rel="noopener"><u>Bossa Nova</u></a></p><p id="viewer-dpfac">	TLDR: Leverages technology such as drones, robots, and fixed cameras to help large-scale retailers automatically answer questions about item supplies and out-of-stock products</p><h3 id="viewer-artuk"><strong>Autonomous Vehicles</strong></h3><p id="viewer-4tu8s"><a href="https://www.aeye.ai/" target="_blank" rel="noopener"><u>AEye</u></a></p><p id="viewer-1pm34">	TLDR: Provides a 2D/3D perception platform for use in sensors of autonomous vehicles</p><p id="viewer-bocqg">
<a href="https://www.nauto.com/" target="_blank" rel="noopener"><u>Nauto</u></a></p><p id="viewer-3rbf3">	TLDR: Uses machine learning to power an in-vehicle device that helps reduce traffic accidents due to distracted driving</p><p id="viewer-drh26"><a href="https://www.pony.ai/en/tech.html" target="_blank" rel="noopener"><u>Pony AI</u></a></p><p id="viewer-5cstf">	TLDR: Develops autonomous vehicle technology including perception, planning and control, and HD mapping</p><h3 id="viewer-8qi25"><strong>Agriculture</strong></h3><p id="viewer-dv2ke"><a href="http://www.bluerivertechnology.com/" target="_blank" rel="noopener"><u>Blue River Technology</u></a></p><p id="viewer-dof1e">	TLDR: Using computer vision to build more efficient crop weed control and agricultural herbicide resistance</p><p id="viewer-9nj1a"><a href="http://www.taranis.ag/" target="_blank" rel="noopener"><u>Taranis</u></a></p><p id="viewer-7fr8v">	TLDR: Leverages computer vision to detect, analyze, and treat early signs of agricultural crop threats</p><h3 id="viewer-51j8o"><strong>Company Operations </strong></h3><p id="viewer-2h3ur"><a href="https://x.ai/" target="_blank" rel="noopener"><u>X.ai</u></a></p><p id="viewer-38u2r">	TLDR: AI-powered meeting and email scheduling</p><p id="viewer-ertfj"><a href="https://vidado.ai/" target="_blank" rel="noopener"><u>Vidado</u></a></p><p id="viewer-5v3g8">	TLDR: Builds sophisticated optical character recognition technology to extract insights from paper documents and forms</p><p id="viewer-9adh5"><a href="https://www.anodot.com/" target="_blank" rel="noopener"><u>Anodot</u></a></p><p id="viewer-6s69r">	TLDR: Real-time monitoring of analyze and correlate company data for tasks like revenue monitoring, customer monitoring, and digital partners monitoring.</p><p id="viewer-96tu8"><a href="https://www.behavox.com/" target="_blank" rel="noopener"><u>Behavox</u></a></p><p id="viewer-77fgm">	TLDR: An end-to-end data platform for deriving insights from internal data within an enterprise, focusing in particular on the financial sector</p><p id="viewer-dcvqi"><a href="https://textio.com/" target="_blank" rel="noopener"><u>TextIO</u></a></p><p id="viewer-6j91d">	TLDR: Provides a platform for helping companies write more targeted and effective hiring content such as job postings, tailored toward building more diverse and inclusive work environments</p><h3 id="viewer-ai0n0"><strong>DevOps and Security</strong></h3><p id="viewer-2kmj"><a href="https://sift.com/" target="_blank" rel="noopener"><u>Sift</u></a></p><p id="viewer-31pdt">	TLDR: Develops a suite of fraud detection APIs to help businesses ensure the digital trust and safety of their products</p><p id="viewer-2ggm0"><a href="https://onfido.com/" target="_blank" rel="noopener"><u>Onfido</u></a></p><p id="viewer-6vv1k">	TLDR: Uses machine learning to power various document and identify verification offerings</p><p id="viewer-fps3j"><a href="https://hunters.ai/" target="_blank" rel="noopener"><u>Hunters AI</u></a></p><p id="viewer-2vckh">	TLDR: Uses machine learning to detect cyberattacks that bypass existing security controls</p><p id="viewer-cuglb"><a href="https://www.crowdstrike.com/" target="_blank" rel="noopener"><u>Crowdstrike</u></a></p><p id="viewer-f7e3o">	TLDR: Utilizes machine learning to battle cybersecurity threats via endpoint detection of network threats</p><p id="viewer-130tg"><a href="https://www.bigpanda.io/" target="_blank" rel="noopener"><u>BigPanda</u></a></p><p id="viewer-ehne">	TLDR: Uses AI to improve infrastructure and devops at companies helping to improve monitoring tools and root cause analysis. </p><h3 id="viewer-e2r23"><strong>Education</strong></h3><p id="viewer-ek7qm">
<a href="https://www.cerego.com/" target="_blank" rel="noopener"><u>Cerego</u></a></p><p id="viewer-17p5t">	TLDR: An adaptive platform that uses machine learning to help improve the learning experience and techniques around remote education curricula</p><p id="viewer-df6hh">While 50 seems like a lot of companies, this only scratches the surface of all the groups out there tackling challenging problems with machine learning and data science and all the companies that will be formed in the future. If these companies deliver on their goals, artificial intelligence promises to be one of the biggest technological paradigm shifts in human history. The future looks bright!</p><p id="viewer-1q3n6">If you're interested in preparing for a job in machine learning or data science, get in touch! Confetti AI's mission is to help empower the next generation of artificial intelligence talent. </p></div></div></div></div></article></div></div>]]>
            </description>
            <link>https://www.confetti.ai/post/50-machine-learning-and-data-science-companies</link>
            <guid isPermaLink="false">hacker-news-small-sites-23659486</guid>
            <pubDate>Sat, 27 Jun 2020 04:20:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How much is your online privacy worth? – About $3.50 according to a new study]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23659315">thread link</a>) | @Oeck
<br/>
June 26, 2020 | https://www.oeck.com/o/how-much-is-your-online-privacy-worth-about-3-50-according-to-a-new-study-we%E2%80%99re-worth-far-more-than-that.57/ | <a href="https://web.archive.org/web/*/https://www.oeck.com/o/how-much-is-your-online-privacy-worth-about-3-50-according-to-a-new-study-we%E2%80%99re-worth-far-more-than-that.57/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

						
						
						

						<div data-lb-id="post-57" data-lb-caption-desc="Peter · Jun 20, 2020 at 1:58 AM">

							
								

	

							

							<article>
								
								<div><div title="1592614747501.png" data-xf-init="lightbox" data-lb-single-image="1" data-lb-container-zoom="1" data-lb-trigger=".js-lbImage-attachment129" data-lb-id="attachment129">
		
			
		
		<p><img src="https://www.oeck.com/attachments/1592614747501-png.129/" data-url="" data-zoom-target="1" alt="1592614747501.png">
	</p></div><p>
In an age where your personal data is being shared with far more companies than you can imagine, the folks at <a href="https://techpolicyinstitute.org/wp-content/uploads/2020/02/Prince_Wallsten_How-Much-is-Privacy-Worth-Around-the-World-and-Across-Platforms.pdf" target="_blank" data-proxy-href="/proxy.php?link=https%3A%2F%2Ftechpolicyinstitute.org%2Fwp-content%2Fuploads%2F2020%2F02%2FPrince_Wallsten_How-Much-is-Privacy-Worth-Around-the-World-and-Across-Platforms.pdf&amp;hash=493602e26ad60bf36acbdc1d6d52c624" rel="nofollow noopener">Tech Policy Institute</a> decided to take a poll. The general public was asked how much money they believe they should be paid by data amalgamators in exchange for their browsing habits, location history, etc. The answers from U.S. respondents ranged from caring almost not at all to just see ads, to demanding $10 for data collectors to see total bank account balances.</p><p>

Across all of the activities covered, Americans would only demand about $3.50/month on average to have each individual piece of personal data shared. A figure far too low when digital advertising revenue eclipsed $100 billion in 2019.</p><p>

As it stands now, the public is being paid $0 for all of the personal information which they choose to share, and for the information which they may not even know is being collected. That information is being used to build data profiles on an individual level which are then repackaged as “targeted advertisements” through ad networks. It’s why you can be searching for something on Google on your desktop and 6 hours later you see multiple ads on Facebook for the same thing for which you were searching on a different machine earlier.</p><p>

VPNs can help cut down on much of the data we unwittingly share, though you’re still going to end up sharing some information if you log into the same accounts across multiple networks or devices.</p><p>

Big Data has, unfortunately, creeped into our lives and is further entrenching itself as time goes on. What’s scary is that Americans, for the most part, do not seem to be concerned about it. Until legislation is passed limiting what can and cannot be collected, there isn’t a lot that can be done about data amalgamation on the macro level. On an individual level, taking care to opt-out of sharing whenever possible, using a VPN and limiting the number of apps on your phone can protect you to some degree.</p></div>
								
								
							</article>

							
								

	

							

							
								
	

							
						</div>

						

						
	

					</div></div>]]>
            </description>
            <link>https://www.oeck.com/o/how-much-is-your-online-privacy-worth-about-3-50-according-to-a-new-study-we%E2%80%99re-worth-far-more-than-that.57/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23659315</guid>
            <pubDate>Sat, 27 Jun 2020 03:29:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[NeXTSTEP on the HP 712 Part 2: Getting Software]]>
            </title>
            <description>
<![CDATA[
Score 106 | Comments 41 (<a href="https://news.ycombinator.com/item?id=23659277">thread link</a>) | @luu
<br/>
June 26, 2020 | https://blog.pizzabox.computer/posts/hp712-nextstep-part-2/ | <a href="https://web.archive.org/web/*/https://blog.pizzabox.computer/posts/hp712-nextstep-part-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
  
  <p><time datetime="2020-06-09T09:45:00-0400">Tue, Jun 9, 2020</time></p><p>In the <a href="https://blog.pizzabox.computer/posts/hp712-nextstep-part-1">last post of this series</a>, I set up NeXTstep on an HP PA-RISC <a href="https://blog.pizzabox.computer/pizzaboxes/hp712">workstation</a>. Today, I’m going to get down to business: configure networking, install system patches, outfit it with developer tools, and install some useful software!</p>
<p>As with the previous post, I’ve also made a YouTube video that covers roughly the same topics! If video is your speed, I’d love for you to check it out!</p>
<p>
  <iframe src="https://www.youtube.com/embed/_4hs4K7AEvQ" allowfullscreen="" title="YouTube Video"></iframe>
</p>

<!-- raw HTML omitted -->
<p>My goal is to end up with a capable machine that I can use like it might have been when new, and learn from the experience.</p>
<h2 id="foreshadowing-networking-woes">Foreshadowing networking woes</h2>
<p>While it is possible to transfer files from SCSI drives (or even floppies!), <strong>getting a pizzabox on my home network makes loading software much easier</strong>.
I first tried out NeXTstep on this workstation a couple years ago. The OS installed OK, but I ran in to trouble with networking. I was initially optimistic that I would figure it out:</p>
<blockquote><p lang="en" dir="ltr">I think I'm done for the day but soon if I can fight with NFS and NetInfo (lolololol) I can get screenshots off it and software on</p>— cron mom (@sophaskins) <a href="https://twitter.com/sophaskins/status/962427825608429568?ref_src=twsrc%5Etfw">February 10, 2018</a></blockquote>


<blockquote>
<p><strong>NARRATOR</strong>: she did not soon win the fight with NFS and NetInfo</p>
</blockquote>
<p>Hang on a second: NeXTstep is a workstation-focused Unix operating system from the 80s-90s - <strong>how could it be difficult to get it on a network</strong>? The answer is a thing called NetInfo.</p>
<p>In a surprise to exactly no one, NeXTstep, being from a company founded by Steve Jobs, had it’s own NeXT-only ecosystem of tools that fit together amazingly well. <strong>The cornerstone of NeXTstep networking was NetInfo</strong>. If you had a collection of NeXT computers on a network, NetInfo gave you a system to:</p>
<ul>
<li>manage user accounts that would work across all machines</li>
<li>configure file sharing</li>
<li>control permissions around access to network resources</li>
<li>assign IP addresses and hostnames</li>
<li>quickly bring new machines in to the network</li>
<li>serve this information in a highly-available manner</li>
</ul>
<p>which is to say: NetInfo is a “directory services” system. That’s all well and good - in the early 1990s that space had many competitors and a “right path” hadn’t yet been established, but…<strong>I don’t <em>want</em> my machine to be part of a directory</strong>, **I just want it to be on my existing TCP/IP network.</p>
<h2 id="starting-a-simple-network">Starting a “simple” network</h2>
<p>With that in mind, I (naively) attempted to use the “SimpleNetworkStarter” application.</p>


<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/simple-network-starter-1.png" alt="SimpleNetworkStarter">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/simple-network-starter-1.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>SimpleNetworkStarter</p>
      </figcaption>
  </figure>
</div>

<p>The SimpleNetworkStarter window has three “steps”:</p>
<ol>
<li>Select <strong>how we’ll integrate</strong> with an existing NetInfo network (since I don’t intend to interact with one at all, I have to choose “Provide the services specified below”, a sort of catch-all)</li>
<li>Specify <strong>my hostname and IP address</strong> - if I were connecting to an existing NetInfo network, I might not have to do this. “Network Options” lets me set more granular IP settings like netmask and gateway; “NetInfo Options” lets me choose how to integrate with existing domains (if relevant).</li>
<li>Setup <strong>network services</strong>: for my setup I don’t really want <em>any</em> of these things, but as a standalone NeXTstep system, I do have to “Maintain the master copy of network administrative data” (aka, the NetInfo database).</li>
</ol>



<div itemscope="" itemtype="http://schema.org/ImageGallery">
	  


<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/simple-network-starter-2.png" alt="Network Options">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/simple-network-starter-2.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>Network Options</p>
      </figcaption>
  </figure>
</div>



<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/simple-network-starter-3.png" alt="NetInfo Options">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/simple-network-starter-3.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>NetInfo Options</p>
      </figcaption>
  </figure>
</div>



<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/simple-network-starter-4.png" alt="Configuration Successful">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/simple-network-starter-4.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>Configuration Successful</p>
      </figcaption>
  </figure>
</div>


</div>

<p>So far, this feels like a really good start, but will it let me fetch files from an NFS share?</p>
<h2 id="networking-woes">Networking woes</h2>
<p>I immediately tried connecting to my NAS over NFS - after all, the main point of setting up networking was making it easier to transfer files. Unfortunately, it didn’t work - I could set up the NFS mount with NFSMananger (more on how to do that later), but the mountpoint would always be empty. Here you can see me attempting to reach it by IP address:</p>


<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/failing-nfs-mount.png" alt="a failing NFS mount">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/failing-nfs-mount.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>a failing NFS mount</p>
      </figcaption>
  </figure>
</div>

<p>So I had <em>some</em> sort of problem. To narrow down potential issues, I ran a few tests:</p>
<ul>
<li><strong>attempting to ping my NAS</strong> from the workstation - this turned out to not work because NeXTstep doesn’t seem to have any <code>ping</code> command. There are probably ways to accomplish something equivalent with the tools it <em>does</em> have, but I just moved on</li>
<li><strong>attempting to ping the workstation</strong> from elsewhere on my network. This worked - I was able to ping it from my laptop!</li>
<li><strong>attempting to connect to my NAS with FTP</strong> - one of the few network tools NeXTstep <em>does</em> seem to have is FTP, so I gave it a shot. To my surprise, this works!</li>
</ul>


<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/ftp-by-ip.png" alt="connecting to my NAS via FTP (successfully)">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/ftp-by-ip.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>connecting to my NAS via FTP (successfully)</p>
      </figcaption>
  </figure>
</div>

<p>It did not work via hostname, though, which points to at least some trouble with DNS. Taking a deeper look at the “NeXTstep 3.3 Network and
System Administration Manual” section on “<a href="http://www.nextcomputers.org/NeXTfiles/Docs/NeXTStep/3.3/nsa/11_MixedNet.htmld/index.html">NEXTSTEP Computers in a Mixed Network</a>” (which I probably should have done earlier) shows that <strong>I need to manually configure DNS</strong>. There’s no GUI options for it, you just have to write out an <code>/etc/resolv.conf</code>:</p>


<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/resolv-conf.png" alt="editing /etc/resolv.conf in vi">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/resolv-conf.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>editing /etc/resolv.conf in vi</p>
      </figcaption>
  </figure>
</div>

<p>After rebooting, I was able to access the NAS via FTP by hostname:


</p><div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/ftp-by-hostname.png" alt="connecting to my NAS via FTP (successfully) by hostname">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/ftp-by-hostname.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>connecting to my NAS via FTP (successfully) by hostname</p>
      </figcaption>
  </figure>
</div>

<p>But still couldn’t use NFS. What gives? I have network connectivity in both directions, and DNS is also now working! I believe this is as far as I got a few years ago, and man I was FRUSTRATED.</p>
<p>Eventually I thought to look in the system log (<code>/usr/adm/messages</code>) for hints:</p>


<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/dmesg.png" alt="an error from autonfsmount">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/dmesg.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>an error from autonfsmount</p>
      </figcaption>
  </figure>
</div>

<p>and there it was:</p>
<pre><code>autonfsmount: Can't get my address
</code></pre><p>Can’t get…<em>my</em> address? Doesn’t the computer know its own address? While I don’t know <em>why</em> it has to do this (googling has provided me a couple of <a href="https://rute.gerdesas.com/node31.html">quick asides</a> mentioning it, but not much detail), <strong>mounting an NFS server requires working <em>reverse</em> DNS for your IP</strong>.</p>
<p>I do have a real-ish DNS server for my home network, and it populates based on DHCP leases and IP reservations. This workstation, though, was just <strong>using an IP that I habitually hardcode for pizzaboxes (192.168.1.200)</strong>. I double-checked the DHCP server config, and it was indeed set up with a different host for that IP, and not set up at all for this hostname. I replaced that entry with one for <code>hp712</code> at <code>192.168.1.200</code> for the MAC address of my workstation, and crossed my fingers.</p>
<p>It worked! I could browse my NAS from the file-browser.</p>


<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/browse-nas.png" alt="browsing my NAS">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/browse-nas.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>browsing my NAS</p>
      </figcaption>
  </figure>
</div>

<h2 id="setting-up-an-nfs-mount">Setting up an NFS mount</h2>
<p>After all that rigamarole, the right way to configure a remote NFS mount goes through the NFSManager.app. While NFSManager lets you configure both “exports” (local directories I share with others) and “imports” (remote directories I want to mount locally).</p>


<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/empty-imports.png" alt="an empty list of nfs imports">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/empty-imports.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>an empty list of nfs imports</p>
      </figcaption>
  </figure>
</div>

<p>All I have to is click “Add” and fill in the details for my NAS:</p>


<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/new-import.png" alt="adding a new nfs import">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/new-import.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>adding a new nfs import</p>
      </figcaption>
  </figure>
</div>

<p>That’s it? A lot of struggle got me to this point, but <em>finally</em> I can transfer files.</p>
<h2 id="patch-tuesday">Patch Tuesday</h2>
<p>The first order of business is to <strong>run system updates</strong>. NeXTstep 3.3 was released in mid-1995, and it had three patch updates: the <a href="https://www.nextop.de/NeXTAnswers/2066.html">first</a> at the end of 1995, and the second and <a href="http://www.nextcomputers.org/NeXTfiles/Software/NEXTSTEP/Patches/NEXTSTEP_3.3_User_Patch_3/nextstep3.3_patch_3_overview.pdf">third</a> in late 1999. Since NeXT were acquired by Apple in 1997, this patch was made by Apple to address Y2k bugs and other longstanding issues. Thanks, Apple! <a href="https://youtu.be/gaI6kBVyu00?t=28"><em>Thapple</em></a>.</p>
<p>The third patch is a cumulative update, so that should be all I need. Nextcomputers.org generously <a href="http://www.nextcomputers.org/NeXTfiles/Software/NEXTSTEP/Patches/NEXTSTEP_3.3_User_Patch_3/">hosts</a> the patch for download. Because I’m using an HP PA-RISC machine, I need <code>NS33RISCUserPatch3.tar</code>. System updates need to be installed as the <code>root</code> user, and if you run them as <code>me</code> (the default user) NeXTstep doesn’t prompt to escalate privilges, it just gives an error. Thus, I need to log in as <code>root</code> directly. In order to do that, I need to give the <code>me</code> user a password so the system will stop automatically logging in at boot (giving me a chance to log in as <code>root</code>). To set a password, you go to Preferences.app and navigate to the lock icon.</p>



<div itemscope="" itemtype="http://schema.org/ImageGallery">
	  


<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/password-before.png" alt="no password!">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/password-before.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>no password!</p>
      </figcaption>
  </figure>
</div>



<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/password-set.png" alt="password set">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/password-set.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>password set</p>
      </figcaption>
  </figure>
</div>



<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/password-secure.png" alt="password secure">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/password-secure.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>password secure</p>
      </figcaption>
  </figure>
</div>


</div>

<p>After the next reboot, I then get the login screen (instead of automatically going to the desktop):</p>


<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/login-screen.png" alt="nextstep 3.3 login screen">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/login-screen.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>nextstep 3.3 login screen</p>
      </figcaption>
  </figure>
</div>

<p>By default, the <code>root</code> password is blank (you can of course fix this after login in the same way as setting a password for the <code>me</code> account). I navigated to where I had put the patch tarball on my NAS, copied it to the HP 712, and unarchived it.</p>



<div itemscope="" itemtype="http://schema.org/ImageGallery">
	  


<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/os-update-copy.png" alt="copying from NAS">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/os-update-copy.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>copying from NAS</p>
      </figcaption>
  </figure>
</div>



<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/os-update-untar.png" alt="untarring">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/os-update-untar.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>untarring</p>
      </figcaption>
  </figure>
</div>



<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/os-update-pkg.png" alt="the patch package">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/os-update-pkg.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>the patch package</p>
      </figcaption>
  </figure>
</div>


</div>

<p>Double-clicking the package brings up a familiar-feeling Installer.app</p>


<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/os-update-installer.png" alt="installer.app for OS update">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/os-update-installer.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>installer.app for OS update</p>
      </figcaption>
  </figure>
</div>

<p>Clicking “Install” prompts me to make sure I’m choosing the right architecture (in my case, PA-RISC), runs a program to determine compatibility, and runs the update.</p>



<div itemscope="" itemtype="http://schema.org/ImageGallery">
	  


<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/os-update-arch.png" alt="choose system arch">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/os-update-arch.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>choose system arch</p>
      </figcaption>
  </figure>
</div>



<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/os-update-install.png" alt="installation in progress">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/os-update-install.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>installation in progress</p>
      </figcaption>
  </figure>
</div>



<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/os-update-complete.png" alt="installation complete">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/os-update-complete.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>installation complete</p>
      </figcaption>
  </figure>
</div>


</div>

<p>After a reboot, I’m on the most recent version of NeXTstep for PA-RISC, and ready for the year 2000!</p>

<p>What’s next for making a usable system? Developer tools! <strong>NeXTstep came on two sets of discs - “User” for the main operating system, and the optional “Developer” disc</strong> with compilers, GUI building tools, libraries, and documentation. While there were separate versions of NeXTstep User for CISC (m68k and i386) and RISC (PA-RISC and SPARC) platforms, the Developer disc is “quad-fat” - it contains binaries for all four platforms. I …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.pizzabox.computer/posts/hp712-nextstep-part-2/">https://blog.pizzabox.computer/posts/hp712-nextstep-part-2/</a></em></p>]]>
            </description>
            <link>https://blog.pizzabox.computer/posts/hp712-nextstep-part-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23659277</guid>
            <pubDate>Sat, 27 Jun 2020 03:22:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Schmidhuber: Critique of 2018 Turing Award for Drs. Bengio and Hinton and LeCun]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23659246">thread link</a>) | @tdhttt
<br/>
June 26, 2020 | http://people.idsia.ch/~juergen/critique-turing-award-bengio-hinton-lecun.html | <a href="https://web.archive.org/web/*/http://people.idsia.ch/~juergen/critique-turing-award-bengio-hinton-lecun.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div face="arial">
<center>
.
<div>
<a href="http://people.idsia.ch/~juergen/critique-turing-award-bengio-hinton-lecun.html"><img src="http://people.idsia.ch/~juergen/critique-turing754x288.png" alt="Critique of 2018 Turing Award for Bengio &amp; Hinton &amp; LeCun"></a>

<center>



<span size="4">
</span></center><span size="4">

<a name="abstract">
<hr>
</a><p><a name="abstract">
<b>Abstract.</b> ACM's 2018 A.M. Turing Award was about
<em>deep learning</em> in artificial neural networks.
ACM lauds the awardees for work based on algorithms
and conceptual foundations first published by other researchers 
whom the awardees failed to cite
(see </a><a href="#exec">Executive Summary</a>
and Sec. 
<a href="#I">I</a>,
<a href="#V">V</a>, 
<a href="#II">II</a>,
<a href="#XII">XII</a>,
<a href="#XIX">XIX</a>, 
<a href="#XXI">XXI</a>,
<a href="#XIII">XIII</a>, 
<a href="#XIV">XIV</a>,  
<a href="#XX">XX</a>, 
<a href="#XVII">XVII</a>).
ACM explicitly mentions "astonishing" deep learning breakthroughs in 4 fields:
<a href="#A"> (A) speech recognition</a>, 
<a href="#B">(B) natural language processing</a>, 
<a href="#C">(C) robotics</a>, 
<a href="#D">(D) computer vision</a>,
as well as "powerful" new deep learning tools in 3 fields: 
<a href="#VII">(VII) medicine, astronomy, materials science</a>.
Most of these breakthroughs and tools, however, were directly based on 
the results of my own labs in the past 3 decades 
 (e.g., Sec.  
<a href="#A">A</a>,
<a href="#B">B</a>,
<a href="#C">C</a>,
<a href="#D">D</a>,
<a href="#VII">VII</a>,
<a href="#XVII">XVII</a>,
<a href="#VI">VI</a>,
<a href="#XVI">XVI</a>). 
I correct ACM's distortions of deep learning history (e.g., Sec. 
<a href="#II">II</a>,  
<a href="#V">V</a>, 
<a href="#XX">XX</a>,
<a href="#XVIII">XVIII</a>) 
and also 
mention 8 of our direct priority disputes 
with Bengio &amp; Hinton (Sec.  <a href="#XVII">XVII</a>, <a href="#I">I</a>).


</p><hr>

<p>
<em>This document (~11,000 words)
reuses and expands some of the material in my <a href="http://people.idsia.ch/~juergen/critique-honda-prize-hinton.html">Critique of the 2019 Honda Prize</a> <a href="#HIN">[HIN]</a> (~3,000 words). 
It has several layers of hierarchical abstraction: 
<b><a href="#abstract">Abstract</a></b> (150 words), <b><a href="#exec">Executive Summary with links to details</a></b> (~1,000 words), <b><a href="#I">Body with 21 comments on 21 claims by ACM</a></b> (~7,700 words) and <b><a href="#conclusion">Conclusion</a></b> (~1,700 words). 
All backed up by  <a href="#References">over 200 references</a> (~6,500 words).
</em>

</p><hr>


<p>We must stop crediting the wrong people for inventions made by others.
Instead let's heed the recent call in the journal <em>Nature</em>:
<b>"Let 2020 be the year in which we value those who ensure that 
science is self-correcting"</b> <a href="#SV20">[SV20]</a>.
Like those who know me can testify, finding and citing original sources of scientific and technological innovations is important to me, whether they are mine or other people's <a href="#DL1">[DL1]</a> <a href="#DL2">[DL2]</a> <a href="#HIN">[HIN]</a> <a href="#NASC1">[NASC1-9]</a>. The present page is offered as a resource for computer scientists who share this inclination. 
By grounding research in its true intellectual foundations and crediting the original inventors, 
I am not diminishing important contributions made by popularizers of those inventions. 
My goal is to encourage the entire community to be more scholarly in its efforts, to recognize the foundational work that sometimes gets lost in the frenzy of modern AI and machine learning,
and to fight plagiarism in all of its more or less subtle forms. 
I am also inviting others to contribute additional relevant 
references (send them to <em>juergen@idsia.ch</em>). 



</p><p> I will focus on 
contributions praised by
ACM's official justification <a href="#T19">[T19]</a> of the 
2018 A.M. Turing Award for Drs. Bengio &amp; Hinton &amp; LeCun  <a href="#R1">[R1]</a> 
 published in 2019.
After the <a href="#exec">Executive Summary</a>,
ACM's full text <a href="#T19">[T19]</a> is split into 21 parts  
labeled by "<b>ACM:</b>" 
<a href="#I">I</a>, 
<a href="#II">II</a>, 
<a href="#III">III</a>, 
<a href="#IV">IV</a>,
<a href="#V">V</a>,
<a href="#VI">VI</a>,
<a href="#VII">VII</a>,
<a href="#VIII">VIII</a>,
<a href="#IX">IX</a>,
<a href="#X">X</a>,
<a href="#XI">XI</a>,
<a href="#XII">XII</a>,
<a href="#XIII">XIII</a>,
<a href="#XIV">XIV</a>,
<a href="#XV">XV</a>,
<a href="#XVI">XVI</a>,
<a href="#XVII">XVII</a>,
<a href="#XVIII">XVIII</a>,
<a href="#XIX">XIX</a>,
<a href="#XX">XX</a>,
<a href="#XXI">XXI</a>.
Each part is followed by a critical "<b>Comment</b>." 
Most of the comments are based on references to original papers and other material from
 recent 
blog posts <a href="#MIR">[MIR]</a> <a href="#DEC">[DEC]</a>  <a href="#HIN">[HIN]</a>.
<b>I'll point out 
that  highly cited publications of the awardees ignored fundamental 
relevant prior work—this may be the reason for some of  ACM's misattributions.</b>
Since ACM's text is a bit repetitive and redundant, so are the partially overlapping
sections of  my critique. 



</p><h2><a name="exec">
<hr>
Executive Summary (~1000 words, with links to details)
<hr>
</a></h2><a name="exec">

</a><p><a name="exec">
While Drs. LeCun &amp; Bengio &amp; Hinton (<b>LBH for short</b>)  
have made  useful improvements of algorithms for 
artificial neural networks (<b>NNs</b>) 
and deep learning (e.g., </a><a href="#I">Sec.  I</a>), ACM lauds
them for more visible 
work based on fundamental methods whose inventors they did not cite,
not even in later surveys
(this may actually explain some of  ACM's misattributions). I correct ACM's distortions of deep learning history.
Numerous <a href="#References">references</a> can be found under the relevant section links I-XXI 
which adhere to the sequential order of ACM's text <a href="#T19">[T19]</a>
(while this summary groups related sections together).


</p><p>
<b>Sec. <a href="#II">II</a>:</b> 
In contrast to ACM's claims, 
NNs for pattern recognition etc. were introduced long before the 1980s. 
 <b>Deep learning with multilayer perceptrons started in 1965</b> through Ivakhnenko &amp; Lapa
long before LBH who have never cited them, not even in recent work.
<b>In the 1980s,</b> "modern" gradient-based learning 
worked only for rather shallow NNs,
<b>but it became really deep in 1991 in my lab,</b>
first through 
<a href="http://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html#Sec.%201">unsupervised pre-training of NNs</a>, 
then through 
<a href="http://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html#Sec.%204">supervised LSTM</a>.
<b>Sec.  <a href="#I">I</a></b> contains 4 subsections 
<b><a href="#A">A</a>, <a href="#B">B</a>, <a href="#C">C</a>, <a href="#D">D</a></b>
on <b>the  4 deep learning "breakthroughs" explicitly 
mentioned by ACM</b>. ACM does not mention that they were 
mostly based on deep learning techniques of my team:

</p><p>
<b>Sec.
<a href="#A">A: Speech Recognition</a></b> (see also <a href="#VI">VI</a> &amp; <a href="#XI">XI</a> &amp; <a href="#XV">XV</a>): The first superior end-to-end neural speech recognition 
combines two methods from my lab: <a href="http://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html#Sec.%204">LSTM</a> (1990s-2005) and CTC (2006), applied to speech in 2007. 
Hinton (2012) and Bengio (<a href="#XV">XV</a>)
still used an old hybrid approach of the 1980s and 90s;
Hinton et al. (2012) did not compare it to 
our revolutionary CTC-LSTM (<a href="http://people.idsia.ch/~juergen/impact-on-most-valuable-companies.html">which was soon on most smartphones</a>).

</p><p>
<b>Sec. <a href="#B">B: Natural Language Processing</a></b> (see also  <a href="#VI">VI</a> &amp; <a href="#XI">XI</a> &amp;  <a href="#XVI">XVI</a>): 
The first superior end-to-end neural machine translation  
(<a href="http://people.idsia.ch/~juergen/impact-on-most-valuable-companies.html">soon used for several billions of
translations each day by the big platform companies</a>)
was also based on our <a href="http://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html#Sec.%204">LSTM</a>.

</p><p>
<b>Sec. <a href="#C">C: Robotics</a></b>.
Our LSTM trained by <b>Reinforcement Learning</b> (RL) was also the core of the 
most visible breakthroughs in robotics and video games.

</p><p>
<b>Sec. <a href="#D">D: Computer Vision</a></b>
(see also   
<a href="#XVIII">XVIII</a> &amp; <a href="#XIV">XIV</a>  &amp; <a href="#XI">XI</a>  &amp;  <a href="#VI">VI</a>)
was revolutionized by <b>convolutional NNs</b> (CNNs).
The basic CNN architecture is due to Fukushima (1979). 
NNs with convolutions were later (1987) combined by Waibel with backpropagation and weight sharing, 
and applied to speech. <b>All before</b> LeCun's CNN work  (<a href="#XVIII">XVIII</a>).
We showed twice (1991-95 and 2006-10) that 
<a href="http://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html#Sec.%2019">deep NNs 
don't need unsupervised 
pre-training</a> (in contrast to Hinton's claims). Our team (Ciresan et al.)  
made CNNs fast &amp; deep enough for  
<a href="http://people.idsia.ch/~juergen/computer-vision-contests-won-by-gpu-cnns.html">superior computer vision  in 2011</a>,
<b>winning 4 image recognition contests in a row
before Hinton's team won one</b>. ResNet (ImageNet 2015 winner)
is a special case of our earlier <a href="http://people.idsia.ch/~juergen/highway-networks.html">Highway Nets</a>.

</p><p>
<b>Sec.  <a href="#XIV">XIV:</a></b>
Again ACM recognizes work that failed to cite the pioneers.
Long before Hinton (2012), Hanson (1990) had a variant of <b>dropout</b>, 
and v. d. Malsburg (1973) had <b>rectified linear neurons</b>; Hinton did not cite them.
Already in 2011,
our deep &amp; fast CNN  more than <b>"halved the error rate for object recognition"</b> (ACM's wording) 
in a computer vision contest 
(<a href="http://people.idsia.ch/~juergen/superhumanpatternrecognition.html">where LeCun participated</a>), 
long before Hinton's similar CNN (2012). 
<b>Sec. <a href="#XI">XI</a>:</b>  ACM mentions GPU-accelerated NNs  
pioneered by Jung &amp; Oh (2004). LBH
did not cite them.
Our deep GPU-NN of 2010 debunked <a href="http://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html#Sec.%2019">unsupervised pre-training (introduced by myself in 1991 and later championed by Hinton)</a>, 
and our GPU-CNN of 2011 was the first  
to win contests in <b>computer 
vision</b> (explicitly mentioned by ACM).
 

</p><p>
<b>Sec.  
<a href="#XVIII">XVIII</a></b>:
ACM credits LeCun for developing CNNs. However, the foundations of CNNs were laid earlier by 
Fukushima and Waibel  (Sec. <a href="#D">D</a>).
 ACM also explicitly mentions <b>autonomous driving</b> and <b>medical image analysis</b>.
The first team to win relevant international contests in these fields 
through deep CNNs was ours (2011, 2012, 2013).
<b>Sec.  
<a href="#VII">VII</a>:</b> ACM explicitly mentions  <b>medicine</b> and
 <b>materials science</b>. Our deep NNs were the 
<a href="http://people.idsia.ch/~juergen/first-time-deep-learning-won-medical-imaging-contest-september-2012.html">first to win medical imaging competitions</a>
 in 2012 and 2013, and the first to apply deep NNs to material defect detection in industry (since 2010).


</p><p>
<b>Sec. <a href="#XII">XII</a> &amp; <a href="#XIX">XIX</a> &amp; <a href="#XXI">XXI</a>:</b> Modern 
<a href="http://people.idsia.ch/~juergen/who-invented-backpropagation.html">backpropagation</a>
was first published by Linnainmaa (1970), 
not by LeCun or Hinton or their collaborators (1985) who did not cite Linnainmaa, 
not even in later surveys. 
<b>Sec. 
<a href="#XIII">XIII</a>  &amp; 
<a href="#II">II</a> &amp; 
<a href="#V">V</a> 
</b>
(&amp; 
<a href="#III">III</a> &amp; 
<a href="#IX">IX</a> &amp;
<a href="#X">X</a> &amp;
<a href="#XX">XX</a>):
Ivakhnenko's deep feedforward nets (since 1965) <b>learned 
internal representations</b> long before Hinton's shallower ones (1980s).
Hinton has never cited him.
<b>Sec. <a href="#XX">XX</a>:</b> ACM credits LeCun for work on
<b>hierarchical feature representation</b> which did not cite Ivakhnenko's much earlier work
on this (since 1965).
<b>Sec. <a href="#XXI">XXI</a>:</b> ACM credits LeCun for work on
<b>automatic differentiation</b> which did not cite its inventor Linnainmaa (1970). 
And also for work on
<b>deep learning for graphs</b> that failed to cite 
the earlier work  by Sperduti &amp; Goller &amp; Küchler &amp; Pollack.



</p><p>
<b>Sec. 
<a href="#XV">XV</a>:</b> ACM credits Bengio for hybrids of NNs and  probabilistic models of sequences. 
His work
was not the first on this topic, and is 
not important for <b>modern deep learning speech recognition systems</b> (mentioned by ACM) based on our CTC-LSTM
 (Sec.  
<a href="#A">A</a> &amp; 
<a href="#B">B</a>).
<b>Sec.
<a href="#XVI">XVI</a>:</b> ACM 
credits Bengio for neural probabilistic language models.
Our 1995 neural probabilistic text model greatly predates Bengio's.
ACM mentions NNs that learn
 sequential <b>attention</b>. <a href="http://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html#Sec.%209">We started this in 1990-93 long before LBH</a> who did not cite this.




</p><p>
<b>Sec.  <a href="#XVII">XVII</a>:</b>
ACM mentions
<b>Generative Adversarial Networks</b> (GANs, 2010-14) of Bengio's team, a special case of
my  Adversarial  
<a href="http://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html#Sec.%205"><b>Artificial Curiosity</b></a>
(1990) which he did not cite. 
I list 7 of 
our <b>additional priority disputes</b> with Bengio &amp; Hinton (more than can be explained by chance),  
on 
<a href="http://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html#Sec.%203">vanishing gradients</a> (1991),
<a href="http://people.idsia.ch/~juergen/metalearner.html">meta-learning</a> (1987),
 <a href="http://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html#Sec.%201">unsupervised pre-training</a> (1991),
<a href="http://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html#Sec.%202">compressing or distilling one NN into another</a> (1991), 
<a href="http://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html#Sec.%208">fast weights  
through outer products</a> (1993), 
<a href="http://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html#Sec.%209">learning sequential attention with NNs</a> (1990),
and other topics <a href="#R2">[R2-R6]</a>.








</p><p>
<b>Sec. <a href="#IV">IV</a></b> is on <a href="http://people.idsia.ch/~juergen/turing.html">Turing</a> (1936) and his predecessors
<a href="http://people.idsia.ch/~juergen/goedel.html">Gödel</a> (1931) and Church (1935).

</p><p>
<b>Sec. <a href="#conclusion">Conclusion:</a></b>
 In the recent <a href="http://people.idsia.ch/~juergen/2010s-our-decade-of-deep-learning.html">decade of deep learning</a>,
most major AI applications mentioned by ACM 
<a href="http://people.idsia.ch/~juergen/impact-on-most-valuable-companies.html">(speech recognition, language translation, etc.) on billions of devices</a>  (also healthcare applications)
heavily depended on our deep learning techniques and conceptual foundations,
while LBH's most visible work ignored
 essential prior art since the 1960s—see, e.g., 
Sec. <a href="#II">II</a> &amp;  
<a href="#III">III</a> &amp; 
<a href="#V">V</a> &amp;
<a href="#XII">XII</a> &amp; 
<a href="#XIII">XIII</a> &amp; 
<a href="#XVII">XVII</a> &amp; 
<a href="#XIV">XIV</a> &amp; 
<a href="#XIX">XIX</a> &amp; 
<a href="#XX">XX</a> &amp; 
<a href="#XXI">XXI</a>, 
<a href="#DL1">[DL1]</a> <a href="#DL2">[DL2]</a> <a href="#DLC">[DLC]</a> <a href="#MIR">[MIR]</a> <a href="#HIN">[HIN]</a> <a href="#R4">[R2-R8]</a>.
But in science, by definition, the facts will always win in …</p></span></div></center></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://people.idsia.ch/~juergen/critique-turing-award-bengio-hinton-lecun.html">http://people.idsia.ch/~juergen/critique-turing-award-bengio-hinton-lecun.html</a></em></p>]]>
            </description>
            <link>http://people.idsia.ch/~juergen/critique-turing-award-bengio-hinton-lecun.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23659246</guid>
            <pubDate>Sat, 27 Jun 2020 03:17:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Examining ARM vs. x86 Memory Models with Rust]]>
            </title>
            <description>
<![CDATA[
Score 237 | Comments 65 (<a href="https://news.ycombinator.com/item?id=23659037">thread link</a>) | @redbluemonkey
<br/>
June 26, 2020 | https://www.nickwilcox.com/blog/arm_vs_x86_memory_model/ | <a href="https://web.archive.org/web/*/https://www.nickwilcox.com/blog/arm_vs_x86_memory_model/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="text">
        
        <p>With Apple’s recent announcement that they are moving away from Intel X86 CPU’s to their own ARM CPU’s for future laptops and desktops I thought it would be a good time to take a look at the some differences that can affect systems programmers working in Rust.</p>

<p>One of the key areas where ARM CPU’s differ from X86 is their memory model. This article will take a look at what a memory model is and how it can cause code to be correct on one CPU but cause race conditions on another.</p>

<h2 id="memory-models">Memory Models</h2>

<p>The way loads and stores to memory interact between multiple threads on a specific CPU is called that architecture’s Memory Model.</p>

<p>Depending on the memory model of the CPU, multiple writes by one thread may become visible to another thread in a different order to the one they were issued in.</p>

<p>The same is true of a thread issuing multiple reads. A thread issuing multiple reads may receive “snapshots” of global state that represent points in time ordered differently to the order of issue.</p>

<p>Modern hardware needs this flexibility to be able to maximize the throughput of memory operations. While CPU clock rates and core counts have been increasing with each new CPU iteration, memory bandwidth has struggled to keep up. Moving data from memory to operate on is often the bottle neck in the performance of applications.</p>

<p>If you’ve never written multi-threaded code, or only done so using higher level synchronization primitives such as <code>std::sync::Mutex</code>, you’ve probably never been exposed to the details of the memory model. This is because the CPU, despite whatever reordering it’s memory model allows it to perform, always presents a consistent view of memory to the current thread.</p>

<p>If we look at the below snippet of code that writes to memory and then reads the same memory straight back, we will always get the expected value of <code>58</code> back when we read. There is never the case that we’d read some stale value from memory.</p>

<div><div><pre><code><span>pub</span> <span>unsafe</span> <span>fn</span> <span>read_after_write</span><span>(</span><span>u32_ptr</span><span>:</span> <span>*</span><span>mut</span> <span>u32</span><span>)</span> <span>{</span>
    <span>u32_ptr</span><span>.write_volatile</span><span>(</span><span>58</span><span>);</span>
    <span>let</span> <span>u32_value</span> <span>=</span> <span>u32_ptr</span><span>.read_volatile</span><span>();</span>
    <span>println!</span><span>(</span><span>"the value is {}"</span><span>,</span> <span>u32_value</span><span>);</span>
<span>}</span>
</code></pre></div></div>
<p><em>I’m using volatile operations because if I used normal pointer operations the compiler is smart enough to skip the memory read and just prints the value <code>58</code>. 
Volatile operations stop the compiler from reordering or skipping our memory operation. However they have no affect on hardware (or the compiler re-ordering relative to non-volatile memory operations).</em></p>

<p>Once we introduce multiple threads, we’re now exposed to the fact that the CPU may be reordering our memory operations.</p>

<p>We can examine the snippet below in a multi-threaded context:</p>

<div><div><pre><code><span>pub</span> <span>unsafe</span> <span>fn</span> <span>writer</span><span>(</span><span>u32_ptr_1</span><span>:</span> <span>*</span><span>mut</span> <span>u32</span><span>,</span> <span>u32_ptr_2</span><span>:</span> <span>*</span><span>mut</span> <span>u32</span><span>)</span> <span>{</span>
    <span>u32_ptr_1</span><span>.write_volatile</span><span>(</span><span>58</span><span>);</span>
    <span>u32_ptr_2</span><span>.write_volatile</span><span>(</span><span>42</span><span>);</span>
<span>}</span>

<span>pub</span> <span>unsafe</span> <span>fn</span> <span>reader</span><span>(</span><span>u32_ptr_1</span><span>:</span> <span>*</span><span>mut</span> <span>u32</span><span>,</span> <span>u32_ptr_2</span><span>:</span> <span>*</span><span>mut</span> <span>u32</span><span>)</span> <span>-&gt;</span> <span>(</span><span>u32</span><span>,</span> <span>u32</span><span>)</span> <span>{</span>
    <span>(</span><span>u32_ptr_1</span><span>.read_volatile</span><span>(),</span> <span>u32_ptr_2</span><span>.read_volatile</span><span>())</span>
<span>}</span>
</code></pre></div></div>

<p>If we initialize the contents of both pointers to <code>0</code>, and then run each function in a different thread, we can list the possible outcomes for the reader. We know that there is no synchronization, but based on our experience with single threaded code we think the possible return values are <code>(0, 0)</code>, <code>(58, 0)</code> or <code>(58, 42)</code>. But the possibility of hardware reordering of memory writes affecting multi-threads means that there is a fourth option <code>(0, 42)</code>.</p>

<p>You might think there are more possibilities due to the lack of synchronization. But all hardware memory models guarantee that aligned loads and store up to the native word size are atomic (u32 or a 32-bit CPU, u64 on a 64-bit CPU). If we changed one of our writes to <code>0xFFFF_FFFF</code>, the read will only ever see the old value or the new value. It will never see a partial value like <code>0xFFFF_0000</code>.</p>

<p>If the details of the CPU’s memory model are hidden away when using regular memory accesses, it seems like we would have no way to control it in multi-threaded programs where it affects program correctness.</p>

<p>Luckily Rust provides as with the <code>std::sync::atomic</code> module containing types that gives us the control we need. We use these types to specify exactly the memory ordering requirements our code needs. We trade performance for correctness. We place restrictions on what order the hardware can perform memory operations, taking away any bandwidth optimizations the hardware would want to perform.</p>

<p>When working with the <code>atomic</code> module, we don’t worry about the actual memory models of individual CPU architectures. Instead the operation of the <code>atomic</code> module works on an abstract memory model that’s CPU agnostic. Once we’ve expressed our requirements on the loads and stores using this Rust memory model, the compiler does the job of mapping to the memory model of the target CPU.</p>

<p>The requirements we specify on each operation takes the form of what reordering we want to allow (or deny) on the operation. The orderings form a hierarchy, with each level placing more restrictions the CPU. For example <code>Ordering::Relaxed</code> means the CPU is free to perform any reordering it wants. <code>Ordering::Release</code> means that a store can only complete after all proceeding stores have finished.</p>

<p>Let’s look at how atomic memory writes are actually compiled, compared to a regular write.</p>

<div><div><pre><code><span>use</span> <span>std</span><span>::</span><span>sync</span><span>::</span><span>atomic</span><span>::</span><span>*</span><span>;</span>

<span>pub</span> <span>unsafe</span> <span>fn</span> <span>test_write</span><span>(</span><span>shared_ptr</span><span>:</span> <span>*</span><span>mut</span> <span>u32</span><span>)</span> <span>{</span>
    <span>*</span><span>shared_ptr</span> <span>=</span> <span>58</span><span>;</span>
<span>}</span>

<span>pub</span> <span>unsafe</span> <span>fn</span> <span>test_atomic_relaxed</span><span>(</span><span>shared_ptr</span><span>:</span> <span>&amp;</span><span>AtomicU32</span><span>)</span> <span>{</span>
    <span>shared_ptr</span><span>.store</span><span>(</span><span>58</span><span>,</span> <span>Ordering</span><span>::</span><span>Relaxed</span><span>);</span>
<span>}</span>

<span>pub</span> <span>unsafe</span> <span>fn</span> <span>test_atomic_release</span><span>(</span><span>shared_ptr</span><span>:</span> <span>&amp;</span><span>AtomicU32</span><span>)</span> <span>{</span>
    <span>shared_ptr</span><span>.store</span><span>(</span><span>58</span><span>,</span> <span>Ordering</span><span>::</span><span>Release</span><span>);</span>
<span>}</span>

<span>pub</span> <span>unsafe</span> <span>fn</span> <span>test_atomic_consistent</span><span>(</span><span>shared_ptr</span><span>:</span> <span>&amp;</span><span>AtomicU32</span><span>)</span> <span>{</span>
    <span>shared_ptr</span><span>.store</span><span>(</span><span>58</span><span>,</span> <span>Ordering</span><span>::</span><span>SeqCst</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>If we look at the <a href="https://godbolt.org/z/uVQM8T">X86 assembly</a> for the above code, we see the first three functions produce identical code. It’s not until the stricter <code>SeqCst</code> ordering that we get a different instruction being produced.</p>

<div><div><pre><code><span>example:</span><span>:</span><span>test_write:</span>
        <span>mov</span>     <span>dword</span> <span>ptr</span> <span>[</span><span>rdi</span><span>],</span> <span>58</span>
        <span>ret</span>

<span>example:</span><span>:</span><span>test_atomic_relaxed:</span>
        <span>mov</span>     <span>dword</span> <span>ptr</span> <span>[</span><span>rdi</span><span>],</span> <span>58</span>
        <span>ret</span>

<span>example:</span><span>:</span><span>test_atomic_release:</span>
        <span>mov</span>     <span>dword</span> <span>ptr</span> <span>[</span><span>rdi</span><span>],</span> <span>58</span>
        <span>ret</span>
        
<span>example:</span><span>:</span><span>test_atomic_consistent:</span>
        <span>mov</span>     <span>eax</span><span>,</span> <span>58</span>
        <span>xchg</span>    <span>dword</span> <span>ptr</span> <span>[</span><span>rdi</span><span>],</span> <span>eax</span>
        <span>ret</span>
</code></pre></div></div>
<p>The first two orderings use the <strong><code>MOV</code></strong> (<strong>MOV</strong>e) instruction to write the value to memory. Only the strictest ordering produces a different instruction, <strong><code>XCHG</code></strong> (atomic e<strong>XCH</strong>an<strong>G</strong>), to a raw pointer write.</p>

<p>We can compare that to the <a href="https://godbolt.org/z/wWQo8P">ARM assembly</a>.</p>

<div><div><pre><code><span>example:</span><span>:</span><span>test_write:</span>
        <span>mov</span>     <span>w8</span><span>,</span> <span>#</span><span>58</span>
        <span>str</span>     <span>w8</span><span>,</span> <span>[</span><span>x0</span><span>]</span>
        <span>ret</span>

<span>example:</span><span>:</span><span>test_atomic_relaxed:</span>
        <span>mov</span>     <span>w8</span><span>,</span> <span>#</span><span>58</span>
        <span>str</span>     <span>w8</span><span>,</span> <span>[</span><span>x0</span><span>]</span>
        <span>ret</span>

<span>example:</span><span>:</span><span>test_atomic_release:</span>
        <span>mov</span>     <span>w8</span><span>,</span> <span>#</span><span>58</span>
        <span>stlr</span>    <span>w8</span><span>,</span> <span>[</span><span>x0</span><span>]</span>
        <span>ret</span>
        
<span>example:</span><span>:</span><span>test_atomic_consistent:</span>
        <span>mov</span>     <span>w8</span><span>,</span> <span>#</span><span>58</span>
        <span>stlr</span>    <span>w8</span><span>,</span> <span>[</span><span>x0</span><span>]</span>
        <span>ret</span>
</code></pre></div></div>

<p>In contrast we can see there is a difference once we hit the release ordering requirement. The raw pointer and relaxed atomic store use <strong><code>STR</code></strong> (<strong>ST</strong>ore <strong>R</strong>egister) while the release and sequential ordering uses the instruction <strong><code>STLR</code></strong> (<strong>ST</strong>ore with re<strong>L</strong>ease <strong>R</strong>egister). <em>The <strong><code>MOV</code></strong> instruction in this disassembly is moving the constant <code>58</code> into a register, it’s not a memory operation.</em></p>

<p>We should be able to see the risk here. The mapping between the theoretical Rust memory model and the X86 memory model is more forgiving to programmer error. It’s possible for us to write code that is wrong with respect to the abstract memory model, but still have it produce the correct assembly code and work correctly on some CPU’s.</p>

<h2 id="writing-a-multi-threaded-program-using-atomic-operations">Writing a Multi-Threaded Program using Atomic Operations</h2>

<p>The program we’ll be exploring builds upon the concept of storing a pointer value being atomic across threads. One thread is going to perform some work using a mutable object it owns. Once it’s finished that work it’s going to publish that work as an immutable shared reference, using an atomic pointer write to both signal the work is complete and allow reading threads to use the data.</p>

<h2 id="the-x86-only-implementation">The X86 Only Implementation</h2>

<p>If we really want to test how forgiving the X86’s memory model is, we can write multi-threaded code that skips any use of the <code>std::sync::atomic</code> module. I want to stress this is not something you should ever actually consider doing. In fact this code has undefined behavior due to not guarding against possible compiler instruction re-ordering (however in Rust 1.44.1 the compiler doesn’t re-order so the code “works”). This is an learning exercise only.</p>

<div><div><pre><code><span>pub</span> <span>struct</span> <span>SynchronisedSum</span> <span>{</span>
    <span>shared</span><span>:</span> <span>UnsafeCell</span><span>&lt;*</span><span>const</span> <span>u32</span><span>&gt;</span><span>,</span>
    <span>samples</span><span>:</span> <span>usize</span><span>,</span>
<span>}</span>

<span>impl</span> <span>SynchronisedSum</span> <span>{</span>
    <span>pub</span> <span>fn</span> <span>new</span><span>(</span><span>samples</span><span>:</span> <span>usize</span><span>)</span> <span>-&gt;</span> <span>Self</span> <span>{</span>
        <span>assert</span><span>!</span><span>(</span><span>samples</span> <span>&lt;</span> <span>(</span><span>u32</span><span>::</span><span>MAX</span> <span>as</span> <span>usize</span><span>));</span>
        <span>Self</span> <span>{</span>
            <span>shared</span><span>:</span> <span>UnsafeCell</span><span>::</span><span>new</span><span>(</span><span>std</span><span>::</span><span>ptr</span><span>::</span><span>null</span><span>()),</span>
            <span>samples</span><span>,</span>
        <span>}</span>
    <span>}</span>

    <span>pub</span> <span>fn</span> <span>generate</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>{</span>
        <span>// do work on data this thread owns</span>
        <span>let</span> <span>data</span><span>:</span> <span>Box</span><span>&lt;</span><span>[</span><span>u32</span><span>]</span><span>&gt;</span> <span>=</span> <span>(</span><span>0</span><span>..</span><span>self</span><span>.samples</span> <span>as</span> <span>u32</span><span>)</span><span>.collect</span><span>();</span>

        <span>// publish to other threads</span>
        <span>let</span> <span>shared_ptr</span> <span>=</span> <span>self</span><span>.shared</span><span>.get</span><span>();</span>
        <span>unsafe</span> <span>{</span>
            <span>shared_ptr</span><span>.write_volatile</span><span>(</span><span>data</span><span>.as_ptr</span><span>());</span>
        <span>}</span>
        <span>std</span><span>::</span><span>mem</span><span>::</span><span>forget</span><span>(</span><span>data</span><span>);</span>
    <span>}</span>

    <span>pub</span> <span>fn</span> <span>calculate</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>expected_sum</span><span>:</span> <span>u32</span><span>)</span> <span>{</span>
        <span>loop</span> <span>{</span>            
            <span>// check if the work has been published yet</span>
            <span>let</span> <span>shared_ptr</span> <span>=</span> <span>self</span><span>.shared</span><span>.get</span><span>();</span>
            <span>let</span> <span>data_ptr</span> <span>=</span> <span>unsafe</span> <span>{</span> <span>shared_ptr</span><span>.read_volatile</span><span>()</span> <span>};</span>
            <span>if</span> <span>!</span><span>data_ptr</span><span>.is_null</span><span>()</span> <span>{</span>
                <span>// the data is now accessible by multiple threads, treat it as an immutable reference.</span>
                <span>let</span> <span>data</span> <span>=</span> <span>unsafe</span> <span>{</span> <span>std</span><span>::</span><span>slice</span><span>::</span><span>from_raw_parts</span><span>(</span><span>data_ptr</span><span>,</span> <span>self</span><span>.samples</span><span>)</span> <span>};</span>
                <span>let</span> <span>mut</span> <span>sum</span> <span>=</span> <span>0</span><span>;</span>
                <span>for</span> <span>i</span> <span>in</span> <span>(</span><span>0</span><span>..</span><span>self</span><span>.samples</span><span>)</span><span>.rev</span><span>()</span> <span>{</span>
                    <span>sum</span> <span>+=</span> <span>data</span><span>[</span><span>i</span><span>];</span>
                <span>}</span>

                <span>// did we access the data we expected?</span>
                <span>assert_eq!</span><span>(</span><span>sum</span><span>,</span> <span>expected_sum</span><span>);</span>
                <span>break</span><span>;</span>
            <span>}</span>
        <span>}</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>The function that calculates the sum of the array starts by executing a loop that reads the …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.nickwilcox.com/blog/arm_vs_x86_memory_model/">https://www.nickwilcox.com/blog/arm_vs_x86_memory_model/</a></em></p>]]>
            </description>
            <link>https://www.nickwilcox.com/blog/arm_vs_x86_memory_model/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23659037</guid>
            <pubDate>Sat, 27 Jun 2020 02:26:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Coherent Unix Goes Open-Source (2015)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23658893">thread link</a>) | @desiderantes
<br/>
June 26, 2020 | http://www.nesssoftware.com/home/mwc/source.php | <a href="https://web.archive.org/web/*/http://www.nesssoftware.com/home/mwc/source.php">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
			
			
			<div id="main">
				<h2>Mark Williams Company Sources</h2>
				<p><img src="http://opensource.org/files/osi_logo_100X133_90ppi.png" height="133" width="100" alt="OSI logo">
				</p>
				<p>
					This page contains links to Mark Williams Company (MWC)
					source code and documentation.
					This material was originally © Mark Williams Company.
					It is posted here as open source software
					by the current copyright holder Robert Swartz under a license
					complying with the <a href="http://opensource.org/">Open Source Initiative</a>.
					This site is not affiliated with
					or endorsed by the Open Source Initiative.
				</p>
				<p>
					Mark Williams Company closed in 1995.
					In 2001, Bob Swartz asked me to archive the
					hard drives containing the Mark Williams source repository;
					the command and system sources here are from that repository.
					I have long intended to catalog and organize these sources,
					but in the meantime they are posted here as is.
					MWC's documentation guru Fred Butzen
					provided the MWC documentation sources.
					The <b>.gtz</b> files in these archives
					are just compressed <b>tar</b> files,
					now commonly called <b>.tgz</b>.
				</p>
				<p><a href="http://www.nesssoftware.com/home/mwc/manpage.php?page=caveat_ut"><i>Caveat utilitor</i></a>, as Fred would say.</p>
				<h3>License</h3>
				<p>
					Copyright © 1977-1995 by Robert Swartz.<br>
					All rights reserved.
				</p>
				<p>Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:</p>
				<p>1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.</p>
				<p>2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.</p>
				<p>3. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.</p>
				<p>This software is provided by the copyright holders and contributors "as is" and any express or implied warranties, including, but not limited to, the implied warranties of merchantability and fitness for a particular purpose are disclaimed. In no event shall the copyright holder or contributors be liable for any direct, indirect, incidental, special, exemplary, or consequential damages (including, but not limited to, procurement of substitute goods or services; loss of use, data, or profits; or business interruption) however caused and on any theory of liability, whether in contract, strict liability, or tort (including negligence or otherwise) arising in any way out of the use of this software, even if advised of the possibility of such damage.</p>
				<br>
				
				
				<p>
					This page is dedicated to my incredibly talented colleagues at Mark Williams Company.
					They're listed in the <a href="http://www.nesssoftware.com/home/mwc/doc/coherent/manual/pdf/preface.pdf">Preface</a> to the <a href="http://www.nesssoftware.com/home/mwc/manual.php"><i>COHERENT</i> manual</a>.
				</p>
				<hr>
			</div>
			
			
		</div></div>]]>
            </description>
            <link>http://www.nesssoftware.com/home/mwc/source.php</link>
            <guid isPermaLink="false">hacker-news-small-sites-23658893</guid>
            <pubDate>Sat, 27 Jun 2020 01:55:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scraping Websites: Python and Beautiful Soup and Ingesting into Elasticsearch]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23658382">thread link</a>) | @rbekker87
<br/>
June 26, 2020 | http://sysadmins.co.za/scraping-websites-with-python-and-beautiful-soup-and-ingesting-into-elasticsearch/ | <a href="https://web.archive.org/web/*/http://sysadmins.co.za/scraping-websites-with-python-and-beautiful-soup-and-ingesting-into-elasticsearch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

		<!-- .post-header -->


		<div>
			<p><img src="http://obj-cache.cloud.ruanbekker.com/python-elasticsearch.png" alt=""></p>
<p>This will be a 2 post guide, where we will scrape this website on <code>Page Title</code>, <code>URL</code> and <code>Tags</code>, for blog posts, then we will ingest this data into Elasticsearch. - <a href="">This Post</a></p>
<p>Once we have our data in Elasticsearch, we will build a Search Engine to search for these posts, the frontend will consist of Python Flask, Elasticsearch Library and HTML, which will be coverend in <a href="https://sysadmins.co.za/building-a-search-engine-for-our-scraped-data-on-elasticsearch-part-2/">Part 2</a></p>
<p><strong>Notice:</strong></p>
<p>Always ensure that you are scraping for the right reasons, in this example, I will use my own blog site as the target, and I won't be scraping the websites data, but only Page Title, URL and Tags, so that we have enough data for our search engine.</p>
<p><strong>Requirements:</strong></p>
<p>For this example I am using Ubuntu 16.04, and we will need some dependencies to install for our Python Script:</p>
<pre><code>$ apt udpate &amp;&amp; apt upgrade -y
$ apt install python python-dev python-setuptools python-lxml openssl libssl-dev python-pip
$ pip install requests
$ pip install bs4
$ pip install elasticsearch
</code></pre>
<p><strong>Python Scraper:</strong></p>
<p>Here is our Python Scraper that will scrape the data from a <code>sitemap.xml</code> and ingest the data into Elasticsearch:</p>
<pre><code>import re
import time
import requests
from bs4 import BeautifulSoup
from elasticsearch import Elasticsearch

es_client = Elasticsearch(['http://10.0.1.10:9200'])

drop_index = es_client.indices.create(index='blog-sysadmins', ignore=400)
create_index = es_client.indices.delete(index='blog-sysadmins', ignore=[400, 404])

def urlparser(title, url):
    # scrape title
    p = {}
    post = title
    page = requests.get(post).content
    soup = BeautifulSoup(page, 'lxml')
    title_name = soup.title.string

    # scrape tags
    tag_names = []
    desc = soup.findAll(attrs={"property":"article:tag"})
    for x in xrange(len(desc)):
        tag_names.append(desc[x-1]['content'].encode('utf-8'))

    # payload for elasticsearch
    doc = {
        'date': time.strftime("%Y-%m-%d"),
        'title': title_name,
        'tags': tag_names,
        'url': url
    }

    # ingest payload into elasticsearch
    res = es_client.index(index="blog-sysadmins", doc_type="docs", body=doc)
    time.sleep(0.5)

sitemap_feed = 'https://sysadmins.co.za/sitemap-posts.xml'
page = requests.get(sitemap_feed)
sitemap_index = BeautifulSoup(page.content, 'html.parser')
urls = [element.text for element in sitemap_index.findAll('loc')]

for x in urls:
    urlparser(x, x)
</code></pre>
<p>This scraper will grab all the posts from the <code>sitemap.xml</code> then loop through each post, with the given logic, ingest the data into elasticsearch.</p>
<p><strong>Running the Python Scraper:</strong></p>
<pre><code>$ python scraper.py
</code></pre>
<p><strong>Verify Documents in Elasticsearch:</strong></p>
<p>After you have executed the python script, have a look at elasticsearch to confirm if the documents were ingested into Elasticsearch:</p>
<pre><code>$ curl http://10.0.1.10:9200/_cat/indices/scrape-sysadmins?v
health status index            uuid                   pri rep docs.count docs.deleted store.size pri.store.size
green  open   blogs-sysadmins gyHONBcwTmaVjZVRj6dYew   5   1         80            0    289.6kb        144.8kb
</code></pre>
<p>As you can see we have ingested 80 documents, having a look at one of our documents:</p>
<pre><code>$ curl http://10.0.1.10:9200/blogs-sysadmins/_search?pretty -d '{"size": 1}'
{
  "took" : 5,
  "timed_out" : false,
  "_shards" : {
    "total" : 5,
    "successful" : 5,
    "failed" : 0
  },
  "hits" : {
    "total" : 80,
    "max_score" : 1.0,
    "hits" : [
      {
        "_index" : "blogs-sysadmins",
        "_type" : "docs",
        "_id" : "AV6j3bZEzCREvIW7N4yt",
        "_score" : 1.0,
        "_source" : {
          "date" : "2017-09-21",
          "url" : "https://sysadmins.co.za/bash-script-setup-a-3-node-hadoop-cluster-on-lxc-containers/",
          "tags" : [
            "LXC",
            "Hadoop",
            "Scripting",
            "LXD"
          ],
          "title" : "Bash Script setup a 3 Node Hadoop Cluster on LXC Containers"
        }
      }
    ]
  }
}
</code></pre>
<p><strong>Next Steps:</strong></p>
<p>In my <a href="https://sysadmins.co.za/building-a-search-engine-for-our-scraped-data-on-elasticsearch-part-2/">next post</a>, I will guide you through the steps on setting up a Search User Interface that will be our search engine to search from blog posts that is stored in Elasticsearch.</p>

		</div><!-- .post-content -->

		<!-- .post-footer -->

		<!-- .comments-area -->



	</article></div>]]>
            </description>
            <link>http://sysadmins.co.za/scraping-websites-with-python-and-beautiful-soup-and-ingesting-into-elasticsearch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23658382</guid>
            <pubDate>Sat, 27 Jun 2020 00:06:55 GMT</pubDate>
        </item>
    </channel>
</rss>
