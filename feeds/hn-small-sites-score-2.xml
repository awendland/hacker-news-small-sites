<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Tue, 17 Nov 2020 16:39:46 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Tue, 17 Nov 2020 16:39:46 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[How to be a normal human being during lockdown]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25109454">thread link</a>) | @KlimYadrintsev
<br/>
November 16, 2020 | https://klimy.co/blog/understanding-life-16-11-2020 | <a href="https://web.archive.org/web/*/https://klimy.co/blog/understanding-life-16-11-2020">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="blog">
                    <h2>Feeling great</h2>
<p>What do you want people to feel when they talk to you? Happiness, sadness or maybe everything combined? </p>
<p>Do you want people to be inspired or motivated to tackle new and exiting problems? </p>
<p>Do you want to make the world a better place?</p>
<p>I think to understand your life purpose, you gotta understand yourself first. Not in a psychoanalytical way, but in a spiritual and reflectional way.</p>
<p>Don’t beat yourself up. Make yourself proud inside of you. If you are proud of what you do, then it means that you are following your heart. If you are following your heart, you are doing the best work you can, because there are too many people that do things for money. If you want to succeed, then there is no better strategy than that.</p>
<p>Live the life that you would feel proud about telling your grandchildren. Live the life that would inspire your children and will set a good role model for them. Be a person that is open to every opportunity, but chooses only those that align with their goals. Be open to success and closed for disappointment.</p>
<p>Shoot each time you have an idea, and don’t afraid to fail. You can miss and embers yourself just a little. Or you can never shoot and never achieve anything in life. Which one sounds worse?</p>
<h2>Understand your surrounding</h2>
<p>The most important part of being successful is in alignment with your surrounding.</p>
<p>Look around yourself. Do your habits improve it? Do people around you improve and getter better because of your actions? Are you on your way to helping others?</p>
<p>Humans are social beings, and the language that we have developed is the biggest indicator of that. If we could survive alone, we wouldn’t have needed a language to communicate. </p>
<p>You need to check up on others and help them. This will cause a domino effect, and in the end, you will benefit even more from that.</p>
<p>You are 5 people who you spend most of your time with. List those people and check if they are improving you and your well being, or are they destroying it? It is essential to make those 5 people stronger and better than you. This will allow you to grow, which will allow you that effect to trickle to other people, improving their lives.</p>
<h2>Don’t be afraid to try</h2>
<p>If you have a particular thing that you want to experiment, calculate how much will it cost. Mostly the things we are the most afraid of trying or doing we can try or do for less than $500 and the drawbacks are not irreversible.</p>
<p>Don’t be afraid to shoot and fail. Try and see how it goes. You can always roll back to the point of start.</p>
<p>Start now. Get perfect later.</p>
<p>Klim Y</p> 
                    
                </div></div>]]>
            </description>
            <link>https://klimy.co/blog/understanding-life-16-11-2020</link>
            <guid isPermaLink="false">hacker-news-small-sites-25109454</guid>
            <pubDate>Mon, 16 Nov 2020 08:35:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rule 1: It’s Always DNS]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25109255">thread link</a>) | @kiyanwang
<br/>
November 16, 2020 | https://talesofatech.com/2017/03/rule-1-its-always-dns/ | <a href="https://web.archive.org/web/*/https://talesofatech.com/2017/03/rule-1-its-always-dns/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
				<p>Brought to you by the “I hate Mondays” department of Tales Of A Tech.</p>
<p>We would like to remind you that if there is a problem and you can’t seem to figure it out there’s always one solution to look to: It’s ALWAYS DNS.</p>

<p><strong>The Story:</strong></p>
<p>Last night I was trying to login to this site in order to make a post about my drone shenanigans (which, by the way, is <a href="https://talesofatech.com/2017/03/drone-shenanigans/">here</a>). &nbsp;I was already super frustrated because Mass Effect: Andromeda is coded by a team of (apparently) monkeys who don’t understand how to make working autosave features (my autosave files are all corrupt, causing me to lose 5+ hours of gameplay) and the site wasn’t being cooperative. &nbsp;I was reaching “blow-your-top” levels of frustration. &nbsp;I was finally able to connect and login but I immediately noticed things were running VERY slowly. &nbsp;It was weird, and I couldn’t figure out why. EVERYTHING seemed slow. &nbsp;Even the SSH connection was jittery and laggy.</p>
<p>At first I thought it was a problem with the network in the apartment. &nbsp;It happens from time to time. &nbsp;We run a lot of equipment in our apartment. &nbsp;I ran some speed tests and some other diagnostics and found that everything seemed to be working. &nbsp;Very weird.</p>
<p>Since I managed to SSH in I decided to check some logs. &nbsp;There didn’t seem to be anything in the apache log. &nbsp;fail2ban wasn’t being uncooperative. MySQL was running and seemingly accepting localhost connections. &nbsp;Very weird. &nbsp;I resorted to the only thing I could think of next: I rebooted the box.</p>
<p>Everything&nbsp;came back up (yay) but the site was still clunky and slow (not so yay).</p>
<p>I decided to enable verbose logging in apache and attempt to restart the service. &nbsp;It timed out. The hell?</p>
<p>I ran “journalctl -xe” per service failure message and noticed a peculiar entry:</p>
<pre>Mar 27 21:17:51 TalesOfAnAdmin systemd[1]: apache2.service: Start operation timed out. Terminating.
Mar 27 21:17:51 TalesOfAnAdmin systemd[1]: Failed to start The Apache HTTP Server.</pre>
<p>Failed to start due to timeout? &nbsp;Timeout of what? SO CONFUSED.</p>
<p>Digging back a little further I saw another confusing line:</p>
<pre>Mar 27 21:15:12 TalesOfAnAdmin apachectl[1860]: [Mon Mar 27 21:15:12.835322 2017] [core:error] [pid 1864] (EAI 2)Name or service not known: AH00547: Could not resolve host name maplerangers.com</pre>
<p>Huh. &nbsp;Weird.</p>
<p>I had a quick confab with Nick and he suggested I check if my websites were in my hostfile. &nbsp;They weren’t, so I added them. &nbsp;Apache startup became instantaneous. &nbsp;Things seemed to be improving. &nbsp;Cool.</p>
<p>I logged in to the website which was up and more responsive, but absolutely slow. &nbsp;Very weird still. &nbsp;I noticed an error on my WordPress Administration page: “curl error 28: operation timed out”</p>
<p>What the hell?</p>
<p>So back to the SSH I go. &nbsp;I try pinging wordpress.com: &nbsp;Unknown host. &nbsp;I try pinging google.com: Unknown host. &nbsp;I try pinging an IP Address for those sites: Working fine.</p>
<p>Grrrr!</p>
<p>I look at /etc/resolv.conf — I’m using Google DNS. &nbsp;Ok.</p>
<p>Let’s see if DigitalOcean has anything about this: Bingo!</p>
<blockquote data-lang="en">
<p dir="ltr" lang="en">Our engineering team is investigating reports of DNS connectivity issues while using the Google resolvers. During… <a href="https://t.co/cEpXMPJ3Nq">https://t.co/cEpXMPJ3Nq</a></p>
<p>— DigitalOcean Status (@DOStatus) <a href="https://twitter.com/DOStatus/status/846430105094250496">March 27, 2017</a></p></blockquote>
<p>Interesting.</p>
<p>I edit the resolv.conf (and interfaces) to reflect a change to OpenDNS as the primary DNS with Google as the fallback DNS (as per the article linked later in the Tweet).</p>
<p>Restart networking.</p>
<p>Boom, everything is working.</p>
<p>It was DNS.</p>
<p><span><strong>It’s always DNS.</strong></span></p>
<p>-M, out.</p>

							</div></div>]]>
            </description>
            <link>https://talesofatech.com/2017/03/rule-1-its-always-dns/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25109255</guid>
            <pubDate>Mon, 16 Nov 2020 08:01:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Everything You Need to Know About Message Queues: A Complete Guide]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25108975">thread link</a>) | @sunilkumarc
<br/>
November 15, 2020 | https://sunilkumarc.in/everything-you-need-to-know-about-message-queues | <a href="https://web.archive.org/web/*/https://sunilkumarc.in/everything-you-need-to-know-about-message-queues">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>Message queues are one of the critical components in any software architecture which helps different components talk to each other asynchronously. In this article let's discuss what message queues are, how they're used in modern architectures and what problems do they solve.</p>
<p>Let's say you want to withdraw some money from an ATM. An ATM machine can only allow one person to do transactions at a time. In this case, what do you do when you see there's a person already using the ATM machine? Do you wait in a queue or do you go back thinking you cannot withdraw money from this machine?</p>
<p>Exactly! You wait in a queue until your turn comes.</p>
<p>So when many people want to withdraw money they will have to wait in a queue and go to the ATM machine in the same order in which they entered the queue. This is one real world example of queues and message queues serve the same purpose in any software architecture.</p>
<p>We will talk about below topics in this article:</p>
<ul>
<li><a href="#what-are">What are message queues?</a></li>
<li><a href="#used-how">How are message queues used in a system?</a></li>
<li><a href="#problems">What problems do message queues solve?</a></li>
<li><a href="#properties">Other properties of message queues</a></li>
<li><a href="#resources">Resources</a></li>
<li><a href="#conclusion">Conclusion</a></li>
</ul>

<h3 id="what-are-message-queues">What Are Message Queues?</h3>
<p>A queue is a First-In First-Out data structure. If you have a computer science background you know how a queue data structure works: the first element pushed into the queue is the first item extracted. It's basically the same concept as what we discussed in our ATM machine example.</p>
<p>A message queue is basically a queuing service used in micro services &amp; server-less architectures to decouple different components that are easier to develop, scale &amp; maintain in the long term. Message queues helps different components to communicate asynchronously by passing messages between them.</p>
<p>Generally in applications where message queues are used there are producers who create and put the messages into message queues. And there are consumers or worker processes which read those messages and take actions.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1605504976290/uqTaa9q5A.png?auto=format&amp;q=60" alt="imageedit_2_4624157258.png"></p>
<p>A message is any data that is passed between two components. It contains all the information needed for the worker components to take actions.</p>
<p>Let's consider a use case where we have to recharge a customer's account. The worker component need to know these details: account_id, card_id, amount (in dollars).</p>
<p>The message the producer creates and puts into a message queues will look something like this:</p>
<pre><code>{
    <span>"account_id"</span>: <span>12345</span>,
    <span>"card_id"</span>: <span>567</span>,
    <span>"amount"</span>: <span>100</span>
}
</code></pre><p>As you can see, the above message contains all the information that a worker process needs to recharge this customer's account.</p>
<p>There are many third party message queueing services like Rabbit MQ, Kafka, Amazon SQS to name a few. Each one of them provide different features suitable for different use cases.</p>

<h3 id="how-are-message-queues-used-in-a-system">How Are Message Queues Used In A System?</h3>
<p>As mentioned earlier message queues are used to decouple different components in a system. But what does it mean to decouple a system? It basically means the process of separating functions so that they're more independent and self contained.</p>
<p>Let's discuss it with an example. Let's say we need an application to generate invoices and send it to our customers at the end of the month. For the sake of this discussion let's assume that generating invoices is a time taking process and take anywhere between few seconds to a minute to generate one single invoice which involves doing the below steps in order:</p>
<ul>
<li>Get customer account details</li>
<li>Get customer billing details</li>
<li>Get data for different products used by the customer during the month</li>
<li>Apply any onetime charges and charge customers</li>
<li>Finally generate a invoice PDF and send it to the customer</li>
</ul>
<p>How would you implement such a functionality?</p>
<p>This is how a naive developer would approach it: Build a single REST service which accepts requests and does the above steps. </p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1605506280058/Y03xhpEYG.png?auto=format&amp;q=60" alt="imageedit_2_8235631782.png"></p>
<p>This is a monolith architecture and has many problems with it:</p>
<ul>
<li><p><strong>No Fault Tolerance:</strong> Fault tolerance is the ability for a system to continue operating without any interruption when one or more of its components fail. Since we have a single REST service, if the service goes down, the whole application stops working.</p>
</li>
<li><p><strong>Components Cannot Be Scaled Independently:</strong> If we want to scale the application when the number of customers accounts increase, then we have to scale the whole application. This means more resources will be used since we cannot scale any individual component independently. So the use cases like Get Account Details will be scaled even though it is unnecessary because this components generally gets less traffic.</p>
</li>
<li><p><strong>No Freedom of Language:</strong> Since all the components are built using a single application, a single language / framework need to be used to build the complete application. We cannot use different languages for different components since the whole application is a single code repository which is built and deployed together.</p>
</li>
<li><p><strong>Increase in Development and Deployment Time:</strong> Having all the components as one single codebase will increase the development time. Since this is a big application, it's possible that different teams would be working on different components of the system at any point in time. So all the teams need to take care of code consistency, code quality and also have to spend time in resolving merge conflicts since active development will be going on. This adds to the development time. Also with bigger codebase it takes more time to build and deploy.</p>
</li>
</ul>
<p>As seen above there are many problems if we go with a monolith architecture for the given problem statement. We need to divide the application into multiple components like Invoice Generation Service, Invoice Generation Service Worker, Account Service, PDF Generation Service etc.</p>
<p>Let's see how diving this into multiple services &amp; having a message queue to communicate between them will solve these problems.</p>

<h3 id="what-problems-do-message-queues-solve">What Problems Do Message Queues Solve?</h3>
<p>With micro services architecture, the architecture would look something like this:</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1605508126047/PhUZ4K-mV.png?auto=format&amp;q=60" alt="imageedit_2_2135728654.png"></p>
<p>In this architecture the Invoice Generation Service will create a message for every customer account. This message would look something like this:</p>
<pre><code>{
    <span>"account_id"</span>: <span>12345</span>,
    <span>"invoice_start_date"</span>: <span>"2020-10-01"</span>,
    <span>"invoice_end_date"</span>: <span>"2020-10-31"</span>
}
</code></pre><p>Therefore if we have 1000 accounts there will be 1000 messages pushed into the queue. The worker service will contain multiple workers. Each worker will pickup a message and start processing it. All the workers will be running concurrently. Each of these workers will talk to Account Service, Billing Service and PDF Generation Services which are micro services themselves.</p>
<p>Now let's see how each of the problems mentioned above will be solved with this architecture.</p>
<ul>
<li><p><strong> Fault Tolerance</strong>: If one of the component fails the other will work seamlessly. Let's say if Invoice Generation Service Worker is down for reasons, Invoice Generation Service will continue to work and keep pushing messages into the queue. It is not dependent on whether Worker service is up or not. If Invoice Generation Service is down, Worker service will continue to pull the messages from the queue and continue to generate invoices. So now there is fault tolerance in the system.</p>
</li>
<li><p><strong>Scalability:</strong> Now since the components are independent of one another they can be scaled independently too. All the heavy weight work is being done by the Worker service and Invoice Generation Service is just creating and pushing the messages into the message queue. So we need more computing power for the Worker service. So we can have powerful machines to run Worker service and we can add more tasks if the number of accounts increase in the future. Whereas the Invoice Generation Service can be run on less powerful machines. With this architecture we're able to scale the different components independently.</p>
</li>
<li><p><strong>Freedom of Language:</strong> Having multiple components like this will give us the freedom to implement different components in different programming languages and frameworks. For example: Invoice Generation Service can be implemented in Java. Worker can be implemented in GoLang.
And if let's say we have another service which is responsible for generating invoice pdf, this can be implemented in Python. So having multiple components like this and having a message queue for communication between them will give us the flexibility over languages used in the architecture.</p>
</li>
<li><p><strong>Improved Developer Productivity &amp; Deployment Time:</strong> Since different components can be developed independently, the developer productivity will increase since they don't have to spend more time in co-ordinating when adding new features, resolving merge conflicts etc. Also the codebase of each of the component or service will be lighter and will have a separate deployment pipeline. So the quality, build and deployment time will decrease.</p>
</li>
</ul>

<h3 id="other-properties-of-message-queues">Other Properties Of Message Queues</h3>
<p>Different message queuing services offer different message queues with properties like visibility timeout, message retention period, message size etc based on the popular use cases in the industry.</p>
<p>AWS provided message queuing service is called SQS (Simple Queue Service).</p>
<p>Let's discuss about SQS provided message queues and their properties in this section which gives you an idea on the different types of properties available with message queues in general.</p>
<p>AWS SQS offers two types of message queues:</p>
<h4 id="standard-queue">Standard Queue:</h4>
<p>Amazon SQS offers standard as the default queue type. Standard queues support a nearly unlimited number of API calls per second, per API action (SendMessage, ReceiveMessage, or DeleteMessage). Standard queues support at-least-once message delivery. However, occasionally (because of the highly distributed architecture that allows nearly unlimited throughput), more than one copy of a message might be delivered out of order. Standard queues provide best-effort ordering which ensures that messages are generally delivered in the same order as they're sent.</p>
<h4 id="fifo-queue">FIFO Queue:</h4>
<p>FIFO (First-In-First-Out) queues are designed to enhance messaging between applications when the order of operations and events is critical, …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sunilkumarc.in/everything-you-need-to-know-about-message-queues">https://sunilkumarc.in/everything-you-need-to-know-about-message-queues</a></em></p>]]>
            </description>
            <link>https://sunilkumarc.in/everything-you-need-to-know-about-message-queues</link>
            <guid isPermaLink="false">hacker-news-small-sites-25108975</guid>
            <pubDate>Mon, 16 Nov 2020 07:09:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Manufacturing in India vs. China]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25108874">thread link</a>) | @hammadn
<br/>
November 15, 2020 | https://www.aliaworld.com/post/manufacturing-in-india-vs-china | <a href="https://web.archive.org/web/*/https://www.aliaworld.com/post/manufacturing-in-india-vs-china">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="8.3.0"><div dir="ltr"><div><p id="viewer-foo"><span>For many importers, the end of profitable manufacturing in China may be near. Apart from a tenuous and vague “phase one” trade deal, any kind of truce in the ongoing China-U.S. trade war seems distant. And without a resolution in the next few weeks, nearly all goods traded between the U.S. and China will have tariffs by December 15.</span></p><p id="viewer-adua0"><span>Is it any wonder why many manufacturers are now considering leaving China, while others are accelerating earlier plans to exit.</span></p><p id="viewer-drn2j"><span>Manufacturing in India stands out as a cost-effective alternative to China. Companies like Hasbro have announced plans to limit their number of China-made products to half, choosing to relocate much of their production to India.</span></p><p id="viewer-3clqd"><span>And Taiwanese Foxconn, which manufacturers Apple’s iPhone and Amazon’s Echo, built their first plant in India in 2015 and plans to expand operations there.</span></p><p id="viewer-5a9o5"><span>But many other companies are either looking for solutions outside India or prefer to remain in China. They view India’s many challenges—a skills gap and inadequate infrastructure among them—as insurmountable barriers to their continued success.</span></p><p id="viewer-1kpog"><span>Let’s explore how manufacturing compares between India and China and whether India may be the right sourcing choice for you.</span></p><div id="viewer-4c75k"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.aliaworld.com/post/manufacturing-in-india-vs-china" data-pin-media="https://static.wixstatic.com/media/3fccd7_b886c6ba02cb42f6ba3909c99634d44b~mv2.png/v1/fit/w_400%2Ch_256%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/3fccd7_b886c6ba02cb42f6ba3909c99634d44b~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p></div></div></div></div><h2 id="viewer-68ao9"><span>WHAT DOES INDIA EXPORT TODAY?</span></h2><p id="viewer-9cbef"><span>India exported more than $323 billion worth of goods in 2018. Meanwhile, China exported goods valued at nearly eight times as much. China’s top exports included products such as electrical machinery, appliances and equipment. While raw materials and products requiring less sophisticated manufacturing composed the majority of India’s exports.</span></p><p id="viewer-f2041"><span><strong>Mineral products, chemical products and precious metals and stones</strong></span></p><p id="viewer-9sv1v"><span>India’s top exports are dominated by mineral products (16 percent), chemical products (14 percent) and precious metals (12 percent). Mineral products include mineral fuels and oils, such as Manufacturing in India vs. Chinapetroleum.</span></p><p id="viewer-4t78m"><span>Chemical products include various organic and inorganic chemicals, soaps, tanning dyes, fertilizers, explosives and, most notably, pharmaceuticals. India’s pharmaceutical industry now reportedly supplies:</span></p><ul><li id="viewer-947qg"><p>50 percent of the world’s demand for various vaccines</p></li><li id="viewer-2k7f4"><p>40 percent of U.S. demand for generic drugs; and</p></li><li id="viewer-ef5ro"><p>25 percent of all medicine in the UK</p></li></ul><p id="viewer-baho4"><span>Contributing seven percent of the country’s GDP, India’s precious metals and stones industry employs 4.6 million workers. Labor-intensive cutting, polishing and processing of small diamonds is a particularly strong sub-sector for India. Other gems, gold and jewelry are other major products in this category.</span></p><div id="viewer-inev"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.aliaworld.com/post/manufacturing-in-india-vs-china" data-pin-media="https://static.wixstatic.com/media/3fccd7_9c904a6c67764948a1492d4f556b20e0~mv2.png/v1/fit/w_327%2Ch_324%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/3fccd7_9c904a6c67764948a1492d4f556b20e0~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p></div></div></div></div><p id="viewer-2i14b"><span><strong>Food and beverage</strong></span></p><p id="viewer-dror4"><span>Food and beverage products represent about 11 percent of India’s total exports, or $35 billion. Some of India’s leading exports in food and beverage include:</span></p><ul><li id="viewer-citq4"><p>Basmati rice</p></li><li id="viewer-8o9ls"><p>Carabeef or meat of bovine animals</p></li><li id="viewer-f7e4l"><p>Frozen shrimp and prawns; and</p></li><li id="viewer-bqua5"><p>Refined sugar</p></li></ul><p id="viewer-3737a"><span>India’s broader agricultural sector accounts for 17 percent of the country’s economy and employs more than 60 percent of the population.</span></p><p id="viewer-7ql2u"><span><strong>Garments and textiles</strong></span></p><p id="viewer-bcu8t"><span>The garment and textiles industry is one of India’s fastest growing. Overall textiles exports were valued at $39 billion in 2018 and are expected to more than double by 2021.</span></p><p id="viewer-9shou"><span>Part of the growth comes from various government initiatives, such as a 2018 increase in basic customs duties from 10 percent to 20 percent on more than 500 textile products. Another contributor is India’s robust production of relevant input materials, such as cotton, which lend supply chain and cost advantages.</span></p><p id="viewer-faukb"><span>These exports include knitted, woven and crocheted textiles and apparel, carpets and textile floor coverings and man-made filaments.</span></p><p id="viewer-7r4hg"><span>Despite China’s current dominance in export value, India’s government is making serious efforts to invest in the country’s manufacturing sector. Though the manufacturing sector now contributes only 16 percent to India’s gross domestic product (GDP), the “Make in India” initiative aims to boost that contribution to 25 percent by 2022.</span></p><p id="viewer-caorn"><span>And companies like Chinese smartphone maker OnePlus are investing heavily in R&amp;D in India. “Our success in India has proven to be a great model for our growth in other regions,” says OnePlus CEO Pete Lau. “…We are now closer to making India as our second headquarters.”</span></p><h2 id="viewer-6tjmf"><span>COST AND AVAILABILITY OF SKILLED LABOR IN INDIA AND CHINA</span></h2><p id="viewer-fp3rq"><span>Differences in manufacturing wages, size and skill level of the labor force should be at the forefront of your decision to move production from China to India. Depending on your product type, some of these factors may highlight clear advantages for remaining in China.</span></p><p id="viewer-6tdee"><span><strong>Manufacturing wages</strong></span></p><p id="viewer-7q1sj"><span>Labor represents one of the main costs of manufacturing goods. And importers have watched China’s labor costs soar in recent decades, often growing by 10-15 percent annually. China’s minimum wages, which now range from about US$140 to US$346 per month, are set at the provincial level.</span></p><p id="viewer-5u605"><span>India’s minimum wages similarly vary across states and range from about US$66 to US$202. Mounting U.S. tariffs on Chinese goods over the past year have only strengthened the case for India as a cost-effective manufacturing alternative. And importers of labor-intensive products, like garments and textiles, are in the best position to realize cost savings by moving to India.</span></p><p id="viewer-2dtbl"><span><strong>Labor force size and skill level</strong></span></p><p id="viewer-5d337"><span>Among the many manufacturing locations opposing China, India is unmatched in the size of its labor force. According to September 2019 data from the World Bank, India’s labor force numbers about 519 million. China’s labor force is still much larger with 783 million strong. But Indonesia’s labor force, with 134 million workers, is a distant third for the region.</span></p><p id="viewer-fh5j3"><span>India falls behind many of its neighbors with regard to factors the World Economic Forum use to rank countries in their human capital report. India ranks 103rd overall, while China ranks 34th.</span></p><p id="viewer-3umpt"><span>One area where India suffers a deficiency is in “know-how”, which includes the breadth and depth of specialized skills at work. We see this directly at play in the quality and complexity of the country’s top export products. This metric also measures employers’ perceived ease at filling job vacancies.</span></p><p id="viewer-8obvp"><span>India also has room to grow with regard to its labor development rank. This rank considers access to and enrollment in formal education, opportunities to upskill and how well the education system fits the needs of a competitive economy.</span></p><p id="viewer-6aqg0"><span>Some have attributed the low development rank to India’s shortage of vocational schools.</span></p><p id="viewer-crl8q"><span>The relatively low labor participation rate in India—just 67 percent among the 25-54 age group as of 2017—also hurt the country’s human capital rank. India’s employment gender gap, one of the world’s largest, was another major contributor. In contrast, China achieved a labor participation rate of 88 percent for the same age group.</span></p><p id="viewer-3r1pr"><span>On the positive side, India has performed relatively well in terms of quality of education, staff training and economic complexity.</span></p><p id="viewer-aa1e7"><span>Read further at <a href="https://www.intouch-quality.com/blog/manufacturing-in-india-vs-china" target="_blank" rel="noopener"><u>https://www.intouch-quality.com/blog/manufacturing-in-india-vs-china</u></a></span></p><p id="viewer-1hgbn"><span><em><strong>If you are looking forward to source high-quality metal jewelry then reach out to us at </strong></em><a href="mailto:info@aliajewelery.com" target="_blank" rel="noopener"><em><strong><u>info@aliajewelery.com</u></strong></em></a><em><strong> &amp; we'll provide you with a free quote as per your requirement.</strong></em></span></p></div></div></div></div></article></div></div>]]>
            </description>
            <link>https://www.aliaworld.com/post/manufacturing-in-india-vs-china</link>
            <guid isPermaLink="false">hacker-news-small-sites-25108874</guid>
            <pubDate>Mon, 16 Nov 2020 06:51:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building Sustainable Electronics]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25108650">thread link</a>) | @davewongillies
<br/>
November 15, 2020 | https://gopher.mills.io/republic.circumlunar.space/0/~xkp/phlog/2020-11-08-building-sustainable-electronics.txt | <a href="https://web.archive.org/web/*/https://gopher.mills.io/republic.circumlunar.space/0/~xkp/phlog/2020-11-08-building-sustainable-electronics.txt">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://gopher.mills.io/republic.circumlunar.space/0/~xkp/phlog/2020-11-08-building-sustainable-electronics.txt</link>
            <guid isPermaLink="false">hacker-news-small-sites-25108650</guid>
            <pubDate>Mon, 16 Nov 2020 06:13:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Short History of Romaji]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 12 (<a href="https://news.ycombinator.com/item?id=25108455">thread link</a>) | @polm23
<br/>
November 15, 2020 | https://www.dampfkraft.com/romaji-history.html | <a href="https://web.archive.org/web/*/https://www.dampfkraft.com/romaji-history.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I recently created a tool called <a href="https://github.com/polm/cutlet">cutlet</a> for converting Japanese to romaji.
While working on cutlet I was surprised at the difficulty of finding a good
guide to the difference between romaji systems, particularly their history and
usage, so I wrote this up.</p>
<h2 id="a-romaji-refresher"> A Romaji Refresher</h2>
<p>There are three relatively well-defined romaji systems. For a quick overview of
some of their differences:</p>
<table>
<thead>
<tr>
<th>Japanese</th>
<th>新橋</th>
<th>お茶漬け</th>
<th>富士山</th>
</tr>
</thead>
<tbody>
<tr>
<td>Hepburn</td>
<td>Shinbashi (or Shimbashi)</td>
<td>ochazuke</td>
<td>Fujisan</td>
</tr>
<tr>
<td>Kunreisiki</td>
<td>Sinbasi</td>
<td>otyazuke</td>
<td>Huzisan</td>
</tr>
<tr>
<td>Nipponsiki</td>
<td>Sinbasi</td>
<td>otyaduke</td>
<td>Huzisan</td>
</tr>
</tbody>
</table>
<p>Hepburn is the most widely used outside Japan, Kunreisiki is officially taught
to children in Japan. Nipponsiki is similar to Kunreisiki but older. Technically
Hepburn uses macrons for long vowels while Kunreisiki and Nipponsiki use
circumflexes, but usage isn't consistent and there's no difference in meaning
between them.</p>
<p>In recent years "wapuro" romaji, based on input when typing Japanese, are also
relatively common, but it's not systematized (except in as far as programs
either take or don't take certain sequences) and isn't used in any kind of
formal writing.</p>
<h2 id="particle-comparison"> Particle Comparison</h2>
<p>As another refresher, here's how non-phonetic particles are represented in the
various systems.</p>
<table>
<thead>
<tr>
<th>Japanese</th>
<th>は</th>
<th>を</th>
<th>へ</th>
</tr>
</thead>
<tbody>
<tr>
<td>Hepburn</td>
<td>wa</td>
<td>wo</td>
<td>e</td>
</tr>
<tr>
<td>Kunreisiki</td>
<td>wa</td>
<td>o</td>
<td>e</td>
</tr>
<tr>
<td>Nipponsiki</td>
<td>ha</td>
<td>wo</td>
<td>he</td>
</tr>
</tbody>
</table>
<p>Hepburn is phonetic except for <em>wo</em>, Kunreisiki is strictly phonetic, and
Nipponsiki is strictly orthographic.</p>
<h2 id="early-romaji"> Early Romaji</h2>
<p>Japanese was first written in the Latin alphabet in the 1600s, mainly by
Christian missionaries. It was used by the missionaries for recording and
learning the language, and also used in texts they produced to try to spread
Christianity. Since Christianity was later supressed in Japan, these forms of
romaji never had wide adoption, though they influenced later efforts.</p>
<h2 id="the-origins-of-the-hepburn-system"> The Origins of the Hepburn System</h2>
<p>In 1867, missionary <a href="https://en.wikipedia.org/wiki/James_Curtis_Hepburn#Missionary_work_in_Japan">James Curtis Hepburn</a> published a
Japanese-English dictionary in Yokohama. Naturally he needed some way to write
Japanese words for people who couldn't read Japanese, so he devised a system of
representing Japanese that reflected the pronunciation of English consonants.
His system wasn't designed from the ground up, but developed based on his
knowledge of existing systems by other missionaries as well as his own
knowledge of Japanese.</p>
<p>Somewhat later, in 1885, an organization known as the
<a href="https://ja.wikipedia.org/wiki/%E3%83%AD%E3%83%BC%E3%83%9E%E5%AD%97%E8%AB%96#%E3%83%AD%E3%83%BC%E3%83%9E%E5%AD%97%E4%BC%9A">羅馬字会</a>
(Romajikai) was established. Mainly a society of Japanese academics, it was
interested in promoting the use of romaji as a replacement for kana and kanji.
Some motivations for getting rid of native writing systems included easier
international communication and improved domestic literacy. The principle
founders were <a href="https://en.wikipedia.org/wiki/Ry%C5%8Dkichi_Yatabe">Ryoukichi Yatabe</a>, a botanist and the first Japanese graduate of Cornell, and <a href="https://ja.wikipedia.org/wiki/%E5%A4%96%E5%B1%B1%E6%AD%A3%E4%B8%80">Masakazu Toyama</a>, a <a href="https://ii.umich.edu/cjs/history-of-cjs.html">graduate of the University of Michigan</a> who
later occupied a high post at what would eventually become Tokyo University.</p>
<figure><a href="https://www.dampfkraft.com/by-id/4d041d6a/max-moritz-romaji.jpg"><img src="https://www.dampfkraft.com/by-id/4d041d6a/img/max-moritz-romaji.jpg.l.jpg"></a><figcaption>The Romajikai published books to promote romaji, including this translation of Max and Moritz, titled "Wampaku Monogatari". This edition was reprinted in 1978. via <a href="https://www.wul.waseda.ac.jp/kotenseki/html/he22/he22_07214/index.html">Waseda University</a>
</figcaption></figure>
<p>In 1886 the Romajikai published <a href="https://dl.ndl.go.jp/info:ndljp/pid/862485">a romaji system</a>. Also in 1886
Hepburn published the third edition of his dictionary, which roughly used the
system.  I've had trouble finding the exact nature of the influence between
Hepburn's system and the Romajikai, but they were on friendly terms and
cooperating. Hepburn's dictionary's third edition took off, the romaji system
mainly came to be called by his name, and it became widely established,
particularly among foreigners dealing with Japan.</p>
<p>If you're interested in learning more about Hepburn's dictionaries, a <a href="http://www.meijigakuin.ac.jp/mgda/waei/">wealth
of information</a> is available via Meiji Gakuin University
Library, including a comparison of romaji in all published versions and
manuscripts.</p>
<h2 id="the-origins-of-the-nipponsiki-system"> The Origins of the Nipponsiki System</h2>
<p>Around the time the Romajikai was established, one of the members, <a href="https://en.wikipedia.org/wiki/Tanakadate_Aikitsu">Aikitu
Tanakadate</a>, developed his
own romaji system, based on some existing informal conventions, that was
specifically designed to mirror the structure of Japanese kana without regard
to foreign pronunciation.</p>
<p>In 1885 Tanakadate proposed this new system to the Romajikai, but they
ultimately rejected his proposal in favor of keeping Hepburn. As a result
Tanakadate left the Romajikai and promoted Nipponsiki on his own. Before
becoming known as "Nipponsiki" this style of Romanization was known as
"Tanakadatesiki".</p>
<p>The disagreement between Tanakadate was only the first in a long series of
arguments between Hepburn and Nipponsiki proponents.</p>
<p>Tanakadate was around 30 when he invented this system, and most of his later
career was in physics. He worked with Lord Kelvin in Scotland and helped bring
about the adoption of the metric system in Japan. He used romaji in personal
writings and promoted it throughout his life. We'll be seeing him again later.</p>
<h2 id="standard-form-and-the-romaji-hirome-kai"> Standard Form and the Romaji Hirome Kai</h2>
<p>In 1905 the ローマ字ひろめ会 (Romaji Hirome Kai, "Society for the Advancement
of Romaji") was established. They published a magazine, called simply "Rômaji",
to create more reading material in romaji and spread its use within Japan.  By
this point Toyama and Yatabe had both passed away, and it's unclear if the
original Romajikai still existed in any capacity. An important early member of
the new society was <a href="https://ja.wikipedia.org/wiki/%E8%97%A4%E5%B2%A1%E5%8B%9D%E4%BA%8C">Katsuji Fujioka</a>, who wrote the
<a href="https://dl.ndl.go.jp/info:ndljp/pid/942994">羅馬字手引</a> (Romaji Tebiki), a kind of romaji dictionary.</p>
<p>Shortly after it was founded the Romaji Hirome Kai proposed a slightly modified
Hepburn and called it 標準式, or "Standard Form". Note that this is "Standard
Form" in general, not "Standard Hepburn", suggesting this was some kind of
official standard romanization system; this may have been a response to
Tanakadatesiki becoming known as "Nipponsiki", which could imply that other
romaji systems were "foreign". As we'll see in a bit, this rhetorical trick
ultimately didn't help official adoption.</p>
<p>I haven't been able to track down the original document with Standard Form, but
the Romaji Tebiki was already using it in 1906.</p>
<p>Standard Form replaced macrons with circumflexes and always romanized ん as
"n", rather than sometimes using "m" depending on the following consonant.</p>
<p>Tanakadate was still around and joined the Romaji Hirome Kai at some point, but
got fed up with their use of Hepburn, left, and founded his own organization in
1914.</p>
<h2 id="the-origins-of-kunreisiki"> The Origins of Kunreisiki</h2>
<p>In 1930 the government formed a committee to evaluate various romaji systems
for official government use. At this point Tanakadate was a member of the
<a href="https://en.wikipedia.org/wiki/House_of_Peers_(Japan)">House of Peers</a>, and Romaji Hirome Kai member and Hepburn proponent
Fujioka was not a politician, but had political influence due to his long and
prominent career as a linguist. Both were involved with the government
committee.</p>
<p>While the system used at this point varied considerably by government agency,
Hepburn was more popular, so it seemed slated for official adoption.  However,
in 1935 Fujioka died of illness. In 1937, following a recommendation from the
committee, a slightly modified version of Tanakadate's Nipponsiki, dubbed
Kunreisiki, was established as the official government romaji system.</p>
<p>The main difference between Kunreisiki and Nipponsiki is that kana that are not
pronounced differently in standard modern Japanese are spelled as their more
common counterpart (づ and ず are both <em>zu</em>), though there are other
differences, like how particles are represented, and how ambiguous phonetic
boundaries are written.</p>
<h2 id="the-war"> The War</h2>
<p>Despite the recent official adoption of a government-approved romaji system,
around 1938 a number of more radical romaji proponents were arrested as
potential (or actual) anti-nationalists. One example was Esperantist and
language researcher <a href="https://ja.wikipedia.org/wiki/%E6%96%8E%E8%97%A4%E7%A7%80%E4%B8%80">Hidekatsu Saitou</a>, who contracted tuberculosis in
prison and died in 1940.</p>
<p>Following World War 2, the occupying American forces rescinded the law making
Kunreisiki official and ordered the use of Hepburn for public signage and
documents. During the occupation, an American educational commission
<a href="https://babel.hathitrust.org/cgi/pt?id=pur1.32754081234191&amp;view=1up&amp;seq=28">recommended native Japanese writing be replaced with romaji</a>.
This never happened, though romaji became a standard component of post-war
education.</p>
<p>Post-war the development of romaji became less dramatic, as serious proponents
of replacing Japanese writing systems with romaji mostly disappeared. There
have been a number of laws and rules issued by the government over the years,
as well as a few special systems like the <a href="https://en.wikipedia.org/wiki/JSL_romanization">unique system</a> developed for a
textbook called "Japanese: The Spoken Language", but Hepburn and
Nipponsiki/Kunreisiki remain the major systems.</p>
<p>There is also much to be written about interaction of romaji with computers,
but that's best left for another time.</p>
<h2 id="what-about-revised-hepburn%3F"> What About Revised Hepburn?</h2>
<p>Sometimes you'll see references to "Revised Hepburn", but nobody knows what
this is. It is used to mean, variously:</p>
<ul>
<li>Hepburn's system in his third edition, in contrast to earlier editions</li>
<li>the 1905 version by the ローマ字ひろめ会 (properly 標準式 or "standard form")</li>
<li>a version introduced with Kenkyuusha's "New Japanese-English Dictionary" in 1954, subsequently <a href="https://www.loc.gov/catdir/cpso/romanization/japanese.pdf">adopted by the American Library of Congress</a></li>
<li>other minor variants proposed at different times</li>
</ul>
<p>While the Library of Congress is surely consistent in their romaji usage, their
choice of a particular 1954 dictionary is a bit odd, and distinguishing it from
the similar 1905 system is a source of confusion. At one point it seemed like
Hepburn might become an ANSI standard, but instead Kunreisiki was adopted, and
that standard (Z39.11-1972) has since been deprecated. This lack of an official
standard contributes to inconsistency in what "Revised Hepburn" means.</p>
<p>In contrast, "traditional Hepburn" is somewhat reliably used to refer to the
system used in Hepburn's third edition as opposed to later forms.</p>
<p>Another common variant, "passport Hepburn" refers to the system previously
mandated for names on Japanese passports, which included some exceptions to
normal Hepburn, but those requirements are <a href="https://www.mofa.go.jp/mofaj/toko/passport/pass_4.html#q17">no longer strictly in force</a>,
and you can use any romanization you want (such as "George" for what would be
"Jouji" in Hepburn) if you have …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.dampfkraft.com/romaji-history.html">https://www.dampfkraft.com/romaji-history.html</a></em></p>]]>
            </description>
            <link>https://www.dampfkraft.com/romaji-history.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25108455</guid>
            <pubDate>Mon, 16 Nov 2020 05:39:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple Responds to macOS Privacy Concerns, Explains Why Apps Were Slow to Launch]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25108108">thread link</a>) | @svrma
<br/>
November 15, 2020 | https://www.iphoneincanada.ca/mac/apple-responds-to-macos-privacy-concerns-explains-why-apps-were-slow-to-launch/ | <a href="https://web.archive.org/web/*/https://www.iphoneincanada.ca/mac/apple-responds-to-macos-privacy-concerns-explains-why-apps-were-slow-to-launch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>


<!-- .entry-social-links -->
<div>
	
	
	
		
		
	
<!-- .entry-social-links -->	
		
		
	<div>
	<p><a href="https://cdn.iphoneincanada.ca/wp-content/uploads/2019/10/Apple_macOS-catalina-available-today_100719_big.jpg.large_.jpg"><img loading="lazy" src="https://cdn.iphoneincanada.ca/wp-content/uploads/2019/10/Apple_macOS-catalina-available-today_100719_big.jpg.large_.jpg" alt="" width="799" height="549" srcset="https://cdn.iphoneincanada.ca/wp-content/uploads/2019/10/Apple_macOS-catalina-available-today_100719_big.jpg.large_.jpg 799w, https://cdn.iphoneincanada.ca/wp-content/uploads/2019/10/Apple_macOS-catalina-available-today_100719_big.jpg.large_-350x240.jpg 350w, https://cdn.iphoneincanada.ca/wp-content/uploads/2019/10/Apple_macOS-catalina-available-today_100719_big.jpg.large_-768x528.jpg 768w, https://cdn.iphoneincanada.ca/wp-content/uploads/2019/10/Apple_macOS-catalina-available-today_100719_big.jpg.large_-640x440.jpg 640w, https://cdn.iphoneincanada.ca/wp-content/uploads/2019/10/Apple_macOS-catalina-available-today_100719_big.jpg.large_-660x453.jpg 660w, https://cdn.iphoneincanada.ca/wp-content/uploads/2019/10/Apple_macOS-catalina-available-today_100719_big.jpg.large_-560x385.jpg 560w" sizes="(max-width: 799px) 100vw, 799px"></a></p>
<p><a href="https://www.iphoneincanada.ca/news/privacy-concerns-emerge-following-apple-ocsp-server-outage/">Following privacy concerns from Mac users after Apple’s Online Certificate Status Protocol (OCSP) server went down, </a>thus causing third-party applications unable to open on Macs, Apple has now responded to the situation,&nbsp; exacerbated by a recent blog post by Jeffrey Paul.</p>	
	
	
	
<p>An Apple spokesperson told<em> iPhone in Canada</em> it had updated its support document, ‘Safely open apps on your Mac’, to now further detail its privacy protections.</p>
<p>“Gatekeeper performs online checks to verify if an app contains known malware and whether the developer’s signing certificate is revoked,” <a href="https://support.apple.com/en-us/HT202491">explains</a> Apple. “We have never&nbsp;combined data from these checks with information about Apple users or their devices. We do not use data from these checks to learn what individual users are&nbsp;launching or running on their devices,” clarified the company.</p>
<p>“Notarization checks if the app contains known malware using an encrypted connection that is resilient to server failures,” says Apple, further emphasizing, “These security checks have never included the user’s Apple ID or the identity of their device. To further protect privacy, we have stopped logging IP addresses&nbsp;associated with Developer ID certificate checks, and we will ensure that any collected IP addresses are removed from logs,” details Apple.</p>
<p>On top of this, Apple says “over the next year we will introduce several changes to our security checks,” specifically:</p>
<ul>
<li>a new encrypted protocol for Developer ID certificate revocation checks</li>
<li>strong protections against server failure</li>
<li>a new preference for users to opt out of these security protections</li>
</ul>
<p>Apple also gave some further technical information on the situation to <em>iPhone in Canada.</em> Certificate revocation checks occur to verify that Developer ID certificates used to sign an app have not been revoked by the company. The move is critical for security since a certificate may be pulled if a developer suspects it has been compromised by third parties, or is being used to sign malicious apps.</p>
<p>The industry-standard online certificate status protocol (OCSP) is used by macOS to verify that the Developer ID code signing certificate issued to an app developer has not been revoked. This OCSP request does not include the Apple ID of the user, or reveal a device or app being launched.</p>
<p>Apple says since OCSP is used to check other certificates, including those used to encrypted web connections, these requests happen over unencrypted HTTP, as normal throughout the industry.</p>
<p>HTTP is used to prevent&nbsp;situations where verifying the validity of the certificate that secures the connection to an OCSP server would potentially depend on the result of a request to that same&nbsp;OCSP server, creating a loop that would make it impossible to resolve the request, according to Apple.</p>
<p>Apple says on macOS Catalina and later, by default, all apps running are notarized by the company to note they have been checked by Apple for known malicious software. When an app launches, macOS will check to verify that the app has not been labeled as malicious by Apple since it was first notarized. These checks happen over an encrypted connection—and are resilient to server failures. Which is what happened the other day and users saw their apps hang and take forever to launch.</p>
<p>What caused the OCSP server problem? Apple says it was due to a server-side misconfiguration that specifically interfered with macOS being able to cache OCSP responses for Developer ID. This configuration error, along with an unrelated content delivery network (CDN) misconfiguration, is what caused the slow performance for apps to launch.</p>
<p>Apple explained to <em>iPhone in Canada</em> it has already fixed this performance issue through a server-side update, that will now allow macOS to cache Developer ID OCSP checks for a longer period. macOS users do not need to do anything to benefit from this Apple update.</p>
<p>App notarization checks are used to verify that apps being launched in macOS have not been found to be malicious by Apple, since they were first notarized. Apple says these checks take place over an encrypted connection and are immune to server failures. Notarization checks were not affected by the server-side issue that caused OCSP requests to fail.</p>

	</div>

</div><!-- .entry-inner -->
</article></div>]]>
            </description>
            <link>https://www.iphoneincanada.ca/mac/apple-responds-to-macos-privacy-concerns-explains-why-apps-were-slow-to-launch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25108108</guid>
            <pubDate>Mon, 16 Nov 2020 04:44:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Improve ADS-B Reception with Your Software-Defined Radio]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25107487">thread link</a>) | @gp10
<br/>
November 15, 2020 | https://www.onesdr.com/2020/11/16/how-to-improve-ads-b-reception/ | <a href="https://web.archive.org/web/*/https://www.onesdr.com/2020/11/16/how-to-improve-ads-b-reception/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
			
<p>Automatic dependent surveillance–broadcast&nbsp;(ADS-B) technology enables aircraft to&nbsp;determine their position via satellite and periodically broadcast this location information. An ADS-B receiver system can be used to decode this broadcast signal to track airplanes. </p>



<div><figure><img loading="lazy" src="https://www.onesdr.com/wp-content/uploads/2020/11/ads-b-system-1024x576.png" alt="" width="473" height="266" srcset="https://www.onesdr.com/wp-content/uploads/2020/11/ads-b-system-1024x576.png 1024w, https://www.onesdr.com/wp-content/uploads/2020/11/ads-b-system-300x169.png 300w, https://www.onesdr.com/wp-content/uploads/2020/11/ads-b-system-768x432.png 768w, https://www.onesdr.com/wp-content/uploads/2020/11/ads-b-system-1536x864.png 1536w, https://www.onesdr.com/wp-content/uploads/2020/11/ads-b-system.png 1600w" sizes="(max-width: 473px) 100vw, 473px"><figcaption>The ADS-B System</figcaption></figure></div>



<p>Now let’s take a look at the various components of an ADS-B station, why they matter, and how to make improvements. </p>



<h2><strong>ADS-B Receiver</strong></h2>



<p>In <a href="https://www.onesdr.com/2020/10/21/the-best-ads-b-receiver-for-2020-2021/">this article we previously discussed the different ADS-B receivers</a> on the market today. Systems like the one from <a href="https://amzn.to/36E08h1">Garmin</a> are completely closed and fully integrated and there’s not much opportunity to understand how they work or improve them. The best you can do is use them as per the manufacturer’s recommendation and that should result in the best performance for this product.</p>







<p>On the other hand, there’s plenty of opportunity to learn from open systems based on  either the <a href="https://amzn.to/3f4pJUk">FlightAware</a> or the <a href="https://amzn.to/3kzQa59">Stratux ADS-B receivers</a>. </p>







<p>Both these systems use <a href="https://amzn.to/3f0RHjH">the RTL-SDR</a> as foundational building blocks. There’s a wealth of information online on the internal architecture and various experiments conducted on these products to understand their specifications, performance and how best to use them. There’s also a large online community to learn from and contribute to. </p>



<h2>How Much ADS-B Signal Do You Really Need?</h2>



<p>In general when a receiver processes signals, there is a range of optimal signal level over which it performs best. Anything lower will result in performance degradation – in other words, you will see fewer airplanes. Anything greater will have the same effect. </p>



<div><figure><img loading="lazy" src="https://www.onesdr.com/wp-content/uploads/2020/11/ADS-B-SIGNAL-LEVELS-1024x677.png" alt="" width="495" height="327" srcset="https://www.onesdr.com/wp-content/uploads/2020/11/ADS-B-SIGNAL-LEVELS-1024x677.png 1024w, https://www.onesdr.com/wp-content/uploads/2020/11/ADS-B-SIGNAL-LEVELS-300x198.png 300w, https://www.onesdr.com/wp-content/uploads/2020/11/ADS-B-SIGNAL-LEVELS-768x508.png 768w, https://www.onesdr.com/wp-content/uploads/2020/11/ADS-B-SIGNAL-LEVELS.png 1202w" sizes="(max-width: 495px) 100vw, 495px"><figcaption>Different ADS-B Signal Ranges </figcaption></figure></div>



<p>At the very extreme, signal levels higher than a certain level will damage the ADS-B receiver. The trick then is to optimize the signal level such that you can get to within the sweet spot of the ADS-B receiver. </p>



<h2><strong>A Note on Measuring Signals </strong></h2>



<p>In general, it is very difficult to predict actual wireless signal strengths received without making a measurement. Typically a spectrum analyzer is used to make signal measurements at any given frequency. However, not everyone can afford a spectrum analyzer or has access to one. Fortunately it is possible to use an application like SDR# with your receiver to determine how strong or weak various received signals actually are and the impact they might be having on performance.</p>



<p>Here is an example of signal measurement with <a href="https://amzn.to/3f0RHjH">the RTL-SDR</a> as viewed in SDR#. The two views shown are the FFT view and the waterfall or spectrogram below it.</p>



<figure><img loading="lazy" width="1024" height="593" src="https://www.onesdr.com/wp-content/uploads/2019/11/FM-before-1024x593.jpg" alt="" srcset="https://www.onesdr.com/wp-content/uploads/2019/11/FM-before-1024x593.jpg 1024w, https://www.onesdr.com/wp-content/uploads/2019/11/FM-before-300x174.jpg 300w, https://www.onesdr.com/wp-content/uploads/2019/11/FM-before-768x445.jpg 768w, https://www.onesdr.com/wp-content/uploads/2019/11/FM-before.jpg 1916w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>FM signals measured with <a href="https://amzn.to/3f0RHjH">the RTL-SDR</a></figcaption></figure>



<p>As you experiment with different antennas and other components below, tune across the frequency range of <a href="https://amzn.to/3f0RHjH">the RTL-SDR</a> to check out various signals and their strengths in the waterfall view. This will give you an idea of how your changes impact performance. It will for instance tell you approximately how much gain you need to add up front. It will also tell you if you actually need any amplification at all. In general avoid doing anything that increases the <strong><span>RED</span></strong> levels as these are very strong signals. </p>



<p>Now let’s take a look at the various parts of the ADS-B system and how they impact performance.</p>



<h2>Antennas</h2>



<p>The antenna is at the very front-end of your ADS-B system. You will need an effective <a href="https://amzn.to/3cyPXNr">antenna for ADS-B</a> as it is key to good signal reception. As is often said, garbage in, garbage out. If you use a lousy antenna, a good receiver isn’t going to compensate for it. You can read our complete <a href="https://www.onesdr.com/2020/04/19/best-antennas-for-ads-b-reception/">review of ADS-B antennas</a>. The best antenna requires some effort for installation and optimization but it’s well worth the time spent. </p>



<h2>RF Cables</h2>



<p>If you’re looking to mount your antenna on your rooftop or on a tower for better reception, you will need to take the length of the RF cable from the antenna to your ADS-B receiver into consideration. Why is that?</p>



<div><figure><img loading="lazy" src="https://www.onesdr.com/wp-content/uploads/2020/11/Installing-an-antenna-on-rooftop-1024x576.png" alt="" width="553" height="311" srcset="https://www.onesdr.com/wp-content/uploads/2020/11/Installing-an-antenna-on-rooftop-1024x576.png 1024w, https://www.onesdr.com/wp-content/uploads/2020/11/Installing-an-antenna-on-rooftop-300x169.png 300w, https://www.onesdr.com/wp-content/uploads/2020/11/Installing-an-antenna-on-rooftop-768x432.png 768w, https://www.onesdr.com/wp-content/uploads/2020/11/Installing-an-antenna-on-rooftop-1536x864.png 1536w, https://www.onesdr.com/wp-content/uploads/2020/11/Installing-an-antenna-on-rooftop.png 1600w" sizes="(max-width: 553px) 100vw, 553px"><figcaption>Installing an Antenna on your Rooftop</figcaption></figure></div>



<p>As the frequency of the signal increases, so do the signal losses or attenuation due to any given length of cable. For instance, if you were to use <a href="https://amzn.to/36DJJcj">LMR-400 cable</a>, the loss at 30 MHz is only 0.7 dB for every 100 ft of cable. For the same length of cable, the loss at 1090 MHz is around 4 dB. This signal loss directly impacts the sensitivity of the system by 4 dB and therefore reduces the range of your ADS-B receiver by more than half relative to if you were to use a very short length of cable. That is quite significant.</p>



<h2>Amplifiers</h2>



<p>Fortunately there is a way to compensate for this degradation in sensitivity due to cable loss. It involves the use of a low noise amplifier (LNA). In general, any LNA with sufficiently low noise figure (typically less than 1 dB) and the required amount of gain can be used. </p>



<p>So the first question is – what is the required gain? </p>



<p>The answer depends on several factors some of which are:</p>



<ul><li>Amount of cable loss at 1090 MHz</li><li>Other RF signals are present in your environment – in particular strong ones</li><li>The dynamic and operating range of your ADS-B receiver</li></ul>



<p>As discussed, cable loss can be overcome with the use of an LNA. However, an LNA will amplify everything within its range of operation. It will amplify AM, FM and other signals. Consider a situation where an FM signal is stronger than the ADS-B signal of interest. The amplified signal will saturate the receiver if it exceeds the dynamic range. The signal will also possibly damage the receiver if you’re operating at signal levels that exceed the range of the receiver. The receiver will not be able to process the ADS-B signal of interest in either case.</p>



<figure><img loading="lazy" width="1024" height="576" src="https://www.onesdr.com/wp-content/uploads/2020/11/LNA-1-1024x576.png" alt="Block diagram showing ADS-B signal amplified" srcset="https://www.onesdr.com/wp-content/uploads/2020/11/LNA-1-1024x576.png 1024w, https://www.onesdr.com/wp-content/uploads/2020/11/LNA-1-300x169.png 300w, https://www.onesdr.com/wp-content/uploads/2020/11/LNA-1-768x432.png 768w, https://www.onesdr.com/wp-content/uploads/2020/11/LNA-1-1536x864.png 1536w, https://www.onesdr.com/wp-content/uploads/2020/11/LNA-1.png 1600w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Amplifying an ADS-B signal</figcaption></figure>



<p>A solution to this problem is to use a Filtered LNA. This is an LNA with a filter integrated along with it as shown in the picture below.</p>



<figure><img loading="lazy" width="1024" height="576" src="https://www.onesdr.com/wp-content/uploads/2020/11/LNA-2-1024x576.png" alt="Filtered LNA for ADS-B" srcset="https://www.onesdr.com/wp-content/uploads/2020/11/LNA-2-1024x576.png 1024w, https://www.onesdr.com/wp-content/uploads/2020/11/LNA-2-300x169.png 300w, https://www.onesdr.com/wp-content/uploads/2020/11/LNA-2-768x432.png 768w, https://www.onesdr.com/wp-content/uploads/2020/11/LNA-2-1536x864.png 1536w, https://www.onesdr.com/wp-content/uploads/2020/11/LNA-2.png 1600w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Filtered Low Noise Amplifier for ADS-B</figcaption></figure>



<p>The LNA is usually the first component and it is followed by a filter specific to the band of interest – in this case 1090 MHz for ADS-B. This product will reject all signals outside the ADS-B frequency range. For instance it will reject strong FM signals, 4G signals from cellular base stations, signals at 2.4 GHz from your Wi-Fi access point and more. </p>



<p>Here are a couple of ADS-B filtered LNAs that will work depending on your setup.</p>







<p>Use <a href="https://gpio.com/collections/filtered-low-noise-amplifier/products/ads-b-filtered-dual-low-noise-amplifier-lna-with-30-db-gain">this Filtered LNA with 30 dB gain</a> if you have a very long cable run and need to compensate for significant signal loss. Using the calculation for LMR400 above, this Filtered LNA can compensate for 700 ft of cable loss. </p>



<p>Use <a href="https://gpio.com/collections/filtered-low-noise-amplifier/products/ads-b-filtered-low-noise-amplifier-lna-with-15-db-gain">this Filtered LNA that provides 15 dB gain</a>, if you have a shorter cable run. </p>



<h3><strong>How to Install an LNA</strong></h3>



<p>It is best to place the LNA very close to the antenna. This will help minimize the noise figure and improve the sensitivity of your ADS-B receiver system. Since it’s difficult to get a power source or supply at the top of an antenna, <a href="https://www.onesdr.com/2020/01/19/what-is-a-bias-tee/">a bias tee system</a> can be used. A bias tee at the receiver is used to send the DC voltage up to the LNA over the RF cable connecting the two. At the LNA there is a reciprocal bias tee that splits the DC and RF signals. The DC is used to power the LNA. The block diagram below shows a situation where the SDR has a built-in bias tee. This is indeed the case with <a href="https://amzn.to/3f0RHjH">the RTL-SDR</a>.</p>



<figure><img loading="lazy" width="1024" height="576" src="https://www.onesdr.com/wp-content/uploads/2020/03/bias-tee-modules-1-1024x576.png" alt="" srcset="https://www.onesdr.com/wp-content/uploads/2020/03/bias-tee-modules-1-1024x576.png 1024w, https://www.onesdr.com/wp-content/uploads/2020/03/bias-tee-modules-1-300x169.png 300w, https://www.onesdr.com/wp-content/uploads/2020/03/bias-tee-modules-1-768x432.png 768w, https://www.onesdr.com/wp-content/uploads/2020/03/bias-tee-modules-1.png 1280w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Use a Bias Tee to Power a Remote LNA</figcaption></figure>



<p>Sometimes when an LNA is connected the results look like in the following picture – amazing results with a tripling of the number of planes observed!</p>



<div><figure><img loading="lazy" width="940" height="529" src="https://www.onesdr.com/wp-content/uploads/2020/11/ads-b-improvement.jpg" alt="" srcset="https://www.onesdr.com/wp-content/uploads/2020/11/ads-b-improvement.jpg 940w, https://www.onesdr.com/wp-content/uploads/2020/11/ads-b-improvement-300x169.jpg 300w, https://www.onesdr.com/wp-content/uploads/2020/11/ads-b-improvement-768x432.jpg 768w" sizes="(max-width: 940px) 100vw, 940px"><figcaption>Improvement in Number of Planes Tracked</figcaption></figure></div>



<p>At other times, the addition of an LNA degrades performance and you will not be able to see any airplanes. Why does this happen? Let’s assume that your LNA is connected properly with the RF input end connected to the antenna and that it is powered correctly. There are then two possibilities:</p>



<ul><li><strong>Too much cable loss</strong> and the amount of LNA gain cannot help overcome this degradation. In this situation more gain is required and you can simply add another LNA. Remember to place the first LNA as close to the antenna as possible so as to minimize noise figure. Remember also to check signal levels so you can adjust the amplitude to be within the optimal range. </li><li><strong>Too much gain </strong>and you are likely saturating your receiver with strong signals. Note that even when using a filtered LNA, if the FM signals in your area are very strong, the out-of-band attenuation due to the filter might not be adequate to prevent receiver saturation. Once again you can check what’s going on with the spectrum analyzer view in SDR#. </li></ul>



<h3><strong>How to Optimize the Signal Levels into the RTL-SDR</strong></h3>



<p>There are three methods by which you can optimize signal levels going into the RTL-SDR after the addition of a Filtered LNA.</p>



<p>In the event that you have strong out-of-band signals, they should be attenuated to a reasonable level. The easiest way to do this is by adding an additional <a href="https://www.tindie.com/products/gpio/ads-b-bandpass-filter-band-pass-1090-mhz-ads-b/">ADS-B bandpass filter</a> after the Filtered LNA.</p>



<p>Another way to optimize gain is to reduce the signal level across the band with an attenuator. Connect <a href="https://amzn.to/2K4a4IY">an inline fixed attenuator</a> to the output of the LNA. You can experiment with different values such as 30 dB, 20 dB, etc. until you start seeing output by way of planes. </p>







<p>The third method is to adjust the gain in the Flightaware stick digitally. The <a href="https://amzn.to/3f4pJUk">FlightAware</a> stick is essentially an <a href="https://amzn.to/3f0RHjH">RTL-SDR</a> and utilizes an R802T chipset. Below is a block diagram of the R802T.</p>



<div><figure><img loading="lazy" src="https://www.onesdr.com/wp-content/uploads/2020/11/R820T-block-1024x689.png" alt="" width="540" height="363" srcset="https://www.onesdr.com/wp-content/uploads/2020/11/R820T-block-1024x689.png 1024w, https://www.onesdr.com/wp-content/uploads/2020/11/R820T-block-300x202.png 300w, https://www.onesdr.com/wp-content/uploads/2020/11/R820T-block-768x517.png 768w, https://www.onesdr.com/wp-content/uploads/2020/11/R820T-block.png 1498w" sizes="(max-width: 540px) 100vw, 540px"><figcaption>R802T Architecture</figcaption></figure></div>



<p>As you can see the user has the ability to modify the Variable Gain Amplifier (VGA). The range over which this can be varied is nearly 50 dB. The <a href="https://amzn.to/3f4pJUk">FlightAware</a> powers up with maximum amplification in the system. So you essentially have to adjust it to a point where you get the best reception. <a href="https://discussions.flightaware.com/t/for-beginners-how-to-set-change-gain/30201">Here are instructions on how to modify the gain</a>. </p>



<p>Many experiments have been conducted and reported on the <a href="https://amzn.to/3f4pJUk">FlightAware</a> discussion site. <a rel="noreferrer noopener" href="https://discussions.flightaware.com/t/gain-adjustment/18376/7" target="_blank">Here is one such discussion</a>. In the plot below, user BartJr has reported an improvement in reception with increase in amplification.</p>



<div><figure><img loading="lazy" width="777" height="392" src="https://www.onesdr.com/wp-content/uploads/2020/11/rtl-vga-inc.png" alt="" srcset="https://www.onesdr.com/wp-content/uploads/2020/11/rtl-vga-inc.png 777w, https://www.onesdr.com/wp-content/uploads/2020/11/rtl-vga-inc-300x151.png 300w, https://www.onesdr.com/wp-content/uploads/2020/11/rtl-vga-inc-768x387.png 768w" sizes="(max-width: 777px) 100vw, 777px"><figcaption>Reception Varies with VGA Gain</figcaption></figure></div>



<p>By contrast below are the results reported by user ieand who has …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.onesdr.com/2020/11/16/how-to-improve-ads-b-reception/">https://www.onesdr.com/2020/11/16/how-to-improve-ads-b-reception/</a></em></p>]]>
            </description>
            <link>https://www.onesdr.com/2020/11/16/how-to-improve-ads-b-reception/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25107487</guid>
            <pubDate>Mon, 16 Nov 2020 02:59:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Can't open apps on macOS: an OCSP disaster waiting to happen – CryptoHack Blog]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25107315">thread link</a>) | @hongsy
<br/>
November 15, 2020 | https://blog.cryptohack.org/macos-ocsp-disaster | <a href="https://web.archive.org/web/*/https://blog.cryptohack.org/macos-ocsp-disaster">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
        <div>
<article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Two days ago, macOS users experienced worrying hangs when opening applications not downloaded from the Mac App Store. Many users suspected hardware issues with their devices, but as they took to social media, they found it was a widespread problem. And it was no coincidence that it was happening so soon after the launch of macOS “Big Sur”.</p>

<p>Eventually, <a href="https://twitter.com/lapcatsoftware/status/1326990296412991489">a tweet by Jeff Johnson</a> pinpointed the underlying issue. Apple’s “OCSP Responder” service was overloaded, therefore macOS was unable to verify app developers’ cryptographic certificates.</p>

<p><img src="https://blog.cryptohack.org/assets/images/apple-tweet.png?style=centerme" alt="Jeff Johnson's tweet"></p>

<p>But why are OCSP Responders in the critical path of apps launching? This post will briefly discuss code signing, how Online Certificate Status Protocol (OCSP) works, why it’s deeply flawed, and what are some better alternatives. Unlike other posts on this incident, I want to emphasise the practical crypto aspects (at a high level) and offer a balanced perspective.</p>

<h3 id="code-signing">Code Signing</h3>

<p>On their developer portal, Apple explain <a href="https://developer.apple.com/support/code-signing/">the purpose of code signing</a>:</p>

<blockquote>
  <p>Code signing your app assures users that it is from a known source and the app hasn’t been modified since it was last signed. Before your app can integrate app services, be installed on a device, or be submitted to the App Store, it must be signed with a certificate issued by Apple.</p>
</blockquote>

<p>In other words, if developers want their apps to be trusted on macOS, they must sign them using a certificate keypair provided by Apple. Apple gives each developer a unique “Developer ID” certificate, which includes a private key for the developer to use, and a public key for distribution. The developer uses the private key to produce cryptographic signatures on their apps as part of their release process.</p>

<p>When you run an app, its signature is verified against the public key of the developer’s certificate. Then, the certificate itself is verified, by checking that it hasn’t expired yet (certificates are typically valid for 1 year), and that it’s ultimately signed by Apple’s root certificate. There may also be intermediate certificates as part of the chain up to the root certificate.</p>

<p>This is similar to the TLS Public Key Infrastructure used on the internet. But it’s also fundamentally different since Apple has total control over its own chain of trust. Other certificate authorities are not allowed to issue valid certificates for code signing as all certificates must chain back up to Apple.</p>

<p>If the verification process wasn’t successful, then users will see a scary dialogue which is difficult to bypass:</p>

<p><img src="https://blog.cryptohack.org/assets/images/apple-failed-verify.png?style=centerme" alt="Apple failed to verify popup"></p>

<h3 id="revocation">Revocation</h3>

<p>What happens when a developer is found to be breaching Apple’s rules, or loses control of their private key? A certificate authority needs to be able to instantly nullify bad certificates they’ve issued. If a certificate is being used maliciously, it’s not acceptable to wait days or months until it expires naturally, otherwise a leak of a high-profile private key would render the whole system useless.</p>

<p>This is where certificate revocation comes in. It’s an additional step in the signature verification process, which involves finding out from the certificate authority if a certificate is still valid.</p>

<p>Originally, at least on the web, this was done the simplest way you can imagine. The certificate authority would give you a Certificate Revocation List (CRL), containing serial numbers of all revoked certificates, and you could check the certificate you are currently verifying is not on the list. However, this approach stopped being used by web browsers since the list got longer and longer and failed to scale. Especially after terrifying exploits like <a href="https://en.wikipedia.org/wiki/Heartbleed">Heartbleed</a> demanded mass revocation of certificates.</p>

<p>Online Certificate Status Protocol (OCSP) is an alternative allowing real-time checking of certificates. Each certificate can include a baked-in “OCSP Responder”, a URL that you can query that will report whether the certificate has been revoked. In Apple’s case, that’s “ocsp.apple.com”. So now, in addition to verifying the cryptographic validity of the signature, each time you launch an app you’re performing a real-time check with Apple (subject to some caching) to ensure they still think the developer’s ID certificate is legitimate.</p>

<h3 id="ocsps-availability-problem">OCSP’s Availability Problem</h3>

<p>There’s a huge problem with OCSP: it makes an external service a single point of failure. What happens if the OCSP Responder is down or unreachable? Do we just refuse to verify the certificate (hard-fail)? Or do we pretend that the check was successful (soft-fail)?</p>

<p>Apple are forced to use the soft-fail behaviour, otherwise apps wouldn’t work when you’re offline. As it happens, all major browsers also implement the soft-fail behaviour, since OCSP Responders have traditionally been unreliable, and browsers want to keep displaying websites even if certificate authorities’ responders are temporarily down.</p>

<p>But soft-fail isn’t great, because it means that an attacker with network control can block requests to the responder, and the revocation check will be skipped. In fact, that was the hotfix widely shared on Twitter during this incident: blackhole traffic to “ocsp.apple.com” by adding a line to <em>/etc/hosts</em>. A lot of people won’t be removing that line anytime soon, since disabling OCSP doesn’t cause any noticeable problems.</p>

<h3 id="the-incident">The Incident</h3>

<p>If Apple’s OCSP check was built to soft-fail, then why did apps hang when the OCSP Responder was down? Probably because this was actually a different failure case: the OCSP Responder was not completely down, it was performing badly.</p>

<p>Due to the load added by millions of users worldwide upgrading to macOS “Big Sur”, Apple’s servers slowed to a crawl, and although they weren’t properly answering OCSP queries, they were working just enough that the soft-fail didn’t trigger.</p>

<h3 id="ocsps-privacy-problem">OCSP’s Privacy Problem</h3>

<p>In addition to OCSP’s availability problems, the protocol wasn’t initially designed with privacy in mind. A basic OCSP query involves an unencrypted HTTP request to the OCSP Responder with the serial number of the certificate. Therefore not only can the responder figure out what certificate you are interested in, but so can your ISP and anybody else intercepting packets. Apple could use this to build a timeline of which developers’ apps you are opening, as could third parties.</p>

<p><img src="https://blog.cryptohack.org/assets/images/apple-ocsp-wireshark.jpg?style=centerme" alt="OCSP packet in wireshark"></p>

<p>Adding encryption is possible, and there’s a better, more private version called <a href="https://en.wikipedia.org/wiki/OCSP_stapling">OCSP stapling</a>, but Apple is not using either of these things.</p>

<h3 id="a-better-future">A Better Future</h3>

<p>This incident has started a lively debate in the software community, with one side proclaiming <a href="https://sneak.berlin/20201112/your-computer-isnt-yours/">“Your Computer Isn’t Yours”</a> and the other arguing that <a href="https://www.security-embedded.com/blog/2020/11/14/application-trust-is-hard-but-apple-does-it-well">“application trust is hard but Apple does it well”</a>. This post aims to show that whichever side you agree with, OCSP is a terrible way to manage certificate revocation, and will lead to more availability and privacy incidents in future. In my opinion, it was a poor engineering decision for Apple to make app launching dependent on OCSP. In the short term at least they have mitigated the damage by <a href="https://lapcatsoftware.com/articles/ocsp.html">increasing the time that responses are cached</a>.</p>

<p>Fortunately, a better revocation method is reaching maturity. CRLite is a way to shrink down lists of all revoked certificates to a reasonable size. <a href="https://scotthelme.co.uk/crlite-finally-a-fix-for-broken-revocation/">Scott Helme’s blog</a> gives a good summary of how CRLite uses Bloom Filters to make the Certificate Revocation List approach – which OCSP superseded – feasible again.</p>

<p>Theoretically, macOS devices could pull updates to this list periodically and do certificate revocation checking on the device itself, addressing the availability and privacy problems with OCSP. On the other hand, since the list of revoked Developer ID certificates is much smaller than the list of all revoked PKI certificates, it’s worth asking why Apple haven’t opted to use CRLs in the first place. Perhaps they don’t want to reveal any information about which certificates they’ve revoked.</p>

<h3 id="conclusion">Conclusion</h3>

<p>Overall, the incident this week was a good time to reflect on the trust model that has been promoted by organisations like Apple and Microsoft. Malware has grown in sophistication and most people aren’t in a position to judge whether it’s safe to run particular binaries. Code signing seems like a neat way to leverage cryptography to determine whether or not to trust applications, and to at least associate apps with known developers. And revocation is a necessary part of maintaining that trust.</p>

<p>However, by adding several mundane failure modes to the verification process, OCSP spoils any cryptographic elegance the code signing and verifying process has. While OCSP is also widely used for TLS certificates on the internet, the large number of PKI certificate authorities and relaxed attitude of browsers means that failures are less catastrophic. Moreover, people are accustomed to seeing websites become unavailable from time to time, but they don’t expect the same from apps on their own devices. macOS users were alarmed at how their apps could become collateral damage for an infrastructure issue at Apple. Yet this was an inevitable outcome arising from the fact that certificate verification depends on external infrastructure, and no infrastructure is 100% reliable.</p>

<p>Scott Helme also has concerns about the power that Certificate Authorities gain when certification revocation actually works effectively. Even if you aren’t bothered about the potential for censorship, there will be occasional mistakes and these must be weighed against the security benefits. As one developer discovered when <a href="https://blog.charliemonroe.net/a-day-without-business/">Apple mistakenly revoked his certificate</a>, the risk of working within a locked down platform is that you may get locked out.</p>

  </div>
</article>
</div>

    </div></div>]]>
            </description>
            <link>https://blog.cryptohack.org/macos-ocsp-disaster</link>
            <guid isPermaLink="false">hacker-news-small-sites-25107315</guid>
            <pubDate>Mon, 16 Nov 2020 02:32:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why It Is Almost 6 Times Harder for Black Founders–and Why You Should Care]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25107008">thread link</a>) | @jkuria
<br/>
November 15, 2020 | https://www.theblackownedbusiness.org/post/6-times-harder-black-founders | <a href="https://web.archive.org/web/*/https://www.theblackownedbusiness.org/post/6-times-harder-black-founders">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.theblackownedbusiness.org/post/6-times-harder-black-founders</link>
            <guid isPermaLink="false">hacker-news-small-sites-25107008</guid>
            <pubDate>Mon, 16 Nov 2020 01:40:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pope’s November prayer intention: that progress in robotics and AI “be human”]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25106937">thread link</a>) | @jelliclesfarm
<br/>
November 15, 2020 | https://www.vaticannews.va/en/pope/news/2020-11/pope-francis-november-prayer-intention-robotics-ai-human.html | <a href="https://web.archive.org/web/*/https://www.vaticannews.va/en/pope/news/2020-11/pope-francis-november-prayer-intention-robotics-ai-human.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>In his video message on his prayer intention for November, Pope Francis emphasizes that progress in robotics and artificial intelligence (AI) be oriented “towards respecting the dignity of the person and of Creation”.</p><div itemprop="articleBody">
            <p><b><i>By Vatican News staff writer</i></b></p> 
<p>During the month of November, Pope Francis draws our attention to the epochal change that humanity is experiencing thanks to advances in artificial intelligence. &nbsp;He, therefore, invites us to pray that this progress always “serve humankind,” respecting human dignity and taking care of Creation.</p> 
<h2><b>True progress</b></h2> 
<p>Artificial Intelligence (AI) has made exponential advances, as evidenced by its many applications in different fields of knowledge. Today, 37% of organizations in the world have implemented AI in some way (which represents a 270% increase in the past four years).</p> 
<p>In “<a href="https://thepopevideo.org/" rel="external nofollow" target="_blank">The Pope Video</a>” this month, Pope Francis clarifies that this progress in robotics and AI “can make a better world possible if it is joined to the common good.” &nbsp;In this sense, he hopes for technological progress that does not increase the inequalities in society.&nbsp; If it does, the Pope says, it will not be “true progress”.&nbsp; Such progress does not take into account the dignity of the human person and care for Creation.</p> 
<h2><b>Benefits</b></h2> 
<p>AI is capable of addressing many problems facing humanity, such as in evaluating the learning capacity of students, in order to detect opportunities for improvement.&nbsp; It can help people with visual or hearing impairments by developing better communication tools (such as converting text to speech or speech to text).&nbsp; AI can also speed up the collection, processing and diffusion of health data to improve the diagnosis and treatment of patients, especially those living in remote areas.</p> 
<p>The same applies to the field of ecology. Through AI, it is possible to analyze data on climate change and create models that can help predict natural disasters. It can also be used to create intelligent and sustainable cities by reducing urban spending, improving the resilience of highways and increasing energy efficiency.&nbsp; There are vast possibilities for using this technological progress for the common good, and “The Pope Video” uses images from the Italian Institute of Technology and the Italian multinational energy company, Enel, to show some of these benefits.</p> 
<h2><b>Serving humanity&nbsp;</b></h2> 
<p>“Innovation,” says Enel’s CEO, Francesco Starace, “has placed at our disposition extraordinary tools that we need to be capable of using in the best possible way.”&nbsp;</p> 
<p>He continues, “As Pope Francis reaffirms, it is our task to ensure that the resulting benefits are distributed fairly and create opportunities and wellbeing.” Starace says, “In order to give a positive orientation to our actions and choices regarding the present and the future, we must put respect for people and for the environment at the centre, adopting a vision based on sustainability. Only in this way can technological evolution be an ally of humanity and create opportunities which, up until a few years ago, we couldn’t even imagine.”</p> 
<p>The Pope’s <a href="https://www.popesprayer.va/" rel="external">Worldwide Prayer Network</a> is responsible for the diffusion of the Pope’s monthly prayer intentions. &nbsp;In comments on the Holy Father’s prayer intention for November, the network’s international director, Jesuit Father Frédéric Fornos also speaks of the need to channel these rapid technological changes for the “good of all.”</p> 
<p>“This month’s prayer intention,” he says, “reinforces the idea that the benefit that humanity has obtained (and will continue to obtain) from technological progress must always take into account as well, and in parallel, ‘adequate development of responsibility and values’.”&nbsp; This, Fr Fornos says, has been underscored by the Pope in his encyclical <i>Laudato si’ </i>and now in his third encyclical, <i>Fratelli tutti,</i> where he says, “How wonderful it would be if the growth of scientific and technological innovation could come with more equality and social inclusion!”</p> 
<p>AI, robotics, and other applications of technology, says Fr Fornos, open great challenges for ethics and social justice. “This is why the Pope’s most recent petition is important: to pray that this progress will always ‘be human.’”</p> 
<p><b>The text of the November 2020 prayer intention:</b></p> 
<p><i>Artificial intelligence is at the heart of the epochal change we are experiencing.&nbsp; Robotics can make a better world possible if it is joined to the common good.&nbsp; Indeed, if technological progress increases inequalities, it is not true progress.&nbsp; Future advances should be oriented towards respecting the dignity of the person and of Creation.&nbsp;</i></p> 
<p><i>Let us pray that the progress of robotics and artificial intelligence may always serve humankind… we could say, may it “be human.”</i><br> </p></div></div>]]>
            </description>
            <link>https://www.vaticannews.va/en/pope/news/2020-11/pope-francis-november-prayer-intention-robotics-ai-human.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25106937</guid>
            <pubDate>Mon, 16 Nov 2020 01:28:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Break neural networks in the browser with adversarial attacks]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25104999">thread link</a>) | @ag8
<br/>
November 15, 2020 | https://kennysong.github.io/adversarial.js/ | <a href="https://web.archive.org/web/*/https://kennysong.github.io/adversarial.js/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <h4>What is the demo doing?</h4>
        <p>Neural networks achieve superhuman performance in many areas, but they are easily fooled.</p>
        <p>In the demo above, we can force neural networks to predict anything we want. By adding nearly-invisible noise to an image, we turn "1"s into "9"s, "Stop" signs into "120 km/hr" signs, and dogs into hot dogs.</p>
        <p>These noisy images are called <a href="https://en.wikipedia.org/wiki/Adversarial_machine_learning#Specific_Attacks_Types">adversarial examples</a>. They break the integrity of machine learning systems, and the illusion of their superhuman performance.</p>

        <h4>Why does this matter?</h4>
        <p>Our world is becoming increasingly automated, yet these systems have strange failure modes.</p>
        <p>If machine learning systems are not properly defended, attackers could:</p>
        <ul>
          <li>Impersonate others in facial recognition systems</li>
          <li>Force autonomous vehicles to misrecognize street signs &amp; obstacles</li>
          <li>Bypass content moderation and spam filters in social networks</li>
          <li>Inject adversarial bytes into malware to bypass antivirus systems</li>
          <li>Digitally alter numbers on a check in a mobile banking app</li>
          <li>(and more)</li>
        </ul>

        <h4>Is this limited to image classification with neural networks?</h4>
        <p>No. Adversarial examples exist for almost every machine learning task: <a href="https://nicholas.carlini.com/code/audio_adversarial_examples">speech recognition</a>, <a href="https://arxiv.org/pdf/1804.07998.pdf">text classification</a>, <a href="https://dl.acm.org/doi/10.1145/3308558.3313533">fraud detection</a>, <a href="https://www.ericswallace.com/imitation">machine translation</a>, <a href="https://adversarialpolicies.github.io/">reinforcement learning</a>, ....</p>
        <p>Moreover, all machine learning models (not just neural networks) are vulnerable. In fact, simpler models such as logistic regression are <a href="https://arxiv.org/pdf/1412.6572.pdf">even more easily attacked</a>.</p>
        <p>Finally – beyond adversarial examples – there are many more adversarial attack vectors, including data poisoning, model backdooring, data extraction, and model stealing.</p>

        <h4>How do I defend against adversarial examples?</h4>
        <p>There are several proposed defenses, including adversarial training and admission control.</p>
        <p>However, no defense is universal and many have proven ineffective, so work with an expert to quantify your risks and invest in defenses appropriately.</p>
        <p>(What happens if someone can make your system predict anything they want?).</p>

        <h4>Where can I learn more?</h4>
        <p>Here's a list of good resources, in rough order of approachability:</p>
        <ul>
          <li><a href="https://kennysong.github.io/adversarial.js/faq.html">The full FAQ</a></li>
          <li><a href="https://kennysong.github.io/adversarial.js/examples.html">The directory of attacks</a> (try running locally and playing with various settings)</li>
          <li><span>[Blog]</span> CleverHans – <a href="http://www.cleverhans.io/security/privacy/ml/2016/12/16/breaking-things-is-easy.html">start here</a></li>
          <li><span>[Blog]</span> Gradient Science – <a href="https://gradientscience.org/intro_adversarial/">start here</a></li>
          <li><span>[Tutorial]</span> <a href="https://adversarial-ml-tutorial.org/">Adversarial Robustness - Theory and Practice</a></li>
          <li><span>[Paper]</span> <a href="https://arxiv.org/pdf/1611.03814.pdf">SoK: Towards the Science of Security and Privacy in Machine Learning</a></li>
          <li><span>[Paper]</span> <a href="https://arxiv.org/pdf/1712.03141.pdf">Wild Patterns: Ten Years After the Rise of Adversarial Machine Learning</a></li>
        </ul>
        <p>Last – feel free to <a href="mailto:hello@kennysong.com">email me questions</a>.</p>

        
      </div></div>]]>
            </description>
            <link>https://kennysong.github.io/adversarial.js/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25104999</guid>
            <pubDate>Sun, 15 Nov 2020 21:22:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting Things Done – personal adaptation and my experiences]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25104995">thread link</a>) | @kossmoboleat
<br/>
November 15, 2020 | https://blog.timforest.com/getting-things-done/ | <a href="https://web.archive.org/web/*/https://blog.timforest.com/getting-things-done/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><h3>Getting Things Done</h3><p><time datetime="2020-11-09"><small>9 Nov, 2020</small></time></p><p>I'm writing this blog post at 21:45 on a weekday after an intense day at work and a full evening of looking after my daughter and cooking pizza. I was in three video conferences and chatted with two colleagues in Teams, all while having my kid run around me all day because the daycare is closed. Now's the time to do something for <strong>me</strong>. Wouldn't it be nice to have some help to juggle all these different things and not feel overwhelmed?</p><p>In the next weeks, I'm trying out the Getting Things Done (GTD for short) method. I have tried GTD for short periods off and on over some years. Without knowing the concept, I used <a href="https://culturedcode.com/things">Things</a> but abandoned it after some time. That was over 10 years in my studies. A few years back, I read the original book and re-read it last year. So why try again? Didn't I learn my lesson?</p><p>No - I didn't :-). Although I've never completely adopted it, I've soaked up more and more of its practices. This time around I'll try to apply <em>all</em> its techniques as well as I can and see where that leads me.</p><h2 id="gtd-in-a-nutshell">GTD in a nutshell</h2><p>Quoted with small changes from the book:</p><ol><li>Capture all the things that might need to get done or have usefulness for you - now, later, someday, big little, or in between -- in a logical and trusted system outside your head and off your mind.</li><li>Direct yourself to make front-end decisions about all of the "inputs" you let into your life so that you will always have a workable inventory of "next actions" that you can implement or renegotiate in the moment.</li><li>Curate and coordinate all of that content, utilizing the recognition of the multiple levels of commitments with yourself and others you will have at play at any point in time.</li></ol><p>There are already many concise and complete introductions to the basics of GTD, so I won't repeat them here. Read <a href="https://hamberg.no/gtd">Erlend Hamberg's well-structured one: GTD in 15 minutes</a>. It's a quick and well-written guide.</p><p>In a sense, GTD is very American because I have the feeling (North) Americans are obsessed with lists. Many clickbait articles you come across have titles like "top X things" where X is more often than not simply the number somebody came up with. Although I must admit the last example was from a German site <a href="https://t3n.de/news/wordpress-hosting-anbieter-vergleich-604474/">13 WordPress-Anbieter</a>.</p><p>GTD has a list of the next actions one wants to look at. This is different from a todo list in that there are stricter rules on what a good entry can be. For example, it has to be a physical action and not a whole project. GTD also prescribes reviews (every day and every week) to keep on top of these lists. There's a comfort to know you'll triage a pressing question or inspiring article the next day or at least at your weekly review. This relief is at the heart of GTD: knowing that nothing will fall through the cracks you can relax from time to time.</p><p>One pays for a generally more relaxed general outlook by following a couple of small practices very closely. To capture all things, David Allen means that all emails or collected snippets are processed and collected too. I found it especially significant that one should collect references and notes on everything that might come in handy later. Collecting things comes <strong>very</strong> naturally to me; as a kid, I liked to collect buttons -- of all things -- and to keep many books around. When at long last I got my own computer I immediately started collecting <em>all the things</em>. My <a href="http://del.icio.us/">del.icio.us</a> accounts probably had more than a thousand collected links when it was shut down. GTD emphasizes to collect references for later usage. A lot of input is not useful at the moment and only potentially later at some point, but still, you can rely on your system to keep it for you.</p><h2 id="is-gtd-for-everybody%3F">Is GTD for everybody?</h2><p>David Allen originally "discovered" it in his work as a consultant and executive coach. I would argue that it's useful when you're already pretty organized. If you're in a routine job with little need for interaction with others it might be overkill for you. A simple todo list and some basic tricks to fight procrastination could be enough. There are fewer and fewer routine jobs. Most office workers are expected to be as "agile" when shifting many responsibilities as executives two decades ago.</p><h2 id="besides-gtd">Besides GTD</h2><p>In summary, I've mentioned that a convenient "setup" serves me better than vague "hacks". It can increase motivation and/or remove distractions. For my productivity, I still find it crucial to avoid news sites as much as possible. I've replaced them with a collection of RSS feeds from newspapers and some blogs. With a configured update interval of four hours, refreshing it every few minutes is less attractive. Turning off communication tools, the popular Pomodoro technique or simply walking to another room, still help me. I like that you can still apply many other ideas and still refine my <em>personal</em> system. If I had <strong>nothing</strong> to procrastinate on, that would be sad too, right?</p><p>I think getting rid of distractions is more important than having the perfect productivity system/todo tool. Cal Newport's ideas from his books (especially <a href="https://www.calnewport.com/books/deep-work/">"Deep Work"</a> and <a href="https://www.calnewport.com/books/digital-minimalism/">"Digital Minimalism"</a>) and his <a href="https://www.calnewport.com/blog/">blog</a> immediately come to mind. <a href="https://www.taniarascia.com/everyday-systems/">Here are some ideas from developer Tania Rascia</a> that I can relate to.</p><h2 id="how-to-implement-gtd">How to Implement GTD</h2><p>You have to decide if you want to go analog or digital. David Allen suggests in his book to keep lists and folders analog first. Digital tools realize GTD with more or less sophistication. I've never tried to use only paper although I tried working a lot with my Moleskine notebook. At some point, I had also used Things but only used it as a fancy todo list.</p><p>For me a very text-centric simple note-taking app called <a href="https://nvultra.com/">nvUltra</a> has worked well. It lets me write lists in different files synced between my laptop and smartphone. It's not very adapted to GTD but I like that it is an excellent reference system too. nvUltra is the commercial successor to the excellent open-source <a href="https://brettterpstra.com/projects/nvalt/">nvAlt</a>. This in turn evolved from <a href="http://notational.net/">Notational Velocity</a>. There are also cross-platform implementations such as <a href="https://github.com/cpbotha/nvpy">nvPY</a>.</p><p><a href="https://todoist.com/productivity-methods/getting-things-done">todoist</a> is a sophisticated tool for GTD too. <a href="https://www.omnigroup.com/omnifocus/">OmniFocus</a> has been around very long and has been refreshed over time. Other general-purpose note-taking tools can be adapted for GTD too, such as Evernote, Notion, or OneNote. <a href="https://orgmode.org/">Org-mode</a> is an alternative plain text file format that's more powerful than Markdown. It's mostly used with the Emacs editor and supports notes and todos as well.</p><h2 id="gtd-horizons">GTD horizons</h2><p>One distinguishing feature of GTD on top of todo management is more abstract and longer-term levels of focus. rom the day-to-day "ground" level, David Allen introduces the level of longer projects at horizon 1 and goes up to the purpose of your life with horizon 5. In his <a href="https://gettingthingsdone.com/2015/05/podcast-01-david-allen-talks-about-the-new-edition-of-getting-things-done/">podcast</a>, David Allen mentions that for many it takes years to reach these longer-term perspectives. It takes a long time to integrate them into the system. He suggests one should start off with the day-to-day and form long-term plans bottom-up.</p><p>GTD horizons with their increased abstraction remind me of Eastern religions such as buddhism. In stoicism as well one works towards a very distant ideal of "enlightenment". This is not far-fetched as David Allen is a black belt karateka and used his experience in the conception of GTD. The book mentions having a "mind like water" to be ready for anything that may come to you as a concept from martial arts. There's also a blog by David Allen with <a href="https://gettingthingsdone.com/2019/05/10-reasons-gtd-is-like-karate/">10 more similarities</a>.</p><h2 id="is-it-simply-self-exploitation%3F">Is it Simply Self-Exploitation?</h2><p>"Increasing productivity" also has a stale 19th century factory worker exploitation aspect to me. At least the basis of management "science" had very questionable origins. Managers "scientifically" noted how long some workers took to complete a task. They noted the fastest and decided to increase work quotas for everybody. Even then short-term exploitation didn't have long-term lasting positive effects.</p><p>One could argue that a personal productivity system only serves as self-exploitation. Where managers exploited industrial workers, we do it ourselves now. I haven't read or though much about this, but a <a href="https://dev.to/tinmanjk/the-curious-case-of-self-exploitation--303j">dev article by Ivan Petrov raises some interesting points</a>. They emphasize:</p><blockquote><p>What I have learned and forgotten and re-learned is that the power NOT to do (negative potency) seems to be the only weapon.</p></blockquote><p>This at least we can take to heart by filtering out many actions. We can also try to move away from "outside" areas of (work) focus and focus on our own values and vision.</p><h2 id="trial-period">Trial Period</h2><p>For the next month until December 6th, I'm implementing GTD and revisiting its techniques. For me some questions still remain unanswered:</p><ul><li>When to "uncover" the following project "next action"? As soon as a previous one is done? At the daily or weekly review?</li><li>Should I track project "next actions" in the same list of individual "next actions"? Wouldn't this create a lot of extra overhead to copy tasks from files to files?</li><li>Can I effectively attach project and action reference material with my bare-bones plain-text system? nvUltra doesn't have support to easily attach images or other files.</li><li>Should I keep some references available for all completed actions for later reference?</li><li>Are the tickler files something I can implement digitally? Should I use it for habits and routines?</li><li>Will I have the discipline to postpone work tasks (that often overwhelm my todo list)?</li><li>Should I copy information from other tracking tools that I use with others, e.g. JIRA?</li><li>How exactly to keep track of deadlines (with tickler files or also in projects)?</li><li>Should I handle personal or professional tasks differently after all?</li><li>What are my higher horizons like "areas of responsibility", "objectives", "vision" and "purpose"?</li></ul><h2 id="references">References</h2><ul><li><a href="https://forum.gettingthingsdone.com/">Official GTD Forum</a></li></ul><h3 id="overview%2Fintroduction">Overview/Introduction</h3><ul><li><a href="https://hamberg.no/gtd">GTD in 15 minutes</a></li><li><a href="https://en.wikipedia.org/wiki/Getting_Things_Done">https://en.wikipedia.org/wiki/Getting_Things_Done</a></li><li><a href="https://www.43folders.com/2004/09/08/getting-started-with-getting-things-done">Merlin Mann's Intro with further links</a></li></ul><h3 id="references-2">References</h3><ul><li><a href="https://web.archive.org/web/20190602235428/http://wiki.43folders.com:80/index.php/GTD">Merlin Mann's wiki via Wayback Machine</a></li></ul><h3 id="scientific-evaluation">Scientific Evaluation</h3><ul><li><a href="http://pespmc1.vub.ac.be/Papers/GTD-cognition.pdf">"Getting Things Done: The Science behind Stress-Free Productivity"</a></li></ul></article></div>]]>
            </description>
            <link>https://blog.timforest.com/getting-things-done/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25104995</guid>
            <pubDate>Sun, 15 Nov 2020 21:21:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DevOps and Ransomware]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25104976">thread link</a>) | @ericalexander0
<br/>
November 15, 2020 | https://ericalexander.org/post/devops-and-ransomware/ | <a href="https://web.archive.org/web/*/https://ericalexander.org/post/devops-and-ransomware/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <div>
  

  <p><time datetime="2020-11-15T13:06:13-0700">Nov 15, 2020</time> · 6 min read
  </p>

  <blockquote>
<p>Mr. Bezos. I’m all in favor of a clean fulfillment center, but tell me: Why do you sweep? Why do you not instead eliminate the source of dirt? - Unknown “insultant”</p>
</blockquote>
<p>Does DevOps pass the “so what?” test? When you start to follow the history of DevOps from Agile, Lean, TOS, TQM, TPS, and beyond; doesn’t it lead to plain old critical thinking? Is it anything special? If it’s so simple, if anyone can do it, then why on earth would the worlds richest person <a href="https://youtu.be/O4MtQGRIIuA?t=1250">pay an “insultant” to teach him</a>? Jeff seems to understand that eliminating waste is important, that you should never pass a defect down the line, but he seems to discard the sweeping question as too abstract, and not useful.</p>
<p>Las Cruces Public Schools (LCPS) may be a perfect example of an organization that’s proud of their ability to <a href="https://www.lcsun-news.com/story/news/education/lcps/2020/11/14/las-cruces-public-schools-what-ransomware-attack-taught-us/6296955002/">scale up sweeping operations in response to a ransomware incident</a>. Why are they so proud of their investment of resources, to deal with ransomware? <a href="http://www.lcps.net/district-overview/">How does that support their mission</a>? Who’s their customer? Ransomware? If DevOps is just critical thinking and LCPS’ value statement is “<a href="http://www.lcps.net/district-overview/">our expectation is that our schools are diverse, equitable, and provide opportunities for the development of critical thinking and democratic ideals</a>”, then shouldn’t we hold them accountable for critical thinking?</p>
<p>Nobody gravitates towards DevOps when everything is working. DevOps isn’t valuable in environments where waste is cheap, it’s valuable where waste isn’t cheap. I’d have to think it’s valuable in any public school system that’s struggling to meet demand within their budget. Maybe it’s too late to help LCPS avoid ransomware, but maybe we can help another school system through a little critical thinking exercise.</p>
<p>Most of what people assume is “DevOps” is just repackaged teaching from an Isreali physicist who wrote a book for the business world in 1984. That book, The Goal, <a href="https://slate.com/business/2012/06/the-goal-eli-goldratts-gripping-thriller-about-operations-theory.html">is still popular in business schools</a>. If there’s one thing Eliyahu Goldratt, the author of The Goal, consistently talks about in all of his teaching, it’s understanding cause and effect. Goldratt advocates for the use of what he calls <a href="https://en.wikipedia.org/wiki/Current_reality_tree_(theory_of_constraints)">Current Reality Tree</a> (CRT) to map out the cause and effect of a problem, the conflict, and where to focus resources on resolution.</p>
<p>Let’s try it out with Ransomware, it may look something like this if we simply map out the cause and effect relationships of what we know about a <a href="https://thedfirreport.com/2020/11/05/ryuk-speed-run-2-hours-to-ransom/">ransomware incident</a>.</p>
<p><img src="https://ericalexander.org/20201115-crt-1.png" alt="simple cause and effect"></p>
<p>Make sense? Now let’s look at a full current reality tree, where we go beyond the ransomware incident, and start to look at how a ransomware opportunity was created.</p>
<p><img src="https://ericalexander.org/20201115-crt-2.png" alt="full crt">
<a href="https://ericalexander.org/20201115-crt-2.png">Full Image</a></p>
<p>It balloons out when we start to understand all the vectors of how they get on our network, and what they do, once they get there.</p>
<p>Vectors:</p>
<ul>
<li><a href="https://thedfirreport.com/2020/11/05/ryuk-speed-run-2-hours-to-ransom/">Phishing</a></li>
<li><a href="https://blog.malwarebytes.com/security-world/business-security-world/2018/08/protect-rdp-access-ransomware-attacks/">Perimeter System: Compromised Credentials</a></li>
<li><a href="https://www.bleepingcomputer.com/news/security/black-kingdom-ransomware-hacks-networks-with-pulse-vpn-flaws/">Perimeter System: Missing Patch</a></li>
</ul>
<p>Once they get on the network they’ll deploy a <a href="https://www.theregister.com/2020/09/24/cobalt_strike_cisco_talos/">command and control</a> (C&amp;C) tool that enables them to drop additional tools and start hunting domain admins. They’ll search for servers or computers <a href="https://github.com/BloodHoundAD/BloodHound">where they can login, and where the domain admin is logged in</a>. Once they find that system they grab either the domain admin’s password, or their session information (<a href="https://en.wikipedia.org/wiki/Pass_the_hash">just as good as a password</a>), then it’s game over. They now have keys to the kingdom and can delete backups and encrypt systems.</p>
<p>Now that you know how it works, and the cause and effect: Did LCPS eliminate the source of dirt?</p>
<p>This is the only statement that covers what they learned, and how they changed:</p>
<blockquote>
<p>Since then, we have installed firewalls, updated our systems, invested in our teachers and improved our infrastructure so we can protect ourselves.</p>
</blockquote>
<p>If we go back to our current reality tree we can ask:</p>
<ul>
<li>Does a firewall address the conflict points? It’s not clear if they’re talking about a new fancy next-gen perimeter firewall, improved network segregation, or host firewalls. Segregation and host firewalls could help if they prevent the bad actor from logging into a shared system where domain admin is logged in.</li>
<li>Was the problem updated systems? Possible vector if they’re not patching, but it doesn’t address the core conflict.</li>
<li>Invested in our teachers and improved our infrastructure. Great. Keep it up, but it still doesn’t address the core conflict.</li>
</ul>
<p>This is the core conflict:</p>
<p><img src="https://ericalexander.org/20201115-crt-3.png" alt="core conflict"></p>
<p>The number of domain admins is the core conflict. It’s rarely necessary to have any domain admins, but most organizations have much more than zero when it’s easier to give somebody domain admin access, than it is to take the time to give them only the access they need to do their job. Plain old Least Privilege. Plain old <a href="https://www.cisecurity.org/controls/controlled-use-of-administrative-privileges/">#4 on the CIS Top 20 security controls</a>.</p>
<p>Did LCPS go back and fix the core conflict, or are they still passing a defect downline? What should they have done prior to the Ransomware breach? What can you do now? Evaluate your blast radius. Your InfoSec and/or IT teams should be following the advice of <a href="https://adsecurity.org/">adsecurity.org</a>. They should be running tools like <a href="https://github.com/PlumHound/PlumHound">Plumhound</a> or <a href="https://www.guardicore.com/infectionmonkey/">Infection Monkey</a> to understand and reduce blast radius.</p>
<p>You don’t have to be an IT or InfoSec expert to get a glimpse into your ransomware risk. You’re at less risk, possibly near zero, if your organization isn’t using Active Directory; but if they are, you can run the powershell below from your computer to evaluate blast radius.</p>
<pre><code># This will install AD tools on Windows 10
Add-WindowsCapability -Online -Name Rsat.ActiveDirectory.DS-LDS.Tools~~~~0.0.1.0
# This will list all domain admins
Get-ADGroupMember -Identity "Domain Admins" -Recursive | %{Get-ADUser -Identity $_.distinguishedName -properties *} | Select Name, Enabled, LastLogonDate, logonCount, PasswordLastSet
# This will list all enterprise admins
Get-ADGroupMember -Identity "Enterprise Admins" -Recursive | %{Get-ADUser -Identity $_.distinguishedName -properties *} | Select Name, Enabled, LastLogonDate, logonCount, PasswordLastSet
</code></pre>
<p>That powershell will list user accounts ransomware teams are interested in, the ones they’ll go after once they land on your network. Ideally that list is zero. It’s not zero? Shocker! How about passwords? Are they being rotated quickly? Ideally every 7 days or less. What’s the logon count look like? Is it in the hundreds? Ouch, somebody is running around with scissors.</p>
<p>Concerned? Send that output to your IT or InfoSec teams. Ask them if they understand the advice of adsecurity.org or Plumhound. Maybe they have it under control, but maybe they need a little poking to remind them it’s important.</p>
<p>Interested in learning more about the so what of DevOps, and how it applies to Information Security? I’m writing a book. Send me an <a href="https://ericalexander.org/cdn-cgi/l/email-protection#127677647d62613c707d7d795277607b71737e776a737c7677603c7d60752d616770787771662f707d7d7934737f6229707d766b2f5e77663720227f77372022797c7d65372022657a777c3720227b6635613720227d6766">email</a> or connect on <a href="https://www.linkedin.com/in/ericalexanderorg">LinkedIn</a> if you’re interested in the book.</p>

</div>

        




  </div></div>]]>
            </description>
            <link>https://ericalexander.org/post/devops-and-ransomware/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25104976</guid>
            <pubDate>Sun, 15 Nov 2020 21:20:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Super Creative Radio – nonstop curated music for creative work]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25104736">thread link</a>) | @URfejk
<br/>
November 15, 2020 | https://www.supercreative.design/radio | <a href="https://web.archive.org/web/*/https://www.supercreative.design/radio">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-ix="super-move"><h2>Share good vibes 🌈</h2><p>Submit your track or artwork to make hundreds of other creatives vibe. We’ll review your submission and feature you in the radio and newsletter.</p><div><div><h6><span>s</span><span>u</span><span>p</span><span>e</span><span>r</span>&nbsp;</h6><p>&nbsp;your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div><p>or</p><div><div><h6><span>s</span><span>u</span><span>p</span><span>e</span><span>r</span>&nbsp;</h6><p>&nbsp;your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div></div></div>]]>
            </description>
            <link>https://www.supercreative.design/radio</link>
            <guid isPermaLink="false">hacker-news-small-sites-25104736</guid>
            <pubDate>Sun, 15 Nov 2020 20:55:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Manylinux1 is obsolete, manylinux2010 is almost EOL, what is next?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25103547">thread link</a>) | @luord
<br/>
November 15, 2020 | https://labs.quansight.org/blog/2020/11/manylinux1-is-obsolete-manylinux2010-is-almost-eol-what-is-next/ | <a href="https://web.archive.org/web/*/https://labs.quansight.org/blog/2020/11/manylinux1-is-obsolete-manylinux2010-is-almost-eol-what-is-next/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody text">
        <div>
<p>The basic installation format for users who install packages via <code>pip</code> is
the wheel format. Wheel names are composed of four parts: a
package-name-and-version tag (which can be further broken down), a Python tag,
an ABI tag, and a platform tag. More information on the tags can be found in
<a href="https://www.python.org/dev/peps/pep-0425">PEP 425</a>.  So a package like NumPy
will be available on PyPI as <code>numpy-1.19.2-cp36-cp36m-win_amd64.whl</code> for 64-bit
windows and <code>numpy-1.19.2-cp36-cp36m-macosx_10_9_x86_64.whl</code> for macOS. Note
that only the plaform tag <code>win_amd64</code> or <code>macosx_10_9_x86_64</code> differs. </p>
<p>But what about Linux? There is no single, vendor controlled, "Linux platform"
e.g., Ubuntu, RedHat, Fedora, Debian, FreeBSD all package software at slightly
different versions. What most Linux distributions do have in common is the
glibc runtime library, and a smattering of various additional system libraries.
So it is possible to define a least common denominator (LCD) of software
expected to be on a Linux platform (exceptions apply, e.g. non-glibc
distributions).</p>
<p>The decision to converge on a LCD common platform gave birth to the
<a href="https://www.python.org/dev/peps/pep-0513/">manylinux1</a> standard. Going back
to our example, numpy is available as
<code>numpy-1.19.2-cp36-cp36m-manylinux1_x86_64.whl</code>.</p>
<p>The first manylinux standard, manylinux1, was based on CentOS5 which has <a href="https://endoflife.software/operating-systems/linux/centos">been
obsolete</a> since
March 2017. The subsequent manylinux2010 standard is based on CentOS6, which
will hit end-of-life in December 2020. The manylinux2014 standard still has some
breathing room. Based on CentOS7, it will reach end-of-life in July 2024.</p>
<p>So what is next for <code>manylinux</code>, and what <code>manylinux</code> should users and package
maintainers use?</p>
<!-- TEASER_END -->

<h3>If <code>manylinux1</code> is obsolete, why are there still manylinux1 wheels?</h3>
<p>Wheels are typically consumed by Pip via <code>pip install</code>. Manylinux wheels are
used for projects that require compilation, otherwise they would ship
pure Python wheels with the "none" platform tag, meaning they are compatible with
any platform. So say you are a library author and want to make it convenient
for users to install your package. If you ship a manylinux2014 wheel, but the
version of Pip your users have is too old to support manylinux2014 wheels, Pip
will happily download the source package and compile it for them. Havoc ensues:
Windows users typically cannot compile, prerequisites will be missing. Pip has
a <code>--only-binary</code> option to prevent it from downloading source code and
compiling, and a <code>--prefer-binary</code> option to prefer older binary packages over
compiling from source, but neither is on by default.</p>
<p>Pip began supporting manylinux2010 wheels with <a href="https://github.com/pypa/pip/blob/master/NEWS.rst#190-2019-01-22">version
19.0</a>,
released in Jan 2019. The version of Pip that is officially shipped with Python 3.6, via
the <a href="https://docs.python.org/3.6/library/ensurepip.html">ensurepip</a> module, is
version 18. Python 3.7 ships pip 20. It is easy enough to upgrade, but to be on
the safe side, and prevent havoc, library authors will ship a manylinux1 wheel
for Python 3.6 support.</p>
<h3>What happens now that Python 3.6 is falling out of favor?</h3>
<p><a href="https://www.python.org/dev/peps/pep-0494">Python 3.6 is no longer in active
development</a>. In fact, the scientific
Python community has decided to stop actively supporting Python 3.6 <a href="https://numpy.org/neps/nep-0029-deprecation_policy.html#support-table">from
July 2020</a>.
So I would expect to see projects begin to drop the older manylinux1 format,
and drop support for Python 3.6 sooner rather than later, meaning that
<strong><code>manylinux2014</code> may soon become the only option</strong> for new versions.</p>
<h3>What about Conda packages?</h3>
<p>Conda does not use the same kind of wheel format provided by PyPI and Pip. Conda's
build system is internally consistent, and Conda packagers build a binary
package for each supported OS, thus they are not bound to the manylinux
designation. Conda does not have a declared policy around deprecating Python
3.6 yet. Conda does support <code>pip</code> (but try not to mix <code>conda</code> and <code>pip</code>
usage!), and the Pip provided should be version 20 or later. If needed,
<code>conda upgrade pip</code> should get you a modern version, so here too
<code>manylinux2014</code> will soon become the only option.</p>
<h3>What comes after manylinux2014?</h3>
<p>The glibc used in manylinux2014 is defined as the one used by CentOS7. This OS
was released in June 2014. This manylinux standard, for the first time,
declared support for non-x86 hardware systems like ARM64 (aarch64), Power
(ppc64) and S390X.  However the ARM platform has grown greatly since 2014, and
glibc has moved from version 2.17 to 2.31, fixing many bugs. Since the real
driver for platform compatibility is glibc, <a href="https://www.python.org/dev/peps/pep-0600/">PEP
600</a> defined a "perennial manylinux
spec" that is based on the glibc version number. A lot of work has <a href="https://github.com/pypa/manylinux/issues/542">already
taken place</a> to support the next
version. Now we need to take the dive: decide what the base OS for the next
manylinux tag will be, roll out a Docker image and tooling around it, and
convince library packaging teams to adopt it. This is needed to allow libraries
like NumPy to confidently use the glibc routines fixed after 2014. For
instance, <a href="https://github.com/numpy/numpy/issues/15763">this issue</a> is
preventing NumPy from properly supporting <code>np.float128</code> on Power and S390X.</p>
<h3>What about non-x86 machines and Linux?</h3>
<p>As mentioned before, starting with manylinux2014 <code>pip</code> and <code>wheel</code> supports
non-x86 architectures like ARM64. Many packages are just now starting to roll
out support for these architectures, as the CI systems that support open source
projects (like TravisCI) have only recently made those platforms available.
It might be easier for users to adopt Conda and the <code>conda-forge</code> channel
since conda-forge has support for non-x86 architectures today.</p>
<h3>OK, so what is the bottom line?</h3>
<ul>
<li>Use pip v20 or later to make it easier on libarary packagers: modern pip
  versions will take the latest manylinux package they can support and will be
  forward-compatible with the PEP 600 perennial manylinux standard.</li>
<li>Manylinux1 and Python 3.6 are going away. Update your systems.</li>
<li>For people looking to move PEP 600 forward, the next step is to dive into the
  <a href="https://github.com/pypa/auditwheel">auditwheel</a> repo to define and support
  the next manylinux version. </li>
</ul>
</div>
    </div></div>]]>
            </description>
            <link>https://labs.quansight.org/blog/2020/11/manylinux1-is-obsolete-manylinux2010-is-almost-eol-what-is-next/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25103547</guid>
            <pubDate>Sun, 15 Nov 2020 18:42:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OpenZFS: DRAID How To]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25103484">thread link</a>) | @zdw
<br/>
November 15, 2020 | https://openzfs.github.io/openzfs-docs/Basic%20Concepts/dRAID%20Howto.html | <a href="https://web.archive.org/web/*/https://openzfs.github.io/openzfs-docs/Basic%20Concepts/dRAID%20Howto.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
    <nav data-toggle="wy-nav-shift">
      
    </nav>

    <section data-toggle="wy-nav-shift">

      
      <nav aria-label="top navigation">
        
          <i data-toggle="wy-nav-top"></i>
          <a href="https://openzfs.github.io/openzfs-docs/index.html">OpenZFS</a>
        
      </nav>


      <div>
        
        <div>
        
          
















          <div role="main" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div id="draid-howto">

<div>
<p>Note</p>
<p>This page a describes <em>work in progress</em> functionality, which is not yet
merged in master branch.</p>
</div>
<div id="introduction">
<h2>Introduction<a href="#introduction" title="Permalink to this headline">¶</a></h2>
<div id="raidz-vs-draid">
<h3>raidz vs draid<a href="#raidz-vs-draid" title="Permalink to this headline">¶</a></h3>
<p>ZFS users are most likely very familiar with raidz already, so a
comparison with draid would help. The illustrations below are
simplified, but sufficient for the purpose of a comparison. For example,
31 drives can be configured as a zpool of 6 raidz1 vdevs and a hot
spare: <img alt="raidz1" src="https://openzfs.github.io/openzfs-docs/_images/draid_raidz.png"></p>
<p>As shown above, if drive 0 fails and is replaced by the hot spare, only
5 out of the 30 surviving drives will work to resilver: drives 1-4 read,
and drive 30 writes.</p>
<p>The same 30 drives can be configured as 1 draid1 vdev of the same level
of redundancy (i.e. single parity, 1/4 parity ratio) and single spare
capacity: <img alt="draid1" src="https://openzfs.github.io/openzfs-docs/_images/draid_draid.png"></p>
<p>The drives are shuffled in a way that, after drive 0 fails, all 30
surviving drives will work together to restore the lost data/parity:</p>
<ul>
<li><p>All 30 drives read, because unlike the raidz1 configuration shown
above, in the draid1 configuration the neighbor drives of the failed
drive 0 (i.e. drives in a same data+parity group) are not fixed.</p></li>
<li><p>All 30 drives write, because now there is no dedicated spare drive.
Instead, spare blocks come from all drives.</p></li>
</ul>
<p>To summarize:</p>
<ul>
<li><p>Normal application IO: draid and raidz are very similar. There’s a
slight advantage in draid, since there’s no dedicated spare drive
which is idle when not in use.</p></li>
<li><p>Restore lost data/parity: for raidz, not all surviving drives will
work to rebuild, and in addition it’s bounded by the write throughput
of a single replacement drive. For draid, the rebuild speed will
scale with the total number of drives because all surviving drives
will work to rebuild.</p></li>
</ul>
<p>The dRAID vdev must shuffle its child drives in a way that regardless of
which drive has failed, the rebuild IO (both read and write) will
distribute evenly among all surviving drives, so the rebuild speed will
scale. The exact mechanism used by the dRAID vdev driver is beyond the
scope of this simple introduction here. If interested, please refer to
the recommended readings in the next section.</p>
</div>
<div id="recommended-reading">
<h3>Recommended Reading<a href="#recommended-reading" title="Permalink to this headline">¶</a></h3>
<p>Parity declustering (the fancy term for shuffling drives) has been an
active research topic, and many papers have been published in this area.
The <a href="http://www.cse.scu.edu/~tschwarz/TechReports/hpca.pdf">Permutation Development Data
Layout</a> is a
good paper to begin. The dRAID vdev driver uses a shuffling algorithm
loosely based on the mechanism described in this paper.</p>
</div>
</div>
<div id="using-draid">
<h2>Using dRAID<a href="#using-draid" title="Permalink to this headline">¶</a></h2>
<p>First get the code <a href="https://github.com/openzfs/zfs/pull/10102">here</a>,
build zfs with <em>configure –enable-debug</em>, and install. Then load the
zfs kernel module with the following options which help dRAID rebuild
performance.</p>
<ul>
<li><p>zfs_vdev_scrub_max_active=10</p></li>
<li><p>zfs_vdev_async_write_min_active=4</p></li>
</ul>
<div id="create-a-draid-vdev">
<h3>Create a dRAID vdev<a href="#create-a-draid-vdev" title="Permalink to this headline">¶</a></h3>
<p>Similar to raidz vdev a dRAID vdev can be created using the
<code><span>zpool</span> <span>create</span></code> command:</p>
<div><div><pre><span></span><span># zpool create &lt;pool&gt; draid[1,2,3][ &lt;vdevs...&gt;</span>
</pre></div>
</div>
<p>Unlike raidz, additional options may be provided as part of the
<code><span>draid</span></code> vdev type to specify an exact dRAID layout. When unspecific
reasonable defaults will be chosen.</p>
<div><div><pre><span></span><span># zpool create &lt;pool&gt; draid[1,2,3][:&lt;groups&gt;g][:&lt;spares&gt;s][:&lt;data&gt;d][:&lt;iterations&gt;] &lt;vdevs...&gt;</span>
</pre></div>
</div>
<ul>
<li><p>groups - Number of redundancy groups (default: 1 group per 12 vdevs)</p></li>
<li><p>spares - Number of distributed hot spares (default: 1)</p></li>
<li><p>data - Number of data devices per group (default: determined by
number of groups)</p></li>
<li><p>iterations - Number of iterations to perform generating a valid dRAID
mapping (default 3).</p></li>
</ul>
<p><em>Notes</em>:</p>
<ul>
<li><p>The default values are not set in stone and may change.</p></li>
<li><p>For the majority of common configurations we intend to provide
pre-computed balanced dRAID mappings.</p></li>
<li><p>When <em>data</em> is specified then: (draid_children - spares) % (parity +
data) == 0, otherwise the pool creation will fail.</p></li>
</ul>
<p>Now the dRAID vdev is online and ready for IO:</p>
<div><div><pre><span></span>  <span>pool</span><span>:</span> <span>tank</span>
 <span>state</span><span>:</span> <span>ONLINE</span>
<span>config</span><span>:</span>

    <span>NAME</span>                 <span>STATE</span>     <span>READ</span> <span>WRITE</span> <span>CKSUM</span>
    <span>tank</span>                 <span>ONLINE</span>       <span>0</span>     <span>0</span>     <span>0</span>
      <span>draid2</span><span>:</span><span>4</span><span>g</span><span>:</span><span>2</span><span>s</span><span>-</span><span>0</span>     <span>ONLINE</span>       <span>0</span>     <span>0</span>     <span>0</span>
        <span>L0</span>               <span>ONLINE</span>       <span>0</span>     <span>0</span>     <span>0</span>
        <span>L1</span>               <span>ONLINE</span>       <span>0</span>     <span>0</span>     <span>0</span>
        <span>L2</span>               <span>ONLINE</span>       <span>0</span>     <span>0</span>     <span>0</span>
        <span>L3</span>               <span>ONLINE</span>       <span>0</span>     <span>0</span>     <span>0</span>
        <span>...</span>
        <span>L50</span>              <span>ONLINE</span>       <span>0</span>     <span>0</span>     <span>0</span>
        <span>L51</span>              <span>ONLINE</span>       <span>0</span>     <span>0</span>     <span>0</span>
        <span>L52</span>              <span>ONLINE</span>       <span>0</span>     <span>0</span>     <span>0</span>
    <span>spares</span>
      <span>s0</span><span>-</span><span>draid2</span><span>:</span><span>4</span><span>g</span><span>:</span><span>2</span><span>s</span><span>-</span><span>0</span>  <span>AVAIL</span>
      <span>s1</span><span>-</span><span>draid2</span><span>:</span><span>4</span><span>g</span><span>:</span><span>2</span><span>s</span><span>-</span><span>0</span>  <span>AVAIL</span>

<span>errors</span><span>:</span> <span>No</span> <span>known</span> <span>data</span> <span>errors</span>
</pre></div>
</div>
<p>There are two logical hot spare vdevs shown above at the bottom:</p>
<ul>
<li><p>The names begin with a <code><span>s&lt;id&gt;-</span></code> followed by the name of the parent
dRAID vdev.</p></li>
<li><p>These hot spares are logical, made from reserved blocks on all the 53
child drives of the dRAID vdev.</p></li>
<li><p>Unlike traditional hot spares, the distributed spare can only replace
a drive in its parent dRAID vdev.</p></li>
</ul>
<p>The dRAID vdev behaves just like a raidz vdev of the same parity level.
You can do IO to/from it, scrub it, fail a child drive and it’d operate
in degraded mode.</p>
</div>
<div id="rebuild-to-distributed-spare">
<h3>Rebuild to distributed spare<a href="#rebuild-to-distributed-spare" title="Permalink to this headline">¶</a></h3>
<p>When there’s a failed/offline child drive, the dRAID vdev supports a
completely new mechanism to reconstruct lost data/parity, in addition to
the resilver. First of all, resilver is still supported - if a failed
drive is replaced by another physical drive, the resilver process is
used to reconstruct lost data/parity to the new replacement drive, which
is the same as a resilver in a raidz vdev.</p>
<p>But if a child drive is replaced with a distributed spare, a new process
called rebuild is used instead of resilver:</p>
<div><div><pre><span></span><span># zpool offline tank sdo</span>
<span># zpool replace tank sdo '%draid1-0-s0'</span>
<span># zpool status</span>
  <span>pool</span><span>:</span> <span>tank</span>
 <span>state</span><span>:</span> <span>DEGRADED</span>
<span>status</span><span>:</span> <span>One</span> <span>or</span> <span>more</span> <span>devices</span> <span>has</span> <span>been</span> <span>taken</span> <span>offline</span> <span>by</span> <span>the</span> <span>administrator</span><span>.</span>
        <span>Sufficient</span> <span>replicas</span> <span>exist</span> <span>for</span> <span>the</span> <span>pool</span> <span>to</span> <span>continue</span> <span>functioning</span> <span>in</span> <span>a</span>
        <span>degraded</span> <span>state</span><span>.</span>
<span>action</span><span>:</span> <span>Online</span> <span>the</span> <span>device</span> <span>using</span> <span>'zpool online'</span> <span>or</span> <span>replace</span> <span>the</span> <span>device</span> <span>with</span>
        <span>'zpool replace'</span><span>.</span>
  <span>scan</span><span>:</span> <span>rebuilt</span> <span>2.00</span><span>G</span> <span>in</span> <span>0</span><span>h0m5s</span> <span>with</span> <span>0</span> <span>errors</span> <span>on</span> <span>Fri</span> <span>Feb</span> <span>24</span> <span>20</span><span>:</span><span>37</span><span>:</span><span>06</span> <span>2017</span>
<span>config</span><span>:</span>

        <span>NAME</span>                <span>STATE</span>     <span>READ</span> <span>WRITE</span> <span>CKSUM</span>
        <span>tank</span>                <span>DEGRADED</span>     <span>0</span>     <span>0</span>     <span>0</span>
          <span>draid1</span><span>-</span><span>0</span>          <span>DEGRADED</span>     <span>0</span>     <span>0</span>     <span>0</span>
            <span>sdd</span>             <span>ONLINE</span>       <span>0</span>     <span>0</span>     <span>0</span>
            <span>sde</span>             <span>ONLINE</span>       <span>0</span>     <span>0</span>     <span>0</span>
            <span>sdf</span>             <span>ONLINE</span>       <span>0</span>     <span>0</span>     <span>0</span>
            <span>sdg</span>             <span>ONLINE</span>       <span>0</span>     <span>0</span>     <span>0</span>
            <span>sdh</span>             <span>ONLINE</span>       <span>0</span>     <span>0</span>     <span>0</span>
            <span>sdu</span>             <span>ONLINE</span>       <span>0</span>     <span>0</span>     <span>0</span>
            <span>sdj</span>             <span>ONLINE</span>       <span>0</span>     <span>0</span>     <span>0</span>
            <span>sdv</span>             <span>ONLINE</span>       <span>0</span>     <span>0</span>     <span>0</span>
            <span>sdl</span>             <span>ONLINE</span>       <span>0</span>     <span>0</span>     <span>0</span>
            <span>sdm</span>             <span>ONLINE</span>       <span>0</span>     <span>0</span>     <span>0</span>
            <span>sdn</span>             <span>ONLINE</span>       <span>0</span>     <span>0</span>     <span>0</span>
            <span>spare</span><span>-</span><span>11</span>        <span>DEGRADED</span>     <span>0</span>     <span>0</span>     <span>0</span>
              <span>sdo</span>           <span>OFFLINE</span>      <span>0</span>     <span>0</span>     <span>0</span>
              <span>%</span><span>draid1</span><span>-</span><span>0</span><span>-</span><span>s0</span>  <span>ONLINE</span>       <span>0</span>     <span>0</span>     <span>0</span>
            <span>sdp</span>             <span>ONLINE</span>       <span>0</span>     <span>0</span>     <span>0</span>
            <span>sdq</span>             <span>ONLINE</span>       <span>0</span>     <span>0</span>     <span>0</span>
            <span>sdr</span>             <span>ONLINE</span>       <span>0</span>     <span>0</span>     <span>0</span>
            <span>sds</span>             <span>ONLINE</span>       <span>0</span>     <span>0</span>     <span>0</span>
            <span>sdt</span>             <span>ONLINE</span>       <span>0</span>     <span>0</span>     <span>0</span>
        <span>spares</span>
          <span>%</span><span>draid1</span><span>-</span><span>0</span><span>-</span><span>s0</span>      <span>INUSE</span>     <span>currently</span> <span>in</span> <span>use</span>
          <span>%</span><span>draid1</span><span>-</span><span>0</span><span>-</span><span>s1</span>      <span>AVAIL</span>
</pre></div>
</div>
<p>The scan status line of the <em>zpool status</em> output now says <em>“rebuilt”</em>
instead of <em>“resilvered”</em>, because the lost data/parity was rebuilt to
the distributed spare by a brand new process called <em>“rebuild”</em>. The
main differences from <em>resilver</em> are:</p>
<ul>
<li><p>The rebuild process does not scan the whole block pointer tree.
Instead, it only scans the spacemap objects.</p></li>
<li><p>The IO from rebuild is sequential, because it rebuilds metaslabs one
by one in sequential order.</p></li>
<li><p>The rebuild process is not limited to block boundaries. For example,
if 10 64K blocks are allocated contiguously, then rebuild will fix
640K at one time. So rebuild process will generate larger IOs than
resilver.</p></li>
<li><p>For all the benefits above, there is one price to pay. The rebuild
process cannot verify block checksums, since it doesn’t have block
pointers.</p></li>
<li><p>Moreover, the rebuild process requires support from on-disk format,
and <strong>only</strong> works on draid and mirror vdevs. Resilver, on the other
hand, works with any vdev (including draid).</p></li>
</ul>
<p>Although rebuild process creates larger IOs, the drives will not
necessarily see large IO requests. The block device queue parameter
<em>/sys/block/</em>/queue/max_sectors_kb* must be tuned accordingly. However,
since the rebuild IO is already sequential, the benefits of enabling
larger IO requests might be marginal.</p>
<p>At this point, redundancy has been fully restored without adding any new
drive to the pool. If another drive is offlined, the pool is still able
to do IO:</p>
<div><div><pre><span></span><span># zpool offline tank sdj</span>
<span># zpool status</span>
 <span>state</span><span>:</span> <span>DEGRADED</span>
<span>status</span><span>:</span> <span>One</span> <span>or</span> <span>more</span> <span>devices</span> <span>has</span> <span>been</span> <span>taken</span> <span>offline</span> <span>by</span> <span>the</span> <span>administrator</span><span>.</span>
        <span>Sufficient</span> <span>replicas</span> <span>exist</span> <span>for</span> <span>the</span> <span>pool</span> <span>to</span> <span>continue</span> <span>functioning</span> <span>in</span> <span>a</span>
        <span>degraded</span> <span>state</span><span>.</span>
<span>action</span><span>:</span> <span>Online</span> <span>the</span> <span>device</span> <span>using</span> <span>'zpool online'</span> <span>or</span> <span>replace</span> <span>the</span> <span>device</span> <span>with</span>
        <span>'zpool replace'</span><span>.</span>
  <span>scan</span><span>:</span> <span>rebuilt</span> <span>2.00</span><span>G</span> <span>in</span> <span>0</span><span>h0m5s</span> <span>with</span> <span>0</span> <span>errors</span> <span>on</span> <span>Fri</span> <span>Feb</span> <span>24</span> <span>20</span><span>:</span><span>37</span><span>:</span><span>06</span> <span>2017</span>
<span>config</span><span>:</span>

        <span>NAME</span>                <span>STATE</span>     <span>READ</span> <span>WRITE</span> <span>CKSUM</span>
        <span>tank</span>                <span>DEGRADED</span>     <span>0</span>     <span>0</span>     <span>0</span>
          <span>draid1</span><span>-</span><span>0</span>          <span>DEGRADED</span>     <span>0</span>     <span>0</span>     <span>0</span>
            <span>sdd</span>             <span>ONLINE</span>       <span>0</span>     <span>0</span>     <span>0</span>
            <span>sde</span>             <span>ONLINE</span>       <span>0</span>     <span>0</span>     <span>0</span>
            <span>sdf</span>             <span>ONLINE</span>       <span>0</span>     <span>0</span>     <span>0</span>
            <span>sdg</span>             <span>ONLINE</span>       <span>0</span>     <span>0</span>     <span>0</span>
            <span>sdh</span>             <span>ONLINE</span>       <span>0</span>     <span>0</span>     <span>0</span>
            <span>sdu</span>             <span>ONLINE</span>       <span>0</span>     <span>0</span>     <span>0</span>
            <span>sdj</span>             <span>OFFLINE</span>      <span>0</span>     <span>0</span>     <span>0</span>
            <span>sdv</span>             <span>ONLINE</span>       <span>0</span>     <span>0</span>     <span>0</span>
            <span>sdl</span>             <span>ONLINE</span>       <span>0</span>     <span>0</span>     <span>0</span>
            <span>sdm</span>             <span>ONLINE</span>       <span>0</span>     <span>0</span>     <span>0</span>
            <span>sdn</span>             <span>ONLINE</span>       <span>0</span>     …</pre></div></div></div></div></div></div></div></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://openzfs.github.io/openzfs-docs/Basic%20Concepts/dRAID%20Howto.html">https://openzfs.github.io/openzfs-docs/Basic%20Concepts/dRAID%20Howto.html</a></em></p>]]>
            </description>
            <link>https://openzfs.github.io/openzfs-docs/Basic%20Concepts/dRAID%20Howto.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25103484</guid>
            <pubDate>Sun, 15 Nov 2020 18:35:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Laser-Guided Lightning May Help Prevent Wildfires]]>
            </title>
            <description>
<![CDATA[
Score 76 | Comments 53 (<a href="https://news.ycombinator.com/item?id=25103339">thread link</a>) | @kposehn
<br/>
November 15, 2020 | https://www.breakingasia.com/news/laser-guided-lightning-may-help-prevent-wildfires/ | <a href="https://web.archive.org/web/*/https://www.breakingasia.com/news/laser-guided-lightning-may-help-prevent-wildfires/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				
				
				<div>
				
				
				<p><h2>Small, portable laser pointers could be used to guide lightning strikes, with a study suggesting the technology may prevent bolts from sparking wildfires, a researcher told AFP Thursday.</h2></p>
			</div> <!-- .et_pb_text --><div>
				
				
				<div><p>A team of international scientists have shown storm clouds could be “short-circuited” by using a hollow laser — like a pipe of light — to deliver particles into the clouds and draw lightning strikes, research co-author Professor Andrey Miroshnichenko from the University of New South Wales in Canberra told AFP.</p>
<p>In lab tests, the team — which also included scientists from the Australian National University (ANU) — successfully used a laser tractor beam to direct the path of an electrical discharge to specific targets, Miroshnichenko said.</p>
<p>In the past, high-powered lasers were needed to achieve similar results, making the technique dangerous, costly and inaccurate.<span>&nbsp;</span></p></div>
			</div> <!-- .et_pb_text --><div>
				
				
				<p><iframe title="Bushfires in Australia: What ignited the deadly crisis" width="1080" height="608" src="about:blank" data-src="https://www.youtube.com/embed/-l28KQ8dJDM?feature=oembed" data-no-lazy="1" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
				
			</div><div>
				
				
				<div><p>But the new research suggested that small, hand-held lasers could be used in the field within the next decade, he said.</p>
<p>“It turns out that to deliver particles, you do not need high-intensity lasers, even low intensity like your laser pointer will be already enough,” Miroshnichenko said.</p>
<p>Using a tractor beam with a hollow centre, micro-particles in the air could be heated up and delivered to a specific point and trigger an electrical discharge.</p></div>
			</div> <!-- .et_pb_text --><p><span><img src="https://www.breakingasia.com/wp-content/uploads/Electrical-Discharge-Induce-by-Microparticle.jpg" data-src="https://www.breakingasia.com/wp-content/uploads/Electrical-Discharge-Induce-by-Microparticle.jpg" alt="Electrical Discharge Induce by Microparticle" title="Electrical Discharge Induce by Microparticle" height="auto" width="auto" data-srcset="https://www.breakingasia.com/wp-content/uploads/Electrical-Discharge-Induce-by-Microparticle.jpg 800w, https://www.breakingasia.com/wp-content/uploads/Electrical-Discharge-Induce-by-Microparticle-300x167.jpg 300w, https://www.breakingasia.com/wp-content/uploads/Electrical-Discharge-Induce-by-Microparticle-768x427.jpg 768w" data-sizes="(max-width: 800px) 100vw, 800px" srcset="https://www.breakingasia.com/wp-content/uploads/Electrical-Discharge-Induce-by-Microparticle.jpg 800w, https://www.breakingasia.com/wp-content/uploads/Electrical-Discharge-Induce-by-Microparticle-300x167.jpg 300w, https://www.breakingasia.com/wp-content/uploads/Electrical-Discharge-Induce-by-Microparticle-768x427.jpg 768w"></span>
			</p><div>
				
				
				<p>The electrical discharge induced by a heated microparticle.</p>
			</div> <!-- .et_pb_text --><div>
				
				
				<div><p>Although it is yet to be tested outside a lab, the technique could potentially be used to control dry lightning strikes, infamous for sparking large blazes including several major <a href="https://www.breakingasia.com/trending/social-media-fakes-australia-bushfire-disinformation/">bushfires in Australia</a> and the western US in the past year, Miroshnichenko added.</p>
<p>“We can imagine a future where this technology may induce electrical discharge from passing lightning, helping to guide it to safe targets and reduce the risk of <a href="https://www.breakingasia.com/trending/makeshift-hospital-saving-dozens-of-koalas-injured-in-bushfires/">catastrophic fires</a>,” co-researcher Vladlen Shvedov, from the ANU Research School of Physics, said.</p>
<p>The research, published in <a href="https://www.nature.com/articles/s41467-020-19183-0" target="_blank" rel="noopener">Nature Communications last month</a>, also involved Texas A&amp;M University in Qatar and the University of California in Los Angeles.<span>&nbsp;</span></p></div>
			</div> <!-- .et_pb_text -->
			</div></div>]]>
            </description>
            <link>https://www.breakingasia.com/news/laser-guided-lightning-may-help-prevent-wildfires/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25103339</guid>
            <pubDate>Sun, 15 Nov 2020 18:14:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Freelance writer earning $275,000/year]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25102940">thread link</a>) | @yitchelle
<br/>
November 15, 2020 | https://superpath.co/blog/freelance-writer-earning-275-000-year | <a href="https://web.archive.org/web/*/https://superpath.co/blog/freelance-writer-earning-275-000-year">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<section>
			<div>
				

				<div>
					<p>Welcome to another post in the $100k Club series. <a href="https://superpath.co/blog/tag/100k-club">You can see the full series here.</a> This is "My Morning Routine" for content marketing folks making six figures. The goal is to shed light on the skills and habits that enable people to achieve lucrative jobs and help get more people in this club.</p><p>These will be anonymous and updated regularly. If you make more than $100k/year and want to contribute, <a href="https://mail.google.com/mail/?view=cm&amp;fs=1&amp;tf=1&amp;to=hey@superpath.co">email me.</a></p><p><a href="https://mail.google.com/mail/?view=cm&amp;fs=1&amp;tf=1&amp;to=hey@superpath.co">For more info on </a><a href="https://superpath.co/blog/2020-content-salary-report">content marketing salaries, check out our salary report.</a></p><hr><p>Want to talk about career growth? <a href="https://superpath.co/blog/slack-community">Come join our 1,700+ strong Slack group.</a></p><hr><h3 id="what-was-your-first-full-time-job-in-content-what-was-the-salary">What was your first full-time job in content? What was the salary?</h3><p>$32,000 doing marketing and communications for a non-profit right out of college. It was a great crash course on producing quality content with little to no budget, and I still use some of those lessons today. The biggest takeaway: Relationships fuel EVERYTHING.</p><h3 id="how-much-do-you-earn-today-what-s-your-job-title">How much do you earn today? What's your job title?</h3><p>Varies annually, but I'm invoicing anywhere between $175-275K per year on average. YTD, I've invoiced $258,170.57. I'm a freelance writer and subject matter expert with a small team 3-4 of subcontractors who help with production and research.</p><h3 id="what-s-the-single-biggest-salary-jump-you-ve-made-either-from-job-hopping-or-a-promotion-raise-">What's the single biggest salary jump you've made? (either from job-hopping or a promotion/raise)</h3><p>Between 2016-2017 I doubled my income (from about $100K to $200K). That happened when my referral engine really started moving and I was consistently booked with work (and consistently raised my rates.)</p><h3 id="what-is-your-most-valuable-skill">What is your most valuable skill?</h3><p>I think I have a solid grasp on workflows and process, which helps me be highly efficient. This always impresses my clients and is a big reason I get so many referrals. Clients know that in working with me, they can hand off a project and let me run with it (and I'll come back with a top-notch finished product).</p><h3 id="what-s-the-best-book-you-ve-ever-read-on-writing-marketing-sales-business-or-productivity-feel-free-to-suggest-more-than-one-">What's the best book you've ever read on writing, marketing, sales, business or productivity? (Feel free to suggest more than one!)</h3><p>Bleck...I honestly hate business books. I can't read them because they stress me out and make me feel bad about things I should be doing but am not. I've read a few Seth Godin books, but other than that, I don't lean into this category too much.</p><h3 id="have-you-had-a-career-mentor-coach-if-so-how-did-you-find-them-and-what-have-you-learned-from-them">Have you had a career mentor/coach? If so, how did you find them and what have you learned from them?</h3><p>No, not in a traditional sense. I have a smart partner who gives me lots of great business ideas and have worked with some smart folks along the way, but nothing formal or structured in terms of a coach or mentor.</p><h3 id="what-skills-or-habits-help-you-thrive-at-work">What skills or habits help you thrive at work?</h3><p>Organization. Hands down. Not only do I stay on top of every part of my work and business, but if I say I'm going to do something, you better believe I'm going to do it (and do it well.) Nothing falls through the cracks and I'm super proactive when it comes to keeping my workload full to the max.</p><h3 id="what-advice-would-you-give-to-someone-who-wants-to-join-the-100k-club">What advice would you give to someone who wants to join the $100k club?</h3><p>Pick a niche, become a subject matter expert. Be the go-to person for ONE THING.</p><h3 id="what-is-your-gender-and-ethnicity-where-do-you-live">What is your gender and ethnicity? Where do you live?</h3><p>I'm a white female living in Chicago, IL.</p>
				</div>

				
			</div>
		</section>
	</div></div>]]>
            </description>
            <link>https://superpath.co/blog/freelance-writer-earning-275-000-year</link>
            <guid isPermaLink="false">hacker-news-small-sites-25102940</guid>
            <pubDate>Sun, 15 Nov 2020 17:33:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[“My goal is to build one app per every task in the world”]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25102892">thread link</a>) | @ent101
<br/>
November 15, 2020 | https://www.outpan.com/d/f706cbeaab72 | <a href="https://web.archive.org/web/*/https://www.outpan.com/d/f706cbeaab72">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>My goal is to build one free, ad-less app per every task in the world! Email me to collaborate.</p><div><p><span> <a href="mailto:tandy.brim@gmail.com" target="_blank">tandy.brim@gmail.com</a></span></p></div></div></div></div>]]>
            </description>
            <link>https://www.outpan.com/d/f706cbeaab72</link>
            <guid isPermaLink="false">hacker-news-small-sites-25102892</guid>
            <pubDate>Sun, 15 Nov 2020 17:28:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Haskell Proposal: Simplify Deriving]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25102636">thread link</a>) | @azhenley
<br/>
November 15, 2020 | https://www.parsonsmatt.org/2020/11/10/simplifying_deriving.html | <a href="https://web.archive.org/web/*/https://www.parsonsmatt.org/2020/11/10/simplifying_deriving.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <p><time>10 Nov 2020</time>
  </p>
  <p>Haskell’s type classes and deriving facilities are a killer feature for type safety and extensibility.
Over nearly 30 years they’ve acquired quite a bit of cruft and language extensions.
With <code>DerivingVia</code>, we now have the ability to dramatically simplify the deriving story.</p>

<p>This post outlines a change to the <em>language</em> that would hopefully be adopted with the next version of the language standard.
They get less reasonable and more dramatic as the post goes on.</p>



<p>GHC has a ton of extensions that only serve to unlock additional type classes to the “stock” deriving strategy.
<code>Derive{Functor,Foldable,Traversable,Generic,Lift,etc}</code>.
We can remove all of these extensions by folding them into the <code>stock</code> deriving strategy.</p>



<p><code>DeriveAnyClass</code> is a footgun.
It allows you to write any type class in a <code>deriving</code> clause.
It pastes in an “empty” instance, relying on <code>DefaultSignatures</code> to fill in the values.</p>

<div><div><pre><code><span>-- With DeriveAnyClass:</span>
<span>data</span> <span>X</span> <span>=</span> <span>X</span>
  <span>deriving</span> <span>ToJSON</span>

<span>-- Without:</span>
<span>data</span> <span>X</span> <span>=</span> <span>X</span>

<span>instance</span> <span>ToJSON</span> <span>X</span>
</code></pre></div></div>



<p><code>DefaultSignatures</code> is used to give a single default implementation of a type class if the underlying type matches a more restrictive constraint.
This is primarily used to provide <code>Generic</code>-based implementations with very little syntax.</p>

<div><div><pre><code><span>data</span> <span>X</span> <span>=</span> <span>X</span> <span>deriving</span> <span>Generic</span>

<span>-- with DefaultSignatures:</span>

<span>class</span> <span>ToJSON</span> <span>a</span> <span>where</span>
    <span>toJSON</span> <span>::</span> <span>a</span> <span>-&gt;</span> <span>Value</span>
    <span>default</span> <span>toJSON</span> <span>::</span> <span>(</span><span>Generic</span> <span>a</span><span>,</span> <span>GToJSON</span> <span>(</span><span>Rep</span> <span>a</span><span>))</span> <span>=&gt;</span> <span>a</span> <span>-&gt;</span> <span>Value</span>
    <span>toJSON</span> <span>=</span> <span>gtoJSON</span> 

<span>instance</span> <span>ToJSON</span> <span>X</span>

<span>-- without DefaultSignatures:</span>

<span>class</span> <span>ToJSON</span> <span>a</span> <span>where</span>
    <span>toJSON</span> <span>::</span> <span>a</span> <span>-&gt;</span> <span>Value</span>

<span>instance</span> <span>ToJSON</span> <span>X</span> <span>where</span>
    <span>toJSON</span> <span>=</span> <span>gtoJSON</span>
</code></pre></div></div>

<p>By privileging a single default, it makes any other possible defaults less useful and less discoverable.</p>

<p>The <code>DeriveAnyClass</code> utility is subsumed by <code>DerivingVia</code>.</p>

<div><div><pre><code><span>newtype</span> <span>Generically</span> <span>a</span> <span>=</span> <span>Generically</span> <span>a</span>

<span>instance</span> <span>(</span><span>Generic</span> <span>a</span><span>,</span> <span>GToJSON</span> <span>(</span><span>Rep</span> <span>a</span><span>))</span> <span>=&gt;</span> <span>ToJSON</span> <span>(</span><span>Generically</span> <span>a</span><span>)</span> <span>where</span>
    <span>toJSON</span> <span>(</span><span>Generically</span> <span>a</span><span>)</span> <span>=</span> <span>gtoJSON</span> <span>a</span>

<span>data</span> <span>X</span> <span>=</span> <span>X</span> 
    <span>deriving</span> <span>stock</span> <span>Generic</span>
    <span>deriving</span> <span>ToJSON</span> <span>via</span> <span>Generically</span> <span>X</span>
</code></pre></div></div>



<p>This extension is subsumed by <code>DerivingVia</code>, also.</p>

<div><div><pre><code><span>-- with GeneralizedNewtypeDeriving</span>
<span>newtype</span> <span>UserId</span> <span>=</span> <span>UserId</span> <span>Text</span>
    <span>deriving</span> <span>newtype</span> <span>(</span><span>Show</span><span>,</span> <span>ToJSON</span><span>)</span>

<span>-- with DerivingVia</span>
<span>newtype</span> <span>UserId</span> <span>=</span> <span>UserId</span> <span>Text</span>
    <span>deriving</span> <span>(</span><span>Show</span><span>,</span> <span>ToJSON</span><span>)</span> <span>via</span> <span>Text</span>
</code></pre></div></div>



<p>Now that there’s only two strategies, we can get rid of <code>DerivingStrategies</code>.</p>

<div><div><pre><code><span>-- Before</span>
<span>data</span> <span>X</span> <span>=</span> <span>X</span>
    <span>deriving</span> <span>stock</span> <span>(</span><span>Show</span><span>,</span> <span>Generic</span><span>)</span>
    <span>deriving</span> <span>(</span><span>ToJSON</span><span>,</span> <span>FromJSON</span><span>)</span> <span>via</span> <span>Generically</span> <span>X</span>

<span>-- After</span>
<span>data</span> <span>X</span> <span>=</span> <span>X</span>
    <span>deriving</span> <span>(</span><span>Show</span><span>,</span> <span>Generic</span><span>)</span>
    <span>deriving</span> <span>(</span><span>ToJSON</span><span>,</span> <span>FromJSON</span><span>)</span> <span>via</span> <span>Generically</span> <span>X</span>
</code></pre></div></div>



<p>Currently, you must write the complete type in a <code>DerivingVia</code> clause.</p>

<div><div><pre><code><span>data</span> <span>X</span> <span>=</span> <span>X</span> 
    <span>deriving</span> <span>Generic</span>
    <span>deriving</span> <span>ToJSON</span> <span>via</span> <span>Generically</span> <span>X</span>

<span>newtype</span> <span>Y</span> <span>=</span> <span>Y</span> <span>Text</span>
    <span>deriving</span> <span>ToJSON</span> <span>via</span> <span>Text</span>
</code></pre></div></div>

<p>This can be cumbersome for a very large type.</p>

<pre><code>newtype App a = App (ExceptT () (StateT () (ReaderT () IO)) a)
    deriving
        ( Functor
        , Applicative
        , Monad
        , MonadReader ()
        , MonadError ()
        , MonadState ()
        )
      via
        ExceptT () (StateT () (ReaderT () IO))
</code></pre>

<p>It’s also annoyingly repetitive, and can lead to errors.</p>

<div><div><pre><code><span>data</span> <span>Foo</span> <span>=</span> <span>Foo</span> 
    <span>deriving</span> <span>Generic</span>
    <span>deriving</span> <span>ToJSON</span> <span>via</span> <span>Generically</span> <span>Foo</span>

<span>-- copy/paste error</span>
<span>data</span> <span>Bar</span> <span>=</span> <span>Bar</span>
    <span>deriving</span> <span>Generic</span>
    <span>deriving</span> <span>ToJSON</span> <span>via</span> <span>Generically</span> <span>Foo</span>
</code></pre></div></div>

<p>A wildcard can be used to indicate either:</p>

<p>a. The underlying type of a <code>newtype</code>, or 
b. The type of the <code>data</code> declaration.</p>

<div><div><pre><code><span>data</span> <span>Foo</span> <span>=</span> <span>Foo</span>
    <span>deriving</span> <span>Generic</span>
    <span>deriving</span> <span>ToJSON</span> <span>via</span> <span>Generically</span> <span>_</span>

<span>-- no more copy paste error</span>
<span>data</span> <span>Bar</span> <span>=</span> <span>Bar</span>
    <span>deriving</span> <span>Generic</span>
    <span>deriving</span> <span>ToJSON</span> <span>via</span> <span>Generically</span> <span>_</span>

<span>-- mmmm nice and clean</span>
<span>newtype</span> <span>App</span> <span>a</span> <span>=</span> <span>App</span> <span>(</span><span>ExceptT</span> <span>()</span> <span>(</span><span>StateT</span> <span>()</span> <span>(</span><span>ReaderT</span> <span>()</span> <span>IO</span><span>))</span> <span>a</span><span>)</span>
    <span>deriving</span>
        <span>(</span> <span>Functor</span>
        <span>,</span> <span>Applicative</span>
        <span>,</span> <span>Monad</span>
        <span>,</span> <span>MonadReader</span> <span>()</span>
        <span>,</span> <span>MonadError</span> <span>()</span>
        <span>,</span> <span>MonadState</span> <span>()</span>
        <span>)</span>
      <span>via</span> <span>_</span>
</code></pre></div></div>



<p>There are two ways to derive things: <code>StandaloneDeriving</code> and attached deriving.
Attached deriving is redundant, but convenient.
<code>StandaloneDeriving</code> is more powerful, but less convenient.
Attached deriving clauses don’t work with <code>GADTs</code>.</p>

<div><div><pre><code><span>-- Before:</span>
<span>data</span> <span>Foo</span> <span>=</span> <span>Foo</span>
    <span>deriving</span> <span>Generic</span>
    <span>deriving</span> <span>(</span><span>FromJSON</span><span>,</span> <span>ToJSON</span><span>)</span> <span>via</span> <span>Generically</span> <span>_</span>
    
<span>newtype</span> <span>App</span> <span>a</span> <span>=</span> <span>App</span> <span>(</span><span>ExceptT</span> <span>()</span> <span>(</span><span>StateT</span> <span>()</span> <span>(</span><span>ReaderT</span> <span>()</span> <span>IO</span><span>))</span> <span>a</span><span>)</span>
    <span>deriving</span>
        <span>(</span> <span>Functor</span>
        <span>,</span> <span>Applicative</span>
        <span>,</span> <span>Monad</span>
        <span>,</span> <span>MonadReader</span> <span>()</span>
        <span>,</span> <span>MonadError</span> <span>()</span>
        <span>,</span> <span>MonadState</span> <span>()</span>
        <span>)</span>
      <span>via</span> <span>_</span>

<span>-- Only standalone:</span>
<span>data</span> <span>Foo</span> <span>=</span> <span>Foo</span>

<span>deriving</span> <span>instance</span> <span>Generic</span> <span>Foo</span>
<span>deriving</span> <span>via</span> <span>Generically</span> <span>_</span> <span>instance</span> <span>ToJSON</span> <span>Foo</span>
<span>deriving</span> <span>via</span> <span>Generically</span> <span>_</span> <span>instance</span> <span>FromJSON</span> <span>Foo</span>

<span>newtype</span> <span>App</span> <span>a</span> <span>=</span> <span>App</span> <span>...</span>

<span>deriving</span> <span>via</span> <span>_</span> <span>instance</span> <span>Functor</span> <span>App</span>
<span>deriving</span> <span>via</span> <span>_</span> <span>instance</span> <span>Applicative</span> <span>App</span>
<span>deriving</span> <span>via</span> <span>_</span> <span>instance</span> <span>Monad</span> <span>App</span>
<span>deriving</span> <span>via</span> <span>_</span> <span>instance</span> <span>MonadReader</span> <span>()</span> <span>App</span>
<span>deriving</span> <span>via</span> <span>_</span> <span>instance</span> <span>MonadError</span> <span>()</span> <span>App</span>
<span>deriving</span> <span>via</span> <span>_</span> <span>instance</span> <span>MonadState</span> <span>()</span> <span>App</span>

<span>-- GADT must use standalone to specify a context</span>
<span>data</span> <span>Some</span> <span>f</span> <span>where</span>
    <span>Some</span> <span>::</span> <span>Show</span> <span>a</span> <span>=&gt;</span> <span>f</span> <span>a</span> <span>-&gt;</span> <span>Some</span> <span>f</span>

<span>deriving</span> <span>instance</span> <span>(</span><span>forall</span> <span>a</span><span>.</span> <span>Show</span> <span>a</span> <span>=&gt;</span> <span>Show</span> <span>(</span><span>f</span> <span>a</span><span>))</span> <span>=&gt;</span> <span>Show</span> <span>(</span><span>Some</span> <span>f</span><span>)</span>
</code></pre></div></div>



<p>The problem with the above proposal is that it carries a significant syntax cost.
The keyword <code>deriving</code> is repeated for each instance, the keyword <code>instance</code> is repeated, the <code>via _</code> clause is repeated, and the type name is repeated.
Multiple instances should be derivable with the same context.</p>

<div><div><pre><code><span>data</span> <span>Foo</span> <span>=</span> <span>Foo</span>

<span>deriving</span> <span>Foo</span> 
    <span>(</span> <span>Generic</span>
    <span>,</span> <span>via</span> 
        <span>(</span><span>Generically</span> <span>_</span><span>)</span>
        <span>(</span> <span>ToJSON</span>
        <span>,</span> <span>FromJSON</span>
        <span>)</span>
    <span>)</span>
</code></pre></div></div>

<p>In this block, we define the <code>ToJSON</code> and <code>FromJSON</code> instances using the same <code>Generically</code> viatype.
We can still use <code>_</code> to refer to the type, since we know the type we’re deriving for: <code>Foo</code>.
This recovers the syntax convenience of “attached deriving.”</p>

<div><div><pre><code><span>newtype</span> <span>App</span> <span>a</span> <span>=</span> <span>App</span> <span>...</span>

<span>deriving</span> <span>App</span>
    <span>via</span> <span>_</span>
        <span>instance</span> 
            <span>(</span> <span>Functor</span>
            <span>,</span> <span>Applicative</span>
            <span>,</span> <span>Monad</span>
            <span>,</span> <span>MonadReader</span> <span>()</span>
            <span>,</span> <span>MonadError</span> <span>()</span>
            <span>,</span> <span>MonadState</span> <span>()</span>
            <span>)</span>
</code></pre></div></div>

<p>This also recovers the convenience of attached deriving.
Let’s look at the main <em>point</em> - GADTs.
Otherwise we could just remove <code>StandaloneDeriving</code> (with the nice benefit/tragedy of banning orphan derived instance).</p>

<div><div><pre><code><span>data</span> <span>Some</span> <span>f</span> <span>where</span>
    <span>Some</span> <span>::</span> <span>Show</span> <span>a</span> <span>=&gt;</span> <span>f</span> <span>a</span> <span>-&gt;</span> <span>Some</span> <span>f</span>

<span>-- old</span>
<span>deriving</span> 
    <span>instance</span> <span>(</span><span>forall</span> <span>a</span><span>.</span> <span>Show</span> <span>a</span> <span>=&gt;</span> <span>Show</span> <span>(</span><span>f</span> <span>a</span><span>))</span> <span>=&gt;</span> <span>Show</span> <span>(</span><span>Some</span> <span>f</span><span>)</span>

<span>-- new</span>
<span>deriving</span> <span>Some</span>
    <span>(</span><span>forall</span> <span>a</span><span>.</span> <span>Show</span> <span>a</span> <span>=&gt;</span> <span>Show</span> <span>(</span><span>f</span> <span>a</span><span>))</span> <span>=&gt;</span> <span>Show</span> <span>(</span><span>_</span> <span>f</span><span>)</span>

<span>-- generally,</span>
<span>deriving</span> <span>SomeGadtType</span>
    <span>(</span><span>SomeContextOn</span> <span>a</span> <span>b</span> <span>c</span><span>)</span> <span>=&gt;</span>
        <span>(</span> <span>Show</span><span>,</span> <span>Eq</span><span>,</span> <span>ToJSON</span><span>,</span> <span>FromJSON</span>
        <span>)</span>
        <span>(</span><span>_</span> <span>a</span> <span>b</span> <span>c</span><span>)</span>
</code></pre></div></div>

<p>The <code>_</code> refers to the type name, without any variables applied.
So you need to apply the type variables in the instance head.
That’s a bit annoying, but maybe it’s fine</p>



<p>GHC provides a <code>newtype Stock a = Stock a</code> that hooks in to <code>DerivingVia</code> somehow.
Now we’re down to one deriving strategy.</p>

<div><div><pre><code><span>data</span> <span>X</span> <span>=</span> <span>X</span>

<span>deriving</span> <span>X</span>
    <span>via</span> <span>Stock</span> <span>_</span>
        <span>(</span> <span>Eq</span><span>,</span> <span>Show</span><span>,</span> <span>Generic</span> <span>)</span>
    <span>via</span> <span>Generically</span> <span>_</span>
        <span>(</span> <span>ToJSON</span><span>,</span> <span>FromJSON</span> <span>)</span>
</code></pre></div></div>

<p>This “deprivileges” the <code>Stock</code> deriving classes.</p>



<p>OK, so maybe you don’t like getting rid of attached deriving.
Let’s get rid of standalone deriving instead.
We need <code>StandaloneDeriving</code> for two reasons:</p>

<ol>
  <li>Orphan derived instances (shame on you)</li>
  <li>Specifying a context for GADTs and allow application of type variables</li>
</ol>

<div><div><pre><code><span>data</span> <span>Some</span> <span>f</span> <span>where</span>
    <span>Some</span> <span>::</span> <span>Show</span> <span>a</span> <span>=&gt;</span> <span>f</span> <span>a</span> <span>-&gt;</span> <span>Some</span> <span>f</span>
    <span>deriving</span>
        <span>(</span> <span>(</span><span>forall</span> <span>a</span><span>.</span> <span>Show</span> <span>a</span> <span>=&gt;</span> <span>Show</span> <span>(</span><span>f</span> <span>a</span><span>))</span>
            <span>=&gt;</span>
            <span>Show</span>
        <span>,</span> <span>-- generally,</span>
            <span>(</span><span>SomeContext</span> <span>f</span><span>)</span>
            <span>=&gt;</span>
            <span>SomeClass</span>
        <span>)</span>
</code></pre></div></div>

<p>The type variable <code>f</code> is in scope from the <code>data</code> declaration.</p>

<p>EDIT: <a href="https://twitter.com/quickdudley/status/1328068260659482624">@quickdudley</a> and <a href="https://twitter.com/nnotm/status/1327998875563683845">@nnotm</a> have correctly pointed out that you also want to be able to define instances of a class at the definition module of a class.
These are perfectly valid instances, and so we must keep <code>StandaloneDeriving</code>.</p>



<p>Alright, post is done.
These ideas are certainly controversial and Bad, but <em>man</em> wouldn’t it be nice to have a simpler story around deriving and type class instances?
The current story is so complex, and I think we can genuinely simplify Haskell-the-language by trimming some fat here.</p>

<p>EDIT: <a href="https://twitter.com/am_i_tom/status/1327992136151789568">@i_am_tom</a> posted a reference to the <a href="https://github.com/tysonzero/ghc-proposals/blob/concrete-class-dictionaries/proposals/0000-concrete-class-dictionaries.md">Concrete Class Dictionaries</a> GHC proposal, which subsumes a lot of this.</p>

</div></div>]]>
            </description>
            <link>https://www.parsonsmatt.org/2020/11/10/simplifying_deriving.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25102636</guid>
            <pubDate>Sun, 15 Nov 2020 17:03:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Coronavirus Simulation]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25102455">thread link</a>) | @kirugan
<br/>
November 15, 2020 | https://flok.codes/coronavirus-simulation | <a href="https://web.archive.org/web/*/https://flok.codes/coronavirus-simulation">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>It's November 2020. There is no cure for coronavirus. What can we do to prevent the disaster?</p>
    <p>Let's take a look at several simulations of the spread of the virus.</p>
    <p>I recommend to visit website from desktop for better experience. Phone may has performance issues.</p>
    <h3>Simulation rules</h3>
    <h4>Assumptions</h4>
    <p>Desease lasts a long time: <strong>2 to 5 weeks.</strong></p>
    <p><strong>30%</strong> of people develop severe symptoms. They are especially vulnerable in a case of a lack of medical care due to overwhelmed medical facilities or weak healthcare systems.</p>
    <p><strong>3%</strong> of people are destined to die. <a href="https://bestpractice.bmj.com/topics/en-gb/3000168/pdf/3000168/COVID-19.pdf" target="_blank"> [Source]</a>. It is due to genetic and age reasons. We are assuming we can save the people through vaccination or isolation. Unfortunately as of November 2020 there are no vaccines approved for public use.</p>
    <h4>Possible states of a person</h4>
    <p><span id="guide-healty"></span> - a healthy person.</p>
    <p><span id="guide-ill"></span> - a sick person. They infect other individuals in a small area around them.</p>
    <p><span id="guide-serious"></span> - a seriously sick person with severe symptoms. They die if the medical system is overloaded. We assume the healthcare system  can handle a maximum of 200 patients at a time. Also, severely ill patients move much slower than other people.</p>
    <p><span id="guide-dead"></span> - a dead person.</p>
    <p><span id="guide-immunity"></span> - a recovered perso. We assume they have developed an immunity and can not get reinfected.</p>
    <h4>Modificators</h4>
    <div>
        <p><span id="guide-healty-mask"></span> - a person with mask. <a href="https://www.japantimes.co.jp/news/2020/10/22/national/science-health/japan-masks-block-coronavirus/" target="_blank">Mask retains up to 50% of exhaled viruses</a>. Also it retains up to 40% of inhaled viruses. If both persons
            wear masks a synergy effect appears.</p>
        <p><span id="guide-healty-screen"></span> - a person with screen. Screen additionally protects against infection.</p>
        <p><span id="guide-healty-both"></span> - a person with screen and mask.</p>
    </div>
    <h2>Let's get started</h2>
    <h3>Virus in a small virtual city</h3>
    <p>There is a virtual city with population of 2 000 people. People contact each other as usual. No measures are taken. What could go wrong? Check it.</p>

          <div id="game-simulation-small-city">
    <p><a id="start-pause-button-small-city" onclick="startButton('small-city', this)">Start</a>
        <span id="no-ill-small-city">No sick people left. Pandemy is over.</span>
        <a id="reset-button-small-city" onclick="resetButton('small-city')">Reset</a>
    </p>
    <p>Hint: game field is scrollable</p>
    
</div>    
    <p>At the end of simulation you will see that everyone get desease. Results may vary, but I had a disaster my first simulation. I have got up to 1500 sick people at same time and
        600 dead people at the end. These are 75% and 30%, respectively. Each person with severe symptoms died.</p>

    <h3>Isolation of sick people</h3>
    <p>We have not taken any measures to protect people. Obviously, we can isolate patients in hospitals. Let's be honest, complete isolation is not possible. Patients will still
        be in contact with service personnel, such as doctors, janitors, couriers. So the virus can be passed on, but it happens less likely.</p>
    <p>Let's see how this affects the spread of the virus. <strong>It is a perfect scenario!</strong> Be prepared it takes long time. I recommend to move ahead after 90th day,
        there is nothing interesting in the following days.</p>

          <div id="game-simulation-isolate-small">
    <p><a id="start-pause-button-isolate-small" onclick="startButton('isolate-small', this)">Start</a>
        <span id="no-ill-isolate-small">No sick people left. Pandemy is over.</span>
        <a id="reset-button-isolate-small" onclick="resetButton('isolate-small')">Reset</a>
    </p>
    <p>Hint: game field is scrollable</p>
    
</div>    
    <p>Wow! In my simulation there were so few infections that medical care was enough for everyone. Over time, the number of people with immunity increased. At some point, the
        patients were in contact only with people with immunity and could not spread the virus further.</p>
    <p>My result is 70 people who died over 498 days of pandemy. Exactly 3% that are in the genetics of people. So, what is your result?</p>

    <h3>Isolation of sick people in real life</h3>
    <p>Sadly, not all people observe isolation. And alas, not all sick people know that they are ill. There is no scientific work reporting how many people are asymptomatic. In my
        city one clinic said 25% of its positive tests were from people with no signs of illness. Let's take this number as a basis. <strong>25% of those infected will not show
            symptoms and will move freely around the city.</strong></p>
          <div id="game-simulation-isolate-part-small">
    <p><a id="start-pause-button-isolate-part-small" onclick="startButton('isolate-part-small', this)">Start</a>
        <span id="no-ill-isolate-part-small">No sick people left. Pandemy is over.</span>
        <a id="reset-button-isolate-part-small" onclick="resetButton('isolate-part-small')">Reset</a>
    </p>
    <p>Hint: game field is scrollable</p>
    
</div>        <p>Well, the burden on the healthcare system is still less than in the very first scenario. But a cemeteries are overcrowded again.</p>

    <h3>Isolation of sick people in real life. But with masks and screens</h3>
    <p>May be masks and screens will help? Of course not all people wear them. Let's say <strong>10% of people wear screens and 50% of people wear masks</strong>.</p>
          <div id="game-simulation-isolate-part-small-masks">
    <p><a id="start-pause-button-isolate-part-small-masks" onclick="startButton('isolate-part-small-masks', this)">Start</a>
        <span id="no-ill-isolate-part-small-masks">No sick people left. Pandemy is over.</span>
        <a id="reset-button-isolate-part-small-masks" onclick="resetButton('isolate-part-small-masks')">Reset</a>
    </p>
    <p>Hint: game field is scrollable</p>
    
</div>        <p>Hmm. Although the effect is small, it is there. Why masks have not worked? Actually they worked. But if you have chance of infection as 5%, 20 contacts turns it to 74%,
        that's it! How many contacts do you have in pub or in club? Do you consider you are breathing the same air with all the pub visitors?</p>
    <h3>Isolation + masks + screens + self-isolation</h3>
    <p>So, our goal is to reduce the number of contacts. It's time for self-isonation. Don't forget to build houses for everyone in our virtual city in advance.</p>
    <p>In this case we have a chance to isolate people who do not know they are ill. One more modification in this simulation is prevention of infection through the walls.</p>
    <p>I live in Russia. So I will draw on the experience of my country. The Moscow mayor's office has obliged business to send <strong>30% of employee to work from home</strong>.
        Let's check what happens when this order is respected.</p>
          <div id="game-simulation-selfisolate-part-small-masks">
    <p><a id="start-pause-button-selfisolate-part-small-masks" onclick="startButton('selfisolate-part-small-masks', this)">Start</a>
        <span id="no-ill-selfisolate-part-small-masks">No sick people left. Pandemy is over.</span>
        <a id="reset-button-selfisolate-part-small-masks" onclick="resetButton('selfisolate-part-small-masks')">Reset</a>
    </p>
    <p>Hint: game field is scrollable</p>
    
</div>        <p>This set of measures has shown maximum efficiency. About 70% of people did not even get infected by the end of the simulation.</p>
    <p>This is most effective step in fight with epidemy. </p>
    <h3>Summary</h3>
    <ul>
        <li>3% of people are destined to die due to their genetics</li>
        <li>30% of people need medical attention due to their genetics</li>
        <li>there is NO cure for the virus.</li>
        <li>Virus control is about probabilities</li>
        <li>We must reduce human contact to reduce the probability of infection</li>
        <li>Forced contacts should be protected with masks, screens, antiseptics.</li>
    </ul>
    <p>I hope you drew the right conclusions. Please, help me convey information to more people. Share this page to somewhere.</p>

    
    <h3><a name="playground">Playground</a></h3>
    <p>You can play with combination of parameters here</p>
          <div id="stat_template_playground">
        
        <div id="playground-controls-playground">
            <p><label>Isolate ill</label></p>
            <p><label>Mandatory masks.</label></p>
            <p><label>Percentage of people with masks</label></p>
            <p><label> Mandatory screens.</label></p>
            <p><label>Percentage of people with screens</label></p>
            <p><label>Mandatory self-isolation</label></p>
            <p><label>Percentage of self-isolated peopfle</label></p>
        </div>
    </div>
    <div id="game-simulation-playground">
    <p><a id="start-pause-button-playground" onclick="startButton('playground', this)">Start</a>
        <span id="no-ill-playground">No sick people left. Pandemy is over.</span>
        <a id="reset-button-playground" onclick="resetButton('playground')">Reset</a>
    </p>
    <p>Hint: game field is scrollable</p>
    
</div>    
</div></div>]]>
            </description>
            <link>https://flok.codes/coronavirus-simulation</link>
            <guid isPermaLink="false">hacker-news-small-sites-25102455</guid>
            <pubDate>Sun, 15 Nov 2020 16:39:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Create Vintage Videos Using FFmpeg in 4 Simple Steps]]>
            </title>
            <description>
<![CDATA[
Score 273 | Comments 45 (<a href="https://news.ycombinator.com/item?id=25102401">thread link</a>) | @ponderingfish
<br/>
November 15, 2020 | https://ottverse.com/create-vintage-videos-using-ffmpeg/ | <a href="https://web.archive.org/web/*/https://ottverse.com/create-vintage-videos-using-ffmpeg/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><strong>It’s time for the holidays and what better way to share love and memories with your family than to create an old-school, vintage movie? You don’t need a time-machine to go back to the 50s or 60s to rmake your homevideo look like a vintage movie. All you need is FFmpeg, some imagination, and perhaps the rest of this guide 🙂 </strong></p>



<p>Let’s take a look at how you can use FFmpeg to make your videos look like old-school/vintage/retro-styled movies, shall we?</p>



<hr>



<h2>What’s Do I Mean By A Vintage Movie?</h2>



<p>Well, good question! </p>



<p><strong>My definition of an old-school movie is a movie with a low frame-rate (like 15 fps), lots of scratches and film-grain to give an aged look, and a sepia tint to it!</strong></p>



<p>Let’s see how we can achieve all of this using FFmpeg.</p>



<p>For this tutorial, I shall be using the “Touchdown Pass” sequence from <a href="https://media.xiph.org/video/derf/" target="_blank" rel="noopener">Xiph</a> to illustrate the steps. It’s a 20 second video, but for the sake of this tutorial, I’ll be cutting it to 10 seconds using FFmpeg (<a href="https://ottverse.com/trim-cut-video-using-start-endtime-reencoding-ffmpeg/">here’s how to do that</a>).</p>



<p>Let’s get started! </p>



<hr>



<h2>Step 1: Changing the Frame Rate using FFmpeg</h2>



<p>The first step is to “speed” up the video. Let’s take the video back to pre-30fps or pre-60fps days and take it all the way down to 10 fps. This gives the video an old-school look right off the bat! </p>



<pre><code>ffmpeg.exe -i td-10sec.mp4 \
-filter:v fps=fps=10 \
td-fast.mp4</code></pre>



<p>Here is the sped-up video. </p>



<p><iframe frameborder="0" allow="autoplay; fullscreen" allowfullscreen="" data-src="https://player.vimeo.com/video/479524704" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></iframe></p>



<hr>



<h2>Step 2: Give The Video a Vintage Look using FFmpeg’s filters</h2>



<p>Next, let’s change the rich, wonderful colors and bring a sepia-link tint to the entire video. This can be done using FFmpeg’s in-built <code>curves</code> filter. You can use the <code>curves</code> filter to change the amount of R, G, B in a frame and specify the “curves” that govern the change or shift in colors. </p>



<p>Luckily for us, FFmpeg has a pre-defined <code>vintage</code> filter that works pretty well, I must say! Here is the commandline to convert our sped-up video into a “vintage” looking video. Simple, right?</p>



<pre><code>ffmpeg.exe -i td-fast.mp4 \
-vf curves=vintage \
td-vintage-fast.mp4</code></pre>



<p>Here’s the result of the <code>curves=vintage</code> filter on our footall video.</p>



<p><iframe frameborder="0" allow="autoplay; fullscreen" allowfullscreen="" data-src="https://player.vimeo.com/video/479525304" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></iframe></p>



<hr>



<h2>Step 3: Getting a Film Grain Overlay and Resizing It</h2>



<p>As the final step, let’s add a lot of film-grain and “scratches” to make our video look like something that was shot on film, stored in a dusty old cupboard, and discovered 40 years later! </p>



<p>I found a fantastic “old school” film overlay on YouTube (<a href="https://www.youtube.com/watch?v=J_MZb7qTenE" target="_blank" rel="noopener">source link</a>) with a download link. </p>



<figure><div>
<p><span><iframe width="1200" height="675" allowfullscreen="true" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation" data-src="https://www.youtube.com/embed/J_MZb7qTenE?version=3&amp;rel=1&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;fs=1&amp;hl=en-US&amp;autohide=2&amp;wmode=transparent" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></iframe></span></p>
</div></figure>



<p>The video’s size is <code>1440x1080</code> pixels and so I had to resize it to <code>1920x1080</code> to match the size of my input video. </p>



<p>Here is the command to resize a video using FFmpeg using the the <code>scale</code> filter. I’ve stored the output video as <code>oldFilm1080.mp4</code>.</p>



<pre><code>ffmpeg -i old-film-grain.wmv \
-vf scale=1920:1080,setsar=1:1 \
oldFilm1080.mp4</code></pre>



<hr>



<h2>Step 4: Add the Overlay To Your Video</h2>



<p>Now we have two videos with us – </p>



<ol><li>our old-school film-grain-scratchy video</li><li>our vintage-looking, sped-up football video. </li></ol>



<p>Now all that’s left to do is to overlay them on each other and enjoy the fruits of <s>our</s> FFmpeg’s labor! </p>



<p>Here’s the commandline to achieve that. </p>



<pre><code>ffmpeg.exe \
-i oldFilm1080.mp4 \
-i td-vintage-fast.mp4 \
-filter_complex "[0]format=rgba,colorchannelmixer=aa=0.25[fg];\
[1][fg]overlay[out]" \
-map [out] \
-pix_fmt yuv420p -c:v libx264 -crf 18 \
touchdown-vintage.mp4</code></pre>



<p>So, what’s going on here? </p>



<ul><li>we provide two input videos to FFmpeg </li><li>using <code>filter_complex</code>, we use <code>colorchannelmixer</code> to overlay by modifying the alpha channel of the film-grain video that is referred to as <code>[0]</code> and and let’s call the output <code>[fg]</code>. It’s black and white, so modifying only the alpha is good enough for our use case. The syntax is as follows <code>colorchannelmixer=rr:rg:rb:ra:gr:gg:gb:ga:br:bg:bb:ba:ar:ag:ab:aa</code>. </li><li>we are modifying only the alpha, and so, we modify only the <code>aa</code> (output’s alpha) to <code>0.25</code>.</li><li>then, we use the vintage-looking football video (referred to as <code>[1]</code>) and overlay them both using the <code>overlay</code> filter to create an interim output stored in a variable called <code>[out]</code>. This is shown in the commands –&gt; <code>[1][fg]overlay[out]</code></li><li>then, we encode the interim output to give us the final video using H.264 with <code>crf=18</code> which should give us a good quality video.</li></ul>







<p><strong>Here is what the final output looks like! Cool, isn’t it? </strong></p>



<p><iframe frameborder="0" allow="autoplay; fullscreen" allowfullscreen="" data-src="https://player.vimeo.com/video/479529512" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></iframe></p>







<p>And, here’s how it looks side-by-side the original video. </p>



<p><iframe frameborder="0" allow="autoplay; fullscreen" allowfullscreen="" data-src="https://player.vimeo.com/video/479529447" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></iframe></p>







<p>Now you can change the opacity of the alpha channels, use a different film grain video, or use a different <code>curves</code> function, but, the process won’t change much. </p>



<p>Hope you all have a lot of fun making “<strong>vintage</strong>” videos this holiday season and please let me know in the comments how it went! Please create some fun videos, share them with your loved ones, and have a few laughs 🙂 </p>



<p>Thank you! </p>



<p>If you enjoyed this post, do check out the rest of<a href="https://ottverse.com/category/ffmpeg/"> <strong>OTTVerse’s FFmpeg tutorials</strong></a> to learn more about how to use FFmpeg to improve your video editing, compression, and processing skills!</p>

</div></div>]]>
            </description>
            <link>https://ottverse.com/create-vintage-videos-using-ffmpeg/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25102401</guid>
            <pubDate>Sun, 15 Nov 2020 16:33:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Case for Properties: Programming Language Design]]>
            </title>
            <description>
<![CDATA[
Score 37 | Comments 45 (<a href="https://news.ycombinator.com/item?id=25102163">thread link</a>) | @WillBAnders
<br/>
November 15, 2020 | https://blog.willbanders.dev/articles/a-case-for-properties.html | <a href="https://web.archive.org/web/*/https://blog.willbanders.dev/articles/a-case-for-properties.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
                <div>
                    
                    <div>
                        <div>
                            <p><span>November 15, 2020</span><br>
                                <span><em>~12m read time</em></span>
                            </p>
                            <p><span>November 15, 2020</span><br>
                                <span><em>~12m read time</em></span>
                            </p>
                        </div>
                    </div>
                </div>
                <p>Properties are a really nice feature of modern languages, and I've recently
                    gotten attached to them in Kotlin. For a while
                    I wasn't comfortable with the idea of 'fields' performing arbitrary computation,
                    but having used them for a few months now I'm really enjoying the simplicity -
                    <em>especially</em> when moving back to Java!</p>
                <p>Having given it some thought, I wanted to lay out a case in support of
                    properties which highlights their benefits over directly accessing fields (which
                    is mostly about getters/setters, but nonetheless), and how we can establish some
                    guidelines on when properties should not be used to avoid the issue of
                    arbitrary computation causing side effects or other unexpected behavior.</p>
                
                <p>In short, a property is <abbr title="Features which aid readability or ease of use but do not impact semantics.">syntax sugar</abbr> for getter/setter methods that look
                    like fields. Instead of having to use the methods <code>item.getQuantity()</code> and
                    <code>item.setQuantity()</code>, we can access the property <code>item.quantity</code> and set it
                    using <code>item.quantity = 1</code>, exactly like a field. The compiler transforms property
                    access and assignment to use the appropriate getters/setters (hence, syntax sugar).
                </p>
                <p>The most noteworthy consequence of this is, in my opinion, allowing <em>validation
                    on assigment</em>. For example, <code>item.quantity</code> may be defined as follows (in Kotlin):</p>
<pre><span>class</span> <span>Item</span> {
    <span>var</span> <span>quantity</span>: <span>Int</span> = <span>0</span>
        <span>set</span>(value) {
            require(value &gt;= <span>0</span>) <span>//throws if negative</span>
            <span>field</span> = value
        }
}
</pre>
<pre><span>
  <i onclick="openDemo('item-property', this)"></i>
</span>item.<span>quantity</span> = <span>-10</span>;
</pre>
                
                <p>The largest benefit of properties is replacing field use, which has a massive
                    amount of drawbacks, with methods instead. In languages like C++ and Java that
                    don't have properties, the best practice is to keep all fields private and
                    manually create getters and setters. More modern languages, like C# and Kotlin,
                    use properties for this instead which can do that automatically.</p>
                <p>Most of the following points are also benefits of using getters/setters over
                    fields, and then properties step in to provide the extra bit of syntax sugar icing on
                    the cake.</p>
                <div>
                    <div>
                        <h3 id="api-safety-and-compatibility">
                            <span>
                                <a href="#api-safety-and-compatibility">
                                    <i></i>
                                </a>
                            </span>
                            <span>API Safety and Compatibility</span>
                        </h3>
                    </div>
                </div>
                <ol>
                    <li>Property getters/setters can have different <abbr title="public/private and friends">access modifiers</abbr>, allowing for
                        fields which are read-only for external use but still mutable within the class.
                        <ul>
                            <li>Example: In Kotlin, <code>val&nbsp;counter&nbsp;=&nbsp;0&nbsp;private&nbsp;set</code>
                                defines a <code>counter</code> field that can be publicly accessed but not modified (unless within the class).
                            </li>
                        </ul>
                    </li>
                    <li>Getters/setters can be used to maintain <abbr title="A (mathematical) property which is expected to hold true in all cases

For example, a unit vector (3D) has the invariant x² + y² + z² == 1.">invariants</abbr> and perform other
                        validation work, such as <code>quantity&nbsp;&gt;=&nbsp;0</code> in the opening example.
                    </li>
                    <li>Since getters/setters are methods, the implementation can be changed without
                        breaking either <abbr title="Application Programming Interface

The interface of the *source* code">API</abbr> or <abbr title="Application Binary Interface

The interface of the *compiled* code">ABI</abbr> compatibility.
                        <ul>
                            <li>Example: A <code>Vector</code> class could have <code>x/y/z</code> properties, but
                                change the implementation to use a component array <code>[x, y, z]</code> instead without issue.
                            </li>
                            <li>Additionally, getters/setters can be inlined during optimization to speed up performance at the cost of ABI compatibility.
                            </li>
                        </ul>
                    </li>
                </ol>
                
                <ol>
                    <li>Properties can be used in interfaces since they're backed by methods, while fields require getters/setters to be defined for them. Notably, these getters/setters would still need to have fields defined in the implementing class to handle their values, while a property can handle that automatically.
                    </li>
                    <li>Properties can be used for methods which often behave like fields, but
                        cannot be implemented with one due to subtypes requiring computation or
                        other restrictions.
                        <ul>
                            <li>Example: <code>List#size()</code> generally doesn't need computation and returns the
                                value of a field, but some implementations (such as a <abbr title="A form of linked list which doesn't track its size, comes from Lisp

Honestly google it, this text box can't do it justice">cons list</abbr>) might.
                            </li>
                            <li>Whether <code>List#size()</code> should be a property is certainly debatable, but with how frequently collections are used I think it's almost a necessity.
                            </li>
                        </ul>
                    </li>
                </ol>
                
                <ol>
                    <li>Properties are a <em>single unit</em>. Getters/setters are located in the same
                        location in the source code as the property declaration, making it easier to
                        fully understand a field as opposed to having them defined in separate locations.
                    </li>
                    <li>Properties almost always have syntax sugar for providing default
                        implementations of <code>get/set</code> (if it's not already done automatically). In Kotlin, <code>val property</code> provides a default
                        getter while <code>var property</code> provides both a getter and setter.
                    </li>
                    <li>Debugging properties is possible without a dedicated debugger by using
                        getters/setters. This may be minor for large languages, but if your language
                        doesn't have an IDE or still in development this is <em>extremely</em> useful.
                    </li>
                    <li>Readability is often increased, albeit debatable. I personally find <code>item.quantity&nbsp;=&nbsp;1</code> to
                        be more readable than <code>item.setQuantity(1)</code>, especially in large chains.
                    </li>
                    <li>Generally, properties imply 'simple' behavior, like fields, as opposed to complex
                        computation that some methods may perform. We'll talk about this in detail soon.
                    </li>
                </ol>
                <div>
                    <div>
                        <h2 id="so-what-are-the-downsides">
                            <span>
                                <a href="#so-what-are-the-downsides">
                                    <i></i>
                                </a>
                            </span>
                            <span>So what are the downsides?</span>
                        </h2>
                    </div>
                </div>
                <p>I think there are two notable downsides to having properties. First, the
                    performance difference between field access and method calls can be significant,
                    especially in low level languages. Second, field access has clear, well-defined
                    behavior while a method call could effectively do anything, thus making it
                    harder to reason about code. Let's dig in to both of these.</p>
                
                <p>Field access is almost always language primitive, and is therefore faster than
                    doing the work of a method call (which then has to access <em>something</em> anyways).</p>
                <p>That said, compiler optimizations like <abbr title="Replacing a method call with it's implementation">inlining</abbr> can easily resolve this for
                    simple properties. In more complex cases, this is actually where properties are
                    most useful - a field itself wasn't sufficient, so the alternative would have
                    been a method call or sacrificing validation anyways.</p>
                <p>In low level languages where memory layout is often important, knowing a field
                    access corresponds to a memory lookup (and not arbitrary computation) can be
                    important. In higher level languages, particularly Object Oriented ones that
                    often encapsulate fields behind methods anyways, I don't believe this
                    distinction is as necessary.</p>
                <div>
                    <div>
                        <h3 id="problem-2-arbitrary-computation">
                            <span>
                                <a href="#problem-2-arbitrary-computation">
                                    <i></i>
                                </a>
                            </span>
                            <span>Problem 2: Arbitrary Computation</span>
                        </h3>
                    </div>
                </div>
                <p>Finally, we've made our way to what I believe is the core issue: since
                    properties can perform arbitrary computation, it is unclear what potential
                    behavior getting/setting a property may have. The extreme example here, of
                    course, is deleting the entire file system. Fields on the other hand have
                    clearly defined behavior - get or set the value, nothing more.</p>
                <p>However, these type of assumptions are not unique to properties. We apply the
                    same assumptions to methods (and honestly everything) as well. I often presume
                    that <code>getX()</code> and <code>setX(x)</code> have 'simple' behavior, but they could use lazy
                    initialization, have unexpected validation checks, or cause side-effects and
                    other unexpected behavior
                    like a database <code>getConnection()</code>. Naming is one of the two hard problems in computer science,
                    likely because we carry assumptions with us that may not always fit.</p>
                <p>That said, these assumptions …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.willbanders.dev/articles/a-case-for-properties.html">https://blog.willbanders.dev/articles/a-case-for-properties.html</a></em></p>]]>
            </description>
            <link>https://blog.willbanders.dev/articles/a-case-for-properties.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25102163</guid>
            <pubDate>Sun, 15 Nov 2020 16:04:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New Trend: Data-Infrastructure-as-a-Service]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25102046">thread link</a>) | @randrews543
<br/>
November 15, 2020 | https://talkinsaasy.com/blog/data-infrastructure-as-a-service | <a href="https://web.archive.org/web/*/https://talkinsaasy.com/blog/data-infrastructure-as-a-service">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-layout-label="Post Body" data-type="item" id="item-5f73b31b98869d427835f0db"><div><div><div data-block-type="2" id="block-3f09a85ee918fc7ad2a2"><div><p>Entrepreneurs and investors are continually looking towards the horizon to see what new challenges and shortcomings are in the market and what solutions can emerge to help solve them. The scale and complexity of data within different industries was already complex and the complexity and scale of it is only increasing every single day. How do we take all this data, wrangle it, and make it more manageable to use, enter Data-Infrastructure-as-a-Service. </p><p>Data-Infrastructure-as-a-Service is an emerging category of startups that bring together functional data from across specific industries and makes it more easily available with strong documentation so startups, developments teams and technology providers can more easily integrate industry data from other products and service providers within their industry.</p><p>Think of these services as the “pipes” that help ensure the data is flowing, you just need to turn on the spigot on your end and it should all come flowing out. Each human on earth  creating 1.7 megabytes of data EACH SECOND! In the time you read this post you will have create 204 new megabytes of data, the sheer volume of it is massive and if we don’t maintain good pipes, everything will clog.</p><p>Startups like <a href="https://withleaf.io/" target="_blank">Leaf Agriculture</a> (Farming and AgTech), <a href="https://www.noyo.com/" target="_blank">Noyo</a> (Healthcare and Insurance), and <a href="https://truelayer.com/" target="_blank">TrueLayer</a> (Banking) are all building industry specific data infrastructure platforms. These tools are helping simplify data and system integration. Shortening innovation cycles, increasing access for developers, enabling integrations, and increasing the overall satisfaction of customers when their disparate tools and systems all work together harmoniously. As both an entrepreneur and investor, keep your eyes peeled for new opportunities on the horizon for industry specific Data Infrastructure platforms.</p></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://talkinsaasy.com/blog/data-infrastructure-as-a-service</link>
            <guid isPermaLink="false">hacker-news-small-sites-25102046</guid>
            <pubDate>Sun, 15 Nov 2020 15:49:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learning all VSCode shortcuts evolved my developing habits in unexpected ways]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25101574">thread link</a>) | @tkainrad
<br/>
November 15, 2020 | https://tkainrad.dev/posts/learning-all-vscode-shortcuts-evolved-my-developing-habits/ | <a href="https://web.archive.org/web/*/https://tkainrad.dev/posts/learning-all-vscode-shortcuts-evolved-my-developing-habits/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="contentdiv">

<p>I spent a few hours spread over the last couple of weeks to learn every single one of VSCode’s keyboard shortcuts, specifically the 149 shortcuts from the <a href="https://code.visualstudio.com/shortcuts/keyboard-shortcuts-windows.pdf">official keyboard shortcuts reference</a>. These are also present in <a href="https://keycombiner.com/collections/vscode/">KeyCombiner’s searchable table of VSCode shortcuts</a>.</p>
<p>Admittedly, I started this challenge to write a blog post about it afterward and as a way to promote <a href="https://keycombiner.com/">KeyCombiner</a> via content marketing. The blog post I had in mind would be similar to my previous one, <a href="https://tkainrad.dev/posts/how-i-learned-50-new-keyboard-shortcuts-in-42-minutes/">documenting my process of learning 50 new web application shortcuts in 42 minutes</a>.</p>
<p>But, as it usually happens only in romantic comedies, my intentions changed over time. This article turned out much different. It is not about the learning process but about how this challenge changed some of the developing habits I had for many years. Workflows that I grew used to during many projects, different IDEs, and even varying programming languages suddenly evolved.</p>

<p>As software engineers, we like to think that we are continually learning and improving our skills. This is certainly true when it comes to the technologies we are using. However, our development habits, such as which features of our IDEs we use, are much more rigid. I believe most of our core workflows are formed early on and very hard to change.
I don’t have data to back this up, but when I look at myself, my co-workers, and other developers I know, this certainly seems true. If you think about it, it is not surprising, the same thing happens in other areas of life. For this very reason, you will find that developers who have studied or worked together will often use similar shortcuts, similar IDE features, and have similar limitations in their workflows.</p>
<p>The usual way to combat this is reading books, blog posts, attending conferences, well, everything that is used in our industry to extend our knowledge. However, with fundamental developing habits, I have found that this works poorly. You might read about a neat feature of your IDE, or see someone demo their workflow, but when you are eventually sitting in front of your screen and writing code, it is easy to fall back to what we already know, what is already set up, and proven to work.</p>
<p>After this experiment, I am convinced that keyboard shortcuts are the main factor in how we form our developing habits, and they can also stop us from evolving our habits.
Even before this challenge, I felt that I was good with shortcuts. I knew quite a few refactoring shortcuts, knew how to pause and stop program executing during debugging, was decent at jumping around between files, searching through my project, and all the other usual stuff. When I saw a co-worker using a shortcut that I didn’t know, I was quick to incorporate it into my workflow, too. After all, I was enough into shortcuts that I built a whole side-project around learning them.
<strong>The thing is, all new shortcuts that I learned were the ones that would augment my existing habits.</strong></p>
<p>This is a hen and egg problem; if you don’t know the shortcuts, you will not start to change your habits and use new IDE features because without shortcuts, they are too tedious to use or not at all usable. But if you don’t form new habits, you will not learn the shortcuts.</p>
<p><strong>Without intending it, I think I found a way to break out of this cycle:
Learning all IDE shortcuts very well <em>before</em> getting back to work. By learning <em>all</em> shortcuts, you are not limited to what somebody shows you and might not be compatible with your situation. You can naturally include what makes sense, in addition to your existing skills.</strong></p>
<p>The next section shows how this worked for me.</p>

<p>I started the learning process as it is usually done with KeyCombiner: By importing some shortcuts from the <a href="https://keycombiner.com/collections/vscode/">public collection of VSCode shortcuts</a> into a personal collection. Intuitively, I started with the ones I already knew and some additional that seemed most useful to me. Back then I was still trying to show that I could learn all shortcuts very quickly with KeyCombiner. I didn’t expect that shortcuts that had nothing to do with my existing workflows will be the real deal.</p>
<p>Some of the first combinations that I picked and that I did not know previously were <kbd>alt</kbd>+<kbd>w</kbd>/<kbd>r</kbd>/<kbd>c</kbd> for toggling find options (match whole word, regex, case sensitivity) because I was already using those features. This went on for a few days. I did a couple practice runs every day and added new shortcuts whenever KeyCombiner was saying that I mastered all of the previous ones.</p>
<p>Eventually, I knew all shortcuts that seemed useful for how I was using VSCode back then. So I had to start adding shortcuts that had nothing to do with my existing habits. This brought up an interesting misconception. Often keyboard shortcuts are seen as a way to do things faster, compared to using the mouse. While that is true, I think there is an even more aspect to shortcut usage in IDEs: Many features are not used at all, if you don’t know the shortcut!</p>
<p>As I was learning new VSCode shortcuts every day, I started to use features that I previously didn’t even know of. One of the first things that suddenly made a lot of sense was <em>Select all Occurences of Find Match</em> with <kbd>Alt</kbd>+<kbd>Enter</kbd> as default binding, especially when combined with regex search. I was so excited about it, that I even <a href="https://twitter.com/ThomasKainrad/status/1305608337799761920">tweeted a Gif</a> showing how I use it to modify the CSV files that are the source for KeyCombiner’s public collection tables.</p>
<p>The process worked both ways: Sometimes, while I was practicing a shortcut on KeyCombiner, it seemed apparent that this was useful and that I should include it into my workflow. Sometimes it hit me while coding that I had just learned a shortcut that can make the current task more efficient.</p>
<p>In the following, I describe the most significant changes in my daily development habits. The list is far from complete though; there are many more small things that I picked up and frequently use now.</p>
<p><strong>Editor and Panel Management</strong><br>
Since knowing all the shortcuts to switch focus between panels and move editors around, I am using VSCode’s powerful layouting capabilities much more. I have 3-5 editor panels open at pretty much all times, seeing many related pieces of code at once. Working this way by using the mouse is very impractical.
I switch between editor panels with keyboard shortcuts and move editors from one group to the other.</p>
<p>There is one negative side-effect, though: I am starting to get annoyed when I use other IDEs (PyCharm, Eclipse), because they lack far behind VSCode when it comes to using multiple editors.</p>
<p><strong>Multi-cursor Editing</strong><br>
If you don’t know the shortcut to add additional cursors, I doubt you will ever use this incredibly powerful feature of VSCode. It is a typical feature that only blends into your habits once you know the shortcuts.
The basic commands are <kbd>Ctrl</kbd>+<kbd>Ctrl</kbd>+<kbd>Down</kbd>/<kbd>Up</kbd> for adding cursors above/below. However, I found the commands to <em>Insert cursor at end of each line selected</em> (<kbd>Shift</kbd>+<kbd>Alt</kbd>+<kbd>i</kbd>), and the above-mentioned <em>Select all Occurences of Find Match</em> (<kbd>Alt</kbd>+<kbd>Enter</kbd>) even more powerful. These commands are why I frequently paste text snippets into VSCode, apply a few operations, and then copy-paste it back into whatever application I was using.</p>
<p><strong>Opening views by shortcut</strong><br>
I sometimes tried to do this before, but it never stuck. Now I finally switch to all views (Explorer, Debug, Search, Problems, etc.) with dedicated keyboard shortcuts. These shortcuts translate very nicely to other IDEs. After learning the VSCode default bindings, which are <kbd>Ctrl</kbd>+<kbd>Shift</kbd>+<kbd>&lt;char&gt;</kbd>, I set the same bindings also for Eclipse and PyCharm. Especially <kbd>Ctrl</kbd>+<kbd>Shift</kbd>+<kbd>e</kbd> for switching to the explorer view and <kbd>Ctrl</kbd>+<kbd>Shift</kbd>+<kbd>d</kbd> for switching to the debug view are among my most used shortcuts now.</p>
<p><strong>Making Selections</strong><br>
I hate to admit it, but I did not use shortcuts to expand and shrink AST selections before. AST stands for <em>abstract syntax tree</em>, which means that the IDE will take the current language’s syntax into account for modifying the selection. Finally, I picked up <kbd>Ctrl</kbd>+<kbd>Shift</kbd>+<kbd>left</kbd>/<kbd>right</kbd> to shrink and expand selections. Not all IDEs handle this in the same way, which can be a bit annoying, but it works well for the most frequent tasks, such as expanding the selection to enclose the current string, method, class, or HTML tag.</p>
<p><strong>Folding</strong><br>
I have started to use folding much more. For years, I have rarely used this feature that all IDEs support to a great extent. Now, I do it frequently. Folding is one of these things that are just not feasible with the mouse. Of course, if you need to fold code, <a href="https://blog.codinghorror.com/the-problem-with-code-folding/">chances are that you need to structure your code better</a>. Many organizations even apply automatic code linters that will complain when methods or classes are too long. However, I have never seen someone recommend splitting up blog posts into multiple files. The same goes for other non-code file types, such as JSON. All we have there is folding.</p>
<p>I am not saying these are the things you should start to learn now, far from it. These are the things I personally integrated deep into my workflows after doing this challenge, without choosing them deliberately, but naturally. Who knows what you will pick up.</p>
<p>Of course, some of the shortcuts I learned still seem a bit, let’s say nonessential, but a little useless knowledge never killed nobody.</p>

<p>In addition to finally breaking out of old habits and experience a real evolution of my IDE usage, there were some additional, less significant, but still delightful second-order effects.</p>
<p>As a shortcut enthusiast, I often had the problem that I needed to decide which binding to use for a particular operation and application pair. KeyCombiner’s public shortcut search helps to find out which binding is the convention for a particular operation, but it can still be tricky. For example, take the frequently used <em>Step Over</em> operation used for debugging. <a href="https://keycombiner.com/collecting/collections/public/search/?description=step+over&amp;keys=&amp;mac_keys=&amp;submit=Search">KeyCombiner shows that VSCode, Eclipse, and JetBrains IDEs all use a different default binding</a>(<kbd>F6</kbd>,<kbd>F8</kbd>,<kbd>F10</kbd>). Learning every single VSCode shortcut has freed me from this mental load of deciding what the best …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tkainrad.dev/posts/learning-all-vscode-shortcuts-evolved-my-developing-habits/">https://tkainrad.dev/posts/learning-all-vscode-shortcuts-evolved-my-developing-habits/</a></em></p>]]>
            </description>
            <link>https://tkainrad.dev/posts/learning-all-vscode-shortcuts-evolved-my-developing-habits/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25101574</guid>
            <pubDate>Sun, 15 Nov 2020 14:46:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Power of Serverless GraphQL with AWS AppSync]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25101263">thread link</a>) | @mooreds
<br/>
November 15, 2020 | https://serverless.pub/the-power-of-serverless-graphql-with-appsync/ | <a href="https://web.archive.org/web/*/https://serverless.pub/the-power-of-serverless-graphql-with-appsync/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
        <div>
            

            <p>
                <a href="https://serverless.pub/author/slobodan">Slobodan Stojanović</a> in <a href="https://serverless.pub/category/Serverless">Serverless</a> <i></i> <i></i> 

  20 minutes

            </p>

            <p>Every story needs a hero. But, not all heroes are the same. Some of them have superpowers, and some are ordinary people. This story’s hero is just a regular software developer who works in a small team on a medium-size application. Our hero loves his job most of the time, except when he sends a test push notification to thousands of their customers in production, like a few minutes ago.</p>

<p><img src="https://serverless.pub/img/the-power-of-serverless-graphql/01-push-notifications.png" alt=""></p>

<p>One day, his boss came with a new project. “We need to build a new complex application for our new important customer.” Nice, our hero loves challenges! “But we need to do it fast, as we have a short deadline because they have an important marketing event!” Ok, how fast do we need to build an app? “It needs to be ready for yesterday. And it needs to be real-time and scalable!”</p>

<p>The new project is a big challenge for our hero, as he never did that kind of project. Can he even do it?</p>

<p>“You can do it,” his boss says. “I also hired a famous consultant to help you.” That’s awesome! Challenge accepted.</p>

<p>After a full-day meeting with the consultant, and a whiteboard full of weird diagrams, the plan was simple: “Just use Kubernetes!”</p>

<p><img src="https://serverless.pub/img/the-power-of-serverless-graphql/02-consultant.png" alt=""></p>

<p>But our hero doesn’t know Kubernetes. And there’s no time to learn it now. What should he do?</p>

<p>He started wondering if he is the only one who doesn’t know Kubernetes. Is he good enough for this job?</p>

<p>Our hero spent a sleepless night in front of his computer with his faithful sidekick, a rubber duck. He tried to learn as much as he can about this new technology. But he ended up more confused and tired.</p>

<p><img src="https://serverless.pub/img/the-power-of-serverless-graphql/03-sidekick.png" alt=""></p>

<h2 id="you-should-try-serverless-graphql">You should try Serverless GraphQL</h2>

<p>In the middle of the night, our hero’s faithful sidekick said, “you should try serverless GraphQL.”</p>

<p><img src="https://serverless.pub/img/the-power-of-serverless-graphql/04-try-serverless-graphql.png" alt=""></p>

<p>Was he dreaming? And what the heck is serverless GraphQL? He knows what serverless is, but what’s GraphQL?</p>

<h3 id="whats-graphql">What’s GraphQL</h3>

<p>Do you remember when Mark Zuckerberg <a href="https://techcrunch.com/2012/09/11/mark-zuckerberg-our-biggest-mistake-with-mobile-was-betting-too-much-on-html5/">said</a>, “our biggest mistake was betting too much on HTML5?” It was a long time ago, back in 2012, when HTML5 was in its early days.</p>

<p>At that moment, the Facebook mobile app was an HTML5 web app embedded in the native mobile shell. They served all the news feed updates as HTML data from the server. However, HTML5 was in its early days, and the mobile web views were not performant enough, so the app wasn’t stable and scalable enough.</p>

<p><img src="https://serverless.pub/img/the-power-of-serverless-graphql/05-fb-mobile-app.png" alt=""></p>

<p>In 2012, Facebook’s engineering team started rebuilding their mobile and switching to the native iOS and Android apps. They evaluated different options for delivering the news feed data, including RESTful services  and Facebook Query Language (FQL).</p>

<p>In the <a href="https://engineering.fb.com/2015/09/14/core-data/graphql-a-data-query-language/">“GraphQL: A data query language”</a> article in 2015, Lee Byron wrote:</p>

<blockquote>
  <p>We were frustrated with the differences between the data we wanted to use in our apps and the server queries they required. We don’t think of data in terms of resource URLs, secondary keys, or join tables; we think about it in terms of a graph of objects and the models we ultimately use in our apps like NSObjects or JSON.</p>
</blockquote>

<p>This frustration led the Facebook engineering team to rethink the way they serve data to their mobile application. Instead of returning a full model with a lot of unnecessary data, they tried to develop a new system to return only the data the application needed.</p>

<p><img src="https://serverless.pub/img/the-power-of-serverless-graphql/06-data.png" alt=""></p>

<p>In 2015, they <a href="https://engineering.fb.com/2015/09/14/core-data/graphql-a-data-query-language/">announced</a> GraphQL, an open-source data query language. The idea behind GraphQL was simple, the client defines the data structure, and the server provides a JSON response with precisely the same format.</p>

<p>For example, the client wants to get the user with a specified ID. However, the application needs only the user’s name, a profile photo with a specific size, and the first five friend connections. Instead of sending two or three different requests to the RESTful API, with GraphQL, you can send a request similar to the one in the image below. And the response will be the JSON with the same structure, as you can see on the right side of the same image.</p>

<p><img src="https://serverless.pub/img/the-power-of-serverless-graphql/07-an-example.jpg" alt=""></p>

<p>That sounds nice and smart. But why should our hero care about GraphQL? He doesn’t have the same problem Facebook had.</p>

<p>The problem Facebook’s engineering team had was the leading cause for inventing GraphQL. However, that’s not the only problem GraphQL solves. If you have one of the following symptoms, GraphQL might be the cure for the problems your application faces, too:</p>

<ul>
  <li>Distinct front end clients for multiple platforms, such as web and mobile, have different data requirements.</li>
  <li>Your back end serves data to your client apps from different sources. For example, your app has SQL and NoSQL databases, and it connects to some external systems.</li>
  <li>Your app has a complex state and caching managements for both front end and back end.</li>
  <li>Slow pages, especially on mobile, caused by multiple dependant HTTP requests.</li>
</ul>

<p>This list is not complete, and GraphQL can bring even more benefits to your application. Some of the main characteristics of GraphQL are:</p>

<ul>
  <li>It defines a data shape. The request always specifies the response’s form, which makes requests more predictable and easier to use.</li>
  <li>It’s hierarchical. Its strict relation between objects with graph-structured data simplifies getting data from multiple sources.</li>
  <li>It’s strongly typed. It can give you descriptive error messages before you run a query.</li>
  <li>It’s a protocol, not storage. Each GraphQL field is backed by a function on the back end, which allows you to connect it to any storage you want in the background.</li>
  <li>It’s introspective. You can query the GraphQL server for the types it supports. This gives you built-in documentation and also a base for a powerful toolset.</li>
  <li>It’s version free. The shape of the data is always defined by the client’s request, which means adding additional fields to your model will not affect your client application until you change the query itself.</li>
</ul>

<p>To combine data from multiple sources using RESTful API, you often send multiple HTTP requests and then connect data on the client-side. This works fine in perfect conditions. However, users don’t always use your app in ideal conditions. They are often on mobile with a limited or unstable network. Or they live in Australia, and each request is a few hundred milliseconds slower.</p>

<p><img src="https://serverless.pub/img/the-power-of-serverless-graphql/08-multiple-data-sources.gif" alt=""></p>

<p>With GraphQL, you can archive the same with a single request. This will push a bit more load to the server-side, but that works just fine in most cases. It’s even better when you don’t own the server.</p>

<p><img src="https://serverless.pub/img/the-power-of-serverless-graphql/09-graphql-request.gif" alt=""></p>

<h3 id="where-to-start-with-graphql">Where to start with GraphQL</h3>

<p>With GraphQL, you start by shaping your data using types. For example, if you are building a blog, you will have an author and a post, similar to the following code snippet. Each post will have its id, a name, a title, and an author. Authors have their ids, names, and a list of their posts.</p>

<p>As you can see, types also define a relation between an author and posts.</p>

<div><div><pre><code><span>type</span><span> </span><span>Author</span><span> </span><span>{</span><span>
  </span><span>id</span><span>:</span><span> </span><span>Int</span><span>
  </span><span>name</span><span>:</span><span> </span><span>String</span><span>
  </span><span>posts</span><span>:</span><span> </span><span>[</span><span>Post</span><span>]</span><span>
</span><span>}</span><span>

</span><span>type</span><span> </span><span>Post</span><span> </span><span>{</span><span>
  </span><span>id</span><span>:</span><span> </span><span>Int</span><span>
  </span><span>title</span><span>:</span><span> </span><span>String</span><span>
  </span><span>text</span><span>:</span><span> </span><span>String</span><span>
  </span><span>author</span><span>:</span><span> </span><span>Author</span><span>
</span><span>}</span><span>
</span></code></pre></div></div>

<p>Once you have types, you can build your GraphQL schema. In the code snippet below, we define two queries: get author by ID and get posts by title. Each of these queries defines input parameters with their types and a return type.</p>

<div><div><pre><code><span>type</span><span> </span><span>Query</span><span> </span><span>{</span><span>
  </span><span>getAuthor</span><span>(</span><span>id</span><span>:</span><span> </span><span>Int</span><span>):</span><span> </span><span>Author</span><span>
  </span><span>getPostsByTitle</span><span>(</span><span>titleContains</span><span>:</span><span> </span><span>String</span><span>):</span><span> </span><span>[</span><span>Post</span><span>]</span><span>
</span><span>}</span><span>

</span><span>schema</span><span> </span><span>{</span><span>
  </span><span>query</span><span>:</span><span> </span><span>Query</span><span>
</span><span>}</span><span>
</span></code></pre></div></div>

<p>As GraphQL is not storage but a protocol, we need to tell GraphQL where and how it can read the data by creating resolvers. In the following code snippet, we define two resolvers: one for the author that connects to the SQL database and one for a list of posts sends an HTTP request to the blog platform API.</p>

<div><div><pre><code>getAuthor(_, args){
  return sql.raw('SELECT * FROM authors WHERE id = %s', args.id);
}

posts(author){
  return request(`https://api.blog.io/by_author/${author.id}`);
}
</code></pre></div></div>

<p>Finally, we can run the query. As we defined queries, we can ask for an author by their ID. Relations allow us to get a list of all author’s posts in the same request. And if we ask for the author’s name for each blog post, that name will be the same as the author’s name above because it points to the same author.</p>

<div><div><pre><code><span>{</span><span>
  </span><span>getAuthor</span><span>(</span><span>id</span><span>:</span><span> </span><span>5</span><span>){</span><span>
    </span><span>name</span><span>
    </span><span>posts</span><span> </span><span>{</span><span>
      </span><span>title</span><span>
      </span><span>author</span><span> </span><span>{</span><span>
        </span><span># this will be the same as the name above</span><span>
        </span><span>name</span><span>
      </span><span>}</span><span>
    </span><span>}</span><span>
  </span><span>}</span><span>
</span><span>}</span><span>
</span></code></pre></div></div>

<p>Once we run the query, GraphQL will parse the request, then validate the types and data shape, and finally, if the first two steps are correct, it will run the query and our resolvers. Once we receive the data, it’ll look similar to the following JSON data:</p>

<div><div><pre><code><span>{</span><span>
  </span><span>"name"</span><span>:</span><span> </span><span>"Slobodan"</span><span>,</span><span>
  </span><span>"posts"</span><span>:</span><span> </span><span>[{</span><span>
    </span><span>"title"</span><span>:</span><span> </span><span>"The power of serverless GraphQL with AppSync"</span><span>,</span><span>
    </span><span>"author"</span><span>:</span><span> </span><span>{</span><span>
      </span><span>"name"</span><span>:</span><span> </span><span>"Slobodan"</span><span>
    </span><span>}</span><span>
  </span><span>},</span><span> </span><span>{</span><span>
    </span><span>"title"</span><span>:</span><span> </span><span>"Handling webhooks with EventBridge, SAM and SAR"</span><span>,</span><span>
    </span><span>"author"</span><span>:</span><span> </span><span>{</span><span>
      </span><span>"name"</span><span>:</span><span> </span><span>"Slobodan"</span><span>
    </span><span>}</span><span>
  </span><span>}]</span><span>
</span><span>}</span><span>
</span></code></pre></div></div>

<p>By GraphQL specification, queries read the data. GraphQL specification also defines mutations and subscriptions. Mutations modify the existing data (i.e., add a new author or edit post), and subscriptions can notify you whenever the data is changed (i.e., it’ll run whenever the post is published).</p>

<h3 id="why-do-we-need-serverless-graphql">Why do we need serverless GraphQL?</h3>

<p>“You can always deploy your GraphQL using Kubernetes and write your resolvers by hand,” the rubber duck said, “but there’s an easier way.”</p>

<p>GraphQL makes retrieving your data from the client-side effortless, but you still need to manage and scale your infrastructure. And now, you have one central place that controls all of your requests. Unless you do the same you do with the other web applications – make your application serverless. Serverless GraphQL brings the best of both worlds: GraphQL makes you client-to-server connection effortless, and serverless simplifies maintenance of your infrastructure.</p>

<p><img src="https://serverless.pub/img/the-power-of-serverless-graphql/10-scaling.png" alt=""></p>

<p>“Interesting, but how do I make GraphQL application serverless?”</p>

<p>“There are many ways to do that,” the rubber duck said. “You can do that manually using the familiar serverless services. For example, on AWS, you can use Amazon API …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://serverless.pub/the-power-of-serverless-graphql-with-appsync/">https://serverless.pub/the-power-of-serverless-graphql-with-appsync/</a></em></p>]]>
            </description>
            <link>https://serverless.pub/the-power-of-serverless-graphql-with-appsync/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25101263</guid>
            <pubDate>Sun, 15 Nov 2020 14:07:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why the Release of Ruby 3 Will Be Monumental]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25101102">thread link</a>) | @enogrob
<br/>
November 15, 2020 | https://www.ruby3.dev/the-art-of-code/2020/11/12/ruby-3-monumental/ | <a href="https://web.archive.org/web/*/https://www.ruby3.dev/the-art-of-code/2020/11/12/ruby-3-monumental/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>We’ve been living in the shadow of Ruby 2 for seven years now. Seven! <a href="https://www.ruby-lang.org/en/news/2013/02/24/ruby-2-0-0-p0-is-released/">Ruby 2 was released in 2013</a> (which incidentally is the same year as the initial public release of React 0.3.0!).</p>

<p>In that span of time, Ruby performance has improved <em>significantly</em> and many, many enhancements to the language have benefited a great many people and projects. We’ve seen companies using Ruby and in many cases Rails become bedrocks of developer and consumer internet infrastructure. GitHub. Shopify. Stripe. Square. AirBnB.</p>

<p>But there has also been some consternation along the way. Is Ruby really a top-tier programming language able to compete with the likes of Javascript, Python, PHP, Go, and beyond? Or was it just a DHH-fueled hype-cycle doomed to inevitable relative obscurity as other technologies and frameworks ascended in its wake? (I don’t actually believe anyone seriously thinks this any more, but you still see the stray head-scratcher whiz by on Hacker News.)</p>

<p>Now we are mere weeks away from a major new Ruby release: version 3. While Ruby 3 is an exciting update with lots of features that make it interesting both now and in the future with various point updates promising even more goodies, I think it’s the <strong>psychology</strong> of turning over from major version 2 to 3 that is most vital to the future health of the community.</p>

<p>Ruby 3 isn’t just a new version. <strong>It’s a new era.</strong></p>

<p>What does this era represent? Let’s list a few talking points I hope we’ll start to push <em>hard</em> and <em>often</em> as Rubyists:</p>

<h3 id="ruby-3-is-fast">Ruby 3 is Fast</h3>

<p>No, I don’t mean Ruby 3 suddenly got a whole lot faster than Ruby 2.7. I mean that Ruby 3 is <em>fast compared to Ruby 2</em>. It’s unfortunate that much of the “Ruby is slow” meme has been a laggard perspective stemming from people’s experiences <em>years ago</em> with the language, or an old version of Rails, or Jekyll, or…the fact is it just wasn’t the zippy experience we’re pleased to enjoy today.</p>

<p>Do we still want even better performance? Of course! But at this point, Ruby is plenty fast as compared to many other “scripting” languages. Most of the time it’s on par with Python. It’s even on par with Javascript. (What? Don’t believe me? <a href="https://css-tricks.com/comparing-static-site-generator-build-times/">Check out how similar Jekyll and Eleventy perform as static site generators.</a>) And as Nate Berskopec often reminds us, your Rails app can perform quite well with just a bit of fine-tuning, and often the typical bottlenecks lie elsewhere in the stack (database, web server, etc.)</p>

<h3 id="ruby-3-is-easy">Ruby 3 is Easy</h3>

<p>These days, you don’t need to wrestle with gem dependency hell or pray to the gods to get Ruby or a Ruby extension to compile. That was “old Ruby”. New Ruby is using a fancy-pants version manager like <code>rbenv</code> combined with Bundler 2.</p>

<p><strong>It just works.</strong></p>

<p>Truly, Ruby is the first thing I install on any new Mac or Linux machine I operate and getting things set up is a piece of cake. Installing Rails. Installing Bridgetown. Installing…whatever. It. Just. Works.</p>

<p>We also have things like Docker and WSL to make things <em>much</em> easier to accomplish on Windows machines if you get stuck wrestling with Win-native Ruby. Heck, you can upload your entire dev environment into the cloud now and use VSCode with remote extensions.</p>

<p>Are there ways Bundler and the ecosystem around Ruby versions/dependencies could be improved? No doubt. But it’s in no way any more complicated or fiddly than the world of npm/yarn, and you don’t see the angry hordes trying to burn down the barn doors over there (except maybe the Deno folks 😉).</p>

<h3 id="ruby-3-is-sleek">Ruby 3 is Sleek</h3>

<p>Ruby isn’t the best choice for all problem domains. It just isn’t. But when it comes to “standard” web development, it often <em>is</em> the best choice. It really is! Spend a few days writing NestJS + TypeORM Typescript code and then come back to Rails. It’s like a breath of fresh, sweet air. And that’s not just when you’re writing controllers or models…it goes all the way up and down the stack.</p>

<p>Ruby just makes everything <em>better</em>. Less code. Less boilerplate. Less ceremony. More streamlined. More properly object-oriented. More polished and pleasurable to read and write. Certainly one could posit there are other web frameworks/languages which have much going for them as well. Laravel is popular with PHP devs, and for good reason. Django is popular with Pythonistas. But can anyone say with a straight face that, all things being equal, PHP is a “superior” programming language to Ruby? Can anyone say that Python—taken as a whole—is more suited to building a website than Ruby is?</p>

<p>I think not. While Ruby wasn’t originally invented as a way to supercharge web development, it found its niche in the rise of such amazing projects as Rails, Rack, Jekyll, plus great APIs by Stripe and many others. It rode much of the early wave of Web 2.0 hits, and that heritage continues to benefit us today.</p>

<h3 id="ruby-3-is-here-to-stay">Ruby 3 is Here to Stay</h3>

<p>Ruby 3 isn’t just another notch on the belt of recent Ruby releases. It’s <strong>Ruby 3.0</strong>. That means we can look forward to 3.1, 3.2, 3.3, and beyond. This is the beginning of a whole new era. New innovations. New patterns. Exciting ideas fusing concepts from other technologies with The Ruby Way. Fresh blood coming into the ecosystem. (Anecdotally, I’m seeing newbies plus returning old-timers jumping into Ruby-based forums and chat rooms <em>all the time</em>, and the pace of interesting new Ruby gems bursting onto the scene finally seems to be increasing after a few years of ho-hum incremental progress.)</p>

<p>The takeaway is this: Ruby 3 represents a moment when we should stand proud as Rubyists and unabashedly proclaim to the bootcamps and engineering departments of the world that we’re open and ready to do business large and small. Sure you could pick something other than Ruby with which to build the next great internet success story. But you’ll definitely be in good company if you do pick Ruby. After all, it’s more likely than not your code will be living in a repository overseen by Ruby (GitHub), you’ll be communicating with your fellow colleagues via Ruby (Basecamp &amp; HEY), you’ll be asking for support via Ruby (Discourse forums), you’ll be researching the latest developer news and techniques via Ruby (Dev.to), and you’ll be spinning up your dev machine while wearing that l33t geek t-shirt you got from an indie vendor via Ruby (Shopify)—that is, after you paid for it via Ruby (Stripe). And when you’re exhausted from all that coding and need to unwind at a private cottage by the beach, Ruby will help you out there too (AirBnB).</p>

<p><em>Excelsior!</em></p>
</div></div>]]>
            </description>
            <link>https://www.ruby3.dev/the-art-of-code/2020/11/12/ruby-3-monumental/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25101102</guid>
            <pubDate>Sun, 15 Nov 2020 13:43:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Regaining Control of Your Computer]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25101094">thread link</a>) | @johndcook
<br/>
November 15, 2020 | https://www.datagubbe.se/subversive/ | <a href="https://web.archive.org/web/*/https://www.datagubbe.se/subversive/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>



<p>
or <b>Better Digital Living By Making Things Harder For Yourself</b><br>
or <b>I spent a Year Without Facebook and Google - Here's What Happened Next</b><br>
</p>

<p><em>Autumn 2020</em></p>


<p>
It's easy to grow disillusioned with tech, even to the point that it 
appals you. I've been using computers since 1988 and the net since 1995
and over time, something's happened. During the last decade or so, my 
mind has increasingly been preoccupied with the following thoughts:
</p>

<ul>
<li>I'm no longer in control of my computer and my OS.</li>
<li>The modern web is a cesspool of tracking scripts, ads, 
malware and clickbait designed to suck you in and make you stupid.</li>
<li>Even the most premium commercial software and hardware more often
than not comes with contraptions to spy on you.</li>
<li>"Cloud apps" are replacing programs I'd much rather run natively.</li>
<li>Thus, we sacrifice our privacy and intellects for faux conveniences.</li>
<li>The Idealist Net we fondly remember is long dead and unlikely to come
back.</li>
<li>...but there are still pockets of sanity left.</li>
</ul>

<p>
As a child of the home computer boom, I'm used to general purpose 
machines that do my bidding without interference from neither the 
manufacturer nor some unknown other wanting to sell me Depends and 
Bitcoins. That's what I want my computing to <i>still</i> be like.
</p>

<p>
The Man wants something different, though. The Man wants you to log in, 
click accept, sell your soul and Buy More Stuff. Hence, working to avoid 
that must be some level of subversive computing: Sticking it to The Man, 
one bit at a time.
</p>

<p>
In this text, I'll try to outline how I do my best to achieve that. Fair 
warning: it doesn't come without what some would call sacrifice, because 
you can't have the cake and eat it. This "sacrifice", however, might 
ultimately turn out to be beneficial.
</p>

<h2>What I absolutely do not use</h2>

<h3>Facebook</h3>

<p>
This is a dead giveaway, of course. No facebook and no facebook services 
(E.G. instagram, whatsapp, messenger, etc).
</p>

<p>
Quitting was, considering the circumstances, very easy. I'd had a 
facebook account since 2007 and I used to live there, sometimes posting 
several times a day and checking in much more often. In the summer of 
2019, I wrote a goodbye post and the day after, I closed my account. 
This is more than a year ago now and I don't miss it.
</p>

<p>
I had an Instagram account for a while, but only used it for maybe a 
month or two. It's the second stupidest "service" available on the net 
right now, and that's saying a lot: It is, quite literally, a site 
where millions of people post daily photos of their dinners. To put it 
as nicely as I can: Instagram has absolutely zero content of any kind of 
real importance to anyone.
</p>

<p>
<b>Coping strategy:</b> None, really. It turns out that people who are 
interested in meeting with or talking to you will send an email or text 
or perhaps even call you. I'm also particularly thankful I didn't have to
witness the COVID-19 debacle unfold on social media.
</p>

<h3>Twitter</h3>

<p>
Beating Instagram, Twitter is currently the stupidest site on the net. 
Best described as a slowly decomposing swamp of infighting and political 
bickering, it's full of people who will not yield a millimeter in any 
direction and will never, ever change their opinions about anything.
</p>

<p>
<b>Coping strategy:</b> None. Ditching twitter is something I advice 
everyone to do, even those who will gladly sell their DNA for a bit of 
"free" online convenience. You'll feel much more at peace with the world 
without it.
</p>

<h3>Google</h3>

<p>
If facebook is a dead giveaway, this is the truly crucial part of the 
concept. Facebook deals with distractions - Google deals with 
infrastructure. No longer one of many actors on the net, their monopoly 
quite simply dictates what goes and what doesn't. A recent reminder was 
when their domain blacklisting suddenly identified 
pouet.net, an innocent site for discussing the demo scene, as a spreader 
of malware. Things were, as usual, only resolved because someone knew 
someone who worked at Google. To discourage their thuggish, predatory 
behavior, we should avoid them in any way possible.
</p>

<p>
I closed down my Google account together with my Facebook account. I 
haven't missed that one, either. I also switched to searching with 
DuckDuckGo. The major point here is to <i>not</i> find a "replacement 
Google", such as Office 365 and Onedrive. That's not taking back control 
over your data, that's just handing it to the next buffoon for continued 
mining.
</p>

<p>
<b>Coping strategy:</b> I now pay for my email. A mom-and-pop hosts it 
all for a very reasonable yearly fee and they throw in some pretty 
decent web hosting, too. Complete self-hosting would of course be ideal 
from a privacy standpoint, but I'm happy with this solution. I can also 
mount the home directory through sshfs, which makes it an excellent 
"cloud drive". When I've been in contact with their customer support,
they've been timely, friendly, efficient and professional.
</p>

<p>
All things considered, it's probably nowhere near as safe 
from third-party intrusion and reliable against service outage as 
the Google equivalent, but then again I didn't use Google Drive for
anything important, either. That's what my hard drives and USB sticks are for. 
Don't hand over the stuff that matters to third parties if you can avoid 
it.
</p>

<p>
<b>Caveat:</b> Some people might actually need Google Docs for work, because 
employers like to force their employees into certain ecosystems. I'm 
forced into other ecosystems by mine, see
<a href="#tacs">Tradeoffs and Concessions</a>
below. The best option in these cases is of course to use it exclusively for 
work, exclusively on your work computer and in a separate web browser if
possible.
</p>

<h3>Many more sites</h3>

<p>
There are tons of sites, services and apps I don't use, for example 
Paypal and Dropbox. In fact, I avoid most sites where I have to register 
an account.
</p>

<h3>Phone Apps</h3>

<p>
My employer supplies me with a smartphone. On it I keep only the apps I 
need for work and banking. When commuting was still a thing, I also 
listened to Spotify. Other than that, I try to use it as little as 
possible these days. I do carry it with me, though: it mostly works fine 
as a phone and mobile phones are pretty damn convenient.
</p>

<p>
<b>Coping strategy:</b> I've never been fond of having a lot of apps.
Most of them are pointless and solve completely invented problems.
</p>

<h3>My local newspaper</h3>

<p>
I used to pay for an online subscription, until I just decided to stop 
one day. Apart from the poor quality of journalism, the biased reporting and 
the insipid editorial texts, I was basically paying money to keep feeding 
the online ad machine. That's a no-go.
</p>

<p>
<b>Coping strategy:</b> It's probably a reasonable idea to keep somewhat 
informed about current events. <a href="#news">See "News" below.</a>
</p>

<h2>Things I do use</h2>

<h3>Linux</h3>

<p>
In terms of user empowerment, even Canonical's Ubuntu with its telemetry 
and mysterious snap packages is so far a much better choice than any 
proprietary home computer OS on the market. From a privacy standpoint, 
other distributions, such as Debian and Slackware, are of course even 
better.
</p>

<h3>Native software</h3>

<p>
Turns out there are plenty of good programs that can be used completely 
offline and will let you store your files locally. They're not even hard 
to find. A few tips: Abiword, GNumeric, The Gimp, WordGrinder, 
Audacious.
</p>


<h3>The Web</h3>

<h4>The web, method one: Links2</h4>

<p>
The web still has good parts and I want to get at those good parts. 
Turns out the really good parts are usually remnants of The Old Web, 
consisting of HTML and great content.
</p>

<p>
I try to do as much web browsing as possible in Links2. It's a fast, 
lean browser with zero support for JavaScript and CSS. The latter means 
some sites look a bit funky. The former means some sites won't work at 
all. My usual strategy for sites that won't render without JavaScript is 
to simply ignore them. If they can't produce something worthwhile 
without scripting, it's probably not worthwhile at all.
</p>

<p>
On the plus side, no JavaScript means that most trackers and other spy- 
and malware just won't run at all. Since Links doesn't save <i>any</i> 
cookies between sessions, other means of tracking will at least be kept 
somewhat confused. The flip side is that it's probably an extremely 
unique browser fingerprint.
</p>

<h4>The web, method two: RSS and native applications</h4>

<p>
You can subscribe to Youtube channels, subreddits and pretty much every 
blog out there using RSS. There are also plenty of specialized TUI:s and 
CLI:s for interfacing with various popular websites such as Youtube and 
Reddit.
</p>

<h4>The web, method three: Firefox with UBlock Origin</h4>

<p>
For some things, like banking and filing taxes, the Internet really has 
made things so much more convenient I don't want to live without them. 
Although my bank could easily provide the services I use completely 
without a single line of JavaScript, they have decided not to. This also 
goes for most online shopping. For these types of sites, I use Firefox.
</p>

<h3>Youtube</h3>

<p>
There's still plenty of worthwhile content published on Youtube, not 
least recordings of demo scene productions for obscure hardware.
</p>

<p>
I watch Youtube using my own <a href="https://www.datagubbe.se/yt">tube script</a> in 
combination with a media player. It's not ideal, since Google will be 
able to infer a bit about my habits through my IP (although that could 
of course be mitigated using a VPN) and some videos don't work due to 
various restrictions imposed by their creators (or copyright laws). 
Somewhere around 90% of them do though, especially the interesting 
ones such as Computerphile and Numberphile. The upside is freedom from 
ads and algorithmic "recommendations": I watch only the videos I really 
want to watch.
</p>

<h3>Wikipedia</h3>

<p>
Still a useful and usable site.
</p>

<h3 id="news">News</h3>

<p>
Most of the content produced by news media is either clickbait or some 
kind of "commentary" by "experts" on actual headline news, which can 
then be milked for another couple of days. More often than not, the 
reporting is either misinformed, or biased, or both. Still, keeping 
somewhat updated can be beneficial for private decision making and 
overall …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.datagubbe.se/subversive/">https://www.datagubbe.se/subversive/</a></em></p>]]>
            </description>
            <link>https://www.datagubbe.se/subversive/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25101094</guid>
            <pubDate>Sun, 15 Nov 2020 13:41:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No one believes in climate change. Not really.]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25100984">thread link</a>) | @RikNieu
<br/>
November 15, 2020 | https://www.riknieu.com/no-one-believes-in-climate-change-not-really/ | <a href="https://web.archive.org/web/*/https://www.riknieu.com/no-one-believes-in-climate-change-not-really/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p>(Photo by <strong><a href="https://www.pexels.com/@sulimansallehi?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels">Suliman Sallehi</a></strong> from <strong><a href="https://www.pexels.com/photo/grey-concrete-structure-1481829/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels">Pexels</a>)</strong></p><p>(<strong>Warning</strong>: This is not a climate denial post, it's my reflection on the state of current affairs)</p><p>The idea of Climate Change doesn't seem to have product-market fit. They've marketed it hard and for decades but it's not really taking off. They've held multiple conferences with a range of &nbsp;popular or obscure characters as keynote speakers, tried bundling it with other products, and made some pretty good cartoons and movies about. And yet society as a whole's doesn't seem to be buying it.</p><p>No one cares about the fact that Climate Change is happening and accelerating. Not really.</p><p>Don't get me wrong - there's lot's of talk <em>about</em> caring about Climate Change, but the real issue is not being seriously address by anyone. Let me explain.</p><h2 id="in-politics-climate-change-is-just-gang-sign-or-pom-poms-">In politics, Climate Change is just gang-sign. Or pom-poms.</h2><p>Climate change is often mentioned in political discussions and, for some reason, seems to be a largely partisan issue, specifically in the Western world. </p><p>It's an excellent tool to signal your affiliation. You see, if you paint it one colour, you can use it as a patch on your conservative jacket. Go Reds! When you paint it another, it's great insignia for your liberal banners. Go Blues! What colour words you use tells other people which gang you belong to.</p><p>For politicians Climate Change is mostly taken seriously as a tool too rile their base. It's very useful to shake around and manipulate your team's spirit. Rah-rah-rah!</p><p>For the conservatives, you're expected to doubt it's veracity, or at the very least, play down its seriousness. Conservative-lites, for instance, will very vaguely argue that technology and human ingenuity will eventually help us all coast this annoying artifact of progress. Full-fat conservatives will go whole-hog and <a href="https://www.scientificamerican.com/article/climate-skeptics-want-more-co2/">argue it'll be of net benefit to society</a>.</p><p>On the liberal side they have their own range of cheers. Liberal-lites are very keen on raising taxes on production, which they argue would somehow help cool down the world. Full-fat liberals try to use Climate Change as an argument for going communist, because we all know communist societies won't engage in any industrialised production.</p><p>But both sides merely skirt around the issue when it comes down to it. It's merely one string connected to the levers which make their supporters dance. And it's often used as a more palatable brand to be wrapped like a mask over schemes that try and force action of other, unrelated kinds, that they know would not have broader public appear.</p><h2 id="for-large-orgs-it-s-press-release-porn">For large Orgs, it's press release porn</h2><p>Then there's the giant multinationals and intergovernmental organisations. They love to throw around the words "Climate" or "Environmentally friendly" too. It's excellent press-release porn.</p><p>There's a regular, periodic drip of kumbaya-like statements from these hydras, with vague expressions of their "great concerns" and "action needing to be taken". The young folks loves that shit, right? </p><p>You see, a well-crafted press release is amazing for creating the illusion of action. It's excellent moral insurance cover. "We often spoke about our concerns, with quite a lot of words and various agreeable degrees of sternness."</p><p>Then there's the epic events. Climate Change is a pretty rad reason to organise those. They have them often. Fly a whole bunch of delegates to this expensive venue in that remote country. There's lots of food and freebies, well-lit stages, fancy hotels and banquets. The pamphlets and banners with their tastefully designed artwork make for excellent photo-op backdrops. The world needs to see how much these very important organisations and their people care. </p><p>For-profit organisations also know how to use Climate Change effectively. It's marketing gold - so hot right now! It's a very effective tool to justify asking for more money while giving less in return. Tell your customers it's for the good of the colony! That charger that you now need to buy separately will surely save us all.</p><p>My point is of course that when it comes to Climate Change<em>,</em> the leaders of our societies, even the ones that don't outright deny that it's happening, all shout out slogans, make speeches, and then recede into the shadows of bureaucracy.</p><p>"Showing support" is easy, cheap and keeps the masses content. No serious thought or action is being mustered into how we're <em>actually</em> going to deal with the arrival of this c<a href="https://www.cbsnews.com/news/new-climate-change-report-human-civilization-at-risk-extinction-by-2050-new-australian-climate/">ivilisation-ending threat</a>. </p><p>Some parts of some governments <em>are</em> actually thinking about it, <a href="https://www.vox.com/2020/2/24/21145687/climate-change-usa-military-book-interview">like the militaries,</a> but for the rest it's just lip service.</p><p>"COVID!", you might retort, "showed us that governments <em>can</em> take swift and decisive action! So there's hope! We just need to vote more and start grass-roots movements!"</p><p>Well, sure, governments did take action with COVID. But most of them took too little action too late. And let's not even go into the mad-surge of power grabbing that happened - the rights being sacrificed on the altar of Security. Or my own government taking the opportunity to elevate corruption and state-looting to new, ever-refined heights.</p><p>But sure, let's simplify it and just consider the fact that action was taken. The problem is that action was only taken when the sparks began to fly. <a href="https://www.theguardian.com/world/2020/jul/15/revealed-the-inside-story-of-europes-divided-coronavirus-response">Action was taken when the viruses were at the gate</a>. Rome had to fall before anyone felt bothered enough to get up.</p><p>Another example of when people collectively decided to take mass action was with the BLM protests. Or the recent electoral battle between the two old men in the US. Magnificent events, for sure. The people made their voices heard. </p><p>But on closer consideration, doesn't it simply add more evidence to my assertion that nobody really believes in Climate Change? It's clearly not deemed important enough to warrant similar such action.</p><p>Well, that's not really true, I guess. </p><p>There was the Climate Change protests in 2019, like the <a href="https://en.wikipedia.org/wiki/September_2019_climate_strikes#:~:text=The%20September%202019%20climate%20strikes,place%20from%2020%E2%80%9327%20September.&amp;text=The%2020%20September%20protests%20were,climate%20strikes%20in%20world%20history.">Global Week for Future</a>. Let's be honest though, nothing really came of that. Lot's of noise was made, lots of fun chanting. School was skipped, selfies were taken. Camaraderie was felt, but <em>actual</em> change was as good as being on holiday. And ever so swiftly, with the emergence of the virus shenanigans, Greta &amp; co also faded into the background.</p><p>Then there's the <a href="https://en.wikipedia.org/wiki/Extinction_Rebellion">Extinction Rebellion</a>. They're hard core. Excellent name too, really catchy. Too extreme for mainstream narratives though, too aggressive and offensive. You can't run feel-good stories after covering that lot. The responsible media can't support such hooliganism.</p><p>So I admit, there <em>were</em> social movements trying to rouse society into action, but they lost steam and fizzled out. Not enough traction. Not compelling enough. Just a fad. No product-market fit.</p><p>I've been thinking about this for quite a while. It's a recurring theme when reading some of the comments on Reddit and HackerNews when the weekly Climate horror threads bubble up. Is it hopelessness, disbelief, distant consequences or laziness? </p><p>Because i<a href="https://climate.nasa.gov/news/3041/beating-back-the-tides/">t's</a> <a href="https://www.sciencedaily.com/releases/2020/11/201109152241.htm">not</a> <a href="https://www.theguardian.com/science/2020/nov/13/rising-levels-of-carbon-dioxide-increasing-extreme-weather-events-in-australia-report-finds">due</a> <a href="https://www.independent.co.uk/environment/climate-change/hurricane-eta-storm-2020-climate-change-b892557.html">to</a> <a href="https://www.independent.co.uk/environment/arctic-sea-ice-level-climate-change-global-warming-siberia-b1345792.html">a</a> <a href="https://www.telegraph.co.uk/news/2019/10/08/russian-scientists-find-powerful-ever-methane-seep-arctic-ocean/">lack</a> <a href="https://climate.nasa.gov/news/3008/stunning-forecast-a-century-of-ice-loss-for-nearly-100000-glaciers/">of</a> <a href="https://www.nature.com/articles/s41598-020-75481-z">evidence</a>. There's <strong>tons</strong> of evidence that things will unhinge pretty soon, and there has been for years. Never mind the fact that even the <a href="https://www.theguardian.com/business/2016/apr/13/climate-change-oil-industry-environment-warning-1968">oil companies knew what they were doing</a> in the 60s, or that even further <a href="https://daily.jstor.org/how-19th-century-scientists-predicted-global-warming/">back in the 19 century, some had started to suspect that things could get bad</a>. </p><p>Then there was also that fun little controversial book, written ages ago in 1972, called <a href="https://en.wikipedia.org/wiki/The_Limits_to_Growth#Conclusions">The Limits to Growth</a>. And what a page-turner it was! Thrilling stuff. </p><p>Here's a trailer.</p><figure><iframe width="480" height="270" src="https://www.youtube.com/embed/cCxPOqwCr1I?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><p>The Limits to Growth caused quite the stir. But not in a good way. It upset quite a lot of people. It dared suggest that our progress was, in fact, not that. And that we should maybe stop.</p><p>Sure, it could be argued that it was based on the results of an oversimplified model with oversimplified assumptions and oversimplified data. <a href="https://www.theguardian.com/commentisfree/2014/sep/02/limits-to-growth-was-right-new-research-shows-were-nearing-collapse">But in hind-sight it seems to have gotten quite a lot, scarily right.</a> </p><p>By all appearances,<a href="https://ec.europa.eu/environment/ecoap/about-eco-innovation/research-developments/eu/limits-to-growth-predictions-borne-out-analysis-finds_en"> we've been heading down the Business As Usual scenario</a> from that study, and things seem to be right on track for our interconnected global civilisation to hit that brick wall quite hard, quite fast.</p><p>And the book didn't even really deal with climate change per se, as we understand it today anyway. Only with regards too good 'ol generic resource overexploitation. </p><p>Now, the point of this post is not to lay out all the evidence and arguments to prove the veracity of the horrendous shit-show that is coming. That has been done millions of times before and is just a Google search away. </p><p>Neither is the aim to go through the all the specific claims of books and studies like the Limits of Growth with a fine-toothed comb to judge exactly how accurate they are. This is not necessary, because there've been enough different studies focussing on different aspects of our effect on the environment, and they all seem to come together as pixels of same picture.</p><p>Make no mistake, it sure looks like the apocalypse is coming. And society(and those driving it) has know this for quite a while. We either just don't care or we're paralysed with fear.</p><p>So how bad can it really? Well, here's a humorous little clip from way back in 2014, to set the scene.</p><figure><iframe width="459" height="344" src="https://www.youtube.com/embed/XM0uZ9mfOUI?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><p>That's from the fictional show Newsroom. <a href="https://www.motherjones.com/politics/2014/11/climate-desk-fact-checks-aaron-sorkins-climate-science-newsroom/">MotherJones did a fact-check on the claims being made in the scene</a> and turns out, it's disturbingly accurate. </p><p>Note the reporter's response at 2:34. Ha. Enlightening, isn't it? And at 3:06, listen carefully. Does that not sound like the intro fo episode 2020 of Humans on Earth?</p><p>Here's some more fun scientific predictions of where things are headed;</p><ul><li><a href="https://www.weforum.org/agenda/2020/02/coral-reefs-climate-crisis-environment-oceans">Most coral reefs will be wiped out by 2100</a></li><li><a href="https://www.theguardian.com/environment/2020/oct/05/amazon-near-tipping-point-of-switching-from-rainforest-to-savannah-study">The Amazon rainforest will turn into a Savannah-like environment</a></li><li><a href="https://www.sciencealert.com/oceans-are-on-their-way-to-rising-over-a-meter-as-soon-as-2100">The sea level may rise up to 1.3m/4ft by 2100</a></li><li><a href="https://blogs.ei.columbia.edu/2018/07/25/climate-change-food-agriculture/">Food production could drop by double-digit figures by 2100</a></li><li><a href="https://openknowledge.worldbank.org/handle/10986/29461">Mass migrations of about 143 million people by 2050</a></li><li><a href="https://www.nature.com/articles/nclimate3322">74% of the world's population could be regularly exposed to lethal heat events by 2100</a></li><li><a href="https://www.gfdl.noaa.gov/global-warming-and-hurricanes/">More intense, frequent and longer lasting hurricanes</a></li><li><a href="https://www.theatlantic.com/science/archive/2017/11/the-zombie-diseases-of-climate-change/544274/">The emergence of ancient diseases and pathogens from melting permafrost</a></li><li><a href="https://www.pnas.org/content/113/42/11770.full">Did you like the wildfires this year? That was just a test run</a></li><li><a href="https://www.vox.com/world/2017/11/14/16589878/global-climate-change-conflict-environment">World-wide resource wars will become …</a></li></ul></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.riknieu.com/no-one-believes-in-climate-change-not-really/">https://www.riknieu.com/no-one-believes-in-climate-change-not-really/</a></em></p>]]>
            </description>
            <link>https://www.riknieu.com/no-one-believes-in-climate-change-not-really/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25100984</guid>
            <pubDate>Sun, 15 Nov 2020 13:23:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You may not need Redis with Elixir]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25100884">thread link</a>) | @thibaut_barrere
<br/>
November 15, 2020 | https://dashbit.co/blog/you-may-not-need-redis-with-elixir | <a href="https://web.archive.org/web/*/https://dashbit.co/blog/you-may-not-need-redis-with-elixir">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <article>
    
<ul>
  <li>
    <i></i> José Valim
  </li>
  <li>
    <i></i> November 11th, 2020
  </li>
  <li>
    <i></i><a href="https://dashbit.co/blog/tags/redis">redis</a>, <a href="https://dashbit.co/blog/tags/phoenix">phoenix</a>, <a href="https://dashbit.co/blog/tags/pubsub">pubsub</a>, <a href="https://dashbit.co/blog/tags/processes">processes</a>
  </li>
</ul>
<p>
If you have participated in a discussion about Elixir, you may have heard “you may not need Redis with Elixir”. Given that Redis has many use cases, this sentence may confuse developers as they try to match Elixir’s different features against Redis’ capabilities. This article aims to explore different scenarios where the above is true, when they are not, and which trade-offs you may want to consider. We will discuss four cases:</p>
<ol>
  <li>
<a href="#post-pubsub">Distributed PubSub</a>  </li>
  <li>
<a href="#post-presence">Presence</a>  </li>
  <li>
<a href="#post-caching">Caching</a>  </li>
  <li>
<a href="#post-async">Asynchronous processing</a>  </li>
</ol>
<p>
Before we start, I want to emphasize we find Redis a fantastic piece of technology. This is not a critique of Redis but rather a discussion of the different options Elixir developers may have available.</p>
<h2 id="post-pubsub">
  Case #1: Distributed PubSub</h2>
<p>
The first scenario where you may not need Redis with Elixir is Distributed <a href="https://en.wikipedia.org/wiki/Publish%E2%80%93subscribe_pattern">PubSub</a>. Throughout this section, we will consider PubSub systems to provide <strong>at-most-once delivery</strong>: they broadcast events to the currently available subscribers. If a subscriber is not around, they won’t receive the message later.</p>
<p>
For this reason, PubSub systems are often paired with databases to offer persistence. For example, every time someone sends a message in a chat application, the system can save the contents to the database and then broadcast it to all users. This means everyone connected at a given moment sees the update immediately, but disconnected users can catch up later.</p>
<p>
Imagine that you have multiple nodes, and you want to exchange messages between said nodes. In Elixir, thanks to the Erlang VM, which ships with distribution support, this can be as simple as:</p>
<pre><code><span>for</span><span> </span><span>node</span><span> </span><span>&lt;-</span><span> </span><span>Node</span><span>.</span><span>list</span><span data-group-id="8737372369-1">(</span><span data-group-id="8737372369-1">)</span><span> </span><span data-group-id="8737372369-2">do</span><span>
  </span><span>send</span><span data-group-id="8737372369-3">(</span><span data-group-id="8737372369-4">{</span><span>:known_name</span><span>,</span><span> </span><span>node</span><span data-group-id="8737372369-4">}</span><span>,</span><span> </span><span>:hello_world</span><span data-group-id="8737372369-3">)</span><span>
</span><span data-group-id="8737372369-2">end</span></code></pre>
<p>
In <a href="https://github.com/phoenixframework/phoenix_pubsub/blob/master/lib/phoenix/pubsub.ex">200LOC or less</a>, you can implement a PubSub system that broadcasts to all subscribers within the same node or anywhere else in a cluster, without bringing any third-party tools. At best, you will need <a href="https://github.com/bitwalker/libcluster">libcluster</a> - an Elixir library - to establish the connection between the nodes based on some strategy (K8s, AWS, DNS, etc.).</p>
<p>
In other words, PubSub pretty much ships out of the box with Elixir. Technologies without distribution would need to rely on Redis PubSub, PostgreSQL Notifications, or similar to achieve the same.</p>
<p>
Of course, the above assumes your infrastructure allows you to directly establish connections between nodes, which may not be possible in some PaaS, such as Heroku. In those cases, you can use any of the technologies above (Phoenix <a href="https://dashbit.co/blog/github.com/phoenixframework/phoenix_pubsub_redis/">has a Redis adapter</a> for its PubSub), or alternatively use platforms, such as <a href="https://www.gigalixir.com/">Gigalixir</a>, that make it trivial to setup a cluster.</p>
<h2 id="post-presence">
  Case #2: Presence</h2>
<p>
Presence is the ability to track who is connected in a cluster right now — the “who” may be users, phones, IoT devices, etc. For example, if Alice is connected to node A, she wants to see that Bob is also available, even if he has joined node B.</p>
<p>
Presence is one of the problems that are more complicated to implement than it sounds. For example, let’s consider implementing Presence by storing the connected entities in a database. However, what happens if a node crashes or leaves the cluster? Because the node crashed, all the users connected to it must be removed, but the node itself cannot do so. Therefore the other nodes need to detect those failure scenarios and act accordingly. But observing failures in a distributed system is also complicated: how do you differentiate between a temporarily unresponsive node from one that permanently failed?</p>
<p>
Another common approach to solve this problem is to frequently write to a database while users are connected. If you have seen no writes within a timeframe, you consider those users to be disconnected. However, such solutions have to choose between being write-intensive or inaccurate. For instance, let’s say that users become disconnected after 1 minute. This means that you need to write to the database every 1 minute for every user. If you have 10k users, that’s 167 writes per second, only to track that the users are connected. Meanwhile, the gap between a user leaving and having their status reflected in the UI is, in the worst-case scenario, also 1 minute. Any attempt at reducing the number of writes implies an increased gap.</p>
<p>
Given Elixir’s clustering support, we can once more implement <a href="https://hexdocs.pm/phoenix/Phoenix.Presence.html">Presence</a> without a need for third-party dependencies! We use a PubSub system to implement Presence, as we need to notify as users join and leave. Instead of relying on centralized storage, the nodes directly communicate and exchange information about who is around. This removes the need for frequent writes. When a user leaves, this is also reflected immediately.</p>
<p>
So while you can use Redis or another storage to provide Presence, Elixir can deliver a solution that is efficient and doesn’t require third-party tools.</p>
<h2 id="post-caching">
  Case #3: Caching</h2>
<p>
The solutions to previous cases were built on top of Erlang’s unique distribution capabilities. In the following sections, the distinguishing factor between needing Redis or not will be <strong>multi-core concurrency</strong>, so this discussion is more generally applicable. Therefore, when we say Elixir in this section, it will also apply to JVM, Go, and other environments. They will contrast to Ruby, Python, and Node.js, in which their primary runtimes do not provide adequate multi-core concurrency within a single Operating System process.</p>
<p>
Let’s start with the non-concurrent scenario. Consider you are building a web application in Ruby, Python, etc. To deploy it, you get two eight-core machines. In languages that do not provide satisfactory multi-core concurrency, a common option for deployment is to start 8 instances of your web application, one per core, on each node. Overall, you will have CxN instances, where C is the number of cores, and N is the number of nodes.</p>
<p>
Now consider a particular operation in this application that is expensive, and you want to cache its results. The easiest solution, regardless of your programming environment, is to cache it in memory. However, given we have 16 instances of this application, caching it in memory is suboptimal: we will have to perform this expensive operation at least 16 times, one for each instance. For this reason, it is widespread to use Redis, Memcached, or similar for caching in environments like Ruby, Python, etc. With Redis, you would cache it only once, and it will be shared across all instances. The trade-off is that we are replacing memory access by a network round-trip, and the latter is orders of magnitude more expensive.</p>
<p>
Now let’s consider environments with multi-core concurrency. In languages like Elixir, you start one instance per node, regardless of the number of cores, since the runtime will share memory and efficiently spread the work across all cores. When it comes to caching, keeping the cache in-memory is a much more affordable scenario, as you will only have to compute once per node. Therefore, you have the <em>option</em> to skip Redis or Memcached altogether and avoid network round-trip.</p>
<p>
Of course, this depends on how many nodes you are effectively running in production. Luckily, many companies report being able to <a href="https://dev.to/erlangsolutions/why-elixir-is-the-programming-language-you-should-learn-in-2020-5g00">run Elixir with an order of magnitude less nodes</a> than technologies they have migrated from.</p>
<p>
You can also choose a mixed approach and store the cache both in-memory and in Redis. First, you look up in memory and, if missing, you fallback to Redis. If unavailable in both, then you execute the operation and cache it in each. The critical part to highlight here is that multi-core environments give you more flexibility to tackle these problems while reducing resource utilization. In Elixir/Erlang, you can also keep the cache in memory and use PubSub to distribute it across nodes. You can see this last approach in action <a href="https://github.com/tompave/fun_with_flags">in the excellent FunWithFlags library</a>.</p>
<p>
Another trade-off to consider is that all in-memory cache will be gone once you deploy new nodes. Therefore, if you need data to persist across deployments, you will want to use Redis as a cache layer, as detailed above, or dump the cache in a storage, such as database, S3, or Redis, before each deployment.</p>
<h2 id="post-async">
  Case #4: Asynchronous processing</h2>
<p>
Another scenario you may not need Redis in Elixir is to perform asynchronous processing. Let’s continue the discussion from the previous case.</p>
<p>
In environments without or with limited multi-core concurrency, given each instance is assigned to one core, they are limited in their ability to handle requests concurrently. This has led to a common saying that “you should avoid blocking the main thread”. For example, imagine that your application has to deliver emails on sign up or generate some computationally expensive reports. While one of your 16 web instances is doing this, it cannot handle other incoming requests efficiently. For this reason, a common choice here is to move the work elsewhere, typically a background-job processing queue. First, you store the work to be done on Redis or similar. Then one of the 16 web instances (or more commonly a completely different set of workers) grabs it from the queue.</p>
<p>
In multi-core concurrent environments, requests can be handled concurrently regardless if they are doing CPU or IO work. Sending the email from the request itself won’t block other requests. Generating the report is not a problem, as requests can be served by other CPUs. These platforms typically get assigned as many requests as they can handle and they distribute the work over the machine resources. Even if you prefer to deliver emails outside of the request, in order to send an earlier response to users, you can spawn an asynchronous worker without a need to move the delivery to an external queue or to another machine. Once again, concurrency gives us a more straightforward option to tackle these scenarios.</p>
<p>
Note the Erlang VM takes care of multiplexing CPU and IO work without a need for developers to tag functions as async or similar. Workers in Erlang/Elixir are …</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dashbit.co/blog/you-may-not-need-redis-with-elixir">https://dashbit.co/blog/you-may-not-need-redis-with-elixir</a></em></p>]]>
            </description>
            <link>https://dashbit.co/blog/you-may-not-need-redis-with-elixir</link>
            <guid isPermaLink="false">hacker-news-small-sites-25100884</guid>
            <pubDate>Sun, 15 Nov 2020 13:07:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Moving my serverless project to Ruby on Rails]]>
            </title>
            <description>
<![CDATA[
Score 329 | Comments 170 (<a href="https://news.ycombinator.com/item?id=25100397">thread link</a>) | @pcr910303
<br/>
November 15, 2020 | https://frantic.im/back-to-rails | <a href="https://web.archive.org/web/*/https://frantic.im/back-to-rails">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <header>
    
    
  </header>
  <p>I have a small side project: <a href="https://hacker.gifts/">digital gift cards for hackers</a>. It uses Shopify for all the store-related stuff: frontend, payments, refunds, reports, etc.</p>

<p>But unlike regular digital products (ebooks, videos) I wanted each card that the user purchases from the store to be unique. So I made a  script that generates personalized images and ran it manually for every order.</p>

<p>The next logical step was automating this process. I started with serverless AWS Lambda. At the time it was the hot new tech and I wanted to learn more. It seemed very fitting for my use-case: single-responsibility functions that can run at any time and don’t require server maintenance.</p>

<p><img src="https://frantic.im/assets/back-to-rails/simple-lambda.png" alt=""></p>

<p>It was super easy to get started. I built a JavaScript function and deployed it to AWS Lambda, added Shopify web hook and it all worked!</p>

<p>Early benefits of serverless (for hobby projects):</p>

<ul>
  <li>Easy to get started</li>
  <li>Don’t have to configure or maintain servers</li>
  <li>Free for small loads</li>
</ul>

<p>In reality, writing the simple Lambda functions turned out to be only 10% of the work.</p>

<p>Time passed and my backend started getting more complex: I needed to store some state for each <a href="https://hacker.gifts/products/space-invaders">puzzle</a>, send confirmation emails, show an order details page. What started as a simple function, grew into a bunch of serverless functions, SNS topics, S3 buckets, DynamoDB tables. All bound together with plenty of YAML glue, schema-less JSON objects passed around and random hardcoded configs in AWS console.</p>

<p>I think it’s just a typical software development lifecycle: things grow organically, become a mess, and require some refactoring. Make it run first (discover market fit), then make it right (refactor to integrate the new discoveries).</p>

<p>But this time it was different. I couldn’t refactor things as easily as I used to in traditional monolithic apps. Here’s why:</p>

<p>When the building blocks are too simple, the complexity moves into the interaction between the blocks.</p>

<p>And the interactions between the serverless blocks happen <em>outside</em> my application. A lambda publishes a message to SNS, another one picks it up and writes something to DynamoDB, the third one takes that new record and sends an email…</p>

<p>I could test every single block in that flow, but I didn’t have confidence in the overall process. What if publishing fails, how would I know that? How would system recover? Can I rollback and try again? Where do the logs go?</p>

<p>Another swarm of problems was hiding in my configuration: bad Route 53 record, typos in SNS topics, wrong S3 bucket region. Tracing errors was a challenge, there’s no single log output I can look into.</p>

<p>With serverless, I was no longer dealing with my project's domain, I was dealing with the distributed system's domain.</p>

<p>At this point I felt fooled.</p>

<p>I came for the easy way to deploy code and not think about servers, but in the end had to design my system around the platform’s limitations.</p>

<p>Drawbacks of serverless (for hobby projects):</p>

<ul>
  <li>Hard to follow information flow</li>
  <li>Impossible to replicate production environment locally</li>
  <li>Slow iteration speed</li>
  <li>Lack of end-to-end testing</li>
  <li>Immature documentation (dominated by often outdated Medium posts)</li>
  <li>No conventions (have to make hundreds of unessential decisions)</li>
</ul>

<p>—</p>

<p>I was clearly not enjoying the serverless. So I decided to rewrite it. After all, it is a side project I’m doing for fun. The tech stack of choice — Ruby on Rails.</p>

<p>I haven’t used Rails since 2013, and for the last 8 years at Facebook I’ve been mostly doing JavaScript.</p>

<p><img src="https://frantic.im/assets/back-to-rails/logo.jpg" alt=""></p>

<p>The experience of picking Rails back up was really nice but… uneventful. Not much had really changed. A few things got added, a few small things moved around.</p>

<p>Of course I did <a href="https://github.com/rails/rails/issues/38060">hit some magical Ruby issues</a>. But unlike my typical experience with JavaScript, I was quickly able to find the solution.</p>

<p>Rails comes with so many things built-in and configured. Over the years, without Rails, I used to gluing random JavaScript libraries together to roll my own routing, file storage wrappers, email preview pipeline, managing secrets, test setup with fixtures, database migrations, logging, performance reporting, deployment scripts. With Rails I didn’t have to think about all these details and could simply focus on making product-visible changes.</p>

<p>It was like driving a Tesla after years of making my own scrappy cars. Similar components, but all configured and aligned to work well together.</p>

<p>Benefits of Rails (for hobby projects):</p>

<ul>
  <li>Conventions</li>
  <li>Tooling, libraries</li>
  <li>Documentation</li>
  <li>Monolith is easy to understand and test</li>
</ul>

<p>Drawbacks of Rails (for hobby projects):</p>

<ul>
  <li>Feels heavyweight in the beginning</li>
  <li>Hurts if your opinions differ from Rails conventions</li>
  <li>Have to host on a server</li>
  <li>Doesn’t sound cool in 2020 (anymore and maybe yet)</li>
</ul>

<p>—</p>

<p>Serverless is like a black hole. It promised exciting adventures, but gravity sucked me in and I spent most of my efforts dealing with its complexity, instead of focusing on my product.</p>

  
  






  <div>
  <div>
    <p>Hi! My name is Alex. I’m a software engineer at Facebook, where I work on React&nbsp;Native, Oculus and Messenger. I love thinking about development experience.</p>
    <p>I write about programming, software design and side projects <a href="https://frantic.im/subscribe/" target="_blank"><svg viewBox="0 0 800 800"><path d="M493 652H392c0-134-111-244-244-244V307c189 0 345 156 345 345zm71 0c0-228-188-416-416-416V132c285 0 520 235 520 520z"></path><circle cx="219" cy="581" r="71"></circle></svg> Subscribe</a></p>
  </div>
</div>

</article></div>]]>
            </description>
            <link>https://frantic.im/back-to-rails</link>
            <guid isPermaLink="false">hacker-news-small-sites-25100397</guid>
            <pubDate>Sun, 15 Nov 2020 11:40:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A framework for offline and decentralised web apps]]>
            </title>
            <description>
<![CDATA[
Score 33 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25100313">thread link</a>) | @dgellow
<br/>
November 15, 2020 | https://concords.app/blog/what-is-concords | <a href="https://web.archive.org/web/*/https://concords.app/blog/what-is-concords">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><p>Concords is an MVP framework for building offline &amp; decentralised web apps, with a file-based approach to storing data. It has no servers or databases and is a static app built with Javascript and HTML, all code is written to run in a browser and nothing is stored outside of the browser or downloaded files.</p> <p>The full MVP is available to try at <a href="https://alpha.concords.app/" rel="nofollow" target="_blank">alpha.concords.app</a></p> <h2 id="why">Why?</h2> <p>SAAS applications run on servers with databases. Each interaction with the UI sends information from the browser to a server, which then likely writes something or fetches something from a centralized database.</p> <p>Maintaining servers and databases is expensive, complex and time-consuming and I'm not really interested in that side of software. I don't want the responsibility to look after data that is depended upon, that's neither my skill-set nor passion. I like to focus my attention on the front-end experience.</p> <p>I set out to build a framework for file-based SAAS apps. Multi-user collaborative apps, with data-driven user flows and advanced UI. But apps that run offline and save state to the filesystem, not send it off to a cloud-based database. Giving users full ownership and visibility of their data, with no dependency on an internet connection. Taking a progressive approach to connectivity, using it to enrich the experience, but not depend on it.</p> <h2 id="technical-steps">Technical Steps</h2> <ul> <li><p>Functional blockchain library in Typescript.</p> </li> <li><p><a href="https://svelte.dev/" rel="nofollow" target="_blank">Svelte</a> &amp; <a href="https://sapper.svelte.dev/" rel="nofollow" target="_blank">Sapper</a> for all things UI.</p> </li> <li><p>Blockchain sync with IndexedDB and reactivity hook.</p> </li> <li><p>Created <a href="https://1.0.0.concords.app/" rel="nofollow" target="_blank">some mini-apps</a> to refine and test the core functionality.</p> </li> <li><p>User Authentication flow.</p> </li> <li><p><a href="https://alpha.concords.app/" rel="nofollow" target="_blank">MVP: Kanban app</a>.</p> </li> </ul> <h2 id="concords-mvp-board-app">Concords MVP: Board App</h2> <p>This MVP serves to demonstrate a basic solution to a truly offline and decentralized experience in a collaborative web app. It's a static app, so just Javascript and HTML, with no servers or databases running in the background. It's a progressive web app with a service worker, that runs entirely in the browser. So once the initial load has been performed, the rest of the experience can work completely offline, where data is stored in files, downloaded and uploaded through the UI.</p> <p>A boards app covers a lot of functionality commonly found in SAAS applications, I figured it's a great benchmark to prove out the technology.</p> <p><img alt="" src="https://concords.app/flows/add-task.gif?raw=true"></p> <hr> <h3 id="authentication">Authentication</h3> <p>With Concords, authentication is all done in the browser, without any communication to a server or external resource.</p> <p>In the Concords authentication system, we issue a downloadable public profile which includes your public key and some basic user info. I keep mine for the MVP on my personal domain. <a href="https://ternent.dev/concords/sam-ternent.profile.concords.json" rel="nofollow" target="_blank">https://ternent.dev/concords/sam-ternent.profile.concords.json</a></p> <p>Anyone with access to my public key is able to encrypt data for me, that only I can read with my private key. I just have that stored on my personal machine. It’s never been online and no-one else knows it.</p> <p>This key is used to log the user into the app and only a valid key combination can login and access the software.</p> <p>For my MVP, this is more than sufficient to complete and decent authentication flow. We can have a recognisable UX of profile/password combination to build a login system, whilst setting us up for an encrypted, multi-user, data flow.</p> <p><img alt="" src="https://concords.app/flows/signup.gif?raw=true"></p> <hr> <p>I know it's a pain to ask users to store both parts of their encryption keys themselves. If the private key is lost, it's unrecoverable and so is any encrypted data to that key. But I couldn't compromise here, it has to be this way to keep things decentralized. But it's a problem that can be fixed through software, it doesn't have to be my software - we're decentralizing things here, but key management software will fix this problem.</p> <h3 id="the-app">The App</h3> <p>Knowing roughly what I needed to build to prove out the concept, and having already implemented User Profile and the authentication flow, the key features I chose to implement were:</p> <ul> <li>Create new and multiple boards</li> <li>Downloadable app files</li> <li>Load any board, from any user</li> <li>Assign tasks to users</li> <li>Editable tasks</li> <li>Timestamped actions</li> <li>Drag to sort columns</li> <li>Draggable tasks across columns</li> <li>Soft delete tasks to the trash, with restore and remove</li> <li>Activity log with an immutable history of the board</li> </ul> <p><img alt="" src="https://concords.app/flows/create-board.gif?raw=true"></p> <hr> <h4 id="multiple-users">Multiple Users</h4> <p>By default, a new user doesn't have edit access to a document. For the purpose of the MVP, we've got a "Join" button in the left-hand sidebar. Clicking this will add the user as an entry to the data store and unlock editing. This covers the concept enough for now, but we are able to achieve direct encryption with the public/private key authentication, so that's going to be an interesting avenue to explore further outside of the MVP context.</p> <p><img alt="" src="https://concords.app/flows/third-user.gif?raw=true"></p> <hr> <h3 id="core-library">Core Library</h3> <p>The core of the framework is written in Typescript. It's a collection of functional utilities which cover the data side of the application. It runs an internal blockchain for writing data, mapped with an IndexDB instance for reading.</p> <h4 id="blockchain">Blockchain</h4> <p>At the heart of the library is the <a href="https://hackernoon.com/merkle-tree-what-is-it-and-why-use-it-8m2a63xjd" rel="nofollow" target="_blank">Merkel Tree</a> solution. Our Merkle Tree (as used in Blockchain and git), is a functional library to act as a blockchain node, from a JSON object structure, in the browser.</p> <p>Built on top of that is a CRUD API which the application will interface with. When an action is performed in the app, a timestamped transaction is created for the blockchain. Once commit, all pending transactions are then added to a block on the chain. Once a block has been added to the blockchain, the hash-based data structure ensures the integrity of the app state.</p> <pre><code>{
 "type": "tasks",
 "action": "create",
 "data": {
   "title": "Task Name",
   "description": "Task Description",
   "completed": false,
   "due_date": "2020-11-02",
   "assigned_to": "a72e75a898db9247be59d1aaf9d4c54459e1d24faa43d9f5da0a5a9611a19eb",
   "column": "2bb6a2b737381377fd962b1bda0771d084abd3cab270648c78b7e06566e6b5",
   "id": "d2e25d4d6c77b34fbe87da5f387cf8c3bec25ffc76673e84bf76dbf2aa15754f",
   "timestamp": 1604144654690
 },
 "user": {
   "firstName": "Sam",
   "lastName": "Ternent",
   "avatarUrl": "https://ternent.dev/concords/avatar.jpeg",
   "organisation": "Team Concords",
   "id": "a72e75a898db9247be59d1aaf9d4c54459e1d24faa43d9f5da0a5a9611a19eb"
 },
 "signature": "NOT RELEASED"
}</code></pre><hr> <h4 id="database">Database</h4> <p>Sitting on the other side of the blockchain is the DB layer. When a transaction it accepted onto the blockchain, we parse the event and perform an operation on an IndexedDB instance in the browser. Transactions are recorded as they go in, so we don’t duplicate transactions and minimise the number of write operations to the database.</p> <p>As long as we have the blockchain data object, we have a full picture of our app and data state. We can drop and recreate a database with complete accuracy, based on secured transactional history. This is a <strong>read only</strong> layer.</p> <p><img alt="" src="https://concords.app/flows/recreate-db.gif?raw=true"></p> <hr> <h4 id="architecture-overview">Architecture Overview</h4> <p><img alt="" src="https://concords.app/images/architecture.svg"></p> <hr> <h2 id="next-steps">Next Steps</h2> <h3 id="desktop-app">Desktop App</h3> <p>A quick leap here is to build this out into a desktop app using electron. Little things like saving the hash to a keychain, directly reading and writing to the filesystem. I'm excited to try running the <a href="https://dat.foundation/" rel="nofollow" target="_blank">DAT</a> project to enable P2P connectivity to give a realtime collaborative experience.</p> <h3 id="intergrations">Intergrations</h3> <p>My primary goal is decentralization. I'm not against storing data on the cloud, I just want to be able to make my own choice as to where. The initial standout integration I want to try is with Dropbox, syncing a folder in your filesystem to dropbox will give us the ability to introduce the "push/pull" aspect found in git.</p> <h3 id="conflict-resolution">Conflict resolution</h3> <p>I need to do further research around conflict resolution. I have the basics for a complete blockchain, which includes proof of work and consensus to ensure the validity of the underlying data structure, but it doesn't secure or handle in-app data conflicts. Visual diffs and conflicts are problems solved in various other applications, with plenty of research available. I'm not sure how it will look yet, but it should be a fun one to solve.</p> <h3 id="user-roles--permissions">User roles &amp; permissions</h3> <p>Using our data structure user roles and permissions are achievable. With the use of application-level permission keys, we can encrypt the access key for a specific user. They will then have access to any data under that permission level.</p> </section></div></div>]]>
            </description>
            <link>https://concords.app/blog/what-is-concords</link>
            <guid isPermaLink="false">hacker-news-small-sites-25100313</guid>
            <pubDate>Sun, 15 Nov 2020 11:26:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ask HN: Do you think we will see another pandemic than COVID19 in your lifetime?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25100233">thread link</a>) | @modinfo
<br/>
November 15, 2020 | https://www.strawpoll.me/23409029 | <a href="https://web.archive.org/web/*/https://www.strawpoll.me/23409029">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
        
    
      
    
<section>
    
        <span>Asked</span>
    
    <span>
        <abbr title="11 15 2020 11:11:45 UTC" data-epoch="1605438705">Nov 15, 2020</abbr>
    </span>
    <p>
        <span>Browser Cookie Duplication Checking</span>
        
    </p>
</section>  
    
   

    


    
   

    
      
    

    </div></div>]]>
            </description>
            <link>https://www.strawpoll.me/23409029</link>
            <guid isPermaLink="false">hacker-news-small-sites-25100233</guid>
            <pubDate>Sun, 15 Nov 2020 11:13:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No Config for Old Men]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25100211">thread link</a>) | @freetonik
<br/>
November 15, 2020 | https://www.datagubbe.se/noconf/ | <a href="https://web.archive.org/web/*/https://www.datagubbe.se/noconf/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<p><b>...or anyone else, for that matter.</b></p>

<p><i>Autumn 2020</i></p>

<p>Ask anyone who's really into cooking and they'll tell you how important it is to have a kitchen that's arranged just right. To someone who rarely cooks, a kitchen is probably just a place to store a few pots and a toaster, and the placement of such stuff doesn't matter much: canned soup and microwave dinners are designed for ease of preparation.</p>


<p>For the enthusiastic home cook, however, a lot of things can go wrong. Often there's only a second's notice to fix something that might ruin a perfect meal or set you back hours of hard toil. Hollandaise starting to split? Better bring out that ice cold water post haste! Garlic burning? Better chop some more right this instant, or the pasta will be overcooked and there goes the Aglio e Oglio.</p>


<p>To achieve speed, you have to know where your knives, pots, pans, spoons, whisks and other utensils are and you want to be able to arrange them so that they're easy to reach. Seasonings, spices, herbs and condiments should be within reach from the stove. Then there's the mise en place before the actual cooking begins: chopping all the vegetables, cubing the meat, slicing the bacon and so on.</p>


<p>All of this is, thankfully, easy to achieve. Even the most cramped kitchen will, after having been battle tested through a few meals, be as optimal as possible according to the cook's personal preference. The same goes for painters, carpenters, car mechanics and even office dwellers. Hammer missing from the hammer hook? For shame! Stapler not to the immediate right of the stack of post-its? Well it should be!</p>


<h3>The regulated kitchen</h3>


<p>Now imagine if you couldn't organize your kitchen to your heart's content. Not because you're lacking the funds or skills, but because some federally appointed clerk is constantly coming to inspect it.</p>


<p>"Nah," he says, adjusting his clip-on tie, "you can't put your spices there. Against regulations. All spices must be kept more than two yards from the stove at all times." He then goes on to explain that you'll have to call him every time you want to use the stove, just to make sure the pots you're using are compliance tested. Plus, they have to be stored in the government approved pot storage cabinet below the sink, otherwise they're not fit for kitchen use.</p>


<p>Want to change the color of the counter top? Sorry, no can do. Want to switch from glass bowls to stainless? Alas, you used to be able a few years ago, but nobody wants stainless anymore anyway, right? The salt <i>can</i> be put next to the stove, but it's not recommended and might change in the near future. Knives are now to be honed every Tuesday afternoon by a designated craftsman. Sure, you can postpone a few times, but eventually, you just have to live with that. Plus, there's going to be some dudes coming to inventory your pantry on a regular basis, most likely when you're in the middle of cooking something really complicated. There's no use in protesting - this is all for your own good.</p>

<p>And yes.


</p><p>Of course this is a metaphor for computers.</p>


<h3>The curious disappearance of configuration</h3>


<p>For the casual user, some of this can <i>maybe</i> be convenient - or at least not annoying. If someone who rarely uses the kitchen has decided to whip up a home cooked feast, it doesn't matter that the spices are kept strangely far from the stove: they're just happy they found them. And <i>maybe</i> there is, for the casual user, some "security" in lock-in efforts such as MacOS calling home<sup><a href="#footnote1">[1]</a></sup> to check if a program is allowed to run and that web browsers automatically block certain URLs.</p>


<p>Likewise, maybe a handful of confused beginners are helped by the fact that certain system settings are extremely hard to find, or that you're supposed to put all your photos in a specific directory, or that you can't decide what partition you want to install a program on, or that some indexing service starts running when you least expect it, or that not a single application gives a crap about the few color settings you're allowed to make.</p>


<p>For the power user, such things range from nuisances to something that seriously hampers productivity and creativity.</p>


<p>It used to be that whenever I got a new computer, I spent a day or two setting it up. I selected the fonts I wanted to use, I picked the colors I liked for window decorations and GUI elements, I installed my preferred tools and utilities and I organized the desktop icons and program launchers to my liking. It took a bit of time, but it was a labor of love. In times of trouble I was, if nothing else, at least the boss of my own desktop environment.</p>


<p>I don't know of any proprietary OS where I can do that anymore. Linux is, considering what's going on with the major distributions, desktop environments and UI toolkits, seemingly heading the same way. Sure, pick your own window manager, see if we care - we've got client side decorations! Want to theme your GUI? Yeah, but not in our Snap packages you won't! Want to turn off cursor blinking? Mmmmyyeeaahhh, not too sure about that. Oh, you started a GUI file manager? Hey, enjoy the ten new folders we've littered your home directory with! They all start with capital letters: designed for typing convenience in a case sensitive file system.</p>


<p>Of course I still spend a fair amount of time setting up a Windows machine, but these days it's not the joyful experience of configuring the best fonts and nicest colors and arranging the icons on the start menu in the correct order for my muscle memory. Instead it's usually a week of swearing over removed settings and working hard to find the ones that actually remain, or trying various registry hacks to circumvent seemingly unchangeable defaults. I'm working against the system instead of with it, and someone else is trying to boss me around.</p>


<h3>A better example</h3>


<p>All of this could be different. It used to be. On my Amiga, I could configure <i>everything</i>. Apart from things like fonts and colors I could draw my own mouse pointer, tiling desktop backgrounds and icons. (Yes, the system really shipped with separate little paint programs just for pointers, desktop tiles and icons.) I could customize double click speed and key repeat rates on millisecond levels. I could even control the exact position of individual icons and the size and position of every individual directory window opened.</p>


<p>Most casual users didn't care about all that, but they didn't have to. The system came with a reasonable set of defaults and when or if they grew more proficient and wanted to change something about their daily working environment, they had the option to do so.</p>


<p>This was a great approach to users. Instead of being treated like an incompetent moron and placed in a walled garden, you were entrusted and empowered. Something as simple as drawing my own mouse pointer on the Amiga was a profound and formative experience for me. As corny as it sounds, it was as if the guys who built this amazing machine put it in my hands and said, "Hey kid, you're in charge. This computer is yours. Learn how to use it and you can make it do anything." It was a call for exploration and creativity.</p>


<p>Today, I can't even change the system font in Windows. I can select an "accent color", but most applications completely ignore it. Every program defaults to downloading into a Downloads folder and I've lost count of how many times I've changed its folder view from grouped to not grouped, only to discover it's been magically changed back the next time I browse it. Lots of settings have been removed completely while others are buried deep in strange places where a user clearly isn't really supposed to venture.</p>


<p>The problem is that there's no toggle for enabling "advanced mode". I'm just supposed to accept that I can no longer change simple things I've been able to configure for the past thirty years. Someone, somewhere just decided that all users have the same basic skill level and that the defaults are always acceptable.</p>


<h3>General purpose Instagram cameras</h3>


<p>I suppose the lack of configurability is a metaphor for personal computing in general: we're not buying our machines, we're renting them by way of bizarrely complex EULA:s for everything from the firmware to the OS and we're not supposed to be curious or creative, we're supposed to sit back and passively consume advertisements. The base level of creative computer use is no longer exploring programming or graphics or music, but photographing a meal someone else has prepared and then applying a predefined sepia filter to said photo. The base level of configuring a system is no longer picking some personal favorites among fonts and colors, but - maybe - selecting between dark and light mode.</p>


<p>
On the flip side, more and more people also need to use computers 
for actually producing stuff - not least programming all those ad 
delivery platforms and the curiously unconfigurable operating systems 
they run on. But there are also armies of innocents; office workers,
administrators, hotel clerks, librarians, teachers - those people now often 
have no choice but to strain their eyes staring at black text on bright 
white backgrounds, unable to select a font they find easier to read.
</p>

<p>Too bad they can no longer store their spices close to the stove, but hey, who cares? Let them take one for the team. We're all swimming in ad revenue and if people learn to configure things, maybe they'll suddenly realize that the presence of those ads should be configurable as well.</p>

<br>

<hr>



<p id="footnote1">
<sup>1</sup> In case my sarcasm isn't coming through here: No, it's not secure. The privacy and security problems this entails are huge.
</p>

</div></div>]]>
            </description>
            <link>https://www.datagubbe.se/noconf/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25100211</guid>
            <pubDate>Sun, 15 Nov 2020 11:11:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Open Source does not mean “Includes Free Support”]]>
            </title>
            <description>
<![CDATA[
Score 295 | Comments 247 (<a href="https://news.ycombinator.com/item?id=25099862">thread link</a>) | @alexellisuk
<br/>
November 15, 2020 | https://raccoon.onyxbits.de/blog/bugreport-free-support/ | <a href="https://web.archive.org/web/*/https://raccoon.onyxbits.de/blog/bugreport-free-support/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
      We need to talk.
    </p><div>

<p>Here’s a paraphrased conversation I’m having way to often, costing me way too much time, keeping me from doing things that are way more important:</p>

<pre>User: Hi, I'd like to report a bug in your application.
Me:   Great! Please open a support ticket, then.
User: But, it looks like I need to pay for that?
Me:   So?
User: I just want to tell you that your app is broken, so you can fix it.
Me:   Yes, that's a support request, please open a ticket.
User: ...
</pre>

<figure>
  <a href="https://raccoon.onyxbits.de/blog/bugreport-free-support/bugreport.png">
    <img src="https://raccoon.onyxbits.de/blog/bugreport-free-support/bugreport.png">
  </a>
  
</figure><p>
                             
                             
From there it typically derails into a whiny tirade about me being a crappy two bit developer who doesn’t give a shit about his code (which is ridiculous, since, professional pride aside, I have every incentive to fix bugs, to prevent my inbox from getting flooded) and just wants to rip off his users.</p>

<p>In the past, I sometimes gave in (when it sounded like something might be wrong). I looked at the issue and almost always found that nothing was broken, just didn’t work as expected (which is actually to be expected for every reasonably complex piece of software). The user just didn’t bother reading the docs and tried to bypass the fee by masquerading the support request as a bug report. So, nowadays my policy simply is: no support ticket, no service. Any such request goes straight to the trash folder without even being looked at.</p>

<h2 id="why-am-i-such-an-asshole">Why am I such an asshole?</h2>

<p>Here’s the thing: I write open source software to solve <strong>my problem</strong>. I let you use my solutions because that comes at zero cost for me (well, almost, I still have to pay for the website, you are downloading from. You are welcome, by the way). I also provide the source code, so you can fix things yourself, should my solution turn out to be unsuitable. However, once you come to me with a “bugreport” that doesn’t also include a patch (or at least very precisely pinpoints the problem), then you are basically asking me to <strong>look at your problem</strong>. At this point, it is no longer zero cost for me and that’s the reason for why I am charging you money: you are asking me to spent time on your behalf. That is commonly called <strong>work</strong>. And surprisingly enough, work is what people expect to be paid for.</p>

<p>Don’t get me wrong. I’m happy to help. Selling support is what keeps the lights on here (did I mention the cost of running a webserver?). But coming to me under false pretense and/or expecting that I <strong>must</strong> provide free service on top of a software I gave away without charge is not going to win you any favours.</p>

<p>It stops being free, when it starts costing me! My time is valuable. If you want a piece of it, I want money in return. Period.</p>

<p><strong>UPDATE:</strong> Seems like this post has struck a nerve and caused a few misunderstandings. <a href="https://raccoon.onyxbits.de/blog/reactions-bugreport-free-support/">Clarification on my position here</a>.</p>
</div></div>]]>
            </description>
            <link>https://raccoon.onyxbits.de/blog/bugreport-free-support/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25099862</guid>
            <pubDate>Sun, 15 Nov 2020 10:12:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lazy Loading Explained]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25099745">thread link</a>) | @DevTalker
<br/>
November 15, 2020 | https://ddimitrov.dev/2020/09/13/what-is-lazy-loading/ | <a href="https://web.archive.org/web/*/https://ddimitrov.dev/2020/09/13/what-is-lazy-loading/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


			
<p>Lazy loading is a very cool design pattern that is not often talked about. Many frameworks implement it without even telling us about it ðŸ˜Š. For example, .NET Entity Framework (all versions) support the pattern.&nbsp;</p>



<p>But what is lazy loading? The idea behind the pattern is simple. By using lazy loading, we defer the initialization of objects (heavy ones) until we need them. Thatâ€™s it.</p>



<p>Letâ€™s provide an example. We have a simple HR application. The application supports the tracking of employee records. Each record has standard fields like name, email, date of birth, and image (like a profile picture), etc.</p>



<p>The application has operations like adding employees, updating employees, searching for an employee, generating reports, etc. Do all functions need the image of the employee? Should we load images in some aggregated reports? Of course not. A picture can take a lot of resources, so it is not reasonable to load it everywhere. And here, lazy loading comes to help us.</p>



<h2>Lazy loading implementation</h2>



<p>There are several ways to implement the lazy loading pattern, but we are going to inspect the most used one (when it comes to manual implementation).</p>



<p>In the source code, the employee domain model is represented like this:</p>



<pre><div><div><p><span>public</span> <span>class</span> Employee<br>
&nbsp; &nbsp; <span>{</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; <span>public</span> <span>string</span> Name <span>{</span> <span>get</span><span>;</span> <span>set</span><span>;</span> <span>}</span></p><p>

&nbsp; &nbsp; &nbsp; &nbsp; <span>public</span> <span>string</span> Email <span>{</span> <span>get</span><span>;</span> <span>set</span><span>;</span> <span>}</span></p><p>

&nbsp; &nbsp; &nbsp; &nbsp; <span>public</span> <span>byte</span><span>[</span><span>]</span> Image <span>{</span> <span>get</span><span>;</span> <span>set</span><span>;</span> <span>}</span></p><p>

&nbsp; &nbsp; &nbsp; &nbsp; <span>public</span> Employee<span>(</span><span>)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; <span>{</span><span>}</span></p><p>

&nbsp; &nbsp; &nbsp; &nbsp; <span>public</span> <span>void</span> Load<span>(</span><span>)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; <span>{</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span>// LOGIC LOADING ALL THE DATA.</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; <span>}</span><br>
&nbsp; &nbsp; <span>}</span></p></div></div>

</pre>



<p>Nothing special. Just a class with three fields and a method which would load all the data. But as we said, most of the time, we do not want the Image data because it could take a lot of resources.</p>



<p>So, how do we <a href="https://ddimitrov.dev/2020/02/15/what-is-code-refactoring/">refactor</a> the class? We do It like this:</p>



<pre><div><div><p><span>public</span> <span>class</span> Employee<br>
&nbsp; &nbsp; <span>{</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; <span>private</span> <span>byte</span><span>[</span><span>]</span> image<span>;</span></p><p>

&nbsp; &nbsp; &nbsp; &nbsp; <span>public</span> <span>string</span> Name <span>{</span> <span>get</span><span>;</span> <span>set</span><span>;</span> <span>}</span></p><p>

&nbsp; &nbsp; &nbsp; &nbsp; <span>public</span> <span>string</span> Email <span>{</span> <span>get</span><span>;</span> <span>set</span><span>;</span> <span>}</span></p><p>

&nbsp; &nbsp; &nbsp; &nbsp; <span>public</span> <span>byte</span><span>[</span><span>]</span> Image <br>
&nbsp; &nbsp; &nbsp; &nbsp; <span>{</span> <br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span>get</span> <span>{</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span>if</span> <span>(</span>image <span>==</span> <span>null</span><span>)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span>{</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; image <span>=</span> LoadImage<span>(</span><span>)</span><span>;</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span>return</span> image<span>;</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span>}</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span>else</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span>{</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span>return</span> image<span>;</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span>}</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span>}</span> <br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span>set</span> <span>{</span> <br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; image <span>=</span> <span>value</span><span>;</span> <br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span>}</span> <br>
&nbsp; &nbsp; &nbsp; &nbsp; <span>}</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; <span>public</span> Employee<span>(</span><span>)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; <span>{</span><span>}</span></p><p>

&nbsp; &nbsp; &nbsp; &nbsp; <span>public</span> <span>void</span> Load<span>(</span><span>)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; <span>{</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span>// LOGIC LOADING ONLY NAME AND EMAIL PROPERTIES.</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; <span>}</span></p><p>

&nbsp; &nbsp; &nbsp; &nbsp; <span>public</span> <span>byte</span><span>[</span><span>]</span> LoadImage<span>(</span><span>)</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; <span>{</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span>// LOGIC LOADING AND RETURNING IMAGE DATA.</span><br>
&nbsp; &nbsp; &nbsp; &nbsp; <span>}</span><br>
&nbsp; &nbsp; <span>}</span></p></div></div>

</pre>



<p>We followed only four steps:</p>



<ol type="1"><li>Extract the logic for image data load from the Load method to a new Method â€“ LoadImage;</li><li>Introduce a new private field for the image data;</li><li>Refactor the Image property to check if image data is null. If it is, the new method loads the image data, assigns it to the image field, and then return it to the consumer.</li></ol>



<p>Next time we load the object (or objects if we load a collection of them), we wonâ€™t have the overhead of loading unnecessary image data. We are going to extract the image data only when we need it (by accessing Image property).</p>



<h2><strong>ORMs</strong></h2>



<p>ORMs like <a href="https://docs.microsoft.com/en-us/ef/core/querying/related-data" target="_blank" rel="noreferrer noopener nofollow">Entity Framework Core</a> support lazy loading. When a query is executed, not all the properties are loaded (unless you have disabled lazy loading). Only by accessing them, another query runs to fetch the data.</p>



<p>For example, imagine we have two entities in relation: a Company entity and an Employee entity. A company has many employees. If we query for a specific company by id and we get a result, the list of its employees wonâ€™t be loaded. Only when we access them a new query will fetch the collection.</p>



<p>In some cases, this is cool in others, not ðŸ˜Š.</p>



<p>Can we implement our own lazy loading if we are using some ORM? Sure. The thing you should do is not to map properties/entities that donâ€™t need to be loaded with every query. Of course, you should provide proper methods to handle the data that is not loaded.</p>



<p>In Entity Framework, you use the [NotMapped] attribute to annotate desired properties.</p>



<p>You can read in many places that lazy loading is used when accessing network resources. That is true but not complete. You can use lazy loading also for any demanding operation, like complex computations, reading big chunks of local data, etc.</p>
				
		</div></div>]]>
            </description>
            <link>https://ddimitrov.dev/2020/09/13/what-is-lazy-loading/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25099745</guid>
            <pubDate>Sun, 15 Nov 2020 09:51:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Ripped Out a £6k Lighting System]]>
            </title>
            <description>
<![CDATA[
Score 218 | Comments 286 (<a href="https://news.ycombinator.com/item?id=25099615">thread link</a>) | @iamflimflam1
<br/>
November 15, 2020 | https://robdobson.com/2020/11/the-10-reasons-i-ripped-out-a-6k-lighting-system/ | <a href="https://web.archive.org/web/*/https://robdobson.com/2020/11/the-10-reasons-i-ripped-out-a-6k-lighting-system/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://robdobson.com/2020/11/the-10-reasons-i-ripped-out-a-6k-lighting-system/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25099615</guid>
            <pubDate>Sun, 15 Nov 2020 09:24:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I don't expect to have an ARM-based PC any time soon]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25099586">thread link</a>) | @pcr910303
<br/>
November 15, 2020 | https://utcc.utoronto.ca/~cks/space/blog/tech/ARMNoPCExpectations | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/tech/ARMNoPCExpectations">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>I don't expect to have an ARM-based PC any time soon</h2>

	<p><small>November 15, 2020</small></p>
</div><div><p>The ARM-related news of the time interval is of course that Apple
has announced several ARM-based Mac laptops and that early (and
preliminary) leaks are that they perform very well and are definitely
competitive. This raises the great hope in many technical people's
minds of ARM based laptops and desktops from more than Apple, ARM
PCs that would run more than Apple's OS X. This is especially a
dream for many Unix people, who already run little or no commercial
binary software and so in theory ARM support is only a recompile
away; moving away from the x86 hegemony would please a lot of people.</p>

<p>(The practice of moving to ARM is somewhat different, especially
for performance sensitive code. Focused use of x86 assembly is
surprisingly common in various places.)</p>

<p>My own view is that while I wouldn't mind using a competitive ARM
based PC (either laptop or desktop), I don't expect to actually
have one any time soon. The rub is that 'competitive'. Right now,
the only ARM chip maker that can compete with the performance of
the x86 hegemony in the desktop/laptop space is Apple, and Apple's
machines only run OS X. While there are promising developments in
the server space, many of them are also bespoke to the large cloud
vendors, and also may not be particularly suitable for scaling down
to desktops and laptops (in all sorts of dimensions, including how
much money can be made on them).</p>

<p>Apple has demonstrated that it's possible to make ARM be competitive
(on laptops, at least, although likely on desktops too), but <a href="https://twitter.com/thatcks/status/1326317293849153540">they
stand alone</a>
and I don't think it's likely for anyone else to join them. Apple has
the benefit of a gigantic market for their own ARM designs that
feeds a firehose of money into their R&amp;D budget and also good
assurance of large production runs even for laptop CPUs (never mind
phone ones). Anyone else would be in the position of trying to take
laptop and desktop CPU market share from Intel and AMD (who are
already fighting each other), without the kind of money firehose
and good market that Apple has.</p>

<p>(Apple also has the benefit of capturing all of the profit from its
laptops. An ARM CPU maker would capture much less of the profit of
machines with its CPUs in them; much of the overall profit would go
to the system vendors or at least to the makers of other parts, like
motherboards.)</p>

<p>The other problem is that merely being competitive isn't good enough,
because there are real costs to switching to ARM (even for Unix
people). It's likely that an ARM PC would need to be clearly better
than the x86 equivalent before very many people became interested,
and might face an extended period of doubt and proving itself. To
be honest, that would be my attitude toward the first generation
of ARM PCs; I would not buy immediately and let other people get
those experiences.</p>

<p>(I think this will be easier on laptops than on desktops, because
on laptops power efficiency can count for a lot. The longer battery
lifetime is already one of Apple's selling points for their new ARM
laptops)</p>

<p>PS: I would love to be wrong on this, as I'm not particularly fond
of the x86 hegemony. But I'm also a pragmatist.</p>
</div></div>]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/tech/ARMNoPCExpectations</link>
            <guid isPermaLink="false">hacker-news-small-sites-25099586</guid>
            <pubDate>Sun, 15 Nov 2020 09:18:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Git blame sucks for understanding WTF code (and what to use instead)]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25098994">thread link</a>) | @stefanjudis
<br/>
November 14, 2020 | https://tekin.co.uk/2020/11/patterns-for-searching-git-revision-histories | <a href="https://web.archive.org/web/*/https://tekin.co.uk/2020/11/patterns-for-searching-git-revision-histories">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <p>You’re happily working your way through a codebase when you happen upon some code that makes you stop and think: What the…!? Maybe it’s a method that’s doing something surprising. Or perhaps it’s doing something completely unsurprising, it’s just doing it in a surprising way.</p>

<p><img src="https://tekin.co.uk/images/20201113/math-lady.jpg" alt=""></p>

<h2 id="git-blame-to-the-rescue">Git blame to the rescue?</h2>

<p>When this happens you might instinctively reach for <code>git blame</code> to help you figure out what’s going on. After all, <code>git blame</code> gives you the commit that most recently touched the line, and often that’s enough to point you in the right direction. But often it isn’t and you’re none the wiser. That’s because:</p>

<ul>
  <li><strong>git blame is too coarse</strong>: it reports against the whole line. If the most recent change isn’t related to the part of the line you’re interested, you’re out of luck.</li>
  <li><strong>git blame is too shallow</strong>: it only reports a single change; the most recent one. The story of the particular piece of code you’re interested in may have evolved over several commits.</li>
  <li><strong>git blame is too narrow</strong>: it only considers the file you are running blame against. The code you are interested in may also appear in other files, but to get the relevant commits on those you’ll need to run blame several times.</li>
</ul>

<p>If you only use <code>git blame</code> you’re limiting yourself to a one-dimensional perspective of the code you’re trying to understand. Wouldn’t it be better to view things in 3D!?</p>

<h2 id="a-more-powerful-way-to-trace-the-history-of-wtf-code">A more powerful way to trace the history of WTF code</h2>

<p>Thankfully Git has some pretty powerful search tools built right in. Let’s take a closer look at some of the tools at our disposal.</p>

<h2 id="find-all-commits-containing-a-particular-piece-code">Find all commits containing a particular piece code</h2>

<p>If <code>git blame</code> is entry-level history search, <code>git log -S</code> (also known as “the pickaxe”) is how you take things to the next level. It lets you search for all commits that contain a given string:</p>

<div><div><pre><code><span>$ </span>git log <span>-S</span> <span>"method_name"</span>
</code></pre></div></div>

<p>This will return all the commits that contain <code>method_name</code> across the entire repository, giving you a bespoke history of a piece of code across both multiple commits and files. You can use the pickaxe to examine the entire history of a particular snippet: all the places it’s been used; how it’s usage has changed; if it’s moved file; when it was first introduced, and more.</p>

<h2 id="see-the-diffs-alongside-the-commit-messages">See the diffs alongside the commit messages</h2>

<p>If you include the <code>-p</code> option (short for <code>--patch</code>) you get the full diff alongside the commit messages, giving you even more context and making it easier to spot the relevant changes:</p>

<div><div><pre><code>$ git log -S "method_name" -p
</code></pre></div></div>

<h2 id="find-the-commit-that-first-added-some-code">Find the commit that first added some code</h2>

<p>Say you want to find the first commit that introduced a particular class, method or snippet of code. You can use the pickaxe combined with the <code>--reverse</code> option to get the commits in reverse-chronological order so the commit where the code first appears is listed at the top:</p>

<div><div><pre><code>$ git log -S "method_name" -p --reverse
</code></pre></div></div>

<h2 id="find-when-a-piece-of-code-was-deleted">Find when a piece of code was deleted</h2>

<p>Because the pickaxe search finds both additions and deletions, you can even use it to find code that has since been deleted:</p>

<div><div><pre><code>$ git log -S "deleted code" -p
</code></pre></div></div>

<p>Assuming the snippet no longer exists in the codebase the first commit returned will be the one where it was removed.</p>

<h2 id="limit-the-scope-of-the-search">Limit the scope of the search</h2>

<p>Because we’re using <code>git log</code> you can also provide a path to focus the search to a given file or folder:</p>

<div><div><pre><code>$ git log -S "some code" -p app/models/user.rb
</code></pre></div></div>

<h2 id="search-deeper-with-a-regular-expression">Search deeper with a regular expression</h2>

<p>I mostly stick to the pickaxe because I find working with regular expressions cumbersome, but if you want to perform a more advanced search using a regular expression you can do so with <code>-G</code> instead:</p>

<div><div><pre><code>$ git log -G "REGEX HERE"
</code></pre></div></div>

<p>It’s also worth noting that searching with <code>-S</code> has a subtle limitation that <code>-G</code> does not: <code>-S</code> only shows commits that either added or removed the search string. If the string you are searching for moved within the same file but was otherwise unchanged, <code>-S</code> won’t include that commit, whereas <code>-G</code> will.</p>

<h2 id="search-the-commit-messages-themselves">Search the commit messages themselves</h2>

<p>Sometimes searching for literal code is too narrow, or the information you’re after isn’t actually in the code but in the commit messages themselves. In which case you can use <code>--grep</code> to search commit messages instead:</p>

<div><div><pre><code>$ git log --grep "commit message search"
</code></pre></div></div>

<h2 id="in-summary">In summary</h2>

<p>Next time some code has you puzzled and you want to understand more about it, look beyond <code>git blame</code> and dig deeper into the history using the pickaxe and friends:</p>

<ul>
  <li>Find the entire history of a snippet of code with <code>git log -S</code></li>
  <li>Include <code>-p</code> to see the diff as well as the commit messages</li>
  <li>Include <code>--reverse</code> to see the commit that introduced the code listed first</li>
  <li>Scope search to specific folders or files by including a path</li>
  <li>Search with a regular expression using <code>git log -G</code></li>
  <li>Search commit messages using <code>git log --grep</code></li>
</ul>

<h2 id="epilogue">Epilogue</h2>

<p>Of course searching a codebase’s history will only be fruitful if the history itself is helpful. If the history hasn’t been constructed with atomic commits that have useful commit messages, searching it will likely be a frustrating and unhelpful experience.</p>

<p>To learn more about the how and why of putting together more useful histories, check out <a href="https://tekin.co.uk/2019/02/a-talk-about-revision-histories">A Branch in Time (a talk about revision histories)</a>.</p>


  </section></div>]]>
            </description>
            <link>https://tekin.co.uk/2020/11/patterns-for-searching-git-revision-histories</link>
            <guid isPermaLink="false">hacker-news-small-sites-25098994</guid>
            <pubDate>Sun, 15 Nov 2020 07:08:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Exercise Reduces Tumour Growth – and Now We Know the Cellular Basis for It]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25098779">thread link</a>) | @pvsukale3
<br/>
November 14, 2020 | https://science.thewire.in/the-sciences/cancer-recovery-exercise-cellular-basis-lactates-cd8-t-cells/ | <a href="https://web.archive.org/web/*/https://science.thewire.in/the-sciences/cancer-recovery-exercise-cellular-basis-lactates-cd8-t-cells/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
										                <p><em>A superresolution image of a group of killer T-cells (green and red) surrounding a cancer cell (blue, centre). Image: US NIH.</em></p>
<p>On World Cancer Day this year, Tata Memorial Hospital in Mumbai, known in India for its cancer care facilities, <a href="https://www.thehindu.com/news/cities/mumbai/exploring-new-options-in-cancer-care/article30729911.ece">announced</a> that it would study the <a href="https://clinicaltrials.gov/ct2/show/NCT02161900">effects of yoga</a> on breast cancer patients. While the association between <a href="https://www.the-scientist.com/features/regular-exercise-helps-patients-combat-cancer-67317">exercise and recovery</a> in cancer patients has been known since the 1990s, we know little about how this works on a molecular level.</p>
<p>A <a href="https://elifesciences.org/articles/59996">new study</a> shows that the key might lie in activating certain immune cells. The study, conducted by Randall Johnson and his team from the Karolinska Institute in Stockholm, Sweden, and the University of Cambridge, was the culmination of three years of research on what makes exercise good for cancer patients.</p>


<p>They first established that exercise could indeed decrease the growth of tumours. They induced tumours in mice, mimicking breast cancer in humans, and separated them into two groups: one exercised on running wheels and one did not. After a few days, the tumours had shrunk in the group that exercised but not in the sedentary group.</p>
<p>When the researchers examined blood samples from the mice, two things had dramatically increased after exercise: immune cells known as CD8+ T-cells and a compound called lactic acid.</p>
<p>The team first looked into CD8+ T-cells, which <a href="https://www.the-scientist.com/news-analysis/the-ever-expanding-t-cell-world-a-primer-31123">defend against</a> tumours and infections. Did increased levels after exercise mean that the cells were involved in reducing tumour growth? To test this, the team removed CD8+ T-cells from tumour-bearing mice and then made them exercise. This time, exercising could not shrink the tumours: removing the T-cells also removed the positive effects of exercise.</p>
<p>“Then we did what, to my mind, is the coolest experiment in the paper,” said Johnson. They made mice exercise, carefully took CD8+ T-cells from them, and transplanted the cells into another set of mice that had tumours but didn’t exercise. To the scientists’ delight, simply transplanting CD8+ T-cells from mice that had exercised could shrink tumours in sedentary mice.</p>
<p>“The T-cells themselves are coming in ‘trained,’ making them better anti-tumour T-cells,” Johnson said.</p>
<p>What was ‘training’ the T-cells, though? That’s when the team turned their attention to lactic acid. After an intense bout of exercise, lactic acid is what makes your muscles feel like they’re burning. In the bloodstream, it circulates as lactate, its ionic form.</p>
<p>To mimic this form and the levels attained after exercise, the researchers injected sodium lactate into sedentary mice that had tumours. As with the T-cells, they found that daily injections of sodium lactate could shrink tumours and improve survival in these mice.</p>
<p>The team now knew that, through exercise, both lactate and CD8+ T-cells could reduce tumour growth. But this still didn’t explain how the two effects were linked.</p>
<p>To answer this, the scientists first checked whether lactate could independently activate CD8+ T-cells – and found that it could. Next, they again injected mice with lactate, only this time they removed the CD8+ T-cells from the mice. Without the T-cells, lactate injections could no longer lessen tumour growth.</p>
<p>“This shows that it’s really the lactate affecting the T-cells and helping them achieve a better anti-tumour effect,” Johnson said.</p>
<p><ins>Also read: <a href="https://science.thewire.in/health/why-everyone-around-you-seems-to-be-getting-cancer/">Why Everyone Around You Seems to Be Getting Cancer</a></ins></p>
<p>The study fills an important gap in our understanding of how exercise and the related metabolite changes boost anti-tumour the activities of our immune cells.</p>
<p>This said, “My main concern is that people should not think that only exercise can cure cancer,” S.V. Chiplunkar, a former director of the Advanced Centre for Treatment, Research and Education in Cancer, Mumbai, and current head of its Cancer Immunology and Immunotherapy division, cautioned.</p>
<p>“A combination of immunotherapy with supervised exercise or yoga regimens may yield significant benefits, but this needs to be tested in a randomised clinical trial.” Chiplunkar wasn’t involved in the study.</p>
<p>And as with any good study, this one spawned more questions than it answered. “Future studies should address how lactate levels are modulated in cancer patients/mice models in response [to] exercise,” Rajender Motiani, an assistant professor and DBT/Wellcome Trust India fellow at the Regional Centre for Biotechnology, Faridabad, said.</p>
<p>“A <a href="https://www.nature.com/articles/s41591-019-0485-4">recent study</a> in elite athletes showed that lactate is utilised by a unique class of gut microbiome, enhancing endurance and performance. It would be worth examining gut microbiota changes in cancer patients in response to exercise.”</p>
<p>Johnson’s team is now working out how much exercise is needed to boost T-cell activity. For example, one question they’re asking is if one hour of intense exercise could be better than two hours of light exercise.</p>
<p>Meanwhile, Helene Rundqvist, the study’s lead author, has been involved in a <a href="https://clinicaltrials.gov/ct2/show/NCT02522260?term=exercise&amp;cond=Breast+Cancer&amp;cntry=SE&amp;city=Stockholm&amp;draw=2&amp;rank=1">clinical trial</a> assessing the effects of exercise on breast cancer patients undergoing chemotherapy. The trial is still active and expected to be completed in 2022.</p>
<p><em>Sruthi Balakrishnan is a Bangalore-based science writer who is intrigued by all things biological.</em></p>
<!-- AI CONTENT END 1 -->
																												              </div></div>]]>
            </description>
            <link>https://science.thewire.in/the-sciences/cancer-recovery-exercise-cellular-basis-lactates-cd8-t-cells/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25098779</guid>
            <pubDate>Sun, 15 Nov 2020 06:23:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a Django CRUD application in 5 minutes]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25098738">thread link</a>) | @root993
<br/>
November 14, 2020 | https://www.sankalpjonna.com/posts/building-a-django-crud-application-in-minutes | <a href="https://web.archive.org/web/*/https://www.sankalpjonna.com/posts/building-a-django-crud-application-in-minutes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The Django framework for building python server applications has been around since forever and I believe that the reason for this is the speed at which you can develop apps without compromising on robustness.<br></p><p>To gauge the usefulness of any backend framework, a great litmus test is to see how easy it is to plug in a database to your application and expose the database models to the client via 4 operations - Create, Read, Update and Delete.<br></p><p>This functionality solves a big chunk of your problems, especially if you are building a product that is more front-end heavy and you want to spend as little bandwidth as possible on building your APIs.<br></p><h3><strong>What is CRUD?</strong><br></h3><p>An application server is nothing but a layer on top of a database which provides the ability for a client application to perform the following underlying operations.<br></p><ol role="list"><li>Create a new entry into a table in the database.</li><li>Read the database table entries either by fetching a list of all entries or retrieving the details of a single entry.</li><li>Update an existing entry in the database either by changing certain details or by replacing it entirely with a new one.</li><li>Delete a database table entry either by removing it from the database or by simply marking it as deleted and deactivating it.<br></li></ol><p>Django has ways of doing all of this right out of the box, but I prefer to use a framework written on top of Django called the <a href="https://www.django-rest-framework.org/" target="_blank">Django Rest Framework</a> which makes things even simpler by providing an intuitive interface to the developers. <br></p><h3><strong>A sample CRUD application</strong><br></h3><div><p>I write all my blog posts on the apple notes app before I edit and publish them and it occurred to me that a note taking app is a great way to <a href="https://github.com/sankalpjonn/django-crud-example" target="_blank">demonstrate a CRUD application</a>. </p></div><figure id="w-node-bc04fc2d279c-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5faf5796ca5e3a5dd77c5b41_XEHsDH39C2XuP7jH2D_R7hv6wYs8ZGIBkCij0NWiAXStAOuzeIqG61JLp52DNELlsmxqfuMj33tIE-0YsgTIIIDeskVcpRMarPKJKsNA4O2rBoMIFmgahW8Vo2J0YCLZqBsym1Mb.png" alt=""></p><figcaption>A note taking app that we will build using Django and Django Rest Framework</figcaption></figure><p>To build an application like this, we need a database table that stores a list of notes consisting of a Title, Content and the last updated timestamp. The notes are sorted according to the last updated timestamp.</p><p>To build this application we need the following functions:&nbsp;</p><ol start="1" role="list"><li>Creating a new note with an empty title and content.</li><li>Updating the newly created note with a title and content.</li><li>Reading the fields of a note.</li><li>Partially updating the note by modifying either tile or content.</li><li>Listing all the notes in the database sorted by last updated timestamp.</li><li>Deleting a note by marking it as deactivated.</li></ol><p>I&nbsp;will be going through all the steps involved in creating this application, but first let's start with the basics.</p><h3>Setting up a Django project</h3><p>There is some basic boilerplate code involved in building any Django application. Here is a summary of all the steps needed to set up the boilerplate<br>‍</p><p><em>&lt;p&gt; CODE:&nbsp;https://gist.github.com/sankalpjonn/07b99adf85538b5a90a0dcaa34de328c.js&lt;/p&gt;</em></p><h5><strong>Need for a virtual environment</strong></h5><p>While building any python applications, it is recommended to create a virtual environment and install all the packages you need within this environment to keep them isolated from the rest of your machine. This not only ensures prevention of conflicts but also makes it easy to deploy this application anywhere you want.</p><p>Once this virtual environment is activated, your development environment is setup.</p><h5><strong>Creating a Django project</strong></h5><p>Once the virtual environment is created and the necessary python packages are installed, the boilerplate code you need can be created by using a nifty tool called django-admin. We will use this to create a project called <em>notesapp</em>. This not only creates the project structure but also configures a default SQLite database that you can use for the application. </p><p>This database is nothing but a single file created locally with the name <em>db.sqlite3</em> and is very handy to quickly prototype your application. You can change the database settings inside <em>settings.py</em> to point it to any database. This can be done later too once the basic functionality of your application is ready and works with SQLIte.</p><p>After your Django project is created, you also have to create a new Django app which we will use to define our models and APIs. Let's call this <em>notes. </em>Make sure to add this to the INSTALLED_APPS section of your settings.py</p><h3>Creating database models</h3><p>Before writing the CRUD&nbsp;APIs, we must first create a database model on which we wish to perform the CRUD&nbsp;operations. Let us create a model called <em>Note </em>in notes/models.py.</p><p>‍</p><p>&lt;p&gt; CODE:&nbsp;https://gist.github.com/sankalpjonn/d5e29080d973326be371f0d03a5d23ef.js&lt;/p&gt;</p><p>‍</p><p>Before we proceed we must update the schema because a new database table needs to be created in the underlying database. This can be done by creating and running migrations</p><p>‍</p><p>&lt;p&gt; CODE: https://gist.github.com/sankalpjonn/8234bd9ad41637718be8dca4dba04235.js&lt;/p&gt;<br>‍</p><h3>Creating the CRUD&nbsp;APIs</h3><p>Now that the model has been created, we need a way to perform CRUD operations on this model by writing as little code as possible. This is where Django Rest Framework comes in. Not only can you expose CRUD&nbsp;APIs on this model within minutes, but you also get a pretty nifty user interface to view those APIs in action. </p><p>To do this, you must first define a serializer for the database model you created in the above step. <strong>‍</strong></p><h5><strong>Defining a serializer</strong></h5><p>A serializer is responsible for two things<br></p><ol start="1" role="list"><li>To validate an incoming create/update request and reject it if the fields are not in the format that is required to create/update an entry in the database table.</li><li>To convert a database table entry into a format like JSON&nbsp;that can be transferred over the internet to the client.</li></ol><p>Let us create a serializer in notes/serializers.py as follows.</p><p>‍</p><p>&lt;p&gt; CODE:&nbsp;https://gist.github.com/sankalpjonn/4d69bb0c0de94789842fe9eb23e8e882.js&lt;/p&gt;</p><p>‍</p><p>Inside the Meta class, we define which database model is being serialized and what all fields within that model should be serialized. We could choose to include only certain fields from the model that we would like to expose over the API.</p><p>We can also define certain fields as <em>read_only</em> which indicates that these fields will be ignored if present in a create/update request but they will be present in the response a read request. </p><p>In this above case, is_active is responsible for indicating if a note has been deleted or not. Therefore we must not allow it to be modified via a create/update request and it should be set to false only when a delete operation is performed. This will become more clear in the upcoming steps. </p><p>We can also define fields as <em>write_only </em>which will indicate that these fields will not be present in a read response but we will allow the field to be modified in a create/update request. We can now proceed to writing the CRUD&nbsp;APIs</p><h5><strong>Defining an API&nbsp;View set</strong></h5><p>In Django, the APIs are written in views.py and each API&nbsp;that does some operation on a certain database resource is a view. In our case we will be performing multiple operations on the database model and hence what we need is a viewset. Here is how you define one in notes/views.py</p><p>‍</p><p>&lt;p&gt; CODE:&nbsp;https://gist.github.com/sankalpjonn/b313384c0774ec4f1dee342ced8ccc20.js&lt;/p&gt;</p><p>‍<br>‍<br>This viewset is now capable of performing all the CRUD&nbsp;operations and it will use the NoteSerializer to determine how the data will be received and how it will be sent back to the requesting client. <br></p><p>Since a read operation could be retrieving a single note or listing all the existing notes, we need a way to handle both cases. </p><p>The <em>get_object </em>is responsible to determine how an object is retrieved. In this case we look for an <em>id </em>field in the query parameters of a a request and use that to retrieve a note. </p><p>This method is also used while making an update operation because to update a particular note we would have to first retrieve that note.</p><p>The <em>get_queryset</em> method is responsible for determining how a list operation will work. In this case we will be listing all the notes which are still active and sort them in the decreasing order of the <em>last_udpated_on</em> timestamp.</p><p>The <em>perform_delete</em> method will determine what to do when a delete operation is requested. In this case we do not want to delete the row from the database and we simply want to deactivate it. Therefore we will be setting the <em>is_active</em> field to False and saving the note.</p><h5>‍<strong>Defining the URL&nbsp;path</strong>‍</h5><p>We just have one more step to complete before we can see our APIs in action and that is to determine what URL&nbsp;path will invoke the above viewset. This can be done in notesapp/urls.py as follows.<br>‍</p><p>‍<br>&lt;p&gt; CODE:&nbsp;https://gist.github.com/sankalpjonn/902b7c23e95e3cb4ddf99f1b52bbbe52.js&lt;/p&gt;</p><div><p>‍</p><p>To explain what is going on here, we are basically saying that if the url <em>/note</em> is called, no matter what the HTTP&nbsp;method is, we will be invoking the NoteViewSet and based on what the HTTP method is we will call a particular method within this viewset.<strong>‍</strong></p></div><ol start="1" role="list"><li>A POST&nbsp;call will result in a create operation of the Note model.</li><li>A GET&nbsp;call will result in retrieving a single Note model object using the <em>id</em> query parameter.</li><li>A&nbsp;PUT&nbsp;call will result in replacing an existing Note model with a new Note and the existing Note model will be fetched using the <em>id</em> query parameter.</li><li>A PATCH&nbsp;call will result in modifying only a certain field inside an existing Note model instead of entirely replacing it and the existing Note model will be fetched using the <em>id</em> query parameter.</li><li>A DELETE&nbsp;call will result in calling a destroy function which internally calls the <em>perform_destroy</em> method defined above in views.py.</li></ol><p>In case you haven't noticed, there is one thing missing in this url PATH and that is the ability to list all the existing Note model objects. </p><p>To solve this I&nbsp;created another URL&nbsp;path <em>/note/all </em>where I am invoking the same viewset as the above one with the difference being the GET&nbsp;call will now invoke a list method on the viewset instead of a retrieve method which means that the <em>get_queryset </em>method defined earlier will be invoked.<br></p><h3>See your APIs in action<br></h3><p>Okay enough talk, let us now run the server and view the APIs in action. You can run the Django development server using the below command and it will expose your server on the 8000 port on localhost.</p><div><p>‍</p><p>&lt;p&gt; CODE:&nbsp;https://gist.github.com/sankalpjonn/473d335affb3426f7d5cbc1a747e4fe4.js&lt;/p&gt;</p></div><blockquote>Please do not forget to include <em>r…</em></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.sankalpjonna.com/posts/building-a-django-crud-application-in-minutes">https://www.sankalpjonna.com/posts/building-a-django-crud-application-in-minutes</a></em></p>]]>
            </description>
            <link>https://www.sankalpjonna.com/posts/building-a-django-crud-application-in-minutes</link>
            <guid isPermaLink="false">hacker-news-small-sites-25098738</guid>
            <pubDate>Sun, 15 Nov 2020 06:12:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Taking Criticism]]>
            </title>
            <description>
<![CDATA[
Score 63 | Comments 21 (<a href="https://news.ycombinator.com/item?id=25098585">thread link</a>) | @WoodenChair
<br/>
November 14, 2020 | https://www.observationalhazard.com/2020/11/on-taking-criticism_15.html | <a href="https://web.archive.org/web/*/https://www.observationalhazard.com/2020/11/on-taking-criticism_15.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-4608430843265935994">
<p>I am what I would call a non-famous public person. What do I mean by that? I mean that I have jobs where people publicly review my work. As a college instructor, I receive student reviews. Some of them get read internally at our school, and some of them get posted publicy. And they’re attached to my name. They’re not some product where people might just know my company or my brand. They know <em>me</em>, and they’re reviewing <em>me</em>. As an author, my books get reviewed. Some of those reviews are by editors and official reviewers internal to the publisher. Some of those reviews are by email. But most of those reviews are posted online. As a software developer and hobbyist podcaster I also get public reviews.</p>

<p>To anyone in a personalized creative field who cares deeply about their work, bad reviews hurt. It’s not just about being sensitive (although I am sensitive and that doesn’t help). It’s that when you really pour your heart into something, as I do my teaching for example, then the product is an extension of you. Nobody would deny that the way a class or a book turns out is an extension of the personality, knowledge, and ability of the teacher/author. And when the product is criticized, it’s like you are being criticized. </p>

<p>My dad, who was also a college instructor, and the producer of nine books and nine instructional videos among many other public creative ventures, had a very thin skin. He couldn’t stand me reading him a bad review. That stuck with me. This very accomplished man, couldn’t stand even a little criticism. When I get too sensitive, I try to remember how his inability to accept criticism hurt some of his products. He was much more about getting things done than doing them perfectly. If he had a little bit more of a perfectionist streak in him, he would have done even better. But maybe he would have done less…</p>

<p>It doesn’t matter if I receive eighteen great reviews for a class. It’s the words of the two bad reviews that stick with me. And do you know why? <em>Because almost always there’s a kernel of truth to those reviews.</em> Does that mean we should listen to them? Well if I only listened to the bad reviews, I would never produce anything. I would just stay in bed. The fact is the people who are getting no bad reviews, are the people who are not taking the risk of putting themselves out there. So, we have to not let ourselves get so discouraged that we stop producing. And we have to remember that while we may not have served those two students well, we may have served those other eighteen students better than they would have been served in a world without us teaching them. </p>

<p>We can’t please every student or every customer. Nothing that gets watched/read by more than a few people is going to be liked by all of them. Even Mother Theresa would get a downvote on YouTube. So, if we’re serving the majority, we don’t want to let the critiques of a few steer us in the wrong direction.</p>

<p>On the other hand, being like my dad is dangerous too. <strong>No, the customer is not always right. But usually the customer has a point. We have to always be working to get better.</strong> Because we’re not perfect, and there’s always room for improvement. <strong>And we need to read those bad reviews to find those spaces for improvement.</strong> It doesn’t mean they’re right, but it does mean we need to think about them.</p>

<p>My dad accomplished an amazing amount. If he let those bad reviews slow him down too much, it’s very possible he would have not accomplished as much. But if he could have found a few tweaks, a few changes, to serve a few customers better, well then he could have grown through them. I want to grow, but I also don’t want to stop. So, I can’t let the reviews get me too down, but I have to read them.</p>


</div></div>]]>
            </description>
            <link>https://www.observationalhazard.com/2020/11/on-taking-criticism_15.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25098585</guid>
            <pubDate>Sun, 15 Nov 2020 05:39:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[VMAF, PSNR, SSIM calculation using FFmpeg]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25098434">thread link</a>) | @ponderingfish
<br/>
November 14, 2020 | https://ottverse.com/calculate-psnr-vmaf-ssim-using-ffmpeg/ | <a href="https://web.archive.org/web/*/https://ottverse.com/calculate-psnr-vmaf-ssim-using-ffmpeg/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><strong>In this article, let’s learn to compute VMAF, PSNR, and SSIM using FFmpeg. While working on videos (compression or post-processing), it is common to compute objective metrics in addition to doing subjective Visual Quality testing. If you are using FFmpeg in your workflow, it is very easy to compute these metrics instead of purchasing expensive tools. </strong></p>



<p>Let’s go ahead and take a look at these metrics and how they are computed, shall we?</p>



<hr>



<h2>What is VMAF?</h2>



<p><strong><a href="https://github.com/Netflix/vmaf" target="_blank" rel="noopener">VMAF from Netflix</a></strong>&nbsp;stands for Video Multi-method Assessment Fusion, and it is a video quality metric that combines human vision modeling with machine learning. It’s become very popular as it succeeds (not fully) at automating subjective quality testing that usually requires humans to watch and score videos.</p>



<p>FFmpeg and Netflix’s VMAF are now part of every video processing and compression engineer’s toolbox. To understand how to install VMAF, please read our “<a href="https://ottverse.com/vmaf-ffmpeg-ubuntu-compilation-installation-usage-guide/">VMAF Installation</a>” article.</p>



<hr>



<h2>How to Compute VMAF using FFmpeg</h2>



<p>Let’s look at a couple of ways of computing VMAF. </p>



<p><strong>If your source and destination videos are of the same dimensions (height and width)</strong>, then you can directly compute the VMAF value using the command line below. </p>



<p>All you need to do is point FFmpeg to the location of the VMAF model file and it will do the rest. </p>



<pre><code>ffmpeg.exe -i videoToCompare.mp4 -i originalVideo.mp4 -lavfi libvmaf="model_path=vmaf_v0.6.1.pkl":log_path=vmaf_logfile.txt -f null -</code></pre>



<p><strong>However, in case the source and destination videos are not of the same resolution, then you have to ensure that the destination is brought to the same resolution as the source video before computing VMAF</strong>.</p>



<p>Here is a simple one-liner that uses the <code>filter_complex</code> to do the resolution change and then computes the VMAF value. I have used the <code>bicubic</code> filter to do the up/down scaling. </p>



<pre><code><code>bin/ffmpeg -i test_720p30.mp4 -i test_1080p30.mp4 -filter_complex "[0:v]scale=1920x1080:flags=bicubic[main]; [1:v]scale=1920x1080:flags=bicubic,format=pix_fmts=yuv420p,fps=fps=30/1[ref]; \</code>
<code>[main][ref]libvmaf=psnr=true:log_path=vmaflog.json:log_fmt=json" \</code>
<code>-f null -</code></code></pre>



<p>The log file that is produced by the VMAF computation is very comprehensive. It provides a frame-wise score of VMAF and its constituent metrics, along with the aggregate score (if that’s all you are looking for). </p>



<p>Here is an example of the VMAF file. </p>



<figure><img loading="lazy" width="1024" height="205" src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/11/vmaf-1.png?resize=1024%2C205&amp;is-pending-load=1#038;ssl=1" alt="VMAF using FFMpeg" data-recalc-dims="1" data-lazy-srcset="https://889329.smushcdn.com/2063466/wp-content/uploads/2020/11/vmaf-1.png?size=240x48&amp;lossy=1&amp;strip=1&amp;webp=1 240w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/11/vmaf-1.png?resize=300%2C60&amp;ssl=1 300w, https://889329.smushcdn.com/2063466/wp-content/uploads/2020/11/vmaf-1.png?size=480x96&amp;lossy=1&amp;strip=1&amp;webp=1 480w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/11/vmaf-1.png?resize=768%2C154&amp;ssl=1 768w, https://889329.smushcdn.com/2063466/wp-content/uploads/2020/11/vmaf-1.png?size=960x192&amp;lossy=1&amp;strip=1&amp;webp=1 960w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/11/vmaf-1.png?resize=1024%2C205&amp;ssl=1 1024w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/11/vmaf-1.png?resize=1200%2C240&amp;ssl=1 1200w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/11/vmaf-1.png?resize=1536%2C307&amp;ssl=1 1536w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/11/vmaf-1.png?w=1771&amp;ssl=1 1771w" data-lazy-sizes="(max-width: 1024px) 100vw, 1024px" data-lazy-src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/11/vmaf-1.png?resize=1024%2C205&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<hr>



<h2>What is PSNR and How Is It Calculated?</h2>



<p>From Wikipedia, </p>



<p><em><strong>Peak signal-to-noise ratio, often abbreviated&nbsp;PSNR, is an engineering term for the ratio between the maximum possible power of a&nbsp;<a href="https://en.wikipedia.org/wiki/Signal_(information_theory)" target="_blank" rel="noopener">signal</a>&nbsp;and the power of corrupting&nbsp;<a href="https://en.wikipedia.org/wiki/Noise" target="_blank" rel="noopener">noise</a>&nbsp;that affects the fidelity of its representation.&nbsp;</strong></em></p>



<p>So, for a video, you are essentially trying to compute how much noise or pixel corruption has been introduced due to the video compression process which is essentially lossy (mainly due to Quantization). </p>



<p>The first step is to compute the Mean Squared Error or MSE. The formula is shown below where I and K represent the original and destination images respectively and <code>m</code> and <code>n</code> are the height and width of the images respectively. </p>



<p><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/3a34719b4f391dba26b3e8e4460b7595d62eece4" alt="{\mathit  {MSE}}={\frac  {1}{m\,n}}\sum _{{i=0}}^{{m-1}}\sum _{{j=0}}^{{n-1}}[I(i,j)-K(i,j)]^{2}" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>



<p>Once you have the MSE, you can compute the PSNR using the formula shown below. </p>



<p><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/fc22801ed1232ff1231c4156b589de5c32063a8a" alt="{\begin{aligned}{\mathit  {PSNR}}&amp;=10\cdot \log _{{10}}\left({\frac  {{\mathit  {MAX}}_{I}^{2}}{{\mathit  {MSE}}}}\right)\\&amp;=20\cdot \log _{{10}}\left({\frac  {{\mathit  {MAX}}_{I}}{{\sqrt  {{\mathit  {MSE}}}}}}\right)\\&amp;=20\cdot \log _{{10}}\left({{\mathit  {MAX}}_{I}}\right)-10\cdot \log _{{10}}\left({{{\mathit  {MSE}}}}\right)\end{aligned}}" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>



<p>Here,&nbsp;<em>MAX<sub>I</sub></em>&nbsp;is the maximum possible pixel value of the image. When the pixels are represented using 8 bits per sample, this is 255. </p>



<h2>How to Calculate PSNR using FFmpeg?</h2>



<p>You don’t have to go through all those calculations while using FFmpeg. All you need to do use the filter module <code>lavfi</code> and tell it to compute the PSNR. That’s it. </p>



<pre><code>ffmpeg.exe -i videoToCompare.mp4 -i originalVideo.mp4 -lavfi psnr=stats_file=psnr_logfile.txt -f null -</code></pre>



<p>FFmpeg will print the average PSNR on the console while the log file will contain a frame-wise list of the MSE and the PSNR for the Luma and Chroma planes (y, u, and v). An example is shown below – </p>



<pre><code>n:1 mse_avg:54.96 mse_y:72.51 mse_u:27.98 mse_v:11.74 psnr_avg:30.73 psnr_y:29.53 psnr_u:33.66 psnr_v:37.43 
 n:2 mse_avg:69.70 mse_y:93.80 mse_u:31.01 mse_v:12.02 psnr_avg:29.70 psnr_y:28.41 psnr_u:33.22 psnr_v:37.33 
 n:3 mse_avg:72.74 mse_y:98.37 mse_u:31.02 mse_v:11.96 psnr_avg:29.51 psnr_y:28.20 psnr_u:33.21 psnr_v:37.35 
 n:4 mse_avg:73.11 mse_y:98.94 mse_u:31.14 mse_v:11.76 psnr_avg:29.49 psnr_y:28.18 psnr_u:33.20 psnr_v:37.43 </code></pre>



<hr>



<h2>How to Calculate SSIM using FFmpeg?</h2>



<p>Finally, let’s take a look at computing SSIM using FFmpeg. Again looking at the <a href="https://en.wikipedia.org/wiki/Structural_similarity" target="_blank" rel="noopener">definition of SSIM</a>, </p>



<p><em><strong>The&nbsp;structural similarity&nbsp;index measure&nbsp;(SSIM) is a method for predicting the perceived quality of digital television and cinematic pictures, as well as other kinds of digital images and videos. SSIM is used for measuring the similarity between two images. The SSIM index is a&nbsp;<a href="https://en.wikipedia.org/wiki/Video_quality#Classification_of_objective_video_quality_metrics" target="_blank" rel="noopener">full reference metric</a>; in other words, the measurement or prediction of&nbsp;<a href="https://en.wikipedia.org/wiki/Image_quality" target="_blank" rel="noopener">image quality</a>&nbsp;is based on an initial uncompressed or distortion-free image as reference.</strong></em></p>



<p>Calculating SSIM using FFmpeg is very similar to calcuating PSNR. </p>



<pre><code>ffmpeg.exe -i videoToCompare.mp4 -i originalVideo.mp4 -lavfi ssim=stats_file=ssim_logfile.txt -f null -</code></pre>



<p>The output of this command is going to look like this – </p>



<pre><code>[Parsed_ssim_0 @ 0000029c82894300] SSIM Y:0.926845 (11.357537) U:0.876798 (9.093807) V:0.860658 (8.559193) All:0.907472 (10.337287)</code></pre>



<p>And the log file will give you information on the SSIM values for each of the planes (Y, U, and V) along with the aggregate for each of the frames of the video. </p>



<pre><code> n:1 Y:0.930033 U:0.926453 V:0.913508 All:0.926682 (11.347897)
 n:2 Y:0.919140 U:0.915343 V:0.910900 All:0.917134 (10.816226)
 n:3 Y:0.922417 U:0.915795 V:0.910959 All:0.919404 (10.936853)
 n:4 Y:0.920077 U:0.916443 V:0.912994 All:0.918291 (10.877300)
 n:5 Y:0.926438 U:0.927597 V:0.917905 All:0.925209 (11.261518)
 n:6 Y:0.920619 U:0.919988 V:0.918780 All:0.920207 (10.980375)</code></pre>



<hr>



<h2>Conclusion</h2>



<p>That’s it folks – now you know how to calculate three very important objective metrics for video quality evaluation — PSNR, VMAF, and SSIM. By computing all three and using them for analysis, it’s hard to be thrown off by artifacts that one metric can catch and the other can’t. </p>



<p>And like always, do spend a few minutes doing some visual testing (subjective) after you’re done with the objective scores! </p>



<p>If you enjoyed this post, do check out the rest of<a href="https://ottverse.com/category/ffmpeg/"> <strong>OTTVerse’s FFmpeg tutorials</strong></a> to learn more about how to use FFmpeg to improve your video editing, compression, and processing skills!</p>

</div></div>]]>
            </description>
            <link>https://ottverse.com/calculate-psnr-vmaf-ssim-using-ffmpeg/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25098434</guid>
            <pubDate>Sun, 15 Nov 2020 05:11:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Everyone Should Learn to Write]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25097929">thread link</a>) | @NerdyAditya
<br/>
November 14, 2020 | https://adityarohilla.com/2020/11/15/why-everyone-should-learn-to-write/ | <a href="https://web.archive.org/web/*/https://adityarohilla.com/2020/11/15/why-everyone-should-learn-to-write/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-951">

	

	
	<div>
		




<p>Do you hate writing? Me too.</p>



<div><p>I am not talking about tweets or IG posts. I’m talking about 500 word long articles and essays. Most of us don’t like writing them. They take too much time and effort. </p><p>But is time really the problem? I don’t think so. We spend a <a rel="noreferrer noopener" href="https://www.broadbandsearch.net/blog/average-daily-time-on-social-media" target="_blank">lot of time</a> on social media everyday right? Yeah time is not the problem.</p></div>



<p>So is effort the problem? Hmm let’s see. What happens when you open a blank page to write? Does anxiety kicks in? For me it does. </p>







<p>See, when I plan to write an article, usually I have a general idea about the topic I plan to write about. Though as soon as I open a blank page, my ideas start ruffling among each other making a mess. I don’t have clarity anymore. Everything starts falling apart, anxiety kicks in and …. I close the tab. Phew too much trouble for a few likes. </p>







<p>But after a few days / weeks those ideas start dying. The worst part is I see them dying without seeing the light of the day. That sucks. </p>



<p>And that’s why I try to write, and you should too.</p>



<p>Writing about a topic gives me a platform to just lay my ideas wide in the open. It’s like clearing my mental hard drive. It feels relaxing. </p>



<p>But If I just pour my random thoughts on a piece of paper that’s just writing, not <em>good</em> writing. I don’t want people to see a mishmash of ill shaped ideas, I want them to see a well ordered architecture where every part fits in. It’s not just for the sake of readers though, It’s for the ideas themselves. </p>



<p>Often about a topic, I have a range of musings. They’re like vectors, each with their own direction and magnitude. They make sense individually but to understand about the topic as a whole, all of them need to come in sync. Their rhythm has to match. That’s what good writing does. </p>



<blockquote><p>Good writing is just clear thinking expressed on paper.</p></blockquote>



<p>Writing about a topic makes me think about it from all the directions and perspectives. </p>



<p><em>What do I know about this topic?</em></p>



<p><em>Do I know enough?</em></p>



<p><em>If everything I know, correct?</em></p>



<p><em>How can I fill my gaps?</em></p>







<p>Jotting down everything I know helps me answer many of these questions. The ones still unanswered force me to research more. It’s a cycle.</p>



<p>Each draft of writing takes me one step closer to the complete and clear picture. The ultimate truth starts showing itself in the end. It’s a bliss moment.</p>



<p>The learning readers get is always a pleasant <em>byproduct</em>. </p>







<p>As one of my favorite writer <a href="https://twitter.com/Julian" target="_blank" rel="noreferrer noopener">@Julian</a> says, </p>



<blockquote><p>The best writing is therapy that you publish for the world to learn from.</p></blockquote>







<p>After self-learning and expression, what is the next best thing writing offers?</p>



<p><strong>Relationships</strong>.</p>



<figure><div>
<div><blockquote data-width="550" data-dnt="true"><div lang="en" dir="ltr"><p>Writing online is a superpower.</p><p>Here’s a list of people who should start writing online.</p><p>1. The Niche Hobbyist</p><p>The Internet rewards people with obscure interests. Writing online will help you find other like-minded hobbyists who you wouldn’t be able to find in real-life.</p></div>— David Perell (@david_perell) <a href="https://twitter.com/david_perell/status/1227612675334660099?ref_src=twsrc%5Etfw">February 12, 2020</a></blockquote></div>
</div></figure>



<div><p>Writing online helps you create meaningful relationships, sometimes even indirectly. When people read well written articles, they can’t stop but appreciate the coherent thinking of the writer. These artifacts demonstrate author’s expertise in the given topic and hence increase their visibility.</p><p>Internet is a great place, good content can reach thousands of people with zero marketing. </p></div>



<blockquote><p>“By making it easy for people to find you online, you’ll create a vehicle for serendipity.” – <a href="https://twitter.com/david_perell">@david_perell</a></p></blockquote>



<p>This visibility can get you job offers, network of influential people, money and many other things. </p>



<div><p>I can go on and on about the benefits of putting yourself out there but it’s a moo point. You have to experience the magic yourself. When a stranger thanks you for a piece of advice or a someone asks if they can use your work, it feels great. </p><p>Not trying to brag here but even as a crappy writer myself, I have experienced the joy of someone reaching out to me to thank me for my work. You should too!</p></div>



<div><figure><a href="https://therandomdeveloper.files.wordpress.com/2020/11/screen-shot-2020-11-15-at-1.11.01-pm.png"><img loading="lazy" data-attachment-id="971" data-permalink="https://adityarohilla.com/screen-shot-2020-11-15-at-1-11-01-pm/" data-orig-file="https://therandomdeveloper.files.wordpress.com/2020/11/screen-shot-2020-11-15-at-1.11.01-pm.png" data-orig-size="1200,1184" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screen-shot-2020-11-15-at-1.11.01-pm" data-image-description="" data-medium-file="https://therandomdeveloper.files.wordpress.com/2020/11/screen-shot-2020-11-15-at-1.11.01-pm.png?w=300" data-large-file="https://therandomdeveloper.files.wordpress.com/2020/11/screen-shot-2020-11-15-at-1.11.01-pm.png?w=750" src="https://therandomdeveloper.files.wordpress.com/2020/11/screen-shot-2020-11-15-at-1.11.01-pm.png?w=1024" alt="" width="400" height="394" srcset="https://therandomdeveloper.files.wordpress.com/2020/11/screen-shot-2020-11-15-at-1.11.01-pm.png?w=400 400w, https://therandomdeveloper.files.wordpress.com/2020/11/screen-shot-2020-11-15-at-1.11.01-pm.png?w=800 800w, https://therandomdeveloper.files.wordpress.com/2020/11/screen-shot-2020-11-15-at-1.11.01-pm.png?w=150 150w, https://therandomdeveloper.files.wordpress.com/2020/11/screen-shot-2020-11-15-at-1.11.01-pm.png?w=300 300w, https://therandomdeveloper.files.wordpress.com/2020/11/screen-shot-2020-11-15-at-1.11.01-pm.png?w=768 768w" sizes="(max-width: 400px) 100vw, 400px"></a></figure></div>























<div><figure><a href="https://therandomdeveloper.files.wordpress.com/2020/11/screen-shot-2020-11-15-at-1.31.15-pm.png"><img loading="lazy" data-attachment-id="972" data-permalink="https://adityarohilla.com/screen-shot-2020-11-15-at-1-31-15-pm/" data-orig-file="https://therandomdeveloper.files.wordpress.com/2020/11/screen-shot-2020-11-15-at-1.31.15-pm.png" data-orig-size="2636,1624" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screen-shot-2020-11-15-at-1.31.15-pm" data-image-description="" data-medium-file="https://therandomdeveloper.files.wordpress.com/2020/11/screen-shot-2020-11-15-at-1.31.15-pm.png?w=300" data-large-file="https://therandomdeveloper.files.wordpress.com/2020/11/screen-shot-2020-11-15-at-1.31.15-pm.png?w=750" src="https://therandomdeveloper.files.wordpress.com/2020/11/screen-shot-2020-11-15-at-1.31.15-pm.png?w=1024" alt="" width="790" height="483"></a></figure></div>











<div><p>Go ahead and write about something. Anything. <br>It can be about an experience, topic, musing … just anything. Put yourself out there and you will get better with time. If you’re looking for some resources to write better, try these:</p><p><a href="https://youtu.be/grXrGaT7DLw" rel="nofollow">https://youtu.be/grXrGaT7DLw</a></p></div>



<p><a href="http://www.paulgraham.com/writing44.html" rel="nofollow">http://www.paulgraham.com/writing44.html</a></p>



<p><a href="https://blogs.amazon.com/the_fractionating_column/" rel="nofollow">https://blogs.amazon.com/the_fractionating_column/</a></p>







<p><br>To sum up, writing offers you a landscape to let your thoughts crash with each each other at full speed until they form a elegant symphony together. </p>



<p>This symphony creates a lasting impression on the audience and opens a gateway to serendipitous interactions.  </p>











<figure><a href="https://therandomdeveloper.files.wordpress.com/2020/11/quasiparticle-collider-head-640x353-1.jpg"><img loading="lazy" data-attachment-id="957" data-permalink="https://adityarohilla.com/quasiparticle-collider-head-640x353-1/" data-orig-file="https://therandomdeveloper.files.wordpress.com/2020/11/quasiparticle-collider-head-640x353-1.jpg" data-orig-size="640,353" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="quasiparticle-collider-head-640×353-1" data-image-description="" data-medium-file="https://therandomdeveloper.files.wordpress.com/2020/11/quasiparticle-collider-head-640x353-1.jpg?w=300" data-large-file="https://therandomdeveloper.files.wordpress.com/2020/11/quasiparticle-collider-head-640x353-1.jpg?w=640" src="https://therandomdeveloper.files.wordpress.com/2020/11/quasiparticle-collider-head-640x353-1.jpg?w=640" alt="" width="766" height="422" srcset="https://therandomdeveloper.files.wordpress.com/2020/11/quasiparticle-collider-head-640x353-1.jpg 640w, https://therandomdeveloper.files.wordpress.com/2020/11/quasiparticle-collider-head-640x353-1.jpg?w=150 150w, https://therandomdeveloper.files.wordpress.com/2020/11/quasiparticle-collider-head-640x353-1.jpg?w=300 300w" sizes="(max-width: 766px) 100vw, 766px"></a><figcaption>Just like these electrons</figcaption></figure>











<p>I hope now you know why I wrote this article.</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

			<div>
	
	<p>
		Software Engineer at Amazon | Ex - Samsung, Walmart Labs, Myntra. 
All things Tech and Startups.		<a href="https://adityarohilla.com/author/amazingcaseofadityarohilla/" rel="author">
			View more posts		</a>
	</p><!-- .author-description -->
</div><!-- .author-bio -->
	
</article><!-- #post-${ID} -->

	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
<!-- #comments -->

		</main><!-- #main -->
	</section><!-- #primary -->



	</div></div>]]>
            </description>
            <link>https://adityarohilla.com/2020/11/15/why-everyone-should-learn-to-write/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25097929</guid>
            <pubDate>Sun, 15 Nov 2020 03:19:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Structure of the ARM A64 instruction set (2017)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25097853">thread link</a>) | @JDW1023
<br/>
November 14, 2020 | https://weinholt.se/articles/arm-a64-instruction-set/ | <a href="https://web.archive.org/web/*/https://weinholt.se/articles/arm-a64-instruction-set/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
      <div>
        <article>
          <section><p>Earlier this year I bought a Raspberry Pi 3 to have as an AArch64
development machine. The fastest way to get familiar with an
instruction set is to write a disassembler for it and I’ve made one
for 64-bit <span>ARM</span> in R6RS Scheme as part of
the <a href="https://github.com/weinholt/machine-code">machine-code</a> project.
The instruction set is called <span>ARM</span> A64, instructions are always 32 bits
wide and they have a neat structure which is pretty fast to decode in&nbsp;software.</p>

<p>The architecture has 31 integer registers (x0-x30). There is also a
stack pointer register and a zero register that always contains
zeroes. Both these registers are encoded as register number 31, and
it’s up to each instruction if an operand can use the stack pointer or
the zero register. The x30 register is used to store the return
address. These registers are all 64-bit registers and the lower 32
bits can be accessed using the names w0-w31. Operations that write to
the lower 32 bits also clear the upper 32 bits, just like on&nbsp;<span>AMD64</span>.</p>
<p>There are also 32 registers usable as either floating point registers
or 128-bit vector registers. As vectors they support different
arrangements that are either 64 or 128 bits in total, containing
8-bit, 16-bit, 32-bit or 64-bit quantities. There are many
instructions that operate on multiple quantities at the same time,
which is an interesting way to speed up code. Multiple loop iterations
can be run&nbsp;simultaneously.</p>
<p>The instructions are documented in the <a href="https://developer.arm.com/docs/ddi0487/a/arm-architecture-reference-manual-armv8-for-armv8-a-architecture-profile"><span>ARM</span> ARM for ARMv8-A</a>. I’ve
counted, not including instruction aliases, 442 instruction mnemonics
(things like <span>ADD</span>, EOR, B.EQ, etc). They are organized in what is
basically a four-level table: main encoding, instruction group, decode
group and instruction. Chapter C4 of the manual follows the same
structure. This structure is nice for fast decoding, but it’s not
strictly necessary since all encodings at the instruction level still
need to have a unique&nbsp;meaning.</p>
<p>For each instruction mnemonic there can be multiple variants that
enable the instruction to handle different types of operands. An
example of this is the <span>FMUL</span> instruction that multiples two floating
point values. In a C program it would look like <code>a = b * c</code>. In A64
assembler it might look like one of these, depending on what the
surrounding code&nbsp;does:</p>
<pre><code><span>fmul</span> <span>s0</span>, <span>s1</span>, <span>s2</span>            
<span>fmul</span> <span>d0</span>, <span>d1</span>, <span>d2</span>            
<span>fmul</span> v0.<span>2</span>s, <span>v1</span>.<span>2</span>s, <span>v2</span>.<span>2</span>s   
<span>fmul</span> v0.<span>4</span>s, <span>v1</span>.<span>4</span>s, <span>v2</span>.<span>4</span>s   
<span>fmul</span> v0.<span>2</span>d, <span>v1</span>.<span>2</span>d, <span>v2</span>.<span>2</span>d   
<span>fmul</span> <span>s0</span>, <span>s1</span>, <span>v2</span>.s[<span>0</span>]       
<span>fmul</span> <span>d0</span>, <span>d1</span>, <span>v2</span>.d[<span>0</span>]
<span>fmul</span> v0.<span>2</span>s, <span>v1</span>.<span>2</span>s, <span>v2</span>.s[<span>0</span>] 
<span>fmul</span> v0.<span>4</span>s, <span>v1</span>.<span>4</span>s, <span>v2</span>.s[<span>0</span>]
<span>fmul</span> v0.<span>2</span>d, <span>v1</span>.<span>2</span>d, <span>v2</span>.d[<span>0</span>]
</code></pre>
<p>That’s quite a few variants for a single mnemonic. Not all mnemonics
have this many variants, but depending on how one counts I estimate
that there are in total around 1000-2000 variants. The instruction set
designers had to fit all these variants into 32 bits, while at the
same time making space for instructions that encode relatively large
immediate operands, and not forgetting about leaving space for future
extensions. As if that wasn’t difficult enough, the instructions
should also be easy to decode with&nbsp;hardware.</p>

<p>I’ve extracted the tables from my disassembler, rendered them with
the <a href="https://www.npmjs.com/package/bit-field">bit-field package</a>, and
made them slightly interactive. If you’re reading this in a browser
you can see the encodings below. The thing to notice is that each
layer adds extra fixed bits: fields that must be a fixed 0 or 1 value.
(The last level, the instruction level, is not shown in this table).
Two encodings under the same parent always have some differences in
these fields, so that they can be separated by an instruction decoder.
Click an encoding to expand the next level of&nbsp;encodings.</p>




<p>There are many conventions in the field names. Instructions that take
register operands encode them in fields named <em>Rd</em>, <em>Rn</em> and <em>Rm</em>.
Immediate values (integers, <span>PC</span>-relative offsets, etc) are named <em>imm</em>.
Fields that change the type of operation tend to be called <em>op</em>N or
<em>opcode</em>. In general a few of the fields encode the operation (or the
size of the operation) and the rest encode the&nbsp;operands.</p>

<p>The image below shows the encoding space of the instruction set. The
<em>x</em> axis goes from 0 to 2<sup>16</sup>-1 and encodes the lower 16 bits
of the instruction space, and the <em>y</em> axis contains the upper 16 bits.
The different colors denote different decode groups, i.e. all the
encodings at the third level of the table above. (There is probably a
better&nbsp;representation).</p>
<p><img src="https://weinholt.se/articles/arm-a64-instruction-set/a64-2048-crushed.png" title="Encoding space used by ARM A64" alt="An image showing the 32-bit
  encoding space. Mostly there are horizontal thick lines of different
  colors. This shows that the higher 16 bits tend to keep similar
  instructions together, although there is some mirroring around the
  middle of the image."></p>
<p>All the dark spots are places where ARMv8 does not have any allocated
instructions, or the encoding is reserved. For many instructions there
are some fields that have reserved encodings and these are also&nbsp;dark.</p>
<p>Even if instructions are kept to the fixed 32 bit encoding there is
still plenty of room for the instruction set to&nbsp;grow.</p>

<p><span>ARM</span> A64 is a quite clean instruction set with only a few quirks here
and there in its encoding. Compared to AMD64 it has twice the amount
of registers, a clean separation of load/store instructions, clean
RISCy operands (mostly one destination register and two source
registers) and of course the register names and most mnemonics are
totally different. Both have 128-bit vector registers and 64-bit
integer registers and a 64-bit address space. They look quite similar,
except everything’s&nbsp;different.</p>
</section>
        </article>
      </div>
    </div></div>]]>
            </description>
            <link>https://weinholt.se/articles/arm-a64-instruction-set/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25097853</guid>
            <pubDate>Sun, 15 Nov 2020 03:02:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why I teach vim]]>
            </title>
            <description>
<![CDATA[
Score 137 | Comments 158 (<a href="https://news.ycombinator.com/item?id=25097788">thread link</a>) | @amichlin
<br/>
November 14, 2020 | https://blog.ceos.io/2020/11/14/why-i-teach-vim/ | <a href="https://web.archive.org/web/*/https://blog.ceos.io/2020/11/14/why-i-teach-vim/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-124">

	

	
	<div>
		
<figure><a href="https://xkcd.com/378/"><img data-attachment-id="133" data-permalink="https://blog.ceos.io/real_programmers/" data-orig-file="https://blogceosio.files.wordpress.com/2020/11/real_programmers.png" data-orig-size="740,406" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="real_programmers" data-image-description="" data-medium-file="https://blogceosio.files.wordpress.com/2020/11/real_programmers.png?w=300" data-large-file="https://blogceosio.files.wordpress.com/2020/11/real_programmers.png?w=740" src="https://blogceosio.files.wordpress.com/2020/11/real_programmers.png?w=740" alt="" srcset="https://blogceosio.files.wordpress.com/2020/11/real_programmers.png 740w, https://blogceosio.files.wordpress.com/2020/11/real_programmers.png?w=150 150w, https://blogceosio.files.wordpress.com/2020/11/real_programmers.png?w=300 300w" sizes="(max-width: 740px) 100vw, 740px"></a></figure>



<p>The why of why people use vim has been <a href="https://dev.to/iggredible/why-i-use-vim-2f40">covered fairly extensively</a>, so I thought I would spend a little time explaining why I <em>teach</em> vim to my high school students, even in 2020.</p>



<p>It all began when I was assigned a mixed class of ninth through twelfth grade students in computer science just after the financial collapse on 2008. Well, the financial collapse first brought me to teach Intro to Programming using VB 6.0 and Windows thin clients, which was an experience unto itself (thanks in part to the <a href="https://en.wikipedia.org/wiki/Conficker">Conficker virus</a>). That experience is worth a separate blog post and is a good part of why one of my specialties is teaching computer security.</p>



<p>So here I am with all levels of student, including AP CS A (read: AP CS Java), and obsolete Windows PCs (at least the thin clients were gone). I couldn’t install any software, wanted to teach C, had to teach Java, and had very few options (these were the days before online web based IDEs).</p>



<p>I had experience with the UNIX command line, primarily Sun Workstations, thanks to my wonderful education at <a href="https://www.soe.ucsc.edu/departments/computer-science-and-engineering">UCSC</a>, so that wasn’t an issue. I had played with Linux in the 1990s to a bit of success, but hadn’t touched it for almost a decade. So I found an old Pentium 2 carcass in the the garbage outside my condo complex, installed a hard drive, and tried this new (to me) flavor of Linux called, strangely, <a href="https://ubuntu.com/">Ubuntu</a>.</p>



<p>I quickly realized this machine could have all the students coding at one, discovered the wonder that is <a href="https://www.chiark.greenend.org.uk/~sgtatham/putty/latest.html">putty.exe</a> (it doesn’t require any installation to run!) to connect the obsolete PCs to the server and soon my students were off and coding.</p>



<p>Why did I teach them vim? I wish I could say I agonized over all the options at the time and decided vim was the best pedagogical solution, but the reality of the situation was that vi was what I used in college because my father taught me vi. You see, I am lucky to have a father who worked in the industry and is even somewhat of a <a href="https://www.bell-labs.com/usr/dmr/www/qed.html">footnote in text editor history</a>. So I taught vi (later vim) because it is what I knew. A running theme in many computer science teacher’s trials by fire… teaching something because it is what they know. I will go as far as to argue that it is more important that the teacher knows the editor, and especially the programming language, rather than assigning any importance to one correct editor or one correct language that all teachers should teach.</p>



<p>Years later, though, I still teach vim and the command line. So here is how I justify my decision, even if only to myself.</p>



<p>It just works. Every time I go to a new school, it takes time to get the software installed necessary to run IDEs. I remember walking into one school in which the AP CS A class was flailing away with Eclipse on Mac OS X because the students needed, and didn’t have, administrator access. I have an amazing tech department at my current job, but even here it took us weeks to figure out how to deploy Visual Studio Code on the student’s MacBook Airs and then we had to figure out how to deploy Python3 and Java. So there’s no confusion, I teach vim along with many IDEs and I fully believe it is my responsibility to teach multiple platforms and multiple IDEs, but the CLI and vim are always my safety net.</p>



<p>My students can program in any number of of languages on a now cloud based CLI Linux machine (thank you <a href="https://www.linode.com/">Linode</a> and <a href="https://www.digitalocean.com/">Digital Ocean</a> – both of whom offer a $5/month plan – just. happy customer!). By using the CLI, I can support literally any type of computer connecting (including iPads, although the lack of a virtual esc key drives me batty as a vim user, and <a href="https://chrome.google.com/webstore/detail/secure-shell-app/pnhechapfaindjhompbnflcldabbghjo?hl=en">ChromeBooks</a>). Students can connect from anywhere in the world and things just work. All of this became infinitely important in the remote and hybrid learning experience of the pandemic. And this is all possible because the students use vim.</p>



<p>I keep track of as many of my students that major in CS and a running theme is they all profusely thank me for teaching them vim and the CLI. Too many colleges start CS1 with an IDE and then throw the CS2 students into the deep end with the CLI. Not everyone is as lucky as I was in regards to having a father well versed in the CLI.</p>



<p>And yes, there are online IDEs these days, but I’ve found those to be full of their own pitfalls, privacy issues, and costs and find doing any advanced work using them to be very difficult if not impossible.</p>



<p>Also, to be clear, both nano and Emacs work quite well in the context of CLI Linux and I don’t make any claim that teachers should use vim over those equally acceptable command line text editors except for one small argument. Most people agree, computer security pretty much requires knowledge of the command line and a text editor. I always tell my students that the one editor they are likely to find already installed on a machine is vim and it is a bad day when you have to install another editor. Maybe just an issue for students interested in ethical penetration testing…</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article><!-- #post-${ID} -->

	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
<!-- #comments -->

		</main><!-- #main -->
	</section><!-- #primary -->


	</div></div>]]>
            </description>
            <link>https://blog.ceos.io/2020/11/14/why-i-teach-vim/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25097788</guid>
            <pubDate>Sun, 15 Nov 2020 02:50:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Notes on Time Management from a Dying Professor]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25097485">thread link</a>) | @craigkerstiens
<br/>
November 14, 2020 | https://www.swyx.io/time-management-randy-pausch/ | <a href="https://web.archive.org/web/*/https://www.swyx.io/time-management-randy-pausch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>In 2007, just after his cancer diagnosis, Carnegie Mellon professor Randy Pausch gave <a href="https://www.youtube.com/watch?v=oTugjssqOT0">a well received lecture on Time Management</a>. These are my notes (<a href="http://www.cs.virginia.edu/~robins/Randy/RandyPauschTimeManagement2007.pdf">slides here</a>, <a href="https://jamesclear.com/great-speeches/time-management-by-randy-pausch">transcript here</a>).</p>
<blockquote>
  <p>Side note - he is better known for his Last Lecture on <a href="https://www.youtube.com/watch?v=ji5_MqicxSo">Achieving Your Childhood Dreams</a> - ironically given <em>before</em> this Time Management talk.</p>
</blockquote>

<section>
  <h2 id="money-vs-time"><a href="#money-vs-time">Money vs Time</a></h2>
  <ul>
    <li>We are very good at dealing with money, but very bad at dealing with time. Having an idea of how much your time costs helps you start making tradeoffs better.</li>
    <li>We have to manage our time better than we manage our money. We have money budgets, what about time budgets?</li>
    <li>We are in a "Time Famine" - nobody says they have "too much time". Yet The typical office worker wastes almost 2 hrs a day at work, and 28 hours a week on TV. This isn't just a one-off problem - you can't solve it one week and then go back to normal - it's systemic and requries change in fundamental processes to address this once and for all.</li>
    <li>The goal is to have fun, be happier, lead a more meaningful life. If you're not going to have fun, why do it?</li>
    <li>Being successful doesn't make you manage your time well. Managing your time well does make you successful.</li>
    <li>Turn money into time - Hire someone to do chores. Esp if you have kids.</li>
  </ul>
</section>
<section>
  <h2 id="goals-priorities-planning"><a href="#goals-priorities-planning">Goals, Priorities, Planning</a></h2>
  <ul>
    <li>
      <p>Always ask: Why am I doing this, What is the goal? Why will I succeed? What will happen if I don't do it?</p>
    </li>
    <li>
      <p><strong>It's more important to do the right things, rather than do things right.</strong></p>
    </li>
    <li>
      <p>Pareto Principle, 80/20 rule. Focus on the high value/impact things.</p>
    </li>
    <li>
      <p>People asked Walt how he built Disneyland in 366 days. His reply: "We used every one of them."</p>
    </li>
    <li>
      <p><strong>Planning is impt</strong>. Failing to plan = planning to fail. Have a plan for day/week/quarter.</p>
    </li>
    <li>
      <p>You can still be fluid - plans can change.</p>
    </li>
    <li>
      <p><strong>Todos</strong> - Break things down into small steps. "Get tenure" is not a todo. Eat your frog - do the ugliest thing first.</p>
    </li>
    <li>
      <p><strong>Prioritization</strong> (MOST IMPORTANT) Covey/Eisenhower Matrix</p>
      <ul>
        <li>urgent + important</li>
        <li>not urgent + important</li>
        <li>urgent + unimportant</li>
        <li>not urgent + unimportant</li>
        <li>the trick is to not do unimportant things, and to tackle important things <strong>before</strong> they become urgent.</li>
      </ul>
      <p>
        <img src="https://dev-to-uploads.s3.amazonaws.com/i/ixrb0xwdka2kb2coycb7.png" alt="Alt Text">
      </p>
    </li>
    <li>
      <p>Keep your desk clear - have 1 thing on your desk</p>
    </li>
    <li>
      <p>Touch each piece of paper, email once. <strong>Inbox is not your todo list</strong>. File the email away and put it on your todo list.</p>
    </li>
    <li>
      <p>A filing system is absolutely essential. Have one place in the house where any piece of paper goes. (Ditto in the cloud/computer)</p>
    </li>
    <li>
      <p><strong>Have at least two, maybe three monitors.</strong> Using just one "is like eating off the airplane tray."</p>
    </li>
    <li>
      <p>Productivity Stack:</p>
      <ul>
        <li>Todolist</li>
        <li>Inbox</li>
        <li>Calendar. Dont use your brain to remember your appointments.</li>
      </ul>
    </li>
    <li>
      <p>Standing during phone calls - will be much faster. Don't get comfortable. "I'd love to keep talking with you but I have students waiting."</p>
    </li>
    <li>
      <p>Exercise on bike - can be spent on phone if you have a headset</p>
    </li>
    <li>
      <p>Write a Thank You note. Tangible way of telling someone you appreciated something. It makes you rare, they remember you well.</p>
    </li>
    <li>
      <p>The dog - reminds you you have better things to do</p>
    </li>
    <li>
      <p>Chair - make your office comfortable for you, optionally comfortable for others (eg folding chair).</p>
    </li>
    <li>
      <p><strong>You do not find time to do something, you make time.</strong> And you make time by electing not to do something else.</p>
    </li>
    <li>
      <p><strong>Learn to say no.</strong> Opportunity cost is real. "Gentle no" = "I'll be your backup". "If you need an 8th person I'll be there."</p>
    </li>
    <li>
      <p>Find your creative time and defend it ruthlessly. It varies for people - could be 10pm-Midnight.</p>
    </li>
    <li>
      <p>Find your dead time and do stuff where you don't need to be at your best.</p>
    </li>
    <li>
      <p><strong>Interruption</strong> takes 6-9mins, but recovery takes 4-5mins. Got to find ways to reduce frequency of interruptions. Turn phone calls into emails. Batch interactions with other people.</p>
    </li>
    <li>
      <p>Giving hints to cut meetings short: Get up, walk to the door, thank them, shake their hand. Walk them out of the room.</p>
    </li>
    <li>
      <p><strong>Time journals</strong> - monitor and update thru the day. <a href="http://www.cs.unc.edu/Events/News/VirtuousReality/">Fred Brooks had actual time clocks</a>.</p>
    </li>
    <li>
      <p>Look at open blocks where you know you are going to be wasting time, as gaps between blocks - make up a fake class.</p>
    </li>
    <li>
      <p>Delegate.</p>
    </li>
    <li>
      <p>"How am I wasting other people's time?"</p>
    </li>
    <li>
      <p>You become more efficient at work so you can leave on time and spend it with the people you love. Once you have kids the stakes are real.</p>
    </li>
  </ul>
</section>
<section>
  <h2 id="procrastination"><a href="#procrastination">Procrastination</a></h2>
  <ul>
    <li>Sometimes you get lucky - if you wait long enough you may not have to do it</li>
    <li>Sometimes you want to avoid Parkinson's Law - Work expands to fill the time available for it.</li>
    <li>But key realization - doing things at the last minute is very expensive. If you push things up to the deadline that's where all the stress comes from</li>
    <li>Make a fake deadline and pretend it is real.</li>
    <li>Identify why you're procrastinating - afraid you are going to fail? scared to ask somebody for something? Sometimes you just have to ask.</li>
  </ul>
</section>
<section>
  <h2 id="delegation"><a href="#delegation">Delegation</a></h2>
  <ul>
    <li>Grant Authority + Responsibility</li>
    <li>Delegate but always do the ugliest job yourself, so it is very clear you are willing to do what you ask</li>
    <li>Treat your people well, esp staff/secretaries</li>
    <li>Don't be vague:
      <ul>
        <li>Give specific thing to do</li>
        <li>Specific date/time</li>
        <li>Specific penalty/reward</li>
      </ul>
    </li>
    <li>Challenge people: delegate until they complain</li>
    <li>Communication has to be CLEAR - and written</li>
    <li>Don't tell them HOW to do it - tell them what you need done, let them come up with solutions. This is how to work with people smarter than you.</li>
    <li>Offer relative importance - so people know what order to do them in</li>
    <li>Beware upward delegation - step back.</li>
    <li>Carrots &gt; Sticks. Reinforce behavior you like. "Thank you I really appreciate you did a good job."</li>
  </ul>
</section>
<section>
  <h2 id="meetings"><a href="#meetings">Meetings</a></h2>
  <ul>
    <li>Take everybody's phones in a meeting. Be present.</li>
    <li>A scribe should take One minute minutes at the end. What decisions got made, and who is responsible for what.</li>
  </ul>
</section>
<section>
  
  <ul>
    <li>"Computers are faster, they just take longer."</li>
    <li>Technology has to make your life better, end to end. eg. if it changes workflow. "Just a little bit faster" is not good enough.</li>
  </ul>
</section>
<section>
  <h2 id="email"><a href="#email">Email</a></h2>
  <ul>
    <li>don't delete email</li>
    <li>If you want something done, don't send it to 5 people. Send it to ONE person. use alf weaver specificity rules.</li>
    <li>If person has not responded in 48 hours, nag them, bc their response rate will be zero</li>
    <li>It's not a vacation if you're reading email</li>
  </ul>
</section>
<section>
  <h2 id="reporting-up"><a href="#reporting-up">Reporting Up</a></h2>
  <ul>
    <li>Ask when is next meeting, what you want by then, who to turn to for help</li>
  </ul>
</section>
<section>
  <h2 id="life-advice"><a href="#life-advice">Life Advice</a></h2>
  <ul>
    <li>Kill your television. Average American spends 28 hrs/wk on TV.</li>
    <li>Eat, sleep, exercise.</li>
    <li>Never break a promise, but re-negotiate them if need be.</li>
    <li>If you haven’t got time to do it right, you don’t have time to do it wrong.</li>
    <li>Recognize that most things are pass/fail. Good Enough is good enough.</li>
    <li>Feedback loops: ask in confidence.</li>
  </ul>
</section>
<section>
  <h2 id="call-to-action"><a href="#call-to-action">Call to Action</a></h2>
  <ul>
    <li>Put your TODO list in priority order</li>
    <li>Do a time journal or count hours of TV you watch</li>
    <li>Make a note to revisit this in 30 days and ask "What Have I Changed?"</li>
  </ul>
</section>
<section>
  <h2 id="style-notes"><a href="#style-notes">Style Notes</a></h2>
  <ul>
    <li>
      <p>He often uses humor - noting the optimistic side of his very grim situation, giving some relief to his audience while also reminding them of the importance of his message.</p>
    </li>
    <li>
      <p>He is also extremely respectful - being humble to specific members of the audience ("Gabe is REALLY in good shape", "I am NOT smarter than Jim Calhoun", "Am I giving a talk with Alf Weaver in the audience?"), as well as the venue/general audience itself ("there aren't many better PhD programs in history than this one").</p>
    </li>
    <li>
      <p>He brings in personal stories and examples, often involving his wife, and they are usually relatable and funny. His slides use photos from his own life living the things he talks about.</p>
    </li>
    <li>
      <p>The anecdotes also inject some variety - 40 minutes in he breaks for a tangent about his dog and a tiny debate he had with his wife.</p>
    </li>
    <li>
      <p>Vocal variation - 53 minutes in he screams "PUT THE CIGARETTE OUT MOM" and that is a nice spike in decibels.</p>
    </li>
    <li>
      <p>Ending is really good: He ends with actionable things to do, and a nice reminder of why this is important:</p>
      <blockquote>
        <p>"If I haven't changed anything, then we still had a pleasant hour together. If you have changed things, then you'll probably have a lot more time to spend with the ones you love. And that's important, time is all we have. And you may find one day, you have less than you think."</p>
      </blockquote>
    </li>
  </ul>
</section>
</div></div>]]>
            </description>
            <link>https://www.swyx.io/time-management-randy-pausch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25097485</guid>
            <pubDate>Sun, 15 Nov 2020 01:57:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Going Bark: A Furry’s Guide to End-to-End Encryption]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25097177">thread link</a>) | @ciarannolan
<br/>
November 14, 2020 | https://soatok.blog/2020/11/14/going-bark-a-furrys-guide-to-end-to-end-encryption/ | <a href="https://web.archive.org/web/*/https://soatok.blog/2020/11/14/going-bark-a-furrys-guide-to-end-to-end-encryption/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<p>Governments are back on their anti-encryption bullshit again.</p>



<p>Between the <a href="https://blog.cryptographyengineering.com/2020/03/06/earn-it-is-an-attack-on-encryption/">U.S. Senate’s “EARN IT” Act</a>, the <a href="https://www.eff.org/deeplinks/2020/10/orders-top-eus-timetable-dismantling-end-end-encryption">E.U.’s slew of anti-encryption proposals</a>, and <a href="https://fee.org/articles/australia-s-unprecedented-encryption-law-is-a-threat-to-global-privacy/">Australia’s new anti-encryption law</a>, it’s become clear that the authoritarians in office view online privacy as a threat to their existence.</p>



<p>Normally, when the governments increase their anti-privacy sabre-rattling, technologists start talking more loudly about Tor, Signal, and other privacy technologies (usually only to be drowned out by paranoid people who think Tor and Signal are government backdoors or something stupid; conspiracy theories ruin everything!).</p>



<p><strong>I’m not going to do that.</strong></p>



<p>Instead, I’m going to show you how to add end-to-end encryption to any communication software you’re developing. (Hopefully, I’ll avoid making <a href="https://soatok.blog/2020/10/28/bizarre-design-choices-in-zooms-end-to-end-encryption/">any bizarre design decisions</a> along the way.)</p>



<p>But first, some important disclaimers:</p>



<ol><li><strong>Yes, you should absolutely do this.</strong> I don’t care how banal your thing is; if you expect people to use it to communicate with each other, you should make it so that you can never decrypt their communications.</li><li>You should absolutely NOT bill the thing you’re developing as an <em>alternative</em> to Signal or WhatsApp.</li><li>The goal of doing this is to increase the amount of end-to-end encryption deployed on the Internet that the service operator cannot decrypt (even if compelled by court order) and make E2EE normalized. The goal is NOT to compete with highly specialized and peer-reviewed privacy technology.</li><li>I am not a lawyer, I’m some furry who works in cryptography. The contents of this blog post is not legal advice, nor is it endorsed by any company or organization. Ask the <a href="https://eff.org/">EFF</a> for legal questions.</li></ol>



<p>The organization of this blog post is as follows: First, I’ll explain <a href="#symmetric-key-encryption">how to encrypt and decrypt data between users</a>, assuming you have a key. Next, I’ll explain <a href="#key-agreement">how to build an authenticated key exchange</a> and <a href="#session-key-management">a ratcheting protocol to determine the keys used in the first step</a>. Afterwards, I’ll explore <a href="#identity-key-management">techniques for binding authentication keys to identities and managing trust</a>. Finally, I’ll discuss <a href="#backdoor-resistance">strategies for making it impractical to ever backdoor your software (and impossible to silently backdoor it)</a>, just to piss <a href="https://en.wikipedia.org/wiki/Five_Eyes">the creeps and tyrants of the world</a> off even more.</p>



<p>You don’t have to implement the full stack of solutions to protect users, but the further you can afford to go, the safer your users will be from privacy-invasive policing.</p>







<h2 id="preliminaries">Preliminaries</h2>



<h3 id="choosing-a-cryptography-library">Choosing a Cryptography Library</h3>



<p>In the examples contained on this page, I will be using the <a href="https://libsodium.gitbook.io/doc/">Sodium cryptography library</a>. Specifically, my example code will be written with the <a href="https://github.com/paragonie/sodium-plus">Sodium-Plus</a> library for JavaScript, since it strikes a good balance between performance and being cross-platform.</p>


<pre title="">const { SodiumPlus } = require('sodium-plus');

(async function() {
     // Select a backend automatically
     const sodium = await SodiumPlus.auto();
     
     // Do other stuff here
})();
</pre>


<p>Libsodium is <a href="https://latacora.micro.blog/2018/04/03/cryptographic-right-answers.html">generally the correct choice for developing cryptography features in software</a>, and is available in most programming languages,</p>



<p>If you’re prone to choose a different library, you should consult your cryptographer (and yes, you should have one on your payroll if you’re doing things different) about your design choices.</p>



<h3>Threat Modelling</h3>



<p>Remember above when I said, “You don’t have to implement the full stack of solutions to protect users, but the further you can afford to go, the safer your users will be from privacy-invasive policing”?</p>



<p>How far you go in implementing the steps outlined on this blog post should be informed by <a href="https://adamcaudill.com/2016/07/20/threat-modeling-for-applications/">a threat model</a>, not an ad hoc judgment.</p>



<p>For example, if you’re encrypting user data and storing it in the cloud, you probably want to pass <a href="https://blog.cryptographyengineering.com/2012/04/05/icloud-who-holds-key/">the Mud Puddle Test</a>:</p>



<blockquote><div><p>1. First, drop your device(s) in a mud puddle.<br>2. Next, slip in said puddle and crack yourself on the head. When you regain consciousness you’ll be perfectly fine, but<em>&nbsp;won’t for the life of you&nbsp;</em>be able to&nbsp;recall your device passwords or keys.<br>3. Now try to get your cloud data back.</p><p>Did you succeed? If so, you’re screwed. Or to be a bit less dramatic, I should say: your cloud provider has access to your ‘encrypted’ data, as does the government if they want it, as does any rogue employee who knows their way around your provider’s internal policy checks.</p></div><cite>Matthew Green describes the Mud Puddle Test, which Apple products <a href="https://sneak.berlin/20201112/your-computer-isnt-yours/">definitely don’t pass</a>.</cite></blockquote>



<p>If you must fail the Mud Puddle Test for your users, make sure you’re clear and transparent about this in the documentation for your product or service.</p>







<h2 id="symmetric-key-encryption">I. Symmetric-Key Encryption</h2>



<p>The easiest piece of this puzzle is to encrypt data in transit between both ends (thus, satisfying the loosest definition of end-to-end encryption).</p>



<p>At this layer, you already have some kind of symmetric key to use for encrypting data before you send it, and for decrypting it as you receive it.</p>



<p>For example, the following code will encrypt/decrypt strings and return hexadecimal strings with a version prefix.</p>


<pre title="">const VERSION = "v1";

/**
 * @param {string|Uint8Array} message
 * @param {Uint8Array} key
 * @param {string|null} assocData
 * @returns {string}
 */
async function encryptData(message, key, assocData = null) {
    const nonce = await sodium.randombytes_buf(24);
    const aad = JSON.stringify({
      'version': VERSION,
      'nonce': await sodium.sodium_bin2hex(nonce),
      'extra': assocData
    });

    const encrypted = await sodium.crypto_aead_xchacha20poly1305_ietf_encrypt(
        message,
        nonce,
        key,
        aad
    );
    return (
       VERSION +
       await sodium.sodium_bin2hex(nonce) +
       await sodium.sodium_bin2hex(encrypted)
    );
}

/**
 * @param {string|Uint8Array} message
 * @param {Uint8Array} key
 * @param {string|null} assocData
 * @returns {string}
 */
async function decryptData(encrypted, key, assocData = null) {
    const ver = encrypted.slice(0, 2);
    if (!await sodium.sodium_memcmp(ver, VERSION)) {
        throw new Error("Incorrect version: " + ver);
    }
    const nonce = await sodium.sodium_hex2bin(encrypted.slice(2, 50));
    const ciphertext = await sodium.sodium_hex2bin(encrypted.slice(50));
    const aad = JSON.stringify({
      'version': ver,
      'nonce': encrypted.slice(2, 50),
      'extra': assocData
    });
    
    const plaintext = await sodium.crypto_aead_xchacha20poly1305_ietf_decrypt(
        ciphertext,
        nonce,
        key,
        aad
    );
    return plaintext.toString('utf-8');
}
</pre>


<p>Under-the-hood, this is using <a href="https://soatok.blog/2020/07/12/comparison-of-symmetric-encryption-methods/#aes-gcm-vs-xchacha20poly1305">XChaCha20-Poly1305</a>, which is less sensitive to timing leaks than AES-GCM. However, like AES-GCM, this encryption mode doesn’t provide <a href="https://eprint.iacr.org/2019/016">message- or key-commitment</a>.</p>



<p>If you want key commitment, you should derive two keys from <code>$key</code> using a KDF based on hash functions: One for actual encryption, and the other <a href="https://eprint.iacr.org/2020/1153">as a key commitment value</a>.</p>



<p>If you want message commitment, you can use AES-CTR + HMAC-SHA256 or XChaCha20 + BLAKE2b-MAC.</p>



<p>If you want both, ask <a href="https://mumble.net/~campbell/">Taylor Campbell</a> about his BLAKE3-based design.</p>



<p>A modified version of the above code with key-commitment might look like this:</p>


<pre title="">const VERSION = "v2";

/**
 * Derive an encryption key and a commitment hash.
 * @param {CryptographyKey} key
 * @param {Uint8Array} nonce
 * @returns {{encKey: CryptographyKey, commitment: Uint8Array}}
 */
async function deriveKeys(key, nonce) {
    const encKey = new CryptographyKey(await sodium.crypto_generichash(
        new Uint8Array([0x01].append(nonce)),
        key
    ));
    const commitment = await sodium.crypto_generichash(
        new Uint8Array([0x02].append(nonce)),
        key
    );
    return {encKey, commitment};
}

/**
 * @param {string|Uint8Array} message
 * @param {Uint8Array} key
 * @param {string|null} assocData
 * @returns {string}
 */
async function encryptData(message, key, assocData = null) {
    const nonce = await sodium.randombytes_buf(24);
    const aad = JSON.stringify({
      'version': VERSION,
      'nonce': await sodium.sodium_bin2hex(nonce),
      'extra': assocData
    });
    const {encKey, commitment} = await deriveKeys(key, nonce);

    const encrypted = await sodium.crypto_aead_xchacha20poly1305_ietf_encrypt(
        message,
        nonce,
        encKey,
        aad
    );
    return (
       VERSION +
       await sodium.sodium_bin2hex(nonce) +
       await sodium.sodium_bin2hex(commitment) +
       await sodium.sodium_bin2hex(encrypted)
    );
}

/**
 * @param {string|Uint8Array} message
 * @param {Uint8Array} key
 * @param {string|null} assocData
 * @returns {string}
 */
async function decryptData(encrypted, key, assocData = null) {
    const ver = encrypted.slice(0, 2);
    if (!await sodium.sodium_memcmp(ver, VERSION)) {
        throw new Error("Incorrect version: " + ver);
    }
    const nonce = await sodium.sodium_hex2bin(encrypted.slice(2, 50));
    const ciphertext = await sodium.sodium_hex2bin(encrypted.slice(114));
    const aad = JSON.stringify({
      'version': ver,
      'nonce': encrypted.slice(2, 50),
      'extra': assocData
    });
    const storedCommitment = await sodium.sodium_hex2bin(encrypted.slice(50, 114));
    const {encKey, commitment} = await deriveKeys(key, nonce);
    if (!(await sodium.sodium_memcmp(storedCommitment, commitment))) {
        throw new Error("Incorrect commitment value");
    }
    
    const plaintext = await sodium.crypto_aead_xchacha20poly1305_ietf_decrypt(
        ciphertext,
        nonce,
        encKey,
        aad
    );
    return plaintext.toString('utf-8');
}
</pre>


<p>Another design choice you might make is to encode ciphertext with base64 instead of hexadecimal. That doesn’t significantly alter the design here, but it does mean your decoding logic has to accommodate this.</p>



<p>You SHOULD version your ciphertexts, and include this in the AAD provided to your AEAD encryption mode. I used “v1” and “v2” as a version string above, but you can use your software name for that too.</p>



<h2 id="key-agreement">II. Key Agreement</h2>



<p>If …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://soatok.blog/2020/11/14/going-bark-a-furrys-guide-to-end-to-end-encryption/">https://soatok.blog/2020/11/14/going-bark-a-furrys-guide-to-end-to-end-encryption/</a></em></p>]]>
            </description>
            <link>https://soatok.blog/2020/11/14/going-bark-a-furrys-guide-to-end-to-end-encryption/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25097177</guid>
            <pubDate>Sun, 15 Nov 2020 01:12:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Botanix Kills Superbug Staph for Surgical Site Infections]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25096961">thread link</a>) | @techinvestor
<br/>
November 14, 2020 | https://marksita.com/botanix-kills-superbug-staph-for-surgical-site-infections/ | <a href="https://web.archive.org/web/*/https://marksita.com/botanix-kills-superbug-staph-for-surgical-site-infections/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content">
    

<section id="main-content">
    <div>
        <div>
                        <div id="main-wrap">

                <div>
                    <article id="post-1065">
    <div><header>
    </header><div>

    
<p>Antibiotic resistance could <a href="https://www.wired.com/2014/12/oneill-rpt-amr/">cost the world $100 trillion by 2050</a>, and approximately kills 700,000 per year. Some in the scientific community say it could be as bad as cancer. Antimicrobial resistance (AMR) has emerged as one of the <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4768623/">principal public health problems</a> of the 21st century. The World Health Organisation published <a href="https://www.who.int/news-room/detail/27-02-2017-who-publishes-list-of-bacteria-for-which-new-antibiotics-are-urgently-needed">a list of bacteria of which new antibiotics are urgently needed</a>, and superbug “Staph” was Priority high. It’s a <a href="https://www.newscientist.com/article/dn25498-antibiotic-resistant-superbugs-now-a-global-epidemic/">global epidemic</a>.</p>



<p>We should be rational optimists, as Matt Ridley explains with evidence in his book. Through science and technology the world gets better via our collective brain.</p>



<p><a href="https://botanixpharma.com/">Botanix Pharmaceuticals</a> (Botanix) has made a scientific breakthrough. In September 2020, Botanix proved its product&nbsp; BTX 1801 kills superbug Staph (aka MRSA or golden Staph) without allowing resistance to develop. <a href="https://www.asx.com.au/asxpdf/20200908/pdf/44mf662gw8dbkd.pdf">It was done in human skin</a>. This product is designed for Surgical Site Infections (SSI) which costs hospitals US$10 billion per year. The Phase 2a study is due in Q4 2020. They did this a year after they <a href="https://www.asx.com.au/asxpdf/20190801/pdf/4473szphv8b084.pdf">raised US$40 million at a valuation of US$198 million</a>.</p>



<p>There was already evidence Cannabidiol (CBD) was antibacterial, which is used in the product. This new data supports bigger studies for a potential new antibiotic. There is a big need for new antibiotics due to antibiotic resistance. The problem is that it is very hard to make these scientific breakthroughs. Botanix has made a breakthrough for the world, and the data will be used by other scientists to save lives. Botanix also has a cash runway to take its clinical pipeline to December 2021 (excluding FDA approved Phase 3 Acne).</p>



<p>There are <a href="https://www.infectiousdiseaseadvisor.com/home/decision-support-in-medicine/hospital-infection-control/surgical-site-infections/">approximately 27 million</a> surgical procedures in the U.S per year. Approximately 5% get infected, which leads to 1.35 million SSI’s per year in the U.S. Occurrence of SSI is estimated to increase hospital stay by 7 to 10 days and add over <a href="https://www.infectiousdiseaseadvisor.com/home/decision-support-in-medicine/hospital-infection-control/surgical-site-infections/">$3,000 in costs of care</a>. Globally, <a href="https://static1.squarespace.com/static/5435b2b9e4b0e1fd29fa9d26/t/5aa2b3374192023932fb6690/1520612157567/Surgical%26AnaesthesiaDataReport.pdf">there are approximately 313 million</a> surgical procedures per year. If 5% of surgical procedures lead to infections, that’s 15.6 million SSI’s globally.</p>



<p>In the U.S there are 1.35 million SSI’s per year, multiply that by $3,000 costs, and it equals $4 billion. SSI’s cost U.S hospitals $4 billion per year. If BTX 1801 is priced at $100, that equals $135 million yearly revenue in the U.S – a huge drop in hospital costs. Presume the product will last 10 years, and that equals $1.3 billion in revenue. Globally, potential annual revenue could be $1.5 billion (SSI’s multiplied by the $100 price).&nbsp;</p>



<p>Keep in mind that this is 1 of 3 products in the Botanix clinical pipeline. Pending studies are FDA approved <a href="http://marksita.com/botanix-pharmaceuticals">Phase 3 Acne</a> and Phase 2 Rosacea.</p>



<p>A recent study found it costs on average <a href="https://amr.solutions/2020/03/06/what-does-an-antibiotic-cost-to-develop-what-is-it-worth-how-to-afford-it/">$1.3 billion to get a new drug approved</a>. By using synthetic Cannabidiol, Botanix is able to make significantly better drugs. Botanix has a competitive advantage, and the <a href="https://www.fda.gov/patients/fast-track-breakthrough-therapy-accelerated-approval-priority-review/fast-track">FDA Fast Track Status</a> application (due to the <a href="https://smallcaps.com.au/botanix-pharmaceuticals-receives-fda-grant-antibacterial-product-btx-1801/">FDA Qualified Infectious Disease Product</a> status) will make it stronger.</p>



<p>Antibiotics is the <a href="https://www.abc.net.au/radionational/programs/rearvision/antibiotics-dilemma-running-out-of-drugs-to-treat-superbugs/7281438">$40 billion drug market</a> that no company wants a part of. <strong>Until now.</strong></p>





</div>
    <p><span>
                <span>Categories</span>
        <a href="https://marksita.com/category/research/" rel="category tag">Research</a>            </span></p></div>
</article>                </div>
                            </div>
                    </div>
    </div>
</section>




</div></div>]]>
            </description>
            <link>https://marksita.com/botanix-kills-superbug-staph-for-surgical-site-infections/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25096961</guid>
            <pubDate>Sun, 15 Nov 2020 00:27:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ask HN: Are you depressed?]]>
            </title>
            <description>
<![CDATA[
Score 395 | Comments 461 (<a href="https://news.ycombinator.com/item?id=25096877">thread link</a>) | @pcbro141
<br/>
November 14, 2020 | http://www.strawpoll.me/22152225 | <a href="https://web.archive.org/web/*/http://www.strawpoll.me/22152225">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
        
    
      
    
<section>
    
        <span>Asked</span>
    
    <span>
        <abbr title="11 15 2020 00:09:57 UTC" data-epoch="1605398997">Nov 15, 2020</abbr>
    </span>
    <p>
        <span>IP Duplication Checking</span>
        
    </p>
</section>  
    
   

    


    
   

    
      
    

    </div></div>]]>
            </description>
            <link>http://www.strawpoll.me/22152225</link>
            <guid isPermaLink="false">hacker-news-small-sites-25096877</guid>
            <pubDate>Sun, 15 Nov 2020 00:12:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[There is little chance CRISPR will ever be widely used to directly treat disease]]>
            </title>
            <description>
<![CDATA[
Score 67 | Comments 47 (<a href="https://news.ycombinator.com/item?id=25096386">thread link</a>) | @contingencies
<br/>
November 14, 2020 | http://www.josiahzayner.com/2020/10/crispr-is-dead.html | <a href="https://web.archive.org/web/*/http://www.josiahzayner.com/2020/10/crispr-is-dead.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-3476191675913246664" itemprop="description articleBody">
<p><a href="https://lh3.googleusercontent.com/-7FtXrDcyX1g/X34I8PRxLlI/AAAAAAAAgFY/RFAjGp7fdiQyBJZnN1ja0p9Tfat8EEY-gCLcBGAsYHQ/image.png"><img alt="" data-original-height="540" data-original-width="405" height="240" src="https://lh3.googleusercontent.com/-7FtXrDcyX1g/X34I8PRxLlI/AAAAAAAAgFY/RFAjGp7fdiQyBJZnN1ja0p9Tfat8EEY-gCLcBGAsYHQ/image.png" width="180"></a></p><p><span>Today, the Nobel Prize was awarded for “genome editing” to Emmanuelle Charpentier and Jennifer Doudna. Essentially this was the CRISPR Nobel Prize. If enough of CRISPR has already come so that it is worthy of a Nobel Prize I can’t imagine there is much place to go from here.&nbsp;</span></p><p><span id="docs-internal-guid-4bf038d4-7fff-ec28-e41c-6ded5276f0c8"><p dir="ltr"><span>Modifying the genome of organisms has always been of great interest to scientists. Adding or removing genes allows us to understand how things work and allows us to create microorganisms, plants or animals(humans are animals right?) that have traits never seen before. Knowingly modifying the genome of organisms has been done since people understood breeding. Inserting specific DNA elements began in the 1970s but it wasn’t very targeted and was mostly just inserting genes into random places in genomes. It wasn’t until the 1990s that people started to be able to do targeted genome modifications.&nbsp;</span></p><p dir="ltr"><span>Targeted genome modifications allow highly specific and accurate changes to an organism’s DNA. The co-opting of the cellular mechanism of homologous recombination is the backbone of all modern genome editing technologies including Zinc Finger Nucleases(ZFNs), Transcription activator-like effector nuclease(TALENs) and Clustered regularly Interspaced Short Palindromic Repeats(CRISPR). Both ZFNs and TALENs are mostly synthetic, i.e. they contain a portion that can be engineered to target DNA and a synthetically attached nuclease that will cleave DNA to initiate recombination and gene editing. CRISPR is almost completely natural which makes one wonder how there are so many patents on it’s use, yikes. </span></p><p dir="ltr"><span>CRISPR can modify most any living cell but so can ZFNs, TALENs and other technologies. So why then was CRISPR </span><span><a href="https://www.technologyreview.com/2014/12/04/170211/who-owns-the-biggest-biotech-discovery-of-the-century/">heralded as the discovery of the century</a></span><span> by the MIT Tech Review? Simply, CRISPR is just easier to use because it uses nucleic acid targeting. That makes it cost less and take less time to produce genetic modifications.&nbsp;</span></p><p dir="ltr"><span>So what has CRISPR made possible? Not much really. Most everything done with CRISPR can be done with one of these other technologies albeit these others are slower and more expensive. CRISPR allows the scaling of genetic engineering so that time and money are much less of a factor. It is the cloud computing of biology at least in my mind.</span></p><p dir="ltr"><span>Despite claims by scientists and pharma companies there is little chance CRISPR will ever be widely used in the clinic to directly treat disease. That is because it suffers from all the same faults as its predecessors and maybe even more so. Gene editing has low efficiency in adult animals(yes humans are animals) no matter the technique used. For instance, if you have a disease that affects the brain you can probably only modify &lt;1% of cells even using the best delivery techniques available.&nbsp;Really, the only way to get rid of genetically inherited diseases using gene editing is by modifying embryos.&nbsp;</span></p><p dir="ltr"><span>Misleading as it has been CRISPR can’t actually make specific changes to a gene easily in an adult animal. That is because it requires what is called a donor template, basically just a DNA template that cells can use to create the genome modifications. There is no efficient way to use donor templates in an adult animal so all genome edits would need to be gene knock-outs only i.e. you can only use CRISPR to destroy bad genes not modify them to make them good genes. As you can imagine this is very limited in scope when it comes to diseases that can and should be reasonably targeted using genome editing.</span></p><p dir="ltr"><span>To date all human clinical trials involve gene editing technology whether CRISPR or otherwise have failed to show any change in the disease condition. I don’t see this as likely to change. While there might be a disease that can be helped despite the low efficiency of CRISPR chances are that normal gene therapy, that doesn’t edit the genome, will be easier and more successful. There are very few diseases that would require genome editing as opposed to just adding an extra copy of the gene to cells like gene therapy does. It’s not all just conjecture either, just recently in August 2020 the pharma giant Abbvie ended a partnership it had with Editas, one of the major CRISPR players. Apparently, I’m not the only one who sees CRISPR's future in the clinic as limited.</span></p><p dir="ltr"><span>So what applications are left for CRISPR besides contributing to research? Some people are betting on diagnostics, using CRISPR’s ability to target specific sequences of DNA. While this seems reasonable it is unlikely that tried and true methods for DNA detection that use PCR will ever be significantly deplatformed. After that we are scraping the bottom of the bowl of guac.</span></p><p dir="ltr"><span>I have been around CRISPR since near the beginning. The only thing that has remained constant is the hype. Even that has been fading. While it is hard to measure hype Google Trends indicates that for 2020 the topic and search term CRISPR is on track to be the lowest searched since 2016. We now know that CRISPR gene drives don’t really work. No success for CRISPR in the clinic. CRISPR has already been used to edit human embryos. Really, the only thing keeping CRISPR hype alive is probably the MIT Tech Review. </span><span><br></span><span><br></span><span>In 2006, RNAi gene silencing was given the Nobel Prize. MIT called it the </span><a href="https://news.mit.edu/2003/rnai-0108"><span>breakthrough of the decade</span></a><span>. I remember everyone being so excited about it! It was the hot topic at conferences and even my graduate school interviews. While RNAi was and always has been a great benefit to researchers its actual application has been extremely limited. It’s taken 13 years from the RNAi Nobel Prize to bring something to the clinic and even then the two drugs have been a bit underwhelming. According to Google Scholar, papers even mentioning RNAi have been on the decline for the past 6 years. The drug approved in the past few years haven't even slowed the decline.</span></p><p dir="ltr"><span>I am sure people will continue to use CRISPR for years to come but I hate to break it to you CRISPR is dead.</span></p><br></span></p>
</div></div>]]>
            </description>
            <link>http://www.josiahzayner.com/2020/10/crispr-is-dead.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25096386</guid>
            <pubDate>Sat, 14 Nov 2020 22:46:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Twitter can't agree on a simple math equation]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 11 (<a href="https://news.ycombinator.com/item?id=25096096">thread link</a>) | @chrisfosterelli
<br/>
November 14, 2020 | https://fosterelli.co/why-twitter-cant-agree-on-a-simple-math-equation | <a href="https://web.archive.org/web/*/https://fosterelli.co/why-twitter-cant-agree-on-a-simple-math-equation">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="divbodyholder">  <div id="divbody"> <div> <h3> Why Twitter can't agree on a simple math equation </h3> <p> November 14, 2020 — Chris Foster </p> <p>I cam across this tweet this morning, followed by the replies of approximately 9.7 thousand people arguing over what the correct answer actually is.</p> <!-- Content Breaker --> <blockquote width="400"><p lang="en" dir="ltr">how smart are my oomfs <a href="https://t.co/YVxtzhNx4c">pic.twitter.com/YVxtzhNx4c</a></p>— dev ᴺᴹ ᴬᴳ (@iambuterastann) <a href="https://twitter.com/iambuterastann/status/1327101241390886915?ref_src=twsrc%5Etfw">November 13, 2020</a></blockquote>  <p>The complete and total conviction in the replies is notable. I’ve seen the same thing on Facebook and I often get caught up with the verocity that people argue with each other. The trick is usually the same, but in this specific case users come mostly to two answers: \(1\) and \(9\). Which is right? The answer is that they <strong>both are</strong>! Read on for why.</p>  <p>As mentioned, there are roughly two categories of answers: \(1\) and \(9\). There’s also some weird ones, like \(0\) being another common one, but these are primarily arithmetic mistakes. First, let’s focus on how someone would arrive at \(9\).</p> <p>Remember PEMDAS? You may have also learned it as BEDMAS. This is a rule taught that helps you remember the order of operations for algebraic notation. We follow this order: <strong>P</strong>arentheses, <strong>e</strong>xponents, <strong>m</strong>ultiplication / <strong>d</strong>ivision, and then <strong>a</strong>ddition / <strong>s</strong>ubtraction. You do each of these steps from left to right. Note that multiplication / division as well as addition / subtraction happen at the same time, rather than multiplication <em>followed by</em> division for example (ironically that leads to a valid answer for invalid reasons and further fuels argument).</p> <p>If you strictly follow PEMDAS you get this result:</p><p> \[6 \div 2(1 + 2) \\ 6 \div 2(3) \\ 6 \div 2 \times 3 \\ 9\] </p><p>Did you see what happened in that second step? Let’s re-look:</p><p> \[6 \div 2(3) \\ 6 \div 2 \times 3\] </p><p>Keep that in mind as we look at what the second category of users, those who concluded the answer is \(1\), are doing:</p><p> \[6 \div 2(1 + 2)\\ 6 \div 2(3)\\ 6 \div 6\\ 1\] </p><p>Did you see the difference? Users who conclude \(1\) multiplied \(2\) and \(3\) together <strong>before</strong> evaluating the multiplication and division left-to-right. You might think “that’s not following PEMDAS!” and you would be right. So why are they doing this?</p> <p>The notation \(2(3)\) can be called an <em><a href="https://www.themathdoctors.org/order-of-operations-implicit-multiplication/">implicit multiplication by juxtaposition</a></em>. It’s <em>implicit</em> because there is no actual multiplication symbol, and it’s understood to be multiplication with the brackets because it’s <em>juxtaposed</em> (“close to”) with them.</p> <p>In some notations it is a common convention to treat these implied multiplications as <em>higher priority</em> than other multiplications. For example you might see authors write things like \(\frac{x}{2(3x + y)}\) as \(x \div 2(3x + y)\), which is different than \(x \div 2 \times (3x + y)\).</p>  <p>So who is correct? A math expression must have only one real answer right? The point of math is it is supposed to be true and inarguable, right?</p> <p>That’s all fair, but “math” is different than “math notation”. Mathematics models real relationships in our physical world, but the things we write down are just an agreed upon language for communicating it.</p> <p>For example, if there is a four legged creature with a cute nose right in front of me:</p> <p><img src="https://fosterelli.co/image/why-twitter-cant-agree-on-a-simple-math-equation/dog.jpg" alt="A cute dog doing some math"></p> <p>and I tell you that I see <em>a dog</em>, you know what I mean. But if I only spoke Spanish and I called it <em>un perro</em>, you may not know what I meant. That doesn’t change the inarguable fact that there is a furry four legged creature in front of me, but you might only understand what I’m trying to communicate if we’re speaking the same notation.</p> <p>There’s lots of examples of this in math. Take something as simple as \(\times\). It should always mean multiplication right? Well, in vector algebra, everyone agreed that \(\times\) actually means something called the <em><a href="https://en.wikipedia.org/wiki/Cross_product#Definition">cross product</a></em> of two vectors, denoted by the formula \(a \times b = \left\| a \right\| \left\| b \right\| \sin(\theta) n\) or to demonstrate visually:</p> <p><img src="https://fosterelli.co/image/why-twitter-cant-agree-on-a-simple-math-equation/vector.png" alt="A visual example of the cross product"></p> <p>There is some overlapping intuition, but this obviously looks and feels nothing like arithmetic multiplication, which is a series of repeated additions. However that’s what we decided to use \(\times\) for when talking about vectors. There are many examples of overlapping notation in math. As long as we agree and can communicate mathematical ideas, the notation isn’t really important.</p> <p>So what users really disagree about is <em>how to read this equation</em>. Does the author who wrote this equation mean \(6 \div 2 \times (1 + 2)\) or do they mean \(6 \div (2 \times (1 + 2))\)? If this was in a textbook, or part of a larger series of equations, it would be clear from the context. With only this single equation to go on, it’s actually unclear what the author intended. Both interpretations are valid.</p>  <p>Of course the vagueness is deliberate in this case. It gets everyone on social media riled up as they think <em>obviously</em> their understanding is correct and <em>obviously</em> the other person is wrong. <em>Didn’t they take 5th grade math?!</em> But really – both groups are making reasonable interpretations and the equation itself is poorly written. If you were to give someone an equation with no other context at all, you should <em>always</em> use appropriate brackets to make it clear what you are communicating.</p> <p>For more fun, you can see that even calculators themselves will differ on how to interpret this question. Some calculators process input left-to-right, some follow PEMDAS, and others will follow PEMDAS while giving implicit multiplication by juxtaposition a higher priority.</p> <blockquote data-conversation="none" width="400"><p lang="en" dir="ltr">Different calculators give different answers - it depends on the choices made by the people making them. In the last pic it automatically added parentheses when giving the answer, it’s just down to convention chosen: <a href="https://t.co/DB9J9j2zTx">pic.twitter.com/DB9J9j2zTx</a></p>— Dave (@DavePunFun) <a href="https://twitter.com/DavePunFun/status/1327327770750271488?ref_src=twsrc%5Etfw">November 13, 2020</a></blockquote>  <p>The real solution is to make this a more official rule that standard education teaches. Right now this is something that students in later education mostly learn by convention – which leads to a lot of confusion when people clearly interpret it differently but have a hard time explaining <em>why</em>. Textbooks can also be awful as they might explain PEMDAS and then give the implicit multiplication priority with no explicit mention of how that works.</p> <p>Anyway, I see something similar on Facebook, Instagram, or Twitter every few months and I thought it was worth writing up a beginner-friendly explanation that I can reference later. Hopefully it was helpful to you too!</p>  </div>  </div> </div></div>]]>
            </description>
            <link>https://fosterelli.co/why-twitter-cant-agree-on-a-simple-math-equation</link>
            <guid isPermaLink="false">hacker-news-small-sites-25096096</guid>
            <pubDate>Sat, 14 Nov 2020 22:07:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Idris, a language that will change the way you think about programming]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25096063">thread link</a>) | @friendly_chap
<br/>
November 14, 2020 | https://crufter.com/idris-a-language-that-will-change-the-way-you-think-about-programming | <a href="https://web.archive.org/web/*/https://crufter.com/idris-a-language-that-will-change-the-way-you-think-about-programming">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <p>Most programming languages barely differ from each other apart from superficial syntax differences, but not Idris. Idris, having a type system supporting dependent types and other innovative ideas, opens up a host of possibilities few other language provides.</p>

<p>When we want to ensure that a piece of code works as intended the usual tool we use is testing. Testing provides plenty of benefits, but wouldn’t you prefer to encode your tests right in the type signature and let the compiler decide if your code is correct given those constraints? With Idris you can do exactly that.</p>

<p>Let’s investigate how by comparing a very simple list operation, append, also called (++) in Haskell and Idris. Append in Haskell has the following type signature:</p>

<figure><pre><code data-lang="haskell"><span>Prelude</span><span>&gt;</span> <span>:</span><span>t</span> <span>(</span><span>++</span><span>)</span>
<span>(</span><span>++</span><span>)</span> <span>::</span> <span>[</span><span>a</span><span>]</span> <span>-&gt;</span> <span>[</span><span>a</span><span>]</span> <span>-&gt;</span> <span>[</span><span>a</span><span>]</span></code></pre></figure>

<p>Sharing most of the syntax and lot of the type system with Haskell, the append for lists looks very similar in Idris:</p>

<figure><pre><code data-lang="haskell"><span>Idris</span><span>&gt;</span> <span>:</span><span>t</span> <span>(</span><span>++</span><span>)</span>
<span>Prelude</span><span>.</span><span>List</span><span>.</span><span>(</span><span>++</span><span>)</span> <span>:</span> <span>List</span> <span>a</span> <span>-&gt;</span> <span>List</span> <span>a</span> <span>-&gt;</span> <span>List</span> <span>a</span>
<span>Prelude</span><span>.</span><span>Strings</span><span>.</span><span>(</span><span>++</span><span>)</span> <span>:</span> <span>String</span> <span>-&gt;</span> <span>String</span> <span>-&gt;</span> <span>String</span>
<span>Prelude</span><span>.</span><span>Vect</span><span>.</span><span>(</span><span>++</span><span>)</span> <span>:</span> <span>Vect</span> <span>m</span> <span>a</span> <span>-&gt;</span> <span>Vect</span> <span>n</span> <span>a</span> <span>-&gt;</span> <span>Vect</span> <span>(</span><span>m</span> <span>+</span> <span>n</span><span>)</span> <span>a</span></code></pre></figure>

<p>When we have a look at the Prelude.List.(++), we can see that it matches the Haskell version - it tells us that it takes two lists and returns a third one - it doesn’t say a single word about the lengths of those lists. But if we look at append for the Prelude.Vect type (vectors are a kind of lists with a size), we see the signature describing the size of the vector:</p>

<figure><pre><code data-lang="haskell"><span>Prelude</span><span>.</span><span>Vect</span><span>.</span><span>(</span><span>++</span><span>)</span> <span>:</span> <span>Vect</span> <span>m</span> <span>a</span> <span>-&gt;</span> <span>Vect</span> <span>n</span> <span>a</span> <span>-&gt;</span> <span>Vect</span> <span>(</span><span>m</span> <span>+</span> <span>n</span><span>)</span> <span>a</span></code></pre></figure>

<p>In dependent type terminology a vector is a list indexed over its length, or in laymen’s terms the type of a vector is a list with a size. This is remotely similar to the concept of fixed sized arrays, (for example, in Go) a [4]int is not the same type as a [5]int. However in Idris, we can not only describe that those lists have different type, but as we can see above we can also express how a given property - in this case the length of a list - changes as a result of a function. As <a href="http://en.wikipedia.org/wiki/Formal_verification">Wikipedia succintly states</a>:</p>

<blockquote>
  <p>A promising type-based verification approach is dependently typed programming, in which the types of functions include (at least part of) those functions’ specifications, and type-checking the code establishes its correctness against those specifications.</p>
</blockquote>

<p>To understand the importance of this it is not enough to inspect the the above functions’ type signature. What meets the eye there could be considered documentation. But the real epiphany comes when we start to implement a function after specifying its signature. Let’s examine the source code of <a href="https://github.com/idris-lang/Idris-dev/blob/43127b17a765dbab2e7bcb6be2f6f2efc7a42386/libs/base/Data/VectType.idr#L181">append</a>:</p>

<figure><pre><code data-lang="haskell"><span>|||</span> <span>Append</span> <span>two</span> <span>vectors</span>
<span>(</span><span>++</span><span>)</span> <span>:</span> <span>Vect</span> <span>m</span> <span>a</span> <span>-&gt;</span> <span>Vect</span> <span>n</span> <span>a</span> <span>-&gt;</span> <span>Vect</span> <span>(</span><span>m</span> <span>+</span> <span>n</span><span>)</span> <span>a</span>
<span>(</span><span>++</span><span>)</span> <span>[]</span>      <span>ys</span> <span>=</span> <span>ys</span>
<span>(</span><span>++</span><span>)</span> <span>(</span><span>x</span><span>::</span><span>xs</span><span>)</span> <span>ys</span> <span>=</span> <span>x</span> <span>::</span> <span>xs</span> <span>++</span> <span>ys</span></code></pre></figure>

<p>But what happens if we intentionally brake the implementation, for example by appending the first argument to itself and ignoring the second argument entirely? The resulting Vector will have a length of <b>m + m</b>, which is clearly different than the <b>m + n</b> stated in the signature.</p>

<figure><pre><code data-lang="haskell"><span>import</span> <span>Data.Vect</span>

<span>vapp</span> <span>:</span> <span>Vect</span> <span>n</span> <span>a</span> <span>-&gt;</span> <span>Vect</span> <span>m</span> <span>a</span> <span>-&gt;</span> <span>Vect</span> <span>(</span><span>n</span> <span>+</span> <span>m</span><span>)</span> <span>a</span>
<span>vapp</span> <span>Nil</span>       <span>ys</span> <span>=</span> <span>ys</span>
<span>vapp</span> <span>(</span><span>x</span> <span>::</span> <span>xs</span><span>)</span> <span>ys</span> <span>=</span> <span>x</span> <span>::</span> <span>vapp</span> <span>xs</span> <span>xs</span></code></pre></figure>

<p>(<a href="https://github.com/idris-lang/Idris-dev/blob/43127b17a765dbab2e7bcb6be2f6f2efc7a42386/test/tutorial006/tutorial006a.idr">link</a>)</p>

<p>The compiler tells exactly what we suspected:</p>

<figure><pre><code data-lang="haskell"><span>Type</span> <span>checking</span> <span>./</span><span>vapp</span><span>.</span><span>idr</span>
<span>vapp</span><span>.</span><span>idr</span><span>:</span><span>5</span><span>:</span><span>23</span><span>:</span><span>When</span> <span>elaborating</span> <span>right</span> <span>hand</span> <span>side</span> <span>of</span> <span>vapp</span><span>:</span>
<span>When</span> <span>elaborating</span> <span>argument</span> <span>xs</span> <span>to</span> <span>constructor</span> <span>Prelude</span><span>.</span><span>Vect</span><span>.:::</span>
        <span>Can't</span> <span>unify</span>
                <span>Vect</span> <span>(</span><span>n</span> <span>+</span> <span>n</span><span>)</span> <span>a</span>
        <span>with</span>
                <span>Vect</span> <span>(</span><span>plus</span> <span>n</span> <span>m</span><span>)</span> <span>a</span>
        
        <span>Specifically</span><span>:</span>
                <span>Can't</span> <span>unify</span>
                        <span>plus</span> <span>n</span> <span>n</span>
                <span>with</span>
                        <span>plus</span> <span>n</span> <span>m</span>
<span>Metavariables</span><span>:</span> <span>Main</span><span>.</span><span>vapp</span></code></pre></figure>

<p>The above example shows an interesting quality of Idris’ type system: the correctness of the code is checked against any specification in the functions’ type. If the implementation does not meet the specification a compile error is triggered. Naturally, any property not described by those specifications will not interest the compiler. Let’s say we implement our ‘vapp’ function the following way:</p>

<figure><pre><code data-lang="haskell"><span>vapp1</span> <span>:</span> <span>Vect</span> <span>n</span> <span>a</span> <span>-&gt;</span> <span>Vect</span> <span>m</span> <span>a</span> <span>-&gt;</span> <span>Vect</span> <span>(</span><span>n</span> <span>+</span> <span>m</span><span>)</span> <span>a</span>
<span>vapp1</span> <span>Nil</span>               <span>ys</span> <span>=</span> <span>ys</span>
<span>vapp1</span> <span>(</span><span>x</span> <span>::</span> <span>x'</span> <span>::</span> <span>xs</span><span>)</span>   <span>ys</span> <span>=</span> <span>x</span> <span>::</span> <span>x</span> <span>::</span> <span>vapp</span> <span>xs</span> <span>ys</span>
<span>vapp1</span> <span>(</span><span>x</span> <span>::</span> <span>xs</span><span>)</span>         <span>ys</span> <span>=</span> <span>x</span> <span>::</span> <span>vapp</span> <span>xs</span> <span>ys</span></code></pre></figure>

<p>This compiling program almost works perfectly but it does have a quirk; the first element from the first argument is present twice, once on the 1st position correctly, and on the second position incorrectly, deleting the second element:</p>

<figure><pre><code data-lang="haskell"><span>*</span><span>vapp</span><span>&gt;</span> <span>vapp1</span> <span>[</span><span>1</span><span>,</span><span>2</span><span>,</span><span>3</span><span>]</span> <span>[</span><span>4</span><span>,</span><span>5</span><span>,</span><span>6</span><span>]</span>
<span>[</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>3</span><span>,</span> <span>4</span><span>,</span> <span>5</span><span>,</span> <span>6</span><span>]</span> <span>:</span> <span>Vect</span> <span>6</span> <span>Integer</span></code></pre></figure>

<p>So we have proved that whatever is stated in the type signature is guaranteed to be correct - but nothing else may be. In our append example we state that ‘given vector a and vector b, calling append with those vectors as arguments will yield a vector with a length of length a + length b’. It does not state that the resulting vector will contain any element from the argument vectors, or if the order is preserved or anything else! But this is pretty obvious since how could the compiler decide wether a code is correct or not if we do not tell it the criteria to judge a piece of code by. Mind reading based programming is not invented yet, unfortunately.</p>

<p>To say the least, dependent types have the potential to become a new useful tool in a programmer’s toolbox - and there is a certain idealistic beauty in building on top of formally verified, guaranteed to be correct code.</p>

<p>Idris version used to compile code snippet(s):</p>

<figure><pre><code data-lang="haskell"><span>$</span> <span>idris</span> <span>-</span><span>v</span>
<span>0.9</span><span>.</span><span>14.2</span><span>-</span><span>git</span><span>:</span><span>45</span><span>de9ab</span></code></pre></figure>

<h3 id="appendix">Appendix</h3>

<ul>
  <li><a href="https://news.ycombinator.com/item?id=10850205">HN thread</a></li>
  <li><a href="https://www.reddit.com/r/programming/comments/3y77ss/meet_idris_a_language_that_will_change_the_way/">r/programming Reddit thread</a></li>
</ul>

            </div></div>]]>
            </description>
            <link>https://crufter.com/idris-a-language-that-will-change-the-way-you-think-about-programming</link>
            <guid isPermaLink="false">hacker-news-small-sites-25096063</guid>
            <pubDate>Sat, 14 Nov 2020 22:03:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Quebec to ban sale of new gas-powered vehicles as of 2035]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25095735">thread link</a>) | @reddotX
<br/>
November 14, 2020 | https://www.cbc.ca/news/canada/montreal/gas-vehicles-ban-electric-quebec-1.5802374 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/canada/montreal/gas-vehicles-ban-electric-quebec-1.5802374">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>The Quebec government will unveil its green economy plan on Monday. A ban on the sale of new gas-powered vehicles as of 2035 is expected to be a major part of it.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.3845473.1605373566!/cpImage/httpImage/image.jpg_gen/derivatives/16x9_780/electric-cars-20100914.jpg"></p></div><figcaption>The province is set to announce a ban on the sale of new, personal-use, gas-powered vehicles that would take effect in 2035.<!-- --> <!-- -->(Jonathan Hayward/Canadian Press)</figcaption></figure><p><span><p>A&nbsp;ban on&nbsp;the sale of new gas-powered vehicles in Quebec as of 2035 stands to be&nbsp;the flagship&nbsp;measure of&nbsp;the Legault government's&nbsp;green economy plan.</p>  <p>The&nbsp;plan, set to be unveiled on Monday, is expected to&nbsp;bank heavily on the electrification of vehicles, which will make&nbsp;up a large portion&nbsp;of the province's&nbsp;$6.7 billion-investment over the next five&nbsp;years to deal with climate change.</p>  <p>Size won't matter, as the ban will target small cars, SUVs, vans&nbsp;and pick-up trucks that are for personal use.</p>  <p>And according to <em>La Presse</em>, which first reported details of the plan, vehicles used for commercial and industrial purposes will be exempt.</p>  <p>The sale of second-hand&nbsp;gas-powered&nbsp;vehicles will still be allowed beyond 2035.</p>  <p>Less than two per cent of the cars and trucks on Quebec's roads are electric or hybrid vehicles, but the government appears confident it can quickly reverse this trend with its ban and by establishing sales quotas for car dealerships to make sure they have enough inventory of electric-powered vehicles.</p>    <p>For now, the government will maintain its Roulez Vert program, a tax rebate for&nbsp;electric cars, but the popular program that provides $8,000 per purchase could be reduced given its&nbsp;current annual cost&nbsp;— $260 million.&nbsp;</p>  <p>As part of the government's plan, the installation of roadside charging stations would also be sped up.</p>  <p>Quebec would not be the only Canadian province&nbsp;with a ban on gas-powered vehicles, as B.C. passed a law last year to ban the sale of gas-powered vehicles by 2040.</p>  <p>Similar bans will take effect in California in 2035, and in Sweden in 2030.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5802527.1605385229!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/dany-lemelin-mitsubishi-dealership.jpg 300w,https://i.cbc.ca/1.5802527.1605385229!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/dany-lemelin-mitsubishi-dealership.jpg 460w,https://i.cbc.ca/1.5802527.1605385229!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/dany-lemelin-mitsubishi-dealership.jpg 620w,https://i.cbc.ca/1.5802527.1605385229!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/dany-lemelin-mitsubishi-dealership.jpg 780w,https://i.cbc.ca/1.5802527.1605385229!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/dany-lemelin-mitsubishi-dealership.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5802527.1605385229!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/dany-lemelin-mitsubishi-dealership.jpg"></p></div><figcaption>Dany Lemelin, owner of the Boucherville Mitsubishi dealership on Montreal's South Shore, applauds the province's goal but is not yet convinced it's a realistic one. <!-- --> <!-- -->(CBC)</figcaption></figure></span></p>  <h2>It's in the car manufacturers' hands, says dealership owner</h2>  <p>Dany Lemelin, who owns a&nbsp;Mitsubishi dealership in Boucherville, on Montreal's South Shore, applauded the province's objective, but stressed the need for manufacturers to supply enough electric vehicles over the next 15 years in order to make it a reality.</p>  <p>"We all want to shift toward&nbsp;vehicles that are more eco-friendly," Lemelin said. "But on the other hand, there's also a question of feasibility and car manufacturers have to be build enough vehicles."</p>  <p>He said California's decision to ban gas-powered vehicles helps in that regard, given the size of its car market.</p>  <p>Lemelin also believes the province should preserve its subsidy for electric cars.</p>  <p>"Quebec accounts for 50 per cent of all Canadian sales," he said. "That's not a coincidence, I think the rebate helps a lot."</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/canada/montreal/gas-vehicles-ban-electric-quebec-1.5802374</link>
            <guid isPermaLink="false">hacker-news-small-sites-25095735</guid>
            <pubDate>Sat, 14 Nov 2020 21:20:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Interactive Introduction to Fourier Transforms]]>
            </title>
            <description>
<![CDATA[
Score 405 | Comments 50 (<a href="https://news.ycombinator.com/item?id=25095724">thread link</a>) | @bpierre
<br/>
November 14, 2020 | http://www.jezzamon.com/fourier/index.html | <a href="https://web.archive.org/web/*/http://www.jezzamon.com/fourier/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
	<p>Fourier transforms are a tool used in a whole bunch of different things. This is an explanation of what a Fourier transform does, and some different ways it can be useful. And how you can make pretty things with it, like this thing:</p>
<canvas id="self-draw" width="500" height="500"></canvas>
<p>I'm going to explain how that animation works, and along the way explain Fourier transforms!</p>
<p>By the end you should have a good idea about</p>
<ul>
<li>What a Fourier transform does</li>
<li>Some practical uses of Fourier transforms</li>
<li>Some pointless but cool uses of Fourier transforms</li>
</ul>
<p>We're going to leave the mathematics and equations out of it for now. There's a bunch of interesting maths behind it, but it's better to start with what it actually does, and why you'd want to use it first. If you want to know more about the how, there's some further reading suggestions below!</p>
<h2 id="sowhatisthisthing">So what is this thing?</h2>
<p>Put simply, the Fourier transform is a way of splitting something up into a bunch of sine waves. As usual, the name comes from some person who lived a long time ago called Fourier.</p>
<p>Let’s start with some simple examples and work our way up. First up we're going to look at waves - patterns that repeat over time.</p>
<p>Here’s an example wave:</p>
<canvas id="combo-sine-wave" width="500" height="300"></canvas>
<p>This wavy pattern here can be split up into sine waves. That is, when we add up the two sine waves we get back the original wave.</p>
<canvas id="combo-sine-wave-split" width="500" height="500"></canvas>
<p>The Fourier transform is a way for us to take the combined wave, and get each of the sine waves back out. In this example, you can almost do it in your head, just by looking at the original wave.</p>
<p>Why? Turns out a lot of things in the real world interact based on these sine waves. We usually call them the wave's frequencies.</p>
<p>The most obvious example is sound – when we hear a sound, we don’t hear that squiggly line, but we hear the different frequencies of the sine waves that make up the sound.</p>



<p>Being able to split them up on a computer can give us an understanding of what a person actually hears. We can understand how high or low a sound is, or figure out what note it is.</p>
<p>We can also use this process on waves that don't look like they're made of sine waves.</p>
<p>Let's take a look at this guy. It’s called a square wave.</p>
<canvas id="square-wave" width="500" height="300"></canvas>
<p>It might not look like it, but it also can be split up into sine waves.</p>
<canvas id="square-wave-split" width="500" height="500"></canvas>
<p>We need a lot of them this time – technically an infinite amount to perfectly represent it. As we add up more and more sine waves the pattern gets closer and closer to the square wave we started with.</p>
<canvas id="square-wave-build-up" width="500" height="500"></canvas>


<p><em>Drag the slider above to play with how many sine waves there are.</em></p>
<p>Visually, you'll notice that actually the first few sine waves are the ones that make the biggest difference. With the slider halfway, we have the general shape of the wave, but it's all wiggly. We just need the rest of the small ones to make the wigglyness flatten out.</p>
<p>When you listen to the wave, you'll hear the sound get lower, because we're removing the higher frequencies.</p>
<p>This process works like that for any repeating line. Give it a go, try drawing your own!</p>


<p><em>Move the slider to see how as we add more sine waves, it gets closer and closer to your drawing</em></p>
<p>Again, aside from the extra wigglyness, the wave looks pretty similar with just half of the sine waves.</p>
<p>We can actually use the fact that the wave is pretty similar to our advantage. By using a Fourier transform, we can get the important parts of a sound, and only store those to end up with something that's pretty close to the original sound.</p>
<p>Normally on a computer we store a wave as a series of points.</p>
<canvas id="wave-samples" width="500" height="500"></canvas>
<p>What we can do instead is represent it as a bunch of sine waves. Then we can compress the sound by ignoring the smaller frequencies. Our end result won't be the same, but it'll sound pretty similar to a person.</p>
<canvas id="wave-frequencies" width="500" height="500"></canvas>
<p>This is essentially what MP3s do, except they're more clever about which frequencies they keep and which ones they throw away.</p>
<p>So in this case, we can use Fourier transforms to get an understanding of the fundamental properties of a wave, and then we can use that for things like compression.</p>
<p>Ok, now let's dig more into the Fourier transform. This next part looks cool, but also gives you a bit more understanding of what the Fourier transform does. But mostly looks cool.</p>
<h2 id="epicycles">Epicycles</h2>
<p>Now at the start, I said it splits things into sine waves. The thing is, the sine waves it creates are not just regular sine waves, but they’re 3D. You could call them "complex sinusoids". Or just "spirals".</p>
<canvas id="complex-sinusoid" width="500" height="500"></canvas>
<p>If we take a look from the side, they look like sine waves. From front on, though, these look like circles.</p>
<canvas id="complex-sinusoid-turn" width="500" height="500"></canvas>
<p>So far everything we’ve been doing has only required the regular 2D sine waves. When we do a Fourier transform on 2D waves, the complex parts cancel out so we just end up with sine waves.</p>
<p>But we can use the 3D sine waves to make something fun looking like this:</p>
<canvas id="peace-epicycles" width="500" height="500"></canvas>
<p>What’s going on here?</p>
<p>Well, we can think of the drawing as a 3D shape because of the way it moves around in time. If you imagine the hand being drawn by a person, the three dimensions represent where the tip of their pencil is at that moment. The x and y dimensions tell us the position, and then the time dimension is the time at that moment.</p>
<canvas id="peace-3d" width="500" height="500"></canvas>
<p>Now that we have a 3D pattern, we can't use the regular 2D sine waves to represent it. No matter how many of the 2D sine waves we add up, we'll never get something 3D. So we need something else.</p>
<p>What we can use is the 3D spiral sine waves from before. If we add up lots of those, we can get something that looks like our 3D pattern.</p>
<p>Remember, these waves look like circles when we look at them from front on. The name for the pattern of a circle moving around another circle is an epicycle.</p>
<canvas id="peace-build-up" width="500" height="500"></canvas>

<p><em>Use the slider above to control how many circles there are.</em></p>
<p>Like before, we get a pretty good approximation of our pattern with just a few circles. Because this is a fairly simple shape, all the last ones do is make the edges a little sharper.</p>
<p>All this applies to any drawing, really! Now it’s your chance to play around with it.</p>


<p><em>Use the slider to control how many circles are used for your drawing</em></p>
<p>Again, you'll see for most shapes, we can approximate them fairly well with just a small number of circles, instead of saving all the points.</p>
<p>Can we use this for real data? Well, we could! In reality we have another data format called SVG, which probably does a better job for the types of shapes we tend to create. So for the moment, this is really just for making cool little gifs.</p>
<canvas id="fourier-title" width="500" height="300"></canvas>
<p>There is another type of visual data that does use Fourier transforms, however.</p>
<h2 id="jpegs">JPEGs</h2>
<p>Did you know Fourier transforms can also be used on images? In fact, we use it all the time, because that's how JPEGs work! We're applying the same principles to images – splitting up something into a bunch of sine waves, and then only storing the important ones.</p>
<p>Now we're dealing with images, we need a different type of sine wave. We need to have something that no matter what image we have, we can add up a bunch of these sine waves to get back to our original image.</p>
<p>To do that, each of our sine waves will be images too. Instead of a wave that's a line, we now have images with black and white sections. To represent the size of a wave, each image will have more or less contrast.</p>
<p>We can also use these to represent color in the same way, but let's start with black-and-white images for now. To represent colorless images, we need some horizontal wave images,</p>
<p><img id="img-y-component" src="http://www.jezzamon.com/fourier/img/components-4-0.png"></p>
<p>Along with some vertical wave images.</p>
<p><img id="img-x-component" src="http://www.jezzamon.com/fourier/img/components-0-4.png"></p>
<p>By themselves, just horizontal and vertical images aren't enough to represent the types of images we get. We also need some extra ones that you get by multiplying the two together.</p>

<p>For an 8x8 image, here are all the images we need.</p>
<p><img src="http://www.jezzamon.com/fourier/img/components-0-0.png">
    <img src="http://www.jezzamon.com/fourier/img/components-0-1.png">
    <img src="http://www.jezzamon.com/fourier/img/components-0-2.png">
    <img src="http://www.jezzamon.com/fourier/img/components-0-3.png">
    <img src="http://www.jezzamon.com/fourier/img/components-0-4.png">
    <img src="http://www.jezzamon.com/fourier/img/components-0-5.png">
    <img src="http://www.jezzamon.com/fourier/img/components-0-6.png">
    <img src="http://www.jezzamon.com/fourier/img/components-0-7.png">
    <img src="http://www.jezzamon.com/fourier/img/components-1-0.png">
    <img src="http://www.jezzamon.com/fourier/img/components-1-1.png">
    <img src="http://www.jezzamon.com/fourier/img/components-1-2.png">
    <img src="http://www.jezzamon.com/fourier/img/components-1-3.png">
    <img src="http://www.jezzamon.com/fourier/img/components-1-4.png">
    <img src="http://www.jezzamon.com/fourier/img/components-1-5.png">
    <img src="http://www.jezzamon.com/fourier/img/components-1-6.png">
    <img src="http://www.jezzamon.com/fourier/img/components-1-7.png">
    <img src="http://www.jezzamon.com/fourier/img/components-2-0.png">
    <img src="http://www.jezzamon.com/fourier/img/components-2-1.png">
    <img src="http://www.jezzamon.com/fourier/img/components-2-2.png">
    <img src="http://www.jezzamon.com/fourier/img/components-2-3.png">
    <img src="http://www.jezzamon.com/fourier/img/components-2-4.png">
    <img src="http://www.jezzamon.com/fourier/img/components-2-5.png">
    <img src="http://www.jezzamon.com/fourier/img/components-2-6.png">
    <img src="http://www.jezzamon.com/fourier/img/components-2-7.png">
    <img src="http://www.jezzamon.com/fourier/img/components-3-0.png">
    <img src="http://www.jezzamon.com/fourier/img/components-3-1.png">
    <img src="http://www.jezzamon.com/fourier/img/components-3-2.png">
    <img src="http://www.jezzamon.com/fourier/img/components-3-3.png">
    <img src="http://www.jezzamon.com/fourier/img/components-3-4.png">
    <img src="http://www.jezzamon.com/fourier/img/components-3-5.png">
    <img src="http://www.jezzamon.com/fourier/img/components-3-6.png">
    <img src="http://www.jezzamon.com/fourier/img/components-3-7.png">
    <img src="http://www.jezzamon.com/fourier/img/components-4-0.png">
    <img src="http://www.jezzamon.com/fourier/img/components-4-1.png">
    <img src="http://www.jezzamon.com/fourier/img/components-4-2.png">
    <img src="http://www.jezzamon.com/fourier/img/components-4-3.png">
    <img src="http://www.jezzamon.com/fourier/img/components-4-4.png">
    <img src="http://www.jezzamon.com/fourier/img/components-4-5.png">
    <img src="http://www.jezzamon.com/fourier/img/components-4-6.png">
    <img src="http://www.jezzamon.com/fourier/img/components-4-7.png">
    <img src="http://www.jezzamon.com/fourier/img/components-5-0.png">
    <img src="http://www.jezzamon.com/fourier/img/components-5-1.png">
    <img src="http://www.jezzamon.com/fourier/img/components-5-2.png">
    <img src="http://www.jezzamon.com/fourier/img/components-5-3.png">
    <img src="http://www.jezzamon.com/fourier/img/components-5-4.png">
    <img src="http://www.jezzamon.com/fourier/img/components-5-5.png">
    <img src="http://www.jezzamon.com/fourier/img/components-5-6.png">
    <img src="http://www.jezzamon.com/fourier/img/components-5-7.png">
    <img src="http://www.jezzamon.com/fourier/img/components-6-0.png">
    <img src="http://www.jezzamon.com/fourier/img/components-6-1.png">
    <img src="http://www.jezzamon.com/fourier/img/components-6-2.png">
    <img src="http://www.jezzamon.com/fourier/img/components-6-3.png">
    <img src="http://www.jezzamon.com/fourier/img/components-6-4.png">
    <img src="http://www.jezzamon.com/fourier/img/components-6-5.png">
    <img src="http://www.jezzamon.com/fourier/img/components-6-6.png">
    <img src="http://www.jezzamon.com/fourier/img/components-6-7.png">
    <img src="http://www.jezzamon.com/fourier/img/components-7-0.png">
    <img src="http://www.jezzamon.com/fourier/img/components-7-1.png">
    <img src="http://www.jezzamon.com/fourier/img/components-7-2.png">
    <img src="http://www.jezzamon.com/fourier/img/components-7-3.png">
    <img src="http://www.jezzamon.com/fourier/img/components-7-4.png">
    <img src="http://www.jezzamon.com/fourier/img/components-7-5.png">
    <img src="http://www.jezzamon.com/fourier/img/components-7-6.png">
    <img src="http://www.jezzamon.com/fourier/img/components-7-7.png">
</p>
<p>If we take the images, adjust their contrast to the right amount, and then add them up we can create any image.</p>
<p>Let's start with this letter 'A'. It's pretty small, but we need it to be small otherwise we'll end up with too many other images.</p>
<p><img src="http://www.jezzamon.com/fourier/img/a.png"></p>
<p>As we add more and more of these images, we end up with something that becomes closer and closer to the actual image. But I think you'll see the pattern here, as we get a reasonable approximation with just a few of them.</p>
<p><img src="http://www.jezzamon.com/fourier/img/img-buildup-0-0.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-0-1.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-0-2.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-0-3.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-0-4.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-0-5.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-0-6.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-0-7.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-1-0.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-1-1.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-1-2.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-1-3.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-1-4.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-1-5.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-1-6.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-1-7.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-2-0.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-2-1.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-2-2.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-2-3.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-2-4.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-2-5.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-2-6.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-2-7.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-3-0.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-3-1.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-3-2.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-3-3.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-3-4.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-3-5.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-3-6.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-3-7.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-4-0.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-4-1.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-4-2.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-4-3.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-4-4.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-4-5.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-4-6.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-4-7.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-5-0.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-5-1.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-5-2.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-5-3.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-5-4.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-5-5.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-5-6.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-5-7.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-6-0.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-6-1.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-6-2.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-6-3.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-6-4.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-6-5.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-6-6.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-6-7.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-7-0.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-7-1.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-7-2.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-7-3.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-7-4.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-7-5.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-7-6.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-7-7.png">
</p>

<p>For actual JPEG images there are just a few extra details.</p>
<p>The image gets broken up into 8x8 chunks, and each chunk gets split up separately. We use a set of frequencies to determine how light or dark each pixel is, and then another two sets for the color, one for red-green, and another for blue-yellow. The number of frequencies that we use for each chunk determines the quality of the JPEG.</p>
<p>Here's a real JPEG image, zoomed in so we can see the details. When we play with the quality levels we can see this process happen.</p>
<p><img src="http://www.jezzamon.com/fourier/img/cat.png">
</p>
<h2 id="conclusion">Conclusion</h2>
<p>So let's recap:</p>
<ul>
<li>Fourier transforms are things that let us take something and split it up into its frequencies.</li>
<li>The frequencies tell us about some fundamental properties of the data we have</li>
<li>And can compress data by only storing the important frequencies</li>
<li>And we can also use them to make cool looking animations with a bunch of circles</li>
</ul>
<p>This is just scratching the surface into some applications. The Fourier transform is an extremely powerful tool, because splitting things up into frequencies is so fundamental. They're used in a lot of fields, …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.jezzamon.com/fourier/index.html">http://www.jezzamon.com/fourier/index.html</a></em></p>]]>
            </description>
            <link>http://www.jezzamon.com/fourier/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25095724</guid>
            <pubDate>Sat, 14 Nov 2020 21:19:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Global Internet Infrastructure Map]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25095708">thread link</a>) | @postit
<br/>
November 14, 2020 | https://live.infrapedia.com/app | <a href="https://web.archive.org/web/*/https://live.infrapedia.com/app">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://live.infrapedia.com/app</link>
            <guid isPermaLink="false">hacker-news-small-sites-25095708</guid>
            <pubDate>Sat, 14 Nov 2020 21:16:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Does Apple really log every app you run? A technical look]]>
            </title>
            <description>
<![CDATA[
Score 606 | Comments 321 (<a href="https://news.ycombinator.com/item?id=25095438">thread link</a>) | @jacopoj
<br/>
November 14, 2020 | https://blog.jacopo.io/en/post/apple-ocsp/ | <a href="https://web.archive.org/web/*/https://blog.jacopo.io/en/post/apple-ocsp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>Apple’s launch of macOS Big Sur was almost immediately followed by server issues which prevented users from running third-party apps on their computers. While a workaround was soon found by people on Twitter, others raised some privacy concerns related to that issue.</p>
<center><blockquote><div lang="en" dir="ltr"><p>Hey Apple users:</p><p>If you're now experiencing hangs launching apps on the Mac, I figured out the problem using Little Snitch.</p><p>It's trustd connecting to <a href="https://t.co/FzIGwbGRan">https://t.co/FzIGwbGRan</a></p><p>Denying that connection fixes it, because OCSP is a soft failure.</p><p>(Disconnect internet also fixes.) <a href="https://t.co/w9YciFltrb">pic.twitter.com/w9YciFltrb</a></p></div>— Jeff Johnson (@lapcatsoftware) <a href="https://twitter.com/lapcatsoftware/status/1326990296412991489?ref_src=twsrc%5Etfw">November 12, 2020</a></blockquote></center> 
<h2 id="what-is-ocsp">What is OCSP?</h2>
<p>OCSP stands for Online Certificate Status Protocol<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>. As the name implies, it is used to verify the validity of a certificate without having to download and scan large certificate revocation lists. macOS uses OCSP to make sure that the developer certificate <strong>hasn’t been revoked</strong> before an app is launched.</p>
<p>As Jeff Johnson explains in his tweet above, if macOS cannot reach Apple’s OCSP responder it skips the check and launches the app anyway - it is basically a fail-open behaviour. The problem is that Apple’s responder didn’t go down; it was reachable but became extremely slow, and this prevented the soft failure from triggering and giving up the check.</p>
<p>It is clear that this mechanism requires macOS to <strong>contact Apple</strong> before an app is launched. The sudden public awareness of this fact, brought about by Apple’s issues, raised some privacy concerns and a post from security researcher <strong>Jeffrey Paul</strong><sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup> became very popular on Twitter. He claims that</p>
<blockquote>
<p>In the current version of the macOS, the OS sends to Apple a hash (unique identifier) of each and every program you run, when you run it.</p>
</blockquote>
<p>That would be creepy indeed.</p>
<p>To make things worse, it is common for OCSP to use HTTP - I’m talking about <em>good old <strong>plaintext HTTP</strong> on port 80, none of that HTTPS rubbish</em>. There is usually a good reason for this, that becomes especially clear when the OCSP service is used for web browsers: preventing loops. If you used HTTPS for checking a certificate with OCSP then you would need to also check the certificate for the HTTPS connection using OCSP. That would imply opening another HTTPS connection and so on.</p>
<p>Of course while OCSP does not mandate encryption, it does require that responses are signed by the server. This still doesn’t solve the initial concern that anyone with a traffic analyzer on your network could eavesdrop every app you open and when you open it.</p>
<h2 id="diving-deeper">Diving deeper</h2>
<p>Knowing some OCSP basics, more questions arise. OCSP is about checking certificates; why should this have anything to do with sending out <em><strong>hashes</strong></em> of apps you run? Does macOS really compute the hash of each executable at each launch? What about very large ones? That would take a significant amount of time; is it possible that nobody noticed? Maybe the hash is computed only once (e.g. the first time you run the app) and it is stored somewhere. But I’m not convinced and I think these claims needs more research.</p>
<p>Capturing a OCSP request is as easy as setting up an HTTP proxy or starting Wireshark. No HTTPS means no encryption, no certificate pinning, no problems whatsoever. I captured the following request while opening Firefox.</p>
<div><pre><code data-lang="http"><span>GET</span> <span>/ocsp-devid01/ME4wTKADAgEAMEUwQzBBMAkGBSsOAwIaBQAEFDOB0e%2FbaLCFIU0u76%2BMSmlkPCpsBBRXF%2B2iz9x8mKEQ4Py%2Bhy0s8uMXVAIIBseUIWx6qTA%3D</span> <span>HTTP</span><span>/</span><span>1.1</span>
<span>Host</span><span>:</span> <span>ocsp.apple.com</span>
<span>Accept</span><span>:</span> <span>*/*</span>
<span>User-Agent</span><span>:</span> <span>com.apple.trustd/2.0</span>
<span>Accept-Language</span><span>:</span> <span>it-it</span>
<span>Accept-Encoding</span><span>:</span> <span>gzip, deflate</span>
<span>Connection</span><span>:</span> <span>keep-alive</span>
</code></pre></div><p>I should also add that after closing Firefox and opening it again, no requests were made. This is reasonable, and indicates that certificate checking isn’t performed at each launch but only after it hasn’t been performed for a certain period of time.</p>
<p>The request is a very simple GET that contains the payload as a base64-encoded string. The actual binary data can be easily dumped to a file:</p>
<div><pre><code data-lang="bash"><span>echo</span> <span>'ME4wTKADAgEAMEUwQzBBMAkGBSsOAwIaBQAEFDOB0e/baLCFIU0u76+MSmlkPCpsBBRXF+2iz9x8mKEQ4Py+hy0s8uMXVAIIBseUIWx6qTA='</span> <span>|</span> base64 --decode &gt; output.bin
</code></pre></div><p>We obtain an 80-byte-long payload that looks nothing like a hash. Sure enough, it isn’t. We can use OpenSSL to extract readable information from the binary file.</p>
<div><pre><code data-lang="bash">openssl ocsp -text -reqin output.bin
</code></pre></div><pre><code>OCSP Request Data:
    Version: 1 (0x0)
    Requestor List:
        Certificate ID:
          Hash Algorithm: sha1
          Issuer Name Hash: 3381D1EFDB68B085214D2EEFAF8C4A69643C2A6C
          Issuer Key Hash: 5717EDA2CFDC7C98A110E0FCBE872D2CF2E31754
          Serial Number: 06C794216C7AA930
</code></pre><p>It is clear that the <code>trustd</code> service on macOS doesn’t send out a hash of the apps you launch. Instead, it just sends information about some certificate - as we would certainly expect after understanding what OCSP is in the first place.</p>
<p>Well, this does not solve the problem, does it? If each app has a unique certificate, then it would still be possible to create a table that associates each serial number to the corresponding app, and thus this would still be a privacy concern. Let’s check if this is the case.</p>
<h2 id="developer-certificates">Developer certificates…</h2>
<p>First of all I would like to determine from which certificate this information comes from. I used Apple’s <code>codesign</code> utility to extract certificates from the Firefox app in order to look for matching data.</p>
<div><pre><code data-lang="bash">codesign -d --extract-certificates /Applications/Firefox.app
</code></pre></div><p>This command results in several files being created with names <code>codesign0</code>, <code>codesign1</code>, etc. The first one is the leaf certificate, while others belong to the certificate chain up until the root. <code>codesign0</code> should be what we are looking for, and once again we can use OpenSSL to extract some info about it.</p>
<div><pre><code data-lang="bash">openssl x509 -inform der -in codesign0 -text
</code></pre></div><pre><code>Certificate:
    Data:
        Version: 3 (0x2)
        Serial Number: 488521955867797808 (0x6c794216c7aa930)
    Signature Algorithm: sha256WithRSAEncryption
        Issuer: CN=Developer ID Certification Authority, OU=Apple Certification Authority, O=Apple Inc., C=US
        Validity
            Not Before: May  8 19:08:58 2017 GMT
            Not After : May  9 19:08:58 2022 GMT
        Subject: UID=43AQ936H96, CN=Developer ID Application: Mozilla Corporation (43AQ936H96), OU=43AQ936H96, O=Mozilla Corporation, C=US
        ...
</code></pre><p>Check the serial number we got (<code>0x6c794216c7aa930</code>) and compare it with the payload of the OCSP request. We have a match! This proves that OCSP requests actually send out information about the app developer certificate.</p>
<h2 id="and-their-generality">…and their generality</h2>
<p>“So what?” you might ask. Well, developer certificates aren’t unique for each app. Once again, don’t take my word for it. We can quickly verify this by checking the certificate of a different app from Mozilla, say Thunderbird.</p>
<div><pre><code data-lang="bash">codesign -d --extract-certificates /Applications/Thunderbird.app
openssl x509 -inform der -in codesign0 -text
</code></pre></div><pre><code>Certificate:
    Data:
        Version: 3 (0x2)
        Serial Number: 488521955867797808 (0x6c794216c7aa930)
    Signature Algorithm: sha256WithRSAEncryption
        Issuer: CN=Developer ID Certification Authority, OU=Apple Certification Authority, O=Apple Inc., C=US
        Validity
            Not Before: May  8 19:08:58 2017 GMT
            Not After : May  9 19:08:58 2022 GMT
        Subject: UID=43AQ936H96, CN=Developer ID Application: Mozilla Corporation (43AQ936H96), OU=43AQ936H96, O=Mozilla Corporation, C=US
        ...
</code></pre><p>That’s exactly the same certificate used for Firefox (of course it is!). So Jeffrey Paul’s analysis isn’t quite accurate - at least for what concerns these parts (emphasis mine).</p>
<blockquote>
<p>The OS sends to Apple a hash (unique identifier) of each and every program you run, when you run it.</p>
</blockquote>
<blockquote>
<p>[An IP address]&nbsp;allows for a table that has the following headings:
Date, Time, Computer, ISP, City, State, <strong>Application Hash</strong></p>
</blockquote>
<blockquote>
<p>[This means that Apple knows] what apps you open there, and how often. They know when you open Premiere over at a friend’s house on their Wi-Fi, and they know when you open Tor Browser in a hotel on a trip to another city.</p>
</blockquote>
<p>macOS does actually send out some opaque information about <strong>the developer</strong> certificate of those apps, and that’s quite an important difference on a privacy perspective.</p>
<h2 id="a-word-about-notarization">A word about notarization</h2>
<p>I would like to clarify something that is probably at the root of this misunderstanding. In fact, there exists a situation where macOS can actually send Apple the hash of an executable, and that is when <strong>Gatekeeper</strong> checks if a notarization ticket exists on Apple’s servers upon first launch, in case the ticket isn’t stapled to the app<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup>.</p>
<p>This has nothing to do with OCSP. It happens under specific circumstances and the check is performed via a secure (HTTPS) endpoint located at <code>api.apple-cloudkit.com</code>. During this process, a pop-up with a progress bar is shown to the user.</p>
<h2 id="about-blocking-ocsp">About blocking OCSP</h2>
<p>As you probably have already learned during Apple’s OCSP responder outage, you can block OCSP requests in several ways, the most popular ones being Little Snitch<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup> and editing your <code>/etc/hosts</code> file. Personally, I wouldn’t suggest doing that as it prevents an <strong>important security feature</strong> from working.</p>
<p>Now that you know the actual facts, if you think your privacy is put at risk by this feature more than having potential undetected malware running on your system, go ahead. Otherwise, don’t bother.</p>
<p>If you use macOS Big Sur, blocking OCSP might not be as trivial. Before crying conspiracy, however, keep in mind that common users are generally not able to fully understand and evaluate the impact of disabling such a complex and delicate security feature on their computer.</p>
<h2 id="tldr">TL;DR</h2>
<ul>
<li>No, macOS <strong>does not</strong> send Apple a hash of your apps each time you run them.</li>
<li>You should be aware that macOS <strong>might transmit</strong> some opaque information about the developer certificate of the apps you run. This information is sent out in clear text on your network.</li>
<li><strong>You shouldn’t</strong> probably block <code>ocsp.apple.com</code> with Little Snitch or in your hosts file.</li>
</ul>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p><a href="https://en.wikipedia.org/wiki/Online_Certificate_Status_Protocol">https://en.wikipedia.org/wiki/Online_Certificate_Status_Protocol</a> <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p><a href="https://sneak.berlin/20201112/your-computer-isnt-yours/">https://sneak.berlin/20201112/…</a></p></li></ol></section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.jacopo.io/en/post/apple-ocsp/">https://blog.jacopo.io/en/post/apple-ocsp/</a></em></p>]]>
            </description>
            <link>https://blog.jacopo.io/en/post/apple-ocsp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25095438</guid>
            <pubDate>Sat, 14 Nov 2020 20:39:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Domain Ownership, Web Authorship and WebVerify]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25095324">thread link</a>) | @Hedja
<br/>
November 14, 2020 | https://jahed.dev/2020/11/13/domain-ownership-web-authorship-and-webverify/ | <a href="https://web.archive.org/web/*/https://jahed.dev/2020/11/13/domain-ownership-web-authorship-and-webverify/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p><time itemprop="datePublished" datetime="2020-11-13T01:00:00.000Z">13 Nov, 2020</time></p><p>The problem I have is simple: no one owns the same domains forever. So when people are visiting or linking to domains owned by a specific person or company, they expect to link to a specific author's work. If that authorship changes, the link is no longer relevant.</p><p>I have this issue with my old domain. I want to get rid of it, but nothing's stopping someone from buying it and serving ads or malicious content. Even after two years, people still use it; linked from other websites and their bookmarks. Even with a redirect page asking them to switch over, those links will never change. There's nothing I can do about it. In a few years, I'll just have to accept it might lead people to malicious websites, unrelated pages, or a dead end. All of which can be annoying when you're browsing the web.</p><h2>So, what's the solution?</h2><p>A somewhat naive approach is to include a signature alongside every page and have links include a public key reference. The browser can then verify the linked page is still authored by whoever the link expects. If it isn't, a warning can show up, or whatever the preference is like using a web archive.</p><h2>Introducing WebVerify</h2><p>Over the past few days, I've been working on a proof-of-concept called <a target="_blank" rel="noopener" href="https://webverify.jahed.dev/">WebVerify</a>. It's a Firefox Web Extension (a.k.a. plugin) (a.k.a. add-on). The first one I've written. I'm not glad about the code quality, but I'm new to the ecosystem so it's expected. Again, it's a proof-of-concept so I'm not expecting anyone to use it -- me included.</p><figure><img src="https://www-static.jahed.dev/2020/2020-11-12-wv-preview.png" alt=""><figcaption>A Web Page Verified by WebVerify</figcaption></figure><h2>Conclusion</h2><p>This was originally one large blog post about my ideas to solve this problem, which eventually split into two, which then became WebVerify. That's Blog-driven Development in action. To read that second blog post which goes into a lot more detail, it's become <a target="_blank" rel="noopener" href="https://webverify.jahed.dev/">WebVerify's Documentation</a>, so check it out if you want.</p><p>Thanks for reading.</p></article></div>]]>
            </description>
            <link>https://jahed.dev/2020/11/13/domain-ownership-web-authorship-and-webverify/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25095324</guid>
            <pubDate>Sat, 14 Nov 2020 20:24:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to specify data types in Python]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25095256">thread link</a>) | @janprincek
<br/>
November 14, 2020 | https://www.pythonstacks.com/blog/type-hints-python/ | <a href="https://web.archive.org/web/*/https://www.pythonstacks.com/blog/type-hints-python/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p>In the low-level programming languages like Java, C, C++, and C#, <span>variables are strictly typed</span> - which means you have to indicate the variable type when creating a variable.</p>

<p>For example, creating variables in <strong>Java</strong>:</p>

<pre><code>String name = "John";       

int age;                    # only an integer can be assigned to age

age = 23;                   # assigning a value to age</code></pre>



<p>Unlike Java, <span>Python gives us the flexibility to declare and assign variables without specifying their types</span> :</p>

<pre><code>name = "John"

age = 23</code></pre>

<p>In this type of coding, Python <span>automatically figures out the type of data that has been assigned to a variable</span>. You can verify that by using the <code>type()</code> function:</p>

<pre><code>print(type(name))              # &lt;class 'str'&gt;
print(type(age))               # &lt;class 'int'&gt;</code></pre>



<h2>Type Hints in Python</h2>

<p>Though <span>Python is not a strictly typed language</span>, you can still <span>give a hint of a variable's data type</span>.</p>

<p>To specify a variable type when declaring it,</p>

<p><code>variable_name: variable_type = value</code></p>

<pre><code>weather: str = "cloudy"

degrees: int                    # you can declare a variable before assigning
degrees = 32</code></pre>



<p>Also note that even <span>after a variable type is indicated in Python, you can still assign a different data type to the variable</span>:</p>

<pre><code>degrees: int = 32
print(degrees)                      # 32

degrees = "thirty-two"
print(degrees)                      # thirty-two</code></pre>



<p>Specifying a variable type in Python does not mean the variable can only accept values of that type. They are just hints that inform a user of the type which a variable is.</p>



<h2>Adding types to functions</h2>

<p>Type hints are very useful in Functions,&nbsp; mostly when declaring function parameters.</p>

<p>For example, here is a <span>simple function that takes in two arguments and returns the sum</span>.</p>

<pre><code>def sum(a, b):
    return a + b</code></pre>

<p>By looking at this code, <span>one cannot be sure if the caller is going to supply integers</span> as the argument or <span>strings</span> or any other data type.</p>

<p>A call to this function works when supplied with <span>int</span> values and with other values such as <span>strings, lists, and tuples</span>:</p>

<pre><code>sum(3, 5)                               # 8

sum([1, 0, 5], ['java', 'c++'])         # [1, 0, 5, 'java', 'c++']

sum('2', '3')                           # 23</code></pre>

<p>Here you can see that the<code> sum()</code> function works well when it is invoked with either <span>int</span> values, <span>string</span> values, or <span>even</span> lists.</p>

<p>But the goal of the <code>sum()</code> function is to<span> add two integers</span>, and not two <span>lists </span>or <span>strings</span>. We can now provide type hints for the parameters in the Function definition indicating the type that we want to allow.</p>

<p>To indicate that we only want to allow <span>int types</span> we can change our function definition to look like:</p>

<pre><code>def sum(a: int, b: int):
    return a + b</code></pre>

<p>This informs the function caller that <span>the arguments required for the sum() function </span>should be<span> integers </span>not otherwise.</p>

<p>Similarly, <span>to indicate only <code>str </code>types are allowed</span>, we'd change our function to specify it as:</p>

<pre><code>def sum(a: str, b: str):
    return a + b</code></pre>



<h2>Specifying A function's return type.</h2>

<p>One could also indicate the return value of a function call :</p>

<pre><code>def sum(number1, number2) -&gt; int :
    return number1 + number1</code></pre>

<p>This informs the caller that the return type of the <code>sum()</code> function should be an integer.</p>




        </div></div>]]>
            </description>
            <link>https://www.pythonstacks.com/blog/type-hints-python/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25095256</guid>
            <pubDate>Sat, 14 Nov 2020 20:13:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Hacker's Diet]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25095213">thread link</a>) | @kirillzubovsky
<br/>
November 14, 2020 | https://www.fourmilab.ch/hackdiet/ | <a href="https://web.archive.org/web/*/https://www.fourmilab.ch/hackdiet/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<center>

<h3><i>How to lose weight and hair through stress and poor nutrition</i></h3>
<address>
By
<a href="https://www.fourmilab.ch/" target="_top">John Walker</a>
</address>
</center>

<p>

<cite>The Hacker's Diet</cite>, notwithstanding its silly
subtitle, is a serious book about how to lose weight and
permanently maintain whatever weight you desire.  It
treats dieting and weight control from an <em>engineering</em>
and <em>management</em> standpoint, and provides the tools
and an understanding of why they work and how to use
them that permit the reader to gain control of their
own weight.  The book is intended primarily for busy,
successful engineers, programmers, and managers who
have struggled unsuccessfully in the past to lose
weight and avoid re-gaining it.
<a href="#Comptools">Computer-based tools</a>
and experiments in Microsoft Excel or the Palm Computing
Platform are available, as well as an online Web application,
but a computer is not necessary to use
the techniques described in the book; paper and pencil
alternatives are provided.
</p>

<h2><a href="https://www.fourmilab.ch/hackdiet/e4/">Fourth Edition (2005)</a></h2>

<p>
<a href="https://www.fourmilab.ch/hackdiet/e4/"><img src="https://www.fourmilab.ch/hackdiet/figures/hdpage4.png" width="256" height="288" alt=""></a>
The Fourth Edition of <cite>The Hacker's Diet</cite> was
released in November 2005.  It is essentially identical in content with the
previous editions, but has been extensively re-formatted to improve
appearance, accessibility, ease of navigation, and standards compliance.
The Fourth Edition strictly complies with the
<a href="http://www.w3.org/TR/xhtml1/" target="Hackdiet_Aux">XHTML&nbsp;1.0</a> (Transitional and Frameset)
and
<a href="http://www.w3.org/TR/CSS21/" target="Hackdiet_Aux">CSS&nbsp;2.1</a>
standards and requires a browser which implements these
standards.  (As of the release of this edition, current versions
of all of the most popular browsers, including Mozilla Firefox,
Opera, and Microsoft Internet Explorer supported these standards
sufficiently to display the book without problems.)  In addition, the
browser and operating system must display Unicode character entities.
JavaScript and DOM/DHTML are used in the navigation bar, but if they're
absent or disabled, everything will still work.  If your browser and/or
system cannot handle this version, the Third Edition (Frames) or the
No-Frame editions, both of which date from 1994, will almost certainly
work.  The content is the same; only the presentation is more rudimentary.
<br clear="right">
</p>

<h2><a name="epub" href="https://www.fourmilab.ch/hackdiet/epub/hackdiet.epub">EPUB Edition (2011)</a></h2>

<p>
<a href="https://www.fourmilab.ch/hackdiet/epub/hackdiet.epub"><img src="https://www.fourmilab.ch/hackdiet/figures/hd_ipad_256.png" width="198" height="288" alt=""></a>
The
<a href="http://en.wikipedia.org/wiki/EPUB" target="Hackdiet_Aux">EPUB</a>
edition is in the open document format
compatible with the iBooks application on the Apple iPad, iPhone, and
iPod&nbsp;touch; Sony Reader; Barnes and Noble Nook; and a variety of
other electronic book devices and mobile platforms.  EPUB books may be
opened directly with a Web browser using the
<a href="http://www.epubread.com/en/" target="Hackdiet_Aux">EPUBReader</a>
add-on for Firefox or the
<a href="http://widgets.opera.com/widget/15552/" target="Hackdiet_Aux">eBook
Reader</a>
widget for Opera, although users of desktop and notebook computers
with Internet connectivity will probably prefer the
<a href="https://www.fourmilab.ch/hackdiet/e4/">Web edition</a>,
due to its more flexible navigation options.
</p>

<p>
If your Web browser has an EPUB-compatible plug-in installed, you can
open the book simply by clicking on the
<a href="https://www.fourmilab.ch/hackdiet/epub/hackdiet.epub" target="Hackdiet_Aux"><cite>The
Hacker's Diet</cite> EPUB Edition</a>
link.  Otherwise, use your browser's idiom to download the
abovementioned file to your computer and then transfer it to your
reading device according to the manufacturer's directions.  For the
iPad and iPhone (etc.), just drag the downloaded
<tt>hackdiet.epub</tt> file to iTunes, where you should see it in the
“Books” section.  Then connect your reading device to the
computer and the book should be transferred to it by the Sync
process.  If the book is not installed, make sure that you've enabled
syncing books to that device, and that if you've opted not to sync all
books in your library to the device, that <cite>The Hacker's
Diet</cite> is checked to be copied.  You must also, of course, have
the Apple
<a href="http://en.wikipedia.org/wiki/IBooks" target="Hackdiet_Aux">iBooks</a>
application installed on the device; if it's missing, go to the App
Store and install it—it's free.
</p>

<p>
<cite>The Hacker's Diet</cite> EPUB edition contains no “Digital
Rights Management” constraints: you are free to install it on as
many devices as you wish, transfer it among them (if their hardware
and software so permit), and pass on copies to others.  It should be
compatible with any EPUB reader hardware and software which can open
standards-compliant unrestricted files.
<br clear="right">
</p>

<h2><a name="Comptools" href="https://www.fourmilab.ch/hackdiet/comptools.html">Computer-Based Tools</a></h2>

<p>
Computer-based tools and experiments for Microsoft
Excel and the Palm Computing Platform are available for downloading.
A Web-based application, The Hacker's Diet <em>Online</em>, which
can be used from any computer with Internet access and a Web
browser, is available.
</p>

<dl>
<dt><b><a href="https://www.fourmilab.ch/hackdiet/online/hdo.html">The Hacker's Diet <em>Online</em></a></b></dt>
    <dd>This Web-based application allows you to maintain weight
    	and exercise logs, produce custom charts, analyse trends,
	and plan diets from any computer with Internet connectivity and
	a Web browser.  Data may be imported from and exported to
	other versions of the computer tools, or exported as CSV or XML for
	analysis with other programs.</dd>

<dt><b><a href="https://www.fourmilab.ch/hackdiet/comptoolsExcel.html">Microsoft Excel</a></b></dt>
    <dd>Versions compatible with
        a variety of Excel releases are available, all ZIPped
        archives of about 250 Kb.</dd>

<dt><b><a href="https://www.fourmilab.ch/hackdiet/palm/">Palm Computing Platform</a></b></dt>
    <dd>An implementation of the Eat Watch nutrition and exercise
        log and analysis software for the Palm Computing Platform
        (PalmPilot, Palm, PalmOS, etc.), including desktop
        software for any platform with a standard C language
        environment which generates illustrated HTML logs
        from databases backed up from the handheld.</dd>
</dl>

<h2><a name="offline" href="https://www.fourmilab.ch/hackdiet/hdpdf.zip">PDF Edition</a></h2>

<p>
<a href="https://www.fourmilab.ch/hackdiet/hdpdf.zip"><img src="https://www.fourmilab.ch/hackdiet/www/figures/hdpdf.gif" width="218" height="256" alt="PDF Screen"></a>
If you prefer to read the book off-line, you can
<a href="https://www.fourmilab.ch/hackdiet/hdpdf.zip">download a PDF edition</a> (1.3 Mb, ZIP compressed)
which you
can read with the Adobe Reader utility,
available for most personal computers and Unix workstations,
which may be
<a href="http://get.adobe.com/reader/" target="Hackdiet_Aux">downloaded
free of charge</a> directly from the
<a href="http://www.adobe.com/" target="Hackdiet_Aux">Adobe Systems</a> Web site.
The PDF edition preserves all the formatting of
the original book, and permits point-and-click navigation
among chapters and to follow cross-references in the text.
</p>

<p>
Adobe is one of the most consistently irritating companies
on Earth with which to do business.  I'd like to give you
a nice button for downloading your own copy of Adobe Reader,
but they won't let me use the image without “registering”
and “licensing” it, which I'm certainly not going to do
in order to promote their product and its file format.
<br clear="right">
</p>

<h2><a href="https://www.fourmilab.ch/hackdiet/hdps.zip">PostScript Edition</a></h2>

<p>
<cite>The Hacker's Diet</cite> was originally typeset
using <a href="http://www.tug.org/" target="Hackdiet_Aux">TeX</a> with the
<a href="http://www.latex-project.org/" target="Hackdiet_Aux">LaTeX</a>
macro package.  Camera-ready copy was generated
from PostScript created by the <tt>dvips</tt>
utility.  The PostScript edition is a single monolithic
file, almost 2.7 megabytes, containing the
entire book as originally typeset.  You can read it on-line
with a PostScript viewing program such as
<a href="http://www.cs.wisc.edu/~ghost/">GhostScript</a>
(which is free), or print it on any PostScript-compatible
printer.  <strong>Before sending this
file to a printer, consider that the book is almost
250 pages long!</strong>  This is a <em>big</em> print
job, which will consume lots of paper, toner, and,
potentially, good will of any colleagues with whom
you share the printer.  The PostScript edition may be
downloaded as either a <a href="https://www.fourmilab.ch/hackdiet/hdps.zip">ZIPped archive</a>
or a <a href="https://www.fourmilab.ch/hackdiet/hackdiet.ps.gz"><b>gzip</b> compressed Unix <b>tar</b>
file</a>; both are 702 Kb in length and uncompress to a 2.7
Mb PostScript file.
</p>

<h2><a href="https://www.fourmilab.ch/hackdiet/www/hackdietf.html">Third Edition (1994 Web Edition with Frames)</a></h2>

<p>
If your browser supports frames but isn't up to the demands
of the Fourth Edition, the original 1994 Web edition with
frames remains available.
It allows navigation with
a panel which lets you click chapter titles and go
directly to that chapter.  If, in addition, your browser
supports JavaScript, simply moving the mouse over a
footnote icon, like this one:
<a onmouseover="javascript:footOver(0);" href="https://www.fourmilab.ch/hackdiet/www/f/0.html"><img src="https://www.fourmilab.ch/hackdiet/www/i/foot.gif" width="15" height="15" alt="[Footnote]"></a>
will pop up a window containing the footnote.  Moving the
mouse over other footnotes displays them in the auxiliary window.
Browsers without JavaScript (or users who have disabled
JavaScript in their browsers) may display footnotes in
the main document window by clicking the footnote icon,
then use their browser's “Back” button to return to the
main text.
</p>

<h2><a href="https://www.fourmilab.ch/hackdiet/www/hackdiet.html">No-Frame Web Edition</a></h2>

<p>
<a href="https://www.fourmilab.ch/hackdiet/www/hackdiet.html"><img src="https://www.fourmilab.ch/hackdiet/www/figures/any_browser.gif" width="88" height="31" alt="Works with Any Browser"></a>
Users with browsers which do not support frames, or those
who prefer a more linear presentation in a single
window, may access a no-frame edition of <cite>The Hacker's
Diet</cite> with identical content to the frame-based book.
The no-frame edition includes the pop-up footnotes present
in the frame edition, but since few browsers which lack
frames are likely to support JavaScript, you can simply click
on the footnote icon to display it, then use the
“Back” button or keystroke to return to the text containing
the footnote.
<br clear="right">
</p>

<hr>
<p>
    <a href="http://validator.w3.org/check?uri=http://www.fourmilab.ch/hackdiet/index.html" target="_blank"><img src="https://www.fourmilab.ch/images/icons/valid-xhtml10.png" alt="Valid XHTML 1.0" height="31" width="88"></a>
</p>
<address>
by <a href="https://www.fourmilab.ch/" target="_top">John Walker</a>
</address>

</div></div>]]>
            </description>
            <link>https://www.fourmilab.ch/hackdiet/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25095213</guid>
            <pubDate>Sat, 14 Nov 2020 20:09:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Adversarial.js – hack neural networks in the browser]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25095069">thread link</a>) | @jellyksong
<br/>
November 14, 2020 | https://kennysong.github.io/adversarial.js | <a href="https://web.archive.org/web/*/https://kennysong.github.io/adversarial.js">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <h4>What is the demo doing?</h4>
        <p>Neural networks achieve superhuman performance in many areas, but they are easily fooled.</p>
        <p>In the demo above, we can force neural networks to predict anything we want. By adding nearly-invisible noise to an image, we turn "1"s into "9"s, "Stop" signs into "120 km/hr" signs, and dogs into hot dogs.</p>
        <p>These noisy images are called <a href="https://en.wikipedia.org/wiki/Adversarial_machine_learning#Specific_Attacks_Types">adversarial examples</a>. They break the integrity of machine learning systems, and the illusion of their superhuman performance.</p>

        <h4>Why does this matter?</h4>
        <p>Our world is becoming increasingly automated, yet these systems have strange failure modes.</p>
        <p>If machine learning systems are not properly defended, attackers could:</p>
        <ul>
          <li>Impersonate others in facial recognition systems</li>
          <li>Force autonomous vehicles to misrecognize street signs &amp; obstacles</li>
          <li>Bypass content moderation and spam filters in social networks</li>
          <li>Inject adversarial bytes into malware to bypass antivirus systems</li>
          <li>Digitally alter numbers on a check in a mobile banking app</li>
          <li>(and more)</li>
        </ul>

        <h4>Is this limited to image classification with neural networks?</h4>
        <p>No. Adversarial examples exist for almost every machine learning task: <a href="https://nicholas.carlini.com/code/audio_adversarial_examples">speech recognition</a>, <a href="https://arxiv.org/pdf/1804.07998.pdf">text classification</a>, <a href="https://dl.acm.org/doi/10.1145/3308558.3313533">fraud detection</a>, <a href="https://www.ericswallace.com/imitation">machine translation</a>, <a href="https://adversarialpolicies.github.io/">reinforcement learning</a>, ....</p>
        <p>Moreover, all machine learning models (not just neural networks) are vulnerable. In fact, simpler models such as logistic regression are <a href="https://arxiv.org/pdf/1412.6572.pdf">even more easily attacked</a>.</p>
        <p>Finally – beyond adversarial examples – there are many more adversarial attack vectors, including data poisoning, model backdooring, data extraction, and model stealing.</p>

        <h4>How do I defend against adversarial examples?</h4>
        <p>There are several proposed defenses, including adversarial training and admission control.</p>
        <p>However, no defense is universal and many have proven ineffective, so work with an expert to quantify your risks and invest in defenses appropriately.</p>
        <p>(What happens if someone can make your system predict anything they want?).</p>

        <h4>Where can I learn more?</h4>
        <p>Here's a list of good resources, in rough order of approachability:</p>
        <ul>
          <li><a href="https://kennysong.github.io/faq.html">The full FAQ</a></li>
          <li><a href="https://kennysong.github.io/examples.html">The directory of attacks</a> (try running locally and playing with various settings)</li>
          <li><span>[Blog]</span> CleverHans – <a href="http://www.cleverhans.io/security/privacy/ml/2016/12/16/breaking-things-is-easy.html">start here</a></li>
          <li><span>[Blog]</span> Gradient Science – <a href="https://gradientscience.org/intro_adversarial/">start here</a></li>
          <li><span>[Tutorial]</span> <a href="https://adversarial-ml-tutorial.org/">Adversarial Robustness - Theory and Practice</a></li>
          <li><span>[Paper]</span> <a href="https://arxiv.org/pdf/1611.03814.pdf">SoK: Towards the Science of Security and Privacy in Machine Learning</a></li>
          <li><span>[Paper]</span> <a href="https://arxiv.org/pdf/1712.03141.pdf">Wild Patterns: Ten Years After the Rise of Adversarial Machine Learning</a></li>
        </ul>
        <p>Last – feel free to <a href="mailto:hello@kennysong.com">email me questions</a>.</p>

        
      </div></div>]]>
            </description>
            <link>https://kennysong.github.io/adversarial.js</link>
            <guid isPermaLink="false">hacker-news-small-sites-25095069</guid>
            <pubDate>Sat, 14 Nov 2020 19:51:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Best and Worst Microcontroller SDKs]]>
            </title>
            <description>
<![CDATA[
Score 98 | Comments 72 (<a href="https://news.ycombinator.com/item?id=25094956">thread link</a>) | @ducktective
<br/>
November 14, 2020 | https://interrupt.memfault.com/blog/the-best-and-worst-mcu-sdks | <a href="https://web.archive.org/web/*/https://interrupt.memfault.com/blog/the-best-and-worst-mcu-sdks">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        <p>In 2020, an MCU is much more than a hunk of silicon. Indeed, it comes with a
whole ecosystem including a BSP, integrated third-party libraries, tooling,
field application support,  and more.</p>

<p>As firmware engineers, we are often handed down an MCU selection as a fait
accompli. Cost concerns, peripheral, or pinout requirements often take precedent
over the SDK.</p>

<p>Yet we are allowed to have an opinion. So here for you today is my first post in
a new “comparing MCU SDKs” series.</p>

<!-- excerpt start -->

<p>In this post, I download SDKs for 10 popular Cortex-M4 microcontrollers, and
evaluate how straightforward it is to get a simple example compiling. I include
some step by step instructions to get started, a rating out of 10, and a few
comments.</p>

<!-- excerpt end -->

<p>It goes without saying that this is an opinion based on my own very specific
setup (MacOS, vim). Your mileage may vary!</p>

<p>Like Interrupt? <a href="https://go.memfault.com/interrupt-subscribe" target="_blank">Subscribe</a> to get our latest posts straight to your mailbox.</p>



<h2 id="what-im-looking-for-in-a-chip-sdk">What I’m looking for in a chip SDK</h2>

<p>My ideal chip SDK provides a way to build and flash projects using tools of
my choosing. This seems like a low bar, but few meet it. Here are things chip
SDKs should <strong>not</strong> do.</p>

<h3 id="dont-choose-my-laptop-os-for-me">Don’t choose my laptop OS for me!</h3>

<p>I left Windows behind when I worked at Sun Microsystems, and I have not looked
back. Today, my daily driver is a MacBook Air.  Unfortunately, some chip vendors
require that you use their Windows-based tools to set up and build your projects.
Now that most compilers are cross-platform, there is no excuse for it.</p>

<h3 id="dont-choose-my-ide-for-me">Don’t choose my IDE for me!</h3>

<p>I’ve been using <code>vim</code> since college, and you can take it from my cold, dead
hands. I love <code>vim</code>! I have it configured just so. It’s lightweight, it’s fast,
and modal editing is the way to work (prove me wrong!). So you’ll understand my
dismay at the spate of Eclipse-based IDEs chip vendors want to foist upon me. I
want nothing to do with their boated, Java environments.</p>

<p>Instead of Eclipse-based IDE, I suggest SDKs provide Makefiles. <code>make</code> is the
lowest common denominator build system, and is well supported by many tools.
Bonus points for project files for IAR and Keil, since many of you like those
tools.</p>

<h3 id="do-include-some-examples">Do include some examples</h3>

<p>If a picture is worth a thousand words, then a working code example is worth a
million. Give me one example of each of the main use cases for your MCU. Bonus
points if you give me an example for each peripheral.</p>

<h2 id="ten-popular-chip-sdks-ranked">Ten Popular Chip SDKs, Ranked</h2>

<h3 id="nordic-semi-nrf5-sdk---1010">Nordic Semi nRF5-SDK - 10/10</h3>

<p>Nordic semiconductor’s line of Cortex-M4 MCUs includes the nRF52810, nRF52810,
and nRF52840. All feature a 2.4GHz radio, which may deter you if all you want is
an MCU.</p>

<p>The nRF5-SDK (soon to be replaced by the equally excellent nRF-Connect-SDK), is
in my view the best chip SDK out there.</p>

<h4 id="why-the-rating">Why the rating</h4>

<ul>
  <li>Cross-platform ✅</li>
  <li>Supports armcc/Keil, IAR, and Makefiles ✅</li>
  <li>Lots of bundled examples ✅</li>
  <li>Single zip, no install needed ✅</li>
</ul>

<p>The nRF5 SDK does everything right. No registration, no install, no online
configurator. It even is distributed under a BSD license!</p>

<h4 id="compiling-a-blinky-example">Compiling a Blinky example</h4>
<ol>
  <li>Download the nRF5 SDK from <a href="https://www.nordicsemi.com/Software-and-tools/Software/nRF5-SDK/Download#infotabs" target="_blank">nRF5 SDK downloads - nordicsemi.com</a>
</li>
  <li>Unzip the resulting <code>DeviceDownload.zip</code> file</li>
  <li>Unzip the SDK archive contained within. In my case that’s <code>nRF5SDK1702d674dde.zip</code>
</li>
  <li>
<code>cd</code> to the example you are interested in. Examples are contained within the <code>example</code> folder. In my case, <code>examples/peripheral/blinky/pca10040/blank</code>.</li>
  <li>
<code>cd</code> to the build system folder of your choice, in my case <code>armgcc</code>
</li>
  <li>Build the example, in my case by invoking <code>GNU_INSTALL_ROOT= make</code>
</li>
</ol>

<p>This will generate a <code>bin</code>, <code>elf</code>, and <code>hex</code> file (among others) under <code>_build</code>.</p>

<h3 id="texas-instruments-tivaware---910">Texas Instruments TivaWare - 9/10</h3>

<p>The Tiva C series is the latest entry in Texas Instruments’s line of Cortex-M
microcontrollers.  I do not have a lot of experience with them, but they seem
like solid microcontrollers with a broad range of peripherals (including USB).</p>

<h4 id="why-the-rating-1">Why the rating</h4>

<ul>
  <li>Cross-platform ✅</li>
  <li>Supports armcc/Keil, IAR, and Makefiles ✅</li>
  <li>Lots of bundled examples ✅</li>
  <li>Single zip, no install needed ✅</li>
</ul>

<p>Like Nordic, Texas Instruments gets a lot right: single-zip download, multi-IDE
support (including Makefiles), and lots of examples. I knocked off a point for
the wonky <code>exe</code> file (see below) and the more complicated license.</p>

<h4 id="compiling-a-blinky-example-1">Compiling a Blinky example</h4>

<ol>
  <li>Download TiWare SDK from <a href="https://www.ti.com/tool/download/SW-TM4C" target="_blank">SW-TM4C_2.2.0.295, TI.com</a>
</li>
  <li>Rename the downloaded file from <code>exe</code> to <code>zip</code>
</li>
  <li>Unzip it</li>
  <li>
<code>cd</code> to the example you are interested in. In my case <code>examples/boards/dk-tm4c129x/blinky</code>.</li>
  <li>Run <code>make</code>, or open the IDE-specific folder of your choice.</li>
</ol>

<p>You’ll be left with an <code>axf</code> (aka an ELF) and a <code>bin</code>  file in the <code>gcc</code> folder.</p>

<h3 id="nxp-mcuxpresso---910">NXP MCUXpresso - 9/10</h3>

<p><img src="https://interrupt.memfault.com/blog/img/best-and-worst-mcu-sdks/E2992448-AC4D-4A31-9B86-E4806F729E51.png" alt=""></p>

<p>NXP Kinetis traces its lineage to Motorola via Freescale. It is one of two
Cortex-M lines from NXP (the other being the LPC).  Like many MCU vendors, NXP
generates their SDK via a configurator and provides an Eclipse-based IDE, both
under the “MCUXpresso” brand.</p>

<h4 id="why-the-rating-2">Why the rating</h4>

<ul>
  <li>Cross-platform ✅</li>
  <li>Supports armcc/Keil, IAR, and Makefiles ✅</li>
  <li>Lots of bundled examples ✅</li>
  <li>Single zip, no install needed ⚠️</li>
</ul>

<p>I found the online MCUXpresso SDK builder a breeze to use. It is snappy,
straightforward, and it keeps track of all your previously configured SDKs.
Great job, NXP! The only downside of the tool is that it requires you to
register on their website.</p>

<p>I still have a preference for the monolithic SDK with all examples and targets
in one place, but you could argue that this generates a smaller, more
streamlined SDK.</p>

<p>Best of all, the SDK uses <code>cmake</code> to generate build files. <code>cmake</code> is arguably
more portable than <code>make</code>, as it is supported natively on Windows.</p>

<h4 id="compiling-a-hello-world-example">Compiling a hello world example</h4>

<ol>
  <li>Go to the MCUXpresso SDK builder and create an account: <a href="https://mcuxpresso.nxp.com/" target="_blank">MCUXpresso SDK Builder</a>
</li>
  <li>Once logged in, click on “Select Board” in the sidebar</li>
  <li>Enter the name of your MCU. In my case, a Kinetic K21</li>
  <li>Click on “Build MCUXpresso SDK” on the right</li>
  <li>Name your project, select a toolchain, and some third party software like FreeRTOS or mbedTLS.</li>
  <li>Click on “Download SDK” at the bottom</li>
  <li>After a bit, the SDK will be ready for download</li>
  <li>Unzip the SDK</li>
  <li>
<code>cd</code> to the example of your choice, in my case <code>boards/twrk21d50m/demo_apps/hello_world/</code>
</li>
  <li>
<code>cd</code> to build system folder, in my case <code>armgcc</code>
</li>
  <li>Use the <code>build_debug.sh</code> build script and specify the<code>ARMGCC_DIR</code> environment variable:
e.g. <code>ARMGCC_DIR=/usr/local/Cellar/arm-none-eabi-gcc/9-2019-q4-major sh build_debug.sh</code>
</li>
</ol>

<p>This will generate an ELF file.</p>

<h3 id="stm32-cube---810">STM32 Cube - 8/10</h3>

<p><img src="https://interrupt.memfault.com/blog/img/best-and-worst-mcu-sdks/6DA202F6-ED4E-4FFE-94B7-3A549D0F212F.png" alt=""></p>

<p>ST has gone through multiple iterations of the SDK for the STM32 family of ICs.
The latest is called STM32 Cube, which replaces the venerable Standard
Peripheral Library. While Cube introduces a lot of complexity, it does so for a
good reason: the STM32 family has grown to include 14 distinct series of MCUs
from the very low power L0 to the very high-performance H7.</p>

<blockquote>
  <p>Note: Reader Nathan Jones <a href="https://community.memfault.com/t/the-best-and-worst-mcu-sdks-interrupt/294/12" target="_blank">pointed
out</a>
after the initial publication of this post that monolithic SDK downloads do
still exist for STM32. For example, <a href="https://www.st.com/content/st_com/en/products/embedded-software/mcu-mpu-embedded-software/stm32-embedded-software/stm32cube-mcu-mpu-packages/stm32cubef1.html" target="_blank">here is the SDK for the
STM32F1</a></p>
</blockquote>

<h4 id="why-the-rating-3">Why the rating</h4>

<ul>
  <li>Cross-platform ✅</li>
  <li>Supports armcc/Keil, IAR, and Makefiles ✅</li>
  <li>Lots of bundled examples ✅</li>
  <li>Single zip, no install needed ❌</li>
</ul>

<p>While Cube comes with support for many IDEs, and more examples than any other
MCU SDK, it wraps it all in a clunky desktop app. I had a terrible time using
STM32CubeMX: I had to install it on my laptop, it’s slow, it’s large, it’s
clunky. I do not like it.</p>

<p>STM32CubeMX generates a “project” directory based on your configuration. This
means that you won’t have all the example code in one folder, and instead will
need to generate different projects for different examples.</p>

<p>Necessary complexity? Perhaps. But I miss the simpler Peripheral Library which
came as a single archive.</p>

<h4 id="compiling-a-hello-world-example-1">Compiling a Hello World example</h4>

<ol>
  <li>
    <p>Download and install CubeMX: <a href="https://www.st.com/en/development-tools/stm32cubemx.html" target="_blank">STM32CubeMX - STM32Cube initialization code generator - STMicroelectronics</a>. Note: this requires registration on ST’s website</p>
  </li>
  <li>Select “ACCESS TO MCU SELECTOR”</li>
  <li>Select the part you are using. In my case “STM32F429IE”</li>
  <li>In the Configuration view, click on the “Project Manager” tab</li>
  <li>Enter a project name, a path, and select a toolchain. In my case “Makefile”</li>
  <li>Click on “Generate Code” at the top right</li>
  <li>
<code>cd</code> to the generated project directory</li>
  <li>Compile the project with your build system. In my case with <code>make</code>.</li>
</ol>

<h3 id="atmel-start-for-samd---710">Atmel START for SAMD - 7/10</h3>

<p><img src="https://interrupt.memfault.com/blog/img/best-and-worst-mcu-sdks/83E37D9A-5975-4815-8937-437DA8675C0D.png" alt=""></p>

<p>Recently acquired by Microchip, Atmel has been making SAM-family MCUs for a long
time. The SAMD21 is well-liked in hobbyist circles and is featured in several
Arduino and Adafruit designs. Atmel’s peripheral library, AXF, went through a
similar transformation to ST’s: it went from a single zip archive to a
configurator.</p>

<h4 id="why-the-rating-4">Why the rating</h4>

<ul>
  <li>Cross-platform ✅</li>
  <li>Supports armcc/Keil, IAR, and Makefiles ✅</li>
  <li>Lots of bundled examples ✅</li>
  <li>Single zip, no install needed ❌</li>
</ul>

<p>Atmel’s configurator is web-based, and a tad more ergonomic than ST’s. However,
the resulting Makefiles are much worse and even feature a bug (I had to fix OS
detection).</p>

<h4 id="compiling-a-hello-world-example-2">Compiling a hello world example</h4>

<ol>
  <li>Go to start.atmel.com</li>
  <li>Click on “Create New Project”</li>
  <li>Select your MCU. In my case a SAMD51 Chip.</li>
  <li>Click on “Export Project” at the top right</li>
  <li>Give it a name, and tick the check-box for your IDE (for me: Makefile)</li>
  <li>Click on “Download Pack”</li>
  <li>Rename resulting file from <code>.azip</code> to <code>.zip</code>
</li>
  <li>Extract it</li>
  <li>
<code>cd</code> to into IDE folder, in my case <code>gcc</code>
</li>
  <li>Fix Makefile OS detection:
    <div>
<div><pre><code><span>@@ -22,7 +22,7 @@</span> else
                MK_DIR = mkdir -p
        endif
    
<span>+       ifeq ($(shell uname | cut -d _ -f 1), Darwin)
</span><span>-       ifeq ($(shell uname | cut -d _ -f 1), DARWIN)
</span>                MK_DIR = mkdir -p
        endif
 endif
</code></pre></div>    </div>
  </li>
  <li>Run <code>make</code>
</li>
</ol>

<h3 id="silabs-simplicity-studio---510">Silabs Simplicity Studio - 5/10</h3>

<p><img src="https://interrupt.memfault.com/blog/img/best-and-worst-mcu-sdks/3F4AD307-656B-4664-B988-4F5A301BD771.png" alt=""></p>

<p>Silabs Cortex-M MCU comes from its acquisition of Energy Micro who was famous for
the very low power consumption of their MCUs. Silabs now makes a range of
Cortex-M based MCUs, some with 2.4GHz radios.</p>

<p>Like many of the vendors in the lower half of this list, Silabs distributes
its SDK alongside an Eclipse-based IDE. In their case, they call it “Simplicity
Studio”. While Simplicity is the best of those IDEs, it does leave those of us
who do not love Eclipse with few solutions. Here, I …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://interrupt.memfault.com/blog/the-best-and-worst-mcu-sdks">https://interrupt.memfault.com/blog/the-best-and-worst-mcu-sdks</a></em></p>]]>
            </description>
            <link>https://interrupt.memfault.com/blog/the-best-and-worst-mcu-sdks</link>
            <guid isPermaLink="false">hacker-news-small-sites-25094956</guid>
            <pubDate>Sat, 14 Nov 2020 19:35:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I made 16 free slides templates based on bestseller online courses]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25094512">thread link</a>) | @jrleonr
<br/>
November 14, 2020 | https://slideslist.com/about | <a href="https://web.archive.org/web/*/https://slideslist.com/about">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

                <p>When you search for premium templates for online courses and start looking at the slides, what do you find? </p>

                <p>Fancy graphs. Big numbers. Animations. Stats. World Maps.</p>

                <p>So if you want to create your own online course and teach it using slides, you may think you have to
                    use that.</p>

                  <p>  <strong>Wrong.</strong></p>

                <p>I decided to analyze the best courses and webinars out there from people that are making thousands of dollars, some of them, even millions. I wanted 
                        to understand what type of slides and visuals the top content creators were using.</p>

                <p>I was very surprised after analyzing a couple of them.</p>

                <p>No fancy graphs. No stats, no world maps, no bright and shiny visuals.</p>

                <p>So I checked more. </p>

                <p>I went through 37 top online courses and webinars and... all the slides were fairly simple.</p>

                <p><strong>Here are the 10 types of slides that professional content creators are using for their online
                        courses. And this is all you need to create yours.</strong></p>

                <h3>1. The Main Title</h3>
                <p>This is where you present your course, the title of your lesson, or the main idea for your webinar.
                </p>

                <p><img src="https://d3clwvzq39rwxi.cloudfront.net/cab4dafb-2cb0-482c-b73c-7ca5fd76d81d/images/slidespics/cover.png" alt="cover"></p><h3>2. What are you going to learn slide</h3>

                <p>Here you introduce what's coming. People like to know what to expect from the lesson or for the
                    webinar. Normally 3 main points work best.</p>

                <p><img src="https://d3clwvzq39rwxi.cloudfront.net/cab4dafb-2cb0-482c-b73c-7ca5fd76d81d/images/slidespics/whatyou.png" alt="cover"></p><h3>3. Where are we in the course</h3>

                <p>A reminder of the situation of the student, how far are we within the lesson, within the module, or
                    within the course.</p>


                <p><img src="https://d3clwvzq39rwxi.cloudfront.net/cab4dafb-2cb0-482c-b73c-7ca5fd76d81d/images/slidespics/whereare.png" alt="cover"></p><h3>4. Alternative Title</h3>

                <p>Similar to the main title, but almost all courses have an alternative way to show another title.</p>

                <p><img src="https://d3clwvzq39rwxi.cloudfront.net/cab4dafb-2cb0-482c-b73c-7ca5fd76d81d/images/slidespics/alttitle.png" alt="cover"></p><h3>The Content</h3>

                <p>There are different ways on how to go about teaching the material, these are the slides used for
                    that:</p>

                <h3>5. A one-line concept</h3>

                <p>Use to explain one concept or idea. You show it on the screen and explain it further talking over it.
                    It goes along with a number generally.</p>


                <p><img src="https://d3clwvzq39rwxi.cloudfront.net/cab4dafb-2cb0-482c-b73c-7ca5fd76d81d/images/slidespics/pilar.png" alt="cover"></p><h3>6. A photo on the left (or right) with a text</h3>

                <p>It could be a photo of a phone or tablet with some freebies you are offering. A photo of a person.
                    Uses go from telling people to wait until the end of the webinar, showing a testimonial, or telling
                    a story.</p>

                <p><img src="https://d3clwvzq39rwxi.cloudfront.net/cab4dafb-2cb0-482c-b73c-7ca5fd76d81d/images/slidespics/leftphoto.png" alt="cover"></p><h3>7. The Big Photo</h3>

                <p>Similar that the previous one. A very common use for this is to show a picture of something
                    funny.</p>
                <p><img src="https://d3clwvzq39rwxi.cloudfront.net/cab4dafb-2cb0-482c-b73c-7ca5fd76d81d/images/slidespics/bigphoto.png" alt="cover"></p><h3>8. Long Text</h3>

                <p>Sometimes you need more text, and this is what this slide is about, to make people read. That's not
                    recommended, but sometimes could be useful.</p>
                <p><img src="https://d3clwvzq39rwxi.cloudfront.net/cab4dafb-2cb0-482c-b73c-7ca5fd76d81d/images/slidespics/titletext.png" alt="cover"></p><h3>9. A quote</h3>


                <p>Almost 100% of the courses I analyzed have quotes.</p>

                <p><img src="https://d3clwvzq39rwxi.cloudfront.net/cab4dafb-2cb0-482c-b73c-7ca5fd76d81d/images/slidespics/quote.png" alt="cover"></p><h3>10. Wrap up</h3>


                <p>A list of the previous one-line concepts into one full slide where you can give a resume of
                    everything you talked about. Very useful to wrap-up your lesson.</p>

                <p><img src="https://d3clwvzq39rwxi.cloudfront.net/cab4dafb-2cb0-482c-b73c-7ca5fd76d81d/images/slidespics/resume.png" alt="cover"></p><p>If you don't want to create them yourself, <a href="https://slideslist.com/">feel free to use all of them</a>, so you can have a starting point to create your online course or
                webinar. If you want to remove the attribution <a href="https://slideslist.com/pricing"> buy a license</a>.</p>


                <h2>
                    Who is behind this project?
                </h2>
                <p>
                    I am José León, <a target="_blank" href="https://twitter.com/jrleonr">follow me on
                        twitter</a> to get updates on this project and futre projects.
                    if you want to support this project and help me create my templates, <a href="https://slideslist.com/pricing">buy a license</a>    or
                    consider <a target="_blank" href="https://www.buymeacoffee.com/jrleonr">buying me a
                        coffee</a>.
                </p>

          

            </div></div>]]>
            </description>
            <link>https://slideslist.com/about</link>
            <guid isPermaLink="false">hacker-news-small-sites-25094512</guid>
            <pubDate>Sat, 14 Nov 2020 18:45:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No, “Open Source” Does Not Mean “Includes Free Support”]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25093881">thread link</a>) | @bluegopher
<br/>
November 14, 2020 | https://raccoon.onyxbits.de/blog/bugreport-free-support/ | <a href="https://web.archive.org/web/*/https://raccoon.onyxbits.de/blog/bugreport-free-support/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
      We need to talk.
    </p><div>

<p>Here’s a paraphrased conversation I’m having way to often, costing me way too much time, keeping me from doing things that are way more important:</p>

<pre>User: Hi, I'd like to report a bug in your application.
Me:   Great! Please open a support ticket, then.
User: But, it looks like I need to pay for that?
Me:   So?
User: I just want to tell you that your app is broken, so you can fix it.
Me:   Yes, that's a support request, please open a ticket.
User: ...
</pre>

<figure>
  <a href="https://raccoon.onyxbits.de/blog/bugreport-free-support/bugreport.png">
    <img src="https://raccoon.onyxbits.de/blog/bugreport-free-support/bugreport.png">
  </a>
  
</figure><p>
                             
                             
From there it typically derails into a whiny tirade about me being a crappy two bit developer who doesn’t give a shit about his code (which is ridiculous, since, professional pride aside, I have every incentive to fix bugs, to prevent my inbox from getting flooded) and just wants to rip off his users.</p>

<p>In the past, I sometimes gave in (when it sounded like something might be wrong). I looked at the issue and almost always found that nothing was broken, just didn’t work as expected (which is actually to be expected for every reasonably complex piece of software). The user just didn’t bother reading the docs and tried to bypass the fee by masquerading the support request as a bug report. So, nowadays my policy simply is: no support ticket, no service. Any such request goes straight to the trash folder without even being looked at.</p>

<h2 id="why-am-i-such-an-asshole">Why am I such an asshole?</h2>

<p>Here’s the thing: I write open source software to solve <strong>my problem</strong>. I let you use my solutions because that comes at zero cost for me (well, almost, I still have to pay for the website, you are downloading from. You are welcome, by the way). I also provide the source code, so you can fix things yourself, should my solution turn out to be unsuitable. However, once you come to me with a “bugreport” that doesn’t also include a patch (or at least very precisely pinpoints the problem), then you are basically asking me to <strong>look at your problem</strong>. At this point, it is no longer zero cost for me and that’s the reason for why I am charging you money: you are asking me to spent time on your behalf. That is commonly called <strong>work</strong>. And surprisingly enough, work is what people expect to be paid for.</p>

<p>Don’t get me wrong. I’m happy to help. Selling support is what keeps the lights on here (did I mention the cost of running a webserver?). But coming to me under false pretense and/or expecting that I <strong>must</strong> provide free service on top of a software I gave away without charge is not going to win you any favours.</p>

<p>It stops being free, when it starts costing me! My time is valuable. If you want a piece of it, I want money in return. Period.</p>

<p><strong>UPDATE:</strong> Seems like this post has struck a nerve and caused a few misunderstandings. <a href="https://raccoon.onyxbits.de/blog/reactions-bugreport-free-support/">Clarification on my position here</a>.</p>
</div></div>]]>
            </description>
            <link>https://raccoon.onyxbits.de/blog/bugreport-free-support/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25093881</guid>
            <pubDate>Sat, 14 Nov 2020 17:37:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Microservice Herds, Cliques of Services, and Flocks of People]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25093811">thread link</a>) | @rpwilcox
<br/>
November 14, 2020 | https://blog.wilcoxd.com/2020/10/24/Herds-Of-Microservices-Flocks-Of-People/ | <a href="https://web.archive.org/web/*/https://blog.wilcoxd.com/2020/10/24/Herds-Of-Microservices-Flocks-Of-People/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
<p>I’ve been in big enterprises, as a day job, for almost 6 years now. I’ve also been working on, and growing, a large scale microservice architecture (about 150 microservices) for about 18 months.</p>
<p>In one way microservices give large enterprises the ability to split large work across a variety of teams with isolated codebases. If the published APIs for these microservices don’t change, none of the producers or consumers into that service care about maintenance or features added to that service.</p>
<p>Yet the working of the product as a whole requires all the micoservices to be deployed, with compatible versions, into the deployment environments.</p>
<p>From a high level perspective it doesn’t matter if these services communicate via HTTPS, protobuf, custom TCP protocols, or message buses like Kafka or an MQ flavor. Microservice A still acts on data that’s supposed to be created by Microservice B, and if it’s not there the user’s going to wonder.</p>
<p>If a user posts a photo on a social network type product, and it doesn’t show up after a couple of seconds the user gets worried. If it doesn’t show up ever - because Microservice A posted the photo to some message queue but Microservice B wasn’t deployed to read and respond to the message - that’s actually a bug. As much as a dialog box in the users face would be.</p>
<p>That dependence: Microservice A requires microservice B, which requires microservice C, all deployed for the product <em>and customer’s user journey</em> to work together, is why it’s called a “herd” of microservices. (or a web of microservices, but herd is the more industry-common name).</p>

<p>Enterprise software engineering is waayyy different from startups. Before my time in BigCo land I spent a lot of time in “small projects and startups” land.</p>
<p>I enumerate some of this article’s assumptions here, assuming they are close to universal. My sample size is small, but I don’t think I just got (un) lucky in my experiences:</p>
<ol>
<li>Of &gt; 500 engineers. Some of which work on things totally unknown to you!</li>
<li>codebases owned by teams. (Because in BigCos having a thing owned by a single person makes people antsy, at least in the BigCos I’ve been in. And having a single group of people makes it easy to <em>page them</em>).</li>
<li>Multiple teams per end user project.</li>
<li>The enterprise is now trying to - or successfully have - transitioned to microservices.</li>
<li>Unified discovery or apparent similar route (“oh look the /search api!“. Maybe behind the curtain it’s 5 teams with 20 microservices or lambdas - whatever, the caller doesn’t know or care)</li>
<li>Microservices can be grouped by what downstream or peer services they call or rely on. (The next section will talk about this cluster or “clique” effect)</li>
</ol>
<p>Note: it’s possible - but exceptional - for a microservice to <em>not</em> have an owner. Perhaps the team owning it all got laid off, or all quit before replacements could be hired. From a corporate perspective this is bad - a year or two from now when that microservice breaks, you’ll have a game of hot potato around who needs to fix it… on the double because there’s some customer facing bug. It’s also, very likely, making teams that depend on those microservices nervous, because, “ummm, who <em>is</em> maintaining the Ad Data Repository that we interface with? Ummm…”</p>
<p>Likewise, it’s possible - but should be exceptional - for a microservice to have <em>two</em> owners. In my experience this means you’re either starting to rebuild a monolith, or introducing situations where Team A doesn’t want to deploy but Team B does.</p>

<p>If we consider all the microservices required for a product - or products - to be a herd of microservices you’ll notice something. You’ll notice that these herds form microservice <em>cliques</em> - the login service only talks to the auth database and the email service, but never the file upload service, for example.</p>
<p>Additionally (because this is the enterprise) teams, not individuals, own services. A team may potentially own the majority of services in a clique, or a couple of cliques. If the enterprise is wise there may be some domain drive design modeling going on to better classify these cliques.</p>
<p>I suspect there are three, maybe four, ways to split up the enterprise to serve a product (or multiple products).</p>

<p>Note that the stars in these pictures may be microservices, but could be front end library components.</p>
<h2>Single product, layered approach</h2>
<p><span>
      <a href="https://blog.wilcoxd.com/static/03b09b8d813492183507406525ea217d/8c381/one-big-product-layer-teams.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="single product, layered" title="single product, layered" src="https://blog.wilcoxd.com/static/03b09b8d813492183507406525ea217d/fcda8/one-big-product-layer-teams.png" srcset="https://blog.wilcoxd.com/static/03b09b8d813492183507406525ea217d/12f09/one-big-product-layer-teams.png 148w,
https://blog.wilcoxd.com/static/03b09b8d813492183507406525ea217d/e4a3f/one-big-product-layer-teams.png 295w,
https://blog.wilcoxd.com/static/03b09b8d813492183507406525ea217d/fcda8/one-big-product-layer-teams.png 590w,
https://blog.wilcoxd.com/static/03b09b8d813492183507406525ea217d/efc66/one-big-product-layer-teams.png 885w,
https://blog.wilcoxd.com/static/03b09b8d813492183507406525ea217d/c83ae/one-big-product-layer-teams.png 1180w,
https://blog.wilcoxd.com/static/03b09b8d813492183507406525ea217d/8c381/one-big-product-layer-teams.png 1267w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<p>This organization has teams close to the user, and teams creating services uncoupled from any one product. Imagine the teams working on our social media app, and the a “data platforms” team that handles hard data storage, vendor data imports, or interfaces to the real source of records.</p>
<p>This is very likely Conway’s Law at play: the database team maintains the big database, and (because enterprise) everything currently flows through the big database. This big database is the Source Of Record.</p>
<h3>Another lens</h3>
<p><a href="https://www.amazon.com/Scaling-Teams-Strategies-Successful-Organizations/dp/149195227X/ref=nodl_">Scaling Teams</a> talks about these teams as potentially being part of a platform. Platform in the most generic of words: “the iOS team”, “the web team”, “the android team”. The “APIs” are provided by folks working on “the backend team”.</p>
<p>Yet the diagram still works for this structure of teams. Chapter 7 of <em>Scaling Teams</em> touches on several themes also in this blog entry.</p>
<h2>Many products, layered approach</h2>
<p><span>
      <a href="https://blog.wilcoxd.com/static/7deeaed6498bb17b4db7ce62b688b698/f470a/couple-of-products.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="multiple products, layered" title="multiple products, layered" src="https://blog.wilcoxd.com/static/7deeaed6498bb17b4db7ce62b688b698/fcda8/couple-of-products.png" srcset="https://blog.wilcoxd.com/static/7deeaed6498bb17b4db7ce62b688b698/12f09/couple-of-products.png 148w,
https://blog.wilcoxd.com/static/7deeaed6498bb17b4db7ce62b688b698/e4a3f/couple-of-products.png 295w,
https://blog.wilcoxd.com/static/7deeaed6498bb17b4db7ce62b688b698/fcda8/couple-of-products.png 590w,
https://blog.wilcoxd.com/static/7deeaed6498bb17b4db7ce62b688b698/efc66/couple-of-products.png 885w,
https://blog.wilcoxd.com/static/7deeaed6498bb17b4db7ce62b688b698/c83ae/couple-of-products.png 1180w,
https://blog.wilcoxd.com/static/7deeaed6498bb17b4db7ce62b688b698/f470a/couple-of-products.png 1443w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<p>Here we have multiple products. Notice that some products aren’t connected to the rest of the herd. Product B is somewhat connected: think how Instagram uses Facebook for authorization, but that’s it.</p>
<h2>Cross functional teams</h2>
<p>Cross functional teams aren’t super new - I heard about them when I was in Total Quality Management classes in college.</p>
<p><span>
      <a href="https://blog.wilcoxd.com/static/7f84f9cd965c4d23f80eff6d50ea3e1b/636d3/cross-functional-teams.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="full stack" title="full stack" src="https://blog.wilcoxd.com/static/7f84f9cd965c4d23f80eff6d50ea3e1b/fcda8/cross-functional-teams.png" srcset="https://blog.wilcoxd.com/static/7f84f9cd965c4d23f80eff6d50ea3e1b/12f09/cross-functional-teams.png 148w,
https://blog.wilcoxd.com/static/7f84f9cd965c4d23f80eff6d50ea3e1b/e4a3f/cross-functional-teams.png 295w,
https://blog.wilcoxd.com/static/7f84f9cd965c4d23f80eff6d50ea3e1b/fcda8/cross-functional-teams.png 590w,
https://blog.wilcoxd.com/static/7f84f9cd965c4d23f80eff6d50ea3e1b/efc66/cross-functional-teams.png 885w,
https://blog.wilcoxd.com/static/7f84f9cd965c4d23f80eff6d50ea3e1b/c83ae/cross-functional-teams.png 1180w,
https://blog.wilcoxd.com/static/7f84f9cd965c4d23f80eff6d50ea3e1b/636d3/cross-functional-teams.png 1222w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<p>But the idea here is that a “two pizza team” should be empowered to change everything about some sliver of functionality from the UI all the way down the stack. Because - an often quoted definition - an agile feature isn’t shipped until a user <em>sees</em> it.</p>
<p>I would also posit that these cross-functional teams don’t break Conway’s Law, but may graft a cross-functional layer on top of the existing org structure.</p>
<p>Likewise, I suspect this approach means you have an implicit layered model too. Perhaps you have services created using the <a href="https://docs.microsoft.com/en-us/azure/architecture/patterns/backends-for-frontends">Backend For Frontend</a> design pattern. Our example social media enterprise might have a BFF microservice that supplies data for the mobile app, and a “data layer” service… which a BFF microservice for the Alexa app uses. I attempt to illustrate that in the diagram, in fact.</p>
<p>I’m not convinced GraphQL solves this problem either - you may have queries and mutations used heavily by some other team too.</p>

<p>Regardless of how your org chart really looks, if - and since - teams are coupled to microservices you can either make your system design look like your org chart <em>or</em> facade over that org chart. Either way you can draw a box around microservice owners and (hopefully!) find edges of parts of your business domain. Or, if that doesn’t work, find the cliques and draw boxes around <em>them</em>.</p>
<h2>on data, technical debt as a metaphor, and other cross cutting concerns</h2>
<p>Take a look back at those diagrams. Notice the different database organizations of the various structures. A layered organization will likely have <em>only</em> one or two databases controlled by the product teams (for “closeness of data” or “only <em>we</em> care about this particular part of the data”) where the teams downstream are the “source of record”.</p>
<p>In a fully cross-functional example there <em>is</em> no “downstream”. Yet the organization still has data to store, maintain and guard. Teams may create a database or two, or one per microservice, to store this data. Yet I would argue that “data standards” is an enterprise wide concern. Is the data secured in transmit and rest, potentially using approved data storage tech, with proper access rights? No enterprise wants a privacy leak and lawsuit like Target or Equifax.</p>
<p>So, how does an enterprise, or a group of teams working on a single product inside the enterprise, establish data standards?</p>
<p>Likewise, how does “technical debt” - perhaps “oh yeah we should secure this database, it’s some technical debt we need to clean up” of a microservice, of a clique, affect the herd? Or the product? Or the business?</p>
<p>In fact, I’m starting to dislike the analogy of technical debt, and starting to lean into the idea of the <a href="https://twitter.com/jessitron/status/1314311394406346752?s=21">functional capability</a> of a system.</p>
<p>In the US there’s often both bad roads and lots of road construction, so the model of functional capacity of a system being <strong>a road to deliver the customer journey</strong> feels natural to me.</p>
<p>If our journey is to drive features to the customer, then we want well paved roads so we can drive quickly, not dirt roads where 35MPH is all you can go. We also want certain, built in, abilities of the road: smooth ride, experts on call in case we break a tire (or a database!), and potentially some kind of guidance to ensure our car is safe to use on the road and not harming others or the environment (like spewing customer data everywhere).</p>
<p>This is the topic of a future blog post: roads and feature capacity of microservice herds. Which will be a much easier conversation to have now that we understand microservices, cliques, herds, products, teams, and how enterprises mash those concepts up in different ways.</p></section></div>]]>
            </description>
            <link>https://blog.wilcoxd.com/2020/10/24/Herds-Of-Microservices-Flocks-Of-People/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25093811</guid>
            <pubDate>Sat, 14 Nov 2020 17:28:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don't make customers think about whether they should pay you]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 9 (<a href="https://news.ycombinator.com/item?id=25093628">thread link</a>) | @krewast
<br/>
November 14, 2020 | https://www.krewast.de/artikel/dont-make-customers-think-about-whether-they-should-pay-you/ | <a href="https://web.archive.org/web/*/https://www.krewast.de/artikel/dont-make-customers-think-about-whether-they-should-pay-you/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><div><h2 id="because-they-probably-wont">…because they probably won’t</h2><p>I recently watched a few videos on YouTube about the latest and greatest LEGO sets. I didn’t do it because I’m super interested in LEGO (that was a while ago) but because the YouTube algorithm decided that I had to. I naturally obeyed. The results were as expected: I felt old and none of those sets triggered any kind of “I need to have this” response. Until I saw this:</p><p><img src="https://www.krewast.de/img/artikel-lego-tree-house.jpg" alt="Lego Tree House"></p><p>This beautiful tree house immediately sparked my interest. It’s cute, it’s not one of those boring license sets (Star Wars, Harry Potter, Minecraft, …), the price to number of LEGO pieces ratio is okay (still super expensive!) and it would fit nicely between my house plants which I foster - and sometimes kill - in my living room.</p><p>So, I did something I usually never do: I made an impulse buy. I put the 195&nbsp;€ tree house into the shopping cart, created a LEGO user account, entered all my data, chose “Invoice” as payment method and clicked “Buy”. I received the automatic “Thank you for your purchase” e-mail and felt happy.</p><h2 id="we-are-sorry">We are sorry</h2><p>On the next day I received another e-mail. This time from the LEGO customer service. You can find the original German version at the end of this post, here is a short translation of the important part:</p><blockquote>Dear Bastian Kres,<p>thank you for ordering your LEGO® toy directly from us.</p><p>Unfortunately, the total amount of your order exceeds the credit limit for payment on account and by direct debit. Therefore, we are not able to send this order yet.</p><p>Please call us to pay by VISA or MasterCard. […]</p></blockquote><p>Well, here’s the thing: LEGO knew that I was a first time customer and they also knew that the total amount of my order was about 195 €. If they didn’t want me to pay on account, why did they offer me the option?</p><h2 id="how-to-kill-enthusiasm">How to kill enthusiasm</h2><p>1.) I would like to mention that wouldn’t have had a problem to pay in advance. PayPal or credit card are good options which I use all the time. But by sending me this e-mail after I already selected my preferred payment method and ordered the thing, LEGO basically tells me that I cannot be trusted. And at the same time they want me to trust them…</p><p>2.) As I wrote before, this purchase was an impulse buy. The tree house is something I wanted. But after receiving this e-mail I had lot of time to think about whether or not I still do? Especially because I could buy a huge amount of real plants for 195&nbsp;€. That would be good for nature, but bad for LEGO.</p><p>3.) By postponing the delivery until after I paid, they also created a whole new experience for me. Now I don’t have the tree house in my hands, see how nice it is and pay happily. No, now I have this bitter taste in my mouth and a decision to make. Should I really be making decisions after I already ordered something?</p><h2 id="some-lessons-for-online-stores">Some lessons for online stores</h2><p>As a web developer I always find it interesting to see how even very big companies still make mistakes like this. But the good thing is: We can learn from them!</p><ul><li>Make it easy for customers to order from you, avoid any friction or inconveniences</li><li>Offer customers a broad set of payment options, omit those you deem too risky</li><li>Don’t send customers “We don’t trust you” messages after they already ordered something from you. It totally kills their enthusiasm</li></ul><p>And that’s it.</p><p>One last question remains: Did LEGO dodge a bullet because I would have sent the tree house back anyway? Maybe, but probably not. I rarely send anything back for two reasons: It’s an effort and I’m generally lazy ;)</p><p>If any of this sound snarky: I’m sorry, that was never my intention. I just found it interesting (and wanted to share) how LEGO decided to set up this process, what consequences it can have and how I probably won’t get a new toy but at least ten new house plants.</p><hr><p>Obligatory link to <a href="https://www.youtube.com/channel/UC_EZd3lsmxudu3IQzpTzOgw" target="_blank" rel="nofollow noopener">Held der Steine</a> and his <a href="https://www.youtube.com/watch?v=nIQJV2o6EPY" target="_blank" rel="nofollow noopener">LEGO Tree House</a> video.</p><h2 id="the-original-german-e-mail">The original German e-mail</h2><blockquote>Guten Tag Bastian Kres,<p>vielen Dank, dass Sie Ihr LEGO® Spielzeug direkt bei uns bestellt haben.</p><p>Leider überschreitet die Gesamtsumme Ihrer Bestellung die Kreditgrenze für Zahlung auf Rechnung und per Lastschriftverfahren. Daher können wir diese Bestellung leider noch nicht abschicken.</p><p>Bitte rufen Sie uns an, um per VISA oder MasterCard zu bezahlen. Sie erreichen uns von Montag bis Freitag von 9 bis 21 Uhr aus dem Festnetz gebührenfrei unter 00800 5346 1111. Aus Sicherheitsgründen sollten Sie Ihre Kreditkartendaten nie per E-Mail oder Brief weitergeben.</p><p>Oder Sie zahlen den Betrag im Voraus auf unser Konto ein:</p><p>[…]</p><p>Sobald wir Ihre Zahlung verbucht haben, geben wir Ihre Bestellung automatisch zum Versand frei.</p><p>Wir möchten Sie um Verständnis für diese Maßnahme bitten und hoffen, Ihnen damit nicht zu viele Umstände bereitet zu haben.</p><p>Bitte melden Sie sich gerne auch mit Rückfragen zu Ihrer Bestellung unter der oben angegebenen Nummer.</p><p>Herzliche Grüße,</p><p>Ihr LEGO Kundenservice</p></blockquote><div id="call-to-action-kontakt"><hr><p>Fragen, Wünsche, Anregungen? Webentwickler aus Regensburg gesucht? Schreiben Sie mir einfach!</p><p><a href="https://www.krewast.de/#kontakt">Kontakt</a></p></div></div></div></div></section></div>]]>
            </description>
            <link>https://www.krewast.de/artikel/dont-make-customers-think-about-whether-they-should-pay-you/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25093628</guid>
            <pubDate>Sat, 14 Nov 2020 17:08:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Going Bark: A Furry’s Guide to End-to-End Encryption]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25093505">thread link</a>) | @quyleanh
<br/>
November 14, 2020 | https://soatok.blog/2020/11/14/going-bark-a-furrys-guide-to-end-to-end-encryption/ | <a href="https://web.archive.org/web/*/https://soatok.blog/2020/11/14/going-bark-a-furrys-guide-to-end-to-end-encryption/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<p>Governments are back on their anti-encryption bullshit again.</p>



<p>Between the <a href="https://blog.cryptographyengineering.com/2020/03/06/earn-it-is-an-attack-on-encryption/">U.S. Senate’s “EARN IT” Act</a>, the <a href="https://www.eff.org/deeplinks/2020/10/orders-top-eus-timetable-dismantling-end-end-encryption">E.U.’s slew of anti-encryption proposals</a>, and <a href="https://fee.org/articles/australia-s-unprecedented-encryption-law-is-a-threat-to-global-privacy/">Australia’s new anti-encryption law</a>, it’s become clear that the authoritarians in office view online privacy as a threat to their existence.</p>



<p>Normally, when the governments increase their anti-privacy sabre-rattling, technologists start talking more loudly about Tor, Signal, and other privacy technologies (usually only to be drowned out by paranoid people who think Tor and Signal are government backdoors or something stupid; conspiracy theories ruin everything!).</p>



<p><strong>I’m not going to do that.</strong></p>



<p>Instead, I’m going to show you how to add end-to-end encryption to any communication software you’re developing. (Hopefully, I’ll avoid making <a href="https://soatok.blog/2020/10/28/bizarre-design-choices-in-zooms-end-to-end-encryption/">any bizarre design decisions</a> along the way.)</p>



<p>But first, some important disclaimers:</p>



<ol><li><strong>Yes, you should absolutely do this.</strong> I don’t care how banal your thing is; if you expect people to use it to communicate with each other, you should make it so that you can never decrypt their communications.</li><li>You should absolutely NOT bill the thing you’re developing as an <em>alternative</em> to Signal or WhatsApp.</li><li>The goal of doing this is to increase the amount of end-to-end encryption deployed on the Internet that the service operator cannot decrypt (even if compelled by court order) and make E2EE normalized. The goal is NOT to compete with highly specialized and peer-reviewed privacy technology.</li><li>I am not a lawyer, I’m some furry who works in cryptography. The contents of this blog post is not legal advice, nor is it endorsed by any company or organization. Ask the <a href="https://eff.org/">EFF</a> for legal questions.</li></ol>



<p>The organization of this blog post is as follows: First, I’ll explain <a href="#symmetric-key-encryption">how to encrypt and decrypt data between users</a>, assuming you have a key. Next, I’ll explain <a href="#key-agreement">how to build an authenticated key exchange</a> and <a href="#session-key-management">a ratcheting protocol to determine the keys used in the first step</a>. Afterwards, I’ll explore <a href="#identity-key-management">techniques for binding authentication keys to identities and managing trust</a>. Finally, I’ll discuss <a href="#backdoor-resistance">strategies for making it impractical to ever backdoor your software (and impossible to silently backdoor it)</a>, just to piss <a href="https://en.wikipedia.org/wiki/Five_Eyes">the creeps and tyrants of the world</a> off even more.</p>



<p>You don’t have to implement the full stack of solutions to protect users, but the further you can afford to go, the safer your users will be from privacy-invasive policing.</p>







<h2 id="preliminaries">Preliminaries</h2>



<h3 id="choosing-a-cryptography-library">Choosing a Cryptography Library</h3>



<p>In the examples contained on this page, I will be using the <a href="https://libsodium.gitbook.io/doc/">Sodium cryptography library</a>. Specifically, my example code will be written with the <a href="https://github.com/paragonie/sodium-plus">Sodium-Plus</a> library for JavaScript, since it strikes a good balance between performance and being cross-platform.</p>


<pre title="">const { SodiumPlus } = require('sodium-plus');

(async function() {
     // Select a backend automatically
     const sodium = await SodiumPlus.auto();
     
     // Do other stuff here
})();
</pre>


<p>Libsodium is <a href="https://latacora.micro.blog/2018/04/03/cryptographic-right-answers.html">generally the correct choice for developing cryptography features in software</a>, and is available in most programming languages,</p>



<p>If you’re prone to choose a different library, you should consult your cryptographer (and yes, you should have one on your payroll if you’re doing things different) about your design choices.</p>



<h3>Threat Modelling</h3>



<p>Remember above when I said, “You don’t have to implement the full stack of solutions to protect users, but the further you can afford to go, the safer your users will be from privacy-invasive policing”?</p>



<p>How far you go in implementing the steps outlined on this blog post should be informed by <a href="https://adamcaudill.com/2016/07/20/threat-modeling-for-applications/">a threat model</a>, not an ad hoc judgment.</p>



<p>For example, if you’re encrypting user data and storing it in the cloud, you probably want to pass <a href="https://blog.cryptographyengineering.com/2012/04/05/icloud-who-holds-key/">the Mud Puddle Test</a>:</p>



<blockquote><div><p>1. First, drop your device(s) in a mud puddle.<br>2. Next, slip in said puddle and crack yourself on the head. When you regain consciousness you’ll be perfectly fine, but<em>&nbsp;won’t for the life of you&nbsp;</em>be able to&nbsp;recall your device passwords or keys.<br>3. Now try to get your cloud data back.</p><p>Did you succeed? If so, you’re screwed. Or to be a bit less dramatic, I should say: your cloud provider has access to your ‘encrypted’ data, as does the government if they want it, as does any rogue employee who knows their way around your provider’s internal policy checks.</p></div><cite>Matthew Green describes the Mud Puddle Test, which Apple products <a href="https://sneak.berlin/20201112/your-computer-isnt-yours/">definitely don’t pass</a>.</cite></blockquote>



<p>If you must fail the Mud Puddle Test for your users, make sure you’re clear and transparent about this in the documentation for your product or service.</p>







<h2 id="symmetric-key-encryption">I. Symmetric-Key Encryption</h2>



<p>The easiest piece of this puzzle is to encrypt data in transit between both ends (thus, satisfying the loosest definition of end-to-end encryption).</p>



<p>At this layer, you already have some kind of symmetric key to use for encrypting data before you send it, and for decrypting it as you receive it.</p>



<p>For example, the following code will encrypt/decrypt strings and return hexadecimal strings with a version prefix.</p>


<pre title="">const VERSION = "v1";

/**
 * @param {string|Uint8Array} message
 * @param {Uint8Array} key
 * @param {string|null} assocData
 * @returns {string}
 */
async function encryptData(message, key, assocData = null) {
    const nonce = await sodium.randombytes_buf(24);
    const aad = JSON.stringify({
      'version': VERSION,
      'nonce': await sodium.sodium_bin2hex(nonce),
      'extra': assocData
    });

    const encrypted = await sodium.crypto_aead_xchacha20poly1305_ietf_encrypt(
        message,
        nonce,
        key,
        aad
    );
    return (
       VERSION +
       await sodium.sodium_bin2hex(nonce) +
       await sodium.sodium_bin2hex(encrypted)
    );
}

/**
 * @param {string|Uint8Array} message
 * @param {Uint8Array} key
 * @param {string|null} assocData
 * @returns {string}
 */
async function decryptData(encrypted, key, assocData = null) {
    const ver = encrypted.slice(0, 2);
    if (!await sodium.sodium_memcmp(ver, VERSION)) {
        throw new Error("Incorrect version: " + ver);
    }
    const nonce = await sodium.sodium_hex2bin(encrypted.slice(2, 50));
    const ciphertext = await sodium.sodium_hex2bin(encrypted.slice(50));
    const aad = JSON.stringify({
      'version': ver,
      'nonce': encrypted.slice(2, 50),
      'extra': assocData
    });
    
    const plaintext = await sodium.crypto_aead_xchacha20poly1305_ietf_decrypt(
        ciphertext,
        nonce,
        key,
        aad
    );
    return plaintext.toString('utf-8');
}
</pre>


<p>Under-the-hood, this is using <a href="https://soatok.blog/2020/07/12/comparison-of-symmetric-encryption-methods/#aes-gcm-vs-xchacha20poly1305">XChaCha20-Poly1305</a>, which is less sensitive to timing leaks than AES-GCM. However, like AES-GCM, this encryption mode doesn’t provide <a href="https://eprint.iacr.org/2019/016">message- or key-commitment</a>.</p>



<p>If you want key commitment, you should derive two keys from <code>$key</code> using a KDF based on hash functions: One for actual encryption, and the other <a href="https://eprint.iacr.org/2020/1153">as a key commitment value</a>.</p>



<p>If you want message commitment, you can use AES-CTR + HMAC-SHA256 or XChaCha20 + BLAKE2b-MAC.</p>



<p>If you want both, ask <a href="https://mumble.net/~campbell/">Taylor Campbell</a> about his BLAKE3-based design.</p>



<p>A modified version of the above code with key-commitment might look like this:</p>


<pre title="">const VERSION = "v2";

/**
 * Derive an encryption key and a commitment hash.
 * @param {CryptographyKey} key
 * @param {Uint8Array} nonce
 * @returns {{encKey: CryptographyKey, commitment: Uint8Array}}
 */
async function deriveKeys(key, nonce) {
    const encKey = new CryptographyKey(await sodium.crypto_generichash(
        new Uint8Array([0x01].append(nonce)),
        key
    ));
    const commitment = await sodium.crypto_generichash(
        new Uint8Array([0x02].append(nonce)),
        key
    );
    return {encKey, commitment};
}

/**
 * @param {string|Uint8Array} message
 * @param {Uint8Array} key
 * @param {string|null} assocData
 * @returns {string}
 */
async function encryptData(message, key, assocData = null) {
    const nonce = await sodium.randombytes_buf(24);
    const aad = JSON.stringify({
      'version': VERSION,
      'nonce': await sodium.sodium_bin2hex(nonce),
      'extra': assocData
    });
    const {encKey, commitment} = await deriveKeys(key, nonce);

    const encrypted = await sodium.crypto_aead_xchacha20poly1305_ietf_encrypt(
        message,
        nonce,
        encKey,
        aad
    );
    return (
       VERSION +
       await sodium.sodium_bin2hex(nonce) +
       await sodium.sodium_bin2hex(commitment) +
       await sodium.sodium_bin2hex(encrypted)
    );
}

/**
 * @param {string|Uint8Array} message
 * @param {Uint8Array} key
 * @param {string|null} assocData
 * @returns {string}
 */
async function decryptData(encrypted, key, assocData = null) {
    const ver = encrypted.slice(0, 2);
    if (!await sodium.sodium_memcmp(ver, VERSION)) {
        throw new Error("Incorrect version: " + ver);
    }
    const nonce = await sodium.sodium_hex2bin(encrypted.slice(2, 50));
    const ciphertext = await sodium.sodium_hex2bin(encrypted.slice(114));
    const aad = JSON.stringify({
      'version': ver,
      'nonce': encrypted.slice(2, 50),
      'extra': assocData
    });
    const storedCommitment = await sodium.sodium_hex2bin(encrypted.slice(50, 114));
    const {encKey, commitment} = await deriveKeys(key, nonce);
    if (!(await sodium.sodium_memcmp(storedCommitment, commitment))) {
        throw new Error("Incorrect commitment value");
    }
    
    const plaintext = await sodium.crypto_aead_xchacha20poly1305_ietf_decrypt(
        ciphertext,
        nonce,
        encKey,
        aad
    );
    return plaintext.toString('utf-8');
}
</pre>


<p>Another design choice you might make is to encode ciphertext with base64 instead of hexadecimal. That doesn’t significantly alter the design here, but it does mean your decoding logic has to accommodate this.</p>



<p>You SHOULD version your ciphertexts, and include this in the AAD provided to your AEAD encryption mode. I used “v1” and “v2” as a version string above, but you can use your software name for that too.</p>



<h2 id="key-agreement">II. Key Agreement</h2>



<p>If …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://soatok.blog/2020/11/14/going-bark-a-furrys-guide-to-end-to-end-encryption/">https://soatok.blog/2020/11/14/going-bark-a-furrys-guide-to-end-to-end-encryption/</a></em></p>]]>
            </description>
            <link>https://soatok.blog/2020/11/14/going-bark-a-furrys-guide-to-end-to-end-encryption/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25093505</guid>
            <pubDate>Sat, 14 Nov 2020 16:54:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Prestige Trap: finance, big tech, and consulting]]>
            </title>
            <description>
<![CDATA[
Score 291 | Comments 298 (<a href="https://news.ycombinator.com/item?id=25093349">thread link</a>) | @wdesilvestro
<br/>
November 14, 2020 | https://wesdesilvestro.com/the-prestige-trap | <a href="https://web.archive.org/web/*/https://wesdesilvestro.com/the-prestige-trap">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>For the past year, I've been on a leave of absence from college working on a startup. As I prepare for my return to school, what comes next has been on my mind.</p><p>Leaving college made me realize there are more career options than ever seemed available to me as a student. I would have expected that taking time off would have had the opposite effect—bringing me up to speed on the areas that interest me and those I should steer clear of. Naturally, the list of options should have winnowed after stepping outside of the college bubble. On the contrary, I find myself with dozens of ideas of things to work on, far more than what seemed possible in college.</p><p>College made it seem like there were just a few worthwhile career tracks. When I chose to take time off, I left in the middle of my junior year during the peak of on-campus recruiting, the process by which Harvard students compete for internships at a narrow list of companies. I say "narrow" to emphasize the fact that just three industries captured the attention of my peers: <strong>finance, big tech, and consulting (FTC)</strong>. When you subtract out the students attending grad school or who don't immediately enter the workforce, nearly half choose one of these fields.<sup id="fnref-1"><a href="#fn-1">1</a></sup> Why?</p><h3>Why FTC?</h3><p>The simplest explanation is money. Students want high-paying jobs and these are industries that pay higher on average. But it's naive to chalk all of this up to economics—there are many instances when students are offered an equally competitive job in terms of salary and still opt for FTC. I recall many different industries, such as consumer packaged goods companies, recruiting and offering salaries similar to entry-level management consulting—but they were seldom the talk of campus.</p><p>Neither is it interest. The average Harvard student would probably prefer to work on Google Maps over Kraft Mac &amp; Cheese, but this doesn't explain why students have such narrow interests <em>within</em> FTC. Why are Google and Facebook so attractive to prospective engineers while Stripe and Nvidia are never brought up? Or why do aspiring consultants obsess over McKinsey, Bain, and BCG to the exclusion of more boutique firms with similar compensation structures?<sup id="fnref-2"><a href="#fn-2">2</a></sup> Holding interest constant, students' decisions are still clustered around a few companies.</p><p>When discussing management consulting, many students talked about how they liked the "optionality" that the industry offered. In short, they viewed it as a few more years of college without the pressure to choose a particular career path. I think people felt similarly about finance and big tech—they didn't narrow your career trajectory in the same way a more niche company might have. But again, this doesn't explain why within FTC, students are still so fixated on a few specific companies.</p><p>When I asked my peers why they preferred these particular firms, they often answered that they were better than the rest of the industry. But by which logic are they better? When asked about the specifics, they'd often give vague non-answers that seemed almost scripted. "I like Bain because I feel like I have a good fit with the firm". Or, "Goldman is attractive to me because it has a culture of excellence." These answers were unsatisfying because it was clear they were ad hoc rationalizations. Thankfully, one student was once blunt enough to confirm what everyone already knew: "I want Google on my resume because it is prestigious." For most, these firms were top of mind because they were prestigious, not because they resonated particularly well with the individual applicant.</p><p>For students unsure of what career to pursue, prestige is often the driving metric in job selection. For many, prestige is useful in that it guarantees one is respected and admired for the job they ultimately choose. This explains the ad hoc rationalizations from before and why students often expressed interest in FTC before they even fully understood what their work would entail. it's like a kindergartener saying "doctor" when adults ask them what they want to be when they grow up. Their answer says more about the desires of the group than themselves.<sup id="fnref-3"><a href="#fn-3">3</a></sup></p><h3>What is Prestige?</h3><p>Prestige is a measure of how much status a group assigns to something. From this definition, a lot of interesting qualities of prestige can be discerned.</p><p>Since prestige depends upon what the <em>group</em> thinks, then it follows that it is not a fixed nor immutable quality. Groups of people differ everywhere, so what is prestigious in one place is not necessarily prestigious in another.</p><p>For example, many college students would love to work for a Silicon Valley startup—but I know of few Harvard students who prefer startups over big tech. Again, this isn't an economic decision—recruits of later-stage startups can command the same or even better compensation than FAANG in some cases—but I've never heard of a Harvard CS major wanting to work for Stripe.<sup id="fnref-4"><a href="#fn-4">4</a></sup> This is surprising since Stripe is prestigious <em>within</em> the Valley itself. Prestige's dependence on the group makes it a localized phenomenon.</p><p>Prestige also changes over time. What we considered prestigious a hundred years ago is very different from what we do today because social status has changed a lot. Understanding the evolution of social status is worthy of a whole separate essay (or perhaps a book). However, I suspect that prestige is closely linked to our economy and thus downstream of culture, policy, and most of all, technology. This would explain why it's more prestigious to start a startup today than it was a hundred years ago—one can simply become a lot richer than they could before.</p><h3>The Roots of Prestige</h3><p>So if prestige depends upon what people find to be high status, then where does it originate in the first place? That is, how does a group come to deem something prestigious initially? The best <a href="http://www.paulgraham.com/love.html">explanation</a> for prestige I've seen thus far comes from Paul Graham:</p><blockquote><p>"Prestige is just fossilized inspiration. If you do anything well enough, you'll <em>make</em> it prestigious. Plenty of things we now consider prestigious were anything but at first. Jazz comes to mind—though almost any established art form would do. So just do what you like, and let prestige take care of itself."</p></blockquote><p>Groups assign status to the things which accurately signal the values and aspirations of that group. For elite college students, FTC originally became prestigious because they represented the height of excellence in the workforce at some point—something this group deeply values.</p><p>Each of the top companies within FTC once transformed their industries, inspiring the ambitious to follow suit. For example, James McKinsey <a href="https://longreads.com/2013/10/23/the-making-of-mckinsey-a-brief-history-of-management/">invented</a> managerial accounting and dramatically improved his clients' budgeting processes. Goldman employees <a href="https://www.goldmansachs.com/our-firm/history/a-brief-history-of-gs.pdf">pioneered</a> the price-to-earnings ratio, now ubiquitous in modern finance. And of course, Gates, Jobs, and other big tech founders are revered in American culture. These accomplishments earned their firms a prestigious reputation once, and they've managed to keep it ever since.</p><p>Prestige is self-reinforcing for its holders in the same way that network effects make big tech hard to topple. Namely, prestigious firms leverage their name and rigorous hiring practices to target top students for recruitment. As students see the best of their class joining these firms, the companies' reputation becomes further entrenched, attracting the next generation of talent. Prestige acts as a competitive moat for these firms and replicates itself over time.</p><h3>The Prestige Trap</h3><p>At first glance, it doesn't seem worrisome to factor prestige into one's job search. If these firms benefit so greatly from their prestige, wouldn't students also be well-served by having them on their resume? Maybe, but only if students are focusing on the right thing.</p><p>Prestige, like the social status it serves as a proxy for, is useful as a form of signaling. To the uninformed observer, it indicates that one is a member of the highly successful creative class. We assume, because we associate these firms with excellence, that possessing prestigious titles demonstrates excellence too. Furthermore, it's hard to evaluate people individually, so we often outsource our decision making and rely upon prestige as a neutral arbiter, regardless of its accuracy.</p><p>If third-parties look at prestige as an indicator of excellence, then it becomes a rough heuristic for replicating success in one's social environment. The top FTC companies represent an opportunity for elite students to become a James McKinsey or Henry Goldman in their own right. Ambitious students seek out prestige thinking it is the missing ingredient to achieving their own excellence. In reality, they have it backward—prestige <em>follows</em> excellence. Exposure to prestige can't make you successful any more than spending time around rich people can make you wealthy.<sup id="fnref-5"><a href="#fn-5">5</a></sup></p><p>Achieving prestige and excellence are not mutually exclusive. Although, one does depend upon the other. Pursuing prestige for its own sake will not lead to excellence, but the reverse can occur. When most ambitious students turn to prestige as a heuristic, they're really just trying to answer the question: "How do I become successful in life and achieve great things?" This explains why many of my peers returned from these prestigious jobs and internships, feeling more dissatisfied than before. They realized that what they were looking for was deeper and more nuanced than could be provided for by an additional resume item.</p><p>Unfortunately, optimizing for prestige is a poor source of evolutionary pressure. It is usually easier to feign excellence than for one to actually cultivate it. Getting a job at a big tech company is a very different thing than becoming an excellent software engineer. A student can find themselves with all of the trappings of success—the distinguished credentials, resume fillers, and prestigious titles—but without having achieved the true excellence they were seeking in the first place. In this way, prestige becomes a trap.</p><p>Why do top students fall for this trap and chase …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://wesdesilvestro.com/the-prestige-trap">https://wesdesilvestro.com/the-prestige-trap</a></em></p>]]>
            </description>
            <link>https://wesdesilvestro.com/the-prestige-trap</link>
            <guid isPermaLink="false">hacker-news-small-sites-25093349</guid>
            <pubDate>Sat, 14 Nov 2020 16:36:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I have finally released a Self-hosted Store QR Menus after months of work]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25093337">thread link</a>) | @altumcode
<br/>
November 14, 2020 | https://altumco.de/easyqr | <a href="https://web.archive.org/web/*/https://altumco.de/easyqr">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
        <div>
            <div>
                
                

                <ul>
                    <li>
                        
                        <p>
                            Unlimited stores &amp; menus
                        </p>
                    </li>

                    <li>
                        
                        <p>
                            Included analytics
                        </p>
                    </li>

                    <li>
                        
                        <p>
                            Ordering feature included
                        </p>
                    </li>
                </ul>

                
            </div>

            <p><img src="https://altumco.de/assets/images/screenshots/index.jpg" loading="lazy">
            </p>
        </div>
    </div>

    

    <div>

        <div>
            <div>
                <div>
                    <h2>Highly customizable store pages</h2>

                    <p>
                        All the stores created can be customized to your own liking with a varied set of built in tools.
                    </p>

                    <ul>
                        <li>
                            
                            <p>
                                Custom menus, categories, items
                            </p>
                        </li>

                        <li>
                            
                            <p>
                                Item extras &amp; item variants
                            </p>
                        </li>

                        <li>
                            
                            <p>
                                Store details, open hours, social links
                            </p>
                        </li>

                        <li>
                            
                            <p>
                                Images, password protection, custom css
                            </p>
                        </li>
                    </ul>
                </div>
            </div>

            <p><img src="https://altumco.de/assets/images/screenshots/example_mobile.png" loading="lazy">
            </p>
        </div>

        

        <div>
            <p><img src="https://altumco.de/assets/images/screenshots/login.png" loading="lazy">
            </p>

            <div>
                <div>
                    <h2>The all-in-one solution</h2>

                    <p>
                        It's easy, simple, intuitive and does everything for you.
                    </p>

                    <ul>
                        <li>
                            
                            <p>
                                No code knowledge needed
                            </p>
                        </li>

                        <li>
                            
                            <p>
                                10 minute installation process
                            </p>
                        </li>

                        <li>
                            
                            <p>
                                Ready to go and maintained software
                            </p>
                        </li>
                    </ul>
                </div>
            </div>
        </div>

        

        <div>
            <div>
                <div>
                    <h2>Search Engine Optimized</h2>

                    <p>
                        Again, we did everything for you, no need to worry about SEO.
                    </p>

                    <ul>
                        <li>
                            
                            <p>
                                Beautiful &amp; custom store URL's
                            </p>
                        </li>

                        <li>
                            
                            <p>
                                OpenGraph ready
                            </p>
                        </li>

                        <li>
                            
                            <p>
                                No CSS or JavaScript fluff
                            </p>
                        </li>

                        <li>
                            
                            <p><strong>Custom Domains</strong> system
                            </p>
                        </li>
                    </ul>
                </div>
            </div>

            <p><img src="https://altumco.de/assets/images/screenshots/gtmetrix.png" loading="lazy">
            </p>
        </div>

        

        <div>
            <p><img src="https://altumco.de/assets/images/screenshots/s_cart.png" loading="lazy">
            </p>

            <div>
                <div>
                    <h2>Item extras, variants &amp; ordering system</h2>

                    <p>
                        You can create item extras &amp; variants for any item on your store and also enable the ability for your visitors to order directly via the menu.
                    </p>

                </div>
            </div>
        </div>

        

        <div>
            <div>
                <div>
                    <h2>Analytics</h2>

                    <p>
                        Every store gets useful and ready to go analytics.
                    </p>

                    <ul>
                        <li>
                            
                            <p>
                                Day by day analytics
                            </p>
                        </li>

                        <li>
                            
                            <p>
                                Referrers
                            </p>
                        </li>

                        <li>
                            
                            <p>
                                Countries
                            </p>
                        </li>

                        <li>
                            
                            <p>
                                Devices, browsers &amp; operating systems
                            </p>
                        </li>

                        <li>
                            
                            <p>
                                Analytics reports by Email
                            </p>
                        </li>
                    </ul>
                </div>
            </div>

            <p><img src="https://altumco.de/assets/images/screenshots/statistics.png" loading="lazy">
            </p>
        </div>
    </div>

    

    <div>
        <div>
            <div>

                <h2>Fully featured Admin Panel</h2>

                <p>
                    Comes right out of the box with a ready to use and functional Admin Panel that allows you to control and check everything that is going on on your website.
                </p>

                <p>
                    Ready to use <strong>Dashboard</strong> for a nice overview of what happens on your website.
                </p>

                <p>
                    A <strong>Users management</strong> system to create, view, update and delete users.
                </p>

                <p>
                    <strong>Stores management</strong> where you can check out and delete any store that is currently on your system.
                </p>

                <p>
                    <strong>Pages management</strong> where you can manage all the extra and custom page on your website.
                </p>

                <p>
                    Powerful <strong>Discount &amp; Redeemable codes system</strong> where you can give out discounts or fully redeemable plans for your users.
                </p>

                <p>
                    <strong>Taxes, billing &amp; invoicing</strong> where you can configure and generate proper invoices and tax rates for you and your paid customers.
                </p>

                <p>
                    <strong>Payments management</strong> to check all the payments made on your platform &amp; <strong>Statistics page</strong> to see an overview of the growth of your website.
                </p>

                <p>
                    <strong>Website Settings</strong> to control the main settings of your website, and many more..
                </p>
            </div>

            <p><img src="https://altumco.de/assets/images/screenshots/admin.png" loading="lazy">
            </p>
        </div>
    </div>

    

    <div>
        <div>
            <div>

                <h2>More features</h2>

                <p>
                    Here are some extra features that you should know about:
                </p>

                <div>
                    

                    <p><span>Dark mode</span>
                        <small>Simply beautiful and ready to go right out of the box.</small>
                    </p>
                </div>

                <div>
                    

                    <p><span>Facebook Login</span>
                        <small>Ready to go facebook login if needed.</small>
                    </p>
                </div>

                <div>
                    

                    <p><span>Automatic generated sitemap</span>
                        <small>Your sitemap is automatically generated and updated for you.</small>
                    </p>
                </div>

                <div>
                    

                    <p><span>Two Factor Authentication</span>
                        <small>You and your users can use 2FA if they want to.</small>
                    </p>
                </div>

                <div>
                    

                    <p><span>Customizable &amp; unlimited plans</span>
                        <small>Admins can create &amp; configure plan features, with their own pricing directly from the admin panel.</small>
                    </p>
                </div>

                <div>
                    

                    <p><span>Multilingual ready</span>
                        <small>The whole platform can be translated to any language by editing 1 json file.</small>
                    </p>
                </div>

                <div>
                    

                    <p><span>SEO Friendly</span>
                        <small>The whole platform was designed with SEO in mind.</small>
                    </p>
                </div>
            </div>

            <p><img src="https://altumco.de/assets/images/screenshots/store_dark.png" loading="lazy">
            </p>
        </div>
    </div>

    

    <div>
        <div>
            <div>
                <div>

                    <div>
                        <p><small>Random testimonial</small>
                        </p>
                        <p>Naboothemes</p>
                        <p><small>Public &amp; verified review can be read on <a href="https://codecanyon.net/ratings/3150740" target="_blank">codecanyon</a>.</small>
                    </p></div>

                    <p>"I had purchased this item with extended license 6 month ago, we worked hard with this product. I have something to say about it.</p>

                    <p>1. For my programmers it was easy to understand the file structure and code - we integrated our two payment gateway in a few days.</p>

                    <p>2. Customer support very fast and loyal. It's really easy to get the answers and get help with product via email.</p>

                    <p>3. Frequent updates - really, you can see changelog and last date of update. Altumcode love this item and he make updates fairly often.</p>

                    <p>I hope that AltumCode don't stop to expand features &amp; improve script &amp; develop more for this. Thanks from my part for your diligence work."</p>

                </div>
            </div>
        </div>
    </div>

    


    <div>
        <div>
            <div>

                <h2>Trusted by more than 6,000+ customers</h2>

                <p>
                    The <a href="https://altumco.de/site" target="_blank">AltumCode</a> brand stands for <strong>high quality</strong>, <strong>reliable</strong> and <strong>affordable</strong> products.
                </p>

                <p>
                    On the <a href="https://altumco.de/site" target="_blank">latest web products</a> that have launched we've got <strong>over 300+ ratings</strong> with an average rating of <strong>5 out of 5 stars</strong> for our constantly increasing quality and customer support.
                </p>

                <p>
                    Here are a few of them, but you can check them out to make sure they are real as well.
                </p>
            </div>

            
        </div>

        <p><small>All these reviews are publicly available on my <a href="https://codecanyon.net/user/altumcode/portfolio" target="_blank">codecanyon profile</a> and via emails from …</small></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://altumco.de/easyqr">https://altumco.de/easyqr</a></em></p>]]>
            </description>
            <link>https://altumco.de/easyqr</link>
            <guid isPermaLink="false">hacker-news-small-sites-25093337</guid>
            <pubDate>Sat, 14 Nov 2020 16:35:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Obfuscating Complexity Considered Harmful]]>
            </title>
            <description>
<![CDATA[
Score 29 | Comments 10 (<a href="https://news.ycombinator.com/item?id=25093191">thread link</a>) | @definetheword
<br/>
November 14, 2020 | https://rule11.tech/obfuscating-complexity-considered-harmful/ | <a href="https://web.archive.org/web/*/https://rule11.tech/obfuscating-complexity-considered-harmful/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
		<p>If you are looking for a good resolution for 2020 still (I know, it’s a bit late), you can’t go wrong with this one: <em>this year, I will focus on making the networks and products I work on truly simpler. </em>Now, before you pull Tom’s take out on me—</p>
<blockquote><p><a href="https://networkingnerd.net/2019/12/27/fast-friday-keeping-up-with-the-times/">There are those that would say that what we’re doing is just hiding the complexity behind another layer of abstraction, which is a favorite saying of Russ White. I’d argue that we’re not hiding the complexity as much as we’re putting it back where it belongs – out of sight. We don’t need the added complexity for most operations.</a></p></blockquote>
<p>Three things: <em><strong>First,</strong> complex solutions are always required for hard problems.</em> If you’ve ever listened to me talk about complexity, you’ve probably seen this quote on a slide someplace—</p>
<blockquote><p><a href="https://faculty.nps.edu/dlalders/docs/AldersonDoyle-tsmca-July2010.pdf">[C]omplexity is most succinctly discussed in terms of functionality and its robustness. Specifically, we argue that complexity in highly organized systems arises primarily from design strategies intended to create robustness to uncertainty in their environments and component parts.</a></p></blockquote>
<p>You <em>cannot</em> solve hard problems—complex problems—without complex solutions. In fact, a lot of the complexity we run into in our everyday lives is a result of saying “this is too complex, I’m going to build something simpler.” <em>(here I’m thinking of a blog post I read last year that said “when we were building containers, we looked at routing and realized how complex it was… so we invented something simpler… which, of course, turned out to be more complex than dynamic routing!)</em></p>
<p><em><strong>Second,</strong> abstraction can be used the right way to manage complexity, and it can be used the wrong way to obfuscate or mask complexity.</em> The second great source of complexity and system failure in our world is we don’t abstract complexity so much as we obfuscate it.</p>
<p><em><strong>Third,</strong> abstraction is not a zero-sum game</em><strong>.</strong> If you haven’t found the tradeoffs, you haven’t looked hard enough. This is something expressed through the state/optimization/surface triangle, which you should <em>know</em> at this point.</p>
<p>Returning to the top of this post, the point is this: Using abstraction to manage complexity is fine. Obfuscation of complexity is not. Papering over complexity “just because I can” never solves the problem, any more than sweeping dirt under the rug, or papering over the old paint without bothering to fix the wall first.</p>
<p>We need to go beyond just figuring out how to make the user interface simpler, more “intent-driven,” automated, or whatever it is. We need to think of the network as a system, rather than as a collection of bits and bobs that we’ve thrown together across the years. We need to think about the modules horizontally and vertically, think about how they interact, understand how each piece works, understand how each abstraction leaks, and be able to ask hard questions.</p>
<p>For each module, we need to understand how things work well enough to ask <em>is this the right place to divide these two modules?</em> We should be willing to rethink our abstraction lines, the placement of modules, and how things fit together. Sometimes moving an abstraction point around can greatly simplify a design while increasing optimal behavior. Other times it’s worth it to reduce optimization to build a simpler mouse trap. <em>But you cannot know the answer to this question until you ask it.</em> If you’re sweeping complexity under the rug because… <em>well, that’s where it belongs…</em> then you are doing yourself and the organization you work for a disfavor, plain and simple. Whatever you sweep under the rug of obfuscation will grow and multiply. You don’t want to be around when it crawls back out from under that rug.</p>
<p>For each module, we need to learn how to ask <em>is this the right level and kind of abstraction?</em> We need to learn to ask <em>does the set of functions this module is doing really “hang together,” or is this just a bunch of cruft no-one could figure out what to do with, so they shoved it all in a black box and called it done?</em></p>
<p>Above all, we need to learn to look at the network as a system. I’ve been harping on this for so long, and yet I still don’t think people understand what I am saying a lot of times. So I guess I’ll just have to keep saying it. 😊</p>
<p>The problems networks are designed to solve are hard—therefore, networks are going to be complex. You cannot eliminate complexity, but you can learn to minimize and control it. Abstraction within a well-thought-out system is a valid and useful way to control complexity and understanding how and where to create modules at the edges of which abstraction can take place is a valid and useful way of controlling complexity.</p>
<p><strong>Don’t obfuscate. Think systemically, think about the tradeoffs, and abstract wisely.</strong></p>

	</div></div>]]>
            </description>
            <link>https://rule11.tech/obfuscating-complexity-considered-harmful/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25093191</guid>
            <pubDate>Sat, 14 Nov 2020 16:15:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Application trust is hard, but Apple does it well]]>
            </title>
            <description>
<![CDATA[
Score 159 | Comments 202 (<a href="https://news.ycombinator.com/item?id=25093161">thread link</a>) | @pvachon
<br/>
November 14, 2020 | https://www.security-embedded.com/blog/2020/11/14/application-trust-is-hard-but-apple-does-it-well | <a href="https://web.archive.org/web/*/https://www.security-embedded.com/blog/2020/11/14/application-trust-is-hard-but-apple-does-it-well">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="44" id="block-yui_3_17_2_1_1605368314078_14495"><div><p>On November 12, 2020 Apple released macOS Big Sur. In the hours after the release went live, somewhere in Apple's infrastructure an Online Certificate Status Protocol (OCSP) responder cried out in pain, dropping to its knees, begging for mercy as load increased beyond what it could handle. The OCSP responder slowing down, being a critical aspect of a modern public key infrastructure (PKI), makes it hard for clients of the PKI to verify the validity of identity documents. These documents, called X.509 Certificates, are attached to every verified application the user is launching on their Mac. Mayhem ensued, and after the issues were cleaned up, many questions remained about the implications of this failure. But first, let's take a look at the mechanisms involved in authenticating an application package, at the most fundamental level.</p>

<p>The X.509 is a ratified ITU specification that defines (among other things) a standard representation for documents that convey trust relationships between entities, known as Certificates. Certificates can be thought of as policy documents. Any X.509 certificate consists of</p>
<ul>
<li>a public key,</li>
<li>an indication who the certificate was issued for,</li>
<li>what actions the authority allows the certificate holder to perform,</li>
<li>the date the certificate is first valid on,</li>
<li>the date the certificate expires on,</li>
<li>metadata about how to check if the certificate has been revoked (optional, but highly recommended),</li>
<li>the authority who issued the certificate, and</li>
<li>a signature across all this metadata, from the authority.</li>
</ul>
<p>By retrieving the authority certificate, one can verify the integrity of the issued certificate. In fact, most authority certificates were issued by an even higher authority. By verifying all the way up to the root entity certificate (the "self-signed" highest level authority), it is possible to get a high degree of confidence of the provenance of the end entity certificate. Oftentimes a certain set of policy requirements must be met for an authority to issue a certificate to an end entity, or any intermediate entity. A certificate can be viewed as an embodiment of the proof that the authorities involved performed the appropriate checks to make sure all these conditions were met. If you fail these checks, an authority should not issue you a certificate!</p>
<p>The ceremony of creating these documents, how to interpret the document, how to represent the hierarchy of business trust decisions are all encoded in a certificate chain. Certificate chains are powerful concepts: they can be used to verify an authority who generated a public key, and who verified it was done to a certain standard. By reducing the scope of public keys to only keys you trust by specifying only certain root authorities you will accept certificate chains originating from, you can make a policy to reject any public keys (and thus any certificates) that were issued by a different authority.</p>
<h2 id="the-hard-part-revocation">The Hard Part: Revocation</h2>
<p>But what if, after the date the certificate is issued and before the date the certificate expires, something goes wrong? Maybe the authority decides that the entity the certificate was issued to has committed some malfeasance, and revokes their certificate. Sometimes the private key for a certificate is stolen, and so the assertions about who the party is that the certificate represents are no longer true, since an entity with the stolen key could impersonate the legitimate original party. There are numerous reasons why a certificate could be revoked.</p>
<p>One of the fantastic design attributes of X.509 is the fact that you should be able to perform X.509 certificate chain validation offline. So long as you have an accurate idea of what the current date is and what root entities you trust, it's (relatively) easy for a party to verify a certificate chain. The offline verification confers a great deal of resilience upon the system. But this revocation problem remains a challenge - for some systems you need to be able to check back with the authority who issued the certificate and ask "hey, is this assertion you made still valid?"</p>
<p>To solve this problem, there are three common mechanisms in use today. First, most authorities publish certificate revocation lists (CRLs). This list, signed by the issuing authority, can be periodically downloaded from a location specified in the certificate's metadata (say on a daily basis). When performing certificate validation, the locally downloaded copy of the CRL will provide a indication if a certificate has been revoked. These CRLs can get quite large though, and having to wait for the CRL to be refreshed for a revocation to take effect could be risky for certain applications. CRLs work for certain use cases, but the storage and update frequency trade-offs are significant.</p>
<p>Enter OCSP. When an authority offers an OCSP responder, the URL for the responder is also encoded in the certificate. A certificate verifier can make a call to the OCSP responder, with the serial number of the certificate to be verified. The OCSP responder checks against its database of revoked certificates. The OCSP responder will then respond with a simple "valid" or "revoked" to the query, and the calling party can then decide what to do with that information. Of course, this means that the OCSP responder can log each and every one of these queries, and build a very useful paper trail to help monitor user behaviour. This risk, along with the systemic resiliency challenges, led to a search for a middle ground.</p>
<p>The final mode is a variant on calling the OCSP responder. An OCSP responder can issue a short-lived, cryptographically signed document to a certificate holder. This document is "stapled" together with the certificate, and is sent to to the verifying party. So long as the time stamps match up, the recipient can assume (within some bounded risk) that the certificate is still valid, per the issuing authority. Of course, this approach only works for certain use cases (usually connectivity-oriented usage), but it does anonymize the certificate verifying parties.</p>
<p>Apple chose the second revocation model for app certificate verification. This mode has its benefits - revocation can be performed in real-time. So, if Apple finds that an app they issued a certificate to is actually malware, they can rapidly revoke this certificate and prevent the malware from running, even on machines it has already installed itself on. This does put a lot of policy control in Apple's hands. This is where you have to make a business decision as to whether or not you trust Apple to be benevolent or not.</p>

<p>A signed application is an interesting corner case in certificate validation. Certificates are valid for a certain range of dates. Additionally, applications don't involve (at least at launch time) any sort of exchange between a server and a client that can perform an OCSP lookup on your behalf. This limits the options we have.</p>
<p>The first problem is more nuanced than one might think. Should an application, signed at a specific point in time, be only launchable between the validity start/end dates of the certificate issued to sign the application? Probably not - this puts an artificial horizon on the application being valid, and if this is an app you paid a lot of money for, this might be frustrating. Implementation details might vary, but there is a concept of a trusted timestamp server, where a timestamp with a nonce is signed by a trusted authority. By integrating a trusted timestamp into the bundle of attributes cryptographically verified by the application launcher, we can reduce this problem to only needing to verify the app signing certificate was valid <em>at the time the bundle was signed</em>. So the current calendar date is irrelevant for determining this validity, but rather the date that has been bundled into the signed app is to be used.</p>
<p>The second problem limits your options for handling revocation. A CRL might be useful in a subset of cases - for example if large swaths of certificates are to be revoked. However, there are some concerns with this approach, beyond scalability and size of these revocation lists. One operational concern is that you could be leaking information about which certificates have been revoked, or providing insight into the revocation process. This could be exploited by malfeasant actors to game the certificate issuing process, or at least make it more obvious which certificates have been revoked and when, so malware developers could get more insight into the process, giving them an edge in "gaming the system."</p>
<p>Apple opted to solve this problem with an OCSP responder. So at every launch of an app (perhaps outside of some window where the OCSP response could be cached - I have not looked into this detail), macOS would dutifully check if the certificate used by the signer is still valid, per the OCSP responder. Of course, if macOS couldn't reach the OCSP responder, it would go about its merry way launching an app. After all, a computer needs to work offline, too.</p>

<p>An OCSP responder certainly would generate logs, as we discussed before. Those logs could contain the serial numbers of certificates that users had requested be checked, as well as the IP address of the requestor. Apple certainly has a database that maps a serial number back to the actual X.509 certificate, which then can likely be used to identify what app(s) this certificate was used to sign. The metadata about the request could likely be mapped back to who you are (through the power of AppleID, perhaps), the and the attributes of the certificate could be tied to your app store purchases (or lack thereof). Theoretically, this could be used to clamp down on piracy, private software distribution and other free use of a device.</p>
<p>But here is where we have to consider the user. I'm knee-deep in systems security problems, day-in and day-out. All these systems we interact with have become more complex than what most people (myself included) can maintain a mental model of. …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.security-embedded.com/blog/2020/11/14/application-trust-is-hard-but-apple-does-it-well">https://www.security-embedded.com/blog/2020/11/14/application-trust-is-hard-but-apple-does-it-well</a></em></p>]]>
            </description>
            <link>https://www.security-embedded.com/blog/2020/11/14/application-trust-is-hard-but-apple-does-it-well</link>
            <guid isPermaLink="false">hacker-news-small-sites-25093161</guid>
            <pubDate>Sat, 14 Nov 2020 16:11:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Having 170 competitors in not an obstacle]]>
            </title>
            <description>
<![CDATA[
Score 138 | Comments 66 (<a href="https://news.ycombinator.com/item?id=25093022">thread link</a>) | @Akcium
<br/>
November 14, 2020 | https://pingr.io/blog/having-170-competitors-is-not-an-obstacle/ | <a href="https://web.archive.org/web/*/https://pingr.io/blog/having-170-competitors-is-not-an-obstacle/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <p>Take a look at this research <a href="https://www.supermonitoring.com/blog/website-monitoring-tools-market-in-2020/">https://www.supermonitoring.com/blog/website-monitoring-tools-market-in-2020/</a></p><p>It states that there are around 170 uptime monitoring services. Despite this fact, I decided to make another one. Before you roll your eyes, let me explain the reasons for making such a decision. At the end of the article, you'll find a comment on hacker news that answers the question.</p><p>First of all, let's accept the term that I consider people who are solo-founders who have enough time &amp; desire to make their products. I'm not talking about an investment of millions of dollars, complex financial calculations of risks/profits, creating a big company with hundreds of employees. I'm talking about small businesses.</p><p>Having such people in mind, let's see what their thoughts can be before starting a new product.</p><p>Most of them refuse to create something alleging that:</p><ul><li>They don't have a brilliant idea</li><li>They don't have enough money/time</li><li>The idea was already implemented / there are a lot of competitors in the area</li></ul><p>Let's examine these statements.</p><h3 id="no-brilliant-idea">No brilliant idea</h3><p>Let me ask: Does every successful product have a brilliant idea? Does every successful business have an idea at all? If so, <a href="https://alternativeto.net/">https://alternativeto.net/</a> didn't exist.</p><p>Everyone knows that idea worth nothing. Implementation does. Marketing does.</p><p>How often do we hear: "Gosh, why nobody solves this, isn't it obvious that people should solver this?!". But why the person who says that didn't solve it, if it's obvious?</p><p>Now, you may argue that new products appearing in the market have USP, Unique Selling Proposition. Usually, yes, however, the USP turns around the idea which was already implemented. They just enhanced it a bit but haven't invented something completely new.</p><p>There are hundreds of to-do apps that solve the task of taking notes of what a person should do.</p><p>There are hundreds of chat apps that solve the task of communicating between people.</p><p>There are hundreds of CRM apps that sole the task of handling customers.</p><h3 id="no-money-time">No money / time</h3><p>When it comes to money, I have the same question: Did every successful business have initial funding?</p><p>As for time, I would agree that this is somewhat necessary if we don't consider funding or investment. Even if we do, we still need to spend some amount of time.</p><h3 id="it-was-already-implemented">It was already implemented</h3><p>Okay, now a person has desire and time. Then, the person goes to Google and finds out that somebody already implemented the idea. Moreover, the "somebody" is a relatively large and famous company. What a pity.</p><p>But what happens if there weren't any competitors at all?</p><p>Well... the chances are that nobody needs this. But you cannot know for sure, so you need to spend time for validation.</p><p>Beware, here comes a <a href="https://en.wikipedia.org/wiki/Confirmation_bias">cognitive bias</a>: if you stick to your idea, really love it, then despite your validation process, you might keep on working on it because people tend to find arguments that sustain their opinion, not vice versa.</p><h3 id="what-others-say">What others say</h3><p>The most common objection for a person who wants to start a business starts with: "Who needs...".</p><p>This is an established human pattern.</p><ul><li>Who needs google if there is Yahoo?</li><li>Who needs dropbox if you have flash drives?</li><li>Who needs yet another... if ... already exists?</li></ul><h3 id="the-answer">The answer</h3><p>Let me show an HN comment from a post by Unsplash <a href="https://news.ycombinator.com/item?id=5794083">https://news.ycombinator.com/item?id=5794083</a></p><figure><img src="https://pingr.io/blog/content/images/2020/11/image.png" alt="" srcset="https://pingr.io/blog/content/images/size/w600/2020/11/image.png 600w, https://pingr.io/blog/content/images/size/w1000/2020/11/image.png 1000w, https://pingr.io/blog/content/images/size/w1600/2020/11/image.png 1600w, https://pingr.io/blog/content/images/2020/11/image.png 2150w" sizes="(min-width: 720px) 720px"></figure><p>Every week, every day, and every hour, a lot of new products are founded. By "products," I mean pretty much everything: a new store, a new SaaS, a new B2B company.</p><p>In most cases, something similar already exists. In most cases, you don't even have a USP (Unique Selling Proposition).</p><p>But does it mean that you:</p><ul><li>Cannot create something already exists</li><li>Cannot make it better</li><li>Cannot get revenue from it?</li></ul><p>Tell me why it's not possible to open an e-commerce shop, which would be much easier/pleasant to use. Okay, tell me why cloning the existing one won't bring some revenue?</p><p>My father sells radio receivers in 2020. Even in his case, somebody needs them.</p><h3 id="reasons">Reasons</h3><p>So why I've decided to do yet another uptime monitoring service? Because I hated the experience, I got with others &amp; because I immediately understood the idea of such services.</p><p>Stop laughing at this moment, and consider this: when Medium was created, WordPress already existed.</p><p>When yet-another-CMS is created and become famous, WordPress already existed.</p><p>Some may say: hey, but WordPress is ugly and slow. And you should host it on your hosting, while Medium is excellent, and you don't need a server for posting your articles!</p><p>Yes, exactly. I hope I'll be able to get Pingr to the same level.</p><p>I'd be like Pingdom (WordPress). But better.</p><h3 id="takeaways">Takeaways</h3><ol><li>Having high competition means that the idea was already validated for you</li><li>You can create a product without a brilliant idea</li><li>You can create a product without funding</li><li>You still need to invest much time</li></ol>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://pingr.io/blog/having-170-competitors-is-not-an-obstacle/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25093022</guid>
            <pubDate>Sat, 14 Nov 2020 15:53:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What a great technical resume can do for you]]>
            </title>
            <description>
<![CDATA[
Score 235 | Comments 104 (<a href="https://news.ycombinator.com/item?id=25092880">thread link</a>) | @mcenedella
<br/>
November 14, 2020 | https://www.meetleet.com/blog/what-a-great-technical-resume-can-do-for-you | <a href="https://web.archive.org/web/*/https://www.meetleet.com/blog/what-a-great-technical-resume-can-do-for-you">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><div><div><p>The purpose of your technical resume is to generate interview requests. A successful resume attracts more interest, from more of the companies you want to interview with, for more of the jobs you would be happy to take.</p><p>You might think of a resume as your personal summary document, covering all of your life’s work to date. But it’s better to think of your resume as a business document that helps you advertise your capabilities to a future employer.</p><p>I’ve worked with thousands of employers, published the <a href="https://www.businessinsider.com/heres-what-recruiters-look-at-during-the-6-seconds-they-spend-on-your-resume-2012-4">ground-breaking research</a> into recruiter resume review time, and written several bestsellers on resumes and other career topics. And that’s why I’m now writing <a href="https://signup.meetleet.com/">great technical resumes for free</a>. Resumes, when done right, are great help in accelerating your career.</p><p>Here are a few things a <a href="https://www.meetleet.com/blog/how-to-write-a-great-technical-resume">technical resume</a> is not:</p><ul><li>Not your autobiography</li><li>Not a comprehensive catalog of everything you’ve done</li><li>Not a way to make you feel good about yourself (though it might also do that)</li><li>Not an academic CV</li><li>Not where you need to explain past ‘bad situations’</li><li>Not where you need to explain why you left prior jobs</li></ul><p>No, a technical resume is none of those things. And that’s because none of those things help get you hired.</p><p>Instead, a technical resume’s primary purpose is to generate interview requests for you. It’s where you make the case to “please pick me out of the pile.”</p><p>(Secondarily, a resume is a useful page of notes to use during interviews, especially behavioral interviews. We all know how our minds can go blank during interviews and it’s useful to have something to aid your memory in those moments.)</p><p>What’s the best way to get a hiring manager or future boss to select your resume from the pile? </p><p>It’s to make it as clear as possible which types of problems you’ve solved in the past, and how well you solved them. With that information, hiring managers have the easiest time in predicting what you can do for them in the future.</p><p>Unfortunately, most technology professionals take the easy way out, and copy and paste their job description into their resume. As a result, their <a href="https://www.meetleet.com/blog/how-to-write-bullet-points-for-a-technical-resume">bullet points</a> are full of sentences that begin “Responsible for” or “Worked on” or “Assigned to.”</p><p>This is a mistake because your future employer is not going to hire you for your past <strong>responsibilities</strong>. Rather, they will hire you for your past <strong>successes</strong>. It’s your achievements and results in technology that get you promoted and elevated to ever-higher levels.</p><p>And that’s why great technical resumes focus on results, <a href="https://www.meetleet.com/blog/why-you-should-include-numbers-on-your-technical-resume">numbers</a> and method. </p><p><strong>Results</strong>: for the technology you were working on, how did it make your company, team, or systems better? Did it increase, decrease, grow, shrink, improve, suppress, optimize, deprecate, add or remove something important for your company? For everything you’ve worked on, there was some reason you were doing it. Hopefully, that reason had to do with making things better. Share the result with your resume readers. </p><p><strong>Numbers</strong>: by how much did you make things better? As a technology professional, you’re used to numbers. We measure the success of what we do in numbers all the time: latency, loadtime, DAUs, Google score. Using numbers to describe the work you’ve done comes naturally in the field.</p><p>So the more you can use numbers to <strong>quantify</strong> how much you helped increase, decrease, grow, shrink, etc., the important metrics in your prior roles, the better and more persuasive your resume will be in getting picked out of the pile. </p><p><strong>Method</strong>: this is the technical “how I did it” part of a great technical resume. If you increased something by 50% what technologies or solutions or methodologies did you use to get there? If you shrank a different metric by 70%, what activities or behaviors or actions did you need to take to achieve this reduction?</p><p>Many technical resumes miss the results and the numbers and only list the method of how they did something. Unfortunately, that’s not as effective at attracting attention to get your resume picked out of the pile.</p><p>To demonstrate, the <a href="https://www.meetleet.com/blog/how-to-write-bullet-points-for-a-technical-resume">bullet points</a> below <strong>with</strong> <a href="https://www.meetleet.com/blog/why-you-should-include-numbers-on-your-technical-resume">numbers</a> are much more powerful than the same bullet point <strong>without</strong> numbers.</p><ul><li>Responsible for for managing our AWS cloud services for cost, reliability and scalability.</li><li>Reduced costs 17% by decommissioning 42 ec2 instances in our AWS implementation while managing for costs, reliability and scalability.</li></ul><ul><li>Refactored our front/end experience using React.</li><li>Increased user engagement 27% by refactoring our front-end experience in React.</li></ul><p>Combining results, numbers and methods on your resume makes your experience stand out from the pile. And that’s the best way to fulfill the purpose of your resume - to get you interview requests.</p><p><a href="https://www.meetleet.com/blog/how-to-write-a-great-technical-resume">Great technical resumes</a> increase your chances of getting hired, and getting ahead in your career. If you’d like MeetLeet to write your technical resume for free, <a href="https://signup.meetleet.com/">sign up here</a>.</p></div></div></div></div>]]>
            </description>
            <link>https://www.meetleet.com/blog/what-a-great-technical-resume-can-do-for-you</link>
            <guid isPermaLink="false">hacker-news-small-sites-25092880</guid>
            <pubDate>Sat, 14 Nov 2020 15:34:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Military History?]]>
            </title>
            <description>
<![CDATA[
Score 134 | Comments 62 (<a href="https://news.ycombinator.com/item?id=25092118">thread link</a>) | @alexpetralia
<br/>
November 14, 2020 | https://acoup.blog/2020/11/13/collections-why-military-history/ | <a href="https://web.archive.org/web/*/https://acoup.blog/2020/11/13/collections-why-military-history/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>This week, I want to talk about the discipline of military history: what it is, why it is important and how I see my own place within it.  This is going to be a bit of an unusual collections post as it is less about the past itself and more about how we study the past; it is also going to be a bit unusual in that it is mostly my own personal reflections, rather than a historical argument.</p>



<p>We do quite a lot of different kinds of history here on the blog.  There is a fair bit of<a href="https://acoup.blog/2019/09/07/new-acquisitions-class-status-and-the-early-church/"> social history,</a> some <a href="https://acoup.blog/2019/12/05/collections-a-trip-through-thucydides-fear-honor-and-interest/">intellectual </a><a href="https://acoup.blog/2019/12/12/collections-a-trip-through-cicero-natural-law/">history</a>, just a<a href="https://acoup.blog/2019/05/20/new-acquisitions-elective-monarchy-and-the-future-of-westeros/"> little bit of political history</a> and an absolute <a href="https://acoup.blog/tag/organic-economy/"><em>ton</em> of economic history</a>.  Obviously, I think all of those analytical lenses (and several I have not done, of course) are very important ways of understanding the past.  But a lot of what we discuss on the blog fits, narrowly or broadly, into the realm of <strong>military history</strong>.  And I want to talk about that.</p>



<p><strong>Now I should note that I do not consider myself purely a military historian</strong> – indeed, in my experience, few historians are ‘pure’ anything and if you narrow down their specialization enough, you simply end up with, “I am a historian of things which interest me” followed by a long list of what those are.  <strong>I see myself as both an economic and military historian (of the Mediterranean world, broadly construed)</strong> and my research tends to exist in the places where those two strands meet.  Sometimes that means processes that read as non-military (if it isn’t evident I have active research projects on farming and metal production, you haven’t been here long!) and sometimes those projects are more narrowly military.  <strong>I am a firm believer that a historian must be prepared to use whatever tools are going to provide the best answers to their research questions</strong>; for my own work, that has included (basic) statistical analysis, textual close reading, economic theory, archaeology (both traditional and experimental), social history, and even some chemistry and physics.  Whatever works!  But certainly, the methods of military history are one tool in my toolbox, even when I am looking to answer questions about non-military aspects of Mediterranean antiquity.</p>



<p><strong>It is no real secret that as a discipline, military history is sometimes held in low regard by other historians</strong>.  There are a number of reasons for this.  Often it has to do with outdated views on what military history <em>is</em> and what military historians <em>do</em>.  Frequently military history, because it has a large enthusiast and amateur audience, is regarded as an amateur field (something which is not helped by publishers who push quite out reams of quite frankly substandard works of this sort) lacking in sophistication, which is not accurate, but often believed.  And perhaps most often, in my experience, <strong>these opinions serve as cover for a deeper conviction that studying militaries and warfare is icky and only done by people who <em>like</em> war</strong> (when I was a student, this opinion when it was expressed by a certain generation of scholars, now mostly retired, came with a <em>very</em> predictable dose of Vietnam-era anti-military sentiment).  Often it seems the study of military history is neglected by other historians precisely because they find the subject matter uncomfortable.</p>



<p>So I want to talk about three major things here: what military history actually is and how it is done these days, why we should study military history and finally what my experience of being a military historian (both as a scholar and a teacher) has been, particularly given that I am a life-long civilian.  </p>



<p>As always, if you like what you are reading here, please share it; if you really like it, you can support me on <a href="https://www.patreon.com/user?u=20122096">Patreon</a>. And if you want updates whenever a new post appears, you can click below for email updates or follow me on twitter (@BretDevereaux) for updates as to new posts as well as my occasional ancient history, foreign policy or military history musings.</p>






<h2>What is Military History?</h2>



<p>The popular conception of military history – indeed, the conception sometimes shared even by other historians – is that it is fundamentally a field about charting the course of armies, describing ‘great battles’ and praising the ‘strategic genius’ of this or that ‘great general.’  One of the more obvious examples of this assumption – and the contempt it brings – comes out of the popular CrashCourse youtube series.  When asked by their audience to cover military history related to their coverage of <em>the American Civil War</em>, the response was <a href="https://youtu.be/25HHVDOaGeE">this video listing battles </a>and reflecting on the pointless of the exercise, as if a list of battles was all that military history was (the same series would later say that military historians <a href="https://youtu.be/rlx6ur_D51s?t=323">don’t talk about about food</a>, a truly baffling statement given the important of logistics studies to the field; certainly in my own subfield, military historians tend to talk about food more than any other kind of historian except for dedicated food historians).</p>



<p>The term for works of history in this narrow mold – all battles, campaigns and generals – is <strong>“drums and trumpets” history, a term generally used derisively</strong>.  The study of battles and campaigns emerged initially as a form of training for literate aristocrats preparing to be officers and generals; it is little surprise that they focused on aristocratic leadership as the primary cause for success or failure.  Consequently, the old ‘drums and trumpets’ histories also had a tendency to<a href="https://acoup.blog/2020/04/16/collections-a-trip-through-bertran-de-born-martial-values-in-the-12th-century-occitan-nobility/"> glory in war </a>and to glorify commanders for their ‘genius’ although this was by no means universal and works of history on conflict as far back as Thucydides and Herodotus (which is to say, as far back as there have been any) have reflected on the destructiveness and tragedy of war.  But military history, like any field, matured over time; I should note that it is <a href="https://acoup.blog/2020/02/07/collections-the-fremen-mirage-part-iiia-by-the-princess-irulan/">hardly the only field of history to have less respectable roots</a> in <a href="https://acoup.blog/2020/02/14/collections-the-fremen-mirage-part-iiib-myths-of-the-atreides/">its quite recent past</a>.  Nevertheless, as the field matured and moved beyond military aristocrats working to emulate older, more successful military aristocrats into a field of scholarly inquiry (still often motivated by the very real concern that officers and political leaders be prepared to lead in the event of conflict) the field has become far more sophisticated and its gaze has broadened to include not merely non-aristocratic soldiers, but non-soldiers more generally.</p>



<p>Instead of the ‘great generals’ orientation of ‘drums and trumpets,’ the field has moved in the direction of three major analytical lenses, laid out quite ably by Jeremy Black in “Military Organisations and Military Charge in Historical Perspective” (<em>JMH</em>, 1998). <strong> He sets out the three basic lenses as technological, social and organizational, which speak to both the questions being asked of the historical evidence but also the answers that are likely to be provided</strong>.  I should note that these lenses are mostly (though not entirely) about <em>academic</em> military history; much of the amateur work that is done is still very much ‘drums and trumpets’ (as is the occasional <em>deeply frustrating</em> books from some older historians we need not discuss here), although that is of course not to say that there isn’t good military history being written by amateurs or that all good military history narrowly follows these schools.  <strong>This is a classification system, not a straight-jacket and I am giving it here because it is a useful way to present the complexity and sophistication of the field as it is, rather than how it is imagined by those who do not engage with it.</strong></p>



<p>(I should note that <em>campaign studies</em> have not been entirely abandoned either.  What distinguishes the modern campaign or battle study from the old ‘drums and trumpets’ style is a broader use of historical causality that reaches beyond just upper-level command decisions. <a href="https://acoup.blog/2020/10/30/fireside-friday-october-30-2020/"> Our recent recommendation, <em>Shattered Sword</em></a> is a good example of how what might have been a ‘drums and trumpets’ narrative of admirals and captains can instead be developed, using more sophisticated historical methods, into a much more complete and compelling historical argument about organizations, doctrines, technologies and so on.  And of course campaign histories will never go out of style – they are the essential foundation on which all other kinds of analysis must be laid)</p>



<p><strong>The technological approach is perhaps the least in fashion these days</strong>, but Geoffery Parker’s <em>The Military Revolution</em> (2nd ed. 1996) provides an almost pure example of the lens.  This approach tends to see changing technology – not merely military technologies, but often also civilian technologies – as the main motivator of military change (and also success or failure for states caught in conflict against a technological gradient).  <strong>Consequently, historians with this focus are often asking questions about how technologies developed, why the developed in certain places, and what their impacts were</strong>.  Another good example of the field, for instance, is the debate about the impact of <a href="https://www.amazon.com/gp/product/0700623833/ref=ppx_yo_dt_b_search_asin_title?ie=UTF8&amp;psc=1">rifled muskets</a> in the <a href="https://www.amazon.com/gp/product/171985727X/ref=ppx_yo_dt_b_asin_title_o07_s00?ie=UTF8&amp;psc=1">American Civil War</a>.  While there has been a real drift away from seeing technologies themselves as decisive on their own (and thus a drift away from mostly ‘pure’ technological military history) in recent decades, this sort of history is very often paired with the others, looking at the ways that social structures, organizational structures and technologies interact.</p>



<p><strong>Perhaps the <em>most</em> popular lens for military historians these days is the social one</strong>, which used to go by the “new military history” (<em>decades </em>ago – it was the standard form even back in the 1990s) but <strong>by this point comprises probably the bulk of academic work on military history</strong>.  In its narrow sense, the social perspective of military history seeks to understand the army (or navy or other service branch) as an extension of the society that created it.  We have, you may note,<a href="https://acoup.blog/2020/05/22/collections-the-battle-of-helms-deep-part-iv-men-of-rohan/"> done a bit of that here</a>.  Rather than understanding the army as a pure instrument of a general’s ‘genius’ it imagines it as a <em><strong>socially embedded</strong></em> institution – which is …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://acoup.blog/2020/11/13/collections-why-military-history/">https://acoup.blog/2020/11/13/collections-why-military-history/</a></em></p>]]>
            </description>
            <link>https://acoup.blog/2020/11/13/collections-why-military-history/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25092118</guid>
            <pubDate>Sat, 14 Nov 2020 13:15:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hello dark mode, my old friend]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25091913">thread link</a>) | @prampey
<br/>
November 14, 2020 | https://prudhvirampey.com/blog/colours/jekyll/css/fastpages/2020/10/30/hello-dark-mode.html | <a href="https://web.archive.org/web/*/https://prudhvirampey.com/blog/colours/jekyll/css/fastpages/2020/10/30/hello-dark-mode.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>I have come to talk with you again, this time for my <code>fastpages</code> blog.</p>

<p><code>fastpages</code> gets a lot of things right for someone who uses <code>Jupyter</code> notebooks and wants to get into blogging. Prashanth Rao’s <a href="https://prrao87.github.io/blog/blogging-for-data-scientists/">article</a> does a great job of making the case for that.</p>



<p>However, being a long time user of the <a href="https://darkreader.org/">Dark Reader</a> browser extension, it was unusual to not have widespread dark mode support on many Jekyll themes, one of which <code>fastpages</code> is built on. Therefore, I decided to bring back the dark mode experience in this post.</p>

<p><img src="https://prudhvirampey.com/blog/images/dark-side.gif" alt=""></p>

<p>I personally prefer dark mode to light as it causes lesser strain on the eyes. It also helps illuminate content while the background fades away. For someone who spends a good part of the day stuck behind a screen, I’ve made it a point to keep the bright light intake for outdoors.</p>

<p>Since I have not dabbled in designing dark mode experiences before, I plan to keep this process simple and understandable. We shall be using a bunch of simple css rules while following Material Design dark theme <a href="https://material.io/design/color/dark-theme.html">guidelines</a> (mostly).</p>

<p>Here’s the sample fastpages sample blog <a href="https://fastpages.fast.ai/jupyter/2020/02/20/test.html">post</a> without Dark mode:</p>

<p><img src="https://prudhvirampey.com/blog/images/light-mode.png" alt="" title="Curb your light mode"></p>

<p>And here’s the <a href="https://prudhvirampey.com/blog/jupyter/2020/02/20/test.html">same one</a> with dark mode enabled!</p>

<p><img src="https://prudhvirampey.com/blog/images/dark-mode.png" alt=""></p>

<p>Pretty cool, yeah? Let’s check out the code now.</p>

<p>If you’re in a hurry to join the dark side, feel free to scroll to the end of this post and download the dark mode stylesheet.</p>

<p>If your curious about the design choices I’ve made and would like to customize for yourself, stick with me here.</p>



<p>Let’s start with defining our palette.</p>

<div><div><pre><code><span>$high-emph</span><span>:</span> <span>rgba</span><span>(</span><span>white</span><span>,</span> <span>0</span><span>.87</span><span>);</span> <span>// Colour 1 -&gt; White</span>
<span>$med-emph</span><span>:</span> <span>rgba</span><span>(</span><span>white</span><span>,</span> <span>0</span><span>.69</span><span>);</span> <span>//Noice</span>
<span>$low-emph</span><span>:</span> <span>rgba</span><span>(</span><span>white</span><span>,</span> <span>0</span><span>.38</span><span>);</span>
<span>$dark-grey</span> <span>:</span> <span>#121212</span><span>;</span> <span>// Colour 2</span>
<span>$overlay</span><span>:</span> <span>mix</span><span>(</span><span>$dark-grey</span><span>,</span> <span>white</span><span>,</span> <span>95%</span><span>);</span>
<span>$overlay-light</span><span>:</span> <span>mix</span><span>(</span><span>$dark-grey</span><span>,</span> <span>white</span><span>,</span> <span>86%</span><span>);</span>
</code></pre></div></div>

<p>That’s it. Two colours and their shades.</p>

<p><img src="https://prudhvirampey.com/blog/images/palette.svg" alt="" title="From left, dark grey and its shades and then the whites"></p>

<ul>
  <li>Baseline <code>dark-grey</code> theme colour which is recommended by Material design and <em>lighter</em> variants of it for components such as code blocks and tables.</li>
  <li>Shades of <code>white</code> for different levels of emphasis of text. <sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup></li>
</ul>

<p>This also gives us the flexibility to choose <em>our own</em> primary dark color. For eg, if we change the value of <code>dark-grey</code> to that of something like <code>deep-purple</code> (<code>#1F1B24</code>). Voilà, we get the following palette:</p>

<p><img src="https://prudhvirampey.com/blog/images/palette-2.svg" alt=""></p>

<p>and theme:</p>

<p><img src="https://prudhvirampey.com/blog/images/purple-mode.png" alt=""></p>

<p>The palette can be easily customized to support your own favorite dark colour!</p>



<p>The rest of the stylesheet is more or less straightforward. Here are some additional quirks that I thought were cool:</p>

<ul>
  <li>Don’t forget to turn over your faithful scrollbar to the dark side</li>
</ul>

<div><div><pre><code><span>*</span> <span>{</span>
    <span>scrollbar-color</span><span>:</span> <span>$dark-grey</span> <span>$overlay-light</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p><img src="https://prudhvirampey.com/blog/images/scrollbars.png" alt=""></p>

<ul>
  <li>You can invert the colour of your charts and plots to keep that dark consistency going.</li>
</ul>

<div><div><pre><code><span>canvas</span> <span>{</span>
    <span>filter</span><span>:</span> <span>invert</span><span>(</span><span>100%</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p><img src="https://prudhvirampey.com/blog/images/light-dark-viz.png" alt="" title="I like my graphs like I like my chocolate, dark"></p>

<blockquote>
  <p>Psst, Check out the dark graphs in action <a href="http://prudhvirampey.com/new_blog/jupyter/2020/02/20/test.html#Example-1:-DropDown">here</a>.</p>
</blockquote>

<ul>
  <li>We also got some dark tables in the house babyy 👾</li>
</ul>

<div><div><pre><code><span>table</span> <span>th</span> <span>{</span>
    <span>background-color</span><span>:</span> <span>$overlay</span><span>;</span>
    <span>border-color</span><span>:</span> <span>$overlay-light</span><span>;</span>
    <span>color</span><span>:</span> <span>$high-emph</span><span>;</span>
<span>}</span>

<span>table</span> <span>td</span> <span>{</span>
    <span>background-color</span><span>:</span> <span>$dark-grey</span><span>;</span>
    <span>border-color</span><span>:</span> <span>$overlay-light</span><span>;</span>
    <span>color</span><span>:</span> <span>$med-emph</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p><img src="https://prudhvirampey.com/blog/images/light-dark-tables.png" alt="" title="Let there be shiny data"></p>



<p>You can get the stylesheet from this Github gist <a href="https://gist.github.com/prampey/aac8f8436827ea09f53a67873142706c">here</a>. Save it to <code>_sass/minima</code> and add this import line in <code>custom-styles.scss</code>.</p>

<div><div><pre><code><span>/*-----------------------------------*/</span>
<span>/*----- ADD YOUR STYLES BELOW -------*/</span>

<span>@import</span> <span>"minima/dark-mode"</span><span>;</span>
</code></pre></div></div>

<p>That’s it! <code>fastpages</code> finally has the power of the dark side.</p>

<p>Enjoy ⚡</p>





  </div>  
  
  
  
</article>
      </div>
    </div></div>]]>
            </description>
            <link>https://prudhvirampey.com/blog/colours/jekyll/css/fastpages/2020/10/30/hello-dark-mode.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25091913</guid>
            <pubDate>Sat, 14 Nov 2020 12:30:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A revolution in the field of energy research]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25091769">thread link</a>) | @CapitalistCartr
<br/>
November 14, 2020 | http://www.upv.es/noticias-upv/noticia-12415-una-revolucion-en.html | <a href="https://web.archive.org/web/*/http://www.upv.es/noticias-upv/noticia-12415-una-revolucion-en.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p><img src="http://www.upv.es/noticias-upv/imagenes/int_itq.jpg" alt="" title=""></p><p>A team of researchers from the Universitat Politècnica de València  (UPV) and the Spanish National Research Council (CSIC) has discovered a new method that makes it possible to transform electricity into hydrogen or chemical products by solely using microwaves – without cables and without any type of contact with electrodes. This can represent a disruption in the field of energy research and a key development for the decarbonisation of process industry, as well as for the future of the automotive sector and the chemical industry, among many others. The study has been published in the latest edition of Nature Energy.</p> 
<p>The technology developed and patented by the UPV and CSIC is based on the phenomenon of the microwave reduction of solid materials, in this study exemplified by the reduction of Cerium oxide. This method enables to carry out electrochemical processes directly without requiring electrodes, which simplifies and significantly reduce capital costs, as it provides more freedom in the design of the structure of the device and choosing the operation conditions, mainly the electrolysis temperature.</p> 
<p>“It is a technology with great practical potential, especially for its use in energy storage and production of synthetic fuels and green chemicals. This aspect has significant importance nowadays, as both transportation and industry are immersed in a transition towards decarbonisation and electrification, meaning they have to meet very challenging targets in 2030 and 2040 in order to decrease the consumption of energy and substances from fossil sources, mainly natural gas and oil,” highlights Prof. José Manuel Serra, researcher from the Chemical Technology Institute (ITQ).</p> 
<h3>Green hydrogen for industrial and transportation uses</h3> 
<p>The main use of this “disruptive” technology reported by researchers from the Information Technologies and Communications Institute (ITACA) of the UPV and ITQ, joint centre of the UPV and CSIC, is the production of green hydrogen (produced without emitting greenhouse gases) from water, for industrial and transportation uses.</p> 
<p>As noted by the ITQ and ITACA team, it is a technology with great potential for the automotive sector, specifically for cars fuelled by fuel cells and hybrids or large vehicles such as trains or ships. But also for the chemical industry, metallurgy, the ceramic sector or the production of fertilisers, among many other sectors. “This method will make it possible to transform renewable electricity, typically of solar or wind origin, into added value products and green fuels. It has countless uses and we hope that new uses will emerge for energy storage and process industry, by tuning materials composition and operation conditions”, highlights Prof. José Manuel Catalá, researcher at the ITACA institute of the UPV.</p> 
<p>In the article published in Nature Energy, the researchers also provide a techno-economic study that reveals that this technology would enable to obtain high energetic efficiency, and that the cost of the facilities (CAPEX) to carry out the hydrogen production process are very competitive compared to conventional technologies for hydrogen production.</p> 
<h3>Ultra-fast charging of batteries… and space exploration</h3> 
<p>The UPV and CSIC team is studying other future uses for this technology, and is currently focusing its efforts on the use for the ultra-fast charging of batteries “Our technology could enable a practically instantaneous reduction (electron injection) of the electrode (metallic anode) that stores energy. In other words, we would go from a (2D) layer-based progressive charging process, which can take hours, to a simultaneous recharging process in the entire (3D) volume of the material storing the energy, which would make it possible to charge a battery in a few seconds,” says Prof. Catalá.</p> 
<p>Another use would be the direct generation of oxygen with microwaves, which opens a broad spectrum of new uses. “One specific use would be the direct production of oxygen with extra-terrestrial rocks (regoliths), which could have a key role in the future exploration and colonisation of the Moon, Mars or other moons in the solar system,” concludes Prof. Serra.</p> 
<h3>A short history of the discovery</h3> 
<p>The team of researchers observed that when ionic materials were treated with microwaves, the materials displayed unusual changes in their properties, especially in their electronic conductivity, changes that did not happen upon conventional heating. “We were very intrigued about these sudden changes in their electrical properties and wanted to understand what process was going on. For this reason, we keep on designing new experiments, new microwave reactors and utilizing other analytical techniques,” explains Prof. Catalá.</p> 
<p>The team from the ITACA and ITQ institutes verified that microwaves interact with these materials by ‘accelerating’ the electrons and triggering the release of molecules of oxygen from their structure (which is also called reduction). This change became visible to us by sudden alterations to the conductivity at relatively low temperatures (approximately 300ºC). “This non-equilibrium state is maintained while microwaves are applied, but tends to revert back via reoxygenation (reoxidation) when microwaves are switched off. At first sight, we realised the great practical potential of this discovery, especially now that very ambitious goals should be meet in the next two decades to reach an economy with zero net greenhouse gas emissions,” concludes Prof. Serra.</p> 
<h3><b>Reference</b></h3> 
<p>J. M. Serra, J. F. Borras-Morell, B. Garcia-Baños, M. Balaguer, P. Plaza-Gonzalez, J. Santos-Blasco, D. Catalán-Martínez, L. Navarrete and J. M. Catala-Civera. Hydrogen production via microwave-induced water splitting at low temperature. Nature Energy</p></div></div>]]>
            </description>
            <link>http://www.upv.es/noticias-upv/noticia-12415-una-revolucion-en.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25091769</guid>
            <pubDate>Sat, 14 Nov 2020 11:55:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Empathy and perspective taking: How social skills are built]]>
            </title>
            <description>
<![CDATA[
Score 103 | Comments 73 (<a href="https://news.ycombinator.com/item?id=25091765">thread link</a>) | @CapitalistCartr
<br/>
November 14, 2020 | https://www.cbs.mpg.de/empathy-and-perspective-taking-how-social-skills-are-built | <a href="https://web.archive.org/web/*/https://www.cbs.mpg.de/empathy-and-perspective-taking-how-social-skills-are-built">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  
  
  
  

  

  <p>Being able to feel empathy and to take in the other person's perspective – these are two abilities through which we understand what is going on in the other person's mind. Although both terms are in constant circulation, it is still unclear what exactly they describe and constitute. Scientists at the Max Planck Institute for Human Cognitive and Brain Sciences (MPI CBS) in Leipzig, together with colleagues from Oxford University and other institutions, have now developed a model which explains what empathy and perspective taking are made of. They show that it is not one specific skill that enables us to put ourselves in another person's shoes. These skills are made up of many individual factors that vary according to the situation.</p>
  
  
<figure data-description="<p>It is not one specific skill that enables us to put ourselves in another person's shoes. These skills are made up of many individual factors that vary according to the situation.</p>" data-picture="base64;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">
      
    

    
    <figcaption>
        <p>It is not one specific skill that enables us to put ourselves in another person's shoes. These skills are made up of many individual factors that vary according to the situation.</p>
        <p>
           shutterstock
        </p>
    </figcaption>
</figure>



<p>Understanding what other people want, how they feel, and how they see the world is becoming increasingly important in our complex, globalised society. Social skills enable us to make friends and create a network of people who support us. But not everyone finds it easy to interact with other people. One of the main reasons is that two of the most important social skills - empathy, i.e. being able to empathise with the other person's emotions, and the ability to take a perspective, i.e. being able to gain an information by adopting another person’s point of view - are developed to different degrees.</p>
<p>Researchers have long been trying to find out what helps one to understand others. The more you know about these two social skills, the better you can help people to form social relationships. However, it still not exactly clear what empathy and perspective taking are (the latter is also known as “theory of mind“). Being able to read a person's emotions through their eyes, understand a funny story, or interpret the action of another person—in everyday life there are always social situations that require these two important abilities. However, they each require a combination of different individual subordinate skills. If it is necessary to interpret looks and facial expressions in one situation, in another it may be necessary to think along with the cultural background of the narrator or to know his or her current needs.</p>

<figure data-description="Both capabilities, empathy and theory of mind, are processed in the brain by a 'main network' specialised in empathy (red brain areas) or changing perspective (blue brain areas), which is activated in every social situation. But, depending on the situation, it also involves additional networks." data-picture="base64;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">
      
    

    
    <figcaption>
        <p>
          Both capabilities, empathy and theory of mind, are processed in the brain by a 'main network' specialised in empathy (red brain areas) or changing perspective (blue brain areas), which is activated in every social situation. But, depending on the situation, it also involves additional networks.
        </p>
        <p>
           Apa PsycNet
        </p>
    </figcaption>
</figure>


<p>To date, countless studies have been conducted that examine empathy and perspective taking as a whole. However, it has not yet been clarified what constitutes the core of both competencies and where in the brain their bases lie. Philipp Kanske, former MPI CBS research group leader and currently professor at the TU Dresden, together with Matthias Schurz from the Donders Institute in Nijmegen, Netherlands, and an international team of researchers, have now developed a comprehensive explanatory model.</p>
<p>"Both of these abilities are processed in the brain by a 'main network' specialised in empathy or changing perspective, which is activated in every social situation. But, depending on the situation, it also involves additional networks," Kanske explains, referring to the results of the study, which has just been published in the journal&nbsp;<i>Psychological Bulletin</i>. If we read the thoughts and feelings of others, for example, from their eyes, other additional regions are involved than if we deduce them from their actions or from a narrative. "The brain is thus able to react very flexibly to individual requirements."</p>
<p>For empathy, a main network that can recognise acutely significant situations, for example, by processing fear, works together with additional specialised regions, for example, for face or speech recognition. When changing perspective, in turn, the regions that are also used for remembering the past or fantasising about the future, i.e., for thoughts that deal with things that cannot be observed at the moment, are active as the core network. Here too, additional brain regions are switched on in each concrete situation.</p>
<p><strong>Complex social problems require a combination of empathy and perspective taking</strong></p>
<p>Through their analyses, the researchers have also found out that particularly complex social problems require a combination of empathy and a change of perspective. People who are particularly competent socially seem to view the other person in both ways­—­on the basis of feelings and on the basis of thoughts. In their judgement, they then find the right balance between the two.</p>
<p>"Our analysis also shows, however, that a lack of one of the two social skills can also mean that not this skill as a whole is limited. It may be that only a certain factor is affected, such as understanding facial expressions or speech melody," adds Kanske. A single test is therefore not sufficient to certify a person's lack of social skills. Rather, there must be a series of tests to actually assess them as having little empathy, or as being unable to take the other person's point of view.&nbsp;</p>
<p>The scientists have investigated these relationships by means of a large-scale meta-analysis. They identified, on the one hand, commonalities in the MRI pattern of the 188 individual studies examined when the participants used empathy or perspective taking. This allowed the localisation of the core regions in the brain for each of the two social skills. However, results also indicated how the MRI patterns differed depending on the specific task and, therefore, which additional brain regions were used.&nbsp;</p>
  
</div></div>]]>
            </description>
            <link>https://www.cbs.mpg.de/empathy-and-perspective-taking-how-social-skills-are-built</link>
            <guid isPermaLink="false">hacker-news-small-sites-25091765</guid>
            <pubDate>Sat, 14 Nov 2020 11:54:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A visual comparison of macOS Catalina and Big Sur]]>
            </title>
            <description>
<![CDATA[
Score 104 | Comments 135 (<a href="https://news.ycombinator.com/item?id=25091739">thread link</a>) | @Kaibeezy
<br/>
November 14, 2020 | https://www.andrewdenty.com/blog/2020/07/01/a-visual-comparison-of-macos-catalina-and-big-sur.html | <a href="https://web.archive.org/web/*/https://www.andrewdenty.com/blog/2020/07/01/a-visual-comparison-of-macos-catalina-and-big-sur.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/BlogPosting">

<div itemprop="articleBody">
<p><img src="https://www.andrewdenty.com/blog/assets/img/catalina-vs-big-sur.jpg" alt="Catalina vs Big Sur">
This post is an attempt to provide a visual comparison of pretty dramatic UI changes between macOS Catalina and Big Sur.</p>
<p>Why did I end up doing this? Well, this week I installed the developer beta of macOS Big Sur as I was curious what impact the new UI would have on the <a href="https://www.andrewdenty.com/airtame-desktop-app.html">app I currently design</a>. I wanted to make sure my team was ahead of any coming changes as we were burned by changes in last year’s release of Catalina.</p>
<p>I found myself taking lots of screenshots to try and track the changes and thought this might be worth sharing. I decided to carry out a quick catalogue of the UI changes as this may be helpful to other people getting ready for macOS Big Sur.</p>
<p>All of the screenshots below are taken on a default install of macOS and the Catalina version is always on the left. I made a conscious effort not to resize any windows or change any default settings. I haven’t captured everything, but it is a good taste of the changes so far.</p>
<h2 id="first-impressions">First impressions</h2>


<p>At first glance macOS is a lot more colourful with, and the biggest obvious change is the bright, slightly more cartoonish iOS shaped icons. Everything is more rounded and it feels like everything has gotten a little bigger. Could this be the first hint that macOS is preparing for touch support in the future? One interesting tidbit, is that even though the icons are based around the capsule shape, many of them (like Contacts, or Preview) have elements which protrude from them giving an extra feeling of depth.</p>
<h2 id="finder-and-preview">Finder and Preview</h2>
<p>Finder sees some significant changes. Of all the places I think Apple needs to get the new UI spot on, is Finder. Overall the default size of Finder seems to be bigger in macOS Big Sur.</p>


<p>One thing that struck me at this point is that Finder looks a mess with many of the more advanced features enabled. The bottom screenshot shows Finder with a Path Bar, Status Bar and multiple tabs. To me, it seems like the design team have not yet been able to find a way to elegantly integrate these elements into the iOS inspired UI.</p>
<p>One final thing to note is that in Finder the search bar at the top right has been replaced with a search icon that expands when clicked. This change seems a little inconsistent as it’s not made it to Preview. I can guarantee this will result in fewer people discovering Finder’s Spotlight search goodness.</p>
<h2 id="preferences">Preferences</h2>
<p>Preferences sees quite a lot of change in some areas.
The Dock preferences pane has become “Dock and Menu Bar” and now integrates controls for the new macOS control center. It uses a nicely integrated sidebar to manage different categories.</p>
<p>It’s a shame that this sidebar hasn’t yet made it to other parts of the preferences UI with Network and Notifications still using a very old looking sidebar.</p>
<p>One aspect of preferences that has been quite controversial (on Twitter at least) is the new icons. I’m going to hold off judgement for now as they don’t yet look finished. For example, the Notifications icon does not even support retina displays.</p>


<p>You’ll notice that the Startup Disk pane uses apples new dialog (or sheet) UI. This is quite a departure from the existing sheet drop-down - it feels much more iOS-like.</p>
<h2 id="menu-bar-and-notification-center">Menu Bar and Notification Center</h2>
<p>This is one of the areas where macOS has changed the most. It’s also difficult to take decent screenshots of both of these. Control Center looks like it’s been badly photocopied and the Notification Center in Catalina has a bug whereby it renders at double it’s normal width.</p>
<p>What was obvious within a few minutes of use was that the Control Center is a massive improvement on Catalina’s row of scattered Menu bar icons. The updated WiFi menu is also a massive improvement, as the old list could easily be overwhelming with the number of WiFi networks displayed.</p>
<p>I’m less convinced that the Notification Center is easier to use though. Now it has no background, there is less to separate a list of notifications from my messy desktop!</p>
<p>I will try and get better screenshots for this section and update it in the near future.</p>


<h2 id="safari">Safari</h2>





<h2 id="reminders">Reminders</h2>


<h2 id="notes">Notes</h2>
<p>The biggest news in Notes is that after years, the Skeuomorphic paper texture has finally been retired!</p>


<h2 id="photos">Photos</h2>


<h2 id="apple-music-and-podcasts">Apple Music and Podcasts</h2>
<p>Music and Podcasts were brand new last year with the release of Catalina. It’s obvious that the new UI has been planned for a while as Apple Music and Podcasts are mostly indistinguishable from their initial Catalina release. For example both apps already include the new full height sidebar.</p>
<p>For me this illustrates a bigger point that <a href="https://twitter.com/stevesi/status/1275311056672325633" target="_blank">Steven Sinofsky recently made on Twitter</a> - that Apple is executing a meticulous multi-year strategy.</p>


<p>One area where changes are evident are is in preferences windows. Both apps make use of Apple’s new accent colour and new glyph icon library.</p>
<h2 id="other-bundled-apps">Other bundled apps</h2>
<p>It was impossible to go into depth with every single bundled app. On the whole, the updates to Maps, Books and Mail all look solid with extensive use of the new sidebar.</p>


<h2 id="utilities">Utilities</h2>
<p>Both Activity Monitor and Disk Utility have received a new style toolbar. As with Finder, there are no longer any rows meaning all elements are at the same level. On first impressions, I feel this is a little visually confusing and makes it harder to scan. The search field also loses a lot of its contrast.</p>
<p>Unsurprisingly Terminal is almost unchanged.</p>


<h2 id="almost-unchanged">Almost unchanged</h2>
<p>On the subject of unchanged apps, there were a number of other apps that are so far relatively unchanged.</p>
<p>Siri in macOS Big Sur shows no apparent changes. I think this is a little strange considering the overhaul Siri is receiving in iOS 14. There don’t even seem to be any radius changes to the borders.</p>
<p>The most extreme case of no change is Stickies. It’s completely identical between both releases. What’s more, I don’t think it’s changed much since MacOS 9 judging from its weird, retro controls.</p>


<p>Boot Camp is also practically unchanged, although this is perhaps unsurprising given Apple’s move to Apple Silicon, so presumably Boot Camp’s days are numbered. It did receive a new icon though.</p>
<h2 id="takeaways">Takeaways</h2>
<p>Overall, the UI changes in macOS aren’t as dramatic as I was expecting. Big Sur’s new UI feels like a largely incremental set of changes to make macOS feel more coherent with iOS and iPad OS. Even if there are a few teething issues and the look is a little jarring at first, this has to be a good thing in the long-term.</p>
<p>Having said that, Apple still has a vast amount of work to do to perfect the new macOS UI. It unsurprising as this is the first developer beta, but there are still many rough edges.</p>
<p>I hope in the long term they focus on creating consistent patterns: for example for the first launch experience of apps. Right now there are several different layouts and approaches to this UI. I also hope Apple don’t leave pro users behind. Right now some of the less frequently used UI elements such as status bars and path bars look a little unloved. They don’t feel well integrated into the UI and in some cases lack visual separation.</p>
<p>If you’re interested in reading even more about the design changes in macOS Big Sur, Cult of Mac have <a href="https://www.cultofmac.com/715717/fantastic-fugly-all-new-app-icons-macos-big-sur/" target="_blank">a comprehensive overview of the new icons</a>.</p>
</div>
</article></div>]]>
            </description>
            <link>https://www.andrewdenty.com/blog/2020/07/01/a-visual-comparison-of-macos-catalina-and-big-sur.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25091739</guid>
            <pubDate>Sat, 14 Nov 2020 11:48:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On the expressive power of programming languages (2019)]]>
            </title>
            <description>
<![CDATA[
Score 199 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25091705">thread link</a>) | @fanf2
<br/>
November 14, 2020 | https://pwlconf.org/2019/shriram-krishnamurthi/ | <a href="https://web.archive.org/web/*/https://pwlconf.org/2019/shriram-krishnamurthi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" role="main">
      


<div>
  <header>
    
    <h2>
      Brown University
    </h2>
    <img src="https://pwlconf.org/images/2019/shriram-krishnamurthi.jpg" alt="photo of Shriram Krishnamurthi">
  </header>
  <div>
    <h2>On the Expressive Power of Programming Languages</h2>
    <div>
      <p>
        <iframe src="https://www.youtube.com/embed/43XaZEn2aLc" frameborder="0" allow="accelerometer; encrypted-media; gyroscope" allowfullscreen=""></iframe>
      </p>
    </div>

    <p>
      Papers are like poems. Some are dazzling, some are pedestrian, some are insightful, and some reward long periods of quiet contemplation. They stir up an emotional reaction that goes beyond the strictly rational, and can often be deeply personal.</p>

    <p>
      In graduate school, during a period of identity crisis, I came across <a href="https://felleisen.org/matthias/">Matthias Felleisen's</a> “<a href="https://www.sciencedirect.com/science/article/pii/016764239190036W">On the Expressive Power of Programming Languages</a>”. At a time when the world was ruled by C++, I had immersed myself in Scheme, so I always looked skeptically at mainstream linguistic claims. However, the language wars seemed beyond rational discourse. So the idea that someone could take a concept as nebulous as “expressiveness&amp;rdquo and formalize it was already a revelation. But the beauty of this paper goes well beyond that: it also lies in the cleanliness of the approach, the correspondence of the formalism to intuition, and the tautness of its execution.</p>

    <p>
      It was the most stunning paper I had ever read, and remains so. It's like the poem that never leaves your soul.</p>

    <p>
      Unfortunately, this paper may not be easy to read for the uninitiated: it depends on a certain amount of “cultural knowledge” of programming language theory. I hope to peel off some of those layers and help you, too, understand the paper — hopefully while preserving the joy and beauty I experienced.</p>
    
    <p>
      Shriram is the Vice President for Programming Languages at Brown University in Providence, RI, USA. He’s not, really, but that’s what it says on his business card. At heart, he's a person of ill-repute: a <a href="https://schemers.org/">Schemer</a>, <a href="https://racket-lang.org/">Racketeer</a>, and <a href="https://www.pyret.org/">Pyreteer</a>. He believes tropical fruit are superior to all other kinds. He is terrified of success, because he may be forced to buy a suit. He is known to interrogate his audiences to ensure they’re paying attention. <strong>So, be alert. You can read email later.</strong>
    </p>
    <ul>
      <li>
        <strong>Twitter:</strong>
        <a href="https://twitter.com/ShriramKMurthi">
          @ShriramKMurthi
        </a>
      </li>
      <li>
        <strong>Site:</strong>
        <a href="https://cs.brown.edu/~sk/">
          https://cs.brown.edu/~sk/
        </a>
      </li>
      <li>
        <strong>DBLP:</strong>
        <a href="https://dblp.uni-trier.de/pers/hd/k/Krishnamurthi:Shriram">
          https://dblp.uni-trier.de/pers/hd/k/Krishnamurthi:Shriram
        </a>
      </li>
    </ul>
  </div>
</div>

      

    </div></div>]]>
            </description>
            <link>https://pwlconf.org/2019/shriram-krishnamurthi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25091705</guid>
            <pubDate>Sat, 14 Nov 2020 11:43:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Leaning into Spivak's Calculus]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25091667">thread link</a>) | @tomhoule
<br/>
November 14, 2020 | https://www.tomhoule.com/leaning-into-calculus-chapter-1/ | <a href="https://web.archive.org/web/*/https://www.tomhoule.com/leaning-into-calculus-chapter-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
    

    <p>2020-11-14
      
        
      
    </p>

    
      
    
    
    
      

  <nav aria-labelledby="toc-heading">
    <h2 id="toc-heading">Table of contents</h2>
    <ol>
      
        <li>
          
          
          
          
          <a href="#just-starting">
            Just starting
          </a>
        </li>
      
        <li>
          
          
          
          
          <a href="#two-weeks-later">
            Two weeks later
          </a>
        </li>
      
        <li>
          
          
          
          
          <a href="#a-few-months-later">
            A few months later
          </a>
        </li>
      
        <li>
          
          
          
          
          <a href="#conclusion">
            Conclusion
          </a>
        </li>
      
    </ol>
  </nav>


    

    <p>This post contains three updates at different points in time on formalizing
chapter 1 of Michael Spivak’s <em>Calculus</em> book and its problems in <a href="https://leanprover-community.github.io/">Lean</a>.</p>
<p>You can find the proofs <a href="https://github.com/tomhoule/spivak-calculus/">on GitHub</a>.</p>
<hr>
<h2 id="just-starting">Just starting</h2>
<blockquote>
<p>On n’écrit qu’à la pointe de son savoir, à cette pointe extrême qui sépare
notre savoir et notre ignorance, et qui fait passer l’un dans l’autre. C’est
seulement de cette façon qu’on est déterminé à écrire.</p>
<p>(<a href="https://en.wikipedia.org/wiki/Difference_and_Repetition"><em>Différence et
répétition</em></a>, towards
the beginning)</p>
</blockquote>
<p>They say the right time to write about something is while learning. I just got
through <a href="https://leanprover.github.io/theorem_proving_in_lean/"><em>Theorem proving in
Lean</em></a> — tons of fun,
warmly recommended — and now feels like the time to see what I can do with it.</p>
<p>I have Michael Spivak’s
<a href="https://www.goodreads.com/book/show/328645.Calculus"><em>Calculus</em></a>, third
edition, lying around at home. It should be accessible with a bit of help from
the internet, so this is what I will attempt to go through. I expect nearly all
of the book’s content to be new to me.</p>
<p>What I want to validate is that for someone reasonably familiar with programming
who wants to learn more mathematics, it is possible to learn by writing proofs
and solving problems from regular maths textbooks with existing tools, and in
particular the Lean theorem prover. <strong>The hard part should be the mathematics,
not handling the theorem prover</strong>.</p>
<p>I have the feeling this would be the best way for me to learn, since I lack the
confidence in my hand-written proofs, and I know by experience that I make a lot
of mistakes. On paper, these mistakes end up derailing the proof, but they
wouldn’t have serious consequences if every step was checked by a computer: I
can just correct them.</p>
<p>I will frequently refer to
<a href="https://github.com/leanprover-community/mathlib">mathlib</a>, the Lean community’s
library of formalized theorems. It contains basic facts and structures you do
not want to build again when writing your own proofs, as well as extremely
useful tactics like <a href="https://leanprover-community.github.io/mathlib_docs/tactics.html#linarith"><code>linarith</code></a>.</p>
<h3 id="first-chapter">First chapter</h3>
<p>The first chapter is titled <em>Basic properties of numbers</em>. Its purpose is to
reformulate and condense facts that the reader supposedly already knows.</p>
<p>Twelve properties are treated. Four properties of addition:</p>
<ol>
<li>Associativity: $$ a + (b + c) = (a + b) + c $$</li>
<li>Zero as the identity element: $$ a + 0 = 0 + a = a $$</li>
<li>Addition of opposites: $$ a + (-a) = (-a) + a = 0 $$</li>
<li>Commutativity: $$ a + b = b + a $$</li>
</ol>
<p>By now, subtraction is already defined, and two small proofs already carried
out. I used the standard library’s <code>int</code> module for the time being, but
I suspect we’ll have to switch to mathlib’s real number module or something
else, after I read a bit more about it.</p>
<p>The next properties are about multiplication:</p>
<ol start="5">
<li>Associativity: $$ a \cdot (b \cdot c) = (a \cdot b) \cdot c $$</li>
<li>One as the identity element: $$ a \cdot 1 = 1 \cdot a = a $$</li>
<li>Multiplication of inverses:
$$ \forall a, a ≠ 0 \to \exists a^{-1}, a \cdot a^{-1} = a^{-1} \cdot a = 1 $$</li>
<li>Commutativity: $$ a \cdot b = b \cdot a $$</li>
</ol>
<p>Division is then defined in terms of multiplication. The part of property 7
about <em>a</em>&nbsp;≠&nbsp;0 explains why division by zero doesn’t work (it has no meaningful
inverse).</p>
<p>At this point, I feel an itch to generalize this beyond integers. We’re going to
need at least real numbers, I figure. I start browsing Wikipedia:
<a href="https://en.wikipedia.org/wiki/Group_(mathematics)">groups</a> aren’t what we want
(numbers under addition are a group, but not multiplication because it lacks
invertibility). Next stop is
<a href="https://en.wikipedia.org/wiki/Multiplication#Multiplication_of_different_kinds_of_numbers">multiplication</a>,
which points me to the page on the <a href="https://en.wikipedia.org/wiki/Construction_of_the_real_numbers#Construction_from_Cauchy_sequences">construction of real
numbers</a>,
where I&nbsp;learn about <a href="https://en.wikipedia.org/wiki/Field_(mathematics)">ordered
fields</a>. This is apparently
what we&nbsp;want, and mathlib <a href="https://leanprover-community.github.io/mathlib-overview.html">apparently supports
them</a>.</p>
<p>I hope this attitude of digging just as deep as I need to in order to make
progress is going to work out.</p>
<p>After a little while digging into how to import mathlib (combination of using
the right lean version in <code>leanpkg.toml</code>, learning the existence of <code>import</code>
statements, and the right <code>leanpkg</code> invocations — <em>Note added later: use
<code>leanproject</code> instead if you want to avoid compiling mathlib, it is very
time-consuming</em>), I realize working with fields won’t let you use convenient
numeric notations. I try real numbers — appropriately located at
<code>data.real.basic</code> in mathlib — only to realize that reflexivity doesn’t work for
things as simple as <code>5 - 3 = 2</code>. Looking at the source for the <code>data.real.basic</code>
module, it seems like many definitions are non-computable. It makes sense,
because real numbers aren’t the floats we know and love, π isn’t some
approximation but really π, and we can’t compute that exactly. I don’t know whether Lean
can “specialize” computable instances automatically, and detect that even though
<code>5</code> and <code>3</code> are real numbers in this context, <code>5 - 3</code> is computable. I’d have to
know more about representations of reals to know if it’s a temporary limitation
in mathlib or something deeper. So I go with rational numbers for the examples
involving reflexivity. <code>α</code> is a field, rational numbers are a field, so it works
out nicely.</p>
<p>The consequences of the properties of multiplication give rise to two nice
examples we can prove in Lean:</p>
<pre><code>example : (a ≠ 0) → (a * b = a * c) → b = c :=
assume hnzero h,
    calc
        b   = 1 * b : by rw one_mul
        ... = (a⁻¹ * a) * b : by rw [inverse_mul α a hnzero]
        ... = a⁻¹ * (a * b) : by rw [mul_assoc']
        ... = a⁻¹ * (a * c) : by rw [h]
        ... = c : by rw [mul_assoc', inverse_mul α a hnzero, one_mul]

example : a ≠ 0 → (a * b = 0) → (a = 0 ∨ b = 0) :=
assume hnzero h,
or.inr $ calc
    b = 1 * b : by rw one_mul b
    ... = (a⁻¹ * a) * b : by rw [inverse_mul α a hnzero]
    ... = a⁻¹ * (a * b) : by rw [mul_assoc']
    ... = a⁻¹ * 0 : by rw h
    ... = 0 : by rw mul_zero
</code></pre>
<p>I started by adding <code>decidable α</code> instance on top of <code>field α</code> to get
<code>a&nbsp;=&nbsp;0&nbsp;∨&nbsp;¬(a&nbsp;=&nbsp;0)</code> for the second example. It felt like it should be possible to
prove it without, but it seemed like even mathlib uses <code>classical</code> (see
<code>mul_eq_zero'</code> in <code>group_with_zero.lean</code>, and <code>division_ring.to_domain</code> in
<code>field.lean</code>). Then I noticed the book relies on <code>a ≠ 0</code> and added the hypothesis.</p>
<ol start="9">
<li>Distributivity: $$ a \cdot (b + c) = (a \cdot b) + (a \cdot c) $$</li>
</ol>
<p>For the next proof, I needed a proof of <code>0&nbsp;≠&nbsp;2</code>, which I got to from <code>0&nbsp;&lt;&nbsp;2</code>,
which required changing the instance of <code>field&nbsp;α</code> to <code>linear_ordered_field&nbsp;α</code>.
That seems reasonable.</p>
<p>Writing down the proof also made it clearer that the part that needs
distributivity is <code>a&nbsp;+&nbsp;a&nbsp;= 2&nbsp;*&nbsp;a</code>:</p>
<pre><code>def add_self_eq_two_mul : a + a = 2 * a :=
calc
    a + a   = (a * 1) + a : by rw mul_one'
        ... = (a * 1) + (a * 1) : by rw mul_one'
        ... = a * (1 + 1) : by rw [←mul_distrib']
        ... = a * 2 : by refl
        ... = 2 * a : by rw mul_comm'
</code></pre>
<p><code>-a</code> can also be called an additive inverse. Interesting.</p>
<p>…<em>ellipsis</em>…</p>
<hr>
<h2 id="two-weeks-later">Two weeks later</h2>
<p>I continued going through the chapter step by step, and now getting started on
the problems.</p>
<ul>
<li>Some patterns like “divide both sides of the equation by the same amount” do
not translate easily to Lean. I had to learn to “summon” values, adding zero,
then opposite, or multiplying by one, then inverse.</li>
<li>Represent sequences with inductively defined functions (gizmo).</li>
<li>A lot of function names to memorize</li>
<li>I somehow find some facts easier to grasp through induction rules:
<ul>
<li><code>choose k n = choose k-1 n-1 + choose k n-1</code></li>
<li><code>n! = n * (n-1)!</code></li>
</ul>
</li>
<li>I had to figure out big operators and how to use finite sets (<code>finset</code>)</li>
<li>For problem 4, I had to figure out casts and
<code>rwa</code>, <code>simpa</code>. Do the computable parts with integers, then cast to reals to
work with square roots. Computations with real numbers were a pain at first,
since they are not computable: you need to cast to something computable, like
rational numbers, to make any progress. <em>Note added later: this was all solved when I learned
about the <a href="https://leanprover-community.github.io/mathlib_docs/tactics.html#norm_num"><code>norm_num</code></a> and <a href="https://leanprover-community.github.io/mathlib_docs/tactics.html#norm_cast"><code>norm_cast</code></a> tactics</em>.</li>
<li><a href="https://leanprover-community.github.io/mathlib_docs/tactics.html#library_search">library_search</a>,
<a href="https://leanprover-community.github.io/mathlib_docs/tactics.html#squeeze_simp%20/%20squeeze_simpa%20/%20squeeze_dsimp%20/%20squeeze_scope">squeeze_simp</a>
are big time-savers and enormously helpful in discovering more of mathlib. One
pattern that works really well when you are looking for the right theorems to
invoke for the next step in your proof, is to write it in the most general way
possible in an example or a helper function, and try <code>library_search</code> on that.</li>
<li>Try <code>#lint</code> — it’s quaint.</li>
</ul>
<p>I’ll stop here now, and focus on solving the problems without worrying about
whether this will make a good blog post.</p>
<hr>
<h2 id="a-few-months-later">A few months later</h2>
<p>Let’s follow up on the experience report, where I wrote down my impressions as I
just started working on the problems from Michael Spivak’s
<a href="https://www.goodreads.com/book/show/328645.Calculus"><em>Calculus</em></a> (3rd ed.) with
the Lean theorem prover.</p>
<p>A few months later, <a href="https://github.com/tomhoule/spivak-calculus/">I finished writing Lean proofs for all the problems in chapter 1</a>.</p>
<p>After the expected period of familiarization with Lean and
mathlib, what I hoped for is what happened: <strong>at this point, for the problems I
am solving, the hard part is the maths, not the theorem prover</strong>.</p>
<h3 id="writing-down-the-problems">Writing down the problems</h3>
<p>Some problems took some thinking to translate from natural language into Lean.
Stating the problem precisely is part of the proof effort.</p>
<p>Take problem 24 (c):</p>
<blockquote>
<p>Let <code>s(a_{1},...,a_{k})</code> be some sum formed from <code>a_{1},...,a_{k}</code>. Show that
$$s(a_{1},…,a_{k}) = a_{1} + … + a_{k}$$</p>
</blockquote>
<p>The “some sum” part is open to interpretation. It could mean different ordering
of the terms, or different precedence. I went with precedence, and wrote the
following proof</p>
<pre><code>-- For any list of lists of sums, show that the sum of the list_sum's is equal
-- to the list_sum of the concatenated lists. This shows the order of
-- additions does not matter.
def part_c : ∀ (sums : list (list ℝ)), list_sum (list.join sums) = sums.foldl running_list_sum 0
| [] := rfl
| (head::tail) := by {
    let consed := list.cons head tail,
    have ih : list_sum (list.join tail) = tail.foldl running_list_sum 0, from part_c tail,
    have left : list_sum …</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.tomhoule.com/leaning-into-calculus-chapter-1/">https://www.tomhoule.com/leaning-into-calculus-chapter-1/</a></em></p>]]>
            </description>
            <link>https://www.tomhoule.com/leaning-into-calculus-chapter-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25091667</guid>
            <pubDate>Sat, 14 Nov 2020 11:36:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Matrix to replace proprietary and centralized chat apps]]>
            </title>
            <description>
<![CDATA[
Score 297 | Comments 210 (<a href="https://news.ycombinator.com/item?id=25091614">thread link</a>) | @jaemoe
<br/>
November 14, 2020 | https://jae.moe/blog/2020/11/using-matrix-to-replace-proprietary-and-centralized-chat-apps/ | <a href="https://web.archive.org/web/*/https://jae.moe/blog/2020/11/using-matrix-to-replace-proprietary-and-centralized-chat-apps/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <h4>Using Matrix to replace proprietary and centralized chat apps</h4><p>
            Reading time: 3 minutes.
            </p><p>As you may know it, I am a fervent user of the chat protocol Matrix.
If you don’t know what Matrix is, this is basically a protocol developed by the Matrix Foundation. Matrix is made to be federated, it means that servers implementing correctly the Matrix specification can communicate and therefore, users that are not on the same servers can still talk to each other. Some examples of federation would be with Activitypub (Mastodon) or Usenet.</p>
<blockquote>
<p>But wait Jae, we already have countless other chat apps already, Telegram, Signal and even XMPP which is federated!</p>
</blockquote>
<p>Well, here are the advantages of Matrix over all of those:</p>
<ol>
<li>
<p>Matrix is 100% open-source. As you may know Telegram’s servers are currently closed-source which poses a problem about trust. Nobody can say what the server is doing nor what it is harvesting which could be very dangerous. On the other hand, Signal, XMPP and Matrix are all fully open-source.</p>
</li>
<li>
<p>Matrix isn’t centralized to a single server. Currently, Telegram and Signal are centralized apps which means if the server goes down, everyone else goes down. moxie0 of Signal even wrote a <a href="https://signal.org/blog/the-ecosystem-is-moving/">blog post</a> on ‘why Signal will never have federation’ which is in my opinion a big mistake. XMPP still stands up as it is federated as well and has plenty of server implementations.</p>
</li>
<li>
<p>Matrix has a flagship client which has a great UX. <strong>This</strong> is a big point, as other federated protocols such as XMPP are kinda like a jungle for new users, you are greeted with a list of all clients which you can use and then comes the step where you have to choose your server. Lots of those servers are sometime hard to find, have very spartan UIs or even no web form or easy way to register whatsoever. On the other hand, Matrix has a flagship, <strong>Element</strong>, which is deemed as the ‘official Matrix client’ since it implements the Matrix specification correctly and is made by basically the same people. While other projects would have only done a server, Element made a polished client, focused mainly on the UX in order for people to take the first steps of moving to anything else easier. Even if the UX is still not perfect and some aspects aren’t finished yet, moving to Element will be easier than moving to any other XMPP client.</p>
</li>
</ol>
<p>I have been using Matrix since 2016 now and it has considerably improved over time, coming from “barely usable” to “let’s host my own homeserver”.
Even in its current state, lots of things are to be improved such as communities or custom stickers but everything is on the right way.
From now on, everything can <strong>only improve</strong>, we are seeing new server implementations, new clients, bots, communities moving to Matrix.</p>
<p>Matrix has several other features such as E2EE (end-to-end encryption) which is now enabled by default and bridges which can be used to temporarily bridge a Matrix room and a slack chat for instance.</p>
<p>If you want to give Matrix a try, download <a href="https://element.io/">Element</a> and create an account, it doesn’t even requires an email address!
You can also come and say ‘hello’ in my very own channel <strong>#home:jae.moe</strong> !</p>
<p>That’s all for today,
I’ll see you next time!
If you like my content, <a href="https://jae.moe/blog/index.xml">don’t forget to subscribe through RSS</a>!</p>

            
                <p><a href="https://news.ycombinator.com/item?id=25091614">Talk about it on Hacker News!</a>
            
        </p></div></div>]]>
            </description>
            <link>https://jae.moe/blog/2020/11/using-matrix-to-replace-proprietary-and-centralized-chat-apps/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25091614</guid>
            <pubDate>Sat, 14 Nov 2020 11:28:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don't use third party auth to sign in]]>
            </title>
            <description>
<![CDATA[
Score 828 | Comments 517 (<a href="https://news.ycombinator.com/item?id=25091420">thread link</a>) | @gurjeet
<br/>
November 14, 2020 | https://gurjeet.singh.im/blog/never-use-google-to-sign-in | <a href="https://web.archive.org/web/*/https://gurjeet.singh.im/blog/never-use-google-to-sign-in">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>If a website offers you to sign-in using Google (or any third-party service, say
Facebook, Github, etc.), don’t use that feature.</p>

<p>The long and short of it is that if Google (or third-party of your choice) locks
your account for some reason, you will be locked out of <em>all</em> the services where
you signed into using Google. There’s no shortage of examples where people have
been locked out of Google (and other services), with no recourse to re-enable
their accounts, and consequently losing all data hosted or protected by that
Google account.</p>

<p>Every respectable service allows you to create accounts using your email
address, so please use that method to create your accounts.</p>


  </div>
  
  
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://gurjeet.singh.im/blog/never-use-google-to-sign-in</link>
            <guid isPermaLink="false">hacker-news-small-sites-25091420</guid>
            <pubDate>Sat, 14 Nov 2020 10:38:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Magnetism and Congress]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25091138">thread link</a>) | @srl
<br/>
November 14, 2020 | https://ineffectivetheory.com/magnetism-congress/ | <a href="https://web.archive.org/web/*/https://ineffectivetheory.com/magnetism-congress/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><header><time datetime="2020-11-14">14 Nov 2020</time></header><h2 id="i">I.</h2><p>In 1842, Morse pressed Congress into allowing him to demonstrate his telegraph by sending a message from one congressional conference room to another. As a result, he was given about a million dollars (inflation-adjusted):</p><blockquote><p><a href="http://memory.loc.gov/cgi-bin/ampage?collId=llsl&amp;fileName=005/llsl005.db&amp;recNum=655"><em>(March 3, 1843)</em></a> Be it enacted… That the sum of thirty thousand dollars be… appropriated… for testing the capacity and usefulness of the system of electro-magnetic telegraphs invented by Samuel F. B. Morse… The Secretary of the Treasury [is] authorized to pay… Morse, and the persons employed under him, such sums of money as he may deem to be a fair compensation…</p></blockquote><p>Today, this seems like an astonishingly implausible story — a single person pesters Congress for a massive sum of money, and <em>gets it</em>.</p><p>This was not Morse’s first demonstration to Congress, though. It took him five years to secure funding.</p><p>In 1837, the Secretary of the Treasury (Levi Woodbury) was instructed by the House to investigate the feasibility of constructing a system of telegraphs for the United States. At the time, “telegraph” generally meant “optical telegraph”; the relays in such a system were humans, who watched one signal and then passed it on. When Woodbury called for proposals, though, Morse replied with his electromagnetic telegraph. This was the beginning of his engagement with Congress.</p><p>In 1838 and 1839, both the House and the Senate considered bills to support the development of Morse’s magnetic telegraph. In the Senate, the issue was whether to allow duty-free importation of construction materials; the House considered a bill for testing the practicality of constructing such a system (presumably with an eye towards directly financing it). Morse demonstrated the system, in 1838, to Congress and the President. Nevertheless, neither bill was ever voted on.</p><p>In 1842, Morse convinced Congress to allow him to demonstrate again. I can’t find any claim that Morse’s second demonstration was noticeably more impressive, but in 1843, Congress finally passed an appropriate for Morse and his colleagues.</p><p>Morse reported in 1844 that the line from the District to Baltimore was complete. Side note: “What hath God wrought” was not, in fact, Morse’s first transmission. The first public transmission, according to wikipedia, was “A patient waiter is no loser”. The famous “What hath God wrought” was the opening line for the D.C.-Baltimore line.</p><p>The Congressional Journal over the next decade is filled with references to petitions and bills for funding expansion of the telegraph system across the country. Congress wasn’t just pleased with the telegraph, though. Morse’s demonstration — and the fact that he delivered on his promises — had made him personally popular. In 1845, the House Committee on Public Buildings and Grounds was instructed to ask Morse</p><blockquote><p>if, in his opinion, he can invent or adopt a more expeditious plan of taking the yeas and nays in this hall…</p></blockquote><p>He seems to have declined, as the House didn’t vote electronically <a href="https://history.house.gov/Exhibitions-and-Publications/Electronic-Technology/House-Technology/">until 1973</a>.</p><p>In 1845, Congress approved an expansion of the telegraph system to New York, and began referring to “Professor Morse” instead of “Samuel F. B. Morse”. In the subsequent years, telegraph lines were often built alongside railroads, funded by Congress in the same bill. By 1870 the magnetic telegraph reached California.</p><p>An astonishing journey, beginning with the audacity of an ordinary man to write to Congress for money.</p><h2 id="ii">II.</h2><p>Or not. To start with, Morse was no ordinary man. He was a consumate self-promoter, intensely concerned with his own reputation, and quite politically active.</p><p>Wikipedia discusses his political activites <a href="https://en.wikipedia.org/wiki/Samuel_Morse">at some length</a>. He published a political tract (explaining how the Catholics were conspiring to take over the country) in 1835. He ran for mayor of New York (to fight the “deep Catholic state”, I assume) in 1836. Note the timeline: neither a prelude nor an afterthought, these activites were essentially contemporary with his creation of the telegraph.</p><p>After the telegraph was well established, in the 1850s, Morse turned his attention to the question of slavery, comparing it favorably to employment, parenting, and government.</p><p>In 1871, H.R. 285 was passed, allowing a statue of Morse to be erected on government land. Morse died in 1872, and a memorial service was held in Congress. I’m assuming this service primarily focused on the telegraph, rather than his paintings (<a href="https://en.wikipedia.org/wiki/Samuel_Morse#/media/File:Samuel_Finley_Breeze_Morse_001.jpg">not bad</a>, actually) or his support for slavey (none too popular with Congress during reconstruction, I guess).</p><h2 id="iii">III.</h2><p>Henry Hall Sherwood was a physician in New York. In the 1830s, the electromagnetic nature of the nervous system was still a relatively new discovery, and Sherwood seems to have gotten a bit over-excited. His <a href="https://collections.nlm.nih.gov/?f%5Bdrep2.authorAggregate%5D%5B%5D=Sherwood%2C+H.+H.+%28Henry+Hall%29">books</a> include case studies; for the most part, he seems to have waved magnets near his patients. He claims this cured them of various ailments. I’d laugh, but there’s an accupuncture clinic a couple blocks from my office. I’m afraid to find out whether this was classified an “essential service” during the lockdown.</p><p>Electromagnetism (or as it was often known then, “magnetism” — even when referring to phenomena we would call electric) was all the rage. A major challenge of the age was to understand the structure of the magnetic field of the Earth, although that’s slightly modern terminology — it was often referred to as “the variation of the compass”. This would be helpful, among other things, for navigation at sea: you can easily imagine that a precise model might allow the measurement of longitude. Sherwood, being an expert on the magnetic nature of the nervous system, decided to lend a hand to this closely related problem. Overall, this went about as well as you’d expect.</p><p>Like his better-known contemporary, Sherwood was bold enough to make requests directly of Congress. He petitioned the House, claiming to have invented an instrument (the <em>geometer</em>) for navigation purely from magnetic observations, and</p><blockquote><p>praying the aid of the Government of the United States in the publication of a work to explain the discoveries…</p></blockquote><p>among other things. It was proposed that he give the House a demonstration of his techniques, in June of 1838. This was voted down, and the matter dropped entirely.</p><p>That same month, Sherwood also petitioned the Senate; his petition was presented by <a href="https://en.wikipedia.org/wiki/Nathaniel_P._Tallmadge">Nathaniel Tallmadge</a> of New York. Like the House, on June 21st, the Senate considered and declined the possiblity of a demonstration. Sherwood’s petition was referred to the Committee on Naval Affairs, which submitted a report, presented again by Tallmadge, to the Senate on July 3rd.</p><p>Here it gets interesting. That report caused something of a stir in the scientific community. No less than <a href="https://en.wikipedia.org/wiki/Joseph_Henry">Joseph Henry</a>, soon to become the first Secretary of the Smithsonian Institution, published a denunciation of the report. You can read his article <a href="https://siarchives.si.edu/sites/default/files/pdfs/JHPVol/JHPP_V4_P75-79_Transcript.pdf">here</a>, which was written in protest</p><blockquote><p>against the plan of discussing such subjects in Congress before proper means have been taken to determine their true character.</p></blockquote><p>In other words, against Congressional meddling and speculation. Most of Henry’s complaint is taken up by a somewhat detailed critique (occasionally, mockery) of Sherwood’s theories. The above quote somewhat masks Henry’s true opinion. A few paragraphs later he writes:</p><blockquote><p>we do not believe that there is a person of any scientific reputation in our country, who has paid attention to this subject, who will not immediately say that the whole affair is perfectly peurile…</p></blockquote><p>Despite his earlier words, I don’t get the impression the Henry would object to Congressional support for a speculative endeavor: just not an entirely futile endeavor. After Henry’s rebuttal was published, the Senate seems to have forgotten about Sherwood’s petition for a while.</p><p>Sherwood again requested financial aid from Congress in mid-February, 1839. Another report was delivered by Tallmadge from his committee, but I can find no details on what it said. It must not have been positive: the last reference to H. H. Sherwood in the papers of Congress is on March 2, 1839, when the Committee on Naval Affairs was given permission, by the Senate, to drop the matter.</p><h2 id="iv">IV.</h2><p>It is sometimes argued that Congress’s support of Morse’s telegraph was not the really the first case in which the new government funded science: for a sufficiently broad definition of “science”, that honor belongs to the Lewis and Clark expedition nearly 40 years prior. But just as Morse’s was not the first time the government <em>considered</em> funding science, the 1803 expedition was not the first time the U.S. government <em>considered</em> funding an expedition.</p><p>John Churchman was <a href="https://bostonraremaps.com/inventory/john-churchman-magnetic-atlas/">a surveyor and mapmaker</a>, who in the 1780s became preoccupied with the task of measuring the longitude of a ship at sea via magnetic observations (much like Sherwood!). Churchman, however, was not a complete crank. Like Morse, he was no stranger to make requests of governments, having (for instance) <a href="https://founders.archives.gov/documents/Jefferson/01-11-02-0378">written</a> to Thomas Jefferson in 1787 to request that a paper of his be presented to the Royal Academy of Sciences at Paris. (That puts things in perspective. There’s no excuse for not sending cold emails!)</p><p>In 1791, Churchman made a request of Congress: “praying the patronage of Government to enable him to undertake a voyage” to investigate the magnetic fields near the geomagnetic north pole. Of course, his <em>motivation</em> for this voyage was to confirm a theory of the behavior of magnetic field lines which is now known to be incorrect. In brief, the behavior of magnetic field lines is not as predictable as he assumed, and therefore not as useful for navigation beyond distinguishing north from south.</p><p>Nevertheless, exploratory voyages based on incorrect assumptions were commonplace and often productive, and Congress considered the matter serious — more seriously, in fact, than the Sherwood business. The House held <a href="http://memory.loc.gov/cgi-bin/ampage?collId=llac&amp;fileName=003/llac003.db&amp;recNum=153">a lengthy discussion</a> on 6 Jan 1792 to consider the petition.</p><p>The representatives (at least those who participate in the debate) come across as reasonably knowledgable about the subject. Halley’s (yes, that Halley) …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ineffectivetheory.com/magnetism-congress/">https://ineffectivetheory.com/magnetism-congress/</a></em></p>]]>
            </description>
            <link>https://ineffectivetheory.com/magnetism-congress/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25091138</guid>
            <pubDate>Sat, 14 Nov 2020 09:15:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I write Elm applications]]>
            </title>
            <description>
<![CDATA[
Score 109 | Comments 89 (<a href="https://news.ycombinator.com/item?id=25091132">thread link</a>) | @galfarragem
<br/>
November 14, 2020 | https://jezenthomas.com/how-i-write-elm-applications/ | <a href="https://web.archive.org/web/*/https://jezenthomas.com/how-i-write-elm-applications/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <article>
    
    <p>
      <span>November  7, 2020</span>
      
      | Gdańsk, Poland
      
    </p>
    <p>Most of my work over the past 10 years has involved writing what is often called a <em>wizard</em>.</p>
<p>A wizard is essentially a multi-step process that guides a user through a particular workflow. For example, if you are installing a new application on your computer, the wizard might guide you through the following process:</p>
<ol type="1">
<li>Enter your license registration details</li>
<li>Agree to the software author’s legal terms</li>
<li>Specify an installation location</li>
</ol>
<p>Most web applications provide something similar. If a user needs to input a large amount of data for the application to then run a bunch of calculations, you could of course just provide the user with one big web form. At a certain size though, a single web form can be intimidating and provide a less than ideal user experience. The canonical way to improve the user experience here is to break up the web form into several separate pages. This is another example of a wizard.</p>
<figure>
<img src="https://jezenthomas.com/static/img/wizard-diagram.jpg" alt="Forms are easier to digest when they’re split into separate steps"><figcaption>Forms are easier to digest when they’re split into separate steps</figcaption>
</figure>
<p>I’ve tried writing wizards in a number of different web technologies, and so far Elm has proven itself as by far the most robust and painless, <em>especially</em> when it inevitably comes to changing some conditional logic to meet the mutable needs of various business processes.</p>
<p>For any small Elm application, project structure is easy. There is no reason why a 1,000 line Elm application can’t live in a single file. In fact this is really how every Elm application ought to begin its life. Start with a single file with the usual boilerplate and the following contents:</p>
<ul>
<li>A single sum type to model all of the messages your application supports</li>
<li>A single model which contains all the application state</li>
<li>A single update function for advancing the application state</li>
<li>A single view function for rendering the application state on the page</li>
</ul>
<p>If your web form is complex enough to warrant being broken into separate pages however, then your application is naturally not going to consist of a small number of lines of code. A common concern among less experienced Elm programmers is that one big sum type for all of your messages becomes unwieldy to maintain. The same is said of having one big shallow record for all of the application state, or one big <code>update</code> function to match all the constructors of the one big <code>Msg</code> type. This is where unnecessary complexity starts to balloon as programmers add <em>clever</em> abstractions and misdirections, usually involving both <code>Html.map</code> and <code>Cmd.map</code>, separate <code>update</code> functions for each logical subsection of your application (usually with noticeably awkward type signatures), and some vague hand-waving in the direction of <em>encapsulation</em> and so-called <em>Clean Code</em>.</p>
<p>I’d argue that this kind of misdirection is almost <em>never</em> what you want. I’d argue further that this applies <em>especially</em> to you if your background is in maintaining complex React/Angular applications, where invented complexity is the status quo and this kind of misdirection is simply what you have become desensitised to.</p>
<p>So if the combination of <code>Html.map</code> and <code>Cmd.map</code> are to be avoided, how can we scale an Elm application without sacrificing developer ergonomics? In short, the tricks to employ are:</p>
<ul>
<li>Nested sum types</li>
<li>Nested record types</li>
<li>Nested update functions</li>
<li>Small, composable view functions</li>
<li>Function composition</li>
<li>Lenses</li>
</ul>
<p>Let’s take a look at a more concrete application of these ideas. As an example, we can model the process of a person applying for a bank loan.</p>
<p>The bank will want to ask the applicant a whole bunch of questions, which we could group into three categories:</p>
<ol type="1">
<li>Personal information</li>
<li>Details on the purpose of the loan</li>
<li>Financial information and creditworthiness</li>
</ol>
<p>This would suggest a three-step wizard or a three-page web form. A reasonable place to begin splitting our application apart into three smaller pieces is in our <code>Msg</code> type.</p>
<h2 id="the-big-msg-type">The Big Msg Type</h2>
<p>The naïve way to model the messages our application should support is with one big sum type, which might look something like this:</p>
<pre><code>type Page
  = PersonalInformationPage
  | LoanPurposePage
  | FinancialDetailsPage

type Msg
  -- System-wide messages
  = NoOp
  | SetPage Page
  -- etc…

  -- Personal information
  | SetFirstName String
  | SetLastName String
  | SetAddressLine1 String
  -- …more messages for the personal information page

  -- Purpose of the loan
  | SetPurchaseItemCategory
  | SetPurchaseItemEstimatedValue
  -- …more messages for the loan purpose page

  -- Financial information
  | SetMonthlyIncomeBeforeTax
  | SetMonthlyRentPayment
  -- …more messages about the applicant's financial details</code></pre>
<p>This <em>does</em> work, but at some point it becomes cumbersome to support a large number of constructors. The value for “large” is of course determined by the individual programmer’s personal taste and/or pain threshold. To ease this pain, people typically <em>extract</em> groups of messages into their own separate sum types, which subsequently forces them to write update functions that return a type <em>other</em> than the top-level <code>Msg</code> type.</p>
<p><em>Don’t do that!</em></p>
<p>The way to break these groups of constructors out is by first nesting them inside the <code>Msg</code> type, like this:</p>
<pre><code>type PersonalInformationMsg
  = SetFirstName String
  | SetLastName String
  | SetAddressLine1 String
  -- etc..

type LoanPurposeMsg -- etc…

type FinancialDetailsMsg -- etc…

type Msg
  = NoOp
  | SetPage Page
  | PersonalInformationMsg PersonalInformationMsg
  | LoanPurposeMsg LoanPurposeMsg
  | FinancialDetailsMsg FinancialDetailsMsg</code></pre>
<p>The new message types can live in the same file as the top-level <code>Msg</code> type. They can also be extracted to different files. That’s your choice.</p>
<p>The next thing to tackle is our <code>update</code> function, since it needs to mirror our <code>Msg</code> type.</p>
<h2 id="nested-update-functions">Nested Update Functions</h2>
<p>I’ve seen people advocate for page-specific <code>update</code> functions which take a page-specific model and return a tuple of that page-specific model and a page-specific <code>Cmd Msg</code> equivalent. This is typically where you see <code>Cmd.map</code> sneaking in. These functions almost inevitably end up needing <em>something</em> from the top-level application-wide state, so you’ll often see some type signature like this:</p>
<pre><code>updatePersonalInformation
   : PersonalInformationMsg
  -&gt; Model
  -&gt; (PersonalInformationModel, Cmd PersonalInformationMsg)
  -&gt; (Model, Cmd Msg)</code></pre>
<p>This is <em>way</em> too complex already, and this approach doesn’t even actually buy you anything.</p>
<p>The far simpler way to do this is to have every nested <code>update</code> function take a page-specific message, the <em>entire</em> application state, and return the same type for that state along with the top-level <code>Msg</code> type, like this:</p>
<pre><code>updatePersonalInformation : PersonalInformationMsg -&gt; Model -&gt; (Model, Cmd Msg)
updatePersonalInformation msg model = case msg of
  SetFirstName a    -&gt; -- …
  SetLastName a     -&gt; -- …
  SetAddressLine1 a -&gt; -- …
  -- etc…

update : Msg -&gt; Model -&gt; (Model, Cmd Msg)
update msg model = case msg of
  NoOp -&gt; (model, Cmd.none)
  SetPage page -&gt; ({ model | page = page }, Cmd.none)
  PersonalInformationMsg subMsg -&gt; updatePersonalInformation subMsg model
  LoanPurposeMsg subMsg -&gt; updateLoanPurpose subMsg model
  FinancialDetailsMsg subMsg -&gt; updateFinancialDetails subMsg model</code></pre>
<p>No complicated type signatures. No juggling of message types. No <code>Cmd.map</code>. Easy.</p>
<p>Of course the whole point of our <code>update</code> function is to advance the state of our model, and the structure of that model is also something that can swell and become unwieldy, so that’s what we will dissect next.</p>
<h2 id="record-surgery">Record Surgery</h2>
<p>Near the inception of the project, all of our individual bits of state might exist at the top level of our <code>Model</code>, which is typically represented as a record. Perhaps something like this:</p>
<pre><code>type alias Model =
  { page : Page
  , firstName : String
  , lastName : String
  , addressLine1 : String
  -- …more personal information fields

  , purchaseItemCategory : ItemCategory
  , purchaseItemEstimatedValue : Money
  -- …more loan purpose fields…

  -- …and also financial details, and system-wide state, etc…
  }</code></pre>
<p>Like the parts of our project we’ve addressed previously, this also can turn into a bit of a mess as it grows. Both application-wide data and page-specific data are mixed in together which feels a bit haphazard. Fortunately, grouping and extracting these fields is typically rather intuitive. We can start by grouping page-specific parts of the state together, and then group further until it no longer <em>feels</em> messy.</p>
<pre><code>type alias Address =
  { line1 : String
  , line2 : String
  , city : String
  , postcode : String
  -- …
  }

type alias PersonalInformation =
  { firstName : String
  , lastName : String
  , address : Address
  -- …
  }

type alias LoanPurpose =
  { purchaseItemCategory : ItemCategory
  , purchaseItemEstimatedValue : Money
  -- …
  }

type alias FinancialDetails = -- …

type alias Model =
  { page : Page
  , personalInformation : PersonalInformation
  , loanPurpose : LoanPurpose
  , financialDetails : FinancialDetails
  }</code></pre>
<p>The problem now however is that when we wish to update a deeply-nested field, we need to write all of the code to unwrap each level until we arrive at the depth we need. Illustrated another way, let’s say we want to update the first line of the applicant’s address.</p>
<p>Retrieving the value of this field is no problem, as we can use Elm’s dot syntax to succinctly get us all the way there, like this:</p>
<pre><code>model.personalInformation.address.line1</code></pre>
<p>What we <em>can’t</em> do here however is <em>update</em> that field in a similar fashion, <em>i.e.</em>, Elm won’t allow us to write something like this:</p>
<pre><code>-- This won't work
{ model.personalInformation.address | line1 = newLine1 }

-- This also won't work
{ model | personalInformation.address.line1 = newLine1 }</code></pre>
<p>The naïve way to unwrap and subsequently update the field in this record is to write something like this:</p>
<pre><code>updatePersonalInformation : PersonalInformationMsg -&gt; Model -&gt; (Model, Cmd Msg)
updatePersonalInformation msg model = case msg of
  SetFirstName _ -&gt; -- …

  SetLastName _ -&gt; -- …

  SetAddressLine1 newLine1 -&gt;
    let
        …</code></pre></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jezenthomas.com/how-i-write-elm-applications/">https://jezenthomas.com/how-i-write-elm-applications/</a></em></p>]]>
            </description>
            <link>https://jezenthomas.com/how-i-write-elm-applications/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25091132</guid>
            <pubDate>Sat, 14 Nov 2020 09:11:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Going Bark: A Furry's Guide to End-to-End Encryption]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25090942">thread link</a>) | @some_furry
<br/>
November 14, 2020 | https://soatok.blog/2020/11/14/going-bark-a-furrys-guide-to-end-to-end-encryption/ | <a href="https://web.archive.org/web/*/https://soatok.blog/2020/11/14/going-bark-a-furrys-guide-to-end-to-end-encryption/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<p>Governments are back on their anti-encryption bullshit again.</p>



<p>Between the <a href="https://blog.cryptographyengineering.com/2020/03/06/earn-it-is-an-attack-on-encryption/">U.S. Senate’s “EARN IT” Act</a>, the <a href="https://www.eff.org/deeplinks/2020/10/orders-top-eus-timetable-dismantling-end-end-encryption">E.U.’s slew of anti-encryption proposals</a>, and <a href="https://fee.org/articles/australia-s-unprecedented-encryption-law-is-a-threat-to-global-privacy/">Australia’s new anti-encryption law</a>, it’s become clear that the authoritarians in office view online privacy as a threat to their existence.</p>



<p>Normally, when the governments increase their anti-privacy sabre-rattling, technologists start talking more loudly about Tor, Signal, and other privacy technologies (usually only to be drowned out by paranoid people who think Tor and Signal are government backdoors or something stupid; conspiracy theories ruin everything!).</p>



<p><strong>I’m not going to do that.</strong></p>



<p>Instead, I’m going to show you how to add end-to-end encryption to any communication software you’re developing. (Hopefully, I’ll avoid making <a href="https://soatok.blog/2020/10/28/bizarre-design-choices-in-zooms-end-to-end-encryption/">any bizarre design decisions</a> along the way.)</p>



<p>But first, some important disclaimers:</p>



<ol><li><strong>Yes, you should absolutely do this.</strong> I don’t care how banal your thing is; if you expect people to use it to communicate with each other, you should make it so that you can never decrypt their communications.</li><li>You should absolutely NOT bill the thing you’re developing as an <em>alternative</em> to Signal or WhatsApp.</li><li>The goal of doing this is to increase the amount of end-to-end encryption deployed on the Internet that the service operator cannot decrypt (even if compelled by court order) and make E2EE normalized. The goal is NOT to compete with highly specialized and peer-reviewed privacy technology.</li><li>I am not a lawyer, I’m some furry who works in cryptography. The contents of this blog post is not legal advice, nor is it endorsed by any company or organization. Ask the <a href="https://eff.org/">EFF</a> for legal questions.</li></ol>



<p>The organization of this blog post is as follows: First, I’ll explain <a href="#symmetric-key-encryption">how to encrypt and decrypt data between users</a>, assuming you have a key. Next, I’ll explain <a href="#key-agreement">how to build an authenticated key exchange</a> and <a href="#session-key-management">a ratcheting protocol to determine the keys used in the first step</a>. Afterwards, I’ll explore <a href="#identity-key-management">techniques for binding authentication keys to identities and managing trust</a>. Finally, I’ll discuss <a href="#backdoor-resistance">strategies for making it impractical to ever backdoor your software (and impossible to silently backdoor it)</a>, just to piss <a href="https://en.wikipedia.org/wiki/Five_Eyes">the creeps and tyrants of the world</a> off even more.</p>



<p>You don’t have to implement the full stack of solutions to protect users, but the further you can afford to go, the safer your users will be from privacy-invasive policing.</p>







<h2 id="preliminaries">Preliminaries</h2>



<h3 id="choosing-a-cryptography-library">Choosing a Cryptography Library</h3>



<p>In the examples contained on this page, I will be using the <a href="https://libsodium.gitbook.io/doc/">Sodium cryptography library</a>. Specifically, my example code will be written with the <a href="https://github.com/paragonie/sodium-plus">Sodium-Plus</a> library for JavaScript, since it strikes a good balance between performance and being cross-platform.</p>


<pre title="">const { SodiumPlus } = require('sodium-plus');

(async function() {
     // Select a backend automatically
     const sodium = await SodiumPlus.auto();
     
     // Do other stuff here
})();
</pre>


<p>Libsodium is <a href="https://latacora.micro.blog/2018/04/03/cryptographic-right-answers.html">generally the correct choice for developing cryptography features in software</a>, and is available in most programming languages,</p>



<p>If you’re prone to choose a different library, you should consult your cryptographer (and yes, you should have one on your payroll if you’re doing things different) about your design choices.</p>



<h3>Threat Modelling</h3>



<p>Remember above when I said, “You don’t have to implement the full stack of solutions to protect users, but the further you can afford to go, the safer your users will be from privacy-invasive policing”?</p>



<p>How far you go in implementing the steps outlined on this blog post should be informed by <a href="https://adamcaudill.com/2016/07/20/threat-modeling-for-applications/">a threat model</a>, not an ad hoc judgment.</p>



<p>For example, if you’re encrypting user data and storing it in the cloud, you probably want to pass <a href="https://blog.cryptographyengineering.com/2012/04/05/icloud-who-holds-key/">the Mud Puddle Test</a>:</p>



<blockquote><div><p>1. First, drop your device(s) in a mud puddle.<br>2. Next, slip in said puddle and crack yourself on the head. When you regain consciousness you’ll be perfectly fine, but<em>&nbsp;won’t for the life of you&nbsp;</em>be able to&nbsp;recall your device passwords or keys.<br>3. Now try to get your cloud data back.</p><p>Did you succeed? If so, you’re screwed. Or to be a bit less dramatic, I should say: your cloud provider has access to your ‘encrypted’ data, as does the government if they want it, as does any rogue employee who knows their way around your provider’s internal policy checks.</p></div><cite>Matthew Green describes the Mud Puddle Test, which Apple products <a href="https://sneak.berlin/20201112/your-computer-isnt-yours/">definitely don’t pass</a>.</cite></blockquote>



<p>If you must fail the Mud Puddle Test for your users, make sure you’re clear and transparent about this in the documentation for your product or service.</p>







<h2 id="symmetric-key-encryption">I. Symmetric-Key Encryption</h2>



<p>The easiest piece of this puzzle is to encrypt data in transit between both ends (thus, satisfying the loosest definition of end-to-end encryption).</p>



<p>At this layer, you already have some kind of symmetric key to use for encrypting data before you send it, and for decrypting it as you receive it.</p>



<p>For example, the following code will encrypt/decrypt strings and return hexadecimal strings with a version prefix.</p>


<pre title="">const VERSION = "v1";

/**
 * @param {string|Uint8Array} message
 * @param {Uint8Array} key
 * @param {string|null} assocData
 * @returns {string}
 */
async function encryptData(message, key, assocData = null) {
    const nonce = await sodium.randombytes_buf(24);
    const aad = JSON.stringify({
      'version': VERSION,
      'nonce': await sodium.sodium_bin2hex(nonce),
      'extra': assocData
    });

    const encrypted = await sodium.crypto_aead_xchacha20poly1305_ietf_encrypt(
        message,
        nonce,
        key,
        aad
    );
    return (
       VERSION +
       await sodium.sodium_bin2hex(nonce) +
       await sodium.sodium_bin2hex(encrypted)
    );
}

/**
 * @param {string|Uint8Array} message
 * @param {Uint8Array} key
 * @param {string|null} assocData
 * @returns {string}
 */
async function decryptData(encrypted, key, assocData = null) {
    const ver = encrypted.slice(0, 2);
    if (!await sodium.sodium_memcmp(ver, VERSION)) {
        throw new Error("Incorrect version: " + ver);
    }
    const nonce = await sodium.sodium_hex2bin(encrypted.slice(2, 50));
    const ciphertext = await sodium.sodium_hex2bin(encrypted.slice(50));
    const aad = JSON.stringify({
      'version': ver,
      'nonce': encrypted.slice(2, 50),
      'extra': assocData
    });
    
    const plaintext = await sodium.crypto_aead_xchacha20poly1305_ietf_decrypt(
        ciphertext,
        nonce,
        key,
        aad
    );
    return plaintext.toString('utf-8');
}
</pre>


<p>Under-the-hood, this is using <a href="https://soatok.blog/2020/07/12/comparison-of-symmetric-encryption-methods/#aes-gcm-vs-xchacha20poly1305">XChaCha20-Poly1305</a>, which is less sensitive to timing leaks than AES-GCM. However, like AES-GCM, this encryption mode doesn’t provide <a href="https://eprint.iacr.org/2019/016">message- or key-commitment</a>.</p>



<p>If you want key commitment, you should derive two keys from <code>$key</code> using a KDF based on hash functions: One for actual encryption, and the other <a href="https://eprint.iacr.org/2020/1153">as a key commitment value</a>.</p>



<p>If you want message commitment, you can use AES-CTR + HMAC-SHA256 or XChaCha20 + BLAKE2b-MAC.</p>



<p>If you want both, ask <a href="https://mumble.net/~campbell/">Taylor Campbell</a> about his BLAKE3-based design.</p>



<p>A modified version of the above code with key-commitment might look like this:</p>


<pre title="">const VERSION = "v2";

/**
 * Derive an encryption key and a commitment hash.
 * @param {CryptographyKey} key
 * @param {Uint8Array} nonce
 * @returns {{encKey: CryptographyKey, commitment: Uint8Array}}
 */
async function deriveKeys(key, nonce) {
    const encKey = new CryptographyKey(await sodium.crypto_generichash(
        new Uint8Array([0x01].append(nonce)),
        key
    ));
    const commitment = await sodium.crypto_generichash(
        new Uint8Array([0x02].append(nonce)),
        key
    );
    return {encKey, commitment};
}

/**
 * @param {string|Uint8Array} message
 * @param {Uint8Array} key
 * @param {string|null} assocData
 * @returns {string}
 */
async function encryptData(message, key, assocData = null) {
    const nonce = await sodium.randombytes_buf(24);
    const aad = JSON.stringify({
      'version': VERSION,
      'nonce': await sodium.sodium_bin2hex(nonce),
      'extra': assocData
    });
    const {encKey, commitment} = await deriveKeys(key, nonce);

    const encrypted = await sodium.crypto_aead_xchacha20poly1305_ietf_encrypt(
        message,
        nonce,
        encKey,
        aad
    );
    return (
       VERSION +
       await sodium.sodium_bin2hex(nonce) +
       await sodium.sodium_bin2hex(commitment) +
       await sodium.sodium_bin2hex(encrypted)
    );
}

/**
 * @param {string|Uint8Array} message
 * @param {Uint8Array} key
 * @param {string|null} assocData
 * @returns {string}
 */
async function decryptData(encrypted, key, assocData = null) {
    const ver = encrypted.slice(0, 2);
    if (!await sodium.sodium_memcmp(ver, VERSION)) {
        throw new Error("Incorrect version: " + ver);
    }
    const nonce = await sodium.sodium_hex2bin(encrypted.slice(2, 50));
    const ciphertext = await sodium.sodium_hex2bin(encrypted.slice(114));
    const aad = JSON.stringify({
      'version': ver,
      'nonce': encrypted.slice(2, 50),
      'extra': assocData
    });
    const storedCommitment = await sodium.sodium_hex2bin(encrypted.slice(50, 114));
    const {encKey, commitment} = await deriveKeys(key, nonce);
    if (!(await sodium.sodium_memcmp(storedCommitment, commitment))) {
        throw new Error("Incorrect commitment value");
    }
    
    const plaintext = await sodium.crypto_aead_xchacha20poly1305_ietf_decrypt(
        ciphertext,
        nonce,
        encKey,
        aad
    );
    return plaintext.toString('utf-8');
}
</pre>


<p>Another design choice you might make is to encode ciphertext with base64 instead of hexadecimal. That doesn’t significantly alter the design here, but it does mean your decoding logic has to accommodate this.</p>



<p>You SHOULD version your ciphertexts, and include this in the AAD provided to your AEAD encryption mode. I used “v1” and “v2” as a version string above, but you can use your software name for that too.</p>



<h2 id="key-agreement">II. Key Agreement</h2>



<p>If …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://soatok.blog/2020/11/14/going-bark-a-furrys-guide-to-end-to-end-encryption/">https://soatok.blog/2020/11/14/going-bark-a-furrys-guide-to-end-to-end-encryption/</a></em></p>]]>
            </description>
            <link>https://soatok.blog/2020/11/14/going-bark-a-furrys-guide-to-end-to-end-encryption/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25090942</guid>
            <pubDate>Sat, 14 Nov 2020 08:04:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Virgin Hyperloop Has Invented the World's Crappiest High-Speed Rail]]>
            </title>
            <description>
<![CDATA[
Score 82 | Comments 116 (<a href="https://news.ycombinator.com/item?id=25090938">thread link</a>) | @Osiris30
<br/>
November 14, 2020 | https://defector.com/virgin-hyperloop-has-invented-the-worlds-crappiest-high-speed-rail/ | <a href="https://web.archive.org/web/*/https://defector.com/virgin-hyperloop-has-invented-the-worlds-crappiest-high-speed-rail/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div id="pico">
<p>Shocking news! In an incredible breakthrough for American mass-transit engineering, the transportation technology company Virgin Hyperloop this past weekend successfully moved two people 500 meters across the barren Las Vegas desert at a top speed of just over 100 mph, setting a new world record for the absolute most pitiful thing anyone not named “Elon Musk” has ever tried to pass off as “high-speed rail.”</p>



<p>Here’s video of the shameful display:</p>



<figure><p>
<iframe title="Watch people travel in Virgin Hyperloop for the first time" width="500" height="281" src="https://www.youtube.com/embed/AZruVz3Ccjk?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>



<p>Virgin Hyperloop, an American company despite the Richard Branson branding, proposes to use a combination of magnetic levitation, or “maglev”—a decades-old technology that has been in commercial operation moving real trains filled with real people in, for example, Shanghai, China, at speeds up to 268 miles per hour, for <em>17 goddamn years</em>—and “vactrain,” a concept design for an enclosed, artificially evacuated tunnel where air resistance may be as low as in the upper parts of Earth’s atmosphere, theoretically allowing for much higher top speeds at much lower levels of energy consumption. It is so goddamn embarrassing to type this. France’s electric TGV system has been in regular commercial operation for nearly 40 years; in April of 2007 one of its trains hit 357 miles per hour in a test.</p>



<p><a href="https://www.cnn.com/2020/11/08/tech/virgin-hyperloop-passengers/index.html">CNN’s article about this event</a> paraphrases a Virgin Hyperloop executive claiming that the hyperloop pods “can travel at the speed of aircraft.” Which is true, in the sense that commercial aircraft with dozens if not hundreds of people aboard do sometimes travel at 100 miles per hour, on the ground, for seconds at a time, during takeoff or landing, when they are going only a fraction as fast as they’re capable of going. It is also true in the sense that, strictly speaking, a paper airplane is a form of “aircraft,” and you can really whip some of those suckers across a room. A more accurate but perhaps less flattering claim would be that my Honda Odyssey can travel at the fastest speed Virgin Hyperloop has yet attained, and with <em>four times as many people riding in it</em>.</p>



<p>Hell, for that matter, as <a href="https://twitter.com/leftistthot420/status/1326561247333134336">a Twitter user</a> helpfully pointed out, <a href="https://en.wikipedia.org/wiki/LNER_Class_A4_4468_Mallard">a freaking <em>steam locomotive</em> hit 126 miles per hour</a> in England, 82 years ago, in 1938.</p>



<p><em>Yeah, but, when it’s done, it’ll go 600 miles per hour</em>, you’re whining, <em>and it’ll have 25 to 30 people in a pod!</em> When exactly will that be? France opened the TGV in 1981. Japan’s oldest high-speed line debuted in 1964—<em>1964!</em>—and was better and faster then than Amtrak’s Acela trains go now. Shanghai’s maglev train has been operable since John Kerry was campaigning to unseat George W. Bush as president. Measure speed by the number of riders the respective services will have moved by, say, 2050. Measure it in carbon emissions. By the year 2020, the best-funded and most sophisticated high-speed rail developer in the United States moved two (2) people 500 meters.</p>



<p>The United States is generations behind much of the rest of the wealthy, industrialized world in this area. For all but a very narrow corridor along the East Coast serviced by the weak half-a-loaf shit that passes for high-speed rail in this country, the best an American commuter can hope for in intercity rail options are crappy and ancient diesel Amtrak trains that top out at around 80 miles per hour. Most American cities simply are not serviced by any intercity rail network at all. The U.S.’s shameful mass-transit situation—and thus its shameful dependence on personal vehicles, and all the downstream bad shit that comes from that—could be improved a zillion percent by just aiming for the level of railroad sophistication French people considered normal before the median 2020 French person was old enough to ride a bicycle. And here are these Professor Frink–ass Hyperloop dinguses, dumping resources beyond counting into inventing some shit that already exists when for a fraction of the cost and in a fraction of the time they could just <em>purchase</em> or at the very least <em>copy</em> what is already working just fine even in backward-ass doofus countries like freaking Italy. It wouldn’t need test tracks! It wouldn’t need years of iteration and development! They already did all that shit, all over the rest of the world! </p>



<p>In a vacuum (a figurative one: an alternate universe in which the rest of the post-industrial world were not absolutely goddamn <em>bursting</em> with operating networks of authentic high-speed rail; where high-speed rail were not already such a well-developed form of transit that the TGV system, which routinely moves huge numbers of day-to-day commuters across large distances of France at speeds well more than twice that achieved by this sad two-person billion-dollar pod going from nowhere to nowhere across a tiny patch of worthless desert, were not both infinitely better and more sophisticated than any presently available commercial rail in the United States <em>and</em> fairly outmoded in comparison to newer [yet still not all that new!] systems in China and Japan and elsewhere) the Virgin Hyperloop could almost look like an impressive accomplishment. Alas, here in the world of context, its only real accomplishment is a promotional one. The business of the American technology sector and its attendant courtier press is to continually recreate and exploit something like a vacuum in the public’s awareness of what the larger world is like, so that clueless observers will congratulate a bunch of boobs for “inventing” a shittier, more expensive version of something that is already regarded as boring and normal—fast, energy-efficient rail service!—pretty much everywhere outside of this stupid and embarrassing country.</p>



<p>Everything about the broken incentives and hollowed-out capacities of American society is crystallized in this dumb pod moseying its way along a track to nowhere in Las Vegas. The United States has a problem: It is too dependent on inefficient, dirty, and expensive forms of transportation, because the vast majority of its people have no practical access to other kinds. Its infrastructure and the health of its communities are all jacked up by the necessity of splattering asphalt all over everything in order for people to drive their big dumb cars to, and park them near, anywhere they’d decide to go. It cannot achieve efficient levels of density or make meaningful turns toward environmental responsibility for as long as this is the case. Thankfully, a solution to this problem already exists and is in operation throughout other parts of the world with comparable levels of wealth and technological capacity: Trains! Networks of fast-moving trains that do not need internal combustion engines in order to move lots of people very quickly along their tracks! Companies and agencies make and install and operate these train systems, and have been doing so for a long time, longer even than the lifetime of the graybeard crap-bag writing this blog. They know how to do it! They can probably just be hired to do it. At some level somebody can probably just buy some of those trains, and install them, and turn them on, and take people from here to there on them.</p>



<p>But who could make it happen? Broke-dick, systematically impoverished municipalities, lashed to budget-balancing like a cinderblock tied to their feet? Close your eyes and try to imagine how a sane and obviously good decision like <em>Just import the TGV and run it between the big American cities instead of spending years and fortunes inventing maglev from scratch for no reason</em> could get made in these United States. Imagine who’d make it, and what their goals would be, and where the money would come from. It simply can’t get made on those terms. It can’t get made at all. No level of American society even has a mechanism for that anymore. If it doesn’t require a messianic assbrain with a Steve Jobs cosplay fantasy pitching some sleepy billionaire or venture capital firm on the possibility of cornering the market on a brand-new technology that will conquer the world, then it will not get done. If it merely delivers a profound benefit to the common good rather than the promise of extravagant enrichment to a shrinking class of hyper-powered parasites, then it simply cannot exist.</p>




</div></div></div></div></div>]]>
            </description>
            <link>https://defector.com/virgin-hyperloop-has-invented-the-worlds-crappiest-high-speed-rail/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25090938</guid>
            <pubDate>Sat, 14 Nov 2020 08:03:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[3D printers fill the air with volatile nanoparticles. More research is needed [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25090795">thread link</a>) | @giuliomagnifico
<br/>
November 13, 2020 | https://www.bfr.bund.de/cm/349/3d-printing-a-dusty-business.pdf | <a href="https://web.archive.org/web/*/https://www.bfr.bund.de/cm/349/3d-printing-a-dusty-business.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.bfr.bund.de/cm/349/3d-printing-a-dusty-business.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25090795</guid>
            <pubDate>Sat, 14 Nov 2020 07:20:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Lagrange – A Beautiful Gemini & Gopher Client]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25090565">thread link</a>) | @davewongillies
<br/>
November 13, 2020 | https://gmi.skyjake.fi/lagrange/ | <a href="https://web.archive.org/web/*/https://gmi.skyjake.fi/lagrange/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="container">



<p>Lagrange is a desktop GUI client for browsing Geminispace. It offers modern conveniences familiar from web browsers, such as smooth scrolling, inline image viewing, multiple tabs, visual themes, Unicode fonts, bookmarks, history, and page outlines.</p>

<p>Like Gemini, Lagrange has been designed with minimalism in mind. It depends on a small number of essential libraries. It is written in C and uses SDL for hardware-accelerated graphics. OpenSSL is used for secure communications.</p>

<p><img src="https://gmi.skyjake.fi/lagrange/lagrange_about.png" title="Screenshot (showing &quot;skyjake.fi/lagrange/&quot;)"></p>
<h2>Features</h2>

<ul>
<li>Beautiful typography using Unicode fonts</li>
<li>Autogenerated page style and Unicode icon for each Gemini domain</li>
<li>Smart suggestions when typing the URL â€” search bookmarks, history, identities</li>
<li>Sidebar for page outline, managing bookmarks and identities, and viewing history</li>
<li>Multiple tabs</li>
<li>Identity management â€” create and use TLS client certificates</li>
<li>Audio playback: MP3, Ogg Vorbis, WAV</li>
<li>And more! Open `about:help` in the app, or see help.gmi</li>
</ul>



<h2>Downloads</h2>




<p>On Linux and other platforms, you'll need to compile the source tarball (CMake).</p>

<h2>What's new?</h2>

<h3>v0.9</h3>
<ul>
<li>Navigating to parent directory or site root (via top banner, menus, keybindings).</li>
<li>Option for monospace body text on all Gopher/Gemini pages.</li>
<li>Gopher: Command line Gopher URLs; updated .desktop file.</li>
<li>Remembering visited URLs during redirections. Note: "visited.txt" format changed, beware if downgrading to 0.8.</li>
<li>Various bug fixes.</li>
</ul>

<h2>Feedback</h2>

<p>If you have questions, comments or improvement ideas, you can reach me via:</p>





<h2>See also</h2>




</div></div>]]>
            </description>
            <link>https://gmi.skyjake.fi/lagrange/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25090565</guid>
            <pubDate>Sat, 14 Nov 2020 05:47:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A GAN to generate dithers minimising frame difference for a slow movie player]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25090215">thread link</a>) | @fkramink
<br/>
November 13, 2020 | http://matpalm.com/blog/dithernet_vsmp/ | <a href="https://web.archive.org/web/*/http://matpalm.com/blog/dithernet_vsmp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
  
<p>it's been about two years since i first saw the awesome
   <a href="https://medium.com/s/story/very-slow-movie-player-499f76c48b62">very slow movie player</a>
   project by bryan boyer. i thought it was such an excellent idea but never got around
   to buying the hardware to make one. more recently though i've seen a couple of references
   to the project so i decided it was finally time to make one.
</p>
<p>one interesting concern about an eink very slow movie player is the screen refresh. simpler
   eink screens refresh by doing a full cycle of a screen of white or black before displaying
   the new image. i hated the idea of an ambient slow player doing this every few minutes
   as it switched frames, so i wanted to make sure i got a piece of hardware that could do
   incremental update.
</p>
<p>after a bit of shopping around i settled on a
   <a href="https://www.waveshare.com/6inch-hd-e-paper-hat.htm">6 inch HD screen from waveshare</a>
</p>
<p>it ticks all the boxes i wanted
</p>
<ul>
 <li>
     6 inch
 </li>

 <li>
     1448×1072 high definition
 </li>

 <li>
     comes with a raspberry pi HAT
 </li>

 <li>
     and, most importantly, support partial refresh
 </li>
</ul>
<p>this screen also supports grey scale, but only with a flashy full cycle redraw,
   so i'm going to stick to just black and white since it supports the partial redraw.
</p>
<p>note: even though the partial redraw is basically instant it does suffer from a ghosting problem;
   when you draw a white pixel over a black one things are fine, but if you draw black over
   white, in the partial redraw, you get a slight ghosting of gray that is present until a
   full redraw :/
</p>


<p>so how do you display an image when you can only show black and white?
   dithering! here's an example of a 384x288 RGB image dithered using
   <a href="https://pillow.readthedocs.io/en/stable/reference/Image.html#PIL.Image.Image.convert">PILS implementation of the Floyd-Steinberg algorithm</a>
</p>
<table>
<tbody><tr><td><img src="http://matpalm.com/blog/imgs/2020/dn/eg.dither.png"></td></tr>
<tr><td>original RGB vs dithered version</td></tr>
</tbody></table>

<p>it makes intuitive sense that you could have small variations in the exact locations of the
   dots as long as you get the densities generally right. s
   so there's a reasonable question then; how do you dither in such a way that you get a
   good result, but with minimal pixel changes from a previous frame? (since we're
   motivated on these screens to change as little as possible)
</p>
<p>there are two approaches i see
</p>
<p>1) spend 30 minutes googling for a solution that no doubt someone came up with 20 years
   ago that can be implemented in 10 lines of c running at 1000fps ...
</p>
<p>2) .... or train an
   <a href="https://jax.readthedocs.io/">jax</a>
   based GAN to generate the dithers with a loss balancing a good dither vs no pixel change. :P
</p>


<p>when building a very slow movie player the most critical decision is...
   what movie to play?
   i really love the 1979 classic <a href="https://www.imdb.com/title/tt0078748/">alien</a>,
   it's such a great dark movie, so i thought i'd go with it.
   the movie is 160,000 frames so at a play back rate of a frame every 200 seconds
   it'll take just over a year to finish.
</p>
<p>note that in this type of problem there is no concern around overfitting.
   we have access to all data going in and so it's fine to overfit as much as we like;
   as long as we're minimising whatever our objective is we're good to go.
</p>


<p>i started with a
   <a href="https://arxiv.org/abs/1505.04597">unet</a>
   that maps 3 channel RGB images to a single channel dither.
</p>
<table>
<tbody><tr><td><img src="http://matpalm.com/blog/imgs/2020/dn/models.v1.png"></td></tr>
<tr><td>v1 architecture</td></tr>
</tbody></table>

<p>i tinkered a bit with the architecture but didn't spend too much time tuning it.
   for the final v3 result i ended with a pretty vanilla stack of encoders &amp; decoders
   (with skip connections connecting an encoder to the decoder at the same spatial resolution)
   each encoder/decoder block uses a residual like shortcut around a couple of convolutions.
   nearest neighbour upsampling gave a nicer result than deconvolutions in the decoder
   for the v3 result.
   also, <a href="https://arxiv.org/abs/1606.08415">gelu</a> is my new favorite activation :)
</p>
<p>for v1 i used a binary cross entropy loss of P(white) per pixel
   ( since it's what worked well for my
   <a href="http://matpalm.com/blog/counting_bees/">bee counting project</a> )
</p>
<p>as always i started by overfitting to a single example to get a baseline feel for capacity required.
</p>
<table>
<tbody><tr><td>
<img src="http://matpalm.com/blog/imgs/2020/dn/overfit.png">
</td></tr>
<tr><td>
v1 overfit result
</td></tr>
</tbody></table>

<p>when scaling up to the full dataset i switched to training on half resolution images
   against a patch size of 128. working on half resolution consistently gave a better
   result than working with the full resolution.
</p>
<p>as expected though this model gave us the classic type of problem we see with
   straight unet style image translation; we get a reasonable sense of the shapes, but no
   fine details around the dithering.
</p>
<table>
<tbody><tr><td>
<img src="http://matpalm.com/blog/imgs/2020/dn/v1.upsample.png">
</td></tr>
<tr><td>
v1 vanilla unet with upsampling example
</td></tr>
</tbody></table>

<p>side notes:
</p>
<ul>
 <li>
     for this v1 version using deconvolutions in the decoder
     (instead of nearest neighbour upsampling) actually looked pretty good!
     nicely captured texture for a dither with a surprisingly small network.
 </li>

 <li>
     i actually did some experiments using branches in the decoder for both upsampling
     and deconvolutions but the deconvs always dominated too much. i thought that would
     allow the upsampling to work as a kind of residual to the deconv but it never happened.
 </li>
</ul>
<table>
<tbody><tr><td>
<img src="http://matpalm.com/blog/imgs/2020/dn/v1.deconv.png">
</td></tr>
<tr><td>
v1 vanilla unet with deconvolution example
</td></tr>
</tbody></table>



<p>for v2 i added a GAN objective in an attempt to capture finer details
</p>
<table>
<tbody><tr><td>
<img src="http://matpalm.com/blog/imgs/2020/dn/models.v2.png">
</td></tr>
<tr><td>
v2 architecture
</td></tr>
</tbody></table>

<p>i started with the original
   <a href="https://arxiv.org/abs/1611.07004">pix2pix</a>
   objective but reasonably quickly moved to use a
   <a href="https://arxiv.org/abs/1701.07875">wasserstein</a>
   critic style objective since i've always found it more stable.
</p>
<p>the generator (G) was the same as the unet above with the discriminator (D) running patch based.
   at this point i also changed the reconstruction loss from a binary objective to just L1.
   i ended up using batchnorm in D, but not G.
   to be honest i only did a little did of manual tuning, i'm sure there's a better result
   hidden in the hyperparameters somewhere.
</p>
<p>so, for this version, the loss for G has two components
</p>
<pre>1. D(G(rgb))             # fool D
2. L1(G(rgb), dither)    # reconstruct the dither
</pre>

<p>very quickly (i.e. in &lt; 10mins ) we get a reasonable result that is started to
   show some more detail than just the blobby reconstruction.
</p>
<table>
<tbody><tr><td>
<img src="http://matpalm.com/blog/imgs/2020/dn/v2.eg.png">
</td></tr>
<tr><td>
v2 partial trained eg
</td></tr>
</tbody></table>

<p>note: if the loss weight of 2) is 0 we degenerate to v1
   (which proved a useful intermediate debugging step).
   at this point i didn't want to tune to much since the final v3 is coming...
</p>


<p>for v3 we finally introduce a loss relating the previous frame
   (which was one of the main intentions of the project in the first place)
</p>
<p>now G takes not just the RGB image, but the dither of the previous frame.
</p>
<table>
<tbody><tr><td>
<img src="http://matpalm.com/blog/imgs/2020/dn/models.v3.png">
</td></tr>
<tr><td>
v3 architecture
</td></tr>
</tbody></table>

<p>the loss for G now has three parts
</p>
<pre>1. D(G(rgb_t1)) =&gt; real      # fool D
2. L1(G(rgb_t1), dither_t1)  # reconstruct the dither
3. L1(G(rgb_t1), dither_t0)  # don't change too much from the last frame
</pre>

<p>normally with a network that takes as input the same thing it's outputting
   we have to be careful to include things like teacher forcing.
   but since we don't intend to use this network for any kind of rollouts
   we can just always feed the "true" dithers in where required.
   having said that, rolling out the dithers from this network would be interesting :D
</p>


<p>the third loss objective, not changing too many pixels from the last frame,
   works well for generally stationary shots
   but is disastrous for scene changes :/
</p>
<p>consider the following graph for a sequence of frames showing the pixel difference
   between frames.
</p>
<p><img src="http://matpalm.com/blog/imgs/2020/dn/pixel_diff_between_scenes.png"></p><p>when there is a scene change we observe a clear "spike" in pixel diff. my first thought
   was to look for these and do a full redraw for them. it's very straightforward to
   find them (using a simple z-score based anomaly detector on a sliding window) but
   the problem is that it doesn't pick up the troublesome case of a panning shot where we don't
   have a scene change exactly. in these cases there is no abrupt scene change, but there
   are a lot of pixels changing so we end up seeing a lot of ghosting.
</p>
<p>i spent ages tinkering with the best way to approach this before deciding that a simple
   approach of <code>num_pixels_changed_since_last_redraw &gt; threshold</code> was good enough to decide
   if a full redraw was required (with a cooldown to ensure we not redrawing all the time)
</p>


<p>the v3 network gets a very good result <em>very</em> quickly; unsurprisingly since the dither at time
   t0 provided to G is a pretty good estimate of the dither at t1 :)
   i.e. G can get a good result simply by copying it!
</p>
<p>the following scenario shows this effect...
</p>
<p>consider three sequential frames, the middle one being a scene change.
</p>
<p><img src="http://matpalm.com/blog/imgs/2020/dn/v3.scene_eg.1.png"></p><p>at the very start of training the reconstruction loss is dominant and
   we get blobby outlines of the frame.
</p>
<p><img src="http://matpalm.com/blog/imgs/2020/dn/v3.scene_eg.2.png"></p><p>but as the contribution from the dither at time t0 kicks it things look good in general but
   the frames at the scene change end up being a ghosted mix attempt to copy through the old
   frame along with dithering the new one.
   (depending on the relative strength of the loss terms of G).
</p>
<p><img src="http://matpalm.com/blog/imgs/2020/dn/v3.scene_eg.3.png"></p>
<p>so the v3 version generally works and i'm sure with some more tuning i could get a better result
   but, as luck would have it, i actually find the results from v2 more appealing when testing
   on the actual eink screen. so even though the intention was do something like v3 i'm going to end
   up running something more like v2 (as shown in these couple of examples (though the resolution
   does it no justice (not to mention the fact the player will run about 5000 times slower than these
   gifs)))
</p>




<p>i'll update this section when i get a proper frame made (though i might try myself?) but for now the
   prototype lives balanced precariously on a piece of foam below it's younger sibling pi zero eink screen
   running game of life.
</p>
<table>
<tbody><tr><td><img src="http://matpalm.com/blog/imgs/2020/dn/prototype.png"></td></tr>
<tr><td>prototype on desk</td></tr>
</tbody></table>



<ul>
 <li>
     for reconstruction and frame change i used L1 loss, but that's not exactly what we
     want. since we want to avoid the ghosting (white changing to black resulting in grey)
     we should try to avoid white to black but ignore black to white.
 </li>

 <li>
     we might be able to better handle scene changes by also including a
     loss component around the <em>next</em> frame.
 </li>

 <li>
     there's a padding issue where i train G on patches but when it's run on the full res
     version we get an edge artefact the size of the original patch (see image below).
     as a hacky fix i just padded the RGB image before passing it to …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://matpalm.com/blog/dithernet_vsmp/">http://matpalm.com/blog/dithernet_vsmp/</a></em></p>]]>
            </description>
            <link>http://matpalm.com/blog/dithernet_vsmp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25090215</guid>
            <pubDate>Sat, 14 Nov 2020 04:06:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Use local dev tools on remote files with SSHFS]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25090117">thread link</a>) | @ykoll58
<br/>
November 13, 2020 | https://curiousstemlovingfellow.com/posts/sshfs-ubuntu-virtualbox/post/ | <a href="https://web.archive.org/web/*/https://curiousstemlovingfellow.com/posts/sshfs-ubuntu-virtualbox/post/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>November 13, 2020</p><p>I often have to work with virtual machines or remote hosts. To utilize my local development environment while doing so I configure SSH and SSHFS. Enabling the use of tools on the local host while working with files on the remote, with the security of ssh.</p><p><strong>SSHFS</strong> (SSH filesystem) enables the mounting of a remote directory over a normal ssh connection to the local filesystem. Prior to installing, make sure <a href="https://curiousstemlovingfellow.com/posts/ssh-ubuntu-virtualbox/post">SSH is setup</a> with the appropriate keys.</p><ol><li>Download &amp; Install <a href="https://osxfuse.github.io/">FUSE for macOS</a></li><li>Download &amp; Install <a href="https://osxfuse.github.io/">SSHFS</a></li></ol><h2 id="mount-remote-filesystems">Mount remote filesystems<a href="#mount-remote-filesystems" aria-label="mount remote filesystems permalink"></a></h2><p>The following command mounts the remote directory to a specified mount point.</p><pre data-language="" data-index="0"><code><span><span>sshfs username@remotesystem:/remote/path/to/directory ~/mount/point</span></span></code></pre><p>The <a href="https://github.com/tkolleh/dotfiles/blob/master/ws/usrBinScripts/executable_rmount.sh"><code>rmount</code></a> and <a href="https://github.com/tkolleh/dotfiles/blob/master/ws/usrBinScripts/executable_rumount.sh"><code>rumount</code></a> bash scripts facilitate convenient mount and unmounts using <code>sshfs</code>. To begin using the scripts.</p><ol><li>Create a folder named <strong>mounts</strong> in your user home directory, <code>~/mounts</code>.</li><li>Download the scripts and make them executable, <code>chmod u+x &lt;path-to-script&gt;</code>.</li></ol><p>The functions reference host named in the local <code>~/.ssh/config</code> file, configured with a key pair (without a password). See <a href="https://curiousstemlovingfellow.com/posts/ssh-ubuntu-virtualbox/post">earlier blog</a> post on the subject for reference.</p><pre data-language="c" data-index="1"><code><span><span><span>Host ml</span></span></span>
<span><span><span>  HostName ec2-*.compute-</span><span>1.amazonaws.com</span></span></span>
<span><span><span>  User ubuntu</span></span></span>
<span><span><span>  PreferredAuthentications publickey</span></span></span>
<span><span><span>  IdentitiesOnly yes</span></span></span>
<span><span><span>  IdentityFile ~/.ssh/aws</span></span></span>
<span><span><span>  Port </span><span>22</span></span></span></code></pre><p>Executing <code>rmount ml</code> - will mount the entire filesystem to a local <code>ml</code> (<code>~/mounts/ml</code>) folder. A folder created by the function. The default “mounts” path, created earlier, can be changed by modifying the function. Executing <code>rmount ml:/home/ec2-user</code> mounts the <code>ec2-user</code> directory in <code>~/mounts/ml/</code>. Running <code>rumount ml</code>, removes the <code>ml</code> folder and unmounts the remote filesystem. </p><p>With a remote filesystem mounted locally, local development tools can be used without having to download each file or having to remember to sync files. Its a secure tunnel to your remote filesystem where files behave almost as if they’re local.</p><p>I’m publishing this as part of 100 Days To Offload. You can learn more by visiting <a href="https://100daystooffload.com/">#100DaysToOffload</a>.</p><br><blockquote><h2 id="references">References<a href="#references" aria-label="references permalink"></a></h2><ul><li><a href="https://tools.ietf.org/html/rfc4251">The Secure Shell Protocol</a></li><li><a href="https://brettterpstra.com/2013/02/10/the-joy-of-sshfs/">Inspiration</a></li></ul></blockquote><hr><div><div><p><strong>T.J. Kolleh</strong></p><p>Engineer with interests in the development &amp; delivery of A.I. enhanced products. This site is a collection of thoughts about technology, and a way to keep track of research.</p></div></div><ul><li><a rel="prev" href="https://curiousstemlovingfellow.com/posts/ssh-ubuntu-virtualbox/post/">← <!-- -->SSH To Guest or Remote OS</a></li><li></li></ul></div></div>]]>
            </description>
            <link>https://curiousstemlovingfellow.com/posts/sshfs-ubuntu-virtualbox/post/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25090117</guid>
            <pubDate>Sat, 14 Nov 2020 03:39:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Visual Guide to Regular Expression]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25090112">thread link</a>) | @gilad
<br/>
November 13, 2020 | https://amitness.com/regex/ | <a href="https://web.archive.org/web/*/https://amitness.com/regex/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="text">
<p>It’s a common task in NLP to either check a text against a pattern or extract parts from the text that matches a certain pattern. A regular expression or “regex” is a powerful tool to achieve this.</p>
<p>While powerful, regex can feel daunting as it comes with a lot of features and sub-parts that you need to remember.</p>
<p>In this post, I will illustrate the various concepts underlying regex. The goal is to help you build a good mental model of how a regex pattern works.</p>
<h2 id="mental-model">Mental Model</h2>
<p>Let’s start with a simple example where we are trying to find the word ‘cool’ in the text.</p>
<p><img src="https://amitness.com/images/regex-mental-model-example.png" alt=""></p>
<p>With regex, we could simply type out the word ‘cool’ as the pattern and it will match the word.</p>

<p>While regex matched our desired word ‘<strong>cool</strong>’, the way it operates is not at the word level but the character level. This is the key idea.</p>
<blockquote>
<p><strong>Key Idea</strong>: Regex works at the character-level, not word-level.</p>
</blockquote>
<p><img src="https://amitness.com/images/regex-working.png" alt=""></p>
<p>The implication of this is that the regex <code>r'cool'</code> would match the following sentences as well.</p>
<p><img src="https://amitness.com/images/regex-exact-word-match.png" alt=""></p>
<h2 id="basic-building-blocks">Basic Building Blocks</h2>
<p>Now that we understand the key idea, let’s understand how we can match simple characters using regex.</p>
<h3 id="a-specific-character">a. Specific character</h3>
<p>We can simply specify the character in the regular expression and it will match all instances in the text.</p>
<p>For example, a regular expression given below will match all instances of ‘a’ in the text. You can use any of the small and capital alphabets.</p>

<p><img src="https://amitness.com/images/regex-match-only-a.png" alt=""></p>
<p>You can also use any digits from 0 to 9 and it will work as well.</p>

<p><img src="https://amitness.com/images/regex-python-3.7-example.png" alt=""></p>
<p>Note that regex is case-sensitive by default and thus the following regex won’t match anything.</p>

<p><img src="https://amitness.com/images/regex-not-matched-by-capital-a.png" alt=""></p>
<h3 id="b-white-space-character">b. White space character</h3>
<p>We can detect special characters such as whitespace and newlines using special escape sequences.</p>
<p><img src="https://amitness.com/images/regex-white-space-characters.png" alt=""></p>
<p>Besides the common ones above, we have:</p>
<ul>
<li><strong>\r</strong> for carriage return</li>
<li><strong>\f</strong> for form feed</li>
<li><strong>\e</strong> for escape.</li>
</ul>
<h3 id="c-special-sequences">c. Special sequences</h3>
<p>Regex provides a bunch of built-in special symbols that can match a group of characters at once. These begin with backslash <code>\</code>.</p>
<h4 id="pattern-d">Pattern: <code>\d</code></h4>
<p>It matches any single-digit number between 0 to 9.</p>
<p><img src="https://amitness.com/images/regex-single-digit.png" alt=""></p>
<p>Notice that matches are single digit. So we have 4 different matches below instead of a single number <code>18.04</code>.</p>
<p><img src="https://amitness.com/images/regex-ubuntu-18.04.png" alt=""></p>
<h4 id="pattern-s">Pattern: \s</h4>
<p>It matches any whitespace character (<span>space</span>, <span>tab</span> or <span>newline</span>).</p>
<p><img src="https://amitness.com/images/regex-match-any-whitespace.png" alt=""></p>
<h4 id="pattern-w">Pattern: \w</h4>
<p>It matches any of the small alphabets(a to z), capital alphabets(A to Z), digits (0 to 9), and underscore.</p>
<p><img src="https://amitness.com/images/regex-slash-w.png" alt=""></p>
<h4 id="pattern-">Pattern: .</h4>
<p>It matches any character except the new line (\n).</p>
<p><img src="https://amitness.com/images/regex-everything-except-newline.png" alt=""></p>
<div><div><pre><code><span>import</span> <span>re</span>

<span>&gt;&gt;&gt;</span> <span>re</span><span>.</span><span>findall</span><span>(</span><span>r'.'</span><span>,</span> <span>'line 1</span><span>\n</span><span>line2'</span><span>)</span>
<span>[</span><span>'l'</span><span>,</span> <span>'i'</span><span>,</span> <span>'n'</span><span>,</span> <span>'e'</span><span>,</span> <span>' '</span><span>,</span> <span>'1'</span><span>,</span> <span>'l'</span><span>,</span> <span>'i'</span><span>,</span> <span>'n'</span><span>,</span> <span>'e'</span><span>,</span> <span>'2'</span><span>]</span>
</code></pre></div></div>
<h4 id="pattern-negations">Pattern: Negations</h4>
<p>If you use the capitalized versions of the patterns above, they act as negation.</p>
<p>For example, if “\d” matched any digits from 0 to 9, then “\D” will match anything except “0 to 9”.</p>
<p><img src="https://amitness.com/images/regex-negation.png" alt=""></p>
<h3 id="d-character-sets">d. Character sets</h3>
<p>These are patterns starting with <code>[</code> and ending with <code>]</code> and specify the characters that should be matched enclosed by brackets.</p>
<p>For example, the following pattern matches any of the characters ‘a’, ‘e’, ‘i’, ‘o’, and ‘u’.
<img src="https://amitness.com/images/regex-aeiou.png" alt=""></p>
<p>You can also replicate the functionality of <code>\d</code> using the below pattern. It will match any digits between 0 to 9.
<img src="https://amitness.com/images/regex-1-to-9.png" alt=""></p>
<p>Instead of specifying all the digits, we can use <code>-</code> to specify only start and end digits. So, instead of <code>[0123456789]</code>, we can do:</p>
<p><img src="https://amitness.com/images/regex-refactor-all-digits.png" alt=""></p>
<p>For example, <code>[2-4]</code> can be used to match any digits between 2 to 4 i.e. (2 or 3 or 4).</p>
<p><img src="https://amitness.com/images/regex-year-2014-example.png" alt=""></p>
<p>You can even use the special characters we learned previously inside the brackets. For example, you can match any digit from 0 to 9 or whitespace as:</p>
<p><img src="https://amitness.com/images/regex-whitespace-or-digit.png" alt=""></p>
<p>Below, I have listed some useful common patterns and what they mean.</p>
<p><img src="https://amitness.com/images/regex-common-pattern-for-bracket.png" alt=""></p>
<h3 id="e-anchors">e. Anchors</h3>
<p>Regex also has special handlers to make the pattern only match if it’s at the start or end of the string.</p>
<p>We can use the <code>^</code> anchor to match patterns only at the start of a line. For example:</p>
<p><img src="https://amitness.com/images/regex-start-anchor.png" alt=""></p>
<p>Similarly, we can use the <code>$</code> anchor after the character to match patterns only if it’s the end of the line. For example:</p>
<p><img src="https://amitness.com/images/regex-anchor-end.png" alt=""></p>
<h3 id="f-escaping-metacharacters">f. Escaping metacharacters</h3>
<p>Consider a case where we want to exactly match the word “Mr. Stark”.</p>
<p>If we write a regex like <code>Mr. Stark</code>, then it will have an unintended effect. Since we know dot has a special meaning in a regex.</p>
<p><img src="https://amitness.com/images/regex-dot-issue.png" alt=""></p>
<p>So, we should always escape the special metacharacters like <code>.</code>, <code>$</code> etc. if our goal is to match the exact character itself.</p>
<p><img src="https://amitness.com/images/regex-dot-fixed.png" alt=""></p>
<p>Here is the list of metacharacters that you should remember to escape if you’re using them directly.</p>
<div><div><pre><code>^ $ . * + ? { } [ ] \ | ( )
</code></pre></div></div>
<h2 id="repetition-of-basic-blocks">Repetition of basic blocks</h2>
<p>Now that we can pattern match any characters, we could repeat things and start building more complicated patterns.</p>
<h3 id="a-naive-repetition">a. Naive repetition</h3>
<p>Using only what we have learned so far, a naive way would be to just repeat the pattern. For example, we can match two-digit numbers by just repeating the character-level pattern.</p>

<p><img src="https://amitness.com/images/regex-slash-d-slash-d.png" alt=""></p>
<h3 id="b-quantifiers">b. Quantifiers</h3>
<p>Regex provides special quantifiers to specify different types of repetition for the character preceding it.</p>
<h4 id="i-fixed-repetition">i. Fixed repetition</h4>
<p>We can use the <code>{...}</code> quantifier to specify the number of times a pattern should repeat.</p>
<p><img src="https://amitness.com/images/regex-manual-counts.png" alt=""></p>
<p>For example, the previous pattern for matching 2-digit number can be recreated as:</p>
<p><img src="https://amitness.com/images/regex-it-is-2020.png" alt=""></p>
<p>You can also specify a range of repetitions using the same quantifier. For example, to match from 2-digit to 4-digit numbers, we could use the pattern:</p>
<p><img src="https://amitness.com/images/regex-min-max-count.png" alt=""></p>
<p>When applied to a sentence, it will match both 4-digit and 2-digit numbers.</p>
<p><img src="https://amitness.com/images/regex-20-years-old.png" alt=""></p>
<div>
<p><strong>Note:</strong></p><p>
There should not be any space between minimum and maximum count For example, \d{2, 4} doesn't work.
</p>
</div>
<h4 id="ii-flexible-quantifiers">ii. Flexible quantifiers</h4>
<p>Regex also provides quantifiers “*”, “+” and “?” using which you can specify flexible repetition of a character.</p>
<ul>
<li>
<p><strong>0 or 1 times</strong>: <code>?</code><br>
The <code>?</code> quantifier matches the previous character if it repeats 0 or 1 times. This can be useful to make certain parts optional. It is equivalent to <code>{0,1}</code>.</p>
<p><img src="https://amitness.com/images/regex-question-mark-clarify.png" alt=""></p>
<p>For example, let’s say we want to match both the word “sound” and “sound” where “s” is optional. Then, we can use the <code>?</code> quantifier that matches if a character repeats 0 or 1 times.<br>
<img src="https://amitness.com/images/regex-question-mark-example.png" alt=""></p>
</li>
<li>
<p><strong>one or more times</strong>: <code>+</code><br>
The <code>+</code> quantifier matches the previous character if it repeats 1 or more times. It is equivalent to <code>{1,}</code>.</p>
<p>For example, we could find numbers of any arbitrary length using the regex <code>\d+</code>.</p>
<p><img src="https://amitness.com/images/regex-example-of-plus.png" alt=""></p>
</li>
<li>
<p><strong>zero or more times</strong>: <code>*</code><br>
The <code>*</code> quantifier matches the previous character if it repeats zero or more times. It is equivalent to <code>{0,}</code>.</p>
</li>
</ul>
<h2 id="usage-in-python">Usage in Python</h2>
<p>Python provides a module called “re” in the standard library to work with regular expression.</p>
<h3 id="need-for-raw-strings">Need for raw strings</h3>
<p>To specify a regular expression in Python, we precede it with <strong>r</strong> to create raw strings.</p>

<p>To understand why we precede with <strong>r</strong>, let’s try printing the expression <strong>\t</strong> without <code>**r**</code>.</p>
<div><div><pre><code><span>&gt;&gt;&gt;</span> <span>pattern</span> <span>=</span> <span>'</span><span>\t</span><span>'</span>
<span>&gt;&gt;&gt;</span> <span>print</span><span>(</span><span>pattern</span><span>)</span>

</code></pre></div></div>
<p>You can see how when we don’t use raw string, the string <code>\t</code> is treated as the escape character for tab by Python.</p>
<p>Now let’s convert it into raw string. We get back whatever we specified.</p>
<div><div><pre><code><span>&gt;&gt;&gt;</span> <span>pattern</span> <span>=</span> <span>r'\t'</span>
<span>&gt;&gt;&gt;</span> <span>print</span><span>(</span><span>pattern</span><span>)</span>
\<span>t</span>
</code></pre></div></div>
<h3 id="using-re-module">Using re module</h3>
<p>To use <code>re</code> module, we can start by importing the <code>re</code> module as:</p>

<h4 id="1-refindall">1. re.findall</h4>
<p>This function allows us to get all the matches as a list of strings.</p>
<div><div><pre><code><span>import</span> <span>re</span>
<span>re</span><span>.</span><span>findall</span><span>(</span><span>r'\d'</span><span>,</span> <span>'123456'</span><span>)</span>
</code></pre></div></div>
<div><div><pre><code>['1', '2', '3', '4', '5', '6']
</code></pre></div></div>
<h4 id="2-rematch">2. re.match</h4>
<p>This function searches for a pattern at the beginning of the string and returns the first occurrence as a match object. If the pattern is not found, it returns None.</p>
<div><div><pre><code><span>import</span> <span>re</span>

<span>match</span> <span>=</span> <span>re</span><span>.</span><span>match</span><span>(</span><span>r'batman'</span><span>,</span> <span>'batman is cool'</span><span>)</span>
<span>print</span><span>(</span><span>match</span><span>)</span>
</code></pre></div></div>
<div><div><pre><code>&lt;re.Match object; span=(0, 6), match='batman'&gt;
</code></pre></div></div>
<p><img src="https://amitness.com/images/regex-match-object.png" alt=""></p>
<p>With the match object, we can get the matched text as</p>


<p>In a case where our pattern is not at the start of the sentence, we will not get any match.</p>
<div><div><pre><code><span>import</span> <span>re</span>

<span>match</span> <span>=</span> <span>re</span><span>.</span><span>match</span><span>(</span><span>r'batman'</span><span>,</span> <span>'The batman is cool'</span><span>)</span>
<span>print</span><span>(</span><span>match</span><span>)</span>
</code></pre></div></div>

<h4 id="3-research">3. re.search</h4>
<p>This function also finds the first occurrence of a pattern but the pattern can occur anywhere in the text. If the pattern is not found, it returns None.</p>
<div><div><pre><code><span>import</span> <span>re</span>

<span>match</span> <span>=</span> <span>re</span><span>.</span><span>search</span><span>(</span><span>r'batman'</span><span>,</span> <span>'the batman is cool'</span><span>)</span>
<span>print</span><span>(</span><span>match</span><span>.</span><span>group</span><span>())</span>
</code></pre></div></div>

<h2 id="references">References</h2>
<ul>
<li>A.M. Kuchling, <a href="https://docs.python.org/3/howto/regex.html">“Regular Expression HOWTO - Python 3.9.0 documentation”</a></li>
</ul>
</section></div>]]>
            </description>
            <link>https://amitness.com/regex/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25090112</guid>
            <pubDate>Sat, 14 Nov 2020 03:37:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Publish Early, Publish Often]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25089952">thread link</a>) | @nottrobin
<br/>
November 13, 2020 | https://robinwinslow.uk/2020/11/14/publish-early-publish-often/ | <a href="https://web.archive.org/web/*/https://robinwinslow.uk/2020/11/14/publish-early-publish-often/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <p>This may fly in the face of conventional wisdom.</p>



<p>In the last few days Iâ€™ve watched about 20 video tutorials on blogging and read similar nubmer of articles.</p>

<p>One very common refrain from these blogging experts is:</p>

<blockquote>
  <p>just start writing!</p>
</blockquote>

<p>This is great advice. My blog has languished too long because I procrastinate horribly, doing research, tweaking my wording, improving my website styling etc. â€œJust start writingâ€� is clearly the solution to all my problems, if I can do it.</p>

<p>But thereâ€™s another frequent piece of advice that seems to contradict this:</p>

<blockquote>
  <p>quality is king!</p>
</blockquote>

<p>Time was, they say, that you could just write down your stream of consciousness and have a successful blog. No longer. Nowadays, there are so many quality content producers that you need to stand out.</p>

<p>So far, so reasonable.</p>

<p>But then they go on to say that to stay ahead in this cuthroat world of blogging, you need to <em>only publish quality content</em>.</p>

<p>This is the worst thing for me to hear.</p>

<p>Until yesterday, Iâ€™d not published anything for 21 months! The reason? I expect perfection from myself, and nothing less will do. Iâ€™m so intimidated by the enormity of the amazing ground-breaking article Iâ€™m about to write any second now that I just procrastinate starting forever.</p>



<p>In my world of web development, we have a saying:</p>

<blockquote>
  <p><a href="https://en.wikipedia.org/wiki/Release_early,_release_often">Release early, release often</a></p>
</blockquote>

<p>We release our products as early as we possibly can - while they only do the bare minimum and sometimes while they still have bugs. Then we make improvements fast.</p>

<p>This is for two reasons:</p>

<ol>
  <li>Because itâ€™s easy for new products to get caught up in a cycle of endless tweaking and never get released, and</li>
  <li>Once itâ€™s out in the world, you can start to see how much people actually like it. You have much more knowledge</li>
</ol>

<p>Why couldnâ€™t the same theory apply to blogging?</p>



<p>One reason to be careful about â€œreleasing earlyâ€� is the potential for reputational damage. If youâ€™re well known, releasing a sub-par product could tarnish your reputation.</p>

<p>So, if a blogger like myself was trying to build a reputation, and their success depended on this reputation, then you would want to be very careful about publishing sub-par content.</p>

<p>However, my experiene of blogging so far is that basically none of my readers know who I am. They find my posts through Google (other search engines are available), read that post, and bugger off. I suspect this is how most blogs are consumed.</p>

<p>Even if people find my articles through, say, my Twitter feed (where hopefully they at least vaguely know who I am), theyâ€™re still only going to click on the articles that look good to them.</p>

<p>If Iâ€™m right about this, it really doesnâ€™t matter how much crap content you produce, as long as you produce <em>some</em> good content. And if youâ€™ve written a bad article that no-one visits, you can always improve it later to make it a good one.</p>



<p>As I <a href="https://robinwinslow.uk/2020/11/13/i-am-a-blogger/">mentioned yesterday</a>, Iâ€™m currently trying to revive my blog. Iâ€™m going to do this by setting the bar for publishing content very low for myself, and hoping to publish daily. At least for a while.</p>

<p>Iâ€™m not going to spend a long time on editing, or let myself expect too much of my posts. Iâ€™m just going to do what I can.</p>

<p>This is my second post in 2 days. So far so good, I guess.</p>

<p>Letâ€™s see how it goes from here.</p>

</article></div>]]>
            </description>
            <link>https://robinwinslow.uk/2020/11/14/publish-early-publish-often/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25089952</guid>
            <pubDate>Sat, 14 Nov 2020 03:04:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Novel fiber optic sensors transmit data up to 100x faster]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25089079">thread link</a>) | @finphil
<br/>
November 13, 2020 | https://nuadox.com/post/634716239692955648/new-fiber-optics-100x-faster | <a href="https://web.archive.org/web/*/https://nuadox.com/post/634716239692955648/new-fiber-optics-100x-faster">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> 
                 
                    
                    <article id="634716239692955648">
                        <div>
                            <div>
                                <a href="https://nuadox.com/post/634716239692955648/new-fiber-optics-100x-faster"><h2>Novel fiber optic sensors transmit data up to 100x faster</h2></a>
                                <figure data-orig-width="1920" data-orig-height="1080"><img src="https://64.media.tumblr.com/cf8f1259a9eee5b800a61b0d6cb930ae/1f0f992b620981dc-b3/s1280x1920/ff616593fe193d87f8e98b402b0f48dd8dcf9777.jpg" alt="image" data-orig-width="1920" data-orig-height="1080" width="1280" height="720"></figure><p><b>- By Clara Marc ,&nbsp;<a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.epfl.ch%2Fen%2F&amp;t=MzAwYTZjMGE0ODczMzQ4MGI2Nzc2NTg5NjUyNjEyM2QyMGIyZDNmYix6YW5YWDQyOA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F634716239692955648%2Fnew-fiber-optics-100x-faster&amp;m=0&amp;ts=1605631237">École polytechnique fédérale de Lausanne (EPFL)</a> -</b></p><p>EPFL engineers have developed an advanced encoding and decoding system that allows fiber optic sensors to send data up to 100 times faster and over a wider area.</p><p>“Unlike conventional sensors that take measurements at a given point, like thermometers, fiber optic sensors record data all along a fiber,” says Luc Thévenaz, a professor at EPFL’s School of Engineering and head of the <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.epfl.ch%2Flabs%2Fgfo%2F&amp;t=ZjNmOWNkYzEzZDAyYWU1MzI4YmE5YjM0YTgyNjdjZTc2MzRiNzVlMix6YW5YWDQyOA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F634716239692955648%2Fnew-fiber-optics-100x-faster&amp;m=0&amp;ts=1605631237">Group for Fibre Optics (GFO)</a>. “But the technology has barely improved over the past few years.”</p><h2><b>Used widely in safety applications</b></h2><p>Fiber optic sensors are commonly used in hazard detection systems, such as to spot cracks in pipelines, identify deformations in civil engineering structures and detect potential landslides on mountain slopes. The sensors can take temperature readings everywhere a fiber is placed, thereby generating a continuous heat diagram of a given site – even if the site stretches for dozens of kilometers. That provides crucial insight into possible accidents before they happen.</p><h2><b>Improving signal quality</b></h2><p>Working in association with the <a href="https://t.umblr.com/redirect?z=http%3A%2F%2Fenglish.bupt.edu.cn%2F&amp;t=OWY2ODEwMmZjNWRiOTNhNGZlNWNlZGYxMjZkNTNlMjY2NmM5NTliNSx6YW5YWDQyOA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F634716239692955648%2Fnew-fiber-optics-100x-faster&amp;m=0&amp;ts=1605631237">Beijing University of Posts and Telecommunications</a>, two GFO engineers – postdoc Zhisheng Yang and PhD student Simon Zaslawski – developed a new system for encoding and decoding data sent along the fibers. With their method, sensors can receive higher-energy signals and decode them faster, resulting in measurements taken more rapidly and over a larger area. Their research <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41467-020-19201-1&amp;t=ZWU0ZTQ1YjI4YmM1YzRlZjFjODgwZjM3YTRhZjhlNDg0ZTAxNjQ1Mix6YW5YWDQyOA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F634716239692955648%2Fnew-fiber-optics-100x-faster&amp;m=0&amp;ts=1605631237">has just been published in <i>Nature Communications</i>.</a></p><p>The engineers describe their system as working like an echo. If you shout a single word, you hear that word back. But if you sing out a song, what you hear back is a blend of sounds that are hard to distinguish. You would need a “key” to decipher the sounds and make them intelligible. Fiber optic sensors function in a similar manner, except that an instrument sends out light pulses – rather than sounds – along a fiber. Signals bounce back up the fiber and a device decodes them, turning the signals into usable data.</p><p>To make the sensors more efficient, Yang and Zaslawski grouped the light pulses into sequences so that the signals bounce back with greater intensity. However, that didn’t solve the “echo” problem – that is, finding a key to make the signals readable. So they developed a method for encoding the data sent along a fiber; their method employs special genetic optimization algorithms to cope with imperfections. “Other systems are either limited in scope or expensive,” says Thévenaz. “But with ours, you just have to add a software program to your existing equipment. No need to adapt your sensors or use complex devices.”</p><p>–</p><p><b>Source:&nbsp;<a href="https://t.umblr.com/redirect?z=https%3A%2F%2Factu.epfl.ch%2Fnews%2Fnew-fiber-optic-sensors-transmit-data-up-to-100-ti%2F&amp;t=MzY0M2YzNjkzZTI3Yzk4MWYyNmFlYWU0NjdkNmY0YWVlMWU1YmJiNix6YW5YWDQyOA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F634716239692955648%2Fnew-fiber-optics-100x-faster&amp;m=0&amp;ts=1605631237">École polytechnique fédérale de Lausanne (EPFL)</a></b></p><p><b>Full study:</b>&nbsp;“Genetic-optimised aperiodic code for distributed optical fibre sensors”, <i>Nature Communications</i>.</p><p><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fdoi.org%2F10.1038%2Fs41467-020-19201-1&amp;t=ODA0ZTk0N2RlNzA0MTUxYWIyZjdiYTI0MDI3ODRmNGYyNTJkYmJhZSx6YW5YWDQyOA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F634716239692955648%2Fnew-fiber-optics-100x-faster&amp;m=0&amp;ts=1605631237">https://doi.org/10.1038/s41467-020-19201-1</a><br></p><h2><b>Read Also</b></h2><p><a href="https://nuadox.com/post/627187404240027648/world-record-internet-speed-record-set-by-ucl-scientists">New world record internet speed set</a></p>
                    
                      
                    
                    
                    
                    
                    
                    
                    
                    
                                             
                                <p><span>
                                    <p>
                                    
                                        <a href="https://nuadox.com/tagged/optics">optics</a>
                                    
                                        <a href="https://nuadox.com/tagged/materials">materials</a>
                                    
                                        <a href="https://nuadox.com/tagged/fiber-optics">fiber optics</a>
                                    
                                        <a href="https://nuadox.com/tagged/telecom">telecom</a>
                                    
                                        <a href="https://nuadox.com/tagged/sensors">sensors</a>
                                    
                                        <a href="https://nuadox.com/tagged/physics">physics</a>
                                    
                                        <a href="https://nuadox.com/tagged/featured">featured</a>
                                    
                                    </p>
                                </span></p>
                                
                            </div>
                        </div>
                    </article>
                 
                </div></div>]]>
            </description>
            <link>https://nuadox.com/post/634716239692955648/new-fiber-optics-100x-faster</link>
            <guid isPermaLink="false">hacker-news-small-sites-25089079</guid>
            <pubDate>Sat, 14 Nov 2020 00:14:04 GMT</pubDate>
        </item>
    </channel>
</rss>
