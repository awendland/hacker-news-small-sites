<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sat, 27 Jun 2020 20:16:44 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sat, 27 Jun 2020 20:16:44 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Big Sur on Unsupported Macs]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 3 (<a href="https://news.ycombinator.com/item?id=23650031">thread link</a>) | @todsacerdoti
<br/>
June 26, 2020 | https://parrotgeek.com/bigsur/ | <a href="https://web.archive.org/web/*/https://parrotgeek.com/bigsur/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><span face="Helvetica, Arial, sans-serif"><b><u>Compatibility
            status</u></b> <br>
        Note: these instructions only support computers<b> </b>that
        have a Metal-capable GPU <i>and</i> native APFS boot support.<br>
      </span></p><div>
      <tbody>
        <tr>
          <td><span face="Helvetica,
              Arial, sans-serif"><b>Model Identifier</b><br>
            </span></td>
          <td><span face="Helvetica,
              Arial, sans-serif"><b>Human-Readable Name</b><br>
            </span></td>
          <td><span face="Helvetica,
              Arial, sans-serif"><b>Status</b><br>
            </span></td>
        </tr>
        <tr>
          <td><span face="Helvetica, Arial, sans-serif">MacBookAir5,1<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">MacBook









              Air (11-inch, Mid 2012)<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif"><span face="Helvetica, Arial, sans-serif">Everything except
                Wi-Fi works</span> </span></td>
        </tr>
        <tr>
          <td><span face="Helvetica, Arial, sans-serif">MacBookAir5,2<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">MacBook









              Air (13-inch, Mid 2012)<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif"><span face="Helvetica, Arial, sans-serif">Everything except
                Wi-Fi works</span> </span></td>
        </tr>
        <tr>
          <td><span face="Helvetica, Arial, sans-serif">MacBookPro9,1<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">MacBook









              Pro (15-inch, Mid 2012)<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif"><span face="Helvetica, Arial, sans-serif">Everything except
                Wi-Fi works</span> </span></td>
        </tr>
        <tr>
          <td><span face="Helvetica, Arial, sans-serif">MacBookPro9,2<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">MacBook









              Pro (13-inch, Mid 2012)<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif"><span face="Helvetica, Arial, sans-serif">Everything except
                Wi-Fi works</span> </span></td>
        </tr>
        <tr>
          <td><span face="Helvetica, Arial, sans-serif">MacBookPro10,1<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">MacBook









              Pro (Retina, 15-inch, Mid 2012)<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif"><span face="Helvetica, Arial, sans-serif">Everything except
                Wi-Fi works</span> </span></td>
        </tr>
        <tr>
          <td><span face="Helvetica, Arial, sans-serif">MacBookPro10,2<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">MacBook









              Pro (Retina, 13-inch, Early 2013)<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif"><span face="Helvetica, Arial, sans-serif">Everything except
                Wi-Fi works</span> </span></td>
        </tr>
        <tr>
          <td><span face="Helvetica, Arial, sans-serif">Macmini6,1<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">Mac
              mini (Late 2012)<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">Everything









              except Wi-Fi works<br>
            </span></td>
        </tr>
        <tr>
          <td><span face="Helvetica, Arial, sans-serif">Macmini6,2<br>
            </span></td>
          <td>
            <meta charset="utf-8">
            <span face="Helvetica, Arial, sans-serif">Mac mini (Late
              2012) quad-core<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif"><span face="Helvetica, Arial, sans-serif">Everything except
                Wi-Fi works</span> </span></td>
        </tr>
        <tr>
          <td><span face="Helvetica, Arial, sans-serif">iMac13,1<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">iMac









              (21.5-inch, Late 2012)<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif"><span face="Helvetica, Arial, sans-serif">Everything except
                Wi-Fi works</span> </span></td>
        </tr>
        <tr>
          <td><span face="Helvetica, Arial, sans-serif">iMac13,2<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">iMac









              (27-inch, Late 2012)<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif"><span face="Helvetica, Arial, sans-serif">Everything except
                Wi-Fi works</span> </span></td>
        </tr>
        <tr>
          <td><span face="Helvetica, Arial, sans-serif">iMac14,1<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">iMac









              (21.5-inch, Late 2013) integrated GPU<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">Everything






              works<br>
            </span></td>
        </tr>
        <tr>
          <td><span face="Helvetica, Arial, sans-serif">iMac14,2<br>
            </span></td>
          <td>
            <meta charset="utf-8">
            <span face="Helvetica, Arial, sans-serif">iMac (27-inch,
              Late 2013)<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">Everything






              works<br>
            </span></td>
        </tr>
        <tr>
          <td><span face="Helvetica, Arial, sans-serif">iMac14,3<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">iMac









              (21.5-inch, Late 2013) discrete GPU</span><br>
          </td>
          <td><span face="Helvetica, Arial, sans-serif">Everything






              works<br>
            </span></td>
        </tr>
        <tr>
          <td><span face="Helvetica, Arial, sans-serif">MacPro5,1<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">Mac
              Pro (Mid 2010/Mid 2012)<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">WiFi


              does not work; sleep issues<br>
            </span></td>
        </tr>
      </tbody>
    </div><p><span face="Helvetica, Arial, sans-serif">Special thanks to
        ASentientBot for the method of removing the installer
        compatibility check ("hax.dylib").</span><br>
    </p></div>]]>
            </description>
            <link>https://parrotgeek.com/bigsur/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23650031</guid>
            <pubDate>Fri, 26 Jun 2020 08:56:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Double Tap the Back of Your iPhone to Open Your Garage]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23649963">thread link</a>) | @eshtocof
<br/>
June 26, 2020 | https://heartbeat.fritz.ai/wwdc20-whats-changed-in-accessibility-on-ios-33e0f144e075 | <a href="https://web.archive.org/web/*/https://heartbeat.fritz.ai/wwdc20-whats-changed-in-accessibility-on-ios-33e0f144e075">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><h2 id="b613">WWDC20</h2><h2 id="299f">Learn how accessibility has changed for the better in iOS 14</h2><div><div><div><p><a href="https://heartbeat.fritz.ai/@vhanagwal?source=post_page-----33e0f144e075----------------------" rel="noopener"><img alt="Vardhan Agrawal" src="https://miro.medium.com/fit/c/96/96/1*ORFRUf6O2Tk4XbG3kElncQ.jpeg" width="48" height="48"></a></p></div></div></div></div></div><div><figure><div><div><div><p><img src="https://miro.medium.com/max/60/1*9wSXSk7Fua06okhjIeQbtw.jpeg?q=20" width="2500" height="1031" role="presentation"></p><p><img src="https://miro.medium.com/max/5000/1*9wSXSk7Fua06okhjIeQbtw.jpeg" width="2500" height="1031" srcset="https://miro.medium.com/max/552/1*9wSXSk7Fua06okhjIeQbtw.jpeg 276w, https://miro.medium.com/max/1104/1*9wSXSk7Fua06okhjIeQbtw.jpeg 552w, https://miro.medium.com/max/1280/1*9wSXSk7Fua06okhjIeQbtw.jpeg 640w, https://miro.medium.com/max/1456/1*9wSXSk7Fua06okhjIeQbtw.jpeg 728w, https://miro.medium.com/max/1632/1*9wSXSk7Fua06okhjIeQbtw.jpeg 816w, https://miro.medium.com/max/1808/1*9wSXSk7Fua06okhjIeQbtw.jpeg 904w, https://miro.medium.com/max/1984/1*9wSXSk7Fua06okhjIeQbtw.jpeg 992w, https://miro.medium.com/max/2160/1*9wSXSk7Fua06okhjIeQbtw.jpeg 1080w, https://miro.medium.com/max/2700/1*9wSXSk7Fua06okhjIeQbtw.jpeg 1350w, https://miro.medium.com/max/3240/1*9wSXSk7Fua06okhjIeQbtw.jpeg 1620w, https://miro.medium.com/max/3780/1*9wSXSk7Fua06okhjIeQbtw.jpeg 1890w, https://miro.medium.com/max/4320/1*9wSXSk7Fua06okhjIeQbtw.jpeg 2160w, https://miro.medium.com/max/4800/1*9wSXSk7Fua06okhjIeQbtw.jpeg 2400w" sizes="100vw" role="presentation"></p></div></div></div></figure></div><div><div><p id="90e1">Apple has long integrated accessibility features into their software — and for good reason. By using accessibility features in your app, you’re allowing your app to reach a wider audience.</p><p id="d948">Sticking with their commitment to accessibility, Apple has introduced several new features at WWDC20 which help developers make their apps easier and more entertaining for users with disabilities. By making apps more accessible, developers eliminate the need for users to purchase clunky, expensive devices in order to use their apps — everything they need to interact with the app is built right into the device.</p><p id="df0d">In this article, you’ll learn about some of the biggest and best upgrades to accessibility, announced at this year’s WWDC.</p></div></div></section><hr><section><div><div><p id="ecb9">The first on the list is an interesting feature — which didn’t get talked about on stage. As the name suggests, Back Tap allows users to set single, double, or triple taps on the back of their iPhones and link them to certain tasks. For example, you could double tap on the back of your iPhone to open the weather app.</p><figure><div><div><div><div><p><img src="https://miro.medium.com/max/60/1*-mtu69eu445jv1BwH76CoQ.jpeg?q=20" width="1200" height="732" role="presentation"></p><p><img src="https://miro.medium.com/max/2400/1*-mtu69eu445jv1BwH76CoQ.jpeg" width="1200" height="732" srcset="https://miro.medium.com/max/552/1*-mtu69eu445jv1BwH76CoQ.jpeg 276w, https://miro.medium.com/max/1104/1*-mtu69eu445jv1BwH76CoQ.jpeg 552w, https://miro.medium.com/max/1280/1*-mtu69eu445jv1BwH76CoQ.jpeg 640w, https://miro.medium.com/max/1400/1*-mtu69eu445jv1BwH76CoQ.jpeg 700w" sizes="700px" role="presentation"></p></div></div></div></div><figcaption>Setting up Back Tap on iOS 14.</figcaption></figure><p id="91c1">And since the tapping feature can be linked to Shortcuts, it opens up a whole range of possibilities with home automation and more! As seen in the example above, you could triple tap the back of your phone to quickly take notes, or you could use it to unlock your door when you’re about to enter the house. Easy, right?</p><p id="563c">For users with hearing impairments, Apple has added the ability to adjust sound frequencies on supported headphones. By doing this, users can now set their own preferences on what they want to hear more of and what they want to hear less of.</p><p id="dc81">The new feature also comes with pre-set profiles for specific outdoor situations, in case the user doesn’t want to manually configure the sound frequencies.</p><blockquote><p id="dba7">This new accessibility feature is designed to amplify soft sounds and adjust certain frequencies for an individual’s hearing, to help music, movies, phone calls, and podcasts sound more crisp and clear. Headphone Accommodations also supports Transparency mode on AirPods Pro, making quiet voices more audible and tuning the sounds of your environment to your hearing needs.</p><p id="8aab">— Apple Documentation</p></blockquote><p id="6a9f">Further, the new feature also supports Transparency Mode on AirPods Pro, which allows users to adjust how much of the surroundings they want to hear. If they want to amplify soft voices or listen to the environment in more detail, they now have that autonomy.</p><p id="d5d2">In the same vein, a new feature called <strong>Sound Recognition</strong> can pick up important sounds in the environment, such as Sirens, Fire Alarms, or Car Horns and alert the user of them. Through machine learning models built into the operating system, these sounds can be picked up and transmitted to the user in any way that they wish.</p></div></div></section><hr><section></section><hr><section><div><div><figure><div><div><div><div><p><img src="https://miro.medium.com/max/38/1*3WhAhhK1A2LktugVV3KGHw.png?q=20" width="700" height="1110" role="presentation"></p><p><img src="https://miro.medium.com/max/1400/1*3WhAhhK1A2LktugVV3KGHw.png" width="700" height="1110" srcset="https://miro.medium.com/max/552/1*3WhAhhK1A2LktugVV3KGHw.png 276w, https://miro.medium.com/max/1000/1*3WhAhhK1A2LktugVV3KGHw.png 500w" sizes="500px" role="presentation"></p></div></div></div></div><figcaption>Real-Time Text on the iPhone.</figcaption></figure><p id="2bf5">Group FaceTime calls have become more important than ever during the global pandemic, and Apple has added a small but important accessibility feature to them. Now, if a member of a group FaceTime call is using sign language to communicate, their video will be automatically pinned.</p><p id="ab6c">Using computer vision to detect this can be a boon to those with hearing loss, since reading sign language while the screen is moving around can be frustrating.</p><p id="43b4">In addition to this, Apple has made further improvements to its Real-Time Text feature, which is used for text based communication during phone calls. Previously, it was difficult for RTT users to multitask during phone calls, but it no longer requires the full screen.</p><p id="0458">When we think of accessibility on iOS, VoiceOver is often the first to come to mind. This year, VoiceOver received several significant updates, making it even more useful than before. If you aren’t familiar with it, VoiceOver is Apple’s screen reader, available on all platforms, including iOS, macOS, tvOS, and watchOS.</p><h2 id="ae54">VoiceOver Recognition</h2><p id="aa80">In the past, VoiceOver would require developers to adopt it inside their apps to work well on third-party apps.</p><blockquote><p id="210b">On-device intelligence recognizes key elements displayed on your screen to add VoiceOver support for app and web experiences that don’t have accessibility support built in. — Apple</p></blockquote><p id="2717">This year, Apple is tapping into their machine learning technology to semantically detect where and how to use VoiceOver on unsupported apps. This makes virtually all apps natively supported by VoiceOver and increases their accessibility for those with visual impairments.</p><h2 id="6119">Image Descriptions</h2><p id="6f0d">To make VoiceOver even more useful, Apple has used its computer vision library with <em>even more</em> machine learning to detect the contents of an image.</p><blockquote><p id="2f5f">VoiceOver reads complete-sentence descriptions of images and photos within apps and on the web. VoiceOver speaks the text it identifies within images and photos. — Apple</p></blockquote><p id="f5ed">Instead of simply stating that an image is present, VoiceOver can now provide detailed descriptions of what’s pictured in an image for more useful information to VoiceOver users. It can also detect text in an image through optical character recognition — another great way that machine learning is being used in the iOS 14 update!</p></div></div></section><hr><section><div><div><p id="d6f7">Evidently, there have been plenty of great updates at WWDC20 in accessibility, with even more that weren’t listed here. By releasing a large number of small features, Apple has made their devices more accessible than ever. And, they’ve supercharged many of their flagship accessibility solutions by coupling machine learning technology with them.</p><p id="ab7f">Be sure to <strong>smash that “clap” button</strong> as many times as you can, <strong>share this tutorial</strong> on social media, and <strong>follow me on Twitter.</strong></p></div></div></section><hr><section><div><div><p id="08a6"><em>Editor’s Note:</em><a href="http://heartbeat.fritz.ai/" target="_blank" rel="noopener"><em> </em><strong><em>Heartbeat</em></strong></a><strong><em> </em></strong><em>is a contributor-driven online publication and community dedicated to exploring the emerging intersection of mobile app development and machine learning. We’re committed to supporting and inspiring developers and engineers from all walks of life.</em></p><p id="7676"><em>Editorially independent, Heartbeat is sponsored and published by</em><a href="http://fritz.ai/" target="_blank" rel="noopener"><em> </em><strong><em>Fritz AI</em></strong></a><em>, the machine learning platform that helps developers teach devices to see, hear, sense, and think. We pay our contributors, and we don’t sell ads.</em></p><p id="7977"><em>If you’d like to contribute, head on over to our</em><a target="_blank" rel="noopener" href="https://heartbeat.fritz.ai/call-for-contributors-october-2018-update-fee7f5b80f3e"><em> </em><strong><em>call for contributors</em></strong></a><em>. You can also sign up to receive our weekly newsletters (</em><a href="https://www.deeplearningweekly.com/" target="_blank" rel="noopener"><strong><em>Deep Learning Weekly</em></strong></a><em> and the </em><a href="https://www.fritz.ai/newsletter/?utm_campaign=fritzai-newsletter&amp;utm_source=heartbeat-statement" target="_blank" rel="noopener"><strong><em>Fritz AI Newsletter</em></strong></a><em>), join us on</em><a href="https://join.slack.com/t/fritz-ai-community/shared_invite/enQtNTY5NDM2MTQwMTgwLWU4ZDEwNTAxYWE2YjIxZDllMTcxMWE4MGFhNDk5Y2QwNTcxYzEyNWZmZWEwMzE4NTFkOWY2NTM0OGQwYjM5Y2U" target="_blank" rel="noopener"><em> </em></a><a href="http://fritz.ai/slack" target="_blank" rel="noopener"><strong><em>Slack</em></strong></a><em>, and follow Fritz AI on</em><a href="https://twitter.com/fritzlabs" target="_blank" rel="noopener"><em> </em><strong><em>Twitter</em></strong></a><em> for all the latest in mobile machine learning.</em></p></div></div></section></div></div>]]>
            </description>
            <link>https://heartbeat.fritz.ai/wwdc20-whats-changed-in-accessibility-on-ios-33e0f144e075</link>
            <guid isPermaLink="false">hacker-news-small-sites-23649963</guid>
            <pubDate>Fri, 26 Jun 2020 08:42:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[3K, 60fps, 130ms: achieving it with Rust]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 22 (<a href="https://news.ycombinator.com/item?id=23649534">thread link</a>) | @lukastyrychtr
<br/>
June 26, 2020 | https://blog.tonari.no/why-we-love-rust?ref=twtr | <a href="https://web.archive.org/web/*/https://blog.tonari.no/why-we-love-rust?ref=twtr">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>How we chose the Rust programming language to advance the state-of-the-art in real-time communication</p><div><p><i>T</i><m><i>his post was written collectively with Ryo Kawaguchi, </i></m><m><m><i>Andrea Law, Brian Schwind</i></m></m><m><i>.</i></m></p><p><m>Our goal for tonari is to build a virtual doorway to another space that allows for truly natural human interactions. Nearly two years in development, tonari is, to the best of our knowledge, the lowest-latency high resolution production-ready "teleconferencing" (we are truly not fond of that word) product available. </m></p><ul><li><b>130ms</b> glass-to-glass latency (the time from light hitting the camera to when it appears on-screen on the other side)</li><li><b>3K, 60fps</b> video transmission</li><li>High-bitrate 48kHz stereo audio</li></ul><p>Compare this to the typical <b>315-500ms</b> latency for Zoom and <m>WebRTC</m>, as measured between two laptops (X1 Carbon and MacBook Pro) on the same network at our office. It's a huge difference. It's the difference between constantly interrupting each other versus having a natural flow of conversation. It's the difference between a blurry face from a camera seemingly pointed up someone's nose versus a wide-view high fidelity image that smoothly transfers all the subtle body language of an in-person conversation.</p><div><picture><source srcset="https://blog.tonari.no/images/ea56c74d-a55d-4183-9a7b-d697954c5159-tonari-frontier-2.png.optimized.webp" type="image/webp"><source srcset="https://blog.tonari.no/images/ea56c74d-a55d-4183-9a7b-d697954c5159-tonari-frontier-2.png.optimized.jpg"><img src="https://blog.tonari.no/images/ea56c74d-a55d-4183-9a7b-d697954c5159-tonari-frontier-2.png.optimized.jpg"></picture></div><p>Since launching <a href="https://blog.tonari.no/changing-communication-and-culture-in-an-organization" rel="noopener" target="_blank">our first pilot</a> in February, we've experienced no software-related downtime (tripping over ethernet cables is a different story). A<m>nd as much as we would love to think we're infallible engineers, we truly don't believe we could have achieved these numbers with this level of stability without Rust.</m></p><a href="#in-the-beginning-(or-why-we're-not-webrtc)" id="in-the-beginning-(or-why-we're-not-webrtc)"><h2>In the beginning (or: why we're not WebRTC)</h2></a><p>The <m>very</m> first tonari proof-of-concept used a basic projector, bluetooth speakers, and a website running on top of vanilla WebRTC (JavaScript). We've come a long way since those days.</p><p>While that prototype (and our opinionated vision of the future) got us grant funding, we knew that tonari would be dead on arrival unless we could<m> achieve </m><i>significantly</i> lower latency and higher fidelity than <m>WebRTC</m>—two things that aren't currently associated with video chat in 2020.</p><p>We figured, “Okay<i>, so we can just </i><m><i>modify</i></m><i> WebRTC directly and wrap it up with a slick UI in C++ and launch it in no time</i>.”</p><p>A week of struggling with WebRTC’s nearly 750,000 LoC <i>behemoth</i> of a codebase revealed just how painful a single small change could be — how hard it was to test, and feel truly <i>safe,</i> with the code you were dealing with.</p><a href="#let-there-be-light...weight-code" id="let-there-be-light...weight-code"><h3>Let there be light...weight code</h3></a><p>So in a furious (read: calm and thoroughly-discussed) rage quit we decided it was easier to re-implement the whole stack from scratch. We wanted to <i>know and understand every line of code</i> being run on our hardware, and it should be designed for the <i>exact</i> hardware we wanted.</p><p>Thus began our journey to the depths beyond high-level interfaces like a browser or existing RTC project, and into the world of low-level systems and hardware interaction from scratch.</p><p>We needed it to <m>be inherently </m><b><m><i>secure</i></m></b><m> to </m>protect the privacy of those who use tonari.  We needed it to be <b><i>performant</i></b> to make it feel as human and real-time as possible.  And we needed it to be <b><i>maintainable</i></b> as the code becomes more mature, as new brains show up and have to learn our work and expand on it.</p><p><m>We discussed and ruled out a handful of alternative approaches:</m></p><ul><li><b><i>Security: </i></b>C and C++ are memory- and concurrency-unsafe, and their disparate and seemingly infinite build systems make it hard to have a consistent and simple development experience.</li><li><i><b>Performance: </b></i>Java, <m>C#, and Go'</m>s memory management is opaque and can be difficult to work with in latency-sensitive applications where you want full control over your memory.</li><li><i><b>Maintainability: </b></i>Haskell, Nim, D, and a handful of other more bespoke languages tend to be more limited in tooling, community, and hire-ability.</li></ul><p>Rust is really the only production-ready language that we found confidently satisfies these needs.</p><a href="#finding-beauty-in-rust" id="finding-beauty-in-rust"><h2>Finding beauty in Rust</h2></a><p>Rust's beauty lies in the countless decisions made by the development community that constantly make you feel like you <m>can have</m> ten cakes and eat all of them too.</p><ul><li>Its build system is opinionated, and cleanly designed. It is itself a complete ecosystem that makes introducing new engineers to your project and setting up dev environments remarkably simple.</li><li>The memory and concurrency safety guarantees cannot be over-appreciated. We're confident that we wouldn't have done our first deployment yet if we had continued this in C++ - we'd still probably be stuck on subtle snags.</li><li>Our ability to interact at the lowest level with hardware via APIs like CUDA, oftentimes through existing <a href="https://crates.io/" rel="noopener" target="_blank"><m>crates</m></a> (Rust's term for a code library), has allowed us to have higher standards about the latency we want from our first production release.</li></ul><p>As tonari is getting more advanced, we're now choosing embedded microcontrollers whose firmware can be written in Rust so we don't have to leave our idyllic utopia into the old world of unsafe system programming.</p><a href="#crates-we-rely-on" id="crates-we-rely-on"><h2>Crates we rely on</h2></a><p>We're not going to <code>cat Cargo.toml</code> here, instead focusing on some select crates that have earned the prestigious award of a lifetime invitation to each of our birthday parties forever.</p><a href="#&quot;better-than-std&quot;-crates" id="&quot;better-than-std&quot;-crates"><h3>"Better-than-std" crates</h3></a><ul><li><a href="https://github.com/crossbeam-rs/crossbeam" rel="noopener" target="_blank"><code>crossbeam</code></a> is better for inter-thread communication than <code>std::sync::mpsc</code> in almost every way, and may be merged into <code>std</code> eventually.</li><li><a href="https://github.com/Amanieu/parking_lot" rel="noopener" target="_blank"><code>parking_lot</code></a> has a mutex implementation better than <code>std::sync::Mutex</code> in almost every way, and may be merged into the standard library (one day). It also provides many other useful synchronization primitives.</li><li><a href="https://github.com/tokio-rs/bytes" rel="noopener" target="_blank"><code>bytes</code></a> is a more robust, and often more performant, way to play with bytes compared to <code>Vec&lt;u8&gt;</code>.</li><li><a href="https://github.com/alexcrichton/socket2-rs" rel="noopener" target="_blank"><code>socket2</code></a> is what you will end up at if you are ever doing lower-level networking optimizations.</li></ul><a href="#beauty-supply" id="beauty-supply"><h3>Beauty supply</h3></a><ul><li><a href="https://github.com/daboross/fern" rel="noopener" target="_blank"><code>fern</code></a> is a dead-simple way to customize and prettify your logging output. We use it to keep our logs readable and internally standardized.</li><li><a href="https://github.com/TeXitoi/structopt" rel="noopener" target="_blank"><code>structopt</code></a> is how you always dreamed CLI arguments would be handled. There's no reason not to use it unless you're going for bare-minimum dependencies.</li></ul><a href="#cargo-cult-classics" id="cargo-cult-classics"><h3>Cargo cult classics</h3></a><ul><li><a href="https://github.com/sunng87/cargo-release" rel="noopener" target="_blank"><code>cargo-release</code></a> allows us to cut internal releases painlessly.</li><li><a href="https://github.com/est31/cargo-udeps" rel="noopener" target="_blank"><code>cargo-udeps</code></a> identifies unused dependencies and allows us to keep our build times minimal.</li><li><code>cargo tree</code> (recently integrated in cargo) shows a dependency tree that's useful in many ways, but <m>mainly</m> in identifying ways to minimize dependencies.</li><li><a href="https://github.com/rust-secure-code/cargo-geiger" rel="noopener" target="_blank"><code>cargo-geiger</code></a> helps us quickly evaluate external dependencies for possible security (or correctness) concerns.</li><li><a href="https://github.com/flamegraph-rs/flamegraph" rel="noopener" target="_blank"><code>cargo-flamegraph</code></a> helps us enormously when tracking down performance hot-spots in our code.</li></ul><a href="#project-structure" id="project-structure"><h2>Project structure</h2></a><p>The tonari codebase is a monorepo. At its root we have a Cargo workspace with a <code>binaries</code> crate, and a number of supporting library crates.</p><p>Having our crates in one repo makes them easy to reference in our <code>binaries</code> crate without needing to publish to <a href="https://crates.io/" rel="noopener" target="_blank">crates.io</a> or get too fancy with specifying git dependencies in our <code>Cargo.toml</code>. When the time comes to publish these libraries as open source, it's trivial to break it out into its own repo.</p><a href="#library,-binary,-why-not-both" id="library,-binary,-why-not-both"><h3>Library, binary, why not both?</h3></a><p>We have one main library crate that contains a unified API for talking to hardware, media codecs, network protocols, etc. Outside of that private API, we also have standalone crates in our workspace that we consider candidates for open-sourcing. For example, we’ve written our own actor framework fit for long-running high-throughput actors, as well as our own network protocol for reliable, high-bandwidth, low-latency media streaming.

We use separate binaries for different parts of the tonari system and each of these lives in <code>binaries</code>, a combination library/binary crate. Its library modules contains a set of reusable actors that combine our private API with our actor system, and then a collection of individual binaries that consume these actors and define the plumbing between them.</p><a href="#flags-as-far-as-the-eye-can-see" id="flags-as-far-as-the-eye-can-see"><h3>Flags as far as the eye can see</h3></a><p>We make extensive use of feature flags to allow development of our project on different OSes (like Brian's 1970s-era MacBook Pro) or different hardware configurations. This allows us to easily swap out camera hardware without extra runtime checks or using awful <code>sed</code> hacks.

For example, Linux uses <code>v4l2</code> (Video For Linux...2) to access most webcams, but other webcams might have their own SDK.  To compile for platforms that don't use <code>v4l2</code> or when an SDK isn't available for a particular OS, we can put those SDKs behind feature flags and export a common interface.

As a (simplified) concrete example, let's say we have a common camera interface defined as a trait:</p><pre><code><span>pub</span> <span>trait</span> Capture <span>{</span>
    
    <span>fn</span> <span>capture</span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span><span>)</span> <span>-&gt;</span> Vec<span>&lt;</span>u8<span>&gt;</span><span>;</span>
<span>}</span></code></pre><p>Let's also say we have three different camera interfaces - <code>v4l2</code>, <code>corevideo</code>, and <code>polaroid.</code> We can make our binaries work exclusively with this trait to be flexible, and we can swap in different implementations of <code>Capture</code> with feature flags.</p><pre><code><span>#[cfg(feature = "v4l2")]</span>
<span>mod</span> v4l2 <span>{</span>
    <span>pub</span> <span>struct</span> V4l2Capture <span>{</span>
        <span>...</span>
    <span>}</span>

    <span>impl</span> Capture <span>for</span> V4l2Capture <span>{</span>
        <span>fn</span> <span>capture</span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span><span>)</span> <span>-&gt;</span> Vec<span>&lt;</span>u8<span>&gt;</span> <span>{</span>
            <span>...</span>
        <span>}</span>
    <span>}</span>
<span>}</span>

<span>#[cfg(feature = "corevideo")]</span>
<span>mod</span> corevideo <span>{</span>
    <span>pub</span> <span>struct</span> CoreVideoCapture <span>{</span>
        <span>...</span>
    <span>}</span>

    <span>impl</span> Capture <span>for</span> CoreVideoCapture <span>{</span>
        <span>fn</span> <span>capture</span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span><span>)</span> <span>-&gt;</span> Vec<span>&lt;</span>u8<span>&gt;</span> <span>{</span>
            <span>...</span>
        <span>}</span>
    <span>}</span>
<span>}</span>

<span>#[cfg(feature = "polaroid")]</span>
<span>mod</span> polaroid <span>{</span>
    <span>pub</span> <span>struct</span> PolaroidCapture <span>{</span>
        <span>...</span>
    <span>}</span>

    <span>impl</span> Capture <span>for</span> PolaroidCapture <span>{</span>
        <span>fn</span> <span>capture</span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span><span>)</span> <span>-&gt;</span> Vec<span>&lt;</span>u8<span>&gt;</span> <span>{</span>
            <span>...</span>
        <span>}</span>
    <span>}</span>
<span>}</span>

<span>#[cfg(feature = "v4l2")]</span>
<span>pub</span> <span>type</span> VideoCapture <span>=</span> v4l2<span>::</span>V4l2Capture<span>;</span>

<span>#[cfg(feature = "corevideo")]</span>
<span>pub</span> <span>type</span> VideoCapture <span>=</span> corevideo<span>::</span>CoreVideoCapture<span>;</span>

<span>#[cfg(feature = "polaroid")]</span>
<span>pub</span> <span>type</span> VideoCapture <span>=</span> polaroid<span>::</span>PolaroidCapture<span>;</span></code></pre><p>If we make our code work with things which implement the <code>Capture</code> trait instead of concrete types, we can now compile on and target various platforms by simply toggling feature flags. For example, we can have a struct which has a field - <code>video_capture: Box&lt;dyn Capture&gt;</code> which will let us store any type which can <code>Capture</code> from a camera.

An example <code>Cargo.toml</code> file to support the capture implementations we wrote above might look something like …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.tonari.no/why-we-love-rust?ref=twtr">https://blog.tonari.no/why-we-love-rust?ref=twtr</a></em></p>]]>
            </description>
            <link>https://blog.tonari.no/why-we-love-rust?ref=twtr</link>
            <guid isPermaLink="false">hacker-news-small-sites-23649534</guid>
            <pubDate>Fri, 26 Jun 2020 07:12:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Promote Imperfect People]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23647901">thread link</a>) | @svmanager
<br/>
June 25, 2020 | https://staysaasy.com/management/2020/06/23/Promote-Imperfect-People.html | <a href="https://web.archive.org/web/*/https://staysaasy.com/management/2020/06/23/Promote-Imperfect-People.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>You’ve likely experienced it: “You’re above and beyond everything we’re asking. There’s no promotion this round but all you need to do is <strong>__</strong>_”. Insert a semi-important but not absolutely necessary thing. Even worse if it’s something you’re really not good at.</p>

<p>One of the most demotivating things that an organization or manager can do is requiring “perfection” for a promotion. It’s a problem with two main dimensions:</p>
<ul>
  <li>It’s incommensurate with the value being added to the business.</li>
  <li>Perfection is subjective.</li>
</ul>

<h2 id="incommensurate-with-value-add">Incommensurate with Value-Add</h2>

<p>Ultimately all performance comes down to one thing: how much value are you adding to the business? Examples of where forcing perfection gets things out of whack:</p>
<ul>
  <li>I coded up a feature that brought in $10M to the business this year. I wasn’t promoted because they said I don’t speak enough in meetings.</li>
  <li>I saved the company from collapse because I was the only one who knew how to debug the system when it was melting. I wasn’t promoted because they said I show up too late every day.</li>
  <li>I identified a winning strategy for the entire business that drove us to another echelon of success. I wasn’t promoted because my design docs have typos.</li>
</ul>

<p>All that matters is the value being added to the business. There are nuances where behavior can set bad examples or cause issues for others, but that detracts from value added to the business and should be considered. The unfortunate and unbelievably common case is that some sort of benign missing strength is held against people.</p>

<h2 id="perfection-is-subjective">Perfection is Subjective</h2>

<p>When managers go down the rabbit whole of chasing perfect promotions they’re much more likely to be biased. In reality, most people’s internal picture of a perfect candidate for a promotion is something like “what did I look like when I got promoted?” That’s often the closest image a manager has of what a promotion at that level looks like.</p>

<p>In mild cases you get things like “when I got promoted I had to walk in the snow to work, uphill both ways.”</p>

<p>In more severe cases you get things like:</p>
<ul>
  <li>Men who don’t promote women because they’re not “aggressive enough” or they “don’t speak up enough”</li>
  <li>Extroverts who don’t promote introverts because they don’t like public speaking.</li>
  <li>Non-parents who don’t promote parents because they don’t work until midnight in the office.</li>
</ul>

<p>Promote people based on impact to the business, not their style of delivery.  Don’t hold people down because they deliver value in a way that isn’t comfortable, known, or practiced by you.</p>

<h2 id="conclusion">Conclusion</h2>

<p>In promotions and growth, focus more on amplifying strengths than fixing “weaknesses”.  You’ll find it’s much easier and much more fruitful to have people play to their strengths.</p>

<p>Promote imperfect people - that’s all you’ve got.</p>

    




  </div></div>]]>
            </description>
            <link>https://staysaasy.com/management/2020/06/23/Promote-Imperfect-People.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23647901</guid>
            <pubDate>Fri, 26 Jun 2020 01:46:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The War on Upstart Fiber Internet Providers]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23647609">thread link</a>) | @joecool1029
<br/>
June 25, 2020 | http://chrishacken.com/the-war-on-upstart-fiber-optic-internet-providers/ | <a href="https://web.archive.org/web/*/http://chrishacken.com/the-war-on-upstart-fiber-optic-internet-providers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>                                
                                    <div> 
                                        <p>As someone who grew up throughout the 90's and 00's, some of my fondest memories stem from progressive advancements in internet and computing technologies.  Upgrading from Dial-Up internet to DSL was a grand event in our house.  I remember my brother and I fighting over the computer day in and day out to play games like Wolfenstein - Enemy Territory, which was released in 2003. (I'm convinced that this will be the all-time best FPS game ever created.)  At around the same time, we upgraded to one of the best Dell computer's available at the time. It had 512MB of RAM and a Pentium 4 processor.  This was a major upgrade from our Compaq Celeron, which had something like 64MB of RAM. <br>
<img src="http://chrishacken.com/content/images/2020/03/MV5BOGFmNjMzZTktNDg2ZS00ZjllLTlkMTAtZTAzMzBkN2UyMzk2XkEyXkFqcGdeQXVyMjU3MzI1NzI@._V1_.jpg" alt="Wolfenstein - Enemy Territory"></p>

<p>Eventually, the grandeur of DSL faded as the rest of the world began to adopt Cable and Fiber internet.  It wasn't until I briefly moved to Philadelphia that I was finally able to experienced what I had been missing out on.  In college I lived in a neighborhood that was one of Verizon's first Fios builds.  I was absolutely blown away by the 25 Mbps connection.  This was in 2009. I'm amazed that over a decade later, in 2020, some households still don't have access to cable or fiber internet yet.</p>

<p>Like many of our customers do now, I could never figure out why it was so difficult to get us fiber service.  The cable is cheap, just throw it up on a pole and give me internet! Right?  Well, not so fast... <br>
<img src="http://chrishacken.com/content/images/2020/03/1849761.jpg" alt="Fiber Spaghetti"></p>

<p>A quick overview of how utility services are run and the challenges involved...</p>

<p>As most people know, there are primarily two ways to deliver utility services to a home or business.  Aerial and underground.  Water, gas, and sewer are always serviced underground for obvious reasons.  Electric, telephone, cable, and fiber have the ability to either be above or below ground.</p>

<h3 id="aerial">Aerial.</h3>

<p>As with anything else, aerial has pro's and con's.</p>

<p>The pro's are primarily upfront costs (this is debatable) and speed of deployment (this is also debatable).</p>

<p>The con's are that contrary to it being cheaper to physically deploy, the pole owners generally charge up-front make ready fee's.  These fees can range from $0 to upwards of $50,000/mile.  It's essentially pay to play.  If we want to attach to 50 poles, the pole owner might determine that 10 of those poles are old and need to be replaced before we can attach to them.  Rather than fork up the cash themselves, they'll force us to pay to replace their poles in order to approve the attachment.</p>

<p>In addition to that, there are the annual pole fee's.  Depending on your agreement, we've seen pole fee's ranging anywhere from $7/pole per year all the way up to $43/pole per year with 10% annual increases (I'm looking at you PPL.  This ridiculous rate was purely intended to keep us from attaching to their poles, IMO.  It's impossible to make money with these rates). <br>
<img src="http://chrishacken.com/content/images/2020/03/Screenshot-2020-03-10-22.04.34.png" alt="Pole Rates"></p>

<p>Another con is that even though installing the cable on poles is faster, it usually takes the pole owner around 6 months just to review applications and to determine make ready requirements and costs.  As an example, if we have fiber on a pole that's 1 pole short from being able to service your house, it would take at least 6 months just to run fiber to that one additional pole. So close, yet so far.</p>

<h3 id="underground">Underground.</h3>

<p>Like aerial, underground has its own list of pro's and con's.</p>

<p>When you install a service underground, you own it for life.  There are no annual fee's.  You pay one time to install it and you're set for life.  This sounds like a pro, but it's also a con.  When we run metro conduit, it generally costs us between $15-25/ft (not including customer drops).  For the sake of argument, let's assume we're at the high-end of our costs.  If we install 1,000ft of conduit, that's $25,000 that we need to pay out of pocket upfront.  Some blocks have upwards of 30 customers, but others have as little as 5.  Let's average it out at 20 customers per block, that's $1,250 upfront per customer, assuming we get every single customer.  Conservatively, we're initially looking at a 50% take rate.  This could grow to 100% overtime, but we never make that assumption. So that's $2,500/customer.  Imagine spending $2,500 per house/building and then have them tell you that your $69/m service is too expensive.  Generally speaking, we won't do a street unless our numbers look better than this, but this is a realistic scenario as we scale and get access to cheaper capital, etc.</p>

<p><img src="http://chrishacken.com/content/images/2020/03/enorthampton01.jpg" alt="Underground Construction">
<img src="http://chrishacken.com/content/images/2020/03/enorthampton02.jpg" alt="Underground Construction Restoration"></p>

<h3 id="politics">Politics</h3>

<p>Cost issues aside, there are a number of other hurdles one needs to get past just to begin the process of building out a network.  You'd think that risking everything you have in an effort to bring your local economy into the 21st Century would be a welcome sight.  That's what I thought too; was I wrong.  While there are plenty of supporters (I truly appreciate you all), there are just as many, if not more, critics.</p>

<p>We've been fortunate enough to have had a handful of people get behind us overtime and give us a shot.  I'm sure others haven't had it so easy.  I know this because even after we've become an established player in our city throughout the past 4 years, neighboring townships and municipalities haven't been as opened armed to welcome us into their communities as I had anticipated or would have liked.</p>

<p>I'll go into more detail on small government policies that really hamper our ability to deploy underground later below.</p>

<h3 id="toomanyopinions">Too Many Opinions</h3>

<p>I'm generally a big fan of individual citizens trying to make an impact in their communities.  However, in too many cases these contributions seem to be made in the form of unproductive complaints rather than productive feedback or action.  Far too many people have a say in things that they probably shouldn't.</p>

<p><strong><em>Case A.</em></strong></p>

<p>A new customer had recently signed an agreement with us to run fiber into their building.  This is a non-profit who's members are selflessly donating their time to restore a landmark in the community.  Upon receiving their signature, I notified the city that we would be pulling a permit to connect the building in question to our underground network.  They said okay; that was that.  Our nearest existing hand hole is approximately 90ft to the right of the new customer's property; in front of another property.  As a courtesy, I notified the manager of that establishment to let her know that we would be performing work over the weekend, from Friday into Saturday.  They're closed Saturday and Sunday so I had assumed they would appreciate the notice and possibly even sign up with us.  The project would involve removing 90ft of sidewalk, running conduit, and then restoring the sidewalk with brand spankin' new concrete.  The total timespan that this would occur, from when our shovel hit the ground to having new sidewalks in place, would be 48 hrs.  The response that I received from a member of their organization made me facepalm.</p>

<p><img src="http://chrishacken.com/content/images/2020/03/Screenshot-2020-03-10-18.53.55-copy.png" alt="Sidewalk Issues"></p>

<p>Not long after receiving this email, I became aware that they didn't even own the building in question, nevermind the sidewalk.  They lease it.  This was eventually "resolved" after a series of negotiations between the non-profit's president and the establishment in question.  Often times we aren't as lucky.</p>

<p>We initially planned to have this new customer installed within a week of them signing the contract.  Now it will end up being around 2 months from start to finish.  Long story short, I learned my lesson in trying to be courteous.</p>

<p><strong><em>Case B.</em></strong></p>

<p>Last year we were installing conduit for our fiber optic network.  There were countless instances where people would literally stop their cars, roll down their windows, and yell profanities at us.  In what world is that acceptable behavior for an adult? I can't imagine being so far off my rocker that I would feel the need to yell at a bunch of construction workers trying to build a fiber optic network (not that they had any idea what we were doing).  If these are the types of people influencing decisions, there's something wrong.</p>

<p>City workers have a tough job fielding complaints from people like this and I commend them for it.  It shouldn't affect policy though.</p>

<p><strong><em>Case C.</em></strong></p>

<p>In another incident that took place not long, maybe a day or two, after <em>Case B</em> above.  A local store owner came back to us as we're swinging pick axes in 95 degree heat telling us we need to hurry up and we should hire more workers.  "My customers keep calling saying there's no where to park."  Mind you, we're standing right next to a massive parking lot that is approximately 1/3rd full.  I made my best attempt to kindly explain that paying 3 guys to stand around a hole to watch one person hand-dig to expose a utility isn't going to make our work go any faster.  I don't think he liked my response.</p>

<h3 id="theconsequences">The Consequences</h3>

<p>In many cases, resident complaints are justified.  Utility providers need to be held accountable for shitty restoration work.  However, the way in which bad restoration work is being combated is counter productive.  There has been a huge increase in curb-to-curb restoration requirements by local governments.  Essentially what these rules state is that anytime a utility cuts asphalt beyond a predetermined length, say 100ft, they are then responsible for replacing the entire road surface from the curb on the left side of the street to the curb on the right side of the street.  I believe some municipalities are also trying to introduce these measures to offload the costs of repaving roads themselves, similar to how pole owners force you to replace their aging utility poles under their make-ready requirements.  (One municipality told me as much when I attended a local council meeting in an effort to get them to waive this ridiculous ordinance for us.)</p>

<p>These policies will ultimately do more harm than good.  For us, these are the one and only thing preventing us from providing superior fiber internet services in these areas.  Forcing curb-to-curb asphalt …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://chrishacken.com/the-war-on-upstart-fiber-optic-internet-providers/">http://chrishacken.com/the-war-on-upstart-fiber-optic-internet-providers/</a></em></p>]]>
            </description>
            <link>http://chrishacken.com/the-war-on-upstart-fiber-optic-internet-providers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23647609</guid>
            <pubDate>Fri, 26 Jun 2020 00:55:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Santa Cruz bans predictive policing]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23647504">thread link</a>) | @wturner
<br/>
June 25, 2020 | https://www.santacruzworks.org/news/santa-cruz-is-the-first-city-to-city-ban-predictive-policing | <a href="https://web.archive.org/web/*/https://www.santacruzworks.org/news/santa-cruz-is-the-first-city-to-city-ban-predictive-policing">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-01f39fcbb7868f9a53a1"><div><div><p>As officials mull steps to tackle police brutality and racism, California’s Santa Cruz has become the first&nbsp;U.S. city to ban predictive policing, which digital rights experts said could spark similar moves across the&nbsp;country.&nbsp;</p><p>“Understanding how predictive policing and facial recognition can be disportionately biased against&nbsp;people of color, we officially banned the use of these technologies in the city of Santa Cruz,” Mayor&nbsp;Justin Cummings said on Wednesday.&nbsp;</p><p>His administration will work with the police to “help eliminate racism in policing”, the seaside city’s first&nbsp;male African-American mayor said on his Facebook page, following a vote on Tuesday evening.&nbsp;</p><p>Used by police across the United States for almost a decade, predictive policing relies on algorithms to&nbsp;interpret police records, analyzing arrest or parole data to send officers to target chronic offenders, or&nbsp;identifying places where crime may occur.&nbsp;</p><p>But critics says it reinforces racist patterns of policing - low-income, ethnic minority neighbourhoods&nbsp;have historically been overpoliced so the data shows them as crime hotspots, leading to the deployment&nbsp;of more police to those areas.&nbsp;</p><p>“As Santa Cruz rightly recognized, predictive policing and facial recognition are dangerous, racially&nbsp;biased technologies that should never be used by our government,” said Matt Cagle, a lawyer with the&nbsp;ACLU.</p></div><p>PredPol Inc, the Santa Cruz-headquartered firm that pioneered the technology, said that it supported the city resolution’s requirement that predictive policing “will not perpetuate bias”, among other criteria. </p><p>  “Given the institutionalized state of racial inequality in America, this is a legitimate filter to be applied to any new technology acquired by a public entity, whether used for public safety or not,” it said on Twitter on Tuesday.   </p><p>Boston’s city council on Wednesday voted to ban face surveillance technology, a move also welcomed by digital rights activists.</p><p>Continue reading <a href="https://www.reuters.com/article/us-usa-police-tech-trfn/california-city-bans-predictive-policing-in-u-s-first-idUSKBN23V2XC">here</a></p></div></div></div>]]>
            </description>
            <link>https://www.santacruzworks.org/news/santa-cruz-is-the-first-city-to-city-ban-predictive-policing</link>
            <guid isPermaLink="false">hacker-news-small-sites-23647504</guid>
            <pubDate>Fri, 26 Jun 2020 00:39:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Draft of my perf book is ready – Easyperf]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 3 (<a href="https://news.ycombinator.com/item?id=23647025">thread link</a>) | @todsacerdoti
<br/>
June 25, 2020 | https://easyperf.net/blog/2020/06/24/Draft-Of-Perf-Book | <a href="https://web.archive.org/web/*/https://easyperf.net/blog/2020/06/24/Draft-Of-Perf-Book">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<hr>
<p><strong>Subscribe to my <a href="https://easyperf.net/blog/2020/06/24/Draft-Of-Perf-Book#mc_embed_signup">mailing list</a> and support me on <a href="https://www.patreon.com/dendibakh">Patreon</a>.</strong></p>

<hr>

<p><strong>It has been a long journey!</strong> I was silent for a while, haven’t posted regularly on my blog. But don’t worry, I’m fine. Instead, I took this situation around coronavirus and focused on writing a book “<em>Performance Analysis and Tuning on Modern CPU</em>”. I started writing this book almost a year ago, so I’m happy I finally can show something to the people. Right now, the <strong>early draft is ready and I’m welcoming everybody to review the book and maybe even add something to it</strong>. I know a lot of people are struggling right now, so I decided to make the book <strong>FREE</strong> for all. Eventually, everyone will be able to download PDF version of it.</p>

<p><strong>Why I started it?</strong> I started this book with one simple goal in mind: educate developers to better understand performance of their applications running on modern HW. Most of developers are used to look no further than the source code of their application without trying to understand performance implications of the changes they make. I know for many of us what happens under the hood is sort of black matter. I know it’s hard, but hopefully with this book, performance world of modern HW will become more accessible.</p>

<p><strong>What is the book about?</strong> Have you ever debated with a coworker about performance of a certain piece of code? Then you probably know how hard it is to predict which version is going to work best. With so many moving parts inside the modern processors even a small tweak to the code can trigger significant performance change. Besides all its complexity, HW has many features that support performance analysis. That’s right, CPUs are capable of telling us what performance bottlenecks are and where they occur. Thus, the book focuses on how your code looks like from the CPU perspective and provides recipes for HW specific optimizations. The core of the book is centered around how to find the right place in the code to improve performance.</p>

<p>Below I present the sweetest parts of the book contents:</p>
<div><div><pre><code>1. Introduction
2. Measuring Performance
3. CPU Microarchitecture 101
4. Terminology And Metrics In Performance Analysis
5. Performance Analysis Approaches
  5.1. Code Instrumentation
  5.2. Tracing
  5.3. Workload Characterization
  5.4. Sampling
  5.5. Static Performance Analysis
  5.6. Compiler Optimization Reports
6. CPU Features For Performance Analysis
  6.1. Top-Down Microarchitecture Analysis (TMAM)
  6.2. Last Branch Record (LBR)
  6.3. Processor Event-Based Sampling (PEBS)
  6.4. Intel Processor Traces (PT)
7. Source Code Tuning For CPU
  7.1. Data-Driven Optimizations
  7.2. CPU Front-End Optimizations
  7.3. CPU Back-End Optimizations
  7.4. Optimizing Bad Speculation
  7.5. Other Tuning Areas
8. Optimizing Multithreaded Applications
</code></pre></div></div>

<p><strong>Who is this book for?</strong> Primarily, this book is written for developers working in performance critical projects. This includes the following areas: High performance computing (HPC), High Frequency Trading (HFT), GameDev, Data Centers (Facebook, Google, etc), and other areas. But I hope it will be useful for any C++ developer: you can use this book to learn performance analysis which will stack up nicely with other skills you might have. All examples in the book are written in C/C++, but to the large extent they are applicable to any native programming language (like C, C++, Rust, Go and even Fortran). While this book is fairly low-level, I hope, it will be accessible even to developers that are just starting performance related work.</p>

<p>I gave this book all my knowledge and experience and I’m eager to share it with community. I decided to make this book open to everyone and <strong>I welcome everyone to review and contribute to the book</strong>. I hope, this way we can combine best performance practices and expertise from people in different areas.</p>

<p><strong>Shoot me an email or leave a comment if you are interested.</strong></p>


			</div></div>]]>
            </description>
            <link>https://easyperf.net/blog/2020/06/24/Draft-Of-Perf-Book</link>
            <guid isPermaLink="false">hacker-news-small-sites-23647025</guid>
            <pubDate>Thu, 25 Jun 2020 23:35:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Use ProxyJump with SSH for VMs with No Public IPs]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23646848">thread link</a>) | @rbekker87
<br/>
June 25, 2020 | https://blog.ruanbekker.com/blog/2020/06/13/using-proxyjump-with-ssh-for-vms-with-no-public-ips/ | <a href="https://web.archive.org/web/*/https://blog.ruanbekker.com/blog/2020/06/13/using-proxyjump-with-ssh-for-vms-with-no-public-ips/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://img.sysadmins.co.za/wngib2.png" alt="ssh-proxy-jump"></p>

<p>I have a dedicated server with LXD installed where I have a bunch of system containers running to host a lot of my playground services, and to access the operating system of those lxc containers, I need to SSH to the LXD host, then exec or ssh into that LXC container.</p>

<p>This became tedious and wanted a way to directly ssh to them, as they don’t have public ip addresses, it’s not possible but found its possible to access them using proxyjump.</p>

<figure><div><table><tbody><tr><td><pre><span>1</span>
</pre></td><td><pre><code><span>[you] -&gt; [hypervisor] -&gt; [vm on hypervisor]</span></code></pre></td></tr></tbody></table></div></figure>


<p>First step is to create our ssh key:</p>

<figure><div><table><tbody><tr><td><pre><span>1</span>
</pre></td><td><pre><code><span>$ ssh-keygen -t rsa</span></code></pre></td></tr></tbody></table></div></figure>


<p>Add the created public key (<code>~/.ssh/id_rsa.pub</code>) on the hypervisor and the target vm’s <code>~/.ssh/authorized_key</code> files.</p>

<p>Then create the SSH Config on your local workstation (<code>~/.ssh/config</code>):</p>

<figure><div><table><tbody><tr><td><pre><span>1</span>
<span>2</span>
<span>3</span>
<span>4</span>
<span>5</span>
<span>6</span>
<span>7</span>
<span>8</span>
<span>9</span>
<span>10</span>
<span>11</span>
<span>12</span>
<span>13</span>
<span>14</span>
</pre></td><td><pre><code><span>Host *
</span><span>  StrictHostKeyChecking no
</span><span>  UserKnownHostsFile=/dev/null
</span><span>
</span><span>Host hypervisor
</span><span>  Hostname hv.domain.com
</span><span>  User myuser
</span><span>  IdentityFile ~/.ssh/id_rsa
</span><span>
</span><span>Host ctr1
</span><span>  Hostname 10.37.117.132
</span><span>  User root
</span><span>  IdentityFile ~/.ssh/id_rsa
</span><span>  ProxyJump hypervisor</span></code></pre></td></tr></tbody></table></div></figure>


<p>Now accessing our lxc container ctr1, is possible by doing:</p>

<figure><div><table><tbody><tr><td><pre><span>1</span>
<span>2</span>
<span>3</span>
<span>4</span>
</pre></td><td><pre><code><span>$ ssh ctr1
</span><span>Warning: Permanently added 'x,x' (ECDSA) to the list of known hosts.
</span><span>Warning: Permanently added '10.37.117.132' (ECDSA) to the list of known hosts.
</span><span>root@ctr1~ $</span></code></pre></td></tr></tbody></table></div></figure>

</div></div>]]>
            </description>
            <link>https://blog.ruanbekker.com/blog/2020/06/13/using-proxyjump-with-ssh-for-vms-with-no-public-ips/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23646848</guid>
            <pubDate>Thu, 25 Jun 2020 23:11:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Data Integrity Protection in Presto]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23646838">thread link</a>) | @findepi
<br/>
June 25, 2020 | https://prestosql.io/blog/2020/06/25/data-integrity-protection.html | <a href="https://web.archive.org/web/*/https://prestosql.io/blog/2020/06/25/data-integrity-protection.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>It all started on an Thursday afternoon in March, when <a href="https://github.com/sopel39">Karol Sobczak</a>
was grilling Presto with heavy rounds of benchmarks, as we were ramping up to Starburst Enterprise
Presto 332-e release. Karol discovered what seemed to be a serious regression, and turned out to be even more
serious Cloud environment issue.</p>

<!--more-->



<p>At the Presto project, we take serious care of stability and efficiency, so releases undergo
rigorous performance benchmarks. The intention is to safe guard against any performance regressions
or stability problems. Usually, the performance improvements are benchmarked separately when they
are being added to the codebase. At Starburst, those benchmarks are even more important, especially
for the Starburst Enterprise Presto LTS releases.</p>

<p>On a side note, we use <a href="https://github.com/prestosql/benchto/">Benchto</a> for organizing
<a href="https://github.com/prestosql/presto/tree/master/presto-benchto-benchmarks">Presto benchmark suites</a>,
executing them and collecting the results. We use managed <a href="https://kubernetes.io/">Kubernetes</a> in a public
cloud for provisioning Presto clusters, along with <a href="https://www.starburstdata.com/presto-on-kubernetes/">Starburst Enterprise Presto Kubernetes</a>.
We use <a href="https://jupyter.org/">Jupyter</a> for producing result reports in HTML and PDF formats.</p>



<p>It all started in March, when <a href="https://github.com/sopel39">Karol Sobczak</a>
was grilling Presto with heavy rounds of benchmarks for the Starburst Enterprise Presto 332-e release.
On one Thursday afternoon he reported stability problems, with few benchmark runs failing with
exceptions similar to:</p>

<div><div><pre><code>Query failed (#20200326_150852_00338_dj225): Unknown block encoding:
LONG_ARRAY� � �� � @@@���� �@  @ � �@@@ @@� @�@D�� @@��@ `� @@� @#�@ � 0�
... (9550 more bytes)
</code></pre></div></div>

<p>In Presto, a block encoding is a way of encoding a particular Block type (here, a <code>LongArrayBlock</code>).
They are used when exchanging blocks of data between Presto nodes, or in spill to disk.
Blocks form a polymorphic class hierarchy, so every time a block is encoded, we need
to also store the encoding identifier. The encoding identifier (here, the <code>LONG_ARRAY</code> string)
is written as <code>&lt;string length&gt;</code> (4-byte, signed integer in little-endian) followed by
<code>&lt;string bytes&gt;</code> containing the UTF-8 representation of the encoding id. Clearly, in the case above,
the receiver read the <code>&lt;encoding id length&gt;</code> as 9623 instead of 10! How could that be ever possible?</p>

<p>Presto 332 brought a lot of good changes and upgrade to Java 11 was one of them.
Therefore, Starburst Enterprise Presto 332-e was the first Starburst release using Java 11 by default.
For earlier releases, we ran benchmarks using AWS EC2 machines orchestrated with <a href="https://www.starburstdata.com/presto-aws-cloud/">Starburst’s Presto
CloudFormation Template (CFT)</a>. This was also the first time we did
Presto release benchmarks running on Kubernetes clusters, with AWS EKS. We could suspect many different factors
as being the cause. We started to sift through the code, search team’s “collective brain” and
the Internet for any ideas. One of the important sources was Vijay Pandurangan’s writeup on <a href="https://tech.vijayp.ca/linux-kernel-bug-delivers-corrupt-tcp-ip-data-to-mesos-kubernetes-docker-containers-4986f88f7a19">data
corruption bug discovered by Twitter in 2015</a>. Of course, we also repeated benchmark runs. Seeing is believing.</p>



<p>On the next day, a customer reported similar problems with their Presto cluster. Of course, they
were not running a yet-to-be-released version that we were still benchmarking. They run into what seemed to
be a very serious regression in a Starburst Enterprise Presto 323-e release line. The customer was also using
the AWS cloud, but not the Kubernetes deployment. They were using <a href="https://www.starburstdata.com/presto-aws-cloud/">CFT-based deployment</a>
– the same stack we were using for all our release benchmarks so far – and we had never run into issues like this before.
As the customer was using a fresh-off-press latest minor release, we decided (in spirit of global health care trend)
to “quarantine” that release and roll back the customer installation to the previous version.</p>

<p>However, the fact that a small bug fix release triggered data problems was unnerving. The fact that we
did not discover any of these problems before, was even more unnerving.</p>



<p>As we were running more and more, and even more test runs, we discovered new failure modes.
For example:</p>
<div><div><pre><code>Query failed (#20200327_001931_00020_8di4r): Cannot cast DECIMAL(7, 2) '18734974449861284.67' to DECIMAL(12, 2)
</code></pre></div></div>
<p>Well, this message is not <em>wrong</em>. It’s not possible to cast <code>18734974449861284.67</code> to <code>DECIMAL(12, 2)</code>.
Except that it is <em>also</em> not possible to have a <code>DECIMAL(7, 2)</code> with such value. Something wrong happened to the
data. At that moment, we realized the problem was very serious, because data could become corrupted.
This corrupted data could lead to a failure (like above), but it could also lead to incorrect query results,
or incorrect data being persisted (in case of <code>INSERT</code> or <code>CREATE TABLE AS</code> queries). We created
a virtual War Room (that is, a Slack channel), got together all Presto experts and our experienced field team
to discuss potential causes, further diagnostics and mitigation strategies.</p>

<p>Since the problem was affecting data exchanges between Presto nodes, we listed the following strategies
to try to dissect the problem:</p>

<ul>
  <li>determining which query (queries) is (are) causing failures,</li>
  <li>running with HTTP/2,</li>
  <li>reverting to running on Java 8,</li>
  <li>enabling exchange compression (as decompression is very sensitive to data corruption),</li>
  <li>trying to upgrade Jetty,</li>
  <li>determining whether failures correlate with JVM GC activity,</li>
  <li>inspecting the source code.</li>
</ul>



<p>We were able to quickly prototype and verify some of the ideas. Switching to HTTP/2 or
upgrading Jetty to the latest version did not help. Nor did downgrading to Jetty version
that had been using for a long time. We also verified that problem was reproducible with Java 8,
so we concluded Java 11 was not the cause of it.</p>



<p>We identified the problem occurs somewhere within exchanges, between one Presto worker
node serializing a <code>Page</code> object (basic unit of data processing in Presto) and another node
deserializing it.</p>

<p>While decimal cast failure didn’t directly point at the data corruption problem (there could
be many other reasons for it), there was no other explanation for the <code>Unknown block encoding</code> exceptions.
The serialization is done in <code>PagesSerde.serialize</code> (used by <code>TaskOutputOperator</code>, the data sender) and
deserialization is done in <code>PagesSerde.deserialize</code> (used by <code>ExchangeOperator</code>, the
receiver of the data). As the logic is nicely encapsulated in <code>PagesSerde</code> class, we
added checksums to the serialized data: <code>&lt;checksum&gt; &lt;serialized page&gt;</code>.
This felt like a smart move – except that it gave us nothing more than a confirmation that
there is a problem (“checksum failure”).
This we already knew.</p>

<p>We considered adding logging to capture data going out from one node and going in on
another node, but that would be huge amount of logs. One run of benchmarks transfers
hundreds of terabytes of data between the nodes.</p>

<p>We went ahead and created a Presto build that added data redundancy to be able to reconstruct
the data on the receiving side.
There are many <a href="https://en.wikipedia.org/wiki/Erasure_code">well-known error-correction codes</a>
(e.g. <a href="https://en.wikipedia.org/wiki/Reed%E2%80%93Solomon_error_correction">Reed–Solomon error correction</a>
available in Hadoop 3). In our case, speed of <em>implementation</em> (a.k.a. simplicity) was a deciding factor,
so we added data mirroring: <code>&lt;checksum&gt; &lt;serialized page&gt; &lt;serialized page&gt;</code>.
In order to avoid logging of all the data exchanges, we added the deserialized pages (both copies)
to the exceptions being raised.</p>

<div><div><pre><code>java.sql.SQLException: Query failed (#20200401_113622_00676_p7qp7): Hash mismatch, read: 1251072184702746109, calculated: 7591448164918409110
    Suppressed: java.lang.RuntimeException: Slice, first half: 040000000A0000004C4F4E475F415252.... (945 kilobytes)
    Suppressed: java.lang.RuntimeException: Slice, secnd half: 040000000A0000004C4F4E475F415252.... (945 kilobytes)
</code></pre></div></div>

<p>The exception told us the first part was changed, since read checksum did not match the calculated
checksum (it was calculated based on the first copy of the data and was different than the checksum
calculated on the sending side).
Having the encoded data in the exception like that, it was easy to extract the actual data and compare,
so now we could see <em>how</em> the data was changed.</p>

<div><div><pre><code>cat failure.txt | grep 'Slice, first half' | cut -d: -f4- | sed 's/^ *//' | xxd -r -p &gt; changed
cat failure.txt | grep 'Slice, secnd half' | cut -d: -f4- | sed 's/^ *//' | xxd -r -p &gt; original
</code></pre></div></div>

<p>Comparing binary files is fun, but in practice it can be more convenient to compare <code>hexdump</code> output.
The output below was created with <code>vimdiff &lt;(hexdump -Cv original) &lt;(hexdump -Cv changed)</code>.</p>
<div><div><pre><code>++--6064 lines: 00000000  04 00 00 00 0a 00 00 00  4c 4f 4...|+ +--6064 lines: 00000000  04 00 00 00 0a 00 00...
 00017b00  00 cb 6a 25 00 00 00 00  00 cb 6a 25 00 00 00 00  |  00 cb 6a 25 00 00 00 00  00 cb 6a 25 00 00 00 00
 00017b10  00 cb 6a 25 00 00 00 00  00 cb 6a 25 00 00 00 00  |  00 cb 6a 25 00 00 00 00  00 cb 6a 25 00 00 00 00
 00017b20  00 cb 6a 25 00 00 00 00  00 e1 67 25 00 00 00 00  |  00 cb 6a 25 00 00 00 00  00 e1 67 25 00 00 00 00
 00017b30  00 e1 67 25 00 00 00 00  00 e1 67 25 00 00 00 00  |  00 e1 67 25 00 00 00 00  00 e1 67 25 00 00 00 00
 00017b40  00 e1 67 25 00 00 00 00  00 e1 67 25 00 00 00 00  |  00 e1 67 25 00 00 00 00  00 e1 67 25 00 00 00 00
 00017b50  00 e1 67 25 00 00 00 00  00 e1 67 25 00 00 00 00  |  00 e1 67 25 00 00 00 00  00 e1 67 25 00 00 00 00
 00017b60  00 e1 67 25 00 00 00 00  00 e1 67 25 00 00 00 00  |  00 e1 67 25 00 00 00 00  e1 67 25 00 00 00 00 00
 00017b70  00 e1 67 25 00 00 00 00  00 fb 69 25 00 00 00 00  |  e1 67 25 00 00 00 00 00  fb 69 25 00 00 00 00 00
 00017b80  00 fb 69 25 00 00 00 00  00 fb 69 25 00 00 00 00  |  fb 69 25 00 00 00 00 00  fb 69 25 00 00 00 00 00
 00017b90  00 fb 69 25 00 00 00 00  00 fb 69 25 00 00 00 00  |  fb 69 25 00 00 00 00 00  fb 69 25 00 00 00 00 00
 00017ba0  00 fb 69 25 00 00 00 00  00 fb 69 25 00 00 00 00  |  fb 69 25 00 00 00 00 00  fb 69 25 00 00 00 00 00
 00017bb0  00 fb 69 25 00 00 00 00  00 fb 69 25 00 00 00 00  |  fb 69 25 00 00 00 00 00  fb 69 25 00 00 00 00 00
 00017bc0  00 fb 69 25 00 00 00 00  00 fb 69 25 00 00 00 00  |  fb 69 25 00 00 00 00 00  fb 69 25 00 00 00 00 00
 00017bd0  00 fb 69 25 00 00 00 00  00 fb 69 25 00 00 00 00  |  fb 69 25 00 00 00 00 00  fb 69 25 00 …</code></pre></div></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://prestosql.io/blog/2020/06/25/data-integrity-protection.html">https://prestosql.io/blog/2020/06/25/data-integrity-protection.html</a></em></p>]]>
            </description>
            <link>https://prestosql.io/blog/2020/06/25/data-integrity-protection.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23646838</guid>
            <pubDate>Thu, 25 Jun 2020 23:11:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[3D human shape estimation from photo and video]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23646602">thread link</a>) | @interweb
<br/>
June 25, 2020 | https://shunsukesaito.github.io/PIFuHD/ | <a href="https://web.archive.org/web/*/https://shunsukesaito.github.io/PIFuHD/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://shunsukesaito.github.io/PIFuHD/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23646602</guid>
            <pubDate>Thu, 25 Jun 2020 22:42:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Foam, a personal knowledge management and sharing system for VSCode]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23646507">thread link</a>) | @radus
<br/>
June 25, 2020 | https://foambubble.github.io/foam/ | <a href="https://web.archive.org/web/*/https://foambubble.github.io/foam/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

      

<p><strong>Foam</strong> is a personal knowledge management and sharing system inspired by <a href="https://roamresearch.com/">Roam Research</a>, built on <a href="https://code.visualstudio.com/">Visual Studio Code</a> and <a href="https://github.com/">GitHub</a>.</p>

<p>You can use <strong>Foam</strong> for organising your research, keeping re-discoverable notes, writing long-form content and, optionally, publishing it to the web.</p>

<p><strong>Foam</strong> is free, open source, and extremely extensible to suit your personal workflow. You own the information you create with Foam, and you’re free to share it, and collaborate on it with anyone you want.</p>

<blockquote>
  <p><strong>In a rush?</strong> You <em>could</em> jump to <a href="#getting-started">Getting started</a>, but I highly recommend reading the introductory sections first. <strong>Foam</strong> isn’t obvious.</p>
</blockquote>

<h2 id="table-of-contents">Table of Contents</h2>

<ul>
  <li><a href="#foam">Foam</a>
    <ul>
      <li><a href="#table-of-contents">Table of Contents</a></li>
      <li><a href="#how-do-i-use-foam">How do I use Foam?</a></li>
      <li><a href="#whats-in-a-foam">What’s in a Foam?</a></li>
      <li><a href="#getting-started">Getting started</a></li>
      <li><a href="#features">Features</a></li>
      <li><a href="#call-to-adventure">Call To Adventure</a></li>
      <li><a href="#thanks-and-attribution">Thanks and attribution</a></li>
      <li><a href="#license">License</a></li>
    </ul>
  </li>
</ul>

<h2 id="how-do-i-use-foam">How do I use Foam?</h2>

<p><strong>Foam</strong> is a tool that supports creating relationships between thoughts and information to help you think better.</p>

<p><img src="https://foambubble.github.io/foam/assets/images/foam-navigation-demo.gif" alt="Short video of Foam in use"></p>

<p>Whether you want to build a <a href="https://www.buildingasecondbrain.com/">Second Brain</a> or a <a href="https://zettelkasten.de/posts/overview/">Zettelkasten</a>, write a book, or just get better at long-term learning, <strong>Foam</strong> can help you organise your thoughts if you follow these simple rules:</p>

<ol>
  <li><a href="https://github.com/foambubble/foam-template/generate">Create a single <strong>Foam</strong> workspace</a> for all your knowledge and research.</li>
  <li>Write your thoughts in markdown documents (I like to call them <strong>Bubbles</strong>, but that might be more than a little twee). These documents should be atomic: Put things that belong together into a single document, and limit its content to that single topic. (<a href="https://zettelkasten.de/posts/overview/#principles">source</a>)</li>
  <li>Use Foam’s shortcuts and autocompletions to link your thoughts together with <code>[[wiki-links]]</code>, and navigate between them to explore your knowledge graph.</li>
  <li>Get an overview of your <strong>Foam</strong> workspace using a [<a href="https://foambubble.github.io/foam/graph-visualisation" title="Graph visualisation">graph-visualisation</a>] (⚠️ WIP), and discover relationships between your thoughts with the use of [<a href="https://foambubble.github.io/foam/backlinking" title="Backlinking">backlinking</a>].</li>
</ol>

<p>Foam is a like a bathtub: <em>What you get out of it depends on what you put into it.</em></p>

<h2 id="whats-in-a-foam">What’s in a Foam?</h2>

<p>Like the soapy suds it’s named after, <strong>Foam</strong> is mostly air.</p>

<ol>
  <li>The editing experience of <strong>Foam</strong> is powered by VS Code, enhanced by workspace settings that glue together [<a href="https://foambubble.github.io/foam/recommended-extensions" title="Recommended Extensions">recommended-extensions</a>] and preferences optimised for writing and navigating information.</li>
  <li>To back up, collaborate on and share your content between devices, Foam pairs well with <a href="http://github.com/">GitHub</a>.</li>
  <li>To publish your content, you can set it up to publish to <a href="https://pages.github.com/">GitHub Pages</a> with zero code and zero config, or to any website hosting platform like <a href="http://netlify.com/">Netlify</a> or <a href="https://foambubble.github.io/foam/vercel">Vercel</a>.</li>
</ol>

<blockquote>
  <p><strong>Fun fact</strong>: This documentation was researched, written and published using <strong>Foam</strong>.</p>
</blockquote>

<h2 id="getting-started">Getting started</h2>

<blockquote>
  <p>⚠️ Foam is still in preview. Expect the experience to be a little rough.</p>
</blockquote>

<p>These instructions assume you have a GitHub account, and you have Visual Studio Code installed.</p>

<ol>
  <li><a href="https://github.com/foambubble/foam-template/generate">Create a GitHub repository from foam-template</a>. If you want to keep your thoughts to yourself, remember to set the repository private.</li>
  <li>Clone the repository and open it in VS Code.</li>
  <li>When prompted to install recommended extensions, click <strong>Install all</strong> (or <strong>Show Recommendations</strong> if you want to review and install them one by one)</li>
</ol>

<p>After setting up the repository, open <a href="https://foambubble.github.io/foam/.vscode/settings.json">.vscode/settings.json</a> and edit, add or remove any settings you’d like for your Foam workspace.</p>

<p>To learn more about how to use <strong>Foam</strong>, read the [<a href="https://foambubble.github.io/foam/recipes" title="Recipes">recipes</a>].</p>

<p>There are [<a href="https://foambubble.github.io/foam/known-issues" title="Known Issues">known-issues</a>], and I’m sure, many unknown issues! Please <a href="http://github.com/foambubble/foam/issues">report them on GitHub</a>!</p>

<h2 id="features">Features</h2>

<p><strong>Foam</strong> doesn’t have features in the traditional sense. Out of the box, you have access to all features of VS Code and all the [<a href="https://foambubble.github.io/foam/recommended-extensions" title="Recommended Extensions">recommended-extensions</a>] you choose to install, but it’s up to you to discover what you can do with it!</p>

<p>Head over to [<a href="https://foambubble.github.io/foam/recipes" title="Recipes">recipes</a>] for some useful patterns and ideas, and</p>

<h2 id="call-to-adventure">Call To Adventure</h2>

<p>The goal of <strong>Foam</strong> is to be your personal companion on your quest for knowledge.</p>

<p>It’s is currently about “10% ready” relative to all the features I’ve thought of, but I’ve only thought of ~1% of the features it could have, and I’m excited to learn from others.</p>

<p>I am using it as my personal thinking tool. By making it public, I hope to learn from others not only how to improve Foam, but also to improve how I learn and manage information.</p>

<p>If that sounds like something you’re interested in, I’d love to have you along on the journey.</p>

<ul>
  <li>Check out [<a href="https://foambubble.github.io/foam/roadmap" title="Roadmap">roadmap</a>] to see what’s in the plans</li>
  <li>Read about our [<a href="https://foambubble.github.io/foam/principles" title="Principles">principles</a>] to understand Foam’s philosophy and direction</li>
  <li>Read the [<a href="https://foambubble.github.io/foam/contribution-guide" title="Contribution Guide">contribution-guide</a>] guide to learn how to participate.</li>
  <li>Feel free to open <a href="https://github.com/foambubble/foam/issues">GitHub issues</a> to give me feedback and ideas for new features.</li>
</ul>

<h2 id="thanks-and-attribution">Thanks and attribution</h2>

<p><strong>Foam</strong> is built by <a href="https://github.com/jevakallio">Jani Eväkallio</a> (<a href="https://twitter.com/jevakallio">@jevakallio</a>).</p>

<p><strong>Foam</strong> was inspired by <a href="https://roamresearch.com/">Roam Research</a> and the <a href="https://zettelkasten.de/posts/overview">Zettelkasten methodology</a></p>

<p><strong>Foam</strong> wouldn’t be possible without <a href="https://code.visualstudio.com/">Visual Studio Code</a> and <a href="https://github.com/">GitHub</a>, and relies heavily on our fantastic open source [<a href="https://foambubble.github.io/foam/recommended-extensions" title="Recommended Extensions">recommended-extensions</a>] and all their contributors:</p>

<h2 id="license">License</h2>

<p>Foam is licensed under the <a href="https://foambubble.github.io/foam/license">MIT license</a>.</p>






      
      
      
    </div></div>]]>
            </description>
            <link>https://foambubble.github.io/foam/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23646507</guid>
            <pubDate>Thu, 25 Jun 2020 22:29:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Convert CSV to JSON on the Fly with Lambda]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23646359">thread link</a>) | @rbekker87
<br/>
June 25, 2020 | http://sysadmins.co.za/convert-csv-to-json-files-with-aws-lambda-and-s3-events/ | <a href="https://web.archive.org/web/*/http://sysadmins.co.za/convert-csv-to-json-files-with-aws-lambda-and-s3-events/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<p>I am a massive AWS Lambda fan, especially with workflows where you respond to specific events.</p><p>In this tutorial, I will keep it basic to demonstrate the power of how you can trigger a AWS Lambda function on a S3 PUT event, so that this can give the reader a basic demonstration to go further and build amazing things.</p><h2 id="what-will-we-be-doing">What will we be doing?</h2><p>In this tutorial we will be converting CSV files to JSON with the help of Lambda using the Python language.</p><p>The workflow will be like this:</p><ul><li>User uploads his csv file to S3, lets say bucket/input/*.csv</li><li>We then use CloudWatch events to trigger when data is uploaded to the bucket/uploads/input prefix and has a suffix of .csv</li><li>We will then trigger our Lamda function to convert the CSV file and write the JSON file to bucket/uploads/output/{year}/{month}/{day}/{timestamp}.json</li></ul><p>You can go furhter than that by using <a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/object-lifecycle-mgmt.html">S3 Lifecycle Policies</a> to delete objects when they are &nbsp;older than, lets say 30 days.</p><h2 id="create-the-s3-bucket">Create the S3 Bucket</h2><p>Head over to <a href="https://s3.console.aws.amazon.com/s3/home?region=eu-west-1">AWS S3</a> and create a New Bucket (or use an existing one):</p><!--kg-card-begin: image--><figure><img src="https://user-images.githubusercontent.com/30043398/78825295-031ba500-79e0-11ea-8ffc-7b5e23522cc6.png"></figure><!--kg-card-end: image--><p>Use a descriptive name of your choice:</p><!--kg-card-begin: image--><figure><img src="https://user-images.githubusercontent.com/30043398/78825341-17f83880-79e0-11ea-8804-c3ab44da35ee.png"></figure><!--kg-card-end: image--><p>Then your S3 bucket should appear in your console:</p><!--kg-card-begin: image--><figure><img src="https://user-images.githubusercontent.com/30043398/78825524-6efe0d80-79e0-11ea-8dd5-9869bd9d312c.png"></figure><!--kg-card-end: image--><h2 id="create-your-lambda-function">Create your Lambda Function</h2><p>Head over to <a href="https://eu-west-1.console.aws.amazon.com/lambda/home?region=eu-west-1#/functions">AWS Lambda</a> and create a function. I will be using Python 3.7 and will be calling it <code>csv-to-json-function</code>:</p><!--kg-card-begin: image--><figure><img src="https://user-images.githubusercontent.com/30043398/78825757-c603e280-79e0-11ea-9407-806388172dd5.png"></figure><!--kg-card-end: image--><p>You can then save the function as is, we will come back to the code.</p><h2 id="s3-events">S3 Events</h2><p>So what we essentially want to do, when ever someone uploads an object to S3, which <strong>MUST</strong> match the prefix <code>uploads/input</code> and has the suffix of <code>.csv</code> we want to trigger our Lambda function to act on that event to load the CSV and convert that object to JSON.</p><p>Head over to your S3 Bucket:</p><!--kg-card-begin: image--><figure><img src="https://user-images.githubusercontent.com/30043398/78826033-2a26a680-79e1-11ea-8aa5-40a7ae3dcd49.png"></figure><!--kg-card-end: image--><p>Select properties and and select events:</p><!--kg-card-begin: image--><figure><img src="https://user-images.githubusercontent.com/30043398/78826079-3b6fb300-79e1-11ea-85ee-4207f8f51a4b.png"></figure><!--kg-card-end: image--><p>and you should see:</p><!--kg-card-begin: image--><figure><img src="https://user-images.githubusercontent.com/30043398/78826115-49253880-79e1-11ea-90f7-eae542ac15a2.png"></figure><!--kg-card-end: image--><p>click add notification and provide what needs to happen. This step is <strong>very importantand should not be done wrong</strong> as it <strong>could incur in a lot of costs</strong> f done wrong.</p><p>We are configuring this S3 Event to trigger a Lambda Function when a object is created with a prefix for example: <code>uploads/input/data.csv</code> , lets say for example your Lambda &nbsp;function writes a <code>.csv</code> file back to the input prefix, your Lambda will go in a triggering loop and will cost a LOT of money, so we have to make sure that our event only listens for <code>.csv</code> suffixes on a <code>uploads/input</code> prefix.</p><p>Provide a Name, on the PUT event, provide the prefix <code>uploads/input</code> as an example, then provide the suffix <code>.csv</code> as we only want to trigger if csv files are uploaded and trigger your Lambda function:</p><!--kg-card-begin: image--><figure><img src="https://user-images.githubusercontent.com/30043398/78826304-943f4b80-79e1-11ea-9272-827e61e39bcf.png"></figure><!--kg-card-end: image--><p>it should look like:</p><!--kg-card-begin: image--><figure><img src="https://user-images.githubusercontent.com/30043398/78826346-a620ee80-79e1-11ea-8004-04a7bacd1d65.png"></figure><!--kg-card-end: image--><h2 id="iam-user">IAM User</h2><p>Now we want to create a IAM user that will be uploading the CSV files to S3.</p><p>Head over to <a href="https://console.aws.amazon.com/iam/home?region=eu-west-1">IAM</a>, select Policies, Create Policy:</p><!--kg-card-begin: code--><pre><code>{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "VisualEditor0",
            "Effect": "Allow",
            "Action": [
                "s3:PutObject"
            ],
            "Resource": "arn:aws:s3:::ruanbekker.demo.blogpost/uploads/input/*"
        }
    ]
}
</code></pre><!--kg-card-end: code--><p>I will call this policy <code>s3-uploads-csv-policy</code>, select users, create a new user and tick programmatic access:</p><!--kg-card-begin: image--><figure><img src="https://user-images.githubusercontent.com/30043398/78826816-73c3c100-79e2-11ea-8987-36a9c974cf01.png"></figure><!--kg-card-end: image--><p>Hit next, assign the policy to the user:</p><!--kg-card-begin: image--><figure><img src="https://user-images.githubusercontent.com/30043398/78826865-8938eb00-79e2-11ea-8e98-34bcc15b5013.png"></figure><!--kg-card-end: image--><p>Hit create user and make note of your aws access and secret key as the secret key is not retrievable after creation:</p><!--kg-card-begin: code--><pre><code>AKIAXXXXXXXXXXXXXXXX
ZCTfXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
</code></pre><!--kg-card-end: code--><p>Head to your terminal and configure the credentials for that user, I will configure it under the profile <code>csv-uploader</code>:</p><!--kg-card-begin: code--><pre><code>$ aws configure --profile csv-uploader
AWS Access Key ID [None]: AKIAXXXXXXXXXXXXXXXX
AWS Secret Access Key [None]: ZCTfXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
Default region name [None]: eu-west-1
Default output format [None]: json
</code></pre><!--kg-card-end: code--><h2 id="lambda-function">Lambda Function</h2><p>Let's head back to Lambda and write some code that will read the CSV file when it arrives onto S3, process the file, convert to JSON and uploads to S3 to a key named: <code>uploads/output/{year}/{month}/{day}/{timestamp}.json</code></p><p>When the S3 event triggers the Lambda function, this is what's passed as the event:</p><!--kg-card-begin: code--><pre><code>{
  "Records": [
    {
      "eventVersion": "2.1",
      "eventSource": "aws:s3",
      "awsRegion": "eu-west-1",
      "eventTime": "2020-04-08T19:50:35.471Z",
      "eventName": "ObjectCreated:Put",
      "userIdentity": {
        "principalId": "AWS:x"
      },
      "requestParameters": {
        "sourceIPAddress": "102.132.218.115"
      },
      "responseElements": {
        "x-amz-request-id": "x",
        "x-amz-id-2": "x/x/x"
      },
      "s3": {
        "s3SchemaVersion": "1.0",
        "configurationId": "TriggerLambdaToConvertCsvToJson",
        "bucket": {
          "name": "ruanbekker.demo.blogpost",
          "ownerIdentity": {
            "principalId": "x"
          },
          "arn": "arn:aws:s3:::ruanbekker.demo.blogpost"
        },
        "object": {
          "key": "uploads/input/foo.csv",
          "size": 0,
          "eTag": "x",
          "sequencer": "x"
        }
      }
    }
  ]
}
</code></pre><!--kg-card-end: code--><p>So we have context on the <strong>key name</strong> as well as the <strong>bucket name</strong>.</p><p>Onto the code of our Lambda Function, there's probably better ways such as streaming to do this, but the focus is on what the task is doing and not really on the code.</p><p>I am reading the CSV file, writing it to the <code>/tmp</code> directory (only path which is writable), processing the data convert to json and write as a json file, then uploads to S3 and remove the files from the disk:</p><!--kg-card-begin: code--><pre><code>import json
import csv
import boto3
import os
import datetime as dt

s3 = boto3.client('s3')

def lambda_handler(event, context):
    
    datestamp = dt.datetime.now().strftime("%Y/%m/%d")
    timestamp = dt.datetime.now().strftime("%s")
    
    filename_json = "/tmp/file_{ts}.json".format(ts=timestamp)
    filename_csv = "/tmp/file_{ts}.csv".format(ts=timestamp)
    keyname_s3 = "uploads/output/{ds}/{ts}.json".format(ds=datestamp, ts=timestamp)
    
    json_data = []

    for record in event['Records']:
        bucket_name = record['s3']['bucket']['name']
        key_name = record['s3']['object']['key']
        
    s3_object = s3.get_object(Bucket=bucket_name, Key=key_name)
    data = s3_object['Body'].read()
    contents = data.decode('utf-8')
    
    with open(filename_csv, 'a') as csv_data:
        csv_data.write(contents)
    
    with open(filename_csv) as csv_data:
        csv_reader = csv.DictReader(csv_data)
        for csv_row in csv_reader:
            json_data.append(csv_row)
            
    with open(filename_json, 'w') as json_file:
        json_file.write(json.dumps(json_data))
    
    with open(filename_json, 'r') as json_file_contents:
        response = s3.put_object(Bucket=bucket_name, Key=keyname_s3, Body=json_file_contents.read())

    os.remove(filename_csv)
    os.remove(filename_json)

    return {
        'statusCode': 200,
        'body': json.dumps('CSV converted to JSON and available at: {bucket}/{key}'.format(bucket=bucket_name,key=keyname_s3))
    }
</code></pre><!--kg-card-end: code--><p>Save the Lambda function.</p><h2 id="upload-csv-to-s3">Upload CSV to S3</h2><p>Back to your terminal, create a CSV file, in my case:</p><!--kg-card-begin: code--><pre><code>$ cat &gt; data.csv &lt;&lt; EOF
name,surname,age,country,city
ruan,bekker,33,south africa,cape town
james,oguya,32,kenya,nairobi
stefan,bester,33,south africa,kroonstad
EOF
</code></pre><!--kg-card-end: code--><p>Now upload the data to S3 <code>uploads/input/foo.csv</code> . The destination filename can be anything, as long as the prefix is <code>uploads/inputs</code> and suffix with <code>.csv</code>:</p><!--kg-card-begin: code--><pre><code>$ aws --profile csv-uploader s3 cp data.csv s3://ruanbekker.demo.blogpost/uploads/input/foo.csv
upload: ./data.csv to s3://ruanbekker.demo.blogpost/uploads/input/foo.csv
</code></pre><!--kg-card-end: code--><p>As we can see from our Lambda Execution Logs on CloudWatch, our execution was successful:</p><!--kg-card-begin: image--><figure><img src="https://user-images.githubusercontent.com/30043398/79764219-5f0df400-8325-11ea-8987-4d54ca8f3b43.png"></figure><!--kg-card-end: image--><p>Looking at S3, we can see our key was created as <code>bucket/uploads/output/{year}/{month}/{day/{timestamp}.json</code></p><!--kg-card-begin: image--><figure><img src="https://user-images.githubusercontent.com/30043398/79763587-90d28b00-8324-11ea-9ecb-7a8f2a680508.png"></figure><!--kg-card-end: image--><p>Selecting our object, hit actions and select open, we can see that our CSV file was converted to JSON (note: I pretty printed the file manually for better readability):</p><!--kg-card-begin: image--><figure><img src="https://user-images.githubusercontent.com/30043398/79763795-d1ca9f80-8324-11ea-977f-bde88391dc95.png"></figure><!--kg-card-end: image--><h2 id="thank-you">Thank You</h2><p>This was a very basic example of what you can do with S3 Events and Lambda, the sky is the limit, you can do awesome things!</p>
		</div></div>]]>
            </description>
            <link>http://sysadmins.co.za/convert-csv-to-json-files-with-aws-lambda-and-s3-events/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23646359</guid>
            <pubDate>Thu, 25 Jun 2020 22:13:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Polyglot Assembly]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23646217">thread link</a>) | @vojtechkral
<br/>
June 25, 2020 | https://vojtechkral.github.io/blag/polyglot-assembly/ | <a href="https://web.archive.org/web/*/https://vojtechkral.github.io/blag/polyglot-assembly/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    
    <p><em>Writing assembly code that runs on multiple architectures.</em></p>
    <p>A few years back, while I worked as a Solaris engineer at Oracle,
I posted an april fools joke to one of our internal mailing lists.
Do you remember <a href="https://en.wikipedia.org/wiki/Solaris_(operating_system)">Solaris</a>?
<a href="https://vojtechkral.github.io/blag/polyglot-assembly/pepperidge-farm.jpg">Pepperidge farm remembers</a>.
Unfortunatelly Solaris 12 was
<a href="https://arstechnica.com/information-technology/2017/01/oracle-sort-of-confirms-demise-of-solaris-12-effort/">never released</a>
(not as such, anyway) and many of the devs were laid off shortly afterwards,
but that's a different story... The april fools e-mail read as follows:</p>
<pre><span>Hi all,
   can I please get a codereview for my new Hello World program?
The purpose of the program is to output a greeting.
As the code is very short, I'm inlining it at the end of this email.
The code has been tested on sparc and x86.
Only 64 bit arch is supported - please compile with cc -m64.
cstyle reports no issues.

Thanks!
Vojtech

$ cat hello.c

const float main[] = {
         -5.0076923e-29, -6.02841476e-21, 1.75860328e-33, -4.3672462e-34,
         -2.03652633e-33, 3.00046579e-32, -6.99961556e-33, -4.36343733e-34,
         -253599.734, 1.87611745e-33, -4.36724253e-34, -2.03652633e-33,
         2.62426763e-32, -4.36343733e-34, -253599.859, -1.05886372e-37,
         -2.84236475e-29, -4.2805483e-28, -7.27646377e-27, -3.28364893e-28,
         -7.3422524e-38, -8.52233404e-38, -7.19531561e-38, -2.84236445e-29,
         -6.02842122e-21, 2.3509887e-38, -7.3422524e-38, -8.52233404e-38,
         -6.02842122e-21, 2.3509887e-38, -7.3422524e-38, -8.52233404e-38,
         1.69276854e-42, 1.58918456e-40, -7.11823707e-31, 3.30286048e-42,
         1.26058568e-39, 6.72382769e-36, 5.90304592e+22, 2.02799612e-19,
         1.17234334e+27, 9.30333261e-40, 1.7976867e-38, 0.0
};
</span></pre>
<p>I expect <code>main()</code> not being a function and instead being an array of numbers
won't be news to many people, this
<a href="http://jroweboy.github.io/c/asm/2015/01/26/when-is-main-not-a-function.html">has been done before</a>.
(If you've never seen this before, have a look at that blogpost, it's pretty good!)</p>
<p>The focus of this post instead is this line:</p>
<blockquote>
<p><strong>The code has been tested on sparc and x86.</strong></p>
</blockquote>
<p>Any code that a Solaris dev looked to push to the core repository
had to be rigorously tested on both architectures targeted by Solaris: x86 and SPARC.
And this code doesn't really look like it could run on multiple architectures, right? ...
But it does. And it does that with a trick I call a <em>polyglot assembly</em> code.
Maybe that's a little too pompous a name for a silly joke, but I didn't know what else to call it...</p>
<h2 id="linux-x86-64-arm">Linux, x86-64 &amp; ARM</h2>
<p>I recently decided to revive the idea and, since both Solaris and SPARC
are fairly obscure nowadays, to port the code over to Linux on x86-64 and ARM.</p>
<p>Here's the new code:</p>
<pre><span>#include </span><span>&lt;stdint.h&gt;

</span><span>const </span><span>uint64_t</span><span> _start[] </span><span>__attribute__</span><span>((section(</span><span>".text"</span><span>))) </span><span>= </span><span>{
    0xe3a00001909032eb, 0xe3a0200ce28f1014,
    0xef000000e3a07004, 0xe3a07001e3a00000,
    0x6c6c6548ef000000, 0x0a214d5241202c6f,
    0x18ec834800000000, 0x4800000045058b48,
    0xa20fc03148240489, 0x0c24548908245c89,
    0x142444c710244c89, 0x01c0c74800000a21,
    0x0001c7c748000000, 0x480124748d480000,
    0x050f00000015c2c7, 0x480000003cc0c748,
    0x6c654820050fff31, 0x00000000202c6f6c,
};
</span></pre>
<p>It's still just a <em>Hello, World!</em> program.</p>
<p>To build it, I recommend <code>gcc -static -nostdlib</code>.
I found out the special section attribute is necessary for gcc to put the code in the right section.</p>
<p>You can also get pre built binaries <a href="https://github.com/vojtechkral/asm-polyglot/releases/tag/0.1">here</a>.</p>
<p>Please keep in mind that the resulting binaries are <strong>still platform-specific</strong>.
The polyglot trick's purpose is to make it possible to build for x86-64 and ARM from the same source file.
While the executable code inside the ELF file is the same bit by bit for both platforms,
the ELF header and section layout is somewhat different and unfortunatelly there seems to be no way around this
(at minimum, the kernel checks the ELF architecture byte and won't load the program unless it matches).</p>
<p>So anyway, how does it work?</p>
<p><img src="https://vojtechkral.github.io/blag/polyglot-assembly/diagram.png#right" alt="diagram"></p>
<p>The basic idea is pretty simple: The code starts with a magical snippet
that gets interpreted by both architectures and basically performs
a conditional jump based on which architecture is runing the code.</p>
<p><em>Architecture #1</em> decodes this bit as a an effective no-op instruction
(in my example it's actually an ALU instruction whose output is ignored)
and simply continues to the area marked blue in the diagram.
<em>Arch-#1</em>-specific code is stored there.</p>
<p><em>Architecture #2</em> decodes the initial part as a jump and proceeds
to jump over to the yellow area where the code for <em>arch #2</em> follows.</p>
<p>How do you come up with the magical architecture-selecting prolog?</p>
<p>It turns out x86 is actually a pretty good choice for <em>arch #2</em>, because it has
a short near-jump instruction, just 2 bytes. Together with 2 <code>NOP</code>s (1 byte each)
this makes up the length of one regular (non-Thumb) ARM instruction.</p>
<p>The three x86 instructions, a <code>JMP</code> and two <code>NOP</code>s, can be arbitrarily reordered
and also the jump distance can be adjusted, and as I found out this is
enough degrees of freedom to find a valid nop-like ARM instruction.</p>
<h2 id="searching-the-instruction-space">Searching the instruction space</h2>
<p>The original Solaris code was a result of basically just hokus-pokus.
In the Linux rewrite I tried to come up with a somewhat more automated way of finding the right combo.
There's a hackish <a href="https://github.com/vojtechkral/asm-polyglot/blob/master/jmps.py">python script</a>
and a Makefile rule that generate <a href="https://vojtechkral.github.io/blag/polyglot-assembly/jmps.txt">a big plaintext list</a> of all <code>NOP</code>/<code>NOP</code>/2-byte <code>JMP</code>
permutations along with their ARM representations.</p>
<p>From the list it's apparent that the <code>JMP</code>, <code>NOP</code>, <code>NOP</code> ordering yields a safe
ARM <code>addsls</code> instruction most of the time, at least as long as the jump distance is small enough
for the <code>addsls</code> to not touch the <code>sp</code> or <code>pc</code> registers...</p>
<p>In my case I only need to <code>JMP</code> 52 bytes ahead. This results in <code>addsls r3, r0, r11, ror #5</code> on ARM,
which is a perfectly harmless instruction. Maybe a bit too complex (a conditional add with a bit rotation), but harmless.</p>
<p>In summary, the magical bytes that make an x86 CPU jump ahead and
an ARM CPU continue are:</p>
<pre><span>eb 32 90 90
</span></pre><h2 id="the-code">The code</h2>
<p>The source code for this mini-project can be found <a href="https://github.com/vojtechkral/asm-polyglot">on my github</a>.</p>
<p>The C file quoted above effectively contains the following two code paths for x86-64 and ARM, respectively:</p>
<div>
<pre><span>x86:
    # create a hello message on the stack
    </span><span>sub     </span><span>$</span><span>24, </span><span>%</span><span>rsp
    </span><span>movq    </span><span>msg(%</span><span>rip</span><span>)</span><span>, </span><span>%</span><span>rax
    </span><span>mov     </span><span>%</span><span>rax, </span><span>(%</span><span>rsp</span><span>)
    </span><span>xor     </span><span>%</span><span>rax, </span><span>%</span><span>rax
    </span><span>cpuid
    mov     </span><span>%</span><span>ebx, 8</span><span>(%</span><span>rsp</span><span>)
    </span><span>mov     </span><span>%</span><span>edx, 12</span><span>(%</span><span>rsp</span><span>)
    </span><span>mov     </span><span>%</span><span>ecx, 16</span><span>(%</span><span>rsp</span><span>)
    movl    </span><span>$</span><span>0x0a21, 20</span><span>(%</span><span>rsp</span><span>)

    # write </span><span>syscall
    mov     </span><span>$</span><span>1, </span><span>%</span><span>rax
    </span><span>mov     </span><span>$</span><span>1, </span><span>%</span><span>rdi
    </span><span>lea     </span><span>1</span><span>(%</span><span>rsp</span><span>)</span><span>, </span><span>%</span><span>rsi
    </span><span>mov     </span><span>$</span><span>21, </span><span>%</span><span>rdx
    </span><span>syscall

    </span><span># exit </span><span>syscall
    mov     </span><span>$</span><span>60, </span><span>%</span><span>rax
    </span><span>xor     </span><span>%</span><span>rdi, </span><span>%</span><span>rdi
    </span><span>syscall

</span><span>msg:
    .ascii  </span><span>" Hello, "
    </span><span>.</span><span>int </span><span>0x0
</span></pre><pre><span>arm:
    # write </span><span>syscall
    mov     </span><span>%r0</span><span>, </span><span>$</span><span>1
    </span><span>adr     %r1</span><span>, </span><span>msg
    </span><span>mov     </span><span>%r2</span><span>, </span><span>$</span><span>len
    </span><span>mov     </span><span>%r7</span><span>, </span><span>$</span><span>4
    </span><span>swi     </span><span>$</span><span>0

    </span><span># exit </span><span>syscall
    mov     </span><span>%r0</span><span>, </span><span>$</span><span>0
    </span><span>mov     </span><span>%r7</span><span>, </span><span>$</span><span>1
    </span><span>swi     </span><span>$</span><span>0

</span><span>msg:
    .ascii  </span><span>"Hello, ARM!\n"
    </span><span>.</span><span>equ </span><span>len</span><span>, </span><span>. </span><span>- </span><span>msg
    .</span><span>int </span><span>0x0
</span></pre></div>
<p>I decided to automate the whole process of generating the C file and the binaries for x86-64 and ARM.
There's a big <code>Makefile</code> that goes through the arduous process of first generating ARM code from the source ARM asm file,
dumping the compiled ARM, feeding that to a Python script with a template of the x86 + compiled ARM code,
compiling that, generating the C source from that, and finally compiling the C source for both x86 and ARM.</p>
<p>Running the Makefile requires having an arm cross-compiling gcc installed along with a matching gdb.</p>
<h2 id="practical-applications">Practical applications</h2>
<p>There are none :-)</p>
<p>At least as far as I know.
As stated earlier, the resulting binary is still platform-specific,
Which means the trick can't be used to make multi-platform ELFs :-|</p>
<p>In theory it could be used to create a multi-platform shellcode,
but I find it unlikely that it would actually be useful in practice.</p>
<p>Multi-platform kernels maybe? But then again boot procedures differ quite a lot
between architectures, so again it's probably not very practical...</p>
<p>So yeah, it's really just a joke done for fun and to perhaps learn something new...</p>

</article></div>]]>
            </description>
            <link>https://vojtechkral.github.io/blag/polyglot-assembly/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23646217</guid>
            <pubDate>Thu, 25 Jun 2020 21:54:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Intro to Docker for Web Developers]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23646145">thread link</a>) | @bajcmartinez
<br/>
June 25, 2020 | https://livecodestream.dev/post/2020-06-25-intro-to-docker-for-web-developers/ | <a href="https://web.archive.org/web/*/https://livecodestream.dev/post/2020-06-25-intro-to-docker-for-web-developers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
        <figure>
            
            <img alt="Feature Image" src="https://livecodestream.dev/post/2020-06-25-intro-to-docker-for-web-developers/featured_hu3f9d36be24b7ab6ea505a5af15c8496f_133171_680x0_resize_q75_box.jpg">
        </figure>
        <p>Knowing how to use containers in application development is a must for a modern-day developer. One reason for the recent demand for containers has been the emergence of Docker. Docker has not only increased the use of containers, it has had a great impact on the way we approach application development.&nbsp;</p>
<p>If you are a developer who is yet to find a proper introduction to this popular technology, you are in the right place. In this article, we are going to introduce you to the concept of Docker and get a hands-on approach to learning Docker by dockerizing a simple application.&nbsp;</p>
<p>First, let’s clarify what Docker is and why it has become this important.</p>
<hr>
<h2 id="what-is-docker">What is Docker?</h2>
<blockquote>
<p>Docker is a tool developers use to create, deploy, and run applications in an isolated environment through containers.&nbsp;</p>
</blockquote>
<p>Here it is again, containers. Though this term is used a few times since the beginning of the article, you may not have an idea what a container is. In order to fully understand the above statement, we have to first understand what a container is.</p>
<hr>
<h2 id="what-is-a-container-and-why-do-we-need-it">What is a Container and Why Do We Need It?</h2>
<p>A container is a software unit that packs application code and all the dependencies used in the application into a single package. Packaging allows the container to isolate the application from the host environment it is running in. The application sees the container as its environment instead of the host device. This abstraction guarantees that an application running in a development environment is able to run in a production environment without going through significant changes.&nbsp;</p>
<p>Even if several applications are running on the host device, the container isolates the containerized application from interfering with the operation of other applications and sharing their resources.&nbsp;</p>
<p>Before containers, virtual machines were used to isolate applications from the host environment. In virtual machines, each machine uses a separate operating system to run the application. Though this approach also achieves the purpose of isolating the applications, it has a downside of adding too much overhead on top of the application. Containers, on the other hand, share the OS kernel of the host device instead of using an OS of its own, which removes the overhead added by the virtual machines. This makes containers more lightweight and resource-efficient compared to virtual machines.&nbsp;</p>








<figure data-src="/post/2020-06-25-intro-to-docker-for-web-developers/docker.svg">
<img src="https://livecodestream.dev/post/2020-06-25-intro-to-docker-for-web-developers/docker.svg" alt="Docker vs VM"> <figcaption>
    <p>Docker vs VM</p>
</figcaption>
</figure>

<p>Though containers have been in use long before Docker, it’s safe to say that Docker is the biggest reason for the extreme popularity of containers in the modern programming world. Other than being open-source, Docker’s ease of use, reliability, and efficiency made the programming world instantly fall in love with this technology.</p>
<hr>
<h2 id="what-are-the-dockerfile-docker-image-and-docker-engine">What are the Dockerfile, Docker Image, and Docker Engine?</h2>
<p>Docker comes with its special language. Dockerfile, Docker image, and Docker engine are 3 words commonly used among Docker users. These are also the 3 most important components used when building Docker containers.&nbsp;</p>
<h3 id="dockerfile">Dockerfile</h3>
<p>Dockerfile contains a set of instructions to build a Docker image, which we are going to discuss next. These instructions will be run one after the other when creating the Docker image. Instructions in the Dockerfile contain information such as the host device’s OS, the programming language of the application, application directory location, network ports, and environment variables.&nbsp;</p>
<h3 id="docker-image">Docker Image</h3>
<p>Docker image is a template that is used to create the final Docker container for the application. We can generate the Docker image of an application by running the docker build command with the Dockerfile as a parameter. To create the Docker container, we use the docker run command and the Docker image.&nbsp;</p>
<h3 id="docker-engine">Docker Engine</h3>
<p>Docker engine is where all the Docker containers are running on. Both Windows and Linux based applications can run on Docker engines.</p>
<hr>
<h2 id="how-to-dockerize-a-simple-application">How to Dockerize a Simple Application</h2>
<p>Now we have got to the most interesting part of this tutorial. We are going to dockerize a simple application to get hands-on Docker experience. First, we will create a simple Node.js application and then, create the Dockerfile, Docker image, and finally the Docker container for the application.&nbsp;</p>
<p>Before continuing, however, make sure you have Docker installed on your device. You can follow the official documentation to install Docker on your <a href="https://docs.docker.com/docker-for-windows/install/">Windows</a> or <a href="https://docs.docker.com/engine/install/ubuntu/">Ubuntu OS</a>. Check out the docs for other OS.</p>
<h3 id="create-a-simple-nodejs-application">Create a Simple Node.js Application</h3>
<p>We are going to create a simple Node application that sends a “Hello World” message when we visit the root route.&nbsp;</p>
<p>Follow these steps to set up your application:</p>
<div><pre><code data-lang="shell">npm init
npm install express --save
</code></pre></div><p>Inside the directory, <code>app.js</code> file contains our main application code.&nbsp;
&nbsp;</p>
<div><pre><code data-lang="javascript"><span>const</span>&nbsp;<span>express</span>&nbsp;<span>=</span>&nbsp;<span>require</span>(<span>'express'</span>)
<span>const</span>&nbsp;<span>app</span>&nbsp;<span>=</span>&nbsp;<span>express</span>()
&nbsp;
<span>app</span>.<span>get</span>(<span>'/'</span>,&nbsp;(<span>req</span>,&nbsp;<span>res</span>)&nbsp;=&gt;&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;<span>res</span>.<span>send</span>(<span>"Hello&nbsp;World!"</span>)
})
&nbsp;
<span>app</span>.<span>listen</span>(<span>process</span>.<span>env</span>.<span>PORT</span>,&nbsp;()&nbsp;=&gt;&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;<span>console</span>.<span>log</span>(<span>"Node&nbsp;server&nbsp;has&nbsp;started&nbsp;running"</span>)
})
</code></pre></div>
<h3 id="create-the-dockerfile-for-the-application">Create the Dockerfile for the Application</h3>
<p>Now we can create the Dockerfile with the information that is needed to create the Docker image.&nbsp;</p>
<p>Create a file named <code>Dockerfile</code> inside the application directory. To create the Docker Image for our application, the Dockerfile should contain a set of commands like this.&nbsp;</p>
<div><pre><code data-lang="dockerfile"><span>FROM</span><span> node:latest</span><span>
</span><span></span> <span>
</span><span></span><span>WORKDIR</span><span> /docker-tutorial</span><span>
</span><span></span> <span>
</span><span></span><span>COPY</span> . .<span>
</span><span></span> <span>
</span><span></span><span>ENV</span> PORT <span>3000</span><span>
</span><span></span> <span>
</span><span></span><span>RUN</span> npm install<span>
</span><span></span> <span>
</span><span></span><span>EXPOSE</span><span> $PORT</span><span>
</span><span></span> <span>
</span><span></span><span>ENTRYPOINT</span> [<span>"node"</span>, <span>"app.js"</span>]<span>
</span></code></pre></div><p>Now we will go through what each of these commands means.&nbsp;</p>
<ol>
<li>FROM—This command sets the base image and the new image of the application is built on top of this. In our case, we use an image that contains npm and the latest Node.js version. This image is pulled from Docker Hub which is a public repository of Docker images.&nbsp;</li>
<li>WORKDIR—This command sets the working directory for the application that will be running inside the container.&nbsp;</li>
<li>COPY—This command copies the files in the application directory to the working directory which we set with the previous command. You can pass the path to a specific file name or do as above to copy all the files in the application directory to the Docker image. In the latter case, make sure you have navigated to the application directory on the command line when running the docker build command.</li>
<li>ENV—In the Node application, note how we passed the environment variable, PORT (process.env.PORT), to the app.listen function instead of directly passing the port number the application should listen to. Therefore, we have to set the PORT environment variable in the application environment. For our application that is going to the Docker container. So, we use the ENV command to pass the variables that we want to set as environment variables inside the Docker container.&nbsp;</li>
<li>RUN—This command runs npm install to install the dependencies used in our application, which are saved to package.json file.&nbsp;</li>
<li>EXPOSE—This command exposes the application to listen to the given port. Since we have already set the port number as an environment variable, we pass the variable name, $PORT, &nbsp;in place of the actual port number. However, remember that the application is exposed to the port 3000 inside the container’s environment and not the host device’s environment.&nbsp;</li>
<li>ENTRYPOINT—This command sets how to enter, or how to start, our application. Docker joins the array we pass to create a single command that starts the application, which is node app.js.&nbsp;</li>
</ol>
<h3 id="build-the-docker-image">Build the Docker Image</h3>
<p>We use docker build command to build the Docker image from the Dockerfile. Here is how it works:</p>
<div><pre><code data-lang="shell">docker build -t &lt;image-name&gt; &lt;dockerfile-location&gt;
</code></pre></div><p>Make sure you have navigated to the application directory on your command-line before running the command. You can pass a dot (.) in place of the Dockerfile location to indicate that the Dockerfile is in the current directory.&nbsp;</p>
<p>For our example we will run:</p>
<div><pre><code data-lang="shell">docker build -t docker-tutorial .
</code></pre></div><p>Output:</p>
<div><pre><code data-lang="text">Sending build context to Docker daemon  2.008MB
Step 1/7 : FROM node:latest
latest: Pulling from library/node
81fc19181915: Pull complete 
ee49ee6a23d1: Pull complete 
828510924538: Pull complete 
a8f58c4fcca0: Pull complete 
33699d7df21e: Pull complete 
923705ffa8f8: Pull complete 
ae06f9217656: Pull complete 
39c7f0f9ab3c: Pull complete 
df076510734b: Pull complete 
Digest: sha256:719d5524c7e927c2c3e49338c7dde7fe56cb5fdb3566cdaba5b37cc05ddf15da
Status: Downloaded newer image for node:latest
 ---&gt; dcda6cd5e439
Step 2/7 : WORKDIR /docker-tutorial
 ---&gt; Running in 8797780960e9
Removing intermediate container 8797780960e9
 ---&gt; b80abb69066b
Step 3/7 : COPY . .
 ---&gt; cc9215d75956
Step 4/7 : ENV PORT 3000
 ---&gt; Running in 4bf08e16b94d
Removing intermediate container 4bf08e16b94d
 ---&gt; 95007721d5ee
Step 5/7 : RUN npm install
 ---&gt; Running in d09f45f0bbd7
npm WARN docker-tutorial@1.0.0 No description
npm WARN docker-tutorial@1.0.0 No repository field.

audited 50 packages in 1.146s
found 0 vulnerabilities

Removing intermediate container d09f45f0bbd7
 ---&gt; 292a854f73e2
Step 6/7 : EXPOSE $PORT
 ---&gt; Running in f2ae755655b3
Removing intermediate container f2ae755655b3
 ---&gt; 6d42325fe934
Step 7/7 : ENTRYPOINT ["node", "app.js"]
 ---&gt; Running in d657168980d8
Removing intermediate container d657168980d8
 ---&gt; 0c6df3f042eb
Successfully built 0c6df3f042eb
Successfully tagged docker-tutorial:latest
</code></pre></div><p>Once you run the docker build command, Docker will execute each command in the Dockerfile consecutively. When executing the FROM command, if the Node image hasn’t been pulled to your device before, Docker will pull the image from Docker Hub.&nbsp;</p>
<p>Once all the commands are executed, you will see the message “successfully built” if the image was created without running into an error.&nbsp;</p>
<p>You can use the command, <code>docker images</code>, to see all the images currently in your device.&nbsp;</p>
<p>Output:</p>
<div><pre><code data-lang="text">REPOSITORY       TAG      IMAGE ID        CREATED         SIZE
docker-tutorial  latest   0c6df3f042eb    3 minutes ago   943MB
node             latest   dcda6cd5e439    2 weeks ago     942MB
</code></pre></div><h3 id="create-the-docker-container">Create the Docker Container</h3>
<p>We use …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://livecodestream.dev/post/2020-06-25-intro-to-docker-for-web-developers/">https://livecodestream.dev/post/2020-06-25-intro-to-docker-for-web-developers/</a></em></p>]]>
            </description>
            <link>https://livecodestream.dev/post/2020-06-25-intro-to-docker-for-web-developers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23646145</guid>
            <pubDate>Thu, 25 Jun 2020 21:46:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mathematical Foundations of Data Sciences [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23645919">thread link</a>) | @memexy
<br/>
June 25, 2020 | https://mathematical-tours.github.io/book-sources/chapters-pdf/machine-learning.pdf | <a href="https://web.archive.org/web/*/https://mathematical-tours.github.io/book-sources/chapters-pdf/machine-learning.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>K‘„ˆ‰2Aûbªø{ð#	×Ö%KcŽ�(¼ŠXŒ(à8ËhBó™HŽYªÉpð[%ÁsãÏ™
ñ÷DwR<c7Ø€,3n(a^Ò6ôËu`]pÏ ç÷ugÂdfqŒw-Ûi¹¶@®Ø½èŽ«Ïû"ùùq?ídpw<="" ’!› ¢â�—ñh}‹Òu="" šfÃ�­\Œp®ž’™="" Øõ+mƒu1Ô£aŒÀ”¦="" i*«j¸ÓõÑqqÃˆn¢côta1@^Â;%u“˜1vr5Ÿ´ûªìr!u÷c‰6ü¢b7Žhxu¸Ò_(pq§lmôxð�q%iø–oî<ì(rdg2ªcÁ_ï†ÜÙy�nÜ’)ˆ¸“zØqµ&],¾Ú½lÛm�™´‚óÎ“Êh¦_ŸsÃt“…h”|*¡¢®+¾¸n ã¬�£¦kž‰ä#“¥mkì’b›$„m-vÊä|†&µÁ‘guf[td="" ~d�Šà&="" “tiÀ±£lÛ$òþƒ‡�^‚$†*±ÕqÓçlq§m="" ¶%„¨9ò”ü(¼è�É&ÍÄ'="" ‡4b±%sæfb&:ô`+¸ Üµy1…~ƒÝ]l#8ˆäej3�¤ml�[udh="" ²b"ó‰„kå?‡’{Óòjhƒå�Êª!¨¸¿­ükÜÕ¯�ÆÚ¥jc¬n ="" šdiòš*íµc‹;4wq¹bj$f•Ï="" €¹9Å°7Ö¤àÀÛ­du¼+gÀÌ›5?lôÅqìg="" Û³l•-ërð¿*="" š'²&|~pÛkÐ™Œkb�Ëi®+ï8¿¢="" ²l¶®="" < o8o)ä="" w\="" úÁƒŽÊg2cËãäur$7<€¸£Šb†„¨b†á¢¿ŒhÂŠ~="" ahÄæüyä°|©ž0�_[oÚjÎ¶t@ŠÀ÷åud‘i!¾û[´È`›ÛmÌ‡kÃs‡í-¢q·£ùa]òqÕ#&="" %Ãv˜Ä–æ;ŽÊq±¿žŽ#È¾ñtc*öd‘ŒÆ5"õe$ÙÆm]ØØ="" “¶h$‘léª¼ˆˆêùeüzà´n¤j°É4,¿�ëÍ¶¬°="" £§è�<Ñã“�×å_žªx…†$j�xs?\uuÄŽ€ž¢ªê«ˆ"ŠÏ”va.8Ïª~Øz9”ÚfÑlpÑqb\šÝ­l–^4#&Áõ4p•c¸ „�!¶Þ‹¢¥}-[gl8ÀÖêâ’î­Šžùxk‰#Â:£¶±zÇ¶Ölp2fÑîÉhý•hÞèì|ª›n½_Ø_p�·xÓåpÉ–*•bÁ8„l°n,:bdbÄ†­† ¸ô„Ér…qæ<bo`,heÁôÏ‘^o¨~="" ®6m´�´ì’zÕu‡="" f±yÂo•="">0`&nbsp;p&lt;~)8H-6…`ÐáMó�Y:ˆüUž“*Ü`ÜlDÄ�ÁõuU´ypbQ7ÉU
Uý±´ŽBm¢ò�%ld*˜«¾ÀtZx_UHÆƒˆñ‘Šª8J(¢&nbsp;ªj‰ˆ^Èá#¹µÓ&amp;éPEˆÍµŸ9+ÇåÓWc ŠËFÑ×ÕPET&gt;�AŸQ…¤#‘oÜ7rº
²¶RCË0Ñü9?ˆºXRäuÄ°{Ñb<bŽ$rÏÆ�®8°ü¯ë€ ¢*="" ¦gŽ�åÎ¶jrâ*¦ª#�!â~1ÆÐÐØÏÕ="" )ƒ!&(#†-8j­€8ÏÆªú´8ûm8‘p¼¦="" ãþuaqiÔecuÆ"¸â±n™½†ÄˆsŽãªÝr9¡d$²ÓnÙ¶ˆõ—¾{ã="" e„!"3‰À#hÇ„~cÖã±…¡ýa“…˜Êo«1rl_8@Ûhì‡\Æt[9jdµ‰ì="">«ò(‰&amp;*’*&amp;6ú*°~ªÊ›f dVTÑ^Éõ.0J(À‡þÔü�þUW&lt;¢"&nbsp;güax,øÅæÔ(íªH¨ß&nbsp;ª£lš*¡*¨|Ç�ZF!N'�R#�W°ßÆúæî~‚äv”št1HÛI3›p_”¦‚f¸ª(¡îN5K=Q&nbsp;f½\:Ú¡h¾sDm·
BŽJwâW•ôLXÊâ³ëü‘&lt;¤ƒÃÁm[6UÓrQpÈ™Ïûø5&lt;""'òÀ!Ïbðžø…øaMVJÅño©HŒT†­¨DÃf¢³_êMCöFc"Cà›gÝcÀ³ÒCUþ	˜&gt;âÌsÒ&amp;GøCZÁ_È�¶4ÞÈª “Ò±×¦dó”¸_•_tBõió¶QDšLAeq¥mÒ}U=QUWÃ¨&gt;œõ}_\`[ð&gt;d~q¶ÙRdYRUng�gTü"£j¾=‹ÇÿÚxWÑ5ÁŠ¦Ÿ¦G�Ù"‰¨$·s¨ŠÉ!6�ê�ÐGuO9.+-&amp;ã­cMšçÀ„‰Ý†Y˜Ø§ÎéqüaHm´A37¤6Æ$\(•£êH�¤™ÄI¦xAG¬šh½ÅÒõwŸ°°ÁJÐ#º'1Q›ìRe„f¤]¿%|û“&gt; ×“ÄC
‡Z6	öy÷t±²Ab8ò€3dØ8îç;Žem#`(‚9çÆ‰å|y$U‰ï.&nbsp;z:ú&amp;|þU_ð�·óu¸0kÛDØ!E ŠÈ®HŠŠ_„õm{çÂlÐ�~$l•U¨þ˜¬¦$áBpŽV|
²‰¿ûUZm¤p‰übŠM0 “,A„i³{Á¢IBÎ:âÃH¦S-Ž�¸ü±)
GGùæ{äxâ"ÛJxv(Â;ù$Òa&nbsp;&nbsp;%|w%ÌüR*™mã—PÛQÐHÊ$?(sÁ¤7•ÃEÈ0~l‰Z_*¸?ËSÈ9àL“Âûgòñ"ËØUÂq~?F©šÜ0y,Ìã´ÎâóKa°;`q^u•$#R	ð¬ƒ~Aü5&lt;6s³÷�~2#šŠ¢
ö6Â&lt;ñ½•´n8ÔZ†˜¥¶Î=(ÏÀLpÕÁ6]T)$Ò¹	çUûWS6k›yìYìŽ9-
a	[t_så	&gt;TEQöTlS+ª¤I:ZVb,�u§$
|p[âEb) ›²H±¦‘	óþP"+…yð-âÿ%Dþ^ƒî€¥ŠÞ øÏ)æeL˜¸JŠ¢Ò¦fYKÈkäµx¥ŽCðá6žR2x8~ã?_‰uQK¤ˆ
XÛÄ
ò¶ÛCò€§²– «m'˜’ã“d ¦ÿÈ¤à¶«%p\GqwÄ©µ’%á\Ë`�CxÞ$Eyä™ò
©*’E[H•NH)Úû±qå|F³_~JCˆŒ6Â’”ƒü¸&gt;ÞÍ¹›DÉ‚ü¦È“†‘�±Œ	ëçÎ'ŒöU!UÏøÄ__ŒEEOrÏQ�6zûh„J
R½rŽÄ~(Ò€ÐÞEU{È’,¯EýÇ”]q§G",ô2Æ¡:jM	dÑOG
H%!DD&amp;‡ùþÛl¤›C<gÛË*"¦¨ªm(8¯È�jÕjšmµŠò&�£Šê(¯Åø5djpeyrÁ¦%x+ïÐ‚�z¡¸Ä]|¤q½�‹�¼tý²kÑ º7±`uŠ7ipùŽ¨¨ˆ¹ê˜¿Ã¿—…ð="" ¨¢ˆ¨€ª¾sÚ¾õ[px="" µmÈ´î×¬buŒnÈ¼%Ì•y3}q§±¶w4Ép_*`x�¨ÈlwÁ<ª="" ª°×ª|¿«Îkð²Ù="" «q�Éd·wö¨í*9&;�äâyu�_Â¬hÈêéÆbÈãÊzÙ?�="" À�Ùë‡="" ÙÕŸu…räahªˆ3u="" rÅ‚òðŸ�†á]6«�Âq¶šf�\aiÂ.�bbtÏãä”w<à™ch‰ž="" àmºk k#kmñ(àúxkàê-d¨ÎÉcÕÿ�ò¸âühâ™—Ìò#iì^Þ¨�!*§…t="" ££iû="" ²�Øuµa2tþgŸymÀe‘äqqiØ“Ç®z´bqeuup‘¿er½t="" ‰ñÍ|—Ò¾òa”¤ªaÆ¾@id«gî2$6ÎkÚý”Ðd0_öþ¸@´uÅtñì¸¤¨‚žØ="">•p}S<xÁ%ò�¨Ÿ³ùe¡*{7#9rhö,þ)’`Æ�’õd"^yµ8dé hwÂ¦lÇ"Âˆ‹Œ›x²u]³2ðÙ:æ$w m“uaqâtc\ðžj$—Ê6¤n="" �#¬'ÌŠˆ*¸="" q="">ALR/Ú È±$Ë
ÊöÛlXi¤)¾HÉ·IÆ…çDù1Ë]…¶–m²Ø#ä3^TU0‡ñãÂ˜ùAmT¿\%OQ$õöÏ‘p|¦©b¸#‰ü³Àø6„ƒÓ×iÅ*Ë§c»Æ&lt;¢’^¦h©Ÿ„Äð˜ë
:2µH�cº›“)¦ #RÈûcn!“~?h0¤©b»í‘\3ÆE1&amp;‹�,Öëˆ¢‚‡ìå¦º±ÔÝ@7Vke;Œk/8‘µ6€™¬Œ€žEÉ/åÙ–Û*í}Ù	¢wjó’¤&lt;î4Ê9‘¢8Ýc~È˜¤‰ˆ¸nz`ª"!þ<yÂu¡Äutu\ð žup\tÁnû'ë¯†Ü�Ðó€¤Úª�œ="" Êëedi\h="" •‘qø•�| ª!‰.,&È¢†xî°Ó˜æšŠ.if¸Þ¦ú«Ô2§@ä*É‘5g}‹viÌ‰«»ñ·–û="" ¡m-)ƒ]aœn±€_ˆeøâ—œõÄüb�®h˜Ë)g°¨å�É‚ÃÎ£•¤™&–b‚h­™Ž**©q!ùo�wóŽº="" ˆÙùs‚o‘="">Ì0Ä3‚3ÁÜDôURq\pÅ|�¯ÏêÚ´®(CPAgÂHŒÓ«
QW9Ý¹"Ù­#d„(Žzyu¿”’(©BM¢ª"¼+ò*	ù5hUPÀ
¶«É¯EL}°5AEOâ&gt;p½¼®zþ|cm“ŠŽK¹a¡•rNŽ“Ø±™\íxöa¤jbºHÈû4Ê
•Cuß*n¡…ŠEVf¼ò¶çœ“=¶ÆrJZ˜¦#"oÁ�ž2EF3Žà2Ë9[±ZT“çãk4À‘ã
òTURSOÂˆ¢¿!ZÊ�£ÁG’
ÚyO$&nbsp;ê†*yÄòÓ¾£îÊ§�%%hH›Dõ2ùCù\Àiá	Ê§çÛ?çI3ó‚Hƒ�Ëe´—xˆ²-ä:F&amp;ê”ˆí£–æ6ª®~º“Í×I2�N‚ #ì˜ì�}ÆÛi[DeÕq°BÇ§§†	L…öÙ!™-Ä‘(È˜˜Yû:±b8é‘ƒá•·UBöÿ¨	LEsóŠ^PƒÈ¾Š¨ó¢èª¢mÁÂÊËÀš$ñ:ªªˆ«†$ƒê£žÉˆ«ˆ˜ˆ©ŠªªÓ¤Ò£§€J8N	8ãßúz¢cÎ2ÚËE°zc×®.H¹’ê;ó9‚ð·‹0±×Á±#¼DÃf± z,Z¶À•3Âxq›zOÄAÿc’&amp;£mÎ³~PŒol#Cqq°ÁUQŒjj´Ž‰KVQ="‰°gt�Ç[Fþ”¢îz‡&nbsp;ñ’§�Ï‚Oá|"b¯òtS!~Ð¹Y.Ýõp±´GQÛˆa"ÃÈ=/Â=#È&gt;ê/Ê÷¢¼ö|Ò=ã=aŸ&lt;ïD~ÁDÜš¸÷íª—ÉŠOy OUQó$±ßO`'PQ]S aQ†£{Bn:`øD_&amp;h¯;!À¦¸®úÈ‰ä÷’¤©ùÄAòˆß–Æ?»eè’Bª~I¯Æ!¹áåwÙ¿e(þ¾"xð*iŽ)®ywÛÿÚ¤ÒtÆl&nbsp;ÕÌ�b×�GÈº£{V“¨@Ÿem]_+–èÌïÓºŸ5›Îäj=Ì]„4˜ZÓ“¶�g›ÁèÝ;¢]D¨•³êce[´ÿWI·Ûê•¥LÝŠÀ j‘Ý±—s2ÊžŠöLÎoË§=&gt;óÀ¸ÍŸLÚû6ãWÎ¸‡h¿�Aß¾º}SÒuÝ#¼ý×Üo{7×ï«AiÅº†á³ó©�*5íçö2ëë'X3#Æ�ý¾·\µ;%…ñlÕòØÜo/]°·‡\ôg-wS�cuÖ´�^Á«Ùî°æåù½sÔt=+¶}ÕÜú±i€Õ½¦&lt;ÐOjëúŒkß¯&lt;ö«dÞ5š}†îÎÕêÍžÕ]ØÊ‰Îø®‘3IÙïì!ÐÅâ·[Œî©öC`‰OO&nbsp;Vìq¶G÷ß®ßPÒŠÂ)¿¼	n½t;õDÍ¶úª«b¼“f_Ô³þ¿½«¨¬‹²°¨ÓéùÜIE°—®íVšƒëÆ÷Õµ¾gõ‡AäzÙÞ;¨j	­]í�
—¹©­»³Áä]ìúèÅ…e½RWÃÓÖÎµkêæfÉ2Áú8úþÑ*&gt;â“©Ä.	ÄîzVá½õký?]Ý�‡¨vx“”ÙO±Û3ZÖÿ¯vC°÷Oµ•&lt;5¦hçñŽEÆáÙíå-–Ê\’(
ÈrâL˜®6õÓP¢i‘_ºº•ÉWÔÒj·Î¡ÏùD*[íÓ±L¾î7}f™¯ò®AsÜ&gt;Öµ·ý&nbsp;Ô¾»ÅÜz&amp;Ã½XSóšD›×´uZ˜6‰E½ì=õ{ká=¦~‰õ¿f£¢l»½§;Óî­ÏiìaõóJ¯×ªõ»[]ºïl�ÂønïÙ¢ð¯¯¯•Â´±×´`¹‡rýLê�JÃa×«ìæíÏßëqê`ÙoÇaþa³ÿ€íÝsdÜbZnôÐgXov’mõ­‡Ô&nbsp;ÝvÎÝ¼O‡¤sþÓ¿é!½í—&lt;‹�£ŸïÒäö5ŠÛ‹{íçxÿ•¬ÙO‘;X¾fÂ¦ê÷mçÓkv·—«æ¥Û4ýfè½ã§özÂj^¥¾Õ4'iõÎ¥Þ6žs#–q+Ž»ßº·G�Î¾�ö^‘KÏ¾‘qÚÙnn4tÕnéPv	c]:“§t‡Ý`œ	&amp;ô¡�!zŸvÑ8lHgTé² ìw=šDþ©õ«ê»ÛÏsíßhF›ØïÇd¶ä.§{ì�—´Ùj&lt;Ò)U^nòö'õn]³loÄ²×4HO]lÑ¬9ÕýŸX§—ÄyfèÇ9æ\§M°ê±�…ªHØ´¨úÆÕÜ¶�âñ"9W*-.á¶m_þ—«·¢Ssèá&amp;÷s�O
-$	–
²Õ2žoëzÞ¿±‘ªÚÆ²¹‰@×ÅÐÇúï
êÕ®·¯RØ–Í§Z5æ«_¡Qp‰¹M‡»H•eõê¥[ÙcëuŒ@¡©v¢’“ž×Ð×m¶³qÖák{&amp;–›UVù¬UDÔ·ëÍJÖv£«Ð•£C3.Û°f=_×ýr¹‡mþ½TÈèÝÃeÜ�ÐxvèÚgåú;œžÃI¸ý§æÜE©ßo&gt;Á}Š�«\ýk×öšx�ÿv¾ÔºN›Ð¥5{Å³ìz–·´ýñ·�í¦Ñ¿ô=æ&gt;¯Íõ«^Ãö¿°ôÆo`FŽ^ç±SQÙ]3E¯së;8lq79î»«òmó·ö
‡éT]Z³bÙ«maó¾m¹uý�•ð¾yÇß£@^ç0Ñk Î­€÷ØÎÉ²íVÔ–fÆóÒ9æ¥§s^µö¡ÐùÆ£¦jôÖøµ1+^xæ«}&amp;ó`ÖXÜm^ÖÞ³ƒ´µwÝË�Îž©c's�µÿ—î¿Ü5þÒô¿±ßX:®©"ºÇœ³³¹ÈÖS�ms^Ûµ‹N�¾Xó}zÞ;{�Læt»h›­½ŠØ}vÒ¤NèVö0¹^å²ì?àúž§�éúï=rÃi/_-~MÅÅ?ŸÍ"X[hZ´›ËYe`W›„·ëymvÕÔvãßè&gt;·Su¿»ëk±Ø¤ßn·Ü[ê„ëÙ·Ýþ3Ì$_Cû×ö&nbsp;µÊnSõ[Vß&gt;üì[$zÝO°uû]_‰é°l¶�ÿ\�2ça³XŽþŒ9nOb\íJÛfÜ&gt;¹síG«už¹,ø†‡²ÞÇÚ-y&amp;Ã·»¯õ-òM/æšOlêv±RÝ-¥´*˜×bÞÎ&nbsp;Ö[…­K­Ñõ¯Øúíú	}zé»—õcH­¾–µÑ¦³¯É–�šx®Z;òKwü²¡©zåÔ�ƒ]T�µX°ÝîËkªÙêåm�Ó§9W&nbsp;@þºóýg¤öÝ·›IÔöš-Ê“º}dÔúc]L›Ë%UnÚ¾›s±t}Ê§mcì.óÎu¡Þ:ÛögÆ7�±(+yýæÏ±@šÎÓ¿OwX�Ñ®«›]‡k®z¶§•RÈÛ{wIÙtº{9ôVQ$ï›Ì×4ŠHiYÍo÷ét~SScsöBé5]./\éõ\w�røŸÙË&gt;X÷;â_bþÏÜj¿W¾—Uý€û¥·lÉÎyŸGêoÑëß^´‹]ËªoÝ	½¯`•0-ô}¾SwºÇ¯Ôñ=wì{þ«õG—ýuåý
Ú“]³ãS/5]ãmûc¢÷&gt;wë¯c©ŒŸ^{Å~µÆøæ©M§aˆW÷[Î½QÔNs˜ZÅv;-&gt;¿YÚ~Ân7ûæ‘õ[qèú‡(Ô¹~½
2F3•ŠU”áÃ¸q¬¾Õív+)Q'W@bUMÎåS]*S'&gt;%s3$„	šn¶ÍnÏg±Ù½ûLüac¥Õ3Ìú¯OÒ7
cm×7z~ÑÍuž¿rúT„Æï¡é:ý'1è±£Â�Ò+©ÇªKrÓh½Ý¶Ö+ö&amp;"0þ¨çèH×·f5×Ê´dI°¶�Ú$g«´È3nn…ôIÚõoç&lt;”6°;~änm›6Ä�oºG7Íã»u›	_²]Sj‰õk“Dî½“«ì›G÷nœÚê8Ú­¶ÕþÆØ^X[M]�O8Ó+¯hô¸Mìñ5¹[U­¬;o­PäÛ¿Oû—¢Häºé�™§jMãšÑîóÓ¯5¾næ›ª7«C',šÒu
:½z4}~Äd–Í,›�ú�_Ñ¹×i{¯ì:‡$Ð4ç&nbsp;E
ÐgM™±F‹¤kqã
W×ÇÙ62��]¿9rnm¢ÓÕOÚk*¶GŸ?c—U
›Fÿ&amp;·¦›9Z�¾]^•}²FÁ}þ��þ?®B×òuÄ‰6&lt;Ûì6Ë¨lZ6ïGÑ5½£[™«À™C'dØŒéÑ`ïŸO¶+©;/(îÔ­•g¼ëLröoa±Ô_Û¢Ð•üûe¹‡®ýk­Ó&nbsp;M°ú[Ï"¹×ºUþ¯2ò¶Ïk6.(iõ´£©é»d‘é³^N‘S©U_ßê’í5º^“³»]ªé+?“}&amp;éû®to®û'…j›u¥lU¹É�S¡È³¨´®�'q:-¡â•ËhuªŸîèhØçõýox¢åœ)ÂÖaê+ÓZÐ7ºÇk¿½ªf&gt;Å%ÇºWAé:õ6»&amp;4}£¡Âƒ%ÐÙÏGµúí¢ïQèáU@�LvÔ-×6v7�jÏcxuÍ¾nÀ0!Å…¤OÕê«'5³³1ŠþuW7.F•Ìj5X¶Ó!=‹{¡£�P�¸¡SGþÆWÏM;A‡y0°77¶6õëîKo&nbsp;÷=?·hº&amp;ÝÏöz¸3blE­µx«àÎ™&nbsp;r�C&nbsp;eçÕcy5¿¦Ç—Ð´¿‘ánÝÛ&nbsp;ÔD£çtÎG�·ì3·�
þbk‘´ÝF=gQ¥¨†
Bþ›^íœ}cµõ&amp;¤è×J;›B¡€×:©e[ÖºÞ¡¤ê�¹ûø7Û÷G³²sÞ‹£F‘°Ò›»
cÛu~¬Ýåa¬ðáµH¬ÿÆïDÙçòO¢Ü’@¬­«¢®pÕ&nbsp;m¶¬­aU7Ô{þ¥£Wt_¶û†Ú\¿²tx[@L“±ÇJºÚ‡	Ø‰•Ê|ö¨ëdØD‘0ÜmÕUÒë[µÜÎßi�¯TWíû¯I¼…¨Gfu•ÃUMÞ\µ±5GËê/kê(µý†0ív9¼lÔú”m3�ºÔ+‹I.kÍAóšoê?ÛºÛÃ'SêqX½½+jk´XŒêý‘Í6ÓŽt}gìøú~Õ©Õk¶}nªlt–'@ÖÛ•Scâ¸(š‡-‰ã½V©»J¶á&lt;¢‚wDàPn*lþŒëð!Ø}Tîê9Ã¾Ã•žÅÂi4Ùƒ%u‡¡\vÁÒx’ØÈ°ú¿Õ#Æè¿R÷).j{Í?*æöÝ¦H¹ÖtY»¹¶r¯°}IÍSé&lt;(•_UxdZ
SWÖÞ{ÕÓðh¤®!xBÇ¶JDMûíg5Ò]éq÷+É:Ÿ*êý–×Fú]N©õãšiE†„Šl�UršS×(~R‹FÓ—[î·Ug!ØÕµðjfÖTÿA{Ýµýz†«Y¬é[ì�-º-…í¦ËQÒdŒ©ëU‹ùPŸ³´µŸ]UKÕçÅýËÚù÷Úv–Å|»å¿Û��õÛyv’ioç±±l®Xë?Xåí1ï9&amp;ç¢“U}M‰oìÕ6ØÝæ¹gÏYÙ¿®Ùyû÷Öz‡:™ZÌYÆ•S*o@“¬Y%äµ¾ÜÎ™m¶‹
Ÿ]¥²‡­ê7W;N¹KËmgf¡¤³«˜­@ñÒÂÙ­®¯G²×jvÿþ²Œ-D‹'ãf2ƒˆO:&nbsp;ŠÏÄN:óBˆê|bb¹ºt=+�Å½ìôu¬tO¼ýE¦íö;ªuG9ÔN‰ÕÞÕ&gt;�qýEm5=]slEŽÍ‡eæƒ|Ý€óu6oŠVVB;ýÆ‡[“]³ÁÜá³e^Â–ÍS÷6Ñé!ýµþÌíDîûØ8þ„_^®»O\Ø.¯a°åu&gt;Ë=å�Õ¸6;á
×7mÚKúÌ=sR·•¶ÛÜ[þ“ß$)U–6›&amp;¯LÞ»Öû.ÂÒ¿~—[k²nèQ´›wcQÛ˜}©¼æSª�Ó:C6Á#m¶l)áÙ¸Ù+i6[6vÎO®ísfðË}®}Ðuö6:þ»O­VÔôÞ�|æ©ÜÚ÷wÝt
Úûìx»§Ð»þÔ´ßç½jæ§‡ì•ôPþM˜úa'‚_„×ð96îŽöû�]$]ßî�&amp;ÓÝß~ên[tÍw›÷Îí?œý	ÔëbÃÕ&gt;¸ò¦·ïºUÔñÏígbêwû‰µÅÕþ–UPGç\¿YÔá±F±’VÙ­ÓSöÞøz¤Ã‘ßô:­_BÐù]_Bf¯i‘QÖì÷]»GíÌuÝ§ª÷OÇjï�Sª;ºú÷Îí¹„½õú†¨&nbsp;AN¿öçSÔä�›&nbsp;ö›{ýöYVë¿®ÅNÉ­ÖD%]±KnnÑ~Ý�õ–š|æÎ¾ßüh­di¨õß™{÷¬uZwX;'Ó Ô4ßVrÉ9Žùö1«mµh[ÀXÙIæ0©·h“ê?¼¬YPnª¦Íf}|Ö¾7=I[U7\7�À_ku›;4ÝVQK­¬’Ôzºø²¡CÖ5‡c§gnôu¡+ìÖ…XWßy6å÷æÚá‹O·ÝòåæygØ~§'™}¤‡FÞ�ôû†!}ÕÐJ?CêÝŽû]Ø`jŒ–�æ›^ËÇôn•·ÄÓ+é«B3–¤’îR¼OfÙö9¼±—¡Dæ”{Á¥¦ªÝþëóØ·¶=Ré»'\°Ô#�Cû›½ßÓê:†á¿îv·ÖŽ9k¡už›Õ+ÿÛ&lt;»êä�£°v¯±[w=¬ú±õ÷d�¬ý‡Ýb3÷ëG‡¤ôÞƒÑ5ý;¯h¶²ö—ì¡B²ŽÓ©qñ´1Ü™³¤×ÕÙØ¢íÕÓu7­oèõ‡rê[ªm.j®�šêWãv÷±a;¦žÑ8ye¿Ø�k[Ù×¬ùý÷û}½AcíbŒ)Ÿh+õÐÚ&gt;Ê3WCû&lt;ÉWô¯±çùß~Ÿ·n®Í©ï½¤±èaÒ§uèÝ¥äØ7o¹ÜlvŸ|g^ôOÿp£wÇuûFµBZå-ÕÆµ¥ý�QÎ¤ýSÔ¤ô=ÿïÝ«�\~Õ­›qõÉoÈgs‡Ïª#?2ËEæZ9�/Ð(ŒœyÇ1ˆC&nbsp;ª5`Ëmõí«µêlïÚgV·Ñt=‡S‚ÏÙtí³ëñxÎ±e·oºç­�˜ÕkW£Qn&amp;•õj«éß7³û#¶ÿä_g¨‡EÖãëÝû}æŸYwî‡®ò¯µÒ~òZUQ¤&amp;5nm­ñR55Sçì7¬=³¥*oÚ_ë¿ÿÚ?.~ÝÂk¹[ŠjA;;õNKo°Mñ�7«åòpÛ`šˆ#¨³lQ–$°ãÙÂÒ$$}¦wîM,6ì±Zª1ÇÚîJ•ê2^SN‰'yN}–ªoMñÝ8zÛjþ¡a€ïÙi`âÛú- »HöÞŸå &nbsp;å?{l_Ô$r4Q�£Ù8)¨÷·®³$Ô¢×/ Ù”À‚1A�uª¢š™­UýÓ´¯�LLÔasCÒkõü`±�9béÉz­½5|?´vœ7¶w&amp;ÈJÖjf…:I¬^J×Aw²¢b�ãÅ=^é©&gt;6ây
¨´ïE¿’ºiZþÜ`ÈšÍÐÚ´ÕT.G’ÕY‡÷{ãè˜" ð@Õ3‚4Òc4ížv‚:Î‘vvØœ9SmÊns=Ü"~XÑÓ,�¨ÒuT`-„Ê�H{„¶”+3ÎÐÜiÀ�æ¹´S¾ª°n�×•$mN7ìÏì£4åM@‚“3iOŠrôŒOåÂïTi¦.ššM­zóª7‡L!l�tíŸèšŽºˆ”Ïµ¦ˆª&nbsp;2îl¨‚šD–¢`²@ç+“VZž�à´RÕT˜'w©kù«+í’Úœíè¼|�¸-ö&gt;M/=Õ_Êº£úêp0µ¸§¨¶C©ì´ÒCÞnùfÈ¨$íþÛL²´­ª¿n&lt;•?%Átÿ!gâröÚ…4_pµ±¹jù 9-4û­h¬jµ®Î1ZY™7¢E÷ÞSH›Ñxˆµ
¯lS‚èÔXezwŽ´—‘{Zi½úER&gt;OÆ(UAPŽ¨”ÈSºßp¶+[ƒ¡…°¶IÉk[ÔÆÜö‡F.0~»“ÀáßØ«ãž&gt;ëKÚØ"k6ÛlÂñÝíŠrH�·ª‘Ð/RN˜‡)„€ÔP×‚€Di�HüµF•¦�ŒI¦qØ6¶Õúþª¡&gt;®`ûK]`µTVª™óŽà=†ôò™îöä¡&gt;i§k}Ñ&amp;v·GŠŒíÆÎ£+ÃúöçT�x‘uÛ…öm(
bÄ[6ÂH|z‰.CAí+ãÊ;§æzoTž8ïì˜¡IƒZ6âˆ¢kÈ¹É`-rÓKœÌSßvkQæù-`¨
.ãÌLZ-0Ôù³ "°"‰Ü2ÔÖˆ²Ð
ÅÏÙSD4ì÷è©ª˜Â+ÈZßtn¶]ÎÄó·
á‘?¥³L!¹	ìÝý„“Â›m%x‚v½™LÂØ"Ñ9¨H7K‰¾ÌK|d7‰Ä÷™Lìõõ^u
FS&gt;&nbsp;nÞµPKUPâ&nbsp;æÖÉ3Ü{âäÚÝSÔ4¾š`«�~/±XekmL02û-�d”g‰dÀi«ùv´Ô•E”Ë‹`´¼y¦¦EH8³ºÒX&lt;îe¯Vóùƒû"Ì&amp;´ülîgÔãg(”	&amp;bçôZ¡.dª�¢m¸´=�ÿ±òST.…ëN“a;24Ô7ZáÌãõTçvÛ&gt;ÄM2Í1‰å½¦M¡’š.XqB¦p0žå¤&amp;•È�0…FIÃ
Z6àµEñ†–ÿnn&nbsp;)¬†ÄÜµSPcx.:z©¾Ïouø�6{ i83Ãª`GäãºÌoû
«\){Ìzµ¤‰5¼[’r ššX&nbsp;E­ÅGòâvF^‹ñ6ÜËÄtæz¼Îï¼O-‰©è†§|ìßCäÂÒöDÓ,mTõÏ5úÀ”SP5®ÌÛjo”¶Vè
‡sn	À$ZÐZþA-ÂÜRÛ“RhôôÞƒ‡Û`Þ¸¦"WÝmŠ[)”ÕTÌô]mè€xDs¹ªÀ¤“°•A®‘ª£ã=¬ÝëøêïÔÉZª6Ü´‘¸Ý™Ï!+×ë§�3Î
š&gt; 5È?Þõ&nbsp;jÒn±QƒIÃ7?FZk‰2k·ÝÉ×�N0~‹M^Qæ˜")$gšÒbØ‹Ö�â�n™~hì»jÔ_N]Q©&nbsp;Ö‚$Þ`x-,Ÿ	£¤»eÕBH|×gs-?‰�¹(EyÉÓsBÍi¤
ŸdiZås÷NÖõXÛ—%.6õZ„9ð‹zìZ¢H¼Ïv™:ÔO5[zŒíwdòÛfæv-S«Òå}1Ú˜bzð^EËìä=Ö�ZØ]É=o½×•·&amp;•ü’�þÞ¬¡o^¡M»ú&amp;u¦£|ÖhUSÔç#ÇÕò¥—ŒÓ�˜Üœ'dÕEœ;NÎ‰¬°ºòËjÔà�f¹æÐÁ®ÎH×UBL�Êo–ÁgGä©œ…Wëü±DÖQŒÑc&nbsp;{Ñ%¡#~iÄ*áÕQvˆƒ6ô]…mw$ArÀF|„v£I,ci/3fxmº*ªi�â'†kVOŸE	;XQäž–|mÁj�F¿Ž­;-Ñ¨m°)ßÈÝh§ø—ÿL)QÀCÒ&lt;Ó�;mS`¿#É7Æ\á‚Nì]EÍR´Q§ã¥ÿÅÿ#î¼‰97òP¥¶^Šzª;yÿ*…1¶ÔÔ‡Øçœ4äéOa¹ÑßŠ-±`œ!F6É;=­’Õ}öï¸©¢ð7§¡Kž+ÔZE“ü•1Z~8œL:¢~2ïèž²æôN€¹¢)‹Êa¯vtÆ¢xvLþ[ÊÐi¤¼˜q,�®
—ºÐä„båIFõ˜_&amp;‹fTšQþòŒðQ!±F’Í8‹¶ªŒ%tí‚@õªAÀÿ4¶#M*®ç‚Òñf{›uâm™10È}Ó³T/'îˆ!=Ù&gt;äô˜à£’4ü±$Áðâ¢=22ˆîŒ€¾g”2œ½\‡GÞJ€e‚ÂÜôé'9%=DR2�¬8'¨šŒãÙZÛ&gt;ŒT'Ï„Ö{ãbjÞ®C„Ž÷L.GX…·ªªGãfuä&amp;Ÿ~O!odÄZØ:‚däÆßlÔSÒ›â:HŽ&gt;7¨vŽ¨k¾3Ãí$EFqÝ7F‘Ÿ«ˆ-_% paº.s(S7·ªÑñ»›ðÃnx&amp;3ÎÜ&amp;5(}âœÉjÖª&nbsp;ÌÛñÊtfäŸLdö¹@vºG22Z/¸¸ìµU�äµfÝ“Õø	3ÿ²§/¡%…­zp_eº¡
æÝV&nbsp;\ì‡t`\]�²ü¿“Ù¦ƒz!…·&amp;ÅTþ�AŠ`ãjo”½·!û*#`aÅ‰æ�øYÎò©¬Ãi€sÄ„ú‡&nbsp;¶õý8¾àš¨‹Zôð®ÍÍ1/ÁøS4×páØ¦$&gt;ðšjCm‡¿Q­ö@r/Ä¢06eÝèŠ‹&lt;íOÇ¥®à=J¤’Ã	s‡"6"5�‰ßî7¯êT2^ŸNËE©ºiê.˜0	“±ÙÍ1¿�Û—’Ò ðS mMJu«ûI©)‚e8doÚŒ�¯š¥&nbsp;/Nck�q{#LCsZ¯0Í§4ê,ÙmLbp’’7µÃº4üq«�Ìö@×UE£&gt;Ã’×¢¦Øeµyû(×¨åì€¢–káÑÊÒìÖÏÑ¦9—·$ôÈLnU
ƒžä�c†dMešwÀàQmÝÓÕH‰ŒyÇd·¨ÅÐÐHbÖËÔ–ï¶’²û÷'¬ªFÈ)‡ö±Ü…?5,
úŸý0ä�ÕY”©ªùHE÷£új—÷�¥ŽËø§¯æ|„(óZ©¨5°žòˆš‰€=;&nbsp;ô»çvÆ’Óúßû*¨©›(öˆEëìžhO =_rp'‘æW�ZFý“j<sš”j�‡Ô€‰² w7to�Ö.œ†="" (06½1r$Ãzc="" Ýyo°…È�$�ÄeeƒßltÀ¦øy�‡�<™0‚€ä­u–ggpœ—„ÓÕtv-?Þµvàâf¢k„9£="" �5ÃõŠËû×p’:éâ~ëÈÛyè´Ó+\ bhîû:4šfÎÈ“,nz¨˜x]™pwnwÞžƒx#û)gv‹Ï¦£;ÖªcŠmñ3ššÑÜŽ§"éan‘="" ’Ãq�»<Ÿ¨u(pèå'Ù="">Jap™ÿÙšWª|µ
²8ˆTAÞ…D‘¤ÈhƒWåˆ¼gÑ0E©£rŠš‡þ™�xRù—ü�r}~iÍ�I5åFHêwáÂõ¥ÀÈÏšñq2Ü‘}©éÓP ›A00f#EDß·$)1!0¿2}eÅÂ[û­u-4Û°ZŒF{­?å~Äõ¯é�$?joŠ'e»£M@š�·!û–Ö˜iåÆÁVä¨’¢"&nbsp;u‚Å\6Ú”ELw®�Ëñ†¤	7eª€5E˜¦ù!VV¿èõú1
¢9&amp;¤†ç±8.àßŒù­DæÃgL—‰ Þù*š&nbsp;ÒGY–0’�hVø£ª§ÛÑ…</sš”j�‡ô€‰²></yâu¡äutu\ð></xá%ò�¨ÿ³ùe¡*{7#9rhö,þ)’`æ�’õd"^yµ8dé hwâ¦lç"âˆ‹œ›x²u]³2ðù:æ$w></gûë*"¦¨ªm(8¯è�jõjšmµšò&�£šê(¯åø5djpeyrá¦%x+ïð‚�z¡¸ä]|¤q½�‹�¼tý²kñ></bž$rïæ�®8°ü¯ë€></c7ø€,3n(a^ò6ôëu`]pï></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mathematical-tours.github.io/book-sources/chapters-pdf/machine-learning.pdf">https://mathematical-tours.github.io/book-sources/chapters-pdf/machine-learning.pdf</a></em></p>]]>
            </description>
            <link>https://mathematical-tours.github.io/book-sources/chapters-pdf/machine-learning.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-23645919</guid>
            <pubDate>Thu, 25 Jun 2020 21:27:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Real-time bandpass filter bank audio spectogram]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23645711">thread link</a>) | @afgho
<br/>
June 25, 2020 | https://grz0zrg.github.io/WABSP2/ | <a href="https://web.archive.org/web/*/https://grz0zrg.github.io/WABSP2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://grz0zrg.github.io/WABSP2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23645711</guid>
            <pubDate>Thu, 25 Jun 2020 21:07:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tufte CSS – Inspired by Edward Tufte]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23645691">thread link</a>) | @x32n23nr
<br/>
June 25, 2020 | https://edwardtufte.github.io/tufte-css/ | <a href="https://web.archive.org/web/*/https://edwardtufte.github.io/tufte-css/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      
      <p>Dave Liepmann</p>
      <section>
        <p>Tufte CSS provides tools to style web articles using the ideas demonstrated by Edward Tufte’s books and handouts. Tufte’s style is known for its simplicity, extensive use of sidenotes, tight integration of graphics with text, and carefully chosen typography.</p>
        <p>Tufte CSS was created by <a href="http://www.daveliepmann.com/">Dave Liepmann</a> and is now an Edward Tufte project. The original idea was cribbed from <a href="https://tufte-latex.github.io/tufte-latex/">Tufte-<span>L<span>a</span>T<span>e</span>X</span></a> and <a href="http://rmarkdown.rstudio.com/tufte_handout_format.html">R Markdown’s Tufte Handout format</a>. We give hearty thanks to all the people who have contributed to those projects.</p>
        <p>If you see anything that Tufte CSS could improve, we welcome your contribution in the form of an issue or pull request on the GitHub project: <a href="https://github.com/edwardtufte/tufte-css">tufte-css</a>. Please note the <a href="https://github.com/edwardtufte/tufte-css#contributing">contribution guidelines</a>.</p>
        <p>Finally, a reminder about the goal of this project. The web is not print. Webpages are not books. Therefore, the goal of Tufte CSS is not to say “websites should look like this interpretation of Tufte’s books” but rather “here are some techniques Tufte developed that we’ve found useful in print; maybe you can find a way to make them useful on the web”. Tufte CSS is merely a sketch of one way to implement this particular set of ideas. It should be a starting point, not a design goal, because any project should present their information as best suits their particular circumstances.</p>
      </section>

      <section>
        <h2 id="getting-started">Getting Started</h2>
        <p>To use Tufte CSS, copy <code>tufte.css</code> and the <code>et-book</code> directory of font files to your project directory, then add the following to your HTML document’s <code>head</code> block:</p>

        <pre><code>&lt;link rel="stylesheet" href="tufte.css"/&gt;</code></pre>

        <p>Now you just have to use the provided CSS rules, and the Tufte CSS conventions described in this document. For best results, View Source and Inspect Element frequently.</p>
      </section>

      <section>
        <h2 id="fundamentals">Fundamentals</h2>
        <h3 id="fundamentals--sections-and-headers">Sections and Headings</h3>
        <p>Organize your document with an <code>article</code> element inside your <code>body</code> tag. Inside that, use <code>section</code> tags around each logical grouping of text and headings.</p>
        <p>Tufte CSS uses <code>h1</code> for the document title, <code>p</code> with class <code>subtitle</code> for the document subtitle, <code>h2</code> for section headings, and <code>h3</code> for low-level headings. More specific headings are not supported. If you feel the urge to reach for a heading of level 4 or greater, consider redesigning your document:</p>
        <blockquote cite="http://www.edwardtufte.com/bboard/q-and-a-fetch-msg?msg_id=0000hB">
          <p>[It is] notable that the Feynman lectures (3 volumes) write about all of physics in 1800 pages, using only 2 levels of hierarchical headings: chapters and A-level heads in the text. It also uses the methodology of <em>sentences</em> which then cumulate sequentially into <em>paragraphs</em>, rather than the grunts of bullet points. Undergraduate Caltech physics is very complicated material, but it didn’t require an elaborate hierarchy to organize.</p>
          
        </blockquote>
        <p>As a bonus, this excerpt regarding the use of headings provides an example of block quotes. In Tufte CSS they are just lightly styled, semantically correct HTML using <code>blockquote</code> and <code>footer</code> elements. See page 20 of <a href="https://www.edwardtufte.com/tufte/books_vdqi">The Visual Display of Quantitative Information</a> for an example in print.</p>
        <p><span>In his later books<label for="sn-in-his-later-books"></label></span><span><a href="http://www.edwardtufte.com/tufte/books_be"><em>Beautiful Evidence</em></a></span>, Tufte starts each section with a bit of vertical space, a non-indented paragraph, and the first few words of the sentence set in small caps. For this we use a span with the class <code>newthought</code>, as demonstrated at the beginning of this paragraph. Vertical spacing is accomplished separately through <code>&lt;section&gt;</code> tags. Be consistent: though we do so in this paragraph for the purpose of demonstration, do not alternate use of header elements and the <code>newthought</code> technique. Pick one approach and stick to it.</p>

        <h3 id="fundamentals--text">Text</h3>
        <p>Although paper handouts obviously have a pure white background, the web is better served by the use of slightly off-white and off-black colors. Tufte CSS uses <code>#fffff8</code> and <code>#111111</code> because they are nearly indistinguishable from their ‘pure’ cousins, but dial down the harsh contrast. We stick to the greyscale for text, reserving color for specific, careful use in figures and images.</p>
        <p>In print, Tufte has used the proprietary Monotype Bembo<label for="sn-proprietary-monotype-bembo"></label><span>See Tufte’s comment in the <a href="http://www.edwardtufte.com/bboard/q-and-a-fetch-msg?msg_id=0000Vt">Tufte book fonts</a> thread.</span> font. A similar effect is achieved in digital formats with the now open-source <a href="https://github.com/edwardtufte/et-book">ETBook</a>, which Tufte CSS supplies with a <code>@font-face</code> reference to a .ttf file. In case ETBook somehow doesn’t work, Tufte CSS shifts gracefully to other serif fonts like Palatino and Georgia.</p>
        <p>Also notice how Tufte CSS includes separate font files for bold (strong) and italic (emphasis), instead of relying on the browser to mechanically transform the text. This is typographic best practice.</p>
        <p>If you prefer sans-serifs, use the <code>sans</code> class. It relies on Gill Sans, Tufte’s sans-serif font of choice.</p>
        <p>Links in Tufte CSS match the body text in color and do not change on mouseover or when clicked. Here is a <a href="#">dummy example</a> that goes nowhere. These links are underlined, since this is the most widely recognized indicator of clickable text. <label for="mn-blue-links">⊕</label><span>Blue text, while also a widely recognizable clickable-text indicator, is crass and distracting. Luckily, it is also rendered unnecessary by the use of underlining.</span> However, because most browsers’ default underlining does not clear descenders and is so thick and distracting, the underline effect is instead achieved using CSS trickery involving background gradients instead of standard <code>text-decoration</code>. Credit goes to Adam Schwartz for that technique.</p>
        <p>As always, these design choices are merely one approach that Tufte CSS provides by default. Other approaches can also be made to work. The goal is to make sentences readable without interference from links, as well as to make links immediately identifiable even by casual web users.</p>
      </section>

      <section>
        <h2 id="epigraphs">Epigraphs</h2>
        <div>
          <blockquote>
            <p>The English language . . . becomes ugly and inaccurate because our thoughts are foolish, but the slovenliness of our language makes it easier for us to have foolish thoughts.</p>
            
          </blockquote>
          <blockquote>
            <p>For a successful technology, reality must take precedence over public relations, for Nature cannot be fooled.</p>
            
          </blockquote>
          <blockquote>I do not paint things, I paint only the differences between things.</blockquote>
        </div>
        <p>If you’d like to introduce your page or a section of your page with some quotes, use epigraphs. Modeled after chapter epigraphs in Tufte’s books (particularly <em>Beautiful Evidence</em>), these are <code>blockquote</code> elements with a bit of specialized styling. Quoted text is italicized. The source goes in a <code>footer</code> element inside the <code>blockquote</code>. We have provided three examples in the epigraph of this section, demonstrating shorter and longer quotes, with and without a paragraph tag, and showing how multiple quotes within an epigraph fit together with the use of a wrapper class.</p>
      </section>

      <section>
        <h2 id="sidenotes">Sidenotes: Footnotes and Marginal Notes</h2>
        <p>One of the most distinctive features of Tufte’s style is his extensive use of sidenotes.<label for="sn-extensive-use-of-sidenotes"></label><span>This is a sidenote.</span> Sidenotes are like footnotes, except they don’t force the reader to jump their eye to the bottom of the page, but instead display off to the side in the margin. Perhaps you have noticed their use in this document already. You are very astute.</p>
        <p>Sidenotes are a great example of the web not being like print. On sufficiently large viewports, Tufte CSS uses the margin for sidenotes, margin notes, and small figures. On smaller viewports, elements that would go in the margin are hidden until the user toggles them into view. The goal is to present related but not necessary information such as asides or citations <em>as close as possible</em> to the text that references them. At the same time, this secondary information should stay out of the way of the eye, not interfering with the progression of ideas in the main text.</p>
        <p>Sidenotes consist of two elements: a superscript reference number that goes inline with the text, and a sidenote with content. To add the former, just put a label and dummy checkbox into the text where you want the reference to go, like so:</p>
        <pre><code>&lt;label for="sn-demo"
       class="margin-toggle sidenote-number"&gt;
&lt;/label&gt;
&lt;input type="checkbox"
       id="sn-demo"
       class="margin-toggle"/&gt;</code></pre>
        <p>You must manually assign a reference <code>id</code> to each side or margin note, replacing “sn-demo” in the <code>for</code> and the <code>id</code> attribute values with an appropriate descriptor. It is useful to use prefixes like <code>sn-</code> for sidenotes and <code>mn-</code> for margin notes.</p>
        <p>Immediately adjacent to that sidenote reference in the main text goes the sidenote content itself, in a <code>span</code> with class <code>sidenote</code>. This tag is also inserted directly in the middle of the body text, but is either pushed into the margin or hidden by default. Make sure to position your sidenotes correctly by keeping the sidenote-number label close to the sidenote itself.</p>
        <p>If you want a sidenote without footnote-style numberings, then you want a margin note.
          <label for="mn-demo">⊕</label>
          
          <span>
            This is a margin note. Notice there isn’t a number preceding the note.
          </span> On large screens, a margin note is just a sidenote that omits the reference number. This lessens the distracting effect taking away from the flow of the main text, but can increase the cognitive load of matching a margin note to its referent text. However, on small screens, a margin note is like a sidenote except its viewability-toggle is a symbol rather than a reference number. This document currently uses the symbol ⊕ (<code>&amp;#8853;</code>), but it’s up to you.</p>
        <p>Margin notes are created just like sidenotes, but with the <code>marginnote</code> class for the content and the <code>margin-toggle</code> class for the label and dummy checkbox. For instance, here is the code for the margin note used in the previous paragraph:</p>
        <pre><code>&lt;label for="mn-demo" class="margin-toggle"&gt;&amp;#8853;&lt;/label&gt;
&lt;input type="checkbox" id="mn-demo" class="margin-toggle"/&gt;
&lt;span class="marginnote"&gt;
  This is a margin note. Notice there isn’t a number preceding the note.
&lt;/span&gt;</code></pre>
        </section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://edwardtufte.github.io/tufte-css/">https://edwardtufte.github.io/tufte-css/</a></em></p>]]>
            </description>
            <link>https://edwardtufte.github.io/tufte-css/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23645691</guid>
            <pubDate>Thu, 25 Jun 2020 21:05:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Re-creating some of Hey's features using Fastmail]]>
            </title>
            <description>
<![CDATA[
Score 29 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23645657">thread link</a>) | @nunodonato
<br/>
June 25, 2020 | https://www.nunodonato.com/2020/06/25/a-guide-on-re-creating-heys-features/ | <a href="https://web.archive.org/web/*/https://www.nunodonato.com/2020/06/25/a-guide-on-re-creating-heys-features/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.nunodonato.com/2020/06/25/a-guide-on-re-creating-heys-features/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23645657</guid>
            <pubDate>Thu, 25 Jun 2020 21:01:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Commenting in Popular Programming Languages]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23645241">thread link</a>) | @sjb_Live
<br/>
June 25, 2020 | https://www.sayham.com/2018/03/commenting-in-popular-programming.html | <a href="https://web.archive.org/web/*/https://www.sayham.com/2018/03/commenting-in-popular-programming.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-5395020165244716099" itemprop="description articleBody">
<p><span> Every main programming language implements comments. Comments are ignored by the compiler and this is how a script generates it's own documentation. We know that Good code is self-documenting. We comment once we delete a chunk of code or to prevent rethink. If we build a library or framework, some sort of API documentation is very important to other developers for easy grasping. Remember to comment as often as possible. It’s important! Here is the list of comment styles of various languages_&nbsp;</span></p><p><img alt="Code commenting on virtualspecies.com" data-original-height="152" data-original-width="400" height="151" src="https://2.bp.blogspot.com/-bWzVJOOaKTY/WzvAjoFDMRI/AAAAAAAB0bo/LhjcDC5ucF8JthxAsEK2wFIe2DwOCDfIgCLcBGAs/s400/CommentPostImg.png" title="Code commenting on virtualspecies.com" width="400"></p><div><p><i></i><span id="lanNmeStl"><b>ActionScript</b></span></p><pre>     <span>// Single line comment in Action Script</span><br>            </pre><pre>     <span>/* Multi-line comment<br>                in ActionScript */</span><br>            </pre></div><div><p><i></i><span id="lanNmeStl"><b>Apple Script</b></span></p><pre>     <span>-- Single line comment in Apple Script</span><br>            </pre><pre>     <span>(* Multi-line comment<br>                in ActionScript *)</span><br>           </pre></div><div><p><i></i><span id="lanNmeStl"><b>Assembly</b></span></p><pre>     <span># Comment in Assembly Language</span> <br>            </pre></div><div><p><i></i><span id="lanNmeStl"><b>Basic</b></span></p><pre>     <span>REM Comment in Basic</span><br>            </pre></div><div><p><i></i><span id="lanNmeStl"><b>Bash Script</b></span></p><pre>     <span># Comment in Bash Script</span><br>            </pre></div><div><p><i></i><span id="lanNmeStl"><b>C#</b></span></p><pre>     <span>// Comment in C#</span><br>            </pre><pre>     <span>/* Multi-line comment<br>                in C# */</span><br>           </pre></div><div><p><i></i><span id="lanNmeStl"><b>C</b></span></p><pre>     <span>/* Comment in C. This comment syntax is guaranteed to work on every compiler */</span></pre><pre>     <span>// Comment in C. but it might present portability challenges</span><br>            </pre></div><div><p><i></i><span id="lanNmeStl"><b>Clojure</b></span></p><pre>     <span>; Comment in Clojure</span><br>            </pre></div><div><p><i></i><span id="lanNmeStl"><b>CoffeScript</b></span></p><pre>     <span># Comment in CoffeScript</span><br>            </pre></div><div><p><i></i><span id="lanNmeStl"><b>ColdFusion</b></span></p><pre>     <span>&lt;!--- Comment in ColdFusion ---&gt;</span><br>            </pre></div><div><p><i></i><span id="lanNmeStl"><b>Curl</b></span></p><pre>     <span>| Single Line Comment in Curl<br>            </span></pre><pre>     <span>|# Multi-line comment <br>                in Curl #|</span><br>           </pre></div><div><p><i></i><span id="lanNmeStl"><b>D</b></span></p><pre>     <span>// Comment in D</span><br>            </pre><pre>     <span>/+ Multi-line comment<br>                in D +/</span><br>           </pre></div><div><p><i></i><span id="lanNmeStl"><b>Delphi</b></span></p><pre>     <span>// Single line comment in Delphi </span><br>            </pre><pre>     <span>{ Multi-line comment<br>                in Delphi }</span><br>           </pre></div><div><p><i></i><span id="lanNmeStl"><b>Elixir</b></span></p><pre>     <span>% Comment in Elixir</span><br>            </pre></div><div><p><i></i><span id="lanNmeStl"><b>Erlang</b></span></p><pre>     <span>% Comment in Erlang</span><br>            </pre></div><div><p><i></i><span id="lanNmeStl"><b>Fortran</b></span></p><pre>     <span>! Comment in Fortran</span><br>            </pre></div><div><p><i></i><span id="lanNmeStl"><b>Go</b></span></p><pre>     <span>// Single line comment in Go</span><br>            </pre><pre>     <span>/* Multi-line comment<br>                in Go */</span><br>           </pre></div><div><p><i></i><span id="lanNmeStl"><b>Haskell</b></span></p><pre>     <span>-- Single line comment in Haskell</span><br>            </pre><pre>     <span>{- Multi-line comment<br>                in Haskell -}</span><br>           </pre></div><div><p><i></i><span id="lanNmeStl"><b>HTML</b></span></p><pre>     <span>&lt;!-- Comment in HTML--&gt;</span><br>            </pre></div><div><p><i></i><span id="lanNmeStl"><b>Java</b></span></p><pre>     <span>// Single line comment in Java</span><br>            </pre><pre>     <span>/* Multi-line comment<br>                in Java */</span><br>        </pre><pre>     <span>/** Multi-line documentation comment<br>            in Java */</span><br>       </pre></div><div><p><i></i><span id="lanNmeStl"><b>Javascript</b></span></p><pre>     <span>// Comment in Javascript</span><br>            </pre><pre>     <span>/* Multi-line comment<br>                in JavaScript */</span><br>           </pre></div><div><p><i></i><span id="lanNmeStl"><b>Kotlin</b></span></p><pre>     <span>// Comment in Kotlin</span><br>            </pre><pre>     <span>/* Multi-line comment<br>                in Kotlin */</span><br>           </pre></div><div><p><i></i><span id="lanNmeStl"><b>LAN</b></span></p><pre>     <span>&lt;!-- Comment in Lan --&gt;</span><br>            </pre></div><div><p><i></i><span id="lanNmeStl"><b>Lua</b></span></p><pre>     <span>-- Single line comment in Lua</span><br>            </pre></div><pre>     <span>--[[Multi line comment <br>                in Lua--]]</span><br>           </pre><div><p><i></i><span id="lanNmeStl"><b>Matlab</b></span></p><pre>     <span>% Comment in Matlab</span><br>            </pre><pre>     <span>%{ Multi line comment <br>                in Matlab %}<br>           </span></pre></div><div><p><i></i><span id="lanNmeStl"><b>Objective C</b></span></p><pre>     <span>// Comment in Objective C</span><br>            </pre><pre>     <span>/* Multi-line comment<br>                in Objective C */</span><br>           </pre></div><div><p><i></i><span id="lanNmeStl"><b>Pascal</b></span></p><pre>     <span>{ Single line comment in Pascal }</span><br>            </pre><pre>     <span>{* Multi-line comment<br>                in Pascal *}</span><br>           </pre></div><div><p><i></i><span id="lanNmeStl"><b>PowerShell</b></span></p><pre>     <span># Single line comment in PowerShell</span><br>            </pre><pre>     <span>&lt;# Multi-line comment<br>                in PowerShell #&gt;</span><br>           </pre></div><div><p><i></i><span id="lanNmeStl"><b>Python</b></span></p><pre>     <span># Comment in Python</span><br>            </pre><pre>     <span>""" Multi line comment <br>                in Python """</span><br>           </pre></div><div><p><i></i><span id="lanNmeStl"><b>R</b></span></p><pre>     <span># Single line comment in R</span><br>            </pre><pre>     <span>&lt;# Multi-line comment<br>                in R #&gt;</span><br>           </pre></div><div><p><i></i><span id="lanNmeStl"><b>Rust</b></span></p><pre>     <span>// Single line comment in Rust </span><br>            </pre><pre>     <span>/* Multi-line comment<br>                in Rust */</span><br>           </pre></div><div><p><i></i><span id="lanNmeStl"><b>S-Lang</b></span></p><pre>     <span>% Comment in S-Lang</span><br>            </pre></div><div><p><i></i><span id="lanNmeStl"><b>Scala</b></span></p><pre>     <span>// Single Line Comment in Scala</span><br>            </pre><pre>     <span>/* Multi line comment <br>                in Scala */</span><br>           </pre></div><div><p><i></i><span id="lanNmeStl"><b>SPARK</b></span></p><pre>     <span>-- Comment in SPARK</span><br>            </pre></div><div><p><i></i><span id="lanNmeStl"><b>Swift</b></span></p><pre>     <span>// Comment in Swift</span><br>            </pre><pre>     <span>/* Multi line comment <br>                in Swift */</span><br>           </pre></div><div><p><i></i><span id="lanNmeStl"><b>TCL</b></span></p><pre>     <span># Single line comment in TCL</span><br>            </pre><pre>     <span>&lt;# Multi-line comment<br>                in TCL #&gt;</span><br>           </pre></div><div><p><i></i><span id="lanNmeStl"><b>TSQL</b></span></p><pre>     <span>-- Comment in TSQL</span><br>            </pre><pre>     <span>/* Multi-line comment<br>                in TSQL */</span><br>           </pre></div><div><p><i></i><span id="lanNmeStl"><b>XML</b></span></p><pre>     <span>&lt;!-- Comment in XML --&gt;</span><br>            </pre></div>

</div></div>]]>
            </description>
            <link>https://www.sayham.com/2018/03/commenting-in-popular-programming.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23645241</guid>
            <pubDate>Thu, 25 Jun 2020 20:23:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using NLP to build a sarcasm classifier – Machine Learning]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23644966">thread link</a>) | @JimPD
<br/>
June 25, 2020 | https://techplanet.today/post/machine-learning-foundations-part-10-using-nlp-to-build-a-sarcasm-classifier | <a href="https://web.archive.org/web/*/https://techplanet.today/post/machine-learning-foundations-part-10-using-nlp-to-build-a-sarcasm-classifier">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
                    
                    <p>Previous: Part 9 - <a href="https://techplanet.today/post/machine-learning-foundations-part-9-using-the-sequencing-apis" rel="nofollow noopener">Using the Sequencing APIs</a></p>
<p>Over the last few parts, we haven't done much machine learning. Instead, we looked at how you can preprocess text data to get it ready for training machine learning models. In this part, you're going to put that knowledge to use in training a text classifier, a model, which, when given a piece of text, will understand the contents of that text.</p>
<p>You'll be working with the Sarcasm in News Headlines data set by Rishabh Misra, which is available on his website <a href="https://www.kaggle.com/rmisra/news-headlines-dataset-for-sarcasm-detection/home" target="_blank" rel="nofollow noopener">here</a>. This is a really fun data set, which collects news headlines from normal news sources, as well as some more comedic ones from spoof news sites.</p>
<p>The data set is a JSON file with three columns. The <code>is_sarcastic</code> one is 1 if the record is sarcastic. Otherwise, it's 0. The <code>headline</code> is the headline of the article, and the <code>article_link</code> is a URL to the text of the article. We're just going to deal with the headlines here. So we have a super easy data set to work with. The headline is our feature, and the <code>is_sarcastic</code> is our label.</p>
<p>The data in JSON looks a bit like this.</p>
<pre>{
    "article_link": "https://www.huffingtonpost.com/entry/versace-black-code_us_5861fbefe4b0de3a08f600d5",
    "headline": "former versace store clerk sues over secret 'black code' for minority shoppers",
    "is_sarcastic": 0
}</pre>
<p>Each entry is a JSON field with the name-value pairs showing the column and associated data.</p>
<p>Here's the code to load it in Python when it's structured like that.</p>
<pre>import json

with open("sarcasm.json", 'r') as f:
    datastore = json.load(f)<br>
sentences = [] 
labels = []
urls = []
for item in datastore:
    sentences.append(item['headline'])
    labels.append(item['is_sarcastic'])
    urls.append(item['article_link'])</pre>
<p>I'll go through this piece by piece. First, we'll <code>import json</code> so that we can use the json parsers in Python. Then we'll open the <code>sarcasm.json</code> file.&nbsp; Using <code>json.load()</code>, we can load and parse the entire thing. I'll initialize arrays for the sentences, labels, and URLs. And I can now simply iterate through the datastore. And, for each item, I can append its headline, the sarcasm label, and URL to the appropriate array.</p>
<p>And that's it for loading the data. In previous parts, you may recall that we had hard-coded sentences into an array of strings. We now have exactly the same data structure for the headline sentences, despite that there are now over 25,000 of them. So, for the next code, despite us using this real data set, it will look very familiar. So let's dive in.</p>
<p>So here's the code to tokenize and sequence the sarcasm data set.</p>
<pre>from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
tokenizer = Tokenizer(oov_token="")
tokenizer.fit_on_texts(sentences)
word_index = tokenizer.word_index<br>
print(len(word_index))
print(word_index)<br>
sequences = tokenizer.texts_to_sequences(sentences)
padded = pad_sequences(sequences, padding='post')<br>
print(padded[0])
print(padded.shape)</pre>
<p>We create a tokenizer and fit it on the sentences. In this case, the sentences are the large array of 25,000-plus sentences that we read from the sarcasm data set. We can use the tokenizer to show us the <code>word_index</code> so we can see what words it learned from the data set.&nbsp;And here's an example of some of the words.</p>
<pre>... 'blowing': 4064, 'packed': 4065, 'deficit': 4066, 'essential': 4067, 'explaining': 4068, 'pollution': 4069, 'braces': 4070, 'protester': 4071, 'uncle': 4072 ...</pre>
<p>Remember from earlier that the words with the lower number tokens are the ones that are more common, and the ones with the higher numbers, was less commonly used in the data set. So, of all of the words here, hurting is the one that was found most often.</p>
<p>We can now turn all of our sentences into sequences where, instead of words, we have the tokens representing those words. We'll pad them post, which means that all of the sentences will be the length of whatever the longest one is. And anything shorter than that will be padded with zeros at the end of the sentences in order to keep them all the same length. If we want to inspect them, we can then print out one of them, and we can print out the shape of the entire padded data structure. You'll see output like this.</p>
<pre>[  308 15115   679  3337  2298    48   382  2576 15116     6  2577  8434
     0     0     0     0     0     0     0     0     0     0     0     0
     0     0     0     0     0     0     0     0     0     0     0     0
     0     0     0     0]<p>(26709, 40)</p></pre>
<p>This is the first sentence in our corpus after tokenizing and padding. It's a shorter sentence. So it ends with a bunch of zeros. And this is the shape of the data structure for the padding. This tells us that we have 26,709 padded sentences, and each of these is 40 values long.</p>
<p>With just a few lines of code, you've loaded the data from sarcasm into sentence arrays, tokenized, and padded them.</p>
<p>First, in the code, you'll see a number of commonly used variables. Each of these will be used throughout the code. You've seen many of them so far, but others, like the embedding dimension, will be clear later. The <code>training_size</code> of 20,000 will be used next.</p>
<pre>vocab_size = 10000
embedding_dim = 16
max_length = 100
trunc_type='post'
padding_type='post'
oov_tok = ""
training_size = 20000</pre>
<p>We have a corpus of many thousands of sentences and labels. And, moments ago, we specified 20,000 as the <code>training_size</code>. So that many sentences and labels will be the training set. And we'll hold back the other 6,000 or so as a validation set.</p>
<p>So our <code>training_sentences</code> will be the complete corpus from 0 to the <code>training_size</code>. And our <code>testing_sentences</code> will be from the <code>training_size</code> to the end of the set. We can do similar with the labels. The training will be the first batch, and the testing will be the last ones.</p>
<pre>training_sentences = sentences[0:training_size]
testing_sentences = sentences[training_size:]
training_labels = labels[0:training_size]
testing_labels = labels[training_size:]</pre>
<p>As we've split the data into training and testing sets, we should do the same for the padded sets, instead of having that one large master one that we had earlier on.</p>
<pre>tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)
tokenizer.fit_on_texts(training_sentences)

word_index = tokenizer.word_index

training_sequences = tokenizer.texts_to_sequences(training_sentences)
training_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)

testing_sequences = tokenizer.texts_to_sequences(testing_sentences)
testing_padded = pad_sequences(testing_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)</pre>
<p>First, we'll create a tokenizer, and we'll specify the number of words that we want and what the out-of-vocabulary token should be. We'll fit the tokenizer to just the training_sentence corpus. This will help us accurately reflect any real-world usage. Our testing_sentences can be tested against the vocab that was learned from the training set. Now we can create a set of <code>training_sequences</code> from just the <code>training_sentences</code>. And we can pad these to get a set of padded training sentences. And then we can just do the same thing for the <code>testing_sentences</code> and for all the labels.</p>
<p>So before we can train a model with this, let's take a look at the concept of embeddings, which help us turn the sentiment of a word into a number in much the same way as we tokenized words earlier. In this case, an embedding is a vector pointing in a direction, and we can use those directions to establish meanings in words. I know this is all very vague. So let me explain it visually.</p>
<p>For example, consider the words <strong>bad</strong> and <strong>good</strong>. Now we know they have opposite meanings. So we could draw them as arrows pointing in opposite directions.<img src="https://techplanet.today/storage/posts/2020/06/5ef4f49f02367.webp" data-src="/storage/posts/2020/06/5ef4f49f02367.webp" alt="Machine Learning Foundations: Part 10 - Using NLP to build a sarcasm classifier" width="826" height="91"> We could then describe the word <strong>meh</strong> as being sort of bad, but not really that bad. So it might be an arrow like this. <img src="https://techplanet.today/storage/posts/2020/06/5ef4f4c9ea586.webp" data-src="/storage/posts/2020/06/5ef4f4c9ea586.webp" alt="Machine Learning Foundations: Part 10 - Using NLP to build a sarcasm classifier" width="797" height="349">And then the phrase not bad, it's not as strong as good, but it's more or less in the same direction as good. So we could draw it with an arrow like this.<img src="https://techplanet.today/storage/posts/2020/06/5ef4f501a791f.webp" data-src="/storage/posts/2020/06/5ef4f501a791f.webp" alt="Machine Learning Foundations: Part 10 - Using NLP to build a sarcasm classifier" width="800" height="343"> If we then plot these on a chart, we could then get coordinates for these arrows. These coordinates could then be seen as embeddings for the sentiment of those words. <img src="https://techplanet.today/storage/posts/2020/06/5ef4f5343248c.webp" data-src="/storage/posts/2020/06/5ef4f5343248c.webp" alt="Machine Learning Foundations: Part 10 - Using NLP to build a sarcasm classifier" width="969" height="491">There's no absolute meaning, but, relative to each other, we can establish sentiment.</p>
<p>To do this in code, we can simply use a Keras layer called an Embedding.</p>
<pre>model = tf.keras.Sequential([
    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),
    tf.keras.layers.GlobalAveragePooling1D(),
    tf.keras.layers.Dense(24, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])
model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])</pre>
<p>Our Embedding should be defined as a vector for every word. So we're going to take vocab-sized words and then specify how many dimensions we want the arrow direction to use.&nbsp; In this case, it's 16 that we created earlier. So the Embedding layer will learn 10,016 dimension vectors where the direction of the vector establishes the sentiment of the word. By matching the words to the labels, it'll have a direction that it can then start learning from.</p>
<p>Once we've defined the model, we can then train it like this.</p>
<pre>num_epochs = 30
history = model.fit(training_padded, training_labels, epochs=num_epochs, validation_data=(testing_padded, testing_labels), verbose=2)</pre>
<p>We simply specify the training_padded features and labels, as well as the validation ones.</p>
<p>Now you can try it for yourself. Here's the <a href="https://www.youtube.com/redirect?q=https%3A%2F%2Fgoo.gle%2F3d6sIJY&amp;redir_token=ONe-_plC_prURgXQYxiQIX-HJVJ8MTU5MzE4OTQ0OEAxNTkzMTAzMDQ4&amp;event=video_description&amp;v=-8XmD2zsFBI" target="_blank" rel="nofollow noopener">URL</a>.</p>
<p>Hopefully that was an interesting exploration for you into the beginnings of NLP with TensorFlow. And that brings us to the end of this 10-part series on foundations of machine learning. I hope you've enjoyed these series, and I hope you've been able to learn from them.</p>
<p><iframe src="https://techplanet.today/storage/settings/April2020/08rLYcVZG5uspJE5KPCf.jpg" data-src="https://www.youtube.com/embed/-8XmD2zsFBI" width="720" height="404" allowfullscreen="allowfullscreen"></iframe></p>
                    
                </article></div>]]>
            </description>
            <link>https://techplanet.today/post/machine-learning-foundations-part-10-using-nlp-to-build-a-sarcasm-classifier</link>
            <guid isPermaLink="false">hacker-news-small-sites-23644966</guid>
            <pubDate>Thu, 25 Jun 2020 20:04:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An illustrated deep dive into the philosophy of money]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23644805">thread link</a>) | @LYeo
<br/>
June 25, 2020 | https://moretothat.com/how-money-forever-changed-us/ | <a href="https://web.archive.org/web/*/https://moretothat.com/how-money-forever-changed-us/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>During my six years of elementary school, many fads came and went.</p>
<p>We had the Tamagotchi, a virtual pet that no one could ever keep alive:</p>
<p><a href="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/12185201/A01-Tamagotchi-v2.png"><img src="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/12185201/A01-Tamagotchi-v2.png" alt="" width="1500" height="1100" srcset="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/12185201/A01-Tamagotchi-v2.png 1500w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/12185201/A01-Tamagotchi-v2-300x220.png 300w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/12185201/A01-Tamagotchi-v2-1024x751.png 1024w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/12185201/A01-Tamagotchi-v2-768x563.png 768w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/12185201/A01-Tamagotchi-v2-610x447.png 610w" sizes="(max-width: 1500px) 100vw, 1500px"></a></p>
<p>The Furby, which still gives people nightmares today:</p>
<p><a href="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165919/A02-Furby.png"><img src="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165919/A02-Furby.png" alt="" width="1500" height="1100" srcset="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165919/A02-Furby.png 1500w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165919/A02-Furby-300x220.png 300w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165919/A02-Furby-1024x751.png 1024w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165919/A02-Furby-768x563.png 768w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165919/A02-Furby-610x447.png 610w" sizes="(max-width: 1500px) 100vw, 1500px"></a></p>
<p>And of course, the Oregon Trail, a game that will forever define a generation:</p>
<p><a href="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/12185217/A03-Oregon-Trail-v2.png"><img src="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/12185217/A03-Oregon-Trail-v2.png" alt="" width="1500" height="1100" srcset="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/12185217/A03-Oregon-Trail-v2.png 1500w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/12185217/A03-Oregon-Trail-v2-300x220.png 300w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/12185217/A03-Oregon-Trail-v2-1024x751.png 1024w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/12185217/A03-Oregon-Trail-v2-768x563.png 768w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/12185217/A03-Oregon-Trail-v2-610x447.png 610w" sizes="(max-width: 1500px) 100vw, 1500px"></a></p>
<p>But there was one fad I remember that not only took our school by storm, but schools all across the country as well. It grew so feverish that after a few months, schools had to actually ban this activity because too many students were getting obsessed with it.</p>
<p>If you were an ‘80s or ‘90s kid, chances are you’ll remember it too.</p>
<p>I’m referring to the infamous world of pogs:</p>
<p><a href="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165927/A04-Pogs.png"><img src="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165927/A04-Pogs.png" alt="" width="1500" height="1100" srcset="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165927/A04-Pogs.png 1500w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165927/A04-Pogs-300x220.png 300w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165927/A04-Pogs-1024x751.png 1024w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165927/A04-Pogs-768x563.png 768w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165927/A04-Pogs-610x447.png 610w" sizes="(max-width: 1500px) 100vw, 1500px"></a></p>
<p>For those that didn’t get to experience this craze, I’ll briefly break it down for you.</p>
<p>Pogs were these thin, circular discs that were largely made from one of three materials: paper, aluminum, or plastic.<span title="Some kids had crazy titanium ones, but for those of us that weren’t born into extreme wealth, it wasn’t an option.">1</span> Each pog had a “face” side that had some sort of cool, colorful design on it, and a “back” side that was left blank.</p>
<p><a href="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165932/A05-Front-and-Back.png"><img src="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165932/A05-Front-and-Back.png" alt="" width="1500" height="1100" srcset="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165932/A05-Front-and-Back.png 1500w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165932/A05-Front-and-Back-300x220.png 300w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165932/A05-Front-and-Back-1024x751.png 1024w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165932/A05-Front-and-Back-768x563.png 768w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165932/A05-Front-and-Back-610x447.png 610w" sizes="(max-width: 1500px) 100vw, 1500px"></a></p>
<p>The game itself was super simple, which made it ideal for 2nd graders across the world.</p>
<p>Each round, the players would contribute a few paper pogs, put them face down, and stack them up into one long cylinder. This is the “ante,” or the prize that the players are looking to win.</p>
<p>Then using a special, denser pog that was either made from aluminum or plastic (known as a “slammer” and “pounder,” respectively), each player would try to slam it on the stack, and flip over as many paper pogs as possible. Whichever pogs are successfully turned over would be the prizes they win.</p>
<p><a href="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165940/A06-Playing-Pogs.png"><img src="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165940/A06-Playing-Pogs.png" alt="" width="1500" height="1100" srcset="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165940/A06-Playing-Pogs.png 1500w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165940/A06-Playing-Pogs-300x220.png 300w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165940/A06-Playing-Pogs-1024x751.png 1024w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165940/A06-Playing-Pogs-768x563.png 768w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165940/A06-Playing-Pogs-610x447.png 610w" sizes="(max-width: 1500px) 100vw, 1500px"></a></p>
<p>That’s the whole game in a nutshell. Essentially, it’s slapping dense discs onto a stack of lesser dense discs, hoping to turn over as much of them as possible before the recess bell rings. Seems pretty harmless, right?</p>
<p>Well… there was one component to the game that made it a bit problematic for child psychology.</p>
<p>Before any game starts, you have to declare whether you’re playing “for fun” or “for keeps.” “For fun” means that you’re not actually keeping the pogs you turn over, and are returning them back to their original owners at the end of each match. “For keeps,” of course, means that you now own the pogs you turn over successfully, meaning that someone must lose something if another person wins.</p>
<p>Basically, a nice little gambling ring was growing amongst us starry-eyed 2nd graders.</p>
<p><a href="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165945/A07-Gambling-Pogs.png"><img src="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165945/A07-Gambling-Pogs.png" alt="" width="1500" height="1100" srcset="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165945/A07-Gambling-Pogs.png 1500w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165945/A07-Gambling-Pogs-300x220.png 300w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165945/A07-Gambling-Pogs-1024x751.png 1024w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165945/A07-Gambling-Pogs-768x563.png 768w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165945/A07-Gambling-Pogs-610x447.png 610w" sizes="(max-width: 1500px) 100vw, 1500px"></a></p>
<p>Pogs originally started off as a little recess activity, but began morphing into something far greater.</p>
<p>Kids began comparing each other to how many pogs they had, and started forming groups based on the types of pogs that were owned and won. The kids with gold-plated, shiny pounders kept winning, so they needed to up the stakes and play for higher prizes. The kids that only had paper discs would be off in the sandbox being peasants.</p>
<p>Pogs became the shared currency of the school. Kids were trading their fruit rollups for slammers, their Lunchables for pounders. Kids were literally getting into fist fights over them. And of course, if you didn’t play pogs at all, you might as well be an invisible node of society. All that mattered was how many of them you had, and if you had the right equipment to win even more.</p>
<p><a href="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/12190140/A08-Pogs-at-School-v2.png"><img src="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/12190140/A08-Pogs-at-School-v2.png" alt="" width="1500" height="1100" srcset="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/12190140/A08-Pogs-at-School-v2.png 1500w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/12190140/A08-Pogs-at-School-v2-300x220.png 300w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/12190140/A08-Pogs-at-School-v2-1024x751.png 1024w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/12190140/A08-Pogs-at-School-v2-768x563.png 768w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/12190140/A08-Pogs-at-School-v2-610x447.png 610w" sizes="(max-width: 1500px) 100vw, 1500px"></a></p>
<p>Eventually, the school staff saw enough crazed, disc-slamming kids in the hallways and put an end to the whole thing. They justified the ban by saying it was a form of gambling, but they probably just wanted to see things come back to normal for a bit.</p>
<p>The irony, of course, was that those adults were playing a very similar game in their own lives as well.</p>
<p>It’s interesting how money is accepted as an inevitable force in our lives, yet when we take out the concept and wrap it in unfamiliar packaging, it seems weird and dumb.</p>
<p>To the school staff, the whole pogs phenomenon probably seemed silly because they couldn’t understand what could be so compelling about flipping over paper and metal discs. But they wouldn’t think twice at the thought of coming into an office everyday, flipping over documents, and depositing a bi-weekly paper check in a metal machine.</p>
<p>In essence, the kids were doing the same thing the adults were doing: they were accumulating value in the form of a communal good. But because it took the form of something unrecognizable, it was considered dumb rather than profound. In the eyes of the adults, pogs were shittily constructed paper discs that had no intrinsic value, and only held importance because the kids themselves thought they were.</p>
<p>Well, those kids could say the same thing about the way we regard our own currency as well.</p>
<p><a href="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165955/B01-Trading-Money.png"><img src="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165955/B01-Trading-Money.png" alt="" width="1500" height="1100" srcset="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165955/B01-Trading-Money.png 1500w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165955/B01-Trading-Money-300x220.png 300w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165955/B01-Trading-Money-1024x751.png 1024w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165955/B01-Trading-Money-768x563.png 768w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165955/B01-Trading-Money-610x447.png 610w" sizes="(max-width: 1500px) 100vw, 1500px"></a></p>
<p>The most fascinating thing about the pogs phenomenon is how closely it mirrors the story of money, and how that concept naturally manifested in children.</p>
<p>On one side you have paper, aluminum, and plastic discs that have no inherent value – they can’t be eaten, worn, or slept on. On their own, they’re useless.</p>
<p>On the other side you have paper bills, metal coins, and digits on a screen that can’t be used as ends in themselves either. They’re just as useless.</p>
<p>Yet in both scenarios, a united story emerged that turned an intrinsically useless thing into the distributor of status, value, and prestige.</p>
<p>How in the world does this happen?</p>
<p>How does something with no intrinsic value become the universal determinant of value? And what are the implications this has on human behavior as a whole?</p>
<p>Discussions of money usually come with the implicit understanding that money is valuable, so they revolve around how one could accumulate more of it, or why it introduces <a href="https://moretothat.com/money/" target="_blank" rel="noopener noreferrer">all kinds of strange behaviors</a>. But in this post, we’re going to take one step back and actually look at the concept of money itself: why we need it to represent value, how it impacts our goals, and how it reconstructs our idea of individuality.</p>
<p>This is a dive into the philosophy of money. It’s a look into humanity’s greatest idea, its greatest paradox, and the story that forever changed human behavior.</p>
<p>Let’s begin.</p>
<h3>Money and The Great Abstraction</h3>
<p>Everything starts with the fact that money has no intrinsic value.</p>
<p>I’m going to explain why this is, but in order to do so, I need to first introduce my favorite game show ever:</p>
<p><a href="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165959/C01-The-Price-Is-Right.png"><img src="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165959/C01-The-Price-Is-Right.png" alt="" width="1500" height="1100" srcset="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165959/C01-The-Price-Is-Right.png 1500w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165959/C01-The-Price-Is-Right-300x220.png 300w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165959/C01-The-Price-Is-Right-1024x751.png 1024w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165959/C01-The-Price-Is-Right-768x563.png 768w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165959/C01-The-Price-Is-Right-610x447.png 610w" sizes="(max-width: 1500px) 100vw, 1500px"></a></p>
<p>The Price Is Right is a brilliant TV show where hyped-up contestants play a series of pricing estimation games. Essentially, whoever can guess the price of random shit better than the next person will find their way to a final showcase, where they can win a combination of a potted plant, a trip to Detroit, and a brand… new…. CAR!!!</p>
<p><a href="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170004/C02-Freaking-Out-Over-Car.png"><img src="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170004/C02-Freaking-Out-Over-Car.png" alt="" width="1500" height="1100" srcset="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170004/C02-Freaking-Out-Over-Car.png 1500w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170004/C02-Freaking-Out-Over-Car-300x220.png 300w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170004/C02-Freaking-Out-Over-Car-1024x751.png 1024w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170004/C02-Freaking-Out-Over-Car-768x563.png 768w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170004/C02-Freaking-Out-Over-Car-610x447.png 610w" sizes="(max-width: 1500px) 100vw, 1500px"></a></p>
<p>One of my favorite mini-games on the show was the Bonus Game, where the contestant must guess whether or not the real price of an item is higher or lower than what is displayed to the public.</p>
<p>And the best part?</p>
<p>The audience also gets to chime in and scream their opinions at the contestant, who then has to sort through a blend of aggressive commands to get to her final answer.</p>
<p>Here’s an amazing clip of the game in action:</p>
<p><iframe src="https://player.vimeo.com/video/429124077" width="650" height="406" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p>
<p>First off, Bob Barker had jokes for days.</p>
<p>But second, and more important:</p>
<p>This game is a perfect example of the discrepancy between subjective value and objective reality.</p>
<p>When people in the audience are <em>screaming</em> their opinions of what the price of an alarm clock is, what they are doing is making a <span><strong>value assessment</strong></span> about the object in question. Each person’s idea of that clock’s value is anchored to a personal experience one has with that item, and that could be based on a host of factors.</p>
<p><em>Am I using that alarm clock now? If not, how much is the one I’m currently using? Does that featured clock look like it’d be of better quality? Wait… why do I even care about this damn clock in the first place?</em></p>
<p>From the contestant’s point of view, the audience members sound like this:</p>
<p><a href="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170008/C03-Higher-Lower.png"><img src="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170008/C03-Higher-Lower.png" alt="" width="1500" height="1100" srcset="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170008/C03-Higher-Lower.png 1500w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170008/C03-Higher-Lower-300x220.png 300w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170008/C03-Higher-Lower-1024x751.png 1024w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170008/C03-Higher-Lower-768x563.png 768w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170008/C03-Higher-Lower-610x447.png 610w" sizes="(max-width: 1500px) 100vw, 1500px"></a></p>
<p>But to each audience member, every shout is guided by a judgment that is formed by personal experience, desire, and need:</p>
<p><a href="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170013/C04-Audience-Members-Value-Assessment.png"><img src="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170013/C04-Audience-Members-Value-Assessment.png" alt="" width="1500" height="1100" srcset="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170013/C04-Audience-Members-Value-Assessment.png 1500w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170013/C04-Audience-Members-Value-Assessment-300x220.png 300w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170013/C04-Audience-Members-Value-Assessment-1024x751.png 1024w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170013/C04-Audience-Members-Value-Assessment-768x563.png 768w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170013/C04-Audience-Members-Value-Assessment-610x447.png 610w" sizes="(max-width: 1500px) 100vw, 1500px"></a></p>
<p>Throughout all this, however, the clock simply exists. It is a collection of atoms and molecules that have been assembled to take this form, and there’s no value that is inherent in its chemical makeup. The only function it has is the one we assign it. We would primarily use it to wake up in the morning, but if there was a scary cockroach nearby that we wanted to get rid of, we could use the clock as an anvil too.</p>
<p>This creates a scenario where reality simply is, but the value we assign it will vary based upon the individual that interacts with it. And as illustrated in The Price Is Right, that value is spread across <span><strong>a spectrum of infinite wants and experiences</strong></span>, where one person would be willing to give up more than her neighbor, and vice versa.</p>
<p>For any one item of reality, there will be all kinds of value assessments attached to it, none of which are expected to be the same.</p>
<p><a href="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170024/C05-Alarm-Clock.png"><img src="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170024/C05-Alarm-Clock.png" alt="" width="1500" height="1100" srcset="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170024/C05-Alarm-Clock.png 1500w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170024/C05-Alarm-Clock-300x220.png 300w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170024/C05-Alarm-Clock-1024x751.png 1024w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170024/C05-Alarm-Clock-768x563.png 768w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170024/C05-Alarm-Clock-610x447.png 610w" sizes="(max-width: 1500px) 100vw, 1500px"></a></p>
<p>So we need to form an intermediary between reality and value that could bridge the gap between the two. A way to standardize infinite value assessments into something understandable and transferable.</p>
<p>That third-party, of course, is money.</p>
<p><a href="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170028/C06-Money-Bridge.png"><img src="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170028/C06-Money-Bridge.png" alt="" width="1500" height="1100" srcset="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170028/C06-Money-Bridge.png 1500w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170028/C06-Money-Bridge-300x220.png 300w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170028/C06-Money-Bridge-1024x751.png 1024w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170028/C06-Money-Bridge-768x563.png 768w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170028/C06-Money-Bridge-610x447.png 610w" sizes="(max-width: 1500px) 100vw, 1500px"></a></p>
<p>Money’s greatest achievement is its ability to standardize value across otherwise incomparable realities. For example, there’s no way I could tell you how many clocks I’d give for your car, or how many clocks I’d give for your house. But communicate those objects of desire through the language of money, and I’ll be able to calculate some relationship between the two.</p>
<p>This ability to create value relationships between every object or service is what allowed money to build a web through every corner of life. Before money, goods stood on their own because they were simply bartered for another object of desire. But after money, the value of goods were always calculated based on a third-party: some currency that was agreed upon by all the members of that society.</p>
<p>The question here then becomes: <em>how was that currency determined?</em></p>
<p>In money’s early history, it needed to have some sort of value inherent in it for people to trust it as an intermediary.</p>
<p>Its first iteration appeared in Sumer around 3,000 BC, where it manifested in the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://moretothat.com/how-money-forever-changed-us/">https://moretothat.com/how-money-forever-changed-us/</a></em></p>]]>
            </description>
            <link>https://moretothat.com/how-money-forever-changed-us/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23644805</guid>
            <pubDate>Thu, 25 Jun 2020 19:51:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Racial Diversity In Tech By The Numbers]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 17 (<a href="https://news.ycombinator.com/item?id=23644796">thread link</a>) | @stephen_greet
<br/>
June 25, 2020 | https://www.beamjobs.com/diversity/racial-diversity-in-tech | <a href="https://web.archive.org/web/*/https://www.beamjobs.com/diversity/racial-diversity-in-tech">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.beamjobs.com/diversity/racial-diversity-in-tech</link>
            <guid isPermaLink="false">hacker-news-small-sites-23644796</guid>
            <pubDate>Thu, 25 Jun 2020 19:51:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Laura Deming, founder of the Longevity Fund, on being homeschooled]]>
            </title>
            <description>
<![CDATA[
Score 106 | Comments 183 (<a href="https://news.ycombinator.com/item?id=23644762">thread link</a>) | @mksm
<br/>
June 25, 2020 | https://blog.withprimer.com/laura-deming/ | <a href="https://web.archive.org/web/*/https://blog.withprimer.com/laura-deming/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
	<article>
		<div>

			<section>
				<p>Laura Deming is a biologist and founder of The Longevity Fund, the first VC firm to focus on companies that work on extending healthy human lifespan and addressing age-related diseases through biotechnology. She grew her roots in biology as a homeschooling student in New Zealand, and moved to the US to work in a <a href="https://hillblomcenter.ucsf.edu/#:~:text=The%20mission%20of%20the%20Hillblom,diseases%20have%20similar%20molecular%20causes.">UCSF biology lab</a> at age 12. By age 14, she was a student at MIT, then became a <a href="https://thielfellowship.org/">Thiel Fellow</a>. We asked Laura to share how her education prepared her to lead and build today.</p><figure><img src="https://blog.withprimer.com/content/images/2020/06/Frame-2.png" alt="" srcset="https://blog.withprimer.com/content/images/size/w600/2020/06/Frame-2.png 600w, https://blog.withprimer.com/content/images/size/w1000/2020/06/Frame-2.png 1000w, https://blog.withprimer.com/content/images/size/w1600/2020/06/Frame-2.png 1600w, https://blog.withprimer.com/content/images/size/w1754/2020/06/Frame-2.png 1754w"><figcaption>Laura Deming. Illustration by <a href="https://www.ne-oh.com/">Annie Oh</a>.</figcaption></figure><h3 id="what-are-you-working-on-and-thinking-about-this-week">What are you working on and thinking about this week?</h3><p>How long do you have? I normally have a few key focuses at work (right now, immune aging from a bunch of different angles), and then a billion other small ideas that float in and out of my cranium. My most persistent focus is something that I can’t talk about yet because it would sound slightly insane, but right now, I’m pursuing these more coherent questions: &nbsp;<br></p><ol><li>Is there a flywheel effect with biological tools? Will biological discoveries become the tools for next-generation discovery? How might we predict progress in biology?</li><li>Why does it normally take about a year for the best proto-entrepreneurs I know to reach full conviction about starting a company? What are ways to accelerate that process?</li><li>Is there an immortal cell that doesn’t replicate anywhere on earth? (We presumably wouldn’t see it if there was.)</li></ol><p>I’m really obsessed with <a href="http://book.bionumbers.org/">Cell Biology by the Numbers</a>. I think quantitative intuitive models of biology are the best thing ever. Also <a href="https://www.cornell.edu/video/nima-arkani-hamed-morality-fundamental-physics">this Nima Arkani-Hamed</a> video is literally the best thing ever.</p><h3 id="what-was-your-education-like">What was your education like?</h3><p>I grew up homeschooled in NZ with a hilariously small amount of context for what the real world was like. In retrospect, it was totally ideal. I had two strong memes deeply implanted in my cranium early in life - <em>I love science </em>and <em>it’s my job to do something really important </em>and<em> I can do it, too. </em>I have no clue who I’d be without those memes, and I’m also not sure that the latter was actually true! My dad just always told me that I was exceptional and could work out a way whatever I wanted to do in the world and I believed him. I still do, in a funny way, despite about a decade of evidence to the contrary and realizing how actually hard it is to make drugs for complex diseases. It’s extraordinarily sad how many otherwise brilliant kids might not do things they could because they don’t have a similarly supportive environment — I’m really excited for things like <a href="https://dcgross.com/">Daniel Gross</a>’s <a href="https://pioneer.app/">Pioneer</a> for that reason. </p><figure><img src="https://blog.withprimer.com/content/images/2020/06/image.png" alt="" srcset="https://blog.withprimer.com/content/images/size/w600/2020/06/image.png 600w, https://blog.withprimer.com/content/images/size/w1000/2020/06/image.png 1000w, https://blog.withprimer.com/content/images/size/w1600/2020/06/image.png 1600w, https://blog.withprimer.com/content/images/size/w2000/2020/06/image.png 2000w"><figcaption>Laura as a child, drawing DNA on the pavement outside of her house in chalk, an anecdote from a talk that she gave for <a href="https://www.youtube.com/watch?v=YwslKJut8eM">TedxYouth@Tallinn</a>. Illustration by <a href="https://www.ne-oh.com/">Annie Oh</a>.</figcaption></figure><p>I feel like it was a lot of puzzle solving and doing obvious stuff. And then starting to think more independently in college, and to try to figure out what problems I wanted to work on. But I had this moment around that time where a friend and I were driving to a camping site, and I was trying to explain a math concept to him, and he abruptly turned to me and said “I’m feeling very frustrated right now because you honestly have absolutely no idea what you are talking about.”<em> </em></p><p>It’s really hard to explain without context how actually useful that comment was. As he explained it, I was just parroting off the definition of something. The real way to understand things is to be able to see, explore, feel the concept from a bunch of different angles, and to be able to rigorously prove things about it. I still struggle with the latter, but having an intuition for what <em>real, deep </em>understanding of a concept looks like has been a great guidepost. For example, I realized I didn’t understand what entropy was, and now kind of do, after a summer of being in near tears with frustration about it. </p><h3 id="where-and-when-did-your-mission-to-improve-longevity-originate">Where and when did your mission to improve longevity originate?</h3><p>It’s funny, because I get asked that question a lot. I think of it like this: if you were to watch a million people jump off a bridge every day and just suffer in a really extreme way throughout all of it, How would we respond as a society? An overwhelming number of people would be inspired to take action and help. When you think of it in acute, immediate terms, viscerally shocking and moving. But with longevity and other deeply existential problems, the horror of what’s happening has been tragically normalized.</p><p>I really just wanted to work on the biggest problem possible. At first I thought that was cancer, but after a variety of experiences, aging just seemed like a bigger deal.</p><p>I have a much less antagonistic relationship with death now than I did when I was a kid. I understand more that we are a species, that there’s something beyond us as individuals — but despite that, I absolutely cannot square the idea of sobbing when a relative gets cancer and then being totally fine with another debilitating degenerative disease also caused by aging that we somehow have collectively decided is natural and normal.</p><h3 id="how-has-the-way-you-learned-as-a-kid-shaped-the-way-you-learn-and-make-decisions-at-the-helm-of-the-longevity-fund">How has the way you learned as a kid shaped the way you learn and make decisions at the helm of The Longevity Fund?</h3><p>I’ve had to un-learn a bunch of stuff I learned when I first came to the professional world. As a kid, I was deeply joyous about science. I loved it directly and with a passion, and I absolutely believed I was going to grow up to be like Michael Faraday (his story about <a href="https://artsandculture.google.com/exhibit/people-of-science-michael-faraday-the-royal-society/HQLyLIo6MWpoKw?hl=en">getting an apprenticeship with Humphrey Davy</a> is amazing, by the way). When I entered the world of finance with my fund, I was totally scared to seem like I didn’t know what I was doing, and I felt like it was really important to hide who I was to seem more ‘adult’. Now, in retrospect, I think that was both understandable and a bit of a mistake.</p><p>One thing I learned as a kid that I keep on forgetting so easily is how not to care about what anyone else thinks (with a few close exceptions). It’s funny - even in Silicon Valley, hypothetically the vanguard of independent thought, I feel like that’s extremely hard to do. In part, because what other people think constrains your access to resources. So it’s an interesting balance. </p><h3 id="i-ve-heard-you-talk-about-your-dad-telling-you-at-12-years-old-to-make-sure-that-everyone-was-a-little-bit-happier-because-you-were-in-the-lab-each-day-what-role-did-your-parents-play-in-your-life-and-education">I’ve heard you talk about your dad telling you at 12 years old to make sure that everyone was a little bit happier because you were in the lab each day. What role did your parents play in your life and education?</h3><p>Oh, man. My Dad had so much good advice as a kid — I really felt like I got a cheat code to life early on. It was like being Ben Franklin’s daughter or something. I’m probably exaggerating, but it felt that way. </p><p>One thing he told me was ‘action comes before motivation’ - that’s always been an incredibly powerful thing in my life. He taught me a lot about putting your head down and working hard and not believing anyone who tells you you are great, having that come mostly from your own self-judgment. Being extremely humble around people who know more, finding any way on earth to help them. </p><p>My dad also taught me a lot about humor and how ridiculous the world was in so many different ways. Almost too much - I think I take things more seriously now. But it’s kind of the Mark Twain effect - the world and everyone in it is a hilarious, self-sabotaging, foolhardy place that is also one of the most deeply joyous and interesting things going on in the galaxy. He used to say you can either look at what’s going on in the world and cry or laugh. Why not pick the latter?</p><p>My mom taught me about kindness and empathy and wanting to help others. She’s probably the most giving person I know. </p><p>When I first met Cynthia Kenyon, who literally changed my and many other lives – she’s amazing – I had this very extreme mental conceit that I would beg her to scrub floors in her lab and somehow work my way up on the academic ladder. I was 12. She very kindly offered for me to just work in her lab as a normal intern, which was so kind in retrospect. It changed my life, to be taken seriously like that at a young age. </p><h3 id="i-love-how-you-describe-the-way-the-longevity-fund-removes-limits-on-who-can-participate-in-biomedical-entrepreneurship-how-can-we-translate-some-of-what-you-ve-learned-about-diverse-participation-in-science-to-the-way-that-kids-learn">I love how you describe the way The Longevity Fund removes limits on who can participate in biomedical entrepreneurship. How can we translate some of what you’ve learned about diverse participation in science to the way that kids learn?</h3><p>I think there’s something about being absolutely delighted when you meet someone who doesn’t know something. That feeling is the best thing in the world because <em>you get to be the first person to tell them about some incredibly cool natural phenomenon</em>. That’s pretty great. I still remember being a preteen in Cynthia’s lab when Marc McCormick described how SVMs (<a href="https://en.wikipedia.org/wiki/Support_vector_machine">Support Vector Machines</a>) worked for handwriting recognition in the postal system. He was just so good at explaining things, and that really stuck. Encourage people to own ideas, be skeptical of them, and learn to delight in poking holes in things.<br></p><p>When thinking about diverse participation, it’s funny – before I came to the Valley, I had absolutely no idea that being a girl was in any way a handicap. To me, it was an obvious advantage – in a sea of people who all looked the same way, I’d stick out like a sore thumb! If I could make it, wouldn’t I obviously be an amazing role model? Being in the valley for a while, it kind of wore off, and the more articles I read about how much it sucked to be a girl in science, the more I believed it. I’m not sure what to think about all of that, really. </p><h3 id="what-s-something-you-believe-that-most-people-don-t">What’s something you believe that most people don’t?</h3><p>I can give you a few!</p><ol><li>That we will see the first drug to measurably affect <a href="https://publichealth.wustl.edu/heatlhspan-is-more-important-than-lifespan-so-why-dont-more-people-know-about-it/">human healthspan</a> tested in the next decade, and that this is one of the biggest deals in how we thinking about disease. It’s not just hype and rhetoric.</li><li>That original thinkers are so darn much more rare to find than I thought they’d be growing up. <br></li></ol><hr><p><em>Primer is a new education company whose goal is to help kids engage in limitless learning, starting with homeschoolers. </em><strong>Homeschooled:</strong><em> is a regular series about homeschooling alumni who have gone on to do amazing things. We're just getting started, so we'd love to hear what you think!</em></p><p>Sign up for …</p></section></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.withprimer.com/laura-deming/">https://blog.withprimer.com/laura-deming/</a></em></p>]]>
            </description>
            <link>https://blog.withprimer.com/laura-deming/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23644762</guid>
            <pubDate>Thu, 25 Jun 2020 19:48:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Egui – An experimental immediate mode GUI written in Rust]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23644730">thread link</a>) | @todsacerdoti
<br/>
June 25, 2020 | https://emilk.github.io/emigui/index.html | <a href="https://web.archive.org/web/*/https://emilk.github.io/emigui/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://emilk.github.io/emigui/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23644730</guid>
            <pubDate>Thu, 25 Jun 2020 19:45:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Query-Based Compiler Architectures]]>
            </title>
            <description>
<![CDATA[
Score 104 | Comments 23 (<a href="https://news.ycombinator.com/item?id=23644391">thread link</a>) | @matt_d
<br/>
June 25, 2020 | https://ollef.github.io/blog/posts/query-based-compilers.html | <a href="https://web.archive.org/web/*/https://ollef.github.io/blog/posts/query-based-compilers.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p>Note: This is an old post originally from the documentation of the <a href="https://github.com/ollef/sixten">Sixten</a> programming language, that I've touched up and fleshed out. After the time that it was written I've found out about <a href="https://github.com/salsa-rs/salsa">Salsa</a>, a Rust library with very similar goals to my Rock library, which is definitely worth checking out as well!</p>
<h2 id="background">Background</h2>
<p>Compilers are no longer just black boxes that take a bunch of source files and produce assembly code. We expect them to:</p>
<ul>
<li>Be incremental, meaning that if we recompile a project after having made a few changes we only recompile what is affected by the changes.</li>
<li>Provide editor tooling, e.g. through a <a href="https://langserver.org/">language server</a>, supporting functionality like going to definition, finding the type of the expression at a specific location, and showing error messages on the fly.</li>
</ul>
<p>This is what Anders Hejlsberg talks about in <a href="https://www.youtube.com/watch?v=wSdV1M7n4gQ">his video on modern compiler construction</a> that some of you might have seen.</p>
<p>In this post I will cover how this is achieved in <a href="https://github.com/ollef/sixten">Sixten</a> by building the compiler around a query system.</p>
<p>For those of you that don't know, Sixten is an experimental functional programming language created to give the programmer more control over memory layout and boxing than most other high-level languages do. The most recent development of Sixten is being done in the <a href="https://github.com/ollef/sixty">Sixty</a> repository, and is completely query-based. Here's a little video giving a taste of what its language server can do, showing type-based completions:</p>

<h2 id="traditional-pipeline-based-compiler-architectures">Traditional pipeline-based compiler architectures</h2>
<p>A traditional compiler pipeline might look a bit like this:</p>
<div id="cb1"><pre><code><span id="cb1-1"><a href="#cb1-1"></a>+-----------+            +-----+                +--------+               +--------+</span>
<span id="cb1-2"><a href="#cb1-2"></a>|           |            |     |                |        |               |        |</span>
<span id="cb1-3"><a href="#cb1-3"></a>|source text|---parse---&gt;| AST |---typecheck-+-&gt;|core AST|---generate---&gt;|assembly|</span>
<span id="cb1-4"><a href="#cb1-4"></a>|           |            |     |       ^        |        |               |        |</span>
<span id="cb1-5"><a href="#cb1-5"></a>+-----------+            +-----+       |        +--------+               +---------</span>
<span id="cb1-6"><a href="#cb1-6"></a>                                       |</span>
<span id="cb1-7"><a href="#cb1-7"></a>                                 read and write</span>
<span id="cb1-8"><a href="#cb1-8"></a>                                     types</span>
<span id="cb1-9"><a href="#cb1-9"></a>                                       |</span>
<span id="cb1-10"><a href="#cb1-10"></a>                                       v</span>
<span id="cb1-11"><a href="#cb1-11"></a>                                  +----------+</span>
<span id="cb1-12"><a href="#cb1-12"></a>                                  |          |</span>
<span id="cb1-13"><a href="#cb1-13"></a>                                  |type table|</span>
<span id="cb1-14"><a href="#cb1-14"></a>                                  |          |</span>
<span id="cb1-15"><a href="#cb1-15"></a>                                  +----------+</span></code></pre></div>
<p>There are many variations, and often more steps and intermediate representations than in the illustration, but the idea stays the same:</p>
<p>We push source text down a pipeline and run a fixed set of transformations until we finally output assembly code or some other target language. Along the way we often need to read and update some state. For example, we might update a type table during type checking so we can later look up the type of entities that the code refers to.</p>
<p>Traditional compiler pipelines are probably quite familiar to many of us, but how query-based compilers should be architected might not be as well-known. Here I will describe one way to do it.</p>
<h2 id="going-from-pipeline-to-queries">Going from pipeline to queries</h2>
<p>What does it take to get the type of a qualified name, such as <code>"Data.List.map"</code>? In a pipeline-based architecture we would just look it up in the type table. With queries, we have to think differently. Instead of relying on having updated some piece of state, we do it as if it was done from scratch.</p>
<p>As a first iteration, we do it <em>completely</em> from scratch. It might look a little bit like this:</p>
<div id="cb2"><pre><code><span id="cb2-1"><a href="#cb2-1"></a><span>fetchType ::</span> <span>QualifiedName</span> <span>-&gt;</span> <span>IO</span> <span>Type</span></span>
<span id="cb2-2"><a href="#cb2-2"></a>fetchType (<span>QualifiedName</span> moduleName name) <span>=</span> <span>do</span></span>
<span id="cb2-3"><a href="#cb2-3"></a>  fileName <span>&lt;-</span> moduleFileName moduleName</span>
<span id="cb2-4"><a href="#cb2-4"></a>  sourceCode <span>&lt;-</span> <span>readFile</span> fileName</span>
<span id="cb2-5"><a href="#cb2-5"></a>  parsedModule <span>&lt;-</span> parseModule sourceCode</span>
<span id="cb2-6"><a href="#cb2-6"></a>  resolvedModule <span>&lt;-</span> resolveNames parsedModule</span>
<span id="cb2-7"><a href="#cb2-7"></a>  <span>let</span> definition <span>=</span> <span>lookup</span> name resolvedModule</span>
<span id="cb2-8"><a href="#cb2-8"></a>  inferDefinitionType definition</span></code></pre></div>
<p>We first find out what file the name comes from, which might be <code>Data/List.vix</code> for <code>Data.List</code>, then read the contents of the file, parse it, perhaps we do name resolution to find out what the names in the code refer to given what is imported, and last we look up the name-resolved definition and type check it, returning its type.</p>
<p>All this for just for getting the type of an identifier? It seems ridiculous because looking up the type of a name is something we'll do loads of times during the type checking of a module. Luckily we're not done yet.</p>
<p>Let's first refactor the code into smaller functions:</p>
<div id="cb3"><pre><code><span id="cb3-1"><a href="#cb3-1"></a><span>fetchParsedModule ::</span> <span>ModuleName</span> <span>-&gt;</span> <span>IO</span> <span>ParsedModule</span></span>
<span id="cb3-2"><a href="#cb3-2"></a>fetchParsedModule moduleName <span>=</span> <span>do</span></span>
<span id="cb3-3"><a href="#cb3-3"></a>  fileName <span>&lt;-</span> moduleFileName moduleName</span>
<span id="cb3-4"><a href="#cb3-4"></a>  sourceCode <span>&lt;-</span> <span>readFile</span> fileName</span>
<span id="cb3-5"><a href="#cb3-5"></a>  parseModule moduleName</span>
<span id="cb3-6"><a href="#cb3-6"></a></span>
<span id="cb3-7"><a href="#cb3-7"></a><span>fetchResolvedModule ::</span> <span>ModuleName</span> <span>-&gt;</span> <span>IO</span> <span>ResolvedModule</span></span>
<span id="cb3-8"><a href="#cb3-8"></a>fetchResolvedModule moduleName <span>=</span> <span>do</span></span>
<span id="cb3-9"><a href="#cb3-9"></a>  parsedModule <span>&lt;-</span> fetchParsedModule moduleName</span>
<span id="cb3-10"><a href="#cb3-10"></a>  resolveNames parsedModule</span>
<span id="cb3-11"><a href="#cb3-11"></a></span>
<span id="cb3-12"><a href="#cb3-12"></a><span>fetchType ::</span> <span>QualifiedName</span> <span>-&gt;</span> <span>IO</span> <span>Type</span></span>
<span id="cb3-13"><a href="#cb3-13"></a>fetchType (<span>QualifiedName</span> moduleName name) <span>=</span> <span>do</span></span>
<span id="cb3-14"><a href="#cb3-14"></a>  resolvedModule <span>&lt;-</span> fetchResolvedModule moduleName</span>
<span id="cb3-15"><a href="#cb3-15"></a>  <span>let</span> definition <span>=</span> <span>lookup</span> name resolvedModule</span>
<span id="cb3-16"><a href="#cb3-16"></a>  inferDefinitionType definition</span></code></pre></div>
<p>Note that each of the functions do everything from scratch on their own, i.e. they're each doing a (longer and longer) prefix of the work you'd do in a pipeline. I've found this to be a common pattern in my query-based compilers.</p>
<p>One way to make this efficient would be to add a memoisation layer around each function. That way, we do some expensive work the first time we invoke a function with a specific argument, but subsequent calls are cheap as they can return the cached result.</p>
<p>This is essentially what we'll do, but we won't use a separate cache per function, but instead have a central cache, indexed by the query. This functionality is provided by <a href="https://github.com/ollef/rock">Rock</a>, a library that packages up some functionality for creating query-based compilers.</p>
<h2 id="the-rock-library">The Rock library</h2>
<p><a href="https://github.com/ollef/rock">Rock</a> is an experimental library heavily inspired by <a href="https://github.com/ndmitchell/shake">Shake</a> and the <a href="https://www.microsoft.com/en-us/research/publication/build-systems-la-carte/">Build systems à la carte paper</a>. It essentially implements a build system framework, like <code>make</code>.</p>
<p>Build systems have a lot in common with modern compilers since we want them to be incremental, i.e. to take advantage of previous build results when building anew with few changes. But there's also a difference: Most build systems don't care about the <em>types</em> of their queries since they work at the level of files and file systems.</p>
<p><em>Build systems à la carte</em> is closer to what we want. There the user writes a bunch of computations, <em>tasks</em>, choosing a suitable type for keys and a type for values. The tasks are formulated assuming they're run in an environment where there is a function <code>fetch</code> of type <code>Key -&gt; Task Value</code>, where <code>Task</code> is a type for describing build system rules, that can be used to fetch the value of a dependency with a specific key. In our above example, the key type might look like this:</p>
<div id="cb4"><pre><code><span id="cb4-1"><a href="#cb4-1"></a><span>data</span> <span>Key</span></span>
<span id="cb4-2"><a href="#cb4-2"></a>  <span>=</span> <span>ParsedModuleKey</span> <span>ModuleName</span></span>
<span id="cb4-3"><a href="#cb4-3"></a>  <span>|</span> <span>ResolvedModuleKey</span> <span>ModuleName</span></span>
<span id="cb4-4"><a href="#cb4-4"></a>  <span>|</span> <span>TypeKey</span> <span>QualifiedName</span></span></code></pre></div>
<p>The build system has control over what code runs when we do a <code>fetch</code>, so by varying that it can do fine-grained dependency tracking, memoisation, and incremental updates.</p>
<p><em>Build systems à la carte</em> is also about exploring what kind of build systems we get when we vary what <code>Task</code> is allowed to do, e.g. if it's a <code>Monad</code> or <code>Applicative</code>. In Rock, we're not exploring <em>that</em>, so our <code>Task</code> is a thin layer on top of <code>IO</code>.</p>
<p>A problem that pops up now, however, is that there's no satisfactory type for <code>Value</code>. We want <code>fetch (ParsedModuleKey "Data.List")</code> to return a <code>ParsedModule</code>, while <code>fetch (TypeKey "Data.List.map")</code> should return something of type <code>Type</code>.</p>
<h3 id="indexed-queries">Indexed queries</h3>
<p>Rock allows us to index the key type by the return type of the query. The <code>Key</code> type in our running example becomes the following <a href="https://en.wikipedia.org/wiki/Generalized_algebraic_data_type">GADT</a>:</p>
<div id="cb5"><pre><code><span id="cb5-1"><a href="#cb5-1"></a><span>data</span> <span>Key</span> a <span>where</span></span>
<span id="cb5-2"><a href="#cb5-2"></a>  <span>ParsedModuleKey</span><span> ::</span> <span>ModuleName</span> <span>-&gt;</span> <span>Key</span> <span>ParsedModule</span></span>
<span id="cb5-3"><a href="#cb5-3"></a>  <span>ResolvedModuleKey</span><span> ::</span> <span>ModuleName</span> <span>-&gt;</span> <span>Key</span> <span>ResolvedModule</span></span>
<span id="cb5-4"><a href="#cb5-4"></a>  <span>TypeKey</span><span> ::</span> <span>QualifiedName</span> <span>-&gt;</span> <span>Key</span> <span>Type</span></span></code></pre></div>
<p>The <code>fetch</code> function gets the type <code>forall a. Key a -&gt; Task a</code>, so we get a <code>ParsedModule</code> when we run <code>fetch (ParsedModuleKey "Data.List")</code>, like we wanted, because the return type depends on the key we use.</p>
<p>Now that we know what <code>fetch</code> should look like, it's also worth revealing what the <code>Task</code> type looks like in Rock, more concretely. As mentioned, it's a thin layer around <code>IO</code>, providing a way to <code>fetch</code> <code>key</code>s (like <code>Key</code> above):</p>
<div id="cb6"><pre><code><span id="cb6-1"><a href="#cb6-1"></a><span>newtype</span> <span>Task</span> key a <span>=</span> <span>Task</span> {<span> unTask ::</span> <span>ReaderT</span> (<span>Fetch</span> key) <span>IO</span> a }</span>
<span id="cb6-2"><a href="#cb6-2"></a><span>newtype</span> <span>Fetch</span> key <span>=</span> <span>Fetch</span> (<span>forall</span> a<span>.</span> key a <span>-&gt;</span> <span>IO</span> a)</span></code></pre></div>
<p>The rules of our compiler, i.e. its "Makefile", then becomes the following function, reusing the functions from above:</p>
<div id="cb7"><pre><code><span id="cb7-1"><a href="#cb7-1"></a><span>rules ::</span> <span>Key</span> a <span>-&gt;</span> <span>Task</span> a</span>
<span id="cb7-2"><a href="#cb7-2"></a>rules key <span>=</span> <span>case</span> key <span>of</span></span>
<span id="cb7-3"><a href="#cb7-3"></a>  <span>ParsedModuleKey</span> moduleName <span>-&gt;</span></span>
<span id="cb7-4"><a href="#cb7-4"></a>    fetchParsedModule moduleName</span>
<span id="cb7-5"><a href="#cb7-5"></a></span>
<span id="cb7-6"><a href="#cb7-6"></a>  <span>ResolvedModuleKey</span> moduleName <span>-&gt;</span></span>
<span id="cb7-7"><a href="#cb7-7"></a>    fetchResolvedModule moduleName</span>
<span id="cb7-8"><a href="#cb7-8"></a></span>
<span id="cb7-9"><a href="#cb7-9"></a>  <span>TypeKey</span> qualifiedName <span>-&gt;</span></span>
<span id="cb7-10"><a href="#cb7-10"></a>    fetchType qualifiedName</span></code></pre></div>
<h3 id="caching">Caching</h3>
<p>The most basic way to run a <code>Task</code> in Rock is to directly call the <code>rules</code> function when a <code>Task</code> fetches a key. This results in an inefficient build system that recomputes every query from scratch.</p>
<p>But the <code>Rock</code> library lets us layer more functionality onto our <code>rules</code> function, and one thing that we can add is memoisation. If we do that Rock caches the result of each fetched key by storing the key-value pairs of already performed fetches in a <a href="https://hackage.haskell.org/package/dependent-hashmap">dependent hashmap</a>. This way, we perform each query at most once during a single run of the compiler.</p>
<h3 id="verifying-dependencies-and-reusing-state">Verifying dependencies and reusing state</h3>
<p>Another kind of functionality that can be layered onto the <code>rules</code> function is incremental updates. When it's used, Rock keeps track of what dependencies a task used when it was executed (much like Shake) in a table, i.e. what keys it fetched and what the values were. Using this information it's able to determine when it's safe to reuse the cache <em>from a previous run of the compiler</em> even though there might be changes in other parts of the dependency graph.</p>
<p>This fine-grained dependency tracking also allows reusing the cache when a dependency of a task changes in a way that has no effect. For example, whitespace changes might trigger a re-parse, but since the AST is the same, the cache can be reused in queries that depend on the …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ollef.github.io/blog/posts/query-based-compilers.html">https://ollef.github.io/blog/posts/query-based-compilers.html</a></em></p>]]>
            </description>
            <link>https://ollef.github.io/blog/posts/query-based-compilers.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23644391</guid>
            <pubDate>Thu, 25 Jun 2020 19:17:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TPUG – official publication for world's largest Commodore users group (1984) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23644387">thread link</a>) | @halturing
<br/>
June 25, 2020 | https://www.tpug.ca/tpug-media/tpugmag/TPUG_Issue_01_1984_Feb.pdf | <a href="https://web.archive.org/web/*/https://www.tpug.ca/tpug-media/tpugmag/TPUG_Issue_01_1984_Feb.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><b µÕt¶áu„ãýºÓ¿�a‘¡="ÒÜy-—" ädä]ýlp–ƒ �kÂ;i d3Çßäzeq¥Óúÿý6íá„·Ò¶ª“ÿ@Ÿz!_!»tÓïiéÃw'¾­èdrÐ|†¤="ÿúÈ&amp;l/KiûuãUéßA8éWð—N(„ÿ[^Ÿ#LE-jCÖQ£Õš¸ad5Ç=CA×é}HWÿ¥v²$r‡)ÈC•³*»t×ð“¤á¦M?ÿëÕo}2[ÔŠeMBÄ)9Ì&amp;" ÿúÝ$ú–!^[ <'%kÅ²9="" ´„ÿ}÷}[_†)Î9ìƒ–="4ÐA¾8hmþ—Iÿ÷°©:¥á@Á'¿!!Â;,»¤" ¤—'Õ«Óªjÿ""?§ªÁ\‰ŸõÇÿúá‘d`+¶w_¯§c»t“´š"y�´0¤iÈ‹[è~byq…ôÝ„¿m'z±‘8@Ûÿ^—ÿÜgo}u„j="}&nbsp;°äÑÂ„kÖÒAa¹çÓÿ«_ÕÓ·Ý?ú©n�/ÿÿ‹}ª•D’u~“´v" Ó¬8µmÓÚéÓ‡„bücß»�†öûjÕb¥ÿþdf�]-5zõñ.¶Ë)fôî;x[ÓtžÝzÓ´ýï~ëa×ÿk™‚v°avÕÚ�¡4°�nyeØ0ûk¦kÛ¦×nÚá…ö®ƒm;Ø[†j¿ÿ‘¼îÎü­�v(="" pÊ´x!+ÛûkrÜa&aƒó²|0©o½ûtv•¬©Çyr\§;”?Ú{·øí&ê—ý®ˆÌªž="" ÒÆˆcºˆÓÒiù\¬Ó="" ¦="" 3®íÒaý{‹{{jl’¦¤[^"#ðÂºa�·m¡iØiì="" !i7êýa}Ú­þ="" ­àÃ[º¶:ÿt¶Ýÿƒ="" ¶ûì*lp_øk²,v¥q¯vƒ;… ƒc§="" u­Ê§Úv="ÛjÚûûVý7_;€²nF?ñ½öé�jtžÿ†" l†qµš«b5o§_ü–×î4÷ ­{ßac°iª}¨="" äe^ÔÈf–ßÖÖ×ÿ="" �qÎ9nttöa‚¤ƒzm'#f¥uµôìÔï‰ØgnÍ}w="" )kl0º Â„="" òÆé?aáºiÑ¶Õ¾Ädd.Õf©õk„·ÿðá¬íÁ`–½{b†;xÓùß\="" kpšj2Çmbÿ|5qÈqÕ~ˆ="" ç´ÌáwÚýò&0pÙy°ƒ="" †»ÊÊím÷="" ÓÐvÖý¼5=""  Ô*<6‡þ°`³¾ŠÇh‹!²(å9à±Ánl„ä@Øhg§ÒµÖpØ{ÂiõoµÐøa[="" c!£�›i¹¦="" ›="" ûr'ƒáa•p×kÂ–Ü="" `ˆ.”c9Êe;(þãµ�\rc÷p}b="" 0`¯k="" "(ë{="" þƒ+yt¢+†¢@Â¬8ÿ™Üˆˆpd�µga:ì="" Ù!}6;ßñÞÂ§a‘7ø0¸pÃšþ÷ vcÍzû="" (hÿ;u•ªÁ‚ïª;!a½éÖ‚wê="¦Ýá”áïŠ†Z¤»è(þ¶Aù" ¶ÿÓ¶·="" ëpƒ“§ÝÛ¯¿â”ìz*q+%¾="">"¡�û
»àˆ&amp;ÒŠ¼k¯ù\�7AaábœRÃ
ÞŸ‘Pjj‘ùÕ7jU":Ü&gt;4Ý»XdvG280V¯ð@ÿväh"­I=7Ùå¤ðˆ4¨Aß}Dvß	�šË[§kúKT6š¶8kv@Ô†¥
¤ÛKáw}x·…õßAïîíûÕaNÇMÂdÑÔŒ@CI8×knÞ´ü/aO}ïa©nrM¨&amp;›I4ï)Ag6Èhßëï[ÎômiàªëÈq×éã^RÄx5C‡h^Î&nbsp;€ƒ[P˜AÓÖ¿Ú·Ã}9
9\aÍe_ãþûð�µ h Øa;ƒ�øØ|;Ûz¯á²)QÀÏ±W•–þœDDjð_ü„ïªB&nbsp;á+­çzä	°´Ð&amp;]¶;k&amp;a�+øbšw&nbsp;l7ï\2¤€«ø&amp;þè'A:qO
4�`èj¢Ø2íÿk~ü6ÇD?�Wõ&amp;ïõNÓ„ö
�p·TÛÎìÿ¿‡È8o‚eÛéä‹¿ÿ
íÃ
ƒ-Ì¼'Wv&amp;“]µü;J­{Ø5ƒo‚ÃùÙÊƒ×û†þ5Oµ{Q
u¿aììàš]¤M�(aÃY
ŸÒÃ{OMÂþ·î“é?-êäÈð†yh‘¿!-“–?á…�SÚ‚F/­ú÷�Ë42™Û™þööé2Ü”VC@åAP“}99„òNßúÞ†JØXlPo­ºÞKbþÕ¾Ý"“n‡ÏðÚAP7_ÓnV,Âê”‚[ƒþòI,NÖaºïûvû©ynp$¨Rnýaƒ[þÕ;ª�ƒ´•Œ›¶ŽÜ2úôG;[×ÿÛïTô@ÿØÖÿrƒ§û&nbsp;ÁÃ	$ÒvÐ?ý(§Õÿ»~ì$¿…†Þ�l-¥Mÿ#Ø‹~ƒ�k¶�¯Þ“;¬([»ñ*wj°ö¹\P)zwþ¯ä@è@¯Ø4
´˜ ¯íÃñßvÕB½¥Nüi¸M&nbsp;øa¿ÚL ÎÍs´€PDõ°¿»VÕwk®d5ê÷„šoZiXAäò–Õ‚ûQM©z|2|�ÿ¿§ÎõýÝ%"¨'TìÏZ¿Ž›mpJ”4ò5dëgf°†÷ÕÓ]b?Ý®ù
rµoøi…V´íöèaß‚Ml'…½·Þ’ �Ë´ï{ÿÝòÓ.?D†!×Ø30×Zî÷ÿˆè A¦Ep�„þ¶ha¾Ø0T×v;Á?Å¬&amp;N?IÂoè„µõn–� Âè.ƒox¤�;¦&nbsp;ËŠ\;5ÿÚÔ íjÎÕ‡ï
•XN×½¾¨&amp;ía&amp;Õ¿ÂNž¼Eøk¥êœª‘›/‘Ã*¿]¥�ãý+£¹ˆ‚;85;§XiÞÝ$òiÕ'þ&lt;$íUÂz¬‡ÒQ½…v�_cäTà�ieˆìtˆ_'TA"Ðý'­Zö—"Ê÷qO5„!2¦—n¡&lt;�Ì#/¤ÿøVÚ^÷a^má¦'TAsc+NžÝzXxÒ„ÿúX0¿ñÕ0¾„aÖ �ì ÒíB„õ·Ân®C›ˆMéHH²9N¯w¯º"À*†l„™6ë­Ø*ë~¸IÈ‰Âÿ¤ÛZ«|‡oó±P•}ÐµíbNð×ˆÓÿ«p–_ýS÷Âº‘·!ƒt�‚�­°ƒ\Rë÷þKaI“×ÿémZÈš‘®hS„'hì
&amp;ðŽçkétKúêJÿÿ½„¤ËÞšÐrUÞ4“½„šßÂè_é*
÷ÿÚÓ	�¨¤Ûl.Ât
‹vˆ".=S|·DÿëÞõ‡ÿÿIZŽ¶¡4äNƒc¬ Û�”0Èd¨*w`ˆR_þÕw§ÿ–i¤K;Ô4Ò¶!‚M:m5A2;Ð1ròÝ‚¢Ó–N
C?¾@‰’µz¿ÿM†
/ÇÓÃÚpƒ`ƒApx´	ä+“�ô
‡¨ éõ‘ˆ½õ»A5ÿ^)NÍSTì&gt;Úä8æNv
„Á�a?©&gt;qÁþ�z×ØUñ	ÿ½Û¨°¾¦-±øA�ˆ×¬?&nbsp;�{v\%}¥úÿmiZµ`ÖB‘úuL)Ð[þÂ[ vÇ^Ã?ÿV�¯�^µAƒ @þ¿¾wÝið`‘*?×ÿ,ª0“A”²rfn�Z–æÂ¾äR
§iÇíìŠ?Iuoþ0ƒ)ÿ_òË¨bA�Ëøa
iƒ!Rš•Ò&nbsp;™Þ&nbsp;›;Q¯á0¶
WûG�¿RßÝk´™á‚µü4#UÎÇ]Ó_ÓTÁäŠá{ö¤{Vë½ÓA&nbsp;Ûõÿ»†¼ }7ð_‚È|�Š$DäU�ì3@Ç¥Úš§­=¤ÓO°’ÿ&nbsp;Ýƒ/ì[L'Óý~$;l!–»Á�Â
ºÂiS]�ÂBXÌ‚©¶‚&nbsp;ÌÒ „�ÿÔ�Kk……G†vR%6úÈæ§&lt;T®ª0ÙÐÓ~®4Ý‘ìx {Qi·¯ö¼2Ü®jALµµêð‰qp¸N¶ÛþE,„ÜWÖµÓØH]Òÿ&nbsp;pIaS+­ûÁ§ ›�š†UPm°\©ÞŸÒ…¦¿KïMCR;½ïÓÔ&amp;h-¦­Zr[°QÃv“ªí´7Úúcý/\-�\aÈGm×þ�%„Ýµj÷…­¾Á*ÝÝ¸ë;ºÏmm­}ŽTÍ!¦Cþø_ééUÞ­Ztê­7Ó`ˆl¿í}}èzKú�lw¡Ó&nbsp;‚„Ÿá…rßzŽØ0“é¸íõ¦ˆâƒ}†«¾µÐl&lt;ú!ž�(IÈJÈƒ•‡5Âd¢ÂÕNøom!œÿû¥{„GŠµ¯µ»þAÄ1J¹ `„CàÉ7¥†ÆÒS·+L&amp;I¯íºu ‘Ðtü,Š\¢áXS¼¿qô6’H…w]ã!ô!ôpšÚáwM0Ð† …õ2Õé¬‹†²C{KGTþ¿ô6ª~—dÉ§é»T“;€„‚HÊa•¾waun‡O]ú°¾¿ÿ¤ôáz§­Ëqj�›Âh&lt;0»PA¦“µ&nbsp;êÍ‡ØLšRº]ï2-ÿé´ºÚ¤´¾¿`ÂÁ&amp;ƒMA…xH ì+Áiñh{d÷J¯™†?Ò––#ÑÞ·`«ºlU&amp;Ÿ�áxÓ�¯`¸|ˆï*ƒ&amp;RôÃPD›iþ›AR+(´àž‚_ý'Ý¸`º	Å
¯Mâ6`¿
Aÿ§	6•T–ÈjÓ[ø+Zvîa†Sï§ÿÃï	|3‚ÿÕ´ªUj#÷íi§mÃ
8tƒhíD¾¾ZÁ¥ñ§ÿN´”xi×åp°Xk�ö÷ÎøÞ—+JÖB§)È²Óyeìp›î{ÿ¥Z�…ëµÁ2q�–Íƒ·IÒ
VFL/‘yé¦WLôÿéÒh+Xa&gt;–ÂÒpnpé�ÐêA�Ýz×ð�¼²þƒ×I¤ÿû	5ŽW%nØ5�%»i†7a"=Z…óµ0Å­øv»…otý:OáÆÐ`›N©Ý½AÃPHnï�‚ƒÃ÷a{í'þ� ˆDÂQºœ mùTZ~ôö˜qAä]Œ"x$&gt;º@Þ·ÓŒ;`·¿ÿÚI°‡	û‹«¾Ú�K`Õ&lt;Dl²»„ûzxvDÅµmcGÖ‚²YáÜ(Múí¿Ë†Mø»A®ùd&nbsp;jîØ@žÔípoÿÂäÜ&nbsp;=]Ò!È!d ïÚ&nbsp;°pé=^)°×ðžì0‚¨0�‡„
ÿ½$¡‘¨mÔŒº;V£ßoánõµºpÖý=Ã'ct?ÿh,'&amp;Ü›zI²±&amp;µí¶¾olqAÅ0ý?B®ƒý$¦UH:MÚ§íd&amp;5¯ké7µÐ~*ÐOÿª��É„ßx*m5_T#÷Ëu¶e\›PkÝa&nbsp;ÒÐoþô4ûÑ£KuU÷ú«NAèPi|'	„©?ûýªµ7½…îÒJ¼~F1A�¨´B´Çò2ü4%¯þÒÕSz¹	&gt;Ü28OýNà%pÓè6~CêC…	¼0]7ÿ«Á›F�d+¸N¼uÆ—çxïA�ŽžX@Ø`šäjÉ&nbsp;Þ‹Jÿí©nH,F‚»jÝý7_çc‡uAÓl;AÅ®^d]á†µWÿixXz}%‘hmÍé]¨D‘‡„é°Ã†FN
¿í?ƒ „1ßý½î»^¼(MjµLpÁ±¤ø·àÁ¯ÿÚ¿]•(“·öéº‘% .M†7xpßýàÃÿþ_]õ­°´íµ7pÂIáƒªs·/ÿ{ÿØV«wOøiÓ]=è6Ì°oÛov¯Ã×ÿª¿þ%Bô›š†C·~=ål1ÿðv2-•Eý…:~È&lt;ò&amp;ˆC·IÕ•¯ºîv£ð¡ýÿM(!ÿ�”`ƒµŠD‹Åáºgd÷D&gt;SÃÛñMd)Êò®×þÙáPãMö¨6ïKmBdíÚ°ëuõˆŒÿÜEmõîÕ§l[©ÄÇefV¡P}Aƒ‘*!6)zïÞÿòÊjË“Ov—Ý5A²¶!‹réáAQáoi,7j8 ~ÂEm¯ýøˆÛÚ¾ØZð˜A¦Ô*ÛÓ*ù:&amp;Áè;nÂäroMwuÿ-*~&gt;¡¨ho	”±
HìÕ­D$·µj·�†íøñßõþu¼0H0ž„ÊA¦£Xn†ƒï@Ã¦îÈ™~¿kþvßÓ
×	pƒð_ã;ó®ðÁµmèV¸ÿú}ÔŒ&nbsp;(&nbsp;a-]'x-o�¾bÿ ìÿ«	í¥þ™‘íê¸2.Äôœ$õÿýÛÃøû_òÊ¤“µn4=,$á‚`µ¿û@ÃÛY
Œæºä†w*›_òÈ–�ié;TÒ¥!ÝÂã
w�}sµkº„{ä4%ár¦W2Øa/ôôá…
5µè'I&lt;&gt;ü¬Á=Õ
­ì!™·ÉÊæ+µÿµ¸ÄE¢ÜÑÕ+Ò!ã…?ém½d�Ï"¶ÞÈ44d{	ûV%þªˆN&amp;ü0“ÿéì&amp;ßU×aZµ†‘)‚Ÿáuû àÿí……AºiX\-R|*{k!ÃVŸþÃÉh4§Õy‘%òh¿äA…v°ø`”‚á­W¯OÂÉv­Õ
Õ†¤,?…÷jkLWüF–äÌ%b‘u¦7^½€0y„ÛŠ&nbsp;ÜÑ°ÑÓC‚°ÒA¦;R×¬2:	‚
ÿúðƒ&nbsp;@Çõ­%¤ßÓÄFÞ1ÈgQxÉÖ±
¯ûöÂA“a&nbsp;�¶ÒW­‚‚ÓnŸÛª†Äè7Â
ø/°¿úÜ ä›†™@©-¯kR=p†ï¦îëd2º,¥ÖÓkÿý93e¶[‰¬ é8¥ÒX"l$Açn…·nŽÎ©Š{,µ
L|ÈÔ=¯ÿôé2Ü×Nz�ÉÁm%ÃaàŽ¡½èl&amp;PäÌ­28éŸ$7þ¿ëôéSNpÍ��ÑpÎ�+T›ám×NÁ"´�³ÁŸMm6¿°¿ëu¾þ“b";k¥vÃ‚w`´„2¶€É°@oA„œ1¦ƒA�ûA¯ùÛªoD"�ð½ZÝiÎÜ-6at(0�Â
6,‚é5Oßh0·ù6æuIš9
w…¥ðÐÖ8`éÌ“Ü‹RL'!—³ ¬ê.ƒBÕW�µ\ d6¯ý[&nbsp;�Ù=d,7Úi«=ÓX é„JBRÈË¸µù-‚‘›ÿ·H ÙKqÒAÛÁ›càÁ×®
¦�A¶=ÉeVCUÊrÇ*Pÿí®à�Â­¬CKÎðz»gjäÐt‚ê€ïNƒ �õDQ„Dkþ®«Aá×IÝ¡X=ÎÇ†›"m;	æCbÈl§,“åÁt�Ùu„ÿø»Tá:¿\4ÂP¾þˆ8ý¡�1­‚(©7_íÕ6ƒW¾”®*C@½
ü„öƒ/ðƒuÓ�ÿ^›ík“bÏ›R1ëµJO+è&gt;·¦©ÿÃM^�Zgx@¼'Ü*ˆlr‡e~Mv»NÿÄFUOx+U†MŠ	×N“Ž¶ä0�&nbsp;äwÐãÙ’x©ÿãÒü„¢´’°™ÙÁ	6’§¥Öè‡VÉ!¦æa³ë_{_òÊ9ü‰ÛY1�†&amp;˜A„Ä Vºuêí&nbsp;�²
v·`×ûú”¢ÿð@ÉM‡íi—mÖ�¸&nbsp;¤ÛPÔLaj©Â^¾t#NÃ`×!Üî{-×ßàƒ!–¿è4v°°öÃm('&nbsp;Ð&amp;)à^C�£•Ä]�Òl á°Û5#VHoÚGvð�ÿúií¥íáiÞ­4ê#D&gt;®Ojš÷&nbsp;á9
°Ç„×V¡]u–ª×ý&lt;,5Kvý¶¨*i��˜ œ é5ÿ¶ƒƒ¶ÿíƒ;XKÿaX`¾íÓNÑo¨Hj™ß‡
,&amp;ö«½ éÈ7Èþ0ƒµa íÓp²ê¶î†Ã4äÚ`ƒ«è;A…!¬9à&amp;þ§þµa……Á˜G‘´aÈàÇþØV+÷¥ �¢dÝáO­¡’¬ŠŸZíÛcý«&nbsp;Ì‰«’YvæíËp&nbsp;]ÿ-Å§
b}PtAÝ&nbsp;Îæ¤œj}­jvŸ¤Ó!tU"ÿ"t&nbsp;‚µþ"!ƒ”ª°y	ôÁƒ_o&nbsp;ÛvÞAÝ�–o�í'{ûÿôØpZ-æ×NH˜B‚ÛJOlÕeyúMñú!&amp;LyØP-ÌÏßÝ?i$¿þžÂ†·Kµ_þA´ÎÃ$4qÈx*fp^�S·IuG…
A@äQÊÝq´žõ®¿ÿmÁZÓ[^éëº·L;%±2m-þè,892rWÞBy7Ý¾—ÿ»å¸Ø(0Ø+l%fhøZOýªÝAëÎÜ=ãNÝ}m†"”`yd[á¨têÂÿÿü N'Ž#ÎøÓÿëyvøAë÷_NàÁ fªôØaIƒ…†á¨kK¿ÞÛÐ,oÚ;py×ªívÑäÞ­Mp@íWn¿Ý¤CAË&amp;vÅ6–þÕ¯ÿ¿Âë&nbsp;ƒAIã·÷þÝßÓ_·…ô¸n
}5§÷ŒMÒÈl‚,?ûv¬&amp;ëœ*ãÚ¿ÖêÒL'»	ÿÛƒ¿ö“­²±�;‡Þ5JFœ!~ý·ÃWXA×tïÿXl8¶º
ý¦ûmÇö¥ïOÆÂK_þÃ´�†õÚXqþ½-ûISÝDmo~È(
-;ÚÓZßþ!‘ÂÎã$÷ªN»½+úÝØ0Lœ?Ú]n“l7ã/«þ‚ëÿ„(·+;Ën0Š9Ç&lt;Ñ60"~çeŸ
}cOµÖüìTÙ?
üWîÓ¶º_ýXz�Ô&nbsp;‰r†7oVã{	UØCOµ;€�ºjƒ»d3/kêÂízÿô´íNw[’];«†¿òªÚ‚kú ßí”‚Êà©õ­G’Ì4:ÿê&nbsp;Ì%ÜDŸÓßãÚÎËu‚eãá„�=x`”=°l²à6{	¶éòP†ÃX_ÿ‡ ÀämíZ
·ÿºnµ×Jƒ²&lt;¥C(6Òn8¶ÍA&nbsp;²Ì5&lt;|/!\±Ê‡ª˜@Æ¿ý ²
éQtá¿°¯^ïEb»¬7'µ�wþò(°·#¬ áˆUÿ„¶šOé{tÝZ}¯[Ö�…n°íé2p—Ó^šüˆ@ ¶Ý7ü[uu¶º×o´›
+i‘Žü…Ðˆ´“}*Ý;ÿÁ °[NŸ°»´Ý=‚ÙAd9C�`sàUôÕÃ	·L#á±—áäÂi6ééuÕð�X-.íÇ‹ð®*ÑÌ"8e².Æi;
õƒX‡öá'|ý¶šÿ¸ V·&gt;²Ÿ}bí_Âý¦•\%¸L2@z
ô„›ÔŒ…ý¸OÿÂ	�qÌ9ÁmJX¨&amp;]ëoÃL'­¯Ä0¤n÷a9¬…®ºÛ…ˆÖC»4 »†ýÐR`Éëåd…Aµ{¬Fëÿa GP‹BÁ6!öž“n’
×Á
¤Ã
ÿ¼*ò$
Ì…:Ýöën®»Á‚„
¶Iâ|}öÝ…A¿ªw(ÿÆOaè…ƒ¬7ÓuO[O©�¡ÓƒBï¶•m0[ckW„˜_í=PO�o«ÔƒA$Hs'XÞ�ÂlC¾ºM»þú_ø6uëTt×ýáI•¸�i»á—îrÖ�ï¬_WwI¯òÊ�ƒLGa4½ö­0©í2±bP®0ƒðNÿ^í{ÐU&nbsp;Áƒè&gt;›[¶¢4Þ·Œ‡„]IÐ ÎÉSOmå“?KN¶ý?÷ƒ
h”A_ö–ÿ¬˜?&nbsp;Ðµ§õÕ¯è&amp;¿Ô1»
¤CÓü0­&lt;;´è;nŸÿêê¡aœÝ­5ÿ‡`à&nbsp;�BþÁ‚�ÈI’‚µÛn�e)ûì.Ò¾ŠXBØØ;ZkýC†½†{Öø? ¤R:w„¶ºE¹“!lÈ~ðÍY-„•ƒ^,%L/òËc#Œ·%$ß«[š„nMÛtžþeøŽ(*iíGD
ÿ‚‡NÜ0“‚‡•°¤ƒv¡'�‡S]zt{ôáSºÖ‡ü(tÚ¯Ž�ïA„ˆeî1úê�÷ûJ�ÓK_êá1öö‚
oNÜQ!í¯òYþµïÒ¯õp»}4™K¿[áì$�¬ÿL'½¦ºÿV�.›¦¯^“Ò‚ö-¬_ôÑ©+bÂJ¿ÔBî�„škuvV|·Ö§Øa0NÁ_~ƒd+ÉÅ;±Z¯Â[�§W¦–ÂÈ&nbsp;ÉU­Ó´éùqÇ"À?áý6"±U
¿è E¸:íÐa'O%Åi°Ý¤»ásá—ü‚Zá0Â’TŒÑ
È6@Û¤Ý„N[qßºt!¹àö¡RévÉÀÆ¼””í¸A�_ò6A@‚zâÂDþµÃtÌ ¡vä+ž„*ÎÛïê¼'�ýBM´“ n¼%]6ñ^�Wä�×l×­íÿéBAÃMPAÚ­Zo»Ôzl×öõ¿ü:pÂ!�ðƒiâîý(V«
½û¿I¹\§ÿh0ÈrÄtô—ïØ-í7[¼x¶úm'ÿƒµÛj®ß£³¢èíT.¦¼y—;�AÖ2v¾ïLü;D+•Õ&amp;Â�:ÖíÕø&amp;
Ý[r!²²Ï¡ö²½×ÿ
Q§ß²[%&gt;ÕÛÖ�3±ÁdÕ&gt;‰Y!Œï_!í¬6ÿƒòmý&amp;V}»XH&lt;ÿjé�‹üF‚2f/aÐOW{×kG@šÂ&lt;†~ŸM?,ˆ5„	•&nbsp;Îÿ P=&gt;šþ©§‹²oÚ…ê¿OÁH4’Â
2¿‚¶¡÷�"Ë²!µUúô‚ÂMÐ&amp;¬Èª¶¿øA&nbsp;Ö�`¿íØ?ÈÍ‚Á‘Ñ¨-¨­…ZMáh5Î¬*úiÖá4Âÿ°ÕêÚˆÝL’#‡Žµ¨ ª—é…ý;J´Óÿ!+[«×…2º´œ��Àæ„t;^»
ÿw«h4ÁÐ�}îÂAj…~hˆ�ˆ~×½BµûÂélì	ÿ«Zµ¶ªÕHJ°N=Šô¬$ÂõäPÁ=¦š`¿ù7‡ÇtŽì@µPƒi6÷áGì7~@¼5)Vw&nbsp;5ÿÒÚUtÈµ!&nbsp;žœu]®ù	ps¼ª ¸Ç!Èi¦ÿþÓn}B;n›újá~l8 oè‚+Â
êÿµ&amp;ñBxA5…„C:àÁÈö
]®÷l&gt;Ò‚
&nbsp;ƒÚ‚ Ñßü›¤Ã	1tBiqA¥!—³Th'§\0VÂ_·„ÞÕƒÁšƒ‚ïÿÃ
nµ’/ä&amp;Ó’ÙvþîªÐ¦"/õºmZÓtñ‚ÿÈ!º,P îƒiÂ„á=µÂ
ªµa&nbsp;OîúbÃI ôø Oÿ$nžÒ…ÛNéûáx+H0ÁÿÞƒ°´ûx Mµè2Ü;N�P§Õ¨Z‘›’x`Â}·TÙFž»ÿîÒe¿Æ™4Úl·®ö“ûÂaE4…íÞ¬R·úÿí&amp;W4�nÑÎ†þÔUÐkÛôÎÔº¯v&nbsp;¯ú¦“øpRñéëjh0_ÖC‘+m^›ô¡ŒƒPè4ˆ.ïÓK¢û	
¶�©ûTñnö’þ˜_èŽ°„0¤"?ÖßS‰« Šéqšh_¤�zmoòÍ5ÿ8a @Û‘)Jê¡©[Ü ðÖø.‚»pÁpŸ]ý…þË	&amp;��ôœiÿ:ÝÉˆí\“zLRÚ:áƒ)úõIì+^ØUlíÁ?Ë!˜Cª¦ÎõP�íSÿ´éØkL-Za§ýSÃ#ÅãhŒ
» Äh6øP@ü©É«ÈjŽEªu»ktðÁ^í¾•\DF[¶¾?ü Õµ²Ü£¦Ñ‚5†F¿Øu~È?¦ƒ‘ˆÈLK#�É&nbsp;`×ÿ|-&gt;…°dØ'ú	ûzu&nbsp;ƒÆŸö™Ùª	¤ìSGc…LÈ1L@È%ëëñö×;/ü+õUÞ›«þBjŠXjû´5@û-Ö Çü*ÿÚ°È!µá'ö�A}/ÿŒ û„@ÁØAù7kÉl¿ÎãðÝ`ÁÿÒzÆ&nbsp;¿·Rƒ…ê©ôì `Õ&gt;Ãï×éÚ»YÙpOú[]0¿]I$IµTûh Æž�}~×úÁƒÿJC¾×°¶«õW¯z´w©ƒ§¸?íÿ·™Ûÿ¤´¯ÿ…üV›tÂéø&gt;¿k!¡Ês¹ø­—ê«þ«a…è+¥ßO}ú†�ÓÚßJGµ=ÑÚ¹Ô ÿÕ'ƒð[_‘§ôõ]¨0ŽÅ u�"`šoö›XG`@Ñ©ÖÂ„÷þ¶*š
n¡wÝr9h­‡m#²†¤&gt;9�ñ†º¶©ò+—p¿î—ÈbÓ@¬0–�6ôÝHaÍ@¤‰„ ƒµà™và‰°Tª×a‚ZÚ]¡%ÿ}4É”‚†ËÅ]mâÝHö14ƒƒ•ëÚm
h-­«@‚ÿÒÚ¡í…¦Ýé¯	°`¦Cà®–¼uØªÛ_S³ƒOÿ«T�?(âõ^ƒŠA«ÖÛýyd±Xa(èƒiÿl$¡®Z†má~›�¤Ó
Õo
ða.›JÃÐ@¿á¨VTcÄZ}6“P£î:ŠöÕA„ºû·R!ª±ÚM¯
—Ú�&nbsp;«¦ÒL�®�ÿu-Á94 ØiïßÂ¿ê5Ë%á6¤M«rÏðD3M„¥3(E$[§
Âh¬Û¢ë	p_³°n‰&nbsp;P@×E†ŽÉ$r@áþÕ i¨`Á‚jñ�•0×§ýÄi®›íþšª0@¿Ú!¢:	ê0gp«AØGz":/
á/ï	®˜a'Ð}§@¿Ú	•�&lt;0ÄCV¤Ø�¨ì’@ƒ°GhÛ	þºatÁ‚ïaHjŽG†pªà¿Á‚A‚!L˜PÃaC0d|Ä	ÉÄ&amp;Uîw„°D6EôŠP9tGÈáŽÁtÆÖš‘¹VDØ»‚ÿÂÈŽì0¢"&lt; ï%Wb¬0�wjˆä6AG)ê»%ApÂ„&gt;Âÿ°ƒŒ&amp;wZ
õˆA%°œ(a„	®Dtƒ�€tÁ~=ªM°ÿé§…	�	=Biö¡ƒ…¸Ó‚ �Ë1T5ypS¢ˆá­&lt;ÿD3ŽXí&lt;*·P—Ðwµ†!*¤è*!&amp;N!y²K
w*¼š�?ýtí&lt; VµIÆšu¨`Œ”Áïº	UË0´:uû X2¬&nbsp;™Üx2Wÿ�Š)ÐA}-éßàÐA·W‚ÂÃe˜.½Uß¦v2íNø1ÿ&nbsp;�´ð@¡……H‡�¿¢Â ƒzZ	%¹f
�?ÿ°ñDvoMC ÅOþnAp‚Qet¨�8UO§ü„Þ¡&amp;ÝxJ�Âÿ"!Õ-ª1m…;¯ôžDü˜Ìß!M…i?†ß‚Mº‘T·K„®»ò
E–¥&nbsp;Éó€‡u†þ˜h)±ÐmþHØ«_!]‡ú¦ÐaST/ÿàä
HgˆIâ0cÿIë}¶»ZKøAÁ»Z4Óv
±*vûlnEØ�&nbsp;ŸÿOXzw}kKè;ÚàÈpéˆø@¿ú‡©£´�ŸÿÒÝì:üÑÁµý½´°aöø@¿ñëIèþŸì\kQô²{.·†¸2¨‚¸ žÒû¼­D.K&nbsp;õë{&gt;iWoØ.´BVúÿëU§£²¡ÿü2	nGWµ]ì‡:Á¨AÎÉø¥~×mOAÿ÷ÿ4&gt;Á„—wãÃÂl¬É¸ ^²
{5È`s¹œ¨!ðÎÆ¾ïýwø}¾0»v­9�º{&nbsp;»
Èg‚eoòDÉ×«Zy]ÿ÷ò¥(;O´�7í7aÎÆä½D&amp;ã�Â¶_"ì¿ª“’?ÿÚÞé¬aÚµj
HÊïzWB?[
Öƒï¿ÿÕ„�îŽøoQ$Óx{¯ÿXS»ê×‡ÿøaa�†ÞD #»aT’
¨jåkƒÛ‘)…u¾ÿî÷Ž0ëD
†¤=
Ë«âØ&amp;ëiÒOŽ‡ÿVëÊšº46[
#ì7øvëö¿ÿïÝ&gt;ƒaƒ	_®ÛuÐQÚ2%¿ÛVêšµÝ&lt;„ío~MÆÁay®\Sÿþ¨ui´èToë6˜[&amp;íCÿûVê¡™£áÇ´Ÿ}p`Äq°KÎù¤¿öÕáTEZÈƒªÝµ&nbsp;ÃÔ'z}ÿÃ Ó"Wl+Ó&amp;ÊÂÂÚÁÒOTïýµ“6XK ‘U}¥#®i	áI�!&nbsp;&amp;¡ÿÃ	U*!&amp;]°ƒÎÖb³‘®CÈ´=†6MÒaƒ,Á ˆ=ÁA�ÚˆU‡þÃZÖ°pƒÎÔKk"È,ƒ‹dŠƒ�…vM|*E¨�&lt;*ßü¨0Õ,-²ÜÔÓtõ¶�V=†ša†VuWöp�ÁNÇÈì�•ñª­Êé`‰ÿkR
À¯O¸0Â"6yý°š¯
ýˆ¢-””‰¥ýÂ
6­?¨&gt;šm&lt;0šö"
ï}¸*ÁÿÕçu)1Õm„cÎ&lt;
ì)ÔÆC4¡Âáƒ‡þYvÐTºxU‘GþµAÓÒ^ƒ¹2¢eIá`ÛjÎÆ"&gt;|°Á§¦0@Ÿ&nbsp;ž`�‡þ×ÞØkÜ&amp;ˆaðâ#NCWXk$&nbsp;±r‡kÿ°a&gt;›@šàÃÿjÓ$4ÚqßNBy7™PûƒáXe@7¶ÿL…"¨$²‚dÈ�ƒÿ,&nbsp;Pj&nbsp;J/¦7Þœ,»ÔŠ¢ÉY
N†—‹ßõ&amp;…0UiƒÿØQ©½ÿKwá4èœA‚ßÃþMÂ˜PÂ¬&amp;¤)Ê-‡þ¡…ØA¶[Ÿ#¯T÷nûþƒƒ%±_ÈœÁ»ôÂƒÚaP|!ƒÿL0µMK~zÈR0·Nö¿)ÃHiúwý0§j0oÂ!ž.
MÃÿ
¦M†&lt;7µ@�ºÜÈ jÿk�`Ñý6ÿá$ÃŒýÚ	¯øRÜ–ûð�Ã#&nbsp;” ß¶�Dä]­NÆx;Uíÿáp`Õè$Ù¦Â³@Ÿé×jƒ¸ŠA?éÈÕ„ò!…</b></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.tpug.ca/tpug-media/tpugmag/TPUG_Issue_01_1984_Feb.pdf">https://www.tpug.ca/tpug-media/tpugmag/TPUG_Issue_01_1984_Feb.pdf</a></em></p>]]>
            </description>
            <link>https://www.tpug.ca/tpug-media/tpugmag/TPUG_Issue_01_1984_Feb.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-23644387</guid>
            <pubDate>Thu, 25 Jun 2020 19:16:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ASGI from scratch – Let's build an ASGI web framework]]>
            </title>
            <description>
<![CDATA[
Score 69 | Comments 11 (<a href="https://news.ycombinator.com/item?id=23644252">thread link</a>) | @lukastyrychtr
<br/>
June 25, 2020 | https://shenli.dev/2020/06/20/asgi-from-scratch.html | <a href="https://web.archive.org/web/*/https://shenli.dev/2020/06/20/asgi-from-scratch.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    
<p>The first time I used <a href="https://asgi.readthedocs.io/">ASGI</a>(<em>Asynchronous Server Gateway Interface</em>) was through <a href="https://github.com/django/channels">Channels</a> 1.0 when ASGI spec was still a draft. It was my first interview project which helped me get my current job at <a href="https://fellow.app/">Fellow</a>. It felt magical at that time how easy it is to add WebSocket functionality to my Django app and handles authentication and other Django related things for me seamlessly.</p>

<p>ASGI specification is now at version 3 at the time of writing and both ASGI and Channels became part of Django Software Foundation. Compared to the draft version, it has matured a lot with added lifecycle calls and better application format, etc. Most excitingly, a healthy and fast-growing community is forming and we are seeing more and more ASGI servers running in production environments. At my company, we are serving a few million requests per day through ASGI running on <a href="https://github.com/django/daphne">Daphne</a>, Netflix’s <a href="https://netflixtechblog.com/introducing-dispatch-da4b8a2a8072">Dispatch</a> is based on <a href="https://fastapi.tiangolo.com/">FastAPI</a>, a popular ASGI web application framework, and apparently, Microsoft is <a href="https://github.com/tiangolo/fastapi/pull/26">using it</a> too.</p>

<p>I would humbly advise anyone building web services in Python to learn about ASGI. And the best way to learn something is to built things with it, so in this blog post, I’ll walk through the steps to build a micro web application framework that speaks ASGI. I hope it can help explain how ASGI works.</p>


<p>Before writing the first line of code, we need to have a basic understanding of what ASGI is and what we are building towards.</p>
<h2 id="how-asgi-works">How ASGI works</h2>
<p>Here’s a simple diagram showing how ASGI works at a high level.</p>
<pre><code>graph TD
	A[Client] --&gt;|HTTP, WebSocket, ...| B(ASGI Server)
	B --&gt; |scope, send, receive| C(ASGI application)
</code></pre>
<p>To put it in simple words, A browser(client), establishes a connection to ASGI server with a certain type of request (HTTP or WebSocket), the ASGI server then calls ASGI  application with information about the connection, encapsulated in a python dictionary called <code>scope</code>, and two callbacks, named <code>send</code> and <code>receive</code>, that the application can use to send and receive messages between server and client.</p>

<p>Here’s an example HTTP request scope</p>
<div><div><pre><code><span>{</span>
    <span>"type"</span><span>:</span> <span>"http"</span><span>,</span>
    <span>"http_version"</span><span>:</span> <span>"1.1"</span><span>,</span>
    <span>"server"</span><span>:</span> <span>(</span><span>"127.0.0.1"</span><span>,</span> <span>8000</span><span>),</span>
    <span>"client"</span><span>:</span> <span>(</span><span>"127.0.0.1"</span><span>,</span> <span>60457</span><span>),</span>
    <span>"scheme"</span><span>:</span> <span>"http"</span><span>,</span>
    <span>"method"</span><span>:</span> <span>"GET"</span><span>,</span>
    <span>"root_path"</span><span>:</span> <span>""</span><span>,</span>
    <span>"path"</span><span>:</span> <span>"/hello/a"</span><span>,</span>
    <span>"raw_path"</span><span>:</span> <span>b"/hello/a"</span><span>,</span>
    <span>"query_string"</span><span>:</span> <span>b""</span><span>,</span>
    <span>"headers"</span><span>:</span> <span>[</span>
        <span>(</span><span>b"host"</span><span>,</span> <span>b"localhost:8000"</span><span>),</span>
        <span>(</span><span>b"connection"</span><span>,</span> <span>b"keep-alive"</span><span>),</span>
        <span>(</span>
            <span>b"user-agent"</span><span>,</span>
            <span>b"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.106 Safari/537.36"</span><span>,</span>
        <span>),</span>
        <span>(</span>
            <span>b"accept"</span><span>,</span>
            <span>b"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9"</span><span>,</span>
        <span>),</span>
        <span>(</span><span>b"accept-encoding"</span><span>,</span> <span>b"gzip, deflate, br"</span><span>),</span>
        <span>(</span><span>b"accept-language"</span><span>,</span> <span>b"en-US,en;q=0.9"</span><span>),</span>
        <span>(</span>
            <span>b"cookie"</span><span>,</span>
            <span>b'csrftoken=dDA2IAPrvgPc7hkyBSyctxDk78KmhHAzUqR0LUpjXI3Xgki0QrGEWazE3RGZuLGl'</span><span>,</span>
        <span>),</span>
    <span>],</span>
<span>}</span>
</code></pre></div></div>

<p>You might notice that <code>scope</code> is not too different from a WSGI <code>environ</code>. In fact, ASGI interface is very similar to WSGI interface, but instead of getting a <code>environ</code> and <code>start_response</code> to send headers and using the return value of WSGI application as the response body, ASGI interfaces with the connection and allows us to receive and send messages multiple times during the lifecycle of the connection <strong>asynchronously</strong> until the connection is closed.  This allows a nice interface for both WebSocket and HTTP.</p>

<p>It’s also totally possible to wrap a WSGI application inside an ASGI application, just prepare a WSGI <code>environ</code> and <code>start_response</code> based on <code>scope</code>, <code>receive</code>, and <code>send</code> then call the WSGI application and it would work. If you delegate that call into a thread pool or something similar, you just made your WSGI application asynchronous. This is roughly how Channels wraps around Django.</p>

<h2 id="define-asgi-framework">Define ASGI framework</h2>
<p>When I say ASGI framework I refer it as a framework that makes building ASGI application easier and this does not include the ASGI server part. I’m mentioning this because some of the earlier Python asynchronous web frameworks have their own server implementation that also takes over tasks such as parsing  HTTP requests, handles network connections, etc. We are not doing those in ASGI web framework. As a spiritual successor to WSGI, where web servers, such as Gunicorn and uwsgi, and web frameworks, such as Flask and Django, are separated, ASGI has this separation too.</p>

<p>So, what does an ASGI application look like?</p>

<h3 id="asgi-hello-world">ASGI Hello World</h3>
<p>A simple ASGI hello world application can be written as:</p>
<div><div><pre><code><span>async</span> <span>def</span> <span>application</span><span>(</span><span>scope</span><span>,</span> <span>receive</span><span>,</span> <span>send</span><span>):</span>
    <span>name</span> <span>=</span> <span>scope</span><span>[</span><span>"path"</span><span>].</span><span>split</span><span>(</span><span>"/"</span><span>,</span> <span>1</span><span>)[</span><span>-</span><span>1</span><span>]</span> <span>or</span> <span>"world"</span>
    <span>await</span> <span>send</span><span>(</span>
        <span>{</span>
            <span>"type"</span><span>:</span> <span>"http.response.start"</span><span>,</span>
            <span>"status"</span><span>:</span> <span>200</span><span>,</span>
            <span>"headers"</span><span>:</span> <span>[[</span><span>b"content-type"</span><span>,</span> <span>b"text/plain"</span><span>],],</span>
        <span>}</span>
    <span>)</span>
    <span>await</span> <span>send</span><span>(</span>
        <span>{</span>
            <span>"type"</span><span>:</span> <span>"http.response.body"</span><span>,</span>
            <span>"body"</span><span>:</span> <span>f"Hello, </span><span>{</span><span>name</span><span>}</span><span>!"</span><span>.</span><span>encode</span><span>(),</span>
            <span>"more_body"</span><span>:</span> <span>False</span><span>,</span>
        <span>}</span>
    <span>)</span>
</code></pre></div></div>
<p><code>http.response.start</code> starts an HTTP response sending status code and response headers. In this example, it responds with the 200 OK status code and  has <code>content-type</code> set to <code>text/plain</code> in the headers.  <code>http.response.body</code> sends the response body, the <code>more_body</code> key tells the server if the response is finished. ASGI server might use this to know if a connection should be closed or automatically decide between a <code>content-length</code> header or a chunked encoding.</p>

<p>We can run the application with <a href="https://www.uvicorn.org/">uvicorn</a>:</p>
<div><div><pre><code>uvicorn asgi-hello:application
</code></pre></div></div>
<p>And you should be able to visit <code>http://localhost:8000/</code> and get <code>Hello, world</code>.Visiting <code>http://localhost:8000/tom</code> would get you <code>Hello, tom</code>.</p>

<blockquote>
  <p>By the way, uvicorn is pretty fast, a simple benchmark with <code>wrk -d10s http://localhost:8000/hi</code> on a 2018 lowest spec MacBook Air yields <code>Requests/sec:  27857.87</code>.</p>
</blockquote>

<p>Although this approach works with a simple hello world example, it’s not exactly convenient to write a more complex application this way. For one, it doesn’t do routing, if you want to respond differently for different paths, you’ll probably end up with a huge  <code>if ... else if ... else</code> clause. Secondly, having to write the ASGI message every time in the form of a python dict is quite arduous. Third, in a complex application, it gets harder to track the status of the connection, such as is the response started, is the response ended, should I start the response here, etc.</p>

<h3 id="goal">Goal</h3>
<p>With the new framework, I hope to be able to write an ASGI application like this:</p>
<div><div><pre><code><span>import</span> <span>asyncio</span>
<span>from</span> <span>aaf</span> <span>import</span> <span>aaf</span> <span># Another ASGI framework
</span><span>from</span> <span>aaf.routing</span> <span>import</span> <span>Router</span>
<span>from</span> <span>aaf.response</span> <span>import</span> <span>HttpResponse</span>

<span>router</span> <span>=</span> <span>Router</span><span>()</span>

<span>@</span><span>router</span><span>.</span><span>route</span><span>(</span><span>'/'</span><span>)</span>
<span>@</span><span>router</span><span>.</span><span>route</span><span>(</span><span>'/&lt;name&gt;'</span><span>)</span>
<span>async</span> <span>def</span> <span>hello</span><span>(</span><span>connection</span><span>,</span> <span>name</span><span>=</span><span>'world'</span><span>):</span>
	<span>return</span> <span>HttpResponse</span><span>(</span><span>f"Hello, </span><span>{</span><span>name</span><span>}</span><span>"</span><span>)</span>


<span>@</span><span>router</span><span>.</span><span>route</span><span>(</span><span>'/count'</span><span>)</span>
<span>@</span><span>router</span><span>.</span><span>route</span><span>(</span><span>'/count/&lt;int:number&gt;'</span><span>)</span>
<span>async</span> <span>def</span> <span>count</span><span>(</span><span>connection</span><span>,</span> <span>number</span><span>=</span><span>10</span><span>):</span>
	<span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>number</span><span>):</span>
		<span>await</span> <span>connection</span><span>.</span><span>send</span><span>(</span><span>f'count </span><span>{</span><span>i</span><span>}</span><span>\n</span><span>'</span><span>,</span> <span>finish</span><span>=</span><span>False</span><span>)</span>
		<span>await</span> <span>asyncio</span><span>.</span><span>sleep</span><span>(</span><span>1</span><span>)</span>
	<span>await</span> <span>connection</span><span>.</span><span>send</span><span>(</span><span>''</span><span>,</span> <span>finish</span><span>=</span><span>True</span><span>)</span>


<span>@</span><span>router</span><span>.</span><span>route</span><span>(</span><span>'/echo'</span><span>)</span>
<span>async</span> <span>def</span> <span>echo</span><span>(</span><span>connection</span><span>):</span>
	<span>body</span> <span>=</span> <span>await</span> <span>connection</span><span>.</span><span>body</span><span>()</span>
	<span>await</span> <span>connection</span><span>.</span><span>send</span><span>(</span><span>body</span><span>,</span> <span>finish</span><span>=</span><span>True</span><span>)</span>


<span>app</span> <span>=</span> <span>aaf</span><span>([</span><span>router</span><span>])</span>
</code></pre></div></div>
<p>I hope this snippet of how I want the framework to look like is self-explanatory. But here are some of the key things I want to achieve:</p>
<ol>
  <li>It should be able to handle HTTP response declaratively and imperatively.</li>
  <li>It should support Flask style routing with parameter parsing.</li>
</ol>


<h2 id="connection-class">Connection class</h2>
<p>The <code>Connection</code> class will represent an ASGI HTTP or WebSocket connection. It’s a class that encapsulates the three basic elements in ASGI, namely <code>scope</code>, <code>send</code> and <code>receive</code>, and expose some convenient methods and properties so that users don’t need to verbosely write out all the ASGI messages and parse everything, such as cookies and headers, from <code>scope</code>. But it should allow users to access the original <code>scope</code>, <code>send</code> and <code>receive</code> when they want to, so that the composability of ASGI applications is maintained. For example, it should allow user to delegate certain <code>connection</code>s to another ASGI application by calling <code>another_asgi_app(connection.scope, connectionn.asgi_send, connection.asgi_receive)</code>.</p>

<p>Here’s a simple implementation of the <code>Connection</code> class.</p>
<div><div><pre><code><span>from</span> <span>enum</span> <span>import</span> <span>Enum</span>
<span>from</span> <span>functools</span> <span>import</span> <span>cached_property</span>
<span>from</span> <span>http.cookies</span> <span>import</span> <span>SimpleCookie</span>
<span>from</span> <span>typing</span> <span>import</span> <span>Any</span><span>,</span> <span>Awaitable</span><span>,</span> <span>Callable</span><span>,</span> <span>Optional</span><span>,</span> <span>Union</span>
<span>from</span> <span>urllib.parse</span> <span>import</span> <span>parse_qsl</span><span>,</span> <span>unquote_plus</span>

<span>from</span> <span>werkzeug.datastructures</span> <span>import</span> <span>Headers</span><span>,</span> <span>MultiDict</span>

<span>CoroutineFunction</span> <span>=</span> <span>Callable</span><span>[[</span><span>Any</span><span>],</span> <span>Awaitable</span><span>]</span>


<span>class</span> <span>ConnectionType</span><span>(</span><span>Enum</span><span>):</span>
    <span>HTTP</span> <span>=</span> <span>"HTTP"</span>
    <span>WebSocket</span> <span>=</span> <span>"WebSocket"</span>


<span>class</span> <span>Connection</span><span>:</span>
    <span>def</span> <span>__init__</span><span>(</span>
        <span>self</span><span>,</span> <span>scope</span><span>:</span> <span>dict</span><span>,</span> <span>*</span><span>,</span> <span>send</span><span>:</span> <span>CoroutineFunction</span><span>,</span> <span>receive</span><span>:</span> <span>CoroutineFunction</span>
    <span>):</span>
        <span>self</span><span>.</span><span>scope</span> <span>=</span> <span>scope</span>
        <span>self</span><span>.</span><span>asgi_send</span> <span>=</span> <span>send</span>
        <span>self</span><span>.</span><span>asgi_receive</span> <span>=</span> <span>receive</span>

        <span>self</span><span>.</span><span>started</span> <span>=</span> <span>False</span>
        <span>self</span><span>.</span><span>finished</span> <span>=</span> <span>False</span>
        <span>self</span><span>.</span><span>resp_headers</span> <span>=</span> <span>Headers</span><span>()</span>
        <span>self</span><span>.</span><span>resp_cookies</span><span>:</span> <span>SimpleCookie</span> <span>=</span> <span>SimpleCookie</span><span>()</span>
        <span>self</span><span>.</span><span>resp_status_code</span><span>:</span> <span>Optional</span><span>[</span><span>int</span><span>]</span> <span>=</span> <span>None</span>

        <span>self</span><span>.</span><span>http_body</span> <span>=</span> <span>b""</span>
        <span>self</span><span>.</span><span>http_has_more_body</span> <span>=</span> <span>True</span>
        <span>self</span><span>.</span><span>http_received_body_length</span> <span>=</span> <span>0</span>

    <span>@</span><span>cached_property</span>
    <span>def</span> <span>req_headers</span><span>(</span><span>self</span><span>)</span> <span>-&gt;</span> <span>Headers</span><span>:</span>
        <span>headers</span> <span>=</span> <span>Headers</span><span>()</span>
        <span>for</span> <span>(</span><span>k</span><span>,</span> <span>v</span><span>)</span> <span>in</span> <span>self</span><span>.</span><span>scope</span><span>[</span><span>"headers"</span><span>]:</span>
            <span>headers</span><span>.</span><span>add</span><span>(</span><span>k</span><span>.</span><span>decode</span><span>(</span><span>"ascii"</span><span>),</span> <span>v</span><span>.</span><span>decode</span><span>(</span><span>"ascii"</span><span>))</span>
        <span>return</span> <span>headers</span>

    <span>@</span><span>cached_property</span>
    <span>def</span> <span>req_cookies</span><span>(</span><span>self</span><span>)</span> <span>-&gt;</span> <span>SimpleCookie</span><span>:</span>
        <span>cookie</span> <span>=</span> <span>SimpleCookie</span><span>()</span>
        <span>cookie</span><span>.</span><span>load</span><span>(</span><span>self</span><span>.</span><span>req_headers</span><span>.</span><span>get</span><span>(</span><span>"cookie"</span><span>,</span> <span>{}))</span>
        <span>return</span> <span>cookie</span>

    <span>@</span><span>cached_property</span>
    <span>def</span> <span>type</span><span>(</span><span>self</span><span>)</span> <span>-&gt;</span> <span>ConnectionType</span><span>:</span>
        <span>return</span> <span>(</span>
            <span>ConnectionType</span><span>.</span><span>WebSocket</span>
            <span>if</span> <span>self</span><span>.</span><span>scope</span><span>.</span><span>get</span><span>(</span><span>"type"</span><span>)</span> <span>==</span> <span>"websocket"</span>
            <span>else</span> <span>ConnectionType</span><span>.</span><span>HTTP</span>
        <span>)</span>

    <span>@</span><span>cached_property</span>
    <span>def</span> <span>method</span><span>(</span><span>self</span><span>)</span> <span>-&gt;</span> <span>str</span><span>:</span>
        <span>return</span> <span>self</span><span>.</span><span>scope</span><span>[</span><span>"method"</span><span>]</span>

    <span>@</span><span>cached_property</span>
    <span>def</span> <span>path</span><span>(</span><span>self</span><span>)</span> <span>-&gt;</span> <span>str</span><span>:</span>
        <span>return</span> <span>self</span><span>.</span><span>sc…</span></code></pre></div></div></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://shenli.dev/2020/06/20/asgi-from-scratch.html">https://shenli.dev/2020/06/20/asgi-from-scratch.html</a></em></p>]]>
            </description>
            <link>https://shenli.dev/2020/06/20/asgi-from-scratch.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23644252</guid>
            <pubDate>Thu, 25 Jun 2020 19:04:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Testers vs. TDD]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 45 (<a href="https://news.ycombinator.com/item?id=23644228">thread link</a>) | @ohjeez
<br/>
June 25, 2020 | https://www.functionize.com/blog/testers-vs-tdd | <a href="https://web.archive.org/web/*/https://www.functionize.com/blog/testers-vs-tdd">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><img width="1080" height="634" src="https://3laqvw22wekb3ykm8z4dbnq8-wpengine.netdna-ssl.com/wp-content/uploads/2020/06/TDD-vs-Testers2.jpg" alt="Testers vs TDD" srcset="https://www.functionize.com/wp-content/uploads/2020/06/TDD-vs-Testers2.jpg 1080w, https://www.functionize.com/wp-content/uploads/2020/06/TDD-vs-Testers2-300x176.jpg 300w, https://www.functionize.com/wp-content/uploads/2020/06/TDD-vs-Testers2-1024x601.jpg 1024w, https://www.functionize.com/wp-content/uploads/2020/06/TDD-vs-Testers2-768x451.jpg 768w" sizes="(max-width: 1080px) 100vw, 1080px">      </p>	  
    
        <blockquote><p>Test-driven development was supposed to eliminate the need for independent testing. Alas, it doesn’t go far enough.</p></blockquote>
<p>Test-driven development (TDD) earned a reputation of making software more robust. Does that mean you can fire all the testers? Spoiler: No.</p>
<p><a href="https://martinfowler.com/bliki/TestDrivenDevelopment.html" target="blank" rel="noopener noreferrer">Test-driven development</a> is a method for writing software in small chunks. You start with a test, then write functional code to make the test pass, and finally refactor the functional code to clean it up. The idea of TDD was proposed by <a href="https://amzn.to/3doabIA" target="blank" rel="noopener noreferrer">Kent Beck</a> in the early 1990s, as part of Extreme Programming, an Agile software development methodology.</p>
<p>TDD is sometimes summarized as “Red, Green, Refactor.” The interfaces on many testing harnesses, such as JUnit (for Java) and NUnit (for .NET), show red lights when tests fail and green lights when tests pass. There’s another step to consider, however. You need to think about the desired behavior and carve out a small chunk of code – typically five lines – to implement next.</p>
<p>As proposed by Beck, in TDD you never write functional code until you have a failing test. Yet, it takes practice to learn to write the tests first (rather than after the fact); developers often have trouble shifting their habitual way of working. Writing the tests before the functional code just feels <em>wrong.</em> You do get used to it, though it may take months; by then it starts feeling <em>right</em>.</p>
<p>The <a href="https://www.functionize.com/blog/what-is-test-driven-development-tdd/">biggest benefit of TDD</a> is that it removes the fear of breaking your code. As you add unit tests and functional code, you also build <a href="https://www.functionize.com/blog/dont-fail-your-next-interview-know-what-differentiates-regression-testing-from-retesting/">a library of regression tests</a> that you run frequently. When you add a new feature, fix a bug, or refactor to clean up your code, running the tests again reassures you that you didn’t break anything. Or at least it confirms that you didn’t break any of the tests that <em>you</em> wrote.</p>
<h3>What do testers bring to the table?</h3>
<p>Software managers are sometimes tempted to eliminate or reduce software QA departments when the coders adopt TDD, on the grounds that the programmers are also writing tests. That decision usually is a mistake, because <a href="https://www.functionize.com/blog/five-must-have-skills-to-look-for-in-a-qa-tester/">testers provide value</a> outside of the developers’ unit tests.</p>
<p>Unit tests are only one of the kinds of tests needed to adequately cover modern code. TDD developers rarely write end-to-end integration tests. They may avoid writing unit tests that require significant setup or that rely on other software components, such as a populated database.</p>
<p>Dedicated testers are more likely than coders to take the time to perform exploratory (ad-hoc) testing, which can find bugs that weren’t imagined during the development of the code. Testers also come to the product with fresh eyes compared to the coders who have been immersed in the software for long hours.</p>
<p>Additionally, software developers often are not interested in setting up CI/CD tooling or in organizing the team’s tests into a master regression test. Testers consider all of that to be part of the job. Developers may not be involved in implementing shift left testing beyond TDD. &nbsp;For shift left testing, testers can gather information, help with requirements management, and help to define the acceptance criteria, before a single test or line of functional code is complete.</p>
<h3>What bugs do testers find that TDD doesn’t?</h3>
<p>Security is one large, important testing area that isn’t normally addressed by writing unit tests. Testers look for security flaws with automated vulnerability testing tools, manual security assessments, penetration tests, security audits, and security reviews.</p>
<p>It’s difficult for developers to write <a href="https://www.functionize.com/blog/the-challenges-of-testing-guis/">unit tests to test GUIs</a>. Instead, testers use automation tools specific to the supported application environments, such as browsers, desktop applications, and mobile apps.</p>
<p>Developers can have a hard time with hardware-dependent bugs, as the dominant way of working is for a coder to work on a single machine. QA departments often collect rooms full of varied computers and devices, as well as images of many operating system versions. An alternative way of testing on many different model devices is to use a crowd-sourced testing service.</p>
<p>While TDD can theoretically catch bugs in edge cases, they are called “edge cases” for a good reason. When a coder designs the tests for a function point, obscure edge cases may escape notice in the heat of the moment. Testers are more likely to find these than are the coders who wrote the software.</p>
<p>Similarly, cross-module flaws can sometimes escape scrutiny in unit tests. They can easily arise when one programmer misunderstands the interface or boundary conditions of another programmer’s module. Cross-module bugs are often found during end-to-end testing and ad-hoc testing.</p>
<p>In summary, while there’s a lot to be said for TDD as a development practice, it doesn’t usually provide complete test coverage of your code. For that, you still need testers.</p>
<blockquote><p>Whoever writes the test cases, it makes sense to follow established guidelines. <a href="https://www.functionize.com/project/best-practices-for-effective-test-case-writing/">These</a> might help.</p></blockquote>
<div>
<div>
<p><img src="https://3laqvw22wekb3ykm8z4dbnq8-wpengine.netdna-ssl.com/wp-content/uploads/2020/02/author-Martin-Heller.jpg" alt="Martin Heller"></p>
<div>
<p><span>by</span> Martin Heller</p>
<p>Martin Heller is a freelance writer. Formerly a web and Windows programming consultant, he developed databases, software, and websites from 1986 to 2010. More recently, he has served as VP of technology and education at Alpha Software and chairman and CEO at Tubifi.</p>
</div>

</div>
</div>
<!-- AddThis Advanced Settings above via filter on the_content --><!-- AddThis Advanced Settings below via filter on the_content --><!-- AddThis Advanced Settings generic via filter on the_content --><!-- AddThis Share Buttons above via filter on the_content --><!-- AddThis Share Buttons below via filter on the_content --><!-- AddThis Share Buttons generic via filter on the_content -->  </div></div>]]>
            </description>
            <link>https://www.functionize.com/blog/testers-vs-tdd</link>
            <guid isPermaLink="false">hacker-news-small-sites-23644228</guid>
            <pubDate>Thu, 25 Jun 2020 19:02:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing a Linux Debugger Part 1: Setup (2017)]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23643865">thread link</a>) | @memexy
<br/>
June 25, 2020 | https://blog.tartanllama.xyz/writing-a-linux-debugger-setup/ | <a href="https://web.archive.org/web/*/https://blog.tartanllama.xyz/writing-a-linux-debugger-setup/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><span itemprop="articleBody"><p>Anyone who has written more than a hello world program should have used a debugger at some point (if you haven’t, drop what you’re doing and learn how to use one). However, although these tools are in such widespread use, there aren’t a lot of resources which tell you how they work and how to write one<sup id="fnref:1"><a href="#fn:1">1</a></sup>, especially when compared to other toolchain technologies like compilers. In this post series we’ll learn what makes debuggers tick and write one for debugging Linux programs.</p>
<p>We’ll support the following features:</p>
<ul>
<li>Launch, halt, and continue execution</li>
<li>Set breakpoints on
<ul>
<li>Memory addresses</li>
<li>Source code lines</li>
<li>Function entry</li>
</ul>
</li>
<li>Read and write registers and memory</li>
<li>Single stepping
<ul>
<li>Instruction</li>
<li>Step in</li>
<li>Step out</li>
<li>Step over</li>
</ul>
</li>
<li>Print current source location</li>
<li>Print backtrace</li>
<li>Print values of simple variables</li>
</ul>
<p>In the final part I’ll also outline how you could add the following to your debugger:</p>
<ul>
<li>Remote debugging</li>
<li>Shared library and dynamic loading support</li>
<li>Expression evaluation</li>
<li>Multi-threaded debugging support</li>
</ul>
<p>I’ll be focusing on C and C++ for this project, but it should work just as well with any language which compiles down to machine code and outputs standard DWARF debug information (if you don’t know what that is yet, don’t worry, this will be covered soon). Additionally, my focus will be on just getting something up and running which works most of the time, so things like robust error handling will be eschewed in favour of simplicity.</p>
<hr>
<h3 id="series-index">Series index</h3>
<ol>
<li><a href="https://blog.tartanllama.xyz/writing-a-linux-debugger-setup/">Setup</a></li>
<li><a href="https://blog.tartanllama.xyz/writing-a-linux-debugger-breakpoints/">Breakpoints</a></li>
<li><a href="https://blog.tartanllama.xyz/writing-a-linux-debugger-registers/">Registers and memory</a></li>
<li><a href="https://blog.tartanllama.xyz/writing-a-linux-debugger-elf-dwarf/">Elves and dwarves</a></li>
<li><a href="https://blog.tartanllama.xyz/writing-a-linux-debugger-source-signal/">Source and signals</a></li>
<li><a href="https://blog.tartanllama.xyz/writing-a-linux-debugger-dwarf-step/">Source-level stepping</a></li>
<li><a href="https://blog.tartanllama.xyz/writing-a-linux-debugger-source-break/">Source-level breakpoints</a></li>
<li><a href="https://blog.tartanllama.xyz/writing-a-linux-debugger-unwinding/">Stack unwinding</a></li>
<li><a href="https://blog.tartanllama.xyz/writing-a-linux-debugger-variables/">Handling variables</a></li>
<li><a href="https://blog.tartanllama.xyz/writing-a-linux-debugger-advanced-topics/">Advanced topics</a></li>
</ol>
<hr>
<h3 id="getting-set-up">Getting set up</h3>
<p>Before we jump into things, let’s get our environment set up. I’ll be using two dependencies in this tutorial: <a href="https://github.com/antirez/linenoise">Linenoise</a> for handling our command line input, and <a href="https://github.com/TartanLlama/libelfin/tree/fbreg">libelfin</a> for parsing the debug information. You could use the more traditional libdwarf instead of libelfin, but the interface is nowhere near as nice, and libelfin also provides a mostly complete DWARF expression evaluator, which will save you a lot of time if you want to read variables. Make sure that you use the fbreg branch of my fork of libelfin, as it hacks on some extra support for reading variables on x86.</p>
<p>Once you’ve either installed these on your system, or got them building as dependencies with whatever build system you prefer, it’s time to get started. I just set them to build along with the rest of my code in my CMake files.</p>
<hr>
<h3 id="launching-the-executable">Launching the executable</h3>
<p>Before we actually debug anything, we’ll need to launch the debugee program. We’ll do this with the classic fork/exec pattern.</p>
<figure><pre><code data-lang="cpp"><span>int</span> <span>main</span><span>(</span><span>int</span> <span>argc</span><span>,</span> <span>char</span><span>*</span> <span>argv</span><span>[])</span> <span>{</span>
    <span>if</span> <span>(</span><span>argc</span> <span>&lt;</span> <span>2</span><span>)</span> <span>{</span>
        <span>std</span><span>::</span><span>cerr</span> <span>&lt;&lt;</span> <span>"Program name not specified"</span><span>;</span>
        <span>return</span> <span>-</span><span>1</span><span>;</span>
    <span>}</span>

    <span>auto</span> <span>prog</span> <span>=</span> <span>argv</span><span>[</span><span>1</span><span>];</span>

    <span>auto</span> <span>pid</span> <span>=</span> <span>fork</span><span>();</span>
    <span>if</span> <span>(</span><span>pid</span> <span>==</span> <span>0</span><span>)</span> <span>{</span>
        <span>//we're in the child process
</span>        <span>//execute debugee
</span>
    <span>}</span>
    <span>else</span> <span>if</span> <span>(</span><span>pid</span> <span>&gt;=</span> <span>1</span><span>)</span>  <span>{</span>
        <span>//we're in the parent process
</span>        <span>//execute debugger
</span>    <span>}</span></code></pre></figure>
<p>We call <code>fork</code> and this causes our program to split into two processes. If we are in the child process, <code>fork</code> returns <code>0</code>, and if we are in the parent process, it returns the process ID of the child process.</p>
<p>If we’re in the child process, we want to replace whatever we’re currently executing with the program we want to debug.</p>
<figure><pre><code data-lang="cpp">   <span>ptrace</span><span>(</span><span>PTRACE_TRACEME</span><span>,</span> <span>0</span><span>,</span> <span>nullptr</span><span>,</span> <span>nullptr</span><span>);</span>
   <span>execl</span><span>(</span><span>prog</span><span>,</span> <span>prog</span><span>,</span> <span>nullptr</span><span>);</span></code></pre></figure>
<p>Here we have our first encounter with <code>ptrace</code>, which is going to become our best friend when writing our debugger. <code>ptrace</code> allows us to observe and control the execution of another process by reading registers, reading memory, single stepping and more. The API is very ugly; it’s a single function which you provide with an enumerator value for what you want to do, and then some arguments which will either be used or ignored depending on which value you supply. The signature looks like this:</p>
<figure><pre><code data-lang="cpp"><span>long</span> <span>ptrace</span><span>(</span><span>enum</span> <span>__ptrace_request</span> <span>request</span><span>,</span> <span>pid_t</span> <span>pid</span><span>,</span>
            <span>void</span> <span>*</span><span>addr</span><span>,</span> <span>void</span> <span>*</span><span>data</span><span>);</span></code></pre></figure>
<p><code>request</code> is what we would like to do to the traced process; <code>pid</code> is the process ID of the traced process; <code>addr</code> is a memory address, which is used in some calls to designate an address in the tracee; and <code>data</code> is some request-specific resource. The return value often gives error information, so you probably want to check that in your real code; I’m just omitting it for brevity. You can have a look at the man pages for more information.</p>
<p>The request we send in the above code, <code>PTRACE_TRACEME</code>, indicates that this process should allow its parent to trace it. All of the other arguments are ignored, because API design isn’t important /s.</p>
<p>Next, we call <code>execl</code>, which is one of the many <code>exec</code> flavours. We execute the given program, passing the name of it as a command-line argument and a <code>nullptr</code> to terminate the list. You can pass any other arguments needed to execute your program here if you like.</p>
<p>After we’ve done this, we’re finished with the child process; we’ll just let it keep running until we’re finished with it.</p>
<hr>
<h3 id="adding-our-debugger-loop">Adding our debugger loop</h3>
<p>Now that we’ve launched the child process, we want to be able to interact with it. For this, we’ll create a <code>debugger</code> class, give it a loop for listening to user input, and launch that from our parent fork of our <code>main</code> function.</p>
<figure><pre><code data-lang="cpp"><span>else</span> <span>if</span> <span>(</span><span>pid</span> <span>&gt;=</span> <span>1</span><span>)</span>  <span>{</span>
    <span>//parent
</span>    <span>debugger</span> <span>dbg</span><span>{</span><span>prog</span><span>,</span> <span>pid</span><span>};</span>
    <span>dbg</span><span>.</span><span>run</span><span>();</span>
<span>}</span></code></pre></figure>
<figure><pre><code data-lang="cpp"><span>class</span> <span>debugger</span> <span>{</span>
<span>public</span><span>:</span>
    <span>debugger</span> <span>(</span><span>std</span><span>::</span><span>string</span> <span>prog_name</span><span>,</span> <span>pid_t</span> <span>pid</span><span>)</span>
        <span>:</span> <span>m_prog_name</span><span>{</span><span>std</span><span>::</span><span>move</span><span>(</span><span>prog_name</span><span>)},</span> <span>m_pid</span><span>{</span><span>pid</span><span>}</span> <span>{}</span>

    <span>void</span> <span>run</span><span>();</span>

<span>private</span><span>:</span>
    <span>std</span><span>::</span><span>string</span> <span>m_prog_name</span><span>;</span>
    <span>pid_t</span> <span>m_pid</span><span>;</span>
<span>};</span></code></pre></figure>
<p>In our <code>run</code> function, we need to wait until the child process has finished launching, then just keep on getting input from linenoise until we get an EOF (ctrl+d).</p>
<figure><pre><code data-lang="cpp"><span>void</span> <span>debugger</span><span>::</span><span>run</span><span>()</span> <span>{</span>
    <span>int</span> <span>wait_status</span><span>;</span>
    <span>auto</span> <span>options</span> <span>=</span> <span>0</span><span>;</span>
    <span>waitpid</span><span>(</span><span>m_pid</span><span>,</span> <span>&amp;</span><span>wait_status</span><span>,</span> <span>options</span><span>);</span>

    <span>char</span><span>*</span> <span>line</span> <span>=</span> <span>nullptr</span><span>;</span>
    <span>while</span><span>((</span><span>line</span> <span>=</span> <span>linenoise</span><span>(</span><span>"minidbg&gt; "</span><span>))</span> <span>!=</span> <span>nullptr</span><span>)</span> <span>{</span>
        <span>handle_command</span><span>(</span><span>line</span><span>);</span>
        <span>linenoiseHistoryAdd</span><span>(</span><span>line</span><span>);</span>
        <span>linenoiseFree</span><span>(</span><span>line</span><span>);</span>
    <span>}</span>
<span>}</span></code></pre></figure>
<p>When the traced process is launched, it will be sent a <code>SIGTRAP</code> signal, which is a trace or breakpoint trap. We can wait until this signal is sent using the <code>waitpid</code> function.</p>
<p>After we know the process is ready to be debugged, we listen for user input. The <code>linenoise</code> function takes a prompt to display and handles user input by itself. This means we get a nice command line with history and navigation commands without doing much work at all. When we get the input, we give the command to a <code>handle_command</code> function which we’ll write shortly, then we add this command to the linenoise history and free the resource.</p>
<hr>
<h3 id="handling-input">Handling input</h3>
<p>Our commands will follow a similar format to gdb and lldb. To continue the program, a user will type <code>continue</code> or <code>cont</code> or even just <code>c</code>. If they want to set a breakpoint on an address, they’ll write <code>break 0xDEADBEEF</code>, where <code>0xDEADBEEF</code> is the desired address in hexadecimal format. Let’s add support for these commands.</p>
<figure><pre><code data-lang="cpp"><span>void</span> <span>debugger</span><span>::</span><span>handle_command</span><span>(</span><span>const</span> <span>std</span><span>::</span><span>string</span><span>&amp;</span> <span>line</span><span>)</span> <span>{</span>
    <span>auto</span> <span>args</span> <span>=</span> <span>split</span><span>(</span><span>line</span><span>,</span><span>' '</span><span>);</span>
    <span>auto</span> <span>command</span> <span>=</span> <span>args</span><span>[</span><span>0</span><span>];</span>

    <span>if</span> <span>(</span><span>is_prefix</span><span>(</span><span>command</span><span>,</span> <span>"continue"</span><span>))</span> <span>{</span>
        <span>continue_execution</span><span>();</span>
    <span>}</span>
    <span>else</span> <span>{</span>
        <span>std</span><span>::</span><span>cerr</span> <span>&lt;&lt;</span> <span>"Unknown command</span><span>\n</span><span>"</span><span>;</span>
    <span>}</span>
<span>}</span></code></pre></figure>
<p><code>split</code> and <code>is_prefix</code> are a couple of small helper functions:</p>
<figure><pre><code data-lang="cpp"><span>std</span><span>::</span><span>vector</span><span>&lt;</span><span>std</span><span>::</span><span>string</span><span>&gt;</span> <span>split</span><span>(</span><span>const</span> <span>std</span><span>::</span><span>string</span> <span>&amp;</span><span>s</span><span>,</span> <span>char</span> <span>delimiter</span><span>)</span> <span>{</span>
    <span>std</span><span>::</span><span>vector</span><span>&lt;</span><span>std</span><span>::</span><span>string</span><span>&gt;</span> <span>out</span><span>{};</span>
    <span>std</span><span>::</span><span>stringstream</span> <span>ss</span> <span>{</span><span>s</span><span>};</span>
    <span>std</span><span>::</span><span>string</span> <span>item</span><span>;</span>

    <span>while</span> <span>(</span><span>std</span><span>::</span><span>getline</span><span>(</span><span>ss</span><span>,</span><span>item</span><span>,</span><span>delimiter</span><span>))</span> <span>{</span>
        <span>out</span><span>.</span><span>push_back</span><span>(</span><span>item</span><span>);</span>
    <span>}</span>

    <span>return</span> <span>out</span><span>;</span>
<span>}</span>

<span>bool</span> <span>is_prefix</span><span>(</span><span>const</span> <span>std</span><span>::</span><span>string</span><span>&amp;</span> <span>s</span><span>,</span> <span>const</span> <span>std</span><span>::</span><span>string</span><span>&amp;</span> <span>of</span><span>)</span> <span>{</span>
    <span>if</span> <span>(</span><span>s</span><span>.</span><span>size</span><span>()</span> <span>&gt;</span> <span>of</span><span>.</span><span>size</span><span>())</span> <span>return</span> <span>false</span><span>;</span>
    <span>return</span> <span>std</span><span>::</span><span>equal</span><span>(</span><span>s</span><span>.</span><span>begin</span><span>(),</span> <span>s</span><span>.</span><span>end</span><span>(),</span> <span>of</span><span>.</span><span>begin</span><span>());</span>
<span>}</span></code></pre></figure>
<p>We’ll add <code>continue_execution</code> to the <code>debugger</code> class.</p>
<figure><pre><code data-lang="cpp"><span>void</span> <span>debugger</span><span>::</span><span>continue_execution</span><span>()</span> <span>{</span>
    <span>ptrace</span><span>(</span><span>PTRACE_CONT</span><span>,</span> <span>m_pid</span><span>,</span> <span>nullptr</span><span>,</span> <span>nullptr</span><span>);</span>

    <span>int</span> <span>wait_status</span><span>;</span>
    <span>auto</span> <span>options</span> <span>=</span> <span>0</span><span>;</span>
    <span>waitpid</span><span>(</span><span>m_pid</span><span>,</span> <span>&amp;</span><span>wait_status</span><span>,</span> <span>options</span><span>);</span>
<span>}</span></code></pre></figure>
<p>For now our <code>continue_execution</code> function will just use <code>ptrace</code> to tell the process to continue, then <code>waitpid</code> until it’s signalled.</p>
<hr>
<h3 id="finishing-up">Finishing up</h3>
<p>Now you should be able to compile some C or C++ program, run it through your debugger, see it halting on entry, and be able to continue execution from your debugger. In the next part we’ll learn how to get our debugger to set breakpoints. If you come across any issues, please let me know in the comments!</p>
<p>You can find the code for this post <a href="https://github.com/TartanLlama/minidbg/tree/tut_setup">here</a>.</p>
<hr>

</span></p><p><small>
<i></i>
c++
</small>
</p>
</div><p>
I <i></i> feedback.<br>
Let me know what you think of this article on twitter <a href="https://www.twitter.com/TartanLlama">@TartanLlama</a> or leave a comment below!
</p></div>]]>
            </description>
            <link>https://blog.tartanllama.xyz/writing-a-linux-debugger-setup/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23643865</guid>
            <pubDate>Thu, 25 Jun 2020 18:28:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cluster Analysis]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23643701">thread link</a>) | @tractific
<br/>
June 25, 2020 | https://tractific.com/blog/cluster-analysis-types | <a href="https://web.archive.org/web/*/https://tractific.com/blog/cluster-analysis-types">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Join early Tractific users getting product updates, blog posts, and free access to beta.</p><div><div><p>×</p><h2>Join early Tractific users getting product updates, blog posts, and free access to beta.</h2><ul><li>Early and free access</li><li>SaaS growth tips</li><li>4 minute read</li></ul></div></div></div>]]>
            </description>
            <link>https://tractific.com/blog/cluster-analysis-types</link>
            <guid isPermaLink="false">hacker-news-small-sites-23643701</guid>
            <pubDate>Thu, 25 Jun 2020 18:12:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: GitHub Action for Salus, an open source app security scanner]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23643379">thread link</a>) | @jsulinski
<br/>
June 25, 2020 | https://www.federacy.com/blog/salus-github-action/ | <a href="https://web.archive.org/web/*/https://www.federacy.com/blog/salus-github-action/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.federacy.com/blog/salus-github-action/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23643379</guid>
            <pubDate>Thu, 25 Jun 2020 17:45:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I made $10K in bug bounties from GitHub secret leaks]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23643373">thread link</a>) | @symbolicretail
<br/>
June 25, 2020 | https://tillsongalloway.com/finding-sensitive-information-on-github/ | <a href="https://web.archive.org/web/*/https://tillsongalloway.com/finding-sensitive-information-on-github/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
            </figure>

            <section>
                <div>
                    <p>API keys, passwords, and customer data are accidentally posted to GitHub every day. </p><p>Hackers use these keys to login to servers, steal personal information, and rack up absurd AWS charges. GitHub leaks can cost a company thousands–or even millions–of dollars in damages. Open-source intelligence gathering on GitHub has become a powerful arrow in every security researcher's quiver: researchers from NC State even wrote an <a href="https://www.ndss-symposium.org/wp-content/uploads/2019/02/ndss2019_04B-3_Meli_paper.pdf">academic paper</a> on the subject. </p><p>This article, written for both bug bounty hunters and enterprise infosec teams, demonstrates common types of sensitive information (secrets) that users post to public GitHub repositories as well as heuristics for finding them. The techniques in this article can be applied to <a href="https://gist.github.com/">GitHub Gist</a> snippets, too.</p><p>In the last year, I've earned nearly $10,000 from bug bounty programs on <a href="https://hackerone.com/">HackerOne</a> without even visiting programs' websites thanks to these techniques. I've submitted over 30 Coordinated Disclosure reports to vulnerable corporations, including eight Fortune 500 companies. </p><p><strong>I've also released <a href="https://github.com/tillson/git-hound">GitHound</a>, an open-source tool designed to automate the process of finding keys across GitHub.</strong> GitHound isn't limited to a single user or organization: it sifts through all of GitHub, using Code Search queries as an entrypoint into repositories and then using context, regexes, and some other neat tricks to find secrets.</p><h2 id="github-code-search">GitHub Code Search</h2><p>Before we get into the automated tools and bug bounty strategies, let's talk about Code Search. </p><p>GitHub provides <a href="https://github.com/search">rich code searching</a> that scans public GitHub repositories (some content is omitted, <a href="https://help.github.com/en/github/searching-for-information-on-github/searching-code#considerations-for-code-search">like forks and non-default branches</a>). Queries can be simple like <code>uberinternal.com</code> or can contain multi-word strings like &nbsp;<code>"Authorization: Bearer"</code>. Searches can even target specific files (<code>filename: vim_settings.xml</code>) or specific languages (<code>language:SQL</code>). Searches can also contain certain <a href="https://help.github.com/en/github/searching-for-information-on-github/understanding-the-search-syntax">boolean qualifiers</a> like <code>NOT</code> and <code>&gt;</code>. </p><p>Knowing the rules of GitHub code search enables us to craft search dorks: queries that are designed to find sensitive information. GitHub dorks can be found online, but the best dorks are the ones that you create yourself.</p><p>For example, <code>filename: vim_settings.xml</code> (<a href="https://github.com/search?q=filename%3Avim_settings.xml&amp;type=Code">try it!</a>) targets <a href="https://www.jetbrains.com/help/idea/settings-tools-settings-repository.html">IntelliJ settings files</a><a>.</a> Interestingly, the <code>vim_settings.xml</code> file contains recent <strong>copy-pasted strings encoded in Base64</strong>. I recently made $2400 from a bug bounty with this dork: SaaS API keys and customer information were exposed in <code>vim_settings.xml</code>.</p><figure><img src="https://tillsongalloway.com/content/images/2020/05/vim_settings.png"></figure><p><code>vim_settings.xml</code> only contains recently copy-pasted strings, but we can exploit the repository's commit history to find the <strong>entire copy-paste history.</strong> Just clone the repository and run <a href="https://gist.github.com/tillson/620e8ef87bc057f25b0a27c423433fda">this 14-line script</a>, and the user's activity will be at your fingertips. GitHound also finds and scans base64 encoded strings for secrets, even in commit history.</p><p>By the way: with <a href="https://github.com/search?q=%22vim_settings.xml%22&amp;type=Commits">a GitHub commit search dork</a>, we can quickly scan all 500,000 of commits that edit <code>vim_settings.xml</code>.</p><figure><img src="https://tillsongalloway.com/content/images/2020/05/commits.png"></figure><h2 id="search-heuristics-for-bug-bounty-hunters">Search Heuristics for Bug Bounty Hunters</h2><p>GitHub dorks broadly find sensitive information, but<strong> what if we want to look for information about a specific company?</strong> GitHub has millions of repositories and even more files, so we'll need some heuristics to narrow down the search space. </p><p>To start finding sensitive information, identify a target. </p><p>I've found that the best way to start is to <strong>find domains or subdomains that identify corporate infrastructure.</strong> </p><p>Searching for <code>company.com</code> probably won't provide useful results: many companies release audited open-source projects that aren't likely to contain secrets. Less-used domains and subdomains are more interesting. This includes specific hosts like <code>jira.company.com</code> as well as more general second-level and lower-level domains. It's more efficient to find a pattern than a single domain: <code>corp.somecompany.com</code>, <code>somecompany.net</code>, or <code>companycorp.com</code> are more likely to appear only in an employee's configuration files. </p><p>The usual suspects for open-source intelligence and domain reconnaissance help here:</p><ul><li><a href="https://github.com/TheRook/subbrute">Subbrute</a> - Python tool for brute-forcing subdomains</li><li><a href="https://www.threatcrowd.org/">ThreatCrowd</a> - Given a domain, find associated domains through multiple OSINT techniques</li><li><a href="https://censys.io/">Censys.io</a> - Given a domain, find SSL certificates using it</li></ul><p>GitHound can help with subdomain discovery too: add a custom regex <code>\.company\.com</code> and run GitHound with the <code>--regex-file</code> flag.</p><p>After finding a host or pattern to search, play around on GitHub search with it (I always do this before using automated tools). There are a few questions I like to ask myself here:</p><ol><li><strong>How many results came up?</strong> If there are over 100 pages, I'll likely need to find a better query to start with (GitHub limits code search results to 100 pages).</li><li><strong>What kind of results came up?</strong> If the results are mostly (intentionally) open-source projects and people using public APIs, then I may be able to refine the search to eliminate those.</li><li><strong>What happens if I change the language?</strong> <code>language:Shell</code> and <code>language:SQL</code> may have interesting results.</li><li><strong>Do these results reveal any other domains or hosts?</strong> Results in the first few pages will often include a reference to another domain (e.g. searching for <code>jira.uber.com</code> may reveal the existence of another domain entirely, like <code>uberinternal.com</code>).</li></ol><p>I spend most of my time in this step.</p><p>It's crucial that the search space is well-defined and accurate. Automated tools and manual searching will be faster and more accurate with the proper query.</p><p>Once I find results that seem interesting based on the criteria above, I run it through <a href="https://github.com/tillson/git-hound">GitHound</a><a> </a>with <code>--dig-files</code> and <code>--dig-commits</code> to look the entire repository and its history. </p><p><code>echo "uberinternal.com" | ./git-hound --dig-files --dig-commits</code></p><p><code>echo "uber.com" | ./git-hound --dig-files --language-file languages.txt --dig-commits</code></p><p><code>echo "uber.box.net" | ./git-hound --dig-files --dig-commits</code></p><p>GitHound also locates interesting files that simply searching won't find, like <code>.zip</code> or <code>.xlsx</code> files. Importantly, I also manually go through results since automated tools often miss customer information, sensitive code, and username/password combinations. Oftentimes, this will reveal more subdomains or other interesting patterns that will give me ideas for more search queries. It's important to remember that open-source intelligence is a recursive process.</p><p>This process almost always finds results. Leaks usually fall into one of these categories (ranked from most to least impactful):</p><ol><li><strong>SaaS API keys</strong> - Companies rarely impose IP restrictions on APIs. AWS, Slack, Google, and other API keys are liquid gold. These are usually found in config files, bash history files, and scripts.</li><li><strong>Server/database credentials</strong> - These are usually behind a firewall, so they're less impactful. Usually found in config files, bash history files, and scripts.</li><li><strong>Customer/employee information</strong> - These hide in XLSX, CSV, and XML files and range from emails all the way to billing information and employee performance reviews.</li><li><strong>Data science scripts</strong> - SQL queries, R scripts, and Jupyter projects can reveal sensitive information. These repos also tend to have "test data" files hanging around.</li><li><strong>Hostnames/metadata</strong> - The most common result. Most companies don't consider this a vulnerability, but they can help refine future searches</li></ol><h2 id="workflow-for-specific-api-providers">Workflow for Specific API Providers</h2><p>Dorks can also be created to target specific API providers and their endpoints. This is especially useful for companies creating automated checks for their users' API keys. With knowledge of an API key's <strong>context</strong> and <strong>syntax</strong>, the search space can be significantly reduced. </p><p>With knowledge of the specific API provider, we can obtain all of the keys that match the API provider's regex and are in an API call context and then we can check them for validity using an internal database or an API endpoint. </p><figure><img src="https://tillsongalloway.com/content/images/2020/05/graph.png"><figcaption>A workflow for finding secrets for a single API provider</figcaption></figure><p>For example, suppose a company (HalCorp) provides an API for users to read and write to their account. By making our own HalCorp account, we discover that API keys are in the form <code>[a-f]{4}-[a-f]{4}-[a-f]{4}</code>. </p><pre><code># Python
import halapi
api = halapi.API()
api.authenticate_by_key('REDACTED')

# REST API with curl
curl -X POST -H "HALCorp-Key: REDACTED" https://api.halcorp.biz/userinfo
</code></pre><p>Armed with this information, we can compose our own GitHub dorks for HalCorp API responses: </p><pre><code># Python
"authenticate_by_key" "halapi" language:python

# REST API
"HALCorp-Key"
</code></pre><p>With a tool like <a href="https://github.com/tillson/git-hound">GitHound</a><a>,</a> we can use regex matching to find strings that match the API key's regex and output them to a file:</p><p><code>echo "HALCorp-Key" | git-hound --dig-files --dig-commits --many-results --regex-file halcorp-api-keys.txt --results-only &gt; api_tokens.txt </code></p><p>Now that we have a file containing potential &nbsp;API tokens, and we can check these against a database for validity (<strong>do not do this if you don't have written permission from the API provider</strong>).</p><p>In the case of HalCorp, we can write a bash script that reads from stdin, checks the <code>api.halcorp.biz/userinfo</code> endpoint, and outputs the response.</p><p><code>cat api_tokens.txt | bash checktoken.bash</code></p><p>Although awareness of secret exposure on GitHub has increased, more and more sensitive data are published each day. </p><p>Amazon Web Services have begun <a href="https://aws.amazon.com/blogs/security/how-to-receive-notifications-when-your-aws-accounts-root-access-keys-are-used/">notifying users if their API keys are posted online</a>. GitHub has added <a href="https://github.com/features/security">security features</a> that scan public repositories for common keys. These solutions are merely bandaids, however. To limit secret leaks from source code, we must update API frameworks and DevOps methodologies to prevent API keys from being stored in Git/SVN repositories entirely. Software like <a href="https://www.vaultproject.io/">Vault</a> safely stores production keys and some API providers, like Google Cloud Platform, have updated their libraries to force API keys to be stored in a file by default.</p><p>Fully eradicating exposure of sensitive information is a more difficult problem: how can customer information be fully detected? What if it's in a Word, Excel, or compiled file? More research must be conducted in this field to study the extent of the problem and its solution.</p>
                </div>
            </section>


       …</article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tillsongalloway.com/finding-sensitive-information-on-github/">https://tillsongalloway.com/finding-sensitive-information-on-github/</a></em></p>]]>
            </description>
            <link>https://tillsongalloway.com/finding-sensitive-information-on-github/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23643373</guid>
            <pubDate>Thu, 25 Jun 2020 17:45:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Build a Culture of Delivery with Lean DevOps]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23643341">thread link</a>) | @jacksonpollock
<br/>
June 25, 2020 | https://cto.ai/blog/build-a-culture-of-delivery-with-lean-devops/ | <a href="https://web.archive.org/web/*/https://cto.ai/blog/build-a-culture-of-delivery-with-lean-devops/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
			<!-- .cover -->
			<div>
				<p>You've probably heard of a Lean Startup approach to building a business, but what about a Lean DevOps approach to scaling your development team?</p><p>To explain the difference between traditional DevOps and Lean DevOps, let's start at a cloud's eye view and work our way down.</p><p>The definition of traditional DevOps, as defined by <a href="https://aws.amazon.com/devops/what-is-devops/#:~:text=DevOps%20is%20the%20combination%20of,development%20and%20infrastructure%20management%20processes.">AWS</a>, is:</p><blockquote>DevOps is the combination of cultural philosophies, practices, and tools that increases an organization’s ability to deliver applications and services at high velocity: evolving and improving products at a faster pace than organizations using traditional software development and infrastructure management processes.</blockquote><!--kg-card-begin: image--><figure><img src="https://cto.ai/blog/content/images/2020/06/traditional-devopscycle-cto.ai.png"></figure><!--kg-card-end: image--><p>Lean DevOps makes a key distinction in the fact that it aims to not just bring velocity to the surface, but also simplicity. As such, Lean DevOps is defined as:</p><blockquote><em>Lean DevOps is a development philosophy that focuses on both velocity and simplicity via a combination of culture, best practices, and workflow automation tools.</em></blockquote><!--kg-card-begin: image--><figure><img src="https://cto.ai/blog/content/images/2020/06/lean-devops-cto.ai.png"></figure><!--kg-card-end: image--><p>Not only is traditional DevOps a major challenge for small companies trying to compete for skilled people, but those same startups also have the most promising opportunity to scale DevOps as part of their organizational structure and culture. In doing so, DevOps can be optimized using a lattice-style team philosophy where generalists and specialists are both leveraged and nurtured.</p><p>And Lean DevOps works. The <a href="https://puppet.com/resources/report/state-of-devops-report/">2019 State of DevOps Report</a> showed that companies who have high performing DevOps programs deploy software not only <strong>200 times more frequently</strong>, but also have <strong>2,555 times faster lead times</strong> for their projects. In addition, they also <strong>recover 24 times faster from failed changes</strong>, with <strong>three times lower change fail rates</strong>.</p><p>That equates to not just faster development, but faster business. You’ll reach milestones, OKRs, and goals earlier, and before your competition does. Thus, bringing developer tools into the realm of revenue generation and not just cost savings.</p><h2 id="-300b-in-lost-developer-productivity">$300B in Lost Developer Productivity</h2><!--kg-card-begin: image--><figure><img src="https://cto.ai/blog/content/images/2020/06/dev-productivity_cto.ai-2.png"></figure><!--kg-card-end: image--><p>Currently, DevOps is fragmented across innumerable tools and technologies. Developers have also been tasked with workflow automation, but this burns valuable time that could be used to build features for paying customers.</p><h3 id="often-you-ll-see-two-main-devops-challenges-">Often you’ll see two main DevOps challenges:</h3><ol><li><strong>Many companies struggle to adopt DevOps practices.</strong></li><li><strong>DevOps tools are far more complex than ever before.</strong></li></ol><p>That’s why <a href="https://stripe.com/reports/developer-coefficient-2018">$300 billion in developer productivity is lost every single year</a> within growing development teams.</p><p>Technical leaders know that, as their teams grow, it is critical to invest in the workflows that their teams require to work. However, it can be too time-consuming to allocate their critical internal resources.</p><p>That’s why a Lean DevOps approach is so important. It allows teams to remain lean, automate repeated workflows, and use tools and behaviors that increase simplicity and velocity.</p><h2 id="the-10x-engineer-is-dead">The 10X Engineer Is Dead</h2><!--kg-card-begin: image--><figure><img src="https://cto.ai/blog/content/images/2020/06/10x-engineer-cto.ai.png"></figure><!--kg-card-end: image--><p>And that’s why the 10X engineer is dead. Or, more appropriately, they never existed. However, a team’s ability to have a 10X impact is still very much alive.</p><p>Taking a Lean DevOps philosophy can work the same magic, but instead, focus on making a team of five engineers 2X as productive.</p><p>All they need to do is build the right culture, utilize industry best practices, and implement the best tools.</p><p>You can also consider building an organizational structure that unblocks your team like a lattice formation (pictured above) or holocracy-style team makeup that promotes a flat organization with limited bureaucracy and decentralized management.</p><p>These are frameworks for encoding autonomy, agility, and purpose-alignment into your organization's DNA.</p><h2 id="5-ways-to-build-a-culture-of-delivery">5 Ways to Build a Culture of Delivery</h2><!--kg-card-begin: image--><figure><img src="https://cto.ai/blog/content/images/2020/06/teamvelocity-process-cto.ai.png"></figure><!--kg-card-end: image--><p>So, how do I move to the Lean DevOps light, you ask? Well, here are five steps to follow while implementing and scaling your lean culture.</p><ol><li><strong>Stick with lean process for as long as possible.</strong> Don’t give in until it’s the right moment. Stay lean allows you to move quickly in the early stages of a company.</li><li><strong><strong><strong>Choose boring technology, invest wisely. </strong></strong></strong>Take time to pick the tools that increase simplicity in your workflows.</li><li><strong><strong><strong>Onboarding sets expectations. </strong></strong></strong>Don’t just drop a new tool at your team’s feet. Implement a rollout plan and lay out the education with it.</li><li><strong><strong><strong>Create a platform for success. </strong></strong></strong>Lead by example to live and breath your new-found Lean DevOps philosophy.</li><li><strong><strong><strong>ICE: Impact + Confidence / Effort. </strong></strong></strong>Balance your workload by debating with data and leveraging your highest value initiatives.</li></ol><p>Take the time necessary to get buy-in for a culture shift from your team. It's never easy, but if you do it right in the beginning the effects will become much more ingrained in your sprints.</p><h2 id="scaling-with-lean-devops">Scaling with Lean DevOps</h2><!--kg-card-begin: image--><figure><img src="https://cto.ai/blog/content/images/2020/06/devops-over-time-cto.ai.png"></figure><!--kg-card-end: image--><p>Remember, as your team scales you’ll move from a flatter organization to an Agile matrix one.</p><p>This will also affect your team velocity as process complexity increases.</p><p>So, as you scale, here are ways to stay within the Lean DevOps methodology:</p><ul><li><strong><strong><strong>Stay flat, fewer managers. </strong></strong></strong>Maintain accountability through transparency via tools like Slack and its companion app marketplace.</li><li><strong><strong><strong>Strategic vertical workstreams. </strong></strong></strong>Track product milestones in tools like Jira to provide visibility and a longer-term vision.</li><li><strong><strong><strong>Holistic horizontal specialization. </strong></strong></strong>Think about research and development, security, and codebase specialization as wide thoughts that span business functions.</li><li><strong><strong><strong>Don’t lose the ability to build a generalist culture. </strong></strong></strong>A team of polymaths will aide your problem solving and creative thinking.</li></ul><p>At the end of the day, there is no perfect process, but a combination of assets.</p><p>Tools with bottom-up adoption, a flat organizational structure to speed things up, adaptability, and a balance between velocity and stability are your targets.</p><p>Welcome to the delivery culture of Lean DevOps. Your team will thank you.</p><p>***</p><p><em>To learn about Lean DevOps in video form press play below.</em></p><!--kg-card-begin: embed--><figure><iframe width="480" height="270" src="https://www.youtube.com/embed/-4Q6xEeVYSY?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><!--kg-card-end: embed-->
			</div><!-- .post-content -->
			<!-- .post-footer -->
		</article></div>]]>
            </description>
            <link>https://cto.ai/blog/build-a-culture-of-delivery-with-lean-devops/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23643341</guid>
            <pubDate>Thu, 25 Jun 2020 17:43:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A mathematical formula that predicts US elections with 87.5% accuracy]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 27 (<a href="https://news.ycombinator.com/item?id=23643050">thread link</a>) | @bnveg
<br/>
June 25, 2020 | https://turingbotsoftware.com/posts/us-election-prediction.html | <a href="https://web.archive.org/web/*/https://turingbotsoftware.com/posts/us-election-prediction.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>              <p>ceil(cos(0.996479*x*((-0.0830122)*(log(x)*(1.58953e-05-x)))))</p>              <p>The formula above, obtained using a Symbolic Regression procedure, has an out-of-sample accuracy of 87.5% in predicting which party will win the US presidential elections in a given year.</p>              </div><div>              <h2>How it was generated</h2><p>The rationale behind this formula was to try to obtain a mathematical expression that classifies which party (Democrat or Republican) will win the US presidential elections in a given election year.</p><p>To train the model, we looked at all the US elections in the last 100 years, and generated a table where at each row the first column is the year, and the second is 0 if the winning candidate was a Democrat and 1 if the candidate was a Republican. These are the last rows in that table:</p><pre>1992 0
1996 0
2000 1
2004 1
2008 0
2012 0
2016 1
</pre><p>The full table can be found <a href="https://turingbotsoftware.com/data/presidents_numbers.txt">here</a>.</p><p>Then, to generate the model, we used the Symbolic Regression software TuringBot. The chosen search metric was classification accuracy, and a 70/30 train/test split was used to reduce the chance of overfitting. The split was sequential: the oldest years were used for the training, and the most recent ones were used for the cross-validation.</p><p>These are the models that were found, along with their corresponding out-of-sample classification accuracies:</p>              <p><img src="https://turingbotsoftware.com/images/president_model.png"></p><p>In these formulas, x is the election year (2012, 2016, 2020, etc). The best formula turned out to be <span>ceil(cos(0.996479*x*((-0.0830122)*(log(x)*(1.58953e-05-x)))))</span>. Its accuracy in the training split is 94.11%, and in the test split 87.5%.</p>              <h2>The prediction for 2020</h2><p>Calculating the formula above at x = 2020, we find that the result is 1. This means that the formula predicts that a Republican is likely to win the elections.</p>              <h2>The prediction for the next elections</h2><p>We can also calculate the formula for the next elections. These are the results:</p><pre>2024: Democrat
2028: Republican
2032: Republican
</pre><p>It should be noted that the accuracy of the model is expected to degrade the further you go into the future.</p>              </div></div>]]>
            </description>
            <link>https://turingbotsoftware.com/posts/us-election-prediction.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23643050</guid>
            <pubDate>Thu, 25 Jun 2020 17:22:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[XMPP in Go]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23642896">thread link</a>) | @SamWhited
<br/>
June 25, 2020 | https://blog.samwhited.com/2020/06/xmpp-in-go/ | <a href="https://web.archive.org/web/*/https://blog.samwhited.com/2020/06/xmpp-in-go/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
		<p><strong>Note:</strong> This post is about the <a href="https://pkg.go.dev/mellium.im/xmpp"><code>mellium.im/xmpp</code></a> project, an XMPP library
for <a href="https://golang.org/">Go</a>.
Some parts of this post may apply exclusively to <a href="https://pkg.go.dev/mellium.im/xmpp@v0.16.0">v0.16.0</a>.
Because this version is pre-1.0, things may change by the time you read this.
The most up-to-date version of this document can always be found at
<a href="https://mellium.im/docs/overview"><code>mellium.im/docs/overview</code></a>.</p>
<hr>
<p>Go is a great language if you need to get a project off the ground quickly. It
has its confusing aspects, and its type system allows for lots of abuse thanks
to <a href="https://blog.samwhited.com/2017/08/the-case-for-interface/">optional dynamic typing</a>, but overall it’s easy to read and easy to quickly
build projects that require clear code over absolute type safety.
Similarly, <!-- raw HTML omitted -->XMPP<!-- raw HTML omitted --><sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> has its warts, but overall is the best choice to get a
chat product off the ground quickly if you want a system that’s well understood
and has a robust ecosystem and sustainable standards body.</p>
<p>Since Go shines at handling I/O bound services (like asynchronous network
protocols used for instant messaging), an XMPP library in Go seems like a great
fit.
There are a handful of libraries to handle XMPP already in existence, but most
of them are small high-level libraries designed only to work with the legacy
version of XMPP that was supported by Google Talk, or don’t follow Go idioms and
best practices.
When I started looking into a Go XMPP implementation around 5 years ago, there
wasn’t a low-level library meant to act as a building block from which higher
level systems could be created, and that’s what I wanted: the equivalent of the
standard libraries <a href="https://golang.org/pkg/net/http/"><code>net/http</code></a> but for XMPP.
This is why I created <a href="https://pkg.go.dev/mellium.im/xmpp"><code>mellium.im/xmpp</code></a>.
This post will be about some of the design decisions I made while building the
library, and about some of the trade offs made along the way.</p>
<h2 id="stream-features">Stream Features</h2>
<p>Let’s start by talking about feature negotiation.
An XMPP session can broadly be divided up into two parts: the synchronous
initial handshake, and the actual asynchronous session.
Within this initial handshake, a series of common features are negotiated in a
certain order.
For example, if TLS isn’t already in use, opportunistic TLS (StartTLS) might be
negotiated, followed by authentication.
This ends up being a loop where the server sends any features it wants to
advertise at the current moment (eg. just TLS) then the client chooses one to
negotiate and proceeds with that features specific negotiation steps.
Then the server sends another list (possibly with new features, eg. now that we
have TLS negotiated the server might advertise that authentication is now ready
to proceed) and the client selects one and moves forward.
This loop is easy enough to write in Go, but representing the features
themselves was tricky.
Features need to be able to encode the name they go by when the server lists
them and any information that should be included in that listing, they need to
be able to parse that payload from the clients side, and the actual negotiation
from the server and clients side needs to happen.
To handle this a struct containing three functions for listing features, parsing
the features list, and negotiating the features was created.
This means less boilerplate and more type safety than using an interface to
represent a stream feature.
It also makes it less likely that a user of this API will get confused and write
stateful stream features, but if necessary the functions can still close over
external state or resources (but don’t do this, you may think you need it, but
you’re almost certainly wrong).</p>
<pre><code>type StreamFeature struct {
	Name xml.Name

	Necessary SessionState
	Prohibited SessionState

	List func(ctx context.Context, e xmlstream.TokenWriter, start xml.StartElement) (req bool, err error)
	Parse func(ctx context.Context, r xml.TokenReader, start *xml.StartElement) (req bool, data interface{}, err error)
	Negotiate func(ctx context.Context, session *Session, data interface{}) (mask SessionState, rw io.ReadWriter, err error)
}
</code></pre><p>We also need to have a way to encode the order features should appear in (eg.
auth should not be attempted before TLS).
I decided that features would order themselves based on the state of the
session at the moment when feature negotiation happens.
The feature would say what properties of the session are or are not allowed, and
the thing doing negotiation can determine whether the session currently meets
those criteria.
Session state information only has 4 properties that are useful for session
negotiation:</p>
<ul>
<li>Is a security layer in place (eg. TLS),</li>
<li>has authentication been performed,</li>
<li>is feature negotiation complete, and</li>
<li>was the session initiated by a remote entity?</li>
</ul>
<p>These are part of the <a href="https://pkg.go.dev/mellium.im/xmpp#SessionState"><code>SessionState</code></a> bits, so in the stream features we can
encode what bits are <a href="https://pkg.go.dev/mellium.im/xmpp#StreamFeature.Necessary">necessary</a> and what bits are <a href="https://pkg.go.dev/mellium.im/xmpp#StreamFeature.Necessary">prohibited</a> and the state
machine that handles session negotiation will be able to figure out when to
advertise or negotiate the feature using simple bit math.</p>
<pre><code>const (
	// Secure indicates that the underlying connection has been secured. For
	// instance, after STARTTLS has been performed or if a pre-secured connection
	// is being used such as websockets over HTTPS.
	Secure SessionState = 1 &lt;&lt; iota

	// Authn indicates that the session has been authenticated (probably with
	// SASL).
	Authn

	// Ready indicates that the session is fully negotiated and that XMPP stanzas
	// may be sent and received.
	Ready

	// Received indicates that the session was initiated by a foreign entity.
	Received

	…
)
</code></pre><h2 id="session-negotiation">Session Negotiation</h2>
<p>Once we have a set of features that we can negotiate, we need to do the actual
session negotiation.
Normally, XMPP negotiates a session over TCP using the features loop that we
already described, however, sometimes an alternative mechanism might be required
for negotiation such as the websocket subprotocol defined in <a href="https://tools.ietf.org/html/rfc7395">RFC 7395</a> or the
legacy <a href="https://xmpp.org/extensions/xep-0114.html">XEP-0114: Jabber Component Protocol</a>.
Generalizing session negotiation meant allowing the user to provide a special
negotiator function and writing a default one for the basic XMPP stream
negotiation protocol.</p>
<pre><code>type Negotiator func(ctx context.Context, session *Session, data interface{})
  (mask SessionState, rw io.ReadWriter, cache interface{}, err error)
</code></pre><p>Because the negotiator can’t change the session state if it’s written in another
package (since the session state bits aren’t exported), it returns any changes
it wants to be made to the session such as the new session state mask, or any
changes to the underlying reader and writer (eg. if we negotiate StartTLS it
might return a new reader and writer that speak TLS).
The internal code that calls the negotiator function can then create a new
session with the requested changes.</p>
<p>The builtin negotiator can be created with <a href="https://pkg.go.dev/mellium.im/xmpp#NewNegotiator"><code>NewNegotiator</code></a> and supports
various options such as setting the stream language and copying the input and
output streams somewhere else (such as an XML console):</p>
<pre><code>// StreamConfig contains options for configuring the default Negotiator. 
type StreamConfig struct {
	// The native language of the stream.
	Lang string

	// S2S causes the negotiator to negotiate a server-to-server (s2s) connection.
	S2S bool

	// A list of stream features to attempt to negotiate.
	Features []StreamFeature

	// If set a copy of any reads from the session will be written to TeeIn and
	// any writes to the session will be written to TeeOut (similar to the tee(1)
	// command).
	// This can be used to build an "XML console", but users should be careful
	// since this bypasses TLS and could expose passwords and other sensitve data.
	TeeIn, TeeOut io.Writer
}

// NewNegotiator creates a Negotiator that uses a collection of StreamFeatures
// to negotiate an XMPP client-to-server (c2s) or server-to-server (s2s)
// session.
// If StartTLS is one of the supported stream features, the Negotiator attempts
// to negotiate it whether the server advertises support or not.
func NewNegotiator(cfg StreamConfig) Negotiator
</code></pre><p>It uses stream features as discussed in the previous
section, but custom negotiators could be written that use a different type for
stream features, making session negotiation and stream features entirely
modular.
You could replace them with your own implementations, and still use the <code>xmpp</code>
package to handle the lower level XMPP protocol.</p>
<p>An example of a custom stream negotiator can be found in the <a href="https://pkg.go.dev/mellium.im/xmpp/component"><code>xmpp/component</code></a>
package which negotiates a <a href="https://xmpp.org/extensions/xep-0114.html">XEP-0114: Jabber Component Protocol</a>
connection.</p>
<h2 id="receiving-data">Receiving Data</h2>
<p>Once the session is negotiated, we need to be able to receive stanzas (the
primitive types of XMPP) and other top level XML elements over the session.
Because the main <code>xmpp</code> package is meant to be lower level than many other XMPP
libraries written for Go, it does not contain callbacks or any way to register
handlers for different types of top level XML element.</p>
<p>Instead, it contains a single <a href="https://pkg.go.dev/mellium.im/xmpp#Session.Serve"><code>Session.Serve</code></a> method that decodes all incoming
XML tokens and delegates handling them to a single <a href="https://pkg.go.dev/mellium.im/xmpp#Handler"><code>Handler</code></a>.</p>
<pre><code>// A Handler triggers events or responds to incoming elements in an XML stream.
type Handler interface {
	HandleXMPP(t xmlstream.TokenReadEncoder, start *xml.StartElement) error
}
</code></pre><p>The <code>Serve</code> method also handles stanza semantics such as always responding to
IQs as required to be compliant with the XMPP protocol.
Because the handler is provided with a stream to use when writing back to the
session, the underlying library can man-in-the-middle the token stream and check
if an IQ response was written and automatically send one if not, or add required
IDs to stanzas that are missing them.</p>
<p>This design also keeps the number of methods on the session relatively low and
keeps the entire library more modular because we can delegate multiplexing
elements to more specific handlers to other packages such as the builtin
<a href="https://pkg.go.dev/mellium.im/xmpp/mux"><code>xmpp/mux</code></a> package.
If a user wants a more advanced multiplexer that buffers the stream and matches
stream elements based on <a href="https://relaxng.org/">RELAX NG</a>, <a href="https://web.archive.org/web/20200320131503/http://www.jclark.com/xml/xmlns.htm">Clark notation</a>, or <a href="https://www.w3.org/TR/xpath/all/">XPath</a>, they could
write it themselves and it would have all the same powers and access as the
built in muxer!
The <code>mux</code> package also provides more specific handlers for the basic XMPP stanza
types: <a href="https://pkg.go.dev/mellium.im/xmpp/mux#IQHandler"><code>IQHandler</code></a>, …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.samwhited.com/2020/06/xmpp-in-go/">https://blog.samwhited.com/2020/06/xmpp-in-go/</a></em></p>]]>
            </description>
            <link>https://blog.samwhited.com/2020/06/xmpp-in-go/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23642896</guid>
            <pubDate>Thu, 25 Jun 2020 17:09:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Real-time uptime monitor of Let's Encrypt]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23642758">thread link</a>) | @enigmabridge
<br/>
June 25, 2020 | https://keychest.net/letsencrypt | <a href="https://web.archive.org/web/*/https://keychest.net/letsencrypt">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://keychest.net/letsencrypt</link>
            <guid isPermaLink="false">hacker-news-small-sites-23642758</guid>
            <pubDate>Thu, 25 Jun 2020 16:57:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A UX approach to video meeting fatigue]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23642756">thread link</a>) | @dxchester
<br/>
June 25, 2020 | https://team.video/blog/camera | <a href="https://web.archive.org/web/*/https://team.video/blog/camera">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p><img src="https://team.video/uploads/camera-on-or-off.jpg" alt=""></p>

<section data-level="1" id="camera-on-or-off-a-ux-approach-to-video-meeting-fatigue">

<section data-level="3" id="video-conferencing-is-the-new-office-living-room-dinner-table-doctors-office-"><h3>Video conferencing is the new office / living room / dinner table / doctors office...</h3>
<p>As the spaces of our social lives have transitioned to a limited number of software interfaces, fatigue and burnout has skyrocketed taxing our mental health and productivity. While video conferencing apps are keeping us employed and connected, they are not prepared to handle this mass shift in our daily routines and social interactions. </p>

</section>
<section data-level="3" id="what-makes-video-conferencing-so-different-"><h3>What makes video conferencing so different?</h3>
<p>When we spend our days sitting in our makeshift offices and personal spaces staring at our coworkers, friends, doctors, teachers and families (and don’t forget ourselves!) in little boxes on our screens we miss so much of the social experience of real face to face interactions. We’re unable to read body language, engage in normal social rituals, have serendipitous conversations—to move!</p>
<p>We’re also responding to a unending amount of new information that our brains need to process—our personal lives surrounding us at home, the apartments and houses of our coworkers and their personal lives happening around them, the host of distractions on our desktops and the lure of almost unnoticeable multitasking. </p>
<p><img src="https://team.video/uploads/camera-ui.jpg" alt=""></p>

</section>
<section data-level="3" id="can-the-design-of-our-meeting-software-help-"><h3>Can the design of our meeting software help?</h3>
<p>As a UX designer working to build a video conferencing platform, it’s been crucial to acknowledge the limitations of the medium in hopes of easing some of the fatigue with features designed not to replicate in person communication but to uncover and build on the strengths of a relatively new space.    </p>

</section>
<section data-level="3" id="improving-our-new-space-the-meeting-room"><h3>Improving our new space - The meeting room</h3>
<p>We spend so much care and effort creating the physical spaces we occupy, and these spaces have a known effect on our mental health as well as our productivity, creativity and sociablility. A black box filled with poor quality images littered with icons can feel like spending all day in a messy room with no windows—of course we’re exhausted after a day of video meetings! But what can we do to make these new rooms feel like  sleek, light filled rooms with all the personal touches that we invest so much thought into? </p>
<p><img src="https://team.video/uploads/camera-meetingroom.jpg" alt=""></p>
<p>The furniture, if you will, of these new spaces is entirely different. Instead of tables, whiteboards and light switches we have new furniture that has to replicate everything else missing from in person interaction—all those icons littered about. Unmute is the desk of a virtual meeting room.</p>
<p>Designing meetings rooms for Team.video has strived to take into account interior design principles as well as UX best practices. Does a glaring red mute icon create more stress and visual clutter than it provides important functional information? Our process has been one of many iterations, focusing on light colors, subtle gradients and subdued accents.</p>

</section>
<section data-level="3" id="camera-on-or-off-"><h3>Camera on or off?</h3>
<p>We’ve never been more aware of the green light at the top of our screens. In almost daily research sessions over the past few months I've yet to encounter a team that has found the golden solution to the camera on or off question. </p>
<p>Companies that had a camera on policy have switched to camera optional and those with a camera optional approach have switched to camera on. Some teams use cameras only for smaller meetings or only require those speaking to use video. </p>
<p>Camera off can feel less personal but also removes the need to process so many different faces and backgrounds at once. While being on camera for the majority of a day is incredibly exhausting and not always necessary for productive work meetings. </p>
<ul>
<li>There is probably no golden solution, but some design attention can greatly improve both sides of the coin. </li>
<li>A more aesthetically pleasing camera off view that still includes the face of a coworker and a signal when/that they are speaking. </li>
<li>Flexible layouts for different scenarios—one speaker, a handful of speakers, screenshare brainstorm etc. </li>
<li>The option to hide or minimize your own video. </li>
<li>Blurred or custom backgrounds for camera on mode—which can be a lot of fun and also a potential new distraction. </li>
</ul>
<p><img src="https://team.video/uploads/cameraonoroff.png" alt=""></p>

</section>

<section data-level="3" id="meetings-start-very-abruptly"><h3>Meetings start VERY abruptly</h3>
<p>All of a sudden you’re face to face with an unfamiliar coworker, from your bedroom...and the person who called the meeting is running late. This scenario is unique to telecommuting. Maybe you regularly walk to the conference room with a coworker, or you introduce yourself politely and take the first few minutes of a meeting to fill your water bottle while everyone else arrives. </p>
<p>All of this is much more awkward over video. Small talk is less natural with mute/unmute issues, lack of non verbal cues and often bandwidth time delays. Widespread goals to keep meetings efficient encourage us to get straight to the point, which can be jarring. </p>
<p>How can UX help those first few meeting minutes? </p>
<ul>
<li>It’s important to know who is already in the meeting before you join so you can decide if you want to be one on one with a C level you’ve never met. </li>
<li>Arrive looking (and sounding!) your best with a pre-meeting ‘haircheck’ where meeting goers can check their audio/video before entering the meeting</li>
<li>Low effort social interaction built in to the welcome minutes. At team.video we’ve implemented an optional word game that early arrivers can play against each other in lieu of or in addition to any amount of small talk. </li>
</ul>
<p><img src="https://team.video/uploads/camera-haircheck.jpg" alt=""></p>
<p><img src="https://team.video/uploads/camera-game.jpg" alt=""></p>

</section>
<section data-level="3" id="keep-trying-new-things-"><h3>Keep trying new things!</h3>
<p>Design is always about observing, trying and testing. With team.video we’ve been able to explore some ideas larger companies have not and we’d love to hear any thoughts or issues that you’ve encountered in our software or others! </p>
<p>Try us out at <a href="https://team.video/">Team.Video</a></p>

</section>
</section>
    </div></div>]]>
            </description>
            <link>https://team.video/blog/camera</link>
            <guid isPermaLink="false">hacker-news-small-sites-23642756</guid>
            <pubDate>Thu, 25 Jun 2020 16:57:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How we launched our MVP in 3 weeks]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 62 (<a href="https://news.ycombinator.com/item?id=23642739">thread link</a>) | @adamthewan
<br/>
June 25, 2020 | https://adamthewan.com/blog/meetbutter/how-we-built-meetbutter-three-weeks/ | <a href="https://web.archive.org/web/*/https://adamthewan.com/blog/meetbutter/how-we-built-meetbutter-three-weeks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAIAAACgpqunAAAACXBIWXMAAAsSAAALEgHS3X78AAADWElEQVQozxWT21MaBxTG95/oUx/71ulDM2msjk2nLRgcjZHEiRgpiQmiIVgUlmyAhb3Ccr8srMsdFpQFuQaQBBMTBLWY6Ux0Js3UNu3YPnQy0z+gY966fT5n5vu+8/0OwFLNsK2hVyQQTRTTciGy7oWr61TTj1Rdxi2WapXS/Q12l7E1AkgtHewkfU8rmX4+8iIV6AAhok7jda8lGiJZy4OkDaRJXQJfzbtNJQrkfZZKxNGMOBsvW697nZO3x2cnr/4Ikw27ng+Rj4EG/9PZu9edWoWyriLmzw0qC41vMfaWx1wWlClD3gmVaWyXYwYJ/0GW2a9m+x64LFiLedpA98mbEldDtTYYvIpaP7FocYeh7oG3PHCpmOim/AcRdymfflDM3SznZ7z4HUjJuYxFO8iTujwA3UuszUdtIFPJ/vh8e4exR2mkJYzNy1wx1X1cdpz9Lvpw/umT9se7ux9tcJ9ZNSmTKmPTbzJkAyBBXnbNu3I/W6gfRJotjXtdrvLoFtMRdysT/eHD+Y3zf794//fUu9+g/R7pd/jvSZ3626xwlKT/KbB4NykWuS9esI4pLTMO83Uc/k6KjYzYKaLFsZk4q0jHR/Z7NyNeBlri0sHa4Yt+LJiGV9ij7ikwLnVMLhBDw8jQEDqxiImniWkJI5Xio5ehWalFPg7Lpx7JJbBiGuYjeVSNbwbT/5z+lVnnc+wOcG3RNqnEL11Ev5lCpXp88j4qvkWMjC6Pjq2JrtogZUqnYMHbybSv0Mm1VPNzQYQ4qh52O2Wt3A+IRc4vL+CiWcTMs9ZCTBawyGn0soicGA/eWYiZVnJZ+plBGSfU4Vq48ufR4dnhyUErx4a/tmpigEjkGL6Ea/F4utlRm6LXH2FXZomvJEgmt/fr6ftB75ds+BlLbRuX44a7bo8p4rPGQKXdrA4L/ACjI6T4BoFns1AgNSdjr4y5hoexGQPZe3s8eHXqs1Yx7UZ/503M1V6S0msKtrk1IHS8eYn7v2cpiMoo9JYXlUGUZNw1MW9XOXxC+NUQAy7FoYWEQFIAqyOarLAdc7f56EujMomscDHPNjDnxGROdM6FyezYtxJC/3Bzp3+sUIeU39OW5Qz1sOgylgT+C4luMbknPAON1e1gIeFrD/Z+/g9UCcPcvxQNXAAAAABJRU5ErkJggg==" alt="Cover"></p></div><div><div><div><p>This should be </p><!-- --><p>an</p><!-- --> <!-- --><p>11 min read</p><p>June 12, 2020</p></div></div><p><img src="https://adamthewan.com/static/adam-head-0b2b466e69071c2bd52efa9911165bc6.png"></p></div><p>Usually, when people think about building and launching a startup, they plan it out a few weeks in advance. In my experience doing software consulting, I’ve seen and worked on some projects where the founders take 2 - 3 months to launch the first version of their product. That’s too much time and effort sunk into a project that may not work.</p><h2>Why you need to get your Minimum Viable Product out ASAP</h2><p>The problem is that most people are not comfortable with launching a minimum viable product. Founders are often creative people who love to explore and dive into “wouldn’t it be cool if”s. This habit can result in a continuous loop of adding features, even before the first version of your product is released.</p><p>Perfectionism can often get in the way of execution, and I’ve fallen for this trap many times. My first product (SideQuest) took me four months to build and launch. To continue developing an untested product is, to put it bluntly, arrogant. Here’s why: it assumes that what you are making is vital for your customer. It assumes that you know what’s best for your user. You don’t.</p><figure>
    <span>
      <a href="https://adamthewan.com/static/bf4b544235b8f033c381798a61ce5e33/c1b63/reiterations.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Image: What your startup journey will probably look like" title="Image: What your startup journey will probably look like" src="https://adamthewan.com/static/bf4b544235b8f033c381798a61ce5e33/fcda8/reiterations.png" srcset="https://adamthewan.com/static/bf4b544235b8f033c381798a61ce5e33/12f09/reiterations.png 148w,https://adamthewan.com/static/bf4b544235b8f033c381798a61ce5e33/e4a3f/reiterations.png 295w,https://adamthewan.com/static/bf4b544235b8f033c381798a61ce5e33/fcda8/reiterations.png 590w,https://adamthewan.com/static/bf4b544235b8f033c381798a61ce5e33/efc66/reiterations.png 885w,https://adamthewan.com/static/bf4b544235b8f033c381798a61ce5e33/c83ae/reiterations.png 1180w,https://adamthewan.com/static/bf4b544235b8f033c381798a61ce5e33/c1b63/reiterations.png 1200w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span>
    <figcaption>Image: What your startup journey will probably look like</figcaption>
  </figure><p>No founder knows until they launch their startup and get feedback from people. Your first version is likely going to suck; it might even miss the mark or be utterly irrelevant to the market. You need to get any negative and positive signals from your target market as soon as possible.</p><p>That was what we tried to do with MeetButter. Everyone on our team has had experience getting burnt by wasting time, runway, effort, and emotion building products or features that were inconsequential in the larger picture.</p><p>Here’s the story of how we managed to build and ship MeetButter in three weeks.</p><h3>Step 1 - Identification</h3><figure>
    <span>
      <a href="https://adamthewan.com/static/bb7bc5be7eb59accce1ffcd6b43444df/c1b63/slack-discussion.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="It started with a thread" title="It started with a thread" src="https://adamthewan.com/static/bb7bc5be7eb59accce1ffcd6b43444df/fcda8/slack-discussion.png" srcset="https://adamthewan.com/static/bb7bc5be7eb59accce1ffcd6b43444df/12f09/slack-discussion.png 148w,https://adamthewan.com/static/bb7bc5be7eb59accce1ffcd6b43444df/e4a3f/slack-discussion.png 295w,https://adamthewan.com/static/bb7bc5be7eb59accce1ffcd6b43444df/fcda8/slack-discussion.png 590w,https://adamthewan.com/static/bb7bc5be7eb59accce1ffcd6b43444df/efc66/slack-discussion.png 885w,https://adamthewan.com/static/bb7bc5be7eb59accce1ffcd6b43444df/c83ae/slack-discussion.png 1180w,https://adamthewan.com/static/bb7bc5be7eb59accce1ffcd6b43444df/c1b63/slack-discussion.png 1200w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span>
    <figcaption>It started with a thread</figcaption>
  </figure><p>The first spark for MeetButter was a Slack thread discussing the pains teachers and educators were dealing with transitioning their classrooms from offline to online. We found that there was a very human problem with online video conferencing - they only allowed the focus to one speaker at a time. It was awkward interrupting the speaker, and this caused some participants to feel reluctant to engage. The discussion thread grew, with more anecdotes and feedback from our friends and family.</p><p>Identifying the problem is the first step. It’s crucial to figure out the groups of people that are facing the same issues and gathering feedback from them. </p><h3>Step 2 - Investigation</h3><p>We decided to take this asynchronous discussion and organize a synchronous brainstorm session. During this particular session, we discussed three significant problems that we had identified and were interested in solving. On the list was the aforementioned “video conferencing” - which eventually became MeetButter.</p><figure>
    <span>
      <a href="https://adamthewan.com/static/a39386985de85513d6f9d5134921e3f4/c1b63/brainstorm.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Breaking down the current video conferencing experience" title="Breaking down the current video conferencing experience" src="https://adamthewan.com/static/a39386985de85513d6f9d5134921e3f4/fcda8/brainstorm.png" srcset="https://adamthewan.com/static/a39386985de85513d6f9d5134921e3f4/12f09/brainstorm.png 148w,https://adamthewan.com/static/a39386985de85513d6f9d5134921e3f4/e4a3f/brainstorm.png 295w,https://adamthewan.com/static/a39386985de85513d6f9d5134921e3f4/fcda8/brainstorm.png 590w,https://adamthewan.com/static/a39386985de85513d6f9d5134921e3f4/efc66/brainstorm.png 885w,https://adamthewan.com/static/a39386985de85513d6f9d5134921e3f4/c83ae/brainstorm.png 1180w,https://adamthewan.com/static/a39386985de85513d6f9d5134921e3f4/c1b63/brainstorm.png 1200w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span>
    <figcaption>Breaking down the current video conferencing experience</figcaption>
  </figure><p>Some significant points were brought up by everyone on the team, and we found that these were problems that each one of us had faced while doing online video conferencing:</p><ol><li>It’s difficult to indicate an interest in speaking, reply to the current conversation, or add to the discussion without feeling like you’re interrupting the current speaker.</li><li>It’s impossible to transition smoothly between one speaker to the next. Sometimes mid-sentence pauses are met with several speakers trying to enter into the conversation at once. Combined with lag, this can get quite awkward.</li><li>The avoidance of awkwardness causes some people to remain quiet.</li><li>The loudest voice in the room problem - some people naturally dominated discussions.</li><li>Social cues are almost non-existent when your entire team gets boxed into tiny windows on-screen and are only visible from their shoulder up.</li></ol><p>The purpose of this brainstorm was not to narrow down into solutions, but it was to dive deep into the problems.</p><div><p>Adam is typing something... (Click to reveal)</p><p><img src="https://adamthewan.com/static/adam-head-0b2b466e69071c2bd52efa9911165bc6.png"></p></div><h3>Step 3 - Sketching</h3><p>After the brainstorm session, we discussed some ideas on how to tackle the problem. Solutions can seem pretty vague, and usually, what happens is that several keywords get thrown around. For us, it was “queue,” “overlay,” and “polls.” It’s good to note that people often visualize keywords differently and form very different concepts in their heads. </p><p>A picture is worth a thousand words. Sketching is an essential skill to learn for any founder, as it’s the best medium to transfer your ideas with a low signal-noise ratio. People often misunderstand your words. If you’re not good at drawing, it’s good to learn how to sketch out a prototype digitally using free tools like Figma. I have even used Google Slides to build a low fidelity prototype for a client once! Sometimes I even screenshot parts of other apps and combine them into a Frankenstein of an image - anything to help bridge the gap between your vision and their imagination.</p><figure>
    <span>
      <a href="https://adamthewan.com/static/ac5ea0b862d651aee09be122cf1e3d76/07a9c/prototype-sketch.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Sketch of the app that turned into MeetButter" title="Sketch of the app that turned into MeetButter" src="https://adamthewan.com/static/ac5ea0b862d651aee09be122cf1e3d76/fcda8/prototype-sketch.png" srcset="https://adamthewan.com/static/ac5ea0b862d651aee09be122cf1e3d76/12f09/prototype-sketch.png 148w,https://adamthewan.com/static/ac5ea0b862d651aee09be122cf1e3d76/e4a3f/prototype-sketch.png 295w,https://adamthewan.com/static/ac5ea0b862d651aee09be122cf1e3d76/fcda8/prototype-sketch.png 590w,https://adamthewan.com/static/ac5ea0b862d651aee09be122cf1e3d76/efc66/prototype-sketch.png 885w,https://adamthewan.com/static/ac5ea0b862d651aee09be122cf1e3d76/c83ae/prototype-sketch.png 1180w,https://adamthewan.com/static/ac5ea0b862d651aee09be122cf1e3d76/07a9c/prototype-sketch.png 1440w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span>
    <figcaption>Sketch of the app that turned into MeetButter</figcaption>
  </figure><p>Based on the feedback and ideas from the team, this was the very first sketch for MeetButter that I built using Figma. After sharing it on our team Slack, we held a meeting to discuss the steps moving forward. We decided to cut out some features and instead focus on the queuing functionality as we were able to test it internally during our daily standup calls.</p><h3>Step 4 - Prototyping</h3><p>I won’t go into too much detail about how we built the prototype. This step will be different for every team: some teams will opt to do a no-code prototype using tools like AirTable and Google Forms; some will choose to do a “simulated” prototype using Figma or Zeplin; some will opt to build a fully functioning albeit minimal prototype using code. We decided to do the latter as it was the fastest for me to code something quickly.</p><figure>
    <span>
      <a href="https://adamthewan.com/static/2bbc76946aa01d921cf2ae13d7aeaeee/c1b63/hackathon.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Developers during a hackathon weekend" title="Developers during a hackathon weekend" src="https://adamthewan.com/static/2bbc76946aa01d921cf2ae13d7aeaeee/fcda8/hackathon.png" srcset="https://adamthewan.com/static/2bbc76946aa01d921cf2ae13d7aeaeee/12f09/hackathon.png 148w,https://adamthewan.com/static/2bbc76946aa01d921cf2ae13d7aeaeee/e4a3f/hackathon.png 295w,https://adamthewan.com/static/2bbc76946aa01d921cf2ae13d7aeaeee/fcda8/hackathon.png 590w,https://adamthewan.com/static/2bbc76946aa01d921cf2ae13d7aeaeee/efc66/hackathon.png 885w,https://adamthewan.com/static/2bbc76946aa01d921cf2ae13d7aeaeee/c83ae/hackathon.png 1180w,https://adamthewan.com/static/2bbc76946aa01d921cf2ae13d7aeaeee/c1b63/hackathon.png 1200w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span>
    <figcaption>Developers during a hackathon weekend</figcaption>
  </figure><p>The purpose of our prototype was to test:</p><ol><li><p>If the core hypothesis works. In this case, we wanted to test if allowing participants to queue would help meetings flow better.</p></li><li><p>If we could build the tech. Founders often underestimate the technical work that goes into creating their vision. Building a prototype allows you to do a mini feasibility test.</p></li></ol><div><p>Adam is typing something... (Click to reveal)</p><p><img src="https://adamthewan.com/static/adam-head-0b2b466e69071c2bd52efa9911165bc6.png"></p></div><h3>Step 5 - Testing and Feedback</h3><figure>
    <span>
      <a href="https://adamthewan.com/static/8282a9af1ca9ee66ef4e2591a938b2d3/c1b63/mvp.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="It's alive!" title="It's alive!" src="https://adamthewan.com/static/8282a9af1ca9ee66ef4e2591a938b2d3/fcda8/mvp.png" srcset="https://adamthewan.com/static/8282a9af1ca9ee66ef4e2591a938b2d3/12f09/mvp.png 148w,https://adamthewan.com/static/8282a9af1ca9ee66ef4e2591a938b2d3/e4a3f/mvp.png 295w,https://adamthewan.com/static/8282a9af1ca9ee66ef4e2591a938b2d3/fcda8/mvp.png 590w,https://adamthewan.com/static/8282a9af1ca9ee66ef4e2591a938b2d3/efc66/mvp.png 885w,https://adamthewan.com/static/8282a9af1ca9ee66ef4e2591a938b2d3/c83ae/mvp.png 1180w,https://adamthewan.com/static/8282a9af1ca9ee66ef4e2591a938b2d3/c1b63/mvp.png 1200w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span>
    <figcaption>It's alive!</figcaption>
  </figure><p>Once you have your prototype, you need to get it in front of some test users. Finding test users can be tricky.  Ideally, the test users should be from within your team; this was the case for us with MeetButter. It meant that we were building a product for ourselves, that we were part of our target market. Building a product to solve your problems has some apparent benefits: </p><ol><li>It creates a shorter and more efficient feedback loop.</li><li>It’s easier to innovate on issues you face</li><li>It somewhat validates your market.</li></ol><p>If you are building a product that’s not for yourself, I’d suggest finding at least ten people within your networks who can become your loyal test users.</p><p>MeetButter was also super easy to integrate into our daily workflow. All we had to do was open up the web app during our regular standup calls. It’s essential to build some sort of feedback loop. I sent a Google Form to the participants of the meeting to gather initial feedback as soon as the meeting ended - it’s best to strike while the iron is hot. We also had several Slack threads discussing additional ideas that came up as we continued testing.</p><h3>Step 6 - Reiteration</h3><p>After testing our prototype, we collected the feedback and went back to the drawing board. At this point, you have to make a clear decision with your prototype - do you continue to reiterate, or do you kill the project? We found that our prototype worked quite well, and although we were skeptical, there was a sense that we were onto something. We started using the prototype in every meeting, so it was hard to deny that our team internally found it useful.</p><figure>
    <span>
      <a href="https://adamthewan.com/static/e766445b8bfa6e293cbb0db6b23fedef/c1b63/feedback-loop.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="The typical product development feedback loop" title="The typical product development feedback loop" src="https://adamthewan.com/static/e766445b8bfa6e293cbb0db6b23fedef/fcda8/feedback-loop.png" srcset="https://adamthewan.com/static/e766445b8bfa6e293cbb0db6b23fedef/12f09/feedback-loop.png 148w,https://adamthewan.com/static/e766445b8bfa6e293cbb0db6b23fedef/e4a3f/feedback-loop.png 295w,https://adamthewan.com/static/e766445b8bfa6e293cbb0db6b23fedef/fcda8/feedback-loop.png 590w,https://adamthewan.com/static/e766445b8bfa6e293cbb0db6b23fedef/efc66/feedback-loop.png 885w,https://adamthewan.com/static/e766445b8bfa6e293cbb0db6b23fedef/c83ae/feedback-loop.png 1180w,https://adamthewan.com/static/e766445b8bfa6e293cbb0db6b23fedef/c1b63/feedback-loop.png 1200w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span>
    <figcaption>The typical product development feedback loop</figcaption>
  </figure><p>We repeated the process of designing, reiterating, and receiving feedback several times. Our testing group grew from our internal team of five people out to our friends within our social circles.</p><h3>Final Step - Launch</h3><p>After a few rounds of iterations, our prototype slowly shed its pieces and morphed into something resembling a product. As soon as we exhausted our immediate networks, we knew that the next step was to launch MeetButter beyond internal test users.</p><p>I began to lay the groundwork for a codebase that could grow into a scalable project. Our tech stack ended up being the following:</p><ul><li>Frontend - NextJS with Redux and GraphQL</li><li>Backend - A mix of Firebase and an Express server that’s powered by Apollo GraphQL and Sequelize</li><li>Infrastructure - We used Netlify and AWS to deployment</li></ul><figure>
    <span>
      <a href="https://adamthewan.com/static/ab6b779f27ff6765213b06367efeec87/c1b63/pmf.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Why it's important to fail fast" title="Why it's important to fail fast" src="https://adamthewan.com/static/ab6b779f27ff6765213b06367efeec87/fcda8/pmf.png" srcset="https://adamthewan.com/static/ab6b779f27ff6765213b06367efeec87/12f09/pmf.png 148w,https://adamthewan.com/static/ab6b779f27ff6765213b06367efeec87/e4a3f/pmf.png 295w,https://adamthewan.com/static/ab6b779f27ff6765213b06367efeec87/fcda8/pmf.png 590w,https://adamthewan.com/static/ab6b779f27ff6765213b06367efeec87/efc66/pmf.png 885w,https://adamthewan.com/static/ab6b779f27ff6765213b06367efeec87/c83ae/pmf.png 1180w,https://adamthewan.com/static/ab6b779f27ff6765213b06367efeec87/c1b63/pmf.png 1200w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span>
    <figcaption>Why it's important to fail fast</figcaption>
  </figure><p>Several factors allowed us to build and ship MeetButter quickly.</p><p>Firstly, we were fortunate to have had the experience and the skills to execute quickly. We didn’t run into many technical limitations, as each one of us had filled the significant roles that were needed. These roles include design/UI UX, software development, and marketing/networking.</p><p>Secondly, we tried to follow the best practices for idea generation. The brainstorm that led to MeetButter wasn’t the first one that we had together. It was probably our fifth brainstorm session after getting together as a team as Project Phoenix. With a lot of practice, we were able to build a set of best practices to have productive brainstorm sessions, get feedback, and reiterate.</p><p>Thirdly, we were close to our target market, which allowed us to test fast and slowly expand our test userbase.</p><p>Fourth, we threw perfection out the window. Our prototype didn’t work 100% of the time, had a bunch of bugs, and built with the bare minimum UI. Despite this, we still used it every single day for our video calls. It was good …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://adamthewan.com/blog/meetbutter/how-we-built-meetbutter-three-weeks/">https://adamthewan.com/blog/meetbutter/how-we-built-meetbutter-three-weeks/</a></em></p>]]>
            </description>
            <link>https://adamthewan.com/blog/meetbutter/how-we-built-meetbutter-three-weeks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23642739</guid>
            <pubDate>Thu, 25 Jun 2020 16:55:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Are peaceful protests more successful than violent ones?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23642525">thread link</a>) | @BafS
<br/>
June 25, 2020 | https://blog.datawrapper.de/are-peaceful-protests-more-successful-than-violent-ones | <a href="https://web.archive.org/web/*/https://blog.datawrapper.de/are-peaceful-protests-more-successful-than-violent-ones">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
            
<p><em>Hi, I’m Edurne (Eddie), writer &amp; support intern here at Datawrapper and aspiring data journalist. Today’s Weekly Chart is about a question I’ve frequently asked myself in the last few years: can civil resistance foster social change and revolution?</em></p>
<p>Between 2017 and 2019, I had the opportunity to work as a foreign correspondent in Kenya, Japan, and Spain. It was not always easy, but I was lucky to learn many interesting things along the way. I was also constantly on the ‘wire’, reading stories from many countries and learning about their past, culture, and daily lives.</p>
<p>Even before that, while I was studying journalism, I  found myself reading and writing a lot about protests, like the <em>Umbrella Movement in Hong Kong</em> or the <em>Yellow Vests</em> (<em>Gilets Jaunes</em>) movement in France. The images from the Arab spring in 2010 stuck with me the most. And it’s not a coincidence that I read about protests so much: <a href="https://www.economist.com/graphic-detail/2020/03/10/political-protests-have-become-more-widespread-and-more-frequent" target="_blank" rel="noopener">the last few decades have seen an increase in campaigns</a>.</p>
<p>But not all protests are the same: There are violent and peaceful ones. I was wondering: Which of them are successful? To find out, I used data from The Non-violent and Violent Campaigns and Outcomes (<a href="https://dataverse.harvard.edu/dataverse/navco" target="_blank" rel="noopener">NAVCO</a>) project by Harvard University, the first of its kind to collect systematic data on violent insurgencies and non-violent civil resistance around the world:</p>





<p>NAVCO gathered data on 622 campaigns between 1900 and 2019. As we can see in the chart, in this time, half of the <strong>321 non-violent campaigns succeeded, while only a quarter of their 301 violent counterparts</strong> did. 56% of violent campaigns failed, compared to 30% of non-violent ones.</p>
<p>Erica Chenoweth, a researcher on violence and co-author of the NAVCO Data Project, found even more evidence that non-violent protests are more successful: “Countries in which there were nonviolent campaigns were about 10 times likelier to transition to democracies within a five-year period compared to countries in which there were violent campaigns – whether the campaigns succeeded or failed”, she explained to <a href="https://news.harvard.edu/gazette/story/2019/02/why-nonviolent-resistance-beats-violent-force-in-effecting-social-political-change/" target="_blank" rel="noopener">The Harvard Gazette</a>.</p>
<p>You can search through all the 622 campaigns that the NAVCO data set contains here:</p>





<h2 id="Data-concerns">Data concerns</h2>
<p>Because it’s a data set collected by hand instead of measured, it’s important to understand the decisions behind it better.</p>
<p>Launched by Harvard University, the NAVCO Data Project covers different aspects of civil resistance and insurgencies through time. For this article, I decided to analyze the 4th iteration of the project: the <strong><a href="https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/ON9XND" target="_blank" rel="noopener">NAVCO 1.3 data set</a></strong>, released on March 17 of this year.</p>
<p>While making statements like “non-violent campaigns are more successful”, we need to bear in mind that this data set might not include all campaigns, suffering a so-called <strong>underreporting bias</strong>. The authors of the NAVCO data set also note in their codebook that the included <strong>non-violent campaigns</strong> are <strong>biased toward success:</strong> the large, mature campaigns are most commonly reported. Some non-violent campaigns are crushed in their infancy (and therefore fail) and are not included in this data set.</p>
<p>This bias has, however, been mitigated by looking only at major campaigns with at least 1,000 people participating in the protest. The dataset also only includes protests with a maximalist objective, such as bringing down a government. Despite not being perfect, the NAVCO Data Project is still a reference <a href="https://www.eurekalert.org/pub_releases/2020-01/hu-imo012420.php" target="_blank" rel="noopener">for many researchers and journalists</a> to analyze the effects of both violent and non-violent protests in global politics.</p>
<h2 id="The-process">The process</h2>
<p>One thing I like about data visualization (although it can be daunting) is the amount of trial and error that it requires to come up with the right chart type. The table I finally created was not close to my first idea (at the beginning I wanted to create a scatterplot or even a map!), which shows that visualization can be really rich in variety as well!</p>
<p>Before looking at the data set, I started with a blank piece of paper and wrote down my initial questions. I believe this step comes from my journalistic background: <strong>I treat data sets as interviewees</strong>. The main question – are non-violent protests more or less successful than violent ones? – was easily answered with a pivot table in Google Sheets.</p>
<p>The main work needed to be done on the Datawrapper table. To help readers navigate this big amount of data, I opted for the use of <strong>emojis</strong> in the <strong>“Success”</strong> column. Now you just need a glance to know how the campaign ended. I also decided to bring ongoing campaigns to the front of the table, since those are the insurgencies and protests that are happening at the moment and people have likely been reading about them in the last few years. Finally, I decided to <strong>highlight the non-violent campaigns that ended up in success</strong>.</p>
<h2 id="References">References</h2>
<p>If you’d like to learn more about protests or recreate any of the charts above, have a look at the following sources:</p>
<ul>
<li>Visit this <a href="https://blog.datawrapper.de/protest-topics-in-germany-are-changing/">Weekly Chart</a> by my coworker Fabian to zoom into the rebellious history of Germans</li>
<li>You can also check out  <a href="https://foreignpolicy.com/2013/10/25/the-dissidents-toolkit/" target="_blank" rel="noopener">this article</a> by Erica Chenoweth on how demonstrations are not enough to undermine authoritarian governments</li>
<li>Some Datawrapper Academy articles on <a href="https://academy.datawrapper.de/article/247-examples-of-datawrapper-tables" target="_blank" rel="noopener">examples of tables</a>, how to format your text in <a href="https://academy.datawrapper.de/article/191-how-to-format-your-text-with-markdown" target="_blank" rel="noopener">Markdown</a> and how to insert <a href="https://academy.datawrapper.de/article/144-how-to-insert-flag-icons-in-tables" target="_blank" rel="noopener">flag icons in tables</a> also helped a lot with this article.</li>
</ul>
<hr>
<p><em>And that’s all for this week! I hope you enjoyed my first article here at Datawrapper. I would love to hear your thoughts on how to spark a revolution! Do you support any political movement? Is there any civil resistance group that you are particularly interested in? Leave a comment below or send me an email at <a href="mailto:edurne@datawrapper.de">edurne@datawrapper.de</a>. See you next Thursday!</em></p>

          </div></div>]]>
            </description>
            <link>https://blog.datawrapper.de/are-peaceful-protests-more-successful-than-violent-ones</link>
            <guid isPermaLink="false">hacker-news-small-sites-23642525</guid>
            <pubDate>Thu, 25 Jun 2020 16:35:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Building a Free Game Assets Directory]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23642352">thread link</a>) | @mpbeauj
<br/>
June 25, 2020 | https://moonlightgamedevs.com/free-assets | <a href="https://web.archive.org/web/*/https://moonlightgamedevs.com/free-assets">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>A curated List of the best free Game Assets!</p><p><span><svg width="24" height="24" viewBox="-3 -3 30 30" xmlns="http://www.w3.org/2000/svg" fill-rule="evenodd" clip-rule="evenodd"><path d="M10.605 0h-10.605v10.609l13.391 13.391 10.609-10.604-13.395-13.396zm-4.191 6.414c-.781.781-2.046.781-2.829.001-.781-.783-.781-2.048 0-2.829.782-.782 2.048-.781 2.829-.001.782.782.781 2.047 0 2.829z"></path></svg></span>Categories</p><div><p><a href="https://moonlightgamedevs.com/free-assets/category/audio">Audio</a><a href="https://moonlightgamedevs.com/free-assets/category/tools">Tools</a><a href="https://moonlightgamedevs.com/free-assets/category/-d%20-art(-models%20/%20-animations)">3D Art</a><a href="https://moonlightgamedevs.com/free-assets/category/tool">Tool</a><a href="https://moonlightgamedevs.com/free-assets/category/code">Code</a><a href="https://moonlightgamedevs.com/free-assets/category/-d%20-art(-sprites%20/%20-textures)">2D Art</a><a href="https://moonlightgamedevs.com/free-assets/category/u-i%20/%20-u-x">UI / UX</a><a href="https://moonlightgamedevs.com/free-assets/category/shader">Shader</a></p></div><p>Updated weekly - subscribe so you don't miss new Listings.</p><section id="newsletter"><div><h3>Newsletter</h3><p>Subscribe for updates on Blog Posts, Podcast Episodes, News, and more. Sent out every Week.</p><form method="post" name="newsletter-subscription"><p><label><p id="email-newsletter-subscription-error">Please enter a valid email</p></label></p><p><label><span>&nbsp;I have read and agree to the<!-- --> <a href="https://moonlightgamedevs.com/privacy-policy">data policy</a>.</span><p id="dataPolicy-newsletter-subscription-error">Please agree to the data policy</p></label></p><label></label></form></div></section></div></div>]]>
            </description>
            <link>https://moonlightgamedevs.com/free-assets</link>
            <guid isPermaLink="false">hacker-news-small-sites-23642352</guid>
            <pubDate>Thu, 25 Jun 2020 16:17:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Critique of 2018 Turing Award for Drs. Bengio and Hinton and LeCun]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23642335">thread link</a>) | @jdp23
<br/>
June 25, 2020 | http://people.idsia.ch/~juergen/critique-turing-award-bengio-hinton-lecun.html | <a href="https://web.archive.org/web/*/http://people.idsia.ch/~juergen/critique-turing-award-bengio-hinton-lecun.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div face="arial">
<center>
.
<div>
<a href="http://people.idsia.ch/~juergen/critique-turing-award-bengio-hinton-lecun.html"><img src="http://people.idsia.ch/~juergen/critique-turing754x288.png" alt="Critique of 2018 Turing Award for Bengio &amp; Hinton &amp; LeCun"></a>

<center>



<span size="4">
</span></center><span size="4">

<a name="abstract">
<hr>
</a><p><a name="abstract">
<b>Abstract.</b> ACM's 2018 A.M. Turing Award was about
<em>deep learning</em> in artificial neural networks.
ACM lauds the awardees for work based on algorithms
and conceptual foundations first published by other researchers 
whom the awardees failed to cite
(see </a><a href="#exec">Executive Summary</a>
and Sec. 
<a href="#I">I</a>,
<a href="#V">V</a>, 
<a href="#II">II</a>,
<a href="#XII">XII</a>,
<a href="#XIX">XIX</a>, 
<a href="#XXI">XXI</a>,
<a href="#XIII">XIII</a>, 
<a href="#XIV">XIV</a>,  
<a href="#XX">XX</a>, 
<a href="#XVII">XVII</a>).
ACM explicitly mentions "astonishing" deep learning breakthroughs in 4 fields:
<a href="#A"> (A) speech recognition</a>, 
<a href="#B">(B) natural language processing</a>, 
<a href="#C">(C) robotics</a>, 
<a href="#D">(D) computer vision</a>,
as well as "powerful" new deep learning tools in 3 fields: 
<a href="#VII">(VII) medicine, astronomy, materials science</a>.
Most of these breakthroughs and tools, however, were directly based on 
the results of my own labs in the past 3 decades 
 (e.g., Sec.  
<a href="#A">A</a>,
<a href="#B">B</a>,
<a href="#C">C</a>,
<a href="#D">D</a>,
<a href="#VII">VII</a>,
<a href="#XVII">XVII</a>,
<a href="#VI">VI</a>,
<a href="#XVI">XVI</a>). 
I correct ACM's distortions of deep learning history (e.g., Sec. 
<a href="#II">II</a>,  
<a href="#V">V</a>, 
<a href="#XX">XX</a>,
<a href="#XVIII">XVIII</a>) 
and also 
mention 8 of our direct priority disputes 
with Bengio &amp; Hinton (Sec.  <a href="#XVII">XVII</a>, <a href="#I">I</a>).


</p><hr>

<p>
<em>This document (~11,000 words)
reuses and expands some of the material in my <a href="http://people.idsia.ch/~juergen/critique-honda-prize-hinton.html">Critique of the 2019 Honda Prize</a> <a href="#HIN">[HIN]</a> (~3,000 words). 
It has several layers of hierarchical abstraction: 
<b><a href="#abstract">Abstract</a></b> (150 words), <b><a href="#exec">Executive Summary with links to details</a></b> (~1,000 words), <b><a href="#I">Body with 21 comments on 21 claims by ACM</a></b> (~7,700 words) and <b><a href="#conclusion">Conclusion</a></b> (~1,700 words). 
All backed up by  <a href="#References">over 200 references</a> (~6,500 words).
</em>

</p><hr>


<p>We must stop crediting the wrong people for inventions made by others.
Instead let's heed the recent call in the journal <em>Nature</em>:
<b>"Let 2020 be the year in which we value those who ensure that 
science is self-correcting"</b> <a href="#SV20">[SV20]</a>.
Like those who know me can testify, finding and citing original sources of scientific and technological innovations is important to me, whether they are mine or other people's <a href="#DL1">[DL1]</a> <a href="#DL2">[DL2]</a> <a href="#HIN">[HIN]</a> <a href="#NASC1">[NASC1-9]</a>. The present page is offered as a resource for computer scientists who share this inclination. 
By grounding research in its true intellectual foundations and crediting the original inventors, 
I am not diminishing important contributions made by popularizers of those inventions. 
My goal is to encourage the entire community to be more scholarly in its efforts, to recognize the foundational work that sometimes gets lost in the frenzy of modern AI and machine learning,
and to fight plagiarism in all of its more or less subtle forms. 
I am also inviting others to contribute additional relevant 
references (send them to <em>juergen@idsia.ch</em>). 



</p><p> I will focus on 
contributions praised by
ACM's official justification <a href="#T19">[T19]</a> of the 
2018 A.M. Turing Award for Drs. Bengio &amp; Hinton &amp; LeCun  <a href="#R1">[R1]</a> 
 published in 2019.
After the <a href="#exec">Executive Summary</a>,
ACM's full text <a href="#T19">[T19]</a> is split into 21 parts  
labeled by "<b>ACM:</b>" 
<a href="#I">I</a>, 
<a href="#II">II</a>, 
<a href="#III">III</a>, 
<a href="#IV">IV</a>,
<a href="#V">V</a>,
<a href="#VI">VI</a>,
<a href="#VII">VII</a>,
<a href="#VIII">VIII</a>,
<a href="#IX">IX</a>,
<a href="#X">X</a>,
<a href="#XI">XI</a>,
<a href="#XII">XII</a>,
<a href="#XIII">XIII</a>,
<a href="#XIV">XIV</a>,
<a href="#XV">XV</a>,
<a href="#XVI">XVI</a>,
<a href="#XVII">XVII</a>,
<a href="#XVIII">XVIII</a>,
<a href="#XIX">XIX</a>,
<a href="#XX">XX</a>,
<a href="#XXI">XXI</a>.
Each part is followed by a critical "<b>Comment</b>." 
Most of the comments are based on references to original papers and other material from
 recent 
blog posts <a href="#MIR">[MIR]</a> <a href="#DEC">[DEC]</a>  <a href="#HIN">[HIN]</a>.
<b>I'll point out 
that  highly cited publications of the awardees ignored fundamental 
relevant prior work—this may be the reason for some of  ACM's misattributions.</b>
Since ACM's text is a bit repetitive and redundant, so are the partially overlapping
sections of  my critique. 



</p><h2><a name="exec">
<hr>
Executive Summary (~1000 words, with links to details)
<hr>
</a></h2><a name="exec">

</a><p><a name="exec">
While Drs. LeCun &amp; Bengio &amp; Hinton (<b>LBH for short</b>)  
have made  useful improvements of algorithms for 
artificial neural networks (<b>NNs</b>) 
and deep learning (e.g., </a><a href="#I">Sec.  I</a>), ACM lauds
them for more visible 
work based on fundamental methods whose inventors they did not cite,
not even in later surveys
(this may actually explain some of  ACM's misattributions). I correct ACM's distortions of deep learning history.
Numerous <a href="#References">references</a> can be found under the relevant section links I-XXI 
which adhere to the sequential order of ACM's text <a href="#T19">[T19]</a>
(while this summary groups related sections together).


</p><p>
<b>Sec. <a href="#II">II</a>:</b> 
In contrast to ACM's claims, 
NNs for pattern recognition etc. were introduced long before the 1980s. 
 <b>Deep learning with multilayer perceptrons started in 1965</b> through Ivakhnenko &amp; Lapa
long before LBH who have never cited them, not even in recent work.
<b>In the 1980s,</b> "modern" gradient-based learning 
worked only for rather shallow NNs,
<b>but it became really deep in 1991 in my lab,</b>
first through 
<a href="http://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html#Sec.%201">unsupervised pre-training of NNs</a>, 
then through 
<a href="http://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html#Sec.%204">supervised LSTM</a>.
<b>Sec.  <a href="#I">I</a></b> contains 4 subsections 
<b><a href="#A">A</a>, <a href="#B">B</a>, <a href="#C">C</a>, <a href="#D">D</a></b>
on <b>the  4 deep learning "breakthroughs" explicitly 
mentioned by ACM</b>. ACM does not mention that they were 
mostly based on deep learning techniques of my team:

</p><p>
<b>Sec.
<a href="#A">A: Speech Recognition</a></b> (see also <a href="#VI">VI</a> &amp; <a href="#XI">XI</a> &amp; <a href="#XV">XV</a>): The first superior end-to-end neural speech recognition 
combines two methods from my lab: <a href="http://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html#Sec.%204">LSTM</a> (1990s-2005) and CTC (2006), applied to speech in 2007. 
Hinton (2012) and Bengio (<a href="#XV">XV</a>)
still used an old hybrid approach of the 1980s and 90s;
Hinton et al. (2012) did not compare it to 
our revolutionary CTC-LSTM (<a href="http://people.idsia.ch/~juergen/impact-on-most-valuable-companies.html">which was soon on most smartphones</a>).

</p><p>
<b>Sec. <a href="#B">B: Natural Language Processing</a></b> (see also  <a href="#VI">VI</a> &amp; <a href="#XI">XI</a> &amp;  <a href="#XVI">XVI</a>): 
The first superior end-to-end neural machine translation  
(<a href="http://people.idsia.ch/~juergen/impact-on-most-valuable-companies.html">soon used for several billions of
translations each day by the big platform companies</a>)
was also based on our <a href="http://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html#Sec.%204">LSTM</a>.

</p><p>
<b>Sec. <a href="#C">C: Robotics</a></b>.
Our LSTM trained by <b>Reinforcement Learning</b> (RL) was also the core of the 
most visible breakthroughs in robotics and video games.

</p><p>
<b>Sec. <a href="#D">D: Computer Vision</a></b>
(see also   
<a href="#XVIII">XVIII</a> &amp; <a href="#XIV">XIV</a>  &amp; <a href="#XI">XI</a>  &amp;  <a href="#VI">VI</a>)
was revolutionized by <b>convolutional NNs</b> (CNNs).
The basic CNN architecture is due to Fukushima (1979). 
NNs with convolutions were later (1987) combined by Waibel with backpropagation and weight sharing, 
and applied to speech. <b>All before</b> LeCun's CNN work  (<a href="#XVIII">XVIII</a>).
We showed twice (1991-95 and 2006-10) that 
<a href="http://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html#Sec.%2019">deep NNs 
don't need unsupervised 
pre-training</a> (in contrast to Hinton's claims). Our team (Ciresan et al.)  
made CNNs fast &amp; deep enough for  
<a href="http://people.idsia.ch/~juergen/computer-vision-contests-won-by-gpu-cnns.html">superior computer vision  in 2011</a>,
<b>winning 4 image recognition contests in a row
before Hinton's team won one</b>. ResNet (ImageNet 2015 winner)
is a special case of our earlier <a href="http://people.idsia.ch/~juergen/highway-networks.html">Highway Nets</a>.

</p><p>
<b>Sec.  <a href="#XIV">XIV:</a></b>
Again ACM recognizes work that failed to cite the pioneers.
Long before Hinton (2012), Hanson (1990) had a variant of <b>dropout</b>, 
and v. d. Malsburg (1973) had <b>rectified linear neurons</b>; Hinton did not cite them.
Already in 2011,
our deep &amp; fast CNN  more than <b>"halved the error rate for object recognition"</b> (ACM's wording) 
in a computer vision contest 
(<a href="http://people.idsia.ch/~juergen/superhumanpatternrecognition.html">where LeCun participated</a>), 
long before Hinton's similar CNN (2012). 
<b>Sec. <a href="#XI">XI</a>:</b>  ACM mentions GPU-accelerated NNs  
pioneered by Jung &amp; Oh (2004). LBH
did not cite them.
Our deep GPU-NN of 2010 debunked <a href="http://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html#Sec.%2019">unsupervised pre-training (introduced by myself in 1991 and later championed by Hinton)</a>, 
and our GPU-CNN of 2011 was the first  
to win contests in <b>computer 
vision</b> (explicitly mentioned by ACM).
 

</p><p>
<b>Sec.  
<a href="#XVIII">XVIII</a></b>:
ACM credits LeCun for developing CNNs. However, the foundations of CNNs were laid earlier by 
Fukushima and Waibel  (Sec. <a href="#D">D</a>).
 ACM also explicitly mentions <b>autonomous driving</b> and <b>medical image analysis</b>.
The first team to win relevant international contests in these fields 
through deep CNNs was ours (2011, 2012, 2013).
<b>Sec.  
<a href="#VII">VII</a>:</b> ACM explicitly mentions  <b>medicine</b> and
 <b>materials science</b>. Our deep NNs were the 
<a href="http://people.idsia.ch/~juergen/first-time-deep-learning-won-medical-imaging-contest-september-2012.html">first to win medical imaging competitions</a>
 in 2012 and 2013, and the first to apply deep NNs to material defect detection in industry (since 2010).


</p><p>
<b>Sec. <a href="#XII">XII</a> &amp; <a href="#XIX">XIX</a> &amp; <a href="#XXI">XXI</a>:</b> Modern 
<a href="http://people.idsia.ch/~juergen/who-invented-backpropagation.html">backpropagation</a>
was first published by Linnainmaa (1970), 
not by LeCun or Hinton or their collaborators (1985) who did not cite Linnainmaa, 
not even in later surveys. 
<b>Sec. 
<a href="#XIII">XIII</a>  &amp; 
<a href="#II">II</a> &amp; 
<a href="#V">V</a> 
</b>
(&amp; 
<a href="#III">III</a> &amp; 
<a href="#IX">IX</a> &amp;
<a href="#X">X</a> &amp;
<a href="#XX">XX</a>):
Ivakhnenko's deep feedforward nets (since 1965) <b>learned 
internal representations</b> long before Hinton's shallower ones (1980s).
Hinton has never cited him.
<b>Sec. <a href="#XX">XX</a>:</b> ACM credits LeCun for work on
<b>hierarchical feature representation</b> which did not cite Ivakhnenko's much earlier work
on this (since 1965).
<b>Sec. <a href="#XXI">XXI</a>:</b> ACM credits LeCun for work on
<b>automatic differentiation</b> which did not cite its inventor Linnainmaa (1970). 
And also for work on
<b>deep learning for graphs</b> that failed to cite 
the earlier work  by Sperduti &amp; Goller &amp; Küchler &amp; Pollack.



</p><p>
<b>Sec. 
<a href="#XV">XV</a>:</b> ACM credits Bengio for hybrids of NNs and  probabilistic models of sequences. 
His work
was not the first on this topic, and is 
not important for <b>modern deep learning speech recognition systems</b> (mentioned by ACM) based on our CTC-LSTM
 (Sec.  
<a href="#A">A</a> &amp; 
<a href="#B">B</a>).
<b>Sec.
<a href="#XVI">XVI</a>:</b> ACM 
credits Bengio for neural probabilistic language models.
Our 1995 neural probabilistic text model greatly predates Bengio's.
ACM mentions NNs that learn
 sequential <b>attention</b>. <a href="http://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html#Sec.%209">We started this in 1990-93 long before LBH</a> who did not cite this.




</p><p>
<b>Sec.  <a href="#XVII">XVII</a>:</b>
ACM mentions
<b>Generative Adversarial Networks</b> (GANs, 2010-14) of Bengio's team, a special case of
my  Adversarial  
<a href="http://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html#Sec.%205"><b>Artificial Curiosity</b></a>
(1990) which he did not cite. 
I list 7 of 
our <b>additional priority disputes</b> with Bengio &amp; Hinton (more than can be explained by chance),  
on 
<a href="http://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html#Sec.%203">vanishing gradients</a> (1991),
<a href="http://people.idsia.ch/~juergen/metalearner.html">meta-learning</a> (1987),
 <a href="http://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html#Sec.%201">unsupervised pre-training</a> (1991),
<a href="http://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html#Sec.%202">compressing or distilling one NN into another</a> (1991), 
<a href="http://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html#Sec.%208">fast weights  
through outer products</a> (1993), 
<a href="http://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html#Sec.%209">learning sequential attention with NNs</a> (1990),
and other topics <a href="#R2">[R2-R6]</a>.








</p><p>
<b>Sec. <a href="#IV">IV</a></b> is on <a href="http://people.idsia.ch/~juergen/turing.html">Turing</a> (1936) and his predecessors
<a href="http://people.idsia.ch/~juergen/goedel.html">Gödel</a> (1931) and Church (1935).

</p><p>
<b>Sec. <a href="#conclusion">Conclusion:</a></b>
 In the recent <a href="http://people.idsia.ch/~juergen/2010s-our-decade-of-deep-learning.html">decade of deep learning</a>,
most major AI applications mentioned by ACM 
<a href="http://people.idsia.ch/~juergen/impact-on-most-valuable-companies.html">(speech recognition, language translation, etc.) on billions of devices</a>  (also healthcare applications)
heavily depended on our deep learning techniques and conceptual foundations,
while LBH's most visible work ignored
 essential prior art since the 1960s—see, e.g., 
Sec. <a href="#II">II</a> &amp;  
<a href="#III">III</a> &amp; 
<a href="#V">V</a> &amp;
<a href="#XII">XII</a> &amp; 
<a href="#XIII">XIII</a> &amp; 
<a href="#XVII">XVII</a> &amp; 
<a href="#XIV">XIV</a> &amp; 
<a href="#XIX">XIX</a> &amp; 
<a href="#XX">XX</a> &amp; 
<a href="#XXI">XXI</a>, 
<a href="#DL1">[DL1]</a> <a href="#DL2">[DL2]</a> <a href="#DLC">[DLC]</a> <a href="#MIR">[MIR]</a> <a href="#HIN">[HIN]</a> <a href="#R4">[R2-R8]</a>.
But in science, by definition, the facts will always win in …</p></span></div></center></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://people.idsia.ch/~juergen/critique-turing-award-bengio-hinton-lecun.html">http://people.idsia.ch/~juergen/critique-turing-award-bengio-hinton-lecun.html</a></em></p>]]>
            </description>
            <link>http://people.idsia.ch/~juergen/critique-turing-award-bengio-hinton-lecun.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23642335</guid>
            <pubDate>Thu, 25 Jun 2020 16:15:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Detecting Street Lanes for Self-Driving Cars in Python]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23642306">thread link</a>) | @fifomihal
<br/>
June 25, 2020 | https://beta.deepnote.com/article/street-lanes-finder | <a href="https://web.archive.org/web/*/https://beta.deepnote.com/article/street-lanes-finder">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-cy="code-cell"><div><p><span>def</span> <span>averaged_lines</span><span>(</span>image<span>,</span> lines<span>)</span><span>:</span>
    right_lines <span>=</span> <span>[</span><span>]</span>
    left_lines <span>=</span> <span>[</span><span>]</span>
    <span>for</span> x1<span>,</span>y1<span>,</span>x2<span>,</span>y2 <span>in</span> lines<span>[</span><span>:</span><span>,</span> <span>0</span><span>]</span><span>:</span>
        parameters <span>=</span> np<span>.</span>polyfit<span>(</span><span>(</span>x1<span>,</span> x2<span>)</span><span>,</span> <span>(</span>y1<span>,</span> y2<span>)</span><span>,</span> <span>1</span><span>)</span>
        slope <span>=</span> parameters<span>[</span><span>0</span><span>]</span>
        intercept <span>=</span> parameters<span>[</span><span>1</span><span>]</span>
        <span>if</span> slope <span>&gt;=</span> <span>0</span><span>:</span> 
            right_lines<span>.</span>append<span>(</span><span>[</span>slope<span>,</span> intercept<span>]</span><span>)</span>
        <span>else</span><span>:</span>
            left_lines<span>.</span>append<span>(</span><span>[</span>slope<span>,</span> intercept<span>]</span><span>)</span>
            
    <span>def</span> <span>merge_lines</span><span>(</span>image<span>,</span> lines<span>)</span><span>:</span>
        <span>if</span> <span>len</span><span>(</span>lines<span>)</span> <span>&gt;</span> <span>0</span><span>:</span>
            slope<span>,</span> intercept <span>=</span> np<span>.</span>average<span>(</span>lines<span>,</span> axis<span>=</span><span>0</span><span>)</span>
            y1 <span>=</span> image<span>.</span>shape<span>[</span><span>0</span><span>]</span>
            y2 <span>=</span> <span>int</span><span>(</span>y1<span>*</span><span>(</span><span>1</span><span>/</span><span>2</span><span>)</span><span>)</span>
            x1 <span>=</span> <span>int</span><span>(</span><span>(</span>y1 <span>-</span> intercept<span>)</span><span>/</span>slope<span>)</span>
            x2 <span>=</span> <span>int</span><span>(</span><span>(</span>y2 <span>-</span> intercept<span>)</span><span>/</span>slope<span>)</span>
            <span>return</span> np<span>.</span>array<span>(</span><span>[</span>x1<span>,</span> y1<span>,</span> x2<span>,</span> y2<span>]</span><span>)</span>
        
    left <span>=</span> merge_lines<span>(</span>image<span>,</span> left_lines<span>)</span>
    right <span>=</span> merge_lines<span>(</span>image<span>,</span> right_lines<span>)</span>
    <span>return</span> left<span>,</span> right

<span>def</span> <span>hough_lines</span><span>(</span>image<span>,</span> rho<span>,</span> theta<span>,</span> threshold<span>,</span> min_line_len<span>,</span> max_line_gap<span>)</span><span>:</span>
    lines_image <span>=</span> np<span>.</span>zeros<span>(</span><span>(</span>image<span>.</span>shape<span>[</span><span>0</span><span>]</span><span>,</span> image<span>.</span>shape<span>[</span><span>1</span><span>]</span><span>,</span> <span>3</span><span>)</span><span>,</span> dtype<span>=</span>np<span>.</span>uint8<span>)</span>
    lines <span>=</span> cv2<span>.</span>HoughLinesP<span>(</span>image<span>,</span> rho<span>,</span> theta<span>,</span> threshold<span>,</span> np<span>.</span>array<span>(</span><span>[</span><span>]</span><span>)</span><span>,</span> minLineLength<span>=</span>min_line_len<span>,</span> maxLineGap<span>=</span>max_line_gap<span>)</span>
    <span>if</span> lines <span>is</span> <span>not</span> <span>None</span><span>:</span>
        lines <span>=</span> averaged_lines<span>(</span>image<span>,</span> lines<span>)</span>
        <span>for</span> line <span>in</span> lines<span>:</span>
            <span>if</span> line <span>is</span> <span>not</span> <span>None</span><span>:</span>
                x1<span>,</span>y1<span>,</span>x2<span>,</span>y2 <span>=</span> line
                cv2<span>.</span>line<span>(</span>lines_image<span>,</span> <span>(</span>x1<span>,</span> y1<span>)</span><span>,</span> <span>(</span>x2<span>,</span> y2<span>)</span><span>,</span> <span>(</span><span>0</span><span>,</span> <span>0</span><span>,</span> <span>255</span><span>)</span><span>,</span> <span>20</span><span>)</span>
        plot_image<span>(</span>lines_image<span>,</span> <span>"lines"</span><span>)</span>
    <span>return</span> lines_image</p></div></div></div>]]>
            </description>
            <link>https://beta.deepnote.com/article/street-lanes-finder</link>
            <guid isPermaLink="false">hacker-news-small-sites-23642306</guid>
            <pubDate>Thu, 25 Jun 2020 16:13:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Use Managed Services. Please]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23642260">thread link</a>) | @dijit
<br/>
June 25, 2020 | http://www.mooreds.com/wordpress/archives/3358 | <a href="https://web.archive.org/web/*/http://www.mooreds.com/wordpress/archives/3358">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">

	    
	<!-- #masthead .site-header -->
    
	    
	<div id="main">
        	    
        <div>

		<div id="primary">
			

			
					
	
	
				
								
					<article id="post-3358">
    
    <div>
     <div>      
 		<p>“Use managed services.”</p>
<p>If there was one piece of advice I wish I could shout from the mountains to all cloud engineers, this would be it.</p>
<p>Operations, especially operations at scale, are a hard problem. Edge cases become commonplace. Failure is rampant. Automation and standardization are crucial. People with experience running software and hardware at this scale tend to be rare and expensive. The mistakes they’ve made and situations they’ve learned from aren’t easy to pick up.</p>
<p>When you use a managed service from one of the major cloud vendors, you’re getting access to all the wisdom of their teams and the power of their automation and systems, for the low price of their software.</p>
<p>A managed service is a service like AWS relational database service, Google Cloud SQL or Azure SQL Database. With all three of these services, you’re getting best of breed configuration and management for a relational database system. There’s configuration needed on your part, but hard or tedious tasks like setting up replication or backups can be done quickly and easily (take this from someone who fed and cared for a mysql replication system for years). Depending on your cloud vendor and needs, you can get managed services for key components of modern software systems like:</p>
<ul>
<li>File storage</li>
<li>Object caches</li>
<li>Message queues</li>
<li>Stream processing software</li>
<li>ETL tools</li>
<li>And more</li>
</ul>
<p>(Note that these are all components of your application, and will still require developer time to thread together.)</p>
<p>You should use managed services for three reasons.</p>
<ul>
<li>It’s going to be operated well. The expertise that the cloud providers can provide and the automation they can afford to implement will likely surpass what you can do, especially across multiple services.</li>
<li>It’s going to be cheaper. Especially when you consider employee costs. The most expensive AWS RDS instance is approximately $100k/year (full price). It’s not an apples to apples comparison, but in many countries you can’t get a database architect for that salary.</li>
<li>It’s going to be faster for development. Developers can focus on connecting these pieces of infrastructure rather than learning how to set them up and run them.</li>
</ul>
<p>A managed service doesn’t work for everyone. If you need to be able to tweak every setting, a managed service won’t let you. You may have stringent performance or security requirements that a managed service can’t meet. You may also start out with a managed service and grow out of it. (Congrats!)</p>
<p>Another important consideration is lock-in. Some managed services are compatible with alternatives (kubernetes services are a good example). If that is the case, you can move clouds. Others are proprietary and will require substantial reworking of your application if you need to migrate.</p>
<p>If you are working in the cloud and you need a building block for your application like a relational database or a message queue, start with a managed service (and self host if it doesn’t meet your needs). Leverage the operational excellence of the cloud vendors, and you’ll be able to build more, faster.</p>
		              </div>
    </div>
    
</article><!-- #post-3358 -->

				
									
	
	

			
			
		</div><!-- #primary .content-area -->

<!-- #secondary .widget-area -->
		</div><!--  .row -->
            
	</div><!-- #main .site-main -->

	<!-- #colophon .site-footer -->
</div></div>]]>
            </description>
            <link>http://www.mooreds.com/wordpress/archives/3358</link>
            <guid isPermaLink="false">hacker-news-small-sites-23642260</guid>
            <pubDate>Thu, 25 Jun 2020 16:08:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ARM Mac: Why I'm Worried About Virtualization]]>
            </title>
            <description>
<![CDATA[
Score 147 | Comments 283 (<a href="https://news.ycombinator.com/item?id=23642178">thread link</a>) | @bmalehorn
<br/>
June 25, 2020 | https://bmalehorn.com/arm-mac/ | <a href="https://web.archive.org/web/*/https://bmalehorn.com/arm-mac/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>It's late 2020 and you just got a brand-new Mac with Apple's own ARM processors. Exciting! But what will development be like?</p><h2>Docker</h2><p><img src="data:image/png;base64,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" width="150"></p><p>I would <strong>expect about a 5x slowdown running Docker images.</strong></p><p>Docker on a Mac utilizes a <strong>hypervisor</strong>. Hypervisors rely on running the <strong>same architecture on the host as the guest</strong>, and are about about 1x - 2x as slow as running natively.</p><p>Since you're running ARM Mac, these hypervisors can only run ARM Linux. They can't run x86_64 Linux.</p><p>What will happen instead? These tools will fall back on <strong>emulators</strong>. Emulators can run <strong>a different architecture between the host and the guest</strong>, but simulate the guest operating system at about 5x-10x slowdown.</p><div><p><img src="https://bmalehorn.com/static/perf-267ab9cfc29b6f68078fbe19892bce23.png"></p><p>A basic performance test comparing gzip performance on amd64 (hypervisor) and arm64v8 (emulator). Note that the emulator is over 6x slower. On an ARM Mac, the amd64 image will instead be 6x slower.</p></div><p>Why can't you update the Docker image to also support ARM? You theoretically could switch your backend to run ARM Linux. However, this would take months - renting out ARM instances, re-building all repositories, and a tense switch over. What if your hosting provider doesn't offer ARM instances with the same system requirements as x86_64? What if you complete this migration and find it runs at half the speed?</p><p>Worse, it might be impossible if your images include files downloaded off the internet, as those are often only compiled for x86_64.</p><div><p><img src="https://bmalehorn.com/static/phantomjs-615e9c8bc9d2deb5ca62a4533c1299d6.png"></p><p>An example of a Docker command that will only work on x86_64. PhantomJS does not release an arm build.</p></div><p>While moving your backend to ARM is far from impossible, it's a serious migration that you shouldn't take lightly. Getting a new laptop isn't enough justification to switch your backend architecture.</p><p>Another option is to <strong>run Docker remotely</strong>. You set up an x86_64 Linux server, then allow Docker to connect to it remotely. From then on, all Docker commands instead run on the server. This is also supported in Docker, <a href="https://www.digitalocean.com/community/tutorials/how-to-use-a-remote-docker-server-to-speed-up-your-workflow">here</a> is a tutorial on setting it up. This is what heavy Docker users will want to do.</p><h2>VirtualBox</h2><p><img src="https://bmalehorn.com/static/virtualbox-c37e4cc82b13d3c1c080f7ced273ae45.png" width="150"></p><p><strong>VirtualBox won't work.</strong></p><p>VirtualBox is a <strong>hypervisor</strong>. Therefore, <strong>it won't be able to run x86 Windows or x86 Linux</strong>.</p><p>You could use VirtualBox to run ARM Windows. Windows already supports ARM, and has a similar binary translation system to Apple's, so it can run x86 binaries. However, VirtualBox only supports x86 hosts and guests and is <a href="https://forums.virtualbox.org/viewtopic.php?f=8&amp;t=98742">unlikely to be ported by ARM</a>.</p><p>VMWare Fusion similarly is a hypervisor that only support x86, but <a href="https://twitter.com/VMwareFusion/status/1275483803536908288?s=20">they're thinking about supporting ARM</a>.</p><p>Instead of VirtualBox you might use QEMU, an emulator. However, QEMU is pretty low level and not often used to emulate Windows.</p><h2>Boot Camp</h2><p><img src="https://bmalehorn.com/static/boot-camp-f05493e57b0fe815dbc1d989ada98dd0.png" width="150"></p><p><strong>Boot Camp won't work.</strong></p><p><a href="https://support.apple.com/boot-camp">Boot Camp</a> is an Apple-approved way to dual-boot Mac OS and Windows. <a href="https://www.theverge.com/2020/6/24/21302213/apple-silicon-mac-arm-windows-support-boot-camp?utm_campaign=theverge&amp;utm_content=chorus&amp;utm_medium=social&amp;utm_source=twitter">Boot Camp will definitely not be available on ARM Macs</a>. It might be added later with the ability to run ARM Windows, though Microsoft <a href="https://www.theverge.com/2020/6/24/21302213/apple-silicon-mac-arm-windows-support-boot-camp">would have to approve</a>.</p><h2>Should I get an ARM Mac?</h2><p>The point of this post isn't to say that ARM Mac is a bad idea, but to give a realistic idea of what developing on one would look like assuming nothing changes. It's possible Apple could release more virtualization tools before the ARM Mac launches.</p><p>Should you get an ARM Mac if you're a developer? If you work largely on frontend, mobile, or native apps, you'll probably be fine. But if you use virtualization often, I wouldn't recommend it. There will be a lot of problems early on, and not all of them will have solutions. My biggest concern is getting an ARM Mac and realizing I simply can't run an essential application on it.</p><p>However if you like troubleshooting these issues and are excited about ARM Mac, go for it! My plan is for those kinds of people to fix these issues.</p><p>Know something I don't? Have questions? Email me at <a href="mailto:bmalehorn@gmail.com">bmalehorn@gmail.com</a>.</p></div></div>]]>
            </description>
            <link>https://bmalehorn.com/arm-mac/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23642178</guid>
            <pubDate>Thu, 25 Jun 2020 16:01:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using OAuth and PKCE to Add Authentication to Your Gatsby Site]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23642003">thread link</a>) | @mooreds
<br/>
June 25, 2020 | https://fusionauth.io/blog/2020/06/25/using-oauth-and-pkce-to-add-authentication-to-your-gatsby-site | <a href="https://web.archive.org/web/*/https://fusionauth.io/blog/2020/06/25/using-oauth-and-pkce-to-add-authentication-to-your-gatsby-site">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
              <p>Gatsby is one of the most popular JavaScript static site generators available. While static sites offer excellent performance, they only store state locally in the user’s browser, so they can’t provide features like user authentication natively. If you want to add authentication to your Gatsby site, FusionAuth is an excellent solution.</p>

<!--more-->

<p>In this blog post, you’ll learn how to create a Gatsby site that uses FusionAuth to allow users to log in and access their profile securely. This application will use an <a href="https://fusionauth.io/learn/expert-advice/oauth/definitive-guide-to-oauth-2#52-code-flow--pkce">OAuth Authorization Code workflow and the PKCE extension</a> to log users in and a Node application to store your access token securely. PKCE stands for Proof Key for Code Exchange, and is often pronounced “pixie”.</p>

<p>At a high level, the authorization process looks like this:</p>

<figure>
        <img src="https://fusionauth.io/assets/img/diagrams/blogs/gatsby/oauth-gatsby.svg" alt="Diagram of the OAuth Authorization Code flow with PKCE extension using FusionAuth and Gatsby.">
        <figcaption>Diagram of the OAuth Authorization Code flow with PKCE extension using FusionAuth and Gatsby.</figcaption>
      </figure>

<p>In this tutorial, you’ll walk through the process step-by-step, but if you want to download the code, it is <a href="https://github.com/fusionauth/fusionauth-example-gatsby">available on Github</a>.</p>

<h2 id="what-well-cover">What we’ll cover</h2>
<ol>
  <li>Setting up FusionAuth</li>
  <li>Creating a new user</li>
  <li>Creating a Node proxy application</li>
  <li>Creating a Gatsby site</li>
  <li>Conclusion and next steps</li>
</ol>

<h2 id="what-youll-need">What you’ll need</h2>
<ul>
  <li><a href="https://fusionauth.io/download">FusionAuth</a></li>
  <li><a href="https://nodejs.org/en/">Node JS</a> (10+ preferred)</li>
  <li><a href="https://www.npmjs.com/">npm</a> package manager</li>
  <li>Web browser</li>
</ul>

<h2 id="setting-up-fusionauth">Setting up FusionAuth</h2>
<p>Before you start writing any code, download FusionAuth and get it running on your local machine. FusionAuth is available <a href="https://fusionauth.io/download">for all major operating systems</a> or it can be <a href="https://fusionauth.io/docs/v1/tech/installation-guide/docker">run in Docker</a>.</p>

<p>Once you have FusionAuth running, log into the admin panel and create a new Application. This process <a href="https://fusionauth.io/docs/v1/tech/5-minute-setup-guide">is outlined here</a>, but you’ll need to add your application’s URLs to the OAuth configuration:</p>

<ul>
  <li>Add <code>http://localhost:9000/oauth-callback</code> to the “Authorized redirect URLs”.</li>
  <li>Add <code>http://localhost:9000</code> to the “Authorized request origin URLs”.</li>
  <li>Enter <code>http://localhost:8000</code> in the “Logout URL” field.</li>
</ul>

<p>You’ll also want to save the “Client Id” and “Client secret” values as you’ll need them later.</p>

<p><img src="https://fusionauth.io/assets/img/blogs/oauth-gatsby/application-setup.png" alt="FusionAuth configuration options for a Gatsby static site."></p>

<p>You’ll also need to create an API key. Go to “Settings”, then to “API Keys”. You may create one with adminstrative privileges for the purposes of this tutorial. For a production application, please follow the principle of least privilege and limit the endpoints available to the key. Save the API key off as you’ll need it later.</p>

<h2 id="creating-a-new-user">Creating a new user</h2>
<p>To test your Gatsby-based login, you’ll need to add a new user and register them for your application in FusionAuth. From the Users page in FusionAuth, click “+” to add a user. Enter an email address and password for your new user and click the save button.</p>

<p><img src="https://fusionauth.io/assets/img/blogs/oauth-gatsby/create-user.png" alt="Creating a new user in FusionAuth."></p>

<p>Next, click “Add registration” to link this user to the application you created in Step 1. Click the save button when you’re finished.</p>

<p><img src="https://fusionauth.io/assets/img/blogs/oauth-gatsby/register-user.png" alt="Registering a user in FusionAuth."></p>

<p>Now that a user is registered for your application, you can start building the Node app.</p>

<h2 id="creating-a-node-proxy-application">Creating a Node proxy application</h2>
<p>This project will use two separate applications: a Node app to securely store your access token and make calls to the FusionAuth API, and a Gatsby site to present information to the user. The Node app will have four endpoints:</p>

<ul>
  <li><code>/login</code> - Generates the FusionAuth login URL with a PKCE challenge</li>
  <li><code>/oauth-callback</code> - Trades the one-time authorization code and PKCE verifier for an access token which is added to session storage</li>
  <li><code>/user</code> - Uses the access token and the FusionAuth <code>introspect</code> endpoint to get information about the current user</li>
  <li><code>/logout</code> - Logs the user out and destroys the session</li>
</ul>

<p>You’ll create all the endpoints first, and then you’ll see how to call them from Gatsby.</p>

<h3 id="setting-up-the-node-app">Setting up the Node app</h3>
<p>Before you get started, you need to create a new subdirectory and initialize an Express app. Use a <a href="https://fusionauth.io/blog/2020/03/10/securely-implement-oauth-in-react">similar structure to the one outlined here</a>:</p>

<div><div><pre><code>fusionauth-gatsby
├─gatsby
├─server
└─config.js
</code></pre></div></div>

<p>Your <code>config.js</code> file should contain all your FusionAuth information. Add the following to the file with your FusionAuth application’s ID, client ID, and ports:</p>

<div><div><pre><code>module.exports = {
  // FusionAuth info (copied from the FusionAuth admin panel)
  clientID: '5eb76e67-c65e-474d-ba23-4cb61b0c8414',
  clientSecret: 'BVS1NIgID3HWE5U38HYSb4DOie3UbIySOsJKLT41WWg',
  redirectURI: 'http://localhost:9000/oauth-callback',
  applicationID: '5eb76e67-c65e-474d-ba23-4cb61b0c8414',

  // Your FusionAuth api key
  apiKey: 'skAHV4mOEhz2zYQcG_5l4BkhsCzmtYTU8VGOi8Y40zo',

  // Ports
  clientPort: 8000,
  serverPort: 9000,
  fusionAuthPort: 9011
};
</code></pre></div></div>

<p>Within the <code>./server</code> directory, create a new <a href="https://expressjs.com/">Express</a> app and install the <a href="https://www.npmjs.com/package/cors">cors</a>, <a href="https://www.npmjs.com/package/express-session">session</a> and <a href="https://www.npmjs.com/package/request">request</a> packages.</p>

<div><div><pre><code>npm init
<span># Complete all the questions as appropriate</span>
npm <span>install </span>express cors express-session request <span>--save</span>
</code></pre></div></div>

<p>Next, open up your <code>package.json</code> file and add a <code>"start"</code> script:</p>

<div><div><pre><code><span>//</span><span> </span><span>...</span><span>
</span><span>"scripts"</span><span>:</span><span> </span><span>{</span><span>
  </span><span>"start"</span><span>:</span><span> </span><span>"node index.js"</span><span>
</span><span>}</span><span>,</span><span>
</span><span>//</span><span> </span><span>...</span><span>
</span></code></pre></div></div>

<p>Finally, create a new file in the <code>./server</code> directory called <code>index.js</code> that will initialize your Express app:</p>

<div><div><pre><code><span>const</span> <span>express</span> <span>=</span> <span>require</span><span>(</span><span>'</span><span>express</span><span>'</span><span>);</span>
<span>const</span> <span>session</span> <span>=</span> <span>require</span><span>(</span><span>'</span><span>express-session</span><span>'</span><span>);</span>
<span>const</span> <span>cors</span> <span>=</span> <span>require</span><span>(</span><span>'</span><span>cors</span><span>'</span><span>);</span>
<span>const</span> <span>config</span> <span>=</span> <span>require</span><span>(</span><span>'</span><span>../config</span><span>'</span><span>);</span>

<span>// configure Express app and install the JSON middleware for parsing JSON bodies</span>
<span>const</span> <span>app</span> <span>=</span> <span>express</span><span>();</span>
<span>app</span><span>.</span><span>use</span><span>(</span><span>express</span><span>.</span><span>json</span><span>());</span>

<span>// configure sessions</span>
<span>app</span><span>.</span><span>use</span><span>(</span><span>session</span><span>(</span>
  <span>{</span>
    <span>secret</span><span>:</span> <span>'</span><span>1234567890</span><span>'</span><span>,</span>
    <span>resave</span><span>:</span> <span>false</span><span>,</span>
    <span>saveUninitialized</span><span>:</span> <span>false</span><span>,</span>
    <span>cookie</span><span>:</span> <span>{</span>
      <span>secure</span><span>:</span> <span>'</span><span>auto</span><span>'</span><span>,</span>
      <span>httpOnly</span><span>:</span> <span>true</span><span>,</span>
      <span>maxAge</span><span>:</span> <span>3600000</span>
    <span>}</span>
  <span>})</span>
<span>);</span>

<span>// configure CORS</span>
<span>app</span><span>.</span><span>use</span><span>(</span><span>cors</span><span>(</span>
  <span>{</span>
    <span>origin</span><span>:</span> <span>true</span><span>,</span>
    <span>credentials</span><span>:</span> <span>true</span>
  <span>})</span>
<span>);</span>

<span>// use routes</span>
<span>app</span><span>.</span><span>use</span><span>(</span><span>'</span><span>/user</span><span>'</span><span>,</span> <span>require</span><span>(</span><span>'</span><span>./routes/user</span><span>'</span><span>));</span>
<span>app</span><span>.</span><span>use</span><span>(</span><span>'</span><span>/login</span><span>'</span><span>,</span> <span>require</span><span>(</span><span>'</span><span>./routes/login</span><span>'</span><span>));</span>
<span>app</span><span>.</span><span>use</span><span>(</span><span>'</span><span>/oauth-callback</span><span>'</span><span>,</span> <span>require</span><span>(</span><span>'</span><span>./routes/oauth-callback</span><span>'</span><span>));</span>
<span>app</span><span>.</span><span>use</span><span>(</span><span>'</span><span>/logout</span><span>'</span><span>,</span> <span>require</span><span>(</span><span>'</span><span>./routes/logout</span><span>'</span><span>));</span>

<span>// start server</span>
<span>app</span><span>.</span><span>listen</span><span>(</span><span>config</span><span>.</span><span>serverPort</span><span>,</span> <span>()</span> <span>=&gt;</span> <span>console</span><span>.</span><span>log</span><span>(</span><span>`FusionAuth example app listening on port </span><span>${</span><span>config</span><span>.</span><span>serverPort</span><span>}</span><span>.`</span><span>));</span>
</code></pre></div></div>

<p>In the following sections, you’ll create the route files listed in the code above.</p>

<h3 id="creating-the-login-route">Creating the login route</h3>
<p>To generate a login URL, your application will need to create a PKCE verifier and challenge. It will send the challenge to FusionAuth via query string parameters along with your client ID and a redirect URL.</p>

<p>Using PKCE adds an additional layer of security, as it is a one time use and guarantees that the Node application that generated the challenge is the same one that sent the verifier. Normally, PKCE is used where the client cannot keep a secret, such as a single page application.</p>

<p>To generate a <a href="https://www.oauth.com/oauth2-servers/pkce/">PKCE challenge and verifier</a>, you’ll need to use some of the <a href="https://nodejs.org/api/crypto.html">Node crypto functions</a>. Create a new folder in the <code>./server</code> directory called <code>helpers</code>. Add a new file called <code>pkce.js</code> to the folder. You will generate a verifier and challenge in this file:</p>

<div><div><pre><code><span>const</span> <span>crypto</span> <span>=</span> <span>require</span><span>(</span><span>'</span><span>crypto</span><span>'</span><span>);</span>

<span>function</span> <span>base64URLEncode</span><span>(</span><span>str</span><span>)</span> <span>{</span>
  <span>return</span> <span>str</span>
    <span>.</span><span>toString</span><span>(</span><span>"</span><span>base64</span><span>"</span><span>)</span>
    <span>.</span><span>replace</span><span>(</span><span>/</span><span>\+</span><span>/g</span><span>,</span> <span>"</span><span>-</span><span>"</span><span>)</span>
    <span>.</span><span>replace</span><span>(</span><span>/</span><span>\/</span><span>/g</span><span>,</span> <span>"</span><span>_</span><span>"</span><span>)</span>
    <span>.</span><span>replace</span><span>(</span><span>/=/g</span><span>,</span> <span>""</span><span>)</span>
<span>}</span>

<span>function</span> <span>sha256</span><span>(</span><span>buffer</span><span>)</span> <span>{</span>
  <span>return</span> <span>crypto</span><span>.</span><span>createHash</span><span>(</span><span>"</span><span>sha256</span><span>"</span><span>).</span><span>update</span><span>(</span><span>buffer</span><span>).</span><span>digest</span><span>()</span>
<span>}</span>

<span>module</span><span>.</span><span>exports</span><span>.</span><span>generateVerifier</span> <span>=</span> <span>()</span> <span>=&gt;</span> <span>{</span>
  <span>return</span> <span>base64URLEncode</span><span>(</span><span>crypto</span><span>.</span><span>randomBytes</span><span>(</span><span>32</span><span>))</span>
<span>}</span>

<span>module</span><span>.</span><span>exports</span><span>.</span><span>generateChallenge</span> <span>=</span> <span>(</span><span>verifier</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>return</span> <span>base64URLEncode</span><span>(</span><span>sha256</span><span>(</span><span>verifier</span><span>))</span>
<span>}</span>
</code></pre></div></div>

<p>The two exported functions, <code>generateVerifier</code> and <code>generateChallenge</code>, will be used in your login route to create a PKCE verifier. Create a new directory called <code>routes</code> in your <code>./server</code> directory and add a new file called <code>login.js</code> to it:</p>

<div><div><pre><code><span>const</span> <span>express</span> <span>=</span> <span>require</span><span>(</span><span>'</span><span>express</span><span>'</span><span>);</span>
<span>const</span> <span>router</span> <span>=</span> <span>express</span><span>.</span><span>Router</span><span>();</span>
<span>const</span> <span>config</span> <span>=</span> <span>require</span><span>(</span><span>'</span><span>../../config</span><span>'</span><span>);</span>
<span>const</span> <span>pkce</span> <span>=</span> <span>require</span><span>(</span><span>'</span><span>../helpers/pkce</span><span>'</span><span>);</span>

<span>router</span><span>.</span><span>get</span><span>(</span><span>'</span><span>/</span><span>'</span><span>,</span> <span>(</span><span>req</span><span>,</span> <span>res</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>// Generate and store the PKCE verifier</span>
  <span>req</span><span>.</span><span>session</span><span>.</span><span>verifier</span> <span>=</span> <span>pkce</span><span>.</span><span>generateVerifier</span><span>();</span>

  <span>// Generate the PKCE challenge</span>
  <span>const</span> <span>challenge</span> <span>=</span> <span>pkce</span><span>.</span><span>generateChallenge</span><span>(</span><span>req</span><span>.</span><span>session</span><span>.</span><span>verifier</span><span>);</span>

  <span>// Redirect the user to log in via FusionAuth</span>
  <span>res</span><span>.</span><span>redirect</span><span>(</span><span>`http://localhost:</span><span>${</span><span>config</span><span>.</span><span>fusionAuthPort</span><span>}</span><span>/oauth2/authorize?`</span><span>+</span>
    <span>`client_id=</span><span>${</span><span>config</span><span>.</span><span>clientID</span><span>}</span><span>&amp;redirect_uri=</span><span>${</span><span>config</span><span>.</span><span>redirectURI</span><span>}</span><span>&amp;response_type=code`</span><span>+</span>
    <span>`&amp;code_challenge=</span><span>${</span><span>challenge</span><span>}</span><span>&amp;code_challenge_method=S256`</span><span>);</span>
<span>});</span>

<span>module</span><span>.</span><span>exports</span> <span>=</span> <span>router</span><span>;</span>
</code></pre></div></div>

<p>Now when users visit <code>localhost:9000/login</code> the Node app will generate a PKCE verifier and challenge, save the verifier to session storage, and redirect the user to FusionAuth with the challenge in the URL. The FusionAuth app will store this challenge and make sure that the verifier sent in the OAuth callback is valid.</p>

<h3 id="creating-the-oauth-callback">Creating the OAuth callback</h3>
<p>Once the user has entered their username and password, the FusionAuth server will check their credentials and redirect them to your Node app’s OAuth callback endpoint with an authorization code. Your app will use that code and the PKCE verifier generated in the previous step to request a <a href="https://fusionauth.io/docs/v1/tech/oauth/tokens">long-lived access token</a>.</p>

<p>Again, adding PKCE adds another layer of security by proving that the entity which sent the challenge is now requesting an access token. Your Node app will store the access token returned by FusionAuth in session storage and redirect the user to the Gatsby profile page we’ll create in the next step.</p>

<p>Create a new route called <code>oauth-callback.js</code> and add the following:</p>

<div><div><pre><code><span>const</span> <span>express</span> <span>=</span> <span>require</span><span>(</span><span>'</span><span>express</span><span>'</span><span>);</span>
<span>const</span> <span>router</span> <span>=</span> <span>express</span><span>.</span><span>Router</span><span>();</span>
<span>const</span> <span>request</span> <span>=</span> <span>require</span><span>(</span><span>'</span><span>request</span><span>'</span><span>);</span>
<span>const</span> <span>config</span> <span>=</span> <span>require</span><span>(</span><span>'</span><span>../../config</span><span>'</span><span>);</span>

<span>router</span><span>.</span><span>get</span><span>(</span><span>'</span><span>/</span><span>'</span><span>,</span> <span>(</span><span>req</span><span>,</span> <span>res</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>request</span><span>(</span>
    <span>// POST request to /token endpoint</span>
    <span>{</span>
      <span>method</span><span>:</span> <span>'</span><span>POST</span><span>'</span><span>,</span>
      <span>uri</span><span>:</span> <span>`http://localhost:</span><span>${</span><span>config</span><span>.</span><span>fusionAuthPort</span><span>}</span><span>/oauth2/token`</span><span>,</span>
      <span>form</span><span>:</span> <span>{</span>
        <span>'</span><span>client_id</span><span>'</span><span>:</span> <span>config</span><span>.</span><span>clientID</span><span>,</span>
        <span>'</span><span>client_secret</span><span>'</span><span>:</span> <span>config</span><span>.</span><span>clientSecret</span><span>,</span>
        <span>'</span><span>code</span><span>'</span><span>:</span> <span>req</span><span>.</span><span>query</span><span>.</span><span>code</span><span>,</span>
        <span>'</span><span>code_verifier</span><span>'</span><span>:</span> <span>req</span><span>.</span><span>session</span><span>.</span><span>verifier</span><span>,</span>
        <span>'</span><span>grant_type</span><span>'</span><span>:</span> <span>'</span><span>authorization_code</span><span>'</span><span>,</span>
        <span>'</span><span>redirect_uri</span><span>'</span><span>:</span> <span>config</span><span>.</span><span>redirectURI</span>
      <span>}</span>
    <span>},</span>

    <span>// callback</span>
    <span>(</span><span>error</span><span>,</span> <span>response</span><span>,</span> <span>body</span><span>)</span> <span>=&gt;</span> <span>{</span>
      <span>// save token to session</span>
      <span>req</span><span>.</span><span>session</span><span>.</span><span>token</span> <span>=</span> <span>JSON</span><span>.</span><span>parse</span><span>(</span><span>body</span><span>).</span><span>access_token</span><span>;</span>

      <span>// redirect to Gatsby</span>
      <span>res</span><span>.</span><span>redirect</span><span>(</span><span>`http://localhost:</span><span>${</span><span>config</span><span>.</span><span>clientPort</span><span>}</span><span>/profile`</span><span>);</span>
    <span>}</span>
  <span>);</span>
<span>});</span>

<span>module</span><span>.</span><span>exports</span> <span>=</span> <span>router</span><span>;</span>
</code></pre></div></div>

<p>Your app now authenticates users and stores their access tokens in …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://fusionauth.io/blog/2020/06/25/using-oauth-and-pkce-to-add-authentication-to-your-gatsby-site">https://fusionauth.io/blog/2020/06/25/using-oauth-and-pkce-to-add-authentication-to-your-gatsby-site</a></em></p>]]>
            </description>
            <link>https://fusionauth.io/blog/2020/06/25/using-oauth-and-pkce-to-add-authentication-to-your-gatsby-site</link>
            <guid isPermaLink="false">hacker-news-small-sites-23642003</guid>
            <pubDate>Thu, 25 Jun 2020 15:46:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[2Ton Digital – Modern tools written in Assembly language]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23641887">thread link</a>) | @smartmic
<br/>
June 25, 2020 | https://2ton.com.au/Products/ | <a href="https://web.archive.org/web/*/https://2ton.com.au/Products/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="lf-main">
<p>
	The standalone binaries here are subject to the same GPLv3 license that the <a href="https://2ton.com.au/HeavyThing/">HeavyThing library</a> itself is, and are provided as conveniences only so that downloading the entire library is not required. See the file <code>LICENSE</code> in the library distribution for further details.
</p>
<ul>
		<li><a href="https://2ton.com.au/HeavyThing/">HeavyThing</a> - x86_64 assembly language library that is the heart of 2 Ton Digital.
			
		</li>
		<li><a href="https://2ton.com.au/rwasa/">rwasa</a> - full featured web server that eclipses nginx.
			<p>
			Standalone binary download: <a href="https://2ton.com.au/standalone_binaries/rwasa">rwasa</a><br>
			SHA256: a5f3ad1da5aac8051f31b62c9c27f953ac0a01642bae1e07d3af74c7f261163b<br>
			Source code: included with the HeavyThing library itself.
			</p>
		</li>
		<li><a href="https://2ton.com.au/toplip/">toplip</a> - command line very strong encryption utility.
			<p>
			Standalone binary download: <a href="https://2ton.com.au/standalone_binaries/toplip">toplip</a><br>
			SHA256: 9ea8978b9d59b2450bb1103972a0869b79622cdc0080d02b846e37abb27c33c4<br>
			Source code: included with the HeavyThing library itself.
			</p>
		</li>
		<li><a href="https://2ton.com.au/sshtalk/">sshtalk</a> - ephemeral multi-person SSH chat.
			<p>
			Standalone binary download: <a href="https://2ton.com.au/standalone_binaries/sshtalk">sshtalk</a><br>
			SHA256: bdbe7f4ec2f1e18148a913825fdc35b6c3ab5ce41999ba815969fe7b49d606a5<br>
			Source code: included with the HeavyThing library itself.
			</p>
		</li>
		<li><a href="https://2ton.com.au/dhtool/">dhtool</a> - Diffie-Hellman parameter generator/verifier/converter.
			<p>
			Standalone binary download: <a href="https://2ton.com.au/standalone_binaries/dhtool">dhtool</a><br>
			SHA256: 607d7e6241554651e7f7f78b19ff144a93e66047ca7519fe63ae6546d23ec020<br>
			Source code: included with the HeavyThing library itself.
			</p>
		</li>
		<li><a href="https://2ton.com.au/hnwatch/">hnwatch</a> - HackerNews API realtime terminal watch/reader.
			<p>
			Standalone binary download: <a href="https://2ton.com.au/standalone_binaries/hnwatch">hnwatch</a><br>
			SHA256: 511204246d9d80339dc46b3bea4ef0f4114216e1ab4c13695cee5467f5685ff1<br>
			Source code: included with the HeavyThing library itself.
			</p>
		</li>
		<li><a href="https://2ton.com.au/webslap/">webslap</a> - website quality assurance reporting tool.
			<p>
			Standalone binary download: <a href="https://2ton.com.au/standalone_binaries/webslap">webslap</a><br>
			SHA256: 45d811ed2c3a7c9e5143d3bcabb0a71ce8ca1946c2d11a8b442c6d1520f14aab<br>
			Source code: included with the HeavyThing library itself.
			</p>
		</li>
	</ul>


					</div></div>]]>
            </description>
            <link>https://2ton.com.au/Products/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23641887</guid>
            <pubDate>Thu, 25 Jun 2020 15:37:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Critical Considerations for a Return to the Office]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23641857">thread link</a>) | @Gpetrium
<br/>
June 25, 2020 | https://gpetrium.com/critical-considerations-for-a-return-to-the-office/ | <a href="https://web.archive.org/web/*/https://gpetrium.com/critical-considerations-for-a-return-to-the-office/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-elementor-type="wp-post" data-elementor-id="2842" data-elementor-settings="[]"><div><div><section data-id="39d49db" data-element_type="section"></section><section data-id="ec8fe89" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;,&quot;shape_divider_bottom&quot;:&quot;opacity-tilt&quot;}"><div><div><div data-id="c9e3186" data-element_type="column"><div><div><div data-id="572a9ee" data-element_type="widget" data-widget_type="image.default"><div><p><img width="1280" height="720" src="https://i2.wp.com/gpetrium.com/wp-content/uploads/2020/06/cog-wheels-2125169_1280-min.jpg?fit=1280%2C720&amp;ssl=1" data-src="https://i2.wp.com/gpetrium.com/wp-content/uploads/2020/06/cog-wheels-2125169_1280-min.jpg?fit=1280%2C720&amp;ssl=1" alt="" data-srcset="https://i2.wp.com/gpetrium.com/wp-content/uploads/2020/06/cog-wheels-2125169_1280-min.jpg?w=1280&amp;ssl=1 1280w, https://i2.wp.com/gpetrium.com/wp-content/uploads/2020/06/cog-wheels-2125169_1280-min.jpg?resize=300%2C169&amp;ssl=1 300w, https://i2.wp.com/gpetrium.com/wp-content/uploads/2020/06/cog-wheels-2125169_1280-min.jpg?resize=1024%2C576&amp;ssl=1 1024w, https://i2.wp.com/gpetrium.com/wp-content/uploads/2020/06/cog-wheels-2125169_1280-min.jpg?resize=768%2C432&amp;ssl=1 768w, https://i2.wp.com/gpetrium.com/wp-content/uploads/2020/06/cog-wheels-2125169_1280-min.jpg?resize=600%2C338&amp;ssl=1 600w" data-sizes="(max-width: 750px) 100vw, 750px"></p></div></div></div></div></div></div></div></section><section data-id="f267f03" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"></section><section data-id="699a2dc" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"></section><section data-id="767dab9" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="d033f7a" data-element_type="column"><div><div><div data-id="c4b6e30" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Amidst the pandemic, the world has had to cope with drastic changes in work related policies. A few organizations have even experienced a permanent move towards work from home (WFH) practices. While many are satisfied with the change for different reasons, others can’t seem to wait to get back to the way that work used to be. At this time, employers have to contend to the short and long-term ramifications of new working conditions and its impacts to productivity, communication, culture, cybersecurity and several other issues that have emerged as a result.</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; As considerations are made, organizations will need to take a holistic approach to ensure a successful transition to a new normal. Below are some of the key areas that leadership has to work with as it builds and implements a return to the office plan.</p></div></div></div><div data-id="4a9e017" data-element_type="widget" data-widget_type="heading.default"><p><h2>Legal &amp; Regulatory Compliance</h2></p></div><div data-id="3019c57" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; There have been multiple public authorities at the federal, state/ provincial and municipal levels that have enacted policies to curb the spread of the pandemic and support all pillars of society. As usual, it falls onto the laps of leadership to ensure that their organization remains in compliance with said laws.</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; As the legal environment changes internationally and nationally, organizations have to consider the legal and financial implications of adopting and complying to new policies. Further deliberation regarding the safety of the workforce need to be taken into account. At this time, companies need to be proactive by revisiting internal policies such as Health and Safety policies, WFH policies, Code of Conduct policies, and Cybersecurity policies. As such, it is essential that senior executives work in tandem with officers on the ground to understand the current atmosphere of their organization, its impact on policies and expectations, as well as ensure that enacted policies reach their desired outcomes.</p></div></div></div><div data-id="7c67953" data-element_type="widget" data-widget_type="image.default"><div><p><img width="360" height="240" src="https://i0.wp.com/gpetrium.com/wp-content/uploads/2020/06/hands-4917949_1280-min.jpg?resize=360%2C240&amp;ssl=1" data-src="https://i0.wp.com/gpetrium.com/wp-content/uploads/2020/06/hands-4917949_1280-min.jpg?resize=360%2C240&amp;ssl=1" alt="" data-srcset="https://i0.wp.com/gpetrium.com/wp-content/uploads/2020/06/hands-4917949_1280-min.jpg?w=1280&amp;ssl=1 1280w, https://i0.wp.com/gpetrium.com/wp-content/uploads/2020/06/hands-4917949_1280-min.jpg?resize=300%2C199&amp;ssl=1 300w, https://i0.wp.com/gpetrium.com/wp-content/uploads/2020/06/hands-4917949_1280-min.jpg?resize=1024%2C680&amp;ssl=1 1024w, https://i0.wp.com/gpetrium.com/wp-content/uploads/2020/06/hands-4917949_1280-min.jpg?resize=768%2C510&amp;ssl=1 768w, https://i0.wp.com/gpetrium.com/wp-content/uploads/2020/06/hands-4917949_1280-min.jpg?resize=360%2C240&amp;ssl=1 360w, https://i0.wp.com/gpetrium.com/wp-content/uploads/2020/06/hands-4917949_1280-min.jpg?resize=600%2C398&amp;ssl=1 600w" data-sizes="(max-width: 360px) 100vw, 360px"></p></div></div><div data-id="651f2b8" data-element_type="widget" data-widget_type="heading.default"><p><h2>Sanitary and Hygiene Practices</h2></p></div><div data-id="24e74cd" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; In an office environment, organizations have to consider how and whether to shoulder the costs of PPE supplies and training for its employees and customers. If that is not an option, leaders have to contend with personally owned PPE which may be inadequate or non-existent. This may pose unintended consequences that may challenge return to the office efforts and increase customer and employee exposure, potentially leading to disruptions in operations. (<span><a href="https://www.nytimes.com/2020/05/19/technology/amazon-coronavirus-workers.html">‘Way Too Late’: Inside Amazon’s Biggest Outbreak</a></span>, NY Times).</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Good personal hygiene such as hand washing and social distancing remains a major part of the fight against COVID-19. To ensure good office practices and training, well positioned pamphlets, workshops, adequate infrastructure, supporting policies, and a culture of cleanliness are just a few of the major drivers of change.</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Office cleanliness will remain a priority to both the organization and employees. Even if it is believed that employees are following sanitary and hygiene practices, the organization will likely need to increase the rate of commercial cleaning services throughout its establishment.</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; In a pandemic environment, sanitary and hygiene practices are not isolated factors that are bound to stay within the secrecy of a company. For example, a <span><a href="https://www.cbsnews.com/news/coronavirus-in-germany-meat-packing-plant-covid-19-outbreak-cases-r-reproduction-rate-up-today-2020-06-22/">single meat packing plant in Germany</a></span> is believed to be behind over 1,000 confirmed cases. Even in optimal conditions, outbreaks of this nature can have a direct impact on society, economic recovery, organizational operations and even raise risks to brand value.</p></div></div></div><div data-id="b6a4e69" data-element_type="widget" data-widget_type="heading.default"><p><h2>Shared Space and Common Area Policies</h2></p></div><div data-id="6fae723" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Prior to the pandemic, many organizations have moved their offices to shared work spaces and common areas within offices such as water coolers, cafeteria or entertainment rooms, were seen as standard infrastructure. Nowadays, there are concerns that these areas will often involve interactions in close proximity, which can further exacerbate pandemic related risks.</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; To lower said risks, organizations need to consider implementing physical distancing and hygiene measures and protocols. At this time, many governmental bodies have stipulated guidelines that can be used to support organizational procedures and help organizations navigate through the reopening of their workplace. The <span><a href="https://covid19.ca.gov/industry-guidance/">State of California</a></span>, <span><a href="https://www1.nyc.gov/site/doh/covid/covid-19-businesses-and-facilities.page">New York City</a></span>, and the <span><a href="https://www.toronto.ca/home/covid-19/covid-19-protect-yourself-others/community-settings-workplaces/">City of Toronto</a></span> are just a few examples of such guidelines being extended to organizations. It is important to follow local guidelines, but whenever possible, borrow additional innovative takes from other jurisdictions.</p></div></div></div><div data-id="776149d" data-element_type="widget" data-widget_type="heading.default"><p><h2>Back to the Office Employee Prioritization</h2></p></div><div data-id="16083af" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Teams or roles that demand a higher amount of physical interaction and can’t perform their duties well via online means should be considered as front-runners of back to the office policies. Simultaneously, leaders should critically assess if individuals whose roles are well suited for remote working, should only make the return to the office at the later phase of the pandemic reopening. Such efforts can help reduce health risks to employees and customers.</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The IT department for example, may return back to the office on a rotational basis or in batches (team by team). Employees involved in the preparation and maintenance of physical technology (e.g. servers and hardware support) are likely to be prioritized while most of the software cast may be held back to later phases since their work may be accomplished remotely.</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; As leadership determines how to prioritize the return to the office, there are a few questions that should always be asked:</p><ul><li>Are there feasible technological or procedural options that can be taken to limit X role’s exposure? If so, would their work be impacted and how?</li><li>How big of a priority would it be to bring certain individuals back to the office under these circumstances?</li><li>Would the solution help potential future disruptions such as a 2<sup>nd</sup> COVID-19 wave?”</li></ul></div></div></div><div data-id="94b69f1" data-element_type="widget" data-widget_type="text-editor.default"><div><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Meeting rooms can follow similar protocols stipulated to shared spaces and common areas, given the limited square footage that such spaces traditionally have which can make it harder to enforce distancing rules and lead to an <span><a href="https://www.cebm.net/covid-19/what-is-the-evidence-to-support-the-2-metre-social-distancing-rule-to-reduce-covid-19-transmission/">increased risk of transmission</a></span>. In said cases, organizations may benefit from setting a threshold on the number of employees permitted per meeting and the distances that are expected. Office administrators may want to set delimitators such as a sign to stipulate social distancing and remove excess chairs to help set the precedent. Reminder mechanisms such as pamphlets to clean spaces before and once they have been used can also beneficial.</p></div></div><div data-id="40674cf" data-element_type="widget" data-widget_type="heading.default"><p><h2>Rotational Work Schedules</h2></p></div><div data-id="0e4000c" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; To diminish contact, some organizations may benefit from building rotational work schedules where a department or group alternates every couple of weeks. This can help set better social distancing in offices that do not have the capacity to handle prior numbers of employees and clients. Some organizations have already started a two week in office and off office rotation, in which the workforce is divided into 2 groups (or more) which rotate the office space – as seen in the case of <span><a href="https://webstercity.com/2020/03/24/city-staff-to-rotate-on-shifts-in-response-to-covid-19/">Webster City</a></span>, Iowa.</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; It also allows teams to regain some of the interactions and experience that the office can provide while still having work from home flexibility. Organizations may find this to be the right mix of home comfort and office experience. Once COVID-19 related issues subside, organizations may find further operational efficiency in having a mixed policy, allowing it to move into smaller offices with lower costs.</p></div></div></div><div data-id="4111b59" data-element_type="widget" data-widget_type="image.default"><div><p><img width="360" height="240" src="https://i2.wp.com/gpetrium.com/wp-content/uploads/2020/06/rattan-5330786_1280-min.jpg?resize=360%2C240&amp;ssl=1" data-src="https://i2.wp.com/gpetrium.com/wp-content/uploads/2020/06/rattan-5330786_1280-min.jpg?resize=360%2C240&amp;ssl=1" alt="" data-srcset="https://i2.wp.com/gpetrium.com/wp-content/uploads/2020/06/rattan-5330786_1280-min.jpg?resize=360%2C240&amp;ssl=1 360w, https://i2.wp.com/gpetrium.com/wp-content/uploads/2020/06/rattan-5330786_1280-min.jpg?zoom=2&amp;resize=360%2C240&amp;ssl=1 720w, https://i2.wp.com/gpetrium.com/wp-content/uploads/2020/06/rattan-5330786_1280-min.jpg?zoom=3&amp;resize=360%2C240&amp;ssl=1 1080w" data-sizes="(max-width: 360px) 100vw, 360px"></p></div></div><div data-id="547cd1e" data-element_type="widget" data-widget_type="text-editor.default"><div><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Currently, most offices are not set-up to accommodate for COVID-19 related concerns such as social distancing. As organization decide when and who may return to the office, considerations over closed workspace, socially distanced offices, signs, contactless technology can be major drivers in helping leaders implement an employee first and health-driven culture.</p></div></div><div data-id="c8cf2f0" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The pandemic has shown that family and individuals can be impacted differently. To ensure a smooth transition back to the office, organizations may benefit from having structure, policies and procedures to handle exceptions. For instance, employees with children or elderly parents at home may have a difficult time procuring the necessary resources to support their needs. At times like these, the organization may benefit from giving the employee an extended work from home period where viable.</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Clients may also prefer to have the option to attend meetings and consultations online. There is a fine balance between organizational, employee, and customer needs. Considerations over the complexity of exception handling should also be taken into account. Critical assessment of said implications and needs can help improve employee and customer satisfaction in the short run while also providing much needed experience on how to handle operational challenges that are bound to occur (crisis handling).</p></div></div></div><div data-id="8c003e6" data-element_type="widget" data-widget_type="heading.default"><p><h2>Clear, Open and Continuous Communication</h2></p></div><div data-id="5470e56" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; In periods with trials and tribulations, society looks for leaders to guide them through rough patches. For an organization, employees and customers are actively looking for cues to understand its trajectory and how it will impact them.</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; At this time, discrepancies in individual habits in relation to work from home and back to office may be front-center in a manager’s mind. Whether it is employee tardiness, commute, productivity, organizational networks and others, readjustment will take time and requires guidance. For that to happen, leaders will need to maintain a transparent, open and continuous communication to help clarify and facilitate solutions for issues that arise.</p></div></div></div><div data-id="ab5c68a" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Transitional periods can be challenging to many and will often lead to resistances. To ensure a smooth transition back to the office, it is important to note the origins of said challenges. At its base, resistance will often involve at least one of the following:</p><p>1) An uncomfortable level of …</p></div></div></div></div></div></div></div></div></section></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://gpetrium.com/critical-considerations-for-a-return-to-the-office/">https://gpetrium.com/critical-considerations-for-a-return-to-the-office/</a></em></p>]]>
            </description>
            <link>https://gpetrium.com/critical-considerations-for-a-return-to-the-office/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23641857</guid>
            <pubDate>Thu, 25 Jun 2020 15:34:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[BLEU Score: Bilingual Evaluation Understudy]]>
            </title>
            <description>
<![CDATA[
Score 56 | Comments 12 (<a href="https://news.ycombinator.com/item?id=23641791">thread link</a>) | @keyboardman
<br/>
June 25, 2020 | https://leimao.github.io/blog/BLEU-Score/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/blog/BLEU-Score/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>BLEU is a standard algorithm for evaluating the machine translations against the human translations. At first I thought it should be very straightforward to use. However, it turns out that there are a lot of caveats.</p>



<p>In this blog post, I am going to show the BLEU algorithm in detail and talk about the caveats.</p>

<h3 id="english-translation-example">English Translation Example</h3>

<p>We will use the following examples to illustrate how to compute the BLEU scores.</p>

<h4 id="example-1">Example 1</h4>

<p>Chinese: 猫坐在垫子上</p>

<p>Reference 1: the cat is on the mat</p>

<p>Reference 2: there is a cat on the mat</p>

<p>Candidate: the cat the cat on the mat</p>

<h4 id="example-2">Example 2</h4>

<p>Chinese: 猫坐在垫子上</p>

<p>Reference 1: the cat is on the mat</p>

<p>Reference 2: there is a cat on the mat</p>

<p>Candidate: the the the the the the the the</p>

<h3 id="precision">Precision</h3>

<p>We count each of the ngram in the candidate sentence whether it has shown in any of the reference sentences, gather the total counts for each of the unique ngram, sum up the total counts for each of the unique ngram, and divided by the number of ngrams in the candidate sentence.</p>

<h4 id="example-1-1">Example 1</h4>

<p>We first compute the unigram precision for example 1. All the unigrams in the candidate sentences have shown in the reference sentences.</p>



<table>
  <tbody><tr>
    <th>Unigram</th>
    <th>Shown?</th>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>cat</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>cat</td>
    <td>1</td>
  </tr>
  <tr>
    <td>on</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>mat</td>
    <td>1</td>
  </tr>
</tbody></table>

<p>We then merge the unigram counts.</p>



<table>
  <tbody><tr>
    <th>Unique Unigram</th>
    <th>Count</th>
  </tr>
  <tr>
    <td>the</td>
    <td>3</td>
  </tr>
  <tr>
    <td>cat</td>
    <td>2</td>
  </tr>
  <tr>
    <td>on</td>
    <td>1</td>
  </tr>
  <tr>
    <td>mat</td>
    <td>1</td>
  </tr>
</tbody></table>

<p>The total number of counts for the unique unigrams in the candidate sentence is 7, and the total number of unigrams in the candidate sentence is 7. The unigram precision is 7/7 = 1.0 for example 1.</p>



<p>We then try to compute the bigram precision for example 1.</p>



<table>
  <tbody><tr>
    <th>Bigram</th>
    <th>Shown?</th>
  </tr>
  <tr>
    <td>the cat</td>
    <td>1</td>
  </tr>
  <tr>
    <td>cat the</td>
    <td>0</td>
  </tr>
  <tr>
    <td>the cat</td>
    <td>1</td>
  </tr>
  <tr>
    <td>cat on</td>
    <td>1</td>
  </tr>
  <tr>
    <td>on the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the mat</td>
    <td>1</td>
  </tr>
</tbody></table>

<p>We then merge the bigram counts.</p>



<table>
  <tbody><tr>
    <th>Unique Bigram</th>
    <th>Count</th>
  </tr>
  <tr>
    <td>the cat</td>
    <td>2</td>
  </tr>
  <tr>
    <td>cat the</td>
    <td>0</td>
  </tr>
  <tr>
    <td>cat on</td>
    <td>1</td>
  </tr>
  <tr>
    <td>on the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the mat</td>
    <td>1</td>
  </tr>
</tbody></table>

<p>The total number of counts for the unique bigrams in the candidate sentence is 5, and the total number of bigrams in the candidate sentence is 6. The bigram precision is 5/6 = 0.833 for example 1.</p>

<h4 id="example-2-1">Example 2</h4>

<p>We first compute the unigram precision for example 2. All the unigrams in the candidate sentences have shown in the reference sentences.</p>



<table>
  <tbody><tr>
    <th>Unigram</th>
    <th>Shown?</th>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
</tbody></table>

<p>We then merge the unigram counts.</p>



<table>
  <tbody><tr>
    <th>Unique Unigram</th>
    <th>Count</th>
  </tr>
  <tr>
    <td>the</td>
    <td>8</td>
  </tr>
</tbody></table>

<p>The total number of counts for the unique unigrams in the candidate sentence is 8, and the total number of unigrams in the candidate sentence is 8. The unigram precision is 8/8 = 1.0 for example 2.</p>



<p>We then try to compute the bigram precision for example 2.</p>



<table>
  <tbody><tr>
    <th>Bigram</th>
    <th>Shown?</th>
  </tr>
  <tr>
    <td>the the</td>
    <td>0</td>
  </tr>
  <tr>
    <td>the the</td>
    <td>0</td>
  </tr>
  <tr>
    <td>the the</td>
    <td>0</td>
  </tr>
  <tr>
    <td>the the</td>
    <td>0</td>
  </tr>
  <tr>
    <td>the the</td>
    <td>0</td>
  </tr>
  <tr>
    <td>the the</td>
    <td>0</td>
  </tr>
  <tr>
    <td>the the</td>
    <td>0</td>
  </tr>
</tbody></table>

<p>We then merge the bigram counts.</p>



<table>
  <tbody><tr>
    <th>Unique Bigram</th>
    <th>Count</th>
  </tr>
  <tr>
    <td>the the</td>
    <td>0</td>
  </tr>
</tbody></table>

<p>The total number of counts for the unique bigrams in the candidate sentence is 0, and the total number of bigrams in the candidate sentence is 7. The bigram precision is 0/7 = 0 for example 2.</p>

<h4 id="drawbacks">Drawbacks</h4>

<p>We can see from example 1 and 2 that unigram precision is very easy to be over-confident about the quality of the machine translation. To overcome this, clipped count and modified precision were proposed.</p>

<h3 id="modified-precision">Modified Precision</h3>

<p>For each unique ngram, we count its maximum frequency in each of the reference sentences. The minimum of this special count and the original count is called the clipped the count. That is to say, the clipped count is no greater than the original count. We then use this clipped count, in place of the original count, for computing the modified precision.</p>

<h4 id="example-1-2">Example 1</h4>



<table>
  <tbody><tr>
    <th>Unique Unigram</th>
    <th>Count</th>
    <th>Clipped Count</th>
  </tr>
  <tr>
    <td>the</td>
    <td>3</td>
    <td>2</td>
  </tr>
  <tr>
    <td>cat</td>
    <td>2</td>
    <td>1</td>
  </tr>
  <tr>
    <td>on</td>
    <td>1</td>
    <td>1</td>
  </tr>
  <tr>
    <td>mat</td>
    <td>1</td>
    <td>1</td>
  </tr>
</tbody></table>

<p>The total number of clipped counts for the unique unigrams in the candidate sentence is 5, and the total number of unigrams in the candidate sentence is 7. The unigram modified precision is 5/7 = 0.714 for example 1.</p>



<table>
  <tbody><tr>
    <th>Unique Bigram</th>
    <th>Count</th>
    <th>Clipped Count</th>
  </tr>
  <tr>
    <td>the cat</td>
    <td>2</td>
    <td>1</td>
  </tr>
  <tr>
    <td>cat the</td>
    <td>0</td>
    <td>0</td>
  </tr>
  <tr>
    <td>cat on</td>
    <td>1</td>
    <td>1</td>
  </tr>
  <tr>
    <td>on the</td>
    <td>1</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the mat</td>
    <td>1</td>
    <td>1</td>
  </tr>
</tbody></table>

<p>The total number of clipped counts for the unique bigrams in the candidate sentence is 4, and the total number of unigrams in the candidate sentence is 6. The bigram modified precision is 4/6 = 0.667 for example 1.</p>

<h4 id="example-2-2">Example 2</h4>



<table>
  <tbody><tr>
    <th>Unique Unigram</th>
    <th>Count</th>
    <th>Clipped Count</th>
  </tr>
  <tr>
    <td>the</td>
    <td>8</td>
    <td>2</td>
  </tr>
</tbody></table>

<p>The total number of clipped counts for the unique bigrams in the candidate sentence is 0, and the total number of unigrams in the candidate sentence is 8. The unigram modified precision is 2/8 = 0.25 for example 2.</p>



<table>
  <tbody><tr>
    <th>Unique Bigram</th>
    <th>Count</th>
    <th>Clipped Count</th>
  </tr>
  <tr>
    <td>the the</td>
    <td>0</td>
    <td>0</td>
  </tr>
</tbody></table>

<p>The total number of clipped counts for the unique bigrams in the candidate sentence is 0, and the total number of bigrams in the candidate sentence is 7. The bigram precision is 0/7 = 0 for example 2.</p>

<h4 id="advantages">Advantages</h4>

<p>Compared to precision, we found that modified precision is a better metric, at least for unigrams.</p>

<h3 id="bleu">BLEU</h3>

<h4 id="algorithm">Algorithm</h4>

<p>BLEU is computed using a couple of ngram modified precisions. Specifically,</p>



<p>where $p_n$ is the modified precision for $n$gram, the base of $\log$ is the natural base $e$, $w_n$ is weight between 0 and 1 for $\log p_n$ and $\sum_{n=1}^{N} w_n = 1$, and BP is the brevity penalty to penalize short machine translations.</p>



<p>where $c$ is the number of unigrams (length) in all the candidate sentences, and $r$ is the best match lengths for each candidate sentence in the corpus. Here the best match length is the closest reference sentence length to the candidate sentences. For example, if there are three references with lengths 12, 14, and 17 words and the candidate translation is a terse 13 words, ideally the best match length could be either 12 or 14, but we arbitrary choose the shorter one which is 12.</p>



<p>Usually, the BLEU is evaluated on corpus where there are many candidate sentences translated from different source texts and each of them has several reference sentences. Then $c$ is the total number of unigrams (length) in all the candidate sentences, and $r$ is the sum of the best match lengths for each candidate sentence in the corpus.</p>



<p>It is not hard to find that BLEU is always a value between 0 and 1. It is because BP, $w_n$, and $p_n$ are always between 0 and 1, and</p>



<p>Usually, BLEU uses $N = 4$ and $w_n = \frac{1}{N}$.</p>

<h4 id="example-1-3">Example 1</h4>

<p>We have computed the modified precision for some of the ngrams. It is not hard to compute the others. Concretely, we have</p>





<p>Because the corpus only has one translation set and thus $c = 7$ and $r = 7$</p>



<p>We plugin these values to the BLEU equation, the BLEU is</p>



<p>We further compare the BLEU to the BLEU computed using <a href="https://www.nltk.org/">NLTK</a>.</p>

<div><div><pre><code><span>&gt;&gt;&gt;</span> <span>import</span> <span>nltk</span>
<span>&gt;&gt;&gt;</span> <span>reference_1</span> <span>=</span> <span>"the cat is on the mat"</span><span>.</span><span>split</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>reference_2</span> <span>=</span> <span>"there is a cat on the mat"</span><span>.</span><span>split</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>candidate</span> <span>=</span> <span>"the cat the cat on the mat"</span><span>.</span><span>split</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>bleu</span> <span>=</span> <span>nltk</span><span>.</span><span>translate</span><span>.</span><span>bleu_score</span><span>.</span><span>sentence_bleu</span><span>(</span><span>references</span><span>=</span><span>[</span><span>reference_1</span><span>,</span> <span>reference_2</span><span>],</span> <span>hypothesis</span><span>=</span><span>candidate</span><span>,</span> <span>weights</span><span>=</span><span>(</span><span>0.25</span><span>,</span><span>0.25</span><span>,</span><span>0.25</span><span>,</span><span>0.25</span><span>))</span>
<span>&gt;&gt;&gt;</span> <span>print</span><span>(</span><span>bleu</span><span>)</span>
<span>0.4671379777282001</span>
</code></pre></div></div>

<p>The value of <code>bleu</code> is 0.467 which is exactly matching to the BLEU we computed manually.</p>

<h4 id="example-2-3">Example 2</h4>

<p>Similarly,</p>





<p>Because the corpus only has one translation set and thus $c = 8$ and $r = 7$</p>



<p>When we plugin these values to the BLEU equation, actually we would need to compute $\log 0$ which is not mathematically defined. We use a small number $10^{-100}$ instead of $0$ for $p_2$, $p_3$ and $p_4$. The BLEU is</p>



<p>We further also compare the BLEU to the BLEU computed using <a href="https://www.nltk.org/">NLTK</a>.</p>

<div><div><pre><code><span>&gt;&gt;&gt;</span> <span>import</span> <span>nltk</span>
<span>&gt;&gt;&gt;</span> <span>reference_1</span> <span>=</span> <span>"the cat is on the mat"</span><span>.</span><span>split</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>reference_2</span> <span>=</span> <span>"there is a cat on the mat"</span><span>.</span><span>split</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>candidate</span> <span>=</span> <span>"the the the the the the the the"</span><span>.</span><span>split</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>bleu</span> <span>=</span> <span>nltk</span><span>.</span><span>translate</span><span>.</span><span>bleu_score</span><span>.</span><span>sentence_bleu</span><span>(</span><span>references</span><span>=</span><span>[</span><span>reference_1</span><span>,</span> <span>reference_2</span><span>],</span> <span>hypothesis</span><span>=</span><span>candidate</span><span>,</span> <span>weights</span><span>=</span><span>(</span><span>0.25</span><span>,</span><span>0.25</span><span>,</span><span>0.25</span><span>,</span><span>0.25</span><span>))</span>
<span>&gt;&gt;&gt;</span> <span>print</span><span>(</span><span>bleu</span><span>)</span>
<span>1.2882297539194154e-231</span>
</code></pre></div></div>

<p>The value of <code>bleu</code> is 0 which is exactly matching to the BLEU we computed manually.</p>

<p>Note that in the above two examples, due to the candidate sentence is long and we only have one translation in the corpus, thus $\text{BP} = 1$. In practice, there could be scenarios where $\text{BP} &lt; 1$.</p>

<h3 id="caveats">Caveats</h3>

<p>In some scenarios, BLEU does not score the translation very well, especially for those short translations with few reference sentences. For example,</p>



<p>Chinese: 你准备好了吗？</p>

<p>Reference 1: are you ready ?</p>

<p>Candidate: you are ready ?</p>

<div><div><pre><code><span>&gt;&gt;&gt;</span> <span>import</span> <span>nltk</span>
<span>&gt;&gt;&gt;</span> <span>reference_1</span> <span>=</span> <span>"are you ready ?"</span><span>.</span><span>split</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>candidate</span> <span>=</span> <span>"you are ready ?"</span><span>.</span><span>split</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>bleu</span> <span>=</span> <span>nltk</span><span>.</span><span>translate</span><span>.</span><span>bleu_score</span><span>.</span><span>sentence_bleu</span><span>(</span><span>references</span><span>=</span><span>[</span><span>reference_1</span><span>],</span> <span>hypothesis</span><span>=</span><span>candidate</span><span>,</span> <span>weights</span><span>=</span><span>[</span><span>0.25</span><span>,</span><span>0.25</span><span>,</span><span>0.25</span><span>,</span><span>0.25</span><span>])</span>
<span>&gt;&gt;&gt;</span> <span>print</span><span>(</span><span>bleu</span><span>)</span>
<span>1.133422688662942e-154</span>
</code></pre></div></div>

<p>This is actually a very good machine translation to me. However, the BLEU score is 0, which means that the machine translation is totally wrong.</p>



<p>In NLTK, you are allowed to provide <a href="https://www.nltk.org/api/nltk.translate.html#nltk.translate.bleu_score.SmoothingFunction">smoothing functions</a>. For example,</p>

<div><div><pre><code><span>&gt;&gt;&gt;</span> <span>import</span> <span>nltk</span>
<span>&gt;&gt;&gt;</span> <span>reference_1</span> <span>=</span> <span>"are you ready ?"</span><span>.</span><span>split</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>candidate</span> <span>=</span> <span>"you are ready ?"</span><span>.</span><span>split</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>bleu</span> <span>=</span> <span>nltk</span><span>.</span><span>translate</span><span>.</span><span>bleu_score</span><span>.</span><span>sentence_bleu</span><span>(</span><span>references</span><span>=</span><span>[</span><span>reference_1</span><span>],</span> <span>hypothesis</span><span>=</span><span>candidate</span><span>,</span> <span>weights</span><span>=</span><span>[</span><span>0.25</span><span>,</span><span>0.25</span><span>,</span><span>0.25</span><span>,</span><span>0.25</span><span>],</span> <span>smoothing_function</span><span>=</span><span>nltk</span><span>.</span><span>translate</span><span>.</span><span>bleu_score</span><span>.</span><span>SmoothingFunction</span><span>().</span><span>method7</span><span>)</span>
<span>&gt;&gt;&gt;</span> <span>print</span><span>(</span><span>bleu</span><span>)</span>
<span>0.4002926439114545</span>
</code></pre></div></div>

<p>This time, the value of <code>bleu</code> is 0.4, which is magically higher than the vanilla one we computed without using smoothing functions.</p>



<p>However, one should be always cautious about the smoothing function used in BLEU computation. At least we have to make sure that the BLEU scores we are comparing against are using no smoothing function or the exact same smoothing function.</p>

<h3 id="references">References</h3>

<ul>
  <li><a href="https://www.aclweb.org/anthology/P02-1040/">BLEU: a Method for Automatic Evaluation of Machine Translation</a></li>
  <li><a href="https://www.youtube.com/watch?v=DejHQYAGb7Q">BLEU - Andrew Ng</a></li>
</ul>

      <hr>
      
    </div></div>]]>
            </description>
            <link>https://leimao.github.io/blog/BLEU-Score/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23641791</guid>
            <pubDate>Thu, 25 Jun 2020 15:27:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WWDC20: What’s Changed in Accessibility on iOS]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23641787">thread link</a>) | @eshtocof
<br/>
June 25, 2020 | https://heartbeat.fritz.ai/wwdc20-whats-changed-in-accessibility-on-ios-33e0f144e075 | <a href="https://web.archive.org/web/*/https://heartbeat.fritz.ai/wwdc20-whats-changed-in-accessibility-on-ios-33e0f144e075">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><h2 id="b613">WWDC20</h2><h2 id="299f">Learn how accessibility has changed for the better in iOS 14</h2><div><div><div><p><a href="https://heartbeat.fritz.ai/@vhanagwal?source=post_page-----33e0f144e075----------------------" rel="noopener"><img alt="Vardhan Agrawal" src="https://miro.medium.com/fit/c/96/96/1*ORFRUf6O2Tk4XbG3kElncQ.jpeg" width="48" height="48"></a></p></div></div></div></div></div><div><figure><div><div><div><p><img src="https://miro.medium.com/max/60/1*9wSXSk7Fua06okhjIeQbtw.jpeg?q=20" width="2500" height="1031" role="presentation"></p><p><img src="https://miro.medium.com/max/5000/1*9wSXSk7Fua06okhjIeQbtw.jpeg" width="2500" height="1031" srcset="https://miro.medium.com/max/552/1*9wSXSk7Fua06okhjIeQbtw.jpeg 276w, https://miro.medium.com/max/1104/1*9wSXSk7Fua06okhjIeQbtw.jpeg 552w, https://miro.medium.com/max/1280/1*9wSXSk7Fua06okhjIeQbtw.jpeg 640w, https://miro.medium.com/max/1456/1*9wSXSk7Fua06okhjIeQbtw.jpeg 728w, https://miro.medium.com/max/1632/1*9wSXSk7Fua06okhjIeQbtw.jpeg 816w, https://miro.medium.com/max/1808/1*9wSXSk7Fua06okhjIeQbtw.jpeg 904w, https://miro.medium.com/max/1984/1*9wSXSk7Fua06okhjIeQbtw.jpeg 992w, https://miro.medium.com/max/2160/1*9wSXSk7Fua06okhjIeQbtw.jpeg 1080w, https://miro.medium.com/max/2700/1*9wSXSk7Fua06okhjIeQbtw.jpeg 1350w, https://miro.medium.com/max/3240/1*9wSXSk7Fua06okhjIeQbtw.jpeg 1620w, https://miro.medium.com/max/3780/1*9wSXSk7Fua06okhjIeQbtw.jpeg 1890w, https://miro.medium.com/max/4320/1*9wSXSk7Fua06okhjIeQbtw.jpeg 2160w, https://miro.medium.com/max/4800/1*9wSXSk7Fua06okhjIeQbtw.jpeg 2400w" sizes="100vw" role="presentation"></p></div></div></div></figure></div><div><div><p id="90e1">Apple has long integrated accessibility features into their software — and for good reason. By using accessibility features in your app, you’re allowing your app to reach a wider audience.</p><p id="d948">Sticking with their commitment to accessibility, Apple has introduced several new features at WWDC20 which help developers make their apps easier and more entertaining for users with disabilities. By making apps more accessible, developers eliminate the need for users to purchase clunky, expensive devices in order to use their apps — everything they need to interact with the app is built right into the device.</p><p id="df0d">In this article, you’ll learn about some of the biggest and best upgrades to accessibility, announced at this year’s WWDC.</p></div></div></section><hr><section><div><div><p id="ecb9">The first on the list is an interesting feature — which didn’t get talked about on stage. As the name suggests, Back Tap allows users to set single, double, or triple taps on the back of their iPhones and link them to certain tasks. For example, you could double tap on the back of your iPhone to open the weather app.</p><figure><div><div><div><div><p><img src="https://miro.medium.com/max/60/1*-mtu69eu445jv1BwH76CoQ.jpeg?q=20" width="1200" height="732" role="presentation"></p><p><img src="https://miro.medium.com/max/2400/1*-mtu69eu445jv1BwH76CoQ.jpeg" width="1200" height="732" srcset="https://miro.medium.com/max/552/1*-mtu69eu445jv1BwH76CoQ.jpeg 276w, https://miro.medium.com/max/1104/1*-mtu69eu445jv1BwH76CoQ.jpeg 552w, https://miro.medium.com/max/1280/1*-mtu69eu445jv1BwH76CoQ.jpeg 640w, https://miro.medium.com/max/1400/1*-mtu69eu445jv1BwH76CoQ.jpeg 700w" sizes="700px" role="presentation"></p></div></div></div></div><figcaption>Setting up Back Tap on iOS 14.</figcaption></figure><p id="91c1">And since the tapping feature can be linked to Shortcuts, it opens up a whole range of possibilities with home automation and more! As seen in the example above, you could triple tap the back of your phone to quickly take notes, or you could use it to unlock your door when you’re about to enter the house. Easy, right?</p><p id="563c">For users with hearing impairments, Apple has added the ability to adjust sound frequencies on supported headphones. By doing this, users can now set their own preferences on what they want to hear more of and what they want to hear less of.</p><p id="dc81">The new feature also comes with pre-set profiles for specific outdoor situations, in case the user doesn’t want to manually configure the sound frequencies.</p><blockquote><p id="dba7">This new accessibility feature is designed to amplify soft sounds and adjust certain frequencies for an individual’s hearing, to help music, movies, phone calls, and podcasts sound more crisp and clear. Headphone Accommodations also supports Transparency mode on AirPods Pro, making quiet voices more audible and tuning the sounds of your environment to your hearing needs.</p><p id="8aab">— Apple Documentation</p></blockquote><p id="6a9f">Further, the new feature also supports Transparency Mode on AirPods Pro, which allows users to adjust how much of the surroundings they want to hear. If they want to amplify soft voices or listen to the environment in more detail, they now have that autonomy.</p><p id="d5d2">In the same vein, a new feature called <strong>Sound Recognition</strong> can pick up important sounds in the environment, such as Sirens, Fire Alarms, or Car Horns and alert the user of them. Through machine learning models built into the operating system, these sounds can be picked up and transmitted to the user in any way that they wish.</p></div></div></section><hr><section></section><hr><section><div><div><figure><div><div><div><div><p><img src="https://miro.medium.com/max/38/1*3WhAhhK1A2LktugVV3KGHw.png?q=20" width="700" height="1110" role="presentation"></p><p><img src="https://miro.medium.com/max/1400/1*3WhAhhK1A2LktugVV3KGHw.png" width="700" height="1110" srcset="https://miro.medium.com/max/552/1*3WhAhhK1A2LktugVV3KGHw.png 276w, https://miro.medium.com/max/1000/1*3WhAhhK1A2LktugVV3KGHw.png 500w" sizes="500px" role="presentation"></p></div></div></div></div><figcaption>Real-Time Text on the iPhone.</figcaption></figure><p id="2bf5">Group FaceTime calls have become more important than ever during the global pandemic, and Apple has added a small but important accessibility feature to them. Now, if a member of a group FaceTime call is using sign language to communicate, their video will be automatically pinned.</p><p id="ab6c">Using computer vision to detect this can be a boon to those with hearing loss, since reading sign language while the screen is moving around can be frustrating.</p><p id="43b4">In addition to this, Apple has made further improvements to its Real-Time Text feature, which is used for text based communication during phone calls. Previously, it was difficult for RTT users to multitask during phone calls, but it no longer requires the full screen.</p><p id="0458">When we think of accessibility on iOS, VoiceOver is often the first to come to mind. This year, VoiceOver received several significant updates, making it even more useful than before. If you aren’t familiar with it, VoiceOver is Apple’s screen reader, available on all platforms, including iOS, macOS, tvOS, and watchOS.</p><h2 id="ae54">VoiceOver Recognition</h2><p id="aa80">In the past, VoiceOver would require developers to adopt it inside their apps to work well on third-party apps.</p><blockquote><p id="210b">On-device intelligence recognizes key elements displayed on your screen to add VoiceOver support for app and web experiences that don’t have accessibility support built in. — Apple</p></blockquote><p id="2717">This year, Apple is tapping into their machine learning technology to semantically detect where and how to use VoiceOver on unsupported apps. This makes virtually all apps natively supported by VoiceOver and increases their accessibility for those with visual impairments.</p><h2 id="6119">Image Descriptions</h2><p id="6f0d">To make VoiceOver even more useful, Apple has used its computer vision library with <em>even more</em> machine learning to detect the contents of an image.</p><blockquote><p id="2f5f">VoiceOver reads complete-sentence descriptions of images and photos within apps and on the web. VoiceOver speaks the text it identifies within images and photos. — Apple</p></blockquote><p id="f5ed">Instead of simply stating that an image is present, VoiceOver can now provide detailed descriptions of what’s pictured in an image for more useful information to VoiceOver users. It can also detect text in an image through optical character recognition — another great way that machine learning is being used in the iOS 14 update!</p></div></div></section><hr><section><div><div><p id="d6f7">Evidently, there have been plenty of great updates at WWDC20 in accessibility, with even more that weren’t listed here. By releasing a large number of small features, Apple has made their devices more accessible than ever. And, they’ve supercharged many of their flagship accessibility solutions by coupling machine learning technology with them.</p><p id="ab7f">Be sure to <strong>smash that “clap” button</strong> as many times as you can, <strong>share this tutorial</strong> on social media, and <strong>follow me on Twitter.</strong></p></div></div></section><hr><section><div><div><p id="08a6"><em>Editor’s Note:</em><a href="http://heartbeat.fritz.ai/" target="_blank" rel="noopener"><em> </em><strong><em>Heartbeat</em></strong></a><strong><em> </em></strong><em>is a contributor-driven online publication and community dedicated to exploring the emerging intersection of mobile app development and machine learning. We’re committed to supporting and inspiring developers and engineers from all walks of life.</em></p><p id="7676"><em>Editorially independent, Heartbeat is sponsored and published by</em><a href="http://fritz.ai/" target="_blank" rel="noopener"><em> </em><strong><em>Fritz AI</em></strong></a><em>, the machine learning platform that helps developers teach devices to see, hear, sense, and think. We pay our contributors, and we don’t sell ads.</em></p><p id="7977"><em>If you’d like to contribute, head on over to our</em><a target="_blank" rel="noopener" href="https://heartbeat.fritz.ai/call-for-contributors-october-2018-update-fee7f5b80f3e"><em> </em><strong><em>call for contributors</em></strong></a><em>. You can also sign up to receive our weekly newsletters (</em><a href="https://www.deeplearningweekly.com/" target="_blank" rel="noopener"><strong><em>Deep Learning Weekly</em></strong></a><em> and the </em><a href="https://www.fritz.ai/newsletter/?utm_campaign=fritzai-newsletter&amp;utm_source=heartbeat-statement" target="_blank" rel="noopener"><strong><em>Fritz AI Newsletter</em></strong></a><em>), join us on</em><a href="https://join.slack.com/t/fritz-ai-community/shared_invite/enQtNTY5NDM2MTQwMTgwLWU4ZDEwNTAxYWE2YjIxZDllMTcxMWE4MGFhNDk5Y2QwNTcxYzEyNWZmZWEwMzE4NTFkOWY2NTM0OGQwYjM5Y2U" target="_blank" rel="noopener"><em> </em></a><a href="http://fritz.ai/slack" target="_blank" rel="noopener"><strong><em>Slack</em></strong></a><em>, and follow Fritz AI on</em><a href="https://twitter.com/fritzlabs" target="_blank" rel="noopener"><em> </em><strong><em>Twitter</em></strong></a><em> for all the latest in mobile machine learning.</em></p></div></div></section></div></div>]]>
            </description>
            <link>https://heartbeat.fritz.ai/wwdc20-whats-changed-in-accessibility-on-ios-33e0f144e075</link>
            <guid isPermaLink="false">hacker-news-small-sites-23641787</guid>
            <pubDate>Thu, 25 Jun 2020 15:26:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Permacomputing]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 18 (<a href="https://news.ycombinator.com/item?id=23641719">thread link</a>) | @ibobev
<br/>
June 25, 2020 | http://viznut.fi/texts-en/permacomputing.html | <a href="https://web.archive.org/web/*/http://viznut.fi/texts-en/permacomputing.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">



<p>This is a collection of random thoughts regarding the application of
permacultural ideas to the computer world.</p>

<p>Some have tried to connect these worlds before (<a href="http://wiki.c2.com/?PermaCulture">WikiWikiWeb's Permaculture
article</a>; <a href="https://en.wikipedia.org/wiki/Kent_Beck">Kent
Beck</a>'s short-lived idea of <a href="https://www.softwarequotes.com/showquotes.aspx?id=559&amp;name=Kent%20Beck">Permaprogramming</a>),
but these have mostly concentrated on enhancing software engineering
practices with some ideas from gardening. I am more interested in the aspect
of cultural and ecological permanence. That is, how to give computers a
meaningful and sustainable place in a human civilization that has a
meaningful and sustainable place in the planetary biosphere.</p>

<h2>1. Problem</h2>

<p>Over the last few hundred years of human civilization, there has been a
dramatic increase in the consumption of artificially produced energy. In the
overarching story, this is often equated with "progress".</p>

<p>In the computer world, this phenomenon gets multiplied by itself:
"progress" facilitates ever greater densities of data storage and digital
logic, thus dramatically exploding the availability of computing resources.
However, the abundance has also caused an equivalent explosion in
wastefulness, which shows in things like mindblowingly ridiculous hardware
requirements for even quite trivial tasks.</p>

<p>At the same time, computers have been failing their <a href="https://en.wikipedia.org/wiki/Computer_Lib/Dream_Machines">utopian
expectations</a>. Instead of amplifying the users' intelligence, they rather
amplify their stupidity. Instead of making it possible to scale down the
resource requirements of the material world, they have instead become a
major part of the problem. Instead of making the world more comprehensible,
they rather add to its incomprehensibility. And they often even manage to
become slower despite becoming faster.</p>

<p>In both computing and agriculture, a major issue is that problems are too
often "solved" by increasing controllability and resource use. Permaculture
takes another way, advocating methods that "let nature do the work" and thus
minimize the dependence on artificial energy input. Localness and
decentralization are also major themes in the thought.</p>

<p>What makes permacultural philosophy particularly appealing (to me) is
that it does not advocate "going back in time" despite advocating a dramatic
decrease in use of artificial energy. Instead, it trusts in human ingenunity
in finding clever hacks for turning problems into solutions, competition
into co-operation, waste into resources. Very much the same kind of creative
thinking I appreciate in computer hacking.</p>

<p>The presence of intelligent life in an ecosystem can be justified by its
strengthening effect. Ideally, humans could make ecosystems more flexible
and more resilient because of their ability to take leaps that are difficult
or impossible for "unintelligent" natural processes. The existence of
computers in a human civilization can be justified by their ability to
augment this potential.</p>

<h2>2. Physical resources</h2>

<h3>2.1. Energy</h3>

<p>Permaculture emphasizes resource-sensitivity. Computers primarily use
electricity, so to them resource-sensitivity primarily means 1) adapting to
changes in energy conditions and 2) using the available energy wisely.
Today's computers, even mobile ones, are surprisingly bad at this. This is
partially due to their legacy as "calculation factories" that are constantly
guaranteed all the resources they "need".</p>

<p>Intense non-urgent computation (such as long machine learning batches)
would take place only when a lot of surplus energy is being produced or
there is a need for electricity-to-heat conversion. This requires that the
computer is aware of the state of the surrounding energy system.</p>

<p>At times of low energy, both hardware and software would prefer to scale
down: background processes would freeze, user interfaces would become more
rudimentary, clock frequencies would decrease, unneeded processors and
memory banks would power off. At these times, people would prefer to do
something else than interact with computers.</p>

<p>It is often wise to store energy for later use. <a href="https://en.wikipedia.org/wiki/Flywheel_energy_storage">Flywheels</a>
are a potential alternative to chemical batteries. They have similar <a href="https://en.wikipedia.org/wiki/Energy_density">energy densities</a>
(MJ/kg) but require no rare-earth materials and last for decades or
centuries instead of mere years.</p>

<h3>2.2. Silicon</h3>

<p>IC fabrication requires large amounts of energy, highly refined machinery
and poisonous substances. Because of this sacrifice, the resulting
microchips should be treasured like gems or rare exotic spices. Their active
lifespans would be maximized, and they would never be reduced to their raw
materials until they are thoroughly unusable.</p>

<p>Instead of planned obsolescence, there should be planned longevity.</p>

<p>Broken devices would be repaired. If the community needs a kind of device
that does not exist, it should preferrably be built from existing components
that have fallen out of use. Chips should be designed open and flexible, so
that they can be reappropriated even for purposes they were never intended
for.</p>

<p>Complex chips should have enough redundancy and bypass mechanisms to keep
them working even after some of their internals wear out. (In a multicore
CPU, for instance, many partially functioning cores could combine into one
fully functioning one.)</p>

<p>Chips that work but whose practical use cannot be justified can find
artistic and other psychologically meaningful use. They may also be stored
away until they are needed again (especially if the fabrication quality and
the storage conditions allow for decades or centuries of "shelf life").</p>

<p>Use what is available. Even chips that do "evil" things are worth
considering if there's a landfill full of them. Crack their DRM locks,
reverse-engineer their black boxes, deconstruct their philosophies. It might
even be possible to reappropriate something like Bitcoin-mining ASICs for
something artistically interesting or even useful.</p>

<p>Minimized on-chip feature size makes it possible to do more computation
with less energy but it often also means increased fragility and shorter
lifespans. Therefore, the densest chips should be primarily used for
purposes where more computation actually yields more. (In entertainment use,
for example, a large use of resources is nothing more than a decadent
esthetic preference.)</p>

<p><a href="https://en.wikipedia.org/wiki/Unconventional_computing">Alternatives
to semiconductors</a> should be actively researched. <a href="https://www.researchgate.net/publication/328395242_Towards_fungal_computer">Living
cells</a> might be able to replace microchips in some tasks sometime in the
future.</p>

<p>Once perfectly clean ways of producing microchip equivalents have been
taken to use, the need for "junk fetishism" will probably diminish.</p>

<h3>2.3. Miscellaneous</h3>

<p>Whenever bright external light is available, displays should be able to
use it instead of competing against it with their own backlight. (See: <a href="https://en.wikipedia.org/wiki/Transflective_liquid-crystal_display">Transflective
LCD</a>)</p>

<p>Personally-owned computers are primarily for those who dedicate
themselves to the technology and thus spend considerable amounts of time
with it. Most other people would be perfectly happy with shared hardware.
Even if the culture and society embraced computers more than anything else,
requiring everyone to own one would be an overkill.</p>

<h2>3. Observation and interaction</h2>

<p>The first item in many lists of permacultural principles is "Observe and
interact." I interpret this as primarily referring to a bidirectional and
co-operative relationship with natural systems: you should not expect your
garden to be easily top-down controllable like an army unit but accept its
quirkiness and adapt to it.</p><h3>3.1. Observation</h3>

<p>Observation is among the most important human skills computers can augment.
Things that are difficult or impossible for humans to observe can be brought
within human cognitive capacity by various computational processes. Gathered
information can be visualized, slight changes and pattern deviances
emphasized, slow processes sped up, forecasts calculated. In Bill Mollison's
words, "Information is <em>the</em> critical potential resource. It becomes
a resource only when obtained and acted upon."</p>

<p>Computer systems should also make their own inner workings as observable as
possible. If the computer produces visual output, it would use a fraction of
its resources to visualize its own intro- and extrospection. A computer that
communicates with radio waves, for example, would visualize its own view of
the surrounding radio landscape.</p>

<p>Current consumer-oriented computing systems often go to ridiculous
lengths to actually prevent the user from knowing what is going on. Even
error messages have become unfashionable; many websites and apps just
pretend everything is fine even if it isn't. This kind of extreme
unobservability is a major source of technological alienation among computer
users.</p>

<p>The visualizations intended for casual and passive observation would be
pleasant and tranquil while making it easy to see the big picture and notice
the small changes. Tapping into the inborn human tendency to observe the
natural environment may be a good idea when designing visualizers. When the
user wants to observe something more closely, however, there is no limit in
how flashy, technical and "non-natural" the presentation can be, as long as
the observer prefers it that way.</p>

<h3>3.2. Yin and yang hacking</h3>

<p>Traditional computer hacking is often very "yang". A total understanding and
control of the target system is valued. Changing a system's behavior is
often an end in itself. There are predefined goals the system is pushed
towards. Optimization tends to focus on a single measurable parameter.
Finding a system's absolute limits is more important than finding its
individual strengths or essence.</p>

<p>In contrast, "yin" hacking accepts the aspects that are beyond rational
control and comprehension. Rationality gets supported by intuition. The
relationship with the system is more bidirectional, emphasizing
experimentation and observation. The "personality" that stems from
system-specific peculiarities gets more attention than the measurable specs.
It is also increasingly important to understand when to hack and when just
to observe without hacking.</p>

<p>The difference between yin and yang hacking is similar to the difference
between permaculture and …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://viznut.fi/texts-en/permacomputing.html">http://viznut.fi/texts-en/permacomputing.html</a></em></p>]]>
            </description>
            <link>http://viznut.fi/texts-en/permacomputing.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23641719</guid>
            <pubDate>Thu, 25 Jun 2020 15:20:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple is systematically erasing our stories]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23641646">thread link</a>) | @egocentric
<br/>
June 25, 2020 | https://www.flicktype.com/ResolutionKit/ | <a href="https://web.archive.org/web/*/https://www.flicktype.com/ResolutionKit/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<div>
<h2>ResolutionKit</h2>
<p>
A framework for change.
</p>
<blockquote><p lang="en" dir="ltr">For the longest time, I've been afraid to speak up about my story with App Review, fearing I'd put my popular app at risk. I've now decided that being transparent and sharing my experience to help others is worth it, so here it goes:👇</p>— Kosta Eleftheriou (@keleftheriou) <a href="https://twitter.com/keleftheriou/status/1274356729224892416?ref_src=twsrc%5Etfw">June 20, 2020</a></blockquote> 

<p>
I admire Apple, and I believe the world is a better place because of them. As a developer, I’ve made my career on their platform and I’m grateful for it.
But I have some criticism. I’m&nbsp;<b>not</b>&nbsp;here to talk about my story, the 30% Apple developer cut, the App Review process, or to challenge any of their guidelines.
I want to talk about&nbsp;<em>transparency</em>, and <em>accountability</em>.
</p>
<p>
For far too long, developers have been discouraged from being able to share their rejection stories with the world.
"If you run to the press and trash us, it never helps", used to be the official guidance.
The risk too great for most, the fear of retribution overwhelming.
And so the stories have largely remained in the shadows, with only a few exceptions.
But there’s another, critical reason why such stories rarely see the light of day, one that hasn’t received enough attention:
</p>
<blockquote><b>Apple is systematically erasing our stories.</b></blockquote>

<p>
Unless we’re talking about your most recent submission, all communication you have <em>ever</em> sent or received through the "Resolution Center" is inaccessible to you.
Rejection notices, appeal results, anything you might want to reference to better understand previous about your product - it's all gone.
Unless you have meticulously and manually kept copies of all correspondence, what happened in the past will forever stay in the past. But why should it?
</p>
<p>
It’s not hard to see why Apple is doing this.
It <em>is</em> hard, however, to see a reason that benefits anyone but Apple.
In doing so, they gain more peace of mind, less worry about consistency and correctness in applying the public guidelines.
The appeal mechanism helps them improve, but only to the extent that Apple deems necessary.
If we ever wanted to know how well Apple is enforcing the guidelines, we have to take their word for it.
But who guards the guardians, when App Review’s accountability to the world has been intentionally reduced to the bare minimum?
</p>
<p>
Transparency is not always the solution.
We can’t expect Apple to be open about their future product plans, for example.
But when they communicate with developers, they should do so like everyone is watching - every time.
And to get there, the <em>possibility</em> that everyone might find out needs to always be on the table.
</p>
<p>
So Apple, please help us see App Review as a reliable ally.
Let us access our past communications with you - including phone call records if we choose to.
Show us that you want to be accountable for what you communicate to developers. There may be some legal challenges, but transparency is a prerequisite to accountability.
It’s only then that we can begin to have a fair and honest discussion with you about the actual process and guidelines.
Because until then, we’re in the shadows.
</p>
<p>
<a href="https://www.change.org/p/apple-let-us-browse-all-our-past-resolution-center-communications">Sign the petition</a>
</p>
<p>
⌚️<i>Thursday, 25 June 2020</i>
</p>
</div>
</div>
<div>
<h2>Are you a developer?</h2>
<p>
<a href="https://twitter.com/keleftheriou">Reach out</a> and share your story with <a href="mailto:kostas.eleftheriou@gmail.com">me</a>.
</p>
<h2>✌️</h2>
</div>
</div></div>]]>
            </description>
            <link>https://www.flicktype.com/ResolutionKit/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23641646</guid>
            <pubDate>Thu, 25 Jun 2020 15:13:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gloo API Gateway v1.4 – Kubernetes Ingress, Istio 1.6, MOAR Helm Values and]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23641631">thread link</a>) | @cloudytoday
<br/>
June 25, 2020 | https://www.solo.io/blog/introducing-gloo-1-4-enhanced-scalability-kubernetes-ingress-and-istio-1-6-support-and-dev-to-ops-experience/ | <a href="https://web.archive.org/web/*/https://www.solo.io/blog/introducing-gloo-1-4-enhanced-scalability-kubernetes-ingress-and-istio-1-6-support-and-dev-to-ops-experience/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><img src="https://www.solo.io/wp-content/uploads/2020/06/Hero_gloo-1.4-1024x230.png" data-src="https://www.solo.io/wp-content/uploads/2020/06/Hero_gloo-1.4-1024x230.png" alt="" width="1024" height="230" data-srcset="https://www.solo.io/wp-content/uploads/2020/06/Hero_gloo-1.4-1024x230.png 1024w, https://www.solo.io/wp-content/uploads/2020/06/Hero_gloo-1.4-300x67.png 300w, https://www.solo.io/wp-content/uploads/2020/06/Hero_gloo-1.4-768x172.png 768w, https://www.solo.io/wp-content/uploads/2020/06/Hero_gloo-1.4.png 1320w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://www.solo.io/wp-content/uploads/2020/06/Hero_gloo-1.4-1024x230.png 1024w, https://www.solo.io/wp-content/uploads/2020/06/Hero_gloo-1.4-300x67.png 300w, https://www.solo.io/wp-content/uploads/2020/06/Hero_gloo-1.4-768x172.png 768w, https://www.solo.io/wp-content/uploads/2020/06/Hero_gloo-1.4.png 1320w"></p><p><span>Today we released version 1.4 of </span><a href="https://www.solo.io/products/gloo/"><span>Gloo, our Envoy Proxy based API Gateway</span></a><span>. In the past few months since our </span><a href="https://www.solo.io/blog/announcing-gloo-1-3-developer-portal-extensibility-performance-and-usability/"><span>1.3 release</span></a><span>, we have been working with our end users and customers to deliver new functionality and enhance existing features to address a wider range of use cases. This release includes an update to both the open source and enterprise versions of Gloo.</span></p><p><b>Highlights of the release include:</b></p><ul><li><span>Improvements to system scalability</span></li><li><span>Expanded support for Kubernetes Ingress&nbsp;</span></li><li><span>Support for the latest Istio 1.6 release</span></li><li>Security enhancements</li><li><span>User experience enhancements for Dev and Ops</span></li><li><span>Plus more options for configuring Gloo&nbsp;</span></li></ul><p><span>Join us for a webinar on </span><b>July 16th</b><span> to learn more about this latest release, get a deep dive into the features and demos – </span><a href="https://solo.zoom.us/webinar/register/WN_1w-yxlabQD6L9GkzP01eww"><span>Register today to save your seat.</span></a><span> Meanwhile, keep reading to get an overview of the new release.</span></p><h2><span>Improvements to System Scalability&nbsp;</span></h2><p><span>In this release we’ve made updates to improve the scalability of Gloo including managing multiple data planes with the </span><a href="https://github.com/solo-io/gloo/issues/2257"><span>ability set granular per gateway level external authentication and rate limiting policies</span></a><span> along with improved status reporting between the multiple instances, and the </span><span>ability to use </span><a href="https://github.com/solo-io/gloo/issues/3047"><span>multiple instances of Gloo to partition Ingress objects</span></a><span> within a single cluster.</span></p><h2><span>Expanded Support for the Kubernetes Ingress&nbsp;</span></h2><p><span>In addition to API Gateway, Gloo can be deployed as a Kubernetes Ingress Controller and in this release we’ve added configuration options including</span> <a href="https://github.com/solo-io/gloo/issues/3050"><span>support for named ports on Kubernetes Ingress </span></a><span>objects, ability to use </span><a href="https://github.com/solo-io/gloo/issues/3047"><span>multiple Gloo controllers to partition Ingress objects</span></a><span> within a single cluster using the customIngressClass variable to the Gloo Helm Chart, and a </span><a href="https://github.com/solo-io/gloo/issues/3051"><span>fix to keep the&nbsp; Ingress Controller</span></a><span> (ingress pod) processing Ingress updates even when a Ingress backend is incorrectly referencing a service port.&nbsp;</span></p><h2><span>Support for Istio 1.6&nbsp;</span></h2><p><span>Gloo seamlessly integrates with service mesh environments and provides mTLS between the ingress traffic to the rest of the cluster. In this release, Gloo has been tested and validated to work with the latest </span><a href="https://istio.io/latest/"><span>Istio 1.6</span></a><span> release. Additionally, </span><a href="https://github.com/solo-io/gloo/issues/2703"><span>Gloo now supports ALPN on the upstream</span></a><span> for more granular control on defining which protocol to use and helps with the integration to the latest version of Istio. Try the Gloo and Istio integration tutorial </span><a href="https://docs.solo.io/gloo/latest/guides/integrations/service_mesh/gloo_istio_mtls/"><span>here</span></a><span>.&nbsp;</span></p><h2><span>Security Enhancements&nbsp;</span></h2><p><span>In this release we expanded security capabilities to protect the Gloo system and applications in the environment including </span><a href="https://github.com/solo-io/gloo/issues/2929"><span>supporting TLS in the external auth service</span></a><span>&nbsp; instead of through an envoy sidecar to handle the TLS termination, the addition of </span><a href="https://github.com/solo-io/gloo/issues/1525"><span>audit logs for the Modsecurity Web Application Filter</span></a><span> (WAF) as part of the access logs to assist debugging and auditing purposes, encrypted communication is now possible with </span><a href="https://github.com/solo-io/gloo/issues/2134"><span>mTLS between Gloo and Envoy instances</span></a><span> for when these components are deployed to separate environments, and an </span><a href="https://github.com/solo-io/gloo/issues/3084"><span>update to the Gloo permissions</span></a><span> reduces the surface area for risk by enabling it to run in a fully restricted Kubernetes environment.&nbsp;</span></p><h2><span>User Experience Improvements for Developers and Operations</span></h2><p><span>Across the CLI and Admin UI we’ve made a number of improvements to expand the functionality of glooctl, expand observability capabilities and error handling to resolve system issues.&nbsp;</span></p><ul><li><b>glooctl</b><b> updates include</b><span> extending the timeout period for port forwarding from 3 to 30 seconds before a</span> <a href="https://github.com/solo-io/gloo/issues/2771"><span>connection refused errors is displayed</span></a><span> improves how commands like </span><span>glooctl check</span><span> or </span><span>glooctl proxy dump</span> <span>work in high latency environments with more time to finish, the </span><a href="https://github.com/solo-io/gloo/issues/2715"><span>glooctl add route</span></a><span> command no longer creates a route table or virtual service with the</span><span> –dry-run </span><span>flag, and </span><a href="https://github.com/solo-io/gloo/issues/2581"><span>glooctl check</span><span> now uses the default namespace</span></a><span> if a specific namespace flag is not provided.</span></li><li><span>The Admin UI has</span> <a href="https://github.com/solo-io/gloo/issues/2812"><span>new tags in the Granfana dashboards</span></a><span> for Envoy and Kubernetes and supports </span><a href="https://github.com/solo-io/gloo/issues/2804"><span>additional observailiby use case</span></a><span>s with gRPC access logging service metrics.</span></li></ul><ul><li><span>Better error handling by </span><a href="https://github.com/solo-io/gloo/issues/2905"><span>logging a clear message</span></a><span> when the upstream port does not match the underlying Kubernetes service, </span><a href="https://github.com/solo-io/gloo/issues/2660"><span>report a status</span></a><span> when an upstream points to a non-existent service, and an </span><a href="https://github.com/solo-io/gloo/issues/2880"><span>update to the error message display to only show the issue </span></a><span>vs. the entire message.</span></li></ul><h2><span>Expanded Configuration Options for Gloo&nbsp;</span></h2><p><span>As a flexible control plane to Envoy Proxy, Gloo is built to support a wide range of deployment scenarios and use cases. In this release we’ve added a number of new options for the admins to customize the behavior of the Gloo environment and traffic handling.</span></p><ul><li><b>New Buffer Filter Improves Request Handling:</b> <span>Gloo now supports enabling the </span><a href="https://www.envoyproxy.io/docs/envoy/latest/api-v3/extensions/filters/http/buffer/v3/buffer.proto#extensions-filters-http-buffer-v3-buffer"><span>Envoy buffer filter</span></a><span> which buffers the entire request before routing it to the service to process the request. This is important because it helps the system understand how big the request is (in case the request size is too big), which avoids having to deal with partial requests and high network latency. </span><a href="https://github.com/solo-io/gloo/issues/2444"><span>The buffer filter can be set </span></a><span>by configuring </span><span>spec.httpGateway.options.buffer </span><span>of the desired gateway and can optionally </span><a href="https://github.com/solo-io/gloo/issues/2835"><span>configure the bytes limit on the upstream connection</span></a><span> (default is 1MiB).&nbsp;</span></li><li><b>Update to validation webhook: </b><span>Now </span><a href="https://github.com/solo-io/gloo/issues/2114"><span>validates inja compilation syntax</span></a><span> before accepting/rejecting virtual services that use transformations, allowing users to properly validate whether configurations are valid against live clusters before applying them&nbsp;</span></li><li><b>SSL Configuration Update: </b><span>Now allows for </span><span>specifying </span><a href="https://github.com/solo-io/gloo/issues/2871"><span>empty SSL configurations for clients</span></a><span> depending on the use case.</span></li><li><b>Helm Chart Updates Expand Available Settings: </b><span>They include two enhancements for Knative including the ability to </span><a href="https://github.com/solo-io/gloo/issues/2778"><span>assign a static IP to the Knative external proxy</span></a><span> and to </span><a href="https://github.com/solo-io/gloo/pull/2683"><span>override the Service type</span></a><span> as an alternative to Load Balancer for Ingress Proxy and Knative. Additionally, the nodeport numbers for the gateway proxy service can now&nbsp; </span><a href="https://github.com/solo-io/gloo/issues/2899"><span>be predefined in the values.yml</span></a><span>. We also added a </span><a href="https://github.com/solo-io/gloo/issues/3016"><span>new value to disable the validation admission webhook</span></a><span> for users who cannot use webhooks but still want to use the Gloo validation API, this value makes it more straightforward to implement.&nbsp;</span></li><li><b>Improved heading formatting:</b><span> The Envoy </span><span>core.Http1ProtocolOptions.HeaderKeyFormat</span><span> is available in the Gloo API as </span><span>httpConnectionManager.http_protocol_options.proper_case_header_key_format</span><span> which</span> <a href="https://github.com/solo-io/gloo/issues/2940"><span>formats the header by proper casing</span></a> <span>which helps with validating the headers.</span></li></ul><ul><li><b>Upstream reference by name: </b><span>This allows virtual services, route tables, and upstreams to </span><a href="https://github.com/solo-io/gloo/issues/2730"><span>refer to an upstream by name only</span></a><span>, </span><span>without causing an error. Gloo will assume the upstream namespace is the namespace of the parent resource.&nbsp;</span></li></ul><p><span>Give the latest Gloo release a try and we’d love to get your feedback in the </span><a href="https://solo-io.slack.com/"><span>community slack</span></a><span> or </span><a href="https://github.com/solo-io/gloo"><span>file an issue/PR on Github</span></a><span>. If you’re already using Gloo, get the upgrade instructions </span><a href="https://docs.solo.io/gloo/latest/operations/upgrading/1.3.0/"><span>here</span></a><span> and </span><a href="https://solo.zoom.us/webinar/register/4415867127300/WN_neq5G0eAToSGoDXUNZMMzQ"><span>register for the upcoming webinar</span></a><span> to learn more.&nbsp; </span></p></div></div></div>]]>
            </description>
            <link>https://www.solo.io/blog/introducing-gloo-1-4-enhanced-scalability-kubernetes-ingress-and-istio-1-6-support-and-dev-to-ops-experience/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23641631</guid>
            <pubDate>Thu, 25 Jun 2020 15:11:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How coding.blog JAMStack blogs became effortlessly fast]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23641457">thread link</a>) | @lorean_victor
<br/>
June 25, 2020 | https://coding.blog/blog/jamstack | <a href="https://web.archive.org/web/*/https://coding.blog/blog/jamstack">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="-codedoc-container"><div><p><img src="https://coding.blog/img/under-the-hood-dark.svg" alt="Banner"></p><p><img src="https://coding.blog/img/under-the-hood.svg" alt="Banner"></p></div><p>Basics of providing content over the internet are fairly straight-forward: Browsers will send requests to your
server, and your server responds with some HTML potentially linked to some JS and CSS.</p><marker><br>

</marker><p>How and when you generate those HTML, CSS and JS content is however an entirely different thing. You might want
to prepare them all in advance and have your server just serve them (pre-rendering), 
you might have your server generate them on the fly (SSR), 
or you might have your server ship some code to the browser that will then generate them (client-side rendering, SPAs). 
You might even generate requested content on the server and ship it with the code that 
would generate subsequently requested content on the browser (isomorphic).</p><marker><br>

</marker><p>There is one particular approach pretty suitable for blogs: you prepare most of the content before hand, then
serve it alongside code that would wire-in interactive bits and generate fully dynamic components. This is called
the <a href="https://jamstack.org/">JAMStack</a>, and it is the approach used by <a href="https://coding.blog/"><code>coding.blog</code></a> and
<a href="https://codedoc.cc/"><strong>CODEDOC</strong></a> for content generation. In this post, we go through the reasons we chose this
approach, and how we implemented it.</p><hr><p>To better understand why we chose <em>JAMStack</em> for <code>coding.blog</code> and how we set our further design goals, its good
to first have a general overview of methods of web content generation/delivery:</p><marker><br>

</marker><p>Pre-Rendering</p><p>Pre-rendering simply means preparing your content before-hand, i.e. in the <em>build stage</em>. This is the fastest
delivery method, and allows you to simply use a CDN instead of writing a server for serving your content.</p><div><p><img src="https://coding.blog/img/blogs/pre-rendering-dark.svg" alt="Pre-Rendering"></p><p><img src="https://coding.blog/img/blogs/pre-rendering.svg" alt="Pre-Rendering"></p></div><p>Server Side Rendering (SSR)</p><p>Instead of preparing the content, you can generate them on-the fly on your server, in response to each request.
This is perhaps useful when your content needs to change based on incoming requests, and perhaps you need to
get some data from some API to be able to create the content. However, this approach is obviously much slower
than pre-rendering.</p><div><p><img src="https://coding.blog/img/blogs/ssr-dark.svg" alt="SSR"></p><p><img src="https://coding.blog/img/blogs/ssr.svg" alt="SSR"></p></div><p>Client-Side Rendering and SPAs</p><p>Highly interactive and dynamic content means you need to generate content on the client-side. To avoid having
content-generation code in multiple places (which is hard to maintain / scale), you could instead conduct all
content generation on the client browser, having your server just ship the content generation code.</p><p>To avoid shipping the content generation code for each page of your site, you can also take control of the 
navigation on the client side, which leads to a <em>Single Page Application</em> (SPA for short). This is the basis
of all modern front-end frameworks.</p><div><p><img src="https://coding.blog/img/blogs/csr-dark.svg" alt="CSR &amp; SPA"></p><p><img src="https://coding.blog/img/blogs/csr.svg" alt="CSR &amp; SPA"></p></div><p>Client-side rendering means the user should wait extra time for being able to see the content, since typically
servers are faster at generating content. It also messes up with SEO, since crawlers might not be able to even
get the content in its full form (since they are not browsers) and so might not be able to properly index it.</p><marker><br>

</marker><p>Isomorphic Apps</p><p>To overcome these issues without spreading the content generation code in multiple places, the concept of <em>isomorphic apps</em>
was introduced. The idea is to basically run the same code both on the server and on the client, while also shipping
the code itself to the client alongside content rendered on the server.</p><div><p><img src="https://coding.blog/img/blogs/isomorphic-dark.svg" alt="Isomorphic Apps"></p><p><img src="https://coding.blog/img/blogs/isomorphic.svg" alt="Isomorphic Apps"></p></div><p>The complexity of isomorphic apps inevitably brings extra constraints and overheads. For example, you need to re-hydrate
the content on client-side, which means you are limited on how you manipulate that content (e.g. for React SSR, React needs
to maintain full control of the DOM tree). These complexities also make it harder to optimize performance since many more
components and their interactions are affecting it.</p><marker><br>

</marker><p>JAMStack Apps</p><p>Another approach would be to pre-render all your static content and then ship the code for filling in dynamic/interactive
parts to the client. This would allow for the same delivery speed of pre-rendering without sacrificing interactivity
of the content. It also implies a clear separation in the code-base as opposed to isomorphic apps: there is code that
pre-renders stuff, and there is code that goes to client and makes stuff interactive.</p><div><p><img src="https://coding.blog/img/blogs/jamstack-dark.svg" alt="JAMStack"></p><p><img src="https://coding.blog/img/blogs/jamstack.svg" alt="JAMStack"></p></div><p>The JAMStack architecture is specifically suitable for mostly static content, which makes it a perfect choice
for likes of <strong>CODEDOC</strong> (which is for documentation / guides about codes) and <code>coding.blog</code> (which is for blogs about
coding / programming). The simplicity of the workflow allows for easy optimization and high degrees of interoperability
and extensibility.</p><hr><p>While the JAMStack architecture was the most suitable for <a href="https://codedoc.cc/"><strong>CODEDOC</strong></a> and <a href="https://coding.blog/"><code>coding.blog</code></a>,
it mandates a split of content generation code into bits that are executed at build stage and bits that are
shipped to the client. This can quickly add a lot of complexity/overhead for any growing project, so we had to
find a solution that addressed this particular issue.</p><p>In other words, we needed to:</p><ul><li>have a shared component system</li><li>easily mark client-side components so that they are not pre-rendered</li><li>seamlessly where these components were to be rendered in the DOM tree</li><li>conveniently and efficiently collect and bundle the code of these clients</li><li>conveniently attach these bundles to pre-rendered content</li></ul><marker><br>

</marker><p>Additionally, we wanted a minimal toolchain and stack with maximum extensibility and interoperability. Generally
we wanted knowledge of HTML/JS/CSS to suffice for serious customization, which made a <a href="https://reactjs.org/docs/introducing-jsx.html">JSX</a>-based 
syntax an optimal choice for our component system (specifically as Typescript supports it out of the box).</p><p>However, we couldn't use a library like React (or any VirtualDOM based solution) since its sensitivity to external changes to 
the DOM tree meant limitations on how the DOM is manipulated by extensions, either during pre-rendering or on the client.
Besides, we needed our content to be as light-weight as possible, which simply prohibited relatively heavy-weight
operations such as VirtualDOM diffing.</p><hr><p>To satisfy our design goals, we created a JSX-based rendering tool which directly sits on top of DOM APIs.
This is called <a href="https://github.com/CONNECT-platform/connective-html">CONNECTIVE HTML</a>, and on a basic level
is merely a wrapper of DOM APIs that allows using them via JSX:</p><pre><code tabindex="0"><span><span></span><span></span><span></span><span></span></span><p><span>1</span><span>import</span> <span>{</span> Renderer <span>}</span> <span>from</span> <span>'@connectv/html'</span><span>;</span></p><p><span>2</span></p><p><span>3</span><span>const</span> renderer <span>=</span> <span>new</span> <span>Renderer</span><span>(</span><span>)</span><span>;</span></p><p><span>4</span>renderer<span>.</span><span>render</span><span>(</span><span><span><span>&lt;</span>div</span><span>&gt;</span></span><span>Hellow World!</span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span><span>)</span><span>.</span><span>on</span><span>(</span>document<span>.</span>body<span>)</span><span>;</span></p><br></code></pre><p>For more dynamic/reactive content, we simply added plugins to allow rendering 
<a href="https://rxjs-dev.firebaseapp.com/guide/observable">RxJS Observables</a>:</p><pre><code tabindex="0"><span><span></span><span></span><span></span><span></span></span><p><span>1</span><span>import</span> <span>{</span> Renderer <span>}</span> <span>from</span> <span>'@connectv/html'</span><span>;</span></p><p><span>2</span><span>import</span> <span>{</span> timer <span>}</span> <span>from</span> <span>'rxjs'</span><span>;</span></p><p><span>3</span></p><p><span>4</span><span>const</span> renderer <span>=</span> <span>new</span> <span>Renderer</span><span>(</span><span>)</span><span>;</span></p><p><span>5</span>renderer<span>.</span><span>render</span><span>(</span><span><span><span>&lt;</span>div</span><span>&gt;</span></span><span>You have been here for </span><span>{</span><span>timer</span><span>(</span><span>0</span><span>,</span> <span>1000</span><span>)</span><span>}</span><span> second(s).</span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span><span>)</span></p><p><span>6</span>        <span>.</span><span>on</span><span>(</span>document<span>.</span>body<span>)</span><span>;</span></p><br></code></pre><p>This of course meant that for interactive components familiarity with <a href="https://www.learnrxjs.io/">RxJS</a> was required, 
however, you generally do require familiarity with some reactive state management library to be able to 
properly create interactive components. RxJS might not be the easiest such library for people to dive in, but
considering its widespread usage and the overall performance gain, we felt this was a compromise well worth it.</p><blockquote><p>Fun fact: Historically CONNECTIVE HTML was developed first and CODEDOC as a tool to document it. However
as a result of popularity of CODEDOC and subsequently <code>coding.blog</code>, I haven't found the time to use it 
for its original purpose yet.</p></blockquote><hr><p>To meet the remainder of our design goals, we created a tool named <a href="https://github.com/CONNECT-platform/connective-sdh">CONNECTIVE SDH</a>. 
SDH stands for <em>Static/Dynamic HTML</em>, which means this library allowed us to seamlessly create both static (pre-rendered) 
and dynamic (rendered on client-side) HTML content.</p><p>This is how CONNECTIVE SDH works:</p><marker><br>

</marker><h2 id="static-content"><span data-ignore-text=""><span data-ignore-text="">link</span></span>Static Content</h2><p>For pre-rendering (or even SSR), the fact that CONNECTIVE HTML is pretty thin meant that we could simply combine it
with <a href="https://github.com/jsdom/jsdom">JSDOM</a> and add some nice functions for storing the results:</p><pre><code tabindex="0"><span><span></span><span></span><span></span><span></span></span><p><span>1</span><span>import</span> <span>{</span> compile <span>}</span> <span>from</span> <span>'@connectv/sdh'</span><span>;</span></p><p><span>2</span></p><p><span>3</span><span>compile</span><span>(</span><span>renderer</span> <span>=&gt;</span> </p><p><span>4</span>  <span><span><span>&lt;</span>html</span><span>&gt;</span></span><span></span></p><p><span>5</span>    <span><span><span>&lt;</span>head</span><span>&gt;</span></span><span></span></p><p><span>6</span>      <span><span><span>&lt;</span>title</span><span>&gt;</span></span><span>Hellow World Example</span><span><span><span>&lt;/</span>title</span><span>&gt;</span></span><span></span></p><p><span>7</span>    <span><span><span>&lt;/</span>head</span><span>&gt;</span></span><span></span></p><p><span>8</span>    <span><span><span>&lt;</span>body</span><span>&gt;</span></span><span></span></p><p><span>9</span>      <span><span><span>&lt;</span>h1</span><span>&gt;</span></span><span>Hellow World!</span><span><span><span>&lt;/</span>h1</span><span>&gt;</span></span><span></span></p><p><span>10</span>    <span><span><span>&lt;/</span>body</span><span>&gt;</span></span><span></span></p><p><span>11</span>  <span><span><span>&lt;/</span>html</span><span>&gt;</span></span></p><p><span>12</span><span>)</span><span>.</span><span>save</span><span>(</span><span>'dist/index.html'</span><span>)</span><span>;</span></p><br></code></pre><marker><br>

</marker><p>Or for a more <em>component oriented</em> example:</p><div><div data-tab-title="Main Code" data-tab-id="Main Code"><pre><code tabindex="0"><span><span></span><span></span><span></span><span>main.tsx</span></span><p><span>1</span><span>import</span> <span>{</span> compile <span>}</span> <span>from</span> <span>'@connectv/sdh'</span><span>;</span></p><p><span>2</span><span>import</span> <span>{</span> Card <span>}</span> <span>from</span> <span>'./card'</span><span>;</span> </p><p><span>3</span></p><p><span>4</span><span>compile</span><span>(</span><span>renderer</span> <span>=&gt;</span> </p><p><span>5</span>  <span><span><span>&lt;</span>fragment</span><span>&gt;</span></span><span></span></p><p><span>6</span>    <span><span><span>&lt;</span>h1</span><span>&gt;</span></span><span>List of stuff</span><span><span><span>&lt;/</span>h1</span><span>&gt;</span></span><span></span></p><p><span>7</span>    <span><span><span>&lt;</span><span>Card</span></span> <span>title</span><span><span>=</span><span>'</span>🥕Carrots<span>'</span></span> <span>text</span><span><span>=</span><span>'</span>they are pretty good for you.<span>'</span></span><span>/&gt;</span></span><span></span></p><p><span>8</span>  <span><span><span>&lt;/</span>fragment</span><span>&gt;</span></span></p><p><span>9</span><span>)</span><span>.</span><span>save</span><span>(</span><span>'dist/index.html'</span><span>)</span><span>;</span></p><br></code></pre></div><div data-tab-title="Component Code" data-tab-id="comp"><pre><code tabindex="0"><span><span></span><span></span><span></span><span>card.tsx</span></span><p><span>1</span><span>const</span> style <span>=</span> <span><span>`</span><span></span></span></p><p><span>2</span>  display: inline-block;</p><p><span>3</span>  vertical-align: top;</p><p><span>4</span>  padding: 8px;</p><p><span>5</span>  border-radius: 8px;</p><p><span>6</span>  margin: 8px;</p><p><span>7</span>  box-shadow: 0 2px 6px rgba(0, 0, 0, .2);</p><p><span>8</span><span>`</span><span>;</span></p><p><span>9</span></p><p><span>10</span><span>export</span> <span>function</span> <span>Card</span><span>(</span><span><span>{</span> title<span>,</span> text <span>}</span><span>,</span> renderer</span><span>)</span> <span>{</span></p><p><span>11</span>  <span>return</span> <span><span><span>&lt;</span>div</span> <span>style</span><span><span>=</span><span>{</span>style<span>}</span></span><span>&gt;</span></span><span></span></p><p><span>12</span>      <span><span><span>&lt;</span>h2</span><span>&gt;</span></span><span>{</span>title<span>}</span><span><span><span>&lt;/</span>h2</span><span>&gt;</span></span><span></span></p><p><span>13</span>      <span><span><span>&lt;</span>p</span><span>&gt;</span></span><span>{</span>text<span>}</span><span><span><span>&lt;/</span>p</span><span>&gt;</span></span><span></span></p><p><span>14</span>    <span><span><span>&lt;/</span>div</span><span>&gt;</span></span></p><p><span>15</span><span>}</span></p><br></code></pre></div></div><marker><br>

</marker><h2 id="dynamic-content"><span data-ignore-text=""><span data-ignore-text="">link</span></span>Dynamic Content</h2><p>For dynamic components, i.e. components that are to be rendered on the client side, we needed to:</p><ul><li>Collect and bundle their code</li><li>Attach that bundle to pre-rendered content</li><li>Create placeholders to maintain their position in the DOM tree</li></ul><p>With CONNECTIVE SDH, this process looks like this:</p><div><div data-tab-title="Main Code" data-tab-id="Main Code"><pre><code tabindex="0"><span><span></span><span></span><span></span><span>main.tsx</span></span><p><span>1</span><span>import</span> <span>{</span> compile<span>,</span> save<span>,</span> Bundle <span>}</span> <span>from</span> <span>'@connectv/sdh'</span><span>;</span></p><p><span>2</span><span>import</span> <span>{</span> $Counter <span>}</span> <span>from</span> <span>'./counter'</span><span>;</span> </p><p><span>3</span></p><p><span>4</span><span>const</span> bundle <span>=</span> <span>new</span> <span>Bundle</span><span>(</span><span>'./bundle.js'</span><span>,</span> <span>'dist/bundle.js'</span><span>)</span><span>;</span></p><p><span>5</span></p><p><span>6</span><span>compile</span><span>(</span><span>renderer</span> <span>=&gt;</span></p><p><span>7</span>  <span><span><span>&lt;</span>fragment</span><span>&gt;</span></span><span></span></p><p><span>8</span>    <span><span><span>&lt;</span>p</span><span>&gt;</span></span><span></span></p><p><span>9</span>      So this content will be prerendered, but the following component will be</p><p><span>10</span>      rendered on the client side.</p><p><span>11</span>    <span><span><span>&lt;/</span>p</span><span>&gt;</span></span><span></span></p><p><span>12</span>     &lt;$Counter/&gt;</p><p><span>13</span>  <span><span><span>&lt;/</span>fragment</span><span>&gt;</span></span></p><p><span>14</span><span>)</span></p><p><span>15</span> <span>.</span><span>post</span><span>(</span>bundle<span>.</span><span>collect</span><span>(</span><span>)</span><span>)</span>                    </p><p><span>16</span><span>.</span><span>save</span><span>(</span><span>'dist/index.html'</span><span>)</span></p><p><span>17</span> <span>.</span><span>then</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>save</span><span>(</span>bundle<span>)</span><span>)</span>                  </p><br></code></pre></div><div data-tab-title="Component Code" data-tab-id="comp"><pre><code tabindex="0"><span><span></span><span></span><span></span><span>counter.tsx</span></span><p><span>1</span><span>import</span> <span>{</span> state <span>}</span> <span>from</span> <span>"@connectv/core"</span><span>;</span></p><p><span>2</span> <span>import</span> <span>{</span> transport <span>}</span> <span>from</span> <span>"@connectv/sdh/transport"</span><span>;</span></p><p><span>3</span></p><p><span>4</span><span>const</span> style <span>=</span> <span><span>`</span><span></span></span></p><p><span>5</span>  border-radius: 3px;</p><p><span>6</span>  background: #424242;</p><p><span>7</span>  cursor: pointer;</p><p><span>8</span>  padding: 8px;</p><p><span>9</span>  color: white;</p><p><span>10</span>  display: inline-block;</p><p><span>11</span>  box-shadow: 0 2px 6px rgba(0, 0, 0, .12);</p><p><span>12</span><span>`</span><span>;</span></p><p><span>13</span></p><p><span>14</span><span>export</span> <span>function</span> <span>Counter</span><span>(</span><span>_<span>,</span> renderer</span><span>)</span> <span>{</span></p><p><span>15</span>  <span>const</span> count <span>=</span> <span>state</span><span>(</span><span>0</span><span>)</span><span>;</span></p><p><span>16</span>  <span>return</span> <span>(</span></p><p><span>17</span>    <span><span><span>&lt;</span>div</span> <span>style</span><span><span>=</span><span>{</span>style<span>}</span></span> <span>onclick</span><span><span>=</span><span>{</span><span>(</span><span>)</span> <span>=&gt;</span> count<span>.</span>value<span>++</span><span>}</span></span><span>&gt;</span></span><span></span></p><p><span>18</span>      You have clicked <span>{</span>count<span>}</span><span> times!</span></p><p><span>19</span>    <span><span><span>&lt;/</span>div</span><span>&gt;</span></span></p><p><span>20</span>  <span>)</span><span>;</span></p><p><span>21</span><span>}</span></p><p><span>22</span></p><p><span>23</span> <span>export</span> <span>const</span> $Counter <span>=</span> <span>transport</span><span>(</span>Counter<span>)</span><span>;</span> </p><br></code></pre></div></div><marker><br>

</marker><h3 id="placeholders"><span data-ignore-text=""><span data-ignore-text="">link</span></span>Placeholders</h3><p>In this example, <code>Counter</code> is a component that needs to be rendered on the client-side, i.e. it needs
to be <em>transported</em> to the client. This is done via …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://coding.blog/blog/jamstack">https://coding.blog/blog/jamstack</a></em></p>]]>
            </description>
            <link>https://coding.blog/blog/jamstack</link>
            <guid isPermaLink="false">hacker-news-small-sites-23641457</guid>
            <pubDate>Thu, 25 Jun 2020 14:54:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Complete Kafka workspace and cloud environment]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23641179">thread link</a>) | @lensesio
<br/>
June 25, 2020 | https://lenses.io/blog/2020/06/perfect-environment-learn-develop-apache-kafka/ | <a href="https://web.archive.org/web/*/https://lenses.io/blog/2020/06/perfect-environment-learn-develop-apache-kafka/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Apache Kafka has gained traction as one of the most widely adopted technologies for building streaming applications - but introducing it (and scaling it) into your business can be a struggle.</p><p>The problem isn’t with Kafka itself so much as the different components you need to learn and different tools required to operate it.</p><p>For those motivated enough, you can invest money, effort and long Friday nights into learning, fixing and streamlining Kafka - and you’ll get there.&nbsp;</p><p>But for those that prefer to spend time focusing on the data and would rather master Kafka’s value than its inner-workings, fear not.&nbsp;</p><p>When we started Lenses.io, we experienced first-hand how difficult it can be to set up a Kafka development environment; so we decided to follow an anti-pattern and create a docker image with a full-fledged Kafka installation: the<a href="https://github.com/lensesio/fast-data-dev"> fast-data-dev docker</a>.&nbsp;</p><p><span><img src="https://images.ctfassets.net/tnuaj0t7r912/dH7CDIWIgsRCvAqBzqE31/90912a877cfab5860632ea82905ed00d/kafka_docker.PNG" alt="Lenses Kafka docker"></span></p><p>
The community loved it and we are grateful for this.&nbsp;</p><p>Fast forward and we created Lenses.io, understanding that now the challenge was operating Kafka and real-time applications and data. So we wanted to create a tool to provide the best developer experience for Kafka: Lenses.&nbsp;&nbsp;</p><p>It is only natural that we had to add it to fast-data-dev and make it free for developers, the people to whom we owe our success.</p><p>Hence, enter the Lenses Box; our most popular download!</p><h3>A complete Kafka-in-a-box</h3><p>To start with, the Box gives you an environment including:
</p><ul><li><p><b>1-node Kafka and Zookeeper</b>: your Kafka service, ready to receive data.</p></li><li><p><b>Kafka Connect</b>: use it to bring data in and out of Kafka, from DBs for example.</p></li><li><p><b>Schema Registry</b>: safely control the structure of your data in Kafka, powered by Avro.</p></li><li><p><b>Elasticsearch</b>: ship your streaming results here for powerful search.</p></li></ul><p>All in a single docker container.</p><p>That’s already quite a lot of time off your plate. Then we package....</p><h3>... A DataOps workspace</h3><p>
In the same container, you’ll get a Lenses.io workspace fully integrated with the Kafka environment.&nbsp;</p><p>If you’re not familiar with Lenses.io, it’s an engineering portal for building &amp; operating real-time applications on Apache Kafka.</p><p><span><img src="https://images.ctfassets.net/tnuaj0t7r912/7DWv3Bt0Hktaxp0wffQrPV/5732afddba639697e37f3342beafbe0d/Portal_blog_copy.jpg" alt="Lenses.io Box Apache Kafka docker container for localhost development"></span></p><h3>How does Box help me develop real-time applications?</h3><p>
As a docker container that unifies all these different technologies into a single developer experience, Box is a perfect solution to learn Kafka or to develop real-time applications on a local instance before promoting to another Kafka environment.&nbsp;</p><p><span><img src="https://images.ctfassets.net/tnuaj0t7r912/sXmd6nQXmkgivJ9ejXxhh/5d6cc3687660dd1ac5655348bf1bf240/Portal_blog2.jpg" alt="Portal blog2"></span></p><p>So, if you’re a developer, you can <code>docker&nbsp;run</code> Lenses.io Box on your machine and try out the following use cases.</p><h3>Connect custom applications &amp; explore data in streams</h3><p>Connect your custom application, written in whatever framework you choose, to the Kafka broker just like you would with any other Kafka environment. Once you’ve done this, you’ll have full visibility into your custom application within a workspace. This includes being able to explore data in the streams using SQL, viewing and alerting on lag. If you use the <a href="https://docs.lenses.io/dev/topology/index.html">Topology client</a>, you’ll be able to even see the full topology of your pipelines.&nbsp;
</p><p><span><img src="https://images.ctfassets.net/tnuaj0t7r912/56OrFbezKepp4RQZEqz7Xn/27a231c4ae58faddbd8e2f0025f74832/image.png" alt="IntelliJ - Connecting consumer or producer client to Lenses.io Box localhost Apache Kafka broker"></span></p><h3>Build &amp; evolve schemas</h3><p>
Your gateway into streaming structured data. With support for multiple standard serialization formats, custom formats, and Schema Registry, you can use Box to understand your data and experiment with schemas and evolution. Lenses SQL gives you a perfect playground to iterate and verify your schema changes.
</p><p><span><img src="https://images.ctfassets.net/tnuaj0t7r912/2D7lSbSE37jmPozW5CGMTb/be2ead015664934f37144a30082650c6/docker-run-lenses.PNG" alt="Docker run Kafka on Lenses"></span></p><p>Do you like SQL? If so, use it to create schemas directly. For example the following statement will create a topic with an AVRO schema for the value of the topic.&nbsp;
</p><pre>CREATE&nbsp;TABLE&nbsp;customers&nbsp;(id&nbsp;string,&nbsp;name&nbsp;string,&nbsp;postcode&nbsp;string,&nbsp;city&nbsp;string)</pre><pre></pre><pre>FORMAT&nbsp;(string,&nbsp;avro)</pre><pre></pre><pre>PROPERTIES&nbsp;(partitions=3,&nbsp;compacted=false);&nbsp;</pre><pre></pre><pre></pre><pre></pre><pre></pre><p>You can run these statements from the browser or from a CLI</p><p><span><img src="https://images.ctfassets.net/tnuaj0t7r912/nObbLUdN7CVPbGKWxf4n8/30e14ad7dbc9797d690238f2817fdcba/image.png" alt="Lenses.io CLI - create Apache Kafka topic and AVRO schema from command line with SQL"></span></p><h3>Test a microservice by injecting data into a stream using SQL</h3><p>
If you’re developing a streaming application that will be read from Kafka, you are effectively making a <b>Kafka consumer.</b> You will be connecting it to the Broker and you might want to test how it behaves when actually consuming data from a stream.
</p><p>That same SQL Engine I mentioned earlier, also extends to injecting data into a topic. For example:&nbsp;</p><pre>INSERT&nbsp;INTO&nbsp;customers&nbsp;(id,&nbsp;name,&nbsp;postcode,&nbsp;city)&nbsp;</pre><pre></pre><pre>VALUES&nbsp;('23423','Xavier',&nbsp;'75009',&nbsp;'Paris'),&nbsp;</pre><pre></pre><pre>('56456','Anne',&nbsp;'E24',&nbsp;'London'),&nbsp;</pre><pre></pre><pre>('8734','Todd',&nbsp;'10175',&nbsp;'New&nbsp;York'),&nbsp;</pre><pre></pre><pre>('6735463','Denise',&nbsp;'3207',&nbsp;'Melbourne');</pre><p><span><img src="https://images.ctfassets.net/tnuaj0t7r912/40FjAJMM5z8Apl3dv0kG7z/56918c58b7a96945dffe8e99539fcbad/image.png" alt="Insert data into an Apache Kafka topic via the Lenses.io CLI client and SQL statement"></span></p><h3>Configure Kafka Connect connectors</h3><p>The easiest way to bring data in and out of Kafka is with the Kafka Connect connectors. They are standard patterns of moving data between Kafka and other data systems.</p><p>
The environment is packaged with a number of popular connectors such as Mongo, Elastic 6, Influx but you can also import others.</p><p>
Want to bring in data from a database? Want to ship your results to Influx? No problem. Just a few clicks and Lenses will get those connectors running for you.</p><p>
This is perfect for testing out the Kafka Connect configuration and connection to those source and target systems. You benefit from the feedback loop: from error handling if you’ve mis-configured anything to seeing the performance of the flow. Not to mention being able to explore the data you are sourcing or sinking with SQL.&nbsp;</p><p><span><img src="https://images.ctfassets.net/tnuaj0t7r912/3bO29ixv0ZCEzQ9ugBBjId/9b6ddfec459225940cdb8897e88a794e/image.png" alt="View and manage Kafka Connect connectors from the Lenses.io Box"></span></p><h3>Build SQL Streaming applications</h3><p>
Last but not least, Box is an environment to build stream processing applications with SQL.&nbsp;</p><p>The Streaming SQL engine allows you to define real-time data processing applications that enrich, filter, aggregate or reshape data streams. Ask things like:
</p><ul><li><p><i>What’s my total number sales up-till-now? Real-time.</i></p></li><li><p><i>How many clients are on my website checking out my new product right now?</i></p></li></ul><p>The answer is in the data. And all it takes is a bit of SQL. No frameworks, no code, no rocket-science engineering.</p><p>Here's an example<i>

</i></p><pre>SET&nbsp;autocreate=true;</pre><pre></pre><pre>SET&nbsp;`auto.offset.reset`='earliest';</pre><pre></pre><pre>SET&nbsp;`commit.interval.ms`='10000';</pre><pre></pre><pre>INSERT&nbsp;INTO&nbsp;frauds_detection</pre><pre></pre><pre>WITH&nbsp;tableCards&nbsp;AS&nbsp;(</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;SELECT&nbsp;ccNumber,&nbsp;provider,</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;expiry,&nbsp;accountEnabled</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;FROM&nbsp;credit_cards_data</pre><pre></pre><pre>)</pre><pre></pre><pre>SELECT&nbsp;STREAM</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;p.provider,</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;p.ccNumber,</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;p.transaction.currency,</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;count(*)&nbsp;attempts</pre><pre></pre><pre>FROM&nbsp;credit_cards_payments&nbsp;AS&nbsp;p</pre><pre></pre><pre>INNER&nbsp;JOIN&nbsp;tableCards&nbsp;AS&nbsp;c&nbsp;ON&nbsp;p.ccNumber&nbsp;=&nbsp;c.ccNumber</pre><pre></pre><pre>WHERE&nbsp;c.accountEnabled&nbsp;=&nbsp;'no'</pre><pre></pre><pre>GROUP&nbsp;BY&nbsp;tumble(5,s),&nbsp;p.provider</pre><p>You don’t need extra services either.. The workload will run locally in your environment for Box. Of course with the full Lenses.io workspace, you can choose to deploy it over your existing Kubernetes infrastructure and run it at scale.</p><h3>“The Cloud”, you said?
</h3><p>As it’s next evolution, yes, Box is now available as a Cloud service!&nbsp; A full Lenses-Kafka developer environment with zero setup.&nbsp;</p><p>Sign up for free on our new <a href="http://portal.lenses.io/register">Lenses.io Portal.</a></p><p>Or if you prefer to run the Docker container yourself, get access to it from <a href="https://lenses.io/downloads/lenses/?path=wizard-form">here</a> <a href="https://lenses.io/downloads/lenses/?path=wizard-form"></a>
</p></div></div>]]>
            </description>
            <link>https://lenses.io/blog/2020/06/perfect-environment-learn-develop-apache-kafka/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23641179</guid>
            <pubDate>Thu, 25 Jun 2020 14:33:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Promote Imperfect People]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23641051">thread link</a>) | @chesterarthur
<br/>
June 25, 2020 | https://staysaasy.com/management/2020/06/23/Promote-Imperfect-People.html | <a href="https://web.archive.org/web/*/https://staysaasy.com/management/2020/06/23/Promote-Imperfect-People.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>You’ve likely experienced it: “You’re above and beyond everything we’re asking. There’s no promotion this round but all you need to do is <strong>__</strong>_”. Insert a semi-important but not absolutely necessary thing. Even worse if it’s something you’re really not good at.</p>

<p>One of the most demotivating things that an organization or manager can do is requiring “perfection” for a promotion. It’s a problem with two main dimensions:</p>
<ul>
  <li>It’s incommensurate with the value being added to the business.</li>
  <li>Perfection is subjective.</li>
</ul>

<h2 id="incommensurate-with-value-add">Incommensurate with Value-Add</h2>

<p>Ultimately all performance comes down to one thing: how much value are you adding to the business? Examples of where forcing perfection gets things out of whack:</p>
<ul>
  <li>I coded up a feature that brought in $10M to the business this year. I wasn’t promoted because they said I don’t speak enough in meetings.</li>
  <li>I saved the company from collapse because I was the only one who knew how to debug the system when it was melting. I wasn’t promoted because they said I show up too late every day.</li>
  <li>I identified a winning strategy for the entire business that drove us to another echelon of success. I wasn’t promoted because my design docs have typos.</li>
</ul>

<p>All that matters is the value being added to the business. There are nuances where behavior can set bad examples or cause issues for others, but that detracts from value added to the business and should be considered. The unfortunate and unbelievably common case is that some sort of benign missing strength is held against people.</p>

<h2 id="perfection-is-subjective">Perfection is Subjective</h2>

<p>When managers go down the rabbit whole of chasing perfect promotions they’re much more likely to be biased. In reality, most people’s internal picture of a perfect candidate for a promotion is something like “what did I look like when I got promoted?” That’s often the closest image a manager has of what a promotion at that level looks like.</p>

<p>In mild cases you get things like “when I got promoted I had to walk in the snow to work, uphill both ways.”</p>

<p>In more severe cases you get things like:</p>
<ul>
  <li>Men who don’t promote women because they’re not “aggressive enough” or they “don’t speak up enough”</li>
  <li>Extroverts who don’t promote introverts because they don’t like public speaking.</li>
  <li>Non-parents who don’t promote parents because they don’t work until midnight in the office.</li>
</ul>

<p>Promote people based on impact to the business, not their style of delivery.  Don’t hold people down because they deliver value in a way that isn’t comfortable, known, or practiced by you.</p>

<h2 id="conclusion">Conclusion</h2>

<p>In promotions and growth, focus more on amplifying strengths than fixing “weaknesses”.  You’ll find it’s much easier and much more fruitful to have people play to their strengths.</p>

<p>Promote imperfect people - that’s all you’ve got.</p>

    




  </div></div>]]>
            </description>
            <link>https://staysaasy.com/management/2020/06/23/Promote-Imperfect-People.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23641051</guid>
            <pubDate>Thu, 25 Jun 2020 14:20:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elixir Wizards S4E6 Sundi Myint on the Visual Side of Elixir]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23640986">thread link</a>) | @smartlogic
<br/>
June 25, 2020 | https://smartlogic.io/podcast/elixir-wizards/s4e6-myint/ | <a href="https://web.archive.org/web/*/https://smartlogic.io/podcast/elixir-wizards/s4e6-myint/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <header>
  

  <!-- Global site tag (gtag.js) - Google Ads: 743722644 -->
  
  
</header>

    <p><a href="https://smartlogic.io/">Home</a>

  
    &gt; <a href="https://smartlogic.io/podcast/">Podcast</a>
  

  
    &gt; <a href="https://smartlogic.io/podcast/elixir-wizards/">Elixir wizards</a>
  

  
    &gt; Sundi Myint on The Visual Side of Elixir, the History of Emojis, and Test- and Domain-Driven Architecture
  

</p>


  <main role="main">
    <section>
      </section>

    <div>

      <section>
        



        <h2>About this Episode</h2>
        <h3>
          Published June 25, 2020 |
          Duration: 45:58 |
          <a href="https://feeds.fireside.fm/smartlogic/rss">RSS Feed</a> |
          <a href="https://aphid.fireside.fm/d/1437767933/03a50f66-dc5e-4da4-ab6e-31895b6d4c9e/f14188bd-903b-49eb-bc8b-f52429966e63.mp3">Direct download</a>
          
          | <a href="https://smartlogic.io/podcast/elixir-wizards/transcripts/s4e6_Sundi_Myint.txt">Transcript</a>
          
        </h3>
        <!-- description copy starts here - pulled from fireside -->
        
        <p>Welcome to another episode of Elixir Wizards as we continue our journey into system and application architecture! Our featured guest today is Sundi Myint and she is here to share her journey with Elixir and her non-traditional path to programming. We hear about Sundi's interest in gaming, her role at Cava and a bit of the inspiration behind her amazing Instagram account! We discuss her first internship and how she found herself in the role quite suddenly before diving into the motivation behind her blog post on the history of emojis. Sundi did some serious research into this interesting subject and she shares some of the more technical aspects of the story with us on the show. We talk about architecture and both test and design-driven approaches. Sundi also explains her process and how mapping things out on a whiteboard has been her favored way to do things for some time. Andrea Leopardi then joins us for another edition of Pattern Matching with Todd! He answers Todd's questions about his home life, media favorites, future projects and more!</p>

<p>Key Points From This Episode:</p>

<ul>
<li>Sundi's Instagram aesthetic and her love of food and photography. </li>
<li>How Sundi got into programming and her first internship.<br></li>
<li>Getting hired at Cava and an introduction to Elixir and the community.</li>
<li>Video game programming and Sundi's thoughts on the possibility of pursuing this path. </li>
<li>Sundi's first paid job out of college and the tech stack at the company.</li>
<li>Thoughts on easily available learning resources and the power of Live View. </li>
<li>Some background on Sundi's amazing blog post on the history of emojis.</li>
<li>Understanding Unicode, how it works and its role in translation and interpretation. </li>
<li>Sundi's perspectives on architecture and domain-driven design.</li>
<li>Code design strategies, workflow and the idea and practice of test-driven code. </li>
<li>Conversations with stakeholders and moving to the planning stage. </li>
<li>How Sundi uses whiteboards to map out her work graphically and Elixir's part in this. </li>
<li>Andrea's travels and some of the amazing locations he has visited for conferences. </li>
<li>Home life and lifestyle in quarantine for Andrea in Italy.</li>
<li>Alternative career paths and Andrea's other interests; balancing creativity and logic. </li>
<li>Music, movies and television choices for Andrea.</li>
<li>Exciting new projects on the horizon for Andrea; a book, HTTP and more!</li>
</ul>

<p>Links Mentioned in Today’s Episode:</p>

<p>SmartLogic — <a href="https://smartlogic.io/" rel="nofollow">https://smartlogic.io/</a> <br>
Sundi Myint on Twitter — <a href="https://twitter.com/sundikhin" rel="nofollow">https://twitter.com/sundikhin</a><br>
Sundi Myint on Instagram — <a href="https://www.instagram.com/sundikhin" rel="nofollow">https://www.instagram.com/sundikhin</a><br>
Cava — <a href="https://cava.com/" rel="nofollow">https://cava.com/</a><br>
Hackers &amp; Painters — <a href="https://www.amazon.com/Hackers-Painters-Big-Ideas-Computer/dp/1449389554" rel="nofollow">https://www.amazon.com/Hackers-Painters-Big-Ideas-Computer/dp/1449389554</a><br>
Lonestar Elixir — <a href="https://lonestarelixir.com/" rel="nofollow">https://lonestarelixir.com/</a><br>
Bruce Tate — <a href="https://codesync.global/speaker/bruce-tate/" rel="nofollow">https://codesync.global/speaker/bruce-tate/</a><br>
EA — <a href="https://www.ea.com/" rel="nofollow">https://www.ea.com</a><br>
Groxio Learning — <a href="https://grox.io/training/elixir/home" rel="nofollow">https://grox.io/training/elixir/home</a><br>
Live View — <a href="https://support.google.com/maps/thread/11554255?hl=en" rel="nofollow">https://support.google.com/maps/thread/11554255?hl=en</a><br>
Build a real-time Twitter clone in 15 minutes with LiveView and Phoenix 1.5 — <a href="https://www.youtube.com/watch?v=MZvmYaFkNJI" rel="nofollow">https://www.youtube.com/watch?v=MZvmYaFkNJI</a><br>
The History of Emojis Blog Post — <a href="https://engineering.upside.com/emojis-a-history-75d595bbe4a5?gi=6cd53698e5d" rel="nofollow">https://engineering.upside.com/emojis-a-history-75d595bbe4a5?gi=6cd53698e5d</a><br>
Burgergate <a href="https://www.theverge.com/2017/10/30/16569346/burgergate-emoji-google-apple" rel="nofollow">https://www.theverge.com/2017/10/30/16569346/burgergate-emoji-google-apple</a><br>
Joy of Coding — <a href="https://joyofcoding.org/" rel="nofollow">https://joyofcoding.org/</a><br>
Test-driven development — <a href="https://en.wikipedia.org/wiki/Test-driven_development" rel="nofollow">https://en.wikipedia.org/wiki/Test-driven_development</a><br>
Mox — <a href="https://hexdocs.pm/mox/Mox.html" rel="nofollow">https://hexdocs.pm/mox/Mox.html</a><br>
Venmo — <a href="https://venmo.com/" rel="nofollow">https://venmo.com/</a><br>
Mint — <a href="https://www.mint.com/" rel="nofollow">https://www.mint.com/</a><br>
Avengers — <a href="https://www.marvel.com/movies/avengers-endgame" rel="nofollow">https://www.marvel.com/movies/avengers-endgame</a><br>
DC Elixir — <a href="https://www.meetup.com/DC-Elixir/" rel="nofollow">https://www.meetup.com/DC-Elixir/</a><br>
Todd Resudek — <a href="https://medium.com/@toddresudek" rel="nofollow">https://medium.com/@toddresudek</a><br>
Andrea Leopardi — <a href="https://andrealeopardi.com/" rel="nofollow">https://andrealeopardi.com/</a><br>
Brooklyn Zelenka — <a href="https://medium.com/@expede" rel="nofollow">https://medium.com/@expede</a><br>
The Lord of Rings — <a href="https://www.rottentomatoes.com/franchise/lord_of_the_rings" rel="nofollow">https://www.rottentomatoes.com/franchise/lord_of_the_rings</a><br>
Wes Anderson — <a href="https://www.imdb.com/name/nm0027572/" rel="nofollow">https://www.imdb.com/name/nm0027572/</a><br>
Scott Pilgrim vs. The World — <a href="https://www.rottentomatoes.com/m/scott_pilgrims_vs_the_world" rel="nofollow">https://www.rottentomatoes.com/m/scott_pilgrims_vs_the_world</a><br>
Community — <a href="https://www.rottentomatoes.com/tv/community" rel="nofollow">https://www.rottentomatoes.com/tv/community</a><br>
The Office — <a href="https://www.rottentomatoes.com/tv/the_office" rel="nofollow">https://www.rottentomatoes.com/tv/the_office</a><br>
Rick and Morty — <a href="https://www.rottentomatoes.com/tv/rick_and_morty" rel="nofollow">https://www.rottentomatoes.com/tv/rick_and_morty</a><br>
Justus Eapen on Twitter — <a href="https://twitter.com/justuseapen" rel="nofollow">https://twitter.com/justuseapen</a><br>
Eric Oestrich on Twitter — <a href="https://twitter.com/ericoestrich" rel="nofollow">https://twitter.com/ericoestrich</a></p><p>Special Guests: Andrea Leopardi and Sundi Myint.</p>
      
        <!-- end copy from fireside -->
      </section>

  </div></main>
  

  </div></div>]]>
            </description>
            <link>https://smartlogic.io/podcast/elixir-wizards/s4e6-myint/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23640986</guid>
            <pubDate>Thu, 25 Jun 2020 14:15:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Angular 10 Now Available]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 7 (<a href="https://news.ycombinator.com/item?id=23640966">thread link</a>) | @theodorejb
<br/>
June 25, 2020 | https://blog.angular.io/version-10-of-angular-now-available-78960babd41 | <a href="https://web.archive.org/web/*/https://blog.angular.io/version-10-of-angular-now-available-78960babd41">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><div><div><div><p><a href="https://blog.angular.io/@stephenfluin?source=post_page-----78960babd41----------------------" rel="noopener"><img alt="Stephen Fluin" src="https://miro.medium.com/fit/c/96/96/1*y_L34o3bW0QELQm1KOFMTw.jpeg" width="48" height="48"></a></p></div></div></div></div><p id="0c65">Version 10.0.0 is here! This is a <a href="https://semver.org/#spec-item-8" target="_blank" rel="noopener">major</a> release that spans the entire platform, including the framework, Angular Material, and the CLI. This release is smaller than typical; it has only been 4 months since we released version 9.0 of Angular.</p><figure><div><div><div><div><p><img src="https://miro.medium.com/max/60/1*NW08J81iLpExTFTz4wnWHQ.jpeg?q=20" width="2048" height="1365" role="presentation"></p><p><img src="https://miro.medium.com/max/4096/1*NW08J81iLpExTFTz4wnWHQ.jpeg" width="2048" height="1365" srcset="https://miro.medium.com/max/552/1*NW08J81iLpExTFTz4wnWHQ.jpeg 276w, https://miro.medium.com/max/1104/1*NW08J81iLpExTFTz4wnWHQ.jpeg 552w, https://miro.medium.com/max/1280/1*NW08J81iLpExTFTz4wnWHQ.jpeg 640w, https://miro.medium.com/max/1400/1*NW08J81iLpExTFTz4wnWHQ.jpeg 700w" sizes="700px" role="presentation"></p></div></div></div></div><figcaption>Photo of Butterfly Beach by Minko Gechev</figcaption></figure><p id="346b">We try to release two major versions each year to keep Angular synchronized with the rest of the JavaScript ecosystem and to have a predictable schedule. We plan to release version 11 this fall.</p><p id="156d"><strong>New Date Range Picker</strong></p><p id="ba59">Angular Material now includes a new date range picker.</p><figure><div><div><div><p><img src="https://miro.medium.com/max/60/0*ruU5G-8_hqEp3UBY?q=20" width="410" height="94" role="presentation"></p><p><img src="https://miro.medium.com/max/820/0*ruU5G-8_hqEp3UBY" width="410" height="94" srcset="https://miro.medium.com/max/552/0*ruU5G-8_hqEp3UBY 276w, https://miro.medium.com/max/820/0*ruU5G-8_hqEp3UBY 410w" sizes="410px" role="presentation"></p></div></div></div><figcaption>Image of the new date range picker</figcaption></figure><p id="f310">To use the new date range picker, you can use the <code>mat-date-range-input</code> and <code>mat-date-range-picker</code> components.</p><p id="5add">See <a href="https://stackblitz.com/angular/nknyovevygv?file=src%2Fapp%2Fdate-range-picker-overview-example.html" target="_blank" rel="noopener">this example on StackBlitz</a>.</p><p id="41ba">Learn more about <a href="https://next.material.angular.io/components/datepicker/overview#date-range-selection" target="_blank" rel="noopener">date range selection</a>.</p><p id="16c4"><strong>Warnings about CommonJS imports</strong></p><p id="aadf">When you use a dependency that is packaged with CommonJS, it can result in <a href="https://web.dev/commonjs-larger-bundles/" target="_blank" rel="noopener">larger slower applications</a>.</p><p id="9444">Starting with version 10, we now warn you when your build pulls in one of these bundles. If you’ve started seeing these warnings for your dependencies, let your dependency know that you’d prefer an ECMAScript module (ESM) bundle.</p><figure><div><div><div><div><p><img src="https://miro.medium.com/max/60/0*udjNtSSP-495QNzL?q=20" width="1600" height="357" role="presentation"></p><p><img src="https://miro.medium.com/max/3200/0*udjNtSSP-495QNzL" width="1600" height="357" srcset="https://miro.medium.com/max/552/0*udjNtSSP-495QNzL 276w, https://miro.medium.com/max/1104/0*udjNtSSP-495QNzL 552w, https://miro.medium.com/max/1280/0*udjNtSSP-495QNzL 640w, https://miro.medium.com/max/1400/0*udjNtSSP-495QNzL 700w" sizes="700px" role="presentation"></p></div></div></div></div><figcaption>CommonJS or AMD dependencies can cause optimization bailouts</figcaption></figure><p id="dde5"><strong>Optional Stricter Settings</strong></p><p id="7e3d">Version 10 offers a more strict project setup when you create a new workspace with <code>ng new</code>.</p><pre><span id="4b6e">ng new --strict</span></pre><p id="9fa5">Enabling this flag initializes your new project with a few new settings that improve maintainability, help you catch bugs ahead of time, and allow the CLI to perform advanced optimizations on your app. Specifically, the <code>strict</code> flag does the following:</p><ul><li id="0ab9">Enables strict mode in TypeScript</li><li id="0f1b">Turns template type checking to Strict</li><li id="6313">Default bundle budgets have been reduced by ~75%</li><li id="855e">Configures linting rules to <a href="https://palantir.github.io/tslint/rules/no-any/" target="_blank" rel="noopener">prevent declarations of type </a><code><a href="https://palantir.github.io/tslint/rules/no-any/" target="_blank" rel="noopener">any</a></code></li><li id="cb7d">Configures your app as side-effect free to enable more advanced tree-shaking</li></ul><p id="2213"><strong>Keeping Up to Date with the Ecosystem</strong></p><p id="e568">As usual, we have made a few updates to the dependencies of Angular to stay synchronized with the JavaScript ecosystem.</p><ul><li id="0658">TypeScript bumped to <a href="https://www.typescriptlang.org/docs/handbook/release-notes/typescript-3-9.html" target="_blank" rel="noopener">TypeScript 3.9</a></li><li id="498e">TSLib has been updated to v<a href="https://github.com/microsoft/tslib/releases/tag/2.0.0" target="_blank" rel="noopener">2.0</a></li><li id="50e3">TSLint has been updated to v6</li></ul><p id="fcf0">We’ve also updated our project layout. Starting with version 10 you will see a new <code>tsconfig.base.json</code>. This additional <code><a href="https://www.typescriptlang.org/docs/handbook/tsconfig-json.html" target="_blank" rel="noopener">tsconfig.json</a></code><a href="https://www.typescriptlang.org/docs/handbook/tsconfig-json.html" target="_blank" rel="noopener"> file</a> better supports the way that IDEs and build tooling resolve type and package configurations.</p><p id="948c"><strong>New Default Browser Configuration</strong></p><p id="eb51">We’ve updated the browser configuration for new projects to exclude older and less used browsers.</p><p id="686d"><strong>v9 Defaults</strong></p><figure><div><div><div><div><p><img src="https://miro.medium.com/max/46/0*jhzqz-biEH3Bd7zQ?q=20" width="787" height="1036" role="presentation"></p><p><img src="https://miro.medium.com/max/1574/0*jhzqz-biEH3Bd7zQ" width="787" height="1036" srcset="https://miro.medium.com/max/552/0*jhzqz-biEH3Bd7zQ 276w, https://miro.medium.com/max/1104/0*jhzqz-biEH3Bd7zQ 552w, https://miro.medium.com/max/1280/0*jhzqz-biEH3Bd7zQ 640w, https://miro.medium.com/max/1400/0*jhzqz-biEH3Bd7zQ 700w" sizes="700px" role="presentation"></p></div></div></div></div></figure><p id="8574"><strong>v10 Defaults</strong></p><figure><div><div><div><p><img src="https://miro.medium.com/max/60/0*kLsNxh2hOj_aQ8HV?q=20" width="685" height="479" role="presentation"></p><p><img src="https://miro.medium.com/max/1370/0*kLsNxh2hOj_aQ8HV" width="685" height="479" srcset="https://miro.medium.com/max/552/0*kLsNxh2hOj_aQ8HV 276w, https://miro.medium.com/max/1104/0*kLsNxh2hOj_aQ8HV 552w, https://miro.medium.com/max/1280/0*kLsNxh2hOj_aQ8HV 640w, https://miro.medium.com/max/1370/0*kLsNxh2hOj_aQ8HV 685w" sizes="685px" role="presentation"></p></div></div></div></figure><p id="a101">This has the side effect of disabling ES5 builds by default for new projects. To enable ES5 builds and differential loading for browsers that require it (such as IE or UC Browser), simply <a href="https://github.com/browserslist/browserslist#browserslist-" target="_blank" rel="noopener">add the browsers you need to support</a> in the <code>.browserslistrc</code> file.</p><p id="df1c"><strong>Angular Team Fixit</strong></p><p id="4207">We’ve dramatically increased our investment in working with the community. In the last three weeks our open issue count has decreased by over 700 issues across <a href="https://github.com/angular/angular/issues" target="_blank" rel="noopener">framework</a>, <a href="https://github.com/angular/angular-cli/issues" target="_blank" rel="noopener">tooling</a>, and <a href="https://github.com/angular/components/issues" target="_blank" rel="noopener">components</a>. We’ve touched over 2,000 issues, and we plan to make large investments over the next few months, working with the community to do even more.</p><p id="c357"><strong>Deprecations and Removals</strong></p><p id="6e18">We’ve made several new deprecations and removals from Angular.</p><p id="61da">The <a href="https://g.co/ng/apf" target="_blank" rel="noopener">Angular Package Format</a> no longer includes ESM5 or FESM5 bundles, saving you 119MB of download and install time when running <code>yarn</code> or <code>npm install</code> for Angular packages and libraries. These formats are no longer needed as any downleveling to support ES5 is done at the end of the build process.</p><p id="a660">Based on heavy consultation with the community, we are deprecating support for older browsers including IE 9, 10, and <a href="https://en.wikipedia.org/wiki/Internet_Explorer_Mobile" target="_blank" rel="noopener">Internet Explorer Mobile</a>.</p><p id="4190">You can <a href="http://v10.angular.io/guide/deprecations" target="_blank" rel="noopener">read more about our deprecations and removals</a>.</p><p id="792e">Visit <a href="https://update.angular.io/" target="_blank" rel="noopener">update.angular.io</a> for detailed information and guidance. To have the best update experience, we recommend always upgrading one major release at a time.</p><p id="4859">To update:</p><pre><span id="d24d">ng update @angular/cli @angular/core</span></pre><p id="e72b">You can read more about this update in our <a href="https://v10.angular.io/guide/updating-to-version-10" target="_blank" rel="noopener">Updating to version 10 guide</a>.</p></div></div></section></div></div>]]>
            </description>
            <link>https://blog.angular.io/version-10-of-angular-now-available-78960babd41</link>
            <guid isPermaLink="false">hacker-news-small-sites-23640966</guid>
            <pubDate>Thu, 25 Jun 2020 14:13:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Logistic regression from scratch]]>
            </title>
            <description>
<![CDATA[
Score 144 | Comments 52 (<a href="https://news.ycombinator.com/item?id=23640762">thread link</a>) | @pmuens
<br/>
June 25, 2020 | https://philippmuens.com/logistic-regression-from-scratch/ | <a href="https://web.archive.org/web/*/https://philippmuens.com/logistic-regression-from-scratch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>You can find working code examples (including this one) in my <a href="https://github.com/pmuens/lab">lab repository</a> on <a href="https://github.com/pmuens">GitHub</a>.</p><p>Sometimes it's necessary to split existing data into several classes in order to predict new, unseen data. This problem is called <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification</a> and one of the algorithms which can be used to learn those classes from data is called Logistic Regression.</p><p>In this article we'll take a deep dive into the Logistic Regression model to learn how it differs from other regression models such as <a href="https://en.wikipedia.org/wiki/Linear_regression">Linear-</a> or <a href="https://en.wikipedia.org/wiki/Linear_regression#Simple_and_multiple_linear_regression">Multiple Linear Regression</a>, how to think about it from an intuitive perspective and how we can translate our learnings into code while implementing it from scratch.</p><h2 id="linear-regression-vs-logistic-regression">Linear Regression vs. Logistic Regression</h2><p>If you've read the post about <a href="https://philippmuens.com/linear-and-multiple-regression-from-scratch/">Linear- and Multiple Linear Regression</a> you might remember that the main objective of our algorithm was to find a best fitting line or <a href="https://en.wikipedia.org/wiki/Hyperplane">hyperplane</a> respectively.</p><p>To recap real quick, a line can be represented via the slop-intercept form as follows:</p><p>\[ y = mx + b \]</p><p>Here, \(m\) represents the slope and \(b\) the y-intercept.</p><p>In Linear Regression we've used the existing data to find a line in slope-intercept form (a \(m\) and \(b\) combination) which "best-fitted through" such data.</p><p>Extending the slope-intercept form slightly to support multiple \(x\) values and multiple slopes (we'll use \(\beta_n\) instead of \(m_n\)) yields the following:</p><p>\[ y = &nbsp;\beta_1x_1 + ... + \beta_nx_n + b \]</p><p>This "scaled-up" slope-intercept formula was used in the <a href="https://en.wikipedia.org/wiki/Linear_regression#Simple_and_multiple_linear_regression">Multiple Linear Regression</a> model to find the \(\beta\) and \(b\) values for the <a href="https://en.wikipedia.org/wiki/Hyperplane">hyperplane</a> which "best-fitted" the data. Once found we were able to use it for predictions by plugging in \(x\) values to get respective \(y\) values.</p><p>Linear Regression models always map a set of \(x\) values to a resulting \(y\) value on a <a href="https://en.wikipedia.org/wiki/Continuous_function">continuous</a> scale. This means that the \(y\) value can e.g. be \(0\), \(42\) or \(5.023.212\). How would we use such a Regression model if our \(y\) value is categorical such as a binary value which is either \(0\) or \(1\)? Is there a way to define a threshold so that a value such as \(42\) is assigned to the category \(1\) while a small value such as \(0.002\) gets assigned to the category \(0\)?</p><p>That's where Logistic Regression comes into play. With Logistic Regression we can map any resulting \(y\) value, no matter its magnitude to a value between \(0\) and \(1\).</p><p>Let's take a closer look into the modifications we need to make to turn a Linear Regression model into a Logistic Regression model.</p><h2 id="sigmoid-functions">Sigmoid functions</h2><p>At the very heart of Logistic Regression is the so-called <a href="https://en.wikipedia.org/wiki/Sigmoid_function">Sigmoid function</a>. A Sigmoid function is a class of functions which follows an S-shape when plotted.</p><p>The most prominent Sigmoid function is the so-called <a href="https://en.wikipedia.org/wiki/Logistic_function">Logistic function</a> which was developed by <a href="https://en.wikipedia.org/wiki/Pierre_Fran%C3%A7ois_Verhulst">Pierre Francois Verhulst</a> to model <a href="https://en.wikipedia.org/wiki/Population_growth">population grown</a>. It's mathematically described via this formula:</p><p>\[ f(x) = \frac{1}{1+e^{-x}} \]</p><p>Don't be intimidated by the math! Right now all you need to know is that this function takes any \(x\) value and maps it to a \(y\) value which ranges from \(0\) to \(1\).</p><p>Plotting the function for a range of \(x\) values proofs this claim and results in the aforementioned S-shape curve:</p><figure><img src="https://philippmuens.com/content/images/2020/06/zsigmoid_result.png"></figure><p>Note that the function gets closer and closer to the \(y\) value \(0\) or \(1\) as the \(x\) values get smaller or larger respectively. Also note that the \(x\) value \(0\) results in the \(y\) value \(0.5\).</p><p>This is exactly what we need. with this function we're able to "squish" any number, no matter its magnitude into a value ranging from \(0\) to \(1\). This makes the function outcome predictable which is useful when we later on define threshold values to associate function outputs with classes.</p><p>Let's turn the function into code:</p><pre><code>def sigmoid(x: float) -&gt; float:
    return 1 / (1 + exp(-x))

assert sigmoid(0) == 0.5</code></pre><p><strong><u>Note</u></strong>: Although there are many <a href="https://en.wikipedia.org/wiki/Sigmoid_function#Examples">different Sigmoid functions</a> to choose from, a lot of people use the name "Sigmoid function" when talking about the Logistic function. We'll adhere to this convention and use the term "Sigmoid function" as a synonym for Logistic function.</p><h2 id="from-linear-regression-to-logistic-regression">From Linear Regression to Logistic Regression</h2><p>Now that we've learned about the "mapping" capabilities of the Sigmoid function we should be able to "wrap" a Linear Regression model such as <a href="https://en.wikipedia.org/wiki/Linear_regression#Simple_and_multiple_linear_regression">Multiple Linear Regression</a> inside of it to turn the regressions raw output into a value ranging from \(0\) to \(1\).</p><p>Let's translate this idea into Math. Recall that our Multiple Linear Regression model looks like this:</p><p>\[ y = &nbsp;\beta_1x_1 + ... + \beta_nx_n + b \]</p><p>"Wrapping" this in the Sigmoid function (we use \(\sigma\) to represent the Sigmoid function) results in the following:</p><p>\[ y = \sigma(\beta_1x_1 + ... + \beta_nx_n + b) \]</p><p>Easy enough! Let's turn that into code.</p><p>The first thing we need to do is to implement the underlying Multiple Linear Regression model. Looking at the Math it seems to be possible to use the <a href="https://en.wikipedia.org/wiki/Dot_product">dot-product</a> to calculate the \(\beta\) and \(x\) part to which we then add the single \(b\) value.</p><p>To make everything easier to calculate and implement we'll use a small trick. Multyping a value by the identify \(1\) yields the value so we prepend \(1\) to the \(x\) values and \(b\) to the \(\beta\) values. This way we can solely use the dot-product calculation without the necessity to add \(b\) separately later on. Here's the mathematical formulation of that trick:</p><p>\[ \vec{x} = \begin{pmatrix} 1 \\ x_1 \\ ... \\ x_n \end{pmatrix} \vec{\beta} = \begin{pmatrix} b \\ \beta_1 \\ ... \\ \beta_n \end{pmatrix} \]</p><p>\[ y = \vec{x} \cdot \vec{m} = \sum_{i=1}^n x_i \beta_i = x_1 \times \beta_1 + ... + x_n \times \beta_n \]</p><p>Once we've calculated the dot-product we need to pass it into the Sigmoid function such that its result is translated ("squished") into a value between \(0\) and \(1\).</p><p>Here's the implementation for the <code>dot</code> function which calculates the <a href="https://en.wikipedia.org/wiki/Dot_product">dot-product</a>:</p><pre><code>def dot(a: List[float], b: List[float]) -&gt; float:
    assert len(a) == len(b)
    return sum([a_i * b_i for a_i, b_i in zip(a, b)])

assert dot([1, 2, 3, 4], [5, 6, 7, 8]) == 70</code></pre><p>And here's the <code>squish</code> function which takes as parameters the \(x\) and \(\beta\) values (remember that we've prepended a \(1\) to the \(x\) values and the \(b\) to the \(\beta\) values), uses the <code>dot</code> function to calculate the dot-product of \(x\) and \(\beta\) and then passes this result into the Sigmoid function to map it to a value between \(0\) and \(1\):</p><pre><code>def squish(beta: List[float], x: List[float]) -&gt; float:
    assert len(beta) == len(x)
    # Calculate the dot product
    dot_result: float = dot(beta, x)
    # Use sigmoid to get a result between 0 and 1
    return sigmoid(dot_result)

assert squish([1, 2, 3, 4], [5, 6, 7, 8]) == 1.0</code></pre><h2 id="the-intuition-behind-the-0-1-range">The intuition behind the 0-1 range</h2><p>We've talked quite a lot about how the Sigmoid function is our solution to make the function outcome predictable as all values are mapped to a \(0\) - \(1\) range. But what does a value in that range represent? Let's take a look at an example.</p><p>The following is a data set which describes how long students have studied for an exam and whether they've passed the exam given the hours they've studied.</p><!--kg-card-begin: html--><table>
    <thead>
        <tr>
            <th>Hours studied</th>
            <th>Exam Passed</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>0,5</td>
            <td>0</td>
        </tr>
        <tr>
            <td>1,0</td>
            <td>0</td>
        </tr>
        <tr>
            <td>1,5</td>
            <td>0</td>
        </tr>
        <tr>
            <td>2,0</td>
            <td>0</td>
        </tr>
        <tr>
            <td>2,5</td>
            <td>1</td>
        </tr>
        <tr>
            <td>3,0</td>
            <td>0</td>
        </tr>
        <tr>
            <td>3,5</td>
            <td>1</td>
        </tr>
        <tr>
            <td>4,0</td>
            <td>1</td>
        </tr>
        <tr>
            <td>4,5</td>
            <td>0</td>
        </tr>
        <tr>
            <td>5,0</td>
            <td>1</td>
        </tr>
        <tr>
            <td>5,5</td>
            <td>1</td>
        </tr>
        <tr>
            <td>6,0</td>
            <td>1</td>
        </tr>
    </tbody>
</table><!--kg-card-end: html--><p>Taking a glance at the data it seems to be that the more hours the students studied, the more likely they were to pass the exam. Intuitively that makes sense.</p><p>Let's plot the data to ensure that our intuition is correct:</p><figure><img src="https://philippmuens.com/content/images/2020/06/zmock_student_data.png"></figure><p>Looking at the plotted data we can immediately see that the values seem to "stick" to either the bottom or top of the graph. Given that it seems to be infeasible to use a Linear Regression model to find a line which best describes the data. How would this line be fitted through the data if the values we'd expect this line should produce are either \(o\) or \(1\)?</p><p>Let's try a thought experiment. What would happen if we've somehow found some coefficients \(\beta\) for the Linear Regression model which "best" describe the data and pass the result it computes through the Sigmoid function? Here's the graph from above with the Sigmoid function added to it:</p><figure><img src="https://philippmuens.com/content/images/2020/06/zmock_student_data_w_sigmoid.png"></figure><p>Looking at the plotting above we can see that the Sigmoid function ensures that the result from the "underlying" Linear Regression model is mapped onto a scale between \(0\) and \(1\), which in turn makes it possible to e.g. define a threshold at \(0.5\) to say that a value which is greater than \(0.5\) might be a predictor for a student passing the exam while a value less than \(0.5\) might mean that she'll fail the exam.</p><p>Note that the wording in the last sentence isn't a coincidence. The value the Signoid function produces can be interpreted as a probability where \(0\) means \(0%\) probability and \(1\) means a \(100%\) probability.</p><h2 id="the-probability-density-function">The Probability Density Function</h2><p>As it turns out we can translate our findings from the previous section into a function called <a href="https://en.wikipedia.org/wiki/Probability_density_function">Probability density function</a> or (PDF for short).</p><p>In particular we can define a <a href="https://en.wikipedia.org/wiki/Conditional_probability">conditional probability</a> which states that given some \(\beta\) and \(x_i\), each corresponding \(y_i\) should equal \(1\) with probability \(\sigma(\beta x_i)\) and \(0\) with probability \(1-\sigma(\beta x_i)\):</p><p>\[ P(y_i \mid \beta x_i) = \sigma(\beta x_i)^{y_i} \times (1-\sigma(\beta x_i))^{1-y_i} \]</p><p>Looking at the formula above it might be a mystery how we deduced it from our verbal description from above. Here's something I want you to try: Please apply the formula by setting \(y_i\) to \(0\) and after that to \(1\) and see what happens. What you'll notice is that depending on what value you set \(y_i\) to, only one part of the formula stays the same while the other is canceled out.</p><p>Here's what we'll end up with if we set \(y_i\) to \(0\) and \(1\):</p><p>\[ 1-\sigma(\beta x_i) \quad \textrm{if} &nbsp;y_i = 0 \]</p><p>\[ \sigma(\beta x_i) \quad \textrm{if} &nbsp;y_i = 1 \]</p><p>And that's exactly the desired behavior we described above.</p><h2 id="deriving-a-loss-function">Deriving a Loss function</h2><p>With Logistic Regression our main objective is to find the models \(\beta\) parameters which maximize the likelihood that for a pair of \(x\) values the \(y\) value …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://philippmuens.com/logistic-regression-from-scratch/">https://philippmuens.com/logistic-regression-from-scratch/</a></em></p>]]>
            </description>
            <link>https://philippmuens.com/logistic-regression-from-scratch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23640762</guid>
            <pubDate>Thu, 25 Jun 2020 13:54:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building GitHub-Style Hovercards with Stimulus and HTML-over-the-Wire]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23640713">thread link</a>) | @kwood
<br/>
June 25, 2020 | https://boringrails.com/articles/hovercards-stimulus/ | <a href="https://web.archive.org/web/*/https://boringrails.com/articles/hovercards-stimulus/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Somewhere along the way toward our current JavaScript hellscape, programmers decided that HTML was over. We’re done with it.</p>

<p>The emergence of tools like <a href="https://reactjs.org/docs/hello-world.html">React</a> shifted programmers away from writing HTML, instead writing <a href="https://reactjs.org/docs/introducing-jsx.html">JSX</a>, a fancier tag-based markup language that worked nicely inside your JavaScript.</p>

<p>Backends were then relegated to being dumb JSON API endpoints. Or if you were fancy and chasing upvotes, you’d use <a href="https://graphql.org/">GraphQL</a>!</p>

<p>But HTML? Yuck!</p>

<h2 id="a-brief-history-of-html-over-the-wire">A Brief History of HTML-over-the-wire</h2>

<p>One of the key pillars of Rails is to <a href="https://rubyonrails.org/doctrine/#integrated-systems">“Value integrated systems”</a>. While the industry moves towards microservices, highly decoupled front-ends and teams, and the siren song of Programming via LEGO Bricks, Rails leans into one system that does it all – termed the <a href="https://m.signalvnoise.com/the-majestic-monolith/">Majestic Monolith</a>.</p>

<p>Instead of rebuilding much of what already works in Rails in a client-side JavaScript MVC framework, apps like Basecamp, GitHub, and Shopify are able to achieve snappy page loads using the concept of “HTML-over-the-wire”.</p>

<p>In his <a href="https://www.youtube.com/watch?v=SWEts0rlezA">seminal RailsConf 2016 talk</a>, <a href="https://twitter.com/sstephenson">Sam Stephenson</a> walks through the pieces of this stack.</p>

<p>By using <a href="https://github.com/turbolinks/turbolinks">Turbolinks</a> (or similar libraries like <a href="https://github.com/defunkt/jquery-pjax">pjax</a> or <a href="https://inertiajs.com/how-it-works">Inertia</a>) and fast HTML responses (aided by caching and avoiding excessive database queries to get <a href="https://www.youtube.com/watch?v=eBccDerJPJE">sub-100ms response times</a>), you could build high performance pages, while still hanging on to the understated benefits of stateless HTTP responses and server-side logic.</p>

<p>As Sam points out, it was truly a “Golden Age of Web Development”.</p>

<p><img src="https://boringrails.com/images/golden-age.png" alt=""></p>

<p>So while much of the industry went down the JavaScript rabbit hole – creating new innovations for <a href="https://reactjs.org/docs/reconciliation.html">reactive rendering</a>, <a href="https://github.com/reduxjs/redux-thunk">functional</a> <a href="https://redux.js.org/">state management containers</a>, and <a href="https://reach.tech/router">approximately</a> <a href="https://github.com/ReactTraining/react-router">seventy</a> <a href="https://github.com/frontarm/navi">different</a> <a href="https://blog.remix.run/p/remix-preview">client-side</a> <a href="https://redwoodjs.com/docs/redwood-router">routing</a> <a href="https://github.com/4Catalyzer/found">libraries</a> – the quiet rebellion in Rails-land was honing these techniques and plugging along building apps out of boring server-rendered HTML.</p>

<p>We’re seeing a renaissance of these tools in 2020 and the excitement (at least in a small corner of the Twitter!) is reaching a fever pitch as Basecamp launches HEY: a fully-featured email client with a tiny JavaScript footprint that pushed the boundaries of the HTML-over-the-wire approach.</p>

<blockquote><div lang="en" dir="ltr"><p>🤯 Basecamp is building a fully-featured, in-browser email client...using a ridiculously small amount of JavaScript. A tiny keyboard shortcut lib, one polyfill, and boring old Stimulus/Turbolinks/Rails...</p><p>🙏 to <a href="https://twitter.com/dhh?ref_src=twsrc%5Etfw">@dhh</a> for generously shipping source maps, amazing learning resource <a href="https://t.co/IEAvwjiKeO">pic.twitter.com/IEAvwjiKeO</a></p></div>— matt swanson 🤔 🦢 (@_swanson) <a href="https://twitter.com/_swanson/status/1253037966710181892?ref_src=twsrc%5Etfw">April 22, 2020</a></blockquote>


<h2 id="turbolinks--stimulus-20xx-the-future">Turbolinks / Stimulus 20XX: The Future</h2>

<p>The stack in 2014-2016 was:</p>

<ul>
  <li>Turbolinks/pjax</li>
  <li>Rails UJS + <code>js.erb</code> templates (<a href="https://signalvnoise.com/posts/3697-server-generated-javascript-responses">Server-generated JavaScript Responses</a>)</li>
  <li>Heavy HTML fragment caching</li>
  <li>Rails Asset Pipeline and <a href="https://coffeescript.org/">CoffeeScript</a></li>
</ul>

<p>You can even trace the origin of these techniques back even further. I was recently <a href="https://twitter.com/chris_vannoy/status/1274682764948844545">sent a link</a> to a nearly 15 year old REST “microformat” called <a href="http://microformats.org/wiki/rest/ahah">“AHAH: Asynchronous HTML and HTTP”</a>, which is an early version of the same ideas we’re so excited about today. (You shouldn’t be surprised to see <a href="https://twitter.com/dhh">David Hansson</a> listed as a contributor!)</p>

<p>Now a “state-of-the-art” 2020 version also includes:</p>

<ul>
  <li><a href="https://stimulusjs.org/handbook/introduction">StimulusJS</a> (see also <a href="https://github.com/alpinejs/alpine">AlpineJS</a>) for lightweight event management, data binding, and “sprinkles” of behavior</li>
  <li>Partial updates with Turbolinks via a new <code>&lt;template&gt;</code> command approach (replacing <code>js.erb</code> and supporting <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/CSP">CSP</a>)</li>
  <li>Real-time Turbolinks updates via <a href="https://guides.rubyonrails.org/action_cable_overview.html">ActionCable</a> (see also <a href="https://docs.stimulusreflex.com/">StimulusReflex</a>/<a href="https://cableready.stimulusreflex.com/">CableReady</a>)</li>
  <li>First-party support for Webpack, ES6, and new CSS approaches like <a href="https://tailwindcss.com/">Tailwind</a> and <a href="https://purgecss.com/">PurgeCSS</a></li>
</ul>

<p>This stack is extremely powerful and the development experience allows you to really fly. You can build fast and interactive applications with a small team, all while still experiencing the joy of a 2014-era vanilla Rails codebase.</p>

<p>But years of a <a href="https://macwright.org/2020/05/10/spa-fatigue.html">JavaScript SPA-heavy monoculture</a> have made it hard to learn about this stack. The community is filled with practitioners, using the tools to build software and businesses. There simply has not been the same level of content produced and so many of these tools are unknown and can be unapproachable.</p>

<p>One of the ways I can contribute is to light the way for those want to know more by showing some real-world examples (not a <a href="http://todomvc.com/">TODO list</a> or a <a href="https://wsvincent.com/react-counter/">Counter</a>). Once you see how you can use tools like Stimulus and HTML responses to build features where you might instead reach for a tool like React, things will start to click.</p>

<h2 id="lets-build-something-real-hovercards">Let’s Build Something Real: Hovercards</h2>

<p>Hovercards show extra contextual information in a popup bubble when you hover over something in your app. You can see examples of this UI pattern on GitHub, Twitter, and even Wikipedia.</p>

<p><img src="https://boringrails.com/images/hovercard-examples.png" alt="Examples of hovercard UI"></p>

<p>This feature is really easy to build with Rails using an HTML-over-the-wire approach.</p>

<p>Here’s the plan:</p>

<ul>
  <li>Build a controller action to render the hovercard as HTML</li>
  <li>Write a tiny Stimulus controller to fetch the hovercard HTML when you hover</li>
</ul>

<p>…and that’s it.</p>

<p>We don’t need to make API endpoints and figure out how to structure all of the data we need. We don’t need to reach for React or Vue to make this a client-side component.</p>

<p>The beauty of this boring Rails approach is that the feature is dead-simple and it’s equally straightforward to build. It’s easy to reason about the code and super extensible.</p>

<p>For this example, let’s build the event feed for a sneaker marketplace app.</p>

<p><img src="https://boringrails.com/images/shoe-hovercard.gif" alt="Shoe feed hovercard example"></p>

<p>When you hover over a shoe, you see a picture, the name, the price, etc. Same for the user, you can see a mini-profile for each user.</p>

<h3 id="the-frontend-stimulus--fetch">The Frontend (Stimulus + fetch)</h3>

<p>The markup for the link looks like:</p>

<div><div><pre><code><span>&lt;!-- app/views/shoes/feed.html.erb --&gt;</span>

<span>&lt;div</span>
  <span>class=</span><span>"inline-block"</span>
  <span>data-controller=</span><span>"hovercard"</span>
  <span>data-hovercard-url-value=</span><span>"</span><span>&lt;%=</span> <span>hovercard_shoe_path</span><span>(</span><span>shoe</span><span>)</span> <span>%&gt;</span><span>"</span>
  <span>data-action=</span><span>"mouseenter-&gt;hovercard#show mouseleave-&gt;hovercard#hide"</span>
<span>&gt;</span>
  <span>&lt;%=</span> <span>link_to</span> <span>shoe</span><span>.</span><span>name</span><span>,</span> <span>shoe</span><span>,</span> <span>class: </span><span>"branded-link"</span> <span>%&gt;</span>
<span>&lt;/div&gt;</span>
</code></pre></div></div>

<p>Note: we are using the APIs from the <a href="https://github.com/stimulusjs/stimulus/pull/202">Stimulus 2.0</a> preview release!</p>

<p>One of the great features of Stimulus is that you can read the markup and understand what’s happening without diving into the JavaScript.</p>

<p>Without knowing anything else about the implementation, you could guess how it’s going to work: this link is wrapped in a <code>hovercard</code> controller, when you hover (via <code>mouseenter</code> and <code>mouseleave</code> events) the card is shown or hidden.</p>

<p>As recommended in <a href="https://boringrails.com/articles/better-stimulus-controllers/">Writing Better Stimulus Controllers</a>, you should pass in the URL for the hover card endpoint as a data property so that we can re-use the <code>hovercard_controller</code> for multiple types of cards. This also keeps us from having to duplicate the application routes in JavaScript.</p>

<div><div><pre><code><span>// app/javascript/controllers/hovercard_controller.js</span>

<span>import</span> <span>{</span> <span>Controller</span> <span>}</span> <span>from</span> <span>"</span><span>stimulus</span><span>"</span><span>;</span>

<span>export</span> <span>default</span> <span>class</span> <span>extends</span> <span>Controller</span> <span>{</span>
  <span>static</span> <span>targets</span> <span>=</span> <span>[</span><span>"</span><span>card</span><span>"</span><span>];</span>
  <span>static</span> <span>values</span> <span>=</span> <span>{</span> <span>url</span><span>:</span> <span>String</span> <span>};</span>

  <span>show</span><span>()</span> <span>{</span>
    <span>if</span> <span>(</span><span>this</span><span>.</span><span>hasCardTarget</span><span>)</span> <span>{</span>
      <span>this</span><span>.</span><span>cardTarget</span><span>.</span><span>classList</span><span>.</span><span>remove</span><span>(</span><span>"</span><span>hidden</span><span>"</span><span>);</span>
    <span>}</span> <span>else</span> <span>{</span>
      <span>fetch</span><span>(</span><span>this</span><span>.</span><span>urlValue</span><span>)</span>
        <span>.</span><span>then</span><span>((</span><span>r</span><span>)</span> <span>=&gt;</span> <span>r</span><span>.</span><span>text</span><span>())</span>
        <span>.</span><span>then</span><span>((</span><span>html</span><span>)</span> <span>=&gt;</span> <span>{</span>
          <span>const</span> <span>fragment</span> <span>=</span> <span>document</span>
            <span>.</span><span>createRange</span><span>()</span>
            <span>.</span><span>createContextualFragment</span><span>(</span><span>html</span><span>);</span>

          <span>this</span><span>.</span><span>element</span><span>.</span><span>appendChild</span><span>(</span><span>fragment</span><span>);</span>
        <span>});</span>
    <span>}</span>
  <span>}</span>

  <span>hide</span><span>()</span> <span>{</span>
    <span>if</span> <span>(</span><span>this</span><span>.</span><span>hasCardTarget</span><span>)</span> <span>{</span>
      <span>this</span><span>.</span><span>cardTarget</span><span>.</span><span>classList</span><span>.</span><span>add</span><span>(</span><span>"</span><span>hidden</span><span>"</span><span>);</span>
    <span>}</span>
  <span>}</span>

  <span>disconnect</span><span>()</span> <span>{</span>
    <span>if</span> <span>(</span><span>this</span><span>.</span><span>hasCardTarget</span><span>)</span> <span>{</span>
      <span>this</span><span>.</span><span>cardTarget</span><span>.</span><span>remove</span><span>();</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>This is all of the JavaScript we’re going to be writing for this feature: it’s only ~30 lines and we can use this for any other hovercards in the app. There isn’t really anything app specific about this controller either, you could pull it into a separate module and re-use it across projects. It’s totally generic.</p>

<p>The controller uses the <code>fetch</code> API to call the provided Rails endpoint, gets some HTML back, and then inserts it into the DOM. As a small improvement, we use the Stimulus <code>target</code> API for data binding to save a reference to the card so that subsequent hovers over this link can simply show/hide the markup without making another network request.</p>

<p><img src="https://boringrails.com/images/hovercard-network.gif" alt="Hovercard Network tab"></p>

<p>We also choose to remove the card when leaving the page (via the <code>disconnect</code> lifecycle method), but you could also opt to hide the card instead depending on how you want caching to work.</p>

<h3 id="the-backend-rails--server-rendered-html">The Backend (Rails + Server rendered HTML)</h3>

<p>There is nothing magic on the frontend and it’s the same story on the backend.</p>

<div><div><pre><code><span># config/routes.rb</span>
<span>Rails</span><span>.</span><span>application</span><span>.</span><span>routes</span><span>.</span><span>draw</span> <span>do</span>
  <span>resources</span> <span>:shoes</span> <span>do</span>
    <span>member</span> <span>do</span>
      <span>get</span> <span>:hovercard</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>Setup a route for <code>/shoes/:id/hovercard</code></p>

<div><div><pre><code><span># app/controllers/shoes_controller.rb</span>
<span>class</span> <span>ShoesController</span> <span>&lt;</span> <span>ApplicationController</span>
  <span>...</span>

  <span>def</span> <span>hovercard</span>
    <span>@shoe</span> <span>=</span> <span>Shoe</span><span>.</span><span>find</span><span>(</span><span>params</span><span>[</span><span>:id</span><span>])</span>

    <span>render</span> <span>layout: </span><span>false</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>Write a basic controller action, the only difference being that we set <code>layout: false</code> so that we do not use the global application layout for this endpoint.</p>

<p>You can even visit this path directly in your browser to quickly iterate on the content and design. The workflow gets even better when using a utility-based styling approach like Tailwind since you don’t even need to wait for your asset bundles to rebuild!</p>

<div><div><pre><code><span>&lt;!-- app/views/shoes/hovercard.html.erb --&gt;</span>

<span>&lt;div</span> <span>class=</span><span>"relative"</span> <span>data-hovercard-target=</span><span>"card"</span><span>&gt;</span>
  <span>&lt;div</span> <span>data-tooltip-arrow</span> <span>class=</span><span>"absolute bottom-8 left-0 z-50 bg-white shadow-lg rounded-lg p-2 min-w-max-content"</span><span>&gt;</span>
    <span>&lt;div</span> <span>class=</span><span>"flex space-x-3 items-center w-64"</span><span>&gt;</span>
      <span>&lt;%=</span> <span>image_tag</span> <span>@shoe</span><span>.</span><span>image_url</span><span>,</span> <span>class: </span><span>"flex-shrink-0 h-24 w-24 object-cover border border-gray-200 bg-gray-100 rounded"</span><span>,</span> <span>alt: </span><span>@shoe</span><span>.</span><span>name</span> <span>%&gt;</span>

      <span>&lt;div</span> <span>class=</span><span>"flex flex-col"</span><span>&gt;</span>
        <span>&lt;span</span> <span>class=</span><span>"text-sm leading-5 font-medium text-indigo-600"</span><span>&gt;</span>
          <span>&lt;%=</span> <span>@shoe</span><span>.</span><span>brand</span> <span>%&gt;</span>
        <span>&lt;/span&gt;</span>

        <span>&lt;span</span> <span>class=</span><span>"text-lg leading-0 font-semibold text-gray-900"</span><span>&gt;</span>
          <span>&lt;%=</span> <span>@shoe</span><span>.</span><span>name</span> <span>%&gt;</span>
        <span>&lt;/span&gt;</span>

        <span>&lt;span</span> <span>class=</span><span>"flex text-sm text-gray-500"</span><span>&gt;</span>
          <span>&lt;%=</span> <span>@shoe</span><span>.</span><span>colorway</span> <span>%&gt;</span>
          <span>&lt;span</span> <span>class=</span><span>"mx-1"</span><span>&gt;</span>
            <span>&amp;middot;</span>
          <span>&lt;/span&gt;</span>
          <span>&lt;%=</span> <span>number_to_currency</span><span>(</span><span>@shoe</span><span>.</span><span>price</span><span>.</span><span>to_f</span> <span>/</span> <span>100</span><span>)</span> <span>%&gt;</span>
        <span>&lt;/span&gt;</span>
      <span>&lt;/div&gt;</span>
    <span>&lt;/div&gt;</span>
  <span>&lt;/div&gt;</span>
<span>&lt;/div&gt;</span>
</code></pre></div></div>

<p>The hovercard is built with a server-rended ERB template, same as any other …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://boringrails.com/articles/hovercards-stimulus/">https://boringrails.com/articles/hovercards-stimulus/</a></em></p>]]>
            </description>
            <link>https://boringrails.com/articles/hovercards-stimulus/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23640713</guid>
            <pubDate>Thu, 25 Jun 2020 13:49:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apache Arrow Spark+AI Summit 2020]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23640428">thread link</a>) | @cocobro
<br/>
June 25, 2020 | https://rohanhonwade.com/posts/apache-arrow-spark-ai-summit/ | <a href="https://web.archive.org/web/*/https://rohanhonwade.com/posts/apache-arrow-spark-ai-summit/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
		<header>
			
		</header>
		
		<main role="main">
		
<article>
	<p>The Spark + AI summit for 2020 is currently happening from June 22nd to June 26th. There were talks by big names in the industry like Matei Zaharia
and even by Nate Silver from fivethirtyeight.com. There were multiple topics being talked about simultaneously and it was a difficult to just
pick one to listen to as all of them seemed interesting! I took some time to listen to Tomer Shiran, the founder of the Dremio project about the origins,
the need and use cases of Apache Arrow and how they used it in Dremio alongside the Apache Arrow Gandiva.</p>
<h2 id="the-data-querying-conundrum-in-data-lakes-paradigm">The data querying conundrum in Data Lakes paradigm</h2>
<p>Data Lakes are the talk of the town today! In today’s age where data is the chief asset that companies prize, they don’t want to lose any of it
and would rather have it stored in a Data Lake even if it does not make much sense to them right now, with the prospect of it being useful at a
later point in time. That very point makes the data unwieldy.</p>
<p>In such a scenario, when your data store has vast amounts of data, querying becomes slow because it is not just that the data is big but that
transferring data over the network when you query such stores also becomes a non-trivial factor. To get around this problem, companies again
copy part of their data from the Data Lake into Data Warehousing solutions like AWS Redshift. They then construct their OLAP cubes and
aggregations on top of this for fast querying of the underlying data. The drawback of this is that the flexibility of doing anything else with
this data reduces as you copy it into the Data Warehouse. This is the problem that the folks at Dremio / Apache Arrow are trying to solve -
how do you query your data directly from the Data Lake without having to copy it anywhere else?</p>
<h2 id="dremio">Dremio</h2>
<p>The folks at Dremio claim that they have built technology to query Data Lakes with 4 to 100 times better performance than existing solutions. The
way they were able to do it is by defining and implementing a new standard - Apache Arrow, of storing data in-memory in a columnar format for efficient
operations on today’s hardware. I will talk more about Apache Arrow later in this article.</p>
<p>Following are some features that power Dremio -</p>
<h3 id="data-reflections">Data Reflections</h3>
<p>Dremio creates a view of your data, an optimized data structure that lends itself well to boost different query patterns. This data structure can
also auto refresh itself.</p>
<h3 id="columnar-cloud-cache-c3">Columnar Cloud Cache (C3)</h3>
<p>The Columnar Cloud Cache feature takes advantage of local storage (generally NVMe - non-volatile memory express) for a distributed real time
caching solution that increases the amount of read throughput and reduces the amount of data transferred over the network. It is automatic, does
not need any user involvement and caches data based on SQL query patterns, workload management and file directory structures to optimize what to
store and evict.</p>
<h3 id="predictive-pipelining">Predictive Pipelining</h3>
<p>Dremio can predict access patterns of data which reduces its query response times. Based on usage patterns of analytical workloads and their understanding
of columnar data format, the Dremio folks provide this feature wherein they fetch data only before execution engine needs it.</p>
<h2 id="difference-between-dremio-and-facebooks-presto">Difference between Dremio and Facebook’s Presto</h2>
<p>Presto by Facebook is a distributed SQL engine over multiple data sources. Dremio offers more features on top of that. It sits between your
data over disparate sources and you who want an analysis of your data - it squashes the need for data warehousing solutions, OLAP cubes,
extracts and aggregations.</p>
<ul>
<li>Dremio claims to offer speeds of interactive nature with data of any volume</li>
<li>It has deep integrations with some data stores and is thus able to push down some compute when queries are made over those data sources</li>
<li>It is able to show how different datasets are related to each other by creating a lineage of data</li>
</ul>
<h2 id="apache-arrow">Apache Arrow</h2>
<p>Apache Arrow is a specification for storing data in a columnar format in memory, serializing the metadata and for transferring data over the network.
It uses Google Flatbuffers for metadata serialization. It was born out of Dremio’s internal memory format.</p>
<p>It provides constant time random access, data adjacency for sequential scans and lends itself easily for SIMD (single instruction, multiple data)
class of instructions in modern processors.</p>
<p>It serializes data as Arrow buffers / vectors which are basically arrays of the same size with different data types. This whole package together
constitutes its schema.</p>
<h2 id="gandiva">Gandiva</h2>
<p>Gandiva is a part of Dremio which provides a high performance execution engine over Apache Arrow data buffers. Gandiva takes a sql expression,
compiles it into LLVM bytecode and translates it to machine code. To get this high performance it is written in C++.</p>
<p>Tomer wrapped up the talk on Dremio with a demo of the platform as well.</p>
<p>Go give Dremio a try!</p>

</article>

		</main>
		
		
		
		
	</div></div>]]>
            </description>
            <link>https://rohanhonwade.com/posts/apache-arrow-spark-ai-summit/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23640428</guid>
            <pubDate>Thu, 25 Jun 2020 13:24:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Programming Shapes the Mind]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23640214">thread link</a>) | @pcmaffey
<br/>
June 25, 2020 | https://www.pcmaffey.com/how-programming-shapes-the-mind | <a href="https://web.archive.org/web/*/https://www.pcmaffey.com/how-programming-shapes-the-mind">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>What we pay attention to <a href="https://lithub.com/how-we-pay-attention-changes-the-very-shape-of-our-brains/" target="_blank">changes the shape of our brain</a>. Like water running through a landscape day after day after day, the neural pathways used in our work and routines cut familiar channels that give rise to the ecosystems of our mind. But paying attention is naturally selective. When we choose what to focus on, we are also choosing what to ignore.</p><p>I’ve been programming on and off since the 20th century. I see marked differences in myself, my behavior, perception, etc. when actively coding vs. not. It's finally time to investigate. What am I really paying attention to when programming? What are the implications?</p><p><i>And for the reader, what is your experience? Similar? Different? Or if you’re not a programmer, how does your discipline shape your perception?</i></p><p>When programming, I am writing the future. Every line of code is an instruction to be carried out predictably, if all goes well, a billion times over. Bits of simple logic—compounded across programs stacked on giant stacks of programs—create complex systems of logical inevitabilities.</p><p>To accomplish this, every command I write exercises a tiny mental loop:</p><ul><li><b><nobr>Step 1: </nobr></b><span>Research and understand the “inner logic” of relevant systems.</span></li><li><b><nobr>Step 2: </nobr></b><span>Formulate a hypothesis that models some new bit of logic.</span></li><li><b><nobr>Step 3: </nobr></b><span>Validate and iterate.</span></li></ul><p>Does it work? I test my code and expect an immediate response from the compiler. If yes, I move on to the next bit of logic in my day's lineup. If no, I retest my underlying arguments, breaking down my code into smaller and smaller bits. Every step of the way, my attention walks as efficiently as possible, a garden of forking yes/no paths. It's as if it were me, and not just an electric current, running through the logic gates of my computer’s circuit board.</p><p>When our brain focuses its attention, neuromodulators amplify its activated neural circuits. Like a spotlight on stage, the "speaking" actor is lit up. And likewise, the rest of the stage is intentionally dimmed. We actively suppress competing areas of the brain <code>"with slow waves in the alpha frequency band (between eight and twelve hertz), which inhibit a circuit by preventing it from developing coherent neural activity."</code></p><p>What part of my brain am I suppressing when I spend all day coding? The easy and obvious answer would be the opposite of logic—something to do with emotion. There’s certainly not much place for emotion in programming. This may influence why some of us gravitate more to front-end development—to be not so far from people. Or vice versa. But does programming suppress emotion? Let’s explore deeper.</p><h2>The Good</h2><p>I <a title="Click to expand">learned to code on LSD.</a><sup title="Click to expand">*</sup> Twenty-some years later, there are a few things I love about software development. But none more than the way it encourages and rewards mental plasticity through constant learning and unlearning.</p><p>We break systems apart in order to understand the imperative logic that glues them together. In the game of programming, the rules are entirely knowable… with enough digging. Somewhere, at some point in time, someone wrote them (and hopefully documented them). Debugging feels like the archeology of quirks, from programs layered atop older programs. There’s a real joy in discovery when we unlock a path forward. Over time, this clarity develops into confidence, and we approach systems knowing that yes, if needed, we could do the work to understand any part of this. Fortunately, this is far from what’s usually required; we rarely go deeper than the syntax and grammar of our immediate environment. But our environment still is always changing, and so we must always be learning.</p><p>The second joy of programming: I can build something out of nothing—or more specifically, out of logic and electricity. I’ve built with stone, wood, ink, plastic, etc. The freedom afforded by code is unique and specific—a kind of scalable mental scaffolding. Logically valid patterns can repeat ad infinitum into some functional space, limited for the most part only by their utility.</p><p>For me, programming enhances this way of seeing, which carries over into other areas of my life. My chess game improves drastically when actively coding. I see more clearly defined the risks and consequences of a position. Things seem more obvious, inevitable. I can break down an argument into its key dependencies, find flaws, and put it all back together efficiently optimized towards some solution. My mind begins to resemble the programs I work on.</p><h2>The Bad</h2><p>My mind begins to resemble the programs I work on. The ability to build applications is empowering; but I lose power when I become just another program in the stack for people to input instructions and expect outputs. I’ve seen it throughout my career. No one wants to be a code monkey. And yet, it’s a natural consequence of specialization. Developers are inevitably busy writing code all day, not talking to people. Yes, we’re a strange bunch to begin with, and to follow the stereotype, likely more comfortable with computers than people anyways. But it seems our work reinforces our role as awkward, estranged mental laborers.</p><p>I’d thought I could hack life with the same ease I could hack a program. But life is not an abstract model of logic where outcomes are inevitable and predictable. From where I stand as a microscopic organism inside an unknown number of infinite universes, math can only solve for so much. Certainly, many of society’s rules can be gamed. My heightened logic serves me well in certain domains. But, I struggle too—there’s a price I pay for spending days programming.</p><p>It’s difficult to be exact talking about this, but I feel it strongly in 3 areas of my life:</p><ul><li><b><nobr>1.</nobr></b><span>As I get older, the health impacts—physical and mental—become more apparent. I sit (or sometimes stand) staring into an artificial sun. My body becomes disoriented by space and time. My mind gets wound up, locked into the gears of software. My eyes go dim and blurry. Hiking with the dogs for an hour at the end of every day helps, but it’s not enough. I still find myself reaching for an easy jolt back to reality, often in the form of a drink.</span></li><li><b><nobr>2.</nobr></b><span>Programming requires a quite specific mental model that makes it difficult to balance in parallel with other, more creative activities (making art, creative writing, cooking, etc.). They all struggle for my attention like children with divergent needs. It’s not so simple as time boxing activities and switching modalities, as I have to travel half way around my mind to get from one headspace to another. Too often, I end up stuck wasting my time commuting between <a title="Click to expand">competing mindsets.</a><sup title="Click to expand">*</sup></span></li><li><b><nobr>3.</nobr></b><span>Finally, and perhaps the most significant consequence: I find it challenging to relate to others when in the mindset of programming. After spending my day communicating with the compiler in encoded logic, writing commands, and expecting immediate responses, talking with a human feels slow and inefficient.</span></li></ul><p>This last point is a bit of a trope, so I want to expand. When my attention is zeroed in programming, it’s not emotion that my mind suppresses, but rather, my ability to listen, to really listen. I notice it when talking with my wife (with whom I have 10+ years of observed patterns). After a day of programming, I hear her “inputs” and I can “output” the appropriate answer. But I lose touch with her human experience. What’s not explicitly defined ceases to register. Unless I’m being intentional about it, programming often degrades my capacity for empathy.</p><p>Empathy requires a different relationship to the unknown. It enables us to “hold space” for the valid, yet truly unknowable experience of another person. It saves us from projecting our ideas of ourselves, filled with expectations and judgements, into that space. That’s not to say we don’t try to understand or pattern-match. Or that we don’t share our own experience in response. It’s just that there’s no equation that can solve for two peoples life, history, genetics, etc. We try, of course, with derivatives, approximations, and metaphor. But this is where logic ends and art begins.</p><h2>The Unknown</h2><p>So what? Programming supports my way of life, my family. These side-effects are collateral damage. But I know that by seeking to understand them, I can at least begin to address negative impacts.</p><p>Perhaps, this is just one man’s experience and not something I should generalize. But my curiosity beckons, if what I’m writing about is an experience at all common to programmers, what are the implications?</p><h3>1. Can we find a healthier, more sustainable balance with programming?</h3><p>This obviously applies to computer work in general; the physical constraints and proposed solutions are well-documented—good ergonomics, exercise, etc. But on the mental side, how do we ground ourselves during a day spent riding the proverbial lightning? Stretched across the course of a career, how does this contribute to programming being a “young person’s game,” where individual contributors as they get older burn out and switch to manager roles?</p><h3>2. Looking through the wide-angle lens: is our work’s suppression of empathy at the root of the tech-lash?</h3><p>Tech has a lossy view of the human experience. We are degraded to a few million data points. Emotion is gamified for attention, dollars, and worse. Human activity online can be easily modeled by a bot. It's common to marvel at how advanced bots and algorithms have become. But on the flip side, it reveals how shallow our models of the human experience online actually are, that a few automated clicks and some NLP can fool us.</p><p>As they say, we only improve what we measure. But we don’t measure what we don’t know. We don’t talk about empathy because it’s not a variable or a metric in any of our systems. So how can we make space for empathy in our programs as they continue to eat the world?</p><h3>3. A final thought on the future of programming</h3><p>We're entering the terrain of science-fiction here, but what would it mean to program for empathy, to encode it in our systems? Here's one possible requirement: can our programs ever account for unknowable truths?</p><p>Pe…</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.pcmaffey.com/how-programming-shapes-the-mind">https://www.pcmaffey.com/how-programming-shapes-the-mind</a></em></p>]]>
            </description>
            <link>https://www.pcmaffey.com/how-programming-shapes-the-mind</link>
            <guid isPermaLink="false">hacker-news-small-sites-23640214</guid>
            <pubDate>Thu, 25 Jun 2020 13:04:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What vertical farming and ag startups don't understand about agriculture, part 2]]>
            </title>
            <description>
<![CDATA[
Score 120 | Comments 118 (<a href="https://news.ycombinator.com/item?id=23640011">thread link</a>) | @kickout
<br/>
June 25, 2020 | http://thinkingagriculture.io/what-sv-doesnt-understand-about-agriculture-part-ii/ | <a href="https://web.archive.org/web/*/http://thinkingagriculture.io/what-sv-doesnt-understand-about-agriculture-part-ii/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-20">
		
	
	<div>
		
<p>Some commenters (/u/coderintherye chain notably) on the <a href="https://news.ycombinator.com/item?id=23630201">HN post</a> of the <a href="https://thinkingagriculture.io/what-silicon-valley-doesnt-understand-about-agriculture/">original article</a> brought up good points that I wanted to expand on and provide some additional context. Also for clarification: although farming is truly global, most ‘farming’ I refer to pertains to the United States (<a href="https://en.wikipedia.org/wiki/Agriculture_in_the_United_States">which is an agriculture juggernaut</a>), but in my experience should reasonably translate across agriculture zones (pending equivalent laws and climatic factors).</p>



<p><strong><em>There is ample VC money for Ag startups</em></strong></p>



<p>The original intention of the article wasn’t to bemoan the lack of capital available for <a href="https://agiowa.com/portfolio/">founders focused on agriculture</a> (there is actually plenty of capital–check out <a href="https://agfundernews.com/">AgFunderNews</a> for examples of successful raises). Instead, it is a recommendation for anyone entering the space to understand the industry and its history to harness existing synergies rather than try and swim upstream. Watching capital go to ‘solved’ problems is painful, because there are many opportunities for a unicorn ag startup if aimed in the correct space. Vertical farming for non-vegetables (or fruits) is likely dead-on-pitch. Yes, vertical farming <em>is</em> and <em>could be</em> successful, but those markets are very specific and probably 10x smaller than people think. Nice businesses no doubt, but not market shaping behemoths VCs are after. Agriculture is rightfully a commodity and the market will brutalize ideas/companies that can’t turn a profit. One bad year (droughts in 2011 and 2012 in the US Midwest) from external forces can absolutely put farmers out of business. Indoor farming has all of the risks of outdoor ag–and more! Indoor farming requires water (whose source can dry up and get shut off unexpectedly, just like a drought), has pests, and requires artificial lighting (power outage for 5 days? Uh oh). Herbicides (and sometimes pesticides) are actually an example of innovation pre-SV. Alternate technologies (i.e mechanical) didn’t work or were uneconomical for the time period; thus, chemical solutions seemed to thrive (glyphosate/glufosinate resistant corn/soy/wheat/cotton/sugar beets &amp; <a href="https://agrilife.org/lubbock/files/2020/02/BtTraitTable_FEB_2020.pdf">BT resistance for insects</a>). I predict in next 5-20 years we see that flip, where chemical and biological solutions fall out in favor of mechanized solutions (who wouldn’t want a semi-autonomous robot pulling weeds in fields in favor of a chemical solution that is <a href="https://www.nbcnews.com/news/us-news/bayer-reaches-10-5-billion-settlement-roundup-cancer-lawsuits-n1232026">open to litigation</a>)? We just have too little understanding of 2nd and 3rd order effects of disrupting nature at this scale (<a href="https://www.nature.com/articles/s41598-019-49660-6">gene drives included</a>, as promising as they appear) using these incredibly effective chemicals.</p>



<p><strong><em>Financing in the Heartland</em></strong></p>



<p>I won’t speak of financing agricultural operations in a municipality not located in the United States, as even understanding the US situation takes time and effort. Let’s be clear though: Most farmers <em>need</em> to borrow capital just to operate for a given year (hence, there is a note called an ‘operating loan’) and financing agriculture operations is more and more important as the size of farms increases. They buy seed, fertilizer, feed, chemicals, etc. to be able to produce an output to then (hopefully) sell at a profit–all to rinse and repeat. Buying big expensive new tractors ($300k+ USD), buildings to store the machines, grain storage, fencing, animal houses–all generally require a loan. Because of the huge cost to purchase these necessities, financing institutions generally need to have a <em>very</em> thorough understanding of the operation (Only farm 160 acres of corn,soy,or wheat? Good luck buying equipment). So bankers have become very good (not perfect) at evaluating and swaying farming practices to ensure maximum likelihood of repayment. Seriously, check of the used auction prices of ag machinery sometime–<a href="https://www.bigiron.com/Lots/2011JohnDeere8335RMFWDTractor-3">this tractor</a> is 10 years old and commands the price of a new Tesla. Is ag financing a place that needs disruption? Likely no because ag lending has evolved hand-in-hand in rural communities where agricultural production is the predominant industry. Because they evolved with ag, they likely have already captured the +EV that startups tend to seek because their very existence depends on it. So where <em>are</em> the value proposition? I know nothing of their founding, but the previous auction link is from <a href="https://www.bigiron.com/">Big Iron Auctions</a> and those founders likely understood ag (“hey, there is a robust secondary market for farm machinery”) and created on-line version of it–with what appears to be great success. I’d imagine these on-line secondary markets exist in Brazil and Eastern Europe given there agriculture exposure. </p>



<p><strong><em>Success Stories</em></strong></p>



<p>There are some truly incredible examples of engineering and innovation in agriculture that focus on the mechanization and scale <em>that already exists</em>. Transplanting vegetables in the Central Valley (CA) used to be labor intensive–<a href="https://www.planttape.com/">this brilliant solution solved that</a>. Auto-steer <a href="https://www.fieldbee.com/blog/fieldbee-tractor-autosteer-versus-other-systems/">systems</a> that leverage machinery that already exists. Sometimes the innovation is statistical/computation (<a href="https://www.annualreviews.org/doi/full/10.1146/annurev-animal-021815-111422">genomic prediction has revolutionized dairy cattle</a>) Starting businesses is hard and agriculture is no different.</p>



<p>Stay away from vertical farming–unless you plan on growing saffron or figure out a way to cultivate morel mushrooms!</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article></div>]]>
            </description>
            <link>http://thinkingagriculture.io/what-sv-doesnt-understand-about-agriculture-part-ii/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23640011</guid>
            <pubDate>Thu, 25 Jun 2020 12:44:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Java's Stream Implementation with Go Generics]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23639960">thread link</a>) | @shagabutdinov
<br/>
June 25, 2020 | https://snake-ci.com/blog/go2go-stream/ | <a href="https://web.archive.org/web/*/https://snake-ci.com/blog/go2go-stream/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
									<div>
										
										<p>The Go team recently released a new post in the Go blog called
<a href="https://blog.golang.org/generics-next-step">Â«The Next Step in GenericsÂ»</a> and updated the design draft on
<a href="https://go.googlesource.com/proposal/+/refs/heads/master/design/go2draft-type-parameters.md">Â«Type ParametersÂ»</a> (a long one).</p>

<p>In the current post I’m going to describe how to port Java’s Stream to Go 2 Generics.</p>

<p>Let’s make it straightforward â€” define the Stream:</p>

<pre><code>type Stream(type Type) struct {
	slice    []Type
	parallel bool
}
</code></pre>

<p>Here we declare a new type using type parameter <code>Type</code> with underlying slice <code>[]Type</code>.</p>

<p>And let’s have a constructor:</p>

<pre><code>func Of(type Type)(slice []Type) *Stream(Type) {
	return &amp;Stream(Type){
		slice: slice,
	}
}
</code></pre>

<p>The parameter <code>(type Type)</code> after name of function and in type declaration is Type Parameter.
The type parameter is required whenever we are going to use generics.</p>

<p>Now we can implement core functions of a typical stream:</p>

<ul>
<li>Filter</li>
<li>Map</li>
<li>Reduce</li>
<li>ForEach</li>
<li>Collect</li>

<li><p>AnyMatch/AllMatch/NoneMatch</p>

<pre><code>func (stream *Stream(Type)) Filter(predicate func(Type) bool) *Stream(Type) {
	filtered := []Type{}
	for _, item := range stream.slice {
		if predicate(item) {
			filtered = append(filtered, item)
		}
	}
	stream.slice = filtered
	return stream
}

func Map(type Type, R)(stream *Stream(Type), predicate func(Type) R) *Stream(R) {
	slice := make([]R, len(stream.slice))
	for i, item := range stream.slice {
		slice[i] = predicate(item)
	}
	return Of(slice)
}

func Reduce(type Type, R)(stream *Stream(Type), predicate func(R, Type) R) R {
	var result R
	for _, item := range stream.slice {
		result = predicate(result, item)
	}
	return result
}

func (stream *Stream(Type)) ForEach(predicate func(Type)) *Stream(Type) {
	for _, item := range stream.slice {
		predicate(item)
	}
	return stream
}
</code></pre></li>
</ul>

<p>Notice that Map and Reduce functions are not declared on <code>Stream(Type)</code>. It’s one of unsolved problems of current generics
design draft â€” parametrized methods are not permitted.</p>

<p>It means that we can have a function that receives type <code>A</code> and returns type <code>B</code>:</p>

<pre><code>func foo(type A, B) (a A) B
</code></pre>

<p>But we can’t declare a parametrized method on type <code>Struct(A)</code> like this:</p>

<pre><code>func (s Struct(A)) foo(type B) (a A) B
</code></pre>

<blockquote>
<p>This design draft does not permit methods to declare type parameters that are specific to the method. The receiver may
have type parameters, but the method not add any type parameters.
<a href="https://go.googlesource.com/proposal/+/refs/heads/master/design/go2draft-type-parameters.md#no-parameterized-methods">Quote from the updated design draft</a></p>
</blockquote>

<p>It’s time for the cherry on top â€” <code>Stream(Type).Collect()</code>.</p>

<p>The signature of Collect function will be pretty simple:</p>

<pre><code>func Collect(type Type, Col)(
	stream *Stream(Type),
	collector collector.Collector(Type, Col),
) Col
</code></pre>

<p>Notice that now we have two type parameters â€” one for original type that was used for creating a stream and another one
for resulting collection.</p>

<p>Here is a interface for a typical collector that consists of four functions:</p>

<ul>
<li><code>Supply()</code> â€” a function that creates and returns a new result container.</li>
<li><code>Accumulate()</code> â€” a function that folds a value into a mutable result container.</li>
<li><code>Combine()</code> â€” a function that accepts two partial results and merges them. This is going to be used only in parallel mode.</li>

<li><p><code>Finish()</code> â€” while in Java this method converts from an intermediate type to the final result type, but in order to save
the simplicity of the implementation, it will return the same type.</p>

<pre><code>type Collector(type Type, Col) interface {
	Supply() Col
	Accumulate(Col, Type) Col
	Finish(Col) Col
	Combine(Col, Col) Col
}
</code></pre></li>
</ul>

<p>Now we have the interface, we need an implementation. But since we want to allow developers to add
their own implementations without declaring new types, we need a constructor that will accept functions, think of it
like <code>http.HandleFunc()</code> which is often used to wrap functions and returns <code>http.Handler</code>.</p>

<p>We will declare a new constructor for <code>Collector(Type, Col)</code> like we did for <code>Stream(Type)</code> that will return unexported
implementation of <code>Collector(Type, Col)</code> that will just call the given functions:</p>

<pre><code>func Of(type Type, Col)(
	supply func() Col,
	accumulate func(Col, Type) Col,
	finish func(Col) Col,
	combine func(Col, Col) Col,
) Collector(Type, Col) {
	return impl(Type, Col){
		supply:     supply,
		accumulate: accumulate,
		finish:     finish,
		combine:    combine,
	}
}
</code></pre>

<p>Notice that we also have to specify <code>(Type, Col)</code> for <code>Collector</code> even though we specified it later <code>impl(Type, Col)</code>.</p>

<p>The <code>impl(Type, Col)</code> type is going to be a holder of functions that implements the <code>Collector(Type, Col)</code> interface:</p>

<pre><code>type impl(type Type, Col) struct {
	supply     func() Col
	accumulate func(Col, Type) Col
	finish     func(Col) Col
	combine    func(Col, Col) Col
}

func (collector impl(Type, Col)) Supply() Col {
	return collector.supply()
}

func (collector impl(Type, Col)) Accumulate(collection Col, item Type) Col {
	return collector.accumulate(collection, item)
}

func (collector impl(Type, Col)) Finish(collection Col) Col {
	if collector.finish == nil {
		return collection
	}
	return collector.finish(collection)
}

func (collector impl(Type, Col)) Combine(collection1, collection2 Col) Col {
	return collector.combine(collection1, collection2)
}
</code></pre>

<p>Here we’re good, now let’s declare a simple collector that is going to convert a <code>Type</code> to <code>Map[Key]Value</code> â€” <code>ToMap</code>:</p>

<pre><code>func ToMap(type Type interface{}, Key comparable, Value interface{})(
	mapper func(Type) (Key, Value),
	accumulator func(Value, Value) Value,
) Collector(Type, map[Key]Value) {
	return Of(
		func() map[Key]Value {
			return map[Key]Value{}
		},
		func(table map[Key]Value, item Type) map[Key]Value {
			key, value := mapper(item)
			now, _ := table[key]
			table[key] = accumulator(now, value)
			return table
		},
		func(table map[Key]Value) map[Key]Value {
			return table
		},
		func(table1, table2 map[Key]Value) map[Key]Value {
			for k2, v2 := range table2 {
				v1, _ := table1[k2]
				table1[k2] = accumulator(v1, v2)
			}
			return table1
		},
	)
}
</code></pre>

<p>An interesting thing about this function is that while it has three separated type parameters, it returns
<code>Collector(Type, map[Key]Value)</code> that uses only two type parameters.</p>

<p>Note that we need to specify Type Constraint for Key <code>comparable</code> in order to use it as key of a map otherwise it just
wouldn’t work.</p>

<p><code>ToMap</code> expects two functions on input:</p>

<ul>
<li>Mapper <code>func(Type) (Key, Value)</code> â€” receives an original element and returns two values: first one is going to be used as key
of the map, and the second one is going to be used as the value of the map[key]</li>
<li>Accumulator <code>func(now Value, update Value) Value</code> â€” receives current value of map[key] and new value <code>update</code> that have to be
somehow accumulated into <code>now</code>.</li>
</ul>

<p>Let’s see how it will work out on practice:</p>

<ol>
<li><p>Declare a simple type that will describe a movie and a score that a user gave to the movie:</p>

<pre><code>type MovieVote struct {
	Name  string
	Score int
}
</code></pre></li>

<li><p>Create a stream of slice of some movies and user votes:</p>

<pre><code>items := stream.Of(
	[]MovieVote{
		{Name: "A", Score: 1},
		{Name: "A", Score: 2},
		{Name: "B", Score: 9},
		{Name: "B", Score: 10},
		{Name: "B", Score: 8},
		{Name: "C", Score: 7},
		{Name: "C", Score: 8},
		{Name: "C", Score: 7},
	},
)
</code></pre></li>

<li><p>Now let’s convert them into <code>map[Name]SumOfScore</code>:</p>

<pre><code>result := stream.Collect(
	items,
	collector.ToMap(MovieVote, string, int)(
		func(movie MovieVote) (string, int) {
			return movie.Name, movie.Score
		},
		func(total, score int) int {
			return total + score
		},
	),
)
fmt.Println(result)
</code></pre></li>
</ol>

<ul>
<li>The mapper returns name as key and score as value</li>
<li>The accumulator sums total and current score</li>
</ul>

<p>Output:</p>

<pre><code>map[A:3 B:27 C:22]
</code></pre>

<p>By the way, this collector also works in Parallel mode, check it out in the source code:</p>

<ul>
<li><a href="https://github.com/reconquest/goava/blob/master/stream/examples_test.go2#L91">how to use with Parallel()</a></li>
<li><a href="https://github.com/reconquest/goava/blob/master/stream/stream.go2#L148">implementation of concurrent Collect() using Combine()</a></li>
</ul>

<p>Source Code is available on GitHub: <a href="https://github.com/reconquest/goava">github.com/reconquest/goava</a></p>

<p>And a big shout-out to Matt Layher for his article about <a href="https://mdlayher.com/blog/go-generics-draft-design-building-a-hashtable/">building a hashtable with new Go generics</a>!</p>

<p>Cool stuff, heh!</p>

									</div>
								</div></div>]]>
            </description>
            <link>https://snake-ci.com/blog/go2go-stream/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23639960</guid>
            <pubDate>Thu, 25 Jun 2020 12:38:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I overcame YouTube addiction and you should too]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23639870">thread link</a>) | @goddamnsteve
<br/>
June 25, 2020 | https://praveenjuge.com/blog/how-i-overcame-youtube-addiction/ | <a href="https://web.archive.org/web/*/https://praveenjuge.com/blog/how-i-overcame-youtube-addiction/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article itemscope="" itemtype="http://schema.org/BlogPosting"><hr><p itemprop="description">I don't use social media often, that's by design. I know if I start using it regularly, I will become addicted to it. So, imagine my surprise when on one Sunday afternoon I found out that I spent the entire day doing nothing but watching videos on YouTube.</p><p>The saddest thing is that I didn’t even remember what I was watching. It was just a clockwork for my brain at that point. Wake up, open YouTube, watch a video, continue watching videos.</p><p>I write this blog on another Sunday afternoon, almost three months after, to say that I watched YouTube for just 10 minutes this week to watch a work-related video that a colleague sent.</p><p>I’m a little proud of myself, to tell the truth.</p><p>This is a log of everything I did to overcome this addiction. If it helped me, it might help someone else too.</p><h2 id="how-and-why-i-became-addicted">How and Why I Became Addicted</h2><p>YouTube is a community where billions of people share their talents, interests and findings with you.</p><p><strong>That’s the hook.</strong></p><p>The <strong>real</strong> YouTube is a billion-dollar company where hundreds of researchers and designers manipulate an algorithm to deliver a low-quality video to you.</p><p>I thought about why I was addicted for a long time. It basically was three things,</p><ul><li>Types of videos I watch</li><li>YouTube’s Algorithm</li><li>YouTube’s Story</li></ul><h3 id="types-of-videos-i-watch">Types of videos I watch</h3><h4 id="gaming-30">Gaming (30%)</h4><p>This one was easy to justify for me, I like watching someone be good at something. Until I realized that this was a passive way of thinking about it.</p><p>I’m not raising my skill by watching this, so what’s the point? The only way I could get better at video games is to play it more, not by watching someone else play it.</p><h4 id="self-help-30">Self Help (30%)</h4><p><strong>Biggest trap of them all.</strong> Productivity, Self Help, Motivational channels might seem to have a good agenda on the onset but they can’t profit if you actually improve yourself.</p><p>Most of the YouTubers in this category are good people at heart. But they know that 90% of the people watching them won’t improve anything in their life. They just like the feeling of improving themselves.</p><p>Every time you watch one of the self-help videos, your brain plays a trick on you. It makes you think that you are actually improving yourself but when in reality you are just actually watching a video that you will forget in 40 minutes.</p><p>You will come for more when that rush is over. And YouTube tells them to create more videos quickly for us to consume.</p><p>For quick reference these are the only things they will say to you from now until eternity:</p><ul><li>Self Help YouTubers: Take care of yourself</li><li>Productivity YouTubers: Organize your life for deep work</li><li>Motivational YouTubers: Never stop the Hustle (This will lead to burnout by the way.)</li></ul><p>Ironically most of these YouTubers recommend you to read a book.</p><h4 id="design-and-development-20">Design and Development (20%)</h4><p>I’m a professional web designer, so it’s important for me to keep up with the latest developments in my field. Of course, that’s what I told myself.</p><p>Things always change but YouTube is not a place to capture it. YouTube videos seem to be the fast-food sector of the industry. Fast to the point but not impactful and everlasting.</p><p>I’ve found that written content like</p><ul><li>Blog Posts</li><li>Documentation</li><li>Best Practices</li><li>Newsletters</li><li>Case Studies</li></ul><p>are often more informative and educational. They let you,</p><ul><li>Read at your own pace</li><li>Accessible and Developer Friendly</li><li>Most of them are intended to be everlasting or updated frequently</li></ul><p>One might argue developer tutorials are inherently good and I agree, but I usually get a better flow in my work from written tutorials.</p><p>These are mostly for entertainment, but as I distance myself from these more and more I find them to be passive entertainment.</p><p>Netflix has a collection of marvelously produced entertainment that will take my entire lifetime to watch. Why should I settle for this glut?</p><h4 id="pointless-internet-drama-10">Pointless Internet Drama (10%)</h4><p>This was the cone of shame for me, I liked reality TV, YouTubers fighting with each other and mostly pointless drama. I was thinking about why I like this, and then a quote someone said came to me,</p><p>Don’t live on someone else’s life.</p><p>I was projecting. I have a simple life with no problems. So, I liked watching other people have problems. I thought I was superior to them in some way and that made me feel good.</p><p>Of course, I was the idiot watching videos while they simply got paid and went home.</p><h3 id="youtubes-algorithm">YouTube’s Algorithm</h3><p>Whenever I open YouTube, it shows me a carefully chosen list of videos that interests me. It’s a combination of what I recently liked, latest videos from the creators I like, trending videos from my location, and cute animals.</p><p><strong>It’s impossible not to click on any of these.</strong></p><p>YouTube’s algorithm is very powerful at this point, probably the most sophisticated recommendation engine in the world. You simply can’t win it.</p><p>You can, however, not participate in its game. Some steps you can take:</p><ul><li><p><strong>Do not <code>smash that like button</code> on any videos.</strong></p><p>If you want to see a video again, download it to your drive. The YouTube video can be removed, blocked, or altered but you can always have what you want.</p></li><li><p><strong>Do not <code>hit that bell icon</code>.</strong></p><p>Voluntarily having more notifications on your phone is the first step to becoming mindless and have other people dictate where you spend your time.</p></li><li><p><strong>Pause Watched History and Search History.</strong></p><p>Again, download important videos. 98% of what you watch is not worth it and the other 2% can easily be searched again.</p></li></ul><p>Clear watch history, remove previously liked videos, clear out your comments. Do not give any indication to YouTube on what you like.</p><p>I even ran a puppeteer (automated script) to remove all the videos from my recommendation but it just pops back up. The <code>Not Interested</code> option is not real.</p><p><strong>Ultimately, be utilitarian on what you want.</strong></p><p>If you want to learn <em>How to Tie a Tie</em>, search for it, learn it and close it. Don’t needlessly subscribe, like or engage in any way.</p><h3 id="youtubes-story">YouTube’s Story</h3><p>A brand’s story is what you want other people to tell about your brand. YouTube’s story is,</p><p>YouTube is a community of people giving free information and entertainment.</p><ul><li><p><strong>YouTube is not a community.</strong></p><p>Individual creators may create a community. But YouTube is a company that wants nothing but profits.</p></li><li><p><strong>YouTube is not free.</strong></p><p>Nothing Google does is free.</p></li><li><p><strong>YouTube gives low-quality information and entertainment.</strong></p><p>Only 5% of its millions of videos are actually helpful. Don’t take that burden of sifting through all that to find something you might like.</p></li></ul><h2 id="how-i-overcame-youtube">How I Overcame YouTube</h2><p>Here are some simple and actionable steps that I took over the months,</p><ol><li><p><strong>Cancelling YouTube Premium</strong></p><p>If you get pissed off at the ads like I do, then it’s good. You will quit the video soon.</p></li><li><p><strong>Turn off notifications</strong></p><p>Taylor Swift’s new music video is not that important to notify you. No one should have the right to disturb you anytime they want.</p></li><li><p><strong>Reducing subscriptions</strong></p><p>Go through your subscription list and remove anyone who you don’t need in your life anymore. I followed this and removed almost 300 subscriptions and I don’t even remember what they were now.</p></li><li><p><strong>Uninstalling apps</strong></p><p>YouTube is available everywhere, it doesn’t need to be on your phone or tablet. You can always watch in your mobile browser for something urgent.</p><p>Mobile apps have 30% higher engagement rate. We actively go back to an app more often than a website. That’s why everyone keeps pushing you to download their app. Don’t.</p></li><li><p><strong>Remove all subscriptions</strong></p><p>After some time, I naturally removed all my subscriptions, I found alternate sources to topics I was interested in. Books, Newsletters, Spotify, and Netflix was enough for me.</p><p>Tip: Subscribe to a channel called <code>Sub with no videos</code> to reduce the recommendations in your subscriptions tab.</p></li><li><p><strong>Add alternate habits</strong></p><p>My viewing hours reduced exponentially at this point. Now I opened YouTube, searched for some good creators, watched their latest video, and closed the site.</p><p>But to quit fully I knew I needed to replace YouTube time with something else. This can be a different thing for you and me. I started writing more often. The silence is great for creative thoughts and reflection.</p></li></ol><p>Today, after all this, I realized that I’m not addicted to YouTube anymore. I should be careful to make sure I don’t go back to it slowly. But I have high hopes for the future.</p><p>And always remember,</p><blockquote><p>“Too much of anything can make you sick” ~ Cheryl Cole</p></blockquote></article></div></div>]]>
            </description>
            <link>https://praveenjuge.com/blog/how-i-overcame-youtube-addiction/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23639870</guid>
            <pubDate>Thu, 25 Jun 2020 12:28:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Hitchhiker's Guide to PlantUML]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23639826">thread link</a>) | @todsacerdoti
<br/>
June 25, 2020 | https://crashedmind.github.io/PlantUMLHitchhikersGuide/ | <a href="https://web.archive.org/web/*/https://crashedmind.github.io/PlantUMLHitchhikersGuide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Tip</p>
<p><a href="http://www.plantuml.com/plantuml/svg/SYWkIImgAStDKU3YAYueoYn9LL39JImgoynJY3OqCgWmD37HDpIBLQZc0j1YTykjipeOWCzxDPX_7Kh2tFybRIJILB7PAtJIxvrfkfonyo1vGKpxh-ByCeVhlytNv-oC--_Wm_iG_3_oty1UsAjxN8x-7XRMkeUDvTsVmavKunxthELFOUigkoz_0dlhtjaRVVmHBEp2TS_SwT_3swvxpLLs7yDhrztpAXyVms7XkcNUTHk0jc5nOrJuZIknSBZB0BWFnpttBeTmlSquODw6_HqMOK_k9eGmGhkm51ntNOc5mz6VONLXjzL1tNtOodfHdy798Y00xy0-MdYwUx3aUC049aWRi0lntkbzsHq-I9TVNDY1nRt0RXyUvqh9Q5rXtyD2_hBJaf-AHycTh-e6FBnmBtY_PFbrq6om1FicFBpu2Upb5wbPfxmDXyzWV_WGJSd0U_0mFuTzRxRPEx0RwaTmq9y-P0Ia_OgFz2aSv6Skc8W2zoquV0vBNDS08lKjsCM_WAF09XlmaVu6zh-5VHBPmf9VmYB_5WuAVx9awdLXmcThxVmjVE_r_gF04QAe3BLMPB4tuG--5eF2YNkZMhAaL1Hw2_xWGK3XWBt3P2VDMx3Alt_MqypBSZjF2yDx-4ZlUos8BkX9aaVIl4fV52OY9gWF5Xdv7UmCV9Mbh91ogIEbJ6tQ8iW8a12Wf52844aEQaLYJaT-1_UuA5d0c4jvW47VifsEHIv9fM5AfK85WL5iQWt2E3UzXRs5PsAgY5A85-sMG-GSOynCIKwF2NZ22DIzarXuezSnPKqfuT-RDXzJJDZoNBLYVS9u7a-Oa5ZXTTAth4sRFQpnxJOrPcYexWYiO6HY1eNT6jRaYiYiRYnnOsCUaT8tZEqEDsgCc0USIiaBEZxKcc8YAdBlalTJrjURAgp8qvNm0YPYoccqkbO4nBg4WOOh90uvvU0r8UNuZxyuXUbApZjy4X8aD-2CX8qXNs6PgSJC86rEG6LeafW14OhGQzV0_GRdauWXz06xMg4nbbktMTWcjCoHYb4VyJDYpN8BSdYXZVfqqnqkPsidrpcTKa6TdnVu59GLhqA760KiQIuIWux-Kcmg9QaxKtzWUi2rSpjF0eLx1a90IA_iT6Uevc41Gid2YfmhGWx-cH1pvTQmfFX8w1Rs4pu5RfmdJ4CX9i1IgwgMdI50mZhP7xegFOj5RX9-qix2BKruVBR820EkrAIjqdj0KfRlQOrgjh3GCEcOAxMVaFR5zmKC_MGSCW_O8GyAILwuDM5NcSMyojh-MWfmipbrZDt0Q60QtD2_UXMtiHoAsdYT-O5maOKcrIvqwqkuTc6amrzP6aqypFx_M2I5xHsqASWB-W9pL1W4qHP_LHHulEW4MgRcIjpQclQ7Nz5IY8N9Fs4ckSbVohTPy1eMwldHUcnf-Q8CgMBJCB6bJ_w6yGTM1xz86jxaKDjv8Ii-fd5-o2mX45hcxeYNX3nlDPM2bZwP7l3nXCKb-9h_fGKcbE5UQwqq_v619pm3kcw97UPUEEe9N5EoKqiKCh3EuqO0zOlc2KrWlD5KKaQQHLfPw1H4zlByhCju4fgnn8IFCucL9WG3o_t8yhM8pE9EM6WJ0NCgf5112oijhdn7XoYPj3IZe5wPiMdu2UUcVNO3xeM8snE-qrXI0KGiDxYXoBFSHrALEL9IgZNhCBxpW0FLKdBi0dUep1PMsW249UUIywNLZHkNQ51n2vmoAp77LD3CGIfkmZfMD-5UvmAXy9ec0AIcUR84E62RLEN20RV6HfLn16VWeqzOPI8MU4rFQkR9nYDREEMAZVBXMM0Jmkp5NC8m90ClwVQK6sCDtZa39vd7CXXtu0lCaEtpVw01knUO1BxBXZP53C1PE0FoMKLuXNbM-meVPYSH0AaPU4dFfQXXYMwcA9nIGOIYm2jCLGPuWREu4vRa6tpljxgTizDCEALSOR31kIjCDRbR8e5xWLqbQSoQ_eRFXZb7R-0w7_cbnnRMAHWEju3vl6pQCX0tfZNzA1hIuMno8sMTpO6jKT7XhU1ssoqMe7_IaAAx9F6YhWC6As-kuSKsjIAIj9NMSd2t724iXFkR9ca1vwh2MYQwD5JYTdECh2gsCe3Gx-3_qMftEwwhEXp0xy_J1FnXSmcawwtEkszCd9OqqpLhh-tvNumgMSgle8P1XZGRBF27RiQHl5dW1bksOhAMwlHdE1EFq9-v2Na4Zi_z1bkus91LVTJVmHW5kwmgOdGiZ7TuZKnPcEMwUBV-7s3w3hPiwZ9nMUYsts6AWosgfPXCH7FdvF0ZtPz5xs-r1KVWNq-r1KMBJXa7lK_w3ekgNc4WFaFf_Zgb6tmFYS5CY5XixtQ7VKsumhp2zzpXUpOMOJ9O-sxq7Ru72IqqWjjVmcQFpAzGsknB_89q1huECURixTQFSDxly3VfhRKY8zhwXpGLaL9_b_PtT_RsWVV7v_hiQFp0PS5EHDmVxx6zcAUhQ8-7SyweK-gz-TegR17HChVmJPX_0WRfVO1C2FdjJbU6sGyf8l7m1YJJpAlfiX-DY0g6mtwwaWrENy8v0pD4mpXS631yXc5Ke4J3CDpVm7wUQEjECAoOCpxd-jrrE9iS2biolE1qWyr5-14OSC9tsGTizMno_Ej4ov3JpJKOVW3EVbpfyiZroDXSmb69XiqbN6MFknCcoC7mtDkiyjFEYpk240fdG5vWo6jMbrMsIFXuhCjENraB0DVQLRSmk1Gbm-2PV0duNxA-LPSj1S69UYl-8dc-l7MBjLjmss9Ws9ATUtsu7_5oeSxUKB5o14nfIsLVv9LEgxjRMXx5505ZJa1roEBoUzmj-sEu5RQqfH2O411DRcpmJSxkFYmLRHPYO64okpvCFkcxkvlRS1i9Wdd8281sKkJoZ9CMmCKrE0V2cORS68o-hLlkKd8uHS9JxW8BxIoMntJPt60O3QFsSDbncF5vxfBT3O95sFVJcUoSIX7Mc3lFGoLjJpXc0H6VwvIIc5neeT7SaQxvvSQirHlvN0yvInz8PNn5ZsxsueR05kGvrq-vxrK9FToQmGLURavR1Em_hulSMsMQuL9DLXYWZzOEMe9WCldSO6Qnuw9Q79O1D_75RBA1y3PWborSUwsAI3DrtWcv96u7WcAoqMO3bG7JsGjKNlT2zkbN6BofdYqeiA0KWor-IGEMR46mPK0glisq49zD1zy1keqZeR2tE2VjGN_9UOHm2VmAX4lrTWlFY66p029i1vF7zo8BXiD7vfc_Y8fFXJABnHiao1GxrIe7mDxcBENSSVlFFH_tHJDnB2ppyTwgJA2rUA6ymIWK2Iixx8zdXqNr2YSG38JB0llZzLpKNfKqkp0CiIFc2vnzUM9lB99d_iBYO5JHKjGGNqPo9lz6efwZXaW0KV1sF7OL2B9NH0XXROyJXS66CLxk6US3hdCDVoiHXi5oWnFW9pX16CnyJ6vAwudg2GjVfpfb284jeiku7EOJzjAh5hW3EU4fhx2AFaifViG6d-DAorJx8kvoJXw8W-tnpmLa1XmkzPGXUm13OPFFnmCWbtgKUg_djx8W4XF6_RYg3uoUTzLwEqfrNkfHyMXhoXe6OxMBCUquojVQ1cRkJ5alSBMsTmtzVznwxVl3Z3O--7YFj94oP4khpIhVm___tpzjd45h8p4CXU_pAyImaDlCFOImi8HDe2cba5EQWp9MR7LiETXomz0_NwVJGW-zYCTxJtpw1Mhoo7B5X0467uk1z-QCmsXJB6B-HHyJt1mhrUgSVpqMmGpjQhZdIvjmMg_-pC5wrN-wwxPf92g1fuj2l7plBQ7TmOspWocMXO7NaXMKl8T0a50TfHS1TLX7cbWiQ0GIYvOWJ5MfAvanXzewqu0b4-p0uHl9Gi76oXBgsfcTsBeVy3jxKKdgM4Quonbl8noFJlMQbtq_9CoEJ60ndULAEtSS-oUFeeVzmvPrS8v7Ilb_OKFz8-ajfl6GgxF7mR5G_jNid0OFsytpvdG2bgo4fklgfT3y9J4b-0y0"><img alt="playbutton_index" src="https://crashedmind.github.io/PlantUMLHitchhikersGuide/_images/play6.png"></a> <strong>Press play</strong></p>
<blockquote>
<div><p>Imagine being able to</p>
<ol>
<li><p>share a model or diagram between all members of the team that they can all understand and contribute to and edit</p></li>
<li><p>draw diagrams like below automatically from a text description.</p></li>
<li><p>describe a system before you build it, when you’re building it, and as you maintain it into the future - keeping the description and the system current, and in sync.</p></li>
<li><p>maintain that text version in a source code repository beside the code for the system it is describing</p></li>
</ol>
<p>Imagine having a diagramming tool that</p>
<ol>
<li><p>fits with a developer workflow, and developers are comfortable using</p></li>
<li><p>enables <strong>lightweight just-enough</strong> <a href="http://agilemodeling.com/essays/barelyGoodEnough.html">AgileModeling</a> in a way that meets <a href="https://tdan.com/best-practices-for-agile-documentation/18936">AgileModelingBP</a></p></li>
<li><p>fits with modern practices of Continuous Integration Continuous Delivery - and “everything as code” including diagrams.</p></li>
</ol>
<p>Well that’s what PlantUML gives you, and more…</p>
</div></blockquote>
</div></div>]]>
            </description>
            <link>https://crashedmind.github.io/PlantUMLHitchhikersGuide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23639826</guid>
            <pubDate>Thu, 25 Jun 2020 12:23:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OpenNebula & Kubernetes: Comparing Two Container Orchestration Models]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23639815">thread link</a>) | @amarti
<br/>
June 25, 2020 | https://opennebula.io/opennebula-kubernetes-comparing-two-container-orchestration-models/ | <a href="https://web.archive.org/web/*/https://opennebula.io/opennebula-kubernetes-comparing-two-container-orchestration-models/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
			    <!-- .entry-header -->

				
					
<article id="post-25483">

    <!-- .entry-header -->

    <div>

		
<div><div id="kt-layout-id_3efdd0-59"><div>
<div><div>
<p>📘 Check our <strong>step-by-step tutorial and screencast</strong> on how to easily deploy on <strong>AWS</strong> a single-node <strong>Firecracker cloud</strong> integrated with the <strong>Docker Hub</strong> marketplace:</p>



<figure><a href="https://support.opennebula.pro/hc/en-us/articles/360045029871-How-to-Use-miniONE-to-Deploy-a-Firecracker-Cloud-Integrated-with-Docker-Hub-on-AWS" target="_blank" rel="noopener noreferrer"><img src="https://opennebula.io/wp-content/uploads/2020/06/FC_AWS.jpg" alt=""></a></figure>
</div></div>



<div><div>
<p>Application container technologies, like <a href="https://www.docker.com/" target="_blank" rel="noreferrer noopener" aria-label="Docker (opens in a new tab)">Docker</a> and <a href="https://kubernetes.io/" target="_blank" rel="noreferrer noopener" aria-label="Kubernetes (opens in a new tab)">Kubernetes</a>, are becoming the de facto leading standards for packaging, deploying and managing applications with increased levels of agility and efficiency. Kubernetes is widely used for the orchestration of containers on clusters, offering features for automating application deployment, scaling, and management.&nbsp;<br></p>



<p>However, <strong>Kubernetes doesn’t necessarily work for every single use case</strong> nor solves all container management-related challenges an organization might face. Just to put an example, its support for multi-tenancy is actually quite limited, and it cannot guarantee perfectly secure isolation between tenants. The only way to run Kubernetes is by providing different teams with their own clusters. Upgrading clusters and patching vulnerabilities is not a quick and easy task, which in the end requires to build an <strong>expensive full-time admin team</strong>.&nbsp;<br></p>



<p>Moreover, Kubernetes does not offer cloud-like self-service provision features for users, nor accounting and advanced authorization features for administrators. Cloud providers and cloud management tools, like <a rel="noreferrer noopener" aria-label="Amazon EKS (opens in a new tab)" href="https://aws.amazon.com/eks/" target="_blank">Amazon Elastic Kubernetes Service (EKS)</a> or <a rel="noreferrer noopener" aria-label="Google Kubernetes Engine (opens in a new tab)" href="https://cloud.google.com/kubernetes-engine" target="_blank">Google Kubernetes Engine (GKE)</a>, try to bridge these gaps by offering <strong>managed Kubernetes-as-a-Service platforms</strong>. What these solutions do is to add an extra control layer that ends up <strong>increasing management complexity, resource consumption, and associated costs</strong>.&nbsp;</p>
</div></div>
</div></div></div>



<h2>OpenNebula 5.12 “Firework”</h2>



<p>The new <a rel="noreferrer noopener" aria-label="OpenNebula 5.12 “Firework” (opens in a new tab)" href="https://opennebula.io/firework/" target="_blank">OpenNebula 5.12 “Firework”</a> brings new exciting features to the container orchestration ecosystem by providing an <strong>innovative open source solution</strong> for organizations that need to build and manage a secure, self-service, multi-tenant cloud for serverless computing. Users of an OpenNebula cloud can now easily run isolated containers without the need to provision and manage servers or additional control layers, thus allowing them to focus on designing and building their applications instead of managing the underlying infrastructure. OpenNebula’s <strong>pioneering approach towards container orchestration</strong> integrates two main technologies: <a rel="noreferrer noopener" aria-label="AWS Firecracker (opens in a new tab)" href="https://firecracker-microvm.github.io/" target="_blank">AWS Firecracker</a> as the VMM that provisions, manages and orchestrates micro-VMs, and <a rel="noreferrer noopener" aria-label="Docker Hub (opens in a new tab)" href="https://hub.docker.com/" target="_blank">Docker Hub</a> as the marketplace for application containers from which users can obtain and seamlessly <strong>deploy Docker images as micro-VMs</strong>.&nbsp;<br></p>



<p>AWS Firecracker is an open source technology that makes use of KVM to launch lightweight Virtual Machines—called micro-VMs—for <strong>enhanced security, workload isolation, and resource efficiency</strong>. It is widely used by AWS as part of their <a href="https://aws.amazon.com/fargate/" target="_blank" rel="noreferrer noopener" aria-label="Fargate (opens in a new tab)">Fargate</a> and <a href="https://aws.amazon.com/lambda/" target="_blank" rel="noreferrer noopener" aria-label="Lambda (opens in a new tab)">Lambda</a> services. Firecracker opens up a whole new world of possibilities as the foundation for serverless solutions that need to quickly deploy critical applications as containers while keeping them in secure isolation. With the recent integration of Firecracker as a <strong>new supported virtualization technology</strong>, OpenNebula provides now an innovative solution to the classic dilemma between using containers—lighter but with weaker security—or Virtual Machines—with strong security but high overhead.&nbsp;&nbsp;<br></p>



<p>OpenNebula’s integration of Docker Hub as a new native marketplace provides users with immediate access to <strong>Docker Hub official images</strong>. Through this integration Docker images can be easily imported into an OpenNebula cloud, following a process similar to the way in which the OpenNebula Public Marketplace operates. The OpenNebula context packages are installed during the import process so, once an image is imported, it becomes fully functional (including auto IP configuration, SSH key management and custom scripts). The Docker Hub marketplace also creates a new VM template associated with the imported image. This template can be customized by the user (e.g. adding the desired kernel, tuning specific parameters, etc.).</p>







<div><figure><img src="https://opennebula.io/wp-content/uploads/2020/06/dh_mktplace-1024x532.png" alt="" width="768" height="399" srcset="https://opennebula.io/wp-content/uploads/2020/06/dh_mktplace-1024x532.png 1024w, https://opennebula.io/wp-content/uploads/2020/06/dh_mktplace-300x156.png 300w, https://opennebula.io/wp-content/uploads/2020/06/dh_mktplace-768x399.png 768w, https://opennebula.io/wp-content/uploads/2020/06/dh_mktplace.png 1206w" sizes="(max-width: 768px) 100vw, 768px"></figure></div>







<h2>An Enterprise Cloud for Containerized Applications</h2>



<p>OpenNebula brings to the container world a series of unique features to <strong>build your own enterprise cloud for serverless computing</strong>. Its unique approach speeds up the deployment of <strong>containerized applications and multi-tier services</strong> within your development workflow. In particular, OpenNebula provides:</p>



<ul><li><strong>Fast startup times</strong>: With OpenNebula you can start containers in seconds by deploying them as Firecracker micro-VMs, without the need to provision and maintain Dockerized hosts or complex Kubernetes infrastructures.</li><li><strong>Direct access to applications</strong>:&nbsp; Deploying a container as a micro-VM allows your container to directly access your networks through the Firecracker micro-VM’s IP address. Furthermore, the micro-VM can be accessed via SSH and VNC by providing interactive modes that help with application development and troubleshooting.</li><li><strong>Hypervisor-level security: </strong>OpenNebula guarantees that your containerized application to run within a Firecracker micro-VM which, in turn, provides VM-grade security and isolation in a multi-tenant environment while preserving the efficiency of lightweight containers.</li><li><strong>Persistent storage: </strong>OpenNebula’s datastores can be used as persistent data volumes for containers by attaching them to your Firecracker micro-VMs. Read-only configuration or data files can be provided by using the OpenNebula file datastore, which can be used by the application within the micro-VM.</li><li><strong>Network access: </strong>Virtual Networks defined within an OpenNebula cloud (i.e. IPv4, IPv6, Dual Stack, Ethernet) can be easily configured so that containerized applications get direct access to the internet without requiring additional components (e.g. ingress controllers, load balancers, etc.). With OpenNebula Virtual Routers it is also possible to connect different virtual networks, allowing applications and Virtual Machines attached to different virtual networks to communicate with each other. It is possible to use security groups for ensuring network security for containers applications.</li><li><strong>Application horizontal scaling</strong>: Application deployed as complex, multi-tier services can be scaled up and down “manually” but also (via the OneFlow component) in an automatic manner, based on user-defined metrics and pre-defined criteria. An <em>init</em> script can be defined to send application metrics to OneGate, OpenNebula’s metadata server.&nbsp;</li><li><strong>Complete multi-tenant environments</strong> with ACLs, users, groups, resource UNIX-like permissions and VDCs, in which cloud admins can easily adapt OpenNebula to their organization’s infrastructure and DevOps requirements and set up independent sets of resources for specific purposes or groups of users (i.e. development, testing, integration and production).</li><li><strong>Geo-distributed applications</strong>: Thanks to its elastic cloud infrastructure feature (OneProvision), OpenNebula allows to build on-demand geo-distributed infrastructures for execution of containerized applications at the Edge.</li></ul>







<h2>Summary</h2>



<p>Although many IT departments providing container execution services have decided to implement their <strong>DevOps requirements on top of Kubernetes</strong>, that doesn’t mean that betting only on one horse is the wisest thing to do. Organizations requiring container orchestration capabilities should first of all state what their main objective is, and be careful not to make apples to oranges comparisons or to fall into <strong>unexpected costs or vendor lock-ins</strong>. Kubernetes is a <strong>very complex and demanding technology</strong>, and—temporary fashions aside—other technologies may actually be the best solution for some use cases.<br></p>



<p>Some of the features provided by Kubernetes (such as its declarative model, self healing, automated rollout and rollbacks, secret and configuration management, service discovery and load balancing) make it ideal for companies that need complete container orchestration services for the deployment and management of containerized workflows in a production environment. Yet, these organizations have to be able to cope with <strong>high operational costs</strong> if what they want is to build and manage a <strong>corporate Kubernetes deployment</strong>.<br></p>



<p><a rel="noreferrer noopener" aria-label="OpenNebula (opens in a new tab)" href="https://opennebula.io/firework/" target="_blank">OpenNebula</a>, on the other hand, becomes an ideal solution for companies that need to build <strong>multi-tenant Container-as-a-Service environments</strong>, but with <strong>lower operational costs</strong>. In this way, users and business units can develop and deploy applications easily and very fast, without their organizations having to manage dockerized hosts or complex orchestration infrastructures such as Kubernetes or OpenShift. With the release of its version 5.12 “Firework”, OpenNebula has become a real alternative for implementing an <strong>agile and serverless cloud paradigm for containerized workloads</strong> in production environments 🚀</p>







<figure><table><tbody><tr><td></td><td><figure><img src="https://opennebula.io/wp-content/uploads/2020/06/opennebula_cloud_logo_white_bg.png" alt=""></figure></td><td><figure><img src="https://opennebula.io/wp-content/uploads/2020/06/kubernetes-horizontal-color.png" alt=""></figure></td></tr><tr><td><strong>Use Case</strong></td><td>Container as a Service</td><td>Container Orchestration</td></tr><tr><td><strong>Purpose</strong></td><td>Create a CaaS multi-tenant Enterprise Cloud for containerized applications </td><td>Manage a cluster of Linux containers as a single system to accelerate development and simplify operations</td></tr><tr><td><strong>Use</strong></td><td>Deliver shared resources to groups of users for secure execution of their container workloads</td><td>Deployment, scaling, and operations of containers across a cluster of hosts of VMs for a single user or group of users</td></tr><tr><td><strong>Applications</strong></td><td>Containerized distributed applications</td><td>Containerized distributed applications</td></tr><tr><td><strong>Access to Applications</strong></td><td>Easy SSH, VNC access to the micro-VM </td><td>Container exec bash access. Hard to troubleshoot</td></tr><tr><td><strong>Orchestration Approach</strong></td><td>Imperative</td><td>Declarative</td></tr><tr><td><strong>Application Management</strong></td><td>User-driven life-cycle application management (create, delete, stop, resume)</td><td>Application rollback and updates, self-healing, service discovery &amp; load balancing</td></tr><tr><td><strong>Application Scheduling &amp; Resource Optimization</strong></td><td>Application micro-VMs are placed according to resource requirements (CPU and Memory), affinity rules, custom heuristics…</td><td>Automatic bin packing is used to place containers based on their resource requirements</td></tr><tr><td><strong>Network Access</strong></td><td>Full support of IPv4, IPv6, Dual Stack, Ethernet networks and security groups</td><td>Allocation of IPv4 and IPv6 …</td></tr></tbody></table></figure></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://opennebula.io/opennebula-kubernetes-comparing-two-container-orchestration-models/">https://opennebula.io/opennebula-kubernetes-comparing-two-container-orchestration-models/</a></em></p>]]>
            </description>
            <link>https://opennebula.io/opennebula-kubernetes-comparing-two-container-orchestration-models/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23639815</guid>
            <pubDate>Thu, 25 Jun 2020 12:22:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Linux on a Laptop, 2020 Edition]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23639747">thread link</a>) | @piotrzientara
<br/>
June 25, 2020 | https://mkozak.pl/linux-on-laptop-2020-edition/ | <a href="https://web.archive.org/web/*/https://mkozak.pl/linux-on-laptop-2020-edition/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <!--kg-card-begin: markdown--><p>After 8 years of using Apple computers (mac mini and multiple MacBooks), I decided to say "Farewell" to Apple.</p>
<p>The quality of both software and hardware when it comes to their mobile computers went downhill in recent years.<br>
Butterfly keyboard issues, old CPUs (compared to what other manufacturers put in their machines), quite limited of memory (until latest iteration of 13" MacBooks Pro it was impossible to get more than 16GB of RAM), software issues with Catalina (audio glitches, random freezes, random reboots) - all of that led me to the point where I decided to sell my 2015-version of MacBook Pro (I still have one MBPro from 2019 that I'm using for work at current company, and I still need to live with this failing system)</p>
<p>When I had switched from 2012 mac mini to PC desktop three years ago (there was no reasonable alternative from Apple on the horizon) I've told myself I'm going to stick with Apple for mobile computing (and I partly do, I still don't see any alternatives to iPhone and iPad) based on my previous experiences with Linux on a laptop. But I decided to give it a try.<br>
When I previously used Linux on a laptop, it was between 2008 and 2011, and it was a mess - battery life was a joke compared to what I could achieve with Windows, constant issues with suspending and hibernation, failing wireless network card.<br>
That was when I joined Apple cult. It was quite the opposite - long battery life, beautiful UI, seamless integration between different products, quite good performance, lot of great apps. Too bad it's only partially true now.  I want to share my journey about looking for a suitable replacement for MacBook Pro in 2020, and I need to make clear that my needs for computing might not be usual. But hey, we're talking about MacBook <em>Pro</em>, and I mean this should be aimed at professionals. I'm 100% sure many people will be happy with their Macs.</p>
<p>Requirements:</p>
<ul>
<li>5-6 hours of battery life</li>
<li>As much memory as possible. I use a lot of Docker containers with memory-hungry applications. And I use Chrome, so there's no such thing as too much memory</li>
<li>Fast disks</li>
<li>Ideally - matte display</li>
<li>Screen no bigger than 14"</li>
<li>Reliably working Wi-Fi card</li>
</ul>
<p>You may think many products will meet these criteria, but you couldn't be more wrong.</p>
<p><a href="https://mkozak.pl/linux-on-laptop-2020-edition-choosing-the-right-machine/">Part 1 - choosing the right machine</a><br>
<a href="https://mkozak.pl/linux-on-a-laptop-2020-edition-arch-on-clevo/">Part 2 - Arch on Clevo</a></p>
<!--kg-card-end: markdown-->
  </div></div>]]>
            </description>
            <link>https://mkozak.pl/linux-on-laptop-2020-edition/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23639747</guid>
            <pubDate>Thu, 25 Jun 2020 12:16:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Faster Integer Parsing]]>
            </title>
            <description>
<![CDATA[
Score 155 | Comments 39 (<a href="https://news.ycombinator.com/item?id=23639486">thread link</a>) | @fanf2
<br/>
June 25, 2020 | https://kholdstare.github.io/technical/2020/05/26/faster-integer-parsing.html | <a href="https://web.archive.org/web/*/https://kholdstare.github.io/technical/2020/05/26/faster-integer-parsing.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
        <p>Back with a post after 6 years of silence. If you had to parse a microsecond-resolution epoch timestamp as quickly as possible, how would you do it?  We’ll take a look at using compiler intrinsics to do it in log(n) time.</p>


        <h3 id="the-problem">The problem</h3>

<p>Let’s say, theoretically, you have some text-based protocol, or file that
contains microsecond timestamps. You need to parse these timestamps as quickly
as possible. Maybe it’s json, maybe it’s a csv file, maybe something else
bespoke. It’s 16 characters long, and this could also apply to credit card
numbers.</p>

<figure><pre><code data-lang="csv">timestamp,event_id
1585201087123567,a
1585201087123585,b
1585201087123621,c</code></pre></figure>

<p>In the end you have to implement a function similar to this:</p>

<figure><pre><code data-lang="cpp"><span>std</span><span>::</span><span>uint64_t</span> <span>parse_timestamp</span><span>(</span><span>std</span><span>::</span><span>string_view</span> <span>s</span><span>)</span>
<span>{</span>
  <span>// ???</span>
<span>}</span></code></pre></figure>

<hr>

<h3 id="the-native-solution">The native solution</h3>

<p>Let’s start with what’s available, and compare. We have
<a href="https://en.cppreference.com/w/cpp/string/byte/atoi"><code>std::atoll</code></a> , a function
inherited from C,
<a href="https://en.cppreference.com/w/cpp/io/basic_stringstream"><code>std::stringstream</code></a>
, the newer C++17
<a href="https://en.cppreference.com/w/cpp/header/charconv"><code>&lt;charconv&gt;</code></a> header, and
by request
<a href="https://www.boost.org/doc/libs/1_73_0/libs/spirit/doc/html/spirit/qi/reference/basics.html"><code>boost::spirit::qi</code></a>.
I’ll be using <a href="https://github.com/google/benchmark">Google Benchmark</a> to
measure the performance, and to have a baseline let’s compare against loading
the final result into a register - i.e. no actual parsing involved.</p>

<p>Let’s run the benchmarks! The code is not important here, it just shows what is being benchmarked.</p>

<figure><pre><code data-lang="cpp"><span>static</span> <span>void</span> <span>BM_mov</span><span>(</span><span>benchmark</span><span>::</span><span>State</span><span>&amp;</span> <span>state</span><span>)</span> <span>{</span>
  <span>for</span> <span>(</span><span>auto</span> <span>_</span> <span>:</span> <span>state</span><span>)</span> <span>{</span>
    <span>benchmark</span><span>::</span><span>DoNotOptimize</span><span>(</span><span>1585201087123789</span><span>);</span>
  <span>}</span>
<span>}</span>

<span>static</span> <span>void</span> <span>BM_atoll</span><span>(</span><span>benchmark</span><span>::</span><span>State</span><span>&amp;</span> <span>state</span><span>)</span> <span>{</span>
  <span>for</span> <span>(</span><span>auto</span> <span>_</span> <span>:</span> <span>state</span><span>)</span> <span>{</span>
    <span>benchmark</span><span>::</span><span>DoNotOptimize</span><span>(</span><span>std</span><span>::</span><span>atoll</span><span>(</span><span>example_timestamp</span><span>));</span>
  <span>}</span>
<span>}</span>

<span>static</span> <span>void</span> <span>BM_sstream</span><span>(</span><span>benchmark</span><span>::</span><span>State</span><span>&amp;</span> <span>state</span><span>)</span> <span>{</span>
  <span>std</span><span>::</span><span>stringstream</span> <span>s</span><span>(</span><span>example_timestamp</span><span>);</span>
  <span>for</span> <span>(</span><span>auto</span> <span>_</span> <span>:</span> <span>state</span><span>)</span> <span>{</span>
    <span>s</span><span>.</span><span>seekg</span><span>(</span><span>0</span><span>);</span>
    <span>std</span><span>::</span><span>uint64_t</span> <span>i</span> <span>=</span> <span>0</span><span>;</span>
    <span>s</span> <span>&gt;&gt;</span> <span>i</span><span>;</span>
    <span>benchmark</span><span>::</span><span>DoNotOptimize</span><span>(</span><span>i</span><span>);</span>
  <span>}</span>
<span>}</span>
<span>static</span> <span>void</span> <span>BM_charconv</span><span>(</span><span>benchmark</span><span>::</span><span>State</span><span>&amp;</span> <span>state</span><span>)</span> <span>{</span>
  <span>auto</span> <span>s</span> <span>=</span> <span>example_timestamp</span><span>;</span>
  <span>for</span> <span>(</span><span>auto</span> <span>_</span> <span>:</span> <span>state</span><span>)</span> <span>{</span>
    <span>std</span><span>::</span><span>uint64_t</span> <span>result</span> <span>=</span> <span>0</span><span>;</span>
    <span>std</span><span>::</span><span>from_chars</span><span>(</span><span>s</span><span>.</span><span>data</span><span>(),</span> <span>s</span><span>.</span><span>data</span><span>()</span> <span>+</span> <span>s</span><span>.</span><span>size</span><span>(),</span> <span>result</span><span>);</span>
    <span>benchmark</span><span>::</span><span>DoNotOptimize</span><span>(</span><span>result</span><span>);</span>
  <span>}</span>
<span>}</span>

<span>static</span> <span>void</span> <span>BM_boost_spirit</span><span>(</span><span>benchmark</span><span>::</span><span>State</span><span>&amp;</span> <span>state</span><span>)</span> <span>{</span>
  <span>using</span> <span>boost</span><span>::</span><span>spirit</span><span>::</span><span>qi</span><span>::</span><span>parse</span><span>;</span>
  <span>for</span> <span>(</span><span>auto</span> <span>_</span> <span>:</span> <span>state</span><span>)</span> <span>{</span>
    <span>std</span><span>::</span><span>uint64_t</span> <span>result</span> <span>=</span> <span>0</span><span>;</span>
    <span>parse</span><span>(</span><span>s</span><span>.</span><span>data</span><span>(),</span> <span>s</span><span>.</span><span>data</span><span>()</span> <span>+</span> <span>s</span><span>.</span><span>size</span><span>(),</span> <span>result</span><span>);</span>
    <span>benchmark</span><span>::</span><span>DoNotOptimize</span><span>(</span><span>result</span><span>);</span>
  <span>}</span>
<span>}</span></code></pre></figure>

<figure>
    <canvas id="benchmark-canvas-native">
    </canvas>

</figure>

<p>Wow, <code>stringstream</code> is pretty bad. Not that it’s a fair comparison but parsing
a single integer using <code>stringstream</code> is 391 times slower than just loading our
integer into a register.  <code>&lt;charconv&gt;</code> and <code>boost::spirit</code> do a lot better by
comparison.</p>

<p>Since we know our string contains the number we’re trying to parse, and we
don’t need to do any whitespace skipping, can we be faster?  Just how much time
is spent in validation?</p>

<hr>

<h3 id="the-naive-solution">The naive solution</h3>

<p>Let’s write a good old for loop. Read the string character by character, and
build up the result.</p>

<figure><pre><code data-lang="cpp"><span>inline</span> <span>std</span><span>::</span><span>uint64_t</span> <span>parse_naive</span><span>(</span><span>std</span><span>::</span><span>string_view</span> <span>s</span><span>)</span> <span>noexcept</span>
<span>{</span>
  <span>std</span><span>::</span><span>uint64_t</span> <span>result</span> <span>=</span> <span>0</span><span>;</span>
  <span>for</span><span>(</span><span>char</span> <span>digit</span> <span>:</span> <span>s</span><span>)</span>
  <span>{</span>
    <span>result</span> <span>*=</span> <span>10</span><span>;</span>
    <span>result</span> <span>+=</span> <span>digit</span> <span>-</span> <span>'0'</span><span>;</span>
  <span>}</span>
  <span>return</span> <span>result</span><span>;</span>
<span>}</span></code></pre></figure>

<figure>
    <canvas id="benchmark-canvas-naive">
    </canvas>

</figure>

<p>That’s actually not bad for a simple for loop. If such a simple solution is
able to beat a standard-library implementation, it means there’s quite a lot of
effort that goes into input validation. As a sidenote - if you know your input,
or can do simpler validation you can get some significant speedups.</p>

<p>For further solutions and benchmarks, let’s ignore the standard library
functions. We should be able to go much faster than this.</p>

<hr>

<h3 id="the-brute-force-solution">The brute force solution</h3>

<p>If we know it’s 16 bytes, why even have a forloop? Let’s unroll it!</p>

<figure><pre><code data-lang="cpp"><span>inline</span> <span>std</span><span>::</span><span>uint64_t</span> <span>parse_unrolled</span><span>(</span><span>std</span><span>::</span><span>string_view</span> <span>s</span><span>)</span> <span>noexcept</span>
<span>{</span>
  <span>std</span><span>::</span><span>uint64_t</span> <span>result</span> <span>=</span> <span>0</span><span>;</span>

  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>0</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>1000000000000000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>1</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>100000000000000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>2</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>10000000000000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>3</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>1000000000000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>4</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>100000000000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>5</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>10000000000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>6</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>1000000000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>7</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>100000000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>8</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>10000000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>9</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>1000000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>10</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>100000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>11</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>10000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>12</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>1000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>13</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>100ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>14</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>10ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>15</span><span>]</span> <span>-</span> <span>'0'</span><span>);</span>

  <span>return</span> <span>result</span><span>;</span>
<span>}</span></code></pre></figure>

<figure>
    <canvas id="benchmark-canvas-brute-force">
    </canvas>

</figure>

<p>Ok, that’s slightly better again, but we’re still processing a character at a time.</p>

<hr>

<h3 id="the-byteswap-insight">The byteswap insight</h3>

<p>Let’s draw out the operations in the unrolled solution as a tree, on a
simplified example of parsing ‘1234’ into a 32-bit integer:</p>

<figure>
    <img width="100%" height="100%" src="https://kholdstare.github.io/diagrams/parse-unrolled.png">

<figcaption><p>Unrolled solution graph of operations for ‘1234’</p>
</figcaption>

</figure>

<p>We can see that the amount of multiplications and additions is linear with the
amount of characters. It’s hard to see how to improve this, because every
multiplication is by a different factor (so we can’t multiply “in one go”), and at
the end of the day we need to add up all the intermediate results.</p>

<p>However, it’s still very regular. For one thing, the first character in the
string is multiplied by the largest factor, because it is the most significant
digit.</p>

<blockquote>
  <p>On a little-endian machine (like x86), an integer’s first byte contains the
least significant digits, while the first byte in a string contains the most
significant digit.</p>
</blockquote>

<figure>
    <img width="100%" height="100%" src="https://kholdstare.github.io/diagrams/parse-byteswap-insight.png">

<figcaption><p>Looking at the string as an integer we can get closer to
the final parsed state in fewer operations - see how the hex representation is
<strong>almost</strong> what we want</p>
</figcaption>

</figure>

<p>Now to reinterpret the bytes of a string as an integer we have to use
<code>std::memcpy</code> (<a href="https://blog.regehr.org/archives/1307">to avoid strict-aliasing
violations</a>), and we have compiler
instrinsic <code>__builtin_bswap64</code> to swap the bytes in one instruction. The
<code>std::memcpy</code> will get optimized out, so this is a win so far.</p>

<figure><pre><code data-lang="cpp"><span>template</span> <span>&lt;</span><span>typename</span> <span>T</span><span>&gt;</span>
<span>inline</span> <span>T</span> <span>get_zeros_string</span><span>()</span> <span>noexcept</span><span>;</span>

<span>template</span> <span>&lt;</span><span>&gt;</span>
<span>inline</span> <span>std</span><span>::</span><span>uint64_t</span> <span>get_zeros_string</span><span>&lt;</span><span>std</span><span>::</span><span>uint64_t</span><span>&gt;</span><span>()</span> <span>noexcept</span>
<span>{</span>
  <span>std</span><span>::</span><span>uint64_t</span> <span>result</span> <span>=</span> <span>0</span><span>;</span>
  <span>constexpr</span> <span>char</span> <span>zeros</span><span>[]</span> <span>=</span> <span>"00000000"</span><span>;</span>
  <span>std</span><span>::</span><span>memcpy</span><span>(</span><span>&amp;</span><span>result</span><span>,</span> <span>zeros</span><span>,</span> <span>sizeof</span><span>(</span><span>result</span><span>));</span>
  <span>return</span> <span>result</span><span>;</span>
<span>}</span>

<span>inline</span> <span>std</span><span>::</span><span>uint64_t</span> <span>parse_8_chars</span><span>(</span><span>const</span> <span>char</span><span>*</span> <span>string</span><span>)</span> <span>noexcept</span>
<span>{</span>
  <span>std</span><span>::</span><span>uint64_t</span> <span>chunk</span> <span>=</span> <span>0</span><span>;</span>
  <span>std</span><span>::</span><span>memcpy</span><span>(</span><span>&amp;</span><span>chunk</span><span>,</span> <span>string</span><span>,</span> <span>sizeof</span><span>(</span><span>chunk</span><span>));</span>
  <span>chunk</span> <span>=</span> <span>__builtin_bswap64</span><span>(</span><span>chunk</span> <span>-</span> <span>get_zeros_string</span><span>&lt;</span><span>std</span><span>::</span><span>uint64_t</span><span>&gt;</span><span>());</span>

  <span>// ...</span>
<span>}</span></code></pre></figure>

<p>But now that we have an integer that kind of, sort of looks like what we want,
how do we get it across the finish line without too much work?</p>

<hr>

<h3 id="the-divide-and-conquer-insight">The divide and conquer insight</h3>

<p>From the previous step, we end up with an integer whose bit representation 
has each digit placed in a separate byte. I.e. even though one byte can
represent up to 256 values, we have values 0-9 in each byte of the integer.
They are also in the right little endian order. Now we just need to “smash”
them together somehow.</p>

<p>We know that doing it linearly would be too slow, what’s the next possibility?
<strong>O(log(n))</strong>! We need to combine every adjacent digit into a pair in one step,
and then each pair of digits into a group of four, and so on, until we have the
entire integer.</p>

<p>After I posted the first version of this article, <a href="https://www.reddit.com/r/cpp/comments/gr18ig/faster_integer_parsing/frx9agb">Sopel97 on
reddit</a>
pointed out that the byteswap is not necessary. Combining adjacent digits works
either way - their order doesn’t matter.  I realized that it helped me with the
next insight, but could be omitted for the final code.</p>

<blockquote>
  <p>The key is working on adjacent digits simultaneously. This allows a tree of
operations, running in O(log(n)) time.</p>
</blockquote>

<p>This involves multiplying the even-index digits by a power of 10 and leaving the
odd-index digits alone. This can be done with bitmasks to selectively apply
operations</p>

<figure>
    <img width="100%" height="100%" src="https://kholdstare.github.io/diagrams/parse-mask-insight.png">

<figcaption><p>By using bitmasking, we can apply operations to more than one digit at a time, to combine them into a larger group</p>
</figcaption>

</figure>

<p>Let’s finish the <code>parse_8_chars</code> function we started earlier by employing this
masking trick. As a neat side-effect of the masking, we don’t need to subtract
<code>'0'</code>, since it will be masked away.</p>

<figure><pre><code data-lang="cpp"><span>inline</span> <span>std</span><span>::</span><span>uint64_t</span> <span>parse_8_chars</span><span>(</span><span>const</span> <span>char</span><span>*</span> <span>string</span><span>)</span> <span>noexcept</span>
<span>{</span>
  <span>std</span><span>::</span><span>uint64_t</span> <span>chunk</span> <span>=</span> <span>0</span><span>;</span>
  <span>std</span><span>::</span><span>memcpy</span><span>(</span><span>&amp;</span><span>chunk</span><span>,</span> <span>string</span><span>,</span> <span>sizeof</span><span>(</span><span>chunk</span><span>));</span>

  <span>// 1-byte mask trick (works on 4 pairs of single digits)</span>
  <span>std</span><span>::</span><span>uint64_t</span> <span>lower_digits</span> <span>=</span> <span>(</span><span>chunk</span> <span>&amp;</span> <span>0x0f000f000f000f00</span><span>)</span> <span>&gt;&gt;</span> <span>8</span><span>;</span>
  <span>std</span><span>::</span><span>uint64_t</span> <span>upper_digits</span> <span>=</span> <span>(</span><span>chunk</span> <span>&amp;</span> <span>0x000f000f000f000f</span><span>)</span> <span>*</span> <span>10</span><span>;</span>
  <span>chunk</span> <span>=</span> <span>lower_digits</span> <span>+</span> <span>upper_digits</span><span>;</span>

  <span>// 2-byte mask trick (works on 2 pairs of two digits)</span>
  <span>lower_digits</span> <span>=</span> <span>(</span><span>chunk</span> <span>&amp;</span> <span>0x00ff000000ff0000</span><span>)</span> <span>&gt;&gt;</span> <span>16</span><span>;</span>
  <span>upper_digits</span> <span>=</span> <span>(</span><span>chunk</span> <span>&amp;</span> <span>0x000000ff000000ff</span><span>)</span> <span>*</span> <span>100</span><span>;</span>
  <span>chunk</span> <span>=</span> <span>lower_digits</span> <span>+</span> <span>upper_digits</span><span>;</span>

  <span>// 4-byte mask trick (works on pair of four digits)</span>
  <span>lower_digits</span> <span>=</span> <span>(</span><span>chunk</span> <span>&amp;</span> <span>0x0000ffff00000000</span><span>)</span> <span>&gt;&gt;</span> <span>32</span><span>;</span>
  <span>upper_digits</span> <span>=</span> <span>(</span><span>chunk</span> <span>&amp;</span> <span>0x000000000000ffff</span><span>)</span> <span>*</span> <span>10000</span><span>;</span>
  <span>chunk</span> <span>=</span> <span>lower_digits</span> <span>+</span> <span>upper_digits</span><span>;</span>

  <span>return</span> <span>chunk</span><span>;</span>
<span>}</span></code></pre></figure>

<hr>

<h3 id="the-trick">The trick</h3>

<p>Putting it all together, to parse our 16-digit integer, we break it up into two
chunks of 8 bytes, run <code>parse_8_chars</code> that we have just written, and benchmark it!</p>

<figure><pre><code data-lang="cpp"><span>inline</span> <span>std</span><span>::</span><span>uint64_t</span> <span>parse_trick</span><span>(</span><span>std</span><span>::</span><span>string_view</span> <span>s</span><span>)</span> <span>noexcept</span>
<span>{</span>
  <span>std</span><span>::</span><span>uint64_t</span> <span>upper_digits</span> <span>=</span> <span>parse_8_chars</span><span>(</span><span>s</span><span>.</span><span>data</span><span>());</span>
  <span>std</span><span>::</span><span>uint64_t</span> <span>lower_digits</span> <span>=</span> <span>parse_8_chars</span><span>(</span><span>s</span><span>.</span><span>data</span><span>()</span> <span>+</span> <span>8</span><span>);</span>
  <span>return</span> <span>upper_digits</span> <span>*</span> <span>100000000</span> <span>+</span> <span>lower_digits</span><span>;</span>
<span>}</span>

<span>static</span> <span>void</span> <span>BM_trick</span><span>(</span><span>benchmark</span><span>::</span><span>State</span><span>&amp;</span> <span>state</span><span>)</span> <span>{</span>
  <span>for</span> <span>(</span><span>auto</span> <span>_</span> <span>:</span> <span>state</span><span>)</span> <span>{</span>
    <span>benchmark</span><span>::</span><span>DoNotOptimize</span><span>(</span><span>parse_trick</span><span>(</span><span>example_stringview</span><span>));</span>
  <span>}</span>
<span>}</span></code></pre></figure>

<figure>
    <canvas id="benchmark-canvas-trick">
    </canvas>

</figure>

<p>Not too shabby, we shaved almost 56% off of the unrolled loop benchmark! Still,
it feels like we are manually doing a bunch of masking and elementwise
operations. Maybe we can just let the CPU do all the hard work?</p>

<hr>

<h3 id="the-simd-trick">The SIMD trick</h3>

<p>We have the main insight:</p>

<ul>
  <li>Combine groups of digits simultaneously to achieve O(log(n)) time</li>
</ul>

<p>We also have a 16-character, or 128-bit string to parse - can we use SIMD? Of
course we can! <a href="https://en.wikipedia.org/wiki/SIMD">SIMD stands for Single Instruction Multiple
Data</a>, and is exactly what we are looking
for. SSE and AVX instructions are supported on both Intel and AMD CPUs, and
 they typically work with wider registers.</p>

<p>I used the <a href="https://software.intel.com/sites/landingpage/IntrinsicsGuide/">Intel Intrinsics
Guide</a> to find
the right compiler intrinsics for the right SIMD CPU instructions.</p>

<p>Let’s set up the digits in each of the 16 bytes first:</p>

<figure><pre><code data-lang="cpp"><span>inline</span> <span>std</span><span>::</span><span>uint64_t</span> <span>parse_1…</span></code></pre></figure></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kholdstare.github.io/technical/2020/05/26/faster-integer-parsing.html">https://kholdstare.github.io/technical/2020/05/26/faster-integer-parsing.html</a></em></p>]]>
            </description>
            <link>https://kholdstare.github.io/technical/2020/05/26/faster-integer-parsing.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23639486</guid>
            <pubDate>Thu, 25 Jun 2020 11:43:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gopherspace in the Year 2020]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 3 (<a href="https://news.ycombinator.com/item?id=23639411">thread link</a>) | @sT370ma2
<br/>
June 25, 2020 | https://cheapskatesguide.org/articles/gopherspace.html | <a href="https://web.archive.org/web/*/https://cheapskatesguide.org/articles/gopherspace.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

   <!-- Title -->
   
   <p><img src="https://cheapskatesguide.org/pics/gopher-240.jpg" alt="Gopher">
      I first had access to the early Internet--what there was of 
      it--through the university I attended.  I remember how different 
      the Internet was back in the mid-to-late 1980's.  We had 
      electronic mail, but almost no one used it.  We logged onto 
      remote computers with telnet and transferred files with FTP.  
      All this was done at the command line.  If I remember correctly, 
      very few graphical user interfaces existed then.  Those that 
      did were composed of ASCII characters.  The first web browser was 
      not released until 1991.  Remembering causes me some sadness, 
      though in some ways the Internet is better now.  It certainly 
      has many more users, and that is a good thing.  I just wish it had 
      more Internet-savvy users.</p>

   <p>I remember that many of the early computer networks and websites on 
      the Internet were run by imaginative people with great senses of 
      humor.  For example, the computer network that I used at the second 
      engineering company for which I worked in the late 1980's had seven 
      sun workstations named after the seven dwarves.  As you may imagine, 
      that provided us with no end of entertainment.  "Dopey is down, 
      AGAIN!"  "Grumpy is acting up."  "Sneezy died yesterday.  When is 
      the funeral?"</p>

   <p>Back then, computers were something special.  They were wondrous.  
      Individuals who owned them were mavericks in a sense.  Buying a 
      personal computer then was the same as painting the word "nerd" in big 
      red letters across your forehead, and being known as a nerd back then was 
      not something you wanted.  One of my highschool friends built a 
      Heathkit computer.  The only display it had was in the form of 
      one-inch, red LED digits on the front.</p>

   <p>Now, that computers permeate our society, no one bothers giving them 
      interesting names.  They've nearly become fungible commodities that we 
      use up and then throw away when they have outlived their usefulness.  
      Nearly everyone uses the Internet at least occassionally.  And, 
      strangely enough, being called a nerd is seen as a good thing.</p>
   <h2>Gopherspace</h2>
   <p>The Gopher protocol was released by the University of Minnesota in 
      1991.  Gopher servers provided users with access to various types 
      of files, including text, binary, image, sound, and GIF.  But the 
      milieu of gopherspace was text.   Text was mostly what Gopher users 
      saw.  Users could also access FTP, telnet, and 
      Usenet servers.  Back in the 1990's, Veronica search engines
      tied together the network of Gopher servers in a similar way as 
      modern search engines do today with the webservers of the
      modern Internet.  In the 1990's, Jughead search engines were designed 
      to search individual Gopher servers.  And, Archie was an FTP search 
      engine.  Archie, Veronica, and Jughead search engines were named 
      after characters in the Archie comics that first appeared in print in
      1941.  Back in the 1980's and early 1990's, when people who loved 
      computers still ran much of the Internet, it reflected their 
      personalities.  Now, the Internet is more a beige and gray  
      reflection of the corporate world.</p> 
  
   <p>Today the Gopher protocol has been supplanted almost completely 
      by the HTTP protocol upon which the World Wide Web is based.
      Though the Internet has changed considerably, Gopher servers are 
      still around.  Text is still mostly what users see 
      in gopherspace, and it can still be navigated with 
      gopher-capable Internet browsers.  Sadly, only one Veronica search 
      engine appears to operate today.  Now, When a user navigates through
      gopherspace with the Veronica search engine, by following links, or
      by entering URL's into his browser, he has an experience in many 
      ways similar to surfing the modern Internet.</p>
   
   <p>Though about <a href="https://en.wikipedia.org/wiki/Gopher_(protocol)"> 
      two dozen Internet browsers</a> can still access gopherspace, either 
      natively or with plugins, I will only talk about one.  I'll focus on the 
      Lynx browser, because it is readily available, easy to use, and 
      powerful.  The Lynx browser also runs on all the major 
      operating systems.  I'll show readers how to use the Lynx browser 
      to get into gopherspace and have a look around.</p>
   <h2>Installing and Using the Lynx Browser</h2>
   <p>The Lynx browser is a text-only Internet browser that has native 
      support for gopherspace.  Lynx allows a user to seamlessly navigate 
      around the Internet and gopherspace using only the keys on his computer's 
      keyboard.  Lynx does not use a mouse or touchpad.  Windows computer 
      users can download the Lynx browser from the 
      <a href="https://lynx.browser.org/">Lynx website</a>.</p>
 
   <div><p>Most Linux users can install Lynx simply by opening a Linux 
      terminal window and typing:
   </p></div><div>
<pre>sudo apt-get install lynx
</pre>
   </div>
   <p>

   Then, type "lynx" (without the quotes) at the command line to start 
   the Lynx browser.</p>

   <p>To go to a Gopher address using the Lynx browser, hit the "g" 
      key on your keyboard.  Near the bottom of the Lynx window, the 
      prompt "URL to open:" will appear.  Now, begin typing the Gopher 
      address.  Gopher URL's can also be copied and pasted from other 
      applications.  First, copy the URL from the other application, 
      then select the Lynx window, hit the right mouse button, and 
      select "paste".  Try going to this Gopher address for practice: 
      gopher://infinitelyremote.com/0/books/Internet_Gopher_Users_Guide.txt.  
      After you hit the "Enter" key, the text file entitled "Internet 
      Gopher Users Guide" should be visible in your Lynx window.</p>

   <p>Lynx has three user modes.  At this point, you are in the novice 
      user mode, so at the bottom of the page, the following instructions 
      should be visible: "-- press space for next page --  Arrow keys: 
      Up and Down to move.  Right to follow a link; Left to go back.  
      H)elp O)ptions P)rint G)o M)ain screen Q)uit /=search 
      [delete]=history list".</p>

   <p>At a basic level, Lynx is very easy to use, so a user does not 
      have to know much to navigate around gopherspace and read text 
      files.  I will go over the basic commands, and leave it to you 
      to learn more later.  To navigate around inside a text file that 
      contains no hyperlinks, press the space bar or the down arrow on 
      your keyboard to move down one page and the up arrow to move back 
      up one page.  The left arrow is like the back button in a modern 
      Internet browser; it takes you to the previous text file that you 
      visited.  In a text file with hyperlinks, pressing the up or down 
      arrow moves the cursor to the hyperlink above or below the 
      cursor's present position.  When the cursor is on a hyperlink, 
      pressing the "Enter" key or the right arrow takes you to the 
      document pointed to by the hyperlink.</p>

   <p>Some Gopher pages contain forms similar to HTML forms.  For 
      example, links to search engines may appear as a search line.  Use 
      the left or right arrow to move the cursor to the search line.  
      Then, type the key words you want to search for and hit the 
      "Enter" key.  This will take you to a search results page.</p>

   <p>To display the Gopher URL of the file you are currently reading, 
      hit the "=" key.  Then, hit the left arrow key to get back to the 
      file you were just reading.</p>

   <p>Exit from Lynx by hitting the "q" key.  By the way, most 
      command-line Linux programs that take control of a terminal 
      window can be exited by hitting either the "q" key or by typing 
      ":q".</p>

   <p>This is all the information you need to know to navigate around 
      in gopherspace (or on the rest of the Internet) using the Lynx 
      browser.  For additional instructions on the use of Lynx, bring 
      up Lynx and hit the "h" key.</p>
   <h2>Exploring Gopherspace</h2>
   <p>Now the fun begins.  Perhaps the best place to enter gopherspace 
      is gopher://gopher.floodgap.com/1/world.  There you will find 
      links to dozens of Gopher servers.  Floodgap claims that it 
      hosts the last Veronica search engine in existence.  So, from 
      Floodgap you can use the Veronica search engine to search 
      gopherspace by key words, or you can go to individual Gopher 
      user sites by following links to the Gopher servers that host them.</p>

   <p>One of the largest collections of Gopher user sites can be found 
      by following the Link on Floodgap labeled "'Greatest hits': most 
      recently verified Gopher servers".  From there, follow the link 
      labeled "sdf.org:70" to the Super-Dimensional Fortress (URL: 
      gopher://sdf.org/1).  There you will find many interesting phlogs 
      and files.  Gopher blogs are called phlogs.  One interesting 
      phlogger is Tomasino (gopher://sdf.org/1/users/tomasino/).  
      Another is solderpunk (gopher://sdf.org/1/users/solderpunk/).  
      There are also may others.  So, have fun and explore!</p>

   <p>For more interesting reading in gopherspace, try these:</p>
   <br>
   <ul>
      <li>gopher://gopher.floodgap.com/0/gopher/relevance.txt</li>
      <li>gopher://sdf.org/1/users/d1337/1990s-life</li>
      <li>gopher://gopherpedia.com/1/</li>
      <li>gopher://gopherddit.com/1/</li>
      <li>gopher://sdf.org/0/users/developer/PHLOG/earlydays.txt</li>
      <li>gopher://tilde.team/1/~ubergeek/news/</li>
      <li>gopher://hngopher.com/1</li>
      <li>gopher://sdf.org/1/users/sysdharma/phlog</li>
      <li>gopher://sdf.org/0/users/dbucklin/posts/2017-12-31-plain-text.txt</li>
      <li>gopher://sdf.org/0/users/dbucklin/posts/2016-03-11-mechanical-keyboards.txt</li>
      <li>gopher://tilde.town/</li>
      <li>gopher://1436.ninja/1/Port70News</li>
      <li>gopher://codevoid.de/1/cnn</li>
      <li>gopher://gopher.floodgap.com/1/feeds/today</li>
      <li>gopher://vger.cloud/1/pubnix</li>
      <li>gopher://sdfeu.org/1/</li>
      <li>gopher://zaibatsu.circumlunar.space/1/%7etfurrows/phlog</li>
      <li>gopher://1436.ninja/1/Phlog</li>
      <li>gopher://baud.baby</li>
      <li>gopher://sdf.org/1/users/xmanmonk/</li>
      <li>gopher://sdf.org/1/users/tokyogringo/</li>
      <li>gopher:/…</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cheapskatesguide.org/articles/gopherspace.html">https://cheapskatesguide.org/articles/gopherspace.html</a></em></p>]]>
            </description>
            <link>https://cheapskatesguide.org/articles/gopherspace.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23639411</guid>
            <pubDate>Thu, 25 Jun 2020 11:33:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don't build password-less login]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23639330">thread link</a>) | @jbarches
<br/>
June 25, 2020 | https://snaphabit.app/blog/password-less-login/ | <a href="https://web.archive.org/web/*/https://snaphabit.app/blog/password-less-login/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://snaphabit.app/blog/content/images/size/w300/2020/06/MagicLink-3.png 300w,
                            https://snaphabit.app/blog/content/images/size/w600/2020/06/MagicLink-3.png 600w,
                            https://snaphabit.app/blog/content/images/size/w1000/2020/06/MagicLink-3.png 1000w,
                            https://snaphabit.app/blog/content/images/size/w2000/2020/06/MagicLink-3.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://snaphabit.app/blog/content/images/size/w2000/2020/06/MagicLink-3.png" alt="Don't build password-less login">
            </figure>

            <section>
                <div>
                    <h3 id="a-metrics-driven-take-on-how-password-less-login-wasted-weeks-of-development-time-and-hurt-our-signup-funnel-">A metrics-driven take on how password-less login wasted weeks of development time and hurt our signup funnel.</h3><p>"Magic Link", also know as password-less login, enables users to sign in by clicking a link. With no need to remember a password or prove email ownership, <a href="https://medium.com/@kelvinvanamstel/should-we-embrace-magic-links-and-leave-passwords-alone-c73db7007fc4">many</a> <a href="https://techbeacon.com/security/your-passwordless-future-make-it-sooner-rather-later">people</a> have hailed "Magic Link" as the perfect authentication solution.</p><p>How it works on SnapHabit? After a user enters their enter email address, we direct them to their inbox to tap a link to sign in. Before diving into what went wrong, here's a snapshot of our authentication funnel:</p><ul><li><strong>11% of users</strong> required at least 4 magic-link emails before completing signing up.</li><li><strong>18% of users never finished signup (clicked the magic link)</strong>. On average, these users attempted signup twice, with several users submitting &gt; 10 times.</li></ul><!--kg-card-begin: html--><!--kg-card-end: html--><h2 id="-why-would-you-use-magic-link-anyways">... why would you use magic link, anyways?</h2><p>Friends are core to SnapHabit, so the functionality to send a friend request is critical. Phone number or email felt like the cheapest way to support a unique identifier — as it could be used for both authentication and finding a friend.</p><p>Like most services, we first looked at using "Sign in with Google/Facebook". However, Apple recently adjusted App Store Guidelines... starting June 30, <strong>"apps that use a social login service ... must also offer Sign in with Apple"</strong></p><figure><img src="https://snaphabit.app/blog/content/images/2020/06/Screen-Shot-2020-06-17-at-3.47.00-PM-2.png"><figcaption>App Store Guidelines, June 17, 2020</figcaption></figure><p>Apple Sign In supports <a href="https://support.apple.com/en-us/HT210425">"Hide My Email"</a>, so many users who sign in with Apple would not have a meaningful email attached to their account. Asking for a user's email after they chose to "hide it" would be a poor user experience.</p><p>So in summary, we had 4 options for account creation:</p><ol><li><strong>Email + Password</strong> ... requires forgot password and users to prove email ownership</li><li><strong>Support all third-party (Apple, Google, Facebook)</strong> ... and add a new unique identifier to allow friends to find each other, given email will not be sufficient</li><li><strong>Phone number magic link</strong> ... we were relying on Expo (previously did not support phone-number auth), and we also felt emails would be a good/cheap tool for communication</li><li><strong>Email magic link</strong> </li></ol><p>Email magic link felt... perfect! &nbsp;We built the login flow, complete with a custom email, instructional webpage, and deep linking. <strong>Hurrah, we had cracked the authentication funnel!</strong></p><!--kg-card-begin: html--><iframe width="560" height="315" src="https://www.youtube.com/embed/QoS2-mIuOZw" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><!--kg-card-end: html--><h2 id="what-went-wrong-and-how-we-tried-to-solve">What went wrong and how we tried to solve</h2><p><em>If you're interested in the technical details of how we implemented some of these fixes, let me know and we'll consider publishing.</em></p><h3 id="1-users-clicking-the-link-on-another-device-">1. Users clicking the link on another device.</h3><p>Of 10 users we chatted with who had issues, 4 tried to click the link on another device. There are two routes to solving this:</p><ul><li>technical solution to support this behavior (clicking the link on desktop will authenticate the user on mobile)</li><li>better instructional text</li></ul><p><strong>The latter was simpler, so we started with that:</strong></p><figure><img src="https://snaphabit.app/blog/content/images/2020/06/firstattempt.png"></figure><p><strong>And again.</strong></p><figure><img src="https://snaphabit.app/blog/content/images/2020/06/email.png"></figure><p><strong>And more.</strong></p><figure><img src="https://snaphabit.app/blog/content/images/2020/06/landingpage.png"></figure><h3 id="2-user-confusion-about-clicking-a-link-to-login">2. User confusion about clicking a link to login</h3><p>At least 2 people mentioned they simply did not understand that they needed to authenticate with email. &nbsp;To solve this, we added</p><ul><li>call-to-action to open Apple Mail or Gmail</li><li>disabled the "resend" button for 10 seconds, to encourage users to tap the mail CTA before attempting login again</li></ul><figure><img src="https://snaphabit.app/blog/content/images/2020/06/buttons.png"></figure><h3 id="3-users-entering-the-wrong-email">3. Users entering the wrong email</h3><p>Many users who did not finish finish signing up (eg. did not click email link) had accounts with a ".con" domain. &nbsp;We added an notice to alert users of a possibly unintended typo:</p><figure><img src="https://snaphabit.app/blog/content/images/2020/06/dotcon.png"></figure><h2 id="-what-s-next">... What's next</h2><div><p>Despite attempting to solve 1, 2 and 3, our funnel drop-off is still larger than we'd like (~15% of users do not open the email correctly).</p><p>So after two months of solution hackery, we're cutting our losses and adding sign in with Google, Facebook and Apple options. If we still see users opting for email sign-in and failing to complete, we'll consider making the full-circle shift back to an email/password model.<br><strong><br>I hope our sharing this painful journey can save you from taking a similar path!</strong> &nbsp;Let me know if you have any questions or feedback at <a href="https://snaphabit.app/cdn-cgi/l/email-protection" data-cfemail="a0cac1cbc5e0d3cec1d0c8c1c2c9d48ec1d0d08e">[email&nbsp;protected]</a></p></div><hr><p><em>Don't have SnapHabit yet? You can download the app on iOS <a href="https://apps.apple.com/us/app/snaphabit-ai-healthy-habits/id1494552185" rel="noopener noreferrer">here</a> and Android <a href="https://play.google.com/store/apps/details?id=io.gravitech.habit.staging" rel="noopener noreferrer">here</a>.</em></p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://snaphabit.app/blog/password-less-login/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23639330</guid>
            <pubDate>Thu, 25 Jun 2020 11:21:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Foam]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23639161">thread link</a>) | @neilkakkar
<br/>
June 25, 2020 | https://foambubble.github.io/foam/ | <a href="https://web.archive.org/web/*/https://foambubble.github.io/foam/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

      

<p><strong>Foam</strong> is a personal knowledge management and sharing system inspired by <a href="https://roamresearch.com/">Roam Research</a>, built on <a href="https://code.visualstudio.com/">Visual Studio Code</a> and <a href="https://github.com/">GitHub</a>.</p>

<p>You can use <strong>Foam</strong> for organising your research, keeping re-discoverable notes, writing long-form content and, optionally, publishing it to the web.</p>

<p><strong>Foam</strong> is free, open source, and extremely extensible to suit your personal workflow. You own the information you create with Foam, and you’re free to share it, and collaborate on it with anyone you want.</p>

<blockquote>
  <p><strong>In a rush?</strong> You <em>could</em> jump to <a href="#getting-started">Getting started</a>, but I highly recommend reading the introductory sections first. <strong>Foam</strong> isn’t obvious.</p>
</blockquote>

<h2 id="table-of-contents">Table of Contents</h2>

<ul>
  <li><a href="#foam">Foam</a>
    <ul>
      <li><a href="#table-of-contents">Table of Contents</a></li>
      <li><a href="#how-do-i-use-foam">How do I use Foam?</a></li>
      <li><a href="#whats-in-a-foam">What’s in a Foam?</a></li>
      <li><a href="#getting-started">Getting started</a></li>
      <li><a href="#features">Features</a></li>
      <li><a href="#call-to-adventure">Call To Adventure</a></li>
      <li><a href="#thanks-and-attribution">Thanks and attribution</a></li>
      <li><a href="#license">License</a></li>
    </ul>
  </li>
</ul>

<h2 id="how-do-i-use-foam">How do I use Foam?</h2>

<p><strong>Foam</strong> is a tool that supports creating relationships between thoughts and information to help you think better.</p>

<p><img src="https://foambubble.github.io/foam/assets/images/foam-navigation-demo.gif" alt="Short video of Foam in use"></p>

<p>Whether you want to build a <a href="https://www.buildingasecondbrain.com/">Second Brain</a> or a <a href="https://zettelkasten.de/posts/overview/">Zettelkasten</a>, write a book, or just get better at long-term learning, <strong>Foam</strong> can help you organise your thoughts if you follow these simple rules:</p>

<ol>
  <li><a href="https://github.com/foambubble/foam-template/generate">Create a single <strong>Foam</strong> workspace</a> for all your knowledge and research.</li>
  <li>Write your thoughts in markdown documents (I like to call them <strong>Bubbles</strong>, but that might be more than a little twee). These documents should be atomic: Put things that belong together into a single document, and limit its content to that single topic. (<a href="https://zettelkasten.de/posts/overview/#principles">source</a>)</li>
  <li>Use Foam’s shortcuts and autocompletions to link your thoughts together with <code>[[wiki-links]]</code>, and navigate between them to explore your knowledge graph.</li>
  <li>Get an overview of your <strong>Foam</strong> workspace using a [<a href="https://foambubble.github.io/foam/graph-visualisation" title="Graph visualisation">graph-visualisation</a>] (⚠️ WIP), and discover relationships between your thoughts with the use of [<a href="https://foambubble.github.io/foam/backlinking" title="Backlinking">backlinking</a>].</li>
</ol>

<p>Foam is a like a bathtub: <em>What you get out of it depends on what you put into it.</em></p>

<h2 id="whats-in-a-foam">What’s in a Foam?</h2>

<p>Like the soapy suds it’s named after, <strong>Foam</strong> is mostly air.</p>

<ol>
  <li>The editing experience of <strong>Foam</strong> is powered by VS Code, enhanced by workspace settings that glue together [<a href="https://foambubble.github.io/foam/recommended-extensions" title="Recommended Extensions">recommended-extensions</a>] and preferences optimised for writing and navigating information.</li>
  <li>To back up, collaborate on and share your content between devices, Foam pairs well with <a href="http://github.com/">GitHub</a>.</li>
  <li>To publish your content, you can set it up to publish to <a href="https://pages.github.com/">GitHub Pages</a> with zero code and zero config, or to any website hosting platform like <a href="http://netlify.com/">Netlify</a> or <a href="https://foambubble.github.io/foam/vercel">Vercel</a>.</li>
</ol>

<blockquote>
  <p><strong>Fun fact</strong>: This documentation was researched, written and published using <strong>Foam</strong>.</p>
</blockquote>

<h2 id="getting-started">Getting started</h2>

<blockquote>
  <p>⚠️ Foam is still in preview. Expect the experience to be a little rough.</p>
</blockquote>

<p>These instructions assume you have a GitHub account, and you have Visual Studio Code installed.</p>

<ol>
  <li><a href="https://github.com/foambubble/foam-template/generate">Create a GitHub repository from foam-template</a>. If you want to keep your thoughts to yourself, remember to set the repository private.</li>
  <li>Clone the repository and open it in VS Code.</li>
  <li>When prompted to install recommended extensions, click <strong>Install all</strong> (or <strong>Show Recommendations</strong> if you want to review and install them one by one)</li>
</ol>

<p>After setting up the repository, open <a href="https://foambubble.github.io/foam/.vscode/settings.json">.vscode/settings.json</a> and edit, add or remove any settings you’d like for your Foam workspace.</p>

<p>To learn more about how to use <strong>Foam</strong>, read the [<a href="https://foambubble.github.io/foam/recipes" title="Recipes">recipes</a>].</p>

<p>There are [<a href="https://foambubble.github.io/foam/known-issues" title="Known Issues">known-issues</a>], and I’m sure, many unknown issues! Please <a href="http://github.com/foambubble/foam/issues">report them on GitHub</a>!</p>

<h2 id="features">Features</h2>

<p><strong>Foam</strong> doesn’t have features in the traditional sense. Out of the box, you have access to all features of VS Code and all the [<a href="https://foambubble.github.io/foam/recommended-extensions" title="Recommended Extensions">recommended-extensions</a>] you choose to install, but it’s up to you to discover what you can do with it!</p>

<p>Head over to [<a href="https://foambubble.github.io/foam/recipes" title="Recipes">recipes</a>] for some useful patterns and ideas, and</p>

<h2 id="call-to-adventure">Call To Adventure</h2>

<p>The goal of <strong>Foam</strong> is to be your personal companion on your quest for knowledge.</p>

<p>It’s is currently about “10% ready” relative to all the features I’ve thought of, but I’ve only thought of ~1% of the features it could have, and I’m excited to learn from others.</p>

<p>I am using it as my personal thinking tool. By making it public, I hope to learn from others not only how to improve Foam, but also to improve how I learn and manage information.</p>

<p>If that sounds like something you’re interested in, I’d love to have you along on the journey.</p>

<ul>
  <li>Check out [<a href="https://foambubble.github.io/foam/roadmap" title="Roadmap">roadmap</a>] to see what’s in the plans</li>
  <li>Read about our [<a href="https://foambubble.github.io/foam/principles" title="Principles">principles</a>] to understand Foam’s philosophy and direction</li>
  <li>Read the [<a href="https://foambubble.github.io/foam/contribution-guide" title="Contribution Guide">contribution-guide</a>] guide to learn how to participate.</li>
  <li>Feel free to open <a href="https://github.com/foambubble/foam/issues">GitHub issues</a> to give me feedback and ideas for new features.</li>
</ul>

<h2 id="thanks-and-attribution">Thanks and attribution</h2>

<p><strong>Foam</strong> is built by <a href="https://github.com/jevakallio">Jani Eväkallio</a> (<a href="https://twitter.com/jevakallio">@jevakallio</a>).</p>

<p><strong>Foam</strong> was inspired by <a href="https://roamresearch.com/">Roam Research</a> and the <a href="https://zettelkasten.de/posts/overview">Zettelkasten methodology</a></p>

<p><strong>Foam</strong> wouldn’t be possible without <a href="https://code.visualstudio.com/">Visual Studio Code</a> and <a href="https://github.com/">GitHub</a>, and relies heavily on our fantastic open source [<a href="https://foambubble.github.io/foam/recommended-extensions" title="Recommended Extensions">recommended-extensions</a>] and all their contributors:</p>

<h2 id="license">License</h2>

<p>Foam is licensed under the <a href="https://foambubble.github.io/foam/license">MIT license</a>.</p>






      
      
      
    </div></div>]]>
            </description>
            <link>https://foambubble.github.io/foam/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23639161</guid>
            <pubDate>Thu, 25 Jun 2020 10:53:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Server Side Rendering React App with Deno]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23638676">thread link</a>) | @kazade
<br/>
June 25, 2020 | https://dev.p.ota.to/post/server-side-rendering-react-app-with-deno-4qf28vm8axb/ | <a href="https://web.archive.org/web/*/https://dev.p.ota.to/post/server-side-rendering-react-app-with-deno-4qf28vm8axb/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody mainEntityOfPage">
        <div><p><img src="https://dev.p.ota.to/images/5670392840585216/" alt="Image"></p>
<h2>Intro</h2>
<p>Two of my favourites things are React and dinosaurs.
In this article I will show how I’ve put them together to develop a server side rendering <a href="https://reactjs.org/">React</a> application with <a href="https://deno.land/">Deno</a>.</p>
<h2>Project Setup</h2>
<p>I will assume that we are all familiar with React and Deno. Knowing that Deno is pretty new, if you don’t know how to install it and how it works, I would highly suggest you to have a read at this great <a href="https://dev.p.ota.to/post/an-introduction-to-deno-4u3suut77w6/">introduction</a> before diving into this article.</p>
<p>Now let’s start creating the project structure and the files needed for this tutorial, I’m using <a href="https://code.visualstudio.com/">Visual Studio Code</a> but any editor will do.
Open your terminal and type:</p>
<pre><code>mkdir deno-react-ssr &amp;&amp; cd $_
code .
</code></pre>
<p>This will create a new folder called <code>deno-react-ssr</code> and will open it with vscode.
In this folder we will need to create three files, <code>app.tsx</code> that will contain the code of the React component, <code>server.tsx</code> for the server code and <code>deps.ts</code> will contain all our dependencies. Think of it as our version of a <code>package.json</code>.
You will end up with a structure like this:</p>
<pre><code>.
├── app.tsx
├── deps.ts
└── server.tsx
</code></pre>
<h2>Setting up the dependencies</h2>
<p>In <code>deps.ts</code> we will have to export all the dependencies needed for this application to run.
Copy the following code and add it to your file.</p>
<pre><code>// @deno-types="https://deno.land/x/types/react/v16.13.1/react.d.ts"
import React from 'https://jspm.dev/react@16.13.1';
// @deno-types="https://deno.land/x/types/react-dom/v16.13.1/server.d.ts"
import ReactDOMServer from 'https://jspm.dev/react-dom@16.13.1/server';
export { React, ReactDOMServer }
export { Application, Context, Router } from 'https://deno.land/x/oak@v4.0.0/mod.ts';
</code></pre>
<p>As you can see, in Deno you import the modules directly from a url. 
I’ve decided to import React and ReactDOMServer from <a href="https://jspm.org/">jspm</a> as suggested in the <a href="https://deno.land/#third-party-modules">documentation for third party modules</a> but you can use any other CDN that provides the same modules.</p>
<p>One unusual thing that may stand out to you could be this:<br>
<code>// @deno-types="https://deno.land/x/types/react/v16.13.1/react.d.ts"</code><br>
Since we are using typescript, this line of code will inform Deno of the location of the types it needs to import and will affect the <code>import</code> statement that follows. A more exhaustive explanation can be found in the <a href="https://deno.land/manual/getting_started/typescript#compiler-hint">Deno Type Hint</a> manual.</p>
<p>I’ve also decided to use <a href="https://github.com/oakserver/oak">Oak</a>, a middleware framework for <a href="https://doc.deno.land/https/deno.land/std/http/mod.ts">Deno's http server</a> that also provides a router, so I’m importing all the modules we will use in the server in addition to the <code>Context</code> type that typescript requires.</p>
<h2>Create your React component</h2>
<p>This is how our <code>app.tsx</code> component will look:</p>
<pre><code>import { React } from "./deps.ts";

const App = () =&gt; {
  const [count, setCount] = React.useState(0);

  const garden = {
    backgroundColor: 'green',
    height: 'auto',
    fontSize: '30px',
    maxWidth: '400px',
    padding: '20px 5px',
    width: '100%'
  };

  return (
    &lt;div className="pure-g pure-u"&gt;
      &lt;h2&gt;My DenoReact App&lt;/h2&gt;
      &lt;button className="pure-button" onClick={() =&gt; setCount(count + 1)}&gt;Add a 🦕 in your garden!&lt;/button&gt;
      &lt;p style={garden}&gt;
      { Array(count).fill(&lt;span&gt;🦕&lt;/span&gt;) }
      &lt;/p&gt;
    &lt;/div&gt;
  );
};

export default App;
</code></pre>
<p>As with any standard React component, we start by importing React from our <code>deps.ts</code> file.</p>
<p>Then we are going to declare our App component that uses <a href="https://reactjs.org/docs/hooks-intro.html">hooks</a> to implement a simple button counter that allows you to add as many dinosaurs as you want in your personal garden!</p>
<h2>Setting up the Server</h2>
<p>For the server I’m using <a href="https://github.com/oakserver/oak">Oak</a> and the code in <code>server.tsx</code> will look like this:</p>
<pre><code>import {
  Application,
  Context,
  React,
  ReactDOMServer,
  Router,
} from './deps.ts';

import App from "./app.tsx";

const PORT = 8008;

const app = new Application();
const jsBundle = "/main.js";

const js =
`import React from "https://jspm.dev/react@16.13.1";
 import ReactDOM from "https://jspm.dev/react-dom@16.13.1";
 const App = ${App};
 ReactDOM.hydrate(React.createElement(App), document.getElementById('app'));`;  


const html =
  `&lt;html&gt;
    &lt;head&gt;
      &lt;link rel="stylesheet" href="https://unpkg.com/purecss@2.0.3/build/pure-min.css"&gt;
      &lt;script type="module" src="${jsBundle}"&gt;&lt;/script&gt;
    &lt;/head&gt;
    &lt;body&gt;
      &lt;main id="app"&gt;${ReactDOMServer.renderToString(&lt;App /&gt;)}&lt;/main&gt;  
    &lt;/body&gt;
  &lt;/html&gt;`;

const router = new Router();
router
  .get('/', (context: Context) =&gt; {
    context.response.type = 'text/html';
    context.response.body = html;
  })
  .get(jsBundle, (context: Context) =&gt; {
    context.response.type = 'application/javascript';
    context.response.body = js;
  });

app.use(router.routes());
app.use(router.allowedMethods());

console.log(`Listening on port ${PORT}...`);

await app.listen({ port: PORT });
</code></pre>
<p>As always we need to import all the dependencies we will use in our server. 
We will also import our App we created earlier, as you can see the extension <code>.tsx</code> is required in Deno so don’t forget it!<br>
Next step is to create our Oak server application and we’ll also need to define some routes:</p>
<ul>
<li><code>'/'</code> will serve our HTML page that contains the rendered app.  </li>
<li><code>'/main.js'</code>  will serve our application code that is needed to <a href="https://reactjs.org/docs/react-dom.html#hydrate">hydrate</a> the client side React application.</li>
</ul>
<p>Finally we tell our application to use the route we just created and start listening on port <code>8008</code>. You can notice I’m also using <code>router.allowedMethods()</code>, it’s a middleware that lets the client know when a route is not allowed.</p>
<h2>Run the application</h2>
<p>Running the SSR React application we just created is extremely simple, you just need to use the following command:</p>
<pre><code>deno run --allow-net ./server.tsx
</code></pre>
<p>Deno is built secure by default, that means that a Deno application will not be able to access your network, to overcome this we'll just need to use Deno's <code>--allow-net</code> flag.<br>
Now the only thing missing is to open <code>http://localhost:8008/</code> and enjoy your new App!</p>
<h2>Conclusion</h2>
<p>I hope you enjoyed the brief tutorial illustrated in this article and I’m looking forward to seeing what will happen next and how more complex applications can be built with this stack.</p>
<p>If you are still unclear about anything we’ve done or want a full reference of the code, here’s the <a href="https://github.com/fleonard/deno-react-ssr">GitHub repository</a>.</p>
</div>
    </div></div>]]>
            </description>
            <link>https://dev.p.ota.to/post/server-side-rendering-react-app-with-deno-4qf28vm8axb/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23638676</guid>
            <pubDate>Thu, 25 Jun 2020 09:34:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Beautiful Visualisations with the Chord Package]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23638474">thread link</a>) | @shahinrostami
<br/>
June 25, 2020 | https://shahinrostami.com/posts/statistics/data-is-beautiful/animal-crossing-villagers-species-and-personalities/ | <a href="https://web.archive.org/web/*/https://shahinrostami.com/posts/statistics/data-is-beautiful/animal-crossing-villagers-species-and-personalities/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="alert">
        <p><a href="https://stamilabs.com/">
        <img src="https://shahinrostami.com/images/stami-labs/mascot/lablet.svg"></a>
            <a href="https://stamilabs.com/">Join our Stami Labs Patreon</a> to get <b>Exclusive Downloads</b>, <b>Direct Support</b>, <b>Early Access</b>, <b>Voting Access</b>, our <b>Books for Free</b>, and so much more!
        </p>
    </div><div role="alert">
        <p><a href="https://store.shahinrostami.com/product/data-is-beautiful/">
        <img src="https://shahinrostami.com/images/data-is-beautiful/front.jpg"></a>
            Enjoying these notebooks and want to support the work?
            Get the <a href="https://store.shahinrostami.com/product/data-is-beautiful/">Data is Beautiful Book</a> or check out the <a href="https://www.youtube.com/playlist?list=PLwWiU_ClpuYpC1tEY47k_-CTzDKz1UYIN">Complementary Videos</a>.
        </p>
        </div></div>]]>
            </description>
            <link>https://shahinrostami.com/posts/statistics/data-is-beautiful/animal-crossing-villagers-species-and-personalities/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23638474</guid>
            <pubDate>Thu, 25 Jun 2020 09:04:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to get your first 100 users as a SaaS startup founder?]]>
            </title>
            <description>
<![CDATA[
Score 35 | Comments 19 (<a href="https://news.ycombinator.com/item?id=23638173">thread link</a>) | @nathanganser
<br/>
June 25, 2020 | https://blog.nat.app/how-to-get-your-first-100-users-as-a-saas-startup-founder-ckbnjyv6v00oajps1v7082imx | <a href="https://web.archive.org/web/*/https://blog.nat.app/how-to-get-your-first-100-users-as-a-saas-startup-founder-ckbnjyv6v00oajps1v7082imx">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>You've got to start somewhere right. You've got your landing page and maybe even an MVP, but no one is visiting your website! How do you actually get those first 100 users? I've been there myself with  <a target="_blank" rel="noopener noreferrer" href="https://nat.app/">my startup</a>, and I would have loved to read such an article when I got started, so here it is! In honour of my past self and to help all fellow startup founders! </p>
<h2 id="get-started">Get started</h2>
<p>Here are a few basic tips you should get started with. They will pay off in the coming months. </p>
<h3 id="start-with-seo">Start with SEO</h3>
<p>SEO will not get you users overnight, but it's an amazing long term investment. Do it. 
Obviously, don't try to rank for super general keywords, instead, focus on niche keywords your audience is interested in. Here are a few examples from our own startup: </p>
<ul>
<li><a target="_blank" rel="noopener noreferrer" href="https://medium.com/@nathanganser/which-contacts-am-i-losing-touch-with-find-out-now-25f2db1320c3">Which contacts am I losing touch with? Find out now</a> </li>
<li><a target="_blank" rel="noopener noreferrer" href="https://medium.com/nat-personal-relationship-manager/what-is-a-gmail-metadata-integration-and-why-you-should-use-it-57b37fe54dbe">What is a Gmail Metadata integration and why you should use it</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://medium.com/nat-personal-relationship-manager/how-i-created-an-automated-relationship-management-tool-using-coda-zapier-8a31a6d2ebe2">How I created an Automated Relationship Management tool using Coda &amp; Zapier</a>  </li>
<li><a target="_blank" rel="noopener noreferrer" href="https://medium.com/nat-personal-relationship-manager/the-ultimate-personal-relationship-manager-list-2ae87acf5070">Top 6 Best Personal CRM apps</a> </li>
</ul>
<p><em>Like passive income, those articles are generating a steady (albeit small) traffic to our app. But what's powerful about this traffic is that its super high-quality people. Only passionate people will find your articles, and when they do, they'll check out your app as well. </em></p>
<h3 id="quora-twitter-answer-to-questions">Quora &amp; Twitter: Answer to questions</h3>
<p>Create a company account and start replying to questions related to what you're doing. Twitter has a really good advanced search feature and Quora will suggest you more than enough questions you can reply to. If you spend a few hours each week generating good content on those platforms, you'll get a steady stream of clicks to your landing page as well. </p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1592240101831/sk3gE249t.png?auto=format&amp;q=60" alt="quora-answers-stats.png"></p>
<h3 id="pioneer-app">Pioneer.app</h3>
<p> <a target="_blank" rel="noopener noreferrer" href="https://pioneer.app/">Pioneer</a>  is an online accelerator that you can join for free. Every week, you submit a progress update and other users will give you feedback. This is a free way to get a few clicks to your app from startup founders. </p>
<h3 id="get-listed-on-10words-betalist">Get listed on 10words &amp; Betalist</h3>
<p> <a target="_blank" rel="noopener noreferrer" href="https://10words.io/">10words</a> and  <a target="_blank" rel="noopener noreferrer" href="https://blog.nat.app/betalist.com">BetaList</a> are like a small Product Hunts. They are much smaller, you can expect around 50 clicks to your website for each. Still worth something! </p>
<h3 id="list-your-startup-on-indie-hacker-makerlog">List your startup on Indie Hacker &amp; Makerlog</h3>
<p>Those are two cool communities. If you're active, you'll definitely get some attention and users! </p>
<ul>
<li><a target="_blank" rel="noopener noreferrer" href="https://getmakerlog.com/">MakerLog</a> </li>
<li><a target="_blank" rel="noopener noreferrer" href="https://blog.nat.app/indiehackers.com">Indie Hacker</a></li>
</ul>
<h3 id="product-hunt-ship">Product Hunt Ship</h3>
<p>Product Hunt has a place for upcoming apps called <strong> <a target="_blank" rel="noopener noreferrer" href="https://www.producthunt.com/ship">Ship</a> </strong>, I've not found it to be very useful, but it can get you a few additional users. </p>
<h2 id="growth-hacks">Growth hacks</h2>
<p>That's where stuff gets exciting. Use these growth hacks with moderation, there is a fine line between marketing and spamming. </p>
<h3 id="product-hunt-phantombuster-twitter">Product Hunt + PhantomBuster + Twitter</h3>
<p>If there are already a few apps on ProductHunt that are similar to what you're building, consider using  <a target="_blank" rel="noopener noreferrer" href="https://www.indiehackers.com/post/how-i-growth-hacked-my-way-to-500-waiting-list-subscribers-9612933fd3">this growth hack</a>. I've used it extensively myself. </p>
<h3 id="buy-targeted-email-lists">Buy targeted email lists</h3>
<p>I've built a tool myself that lets me scrape email addresses from founders on Indie Hacker. What's powerful is that you can filter by every filter available on Indie Hacker (revenue, location, business model, ...). You can use it to buy an email list here and use a tool like <a target="_blank" rel="noopener noreferrer" href="https://gmass.com/">Gmass</a> or Streak to reach out.  <a target="_blank" rel="noopener noreferrer" href="https://scrapeindiehacker.app/">Buy a list here</a>.</p>
<p>I don't recommend just sending the same email to everyone as this will impact your reputation. Instead, send personalized mass emails. It does take a bit longer, but it's worth every second considering the impact it will have on response rate and trust.</p>

<p>There are many chrome extensions out there that have tons of users but that are not maintained anymore. You can buy one for very cheap that is related to what you do and advertise your business on there. I bought  <a target="_blank" rel="noopener noreferrer" href="https://chrome.google.com/webstore/detail/google-contacts-opener/pjpambjkhcilibnmeihhfgdkhfelbdkj">Google Contacts Opener</a>  and it's been generating significant traffic to our website ever since. </p>
<h2 id="what-you-should-not-be-doing">What you should not be doing</h2>
<h3 id="advertising">Advertising</h3>
<p>It will cost you too much. Just don't think about it. In the early days, ads are not the way to go.</p>
<h3 id="launch-on-product-hunt">Launch on Product Hunt</h3>
<p>You've got only one shot at this, it better be big. You don't want to launch on Product Hunt before having built a mature product. Product Hunt is not for the launching phase, it's for the growth phase.  <a target="_blank" rel="noopener noreferrer" href="https://betalist.com/">BetaList</a> is a better place to start.</p>
<h3 id="my-startup-s-traffic">My startup's traffic</h3>
<p>Here is a breakdown of who visited our website recently. This will give you a better idea of what you should focus on. 
<img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1592241905463/7LrJ4YdmB.png?auto=format&amp;q=60" alt="website visitor origin.png"></p>
</div></div>]]>
            </description>
            <link>https://blog.nat.app/how-to-get-your-first-100-users-as-a-saas-startup-founder-ckbnjyv6v00oajps1v7082imx</link>
            <guid isPermaLink="false">hacker-news-small-sites-23638173</guid>
            <pubDate>Thu, 25 Jun 2020 08:21:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Zoom works [slides]]]>
            </title>
            <description>
<![CDATA[
Score 186 | Comments 143 (<a href="https://news.ycombinator.com/item?id=23638116">thread link</a>) | @Spidery
<br/>
June 25, 2020 | https://builtformars.co.uk/how-zoom-works/ | <a href="https://web.archive.org/web/*/https://builtformars.co.uk/how-zoom-works/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-elementor-type="single" data-elementor-id="2530" data-elementor-settings="[]">
		<div>
			<div>
						<section data-id="c26fc93" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="28a6896" data-element_type="column">
			<div>
					<div>
				
				<div data-id="b04b2c1" data-element_type="widget" data-widget_type="theme-post-excerpt.default">
				<p>
			Zoom is a significant challenger in the video conferencing space, but is their UX any better than Skype or Cisco?		</p>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="052a335" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="4224d77" data-element_type="column">
			<div>
					<div>
				<div data-id="5ad8739" data-element_type="widget" data-widget_type="theme-post-featured-image.default">
				<div>
					<p><img width="720" height="410" src="https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom.png" alt="Zoom UX case study" srcset="https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom.png 1018w, https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom-300x171.png 300w, https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom-768x438.png 768w, https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom-100x57.png 100w, https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom-700x399.png 700w" sizes="(max-width: 720px) 100vw, 720px">											</p>
				</div>
				</div>
						</div>
			</div>
		</div>
				<div data-id="a001539" data-element_type="column">
			<div>
					<div>
				
				<div data-id="724633a" data-element_type="widget" data-widget_type="post-info.default">
				<div>
					<ul>
					<li itemprop="datePublished">
										<span>
															</span>
									<span>
							<span>📅 Added on</span>
										April 15, 2020					</span>
								</li>
				</ul>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="2643ed8" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="a995590" data-element_type="column">
			<div>
					<div>
				<div data-id="c9f06a8" data-element_type="widget" data-widget_type="theme-post-featured-image.default">
				<div>
					<p><img width="720" height="410" src="https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom.png" alt="Zoom UX case study" srcset="https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom.png 1018w, https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom-300x171.png 300w, https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom-768x438.png 768w, https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom-100x57.png 100w, https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom-700x399.png 700w" sizes="(max-width: 720px) 100vw, 720px">											</p>
				</div>
				</div>
						</div>
			</div>
		</div>
				
						</div>
			</div>
		</section>
				<section data-id="ca3ca43" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
							
							<div>
				<div>
				<div data-id="ec20c55" data-element_type="column">
			<div>
					<div>
				<div data-id="682e138" data-element_type="widget" data-widget_type="theme-post-content.default">
				<div>
					<div data-elementor-type="wp-post" data-elementor-id="3204" data-elementor-settings="[]">
			<div>
				<div>
							<section data-id="7b73c3c" data-element_type="section">
						<div>
				<div>
				<div data-id="d0a7d7b" data-element_type="column">
			<div>
					<div>
				<div data-id="cd0bf0c" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><div><div role="region" aria-label="Slider"><p><img src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxMjAwIiBoZWlnaHQ9IjkwMCIgPjwvc3ZnPg==" alt="Slider"></p></div></div></div>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
						</div>
			</div>
		</div>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="375357f" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="353f855" data-element_type="column">
			<div>
					<div>
				<div data-id="891920c" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>💡<strong>Tip:</strong> Try using the ⬅️ <span>➡️arrows on your keyboard to navigate the slides.</span></p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="9ffc41b" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="5f2393c" data-element_type="column">
			<div>
					<div>
				<div data-id="b2a958e" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p><strong>Mobile tip:</strong> Try swiping ⬅️<span>👆➡️ left and right to navigate the slides.</span></p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="5094e89" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="4d0fdca" data-element_type="column">
			<div>
					<div>
				
				<div data-id="560b6f9" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>New case studies—packed with UX lessons—are published every <strong>14 days</strong>.</p>
				</div>
				</div>
				<div data-id="c135888" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p><span>📮 No spam, ever.&nbsp; &nbsp;</span><span>📅 1 email a week.&nbsp; &nbsp;</span><span>👋 Unsubscribe anytime.</span></p>
				</div>
				</div>
				
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="3daa393" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="4876312" data-element_type="column">
			<div>
					<div>
				<section data-id="05a68ee" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="09ef108" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
			<div>
							
					<div>
				<div data-id="31901c7" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>Subscribe and get a new case study like this every <strong>14 days</strong>!</p>
				</div>
				</div>
						</div>
			</div>
		</div>
				
						</div>
			</div>
		</section>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="94d99dd" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="3a870f9" data-element_type="column">
			<div>
					<div>
				<div data-id="91f57f2" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>There’s always more to learn</p>
				</div>
				</div>
				<div data-id="2f5c033" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>Dive into other case studies. They’re typically a <strong>5 minute read</strong>.</p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="c62cabd" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						
		</section>
					</div>
		</div>
		</div></div>]]>
            </description>
            <link>https://builtformars.co.uk/how-zoom-works/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23638116</guid>
            <pubDate>Thu, 25 Jun 2020 08:13:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Goodbye, Bountysource]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23637831">thread link</a>) | @reddotX
<br/>
June 25, 2020 | https://blog.elementary.io/goodbye-bountysource-hello-github-sponsors/ | <a href="https://web.archive.org/web/*/https://blog.elementary.io/goodbye-bountysource-hello-github-sponsors/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  
  <header>
    
    
      <h2>



   We’re leaving Bountysource. Here’s&nbsp;why.

</h2>
    

    



<div>
  <p><img srcset="https://www.gravatar.com/avatar/41275ecc8271aca852ce2c0ff72d2610?s=96&amp;d=blank 2x" src="https://www.gravatar.com/avatar/41275ecc8271aca852ce2c0ff72d2610?s=48&amp;d=blank" alt="Avatar for Cassidy James Blaede">
  </p>
  
  <p><time datetime="2020-06-24">Wed, Jun 24, 2020</time>
  
    <span title="Estimated read time">
  
  4 min read
</span>


  
</p></div>


    


  </header>

  <section>
    <p><img src="https://blog.elementary.io/images/goodbye-bountysource-hello-github-sponsors/feature.png" alt="Bountysource → GitHub Sponsors" width="800" height="450" srcset="https://blog.elementary.io/images/goodbye-bountysource-hello-github-sponsors/feature@2x.png"></p>

<p>If you have used <a rel="nofollow noopener noreferrer" target="_blank" href="https://bountysource.com/">Bountysource</a> in the past, you may have received an email announcing new terms of service that included a clause that would forfeit unclaimed bounties. On June 16, Bountysource sent this message:</p>

<blockquote>
  <p>You are receiving this email because we are updating the Bountysource Terms of Service, effective 1st July 2020.</p>

  <h4 id="whats-changing">What’s changing?</h4>
  <p>We have added a Time-Out clause to the Bounties section of the agreement:</p>

  <blockquote>
    <p><em>2.13 Bounty Time-Out.</em></p>

    <p><em>If no Solution is accepted within two years after a Bounty is posted, then the Bounty will be withdrawn and the amount posted for the Bounty will be retained by Bountysource. For Bounties posted before June 30, 2018, the Backer may redeploy their Bounty to a new Issue by contacting <a href="mailto:support@bountysource.com">support@<wbr>bountysource.com</a> before July 1, 2020. If the Backer does not redeploy their Bounty by the deadline, the Bounty will be withdrawn and the amount posted for the Bounty will be retained by Bountysource.</em></p>
  </blockquote>

  <p>…</p>
  <h4 id="what-do-i-need-to-do">What do I need to do?</h4>
  <p>If you agree to the new terms, you don’t have to do anything… Or, if you do not agree with the new terms, please discontinue using Bountysource.</p>
</blockquote>

<p>This gave open source projects and their bounty hunters just two weeks to act; oftentimes it would take <em>longer than that</em> to even get a response from the support team. The controversial terms have since been withdrawn—at least for now. On June 17, Bountysource sent the following message (emphasis theirs):</p>

<blockquote>
  <p>You’re receiving this because we updated our Terms of Service.</p>

  <h4 id="withdrawal-of-new-terms-of-service">Withdrawal of new Terms of Service</h4>
  <p>Yesterday, we communicated a change to the Bountysource Terms of Service (ToS) agreement. <br>
<strong>These changes have been withdrawn and the ToS reverted to its prior state.</strong><br>
The ToS will be revised and clarified in the future.</p>

  <p>Thankyou</p>
</blockquote>

<p>In December, 2017, <a rel="nofollow noopener noreferrer" target="_blank" href="https://web.archive.org/web/20191008103840/https://blog.canya.com/2017/12/20/canya-acquires-majority-stake-in-bountysource-adds-over-46000-users/">Bountysource was acquired</a> by a cryptocurrency company called CanYa who redesigned the Bountysource site and service with a new cryptocoin focus. In addition to the general friction we’ve experienced with using the service since to get developers paid, we feel like this policy change–even withdrawn–is concerning. It calls into question the future of Bountysource as a platform and the stability of their business model. While we understand that operating a platform incurs costs, we want to make sure that funds are primarily going to developers, not being automatically scooped up by corporate stakeholders.</p>

<p>These events have led us to re-think our recommendation and use of Bountysource. As such, we’ve removed Bountysource from our website, removed any Bountysource integration with elementary repos on GitHub, withdrawn our funds, and closed our account. For backers and bounty hunters on Bountysource, your bounties on elementary projects will automatically be returned to you. You may also wish to withdraw any funds and close your account by emailing <a href="mailto:support@bountysource.com">support@<wbr>bountysource.com</a>.</p>



<p>As an alternative, we recommend checking out <a rel="nofollow noopener noreferrer" target="_blank" href="https://github.com/sponsors/elementary">GitHub Sponsors</a>. We recently launched a few tiers on Sponsors, and have been very pleased with it.</p>

<p>You can directly sponsor <a rel="nofollow noopener noreferrer" target="_blank" href="https://github.com/sponsors/elementary">organizations like elementary</a>, as well as individual contributors. For elementary specifically, we have a new $50/month tier that offers the closest equivalent to a bug bounty program: each month, backers at this tier can comment on any elementary issue to get at least an hour of our investigation time. This is a great way to help steer development in the direction you see fit while also directly supporting us.</p>



<p>GitHub also covers payment processing and doesn’t charge any fees for GitHub Sponsors; this means <strong>100% of your sponsorship goes to elementary</strong> to help fund our work.</p>

<p>If GitHub Sponsors isn’t your cup of tea, you can also check out the funding section on our <a rel="nofollow noopener noreferrer" target="_blank" href="https://elementary.io/get-involved#funding">Get Involved</a> page to see other ways you can help support elementary OS.</p>


  </section>

  
<div>
  <hr>

  <h2>Thank You</h2>
  <p>Thanks to all of our supporters, backers, and customers! Your contributions make elementary possible. If you’d like to help build and improve elementary OS, don’t hesitate to <a rel="nofollow noopener noreferrer" target="_blank" href="https://elementary.io/get-involved">Get Involved</a>.</p>

  
</div>




</article></div>]]>
            </description>
            <link>https://blog.elementary.io/goodbye-bountysource-hello-github-sponsors/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23637831</guid>
            <pubDate>Thu, 25 Jun 2020 07:29:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No code tools for each stage of application development]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23637671">thread link</a>) | @GeneloJ
<br/>
June 25, 2020 | https://www.testcraft.io/no-code-tools-application-development/ | <a href="https://web.archive.org/web/*/https://www.testcraft.io/no-code-tools-application-development/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<div id="mk-page-id-6013">
					<div itemprop="mainEntityOfPage">
							
	<article id="6013" itemscope="itemscope" itemprop="blogPost" itemtype="http://schema.org/BlogPosting">

					<h2 itemprop="headline">17 no-code tools for each stage of application development [Infographic]</h2>
	







<div itemprop="mainEntityOfPage">
	
<p>It seems that coding skills are becoming less and less of a barrier to building and launching a successful application.</p>
<p>No-code tools have offered everyone from small businesses to enterprises the opportunity to achieve digital transformation both simply and sustainably. In the <a href="https://www.forbes.com/sites/johneverhard/2019/01/15/what-really-is-low-codeno-code-development/#61935a6f2a8e" target="_blank" rel="noopener noreferrer">words of Forbes contributor John Everhard</a>, no-code, as well as often-associated low-code, solutions help “build powerful applications that can scale for any organization—without writing any code.”</p>
<p>Everhard further discussed in his article the powerful impact that no-code tools, also known as codeless tools, can have. With these types of software, IT teams no longer need to spend 60% of their time keeping their current systems working. Instead, no-code solutions help companies maintain a competitive edge over their peers with up to a 75% improvement on time to market.</p>
<p>Industry analysts have taken note of the “no-code movement” as well, with <a href="https://www.salesforce.com/blog/2019/08/gartner-lcap.html" target="_blank" rel="noopener noreferrer">Gartner predicting</a> that low-code application platforms (LCAP) will account for 65% of application development activity by 2024. Enterprises seem to be taking note as well, whether by <a href="https://www.testcraft.io/testcraft-joins-perforce/" target="_blank" rel="noopener noreferrer">acquiring codeless tools</a> or by releasing no-code capabilities of their own.</p>
<p>With that in mind, here is a list of different tools to keep on your radar in the no-code space. These tools cover every stage of application development, although there are other solutions that are not covered here, such as industry-specific solutions and payment applications.</p>

<h2><a href="https://www.testcraft.io/wp-content/uploads/2020/06/copy-of-17-no-code-tools-for-each-stage-of-application-development.pdf"><img src="https://www.testcraft.io/wp-content/uploads/2020/06/copy-of-17-no-code-tools-for-each-stage-of-application-development1-1-410x1024.png" alt="17 no-code tools for each stage of application development infographic" width="410" height="1024" srcset="https://www.testcraft.io/wp-content/uploads/2020/06/copy-of-17-no-code-tools-for-each-stage-of-application-development1-1-410x1024.png 410w, https://www.testcraft.io/wp-content/uploads/2020/06/copy-of-17-no-code-tools-for-each-stage-of-application-development1-1-120x300.png 120w, https://www.testcraft.io/wp-content/uploads/2020/06/copy-of-17-no-code-tools-for-each-stage-of-application-development1-1-768x1920.png 768w, https://www.testcraft.io/wp-content/uploads/2020/06/copy-of-17-no-code-tools-for-each-stage-of-application-development1-1.png 800w" sizes="(max-width: 410px) 100vw, 410px"></a></h2>
<h2>No-code web &amp; mobile application development tools</h2>
<ul>
<li><strong><a href="https://bubble.io/" target="_blank" rel="noopener noreferrer">Bubble</a></strong>: A visual programming language that helps anyone build a web application without coding knowledge.</li>
<li><strong><a href="https://www.glideapps.com/" target="_blank" rel="noopener noreferrer">Glide</a></strong>: A free no-code tool that allows users to build a mobile application in five minutes from Google Sheets.</li>
<li><strong><a href="https://www.voiceflow.com/" target="_blank" rel="noopener noreferrer">Voiceflow</a></strong>: A codeless way to develop voice apps for Amazon Alexa and Google Assistant.</li>
<li><strong><a href="https://webflow.com/" target="_blank" rel="noopener noreferrer">Webflow</a></strong>: An online visual editor platform that allows users to design, build, and launch responsive websites.</li>
<li><strong><a href="https://carrd.co/" target="_blank" rel="noopener noreferrer">Carrd</a></strong>: A free platform for building simple, fully responsive one-page web sites without code.</li>
</ul>
<h2>Codeless testing tools</h2>
<ul>
<li><strong><a href="https://www.testcraft.io/product/" target="_blank" rel="noopener noreferrer">TestCraft</a></strong>: A codeless Selenium test automation platform for continuous and regression testing of web applications.</li>
<li><strong><a href="https://www.accelq.com/codeless_api" target="_blank" rel="noopener noreferrer">AccelQ API</a></strong>: A no-code API test automation tool that allows companies to test REST APIs.</li>
<li><strong><a href="https://www.pcloudy.com/" target="_blank" rel="noopener noreferrer">pCloudy</a></strong>: A mobile test automation platform that helps users build and execute mobile tests without code.</li>
</ul>
<h2>No-code content and data management tools</h2>
<ul>
<li><strong><a href="https://airtable.com/" target="_blank" rel="noopener noreferrer">Airtable</a></strong>: A spreadsheet-database hybrid that helps teams manage content, projects, and other initiatives.</li>
<li><strong><a href="https://www.notion.so/" target="_blank" rel="noopener noreferrer">Notion</a></strong>: A no-code tool for managing documents, notes, tasks, spreadsheets, and databases.</li>
</ul>
<h2>Visual task automation tools</h2>
<ul>
<li><strong><a href="https://zapier.com/" target="_blank" rel="noopener noreferrer">Zapier</a></strong>: A codeless tool for connecting your applications and automating your workflows.</li>
<li><strong><a href="https://tryretool.com/" target="_blank" rel="noopener noreferrer">Retool</a></strong>: A platform for building internal tools without code.</li>
<li><strong><a href="https://www.actiondesk.io/" target="_blank" rel="noopener noreferrer">ActionDesk</a></strong>: A spreadsheet software that lets you import data from SQL, Stripe, Salesforce, HubSpot, and others to automate a variety of tasks.</li>
<li><strong><a href="https://build.stdlib.com/" target="_blank" rel="noopener noreferrer">Standard Library</a></strong>: A no-code library that helps users build automated workflows and APIs.</li>
</ul>
<h2>Codeless communication tools</h2>
<ul>
<li><strong><a href="https://www.typeform.com/" target="_blank" rel="noopener noreferrer">Typeform</a></strong>: A tool for designing surveys and other responsive forms without code.</li>
<li><strong><a href="https://mailchimp.com/" target="_blank" rel="noopener noreferrer">Mailchimp</a></strong>: A no-code email marketing service that gives users the ability to create professional, designed emails visually.</li>
<li><strong><a href="https://anchor.fm/" target="_blank" rel="noopener noreferrer">Anchor</a></strong>: A codeless platform for creating, hosting, and distributing podcast episodes.</li>
</ul>

<p><!--HubSpot Call-to-Action Code --><span id="hs-cta-wrapper-6302584c-b0f6-4c2f-b1f8-c05e4cede1aa"><span id="hs-cta-6302584c-b0f6-4c2f-b1f8-c05e4cede1aa"><!-- [if lte IE 8]>


<div id="hs-cta-ie-element"></div>


<![endif]--><a href="https://cta-redirect.hubspot.com/cta/redirect/2539507/6302584c-b0f6-4c2f-b1f8-c05e4cede1aa" target="_blank" rel="noopener noreferrer"><img id="hs-cta-img-6302584c-b0f6-4c2f-b1f8-c05e4cede1aa" src="https://no-cache.hubspot.com/cta/default/2539507/6302584c-b0f6-4c2f-b1f8-c05e4cede1aa.png" alt="Selenium Testing eBook" width="800" height="160"></a></span></span><!-- end HubSpot Call-to-Action Code --></p>
</div>



    
</article>

							
											</div>
					
					
				</div>
			</div></div>]]>
            </description>
            <link>https://www.testcraft.io/no-code-tools-application-development/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23637671</guid>
            <pubDate>Thu, 25 Jun 2020 07:02:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why AES-GCM Sucks]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23637605">thread link</a>) | @yinso
<br/>
June 24, 2020 | https://soatok.blog/2020/05/13/why-aes-gcm-sucks/ | <a href="https://web.archive.org/web/*/https://soatok.blog/2020/05/13/why-aes-gcm-sucks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<p>If you’re reading this wondering if you should stop using AES-GCM in some standard protocol (TLS 1.3), the short answer is “No, you’re fine”. </p>



<p>I specialize in secure implementations of cryptography, and my years of experience in this field have led me to dislike AES-GCM.</p>



<p>This post is about why I dislike AES-GCM’s design, not “why AES-GCM is insecure and should be avoided”. AES-GCM is still miles above what most developers reach for when they want to encrypt (e.g. <a href="https://blog.filippo.io/the-ecb-penguin">ECB mode</a> or <a href="https://robertheaton.com/2013/07/29/padding-oracle-attack/">CBC mode</a>).</p>



<p>To be clear: This is solely my opinion and not representative of any company or academic institution.</p>



<h2 id="what-is-aes-gcm">What is AES-GCM?</h2>



<p>AES-GCM is an authenticated encryption mode that uses the AES block cipher in counter mode with a polynomial MAC based on Galois field multiplication.</p>



<p>In order to explain why AES-GCM sucks, I have to first explain what I dislike about the AES block cipher. Then, I can describe why I’m filled with sadness every time I see the AES-GCM construction used.</p>



<h3 id="what-is-aes">What is AES?</h3>



<p>The Advanced Encryption Standard (AES) is a specific subset of a block cipher called Rijndael.</p>



<p>Rijndael’s design is based on a substitution-permutation network, which broke tradition from many block ciphers of its era (including its predecessor, DES) in not using a Feistel network.</p>



<p>AES only includes three flavors of Rijndael: AES-128, AES-192, and AES-256. The difference between these flavors is the size of the key and the number of rounds used, but–and this is often overlooked–not the block size.</p>



<p>As a block cipher, AES always operates on 128-bit (16 byte) blocks of plaintext, regardless of the key size.</p>



<p>This is generally considered acceptable because AES is a secure pseudorandom permutation (PRP), which means that every possible plaintext block maps directly to one ciphertext block, and thus <a href="https://en.wikipedia.org/wiki/Birthday_problem#Cast_as_a_collision_problem">birthday collisions</a> are not possible. (A pseudorandom function (PRF), conversely, does have birthday bound problems.)</p>



<h3 id="why-aes-sucks">Why AES Sucks</h3>







<h4 id="side-channels">Side-Channels</h4>



<p>The biggest reason why AES sucks is that its design uses a lookup table (called an S-Box) <a href="https://github.com/veorq/cryptocoding#avoid-table-look-ups-indexed-by-secret-data">indexed by secret data</a>, which is inherently vulnerable to cache-timing attacks (<a href="https://cr.yp.to/antiforgery/cachetiming-20050414.pdf">PDF</a>).</p>



<p>There are workarounds for this AES vulnerability, but they either require hardware acceleration (AES-NI) or a technique called <a href="https://github.com/jedisct1/libsodium/tree/1.0.14/src/libsodium/crypto_stream/aes128ctr/nacl">bitslicing</a>.</p>



<p>The short of it is: With AES, you’re either using hardware acceleration,<em> or </em>you have to choose between performance and security. You cannot get fast, constant-time AES without hardware support.</p>



<h4 id="block-size">Block Size</h4>



<p>AES-128 is considered by experts to have a security level of 128 bits.</p>



<p>Similarly, AES-192 gets certified at 192-bit security, and AES-256 gets 256-bit security.</p>



<p><strong>However, the AES block size is only 128 bits!</strong></p>



<p>That might not sound like a big deal, but it severely limits the constructions you can create out of AES.</p>



<p>Consider the case of <a href="https://en.wikipedia.org/wiki/Block_cipher_mode_of_operation#Cipher_block_chaining_(CBC)">AES-CBC</a>, where the output of each block of encryption is combined with the next block of plaintext (using XOR). This is typically used with a random 128-bit block (called the initialization vector, or IV) for the first block.</p>



<p>This means you expect a collision after encrypting <img src="https://s0.wp.com/latex.php?latex=2%5E%7B64%7D&amp;bg=0a0a0a&amp;fg=f0f0f0&amp;s=3" alt="2^{64}" title="2^{64}"> (at 50% probability) blocks.</p>



<p>When you start getting collisions, you can break CBC mode, as this video demonstrates:</p>



<figure><p><span><iframe width="580" height="327" src="https://www.youtube.com/embed/v0IsYNDMV7A?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span>
</p><figcaption>Their attack on CBC mode completely hand-waves away the block size detail that the demo depends on, but so long as you keep that in mind, their attack is valid.</figcaption></figure>



<p>This is significantly smaller than the <img src="https://s0.wp.com/latex.php?latex=2%5E%7B128%7D&amp;bg=0a0a0a&amp;fg=f0f0f0&amp;s=3" alt="2^{128}" title="2^{128}"> you expect from AES.</p>



<h4 id="aes-post-quantum">Post-Quantum Security?</h4>



<p>Cryptographers estimate that AES-128 will have a post-quantum security level of  64 bits, AES-192 will have a post-quantum security level of 96 bits, and AES-256 will have a post-quantum security level of 128 bits.</p>



<p>This is because Grover’s quantum search algorithm can search <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=0a0a0a&amp;fg=f0f0f0&amp;s=3" alt="n" title="n"> unsorted items in <img src="https://s0.wp.com/latex.php?latex=%5Csqrt%7Bn%7D&amp;bg=0a0a0a&amp;fg=f0f0f0&amp;s=3" alt="\sqrt{n}" title="\sqrt{n}"> time, which can be used to reduce the total number of possible secrets from <img src="https://s0.wp.com/latex.php?latex=2%5E%7Bn%7D&amp;bg=0a0a0a&amp;fg=f0f0f0&amp;s=3" alt="2^{n}" title="2^{n}"> to <img src="https://s0.wp.com/latex.php?latex=%5Csqrt%7B2%5E%7Bn%7D%7D&amp;bg=0a0a0a&amp;fg=f0f0f0&amp;s=3" alt="\sqrt{2^{n}}" title="\sqrt{2^{n}}">. This cuts the security level, expressed in bits, in half.</p>



<p><strong>But remember, even AES-256 operates on 128-bit blocks.</strong></p>



<p>Consequently, for AES-256, there should be approximately <img src="https://s0.wp.com/latex.php?latex=2%5E%7B128%7D&amp;bg=0a0a0a&amp;fg=f0f0f0&amp;s=3" alt="2^{128}" title="2^{128}"> (plaintext, key) pairs that produce any given ciphertext block.</p>



<p>Furthermore, there will be many keys that, for a constant plaintext block, will produce the same ciphertext block despite being a different key entirely. (n.b. This doesn’t mean for <em>all</em> plaintext/ciphertext block pairings, just some arbitrary pairing.)</p>



<p><strong>Concrete example:</strong> Encrypting a plaintext block consisting of sixteen NUL bytes will yield a specific 128-bit ciphertext exactly once for each given AES-128 key. However, there are <img src="https://s0.wp.com/latex.php?latex=2%5E%7B128%7D&amp;bg=0a0a0a&amp;fg=f0f0f0&amp;s=3" alt="2^{128}" title="2^{128}"> times as many AES-256 keys as there are possible plaintext/ciphertexts. Keep this in mind for AES-GCM.</p>



<p>This means it’s conceivable to accidentally construct a protocol that, despite using AES-256 safely, has a post-quantum security level on par with AES-128, which is only 64 bits.</p>



<p>This would <em>not</em> be nearly as much of a problem if AES’s block size was 256 bits.</p>



<h4 id="aes-signal-protocol">Real-World Example: Signal</h4>



<p>The Signal messaging app is the state-of-the-art for private communications. If you were previously <a href="https://latacora.micro.blog/2019/07/16/the-pgp-problem.html">using PGP</a> and email, you should use Signal instead.</p>



<p>Signal aims to provide private communications (text messaging, voice calls) between two mobile devices, piggybacking on your pre-existing contacts list.</p>



<p>Part of their operational requirements is that they must be user-friendly and secure on a wide range of Android devices, stretching all the way back to Android 4.4.</p>



<p>The Signal Protocol uses <a href="https://github.com/signalapp/libsignal-protocol-java/blob/4f5e1ff299cea22cc75bb97249020a7da67b816d/java/src/main/java/org/whispersystems/libsignal/SessionCipher.java#L395-L413">AES-CBC</a> + <a href="https://github.com/signalapp/libsignal-protocol-java/blob/4f5e1ff299cea22cc75bb97249020a7da67b816d/java/src/main/java/org/whispersystems/libsignal/protocol/SignalMessage.java#L111-L139">HMAC-SHA256</a> for message encryption. Each message is encrypted with a different AES key (due to the <a href="https://signal.org/docs/specifications/doubleratchet/">Double Ratchet</a>), which limits the practical blast radius of a cache-timing attack and makes practical exploitation difficult (since you can’t effectively replay decryption in order to leak bits about the key).</p>



<p>Thus, Signal’s message encryption is still secure even in the presence of vulnerable AES implementations.</p>



<div><figure><img data-attachment-id="128" data-permalink="https://soatok.blog/hype/" data-orig-file="https://soatok.files.wordpress.com/2020/04/hype.png" data-orig-size="224,224" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Hype!" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2020/04/hype.png?w=224" data-large-file="https://soatok.files.wordpress.com/2020/04/hype.png?w=224" src="https://soatok.files.wordpress.com/2020/04/hype.png?w=224" alt="Soatok is HYPED!!!" srcset="https://soatok.files.wordpress.com/2020/04/hype.png 224w, https://soatok.files.wordpress.com/2020/04/hype.png?w=150 150w" sizes="(max-width: 224px) 100vw, 224px"><figcaption>Hooray for well-engineered protocols managing to actually protect users.<br>Art by <a href="https://twitter.com/swizzlestixick">Swizz</a>.</figcaption></figure></div>



<p>However, the storage service in the Signal App uses <a href="https://github.com/signalapp/Signal-Android/blob/c24d285cd3e93f32fbcd94c7296aa6ac3a6967d0/libsignal/service/src/main/java/org/whispersystems/signalservice/api/storage/SignalStorageCipher.java">AES-GCM</a>, and this key has to be reused in order for the encrypted storage to operate.</p>



<p>This means, for older phones without dedicated hardware support for AES (i.e. low-priced phones from 2013, which Signal aims to support), <strong>the risk of cache-timing attacks is still present</strong>.</p>



<div><figure><img data-attachment-id="130" data-permalink="https://soatok.blog/computeranger/" data-orig-file="https://soatok.files.wordpress.com/2020/04/computeranger.png" data-orig-size="224,224" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="This is outrageous!" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2020/04/computeranger.png?w=224" data-large-file="https://soatok.files.wordpress.com/2020/04/computeranger.png?w=224" src="https://soatok.files.wordpress.com/2020/04/computeranger.png?w=224" alt="Soatok angrily grasping computer monitor" srcset="https://soatok.files.wordpress.com/2020/04/computeranger.png 224w, https://soatok.files.wordpress.com/2020/04/computeranger.png?w=150 150w" sizes="(max-width: 224px) 100vw, 224px"><figcaption>This is unacceptable!</figcaption></figure></div>



<p>What this means is, a malicious app that can flush the CPU cache and measure timing with sufficient precision can siphon the AES-GCM key used by Signal to encrypt your storage without ever violating the security boundaries enforced by the Android operating system.</p>



<p>As a result of the security boundaries never being crossed, these kind of side-channel attacks would likely evade forensic analysis, and would therefore be of interest to the malware developers working for nation states.</p>



<p>Of course, if you’re on newer hardware (i.e. Qualcomm Snapdragon 835), you have hardware-accelerated AES available, so it’s probably a moot point.</p>



<h3 id="aes-gcm-worse">Why AES-GCM Sucks Even More</h3>



<p>AES-GCM is an authenticated encryption mode that also supports additional authenticated data. Cryptographers call these modes <a href="https://tonyarcieri.com/all-the-crypto-code-youve-ever-written-is-probably-broken">AEAD</a>.</p>



<p>AEAD modes are more flexible than simple block ciphers. Generally, your encryption API accepts the following:</p>



<ol><li>The plaintext message.</li><li>The encryption key.</li><li>A nonce (<img src="https://s0.wp.com/latex.php?latex=n_%7Bonce%7D&amp;bg=0a0a0a&amp;fg=f0f0f0&amp;s=3" alt="n_{once}" title="n_{once}">: A number that must only be used once).</li><li>Optional additional data which will be authenticated but not encrypted.</li></ol>



<p>The output of an AEAD function is both the ciphertext and an authentication tag, which is necessary (along with the key and nonce, and optional additional data) to decrypt the plaintext.</p>



<p>Cryptographers almost universally recommend using AEAD modes for symmetric-key data encryption.</p>



<p>That being said, AES-GCM is possibly my least favorite AEAD, and I’ve got good reasons to dislike it beyond simply, “It uses AES”.</p>



<div><figure><img data-attachment-id="119" data-permalink="https://soatok.blog/soatok_stickerpack-rage/" data-orig-file="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-rage.png" data-orig-size="512,512" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Soatok Angery" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-rage.png?w=300" data-large-file="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-rage.png?w=512" src="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-rage.png?w=512" alt="Grrrrrr" srcset="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-rage.png 512w, https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-rage.png?w=150 150w, https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-rage.png?w=300 300w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>The deeper you look into AES-GCM’s design, the harder you will feel this sticker.</figcaption></figure></div>



<h4 id="ghash">GHASH Brittleness</h4>



<p>The way AES-GCM is initialized is stupid: You encrypt an all-zero block with your AES key (in ECB mode) and store it in a variable called <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=0a0a0a&amp;fg=f0f0f0&amp;s=3" alt="H" title="H">. This value is used for authenticating all messages authenticated under that AES key, rather than for a given (key, nonce) pair.</p>



<figure><a href="https://soatok.files.wordpress.com/2020/05/1000px-gcm-galois_counter_mode_with_iv.svg_.png" target="_blank"><img data-attachment-id="541" data-permalink="https://soatok.blog/1000px-gcm-galois_counter_mode_with_iv-svg_/" data-orig-file="https://soatok.files.wordpress.com/2020/05/1000px-gcm-galois_counter_mode_with_iv.svg_.png" data-orig-size="1000,1099" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="1000px-gcm-galois_counter_mode_with_iv.svg_" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2020/05/1000px-gcm-galois_counter_mode_with_iv.svg_.png?w=273" data-large-file="https://soatok.files.wordpress.com/2020/05/1000px-gcm-galois_counter_mode_with_iv.svg_.png?w=580" src="https://soatok.files.wordpress.com/2020/05/1000px-gcm-galois_counter_mode_with_iv.svg_.png?w=932" alt="" srcset="https://soatok.files.wordpress.com/2020/05/1000px-gcm-galois_counter_mode_with_iv.svg_.png?w=932 932w, https://soatok.files.wordpress.com/2020/05/1000px-gcm-galois_counter_mode_with_iv.svg_.png?w=136 136w, https://soatok.files.wordpress.com/2020/05/1000px-gcm-galois_counter_mode_with_iv.svg_.png?w=273 273w, https://soatok.files.wordpress.com/2020/05/1000px-gcm-galois_counter_mode_with_iv.svg_.png?w=768 768w, https://soatok.files.wordpress.com/2020/05/1000px-gcm-galois_counter_mode_with_iv.svg_.png 1000w" sizes="(max-width: 932px) 100vw, 932px"></a><figcaption>Diagram describing Galois/Counter Mode, taken from <a href="https://en.wikipedia.org/wiki/Galois/Counter_Mode">Wikipedia</a>.</figcaption></figure>



<p>This is often sold as an advantage: Reusing <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=0a0a0a&amp;fg=f0f0f0&amp;s=3" alt="H" title="H"> allows for better performance. However, it makes GCM brittle: Reusing a nonce allows an attacker to recover H and then forge messages forever. This is called the “forbidden attack”, and led to <a href="https://eprint.iacr.org/2016/475">real world practical breaks</a>.</p>



<p>Let’s contrast AES-GCM with the other AEAD mode supported by TLS: ChaCha20-Poly1305, or ChaPoly for short.</p>



<p>ChaPoly uses one-time message authentication keys (derived from each key/nonce pair). If you manage to leak a Poly1305 key, the impact is limited to the messages encrypted under that (ChaCha20 key, nonce) pair.</p>



<p>While that’s still <em>bad</em>, it isn’t “decrypt all messages under that key forever” bad like with AES-GCM.</p>



<h4 id="short-nonces">Short Nonces</h4>



<p>Although the AES block size is 16 bytes, AES-GCM nonces are only 12 bytes. The latter 4 bytes are dedicated to an internal counter, which is used with AES in Counter Mode to actually encrypt/decrypt messages. </p>



<p>(Yes, you can use arbitrary length nonces with AES-GCM, but if you use nonces longer than 12 bytes, they get hashed into 12 bytes anyway, so it’s not a detail most people should concern themselves with.)</p>



<p>If you ask a cryptographer, “How much can I encrypt safely with AES-GCM?” you’ll get two different answers.</p>



<ol><li><strong>Message Length Limit: </strong>AES-GCM can be used to encrypt messages up to <img src="https://s0.wp.com/latex.php?latex=2%5E%7B36%7D+-+32&amp;bg=0a0a0a&amp;fg=f0f0f0&amp;s=3" alt="2^{36} - 32" title="2^{36} - 32"> bytes long, under a given (key, nonce) pair.</li><li><strong>Number of Messages Limit: </strong>If you generate your nonces randomly, you have a 50% chance of a nonce collision after <img src="https://s0.wp.com/latex.php?latex=2%5E%7B48%7D&amp;bg=0a0a0a&amp;fg=f0f0f0&amp;s=3" alt="2^{48}" title="2^{48}"> messages.<p>However, 50% isn’t conservative enough for most systems, so the safety margin is usually much lower. Cryptographers generally set the key wear-out of AES-GCM at <img src="https://s0.wp.com/latex.php?latex=2%5E%7B32%7D&amp;bg=0a0a0a&amp;fg=f0f0f0&amp;s=3" alt="2^{32}" title="2^{32}"> …</p></li></ol></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://soatok.blog/2020/05/13/why-aes-gcm-sucks/">https://soatok.blog/2020/05/13/why-aes-gcm-sucks/</a></em></p>]]>
            </description>
            <link>https://soatok.blog/2020/05/13/why-aes-gcm-sucks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23637605</guid>
            <pubDate>Thu, 25 Jun 2020 06:49:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Liberty (1859) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 165 | Comments 101 (<a href="https://news.ycombinator.com/item?id=23636407">thread link</a>) | @mrfusion
<br/>
June 24, 2020 | https://socialsciences.mcmaster.ca/econ/ugcm/3ll3/mill/liberty.pdf | <a href="https://web.archive.org/web/*/https://socialsciences.mcmaster.ca/econ/ugcm/3ll3/mill/liberty.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div p="">&gt; 
endobj
379 0 obj
&lt;&lt; /S 964 /O 1045 /Filter /FlateDecode /Length 380 0 R &gt;&gt; 
stream
ì+ªýc„-ÌéEÎØµ«°L½÷Ëÿé;ÄÛxÃ¼to•F$ˆ¡)•ãz§%u­ÌP¬5,‚|)äìº„H”˜Ïk‚Æ&nbsp;s˜Z‡}8kxgF¼�Ew�‰	ÕìC¸‡2÷¨ÿ&gt;JùwãÏ@ãù«z‰7s¹vëëœEªœ:Øy±cˆ[°ÅÄ§ÁôCEb´.&gt;øõ½ó¶B�š:DØ´×¸æ¢¬aqäÁ"Õ&gt;(¿ìøzF|ñlçJ´W‘~|‹§	|hÓwÎ�&gt;|³¹Žö™&amp;¬frË�/^@¦Šà°GM4mejD›ê²õ`X–Þrm¯ð²ÝUdñØ"LjÝÁ{um]4tÈj»­)6qbÕ<v%aÁ£œps1�l`Ôbä2[›;� qhu'…„+~€úmÿÓ‚Ámïx="£ËÝfÊÙÁš¨Ìâ|â3É5¸æ£gøÕû‘jªãt" Øl4ï="ù2Jd·”õ" ŠÖö*uxi«Áx4ãõ€�´�+otx‰³ö÷ö,¼Þ1¢fçÐ¾›ûødÝ^h¸ÚdÎÌ4bÅs×Çê†~k%’î¦—¦¨éå6xª+§qÔÒ„†hÐ[s¹="ˆžµ—QäyÀ½fî¤u*�su$ØÐwrg" endstream="" endobj="" 380="" 0="" obj="" 488="" 352="" <<="" type="" page="" parent="" 336="" r="" resources="" 366="" contents="" 371="" mediabox="" [="" 432="" 648="" ]="" cropbox="" rotate="">&gt; 
endobj
353 0 obj
&lt;&lt; 
/Count 1 
/First 354 0 R 
/Last 354 0 R 
&gt;&gt; 
endobj
354 0 obj
&lt;&lt; 
/Title (T¬Þô¯ø1n)
/Dest [ 4 0 R /Fit ] 
/Parent 353 0 R 
/First 355 0 R 
/Last 356 0 R 
/Count -11 
&gt;&gt; 
endobj
355 0 obj
&lt;&lt; 
/Title (š[ÌBe°†à0úg)
/Dest [ 20 0 R /Fit ] 
/Parent 354 0 R 
/Next 365 0 R 
&gt;&gt; 
endobj
356 0 obj
&lt;&lt; 
/Title (‘'G`iŸ)
/Dest [ 320 0 R /Fit ] 
/Parent 354 0 R 
/Prev 357 0 R 
&gt;&gt; 
endobj
357 0 obj
&lt;&lt; 
/Title (°DÞ—9³Ùí+ Šk¹)
/Dest [ 260 0 R /Fit ] 
/Parent 354 0 R 
/Prev 358 0 R 
/Next 356 0 R 
&gt;&gt; 
endobj
358 0 obj
&lt;&lt; 
/Title (ø“€·+Š*—ÜI)
/Dest [ 260 0 R /Fit ] 
/Parent 354 0 R 
/Prev 359 0 R 
/Next 357 0 R 
&gt;&gt; 
endobj
359 0 obj
&lt;&lt; 
/Title (*I“KP8iÃ]3¨ŒÎÙÝÊÜ®%zÙ3k&gt;g’Bn~|‹Û°.¦7Z#Ð\(Ü²ÄÃhÿ"SÀv7�K/J\()
/Dest [ 209 0 R /Fit ] 
/Parent 354 0 R 
/Prev 360 0 R 
/Next 358 0 R 
&gt;&gt; 
endobj
360 0 obj
&lt;&lt; 
/Title (D7A­­*!P])
/Dest [ 209 0 R /Fit ] 
/Parent 354 0 R 
/Prev 361 0 R 
/Next 359 0 R 
&gt;&gt; 
endobj
361 0 obj
&lt;&lt; 
/Title (õËÃª5tT±ZOJR¨�»[¿5&lt;¿j+æN*œ§h4èÉÄo	É»W'±WßK¥ÞZ_š¦&amp;-M)
/Dest [ 158 0 R /Fit ] 
/Parent 354 0 R 
/Prev 362 0 R 
/Next 360 0 R 
&gt;&gt; 
endobj
362 0 obj
&lt;&lt; 
/Title (’›­öëQ“uö)
/Dest [ 158 0 R /Fit ] 
/Parent 354 0 R 
/Prev 363 0 R 
/Next 361 0 R 
&gt;&gt; 
endobj
363 0 obj
&lt;&lt; 
/Title (-hs~FD»M„íM±VleÁŸï!Å¤Ÿpnt­ô6qñ‡-Œí*üKª©)
/Dest [ 56 0 R /Fit ] 
/Parent 354 0 R 
/Prev 364 0 R 
/Next 362 0 R 
&gt;&gt; 
endobj
364 0 obj
&lt;&lt; 
/Title (:Gû¹ÀS ˜&nbsp;2)
/Dest [ 56 0 R /Fit ] 
/Parent 354 0 R 
/Prev 365 0 R 
/Next 363 0 R 
&gt;&gt; 
endobj
365 0 obj
&lt;&lt; 
/Title (²ú"0P“ºSf÷–wn&lt;)
/Dest [ 20 0 R /Fit ] 
/Parent 354 0 R 
/Prev 355 0 R 
/Next 364 0 R 
&gt;&gt; 
endobj
366 0 obj
&lt;&lt; 
/ProcSet [ /PDF /Text ] 
/Font &lt;&lt; /F5 368 0 R /F6 372 0 R /F7 375 0 R &gt;&gt; 
/ExtGState &lt;&lt; /GS1 378 0 R /GS2 377 0 R &gt;&gt; 
&gt;&gt; 
endobj
367 0 obj
&lt;&lt; 
/Type /FontDescriptor 
/Ascent 0 
/CapHeight 0 
/Descent 0 
/Flags 4 
/FontBBox [ -146 -274 1207 909 ] 
/FontName /HDDGLC+MSTT31c6b7 
/ItalicAngle 0 
/StemV 0 
/CharSet (ì»µ”±ßhZ\)0UŠ	wå*‹*Àá&nbsp;|B¬=ŠÉš¬b_Øö1ÈÖ2a¼-Sè�bœ”¿r«áÞ„’nòj"<tøþ˜Ì\ ¬ØtrùÇ;f[û<="" {²h[r)="" fontfile="" 369="" 0="" r="">&gt; 
endobj
368 0 obj
&lt;&lt; 
/Type /Font 
/Subtype /Type1 
/Name /F5 
/FirstChar 31 
/LastChar 255 
/Widths [ 750 260 320 380 520 520 900 740 220 440 440 500 520 260 333 260 580 
556 556 556 556 556 556 556 556 556 556 260 260 520 520 520 400 
820 660 640 680 740 620 540 740 820 360 340 660 620 880 760 820 
580 800 660 520 660 780 640 900 740 520 600 440 260 440 520 500 
360 556 556 556 611 500 444 611 667 333 333 556 500 722 611 611 
500 611 556 444 556 611 556 778 611 556 500 280 260 280 520 750 
750 750 300 520 400 1000 500 500 420 1300 520 320 1000 750 750 750 
750 300 300 400 400 460 556 1000 420 980 444 320 833 880 750 520 
750 320 520 520 611 520 260 500 380 740 340 480 520 750 740 400 
400 520 312 312 360 580 600 320 300 312 360 480 780 780 780 400 
660 660 660 660 660 660 880 680 620 620 620 620 360 360 390 370 
740 760 820 820 820 820 820 520 820 780 780 780 780 520 580 888 
556 556 556 556 556 556 722 556 500 500 500 500 347 347 377 357 
611 611 611 611 611 611 611 520 611 611 611 611 611 556 500 556 
] 
/Encoding 370 0 R 
/BaseFont /HDDGLC+MSTT31c6b7 
/FontDescriptor 367 0 R 
&gt;&gt; 
endobj
369 0 obj
&lt;&lt; /Length 10526 /Length1 4144 /Length2 6380 /Length3 0 &gt;&gt; 
stream
zv¥gjQkÜuùxúõüó½�ÕñQÇ9;Õê¡ƒÀÉd¾Ñ®ôQÛçFeœ5íNRAžW!evÔ=Ë½ý™îžÍ8g(XmØpJe*åº0bÝæÆ¡]ó�úqÐÁÊ©OíiÂåt/x�Ò¿ÖUÑS3P¸43G`œŽZŽBª„zïùÖ§¶«X™Åe3?»¹ÏébÃè¦sQŒ–«;îWßê¾ý„ÆaçXOˆn&amp;7¸}ÃŠÈ�Æ³ed½‚$/´ñ?þ2ÿÓ#øKˆÖl%Ù“—0ñ‡ €Eê„†4áN-.‚ÑJHÊr	Ž×+«2¦wDqV/{±gp“™|Mú:4µ$�”yC¿¹
•ÞžœN:sâ-Ú¹(}4,O™�Ù€¡í½MMùcƒÂ–¯­.N¥UwîÈ#G‹©šÕÜ­Š�)~D<a€â-ÑÔší³’È¯=¬Éky÷Ãßm~•‚ 7µl¥”÷á’dï*§yc="" $="">�»‰NHÞVý×ÙpW{5 ÞCžYìg6´Ì�9BUÐñ1Ë^t^8ûªøo#žÞv“–†mEK["ˆ03IBè3F÷Éº ŒB°È:ô•\ˆ÷Gñx?½(Å’=c×ø†Ÿ$h‡ò0KÄqÛÍ°·Ú‘<a}×¨¦’mÑ2uýúsþã¶µf”�[g` dØhhœmí×¹Ä”Žýçfç’Ž’“g›‹%†�ËiÓí="" f{¹õûâð*¾o¶¡e�u©o‚‰Ïß="" %hÌ8ìr1³1<ÁÑ_?dqï½×°˜âÞ%»bb="" œll4beb="A§#Æ‘ìŠá°Fr×i1€" l‰²[r½$ï¨ð*lîn(0vq„Ý="" Ý�="" 5ºð²¢¤m}_‡pü&8r¡äÿu©)›r“boÏ%¶tÀpkÇr$e!óp¾éj”��.\˜þÏÎÌdå$«båý+��'b…wvÎØ.ºõ b£jt3mñ»-}ø¹¤é–Ývoàéƒg¡ìiõ*h0-n¬býá*cÀÍá›®á\="">ÔÅ¨
‚°ôæ‰Ä¦Š¬‡ìäóËp¯;tPÿúÿ$	ÿrëK[Õeœ15X&nbsp;Ñ—åûê	‘3º(uÕ•ÙÛ¯.W6¤Å3r®êÞí´&nbsp;MQtêã}ñ|µ²ÔSùòP^°êéËuÿi•”‚ï¼�Ë‘Ý[Í_Ký@¾Onj³ûö
Ç	âƒ
`IRùÁY…µlt‰¼õ;�(QAr­èz¹LÇœµ.:Ô�#@+‰71.�pU¤ØÄy
D|ÕˆÝ)ÛŸ¸ýáv»ƒo´{œs^áœ,:ïË£óéqžËJ4t¯Dp³ÐzzÑ8þ›+Vpó‘lºÓ±#Q¾Ø¬ªC©ºƒÉ«€{³¶&nbsp;c\tÇ6�OÍ¸A�ÇbXöÃ&amp;4¢­3)³1Ëì\hçÃ|£:’G?£¡¬:zrL{µ¹zÕ÷|b}Oƒ`(uš7êø0s!Ñø ¼Ne�8Ìütr|LYtc”ü†‡}Ñÿ$'Í?XÓœ&nbsp;f/¨•39
PÃál²®sY”0—�2xøZ*úÝÏêt°S?ê2•=¦bAPMóïtØÀªÁìµ¼™à}ZyÙ@	ÕD°—ÚhÄ©Í÷µÇ&gt;9²”0¼çáãB»Ûzû�‹L¾&amp;ãæjÂ¥L–1»#²=çsv)érÁb8A(jóO�o1L‹*Ì*âÃ
¨Ñý—ô”õq7™Ã�Q‰Â`“6Ù-óû/w¯-meèL�´\]
‹c’"øGÇw[®†#úr¯7 ŸFÂ·§°ŸCÀç´§
X¢+F£ŒKôxœŒcye�æÖÖÛ€õ&nbsp;Ã–˜š®[ø
}¿
N5åù?wúmÔ&amp;UZvfc¼“d¼š´ÖÁÕyÝ¥#b¥ôhÑéöÖš]�&amp;QóÞ¸tÄ�*Vù\ÿ~#BÿÛñeóÙuˆ/gÃØ2báwP¿,mÙ¦¥«õ)ã™‰™}°YWó¨ÞP`rÝN½¡ÎVè¸c}'œUà­&gt;?2G�±HÎh¸º¬x’6»î9ÏºÉÐØÓê=ø=ØR'ý‚7¨°}s;mÀ:ÿïp°6…!¬np‰·»Â¼7_ê»-ær?]«tí%I¡8òWÇðf¯?Zö++vÇo#Ò2¼±3Ùú×UP_XkÊGæ¨]8„ÈÞDTœý&amp;˜ðï³{Ô[_²�”‰Å%Z4Y†òvÛØãWááá„¿Œ‡kß(–×\�&nbsp;Ó&lt;¢c.æUp	YíÄª4æ¤g»¥�º%ö?UžÖ´Iõ§7²ø«{xÓóõˆxQ8L†™ÝÑìˆF~•TbÈÚf¥TGKoc	1Q$¯¾iÄFXÏ½¡øiÆÃZMÊ™õõh`3‰Ã}~}&nbsp;)â‡Žáåg¿ƒ«“ÁËÏÊŸ,«“–Ô&nbsp;5$Øe„w‚)î©'Íq‡WÌœìæLÒÅ8Î…6±¾¥6{f¾C&amp;l€@'´%LºJëº&lt;Ç8{;ÏÌ¶à5�\„_öotÝœNxí9NŒTNøÓ‚YVqN¥‰Â³'÷‹‘	€f¸Cù­¸‰Î{)À­ªã^vO/=0”º÷Å£VòŒÜ½þÇv4µÒO9Ôž„Qaœ%0t|'³]±Ý¥
åîSÛÞ9W^ì|�KwAKôpZ—ÚŽÒç.Ÿ@®[;œªc{e]`·h;ïý(¼ËTpÏí¾”éÉ.ïlŒšÖî3%@ö¥n¡Niƒ¦rg\¿°&lt;¥&gt;\î‚RðÆ?ÒO’×ôm“Å‚Þ»ûxæFX·áÛþ0ØË¬ûu5îîlPÁp:�ÖòsŽ#€¹žgv»ÞR—â¯”{È�	ÿ„O˜òþñŒ+i“Ú&nbsp;aJÙ¢aæ@¯ì-zØ ¬”`Úû˜Ã»§vñª¼ ;p9ý”¾!æ¡«Þ”9²&gt;&lt;Nž²Dc^Ìç7òÒý B€³§'×Ýš¬±�5Ã}I©ö¸gWªe´ÀÔââBùˆôç•o¾‘¸åw,TJlY¶�ŠS†×§ÄS/çÇµ-»PÏó¬T¥ÜäåÐÚômüçd›}_öû`$N;_l;Í�€ COH(WÃˆÙ»
¯ºzÒö/¦ç¦P®ð"z#oÈÅŒuà-K—AøXÁ�¿®SàB˜YÅDmŒþƒCÅ/‹Áp¶vø€qã¹ÔPsš3(‹Pïñ+LÒv7W¦&lt;Ô!¶²á+Áw{ml°Pç®r@nsuuTg°ÅHì0ÞG¸¬E/:|Ì�ûÀgGEl=²ìÑQÇF5_ô`Ct˜L&amp;r×ŠàÛãN¨çßIôÙ¯ÎÑÔrDì·³ütr6H›W³©á5Py†¸)´ FFdúøµê¤ö¿¼Ís&amp;XAÖÖ±\Ì6æ¬Ub:iÈ_1œ·´mb;½Šq•ñîË¯Í»8Í9ÊfKÅ³×[u&amp;âÛnª¦&amp;Ë"é¢õB·�˜ïuŸø©EîŸaà8qëÊ	ãíø*¿&lt;Ï *‹´fS15÷î¨©:â©Å¦-3öÈù´�ñEãÓ�A½}šd
Î™Òü= RGW?ÖUì˜U¿»²áŠÊNÇ…�(á­}b¢/WnT	Ï_DgòÝûnÌ¡”/EŒaç¢êÆV`�rø„BšOî|ŠÚ­TàìšÜyá‰»PPáûË £?T’Í¡CÊðs¡µì5x†y×�ñæáÜÏ_'§L´Ãx-(§�U&nbsp;bû[ír&gt;Co™»†j²	Býúç†íO,ô×‰²¬Œ•‰È�—T&nbsp;SæÂÖý²'‘|ã[0}&gt;vE&nbsp;âÐÚa†7LÉtàù0ÒÄH6nx×”ŒÚ¦E…è„žßÍC�³ˆ#”lÇ4ç&nbsp;}ÏG=x=í'´æ#árýÕtƒ,‚ÔÃŸp;¹ïÚrf¶Å[Î¡ÕH?”‚-ê'Ì¦ÜX¶Á-é‡dìõžIV
[�±	ƒ5Úñ¾d&lt;ÆŽž·L/î9þSGæOŒq;«T^�…œå�@¶x•ââñäïŸxœ0ë³­'ƒXòOaÐð‰³´+š“
®ˆ[ˆø;igV`Ôz}á±„n&gt;Éõ&gt;â¬@‚ù‡ç(ÏNwSF~›¨H¶;P’ñˆî´Õç)b½øG–�—ÂU–ÀQ/§Ð^Û¼d„vÚË–N?7½ùj¤‰Îï¼Y
kG–ˆ½À“ÊBÆç€EC`ÙîŸ?.„þù5âêEÉé&lt;¦Hªþ^øÔ!µÎÛe19ü,âlÝœITw sPÇFí�=µœÍ?Rn'Ds‡vK‹7m^„Ù¿p–ŒÑX
ÉÎb§R&nbsp;%ì))åðà gF©_¿Ðþ9ÌCÖúWGÂ@¹!~Ýã}rÂK÷¢Öµs5e[þIBn-É3ú*AUIž­±Š]�#l81nfŸc)ôLß¡g�
ˆ¼£¯FŠ\¸Ç^ïÒ¬�wÌ—0;öÑêä§GEóÓ"Ë³fó
øX*`‰{ˆÌB«3ÝŠmX¨&amp;ñþ·mÕŠ²©š]ºì�Ëó üˆqXi’“çñ(†aÜ
@0ö�.Díz«+êŒœ'µqX]&gt;�8óšª¤r(¤�ßW(¢eã‹‡‚YA,±õ/É–�hizjGž�,m.×Üˆ¯.Y+„nÈT‚7þp¯:|Goª‡­
‹X°¨‡Zø6&amp;L²×ú#Ÿ­Ÿí §sØ&nbsp;žä½×ùÃ
ÕJW$ç
8aY&nbsp;”†êkÿ²X=­ïIrd¯€ÃËÊ¤ž˜.•ÿä¶‹g™$Š^«&lt;Þø¥Ÿ•*ˆÐxEødèriR5YÖÏi‘+âÔ«x‰¶\®ÓÅ{
ŸîVå?B‡�&lt;ë] ëËî:Xå$÷SBáKN[F�¬ê¬è=C…‚³NƒO(ÞåÐPW&amp;ƒÃâ}Ã8wž¸3éJI”×9G#8NmW„ª±iI‰ûœÏ¤$ÍïNgr11§8‘É
îÐ–ÿ¹lžG­ƒÚËÔ3\x—HSâx˜ð"S…�á4@Wâ’•Ì@Õ(jE„ª
dã{8·2œŒþVŒÍð9q¬�ÏOtÅfyš%ÜpL\Öb±Õ„¥Ú™Žzåmí~þí¡Ö78R�âªË‹ÐÉúýÊ¨%&gt;L²È¶Õ™Žl–ý~ö
Ž\Å“#SöläQáù@z9ÒvÃ°�FZÕâU†“ç†c%†=þEdµ;¨£ÚCó•¥sf7OŒC�‹Û€€¾rqÁ([ü±‡X\•[Z›õmUõŸæîwk4³†	]?ÿY_áŠÀéj&amp;¬UáÃ(dW‡f¿%V†G"{ÏÛUdÑ×„W¿À„¡c&lt;•ˆUW.ùÂ<wemj%º‹Ü#‡øÚ\þf�Ïbàn…Ìçzq.hÚaŠš¸Ž+‚¦«Ú%¯ˆ¿’�i*‘¸ïžÇßrß†í£Ê²¦>#OZy?ªD½qÝfK¼cŸlÔ'åGÑºýõ‚Å-x²´ÎZGr—ôé‚÷óÄé+?XÝ#_[¤ì½	Å„6üsl5
ð‰Œ÷±ÌÑ~ù»ñàvÂ3ûÕï�HT¹OöMùˆƒ¹eL¤Âl™Y«(ê‘3mðbBO)Ï˜ø
æÍYb–&lt;î~óÖ¿x¡°S�ƒ
2âQÛTM±áÂæð¸¢Õÿ_:nºðÜ9ÒVŽA¨6¸&gt;ó½�h�H6¹™Ô±A²7NÕ¥žäæ|�Ìû.€rlêMsÐ•�läÛ(f0Û0Œ^€ªö·�¥áûsnÁ\._àñløÈ.�Qò¬à=e‘i¯Ä$Û½ÞN‘wIKÛ³”“ä›|iŽ1?ÆØÂ!n…øú¬ƒÁ(Iè ¶IÞ�'ÓîýêàCãþÜY€VÔ(œ,JV°ý�ÙYšWbÅé§»3?!äà”Òè5…ÕÍ…z?ï,GÀ°]úä±®+¨gùFÙ¿€qÝÐg¯Xç`ñý‘H|žZóëNGòŒ@×nù�ë!(Bå‚{XÊ(!‡ŽXó§ï$c[P$ßb¨Û/!lyîH�âi€1˜´NAbËåt;êN‘§éÐö`ô
Îj•ÓŽŠ¬SüËÜŸŽur!!«�)Sß£¹y¢¾i±iŽG³ŸÐwW×CµˆSc¬;ð–7íB-™“¢^ÂÈ ‚«O
{wã½„J§×üøŒó¤9�ZæÉb8£\‡Ï±™—¼^kO;YU,‚/ª°Xå¼ÌD‰+¼˜Àý¥&amp;q™&lt;1V&nbsp;Bhû3Ê… EùI®¨�±’gÐxeÚƒxK‡Ž^�«Cé¸q9WËñ§X["(ÓbQ·bÐs€4ûZ…º±Þžì»ëûU%*�nºi½&lt;Á®†·Gô»W†öõP‹³^¡9È¤K¯œ˜FCÒÏgó*s²ÁFç+ÒÍ°Pôe#÷a8›1òêOöë=ÕZÂ›Žw?¿Ò"™´f¤¼¿ƒÙ&nbsp;…â&gt;¾–Ly¨›¥˜Úýœ§sh¨?’9Þ×¤ƒ(ÕúfB�¬S×ùÉÏÍÞ„‚$Á�)Ø:&amp;…‰1oÛXÑÖ±òÜÂÇNï
œ±�þµðaØŽ`öâôãLò›Ñ�i„täj?Â�RBUF7+à%žÕ	î@š­ÌãBºšæ‚&amp;"À‹f&amp;ýµlÀ²MÓd-)nÐÅïWèùf[¨Ëä¤„…K!ê›Î =›s(æäæ¢ŽhZ?°àê,ˆOè]Ìé_YÝùäÙÉôÏ«X#«=Ãig‘Â8U³Èg~¸Y’þ•hx1Q6P!§}âj³)ÿÀzÐwÒÛG
&gt;\oÔ$
S�€´¾^ÔMmPÍjqË|QoÄ°áÒp£¡ÑVqAÑ—Ü)

˜eù)­€5¯£€�zè\^…ìýš3ãì*Á¹îí!]Oó„3Š9Ó^àø55È„È“—×¶t™R@„¯Ä®¦uŒéÖwÈV4,ª£Éœlïá)U[J¤Ù;aÑn�H‰Ž
y&lt;£«¹rÜû2ø�k4z®‚¢+¶¿&nbsp;èØñX×žÏ—Kÿe“zvIU­›»ÓaÕ&lt;Ô3®ÜÞæŸ|ÏvE€e&nbsp;]Ö1ú¨HÆÄ^êÄÐ\¥v™E=üPM&lt;Æé’ÉÅi¯„êœ1Ù,t‘rê0iìIø}âsI¦¤N|÷2˜è]€T½3;Ùã`{amPcÞád€ÏT˜N%&amp;Ô×G	¿ýHÍU~=@‚vœ0”9qØ@ˆ}ÆÐ­H°õfÞ—º‰ç½µúIiKØf�mOW¿“�ãì,lÁ¦¡S.C"bx*ú¥j}º–å›Vj¶´Ô§G@–]˜•5â£,³ü&nbsp;ºPÖ�GÉè"Ê�Àxó¯_d`�Á�Vtý¶&lt;ÛYýø,µ80ÖÔ§yœÓE5“v©4Œˆ_©—Œž¬ü¨÷l±2&lt;‡˜ÛÔ•Á„�&amp;�àÏ²‡u'ÖÍ\ü¥Ü.?àðšñ}ølá©¼#�·S‹enê2õo­Û«ïå`é—‡°,ËMµ�
¢T�ŽS“Ä9œæ¥£ôÐÎ–ÂMøèßb�6üú”fr3Á ÓYc�d£b¥•à±LŽ$«Æ†ˆ7ôQ³à�OU–uÕó7Neÿ*ókâØÅÿ`×©¿‘öÇxñtøpfã+Ýv'“^¥œ�èµìF
»~È9Þguq`ø™ü9î-BÉè³qâ¡Ì%h-Ûn…JF_¦[£Èw¥`&lt;\U.lÞZ´!(‡€âÙ²ÛDZ0®´*§ë›&nbsp;ÞÚ–še¡Õ"ÁÐy¥§~§TÒÅlÇ0SüxÄsG�8®�SS*5çó;†2JT»Ø‘UB&amp;f|î<púß¶¿93žg”tÏö|nº•×4|¨zx+vÖ]‰´)c‘¼ât¬› ðuÒ¥ãlà×‡j<¤îh="" ·^káqµt€èb}+lÑ©_="" ÍÃÈx‚¥þ£2üo0¦hc0«Ëô·z£="" e3©nt±”ÀÄlsq ¾l3§›š6k^Ü:ƒûìi…É"ü6ù×'¯c×Í®<p4Žêxspez1@¼¿²ÑÓ‚°âdàØiÐe¾À«»ˆlå†)–~ÛhgËf›@ºÏ°fãp†f="" %Ä2µk5aùÔi9nÀ"~ŸÄ­9}gqçz]%Çô±!15zvŸô-ezr)Æóiè:•còñ¾j3Ô%h="" ã�\à8îv¼›¦©“v§òñ‘“•~="" Ê6Ð="" mtft03="" i:¡‹ÿh¬akêt*& ="" {�ÕªÚôùù="" ·£Æ(ìÖ9üük#ðïŠwobi±l�(Ðœ?ñêˆ—Ôsq¡-r˜xÃ‹px%÷‰v}¼5‹•¡‹ùû„¸Ûho-¤ï„¢ÿŒÙuáe©øþ‰¤a`,a€m7ªi–rÛ÷�fez¬Ð…k.}sñÁ’¥8²�Óo'é?]?,¥-áºaÕ´vòfj�¼žÆÆ6_Ãé(u!ù3guùåólücr)3žzø59à�°6$øâ’ïÕ©§4ñÆhsñ‰�oµ»noÆ2="�ŒiêR‡#ÆµYª+hQJwCçBy/A´H&nbsp;Â" q¥u"„‹øé:c�ÆÑwòqx1p°?Ð+©™æx²�b|Üf="ŽªÄ²,q`”Õba}n•ñ|yŸYó;íÆÔEB­¿á�é¶L§’’8HÑÜÑµò‘jÎ�g­µLŒ&nbsp;¾`™Mºªhw™õò•·šÅæwT—†³Î�»R]3ºî�²Îúè/|‰°ˆ§vr1û£6ÎB¸´<<™»°ãLˆöˆ�×çS1·6ø!¼ñ—›" šv="">Í€½±1¨T5w¤Ò4öªV¶-_;­_÷üÀ¢càCò9V8äÈ‹Éw�àµ¦u1ÐCÒÍªþ3N†Üoˆ@#�ÙÈªÖ%ÎO¥ˆ¹
c?ÿOl2t¨»(–˜°1#*«QqÈ&gt;ä«ÇJø¸ƒJ¦SÝþùcåpÿ–Ãà�•ÓÎ-ÀŽ¢Ê”ÓF¥0Båò0¬ì&nbsp;/‡U�d"žŸéPebFX)ÞXx&amp;¢¤Ñh›ç&gt;PÌƒž³))ŒÚ÷`R&gt;†j=çtQå~Â;b£Ò{îyÊUÆ­+:mLbzi8…‘°AÙ~‰“OñËÿV½ooB•cQ­¾ÆRÞöÊ°/tI�­ü¹¹³ü
ç:Â;)û§{¡€RsÙ÷aß"Õ+¹I¼O#…Eº&nbsp;¯€*¦rudêdI/ÁÿØ†¿ößuÏ�!w†U2×Ì—`§ëgúÑv¿]¢&lt;+ÑrCË}É{‹	&gt;‚ýT¾I)¦E9Å®Tvý�ëÙ‰øÃó§¸@Yþù!¨Ø:n~H~ÜÖ3-£ýOL.-‡@}f„* ¹b2J6HyŠGHOª}É½«±à¬œ¤8RB°"úâ6zµNÖiu%eœM×uGŒåÅôµ‹p=£j²ö»_È°/_Œé oGªßFo_–HÑR1Ò€yNlê÷•[úûk€‡KÓdÏèvuSÉØïâ^®À‰Akü‰"y£9ÃJ+ÚLùòóË.ú»ÐMèŸvŒû¾Ëö7zOKvròF½Š#PF:ñ[k"ˆ°_/¡ÅîÇßþþ-ò+u�®�F•sMa•	òVëØ¨úúB+WÛFšÙ;(Ô&amp;4"Hë4'uÃ4C&amp;hfqÎ½&gt;k†ŒÕ"áÃ^†W_o	—·Äñ.OÓ&amp;ƒáº–g-éHvs8CÖñfµB$�âÛ:H=OþãJ¹¦Éú,Òœ?=™SëélË†;ðFÁ’ªàì†µ 5(hN„;™™;;³Û•SJN”þêd²kõM[Dq=p‹Æ©Á‚�
,Nò�ùœÝ!m|´y}QƒLX¼V 
#Aµ½)7•&gt;˜Ý+xÀó:4&gt;ªìÜçå=Mãt~LIÓJ‡´’„M|›’¤*0±	ñCË»–†éFç4ÕˆPüâ¤(…7Õ›Ð«qäá~ìA‹“´÷8ƒôUê`P&gt;</púß¶¿93žg”tïö|nº•×4|¨zx+vö]‰´)c‘¼ât¬›></wemj%º‹ü#‡øú\þf�ïbàn…ìçzq.húašš¸ž+‚¦«ú%¯ˆ¿’�i*‘¸ïžçßrß†í£ê²¦></a}×¨¦’mñ2uýúsþã¶µf”�[g`></a€â-ñôší³’è¯=¬éky÷ãßm~•‚></tøþ˜ì\></v%aá£œps1�l`ôbä2[›;�></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://socialsciences.mcmaster.ca/econ/ugcm/3ll3/mill/liberty.pdf">https://socialsciences.mcmaster.ca/econ/ugcm/3ll3/mill/liberty.pdf</a></em></p>]]>
            </description>
            <link>https://socialsciences.mcmaster.ca/econ/ugcm/3ll3/mill/liberty.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-23636407</guid>
            <pubDate>Thu, 25 Jun 2020 02:54:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Unix's design issue of device numbers being in stat() results for files]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23636376">thread link</a>) | @todsacerdoti
<br/>
June 24, 2020 | https://utcc.utoronto.ca/~cks/space/blog/unix/FilesystemStatDeviceProblem | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/unix/FilesystemStatDeviceProblem">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>Unix's design issue of device numbers being in stat() results for files</h2>

	<p><small>June 24, 2020</small></p>
</div><div><p>Sometimes, you will hear the view that Unix's design is without
significant issues, especially the 'pure' design of Research Unix
(before people who didn't really understand Unix like Berkeley and
corporate AT&amp;T got their hands on it). Unfortunately that is not
the case, and there are some areas where Research Unix made decisions
that still haunt us to this day. For reasons beyond the scope of
this entry, today's example is that part of the file attributes
that you get from <a href="https://man.openbsd.org/stat.2"><code>stat()</code></a> system
call and its friends is the 'device number' of the filesystem the
file is on.</p>

<p>(To be specific, this is the <code>st_dev</code> field of the <code>struct stat</code>
that <code>stat()</code> returns, which has been since <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/include/sys/stat.h">V7's stat.h</a>.
The <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V6/usr/man/man2/stat.2">V6 stat()</a> was
even more explicit about what it was returning.)</p>

<p>In Unix, the user level file attributes you get back need some kind
of locally unique identifier for the filesystem that the file is
on, so the presence of some identifier is not a mistake. The
identifier being different between two files is how you detect
things like that you're at a filesystem mount point, that you can't
use <a href="https://man.openbsd.org/link.2"><code>link()</code></a>, or that two otherwise
identical looking files are not actually hardlinked together because
they're on different filesystems. It's also useful to have an
identifier that can be matched up with things like a list of mounted
filesystems.</p>

<p>However, early Unixes didn't make this merely some identifier, they
made this specifically the device number of the underlying disk
device that the filesystem was mounted from (hence its name as
'<code>st_dev</code>'). This had the unfortunate consequence of permanently
joining two logically separate identifier namespaces, the namespace
of (mounted) filesystems and the namespace of block devices.</p>

<p>Now, 40 odd years later, we have plenty of Unix filesystems that
don't have underlying block devices (especially singular ones).
Anything mounted using one of these filesystems needs to somehow
make up a 'device number' for itself, and this device number can't
be the same as any real block device. This generally requires Unixes
to carve out a section of their overall block device numbers that's
reserved for filesystems to do this with, in other words things
that aren't actually block devices. Fortunately modern Unixes have
generally made the namespace of device numbers be much larger than
it used to be.</p>

<p>(Then because device numbers for block devices are generally stable,
a certain amount of software expects the 'device number' returned as
part of file attributes to also be stable, for any arbitrary filesystem.
When the kernel and a filesystem has to make this number up on the fly,
this is not always the case.)</p>

<p>At the same time, this is a good design for V7 itself, in the time and
the context. V7 and its kernel were intended to be a small system, and
in a small system you don't want to go doing extra work unless you
absolutely have to, especially in the kernel. V7 could reuse the device
number to be the filesystem identifier essentially for free, so that's
what it did.</p>

<p>(V7's kernel took any number of shortcuts in the interests of having
a simple implementation. For instance, a lot of things were stored
in small fixed-sized arrays, because you would never have more than
a modest number of processes, open files, or so on.)</p>
</div></div>]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/unix/FilesystemStatDeviceProblem</link>
            <guid isPermaLink="false">hacker-news-small-sites-23636376</guid>
            <pubDate>Thu, 25 Jun 2020 02:49:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Undervolting with SecureBoot in Linux]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23636357">thread link</a>) | @kinghajj
<br/>
June 24, 2020 | https://kinghajj.github.io/blog/undervolting-with-secureboot-in-linux/ | <a href="https://web.archive.org/web/*/https://kinghajj.github.io/blog/undervolting-with-secureboot-in-linux/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
      <p>Many laptop users choose to undervolt their machines. This decreases thermal output, which, in turn, can increase program performance, since modern CPUs will automatically adjust their operating frequency depending on the available thermal headroom. Undervolting tools exist for all major operating systems; they typically require administrator rights, but otherwise are easy to use. In Linux, however, things aren't quite so simple: recent versions of the kernel prohibit the mechanism used for undervolting Intel CPUs when SecureBoot is enabled. The most common way around this, unsurprisingly, is just to disable SecureBoot. With a bit of work, though, it is possible to keep SecureBoot enabled, but allow controlled access to the undervolting mechanism.</p>
<p>The next sections will go into some background information on undervolting, SecureBoot, and why newer versions of Linux prevent the former while the latter is enabled. You can skip any of these if you're already familiar with the topic.</p>

<p>Some laptops today are well-known for having thermal issues. A common culprit is that these laptops ship with voltage settings that are higher than actually required. This is a good default behavior, since chips' performance can vary significantly, even within a SKU. High-end chips that are put into more expensive models of these laptops, however, tend to be better binned, and often work without errors at substantially lower voltage. Since all modern chips implement some sort of "auto-overclock" when there is enough thermal headroom, this can translate into increased clock speeds, and thus, better performance.</p>
<p>My current laptop is a Dell XPS 15 7590, with an 8-core Intel® i9-9980HK. This particular model performs better compared to its predecessors, but there is still room for improvement. Unfortunately, Dell's UEFI provides no way to control the voltage settings, so any adjustments must be done after booting up.</p>

<p>The <a href="https://wiki.debian.org/SecureBoot#What_is_UEFI_Secure_Boot.3F">Debian Wiki</a> has a great explanation of SecureBoot and Machine Owner Keys:</p>
<blockquote>
<p>UEFI Secure Boot (SB) is a verification mechanism for ensuring that code launched by a computer's UEFI firmware is trusted. It is designed to protect a system against malicious code being loaded and executed early in the boot process, before the operating system has been loaded. SB works using cryptographic checksums and signatures. Each program that is loaded by the firmware includes a signature and a checksum, and before allowing execution the firmware will verify that the program is trusted by validating the checksum and the signature. When SB is enabled on a system, any attempt to execute an untrusted program will not be allowed. This stops unexpected / unauthorized code from running in the UEFI environment.</p>
<p>...</p>
<p>A key part of the shim design is to allow users to control their own systems. The distro CA key is built in to the shim binary itself, but there is also an extra database of keys that can be managed by the user, the so-called Machine Owner Key (MOK for short).</p>
</blockquote>
<p>Large distros, like Ubuntu, ship with kernels signed by the same CA key used by Microsoft for Windows. This lets them be installed onto systems with SecureBoot without making the user go through the hassle of registering their own MOK and signing the kernel manually. If you want to run any custom kernel modules, however, you must create and register a MOK with the UEFI, and sign the driver(s) with it, or the kernel will refuse the load them.</p>

<p>Intel CPUs have had MSRs—<em>model-specific registers</em>—for quite some time. All sorts of tracing and debugging functionality is available through them, but, importantly for this topic, this is also how they provide a way to dynamically adjust voltages applied to the core and caches of the CPU. More troubling, though, is that these registers can also be used to violate protection rings, allowing user applications to read <em>and write</em> over kernel memory, including kernel code. This is why applications that use the MSRs have always required some sort of elevated privileges.</p>
<p>Previously, programs that wrote to the MSRs only required the <code>SYS_RAWIO</code> capability in Linux. Recent version of the kernel, however, don't allow any writes to the MSRs whatsoever when SecureBoot is enabled. (In kernel parlance, this is called "lockdown mode.") The motivation here is sound: the entire purpose of SecureBoot is to have a trusted environment that runs only the exact code that's been authorized, so any mechanism that potentially allows modification of kernel code at runtime flies in the face of that goal.</p>
<p>There has been at least <a href="https://lore.kernel.org/linux-security-module/38d18a24-c580-d56b-f0cd-91e8184e1f0d@gmail.com/T/">one recent proposal</a> to open up the subset of MSRs used for undervolting, even when the kernel is locked down. A consensus hasn't yet been reached, though, so for the time being, we must come up with our own solutions.</p>

<p>tl;dr: the easiest way to allow undervolting in Linux while using SecureBoot:</p>
<ul>
<li>Generate your own MOK and register it with the UEFI.</li>
<li>Patch the <code>msr</code> module to remove the checks for lockdown mode.</li>
<li>Build, sign, and install the patched module.</li>
<li>Install an undervolting tool, like <code>intel-undervolt</code>, and give it the
<code>RAW_IO</code> capability.</li>
<li>Rejoice!</li>
</ul>
<p>In my case, Ubuntu 20.04 uses kernel v5.4.0, and the patch looks like this:</p>
<pre><span>--- ./linux-source-5.4.0/arch/x86/kernel/msr.c.orig
+++ ./linux-source-5.4.0/arch/x86/kernel/msr.c
@@ -77,15 +77,15 @@
        u32 data[2];
        u32 reg = *ppos;
        int cpu = iminor(file_inode(file));
        int err = 0;
        ssize_t bytes = 0;

-       err = security_locked_down(LOCKDOWN_MSR);
-       if (err)
-               return err;
+       //err = security_locked_down(LOCKDOWN_MSR);
+       //if (err)
+       //      return err;

        if (count % 8)
                return -EINVAL; /* Invalid chunk size */

        for (; count; count -= 8) {
                if (copy_from_user(&amp;data, tmp, 8)) {
@@ -132,15 +132,15 @@
                        break;
                }
                if (copy_from_user(&amp;regs, uregs, sizeof(regs))) {
                        err = -EFAULT;
                        break;
                }
-               err = security_locked_down(LOCKDOWN_MSR);
-               if (err)
-                       break;
+               //err = security_locked_down(LOCKDOWN_MSR);
+               //if (err)
+               //      break;
                err = wrmsr_safe_regs_on_cpu(cpu, regs);
                if (err)
                        break;
                if (copy_to_user(uregs, &amp;regs, sizeof(regs)))
                        err = -EFAULT;
                break;
</span></pre>
<p>Pretty straightforward: look for all instances of <code>LOCKDOWN_MSR</code> in this file,
and comment-out the lockdown check &amp; error-handling code.</p>

<p>For all tests, these are the undervolt settings:</p>
<table><thead><tr><th>Component</th><th>ΔmV</th></tr></thead><tbody>
<tr><td>CPU Core</td><td>-99.6mV</td></tr>
<tr><td>CPU Cache</td><td>-99.6mV</td></tr>
</tbody></table>
<p>The first test is running Prime95 with default settings. Starting with the undervolt applied, I let the CPU frequency and temperature settle. Then, I set the voltage to stock settings, and let the system settle again. Measurements were done using the <code>intel-undervolt</code> tool. Here's the averaged &amp; rounded results:</p>
<table><thead><tr><th>Voltages</th><th>CPU Core (W)</th><th>CPU Core (°C)</th><th>CPU Core (Hz)</th></tr></thead><tbody>
<tr><td>Stock</td><td>38 W</td><td>92 °C</td><td>2350 Hz</td></tr>
<tr><td>Undervolted</td><td>34 W</td><td>92 °C</td><td>2950 Hz</td></tr>
</tbody></table>
<p>To see how this change would affect a realistic workload for myself, I compiled the latest trunk branches of Firefox and alacritty. Both of these runs were done with the same settings, and with a clean build tree.</p>
<table><thead><tr><th>Voltages</th><th>Firefox Time (s)</th><th>alacritty time (s)</th></tr></thead><tbody>
<tr><td>Stock</td><td>1401 s</td><td>139 s</td></tr>
<tr><td>Undervolted</td><td>1273 s</td><td>129 s</td></tr>
</tbody></table>
<p>These are only brief, non-rigorous tests, but the results suggest that undervolting can provide tangible benefits.</p>

<p>The obvious objection to this solution, of course, is that it makes SecureBoot useless. Or does it? If your system has multiple tenants, some of whom require the ability to grant programs the <code>SYS_RAWIO</code> capability, then this objection holds water. For the vast majority of laptop users, though, this isn't a threat. The owner decides which programs are allowed to perform raw I/O, and is responsible for their own security.</p>
<p>As for the common solution to this problem—disabling SecureBoot entirely—the drawbacks are pretty clear: you're throwing the baby out with the bathwater, abandoning any sense of security and peace-of-mind that comes from cryptographic verification of your operating system. Users shouldn't have to sacrifice critical security features for acceptable performance.</p>
<p>The best solution would satisfy the needs of both server and desktop use cases. If the kernel had an interface to control undervolting, without providing access to the raw MSRs, then we could have the best of both worlds: no way to violate the SecureBoot contract from userspace, and laptop users can get better performance. Designing a good, reusable interface for this would undoubtedly take some time; we don't want it to be married specifically to one vendor, architecture, or platform. Until such an interface gets made and merged, we'll have to stick to workarounds.</p>

<p>Undervolting can provide noticeable benefits for many laptop configurations. Unfortunately, some OEMs prevent adjusting these settings in their UEFI, requiring the use of runtime mechanisms. Even <em>more</em> unfortunately, the mechanism for Intel CPUs also comes with potential security holes, which make it a challenge to provide this functionality in a way that completely complies with protocols like SecureBoot. Linux, in particular, takes the most conservative approach, absolutely forbidding access to undervolting mechanisms when running under a secure context. That is a sane starting point, but it would certainly be worthwhile to figure out an acceptable solution.</p>

    </div></div>]]>
            </description>
            <link>https://kinghajj.github.io/blog/undervolting-with-secureboot-in-linux/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23636357</guid>
            <pubDate>Thu, 25 Jun 2020 02:46:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to write PureScript react components to replace JavaScript]]>
            </title>
            <description>
<![CDATA[
Score 99 | Comments 72 (<a href="https://news.ycombinator.com/item?id=23636336">thread link</a>) | @JacksonGariety
<br/>
June 24, 2020 | https://thomashoneyman.com/articles/replace-react-components-with-purescript/ | <a href="https://web.archive.org/web/*/https://thomashoneyman.com/articles/replace-react-components-with-purescript/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  

  

<p>I have twice migrated large JavaScript apps to PureScript. At CitizenNet we replaced Angular with Halogen, and at Awake Security we’ve replaced most of a React application with PureScript React. Both companies have seen a dramatic drop in bugs in production.</p>

<p>It’s relatively easy to replace React due to PureScript’s <code>react</code> and <code>react-basic</code> libraries. The React mental model fits well with a strongly-typed, pure functional language like PureScript (or Reason), and using the same underlying library means that components can be shared between languages with little modification.</p>

<p>At Awake Security we share internationalization, a Redux store and middleware, and much more in an code base where PureScript regularly imports JavaScript and JavaScript regularly imports PureScript.</p>

<p>The best way to rewrite a significant app from one language to another is incrementally, while it runs. At first the new language can take over logically isolated parts of the app: the management dashboard, or the chat window, or a form. But eventually you must mix components from both languages together – for example, to support shared global state.</p>

<p>At this point you can’t just let the new language take over a DOM node. You need to support simple, clear features for intermixing the languages. Fortunately, you can transform the interface of idiomatic PureScript code into idiomatic JavaScript (and vice versa). With <code>react</code> and <code>react-basic</code> you can write business logic in PureScript but easily interoperating with the larger React ecosystem and your existing code.</p>

<p>In this article I will demonstrate how to replace part of a React application with simple components written in PureScript. Along the way, I’ll share best practices for making this interop convenient and dependable. The examples will be simple, but the same techniques also apply to complex components.</p>

<h4 id="sections">Sections</h4>

<ol>
<li><a href="#let-s-write-a-react-app-in-javascript">Write a tiny React application in JavaScript</a></li>
<li><a href="#setting-up-a-shared-purescript-javascript-project">Update the application to support PureScript</a></li>
<li><a href="#replacing-a-react-component-with-purescript-react">Replace a React component with PureScript React, with the same interface and behavior as the original</a></li>
<li><a href="#replacing-a-react-component-with-purescript-react-basic">Replace the component again with React Basic</a></li>
</ol>

<p>I encourage you to code along with this article; no code is omitted and dependencies are pinned to help ensure the examples are reproducible. This code uses Node <code>v11.1.0</code>, Yarn <code>v1.12.0</code>, and NPX <code>v6.5.0</code> installed globally, and PureScript tooling installed locally.</p>

<p>Peter Murphy has <a href="https://github.com/ptrfrncsmrph/purescript-react-tutorial">implemented the ideas in this article using React Hooks</a> if you’d like to see this in action.</p>




<h2 id="let-s-write-a-react-app-in-javascript">Let’s write a React app in JavaScript</h2>

<p>We are going to write a tiny React application which shows a few counters, and then we’re going to replace its components with PureScript. The resulting JavaScript code will be indistinguishable, aside from imports, from the original, and yet it will all be PureScript under the hood.</p>

<p>Let’s follow the official React docs in using <code>create-react-app</code> to initialize the project and then trim our source code to the bare minimum.</p>
<div><pre><code data-lang="sh"><span># Create the app</span>
npx create-react-app my-app <span>&amp;&amp;</span> <span>cd</span> my-app</code></pre></div>
<p>At the time of writing, <code>create-react-app</code> produces these React dependencies:</p>
<div><pre><code data-lang="json"><span>"dependencies"</span><span>:</span> <span>{</span>
    <span>"react"</span><span>:</span> <span>"^16.8.6"</span><span>,</span>
    <span>"react-dom"</span><span>:</span> <span>"^16.8.6"</span><span>,</span>
    <span>"react-scripts"</span><span>:</span> <span>"3.0.1"</span>
  <span>}</span></code></pre></div>
<p>We have a handful of source files under <code>src</code>, but our application will need just two of them: <code>index.js</code>, the entrypoint for Webpack, and <code>App.js</code>, the root component of our application. We can delete the rest:</p>
<div><pre><code data-lang="sh"><span># Delete all the source files except for the entrypoint and</span>
<span># root app component</span>
find src -type f -not <span>\(</span> -name <span>'index.js'</span> -or -name <span>'App.js'</span> <span>\)</span> -delete</code></pre></div>
<p>Finally, let’s replace the contents of those two files with the bare minimum we’ll need for this article. From here on out I’ll supply diffs that you can supply to <code>git apply</code> to apply the same changes I did.</p>

<p>First, our entrypoint:</p>
<div><pre><code data-lang="jsx"><span>// src/index.js
</span><span></span><span>import</span> <span>React</span> <span>from</span> <span>"react"</span><span>;</span>
<span>import</span> <span>ReactDOM</span> <span>from</span> <span>"react-dom"</span><span>;</span>
<span>import</span> <span>App</span> <span>from</span> <span>"./App"</span><span>;</span>

<span>ReactDOM</span><span>.</span><span>render</span><span>(&lt;</span><span>App</span> <span>/&gt;,</span> <span>document</span><span>.</span><span>getElementById</span><span>(</span><span>"root"</span><span>));</span></code></pre></div>
<p>Then our main app component:</p>
<div><pre><code data-lang="jsx"><span>// src/App.js
</span><span></span><span>import</span> <span>React</span> <span>from</span> <span>"react"</span><span>;</span>

<span>function</span> <span>App</span><span>()</span> <span>{</span>
  <span>return</span> <span>(</span>
    <span>&lt;</span><span>div</span><span>&gt;</span>
      <span>&lt;</span><span>h1</span><span>&gt;</span><span>My</span> <span>App</span><span>&lt;/</span><span>h1</span><span>&gt;</span>
    <span>&lt;/</span><span>div</span><span>&gt;</span>
  <span>);</span>
<span>}</span>

<span>export</span> <span>default</span> <span>App</span><span>;</span></code></pre></div>
<h3 id="writing-a-react-component">Writing a React component</h3>

<p>Let’s write our first React component: a counter. This is likely the first example of a React component you ever encountered; it’s the first example in the PureScript React libraries as well. It’s also small and simple enough to be replaced twice over the course of this article.</p>

<p>The counter will be a button which maintains the number of times it has been clicked. It will accept, as its only prop, a label to display on the button.</p>
<div><pre><code data-lang="jsx"><span>// src/Counter.js
</span><span></span><span>import</span> <span>React</span> <span>from</span> <span>"react"</span><span>;</span>

<span>class</span> <span>Counter</span> <span>extends</span> <span>React</span><span>.</span><span>Component</span> <span>{</span>
  <span>constructor</span><span>(</span><span>props</span><span>)</span> <span>{</span>
    <span>super</span><span>(</span><span>props</span><span>);</span>
    <span>this</span><span>.</span><span>state</span> <span>=</span> <span>{</span>
      <span>count</span><span>:</span> <span>0</span>
    <span>};</span>
  <span>}</span>

  <span>render</span><span>()</span> <span>{</span>
    <span>return</span> <span>(</span>
      <span>&lt;</span><span>button</span> <span>onClick</span><span>=</span><span>{()</span> <span>=</span><span>&gt;</span> <span>this</span><span>.</span><span>setState</span><span>({</span> <span>count</span><span>:</span> <span>this</span><span>.</span><span>state</span><span>.</span><span>count</span> <span>+</span> <span>1</span> <span>})}</span><span>&gt;</span>
        <span>{</span><span>this</span><span>.</span><span>props</span><span>.</span><span>label</span><span>}</span><span>:</span> <span>{</span><span>this</span><span>.</span><span>state</span><span>.</span><span>count</span><span>}</span>
      <span>&lt;/</span><span>button</span><span>&gt;</span>
    <span>);</span>
  <span>}</span>
<span>}</span>

<span>export</span> <span>default</span> <span>Counter</span><span>;</span></code></pre></div>
<p>Then, we’ll import our new counters into our main application:</p>
<div><pre><code data-lang="diff"><span>--- a/src/App.js
</span><span></span><span>+++ b/src/App.js
</span><span></span><span>@@ -1,9 +1,13 @@
</span><span></span> import React from "react";
<span>+import Counter from "./Counter";
</span><span></span>
 function App() {
   return (
     &lt;div&gt;
       &lt;h1&gt;My App&lt;/h1&gt;
<span>+      &lt;Counter label="Count" /&gt;
</span><span>+      &lt;Counter label="Clicks" /&gt;
</span><span>+      &lt;Counter label="Interactions" /&gt;
</span><span></span>     &lt;/div&gt;
   );
 }
</code></pre></div>
<p>With <code>yarn start</code> we can run the dev server and see our app in action.</p>

<p><img src="https://thomashoneyman.com/images/2019/running-app.gif" alt="running app"></p>



<p>We’ve written entirely too much JavaScript. Let’s support PureScript in this project as well. Our goal is to write code in either language and freely import in either direction without friction. To accomplish that, we will install PureScript tooling, create a separate PureScript source directory, and rely on the compiler to generate JavaScript code.</p>

<h3 id="1-install-the-compiler-and-package-manager">1. Install the compiler and package manager</h3>

<p>First we must install PureScript tooling. I recommend installing versions of the compiler and Spago (a package manager and build tool) which match those used in this article. I’ll use NPX to ensure all commands are run using local copies.</p>
<div><pre><code data-lang="sh"><span># Install the compiler and the Spago package manager however you prefer;</span>
<span># since we're already in a React project I'll use Yarn</span>
yarn add -D purescript@0.13.2 spago@0.8.4</code></pre></div>
<h3 id="2-initialize-the-project-and-package-set">2. Initialize the project and package set</h3>

<p>We can create a new PureScript project with <code>spago init</code>. As of version 0.8.4, Spago always initializes with the same package set, which means you should have identical package versions to those used to write this article. I’m using the <code>psc-0.13.0-20190607</code> package set.</p>
<div><pre><code data-lang="sh"><span># npx ensures we're using our local copy of Spago installed in node_modules.</span>
npx spago init</code></pre></div>
<p>Spago has created a <code>packages.dhall</code> file which points at the set of packages which can be installed and a <code>spago.dhall</code> file which lists the packages we’ve actually installed. We can now install any dependencies we need and we’ll know for sure the versions are all compatible.</p>

<p>Before installing anything, let’s update the existing <code>.gitignore</code> file to cover PureScript. For a Spago-based project this will work:</p>
<div><pre><code data-lang="sh"><span>echo</span> -e <span>"\noutput\n.psc*\n.purs*\.spago"</span> &gt;&gt; .gitignore</code></pre></div>
<h3 id="3-adjust-the-directory-structure">3. Adjust the directory structure</h3>

<p>Finally, let’s organize our source code. It’s typical to separate JavaScript source from PureScript source except when writing an FFI file for PureScript. Since we aren’t doing that in this project, our source files will be entirely separated. Let’s move all JavaScript code into a <code>javascript</code> subdirectory and create a new <code>purescript</code> folder next to it.</p>
<div><pre><code data-lang="sh">mkdir src/javascript src/purescript
mv src/App.js src/Counter.js src/javascript</code></pre></div>
<p>Next, we’ll adjust <code>index.js</code> to the new location of our root component:</p>
<div><pre><code data-lang="diff"><span>--- a/src/index.js
</span><span></span><span>+++ b/src/index.js
</span><span></span><span>@@ -1,5 +1,5 @@
</span><span></span> import React from "react";
 import ReactDOM from "react-dom";
<span>-import App from "./App";
</span><span></span><span>+import App from "./javascript/App";
</span><span></span>
 ReactDOM.render(&lt;App /&gt;, document.getElementById("root"));
</code></pre></div>
<p>We’ve just one task left. The PureScript compiler generates JavaScript into a directory named <code>output</code> in the root of the project. But <code>create-react-app</code> disables importing anything outside the <code>src</code> directory. While there are fancier solutions, for this project we’ll get around the restriction by symlinking the <code>output</code> directory into the <code>src</code> directory.</p>
<div><pre><code data-lang="sh"><span># we can now import compiled PureScript from src/output/...</span>
ln -s <span>$PWD</span>/output <span>$PWD</span>/src</code></pre></div>
<p>Your <code>src</code> directory should now look like this:</p>
<div><pre><code data-lang="sh">src
├── index.js
├── javascript
│ ├── App.js
│ └── Counter.js
├── output -&gt; ../output
└── purescript</code></pre></div>
<h2 id="replacing-a-react-component-with-purescript-react">Replacing a React component with PureScript React</h2>

<p>I like to follow four simple steps when replacing a JavaScript React component with a PureScript one:</p>

<ol>
<li>Write the component in idiomatic PureScript.</li>
<li>Write a separate interop module for the component. This module provides the JavaScript interface and conversion functions between PureScript and JavaScript types and idioms.</li>
<li>Use the PureScript compiler to generate JavaScript</li>
<li>Import the resulting code as if it were a regular JavaScript React component.</li>
</ol>

<p>We’ll start with the <code>react</code> library, which we use at Awake Security. It’s similar to <code>react-basic</code> but maps more directly to the underlying React code and is less opinionated. Later, we’ll switch to <code>react-basic</code>, which will demonstrate some differences between them.</p>

<p>As we take each step in this process I’ll explain more about why it’s necessary and some best practices to keep in mind. Let’s start: install the <code>react</code> library and prepare to write our component:</p>
<div><pre><code data-lang="sh"><span># install the purescript-react library</span>
npx spago install react

<span># build the project so editors can pick up the `output` directory</span>
npx spago build

<span># create the component source file</span>
touch src/purescript/Counter.purs</code></pre></div>
<h3 id="1-write-the-react-component-in-idiomatic-purescript">1. Write the React component in idiomatic PureScript</h3>

<p>Even though we are writing a component to be used from JavaScript, we should still write ordinary PureScript. As we’ll soon see, it’s possible to adjust only the interface of the component for JavaScript but leave the internals untouched. This is especially important if this component is meant to be used by both PureScript and …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thomashoneyman.com/articles/replace-react-components-with-purescript/">https://thomashoneyman.com/articles/replace-react-components-with-purescript/</a></em></p>]]>
            </description>
            <link>https://thomashoneyman.com/articles/replace-react-components-with-purescript/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23636336</guid>
            <pubDate>Thu, 25 Jun 2020 02:40:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stop Sabotaging Your Career with Short Stints]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 29 (<a href="https://news.ycombinator.com/item?id=23636077">thread link</a>) | @gmays
<br/>
June 24, 2020 | https://staysaasy.com/engineering/2020/06/16/Stop-Sabotaging.html | <a href="https://web.archive.org/web/*/https://staysaasy.com/engineering/2020/06/16/Stop-Sabotaging.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Life before a software engineering career is commonly a series of time-bound efforts to gain competency in a new area. This semester you learn geometry. That semester you learn history. Next semester you learn calculus. And so on.</p>

<p>As a result, most people entering the software engineering workforce equate learning with learning a brand new topic. I didn’t know ruby, I learned ruby. I didn’t know SQL, now I know SQL.</p>

<p>This kind of thinking leads people to 2 year cycles. On most modern software teams, it takes roughly one year to really feel like you have your feet under you. By that time the kind of learning novelty people are used to isn’t there. By 16 months they’re restless. By 24 months they’re gone.</p>

<p>This is a problem. It’s a problem because the majority of durable and transferable knowledge comes after achieving basic competency. Mastery of a skillset, understanding and learning from the outcomes of decisions made years ago, architecture and design, leading projects - these all come well after basic competency.</p>

<p>Not only does a life of cyclic learning work against reaching these next levels, but your ego and willpower also work against you. Those next-level skills are harder to learn. And once you’ve gained competency you lose the excuse of “I’m onboarding” or “still ramping up” when something goes wrong.</p>

<p>I always challenge engineers that want to make big changes in what they’re working on to consider whether they’re simply at the end of a novelty cycle. I always encourage them to go after those next level skills.</p>

<p>On the hiring front, I see a lot of people who have a career’s worth of 2-year stints. You can do that successfully for an entire career, and there are even some people that’ll tell you it’s a way to optimize earnings over time. If it does, I believe it only optimizes earnings for people who can’t get to those next level skills. The biggest earnings come from building and growing with a winning company.</p>

<p>24-monthers never deeply learn how things work. They’ll typically add value to a new company by carrying a collection of things they’ve seen before and shallowly applying them to similar problems. But when faced with a new problem that doesn’t map easily to the solutions they’ve seen, things start to break down.</p>

<p>The end-games for both careers are very different.</p>

<p>24-monthers eventually can get into C-level positions where it’s not uncommon to bring in someone who can just apply the common solutions to the similar task at hand. Their stints usually end right around the time where they’ve upleveled the company in some way and don’t know how to grow their team or evolve their strategy or deal with the short-comings of some of their decisions.</p>

<p>People who learn next level skills and how to deeply understand and react to the tasks at hand lead companies to uniquely successful outcomes. The best CEOs, the best CTOs, the best C-level anything - their careers are often a small handful of long-duration roles where they didn’t apply rote practices but innovated and reacted to change and created novel solutions based on deep understanding.</p>

<h2 id="conclusion">Conclusion</h2>

<p>I’m not saying you should stay with any given job. There are bad roles and bad bosses and everything in between. And skill diversification is important. But every job has problems. If you’re leaving because you’re chasing novelty or avoiding tackling your company’s challenges, you’ll start over in the cycle. Leave enough places for these reasons and you’ll find you’ve seriously limited your opportunities and earnings over time.</p>


    




  </div></div>]]>
            </description>
            <link>https://staysaasy.com/engineering/2020/06/16/Stop-Sabotaging.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23636077</guid>
            <pubDate>Thu, 25 Jun 2020 01:59:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Anomaly Detection as a Foundation of Autonomous Monitoring]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23635559">thread link</a>) | @gk1
<br/>
June 24, 2020 | https://www.zebrium.com/blog/log-metrics-anomaly-detection-as-a-foundation-of-autonomous-monitoring | <a href="https://web.archive.org/web/*/https://www.zebrium.com/blog/log-metrics-anomaly-detection-as-a-foundation-of-autonomous-monitoring">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p>We believe the future of monitoring, especially for platforms like <a href="https://www.zebrium.com/k8s" rel=" noopener">Kubernetes</a>, is truly <a href="https://www.zebrium.com/blog/the-future-of-monitoring-is-autonomous" rel="noopener" target="_blank">autonomous</a>. Cloud native applications are increasingly distributed, evolving faster and failing in new ways, making it harder to monitor, troubleshoot and resolve incidents. Traditional approaches such as dashboards, carefully tuned alert rules and searches through logs are reactive and time intensive, hurting productivity, the user experience and MTTR. We believe machine learning can do much better – <a href="https://www.zebrium.com/blog/using-machine-learning-to-detect-anomalies-in-logs" rel=" noopener">detecting anomalous patterns</a> automatically, creating highly diagnostic incident alerts and shortening time to resolution.</p>
<!--more-->
<h3>What do you imagine when you see "Anomaly Detection"?</h3>
<p>When you think about anomaly detection, you probably visualize it for metrics: detection of outlier values like peaks, dropouts, or other deviations from normal. <img src="https://www.zebrium.com/hs-fs/hubfs/anomaly%20detection.png?width=303&amp;name=anomaly%20detection.png" alt="anomaly detection" width="303" srcset="https://www.zebrium.com/hs-fs/hubfs/anomaly%20detection.png?width=152&amp;name=anomaly%20detection.png 152w, https://www.zebrium.com/hs-fs/hubfs/anomaly%20detection.png?width=303&amp;name=anomaly%20detection.png 303w, https://www.zebrium.com/hs-fs/hubfs/anomaly%20detection.png?width=455&amp;name=anomaly%20detection.png 455w, https://www.zebrium.com/hs-fs/hubfs/anomaly%20detection.png?width=606&amp;name=anomaly%20detection.png 606w, https://www.zebrium.com/hs-fs/hubfs/anomaly%20detection.png?width=758&amp;name=anomaly%20detection.png 758w, https://www.zebrium.com/hs-fs/hubfs/anomaly%20detection.png?width=909&amp;name=anomaly%20detection.png 909w" sizes="(max-width: 303px) 100vw, 303px">In the realm of application monitoring metrics are a scheduled measurements of a large set (thousands) of system health attributes – such as CPU, memory, latency and throughput. So metrics anomaly detection can be a useful tool to detect application health incidents, with the metrics anomalies serving as symptoms of the incident. A challenge with traditional time series anomaly detection is that it is noisy – applications can generate thousands of metrics, and in any given day it’s common to see many of them deviating from their historical ranges. Alerting on all of these would be a noisy mess,so users need to do more work to avoid alert fatigue. They must handpick which ones really matter, carefully tune thresholds, make adjustments for seasonality and trend lines, plus be thoughtful about algorithm selection.</p>
<p><br>This approach is untenable to detect new failure modes (unknown failure modes with as yet unknown symptoms). And it does not take advantage of the fact that when software incidents occur, they almost never impact just one metric. For example, memory contention on a node impacts multiple containers. Similarly, network bottlenecks impact latency for many operations which show up in metrics.</p>
<img src="https://www.zebrium.com/hs-fs/hubfs/correlated%20metrics%20anomalies.png?width=307&amp;name=correlated%20metrics%20anomalies.png" alt="correlated metrics anomalies" width="307" srcset="https://www.zebrium.com/hs-fs/hubfs/correlated%20metrics%20anomalies.png?width=154&amp;name=correlated%20metrics%20anomalies.png 154w, https://www.zebrium.com/hs-fs/hubfs/correlated%20metrics%20anomalies.png?width=307&amp;name=correlated%20metrics%20anomalies.png 307w, https://www.zebrium.com/hs-fs/hubfs/correlated%20metrics%20anomalies.png?width=461&amp;name=correlated%20metrics%20anomalies.png 461w, https://www.zebrium.com/hs-fs/hubfs/correlated%20metrics%20anomalies.png?width=614&amp;name=correlated%20metrics%20anomalies.png 614w, https://www.zebrium.com/hs-fs/hubfs/correlated%20metrics%20anomalies.png?width=768&amp;name=correlated%20metrics%20anomalies.png 768w, https://www.zebrium.com/hs-fs/hubfs/correlated%20metrics%20anomalies.png?width=921&amp;name=correlated%20metrics%20anomalies.png 921w" sizes="(max-width: 307px) 100vw, 307px">

<p>To be useful for incident detection, anomaly detection has to work autonomously across all time series, but also separate the signal from&nbsp;the noise by picking out the hotspots of correlated anomalies that are indicators of real problems. And to be even more useful, it should automatically correlate these metric anomaly hotspots with something that is even harder to build rules for – anomalies in log events. &nbsp;&nbsp;</p>

<h3><span><strong>Anomaly detection applied to logs is very different</strong></span></h3>

<p>Log events are generated synchronous with execution of specific software paths. This makes them incredibly granular (micro-second or even finer resolution). They are also rich: since log events are only generated when specific conditions are encountered, they can selectively output data with almost unbounded cardinality (such as labels and IDs). Most significantly, events provide the best indication of causality. Where metrics measure aggregate symptoms about the application, log events are closely linked to specific code paths or error conditions in the software. For all of the above reasons, logs are an invaluable trove of information, so troubleshooting invariably involves digging through logs to find out root cause of an incident.&nbsp;</p>

<p>What if you didn’t have to do this reactively? Why couldn’t anomaly detection also be applied to events, with the goal of detecting highly unusual patterns of code execution, or rare errors or conditions. In other words, patterns that are diagnostic of a software problem, an infrastructure issue that impacts the application, or even security incidents. This is a bit harder to conceptualize than anomaly detection for metrics, but here is how it works.</p>
<h3>Learn what to track</h3>
<p>Metrics are explicitly tagged with labels and IDs – so it is clear what is being measured. Unfortunately, the link between a specific log event and the corresponding line of code is not explicit – most log events don’t contain references to source code, and they are typically unstructured, free form outputs coded by developers to help them troubleshoot. As a result, many of them look similar to the human eye because they contain similar keywords or strings.</p>

<p>Luckily machine learning can do far better than a human in this regard – it only needs to see a few variants of each message type to fully extract the fixed and variable parts of each message type – rapidly learning all the unique message types. This essentially constitutes the “dictionary” <strong><em>of all unique event types generated by the application stack</em></strong> – all that’s</p>
<p><img src="https://www.zebrium.com/hs-fs/hubfs/Structuring%20an%20event.png?width=974&amp;name=Structuring%20an%20event.png" alt="Structuring an event" width="974" srcset="https://www.zebrium.com/hs-fs/hubfs/Structuring%20an%20event.png?width=487&amp;name=Structuring%20an%20event.png 487w, https://www.zebrium.com/hs-fs/hubfs/Structuring%20an%20event.png?width=974&amp;name=Structuring%20an%20event.png 974w, https://www.zebrium.com/hs-fs/hubfs/Structuring%20an%20event.png?width=1461&amp;name=Structuring%20an%20event.png 1461w, https://www.zebrium.com/hs-fs/hubfs/Structuring%20an%20event.png?width=1948&amp;name=Structuring%20an%20event.png 1948w, https://www.zebrium.com/hs-fs/hubfs/Structuring%20an%20event.png?width=2435&amp;name=Structuring%20an%20event.png 2435w, https://www.zebrium.com/hs-fs/hubfs/Structuring%20an%20event.png?width=2922&amp;name=Structuring%20an%20event.png 2922w" sizes="(max-width: 974px) 100vw, 974px"></p>
<p>missing is the corresponding line # from the source code.</p>

<p>Note that this event type dictionary is not as big as you might think – an entire Atlassian suite has fewer than 1,000 unique event types.</p>
<h3>Learn the normal, detect the abnormal</h3>
<p>Once we’ve assembled this foundational dictionary of event types, another layer of ML learns<img src="https://www.zebrium.com/hs-fs/hubfs/learn%20the%20normal%20and%20detect%20the%20abnormal.png?width=300&amp;name=learn%20the%20normal%20and%20detect%20the%20abnormal.png" alt="learn the normal and detect the abnormal" width="300" srcset="https://www.zebrium.com/hs-fs/hubfs/learn%20the%20normal%20and%20detect%20the%20abnormal.png?width=150&amp;name=learn%20the%20normal%20and%20detect%20the%20abnormal.png 150w, https://www.zebrium.com/hs-fs/hubfs/learn%20the%20normal%20and%20detect%20the%20abnormal.png?width=300&amp;name=learn%20the%20normal%20and%20detect%20the%20abnormal.png 300w, https://www.zebrium.com/hs-fs/hubfs/learn%20the%20normal%20and%20detect%20the%20abnormal.png?width=450&amp;name=learn%20the%20normal%20and%20detect%20the%20abnormal.png 450w, https://www.zebrium.com/hs-fs/hubfs/learn%20the%20normal%20and%20detect%20the%20abnormal.png?width=600&amp;name=learn%20the%20normal%20and%20detect%20the%20abnormal.png 600w, https://www.zebrium.com/hs-fs/hubfs/learn%20the%20normal%20and%20detect%20the%20abnormal.png?width=750&amp;name=learn%20the%20normal%20and%20detect%20the%20abnormal.png 750w, https://www.zebrium.com/hs-fs/hubfs/learn%20the%20normal%20and%20detect%20the%20abnormal.png?width=900&amp;name=learn%20the%20normal%20and%20detect%20the%20abnormal.png 900w" sizes="(max-width: 300px) 100vw, 300px"> the normal patterns of <strong><em>each event</em></strong> <strong><em>type</em></strong>. This includes things such as its frequency, periodicity, severity, and even the values of metrics embedded within each event type. Now when a log event breaks pattern significantly, it is anomalous.</p>

<p>Particularly important variants include the first occurrence of a very rare event, and the sudden stoppage of a normal event (e.g. a system heartbeat).</p>
<h3>Increase the contrast between signal and noise</h3>
<p>In practice you can’t stop there – most enterprise applications have dozens of service</p>
<img src="https://www.zebrium.com/hs-fs/hubfs/machine%20learning%20for%20log%20anomaly%20detection.png?width=207&amp;name=machine%20learning%20for%20log%20anomaly%20detection.png" alt="machine learning for log anomaly detection" width="207" srcset="https://www.zebrium.com/hs-fs/hubfs/machine%20learning%20for%20log%20anomaly%20detection.png?width=104&amp;name=machine%20learning%20for%20log%20anomaly%20detection.png 104w, https://www.zebrium.com/hs-fs/hubfs/machine%20learning%20for%20log%20anomaly%20detection.png?width=207&amp;name=machine%20learning%20for%20log%20anomaly%20detection.png 207w, https://www.zebrium.com/hs-fs/hubfs/machine%20learning%20for%20log%20anomaly%20detection.png?width=311&amp;name=machine%20learning%20for%20log%20anomaly%20detection.png 311w, https://www.zebrium.com/hs-fs/hubfs/machine%20learning%20for%20log%20anomaly%20detection.png?width=414&amp;name=machine%20learning%20for%20log%20anomaly%20detection.png 414w, https://www.zebrium.com/hs-fs/hubfs/machine%20learning%20for%20log%20anomaly%20detection.png?width=518&amp;name=machine%20learning%20for%20log%20anomaly%20detection.png 518w, https://www.zebrium.com/hs-fs/hubfs/machine%20learning%20for%20log%20anomaly%20detection.png?width=621&amp;name=machine%20learning%20for%20log%20anomaly%20detection.png 621w" sizes="(max-width: 207px) 100vw, 207px">
<p>s, with hundreds if not thousands of instances (many of them ephemeral), scaling operations and frequent updates. Good anomaly detection can be very selective - picking out the one in a million event that is truly anomalous. However, one in a million would still be too many things to focus on in an environment that generates billions of messages a day. Once again, machine learning to the rescue – it takes advantage of the fact that a single anomaly in one event type is rarely alert worthy – but when tightly clustered group of anomalies pops up across multiple event streams – that IS almost always alert worthy. What constitutes “unusually tight cluster” depends on the specific deployment of an application, so it needs to be learned on the fly.</p>
<h3>See a complete narrative</h3>
<p>This type of anomaly clustering doesn’t just improve signal to noise by several orders of magnitude. It also constructs an automatic summary of the incident – picking out the sequence of anomalous events and the related anomalous metrics, as well as highlighting the hosts and log types that fully describe the incident.</p>

<p><img src="https://www.zebrium.com/hs-fs/hubfs/logs%20and%20metrics%20incident.png?width=908&amp;name=logs%20and%20metrics%20incident.png" alt="logs and metrics incident" width="908" srcset="https://www.zebrium.com/hs-fs/hubfs/logs%20and%20metrics%20incident.png?width=454&amp;name=logs%20and%20metrics%20incident.png 454w, https://www.zebrium.com/hs-fs/hubfs/logs%20and%20metrics%20incident.png?width=908&amp;name=logs%20and%20metrics%20incident.png 908w, https://www.zebrium.com/hs-fs/hubfs/logs%20and%20metrics%20incident.png?width=1362&amp;name=logs%20and%20metrics%20incident.png 1362w, https://www.zebrium.com/hs-fs/hubfs/logs%20and%20metrics%20incident.png?width=1816&amp;name=logs%20and%20metrics%20incident.png 1816w, https://www.zebrium.com/hs-fs/hubfs/logs%20and%20metrics%20incident.png?width=2270&amp;name=logs%20and%20metrics%20incident.png 2270w, https://www.zebrium.com/hs-fs/hubfs/logs%20and%20metrics%20incident.png?width=2724&amp;name=logs%20and%20metrics%20incident.png 2724w" sizes="(max-width: 908px) 100vw, 908px"></p>
<h3>Conclusion</h3>
<p>Done right, anomaly detection can <a href="https://www.zebrium.com/blog/is-autonomous-monitoring-the-anomaly-detection-you-actually-wanted" rel=" noopener">enable autonomous incident creation</a>, making it an incredibly powerful pillar of a monitoring strategy. It detects previously unknown problems the first time they occur, and reduces MTTR by automatically surfacing the unusual events and anomalies in metrics that describes an incident. But doing it right means understanding unique event types, learning the patterns and correlations of log events and metrics, and detecting anomaly clusters with good signal to noise. And for this to be practical, all of this has to work without extensive configuration, manual tuning, or impractical training windows.</p>

<p><span><a href="https://www.zebrium.com/sign-up?utm_campaign=Sign-up&amp;utm_source=adaa" rel=" noopener">Try it for yourself now</a></span>.</p></span>
</p>
<p id="hubspot-topic_data"> Tags:
<a href="https://www.zebrium.com/blog/tag/devops">devops</a>,
<a href="https://www.zebrium.com/blog/tag/observability">observability</a>,
<a href="https://www.zebrium.com/blog/tag/k8s">k8s</a>,
<a href="https://www.zebrium.com/blog/tag/kubernetes">kubernetes</a>,
<a href="https://www.zebrium.com/blog/tag/monitoring">monitoring</a>,
<a href="https://www.zebrium.com/blog/tag/autonomous-log-monitoring">autonomous log monitoring</a>,
<a href="https://www.zebrium.com/blog/tag/log-anomaly-detection">log anomaly detection</a>,
<a href="https://www.zebrium.com/blog/tag/autonomous-monitoring">autonomous monitoring</a>
</p>
</div></div>]]>
            </description>
            <link>https://www.zebrium.com/blog/log-metrics-anomaly-detection-as-a-foundation-of-autonomous-monitoring</link>
            <guid isPermaLink="false">hacker-news-small-sites-23635559</guid>
            <pubDate>Thu, 25 Jun 2020 00:44:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Feasibility of Using a Corncob as a Football]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23635069">thread link</a>) | @a7b3fa
<br/>
June 24, 2020 | https://blog.nathanv.me/posts/corncob-football/ | <a href="https://web.archive.org/web/*/https://blog.nathanv.me/posts/corncob-football/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<h2>Table of Contents</h2>

<h2 id="background">Background</h2>
<p>I had written this a while ago to be a humorous post on
<a href="https://www.reddit.com/r/cfb" rel="noreferrer" target="_blank">/r/CFB</a>, but due to COVID-19, I totally
forgot to post it. This is not meant to be serious. Enjoy.</p>

<p>To begin with, we need to gather actual data from real footballs.
This is to help with our calculations for corncobs, and to provide as a reference
to ensure our process is correct.</p>
<h3 id="size-and-mass">Size and Mass</h3>
<p>First, we need the mass and frontal area of a football.
I don’t know if college footballs are different from NFL footballs, but I was able to
find that a NFL football should be between 14 to 15 ounces in weight and have
a circumference of 22 inches.
<a href="https://www.sportsrec.com/6560043/what-is-the-official-size-of-the-nfl-football" rel="noreferrer" target="_blank">Source.</a>
We’ll meet the weight half-way and
call it 14.5 ounces or 0.41 kg. With a circumference of 22 inches,
that means (assuming the football front is perfectly circular)
the frontal area is 38.52 in<sup>2</sup> or 0.0248 m<sup>2</sup>.</p>
<h3 id="throwing-velocity">Throwing Velocity</h3>
<p>So, how fast can a quarterback <em>actually</em> throw a football? More importantly, how much
<em>force</em> can a quarterback impart on a football? (you’ll see why later)
Based on some research, a fast throw is around 60 mph (26.82 m/s)
with a rotation of about 600 rpm (62.83 rad/s).
<a href="https://www.sportsrec.com/6938474/maximum-speed-of-a-football" rel="noreferrer" target="_blank">Source.</a>
However, that still doesn’t provide us
the force of the throw, as force equals mass times acceleration. In order to figure out
acceleration, we need to know how long the throw takes.
Using <a href="https://youtu.be/tVoqA-LKGb4?t=206" rel="noreferrer" target="_blank">this clip</a>,
I counted the throw taking 11 frames, from winding back,
to the ball leaving Drew’s hand. In that 30fps video, that’s 0.36 seconds,
which means the ball experienced about 74.5 m/s<sup>2</sup> of acceleration.
This means that about 30.545 Newtons of force was imparted onto the ball.</p>
<h3 id="throwing-height">Throwing Height</h3>
<p>Another important factor is at what height the football is thrown from. Someone taller
will be able to throw the ball farther. I don’t know much about football,
but it seems that when throwing the football, it’s released around head-height,
so we’ll estimate it as that. Therefore, we need an idea of idea of how tall
our average quarterback is. Thankfully, a quick search reveals that to be around
6’1” or about 1.55 meters.
<a href="https://www.ncsasports.org/football/recruiting-guidelines" rel="noreferrer" target="_blank">Source.</a></p>
<h3 id="air-properties">Air Properties</h3>
<p>Next, we need to figure out the properties of air (density, temperature, pressure)
that footballs are being thrown in,
as this affects the drag and trajectory. While we could just assume sea-level, let’s
find the average altitude of every college football stadium, and use a
standard atmosphere lookup table to find the air properties.</p>
<p>Unfortunately, I was unable to find a list of altitudes of college football stadiums.
Instead, I had to get creative. I <em>did</em> manage to find a list of
every college football stadium.
<a href="http://www.collegegridirons.com/comparisons.htm" rel="noreferrer" target="_blank">Source.</a>
From there, I wrote a script that ran each
stadium through the Google Maps API to get an elevation.
<a href="https://developers.google.com/maps/documentation/elevation/start" rel="noreferrer" target="_blank">Source.</a>
Just average all the values together, and ta-da, the average elevation
of every US college football stadium is around 285 meters.</p>
<p>With the average elevation, we can now determine the standard air density. This comes
out to:</p>
<ul>
<li>Density: 1.19183 kg/m<sup>3</sup></li>
<li>Temperature: 286.297 K</li>
<li>Pressure: 97947.8 Pa</li>
</ul>
<p><a href="https://www.digitaldutch.com/atmoscalc/" rel="noreferrer" target="_blank">Source.</a></p>
<h3 id="coefficient-of-drag">Coefficient of Drag</h3>
<p>A crucial number in determining the trajectory of a flying object is it’s
“coefficient of drag”. This is a unitless coefficient that represents how much
drag an object experiences. This is a very difficult number to calculate,
and is usually found experimentally.</p>
<p>Research shows that the coefficient of drag of a football is around 0.05-0.06.
<a href="http://users.df.uba.ar/sgil/physics_paper_doc/papers_phys/fluids/drag_football.pdf" rel="noreferrer" target="_blank">Source.</a>
However, to ensure our process is correct, I’d like to replicate this result with CFD
(computational fluid dynamics) software.</p>
<h4 id="3d-model">3D Model</h4>
<p>In order to compute our own coefficient of drag, we need a 3D model. Thankfully
a quick search on GrabCAD found the
<a href="https://grabcad.com/library/american-football-5" rel="noreferrer" target="_blank">perfect candidate</a>.
This model was hollow, so to avoid any weird effects in CFD, I filled in the model.</p>
<h4 id="cfd">CFD</h4>
<p>I setup a fluid simulation in SOLIDWORKS (my CAD program of choice), with the following
parameters, and an equation goal to compute the drag coefficient from the
drag force imparted on the football.
<a href="https://www.grc.nasa.gov/WWW/K-12/airplane/dragco.html" rel="noreferrer" target="_blank">Source.</a></p>
<p>Parameters:</p>
<ul>
<li>External Analysis
<ul>
<li>Exclude cavities without flow conditions</li>
<li>Exclude internal space</li>
</ul></li>
<li>Gravity on</li>
<li>Global rotation @ 62.83 rad/s</li>
<li>Air preset</li>
<li>Laminar and turbulent flow</li>
<li>Humidity effects on (default settings)</li>
<li>Turbulence effects on (default settings)</li>
<li>Adiabatic wall with 100 micrometer roughness</li>
<li>97947.8 Pa pressure</li>
<li>286.297 K temperature</li>
<li>-26.82 m/s flow velocity relative to rotating frame</li>
<li>Level 6 density global mesh</li>
<li>Computational Domain +/- 0.2 m on sides, +/- 0.3 m front-to-back.</li>
</ul>
<p>After it was done, I was pleasantly surprised to find my coefficient of drag to
come out to 0.0953. This means we’re in the right ballpark. (I didn’t expect to
hit the value exactly as CFD inherently has some error, and SOLIDWORKS flow
simulation isn’t a top-tier product)</p>
<figure>
<a href="https://blog.nathanv.me/posts/corncob-football/img/football_cfd.png" target="_blank">
<img src="https://blog.nathanv.me/posts/corncob-football/img/football_cfd.png" alt="Football CFD">
</a>
<figcaption>Football CFD</figcaption>
</figure>
<h3 id="reference-calculations">Reference Calculations</h3>
<p>Finally, with all of this data, we can now plot theoretical trajectories.
<a href="https://www.grc.nasa.gov/www/k-12/airplane/flteqs.html" rel="noreferrer" target="_blank">Source.</a></p>
<figure>
<a href="https://blog.nathanv.me/posts/corncob-football/img/football_flights.png" target="_blank">
<img src="https://blog.nathanv.me/posts/corncob-football/img/football_flights.png" alt="Football Trajectories">
</a>
<figcaption>Football Trajectories</figcaption>
</figure>
<div><pre><code data-lang="txt">Thrown at 5 degrees, a football will fly for 0.85 seconds, landing 21.85 meters downfield.
Thrown at 10 degrees, a football will fly for 1.21 seconds, landing 30.28 meters downfield.
Thrown at 15 degrees, a football will fly for 1.6 seconds, landing 38.85 meters downfield.
Thrown at 20 degrees, a football will fly for 2.01 seconds, landing 46.67 meters downfield.
Thrown at 25 degrees, a football will fly for 2.41 seconds, landing 53.32 meters downfield.
Thrown at 30 degrees, a football will fly for 2.79 seconds, landing 58.52 meters downfield.
Thrown at 35 degrees, a football will fly for 3.15 seconds, landing 62.14 meters downfield.
Thrown at 40 degrees, a football will fly for 3.49 seconds, landing 64.08 meters downfield.
Thrown at 45 degrees, a football will fly for 3.8 seconds, landing 64.34 meters downfield.
Thrown at 50 degrees, a football will fly for 4.07 seconds, landing 62.93 meters downfield.
Thrown at 55 degrees, a football will fly for 4.32 seconds, landing 59.87 meters downfield.
Thrown at 60 degrees, a football will fly for 4.53 seconds, landing 55.23 meters downfield.
Thrown at 65 degrees, a football will fly for 4.72 seconds, landing 49.07 meters downfield.
Thrown at 70 degrees, a football will fly for 4.86 seconds, landing 41.51 meters downfield.
Thrown at 75 degrees, a football will fly for 4.98 seconds, landing 32.66 meters downfield.
Thrown at 80 degrees, a football will fly for 5.06 seconds, landing 22.66 meters downfield.
Thrown at 85 degrees, a football will fly for 5.11 seconds, landing 11.71 meters downfield.</code></pre></div>
<p>Thrown at an optimal 45 degrees, our theoretical football calculations say the
ball will fly about 64 meters. Based on record throw data from
<a href="https://www.topendsports.com/sport/gridiron/longest-throw.htm" rel="noreferrer" target="_blank">this site</a>
it looks like our data is pretty feasible, though maybe a bit on the short side.</p>
<h2 id="corncob">Corncob</h2>
<p>Time to perform the same analysis with a corncob.</p>
<h3 id="size-and-mass-1">Size and Mass</h3>
<p>Once again, we first need the
size and mass of a corncob. Research shows that the average ear of corn
was between 156.80 mm and 178.13 mm in length, depending on when it was picked.
<a href="https://www.researchgate.net/publication/303010127_Azospirillum_brasilense_promotes_increment_in_corn_production" rel="noreferrer" target="_blank">Source.</a>
(I know this research is from Africa. It’s best I could come up with
without going to the grocery store with a ruler looking like an idiot.)</p>
<p>Finding the mass of an average corncob was a bit trickier. I was able to find
that a pound of corn is about 1300 kernels, and that an ear of corn averages
800 kernels. This means that we can estimate that an ear of corn is about 0.615 pounds
or 0.279kg.
<a href="https://www.nefbfoundation.org/Images/FOUndation/Educators/Enriching-Activities/Corn-Calculations.pdf" rel="noreferrer" target="_blank">Source.</a></p>
<h3 id="throwing-velocity-1">Throwing Velocity</h3>
<p>So, how fast can you throw a corncob?
Given that the corncob has a mass of only 0.279 kg, this means with 30.545 Newtons
of force, the corncob can be accelerated at a rate of 109.48 m/s<sup>2</sup>. Over the same
0.36 second period, that’s 39.413 m/s or a little over 88 mph (where we’re going,
we don’t need roads).</p>
<h3 id="coefficient-of-drag-1">Coefficient of Drag</h3>
<h4 id="3d-model-1">3D Model</h4>
<p>I didn’t have any desire to 3D model an ear of corn, so I went looking for a model
I could download for free. Surprisingly, there weren’t many options. Thankfully,
I did manage to find one
<a href="https://free3d.com/3d-model/cornoncob-v01--775846.html" rel="noreferrer" target="_blank">free model</a>.
A quick measurement shows the length of the model falls within our acceptable range,
so no scaling required.</p>
<figure>
<a href="https://blog.nathanv.me/posts/corncob-football/img/corn_length.png" target="_blank">
<img src="https://blog.nathanv.me/posts/corncob-football/img/corn_length.png" alt="Corncob Length">
</a>
<figcaption>Corncob Length</figcaption>
</figure>
<p>In order to get the frontal area of our selected corncob, I simply measured
the diameter of the model, which happened to be a near-perfect circle with
a diameter of 35.49 mm.</p>
<figure>
<a href="https://blog.nathanv.me/posts/corncob-football/img/corn_diameter.png" target="_blank">
<img src="https://blog.nathanv.me/posts/corncob-football/img/corn_diameter.png" alt="Corncob Diameter">
</a>
<figcaption>Corncob Diameter</figcaption>
</figure>
<p>This gives the corncob a frontal area of 989.24 mm<sup>2</sup> or 0.00098924 m<sup>2</sup>.</p>
<h4 id="cfd-1">CFD</h4>
<p>I setup a very similar simulation as described above, just with a higher velocity
and smoother walls. I then fired off the simulation and let my processor chug
for about 20 minutes. This simulation took significantly longer as the model
was not a native SOLIDWORKS file, but a very complex imported geometry. Meshing
the model alone took about 5 minutes.</p>
<figure>
<a href="https://blog.nathanv.me/posts/corncob-football/img/cpu_usage.png" target="_blank">
<img src="https://blog.nathanv.me/posts/corncob-football/img/cpu_usage.png" alt="CPU Usage">
</a>
<figcaption>CPU Usage</figcaption>
</figure>
<p>After the simulation was finished, I was very surprised to have the coefficient of drag
come out to 0.184 (almost twice that of the football).
My best guess for this is despite the corncob’s small size,
the higher velocity and rougher surface contributed to more relative drag.
Another theory I have is that the kernels protruding create a lot of low-pressure areas,
increasing drag, as you can see in the image below with the sort of “ripples” of
pressure values.</p>
<figure>
<a href="https://blog.nathanv.me/posts/corncob-football/img/corncob_cfd.png" target="_blank">
<img src="https://blog.nathanv.me/posts/corncob-football/img/corncob_cfd.png" alt="Corncob CFD">
</a>
<figcaption>Corncob CFD</figcaption>
</figure>
<h3 id="throwing-distance">Throwing Distance</h3>
<p>Now, we bring it all together. How far can you actually throw a corncob? I plotted
theoretical trajectories using the same math as before.</p>
<figure>
<a href="https://blog.nathanv.me/posts/corncob-football/img/corncob_flights.png" target="_blank">
<img src="https://blog.nathanv.me/posts/corncob-football/img/corncob_flights.png" alt="Corncob Trajectories">
</a>
<figcaption>Corncob Trajectories</figcaption>
</figure>
<div><pre><code data-lang="txt">Thrown at 5 degrees, a corncob will fly for 1.01 seconds, landing 39.47 meters downfield.
Thrown at 10 degrees, a corncob will fly for 1.59 seconds, landing 61.1 meters downfield.
Thrown at 15 degrees, a corncob will fly for 2.22 seconds, landing 83.16 meters downfield.
Thrown at 20 degrees, a corncob will fly for 2.85 seconds, landing 103.55 meters downfield.
Thrown at 25 degrees, a corncob will fly for 3.48 seconds, landing 121.23 meters downfield.
Thrown at 30 degrees, a corncob will fly for 4.08 seconds, landing 135.46 meters downfield.
Thrown at 35 degrees, a corncob will fly for 4.65 seconds, landing 145.79 meters downfield.
Thrown at 40 degrees, a corncob will fly for 5.18 …</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.nathanv.me/posts/corncob-football/">https://blog.nathanv.me/posts/corncob-football/</a></em></p>]]>
            </description>
            <link>https://blog.nathanv.me/posts/corncob-football/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23635069</guid>
            <pubDate>Wed, 24 Jun 2020 23:33:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learn Elasticsearch with Hollywood Movies]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23634924">thread link</a>) | @lackoftactics
<br/>
June 24, 2020 | https://realptsdengineer.com/learn-elasticsearch-fun-way/ | <a href="https://web.archive.org/web/*/https://realptsdengineer.com/learn-elasticsearch-fun-way/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
			<!-- .cover -->


			<div>
				<p>I am tired of boring Elasticsearch tutorials. Learning should be interactive; it shouldn't feel like reading lengthy technical documentation. Today we are going to learn the basics of Elasticsearch using a movie database. I have a small database of titles ready for you to import.</p><p>Don't we need some theory? You didn't click to view the typical technical blog post. If you are stubborn, jump to the workshop section and learn on the fly. Some people learn this way better, &nbsp;nothing wrong with that. If you want to get to know some essentials, go through Slideshare I created.</p><figure> 

</figure><p>Before we begin clone this repo: <code>git clone <a>git@github.com</a>:ptsdengineer/learn-elasticsearch-with-hollywood-movies.git</code> or<strong> <a href="https://github.com/ptsdengineer/learn-elasticsearch-with-hollywood-movies/archive/master.zip">download zip</a></strong></p><h3 id="installing-elasticsearch-and-seeding-data">Installing Elasticsearch and seeding data</h3><p><strong>For Mac users</strong>: the most comfortable way would be to install it from homebrew: <code>brew install Elasticsearch</code></p><p><strong>For Linux users</strong>: Please try this tutorial here: <a href="https://www.digitalocean.com/community/tutorials/how-to-install-and-configure-elasticsearch-on-ubuntu-14-04" rel="nofollow">https://www.digitalocean.com/community/tutorials/how-to-install-and-configure-elasticsearch-on-ubuntu-14-04</a></p><p><strong>Run Elasticsearch</strong></p><p><code>elasticsearch</code> on Mac</p><p> <code>sudo service elasticsearch start</code> on Ubuntu</p><p> Check if it's running on <a href="http://localhost:9200/" rel="nofollow">http://localhost:9200</a></p><h3 id="run-using-docker">Run using docker</h3><p>If you prefer docker way, you can also use it in tutorial. I have docker-compose file ready.</p><p><code>docker-compose up</code></p><p><strong>Credentials</strong>: user is <strong><code>elastic</code></strong> and password <strong><code>changeme</code></strong></p><p><strong>Use Postman, curl or Insomnia for making calls to Elasticsearch API</strong>. I can't recommend <a href="https://insomnia.rest/">Insomnia</a> enough, this piece of software makes life so much easier.</p><h2 id="creating-data">Creating data</h2><p>Create index for movies, it will hold all the movies documents that we will import in a minute. Open insomnia and make your first call.</p><figure><img src="http://realptsdengineer.com/content/images/2020/06/put-movies-1.png" alt="" srcset="http://realptsdengineer.com/content/images/size/w600/2020/06/put-movies-1.png 600w, http://realptsdengineer.com/content/images/size/w1000/2020/06/put-movies-1.png 1000w, http://realptsdengineer.com/content/images/size/w1600/2020/06/put-movies-1.png 1600w, http://realptsdengineer.com/content/images/size/w2178/2020/06/put-movies-1.png 2178w"></figure><p>Now let's import data into our index. I prepared JSON with all the documents that could be easily run.</p><figure><pre><code>curl -s --header "Content-Type:application/json"  -XPOST localhost:9200/_bulk --data-binary @movies.json
</code></pre><figcaption>Bulk import of movies from json</figcaption></figure><p>*Use option <code>-u</code> for typing user and password when running with docker.</p><p>If you want to learn more about this feature: <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-bulk.html" rel="nofollow">Bulk import</a></p><h2 id="match-all">Match all</h2><p>Let's make the most straightforward possible query to our movies index. The query that returns all results, it's called match all query.</p><pre><code>GET &lt;name_of_index&gt;/_search
{
    "query": {
        "match_all": {}
    }
}
</code></pre><p>You should get this type of result in response:</p><pre><code>"hits": {
    "total": 306,
    "max_score": 1,
</code></pre><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-match-all-query.html" rel="nofollow">Match all docs</a></p><h4 id="exercise">Exercise</h4><p>Type this query into Insomnia. You will get results for the movies index.</p><h2 id="string-query">String query</h2><p>Still straightforward query, we will only search for a particular string.</p><pre><code>GET /_search
{
    "query": {
        "query_string" : {
            "default_field" : "content",
            "query" : "this AND that OR thus"
        }
    }
}
</code></pre><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-query-string-query.html" rel="nofollow">String query documentation</a></p><h5 id="exercise-">Exercise.</h5><p>Using this knowledge find movie Scarface in the Elasticsearch. There should be only one result.</p><h3 id="operators">Operators</h3><p>Let's build on this. We want to extend our search capabilities. Elasticsearch uses operators like in programming, by default it uses <code>OR</code> but we can use <code>AND</code> to get an exact match.</p><pre><code>GET /_search
{
    "query": {
        "query_string" : {
            "default_field" : "content",
            "query" : "Strawberry pie with jello",
            "default_operator": "AND"
        }
    }
}
</code></pre><p>Now we will be sure that we will only get recipes we are interested.</p><h5 id="exercise--1">Exercise.</h5><p>Make a query to Elasticsearch that will return only <strong>one</strong> result on query <code>Captain America first avenger</code></p><pre><code>"hits": {
     "total": 1,
     "max_score": 11.263437,
     "hits": [
        {
           "_index": "movies",
           "_type": "movie",
           "_id": "139",
           "_score": 11.263437,
           "_source": {
              "title": "Captain America: The First Avenger",
              "plot": "Predominantly set during World War II, Steve Rogers is a sickly man from Brooklyn who's transformed into super-soldier Captain America to aid in the war effort. Rogers must stop the Red Skull – Adolf Hitler's ruthless head of weaponry, and the leader of an organization that intends to use a mysterious device of untold powers for world domination.",
              "genres": null,
</code></pre><h3 id="fuzziness">Fuzziness</h3><p>What about cases when users don't type query correctly? We should also handle those cases. Fortunately Elasticsearch has an answer, match query with a fuzzy query, it's a simpler cousin of string query.</p><pre><code>"query": {
  "match": {
    "text": {
      "query": "jomped over me!",
      "fuzziness": "AUTO",
      "operator":  "and"
    }
  }
}
</code></pre><p><code>"fuzziness": "AUTO"</code> generates an edit distance based on the length of the term. <code>0..2</code> must match exactly <code>3..5</code> one edit allowed <code>&gt;5</code> two edits allowed</p><p>You could also use number values, like <code>0, 1, 2</code>. Fuzziness is interpreted as Levenshtein Edit Distance. More about: <a href="https://www.elastic.co/guide/en/elasticsearch/guide/current/fuzziness.html" rel="nofollow">fuzziness</a></p><p><strong>Exercise.</strong></p><p>Write a query that will return all Captain America movies based on a query, which was mistyped: "Captaon America"</p><h2 id="filtering">Filtering</h2><h3 id="we-are-using-a-range-query-">We are using a range query.</h3><p>Matches documents with fields that have terms within a certain range. The Lucene query type depends on the field type, for string fields, the TermRangeQuery, while for number/date fields, the query is a NumericRangeQuery. The following example returns all documents where age is between 10 and 20:</p><pre><code>GET _search
{
    "query": {
        "range" : {
            "age" : {
                "gte" : 10,
                "lte" : 20,
                "boost" : 2.0
            }
        }
    }
}
</code></pre><p><strong>gte</strong> = Greater-than or equal to</p><p><strong>gt</strong> = Greater-than</p><p><strong>lte</strong> = Less-than or equal to</p><p><strong>lt</strong> = Less-than</p><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-range-query.html" rel="nofollow">Range query</a></p><h4 id="exercise--2">Exercise.</h4><p>Create a query that would return movies with a running time between 60 and 90 minutes.<br>It should return 57 results.</p><h2 id="bool-query">Bool query</h2><p>The bool query takes a more-matches-is-better approach, so the score from each matching <code>must</code> or <code>should</code> clause will be added together to provide the final <code>_score</code> for each document.</p><p><code>must</code> - The clause (query) must appear in matching documents and will contribute to the score.</p><p><code>filter</code> - Filter clauses are executed in filter context. Scoring is ignored and clauses are considered for caching.</p><p><code>should</code> - The clause (query) should appear in the matching document.</p><p><strong>Example query:</strong></p><pre><code>POST _search
{
  "query": {
    "bool" : {
      "must" : {
        "term" : { "user" : "kimchy" }
      },
      "filter": {
        "term" : { "tag" : "tech" }
      },
      "must_not" : {
        "range" : {
          "age" : { "gte" : 10, "lte" : 20 }
        }
      },
      "should" : [
        { "term" : { "tag" : "wow" } },
        { "term" : { "tag" : "elasticsearch" } }
      ],
      "minimum_should_match" : 1,
      "boost" : 1.0
    }
  }
}
</code></pre><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-bool-query.html" rel="nofollow">Bool query</a></p><h4 id="exercise--3">Exercise.</h4><p>Create a query that will find superhero movies (keywords field: superhero) that are no longer than 120 minutes and no shorter than 60 minutes (field runtime) and must not have Robert Downey Jr. as a starring actor (actors field).</p><p>You should get 12 results for this query.</p><h2 id="aggregations">Aggregations</h2><p>Let's get some interesting stats for analytics. We want to get an overall view of how some value occurs through the documents. The stats aggregation would give us count, minimum value, maximum value, averages. It's useful for getting overall insight.</p><pre><code>{
    "aggs" : {
        "grades_stats" : { "stats" : { "field" : "grade" } }
    }
}
</code></pre><p>and returns:</p><pre><code>{
    ...

    "aggregations": {
        "grades_stats": {
            "count": 6,
            "min": 60,
            "max": 98,
            "avg": 78.5,
            "sum": 471
        }
    }
}
</code></pre><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations.html" rel="nofollow">Read more about aggregations here</a></p><h4 id="exercise--4">Exercise.</h4><p>Get overall data for ratings in movies: min, max, average. Do that using stats query.</p><h4 id="range-aggregation">Range Aggregation</h4><p>A multi-bucket value source-based aggregation enables the user to define a set of ranges - each representing a bucket.</p><pre><code>GET products/_search?size=0

{
  "aggs": {
    "weight_ranges": {
      "range": {
        "field": "weight",
        "ranges": [
          {
            "to": 500
          },
          {
            "from": 500,
            "to": 1000
          },
          {
            "from": 1000,
            "to": 1500
          }
        ]
      }
    }
  }
}
</code></pre><p>Returns aggregated data:</p><pre><code>    ...

    "aggregations": {
        "weight_ranges" : {
            "buckets": [
                {
                    "to": 500,
                    "doc_count": 20
                },
                {
                    "from": 500,
                    "to": 1000,
                    "doc_count": 4
                },
                {
                    "from": 1000,
                    "doc_count": 4
                }
            ]
        }
    }
}
</code></pre><h4 id="exercise--5">Exercise.</h4><p>Using range queries, count how many movies were in specific run times: below 60 minutes, between 60 and 75 minutes, between 90 and 120 minutes.</p><h2 id="histogram-aggregation">Histogram aggregation</h2><p>We can also use a histogram to bucket data instead of ranges. It's useful for prices in shops, so we can see how prices fall between different ranges like 0$-10$, 10$-20$.</p><pre><code>POST /sales/_search?size=0
{
    "aggs" : {
        "prices" : {
            "histogram" : {
                "field" : "price",
                "interval" : 10
            }
        }
    }
}
</code></pre><p>Would return:</p><pre><code>{
    ...
    "aggregations": {
        "prices" : {
            "buckets": [
                {
                    "key": 0.0,
                    "doc_count": 1
                },
                {
                    "key": 50.0,
                    "doc_count": 1
                },
                {
                    "key": 100.0,
                    "doc_count": 0
                },
                {
                    "key": 150.0,
                    "doc_count": 2
                },
                {
                    "key": 200.0,
                    "doc_count": 3
                }
            ]
        }
    }
}
</code></pre><h4 id="exercise--6">Exercise.</h4><p>Create histogram aggregation for a rating in movies with interval equal 1.</p><h2 id="sorting">Sorting</h2><p>Allows adding one or more sort on specific fields. Each sort can be reversed as well. The sort is defined on a per-field level, with particular field name for <code>_score</code> to sort by score, and <code>_doc</code> to sort by index order.</p><pre><code>GET /my_index/my_type/_search
{
    "sort" : [
        { "post_date" : {"order" : "asc"}},
        …</code></pre></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://realptsdengineer.com/learn-elasticsearch-fun-way/">https://realptsdengineer.com/learn-elasticsearch-fun-way/</a></em></p>]]>
            </description>
            <link>https://realptsdengineer.com/learn-elasticsearch-fun-way/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23634924</guid>
            <pubDate>Wed, 24 Jun 2020 23:11:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I deleted my Facebook, WhatsApp, and Instagram accounts, and felt great since]]>
            </title>
            <description>
<![CDATA[
Score 414 | Comments 228 (<a href="https://news.ycombinator.com/item?id=23634788">thread link</a>) | @shog_hn
<br/>
June 24, 2020 | https://www.shogan.co.uk/life/how-i-deleted-my-facebook-whatsapp-and-instagram-accounts-and-felt-great-since/ | <a href="https://web.archive.org/web/*/https://www.shogan.co.uk/life/how-i-deleted-my-facebook-whatsapp-and-instagram-accounts-and-felt-great-since/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.shogan.co.uk/life/how-i-deleted-my-facebook-whatsapp-and-instagram-accounts-and-felt-great-since/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23634788</guid>
            <pubDate>Wed, 24 Jun 2020 22:55:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[IBM, Microsoft, and Amazon Halt Sales of Facial Recognition to Police]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23634776">thread link</a>) | @andreyk
<br/>
June 24, 2020 | https://www.skynettoday.com/briefs/face-recog-police | <a href="https://web.archive.org/web/*/https://www.skynettoday.com/briefs/face-recog-police">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>        
      
      
      <h4>Movements against unregulated police use of facial recognition, which compound its many ethical issues, are gaining speed</h4>
      
      </div><div>
      <h2 id="summary">Summary</h2>

<ul>
  <li>Recent protests in racial discrimination and police brutality led IBM to cease developing facial recognition technology and Microsoft and Amazon to pause selling face recognition technology to law enforcement.</li>
  <li>While this is a good starting point, as companies are not only acknowledging but addressing known flaws and biases in face recognition systems, much work remains to be done.</li>
  <li>In particular, continued pressure from the public is needed to ensure ethical developments and regulations of face recognition technology in the future.</li>
</ul>

<h2 id="what-happened">What Happened</h2>

<p>In a June 8 <a href="https://www.ibm.com/blogs/policy/facial-recognition-susset-racial-justice-reforms/">letter</a> to members of Congress, IBM declared its opposition to technologies that would enable surveillance, including facial recognition. 
Microsoft and Amazon followed suit on facial recognition, respectively <a href="https://www.washingtonpost.com/technology/2020/06/11/microsoft-facial-recognition/">banning police use</a> and placing a <a href="https://blog.aboutamazon.com/policy/we-are-implementing-a-one-year-moratorium-on-police-use-of-rekognition">one-year moratorium</a> on use. 
Other companies, <a href="https://www.theguardian.com/australia-news/2020/jun/19/victoria-police-distances-itself-from-controversial-facial-recognition-firm-clearview-ai">such as Clearview AI</a>, still offer the technology to police departments. 
As <a href="https://www.washingtonpost.com/technology/2020/06/11/ibm-facial-recognition/">The Washington Post</a> reports, IBM’s decision to drop facial recognition technology has been preceded by years of debate, particularly in response to a 2018 study called <a href="http://gendershades.org/overview.html">Gender Shades</a> which found that industry facial recognition systems have much higher error rates on darker-skinned faces.</p>

<figure>
 <img src="https://www.skynettoday.com/assets/img/briefs/face-recog-police/gender-shades.png" alt=" Gender classification disparities in darker vs. lighter skinned faces. From the 2018 Gender Shades study">
  <figcaption>
    Gender classification disparities in darker vs. lighter skinned faces. From the <a href="http://proceedings.mlr.press/v81/buolamwini18a/buolamwini18a.pdf">2018 Gender Shades study</a> .
  </figcaption>
</figure>

<iframe width="560" height="315" src="https://www.youtube.com/embed/TWWsW1w-BVo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<p>Civil rights and justice groups, including the <a href="https://medium.com/@Joy.Buolamwini/ibm-leads-more-should-follow-racial-justice-requires-algorithmic-justice-and-funding-da47e07e5b58">Algorithmic Justice League</a> and <a href="https://www.aclu.org/press-releases/aclu-statement-amazon-face-recognition-moratorium">ACLU</a>, have commended these actions from IBM and Amazon:</p>

<blockquote>
  <p>The Algorithmic Justice League commends this decision as a first move forward towards company-side responsibility to promote equitable and accountable AI.</p>
</blockquote>

<blockquote>
  <p>It took two years for Amazon to get to this point, but we’re glad the company is finally recognizing the dangers face recognition poses to Black and Brown communities and civil rights more broadly.</p>
</blockquote>

<p>Facial recognition technology, capable of identifying a person from a digital image or video frame, has been under development for decades. 
With the major advances in deep learning over the past decade, facial recognition has also seen substantial progress. 
Modern AI-powered face recognition systems rely on large datasets of faces for two purposes: 1) training a neural network that can extract key features of human faces and 2) finding similar-looking faces using these features. 
There are multiple privacy and ethical concerns with collecting such large datasets, ranging from biased data that results in biased predictions to how these data <a href="https://onezero.medium.com/i-got-my-file-from-clearview-ai-and-it-freaked-me-out-33ca28b5d6d4">can be collected without consent</a>.</p>

<p>The recent controversies regarding face recognition are specifically centered around use by law enforcement. 
There are currently no federal laws, and few local ones, regulating how and when police and other government agencies can use such technologies. 
This is despite commercial offerings already being available for years, and <a href="https://www.nytimes.com/2020/01/12/technology/facial-recognition-police.html">being used</a> by some police departments. 
When these flawed systems are applied by law enforcement, they can place people of color at higher risk due to the higher error rate. 
Even if these systems worked perfectly, they can still be <a href="https://www.technologyreview.com/2020/06/12/1003482/amazon-stopped-selling-police-face-recognition-fight/">“easily weaponized against communities to harass them.”</a></p>

<h2 id="the-reactions">The Reactions</h2>

<p><strong>From the Press:</strong></p>

<ul>
  <li><a href="https://www.vox.com/recode/2020/6/10/21287194/amazon-microsoft-ibm-facial-recognition-moratorium-police">Vox</a> notes that public statements on facial recognition from such major companies is a step forward, but there are also concerns that smaller companies like Clearview AI may step in to take their place. Some are also skeptical of the recent moves by tech companies, calling them PR stunts:</li>
</ul>

<blockquote>
  <p>Evan Greer, the deputy director of Fight for the Future, called Amazon’s announcement “a public relations stunt.” The Surveillance Technology Oversight Project, a New York-based anti-surveillance legal organization, called the company’s move “too little, too late.” Its director, Albert Fox Cahn, added in an emailed statement, “Amazon shouldn’t just end this practice for one year or one decade; it should end it forever.”</p>
</blockquote>

<ul>
  <li><a href="https://www.forbes.com/sites/tomtaulli/2020/06/13/facial-recognition-bans-what-do-they-mean-for-ai-artificial-intelligence/#c15825c46ee3">Forbes</a> reports that with the condemnations and moratoriums, there is enough conflation between the different sorts of technology that people aren’t quite sure what exactly is being renounced. Nonetheless, the public attention on face recognition systems is a good starting point to ensure ethical developments of this technology in the future.</li>
</ul>

<blockquote>
  <p>This should then be backed up with a strong set of principles and ethical standards that the industry can follow. The result will likely be a stronger foundation for AI.</p>
</blockquote>

<ul>
  <li><a href="https://www.wired.com/story/ibm-withdrawal-wont-mean-end-facial-recognition/">Wired</a> also believes that we are far from the end with facial recognition, agreeing with Vox that plenty of smaller companies are still there to fill the void–the technology produced by these companies is prey to the same fatal flaws that resulted in the blowback against IBM et al in the first place.</li>
</ul>

<p><strong>From the Experts:</strong></p>

<ul>
  <li>Some, such as <a href="https://mobile.twitter.com/jathansadowski/status/1270855471222550528?cxt=HHwWgIC1tZqbgaMjAAAA">Jathan Sadowski</a> (research fellow at Monash U emerging tech lab), see the “victory” of pushback against facial recognition as merely symbolic and an opportunity to push harder.</li>
</ul>

<blockquote><p lang="en" dir="ltr">Yes, I see this not so much as winning a battle, but as an opportunity to go on the offensive, to push harder, to actually extract real and lasting victories. We've all had fight so hard just to gain enough ground to strike back. And I'm finally starting to feel a bit surefooted.</p>— Jathan Sadowski (@jathansadowski) <a href="https://twitter.com/jathansadowski/status/1270855471222550528?ref_src=twsrc%5Etfw">June 10, 2020</a></blockquote>


<ul>
  <li><a href="https://mobile.twitter.com/FoxCahn/status/1270840507971837954">Albert Fox Cahn</a> described the step as a milestone, but “like hearing an arsonist agree to stop pouring gasoline on a forest fire, without doing much to put out the blaze.”  \</li>
</ul>

<blockquote><p lang="en" dir="ltr">I agree that’s a huge milestone, but it feels like hearing an arsonist agree to stop pouring gasoline on a forest fire, without doing much to put out the blaze, and I hope many see it as a sign of just how much more can be accomplished through even more pressure.</p>— Albert Fox Cahn🔯 (@FoxCahn) <a href="https://twitter.com/FoxCahn/status/1270840507971837954?ref_src=twsrc%5Etfw">June 10, 2020</a></blockquote>


<ul>
  <li>Regardless, these steps, even Amazon’s one-year moratorium, are seen as <a href="https://mobile.twitter.com/EvanSelinger/status/1270838110625071106">a step in the right direction</a>.</li>
</ul>

<blockquote><p lang="en" dir="ltr">This is almost unbelievable! Nonstop activism + timing = Amazon has finally relented and is making a move in the right direction: implementing a one-year moratorium on the police use of its facial recognition tech, Rekognition! h/t <a href="https://twitter.com/BrendaKLeong?ref_src=twsrc%5Etfw">@BrendaKLeong</a> <a href="https://t.co/W5fWEaHtpY">https://t.co/W5fWEaHtpY</a></p>— Evan Selinger (@EvanSelinger) <a href="https://twitter.com/EvanSelinger/status/1270838110625071106?ref_src=twsrc%5Etfw">June 10, 2020</a></blockquote>


<p><strong>From the Source:</strong></p>

<p>After the announcements from IBM, Microsoft, and Amazon, Microsoft’s president <a href="https://www.cnn.com/2020/06/18/tech/brad-smith-microsoft-facial-recognition/index.html">repeated the call</a> for federal regulation of facial recognition technology:</p>

<blockquote>
  <p>“We need to start teasing this issue apart, to understand it better and move just beyond a binary conversation of: permit it or ban it,” Smith said. “And think about: what is the right way to regulate it?”</p>
</blockquote>

<p><strong>Summary</strong></p>

<ul>
  <li>The enthusiasm for IBM’s, Microsoft’s, and Amazon’s moves on facial recognition have been mixed.</li>
  <li>Adding to the worries are the existence of other companies peddling facial recognition technology, such as Clearview AI.</li>
  <li>While many see these announcements as a small step down a long road, they do see it as a step in the right direction.</li>
</ul>

<h2 id="our-perspective"><strong>Our Perspective</strong></h2>

<p>Amazon and Microsoft have engaged in the same marketing of facial recognition that is being lambasted today. 
While Amazon’s contracts are already public knowledge, Microsoft was recently found to have <a href="https://techcrunch.com/2020/06/17/microsoft-dea-facial-recognition/">pitched its facial recognition technology to the Drug Enforcement Administration</a> (DEA) as far back as 2017. 
The recent announcements from IBM, Microsoft, and Amazon are a promising step forward in the fight against unfettered use of facial recognition technology, particularly in policing. 
There are strong arguments that due to the inherent difficulties in fairly implementing automation technology in law enforcement, <a href="https://www.nytimes.com/2020/06/09/technology/facial-recognition-software.html">police should be banned from using facial recognition altogether</a>. 
In addition, as <a href="https://www.youtube.com/watch?v=jZjmlJPJgug">John Oliver</a> pointed out, development of facial recognition in and of itself has opened a Pandora’s Box that even some in Silicon Valley were too afraid to touch.</p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/jZjmlJPJgug" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<p>In particular, the following immediate issues remain:</p>

<ul>
  <li>Amazon is still engaged with the police in surveillance applications - Ring allegedly <a href="https://www.cnet.com/features/rings-work-with-police-lacks-solid-evidence-of-reducing-crime/">has partnered with over 1000 police departments in the US</a>.</li>
  <li>Even if Microsoft and Amazon decide to go as far as IBM has in the moral sense, the fact remains that companies like Clearview AI and Banjo continue to offer facial recognition services. As long as there are people who want to continue to use facial recognition for any purpose, its development will go on.</li>
  <li>Without substantive federal regulations on such technology, no one company (or three companies) will have much of an impact on the development and use of facial recognition technology and the associated risks.</li>
</ul>

<p>The current spotlight on the existing and potential abuses of face recognition technology is pressuring both industry leaders and governments to re-evaluate and re-imagine the future of face recognition. 
Congress is currently considering a police reform bill that limits face recognition in law enforcement. 
Many see this bill and the recent responses from tech companies as promising starting points. 
However, more pressure is needed to ensure fair and ethical uses of face recognition and other AI technologies with significant social impacts.</p>

<h2 id="conclusion">Conclusion</h2>

<p>The moves by IBM, Microsoft, and Amazon to stop (or pause) development of face recognition technology, especially for law enforcement, at least until adequate federal regulations are in place, are promising starting points to ensure ethical uses of this technology. 
Although studies have revealed flaws in commercial face recognition systems for years, companies are only now taking action as a result of recent protests and the national conversation on racial discrimination and police brutality. 
This also suggests that continuous pressure from consumers, civil liberty groups, and the public at large is needed to ensure progress in the ethical development and regulation of face recognition technology.</p>

    </div></div>]]>
            </description>
            <link>https://www.skynettoday.com/briefs/face-recog-police</link>
            <guid isPermaLink="false">hacker-news-small-sites-23634776</guid>
            <pubDate>Wed, 24 Jun 2020 22:53:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AWS Chalice]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23634533">thread link</a>) | @aratno
<br/>
June 24, 2020 | https://aws.github.io/chalice/ | <a href="https://web.archive.org/web/*/https://aws.github.io/chalice/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
	    <p><img src="https://aws.github.io/chalice/_static/img/coding.png" alt="Coding"></p><div>
                <h2>Focus on writing your application code</h2>
                <p>Focus on writing your application code
		   instead of the resources or services needed to deploy
		   your application.  Chalice automatically determines how to
		   provision the necessary resources for your application.</p>
            </div>
	    <p><img src="https://aws.github.io/chalice/_static/img/programming.png" alt="Coding"></p><div>
                <h2>A familiar decorator based API</h2>
                <p>Chalice's API for writing serverless application uses a familiar
		   decorator-based syntax used in frameworks such as Flask,
		   bottle, and FastAPI.  Skip the learning curve and get up and
		   running quickly.
		   </p>
            </div>
	    <p><img src="https://aws.github.io/chalice/_static/img/maintenance.png" alt="Coding"></p><div>
                <h2>Supports multiple deployment systems</h2>
                <p>Chalice supports multiple tools to deploy your application
		   including AWS CloudFormation, Terraform, and its own built-in
		   deployer based on the AWS SDK for Python.  Use the deployment
		   tools and services you're already familiar with.</p>
            </div>
        </div>
    </div></div>]]>
            </description>
            <link>https://aws.github.io/chalice/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23634533</guid>
            <pubDate>Wed, 24 Jun 2020 22:21:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Experts warn parts of U.S. on verge of being overwhelmed by Covid-19 resurgence]]>
            </title>
            <description>
<![CDATA[
Score 48 | Comments 66 (<a href="https://news.ycombinator.com/item?id=23634517">thread link</a>) | @awnird
<br/>
June 24, 2020 | https://www.cbc.ca/news/world/coronavirus-covid19-world-june24-1.5624885 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/world/coronavirus-covid19-world-june24-1.5624885">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Here's what's happening around the world with COVID-19 on Wednesday.</p><div><p><span><span><span></span><span>Isolating COVID-19 cases and quarantining contacts is necessary in the Americas in order to prevent further lockdowns, says the World Health Organization.<!-- --> <!-- -->2:52</span></span></span></p><p><span><p><strong><em>The latest:</em></strong></p>  <ul>   <li><em><strong>IMF <a href="https://www.cbc.ca/news/business/img-downgrades-outlook-global-economy-1.5625010">sharply downgrades outlook</a> for global economy in face of COVID-19.</strong></em></li>   <li><strong><em>EU travel recommendations may <a href="https://www.cbc.ca/news/world/european-union-travel-americans-russians-coronavirus-1.5624911">impede Americans and Russians</a>.</em></strong></li>   <li><strong><em>Australia scrambles to <a href="https://www.cbc.ca/news/world/australia-scrambles-to-prevent-2nd-covid-19-wave-after-1st-death-in-a-month-1.5624963">prevent 2nd&nbsp;wave</a> after 1st death in a month.</em></strong></li>   <li><strong><em>Beware 2nd wave of coronavirus, <a href="https://www.cbc.ca/news/world/warning-second-wave-coronavirus-britain-1.5625074">medics warn Britain</a>.</em></strong></li>   <li><strong><em>Russia holds coronavirus-delayed <a href="https://www.cbc.ca/news/world/russia-victory-day-parade-1.5624914">Victory Day parade</a>.</em></strong></li>   <li><em><strong>Some countries <a href="https://www.cbc.ca/news/health/2-metres-coronavirus-covid-distancing-1.5624439">reconsider 2-metre rule</a> for physical distancing, but not Canada.</strong></em></li>   <li><em><strong>How Canada got into a pandemic economy — <a href="https://www.cbc.ca/news/politics/pandemic-covid-coronavirus-economy-debt-canada-1.5622374">and how it might get out</a>.</strong></em></li>   <li><em><strong>INTERACTIVE | <a href="https://newsinteractives.cbc.ca/coronavirustracker/">Tracking the coronavirus</a> in Canada and around the world.</strong></em></li>  </ul>  <p>A coronavirus resurgence is wiping out two months of progress <strong>in the U.S.</strong> and sending infections to dire new levels across the country's South and West, with hospital administrators and health experts warning Wednesday that politicians and a tired-of-being-cooped-up public are letting a disaster unfold.</p>  <p>The U.S. recorded a one-day total of 34,700 new COVID-19 cases, just short of the nation's late-April peak of 36,400, according to the count kept by Johns Hopkins University.</p>  <p>While new cases have been declining steadily in early U.S.&nbsp;hotspots such as New York and New Jersey, several other states set single-day case records this week, including Arizona, California, Mississippi, Nevada,&nbsp;Texas and Oklahoma. Some of them also broke hospitalization records, as did North Carolina and South Carolina.</p>  <p>"People got complacent," said Dr. Marc Boom, CEO of the Houston Methodist hospital system. "And it's coming back and biting us, quite frankly."</p>  <p><em><strong>WATCH |&nbsp;Long lines at COVID-19 test sites in U.S.:</strong></em></p>  <p><span><span><span></span><span>Traffic is seen at a standstill as drivers wait at drive-thru COVID-19 test sites in the U.S.<!-- --> <!-- -->1:11</span></span></span></p>  <p>The stock market slid sharply Wednesday as the virus's resurgence clouded investors' hopes for a relatively quick economic turnaround. The virus&nbsp;has been blamed for more than 120,000 deaths in the U.S. — the highest toll in the world — and more than 2.3 million confirmed infections there.</p>  <p>California, the most populous state, reported over 7,100 new cases, a record.&nbsp;Florida's single-day count of new confirmed cases surged Wednesday to 5,500&nbsp;—&nbsp;a 25 per cent jump from the record set last week.</p>  <p>In Texas, which began lifting its shutdowns on May 1, hospitalizations have doubled and new cases have tripled in two weeks. Gov. Greg Abbott told KFDA-TV that the state is facing a "massive outbreak" and might need new local restrictions to preserve hospital space.</p>  <p>The Houston area's intensive care units are nearly full, and two public hospitals are running at capacity, Mayor Sylvester Turner said. Houston Methodist's Boom said Texans need to "behave perfectly and work together perfectly" to slow the infection rate.</p>  <p>"When I look at a restaurant or a business where people ... are not following the guidelines, where people are just throwing caution to the wind, it makes me angry."</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5625848.1593031612!/cpImage/httpImage/image.jpg_gen/derivatives/original_300/virus-outbreak-texas.jpg 300w,https://i.cbc.ca/1.5625848.1593031612!/cpImage/httpImage/image.jpg_gen/derivatives/original_460/virus-outbreak-texas.jpg 460w,https://i.cbc.ca/1.5625848.1593031612!/cpImage/httpImage/image.jpg_gen/derivatives/original_620/virus-outbreak-texas.jpg 620w,https://i.cbc.ca/1.5625848.1593031612!/cpImage/httpImage/image.jpg_gen/derivatives/original_780/virus-outbreak-texas.jpg 780w,https://i.cbc.ca/1.5625848.1593031612!/cpImage/httpImage/image.jpg_gen/derivatives/original_1180/virus-outbreak-texas.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5625848.1593031612!/cpImage/httpImage/image.jpg_gen/derivatives/original_780/virus-outbreak-texas.jpg"></p></div><figcaption>A health-care worker takes down a patient's information at a COVID-19 testing site in Houston on Wednesday.<!-- --> <!-- -->(David J. Phillip/The Associated Press)</figcaption></figure></span></p>  <p>Just 17 percent of intensive-care beds were available Wednesday in Alabama — including just one in Montgomery — though hospitals can add more, said Dr. Don Williamson, head of the Alabama Hospital Association.</p>  <p>"There is nothing that I'm seeing that makes me think we are getting ahead of this," he said.</p>  <p>In Arizona, emergency rooms are seeing about 1,200 suspected COVID-19 patients a day, compared with around 500 a month ago. If the trends continue, hospitals will probably exceed capacity within the next several weeks, said Dr. Joseph Gerald, a University of Arizona public health policy professor.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5625503.1593036438!/cpImage/httpImage/image.jpg_gen/derivatives/original_300/virus-outbreak-florida.jpg 300w,https://i.cbc.ca/1.5625503.1593036438!/cpImage/httpImage/image.jpg_gen/derivatives/original_460/virus-outbreak-florida.jpg 460w,https://i.cbc.ca/1.5625503.1593036438!/cpImage/httpImage/image.jpg_gen/derivatives/original_620/virus-outbreak-florida.jpg 620w,https://i.cbc.ca/1.5625503.1593036438!/cpImage/httpImage/image.jpg_gen/derivatives/original_780/virus-outbreak-florida.jpg 780w,https://i.cbc.ca/1.5625503.1593036438!/cpImage/httpImage/image.jpg_gen/derivatives/original_1180/virus-outbreak-florida.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5625503.1593036438!/cpImage/httpImage/image.jpg_gen/derivatives/original_780/virus-outbreak-florida.jpg"></p></div><figcaption>Volunteers prepare packages of personal protective equipment and sanitizers to be donated in Orlando, Fla., on Wednesday.<!-- --> <!-- -->(John Raoux/The Associated Press)</figcaption></figure></span></p>  <p>"We are in deep trouble," said Gerald, urging the state to impose new restrictions on businesses, which Gov. Doug Ducey has refused to do.</p>  <p>Infectious-disease expert Dr. Peter Hotez said he worries that the states will squander what time they have to head off a much larger crisis.</p>  <ul>   <li><strong><a href="http://cbc.ca/1.5626006">Democrats to hold mostly virtual presidential nomination convention due to pandemic</a></strong></li>  </ul>  <p>"We're still talking about subtlety, still arguing whether or not we should wear masks, and still not understanding that a vaccine is not going to rescue us," said Hotez, of the Baylor College of Medicine in Texas.</p>  <p>Texas Gov. Greg Abbott initially barred local officials from fining or penalizing anyone for not wearing a mask as the state reopened. After cases began spiking, he said last week that cities and counties could allow businesses to require masks. Both Abbott and Ducey are Republicans.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5625948.1593034776!/cpImage/httpImage/image.jpg_gen/derivatives/original_300/virus-outbreak-texas-daily-life.jpg 300w,https://i.cbc.ca/1.5625948.1593034776!/cpImage/httpImage/image.jpg_gen/derivatives/original_460/virus-outbreak-texas-daily-life.jpg 460w,https://i.cbc.ca/1.5625948.1593034776!/cpImage/httpImage/image.jpg_gen/derivatives/original_620/virus-outbreak-texas-daily-life.jpg 620w,https://i.cbc.ca/1.5625948.1593034776!/cpImage/httpImage/image.jpg_gen/derivatives/original_780/virus-outbreak-texas-daily-life.jpg 780w,https://i.cbc.ca/1.5625948.1593034776!/cpImage/httpImage/image.jpg_gen/derivatives/original_1180/virus-outbreak-texas-daily-life.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5625948.1593034776!/cpImage/httpImage/image.jpg_gen/derivatives/original_780/virus-outbreak-texas-daily-life.jpg"></p></div><figcaption>A sign requiring face coverings at a business is seen in San Antonio, Texas, on Wednesday.<!-- --> <!-- -->(Eric Gay/The Associated Press)</figcaption></figure></span></p>  <p>North Carolina Gov. Roy Cooper, a Democrat, ordered people to wear masks in public as the daily count of hospitalizations and new cases hovered near records. In Florida, several counties and cities have recently started requiring masks in public places and cracking down on businesses that don't enforce social distancing rules.</p>  <p>In a sign of the shift in the outbreak, New York, Connecticut and New Jersey announced they will require visitors from states with high coronavirus infection rates to quarantine themselves for 14 days. That is a turnaround from March, when Florida Gov. Ron DeSantis issued such an order for visitors from the New York City area, where cases were surging at the time.</p>  <p>Cases are also surging in some other parts of the world. <strong>India </strong>reported a record daily increase of nearly 16,000 new cases, with an outbreak in the capital city of New Delhi becoming a rising concern. <strong>Mexico</strong>, where testing rates have been low, also set a record with more than 6,200 new cases.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5625473.1593025804!/cpImage/httpImage/image.jpg_gen/derivatives/original_300/aptopix-virus-outbreak-india.jpg 300w,https://i.cbc.ca/1.5625473.1593025804!/cpImage/httpImage/image.jpg_gen/derivatives/original_460/aptopix-virus-outbreak-india.jpg 460w,https://i.cbc.ca/1.5625473.1593025804!/cpImage/httpImage/image.jpg_gen/derivatives/original_620/aptopix-virus-outbreak-india.jpg 620w,https://i.cbc.ca/1.5625473.1593025804!/cpImage/httpImage/image.jpg_gen/derivatives/original_780/aptopix-virus-outbreak-india.jpg 780w,https://i.cbc.ca/1.5625473.1593025804!/cpImage/httpImage/image.jpg_gen/derivatives/original_1180/aptopix-virus-outbreak-india.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5625473.1593025804!/cpImage/httpImage/image.jpg_gen/derivatives/original_780/aptopix-virus-outbreak-india.jpg"></p></div><figcaption>A health worker conducts a COVID-19 test on a patient as others wait in New Delhi on Wednesday.<!-- --> <!-- -->(Manish Swarup/The Associated Press)</figcaption></figure></span></p>  <p>But <strong>China </strong>appears to have tamed a new outbreak in Beijing, once again demonstrating its ability to quickly mobilize its vast resources by testing nearly 2.5 million people in 11 days. China on Wednesday reported 12 cases nationwide, down from 22 the day before.</p>  <p>In Europe, countries are both easing and increasing restrictions as the outbreaks evolve. <strong>Slovenia </strong>reintroduced mandatory use of face masks in public transportation and other enclosed public spaces after cases spiked in recent days, while <strong>Belgium </strong>said theatres and swimming pools could reopen next month. Infections there have nosedived over the past two months.</p>  <p><em><strong>WATCH |&nbsp;Belgian entrepreneur gives coronavirus masks the human touch:</strong></em></p>  <p><span><span><span></span><span>Photo booth operator makes custom masks to show the lower half of the wearer's face.<!-- --> <!-- -->1:59</span></span></span></p>  <p><strong>In Africa</strong>, the head of the Ethiopia-based Africa&nbsp;Centers for Disease Control and Prevention,&nbsp;John Nkengasong, said the outbreak is "picking up speed very quickly," with a steep increase in cases and deaths as more countries loosen lockdowns. Africa has seen nearly 325,000 cases and over 8,600 deaths.</p>  <p>Worldwide, more than 9.3&nbsp;million people have been confirmed infected, and more than 479,000 have died, <a href="https://coronavirus.jhu.edu/map.html">according to the Johns Hopkins&nbsp;count</a>.</p>  <hr>  <h2>What's happening with COVID-19 in Canada</h2>  <p>As of 7&nbsp;p.m. ET on Wednesday, Canada had 102,241 confirmed and presumptive coronavirus cases. Provinces and territories listed 65,091 of the cases as recovered or resolved. A CBC News tally of deaths based on provincial reports, regional health information and CBC's reporting stood at 8,530.</p>  <p>In Ontario, patios and hair salons were back in business in <a href="https://www.cbc.ca/news/canada/toronto/covid-coronavirus-ontario-toronto-peel-1.5624924" target="_blank">Toronto and Peel Region</a> on Wednesday.</p>  <p>Premier Doug&nbsp;Ford also announced&nbsp;a plan to&nbsp;<a href="https://www.cbc.ca/news/canada/windsor/ontario-government-announcement-plan-june24-windsor-essex-1.5625150" target="_blank">reopen&nbsp;parts of Windsor-Essex,</a>&nbsp;which until now has been the&nbsp;only region not cleared to move to the next phase of reopening, due to stubbornly high COVID-19 case numbers among migrant workers on farms in the region.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5625871.1593083182!/cumulusImage/httpImage/image.jpg_gen/derivatives/original_300/covid-coronavirus-ottawa-mask.jpg 300w,https://i.cbc.ca/1.5625871.1593083182!/cumulusImage/httpImage/image.jpg_gen/derivatives/original_460/covid-coronavirus-ottawa-mask.jpg 460w,https://i.cbc.ca/1.5625871.1593083182!/cumulusImage/httpImage/image.jpg_gen/derivatives/original_620/covid-coronavirus-ottawa-mask.jpg 620w,https://i.cbc.ca/1.5625871.1593083182!/cumulusImage/httpImage/image.jpg_gen/derivatives/original_780/covid-coronavirus-ottawa-mask.jpg 780w,https://i.cbc.ca/1.5625871.1593083182!/cumulusImage/httpImage/image.jpg_gen/derivatives/original_1180/covid-coronavirus-ottawa-mask.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5625871.1593083182!/cumulusImage/httpImage/image.jpg_gen/derivatives/original_780/covid-coronavirus-ottawa-mask.jpg"></p></div><figcaption>People are seen wearing protective face coverings in Ottawa on Wednesday.<!-- --> <!-- -->(Andrew Lee/CBC)</figcaption></figure></span></p>  <p>British Columbia is <a href="https://www.cbc.ca/news/canada/british-columbia/covid-19-bc-phase-three-john-horgan-1.5625598">further easing restrictions</a>, meaning residents will be allowed to travel within the province as hotels, motels, resorts, spas&nbsp;and RV parks look to reopen.</p>  <p>Premier John Horgan announced Wednesday that B.C.&nbsp;will gradually be&nbsp;moving into Phase 3 of its restart plan, after the province managed&nbsp;to increase activity without seeing a spike in the number of COVID-19 cases in recent weeks.</p>  <p>Phase 3 of B.C.'s restart plan also means residents can travel within the province&nbsp;"safely and respectfully."</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5626141.1593040455!/cumulusImage/httpImage/image.jpg_gen/derivatives/original_300/senior-covid-survivor-walking-laps.jpg 300w,https://i.cbc.ca/1.5626141.1593040455!/cumulusImage/httpImage/image.jpg_gen/derivatives/original_460/senior-covid-survivor-walking-laps.jpg 460w,https://i.cbc.ca/1.5626141.1593040455!/cumulusImage/httpImage/image.jpg_gen/derivatives/original_620/senior-covid-survivor-walking-laps.jpg 620w,https://i.cbc.ca/1.5626141.1593040455!/cumulusImage/httpImage/image.jpg_gen/derivatives/original_780/senior-covid-survivor-walking-laps.jpg 780w,https://i.cbc.ca/1.5626141.1593040455!/cumulusImage/httpImage/image.jpg_gen/derivatives/original_1180/senior-covid-survivor-walking-laps.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5626141.1593040455!/cumulusImage/httpImage/image.jpg_gen/derivatives/original_780/senior-covid-survivor-walking-laps.jpg"></p></div><figcaption>People speak through a glass barrier at the Lynn Valley Care Centre in North Vancouver on Tuesday.<!-- --> <!-- -->(Ben Nelms/CBC)</figcaption></figure></span></p>  <p>Canada's Atlantic provinces announced Wednesday they will move forward with <a href="http://www.cbc.ca/news/canada/prince-edward-island/pei-atlantic-bubble-covid19-1.5625133">a so-called travel bubble</a> as of July 3, allowing travellers in Prince Edward Island, New Brunswick, Nova Scotia and Newfoundland and Labrador to move between provinces without self-isolating.</p>  <p>Visitors from provinces and territories outside the region will still be required to self-isolate for 14 days and adhere to the local entry requirements in each of the four jurisdictions. However, once the self-isolation period has passed, these visitors will also be allowed to travel within the Atlantic region.</p>  <ul>   <li><strong><a href="https://www.cbc.ca/news/politics/cerb-recipients-payments-ei-1.5623923">Why some CERB recipients are getting smaller payments this month</a></strong></li>   <li><strong><a href="http://cbc.ca/1.5625811">Yukon to open borders to B.C., N.W.T., and Nunavut residents July 1</a></strong></li>   <li><strong><a href="https://www.cbc.ca/news/canada/british-columbia/bc-covid-update-june-23-1.5624328">B.C. runs risk of rapid rebound in COVID-19 cases if contacts exceed 65% of normal, health officials say</a></strong></li>   <li><strong><a href="https://www.cbc.ca/news/canada/saskatoon/saskatchewan-interprovincial-travel-covid-19-1.5625045">Sask. working on 'more permissive approach' to interprovincial travel</a></strong></li>   <li><a href="https://www.cbc.ca/news/canada/edmonton/alberta-invests-10m-in-serology-testing-to-help-track-spread-of-covid-19-1.5623785"><strong>Alberta invests $10M in serology testing to help track spread of COVID-19</strong></a></li>   <li><strong><a href="https://www.cbc.ca/news/canada/manitoba/intellectual-disabilities-visits-manitoba-covid19-1.5624387">'Pure joy' as Manitoba adults with intellectual disabilities allowed to have loved ones over for visits</a></strong></li>   <li><strong><a href="https://www.cbc.ca/news/canada/north/nwt-extends-state-of-emergency-1.5624556">N.W.T. extends state of emergency, public health emergency for 7th time</a></strong></li>  </ul></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/world/coronavirus-covid19-world-june24-1.5624885</link>
            <guid isPermaLink="false">hacker-news-small-sites-23634517</guid>
            <pubDate>Wed, 24 Jun 2020 22:19:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Driving Coast to Coast (To Coast): How to Take the Road Trip of a Lifetime]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23634127">thread link</a>) | @joebalcom
<br/>
June 24, 2020 | https://joebalcom.blog/2020/06/24/driving/ | <a href="https://web.archive.org/web/*/https://joebalcom.blog/2020/06/24/driving/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1248">
		<!-- .entry-header -->

	
	<div>
		
<figure><img data-attachment-id="1250" data-permalink="https://joebalcom.blog/2020/06/24/driving/image-6/" data-orig-file="https://i0.wp.com/joebalcom.blog/wp-content/uploads/2020/06/image-6.png?fit=626%2C340&amp;ssl=1" data-orig-size="626,340" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-6" data-image-description="" data-medium-file="https://i0.wp.com/joebalcom.blog/wp-content/uploads/2020/06/image-6.png?fit=300%2C163&amp;ssl=1" data-large-file="https://i0.wp.com/joebalcom.blog/wp-content/uploads/2020/06/image-6.png?fit=525%2C285&amp;ssl=1" src="https://i0.wp.com/joebalcom.blog/wp-content/uploads/2020/06/image-6.png?resize=525%2C285&amp;ssl=1" alt="Driving cross-country" width="525" height="285" srcset="https://i0.wp.com/joebalcom.blog/wp-content/uploads/2020/06/image-6.png?w=626&amp;ssl=1 626w, https://i0.wp.com/joebalcom.blog/wp-content/uploads/2020/06/image-6.png?resize=300%2C163&amp;ssl=1 300w, https://i0.wp.com/joebalcom.blog/wp-content/uploads/2020/06/image-6.png?resize=350%2C190&amp;ssl=1 350w" sizes="(max-width: 525px) 100vw, 525px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/joebalcom.blog/wp-content/uploads/2020/06/image-6.png?w=626&amp;ssl=1 626w, https://i0.wp.com/joebalcom.blog/wp-content/uploads/2020/06/image-6.png?resize=300%2C163&amp;ssl=1 300w, https://i0.wp.com/joebalcom.blog/wp-content/uploads/2020/06/image-6.png?resize=350%2C190&amp;ssl=1 350w" data-lazy-src="https://i0.wp.com/joebalcom.blog/wp-content/uploads/2020/06/image-6.png?resize=525%2C285&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p><em>A word of caution: This post is being written during the COVID-19 pandemic that has swept across the United States and the rest of the world. Before taking any action on the information provided in this post, please be prepared to take the proper precautions: wear a mask, wash your hands, have plenty of hand sanitizer, distance yourself at least six feet away from others, and quarantine yourself for at least 14 days at the conclusion of any period of extended or out-of-state exposure. You might not feel that this applies to you, but I assure you, it does. The elderly and the more vulnerable people in your life are depending on you be responsible and take the virus and its effects seriously, regardless of what politicians on TV might be telling you. Have fun and live life but be responsible.</em></p>



<h4><strong>What’s in a Road Trip?</strong></h4>



<ul><li>17 sun-drenched days, 17 starry-skied nights (with a few gnarly storms here and there)</li><li>8,462 total miles driven (sorry, not sorry, Enterprise!)</li><li>120+ hours of fun, laughs, audiobooks, music, and podcasts in the car (estimated)</li><li>22 gas pumps (and lots of hand sanitizer)</li><li>16 States (PA, OH, IN, IL, IA, NE, CO, UT, AZ, NV, CA, NM, TX, OK, MO, WV)</li><li>11 State Capitals (Des Moines, Lincoln, Denver, Salt Lake City, Phoenix, Santa Fe, Oklahoma City, Springfield, Indianapolis, Columbus, Harrisburg)</li><li>Plains, mountains, forests, deserts, oceans, lots of cows, horses, elk, coyotes, roadrunners and tumbleweeds</li><li>Temperatures ranging between 36° in the Rocky Mountains and 108° in southern Arizona</li><li>Elevations ranging between 0’ at Redondo Beach, CA and 13,478’ in Rocky Mountain National Park</li><li>3+ large (1000+ acre) forest fires</li><li>10,000+ dead bugs on the front of the car</li><li>1 pull-over by Border Patrol in Southern New Mexico</li><li>Coral pink sand, red dirt, and inches of white salt in our shoes and tires (all from Utah)</li><li>Countless unexpected diversions that will make any long road trip truly unforgettable</li></ul>



<p>And it’s crazy to think that we haven’t even scratched the surface of America…</p>



<p>Over the past week I’ve recapped the 17 days of my road trip that that took me and my girlfriend from the Pocono Mountains in northeastern Pennsylvania through the arid northern Arizona desert, to the Pacific Ocean and back. If you want to check out some pictures or need a little motivation to get out and take the trip of your lifetime, I recommend checking out <a href="https://joebalcom.blog/2020/06/15/road-trip/">Part I</a> and <a href="https://joebalcom.blog/2020/06/23/road-trip-2/">Part II</a>.</p>



<p>My goal with this post is not just to show and tell my experiences, but primarily to set proper expectations and to show you exactly how to get up off the couch, out of your cubicle, out of bed, away from the TV, and into a car (fuel efficient if possible) that will take you on a trip that you will never forget.</p>



<p>The following is based solely on my own experiences, so I cannot promise that it will optimize for your specific needs. What it will do is give you a framework from which to build your own plan.</p>



<h4><strong>Layers of the Onion</strong></h4>



<p>Planning an extended road trip is a lot like peeling the layers of an onion. The conventional road trip, during normal times, has layers and layers of decisions that could effect each subsequent layer of decisions:</p>



<ul><li>Choosing between an RV, your own car, and a rental.</li><li>Selecting your destination and which cities and towns to stop in.</li><li>Navigation—which routes will get you to where you want to go within the parameters of your goals.</li><li>Deciding how much time you have and how much you want to cram into the trip.</li><li>Accounting for the difference between how much money you are willing/able to spend, and how much it will actually cost.</li><li>Identifying all expenses and hidden costs that will make up your total expenditure: gas, food, rentals, parks passes, insurance, lodging, etc.</li><li>How to stay sane in the car for hours on end.</li><li>Technology—how to communicate, or even navigate in areas with absolutely no cell phone service.</li></ul>



<p>These are just some of the complexities you would expect in normal times. But these are no normal times. COVID-19 has added new layers of complexity to the road trip, while simultaneously removing others. Different states have different restrictions and different attitudes. National parks are either closed or limited. Many businesses are closed or operating within tight constraints. But places to stay are widely available at cheaper prices than normal. Gas prices are at 10-20 year lows. The roads are emptier than ever. And the air is cleaner than ever. What better time to take the trip of a lifetime?</p>



<p>If you have never done an extended road trip, all of this might seem intimidating and overwhelming to the point where it might not even feel worth doing such a trip. But I have good news: you don’t have to reinvent the wheel. Just use my experience as a guide and shape it to fit your own aspirations for the perfect road trip.</p>



<h4><strong>Part 1: Decide and Commit</strong></h4>



<p>Like building a business or any large undertaking, dreams of a cross-country road trip can vanish before they ever materialize. And almost always, our indecision and inaction is the culprit. There are a million and one reasons to delay or put it off. Don’t. Decide what you want and make an irreversible decision, <a href="https://joebalcom.blog/2020/05/02/forcing-function/">a forcing function, to keep you from talking yourself out of it</a>.</p>



<p>Like many of my adventures, I didn’t plan this road trip with a lot of lead time (started planning 5/25, left on 6/5). Sure, anticipation is half the fun, but it is also the source of all second-guessing. To eliminate that possibility, my girlfriend and I set a goal to drive from the Pocono Mountains in Pennsylvania to Page, AZ. I made a simple spreadsheet with the dates that we felt comfortable with (for quarantine purposes and other obligations that would follow) and made the most sense. More on this in the next step.</p>



<p>Page, AZ is a town that we have previously visited and enjoyed it enough that we decided to make it a primary destination. It served as a strategic base, as it is accessible to many of the Southwest’s best national parks and destinations. So I booked a place in Page for nine days. You will soon see how quickly plans change.</p>



<h4><strong>Part 2: Prioritize Structure So You’re Free to Play</strong></h4>



<p>Do not over plan. It will take the fun, the serendipity, and the wonder out of the whole experience. What you want to do is build constraints or safety nets that will allow you the freedom to do what you want while ensuring that you don’t overextend yourself. As you can see in the tables below, due to unforeseen circumstances, our original plan and our actual outcome differ drastically.</p>



<p>While in Page, we decided that we might as well go all the way to the coast. What is a cross country road trip without seeing the Pacific Ocean?? That forced us to sacrifice the last two nights in Page (lodging costs in Part 5), and book places in new cities. Personal experience had taught me not to book everything from the original plan, as I knew things were bound to change.</p>



<p>Imagine if we planned everything down to the smallest detail and booked every hotel! It would be a logistical mess, or at the very least, a duller road trip.</p>



<figure><img data-attachment-id="1251" data-permalink="https://joebalcom.blog/2020/06/24/driving/image-7/" data-orig-file="https://i2.wp.com/joebalcom.blog/wp-content/uploads/2020/06/image-7.png?fit=624%2C253&amp;ssl=1" data-orig-size="624,253" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-7" data-image-description="" data-medium-file="https://i2.wp.com/joebalcom.blog/wp-content/uploads/2020/06/image-7.png?fit=300%2C122&amp;ssl=1" data-large-file="https://i2.wp.com/joebalcom.blog/wp-content/uploads/2020/06/image-7.png?fit=525%2C213&amp;ssl=1" src="https://i2.wp.com/joebalcom.blog/wp-content/uploads/2020/06/image-7.png?resize=525%2C213&amp;ssl=1" alt="Plan for driving cross-country" width="525" height="213" srcset="https://i2.wp.com/joebalcom.blog/wp-content/uploads/2020/06/image-7.png?w=624&amp;ssl=1 624w, https://i2.wp.com/joebalcom.blog/wp-content/uploads/2020/06/image-7.png?resize=300%2C122&amp;ssl=1 300w, https://i2.wp.com/joebalcom.blog/wp-content/uploads/2020/06/image-7.png?resize=350%2C142&amp;ssl=1 350w" sizes="(max-width: 706px) 89vw, (max-width: 767px) 82vw, 740px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/joebalcom.blog/wp-content/uploads/2020/06/image-7.png?w=624&amp;ssl=1 624w, https://i2.wp.com/joebalcom.blog/wp-content/uploads/2020/06/image-7.png?resize=300%2C122&amp;ssl=1 300w, https://i2.wp.com/joebalcom.blog/wp-content/uploads/2020/06/image-7.png?resize=350%2C142&amp;ssl=1 350w" data-lazy-src="https://i2.wp.com/joebalcom.blog/wp-content/uploads/2020/06/image-7.png?resize=525%2C213&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>Create a structure that will give you an idea of what you have to work with. Timeframe, distance, destinations. Knowing these will give you a sufficient framework and the freedom to adjust on the fly.</p>



<h4><strong>Part 3: Preparations</strong></h4>



<p><strong>(Note: All costs are listed in Part 5)</strong></p>



<ul type="1"><li>Rent a car. If you don’t have an RV or don’t want to drive your own car, rent a fuel-efficient car from Enterprise (I have no financial stake in that recommendation!). The reason I recommend Enterprise is that they do not charge petty fees for out of state driving or for mileage like most of the other “cheaper” rental companies. You can drive 10 miles, or 10,000 miles and you will still be charged the same. Go to a small town rental location, as they will probably have cheaper options, and more availability.</li><li>Be mindful of your thirst for adventure. You don’t want to drive off-road on rocks and sand, or up steep mountains in a Smart Car. But you also don’t want to break the bank with the rental or at the gas pump. Find the right balance for your needs.</li><li>Insurance: this decision comes down to your toleration of risk. You typically don’t have to take the rental company’s insurance if you are covered under your own plan. But some form of insurance is required.</li></ul>



<ul><li>Pack only what you <strong>need</strong>. It is tempting to take everything you own for a three-week trip, but you will feel much freer by travelling lighter. Odds are you will only use half of what you bring anyway. Like how a messy desk creates feelings of anxiety and disorganization at work, a messy car will create the same for you on the road.</li><li>Unfortunately for us, we were already coming from a rental property in the Poconos, so in addition to our clothes and food, I had my kettlebell and pullup bar and other random bags taking up space. Not ideal for being stopped by border patrol, but we made it work.</li></ul>



<ul><li>Searching for towns/lodging. This is totally subjective, as people range from minimalist campers to those who need every comfort and accommodation. We mainly kept it to Airbnb and simple hotel searches. Prices were cheaper than normal, and hotels were cheaper than Airbnb on average. Other than for Page, we didn’t book anything further out than three days. In busier times, that might have to change. But we valued flexibility over all else.</li><li>Location depended largely on our interests, and our stomach for longer drives. A rule of thumb for a cross country trip would be to take your total distance and divide it by how many days you plan on driving. From that you will have an average daily distance, which will give you an idea of where to stay each night. For us, we did a 24-hour drive on the first night (2pm in PA to 12 noon the next day in Boulder), which allowed for more time in the western part of the country. On the way back, I simply divided 2800 miles by 4 days, which gave me 700 miles each day. We then chose our return stops based on that. We had a consistent average of 65-70mph on the …</li></ul></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://joebalcom.blog/2020/06/24/driving/">https://joebalcom.blog/2020/06/24/driving/</a></em></p>]]>
            </description>
            <link>https://joebalcom.blog/2020/06/24/driving/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23634127</guid>
            <pubDate>Wed, 24 Jun 2020 21:33:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understand WebAssembly in 5 Minutes]]>
            </title>
            <description>
<![CDATA[
Score 35 | Comments 11 (<a href="https://news.ycombinator.com/item?id=23634033">thread link</a>) | @jesuisundev
<br/>
June 24, 2020 | https://www.jesuisundev.com/en/understand-webassembly-in-5-minutes/ | <a href="https://web.archive.org/web/*/https://www.jesuisundev.com/en/understand-webassembly-in-5-minutes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

			
<!-- Horizontal Top Article -->
<p>WebAssembly joined HTML, CSS and Javascript as a web standard on December 5, 2019. This will be useful for many things, and in terms of performance, it’s something never seen before in a browser. If you’ve got five minutes, I need to explain the little revolution that’s going on.</p>



<h3>Once upon a time</h3>



<p>In 1995, Javascript was created <a rel="noreferrer noopener" href="https://thenewstack.io/brendan-eich-on-creating-javascript-in-10-days-and-what-hed-do-differently-today/" target="_blank">within 10 days</a> by <a rel="noreferrer noopener" href="https://twitter.com/BrendanEich" target="_blank">Brendan Eich</a>. And at that time, Javascript was not designed to be fast. <strong>It’s basically for form validation and it’s slow like crazy.</strong> As time went by it got better.</p>



<p>In 2008, Google came out of nowhere and put on the table its new browser: Google Chrome. Inside Chrome was a Javascript engine called V8. <strong>And the revolution of V8 was the Just in Time (JIT) compilation of Javascript.</strong> This change from interpreted code to  JIT compilation monstrously accelerated the performance of Javascript, and thus of browsers in general. This speed was going to allow the birth of technology like NodeJS or Electron and the explosion of popularity of Javascript.</p>



<figure><img src="https://i.imgur.com/YHJMavH.jpg" data-src="https://i.imgur.com/YHJMavH.jpg" alt="webassembly"></figure>



<p>In 2015, WebAssembly is announced for the first time with a <a href="https://www.eteknix.com/gaming-in-your-browser-is-about-to-get-interesting-with-webassembly/" target="_blank" rel="noreferrer noopener">small demo of a game</a> running under Unity. The game runs directly in the browser!</p>



<p>In 2019, the W3C made WebAssembly a new web standard. Just as the V8 engine was in its day, <strong>WebAssembly is shaping up to be the new performance revolution</strong>. So WebAssembly is already here, and it’s off to a flying start.</p>



<h3>What is WebAssembly?</h3>



<p>WebAssembly, abbreviated to wasm, is a way to use non-Javascript code and run it in your browser. This code can be C, C++, Rust and many others. <strong>It will be compile and run in your browser at near native speed on your CPU.</strong> This code is in the form of a binary file that you can use directly from Javascript as a module.</p>



<p><strong>WebAssembly is not there to replace Javascript</strong>. On the contrary, these two technologies are made to work together. By using the <a rel="noreferrer noopener" href="https://developer.mozilla.org/en-US/docs/WebAssembly/Using_the_JavaScript_API" target="_blank">Javascript API</a> you can load WebAssembly modules into your page. This means that you can take advantage of the performance of compiled code via WebAssembly with the flexibility of Javascript.</p>



<div><figure><img src="https://i.imgur.com/gbBMTTf.jpg" data-src="https://i.imgur.com/gbBMTTf.jpg" alt="internet"></figure></div>



<p>The name WebAssembly is a bit misleading. <strong>WebAssembly does indeed work for the Web, but it is not limited to it!</strong> The team that made WebAssembly has gone to a lot of trouble to make it generic so that it can be used everywhere. We’re starting to see <a href="https://github.com/wasmerio/wasmer" target="_blank" rel="noreferrer noopener">examples of this</a>.</p>



<p>Also, there’s a misconception that comes up all the time. <strong>WebAssembly is not a programming language.</strong> WebAssembly is an intermediate format, a <a href="https://en.wikipedia.org/wiki/Bytecode" target="_blank" rel="noreferrer noopener">bytecode</a>, which acts as a compilation target for other languages. Okay, it’s not clear, let’s make some drawings.</p>



<h3>How does it work?</h3>



<div><figure><img src="https://i.imgur.com/EHwFHv0.jpg" data-src="https://i.imgur.com/EHwFHv0.jpg" alt="webassembly"></figure></div>



<p>Did you see that? Another work of art. Do you believe me if I tell you I use Photoshop? Anyway !</p>



<ul><li><strong>Step 1</strong> : It’s you and your developer skills. <strong>You produce source code in C, C++</strong> (you can use others languages). This code is supposed to fix a problem or make a process too intensive for Javascript in the browser.</li></ul>



<ul><li><strong>Step 2 </strong>: you will use <a rel="noreferrer noopener" href="https://emscripten.org/index.html" target="_blank">Emscripten</a> to do the translation. <strong>Emscripten is a tool chain, built with <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/LLVM" target="_blank">LLVM</a>, that will compile your source code into WebAssembly</strong>. You can install it and compile whatever you want <a rel="noreferrer noopener" href="https://webassembly.org/getting-started/developers-guide/" target="_blank">in a few quick steps</a>, we’ll look at it later. At the end of this step, you will have a WASM file.</li></ul>



<ul><li><strong>Step 3</strong> : You will use the WASM file on your web page. <strong>If you come from the future, you can load this file like any ES6 module.</strong> Right now, the usage is slightly more complex, but nothing fancy.</li></ul>



<p>OK, let’s get our hands dirty.</p>



<h3>Show me the code</h3>



<p>First of all, we need a small piece of C++ code to compile. Where some people will offer you the whole <a href="https://d07riv.github.io/diabloweb/" target="_blank" rel="noreferrer noopener">Diablo 1  game in the browser</a> as an example, <strong>I’ll keep it simple with a function that adds two digits</strong>. We’re not going to prove the speed of C++ with that, it’s for the example.</p>



<pre data-enlighter-language="cpp" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">int add(int firstNumber, int secondNumber) {
  return firstNumber + secondNumber;
}</pre>



<p>Then go to the Linux distribution of your choice. We will start by downloading and installing emscripten.</p>



<pre data-enlighter-language="generic" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group=""># installing dependencies (yes, you can use newer version of python)
sudo apt-get install python2.7 git

# gettin emscripten via a git clone.
git clone https://github.com/emscripten-core/emsdk.git

# downloading, installing and activating the sdk
cd emsdk
./emsdk install latest
./emsdk activate latestl
source ./emsdk_env.sh

# make sure the installation worked
emcc --version

# compiling the c++ file to a webassembly template
emcc helloWebassembly.cpp -s WASM=1 -o helloWebassembly.html

# we serve the HTML and look at the result
emrun helloWebassembly.html</pre>



<p>That was the hackerman way of doing the wasm. There’s a simpler way. </p>



<p>You can go to <a rel="noreferrer noopener" href="https://mbebenita.github.io/WasmExplorer/" target="_blank">this site</a> and put your C++ code on the left. Then you get the name of the exported function in the WAT part. <strong>Using the add function code showed before i got : “_Z3addii” as function name, we’ll use that just after</strong>. You just have to click on download and you will get your WASM file back. Easy !</p>



<p><strong>Now we can make WebAssembly work directly in the browser without all the annoying noise around.</strong> </p>



<pre data-enlighter-language="generic" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">&lt;html&gt;
  &lt;head&gt;
    &lt;title&gt;WASM test&lt;/title&gt;
    &lt;link rel="stylesheet" href="/stylesheets/style.css" /&gt;
  &lt;/head&gt;

  &lt;body&gt;
    &lt;script&gt;
      const getRandomNumber = () =&gt; Math.floor(Math.random() * 10000);

      WebAssembly.instantiateStreaming(
        fetch("https://012q1.sse.codesandbox.io/wasm/add.wasm")
      )
        .then(obj =&gt; obj.instance.exports._Z3addii)
        .then(add =&gt; {
          document.getElementById("addTarget").textContent = add(
            getRandomNumber(),
            getRandomNumber()
          );
        });
    &lt;/script&gt;

    &lt;h1&gt;Résultat du C++&lt;/h1&gt;
    &lt;p id="addTarget"&gt;&lt;/p&gt;
  &lt;/body&gt;
&lt;/html&gt;</pre>



<p>This is it. This html web page allows you to use C++ compiled into WebAssembly ! I skip all the HTML and obvious stuff to go directly to line 11 with the <strong>InstantiateStreaming </strong>function. As the <a rel="noreferrer noopener" href="https://developer.mozilla.org/fr/docs/Web/JavaScript/Reference/Objets_globaux/WebAssembly/instantiateStreaming" target="_blank">Mozilla documentation</a> says, this function allows you to compile and instantiate our WebAssembly module via a simple fetch.</p>



<p>Then, I use the add function via the function name we retrieved earlier and use it to replace a piece of DOM. And voila ! <strong>C++ via Javascript inside your browser.</strong> How crazy is that? Look, I even made you a <a rel="noreferrer noopener" href="https://codesandbox.io/s/webassembly-en-5-minutes-012q1?fontsize=14&amp;hidenavigation=1&amp;module=%2Fpublic%2Findex.html&amp;theme=dark" target="_blank">codesandbox</a> with a working demo. I’m embedding it right here, play with it !</p>







<p>You’re gonna tell me it’s complicated just to do this, and you’re right. <strong>They’re working to replace the instantiation javascript bit with a simple import into the future.</strong> So be patient, it’s coming. </p>



<figure><img src="https://i.imgur.com/4FjTgL7.jpg" data-src="https://i.imgur.com/4FjTgL7.jpg" alt="fast"></figure>



<h3>Epilogue</h3>



<p>We’ve already been talking for five minutes, so I’ll stop here. If you want to know more about WebAssembly and you have time in front of you : i<strong> recommend this <a rel="noreferrer noopener" href="https://www.javascriptjanuary.com/blog/webassembly-neither-web-nor-assembly-but-revolutionary" target="_blank">excellent article</a> to go deeper in the subject.</strong> For the rest of the story, I’m looking forward to what this opening of the Web to other languages will bring. There’s a lot of potential and i can’t wait for the web to get even faster !</p>

			<!-- clearfix -->
			

			
		</div></div>]]>
            </description>
            <link>https://www.jesuisundev.com/en/understand-webassembly-in-5-minutes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23634033</guid>
            <pubDate>Wed, 24 Jun 2020 21:23:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My 10 Year Game Development Journey]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 4 (<a href="https://news.ycombinator.com/item?id=23633738">thread link</a>) | @cedricr
<br/>
June 24, 2020 | http://nicotuason.com/10years.html | <a href="https://web.archive.org/web/*/http://nicotuason.com/10years.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>My 10 Year Game Development Journey</p>
		<h4>June 24, 2020</h4>
        <hr>
	
		<p>Hello! My name is Nico Tuason and I'm an indie game developer from the Philippines. This year marks the 10th year of my game development journey. I'd like to share my entire story with you - my failures, triumphs, and major life events. I hope it will be worth your time.</p>
		<h2>2010 - A Leap of Faith</h2>
		<p>At the start of the decade, I was 23 years old and had just left my job at a local web development company. I had been working there for a year and was making about <strong>22,000 PHP</strong> or <strong>440 USD</strong> a month. The pay was not bad for a fresh grad, but I was unproductive and unhappy. Additionally, my girlfriend of 4 years was dropping plenty of hints of her desire to get married, and 20k pesos just wasn't going to cut it.</p>
		<p>Being Asian (Filipinos are Asian too!) it was not acceptable for my parents that I was not either working or studying, so I applied for a post-grad Multimedia course in Singapore. Little did my parents know, shortly after applying I had received a rejection letter. I would keep telling them that "my application was pending", because I was secretly working on a passion project - my first game.</p>
		<p>To me, video games were more than a fun past-time. They were my refuge during hard and lonely times growing up. I spent almost all my free time playing games on the family PC. One of the first video games I ever received was Star Wars Rebel Assault II, a short but cinematic game. I played through it on every difficulty multiple times. After that, my parents bought me Command and Conquer and my fate was sealed. Growing up, I spent all my money on upgrading the family PC and buying boxed copies of games.</p>
		<p>Being in web development, I learned to use Flash to create banner ads and menu navigation for our clients. Out of necessity, I also had to learn how to create attractive UI and graphic design. While researching, I stumbled across a website called FGL.com (Flash Game License) that allowed anyone in the world to upload a Flash game and have sponsor websites bid on the right to put their logo on the game. They showed what some of the games were bidding for - <strong>3000 USD</strong>,  <strong>5000 USD</strong>! To me this looked like an incredible amount of money. There were even some mythical games going for <strong>10,000 - 20,000 USD</strong>! I devoured all the tutorials I could find. Before I had an idea for a game, I wanted to see if I could do a basic animation.</p>

		<div><p><img src="http://nicotuason.com/img/10years/male1_walk_side.gif"></p><p>My first animation</p>
		</div>
		
		<p>It looked good! But I knew I wanted to make a game in the isometric perspective. I had fallen in love with classic isometric RPGs like Baldur's Gate, and I was sure that any game I made had to be in isometric view. So, I repeated the animation but from different angles.</p>

		<div><p><img src="http://nicotuason.com/img/10years/male1_sheet.gif"></p><p>My first spritesheet</p>
		</div>

		<div><p><img src="http://nicotuason.com/img/10years/iso_walk.gif"></p><p>Resulting animation</p>
		</div>

		<p>The next step was to see if it actually looked good moving around a surface.</p>

		<div><p><img src="http://nicotuason.com/img/10years/walk_test1.gif"></p><p>Yes!</p>
		</div>

		
		<p>I didn't know any game math, but I knew from tutorials that in an isometric perspective, a square is twice as wide as it is tall. So, any movement along the y-axis had to be halved. This made for a very simple isometric transform:</p>
		<div>
		<p>screen_x = x;</p>
		<p>screen_y = y*0.5;</p>
		</div>
		<p>Ok, after I got the basics down, It was time for a stress test.</p>

		<div><p><img src="http://nicotuason.com/img/10years/walk_test2.gif"></p><p>Stress me out</p>
		</div>
		
		<p>By now I was waking up at 6am and jumping right into the computer to make more sprite sheets. It was intoxicating. Every day I felt a step closer to realizing my dream of making a game.</p>
		<p>I did a bunch more tests and I found the fastest way to draw stuff on screen using Flash was to use a method called "copyPixels". The tutorials called it "bitmap blitting" but I only cared that it was super fast. Most flash games those days used Vector graphics - very sharp and smooth shapes. This was a huge burden on CPUs around the world (and eventually led to Flash's demise), but by using copyPixels my game could have way more stuff onscreen than other Flash games.</p>

		<div><p><img src="http://nicotuason.com/img/10years/walk_test3.gif"></p><p>Walk all over me</p>
		</div>
		
		<p>Ok, the tech looked good, so it was time to start thinking about what kind of game this was going to be. At the time, tower defense was a very popular genre, and I loved RTS games. I decided that the simplest route was to make a bunch of enemies walk in one direction while you try to stop them, with lasers. Taking heavy influence from Starship Troopers and Starcraft, I created a suitable enemy that you could have fun slaughtering by the hundreds.</p>

		<div><p><img src="http://nicotuason.com/img/10years/walk_test4.gif"></p><p>Blizzard dont sue pls</p>
		</div>
		
		<p>I kept developing the game like this, working on one thing at a time and making sure it was acceptable before moving on to the next thing. If I don't stop myself, I could probably talk about every little detail that went into making the game, but we still have a long way to go.</p>
		<p><strong>7 months later...</strong></p>
		<p>I had a small but complete game on my hands. I called it "Desert Moon".</p>

		<div><p><img src="http://nicotuason.com/img/10years/desert_moon.gif"></p><p>C'mon you apes, you wanna live forever!?</p>
		</div>

		
		<p>It was time to put the game up for bidding. I uploaded the game to FGL.com and proceeded to not sleep for the next few days. I wish I took more screenshots of this process. I think at the time the bidding period lasted 1 month. After many tens-of-thousands of "reload page" clicks later, there was finally a winning bid. It was <strong>8500 USD</strong>! I don't know how to describe how I felt, but my head must have grown very large. I showed my girlfriend and my parents, the latter finally accepting that I wasn't going to grad school.</p>
		<p>My girlfriend, Terry, also loved Tower Defense games and she was the main play-tester during development. This was a very happy time for us.</p>
		<p>All I had to do was slap the Sponsor's logo onto the game and we could release it to the world.</p>


		<div><p><img src="http://nicotuason.com/img/10years/maxgames_intro.gif"></p><p>Thank you business daddy!</p>
		</div>

		<p>The game launched on the major Flash game portals (Kongregate, Newgrounds, Armorgames, etc.) on December 11, 2010, and thus began my gamedev career.</p>
		


		<h2>2011 - Indie to Employee</h2>
		<p>Flash games are free, so once a game is out there's not much you can do to make more money besides make another game. It takes a while before securing a sponsor and the game finally being released so I immediately started on another game called "Solarmax".</p>

		<div><p><img src="http://nicotuason.com/img/10years/solarmax_test.gif"></p><p>First prototype</p>
		</div>
		
		<p>One of my favorite games of all time is Homeworld. There's just nothing like the epic feeling of the fate of your entire race, your entire <em>history</em>, resting on your shoulders. I couldn't do anything near a 3D RTS like Homeworld, but there was a popular genre of Flash game called "Swarm" defense / strategy. I think Phage Wars was the most popular of these. I thought it would work well translated into epic space battles.</p>

		<div><p><img src="http://nicotuason.com/img/10years/solarmax.gif"></p><p>Scientifically accurate depiction of orbital mechanics</p>
		</div>
		
		<p>I spent some time learning 3D modeling software for this game. I was quite tired of pixel art after doing all the spritesheets for Desert Moon and exporting 3D models as a png sequence seemed like a good way to get all the angles needed for an isometric perspective without having to manually draw every frame.</p>

		<div><p><img src="http://nicotuason.com/img/10years/solarmaxb.gif"></p><p>pew pew!</p>
		</div>
		
		<p>The game was completed in 3 months, much faster than my first project! I was able to get it sponsored for <strong>6000 USD</strong>. A bit less than before, but it was a "non-exclusive" sponsorship meaning I could still sell "sitelocked" versions of the game. This was a common practice back then of having 1 version that would spread to all the portals, and many "sitelocked" versions that had a different site's branding but could only be played on their site.</p>
		<p>I planned to keep building small games like this as my skills grew, but then something unexpected happened. I got a job!</p>
		<p>I got an email from the CEO of a tech company in the U.S. who had seen my games and was looking for a flash programmer for a game they were making. Who knew CEOs were randomly playing flash games and emailing the developer?</p>
		<p>My first response was actually to decline the offer, because number 1 - I'm a dunce, and number 2 - I thought I could just make small flash games forever. Luckily this guy was persistent and I would still get to work on Flash games, but with more team members! And and... they were going to fly me out to the States to attend <strong>GDC</strong>!!!</p>

		<div><p><img src="http://nicotuason.com/img/10years/gdc1.jpg"></p><p>I'm in GDC!</p>
		</div>

		<div><p><img src="http://nicotuason.com/img/10years/gdc2.jpg"></p><p>I'm in San Francisco!</p>
		</div>

		<div><p><img src="http://nicotuason.com/img/10years/gdc4.jpg"></p><p>Another time, baby</p>
		</div>
		
		<p>I'm so grateful to the people who made this happen! As a young game dev, going to GDC is like going to see the Vatican if you're ultra-Catholic. I was over the moon.</p>
		<p>Plus, the salary... it was <strong>3000 USD</strong> a month! A U.S.-based salary for someone living in the Philippines! I have to tell you, I really thought I was hot shit at the time.</p>
		<p>After I got my first paycheck, I proposed to my girlfriend Terry, who I was sure would say yes because the year before her lawyer-auntie cornered me and demanded a deposition on why I had not married her niece yet.</p>
		<p>Things were going great!</p>



		<h2>2012 - Life... finds a way</h2>
		<p>In January, Terry and I got married! I was imagining that the next few years would be just the two of us, traveling together to different countries... making up for all the times we weren't allowed to travel together because the Philippines is a conservative country and it would be scandalous.</p>

		<div><p><img src="http://nicotuason.com/img/10years/wedding.jpg"></p><p>Our wedding Jeepney</p>
		</div>
		
		<p>Instead, 9 months later we had our first child! Which is great too I guess haha... ha.</p>

		<div><p><img src="http://nicotuason.com/img/10years/andres.jpg"></p><p>Yup, that's a baby alright</p>
		</div>
		
		<p>Becoming a dad mostly just means that a full-night's sleep is a thing of the past, at least in the beginning. I was working from home anyway so the arrangement was very doable.</p>
		<p>Meanwhile, work as an employee started out great and we produced lots of small games in a short time frame. Over the months though things started to drag. I felt myself becoming less and less productive. I missed the feeling of always learning something new and putting what I learned into a game. Maybe I'm just a bad employee?</p>
		<p>To prove how bad of an employee I was, here are some prototypes I made <em>mostly</em> during my free time.</p>
		<p>An isometric aerial dogfighting game in a fantasy WW1 setting:</p>
		
		<div><p><img src="http://nicotuason.com/img/10years/dogfight.gif"></p><p>I challenge you to a duel, good sir!</p>
		</div>
		
		<p>A pixel-ly survival game where you explore a …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://nicotuason.com/10years.html">http://nicotuason.com/10years.html</a></em></p>]]>
            </description>
            <link>http://nicotuason.com/10years.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23633738</guid>
            <pubDate>Wed, 24 Jun 2020 20:52:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Let's learn about Protocol Buffers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23633542">thread link</a>) | @forthwall
<br/>
June 24, 2020 | https://docs.shub.club/data/protobufs | <a href="https://web.archive.org/web/*/https://docs.shub.club/data/protobufs">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div id="main-content">
<p><strong>Protocol Buffers</strong>  or <strong>“Protobufs”</strong> is a term often thrown around the rooms of big tech companies when designing <a href="https://systems-analysis.net/application/definition.html">application systems</a>. Application systems can contain hundreds of thousands of machines all communicating with each other. At that scale, many companies try to optimize in any way possible—Protocol Buffers is tool you can use to send data between your applications at high speeds. </p>
<p>In this article, I’ll be shedding some light on protocol buffers and showing you how to use it!</p>
<p>Protobufs are often paired with gRPCs (<a href="https://grpc.io/">Remote Procedure Calls</a>), which are a topic of its own. I’ll try to cover it in a few weeks.</p>
<div>
    <picture>
      <source srcset="https://shub.sfo2.digitaloceanspaces.com/docs/data/protobufs/cover.png, https://shub.sfo2.digitaloceanspaces.com/docs/data/protobufs/cover@2x.png 2x">
    <img height="289" width="516" src="https://shub.sfo2.digitaloceanspaces.com/docs/data/protobufs/cover@2x.png" alt=" High-speed 'Protobuf Railway' vs crowded 'JSON Expressway'">
    </picture>
        <p>What would you take your data on?</p>
</div>
<h2 id="the-gist">The Gist</h2>
<p>Protobufs is an <a href="https://stackoverflow.com/questions/670630/what-is-idl">interface definition language</a> and <a href="https://simple.wikipedia.org/wiki/Communication_protocol">communication protocol</a> used to build applications and transport data between them. Protobufs accomplishes this by enforcing a common data structure in the sections of code where data will be transmitted between applications. These data structures are defined in <code>.proto</code> files. A commandline tool, <code>protoc</code>, uses those <code>.proto</code> files to generate class files that are used to write your applications. </p>
<p>These classes come with a few helper functions that can convert data defined in a class to binaries--which then is used to transmit data between two servers. </p>
<p>Protobufs can be compared to JSON, the two differences are:</p>
<ol>
<li>You need to pre-define how your structure looks like in <code>.proto</code> files</li>
<li>The data stored in protobufs are modified by helper functions provided by the autogenerated classes from those <code>.proto</code> files</li>
</ol>
<p>Any time you transmit JSON between two servers; you could replace that with a protobuf binary instead. Sending data via protobuf binaries can offer performance improvements in faster download times between 4 to 78% depending on the situation (I discuss more in Tradeoffs and Benefits).</p>
<p>In my mind, there are two processes when developing with protobufs: the development process and the implementation process. The development process deals with creating and managing protobufs. The implementation process is the use of protobuf classes to build our applications/servers/services.</p>
<div>
    <picture>
      <source srcset="https://shub.sfo2.cdn.digitaloceanspaces.com/docs/data/protobufs/proto-dev-cycle-1x.png, https://shub.sfo2.cdn.digitaloceanspaces.com/docs/data/protobufs/proto-dev-cycle-2x.png 2x">
    <img height="428" width="600" src="https://shub.sfo2.cdn.digitaloceanspaces.com/docs/data/protobufs/proto-dev-cycle-1x.png" alt="Protobuf development process visualized, explained below">
    </picture>
    <p>The development process, visualized</p>
</div>
<p>Let's look at these processes by example. Let's say we're developing an application that returns us a list of customers our company has. </p>
<p>Our development process looks like the following:</p>
<ol>
<li>A developer writes some data structures called <code>CustomerList</code> and <code>Customer</code> in a <code>customerlist.proto</code> file</li>
<li>A command line tool that comes with the protobuf library, called <code>protoc</code>, reads <code>.proto</code> files and generates classes in the programming langauge of the developer's choice.</li>
<li>The developer commits the <code>.proto</code> and generated code into their codebase</li>
<li>If any changes are needed to that datastructure, we start again at step one.</li>
</ol>
<p>The generated code in our case is the classes <code>CustomerList</code> and <code>Customer</code>. We can now use these classes to build out application. </p>
<p>When the time comes to send data between two systems, we can invoke a helper function that's attached to these classes to convert our Class data into a string. An invoked REST/gRPC/etc call passes this data to another service. Our listener on our other service can then use the same classes to deserialize the string back into language readable data.</p>
<h2 id="implementing-protobufs">Implementing protobufs</h2>
<div>
    <picture>
      <source srcset="https://shub.sfo2.cdn.digitaloceanspaces.com/docs/data/protobufs/protobuf-our-system.png, https://shub.sfo2.cdn.digitaloceanspaces.com/docs/data/protobufs/protobuf-our-system@2x.png 2x">
    <img height="176" width="600" src="https://shub.sfo2.cdn.digitaloceanspaces.com/docs/data/protobufs/protobuf-our-system.png" alt="Our system diagram. This details a client communicating to a web server communicating to a database server">
    </picture>
    <p>Let's build something like this!</p>
</div>
<p>Let’s build a system that transports a list of customers from our python application server to a Node.js webserver and shows us that list on a table.</p>
<p>This application is a bit complicated, so I have provided a Github link below for you to follow along:<br>
<a href="https://github.com/4shub/protobufs-example">https://github.com/4shub/protobufs-example</a></p>
<p>The file structure of our application should look like the following:</p>
<pre><code>// @language-override:Our folder
application_root
|_src
   |_ generated
   |_ protos</code></pre>
<p>First let’s build a <code>customerlist.proto</code> in <code>src/protos</code>:</p>
<pre><code>// @language-override:proto3
syntax = "proto3";

message Customer {
  required string name = 1;
  required int32 id = 2;
  required string email = 3; 
  required bool isNewCustomer = 4;
}

message CustomerList {
  repeated Customer customer = 1;
}</code></pre>
<p>Above I created our data structure following the <a href="https://developers.google.com/protocol-buffers/docs/proto3">proto3 language</a>. </p>
<p>Then we need to run following command in our application root:</p>
<pre><code>// @language-override:Terminal
protoc --python_out=src/generated --js_out=import_style=commonjs,binary:src/generated src/protos/customerlist.proto -I src/protos</code></pre>
<p>This command will generate our classes in files named <code>customerlist_pb.py</code> and <code>customerlist_pb.js</code> in a folder called <code>generated</code>.</p>
<p>Now let’s build our python server</p>
<pre><code># @language-override:Python + Flask
import flask
from generated import customerlist_pb2

app = flask.Flask(__name__)

# creating our "database"
customer1 = customerlist_pb2.Customer(name='Shubham', id=0, email='<a href="https://docs.shub.club/cdn-cgi/l/email-protection" data-cfemail="f98a918c9bb98a918c9bd79a958c9b">[email&nbsp;protected]</a>')
customer2 = customerlist_pb2.Customer(name='Rui', id=1, email='<a href="https://docs.shub.club/cdn-cgi/l/email-protection" data-cfemail="d8aaadb198acb7b7f6bbb7b5">[email&nbsp;protected]</a>', isNewCustomer=True)

customer_list = customerlist_pb2.CustomerList()
customer_list.customer.append(customer1)
customer_list.customer.append(customer2)


@app.route('/customer-list')
def get_customer_list():
    # `SerializeToString` is a helper function that serializes customer_list to a binary format
    return customer_list.SerializeToString()

if __name__ == "__main__":
    app.run(host='0.0.0.0', port=3001)</code></pre>
<p>In the code above, I instantiate the class <code>CustomerList</code> and populate it with some customer data. Then I convert that data into a protobuf binary and pass it anyone who requests <code>/customer-list</code>.</p>
<p>Our node server will act as our receiving server, it will host a html page that would contain a button that requests us the customer list stored on the python server. The node.js server will make the request on behalf of the client to get that data.</p>
<pre><code>// @language-override:Node.js + Express
const path = require('path');
const axios = require('axios');
const express = require('express');
const app = express();
const port = 3000;

const { CustomerList } = require('./generated/customerlist_pb');
const PYTHON_SERVER_URL = 'http://localhost:3001';

app.get('/customers', async (req, res) =&gt; {
    try {
        const binaryData = await axios.get(`${PYTHON_SERVER_URL}/customer-list`);

        // convert string to base64 to be read by `deserializeBinary`
        const base64data = Buffer.from(binaryData.data).toString('base64')

        const customerList = CustomerList.deserializeBinary(base64data)

        // convert to json
        res.send(customerList.toObject());
    } catch (e) {
        console.log(e)
        res.send(404);
    }
});

app.get('/', (req, res) =&gt; res.sendFile(path.join(__dirname, './index.html')));

app.listen(port, () =&gt; console.log(`Example app listening at http://localhost:${port}`))</code></pre>
<p>We see <code>CustomerList</code>'s helper function <code>deserializeBinary</code> converting our binary string into a workable <code>CustomerList</code> class object. We use <code>toObject</code> to convert our class data into a JSON. We finally pass the JSON to the client.</p>
<h2 id="tradeoffs-and-benefits">Tradeoffs and Benefits</h2>
<p><strong>Not everything you build requires protobufs!</strong></p>
<p>Sometimes it’s easier and more efficient to not deal with sophisticated methods over sending data. In a study by Auth0 [0], where they compared JSON vs protobuf binary performance, Protobufs significantly improved data transmission rates from java server to java server communication (78% download time reduction), while java server to client communication had only a 4% download time reduction. </p>
<p>Auth0 also did a second test from a java server to the client in an “uncompressed” environment. Download time was improved by 21%. Using this information, if your goal is just to enhance performance, it's much better just to compress your JSON data and forget implementing protobufs.</p>
<p>Outside optimizations, protobufs provides a method of documenting and enforcing a data structure. This is super useful with keeping data consistent across multiple programming languages and multiple teams. </p>
<p>What do tradeoffs and benefits mean for you, the developer? It means that sometimes a tool you could use in one part of your application system might not be useful elsewhere. Or it could mean that maybe the additional development time to enforce protobufs on your whole application is worth it. In the end, it's up to you as a developer to see if a solution is viable for your product or use-case. </p>
<h2 id="conclusion">Conclusion</h2>
<p>Building an application ecosystem can be daunting, but with protobufs in your toolkit you can optimize your networking capacity to its full potential. Companies like Square, Google and Netflix use it every day in their systems. Maybe you can try and build something cool with it too. As always, let me know what you’ve built with protobufs.</p>
<p>[0] <a href="https://auth0.com/blog/beating-json-performance-with-protobuf/">https://auth0.com/blog/beating-json-performance-with-protobuf/</a></p></div>
        </div></div>]]>
            </description>
            <link>https://docs.shub.club/data/protobufs</link>
            <guid isPermaLink="false">hacker-news-small-sites-23633542</guid>
            <pubDate>Wed, 24 Jun 2020 20:36:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Developers are artists not factory workers]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23633493">thread link</a>) | @doorknobguy
<br/>
June 24, 2020 | https://usehaystack.io/blog/post/software-development-metrics-measuring-what-matters-2/ | <a href="https://web.archive.org/web/*/https://usehaystack.io/blog/post/software-development-metrics-measuring-what-matters-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-w-id="0ea0c8ae-8333-a516-8908-f86a85ef9373"><h2>Most teams don't know what or how to measure. You're not alone.</h2><p>After advising hundreds of CTOs - I noticed a set of questions that consistently came up. They seem simple at face value but in reality they are some of the hardest questions to answer as an engineering leader.</p><p>‍</p><h2>Common Questions:</h2><ol role="list"><li>Are we getting better?</li><li>Where can we improve?</li><li>Are we even good at all?</li></ol><p>‍</p><p>As a manager it can be incredibly frustrating to not have the answers to these questions - &nbsp;even more so when you have to answer to outside stakeholders.</p><p>We often rely on trust and culture - but even in the best cases these questions largely go unanswered. It's incredibly difficult to quantify a team's progress and many go so far as to say "it's impossible" and "wrong to even try".</p><p>The end result? </p><p>‍</p><h3><em>"We're flying blind. And we know it."</em></h3><p>‍</p><p>‍</p><h2>Software Metrics are incredibly hard.</h2><p>The history of software development metrics has shown many (flawed) attempts at measuring developer productivity. Half baked metrics can ruin teams, destroy culture and make developers live miserable. We've seen it time and time again from lines of code to coding days per week - failed after failed attempt.</p><p>‍</p><h3>Common Metrics That Fail - Output Metrics</h3><ol role="list"><li>Commits</li><li>Lines of Code</li><li>Pull Request Count</li><li>Velocity Points</li><li>"Impact"</li></ol><p>‍</p><h3>Output Cannot Be Measured Accurately</h3><p>These metrics fail because they attempt to measure output - but software development isn't a factory assembly line where we can count up the number of widgets produced and quickly determine how much they cost.</p><p>‍</p><h3>Software Development is more like art</h3><p>Throwing more paint on the canvas is often more harmful than helpful. More lines of code or commits is often the opposite of what we want and just as it may take an artist a full day to find out the perfect brush stroke - a single line of code can take an immense amount of effort to get right.</p><p>‍</p><h3><em>"There are many things we can measure but very few things we should."</em></h3><p>‍</p><p>‍</p><h2>So what should we measure?</h2><p>To answer that, we need to think about why we're measuring at all. Most of us simply want to drive improvement and express our efforts in a tangible way. </p><p>‍</p><p>Ultimately what we want is a productive, happy team. But what does developer productivity look like? What do you imagine when you think of a productive team? </p><p>‍</p><p>Are you imagining a lot of lines written? A ton of pull requests created? What about a super high velocity count? Probably not. You're probably imagining a team that's responsive to one another, collaborating effectively, and has a really efficient process - and the metrics you use should reflect that.</p><p>‍</p><p>‍</p><h2>Measure what matters - Process Metrics</h2><p>Use software development metrics that enable productivity. </p><p>‍</p><p>Measuring <strong>responsiveness, collaboration, and process</strong> allows the team to improve how they work together. What's great about process metrics is - as developers - we really care about this stuff. They directly impact our day to day and allow us to improve while having concrete numbers to show our organization.</p><p>‍</p><p>When we measure process we drive productivity - ultimately giving leaders quantitative ways to express improvement while enabling developers to drive meaningful change in their day-to-day experience.</p><p>‍</p><h3><em>"Process metrics enhance culture. Not hurt it."</em></h3><p>‍</p><p>‍</p><h2>What are process metrics?</h2><p><a href="https://usehaystack.io/engineering-management-ebook.html?utm_source=blog&amp;utm_medium=measure%20what%20matters&amp;utm_campaign=inside%20blog">Download our Book of Engineering</a> for a <strong>full list of process metrics</strong> and how you can use them on your team.</p><p>You can also subscribe to our newsletter or reach out to us directly at <a href="mailto:julian@usehaystack.io?subject=I%20just%20read%20your%20blog%20and%20want%20to%20connect!">julian@usehaystack.io</a>. We'd be happy to help you design what metrics are best for your team.</p><p>‍</p><p>‍</p><figure id="w-node-18b2bd14c5bd-0cbffd4a"><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5ef130052901e5cad8432b81_Haystack_Designed_Presentation.png" alt=""></p></figure><p><a href="https://usehaystack.io/?utm_source=blog&amp;utm_medium=measure%20what%20matters&amp;utm_campaign=inside%20blog">Haystack</a> helps engineering leaders identify blockers and trends. Instead of guessing if you're improving, or constantly bothering your team for progress updates, simply use Haystack to get alerts in your inbox every morning. Plus a dashboard to track improvements over time.</p><p><a href="https://usehaystack.io/?utm_source=blog&amp;utm_medium=measure%20what%20matters&amp;utm_campaign=inside%20blog">Try it for free</a></p><p>‍</p></div></div>]]>
            </description>
            <link>https://usehaystack.io/blog/post/software-development-metrics-measuring-what-matters-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23633493</guid>
            <pubDate>Wed, 24 Jun 2020 20:31:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google blew a 10 years lead – Because they only seek to hit competitors]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23633440">thread link</a>) | @snird
<br/>
June 24, 2020 | https://snir.dev/blog/google-10-years-lead | <a href="https://web.archive.org/web/*/https://snir.dev/blog/google-10-years-lead">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>An interesting essay caught my eye today at HN about how <a href="https://secondbreakfast.co/google-blew-a-ten-year-lead">google blew a 10 years lead </a> , mostly in services. The essay described how most services that were the peak of innovation 10 years ago have subsequently stood stagnant and lost their technology edge to small companies. </p> <p>Gmail is less innovative than HEY (and superhuman and many others). Google docs is not as good as Notion for knowledge sharing and collaboration. And the list goes on. </p> <p>Initially, I thought it was because Google targets only big business customers, competing with Microsoft 365. Other product innovations do not scare them, they still offer a package with mail, video conferencing, docs, sheets, drive, etc. This is great for big business collaboration tools. Competitors like Notion and HEY are too small for Google business to care. </p> <p>Docs, sheets, drive, mail are all products targeted at corporate collaboration. These are directly competing with Microsoft alone. What about Google Cloud? What about Android? What happened there? </p> <p>Google consistently follows the market preventing its competitors from achieving market control. And in Google's case, "the market" is Amazon, Microsoft, Apple, and Facebook. </p> <img alt="google logo" src="https://snir.dev/blog/google-10-years-lead/google.png"> <p>We'll start with Microsoft since they were the first. And beating them down took place ~10 years ago, that's why it seems like the tech from back then never progressed much. Because the hit had already struck. </p> <p>Microsoft dominated the corporate world with its mail software Outlook, and with its Office suite, Word, Excel, etc. Google is native to the web and they leveraged their position to slowly hit Microsoft in this spot. Gmail first, then Google Drive, and then Chrome to kill IE as a final strike. And it was successful. </p> <p>Amazon got big into the tech business through AWS. Google brought Google Cloud to the fight. The offering is no only cheaper, it also provides technologies that can't be explained any other way than as a way to hit AWS. Kubernetes as an open platform is against any business textbook rukes to lock in customers. But it will allow for an easy way out of AWS in the long run, preferably to GCP, but it can be any other cloud provider that provides Kubernetes service as well. It is strategically more of a hit to the front runner, Amazon, than a benefit to GCP. </p> <p>Google's first priority is to hit the front runner, then everything else. This can also be seen with the Apple case. Android came after the iPhone. It has a much larger market share, and yet, generates far less revenue to Google than the iPhone is to Apple. That's because the main goal is to prevent Apple from winning the market. And in that, it is successful. </p> <p>Google Buzz. Ouch. Google Plus. Double ouch. Google spent so much effort into hitting Facebook as hard as they can. They were not succeful here, but from the history of things it is obvious how Google try to hit Facebook. They did not try to create a new social platform, no. Otherwise they would come up with something that is not.. well, exactly like facebook. </p> <p>Google home initially released at 2016. Amazon Alexa in 2014.</p> <p>I have so many more examples that comes to mind as I write, but the point is already clear. </p> <p>On a final note, I'll say, Google is not only trying to bend down competitors. Google Glass is one new product market they tried to create. The self-driving cars initiative is another example the comes to mind. They do innovate. </p> <p>They just have so much money, blocking out other big tech companies is a strategy they are not willing to give up. And when this is the strategy, well, Google sheets already took a huge chunk from Microsoft, what more does it need? </p> <form action="https://snir.substack.com/api/v1/free?nojs=true" method="post" min-width="400 500 600 700 800"> <div data-style="minimal">  <ul data-element="errors" data-group="alert"></ul>  <p>I wont send you spam. Unsubscribe at any time.</p></div></form></article></div>]]>
            </description>
            <link>https://snir.dev/blog/google-10-years-lead</link>
            <guid isPermaLink="false">hacker-news-small-sites-23633440</guid>
            <pubDate>Wed, 24 Jun 2020 20:26:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dynamic Water Demo with Godot]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23633174">thread link</a>) | @homarp
<br/>
June 24, 2020 | https://captainproton42.github.io/DynamicWaterDemo/ | <a href="https://web.archive.org/web/*/https://captainproton42.github.io/DynamicWaterDemo/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
  <div>
    <div>
      

<p>Click anywhere to interact with objects or spawn crates. You can also change the quality of the water texture and reset the scene.</p>

<h2 id="about">About</h2>

<p>View this page without the runnable demo scene <a href="https://captainproton42.github.io/DynamicWaterDemo/no_demo/">here</a>.</p>

<p>The entire code of this project is hosted on <a href="https://github.com/CaptainProton42/DynamicWaterDemo">GitHub</a>. It is lincensed under MIT so feel free to do with it whatever you want.</p>

<p>You can also find me on Twitter <a href="https://twitter.com/CaptainProton42">@CaptainProton</a> and on Reddit <a href="https://www.reddit.com/user/captainproton42">u/CaptainProton42</a>.</p>

<p>Below you will find a step-by-step explanation of the implementation.</p>

<h2 id="how-i-did-this">How I did this</h2>

<p>My implementation uses a finite-differencing method in order to solve the wave equation on a grid. I used the paper <a href="https://www.researchgate.net/publication/221314832_Real-Time_Open_Water_Environments_with_Interacting_Objects">Real-Time Open Water Environments with Interacting Objects</a> by H. Cords and O. Staadt as a reference. If you want to know more about the technical aspects of this implementation or more advanced techniques like infinite water, it’s a really good read.</p>

<h3 id="the-wave-equation">The wave equation</h3>

<p>A very important equation in phyiscs is the <a href="https://en.wikipedia.org/wiki/Wave_equation">wave equation</a>. It describes the propagation of many types of waves like water waves, sound waves, and even light. It therefore plays a large role in many fields of physics like fluid dynamics, acoustics, and optics. We can use it to describe the behaviour of our waves as well.</p>

<p>The equation itself is a <a href="https://en.wikipedia.org/wiki/Hyperbolic_partial_differential_equation">hyperbolic partial differential equation of second order</a>. If this sounds very complex, don’t worry, the equation itself is actually quite short:</p>



<p>Here,  is the current time,  is the position on the water surface and  is the wave speed.  then denotes the displacement, that is the height, of the water surface at position  and time .</p>

<p>The opertator  is the so-called Laplace operator and denotes the sum of the second spatial derivatives in every direction:</p>



<p>Thus we can see that the wave equation connects the second spatial derivates of the wave height with its second derivative in time. This property results in the motion of waves as we would observe it in nature.</p>

<h3 id="the-finite-difference-method">The finite difference method</h3>

<p>So now that we know what equation we want to solve we still have to figure out how to obtain a solution. Generally, this cannot be done analytically so we resort to a very popular numerical method: <a href="https://en.wikipedia.org/wiki/Finite_difference_method">the finite difference method</a>. In this method, we discretise the area in which we want to solve our equation into a grid. We then determina an approximate solution at each point of that grid.</p>

<p>Since we are discretising the water surface, we need to discretise the wave equation as well. For this, we use <em>stencils</em>. More specifically, a <em>five point stencil</em> for the Laplace operator and a <em>three point stencil</em> for the second derivative in time.</p>

<p>Let’s start with the Laplace operator: As previously stated, we dicretise the water surface as a grid. Let’s denote  as the value of the function  at the grid coordinates . Using a <em>five point stencil</em>, we can then <em>approximate</em> the derivative at that point as</p>



<p>where  is the distance between two grid points which is assumed to be equal in  and  direction. So, in order get the second spatial derivative at point  we need to sample all direct (non-diagonal) neighbours of that point (see the figure below).</p>

<p><img width="30%" src="https://raw.githubusercontent.com/CaptainProton42/DynamicWaterDemo/media/stencil.png"></p>

<p>However, the wave equation also contains a second time derivative which we need to discretise as well. For the time discretisation, we simply use the physics process delta time  (which is constant in Godot). We use the upper index  to denote the point in time. The complete notation is  for the displacement at grid coordinates  and time . In order to now approximate the second time derivate, we can just use the following three-point-stencil:</p>



<p>Now that we have dicretized both derivatives, let’s just plug them back into the initial wave equation and solve for :</p>



<p>where we introduce . In order to obtain a stable simulation,  needs to hold true. We thus have some limits on our choice of $\Delta t$ and $h$, depending on how fast our waves should propagate. Grids with less points (and thus large ) are generally more stable but also less accurate. It is desirable to keep  as small as reasonably possible which means high framerates will benefit our simulation.</p>

<p><strong>Let’s break down the final equation:</strong> In order to update and retreive , we need to know the grid neighbouring grid values at time  as well as the previous displacement values at time  and . We can start our grid from any arbitrary initial conditions and let it evolve over time.</p>

<p>Now that we know the theory, let’s get to the actual implementation.</p>

<h3 id="implementation-of-the-finite-difference-method">Implementation of the finite difference method</h3>

<p>In order to bring the finite difference method to life, we use fragment shaders. Textures are basically just two-dimensional grids that can hold values (colors) at each grid point (pixel). We make use of this convenient property and simply use a texture as the grid for our finite difference method.</p>

<p>In the editor, we create a new viewport called <code>SimulationViewport</code>. This viewport in return contains a <code>ColorRect</code> as shown below.</p>

<p><img width="30%" src="https://raw.githubusercontent.com/CaptainProton42/DynamicWaterDemo/media/implementation.PNG"></p>

<p>We then apply a shader to the <code>ColorRect</code> which contains the simulation code. The size (in pixels) of the <code>ColorRect</code> thus defines the size of the simulation grid. Two textures are passed as uniforms to this shader: <code>z_tex</code> which holds the grid values  and <code>z_old_tex</code> which holds the grid values . The resulting values  are then rendered to the <code>ColorRect</code> by the fragment shader. In order to retreive the current grid values, we can then simply retreive the contents of <code>SimulationViewport</code> with a <code>ViewportTexture</code>.</p>

<p>The snippet below contains the part of the simulation shader assigned to <code>ColorRect</code> which does the heavy lifting:</p>

<div><div><pre><code>void fragment() {
    float pix_size = 1.0f/grid_points;

    vec4 z = a * (texture(z_tex, UV + vec2(pix_size, 0.0f))
                  + texture(z_tex, UV - vec2(pix_size, 0.0f))
		  + texture(z_tex, UV + vec2(0.0f, pix_size)) 
		  + texture(z_tex, UV - vec2(0.0f, pix_size)))
	     + (2.0f - 4.0f * a) * (texture(z_tex, UV))
	     - (texture(old_z_tex, UV));

    float z_new_pos = z.r; // positive waves are stored in the red channel
    float z_new_neg = z.g; // negative waves are stored in the green channel

    ...

    COLOR.r = z_new_pos;
    COLOR.g = z_new_neg;
}
</code></pre></div></div>

<p><em>Note that we store “positive” waves in the red and “negative” waves in the green channel. This is not particularly important now and we will explain it later on.</em></p>

<p>You can see that we first read the neighbouring grid values as well as the current and last values at the grid position and then combine them according to our formula. The resulting value is then assigned to <code>COLOR</code>.</p>

<p><code>a</code> can be se at initialisation of the scene as a <code>uniform</code> since the physics frame rate is constant.</p>

<p>We also need a script that updates the simulation as well as grid textures each step. This is done in a script assigned to the <code>Water</code> Node. <code>_update</code> is called each physics frame:</p>

<div><div><pre><code>func _update():
    ...
    update_height_map()

    # Render one frame of the simulation viewport to update the simulation
    simulation_viewport.render_target_update_mode = Viewport.UPDATE_ONCE

    # Wait until the frame is rendered
    yield(get_tree(), "idle_frame")
    ...

func update_height_map():
    # Update the height maps
    var img = simulation_texture.get_data() # Get currently rendered map
    # Set current map as old map
    var old_height_map = simulation_material.get_shader_param("z_tex")
    simulation_material.get_shader_param("old_z_tex") \
        .set_data(old_height_map.get_data())
    # Set the current height map from current render
    simulation_material.get_shader_param("z_tex").set_data(img)
</code></pre></div></div>

<p>And that’s it for our basic simulation. We now know how to propagate waves along the surface but have yet to create them.</p>

<h3 id="creating-waves">Creating waves</h3>

<p>When considering a boat moving through water, we need to be aware of two “types” of waves, <em>bow</em> waves and <em>stern</em> waves. Bow waves are created were the the boat’s hull pushes away the water. Stern waves, on the other hand, are created behind the boat, where water is rushing back to fill the space the boat previously occupied. We thus create <em>positive</em> bow waves in front of the boat and <em>negative</em> stern waves behind the boat. Creating positive or negative waves just means manually setting grid points to positive or negative values.</p>

<p>The intensity of both creatd wave types will also depend on the speed of the boat: The faster the boat, the higher the waves.</p>

<p>In order to create waves we first need to know <em>where</em> to create them. We thus need to know the intersection of the boat’s hull with the water surface.</p>

<p>We use a little trick to accomplish this:</p>

<p>Let’s create a second viewport called <code>CollisionViewport</code>. This viewport will hold the texture which contains the intersection areas of all objects with the surface.</p>

<p>We then add a new camera called <code>CollisionCamera</code> to <code>CollisionViewport</code>. This camera uses on orthogonal projection and has its size set to that of the water surface. The near plane is set to match the water surface and the far plane should be moved sufficiently far away, as shown below.</p>

<p><img width="75%" src="https://raw.githubusercontent.com/CaptainProton42/DynamicWaterDemo/media/viewing_frustum.png"></p>

<p>Next, we add an additional mesh to every node that should be able to create waves and call it <code>CollisionMesh</code>. This mesh defines the hull of our boat.</p>

<p><img width="30%" src="https://raw.githubusercontent.com/CaptainProton42/DynamicWaterDemo/media/collision_mesh.png"></p>

<p>This mesh has a special material which consists of two passes: The first one is a <code>ShaderMaterial</code> with a shader <code>collision.shader</code> that looks like this (this can also be done with a <code>SpatialMaterial</code> but I find this variant to be more verbose):</p>

<div><div><pre><code>shader_type spatial;

uniform float speed;

render_mode cull_front;

void fragment() {
    ALBEDO.r = speed;
}
</code></pre></div></div>

<p>The second pass is just a <code>SpatialMaterial</code> with albedo set to black and a <em>higher</em> render priority (so that front faces are drawn in front of back faces).</p>

<p>The resulting material will draw the <em>inside</em> of the mesh whatever color we set from <code>speed</code> and the <em>outside</em> plain black. Since the camera culls every fragment above the water surface (its near plane), it will draw the colored inside of objects that intersect the surface. The viewport texture will then be black where there is no intersection and colored for all areas where a hull intersects.</p>

<p>We can also give …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://captainproton42.github.io/DynamicWaterDemo/">https://captainproton42.github.io/DynamicWaterDemo/</a></em></p>]]>
            </description>
            <link>https://captainproton42.github.io/DynamicWaterDemo/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23633174</guid>
            <pubDate>Wed, 24 Jun 2020 20:02:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Operating Systems via Development]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23632833">thread link</a>) | @simedw
<br/>
June 24, 2020 | https://www.theerlangelist.com/article/operating_via_development | <a href="https://web.archive.org/web/*/https://www.theerlangelist.com/article/operating_via_development">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>About two years ago I decided to add HTTPS support to this site, using automatic certification via Let’s Encrypt. All the articles on the subject relied on a tool called <a href="https://certbot.eff.org/">certbot</a>. A couple of variations were mentioned, some requiring the tool to run while the site is down, others using nginx + certbot combination. It seemed that installing and running some additional external tool(s) in production was mandatory.</p>
<p>At that point The Erlangelist was a standalone Elixir-powered system which required no external program. It seemed that now I have to start worrying about setting up additional services and interact with them using their custom DSLs. This would complicate operations, and create a disconnect between production and development. Any changes to the certification configuration would need to be tested directly in production, or alternatively I’d have to setup a staging server. Either way, testing of certification would be done manually.</p>
<p>Unhappy with this state I started the work on <a href="https://hexdocs.pm/site_encrypt/readme.html">site_encrypt</a>, a library which takes a different approach to automatic certification:</p>
<ol>
<li>site_encrypt is a library dependency, not an external tool. You’re not required to install any OS-level package to use it.
</li>
<li>The certification process and periodical renewal are running in the same OS process as the rest of the system. No other OS processes need to be started.
</li>
<li>Everything is configured in the same project where the system is implemented.
</li>
<li>Interaction with site_encrypt is done via Elixir functions and data. No yaml, ini, json, or other kind of DSL is required.
</li>
<li>It’s trivial to run the certification locally, which reduces the differences between prod and local dev.
</li>
<li>The support for automatic testing of the certification is provided. There’s no need to setup staging machines, or make changes directly on the production system.
</li>
</ol>
<p>This is an example of what I call “integrated operations”. Instead of being spread across a bunch of yamls, inis, jsons, and bash scripts, somehow all glued together at the OS-level, most of the operations is done in development, i.e. the same place where the rest of the system is implemented, using the same language. Such approach significantly reduces the technical complexity of the system. The Erlangelist is mostly implemented in Elixir, with only a few administrative tasks, such as installation of OS packages, users creation, port forwarding rules, and similar provisioning tasks being done outside of Elixir.</p>
<p>This also simplifies local development. The <a href="https://github.com/sasa1977/erlangelist/#running-the-site-locally">instructions to start the system locally</a> are very simple:</p>
<ol>
<li>Install build tools (Elixir, Erlang, nodejs)
</li>
<li>Fetch dependencies
</li>
<li>Invoke a single command to start the system
</li>
</ol>
<p>The locally started system will be extremely close to the production version. There is almost nothing of significance running on production which is not running locally. The only two differences of note I can think of are:</p>
<ol>
<li>Ports 80/443 are forwarded in prod
</li>
<li>The prod version uses Lets Encrypt for certification, while the local version uses a local CA server (more on this later).
</li>
</ol>
<p>Now, this may not sound like much for a simple blog host, but behind the scene The Erlangelist is a bit more than a simple request responder:</p>
<ol>
<li>The Erlangelist system runs two separate web servers. The public facing server is the one you use to read this article. Another internal server uses the <a href="https://hexdocs.pm/phoenix_live_dashboard/Phoenix.LiveDashboard.html">Phoenix Live Dashboard</a> to expose some metrics.
</li>
<li>A small hand-made database is running which collects, aggregates, and persists the reading stats, periodically removing older stats from the disk.
</li>
<li>The system periodically renews the certificate.
</li>
<li>Locally and on CI, another web server which acts as a local certificate authority (CA) is running.
</li>
</ol>
<p>In other words, The Erlangelist is more than just a blog, a site, a server, or an app. It’s a system consisting of multiple activities which collectively work together to support the full end-user service, as well as the operational aspects of the system. All of these activities are running concurrently. They don’t block each other, or crash each other. The system utilizes all CPU cores of its host machine. For more details on how this works take a look at my talk <a href="https://www.youtube.com/watch?v=JvBT4XBdoUE">The soul of Erlang and Elixir</a>.</p>
<p>Let’s take a closer look at site_encrypt.</p>
<h2>Certification</h2>
<p>Let’s Encrypt supports automatic certification via the <a href="https://tools.ietf.org/html/rfc8555">ACME (Automatic Certificate Management Environment) protocol</a>. This protocol describes the conversation between the client, which is a system wanting to obtain the certificate for some domain, and the server, which is the certificate authority (CA) that can create such certificate. In ACME conversation, our system asks the CA to provide the certificate for some domain, and the CA asks us to prove that we’re the owners of that domain. The CA gives us some random bytes, and then makes a request at our domain, expecting to get those same bytes in return. This is also called a challenge. If we successfully respond to the challenge, the CA will create the certificate for us. The real story is of course more involved, but this simplified version hopefully gives you the basic idea.</p>
<p>This conversation is an activity of the system. It’s a job which needs to be occasionally done to allow the system to provide the full service. If we don’t do the certification, we don’t have a valid certificate, and most people won’t use the site. Likewise, if I decide to shut the site down, the certification serves no purpose anymore.</p>
<p>In such situations my preferred approach is to run this activity together with the rest of the system. The less fragmented the system is, the easier it is to manage. Running some part of the system externally is fine if there are stronger reasons, but I don’t see such reasons in this simple scenario.</p>
<p><a href="https://hexdocs.pm/site_encrypt/readme.html#quick-start">site_encrypt makes this task straightforward</a>. Add a library dep, fill in some blanks, and you’re good to go. The certification configuration is provided by defining the <code>certification</code> function:</p>
<pre><code><span>def</span><span> </span><span>certification</span><span> </span><span data-group-id="0390845481-1">do</span><span>
  </span><span>SiteEncrypt</span><span>.</span><span>configure</span><span data-group-id="0390845481-2">(</span><span>
    </span><span>client</span><span>:</span><span> </span><span>:native</span><span>,</span><span>
    </span><span>domains</span><span>:</span><span> </span><span data-group-id="0390845481-3">[</span><span>"mysite.com"</span><span>,</span><span> </span><span>"www.mysite.com"</span><span data-group-id="0390845481-3">]</span><span>,</span><span>
    </span><span>emails</span><span>:</span><span> </span><span data-group-id="0390845481-4">[</span><span>"contact@mysite.com"</span><span>,</span><span> </span><span>"another_contact@mysite.com"</span><span data-group-id="0390845481-4">]</span><span>,</span><span>
    </span><span>db_folder</span><span>:</span><span> </span><span>"/folder/where/site_encrypt/stores/files"</span><span>,</span><span>
    </span><span>directory_url</span><span>:</span><span> </span><span>directory_url</span><span data-group-id="0390845481-5">(</span><span data-group-id="0390845481-5">)</span><span>,</span><span>
  </span><span data-group-id="0390845481-2">)</span><span>
</span><span data-group-id="0390845481-1">end</span></code></pre>
<p>This code looks pretty declarative, but it is executable code, not just a collection of facts. And that means that we have a lot of flexibility to shape the configuration data however we want. For example, if we want to make the certification parameters configurable by the system operator, say via a yaml file, nothing stops us from invoking <code>load_configuration_from_yaml()</code> instead of hardcoding the data. Say we want to make only some parameters configurable (e.g. domains and email), while leaving the rest hardcoded. We can simply do <code>Keyword.merge(load_some_params_from_yaml(), hardcoded_data)</code>. Supporting other kinds of config sources, like etcd or a database, is equally straightforward. You can always build declarative on top of imperative, while the opposite will require some imagination and trickery, such as running external configuration generators, and good luck managing that in production :-)</p>
<p>It’s also worth mentioning that site_encrypt internally ships with two lower-level modules, a sort of plumbing to this porcelain. There is a <a href="https://hexdocs.pm/site_encrypt/SiteEncrypt.Acme.Client.html#content">mid-level module</a> which provides workflow-related operations, such as “create an account”, or “perform the certification”, and a <a href="https://hexdocs.pm/site_encrypt/SiteEncrypt.Acme.Client.API.html#content">lower-level module</a> which provides basic ACME client operations. These modules can be used when you want a finer grained control over the certification process.</p>
<h2>Reducing the dev-production mismatch</h2>
<p>There’s one interesting thing happening in the configuration presented earlier:</p>
<pre><code><span>def</span><span> </span><span>certification</span><span> </span><span data-group-id="3249251622-1">do</span><span>
  </span><span>SiteEncrypt</span><span>.</span><span>configure</span><span data-group-id="3249251622-2">(</span><span>
    </span><span># ...</span><span>
    </span><span>directory_url</span><span>:</span><span> </span><span>directory_url</span><span data-group-id="3249251622-3">(</span><span data-group-id="3249251622-3">)</span><span>,</span><span>
  </span><span data-group-id="3249251622-2">)</span><span>
</span><span data-group-id="3249251622-1">end</span></code></pre>
<p>The <code>directory_url</code> property defines the CA where site_encrypt will obtain the certificate. Instead of hardcoding this url, we’re invoking a function to compute it. This happens because we need to use different urls for production vs staging vs local development. Let’s take a look:</p>
<pre><code><span>defp</span><span> </span><span>directory_url</span><span> </span><span data-group-id="5360223777-1">do</span><span>
  </span><span>case</span><span> </span><span>System</span><span>.</span><span>get_env</span><span data-group-id="5360223777-2">(</span><span>"MODE"</span><span>,</span><span> </span><span>"local"</span><span data-group-id="5360223777-2">)</span><span> </span><span data-group-id="5360223777-3">do</span><span>
    </span><span>"production"</span><span> </span><span>-&gt;</span><span> </span><span>"https://acme-v02.api.letsencrypt.org/directory"</span><span>
    </span><span>"staging"</span><span> </span><span>-&gt;</span><span> </span><span>"https://acme-staging-v02.api.letsencrypt.org/directory"</span><span>
    </span><span>"local"</span><span> </span><span>-&gt;</span><span> </span><span data-group-id="5360223777-4">{</span><span>:internal</span><span>,</span><span> </span><span>port</span><span>:</span><span> </span><span>4002</span><span data-group-id="5360223777-4">}</span><span>
  </span><span data-group-id="5360223777-3">end</span><span>
</span><span data-group-id="5360223777-1">end</span></code></pre>
<p>Here, we’re distinguishing production from staging from development based on the <code>MODE</code> OS env (easily replaceable with other source, owing to programmable API). If the env is not provided, we’ll assume that the system running locally.</p>
<p>On a production machine, we go to the real CA, while for staging we’ll use Let’s Encrypt staging site. But what about the <code>{:internal, port: 4002}</code> thing which we use in local development? If we pass this particular shape of data to site_encrypt, an internal ACME server will be started on the given port, a sort of a local mock of Let’s Encrypt. This server is running inside the same same OS process as the rest of the system.</p>
<p>So locally, site_encrypt will start a mock of Let’s Encrypt, and it will use that mock to obtain the certificate. In other words, locally the system will certify itself. Here’s an example of this in action on a local version of The Erlangelist:</p>
<pre><code>$ iex -S mix phx.server

[info]  Running ErlangelistWeb.Blog.Endpoint at 0.0.0.0:20080 (http)
[info]  Running ErlangelistWeb.Blog.Endpoint at 0.0.0.0:20443 (https)
[info]  Running local ACME server at port 20081
[info]  Creating new ACME account for domain theerlangelist.com
[info]  Ordering a new certificate for domain theerlangelist.com
[info]  New certificate for domain theerlangelist.com obtained
[info]  Certificate successfully obtained!</code></pre>
<h2>Testability</h2>
<p>Since local Erlangelist behaves exactly as the real one, we can test more of the system behaviour. For example, even on the local version HTTP requests are redirected to HTTPS. Here’s a test verifying this:</p>
<pre><code><span>test</span><span> </span><span>"http requests are redirected to https"</span><span> </span><span data-group-id="4049071146-1">do</span><span>
  </span><span>assert</span><span> </span><span>redirected_to</span><span data-group-id="4049071146-2">(</span><span>Client</span><span>.</span><span>get</span><span data-group-id="4049071146-3">(</span><span>"http://localhost/"</span><span data-group-id="4049071146-3">)</span><span>,</span><span> </span><span>301</span><span data-group-id="4049071146-2">)</span><span> </span><span>==</span><span>
    </span><span>"https://localhost/"</span><span>
</span><span data-group-id="4049071146-1">end</span></code></pre>
<p>Like…</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.theerlangelist.com/article/operating_via_development">https://www.theerlangelist.com/article/operating_via_development</a></em></p>]]>
            </description>
            <link>https://www.theerlangelist.com/article/operating_via_development</link>
            <guid isPermaLink="false">hacker-news-small-sites-23632833</guid>
            <pubDate>Wed, 24 Jun 2020 19:35:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Zoom Hires Jason Lee as CISO]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23632731">thread link</a>) | @l8rpeace
<br/>
June 24, 2020 | https://blog.zoom.us/zoom-hires-jason-lee-as-chief-information-security-officer/ | <a href="https://web.archive.org/web/*/https://blog.zoom.us/zoom-hires-jason-lee-as-chief-information-security-officer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              
              
              <div>
                <p><a href="https://blog.zoom.us/author/zoom/" title="Zoom">
                                            <img data-src="https://blog.zoom.us/wp-content/uploads/2020/06/Zoom-Icon-62x62.png" alt="Zoom" title="Zoom" src="https://blog.zoom.us/wp-content/uploads/2020/06/Zoom-Icon-62x62.png">
                                      </a>
                </p>
                <div>
                  <p><a href="https://blog.zoom.us/author/zoom/" title="https://blog.zoom.us/author/zoom/">Zoom</a></p><p>June 24, 2020<span>3 min read</span></p>
              </div>
            </div>
                          <p><img data-src="https://blog.zoom.us/wp-content/uploads/2020/06/Jason-Lee-Headshot.png" alt="Zoom Hires Jason Lee as Chief Information Security Officer" src="https://blog.zoom.us/wp-content/uploads/2020/06/Jason-Lee-Headshot.png">
                                      </p>
                <!--?xml encoding="UTF-8" ?--><p>Today Zoom <a rel="noreferrer noopener" href="http://www.globenewswire.com/news-release/2020/06/24/2052921/0/en/Zoom-Hires-Jason-Lee-as-Chief-Information-Security-Officer.html" target="_blank">announced</a> that Jason Lee will join the company as its Chief Information Security Officer, effective June 29, 2020. Lee brings 20 years of expertise in information security and operating mission-critical services. He was most recently the Senior Vice President of Security Operations at Salesforce, and previously was Principal Director of Security Engineering at Microsoft. Lee will lead Zoom’s security team and report to Aparna Bawa, Zoom’s Chief Operating Officer.&nbsp;</p>



<p>Zoom is nearing the end of its 90-day security and privacy plan, put into place during a time of unprecedented growth that has made Zoom the platform of choice for over 300 million daily meeting participants, including those at some of the world’s largest enterprises. Lee will focus on continuing Zoom’s path of putting the security and privacy of its users first by ensuring that the frictionless and easy-to-use platform remains secure.&nbsp;&nbsp;</p>



<p>“Our customers’ security is extremely important and is at the core of everything we do. We are excited to welcome Jason, who has deep industry experience, understands the complexity of servicing a wide variety of users, and can lead Zoom’s efforts to strengthen the security of our platform during this time of rapid expansion,” said Bawa.</p>



<p>“Zoom is on an incredible journey of growth and I am thrilled to bring my experience of running world-class security organizations to the company. Ensuring that customers trust our products is of the utmost importance and I look forward to working with the team to continue instilling security into the DNA of Zoom,” said Lee.&nbsp;</p>



<h3><strong>About Jason Lee</strong></h3>



<p>Jason Lee is the Chief Information Security Officer at Zoom with 20 years of experience in technology, with a specialization in information security and operating mission-critical services. He was recently the Senior Vice President of Security Operations at Salesforce where he was accountable for the global organization delivering critical end-to-end security operations to customers and employees including company-wide network and system security, incident response, threat intel, data protection, vulnerability management, intrusion detection, identity and access management, and the offensive security team. Prior to Salesforce, he held the position of Principal Director of Security Engineering for the Windows and Devices division in Microsoft with the charter of protecting the online services of Windows Update, XBOX Live, and the Microsoft online store. He was also the Senior Director of Developer Services where he was responsible for the design and management of the mission-critical PKI for all products across Microsoft. This included cryptographic services in products such as Windows and SQL Server, and cloud services such as Azure and Office 365. Additionally, Jason was responsible for the codesigning and anti-malware services supporting Microsoft in that role.</p>
                              
            </div></div>]]>
            </description>
            <link>https://blog.zoom.us/zoom-hires-jason-lee-as-chief-information-security-officer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23632731</guid>
            <pubDate>Wed, 24 Jun 2020 19:28:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Types of Indexes in PostgreSQL]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23632663">thread link</a>) | @boshomi
<br/>
June 24, 2020 | https://www.highgo.ca/2020/06/22/types-of-indexes-in-postgresql/ | <a href="https://web.archive.org/web/*/https://www.highgo.ca/2020/06/22/types-of-indexes-in-postgresql/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                        
<p>Finding relevant information quickly speeds up performance. For example, while reading a book <span>in which you have to find a topic that you would like to read, if you know that it is in a certain chapter then you will simply go to that chapter, perhaps look through it and start reading the desired topic. </span></p>



<p><span>However if you don’t know then you can consult with the book index that’s usually available at the end of the book first, and find out which pages might list the desired topic. This way you will go only those pages to look for the topic. However if the index is not available then you will have to browse through the whole book looking for the pages of interest. This will obviously consume a lot of time in finding the relevant pages instead of quickly jumping to the desired pages right away.</span></p>



<p><span>The analogy of using a book index for searching the desired pages is similar to searching a database table for the desired tuples. If you can create an index on a database table the query execution may get quite fast and if you don’t have the index then it may end up taking quite a lot of time. I used the word “may” because in some cases a full table scan might be faster than an index scan, we will explore some of these in this blog moving forward.</span></p>



<p><span>PostgreSQL provides a variety of indexes and also quite a number of ways to create these indexes. The blog provides a brief introduction of all the different index types available in PostgreSQL, and also provides some examples to elaborate the index types.</span></p>



<h3><strong>1. B-Tree Index</strong></h3>



<p><span>It is the default index type in PostgreSQL that gets created when you do a ‘CREATE INDEX’ statement without mentioning the index name.</span></p>



<p><span>This index is much suitable for the data that can be sorted and can handle equality and range queries.</span> <span>The following command is used to create a btree index:</span></p>



<pre data-enlighter-language="sql" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="false" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">CREATE INDEX name ON table (column); or
CREATE INDEX name ON table USING BTREE (column);</pre>



<h3><strong>2. Hash Index</strong></h3>



<p><span>The hash index prior to PostgreSQL version 10 were almost discouraged for various reasons such as:</span></p>



<ul><li><span>Not WAL logged hence not crash safe</span></li><li><span>Not replicated to stand-by server</span></li><li><span>Performance is not so good and may take a long time to build the index (depending on the&nbsp; table size)</span></li></ul>



<p><span>However since version 10, these problems have been resolved. They are now crash safe and are able to be replicated to standby server. They sometimes perform better than b-tree indexes and are also space efficient.</span></p>



<p><span>The Hash index only works with equality operators that means that you can only look up for data that matches exactly. However it is now much optimized and does a much faster lookup which makes this index a bit of specialized index that can be used where equal comparison is more important. </span><span>The following command is used to create a hash index:</span></p>



<pre data-enlighter-language="sql" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="false" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">CREATE INDEX name ON table USING HASH (column);</pre>



<h3><strong>3. Gist Index</strong></h3>



<p><span>Gist or Generalized Search Tree are useful when the data to be indexed is more complex than to do a simple equate or ranged comparison like finding nearest-neighbor and pattern matching. The example of such data includes geometric data, network address comparisons and full-text searches.&nbsp;</span></p>



<p><span>The Gist index itself provides an infrastructure to implement different strategies for indexing data such as B-trees and R-trees. </span><span>The following command is used to create a hash index:</span></p>



<pre data-enlighter-language="sql" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="false" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">CREATE INDEX name ON table USING gist (column);</pre>



<h3><strong>4. SP-Gist Index</strong></h3>



<p><span>SP-Gist or Space partitioned Gist indexes are useful when the data can be grouped into non-overlapping groupings. Like Gist index, it also provides an infrastructure for implementing different indexing strategies. However SP-Gist is non-balanced in nature and divides data in partitions, so it allows the implementation of </span><span>quad-trees, k-d trees, and radix trees (tries).</span></p>



<h3><strong>5. Gin Index</strong></h3>



<p><span>Generalized Inverted indexes are useful in indexing data that consist of multiple elements in a single column such as arrays, json documents (jsonb) or text search documents (tsvector).</span></p>



<pre data-enlighter-language="sql" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="false" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">CREATE INDEX name ON table USING gin (column);</pre>



<h3><strong>6. BRIN Index</strong></h3>



<p><span>Block Range Indexes are useful for large size tables that have columns with some natural sort order. The BRIN index divides the table into block ranges and keeps a summary of those blocks. This summary includes min, max values of the range. </span><span>The following command is used to create a hash index:</span></p>



<pre data-enlighter-language="sql" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">CREATE INDEX name ON table USING brin (column);</pre>



<p>The above list&nbsp;discribes&nbsp;the available&nbsp;index algorithms&nbsp;availble in&nbsp;postgres database, now lets see&nbsp;some of the characteristics of&nbsp;indexes&nbsp;that&nbsp;can be used to&nbsp;further&nbsp;tweek&nbsp;and&nbsp;enhance&nbsp;the performance of&nbsp;indexes.</p>



<h2><span>Multicolumn Indexes</span></h2>



<p><span>PostgreSQL does allow creation of an index on multiple columns. However you can only have a maximum of 32 columns and such indexes only work with Btree, Gist, Gin and Brin. An example of such index is:</span></p>



<pre data-enlighter-language="sql" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="false" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">CREATE TABLE test (x int, y int);
CREATE INDEX multi_idx ON test (x, y);

postgres=# EXPLAIN (costs off) SELECT * from test WHERE x = 10 AND y = 100;
               QUERY PLAN                
-----------------------------------------
 Index Only Scan using multi_idx on test
   Index Cond: ((x = 10) AND (y = 100))
(2 rows)
</pre>



<h2><span>Unique Indexes</span></h2>



<p><span>A unique index enforces the uniqueness of the values in the column. In PostgreSQL a unique index can be created on one or multiple columns. If a unique index is created for multiple columns the uniqueness is ensured using the combined values of columns.&nbsp;however only&nbsp;B-tree&nbsp;index can be&nbsp;declared&nbsp;unique.</span></p>



<pre data-enlighter-language="sql" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="false" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">CREATE TABLE test (x int, y int);
CREATE UNIQUE INDEX unique_idx ON test (x);
postgres=# \d test
                Table "public.test"
 Column |  Type   | Collation | Nullable | Default 
--------+---------+-----------+----------+---------
 x      | integer |           |          | 
 y      | integer |           |          | 
Indexes:
    "unique_idx" UNIQUE, btree (x)
</pre>



<p>Let’s create a multi-column index.</p>



<pre data-enlighter-language="sql" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="false" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">CREATE UNIQUE INDEX unique_multi_col_idx ON test (x, y);
postgres=# \d test
                Table "public.test"
 Column |  Type   | Collation | Nullable | Default 
--------+---------+-----------+----------+---------
 x      | integer |           |          | 
 y      | integer |           |          | 
Indexes:
    "unique_idx" UNIQUE, btree (x)
    "unique_multi_col_idx" UNIQUE, btree (x, y)
</pre>



<p><span>NULL values are not considered equal, hence they are considered unique values. Adding multiple NULLs in a unique column won’t result in index violation.</span></p>



<p><span>Also note that, if you declare a unique constraint or primary key for a column, PostgreSQL automatically creates a unique index. An example of such index is:</span></p>



<pre data-enlighter-language="sql" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="false" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">CREATE TABLE test (x int PRIMARY KEY, y int UNIQUE);
postgres=# \d test
                Table "public.test"
 Column |  Type   | Collation | Nullable | Default 
--------+---------+-----------+----------+---------
 x      | integer |           | not null | 
 y      | integer |           |          | 
Indexes:
    "test_pkey" PRIMARY KEY, btree (x)
    "test_y_key" UNIQUE CONSTRAINT, btree (y)
</pre>



<h2><span>Indexes on Expressions</span></h2>



<p><span>It is also possible in PostgreSQL database to create the indexed columns based on the result of a function or scalar expression computed from one or more columns of the table. Since the result of computed expression is stored on the index and it won’t be computed at run time, the access to table data becomes much faster. However the insertion and updation of the data becomes more expensive. Some example of this index are:</span></p>



<pre data-enlighter-language="sql" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="false" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">CREATE TABLE test (x int, y text);
postgres=# EXPLAIN (costs off) SELECT * from test WHERE lower(y) = 'value';
              QUERY PLAN              
--------------------------------------
 Seq Scan on test
   Filter: (lower(y) = 'value'::text)
(2 rows)
</pre>



<p><span>Now lets create an indexed expression and see the query again. It should show the index being built using the expression now, instead of the table field.</span></p>



<pre data-enlighter-language="sql" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="false" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">postgres=# CREATE INDEX expr_idx ON test (lower(y));
CREATE INDEX
postgres=# EXPLAIN (costs off) SELECT * from test WHERE lower(y) = 'value';
                   QUERY PLAN                   
------------------------------------------------
 Bitmap Heap Scan on test
   Recheck Cond: (lower(y) = 'value'::text)
   -&gt;  Bitmap Index Scan on expr_idx
         Index Cond: (lower(y) = 'value'::text)
(4 rows)

postgres=# \d test
                Table "public.test"
 Column |  Type   | Collation | Nullable | Default 
--------+---------+-----------+----------+---------
 x      | integer |           |          | 
 y      | text    |           |          | 
Indexes:
    "expr_idx" btree (lower(y)
</pre>



<h2><span>Partial Indexes</span></h2>



<p><span>There are some situations where you don’t want to index the whole table, instead you will want to filter out some specific data based on some conditions. This kind of index is called a partial index. The partial index only contains the data for those rows that fulfill that specific condition.</span></p>



<p><span>These indexes contain a WHERE clause and result in much smaller index sizes than the usual indexes (without conditions). Since they have a smaller footprint, they result in faster data access. An example of such index is:</span></p>



<pre data-enlighter-language="sql" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="false" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">CREATE TABLE test (x int, y text);
postgres=# EXPLAIN (costs off) SELECT * from test WHERE y IS NULL;
      QUERY PLAN       
-----------------------
 Seq Scan on test
   Filter: (y IS NULL)
(2 rows)
</pre>



<p><span>Lets create a partial index</span></p>



<pre data-enlighter-language="sql" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="false" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">postgres=# CREATE INDEX partial_idx ON test (y) WHERE y IS NULL;
CREATE INDEX
postgres=# EXPLAIN (costs off) SELECT * from test WHERE y IS NULL;
               QUERY PLAN               
----------------------------------------
 Bitmap Heap Scan on test
   Recheck Cond: (y IS NULL)
   -&gt;  Bitmap Index Scan on partial_idx
(3 rows)
</pre>



<h2><span>Index-Only Scans</span></h2>



<p><span>Index only scans are the index where all the needed data by the query is available directly from the index. Normally when an index is created, it is stored separately from the table data and whenever a query is executed to fetch the data rows it is …</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.highgo.ca/2020/06/22/types-of-indexes-in-postgresql/">https://www.highgo.ca/2020/06/22/types-of-indexes-in-postgresql/</a></em></p>]]>
            </description>
            <link>https://www.highgo.ca/2020/06/22/types-of-indexes-in-postgresql/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23632663</guid>
            <pubDate>Wed, 24 Jun 2020 19:24:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why not just use bitmap fonts?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23632572">thread link</a>) | @stargrave
<br/>
June 24, 2020 | https://dataswamp.org/~lich/musings/bitmap-fonts.html | <a href="https://web.archive.org/web/*/https://dataswamp.org/~lich/musings/bitmap-fonts.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<p><small><em>Fri, 26 Jun 2020 14:31:01 +0200</em></small></p>

<p><strong>Disclaimer: In this text, as all of mine, I am writing from a
perspective of a Linux user. Then my remarks won’t hold fully true for
MacOS users or Windows users as their setups might be different.</strong></p>

<p><a href="https://i.pinimg.com/474x/fb/ec/45/fbec45ac5ba8cdee978b3b460f982104.jpg">I am angry. Angry about GNOME and the modern GUI design.</a> After reading
<a href="https://tonsky.me/blog/monitors/">an article by tonsky</a>, I realised how most of projects have forgotten
about bitmap fonts. It is one of these weird occurences, as bitmap
fonts are much simpler to program and use. I think that BDF fonts are
the only font format that is human readable in the raw form.</p>



<p>In his blogpost tonsky argued that you should buy a 4K display as on
lower PPI displays outline fonts look terrible. They do, and it is a
fact for any person that cares about fonts. I hold that at &gt;150 PPI
outline fonts should be auxillary. They ought to be used in the
necessary cases (for example: typesetting, official documents, etc.).
In any other uses, they are unbearable to look at as they are not
designed to work without antialiasing nor hinting.</p>

<p>On the other hand, bitmap fonts are designed <em>against</em> antialising and
hinting. They are not meant to be resized so they stay at maximum in
couple of sizes. That keeps them predictable and efficient. There are
no issues related to bluriness, as pixels themselves are the determine
their borders and they follow the limitations of displays. Their
formats, such as ancient BDF are so simple that they are human
readable. Thus it is much easier to customise, than the sanity
questioning of outline fonts and the hellscape of <code>fontforge(1)</code>.</p>

<p>Look at this code of a glyph (from <a href="https://notabug.org/invest/atarist-lich">Atarist</a> font) in BDF format in 142 bytes.</p>

<pre><code>STARTCHAR HEBREW LETTER HE
ENCODING 1492
SWIDTH 512 0
DWIDTH 8 0
BBX 8 16 0 -2
BITMAP
00
00
7E
7E
06
66
66
66
66
66
66
66
00
00
00
00
ENDCHAR
</code></pre>

<p>You are instantly aware of each element of the glyph and how it will
behave within this format. Such is not as easy for outline fonts. I do
not need to give screenshots to explain what is going on.</p>



<p>As bitmap fonts just became non-standard fonts they are treated worse
than outline fonts. The change in <a href="https://blogs.gnome.org/mclasen/2019/08/07/pango-1-44-wrap-up/">Pango 1.44</a> to only use .otb fonts
which are not something what indsutry was used to. Majority of
software which uses Pango now struggles with .otb bitmap fonts and
gives them wrong outlines, or just does not print them at all (i.e.
zathura or dunst).</p>

<p>The description of the change in Pango 1.44 shows the lack of
responsibiltiy of GNOME developers. They push the task of solving the
issue they created towards ‘the internet community’. These fonts are
supposed be easiest to handle and should not be treated like this.</p>

<p>Also, nobody offers any reliable solution for scaling bitmap fonts on
high DPI displays. There, a simple proportional scaling would be fine
for solving this problem.</p>

<p>I do not want to worry about fonts, I just want them to be readable
and non-blurry on my display. Such is not achievable (on low PPI
displays) with greatly promoted outline fonts. That’s that. When I
want a high PPI display, then I can use my e-reader, or better yet -
print it.</p>
</article></div>]]>
            </description>
            <link>https://dataswamp.org/~lich/musings/bitmap-fonts.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23632572</guid>
            <pubDate>Wed, 24 Jun 2020 19:17:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Memorable Passwords]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23632533">thread link</a>) | @espadrine
<br/>
June 24, 2020 | https://espadrine.github.io/blog/posts/memorable-passwords.html | <a href="https://web.archive.org/web/*/https://espadrine.github.io/blog/posts/memorable-passwords.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <article>

<p>We are slowly getting to a comfortable password situation.</p>
<p>Research has improved on which passwords are easier to remember.
Cryptographers have <a href="https://password-hashing.net/argon2-specs.pdf">strenghtened the cost</a> of cracking weak passwords.
People are more aware of the security risks,
and the usage of password managers grows.</p>
<p>The consensus on password handling is this:</p>
<ol>
<li>Keep a very strong master password in your head, stored nowhere.</li>
<li>Use it to unlock your password manager.</li>
<li>Use your password manager to store and create very random passwords for individual websites.
You would never be able to remember them, but you only need to remember the master password.
Typically, for alphanumerical outputs, you need ⌈128÷log2(26·2+10)⌉ = 22 characters.</li>
<li>The websites, and more importantly, the password manager,
use a key derivation function such as <a href="https://password-hashing.net/argon2-specs.pdf">Argon2</a> either on the front-end
(server relief) or on the backend, and only stores the output.
It ensures computation is both time-hard and memory-hard, with settings kept up-to-date
to ensure that each computation takes 0.5 seconds and/or 4 GB of RAM.</li>
</ol>
<p>But some details are left unset: exactly how strong should the master password be?
How do we even know?
Can this situation converge to an easier user experience for login on the Web?</p>
<h2>Password hashing</h2>
<p>Some accurate statements may be surprising to the general population.
This is one:</p>
<p><strong>Multiple passwords can unlock your account.</strong></p>
<p>The reason? Your password is not compared byte-for-byte (thankfully!)
but through a hashing method that does not map one-to-one.</p>
<p>Indeed, hashes have fixed sizes (typically 256 bits),
while passwords have arbitrary length.</p>
<p>Overall, this consideration is unimportant,
because virtually no password is strong enough
to even compete with the collision risk of the hash:
it is tremendously more likely for a collision to be caused by
the generation process, than by the hash,
whose collision risk is 2<sup>N÷2</sup>
where N is the size of the hash, typically 256 bits nowadays.</p>
<p>On top of this, some companies build their login system
in a way that is more resilient to user error,
such as <a href="https://www.zdnet.com/article/facebook-passwords-are-not-case-sensitive-update">having caps lock on</a>.</p>
<p>That too is irrelevant, since the search space is typically only reduced
by one bit (corresponding to the choice between setting caps lock or not).</p>
<h2>Target strength</h2>
<p><a href="https://crypto.stackexchange.com/questions/60815/recommended-minimum-entropy-for-online-passwords-in-2018">Some suggestions target specific cryptographic algorithms</a>.
But this pushes machine limits into human constraints:
algorithms require 128-bit security, not because 127 is not enough,
but because it is a power of two that neatly fits with various engineering techniques.</p>
<p>The real human constraint is your lifetime.
Once you are dead, it does not matter too much to your brain whether your secrets are out,
since your brain becomes mulch.</p>
<p>The longest person alive is a French woman that died nearly reaching 123.
Let’s imagine that health will improve
such that someone will live double that amount, Y = 246 years.
What is the minimum strength needed to ensure they won’t have their secrets cracked alive?</p>
<p>Current compute costs hover around €3/month on low-end machines.
Let’s imagine that it will improve a hundredfold in the coming century.</p>
<p>The NSA yearly budget is estimated at B = €10 billion.
Can they hack you before you die?</p>
<p>First, under those assumptions,
assuming the NSA consumes its whole budget cracking you,
how many computers will it use to crack you in parallel?
The result is P = B ÷ 12 ÷ 0.03 = 28 billion servers.</p>
<p>If your password has an N-bit entropy,
it will take 2<sup>N-1</sup>·0.005÷P÷3600÷24÷365 years on average,
assuming the NSA is brute-forcing with CPUs that can do one attempt every 5 milliseconds
(a hundredth of the <a href="https://password-hashing.net/argon2-specs.pdf">Argon2</a> recommended setting,
to account for the possibility that the NSA has machines a hundred times more powerful
than the rest of us, which is both unlikely, and would not cost what we estimated).</p>
<p>As a result, our formula for picking strength is
N = log2(B÷12÷0.03 · Y·365·24·3600÷0.005) + 1 = 77 bits of security.</p>
<p>Note that we can assume that a good KDF is used,
since we are only worried about password strength for the password manager,
which should be pretty good at choosing the right design.
The password manager will generate all normal passwords above 128 bits of security anyway.
(Except for those pesky websites that inexplicably have an upper password length limit.
But those are beyond saving.)</p>
<p>I parameterized some values so that you can plug your own situation.
For instance, if you make a password for your startup
that you believe will beat the odds of an average 5-year lifespan,
and become a behemoth a thousand years into the future, you can set Y = 1000
and get a very slight increase to 79 bits.</p>
<p>If you instead believe that your adversary will spend a trillion euros every year,
you can bump things up to 83 bits of security.</p>
<h2>Master password generation</h2>
<p>How do you convert a number of bits of security into a master password?
Well, those bits represent the amount of entropy of the random generator.
Or in other words, the quantity of uncertainty of the password-making process.</p>
<p>Each bit represents one truly random choice between two options.
If you have four options, it is as if you made two choices, and so on.</p>
<p>A good way to make memorable master passwords is to pick words among large dictionaries,
since picking from a long list adds a lot of entropy (since there are so many binary choices)
but each word is very distinctively evocative.</p>
<p>However, each word is independent, and therefore,
making stories in your head that combines those words gets harder the more words there are.
So we randomize the word separators as symbols,
which both adds entropy (so that we can have less words),
and is not too hard to remember. Besides, breaking words apart ensures that
we don’t lose entropy by ending up with two words that, concatenated,
are actually a single word from the same dictionary.</p>
<p>I implemented these principles on <a href="https://espadrine.github.io/passphrase/">this passphrase generation page</a>.</p>
<h2>Thank you, Next</h2>
<p>I feel strongly that passwords are passé.
I would love to talk about my hopes for the future of Web authentication.</p>
<p><a href="https://www.reddit.com/r/programming/comments/hf63bp/generate_cryptographically_secure_passphrases_at/">Reddit comments here</a>.
<a href="https://news.ycombinator.com/item?id=23632533">HN comments here</a>.</p>

    
  </article>
</div></div>]]>
            </description>
            <link>https://espadrine.github.io/blog/posts/memorable-passwords.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23632533</guid>
            <pubDate>Wed, 24 Jun 2020 19:15:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Evolution of Precomputation Technology]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23631987">thread link</a>) | @samanticora
<br/>
June 24, 2020 | https://kyligence.io/blog/the-evolution-of-precomputation-technology/ | <a href="https://web.archive.org/web/*/https://kyligence.io/blog/the-evolution-of-precomputation-technology/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                                
<div><figure><img src="https://siteprod-s3-azcdn.kyligence.io/2020/06/Evolution.png" alt="Precompute Evolution" srcset="https://siteprod-s3-azcdn.kyligence.io/2020/06/Evolution.png 558w, https://siteprod-s3-azcdn.kyligence.io/2020/06/Evolution-300x152.png 300w" sizes="(max-width: 558px) 100vw, 558px"></figure></div>



<p>Precomputation is commonly used in information retrieval and analysis. With precomputation, we compute the results once and then store them in a table or other data structure, either on a disk or in memory. In this table, each input (or combination of inputs) maps to an output value. In order to answer a question, we just need to find the output value corresponding to the input value(s). </p>







<h2>Early Forms of Precomputation</h2>



<div><figure><img src="https://siteprod-s3-azcdn.kyligence.io/2020/06/Multiplication-Table.png" alt="Figure 1: Multiplication Table (Wikipedia.org)"><figcaption><strong>Figure 1: Multiplication Table (Wikipedia.org)</strong></figcaption></figure></div>



<p> The form you are likely familiar with, and probably the most common form of precomputation, is the multiplication table (Figure 1). In this table, to find the result of 7*8, all you need to do is find row 7 (or 8) and then move across to column 8 (or 7) â€“ and there is your answer: 56! Most of us memorized the multiplication table in grade school, so we donâ€™t even realize that we are actually using this table when we perform these operations now.</p>



<div><figure><img src="https://siteprod-s3-azcdn.kyligence.io/2020/06/Logarithms-Table.png" alt="Figure 2: Logarithms Table (Wikipedia.org) " srcset="https://siteprod-s3-azcdn.kyligence.io/2020/06/Logarithms-Table.png 304w, https://siteprod-s3-azcdn.kyligence.io/2020/06/Logarithms-Table-300x241.png 300w" sizes="(max-width: 304px) 100vw, 304px"><figcaption><strong>Figure 2: Logarithms Table (Wikipedia.org)</strong> </figcaption></figure></div>



<p> Another, more advanced, example of precomputation is the logarithms table (Figure 2). If you donâ€™t remember how to use it, Iâ€™m sure youâ€™re not alone. Fun fact: The first tables of logarithms were published independently by Scottish mathematician John Napier in 1614 and Swiss mathematician Justus Byrgius in 1620. Napier actually started his work in 1594 and it took him 20 years to complete the tables </p>







<h2>From Database to Big Data to The Cloud</h2>



<p>Precomputation has been used in databases for many years. To
save time on joining tables and calculating columns, we can run these queries
upfront and save the results into materialized views. Future queries will be
directed to these materialized views to retrieve their results.</p>



<p>In 1993, Edgar F. Codd, the father of the relational database, coined the term <a href="https://kyligence.io/apache-kylin-overview/" target="_blank" rel="noreferrer noopener" aria-label="OLAP (opens in a new tab)">OLAP</a> for On-Line Analytical Processing in a white paper published by Arbor Software. In OLAP, transactional data is extracted from operational systems and loaded into data warehouses where data is organized for fast reporting performance. However, the query performance is still not satisfactory for interactive analysis. </p>



<p>For this purpose, OLAP systems calculate common queries from data warehouses and store those results in a data structure called a cube. When an OLAP product receives a query, it simply looks up the data already stored in the cube and fetches the result. This method significantly reduces query times. Over time, â€œOLAPâ€� and â€œCubeâ€� became synonyms, although, later â€œOLAPâ€� was expanded into <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://en.wikipedia.org/wiki/Online_analytical_processing#Multidimensional_OLAP_(MOLAP)" target="_blank">MOLAP</a>, <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://en.wikipedia.org/wiki/Online_analytical_processing#Relational_OLAP_(ROLAP)" target="_blank">ROLAP</a>, and <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://en.wikipedia.org/wiki/Online_analytical_processing#Hybrid_OLAP_(HOLAP)" target="_blank">HOLAP</a> architectures. </p>



<div><figure><img src="https://siteprod-s3-azcdn.kyligence.io/2020/06/Data-Cube.png" alt="Data Cube" srcset="https://siteprod-s3-azcdn.kyligence.io/2020/06/Data-Cube.png 320w, https://siteprod-s3-azcdn.kyligence.io/2020/06/Data-Cube-300x259.png 300w" sizes="(max-width: 320px) 100vw, 320px"></figure></div>



<p>As illustrated in the cube diagram here, if you need to analyze sales volume based on three attributes â€“ e.g. Products, Cities, and Time â€“ you can create a three-dimensional cube. This cube is basically a three-dimensional spreadsheet. </p>



<p>Keep in mind that although the data structure is called a <em>cube</em>, in reality most applications have more than three dimensions, but obviously there is no easy way to illustrate that in a diagram. OLAP cubes became quite popular in late 90sâ€™ with products like <a rel="noreferrer noopener" aria-label="Microsoft SSAS (opens in a new tab)" href="https://kyligence.io/solution/replace-ssas-and-scale-olap%e2%80%8b/" target="_blank">Microsoft SSAS</a>, <a href="https://kyligence.io/solution/cognos-olap%e2%80%8b-migration/" target="_blank" rel="noreferrer noopener" aria-label="Cognos (opens in a new tab)">Cognos</a>, MicroStrategy, etc. </p>



<p>In the big data and cloud era, we have seen various
technologies try to address query performance issues for large volumes of data.
From query engines to cloud data warehouses to data virtualization products,
these technologies use different forms of MPP (Massive Parallel Processing)
architecture. Although they have improved dramatically over the years, their
performances still degrade when running complex aggregate queries against a large
amount of data.</p>



<p>Caching, as a special type of precomputation, is commonly used by these products to improve performance. Query engines cache result sets in memory so the exact same query can reuse the same result set. Cloud Data Warehouses bring tables into the compute layer to avoid future network traffic between the compute and storage layers. </p>



<p>These techniques can speed up a very limited subset of queries and donâ€™t really solve the fundamental problem â€“ they donâ€™t truly support citizen analysts conducting ad-hoc analysis on large amounts of data, at the speed of thought. </p>







<h2>Kyligence â€“ A New Generation of Precomputation Technology</h2>



<p>Kyligence fundamentally changes how modern analytics is done with its breakthrough precomputation technology. When <a href="https://kyligence.io/blog/apache-kylin-through-the-eyes-of-the-founders-episode-one/" target="_blank" rel="noreferrer noopener" aria-label="the creators of the Apache Kylin project (opens in a new tab)">the creators of the Apache Kylin project</a> founded the company back in 2016, they had a vision to create a platform that could enable citizen analysts to do their jobs without worrying about the size of their data and the number of concurrent users. Today, its products are being used by some of the world largest banks, insurance companies, retailers, manufacturers, and so on.</p>







<p><strong>Know the Questions Before They Are Asked</strong></p>



<p>Wouldnâ€™t it be nice to be fully prepared and know all the questions you will be asked before you walk into an interview? Thatâ€™s exactly the approach Kyligence takes. By learning past query histories, analystsâ€™ behaviors, data profiles, and system logs, Kyligence automatically predicts the common questions people ask, and prepares answers based on its predictions. </p>



<p>This process is driven by its AI engine, and the more queries it processes, the more accurately it predicts the questions. The system analysts can further optimize the AI engineâ€™s work based on human knowledge about their business processes. </p>







<p><strong>Blazing Fast Processing Speed</strong></p>



<p>Knowing what questions users are going to ask is just the first step. The software needs to prepare the answers in time so they are available when users need them. This is the â€˜computeâ€™ part of precomputation technology. Kyligenceâ€™s Spark-based compute engine adopts many optimization techniques to speed up the building of aggregate indexes. </p>



<p>In addition to the typical batch mode, indexes can also be refreshed through a pre-scheduled incremental load, or real-time updates from messaging products such as Kafka. The fast processing speed allows users to incorporate the latest information into the aggregate index and gives them the most accurate picture of their business.</p>







<p><strong>Built for the Modern Data Platform</strong></p>



<p>Kyligenceâ€™s flagship products, <a rel="noreferrer noopener" aria-label="Kyligence Cloud (opens in a new tab)" href="https://kyligence.io/kyligence-cloud/" target="_blank">Kyligence Cloud</a> and <a href="https://kyligence.io/kyligence-enterprise/" target="_blank" rel="noreferrer noopener" aria-label="Kyligence Enterprise (opens in a new tab)">Kyligence Enterprise</a>, are built from the ground up for the modern data platform. They leverage the latest technologies to increase manageability and reduce infrastructure cost. </p>



<p>In the cloud, Kyligence can be deployed on AWS, Azure, and Google Cloud, either directly from the Kyligence portal or through the AWS and Azure Marketplace. It works with modern Cloud Data Warehouses as well as cloud data storage systems. Kyligence Cloud takes advantage of the elasticity of the cloud platform so that enterprises donâ€™t have to overpay for infrastructure and still have the capability to support usage spikes. </p>







<p><strong>Unlimited Scale</strong></p>



<p>Kyligenceâ€™s aggregate index is stored in Parquet files, a modern storage format best suited for analytics workloads. The aggregate index is stored either in cloud object stores or on Hadoop File Systems, when deployed on-premises. This type of distributed storage makes it possible to build an aggregate index 100s of times larger than other precomputation products. </p>



<p>One of our clients stores petabytes of data in the aggregate index so that <em>all</em> historical information is <em>always</em> available for their analysts. Businesses no longer have to choose between having complete access to historical data and the speed of their analytics.</p>







<p><strong>Constantly Improving</strong></p>



<p>Traditional precomputation products, such as OLAP Cubes, were very rigid. Adding an extra measure or dimension meant you had to rebuild the cubes, which lead to extra development costs and system downtime. Kyligence can handle the source schema changes and adjust measures and dimensions accordingly, and conveniently update the aggregate index. </p>



<p>The system also automatically adjusts the index to balance the often-conflicting requirements of query performance, storage space, update time, etc. Users can adjust these settings and the software will train itself to fine tune the indexes based on user behaviors.</p>







<h2>Summary<br></h2>



<p>In this blog, we looked at the history of precomputation and introduced Kyligenceâ€™s game-changing precomputation technology. This technology opens the doors for enterprises and their data scientists to conduct analytics at unprecedented speed and scale.</p>
                            </div></div>]]>
            </description>
            <link>https://kyligence.io/blog/the-evolution-of-precomputation-technology/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23631987</guid>
            <pubDate>Wed, 24 Jun 2020 18:33:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Device Firmware Update Cookbook]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23631985">thread link</a>) | @fra
<br/>
June 24, 2020 | https://interrupt.memfault.com/blog/device-firmware-update-cookbook | <a href="https://web.archive.org/web/*/https://interrupt.memfault.com/blog/device-firmware-update-cookbook">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        <p>Implementing OTA (Over The Air) firmware updates is a rite of passage for
firmware engineers. Device firmware update is a key component of most hardware
projects. Often, it is also one of the more complicated components.</p>

<p>I have worked on multiple firmware update systems over the year, and every time
I have learned something new. How do I package my images? How do I make sure I
don’t brick the device? How do I share information between my bootloader and my
application? Little by little all firmware engineers accumulate answers to
those questions and develop favored design patterns.</p>

<!-- excerpt start -->
<p>In this post, I share the device firmware update architecture I would implement
knowing everything I know now. I also highlight a few design patterns that are
particularly useful. The example comes with a fully functional example of a
multi-stage bootloader with DFU functionality.
<!-- excerpt end --></p>

<p>I learned some of these lessons in this post the hard way, and I hope I can spare
you and your colleagues a few sleepless nights spent debugging firmware update
problems in the wild!</p>

<p><em>Like Interrupt? <a href="http://eepurl.com/gpRedv">Subscribe</a> to get our latest posts
straight to your mailbox</em></p>

<h2 id="table-of-contents">Table of Contents</h2>

<!-- prettier-ignore -->
<ul id="markdown-toc">
  <li><a href="#table-of-contents" id="markdown-toc-table-of-contents">Table of Contents</a></li>
  <li><a href="#setup" id="markdown-toc-setup">Setup</a>    <ul>
      <li><a href="#renode" id="markdown-toc-renode">Renode</a></li>
      <li><a href="#toolchain" id="markdown-toc-toolchain">Toolchain</a></li>
      <li><a href="#building--running-the-example" id="markdown-toc-building--running-the-example">Building &amp; Running the Example</a></li>
    </ul>
  </li>
  <li><a href="#high-level-architecture" id="markdown-toc-high-level-architecture">High-Level Architecture</a>    <ul>
      <li><a href="#dfu-should-be-separate-from-the-application" id="markdown-toc-dfu-should-be-separate-from-the-application">DFU should be separate from the application</a></li>
      <li><a href="#dfu-code-should-be-updatable" id="markdown-toc-dfu-code-should-be-updatable">DFU code should be updatable</a></li>
      <li><a href="#dfu-should-use-minimal-code-space" id="markdown-toc-dfu-should-use-minimal-code-space">DFU should use minimal code space</a></li>
      <li><a href="#dfu-failures-should-not-brick-the-device" id="markdown-toc-dfu-failures-should-not-brick-the-device">DFU failures should not brick the device</a></li>
    </ul>
  </li>
  <li><a href="#design-patterns--recipes" id="markdown-toc-design-patterns--recipes">Design Patterns &amp; Recipes</a>    <ul>
      <li><a href="#image-metadata" id="markdown-toc-image-metadata">Image Metadata</a></li>
      <li><a href="#loading-images" id="markdown-toc-loading-images">Loading Images</a></li>
      <li><a href="#writing--committing-images" id="markdown-toc-writing--committing-images">Writing &amp; Committing Images</a></li>
      <li><a href="#shared-memory" id="markdown-toc-shared-memory">Shared Memory</a></li>
      <li><a href="#boot-stability" id="markdown-toc-boot-stability">Boot Stability</a></li>
    </ul>
  </li>
  <li><a href="#closing" id="markdown-toc-closing">Closing</a></li>
</ul>

<h2 id="setup">Setup</h2>

<p>All the code in this post was written for the STM32F429 MCU by ST Micro. While
the examples run fine on the STM32F429i discovery board they were developed in
Renode, a popular MCU emulation platform.</p>

<p>You can find the complete code example for this blog post in the <a href="https://github.com/memfault/interrupt/tree/master/example/fwup-architecture">Interrupt
Github repository</a></p>

<h3 id="renode">Renode</h3>

<p>Since writing about Renode for Interrupt, I’ve been looking for an opportunity
to use it for another project. This blog post was the perfect pretext. If you
are not familiar with Renode, I recommend reading <a href="https://interrupt.memfault.com/intro-to-renode">my previous blog post</a> on
the topic.</p>

<p>Because we use true firmware images <code>.bin</code>’s rather than <code>elf</code> files in this post, I had to make two
change to the Renode configuration:</p>

<ol>
  <li>I used <code>sysbus LoadBinary $bin 0x8000000</code> rather than <code>LoadELF</code> to load the
firmware.</li>
  <li>I manually set the Vector Table Offset with <code>sysbus.cpu VectorTableOffset
0x8000000</code>. By default, Renode looks for the vector table at <code>0x0</code> which
different from the default behavior of the STM32.</li>
</ol>

<p>Additionally, I had to modify Renode slightly to enable software-controlled
resets. Cortex-M microcontrollers can be reset by writing to the AICR register,
which was not fully implemented in the emulator. As of this writing, this change
is still in review and not yet merged into the emulator. You can find the pull
request <a href="https://github.com/renode/renode-infrastructure/pull/15/files">on Github</a>.</p>

<p>Thankfully, building our own version of Renode is relatively
straightforward using <a href="https://renode.readthedocs.io/en/latest/advanced/building_from_sources.html">their
instructions</a>.</p>

<p>I updated my <code>start.sh</code> script to run my home-built Renode instance rather than
the installed binary:</p>

<div><div><pre><code><span>#!/bin/sh</span>

<span>RENODE_EXE_PATH</span><span>=</span>~/code/renode/output/bin/Release/Renode.exe

mono64 <span>$RENODE_EXE_PATH</span> renode-config.resc
</code></pre></div></div>

<p>You will have to update this script to point at your own <code>Renode.exe</code>.</p>

<h3 id="toolchain">Toolchain</h3>

<p>I used the following tools to build my firmware:</p>
<ul>
  <li>GNU Make 4.2.1 as the build system</li>
  <li><code>arm-none-eabi-gcc</code> version 9.2.1 20191025 (release) as compiler</li>
</ul>

<p>Rather than the STM32Cube HAL, I used an open source MCU HAL called <code>libopencm3</code>
with excellent support for the STM32. I find it easier to use, and like that it
is open source and on Github. The included <code>Makefile</code> will clone <code>libopencm3</code>
during your first build.</p>

<h3 id="building--running-the-example">Building &amp; Running the Example</h3>

<p>The example can be built with Make. From the <code>examples/fwup-architecture</code>
directory:</p>

<div><div><pre><code><span>$</span> make
<span>  LD            build/fwup-example-boot.elf
  OBJCOPY       build/fwup-example-boot.bin
  LD            build/fwup-example-app.elf
  OBJCOPY       build/fwup-example-app.bin
  XXD           build/app_bin.c
  LD            build/fwup-example-loader.elf
  OBJCOPY       build/fwup-example-loader.bin
  CAT           build/fwup-example.bin
</span></code></pre></div></div>

<p>After which you can call <code>./start.sh</code> to start Renode. You will need to type the
<code>start</code> command in the Renode window to get the emulation going.</p>

<p><img src="https://interrupt.memfault.com/img/fwup-architecture/renode-running.png" alt=""></p>

<h2 id="high-level-architecture">High-Level Architecture</h2>

<p>Over the years, I’ve come up with a set of basic requirements most DFU systems
should fulfill. Let’s walk through these one by one and iteratively design our
system.</p>

<p>We start with the simplest possible description of what we want to achieve with
DFU: an application that updates itself.</p>



<p>
  <svg viewBox="0 0 256 120" xmlns="http://www.w3.org/2000/svg" xmlns:inkspace="http://www.inkscape.org/namespaces/inkscape" xmlns:xlink="http://www.w3.org/1999/xlink">
  <defs id="defs_block">
    <filter height="1.504" id="filter_blur" inkspace:collect="always" width="1.1575" x="-0.07875" y="-0.252">
      <feGaussianBlur id="feGaussianBlur3780" inkspace:collect="always" stdDeviation="4.2"></feGaussianBlur>
    </filter>
  </defs>
  <title>blockdiag</title>
  <desc>
blockdiag {
   // Set labels to nodes.
   A [label = "Application"];
   A -&gt; A [label = "Updates", fontsize=8];
}
</desc>
  <rect fill="rgb(0,0,0)" height="40" stroke="rgb(0,0,0)" style="filter:url(#filter_blur);opacity:0.7;fill-opacity:1" width="128" x="67" y="46"></rect>
  <rect fill="rgb(255,255,255)" height="40" stroke="rgb(0,0,0)" width="128" x="64" y="40"></rect>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="11" font-style="normal" font-weight="normal" text-anchor="middle" textLength="66" x="128" y="66">Application</text>
  <path d="M 192 60 L 208 60" fill="none" stroke="rgb(0,0,0)"></path>
  <path d="M 208 60 L 208 25" fill="none" stroke="rgb(0,0,0)"></path>
  <path d="M 128 25 L 208 25" fill="none" stroke="rgb(0,0,0)"></path>
  <path d="M 128 25 L 128 32" fill="none" stroke="rgb(0,0,0)"></path>
  <polygon fill="rgb(0,0,0)" points="128,39 124,32 132,32 128,39" stroke="rgb(0,0,0)"></polygon>
  <rect fill="white" height="12" stroke="rgb(0,0,0)" width="46" x="153" y="4"></rect>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="8" font-style="normal" font-weight="normal" text-anchor="middle" textLength="30" x="176" y="14">Updates</text>
</svg>

</p>

<p>This is not a practical design. For one, self-modifying code is easy
to mess up. Let’s see how we might modify this architecture to get to something
we’re happy with.</p>

<h3 id="dfu-should-be-separate-from-the-application">DFU should be separate from the application</h3>

<p>The only time I ever broke DFU on a device, I did it without changing a line of
code related to DFU. Unbeknownst to me, our DFU processes accidentally depended on an
uninitialized variable which up until then had always ended up being <code>0</code>.
Inevitably a new version reshuffled the content of the stack, and all of a
sudden our uninitialized variable held a “1”. This prevented DFU from taking
place.<sup id="fnref:chris-dfu-debug"><a href="#fn:chris-dfu-debug">1</a></sup></p>

<p>The moral to this story: keep your DFU process and your application code
separate. Firmware update code is critical and should not be changed unless
absolutely necessary. Separating application code from firmware update code
allows us to update our application code without risking problems with DFU.</p>

<p>How do we modify our architecture to meet this requirement? We simply split the
firmware into a “Loader” and an “Application”. The loader verifies the
application, runs it, and can update it.</p>



<p>
  <svg viewBox="0 0 556 120" xmlns="http://www.w3.org/2000/svg" xmlns:inkspace="http://www.inkscape.org/namespaces/inkscape" xmlns:xlink="http://www.w3.org/1999/xlink">
  <defs id="defs_block">
    <filter height="1.504" id="filter_blur" inkspace:collect="always" width="1.1575" x="-0.07875" y="-0.252">
      <feGaussianBlur id="feGaussianBlur3780" inkspace:collect="always" stdDeviation="4.2"></feGaussianBlur>
    </filter>
  </defs>
  <title>blockdiag</title>
  <desc>
blockdiag {
    span_width = 100;
    // Set labels to nodes.
    A [label = "App Loader"];
    B [label = "Application"];
    A -&gt; B [label = "Loads, Updates", fontsize=8];
}
</desc>
  <rect fill="rgb(0,0,0)" height="40" stroke="rgb(0,0,0)" style="filter:url(#filter_blur);opacity:0.7;fill-opacity:1" width="128" x="103" y="46"></rect>
  <rect fill="rgb(0,0,0)" height="40" stroke="rgb(0,0,0)" style="filter:url(#filter_blur);opacity:0.7;fill-opacity:1" width="128" x="331" y="46"></rect>
  <rect fill="rgb(255,255,255)" height="40" stroke="rgb(0,0,0)" width="128" x="100" y="40"></rect>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="11" font-style="normal" font-weight="normal" text-anchor="middle" textLength="60" x="164" y="66">App Loader</text>
  <rect fill="rgb(255,255,255)" height="40" stroke="rgb(0,0,0)" width="128" x="328" y="40"></rect>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="11" font-style="normal" font-weight="normal" text-anchor="middle" textLength="66" x="392" y="66">Application</text>
  <path d="M 228 60 L 320 60" fill="none" stroke="rgb(0,0,0)"></path>
  <polygon fill="rgb(0,0,0)" points="327,60 320,56 320,64 327,60" stroke="rgb(0,0,0)"></polygon>
  <rect fill="white" height="12" stroke="rgb(0,0,0)" width="77" x="240" y="39"></rect>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="8" font-style="normal" font-weight="normal" text-anchor="middle" textLength="61" x="278" y="49">Loads, Updates</text>
</svg>

</p>

<h3 id="dfu-code-should-be-updatable">DFU code should be updatable</h3>

<p>While we want to update our DFU code as little as possible, updating it should
still be <em>possible</em>. Inevitably we will find a bug in our firmware update code
which we must fix. We may want to change our memory map to allocate more code
space to our app, or to rotate a security key baked into our Loader.</p>

<p>But where should the code that updates our Loader live? It cannot be in the
application, or else we would violate the previous principle. It cannot be in
the Loader itself either. That leaves one option: a third program tasked with
updating the loader. We’ll call it the “Updater”.</p>

<p>The Updater is loaded by the Loader, perhaps when a specific input is received.
All it knows how to do is update the Loader.</p>



<p>
  <svg viewBox="0 0 556 200" xmlns="http://www.w3.org/2000/svg" xmlns:inkspace="http://www.inkscape.org/namespaces/inkscape" xmlns:xlink="http://www.w3.org/1999/xlink">
  <defs id="defs_block">
    <filter height="1.504" id="filter_blur" inkspace:collect="always" width="1.1575" x="-0.07875" y="-0.252">
      <feGaussianBlur id="feGaussianBlur3780" inkspace:collect="always" stdDeviation="4.2"></feGaussianBlur>
    </filter>
  </defs>
  <title>blockdiag</title>
  <desc>
blockdiag {
    span_width = 100;
    // Set labels to nodes.
    A [label = "App Loader"];
    B [label = "Application"];
    A -&gt; B [label = "Loads, Updates", fontsize=8];

    E [label = "Updater"];
    A -&gt; E [label = "Loads, Updates", fontsize=8];
    E -&gt; A [label = "Updates", fontsize=8];
}
</desc>
  <rect fill="rgb(0,0,0)" height="40" stroke="rgb(0,0,0)" style="filter:url(#filter_blur);opacity:0.7;fill-opacity:1" width="128" x="103" y="46"></rect>
  <rect fill="rgb(0,0,0)" height="40" stroke="rgb(0,0,0)" style="filter:url(#filter_blur);opacity:0.7;fill-opacity:1" width="128" x="331" y="46"></rect>
  <rect fill="rgb(0,0,0)" height="40" stroke="rgb(0,0,0)" style="filter:url(#filter_blur);opacity:0.7;fill-opacity:1" width="128" x="331" y="126"></rect>
  <rect fill="rgb(255,255,255)" height="40" stroke="rgb(0,0,0)" width="128" x="100" y="40"></rect>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="11" font-style="normal" font-weight="normal" text-anchor="middle" textLength="60" x="164" y="66">App Loader</text>
  <rect fill="rgb(255,255,255)" height="40" stroke="rgb(0,0,0)" width="128" x="328" y="40"></rect>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="11" font-style="normal" font-weight="normal" text-anchor="middle" textLength="66" x="392" y="66">Application</text>
  <rect fill="rgb(255,255,255)" height="40" stroke="rgb(0,0,0)" width="128" x="328" y="120"></rect>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="11" font-style="normal" font-weight="normal" text-anchor="middle" textLength="42" x="392" y="146">Updater</text>
  <path d="M 228 60 L 320 60" fill="none" stroke="rgb(0,0,0)"></path>
  <polygon fill="rgb(0,0,0)" points="327,60 320,56 320,64 327,60" stroke="rgb(0,0,0)"></polygon>
  <path d="M 228 60 L 278 60" fill="none" stroke="rgb(0,0,0)"></path>
  <path d="M 278 60 L 278 140" fill="none" stroke="rgb(0,0,0)"></path>
  <path d="M 278 140 L 320 140" fill="none" stroke="rgb(0,0,0)"></path>
  <polygon fill="rgb(0,0,0)" points="327,140 320,136 320,144 327,140" stroke="rgb(0,0,0)"></polygon>
  <path d="M 456 140 L 481 140" fill="none" stroke="rgb(0,0,0)"></path>
  <path d="M 481 140 L 481 25" fill="none" stroke="rgb(0,0,0)"></path>
  <path d="M 164 25 L 481 25" fill="none" stroke="rgb(0,0,0)"></path>
  <path d="M 164 25 L 164 32" fill="none" stroke="rgb(0,0,0)"></path>
  <polygon fill="rgb(0,0,0)" points="164,39 160,32 168,32 164,39" stroke="rgb(0,0,0)"></polygon>
  <rect fill="white" height="12" stroke="rgb(0,0,0)" width="77" x="240" y="39"></rect>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="8" font-style="normal" font-weight="normal" text-anchor="middle" textLength="61" x="278" y="49">Loads, Updates</text>
  <rect fill="white" height="12" stroke="rgb(0,0,0)" width="77" x="240" y="119"></rect>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="8" font-style="normal" font-weight="normal" text-anchor="middle" textLength="61" x="278" y="129">Loads, Updates</text>
  <rect fill="white" height="12" stroke="rgb(0,0,0)" width="46" x="458" y="104"></rect>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="8" font-style="normal" font-weight="normal" text-anchor="middle" textLength="30" x="481" y="114">Updates</text>
</svg>

</p>

<h3 id="dfu-should-use-minimal-code-space">DFU should use minimal code space</h3>

<p>Every firmware project I’ve ever worked on has run out of code space. At Pebble,
we spent months porting our 3.0 firmware to the original watch; most of that
time was spent slimming down the code so it could fit within the 512KB of Flash
available on that device<sup id="fnref:pebble-3"><a href="#fn:pebble-3">2</a></sup>.</p>

<p>With that in mind, we should make sure our Loader and Updater do not take more
code space than absolutely necessary. Are there ways we can update our design to
use less code space? Absolutely!</p>

<p>The key insight here is that the Updater needs to run very rarely and that it
never needs to coexist with the application. We can, therefore, use the same
“slot” in flash for both the Updater and the Application. The main tradeoff here
is that our Loader update flow becomes more complicated as we need to do a DFU
to get the Updater, then another to update the loader, then a third to load the
application back. In other words:</p>

<p>Go to Loader → DFU Updater in the Application’s place → Load Updater →
DFU the new Loader → Reboot into Loader → DFU the Application back in its slot</p>

<p>We can tolerate this complexity because it should not be used often.</p>

<p>
  <svg viewBox="0 0 556 200" xmlns="http://www.w3.org/2000/svg" xmlns:inkspace="http://www.inkscape.org/namespaces/inkscape" xmlns:xlink="http://www.w3.org/1999/xlink">
  <defs id="defs_block">
    <filter height="1.504" id="filter_blur" inkspace:collect="always" width="1.1575" x="-0.07875" y="-0.252">
      <feGaussianBlur id="feGaussianBlur3780" inkspace:collect="always" stdDeviation="4.2"></feGaussianBlur>
    </filter>
  </defs>
  <title>blockdiag</title>
  <desc>
blockdiag {
    span_width = 100;
    // Set labels to nodes.
    A [label = "App Loader"];
    B [label = "Application"];
    A -&gt; B [label = "Loads, Updates", fontsize=8];

    E [label = "Updater"];
    A -&gt; E [label = "Loads, Updates", fontsize=8];
    E -&gt; A [label = "Updates", fontsize=8];

    group {
        label = "Slot 1";
        color = "LightPink";
        A;
    }
    group {
        label = "Slot 2";
        color = "LemonChiffon";
        B; E;
    }
}
</desc>
  <rect fill="rgb(255,182,193)" height="60" style="filter:url(#filter_blur)" width="152" x="88" y="30"></rect>
  <rect fill="rgb(255,250,205)" height="140" style="filter:url(#filter_blur)" width="152" x="316" y="30"></rect>
  <rect fill="rgb(0,0,0)" height="40" stroke="rgb(0,0,0)" style="filter:url(#filter_blur);opacity:0.7;fill-opacity:1" width="128" x="103" y="46"></rect>
  <rect fill="rgb(0,0,0)" height="40" stroke="rgb(0,0,0)" style="filter:url(#filter_blur);opacity:0.7;fill-opacity:1" width="128" x="331" y="46"></rect>
  <rect fill="rgb(0,0,0)" height="40" stroke="rgb(0,0,0)" style="filter:url(#filter_blur);opacity:0.7;fill-opacity:1" width="128" x="331" y="126"></rect>
  <rect fill="rgb(255,255,255)" height="40" stroke="rgb(0,0,0)" width="128" x="100" y="40"></rect>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="11" font-style="normal" font-weight="normal" text-anchor="middle" textLength="60" x="164" y="66">App Loader</text>
  <rect fill="rgb(255,255,255)" height="40" stroke="rgb(0,0,0)" width="128" x="328" y="40"></rect>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="11" font-style="normal" font-weight="normal" text-anchor="middle" textLength="66" x="392" y="66">Application</text>
  <rect fill="rgb(255,255,255)" height="40" stroke="rgb(0,0,0)" width="128" x="328" y="120"></rect>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="11" font-style="normal" font-weight="normal" text-anchor="middle" textLength="42" x="392" y="146">Updater</text>
  <path d="M 228 60 L 320 60" fill="none" stroke="rgb(0,0,0)"></path>
  <polygon fill="rgb(0,0,0)" points="327,60 320,56 320,64 327,60" stroke="rgb(0,0,0)"></polygon>
  <path d="M 228 60 L 278 60" fill="none" stroke="rgb(0,0,0)"></path>
  <path d="M 278 60 L 278 140" fill="none" stroke="rgb(0,0,0)"></path>
  <path d="M 278 140 L 320 140" fill="none" stroke="rgb(0,0,0)"></path>
  <polygon fill="rgb(0,0,0)" points="327,140 320,136 320,144 327,140" stroke="rgb(0,0,0)"></polygon>
  <path d="M 456 140 L 481 140" fill="none" stroke="rgb(0,0,0)"></path>
  <path d="M 481 140 L 481 25" fill="none" stroke="rgb(0,0,0)"></path>
  <path d="M 164 25 L 481 25" fill="none" stroke="rgb(0,0,0)"></path>
  <path d="M 164 25 L 164 32" fill="none" stroke="rgb(0,0,0)"></path>
  <polygon fill="rgb(0,0,0)" points="164,39 160,32 168,32 164,39" stroke="rgb(0,0,0)"></polygon>
  <rect fill="white" height="12" stroke="rgb(0,0,0)" width="77" x="240" y="39"></rect>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="8" font-style="normal" font-weight="normal" text-anchor="middle" textLength="61" x="278" y="49">Loads, Updates</text>
  <rect fill="white" height="12" stroke="rgb(0,0,0)" width="77" x="240" y="119"></rect>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="8" font-style="normal" font-weight="normal" text-anchor="middle" textLength="61" x="278" y="129">Loads, Updates</text>
  <rect fill="white" height="12" stroke="rgb(0,0,0)" width="46" x="458" y="104"></rect>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="8" font-style="normal" font-weight="normal" text-anchor="middle" textLength="30" x="481" y="114">Updates</text>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="11" font-style="normal" font-weight="normal" text-anchor="middle" textLength="36" x="164" y="36">Slot 1</text>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="11" font-style="normal" font-weight="normal" text-anchor="middle" textLength="36" x="392" y="36">Slot 2</text>
</svg>

</p>

<h3 id="dfu-failures-should-not-brick-the-device">DFU failures should not brick the device</h3>

<p>This one should be obvious. Whether there is a bug in our DFU process, or a power loss event while we are
writing firmware, the device should be able to recover. It may operate in a
degraded mode for a bit, but it should at least be able to update itself back to
a good state.</p>

<p>Our design already does a reasonable job of this: if we lose power in the middle
of an Application update, we can reboot into our Loader and start our update
again. There are however two failure modes we must deal with.</p>

<p>First, in the event we lose power while updating the Loader, we could find
ourselves with no valid image at the address the chip boots from (<code>0x0</code> by
default for Cortex-M, but aliased to <code>0x80000000</code> on STM32). The solution is to
add a small, immutable bootloader whose sole job is to sit at the start address
and load our Loader.</p>

<p>Second, what happens if we find ourselves without a functional Loader? We would
want to fall back to the Updater. Here again, the small bootloader is the
solution. In the event no valid Loader is found, it should try to load whatever
is found in the “Application” slot.</p>



<p>
  <svg viewBox="0 0 784 280" xmlns="http://www.w3.org/2000/svg" xmlns:inkspace="http://www.inkscape.org/namespaces/inkscape" xmlns:xlink="http://www.w3.org/1999/xlink">
  <defs id="defs_block">
    <filter height="1.504" id="filter_blur" inkspace:collect="always" width="1.1575" x="-0.07875" y="-0.252">
      <feGaussianBlur id="feGaussianBlur3780" inkspace:collect="always" stdDeviation="4.2"></feGaussianBlur>
    </filter>
  </defs>
  <title>blockdiag</title>
  <desc>
blockdiag {
    span_width = 100;
    // Set labels to nodes.
    C [label = "Bootloader"];
    A [label = "App Loader"];
    B [label = "Application"];
    C -&gt; A [label = "Loads", fontsize=8];
    A -&gt; B [label = "Ld, Updt", fontsize=8];

    E [label = "Updater"];
    A -&gt; E [label = "Ld, Updt", fontsize=8];
    E -&gt; A [label = "Updates", fontsize=8];
    C -&gt; E [label = "Loads", style=dashed, fontsize=8];

    group {
        label = "Slot 0";
        color = "PaleGreen";
        C;
    }
    group {
        label = "Slot 1";
        color = "LightPink";
        A;
    }
    group {
        label = "Slot 2";
        color = "LemonChiffon";
        B; E;
    }
}
</desc>
  <rect fill="rgb(152,251,152)" height="60" style="filter:url(#filter_blur)" width="152" x="88" y="30"></rect>
  <rect fill="rgb(255,182,193)" height="60" style="filter:url(#filter_blur)" width="152" x="544" y="30"></rect>
  <rect fill="rgb(255,250,205)" height="140" style="filter:url(#filter_blur)" width="152" x="316" y="110"></rect>
  <rect fill="rgb(0,0,0)" height="40" stroke="rgb(0,0,0)" style="filter:url(#filter_blur);opacity:0.7;fill-opacity:1" width="128" x="103" y="46"></rect>
  <rect fill="rgb(0,0,0)" height="40" stroke="rgb(0,0,0)" style="filter:url(#filter_blur);opacity:0.7;fill-opacity:1" width="128" x="559" y="46"></rect>
  <rect fill="rgb(0,0,0)" height="40" stroke="rgb(0,0,0)" style="filter:url(#filter_blur);opacity:0.7;fill-opacity:1" width="128" x="331" y="126"></rect>
  <rect fill="rgb(0,0,0)" height="40" stroke="rgb(0,0,0)" style="filter:url(#filter_blur);opacity:0.7;fill-opacity:1" width="128" x="331" y="206"></rect>
  <rect fill="rgb(255,255,255)" height="40" stroke="rgb(0,0,0)" width="128" x="100" y="40"></rect>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="11" font-style="normal" font-weight="normal" text-anchor="middle" textLength="60" x="164" y="66">Bootloader</text>
  <rect fill="rgb(255,255,255)" height="40" stroke="rgb(0,0,0)" width="128" x="556" y="40"></rect>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="11" font-style="normal" font-weight="normal" text-anchor="middle" textLength="60" x="620" y="66">App Loader</text>
  <rect fill="rgb(255,255,255)" height="40" stroke="rgb(0,0,0)" width="128" x="328" y="120"></rect>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="11" font-style="normal" font-weight="normal" text-anchor="middle" textLength="66" x="392" y="146">Application</text>
  <rect fill="rgb(255,255,255)" height="40" stroke="rgb(0,0,0)" width="128" x="328" y="200"></rect>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="11" font-style="normal" font-weight="normal" text-anchor="middle" textLength="42" x="392" y="226">Updater</text>
  <path d="M 228 60 L 548 60" fill="none" stroke="rgb(0,0,0)"></path>
  <polygon fill="rgb(0,0,0)" points="555,60 548,56 548,64 555,60" stroke="rgb(0,0,0)"></polygon>
  <path d="M 228 60 L 278 60" fill="none" stroke="rgb(0,0,0)" stroke-dasharray="4"></path>
  <path d="M 278 60 L 278 220" fill="none" stroke="rgb(0,0,0)" stroke-dasharray="4"></path>
  <path d="M 278 220 L 320 220" fill="none" stroke="rgb(0,0,0)" stroke-dasharray="4"></path>
  <polygon fill="rgb(0,0,0)" points="327,220 320,216 320,224 327,220" stroke="rgb(0,0,0)"></polygon>
  <path d="M 620 80 L 620 100" fill="none" stroke="rgb(0,0,0)"></path>
  <path d="M 392 100 L 527 100" fill="none" stroke="rgb(0,0,0)"></path>
  <path d="M 527.0 100.0 A4,4 0 0 1 535.0 100.0" fill="none" stroke="rgb(0,0,0)"></path>
  <path d="M 535 100 L 620 100" fill="none" stroke="rgb(0,0,0)"></path>
  <path d="M 392 100 L 392 112" fill="none" stroke="rgb(0,0,0)"></path>
  <polygon fill="rgb(0,0,0)" points="392,119 388,112 396,112 392,119" stroke="rgb(0,0,0)"></polygon>
  <path d="M 620 80 L 620 180" fill="none" stroke="rgb(0,0,0)"></path>
  <path d="M 392 180 L 527 180" fill="none" stroke="rgb(0,0,0)"></path>
  <path d="M 527.0 180.0 A4,4 0 0 1 535.0 180.0" fill="none" stroke="rgb(0,0,0)"></path>
  <path d="M 535 180 L 620 180" fill="none" stroke="rgb(0,0,0)"></path>
  <path d="M 392 180 L 392 192" fill="none" stroke="rgb(0,0,0)"></path>
  <polygon fill="rgb(0,0,0)" points="392,199 388,192 396,192 392,199" stroke="rgb(0,0,0)"></polygon>
  <path d="M 456 220 L 531 220" fill="none" stroke="rgb(0,0,0)"></path>
  <path d="M 531 220 L 531 60" fill="none" stroke="rgb(0,0,0)"></path>
  <path d="M 531 60 L 548 60" fill="none" stroke="rgb(0,0,0)"></path>
  <polygon fill="rgb(0,0,0)" points="555,60 548,56 548,64 555,60" stroke="rgb(0,0,0)"></polygon>
  <rect fill="white" height="12" stroke="rgb(0,0,0)" width="37" x="374" y="39"></rect>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="8" font-style="normal" font-weight="normal" text-anchor="middle" textLength="21" x="392" y="49">Loads</text>
  <rect fill="white" height="12" stroke="rgb(0,0,0)" width="37" x="260" y="199"></rect>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="8" font-style="normal" font-weight="normal" text-anchor="middle" textLength="21" x="278" y="209">Loads</text>
  <rect fill="white" height="12" stroke="rgb(0,0,0)" width="50" x="424" y="84"></rect>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="8" font-style="normal" font-weight="normal" text-anchor="middle" textLength="34" x="449" y="94">Ld, Updt</text>
  <rect fill="white" height="12" stroke="rgb(0,0,0)" width="50" x="424" y="164"></rect>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="8" font-style="normal" font-weight="normal" text-anchor="middle" textLength="34" x="449" y="174">Ld, Updt</text>
  <rect fill="white" height="12" stroke="rgb(0,0,0)" width="46" x="483" y="184"></rect>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="8" font-style="normal" font-weight="normal" text-anchor="middle" textLength="30" x="506" y="194">Updates</text>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="11" font-style="normal" font-weight="normal" text-anchor="middle" textLength="36" x="164" y="36">Slot 0</text>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="11" font-style="normal" font-weight="normal" text-anchor="middle" textLength="36" x="620" y="36">Slot 1</text>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="11" font-style="normal" font-weight="normal" text-anchor="middle" textLength="36" x="392" y="116">Slot 2</text>
</svg>

</p>

<p>In summary, we end up with four programs:</p>

<ol>
  <li>An immutable Bootloader whose sole job is to load the Loader, and fallback to
another image if the Loader is invalid.</li>
  <li>A Loader that can verify our Application image, load it, and update it.</li>
  <li>An Application which does not do any updates itself</li>
  <li>An Updater that temporarily replaces the Application and can update the
Loader.</li>
</ol>

<p>This is not the only valid firmware update architecture, but it avoids many of
the pitfalls of DFU without consuming too much code space.</p>

<h2 id="design-patterns--recipes">Design Patterns &amp; Recipes</h2>

<p>I have put together a full implementation of the Bootloader, the Loader, and the
Application in the <a href="https://github.com/memfault/interrupt/tree/master/example/fwup-architecture">Interrupt
Github
repository</a>.
While discussing every line in detail is outside of the scope of this
conversation, I want to highlight a few patterns I have learned over the years.
These include ways to package firmware images, write them to flash, share data
between programs, and more!</p>

<p>This post builds upon many ideas previously written about on Interrupt. If you
haven’t read them already, I recommend the following:</p>
<ul>
  <li><a href="https://interrupt.memfault.com/how-to-write-a-bootloader-from-scratch">How to Write a Bootloader from Scratch</a></li>
  <li><a href="https://interrupt.memfault.com/how-to-write-linker-scripts-for-firmware">How to Write Linker Scripts for Firmware</a></li>
  <li><a href="https://interrupt.memfault.com/gnu-build-id-for-firmware">GNU Build IDs for Firmware</a></li>
  <li><a href="https://interrupt.memfault.com/firmware-shell">Building a Tiny CLI Shell for Tiny Firmware</a></li>
</ul>

<h3 id="image-metadata">Image Metadata</h3>

<p>Firmware images typically …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://interrupt.memfault.com/blog/device-firmware-update-cookbook">https://interrupt.memfault.com/blog/device-firmware-update-cookbook</a></em></p>]]>
            </description>
            <link>https://interrupt.memfault.com/blog/device-firmware-update-cookbook</link>
            <guid isPermaLink="false">hacker-news-small-sites-23631985</guid>
            <pubDate>Wed, 24 Jun 2020 18:33:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Harm of Studying Abroad]]>
            </title>
            <description>
<![CDATA[
Score 85 | Comments 109 (<a href="https://news.ycombinator.com/item?id=23631503">thread link</a>) | @jeffreyrogers
<br/>
June 24, 2020 | https://www.readingthechinadream.com/zhang-yongle-the-harm-of-studying-abroad.html | <a href="https://web.archive.org/web/*/https://www.readingthechinadream.com/zhang-yongle-the-harm-of-studying-abroad.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.readingthechinadream.com/zhang-yongle-the-harm-of-studying-abroad.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23631503</guid>
            <pubDate>Wed, 24 Jun 2020 17:59:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Linux is Most Used OS in Microsoft Azure]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23631370">thread link</a>) | @crpietschmann
<br/>
June 24, 2020 | https://build5nines.com/linux-is-most-used-os-in-microsoft-azure-over-50-percent-fo-vm | <a href="https://web.archive.org/web/*/https://build5nines.com/linux-is-most-used-os-in-microsoft-azure-over-50-percent-fo-vm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-content">
		<div>
		<div id="content-area">
			<div id="left-area">
											<article id="post-28288">
											 <!-- .et_post_meta_wrapper -->
				
					<div>
					
<p>For the last few years, Microsoft has stated during event keynotes and in other places that Linux is a rapidly growing operating system (OS) being used within Microsoft Azure. They had proudly stated that 50% of new VMs running in Azure were running Linux. (This is the latest stat I remember Microsoft saying publicly a while back already.) Well, I came across an interesting<a href="https://www.linkedin.com/posts/adirron_linuxonazure-progress-activity-6665502370795003905-DY1G" target="_blank" rel="noopener"> infographic recently (thanks to Adir Ron) </a>that gives some statistics and other information regarding the percentage and overall usage of the Linux OS in Microsoft Azure.</p>



<p>Based on the past growth of Linux adoption in Microsoft Azure, I’ve long suspected that Microsoft Azure hosts more Linux VMs than Windows VMs. This infographic looks to shed some light on this most likely being true, as it states “More than 50% of VM cores runs Linux on Azure”.</p>



<p>Before you look at the infographic itself, here are a few stats listed in it that I’d like to point out:</p>



<ul><li>More than 50% of VM cores runs Linux on Azure</li><li>Linux-based images comprise 60% of Azure Marketplace images</li><li>Top 100 Microsoft customers deploy Linux workloads on Azure</li><li>Azure Tuned Kernels provide 25% faster network throughput</li><li>Microsoft supports all major Linux distros, like: Red Hat, SUSE, Ubuntu, Oracle Linux, Debian, CentOS, CoreOS, and OpenSUSE <em>(Related: Azure also supports FreeBSD)</em></li><li>Azure offers two natively supported managed Kubernetes orchestration services: Azure Kubernetes Service, and Azure Red Hat OpenShift</li></ul>



<p>Here’s the “Did you know? Linux is the fastest growing platform on Azure” <a href="https://build5nines.com/tag/infographic/">infographic</a> below:</p>



<figure><a href="https://i1.wp.com/build5nines.com/wp-content/uploads/2020/05/Linux-fastest-growing-platform-on-microsoft-azure-2020-05-11.jpg?ssl=1" target="_blank" rel="noopener noreferrer"><img data-attachment-id="28289" data-permalink="https://build5nines.com/linux-is-most-used-os-in-microsoft-azure-over-50-percent-fo-vm-cores/linux-fastest-growing-platform-on-microsoft-azure-2020-05-11/" data-orig-file="https://i1.wp.com/build5nines.com/wp-content/uploads/2020/05/Linux-fastest-growing-platform-on-microsoft-azure-2020-05-11.jpg?fit=1200%2C4464&amp;ssl=1" data-orig-size="1200,4464" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Linux-fastest-growing-platform-on-microsoft-azure-2020-05-11" data-image-description="" data-medium-file="https://i1.wp.com/build5nines.com/wp-content/uploads/2020/05/Linux-fastest-growing-platform-on-microsoft-azure-2020-05-11.jpg?fit=81%2C300&amp;ssl=1" data-large-file="https://i1.wp.com/build5nines.com/wp-content/uploads/2020/05/Linux-fastest-growing-platform-on-microsoft-azure-2020-05-11.jpg?fit=275%2C1024&amp;ssl=1" src="https://i1.wp.com/build5nines.com/wp-content/uploads/2020/05/Linux-fastest-growing-platform-on-microsoft-azure-2020-05-11.jpg?fit=275%2C1024&amp;ssl=1" alt="Linux is Most Used OS in Microsoft Azure - over 50 percent of VM cores 1" width="275" height="1024" srcset="https://i1.wp.com/build5nines.com/wp-content/uploads/2020/05/Linux-fastest-growing-platform-on-microsoft-azure-2020-05-11.jpg?w=1200&amp;ssl=1 1200w, https://i1.wp.com/build5nines.com/wp-content/uploads/2020/05/Linux-fastest-growing-platform-on-microsoft-azure-2020-05-11.jpg?resize=275%2C1024&amp;ssl=1 275w, https://i1.wp.com/build5nines.com/wp-content/uploads/2020/05/Linux-fastest-growing-platform-on-microsoft-azure-2020-05-11.jpg?resize=768%2C2857&amp;ssl=1 768w, https://i1.wp.com/build5nines.com/wp-content/uploads/2020/05/Linux-fastest-growing-platform-on-microsoft-azure-2020-05-11.jpg?resize=413%2C1536&amp;ssl=1 413w, https://i1.wp.com/build5nines.com/wp-content/uploads/2020/05/Linux-fastest-growing-platform-on-microsoft-azure-2020-05-11.jpg?resize=1080%2C4018&amp;ssl=1 1080w, https://i1.wp.com/build5nines.com/wp-content/uploads/2020/05/Linux-fastest-growing-platform-on-microsoft-azure-2020-05-11.jpg?resize=980%2C3646&amp;ssl=1 980w, https://i1.wp.com/build5nines.com/wp-content/uploads/2020/05/Linux-fastest-growing-platform-on-microsoft-azure-2020-05-11.jpg?resize=480%2C1786&amp;ssl=1 480w" sizes="(max-width: 275px) 100vw, 275px" title="Linux is Most Used OS in Microsoft Azure - over 50 percent of VM cores 1" data-lazy-srcset="https://i1.wp.com/build5nines.com/wp-content/uploads/2020/05/Linux-fastest-growing-platform-on-microsoft-azure-2020-05-11.jpg?w=1200&amp;ssl=1 1200w, https://i1.wp.com/build5nines.com/wp-content/uploads/2020/05/Linux-fastest-growing-platform-on-microsoft-azure-2020-05-11.jpg?resize=275%2C1024&amp;ssl=1 275w, https://i1.wp.com/build5nines.com/wp-content/uploads/2020/05/Linux-fastest-growing-platform-on-microsoft-azure-2020-05-11.jpg?resize=768%2C2857&amp;ssl=1 768w, https://i1.wp.com/build5nines.com/wp-content/uploads/2020/05/Linux-fastest-growing-platform-on-microsoft-azure-2020-05-11.jpg?resize=413%2C1536&amp;ssl=1 413w, https://i1.wp.com/build5nines.com/wp-content/uploads/2020/05/Linux-fastest-growing-platform-on-microsoft-azure-2020-05-11.jpg?resize=1080%2C4018&amp;ssl=1 1080w, https://i1.wp.com/build5nines.com/wp-content/uploads/2020/05/Linux-fastest-growing-platform-on-microsoft-azure-2020-05-11.jpg?resize=980%2C3646&amp;ssl=1 980w, https://i1.wp.com/build5nines.com/wp-content/uploads/2020/05/Linux-fastest-growing-platform-on-microsoft-azure-2020-05-11.jpg?resize=480%2C1786&amp;ssl=1 480w" data-lazy-src="https://i1.wp.com/build5nines.com/wp-content/uploads/2020/05/Linux-fastest-growing-platform-on-microsoft-azure-2020-05-11.jpg?fit=275%2C1024&amp;ssl=1&amp;is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></figure>



<p>Happy running Linux in Azure!</p>



<blockquote><p>P.S. If you’re looking to save money hosting VMs in Microsoft Azure (both Windows and Linux), you should read my article showing you how to <a href="https://build5nines.com/properly-shutdown-azure-vm-to-save-money/">properly shutdown Azure VMs to save money</a>!</p></blockquote>

<br><h3>Article Author</h3>
					<div id="author-info">
						<p><img alt="" src="https://secure.gravatar.com/avatar/d565ce4d3fdf8007e1d707362cca9465?s=128&amp;d=identicon&amp;r=g" srcset="https://secure.gravatar.com/avatar/d565ce4d3fdf8007e1d707362cca9465?s=256&amp;d=identicon&amp;r=g 2x" height="128" width="128" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7">																						<img id="author-img-mvp" src="https://build5nines.com/wp-content/uploads/2019/08/mvp_logo_horizontal_preferred_cyan300_rgb_300ppi_163x65.png" alt="Microsoft MVP">
													</p>
						
						<p id="author-desc">Chris is a <strong>Microsoft MVP</strong> and has 20 years of experience designing and building Cloud &amp; Enterprise systems. He is also a <strong>Microsoft Certified: Azure Solutions Architect</strong>, developer, <strong>Microsoft Certified Trainer</strong> (MCT), and Cloud Advocate. He has a passion for technology and sharing what he learns with others to help enable them to learn faster and be more productive.</p>
						
					</div>
					
						
										</div> <!-- .entry-content -->
					 <!-- .et_post_meta_wrapper -->
				</article> <!-- .et_pb_post -->

						</div> <!-- #left-area -->

				 <!-- end #sidebar -->
		</div> <!-- #content-area -->
	</div> <!-- .container -->
	</div></div>]]>
            </description>
            <link>https://build5nines.com/linux-is-most-used-os-in-microsoft-azure-over-50-percent-fo-vm</link>
            <guid isPermaLink="false">hacker-news-small-sites-23631370</guid>
            <pubDate>Wed, 24 Jun 2020 17:51:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I Built Calendly in 3 Hours]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23631119">thread link</a>) | @benn_88
<br/>
June 24, 2020 | https://anvil.works/learn/examples/calendly | <a href="https://web.archive.org/web/*/https://anvil.works/learn/examples/calendly">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
        <svg width="100%" height="110" viewBox="0 0 460.8 20" xmlns="http://www.w3.org/2000/svg" version="1.1" preserveAspectRatio="xMidYMax slice" style="fill:#f7fdff;stroke:none;">
          <use xlink:href="#img-concave"></use>
        </svg>
        
  <section>
      <div>
          <article>
              



<p><a href="https://anvil.works/learn/examples/meter-feeder">Part 1 of this series: Meter Feeder in 1.5 hours &gt;</a></p>

<p>How long <em>does</em> it take to prototype a startup? When we look at a product like <a href="https://calendly.com/">Calendly</a>, it’s hard to imagine scheduling meetings without it. But when Tope Awotona first had the idea, it wasn’t obvious that it would take off. He had to build a prototype.</p>

<p>Prototyping is always a risk – it’s easy to spend months building something that nobody wants. But if you <em>have</em> a prototype, those conversations with initial customers are so much easier. So we’re setting out to see how fast we can get that crucial prototype. If we can get it down to days, or even hours, we’re onto a winner:</p>

<div>
    
    <div>
        <p>Launching a mediocre product as soon as possible, and then talking to customers and iterating, is much better than waiting to build the “perfect” product.</p>
        <h4>Geoff Ralston and Michael Seibel</h4>
        <h5>in Y Combinator’s <a href="https://blog.ycombinator.com/ycs-essential-startup-advice/">Essential Startup Advice</a></h5>
    </div>
</div>

<p>Our secret weapon is <a href="https://anvil.works/">Anvil</a>. It’s a platform for building web apps without the fuss: it’s got a visual interface designer, client- and server-side code is all in Python, and it deploys to the cloud with one click.</p>

<hr>

<h2 id="the-build">The Build</h2>

<p>I’ll walk you through the design process, show you some screenshots, and give a breakdown of how long each stage took:</p>

<h3 id="1-google-integration-and-user-setup-30-minutes">1. Google Integration and User Setup (30 minutes)</h3>

<p>Calendly connects to your calendar to automatically check availability, so you don’t need those endless back-and-forth emails. Integrating an OAuth flow with Google Calendar could take all day, but Anvil’s <a href="https://anvil.works/docs/integrations/google">Google integration</a> makes it really simple:</p>

<div title="Client-side Python" tabindex="0"><div><pre><code data-lang="python"><span>anvil</span><span>.</span><span>google</span><span>.</span><span>auth</span><span>.</span><span>login</span><span>([</span><span>'https://www.googleapis.com/auth/calendar'</span><span>])</span></code></pre></div></div>


<p>That gives us a login screen:</p>


<div>
    <figure><img src="https://anvil.works/learn/examples/img/calendly/google_auth_screen.png" alt="Google OAuth Screen"> <figcaption>
                <p>Google OAuth Screen</p>
            </figcaption>
    </figure>
</div>

<p>And now we have the OAuth tokens to use with the Calendar API:
</p><div title="Server-side Python" tabindex="0"><div><pre><code data-lang="python"><span>refresh_token</span> <span>=</span> <span>anvil</span><span>.</span><span>google</span><span>.</span><span>auth</span><span>.</span><span>get_user_refresh_token</span><span>()</span>
<span>access_token</span>  <span>=</span> <span>anvil</span><span>.</span><span>google</span><span>.</span><span>auth</span><span>.</span><span>refresh_access_token</span><span>(</span><span>refresh_token</span><span>)</span></code></pre></div></div>


<p>To keep the refresh token secure from prying eyes, we encrypt it with Anvil’s <a href="https://anvil.works/docs/security/encrypting-secret-data">Secrets Service</a>, then store it in a <a href="https://anvil.works/docs/data-tables">Data Table</a>:</p>

<div title="Server-side Python" tabindex="0"><div><pre><code data-lang="python"><span>user</span><span>[</span><span>'refresh_token'</span><span>]</span> <span>=</span> <span>anvil</span><span>.</span><span>secrets</span><span>.</span><span>encrypt_with_key</span><span>(</span><span>'token_key'</span><span>,</span> <span>refresh_token</span><span>)</span></code></pre></div></div>


<hr>

<h3 id="2-basic-interaction-1-hour-15-minutes">2. Basic Interaction (1 hour 15 minutes)</h3>

<p>There are two parties here - the Organiser, who is advertising their availability, and the Attendee, who is picking a meeting time with them.</p>

<p>We make a <strong>Settings</strong> page, so the Organiser can specify the length of their meeting slots, and give them a unique URL they can provide to their attendees:</p>


<div>
    <figure><img src="https://anvil.works/learn/examples/img/calendly/beta_settings.png" alt="The Organiser configures their settings"> <figcaption>
                <p>The Organiser configures their settings</p>
            </figcaption>
    </figure>
</div>

<p>When the Attendee clicks that link, they get the <strong>Booking</strong> page, where they can choose a meeting (at any time, for now), then provide their details to confirm their slot.</p>


<div>
    <figure><img src="https://anvil.works/learn/examples/img/calendly/attendee_details.png" alt="The Attendee enters their details"> <figcaption>
                <p>The Attendee enters their details</p>
            </figcaption>
    </figure>
</div>

<p>We create a calendar event by POSTing to the <a href="https://developers.google.com/calendar/concepts">Google Calendar API</a>, using the Organiser’s OAuth tokens. (Google’s API docs are somewhat confusing, but the <a href="https://anvil.works/docs/integrations/google/google-rest-apis">Anvil docs</a> show us how.)</p>


<div>
    <figure><img src="https://anvil.works/learn/examples/img/calendly/calendar_event.png" alt="Calendar event"> <figcaption>
                <p>Calendar event</p>
            </figcaption>
    </figure>
</div>

<p>We then send an email to tell the Organiser about the new booking:<br>(Sending email is <a href="https://anvil.works/docs/email/sending_and_receiving#sending-email">one line of code</a> with Anvil – it’s all built in!)

</p><div>
    <figure><img src="https://anvil.works/learn/examples/img/calendly/email_example.png" alt="Example email"> <figcaption>
                <p>Example email</p>
            </figcaption>
    </figure>
</div>

<hr>

<h3 id="3-adjust-availability-55-mins">3. Adjust Availability (55 mins)</h3>

<p>Of course, the real magic of Calendly is that the Organiser can specify their availability, and we avoid clashing with existing appointments.</p>

<p>Let’s tackle the first one first: We need a page for the Organiser to set up the times they’re willing to meet:</p>


<div>
    <figure><img src="https://anvil-website-static.s3.eu-west-2.amazonaws.com/learn/examples/calendly/availability.gif" alt="Booking a meeting"> <figcaption>
                <p>Booking a meeting</p>
            </figcaption>
    </figure>
</div>

<p>The data structure was the tricky part here, but Python’s <code>datetime</code> module simplified this process – especially as we can use <a href="https://anvil.works/python-browser">Python in the browser</a> too!</p>

<p>I didn’t need to keep translating from Python <code>datetime</code> objects, to JSON, to Javascript <code>Date</code> objects, and back again. This melted my brain a lot less than it might have done.</p>

<hr>

<h3 id="4-timezone-awareness-15-minutes">4. Timezone Awareness (15 minutes)</h3>

<p>Timezones are a minefield. Having an Organiser in one timezone and an Attendee in a different timezone is a real headache – we can’t sensibly ask the Attendee to mentally convert the times in their head!</p>

<p>Nobody wants to write their own timezone module, but Python has <code>pytz</code>, which is available on the Anvil server, and we can use Anvil’s <a href="https://anvil.works/docs/server/dealing-with-timezones">timezone library</a> to capture the timezone of the browser:</p>

<div title="Client-side Python" tabindex="0"><div><pre><code data-lang="python"><span>import</span> <span>anvil.tz</span>
<span>browser_tz</span> <span>=</span> <span>anvil</span><span>.</span><span>tz</span><span>.</span><span>tzlocal</span><span>()</span></code></pre></div></div>


<p>So if the Organiser is in the UK, and available from 12pm-3pm on Thursdays, and I’m in Malaysia…</p>


<div>
    <figure><img src="https://anvil.works/learn/examples/img/calendly/timezone.png" alt="Pick a slot &amp;ndash; in my timezone!"> <figcaption>
                <p>Pick a slot – in my timezone!</p>
            </figcaption>
    </figure>
</div>

<hr>

<h3 id="5-avoiding-calendar-clashes-20-minutes">5. Avoiding Calendar Clashes (20 minutes)</h3>

<p>A booking system would be useless if it allowed two bookings at the same time! So we use the Google Calendar API to get a list of events when the Organiser is ‘busy’, and only offer Attendees slots when the Organiser is available:</p>


<div>
    <figure><img src="https://anvil.works/learn/examples/img/calendly/calendar_busy_1.png" alt="Prior engagement"> <figcaption>
                <p>Prior engagement</p>
            </figcaption>
    </figure>
</div>


<div>
    <figure><img src="https://anvil.works/learn/examples/img/calendly/calendar_busy_2.png" alt="No slots due to prior engagement"> <figcaption>
                <p>No slots due to prior engagement</p>
            </figcaption>
    </figure>
</div>

<hr>

<h2 id="total-time-3-hours-15-minutes">Total Time: 3 hours 15 minutes</h2>

<p>And that’s it! We’ve prototyped a fully functioning booking system, and <strong>it’s not even lunchtime</strong>.</p>

<p>We can spend the afternoon showing it to potential users, and watching them interact with it. If they get stuck on something, we can rebuild it tomorrow!</p>

<hr>

<p>Want to see the source code and explore it yourself? Click this fine link:</p>




<p><em>To run the app yourself, you’ll need your own <code>client_id</code> and <code>client_secret</code> for the Google API. Following the steps in the Anvil docs: <a href="https://anvil.works/docs/integrations/google/linking-google-and-anvil">Linking Google to Anvil</a>.</em></p>

<hr>

<h2 id="more-rapid-prototypes">More Rapid Prototypes</h2>

<p>Want to see more rapid prototyping? We’ve rebuilt a few famous startups in record time.</p>

<p>Here’s another one:</p>




          </article>
      </div>
      
  </section>

    </div></div>]]>
            </description>
            <link>https://anvil.works/learn/examples/calendly</link>
            <guid isPermaLink="false">hacker-news-small-sites-23631119</guid>
            <pubDate>Wed, 24 Jun 2020 17:34:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Organisational Benefits of Kubernetes]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23630537">thread link</a>) | @mstipetic
<br/>
June 24, 2020 | https://www.msb.com/post/organisational-benefits-of-kubernetes | <a href="https://web.archive.org/web/*/https://www.msb.com/post/organisational-benefits-of-kubernetes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="7.10.5"><div dir="ltr"><div><div id="viewer-6scun"><div><div data-hook="imageViewer"><div role="img"><p><img data-pin-url="https://www.msb.com/post/organisational-benefits-of-kubernetes" data-pin-media="https://static.wixstatic.com/media/nsplsh_437073544155506f536377~mv2.jpg/v1/fit/w_5000,h_4000,al_c,q_80/file.png" src="https://static.wixstatic.com/media/nsplsh_437073544155506f536377~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p><svg viewBox="0 0 19 19"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 01-.283 0l-.374-.374a.2.2 0 010-.283l4.356-4.355h-3.786a.2.2 0 01-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 01-.2.2h-.529a.2.2 0 01-.2-.2zm-6.5 6.9v.529a.2.2 0 01-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 01.283 0l.374.374a.2.2 0 010 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z"></path></svg></div></div></div></div><p id="viewer-bavv2">Before actual collaboration with companies and providing our professional Kubernetes training, we often have to explain the benefits of Kubernetes to several stakeholders, especially at the enterprise level.</p><p id="viewer-4ceqi">We believe that the Kubernetes community does a very good job explaining the technical details and benefits of switching to its technology base. However we also believe that we can do an even better job at advocating it at the management level.</p><p id="viewer-43jln">Technical champions inside organisations sometimes have a hard time understanding the perspectives of various stakeholders inside their organisations, so we thought we'd make a "how to convince your boss" list of benefits of a Kubernetes transition to communicate its advantages more effectively.</p><p id="viewer-7j4al">Most benefits can be summarised in one word - standardisation, but let's dig a bit into specifics.</p><p id="viewer-9a4oj">Some of the benefits of a Kubernetes transition include:</p><ol><li id="viewer-cso6i"><p>Standardised hiring</p></li><li id="viewer-c7lvl"><p>Standardised configuration management, removing knowledge silos</p></li><li id="viewer-bblnl"><p>Enforcing standards</p></li><li id="viewer-117hv"><p>Easy access to a huge software ecosystem</p></li><li id="viewer-63hfg"><p>Removing vendor lock-in</p></li></ol><h2 id="viewer-1u0ie">Standardised hiring</h2><p id="viewer-24hq1">A standard job post for a backend/DevOps person just a few years ago used to include a list of requirements which usually included a permutation of several of the many technologies available at the time (Puppet, Chef, Ansible, Docker Swarm, Mesos...), mostly driven by the requirements bespoke backends of each company.</p><p id="viewer-4dcjd">To achieve things coming out-of-the-box with Kubernetes, backend and DevOps teams usually built their own solutions out of necessity, using tools they were personally familiar with. <span>This made finding people with exact needed skillsets hard and usually included a long onboarding time.</span></p><p id="viewer-5gpog"><span>Looking at job postings of companies utilising k8s right now we see a simplified job posting, focusing on Kubernetes experience with a few "nice to have" skills.</span></p><p id="viewer-b4hgh"><span>A big objection to keep in mind is that Kubernetes is a fairly young technology and finding qualified engineers can be harder, but a whole ecosystem of education and certification has sprung up in recent years (including MSB), so it's becoming less relevant.</span></p><h2 id="viewer-95rl0"><span>Standardised configuration management</span></h2><p id="viewer-3g20d"><span>A major advantage, that we feel is not being talked about enough is standardisation of configuration management inside k8s.</span></p><p id="viewer-51jbs"><span>In every company I've personally worked in the past, a large part of onboarding has been just knowing how to store, use and find various configurations necessary to access in my services. There were usually a few "old-timer" DevOps who knew how everything fits together and where the various configurations were stored, and they were indispensable to the running of the company.</span></p><p id="viewer-16kj9"><span>In companies that are advanced k8s users we currently see the DevOps teams being freed up to focus on process automation, building whole project templates that allow you spin up and integrate whole services in no time, with security, secret management and processes built in, so engineers can focus on building the actual services. This allows engineers not only to build their own services, but also to be able to quickly jump into other teams' services and have a good understanding of how things work.</span></p><h2 id="viewer-3frfv"><span>Enforcing standards</span></h2><p id="viewer-d1aau"><span>A big part of Kubernetes' mechanisms that don't get enough attention are mechanisms that allow you to encode various security and process requirements into the cluster itself, ensuring a standard baseline of security and governance practices that have to be respected before a workload is permitted to be deployed on the cluster.</span></p><p id="viewer-ckorf"><span>Various </span><a href="https://kubernetes.io/blog/2019/03/21/a-guide-to-kubernetes-admission-controllers/" target="_blank" rel="noopener"><span><u>admission controllers</u></span></a><span> allow you to enforce best practices through code and reduce micromanagement overhead of your teams.</span></p><p id="viewer-3hl1c"><span>This is a somewhat advanced topic, but we think it's not discussed enough and important enough that we have a </span><a href="https://msb.com/bootcamp" target="_blank" rel="noopener"><span><u>whole day training</u></span></a><span> devoted just for this topic.</span></p><h2 id="viewer-c6e8"><span>Easy access to a huge software ecosystem</span></h2><p id="viewer-78d9r">Almost every open-source or commercial project currently offers a Helm chart or a Custom Operator to deploy directly into your cluster using a standardised and fully configurable interface.</p><p id="viewer-ekvv2">Here's an example of a highly available postgres cluster being deployed with one command and visualised using the MSB platform:</p><p id="viewer-1bh23">This allows teams to choose technologies needed for running their services and spend minimal time deploying them, while knowing best practices are followed. Most engineers are not experts in deploying things like high availability elasticsearch clusters, and before k8s a lot of preparation had to take place to ensure a production-ready system. Currently we get the benefit of the community or vendors spending time optimising their packages, so we can easily configure and use them.</p><h2 id="viewer-e3d4">Removing vendor lock-in</h2><p id="viewer-sgsh">This point has been reiterated multiple times, and research shows that organisations rarely take advantage of it, but it's still important to keep in mind. Kubernetes provides a standard API to which all cloud providers have to conform to, giving you the flexibility to negotiate and switch providers once operating at a significant scale.</p><p id="viewer-a1ig9">We hope you'll take these points into consideration when deciding on your Kubernetes strategy, or they will be useful to you to convince your organisation to make the switch.</p><p id="viewer-69s9s">If you'd like to hear first hand from a professional selling k8s into organisations, please have a listen to our <a href="https://www.msb.com/podcast/episode/37572d1a/001-kubernetes-enterprise-adoption-with-jeroen-overmaat" target="_blank" rel="noopener"><u>podcast episode</u></a> with Jeroen Overmaat, Rancher NEMEA Regional Director</p></div></div></div></div></article></div></div>]]>
            </description>
            <link>https://www.msb.com/post/organisational-benefits-of-kubernetes</link>
            <guid isPermaLink="false">hacker-news-small-sites-23630537</guid>
            <pubDate>Wed, 24 Jun 2020 16:54:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mathematics and Its Symbols]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23630288">thread link</a>) | @R3G1R
<br/>
June 24, 2020 | https://mathvault.ca/hub/higher-math/math-symbols/ | <a href="https://web.archive.org/web/*/https://mathvault.ca/hub/higher-math/math-symbols/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><p> <span>T</span>he language and vocabulary of mathematics contain a large amount of <strong>symbols</strong> — some being more technical than others. Like letters in the alphabet, they can be used to form words, phrases and sentences that would constitute a larger part of the mathematical lexicon. \[ \begin{gather*}x \longrightarrow x+1 \longrightarrow (x+1)^2 \longrightarrow (x+1)^2 \ge 0 \\ \longrightarrow \forall x \in \mathbb{R} [ (x+1)^2 \ge 0 ] \end{gather*} \] A math symbol can be used for different <strong>purposes</strong> from one mathematical subfield to another (e.g., $\sim$ as logical negation and similarity of triangle), just as multiple symbols can be used to delineate the same concept or relation (e.g., $\times$ and $\cdot$ in multiplication).</p><p>A basic understanding about mathematical terminology is essential to a solid foundation in higher mathematics. To that end, the following is a compilation of some of the most well-adapted, <strong>commonly-used symbols</strong> in mathematics.</p><p>Moreover, these symbols are further categorized by their <strong>function</strong>&nbsp;into tables. More comprehensive lists of symbols — as categorized by <strong>subject</strong>&nbsp;and <strong>type</strong> — can be also found in the relevant pages below (or in the navigational panel).</p><div><div><div><figure><img src="https://mathvault.ca/wp-content/uploads/Math-Symbols-eBook-Cover.png" alt="Cover of Math Vault's Comprehensive List of Mathematical Symbols eBook" srcset="https://mathvault.ca/wp-content/uploads/Math-Symbols-eBook-Cover.png 400w, https://mathvault.ca/wp-content/uploads/Math-Symbols-eBook-Cover-309x400.png 309w, https://mathvault.ca/wp-content/uploads/Math-Symbols-eBook-Cover-300x389.png 300w" sizes="(max-width: 400px) 100vw, 400px" title="Math Symbols eBook Cover" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-srcset="https://mathvault.ca/wp-content/uploads/Math-Symbols-eBook-Cover.png 400w, https://mathvault.ca/wp-content/uploads/Math-Symbols-eBook-Cover-309x400.png 309w, https://mathvault.ca/wp-content/uploads/Math-Symbols-eBook-Cover-300x389.png 300w" data-lazy-src="https://mathvault.ca/wp-content/uploads/Math-Symbols-eBook-Cover.png"></figure><div><p>Prefer the PDF version instead?</p><p>Get the master summary of mathematical symbols in <strong>eBook form</strong> — along with each symbol’s usage and LaTeX code.</p> </div></div></div></div><h2><span id="Constants"></span>Constants<span></span></h2><p>In mathematics, constants are symbols that are used to refer to <strong>non-varying objects</strong>. These can include key numbers, key mathematical sets, key mathematical infinities and other key mathematical objects (such as the identity matrix $I$).</p><p>Mathematical constants often take form of an <a href="https://mathvault.ca/hub/higher-math/math-symbols/greek-hebrew-latin-symbols/" target="_blank" rel="noopener noreferrer"><strong>alphabet letter</strong></a> — or a derivative of it. In some occasions, a constant might be regarded as a variable in the larger context. The following tables feature some of the most commonly-used constants, along with their name, meaning and usage.</p><h3><span id="Key_Mathematical_Numbers"></span>Key Mathematical Numbers<span></span></h3><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$0$ (<strong>Zero</strong>)</td><td>Additive identity of common numbers</td><td>$3 + 0 =3$</td></tr><tr><td>$1$ (<strong>One</strong>)</td><td>Multiplicative identity of common numbers</td><td>$5 \times 1 = 5$</td></tr><tr><td>$\sqrt{2}$ (<strong>Square root of $2$</strong>)</td><td>Positive number whose square is $2$. Approximately $1.41421$.</td><td>$(\sqrt{2} + 1)^2 = 3 + 2\sqrt{2}$</td></tr><tr><td>$e$ (<strong><a href="https://en.wikipedia.org/wiki/E_(mathematical_constant)" target="_blank" aria-label="Euler's constant (opens in a new tab)" rel="noreferrer noopener">Euler’s constant</a></strong>)</td><td>Base of the natural logarithm. Limit of the sequence $(1+\frac{1}{n})^n$. Approximately $2.71828$.</td><td>$\ln (e^2) = 2 $</td></tr><tr><td>$\pi$ (<strong><a href="https://en.wikipedia.org/wiki/Pi" target="_blank" aria-label="Pi (opens in a new tab)" rel="noreferrer noopener">Pi</a></strong>, Archimedes’ constant)</td><td>Ratio of a circle’s circumference to its diameter. Half-circumference of a unit circle. Approximately $3.14159$.</td><td>$\dfrac{\pi^2}{6} = \dfrac{1}{1^2} + \dfrac{1}{2^2} + \cdots$</td></tr><tr><td>$\varphi$ (<strong>Phi</strong>, <a href="https://en.wikipedia.org/wiki/Golden_ratio" target="_blank" aria-label="golden ratio (opens in a new tab)" rel="noreferrer noopener">golden ratio</a>)</td><td>Ratio between a larger number $a$ and a smaller number $b$ when $\frac{a+b}{a} = \frac{a}{b}$. Positive solution to the equation $x^2-x-1 = 0$.</td><td> $\varphi = \dfrac{1+\sqrt{5}}{2} \approx 1.61803$</td></tr><tr><td>$i$ (<strong><a href="https://en.wikipedia.org/wiki/Imaginary_unit" target="_blank" aria-label="Imaginary unit (opens in a new tab)" rel="noreferrer noopener">Imaginary unit</a></strong>)</td><td>The principal root of $-1$. Foundational component of a complex number.</td><td>$(1+i)^2 = 2i$</td></tr></tbody></table></figure><h3><span id="Key_Mathematical_Sets"></span>Key Mathematical Sets<span></span></h3><p>For a more comprehensive list, see <a href="https://mathvault.ca/hub/higher-math/math-symbols/algebra-symbols/#Key_Mathematical_Sets" target="_blank" rel="noopener noreferrer"><strong>key mathematical sets in algebra</strong></a>.</p><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$\varnothing$ (<strong>Empty set</strong>)</td><td>Set with no element</td><td>$|\varnothing| = 0$</td></tr><tr><td>$\mathbb{N}$ (<strong>N</strong>)</td><td>Set of natural numbers</td><td>$\forall x, y \in \mathbb{N}$,<br>$x+y \in \mathbb{N}$</td></tr><tr><td>$\mathbb{Z}$ (<strong>Z</strong>)</td><td>Set of integers (Z stands for zahlen, number in German)</td><td>$ \mathbb{N} \subseteq \mathbb{Z}$</td></tr><tr><td>$\mathbb{Z}_+$ (<strong>Z-plus</strong>)</td><td>Set of positive integers</td><td>$3 \in \mathbb{Z}_+$</td></tr><tr><td>$\mathbb{Q}$ (<strong>Q</strong>)</td><td>Set of rational numbers (Q stands for quotient)</td><td>$\sqrt{2} \notin \mathbb{Q}$</td></tr><tr><td>$\mathbb{R}$ (<strong>R</strong>)</td><td>Set of real numbers</td><td>$\forall x \in \mathbb{R}, x^2 \ge 0$</td></tr><tr><td>$\mathbb{R}_+$ (<strong>R-plus</strong>)</td><td>Set of positive real numbers</td><td>$\forall x,y \in \mathbb{R}_+$, $xy \in \mathbb{R}_+$</td></tr><tr><td>$\mathbb{C}$ (<strong>C</strong>)</td><td>Set of complex numbers</td><td>$\exists z \in \mathbb{C}\, (z^2 + 1 =0)$</td></tr><tr><td>$\mathbb{Z}_n$ (<strong><a href="https://en.wikipedia.org/wiki/Modular_arithmetic#Integers_modulo_n" target="_blank" aria-label="Z-n (opens in a new tab)" rel="noreferrer noopener">Z-n</a></strong>)</td><td>Set of integers modulo $n$</td><td>In the world of $\mathbb{Z}_2$, $1+1=0$.</td></tr><tr><td>$\mathbb{R}^3$ (<strong><a href="https://en.wikipedia.org/wiki/Three-dimensional_space" target="_blank" aria-label="R-three (opens in a new tab)" rel="noreferrer noopener">R-three</a></strong>)</td><td>Three-dimensional Euclidean space</td><td>$(5, 1, 2) \in \mathbb{R}^3$</td></tr></tbody></table></figure><h3><span id="Key_Mathematical_Infinities"></span>Key Mathematical Infinities<span></span></h3><p>In mathematics, many different types of <a href="https://mathvault.ca/math-glossary/#infinite"><strong>infinity</strong></a> exist. These include the purely notational use of the lemniscate symbol ($\infty$), and the use of the following symbols in the context of cardinal/ordinal infinities:</p><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$\aleph_0$ (<strong><a href="https://en.wikipedia.org/wiki/Aleph_number#Aleph-naught" target="_blank" aria-label="Aleph-naught (opens in a new tab)" rel="noreferrer noopener">Aleph-naught</a></strong>)</td><td>Cardinality of the set of natural numbers</td><td>$\aleph_0 + 5 = \aleph_0$</td></tr><tr><td>$\mathfrak{c}$ (<strong><a href="https://en.wikipedia.org/wiki/Continuum_(set_theory)" target="_blank" aria-label="Continuum (opens in a new tab)" rel="noreferrer noopener">Continuum</a></strong>)</td><td>Cardinality of the set of real numbers</td><td>$\mathfrak{c}=2^{\aleph_0}$</td></tr><tr><td>$\omega$ (<strong><a href="https://en.wikipedia.org/wiki/Aleph_number#Aleph-null" target="_blank" aria-label="Omega (opens in a new tab)" rel="noreferrer noopener">Omega</a></strong>)</td><td>Smallest infinite ordinal number</td><td>$\forall n \in \mathbb{N}, n &lt; \omega$</td></tr></tbody></table></figure><p>For a more comprehensive list, see <a href="https://mathvault.ca/hub/higher-math/math-symbols/set-theory-symbols/#Cardinalityrelated_Symbols" target="_blank" rel="noopener noreferrer"><strong>cardinality-related symbols</strong></a>.</p><h3><span id="Other_Key_Mathematical_Objects"></span>Other Key Mathematical Objects<span></span></h3><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$\mathbf{0}$ (<strong>Zero</strong>)</td><td>Zero vector of a vector space</td><td>$\forall \mathbb{v} \in V$,<br>$\mathbf{v} + \mathbf{0} = \mathbf{v}$</td></tr><tr><td>$e$ (<strong>E</strong>)</td><td><a href="https://en.wikipedia.org/wiki/Identity_element" target="_blank" aria-label="Identity element (opens in a new tab)" rel="noreferrer noopener">Identity element</a> of a group</td><td>$e \circ e = e$</td></tr><tr><td>$I$ (<strong>I</strong>)</td><td><a href="https://en.wikipedia.org/wiki/Identity_matrix" target="_blank" aria-label="Identity matrix (opens in a new tab)" rel="noreferrer noopener">Identity matrix</a></td><td>$AI = IA =I$</td></tr><tr><td>$C$ (<strong>C</strong>)</td><td><a href="https://en.wikipedia.org/wiki/Constant_of_integration" target="_blank" aria-label="Constant of integration (opens in a new tab)" rel="noreferrer noopener">Constant of integration</a></td><td>$\displaystyle \int 1 \, \mathrm{d}x =$<br>$x + C$</td></tr><tr><td>$\top$ (<strong><a href="https://en.wikipedia.org/wiki/Tautology_(logic)" target="_blank" aria-label="Tautology (opens in a new tab)" rel="noreferrer noopener">Tautology</a></strong>)</td><td>A sentence in formal logic which is unconditionally true</td><td>For each proposition $P$, $P \land \top \equiv P$.</td></tr><tr><td>$\bot$ (<strong><a href="https://en.wikipedia.org/wiki/Contradiction#In_formal_logic" target="_blank" aria-label="Contradiction (opens in a new tab)" rel="noreferrer noopener">Contradiction</a></strong>)</td><td>A sentence in formal logic which is unconditionally false</td><td>For each proposition $P$, $P \land \lnot P \equiv \bot.$</td></tr><tr><td>$Z$ (<strong>Z</strong>)</td><td><a href="https://en.wikipedia.org/wiki/Normal_distribution#Standard_normal_distribution" target="_blank" aria-label="Standard normal distribution (opens in a new tab)" rel="noreferrer noopener">Standard normal distribution</a></td><td>$Z \sim N(0,1)$</td></tr></tbody></table></figure><h2><span id="Variables"></span>Variables<span></span></h2><p>A mathematical variable is a symbol that functions as a placeholder for <strong>varying expressions</strong> or <strong>quantities</strong>. The same variable can be used on a repeated basis to refer to the same thing — or <i>quantified</i> to form sentences that have a more definite meaning: \begin{gather*}x, y \longrightarrow x + e^x = y \longrightarrow \exists y \in \mathbb{R}\, (x + e^x = y) \\ \longrightarrow \forall x \in \mathbb{R} \, \exists y \in \mathbb{R}\, (x + e^x = y) \end{gather*} In some cases, variables can be thought of as <strong>constants</strong> in narrower contexts (e.g., as parameters), while in other cases, variables are used in conjunction with <strong>subscripts</strong> to make up for the lack of letters (e.g., $x_3$).</p><p>While variables in mathematics are often used to represent <strong>numbers</strong>, they can also be used to represent other objects such as vectors, functions and matrices. The following tables document some of the most common conventions for variables — along with the context where they are adopted and used.</p><h3><span id="Variables_for_Numbers"></span>Variables for Numbers<span></span></h3><figure><table><thead><tr><th>Symbol(s)</th><th>Used For</th><th>Example</th></tr></thead><tbody><tr><td>$m, n, p, q$</td><td><strong>Integers</strong> and <strong>natural numbers</strong></td><td>If $mn$ is odd, then both $m$ and $n$ are odd.</td></tr><tr><td>$a, b, c$</td><td><strong>Coefficients</strong> of functions and equations</td><td>A line of the form $ax+by=0$ passes through the origin.</td></tr><tr><td>$x, y, z$</td><td><strong>Unknowns</strong> in functions and equations</td><td>If $2x + 5= 3$, then $x=-1$.</td></tr><tr><td>$\Delta$</td><td><strong><a href="https://mathvault.ca/quadratic-factorisation/#The_General_Method_Theory">Discriminant</a></strong></td><td>$\Delta = b^2 – 4ac$ for quadratic polynomials</td></tr><tr><td>$i, j, k$</td><td><strong>Index variables</strong> in summations and products</td><td>$\sum _{i=1}^{10} i = 55$</td></tr><tr><td>$t$</td><td><strong>Time</strong></td><td>At $t=5$, the velocity is $v(5)=32$.</td></tr><tr><td>$z$</td><td><strong>Complex numbers</strong></td><td>$z \overline{z} = |z|^2$</td></tr></tbody></table></figure><h3><span id="Variables_in_Geometry"></span>Variables in Geometry<span></span></h3><p>For more symbols in geometry and trigonometry, see <a href="https://mathvault.ca/hub/higher-math/math-symbols/geometry-trigonometry-symbols/" target="_blank" rel="noopener noreferrer"><strong>geometry and trigonometry symbols</strong></a>.</p><figure><table><thead><tr><th>Symbol(s)</th><th>Used For</th><th>Example</th></tr></thead><tbody><tr><td> $P, Q, R, S$</td><td> <strong>Vertices </strong></td><td> $\overline{PQ} \perp \overline{QR}$</td></tr><tr><td> $\ell$</td><td><strong>Lines</strong></td><td> $\ell_1 \parallel \ell_2$</td></tr><tr><td> $\alpha, \beta, \gamma, \theta$</td><td> <strong>Angles</strong></td><td> $\alpha + \beta + \theta = 180^{\circ}$</td></tr></tbody></table></figure><h3><span id="Variables_in_Calculus"></span>Variables in Calculus<span></span></h3><p>For a more comprehensive list, see <a href="https://mathvault.ca/hub/higher-math/math-symbols/calculus-analysis-symbols/#Constants_and_Variables" target="_blank" rel="noopener noreferrer"><strong>constants and variables in calculus</strong></a>.</p><figure><table><thead><tr><th>Symbol(s)</th><th>Used For</th><th>Example</th></tr></thead><tbody><tr><td> $f(x), g(x,y),h(z)$</td><td><strong>Functions</strong></td><td> $f(2) = g(3,1) + 5$</td></tr><tr><td> $a_n, b_n, c_n$</td><td><strong>Sequences</strong></td><td> $\displaystyle a_ n = \frac{3}{n+2} $</td></tr><tr><td> $h, \Delta x$</td><td><strong>Limiting variables</strong> in derivatives</td><td> $\displaystyle \lim_{h \to 0} \frac{e^{h}-e^{0}}{h} = 1$</td></tr><tr><td> $\delta, \varepsilon$</td><td><strong>Small quantities</strong> in <a href="https://en.wikipedia.org/wiki/(%CE%B5,_%CE%B4)-definition_of_limit#Precise_statement_and_related_statements" target="_blank" aria-label="proofs involving limits (opens in a new tab)" rel="noreferrer noopener">proofs involving limits</a></td><td> For all $\varepsilon &gt;0$, there is a $\delta &gt;0$ such that $|x|&lt;\delta$ implies $|2x|&lt;\varepsilon$.</td></tr><tr><td> $F(x), G(x)$</td><td><strong><a href="https://en.wikipedia.org/wiki/Antiderivative" target="_blank" aria-label="Antiderivatives (opens in a new tab)" rel="noreferrer noopener">Antiderivatives</a></strong></td><td> $F(x)’ = f(x)$</td></tr></tbody></table></figure><h3><span id="Variables_in_Linear_Algebra"></span>Variables in Linear Algebra<span></span></h3><p>For a more comprehensive list, see <a href="https://mathvault.ca/hub/higher-math/math-symbols/algebra-symbols/#Variables" target="_blank" rel="noopener noreferrer"><strong>variables in algebra</strong></a>.</p><figure><table><thead><tr><th>Symbol(s)</th><th>Used For</th><th>Example</th></tr></thead><tbody><tr><td> $\mathbf{u}, \mathbf{v}, \mathbf{w}$</td><td><strong>Vectors</strong></td><td> $3\mathbf{u}+4\mathbf{v}=\mathbf{w}$</td></tr><tr><td> $A, B, C$</td><td><strong>Matrices</strong></td><td> $AX = B$</td></tr><tr><td> $\lambda$</td><td><strong><a href="https://en.wikipedia.org/wiki/Eigenvalues_and_eigenvectors#Formal_definition" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener">Eigenvalues</a></strong></td><td> $A\mathbf{v}=\lambda \mathbf{v}$</td></tr></tbody></table></figure><h3><span id="Variables_in_Set_Theory_and_Logic"></span>Variables in Set Theory and Logic<span></span></h3><p>For more comprehensive lists on the topics, see <a href="https://mathvault.ca/hub/higher-math/math-symbols/logic-symbols/#Variables" target="_blank" rel="noopener noreferrer"><strong>variables in logic</strong></a> and <a href="https://mathvault.ca/hub/higher-math/math-symbols/set-theory-symbols/#Variables" target="_blank" rel="noopener noreferrer"><strong>variables in set theory</strong></a>.</p><figure><table><thead><tr><th>Symbol(s)</th><th>Used For</th><th>Example</th></tr></thead><tbody><tr><td>$A, B, C$</td><td><strong>Sets</strong></td><td>$A \subseteq B \cup C$</td></tr><tr><td>$a, b, c$</td><td><strong>Elements</strong></td><td>$a \in A$</td></tr><tr><td> $P, Q, R$</td><td><strong>Propositions</strong></td><td> $P \lor \lnot P \equiv \top$</td></tr></tbody></table></figure><h3><span id="Variables_in_Probability_and_Statistics"></span>Variables in Probability and Statistics<span></span></h3><p>For a more comprehensive list, see <a href="https://mathvault.ca/hub/higher-math/math-symbols/probability-statistics-symbols/#Variables" target="_blank" rel="noopener noreferrer"><strong>variables in probability and statistics</strong></a>.</p><figure><table><thead><tr><th>Symbol(s)</th><th>Used For</th><th>Example</th></tr></thead><tbody><tr><td> $X, Y, Z$</td><td><strong><a href="https://en.wikipedia.org/wiki/Random_variable#Definition" target="_blank" aria-label="Random variables (opens in a new tab)" rel="noreferrer noopener">Random variables</a></strong></td><td>$E(X + Y) =$ <br>$E(X) + E(Y)$</td></tr><tr><td>$\mu$</td><td><strong>Population means</strong></td><td>$H_0\!:\mu = 5$</td></tr><tr><td>$\sigma$</td><td><strong>Population standard deviations</strong></td><td>$\sigma_1 = \sigma_2$</td></tr><tr><td>$s$</td><td><strong>Sample standard deviations</strong></td><td>$s \ne \sigma$</td></tr><tr><td>$n$</td><td><strong>Sample sizes</strong></td><td>If $n\ge 30$, use the normal distribution.</td></tr><tr><td>$\rho$</td><td><strong>Population correlations</strong></td><td>$H_a\!: \rho &lt; 0$</td></tr><tr><td>$r$</td><td><strong>Sample correlations</strong></td><td>If $r = 0.75$, then $r^2 = 0.5625$.</td></tr><tr><td>$\pi$</td><td><strong>Population proportions</strong></td><td>$\pi = 0.5$</td></tr><tr><td>$p$</td><td><strong>Sample proportions</strong></td><td>$p = \dfrac{X}{n}$</td></tr></tbody></table></figure><h2><span id="Delimiters"></span>Delimiters<span></span></h2><p><span data-wfid="0ff7d9a9b3d1"><span>Similar to punctuation marks in English, delimiters are a set of symbols which indicate the <strong>boundaries</strong> between independent mathematical expressions. They are often used to specify the scope for which an operation or rule would apply, and can occur both as an isolate symbol or as a pair of opposite-looking symbols.</span></span></p><p><span data-wfid="8b278eb88b07"><span>In many scenarios, delimiters are used primarily for <strong>grouping purposes</strong>. The following table features some of the most commonly-used delimiters, along with their function and usage.</span></span></p><figure><table><thead><tr><th>Symbol(s)</th><th>Function</th><th>Example</th></tr></thead><tbody><tr><td>$.$</td><td><strong><a href="https://en.wikipedia.org/wiki/Decimal_separator" target="_blank" aria-label="Decimal separator (opens in a new tab)" rel="noreferrer noopener">Decimal separator</a></strong></td><td>$25.9703$</td></tr><tr><td>$:$</td><td><strong><a href="https://en.wikipedia.org/wiki/Ratio#Notation_and_terminology" target="_blank" aria-label="Ratio indicator (opens in a new tab)" rel="noreferrer noopener">Ratio indicator</a></strong></td><td>$1:4:9 =$<br>$3:12:27$</td></tr><tr><td>$,$</td><td><strong><a href="https://mathworld.wolfram.com/Comma.html" target="_blank" aria-label="Object separator (opens in a new tab)" rel="noreferrer noopener">Object separator</a></strong></td><td>$(3, 5, 12)$</td></tr><tr><td>$(), [], \{\}$</td><td><strong><a aria-label="Order-of-operation (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Order_of_operations" target="_blank">Order-of-operation</a> indicators</strong></td><td>$(a + b) \times c$</td></tr><tr><td>$(), []$</td><td><strong><a href="https://en.wikipedia.org/wiki/Bracket_(mathematics)#Intervals" target="_blank" aria-label="Interval indicators (opens in a new tab)" rel="noreferrer noopener">Interval indicators</a></strong></td><td>$3\notin (3,4]$,<br> $4 \in (3,4]$.</td></tr><tr><td> $(), []$</td><td><strong>Vector/matrix builder</strong></td><td> $\begin{pmatrix} 1 &amp; 4 \\ 3 &amp; 6 \end{pmatrix}$</td></tr><tr><td>$\{\}$</td><td><strong>Set builder</strong></td><td>$\{ \pi, e, i\}$</td></tr><tr><td>$|$, $\, :$</td><td><strong><a href="https://en.wikipedia.org/wiki/Set-builder_notation#Sets_defined_by_a_predicate" target="_blank" aria-label="&quot;Such that&quot; markers (opens in a new tab)" rel="noreferrer noopener">“Such that” markers</a></strong></td><td>$\{ x \in \mathbb{R} \, |\, x^2 – 2 =0 \}$</td></tr><tr><td>$| |, \| \|$</td><td><strong><a href="https://en.wikipedia.org/wiki/Norm_(mathematics)#Notation" target="_blank" aria-label="Norm-related operators (opens in a new tab)" rel="noreferrer noopener">Norm-related operators</a></strong></td><td>$\| (3, 4) \| = 5$</td></tr><tr><td>$\begin{cases}\end{cases}$</td><td><strong><a href="https://en.wikipedia.org/wiki/Piecewise#Notation_and_interpretation" target="_blank" aria-label="Piecewise-function marker (opens in a new tab)" rel="noreferrer noopener">Piecewise-function marker</a></strong></td><td>$f(x) = \begin{cases} 1 &amp; x \ge 0 \\ 0 &amp; x &lt; 0 \end{cases}$</td></tr><tr><td>$\langle\rangle$</td><td><strong><a href="https://en.wikipedia.org/wiki/Inner_product_space#Definition" target="_blank" aria-label="Inner product (opens in a new tab)" rel="noreferrer noopener">Inner product</a> operator</strong></td><td>$\langle ka, b\rangle = k\langle a, b \rangle$</td></tr><tr><td>$\lceil \rceil$</td><td><strong><a href="https://en.wikipedia.org/wiki/Floor_and_ceiling_functions" target="_blank" aria-label="Ceiling operator (opens in a new tab)" rel="noreferrer noopener">Ceiling operator</a></strong></td><td>$\lceil 2.476 \rceil = 3$</td></tr><tr><td>$\lfloor \rfloor$</td><td><strong><a href="https://en.wikipedia.org/wiki/Floor_and_ceiling_functions" target="_blank" aria-label="Floor operator (opens in a new tab)" rel="noreferrer noopener">Floor operator</a></strong></td><td>$\lfloor \pi \rfloor = 3$</td></tr></tbody></table></figure><h2><span id="Operators"></span>Operators<span></span></h2><p>An operator is a symbol used to denote an <strong><a href="https://mathvault.ca/math-glossary/#operation">operation</a></strong> — a function which takes one or multiple objects to another similar object. Most of the operators are unary and binary in nature (i.e., taking one and two inputs to their …</p></div></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mathvault.ca/hub/higher-math/math-symbols/">https://mathvault.ca/hub/higher-math/math-symbols/</a></em></p>]]>
            </description>
            <link>https://mathvault.ca/hub/higher-math/math-symbols/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23630288</guid>
            <pubDate>Wed, 24 Jun 2020 16:40:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What vertical farming and ag startups don't understand about agriculture]]>
            </title>
            <description>
<![CDATA[
Score 341 | Comments 311 (<a href="https://news.ycombinator.com/item?id=23630201">thread link</a>) | @kickout
<br/>
June 24, 2020 | http://thinkingagriculture.io/what-silicon-valley-doesnt-understand-about-agriculture/ | <a href="https://web.archive.org/web/*/http://thinkingagriculture.io/what-silicon-valley-doesnt-understand-about-agriculture/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-5">
		
	
	<div>
		
<p>I was browsing HackerNews recently and a (rare) agriculture news story popped up, <a href="https://news.ycombinator.com/item?id=23208954">this one to be specific</a>, <a href="https://news.ycombinator.com/item?id=20899721">but there are others</a>. As these are of interest to me I clicked and read through the comments. These linked articles aren’t all that note-worthy, but they are indicative of a trend. As a casual follower of the Ag startup scene and witnessing the vertical farming fascination for the past ~10 years grow, I’ve been genuinely confused as to some of the approaches founders are taking with their startups. For the longest time, I believed the hype that vertical farming was <em>needed</em> and more importantly, coming to a city near you™. This implies and inherent inefficiency in both current food production and its distribution chains.</p>



<p>I can only conclude Silicon Valley thinks agriculture lacks innovation or is in need of ‘disruption’ and efficiency boosting and the truth couldn’t be more opposite. The truth is, modern agriculture as most people understand it <em>already have</em> the things SV-types desire and crave: massive scale, incredible automation, hyper-efficiency. Because we live in an urban based society (roughly 20% of people in America are classified into ‘rural’ aread <a href="https://www.census.gov/newsroom/press-releases/2016/cb16-210.html">according to the census</a>), most people don’t realize just how big agriculture is. The Midwest in the United States has close to 90M acres of corn, <a href="https://observablehq.com/@kickout/untitled">85M acres of soybean</a>, and 30M acres of wheat. Brazil has as much, and usually more, soybean acreage grown every year in their breadbasket (centered in Mato Grosso, Sorriso, Brazil). Truly incomprehensible scale. All of this is accomplished outdoors using soil that already exists, using the most cheapest energy source available–the sun–to convert carbon to a human usable form. To be clear, soil is a natural resource that will become endangered if we do not mitigate the severe erosion problems that stem from single species field that are barren (re: nothing actively growing) for 30-40% of the calendar year (in North America).</p>



<p>Modern agriculture is scaled and the modern row crop farmer is equally scaled–mostly enabled by robust automation (auto-steer tractors, precision planting machines, etc.). The average farm size is increasing and has been for quite sometime. As farm size increases, the number of people <em>directly</em> involved in agriculture for their livelihood continues to be <a href="https://www.nass.usda.gov/Publications/Todays_Reports/reports/fnlo0419.pdf">exceedingly small</a> (there are only about ~ million farms in the United States). Sophisticated and (and generally physically massive) machines–with varying degrees of automation–have continuously driven the efficiency of a single farmer higher and higher requiring less hand labor and obtaining efficiencies of scale for cost. Farmers are the original innovators and scaled agricultural production has largely enabled the population growth seen in the last ~150 years (humans domesticated crops ~10,000 BC, well before written communication). Farmers have always been smart and savvy when evaluating decisions that affect their livelihood. They can detect when a company is trying to sell them something that actually holds no value. Why? Because if a farmer is continuously spending money on things that do not return value, they can (and do) go <a href="https://www.fb.org/market-intel/farm-bankruptcies-rise-again">out of business</a> quickly. There are no VC-funded farmers, so positive cash flow isn’t merely a good thing, its the only thing. So if a company is trying to sell a product for ~$15 an acre, a wise farmer will ensure they are getting &gt;$15 on profit from said product. This is a primary reason companies like The Climate Corporation has struggled to monetize ‘farm data’. <a href="https://www.theverge.com/2013/10/10/4823004/monsanto-bets-the-farm-on-big-data">Big bets largely haven’t panned out as expected</a>. SV companies often claim data is worth <em>$x</em>, but that value generally only exists in the abstract and has poor basis on the farm and the lack of adoption suggest the product isn’t working as intended or its severely mispriced from its value. Compounding that and in addition to, University extension programs, <a href="https://en.wikipedia.org/wiki/Land-grant_university">mostly from Land Grant Universities</a>, have traditionally filled the role of keeping farmers up-to-date on the latest methods and profitability studies (e.g. <a href="https://coolbean.info/">Cool Bean</a>) using grant money (often funded via taxes or through ‘<a href="https://ncga.com/stay-informed/media/in-the-news/article/2020/03/corn-checkoff-assisting-teachers-with-online-curriculum-">check-off</a>‘ programs). These types of programs represent an already existing framework of farmers ‘paying’ for this type of knowledge. This model has proven scalable, even more so with the internet and social media making information readily available. Note this doesn’t prevent <em>bad</em> information from being shared, but since savvy farmers will try and eventually ignore unprofitable methods, one can assume this is an efficient system.</p>



<p>So why am I not worried about vertical farming or startups that are trying to reinvent the wheel? They are busy fighting battles that simply don’t exist for their competition (outdoor/field-based agriculture). Current agriculture doesn’t need an artificial energy source and the automation that exists <em>today</em> is breathtaking. It is completely reasonable for a single human, with assistance from machines, to comfortably farm 1,000 acres or more of traditional rows crops. It generally doesn’t matter if a vertical farm can ‘produce’ 365 days a year, the existing agriculture infrastructure in the breadbaskets of the world (United States, Brazil/Argentina/Eastern Europe) make any indoor advantage disappear, and quickly. These centers are ‘connected’ as well, with existing GPS and cellular networks available today. </p>



<p>The free advice I would give anyone looking to enter the ag startup scene: take advantage of the existing pros (scale, automation, mechanization). Startups that try to hitch along to already existing scale rather than trying to re-invent it present a much better opportunity for success.</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article></div>]]>
            </description>
            <link>http://thinkingagriculture.io/what-silicon-valley-doesnt-understand-about-agriculture/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23630201</guid>
            <pubDate>Wed, 24 Jun 2020 16:36:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Redash Is Joining Databricks]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23629862">thread link</a>) | @atriix
<br/>
June 24, 2020 | https://blog.redash.io/redash-joins-databricks/ | <a href="https://web.archive.org/web/*/https://blog.redash.io/redash-joins-databricks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <section>
                <div>
                    <p>We’re happy to announce that Redash is joining Databricks. We’ve been an open-source company grounded in helping our community of users make sense of their data. We found this same culture and values in Databricks, and we’re excited to be able to carry on our vision to democratize access to data — now in a larger home where we can bring this to even more people.</p><p>We’re excited to be one of the many open-source projects that Databricks supports. They’re the original creators of Apache Spark™, the standard for large-scale data processing, as well as Delta Lake for reliable data lakes, MLflow for the machine learning lifecycle, Koalas for data science productivity on Spark. Now, Redash joins this community of open source projects for collaborative SQL queries and dashboarding. We look forward to growing the Redash engineering team and have a lot of plans in our road map to deliver an even better experience with Redash, with more functionality, security and support. Open Source Redash remains in its current code repo, and we will be releasing a new v9 shortly so stay tuned for more details.</p><p>As part of this acquisition, we will be offering a new way to use Redash from directly within Databricks. For our current Redash SaaS paid customers, your service will continue unchanged, and we will be sharing more details in the coming months on how we’re planning to expand the service. You can learn more in our <a href="https://redash.io/help/faq/databricks">customer FAQ</a>.</p>
                </div>
            </section>

            


        </article>


    </div>
</div></div>]]>
            </description>
            <link>https://blog.redash.io/redash-joins-databricks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23629862</guid>
            <pubDate>Wed, 24 Jun 2020 16:20:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New technology for aluminum production promises zero CO2 emission]]>
            </title>
            <description>
<![CDATA[
Score 145 | Comments 67 (<a href="https://news.ycombinator.com/item?id=23629859">thread link</a>) | @dagurp
<br/>
June 24, 2020 | https://icelandmonitor.mbl.is/news/news/2020/06/24/iceland_s_co2_emissions_could_be_reduced_by_a_third/ | <a href="https://web.archive.org/web/*/https://icelandmonitor.mbl.is/news/news/2020/06/24/iceland_s_co2_emissions_could_be_reduced_by_a_third/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
  
    

        
          <p>
 A new Icelandic technology intended for aluminum production offers hopes of eliminating CO2 emissions from the production,
 <em>
  <a href="https://www.mbl.is/frettir/innlent/2020/06/22/gaeti_minnkad_losun_co2_um_thridjung/" target="_blank">
   mbl.is
  </a>
 </em>
 reports.
</p>

        
          <p>
 The company Arctus Metals, in cooperation with Innovation Center Iceland, reached a milestone recently, when it successfully produced aluminum with this new method in a large pot. Instead of creating CO2 emissions, the process emits oxygen.
</p>

        
          <p>
 The main part of the innovation consists of using multiple,&nbsp;vertical inert metal-alloy anodes and ceramic cathodes, instead of using electrodes made of carbon.
</p>

        
          <p>
 This innovation could potentially eliminate CO2 emissions from aluminum smelters in Iceland and elsewhere.
</p>

        
          
  
  

  



        
          <p>
 “Iceland’s three aluminum smelters produce more than 800,000 tons of aluminum a year and emit more than 1.6 million tons of CO2 a year,” states Arctus Metals CEO Jón Hjaltalín Magnússon. “Their emissions make up 30 percent of Iceland’s total CO2 emissions.”
</p>

        
          <p>
 “If all our aluminum smelters adopted this new technology, Iceland’s CO2 emissions would be reduced by 30 percent,
 <span>
  ”
 </span>
 he adds,
 <span>
  “
 </span>
 enabling us to fulfill our international obligations and more. Using the new Arctus Metals method, an aluminum smelter, the size of [Rio Tinto’s] in Straumsvík [Southwest Iceland] would produce as much oxygen as a forest covering 500 square kilometers.”
</p>

        
          <p>
 Jón reports that a cooperation agreement has been signed between the German company Trimet Aluminum, one of the world’s largest producers of aluminum, which will continue the development process by starting production in larger pots, and planning to eventually convert production in their four smelters to this method.
</p>

        
          <p>
 The project was presented to Icelandic President Guðni Th. Jóhannesson yesterday at the offices of Innovation Center Iceland.
</p>

        
          <p>
 In the video above, you can see the first chunk of aluminum processed in this new way, presented by CEO Jón Hjaltalín Magnússon.
</p>

        
          <p>
 You can read more about the company and the project
 <a href="http://www.sustainordic.com/portfolio/items/arctus-metals/" target="_blank">
  here
 </a>
 .
</p>

    

  

  

      </div></div>]]>
            </description>
            <link>https://icelandmonitor.mbl.is/news/news/2020/06/24/iceland_s_co2_emissions_could_be_reduced_by_a_third/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23629859</guid>
            <pubDate>Wed, 24 Jun 2020 16:19:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Relay by Puppet: IFTTT for DevOps]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23629644">thread link</a>) | @bradhe
<br/>
June 24, 2020 | https://relay.sh/blog/relay-public-beta/ | <a href="https://web.archive.org/web/*/https://relay.sh/blog/relay-public-beta/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>Today we announce <a href="https://relay.sh/">Relay</a>, an event-driven automation platform. <a href="https://app.relay.sh/signup">Sign up now</a> and try it out! Relay connects infrastructure and operations platforms, APIs, and tools together into a cohesive, easy-to-automate whole. Relay is simple enough for you to start automating common, <em>if-this-then-that</em> (IFTTT) style DevOps tasks in minutes and powerful enough to model multi-step, branching, parallelized DevOps processes when the need arises.</p>
<p>Why bother? Because for all the progress we’ve made as builders and operators, <a href="https://landscape.cncf.io/">things are more complicated than ever</a>. Modern applications comprise a growing variety of runtimes, clouds, infrastructure platforms, 3rd party services, and APIs. Mounting sophistication (<a href="https://www.youtube.com/watch?v=dtI5dMpBmQo">and complexity</a>) of how applications are constructed complicates how we operate and manage them. As a result, accomplishing many basic operational tasks can involve touching many different components, with different APIs, different semantics, from different upstreams, vendors and dev teams. Connecting all of these components together is tough, and automating anything across them all can range from tedious to nightmare fuel.</p>
<p>At layers above the plumbing, <a href="https://relay.sh/blog/rise-of-the-apis/">managing infrastructure stops looking like classic configuration management and starts looking like orchestrating workflows</a>. However, workflows can be tricky. Connectivity, secrets handling, event listening, ordering, parallelism, error handling, and control flow all conspire to make writing workflows from scratch pretty gnarly. The complexity adds up fast. We can do better!</p>
<blockquote>
<p>“Automated workflows are the bedrock of all software organizations.”<br>
— Jason Warner, CTO @ GitHub</p>
</blockquote>
<p>Relay lets you represent any DevOps workflow as code, composed of triggers that listen for incoming events, and steps that define the task you’re automating. Relay does not limit what you can talk to. A single workflow could listen for alerts from PagerDuty, query metrics from DataDog, reconfigure infrastructure with Terraform, and send a notification via Slack. It’s easy to leverage pre-existing triggers, steps, and workflows, and it’s simple to make your own if the need arises.</p>
<p>As a hosted service, Relay supervises things on your behalf. It will automatically trigger your workflow based on incoming events, execute your workflow’s steps in parallel, notify you if you need to intervene, and keep meticulous records of everything done. Relay does this all automatically, so you don’t have to.</p>
<p>Today, we’re proud to announce <a href="https://relay.sh/">beta availability</a> for Relay. Read on to see how it works!</p>
<h2>Workflows</h2>
<p>Relay’s core method of automation is <a href="https://relay.sh/docs/using-workflows/"><em>the workflow</em></a>. Workflows combine useful activities together to accomplish a particular task:</p>
<ul>
<li>When we detect an unused Azure Disk, delete it <em>(so we can save money)</em></li>
<li>When they go unused, nuke any AWS authentication keypairs <em>(so we can reduce our attack surface)</em></li>
<li>When a PagerDuty alert fires with a certain severity, create tickets in Jira and a room in Slack <em>(so we can more quickly troubleshoot issues)</em></li>
</ul>
<p>Relay lets you succinctly express these types of workflows, and beyond, <a href="https://relay.sh/docs/reference/relay-workflows/">as code</a>. And like code, workflows can be versioned, reviewed, refactored, and reused. We’re Puppet; <a href="https://www.google.com/search?hl=en&amp;q=puppet%20infrastructure%20as%20code">we wouldn’t have it any other way</a>.</p>
<p>Running your first workflow is easy, and should only take you about a minute. As tradition demands, here’s “Hello, world” (<a href="https://app.relay.sh/login">log in</a> and follow along!):</p>
<p><img src="https://relay.sh/debec11953b60317076234251dc8c4f0/hello-world.gif" alt="Hello, world!"></p>
<p>Because workflows are code, you can treat them like code. Modifying a workflow is straightforward. Let’s change the workflow, adding a step to emit the current date:</p>
<p><img src="https://relay.sh/2105fe13ad95afadea7d0e9dc45e3976/cli.gif" alt="Change the workflow using the CLI"></p>
<p>That covered <a href="https://relay.sh/docs/getting-started/#install-the-cli">getting the CLI installed</a>, authenticating against the service, downloading your workflow, modifying the logic, and then letting Relay know the code is updated.</p>
<h2>Triggers and steps</h2>
<p>Workflows contain <em>triggers</em> and <em>steps</em>: Triggers determine when Relay should execute your workflow: manually, on a schedule, or when pinged by an external source. Steps represent the set of actions and activities necessary to make your workflow accomplish its goals. Steps are just <a href="https://www.docker.com/resources/what-container">containers</a>, so you’re pretty unconstrained when it comes to what a step can do. Both triggers and steps <a href="https://relay.sh/docs/integrating-with-relay/">are easy to create, remix, and share</a>. With these building blocks, Relay is capable of modeling a huge variety of workflows, and executing them on your behalf. There are a bunch already written, and it’s straightforward to <a href="https://relay.sh/docs/getting-started/">make your own</a>.</p>
<p>Here’s a more interesting example workflow that <a href="https://relay.sh/workflows/ec2-reaper/">cleans up some unneeded EC2 instances</a>. It has more steps, including some that consume AWS credentials, and one which represents a <em>manual approval</em> gate:</p>
<p><img src="https://relay.sh/18f91058f6a39345a357bc6d72855ed8/ec2-reaper.gif" alt="Cleaning up some EC2 instances"></p>
<p>It’s easy to add, remove, or replace triggers and steps to suit your liking. Some modifications for the preceding example could include adding a webhook-based trigger for the workflow, adding a notification step at the end, or better integrating it into your GitOps setup. Perhaps a step that takes the list of terminated instances, computes their money you just saved, then buys an equivalent amount of stuff from your Amazon wish list? Ops is hard work - treat yourself!</p>
<p>Our examples thus far have shown short, linear sequences of steps but you can also express some pretty elaborate processes just as easily. Here’s a picture of the execution graph of one of workflows we use to manage Relay itself:</p>
<p><span>
      <a href="https://relay.sh/static/ed787c9f007e7856c5846c98c4c7f6fa/065ce/relay-graph.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="A more complex workflow graph" title="A more complex workflow graph" src="https://relay.sh/static/ed787c9f007e7856c5846c98c4c7f6fa/64756/relay-graph.png" srcset="https://relay.sh/static/ed787c9f007e7856c5846c98c4c7f6fa/a8a0d/relay-graph.png 300w,
https://relay.sh/static/ed787c9f007e7856c5846c98c4c7f6fa/dface/relay-graph.png 600w,
https://relay.sh/static/ed787c9f007e7856c5846c98c4c7f6fa/64756/relay-graph.png 1200w,
https://relay.sh/static/ed787c9f007e7856c5846c98c4c7f6fa/28bdc/relay-graph.png 1800w,
https://relay.sh/static/ed787c9f007e7856c5846c98c4c7f6fa/98e2c/relay-graph.png 2400w,
https://relay.sh/static/ed787c9f007e7856c5846c98c4c7f6fa/065ce/relay-graph.png 2680w" sizes="(max-width: 1200px) 100vw, 1200px" loading="lazy">
  </a>
    </span></p>
<h2>The Relay service</h2>
<p>Listening for events and running workflows might appear conceptually simple, but there are a lot of practical details that need to be worked out. Relay’s execution environment (and <a href="https://github.com/puppetlabs/relay-core">underlying engine</a>):</p>
<ul>
<li>Manages <a href="https://relay.sh/docs/using-workflows/adding-connections/">connections</a> to upstream/downstream APIs and services, making them securely available to the workflows that need them</li>
<li>Automatically creates <a href="https://relay.sh/docs/reference/relay-workflows/#push"><em>push triggers</em></a> for your workflows, complete with workflow-specific security tokens, so you can easily kick it off from all kinds of other tools</li>
<li>Automatically constructs an environment for running webhooks, so your workflows can respond to events from webhook-only services</li>
<li>Sandboxes workflow and step execution, for fault isolation</li>
<li>Manages your workflows with all the necessary <em>ops accoutrements</em> (e.g. monitoring, logging, error handling)</li>
<li>Supervises the execution of your workflows, invoking steps in the right order (with automatic parallelization)</li>
<li>Standardizes the interfaces between all these pieces so steps, triggers, and connections are reusable and remixable across workflows</li>
</ul>
<p>Relay takes care of this stuff so you don’t have to. Instead, you can focus on the logic of your workflow, the core of what you’re trying to automate.</p>
<p>After all, isn’t that the point?</p>
<h2>Automation for everyone</h2>
<p>How many unique applications are running out there across the planet (<a href="https://twitter.com/lkanies/status/1182350689529298944">or above it</a>)? Thousands? Millions? <a href="https://www.merriam-webster.com/dictionary/bajillion">Bajillions</a>? How many of them are running on identical infrastructure stacks, built with identical technology stacks, managed in identical ways at an identical scale? There’s a truly staggering variety of approaches and constraints.</p>
<p>If there’s no <em>One True Stack</em>, then there’s no <em>One True Way To Manage It</em>. The tools you employ should thrive in this sort of world because that’s the world we’ve got.</p>
<p>Relay’s core value lies in letting you tie a <a href="https://relay.sh/integrations/">wide variety of services, APIs, and platforms</a> together. It’s constructed in a deliberately pluggable way. Users can readily extend the system to talk to new technologies, respond to new kinds of events, and take action in new ways…no CS degree required. Those extensions should be easy to share, so the entire user community can benefit. The ecosystems around the tools we use are every bit as important as the tools themselves.</p>
<p>Even though it’s early days, Relay can already do quite a lot. The future holds many possibilities: new workflows, more integrations with more tools and platforms, higher-level workflow syntax, a more streamlined authoring experience, simplified input/output from steps, and more. Early users have already given us a ton of great suggestions, and we’d love to hear yours!</p>
<h2>Next steps</h2>
<p>The next step (and best step) is to <a href="https://relay.sh/">try it out</a>! And if you’d like to learn more about Relay, you can check out:</p>
<ul>
<li><a href="https://relay.sh/blog/relay-and-open-source/">How to get involved</a>, extend Relay to better meet your needs, and become part of Relay community</li>
<li><a href="https://relay.sh/docs/">The documentation</a> does a great job of introducing Relay, its usage, core concepts, and extension points</li>
<li><a href="https://relay.sh/workflows/">Peruse some workflows</a> to see what they can do. The code and its graphical execution plan are available on every workflow’s page.</li>
<li><a href="https://puppetcommunity.slack.com/archives/CMKBMAW2K">Slack</a> - come linger in the #relay channel! The more the merrier</li>
</ul>
<p>Thanks, and let a thousand workflows bloom!</p></section></div>]]>
            </description>
            <link>https://relay.sh/blog/relay-public-beta/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23629644</guid>
            <pubDate>Wed, 24 Jun 2020 16:07:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Sborex, a minimal-code visual service designer with web builder (POC)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23629607">thread link</a>) | @fedd
<br/>
June 24, 2020 | http://sborex.com/poc/ | <a href="https://web.archive.org/web/*/http://sborex.com/poc/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <p>
                    This is a P.O.C. of a flexible and visually configurable platform for creation of different 
                    kinds of applications, from small micro-services to enterprise-level information systems.
                </p>
                <p>
                    In a nutshell, Sborex is a visual diagram 
                    execution engine with extended web and integration capabilities.
                </p>
                <p><a href="http://sborex.com/poc/sborex-poc.jar">Download</a></p><p>
                    It runs on Java and starts a webserver on port <span>8585</span>.
                </p>

                <h2>
                    What's Inside
                </h2>
                <p>
                    This is a demo app to try how the system will work. 
                   The entities described below are automatically deployed for demonstration purposes.
                </p>

                <h3>
                    Customer
                </h3>
                <p>                    
                    This is an example of a customer record representation and a contact dialogue initial form.
                </p>
                <p>
                    <img src="http://sborex.com/poc/customer.png" alt="Customer View">
                </p>
                <p>
                    The customer lifecycle process and a simple interaction script
                    for a user contacting the customer are defined in a 
                    <a href="http://www.bpmn.org/">BPMN</a>-like diagram:
                </p>
                <p>
                    <img src="http://sborex.com/poc/customer.svg" alt="Customer Process Definition">
                </p>
                <p>
                    The User Tasks and the customer data presentations are designed visually in a view editor:
                </p>
                <p>
                    <img src="http://sborex.com/poc/form.png" alt="Customer Process Definition">
                </p>

                <p>
                    <img src="http://sborex.com/poc/view.png" alt="Customer Process Definition">
                </p>






                <h3>
                    Register
                </h3>
                <p>
                    The Register flowchart defines a process that acquires a customer data file via web or from a filesystem, 
                    transforms it and then passes to a Customer process, iterating over each line of the input file.
                </p>
                <p>
                    Note the integration points that are serviced by embedded <a href="https://camel.apache.org/">Apache Camel</a> 
                    framework.
                </p>
                <p>
                    <img src="http://sborex.com/poc/register.svg" alt="Register Process Definition">
                </p>


                <h3>
                    SIP Server
                </h3>
                <p>
                    This process demonstrates how a simple or complex technical service can be designed in the system. Any of the 
                    <a href="https://camel.apache.org/components/latest/">Camel components</a> can be used with or without 
                    little initial configuration, all made in a Sborex process definition.
                </p>
                <p>
                    <img src="http://sborex.com/poc/sipserver.svg" alt="SIP Server Process Definition">
                </p>

                <h3>
                    Session
                </h3>
                <p>
                    This is a technical process that gets started for each of the new web sessions. 
                </p>
                <p>
                    With the help of LDAP integration process elements
                    it may query your enterprise user database for roles and permissions, or you may configure access to a custom 
                    user storage, but currently it just stores the username entered by the user.
                </p>
                <p>
                    For simplicity this process also provides a process editor available to the user right on the app's home page.
                </p>
                <p>
                    <img src="http://sborex.com/poc/session.svg" alt="Session Process Definition">
                </p>



                <h2>
                    Try It Yourself
                </h2>
                <p>
                    To try it out, download the Java executable file below:
                </p>
                <p><a href="http://sborex.com/poc/sborex-poc.jar">Download</a></p><p>
                    Place it in a dedicated folder as it will create a database directory and files along with it.
                </p>
                <p>
                    Run it as a Java program:
                </p>
                <p>
                    java -jar sborex-poc.jar
                </p>
                <p>
                    After the system starts go to the system's web server:
                </p>
                <p>
                    <a href="http://localhost:8585/">http://localhost:8585/</a>
                </p>
                <p>
                    (Replace <span>localhost</span> with the actual machine address if you are accessing 
                    it from outside the running host)
                </p>
                <p>
                    Log in as a user with the name <span>fedd</span> and start exploring the system.
                </p>
                <p>
                    In process definition editor pages, you may click the elements (rectangles, circles and diamonds) 
                    and choose the gear icon to see the element configuration.
                </p>
                <p>
                    <img src="http://sborex.com/poc/edit.png" alt="Customer Process Definition">
                </p>
                <h3>
                    Load File and See Customers
                </h3>
                <p>
                    To test the load and transform capabilities, go to 
                </p>
                <p>
                    <a href="http://localhost:8585/register">http://localhost:8585/register</a>
                </p>
                <p>
                    and follow the instructions. 
                </p>

                <h3>
                    Troubleshooting
                </h3>
                <p>
                    If the ports 8585 and 5060 are occupied on the host machine, we may override the default 
                    configuration by providing other port numbers at start time:
                </p>
                <p>
                    java -jar sborex-poc.jar -Dintegration.web.port=8586 -Dintegration.sip.port=5061
                </p>

                <h2>
                    Technical Details
                </h2>
                <p>
                    The system is written in Java and is able to run on versions 8+. It doesn't utilize Spring Boot or Spring whatsoever. 
                    It's not based on any of the opensource BPMN engines.
                </p>
                <p>
                    Apache Camel included in the system is of version 2.24.0. It runs an embedded Jetty webserver 
                    for the web pages, rest services and websockets.
                </p>
                <p>
                    For the demo it is configured to run with Derby database, also embedded version. It can be configured to use 
                    PostgreSQL or any other relational database servers or Elasticsearch as its datastore.
                </p>
                <p>
                    The neat <a href="https://bpmn.io/">bpmn.io</a> library is used for displaying and editing the process definitions. 
                    There are plans to add a modeler specifically designed for Sborex to ease the use of the system's features that are not 
                    actually compliant with BMPN standard.
                </p>
                <p>
                    There is also a thirdparty web page designer that opens by Edit Layout button wherever the element is accompanied with 
                    a web page template. (Please note that it is not yet fully integrated.)
                </p>

                <h2>
                    Status and Prospects
                </h2>
                <p>
                    Sborex is currently not production ready and requires further investment. 
                    The current refactoring iteration may experience performance problems under high load.
                </p>
                <p>
                    As mentioned before, the current process modeler will also be redesigned. Visual editors 
                    for transformation, service, configuration artifacts will also be added to provide a 
                    "low code" experience.
                </p>
                <p>
                    The latest refactoring effort was taken to get the product ready for embedding the neural 
                    networking solutions and distributed computing for higher loads. 
                </p>

                <h2>
                    Contact
                </h2>
                <p>
                    My name is Fyodor "Fedd" Kravchenko. You may contact me via <a href="https://www.linkedin.com/in/kfedd/">LinkedIn</a> or 
                    drop me <a href="mailto:info@sborex.com">an email</a>. 
                </p>

            </div></div>]]>
            </description>
            <link>http://sborex.com/poc/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23629607</guid>
            <pubDate>Wed, 24 Jun 2020 16:05:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Advanced Active Record: Using Subqueries in Rails]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23629450">thread link</a>) | @moritzplassnig
<br/>
June 24, 2020 | https://pganalyze.com/blog/active-record-subqueries-rails | <a href="https://web.archive.org/web/*/https://pganalyze.com/blog/active-record-subqueries-rails">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Active Record provides a great balance between the ability to perform simple queries simply, and also the ability to access the raw SQL sometimes required to get our jobs done. In this article, we will see a number of real-life examples of business needs that may arise at our jobs.</p>
<p>They will come in the form of a request for data from someone else at the company, where we will first translate the request into SQL, and then into the Rails code necessary to find those records. We will be covering five different types of subqueries to help us find the requested data.</p>
<p>Let's take a look at why subqueries matter:</p>
<!-- -->

<svg version="1.1" xmlns:xl="http://www.w3.org/1999/xlink" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns="http://www.w3.org/2000/svg" viewBox="29.5 167 879.5 452" width="879.5" height="452">
  <defs>
    <font-face font-family="Helvetica Neue" font-size="16" panose1="2 0 8 3 0 0 0 9 0 4" units-per-em="1000" underline-position="-100" underline-thickness="50" slope="0" x-height="524" cap-height="722" ascent="975.0061" descent="-216.99524" font-weight="700">
      <font-face-src>
        <font-face-name name="HelveticaNeue-Bold"></font-face-name>
      </font-face-src>
    </font-face>
    <marker orient="auto" overflow="visible" markerUnits="strokeWidth" id="FilledArrow_Marker" strokelinejoin="miter" strokemiterlimit="10" viewBox="-1 -4 10 8" markerWidth="10" markerHeight="8" color="#cc0102">
      <g>
        <path d="M 8 0 L 0 -3 L 0 3 Z" fill="currentColor" stroke="currentColor" stroke-width="1"></path>
      </g>
    </marker>
    <marker orient="auto" overflow="visible" markerUnits="strokeWidth" id="Arrow_Marker" strokelinejoin="miter" strokemiterlimit="10" viewBox="-1 -4 10 8" markerWidth="10" markerHeight="8" color="#346591">
      <g>
        <path d="M 8 0 L 0 -3 L 0 3 Z" fill="none" stroke="currentColor" stroke-width="1"></path>
      </g>
    </marker>
    <marker orient="auto" overflow="visible" markerUnits="strokeWidth" id="FilledArrow_Marker_2" strokelinejoin="miter" strokemiterlimit="10" viewBox="-1 -4 10 8" markerWidth="10" markerHeight="8" color="#cb0200">
      <g>
        <path d="M 8 0 L 0 -3 L 0 3 Z" fill="currentColor" stroke="currentColor" stroke-width="1"></path>
      </g>
    </marker>
    <font-face font-family="Monaco" font-size="14" units-per-em="1000" underline-position="-37.597656" underline-thickness="75.68359" slope="0" x-height="545.41016" cap-height="757.8125" ascent="1000" descent="-250" font-weight="400">
      <font-face-src>
        <font-face-name name="Monaco"></font-face-name>
      </font-face-src>
    </font-face>
    <font-face font-family="Monaco" font-size="13" units-per-em="1000" underline-position="-37.597656" underline-thickness="75.68359" slope="0" x-height="545.41016" cap-height="757.8125" ascent="1000" descent="-250" font-weight="400">
      <font-face-src>
        <font-face-name name="Monaco"></font-face-name>
      </font-face-src>
    </font-face>
  </defs>
  <g id="Canvas_1" style="stroke-dasharray:none" fill-opacity="1" fill="none" stroke-opacity="1" stroke="none">
    <title>Canvas 1</title>
    <g id="Canvas_1: Layer 1">
      <title>Layer 1</title>
      <g id="Graphic_2">
        <rect x="765.5" y="177" width="133.5" height="43.75" fill="#326691"></rect>
        <text transform="translate(770.5 189.14294)" fill="white">
          <tspan font-family="Helvetica Neue" font-size="16" font-weight="700" fill="white" x="27.67" y="16">Postgres</tspan>
        </text>
      </g>
      <g id="Graphic_3">
        <rect x="39.5" y="177" width="133.5" height="43.75" fill="#cc0100"></rect>
        <text transform="translate(44.5 189.14294)" fill="white">
          <tspan font-family="Helvetica Neue" font-size="16" font-weight="700" fill="white" x="42.958" y="16">Rails</tspan>
        </text>
      </g>
      <g id="Graphic_9">
        <text transform="translate(309.538 466.27576)" fill="black">
          <tspan font-family="Helvetica Neue" font-size="16" font-weight="700" fill="black" x="0" y="16">Advanced Active Record with Subqueries:</tspan>
        </text>
      </g>
      <g id="Line_12">
        <line x1="106.25" y1="220.75" x2="106.25" y2="608.5" stroke="#c00" style="stroke-dasharray:4.0,4.0" stroke-width="1"></line>
      </g>
      <g id="Line_13">
        <line x1="831.75" y1="220.75" x2="831.75" y2="608.5" stroke="#326690" style="stroke-dasharray:4.0,4.0" stroke-width="1"></line>
      </g>
      <g id="Line_15">
        <line x1="117.5" y1="296.5" x2="811.1" y2="296.5" marker-end="url(#FilledArrow_Marker)" stroke="#cc0102" stroke-width="1"></line>
      </g>
      <g id="Line_17">
        <line x1="821" y1="328" x2="127.4" y2="328" marker-end="url(#Arrow_Marker)" stroke="#346591" style="stroke-dasharray:4.0,4.0" stroke-width="1"></line>
      </g>
      <g id="Line_18">
        <line x1="117.5" y1="375" x2="811.1" y2="376.97186" marker-end="url(#FilledArrow_Marker_2)" stroke="#cb0200" stroke-width="1"></line>
      </g>
      <g id="Graphic_20">
        <text transform="translate(350.01 224.35327)" fill="black">
          <tspan font-family="Helvetica Neue" font-size="16" font-weight="700" fill="black" x="0" y="16">Simple usage of Active Record:</tspan>
        </text>
      </g>
      <g id="Graphic_21">
        <rect x="94.5" y="293" width="22.5" height="119" fill="#cc0100"></rect>
      </g>
      <g id="Graphic_25">
        <rect x="821" y="293" width="22.5" height="38.25049" fill="#326691"></rect>
      </g>
      <g id="Graphic_40">
        <text transform="translate(320.5 273.54273)" fill="black">
          <tspan font-family="Monaco" font-size="14" font-weight="400" fill="black" x="0" y="14">SELECT AVG(salary) FROM employees</tspan>
        </text>
      </g>
      <g id="Graphic_43">
        <text transform="translate(431.8181 309.16504)" fill="black">
          <tspan font-family="Monaco" font-size="13" font-weight="400" fill="black" x="0" y="13">99306.4</tspan>
        </text>
      </g>
      <g id="Graphic_44">
        <text transform="translate(265.8911 352.83105)" fill="black">
          <tspan font-family="Monaco" font-size="14" font-weight="400" fill="black" x="0" y="14">SELECT * FROM employees WHERE salary &gt; 99306.4</tspan>
        </text>
      </g>
      <g id="Line_48">
        <line x1="821" y1="408.7495" x2="127.4" y2="408.7495" marker-end="url(#Arrow_Marker)" stroke="#346591" style="stroke-dasharray:4.0,4.0" stroke-width="1"></line>
      </g>
      <g id="Graphic_47">
        <rect x="821" y="372.64905" width="22.5" height="38.25049" fill="#326691"></rect>
      </g>
      <g id="Graphic_46">
        <text transform="translate(435.71875 389.91455)" fill="black">
          <tspan font-family="Monaco" font-size="13" font-weight="400" fill="black" x="0" y="13">Result</tspan>
        </text>
      </g>
      <g id="Line_53">
        <line x1="117.5" y1="534" x2="811.1" y2="534" marker-end="url(#FilledArrow_Marker_2)" stroke="#cb0200" stroke-width="1"></line>
      </g>
      <g id="Graphic_52">
        <text transform="translate(151.27197 511.0972)" fill="black">
          <tspan font-family="Monaco" font-size="14" font-weight="400" fill="black" x="0" y="14">SELECT * FROM employees WHERE salary &gt; (SELECT AVG(salary) FROM employees)</tspan>
        </text>
      </g>
      <g id="Line_51">
        <line x1="821" y1="565.0156" x2="127.4" y2="565.0156" marker-end="url(#Arrow_Marker)" stroke="#346591" style="stroke-dasharray:4.0,4.0" stroke-width="1"></line>
      </g>
      <g id="Graphic_50">
        <rect x="821" y="529.76514" width="22.5" height="38.25049" fill="#326691"></rect>
      </g>
      <g id="Graphic_49">
        <text transform="translate(438.71875 546.1807)" fill="black">
          <tspan font-family="Monaco" font-size="13" font-weight="400" fill="black" x="0" y="13">Result</tspan>
        </text>
      </g>
      <g id="Graphic_54">
        <rect x="94.5" y="530.0156" width="22.5" height="38.25049" fill="#cc0100"></rect>
      </g>
    </g>
  </g>
</svg>
<p>In the first case, without subqueries, we are going to the database twice: First to get the average salary, and then again to get the result set. With a subquery, we can avoid the extra roundtrip, getting the result directly with a single query.</p>
<h2 id="working-with-active-record-in-rails"><a href="#working-with-active-record-in-rails" aria-label="working with active record in rails permalink"></a>Working with Active Record in Rails</h2>
<p>Active Record is a little like a walled garden. It protects us as developers (and our users) from the harsh realities of what lies beyond those walls: Differences in SQL between databases (MySQL, Postgres, SQLite), knowing how to properly escape strings to avoid <a href="https://en.wikipedia.org/wiki/SQL_injection">SQL injection attacks</a>, and generally providing an elegant abstraction to interact with our database using the language of our choice, Ruby.</p>
<p>But, SQL is extremely powerful! By understanding the SQL that Active Record is executing, we can open the gate in our walled garden to <strong>reach beyond what you may think is possible to accomplish in Rails</strong>, taking advantage of optimizations and flexibility that may be difficult to achieve otherwise.</p>
<h2 id="what-are-subqueries-in-rails"><a href="#what-are-subqueries-in-rails" aria-label="what are subqueries in rails permalink"></a>What are Subqueries in Rails</h2>
<p>In this article, we will be learning how to use subqueries in Active Record. Subqueries are what their name implies: A query within a query. We will look at how to embed subqueries into the <code>SELECT</code>, <code>FROM</code>, <code>WHERE</code>, and <code>HAVING</code> clauses of SQL, to meet the demands of our business counterparts who are asking to view data in different and interesting ways.</p>
<p>We'll be playing the role of a developer fielding questions from HR. They are asking for reports about our employees at BCE (Best Company Ever), and we'll do our best to find the data they need using Active Record.</p>
<p>The <a href="https://github.com/pganalyze/subqueries-rails-example">source code for this article</a> is available on GitHub.</p>
<h2 id="an-overview-of-our-data"><a href="#an-overview-of-our-data" aria-label="an overview of our data permalink"></a>An Overview of our Data</h2>
<p>Our database has 4 tables:</p>
<ul>
<li><strong>roles</strong>: The job roles of our employees (Finance, Engineering, Sales, HR, etc...)</li>
<li><strong>employees</strong>: The people that work for BCE</li>
<li><strong>performance_reviews</strong>: Performance reviews carried out by an employee's manager, giving them a score between 0 and 100</li>
<li><strong>vacations</strong>: Keeping track of when employees have taken vacation</li>
</ul>
<p>Using <a href="https://dbdiagram.io/">https://dbdiagram.io/</a> we're able to see how these tables relate to each other:</p>
<p>
<span>
      <a href="https://pganalyze.com/static/544de74e19f0479f8d32a99abbac1d1a/c2d9c/subqueries-rails-diagram-dark.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="An Overview of how 4 tables in our database relate to each other" title="An Overview of how 4 tables in our database relate to each other" src="https://pganalyze.com/static/544de74e19f0479f8d32a99abbac1d1a/8c557/subqueries-rails-diagram-dark.png" srcset="https://pganalyze.com/static/544de74e19f0479f8d32a99abbac1d1a/4edbd/subqueries-rails-diagram-dark.png 175w, https://pganalyze.com/static/544de74e19f0479f8d32a99abbac1d1a/13ae7/subqueries-rails-diagram-dark.png 350w, https://pganalyze.com/static/544de74e19f0479f8d32a99abbac1d1a/8c557/subqueries-rails-diagram-dark.png 700w, https://pganalyze.com/static/544de74e19f0479f8d32a99abbac1d1a/e996b/subqueries-rails-diagram-dark.png 1050w, https://pganalyze.com/static/544de74e19f0479f8d32a99abbac1d1a/c2d9c/subqueries-rails-diagram-dark.png 1326w" sizes="(max-width: 700px) 100vw, 700px" loading="lazy">
  </a>
    </span>
</p>
<p>If you are following along, the <code>rails db:seed</code> command will generate 1,000 employees, 1,000 vacations, and 10,000 performance reviews.</p>
<h2 id="the-where-subquery"><a href="#the-where-subquery" aria-label="the where subquery permalink"></a>The Where Subquery</h2>
<p>Now that we have our data set and we’re ready to go let’s help our HR team with their first request:</p>
<blockquote>
<p>Leigh, could you find us all the employees that make <em>more than the average salary</em> at BCE?</p>
</blockquote>
<p>Here we will use a subquery within the <code>WHERE</code> clause to find the employees that match HR's request:</p>
<div data-language="sql"><pre><code><span>SELECT</span> <span>*</span>
<span>FROM</span> employees
<span>WHERE</span>
  employees<span>.</span>salary <span>&gt;</span> <span>(</span>
    <span>SELECT</span> <span>avg</span><span>(</span>salary<span>)</span>
    <span>FROM</span> employees<span>)</span></code></pre></div>
<p>My first attempt at replicating the query above looked like this:</p>
<div data-language="ruby"><pre><code><span>Employee</span><span>.</span>where<span>(</span><span>'salary &gt; :avg'</span><span>,</span> avg<span>:</span> <span>Employee</span><span>.</span>average<span>(</span><span>:salary</span><span>)</span><span>)</span></code></pre></div>
<p><em>But what it produced was two queries</em>: One to find the average, and a second to query employees with a salary greater than that number. Not technically wrong, but <strong>it doesn't line up with the SQL we were going for.</strong> There is also a potential performance impact of two round-trip requests to the database server, along with potential inconsistencies if a new employee making $1B/year is hired between queries one and two. Although this is unlikely in this particular scenario, it’s something to consider as a potential risk.</p>
<div data-language="sql"><pre><code>
<span>SELECT</span> <span>AVG</span><span>(</span><span>"employees"</span><span>.</span><span>"salary"</span><span>)</span> <span>FROM</span> <span>"employees"</span>

<span>SELECT</span> <span>"employees"</span><span>.</span><span>*</span> <span>FROM</span> <span>"employees"</span> <span>WHERE</span> <span>(</span>salary <span>&gt;</span> <span>99306.4</span><span>)</span></code></pre></div>
<p>What we shouldn’t forget about <a href="https://guides.rubyonrails.org/active_record_querying.html">Active Record</a> is that certain methods, such as <code>average(:salary)</code>, actually execute the query and return a result, while other methods implement <a href="https://en.wikipedia.org/wiki/Method_chaining">Method Chaining</a>, allowing you to chain multiple Active Record methods together, building up more complex SQL statements prior to their execution.</p>
<div data-language="ruby"><pre><code><span>Employee</span><span>.</span>where<span>(</span><span>'salary &gt; (:avg)'</span><span>,</span> avg<span>:</span> <span>Employee</span><span>.</span>select<span>(</span><span>'avg(salary)'</span><span>)</span><span>)</span></code></pre></div>
<p>This produces the SQL we want, but note that we had to wrap the placeholder condition <code>:avg</code> in brackets, because the database wants subqueries wrapped in brackets as well.</p>
<p>Because the seed data is generated randomly, your results will vary from mine, but I am seeing <em>487</em> matching employees, getting a result that looks like this:</p>
<div data-language="text"><pre><code>#&lt;ActiveRecord::Relation [#&lt;Employee id: 4, role_id: 5, name: "Bob Williams", salary: 127053.0, created_at: "2020-04-26 18:42:53", updated_at: "2020-04-26 18:42:53"&gt;, #&lt;Employee id: 5, role_id: 4, name: "Bob Florez", salary: 149218.0, created_at: "2020-04-26 18:42:53", updated_at: "2020-04-26 18:42:53"&gt;, ...]&gt;</code></pre></div>
<h3 id="where-not-exists"><a href="#where-not-exists" aria-label="where not exists permalink"></a>Where Not Exists</h3>
<blockquote>
<p>Leigh, we would like to encourage employees to have a healthy work-life balance, and were hoping you could provide us with a list of all the <em>employees who have yet to take any vacation time</em>.</p>
</blockquote>
<p>For this case, <code>NOT EXISTS</code> is a perfect fit, since it only matches records that <strong>do not</strong> have a match in the subquery. An alternative is to perform a left outer join, only choosing the records with no matches on the right side. This is referred to as an <a href="https://gerardnico.com/data/type/relation/sql/anti_join">anti-join</a>, where the purpose of the join is to find records that <strong>do not</strong> have a matching record.</p>
<div data-language="sql"><pre><code><span>SELECT</span> <span>*</span>
<span>FROM</span> employees
<span>WHERE</span>
  <span>NOT</span> <span>EXISTS</span> <span>(</span>
    <span>SELECT</span> <span>1</span>
    <span>FROM</span> vacations
    <span>WHERE</span> vacations<span>.</span>employee_id <span>=</span> employees<span>.</span>id<span>)</span></code></pre></div>
<p>If you're interested in the <strong>LEFT OUTER JOIN</strong> equivalent, it might look like this:</p>
<div data-language="sql"><pre><code><span>SELECT</span> employees<span>.</span><span>*</span>
<span>FROM</span>
  employees
  <span>LEFT</span> <span>OUTER</span> <span>JOIN</span> vacations <span>ON</span> vacations<span>.</span>employee_id <span>=</span> employees<span>.</span>id
<span>WHERE</span> vacations<span>.</span>id <span>IS</span> <span>NULL</span></code></pre></div>
<p>The subquery depends on a match between the <code>employees.id</code> column and the <code>vacations.employee_id</code> column, making it a <a href="https://learnsql.com/blog/correlated-sql-subqueries-newbies/">correlated subquery</a>. Because Rails follows standard naming conventions when querying (the downcased plural form of our model), we can add the above condition into our subquery without too much difficulty.</p>
<div data-language="ruby"><pre><code><span>Employee</span><span>.</span>where<span>(</span>
  <span>'NOT EXISTS (:vacations)'</span><span>,</span>
  vacations<span>:</span> <span>Vacation</span><span>.</span>select<span>(</span><span>'1'</span><span>)</span><span>.</span>where<span>(</span><span>'employees.id = vacations.employee_id'</span><span>)</span>
<span>)</span></code></pre></div>
<p>Using my seed data, I am seeing <em>369</em> employees that have yet to take any vacations.</p>
<div data-language="text"><pre><code>#&lt;ActiveRecord::Relation [#&lt;Employee id: 2, role_id: 2, name: "Alice Florez", salary: 86920.0, created_at: "2020-04-26 18:42:53", updated_at: "2020-04-26 18:42:53"&gt;, #&lt;Employee id: 5, role_id: 4, name: "Bob Florez", salary: 149218.0, created_at: "2020-04-26 18:42:53", updated_at: "2020-04-26 18:42:53"&gt;, ...]&gt;</code></pre></div>
<h2 id="the-select-subquery"><a href="#the-select-subquery" aria-label="the select subquery permalink"></a>The Select Subquery</h2>
<blockquote>
<p>Leigh, could you provide us with a list of employees, <em>including the average salary</em> of a BCE employee, and how much this <em>employee's salary differs from the average</em>?</p>
</blockquote>
<div data-language="sql"><pre><code><span>SELECT</span>
  <span>*</span><span>,</span>
  <span>(</span><span>SELECT</span> <span>avg</span><span>(</span>salary<span>)</span>
    <span>FROM</span> employees<span>)</span> avg_salary<span>,</span>
  salary <span>-</span> <span>(</span>
    <span>SELECT</span> <span>avg</span><span>(</span>salary<span>)</span>
    <span>FROM</span> employees<span>)</span> above_avg
<span>FROM</span> employees</code></pre></div>
<p>Because the subquery is repeated, we can save ourselves a little bit of hassle by placing the subquery SQL into a variable that we'll embed into the outer query. The <code>to_sql</code> method is perfect for this, but it's also fantastic to peak into the SQL that Rails is producing without actually executing the query.</p>
<div data-language="ruby"><pre><code>avg_sql <span>=</span> <span>Employee</span><span>.</span>select<span>(</span><span>'avg(salary)'</span><span>)</span><span>.</span>to_sql

<span>Employee</span><span>.</span>select<span>(</span>
  <span>'*'</span><span>,</span>
  <span>"(<span><span>#{</span>avg_sql<span>}</span></span>) avg_salary"</span><span>,</span>
  <span>"salary - (<span><span>#{</span>avg_sql<span>}</span></span>) avg_difference"</span>
<span>)</span></code></pre></div>
<p>This query does not limit the results in any way, but instead selects two additional columns (<code>avg_salary</code> and <code>avg_difference</code>). Looking at the first three results, I am seeing:</p>
<div data-language="ruby"><pre><code><span>[</span>
  <span>{</span><span>"id"</span><span>=</span><span>&gt;</span><span>1</span><span>,</span> <span>"role_id"</span><span>=</span><span>&gt;</span><span>1</span><span>,</span> <span>"name"</span><span>=</span><span>&gt;</span><span>"Joe Serna"</span><span>,</span> <span>"salary"</span><span>=</span><span>&gt;</span><span>86340.0</span><span>,</span> <span>"avg_salary"</span><span>=</span><span>&gt;</span><span>99306.4</span><span>,</span> <span>"avg_difference"</span><span>=</span><span>&gt;</span><span>-</span><span>12966.399999999994</span><span>}</span><span>,</span> 
  <span>{</span><span>"id"</span><span>=</span><span>&gt;</span><span>2</span><span>,</span> <span>"role_id"</span><span>=</span><span>&gt;</span><span>2</span><span>,</span> <span>"name"</span><span>=</span><span>&gt;</span><span>"Alice Florez"</span><span>,</span> <span>"salary"</span><span>=</span><span>&gt;</span><span>86920.0</span><span>,</span> <span>"avg_salary"</span><span>=</span><span>&gt;</span><span>99306.4</span><span>,</span> <span>"avg_difference"</span><span>=</span><span>&gt;</span><span>-</span><span>12386.399999999994</span><span>}</span><span>,</span> 
  <span>{</span><span>"id"</span><span>=</span><span>&gt;</span><span>3</span><span>,</span> <span>"role_id"</span><span>=</span><span>&gt;</span><span>3</span><span>,</span> <span>"name"</span><span>=</span><span>&gt;</span><span>"Amanda Florez"</span><span>,</span> <span>"salary"</span><span>=</span><span>&gt;</span><span>93600.0</span><span>,</span> <span>"avg_salary"</span><span>=</span><span>&gt;</span><span>99306.4</span><span>,</span> <span>"avg_difference"</span><span>=</span><span>&gt;</span><span>-</span><span>5706.399999999994</span><span>}</span>
<span>]</span></code></pre></div>
<p>As with any SQL query, there are often many ways to arrive at the same result. In this example we used subqueries to find the average employee salary, but it may have been better to use <a href="https://www.postgresql.org/docs/current/tutorial-window.html">window functions</a> instead. They give us the same result, but provide a simpler query which is actually more performant as well. Even on a small dataset of 1000 employees, this query takes approximately 12ms vs 18ms for the subquery equivalent.</p>
<div data-language="sql"><pre><code><span>SELECT</span>
  <span>*</span><span>,</span>
  <span>avg</span><span>(</span>salary<span>)</span> <span>OVER</span> <span>(</span><span>)</span> <span>AS</span> avg_salary<span>,</span>
  salary <span>-</span> <span>avg</span><span>(</span>salary<span>)</span> <span>OVER</span> <span>(</span><span>)</span> <span>AS</span> avg_salary
<span>FROM</span>
  employees</code></pre></div>
<p>The window function approach is actually easier to write in Rails as well!</p>
<div data-language="ruby"><pre><code><span>Employee</span><span>.</span>select<span>(</span>
  <span>'*'</span><span>,</span>
  <span>"avg(salary) OVER () avg_salary"</span><span>,</span>
  <span>"salary - avg(salary) OVER () avg_difference"</span>
<span>)</span></code></pre></div>
<h2 id="the-from-subquery"><a href="#the-from-subquery" aria-label="the from subquery permalink"></a>The From Subquery</h2>
<blockquote>
<p>Leigh, we'd like to know the <em>average performance review score</em> given across all our managers.</p>
</blockquote>
<p>After clarifying with HR, they are looking to take the average score each manager has given, and then take the average of those averages. In other words, the average average. When you are dealing with an <strong>aggregate of aggregates</strong>, it needs to be accomplished in two steps. This can be done using a subquery as the <code>FROM</code> clause, essentially giving us a temporary table to then select from, allowing us to find the average of those averages.</p>
<div data-language="sql"><pre><code><span>SELECT</span> <span>avg</span><span>(</span>avg_score<span>)</span> reviewer_avg
<span>FROM</span> <span>(</span>
  <span>SELECT</span> reviewer_id<span>,</span> <span>avg</span><span>(</span>score<span>)</span> avg_score
  <span>FROM</span> performance_reviews
  <span>GROUP</span> <span>BY</span> reviewer_id<span>)</span> reviewer_avgs</code></pre></div>
<p>To keep our Ruby code clean, we'll place the subquery into a variable which can then be embedded into the main query.</p>
<div data-language="ruby"><pre><code>from_sql <span>=</span>
  <span>PerformanceReview</span><span>.</span>select<span>(</span><span>:reviewer_id</span><span>,</span> <span>'avg(score) avg_score'</span><span>)</span><span>.</span>group<span>(</span>
    <span>:reviewer_id</span>
  <span>)</span><span>.</span>to_sql

<span>PerformanceReview</span><span>.</span>select<span>(</span><span>'avg(avg_score) reviewer_avg'</span><span>)</span><span>.</span>from<span>(</span>
  <span>"(<span><span>#{</span>from_sql<span>}</span></span>) as reviewer_avgs"</span>
<span>)</span><span>.</span>take<span>.</span>reviewer_avg</code></pre></div>
<p>The result of this query is <code>50.652</code>. This makes sense given that the seed data …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pganalyze.com/blog/active-record-subqueries-rails">https://pganalyze.com/blog/active-record-subqueries-rails</a></em></p>]]>
            </description>
            <link>https://pganalyze.com/blog/active-record-subqueries-rails</link>
            <guid isPermaLink="false">hacker-news-small-sites-23629450</guid>
            <pubDate>Wed, 24 Jun 2020 15:55:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hey.com Review]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23628952">thread link</a>) | @manuw
<br/>
June 24, 2020 | https://schipplock.org/rants/hey.html | <a href="https://web.archive.org/web/*/https://schipplock.org/rants/hey.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://schipplock.org/rants/hey.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23628952</guid>
            <pubDate>Wed, 24 Jun 2020 15:25:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google Blew a Ten-Year Lead]]>
            </title>
            <description>
<![CDATA[
Score 834 | Comments 542 (<a href="https://news.ycombinator.com/item?id=23628761">thread link</a>) | @secondbreakfast
<br/>
June 24, 2020 | https://secondbreakfast.co/google-blew-a-ten-year-lead | <a href="https://web.archive.org/web/*/https://secondbreakfast.co/google-blew-a-ten-year-lead">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>Back when there were rumors of Google building an operating system, I thought<span></span> <span>“</span>Lol.”</p>
<p>Then I watched then-PM Sundar Pichai <a href="https://www.youtube.com/watch?v=0QRO3gKj3qw">announce Chrome <span>OS</span></a>. My heart raced. It was perfect.</p>
<p>I got my email through Gmail, I wrote documents on Docs, I listened to Pandora, I viewed photos on TheFacebook. Why did I need all of Windows Vista?</p>
<p>In 2010, I predicted that by 2020 Chrome <span>OS</span> would be the most popular desktop <span>OS</span> in the world. It was fast, lightweight, and $0.</p>
<p><span>“</span>Every Windows and <span>OS</span> X app will be re-built for the browser!” I thought. Outlook-&gt;Gmail. Excel-&gt;Sheets. Finder-&gt;Dropbox. Photoshop-&gt;Figma. Terminal-&gt;Repl.it.</p>
<p>All of your files would be accessible by whoever you wanted, wherever you wanted, all the time. It was obvious. Revolutionary.</p>
<p>I haven’t installed <span>MSFT</span> Office on a machine since 2009. Sheets and Docs have been good enough for me. The theoretical unlimited computing power and collaboration features meant Google Docs was better than Office (and free!).</p>
<p>Then something happened at Google. I’m not sure what. But they stopped innovating on cloud software.</p>
<p>Docs and Sheets haven’t changed in a decade. Google Drive remains impossible to navigate. Sharing is complicated. Sheets freezes up. I can’t easily interact with a Sheets <span>API</span> (I’ve tried!). Docs still shows page breaks by default! <span>WTF</span>!</p>
<p>Even though I have an iPhone and a MacBook, I’ve been married to Google services. I browse Chrome. I use Gmail. I get directions and lookup restaurants on Maps. I’m a YouTube addict.</p>
<p>Yet I’ve been ungluing myself from Google so far this year. Not because of Google-is-reading-my-emails-and-tracking-every-keystroke reasons, but because I like other software so much more that it’s worth switching.</p>
<p>At <span>WWDC</span>, Apple shared Safari stats for macOS Big Sur. It reminded me how much Chrome makes my machine go <span>WHURRRRRR</span>. Yesterday, I made Safari my default browser again.</p>
<p>My Gmail inbox has become a mailbox stuffed with clothing flyers, SaaS mailers, and Rollbar alerts. I love when people respond to Second Breakfast, but their responses get lost amid a sea of plastic bottles. I started using <span>HEY</span> last week. My new email is <a href="mailto:billy@hey.com">billy@hey.com</a>. I love it so far.</p>
<p>I’ve given up on Google Docs. I can never find the documents Andy shares with me. The formatting is tired and stuck in the you-might-print-this-out paradigm. Notion is a much better place to write and brainstorm with people.</p>
<p>The mobile Google results page is so cluttered that I switched my iPhone’s default search to DuckDuckGo. The results are a tad worse, but I’m never doing heavy-duty searches on the go. And now I don’t have to scroll past 6 ads to get the first result. DuckDuckGo’s privacy is an added bonus.</p>
<p>I still use Google Sheets heavily. But wow, Airtable makes Sheets feel decrepit. Where’s the easy API? New ways of formatting? Better collaboration? Simple sheet-as-a-database?</p>
<p>My new usage patterns:</p>
<ul>
<li>Email: <del>Gmail</del> <span>HEY</span></li>
<li>Search: <del>Google</del> DuckDuckGo (mobile) and Google (desktop)</li>
<li>Maps: Google</li>
<li>Docs: <del>Google</del> Notion</li>
<li>Sheets: Google</li>
<li>Video: YouTube (but increasingly I’m noticing other people use Twitch, Instagram, and TikTok)</li>
<li>Video Calls: <del>Google Meet</del> Zoom</li>
</ul>
<p>I’m a long shareholder of Google. It’s amazing how they have four monopolies and only monetize one of them. I’m confident they have a bright future ahead.</p>
<p>But the lack of innovation is frustrating. The product goals are all over the place. Microsoft has a new clear mission: The Cloud. What’s Google’s clear mission?</p>
<p>It feels like they blew a 10 year lead.</p>
</div></div>]]>
            </description>
            <link>https://secondbreakfast.co/google-blew-a-ten-year-lead</link>
            <guid isPermaLink="false">hacker-news-small-sites-23628761</guid>
            <pubDate>Wed, 24 Jun 2020 15:12:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stock Analysis in Python]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23628196">thread link</a>) | @rbanffy
<br/>
June 24, 2020 | https://beta.deepnote.com/article/stock-analysis-in-python | <a href="https://web.archive.org/web/*/https://beta.deepnote.com/article/stock-analysis-in-python">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://beta.deepnote.com/article/stock-analysis-in-python</link>
            <guid isPermaLink="false">hacker-news-small-sites-23628196</guid>
            <pubDate>Wed, 24 Jun 2020 14:23:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Review of Hooked – How to Build Habit-Forming Products]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23628099">thread link</a>) | @herrkra
<br/>
June 24, 2020 | https://jochemgerritsen.com/2020/06/book-review-hooked/ | <a href="https://web.archive.org/web/*/https://jochemgerritsen.com/2020/06/book-review-hooked/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					<p><img src="https://jochemgerritsen.com/wp-content/uploads/2020/06/Hooked-How-to-Build-Habit-Forming-Products-image-199x300.jpg" alt="Image of the Hooked book" width="199" height="300" srcset="https://jochemgerritsen.com/wp-content/uploads/2020/06/Hooked-How-to-Build-Habit-Forming-Products-image-199x300.jpg 199w, https://jochemgerritsen.com/wp-content/uploads/2020/06/Hooked-How-to-Build-Habit-Forming-Products-image.jpg 331w" sizes="(max-width: 199px) 100vw, 199px"><br>
What makes you check your phone 100 times per day? Why do you always use Google instead of Bing? Or why do lay awake at night, scrolling through your Instagram feed, even when you know you should be sleeping?</p>
<p>In <a href="https://amzn.to/2Bww2Ak">Hooked: How to Build Habit Building Products</a>, Nir Eyal provides the exact model that many digital products use to make us addicted. According to the author, all these apps use the Hook model — finding ways to intertwine their usage into our daily lives, routines and habits.</p>
<p>The book has been praised by many well-known entrepreneurs, such as Eric Ries (the Lean Startup), Dave McClure (500 Startups) and Boris Veldhuijzen van Zanten (The Next Web). So clearly, Hooked is a great read for company founders, particularly when you want to dive into the psychology of user interaction and making your app or product ‘stick’. So if you want a quick overview of the model without needing to read the entire book, you can find a summary and my book review of Hooked below.</p>


<h2>Highlights of Hooked: The Hook Model</h2>
<p>In summary, the book Hooked provides a model to ‘hook’ users. It’s a model to make them come again and again (I suppose ‘Addicted’ could have been an alternative title for the book but one with a bit less flair).</p>
<p>As you can see in the image below, the Hook model consists of four different steps. The Trigger, the Action, the Variable Reward, and the Investment. Specifically, users are:</p>
<ol>
<li>Triggered to open your app or product;</li>
<li>After which they perform an action within the product;</li>
<li>This results in a variable reward;</li>
<li>And finally they make an investment to improve their experience.</li>
</ol>
<p><img src="https://cdn0.tnwcdn.com/wp-content/blogs.dir/1/files/2014/01/the_hook-520x403.png" alt="the_hook"></p>
<p>Take any social media platform as an example, such as Instagram. Suppose you’re at work, and suddenly your phone shows a notification. A friend commented on your Instagram photo! This notification serves as a trigger for you to open the Instagram app. You look at the picture, and perhaps you like your friend’s comment. This is the action you’ve just taken. Consequently, you mindlessly scroll through your feed, hoping to find interesting photos, videos or other hidden gems. Considering that you sometimes find a hidden gem, and sometimes you don’t, this is the variable reward. And finally, you leave a comment somewhere, and perhaps you take a work selfie that you upload to the app. This is the investment you make.</p>
<p>This is a simple example of the Hooked model; in the book, the author expands on each different section — which I will do here shortly too.</p>
<h3>Trigger</h3>
<p>The Hook Model starts with the trigger. In this example, the trigger was a notification on your phone. According to Eyal, the trigger can be both internal and external.</p>
<p>In this case, the Instagram notification is an external trigger. Similarly, an advertisement, email, or even word-of-mouth marketing may be the external trigger you need as a user to start engaging with a product.</p>
<p>Alternatively, a trigger can be internal. This is the case when users have already gone through the Hooked model (and the circle in the image above) once or several times. You yourself trigger a need or want to open the Instagram app, without any external interference.</p>
<h3>Action</h3>
<p>What is the action you want a user to take in/with your product? The goal of the product team is to (among many other things) make the action as easy as possible.</p>
<p>In both this model and life in general, an action consists of three aspects: motivation, ability, and trigger. This is also called the Fogg Behavioral Model, represented as B = MAT. Take a simple example: the behavior (or action) of doing groceries. If you do groceries you need to be 1) motivated to do so, 2) able to do so, and 3) you need a certain trigger. So if it’s Friday night and you don’t feel like going outside (motivation), if your car has stopped working (ability) or if you have a full fridge (trigger), you’re not very likely to go to the supermarket.</p>
<h3>Variable Reward</h3>
<p>Interestingly, a reward a user gets from a product should not be the same every time. Just like with gambling, there should be a variable reward — sometimes you get X, sometimes you get Y, or perhaps sometimes you get nothing at all.</p>
<p>Preferably, a product has so-called “infinite variability”. You can find this infinite variability in the un-ending scroll of products like Instagram, Reddit, Pinterest or even certain news sites. You never know what you can expect, making the product new and exciting, every time you open it.</p>
<h3>Investment</h3>
<p>Users making an investment into your product helps them get back to the product in several ways. First, investing in the product usually improves the product itself. For instance, LinkedIn adding more information to their profile makes the entire platform more useful for other users.</p>
<p>In addition, one bias (or fallacy) we all face is the sunk cost fallacy. I’ve mentioned <a href="https://jochemgerritsen.com/2019/11/making-unrestricted-choices/">cognitive biases</a> before, and the sunk cost fallacy is the idea that when you put more effort or energy into something, it becomes more difficult to let it go or step away. In this sense, a user’s investment in your product will make it more likely for him/her to stick with your product, even if there are better alternatives on the market.</p>

<h2>Applying the Lessons of Hooked</h2>
<p>Whenever you read a business book, it’s important to look at how to apply it to your specific case. Luckily, Nir Eyal provides several questions and small to-do’s at the end of every chapter that you can use to apply the Hooked model to your product.</p>
<p>Specifically, you could look at your product (or service) and answer questions such as:</p>
<ul>
<li>Which internal trigger does your user experience most frequently?</li>
<li>Which resources are limiting your users’ ability to accomplish the tasks [or actions] that will become habits?</li>
<li>What are 3 ways your product might increase users’ search for variable rewards?</li>
<li>What ‘bit of work’ [or investment] are your users doing to increase their likelihood of returning?</li>
</ul>
<p>These are just a couple of questions from the book; if you truly want to apply this model to your product, I recommend reading (and answering) all of them.</p>

<h2>Hooked Book Review by an entrepreneur</h2>
<p>In my opinion, the Hooked model and book is particularly relevant for entrepreneurs and company founders building B2C digital products. Whether you’re building a new kind of social media platform, a videogame, an app to order groceries, or something else, the Hooked model can help you to increase the chances of your users returning to your product.&nbsp;That said, the ideas in the book are useful for B2B products too, but it really depends on your product whether the model is relevant.</p>
<p>While the book’s theory isn’t entirely ground-breaking, I think it’s very useful to have a model which you can apply to the interactions of your users with your product. As founders or product managers, we often talk about a <em>customer journey</em>, which is a good way of looking at it. However, by using the Hooked model, you may find new improvements you can make to that customer journey, that you wouldn’t have found otherwise.</p>
<p>This particularly applies to the ‘variable reward’ and ‘investment’ steps of the Hooked circle. Most people designing a product know the trigger leading to a user interaction, and the action they want their users to take. However, creating a variable reward, and ensuring that a user goes beyond ‘just interacting’ to actually investing in the product, is something that often comes as an after-thought. Applying this model to your product, makes you really think about the different ways and new functionalities you could implement to enable these two steps.</p>
<p>Overall, I found the book quite enjoyable. As is usually the case with books that offer a model, it is not entirely necessary to read the whole book. By reading this article, you already have a fair understanding of the model, and otherwise you could simply read some extra material on <a href="https://www.nirandfar.com/hooked-user-behavior-resources/">the author’s blog</a>. However, reading the entire book does make everything sink in better, and if you want to apply the model directly to your product, it may be useful to <a href="https://amzn.to/2Bww2Ak">get yourself a copy</a>.</p>
<p><span>Note that I only write about books that I’ve actually read and products I’ve actually used — this post contains an affiliate link from Amazon; as an Amazon Associate I may earn a small commission if you click and buy the product in question.</span></p>
<hr>
					</div></div>]]>
            </description>
            <link>https://jochemgerritsen.com/2020/06/book-review-hooked/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23628099</guid>
            <pubDate>Wed, 24 Jun 2020 14:15:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Boring Benefits of Lisp]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23627627">thread link</a>) | @selff
<br/>
June 24, 2020 | https://justinmeiners.github.io/boring-benefits-of-lisp/ | <a href="https://web.archive.org/web/*/https://justinmeiners.github.io/boring-benefits-of-lisp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">




<p>Lisp advocates are famous for having extravagant reasons for why Lisp is their favorite language.
You might have heard that its the <a href="http://www.paulgraham.com/avg.html">most powerful language</a>,
due to feature like <a href="http://www.paulgraham.com/onlisp.html">macros</a> or <a href="https://en.wikipedia.org/wiki/Homoiconicity">homioconicty</a>.
Certainly, Common Lisp and Scheme have no shortage of beautiful ideas,
but due to their influence, most of their benefits have now been included
in modern languages, and as you may know fancy language abstractions <a href="https://justinmeiners.github.io/think-in-math/">don’t
appeal to me</a>.
I am now interested in it for very simple and practical reasons;</p>

<ol>
<li>Lisp is a fully standardized language. Consequently, it is well understood, cross-platform, and has multiple implementations, including several with free licenses.</li>
<li>Lisp has great documentation, books, and learning resources. SICP is “the book” for Scheme. Common Lisp has several good ones.</li>
<li>Lisp is mature and extremely stable. Code be written once, and run again years later, without modification.</li>
<li>Lisp implementations are reasonably fast. The true believers claim Common Lisp is as fast as C. In general it’s not even close, but for a high-level, dynamic, language, <a href="https://benchmarksgame-team.pages.debian.net/benchmarksgame/fastest/lisp.html">it’s pretty fast</a>.</li>
<li>Lisp is well designed and follows solid computer science principles.
It has a focused selection of features and an elegant evaluation model which make it easy to
write and compose functionality.</li>
</ol>


<p>These features don’t appear too remarkable or unique to Lisp.
In fact, this pattern of requirements was actually established by ANSI C first, and later adopted by Lisp.
But, the surprising thing is how few languages since have followed the pattern.
Of course satisfaction lies on a spectrum; some languages do more than others,
but very few follow it to a degree that can be asserted with confidence.
Usually, you can say a language somewhat satisfies it, followed by a list of ugly qualifications.</p>

<p>Take Python for example. It’s well designed, has great resources, is fairly stable.
It has an <a href="https://norvig.com/python-lisp.html">elegant design</a> like Lisp.
But, is it standardized? Kind of, they have a spec, but it has one defacto implementation.
CPython does whatever they want, and others follow along.
The alternative implementations all have compatibility compromises.
Neither is it fast, unless you use a [JIT] implementation which makes it tolerable,
but that has its own quirks, and you can’t use many libraries with it.</p>

<p>So are Lisp and C the only languages that do this? No, but there aren’t as many as you think.
Lisp just happens to be one of them, and it’s a design that I enjoy using and learning about.</p>


</div>]]>
            </description>
            <link>https://justinmeiners.github.io/boring-benefits-of-lisp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23627627</guid>
            <pubDate>Wed, 24 Jun 2020 13:29:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Styling Browser Console]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23627456">thread link</a>) | @tsl143
<br/>
June 24, 2020 | https://itsopensource.com/how-to-format-browser-console/ | <a href="https://web.archive.org/web/*/https://itsopensource.com/how-to-format-browser-console/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p><code>console.log</code> is the most widely used debugging technique used by Javascript developers. While debugging <code>console.log</code> is sprinkled almost anywhere in the code, after code execution, console panel is full of console messages, this blog lists some useful console commands which can help to format and declutter console panel for more meaningful console messages.</p>
<h3><center> console.(log/info/warn/error) </center></h3>
<h4>Basic usage</h4>
<div data-language="javascript"><pre><code>console<span>.</span><span>log</span><span>(</span><span>123</span><span>)</span><span>;</span>


console<span>.</span><span>log</span><span>(</span><span>"abc"</span><span>,</span> <span>123</span><span>)</span><span>;</span>


console<span>.</span><span>log</span><span>(</span><span>[</span><span>1</span><span>,</span><span>2</span><span>,</span><span>3</span><span>]</span><span>,</span> <span>"abc"</span><span>,</span> <span>123</span><span>)</span><span>;</span>
</code></pre></div>
<h4>Substitution in console</h4>
<div data-language="javascript"><pre><code>console<span>.</span><span>log</span><span>(</span><span>"This is a %s example also accept %d number, and %o object too"</span><span>,</span> <span>"substitution"</span><span>,</span> <span>33</span><span>,</span> <span>{</span> a<span>:</span> <span>1</span> <span>}</span><span>)</span><span>;</span></code></pre></div>
<p><span>
      <a href="https://itsopensource.com/static/0c8ee580f41c12f778b419b6b2269061/969f4/substitution-console.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="substitution-console" title="substitution-console" src="https://itsopensource.com/static/0c8ee580f41c12f778b419b6b2269061/799d3/substitution-console.png" srcset="https://itsopensource.com/static/0c8ee580f41c12f778b419b6b2269061/00d96/substitution-console.png 148w,
https://itsopensource.com/static/0c8ee580f41c12f778b419b6b2269061/0b23c/substitution-console.png 295w,
https://itsopensource.com/static/0c8ee580f41c12f778b419b6b2269061/799d3/substitution-console.png 590w,
https://itsopensource.com/static/0c8ee580f41c12f778b419b6b2269061/969f4/substitution-console.png 776w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span>
<em>Please take care of the sequence of params</em></p>
<h4>Styling in console</h4>
<p><code>console</code> accepts CSS styles we can use <code>%c</code> to pass CSS styles 😎. Styles apply to whatever text is after <code>%c</code>. It can be mixed with substitutions too, but again make sure of the sequence of parameters.</p>
<div data-language="javascript"><pre><code>console<span>.</span><span>log</span><span>(</span><span>"This is some %cShow off console message"</span><span>,</span> <span>"font-size:30px; color: #fff; background: #3d7e9a"</span><span>)</span><span>;</span></code></pre></div>
<p><span>
      <a href="https://itsopensource.com/static/b51a12408365feff4d934e102ecbff7b/fd398/styled-console.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="styled-console" title="styled-console" src="https://itsopensource.com/static/b51a12408365feff4d934e102ecbff7b/799d3/styled-console.png" srcset="https://itsopensource.com/static/b51a12408365feff4d934e102ecbff7b/00d96/styled-console.png 148w,
https://itsopensource.com/static/b51a12408365feff4d934e102ecbff7b/0b23c/styled-console.png 295w,
https://itsopensource.com/static/b51a12408365feff4d934e102ecbff7b/799d3/styled-console.png 590w,
https://itsopensource.com/static/b51a12408365feff4d934e102ecbff7b/fd398/styled-console.png 767w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<hr>
<h3><center> console.assert </center></h3>
<p>This is generally used for conditional logging, accepts a <code>condition</code> as the first param, and logs the next params only if the given condition is false with <code>Assertion failed</code> error.</p>
<div data-language="javascript"><pre><code><span>const</span> a <span>=</span> <span>1</span><span>;</span>
console<span>.</span><span>assert</span><span>(</span>a<span>===</span><span>1</span><span>,</span> <span>"a is not equal to 1"</span><span>)</span><span>;</span>

console<span>.</span><span>assert</span><span>(</span>a<span>===</span><span>2</span><span>,</span> <span>"a is not equal to 2"</span><span>)</span><span>;</span>
</code></pre></div>
<p><span>
      <a href="https://itsopensource.com/static/d6749a94989266cd09be0d34b0ce7ca1/275e0/assert-console.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="assert-console" title="assert-console" src="https://itsopensource.com/static/d6749a94989266cd09be0d34b0ce7ca1/275e0/assert-console.png" srcset="https://itsopensource.com/static/d6749a94989266cd09be0d34b0ce7ca1/00d96/assert-console.png 148w,
https://itsopensource.com/static/d6749a94989266cd09be0d34b0ce7ca1/0b23c/assert-console.png 295w,
https://itsopensource.com/static/d6749a94989266cd09be0d34b0ce7ca1/275e0/assert-console.png 492w" sizes="(max-width: 492px) 100vw, 492px" loading="lazy">
  </a>
    </span></p>
<hr>
<h3><center> console.(time/timeLog/timeEnd) </center></h3>
<p>When we try to measure the performance of a website or a function we use to add <code>console.log(Date.now)</code> before and after a function and do the maths to get execution time. Javascript has a native way to achieve this. <code>console.time</code> marks the start of time, <code>console.timeEnd</code> stops the timer and gives the total time taken. <code>console.time</code> takes label as a parameter in case you want to use multiple timers. <code>console.timeLog</code> can be used anywhere in between to check time elapsed till then.</p>
<div data-language="javascript"><pre><code><span>function</span> <span>checkTime</span><span>(</span><span>)</span> <span>{</span>
  console<span>.</span><span>time</span><span>(</span><span>"checkTime"</span><span>)</span><span>;</span>
  <span>for</span> <span>(</span><span>let</span> i <span>=</span> <span>0</span><span>;</span> i <span>&lt;=</span> <span>300000000</span><span>;</span> i<span>++</span><span>)</span> <span>{</span>
		<span>if</span> <span>(</span>i <span>===</span> <span>15000000</span><span>)</span> console<span>.</span><span>timeLog</span><span>(</span><span>"checkTime"</span><span>)</span><span>;</span>
	<span>}</span>
	console<span>.</span><span>timeEnd</span><span>(</span><span>"checkTime"</span><span>)</span><span>;</span>
<span>}</span>
<span>checkTime</span><span>(</span><span>)</span><span>;</span>


</code></pre></div>
<p><span>
      <a href="https://itsopensource.com/static/2e483794c9918a1dcb5c155c9498d05d/68a6d/time-console.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="time-console" title="time-console" src="https://itsopensource.com/static/2e483794c9918a1dcb5c155c9498d05d/68a6d/time-console.png" srcset="https://itsopensource.com/static/2e483794c9918a1dcb5c155c9498d05d/00d96/time-console.png 148w,
https://itsopensource.com/static/2e483794c9918a1dcb5c155c9498d05d/0b23c/time-console.png 295w,
https://itsopensource.com/static/2e483794c9918a1dcb5c155c9498d05d/68a6d/time-console.png 484w" sizes="(max-width: 484px) 100vw, 484px" loading="lazy">
  </a>
    </span></p>
<hr>
<h3><center> console.(count/countReset) </center></h3>
<p>There are times where we want to count how many times a function is called, we need to create a dummy counter just for logging, <code>console.count</code> handles this, every time it is called it increments by 1 and consoles the value against the passed <code>label</code> or <code>default</code>. We can use multiple counters in the same code with different labels. Any counter can be reset with <code>console.countRest</code> passing respective label or nothing in case of <code>default</code>.</p>
<div data-language="javascript"><pre><code>console<span>.</span><span>count</span><span>(</span><span>"myCounter"</span><span>)</span><span>;</span>

console<span>.</span><span>count</span><span>(</span><span>"myCounter"</span><span>)</span><span>;</span>

console<span>.</span><span>count</span><span>(</span><span>"myCounter"</span><span>)</span><span>;</span>

console<span>.</span><span>countReset</span><span>(</span><span>"myCounter"</span><span>)</span><span>;</span>

console<span>.</span><span>count</span><span>(</span><span>"myCounter"</span><span>)</span><span>;</span>
</code></pre></div>
<p><span>
      <a href="https://itsopensource.com/static/df10483a24aee1f15b0d6815cdbc403b/20978/count-console.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="count-console" title="count-console" src="https://itsopensource.com/static/df10483a24aee1f15b0d6815cdbc403b/20978/count-console.png" srcset="https://itsopensource.com/static/df10483a24aee1f15b0d6815cdbc403b/00d96/count-console.png 148w,
https://itsopensource.com/static/df10483a24aee1f15b0d6815cdbc403b/0b23c/count-console.png 295w,
https://itsopensource.com/static/df10483a24aee1f15b0d6815cdbc403b/20978/count-console.png 515w" sizes="(max-width: 515px) 100vw, 515px" loading="lazy">
  </a>
    </span></p></section></div>]]>
            </description>
            <link>https://itsopensource.com/how-to-format-browser-console/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23627456</guid>
            <pubDate>Wed, 24 Jun 2020 13:14:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Slate Star CoDoxxed]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23627301">thread link</a>) | @mhb
<br/>
June 24, 2020 | https://www.stationarywaves.com/2020/06/slate-star-codoxxed.html | <a href="https://web.archive.org/web/*/https://www.stationarywaves.com/2020/06/slate-star-codoxxed.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-451966706447828793" itemprop="description articleBody">
<div dir="ltr" trbidi="on"><p>
Get it? Because he says they're "doxxing" him.</p><p>

"Doxxing" is a type of cyber-bullying in which the bully publicly reveals private information about the target, such as their home phone number or address, their employer's information, photos of the target's children, and so on. This is considered to be extremely threatening. Imagine that someone publicly posts a photo of your small child playing at the park, along with the Google Maps link to the park and a comment to the effect of, "This is where that racist Joe plays with his kids." That's doxxing. Yes, it's bad.</p><p>

But that's not what's happening to Dr. Scott Alexander So-and-So. Let's dive in.</p><h3>
First, The Back-Story</h3>
<p>
Go ahead and cruise on over to slatestarcodex.com to get Dr. Scott Alexander So-and-So's version of the story. It goes something like this: A writer from <i>The New York Times</i> wanted to write a story about a popular blog that generates a lot of interest and that maybe got some things right about COVID-19 early on. That was fine with Dr. Scott Alexander So-and-So until the journalist said, "By the way, I've been able to figure out what the So-and-So stands for, and I'm going to put that into my story." Dr. Scott freaks out a little and says no, don't do that. The journalist says it's company policy.</p>

<p>
So, Dr. Scott Alexander So-and-So deleted his whole blog, saying that <i>The New York Times</i> was trying to endanger him by doxxing him "for clicks."</p>

<p>
Before I go on, I would like to remind my readers of my previous posts about Dr. Scott Alexander So-and-So. <a href="https://www.stationarywaves.com/search?q=slate+star+codex" target="_blank">Here's a link</a>. You will see from what I've written before that I consider the guy to be really weird. It's not just that I dislike his blog - and I do - it's that he seems emblematic of a very bizarre strain of Silicon Valley culture, and the deeper you get into this crowd, the heebier the jeebies, if you catch my drift.&nbsp;</p>

<p>
His blog rose to prominance when some well-regarded bloggers started linking to his posts. They all seemed to consider him very smart and thoughtful. Soon enough, "everyone" was reading him. Over time, his posts have become more performative. He started out writing like a self-conscious nerd, and now he writes as though he is playing the part of a self-conscious nerd who thinks he is a really smart and funny guy. That's fine. Fame changes you. I don't care.</p>

<p>
What I do care about is the content of his blog. Each post tackles any number of topics. He's written on climate science and economics and technology and artificial intelligence and psychiatry and biology and sociology and anything else. He always presents his views as though he is an expert, but quite often it's painfully obvious that he's just done a couple of hours of internet research. There's no shame in doing some casual research and blogging about it, but when everyone starts calling you an expert, and you keep doing light research and presenting it as Dr. Scott Alexander So-and-So Presents The Answer To A Problem That People Have Been Trying To Solve For Decades, then it starts to get on my nerves.</p>

<p>
I mean, it's <i>dorky</i> to do what effectively amounts to college homework assignments as an adult passing the time. But it's problematic to be taken seriously for it. </p>
<br>
<h3>
An "Anonymous" Blogger</h3>
<p>
Dr. Scott Alexander So-and-So openly admits that his name is a pseudonym. First question: Why is he using a pseudonym? Maybe it's like a stage name. Lots of people have stage names. Stage names can be a lot of fun. But that's not why Dr. Scott Alexander So-and-So says he uses a pseudonym. Instead, he says it's because he wants to remain anonymous.</p>

<p>
But Dr. Scott Alexander So-and-So <i>also</i> says that Scott Alexander is his real-life first and last name. That sure is an odd choice of pseudonyms for someone who wishes to remain anonymous. The legendary whistleblower "Deep Throat" wasn't a guy named Deep Throat McInnis, and if he was, going by "Deep Throat" wouldn't exactly be a cloak of anonymity. "Deep Throat" was not a pseudonym that resembled his or her real name at all. It was an obviously made-up moniker; it was intended to be <i>obviously</i> made up, because if everyone knows that Deep Throat's real name is nothing whatsoever resembling Deep Throat, then no one has any idea what Deep Throat's real name is. That's true anonymity. That's not what Dr. Scott Alexander So-and-So wanted, obviously. If he wanted <i>that kind</i> of anonymity, then he would have chosen a pseudonym more like "Deep Throat," or "Alone" (the pseudonym of the writer of <i>The Last Psychiatrist</i> blog), or "Slate Star Codex Guy" or something.</p>

<p>
Pretty much everyone knows that Mark Twain is Samuel Clemens. Samuel Clemens didn't choose "Mark Twain" as a pen name because he wanted to be anonymous. He chose it because he thought he could sell more books under the name "Mark Twain" than under the name "Samuel Clemens," and he was probably right. Mark Twain sounds way better. But when the press discovered his real name, Samuel Clemens didn't delete all his books and complain about being doxxed. He just did what any normal person using a pen name would do: He said, yep, but I write books under the name Mark Twain. And there was no issue.</p>

<p>
The matter was slightly different with "Publius," or "Publicus," or whatever name they were using to write <i>The Federalist Papers</i>. In that case, they had to be anonymous because they could have been killed for treason. Notice again how "Publius" bears scant resemblance to "John Jay" or "John Adams."</p>

<p>
It gets worse, of course. Not only did Dr. Scott Alexander So-and-So choose a "pseudonym" that was actually just his real name, he published many old links to all his old blog posts, in which he discussed personal details of his life. He discussed the experiences of the patients he saw in his clinical psychiatric practice. He held public meet-ups, advertised on his blog and on his social media accounts, where he agreed to meet with pretty much any old person who happened to read his blog or follow him on Twitter. He didn't meet strangers with a cloak and a mask, either. He met them using his real face and his real name and as his own, real, self. In short, he presented himself publicly as Dr. Scott Alexander So-and-So, Please Don't Use My Last Name Because I Want To Be Anonymous, Honest.</p>

<p>
Not exactly the behavior of a man who seeks anonymity, is it?</p>

<h3>
Playing At Being Famous</h3>
<p>
But okay, maybe he was just naive about the matter. That could be the explanation, right?</p>

<p>
Still, <i>fifteen years</i> of naivete over the course of progressively building internet fame seems to strain credulity. Once you start getting calls from <i>The Times</i>, wouldn't you reconsider your willy-nilly attitude toward divulging personal details? I mean, if it mattered to you that you remain anonymous, and you started to become famous, wouldn't you then quietly cull your blog of all references to your real life and real identity, and then just stick to publishing bi-weekly homework essays? Wouldn't you cool it with the public meet-ups and stuff?</p>

<p>
You would indeed, <i>if you cared about anonymity</i>.</p>

<p>
So, another possible explanation here is that Dr. Scott Alexander So-and-So liked being famous and well-regarded for publishing homework essays on the internet. He liked being able to organize meet-ups and watch strangers show up, wanting to meet him. He got a taste for fame, and decided he wanted to keep up with it. That's find and dandy, too. I don't fault a man for wanting to be famous. Lots of people want that.&nbsp;</p>

<p>
Then, this feature in the <i>New York Times</i> should be his big break, right? Finally he gets his big spotlight in the press. Finally he can divulge his true identity, set up a Patreon account, publish a book, and maybe secure a regular writing spot at <i>Slate Magazine</i>, or Vox, or The Atlantic or something. If you wanted to be a famous public intellectual, isn't that what you'd do? That's what I would do. I would work hard for my big break, and when it finally came, I would try to make the most of it. I'd try to capitalize.</p>

<p>
But that's not what Dr. Scott Alexander So-and-So would do. What would he do? <i>Delete his whole blog and complain that he's being persecuted.</i> Weird, right?</p>

<h3>
Another Possibility</h3>
<p>
I'm just going to float this theory. I have no idea if it's true, and no skin in the game one way or the other. But it's a theory that makes sense to me.</p>

<p>
Imagine you did homework essays for fun. Imagine you were kind of a nerd who lived with ten other people in the same house, you've gone on record saying that you don't have much luck with women, and you're basically just a clinical psychiatrist somewhere. Then imagine one day a lot of genuinely smart public intellectuals start reading your homework and say, "Hey, look at this guy. He seems smart."</p>

<p>
So then imagine that you decide to keep up with the homework. People are reading your posts. You feel well-regarded. Heck, you <i>are</i> well-regarded. You get a taste of fame, and you decide you enjoy it and you want more of it. So you keep at your homework, and people keep reading you and linking to you.</p>

<p>
And it's all pretty nice because it comes easy to you. You can do a couple of hours of internet research and write about it, no problem. So that's what you do. But at the bottom of it all, you know you're not really solving any problems. You know that your lengthy essays aren't really all that meritorious. You don't think you're all that smart, but everyone keeps saying that you are anyway. Thus, you enjoy the position you're in, you love the fame and the accolades, you like the meet-ups, maybe you even get more romantic attention than you did before.</p>

<p>
But you don't have what it takes to capitalize on your fame because, at the bottom of it, you only have the willingness to do a couple hours' internet research per week. You know that people who write books - people like Malcolm Gladwell and James Altucher - actually spend a lot of time and money on research and interviews and collecting information. You know that it's their full-time job. And you know …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.stationarywaves.com/2020/06/slate-star-codoxxed.html">https://www.stationarywaves.com/2020/06/slate-star-codoxxed.html</a></em></p>]]>
            </description>
            <link>https://www.stationarywaves.com/2020/06/slate-star-codoxxed.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23627301</guid>
            <pubDate>Wed, 24 Jun 2020 12:56:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Breaking into a house using a Power Bank]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23627143">thread link</a>) | @novamostra
<br/>
June 24, 2020 | https://novamostra.com/2020/06/23/breaking-into-a-house-using-a-power-bank/ | <a href="https://web.archive.org/web/*/https://novamostra.com/2020/06/23/breaking-into-a-house-using-a-power-bank/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-214">
	
	<!-- .entry-header -->

	<div>
		<p>Or… how insecure is the two wire video doorbell implementation from Avidsen.</p>
<p><iframe width="560" height="315" src="https://www.youtube.com/embed/gtnDg_UzcPE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>

<p>About a month ago I bought the <a href="https://www.avidsenstore.com/visiophone-ylva-2-lecteur-rfid-p.html">Avidsen Visiophone YLVA 2+</a> and the reason why I chose to buy a wired video doorbell over a wireless one, was due to security concerns. Lucky me… I found that with the current device it takes almost the same time for someone with a Quick Charge enabled Power Bank to enter my house as with someone with the door’s key!</p>
<p>Immediately after unboxing the doorbell and removing the single screw from the doorbell for an initial inspection I noticed that both Entry Gate’s and Door’s control electrical contacts where located at the doorbell site. Wait… it couldn’t be, I may be wrong… let’s read the <a href="https://www.avidsen.com/cache/documents/product/notice-112249-avidsen.pdf">manual</a>.</p>
<p><strong>Page 27 of the PDF</strong> (Page 7 of the English Version manual):<br>
No! Bad luck! Exactly what I thought!<br>
<img src="https://novamostra.com/wp-content/uploads/2020/05/doorphone.png" alt="Avidsen videophone"><br>
<strong>Page 29 of the PDF:</strong><br>
The doorbell, with all the controls, is secured in place with a <strong>single</strong> Philips screw without any form of tamper protection!<br>
<img src="https://novamostra.com/wp-content/uploads/2020/05/singleScrew.png" alt="Doorphone installation"></p>
<p><strong>Page 32 of the PDF:</strong><br>
How to control a 12V electric strike plate for the door and the Gateway entry control:<br>
<img src="https://novamostra.com/wp-content/uploads/2020/05/installation.png" alt="Door and Gate control"></p>
<h2>How to get 12V from a QC Power Bank</h2>
<p>Power Bank’s rated as QuickCharge 3 (QC3) and later, can output 12V by using Sam Mallicoat’s <a href="https://hackaday.com/2017/03/04/unlocking-12v-quick-charge-on-a-usb-power-bank/#comment-4199744">reply from hackaday</a>:</p>
<blockquote>
<p>It’s easy to set a QC3 supply to 12V with just two resistors and a toggle or push button switch. Here’s how: Take a 10K Ohm and a 2.2K Ohm and solder in series across the Vbus (red) to ground(black wire). The tap between the two resistors will measure about a Volt. Solder D+ (green to this tap. Then wire the D- (white) through a N.O. switch to the same tap.<br>
Apply adapter or power pack supply and wait 1.5 seconds to push the button. Presto, 12V @1.5! No need to hold the button, the supply stays at 12.</p>
</blockquote>
<h2>Schematic</h2>
<p><img src="https://novamostra.com/wp-content/uploads/2020/05/qc12V.jpg" alt="Get 12V from Quickharge"></p>
<p><strong>The output when using a Blitzwolf BW-P6, 10000 mAH with Quick charge 3.0</strong></p>
<p><iframe width="560" height="315" src="https://www.youtube.com/embed/xZJG_Px8mw0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<h2>Breaking into the house</h2>
<p>So the procedure is as follows:<br>
<strong>1st Step:</strong> Unscrew the single Philips Screw.<br>
<strong>2nd Step:</strong> Apply 12 volts to LK+ and LK- contacts.<br>
<strong>3rd Step:</strong> Get into the house! (Optional, screw the doorbell  back to leave no traces)</p>
<h2>This is a serious security issue and every owner should be aware of.</h2>
<p>I tried to contact Avidsen from their site’s Contact Form and using two emails from their contact page without any luck. I hope that this post will reach owners out there to avoid any bad situations.</p>
<h2>Furthermore, my doorbell is not the only model. There are many more :</h2>
<ul>
<li><a href="https://www.avidsenstore.com/interphone-video-asgard-2-fils-p.html">Asgard</a></li>
<li><a href="https://www.avidsenstore.com/visiophone-2-fils-bulla-p.html">Bulla</a></li>
<li><a href="https://www.avidsenstore.com/interphone-video-effet-miroir-p.html">Effet miroir</a></li>
<li><a href="https://www.avidsenstore.com/visiophone-couleur-ultra-plat-design-effet-miroir.html">Effet miroir ref: 642277</a></li>
<li><a href="https://www.avidsenstore.com/interphone-video-krasten-2-fils-p.html">Krasten 2</a></li>
<li><a href="https://www.avidsenstore.com/interphone-video-nora-noir-p.html">Nora Noir</a></li>
<li><a href="https://www.avidsenstore.com/visiophone-thomson-smart-p.html">Smart 761</a></li>
<li><a href="https://www.avidsenstore.com/interphone-video-thomson-ecran-18-cm-p.html">Thomson 7" ref: 512162</a></li>
<li><a href="https://www.avidsenstore.com/interphone-video-ylva-ecran-11cm-p.html">Ylva</a>, <a href="https://www.avidsenstore.com/visiophone-ylva-2-lecteur-rfid-p.html">2+</a>, <a href="https://www.avidsenstore.com/visiophone-2-fils-avec-ecran-7-pouces-ylva-3-avidsen.html">3</a>, <a href="https://www.avidsenstore.com/visiophone-2-fils-avec-ecran-4-et-acces-rfid-ylva-3-compact.html">3+</a>, <a href="https://www.avidsenstore.com/visiophone-2-fils-avec-ecran-4-et-acces-rfid-ylva-3-compact.html">3+ Compact</a><br>
<h3>The worst of all is that they are aware of this issue:</h3>
<p>It seems that Avidsen’s – Thomson Smart Bracket 2 model suggests in the manual the use of silicone as a solution:<br>
From <a href="https://www.avidsenstore.com/cache/documents/product/qs-visiophone-smart-bracket-2-maisonic-1496.pdf">Visiophone Smart Bracket 2 – Thomson manual</a>:<br>
<img src="https://novamostra.com/wp-content/uploads/2020/05/silicone.png" alt="Secure with Silicone"></p>
</li>
</ul>
<p><strong>Even some of their 4 wire Video doorbells have the same vulnerability:</strong></p>
<ul>
<li><a href="https://www.avidsenstore.com/visiophone-compact-horizon-p.html">Horizon</a></li>
<li><a href="https://www.avidsenstore.com/interphone-video-ultra-plat-nordstrom-vision-4-p.html">Nordström Vision 4+</a></li>
</ul>
<p><strong>The same problem seems to exist on their wireless model also:</strong></p>
<ul>
<li><a href="https://www.avidsenstore.com/visiophone-sans-fil-izzy-tomson-p.html">IZZY-768W</a></li>
</ul>
<h2>Be careful… this is not the only company with this vulnerability</h2>
<p>After my findings with the current device, I found out that there are many companies out there using two wire implementations for doorbells leaving entrance control exposed. Pay special attention if you plan to buy or already using a wired doorbell for the way the entrance control works. Most of the times the manuals are online, so you can avoid situations like this one.</p>
	</div><!-- .entry-content -->

	
	<!-- .entry-footer -->

</article></div>]]>
            </description>
            <link>https://novamostra.com/2020/06/23/breaking-into-a-house-using-a-power-bank/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23627143</guid>
            <pubDate>Wed, 24 Jun 2020 12:36:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tuvalu Makes $4M a Year]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 15 (<a href="https://news.ycombinator.com/item?id=23627010">thread link</a>) | @jwdmsd1
<br/>
June 24, 2020 | https://factinator.com/tuvalu-island/ | <a href="https://web.archive.org/web/*/https://factinator.com/tuvalu-island/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
		<div id="content">
	<div id="primary">
		<main id="main">

		
<article id="post-14">
	<!-- .entry-header -->



	<div>
		<p>Tuvalu, a tiny island midway between Hawaii and Australia with a population of just 9,860, receives yearly payment of almost $4 million for literally doing nothing at all. The reason? This is the money that the Tuvalu government receives from royalties from the country’s domain name, <strong>.tv</strong>!</p>
<p><img src="https://factinator.com/wp-content/uploads/2014/01/tv.jpg" alt="tv" width="268" height="175"></p>
<p><span id="more-14"></span>Before you all fire up your calculator, let me burst your bubble that the money comes down to just about $405 per person and also that this money goes to the Tuvalu’s government. Tuvalu commercialized its internet TLD, .tv, in 1988 and started receiving royalties which now account for almost 10% of the government’s total revenue.</p>

<p><img src="https://factinator.com/wp-content/uploads/2014/01/Tuvalu.jpg" alt="Tuvalu" width="600" height="380" srcset="https://factinator.com/wp-content/uploads/2014/01/Tuvalu.jpg 600w, https://factinator.com/wp-content/uploads/2014/01/Tuvalu-300x190.jpg 300w" sizes="(max-width: 600px) 100vw, 600px"></p>
<p>Isn’t it amazing that a country that’s merely a speck in ocean (10 sq miles to be exact) with nothing but hundreds of miles of water around it controls something so crucial to the internet world?! [via: Neeharika Palaka on <a href="mailto:http://www.quora.com/Neeharika-Palaka/answers?share=1">Quora</a> ]</p>


	</div><!-- .entry-content -->

<!--	<footer class="entry-footer">
		<span class="cat-links">Posted in <a href="https://factinator.com/category/read/" rel="category tag">Read Something</a></span><span class="tags-links">Tagged <a href="https://factinator.com/tag/facts/" rel="tag">facts</a>, <a href="https://factinator.com/tag/internet-facts/" rel="tag">internet facts</a>, <a href="https://factinator.com/tag/tuvalu-tv/" rel="tag">Tuvalu tv</a></span>	</footer>--><!-- .entry-footer -->
</article><!-- #post-14 -->

		
			
	
			
		

<ins data-ad-format="autorelaxed" data-ad-client="ca-pub-4948218261801237" data-ad-slot="8302572482"></ins>


			
                            
	
		</main><!-- #main -->
	</div><!-- #primary -->


<!-- #secondary -->
	</div><!-- #content -->
</div></div>]]>
            </description>
            <link>https://factinator.com/tuvalu-island/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23627010</guid>
            <pubDate>Wed, 24 Jun 2020 12:19:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Graphics Study: Red Dead Redemption 2]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23627009">thread link</a>) | @strangecasts
<br/>
June 24, 2020 | https://imgeself.github.io/posts/2020-06-19-graphics-study-rdr2/ | <a href="https://web.archive.org/web/*/https://imgeself.github.io/posts/2020-06-19-graphics-study-rdr2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                

<p>One of my favorite games of all time, <a href="https://en.wikipedia.org/wiki/Red_Dead_Redemption" target="_blank">Red Dead Redemption</a>
returned with a <a href="https://en.wikipedia.org/wiki/Red_Dead_Redemption_2" target="_blank">prequel</a> for consoles in 2018. Then it came for PCs in 2019.
I finally managed to play the game and amazed by its graphics immediately.
But I got upset because I can barely play the game on medium settings at 25 FPS with a 1050Ti laptop GPU.
I know that I don't have a good rig but 25 FPS on medium settings?</p>

<p>Today, we are going to look at some frame captures from the game and try to analyze graphics techniques used in the game.</p>

<h2 id="foreword">Foreword</h2>

<p>This isn't an official breakdown of the game. It just me analyzing <a href="https://renderdoc.org/" target="_blank">RenderDoc</a> frame captures.
If you want to learn from the actual developers,
you can check the slides from a SIGGRAPH talk by <a href="https://twitter.com/globbbe" target="_blank">Fabian Bauer</a>.
<a href="https://advances.realtimerendering.com/s2019/index.htm" target="_blank">Slides</a> (At the bottom of the page), <a href="https://dl.acm.org/doi/10.1145/3305366.3335036" target="_blank">Video</a> (starts at 1:58:00)</p>

<p>You can also read a graphics analysis of GTA5 by Adrian Courrèges <a href="https://www.adriancourreges.com/blog/2015/11/02/gta-v-graphics-study/" target="_blank">here</a>.
Since both RDR2 and GTA5 are from the same company and uses the same engine, some of the techniques from GTA5 present here as well.</p>

<p>Another important thing is that, I am not a senior graphics programmer or anything like that.
I am still a junior in this field.
So, there will be plenty of things that I don't understand. If you find any mistakes or things that can be improved, please reach out to me. Here we go!</p>

<h2 id="dissecting-a-frame">Dissecting a frame</h2>

<p>Here is the main frame for dissecting:</p>

<p><img src="https://imgeself.github.io/img/mainframe.jpg" alt="MainFrame">
<em>Captured on PC, medium settings.</em></p>

<blockquote>
<p>When it comes to a game like RDR2, it's almost impossible to see all the techniques in one frame.
It amortizes its work across multiple frames.
Because of that, I captured more than a single frame but this is the main one we are going to be focusing on.
It contains a lot of properties like; spot and point lights, directional light (it's very subtle but it's there), buildings, NPCs, a horse, trees, vegetation, clouds, etc. It should demonstrate most of the rendering techniques used in the game.</p>
</blockquote>

<p>RDR2 is an open-world game that streams data constantly. Because of that, the frame starts with a bunch of tasks like creating and deleting textures, shader resource views, unordered access views, updating descriptors, buffers, etc.</p>

<h3 id="mud-map">Mud map</h3>

<p>Mud plays a big role in the game. Beside being a game mechanic, it makes envrionments more realistic. The game renders footprint textures of humans and horses into a displacement map along with trail textures of horse wagon wheels. This accumulated texture is used for <a href="https://developer.amd.com/wordpress/media/2012/10/Tatarchuk-POM.pdf" target="_blank">Parallax Occlusion Mapping</a> when rendering terrain.</p>

<p><img src="https://imgeself.github.io/img/mudmap.png" alt="MudMap">
<em>Mud map: 2048x2048 <code>R16_UNORM</code></em></p>

<h3 id="sky-and-clouds">Sky and clouds</h3>

<p>After the mud pass, the game does a lot of work on GPU compute. Most of them related to sky and clouds.
Clouds, fog, and volumetrics are RDR2's prominent effects.
You can find more information about this stage on Fabian's slides. He explains in far more detail than I could ever explain.</p>

<h3 id="environment-map">Environment map</h3>

<p>Environment maps are the main source of reflections in RDR2 as well as GTA5.
<a href="http://www.adriancourreges.com/blog/2015/11/02/gta-v-graphics-study/#environment-cubemap" target="_blank">Like the GTA5</a>, RDR2 generates an environment cubemap from the camera position.
It generates a thin GBuffer for the envrionment map, similar to <a href="https://www.youtube.com/watch?v=rD6KcxcCl_8" target="_blank">Far Cry 4</a>.</p>

<p><img src="https://imgeself.github.io/img/envalbedo.jpg" alt="EnvironmentMapAlbedo">
<em>Environment Cubemap Faces (Albedo): <code>RGBA8_SRGB</code></em></p>

<p><img src="https://imgeself.github.io/img/envnormal.jpg" alt="EnvironmentMapNormal">
<em>Environment Cubemap Faces (Normal): <code>RGBA8_UNORM</code></em></p>

<p><img src="https://imgeself.github.io/img/envdepth.jpg" alt="EnvironmentMapDepth">
<em>Environment Cubemap Faces (Depth): <code>D32S8</code></em></p>

<p>Environment cubemap generation in every frame can be a heavy task. RDR2 does some optimizations to reduce the cost.
For example, the game only draws static and opaque objects, does <a href="https://www.gamedev.net/tutorials/programming/general-and-gameplay-programming/frustum-culling-r4613/" target="_blank">frustum culling</a> before rendering each face, and draws lower LOD versions of models.
Although, I've found that poly count of the terrain is still very high for environment maps.</p>

<p>After the G-Buffer pass, a sky environment cubemap is generated using a sky paraboloid map and cloud-related textures.
The next step is convolution. RDR2 uses <a href="https://blog.selfshadow.com/publications/s2013-shading-course/karis/s2013_pbs_epic_notes_v2.pdf" target="_blank">split sum approximation</a> for Image Based Lighting.
That method uses a pre-filtered environment cubemap along with an environment BRDF LUT.
For filtering, the game convolutes an environment cubemap and stores convoluted versions in the cubemap's mipmap levels.</p>

<p>Before executing a lighting pass for the environment cubemap, RDR2 renders baked large-scale ambient occlusion into another cubemap texture.
The game uses screen space ambient occlusion but SSAO can help you on a small scale.
Baked ambient occlusion helps to darken on a large scale such as darkening in patios and interiors.</p>

<p><img src="https://imgeself.github.io/img/envao.jpg" alt="EnvironmentMapBakedAO">
<em>Environment Cubemap Faces (Baked AO): <code>R8_UNORM</code></em></p>

<p>The game uses <a href="https://www.gdcvault.com/play/1023510/Advanced-Graphics-Techniques-Tutorial-Day" target="_blank">tile-based deferred rendering</a> path for calculating the lighting of environment maps.
The light culling and the lighting are calculated together in one compute pass for each environment map face. (thanks <a href="https://twitter.com/benoitvimont" target="_blank">@benoitvimont</a> for pointing that out)
The game also uses the "top-down world lightmap" technique, <a href="https://www.gdcvault.com/play/1017710/Rendering-Assassin-s-Creed" target="_blank">similar to Assassin's Creed III</a>, for baked lighting.</p>

<p>For each cubemap face, RDR2 renders the final color on top of the sky environment texture.
Then it filters the environment cubemap same as the sky environment cubemap.</p>

<p><img src="https://imgeself.github.io/img/envfinal.jpg" alt="EnvironmentMapFinal">
<em>Environment Cubemap Faces (Final): <code>R11G11B10_FLOAT</code></em></p>

<p>RDR2 also loads envrionment maps that located in building interiors when the player is near a building.
These are also cubemap G-Buffers streamed from the disk.</p>

<p><img src="https://imgeself.github.io/img/bakedenvalbedo.jpg" alt="BakedEnvironmentMapAlbedo">
<em>Baked Environment Cubemap Faces (Albedo): <code>BC3_SRGB</code> (Baked AO stored in alpha channel)</em></p>

<p><img src="https://imgeself.github.io/img/bakedenvnormal.jpg" alt="BakedEnvironmentMapNormal">
<em>Baked Environment Cubemap Faces (Normal): <code>BC3_UNORM</code></em></p>

<p><img src="https://imgeself.github.io/img/bakedenvdepth.jpg" alt="BakedEnvironmentMapDepth">
<em>Baked Environment Cubemap Faces (Depth): <code>R16_UNORM</code></em></p>

<p>The game calculates the lighting of these maps and filters them like the previous ones.
It only calculates one baked environment map at a time and only recalculates them when the time of day changes.
All of the environment maps are stored in a texture cubemap array. There isn't any <a href="http://www.adriancourreges.com/blog/2015/11/02/gta-v-graphics-study/#cubemap-to-dual-paraboloid-map" target="_blank">cubemap to dual-paraboloid map conversion</a>.</p>

<h3 id="g-buffer-pass">G-Buffer Pass</h3>

<p>This stage starts with terrain depth prepass and then the game renders scene into G-Buffers.</p>

<table>
<thead>
<tr>
<th>GBuffer 0 <code>RGB</code></th>
<th>GBuffer 0 <code>A</code></th>
</tr>
</thead>

<tbody>
<tr>
<td><img src="https://imgeself.github.io/img/albedo.jpg" alt="AlbedoTarget"></td>
<td><img src="https://imgeself.github.io/img/albedoa.jpg" alt="AlbedoTargetA"></td>
</tr>
</tbody>
</table>

<ul>
<li><code>RGBA8_SRGB</code> - This buffer contains albedo(base color) in RGB channels. I'm not sure what the alpha channel data is for but it's used on anti-aliasing stage.
</li>
</ul>

<table>
<thead>
<tr>
<th>GBuffer 1 <code>RGB</code></th>
<th>GBuffer 1 <code>A</code></th>
</tr>
</thead>

<tbody>
<tr>
<td><img src="https://imgeself.github.io/img/normal.jpg" alt="NormalTarget"></td>
<td><img src="https://imgeself.github.io/img/normala.jpg" alt="NormalTargetA"></td>
</tr>
</tbody>
</table>

<ul>
<li><code>RGBA8_UNORM</code>: The RGB channels contain normals and the alpha channel contains something related to cloth and hair.
</li>
</ul>

<table>
<thead>
<tr>
<th>GBuffer 2 <code>RGB</code></th>
<th>GBuffer 2 <code>A</code></th>
</tr>
</thead>

<tbody>
<tr>
<td><img src="https://imgeself.github.io/img/material.jpg" alt="MaterialTarget"></td>
<td><img src="https://imgeself.github.io/img/materiala.jpg" alt="MaterialTargetA"></td>
</tr>
</tbody>
</table>

<ul>
<li><code>RGBA8_UNORM</code>: This target is for material properties.

<ul>
<li>R: Reflectance(f0)</li>
<li>G: Smoothness</li>
<li>B: Metallic</li>
<li>A: Contains some shadowing (this channel will be used as a shadow mask at later stages)
</li>
</ul></li>
</ul>

<table>
<thead>
<tr>
<th>GBuffer 3 <code>R</code></th>
<th>GBuffer 3 <code>B</code></th>
</tr>
</thead>

<tbody>
<tr>
<td><img src="https://imgeself.github.io/img/cavity.jpg" alt="Material2TargetR"></td>
<td><img src="https://imgeself.github.io/img/cavityb.jpg" alt="Material2TargetB"></td>
</tr>
</tbody>
</table>

<ul>
<li><code>RGBA8_UNORM</code>: The red channel contains cavity. There is another mystery data in the blue channel. And hair related data in the alpha channel. I can't find anything on the green channel.
</li>
</ul>

<table>
<thead>
<tr>
<th>GBuffer 4 <code>RG</code></th>
</tr>
</thead>

<tbody>
<tr>
<td><img src="https://imgeself.github.io/img/motionblur.jpg" alt="MotionBlurTarget"></td>
</tr>
</tbody>
</table>

<ul>
<li><code>RG16_FLOAT</code>: This buffer contains screen space velocity for motion blur.
</li>
</ul>

<table>
<thead>
<tr>
<th>GBuffer 5 <code>Depth</code></th>
<th>GBuffer 5 <code>Stencil</code></th>
</tr>
</thead>

<tbody>
<tr>
<td><img src="https://imgeself.github.io/img/depth.jpg" alt="DepthTarget"></td>
<td><img src="https://imgeself.github.io/img/stencil.jpg" alt="StencilTarget"></td>
</tr>
</tbody>
</table>

<ul>
<li><code>D32S8</code>: Like the GTA5, RDR2 is also using <a href="https://developer.nvidia.com/content/depth-precision-visualized" target="_blank">reversed-z</a> for depth and using the stencil buffer to assign certain values to certain group of meshes.
</li>
</ul>

<p>There is another target is generated from baked data:</p>

<table>
<thead>
<tr>
<th>GBuffer 6 <code>R</code></th>
<th>GBuffer 6 <code>G</code></th>
</tr>
</thead>

<tbody>
<tr>
<td><img src="https://imgeself.github.io/img/gitarget.jpg" alt="BakedAO"></td>
<td><img src="https://imgeself.github.io/img/gitargetg.jpg" alt="MysteryTarget"></td>
</tr>
</tbody>
</table>

<p>This buffer contains baked ambient occlusion in the red channel, the same as in the environment map stage.
But there are other channels in this texture. The green channel contains some data that looks like the data in GBuffer 3's blue channel.
Again, I don't know what is this data used for. And I can't find any data in blue and alpha channels on my captures. I will investigate this further.</p>

<h3 id="shadow-map-generation">Shadow Map Generation</h3>

<p>After the G-Buffer stage, the game starts to render shadow maps.
It uses 2D texture arrays for point light shadow maps and texture cube arrays for point light shadow maps.</p>

<p>Some games use big shadow atlas texture for shadow maps (<a href="http://advances.realtimerendering.com/s2016/Siggraph2016_idTech6.pdf" target="_blank">e.g DOOM</a>).
One of the advantages of that method is shadow map size can vary based on distance.
When you use texture arrays, you lose that flexibility because all of the textures in texture arrays must be the same size.
RDR2 has 3 different texture arrays for different quality.
For example, spotlights have:</p>

<ul>
<li><strong>512x768 D16</strong> for distant lights</li>
<li><strong>1024x1536 D16</strong> for medium distance(and closer distance on medium setting) lights</li>
<li><strong>2048x3072 D16</strong> for closer lights (on high/ultra settings)</li>
</ul>

<p>Point lights cast shadows in all directions. To deal with that problem, games use a technique called <a href="https://learnopengl.com/Advanced-Lighting/Shadows/Point-Shadows" target="_blank">Omnidirectional Shadow Mapping</a>
where you render the scene into a depth cubemap from the camera position. Campfire shadows and shadows from Arthur's lantern are rendered using this technique.
Point light shadows have 3 different arrays for different quality settings same as spotlights.</p>

<p>Most of the static point lights in the game have baked shadow cubemaps.
So, the game uses baked shadows whenever it can and only generates shadow maps when the player is near a light-volume.
But things get more interesting than that.</p>

<p>Most of the lights on walls are spotlights but the game doesn't generate an omnidirectional shadow map for them.
Instead, it generates a spotlight shadow map and copies that shadow map's memory into pointlight shadow map cube array.</p>

<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>

<tbody>
<tr>
<td><img width="512" height="768" src="https://imgeself.github.io/img/spotshadow.jpg"></td>
<td><img width="128" height="768" src="https://imgeself.github.io/img/pointshadow.jpg"></td>
</tr>
</tbody>
</table>

<p><em>Left image is a 1024x1536 spotlight shadow map, right image is the same image data in 512x512 texture cube format</em></p>

<blockquote>
<p>Note that local light shadow maps stores linear z.</p>
</blockquote>

<p>That explains why they are not using a square sized shadow map for spotlights.
Pixel count for spotlight shadow and point light texture cubemap should be the same.
I am sure you noticed some slice pattern in the right image.
That happens because the width of spot and point light shadow map is different.</p>

<p>Also note that this texture doesn't cover 360 degrees.
But luckily, lights on buildings generally have a wall on their backside and baked shadow maps cover it.</p>

<p>Another interesting thing is that this process is vice-versa.
For example, in Saint Denis -one of the biggest cities in the game- the game generates omnidirectional shadow maps for spotlights
and copies that data into spotlight shadow map array.
I don't know why RDR2 doing shadow mapping like this. I couldn't find any similar technique on the internet.</p>

<p>Directional light shadow mapping in RDR2 is pretty much the <a href="http://www.adriancourreges.com/blog/2015/11/02/gta-v-graphics-study/#shadows" target="_blank">same as in GTA5</a>. <a href="https://docs.microsoft.com/en-us/windows/win32/dxtecharts/cascaded-shadow-maps" target="_blank">Cascaded Shadow Mapping</a> with 4 cascades.
Each 1024x1024 tile of the 1024x4096(medium settings) …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://imgeself.github.io/posts/2020-06-19-graphics-study-rdr2/">https://imgeself.github.io/posts/2020-06-19-graphics-study-rdr2/</a></em></p>]]>
            </description>
            <link>https://imgeself.github.io/posts/2020-06-19-graphics-study-rdr2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23627009</guid>
            <pubDate>Wed, 24 Jun 2020 12:18:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Text-Only Websites]]>
            </title>
            <description>
<![CDATA[
Score 291 | Comments 113 (<a href="https://news.ycombinator.com/item?id=23626929">thread link</a>) | @lcnmrn
<br/>
June 24, 2020 | https://sjmulder.nl/en/textonly.html | <a href="https://web.archive.org/web/*/https://sjmulder.nl/en/textonly.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<p>By <a href="https://sjmulder.nl/en/">Sijmen J. Mulder</a></p>

<p>This is a directory of websites that <strong>primarily stick with
simple, marked up, hyperlinked text</strong>. I appreciate these sites
because they load quickly, scroll smoothly, spare my battery, are more
compact, and lack the usual nonsense that infects many websites.</p>

<p><small><sup>*</sup> not <em>quite</em> text-only, see preceding
parapgraph. See <a href="#notquite">Honorable mentions</a> below
for sites that aren't quite ‘text-only’ but lightweight
and worth visiting nonetheless.</small></p>

<h3>News</h3>

<ul>
  <li><a href="http://thin.npr.org/">NPR</a></li>
  <li><a href="http://lite.cnn.io/en">CNN</a></li>
  <li>
    <a href="https://www.csmonitor.com/layout/set/text/textedition">
      The Christian Science Monitor
    </a>
  </li>
  <li><a href="https://noslite.nl/">NOS</a> (Dutch)</li>
  <li><a href="https://legiblenews.com/">Legible News</a></li>
  <li><a href="https://lite.poandpo.com/">POST Online Media</a></li>
  <li><a href="https://www.ard-text.de/mobil/">ARD Teletext</a></li>
</ul>

<h3>Social</h3>

<ul>
  <li><a href="https://lobste.rs/">Lobsters</a></li>
  <li>
    <a href="https://rawtext.club/">rawtext.club</a>
    – “<em>Resist</em> the dazzling spectacle”
  </li>
</ul>

<h3>Technology</h3>

<ul>
  <li><a href="https://news.ycombinator.com/">Hacker News</a></li>
  <li>
    <a href="https://www.rfc-editor.org/rfc-index-100a.html">
      RFC index
    </a>
  </li>
  <li>
    <a href="https://www.freesoft.org/CIE/Topics/index.htm">Connected</a>,
    an internet encyclopedia.
  </li>
  <li>
    <a href="https://bearblog.dev/">Bear Blog</a>,
    text-first blogging platform
  </li>
  <li>
    <a href="https://mataroa.blog/">Mataroa blog</a>,
    another text-first blogging platform
  </li>
  <li>
    <a href="http://manpages.bsd.lv/index.html">Practical UNIX Manuals</a>,
    on <em>mdoc</em> and history
  </li>
</ul>

<h3>Blogs &amp; Personal</h3>

<ul>
  <li>
    <a href="http://idlewords.com/talks/">Maciej Cegłowski</a>
    (talks on various topics, not quite text only)
  </li>
  <li>
    <a href="http://sommarskog.se/">Erland Sommarskog</a> (mostly SQL)
  </li>
  <li>
    <a href="http://bactra.org/">Cosma's Home Page</a>
  </li>
  <li>
    <a href="http://blog.fefe.de/" hreflang="de">Fefes Blog</a>
    (German)
  </li>
  <li>
    <a href="https://gir.st/">Tobias Girstmair</a>,
    <a href="https://gir.st/blog">blog</a>
    (hardware &amp; software hacker)
  </li>
  <li>
    <a href="http://verisimilitudes.net/">verisimilitudes.net</a>
  </li>
  <li><a href="https://lukesmith.xyz/blogindex">Luke Smith</a></li>
  <li><a href="http://www.tomcooks.com/">Tom Cooks</a></li>
  <li><a href="http://danluu.com/">Dan Luu</a></li>
  <li>
    <a href="https://www.artemix.org/">Artemix</a>
    (back end and UX)
  </li>
  <li>
    <a href="https://idle.nprescott.com/">Nolan Prescott</a>,
    or “Idle Thoughts” (tech &amp; thinking)
  </li>
  <li>
    <a href="https://prog21.dadgum.com/">Programming in the Twenty-First Century</a>
  </li>
  <li>
     <a href="https://nullprogram.com/">null program</a>
     by Chris Wellons
  </li>
  <li>
    <a href="https://greghendershott.com/">Greg Hendershott</a>
    (mostly Racket)
  </li>
  <li><a href="https://terkel.com/">Terkel</a></li>
  <li><a href="https://brokensandals.net/">Jacob Williams</a></li>
  <li>
    <a href="http://www.jaruzel.com/">Jaruzel’s Home</a>
    of Retro and Other Curios
  </li>
  <li><a href="https://allstead.dev/">Willis Allstead</a></li>
  <li><a href="https://www.thomasjost.com/">Thomas Jost</a></li>
  <li><a href="https://wildauer.io/">Manuel Wildauer</a></li>
  <li>
    <a href="https://rgz.ee/">Roman Zolotarev</a>
    (<a href="https://www.openbsd.org/">OpenBSD</a> enthousiast)
  </li>
  <li>
    <a href="https://drewdevault.com/">Drew DeVault</a>,
    creator of <a href="https://sourcehut.org/">SourceHut</a>
  </li>
  <li>
    <a href="http://jrm4.com/">John R. Marks, IV</a>
    (created with <a href="http://zim-wiki.org/">Zim</a>)
  </li>
  <li>
    <a href="https://creativegood.com/">Creative Good</a>
    <span>– Since 1997</span>
  </li>
  <li><a href="https://patrickcollison.com/">Patrick Collison</a></li>
  <li><a href="http://eradman.com/">Eric Radman</a> (BSD &amp; SQL)</li>
</ul>

<h3>Music &amp; Podcasts</h3>

<ul>
  <li>
    <a href="https://vulfpeck.com/">Vulfpeck</a>,
    an American funk band
  </li>
  <li><a href="https://techtonic.fm/">Techtonic</a></li>
  <li><a href="https://19hz.info/">Electronic Music Calendars</a></li>
</ul>

<h3>Misc</h3>

<ul>
  <li>
    <a href="https://gopherpedia.com/">Gopherpedia</a>
    (<a href="https://en.wikipedia.org/wiki/Gopher_(protocol)">Gopher</a> interface to Wikipedia)
  </li>
  <li><a href="http://wttr.in/">wttr</a> (weather)</li>
  <li>
    <a href="http://rate.sx/">rate.sx</a>
    (crypto rates, same author)
  </li>
  <li>
    <a href="https://yarchive.net/">Usenet Archives</a>
    by Norman Yarvin
  </li>
  <li>
    <a href="https://every.sdf.org/">every.sdf.org</a>,
    a collection of plain-text files
  </li>
  <li><a href="https://www.craigslist.org/">Craigslist</a>
</li></ul>

<p>Please send me suggestions on <a href="mailto:ik@sjmulder.nl">ik@sjmulder.nl</a>.</p>

<p><a href="#top">Back to top</a></p>

<hr>

<h2 id="notquite">Honorable mentions</h2>

<p>Note quite as ‘text-only’ but lightweight and worth
visiting nonetheless!</p>

<h3>News</h3>

<ul>
  <li>
    <a href="https://readspike.com/">Readspike</a>
    "Simple news aggregator"
  </li>
  <li><a href="https://spidr.today/">Spidr</a> (aggregator)</li>
  <li>
    <a href="https://www.svt.se/svttext/web/pages/100.html">SVT Text</a>
    (Swedish teletext service)
  </li>
  <li><a href="https://radfi.com/">Radio Fidelity</a> (aggregator)</li>
</ul>

<h3>Social</h3>

<ul>
  <li>
    <a href="https://subreply.com/">Subreply</a>
    (social network)
  </li>
  <li>
    <a href="https://needgap.com/">Needgap</a>
    (“problem validation”)
  </li>
  <li>
    <a href="https://midnight.pub/">midnight</a>
    (“networked writing” platform)
  </li>
</ul>

<h3>Technology</h3>

<ul>
  <li>
    <a href="https://sourcehut.org/">SourceHut</a>
    (git, mailing lists, etc)
  </li>
  <li>
    <a href="https://archive.vn/">archive.today</a>
    (web archiving)
  </li>
</ul>

<h3>Blogs &amp; Personal</h3>

<ul>
  <li>
    <a href="https://engineeringblogs.xyz/">Engineering Blogs</a>,
    a curated collection
  </li>
  <li>
    <a href="http://lucumr.pocoo.org/">Armin Ronacher</a> (mostly Rust)
  </li>
  <li>
    <a href="https://www.gwern.net/">Gwern Branwen</a> (various topics)
  </li>
  <li>
    <a href="https://hugotunius.se/">Hugo Tunius</a> (programming)
  </li>
  <li><a href="https://usmanity.com/">Muhammad Usman</a></li>
  <li>
    <a href="https://sgolem.com/">Stjepan Golemac</a>
    (JS, React, Node, Rust)
  </li>
  <li>
    <a href="http://maddox.xmission.com/">”The Best Page in the Universe”</a>
  </li>
  <li><a href="https://lawzava.com/">Law Zava</a></li>
  <li><a href="https://hitstartup.com/">hitstartup</a></li>
  <li><a href="https://jvns.ca/">Julia Evans</a> (tech)</li>
  <li>
    <a href="https://wingolog.org/">Wingolog</a>
    (mostly functional programming)
  </li>
  <li>
    <a href="http://matt.might.net/">Matt Might</a>
    (medicine and computer science)
  </li>
  <li><a href="https://mnmlist.com/">mnmlist</a></li>
  <li>
    <a href="https://neil.computer/">Neil Panchal</a>
    – “quantum integrated circuits”!
  </li>
  <li>
    <a href="https://www.imperialviolet.org/">ImperialViolet</a>
    by adam Langley (mostly crypto)
  </li>
  <li><a href="https://sirodoht.com/">sirodoht</a></li>
  <li><a href="https://sheep.horse/">Andrew Stephens</a></li>
  <li><a href="https://fnune.com/">Fausto</a></li>
  <li>
    <a href="https://noncombatant.org/">Noncombatant</a>
    (tech, music, more)
  </li>
  <li>
    <a href="https://daringfireball.net/">Daring Fireball</a>
    (predominantly Apple)
  </li>
  <li>
    <a href="https://inessential.com/">Inessential</a>
    by Brent Simmons, author of NetNewsWire
  </li>
</ul>

<h3>Misc</h3>

<ul>
  <li>
    <a href="https://wiby.me/">Wiby</a>,
    a search engine for these kinds of sites
  </li>
  <li><a href="http://www.jimmyr.com/">JimmyR</a> (aggregator)</li>
  <li>
    <a href="http://amasci.com/">Science Hobbyist</a>
    (90s design warning!)
  </li>
  <li>
    <a href="https://tilde.pt/~fimdomeio/index2.html">Web 0.5</a>
    (only for text browsers!)
  </li>
  <li>
    <a href="http://gutenberg.net.au/">Project Gutenberg Australia</a>
  </li>
  <li>
    <a href="http://www.rowlingindex.org/">The J.K. Rowling Index</a>
  </li>
  <li><a href="https://copypastelist.com/">Copy Paste List</a></li>
</ul>

<p><a href="#top">Back to top</a></p>
</div>]]>
            </description>
            <link>https://sjmulder.nl/en/textonly.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23626929</guid>
            <pubDate>Wed, 24 Jun 2020 12:08:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Machine Learning Tools That You Can’t Go Without]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23626841">thread link</a>) | @NaeosPsy
<br/>
June 24, 2020 | https://serokell.io/blog/popular-machine-learning-tools | <a href="https://web.archive.org/web/*/https://serokell.io/blog/popular-machine-learning-tools">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>When you choose a machine learning tool, you choose your future. We all know how quickly everything changes in the world of artificial intelligence, so it is important to keep the balance between “old dog, old tricks” and “just made it yesterday”.</p><p>In this post, we are going to have a look at 18 popular machine learning tools. This review will cover ML platforms, frameworks, and ML libraries.</p><h2 id="top-machine-learning-frameworks%2C-libraries-and-platforms">Top machine learning frameworks, libraries and platforms</h2><p><img src="https://serokell.io/files/do/dogamq3v.1_(24).jpg" alt="top ML tools and platforms"></p><p>First, we are going to talk about platforms. They are built on a single channel architecture and designed in a way that it is convenient to program tasks. They may offer other services like work in the cloud, collaborative working options, or graphic processors for data visualization. They also use popular frameworks by Google, Microsoft, or Amazon.</p><p>Then, we will have a look at the frameworks to use when developing an ML application.</p><h3 id="machine-learning-platforms">Machine learning platforms</h3><p>If you are starting to work with ML, a platform with ready-made datasets and standard model templates will allow you to create your first solutions quicker and with fewer bugs. These platforms install all the necessary tools to let you start working in no time.</p><h4 id="1.-ai-platform-and-datasets-on-google-cloud">1. AI Platform and Datasets on Google Cloud</h4><p>The fundamental problem of any ML model is that you need a correct dataset to train it. They are expensive to make and take lots of time. <a href="https://cloud.google.com/public-datasets">Google Cloud Public Datasets</a> are datasets curated by Google that are regularly updated. The formats are very different: from images to audio, video, and texts. The data is intended for a wide range of researchers with different use cases.</p><p>In addition, Google offers other <a href="https://cloud.google.com/ai-platform">useful services</a> that you could find interesting:</p><ul>
<li>AI platform for training and managing ML models;</li>
<li>Natural language processing services;</li>
<li>Vision AI (models for computer vision);</li>
<li>Speech synthesis software in more than 30 languages etc.</li>
</ul><p>Google is known for their expertise in AI, so you can feel confident about using their solutions for your own projects.</p><h4 id="2.-amazon-web-services">2. Amazon Web Services</h4><p><img src="https://serokell.io/files/o7/o7x09kqd.2_(16).jpg" alt="Amazon Web Services"></p><p><a href="https://aws.amazon.com/machine-learning/">AWS</a> is a platform that provides artificial intelligence and machine learning services to developers. It is possible to choose one of the pre-trained AI services to work with computer vision, language recognition, speech generation, build recommender system and prediction models.</p><p>Using <a href="https://aws.amazon.com/sagemaker/">Amazon SageMaker</a>, you can quickly create, train, and deploy scalable machine learning models, or create custom models that support all the popular open-source ML platforms.</p><p>You can also use Amazon’s services to provide new functionality to existing business solutions. They can be easily integrated with different software, for example, to modernize the contact center and increase customer retention. AWS can help achieve higher customer satisfaction and expand the standard set of business tools.</p><h4 id="3.-microsoft-azure">3. Microsoft Azure</h4><p><a href="https://azure.microsoft.com/">Azure Machine Learning Studio</a> allows developers who don’t have experience in machine learning to use the drag-and-drop functionality. This platform allows you to build solutions directly “on the cloud” and easily create BI applications regardless of the quality of the data.</p><p>Microsoft also offers Cortana Intelligence, a tool that allows you to fully manage big data and analytics and transform data into meaningful information and subsequent actions.</p><p>Overall, Azure can be used by teams and large organizations to work on ML solutions together in the cloud. It has a wide set of tools for different purposes, which makes it so loved by international corporations.</p><h4 id="4.-rapidminer">4. RapidMiner</h4><p><a href="https://rapidminer.com/">RapidMiner</a> is a platform for data science and machine learning. It has a convenient graphical interface and allows to process data from a variety of different formats, including .csv, .txt, .xls, .pdf. Due to this ease of use and respect for privacy, Rapid Miner is used by thousands of enterprises around the world.</p><p>This tool is good when you need to build automated models quickly. It will help you to automatically analyze data and identify common quality problems with correlations, missing values, and stability. However, in order to solve more complex research problems, it is better to use other tools.</p><h4 id="5.-ibm-watson">5. IBM Watson</h4><p><img src="https://serokell.io/files/h0/h0ururfe.3_(13).jpg" alt="IBM Watson"></p><p>If you’re looking for a fully-functional platform with a number of tools for both research teams and enterprises, check out the <a href="https://www.ibm.com/watson">Watson platform by IBM</a>.</p><p>Watson is an open-source API suite. Its users have access to sample codes, a starter toolkit, and can create cognitive search engines and virtual agents. Their tools can be used by any developer to create their own software in the cloud, and the prices are very customer-friendly, which makes it a good solution for small and medium-sized businesses.</p><p>In addition, Watson has a chatbot creation platform that can be used by machine learning beginners for faster bot training.</p><h4 id="6.-anaconda">6. Anaconda</h4><p><a href="https://www.anaconda.com/">Anaconda</a> is an open-source ML platform for data analytics that works with Python and R. It can run on any supported operating systems for other platforms. It allows developers to use more than 1,500 Python and R data science packages, manage libraries and environments (including Dask, NumPy, and pandas).</p><p>Anaconda has great visualization capabilities for reports and modeling. This tool is popular because it brings together many tools with just one install.</p><p>Now, let us have a closer look at frameworks, libraries, and other tools for machine learning that you cannot miss out on.</p><h2 id="popular-languages-for-machine-learning">Popular languages for machine learning</h2><p><img src="https://serokell.io/files/d0/d0pza5ia.4_(8).jpg" alt="what is the best language for artificial intelligence?"></p><p>Python is one of the most popular ML languages. It is flexible and easy to learn. Python is an old language, and it has a rich set of libraries and frameworks that are regularly updated. These resources help to develop machine learning solutions faster thanks to sets of pre-programmed elements.</p><p>Another fairly popular language for machine learning applications is R. This language was created in order to work with statistical analysis. It has powerful visualization capabilities. If you want to work with R, you will need special packages. Ubuntu Pit has collected <a href="https://www.ubuntupit.com/best-r-machine-learning-packages/">20 best R packages</a> for you to use in ML.</p><p>You will find tools for these languages and more (like C++, Julia, Ruby, and Scala) below.</p><h3 id="python-tools">Python tools</h3><p><img src="https://serokell.io/files/9w/9wikp9ie.5_(6).jpg" alt="Machine Learning Tools: Experts' Top Picks 2020"></p><p>Python is the most widely used language in the domain of machine learning. Therefore, many important libraries for machine learning are in Python.</p><h4 id="7.-tensorflow">7. TensorFlow</h4><p><a href="https://www.tensorflow.org/">TensorFlow</a> is a set of open-source deep learning software libraries by Google. Using TensorFlow tools, ML specialists can create highly accurate and feature-rich machine learning models.</p><p>This software simplifies the process of building and deploying complex neural networks. TensorFlow offers APIs for Python and C/C ++ languages ​​that allow exploring its possibilities for research purposes. Moreover, enterprises all around the world get powerful tools for working with their own data and processing it in a cheap cloud environment.</p><p>TensorFlow libraries significantly simplify the integration of self-learning elements for applications designed to solve high complexity problems like speech recognition, computer vision, or natural language processing.</p><h4 id="8.-scikit-learn">8. Scikit-learn</h4><p><a href="https://scikit-learn.org/stable/">Scikit-learn</a> simplifies the process of creating classification, regression, dimensionality reduction algorithms, and helps with predictive data analytics. This library is open-source and can be used for both research and commercial purposes. Sklearn is built on <a href="https://www.youtube.com/watch?v=oYTs9HwFGbY">NumPy, SciPy, pandas, and matplotlib</a>, which are indispensable tools for ML programming in Python.</p><h4 id="9.-jupyter-notebook">9. Jupyter Notebook</h4><p><img src="https://serokell.io/files/e1/e1zq4m9t.6_(2).jpg" alt="Jupyter Notebook"></p><p><a href="https://jupyter.org/">Jupyter Notebook</a> is a command shell for interactive computing. This tool can be used not only with Python, but also with other programming languages: Julia, R, Haskell, and Ruby. It is often used for data analytics, statistical modeling, and machine learning.</p><p>Basically, Jupyter Notebook helps with interactive representations of projects in the field of data science. It allows to create beautiful analytics reports and to store and share code, visualizations, and comments.</p><h4 id="10.-colab">10. Colab</h4><p>Another handy tool you might want to have if you’re working with Python is Colab. Colaboratory, or simply Colab, allows you to write and execute Python in the browser. It requires zero configuration, gives you access to GPU power, and the results are easy to share.</p><h4 id="11.-pytorch">11. PyTorch</h4><p><a href="https://pytorch.org/">PyTorch</a> is a Python-based open-source framework for deep learning based on Torch. It does GPU-accelerated tensor computing like NumPy. On top of this, PyTorch offers a large library of APIs for programming neural network applications.</p><p>PyTorch differs from other machine learning services. Unlike TensorFlow or Caffe2, it doesn’t use static graphs. On the contrary, graphs in PyTorch are <a href="https://datascience.stackexchange.com/questions/45019/static-graphs-v-s-dynamic-graphs">dynamic and calculated on the go</a>. Working with dynamic graphs makes PyTorch easier to work with for some people and allows even beginners to apply deep learning in their projects.</p><h4 id="12.-keras">12. Keras</h4><p><a href="https://keras.io/">Keras</a> is a neural network API that provides a deep learning library for Python. Keras is the most widely-chosen deep learning framework among winning teams on <a href="https://www.kaggle.com/">Kaggle</a>. This is one of the best tools for those who start their career as a machine learning specialist. Compared to other libraries, Keras is much easier to understand. Also, it is more high-level, therefore, it is easier to conceptualize the big picture using Keras. Popular Python frameworks such as TensorFlow, CNTK, or Theano can work with it as well.</p><h3 id="other-frameworks">Other frameworks</h3><p>Machine learning is realized with a great variety of different languages and tools. Here are some frameworks that are not exclusively “for Python”.</p><h4 id="13.-knime">13. Knime</h4><p>You will need <a href="https://www.knime.com/knime-open-source-story">Knime</a> to work with data analytics and form reports. This open-source machine learning tool integrates numerous components for machine learning and data mining through its modular data pipelining concept. This software has regular releases and excellent support.</p><p>One of the big advantages of this tool is that It can integrate the code of various programming languages like C, C++, R, Python, Java, and JavaScript. It can easily be adopted by a team with different programming skills.</p><h4 id="14.-apache-spark-mllib">14. Apache Spark MLlib</h4><p><img src="https://serokell.io/files/j6/j69fht4j.8.jpg" alt="Apache Spark MLlib"></p><p><a href="http://spark.apache.org/mllib/">Apache Spark MLlib</a> is a data processing framework that has an expansive database of …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://serokell.io/blog/popular-machine-learning-tools">https://serokell.io/blog/popular-machine-learning-tools</a></em></p>]]>
            </description>
            <link>https://serokell.io/blog/popular-machine-learning-tools</link>
            <guid isPermaLink="false">hacker-news-small-sites-23626841</guid>
            <pubDate>Wed, 24 Jun 2020 11:56:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Python should not be taught as a foundational language]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 79 (<a href="https://news.ycombinator.com/item?id=23626768">thread link</a>) | @illuminated
<br/>
June 24, 2020 | https://thedropout.dev/why-python-should-not-be-taught-in-colleges/ | <a href="https://web.archive.org/web/*/https://thedropout.dev/why-python-should-not-be-taught-in-colleges/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://thedropout.dev/content/images/size/w300/2019/07/chris-ried-ieic5Tq8YMk-unsplash.jpg 300w,
                            https://thedropout.dev/content/images/size/w600/2019/07/chris-ried-ieic5Tq8YMk-unsplash.jpg 600w,
                            https://thedropout.dev/content/images/size/w1000/2019/07/chris-ried-ieic5Tq8YMk-unsplash.jpg 1000w,
                            https://thedropout.dev/content/images/size/w2000/2019/07/chris-ried-ieic5Tq8YMk-unsplash.jpg 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 700px,
                            1400px" src="https://thedropout.dev/content/images/size/w2000/2019/07/chris-ried-ieic5Tq8YMk-unsplash.jpg" alt="Why Python should not be taught as a foundational language">
            </figure>

            <section>
                <div>
                    <p>Let me preface by adding "to Computer Science/Engineering majors". I think Python is a fine language and that it is very useful in a lot of situations, but I also think using Python as a foundational language is setting students up for a lot of unnecessary headache later on.</p><h3 id="syntax-and-semantics">Syntax and semantics</h3><p>My main gripe with Python is the syntax and semantics. Python looks something like this:</p><!--kg-card-begin: code--><pre><code>def some_func(var_one, var_two):
	for i in range(10):
    	num = i
    	print(i)
    # we can still see num here
    print(num)
    
some_func("thing1", "thing2")</code></pre><!--kg-card-end: code--><p>Right off the bat you should notice a few things, the lack of types, functional scope, and the lack of curly braces. The typing issue I can get over, Python is meant to be dynamically typed, and it is not as weird about it as <a href="https://thedropout.dev/javascript-the-bad-parts/">JavaScript is</a> and it recently added support for defining variable types in function parameters so it's OK in my book. </p><p>However Python does suffer from the same scoping issue as JavaScript, and scoping is done on a functional, rather than block, level. This can be confusing, especially since Python takes the insanity a step further and gets rid of the <code>var</code> ,<code>let</code> ,<code>const</code> keywords entirely, meaning there is not even a concept of a constant variable in Python. </p><p>Lastly, the most obvious difference from most languages you have likely seen is that there are no curly braces. This is because Python decided it would be a fun idea to govern blocks using whitespace, instead of wrapping everything in braces. In theory this might seem OK since you should already be properly indenting blocks of code, however in practice I find that it is much less legible and more kludgy to work with.</p><h3 id="naming-quirks">Naming Quirks</h3><p>Python also decided to go above and beyond and do things differently from most other languages. Part of this is the break from C-Style syntax, and they also name things differently. For instance, what is called an "Array" in pretty much every mainstream language, is instead called a "List" in Python. Key-Value stores that are usually called a "Map" or a "HashMap" are instead referred to as a "Dictionary".</p><h3 id="strings">Strings</h3><p>Then there are Strings, Strings in Python are horribly over-complicated. In most languages you have a <code>char</code> which is a single character, you can have a <code>char[]</code> or just an array of characters, and then a <code>String</code> that is usually some fancy wrapper around a regular <code>char[]</code>. When creating a string in most mainstream languages you can usually just do something along the lines of <code>var s = "string"</code> or for a <code>char</code> you usually use single quotes <code>var c = 'c'</code>. Python decided this was too simple and not specific enough. You can create a string the "normal" way, <code>s = "string"</code> or you can use single quotes <code>s = 'string'</code> or if you want a unicode string you would do <code>uni = u'unicode'</code> or you can craft a binary string <code>bin = b'some binary'</code>. You can also tell it directly what encoding you want to use, <code>utf = "some string".encode("utf-8")</code>. And you can also cast to string using <code>string = str("something")</code> because why not add another way to do things? Now I'm not saying its bad to specify what encoding you're using, but maybe if you could make it a bit more clear or use a syntax that is more common. </p><h3 id="version-split">Version split</h3><p>Another issue with Python is that it is essentially two different languages, there's Python 2.7 and Python 3+. Code written using Python &lt;= 2.7 will <em>sometimes </em>work on Python 3+, and code written using Python 3+ will <em>sometimes</em> work with Python &lt;= 2.7. This is because there were quite a few breaking changes introduced, that make many features that worked in 2.7, no longer work, or work differently in 3+. This as simple as the <code>print</code> function now work differently, for instance:</p><!--kg-card-begin: code--><pre><code>print 'Hello World'</code></pre><!--kg-card-end: code--><p>will work using Python &lt;= 2.7, however with Python 3+ this will raise a SyntaxError as you have to do</p><!--kg-card-begin: code--><pre><code>print('Hello World')</code></pre><!--kg-card-end: code--><p>Another popular feature in Python 2 was <code>xrange</code> which basically created an iterable object that is useful, and a bit quicker than <code>range</code>, in for loops. However, it was simply removed in Python 3. So, if I wanted to write the same code as above to be compatible for python 2.7, I would do something like this:</p><!--kg-card-begin: code--><pre><code>def some_func(var_one, var_two):
	for i in xrange(10):
    	num = i
    	print i
    # we can still see num here
    print num
    
some_func("thing1", "thing2")</code></pre><!--kg-card-end: code--><p>It is very common for languages to introduce new, backwards incompatible features. Especially with major revisions. However it is fairly uncommon to break so many widely used parts of the language that most code written before 3 simply cannot be run on the newer interpreter. The fact is that so much was broken that the community essentially split, and many people are staying on Python 2.7 as their libraries wont work on 3+ or they don't want to maintain 2 version of their codebase for backwards compatibility. This means that even though you are coding in 'Python', depending on which version you pick you are isolating yourself to a subset of the possible libraries or dependencies you can use. </p><p>All of these issues, and more, contribute to some serious headaches for new programmers. If you start by learning Python as a foundational language, when you inevitably switch to another language like C++ or Java, you have to learn an entire new vocabulary and grammar on top of the more difficult concepts as well. And Python's many quirks and irregularities don't make it the simplest language to learn from the get-go either.</p>
                </div>
            </section>

            <section>
                <h3>Subscribe to The Dropout Dev</h3>
                <p>Get the latest posts delivered right to your inbox</p>
                


            </section>

            

<!--            <section class="post-full-comments">-->
<!--                <div id="disqus_thread"></div>-->
<!--                <script>-->

<!--                    /**-->
<!--                     *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.-->
<!--                     *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/-->
<!--                    var disqus_config = function () {-->
<!--                    this.page.url = "https://thedropout.dev/why-python-should-not-be-taught-in-colleges/";  // Replace PAGE_URL with your page's canonical URL variable-->
<!--                    this.page.identifier = "ghost-5d1fc5f9114174269e1bf2b1"; // Replace PAGE_IDENTIFIER with your page's unique identifier variable-->
<!--                    };-->
<!--                    (function() { // DON'T EDIT BELOW THIS LINE-->
<!--                        var d = document, s = d.createElement('script');-->
<!--                        s.src = 'https://the-dropout-dev.disqus.com/embed.js';-->
<!--                        s.setAttribute('data-timestamp', +new Date());-->
<!--                        (d.head || d.body).appendChild(s);-->
<!--                    })();-->
<!--                </script>-->
<!--                <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>-->
<!--            </section>-->

        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://thedropout.dev/why-python-should-not-be-taught-in-colleges/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23626768</guid>
            <pubDate>Wed, 24 Jun 2020 11:46:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tracking eye centers location with Rust and OpenCV]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23626594">thread link</a>) | @todsacerdoti
<br/>
June 24, 2020 | https://www.blog.nodrama.io/rust-opencv-eye-center-localisation/ | <a href="https://web.archive.org/web/*/https://www.blog.nodrama.io/rust-opencv-eye-center-localisation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    

<p>Ever since finding <a href="https://github.com/twistedfall/opencv-rust/">OpenCV Rust bindings</a> I’ve been looking for a good project to try it out.
Than a <a href="https://github.com/jpmonettas/">friend</a> sparked my curiosity when talking about gesture recognition project he was implementing.</p>

<p>This inspired me to create a tool which can read frames from the camera, track eye movements and translate them to mouse cursor movements.
I reckoned Rust is a good fit for writing performant, numerical code.
First step would be to implement an algorithm responsible for tracking the location of eye center in a frame (the pupil), and this blog post is dedicated to describing one possible approach.</p>

<p>I started researching the subject and quickly found that the current state-of-the art is described in <a href="https://www.inb.uni-luebeck.de/fileadmin/files/PUBPDFS/TiBa11b.pdf">Timm and Barth, 2011</a> - I highly recommend reading the paper.
A bit more searching revealed that <a href="https://github.com/trishume/eyeLike">trishume</a> did all the hard work of implementing the algorithm in C++ using OpenCV.
Armed with this reference implementation and the original paper I could easily port it to Rust.</p>



<p>The algorithm described in the paper, which I will colloquially refer to as Timm-Barth, aims at finding a centre of a circular object.
It does so by optimizing (finding a maximum) of an objective function, which is a (weighted) sum of dot products of two vectors:</p>
<ul>
  <li>the normalized gradient vector  at pixel position  such that  and</li>
  <li>the displacement vector 
where  is a possible center.</li>
</ul>

<p>Formally:</p>



<p>The weights  are a way of incorporating prior knowledge: since the pupil is darker than the sclera or facial skin, darker pixels are more likely to be the centers.
If we consider that $I^*$ is the (smoothed and in a greyscale, as per paper’s suggestion) input frame, than at pixel with coordinates  we have that: .</p>



<p>An image gradient is a directional change in the or color intensity of the image.
At each pixel point of the frame, the gradient is a vector that points in the direction of the largest intensity increase, and the length of this vector corresponds to the rate of the change.</p>

<p>More formally the gradient of a two variable function  is defined as a vector of partial derivatives of that function in each direction:</p>

<!-- $$\nabla f = {\begin{bmatrix}g_{x}\\g_{y}\end{bmatrix}}={\begin{bmatrix}{\frac {\partial f}{\partial x}}\\{\frac {\partial f}{\partial y}}\end{bmatrix}$$ -->
<p><img src="https://www.blog.nodrama.io/images/2020-07-01-rust-opencv-eye-center-localisation/CodeCogsEqn.gif" alt="_config.yml"></p>

<p>Since the intensity function of a digital image is known only at discrete points, derivatives of this function cannot be defined, unless we assume some known, differentiable function which has been sampled at these points.</p>

<p>This is why typically the derivative of an image is approximated using <a href="https://en.wikipedia.org/wiki/Finite_difference">finite differences</a>
The <a href="https://github.com/trishume/eyeLike">implementation by trishume</a> implements a procedure where for inner rows of a given frame  which calculates the gradient for inner rows as a central difference.
<!-- For $$\forall (i,j), \: i\neq j$$ the gradient in direction $$x$$ is: --></p>



<p>and in direction :</p>



<p>For the edge rows the gradient value is the difference between the value and the adjacent position.</p>



<p>I decided to deviate a bit from the reference implementation.
Similar to what the paper describes I start by detecting the face region using framework descibed by <a href="https://www.researchgate.net/publication/220660094_Robust_Real-Time_Face_Detection">Viola and Jones, 2004</a>:</p>

<div><div><pre><code><span>let</span> <span>face_detector_name</span> <span>:</span> <span>&amp;</span><span>str</span> <span>=</span> <span>"/opt/opencv/opencv-4.2.0/data/haarcascades/haarcascade_frontalface_alt.xml"</span><span>;</span>
<span>let</span> <span>camera_window_name</span> <span>=</span> <span>"camera"</span><span>;</span>

<span>highgui</span><span>::</span><span>named_window</span><span>(</span><span>camera_window_name</span><span>,</span> <span>highgui</span><span>::</span><span>WINDOW_AUTOSIZE</span><span>)</span><span>?</span><span>;</span>

<span>let</span> <span>face_features</span> <span>=</span> <span>core</span><span>::</span><span>find_file</span><span>(</span><span>face_detector_name</span><span>,</span> <span>true</span><span>,</span> <span>false</span><span>)</span><span>?</span><span>,</span>
<span>let</span> <span>mut</span> <span>face_model</span> <span>:</span> <span>objdetect</span><span>::</span><span>CascadeClassifier</span> <span>=</span> <span>objdetect</span><span>::</span><span>CascadeClassifier</span><span>::</span><span>new</span><span>(</span><span>&amp;</span><span>face_features</span><span>)</span><span>?</span><span>;</span>

<span>let</span> <span>mut</span> <span>frame</span> <span>=</span> <span>Mat</span><span>::</span><span>default</span><span>()</span><span>?</span><span>;</span>
<span>cam</span><span>.read</span><span>(</span><span>&amp;</span><span>mut</span> <span>frame</span><span>)</span><span>?</span><span>;</span>

<span>face_model</span><span>.detect_multi_scale</span><span>(</span>
    <span>&amp;</span><span>frame</span><span>,</span> <span>// input image</span>
    <span>&amp;</span><span>mut</span> <span>faces</span><span>,</span> <span>// output : vector of rects</span>
    <span>1.1</span><span>,</span> <span>// scaleFactor: The classifier will try to upscale and downscale the image by this factor</span>
    <span>2</span><span>,</span> <span>// minNumNeighbors: How many true-positive neighbor rectangles do you want to assure before predicting a region as a face? The higher this face, the lower the chance of detecting a non-face as face, but also lower the chance of detecting a face as face.</span>
    <span>objdetect</span><span>::</span><span>CASCADE_SCALE_IMAGE</span><span>,</span>
    <span>core</span><span>::</span><span>Size</span> <span>{</span>
            <span>width</span><span>:</span> <span>150</span><span>,</span>
            <span>height</span><span>:</span> <span>150</span>
    <span>},</span> <span>// min_size. Objects smaller than that are ignored (poor quality webcam is 640 x 480, so that should do it)</span>
    <span>core</span><span>::</span><span>Size</span> <span>{</span>
            <span>width</span><span>:</span> <span>0</span><span>,</span>
            <span>height</span><span>:</span> <span>0</span>
    <span>}</span> <span>// max_size</span>
  <span>)</span><span>?</span><span>;</span>
</code></pre></div></div>

<p>The article posits selecting the eye regions as fractions of the face region.
I opted for using viola-jones algorithm again, but this time with a model trained to detect eyes in the face region:</p>

<div><div><pre><code><span>if</span> <span>faces</span><span>.len</span> <span>()</span> <span>&gt;</span> <span>0</span> <span>{</span>
  <span>// region of interest (submatrix), first detected face</span>
  <span>let</span> <span>face_region</span> <span>=</span> <span>Mat</span><span>::</span><span>roi</span> <span>(</span><span>&amp;</span><span>enhanced_frame</span><span>,</span> <span>faces</span><span>.get</span> <span>(</span><span>0</span><span>)</span><span>?</span><span>)</span><span>?</span><span>;</span>
  <span>let</span> <span>face</span> <span>=</span> <span>faces</span><span>.get</span> <span>(</span><span>0</span><span>)</span><span>?</span><span>;</span>
  <span>// calls viola-jones eyes classifier</span>
  <span>let</span> <span>eyes</span> <span>=</span> <span>detect_eyes</span> <span>(</span><span>&amp;</span><span>face_region</span><span>,</span>
                          <span>&amp;</span><span>mut</span> <span>eyes_model</span><span>)</span><span>?</span><span>;</span>
 <span>}</span>
</code></pre></div></div>

<p>Finally for each detected eye I apply the implemented Timm-Barth algorithm:</p>

<div><div><pre><code><span>if</span> <span>eyes</span><span>.len</span> <span>()</span> <span>==</span> <span>2</span> <span>{</span>
  <span>let</span> <span>left_eye</span> <span>=</span> <span>eyes</span><span>.get</span> <span>(</span><span>0</span><span>)</span><span>?</span><span>;</span>
  <span>let</span> <span>left_eye_region</span> <span>=</span> <span>Mat</span><span>::</span><span>roi</span> <span>(</span><span>&amp;</span><span>face_region</span><span>,</span> <span>left_eye</span><span>)</span><span>?</span><span>;</span>
  <span>let</span> <span>left_eye_center</span> <span>=</span> <span>timm_barth</span><span>::</span><span>find_eye_center</span> <span>(</span><span>&amp;</span><span>left_eye_region</span><span>,</span> <span>left_eye</span><span>.width</span><span>)</span><span>?</span><span>;</span>

  <span>let</span> <span>right_eye</span> <span>=</span> <span>eyes</span><span>.get</span> <span>(</span><span>1</span><span>)</span><span>?</span><span>;</span>
  <span>let</span> <span>right_eye_region</span> <span>=</span> <span>Mat</span><span>::</span><span>roi</span> <span>(</span><span>&amp;</span><span>face_region</span><span>,</span> <span>right_eye</span><span>)</span><span>?</span><span>;</span>
  <span>let</span> <span>right_eye_center</span> <span>=</span> <span>timm_barth</span><span>::</span><span>find_eye_center</span> <span>(</span><span>&amp;</span><span>right_eye_region</span><span>,</span> <span>right_eye</span><span>.width</span><span>)</span><span>?</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>The implementation itself can be found in a repository <a href="https://github.com/fbielejec/rust-opencv/blob/master/src/timm_barth.rs#L142">here</a>,
and pretty-much follows the reference implementation.
The same repository contains the working code, as well as instructions on installing the OpenCV framework (see <a href="https://github.com/fbielejec/rust-opencv#install-image-and-video-io-libraries">README</a>).</p>

<p>Here is a video of the algorithm in action:</p>

<video width="640" height="480" controls="controls" poster="https://www.blog.nodrama.io/images/2020-07-01-rust-opencv-eye-center-localisation/screenshot.png">
  <source src="https://www.blog.nodrama.io/images/2020-07-01-rust-opencv-eye-center-localisation/screencast_2.mp4" type="video/mp4">
    Your browser does not support the video tag.
</video>

<p>Thanks for reading!</p>

  </div></div>]]>
            </description>
            <link>https://www.blog.nodrama.io/rust-opencv-eye-center-localisation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23626594</guid>
            <pubDate>Wed, 24 Jun 2020 11:18:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[HEY Email is a niche offering masquerading as a category disruptor]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23626542">thread link</a>) | @latc
<br/>
June 24, 2020 | https://4thquadrant.io/exclusive/hey-can-a-ui-ux-makeover-disrupt-the-free-email/ | <a href="https://web.archive.org/web/*/https://4thquadrant.io/exclusive/hey-can-a-ui-ux-makeover-disrupt-the-free-email/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-td-block-uid="tdi_29_ff5">

<div>
<div id="slimcalltoaction"><p>This is box title</p><p>All content, including this exclusive article, is free to access during the launch month of June. View our subscription options <a href="https://4thquadrant.io/subscribe">here.</a></p></div>



<p>HEY is the new email client pledging to make email great again, it’s landing page is an open letter detailing the failed state of current email services, naming Gmail, Yahoo, Outlook and Apple as the service providers that simply “let it happen”. Along with its ‘reinvention’ of email, HEY is also introducing a $99 annual subscription model – with 2 character emails costing up to $999 per user. Its justification for the pricing is that free email charges users in the form of data mining and advertising, acknowledging that while $99 is expensive for certain (developing) markets it is the price tag of a private, ad-free email space.&nbsp;</p>



<p>From the outset it’s obvious that HEY is targeted at a niche user base, the aim here isn’t to be a ‘fresh start’ for the hundreds of millions of people using free email at the moment. In fact moving away from a ubiquitous, free model toward a premium subscription model is akin to the friction of returning to SMS texting rather than Whatsapp or Messenger. HEY’s premium user experience is a product strategy used to target niche high-frequency users. While this limited user base is willing to move away from ingrained digital habits, the true disruption of email would require a widely accessible innovation of its core utility.</p>



<h3>Returning to the ‘wonder’ of emails: necessity or marketing</h3>



<p>UI/UX differentiation is a competitive method used to service saturated markets, it is targeted at carving out segments of the existing market rather than creating new demand. HEY is addressing the ‘experience problem’ of emails, hoping to make it more effective, personable and enjoyable. The idea is that email has devolved into a heap of spam and unwanted contact, becoming a chore to wade through. HEY’s vision statement implies that it wants to get back to the days when email used to be a “wonder”, tapping into the nostalgia of what snail-mail used to represent.&nbsp;</p>



<p>Let’s address this first: is email supposed to be enjoyable? Maybe at the outset it was a replication of snail mail, holiday cards from family or the primary way of keeping in contact with long-distance friends. While these are still things we treasure, social media, instant messaging and niche applications have replaced the need for email to serve this function. Email has very much become a practical function of our lives, aggregating bills and newsletters – that isn’t necessarily a ‘problem’.&nbsp;</p>



<h3>Converting free users into subscription users</h3>



<p>In a saturated market like email services, capturing a niche comes at the cost of servicing the masses. Where HEY cannot preserve its private and ad-free proposition while maintaining a free or even a more affordable subscription model, it opts to provide a premium service. A profit making alternative to the currently free email model is yet to emerge.&nbsp;</p>



<p>The conversion of free users into subscription users hinges on HEY’s ability to convince these users that its features are more value adding than the $99 fee. From the user’s end there is also the need to relearn email habits – even when these are seemingly more efficient habits, this is a big ask in the world of user services. This leaves HEY with access to a smaller set of users who are already looking to renovate their email habits – their marketing strategy needing to play a big role in expanding this user pool.</p>



<p>Hey is basically targeting two focus areas, improved user experience (ad-free, organisational features) and better privacy. These can act as two separate user desires, users may be drawn in on the premise of either or both. The privacy based niche is already being competed for by several contenders. HEY’s premium pricing might prompt users to opt for other privacy focused email services, free or subscription-based, like Protonmail or Fastmail. This makes HEY’s UI/UX offering all the more important, their one point of unique potential to win customer loyalty. Given that UI/UX improvements – no matter how great – are only marginal improvements in the eyes of the user (as opposed to product innovation) this strategy often falls back on aggressive marketing efforts.&nbsp;</p>



<p>In this scenario there are two ways that this business model can extract value:</p>



<ul><li>Subscription model that is more suitable for a niche market&nbsp;</li><li>Free service that banks on similar monetisation avenues available in the existing services&nbsp;</li></ul>



<p>UI/UX solutions for ubiquitous and free services tend to opt for a subscription-based offering as a form of capturing value, reaping the rewards of a more condensed user base and opting out of the tradeoffs necessary for disrupting the ubiquitous forms of use. However, a subscription model, as we discussed earlier, creates a ceiling on adoption – relegating it in the near term to a novel solution.</p>



<p>Regardless of speculation on the true motive behind it, HEY’s recent and very public dispute with Apple over its IOS App store listing was a boon for the product’s virality. HEY’s strategy initially started with an invite-only exclusive approach, but the apparent struggle with Apple has had much further reaching impact on product awareness. As HEY leans into the anti-big-tech narrative to leverage its marketing potential, it needs to tread carefully such that it doesn’t risk seeming intellectually dishonest – especially given that it is not providing a truly accessible alternative to the large email service providers it claims to be competing with.&nbsp;</p>



<p>HEY’s ability to retain users on the platform will become dependent on their ability to continue convincing users that there is value in the experience of an email – especially where functionality remains abundant on much larger competing platforms. HEY’s annual subscription is an intentional habit building funnel, user’s who subscribe will have a year to become familiar with – and hopefully attached to – the service’s features. Given that there is always the potential for habits to be transferred across platforms though, it will be imperative that HEY continues innovating its unique proposition.</p>



<p><span>Down the Rabbit Hole</span>
</p>



<h3>1. Red ocean traps demonstrate the pitfalls faced by founders attempting to find or create fertile grounds for products and services</h3>



<p>As market power increasingly moves from companies to consumers, competition intensifies. Long-term success will increasingly “depend on the ability to generate new demand and create and capture new markets.” “Red ocean traps” are pitfalls that hinder the creation or identification of new markets.</p>



<p>“We have come to think of them as red ocean traps, because they effectively anchor managers in red oceans—crowded market spaces where companies engage in bloody competition for market share—and prevent them from entering blue oceans, previously unknown and uncontested market spaces with ample potential.”</p>



<p>Red ocean traps confuse strategies for competitive advantages with creating new markets.</p>



<p><strong>Trap one: seeing market-creating strategies as customer-oriented approaches</strong></p>



<p>Focusing on existing customers keeps companies mired in red oceans.&nbsp;</p>



<p><strong>“</strong>an organization needs to turn its focus to noncustomers and why they refuse to patronize an industry’s offering. Noncustomers, not customers, hold the greatest insight into the points of pain and intimidation that limit the boundary of an industry.”</p>



<p><strong>Trap two: treating market-creating strategies as niche strategies</strong></p>



<p>Segmenting existing markets into finer segments to identify niches is not the same as creating new markets.</p>



<p>“Successful market-creating strategies don’t focus on finer segmentation. More often, they “desegment” markets by identifying key commonalities across buyer groups that could help generate broader demand.”</p>



<p><strong>Trap three: confusing technology innovation with market-creating strategies</strong></p>



<p>“Value innovation, not technology innovation, is what launches commercially compelling new markets. Successful new products or services open market spaces by offering a leap in productivity, simplicity, ease of use, convenience, fun, or environmental friendliness. But when companies mistakenly assume that market creation hinges on breakthrough technologies, their organizations tend to push for products or services that are too “out there,” too complicated, or, like the Segway, lacking a necessary ecosystem.“</p>



<p><strong>Trap four: equating creative destruction with market creation</strong></p>



<p>Creative destruction refers to a new invention replacing an existing product or technology. But creating new markets does not always require creative destruction.&nbsp;</p>



<p>“Many market-creating moves are nondestructive, because they offer solutions where none previously existed. We’ve also seen this happen with the social networking and crowdfunding industries. And even when a certain amount of destruction is involved in market creation, nondestructive creation is often a larger element than you might think. Nintendo’s Wii game player, for example, complemented more than replaced existing game systems, because it attracted younger children and older adults who hadn’t previously played video games.”</p>



<p><strong>Trap five: equating market-creating strategies with differentiation</strong></p>



<p>Differentiation is when a competitor stands out from the competition by providing premium value and the trade-off is higher costs for both the consumer and the competitor.</p>



<p>“In reality, a market-creating move breaks the value-cost trade-off. It is about pursuing differentiation and low cost simultaneously… A market-creating move is a “both-and,” not an “either-or,” strategy. …when companies mistakenly assume that market creation is synonymous with differentiation, they often focus on what to improve or create to stand apart and pay scant heed to what they can eliminate or reduce to simultaneously achieve low cost.”</p>



<p><strong>Trap six: equating market-creating strategies with low-cost strategies</strong></p>



<p>“This …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://4thquadrant.io/exclusive/hey-can-a-ui-ux-makeover-disrupt-the-free-email/">https://4thquadrant.io/exclusive/hey-can-a-ui-ux-makeover-disrupt-the-free-email/</a></em></p>]]>
            </description>
            <link>https://4thquadrant.io/exclusive/hey-can-a-ui-ux-makeover-disrupt-the-free-email/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23626542</guid>
            <pubDate>Wed, 24 Jun 2020 11:08:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Software Entropy]]>
            </title>
            <description>
<![CDATA[
Score 50 | Comments 17 (<a href="https://news.ycombinator.com/item?id=23626253">thread link</a>) | @1penny42cents
<br/>
June 24, 2020 | https://camhashemi.com/2020/06/23/software-entropy/ | <a href="https://web.archive.org/web/*/https://camhashemi.com/2020/06/23/software-entropy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-195">
			<!-- .entry-header -->
		<div>
		
<h2>Defining Entropy</h2>



<p>Entropy is a measure of chaos, or disorder, in a system.</p>



<p>My college physics professor described entropy using two shoe closets.</p>



<p>Imagine a clean shoe closet, where all shoes are paired and sorted by color. The closet’s entropy is the total number of arrangements its shoes can have. A clean closet’s entropy is relatively small. There may be a few pairs of grey or blue shoes that can be switched around – but this doesn’t add much complexity. In a closet with low entropy, it’s easy to add or remove shoes from that closet as needed.</p>



<p>Now imagine a messy shoe closet. None of the shoes are paired, and they’re all tangled in a big pile. How many possible combinations can these shoes be in? You can quickly find out by trying to pull out the pair you want. The messy shoe closet has a much greater entropy than the clean one.</p>



<p>In short, we measure entropy by counting the number of possible states a system can be in. More states mean more entropy.</p>



<h2>Entropy in Software</h2>



<p>In software, our building blocks are simple enough for us to measure entropy in a crude way. Take this model for example:</p>


<pre title="">Transaction(
  createdAt: String
  buyerId: String,
  sellerId: String
  amount: Int
)
</pre>


<p>As simple as it seems, this model is like our messy shoe closet. There are many more ways for this model to be wrong than there are for it to be right. We can see that by comparing it to an organized shoe closet:</p>


<pre title="">Transaction(
  createdAt: DateTime,
  buyerId: UserId,
  sellerId: UserId,
  amount: Price
)
</pre>


<p>When `createdAt` was an arbitrary string, it could take on invalid values “foo” and “bar” just as easily as a valid value “06-23-2020”. There are many more possible states that the field can be in, and most of them are invalid. This choice of a broad data type allows chaos into our model. This unwanted chaos leads to misunderstandings, bugs, and wasted energy.</p>



<p>When each model is strongly typed to a strict set of values, this chaos is minimized. DateTime, UserId, and Price are typed such that all possible values are valid. Accordingly, these types are more predictable, easier to manipulate, and lead to less surprises in practice.</p>



<p>As in life, entropy is not all bad – some of it is desirable and some of it is not. In software, we need entropy to a certain extent: our code is valuable <em>because </em>it supports a variety of possible dates, users, and prices. But when this chaos grows beyond the value it adds, our software becomes painful to use and painful to maintain.</p>



<h2>Modeling Software Entropy</h2>



<p>Given our observations, we can describe a simple rule:</p>



<p><code>complexity = number of total possible states</code></p>



<p>A construct with only a few possible states is simple. Booleans and enums are much simpler than strings. A system with one moving piece is much simpler than a system with many moving pieces.</p>



<p>Sometimes, our problems are essentially complex. In these cases, our solutions need some essential complexity to match. But when does essential complexity become unnecessary? In these cases, we can use another rule:</p>



<p><code>cleanliness = number of <strong>valid</strong> possible states / number of <strong>total</strong> possible states</code></p>



<p>If there are thousands of total possible states, but only two of them are valid: it’s a messy solution. A simple example of this is representing a boolean value as a string.</p>


<pre title="">if value == "true": do this
else if value == "false": do that
else: throw error
</pre>


<p>There are many ways for this code to go wrong; not just in execution but also in interpretation. Keeping our solutions clean improves correctness, readability, and maintainability. It’s one of the primary measures of “quality” in my view.</p>



<h2>Minimizing Software Entropy</h2>



<p>Given these definitions, we can ask ourselves some questions to guide our software decisions:</p>



<ol><li>How many possible states does this solution have?</li><li>How many of those states are invalid?</li><li>Is there any way to make the solution simpler, by trimming the number of <em>total</em> possible states?</li><li>Is there any way to make the solution cleaner, by trimming the number of <em>invalid</em> possible states?</li></ol>



<p>The power of this concept is that it smoothly scales up and down the ladder of abstraction. It applies to basic data types just as well as it does to solution architecture and product development.</p>



<p>How many moving pieces does our solution need? When an unimaginable requirement flies in and tries to blow our solution to the ground, how many pieces can be left standing? When an unexpected input arrives, do invalid states propagate across the system, or are they contained and eliminated on sight? In short, how clean is our solution?</p>



<p>To make life possible, we utilize chaos by creating complex systems that support a diversity of people and their use cases. To make life predictable, we combat undesirable chaos by keeping those systems as clean and orderly as possible.</p>



<p>In software, we work in a world where chaos is measurable and cleanliness is achievable. We just need the right set of signals and responses to make it happen.</p>
			</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://camhashemi.com/2020/06/23/software-entropy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23626253</guid>
            <pubDate>Wed, 24 Jun 2020 10:20:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Making $32k/month building websites for churches]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23626159">thread link</a>) | @vinrob92
<br/>
June 24, 2020 | https://productizedstartups.com/making-32k-month-building-websites-for-churches/ | <a href="https://web.archive.org/web/*/https://productizedstartups.com/making-32k-month-building-websites-for-churches/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-1490">

	
<!-- .entry-header -->

	<div>

		<div>

			
<figure><img src="https://productizedstartups.com/wp-content/uploads/2020/06/Building-Websites-for-Churches-02-1.jpg" alt="" srcset="https://productizedstartups.com/wp-content/uploads/2020/06/Building-Websites-for-Churches-02-1.jpg 1024w, https://productizedstartups.com/wp-content/uploads/2020/06/Building-Websites-for-Churches-02-1-300x150.jpg 300w, https://productizedstartups.com/wp-content/uploads/2020/06/Building-Websites-for-Churches-02-1-768x384.jpg 768w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<h3><strong>1. Hello! Who are you and what is your business?</strong></h3>



<p>I’m Paul, I run a company called <a href="https://thechurchco.com/">The Church Co</a>. It’s a website builder for churches. The key difference being that, compared to other website builders out there (building your own), we build the websites for the church in 7 days and then hand it over for them to maintain. We think that maintaining a website and building a website are two different skill sets.&nbsp;</p>



<p>I got my degree in digital media in The Internet and Interactive Design back in 2007. Then I decided to go to Bible school. I moved to Sydney, Australia (where I went to Bible school) and ended up getting hired at a church there, going back and doing web design. During that process, I started learning about using my skills together and combining two of the passions that I had. I started The Church Co years later, which is ultimately the combination of both of those things.</p>



<p>I had some friends that worked at different churches and was able to reach out to them to trial it. We ran it for free for a year and a half before ever taking payments. We lost half of our customers the day we turned the payments on, and then just started building them back. It all grew word of mouth via happy customers and Facebook groups.</p>



<p>The Church Co makes <strong>$30k-32k a month</strong> in subscriptions. We have optional add-ons like custom themes, sermon and blog imports. If you need more than the 15 pages that will do for free in the build. There are one-time fees which accounts for around $3,000 a month in addition to the subscriptions.</p>



<p>Our pricing plans start at $20 for basic, $50 at premium, and ultimate for $199. The basic plan is simply everything you need for a standard website: web pages, blogs, sermons (which are podcast events systems). The premium plan has nice church features that we’ve added that are geared towards interaction with members that come to your church. One example is a sermon note-taker where the pastor can outline their sermon notes and you can follow along via your phone, add your own notes, and then compile and send them to yourself. We also have a small group locator, which shows small groups that meet in the community that are all part of your church. We’ve got options for live streams, chats, and online giving/donations through stripe.</p>



<p>These features are all niche-targeted features that make it easier to manage and get more interactions. From here, we incentivize people to upgrade as well. The ultimate plan has all the same features as premium, but we manage your content for you. You’ll basically never have to log into your website — just email us and tell us to do something for Christmas and we’ll spin up a page for you.</p>



<p>For expenses, we vary between like $9k-11k each month. This includes salaries, servers, intercom, etc. We pay contractors in addition to our full-time people (myself and one other individual) that we have to build other websites for the churches. This varies with how many people sign up and how many hours it takes them to build the sites.&nbsp;</p>



<p>Before COVID I would’ve considered a customer a day (totaling about 30 for the month) to be a great month. Then we started doing the same amount in a week when stay-at-home orders came to the point of gaining 100 new customers in a month — which was wild! We spend a lot of time on customer support and brought on a lot of contractors to kind of help get that done.&nbsp;</p>



<p>It was mind-blowing that there were so many fully functioning organizations that had never had websites. It was an unfortunate event that was bad for a lot of people, but it really pushed many into a digital space, which we were prepared for. In the last three months, we did the equivalent of how many sites we did all of last year, so it scaled quickly. And luckily the processes were all in place to make that happen.</p>



<h3><strong>2. How do you attract and retain your customers?</strong></h3>



<p>The main way we’ve grown is word of mouth, especially through really niche Facebook groups. My background from working in the communications role at a church helped me get involved in those groups, just to be a help to other people. I never spammed my product (nor did I ever have to). We haven’t invested money into any ads except maybe a few dollars for some Google ads and a few dollars for some retargeting Facebook ads.&nbsp;</p>



<p>As far as retaining customers, one of the beauties of websites is, you don’t change them that often. We work really hard to get you on your domain name, and once you’re on that, then you’re typically going to stay for 3+ years. We do a lot of work in the beginning stages to onboard people, build their site, and get them up through launching. What makes it different to most SaaS products is that you can see if someone stops logging in — that’s when they churn. But for us, that’s when they’re happy, and good to go. Really happy customers could log in once a week just to add a new event or upload a podcast from the weekend.&nbsp;</p>



<p>One of the reasons that we found why organizations churn is when they get a new volunteer that is familiar with another website builder. We ensure they stick around by separating the data from the design, which means you can change your theme at any time and it auto adjusts the layout.&nbsp;</p>



<p>We release new themes every year. The goal is that if you’ve been on the platform for 5 or so years, and want a new look, you can just browse our theme library, preview and activate without needing additional work.&nbsp;</p>



<p>This is the big focus: getting people onto the domain and then making sure we’re releasing new features. It’s helped with keeping customers.&nbsp;</p>



<h3><strong>3. What were your challenges and obstacles of growing your business?</strong></h3>



<p>When I started this company, I thought people would see the website and think that it’s much better than what they could build themselves. I realized that <strong>you’re not actually selling the final product — it’s the experience of making the product.</strong>&nbsp;</p>



<p>It was within the first 6 weeks with our first trial customer that I realized people were not going to build their own websites (or they’d take 6 months to do it, which was way too long of a sales cycle). I thought, <em>well, I built the system, I can do it pretty quick.</em> So we started offering our done-for-you website building, which was a game changer. It ran great for a while when we did it all for free (but requested payment for site launch).&nbsp;</p>



<p>Then we burned out a few times. So we started asking for credit card information first, as a commitment to do this, and we would build a website — which worked great until we got websites that requested 500 pages. That would take us a month to build, and there’s no way it was sustainable.&nbsp;</p>



<p>This was iterated down to the point we are today: we start building the website which is a free 15 pages, (about the average size of a church website). Making money was never the goal.&nbsp;</p>



<p>Before I had contractors I used to get up at 5am and go to a coffee shop, build three websites and go to my day job for 8 hours. Then I’d come home, have some family time and then, after everyone’s asleep, jump back on and build more websites. It wasn’t the most fun in that stage, and it continued that way until it scaled enough with revenue to hire people to do that for me. I think a lot of people quit when they hit that first wall, instead of thinking: <em>what’s the wildest solution to this (even if it’s not like a fun one)?</em>&nbsp;</p>



<p>We pivoted from my original idea, in that I thought people would build their own websites (which was not the case). Currently, I’m in the middle of a bit of a pivot as well, adding design to our service.</p>



<p>We’ve never been a design tool. We’re no code and we’re no design. Our ideal customer is a church that doesn’t have a creative staff member. and the value is on the content. We convert about 25% of trials into customers, which is pretty high; but the feedback we get from the other 75% are usually about design related things (i.e. they have a design in mind they wanted to implement). Part of the big push on version 2 is adding more design capabilities and flexibility for the people that want it.&nbsp;</p>



<p>There were a lot of assumptions I made around design in the initial version that looking back, I would have done a little bit more research: i.e. surveying a few people working in churches that weren’t my friends to see what they were struggling with and what they needed.&nbsp;</p>



<p>I would have also made strategic partnerships earlier (I was very anti-affiliates for a long time). I would see 10 people spamming affiliate links in the Facebook groups and would immediately be biased against the products because it needs affiliates to sell. While I don’t think we suffered from refusing to do affiliates, a lot of competitors did which kept paired them up with influencers in the space. We ended up caving and now have an affiliate plan.&nbsp;</p>



<p>Another challenge was letting go of control on intercom, but it needed to happen. It’s the only communication we have; there’s no phone line. Anyone who gets the role needs to be well vetted in communication skills and sales, the ability to convert someone that’s just browsing into a paying customer.&nbsp;</p>



<p>I was a bit too close to the product. I’m more prone to talk about specific technical things that customers would simply not understand. Handing the role off to someone else has made more sales and has overall been one of the best moves I’ve made.</p>



<h3><strong>4. What has been helpful to help you to grow your business?</strong></h3>



<p>The Indie Hackers community. I think having really ‘<em>switched-on’</em> people that are willing to give you constructive and honest feedback is really valuable. I suppose it’s a bit like having a life coach. It’s gotten us to where we are today.&nbsp;</p>



<p>When we added a chat to the dashboard, it helped drive sales (despite chat being the bane of my existence). You can’t log into any of the major competitors’ sites (that I know of), and live chat with a web developer to ask them questions. We do, and it was a tool that really …</p></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://productizedstartups.com/making-32k-month-building-websites-for-churches/">https://productizedstartups.com/making-32k-month-building-websites-for-churches/</a></em></p>]]>
            </description>
            <link>https://productizedstartups.com/making-32k-month-building-websites-for-churches/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23626159</guid>
            <pubDate>Wed, 24 Jun 2020 10:06:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Empty Ubuntu to Live Reload: Haskell IHP Web Framework and Nix]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23625978">thread link</a>) | @_query
<br/>
June 24, 2020 | https://codygman.dev/posts/2020-06-24-Haskell-IHP-Web-Framework-and-Nix.html | <a href="https://web.archive.org/web/*/https://codygman.dev/posts/2020-06-24-Haskell-IHP-Web-Framework-and-Nix.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    
    <section>
        <p>I came across <a href="https://www.reddit.com/r/haskell/comments/hee4r4/ihp_is_a_modern_batteriesincluded_web_framework/">IHP is a modern batteries-included Web Framework, built on top of Haskell and Nix</a> today and being about web frameworks <em>and</em> nix it immediately caught my eye. I read the comments first, got mildly annoyed at the first comment being about “it’s nix only”, and kept scrolling until I saw a comment (you’ll see in the stream) that properly motivated me to actually read the link attached :D</p>
<p>I then resolved to stream playing around with this cool framework and also to do it from an ubuntu vm in virtualbox to show how seamless nix can make the setup (or can it?!?). Here’s a video of the stream in case you missed it:</p>
<center><iframe src="https://player.twitch.tv/?video=659859279&amp;parent=codygman.dev" frameborder="0" allowfullscreen="true" scrolling="no" height="378" width="620"></iframe></center>
<p>If this generates much interest, I’ll try doing a follow up soon where we get to the more complex pieces like adding custom Haskell packages (or even in Hackage or nixpkgs).</p>
    </section>
</article></div>]]>
            </description>
            <link>https://codygman.dev/posts/2020-06-24-Haskell-IHP-Web-Framework-and-Nix.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23625978</guid>
            <pubDate>Wed, 24 Jun 2020 09:40:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Indexing Jsonb Columns in PostgreSQL]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23625883">thread link</a>) | @dijit
<br/>
June 24, 2020 | https://vsevolod.net/postgresql-jsonb-index/ | <a href="https://web.archive.org/web/*/https://vsevolod.net/postgresql-jsonb-index/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
        <p>Since time immemorial PostgreSQL supports JSON fields and can even index
them. By immemorial I mean this functionality was added in versions 9.2 and 9.4
that are unsupported now. </p>
<p>I perfectly remember the world where PostgreSQL had no JSON support because 9.2
<a href="https://www.postgresql.org/docs/9.2/release-9-2.html">was released</a> in 2012,
and before that, I worked in a company that used MongoDB (we suffered
greatly<a href="https://vsevolod.net/postgresql-jsonb-index/#note1"><sup id="back1">[1]</sup></a>). It was an ample bit of marketing
for Mongo back then: "you can store any document without tediously defining an
ungodly schema! You gain so much flexibility!"</p>
<p>Little did we know back then that the world does not work that way, and
relational SQL databases are actually way more flexible than document-oriented
DBs, columnar DBs, or whatever.<a href="https://vsevolod.net/postgresql-jsonb-index/#note2"><sup id="back2">[2]</sup></a> Because
often we don't know what exactly are we going to do with the data, and with
relational DBs we can lay out the data however seems reasonable, and then add
indexes to support our use cases. </p>
<p>In document-oriented DBs you need to lay out your data exactly the way you're
going to query it later. Or else you'll need to migrate data inside your
schema-less database to another layout, which is way more cumbersome and
error-prone than adding some indexes and JOINs. </p>
<p>Don't trust me - there is an exceptional talk on <a href="https://www.youtube.com/watch?v=HaEPXoXVf2k">Advanced Design Patterns for
DynamoDB</a> by Rick Houlihan, a
Principal Technologist at AWS. He explains that and so much more - it's a very
information-dense presentation with interesting ideas. I found it useful even
though I don't plan to use DynamoDB nor MongoDB in the near future.</p>
<p>Anyway, JSON support was added into PostgreSQL a long time ago, because
sometimes it is useful to store some documents in the database. And it can be
indexed in <a href="https://www.postgresql.org/docs/current/datatype-json.html#JSON-INDEXING">two different
ways</a> -
full <abbr title="Generalized Inverted Index">GIN</abbr> and a special
<code>jsonb_path_ops</code> that supports indexing the <code>@&gt;</code> operator only. It means
"contains" and can be used like this:</p>
<pre><span>SELECT * FROM table WHERE jsonb_field @&gt; '{"employer": {"country": "ZA"}}';
</span></pre>
<p>Let me tell you a story about how I cleverly used this feature and it bit me in
the ass.</p>
<h2 id="story-time">Story time<a href="#story-time" aria-label="Anchor link for: story-time">🔗</a></h2>
<p>I am a co-founder at <a href="https://www.prophy.science/">www.prophy.science</a> which is
a product that can understand, search and recommend scientific papers and
experts. To do that well, we need a collection of all scientific papers, and
papers are often provided by many different providers with different ids. There
are <a href="https://www.ncbi.nlm.nih.gov/pubmed/">PubMed</a> (30M+ articles), <a href="https://www.ncbi.nlm.nih.gov/pmc/">PubMed
Central</a> (6M+ articles),
<a href="https://www.crossref.org/">Crossref</a> (80-100M+),
<a href="https://inspirehep.net/">INSPIRE</a>, there are preprint servers like
<a href="https://arxiv.org/">arXiv</a>, <a href="https://www.biorxiv.org/">biorXiv</a>,
<a href="https://www.medrxiv.org/">medRxiv</a> and many others.</p>
<p>There is a widespread system of <abbr title="Digital object
identifier">DOIs</abbr> that are used to persistently identify journal articles,
research reports and data sets. It was introduced in the year 2000, and, as many
of these bibliographic databases predate DOI standard, they have their own
identifiers. Sometimes they even cross-link their IDs between different
services, and sometimes they cross-link wrong articles.</p>
<p>Some monitoring services download data from Crossref, Pubmed, PMC and some other
sources, add them and report that they have 180 million articles, 220 million,
or some other bullshit. We strive to merge the same article from different
sources into one entity with many external identifiers. We called these
identifiers "origin ids" and stored them in a special <code>jsonb</code> column, so one row
could have a record like this:</p>
<pre><span>{"pubmed": "3782696", "pmc": "24093010", "doi": "10.3389/fnhum.2013.00489"}
</span></pre>
<p>It was a simple key-value document with a <code>jsonb_path_ops</code> index on it. And
whenever we needed to fetch an article by an origin id, we queried it using a
<code>@&gt;</code> operator like that:</p>
<pre><span>SELECT id FROM articles WHERE origin_ids @&gt; '{"pubmed": "123456"}';
</span></pre>
<p>It is a bit easier to store ids this way, no need to maintain a separate table
with hundreds of millions of rows.</p>
<p>One problem arose when we tried to query the index with many different origin
ids. There is no <code>IN</code> nor <code>ANY()</code>, so we stitched lots of <code>OR</code>s together:</p>
<pre><span>SELECT id FROM articles WHERE 
    origin_ids @&gt; '{"pubmed": "123456"}' OR 
    origin_ids @&gt; '{"pubmed": "654321"}' OR 
    origin_ids @&gt; '{"pubmed": "123321"}' OR 
    origin_ids @&gt; '{"pubmed": "456654"}';
</span></pre><h2 id="explain-everything">Explain everything<a href="#explain-everything" aria-label="Anchor link for: explain-everything">🔗</a></h2>
<p>And with enough <code>OR</code>s the query gets really slow. Why? <code>EXPLAIN</code> helpfully says
that it becomes a sequential scan (I shortened output for clarity):</p>
<pre><span>EXPLAIN
 SELECT id, origin_ids
   FROM articles
  WHERE origin_ids @&gt; '{"pubmed": "123456"}' OR
        origin_ids @&gt; '{"pubmed": "654321"}' OR
        ....;   - x200
                        QUERY PLAN
------------------------------------------------------------
 Seq Scan on articles  (rows=7805036)
   Filter: ((origin_ids @&gt; '{"pubmed": "123456"}') OR
            (origin_ids @&gt; '{"pubmed": "654321"}') OR   ...x200)
</span></pre>
<p>Why? For some reason it thinks that this query will return millions of rows. But
one origin id can match at most one article if my data is correct, so 200
filters should only match 0..200 rows. Let's look at <code>EXPLAIN ANALYZE</code> to check:</p>
<pre><span>EXPLAIN ANALYZE
 SELECT id, origin_ids
   FROM articles
  WHERE origin_ids @&gt; '{"pubmed": "123456"}' OR
        origin_ids @&gt; '{"pubmed": "654321"}' OR
        ....;   - x200
                        QUERY PLAN
------------------------------------------------------------
 Seq Scan on articles  (rows=7805036) (actual rows=200)
   Filter: ((origin_ids @&gt; '{"pubmed": "123456"}') OR
            (origin_ids @&gt; '{"pubmed": "654321"}') OR   ...x200)
</span></pre>
<p>It does indeed return only 200 rows. Hmmm... Let's check one row:</p>
<pre><span>EXPLAIN ANALYZE
 SELECT id, origin_ids
   FROM articles
  WHERE origin_ids @&gt; '{"pubmed": "123456"}';
                        QUERY PLAN
------------------------------------------------------------
 Bitmap Heap Scan on articles  (rows=43038) (actual rows=1)
   Recheck Cond: (origin_ids @&gt; '{"pubmed": "123456"}')
    -&gt;  Bitmap Index Scan on  ... (rows=43038) (actual rows=1)
         Index Cond: (origin_ids @&gt; '{"pubmed": "123456"}')
</span></pre>
<p>Supposedly 43 thousand rows for only one filter! And 7.8 million rows are 39
thousand times more than 200, which is pretty close. At the time I fired these
queries we had only 43 million of articles. PostgreSQL <a href="https://www.postgresql.org/docs/current/planner-stats.html">gathers some
statistics</a> about
values in different columns to be able to produce reasonable query plans, and
looks like it's shooting blanks for this column.</p>
<p>What's the simplest fix? Oftentimes
<a href="https://www.postgresql.org/docs/current/sql-analyze.html"><code>ANALYZE</code></a> on a table
is enough to fix broken statistics, but this time it didn't help at
all. Sometimes it's useful to adjust how many rows are analyzed to gather
statistics, and it can be adjusted down to a per-column basis with <a href="https://www.postgresql.org/docs/current/sql-altertable.html"><code>ALTER TABLE ... ALTER COLUMN ... SET STATISTICS</code></a>, but
here it had no effect as well.</p>
<p>Since version 10 PostgreSQL supports <a href="https://www.postgresql.org/docs/current/sql-createstatistics.html"><code>CREATE STATISTICS</code></a>
to gather complex statistics for inter-column dependencies and whatnot, but our
filter is single-column, no luck here as well.</p>
<h2 id="contsel">Contsel<a href="#contsel" aria-label="Anchor link for: contsel">🔗</a></h2>
<p>So I dug some more, and more... And found that operator <code>@&gt;</code> uses something
called <code>contsel</code>. It was mentioned in <a href="https://www.postgresql.org/message-id/23452.1288288224@sss.pgh.pa.us">PostgreSQL mailing
list</a>
in 2010. I tried to decrypt what <code>contsel</code> means and I think it stands for
"contains selectivity". Then I tried searching PostgreSQL sources for <a href="https://github.com/postgres/postgres/search?q=contsel&amp;unscoped_q=contsel"><code>contsel</code>
mentions</a>
and found exactly <a href="https://github.com/postgres/postgres/blob/master/src/backend/utils/adt/geo_selfuncs.c#L80">one
place</a>
in C code which mentions it:</p>
<pre><span>Datum
contsel(PG_FUNCTION_ARGS)
{
	PG_RETURN_FLOAT8(0.001);
}
</span></pre>
<p>0.001? That looks exactly like the ratio between 43 million rows in the table
and an estimated 43 thousand rows in the result. However, if we just multiply 43
thousand by 200 filters we should get 8.6 million, and PostgreSQL estimated only
7.8M. This discrepancy bothered me for a minute because I like to understand
things completely, so they won't set me up for an unpleasant surprise later<a href="https://vsevolod.net/postgresql-jsonb-index/#note3"><sup id="back3">[3]</sup></a>.</p>
<p>After a minute of contemplating the difference I realized that it's probability
in play - PostgreSQL thinks that every filter can match 0.1% of the total number
of rows and they can overlap. The actual math is:</p>
<pre><span>1 - 0.999 ** 200 = 1 - 0.819 = 0.181
</span></pre>
<p>18.1% of 43 million is 7.8 million (I'm rounding numbers here). Itch scratched
successfully.</p>
<p>And, depending on the <a href="https://www.postgresql.org/docs/current/runtime-config-query.html#RUNTIME-CONFIG-QUERY-CONSTANTS">different
costs</a>
of various factors in the config, Postgres will select either sequential scan or
will use an index. Our first solution was to slice these filters into batches
with no more than 150 of them per query. It worked quite well for a couple of
years.</p>
<h2 id="domain-modeling-failure">Domain modeling failure<a href="#domain-modeling-failure" aria-label="Anchor link for: domain-modeling-failure">🔗</a></h2>
<p>Until we learned that one article could have more than one such external
identifier per type. For example, some pre-print services grant new DOI for each
version. <a href="https://dx.doi.org/10.26434/chemrxiv.11938173.v8">10.26434/chemrxiv.11938173.v8</a>
has eight of them at the time of writing. And then it has the main DOI without
version
<a href="https://dx.doi.org/10.26434/chemrxiv.11938173">10.26434/chemrxiv.11938173</a>, and
will have another one if it will be published after peer review. There are other
cases for some other identifier types (we call these types "origin name").</p>
<p>We had two options:</p>
<ul>
<li>
<p>Store origin ids in a separate table with columns <code>article_id</code>, <code>origin_name</code>
and <code>origin_id</code> with two indexes - one on <code>article_id</code> and the other on
<code>(origin_name, origin_id)</code>;</p>
</li>
<li>
<p>Accommodate many values per key in <code>jsonb</code>. Two more possible options here:</p>
<ul>
<li>Many values per key: <code>{"doi": ["10.26434/3", "10.26434/3.v1"]}</code></li>
<li>List of pairs: <code>[["doi", "10.26434/3"], ["doi", "10.26434/3.v1"]]</code></li>
</ul>
<p>Both can be queried with <code>@&gt;</code>, but it's getting even more uglier than it was.</p>
</li>
</ul>
<p>We ended up doing kind of both - we created a separate table that's much easier
to query with many origin ids at once, and we store a list of pairs in a
separate non-indexed column so it's convenient to query.</p>
<h2 id="separate-table-speed-up">Separate table speed-up<a href="#separate-table-speed-up" aria-label="Anchor link for: separate-table-speed-up">🔗</a></h2>
<p>As a bonus, it's much-much faster to query a btree index with lots of filters
than a GIN one. With a GIN every <code>@&gt;</code> turns into a separate Bitmap Index Scan
that costs approximately millisecond for each (0.7-1.2 ms each if in
cache). With a btree index on two columns we construct a query that looks like
this:</p>
<pre><span>SELECT article_id FROM articles_origin_ids WHERE
    (origin_name = $1 AND origin_id = ANY($2)) OR
    (origin_name = $3 AND origin_id = ANY($4)) OR
    (origin_name = $5 AND origin_id = ANY($6));
</span></pre>
<p>Accessing a btree index is faster even by itself, I get 0.07 ms for Bitmap Index
Scan node in <code>EXPLAIN ANALYZE</code> for one <code>origin_name</code>, <code>origin_id</code> pair. …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vsevolod.net/postgresql-jsonb-index/">https://vsevolod.net/postgresql-jsonb-index/</a></em></p>]]>
            </description>
            <link>https://vsevolod.net/postgresql-jsonb-index/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23625883</guid>
            <pubDate>Wed, 24 Jun 2020 09:26:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Techniques to regain control of your Legacy codebase]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23625819">thread link</a>) | @a7b3fa
<br/>
June 24, 2020 | https://understandlegacycode.com/blog/7-techniques-to-regain-control-of-legacy/ | <a href="https://web.archive.org/web/*/https://understandlegacycode.com/blog/7-techniques-to-regain-control-of-legacy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>🇫🇷 Si tu souhaites lire cet article en français, je l’ai écris à l’origine <a href="https://www.jesuisundev.com/7-techniques-pour-reprendre-le-controle-de-ton-legacy-code/">en tant qu’article invité sur jesuisundev.com</a>.</em></p><p>Let’s face it: we spend most of our time changing existing code. Usually, we didn’t even write that code in the first place. Often, there’s no test. Sometimes, the authors of the code are long gone! And yet, we have to understand and modify this code – without introducing any bug, thank you.</p><p>You’d love to change any part of the code with confidence… but you never have time! This change has been estimated as a 2-day task and there are many others to ship before the end of the Sprint/demo to the client/delivery/<em>&lt;insert your deadline here<!-- -->&gt;</em>. Nightmare!</p><p>But what if you had a secret weapon? Techniques to approach this Legacy efficiently, reach your goal without getting distracting with all the Technical Debt? You could regain control of this project and make it easier to maintain, each iteration!</p><p>Working on Legacy Code is indeed no fun… but it could be.</p><p>Here are 7 concrete techniques that will help you regain control of your Legacy.</p><h2 id="1-the-brain-dump-🧠"><a href="#1-the-brain-dump-%F0%9F%A7%A0" aria-label="1 the brain dump 🧠 permalink"></a>1. The Brain Dump 🧠</h2><p>Your brain is not optimized to memorize a lot of things. You can only juggle with a limited number of thoughts.</p><p>The problem is: your Legacy is a jungle. It’s full of badly named variables, non-standard structures, useless indirections, bad abstractions… To reach your goal, you need to go through a lot of traps you can’t anticipate. When you move something, you reveal 3 more issues that were hidden behind!</p><p>If you try to juggle with all of these things in your head, you’ll get lost.</p><p>It’s the “I’m almost done on this ticket” effect. You have been repeating that for the past 3 days during stand-up. This usually ends up with Pull Requests that are too long and contain many more changes than expected.</p><p>You need to get these ideas out to not getting lost. The easiest way to do that is <strong>a sheet of paper</strong>.</p><p>Take a sheet and a pencil. Start by dumbing everything you want to do on this code. Write down a TODO list.</p><p>Then, choose a first task and start doing it.</p><p>As you move on this task, you’ll have new ideas. New tasks that you discover. Refactors you want to do. When it happens, don’t do them: <strong>write them down!</strong></p><p><undefined>
  <a href="https://understandlegacycode.com/static/1ca540bf66618f065082a0318a734da6/6ed10/brain-dump.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="brain dump" title="" src="https://understandlegacycode.com/static/1ca540bf66618f065082a0318a734da6/799d3/brain-dump.png" srcset="https://understandlegacycode.com/static/1ca540bf66618f065082a0318a734da6/00d96/brain-dump.png 148w,https://understandlegacycode.com/static/1ca540bf66618f065082a0318a734da6/0b23c/brain-dump.png 295w,https://understandlegacycode.com/static/1ca540bf66618f065082a0318a734da6/799d3/brain-dump.png 590w,https://understandlegacycode.com/static/1ca540bf66618f065082a0318a734da6/2a3d6/brain-dump.png 885w,https://understandlegacycode.com/static/1ca540bf66618f065082a0318a734da6/6ed10/brain-dump.png 900w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    </undefined></p><p>Writing them down on your piece of paper has 2 main benefits:</p><ol><li><strong>You calm your mind.</strong> It knows information is out of your head and you won’t forget it. Thus, you’ll stop rehashing this idea every 5 minutes and you can focus on the ongoing task!</li><li><strong>You’ll avoid the tunnel effect.</strong> You’ll end what you started before you start something else. You’ll cross off the task that is done, commit, and take a break! You’ll have a clearer vision of your progress instead of a vague feeling of “almost done”.</li></ol><p>If you know <a href="https://gettingthingsdone.com/">the GTD method</a>, this will feel familiar.</p><h2 id="2-the-mikado-method-🥢"><a href="#2-the-mikado-method-%F0%9F%A5%A2" aria-label="2 the mikado method 🥢 permalink"></a>2. The Mikado Method 🥢</h2><p>The Mikado Method is a similar concept than the Brain Dump, but with more structure. It’s perfect when you want to reach a particular goal and you don’t know what will get in your way.</p><p>Here again, you just need a sheet and a pencil.</p><p>Start writing down your main goal. Circle it twice. Then, try to achieve it.</p><p>If you realize you need something else to do this task, do these 2 very important things:</p><ol><li>Cancel your pending changes (<code>git reset --hard</code>)</li><li>Write down the subtask you need to do and link it to the main task.</li></ol><p>Then, start over from the subtask. Iterate if you realize you miss something again.</p><p><undefined>
  <a href="https://understandlegacycode.com/static/3b727308693fc6ab11943c10c646142a/5d675/mikado.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="mikado" title="" src="https://understandlegacycode.com/static/3b727308693fc6ab11943c10c646142a/799d3/mikado.png" srcset="https://understandlegacycode.com/static/3b727308693fc6ab11943c10c646142a/00d96/mikado.png 148w,https://understandlegacycode.com/static/3b727308693fc6ab11943c10c646142a/0b23c/mikado.png 295w,https://understandlegacycode.com/static/3b727308693fc6ab11943c10c646142a/799d3/mikado.png 590w,https://understandlegacycode.com/static/3b727308693fc6ab11943c10c646142a/2a3d6/mikado.png 885w,https://understandlegacycode.com/static/3b727308693fc6ab11943c10c646142a/5d675/mikado.png 1000w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    </undefined></p><p>At some point, the subtask will be so small that you’ll be able to do it without trouble. Great! Commit that, cross off that task, and celebrate internally!</p><p>Then, take another subtask and continue. As you achieve subtasks, you make the main one easier. At some point, doing it will be really easy!</p><p>Just like the Brain Dump, you’ll feel less stressed and you’ll have a better view of your progress. You’ll be able to push intermediate Pull Requests that will progressively make the main goal easier to achieve.</p><p>If you want to learn more, I’ve dedicated <a href="https://understandlegacycode.com/blog/a-process-to-do-safe-changes-in-a-complex-codebase">a full post on this</a> and <a href="https://www.manning.com/books/the-mikado-method">there’s a book on that</a>.</p><h2 id="3-over-committing-"><a href="#3-over-committing-" aria-label="3 over committing  permalink"></a>3. Over-committing ➿</h2><p>When you work on Legacy Code, it’s very easy to get stuck in a position where nothing works anymore and you don’t really know why.</p><p>In this context, I recommend taking a safer approach.</p><p>I mean, if only you had a way to have checkpoints for every single step you take in the right direction! With this, you won’t have to start over again if you do one or two wrong moves. You could just go back to the last checkpoint!</p><p>Well, this is <em>exactly</em> where your version control system excels. Create checkpoints.</p><p>My advice: when you work on Legacy Code, commit very very very often. You should commit more often than you imagine. Here are 2 options:</p><ol><li><strong>Commit every 5 minutes.</strong> That’s easy to do, you only need a timer. Each time it rings, commit and run the timer again.</li><li><strong>If you practice the Mikado Method, commit every subtask you achieve.</strong> The technique is optimized to make you do small changes, therefore it’s perfect for frequent commits.</li></ol><p><undefined>
  <a href="https://understandlegacycode.com/static/268aa13a160fdfe7f8172d8b9e7b9969/3c21b/overcommit.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="overcommit" title="" src="https://understandlegacycode.com/static/268aa13a160fdfe7f8172d8b9e7b9969/799d3/overcommit.png" srcset="https://understandlegacycode.com/static/268aa13a160fdfe7f8172d8b9e7b9969/00d96/overcommit.png 148w,https://understandlegacycode.com/static/268aa13a160fdfe7f8172d8b9e7b9969/0b23c/overcommit.png 295w,https://understandlegacycode.com/static/268aa13a160fdfe7f8172d8b9e7b9969/799d3/overcommit.png 590w,https://understandlegacycode.com/static/268aa13a160fdfe7f8172d8b9e7b9969/3c21b/overcommit.png 777w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    </undefined></p><p>It’s OK if your commit messages are messy or duplicated. You can (should) edit them before you push on the shared repository. I frequently create commits that I squash later. Having too many commits will help you more than not having enough.</p><p>Practice this technique and you’ll see the quality of your Pull Requests raise up after a few weeks. But most of all, you’ll have your checkpoints!</p><h2 id="4-adrs-"><a href="#4-adrs-" aria-label="4 adrs  permalink"></a>4. ADRs 📝</h2><p>Sometimes, you’ll hit a very annoying obstacle: lack of context.</p><p>It’s terrible when you don’t know why something is written that way. It makes you face a dilemma: keep the code as it is and work around, or change it and take the risk of breaking something unexpected. At best, this will just take longer to solve. Tracing back to the original decision behind the code you have in front of you feels like archaeology, and it’s not easy!</p><p>Unfortunately, I don’t have a magic spell to generate missing documentation for you. But I still have a technique that will stop your code from bleeding so hard. Here’s an advice that’s more pragmatic than “just write the doc”.</p><p>Meet <strong>Architecture Decision Records</strong> (ADRs).</p><p>Here’s the concept: each time you make a non-trivial decision, write a note about it. The good news is that you don’t really have to maintain this note. It captures the “why” behind your decision like a snapshot. Your future self will thank you for taking 5 extra minutes to write this down!</p><p>Here’s what it looks like:</p><p><undefined>
  <a href="https://understandlegacycode.com/static/2ffc68d37c322bf50a6b1b3c1f3b6248/74b92/adrs.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="adrs" title="" src="https://understandlegacycode.com/static/2ffc68d37c322bf50a6b1b3c1f3b6248/799d3/adrs.png" srcset="https://understandlegacycode.com/static/2ffc68d37c322bf50a6b1b3c1f3b6248/00d96/adrs.png 148w,https://understandlegacycode.com/static/2ffc68d37c322bf50a6b1b3c1f3b6248/0b23c/adrs.png 295w,https://understandlegacycode.com/static/2ffc68d37c322bf50a6b1b3c1f3b6248/799d3/adrs.png 590w,https://understandlegacycode.com/static/2ffc68d37c322bf50a6b1b3c1f3b6248/2a3d6/adrs.png 885w,https://understandlegacycode.com/static/2ffc68d37c322bf50a6b1b3c1f3b6248/74b92/adrs.png 945w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    </undefined></p><p>The structure is simple:</p><ol><li>The title that recaps the decision you’re taking</li><li>The date</li><li>Context around this decision. Explain why you’re going this way instead of another. Describe your constraints, what you know, how things work today, etc. Everything that motivates this decision.</li><li>The decision itself</li><li>Consequences of this decision, good and bad. Maybe this comes with compromise, document them!</li></ol><p>Keep ADRs versioned along with the code. It’s simple, easy to find, and to search when you’re looking for a particular decision.</p><p>Make a habit to write these ADRs. It’s a little investment that quickly pays off. From my experience, that also helps the reviewer of the Pull Request!</p><p>Finally, I’d recommend you use <a href="https://github.com/npryce/adr-tools">the adr-tools CLI</a>. It makes all of this so easy that you won’t have any excuse not to write them.</p><p>If you want to learn more about ADRs, <a href="https://understandlegacycode.com/blog/earn-maintainers-esteem-with-adrs">I wrote a detailed post on this topic</a> too.</p><h2 id="5-approval-testing-"><a href="#5-approval-testing-" aria-label="5 approval testing  permalink"></a>5. Approval Testing ✅</h2><p>This technique feels like a secret weapon.</p><p>This is the fastest way I know to write tests on existing code, so you can refactor it safely.</p><p>You may know it under a different name: Characterization Tests, Golden Master, or Snapshot Tests.</p><p>It comes in 3 main steps:</p><ol><li>📸 Generate an output you can snapshot</li><li>✅ Use test coverage to find all input combinations</li><li>👽 Use mutations to verify your snapshots</li></ol><h3 id="1--generate-an-output-you-can-snapshot"><a href="#1--generate-an-output-you-can-snapshot" aria-label="1  generate an output you can snapshot permalink"></a>1. 📸 Generate an output you can snapshot</h3><p>The first step is also the most complex. Generate a text you can write in some file: this will be your snapshot.</p><p>If the code you’re testing returns a value, you already have it. Otherwise, you’ll likely need to intercept calls made in your code to log the parameters that are given… A different approach is to introduce logs in your code.</p><p>Here’s an example using the Jest library, in JavaScript:</p><pre data-language="js"><code><span><span>it</span><span>(</span><span>"should update quality"</span><span>, () </span><span>=&gt;</span><span> {</span></span>
<span><span>  </span><span>expect</span><span>(</span><span>updateQuality</span><span>(</span><span>"foo"</span><span>, </span><span>0</span><span>, </span><span>0</span><span>)).</span><span>toMatchSnapshot</span><span>()</span></span>
<span><span>})</span></span></code></pre><p>The first time you run the test, it passes and stores the result in a file. Then, it compares the result of further runs with the one that was stored. If it’s different, the test will fail. The idea is to detect if anything changed!</p><h3 id="2--use-test-coverage-to-find-all-input-combinations"><a href="#2--use-test-coverage-to-find-all-input-combinations" aria-label="2  use test coverage to find all input combinations permalink"></a>2. ✅ Use test coverage to find all input combinations</h3><p>Once you have your first snapshot, you have 1 scenario covered. There is certainly much more you need to find out before you can feel confident changing your code.</p><p>This is where test coverage is a very useful tool. It tells you which code is not tested!</p><p>Here’s an example:</p><p><undefined>
  <a href="https://understandlegacycode.com/static/031e5ae187cbdecc3aa7a648e5095867/5d675/gilded-rose.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="gilded rose" title="" src="https://understandlegacycode.com/static/031e5ae187cbdecc3aa7a648e5095867/799d3/gilded-rose.png" srcset="https://understandlegacycode.com/static/031e5ae187cbdecc3aa7a648e5095867/00d96/gilded-rose.png 148w,https://understandlegacycode.com/static/031e5ae187cbdecc3aa7a648e5095867/0b23c/gilded-rose.png 295w,https://understandlegacycode.com/static/031e5ae187cbdecc3aa7a648e5095867/799d3/gilded-rose.png 590w,https://understandlegacycode.com/static/031e5ae187cbdecc3aa7a648e5095867/2a3d6/gilded-rose.png 885w,https://understandlegacycode.com/static/031e5ae187cbdecc3aa7a648e5095867/5d675/gilded-rose.png 1000w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    </undefined></p><p>Red lines are the ones that are not covered. Your goal is to have no red line. Change all inputs you can so you cover as many scenarios as possible!</p><h3 id="3--use-mutations-to-verify-your-snapshots"><a href="#3--use-mutations-to-verify-your-snapshots" aria-label="3  use mutations to verify your snapshots permalink"></a>3. 👽 Use mutations to verify your snapshots</h3><p>Once you’ve covered everything with tests, there’s one last thing to check: that you’re actually covering the code.</p><p>This is the limit of test coverage: it doesn’t prove the quality of your tests. You can have 100% test coverage without testing much. This is why I never set a % of test coverage as a metric. It’s a useful tool, but it can’t be an objective.</p><p>How do you quickly verify the quality of your tests? By introducing “mutations”. Concretely, this means you should introduce bugs in the source code deliberately, so you can check a test is failing.</p><p>My preferred way of doing so is to comment code. Comment a line of code, then run the tests:</p><ul><li>If they fail, you can rejoice to know that you have a safety net if you introduce a bug here.</li><li>If they pass, you need to find the combination of the missing inputs that will cover this scenario.</li></ul><h3 id="why-does-it-work"><a href="#why-does-it-work" aria-label="why does it work permalink"></a>Why does it work?</h3><p>When you’re done, you can restructure your code safely. If you do a mistake, you’ll know …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://understandlegacycode.com/blog/7-techniques-to-regain-control-of-legacy/">https://understandlegacycode.com/blog/7-techniques-to-regain-control-of-legacy/</a></em></p>]]>
            </description>
            <link>https://understandlegacycode.com/blog/7-techniques-to-regain-control-of-legacy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23625819</guid>
            <pubDate>Wed, 24 Jun 2020 09:14:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Improving API Performance with Telnet]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23625795">thread link</a>) | @tosh
<br/>
June 24, 2020 | https://blog.teller.io/2020/06/23/improving-api-performance-with-telnet.html | <a href="https://web.archive.org/web/*/https://blog.teller.io/2020/06/23/improving-api-performance-with-telnet.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><header><img src="https://blog.teller.io/images/authors/stevegraham.jpg"></header><p>As you may or may not know, banks do not generally provide third party developers with API access. This is because providing developers with easy API access to customer accounts means actual competition and ultimately compressed margins. In fairness to banks, building a new API channel costs a lot of money and if all it does is increase competitive pressure why would you spend any time or money on it? It's a rational response given their incentives.</p>

<p>Despite this people still want to connect their bank accounts to services they trust, and companies still want to build those services.</p>

<p>So, where does this leave us? Thankfully the market has stepped in to provide solutions that enable us all to connect trusted apps with our financial accounts, despite this banks still actively block third party access by blocking their traffic.</p>

<h2 id="all-ip-addresses-are-not-created-equal">All IP addresses are not created equal</h2>

<p>The way we have solved this is to route our financial institution traffic onto the public internet via mobile phone carrier networks.</p>

<p>The great thing about carrier IP ranges is that carriers have significantly more customers than they have IP addresses, meaning public internet breakout is heavily <a href="https://en.wikipedia.org/wiki/Network_address_translation">NAT</a>-ed, i.e. a single address is shared and used by many customers simultaneously. The other great thing is there is good chance you're on mobile data when you use your bank's mobile app and your IP address is in the carrier’s IP range.</p>

<p>By sending our traffic onto the internet using the same IP addresses shared by millions of a bank’s own customers using the bank’s mobile app, we both make it significantly more difficult to identify and subsequently block our traffic and we also increase the collateral damage of any hostile action a bank might take against us and our users, i.e. erroneously blocking their own customers using their mobile banking app.</p>

<svg width="405px" height="279px" viewBox="0 0 405 279" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
    <!-- Generator: Sketch 52.6 (67491) - http://www.bohemiancoding.com/sketch -->
    <title>Untitled 4</title>
    <desc>Created with Sketch.</desc>
    <defs>
        <linearGradient x1="50%" y1="0%" x2="50%" y2="100%" id="linearGradient-1">
            <stop stop-color="#FBFBFB" offset="0%"></stop>
            <stop stop-color="#FFFFFF" offset="100%"></stop>
        </linearGradient>
        <rect id="path-2" x="0" y="0" width="83" height="85" rx="11"></rect>
        <filter x="-6.0%" y="-4.7%" width="112.0%" height="111.8%" filterUnits="objectBoundingBox" id="filter-3">
            <feOffset dx="0" dy="1" in="SourceAlpha" result="shadowOffsetOuter1"></feOffset>
            <feGaussianBlur stdDeviation="1.5" in="shadowOffsetOuter1" result="shadowBlurOuter1"></feGaussianBlur>
            <feColorMatrix values="0 0 0 0 0   0 0 0 0 0   0 0 0 0 0  0 0 0 0.5 0" type="matrix" in="shadowBlurOuter1"></feColorMatrix>
        </filter>
        <rect id="path-4" x="0" y="0" width="83" height="85" rx="11"></rect>
        <filter x="-6.0%" y="-4.7%" width="112.0%" height="111.8%" filterUnits="objectBoundingBox" id="filter-5">
            <feOffset dx="0" dy="1" in="SourceAlpha" result="shadowOffsetOuter1"></feOffset>
            <feGaussianBlur stdDeviation="1.5" in="shadowOffsetOuter1" result="shadowBlurOuter1"></feGaussianBlur>
            <feColorMatrix values="0 0 0 0 0   0 0 0 0 0   0 0 0 0 0  0 0 0 0.5 0" type="matrix" in="shadowBlurOuter1"></feColorMatrix>
        </filter>
        <linearGradient x1="50%" y1="2.30762283%" x2="50%" y2="100%" id="linearGradient-6">
            <stop stop-color="#F4F4F4" offset="0%"></stop>
            <stop stop-color="#FFFFFF" offset="100%"></stop>
        </linearGradient>
        <rect id="path-7" x="0" y="0" width="83" height="85" rx="11"></rect>
        <filter x="-6.0%" y="-4.7%" width="112.0%" height="111.8%" filterUnits="objectBoundingBox" id="filter-8">
            <feOffset dx="0" dy="1" in="SourceAlpha" result="shadowOffsetOuter1"></feOffset>
            <feGaussianBlur stdDeviation="1.5" in="shadowOffsetOuter1" result="shadowBlurOuter1"></feGaussianBlur>
            <feColorMatrix values="0 0 0 0 0   0 0 0 0 0   0 0 0 0 0  0 0 0 0.5 0" type="matrix" in="shadowBlurOuter1"></feColorMatrix>
        </filter>
        <rect id="path-9" x="0" y="0" width="83" height="85" rx="11"></rect>
        <filter x="-6.0%" y="-4.7%" width="112.0%" height="111.8%" filterUnits="objectBoundingBox" id="filter-10">
            <feOffset dx="0" dy="1" in="SourceAlpha" result="shadowOffsetOuter1"></feOffset>
            <feGaussianBlur stdDeviation="1.5" in="shadowOffsetOuter1" result="shadowBlurOuter1"></feGaussianBlur>
            <feColorMatrix values="0 0 0 0 0   0 0 0 0 0   0 0 0 0 0  0 0 0 0.5 0" type="matrix" in="shadowBlurOuter1"></feColorMatrix>
        </filter>
    </defs>
    <g id="Page-2" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
        <g id="Direct" transform="translate(3.000000, 2.000000)">
            <g id="Teller">
                <g id="Rectangle">
                    <use fill="black" fill-opacity="1" filter="url(#filter-3)" xlink:href="#path-2"></use>
                    <use fill="url(#linearGradient-1)" fill-rule="evenodd" xlink:href="#path-2"></use>
                </g>
                <g id="logo-icon" transform="translate(19.462069, 19.931034)">
                    <path d="M14.8827586,31.6551724 L32.6275862,42.3854528 C29.5320561,44.1410729 25.9869012,45.137931 22.2194476,45.137931 C19.6460127,45.137931 17.1762988,44.6728122 14.8827586,43.8184589 L14.8827586,31.6551724 Z" id="Path" fill="#7985F2"></path>
                    <path d="M0,25.873964 L10.8758621,20.5172414 L10.8758621,42.2068966 C5.10335134,38.7926982 0.978977218,32.8443874 0,25.873964 Z" id="Path" fill="#F279D2"></path>
                    <path d="M0,21.6896552 C0.271210478,15.10675 3.30641844,9.24809514 7.95952004,5.27586207 L18.8896552,11.6748484 L11.488822,16.0076248 L0,21.6896552 Z" id="Path" fill="#F27979"></path>
                    <path d="M21.7854166,0 C24.5975441,0 27.2879935,0.532858373 29.7655172,1.5052445 L29.7655172,14.0689655 L10.8758621,2.91406436 C14.1003847,1.05844846 17.8220523,0 21.7854166,0 Z" id="Path" fill="#FFD780"></path>
                    <path d="M43.5034483,19.4519397 L33.2,25.2068966 L33.2,3.51724138 C38.6814991,6.95475181 42.5720341,12.7258567 43.5034483,19.4519397 Z" id="Path" fill="#91E673"></path>
                    <path d="M44.0758621,24.0344828 C43.7596445,30.6495208 40.6674041,36.5184923 35.9655559,40.4482759 L25.7586207,34.4203712 L44.0758621,24.0344828 Z" id="Path" fill="#79DEF2"></path>
                </g>
            </g>
            <g id="Bank" transform="translate(316.000000, 1.000000)">
                <g id="Rectangle">
                    <use fill="black" fill-opacity="1" filter="url(#filter-5)" xlink:href="#path-4"></use>
                    <use fill="url(#linearGradient-1)" fill-rule="evenodd" xlink:href="#path-4"></use>
                </g>
                <text id="🏦" font-family="AppleColorEmoji, Apple Color Emoji" font-size="42" font-weight="normal" fill="#616161">
                    <tspan x="21" y="56">🏦</tspan>
                </text>
            </g>
            <path d="M84.5,43.4482759 L310,43.4482759" id="Line" stroke="#DC6F6F" stroke-width="3" stroke-linecap="square"></path>
            <polygon id="Triangle" fill="#DC6F6F" transform="translate(307.000000, 43.000000) rotate(-270.000000) translate(-307.000000, -43.000000) " points="307 35 315 51 299 51"></polygon>
            <text id="😤" font-family="AppleColorEmoji, Apple Color Emoji" font-size="30" font-weight="normal" fill="#616161">
                <tspan x="306" y="92">😤</tspan>
            </text>
            <path d="M183,57.9974594 C182.925417,57.9991501 182.850628,58 182.775641,58 C177.376704,58 173,53.5942914 173,48.1595745 C173,42.7248575 177.376704,38.3191489 182.775641,38.3191489 C182.918809,38.3191489 183.061258,38.322247 183.202926,38.3283802 C183.803357,28.6569802 191.785809,21 201.544872,21 C208.207767,21 214.042526,24.5691708 217.265242,29.9117828 C218.12594,29.7462314 219.014455,29.6595745 219.923077,29.6595745 C227.697547,29.6595745 234,36.0037948 234,43.8297872 C234,51.6557796 227.697547,58 219.923077,58 C219.270736,58 218.628759,57.9553331 218,57.8688719 L218,58 L183,58 L183,57.9974594 Z" id="Cloud" stroke="#979797" stroke-width="3" fill="url(#linearGradient-6)"></path>
            <text id="Cloud-traffic-is-eas" font-family="HelveticaNeue, Helvetica Neue" font-size="14" font-weight="normal" fill="#2D2D2D">
                <tspan x="38.278" y="117.551724">Cloud traffic is easily detectable and trivial to block</tspan>
            </text>
        </g>
        <g id="Telnet" transform="translate(3.000000, 158.000000)">
            <g id="Teller">
                <g id="Rectangle">
                    <use fill="black" fill-opacity="1" filter="url(#filter-8)" xlink:href="#path-7"></use>
                    <use fill="url(#linearGradient-1)" fill-rule="evenodd" xlink:href="#path-7"></use>
                </g>
                <g id="logo-icon" transform="translate(19.462069, 19.931034)">
                    <path d="M14.8827586,31.6551724 L32.6275862,42.3854528 C29.5320561,44.1410729 25.9869012,45.137931 22.2194476,45.137931 C19.6460127,45.137931 17.1762988,44.6728122 14.8827586,43.8184589 L14.8827586,31.6551724 Z" id="Path" fill="#7985F2"></path>
                    <path d="M0,25.873964 L10.8758621,20.5172414 L10.8758621,42.2068966 C5.10335134,38.7926982 0.978977218,32.8443874 0,25.873964 Z" id="Path" fill="#F279D2"></path>
                    <path d="M0,21.6896552 C0.271210478,15.10675 3.30641844,9.24809514 7.95952004,5.27586207 L18.8896552,11.6748484 L11.488822,16.0076248 L0,21.6896552 Z" id="Path" fill="#F27979"></path>
                    <path d="M21.7854166,0 C24.5975441,0 27.2879935,0.532858373 29.7655172,1.5052445 L29.7655172,14.0689655 L10.8758621,2.91406436 C14.1003847,1.05844846 17.8220523,0 21.7854166,0 Z" id="Path" fill="#FFD780"></path>
                    <path d="M43.5034483,19.4519397 L33.2,25.2068966 L33.2,3.51724138 C38.6814991,6.95475181 42.5720341,12.7258567 43.5034483,19.4519397 Z" id="Path" fill="#91E673"></path>
                    <path d="M44.0758621,24.0344828 C43.7596445,30.6495208 40.6674041,36.5184923 35.9655559,40.4482759 L25.7586207,34.4203712 L44.0758621,24.0344828 Z" id="Path" fill="#79DEF2"></path>
                </g>
            </g>
            <g id="Bank" transform="translate(316.000000, 1.000000)">
                <g id="Rectangle">
                    <use fill="black" fill-opacity="1" filter="url(#filter-10)" xlink:href="#path-9"></use>
                    <use fill="url(#linearGradient-1)" fill-rule="evenodd" xlink:href="#path-9"></use>
                </g>
                <text id="🏦" font-family="AppleColorEmoji, Apple Color Emoji" font-size="42" font-weight="normal" fill="#616161">
                    <tspan x="21" y="56">🏦</tspan>
                </text>
            </g>
            <path d="M84.5,43.4482759 L310,43.4482759" id="Line" stroke="#9EDC6F" stroke-width="3" fill="#9EDC6F" stroke-linecap="square"></path>
            <polygon id="Triangle" fill="#9EDC6F" transform="translate(307.000000, 43.000000) rotate(-270.000000) translate(-307.000000, -43.000000) " points="307 35 315 51 299 51"></polygon>
            <text id="📱" font-family="AppleColorEmoji, Apple Color Emoji" font-size="45" font-weight="normal" fill="#616161">
                <tspan x="178" y="61">📱</tspan>
            </text>
            <text id="😌" font-family="AppleColorEmoji, Apple Color Emoji" font-size="30" font-weight="normal" fill="#616161">
                <tspan x="306" y="92">😌</tspan>
            </text>
            <text id="Traffic-routed-via-c" font-family="HelveticaNeue, Helvetica Neue" font-size="14" font-weight="normal" fill="#2D2D2D">
                <tspan x="5.728" y="117.551724">Traffic routed via carrier networks passes through undetected</tspan>
            </text>
        </g>
    </g>
</svg>

<p>Until recently we used a third party provider for mobile carrier network transit, but suddenly without warning their performance and availabilty degraded to unacceptable levels. Requests occasionally took 20-30 seconds to complete. A single Teller API transaction might actually involve several requests to the financial institution, and even if we can parallelize some of these it's a disaster for us if any of them take 30 seconds.</p>

<p>Teller provides live access to financial accounts. <strong>When you request an account balance, Teller synchronously fetches that data live from the financial institition and returns it to you</strong>. Fast and reliable network access is an absolute must in order for us to provide that level of access. Other providers can get away with lesser network performance because they don't actually ever return live data in an API call. They periodically poll the institution a couple of times a day, and give you the most recent data they have when you make your API call.</p>

<p>We immediately began to design and build an in house solution to solve this problem once and for all.</p>

<h2 id="introducing-telnet">Introducing Telnet</h2>

<p>Telnet is our propietary mobile carrier proxy network. The name is a portmanteau of Teller Network, but if we're honest it began as an internal joke as it's built on top of <a href="https://en.wikipedia.org/wiki/Secure_Shell">SSH</a>, the remote access protocol that obsoleted the original <a href="https://en.wikipedia.org/wiki/Telnet">Telnet</a>.</p>

<p>Telnet is composed of a large number of edge nodes, which are single board Linux computers with LTE modems attached running our own software written using <a href="https://www.nerves-project.org/">Nerves</a>. When nodes boot they reverse SSH into our network and register themselves as available to route API traffic. Our infrastructure then routes our financial institution traffic via our Telnet edge nodes, egressing onto the internet on carrier IP ranges.</p>

<svg width="362px" height="360px" viewBox="0 0 362 360" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
    <!-- Generator: Sketch 52.6 (67491) - http://www.bohemiancoding.com/sketch -->
    <title>Graph</title>
    <desc>Created with Sketch.</desc>
    <g id="Page-1" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
        <g id="Graph" transform="translate(1.000000, -3.000000)">
            <g id="Vendor" transform="translate(16.000000, 39.000000)">
                <text id="Vendor-A" font-family="HelveticaNeue, Helvetica Neue" font-size="14" font-weight="normal" fill="#616161">
                    <tspan x="21" y="323">Vendor A</tspan>
                </text>
                <rect id="Rectangle" fill="#DDE8FF" x="0" y="0" width="100" height="300"></rect>
            </g>
            <g id="Telnet" transform="translate(129.000000, 312.000000)">
                <text font-family="HelveticaNeue, Helvetica Neue" font-size="14" font-weight="normal" fill="#616161">
                    <tspan x="32" y="50">Telnet</tspan>
                </text>
                <rect id="Rectangle" fill="#DDE8FF" x="0" y="0" width="100" height="27"></rect>
            </g>
            <g id="Direct" transform="translate(242.000000, 327.000000)">
                <text font-family="HelveticaNeue, Helvetica Neue" font-size="14" font-weight="normal" fill="#616161">
                    <tspan x="32" y="35">Direct</tspan>
                </text>
                <rect id="Rectangle" fill="#DDE8FF" x="0" y="0" width="100" height="12"></rect>
            </g>
            <g id="Axes" transform="translate(0.000000, 36.000000)" stroke="#979797" stroke-linecap="square" stroke-width="3">
                <path d="M0.5,0.5 L0.5,302.5" id="Line"></path>
                <path d="M0.5,302.5 L359.100943,302.5" id="Line-2"></path>
            </g>
            <text id="Request-latency" font-family="HelveticaNeue, Helvetica Neue" font-size="14" font-weight="normal" fill="#2D2D2D">
                <tspan x="130.065" y="13">Request latency</tspan>
            </text>
        </g>
    </g>
</svg>

<p><strong>It works amazingly well</strong>. We have not only cut the latency overhead to the bone, according to our logs requests failing due to proxy errors have become a thing of the past too.</p>

<p>Credit goes to the team for shipping this so quickly. They went from bare git repo to production deployment of a fleet of embedded devices with OTA software updates in weeks. I'm very proud of them.</p>

<p>Follow <a href="https://twitter.com/tellerapi">@tellerapi</a> for a future blog post on how we built Telnet.</p>

<p>Think this is cool? <a href="https://jobs.lever.co/teller">We're hiring</a>.</p>
</article></div></div>]]>
            </description>
            <link>https://blog.teller.io/2020/06/23/improving-api-performance-with-telnet.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23625795</guid>
            <pubDate>Wed, 24 Jun 2020 09:08:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Is an API? Learn by Building One, Without Code]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23625373">thread link</a>) | @mmckeaveney
<br/>
June 24, 2020 | https://www.martinmck.com/posts/what-is-an-api-learn-by-building-one-without-code/ | <a href="https://web.archive.org/web/*/https://www.martinmck.com/posts/what-is-an-api-learn-by-building-one-without-code/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Learn how to leverage integromat and other tools to build an HTTP API that could be integrated with thousands of different applications and platforms</p><div><p>Think about this:</p><p><strong>How do you retrieve information from computer?</strong></p><p>Take this scenario - you have navigated to your favourite news site or subreddit to procrastinate for a while on that thing you really <strong>should</strong> be doing. In doing so, how often do you think about <em>how</em> the website appeared on your screen? Where do those cat memes on your screen actually come from?</p><p>Humans and computers comprehend data very differently. We as humans can read words on a screen, or process the experiences presented to us in the form of websites, applications and command line interfaces. We can make assumptions about things that we see, based on our previous experiences and memories.</p><p>Computers, on the other hand, cannot. They process numbers at their lowest level. Based on the sequences of numbers, the computer will perform a specific set of tasks. This makes computers extremely good at repetitive tasks that would be either very tedious or very difficult for a human to do as quickly and as consistently as a computer can.</p><p>There are a a lot of intermediate steps that occur between the purely logical, number crunching power of your computers internals and the beautiful, highly immersive visual experiences that modern technology allows us to enjoy today. How does the computer perform its work and tell us what we want to know in a format <em>we</em> understand?</p><p>A website making it from a web server to your eyeballs is not possible without an <strong>Application Programming Interface</strong> (API).  APIs are how your computer interacts with data and are the foundations on which a majority of the modern web is built. An API is a simplified interface allowing a developer to integrate their program with another existing one. You could think of an API as a book that only your computer knows how to read from or write in.</p><p><img src="https://www.martinmck.com/images/daria-nepriakhina-xY55bL5mZAM-unsplash.jpg"></p><p>Some simple examples:</p><ul><li>When you visit your favourite news site, you get the latest news stories from that sites API.</li><li>You can build an app that sends email by using the gmail API.</li><li>You can sign in to many websites with just your facebook account by using the facebook authentication API</li></ul><p>APIs generally define a contract which details the operations the application that uses the API can and cannot do. Staying with the book analogy above, this would mean certain books only let you write specific words in them, in a specific language. This helps prevent bad actors from doing rather annoying things such as abusing your API and potentially crashing your server, or getting access to your data.</p><p>With hundreds of thousands of APIs available and thousands more being created every day, thereâ€™s really no escaping APIs when you are building software. Most applications are enhanced a great deal when they are integrated with others. This is true regardless of whether you are building applications with code or no-code tools.</p><p>To build an API <em>with</em> code, you generally need knowledge around the following software development topics:</p><ul><li>Server side programming languages (Python, Ruby, Java, NodeJS etc.)</li><li>Databases</li><li>HTTP (the protocol that powers the internet by allowing communication between web browsers and web servers)</li><li>Infrastructure and deployment - getting your code to run on a public server so other people can use it</li></ul><p>There are many tools that make the above much easier, but thereâ€™s still a lot to learn if you just want to a simple API that works for you.</p><p>In this post, we are going to build our very own web API <em>without</em> any code at all. </p><p>In a time where <a href="https://a16z.com/2011/08/20/why-software-is-eating-the-world/" title="Software is eating the world">software is eating the world</a>, itâ€™s increasingly important to understand the concepts behind the devices and technology that you are likely to use for a large portion of your day. Being able to explore technical topics without learning programming is a very powerful for anyone with interest in how the world around them works.</p><p>Letâ€™s get into it.</p><h2>Our Tools</h2><p>We are going to use 3 tools in this tutorial:</p><ul><li><strong>Integromat</strong> - an automation platform that lets us glue different applications together without code</li><li><strong>Postman</strong> - an API testing tool. We are going to use this to interact with our API</li><li><strong>Google Sheets</strong> - We are going to use google sheets as our â€œdatabaseâ€�. This is where the data sent to our API will be stored.</li></ul><h2>Our API</h2><p>We are going to use the slightly contrived example of building an HTTP API allowing people to vote for places to go for lunch near the office. We want consumers of the API to be able to register their vote for a particular lunch spot near the office. This will increment the count of a particular lunch spot by one. </p><h3>Setting Up Our Google Sheet</h3><p>First of all we need to create a google sheet. Nothing particularly challenging here. Just go to google sheets and create a blank spreadsheet. Letâ€™s call it â€œLunch Voterâ€�.</p><p><img src="https://www.martinmck.com/images/Screenshot%202020-06-20%20at%2013.43.20.png"></p><h3>Integromat</h3><p>We now have our â€œdatabaseâ€� set up. Letâ€™s create our actual API now to interact with it. First of all, you will need to <a href="https://www.integromat.com/en/register" title="create an integromat account">create an integromat account</a> to get started.</p><p>Integromat is billed as the â€œglue of the internetâ€� and for good reason. It allows you to connect well over 200+ different applications with each other. For example if you want to automatically save gmail attachments to your dropbox account, or send you zoom links directly via WhatsApp for an upcoming calendar meeting, Integromat is your friend. </p><p>The above example are some of the simplest things you could possibly do with integromat - you can automate almost anything with the platform.</p><p><img src="https://www.martinmck.com/images/Screenshot%202020-06-20%20at%2013.48.26.png"></p><h4>Creating an Integromat Scenario</h4><p>Integromat uses a very intuitive flowchart structure for you to define your workflows or â€œscenariosâ€� as they are known. Letâ€™s create a new scenario for our lunch voter API by Navigating to the integromat dashboard and clicking the â€œCreate a new scenarioâ€� button. </p><p>You will be taken to a page allowing you to select integrations you want to use. This step is optional, as we will have access to all the integrations that we need when we get into the integromat builder. Letâ€™s click â€œskipâ€� for now.</p><p><img src="https://www.martinmck.com/images/Screenshot%202020-06-20%20at%2013.56.53.png"></p><p>You will then be presented with the integromat scenario builder. This is where we configure and edit our scenario. Before we build anything, itâ€™s always important to outline the steps we plan to take before we execute. For our lunch voter API, we want to:</p><ul><li>Allow someone to interact with our API telling us the name of the restaurant they want to upvote</li><li>If it doesnâ€™t exist, create a new row in our spreadsheet</li><li>If it exists, update itâ€™s vote count by 1</li></ul><p>Letâ€™s focus on the first item, and provide a way for people to interact with our API. The way we do that is through a <strong>webhook</strong>, which is at its core a way to let applications notify each other of events over the internet. </p><p>Letâ€™s build one.</p><h3>Creating a Webhook</h3><p>To create a Webhook in integromat, click the first module (with the large question mark) and you will see a menu to select an integration. Search for â€œWebhooksâ€� and select it and you will see the options for your webhook. Select â€œCustom Webhookâ€�.</p><p><img src="https://www.martinmck.com/images/Screenshot%202020-06-20%20at%2014.09.36.png"></p><p>Click â€œAddâ€� to add a new webhook. We are going to call ours â€œLunch Voter Webhookâ€�.</p><p><img src="https://www.martinmck.com/images/Screenshot%202020-06-20%20at%2014.10.04.png"></p><p>Click save and you will see a URL. This is how we will talk to our API. Copy this URL to your clipboard by clicking â€œCopy address to clipboardâ€�. </p><p><img src="https://www.martinmck.com/images/Screenshot%202020-06-20%20at%2014.10.43.png"></p><h3>Testing the Webhook</h3><p>We now have an API to interact with, but it isnâ€™t very useful yet. We need to tell the webhook what our data will â€œlook likeâ€� so itâ€™s able to understand when we interact with it.</p><p><img src="https://www.martinmck.com/images/Screenshot%202020-06-20%20at%2014.21.14.png"></p><p>The webhook is now waiting for you to interact with it. We do this by making an HTTP request to that URL. For context, an HTTP request is what happens when you visit a website. Your browser makes an HTTP request for google.com when you try to navigate there, for instance. </p><p>We are going to use a tool called Postman to make our HTTP request. You can download it <a href="https://www.postman.com/downloads/" title="Download Postman">here</a>.  Open up postman and create a new request then paste in the URL you copied earlier from your webhook in integromat. Change the dropdown beside your URL from <strong>GET</strong> to <strong>POST</strong>.  Finally: </p><ul><li>click the â€œBodyâ€� tab</li><li>click the â€œrawâ€� option</li><li>Select â€œJSONâ€� from the dropdown on the right</li><li>paste in the following to the large textarea:</li></ul><pre><code>{
  "restaurant": "My Favourite Restaurant"
}
</code></pre><p>Your Postman Screen should look something like this:</p><p><img src="https://www.martinmck.com/images/Screenshot%202020-06-20%20at%2015.25.40.png"></p><p>Click the blue â€œSendâ€� button to send your HTTP request and interact with your integromat webhook.</p><p>Back in integromat, you will see a message telling you that the shape of your data has been successfully determined. Letâ€™s store it in our spreadsheet!</p><h3>Google Sheets</h3><p>In order to update our google sheet, we need to check whether or not a row for the restaurant already exists before either updating the vote count by one or creating a new row. Hereâ€™s a reminder of our steps to save you scrolling:</p><ul><li>Check if a row exists with the restaurant name we sent in our JSON data</li><li>If it doesnâ€™t exist, create a new row in our spreadsheet</li><li>If it exists, update that restaurants vote count by 1</li></ul><h4>Searching For An Existing Row</h4><p>Letâ€™s set up the google sheets module in integromat to search for a row. Click your webhook module and click the plus button to creae a new module in your integromat scenario. </p><ul><li>Search for â€œgoogle sheetsâ€� in the search bar, click it </li><li>Select the â€œSearch Rowsâ€� module.</li></ul><p><img src="https://www.martinmck.com/images/Screenshot%202020-06-20%20at%2021.52.04.png"></p><p>To configure your search rows module, you need to authenticate integromat with your google account by adding your google account connection. Once you have done that, then select your Lunch Voter spreadsheet and sheet.</p><p>Finally, set up your filter. This is how integromat will search your google sheet to check if a restaurant already exists. We want to check if any value in column <strong>A</strong> matches the data we are passing to our API. Your module setup should look like the following:</p><p><img src="https://www.martinmck.com/images/Screenshot%202020-06-20%20at%2021.05.59.png"></p><p>Click OK when done.</p><h4>If This, Then That</h4><p>Now to move on to the next step, which is to perform one action if the restaurant exists, or another if it doesnâ€™t. In order to do that in integromat, we must use a <strong>router</strong>. A router is basically a fork in the road, where you can perform 2 different actions …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.martinmck.com/posts/what-is-an-api-learn-by-building-one-without-code/">https://www.martinmck.com/posts/what-is-an-api-learn-by-building-one-without-code/</a></em></p>]]>
            </description>
            <link>https://www.martinmck.com/posts/what-is-an-api-learn-by-building-one-without-code/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23625373</guid>
            <pubDate>Wed, 24 Jun 2020 08:03:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don’t Fly During Ramadan (2013)]]>
            </title>
            <description>
<![CDATA[
Score 172 | Comments 101 (<a href="https://news.ycombinator.com/item?id=23625215">thread link</a>) | @luu
<br/>
June 24, 2020 | https://adityamukerjee.net/2013/08/22/dont-fly-during-ramadan/ | <a href="https://web.archive.org/web/*/https://adityamukerjee.net/2013/08/22/dont-fly-during-ramadan/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>A couple of weeks ago, I was scheduled to take a trip from New York (JFK) to Los Angeles on JetBlue. Every year, my family goes on a one-week pilgrimage, where we put our work on hold and spend time visiting temples, praying, and spending time with family and friends. To my Jewish friends, I often explain this trip as vaguely similar to the <a href="https://en.wikipedia.org/wiki/Sabbath" target="_blank" rel="noopener">Sabbath</a>, except we take one week of rest per year, rather than one day per week.</p>
<p>Our family is not Muslim, but by coincidence, this year, our trip happened to be during the last week of <a href="https://en.wikipedia.org/wiki/Ramadan" target="_blank" rel="noopener">Ramadan</a>.</p>
<p>By further coincidence, this was <em>also</em> the same week that I was moving out of my employer-provided temporary housing (at NYU) and moving into my new apartment. The night before my trip, I enlisted the help of two friends and we took most of my belongings, in a couple of suitcases, to my new apartment. The apartment was almost completely unfurnished – I planned on getting new furniture upon my return – so I dropped my few bags (one containing an air mattress) in the corner. Even though I hadn’t decorated the apartment yet, in accordance with Hindu custom, I taped a single photograph to the wall in my bedroom — a long-haired saint with his hands outstretched in <em><a href="https://www.google.com/search?q=pronam&amp;source=lnms&amp;tbm=isch&amp;sa=X&amp;ei=fR8WUre0GIG28wSH94DwCw&amp;ved=0CAcQ_AUoAQ&amp;biw=1046&amp;bih=733" target="_blank" rel="noopener">pronam</a></em> (a sign of reverence and respect).</p>
<p>The next morning, I packed the rest of my clothes into a suitcase and took a cab to the airport. I didn’t bother to eat breakfast, figuring I would grab some yogurt in the terminal while waiting to board.</p>
<p>I got in line for security at the airport and handed the agent my ID. Another agent came over and handed me a paper slip, which he said was being used to track the length of the security lines. He said, “just hand this to someone when your stuff goes through the x-ray machines, and we’ll know how long you were in line.’ I looked at the timestamp on the paper: 10:40.</p>
<p>When going through the security line, I opted out (as I always used to) of the millimeter wave detectors. I fly often enough, and have opted out often enough, that I was prepared for what comes next: a firm pat-down by a TSA employee wearing non-latex gloves, who uses the back of his hand when patting down the inside of the thighs.</p>
<p>After the pat-down, the TSA agent swabbed his hands with some cotton-like material and put the swab in the machine that supposedly checks for explosive residue. The machine beeped. “We’re going to need to pat you down again, this time in private,” the agent said.</p>
<p>Having been selected before for so-called “random” checks, I assumed that this was another such check.</p>
<p>“What do you mean, ‘in private’? Can’t we just do this out here?”</p>
<p>“No, this is a different kind of pat-down, and we can’t do that in public.” When I asked him why this pat-down was different, he wouldn’t tell me. When I asked him specifically why he couldn’t do it in public, he said “Because it would be obscene.”</p>
<p>Naturally, I balked at the thought of going somewhere behind closed doors where a person I just met was going to touch me in “obscene” ways. I didn’t know at the time (and the agent never bothered to tell me) that the TSA has a policy that requires two agents to be present during every private pat-down. I’m not sure if that would make me feel more or less comfortable.</p>
<p>Noticing my hesitation, the agent offered to have his supervisor explain the procedure in more detail. He brought over his supervisor, a rather harried man who, instead of explaining the pat-down to me, rather rudely explained to me that I could either submit immediately to a pat-down behind closed-doors, or he could call the police.</p>
<p>At this point, I didn’t mind having to leave the secure area and go back through security again (this time not opting out of the machines), but I didn’t particularly want to get the cops involved. I told him, “Okay, fine, I’ll leave”.</p>
<p>“You can’t leave here.”</p>
<p>“Are you detaining me, then?” I’ve been through enough “<a href="https://www.flexyourrights.org/" target="_blank" rel="noopener">know your rights</a>” training to know how to handle police searches; however, TSA agents are not law enforcement officials. Technically, they don’t even have the right to detain you against your will.</p>
<p>“We’re not detaining you. You just can’t leave.” My jaw dropped.</p>
<p>“Either you’re detaining me, or I’m free to go. Which one is it?” I asked.</p>
<p>He glanced for a moment at my backpack, then snatched it out of the conveyor belt. “Okay,” he said. “You can leave, but I’m keeping your bag.”</p>
<p>I was speechless. My bag had both my work computer and my personal computer in it. The only way for me to get it back from him would be to snatch it back, at which point he could simply claim that I had assaulted him. I was trapped.</p>
<p>While we waited for the police to arrive, I took my phone and quickly tried to call my parents to let them know what was happening. Unfortunately, my mom’s voicemail was full, and my dad had never even set his up.</p>
<p>“Hey, what’s he doing?” One of the TSA agents had noticed I was touching my phone.<br>
“It’s probably fine; he’s leaving anyway,” another said.</p>
<p>The cops arrived a few minutes later, spoke with the TSA agents for a moment, and then came over and gave me one last chance to submit to the private examination. “Otherwise, we have to escort you out of the building.” I asked him if he could be present while the TSA agent was patting me down.</p>
<p>“No,” he explained, “because when we pat people down, it’s to lock them up.”</p>
<p>I only realized the significance of that explanation later. At this point, I didn’t particularly want to miss my flight. Foolishly, I said, “Fine, I’ll do it.”</p>
<p>The TSA agents and police escorted me to a holding room, where they patted me down again – this time using the front of their hands as they passed down the front of my pants. While they patted me down, they asked me some basic questions.</p>
<p>“What’s the purpose of your travel?”</p>
<p>“Personal,” I responded, (as opposed to business).</p>
<p>“Are you traveling with anybody?”</p>
<p>“My parents are on their way to LA right now; I’m meeting them there.”</p>
<p>“How long is your trip?”</p>
<p>“Ten days.”</p>
<p>“What will you be doing?”</p>
<p>Mentally, I sighed. There wasn’t any other way I could answer this next question.</p>
<p>“We’ll be visiting some temples.” He raised his eyebrow, and I explained that the next week was a religious holiday, and that I was traveling to LA to observe it with my family.</p>
<p>After patting me down, they swabbed not only their hands, but also my backpack, shoes, wallet, and belongings, and then walked out of the room to put it through the machine again. After more than five minutes, I started to wonder why they hadn’t said anything, so I asked the police officer who was guarding the door. He called over the TSA agent, who told me,</p>
<p>“You’re still setting off the alarm. We need to call the explosives specialist”.</p>
<p>I waited for about ten minutes before the specialist showed up. He walked in without a word, grabbed the bins with my possessions, and started to leave. Unlike the other agents I’d seen, he wasn’t wearing a uniform, so I was a bit taken aback.</p>
<p>“What’s happening?” I asked.</p>
<p>“I’m running it through the x-ray again,” he snapped. “Because I can. And I’m going to do it again, and again, until I decide I’m done”. He then asked the TSA agents whether they had patted me down. They said they had, and he just said, “Well, try again”, and left the room. Again I was told to stand with my legs apart and my hands extended horizontally while they patted me down all over before stepping outside.</p>
<p>The explosives specialist walked back into the room and asked me why my clothes were testing positive for explosives. I told him, quite truthfully, “I don’t know.” He asked me what I had done earlier in the day.</p>
<p>“Well, I had to pack my suitcase, and also clean my apartment.”</p>
<p>“And yesterday?”</p>
<p>“I moved my stuff from my old apartment to my new one”.</p>
<p>“What did you eat this morning?”</p>
<p>“Nothing,” I said. Only later did I realize that this made it sound like I was fasting, when in reality, I just hadn’t had breakfast yet.</p>
<p>“Are you taking any medications?”</p>
<p>The other TSA agents stood and listened while the explosives specialist and asked every medication I had taken “recently”, both prescription and over-the-counter, and asked me to explain any medical conditions for which any prescription medicine had been prescribed. Even though I wasn’t carrying any medication on me, he still asked for my complete “recent” medical history.</p>
<p>“What have you touched that would cause you to test positive for certain explosives?”</p>
<p>“I can’t think of anything. What does it say is triggering the alarm?” I asked.</p>
<p>“I’m not going to tell you! It’s right here on my sheet, but I don’t have to tell you what it is!” he exclaimed, pointing at his clipboard.</p>
<p>I was at a loss for words. The first thing that came to my mind was, “Well, I haven’t touched any explosives, but if I don’t even know what chemical we’re talking about, I don’t know how to figure out why the tests are picking it up.”</p>
<p>He didn’t like this answer, so he told them to run my belongings through the x-ray machine and pat me down again, then left the room.</p>
<p>I glanced at my watch. Boarding would start in fifteen minutes, and I hadn’t even had anything to eat. A TSA officer in the room noticed me craning my neck to look at my watch on the table, and he said, “Don’t worry, they’ll hold the flight.”</p>
<p>As they patted me down for the fourth time, a female TSA agent asked me for my baggage claim ticket. I handed it to her, and she told me that a woman from JetBlue corporate security needed to ask me some questions as well. I was a bit surprised, but agreed. After the pat-down, the JetBlue representative walked in and cooly introduced herself by name.</p>
<p>She explained, “We have some questions for you to determine whether or not you’re permitted to fly today. Have you flown on JetBlue before?”</p>
<p>“Yes”</p>
<p>“How often?”</p>
<p>“Maybe about ten times,” I guessed.</p>
<p>“Ten what? Per month?”</p>
<p>“No, ten times total.”</p>
<p>She paused, then asked,</p>
<p>“Will you have any trouble following the instructions of the crew and flight attendants on board the flight?”</p>
<p>“No.” I had no idea why this would even be in doubt.</p>
<p>“We have some female …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://adityamukerjee.net/2013/08/22/dont-fly-during-ramadan/">https://adityamukerjee.net/2013/08/22/dont-fly-during-ramadan/</a></em></p>]]>
            </description>
            <link>https://adityamukerjee.net/2013/08/22/dont-fly-during-ramadan/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23625215</guid>
            <pubDate>Wed, 24 Jun 2020 07:43:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PostgreSQL Query JIT]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23624751">thread link</a>) | @kureikain
<br/>
June 23, 2020 | https://solovyov.net/blog/2020/postgresql-query-jit/ | <a href="https://web.archive.org/web/*/https://solovyov.net/blog/2020/postgresql-query-jit/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="articleBody">
  <p>We’re proud users of PostgreSQL. Proud in a sense we’re really glad that our main data store is such a stable, performant, introspective, and overall great DBMS. It’s been very reliable for us and in times of turbulence made it possible to understand what the issue is. Overall, I love it.</p>

<p>We were on 10.x since ages - upgraded a month after it came out. We did a regular old school upgrade using <code>pg_upgrade</code>. You see, one of PG traits is that on-disk data layout is different between major versions. That means that version 10 can’t work with data from version 9 (and vice versa) and you have to convert the data to run a new version. It’s a PITA but gives you time to test and see if everything is okay, etc.</p>

<p>But when 11th came out something stopped us from upgrading (I don’t remember what). Plus around that time we started using <a href="https://www.2ndquadrant.com/en/resources/pglogical/">pglogical</a> for a purpose of having, for example, an analytical replica. Or a partial replica to speed up something. And our idea of the next major upgrade was to use logical replication to copy data from our main db to the new node with newer PostgreSQL. It’s one of the cool features of logical replication - you can replicate data between nodes with different major versions.</p>

<p>Then pg12 came out. It was a great (as always) release, with a lot of performance improvements (CTE is not an optimization fence anymore, woohoo!), plus JIT was improved and enabled by default, and some new exciting features (jsonpath anyone?). And we’re experienced users of logical replication now.</p>

<p>It is time to upgrade then, right? Not so fast, amigo. 2ndQuadrant, authors of pglogical, had some problems with rolling out new release for pg12. I don’t know details here, but after some time they figured stuff out and February saw release of pglogical 2.3.</p>

<p>Cool! So after weeks of preparation on one uneventful (so far) night of 16th of April, a designated person did a migration. Well, a migration was done by logical replication before, so he switched pgbouncer to the new main db.</p>

<p>As a logical (heh) consequence of that - we did not really test pg12 on production traffic. Is that because of blind faith? Or laziness? It’s a hard question.</p>

<p>For some time everything was normal. New PostgreSQL, running smoothly, yada-yada-yada. And then the traffic came. It wasn’t even some peak sale or anything. Our daily campaigns start at 6:00, so that’s the start of the day for the site. Right at 6:00 pg started to feel unwell.</p>

<p>At 6:40, when I was woken up, site barely moved. We tracked slowdown to a very popular query, which selected a user from db: it was executed on every request which required authentication.</p>

<p>And what was wrong? Query plan for this query was so wildly weird that we’ve tried to use our intuition first and just disabled non-critical parts which we knew were heavy. This improved our mean API timings from 10s to 5s. Which is still strictly in “site is unresponsive” category.</p>

<p>Okay, back to investigation. Explain for that query was the same as on pg10, but explain analyze said that 12.9s of 13s of execution (API timings are lower because of caches) are spent on joining <code>auth_user</code> and <code>user_userprofile</code>. We’re an ex-Django site and that means some peculiarities in database design. For example, having a table called <code>product_product</code>, or that stuff where <code>auth_user</code> is a table about users and <code>user_userprofile</code> is about users data. So the interesting part of the query plan looks like this:</p>

<pre><code>-&gt;  Nested Loop  (cost=0.86..12.89 rows=1 width=310) (actual time=13708.286..13708.290 rows=1 loops=1)
      -&gt;  Index Scan using auth_user_pkey on auth_user u  (cost=0.43..6.44 rows=1 width=97) (actual time=0.108..0.108 rows=1 loops=1)
            Index Cond: (id = 7002298)
      -&gt;  Index Scan using user_userprofile_user_id_key on user_userprofile p  (cost=0.43..6.44 rows=1 width=217) (actual time=0.087..0.088 rows=1 loops=1)
            Index Cond: (user_id = 7002298)
</code></pre>

<p>What is the magic here? How does <code>0.08 + 0.1</code> results in <code>13708</code>? Is this the real life or is this just fantasy? We’ve spent half an hour pondering on that question until <a href="https://vsevolod.net/">Vsevolod</a> woke up and told me there is a JIT report at the end of the query plan:</p>

<pre><code> Planning Time: 2.515 ms
 JIT:
   Functions: 138
   Options: Inlining true, Optimization true, Expressions true, Deforming true
   Timing: Generation 108.775 ms, Inlining 888.683 ms, Optimization 7700.314 ms, Emission 5091.838 ms, Total 13789.610 ms
 Execution Time: 13821.487 ms
</code></pre>

<p>I blame this on both being too sleepy (being woken up in the wrong sleep phase is a pain) and having absolutely zero experience with JIT. Somehow this <code>Optimizations</code> word has captured my attention and I’ve spent quite a bit of time reading up on new optimizations in PostgreSQL and how to disable them. No idea why <code>Emission</code> did not have my attention - I guess its time just didn’t come yet. :-)</p>

<p>JIT got disabled. API response timings dropped from 5s to whatever they are normally. Things went back to usual state.</p>

<h2>Reasons</h2>

<p>Discussion on <a href="https://lobste.rs/s/r6ydjp/postgresql_query_jit">lobste.rs</a> was coming to a conclusion that 14 seconds is too much for a JIT and maybe we triggered some bug in PostgreSQL. So I went up to reproduce this, but with more verbose query plan (literally <code>explain (analyze, verbose, buffers) ...</code>). And got this:</p>

<pre><code> Planning Time: 2.240 ms
 JIT:
   Functions: 101
   Options: Inlining false, Optimization false, Expressions true, Deforming true
   Timing: Generation 13.719 ms, Inlining 0.000 ms, Optimization 3.280 ms, Emission 83.755 ms, Total 100.753 ms
 Execution Time: 102.812 ms
</code></pre>

<p>My first reaction was of course “argh it fixed itself or what?!” But then it hit me: this is one of the most frequent queries in our database and JIT adding 100 ms of CPU time (because just in time compilation for sure is not some I/O wait) put such a massive load on our CPUs that eventually that 100 ms went up to being 14 seconds.</p>

<h2>Conclusion</h2>

<p>We should have tested more. Also, we need more monitoring to see that one query became too slow. I’ve been thinking that not skipping PG11 would’ve helped to test JIT and identify this issue early. OTOH it seems it wasn’t that straightforward to enable.</p>

<p>With all that said, I can’t shake off the feeling that JIT being enabled by default is a bit too early.</p>

  </section></div>]]>
            </description>
            <link>https://solovyov.net/blog/2020/postgresql-query-jit/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23624751</guid>
            <pubDate>Wed, 24 Jun 2020 06:29:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Good Ideas, Through the Looking Glass  (2005) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23624575">thread link</a>) | @peter_d_sherman
<br/>
June 23, 2020 | https://people.inf.ethz.ch/wirth/Articles/GoodIdeas_origFig.pdf | <a href="https://web.archive.org/web/*/https://people.inf.ethz.ch/wirth/Articles/GoodIdeas_origFig.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://people.inf.ethz.ch/wirth/Articles/GoodIdeas_origFig.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-23624575</guid>
            <pubDate>Wed, 24 Jun 2020 05:58:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Going for a 100% Lighthouse Score? Read this]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23624555">thread link</a>) | @arunoda
<br/>
June 23, 2020 | https://arunoda.me/blog/lighthouse-syndrome?on=hn | <a href="https://web.archive.org/web/*/https://arunoda.me/blog/lighthouse-syndrome?on=hn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://arunoda.me/blog/lighthouse-syndrome?on=hn</link>
            <guid isPermaLink="false">hacker-news-small-sites-23624555</guid>
            <pubDate>Wed, 24 Jun 2020 05:56:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Go Out]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23624176">thread link</a>) | @patwalls
<br/>
June 23, 2020 | https://patwalls.com/go-out | <a href="https://web.archive.org/web/*/https://patwalls.com/go-out">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://patwalls.com/go-out</link>
            <guid isPermaLink="false">hacker-news-small-sites-23624176</guid>
            <pubDate>Wed, 24 Jun 2020 04:42:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Staring into the COM Abyss]]>
            </title>
            <description>
<![CDATA[
Score 76 | Comments 66 (<a href="https://news.ycombinator.com/item?id=23623994">thread link</a>) | @todsacerdoti
<br/>
June 23, 2020 | https://cmpct.info/~calvin/Articles/COMAbyss/ | <a href="https://web.archive.org/web/*/https://cmpct.info/~calvin/Articles/COMAbyss/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
		
		<p>
			If you're aware of how software is developed on Windows, chances are you're eventually going to run into COM. While Windows exposes some simple C APIs (and these APIs were much better than its contemporaries like Toolbox, X, or Intuition), pretty much anything more complex than USER32 is exposed through COM interfaces, from Internet Explorer to DirectX. COM is also used to <em>extend</em> applications too: Office, Visual Studio, even the Windows shell provide COM interfaces to applications to hook into. Microsoft loves using COM for everything in Windows, even if third-parties don't like it as much (Usually, out of portability/complexity reasons.). Using COM to its full extent can <a href="https://www.joelonsoftware.com/2009/09/23/the-duct-tape-programmer/">make your application 34% sparklier</a>, but it's a lot of work to properly use those interfaces (and there's a lot of them!).
		</p>
		<p>
			Unfortunately not many were able to take advantage of COM, let alone in more obscure scenarios such as extending the shell. The people who could do so were quite rare, as Spolsky pointed out. Naturally, I was <a href="https://xkcd.com/356/">nerd sniped</a> by a friend to write a <a href="https://docs.microsoft.com/en-us/windows/win32/shell/nse-works">shell namespace extension</a>, one of the more obscure (little documentation, few did it, few know they exist) categories of COM extension. A shell namespace extension adds a "namespace" (basically virtual folder) to the shell, which has further objects represented in it. Common use cases for them include MTP for phones, inline ZIP file viewing, etc.
		</p>
		<p>
			My extension was simple enough I thought I could implement it (and I did... with difficulty, as you'll see) myself. It would enumerate all the open Windows Explorer windows, and put links to them in a namespace. The point of this is that this was accessible from the stock system file dialogs, which is useful if you have a bunch of Explorer windows open, but want to save to one of them quickly. This was inspired by an OS/2 Workplace Shell feature (the one good feature of OS/2!). The challenge was going from a bare minimum knowledge of COM to knowing just enough to be <del>dangerous</del> able to make a shell namespace extension that works.
		</p>
		<img src="https://cmpct.info/~calvin/Articles/COMAbyss/os2-version.jpg" alt="The OS/2 feature" title="The OS/2 feature">
		<h2>A Brief Primer on COM</h2>
		<p>
			For something with a near-legendary reputation of complexity, it turns out COM is actually based on some very simple primitives. COM is based on interfaces (in the C++ manner) that implement vtables (a structure full of functions). These interfaces have a fixed shape, so they can be used from C. Every COM class implements the interface <code>IUnknown</code>, which implements three functions:
		</p>
		<ul>
			<li><code>AddRef</code>, which increments the reference count. Every COM object is reference counted, so you'll use this when you make a copy of a held-on reference.</li>
			<li><code>Release</code>, which decrements the reference count. The object frees itself when the count hits zero.</li>
			<li><code>QueryInterface</code>, which gives you the vtable of another interface if the object implements it (casting). The interfaces are identified by a GUID.</li>
		</ul>
		<p>
			This isn't so bad. Of course, objects can implement a <em>lot</em> of interfaces, and because interfaces have a fixed shape, to extend an interface later, you have to create another interface. Microsoft ends up numbering them, so you get into situations where you have an <a href="https://docs.microsoft.com/en-us/windows/win32/api/shobjidl_core/nn-shobjidl_core-ishellfolder2"><code>IShellFolder2</code></a>. And as Microsoft implements more features that require more interfaces, a class can get unwieldy if you're not careful. And then you have to assume the interfaces are well documented! And for extensibility, debugging isn't (as far as I'm aware) very great beyond printf macros.
		</p>
		<p>
			COM classes are registered (that's what REGSVR32 is for), where they become known by other applications. A <a href="https://docs.microsoft.com/en-us/windows/win32/midl/com-dcom-and-type-libraries">type library</a> provides metadata, and is usually generated by an IDL file.
		</p>
		<p>
			While you can use COM from C, it can get a bit unwieldy, because COM benefits from an environment of RAII and scoped destructors. ATL provides a template-based wrapper around COM for C++, and is what Microsoft recommends for COM development. Visual Studio greatly assists in terms of generating the boilerplate for categories of COM classes.
		</p>
		<h2>Do You Eat Your Burgers With or Without the Shell?</h2>
		<p>
			The beautiful part of Windows is how extensible it is. The ugly part of Windows is how no one can extend it properly. Trying to write a shell namespace extension from scratch is a Sisyphean endeavour. I don't think anyone's done it. Instead, you have to do things like your average Windows programmer in 2002 would have done - read someone much smarter than you's <a href="https://www.codeproject.com/Articles/1649/The-Complete-Idiot-s-Guide-to-Writing-Namespace-Ex">article on CodeProject</a>, the site people copied and pasted from <em>before</em> Stack Overflow. His examples are helpful, but they have a critical flaw - they implement the list view on their own, instead of delegating out to the interface which handles using the stock one and its default behaviours for you. (For example, the example will crash on XP and newer because it doesn't handle the new ListView views.) Insightful, but back to the drawing board.
		</p>
		<p>
			Round two. The <a href="https://www.codeproject.com/Articles/7973/An-almost-complete-Namespace-Extension-Sample">example by Pascal Hurni</a> is while slightly rougher, closer to what we want. His example uses the system ShellView, which gives you default behaviours and the ability to use it from a stock file dialog, which is what we want. The example enumerates through the registry (specifically, favourites for the file manager <a href="https://www.gpsoft.com.au/">Directory Opus</a>) and represents real filesystem entities, which is close to what we want - just swap out the enumerator.
		</p>
		<p>
			I took some code I wrote for experimenting with actually listing Explorer windows. First I thought I'd have to enumerate all visible windows and filter on <code>CabinetWClass</code>, then figure out what messages to send to it in order to get useful information out, but it turns out an easier way was possible through COM. You create an instance of <code>IShellWindows</code>, then call <code>get_Count</code> and <code>Item</code>, which returns an <code>IDispatch</code> representing your window. <code>IDispatch</code> is essentially <code>IUnknown</code> with reflection, intended for situations like VBA where you want to enumerate methods and properties. We can cast it to an <code>IWebBrowser</code> (a remnant of when Internet Explorer and Windows Explorer were welded together), and get the location from there. Grafting it onto Pascal's example (and ripping out what code I didn't need for clarity), I had a working MVP (with bugs, of course)
		</p>
		<img src="https://cmpct.info/~calvin/Articles/COMAbyss/explorer-windows.png" alt="Windows XP, opened Explorer windows" title="Windows XP, opened Explorer windows">
		<h2>PIDLy Details</h2>
		<p>
			I <del>cargo-culted (first step of learning)</del> learned some things about the shell, and there's still a lot more I don't know about. Tip of the iceberg as follows:
		</p>
		<ul>
			<li>A PIDL is basically an ID used by Explorer to represent items, since entities may not have real FS representation. A PIDL is basically a free-form struct that has what you want tagged with its size, and what your NSE will use to identify items. They can be absolute or relative (where it only matters to you), like a path.</li>
			<li>It likes to request wrapped PIDLs in the form of <code>IDataObject</code>, one of those can-contain-anything OLE structures usually used for the clipboard.</li>
			<li>Namespaces can be registered at a <em>junction point</em>, which makes it accessible from places other than making a shortcut to its CLSID (GUID). There's also some ceremony in registering the namespace at all; there's a registry resource script that gets called whenever the DLL is registered to make it easier. Some information on creating namespaces (but from a customizer's perspective, so pointing it at existing locations) and making it known in places is available <a href="http://virtualplastic.net/html/ui_shell.html">here</a>.</li>
			<li>Some software (cough, Office) requires an NSE represent a real location before it'll show it. The example works around this by using the temporary directory as a physical manifestation. This can result in weird behaviour, but it's the price to pay to have it work.</li>
			<li>Late in XP's lifecycle and especially Vista, Microsoft extended the column scheme to have property keys. These represent metadata more faithfully, can be extended, and is actively used for search. Namespace extensions can of course, implement these. However, it's not clear on what's the bare minimum you implement to get things like tile view subtitles working. You're almost led to believe you need an <code>IPropertyStore</code> and XML file representing custom metadata columns, but I was seemingly lucky enough I could just use built-in property keys and (I believe) the real filesystem entities have their metadata fill in. I just had to map the (most; I didn't notice anything bad from not mapping everything) column IDs I was using to the system included property keys and handle the property keys that resolve to other property keys for what to display on tiles and such.</li>
		</ul>
		<p>
			The real sad part is for things like this, because the documentation is so lacking/missing, is that you may run into issues where not even Stack Overflow can help you. Experimentation or blind trust in ancient Usenet posts may be required. Or maybe you can be lucky enough to know someone who was there, remembers, and still cares. Remember, not many at the time knew how to use these effectively, and the number of people who do dwindles, to a point of extinction, another point to the <a href="https://www.devever.net/~hl/windowsdefeat">cultural defeat of Windows</a>.
		</p>
		<p>
			I also found <a href="https://www.viksoe.dk/code/regfolder.htm">someone who implemented a wrapper class library and a bunch of samples around them</a>, which probably would be handy if I didn't discover it <em>after</em> actually managing to make it. It might have been useful, but it does a lot for you, so perhaps it was for the best to understand how the shell/COM works at a lower level.
		</p>
		<h2>IActuallyDidIt2</h2>
		<p>
			I managed to actually write the extension. It's available <a href="https://github.com/NattyNarwhal/OpenWindows">on GitHub</a>, and I hope it provides a clearer example of a shell namespace extension (since you're likely not going to find many, let alone many who know it) as well as be useful to Explorer freaks. I had also contacted Pascal about the licensing ambiguities (since people just did open source in Windows circles by the edge of their seats back then) - it's MIT licensed for sure. Now you know how the ISausage is made, and it is delicious - if only people could figure out the best way to eat it.
		</p>
		<img src="https://cmpct.info/~calvin/Articles/COMAbyss/save-dialog.png" alt="Windows Vista, save dialog" title="Windows Vista, save dialog">
	

</div>]]>
            </description>
            <link>https://cmpct.info/~calvin/Articles/COMAbyss/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23623994</guid>
            <pubDate>Wed, 24 Jun 2020 04:08:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[From English Major to Software Engineer]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 3 (<a href="https://news.ycombinator.com/item?id=23623709">thread link</a>) | @breyerjs
<br/>
June 23, 2020 | https://www.jacksonbreyer.com/words/from-english-major-to-software-engineer | <a href="https://web.archive.org/web/*/https://www.jacksonbreyer.com/words/from-english-major-to-software-engineer">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="__next"><div><div><div><h4>What's This?</h4><p>I studied English as an undergraduate, but since then I've taken an untraditional path into software engineering. Years later, I'm working as an Engineering Manager at Yelp. </p><p>I've heard everything from curiosity to outright scorn when people learn my background. </p><p>I'm writing for the curious, to share how I changed from one career to a very different one. I'm also writing for those who are considering a similar jump. Hopefully my story sheds some light on the road ahead.</p><h4>English Major</h4><p>I majored in English for the usual reasons. I like reading, writing, diagramming sentences, and picking apart complex narratives. I wanted to learn more about those things. And at eighteen years old, I was not particularly concerned about the future.</p><p>As graduation approached, I realized that in order to make money, I would need a job. So which job?</p><h4>Law</h4><p>Law seemed like a good fit. It's meaningful and interesting work. There is plenty of reading, writing, and picking apart complex narratives.</p><p>But becoming a lawyer means law school, which is expensive and itself requires the LSAT. And the LSAT takes months of study in order to do well. I needed time to scope out the industry before committing all that money. </p><p>So I became a paralegal. I worked at Cadwalader, Wickersham, and Taft (CWT), which is a very old, very large, and very traditional law firm. If you've heard of BigLaw, that's CWT.</p><p>I had a productive first year at CWT. I got the LSAT score I needed, I secured some strong recommendations, and I feel like I got an excellent window into the industry. </p><p>After all that, I was dismayed to admit: I didn't want to be a lawyer. While I liked many of the people I met at CWT, the lifestyle of the profession didn't appeal to me at all.</p><p>As someone who self-identifies as "quirky" at minimum, I felt like I would need to drastically alter my personality to suit the profession. Even more frightening: I thought I might be capable of doing that. What a terrible fate.</p><p>Back to square one. My paralegal job felt like a dead-end and law school felt like an expensive mistake. What to do?</p><h4>Learn Everything</h4><p>While continuing on as a paralegal, I tried to learn everything I could about other industries. Maybe one of them would stand out.</p><p>After a few months, my friend said to me: "You like linguistics, right? How about you try programming in Python. There are lots of cool linguistic applications for Python programming." </p><p>I'd never programmed before, but...sure. Why not? </p><p>So at 23-years-old, I wrote my first line of code. And let me tell you, when I saw "hello world" printed in the terminal, it was glorious. </p><p>Silly as it was, I was drunk with power. I could make the computer print out <em>anything</em>. In a strange way, I found programming similar to the creative / logical act of sentence diagramming, which I loved. So I was hooked. I started spending all of my free time programming. </p><h4>Learn Programming</h4><p>There were several initial hurdles to overcome. What curriculum would I follow? What language should I learn? Heck, what editor should I use to write code and where could I even execute it?</p><p>I imagine these things are obvious to someone who goes to school for Computer Science. But I was sitting at home with just the internet and a few spare hours. Fortunately, I had two great resources. </p><p>First, my programmer friends. I'm sure they got sick of my endless questions, but their help was invaluable. Working on your own, it's easy to get lost in StackOverflow posts and wind up dismayed. My friends kept me on track and cleared up a lot of confusing points. ("What's a constructor function?" "What's a list comprehension?") </p><p>Second, I found a fantastic e-book called <a href="https://inventwithpython.com/invent4thed/">Invent Your Own Computer Games With Python</a>. It's targeted at an audience...much younger than I was. As a result, the writing is exceptionally clear and simple. Perfect for an absolute beginner with limited guidance. </p><p>Armed with these tools, I wrote <em>lots</em> of sloppy, beginner-style programs. My crowning glory was a dinky chatbot that had hard-coded responses to common phrases. Success was just around the corner.</p><p>Except it wasn't.</p><p>I sent out a blizzard of internship applications, and every single one was rejected. It was a seemingly endless stream: rejection after rejection after rejection. I even got rejected from Yelp, where I currently work.</p><p>Around this time, a well-meaning acquaintance told me that I should give up trying to be a software engineer. It was too hard, there was too much math, and didn't I know? Software Engineers were <em>really</em> smart.  </p><p>Boy did that make me mad. I'm still mad, just thinking about it. </p><p>Any thoughts I had of giving up were promptly sidelined. I was <em>sure</em> I could break into the industry, given enough time. Maybe I needed more education.</p><h4>What Sort of Education?</h4><p>By whatever fortune, during that period I was blessed with clarity of vision. I was going to be a software engineer, full stop. I wanted to build the foundation for my life's professional work.</p><p>Around this time, programming bootcamps had become very popular. I spent a long time weighing them against a traditional graduate school.</p><p>It's easy to understand bootcamps' appeal. They teach you industry-relevant skills, they help you apply for jobs, and they promise to help you shift careers at supersonic speed: often in just a few months. </p><p>I thought for a long time about enrolling in a bootcamp. But, for whatever reason, it seemed risky. </p><p>Maybe it was the horror stories about poorly-run bootcamps. Maybe it was a personal bias towards traditional education. Maybe it was the impression I got online, that companies looked down on bootcamp graduates. Or a worry that I'd miss out on theoretical aspects of Computer Science. </p><p>Switching careers already felt risky, and I was desperate to reduce uncertainty. Bootcamps were out.</p><p>I've met many bootcamp graduates since then, most of them highly driven and intelligent. Some have found success, some not. </p><p>It's worth acknowledging that I enjoy several privileges which made it possible for me to quit my job and spend two years in grad school. I am very fortunate in that respect, and very grateful.</p><h4>Applying to Grad School</h4><p>Applying to grad school was pretty straightforward. The GRE felt like a piece of cake after the LSAT. I just needed to relearn high-school math (English major, remember?). </p><p>Few schools would accept me without a bachelor's in Computer Science. So that narrowed the field for me, in some ways a blessing. I applied to about five schools.</p><p>Of those, Brandeis was my top pick. There, I could take remedial undergraduate classes while I did my Master's. And they had a strong Computational Linguistics program to boot.</p><p>My background actually made parts of the application very easy. Writing a personal statement? No problem. Verbal portion of the GRE? Forget about it. </p><p>After submitting the applications, I took a mid-summer trip to Boracay, a remote island in the Philippines. I ducked in from the white-sand beach to check my email and found out that Brandeis had accepted me. Despite all the surf and sun, I could only dream of Boston in winter.</p><h4>First Year at Brandeis</h4><p>Brandeis was as great as Boston was cold.</p><p>I spent my time learning Computer Science, surrounded by intelligent people who had similar interests. It was like paradise.</p><p>Except for Discrete Math, that is. Everyone's got that one class where they struggle. But even tougher than the material was the imposter syndrome I felt as a result. It was my first semester and, heck, I was just an English major. If I was already struggling, maybe I didn't belong in a Computer Science program? Surely I'd be exposed as a fraud.</p><p>In the end, I managed to scrape out a hard-won B+. And boy was I grateful. I won't say it fully alleviated my imposter syndrome, but it was a good start.</p><p>There were high points too. Like the few Computational Linguistics classes I managed to sneak in. Boy were they fun. Finally I was back to diagramming sentences, but now the computer did it for me.</p><h4>Internship</h4><p>That summer, I was lucky to get an internship with Ginger.io, out in mythical San Francisco. I'd never been to SF, and didn't know much about Ginger.io. But on paper, it was perfect. </p><p>Ginger.io was a small-ish startup, with ~20 engineers. Their goal was to provide mental healthcare to people without the usual means of access—something I'm personally passionate about. </p><p>Their tech-stack was Python-based too. That meshed with the programming I'd done at Brandeis. Finally, <em>this time</em> success was just around the corner.</p><p>Except it wasn't.</p><p>The people at Ginger.io were patient and kind. But, to be frank, I was woefully underprepared. </p><p>I'd done very little collaborative programming. I was somewhat baffled by the command line, and <em>exceptionally</em> baffled by git. I'd never even dreamed of a codebase bigger than a few files. </p><p>It was one of the most difficult periods of my life. I spent much of the summer trying to learn all the things software engineers take for granted—automated testing, development environments, version control, architectural patterns, and so forth. I worked very slowly and I felt like I'd let the team down. It was doubly painful, since I cared deeply about the company's mission.</p><h4>Second Year at Brandeis</h4><p>As difficult as it was, that summer at Ginger.io was transformative for my education. I was determined to be better prepared for the next opportunity.</p><p>Suddenly, it was obvious which courses I should take. It was obvious which modules I needed to pay close attention to. I still managed to take a few Computational Linguistics courses, but I added other electives like Databases and Web Development. </p><p>As the year wound down, I felt vastly more prepared for professional software engineering than I had the previous summer. Letting the challenges of my internship guide my education was one of the most effective things I've done.</p><h4>Interviewing</h4><p>Many people have written about the software industry's interviewing practices. I won't dwell on that, except to say that it ain't no fun.</p><p>The process is long, emotionally fraught, and exhausting. As many as …</p></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.jacksonbreyer.com/words/from-english-major-to-software-engineer">https://www.jacksonbreyer.com/words/from-english-major-to-software-engineer</a></em></p>]]>
            </description>
            <link>https://www.jacksonbreyer.com/words/from-english-major-to-software-engineer</link>
            <guid isPermaLink="false">hacker-news-small-sites-23623709</guid>
            <pubDate>Wed, 24 Jun 2020 03:28:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thank you, next (On gerontocracy: government run by old people)]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23623445">thread link</a>) | @feross
<br/>
June 23, 2020 | https://blog.dcpos.ch/thank-you-next | <a href="https://web.archive.org/web/*/https://blog.dcpos.ch/thank-you-next">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post_body_1527779">
    
      <div><p>A gerontocracy is a government run by old people.<br></p><div><p>Societies are usually run by people in the second half of their lives--people in their 40s, 50s, sometimes 60s. That's normal and healthy. Wisdom and empathy both come from experience. You cross the line into gerontocracy when power concentrates into people in their 70s and beyond.</p></div><div id="posthaven_gallery[1553143]">
          <p>
          <img src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2429868/c-a-Eqb8EAkBswUMGjOmGtmyyEU/medium_Screen_Shot_2020-04-06_at_2.57.02_AM.png" data-posthaven-state="processed" data-medium-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2429868/c-a-Eqb8EAkBswUMGjOmGtmyyEU/medium_Screen_Shot_2020-04-06_at_2.57.02_AM.png" data-medium-width="800" data-medium-height="334" data-large-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2429868/c-a-Eqb8EAkBswUMGjOmGtmyyEU/large_Screen_Shot_2020-04-06_at_2.57.02_AM.png" data-large-width="1200" data-large-height="501" data-thumb-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2429868/c-a-Eqb8EAkBswUMGjOmGtmyyEU/thumb_Screen_Shot_2020-04-06_at_2.57.02_AM.png" data-thumb-width="200" data-thumb-height="200" data-xlarge-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2429868/c-a-Eqb8EAkBswUMGjOmGtmyyEU/xlarge_Screen_Shot_2020-04-06_at_2.57.02_AM.png" data-xlarge-width="1672" data-xlarge-height="698" data-orig-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2429868/c-a-Eqb8EAkBswUMGjOmGtmyyEU/Screen_Shot_2020-04-06_at_2.57.02_AM.png" data-orig-width="1672" data-orig-height="698" data-posthaven-id="2429868">
        </p>
          
        </div>
<p>Historically, gerontocracy has not gone well. The USSR in the early 1980s, China in the 1900s, Austria heading into WW1: if you look around you and the people in charge are all very old, expect turbulence.<br></p><p>The reasons from this range from the poetic to the dry and actuarial.</p><p><b>First, gerontocracy represents a failure of imagination.</b> Time horizons become compressed. It's rare for an 80 year old to start a brand new project. People at that age naturally want to <i>complete</i> some vision. Whatever dissonance they still feel in their own story, they want to see it resolve. They want closure. This is actually a beautiful impulse, but when too much power ends up in the hands of people who are heads-down finishing their final chapter, it sucks the air out of the room and leaves no space for new ideas.<br></p><div><p><b>Second, it represents a process failure.</b> Every society has a process for generational transfer, renewal, some kind of changing of the guard. When the seats of power are filled with people over 75, it's direct evidence that this process has stopped working.</p><p><b>Third, it predicts disruption.</b> Someone who's 40, elected to an 8-year term in office, has a 97% chance of being able to finish.[1] A 60-year-old has a 90% chance. Someone who's 80 today, a coin flip. And those numbers don't count all the other things that can go wrong, short of dying in office. Reagan had Alzheimer's towards the end of his presidency. When those things happen, real decision-making shifts from leaders to other, less publicly accountable people around them. The shift can be gradual and subtle. History shows it to be dangerous.</p></div><p><b>And ultimately, gerontocracy rusts the gears, and government kind of... seizes up.</b><br>
</p><div>
<br>        <div id="posthaven_gallery[1553144]">
          <p>
          <img src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2429869/E6KyYT7Ah7MbBjbnXmzK7QxZ8Vo/medium_Screen_Shot_2020-04-06_at_3.07.10_AM.png" data-posthaven-state="processed" data-medium-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2429869/E6KyYT7Ah7MbBjbnXmzK7QxZ8Vo/medium_Screen_Shot_2020-04-06_at_3.07.10_AM.png" data-medium-width="800" data-medium-height="313" data-large-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2429869/E6KyYT7Ah7MbBjbnXmzK7QxZ8Vo/large_Screen_Shot_2020-04-06_at_3.07.10_AM.png" data-large-width="1200" data-large-height="469" data-thumb-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2429869/E6KyYT7Ah7MbBjbnXmzK7QxZ8Vo/thumb_Screen_Shot_2020-04-06_at_3.07.10_AM.png" data-thumb-width="200" data-thumb-height="200" data-xlarge-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2429869/E6KyYT7Ah7MbBjbnXmzK7QxZ8Vo/xlarge_Screen_Shot_2020-04-06_at_3.07.10_AM.png" data-xlarge-width="1812" data-xlarge-height="708" data-orig-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2429869/E6KyYT7Ah7MbBjbnXmzK7QxZ8Vo/Screen_Shot_2020-04-06_at_3.07.10_AM.png" data-orig-width="1812" data-orig-height="708" data-posthaven-id="2429869">
        </p>
          
        </div>
</div><p>Source: [4], [5]<br>
</p><p>The ability to absorb new information, synthesize, and commit to decisions. The capacity for clear thinking and communication. The executive function to follow through.<br>
</p><div><p>The uncomfortable truth is that each of us will eventually lose those things. When too many leaders hit the steep part of their curve, the organization as a whole loses those capabilities, too. The dysfunction trickles down.</p><p>We're in a difficult moment in America. I collected data about the top positions in our politics over the last 100 years, and it supports what I suspected. <b>Our current political leaders are the oldest we've ever had.</b></p></div><div>
<p>Our president, the house speaker and senate majority leader were all born in the 1940s. Their median age is now 78.<br>
</p></div><div>        <div id="posthaven_gallery[1553141]">
          <p>
          <img src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2429866/rKB1QaWvJajByTQqD7Qt-W1iTrk/medium_Screen_Shot_2020-04-06_at_2.36.49_AM.png" data-posthaven-state="processed" data-medium-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2429866/rKB1QaWvJajByTQqD7Qt-W1iTrk/medium_Screen_Shot_2020-04-06_at_2.36.49_AM.png" data-medium-width="800" data-medium-height="338" data-large-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2429866/rKB1QaWvJajByTQqD7Qt-W1iTrk/large_Screen_Shot_2020-04-06_at_2.36.49_AM.png" data-large-width="1200" data-large-height="507" data-thumb-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2429866/rKB1QaWvJajByTQqD7Qt-W1iTrk/thumb_Screen_Shot_2020-04-06_at_2.36.49_AM.png" data-thumb-width="200" data-thumb-height="200" data-xlarge-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2429866/rKB1QaWvJajByTQqD7Qt-W1iTrk/xlarge_Screen_Shot_2020-04-06_at_2.36.49_AM.png" data-xlarge-width="2400" data-xlarge-height="1014" data-orig-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2429866/rKB1QaWvJajByTQqD7Qt-W1iTrk/Screen_Shot_2020-04-06_at_2.36.49_AM.png" data-orig-width="2480" data-orig-height="1048" data-posthaven-id="2429866">
        </p>
          
        </div>
</div><div>
<p>
Regardless of what happens this year, we are on track to break that record repeatedly over the next few years.</p></div><p>--</p><div><p>The boomers had a vision: a backyard, a quiet street, two cars in every garage, global hegemony. It succeeded, to an extent, and it was beautiful, for some people. Idyllic, even. That vision has frayed. The yards and streets multiplied into sprawl and traffic.Â&nbsp; The cars in every garage are now measurably cooking the planet. And the global hegemony is probably ending. Whatever comes next will be different.</p><p>The good news is that the present situation is so clearly transitional that it's motivating people. For the first time in a long time, we have a cluster of youth based movements starting to articulate a new vision.</p><p>A new vision needs clarity. The kind of reactive politics that gets likes and retweets won't help us. We can't be defined by what we're against. Nor can we talk in vagaries and -isms. If you're the type who thinks that "capitalism" is in its late stage and will be replaced by "socialism", prepare to get concrete about what those words mean to you.</p></div><p>A vision is specific. It has to be <i>visual</i>. Visceral. It has to be as clear as that backyard with the green grass, grill going, kids playing tag, Buick sitting in the garage. <br>
</p><div><p>Then, the challenge is to do the hard work of building power. The time is past ripe.</p><p>--</p></div></div>
    
  </div></div>]]>
            </description>
            <link>https://blog.dcpos.ch/thank-you-next</link>
            <guid isPermaLink="false">hacker-news-small-sites-23623445</guid>
            <pubDate>Wed, 24 Jun 2020 02:49:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[One of the best projects I worked on had zero-overhead communication]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23623360">thread link</a>) | @y39qpcen
<br/>
June 23, 2020 | https://sidhion.com/blog/posts/zero-overhead-communication/ | <a href="https://web.archive.org/web/*/https://sidhion.com/blog/posts/zero-overhead-communication/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>There’s a project I worked on some time ago that provided me one of the most pleasant experiences I had.
When I say pleasant, I mean it in the project management sense.</p>
<p>The work itself wasn’t that fancy:
I had to migrate a lot of machines to a new system.
Nothing cutting edge, no new products, just some migration to a much better system that
would allow us to control the machines smoothly.
The trick is that these machines were serving a really big number of customers,
and we couldn’t just stop them.
On top of that, the code running on the machines was in some cases over 10 years old,
and of course we didn’t have a single person with knowledge about the entire thing.</p>
<p>I don’t really want to talk about the technical side of the project because it’s boring:
you perform a few tests with machines not serving production traffic,
then you start to slowly roll out the migration to machines serving customers,
you’ll then learn of a few scenarios you missed because
the scale of the traffic you tested with wasn’t big enough
(a good problem to have?),
and then you figure out how to deal with that,
incorporate the learnings into the product code,
and resume the migration.</p>
<p>What I want to focus on, though, is my experience leading this migration,
and why I think this was a very pleasant experience.</p>
<p>Given the nature of the problem,
it was somewhat easy to convince management that
there really wasn’t a timeline we could realistically follow.
Machine migrations take time, you need to do it under heavy control to
avoid cases where too many machines are brought offline and you’re unable to serve your traffic.
Sometimes, you’ll also need to replace certain machines,
because they could have some underlying issues that you just can’t
manually investigate due to the scale (this was a migration of over 20,000 machines).
We also had 2 people dedicated on this,
and we knew we’d hit some roadblocks along the way,
but we didn’t really know which ones.
Nobody knew 100% of the code running on the machines,
as it was a really big codebase.</p>
<p>Even though management was ok without some kind of “hard” deadline,
we still aimed at moving things as fast as possible.
Some prep work would need to be done before the migration,
and since we’re talking about a Big N company here,
you can imagine all kinds of internal systems we had to mess around with to make this possible.</p>
<p>Here’s the really nice part:
I felt like the other person working on this project was completely in sync with me.
They didn’t know everything involved in the migration
(I handled a lot of human coordination transparently for them),
but they knew enough about the code running on the machines to
understand all the prep work we’d need.
They knew about some edge cases we’d need to cover.
When talking about the initial steps for this project,
things went so well and we finished discussing so quickly that I
even became worried they hadn’t understood some of the things we’d need to do.
I let them roll with it, though,
and when reviewing the code patches I was really surprised:
in the few minutes we talked about the prep stuff,
we’d synced about the approaches to take,
and then we just started doing it.
Contrast this to either of the following two (way more common) scenarios I encountered in the past:
someone needs a lot of help to understand parts of the code or the system,
and needs some mentoring to figure things out;
or someone holds some strong beliefs about the way things should be done,
and an unproductive discussion arises about how to do things,
when pretty much every alternative proposed is good enough and there is just no right answer.</p>
<p>When we found a roadblock, syncing up was also so easy and smooth,
because nobody held any strong opinions on which approach to take.
We knew which alternatives would solve the problem,
and we favored gettings things done rather than finding some mythical
perfect solution.
Reporting on the progress of the migration was also pretty smooth.
We kept a simple spreadsheet with a bunch of information of things that were already done,
and things that still needed to be done,
and both of us dedicated a few minutes every day to update things there.
If we were to track those using the company’s task management system,
it would’ve taken ages to update information the same way we did with the spreadsheet.
There were days we didn’t even talk at all,
because we were aware of what needed to be done,
and we knew what things were already done just by looking at a somewhat simple table.
No standups required.</p>
<p>Overall, working with this person felt like I was just working with an extension of myself.
I say this in the good sense.
Working with people all in the same mindset might skew projects towards some
below average solutions and not bring enough diversity to the table.
This wasn’t the case here.
We both thought about different approaches to solve the problems we faced,
but we also knew well how to evaluate them,
and knew when they were good enough and discussing more wouldn’t help much.</p>
<p>After we finished this project,
I realized that I had become addicted to the way this project was going.
It was just so pleasant that I didn’t want it to end.
To this day, I still regularly think about this project,
and wonder if I’ll ever be part of or help build a team full of people like this.
Is this how high performing teams work?
Is this how working at very productive companies feels like?
If it is, I want more of it.</p>

    </div></div>]]>
            </description>
            <link>https://sidhion.com/blog/posts/zero-overhead-communication/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23623360</guid>
            <pubDate>Wed, 24 Jun 2020 02:38:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Prescriptions Are a Dead End]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 29 (<a href="https://news.ycombinator.com/item?id=23623306">thread link</a>) | @gbasin
<br/>
June 23, 2020 | https://garybasin.com/prescriptions-are-a-dead-end/ | <a href="https://web.archive.org/web/*/https://garybasin.com/prescriptions-are-a-dead-end/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1988">
		<div>
		<!-- .entry-header -->

		<div>
			
<p>I love to read about how great people accomplish great things. It’s similar to getting advice — I’m left with a high. I imagine that if I can follow the instructions, then I too will accomplish what they have. It’s a logical and tantalizing idea: follow the prescription, get the reward. In practice, it tends to fall short.</p>



<p>Kapil Gupta and Naval did a <a href="https://youtu.be/sBtuqpNZwio" data-rel="lightbox-video-0">great interview</a> where they touched on this pitfall. </p>



<p>The catch is, to achieve something truly remarkable, you have to do something new. It’s practically in the definition. Copying others can help you learn a domain. Imitation is good practice. But to do something new — to create art — you inevitably have to write your own script.</p>



<p>I expanded on these thoughts in a <a href="https://twitter.com/garybasin/status/1274859897826488322?s=19">Twitter thread here</a>, also touching on how prescriptions can act like false Gods.</p>
					</div><!-- .entry-content -->

		<!-- .entry-meta -->
	</div>

	
</article></div>]]>
            </description>
            <link>https://garybasin.com/prescriptions-are-a-dead-end/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23623306</guid>
            <pubDate>Wed, 24 Jun 2020 02:30:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why People Become Internet Trolls]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 11 (<a href="https://news.ycombinator.com/item?id=23623017">thread link</a>) | @rchaudhary
<br/>
June 23, 2020 | https://dradambell.com/why-people-become-internet-trolls/ | <a href="https://web.archive.org/web/*/https://dradambell.com/why-people-become-internet-trolls/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="1c056633" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div>
<p><span>When I was 10 years old and first introduced to the miracle of the World Wide Web, chat rooms were by far my favorite thing. Talking to random people from all over the world about anything you want — what more could a bored kid ask for?</span></p>

<p><span>I’d spend hours in these chat rooms, asking my new friends how old they were, what they had for breakfast, and how much pocket money their parents gave them. I shared this experience with a friend who didn’t own a computer and had never used the internet.</span></p>

<p><span>He asked if he could have a go. “Sure!” I said, excited for him to experience the wonder of the internet. Without hesitation, he began typing the worst insults and swear words he could think of. Horrified I had awoken a dark and malevolent force, and fearing he had forever ruined my friendship with strawberry88, I shut down my computer and didn’t invite him to play on the internet again.</span></p>

<p><span>To this day, I remain baffled by this behavior. When faced with the endless possibility of the internet, my childhood friend’s first impulse was to verbally abuse strangers. This innocent 10-year-old had become a troll.</span></p>

<h4 id="02ff"><span>Wretched impulses</span></h4>

<p><span>John Oliver once described the internet as a “dark carnival of humanity’s most wretched impulses.” Was it these wretched impulses that had consumed my childhood friend?</span></p>

<p><span>The act of trolling is best described from where its name&nbsp;<a href="https://www.etymonline.com/word/troll" target="_blank" rel="noreferrer noopener">may have come from</a>&nbsp;— the form of fishing where a lure is dangled off a moving boat.</span></p>

<figure><span><img src="https://miro.medium.com/max/3200/0*f3HYZpvSGgrg1vHC" alt=""></span></figure>

<p><span>The troll casts his bait (the offensive comment) into the water of the internet. An unsuspecting fish (the targeted user) sees the bait and feels compelled to go for it (the defensive comment). Soon they are hooked and reeled in without mercy. But unlike trolling for fish, which delivers a clear and edible reward, the troll’s reward isn’t entirely clear.</span></p>

<p><span>Trolling is a hard concept to define because there are various methods of trolling and differing degrees of depravity. Some are abhorrent, like “suicide baiting,” where trolls encourage vulnerable users to kill themselves, or “RIP trolls” who vandalize Facebook memorial sites of the recently deceased. But others, like “griefers” who play online games in a manner that purposely disrupts other players, are more of a nuisance.</span></p>

<p><span>Who are these trolls, and what drives them?</span></p>

<h4 id="4d5f"><span>The dark tetrad</span></h4>

<p><span>Psychologists have found&nbsp;<a href="https://www.sciencedirect.com/science/article/abs/pii/S0191886914000324" target="_blank" rel="noreferrer noopener">a link between trollish behavior</a>&nbsp;and a set of personality traits called “the dark tetrad.”</span></p>

<figure><span><img src="https://miro.medium.com/max/2974/0*sAMy6kU4hSsBKYQy" alt=""></span></figure>

<p><span>The dark tetrad comprises:</span></p>

<ul>
<li><span>Sadism — deriving pleasure from another’s pain</span></li>
<li><span>Psychopathy — impairment of empathy and remorse</span></li>
<li><span>Machiavellianism — manipulative and emotionally “cold” behavior</span></li>
<li><span>Narcissism — self-involvement and a need for admiration</span></li>
</ul>

<p><span><a href="https://www.academia.edu/41115419/Loneliness_moderates_the_relationship_between_Dark_Tetrad_personality_traits_and_internet_trolling" target="_blank" rel="noreferrer noopener">In a recent study</a>, trolls were positively correlated with three of the four dark tetrad traits, with narcissism being the odd one out. They found trolls were manipulative, lacked empathy, and enjoyed hurting others. Men exhibited these traits more commonly than women and were more likely to troll. Loneliness was also a significant predictor of trolling when in the presence of Machiavellianism or psychopathy.</span></p>

<p><span>Most studies on trolls use internet surveys to collect data, which is questionable: Can we really trust trolls to complete surveys accurately? This method may also not account for those who don’t consider their behavior to be trollish or those unaware of their trollish behavior.</span></p>

<p><span>In the book&nbsp;<a href="https://www.hardiegrant.com/au/publishing/bookfinder/book/troll-hunting-by-ginger-gorman/9781743794357" target="_blank" rel="noreferrer noopener"><em>Troll Hunting</em></a>, journalist Ginger Gorman spends years building relationships with the worst trolls she can find in an attempt to understand what drives them. To her surprise, trolls were not uneducated lost souls who lacked social skills and lived in their mother’s basement. These trolls had partners, children, and full-time jobs. They showed leadership skills as commanders of&nbsp;<a href="https://www.theguardian.com/books/2019/jan/28/it-was-like-being-skinned-alive-ginger-gorman-goes-hunting-for-trolls" target="_blank" rel="noreferrer noopener">large trolling syndicates</a>. They were socially intelligent and able to pinpoint users’ weaknesses with vicious precision. But what was driving them?</span></p>

<p><span>Many saw trolling as a hobby — something that entertained or amused. Some were ideologically driven, attacking anybody opposing their belief system. But both types of troll tended to engage users that threatened their beliefs or sense of self.</span></p>

<p><span>Some of the trolls exhibited dark tetrad traits. In these trolls, she saw a common pattern — excessive internet use with little to no parental supervision between the ages of 11 and 16. But some trolls didn’t fit the dark tetrad personality type. These trolls were pleasant, friendly, and compassionate when she engaged them directly. How could these trolls behave so antisocially online yet appear to function as typical members of society offline?</span></p>

<h4 id="7160"><span>Empathy deficit</span></h4>

<p><span>The human brain was primarily designed for face-to-face interaction. It hasn’t had time to adapt to communication over the internet.</span></p>

<p><span>Nonverbal communication — facial expressions, gestures, and voice qualities — provides the precise social context of an interaction. While the claim that 93% of communication being nonverbal is&nbsp;<a href="https://cornerstone.lib.mnsu.edu/cgi/viewcontent.cgi?article=1000&amp;context=ctamj" target="_blank" rel="noreferrer noopener">inaccurate</a>, it is a crucial part of how we communicate. Words alone can only go so far. Even if we used the full&nbsp;<a href="https://englishlive.ef.com/blog/language-lab/many-words-english-language/" target="_blank" rel="noreferrer noopener">170,000 words</a>&nbsp;currently in use in the English language, we still couldn’t convey what an expressive face or a suggestive voice could.</span></p>

<p><span>Most internet discussions only allow words. Well, words and emojis and GIFs and stickers and all the other substitutes created to replace nonverbal cues.</span></p>

<p><span>If you say something mean to my face and make me cry, you will probably start to feel uncomfortable. Unless you’re especially mean or psychopathic, my distress will trigger an empathic response and lead you to have mercy. If you tweet something mean and make me cry, no amount of emojis can convey what the sight of a grown man weeping can. If there is no social cue to elicit an empathic response, you might continue your tirade of meanness.</span></p>

<p><span>The absence of nonverbal feedback leads to an “empathy deficit,” and this is what sociopaths suffer from.</span></p>

<h4 id="53a2"><span>Toxic disinhibition</span></h4>

<p><span>When you combine an empathy deficit with the anonymity of online interactions, you get “<a href="https://en.wikipedia.org/wiki/Online_disinhibition_effect" target="_blank" rel="noreferrer noopener">toxic disinhibition</a>,” which is more than just the phenomenon of being rude to bar staff after that fifth shot of tequila.</span></p>

<p><span>Anonymity can lead to “<a href="https://en.wikipedia.org/wiki/Deindividuation" target="_blank" rel="noreferrer noopener">deindividuation</a>” — a temporary loss of one’s identity leading to behavior incongruent with one’s character. It explains why groups of civilized people can engage in riots. It also explains trolling. If a lack of nonverbal cues is what makes us detached from the other person’s suffering, deindividuation is what makes us detached from the awareness of our misconduct.</span></p>

<p><span>True anonymity offers protection from real-world social repercussions, and this has profound effects on human behavior. The image-based bulletin board 4chan, where registration isn’t possible and users remain anonymous, has been&nbsp;<a href="https://theconversation.com/4chan-raids-how-one-dark-corner-of-the-internet-is-spreading-its-shadows-68394" target="_blank" rel="noreferrer noopener">infamous as a troll incubator</a>&nbsp;for this reason. When there are no real-world consequences to your actions, it liberates you from a lifetime of societally inhibited behaviors. Society discourages antisocial behavior and encourages prosocial behavior, so it is antisocial behavior that seeks liberation.</span></p>

<p><span>We are a delicate balance between prosocial humans and antisocial primates. When society cannot enforce prosocial human behavior, the antisocial primate may come back into power. And thus the troll is created.</span></p>

<h4 id="f597"><span>Troll begets troll</span></h4>

<p><span>Researchers at Stanford and Cornell universities performed a large-scale data analysis on&nbsp;<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5791909/" target="_blank" rel="noreferrer noopener">over 16 million comments</a>&nbsp;from December 2012 to August 2013 on CNN.com and found 1 in 4 posts flagged as abusive were from users with no prior record of trollish behavior. This suggests trolling isn’t always a full-time occupation and that one may indulge sporadically.</span></p>

<p><span>The researchers could predict the likelihood of trolling based on the nature of other comments in the discussion and the user’s mood. If earlier comments were negative, the propensity to troll was greater. Like a bad mood, trolling is contagious. All it takes is another user’s trollish comment and a bad mood to create an environment in which our inner troll can blossom.</span></p>

<h4 id="b294"><span>The inner troll</span></h4>

<p><span>It is easier to view trolls as bad apples than see them as something inside all of us, waiting for the right environment to let loose. But when we condemn trolls as inherently malicious individuals, we limit our understanding of what may drive these behaviors.</span></p>

<p><span>While RIP trolls or suicide baiters are likely to be dark tetrad personality types who use the internet as an outlet to indulge their darkest impulses, lesser trolls may be part-time participants who will engage with the right combination of a bad day and a noxious environment. We have only begun to scratch the surface in our understanding of trolls, but the evidence we have suggests we may all be vulnerable.</span></p>

<p><span>Is anyone exempt from toxic disinhibition? Few respond to a tweet that offends them with “Excuse me, I really don’t want to be rude, but if I may could I please respectfully disagree with your opinion for these reasons …” While an offhand remark may appear harmless, the less empathic our online interactions collectively become, the greater risk we all stand of becoming trolls. The gentle ripples of impolite tweets may become crashing toxic waves of disinhibited hatred.</span></p>

<p><span>Trolling isn’t black and white, it is somewhere in the grey between prosocial human and antisocial primate. Ultimately, our propensity for antisocial behavior in the physical world is likely to predict similar online behavior.</span></p>

<h4 id="9272"><span>How can we manage our inner trolls?</span></h4>

<p><span>The more accountable we are for our behavior, the less potential we have of becoming trolls. Employing&nbsp;<a href="https://scholarspace.manoa.hawaii.edu/bitstream/10125/41373/1/paper0224.pdf" target="_blank" rel="noreferrer noopener">less anonymity may help</a>, but this raises privacy concerns for many. Anonymity can also be a good thing. Benign disinhibition — the friendly sibling of toxic disinhibition — is where users freely discuss their deepest insecurities and concerns with other users. This can be very therapeutic and shouldn’t be discouraged. But by using anonymity only where it is necessary, we reduce the likelihood of toxic disinhibition.</span></p>

<p><span>Empathy doesn’t come …</span></p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dradambell.com/why-people-become-internet-trolls/">https://dradambell.com/why-people-become-internet-trolls/</a></em></p>]]>
            </description>
            <link>https://dradambell.com/why-people-become-internet-trolls/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23623017</guid>
            <pubDate>Wed, 24 Jun 2020 01:51:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Automated Landscape Painting in the Style of Bob Ross [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23622971">thread link</a>) | @kmstout
<br/>
June 23, 2020 | https://uwspace.uwaterloo.ca/bitstream/handle/10012/2761/AlexKalaidjianThesis.pdf | <a href="https://web.archive.org/web/*/https://uwspace.uwaterloo.ca/bitstream/handle/10012/2761/AlexKalaidjianThesis.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://uwspace.uwaterloo.ca/bitstream/handle/10012/2761/AlexKalaidjianThesis.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-23622971</guid>
            <pubDate>Wed, 24 Jun 2020 01:44:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elon Musk and the Value of Localism-What We Should Do Instead of Going to Mars]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 9 (<a href="https://news.ycombinator.com/item?id=23622970">thread link</a>) | @richeyrw
<br/>
June 23, 2020 | https://wearenotsaved.com/2020/06/24/elon-musk-and-the-value-of-localism-or-what-we-should-do-instead-of-going-to-mars/ | <a href="https://web.archive.org/web/*/https://wearenotsaved.com/2020/06/24/elon-musk-and-the-value-of-localism-or-what-we-should-do-instead-of-going-to-mars/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						<p><span>If you prefer to listen rather than read, this blog is available as a podcast <a href="https://itunes.apple.com/us/podcast/we-are-not-saved/id1175122428">here</a>. Or if you want to listen to just this post:</span></p>

<p><span><a href="https://traffic.libsyn.com/secure/wearenotsaved/Elon_Musk_and_the_Value_of_Localism_or_What_We_Should_Do_Instead_of_Going_to_Mars.mp3">Or download the MP3</a></span></p>
<hr>
<p><strong>I.</strong></p>
<p><span>Elon Musk has asserted, accurately in my opinion, that unless humanity becomes a two planet species that we are eventually doomed (absent some greater power out there which saves us, which could </span><a href="https://wearenotsaved.com/2016/08/27/fermis-paradox-as-a-proof-of-the-existence-of-god/"><span>include either God or aliens</span></a><span>). And he has built an entire company, SpaceX, around making sure that this happens (the two planet part, not the doomed part). As I mentioned, I think this is an accurate view of how things will </span><em><span>eventually</span></em><span> work out, but it’s also </span><a href="https://wearenotsaved.com/2017/01/14/how-to-save-humanity/"><span>incredibly costly and difficult</span></a><span>. Is it possible that in the short term we can achieve most of the benefits of a Mars colony with significantly less money and effort? Might this be yet another 80/20 situation, where 80% of the benefits can be achieved for only 20% of the resources?</span></p>
<p><span>In order to answer that question, it would help to get deeper into Musk’s thinking and reasoning behind his push for a self-sustaining outpost on Mars. To quote from the man himself:</span></p>
<p><em><span>I think there are really two fundamental paths. History is going to bifurcate along two directions. One path is we stay on Earth forever, and then there will be some eventual extinction event — I don’t have an immediate doomsday prophecy … just that there will be some doomsday event. The alternative is to become a space-faring civilization and a multiplanet species.</span></em></p>
<p><span>While I agree with Musk that having a colony on Mars will prevent some doomsday scenarios, I’m not sure I agree with his implied assertion that it will prevent all of them, that if we choose the alternative of being a space-faring civilization, that it forever closes off the other alternative of doomsday events. To see why that might be, we need to get into a discussion of what potential doomsdays await us, or to use the more common term, what existential risks, or x-risks are we likely to face?</span></p>
<p><span>If you read my round up of the </span><a href="https://wearenotsaved.com/2020/06/05/books-i-finished-in-may/"><span>books I finished in May</span></a><span>, one of my reviews covered </span><a href="https://www.amazon.com/Precipice-Existential-Risk-Future-Humanity/dp/0316484911"><span>Toby Ord’s book, The Precipice: Existential Risk and the Future of Humanity</span></a><span> which was entirely dedicated to a discussion of this very subject. For those who don’t remember, Ord produced a chart showing what he thought the relative odds were for various potential x-risks. Which I’ll once again include.</span></p>
<table>
<tbody>
<tr>
<td><strong>Existential catastrophe via</strong></td>
<td><strong>Chance within the next 100 years</strong></td>
</tr>
<tr>
<td><span>Asteroid/comet Impact</span></td>
<td><span>~1 in 1,000,000</span></td>
</tr>
<tr>
<td><span>Supervolcanic eruption</span></td>
<td><span>~1 in 10,000</span></td>
</tr>
<tr>
<td><span>Stellar explosion</span></td>
<td><span>~1 in 1,000,000</span></td>
</tr>
<tr>
<td><em><span>Total natural risk</span></em></td>
<td><span>~1 in 10,000</span></td>
</tr>
<tr>
<td><span>Nuclear war</span></td>
<td><span>~1 in 1,000</span></td>
</tr>
<tr>
<td><span>Climate change</span></td>
<td><span>~1 in 1,000</span></td>
</tr>
<tr>
<td><span>Other environmental damage</span></td>
<td><span>~1 in 1,000</span></td>
</tr>
<tr>
<td><span>Naturally arising pandemics</span></td>
<td><span>~1 in 10,000</span></td>
</tr>
<tr>
<td><span>Engineered pandemics</span></td>
<td><span>~1 in 30</span></td>
</tr>
<tr>
<td><span>Unaligned artificial intelligence</span></td>
<td><span>~1 in 10</span></td>
</tr>
<tr>
<td><span>Unforeseen anthropogenic risks</span></td>
<td><span>~1 in 30</span></td>
</tr>
<tr>
<td><span>Other anthropogenic risks</span></td>
<td><span>~1 in 50</span></td>
</tr>
<tr>
<td><em><span>Total anthropogenic risks</span></em></td>
<td><span>~1 in 6</span></td>
</tr>
<tr>
<td><em><span>Total existential risk</span></em></td>
<td><span>~1 in 6</span></td>
</tr>
</tbody>
</table>
<p><span>Reviewing this list, which x-risks are entirely avoided by having a self-sustaining colony on Mars? The one it most clearly prevents is the asteroid/comet impact, and indeed that’s the one everyone thinks of. I assume it would also be perfect for protecting humanity from a supervolcanic eruption and a naturally arising pandemic. I’m less clear on how well it would do at protecting humanity from a stellar explosion, but I’m happy to toss that in as well. But you can instantly see the problem with this list, particularly if you read my book review. These are all naturally arising risks, and as a category they’re all far less likely (at least according to Ord) to be the cause of our extinction. What we really need to be hedging against is the category of anthropogenic risks. And it’s not at all clear that a Mars colony is the cheapest or even the best way to do that.&nbsp;</span></p>
<p><span>The risks we’re trying to prevent are often grouped into the general category of “having all of our eggs in one basket”. But just as we don’t want all of our eggs in the “basket” of Earth, I don’t think we want all of our risk mitigation to end up in the “basket” of a Mars colony. To relate it to my </span><a href="https://wearenotsaved.com/2020/06/13/dont-make-the-second-mistake/"><span>last post</span></a><span>, this is very similar to my caution against a situation where we all make the same mistake. Only this time rather than a bunch of independent actors all deciding to independently take the same ultimately catastrophic action, here the consensus happens a little more formally, with massive time and effort put into one great effort. One of the reasons this effort seems safe is that it’s designed to reduce risk, but that doesn’t really matter, it could still be a mistake. A potential mistake which is aggravated by focusing on only one subset of potential x-risks, naturally occurring ones, and this one method for dealing with them, a Mars Colony. In other words in attempting to avoid making a mistake we risk making a potentially different mistake. The mistake of having too narrow a focus. Surviving the next few hundred years is a hugely complicated problem (one I hope to bring greater attention to by </span><a href="https://wearenotsaved.com/2019/12/14/i-finally-figure-out-what-i-want-to-be-when-i-grow-up-an-eschatologist/"><span>expanding the definition and discipline of eschatology</span></a><span>). And the mistakes we could make are legion. But, in my opinion, focusing on a Mars Colony, as the best and first step in preventing those mistakes </span><em><span>turns out to be a mistake itself</span></em><span>.&nbsp;</span></p>
<p><strong>II.</strong></p>
<p><span>At this point it’s only natural to ask what I would recommend instead. And as a matter of fact I do have a proposal:</span></p>
<p><span>Imagine that instead of going to Mars that we built a couple of large underground bunkers, something similar to NORAD. In fact we might even be able to repurpose, or piggyback on NORAD for one of them. Ideally the other one would be built at roughly the opposite spot on the globe from the first. So maybe something in Australia. Now imagine that you paid a bunch of people to live there for two years. You would of course supply them with everything they needed, entertainment, food, power, etc. In fact as far as food and power you’d want to have as robust a supply of those on hand as you could manage. But as part of it they would be </span><em><span>completely cut off from everything</span></em><span> for those two years, no internet connection, no traffic in our out, no inbound communication of any sort. You would of course have plenty of ways to guarantee the necessities like air, food and water. Basically you make this place as self-contained and robust as possible.&nbsp;</span></p>
<p><span>When I say “a bunch of people”, you’d want as many as you could afford, but in essence you want to have enough people in either bunker that </span><em><span>by themselves</span></em><span> they could regenerate humanity if, after some unthinkable tragedy, they were all that remained. The minimum number I’ve seen is 160, with 500 seeming closer to ideal. Also if you wanted to get fancy/clever you could have 80% of the population be female, with lots of frozen sperm. Also it should go without saying that these people should be of prime child bearing age, with a fertility test before they went in.</span></p>
<p><span>Every year you’d alternate which of the bunkers was emptied and refilled with new people. This ensures that neither bunker is empty at the same time and that the period where even one bunker was empty would only be a week or so.</span></p>
<p><span>Beyond all of the foregoing, I’m sure there are many other things one could think of to increase the robustness of these bunkers, but I think you get the idea. So now let’s turn to Ord’s list of x-risks and compare my bunker idea to Musks’ Mars plan.&nbsp;</span></p>
<p><span>All natural risks: Mars is definitely superior, but two things to note, first, even if you combine all possible natural risks together, they only have a 1 in 10,000 chance, according to Ord, of causing human extinction in the next century. I agree that you shouldn’t build a bunker just to protect against natural x-risks, but it also seems like a weak reason to go to Mars as well. Second, don’t underestimate the value the bunker provides even if Ord is wrong and the next giant catastrophe we have to worry about is natural. There are a whole host of disasters one could imagine where having the bunker system I described would be a huge advantage. But, even if it’s not, we’re mostly worried about anthropogenic risks, and it’s when we turn to considering them that the bunker system starts to look like the superior option.&nbsp;</span></p>
<p><span>Taking each anthropogenic risk in turn:</span></p>
<p><span>Nuclear war- Bunkers as a protection against nuclear weapons is an idea almost as old as the weapons themselves. Having more of them, and making sure they’re constantly occupied, could only increase their protective value. Also Ord only gives nuclear war a 1 in 1000 chance of being the cause of our extinction, mostly because it would be so hard to </span><strong>completely</strong><span> wipe humanity out. The bunker system would make that even harder. A Mars colony doesn’t seem necessarily any better as a protection against this risk, for one thing how does it end up escaping this hypothetical war? And if it doesn’t, it would seem to be very vulnerable to attack. At least as vulnerable as a hardened bunker and perhaps far more so given the precariousness of any Martian existence.</span></p>
<p><span>Climate Change- I don’t deny the reality of climate change, but I have a hard time picturing how it wipes out every last human. Most people when pressed on this issue say that the disruption it causes leads to Nuclear War, which just takes us back to the last item.&nbsp;</span></p>
<p><span>Environmental Damage- Similar to climate change, also if we’re too dumb to prevent these sorts of slow moving extinction events on Earth, what makes you think we’ll do any better on Mars?&nbsp;</span></p>
<p><span>Engineered Pandemics- The danger of the engineered pandemic is the malevolent actor behind it, preventing this x-risk means keeping this malevolent actor from infecting everyone, in such a way that we all die. Here the advantage Mars has is its great distance from Earth, meaning you’d have to figure out a way to have a simultaneous outbreak on both planets. The advantage the bunker has is that it’s whole function is to avoid x-risks. Meaning anything that might protect from this sort of threat is not only allowed but expected. The kind of equipment necessary to synthesis a disease? Not allowed in the …</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://wearenotsaved.com/2020/06/24/elon-musk-and-the-value-of-localism-or-what-we-should-do-instead-of-going-to-mars/">https://wearenotsaved.com/2020/06/24/elon-musk-and-the-value-of-localism-or-what-we-should-do-instead-of-going-to-mars/</a></em></p>]]>
            </description>
            <link>https://wearenotsaved.com/2020/06/24/elon-musk-and-the-value-of-localism-or-what-we-should-do-instead-of-going-to-mars/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23622970</guid>
            <pubDate>Wed, 24 Jun 2020 01:44:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OneDev 3.2 – Self-Hosted All-in-One DevOps Platform]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23622908">thread link</a>) | @robinshen
<br/>
June 23, 2020 | https://www.onedev.io/v3.2.0 | <a href="https://web.archive.org/web/*/https://www.onedev.io/v3.2.0">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>Got bunch of feedbacks from OneDev users and this major version ships some of them. Thank you for getting OneDev even better! </p>
<h3>OpenID connect integration</h3>
<p>With OIDC integration, it is now possible to login via GitHub, Gmail, Okta, or any other OIDC compliant identify providers. Besides authentication, this integration can also authorize users with appropriate permissions based on group claims. Check usage scenarios <a href="https://code.onedev.io/projects/onedev-manual/blob/3.2/pages/okta-sso.md">here</a> and <a href="https://code.onedev.io/projects/onedev-manual/blob/3.2/pages/github-sso.md">here</a> for details</p>
<p><span>
      <a href="https://www.onedev.io/static/84ad90df8004dc795401cee246cbd5d5/25c1c/oidc.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="OpenID connect integration" title="OpenID connect integration" src="https://www.onedev.io/static/84ad90df8004dc795401cee246cbd5d5/fcda8/oidc.png" srcset="https://www.onedev.io/static/84ad90df8004dc795401cee246cbd5d5/12f09/oidc.png 148w,
https://www.onedev.io/static/84ad90df8004dc795401cee246cbd5d5/e4a3f/oidc.png 295w,
https://www.onedev.io/static/84ad90df8004dc795401cee246cbd5d5/fcda8/oidc.png 590w,
https://www.onedev.io/static/84ad90df8004dc795401cee246cbd5d5/efc66/oidc.png 885w,
https://www.onedev.io/static/84ad90df8004dc795401cee246cbd5d5/25c1c/oidc.png 1047w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h3>Clone with custom credential in CI job</h3>
<p>For security reason, OneDev clones source in CI job with a default credential which does not have permission to access other projects, or push back commits. To get additional permissions, one has to define custom job secrets accessible to certain branches, and use these secrets in CI job to clone source. Refer to usage scenario <a href="https://code.onedev.io/projects/onedev-manual/blob/3.2/pages/clone-submodules-via-ssh.md">here</a> for example setup</p>
<p><span>
      <a href="https://www.onedev.io/static/d907b034a8cc26e7ec0c7703a54baee6/25c1c/custom-clone-credential.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="clone with custom credential" title="clone with custom credential" src="https://www.onedev.io/static/d907b034a8cc26e7ec0c7703a54baee6/fcda8/custom-clone-credential.png" srcset="https://www.onedev.io/static/d907b034a8cc26e7ec0c7703a54baee6/12f09/custom-clone-credential.png 148w,
https://www.onedev.io/static/d907b034a8cc26e7ec0c7703a54baee6/e4a3f/custom-clone-credential.png 295w,
https://www.onedev.io/static/d907b034a8cc26e7ec0c7703a54baee6/fcda8/custom-clone-credential.png 590w,
https://www.onedev.io/static/d907b034a8cc26e7ec0c7703a54baee6/efc66/custom-clone-credential.png 885w,
https://www.onedev.io/static/d907b034a8cc26e7ec0c7703a54baee6/25c1c/custom-clone-credential.png 1047w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h3>Reworked pull request workflow</h3>
<p>Instead of merging pull requests automatically after getting all approvals from revewers, assignee has to merge them manually to ensure responsibilities, as well as crafting commit message if necessary. Also merged commits from target branch will be excluded when displaying incremental pull request changes to make it easier to understand</p>
<p><span>
      <a href="https://www.onedev.io/static/753c01e3ffb458db46a31ef3f7a4d77f/25c1c/pull-request-assignees.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="pull request assignees" title="pull request assignees" src="https://www.onedev.io/static/753c01e3ffb458db46a31ef3f7a4d77f/fcda8/pull-request-assignees.png" srcset="https://www.onedev.io/static/753c01e3ffb458db46a31ef3f7a4d77f/12f09/pull-request-assignees.png 148w,
https://www.onedev.io/static/753c01e3ffb458db46a31ef3f7a4d77f/e4a3f/pull-request-assignees.png 295w,
https://www.onedev.io/static/753c01e3ffb458db46a31ef3f7a4d77f/fcda8/pull-request-assignees.png 590w,
https://www.onedev.io/static/753c01e3ffb458db46a31ef3f7a4d77f/efc66/pull-request-assignees.png 885w,
https://www.onedev.io/static/753c01e3ffb458db46a31ef3f7a4d77f/25c1c/pull-request-assignees.png 1047w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h3>Show review and build status in pull request list</h3>
<p>To help users getting a better glance of what happened in pull requests, review and build status now get displayed in pull request list</p>
<p><span>
      <a href="https://www.onedev.io/static/7a7d35672c53b7c09c14953278093fc8/25c1c/pull-request-list.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="pull request list status" title="pull request list status" src="https://www.onedev.io/static/7a7d35672c53b7c09c14953278093fc8/fcda8/pull-request-list.png" srcset="https://www.onedev.io/static/7a7d35672c53b7c09c14953278093fc8/12f09/pull-request-list.png 148w,
https://www.onedev.io/static/7a7d35672c53b7c09c14953278093fc8/e4a3f/pull-request-list.png 295w,
https://www.onedev.io/static/7a7d35672c53b7c09c14953278093fc8/fcda8/pull-request-list.png 590w,
https://www.onedev.io/static/7a7d35672c53b7c09c14953278093fc8/efc66/pull-request-list.png 885w,
https://www.onedev.io/static/7a7d35672c53b7c09c14953278093fc8/25c1c/pull-request-list.png 1047w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h3>UI to compose complex sorts</h3>
<p>Previously one has to use <em>order by</em> clause to sort issues, builds and pull requests. Now this task is easier via a smart sort widget. Just select fields to order, and OneDev will compose the query automatically </p>
<p><img src="https://www.onedev.io/5818d4a1f54412d7be2f8292473840a0/orderby.gif" alt="order by widget"></p>
<h3>Publish and render markdown in build</h3>
<p>Besides ordinary artifacts and html reports, one can also publish markdown in a build process and get it rendered in a separate build tab to make important information explicit</p>
<p><span>
      <a href="https://www.onedev.io/static/aba8d21dfc88d7be1f6ba80bfac9a2c6/25c1c/markdown-report.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="markdown report" title="markdown report" src="https://www.onedev.io/static/aba8d21dfc88d7be1f6ba80bfac9a2c6/fcda8/markdown-report.png" srcset="https://www.onedev.io/static/aba8d21dfc88d7be1f6ba80bfac9a2c6/12f09/markdown-report.png 148w,
https://www.onedev.io/static/aba8d21dfc88d7be1f6ba80bfac9a2c6/e4a3f/markdown-report.png 295w,
https://www.onedev.io/static/aba8d21dfc88d7be1f6ba80bfac9a2c6/fcda8/markdown-report.png 590w,
https://www.onedev.io/static/aba8d21dfc88d7be1f6ba80bfac9a2c6/efc66/markdown-report.png 885w,
https://www.onedev.io/static/aba8d21dfc88d7be1f6ba80bfac9a2c6/25c1c/markdown-report.png 1047w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h3>Rule to transit inactive issues to specified state</h3>
<p>Sometimes it is desirable to transit inactive issues to a certain state, for instance to mark it idle and notify relevant participants, and finally close it if no one cares about it. Now this is possible via a custom state transition rule</p>
<p><span>
      <a href="https://www.onedev.io/static/fe1e5fa89bb15733cae5977fd7cae3fa/25c1c/inactive-transition.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="idle-issue-transition" title="idle-issue-transition" src="https://www.onedev.io/static/fe1e5fa89bb15733cae5977fd7cae3fa/fcda8/inactive-transition.png" srcset="https://www.onedev.io/static/fe1e5fa89bb15733cae5977fd7cae3fa/12f09/inactive-transition.png 148w,
https://www.onedev.io/static/fe1e5fa89bb15733cae5977fd7cae3fa/e4a3f/inactive-transition.png 295w,
https://www.onedev.io/static/fe1e5fa89bb15733cae5977fd7cae3fa/fcda8/inactive-transition.png 590w,
https://www.onedev.io/static/fe1e5fa89bb15733cae5977fd7cae3fa/efc66/inactive-transition.png 885w,
https://www.onedev.io/static/fe1e5fa89bb15733cae5977fd7cae3fa/25c1c/inactive-transition.png 1047w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h3><a href="https://code.onedev.io/projects/onedev-server/builds/797/fixed-issues?query=%22State%22+is+%22Released%22+order+by+%22Type%22+asc+and+%22Priority%22+desc">And many more</a></h3></section></div>]]>
            </description>
            <link>https://www.onedev.io/v3.2.0</link>
            <guid isPermaLink="false">hacker-news-small-sites-23622908</guid>
            <pubDate>Wed, 24 Jun 2020 01:35:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Big Sur and the Temptation of the App Store]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23622783">thread link</a>) | @GavinAnderegg
<br/>
June 23, 2020 | https://anderegg.ca/2020/06/23/big-sur-and-the-temptation-of-the-app-store | <a href="https://web.archive.org/web/*/https://anderegg.ca/2020/06/23/big-sur-and-the-temptation-of-the-app-store">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
			<section id="content">
				<article>
					
					<h3>June 23, 2020</h3>
					<p>At WWDC this year, Apple announced their switch to “<a href="https://www.apple.com/newsroom/2020/06/apple-announces-mac-transition-to-apple-silicon/">Apple silicon</a>” for Mac hardware. This had been heavily rumoured for years, and there was a lot of discussion about it. Some worried that Apple would use the transition as an excuse to lock down app delivery further — perhaps only allowing apps to be installed from the Mac App Store.</p>

<p>This didn’t happen. You can still choose to <a href="https://support.apple.com/en-ca/HT202491">install apps from identified developers</a>, or <a href="https://support.apple.com/en-ca/guide/mac-help/mh40616/mac">install an unsigned app</a> if you trust it. But something else happened instead: Apple announced that iOS apps are coming directly to the Mac. Specifically, Macs that use their new chips and run the upcoming version of macOS, <a href="https://www.apple.com/macos/big-sur-preview/">Big Sur</a>.</p>

<p>I’m worried about this. Here’s my thinking.</p>

<p>There are an order of magnitude more <a href="https://www.theverge.com/2019/1/29/18202736/apple-devices-ios-earnings-q1-2019">iOS devices</a> than <a href="https://techcrunch.com/2018/10/30/there-are-now-100-million-macs-in-use/">macOS devices</a> in use. I couldn’t find hard numbers, but I’d bet there are similarly way more iOS developers than macOS developers. This makes sense, as iOS is the newer and more exciting platform. Apple focused a lot of attention on iOS since introducing the iPhone, and the Mac became a bit more of a workhorse over time. People still develop apps for macOS, but there have been fewer over time. Also, many new Mac apps are developed with cross-platform tools like Electron.</p>

<p>That Electron piece is interesting. Slack is the poster-child for Electron on desktops, <a href="https://twitter.com/slackhq/status/931599784137363459">but their iOS app is native</a>. Personally, I think the Slack experience on iOS is nicer. With iOS apps coming to Big Sur, it’s not crazy to imagine Slack eventually shipping their iOS app on the Mac instead of the Electron version. Other developers with both macOS and iOS software would be in a similar position.</p>

<p>The thing about those iOS apps is that they have to come from the App Store, even on the Mac. Of course, developers can always choose to use the iOS version as a starting point and build a custom <a href="https://swiftwithmajid.com/2019/10/23/reusing-swiftui-views-across-apple-platforms/">SwiftUI</a>/<a href="https://developer.apple.com/mac-catalyst/">Mac Catalyst</a> version specifically for macOS – but going the easier route will be pretty tempting. Writing something once and publishing for multiple platforms saves on developer time, which is why Slack uses Electron for their desktop apps. It makes sense to put more resources into the version with the bigger audience as well, which probably why I prefer Slack on my iPad.</p>

<p>The worst part is that Apple seems to be doing this themselves. Just before WWDC this year, <a href="https://www.macrumors.com/2020/06/15/apple-developer-app-for-mac/">Apple released a Mac version of their Developer app</a>. It’s a Mac Catalyst port of the iPad version, and <a href="https://pilky.me/apples-developer-app/">it really doesn’t feel at home on macOS</a>. Is it better than nothing? Sure. It just <a href="https://daringfireball.net/linked/2020/06/17/developer-app-for-mac">doesn’t fill me with hope</a> for the quality of Mac apps going forward.</p>

<p>Before WWDC, I wasn’t worried about the ARM transition meaning the Mac would go App Store only. Sure, Apple would love for more apps to be in the App Store for security (and monetary) reasons, but the platform needs apps that the App Store can’t support. The whole “iOS apps on the Mac” wasn’t something I saw coming, though. Apple won’t enforce this change, but I worry that developing a “good enough” iOS app for the Mac might become the future of the platform.</p>

<hr>

<p><a href="https://news.ycombinator.com/item?id=23622783">Discuss on Hacker News</a></p>

				</article>
			</section>
		</div></div>]]>
            </description>
            <link>https://anderegg.ca/2020/06/23/big-sur-and-the-temptation-of-the-app-store</link>
            <guid isPermaLink="false">hacker-news-small-sites-23622783</guid>
            <pubDate>Wed, 24 Jun 2020 01:19:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bastions on demand in an AWS VPC]]>
            </title>
            <description>
<![CDATA[
Score 34 | Comments 31 (<a href="https://news.ycombinator.com/item?id=23622728">thread link</a>) | @mooreds
<br/>
June 23, 2020 | https://theconsultingcto.com/posts/bastions-on-demand/ | <a href="https://web.archive.org/web/*/https://theconsultingcto.com/posts/bastions-on-demand/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>Any time you have a VPC, you’ll likely need some way to gain access to the resources within the VPC from your local box. Typically, the way to do that is to run a bastion (or jumpbox) which you and your team can SSH into. The downside is that you are exposing an entry point into your network that is accessible by multiple people and running 24x7. And depending on how you manage permissions, you may not be able to restrict access to the box via IAM. Obviously, this is not ideal.</p>
<p>Luckily, we have <a href="https://aws.amazon.com/fargate/">Fargate</a>.</p>
<p>With Fargate, we no longer need to maintain permanent bastion instances—we can create bastions when needed and tear them down when no longer in use. We can lock down bastion instances to an individual user both in terms of SSH keys and IP address. And we can restrict access via IAM to both the API used to manage bastions and to which SSH keys are used to log into an instance.</p>
<p>All in all, we save on infrastructure spend while reducing our attack surface.</p>
<p>Throughout this guide, I’ll be referencing the code from my <a href="https://github.com/jdhollis/bastions-on-demand/"><code>bastions-on-demand</code></a> repo. If you want to skip the explanation, just clone it and follow the directions in the <a href="https://github.com/jdhollis/bastions-on-demand/blob/master/README.md">README.md</a> to get started.</p>
<p>If you run into any trouble, <a href="https://github.com/jdhollis/bastions-on-demand/issues/new/choose">create an issue</a>, and I’ll respond as best I can.</p>
<p>Otherwise, buckle up. This is going to be a bit in-depth.</p>
<h2 id="architecture">Architecture</h2>
<p>There are two key components to bastions on demand—<a href="https://github.com/jdhollis/bastions-on-demand/tree/master/bastion">the infrastructure for managing the bastion image</a> and <a href="https://github.com/jdhollis/bastions-on-demand/tree/master/service">the bastion service itself</a>.</p>
<p>The <a href="#container-infrastructure">container infrastructure</a> consists of an <a href="https://aws.amazon.com/ecr/">ECR</a> repository, a Docker container, an IAM role for fetching a user’s public keys, and scripts for building and pushing images. Typically, I share this infrastructure across multiple services because the requirements don’t vary much. But if a team wants complete service isolation or needs to customize their bastion image, it’s trivial to make that work.</p>
<p>The <a href="#bastion-service">bastion service</a> consists of an <a href="https://aws.amazon.com/ecs/">ECS</a> task, a task role that enables access to any required resources, an API to create and destroy bastion instances, and a set of scripts to make it easy for team members to do just that. The bastion service module should be included in any service that needs bastions—keep it in the service’s repository for ease of access and deploy it alongside the parent service.</p>
<p>Naturally, all of this infrastructure is managed with <a href="https://www.terraform.io/">Terraform</a>.</p>
<p>I owe a debt of gratitude to the following authors as they provided valuable examples that helped me develop this approach:</p>
<ul>
<li><a href="https://ig.nore.me/2018/07/serverless-bastions-on-demand/">Serverless Bastions on Demand</a> &amp; <a href="https://github.com/ArjenSchwarz/workshop-fargate-bastion">ArjenSchwarz/workshop-fargate-bastion</a></li>
<li><a href="https://github.com/alex0ptr/fargate-bastion">alex0ptr/fargate-bastion</a></li>
<li><a href="https://cloudonaut.io/manage-aws-ec2-ssh-access-with-iam/">Manage AWS EC2 SSH access with IAM</a></li>
</ul>
<p>While I recommend using multiple AWS accounts for security and isolation, in this guide, I’m going to use a single account so that we can focus on the essentials. If there’s interest, I will address how to modify this approach for use with multiple accounts in a separate guide. Everything in this guide assumes you’re using the <code>default</code> profile, but you can override via the <code>AWS_PROFILE</code> environment variable.</p>
<p>I’m also deliberately not using <a href="https://www.terraform.io/docs/state/remote.html">Terraform remote state</a> in this guide to make it easier for you to try out my code. If you’re going to use this in a live account, you absolutely should use remote state—insert your own backend configuration where appropriate. And if you don’t have a remote backend, have a look at my <a href="https://github.com/jdhollis/remote-state">remote-state</a> repo for an example of how to set one up on S3 with DynamoDB and KMS.</p>
<p>Now, let’s get started.</p>
<h2 id="initial-setup">Initial Setup</h2>
<p>If you haven’t already, create a role for API Gateway logging:</p>
<section>
<div><pre><code data-lang="hcl"><span>data</span> <span>"aws_iam_policy_document" "assume_role"</span> {
  <span>statement</span> {
    actions <span>=</span> [<span>"sts:AssumeRole"</span>]

    <span>principals</span> {
      identifiers <span>=</span> [<span>"apigateway.amazonaws.com"</span>]
      type        <span>=</span> <span>"Service"</span>
    }
  }
}

<span>data</span> <span>"aws_iam_policy_document" "logger"</span> {
  <span>statement</span> {
    actions <span>=</span> [
      <span>"logs:CreateLogGroup"</span>,
      <span>"logs:CreateLogStream"</span>,
      <span>"logs:DescribeLogGroups"</span>,
      <span>"logs:DescribeLogStreams"</span>,
      <span>"logs:FilterLogEvents"</span>,
      <span>"logs:GetLogEvents"</span>,
      <span>"logs:PutLogEvents"</span>,
    ]

    resources <span>=</span> [<span>"*"</span>]
  }
}

<span>resource</span> <span>"aws_iam_role" "logger"</span> {
  name               <span>=</span> <span>"api-gateway-cloudwatch-logger"</span>
  assume_role_policy <span>=</span> <span>data</span>.<span>aws_iam_policy_document</span>.<span>assume_role</span>.<span>json</span>
}

<span>resource</span> <span>"aws_iam_role_policy" "logger"</span> {
  name   <span>=</span> <span>"api-gateway-cloudwatch-logger"</span>
  policy <span>=</span> <span>data</span>.<span>aws_iam_policy_document</span>.<span>logger</span>.<span>json</span>
  role   <span>=</span> <span>aws_iam_role</span>.<span>logger</span>.<span>name</span>
}

<span>resource</span> <span>"aws_api_gateway_account" "global"</span> {
  cloudwatch_role_arn <span>=</span> <span>aws_iam_role</span>.<span>logger</span>.<span>arn</span>
}
</code></pre></div>  
</section>
<p>Logging API Gateway access is a good idea in general. Unfortunately, this is a global account setting, so use with caution. API Gateway has a lot of stateful corners. I typically manage this logger in a separate repository since it’s shared across all services running in an account.</p>
<h2 id="container-infrastructure">Container Infrastructure</h2>
<p>Creating the ECR repository is straightforward:</p>
<section>
<div><pre><code data-lang="hcl"><span>resource</span> <span>"aws_ecr_repository" "bastion"</span> {
  name <span>=</span> <span>"bastion"</span>
}
</code></pre></div>  
</section>
<p>Next we need to create a role that can fetch a user’s public keys.</p>
<section>
<div><pre><code data-lang="hcl"><span>data</span> <span>"aws_caller_identity" "env"</span> {}<span>
</span><span>
</span><span># …
</span><span></span>
<span>data</span> <span>"aws_iam_policy_document" "assume_role"</span> {
  <span>statement</span> {
    actions <span>=</span> [<span>"sts:AssumeRole"</span>]

    <span>principals</span> {
      identifiers <span>=</span> [<span>"arn:aws:iam::${data.aws_caller_identity.env.account_id}:root"</span>]
      type        <span>=</span> <span>"AWS"</span>
    }
  }
}

<span>data</span> <span>"aws_iam_policy_document" "public_key_fetcher"</span> {
  <span>statement</span> {
    actions <span>=</span> [
      <span>"iam:GetSSHPublicKey"</span>,
      <span>"iam:ListSSHPublicKeys"</span>,
    ]

    resources <span>=</span> [<span>"arn:aws:iam::${data.aws_caller_identity.env.account_id}:user/*"</span>]
  }
}

<span>resource</span> <span>"aws_iam_role" "public_key_fetcher"</span> {
  name               <span>=</span> <span>"public-key-fetcher"</span>
  assume_role_policy <span>=</span> <span>data</span>.<span>aws_iam_policy_document</span>.<span>assume_role</span>.<span>json</span>
}

<span>resource</span> <span>"aws_iam_role_policy" "public_key_fetcher"</span> {
  name   <span>=</span> <span>"public-key-fetcher"</span>
  policy <span>=</span> <span>data</span>.<span>aws_iam_policy_document</span>.<span>public_key_fetcher</span>.<span>json</span>
  role   <span>=</span> <span>aws_iam_role</span>.<span>public_key_fetcher</span>.<span>id</span>
}
</code></pre></div>  
</section>
<p>This role will be used by the bastion instance to fetch a user’s keys when the user attempts to SSH into the instance, as we’ll see below.</p>
<h3 id="dockerfile">Dockerfile</h3>
<p>Creating the container image is fairly straightforward. We start with <a href="https://alpinelinux.org/">Alpine Linux</a> because it’s small and security-oriented and add the scripts we’ll need to start <code>sshd</code> and handle login.</p>
<section>
<div><pre><code data-lang="dockerfile"><span>FROM</span><span> alpine:3.11</span><span>
</span><span>
</span><span></span><span>WORKDIR</span><span> /root</span><span>
</span><span>
</span><span></span><span>ADD</span> fetch_authorized_keys.sh /usr/local/bin/fetch_authorized_keys.sh<span>
</span><span></span><span>ADD</span> entrypoint.sh /usr/local/bin/entrypoint.sh<span>
</span></code></pre></div>  
</section>
<p>Next, we install dependencies including the <a href="https://aws.amazon.com/cli/">AWS CLI</a>. If you typically need any other packages for your bastion, add ‘em to the list. (It still bugs me that AWS doesn’t provide checksums for its CLI bundle. Oh well.)</p>
<section>
<div><pre><code data-lang="dockerfile"><span>RUN</span> <span>echo</span> <span>"Installing dependencies..."</span> <span>&amp;&amp;</span> <span>\
</span><span></span>  apk --no-cache <span>\
</span><span></span>    add <span>\
</span><span></span>      bash <span>\
</span><span></span>      curl <span>\
</span><span></span>      openssh <span>\
</span><span></span>      python <span>\
</span><span></span>      tini <span>\
</span><span></span>  <span>&amp;&amp;</span> <span>\
</span><span></span>  <span>echo</span> <span>"Installing AWS CLI..."</span> <span>&amp;&amp;</span> <span>\
</span><span></span>  wget https://s3.amazonaws.com/aws-cli/awscli-bundle.zip <span>&amp;&amp;</span> <span>\
</span><span></span>  unzip awscli-bundle.zip <span>&amp;&amp;</span> <span>\
</span><span></span>  rm awscli-bundle.zip <span>&amp;&amp;</span> <span>\
</span><span></span>  ./awscli-bundle/install -i /usr/local/aws -b /usr/local/bin/aws <span>&amp;&amp;</span> <span>\
</span><span></span>  rm -R awscli-bundle <span>&amp;&amp;</span> <span>\
</span><span></span>  /usr/local/bin/aws --version<span>
</span></code></pre></div>  
</section>
<p>Now we need a user to log in as.</p>
<p>You could use <code>root</code>. I have in the past with small teams that needed the additional flexibility. But if you’re providing an image to teams that are independent of whoever handles security, you don’t necessarily want people making changes to the bastion that could open up holes in your network.</p>
<p>Instead, we create a user named <code>ops</code> and unlock the account for login.</p>
<section>
<div><pre><code data-lang="dockerfile"><span>RUN</span> <span>echo</span> <span>"Creating user \"ops\"..."</span> <span>&amp;&amp;</span> <span>\
</span><span></span>  adduser ops --disabled-password<span>
</span><span>
</span><span></span><span>RUN</span> <span>echo</span> <span>"Unlocking \"ops\"..."</span> <span>&amp;&amp;</span> <span>\
</span><span></span>  sed -i <span>"s/ops:!:/ops:*:/g"</span> /etc/shadow<span>
</span></code></pre></div>  
</section>
<p>With that out of the way, we now configure <code>sshd</code>.</p>
<section>
<div><pre><code data-lang="dockerfile"><span>RUN</span> <span>echo</span> <span>"Configuring sshd..."</span> <span>&amp;&amp;</span> <span>\
</span><span></span>  sed -i <span>"s:#AuthorizedKeysCommand none:AuthorizedKeysCommand /usr/local/bin/fetch_authorized_keys.sh:g"</span> /etc/ssh/sshd_config <span>&amp;&amp;</span> <span>\
</span><span></span>  sed -i <span>"s:#AuthorizedKeysCommandUser nobody:AuthorizedKeysCommandUser nobody:g"</span> /etc/ssh/sshd_config <span>&amp;&amp;</span> <span>\
</span><span></span>  sed -i <span>"s:#GatewayPorts no:GatewayPorts yes:g"</span> /etc/ssh/sshd_config <span>&amp;&amp;</span> <span>\
</span><span></span>  sed -i <span>"s:#PasswordAuthentication yes:PasswordAuthentication no:g"</span> /etc/ssh/sshd_config <span>&amp;&amp;</span> <span>\
</span><span></span>  sed -i <span>"s:#PermitTunnel no:PermitTunnel yes:g"</span> /etc/ssh/sshd_config <span>&amp;&amp;</span> <span>\
</span><span></span>  sed -i <span>"s:AllowTcpForwarding no:AllowTcpForwarding yes:g"</span> /etc/ssh/sshd_config <span>&amp;&amp;</span> <span>\
</span><span></span>  sed -i <span>"s:AuthorizedKeysFile .ssh/authorized_keys:AuthorizedKeysFile none:g"</span> /etc/ssh/sshd_config<span>
</span></code></pre></div>  
</section>
<p>We’re configuring <code>sshd</code> to do a few different things.</p>
<p>We’re setting the <code>AuthorizedKeysCommand</code> to use <code>fetch_authorized_keys.sh</code>, and we’re disabling both password logins and the ability to use an <code>AuthorizedKeysFile</code> on the instance. The intention here is to make it possible to only use the logic in <code>fetch_authorized_keys.sh</code> to authenticate the user.</p>
<p>We’re also setting <code>sshd</code> up for proxying.</p>
<p>Finally, we configure the <code>ENTRYPOINT</code>:</p>
<section>
<div><pre><code data-lang="dockerfile"><span>ENTRYPOINT</span> [ <span>"/sbin/tini"</span>, <span>"--"</span> ]<span>
</span><span></span><span>CMD</span> [ <span>"/bin/sh"</span>, <span>"/usr/local/bin/entrypoint.sh"</span> ]<span>
</span></code></pre></div>  
</section>
<p>The only interesting thing here is we’re using <a href="https://github.com/krallin/tini"><code>tini</code></a>. If you’re interested in why, check out <a href="https://github.com/krallin/tini/issues/8">this GitHub issue</a>.</p>
<h3 id="entrypointsh">entrypoint.sh</h3>
<p>On container startup, the first thing we need to do is generate host keys.</p>
<section>
  
</section>
<p>Then we export the global environment which includes the AWS credentials injected into the container, the role for fetching SSH keys, and the user name of the person for whom this bastion instance is intended.</p>
<section>
<div><pre><code data-lang="sh"><span>echo</span> <span>"export AWS_CONTAINER_CREDENTIALS_RELATIVE_URI=</span><span>$AWS_CONTAINER_CREDENTIALS_RELATIVE_URI</span><span>"</span> &gt; /etc/profile.d/authorized_keys_configuration.sh
<span>echo</span> <span>"export AWS_DEFAULT_REGION=</span><span>$AWS_DEFAULT_REGION</span><span>"</span> &gt;&gt; /etc/profile.d/authorized_keys_configuration.sh
<span>echo</span> <span>"export AWS_EXECUTION_ENV=</span><span>$AWS_EXECUTION_ENV</span><span>"</span> &gt;&gt; /etc/profile.d/authorized_keys_configuration.sh
<span>echo</span> <span>"export AWS_REGION=</span><span>$AWS_REGION</span><span>"</span> &gt;&gt; /etc/profile.d/authorized_keys_configuration.sh
<span>echo</span> <span>"export ECS_CONTAINER_METADATA_URI=</span><span>$ECS_CONTAINER_METADATA_URI</span><span>"</span> &gt;&gt; /etc/profile.d/authorized_keys_configuration.sh
<span>echo</span> <span>"export ASSUME_ROLE_FOR_AUTHORIZED_KEYS=</span><span>$ASSUME_ROLE_FOR_AUTHORIZED_KEYS</span><span>"</span> &gt;&gt; /etc/profile.d/authorized_keys_configuration.sh
<span>echo</span> <span>"export USER_NAME=</span><span>$USER_NAME</span><span>"</span> &gt;&gt; /etc/profile.d/authorized_keys_configuration.sh
</code></pre></div>  
</section>
<p>Because <code>fet…</code></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://theconsultingcto.com/posts/bastions-on-demand/">https://theconsultingcto.com/posts/bastions-on-demand/</a></em></p>]]>
            </description>
            <link>https://theconsultingcto.com/posts/bastions-on-demand/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23622728</guid>
            <pubDate>Wed, 24 Jun 2020 01:11:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How effective communication can be achieved in a digital work environment]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23622241">thread link</a>) | @markshepard
<br/>
June 23, 2020 | https://www.airsend.io/blog/index.php/2020/05/24/1-tip-on-how-effective-communication-can-be-achieved-in-a-digital-work-environment/ | <a href="https://web.archive.org/web/*/https://www.airsend.io/blog/index.php/2020/05/24/1-tip-on-how-effective-communication-can-be-achieved-in-a-digital-work-environment/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1668">
	

	




	<div>
		
<div><figure><img src="https://www.airsend.io/blog/wp-content/uploads/2020/05/undraw_Group_chat_unwm-3-1024x692.png" alt="" width="412" height="278" srcset="https://www.airsend.io/blog/wp-content/uploads/2020/05/undraw_Group_chat_unwm-3-1024x692.png 1024w, https://www.airsend.io/blog/wp-content/uploads/2020/05/undraw_Group_chat_unwm-3-300x203.png 300w, https://www.airsend.io/blog/wp-content/uploads/2020/05/undraw_Group_chat_unwm-3-768x519.png 768w, https://www.airsend.io/blog/wp-content/uploads/2020/05/undraw_Group_chat_unwm-3.png 1384w" sizes="(max-width: 412px) 100vw, 412px"><figcaption>Source: unDraw</figcaption></figure></div>



<p>A multi-billion dollar company. A winning presidential
campaign. A happy marriage. What do these three things have in common? The
foundation of success in each is effective communication. </p>



<p>Effective communication has the power to amass riches and
make history. With it, governments have been transformed, along with the lives
of billions of people. With it, enterprises like Amazon, Apple, and Alibaba
rise from obscurity. </p>



<p>It’s no wonder that all successful businesses need strong
communication infrastructures in order to grow and prosper. But that’s not what
this article is about. The topic of communication is so vast that you can get a
Ph.D. in it. This article would have to be a book, maybe three, to properly
cover the topic. </p>



<p>What this article focuses on is a single concept that, if
grasped, can give your organization a big push in the right direction towards
effective communication in a digital work environment. The concept is this:</p>



<blockquote><p><em>Chat is like a river; Wiki is like a dam.</em></p></blockquote>



<h2>River? Dam?</h2>



<div><figure><img src="https://www.airsend.io/blog/wp-content/uploads/2020/05/undraw_chat_1wo5-1024x734.png" alt="" width="357" height="255" srcset="https://www.airsend.io/blog/wp-content/uploads/2020/05/undraw_chat_1wo5-1024x734.png 1024w, https://www.airsend.io/blog/wp-content/uploads/2020/05/undraw_chat_1wo5-300x215.png 300w, https://www.airsend.io/blog/wp-content/uploads/2020/05/undraw_chat_1wo5-768x551.png 768w, https://www.airsend.io/blog/wp-content/uploads/2020/05/undraw_chat_1wo5.png 1109w" sizes="(max-width: 357px) 100vw, 357px"><figcaption>Source: unDraw</figcaption></figure></div>



<p>A while ago, we published an article that dives into
synchronous and asynchronous communication. Synchronous communication is communication
that happens in real time. It’s a company meeting on Zoom or an active chat
room. Asynchronous communication is communication that happens… not in real
time. It’s that email you send to a client which you know you won’t get a
response to until weeks later, or notes on that Zoom company meeting posted to
an online bulletin. Both are important because different types of information
do best in different formats. </p>



<p>Synchronous communication is fast, immediate, brief. Information
flows like a river — as it does in a chat. This format is best for times of uncertainty
and/or urgency. It’s good for exploring ideas together, having discussions to
make decisions, and addressing crisis situations. </p>



<p>Asynchronous communication is slower, usually more
considered and voluminous. Information gathers like a dam — as it does in a
Wiki. This format is best for adding context to real time communication after
it has happened, putting together detailed information, and explaining complex
concepts.</p>



<p>When used properly, synchronous and asynchronous
communication together form effective communication.</p>



<h2>Increasing Effective Communication in Your Organization</h2>



<div><figure><img src="https://www.airsend.io/blog/wp-content/uploads/2020/05/undraw_online_collaboration_7pfp.png" alt="" width="364" height="291" srcset="https://www.airsend.io/blog/wp-content/uploads/2020/05/undraw_online_collaboration_7pfp.png 1000w, https://www.airsend.io/blog/wp-content/uploads/2020/05/undraw_online_collaboration_7pfp-300x240.png 300w, https://www.airsend.io/blog/wp-content/uploads/2020/05/undraw_online_collaboration_7pfp-768x615.png 768w" sizes="(max-width: 364px) 100vw, 364px"><figcaption>Source: unDraw</figcaption></figure></div>



<p>When synchronous and asynchronous communication are used
appropriately in an organization, communication is at its best and collaboration
is smooth and easy. In a digital work environment, some of the most common modes
of communication are chat and Wiki. As mentioned before, chat facilitates
synchronous communication and a Wiki facilitates asynchronous communication. </p>



<p>Increasing effective communication in your organization is
as simple as having both chat and a Wiki available to everyone and then making
it clear which medium to use for each type of interaction. In other words, the
roadmap to achieving effective communication in a digital work environment is:</p>



<ol><li><strong>Provide
the right tools</strong> – Have chat and a Wiki available to all team members and
get everyone accustomed to using them. </li><li><strong>Ensure the tools are used correctly</strong> – Do
this by training management on the concept of synchronous and asynchronous
communication (or “<em>Chat is like a river;
Wiki is like a dam.”) </em>and have them lead by example so the rest of your organization
follows.</li></ol>



<h2>Chat and Wiki in AirSend</h2>



<p>In AirSend, each channel has both a chat section and a Wiki
section. The chat is great for quickly discussing new developments, exchanging links
to articles or tidbits of information, and scheduling calls for further
discussion. The Wiki is great for storing, sharing, and collaborating on more detailed,
complex items.</p>



<p>Having the chat and Wiki together in one place makes communication
much smoother and more efficient than the previous model of emailing back and
forth with document links or attachments. </p>



<figure><video controls="" src="https://www.airsend.io/blog/wp-content/uploads/2020/05/Chat-Wiki-GIF-S10.mp4"></video></figure>



<h2>Finding Balance </h2>



<p>Effective communication is powerful, and one of the key factors of communicating effectively in a digital environment is finding the balance between synchronous and asynchronous communication. When used together correctly, chat and Wiki can streamline the communication process for clutter-free collaboration, resulting in increased productivity. </p>



<p>Just remember: <em>Chat is like a river; Wiki is like a dam.</em></p>
	</div><!-- .entry-content -->

	 <!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://www.airsend.io/blog/index.php/2020/05/24/1-tip-on-how-effective-communication-can-be-achieved-in-a-digital-work-environment/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23622241</guid>
            <pubDate>Wed, 24 Jun 2020 00:18:52 GMT</pubDate>
        </item>
    </channel>
</rss>
