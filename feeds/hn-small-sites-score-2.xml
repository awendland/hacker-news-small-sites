<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Mon, 25 Jan 2021 02:02:15 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Mon, 25 Jan 2021 02:02:15 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Raspberry Pi as x2go “thin” client]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25881126">thread link</a>) | @indigodaddy
<br/>
January 23, 2021 | http://www.multi-seat.com/x2go/ | <a href="https://web.archive.org/web/*/http://www.multi-seat.com/x2go/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://www.multi-seat.com/x2go/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25881126</guid>
            <pubDate>Sat, 23 Jan 2021 10:03:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bitcoin Core Lead Maintainer Steps Back, Encourages Decentralization]]>
            </title>
            <description>
<![CDATA[
Score 80 | Comments 121 (<a href="https://news.ycombinator.com/item?id=25880727">thread link</a>) | @runeks
<br/>
January 23, 2021 | https://laanwj.github.io/2021/01/21/decentralize.html | <a href="https://web.archive.org/web/*/https://laanwj.github.io/2021/01/21/decentralize.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Recent events have made me reflect on a few things in my life I was already thinking about for a while. Also, responses on social media have made me realize that people have <em>strange</em> expectations from me, and what my role in the Bitcoin Core project is.</p>

<h2 id="growth">growth</h2>

<p>Bitcoin has grown a lot since I started contributing to it in 2011. Some arrangements that were acceptable for a small scale FOSS project are no longer so for one runing a 600 billion dollar system. Market cap is famously deceptive, but my point is not about specific numbers here.</p>

<p>One thing is clear: this is a serious project now, and we need to start taking decentralization seriously.</p>

<h2 id="moving-on">moving on</h2>

<p>I realize I am myself somewhat of a centralized bottleneck. And although I find Bitcoin an extremely interesting project and believe it’s one of the most important things happening at the moment, I also have many other interests. It’s also particularly stressful and I don’t want it, nor the bizarre spats in the social media around it, to start defining me as a person.</p>

<h2 id="spreading-out">spreading out</h2>

<p>I will start by delegating my own tasks, and decreasing my involvement. I do not intend to stop contributing to Bitcoin, or even to the Bitcoin Core project, but I would like to remove myself from the critical path and take (even more) of a background role.</p>

<p>Note that we had a nice growth in development activity, and that maintenance of the code itself has already been spread over multiple people for a while. I’m not the most active maintainer. Looking at the number of git merges</p>

<div><div><pre><code>bitcoin<span>$ </span>git log <span>--pretty</span><span>=</span><span>"format:%cn"</span> <span>--merges</span> <span>--since</span><span>=</span>2020-01-01 | <span>sort</span>| <span>uniq</span> <span>-c</span>
    313 fanquake
     51 Jonas Schnelli
    727 MarcoFalke
      7 Pieter Wuille
     65 Samuel Dobson
    363 Wladimir J. van der Laan
</code></pre></div></div>

<p>Only about 24% of the merges were done by me, last year.</p>

<h2 id="plans">plans</h2>

<p>But there’s plenty of things left to figure out, from the top of my head:</p>

<ul>
  <li>
    <p>Decentralize distribution.</p>

    <ul>
      <li>
        <p>In the short run, transfer bitcoincore.org to an organization instead of private ownership. Reduce the “bus factor”.</p>
      </li>
      <li>
        <p>I think it would be good if some other organizations set up mirrors, so there is less incentive to try to take bitcoincore.org down.</p>
      </li>
      <li>
        <p>In the long run, move away from a website for code distribution completely. No matter who owns it, a website on the clearnet can be shut down with the press of a button, and it seems that the global internet is gearing up to make censorship increasingly easy. We need a decentralized web. For us, one option would be IPFS, which is starting to catch on. For the binaries themselves there’s already the option of downloading through torrents.</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Decentralize the release process, and release signing.</p>

    <ul>
      <li>
        <p>Delegate more parts of the release process. Other maintainers should be able to do a release without my involvement.</p>
      </li>
      <li>
        <p>Rename the GPG key used to sign <code>SHA256SUMS.asc</code> to “Bitcoin Core release signing key”, instead of having it in my personal title. Make some construct so that N of M (minimally) trusted gitian signers doing a succesful build automatically results in a signed distribution.</p>
      </li>
      <li>
        <p>Same for the native code signing for Windows and MacOS.</p>
      </li>
      <li>
        <p>Even better in the long run would be to split up the keys, e.g. though RSA threshold signing, so that the whole process is geographically distributed.</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Decentralize the development hub.</p>

    <ul>
      <li>It’s not clear whether github can be trusted to act in our interest in the long run. Although issues and PRs are backed up through the API, having to move somewhere else could give significant interruption in development. And hopping from provider to provider would be awful—ideally the whole thing would not rely on a central server <em>at all</em>. For this I’ve been watching the <a href="https://radicle.xyz/">radicle</a> project, a P2P distributed code collaboration platform. It’s not quite there yet, but seems promising.</li>
    </ul>
  </li>
</ul>

<p>Bitcoin is quite different in some of the requirements here from other FOSS projects, so we’ll have to develop some tools as we go. We could also, definitely, use some help here.</p>

<p>Some smaller things to consider:</p>

<ul>
  <li>
    <p>Find someone else who wants to do the IRC meeting chair instead of me. Or maybe rotate it between multiple people.</p>
  </li>
  <li>
    <p>Release (and release candidate) mails to the <code>bitcoin-dev</code> and <code>bitcoin-core-dev</code> lists will no longer be necessarily signed and sent by me.</p>
  </li>
  <li>
    <p>There’s some development specific tooling hosted by me (e.g. the PR notification bots on IRC and mastodon). As they are non-critical and only little time goes into maintaining them, I’m fine with this for now.</p>
  </li>
</ul>

<p>As for decentralizing Bitcoin’s node software itself:</p>

<ul>
  <li>Carl Dong’s <code>libbitcoin_kernel</code> work. Bitcoin Core is a large monolithic project which includes the consensus code, which is much more critical than the other parts. The kernel would be an isolated part with well-defined interface, and at some point, its own review flow for changes. The difference with previous <code>libbitcoin_consensus</code> plans is that the kernel is stateful: it includes UTXO management and validation. It however does not include P2P, mempool policy, wallet, GUI, and RPC code. It could be re-used in different clients, to have more diversity in clients, but without the risks of a deviating consensus implementation.</li>
</ul>

<p>Over the course of 2021 this will be my focus with regard to Bitcoin Core.</p>

  </div></div>]]>
            </description>
            <link>https://laanwj.github.io/2021/01/21/decentralize.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25880727</guid>
            <pubDate>Sat, 23 Jan 2021 08:45:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WhatsApp facing up to €50M privacy fine]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25880609">thread link</a>) | @gr2zr4
<br/>
January 23, 2021 | https://www.politico.eu/article/whatsapp-privacy-fine-data-protection-europe-50-million/ | <a href="https://web.archive.org/web/*/https://www.politico.eu/article/whatsapp-privacy-fine-data-protection-europe-50-million/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
									<p>Facebook-owned messaging app WhatsApp could be fined up to €50 million over violations of the European Union's data protection rules, according to three people with direct knowledge of the procedure who spoke with POLITICO.</p>
<p>The preliminary penalty — the figure is now under consultation with the bloc's other data protection agencies — would be one of the largest-ever fines under the EU's General Data Protection Regulation, a set of privacy rules that came into force in 2018. </p>
<p>As part of Ireland's draft findings, the internet messenger may face a fine of between €30 million and €50 million for not living up to transparency requirements under Europe's privacy regime. Whatsapp could also be required to change how it handles its users' data, as the case relates to how the messenger may have failed to properly inform its EU users about how it would share their data with Facebook.</p>

<p>France's privacy authority <a href="https://www.cnil.fr/en/cnils-restricted-committee-imposes-financial-penalty-50-million-euros-against-google-llc" target="_blank">has fined</a> Google €50 million for separate privacy violations, while Ireland's Data Protection Commission, which has regulatory authority over Facebook, recently <a href="https://www.politico.eu/article/irish-data-regulator-fines-twitter-e450000/">issued</a> a €450,000 penalty against Twitter. That represented its first levy against any Silicon Valley company, many of which fall under Dublin's jurisdiction because these firms are legally domiciled in Ireland, mostly for tax reasons.</p>
<p>The multi-million euro draft WhatsApp fine is an initial proposal from Dublin, and has been opened up to other European data protection agencies for their feedback. A final decision on how big the fine should be — and what other remedies WhatsApp should agree to — is not expected until later in the year.</p>
<p>A spokesman for Ireland's Data Protection Commissioner declined to comment. A spokesman for WhatsApp said the company was awaiting the final privacy decision.</p>
<p>In November, Facebook&nbsp;<a href="https://www.politico.eu/?p=1521035">earmarked €77.5 million&nbsp;for a likely privacy fine against its messaging service WhatsApp,&nbsp;</a>which, unlike Instagram, is a separate legal entity in Ireland and therefore has its own set of financial records. The Irish data protection agency is conducting a separate investigation into whether WhatsApp can legally share its users' data with Facebook's other digital services, among other privacy-related concerns.</p>
<p>The draft penalty against WhatsApp, which Ireland <a href="https://www.politico.eu/?p=1577539">submitted</a> to other EU agencies for review just before Christmas, comes as the messenger faces a global backlash over planned updates to its terms and conditions. Those include&nbsp;clarifying to its billions of users how their data is shared more widely with Facebook's other services.</p>
<p>Those changes will not affect WhatsApp European operations, but people across the bloc and elsewhere still have flocked to rivals like Signal because of privacy fears. On January 15, the messenger <a href="https://blog.whatsapp.com/giving-more-time-for-our-recent-update" target="_blank">said</a> it was delaying the upcoming privacy changes, in part because of the confusion generated by the proposed overhaul.</p>

<p>Johannes Caspar, Hamburg's privacy regulator who filed objections to a previous Irish decision against Twitter, told POLITICO earlier this week that he<a href="https://www.politico.eu/?p=1579886"> had not ruled out </a>doing the same in the WhatsApp case. </p>
<p>"WhatsApp has an enormous amount of users," he said. "It must be clear that the consent mechanism they use must be lawful and that consent is informed and freely given by the users."</p>
								</div></div>]]>
            </description>
            <link>https://www.politico.eu/article/whatsapp-privacy-fine-data-protection-europe-50-million/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25880609</guid>
            <pubDate>Sat, 23 Jan 2021 08:15:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bournegol – Algol-like C dialect that Steve Bourne used to write Bourne shell]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25879517">thread link</a>) | @segfaultbuserr
<br/>
January 22, 2021 | http://oldhome.schmorp.de/marc/bournegol.html | <a href="https://web.archive.org/web/*/http://oldhome.schmorp.de/marc/bournegol.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<p><b>Last change: 2014-12-30</b></p>




While browsing, I found this except from the book <a href="http://www.amazon.com/exec/obidos/ASIN/1565922603/heinersshelldora/002-6407720-0447242">Unix Power Tools</a>:

<blockquote>
   ... To fix it, first get the source, and then change it in the obvious three places in xec.c. You will have to learn <strong>Bournegol</strong> [the ALGOL-like dialect of C that Steve Bourne used to
   write the original Bourne shell-JP ]. Another alternative is to replace /bin/sh with one of the free sh look-alikes... (CT in comp.unix.questions on Usenet, 20 February 1990)
</blockquote>

I immediately asked myself: what could Bournegol look like? Well,
it's not that easy to find the <a href="http://minnie.tuhs.org/UnixTree/V7/usr/src/cmd/sh/">original Bourne
Shell</a> sourcecode, so,
after some googling, I thought I might put an example of Bournegol on
my homepage, so other people have the chance to find about "Bournegol"
without the tedious search.<p>

(many years later I found <a href="http://www.collyer.net/who/geoff/sh.tour.ps">this
paper</a>, A Partial Tour Through
the UNIX Shell, which makes for very nice reading).

Ok, without any further ado, here is an excerpt of the file
<tt>xec.c</tt>, referenced above, supposedly from the <a href="http://minnie.tuhs.org/UnixTree/V7/usr/src/">7th Edition UNIX</a>, that gives you an
impression of bournegol:</p><pre>LOCAL INT	parent;

SYSTAB		commands;

/* ========	command execution	========*/

execute(argt, execflg, pf1, pf2)
	TREPTR		argt;
	INT		*pf1, *pf2;
{
	/* `stakbot' is preserved by this routine */
	REG TREPTR	t;
	STKPTR		sav=savstak();

	sigchk();

	IF (t=argt) ANDF execbrk==0
	THEN	REG INT		treeflgs;
		INT		oldexit, type;
		REG STRING	*com;

		treeflgs = t-&gt;tretyp; type = treeflgs&amp;COMMSK;
		oldexit=exitval; exitval=0;

		SWITCH type IN

		case TCOM:
			BEGIN
			STRING		a1;
			INT		argn, internal;
			ARGPTR		schain=gchain;
			IOPTR		io=t-&gt;treio;
			gchain=0;
			argn = getarg(t);
			com=scan(argn);
			a1=com[1]; gchain=schain;

			IF (internal=syslook(com[0],commands)) ORF argn==0
			THEN	setlist(t-&gt;comset, 0);
			FI

			IF argn ANDF (flags&amp;noexec)==0
			THEN	/* print command if execpr */
				IF flags&amp;execpr
				THEN	argn=0;	prs(execpmsg);
					WHILE com[argn]!=ENDARGS
					DO prs(com[argn++]); blank() OD
					newline();
				FI

				SWITCH internal IN

				case SYSDOT:
					IF a1
					THEN	REG INT		f;
	
						IF (f=pathopen(getpath(a1), a1)) &lt; 0
						THEN failed(a1,notfound);
						ELSE execexp(0,f);
						FI
					FI
					break;
	
				case SYSTIMES:
					{
					L_INT	t[4]; times(t);
					prt(t[2]); blank(); prt(t[3]); newline();
					}
					break;
	
				case SYSEXIT:
					exitsh(a1?stoi(a1):oldexit);
	
</pre>
[...]<br>
<pre>				case SYSTRAP:
					IF a1
					THEN	BOOL	clear;
						IF (clear=digit(*a1))==0
						THEN	++com;
						FI
						WHILE *++com
						DO INT	i;
						   IF (i=stoi(*com))&gt;=MAXTRAP ORF i&lt;MINTRAP
						   THEN	failed(*com,badtrap);
						   ELIF clear
						   THEN	clrsig(i);
						   ELSE	replace(&amp;trapcom[i],a1);
							IF *a1
							THEN	getsig(i);
							ELSE	ignsig(i);
							FI
						   FI
						OD
					ELSE	/* print out current traps */
						INT		i;
	
						FOR i=0; i&lt;MAXTRAP; i++
						DO IF trapcom[i]
						   THEN	prn(i); prs(colon); prs(trapcom[i]); newline();
						   FI
						OD
					FI
					break;
	
</pre>
[...]<br>
<pre>                                                   
		case TFORK:
			IF execflg ANDF (treeflgs&amp;(FAMP|FPOU))==0
			THEN	parent=0;
			ELSE	WHILE (parent=fork()) == -1
				DO sigchk(); alarm(10); pause() OD
			FI

			IF parent
			THEN	/* This is the parent branch of fork;    */
				/* it may or may not wait for the child. */
				IF treeflgs&amp;FPRS ANDF flags&amp;ttyflg
				THEN	prn(parent); newline();
				FI
				IF treeflgs&amp;FPCL THEN closepipe(pf1) FI
				IF (treeflgs&amp;(FAMP|FPOU))==0
				THEN	await(parent);
				ELIF (treeflgs&amp;FAMP)==0
				THEN	post(parent);
				ELSE	assnum(&amp;pcsadr, parent);
				FI

				chktrap();
				break;

</pre>
[...]<p>

(Note the <em>single</em> use of curly braces after <tt>case SYSTIMES</tt>. This
and the lowercase <tt>case</tt> let me believe this segment might have been
added at a later stage). The necesssary macro definitions to understand (if
you dare to try) the above excerpt can be found in the file <tt>mac.h</tt>:

</p><pre>/*
 *	UNIX shell
 *
 *	S. R. Bourne
 *	Bell Telephone Laboratories
 *
 */

#define LOCAL	static
#define PROC	extern
#define TYPE	typedef
#define STRUCT	TYPE struct
#define UNION	TYPE union
#define REG	register

#define IF	if(
#define THEN	){
#define ELSE	} else {
#define ELIF	} else if (
#define FI	;}

#define BEGIN	{
#define END	}
#define SWITCH	switch(
#define IN	){
#define ENDSW	}
#define FOR	for(
#define WHILE	while(
#define DO	){
#define OD	;}
#define REP	do_lbr
#define PER	}while(
#define DONE	);
#define LOOP	for(;;){
#define POOL	}


#define SKIP	;
#define DIV	/
#define REM	%
#define NEQ	^
#define ANDF	&amp;&amp;
#define ORF	||

#define TRUE	(-1)
#define FALSE	0
#define LOBYTE	0377
#define STRIP	0177
#define QUOTE	0200

#define EOF	0
#define NL	'\n'
#define SP	' '
#define LQ	'`'
#define RQ	'\''
#define MINUS	'-'
#define COLON	':'

#define MAX(a,b)	((a)&gt;(b)?(a):(b))
</pre><p>

Hope you found this interesting ;)


</p><p><img src="http://oldhome.schmorp.de/marc/images/hbar.gif" alt="=======================================================" images="" hbar.gif="" gif="" 775x16="" 775x16+0+0="" pseudoclass="" 8c="" 381=""></p>
<p>Any questions/hints/critics? Contact the <a href="mailto:pcg@goof.com">author</a> of this page!





                  

</p></div>]]>
            </description>
            <link>http://oldhome.schmorp.de/marc/bournegol.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25879517</guid>
            <pubDate>Sat, 23 Jan 2021 04:01:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Rysolv – Fix open source issues, get paid]]>
            </title>
            <description>
<![CDATA[
Score 128 | Comments 39 (<a href="https://news.ycombinator.com/item?id=25879238">thread link</a>) | @themanmaran
<br/>
January 22, 2021 | https://rysolv.com/issues | <a href="https://web.archive.org/web/*/https://rysolv.com/issues">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://rysolv.com/issues</link>
            <guid isPermaLink="false">hacker-news-small-sites-25879238</guid>
            <pubDate>Sat, 23 Jan 2021 03:14:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Primer on How to Work with the Usenet Community (1984)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25878578">thread link</a>) | @nkurz
<br/>
January 22, 2021 | https://www.krsaborio.net/internet/research/1984/0603.htm | <a href="https://web.archive.org/web/*/https://www.krsaborio.net/internet/research/1984/0603.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.krsaborio.net/internet/research/1984/0603.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-25878578</guid>
            <pubDate>Sat, 23 Jan 2021 01:20:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Role of Discomfort in Decision Making]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25878526">thread link</a>) | @ruborcalor
<br/>
January 22, 2021 | https://colekillian.com/posts/discomfort/ | <a href="https://web.archive.org/web/*/https://colekillian.com/posts/discomfort/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<p>Discomfort, a slight physical or emotional pain, developed as an evolutionary necessity; historically, considering the unpleasantness of discomfort during decision making was for the best of the species. Berries make your stomach uneasy? Stop eating them. Prickly bush scratches your skin? Don’t let it happen again.</p>
<p>On average your body does a good job correlating discomfort with actions that are bad for your well being, but it’s important to note that your body isn’t right 100% of the time!</p>
<p>The world has changed a lot since we developed the capacity to feel discomfort. I claim that people would be better off if they were to diminish or even eliminate the role that discomfort plays in the decision making process, opting instead for considering “long term” consequences. At least personally, this mentality shift has had a huge positive impact on my day to day life.</p>

<p>There are many things that people know they should be doing try to do but can’t do with success:</p>
<ul>
<li>eating healthy</li>
<li>getting 8 hours of sleep a night</li>
<li>exercising regularly</li>
<li>taking cold showers</li>
</ul>
<p>A common reason people don’t commit to these resolutions is that they rationalize them away on the basis of the required discomfort. People don’t want to miss out on the taste of junk food, or deal with the pain of a work out. After removing discomfort, the only reason left not to do build these healthy habits would be the cost of time, but even the busiest people can carve out a little bit of time for these activities that have much higher returns than the time investment (yes even you!).</p>

<p>Since the new year I have started every morning with a 20 minute workout. My workout consists of handstand pushups, pullups, hanging leg raises, and stretching. By framing the workout as having a cost of 20 minutes and forgetting about the discomfort I will experience during the workout, I am having an easier time maintaining the habit (knock on wood). It takes just 20 minutes and leaves me feeling energized for the rest of the day.</p>
<p>After my workout I hop into a cold shower. Similarly, I dispell thoughts relating to the discomfort of the cold water, and instead phrase the cold shower as a healthy experience that will take just 5 minutes. I wake right up and feel warm as soon as I get out of the cold.</p>

<p>The previous examples were activites of relatively minor discomfort that have compounding positive effects when incorporating them into daily life. Another benefit of making them ritual is to prepare you for dire needs which may include:</p>
<ul>
<li>a necessary confrontation</li>
<li>asking someone out</li>
<li>asking for a raise</li>
<li>building moral courage</li>
<li>generally getting out of one’s comfort zone</li>
</ul>
<p>These are the types of scenarios where people often regret not stepping out of their comfort zones; by building a tolerance for discomfort you will more easily take them on.</p>
<blockquote>
<p>Keep the faculty of effort alive in you by a little gratuitous exercise every day. Do every day or two something for no other reason than that you would rather not do it, so that when the hour of dire needs draws nigh, it may find you not unnerved and untrained to stand the test - The Way To Willpower</p>
</blockquote>

<p>I hope that this mentality shift is as helpful to you as it was to me. Please leave any comments or reflections below :)</p>
</div></div>]]>
            </description>
            <link>https://colekillian.com/posts/discomfort/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25878526</guid>
            <pubDate>Sat, 23 Jan 2021 01:13:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Databricks Raising a Private Round at $27B]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25877748">thread link</a>) | @zuhayeer
<br/>
January 22, 2021 | https://www.newcomer.co/p/sources-databricks-raising-at-27 | <a href="https://web.archive.org/web/*/https://www.newcomer.co/p/sources-databricks-raising-at-27">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Databricks — a data and AI platform — is in talks to raise a private funding round that could value the company at about $27 billion.</p><p>It seems like the private deal is being done by buyside public investors, though I don’t know who is winning out, if it’s been decided, or how much they’re investing.</p><p>I’ve been hearing a lot about Databricks recently. For one, it has a similar investor story to Snowflake, and we saw the appetite on the public stock market for that company. Investors seem to want exposure to horizontal cloud computing companies outside of big tech. I’ve also been deep in the world of Andreessen Horowitz and this is an extremely important company for the portfolio. Andreessen Horowitz led Series A, D, and E rounds, according to Pitchbook. NEA led the Series B and C. </p><p>A spokesperson for Databricks declined to comment.</p><div><p>Mostly I care because it’s a huge frothy-sounding number that no one has reported so far.</p><p>Have a nice weekend. </p></div></div></div>]]>
            </description>
            <link>https://www.newcomer.co/p/sources-databricks-raising-at-27</link>
            <guid isPermaLink="false">hacker-news-small-sites-25877748</guid>
            <pubDate>Fri, 22 Jan 2021 23:36:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SymQEMU: Compilation-based symbolic execution for binaries]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25877317">thread link</a>) | @homarp
<br/>
January 22, 2021 | http://s3.eurecom.fr/tools/symbolic_execution/symqemu.html | <a href="https://web.archive.org/web/*/http://s3.eurecom.fr/tools/symbolic_execution/symqemu.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  

  <blockquote>
    <p>
      SymQEMU: Compilation-based symbolic execution for binaries
    </p>
    
    <em>Proceedings of the Network and Distributed System Symposium (NDSS 2021),
    San Diego, CA, USA</em>
    
    
    <p>
      Symbolic execution is a powerful technique for software analysis and bug
      detection. Compilation-based symbolic execution is a recently proposed
      flavor that has been shown to improve the performance of symbolic
      execution significantly when source code is available. We demonstrate a
      novel technique to enable compilation-based symbolic execution of binaries
      (i.e., without the need for source code). Our system, SymQEMU, builds on
      top of QEMU, modifying the intermediate representation of the target
      program before translating it to the host architecture. This enables
      SymQEMU to compile symbolic-execution capabilities into binaries and reap
      the associated performance benefits while maintaining architecture
      independence.
    </p>
    
    <p>
      We present our approach and implementation, and we show that it
      outperforms the state-of-the-art binary symbolic executors S2E and QSYM
      with statistical significance; on some benchmarks, it even achieves better
      performance than the source-based SymCC. Moreover, our tool has found a
      previously unknown vulnerability in the well-tested libarchive library,
      demonstrating its utility in testing real-world software.
    </p>
  </blockquote>

  <h2 id="intro">Introduction</h2>

  <p>
    SymQEMU is a fast symbolic execution engine for binaries. On this page, we
    provide its source code, the raw results of the experiments described in the
    paper, and instructions how you can replicate those experiments yourself.
  </p>

  <h2>Code</h2>

  <p>
    SymQEMU is available
    on <a href="https://github.com/eurecom-s3/symqemu">GitHub</a>.
  </p>

  <h2>Experiments</h2>

  <p>
    In the paper, we describe three sets of experiments: we first benchmark
    SymQEMU with Google FuzzBench, then we run it on real-world software, and
    finally we perform a benchmark comparison during concolic execution of fixed
    paths. This section describes how to replicate our experiments, and provides
    links to our results.
  </p>

  <ol>
    <li>
      <p>
        FuzzBench (see the <a href="http://s3.eurecom.fr/~seba/2020-05-24-symqemu.zip">report</a>)
      </p>

      <p>
        We will share our integration scripts shortly; they're being cleaned up
        to obtain SymQEMU and its dependencies from the new public repository.
      </p>
    </li>

    <li>
      <p>Real-world software</p>

      <p>
        For the analysis of real-world software we used the same setup as in the
        <a href="http://s3.eurecom.fr/tools/symbolic_execution/symcc.html">evaluation of SymCC</a>. The binaries for SymQEMU,
        QSYM and S2E were plain builds without any instrumentation. SymQEMU was
        run via SymCC's fuzzing helper by prefixing the target command
        with <tt>/path/to/symqemu-x86_64</tt>. For the S2E analysis, we created
        a default project, then enabled the <tt>FunctionModels</tt> plugin and
        activated the option <tt>generateOnStateFork</tt> in
        the <tt>TestCaseGenerator</tt> plugin; coverage was evaluated
        with <tt>afl-showmap</tt> at the end of the analysis, using the same
        AFL-instrumented binaries as with the hybrid fuzzers.
      </p>

      <ul>
          <li>
            OpenJPEG
            (<a href="http://www.s3.eurecom.fr/~seba/symqemu_afl_openjpeg.tar.gz">our
            results</a>), libarchive
            (<a href="http://www.s3.eurecom.fr/~seba/symqemu_afl_libarchive.tar.gz">our
            results</a>), tcpdump
            (<a href="http://www.s3.eurecom.fr/~seba/symqemu_afl_tcpdump.tar.gz">our
            results</a>): please find the details on
            our <a href="http://s3.eurecom.fr/tools/symbolic_execution/symcc.html">SymCC page</a>.
          </li>

          <li>
            <a href="https://www.rarlab.com/download.htm">WinRAR</a>
            (<a href="http://www.s3.eurecom.fr/~seba/symqemu_afl_rar.tar.gz">our
            results</a>): we downloaded version 6.00 for 64-bit Linux.
          </li>
        </ul>
      
    </li>

    <li>
      <p>
        Benchmark experiments
          (<a href="http://www.s3.eurecom.fr/~seba/symqemu_benchmark.tar.gz">our
          results</a>)
      </p>

      <p>
        After the analysis of real-world software described above, we randomly
        collected 1,000 generated test cases per open-source target. We ran
        SymQEMU, QSYM and SymCC on each of those inputs, recording the time
        spent in execution and SMT solving, respectively, as per the logging
        output from the QSYM backend.
      </p>
    </li>
  </ol>

  <h2>Acknowledgements</h2>

  <p>
    This work has been supported partly by the DAPCODS/IOTics ANR 2016 project
    (ANR-16-CE25-0015) and partly by the Defense Advanced Research
    Projects Agency (DARPA) under agreement number FA875019C0003.
  </p>

  <h2>Contact</h2>

  <p>
    Feel free to <a href="http://www.s3.eurecom.fr/~seba/">reach out</a> to us
    if anything is unclear or if you need more information.
  </p>
</div></div>]]>
            </description>
            <link>http://s3.eurecom.fr/tools/symbolic_execution/symqemu.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25877317</guid>
            <pubDate>Fri, 22 Jan 2021 22:54:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Analog Computer Inside Prime Minister]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25877102">thread link</a>) | @homarp
<br/>
January 22, 2021 | http://www.insidegmt.com/2021/01/the-analog-computer-inside-prime-minister/ | <a href="https://web.archive.org/web/*/http://www.insidegmt.com/2021/01/the-analog-computer-inside-prime-minister/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<div><figure><img loading="lazy" width="657" height="217" src="http://www.insidegmt.com/wp-content/uploads/2021/01/PrimeMinister_banner2.jpg" alt="" srcset="http://www.insidegmt.com/wp-content/uploads/2021/01/PrimeMinister_banner2.jpg 657w, http://www.insidegmt.com/wp-content/uploads/2021/01/PrimeMinister_banner2-300x99.jpg 300w, http://www.insidegmt.com/wp-content/uploads/2021/01/PrimeMinister_banner2-518x171.jpg 518w, http://www.insidegmt.com/wp-content/uploads/2021/01/PrimeMinister_banner2-82x27.jpg 82w, http://www.insidegmt.com/wp-content/uploads/2021/01/PrimeMinister_banner2-600x198.jpg 600w" sizes="(max-width: 657px) 100vw, 657px"></figure></div>



<p><span title="G">G</span>lance at <em>Prime Minister</em>’s game board and player mats, and the first thing you’ll notice are all the numbers. The most important one is 330: the number of seats you need for a majority in the House of Commons. In this article, we’ll take a look at <em>Prime Minister</em>’s numerical side, with a focus on its measurement of public opinion.</p>



<p>At the heart of the game is an analog computer simulating the Victorian-era British political system. It tracks and links about 30 different political factors, including Parliament’s confidence in each player, each party’s popular support in eight key sectors of the electorate, current election projections, the number of government MPs and their “moderate” or “partisan” inclinations, projected votes on the government’s bills, the “uncertainty” factor in elections and Parliamentary votes, and Queen Victoria’s support for different players. By reducing these factors to numerical values and structuring their relationships, this analog computer decides who gets to lead each party, which party controls the government, and what bills the government can pass. Whoever does the best job of manipulating the factors controls the system and gets an edge in the game.</p>



<div><figure><a href="http://www.insidegmt.com/wp-content/uploads/2021/01/PM_1.png"><img loading="lazy" width="977" height="550" src="http://www.insidegmt.com/wp-content/uploads/2021/01/PM_1.png" alt="" srcset="http://www.insidegmt.com/wp-content/uploads/2021/01/PM_1.png 977w, http://www.insidegmt.com/wp-content/uploads/2021/01/PM_1-300x169.png 300w, http://www.insidegmt.com/wp-content/uploads/2021/01/PM_1-768x432.png 768w, http://www.insidegmt.com/wp-content/uploads/2021/01/PM_1-760x428.png 760w, http://www.insidegmt.com/wp-content/uploads/2021/01/PM_1-518x292.png 518w, http://www.insidegmt.com/wp-content/uploads/2021/01/PM_1-82x46.png 82w, http://www.insidegmt.com/wp-content/uploads/2021/01/PM_1-600x338.png 600w" sizes="(max-width: 977px) 100vw, 977px"></a></figure></div>



<p>Here you can see a partial snapshot of <em>Prime Minister</em>’s game board, showing the most detailed part of its analog computer: the eight key sectors of the electorate. They include a mix of geographic, social, and ideological groups: Conservatives, Farmers, the Gentry, Ireland, Liberals, the Middle Class, Scotland, and Workers. You’ll track support for each party in each sector, moving wooden markers up and down the numerical tracks. The side with the blue rosette tracks support for the Conservative Party, and the side with the orange rosette does the same for the Liberal Party. The green circles indicate each party’s starting position in the game’s standard setup. During the game, you’ll encounter icons from bills, events, and actions that tell you when to move the markers up and down a track. By moving a marker up one step, you earn one to three popularity points, depending on the sector and your current position. The popularity points that each party earns in the different sectors are added up, and the total relative point difference between the parties determines projections for the next election.</p>



<p>The eight sectors overlap so that one voter might belong to several different sectors at once. For example, a landowner in Scotland might belong to the Conservatives, Gentry, Farmer, and Scotland sectors. The Conservative Party might win his vote by appealing to his ideological identity as a Conservative, or the Liberal Party might win his vote by appealing to his geographic Scots identity. A sector’s significance in each election varies depending on the parties’ respective strategies. If both parties neglect Farmers, then Farmers will have no significance. But if the Conservative Party maxes out its popularity among Farmers while the Liberal Party earns nothing there, the Farmers sector will weigh heavily in the next election–not only because Farmers prefer the Conservative Party, but because they have been motivated to vote according to their economic interests.</p>



<p>Different sectors have different point spreads, reflecting their importance in the Victorian-era electorate. In this era, most British subjects didn’t have the right to vote, so the point spreads aren’t simply based on population distribution. They’re based on the number of voters and each sector’s overall impact on the election results, factoring in the value of campaign contributions, endorsements, and other means of influence. This is why the Gentry sector has more points than Workers, despite being a much smaller slice of the population.</p>



<p>As the game progresses, parties will reach maximum or minimum values in some sectors. These maximums and minimums affect the game’s strategy and evoke real-life political effects. No matter how strongly Scotland prefers one party over another, Scotland’s impact is limited by the number of voters in Scotland. Once the Conservative Party has maxed out its popularity in Scotland, it can gain nothing more there; it must look for additional points in other sectors while being careful not to rock the boat in Scotland. Conversely, once the Conservative Party has bottomed out in Ireland, it has nothing more to lose there and incurs no further penalty for continuing to neglect the Irish–a circumstance which may become useful. As in real life, the parties and politicians in <em>Prime Minister </em>can’t please everyone all the time. When faced with hard choices, they favor their political patrons and write off sectors that are unimportant to them. If there’s a rail disaster in Scotland, a Conservative Prime Minister (PM) will be forced to deal with it if he wants to retain his party’s support there. But if a problem surfaces in Ireland, the same PM might choose to ignore it and focus on something else, knowing that his party can’t do any worse in Ireland.</p>



<p>In addition to tracking popular support, the sectors also track the public’s mood for partisanship, which in turn can result in “partisan” MPs who support more radical bills. The game board measures public partisanship through “red points” that are printed side-by-side next to the total points for some sectors. Not every sector produces red points. For example, the Middle Class–not known for favoring radicalism–doesn’t generate any red points. At the other end of the spectrum, the ideological sectors (Conservatives and Liberals) produce only red points. Red points are always party-specific. If a sector offers red points, it offers them to one party only. By appealing to Workers, the Liberal Party can earn up to 7 red points, reflecting the support of radical Workers who favor partisan Liberal MPs. The Conservative Party can also earn popularity points in the Workers sector, but can’t earn any red points there because Workers who support the Conservative Party prefer moderate MPs.</p>



<p>Each sector has its own flavor and strategic impact. Both parties are free to pursue popularity in any sector–the Conservative Party may pursue a limited number of points in the Liberals sector, for example–but some sectors have a natural affinity or resistance to a particular party. In pursuing popular support in the different sectors, players have to think not only about the raw number of points they earn, but also the difficulty of holding particular sectors. Scotland has the fewest points, but it’s the most stable sector. Scotland’s interests aren’t directly implicated in the hot-button political issues of the day, so there are no bills that upset the Scots. The Middle Class is equally open to both parties and offers more points than Scotland, but is somewhat harder to hold owing to its more sensitive economic and moral preferences. Players also need to think about maintaining a coherent moderate or partisan strategy. The sectors for Conservatives and Liberals are the richest in points, making them tempting targets early in the game. But appealing to voters’ partisanship results in partisan MPs who favor divisive bills that could come back to haunt you. And if your government is equally split between moderate and partisan MPs, you may have a hard time getting them to agree on legislation.</p>



<p>In standard games, <em>Prime Minister</em>’s framework supports an open-ended format in which players strive to control government, win elections, and pass bills. Different politician abilities and about 200 unique cards ensure that no two games are the same. The same framework also supports specific scenarios that simulate historical problems, like home rule for Ireland or the repeal of the Corn Laws. Automated “Clockwork” politicians can readily function within the game’s system, opening the door to solitaire play.</p>



<p>Players have a wide variety of ways to interact with the game, starting with an action point system that allows you to perform a variable number of actions per turn. Depending on your current player mat and your politician’s fixed abilities, you can campaign to increase your party’s popularity in particular sectors, debate for or against bills, flatter Her Majesty to gain her favor, or influence MPs to make them more moderate or partisan. You can also draw “supporter” cards featuring influential Victorians who perform actions on your behalf. You’ll always have many things to do and not enough action cubes to spend, forcing you to prioritize your actions while anticipating future events. The PM’s response to random events and Parliament’s enactment of important bills have consequences that ripple through the system. The players and parties are in a constant tug of war. Collecting the right supporters, unleashing them at the right moment, and coordinating your actions with other players can help you achieve a breakthrough. But the game is not all about numbers. Relationships between players also factor heavily in the game, particularly in its 3- or 4-player mode. We’ll take a look at the players’ roles and relationships in the next <em>InsideGMT</em> article for <em>Prime Minister</em>.</p>



<hr>



<div><figure><a href="https://www.gmtgames.com/p-906-prime-minister.aspx"><img loading="lazy" width="657" height="217" src="http://www.insidegmt.com/wp-content/uploads/2021/01/PrimeMinister_banner3.jpg" alt="" srcset="http://www.insidegmt.com/wp-content/uploads/2021/01/PrimeMinister_banner3.jpg 657w, http://www.insidegmt.com/wp-content/uploads/2021/01/PrimeMinister_banner3-300x99.jpg 300w, http://www.insidegmt.com/wp-content/uploads/2021/01/PrimeMinister_banner3-518x171.jpg 518w, http://www.insidegmt.com/wp-content/uploads/2021/01/PrimeMinister_banner3-82x27.jpg 82w, http://www.insidegmt.com/wp-content/uploads/2021/01/PrimeMinister_banner3-600x198.jpg 600w" sizes="(max-width: 657px) 100vw, 657px"></a></figure></div>

	</div></div>]]>
            </description>
            <link>http://www.insidegmt.com/2021/01/the-analog-computer-inside-prime-minister/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25877102</guid>
            <pubDate>Fri, 22 Jan 2021 22:29:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Linux Unplugged 308: The One About GPU Passthrough]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25876995">thread link</a>) | @tambourine_man
<br/>
January 22, 2021 | https://linuxunplugged.com/308 | <a href="https://web.archive.org/web/*/https://linuxunplugged.com/308">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  


<header>
  <div>
    <div>
        <h5>Episode 308</h5>
      

      <div>
          
<div id="fireside-player" data-started="false" data-theme="minimal-dark" data-player-type="embed" data-player-download="https://chtbl.com/track/392D9/aphid.fireside.fm/d/1437767933/f31a453c-fa15-491f-8618-3f71f1d565e5/5f78aaf3-0565-405c-8685-a5c0e56f7843.mp3" data-player-duration="3406" data-player-share="/308" data-player-theme="minimal-dark" data-player-time="0">
  

  <div>
    <p><audio preload="none">
      <source src="https://media.fireside.fm/file/fireside-audio/podcasts/audio/f/f31a453c-fa15-491f-8618-3f71f1d565e5/episodes/5/5f78aaf3-0565-405c-8685-a5c0e56f7843/5f78aaf3-0565-405c-8685-a5c0e56f7843.mp3" type="audio/mpeg">
      Your browser does not support the audio tag.
    </audio></p>

    

    

    

    </div>

  

</div>

      </div>
      <div>
        <div>
          <p>
            <i></i>
            July 2nd, 2019
          </p>
          <p>
            <i></i>
            56 mins 46 secs
          </p>
        </div>
        
      </div>
      <div>
        
        <div>
            <h5>
              Special Guest
            </h5>
            <ul>
                <li>
                  <a title="Alex Kretzschmar" href="https://linuxunplugged.com/guests/alexktz">
                    <img src="https://assets.fireside.fm/file/fireside-images/podcasts/images/f/f31a453c-fa15-491f-8618-3f71f1d565e5/guests/7/7b468271-67fc-4c41-88a7-d883cb0c436d/avatar_small.jpg?v=1">
</a>                </li>
            </ul>
        </div>
      </div>
        <h5>Tags</h5>
        
    </div>
  </div>
</header>

<nav>
  <ul>
      <li><a href="https://linuxunplugged.com/rss"> RSS</a></li>
      <li><a href="https://itunes.apple.com/us/podcast/linux-unplugged-podcast/id687598126"><i></i> Apple Podcasts</a></li>
      <li><a href="https://podcasts.google.com/?feed=aHR0cHM6Ly9mZWVkcy5maXJlc2lkZS5mbS9saW51eHVucGx1Z2dlZC9yc3M="><i></i> Google Podcasts</a></li>
      <li><a href="https://playmusic.app.goo.gl/?ibi=com.google.PlayMusic&amp;isi=691797987&amp;ius=googleplaymusic&amp;apn=com.google.android.music&amp;link=https://play.google.com/music/m/I2hmp7hkpuqnu7qnbw5k46ngray?t%3DLINUX_Unplugged%26pcampaignid%3DMKT-na-all-co-pr-mu-pod-16"><i></i> Google Play</a></li>
      <li><a href="https://castbox.fm/channel/LINUX-Unplugged-id2120644?country=us"><i></i> Castbox</a></li>
      <li><a href="https://overcast.fm/itunes687598126/linux-unplugged-podcast"><i></i> Overcast</a></li>
      <li><a href="http://pca.st/itunes/687598126"><i></i> Pocket Casts</a></li>
      <li><a href="https://radiopublic.com/linux-unplugged-G2BldG"><i></i> RadioPublic</a></li>
      <li><a href="https://www.iheart.com/podcast/256-linux-unplugged-31099185/"><i></i> iHeartRadio</a></li>
      <li><a href="https://open.spotify.com/show/7bVFJvj8A2ZuYVs5lS992b"><i></i> Spotify</a></li>
      <li><a href="https://www.stitcher.com/podcast/jupiter-broadcasting/linux-unplugged"><i></i> Stitcher</a></li>
      <li><a href="https://tunein.com/podcasts/Technology-Podcasts/LINUX-Unplugged-p1136199/"><i></i> TuneIn</a></li>
      <li>
    <a href="#share_modal" data-modal=""> Share</a>
  </li>

  </ul>
</nav>


<section>
  <div>
    

    <p>Our crew walks you through their PCI Passthrough setups that let them run Windows, macOS, and distro-hop all from one Linux machine.</p>

<p>Forget multiple partitions, dual booting, and Hackintoshes; you can do it all with Linux and KVM.</p>

<p>Near-native VM performance doesn't have to be painful. You only need a few prerequisites and a little help. </p>


      <p><a target="_blank" rel="payment" href="https://jupitersignal.memberful.com/checkout?plan=52946">Support LINUX Unplugged</a></p>
      <ul>
        <li><a title="Windows VirtIO Drivers" rel="nofollow" href="https://www.linux-kvm.org/page/WindowsGuestDrivers/Download_Drivers">Windows VirtIO Drivers</a> — 64-bit versions of Windows Vista and newer require the drivers to be digitally signed.</li><li><a title="Alex's arch-vfio-ovmf scripts" rel="nofollow" href="https://github.com/IronicBadger/arch-vfio-ovmf">Alex's arch-vfio-ovmf scripts</a> — Arch Linux installation and VFIO setup scripts
</li><li><a title="Looking Glass - Quickstart Guide" rel="nofollow" href="https://looking-glass.hostfission.com/quickstart">Looking Glass - Quickstart Guide</a> — These guides are designed to help you get Looking Glass up and running on an already configured QEMU KVM Virtual Machine that has a VGA PCI Passthrough device. </li><li><a title="duncanthrax/scream" rel="nofollow" href="https://github.com/duncanthrax/scream#using-ivshmem-between-windows-guest-and-linux-host">duncanthrax/scream</a> — Scream is a virtual device driver for Windows that provides a discrete sound device. Audio played through this device is published on your local network as a PCM multicast stream.

</li><li><a title="ACS patch COPR" rel="nofollow" href="https://copr.fedorainfracloud.org/coprs/jlay/kernel-acspatch/">ACS patch COPR</a> — Fedora kernels with add-acs-overrides patch from Arch AUR</li><li><a title="ACS Override Kernel Builds" rel="nofollow" href="https://queuecumber.gitlab.io/linux-acs-override/">ACS Override Kernel Builds</a> — This page contains links to the latest kernel builds with the ACS override patch applied for PCI devices.

</li><li><a title="natalie-/fedora-acs-override" rel="nofollow" href="https://github.com/natalie-/fedora-acs-override">natalie-/fedora-acs-override</a> — Using the ACS override patch for Fedora</li><li><a title="VFIO tips and tricks: IOMMU Groups, inside and out" rel="nofollow" href="https://vfio.blogspot.com/2014/08/iommu-groups-inside-and-out.html">VFIO tips and tricks: IOMMU Groups, inside and out</a> — Sometimes VFIO users are befuddled that they aren't able to separate devices between host and guest or multiple guests due to IOMMU grouping and revert to using legacy KVM device assignment, or as is the case with may VFIO-VGA users, apply the PCIe ACS override patch to avoid the problem. &nbsp;Let's take a moment to look at what this is really doing.
</li><li><a title="&quot;Error 43: Driver failed to load&quot; on Nvidia GPUs passed to Windows VMs" rel="nofollow" href="https://wiki.archlinux.org/index.php/PCI_passthrough_via_OVMF#%22Error_43:_Driver_failed_to_load%22_on_Nvidia_GPUs_passed_to_Windows_VMs">"Error 43: Driver failed to load" on Nvidia GPUs passed to Windows VMs</a> — Since version 337.88, Nvidia drivers on Windows check if an hypervisor is running and fail if it detects one, which results in an Error 43 in the Windows device manager. Starting with QEMU 2.5.0 and libvirt 1.3.3, the vendor_id for the hypervisor can be spoofed, which is enough to fool the Nvidia drivers into loading anyway.</li><li><a title="Mac OS Adds Early Support for VirtIO, Qemu - The Passthrough POST" rel="nofollow" href="https://passthroughpo.st/mac-os-adds-early-support-for-virtio-qemu/">Mac OS Adds Early Support for VirtIO, Qemu - The Passthrough POST</a> — In a new development uncovered by Qemu developer Gerd Hoffmann, Apple has apparently added early support for VirtIO and framebuffer graphics in a later Mac OS Mojave release.
</li><li><a title="New and Improved Mac OS Tutorial, Part 1 (The Basics) - The Passthrough POST" rel="nofollow" href="https://passthroughpo.st/new-and-improved-mac-os-tutorial-part-1-the-basics/">New and Improved Mac OS Tutorial, Part 1 (The Basics) - The Passthrough POST</a> — Due to certain recent developments, It’s become clear to us that it’s necessary to update and improve our OSX VM guide. A lot’s changed since we wrote it, and rolling in those changes will make the process much more user friendly and accessible to newer VFIO users.

</li><li><a title="Mac OS VM Guide Part 2 (GPU Passthrough and Tweaks) - The Passthrough POST" rel="nofollow" href="https://passthroughpo.st/mac-os-vm-guide-part-2-gpu-passthrough-and-tweaks/">Mac OS VM Guide Part 2 (GPU Passthrough and Tweaks) - The Passthrough POST</a> — We’ve made every attempt to make this as straightforward as possible, but there’s a lot more ground to cover here than in the first part of the guide</li><li><a title="UGREEN USB 3.0 Sharing Switch Selector 4 Port 2 Computers Peripheral Switcher Adapter Hub for PC, Printer, Scanner, Mouse, Keyboard with One Button Swapping" rel="nofollow" href="https://www.amazon.com/UGREEN-Selector-Computers-Peripheral-Switcher/dp/B01N6GD9JO/ref=sr_1_3?keywords=usb+switcher&amp;qid=1561573709&amp;s=gateway&amp;sr=8-3">UGREEN USB 3.0 Sharing Switch Selector 4 Port 2 Computers Peripheral Switcher Adapter Hub for PC, Printer, Scanner, Mouse, Keyboard with One Button Swapping</a> — This USB Switch 4 Port device allows up to 2 users to share 4 USB 3.0 peripheral devices, such as printer,scanner,mouse,keyboard or usb disk etc without the need to constantly swap cables or set up complicated network sharing software. It's a great for use at home if you have multiple PCs or Macs.</li><li><a title="How to setup VFIO GPU passthrough using OVMF and KVM on Arch Linux" rel="nofollow" href="https://blog.linuxserver.io/2017/04/28/how-to-setup-vfio-gpu-passthrough-using-ovmf-and-kvm-on-arch-linux/">How to setup VFIO GPU passthrough using OVMF and KVM on Arch Linux</a> — This article will detail the steps required to passthrough your GPU to a guest VM which will in our case be a Windows 10 VM used for gaming. Yes, this is the exact same technology made popular by Linus on his LinusTechTips YouTube channel in the seven gamers, one CPU video.</li><li><a title="Chris' HDMI Monitor 1920x1080 16: 9 LCD Screen" rel="nofollow" href="https://www.amazon.com/gp/product/B0762NKY3D/">Chris' HDMI Monitor 1920x1080 16: 9 LCD Screen</a></li><li><a title="Lenovo G0A10170UL Thunderbolt 3 Graphics Dock" rel="nofollow" href="https://www.amazon.com/Lenovo-G0A10170UL-Thunderbolt-Graphics-Dock/dp/B079JFW3YT">Lenovo G0A10170UL Thunderbolt 3 Graphics Dock</a> — Amplify your ultrabook’s graphics performance with the integrated NVIDIA GeForce GTX 1050 graphics card. </li><li><a title="Mantiz Venus MZ-02 External Graphic Enclosure eGPU" rel="nofollow" href="https://www.amazon.com/gp/product/B0745H6GTX/ref=ppx_yo_dt_b_asin_title_o09_s00?ie=UTF8&amp;psc=1">Mantiz Venus MZ-02 External Graphic Enclosure eGPU</a> — Connects Full High Full Length 120" Width 2.5 PCIE Desktop Power GPU to computer WITH an Intel Certified Thunderbolt 3 port.</li><li><a title="Synergy" rel="nofollow" href="https://symless.com/synergy">Synergy</a> — Synergy is a software download that shares one mouse and one keyboard between multiple computers. Simply move your mouse between your computers effortlessly</li><li><a title="barrier: Open-source KVM software" rel="nofollow" href="https://github.com/debauchee/barrier">barrier: Open-source KVM software</a> — Barrier is KVM software forked from Symless's synergy 1.9 codebase. Synergy was a commercialized reimplementation of the original CosmoSynergy written by Chris Schoeneman.

</li><li><a title="foxlet/macOS-Simple-KVM" rel="nofollow" href="https://github.com/foxlet/macOS-Simple-KVM/">foxlet/macOS-Simple-KVM</a> — Documentation to set up a simple macOS VM in QEMU, accelerated by KVM.

</li>
      </ul>

  </div>

  
</section>


  <nav>
      <a href="https://linuxunplugged.com/307">← Previous episode</a>
      <a href="https://linuxunplugged.com/309">Next episode →</a>
  </nav>
</div></div>]]>
            </description>
            <link>https://linuxunplugged.com/308</link>
            <guid isPermaLink="false">hacker-news-small-sites-25876995</guid>
            <pubDate>Fri, 22 Jan 2021 22:17:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Craft of Experimental Physics]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25876989">thread link</a>) | @mdturnerphys
<br/>
January 22, 2021 | http://www.jameshedberg.com/writing/2015/02/01/the-craft-of-experimental-physics.html | <a href="https://web.archive.org/web/*/http://www.jameshedberg.com/writing/2015/02/01/the-craft-of-experimental-physics.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>In the basement of the Argosy Book Store, I found a collection of essays from 1933. The one that prompted the purchase of the book was entitled: The Craft of Experimental Physics, by P.M.S. Blackett. Though written more than 80 years ago, the salient points are just as relevant today. I might go so far as to say it should be required reading for both newcomers to the field, as well as for established lab rats. Aside from a few ‘old fashioned’ tendencies (gender specific pronouns being the most notable) and dated technologies mentioned (a valve is a vacuum tube), the essay should resonate with all who have spent a few years poking around the dark corners of Nature with their fingers. Here are some selected passages. (A link to the whole pdf is below)</p>

<blockquote>
  <p>For the experimental physicist is a Jack-of-All Trades, a versatile but amateur craftsman. He must blow glass and turn metal, though he could not earn his living as a glassblower nor ever be classed as a skilled mechanic; he must carpenter, photograph, wire electric circuits and be a master of gadgets of all kinds; he may find invaluable a training as an engineer and can profit always by utilising his gifts as a mathematician. In such activities will he be engaged for three-quarters of his working day. During the rest, he must be a physicist, that is, he must cultivate an intimacy with the behaviour of the physical world.</p>
</blockquote>

<p>In this opening paragraph, Blackett sums it up perfectly. My days, especially the early ones, in the lab were indeed spent with carpentry, photography (digital of course these days), soldering, and often needing to incorporate a new device (gadget) on the fly, sometime with no manual or instructions to serve as a guide. I myself never had to blow any glass, though friends of mine did, but I sure turned some metal now and then. All the meanwhile, one couldn’t lose sight of the bigger goal — to do some physics.</p>

<div>
<figure>
   <img src="http://www.jameshedberg.com/assets/img/control-station.jpg" alt="control station">
   <figcaption> A lot of gadgets all talking nicely to each other.</figcaption>
</figure>
</div>

<blockquote>
  <p>The experimental physicist must be enough of a theorist to know what experiments are worth doing and enough of a craftsman to be able to do them. He is only preeminent in being able to do both.</p>
</blockquote>

<p>This line captures another aspect well. Not only must we know how to do things, we must at least have a good inclination as to why. Like the famous quote from that dinosaur movie: “…but your scientists were so preoccupied with whether or not they could that they didn’t stop to think if they should.” Of course we weren’t battling over moral dilemmas (that much) but more so over the question of what would we achieve by measuring something. So you can measure the voltage with nanovolt precision – but will it help?</p>

<blockquote>
  <p>Certainly the way of a researcher is hard who does not in some degree delight in handy work for its own sake. However much his theoretical interest may be excited by the problem he is to investigate, he may feel a certain dismay on being assigned a room empty perhaps of all but a table, a blow-pipe and a few tools. Often two years may elapse before definite results come in sight; two years occupied with carpentering, metal work, glassblowing, and the wiring of electric circuits. Even when an apparatus is completed, an endless succession of minor difficulties and mishaps may postpone its successful use. A glass tube may crack overnight, a single hair may short circuit an electrometer, a filament may burn out, or the failing of the water supply may wreck an elaborate apparatus. But almost the worst trials to the experimenters patience are due to leaks, and a considerable portion of his time is often spent in finding them. An experimenter was once heard to complain, I have spent two days in getting the leak in my apparatus so small that it will now take me a week to find it. If the experimenter does not find pleasure in such activities, that is, if he has not in some degree the temperament of the amateur craftsman, much of his work must be a weariness.</p>
</blockquote>

<p>My first day in the lab, in 2005, I painted the floor. It was great. Part of the instrument that I was to work on lay in a coffin-like wooden box, in pieces. Other parts didn’t exists yet. There was pvc pipe to be hung, hundred of meters of wire to direct, and many other tasks that might at first glance seem not very physics related.</p>

<div>
<figure>
   <img src="http://www.jameshedberg.com/assets/img/floor.jpg" alt="the pit">
   <figcaption> The freshly painted concrete pit.</figcaption>
</figure>
</div>

<p>And of course, let’s be humble about the whole thing also:</p>

<blockquote>
  <p>Taken singly, the qualities of hand and mind required to make a good experimental physicist are not rare.</p>
</blockquote>

<p>Indeed. None of us were truly talented craftsmen. I did build a table out of an old crate, and it worked well for years, (it might even still be there) but it would hardly be worthy of a spot on a showroom floor.</p>

<div>
<figure>
   <img src="http://www.jameshedberg.com/assets/img/table.jpg" alt="table">
   <figcaption> The aforementioned table in the upper left portion of the image, along with another fantastic experimentalist.</figcaption>
</figure>
</div>

<p>Nor would most of us have gotten very far in the math olympiads. But, as is pointed out in the subsequent sentence,</p>

<blockquote>
  <p>But the combination of these abilities in one individual with the right temperament to use them to the full is rare.</p>
</blockquote>

<p>it requires more than just steady hands and a way with math to do the physics. It requires a subtle combination of patience, stubbornness, determination, and even some cowboy-esque roping to get the job done.</p>

<p>Blackett then goes on, in such a polite way, to highlight a major issue with experimental physics that persists today: working with the machine shop.</p>

<blockquote>
  <div><p>The rapidity with which an alteration to an apparatus can be carried out is a matter of primary and not of secondary importance. If a days work is required to test out an idea, it may be done; if a weeks work, it may not be done at all. </p><p> So even when professional assistance is available, many experimenters prefer to make their own apparatus, however amateurishly. It is very often so very much quicker. For if the aid of a mechanic is called in, scale drawings will have to be made, and it is often easier to construct a small piece of complicated apparatus than to make a drawing of it</p></div>
</blockquote>

<p>While my PhD was not finished in record time, it would have taken twice as long if every threaded hole had to be formally requested and accompanied by shop drawings. Sure, there were some parts of the apparatus that were well beyond my abilities in the shop, and those we handed over to the highly trained professionals (often aided by computer controlled machining capabilities). But having the ability to simply run over to a drill press and tap a 1/4-20 hole was indispensable. I couldn’t imagine having to ask every time I needed the smallest bit of machining done.</p>

<div>
<figure>
   <img src="http://www.jameshedberg.com/assets/img/measure-hookes-law.jpg" alt="hookes law measurement">
   <figcaption> Here is a measurement to see if the spring constant of a stainless steel bellows would change at very low temperatures.</figcaption>
</figure>
</div>

<p>The middle section of the essay is spent discussing three technologies that were common at the time: the scintillator, amplification (via tubes), and the cloud chamber. Scintillators are still used today to observe radiation. Of course our amplifiers are no longer based on vacuum tubes, but no lab could function without the solid state versions. The cloud chamber has little presence in today’s labs, but the evolution of that technology can be seen in today modern particle detectors.</p>

<p>The third and final section of essay makes some interesting points about how the experimental physicist might, by the very nature of his hands-on approach to the world, be in a good position to understand physics. Essentially, Blackett makes the argument that our intuition gained from a mechanistic interaction with the world might be of some advantage in trying to navigate the abstractions of modern physics. While very much the case for introductory physics topics, I’m not convinced that experience, however measured and probing it may be, with the macroscopic, human scale objects of daily life, can really be a strong source of conceptual foundation for much of what comes out of modern theoretical physics land. Perhaps occasionally, but I usually felt my rootedness in the mechanical world to be a bit of a handicap when exploring the abstract landscape of theory.</p>

<p>The separation between theorist and experimentalist will more than likely be a constant feature of the practice of natural science. There are of course exceptions to be found in the historical record, and in the current era – now and then, some people get really good at both. As is discussed in the essay, the experimentalist most likely has not the time nor the resources to become a fully functional theorist, and the theorists, in general, seem uninterested in arts and crafts. Exactly what leads one towards a particular camp is most likely a factor of both our innate circuitries as well as what filled our days during our youths. I had a neighbor who regularly deposited old stereos and other small appliances on my doorstep when I was young. I would dismantle, and occasionally re-mantle these gifts. There were numerous sets of blocks, legos, logs, and other construction elements in my hands at all time. I’m guessing those sorts of things had something to do with the paths I followed.</p>

<blockquote>
  <p>The experimental physicist is luckier; his legitimate field of activity ranges from carpentering to quantum mechanics; it is his job to make and think, and he can divide his time as he thinks fit between both these pleasurable occupations.</p>
</blockquote>

<p>Exactly.</p>

<div>
<figure>
   <img src="http://www.jameshedberg.com/assets/img/theorist.jpg" alt="hookes law measurement">
   <figcaption> Theorist at work</figcaption>
</figure>
</div>

<p>Here is a link to the <a href="http://jameshedberg.com/assets/docs/TheCraftofExperimentalPhysics-Blackett.pdf">whole pdf</a>. It really is a fantastic read and affirms much of the wonderful aspects of being involved in natural science.</p>

      </div></div>]]>
            </description>
            <link>http://www.jameshedberg.com/writing/2015/02/01/the-craft-of-experimental-physics.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25876989</guid>
            <pubDate>Fri, 22 Jan 2021 22:16:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Interview with Virologist Christian Drosten]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25876682">thread link</a>) | @Tomte
<br/>
January 22, 2021 | https://www.spiegel.de/international/germany/interview-with-virologist-christian-drosten-i-am-quite-apprehensive-about-what-might-otherwise-happen-in-spring-and-summer-a-f22c0495-5257-426e-bddc-c6082d6434d5 | <a href="https://web.archive.org/web/*/https://www.spiegel.de/international/germany/interview-with-virologist-christian-drosten-i-am-quite-apprehensive-about-what-might-otherwise-happen-in-spring-and-summer-a-f22c0495-5257-426e-bddc-c6082d6434d5">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-article-el="body">
<section data-app-hidden="">


</section>
<section>
<div>
<figure data-component="Image" data-zoom-id="0155abea-33b6-4ce4-a032-4a5bf5d53821" data-settings="{&quot;id&quot;:&quot;24e27727-88e6-406c-9b86-4f907da0941b&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;0155abea-33b6-4ce4-a032-4a5bf5d53821&quot;}">
<p><span>
<span data-image-el="aspect">
<span>
<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/24e27727-88e6-406c-9b86-4f907da0941b_w948_r1.77_fpx66_fpy45_fd50.jpg" srcset="https://cdn.prod.www.spiegel.de/images/24e27727-88e6-406c-9b86-4f907da0941b_w520_r1.77_fpx66_fpy45_fd50.jpg 520w, https://cdn.prod.www.spiegel.de/images/24e27727-88e6-406c-9b86-4f907da0941b_w948_r1.77_fpx66_fpy45_fd50.jpg 948w" width="948" height="536" sizes="948px" title="Christian Drosten on the grounds of Charité Universtiy Hospital in Berlin" alt="Christian Drosten on the grounds of Charité Universtiy Hospital in Berlin">
</span>
</span>
</span>

</p>
<figcaption>
<p>Christian Drosten on the grounds of Charité Universtiy Hospital in Berlin</p>
<span>
Foto: <p>Julia Steinigeweg&nbsp;/ DER SPIEGEL</p>
</span>
</figcaption>
</figure>
</div><div>
<p><strong>DER SPIEGEL:</strong> Professor Drosten, the pandemic has entered a decisive phase. The beginning of the vaccination campaign has meant light at the end of the tunnel, but now, more contagious virus variants have appeared. How dangerous is the situation in Germany at the moment?</p>


<p><strong>Drosten:</strong> I am, of course, closely monitoring the situation. Politicians are also acutely aware that we have to be careful. Early on, I admit that I had my doubts as to whether B.1.1.7, the new variant from Britain, was as much more contagious as people were claiming. But now, there is a new study from Oxford, really solid data, showing that this mutation is up to 35 percent more contagious than the wild-type virus. It is rather astonishing that the virus has boosted its infectiousness to that degree. That is, unfortunately, more dangerous than if it had become more deadly – because every new case will infect more people, and each of them will infect more people, such that the number of cases will grow exponentially.</p>

<p><strong>DER SPIEGEL:</strong> On Monday evening, you were part of the group of experts advising Chancellor Angela Merkel and the governors of Germany's 16 states. What recommendations did you make?</p>
<p><strong>Drosten:</strong> Right now, I am most concerned about the British variant, primarily because of our geographical proximity to the UK. According to the facts we currently have, B.1.1.7 has just started spreading in Germany. I think we have the singular opportunity to prevent, or at least significantly slow, the advance of this variant. With B.1.1.7, there could be a kind of threshold effect. If we are able to keep the new variant below a critical benchmark, we would at least have hope that it wouldn't spread as quickly here.</p>

<div>
<p><strong>DER SPIEGEL:</strong> Are the measures decreed on Tuesday sufficient?</p><p><strong>Drosten:</strong> In the negotiations, I think there was an effort made to find the gaps, the places where not enough has thus far been undertaken to stop the spread. It's clear that it was a struggle and that the results are a compromise. Some areas appear particularly important to me. Schools and daycare centers, for one, particularly the classes in secondary schools. England has closed such schools, with the exception of children of critical workers, and I think that is also where the most reliable data is to be found. For me, this is unequivocal, and Germany should use it as an orientation.</p>
</div>


<div>
<p><strong>DER SPIEGEL:</strong> What about the measures pertaining to working from home?</p><p><strong>Drosten:</strong> More could certainly have been done on that issue. It would have been good to take inspiration from the Irish experience in the autumn. Ireland introduced strict measures regarding working from home, and it was apparently quite effective. Doing so automatically reduces public transport occupancy. There is also a third aspect where improvements are necessary, something the British are doing: Targeted contact and support for the socially disadvantaged and groups that are difficult to reach in the pandemic. Here, the virus frequently spreads explosively, because many people live in close quarters and have jobs that don't allow them to work from home. Many perhaps don't fully understand the problem presented by confined spaces. I think there is still a lot to do here.</p><p><strong>DER SPIEGEL:</strong> You've come up with an image to illustrate our current situation in the pandemic: We are in a rickety truck that is driving down a steep mountainside ...</p><p><strong>Drosten:</strong> ... and we don't know what curves are coming up and whether the road is suddenly about to get steeper. We also don't know how far we still have to go, but we do know that we absolutely have to avoid missing a corner. In a situation like this, closing our eyes doesn't help. We have to keep going and do one thing in particular: Hit the brakes, even if they might be rusty.</p><p><strong>DER SPIEGEL:</strong> What do you mean by that?</p><p><strong>Drosten:</strong> That means, we have to lower the reproduction number R.</p><p><strong>DER SPIEGEL:</strong> The value that tells us the average number of people an infected person passes the virus to.</p><p><strong>Drosten:</strong> Precisely. Currently, that number is at 0.9. It is great that we have finally managed to push it back down below 1, so that the number of cases can begin to drop. But 0.9 isn't enough if we want to quickly loosen the brakes. With an R of 0.9, it takes about a month to reduce the number of infections by half. That is too long. We should try, through an intensification of the shutdown, to get the number down to 0.7. Then, the case numbers will drop by half in just a week, and we can get to a point where we can stop the spread of B.1.1.7 or at least give ourselves a head start.</p>
</div>

<section data-area="contentbox">

</section>
<div>
<p><strong>DER SPIEGEL:</strong> Do you think that the so-called Zero-COVID strategy, the goal of sinking the number of new infections to zero, is the right way forward?</p><p><strong>Drosten:</strong> I do think it would be possible with a significant effort. The virus, of course, would continue to flare up, just as we have seen in China and Australia. But it would absolutely be worthwhile to at least identify zero new infections as a target. Primarily because I am quite apprehensive about what might otherwise happen in the spring and summer.</p><p><strong>DER SPIEGEL:</strong> What do you mean?</p><p><strong>Drosten:</strong> Once the elderly and maybe part of the risk groups have been vaccinated, there will be immense economic, social, political and perhaps also legal pressure to end the corona measures. And then, huge numbers of people will become infected within just a short amount of time, more than we can even imagine at the moment. We won't have 20,000 or 30,000 new cases a day, but up to 100,000 in a worst-case scenario. It will, of course, be primarily younger people who are less likely than older people to have severe symptoms, but when a huge number of younger people get infected, then the intensive care units will fill up anyway and a lot of people will die. Just that it will be younger people. We can cushion this terrible scenario somewhat by pushing the numbers way down now.</p><p><strong>DER SPIEGEL:</strong> Can we be confident that case numbers will begin to drop in spring as temperatures rise?</p><p><strong>Drosten:</strong> I don't think so. The fact that we had such a relaxed summer in 2020 likely had to do with the fact that our case numbers remained below a critical threshold in the spring. But that's not the case any longer. I am afraid that it will be more like in Spain, where case numbers climbed rapidly again after the lockdown was lifted, even though it was quite hot. In South Africa, too, where it is currently summer, case numbers are at a high level. (<em>Sinks into thought, saying nothing</em>) I'm sorry, unfortunately I'm extremely tired.</p><p><strong>DER SPIEGEL:</strong> Because you were advising politicians deep into the night?</p>
</div>
<div>
<p><strong>Drosten:</strong> (<em>laughs</em>) No. Because I worked until 1 a.m. and then woke up this morning at 5:30.</p><p><strong>DER SPIEGEL:</strong> How well are you able to juggle your work with family life?</p><p><strong>Drosten:</strong> I don't really want to talk about my private life. But I do think that it's a problem many families are facing at the moment. The pandemic has found a sore spot. In countries like Germany, where people generally aren't living together with grandma and grandpa, many families find themselves in an extremely difficult situation. I hope that we can learn from this and find new solutions.</p><p><strong>DER SPIEGEL:</strong> Do you still have time for your real work, as a virologist?</p><p><strong>Drosten:</strong> Yes, of course. We are currently taking a closer look at the British variant. We hope to have initial results in a few weeks.</p><p><strong>DER SPIEGEL:</strong> Which of the new mutants do you believe is the most dangerous?</p>
</div>
<figure>
<div data-component="Image" data-zoom-id="e645c055-a27f-43b1-ad1e-c2118d9d5214" data-settings="{&quot;id&quot;:&quot;901740b1-c534-4785-b6b3-16ab224c5156&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;e645c055-a27f-43b1-ad1e-c2118d9d5214&quot;}">
<div>
<div>
<p><span>
<span data-image-el="aspect">
<span>

<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/901740b1-c534-4785-b6b3-16ab224c5156_w718_r0.75_fpx49.88_fpy37.41.jpg" srcset="https://cdn.prod.www.spiegel.de/images/901740b1-c534-4785-b6b3-16ab224c5156_w488_r0.75_fpx49.88_fpy37.41.jpg 488w, https://cdn.prod.www.spiegel.de/images/901740b1-c534-4785-b6b3-16ab224c5156_w616_r0.75_fpx49.88_fpy37.41.jpg 616w, https://cdn.prod.www.spiegel.de/images/901740b1-c534-4785-b6b3-16ab224c5156_w718_r0.75_fpx49.88_fpy37.41.jpg 718w" width="718" height="957" sizes="718px" loading="lazy" data-srcset="https://cdn.prod.www.spiegel.de/images/901740b1-c534-4785-b6b3-16ab224c5156_w488_r0.75_fpx49.88_fpy37.41.jpg 488w, https://cdn.prod.www.spiegel.de/images/901740b1-c534-4785-b6b3-16ab224c5156_w616_r0.75_fpx49.88_fpy37.41.jpg 616w, https://cdn.prod.www.spiegel.de/images/901740b1-c534-4785-b6b3-16ab224c5156_w718_r0.75_fpx49.88_fpy37.41.jpg 718w" title="Christian Drosten: &quot;I'm sorry, unfortunately I'm extremely tired.&quot;" alt="Christian Drosten: &quot;I'm sorry, unfortunately I'm extremely tired.&quot;">
</span>
</span>
</span>
</p><figcaption>
<p><strong>Christian Drosten:</strong> "I'm sorry, unfortunately I'm extremely tired."</p>
<span>
Foto: Julia Steinigeweg&nbsp;/ DER SPIEGEL
</span>
</figcaption>
</div>
</div>
</div>
</figure><div>
<p><strong>Drosten:</strong> In a population that still isn't immune, like here in Germany, the variant from Britain will likely find success, because it is better at spreading, it is more contagious. The South African and Brazilian variants may be able to infect people who have already had the disease, but that likely doesn't give them an advantage in a population where immunity isn't yet widespread. Which means that the virus will be distributed here and there over the course of the next year, and new variants will surely appear.</p><p><strong>DER SPIEGEL:</strong> What does that mean for the vaccines?</p><p><strong>Drosten:</strong> One of the mutations in the Brazilian and South African variants has already demonstrated a serious immune escape ...</p><p><strong>DER SPIEGEL:</strong> ... which helps the virus evade our immune defenses. Does that mean that the vaccines will be ineffective?</p><p><strong>Drosten:</strong> Antibodies are just one component of immune protection, another is T-cell immunity. That protects much more strongly against a serious progression of the illness. If the virus mutates, it doesn't have an effect on T-cell immunity. As such, I don't think that we have to fear that our vaccines will be ineffective.</p><p><strong>DER SPIEGEL:</strong> When you formulate such assessments, people across Germany are listening, and it often determines public opinion. How well are you able to live with that responsibility?</p><p><strong>Drosten:</strong> It doesn't rob me of sleep. From the very beginning, I hoped that this public role would be shared among several people. And luckily, that is happening.</p><p><strong>DER SPIEGEL:</strong> Last year, experts who have argued time and again against scientifically proven measures – e.g. Jonas Schmidt-Chanasit and Hendrik Streeck – likely did more damage than corona-truthers. Protecting high-risk groups must have priority, you frequently heard from their group. Yet it has long-since been clear that doing so is impossible when case numbers are high. At what point do you lose your patience?</p><p><strong>Drosten:</strong> Are you trying to get me to criticize colleagues by name? I don't think much of personal attacks.</p><p><strong>DER SPIEGEL:</strong> We are more interested in a fundamental point. Many such experts awaken the impression that only opinions are important in science, and not evidence. That undermines the credibility of researchers who take a more serious approach. How do you deal with that?</p><p><strong>Drosten:</strong> Like most scientists, …</p></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.spiegel.de/international/germany/interview-with-virologist-christian-drosten-i-am-quite-apprehensive-about-what-might-otherwise-happen-in-spring-and-summer-a-f22c0495-5257-426e-bddc-c6082d6434d5">https://www.spiegel.de/international/germany/interview-with-virologist-christian-drosten-i-am-quite-apprehensive-about-what-might-otherwise-happen-in-spring-and-summer-a-f22c0495-5257-426e-bddc-c6082d6434d5</a></em></p>]]>
            </description>
            <link>https://www.spiegel.de/international/germany/interview-with-virologist-christian-drosten-i-am-quite-apprehensive-about-what-might-otherwise-happen-in-spring-and-summer-a-f22c0495-5257-426e-bddc-c6082d6434d5</link>
            <guid isPermaLink="false">hacker-news-small-sites-25876682</guid>
            <pubDate>Fri, 22 Jan 2021 21:43:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Weak Men Are Superweapons (2014)]]>
            </title>
            <description>
<![CDATA[
Score 247 | Comments 148 (<a href="https://news.ycombinator.com/item?id=25876554">thread link</a>) | @skinkestek
<br/>
January 22, 2021 | https://www.slatestarcodexabridged.com/Weak-Men-Are-Superweapons | <a href="https://web.archive.org/web/*/https://www.slatestarcodexabridged.com/Weak-Men-Are-Superweapons">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wikitext">

<p><span>May 12, 2014</span>
</p>
<h3>I</h3>
<p>There was an argument on Tumblr which, like so many arguments on Tumblr, was terrible. I will rephrase it just a little to make a point.
</p>
<p>Alice said something along the lines of “I hate people who frivolously diagnose themselves with autism without knowing anything about the disorder. They should stop thinking they’re ‘so speshul’ and go see a competent doctor.”
</p>
<p>Beth answered something along the lines of “I diagnosed myself with autism, but only after a lot of careful research. I don’t have the opportunity to go see a doctor. I think what you’re saying is overly strict and hurtful to many people with autism.”
</p>
<p>Alice then proceeded to tell Beth she disagreed, in that special way only Tumblr users can. I believe the word “cunt” was used.
</p>
<p>I notice two things about the exchange.
</p>
<p>First, why did Beth take the bait? Alice said she hated people who <em>frivolously</em> self-diagnosed <em>without knowing anything about the disorder</em>. Beth clearly was not such a person. Why didn’t she just say “Yes, please continue hating these hypothetical bad people who are not me”?
</p>
<p>Second, why did <em>Alice</em> take the bait? Why didn’t she just say “I think you’ll find I wasn’t talking about you?”
</p>
<h3>II</h3>
<p>One of the cutting-edge advances in fallacy-ology has been the <a href="http://www.scientificamerican.com/article/getting-duped/" rel="nofollow">weak man</a>, a terribly-named cousin of the straw man. The straw man is a terrible argument nobody really holds, which was only invented so your side had something easy to defeat. The weak man is a terrible argument that only a few unrepresentative people hold, which was only <em>brought to prominence</em> so your side had something easy to defeat.
</p>
<p>For example, “I am a proud atheist and I don’t like religion. Think of the terrible things done by religion, like the actions of the Westboro Baptist Church. They try to disturb the funerals of heroes because they think God hates everybody. But this is horrible. Religious people can’t justify why they do things like this. That’s why I’m proud to be an atheist.”
</p>
<p>It’s not a straw man. There really is a Westboro Baptist Church, for some reason. But one still feels like the atheist is making things just a little too easy on himself.
</p>
<p>Maybe the problem is that the atheist is indirectly suggesting that Westboro Baptist Church is typical of religion? An implied falsehood?
</p>
<p>Then suppose the atheist posts on Tumblr: “I hate religious people who are rabidly certain that the world was created in seven days or that all their enemies will burn in Hell, and try to justify it through ‘faith’. You know, the sort of people who think that the Bible has all the answers and who hate anyone who tries to think for themselves.”
</p>
<p>Now there’s practically no implication that these people are typical. So that’s fine, right?
</p>
<p>On the other side of the world, a religious person is writing “I hate atheists who think morality is relative, and that this gives them the right to murder however many people stand between them and a world where no one is allowed to believe in God”.
</p>
<p>Again, not a straw man. The Soviet Union contained several million of these people. But if you’re an atheist, would you just let this pass?
</p>
<p>How about “I hate black thugs who rob people”?
</p>
<p>What are the chances a black guy reads that and says “Well, good thing I’m not a thug who robs people, he’ll probably <em>love</em> me”?
</p>
<h3>III</h3>
<p>What is the problem with statements like this?
</p>
<p>First, they are meant to re-center a category. Remember, people think in terms of categories with central and noncentral members – a sparrow is a central bird, an ostrich a noncentral one. But if you live on the Ostrich World, which is inhabited only by ostriches, emus, and cassowaries, then probably an ostrich seems like a pretty central example of ‘bird’ and the first sparrow you see will be fantastically strange.
</p>
<p>Right now most people’s central examples of religion are probably things like your local neighborhood church. If you’re American, it’s probably a bland Protestant denomination like the Episcopalians or something.
</p>
<p>The guy whose central examples of religion are Pope Francis and the Dalai Lama is probably going to have a different perception of religion than the guy whose central examples are Torquemada and Fred Phelps. If you convert someone from the first kind of person to the second kind of person, you’ve gone most of the way to making them an atheist.
</p>
<p>More important, if you convert a culture from thinking in the first type of way to thinking in the second type of way, then religious people will be unpopular and anyone trying to make a religious argument will have to spend the first five minutes of their speech explaining how they’re not Fred Phelps, honest, and no, they don’t picket any funerals. After all that time spent apologizing and defending themselves and distancing themselves from other religious people, they’re not likely to be able to make a very rousing argument for religion.
</p>
<h3>IV</h3>
<p>In <a href="https://slatestarcodex.com/2014/04/15/the-cowpox-of-doubt/" rel="nofollow">Cowpox of Doubt</a>, I mention the inoculation effect. When people see a terrible argument for an idea get defeated, they are more likely to doubt the idea later on, even if much better arguments show up.
</p>
<p>Put this in the context of people attacking the Westboro Baptist Church. You see the attacker win a big victory over “religion”, broadly defined. Now you are less likely to believe in religion when a much more convincing one comes along.
</p>
<p>I see the same thing in atheists’ odd fascination with creationism. Most of the religious people one encounters are not young-earth creationists. But these people have a dramatic hold on the atheist imagination.
</p>
<p>And I think: well, maybe if people see atheists defeating a terrible argument for religion enough, atheists don’t <em>have to</em> defeat any of the others. People have already been inoculated against religion. “Oh, yeah, that was the thing with the creationism. Doesn’t seem very smart.”
</p>
<p>If this is true, it means that all religious people, like it or not, are in the same boat. An atheist attacking creationism becomes a deadly threat for the average Christian, even if that Christian does not herself believe in creationism.
</p>
<p>Likewise, when a religious person attacks atheists who are moral relativists, or communists, or murderers, then all atheists have to band together to stop it somehow or they will have successfully poisoned people against atheism.
</p>
<h3>V</h3>
<p>This is starting to sound a lot like <a href="http://squid314.livejournal.com/329171.html" rel="nofollow">something I wrote on my old blog about superweapons</a>.
</p>
<p>I suggested imagining yourself in the shoes of a Jew in czarist Russia. The big news story is about a Jewish man who killed a Christian child. As far as you can tell the story is true. It’s just disappointing that everyone who tells it is describing it as “A Jew killed a Christian kid today”. You don’t want to make a big deal over this, because no one is saying anything objectionable like “And so all Jews are evil”. Besides you’d hate to inject identity politics into this obvious tragedy. It just sort of makes you uncomfortable.
</p>
<p>The next day you hear that the local priest is giving a sermon on how the Jews killed Christ. This statement seems historically plausible, and it’s part of the Christian religion, and no one is implying it says anything about the Jews today. You’d hate to be the guy who barges in and tries to tell the Christians what Biblical facts they can and can’t include in their sermons just because they offend you. It would make you an annoying busybody. So again you just get uncomfortable.
</p>
<p>The next day you hear people complain about the greedy Jewish bankers who are ruining the world economy. And really a disproportionate number of bankers are Jewish, and bankers really do seem to be the source of a lot of economic problems. It seems kind of pedantic to interrupt every conversation with “But also some bankers are Christian, or Muslim, and even though a disproportionate number of bankers are Jewish that doesn’t mean the Jewish bankers are disproportionately active in ruining the world economy compared to their numbers.” So again you stay uncomfortable.
</p>
<p>Then the next day you hear people complain about Israeli atrocities in Palestine (what, you thought this was past czarist Russia? This is future czarist Russia, after Putin finally gets the guts to crown himself). You understand that the Israelis really do commit some terrible acts. On the other hand, when people start talking about “Jewish atrocities” and “the need to protect Gentiles from Jewish rapacity” and “laws to stop all this horrible stuff the Jews are doing”, you just feel worried, even though you personally are not doing any horrible stuff and maybe they even have good reasons for phrasing it that way.
</p>
<p>Then the next day you get in a business dispute with your neighbor. Maybe you loaned him some money and he doesn’t feel like paying you back. He tells you you’d better just give up, admit he is in the right, and apologize to him – because if the conflict escalated everyone would take his side because he is a Christian and you are a Jew. And everyone knows that Jews victimize Christians and are basically child-murdering Christ-killing economy-ruining atrocity-committing scum.
</p>
<p>You have been boxed in by a serious of individually harmless but collectively dangerous statements. None of them individually referred to you – you weren’t murdering children or killing Christ or owning a bank. But they ended up getting you in the end anyway.
</p>
<p>Depending on how likely you think this is, this kind of forces Jews together, makes them become strange bedfellows. You might not like what the Jews in Israel are doing in Palestine. But if you think someone’s trying to build a superweapon against you, and you don’t think you can differentiate yourself from the Israelis reliably, it’s in your best interest to defend them anyway.
</p>
<h3>VI</h3>
<p>I wrote the superweapon post to address some of my worries about feminism, so it would not be surprising at all if we found this dynamic there.
</p>
<p>Feminists tend to talk about things like “Men tend to silence women and not respect their opinions” or “Men treat women like objects …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.slatestarcodexabridged.com/Weak-Men-Are-Superweapons">https://www.slatestarcodexabridged.com/Weak-Men-Are-Superweapons</a></em></p>]]>
            </description>
            <link>https://www.slatestarcodexabridged.com/Weak-Men-Are-Superweapons</link>
            <guid isPermaLink="false">hacker-news-small-sites-25876554</guid>
            <pubDate>Fri, 22 Jan 2021 21:26:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why it's bad to have a high GDP]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25876206">thread link</a>) | @wooque
<br/>
January 22, 2021 | https://lukesmith.xyz/articles/gdp | <a href="https://web.archive.org/web/*/https://lukesmith.xyz/articles/gdp">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    


    <p>by <a href="https://lukesmith.xyz/index.html">Luke Smith</a>, originally a blog post in November 2018, rewritten for this website.</p>

    <h2>To put it in other words...</h2>

<p>
The common way of looking at Gross Domestic Product (GDP) is that it's a metric of economic success: more GDP is more wealth.
Wealth is good. "Poverty" (meaning low <em>per capita</em> GDP) is bad.
Nowadays, pretty much everyone talks about "economics" like this as if this truism was scribbled on the back walls of the cosmos.
</p>

<p>
This is just looking at one side of the ledger in a kind of global double-entry accounting book.
A logically equivalent way of looking at it is that <strong>GDP is a metric of economic exchange required for survival in society as it exists</strong>.
You can say that some area "produced" $1 billion of output (sounds good), but you can just as easily say that $1 billion was required for that area to sustain itself (sounds bad).
These two are simply logically equivalent.
</p>

<h2>Living on $1 a day</h2>

<figure>
<a href="https://lukesmith.xyz/articles/pix/ivanov01.jpg">
<img alt="Hyperborea" title="(((They))) don't want you to know about this." src="https://lukesmith.xyz/articles/pix/ivanov01s.jpg">
</a>
<figcaption>Antediluvian Hyperborea. GDP: $0 per year.</figcaption>
</figure>

<p>
Let's dive into the Gestalt: when you hear that a family of eight lives on less than a dollar per day (PPP adjusted), you might wonder how they manage!
To <em>actually</em> do such a thing would require buying large bags of rice for the whole family, eat only that and live in free cardboard boxes.
</p>

<p>
The reality is that that often uttered phrase means that they use less than $1 a day in the general economy, while the rest of their livelihood is "off-the-grid" or self-sufficient.
They may grow food in a family farm, hunt for food, and most of their daily needs from cooking oils, to plates, to pottery, to soap are often made at home as well.
</p>

<p>
There is still "an economy" but often one that is barter based or <em>socialist</em> in the real pre-socialist sense of the word: mediated by direct face-to-face social tit-for-tat between neighbors and friends, none of this mediated by currency being exchanged, thus it is not part of the GDP.
</p>

<p>
If you read about some Bangladeshi village where the only product is "textiles", that doesn't mean that everyone there makes textiles all day and, without a textile company, everyone would've starved to death.
It means that the only on-paper, measurable global industry practiced there is textile manufacturing.
Other villagers might farm, hunt, even do some kind of gathering in some places.
They will produce the arts and crafts and live the way people live when you leave them alone.
If your view of the world is mediated by GDP, you're only seeing the extremely small sliver that pops into existence when people exchange something involving legal tender.
</p>

<p>
This is extremely difficult for us modern bugpeople to understand because to be a bugman in a large city is to produce absolutely nothing on one's own and buy literally everything you need from the store.
To us non-productive people, GDP means income which means survival.
But the further out of Bugmanville you go, the clearer the vacuousness of GDP becomes.
When you realize that most of human wealth is unmeasured by GDP, you realize that Whig History and Steven Pinkerism is based on shaky foundations.
</p>

<h2>Example</h2>

<p>
A minor example.
We had a large Thanksgiving feast near my uncle's house in very rural Florida.
As it got cold in the night, we had a fire in a repurposed old sugar cane cooking vat artfully standing on used symmetrical cinderblock pieces.
A bugman hipster might pay two hundred dollars or more for a similar looking "authentic" piece of equipment. Those $200 would be counted in the GDP.
A bugman hipster might have also bought or rented chairs for the event, "contributing" more to the GDP, but my uncle, as part of the local wholesome church community, simply borrowed some from the church.
Thus our event produced basically no GDP output in goods or services, despite being functionally equivalent to some similar but expensive and ergo "productive" "Friendsgiving" practiced by urbanites.
In reality <em>we</em> are richer than the bugmen hipsters who blew hundreds of dollars on a faux-folksy party.
In this case, we owned the firepit and had easy access and permission to the chairs, thus we are more economically flexible than they are.
That GDP that they produced/expended is evidence of deeper reliance on the economic system.
That GDP output is a marker of <em>fragility</em>, reliance on the conditions of the outside economy in the same way that a village of Bangladeshis who abandon their traditional way of lives to work on textiles are more fragile, despite being able to save up for iPhones.
</p>

<h2>What GDP really measures</h2>

<p>
<strong>Most of the increase in GDP across the world is simply the movement from local partially-social partially-under-the-table economies to economies mediated by taxable currency.</strong>
An economically self-sufficient village with close social relationships and a barter economy has 0 GDP.
A township of entrepreneurs and artisans you partially barter and partially use currency which they don't report has 0 GDP.
All of these people are "in poverty" and "earn less than a dollar a day".
And if you want to be truly self-sufficient, that means having a personal GDP of zero.
</p>

<p>
More than that, pretty much everywhere, GDP is a strong indicator of social upheaval.
If you think that GDP is some eternal goodness, remember that <em>everything "good" about industrialization shows up in the GDP</em>, while at the same time, <em>everything bad about it will not show up</em>.
Or, sometimes bad things are registered as positive economic growth: urbanization has caused mass-disease, and if that means a market for new medical services and pharmaceuticals, great!
The GDP just went up!
The Ganges is polluted due to the textile plant? That just means more opportunities for local entrepreneurs to sell bottled water!
The GDP just went up!
Are people being pushed out of fishing or other subsistence occupations because of it? Even better! Now they have no choice but to contribute to the GDP!
With every passing year, in fact, more and more of the GDP is produced by dealing with the problems that our higher level of GDP have caused.
</p>

<p>
At the end of the day, <strong>GDP is only a measurement of how reliant a place or country is on the global economy</strong>.
Self-sufficiency has a GDP of 0.
Wasteful consooomerism has an extremely large GDP.
</p>

<h2>Planned obsolescence</h2>

<p>
I have one of my great grandfather's early electric circular saws.
It has a bunch of gunk in it, but it still works (although I recently took it apart to replace some old screws and springs and other little parts to be careful).
They literally do not make circular saws like it; it's all metal, while even the fancy modern stuff is mostly plastic.
</p><p>
The "unfortunate" thing about it and other durable tools is that it's "bad for the economy," especially the GDP.
Since that thing has been around since maybe the 50's or 60's, that's as long as 70 years the economy has gone without the "stimulation" of us having to buy another saw.
</p>

<p>
Viewers of my technology videos: Which would be better for the world, if everyone used the material equivalent of a classic American-made IBM ThinkPad, or some Apple Laptops that are unfixable computers made of mostly batteries designed to conk out right before the new version comes out?
Regardless, the Apple Macs that cost thousands a piece are much better for the "economy."
</p>

<p>
That's what I mean.
If you have quality tools and do not need to constantly throw money at the system to buy things, fix things and otherwise waste money, you are going to be having a lower GDP.
That's just how it is.
</p>

<h2>The propagandistic role of GDP</h2>

<p>
When you don't think things through like this, GDP is supposed to appear as an objective measure of economic goodness.
You're supposed to be looking at those GDP charts and saying, "Wow, my life might be terrible, I am not free, I am subject to forces out of my control, and I and told I have to participate in mass-consumerism to survive, but these charts are the facts[!], and the facts say that things are better now, so I believe them!"
</p>

<p>
It's legitimately surprising to me how big of a boon the idea of increasing GDP is for Whig history and NPCs of many different ideologies.
People of the Left and Right will matter-of-factly tell me that a plastic based economy taking over the world is still good because the line is going up.
I've heard it as a justification for everything:
</p>


<blockquote>
    Don't like globalization?<br>
    <span>You're wrong, the GDP is going up.</span><br>

    Don't trust state-funded institutionalized science?<br>
    <span>You're wrong, the GDP is going up.</span><br>

    Don't want child drag queens?<br>
    <span>You're wrong, the GDP is going up.</span><br>

    Don't want everything to be made of plastics and other petrochemicals?<br>
    <span>You're wrong, the GDP is going up.</span><br>

    Don't want mass pornography?<br>
    <span>You're wrong, the GDP is going up.</span><br>
    Don't want free sugary drinks since infancy?<br>
    <span>You're wrong, the GDP is going up.</span><br>
</blockquote>

<p>
When you abandon the illusion of GDP, you are suddenly able to ask whether
massive technological "progress" has <em>actually</em> been good for real human
life and human pychology.
</p>

    <hr>

    



</div>]]>
            </description>
            <link>https://lukesmith.xyz/articles/gdp</link>
            <guid isPermaLink="false">hacker-news-small-sites-25876206</guid>
            <pubDate>Fri, 22 Jan 2021 20:51:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[.NET GC Internals mini-series]]>
            </title>
            <description>
<![CDATA[
Score 161 | Comments 48 (<a href="https://news.ycombinator.com/item?id=25876087">thread link</a>) | @GordonS
<br/>
January 22, 2021 | https://tooslowexception.com/net-gc-internals-mini-series/ | <a href="https://web.archive.org/web/*/https://tooslowexception.com/net-gc-internals-mini-series/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-625">
	
		
	
	<div itemprop="articleBody">
				<p>I’ve decided to make a series of at least <a href="https://www.youtube.com/playlist?list=PLpUkQYy-K8Y-wYcDgDXKhfs6OT8fFQtVm" target="_blank">8 free weekly-based webinars</a> about<strong> in-depth implementation details of the .NET GC</strong> and… I’m super happy with it! Why the idea? Many <strong>my other activities are about more practical “.NET memory management”</strong>, like <a href="https://prodotnetmemory.com/" target="_blank">my book</a> or <a href="https://workshop.prodotnetmemory.com/" target="_blank">workshops/trainings/consultancy</a> I gave. But during all this practical-oriented events t<strong>here is always not enough time</strong> to explain in details how .NET GC is implemented. Obviously, I always explain some concepts and algorithms, to the level that helps in understanding the whole concept. But not with the level of details that I am satisfied.</p>
<p>Hence the idea – make a separate <strong>content that will be just as deep as I like</strong> 🙂 So, I will cover details on the level of bits, bytes and source code, not only on the level of the overall algorithm description.</p>
<p>The first episode was yesterday, feel invited to watch:</p>
<p><iframe width="560" height="315" src="https://www.youtube.com/embed/8i1Nv7wGsjk" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="allowfullscreen"></iframe></p>

<p>The topics I’ve covered in the first module:</p>
<ul>
<li>the whole series roadmap</li>
<li>some fundamentals like reference counting (including more modern algorithms) and tracing GC</li>
<li>.NET GC types and its history</li>
<li>first dive into the .NET 5 runtime source code, including the first breakpoints in the famous 40 kLOC gc.cpp</li>
</ul>
<p>And the whole <a href="https://www.youtube.com/playlist?list=PLpUkQYy-K8Y-wYcDgDXKhfs6OT8fFQtVm" target="_blank">playlist is also available on YouTube</a>.</p>
<p>The topics I will cover during the whole series are as follows:</p>
<p><a href="https://tooslowexception.com/wp-content/uploads/2021/01/gcwebinar02.png"><img src="https://tooslowexception.com/wp-content/uploads/2021/01/gcwebinar02-1024x535.png" alt="gcwebinar02" width="720" height="376" srcset="https://tooslowexception.com/wp-content/uploads/2021/01/gcwebinar02-1024x535.png 1024w, https://tooslowexception.com/wp-content/uploads/2021/01/gcwebinar02-300x157.png 300w, https://tooslowexception.com/wp-content/uploads/2021/01/gcwebinar02-768x401.png 768w, https://tooslowexception.com/wp-content/uploads/2021/01/gcwebinar02.png 1402w" sizes="(max-width: 720px) 100vw, 720px"></a></p>
<p>And we will see whethere it ends after eight episodes, or maybe a new interesting topics will emerge (including, from your questions).</p>
<p>Have a nice watch!</p>
							</div>
		</article></div>]]>
            </description>
            <link>https://tooslowexception.com/net-gc-internals-mini-series/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25876087</guid>
            <pubDate>Fri, 22 Jan 2021 20:39:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Performance Analysis – Methodologies Introduction]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25875216">thread link</a>) | @rafaelgss
<br/>
January 22, 2021 | https://blog.rafaelgss.com.br/performance-methodologies | <a href="https://web.archive.org/web/*/https://blog.rafaelgss.com.br/performance-methodologies">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<section>

<p>Poor performance costs the software industry millions of dollars annually in lost revenue, decreased productivity, increased development, hardware costs and damaged customer relations.</p>
<p>Most applications tend to focus on correctness over performance. The shift towards performance only occurs once it is seen as a problem.
When that happens, one rarely has time to dedicated towards improving it. This article aims to show you that <strong>there is no simple answer</strong>.
A lot of performance work should be done in early phases of development. For the rest of the article, the reader is considered having a role of Performance Engineer or “acting” as one.</p>
<p>In my experience, a strictly “agile” methodology (Idea -&gt; MVP -&gt; Feature -&gt; “Refactor”) tends to leave out proper performance engineering, since performance is not a goal but an expectation.</p>
<blockquote><p><em>Performance is a field where the more you know, the less you understand</em>.</p>
</blockquote>
<p>Regardless of the source, when a performance issue appears it should be fixed immediately. Two ways are: 1) modifying code/architecture or throwing money at additional hardware resources. The second path in some time will lead to the same problem down the line.</p>
<p>Prior starting performance analysis, you <strong>must</strong>  understand your application architecture. Any analysis requires clear boundaries and a full understanding of dependencies and third-party services.</p>
<p>A diagram of your software architecture is a great starting point.</p>
<blockquote><p>The foundation of your software should be resilient to achieve better results.</p>
</blockquote>
<h2>Monitoring</h2>
<p>Today, a big part of the market is adopting distributed systems. As we’ve come to learn, such systems adds a lot of complexity to your architecture in exchange for scalability and availability (resilience).</p>
<p>It also adds more components to your list of dependencies. Therefore, you should monitor these dependencies to have better visibility when things deviate from a happy path.</p>
<p>Each part of the architecture (or software) needs individual monitoring that helps us go back in time and answer some of these questions:</p>
<ul>
<li>When did the software start performing worse?
</li>
<li>During what timeframe are we seeing most activity?
</li>
<li>How are components behaving during these timeframes? Think: I/O latency, DNS resolution, CPU or RAM consumption
</li>
</ul>
<p>These questions will help to choose the right performance methodology to apply.</p>
<h2>Known-Unknowns</h2>
<p><img src="https://blog.rafaelgss.com.br/images/performance-analysis/diagram-known-unknowns.png" alt="Known Unknowns"></p>
<blockquote><p><em>This section is a reference to the book <a href="https://www.goodreads.com/book/show/18058001-systems-performance">System Performance</a> by the author Brendan Gregg.</em></p>
</blockquote>
<p>In performance analysis we can split information into three types:</p>
<ul>
<li>Know-Knows: These are things you know, for instance, you know that you should be checking CPU utilization <strong>and</strong> you know that the value is 10% on average.
</li>
<li>Know-Unknows: There are things that you know that you do not know. You know that an increase in API response time can be related to a third-party component, but you don’t have metrics showing it.
</li>
<li>Unknown-Unknowns: These are things you are unaware of not knowing. Confusing? For instance: you may not know that DNS resolution can become heavy I/O latency, so you are not checking them (because you didn’t know).
</li>
</ul>
<p>While creating architecture diagrams,  <em>unknowns-unknowns</em>  obviously aren’t mappable since you don’t know about them.</p>
<blockquote><p><code>unknown-unknows</code> are common. It is your job as a performance engineer to transform the <code>unknown-unknowns</code> into <code>know-unknows</code>.</p>
</blockquote>
<p>The Diagram above map <code>known-knowns</code> (Green box) and <code>known-unknows</code> (Red box)</p>
<h2>Observability Tools</h2>
<p>As previously mentioned, achieving observability in our software/architecture is fundamental to perform performance improvements. In this section, I’ll walk through a few tools that are great for this purpose.</p>
<h3>Tracing</h3>
<p>Tracing collects per-event data for analysis. Normally, tracing tools are not enabled by default since it adds CPU overhead to capture and send/store the data.</p>
<p>Logging (including system logs) can be seen as low-frequency tracing that is enabled by default.</p>
<p>Some common tools:</p>
<p><strong>system-wide</strong>:</p>
<ul>
<li><code>tcpdump</code>: network packet tracing
</li>
<li><code>perf</code>: Linux Performance Events (tracing static and dynamic probes)
</li>
</ul>
<p><strong>per-process</strong>:</p>
<ul>
<li><code>strace</code>: system call tracing
</li>
<li><code>USDT</code> (Userland Statically Defined Tracing)
</li>
<li><code>DTrace</code>: observability framework that includes a programming language and a tool.
</li>
</ul>
<p>TracePoints is a great way to observe your software in the production environment. You can use USDT (dynamic probes) or static tracepoints.
For further information check the <em>useful links</em> section.</p>
<h3>Profiling</h3>
<p>Profiling characterizes the target by collecting a set of samples of snapshots. CPU usage is a common example where samples are taken of the stack trace to characterize the code paths that are consuming CPU cycles.</p>
<p><strong>Note</strong>: For further information about Profiling CPU, I’ve made a blog post doing CPU Profiling in a Node.js application. <a href="https://blog.rafaelgss.com.br/node-cpu-profiler">Check here</a>.</p>
<p>Tools:</p>
<ul>
<li><code>perf</code>: Linux Performance Events (profiling)
</li>
<li><code>cachegrind</code>: a Valgrind sub tool, can profile hardware cache usage and be visualized using <code>kcachegrind</code>
</li>
</ul>
<blockquote><p><code>/proc</code> is a file system interface for kernel statistics, it contains directories where each directory is named after the <strong>PID</strong> of the process. These directories contain a number of files containing information and statistics about each process mapped from kernel data structures.</p>
</blockquote>
<p><img src="https://pbs.twimg.com/media/DZ3HpVXXkAEgxpc?format=jpg&amp;name=large" alt="Julia Evans - Comic /proc"> - <a href="https://twitter.com/b0rk/status/981159808832286720/photo/1">reference</a></p>
<h2>Methodologies</h2>
<p>This section will describe three of the most used methodologies (by me at least). Apply a methodology when performance issues start showing up; there is no rule about choosing the best approach.
Previous experience with your software architecture will likely be the best way to make a decision.</p>
<h3>USE</h3>
<p>Utilization, Saturation and Errors (USE) is an methodology that <strong>should be used early in performance investigation</strong>. For every resource, check the utilization, saturation, and errors:</p>
<ul>
<li><strong>Resource</strong>: server components (CPU, buses, …)
</li>
<li><strong>Utilization</strong>: for a set time interval, the percentage of time that the resource was busy servicing work. While busy, the resource may <strong>still be able to accept more work</strong>.
</li>
<li><strong>Saturation</strong>: additional work to be done, likely waiting in a queue. Jobs that cannot be dealt with instantly.
</li>
</ul>
<p><img src="https://blog.rafaelgss.com.br/images/performance-analysis/workflow-use.png" alt="Workflow with USE Methodology"></p>
<p>Its important to consider that it can be counter-intuitive; a short burst of high utilization can introduce saturation and performance issues even though the overall utilization is low over a long interval. CPU utilization <strong>can change dramatically from second to second</strong> so a 5-minute average may disguise short periods of 100% utilization and therefore lead to saturation.</p>
<p>Note: The saturation could not be easier to identify.</p>
<p>The first step is to create a list of resources:</p>
<ul>
<li><strong>CPUs:</strong> sockets, cores, hardware threads (virtual CPUs)
</li>
<li><strong>Main memory</strong>: DRAM
</li>
<li><strong>Network interfaces</strong>: Ethernet ports
</li>
<li><strong>Storage devices</strong>: disks
</li>
<li><strong>Controllers</strong>: storage, network
</li>
<li><strong>Interconnects</strong>: CPU, memory, I/O
</li>
</ul>
<blockquote><p>Virtual resources are fundamentally different than dedicated hardware. Especially as your resources are both shared and intentionally throttled. Some - if not all - cloud providers make their money by overselling and betting on idle processes.</p>
</blockquote>
<p>The USE method is most effective for resources that suffer performance degradation under high utilization or saturation, leading to bottlenecks. Fortunately, they are not common system bottlenecks, as they are typically designed to provide an excess of throughput. Unfortunately, if they are the problem, can be difficult to solve.</p>
<p>After you get the list of resources, try to create some metrics for it:</p>
<p><img src="https://blog.rafaelgss.com.br/images/performance-analysis/list-resources-use.png" alt="List of resources to create metric"></p>
<p>The process of elimination is good for us. Eliminate a possible resource bottleneck may help us to focus on another resource limiting our scope.</p>
<h3>Drill Down</h3>
<p>The process iterates through deeper layers of the software stack – even to hardware if necessary – to find the root cause of the issue. I try to to apply this methodology in every part of the software stack. It’s usually harder to do so  without having the bigger picture; but as you get more experienced you start recognizing recurring issues.</p>
<blockquote><p>Collecting and monitoring metrics is fundamental. Without it, we cannot fix the bugs the components cause.</p>
</blockquote>
<p>Such deeper analysis may involve the creation of custom tools and inspection of source code (if available). Here is where most of the drilling takes place, peeling away layers of the software stack as necessary to find the root cause.</p>
<p>Imagine an application that after a month in an production environment has begun to perform poorly.</p>
<p><strong>Five Whys</strong></p>
<ol>
<li>A database has performing poorly for some queries. Why?
</li>
<li>It’s delayed by disk I/O due to memory paging. Why?
</li>
<li>Database memory usage has grown too large. Why?
</li>
<li>The allocator is consuming more memory than expected. Why?
</li>
<li>The allocator has a memory fragmentation issue.
</li>
</ol>
<p>This is a good real sample extracted from <a href="https://www.goodreads.com/book/show/18058001-systems-performance">System Performance</a> book. There is not limit to go deep into <em>Why?</em>, but, one has to when the software is performing well.</p>
<p><img src="https://blog.rafaelgss.com.br/images/performance-analysis/5-whys.png" alt="Five why - Drill Down"></p>
<h3>Scientific Method</h3>
<p>The <em>scientific method</em> studies the <em>unknown</em> by making hypotheses and testing them. The <code>unknown</code> here can mean the <code>unknown-unknown</code> as discussed in <a href="#know-unknowns"><code>Know-Unknows</code></a> section.</p>
<p>Every <em>scientific method</em> consists:</p>
<ol>
<li>Formulation of a question?
</li>
<li>Hypothesis
</li>
<li>Prediction
</li>
<li>Testing
</li>
<li>Analysis
</li>
</ol>
<blockquote><p>For more information about how <em>scientific methods</em>, see <a href="https://en.wikipedia.org/wiki/Scientific_method">here</a></p>
</blockquote>
<p>First, define a question based on performance problem; for instance: <em>Why does my application have degraded throughput?</em>.</p>
<p>Second, build a hypothesis about what the cause of poor performance may be. <em>CPU Miss rate</em>? Write a test to prove your theory by for instance using <code>Valgrind</code>.</p>
<p>Collect results from your previous step and analyze how it behaves over time. It will give you a better idea of what components are connected and ultimately affected.</p>
<p><strong>Note:</strong> Shaping a hypothesis requires a clear understanding of your software architecture. Versioning your architectural changes can play a key role in understanding sudden changes.</p>
<p><img src="https://blog.rafaelgss.com.br/images/performance-analysis/scientific-method-steps.png" alt="Scientific Method Steps"></p>
<h2>Memory</h2>
<p>Usually, when a system boots the memory usage starts to grow as the operating system uses available memory to cache file system improving performance.
A system may report that it has only 10 MB of available memory when it actually has 10 GB of file system cache that can be reclaimed by applications immediately when …</p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.rafaelgss.com.br/performance-methodologies">https://blog.rafaelgss.com.br/performance-methodologies</a></em></p>]]>
            </description>
            <link>https://blog.rafaelgss.com.br/performance-methodologies</link>
            <guid isPermaLink="false">hacker-news-small-sites-25875216</guid>
            <pubDate>Fri, 22 Jan 2021 19:25:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Fundamental Mechanism of Scaling]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25875156">thread link</a>) | @ignoramous
<br/>
January 22, 2021 | https://brooker.co.za/blog/2021/01/22/cloud-scale.html | <a href="https://web.archive.org/web/*/https://brooker.co.za/blog/2021/01/22/cloud-scale.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post">


<p>It's not Paxos, unfortunately.</p>


<p>A common misconception among people picking up distributed systems is that replication and consensus protocols—Paxos, Raft, and friends—are the tools used to build the largest and most scalable systems. It's obviously true that these protocols are important building blocks. They're used to build systems that offer more availability, better durability, and stronger integrity than a single machine. At the most basic level, though, they don't make systems scale.</p>

<p>Instead, the fundamental approach used to scale distributed systems is <em>avoiding</em> co-ordination. Finding ways to make progress on work that doesn't require messages to pass between machines, between clusters of machines, between datacenters and so on. The fundamental tool of cloud scaling is coordination avoidance.</p>

<p><strong>A Spectrum of Systems</strong></p>

<p>With this in mind, we can build a kind of spectrum of the amount of coordination required in different system designs:</p>

<p><em>Coordinated</em> These are the kind that use paxos, raft, chain replication or some other protocol to make a group of nodes work closely together. The amount of work done by the system generally scales with the offered work (<em>W</em>) and the number of nodes (<em>N</em>), something like O(<em>N</em> * <em>W</em>) (or, potentially, worse under some kinds of failures).</p>

<p><em>Data-dependent Coordination</em> These systems break their workload up into uncoordinated pieces (like shards), but offer ways to coordinate across shards where needed. Probably the most common type of system in this category is sharded databases, which break data up into independent pieces, but then use some kind of coordination protocol (such as two-phase commit) to offer cross-shard transactions or queries. Work done can vary between O(<em>W</em>) and O(<em>N</em> * <em>W</em>) depending on access patterns, customer behavior and so on.</p>

<p><em>Leveraged Coordination</em> These systems take a coordinated system and build a layer on top of it that can do many requests per unit of coordination. Generally, coordination is only needed to handle failures, scale up, redistribute data, or perform other similar management tasks. In the happy case, work done in these kinds of systems is O(<em>W</em>). In the bad case, where something about the work or environment forces coordination, they can change to O(<em>N</em> * <em>W</em>) (see <a href="http://brooker.co.za/blog/2019/05/01/emergent.html">Some risks of coordinating only sometimes</a> for more). Despite this risk, this is a rightfully popular pattern for building scalable systems.</p>

<p><em>Uncoordinated</em> These are the kinds of systems where work items can be handled independently, without any need for coordination. You might think of them as embarrassingly parallel, sharded, partitioned, geo-partitioned, or one of many other ways of breaking up work. Uncoordinated systems scale the best. Work is always O(<em>W</em>).</p>

<p>This is only one cut through a complex space, and some systems don't quite fit<sup><a href="#foot1">1</a></sup>.  I think it's still useful, though, because by building a hierarchy of coordination we can think clearly about the places in our systems that scale the best and worst. The closer a system is to the uncoordinated end the better it will scale, in general.</p>

<p><strong>Other useful tools</strong></p>

<p>There are many other ways to approach this question of when coordination is necessary, and how that influences scale.</p>

<p>The CAP theorem<sup><a href="#foot2">2</a></sup>, along with a rich tradition of other impossibility results<sup><a href="#foot3">3</a></sup>, places limits on the kinds of things systems can do (and, most importantly, the kinds of things they can offer to their clients) without needing coordination. If you want to get into the details there, the breakdown in Figure 2 of <a href="http://www.bailis.org/papers/hat-vldb2014.pdf">Highly Available Transactions: Virtues and Limitations</a> is pretty clear. I like it because it shows us both what is possible, and what isn't.</p>

<p>The <a href="https://arxiv.org/pdf/1901.01930.pdf">CALM theorem</a><sup><a href="#foot4">4</a></sup> is very useful, because it provides a clear logical framework for whether particular programs can be run without coordination, and something of a path for constructing programs that are coordination free. If you're going to read just one distributed systems paper this year, you could do a lot worse than <a href="https://arxiv.org/pdf/1901.01930.pdf">Keeping CALM</a>.</p>

<p><a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.33.411">Harvest and Yield</a> is another way to approach the problem, by thinking about when systems can return partial results<sup><a href="#foot4">4</a></sup>. This is obviously a subtle topic, because the real question is when your clients and customers can accept partial results, and how confused they will be when they get them. At the extreme end, you start expecting clients to write code that can handle any subset of the full result set. Sometimes that's OK, sometimes it sends them down the same rabbit hole that CALM takes you down. Probably the hardest part for me is that partial-result systems are hard to test and operate, because there's a kind of mode switch between partial and complete results and <a href="https://aws.amazon.com/builders-library/avoiding-fallback-in-distributed-systems/">modes make life difficult</a>. There's also the minor issue that there are 2<sup>N</sup> subsets of results, and testing them all is often infeasible. In other words, this is a useful too, but it's probably best not to expose your clients to the full madness it leads to.</p>

<p>Finally, we can think about the work that each node needs to do. In a <em>coordinated</em> system, there is generally one or more nodes that do O(<em>W</em>) work. In an uncoordinated system, the ideal node does O(<em>W</em>/<em>N</em>) work, which turns into O(1) work because <em>N</em> is proportional to <em>W</em>.</p>

<p><strong>Footnotes</strong></p>

<ol>
<li><a name="foot1"></a> Like systems that coordinate heavily on writes by mostly avoid coordination on reads. <a href="https://www.usenix.org/legacy/event/usenix09/tech/full_papers/terrace/terrace.pdf">CRAQ</a> is one such system, and a paper that helped me fall in love with distributed systems. So clever, and so simple once you understand it.</li>
<li><a name="foot2"></a> Best described by <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.67.6951&amp;rep=rep1&amp;type=pdf">Brewer and Lynch</a>.</li>
<li><a name="foot3"></a> See, for example, Nancy Lynch's 1989 paper <a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.13.5022">A Hundred Impossibility Proofs for Distributed Computing</a>. If there were a hundred of these in 1989, you can imagine how many there are now, 32 years later. Wow, 1989 was 32 years ago. Huh.</li>
<li><a name="foot4"></a> I wrote <a href="http://brooker.co.za/blog/2014/10/12/harvest-yield.html">a post</a> about it back in 2014.</li>
</ol>


</div></div>]]>
            </description>
            <link>https://brooker.co.za/blog/2021/01/22/cloud-scale.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25875156</guid>
            <pubDate>Fri, 22 Jan 2021 19:21:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The widening gyre: how to decentralize Bitcoin]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25875107">thread link</a>) | @ur-whale
<br/>
January 22, 2021 | https://laanwj.github.io/2021/01/21/decentralize.html | <a href="https://web.archive.org/web/*/https://laanwj.github.io/2021/01/21/decentralize.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Recent events have made me reflect on a few things in my life I was already thinking about for a while. Also, responses on social media have made me realize that people have <em>strange</em> expectations from me, and what my role in the Bitcoin Core project is.</p>

<h2 id="growth">growth</h2>

<p>Bitcoin has grown a lot since I started contributing to it in 2011. Some arrangements that were acceptable for a small scale FOSS project are no longer so for one runing a 600 billion dollar system. Market cap is famously deceptive, but my point is not about specific numbers here.</p>

<p>One thing is clear: this is a serious project now, and we need to start taking decentralization seriously.</p>

<h2 id="moving-on">moving on</h2>

<p>I realize I am myself somewhat of a centralized bottleneck. And although I find Bitcoin an extremely interesting project and believe it’s one of the most important things happening at the moment, I also have many other interests. It’s also particularly stressful and I don’t want it, nor the bizarre spats in the social media around it, to start defining me as a person.</p>

<h2 id="spreading-out">spreading out</h2>

<p>I will start by delegating my own tasks, and decreasing my involvement. I do not intend to stop contributing to Bitcoin, or even to the Bitcoin Core project, but I would like to remove myself from the critical path and take (even more) of a background role.</p>

<p>Note that we had a nice growth in development activity, and that maintenance of the code itself has already been spread over multiple people for a while. I’m not the most active maintainer. Looking at the number of git merges</p>

<div><div><pre><code>bitcoin<span>$ </span>git log <span>--pretty</span><span>=</span><span>"format:%cn"</span> <span>--merges</span> <span>--since</span><span>=</span>2020-01-01 | <span>sort</span>| <span>uniq</span> <span>-c</span>
    313 fanquake
     51 Jonas Schnelli
    727 MarcoFalke
      7 Pieter Wuille
     65 Samuel Dobson
    363 Wladimir J. van der Laan
</code></pre></div></div>

<p>Only about 24% of the merges were done by me, last year.</p>

<h2 id="plans">plans</h2>

<p>But there’s plenty of things left to figure out, from the top of my head:</p>

<ul>
  <li>
    <p>Decentralize distribution.</p>

    <ul>
      <li>
        <p>In the short run, transfer bitcoincore.org to an organization instead of private ownership. Reduce the “bus factor”.</p>
      </li>
      <li>
        <p>I think it would be good if some other organizations set up mirrors, so there is less incentive to try to take bitcoincore.org down.</p>
      </li>
      <li>
        <p>In the long run, move away from a website for code distribution completely. No matter who owns it, a website on the clearnet can be shut down with the press of a button, and it seems that the global internet is gearing up to make censorship increasingly easy. We need a decentralized web. For us, one option would be IPFS, which is starting to catch on. For the binaries themselves there’s already the option of downloading through torrents.</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Decentralize the release process, and release signing.</p>

    <ul>
      <li>
        <p>Delegate more parts of the release process. Other maintainers should be able to do a release without my involvement.</p>
      </li>
      <li>
        <p>Rename the GPG key used to sign <code>SHA256SUMS.asc</code> to “Bitcoin Core release signing key”, instead of having it in my personal title. Make some construct so that N of M (minimally) trusted gitian signers doing a succesful build automatically results in a signed distribution.</p>
      </li>
      <li>
        <p>Same for the native code signing for Windows and MacOS.</p>
      </li>
      <li>
        <p>Even better in the long run would be to split up the keys, e.g. though RSA threshold signing, so that the whole process is geographically distributed.</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Decentralize the development hub.</p>

    <ul>
      <li>It’s not clear whether github can be trusted to act in our interest in the long run. Although issues and PRs are backed up through the API, having to move somewhere else could give significant interruption in development. And hopping from provider to provider would be awful—ideally the whole thing would not rely on a central server <em>at all</em>. For this I’ve been watching the <a href="https://radicle.xyz/">radicle</a> project, a P2P distributed code collaboration platform. It’s not quite there yet, but seems promising.</li>
    </ul>
  </li>
</ul>

<p>Bitcoin is quite different in some of the requirements here from other FOSS projects, so we’ll have to develop some tools as we go. We could also, definitely, use some help here.</p>

<p>Some smaller things to consider:</p>

<ul>
  <li>
    <p>Find someone else who wants to do the IRC meeting chair instead of me. Or maybe rotate it between multiple people.</p>
  </li>
  <li>
    <p>Release (and release candidate) mails to the <code>bitcoin-dev</code> and <code>bitcoin-core-dev</code> lists will no longer be necessarily signed and sent by me.</p>
  </li>
  <li>
    <p>There’s some development specific tooling hosted by me (e.g. the PR notification bots on IRC and mastodon). As they are non-critical and only little time goes into maintaining them, I’m fine with this for now.</p>
  </li>
</ul>

<p>As for decentralizing Bitcoin’s node software itself:</p>

<ul>
  <li>Carl Dong’s <code>libbitcoin_kernel</code> work. Bitcoin Core is a large monolithic project which includes the consensus code, which is much more critical than the other parts. The kernel would be an isolated part with well-defined interface, and at some point, its own review flow for changes. The difference with previous <code>libbitcoin_consensus</code> plans is that the kernel is stateful: it includes UTXO management and validation. It however does not include P2P, mempool policy, wallet, GUI, and RPC code. It could be re-used in different clients, to have more diversity in clients, but without the risks of a deviating consensus implementation.</li>
</ul>

<p>Over the course of 2021 this will be my focus with regard to Bitcoin Core.</p>

  </div></div>]]>
            </description>
            <link>https://laanwj.github.io/2021/01/21/decentralize.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25875107</guid>
            <pubDate>Fri, 22 Jan 2021 19:16:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple plans new MacBook Air with Magsafe, MacBook Pro with SD Card Slot]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25874703">thread link</a>) | @fudgy
<br/>
January 22, 2021 | https://www.bloomberg.com./news/articles/2021-01-22/apple-aapl-plans-new-macbook-air-with-magsafe-macbook-pro-with-sd-card-slot | <a href="https://web.archive.org/web/*/https://www.bloomberg.com./news/articles/2021-01-22/apple-aapl-plans-new-macbook-air-with-magsafe-macbook-pro-with-sd-card-slot">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
        <section>
            <h3>Why did this happen?</h3>
            <p>Please make sure your browser supports JavaScript and cookies and that you are not blocking them from loading. For more information you can review our <a href="https://www.bloomberg.com./notices/tos">Terms of Service</a> and <a href="https://www.bloomberg.com./notices/tos">Cookie Policy</a>.</p>
        </section>
        <section>
            <h3>Need Help?</h3>
            <p>For inquiries related to this message please <a href="https://www.bloomberg.com./feedback">contact our support team</a> and provide the reference ID below.</p>
            <p>Block reference ID: </p>
        </section>
    </section></div>]]>
            </description>
            <link>https://www.bloomberg.com./news/articles/2021-01-22/apple-aapl-plans-new-macbook-air-with-magsafe-macbook-pro-with-sd-card-slot</link>
            <guid isPermaLink="false">hacker-news-small-sites-25874703</guid>
            <pubDate>Fri, 22 Jan 2021 18:46:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Avalonia 0.10.0 Release – A cross platform XAML framework for .NET]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25874397">thread link</a>) | @wiso
<br/>
January 22, 2021 | http://avaloniaui.net/blog/2020-12-29-avalonia-0.10.0-release | <a href="https://web.archive.org/web/*/http://avaloniaui.net/blog/2020-12-29-avalonia-0.10.0-release">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    
    <dl>
        <dt>Published</dt>
        <dd>2020-12-29</dd>

        <dt>Author</dt>
        <dd>Steven Kirk</dd>

        <dt>Category</dt>
          <dd>Release</dd>
    </dl>
    <p>We are pleased to announce that <a href="https://github.com/AvaloniaUI/Avalonia">Avalonia</a> 0.10.0 has been
released.</p>
<p>0.10 is a huge update, it has been extensively tested and brings some great new features and improvements.</p>
<h2 id="fluent-theme">Fluent Theme</h2>
<p>The most noticable change for Avalonia 0.10 is a beautiful new Fluent theme. Now your Avalonia applications will look better than ever:</p>
<p><img src="http://avaloniaui.net/blog/2020-12-29-avalonia-0.10.0-release/fluent-control-gallery-light.png" alt="Xaml Control Gallery">
<img src="http://avaloniaui.net/blog/2020-12-29-avalonia-0.10.0-release/fluent-control-gallery-dark.png" alt="Xaml Control Gallery">
<a href="https://github.com/AvaloniaUI/xamlcontrolsgallery">Xaml Control Gallery</a></p>
<p>The fluent theme is available in light and dark modes, and will be used by the 0.10 templates by default. It can be enabled in existing applications by including the following in your <code>App.axaml</code>:</p>
<pre><code>&lt;Application.Styles&gt;
  &lt;FluentTheme Mode="Light"/&gt;
&lt;/Application.Styles&gt;
</code></pre>
<p>Where <code>Mode</code> can be <code>Light</code> or <code>Dark</code>.</p>
<h2 id="new-controls">New Controls</h2>
<p>Along with the fluent theme, several new controls have been added:</p>
<h3 id="datepickertimepicker">DatePicker/TimePicker</h3>
<p>The <code>DatePicker</code> and <code>TimePicker</code> controls give you a standardized way to let users pick a localized date or time value value using touch, mouse, or keyboard input.</p>
<pre><code>&lt;DatePicker Header="Date of birth"/&gt;
</code></pre>
<p><img src="http://avaloniaui.net/blog/2020-12-29-avalonia-0.10.0-release/datepicker.png" alt="Xaml Control Gallery"></p>
<h3 id="toggleswitch">ToggleSwitch</h3>
<p><code>ToggleSwitch</code> is a control that can be toggled between 2 states.</p>
<pre><code>&lt;ToggleSwitch OffContent="Power Off" OnContent="Power On"/&gt;
</code></pre>
<p><img src="http://avaloniaui.net/blog/2020-12-29-avalonia-0.10.0-release/toggleswitch.png" alt="Xaml Control Gallery"></p>
<h3 id="label">Label</h3>
<p>The <code>Label</code> control allows a text label with a shortcut key to be assocated with a control such as a <code>TextBox</code> such that pressing Alt plus the shortcut key will focus the associated control:</p>
<pre><code>&lt;StackPanel&gt;
  &lt;!-- Pressing Alt+N will focus nameTextBox --&gt;
  &lt;Label Target="nameTextBox"&gt;_Name&lt;/Label&gt;
  &lt;TextBox Name="nameTextBox"&gt;
&lt;/StackPanel&gt;
</code></pre>
<p>The shortcut key is designated by prepending an underscore to the desired character in the <code>Label</code> content, <code>N</code> in this example.</p>
<p>Related PRs:</p>
<ul>
<li><a href="https://github.com/AvaloniaUI/Avalonia/pull/4904">https://github.com/AvaloniaUI/Avalonia/pull/4904</a></li>
</ul>
<h2 id="compiled-bindings">Compiled Bindings</h2>
<p>Avalonia 0.10 includes experimental support for compiled bindings. When using compiled bindings, binding paths are verified at compile time and do not use reflection at runtime.</p>
<p>To enable compiled bindings, add an <code>x:DataType</code> attribute to your root control and use the <code>{CompiledBinding}</code> markup extension or set <code>x:CompileBindings="True"</code>.</p>
<pre><code>&lt;Window xmlns="https://github.com/avaloniaui"
        xmlns:x='http://schemas.microsoft.com/winfx/2006/xaml'
        x:Class="AvaloniaApplication"
        xmlns:vm="using:AvaloniaApplication.ViewModels" 
        x:DataType="vm:MainWindowViewModel"&gt;
  &lt;!-- The existence of the MyValue property will be checked at compile-time --&gt;
  &lt;TextBox Text="{CompiledBinding MyValue}"/&gt;
&lt;/Window&gt;
</code></pre>
<p><a href="http://avaloniaui.net/docs/advanced/compiled-bindings">Documentation</a></p>
<p>Related PRs:</p>
<ul>
<li><a href="https://github.com/AvaloniaUI/Avalonia/pull/2734">https://github.com/AvaloniaUI/Avalonia/pull/2734</a></li>
</ul>
<h2 id="unicode-support">Unicode Support</h2>
<p>Avalonia's <code>TextBlock</code> now correctly supports unicode characters.</p>
<p><img src="http://avaloniaui.net/blog/2020-12-29-avalonia-0.10.0-release/unicode.png" alt="Unicode Support"></p>
<p>Full Unicode support for <code>TextBox</code> will be incoming in the near future.</p>
<p>Related PRs:</p>
<ul>
<li><a href="https://github.com/AvaloniaUI/Avalonia/pull/3438">https://github.com/AvaloniaUI/Avalonia/pull/3438</a></li>
</ul>
<h2 id="box-shadows">Box Shadows</h2>
<p>Box shadows can now be applied to <code>Border</code> controls:</p>
<pre><code>&lt;Border BoxShadow="4 4 4 gray"
        Background="Silver"
        Margin="20"
        Padding="10"&gt;
  &lt;TextBlock&gt;Box Shadow&lt;/TextBlock&gt;
&lt;/Border&gt;
</code></pre>
<p><img src="http://avaloniaui.net/blog/2020-12-29-avalonia-0.10.0-release/box-shadow.png" alt="Box Shadows"></p>
<p><a href="http://avaloniaui.net/docs/controls/border#box-shadows">Documentation</a></p>
<p>Related PRs:</p>
<ul>
<li><a href="https://github.com/AvaloniaUI/Avalonia/pull/3871">https://github.com/AvaloniaUI/Avalonia/pull/3871</a></li>
</ul>

<p>DevTools has been completely revamped for the 0.10 release.</p>
<p><img src="http://avaloniaui.net/blog/2020-12-29-avalonia-0.10.0-release/devtools.png" alt="DevTools"></p>
<p>The new features include:</p>
<ul>
<li>A built-in console using roslyn scripting which allows running arbitrary code</li>
<li>Editing of property values</li>
<li>Improved display and grouping of control properties</li>
<li>Filtering control properties using a string or regular expression</li>
<li>A visualization of a control's layout properties such as width, height, margins and padding:</li>
<li>Toggle an FPS overlay and dirty rect visualization for the window from DevTools from the "Options" menu</li>
</ul>
<p><a href="http://avaloniaui.net/docs/quickstart/devtools">Documentation</a></p>
<p>Related PRs:</p>
<ul>
<li><a href="https://github.com/AvaloniaUI/Avalonia/pull/3462">https://github.com/AvaloniaUI/Avalonia/pull/3462</a></li>
<li><a href="https://github.com/AvaloniaUI/Avalonia/pull/4523">https://github.com/AvaloniaUI/Avalonia/pull/4523</a></li>
<li><a href="https://github.com/AvaloniaUI/Avalonia/pull/4529">https://github.com/AvaloniaUI/Avalonia/pull/4529</a></li>
<li><a href="https://github.com/AvaloniaUI/Avalonia/pull/4609">https://github.com/AvaloniaUI/Avalonia/pull/4609</a></li>
</ul>
<h2 id="typed-property-change-notifications">Typed Property Change Notifications</h2>
<p>The <code>OnPropertyChanged</code> method and <code>AvaloniaProperty&lt;T&gt;.Changed</code> observable APIs have been changed to use a typed <code>AvaloniaPropertyChangedEventArgs&lt;T&gt;</code> class to prevent boxing. Note that this is a <a href="https://github.com/AvaloniaUI/Avalonia/wiki/Breaking-Changes">breaking change</a>.</p>
<p>Related PRs:</p>
<ul>
<li><a href="https://github.com/AvaloniaUI/Avalonia/pull/3255">https://github.com/AvaloniaUI/Avalonia/pull/3255</a></li>
<li><a href="https://github.com/AvaloniaUI/Avalonia/pull/4648">https://github.com/AvaloniaUI/Avalonia/pull/4648</a></li>
</ul>
<h2 id="selectionmodel">SelectionModel</h2>
<p>Selection on <code>SelectingItemsControl</code>-derived controls such as <code>ListBox</code> and <code>ComboBox</code> now implement their selection tracking via a <code>SelectionModel</code> which gives the following improvements:</p>
<ul>
<li>Selection ranges are now stored as a range of indexes, so selecting all items in a large list of for example 100,000 elements is now stored simply as a range of <code>0-99999</code>. Previously each selected item was added to a list, inflating memory usage</li>
<li>Selection now handles duplicate items</li>
<li>The selection model can be bound to a view model allowing fine control of the selected items at the view model layer</li>
</ul>
<p><a href="http://avaloniaui.net/docs/controls/listbox#selection">Documentation</a></p>
<p>Related PRs:</p>
<ul>
<li><a href="https://github.com/AvaloniaUI/Avalonia/pull/4533">https://github.com/AvaloniaUI/Avalonia/pull/4533</a></li>
</ul>
<h2 id="breaking-changes">Breaking Changes</h2>
<p>See <a href="https://github.com/AvaloniaUI/Avalonia/wiki/Breaking-Changes">our wiki</a> for a list of breaking changes in this release.</p>
<h2 id="getting-started">Getting started</h2>
<p>Follow instructions <a href="http://avaloniaui.net/docs/quickstart">here</a>.</p>
<h2 id="support-and-contributing">Support and Contributing</h2>
<p>The best way to support Avalonia is to get involved, implement a feature, fix a bug or help test. See <a href="http://avaloniaui.net/contributing">contributing</a> for information on how to get started.</p>
<p>For commercial users, AvaloniaUI OÜ provides support packages and custom development services. Contact us at team@avaloniaui.net for more information.</p>
<p>Otherwise you can sponsor Avalonia financially via <a href="https://opencollective.com/Avalonia#sponsor">OpenCollective</a>.</p>
<p>We hope you enjoy developing with Avalonia - please let us know what you are building!</p>
<p><a href="https://github.com/grokys">grokys</a></p>

  </article></div>]]>
            </description>
            <link>http://avaloniaui.net/blog/2020-12-29-avalonia-0.10.0-release</link>
            <guid isPermaLink="false">hacker-news-small-sites-25874397</guid>
            <pubDate>Fri, 22 Jan 2021 18:19:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How hard should I push myself?]]>
            </title>
            <description>
<![CDATA[
Score 260 | Comments 175 (<a href="https://news.ycombinator.com/item?id=25874374">thread link</a>) | @dshipper
<br/>
January 22, 2021 | https://superorganizers.every.to/p/how-hard-should-i-push-myself | <a href="https://web.archive.org/web/*/https://superorganizers.every.to/p/how-hard-should-i-push-myself">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F3d2ebce7-e447-49bf-a6b4-f78c21198041_1400x934.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F3d2ebce7-e447-49bf-a6b4-f78c21198041_1400x934.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/3d2ebce7-e447-49bf-a6b4-f78c21198041_1400x934.jpeg&quot;,&quot;height&quot;:934,&quot;width&quot;:1400,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:181814,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>How hard should I push myself?</p><p>It’s a question I ask myself a lot, and I bet you do too. On the one hand I really want to push myself. I’m ambitious, I want to leave it all out on the field—some of my peak work moments have come from times when I’ve pushed myself to a place where I didn’t think I could go. We all have more ability to adapt to stress and pressure than we think we do.</p><p>On the other hand, I want to be kind to myself. I wonder how much the drive to push myself is really just a drive to make up for something that I feel is missing or inadequate—and whether pushing myself will actually fill the hole. I also sometimes wonder whether letting myself off the hook is just laziness masquerading as self-care. It’s hard to tell.</p><p>But importantly, I wonder whether pushing myself might, in fact, kill me. Constant pressure creates chronic stress, and there’s all sorts of scientific studies that show that chronic stress is really bad for you. It makes you more susceptible to heart disease, it makes it harder to recover from illnesses, it can affect your sleep, and it can even affect your working memory.</p><p>There’s also all sorts of literature (and conversations on Twitter) that says that stress is actually good for you.&nbsp;</p><p>What gives? How much stress is good, and how much is bad?&nbsp;</p><p>I think that in order to understand the question we posed at the top—how much we should be pushing ourselves—we have to better understand stress. We need to understand what the stress of pushing ourselves does to our bodies, how much we can take of it, and how we can, hopefully, learn to cope with it better.</p><p>That’s what <a href="https://us.macmillan.com/books/9780805073690">Why Zebra's Don't Get Ulcers</a> by Robert M. Sapolsky is about. Robert's a stress researcher, and as far as I can tell he's one of the good ones. He's the kind of intellectual who's smart, but also smart enough to know what he doesn't know. He's written a book, but he doesn't come across as trying to sell it to you—he's kind of like your zany self-aware smart-as-hell uncle who happens to study the stress responses of baboons for a living.</p><p>In the book Dr. Sapolsky harnesses his own research, as well as a wide array of animal and human studies to figure out the answer to a fairly simple question: how does stress work, and why do humans get stress-related diseases?&nbsp;</p><p>It’s an interesting question—you can understand why a human body might react poorly to not being fed enough. But why would psychological stress have dangerous consequences? The basic gist is this:&nbsp;</p><p>The stress response is built to get us out of danger. If you're an animal in the Serengeti and you're being chased by a lion you really, really want to have a stress response. Being stressed means you’re preparing your muscles to move—a lot. Your heart rate rises and pushes blood to your extremities. Glucose is released into your bloodstream to help run your muscles as fast as possible.&nbsp;</p><p>The stress response pushes certain parts of your body into high gear—but it also turns certain parts of your body off. For example, when you’re stressed digestion is inhibited. What’s the point of wasting energy on digesting food for later when you might not even survive for 10 more minutes? Reproduction is also inhibited. Same reason.&nbsp;</p><p>This is all well and good in the wild—you don't need to reproduce if a lion is eating your face off. But humans, and some more intelligent animals, have evolved the stress response from an unqualified Good Thing into...well, something that might kill you.</p><p>What’s different about our stress response? Well, we have the ability to <em>anticipate</em> danger. Other animals have this ability too: it’s a good thing to get stressed seeing the lion all the way across the savannah, instead of only when it mauls your intestines out. But humans have evolved this anticipation ability to extend far beyond other animals. We anticipate bad things months, years, or even decades out. And when we do this, the very same stress response gets turned on—even though there is no immediate danger, and there is no immediate way to avoid it.&nbsp;</p><p>Suddenly, you aren’t just activating the stress response for a few minutes when you’re running for your life. Instead, it’s activated all the time—chronically. And this is where the problems start.&nbsp;</p><p>Remember we mentioned earlier that the stress response amps some parts of your body into high gear, and turns off others? If you’re doing that chronically, you start to have problems. Suddenly, your digestive system isn’t just inhibited for a few minutes while you’re escaping danger. It’s chronically inhibited. The same thing happens with your immune system—chronic stress tamps it down, and makes it harder for you to fight off diseases. Stress is bad for your heart too—if you’re pumping blood as if you need to run from something all the time, you’re going to get high blood pressure.&nbsp;</p><p>In these cases, according to Sapolsky, “the stress response can become more dangerous than the stressor itself, especially when the stress is purely psychological.”</p><p>To be clear, stress doesn’t actually make you sick. But it does leave you more vulnerable to disease and illnesses than you otherwise would be—and those <em>can</em> make you very sick.</p><h3><strong>So is stress bad?</strong></h3><p>Stress isn’t good or bad. It’s a tool. In small doses it’s good, but too much of a good thing becomes a bad thing pretty quickly.</p><p>When your stress response is working properly it makes you run faster, your memory gets better, you’re able to focus better. But when your stress response is over-activated, or chronically activated—you get ulcers and heart disease. It’s bad!&nbsp;</p><p>A good analogy is exercise. Too little exercise and you open yourself up to a whole host of diseases, both physical and psychological. Too much, and you can actually kill yourself.&nbsp;</p><h3><strong>What do we do about it?</strong></h3><p>The answer to the question we posed at the top, then, is that it’s great to push yourself—but you should be paying attention to the signs that tell you that you need a break. And it’s to give yourself plenty of ways to manage stress while you’re going through it, so that it doesn’t affect you as badly as it could.</p><p>This is the really interesting nugget: stress isn’t mathematical. Expose the same person to the same stressor and they will have different stress responses based on their coping strategies. Which means if you want to live a life where you’re pushing yourself, it’s best to develop a variety of coping strategies to help you manage it.&nbsp;</p><p>Here’s what Sapolsky recommends:</p><h4><strong>Increase your sense of control</strong>.&nbsp;</h4><p>If you put a human in a room where loud noises are going off, you’ll activate their stress response. If you give the human a button to reduce the volume of the loud noises they’ll be less stressed—regardless of whether they even use the button.&nbsp;</p><p>What that means is, just knowing you have the <em>option</em> to reduce stress is enough to make something less stressful—even if you’re not actually controlling the stressors at all.&nbsp;</p><p>It’s why the first few sessions of therapy are often so powerful for patients. You’ve finally found a way to manage how you’re feeling, even though you probably haven’t changed too much about your life.</p><p>When you’re facing mild to moderate stressors, ask yourself, <em>How can I increase my sense of control in this situation?</em> You might find there are simple answers that will make you feel a lot better.</p><h4><strong>Increase your sense of predictability.</strong></h4><p>Rats that are exposed to repeated electric shocks are more likely to get ulcers. But if you ring a bell before you administer the shock—making the shock more predictable—the rats are less likely to get ulcers. If you make the stressor predictable, you only have to get stressed right before it happens. That means you’re not stressed the rest of the time, and therefore the stress response doesn’t wreak as much havoc on your body.</p><p>Making the stressors in your life more predictable can have a similar effect. When you see CEOs that keep their calendars clear and never do phone calls—you’re seeing the benefit of predictability in action.</p><p>Of course, we can’t make our lives totally predictable (and in fact that wouldn’t be desirable.) But the more you can expose yourself to stressors in a predictable way the better off you’ll be. For example, maybe only doomscroll on Twitter once a week. Or only check email a couple of times a day.</p><h4><strong>Create outlets for frustration.</strong></h4><p>When rats that are exposed to repeated stressors are given a piece of wood to gnaw on, they are far less likely to develop ulcers. Outlets for frustration are another important coping mechanism for stress.&nbsp;&nbsp;</p><p>There are many unproductive outlets—for example, taking things out on your partner or a co-worker. But there are also many productive ones, like exercise or journaling. Making a list of outlets and making sure to return to them again and again can reduce the havoc that chronic stress can wreak on your body.</p><h4><strong>Increase social support.</strong></h4><p>Social support is the last coping strategy on the list, and it’s perhaps my favorite one.</p><p>If you give a primate a stressor in the lab, you’ll find elevated markers of stress in its behavior and in its blood. But give the primate a stressor when it’s surrounded by friends—its stress markers will be lower, even for the same level of stressor.</p><p>The same thing happens in humans. For example, in one study parents of children who have been killed in war were no more likely to get disease or die—except if they were already widowed or divorced.</p><p>Creating a vibrant sense of social support can put an unmanageable stressor into perspective and help keep it under control. Without social support, even small things can set us off in ways that are unproductive and unhealthy.</p><h2><strong>What did you think of this article?</strong></h2><p><a href="https://docs.google.com/forms/d/e/1FAIpQLSeMqlgyA7pSRFgxvzNkEFFqsPIvmkxtZ81IiGD0LQzYFL5-AA/viewform?usp=pp_url&amp;entry.1276325438=Amazing">Amazing</a>&nbsp;-&nbsp;&nbsp;<a href="https://docs.google.com/forms/d/e/1FAIpQLSeMqlgyA7pSRFgxvzNkEFFqsPIvmkxtZ81IiGD0LQzYFL5-AA/viewform?usp=pp_url&amp;entry.1276325438=Good">Good</a>&nbsp;-&nbsp;&nbsp;<a href="https://docs.google.com/forms/d/e/1FAIpQLSeMqlgyA7pSRFgxvzNkEFFqsPIvmkxtZ81IiGD0LQzYFL5-AA/viewform?usp=pp_url&amp;entry.1276325438=Meh">Meh</a>&nbsp;-&nbsp;&nbsp;<a href="https://docs.google.com/forms/d/e/1FAIpQLSeMqlgyA7pSRFgxvzNkEFFqsPIvmkxtZ81IiGD0LQzYFL5-AA/viewform?usp=pp_url&amp;entry.1276325438=Bad">Bad</a></p></div></div>]]>
            </description>
            <link>https://superorganizers.every.to/p/how-hard-should-i-push-myself</link>
            <guid isPermaLink="false">hacker-news-small-sites-25874374</guid>
            <pubDate>Fri, 22 Jan 2021 18:16:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Address and POI Matching Without Writing Code]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25874219">thread link</a>) | @kpaddie10
<br/>
January 22, 2021 | https://www.placekey.io/blog/introducing-placekey-for-google-sheets-and-placekey-for-excel | <a href="https://web.archive.org/web/*/https://www.placekey.io/blog/introducing-placekey-for-google-sheets-and-placekey-for-excel">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Read more about the announcement in <a href="https://www.directionsmag.com/pressrelease/10385"><em>Directions Magazine</em></a>.</p><p>‍</p><p>Imagine you’re a retail brand trying to determine which of your stores performs best on a revenue-per-visit basis (RPV), compared to others. How would you solve this problem?</p><p>Analyses like these are interesting, because they require multiple disparate datasets to be brought together in order to tell a story. In this example, you’d be analyzing transaction data to calculate revenue per store over a certain time period, along with foot-traffic data. Maybe you’d even compare it against other variables like store age, square footage, and more. You would want to use data from different sources— store transaction data from <a href="https://www.affinity.solutions/">Affinity Solutions</a>, and foot traffic data from <a href="https://www.safegraph.com/?utm_source=referral&amp;utm_medium=pkblog&amp;utm_campaign=nocode">SafeGraph</a>.<br></p><p>The tough thing about this approach is that you need all these datasets to talk to each other. Problems like these are why data scientists spend up to <a href="https://www.forbes.com/sites/gilpress/2016/03/23/data-preparation-most-time-consuming-least-enjoyable-data-science-task-survey-says/?sh=578166c86f63">80% of their time</a> doing <em>data preparation, </em>rather than driving insights. This situation is especially problematic when you’re working with location data, since many addresses don’t have standardization. A Target at 2626 E Stone Dr in one dataset might be listed as 2626 E Stone Dr Ste 90 in another, even though they’re the same store. A dataset indexed on the first address wouldn’t match the second.<br></p><p><a href="https://www.placekey.io/?utm_source=referral&amp;utm_medium=pkblog&amp;utm_campaign=nocode">Placekey</a> was designed to solve address and POI matching problems like these. It works like this: an address or place name is inputted, and Placekey generates a unique, authoritative identifier that can be used for address and POI matching, deduplication, normalization, entity resolution, and more.&nbsp;<br></p><p>This week, Placekey officially announced the launch of its no-code solutions for <a href="https://workspace.google.com/marketplace/app/address_matching_by_placekey/611255445050">Google Sheets</a> and <a href="https://appsource.microsoft.com/en-us/product/office/WA200002522?tab=Overview">Excel</a>. What this means is that thorny address and POI matching problems can now be solved without writing a single line of code.</p><p>We’ll look at how <a href="https://www.affinity.solutions/">Affinity Solutions</a>, a leading provider for consumer purchase and intent behavior is using Placekeys appended to their data sets to make it easier to combine with other data sets and drive insights. For more context, you can check Nitin Duggal, Affinity’s Chief Product Officer discussing Placekey here:</p><figure id="w-node-4a727786a108-be1d9f6e"><p><iframe allowfullscreen="true" frameborder="0" scrolling="no" src="https://www.youtube.com/embed/-WjKy-CK3Hs"></iframe></p></figure><p>This blog post will walk you through a practical example of a Placekey use case: where one is merging purchase intelligence information from Affinity, and places data from <a href="https://www.safegraph.com/?utm_source=referral&amp;utm_medium=pkblog&amp;utm_campaign=nocode">SafeGraph</a>— all without code.<strong>‍</strong></p><p><strong>The Data: Affinity and SafeGraph</strong><br></p><p>Since<strong> </strong><a href="https://www.affinity.solutions/">Affinity</a> is the leading provider of purchase data intelligence, their dataset covers granular transactions, down to the individual store level. Here’s a sample of data about US-based Target stores:</p><figure id="w-node-95555a0afff4-be1d9f6e"><p><img src="https://assets.website-files.com/5f277eb85e5f02d500828d71/600b0c41866be87357905e46_pasted%20image%200%20(11).png" loading="lazy" alt=""></p></figure><p>On the foot traffic data side, <a href="https://www.safegraph.com/">SafeGraph</a> aggregates anonymized location data from numerous applications, and generates information like number of visits, bucketed dwell times, and more. Here’s a sample of SafeGraph data for one US-based Target location:</p><figure id="w-node-3e414f5208fa-be1d9f6e"><p><img src="https://assets.website-files.com/5f277eb85e5f02d500828d71/600b0c667e793011bcda6851_pasted%20image%200%20(12).png" loading="lazy" alt=""></p></figure><p><strong>The Problem: Merging Location-based Datasets is Really Hard</strong><br></p><p>While we want to merge these datasets together in order to leverage Affinity’s spend data and SafeGraph’s mobility information for each store, addresses weren’t invented in a time of machine-tooled standardization. Arbitrary format convention differences in point-of-interest or POI naming s make the task of joining location-based datasets together super hard. For example, in these two data sets above, the respective address formats differ considerably.</p><figure id="w-node-8d54ce993e7f-be1d9f6e"><p><img src="https://assets.website-files.com/5f277eb85e5f02d500828d71/600b0c93e6ddc261570af0fe_pasted%20image%200%20(13).png" loading="lazy" alt=""></p></figure><p>To unlock the insights that come from bringing multiple datasets together, we need a way to cleanly merge address and POI data.<br></p><p><strong>The Solution: Meet Placekey</strong><br><a href="https://www.placekey.io/?utm_source=referral&amp;utm_medium=pkblog&amp;utm_campaign=nocode">Placekey</a> is a universal standard identifier for a physical location, and it was created to solve problems like these. Placekey does the tough job of address and POI resolution, standardization, validation, and geolocation behind the scenes, producing instead a simple identifier that uniquely identifies a place. Here, the two different street names resolve to the same Placekey, which can then be used to merge the data together.</p><figure id="w-node-79f19d4e95e1-be1d9f6e"><p><img src="https://assets.website-files.com/5f277eb85e5f02d500828d71/600b0cb2e832196767475950_pasted%20image%200%20(14).png" loading="lazy" alt=""></p></figure><p>Now, using Placekey as a join key to merge these two datasets produces the below dataset:</p><figure id="w-node-3ed6da2d5ebb-be1d9f6e"><p><img src="https://assets.website-files.com/5f277eb85e5f02d500828d71/600b0cfc02432de21342ed01_pasted%20image%200%20(15).png" loading="lazy" alt=""></p></figure><p>Now, from these columns, it is possible to directly compute dollars spent per visit - an analysis which relies on data from both Affinity and SafeGraph, and gives a more holistic view of revenue-per-visitor (RPV) at a granular level. We can also leverage the store age column to produce the below plot of store age vs. conversion.</p><figure id="w-node-3a095848eb16-be1d9f6e"><p><img src="https://assets.website-files.com/5f277eb85e5f02d500828d71/600b0ce987306118ee90cfe4_imageLikeEmbed.png" loading="lazy" alt=""></p></figure><p><br><strong>Demo: Merging Affinity and SafeGraph Data Using the Placekey No-Code Integrations for Excel and Google Sheets&nbsp;</strong><br></p><p>To conduct a similar analysis, you can append Placekeys to your dataset using Excel or Google Sheets. Here’s how you do it:<br></p><ul role="list"><li>After loading your data into Excel (or Google Sheets), open the Placekey extension, and click “Generate Placekeys”.</li><li>Enter your API key (note: this is not always required). If you don’t yet have one, sign up for free <a href="https://dev.placekey.io/default/register">here</a> in a few seconds.</li><li>Open the first dataset you’re working with. Map the headers in the data (i.e. brand, street, city, state, and zip) to the relevant API field values, and when you’re done, click “Generate Placekeys”</li></ul><figure id="w-node-45eaf86adc10-be1d9f6e"><p><img src="https://assets.website-files.com/5f277eb85e5f02d500828d71/600b0d7e55c3ac3341efb1c6_VJBq9jKrNxtRHhc_dBrUqPHLKjztah9WMIxAKLLJKxCzyCIEIhQm5LvmZYwPrXRIsq_MLA7NJchOMwVhSwl8vUpaNxFJBrOxTbki76wURGGyfjCV6NfuNGEk5S4m31dfrESv74j6.png" alt=""></p></figure><ul role="list"><li>After a few seconds, the Placekeys are appended to the data in a new column.</li></ul><figure id="w-node-d874ebb5fd9a-be1d9f6e"><p><img src="https://assets.website-files.com/5f277eb85e5f02d500828d71/600b0d6face7fd52ffb5a1e3_pasted%20image%200%20(16).png" loading="lazy" alt=""></p></figure><ul role="list"><li>Repeat the same process on the data you would like to join. Here, the SafeGraph data already has a Placekey column, making it super easy to join in without any pre-processing.&nbsp;</li><li>Use a standard Google Sheets or Excel VLOOKUP function to merge the rows of the two datasets. Here, we highlight two relevant columns — spend data from Affinity and visits data from SafeGraph, plus a simulated value for the age of the store.</li></ul><figure id="w-node-5e078560ae0b-be1d9f6e"><p><img src="https://assets.website-files.com/5f277eb85e5f02d500828d71/600b0d9612125f094b91615c_Bc_WWUQZg_xDdeCxE0-BuRAvglnxSooLagXQ6tvIJiIFbhT0TGcSmuyYWsPkuPQF-EJsWQVST-f-PD-YDRDvVH-QD-fJWJszu1CPnJqsTxLDbnWBdySZp4PLsSFS4S61o8GIuSOh.png" alt=""></p></figure><ul role="list"><li>From these columns, you can directly compute a measure of dollars spent per visit. As mentioned above, the store age column can also be leveraged to produce the below plot:</li></ul><figure id="w-node-3f488d7fa48d-be1d9f6e"><p><img src="https://assets.website-files.com/5f277eb85e5f02d500828d71/600b0dbc9d4c6158f07d5675_lbjMhl9cq1fxzd2OtRktHYaaOsyJbWRYUwmnngag3NQ7srwf4QPJ0FK52MIzq0-50ADb51SKn3xgA3tR6Y0sCrAhSq_S6k_zVH7fm3vgAcwcvoe3mKrgpFO2gLjtUQhYzNQX8F-P.png" alt=""></p></figure><p>This example demonstrates how any best-in-class transaction dataset can be joined to third-party data sources by leveraging Placekey to match addresses and POIs. Placekey opens the door for analyses such as this and many more to be performed by expanding the interoperability of different data solutions.</p><p>‍</p><p>‍</p></div></div>]]>
            </description>
            <link>https://www.placekey.io/blog/introducing-placekey-for-google-sheets-and-placekey-for-excel</link>
            <guid isPermaLink="false">hacker-news-small-sites-25874219</guid>
            <pubDate>Fri, 22 Jan 2021 18:02:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lessons learned in my first year being CTO]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25874094">thread link</a>) | @feross
<br/>
January 22, 2021 | https://shekhargulati.com/2021/01/03/being-chief-technology-officer-lessons-learned-in-my-first-year/ | <a href="https://web.archive.org/web/*/https://shekhargulati.com/2021/01/03/being-chief-technology-officer-lessons-learned-in-my-first-year/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-6462">
	<!-- .entry-header -->

	
	
	<div>
		<br>
<blockquote><p>Happy New Year!</p><p>2020 was a difficult year for most of us, as we fought with COVID-19 and came to terms with the remote way of working. It was a year when we had a lot more time in our hands as all of us were locked in our houses with almost no travel. The things that we took for granted were taken from us and there was a constant fear of losing the loved ones.&nbsp;</p><p>I hope in 2021 we regain our freedom to live freely. But, this time with a sense of responsibility and awareness.&nbsp;</p></blockquote>



<p>It is now little over a year since I became Chief Technology Officer (CTO) in my current organization. And, I thought it will be a good time to do a quick retrospective on the lessons learned in my first year as CTO. The journey has been tough but deeply rewarding for me. There were occasions when I thought the leadership role was not for me and I should go back to being an individual contributor. But, with support from my organization and learning (books, blogs, observation), I have started to enjoy the role and its challenges.</p>



<p>Before I talk about the lessons I learned, let’s look at my software engineering journey.&nbsp;&nbsp;</p>



<h2>My software engineering journey</h2>



<ul><li>2005-2008: Software Engineer</li><li>2008-2012: Senior Software Engineer</li><li>2013-2014: Principal Technology Evangelist</li><li>2014-2019: Principal Engineer/Architect (during this period, I was in the role of Director, but I was neck-deep in writing code, building systems, and technology consulting)</li><li>2020-present: Chief Technology Officer (my first leadership/management role)</li></ul>



<p>Yes, this is my first leadership and management role. The leap from an individual contributor to a CTO was as much nerve-wracking as it was ambitious in terms of responsibilities.</p>



<p>Of course, along with this opportunity came its share of pros and cons. Nonetheless, I took the plunge and went through this transition without any preconceived notion.&nbsp;&nbsp;</p>



<h2>Defining the CTO role</h2>



<p>When I was told that I will be the next CTO, I immediately looked for a playbook that would describe and provide best practices and guide me on the rules of becoming a good, successful CTO. I wanted to be ready for the role and study the entire CTO literature available on the web. Guess what? There was no such playbook.&nbsp;</p>



<p>At the end of the day, it is always about learning on the job and not making the same mistake twice.&nbsp;</p>



<p>The first thing that I read was what people usually define the role of Chief Technology Officer as. Apparently, it is one of the most confusing C-level roles, and each CTO plays a bit differently. The best description of this role that I found was in an <a href="https://www.linkedin.com/pulse/five-flavors-being-cto-matt-tucker/">essay</a> by Matt Tucker. According to Matt, to better understand the role, you should break into five flavors.</p>



<figure><a href="https://whyjava.files.wordpress.com/2021/01/screenshot-2021-01-03-at-9.09.34-pm.png"><img data-attachment-id="6464" data-permalink="https://shekhargulati.com/screenshot-2021-01-03-at-9-09-34-pm/" data-orig-file="https://whyjava.files.wordpress.com/2021/01/screenshot-2021-01-03-at-9.09.34-pm.png" data-orig-size="1248,704" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screenshot-2021-01-03-at-9.09.34-pm" data-image-description="" data-medium-file="https://whyjava.files.wordpress.com/2021/01/screenshot-2021-01-03-at-9.09.34-pm.png?w=300" data-large-file="https://whyjava.files.wordpress.com/2021/01/screenshot-2021-01-03-at-9.09.34-pm.png?w=840" src="https://whyjava.files.wordpress.com/2021/01/screenshot-2021-01-03-at-9.09.34-pm.png?w=1024" alt="" srcset="https://whyjava.files.wordpress.com/2021/01/screenshot-2021-01-03-at-9.09.34-pm.png?w=1024 1024w, https://whyjava.files.wordpress.com/2021/01/screenshot-2021-01-03-at-9.09.34-pm.png?w=150 150w, https://whyjava.files.wordpress.com/2021/01/screenshot-2021-01-03-at-9.09.34-pm.png?w=300 300w, https://whyjava.files.wordpress.com/2021/01/screenshot-2021-01-03-at-9.09.34-pm.png?w=768 768w, https://whyjava.files.wordpress.com/2021/01/screenshot-2021-01-03-at-9.09.34-pm.png 1248w" sizes="(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 1362px) 62vw, 840px"></a><figcaption>CTO Framework by Matt Tucker</figcaption></figure>



<p>I think the above framework gives a good mental model on how to think about the role of a CTO. Mostly, they come with a combination of two or more aforementioned flavors.&nbsp;</p>



<p>Let me share what my role, as a Chief Technology Officer, looks like. In my view, the framework (above) shared by Matt Tucker is from a product organization’s perspective. I am a CTO of an IT services organization, where this role gets diluted, fragmented and challenging because of the following additional factors:</p>



<ul><li>People are an important asset in any organization, but for an IT service organization, growth is directly proportional to the number of people. If you want to remain a niche service provider, then the story could be different.&nbsp;</li><li>You have to make modern technology accessible to large enterprises that are not ready for the change. In the last 5 years or so, there is a push towards digital transformation in most organizations. In my experience, organizations are now more open toward trying new technologies (React, Golang, Flutter, Cloud, Kubernetes) and architecture styles (Microservices, Event-driven, Serverless), more than ever before. This is a great news, but very few organizations understand the complexity introduced by these modern technology stacks. They are not doing the groundwork required to become the next Google in their domain. You can read my post <a href="https://medium.com/xebia-engineering/11-reasons-why-you-are-going-to-fail-with-microservices-29b93876268b"><em>11 Reasons Why You Are Going To Fail With Microservices</em></a>&nbsp;</li><li>There are not many good software engineers in the market with real experience in these modern technologies. Good software engineers are expensive and their financial and work aspirations are more aligned with product organizations. For an IT service organization, it is not possible to pay at the scale of product organizations.&nbsp;</li></ul>



<p>There is not much written about/by the CTOs of IT service organizations. It is not clear who should be your role model, so I will take Matt’s framework and define it for myself.</p>



<p>Here, you will see Matt’s framework modified by virtue of the flavors comprising my role. I have given a rough estimate on the time I had spent on each activity in the last year.&nbsp;</p>







<figure><a href="https://whyjava.files.wordpress.com/2021/01/screenshot-2021-01-03-at-9.09.48-pm.png"><img data-attachment-id="6466" data-permalink="https://shekhargulati.com/screenshot-2021-01-03-at-9-09-48-pm/" data-orig-file="https://whyjava.files.wordpress.com/2021/01/screenshot-2021-01-03-at-9.09.48-pm.png" data-orig-size="1240,1166" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screenshot-2021-01-03-at-9.09.48-pm" data-image-description="" data-medium-file="https://whyjava.files.wordpress.com/2021/01/screenshot-2021-01-03-at-9.09.48-pm.png?w=300" data-large-file="https://whyjava.files.wordpress.com/2021/01/screenshot-2021-01-03-at-9.09.48-pm.png?w=840" src="https://whyjava.files.wordpress.com/2021/01/screenshot-2021-01-03-at-9.09.48-pm.png?w=1024" alt="" srcset="https://whyjava.files.wordpress.com/2021/01/screenshot-2021-01-03-at-9.09.48-pm.png?w=1024 1024w, https://whyjava.files.wordpress.com/2021/01/screenshot-2021-01-03-at-9.09.48-pm.png?w=150 150w, https://whyjava.files.wordpress.com/2021/01/screenshot-2021-01-03-at-9.09.48-pm.png?w=300 300w, https://whyjava.files.wordpress.com/2021/01/screenshot-2021-01-03-at-9.09.48-pm.png?w=768 768w, https://whyjava.files.wordpress.com/2021/01/screenshot-2021-01-03-at-9.09.48-pm.png 1240w" sizes="(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 1362px) 62vw, 840px"></a><figcaption>Modified CTO Framework</figcaption></figure>



<p>As you can see in the above table, I am everywhere. Luckily for me, I had less overhead in context switching. The main reason was I made sure that I never get involved in more than 2 tasks at a time.&nbsp;</p>



<p>In my first year as the CTO, I have built some level of delegation hierarchy. Hopefully, in the second year, I will be more focussed on a few of these flavors.</p>



<h2>Lessons learned in the first year</h2>



<p>So far, I have shared about my journey and the CTO role definition. Next, let me walk you through the lessons that I have learned in the first year as CTO.</p>



<h3>Lesson #0: You have to believe in yourself and ask for the role</h3>



<p>Most software engineers dream of becoming a CTO one day. This is how some of us define a successful engineering career. Someone will not make you the CTO just because you are the most capable software engineer/architect in your organization. You really need to have the hunger.&nbsp;</p>



<p>It took me close to 2-3 years before I was sure in my mind that I am ready to become a CTO. One of the reasons I thought I was not ready for a leadership role was Peter Principle.&nbsp;</p>



<blockquote><p>The Peter Principle is an observation that the tendency in most organizational hierarchies, such as that of a corporation, is for every employee to rise in the hierarchy through promotion until they reach a level of respective incompetence.</p></blockquote>



<p>I always took pride in being a competent software engineer/architect. The fear of becoming incompetent one day made me stick to the hands-on individual contributor role.</p>



<p>One thing that I realized was if I am not going to do the role, someone else will. Since, I knew the organization long enough and I have figured out my engineering leadership style, so why not give it a try. The most difficult part for me was asking for the role. The sad part is if you don’t ask people, they don’t give you what you deserve.&nbsp;</p>



<blockquote><p>Now, I’ve actually always found something to be very true, which is that most people don’t get those experiences because they never ask. I’ve never found anybody who didn’t want to help me when I’ve asked them for help – Steve Jobs [1]</p></blockquote>



<h3>Lesson #1: Schedule time for yourself</h3>



<p>A couple of weeks back, a colleague asked me how you are able to do deep work when you have to attend so many meetings. I discovered that people will add you to a meeting as soon as they find a free meeting slot in your calendar. I struggled with this for the first half of 2020.&nbsp; I was in meetings most of the day. Most of the thinking work that I did during this period was either after office hours or on weekends.&nbsp;</p>



<p>I changed my way of working in the second half after realizing that I can also schedule time&nbsp; with myself. Now, everyday I schedule a couple of hours to half a day with myself and do one deep work task. This way I am able to manage between maker schedule and manager schedule [2].</p>



<p>Another way, I avoid becoming a slave to my calendar, is by ensuring with the organizer whether my presence in the meeting is critical. At other times, I decline meetings when someone from my team is already attending.&nbsp;</p>



<h3>Lesson #2: Getting things done without doing them</h3>



<p>This is the challenge that most individual contributors face when they take up managerial/leadership roles. You know you can do the task better and faster. Thereby, you prefer to do the task yourself. This does not scale and you quickly become the bottleneck. And I bet you already know the answer.&nbsp;</p>



<p>The best way to scale yourself is through delegation. There are two parts in the delegation: what to delegate and which delegation level to apply.</p>



<p><strong>What to delegate</strong></p>



<p>In <em>How to Decide Which Tasks to Delegate </em>[3], Jenny Blake categorizes tasks into 6 categories which she calls 6 Ts.</p>



<ul><li><strong>Tiny</strong>: Tasks that are so small they seem inconsequential to tackle but they add up.</li><li><strong>Tedious</strong>: Tasks that are relatively simple probably are not&nbsp; the best use of your time.</li><li><strong>Time-consuming</strong>: Tasks that, although they may be important and even somewhat complex, are time-consuming and do not require you to do the initial 80% of research.</li><li><strong>Teachable</strong>: Tasks that, although complicated-seeming at first and possibly comprising several smaller subtasks, can be translated into a system and passed along, with you still providing quality checks and final approval.</li><li><strong>Terrible At</strong>: Tasks that not only do not fall into your strengths, but an area where you feel unequipped.</li><li><strong>Time sensitive</strong>: Tasks that are time-sensitive but compete with other priorities; there isn’t enough time to do them all at once, so you delegate an important and time-sensitive task so that it can be done in parallel to your other project-based deadlines.</li></ul>



<p>Tasks like organizing internal tech talks, operating internal infra, code reviews, junior engineer hiring I have delegated to others in my team.&nbsp;</p>



<p>Once you know which tasks to delegate, you have to use a delegation level that gets the best job done. I learnt about 7 levels of delegation at Management 30 website [4].</p>



<ol><li><strong>Tell</strong>: I will tell them&nbsp;</li><li><strong>Sell</strong>: I will try and sell it to them&nbsp;</li><li><strong>Consult</strong>: I will consult and then decide&nbsp;</li><li><strong>Agree</strong>: We will agree together&nbsp;</li><li><strong>Advise</strong>: I will advise but they decide&nbsp;</li><li><strong>I…</strong></li></ol></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://shekhargulati.com/2021/01/03/being-chief-technology-officer-lessons-learned-in-my-first-year/">https://shekhargulati.com/2021/01/03/being-chief-technology-officer-lessons-learned-in-my-first-year/</a></em></p>]]>
            </description>
            <link>https://shekhargulati.com/2021/01/03/being-chief-technology-officer-lessons-learned-in-my-first-year/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25874094</guid>
            <pubDate>Fri, 22 Jan 2021 17:49:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Setting up Matrix Synapse on a delegated subdomain]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25874010">thread link</a>) | @pngmangi
<br/>
January 22, 2021 | https://ansonvandoren.com/posts/matrix-server-digital-ocean/ | <a href="https://web.archive.org/web/*/https://ansonvandoren.com/posts/matrix-server-digital-ocean/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
<h2 id="why-do-i-want-to-do-this">Why do I want to do this?</h2>
<p>That's a good question. I think the honest answer is because I had some spare time this week and I wanted to learn
something new. Part of me also says that after having left at least 5 different primary messaging platforms
over the last 20 years due to them either being killed off (looking at you, Google), or becoming irrelevant (ICQ anyone?),
or becoming too creepy (WhatsApp, WeChat), it might be worth investing in a chat platform that's under (mostly) my own
control.</p>
<p>I've seen bits and pieces about Matrix over the last couple of years, but never really investigated it much. I knew
that it was open source and self-hosted, but what I didn't know until yesterday is that it also has quite a few
<a href="https://matrix.org/bridges/">bridges</a> to connect to the chat apps I still do use. Most of my day-to-day chatting
right now is via Telegram, which has been working out pretty well for the last two years, but I'm not convinced
how much longer a Russian tech billionaire is going to want to keep self-funding the project, especially after
the TON ICO <a href="https://www.sec.gov/news/press-release/2019-212">was halted by the SEC</a>.</p>
<p>Anyway, if nothing else I'd learn a bit about the Matrix community, keep current on some sysadmin skills, and
build a little more feeling of ownership in the parts of the internet that I use on a daily basis. If I found
a lot of value in Matrix after it was up and running, maybe I'd try to get some of my normal contacts to add/switch,
or if not than I should be able to set up some bridging and still talk via my usual platforms, but with my own
copy of the chats on my private server, and the knowledge that I'd marginally improved my online privacy.</p>
<p>Before going too much further, I read the <a href="https://matrix.org/docs/guides/getting-involved">How can I get involved?</a>
page on the Matrix website, and spent a bit of time testing out the <a href="https://matrix.org/docs/projects/client/element">Element client</a>
in both the web and the desktop (Windows) app forms. Satisfied that it all seemed usable enough that I could
get used to it for a daily driver, I started investigating what it takes to self-host a
<a href="https://matrix.org/docs/guides/installing-synapse">Synapse server</a>.</p>
<h2 id="domain-name-setup-on-namecheap">Domain name setup on Namecheap</h2>
<p>First thing I need is a domain name to point at my new chat server. I already own several domain names (OK, domain collecting
is actually something of a bad habit of mine), but since the domain name of the server is reflected in one's Matrix
ID, I wanted to stick with <code>ansonvandoren.com</code>, to mirror both this website, and my email addresses. To complicate this just a bit,
I didn't want to use the same VPS that hosts my blog, and I also wanted Synapse to actually listen on a subdomain,
(e.g., <code>matrix.ansonvandoren.com</code>) instead of the domain name itself. Neither of these criteria makes the setup unmanageable,
but each adds a bit of complexity that I'll describe below.</p>
<p>My domain name is registered through <a href="https://namecheap.com/">NameCheap</a>, which has been an absolute pleasure to work
with over the last few years. Since the nameservers for <code>ansonvandoren.com</code> already point towards DigitalOcean, I don't
need to make any changes there.</p>
<p>If you're starting out from scratch and do need to point a Namecheap domain at a Digital Ocean droplet, you'll want the
“Custom DNS” setting, and the nameservers shown below:</p>
<p><img src="https://ansonvandoren.com/images/namecheap-nameservers.png" alt="Nameserver setup for Namecheap and DigitalOcean"></p>
<h2 id="droplet-creation-on-digital-ocean">Droplet creation on Digital Ocean</h2>
<p>I've been using Digital Ocean for hosting for years now and love their services. The price is right for the hobby
projects I usually take on, and the setup and maintenance is easy. If you're interested, here's a
<a href="https://m.do.co/c/4b40cdbde86d">referral link</a> you can use to sign up. <em>I'll get a small commission if you
sign up and keep using them, but it doesn't cost you anything</em>.</p>
<p>Based on the <a href="https://github.com/matrix-org/synapse/blob/master/INSTALL.md">Synapse installation guide</a>, the minimum
system requirements are 1GB of RAM. As you'll see later, it's fairly easy to limit the memory used even further if you
don't have many users on your homeserver. I chose an Ubuntu 20.04, Basic/Shared CPU $5/mo droplet with 1GB RAM, 1 (shared) CPU,
25GB storage, and 1000GB/mo bandwidth. Since I live in California, I chose a San Francisco datacenter. I selected IPv6 and Monitoring
options, and re-used my existing SSH keys from previous droplets. I chose a hostname of <code>matrix</code> and some relevant tags,
assigned it to my personal project, and enabled backups.</p>
<p>It takes a few moments to spin up. Before connecting the first time, I set up a subdomain record through DigitalOcean
(under the Networking menu) that points <code>matrix.ansonvandoren.com</code> to the newly created droplet. I did this for both an
A record and an AAA record (IPv4 and IPv6).</p>
<p><img src="https://ansonvandoren.com/images/digitalocean-dns.png" alt="DNS setup on Digital Ocean"></p>
<p>Since I chose to use a SSH key to login, I didn't need the Access Console at all, and
instead just connected from a terminal session using:</p>
<div><pre><code data-lang="sh">$ ssh root@matrix.ansonvandoren.com
</code></pre></div><p>It takes some time for the new DNS records to propagate, so if you get an error message like this, then try
using the IP address instead, or just wait an hour or so.</p>
<div><pre><code data-lang="sh">ssh: Could not resolve hostname matrix.ansonvandoren.com: No address associated with hostname
</code></pre></div><h2 id="initial-droplet-setup">Initial droplet setup</h2>
<p>Following the <a href="https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-20-04">Initial Server Setup with Ubuntu 20.04</a>
documentation from Digital Ocean, I created a new non-root user, generated a memorable and secure password using
<a href="https://correcthorsebatterystaple.net/">Correct Horse Battery Staple</a>, and saved the new credentials in <a href="https://1password.com/">1Password</a>.</p>
<p>I finished out the guide by:</p>
<ul>
<li>Copying the SSH authorized_keys over to the new user</li>
<li>Making the new user a superuser</li>
<li>Setting up <code>ufw</code> firewall rules (allowing <code>OpenSSH</code>, <code>http</code>, <code>https</code>)</li>
<li>Updating Linux packages</li>
</ul>
<h2 id="installing-synapse">Installing Synapse</h2>
<p>I followed <a href="https://github.com/matrix-org/synapse/blob/master/INSTALL.md">these instructions</a> from the Matrix
Github page, installing the prebuilt packages for Ubuntu:</p>
<div><pre><code data-lang="sh">$ sudo apt install -y lsb-release wget apt-transport-https
$ sudo wget -O /usr/share/keyrings/matrix-org-archive-keyring.gpg https://packages.matrix.org/debian/matrix-org-archive-keyring.gpg
$ <span>echo</span> <span>"</span><span>deb [signed-by=/usr/share/keyrings/matrix-org-archive-keyring.gpg] https://packages.matrix.org/debian/ </span><span>$(</span>lsb_release -cs<span>)</span><span> main</span><span>"</span> |
    sudo tee /etc/apt/sources.list.d/matrix-org.list
$ sudo apt update
$ sudo apt install matrix-synapse-py3
</code></pre></div><p>During the installation, when prompted for the Synapse server name, I used <code>ansonvandoren.com</code> even though the Synapse
server is actually pointed to by <code>matrix.ansonvandoren.com</code> since I intend to set up delegation later. Your
needs may be different, so you may want to read the <a href="https://github.com/matrix-org/synapse/blob/master/docs/delegate.md">delegation docs</a>
to help you decide. By choosing <code>ansonvandoren.com</code> as the server name and then delegating it, I can keep logical
servers with different names to improve organization and security, but still keep my Matrix ID as something
like <code>@anson:ansonvandoren.com</code> instead of <code>@anson:matrix.ansonvandoren.com</code>.</p>
<h2 id="installing-postgresql-for-synapse">Installing PostgreSQL for Synapse</h2>
<p>This isn't required, and probably not actually needed since I don't plan to host a lot of users, but it seemed
easier to do it now rather than try to do it down the road. There is a migration path from SQLite to PostgreSQL, but it looks
a little error-prone, and also, according to the official docs:</p>
<blockquote>
<p>Almost all installations should opt to use PostgreSQL</p>
</blockquote>
<p>Installation instructions are <a href="https://github.com/matrix-org/synapse/blob/master/docs/postgres.md">linked</a> from the main
Synapse install page, but those assume you already have Postgres installed, which I did not on the new droplet. There is
a pretty good <a href="https://www.digitalocean.com/community/tutorials/how-to-install-postgresql-on-ubuntu-20-04-quickstart">tutorial</a>
on Digital Ocean for setting up Postgres that I referenced to get started.</p>
<p>Install PostgreSQL:</p>
<div><pre><code data-lang="sh">$ sudo apt install postgresql postgresql-contrib
</code></pre></div><p>Switch to the newly created <code>postgres</code> user:</p>
<p>Create a <code>synapse_user</code> Postgres role:</p>
<div><pre><code data-lang="sh">$ createuser --pwprompt synapse_user
</code></pre></div><p>Enter a new password (and don't forget to store it in 1Password).</p>
<p>Create the Synapse database by first starting <code>psql</code></p>
<div><pre><code data-lang="sh">$ psql
psql (12.5 (Ubuntu 12.5-0ubuntu0.20.04.1))
Type <span>"help"</span> <span>for</span> help.
</code></pre></div><p>then from the Postgres prompt, create the database:</p>
<div><pre><code data-lang="postgres">postgres=# <span>CREATE</span> <span>DATABASE</span> synapse
             <span>ENCODING</span> <span></span><span>'</span><span>UTF8</span><span>'</span>
             <span>LC_COLLATE</span>=<span></span><span>'</span><span>C</span><span>'</span>
             <span>LC_CTYPE</span>=<span></span><span>'</span><span>C</span><span>'</span>
             <span>template</span>=template0
             <span>OWNER</span> synapse_user;
</code></pre></div><p>Exit the Postgres prompt by typing <code>\q</code>, and then exit back into the normal user login.</p>
<p>To set Synapse to use Postgres instead of the default SQLite, edit the config file:</p>
<div><pre><code data-lang="sh">$ sudo vim /etc/matrix-synapse/homeserver.yaml
</code></pre></div><p>Search for the <code>database</code> section, and comment out the <code>sqlite3</code> section, and uncomment the <code>psycopg2</code> part.
Mine looks like this:</p>
<div><pre><code data-lang="yaml">database:
  name: psycopg2
  args:
    user: synapse_user
    password: secretpassword
    database: synapse
    host: localhost
    cp_min: <span>5</span>
    cp_max: <span>10</span>
</code></pre></div><p>Obviously, change <code>secretpassword</code> to whatever your <code>synapse_user</code> password is (created a few steps above).</p>
<h2 id="configuring-reverse-proxy-for-synapse">Configuring reverse proxy for Synapse</h2>
<p>Again, the Matrix team has a reasonable set of instructions <a href="https://github.com/matrix-org/synapse/blob/master/docs/reverse_proxy.md">here</a>.
I chose to use Caddy for a reverse proxy, mostly because I already use Nginx for other projects, and wanted some different
experience. I followed the basic Caddy 2 installation instructions <a href="https://caddyserver.com/docs/install#debian-ubuntu-raspbian">from here</a>.</p>
<div><pre><code data-lang="sh">$ sudo apt install -y debian-keyring debian-archive-keyring apt-transport-https
$ curl -1sLf <span>'https://dl.cloudsmith.io/public/caddy/stable/cfg/gpg/gpg.155B6D79CA56EA34.key'</span> | sudo apt-key add -
$ curl -1sLf <span>'https://dl.cloudsmith.io/public/caddy/stable/cfg/setup/config.deb.txt?distro=debian&amp;version=any-version'</span> | sudo tee -a /etc/apt/sources.list.d/caddy-stable.list
$ sudo apt update
$ sudo apt install caddy
</code></pre></div><p>There is a default Caddyfile in <code>/etc/caddy/Caddyfile</code> that I edited to look like below:</p>
<pre><code data-lang="caddy">matrix.ansonvandoren.com {
  # enable logging
  log

  reverse_proxy /_matrix/* http://localhost:8008
  reverse_proxy /_synapse/client/* http://localhost:8008
}
</code></pre><p><strong>From that folder</strong>, reload caddy with</p>
<p>Then wait for LetsEncrypt to generate the certs. Make sure that <code>http</code> and <code>https</code> are enabled via <code>ufw</code>.</p>
<h2 id="delegating-access-to-a-subdomain">Delegating access to a subdomain</h2>
<p>Since the Synapse server is hosted on a different box and a subdomain (not just <code>ansonvandoren.com</code>),
I needed to delegate access. The easiest way seems to be with a <code>.well-known</code> directive, so I followed the
basic instructions <a href="https://github.com/matrix-org/synapse/blob/master/docs/delegate.md">here</a>. Sort of.</p>
<p>Actually I needed quite a bit from <a href="https://git.finallycoffee.eu/jdreichmann/matrix-docker-ansible-deploy_dev/src/commit/c1a9549d54538cf35076f2a6a19e13004a483a06/docs/configuring-well-known.md">this document</a> as well.</p>
<p>On my regular <code>ansonvandoren.com</code> host, in the same Nginx server block that holds information
for this website, I added the following:</p>
<div><pre><code data-lang="nginx"><span>server</span> {
    <span>server_name</span> <span>ansonvandoren.com</span>;

    <span># ... other config ... #
</span><span></span>
<span>    <span># matrix delegation
</span></span><span><span></span>    <span>location</span> <span>/.well-known/ma…</span></span></code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ansonvandoren.com/posts/matrix-server-digital-ocean/">https://ansonvandoren.com/posts/matrix-server-digital-ocean/</a></em></p>]]>
            </description>
            <link>https://ansonvandoren.com/posts/matrix-server-digital-ocean/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25874010</guid>
            <pubDate>Fri, 22 Jan 2021 17:42:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Twitter Bluesky Is a Business Strategy]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25873965">thread link</a>) | @WClayFerguson
<br/>
January 22, 2021 | https://quanta.wiki/u/WClayFerguson/twitter-bluesky | <a href="https://web.archive.org/web/*/https://quanta.wiki/u/WClayFerguson/twitter-bluesky">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://quanta.wiki/u/WClayFerguson/twitter-bluesky</link>
            <guid isPermaLink="false">hacker-news-small-sites-25873965</guid>
            <pubDate>Fri, 22 Jan 2021 17:39:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Marketing can make the world a better place]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25873957">thread link</a>) | @jnoog
<br/>
January 22, 2021 | https://boundlesshumanblog.com/marketing-makes-the-world-a-better-place-cory-ames-grow-ensemble/ | <a href="https://web.archive.org/web/*/https://boundlesshumanblog.com/marketing-makes-the-world-a-better-place-cory-ames-grow-ensemble/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-24">
	<!-- .entry-header -->

	<div>
		
<figure><img loading="lazy" width="640" height="853" src="https://i2.wp.com/boundlesshumanblog.com/wp-content/uploads/2020/10/Cory-Ames-CEO-of-Grow-Ensemble-768x1024.jpeg?resize=640%2C853&amp;ssl=1" alt="Cory Ames CEO of Grow Ensemble wearing yellow beanie and jacket" srcset="https://i1.wp.com/boundlesshumanblog.com/wp-content/uploads/2020/10/Cory-Ames-CEO-of-Grow-Ensemble.jpeg?resize=768%2C1024&amp;ssl=1 768w, https://i1.wp.com/boundlesshumanblog.com/wp-content/uploads/2020/10/Cory-Ames-CEO-of-Grow-Ensemble.jpeg?resize=225%2C300&amp;ssl=1 225w, https://i1.wp.com/boundlesshumanblog.com/wp-content/uploads/2020/10/Cory-Ames-CEO-of-Grow-Ensemble.jpeg?resize=1152%2C1536&amp;ssl=1 1152w, https://i1.wp.com/boundlesshumanblog.com/wp-content/uploads/2020/10/Cory-Ames-CEO-of-Grow-Ensemble.jpeg?resize=1536%2C2048&amp;ssl=1 1536w, https://i1.wp.com/boundlesshumanblog.com/wp-content/uploads/2020/10/Cory-Ames-CEO-of-Grow-Ensemble.jpeg?w=1920&amp;ssl=1 1920w, https://i1.wp.com/boundlesshumanblog.com/wp-content/uploads/2020/10/Cory-Ames-CEO-of-Grow-Ensemble.jpeg?w=1280&amp;ssl=1 1280w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1"></figure>



<p id="block-feb40dbc-4d12-4f90-8338-808d52cca5e4">Fun fact: Cory dropped out of university and began working at a multi-million-dollar marketing agency. He quickly climbed up the ranks from Assistant Project Manager to CEO within 18 months.</p>



<p id="block-feb40dbc-4d12-4f90-8338-808d52cca5e4">Though I would never suggest anyone to take ditching school lightly, sometimes it can work out for the best.</p>



<p id="block-027cc4d0-39a6-4811-bd23-a17f9f80fc84">Cory first reached out to me to update some content for his podcast and I jumped on board immediately because I loved its mission. I’ve been following Grow Ensemble, his marketing agency and consultancy for purpose-driven companies, ever since.</p>



<p id="block-5cc1b2af-3eaa-4447-a2c5-12a330b7f149">He and his team have helped hundreds of social enterprises, lead by similarly passionate entrepreneurs, grow. Indeed, profit and purpose can exist in perfect harmony.</p>



<p id="block-54e98d7e-fa85-4e32-b039-774c6f11faa2">So whatever they tell you about sleazy marketers trying to sell you snake oil, it’s not always true.</p>



<p id="block-662133ef-7438-427f-af40-6b036ea3e6e8">His background makes him the perfect first guest on Boundless Human so I didn’t hesitate to ask him for an interview. But enough from me, I’ll give Cory the stage now.</p>



<blockquote><p><em>In our most ambitious frame of mind, we want Grow Ensemble to inspire a cultural transformation—one where we begin to think more communally, rather than hyper-individually.&nbsp;&nbsp;</em></p><p>Cory Ames</p></blockquote>



<h2><strong>1. Where does the desire to do good come from? What inspires you in this regard?</strong></h2>



<p>First, I know I am insanely privileged. There has been little in my life that I’ve wanted to do that I haven’t been able to. And really, that’s all a product of luck. I was lucky enough to be born into a middle-class/upper-middle-class family, have extremely supportive parents, and be a skin color (white) that’s preferential to receiving “opportunities” in America.&nbsp;</p>



<p>I didn’t do anything to <em>deserve </em>this; I didn’t earn this in any way, it was all by chance. And so, I feel obligated to use my privilege to ideally make the world a (truly) better place for those who aren’t as lucky.&nbsp;</p>



<p>Second, I’m really not sure what could be a better or more meaningful use of my own skills and capacities than to work towards reducing the unnecessary suffering of others and leaving the world a more just, equitable, and habitable place for all of us, not just some of us. If we have skills, if we have resources, and if we have time, it should be spent thinking about and working towards making others better off, no?&nbsp;</p>



<h2><strong>2. You dropped out of university to pursue digital marketing and went on to become the CEO of a multi-million dollar marketing agency in just 18 months. You clearly like to “colour outside the lines”. Do you embody this ethos in other aspects of your life?</strong></h2>



<p>Definitely. And honestly, I feel that the quality of mine might cause me some distress. I can often be so committed to doing things the exact way I want to, at the time I want to, where I want to. I can shy away from or procrastinate on maybe more mundane, repetitive, but still <em>very important </em>things. Sometimes the things that I <em>have </em>to do, but don’t <em>want </em>to fall to the wayside.&nbsp;</p>



<h2><strong>3. Imagine an ideal future and the ultimate impact you want to make with Grow Ensemble. What would that look like?</strong></h2>



<p>We started Grow Ensemble because we wanted to create a community around ‘bettering the world.’ Research shows that we are more lonely and depressed than we ever have been. We hope that Grow Ensemble can be a vehicle for inspiring others to do good in their day-to-day lives with a like-minded, like-valued community.&nbsp;</p>



<p>In our most ambitious frame of mind, we want Grow Ensemble to inspire a cultural transformation—one where we begin to think more communally, rather than hyper-individually.&nbsp;&nbsp;</p>



<h2><strong>4. What’s your favourite book / podcast / song / etc. (choose one) and why?</strong></h2>



<p>Player Piano, by Kurt Vonnegut—I’m eternally grateful to my partner, Annie, for this recommendation.&nbsp;</p>



<p>To quote Vonnegut himself, “This book is not a book about what is, but a book about what could be.” He published Player Piano in 1952. Vonnegut’s predictions about “what could be,” were eerie.&nbsp;&nbsp;</p>



<p>The book is set in a completely ‘automated’ American society. Through automation and technology, every single one of our conveniences has been met. This book had me questioning our obsession with “progress” and technological innovation.&nbsp;</p>



<p>Is progress for progress’ sake really what’s best for us both individually and collectively? What are we ‘optimizing’ for?&nbsp;</p>



<p>As we watch automation wipe out hundreds of thousands of livelihoods and we create another widget to make it easier to do something insignificant like brushing our teeth, or finding a new T.V. show, I can’t help but wonder, is all the “advancement” in fact improving our lives?&nbsp;</p>



<h2><strong>5. ‎What’s the bravest thing you’ve ever done?</strong></h2>



<p>This is interesting. I don’t consider myself to be particularly courageous and boiling that down to one single moment doesn’t really seem to fit with how I think of myself. I’m very reflective and analytical. I think through potential life choices and actions I can take rather exhaustively.&nbsp;</p>



<p>And then, when the event comes, it feels almost “normal,” or exactly what I should be doing.&nbsp;</p>



<p>Leaving university early didn’t feel all particularly courageous at the time, because I felt extremely certain of what I wanted to do. If anything, the bravest things I’ve done revolve around moving or travel.&nbsp;</p>



<p>Of anything, I’d say those experiences have taken me the most out of my comfort zone and maybe have rewarded me the most.&nbsp;</p>



<p>While I’ve spent some significant time traveling/living within different countries, most meaningful may have been my move from Washington state to Texas. This felt like a ‘starting fresh’ of sorts, making new friends, finding new routines, and spending significant time away from my family.&nbsp;</p>



<p>And now, I’m so endlessly grateful I made the move as the universe certainly “rewarded me” with meeting my now partner who I plan to spend the rest of my life with.&nbsp;</p>



<p><em>If you want to learn more about Cory and his mission, check out his <a href="https://coryames.com/">personal website</a>, <a href="https://growensemble.com/">Grow Ensemble</a> and <a href="https://growensemble.com/podcast/">the Social Entrepreneurship and Innovation Podcast</a>.</em></p>












	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://boundlesshumanblog.com/marketing-makes-the-world-a-better-place-cory-ames-grow-ensemble/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25873957</guid>
            <pubDate>Fri, 22 Jan 2021 17:39:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A curriculum developed around the television series, Halt and Catch Fire]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25873949">thread link</a>) | @_pius
<br/>
January 22, 2021 | https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/ | <a href="https://web.archive.org/web/*/https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="about">
      

<p>This site features a curriculum developed around the television series, <a href="https://www.google.com/search?channel=fs&amp;client=ubuntu&amp;q=halt+and+catch+fire">Halt and Catch Fire</a> (2014-2017), a fictional narrative about people working in tech during the 1980s-1990s.</p>

<p>The intent is for this website to be used by self-forming small groups that want to create a “watching club” (like a book club) and discuss aspects of technology history that are featured in this series.</p>

<p>There are 15 classes, for a “semester-long” course:<br>
~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/01.html">#01</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/02.html">#02</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/03.html">#03</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/04.html">#04</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/05.html">#05</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/06.html">#06</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/07.html">#07</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/08.html">#08</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/09.html">#09</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/10.html">#10</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/11.html">#11</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/12.html">#12</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/13.html">#13</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/14.html">#14</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/15.html">#15</a> ~</p>

<p><strong>Prefer a <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/HaltAndCatchFireSyllabus.pdf">PDF</a>?</strong></p>

<p>Brief guide to class layout:</p>
<ul>
  <li><strong>Apéritifs</strong> Casual viewing presented before gathering. This is entertainment; not required viewing.</li>
  <li><strong>RFC as koan</strong> A Request for Comments from the Internet Engineering Task Force, for reflecting on.</li>
  <li><strong>Emulation as koan</strong> An emulated computer in the browser, also for reflection.</li>
  <li><strong>Themes</strong> Recommendations for topics to be discussed.</li>
  <li><strong>Prompts</strong> Questions to inspire conversation when gathering.</li>
  <li><strong>Readings</strong> Related material for deeper thinking on the class topic.</li>
  <li><strong>Description</strong> Brief summary of what’s going on in the episodes and how it relates to tech history at large / the weekly topic.</li>
  <li><strong>Episode summaries</strong> A link to summaries of the episodes that should be watched prior to meeting as a group. Watching each episode is not required; if time doesn’t allow, refer to the summaries. Content warnings are provided for relevant episodes. If there are specific concerns, this can determine which episodes should be skipped or anticipated before viewing.</li>
</ul>

<p><br>
Curriculum and website designed by <a href="https://ashleyblewer.com/">Ashley Blewer</a>.<br>
see also ↠ <a href="https://github.com/ablwr/halt-and-catch-fire-syllabus">source code &amp; site metadata</a></p>

<p><img src="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/assets/img/construction.gif" alt="under construction"></p>

    	</div></div>]]>
            </description>
            <link>https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25873949</guid>
            <pubDate>Fri, 22 Jan 2021 17:38:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Proof of Reserves and Why It Matters]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25873947">thread link</a>) | @Bluestein
<br/>
January 22, 2021 | https://www.quadrigainitiative.com/proofofreserves.php | <a href="https://web.archive.org/web/*/https://www.quadrigainitiative.com/proofofreserves.php">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<p>In case you missed them, so far this year we've seen 3 large scale exchange events:</p>
<ul>
<li>QuadrigaCX</li>
<li>EZ-BTC</li>
<li>Cryptopia</li></ul>

<p>Each one represents massive losses for those involved - hundreds and thousands of affected lives. These are real people and families at the other ends, with hopes and dreams, who worked hard for their money.</p>

<p>In the case of QuadrigaCX, it took the freezing of the bank accounts, the death/disappearance of the CEO, and concerted legal action to even realize it was insolvent.</p>

<p>Exchanges can easily continue to operate for years with whatever level of reserves they like. Nothing prevents exchange owners from spending cryptocurrency stored by users, or failing to disclose if reserves are breached. Third party audits are riddled with holes like:</p>
<ul>

<li>How can they know the client list they're given is legitimate and fully inclusive?</li>

<li>How can you know the funds weren't borrowed for the audit purposes?</li>

<li>How old is the report? How can you trust the auditor?</li></ul>

<p>On top of that - most exchange platforms still don't even bother to audit. Despite the warnings about storing funds on exchanges, people still do. And remember that many affected users weren't storing funds on Quadriga - they simply got stuck with no way to withdraw.</p>

<p>Proof of Reserves asks exchanges to:</p>
<ul>

<li>Publish the wallet public keys so people can see that funds are fully backed. (A satoshi test can prove ownership of those wallets.)</li>

<li>Publish a hash tree to let each customer validate that their balance is included in the total.</li></ul>

<p>What it doesn't prevent:</p>

<ul>

<li>Same as presently, if funds are not secured in proper multi-sig wallets or multiple exchange operators are corrupt, the funds could still be taken, up to what's stored. However, this would be immediately known to everyone instead of revealed whenever admins felt like it (or never).</li>

<li>The balances of customers who never check the hash tree could be excluded by a dishonest exchange, which wouldn't be noticed until one of those customers decided to check.</li>

<li>A dishonest exchange could still dispute the balance of a customer or arbitrarily prevent withdrawals. In this case, the customer and exchange would have to sort that out.</li>

<li>A dishonest exchange could pretend to own wallets it doesn't. A satoshi test would help with this, where the exchange operators send a small amount at a specified time.</li>

<li>While it makes things safer, it's still not a good idea to store funds on the exchange.</li></ul>

<p>What it does prevent:</p>

<ul>

<li>The exchange owner can't spend funds of active customers, and still claim to hold them.<ul>

<li>ie QuadrigaCX, EZ-BTC</li></ul></li>

<li>The exchange owner can't conceal if funds are hacked or stolen. It becomes known immediately.<ul>

<li>ie Mt. Gox, Cryptopia, Bitgrail</li></ul></li>

<li>Anyone can see if the exchange is solvent before trading.<ul>

<li>ie Anyone with "bad timing" using an insolvent exchange.</li></ul></li></ul>

<p><a href="https://web.archive.org/web/20170114112433/https://iwilcox.me.uk/2014/proving-bitcoin-reserves">Check this link for more details on Proof of Reserves, including the full hash tree algorithm.</a></p>

<p>Despite the relative simplicity of publishing wallet keys, the vast selection of exchanges we have in Canada, and the many millions of dollars stored, not a single exchange has done so. The hash tree algorithm has existed since 2014. It's presently on one exchange (last audited in 2014).</p>

<p><a href="https://www.quadrigainitiative.com/txquick.php">This is why we are so pleased to work with an exchange partner committed to transparency, who will be implementing a full proof of reserves.</a></p>

<p>It's time to do something about this!</p>

<!--<form action="emailonly.php" method="post">
<input type="hidden" name="r" value="">
<table width="100%">
<tbody><tr><td colspan="3"><h3>Join the Fight for Proof of Reserves</h3></td></tr>
<tr><td>First&nbsp;Name:</td><td><input type="text" name="first" value=""></td><td>Enter your first name. (Used in email contact.)</td></tr>
<tr><td>Email:</td><td><input type="text" name="email" value=""></td><td>Enter an email address which will work to receive a launch announcement in a few months.</td></tr>
<tr><td colspan="3" style="text-align:center"><input type="checkbox" value="1" name="confirm" id="confirm"><label for="confirm"> I accept the <a href="terms.php">Terms of Use</a> and <a href="privacy.php">Privacy Policy</a>.</label></td></tr>
<tr><td colspan="3"><input type="submit" value="Email-Only Signup" style="width:100%;font-size: 1.17em;"></td></tr></tbody></table>
</form>-->

</div><p>Your use of this site/service accepts the <a href="https://www.quadrigainitiative.com/terms.php">Terms of Use</a> and <a href="https://www.quadrigainitiative.com/privacy.php">Privacy Policy</a>. This site is not associated with Ernst &amp; Young, Miller Thompson, or the Official Committee of Affected User. For questions or enquiries, email <a href="mailto:info@quadrigainitiative.com">info@quadrigainitiative.com</a>.</p></div>]]>
            </description>
            <link>https://www.quadrigainitiative.com/proofofreserves.php</link>
            <guid isPermaLink="false">hacker-news-small-sites-25873947</guid>
            <pubDate>Fri, 22 Jan 2021 17:38:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dissecting the Apple M1 GPU, Part II]]>
            </title>
            <description>
<![CDATA[
Score 517 | Comments 173 (<a href="https://news.ycombinator.com/item?id=25873887">thread link</a>) | @dddddaviddddd
<br/>
January 22, 2021 | https://rosenzweig.io/blog/asahi-gpu-part-2.html | <a href="https://web.archive.org/web/*/https://rosenzweig.io/blog/asahi-gpu-part-2.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<header><p>22 Jan 2021</p></header><p>Less than a month ago, I began <a href="https://rosenzweig.io/blog/asahi-gpu-part-1.html">investigating the Apple M1 GPU</a> in hopes of developing a free and open-source driver. This week, I’ve reached a second milestone: drawing a triangle with my own open-source code. The vertex and fragment shaders are handwritten in machine code, and I interface with the hardware via the IOKit kernel driver in an identical fashion to the system’s Metal userspace driver.</p>
<figure>
<img src="https://rosenzweig.io/M1HelloTriangle.png" alt=""><figcaption>A triangle rendered on the M1 with open-source code</figcaption>
</figure>
<p>The bulk of the new code is responsible for constructing the various command buffers and descriptors resident in shared memory, used to control the GPU’s behaviour. Any state accessible from Metal corresponds to bits in these buffers, so understanding them will be the next major task. So far, I have focused less on the content and more on the connections between them. In particular, the structures contain pointers to one another, sometimes nested multiple layers deep. The bring-up process for the project’s triangle provides a bird’s eye view of how all these disparate pieces in memory fit together.</p>
<p>As an example, the application-provided vertex data are in their own buffers. An internal table in yet another buffer points each of these vertex buffers. That internal table is passed directly as input to the vertex shader, specified in another buffer. That description of the vertex shader, including the address of the code in executable memory, is pointed to by another buffer, itself referenced from the main command buffer, which is referenced by a handle in the IOKit call to submit a command buffer. Whew!</p>
<p>In other words, the demo code is not yet intended to demonstrate an understanding of the fine-grained details of the command buffers, but rather to demonstrate there is “nothing missing”. Since GPU virtual addresses change from run to run, the demo validates that all of the pointers required are identified and can be relocated freely in memory using our own (trivial) allocator. As there is a bit of “magic” around memory and command buffer allocation on macOS, having this code working at an early stage gives peace of mind going forward.</p>
<p>I employed a piecemeal bring-up process. Since my IOKit wrapper exists in the same address space as the Metal application, the wrapper may modify command buffers just before submission to the GPU. As an early “hello world”, I identified the encoding of the render target’s clear colour in memory, and demonstrated that I could modify the colour as I pleased. Similarly, while learning about the instruction set to bring up the disassembler, I replaced shaders with handwritten equivalents and confirmed I could execute code on the GPU, provided I wrote out the machine code. But it’s not necessary to stop at these “leaf nodes” of the system; after modifying the shader code, I tried uploading shader code to a different part of the executable buffer while modifying the command buffer’s pointer to the code to compensate. After that, I could try uploading the commands for the shader myself. Iterating in this fashion, I could build up every structure needed while testing each in isolation.</p>
<p>Despite curveballs, this procedure worked out far better than the alternative of jumping straight to constructing buffers, perhaps via a “replay”. I had used that alternate technique to bring-up Mali a few years back, but it comes with the substantial drawback of fiendishly difficult debugging. If there is a single typo in five hundred lines of magic numbers, there would be no feedback, except an error from the GPU. However, by working one bit at a time, errors could be pinpointed and fixed immediately, providing a faster turn around time and a more pleasant bring-up experience.</p>
<p>But curveballs there were! My momentary elation at modifying the clear colours disappeared when I attempted to allocate a buffer for the colours. Despite encoding the same bits as before, the GPU would fail to clear correctly. Wondering if there was something wrong with the way I modified the pointer, I tried placing the colour in an unused part of memory that was already created by the Metal driver – that worked. The contents were the same, the way I modified the pointers was the same, but somehow the GPU didn’t like my memory allocation. I wondered if there was something wrong with the way I allocated memory, but the arguments I used to invoke the memory allocation IOKit call were bit-identical to those used by Metal, as confirmed by <code>wrap</code>. My last-ditch effort was checking if GPU memory had to be mapped explicitly via some side channel, like the <code>mmap</code> system call. IOKit does feature a device-independent memory map call, but no amount of fortified tracing found any evidence of side-channel system call mappings.</p>
<p>Trouble was brewing. Feeling delirious after so much time chasing an “impossible” bug, I wondered if there wasn’t something “magic” in the system call… but rather in the GPU memory itself. It was a silly theory since it produces a serious chicken-and-egg problem if true: if a GPU allocation has to be blessed by another GPU allocation, who blesses the first allocation?</p>
<p>But feeling silly and perhaps desperate, I pressed forward to test the theory by inserting a memory allocation call <em>in the middle</em> of the application flow, such that every subsequent allocation would be at a different address. Dumping GPU memory before and after this change and checking for differences revealed my first horror: an auxiliary buffer in GPU memory tracked all of the required allocations. In particular, I noticed values in this buffer increasing by one at a predictable offset (every <code>0x40</code> bytes), suggesting that the buffer contained an array of handles to allocations. Indeed, these values corresponded exactly to handles returned from the kernel on GPU memory allocation calls.</p>
<p>Putting aside the obvious problems with this theory, I tested it anyway, modifying this table to include an extra entry at the end with the handle of my new allocation, and modifying the header data structure to bump the number of entries by one. Still no dice. Discouraging as it was, that did not sink the theory entirely. In fact, I noticed something peculiar about the entries: contrary to what I thought, not <em>all</em> of them corresponded to valid handles. No, all but the <em>last</em> entry were valid. The handles from the kernel are 1-indexed, yet in each memory dump, the final handle was always <code>0</code>, nonexistent. Perhaps this acts as a sentinel value, analogous to NULL-terminated strings in C. That explanation begs the question of why? If the header already contains a count of entries, a sentinel value is redundant.</p>
<p>I pressed on. Instead of adding on an extra entry with my handle, I copied the last entry <code>n</code> to the extra entry <code>n + 1</code> and overwrote the (now second to last) entry <code>n</code> with the new handle.</p>
<p>Suddenly my clear colour showed up.</p>
<p>Is the mystery solved? I got the code working, so in some sense, the answer must be yes. But this is hardly a satisfying explanation; at every step, the unlikely solution only raises more questions. The chicken-and-egg problem is the easiest to resolve: this mapping table, along with the root command buffer, is allocated via a special IOKit selector independent from the general buffer allocation, and the handle to the mapping table is passed along with the submit command buffer selector. Further, the idea of passing required handles with command buffer submission is not unheard of; a similar mechanism is used on mainline Linux drivers. Nevertheless, the rationale for using 64-byte table entries in shared memory, as opposed to a simple CPU-side array, remains totally elusive.</p>
<p>Putting memory allocation woes behind me, the road ahead was not without bumps (and potholes), but with patience, I iterated until I had constructed the entirety of GPU memory myself in parallel to Metal, relying on the proprietary userspace only to initialize the device. Finally, all that remained was a leap of faith to kick off the IOKit handshake myself, and I had my first triangle.</p>
<p>These changes amount to around 1700 lines of code since the last blog post, available on <a href="https://github.com/AsahiLinux/gpu">GitHub</a>. I’ve pieced together a simple demo animating a triangle with the GPU on-screen. The window system integration is effectively nonexistent at this point: XQuartz is required and detiling the (64x64 Morton-order interleaved) framebuffer occurs in software with naive scalar code. Nevertheless, the M1’s CPU is more than fast enough to cope.</p>
<p>Now that each part of the userspace driver is bootstrapped, going forward we can iterate on the instruction set and the command buffers in isolation. We can tease apart the little details and bit-by-bit transform the code from hundreds of inexplicable magic constants to a real driver. Onwards!</p>
<p><a href="https://rosenzweig.io/">Back to home</a></p>
</div>]]>
            </description>
            <link>https://rosenzweig.io/blog/asahi-gpu-part-2.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25873887</guid>
            <pubDate>Fri, 22 Jan 2021 17:34:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thoughts on Making Small Games]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25873837">thread link</a>) | @adnzzzzZ
<br/>
January 22, 2021 | https://a327ex.github.io/blog/small-games | <a href="https://web.archive.org/web/*/https://a327ex.github.io/blog/small-games">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><small><i>published on: 2021-01-22</i></small><br><small><i>last updated on: 2021-01-22</i></small></p></div></div><!--
title: Thoughts on making small games
date: 2021-01-22
update: 2021-01-22
-->

<p>I notice more people talking about making small games. As I'm currently also focused on this goal I thought it would be good to write something about it.</p>
<p>I personally think that indiedevs currently focused on this have a few misconceptions about the problem and aren't thinking about it clearly enough, and in this post I'll go over that argument.</p>
<h2 id="the-meaning-of-small">The meaning of small</h2>
<p>The first thing to notice is that the word <em>small</em>, when used in the context of making games, is conflating multiple meanings into one word. The first meaning is related to how long or how many people it took to make the game. The second meaning is related to how long it takes players to go through the game.</p>
<p>When indie developers use this word to describe their games, they're generally referring to both meanings at the same time, or to one of them in an interchangeable way with the other.</p>
<p>For instance, <a href="https://www.youtube.com/watch?v=wb22xeh_VqM" target="_blank">this great talk</a> (watch it in its entirety, I highly recommend it) goes over techniques for making games every month. However, it implicitly assumes that because this development duration is small, the games also will be fairly small for the players. This is illustrated in the first point where one month games are referred to as concept games rather than real games.</p>
<p><iframe width="100%" height="100%" src="https://www.youtube.com/embed/wb22xeh_VqM?rel=0&amp;modestbranding=1&amp;feature=oembed" allowfullscreen="" scrolling="no" allow="encrypted-media; accelerometer; clipboard-write; gyroscope; picture-in-picture"></iframe></p>
<p>Another example of a similar assumption being made is in <a href="https://howtomarketagame.com/2021/01/18/can-you-make-a-living-from-small-games-on-steam/" target="_blank">this article</a>, which goes over a game made in 4 months. Similarly, it is implicitly assumed that because the game was made in a short timeframe, the game would also necessarily be fairly small from the perspective of the players - as far as I can tell it can be finished in about 1 or 2 hours - and there's not a single point made by the author in relation to that.</p>
<p>In both of these cases you see the same error being implicitly made, which is that both meanings of the word small are the same thing, and this logically leads to the idea that if you make a game in a short timespan it must be the case that the game will not last a very long amount of time to the player. These are just two examples, and they're simply illustrative because this error is made by pretty much every indiedev talking about making small games.</p>
<h2 id="the-game-scope-chart">The game scope chart</h2>
<p>To further illustrate the point, you could look at this problem as a chart with four quadrants. On the horizontal axis we'll have one meaning of the word, on the vertical axis we'll have another. For clarity's sake, we'll refer to the meaning that pertains to development as small/big and to the other as short/long.</p>
<p><img src="https://i.imgur.com/mG5qz09.png"></p>
<p>We generally don't care about the top two quadrants of the chart. Those are related to games that have big development times or teams, and that's not what people are referring to when they talk about small games. We're then left with the bottom two quadrants, and here we have a spectrum that goes from small short games to small long games.</p>
<p>Most indie devs inherently assume that because a game is small, it has to be short. I reject this notion entirely. I think the quadrant of small long games is fairly unexplored, at least in the context of small games discussions, and it's useful to think about if this is a valid quadrant at all.</p>
<h2 id="my-experience-with-bytepath">My experience with BYTEPATH</h2>
<p>The only game I've released so far is <a href="https://store.steampowered.com/app/760330/BYTEPATH/" target="_blank">BYTEPATH</a>, and it falls under what I would consider a small long game.</p>
<p>It's small because it was made in about 4 months by me alone, and it also has a fairly small scope. By the nature of its gameplay it's essentially a single screen game with lots of upgrades, like one of those old flash games.</p>
<p>And it's long because it feels like a long game. Despite the game being small and made in just 4 months, it has a skill tree with about 900 nodes, it has 10 different characters, I don't even remember how many different classes but probably around 40, essentially, it's what I also like to call a <em>spacious</em> game.</p>
<p>You ever listen to a song or an album for hundreds of hours? I'm currently doing this for <a href="https://eirthankyouscientist.bandcamp.com/album/terraformer" target="_blank">Thank You Scientist's Terraformer</a> and it's crazy how despite listening to it for so long I still find new things in each song that I didn't notice before. This album is a spacious album. It can be thought of as this large space, and as you listen to it, you're exploring it, mapping the environment, finding new walls, rooms, objects, that you didn't know were there before.</p>
<p>Games can also be like this, and long games are generally like this. BYTEPATH certainly is because it was made to be so, as the goal of the game is finding new builds to play, to the point where the main gameplay itself is kind of irrelevant.</p>
<p>And because of this I think BYTEPATH did way better than I expected it to do. It's also important to note that despite me calling spacious games long games, they don't necessarily have to be played by most people for a very long time. Here's what BYTEPATH's hour distribution looks like:</p>
<p><img src="https://i.imgur.com/Fqmq6hW.png"></p>
<p>This is definitely not impressive but it's also not too bad. And I know for a fact there's at least one guy (I saw him in the game's reviews) who played it for over 100 hours. When games feel spacious they have the possibility of keeping people playing for a fairly long time, which increases the chances that the game will do well.</p>
<h2 id="small-long-games">Small long games</h2>
<p>The most important point here is that small long/spacious games <em>DO NOT</em> need to take a long time to be made. If I were to make a game like BYTEPATH again I'm fairly confident I could do it in 2 months, and it would be a significantly better game too, simply because it's actually not that hard. (I'm 100% not some kind of disciplined productivity God or anything)</p>
<p>When developers focus on making small games, this implicit notion that the games also have to be short is pretty wrong. You can make small long games, and because of the way the market works, those kinds of games will tend to do better than short games. I'm not the first person to notice this:</p>
<p><iframe width="100%" height="100%" src="https://www.youtube.com/embed/sIqz5xmQKnc?rel=0&amp;modestbranding=1&amp;feature=oembed" allowfullscreen="" scrolling="no" allow="encrypted-media; accelerometer; clipboard-write; gyroscope; picture-in-picture"></iframe></p><br>
<h2 id="marketing">Marketing</h2>
<p>Another issue that happens often is that because developers are making small games that they feel are sort of worthless, they don't really do a good, serious job at marketing them. For instance, the example game from <a href="https://howtomarketagame.com/2021/01/18/can-you-make-a-living-from-small-games-on-steam/" target="_blank">this article</a> was marketed on Twitter only.</p>
<p>Anyone who has released a game knows that Twitter is notoriously poor at driving sales, and that sites like reddit are much better. Would it really have cost these developers that much time to make a few posts about their games on reddit? No. And I know for a fact that a game of such visual quality would have done very well on multiple subreddits.</p>
<p>So a lot of the conclusions people reach about their efforts with smaller games, and the conclusion the author reaches in that article as well are pretty pessimist and in my view mistaken. I think that most devs making smaller games would benefit tremendously from taking making their games somewhat more spacious and from thinking more clearly about how they're going to market it.</p>
<h2 id="the-right-development-duration">The right development duration</h2>
<p>Another thing to consider is what's the right timeframe for making a small game. One of the videos above focuses on 1 month per game, and both my previous game and the game from the article above took 4 months. I think the right duration is between 1 and 2 months.</p>
<p>The reasons for this are fairly simple. If you're making a 1 month game you probably want something with a scope such that it can be finished in 2-3 days, and then you spend the rest of the month polishing it in various ways. This keeps your game fairly focused and it's a good strategy if you want to drastically increase your chances of actually finishing and release the game.</p>
<p>If you're making a 2 month game this affords you a little more time such that you can actually start adding some meat to it and make it more spacious. But I personally think that it's too easy to start getting lost in scope-creep if you give yourself much more time than 2 months, so that would be my limit. Currently that's what I'm aiming for with the game I'm making and I already overscoped myself slightly (meaning I should have chosen an even smaller game), so I think it really pays to keep this duration limited like this unless you're already more experienced and know you can avoid making these kinds of mistakes.</p>
<p>What also matters is how much money you can expect to make off of these games. BYTEPATH for instance made about $10k over its lifetime, and if I were to release a game like BYTEPATH every 2 months and they all did half as well as it did, then that would be considered "making a living from small games on Steam". But that's largely because I live in Brazil and that amount of money here (even accounting for cuts and taxes) every 2 months would be a pretty comfortable salary. If you're in more expensive countries then perhaps that isn't such a good strategy, so this timeframe consideration really depends on your personal situation as well.</p>
<h2 id="luck">Luck</h2>
<p>To finalize this fairly rambly article, one of the reasons people cite for making small games is to hedge their bets. The argument goes that if they make lots of games, chances are that one of those games will succeed wildly and cover for the costs of the other failures. More specifically <a href="https://www.gamasutra.com/blogs/DanielCook/20150415/241145/Minimum_Sustainable_Success.php" target="_blank">this article</a> said that using this famous graph:</p>
<p><img src="https://i.imgur.com/FNg1WW8.png"></p>
<p>I similarly reject this notion. In my opinion you shouldn't make small games for any reason having to do with what that article says. When you're approaching things from this economic portfolio theory approach you're mirrorring the biases of our society around the notion of luck and chance and it more likely than not will sap your motivation to work on things without you even realizing it.</p>
<p>Additionally, for a single indie developer like me, I don't think it's actually that hard to get a game to sell, say 5000 copies. And if you can do that consistently you can definitely make a living off it. Maybe I'm arrogant and I don't know what I'm talking about. I probably am, after all I've only released one game. But I'd rather be arrogant like that than view things from this lottery/luck oriented approach that so many people seem to fall prey to these days.</p>
<p>This …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://a327ex.github.io/blog/small-games">https://a327ex.github.io/blog/small-games</a></em></p>]]>
            </description>
            <link>https://a327ex.github.io/blog/small-games</link>
            <guid isPermaLink="false">hacker-news-small-sites-25873837</guid>
            <pubDate>Fri, 22 Jan 2021 17:29:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ClickHouse Is Apache 2.0]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25873409">thread link</a>) | @hodgesrm
<br/>
January 22, 2021 | https://altinity.com/blog/clickhouse-is-apache-2-0 | <a href="https://web.archive.org/web/*/https://altinity.com/blog/clickhouse-is-apache-2-0">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	

	<p>Open source licenses are in the news again. Elastic recently <a href="https://www.elastic.co/blog/licensing-change" target="_blank" rel="noreferrer noopener">changed the licensing for ElasticSearch and Kibana</a> from Apache 2.0 to a choice of <a href="https://www.mongodb.com/licensing/server-side-public-license" target="_blank" rel="noreferrer noopener">Server Side Public License</a> (SSPL) or the non-open source Elastic license. Like most open source licensing changes, this one prompted a lot of discussion. Examples <a href="https://news.ycombinator.com/item?id=25776657" target="_blank" rel="noreferrer noopener">here</a> and <a href="https://news.ycombinator.com/item?id=25833781" target="_blank" rel="noreferrer noopener">here</a> include some of the more printable comments.&nbsp;</p><p>But we’re not here to discuss Elastic’s business model or their choice of license(s).&nbsp; We’re here to discuss ClickHouse licensing and Altinity’s view of it. Here’s the executive summary.&nbsp;</p><p><strong>ClickHouse is Apache 2.0.&nbsp; Altinity is committed to ensuring it stays that way.&nbsp;</strong></p><p>Our contributions to ClickHouse are<a href="https://en.wikipedia.org/wiki/Apache_License" target="_blank" rel="noreferrer noopener"> Apache 2.0</a>. Our ecosystem projects like the ClickHouse Kubernetes operator are likewise Apache 2.0. We believe the Apache 2.0 license is best for our users. It’s also the best way to make ClickHouse the most popular SQL data warehouse on the planet. There are several reasons for our outlook.&nbsp;</p><p>The most important feature of Apache 2.0 is that it allows use for any purpose, which is the first of the <a href="https://www.gnu.org/philosophy/free-sw.en.html" target="_blank" rel="noreferrer noopener">four essential freedoms</a> of open source software. Such freedom is important for all applications, regardless of whether they run on-prem or as cloud services. Apache 2.0 opens the door to imaginative new services as well as creative paths to develop them. Installed&nbsp;applications morph into online services. Services that hide data behind APIs morph into open data. This freedom is key to enabling innovative new ways to incorporate analytics into applications, which in turn unlocks new business opportunities.&nbsp;</p><p>Apache 2.0 is also a great license for contributors.&nbsp; It has been around since 2004, which is a long time in open source. Corporate legal departments understand it and can easily approve contributions from employees. Individual contributors understand the freedom Apache 2.0 confers to publish their work and use it freely in future. It’s a win-win: companies are motivated to make investment decisions in open source projects, and contributors are motivated to implement them.&nbsp;</p><p>Apache 2.0 licensing opens a path to increasing ClickHouse capabilities and worldwide use. More important, it is enabling a flood of innovation in analytic applications. In a crowded market with many database products besides ClickHouse, that’s a critical competitive advantage.&nbsp;</p><p><h2 id="h-apache-2-0-creates-a-level-playing-field">Apache 2.0 creates a level playing field</h2>
</p><p>Since the ClickHouse Apache 2.0 license places no restriction on business use, we can expect many competing services that leverage ClickHouse in one way or another.&nbsp; This includes hosted ClickHouse and value-added analytic services built on top of ClickHouse capabilities. It also extends to add-ons for countless existing services ranging from web analytics to network flow log management to financial asset valuation and everything in between.</p><p>The competition will be distressing for unprepared vendors, but it’s great for users. Competing services mean that users have alternatives. It also means that innovation is not random but focused on things that users care about: SQL features, performance, security, cost-efficiency, and time to market.&nbsp;</p><p>The same vendors that offer ClickHouse managed services have contributed popular features to ClickHouse like <a href="https://altinity.com/blog/clickhouse-and-s3-compatible-object-storage" target="_blank" rel="noreferrer noopener">S3 storage integration</a>, <a href="https://clickhouse.tech/docs/en/operations/access-rights/#role-management" target="_blank" rel="noreferrer noopener">Role-based Access Control</a>, <a href="https://clickhouse.tech/docs/en/sql-reference/statements/select/with/" target="_blank" rel="noreferrer noopener">Common Table Expressions</a>, and many more. ClickHouse is experiencing the same <a href="https://en.wikipedia.org/wiki/Coopetition" target="_blank" rel="noreferrer noopener">co-opetition</a> feedback effect that helped fuel the success of Linux, Kubernetes, PostgreSQL, and other open source projects.&nbsp;</p><p><h2 id="h-restrictive-licenses-like-sspl-are-antithetical-to-user-interests">Restrictive licenses like SSPL are antithetical to user interests</h2>
</p><p>The Server Side Public License is an attempt to set back the clock on open source software development. It rules out new SaaS offerings based on projects whose value&nbsp;</p><div><blockquote>
<p>…entirely or primarily derives from the value of the Program or modified version, or offering a service that accomplishes for users the primary purpose of the Program or modified version.&nbsp; (SSPL Section 13).&nbsp;</p>
</blockquote>
</div><p>The goal of the SSPL and similar licenses is nothing short of setting up monopoly providers of SaaS offerings. It has ambiguous terms–creating uncertainty for potential competitors–and onerous viral requirements. Services that fall under Section 13 must release all source code required to run the entire SaaS offering. That includes everything from the service management plane down to deployment and backup scripts. SSPL is <a href="https://www.gnu.org/licenses/copyleft.en.html" target="_blank" rel="noreferrer noopener">copyleft</a> with fangs.&nbsp;</p><p>This obviously affects vendors trying to set up competing services to the copyright holders of SSPL projects. But the effect on the market is far wider.&nbsp; Analytics are pervasive in modern applications and SaaS is the primary way that software is now distributed. The SSPL potentially harms any user building an application who just wants a managed offering to take care of running it. We believe that’s an unacceptable limitation.&nbsp;</p><p><h2 id="h-but-wait-what-about-amazon">But wait, what about Amazon?</h2>
</p><p>Many vendors have justified <a href="https://techcrunch.com/2018/10/16/mongodb-switches-up-its-open-source-license/" target="_blank" rel="noreferrer noopener">open source relicensing as a necessary defense</a> against “strip mining” from public clouds. Aren’t we afraid of this ourselves? If so, it’s a bit late. There are already multiple cloud services for ClickHouse, including our own offering, <a href="https://altinity.com/cloud-database/" target="_blank" rel="noreferrer noopener">Altinity.Cloud</a>. There’s also <a href="https://cloud.yandex.com/services/managed-clickhouse" target="_blank" rel="noreferrer noopener">Yandex.Cloud</a> and at least three services in China. New entrants need to compete by adding additional value, <a href="https://siliconangle.com/2020/07/08/suse-acquires-rancher-labs-reported-600m-chases-1b-revenue-goal/" target="_blank" rel="noreferrer noopener">just as Rancher did</a> in the Apache 2.0-licensed Kubernetes market.&nbsp;&nbsp;</p><p>Our goal at Altinity is to help customers bring high-value analytic applications to market quickly and operate them cost-effectively. We focus on development efficiency, data privacy, world-class support, and operations. We do so on all platforms, both public cloud and on-prem. Anybody who has worked on such services knows there’s opportunity here to build many valuable companies, not just one.&nbsp;</p><p>Other paths are possible. Vendors may fork ClickHouse and try to add licenses that create a proprietary fortress. If so, we would point to some friendly advice from a famous competitive analyst of the Italian Renaissance:&nbsp;</p><div><blockquote>
<p><em>So the best fortress that exists is to avoid being hated by the people. If you have fortresses and the people hate you, they will not save you</em>.</p>
<p><cite><em>Niccolo Machiavelli, The Prince</em></cite></p></blockquote>
</div><p>We don’t want to build new fortresses to protect ourselves against our users. We want to tear them down. Apache 2.0 is the key to enabling a new generation of analytic applications based on ClickHouse. Altinity is all in.&nbsp;</p><p>P.S., If you are worried about ElasticSearch and Kibana switching licenses, this might be a nice time to look at alternatives. ClickHouse can store log data remarkably well. More on that in future articles.&nbsp;</p>
	


					</div></div>]]>
            </description>
            <link>https://altinity.com/blog/clickhouse-is-apache-2-0</link>
            <guid isPermaLink="false">hacker-news-small-sites-25873409</guid>
            <pubDate>Fri, 22 Jan 2021 16:58:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[EU Parliament condemns China deal over HK crackdown]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25873389">thread link</a>) | @riffraff
<br/>
January 22, 2021 | https://news.rthk.hk/rthk/en/component/k2/1571688-20210122.htm?spTabChangeable=0 | <a href="https://web.archive.org/web/*/https://news.rthk.hk/rthk/en/component/k2/1571688-20210122.htm?spTabChangeable=0">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
			The EU has lost credibility on human rights by sealing an investment deal with China, a resolution in the European Parliament warned on Thursday.</p><p>

MEPs meeting by videolink in Brussels overwhelmingly passed the resolution which broadly condemned the crackdown on Hong Kong activists by the central government in China.</p><p>

The resolution also called for "targeted sanctions" against Chinese and Hong Kong officials held responsible for the police action.</p><p>

The opinion of EU lawmakers is important as they will need to approve the German-backed investment deal that was agreed in principle last month after years of talks.</p><p>

Given the Hong Kong crackdown, doubts about the accord have quickly emerged, with ratification by MEPs very much uncertain, though the vote is not expected until the end of the year at the earliest.</p><p>

The resolution said that MEPs "regret" that the EU-China investment talks were not seized "as a leverage tool aimed at preserving Hong Kong's high degree of autonomy, as well as its basic rights and freedoms".</p><p>

"By rushing to reach this agreement while not taking concrete action against ongoing, grave human right violations, for example in Hong Kong, Xinjiang province and Tibet, the EU risks undermining its credibility as a global human rights actor," it said.</p><p>

China is accused of grave human rights abuses against the Uighur minority in Xinjiang.</p><p>

The resolution said parliament will "carefully scrutinise" the deal and will take the human rights situation in China into account when it votes on the deal.</p><p>

The EU commission, which began negotiating the deal in 2014, said it helps rectify the long-standing imbalance in the way Brussels and Beijing treat investors and the access they allow them.</p><p>

It also says that China agreed through the deal - known as the Comprehensive Agreement on Investment (CAI) - to work harder towards approving International Labour Organisation (ILO) conventions on forced labour. (AFP)		</p></div></div>]]>
            </description>
            <link>https://news.rthk.hk/rthk/en/component/k2/1571688-20210122.htm?spTabChangeable=0</link>
            <guid isPermaLink="false">hacker-news-small-sites-25873389</guid>
            <pubDate>Fri, 22 Jan 2021 16:57:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The strange economics of open-source software (2015)]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25873194">thread link</a>) | @alexrustic
<br/>
January 22, 2021 | https://www.philipotoole.com/the-strange-economics-of-open-source-software/ | <a href="https://web.archive.org/web/*/https://www.philipotoole.com/the-strange-economics-of-open-source-software/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p><a href="https://www.maynardkeynes.org/" target="_blank" rel="noopener noreferrer"><img title="John Maynard Keynes" src="https://www.philipotoole.com/wp-content/uploads/2015/09/keynes-150x150.png" alt="John Maynard Keynes" width="150" height="150"></a>I always use the names of economists for my machines’ <a href="http://tools.ietf.org/html/rfc1034" target="_blank" rel="noopener noreferrer">hostnames</a>. <a href="http://www.econlib.org/library/Enc/bios/Keynes.html" target="_blank" rel="noopener noreferrer"><em>keynes</em></a>, <a href="http://www.nobelprize.org/nobel_prizes/economic-sciences/laureates/1976/friedman-bio.html" target="_blank" rel="noopener noreferrer"><em>friedman</em></a>, <a href="https://en.wikipedia.org/wiki/Karl_Marx" target="_blank" rel="noopener noreferrer"><em>marx</em></a>, <em><a href="https://fraser.stlouisfed.org/docs/meltzer/fisdeb33.pdf" target="_blank" rel="noopener noreferrer">fisher</a>, </em><em><a href="http://www.britannica.com/biography/David-Ricardo" target="_blank" rel="noopener noreferrer">ricardo</a></em>.</p>
<p>So every so often the strange economics of open-source software hits me.</p>
<p><span id="more-2749"></span><br>
Today it is almost taken for granted that the source code for most software is freely available. This is a profound and remarkable change, given how different it was only 15 years ago. From a certain point of view our industry is “giving away” its product, and yet the industry <a href="http://www.nytimes.com/2015/09/20/opinion/is-big-tech-too-powerful-ask-google.html?_r=0" target="_blank" rel="noopener noreferrer">is richer and more powerful than ever</a>.&nbsp; So where is the value? What are the implications?</p>
<h2>Where has all the closed-source software gone?</h2>
<p>Of course, it’s not <strong>gone</strong>. It’s there at the banks, within embedded devices, and companies such as <a href="https://www.microsoft.com/" target="_blank" rel="noopener noreferrer">Microsoft</a> and <a href="https://www.oracle.com/" target="_blank" rel="noopener noreferrer">Oracle</a> remain among the most powerful companies in the world, but almost all the innovation — and most importantly most of the excitement —&nbsp; is happening within open-source.</p>
<p>Within our industry it is becoming apparent that services — <a href="http://searchcloudcomputing.techtarget.com/definition/Software-as-a-Service" target="_blank" rel="noopener noreferrer">SaaS</a>&nbsp; and companies such as <a href="https://www.airbnb.com/" target="_blank" rel="noopener noreferrer">Airbnb </a>— are the future.&nbsp; And in fact, it sometimes seems to be that the only way to write really valuable closed-source software nowadays is within the context of a service. Behind all the <a href="https://en.wikipedia.org/wiki/Representational_state_transfer" target="_blank" rel="noopener noreferrer">REST</a> endpoints, the&nbsp; <a href="https://aws.amazon.com/elasticloadbalancing/" target="_blank" rel="noopener noreferrer">AWS ELBs</a>, and the<a href="http://www.haproxy.org/" target="_blank" rel="noopener noreferrer"> HAProxy systems</a>, sits some of most closely-guarded software in the world.</p>
<h2>The ever-increasing dominance of open-source</h2>
<p>The increasing dominance of open-source software seems particularly true with respect to infrastructure software.&nbsp; While security software has often been open-source through necessity — no-one would trust it otherwise — infrastructure is becoming the dominant category of open-source. Look at databases — <a href="https://dev.mysql.com/doc/internals/en/guided-tour.html" target="_blank" rel="noopener noreferrer">MySQL</a>, <a href="https://www.mongodb.org/" target="_blank" rel="noopener noreferrer">MongoDB</a>, <a href="https://www.rethinkdb.com/" target="_blank" rel="noopener noreferrer">RethinkDB</a>, <a href="https://github.com/apache/couchdb" target="_blank" rel="noopener noreferrer">CouchDB</a>, <a href="https://influxdb.com/" target="_blank" rel="noopener noreferrer">InfluxDB</a> (of which I am part of the <a href="https://github.com/influxdata/influxdb/graphs/contributors" target="_blank" rel="noopener noreferrer">development team</a>), or <a href="http://www.cockroachlabs.com/" target="_blank" rel="noopener noreferrer">cockroachdb</a>. Is there anyone today that would even consider developing a new closed-source database? Or take search technology — <a href="https://github.com/elastic/elasticsearch" target="_blank" rel="noopener noreferrer">elasticsearch</a>, <a href="http://lucene.apache.org/solr/" target="_blank" rel="noopener noreferrer">Solr</a>, and <a href="http://www.blevesearch.com/" target="_blank" rel="noopener noreferrer">bleve</a> — all open-source. And <a href="https://www.linux.com/" target="_blank" rel="noopener noreferrer">Linux</a> is so obvious, it is almost pointless to mention it.<br>
If you want to create a closed-source infrastructure solution, you better have an enormously compelling story, or be delivering it as part of a bigger package such as a software appliance.</p>
<h2>So where is the value?</h2>
<p>Compared to when I first <a href="https://en.wikipedia.org/wiki/Nortel" target="_blank" rel="noopener noreferrer">started programming,</a> that some of the most valuable companies in software now give away their product is astounding, when you actually think about it. So where is the real value within a such a company, when its product is free? It’s where it’s always been — just more so.</p>
<p>The real value is within the development team and its ideas, that the team behind the software are, and remain, innovative, execute well, and produce quality software. And that they remain so is key — so that it does not matter that what they produce is freely available.&nbsp; It is of little benefit to a competitor that the source is freely available, when the team behind the project is probably six months ahead — and often more — conceptually in terms of design, development and process.</p>
<h2>The economics of recruitment</h2>
<p>And the implications go far beyond how software is developed.<br>
It is generally accepted these days within <a href="https://en.wikipedia.org/wiki/Silicon_Valley">The Valley</a> that large, older, firms find it particularly hard to hire. The excitement, and latitude for creativity, within a start-up has always appealed, and even more so now with the outstanding <a href="http://www.bloomberg.com/news/articles/2014-10-28/facebook-s-22-billion-whatsapp-deal-buys-10-million-in-sales" target="_blank" rel="noopener noreferrer">commercial success of some</a>.</p>
<p>But a second-order effect is also prevalent — many developers baulk at the idea that their work may never be seen by their peers in the open-source community, and therefore may never help them progress in their careers. And it is at larger, older firms, that the least amount of open-source software is written — what <a href="http://paulgraham.com/index.html" target="_blank" rel="noopener noreferrer">Paul Graham</a> calls <a href="http://paulgraham.com/ideas.html" target="_blank" rel="noopener noreferrer">downwind jobs</a>.</p>
<p>But Services remain part of the future — because while the code that Service software developers write may not be visible, the functionality is visible to the world and with the advent of cloud-computing, the power accruing to these developers is significant and growing. Services can hire, unlike the traditional firms.</p>
<h2>Possibilities for our grandchildren</h2>
<p>The rise of open-source has been a remarkable development in the history of economics and production. I often wonder what <a href="http://www.econ.yale.edu/smith/econ116a/keynes1.pdf" target="_blank" rel="noopener noreferrer">Keynes</a>, Marx, and even Ricardo, would think of it all.</p>
	</div></div>]]>
            </description>
            <link>https://www.philipotoole.com/the-strange-economics-of-open-source-software/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25873194</guid>
            <pubDate>Fri, 22 Jan 2021 16:40:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Define New Intrinsics in SBCL (2014)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25872734">thread link</a>) | @Tomte
<br/>
January 22, 2021 | https://www.pvk.ca/Blog/2014/08/16/how-to-define-new-intrinsics-in-sbcl/ | <a href="https://web.archive.org/web/*/https://www.pvk.ca/Blog/2014/08/16/how-to-define-new-intrinsics-in-sbcl/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>This
<a href="https://stackoverflow.com/questions/25078285/replacing-a-32-bit-loop-count-variable-with-64-bit-introduces-crazy-performance">Stack Overflow</a>
post points out an obscure and undocumented weakness in Intel’s
implementation of the POPCNT instruction: although the population
count (number of bits equal to 1) is only a function of the source
argument, hardware schedules it as though it also depended on the
destination. GCC, clang and MSVC all fail to take this issue into
account.</p>
<p>Until a new patched version of my favourite C compiler is released,
there aren’t many tasteful workarounds for this performance bug. I’d
have to switch to inline asm, and either force the compiler to
allocate the same register to the input and the result, or force
different registers and clear the spurious dependency with a xor.
Ideally, I wouldn’t impose any additional constraint on the register
allocator and only insert a xor if the destination and source
registers don’t match.</p>
<p>SBCL easily supports this use case, without having to re-release or
even recompile the implementation: VOPs (virtual operations) execute
arbitrary CL code during code generation and they can be defined at
runtime.</p>
<p>The first step is to make sure that SBCL’s assembler knows how to emit
popcnt: the assembler can also be extended at runtime, but that’s more
hairy and a topic for another post. Instruction encodings are defined
in <code>src/compiler/$ARCH/insts.lisp</code>, and a quick grep reveals
<code>(define-instruction popcnt (segment dst src) ...)</code>: the x86-64
backend learned about popcnt in May 2013 (thanks to Douglas Katzman).</p>
<p>We define VOPs via <code>define-vop</code>, a macro that exposes many options.
Most of the time, it’s easiest to look at a pre-existing definition
for an operation that’s similar to the one we want to add. Popcount
looks like integer negation: it has a single (machine integer)
argument and returns another integer. Integer negation is defined in
<code>src/compiler/$ARCH/arith.lisp</code>:</p>
<div><notextile><figure><div><table><tbody><tr><td><pre><span>1</span>
<span>2</span>
<span>3</span>
<span>4</span>
<span>5</span>
<span>6</span>
<span>7</span>
<span>8</span>
<span>9</span>
<span>10</span>
<span>11</span>
<span>12</span>
<span>13</span>
<span>14</span>
<span>15</span>
<span>16</span>
<span>17</span>
<span>18</span>
<span>19</span>
<span>20</span>
<span>21</span>
<span>22</span>
<span>23</span>
<span>24</span>
<span>25</span>
<span>26</span>
<span>27</span>
<span>28</span>
<span>29</span>
<span>30</span>
<span>31</span>
<span>32</span>
<span>33</span>
<span>34</span>
<span>35</span>
<span>36</span>
<span>37</span>
<span>38</span>
<span>39</span>
<span>40</span>
</pre></td><td><pre><code><span>;;;; unary operations
</span><span>
</span><span>(define-vop (fast-safe-arith-op)
</span><span>  (:policy :fast-safe)
</span><span>  (:effects)
</span><span>  (:affected))
</span><span>
</span><span>(define-vop (fixnum-unop fast-safe-arith-op)
</span><span>  (:args (x :scs (any-reg) :target res))
</span><span>  (:results (res :scs (any-reg)))
</span><span>  (:note "inline fixnum arithmetic")
</span><span>  (:arg-types tagged-num)
</span><span>  (:result-types tagged-num))
</span><span>
</span><span>(define-vop (signed-unop fast-safe-arith-op)
</span><span>  (:args (x :scs (signed-reg) :target res))
</span><span>  (:results (res :scs (signed-reg)))
</span><span>  (:note "inline (signed-byte 64) arithmetic")
</span><span>  (:arg-types signed-num)
</span><span>  (:result-types signed-num))
</span><span>
</span><span>(define-vop (fast-negate/fixnum fixnum-unop)
</span><span>  (:translate %negate)
</span><span>  (:generator 1
</span><span>    (move res x)
</span><span>    (inst neg res)))
</span><span>
</span><span>(define-vop (fast-negate/signed signed-unop)
</span><span>  (:translate %negate)
</span><span>  (:generator 2
</span><span>    (move res x)
</span><span>    (inst neg res)))
</span><span>
</span><span>(define-vop (fast-negate/unsigned signed-unop)
</span><span>  (:args (x :scs (unsigned-reg) :target res))
</span><span>  (:arg-types unsigned-num)
</span><span>  (:translate %negate)
</span><span>  (:generator 3
</span><span>    (move res x)
</span><span>    (inst neg res)))</span></code></pre></td></tr></tbody></table></div></figure></notextile></div>
<p>The code snippet above includes a bit of boilerplate to factor out
commonalities via inheritance. The first definition introduces
<code>fast-safe-arith-op</code>, VOPs that apply in both high speed and high
safety settings (the rest is copy/pasted noise from earlier ports that
sport a scheduler); the second one extends <code>fast-safe-arith-op</code> to
define <code>fixnum-unop</code>, a base definition for single-argument operations
on fixnums, while the third one is the same, but for machine integers.
The last three definitions fill in the blanks so the compiler can
compile <code>%negate</code> of fixnum, signed and unsigned integers. The
<code>(:translate %negate)</code> bit means that these VOPs can be emitted
instead of calls to <code>%negate</code>. The integer after <code>:generator</code> defines
the “cost” of each variant; the compiler will choose the (applicable)
variant with the least cost and execute the code sequence that follows
to convert a call to <code>%negate</code> into machine code.</p>
<p>This kind of implementation inheritance is fine for an SBCL backend,
where we define many VOPs and expect developers to understand the
system. I doubt it’s a didactic win. Let’s do something simpler for
<code>popcnt</code>. In the interest of simplicity, I’ll also completely
disregard powerful details in <code>define-vop</code> that are rarely relevant
when defining intrinsics that map directly to machine instructions.</p>
<p>First, we need to tell the compiler that we’re about to do special
things to a function named <code>popcnt</code> (and to blow away any pre-existing
information if the <code>defknown</code> form is re-evaluated).</p>
<div><notextile><figure><div><table><tbody><tr><td><pre><span>1</span>
<span>2</span>
<span>3</span>
<span>4</span>
<span>5</span>
<span>6</span>
<span>7</span>
<span>8</span>
<span>9</span>
</pre></td><td><pre><code><span>(defpackage "POPCNT"
</span><span>  (:use "CL")
</span><span>  (:export "POPCNT"))
</span><span>
</span><span>(in-package "POPCNT")
</span><span>
</span><span>(sb-c:defknown popcnt ((unsigned-byte 64)) (integer 0 64)
</span><span>    (sb-c:foldable sb-c:flushable sb-c:movable)
</span><span>  :overwrite-fndb-silently t)</span></code></pre></td></tr></tbody></table></div></figure></notextile></div>
<p>This says that <code>popcnt</code> accepts a 64-bit unsigned integer and returns
an integer between 0 and 64 (inclusively), and that the function can
be constant-folded, flushed (eliminated as dead code) and moved around
(it’s pure).</p>
<p>Now, to define a VOP that implements <code>popcnt</code>:</p>
<div><notextile><figure><div><table><tbody><tr><td><pre><span>1</span>
<span>2</span>
<span>3</span>
<span>4</span>
<span>5</span>
<span>6</span>
<span>7</span>
<span>8</span>
<span>9</span>
<span>10</span>
<span>11</span>
<span>12</span>
<span>13</span>
</pre></td><td><pre><code><span>(in-package "SB-VM")
</span><span>
</span><span>(define-vop (popcnt:popcnt)
</span><span>  (:policy :fast-safe)
</span><span>  (:translate popcnt:popcnt)
</span><span>  (:args (x :scs (unsigned-reg) :target r))
</span><span>  (:arg-types unsigned-num)
</span><span>  (:results (r :scs (unsigned-reg)))
</span><span>  (:result-types unsigned-num)
</span><span>  (:generator 3
</span><span>    (unless (location= r x) ; only break the spurious dep. chain
</span><span>      (inst xor r r))       ; if r isn't the same register as x.
</span><span>    (inst popcnt r x)))</span></code></pre></td></tr></tbody></table></div></figure></notextile></div>
<p>We define a new VOP named <code>popcnt:popcnt</code> (the name is arbitrary, as
long as it doesn’t collide with another VOP) that is applicable at all
optimization policies (both high speed and high debug level), and that
implements <code>popcnt:popcnt</code>. Its first and only argument, <code>x</code>, is an
<code>unsigned-num</code>, an unsigned machine integer, that can only be stored
in a register. Moreover, if possible, we’d like <code>x</code> to be allocated
the same register as the result, <code>r</code>. There’s only one result (<code>r</code>)
and it’s an unsigned machine integer in a register, just like <code>x</code>.
The generator, of cost 3 (a common default for arithmetic operations),
breaks any dependency chain in <code>r</code> if necessary, and stores the
population count of <code>x</code> in <code>r</code>.</p>
<p>At first sight, the <code>defknown</code> form seems to conflict with the VOP.
We declare that the return value of <code>popcnt</code> is a small integer,
clearly a fixnum, and then define a VOP that returns a machine
integer. The subtlety is that <code>defknown</code> is concerned with IR1, the
higher level intermediate representation, which works on CL types
(i.e, types as sets) and abstract values. VOPs, on the other hand,
are defined for the lower level IR2, where types describe concrete
representations (like C). It is perfectly meaningful to say that a
small integer will be represented as an untagged machine integer.</p>
<p>The next step isn’t strictly necessary, but helps people who like
their REPL. The compiler knows how to compile calls to <code>popcnt</code>, so
we can define <code>popcnt</code>… as a call to <code>popcnt</code>. Our new function is
now a first-class value that can be called from interpreted code and
passed to higher-order functions, like the compiler’s constant-folding
pass.</p>
<div><notextile><figure><div><table><tbody><tr><td><pre><span>1</span>
<span>2</span>
<span>3</span>
<span>4</span>
</pre></td><td><pre><code><span>(in-package "POPCNT")
</span><span>
</span><span>(defun popcnt (x)
</span><span>  (popcnt x))</span></code></pre></td></tr></tbody></table></div></figure></notextile></div>
<pre><code>CL-USER&gt; (disassemble 'popcnt:popcnt)
; disassembly for POPCNT:POPCNT
; Size: 25 bytes
; 07FCDB6E:       4831D2           XOR RDX, RDX               ; no-arg-parsing entry point
;       71:       F3480FB8D1       POPCNT RDX,RCX
;       76:       48D1E2           SHL RDX, 1
;       79:       488BE5           MOV RSP, RBP
;       7C:       F8               CLC
;       7D:       5D               POP RBP
;       7E:       C3               RET
[ error trap noise ]
CL-USER&gt; (popcnt:popcnt 42)
3
</code></pre>
<p>The disassembly shows that we get the code that we expect, including
the dependency-breaking workaround, and the smoke test passes.
There’s one interesting detail: we only defined a VOP that returns a
machine integer. However, <code>popcnt</code> returns a tagged value (a fixnum),
and does so with an efficient shift. IR2 takes care of inserting any
coercion needed between VOPs (e.g., between <code>popcnt</code> and the VOP used to
return boxed values from functions), and the IR1 <code>defknown</code> guarantees
that the result of <code>popcnt</code>, despite being <em>represented</em> in an
unsigned machine integer, is small enough for a fixnum.</p>
<p>Let’s see what happens when we feed arithmetic into <code>popcnt</code>, e.g.:</p>
<pre><code>CL-USER&gt; (disassemble (lambda (x y)
                        (declare (type (unsigned-byte 32) x y))
                        (popcnt:popcnt (+ x y))))
; disassembly for (LAMBDA (X Y))
; Size: 55 bytes
; 0752BD59:       4801FA           ADD RDX, RDI               ; no-arg-parsing entry point
;       5C:       48D1FA           SAR RDX, 1
;       5F:       F3480FB8D2       POPCNT RDX,RDX
;       64:       48D1E2           SHL RDX, 1
;       67:       488BE5           MOV RSP, RBP
;       6A:       F8               CLC
;       6B:       5D               POP RBP
;       6C:       C3               RET
</code></pre>
<p>After adding two fixnums, an automatic coercion unboxes the resulting
fixnum into a machine integer which is then passed to <code>popcnt</code>
(note the lack of dependency-breaking <code>xor</code> now that the source and
destination are the same register).</p>
<p>That’s pretty good code, but we can do better: fixnums are tagged with
0, so we can simply pass fixnums to <code>popcnt</code> without untagging.</p>
<p>This is where the cost parameter to <code>:generator</code> comes in: we can
define another VOP for <code>popcnt</code> of fixnums and bias the compiler to
prefer the fixnum VOP.</p>
<div><notextile><figure><div><table><tbody><tr><td><pre><span>1</span>
<span>2</span>
<span>3</span>
<span>4</span>
<span>5</span>
<span>6</span>
<span>7</span>
<span>8</span>
<span>9</span>
<span>10</span>
<span>11</span>
<span>12</span>
<span>13</span>
</pre></td><td><pre><code><span>(in-package "SB-VM")
</span><span>
</span><span>(define-vop (popcnt/fx)
</span><span>  (:policy :fast-safe)
</span><span>  (:translate popcnt:popcnt)
</span><span>  (:args (x :scs (any-reg) :target r))
</span><span>  (:arg-types positive-fixnum)
</span><span>  (:results (r :scs (unsigned-reg)))
</span><span>  (:result-types unsigned-num)
</span><span>  (:generator 2 ; 2 is lower than 3, so popcnt/fx is preferable to popcnt
</span><span>    (unless (location= r x)
</span><span>      (inst xor r r))
</span><span>    (inst popcnt r x)))</span></code></pre></td></tr></tbody></table></div></figure></notextile></div>
<pre><code>CL-USER&gt; (disassemble (lambda (x y)
                        (declare (type (unsigned-byte 32) x y))
                        (popcnt:popcnt (+ x y))))
; disassembly for (LAMBDA (X Y))
; Size: 47 bytes
; 07BEABE9:       4801FA           ADD RDX, …</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.pvk.ca/Blog/2014/08/16/how-to-define-new-intrinsics-in-sbcl/">https://www.pvk.ca/Blog/2014/08/16/how-to-define-new-intrinsics-in-sbcl/</a></em></p>]]>
            </description>
            <link>https://www.pvk.ca/Blog/2014/08/16/how-to-define-new-intrinsics-in-sbcl/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25872734</guid>
            <pubDate>Fri, 22 Jan 2021 15:57:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[All About Identity Providers: The ABCs of IDPs]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25872585">thread link</a>) | @sbauch
<br/>
January 22, 2021 | https://ossoapp.com/blog/all-about-idps/ | <a href="https://web.archive.org/web/*/https://ossoapp.com/blog/all-about-idps/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><img alt="IDP" src="https://d33wubrfki0l68.cloudfront.net/2e3bb3dac11a682694ccdbae58843d5023524bb1/88d05/img/idps.jpg"><h3>The ABCs of IDPs<a href="#the-abcs-of-idps" title="Direct link to heading">#</a></h3><p>Identity Providers (IDPs) are a category of software applications responsible for <strong>managing employee access</strong> to the various third party applications (AKA Service Providers) that modern enterprise companies rely on.</p><h3>Why companies use Identity Providers<a href="#why-companies-use-identity-providers" title="Direct link to heading">#</a></h3><p>On average, companies with fewer than 1,000 employees rely on <a href="https://www.mcafee.com/blogs/enterprise/cloud-security/every-company-is-a-software-company-today" target="_blank" rel="noopener noreferrer">22 separate applications to run their business</a>. As a result, for each application an employee has access to, the employee will need to be onboarded with the proper privileges, a username and password created, and eventually offboarded upon their departure. Each point in this process gives rise to security risks.</p><p>An Identity Provider enables companies to take control of this process and ensure the correct employee is receiving the proper access levels to applications necessary for them to do their job. Additionally, Identity Providers provide employees Single Sign-On (SSO) access to applications so they don’t have to remember multiple passwords or reuse the same passwords across many applications. Upon departure, an administrator of the Identity Provider can disable access to all applications for the exiting employee at the same time.</p><h3>How Identity Providers work<a href="#how-identity-providers-work" title="Direct link to heading">#</a></h3><p>An Identity Provider is basically just a list of employee names and their job titles. A Service Provider can be anything from a chat app for internal communication where every employee requires access, to more specialized applications like that of payroll management where only a few employees are granted access.</p><p><strong>An employee attempting to login to an application used for their work typically has one of two methods to do so via IDP:</strong></p><h4>1. Identity Provider-initiated<a href="#1-identity-provider-initiated" title="Direct link to heading">#</a></h4><p>Logging into an application through an Identity Provider-initiated workflow relies on the employee to log in to their Identity Provider Portal; this is often the only username and password employees will need. From the portal, they select the application they’d like to access, and will then be redirected via a new browser window to their desired Service Provider. The Service Provider will get a message from the Identity Provider saying that the person logging in has been authenticated and is in fact who they say they are. The Service Provider sees this and grants the employee access.</p><h4>2. Service Provider-initiated<a href="#2-service-provider-initiated" title="Direct link to heading">#</a></h4><p>Signing into applications via the IDP can sometimes feel inconvenient to employees. As a result, Service Provider-initiated login is a more popular alternative. This method allows employees to login via the Service Provider’s website, just like they would normally if their employer didn’t require the use of an Identity Provider. With this method, when the employee enters their email into the Service Provider’s website, the SP will send an authentication request to the IDP associated with the employee’s email address. If the employee is already logged into their employer’s IDP, and has access to the SP making the request, the IDP will return a message to the SP letting them know the employee’s identity has been authenticated, thereby granting them access. If the employee isn’t logged into their IDP, a separate screen will prompt the employee to log in to the IDP in order for them to be authenticated and gain access to the SP.</p><h3>Challenges of Integrating Identity Providers<a href="#challenges-of-integrating-identity-providers" title="Direct link to heading">#</a></h3><p>Although each Identity Provider relies on SAML as a common means to enable SSO across Service Providers, they each have a slightly different workflow for onboarding a new Service Provider. As a result, Service Providers have to familiarize themselves with the workflow of each Identity Provider they support.</p><p>This isn’t too much of an issue when they’re supporting one or two Identity Providers, but as companies grow and mature they continue to acquire enterprise customers, and eventually they’ll be asked to support yet another new Identity Provider. Soon enough, one or two IDPs turns into five or ten, each with their own unique workflow that needs to be learned and supported.</p><h3>Benefits of supporting Identity Providers within your Service<a href="#benefits-of-supporting-identity-providers-within-your-service" title="Direct link to heading">#</a></h3><p>As B2B SaaS companies begin to sell upmarket into the enterprise space, certain security features are considered table stakes and are viewed as a prerequisite to even begin a sales conversation. SAML SSO falls into this category of features and is often viewed as a bare minimum requirement to begin selling into enterprise companies.</p><p>Additionally, when a Service Provider supports an Identity Provider they are given the opportunity to be a part of that Identity Provider’s Marketplace. This is where enterprise companies can search for software solutions that already connect to their chosen IDP.</p><p>Don’t let prospective customers disqualify themselves from your solution. Since SAML SSO is so often considered to be a prerequisite, when shopping for software many prospects will eliminate vendors based on this requirement when creating a shortlist. It is in your best interest, as a Service Provider, to support as many Identity Providers as possible to ensure this is not an objection for future prospects.</p><h3>Which Identity Providers you should support first<a href="#which-identity-providers-you-should-support-first" title="Direct link to heading">#</a></h3><p>Since balancing resources when determining your feature roadmap is a constant concern, you’ll need to prioritize the Identity Provider with the greatest reach. <a href="https://www.okta.com/" target="_blank" rel="noopener noreferrer">Okta</a> and Microsoft’s <a href="https://azure.microsoft.com/en-us/services/active-directory/" target="_blank" rel="noopener noreferrer">Azure Active Directory</a> are the industry leaders, but still require scoping, coding, testing, documenting, and training in order to produce a working prototype.</p><h3>The easy way to enable IDP logins<a href="#the-easy-way-to-enable-idp-logins" title="Direct link to heading">#</a></h3><p>Given the challenges of supporting multiple IDPs, it won’t surprise you that we recommend giving <a href="https://ossoapp.com/blog/1-0-0-release-candidate">Osso</a> a try. We’ve built a one-stop solution to connect your Service to a number of Identity Providers (and we’re constantly adding more), in addition to providing an intuitive dashboard to help manage and onboard your enterprise customers. Each Identity Provider has been outfitted with customized <a href="https://ossoapp.com/docs/user-guide/onboarding-customers">documentation</a> so that your Customer Success and Sales teams can take the lead on seamlessly onboarding your next enterprise customer to their preferred Identity Provider. </p><p>We’re excited to help businesses of all sizes support SAML, so if that sounds appealing please check out our <a href="https://ossoapp.com/pricing">plans</a> to find an option that fits your needs.</p></section></div>]]>
            </description>
            <link>https://ossoapp.com/blog/all-about-idps/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25872585</guid>
            <pubDate>Fri, 22 Jan 2021 15:43:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: An Interactive Virtual Keyboard to Visualize Collections of Shortcuts]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25872549">thread link</a>) | @tkainrad
<br/>
January 22, 2021 | https://tkainrad.dev/posts/visualize-collections-of-keyboard-shortcuts/ | <a href="https://web.archive.org/web/*/https://tkainrad.dev/posts/visualize-collections-of-keyboard-shortcuts/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="contentdiv">

<p>An important part of <a href="https://keycombiner.com/">KeyCombiner</a> is displaying collections of keyboard shortcuts. Therefore, I have invested a lot of time to design searching and filtering features that help to browse even large collections.</p>
<p>Unfortunately, these feature are not sufficient when you want to understand a collection of hundreds of shortcuts at a glance. I have been thinking about this problem since I started working on KeyCombiner almost precisely one year ago. Today, I am happy to announce that KeyCombiner offers a solution:<br>
The Shortcut Collection Visualizer</p>
<figure>
<img src="https://tkainrad.dev/images/keycombiner/collection-visualizer/visual-keyboard-short-blog-bg.gif" alt="Collection Visualizer for XCode, one of very few applications that use all 4 modifier keys at the same time."> <figcaption>
<p>Collection Visualizer for <a href="https://keycombiner.com/collections/xcode/">XCode</a>, one of very few applications that use all 4 modifier keys at the same time.</p>
</figcaption>
</figure>
<p>It is heavily inspired by Waldo Bronchart’s open-source <a href="https://github.com/waldobronchart/ShortcutMapper">Application Shortcut Mapper</a>. However, it is a new VueJS-based implementation, adding several additional features that work together with the rest of KeyCombiner. Most importantly, it can efficiently process KeyCombiner’s collection tables and hence works for any shortcut collection on KeyCombiner, <a href="https://keycombiner.com/collecting/collections/public/search/?description=dialog&amp;keys=&amp;mac_keys=&amp;submit=Search">even search results</a>.</p>
<p>If you want to play around with it right away, go to any public KeyCombiner collection, e.g. for <a href="https://keycombiner.com/collections/vscode/">VSCode</a>, <a href="https://keycombiner.com/collections/intellij-idea/winlinux/">IntelliJ IDEA</a>, <a href="https://keycombiner.com/collections/xcode/">XCode</a>, <a href="https://keycombiner.com/collections/chrome/winlinux/">Chrome</a> or one of <a href="https://keycombiner.com/collections/">the other 60+ public collections</a>. If you want to fully undestand its potential, please read on.</p>

<h2 id="overview">Overview</h2>
<p>The virtual keyboard packs a lot of data into a relatively small space. Each button of the keyboard consists of the following elements:</p>
<figure>
<img src="https://tkainrad.dev/images/keycombiner/collection-visualizer/visual-keyboard-description.png" alt="Elements on each key of the virtual keyboard."> <figcaption>
<p>Elements on each key of the virtual keyboard.</p>
</figcaption>
</figure>
<h2 id="grouping-by-modifier-combination">Grouping by Modifier Combination</h2>
<p>A proper keyboard shortcut consists of 0 or more modifier keys and exactly one non-modifier key. There are 4 modifier keys:</p>
<ol>
<li><kbd>Ctrl</kbd></li>
<li><kbd>Shift</kbd></li>
<li><kbd>Alt</kbd></li>
<li><kbd>Cmd</kbd> (macOS) / <kbd>Super</kbd> (Windows and Linux)</li>
</ol>
<p>This order of modifiers is not random. KeyCombiner <em>always</em> shows keyboard shortcuts with precisely this order. <a href="https://twitter.com/ThomasKainrad/status/1340769935971282946">There are good reasons for this</a>.</p>
<p>This means that we have four boolean variables, resulting in $2^4$ possible modifier combinations. For each of these 16 states, the Collection Visualizer uses a different background color, or background gradient if there are multiple active modifiers.</p>
<p>To toggle modifiers, click on the virtual buttons with your mouse, or press the respective modifier key on on your physical keyboard. The entire virtual keyboard will then update according to the active combination of modifiers.</p>
<figure>
<img src="https://tkainrad.dev/images/keycombiner/collection-visualizer/all-modifier-states.gif" alt="It is very rare that a key has a shortcut for every modifier combination. However, it can happen, especially when combining shortcuts of multiple applications in personal collections. (Please don&amp;rsquo;t tell me I forgot one of the 16 modifier combinations - it took me way too long to create this animation.)"> <figcaption>
<p>It is very rare that a key has a shortcut for every modifier combination. However, it can happen, especially when combining shortcuts of multiple applications in personal collections. <br> (Please don’t tell me I forgot one of the 16 modifier combinations - it took me way too long to create this animation.)</p>
</figcaption>
</figure>
<h2 id="filter-collection-table">Filter Collection Table</h2>
<p>One of my favorite things about KeyCombiner’s shortcut collections is that I can filter them by context, category, or modifier combination with a single click using the panes on the side.</p>
<p>The collection visualizer expands on this concept. If you click on any non-modifier key, the collection table will show all shortcuts that use this particular key. To show all shortcuts containing the key <kbd>F</kbd> click on the F button on the virtual keyboard.</p>
<figure>
<img src="https://tkainrad.dev/images/keycombiner/collection-visualizer/filter-by-key-press.gif" alt="Filtering the collection table for all shortcuts that contain the F key."> <figcaption>
<p>Filtering the collection table for all shortcuts that contain the <kbd>F</kbd> key.</p>
</figcaption>
</figure>
<h2 id="real-time-updates-on-changes">Real-time updates on changes</h2>
<p>Building personal collections of keyboard shortcuts and text snippets is the foundational concept behind KeyCombiner. You can then practice these collections with its interactive trainer, relying on spaced repetition techniques and advanced statistics to guide your learning progress. You can also use <a href="https://keycombiner.com/desktop/">KeyCombiner Desktop</a> to instantly look up all combinations in your collections without leaving your current context.</p>
<p>Oh wait, I am getting side-tracked. I meant to say that the collection visualizer updates immediately whenever you make a change to one of your collections. A change could be adding new shortcuts, editing existing entries, or re(moving) entries. This works in the blink of an eye, even if you remove hundreds of combinations at once.</p>
<h2 id="additional-features">Additional Features</h2>
<p>I am getting the sense that this post will be too long for the average person’s interest in keyboard shortcuts. So, I will list some additional features in shorter form:</p>
<ul>
<li>There are three levels of opacity:
<ol>
<li>Keys without any mapped combinations</li>
<li>Keys with mapped shortcuts, but none that use the current modifiers</li>
<li>Keys that have a combination with the currently activated modifiers</li>
</ol>
</li>
</ul>
<figure>
<img src="https://tkainrad.dev/images/keycombiner/collection-visualizer/opacity.png" alt="Different levels of opacity carry information."> <figcaption>
<p>Different levels of opacity carry information.</p>
</figcaption>
</figure>
<ul>
<li>If, for any modifier combination, there are two or more shortcuts bound to a key, the number of combinations in the top right of the button is marked red.</li>
<li>If there are two or more combinations on a key for the current modifier state, the shortcut description for this key says <em>Conflict</em>.</li>
<li>There is a small text below the virtual keyboard saying how many shortcuts are mapped onto the virtual keyboard, and how many combinations had to be skipped. (See <a href="#current-limitations">Current Limitations</a>)</li>
<li>The keyboard must be in focus if you want to activate modifiers by pressing the respective buttons on your physical keyboard. This is so that you can still use <kbd>Ctrl</kbd> and <kbd>Shift</kbd> for table selection operations without affecting the visualizer. Buttons below the virtual keyboard allow toggling the focus.</li>
</ul>

<h2 id="quickly-grasp-a-set-of-shortcuts">Quickly Grasp a Set of Shortcuts</h2>
<p>Perhaps the most obvious use case is exploring a collection of shortcuts. The visual keyboard helps immensely in this process. Within seconds, you can get a feeling of which modifiers are used by a specific application and whether it uses Vim-like home row navigation or something else entirely.</p>
<p>The different layers of opacity aid this use case. Without activating any modifiers, you can already understand where the most shortcuts are located. This is supported further by the combination count in each virtual keyboard button’s top right.
Filtering the collection table by clicking on a specific key lets you see all shortcuts for that key and understand how they are related.</p>
<h2 id="see-conflicts-and-free-combinations">See Conflicts and Free Combinations</h2>
<p>At the moment, this is my favorite use case, as I have used it plenty of times already with great success.</p>
<p>I recently <a href="https://tkainrad.dev/posts/learning-all-vscode-shortcuts-evolved-my-developing-habits/">learned all VSCode shortcuts</a> with KeyCombiner’s interactive trainer. However, since then, I have started to experiment with <a href="https://tkainrad.dev/posts/learning-all-vscode-shortcuts-evolved-my-developing-habits/">Foam</a> and picked up some other extensions. All of these come with their own set of commands. So, I frequently have to find an available key combination for a new command I want to use efficiently. VSCode itself is not much help with that. It tells you <em>after</em> setting a combination that it is already taken:</p>
<figure>
<img src="https://tkainrad.dev/images/keycombiner/collection-visualizer/vscode-binding-exists.png" alt="Different levels of opacity carry information."> <figcaption>
<p>Different levels of opacity carry information.</p>
</figcaption>
</figure>
<p>I guess it’s better than nothing, but trying multiple combinations and manually checking what other combination is already using that binding and whether you might be able to remove that other binding is not much fun.
The collection visualizer made it trivial to see that there are actually plenty of free combinations in VSCode, only <kbd>Ctrl</kbd> and <kbd>Shift</kbd> are quite busy by default. Things start happening if you mix in <kbd>Alt</kbd>:</p>
<figure>
<img src="https://tkainrad.dev/images/keycombiner/collection-visualizer/vscode-free-combinations.png" alt="All modifier combinations with Alt are wide open for your own assignments in VSCode."> <figcaption>
<p>All modifier combinations with <kbd>Alt</kbd> are wide open for your own assignments in VSCode.</p>
</figcaption>
</figure>
<p>You can then go one step further and find free combinations that are easy to type. For me, these are combinations that I can type with just my left hand. If the non-modifier key is on the home row, that’s another big plus. In any case, a convenient shortcut should have a maximum of two modifiers.</p>
<h2 id="design-a-coherent-set-of-shortcuts">Design a Coherent Set of Shortcuts</h2>
<p>The collection visualizer helps design a coherent set of shortcuts, either for yourself or for an application you are developing.</p>
<p>Unfortunately, many application designers do not think very hard about keyboard shortcuts. Often, you end up with a set that is neither intuitive nor easy to type. Heck, even <a href="https://keycombiner.com/collections/keycombiner/">KeyCombiner’s own shortcuts</a> are all over the place with sequences and different modifier combinations. Given that I work more or less alone on the project and try to be very efficient with my time, I didn’t think about these bindings enough. The collection visualizer makes this painfully obvious, and I will soon come up with new shortcuts. However, it will be very hard not to annoy users who have already memorized these shortcuts.
So, I recommend that you be smarter than me and start to design a coherent set of shortcuts for your application right away. The collection visualizer is here to help you with that.</p>
<p>If you are not an application designer, you might still want to design a coherent set of key bindings for your personal use. Without any tools to assist you, this is a suprisingly hard taks, especially when you try to find a coherent set for or <em>multiple</em> applications. You have to keep in mind which commands are available in these different apps, what the defaults are, and how to resolve these constraints into a set that works everywhere.
The collection visualizer, along with KeyCombiner’s other collection management features, can help you get there.</p>

<p>Above, I have written that a proper keyboard shortcut consists of 0 or more modifier keys and exactly one non-modifier key. However, KeyCombiner also allows sequences, such as the <em>Go To</em> shortcuts used by Gmail. I have been thinking a lot about how to visualize those on a virtual keyboard, but have not found a good solution yet.</p>
<p>Furthermore, KeyCombiner collections can also hold short text snippets, such as commands and programming language syntax. Many people use these snippets with the <a href="https://tkainrad.dev/posts/app-to-show-shortcuts-of-current-application-windows-linux-macos">Desktop Apps' instant lookup</a>. It turns your collections into an instant, context-aware, searchable cheatsheet. However, I struggle to find a way to visualize them on a keyboard.</p>

<p>In its first days, the collection visualizer has already helped me plenty of times. I improved my VSCode bindings, realized that KeyCombiner’s own default bindings are not intuitive, and found better ways to reuse my VSCode bindings in PyCharm and Eclipse.
I’d be thrilled to hear about your experiences in the comments below or via <a href="https://tkainrad.dev/cdn-cgi/l/email-protection#37435f585a564477435c565e5945565319535241">mail</a>.</p>
<p>I will write about the collection visualizer’s implementation in a future blog post. Spoiler: Vue and (S)CSS do the heavy lifting.</p>
<br>
</div></div>]]>
            </description>
            <link>https://tkainrad.dev/posts/visualize-collections-of-keyboard-shortcuts/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25872549</guid>
            <pubDate>Fri, 22 Jan 2021 15:40:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pidgin – A Universal Chat Client]]>
            </title>
            <description>
<![CDATA[
Score 619 | Comments 420 (<a href="https://news.ycombinator.com/item?id=25872525">thread link</a>) | @smusamashah
<br/>
January 22, 2021 | https://www.pidgin.im/plugins | <a href="https://web.archive.org/web/*/https://www.pidgin.im/plugins">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                        <tr data-type="Protocol">
                            <td>
                                &nbsp;
                            </td>
                            <td>
                                <a href="https://github.com/awslabs/pidgin-chime/">Amazon Chime</a>
                            </td>
                            <td>
                                <span aria-label="Community">
                                    <i></i>
                                </span>
                            </td>
                            <td>
                                Protocol
                            </td>
                            <td>
                                Online meeting and video conferencing
                            </td>
                            <td>
                                Amazon Web Services - Labs
                            </td>
                        </tr>
                        <tr data-type="Protocol">
                            <td>
                                &nbsp;
                            </td>
                            <td>
                                <a href="https://github.com/nmbook/pidgin-libbnet/">Battle.net Classic</a>
                            </td>
                            <td>
                                <span aria-label="Community">
                                    <i></i>
                                </span>
                            </td>
                            <td>
                                Protocol
                            </td>
                            <td>
                                Blizzard’s gaming network: notably for StarCraft, Diablo II, and WarCraft III
                            </td>
                            <td>
                                nmbook
                            </td>
                        </tr>
                        <tr data-type="Protocol" istrusted="true">
                            <td>
                                <img src="https://github.com/EionRobb/purple-battlenet/raw/master/battlenet48.png" alt="Battle.net v2 logo">
                            </td>
                            <td>
                                <a href="https://github.com/EionRobb/purple-battlenet#readme">Battle.net v2</a>
                            </td>
                            <td>
                                <span aria-label="Trusted">
                                    <i></i>
                                </span>
                            </td>
                            <td>
                                Protocol
                            </td>
                            <td>
                                Blizzard’s gaming network for WoW, Overwatch and others
                            </td>
                            <td>
                                EionRobb
                            </td>
                        </tr>
                        <tr data-type="Protocol">
                            <td>
                                <img src="https://github.com/jrfoell/campfire-libpurple/raw/master/campfire48.png" alt="Campfire logo">
                            </td>
                            <td>
                                <a href="https://github.com/jrfoell/campfire-libpurple/">Campfire</a>
                            </td>
                            <td>
                                <span aria-label="Community">
                                    <i></i>
                                </span>
                            </td>
                            <td>
                                Protocol
                            </td>
                            <td>
                                Protocol plugin for Basecamp’s Campfire IM
                            </td>
                            <td>
                                jrfoell
                            </td>
                        </tr>
                        <tr data-type="Protocol">
                            <td>
                                &nbsp;
                            </td>
                            <td>
                                <a href="https://github.com/ccpp/deltachat-purple/">Deltachat</a>
                            </td>
                            <td>
                                <span aria-label="Community">
                                    <i></i>
                                </span>
                            </td>
                            <td>
                                Protocol
                            </td>
                            <td>
                                IM over email
                            </td>
                            <td>
                                ccpp
                            </td>
                        </tr>
                        <tr data-type="Protocol" istrusted="true">
                            <td>
                                &nbsp;
                            </td>
                            <td>
                                <a href="https://github.com/EionRobb/purple-discord/#readme">Discord</a>
                            </td>
                            <td>
                                <span aria-label="Trusted">
                                    <i></i>
                                </span>
                            </td>
                            <td>
                                Protocol
                            </td>
                            <td>
                                Text chat for gamers
                            </td>
                            <td>
                                EionRobb
                            </td>
                        </tr>
                        <tr data-type="Protocol">
                            <td>
                                &nbsp;
                            </td>
                            <td>
                                <a href="https://github.com/samuelkarp/purple-docker/">Docker</a>
                            </td>
                            <td>
                                <span aria-label="Community">
                                    <i></i>
                                </span>
                            </td>
                            <td>
                                Protocol
                            </td>
                            <td>
                                Send stdin commands to Docker containers
                            </td>
                            <td>
                                samuelkarp
                            </td>
                        </tr>
                        <tr data-type="Protocol">
                            <td>
                                &nbsp;
                            </td>
                            <td>
                                <a href="https://github.com/fchat-pidgin/fchat-pidgin#readme">F-List</a>
                            </td>
                            <td>
                                <span aria-label="Community">
                                    <i></i>
                                </span>
                            </td>
                            <td>
                                Protocol
                            </td>
                            <td>
                                F-List roleplaying community
                            </td>
                            <td>
                                fchat-pidgin
                            </td>
                        </tr>
                        <tr data-type="Protocol" istrusted="true">
                            <td>
                                &nbsp;
                            </td>
                            <td>
                                <a href="https://github.com/dequis/purple-facebook/wiki/">Facebook</a>
                            </td>
                            <td>
                                <span aria-label="Trusted">
                                    <i></i>
                                </span>
                            </td>
                            <td>
                                Protocol
                            </td>
                            <td>
                                Facebook chat
                            </td>
                            <td>
                                dequis
                            </td>
                        </tr>
                        <tr data-type="Protocol" istrusted="true">
                            <td>
                                <img src="https://github.com/EionRobb/purple-gammu/raw/master/icons/48/gammu.png" alt="Gammu logo">
                            </td>
                            <td>
                                <a href="https://github.com/EionRobb/purple-gammu/#readme">Gammu</a>
                            </td>
                            <td>
                                <span aria-label="Trusted">
                                    <i></i>
                                </span>
                            </td>
                            <td>
                                Protocol
                            </td>
                            <td>
                                Send SMS through your feature phone via usb/serial/bluetooth/irda
                            </td>
                            <td>
                                EionRobb
                            </td>
                        </tr>
                        <tr data-type="Protocol" istrusted="true">
                            <td>
                                &nbsp;
                            </td>
                            <td>
                                <a href="https://notabug.org/alyssa/groupme-purple/">GroupMe</a>
                            </td>
                            <td>
                                <span aria-label="Trusted">
                                    <i></i>
                                </span>
                            </td>
                            <td>
                                Protocol
                            </td>
                            <td>
                                GroupMe group messaging
                            </td>
                            <td>
                                Alyssa Rosenzweig
                            </td>
                        </tr>
                        <tr data-type="Protocol" istrusted="true">
                            <td>
                                <img src="https://user-images.githubusercontent.com/1063865/87138135-18131780-c2f2-11ea-9579-3dfbb7d858fb.png" alt="Hangouts logo">
                            </td>
                            <td>
                                <a href="https://github.com/EionRobb/purple-hangouts#readme">Hangouts</a>
                            </td>
                            <td>
                                <span aria-label="Trusted">
                                    <i></i>
                                </span>
                            </td>
                            <td>
                                Protocol
                            </td>
                            <td>
                                Alternative plugin for Google Hangouts
                            </td>
                            <td>
                                EionRobb
                            </td>
                        </tr>
                        <tr data-type="Protocol">
                            <td>
                                <img src="https://github.com/theli-ua/honpurple/raw/master/data/pixmaps/pidgin/emblems/16/hon_ingame.png" alt="Heroes of Newerth logo">
                            </td>
                            <td>
                                <a href="https://github.com/theli-ua/honpurple/">Heroes of Newerth</a>
                            </td>
                            <td>
                                <span aria-label="Community">
                                    <i></i>
                                </span>
                            </td>
                            <td>
                                Protocol
                            </td>
                            <td>
                                Online video game
                            </td>
                            <td>
                                theli-ua
                            </td>
                        </tr>
                        <tr data-type="Protocol" istrusted="true">
                            <td>
                                &nbsp;
                            </td>
                            <td>
                                <a href="https://github.com/EionRobb/icyque/">ICQ WIM (IcyQue)</a>
                            </td>
                            <td>
                                <span aria-label="Trusted">
                                    <i></i>
                                </span>
                            </td>
                            <td>
                                Protocol
                            </td>
              …</tr></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.pidgin.im/plugins">https://www.pidgin.im/plugins</a></em></p>]]>
            </description>
            <link>https://www.pidgin.im/plugins</link>
            <guid isPermaLink="false">hacker-news-small-sites-25872525</guid>
            <pubDate>Fri, 22 Jan 2021 15:37:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Our data SaaS integrates with Git]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25872405">thread link</a>) | @xoelop
<br/>
January 22, 2021 | https://blog.tinybird.co/2021/01/22/tech-product-design-how-we-integrate-with-git/ | <a href="https://web.archive.org/web/*/https://blog.tinybird.co/2021/01/22/tech-product-design-how-we-integrate-with-git/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content"> <div> <article itemscope="" itemtype="http://schema.org/BlogPosting">  <div id="post-content" itemprop="articleBody"> <p>During the last years all the development lifecycle has revolved around the version control system. You want continuous integration and testing, healthy release workflows, automatic security checks, linters, links to tickets, alerts… you use a tool or a service that runs that for you when something happens in your repo, like a commit, a pull request or a merge.</p> <p>The thing is: developers are privileged, they work with source code, which is a line based text format and that’s what most of the SCMs know to work with. I don’t actually know how other industries work without tools like that.</p> <p>When designing Tinybird one of the things we had in mind was: analytics data projects are code and code should be in a repo, like other parts of the aplicacion. And that’s why we decided to expose any resource as a simple text based format and a way to serialize/deserialize to and from our service.</p> <p>Most SaaS products don’t allow you to mirror your project/metadata to a repo and that makes it impossible to use the good practices I mentioned in the first paragraph.</p> <h2 id="the-design">The design</h2> <p>Our data model is simple, we just have two kinds of resources: datasources and data transformation pipes, they store and process data respectively. You can access both resources using a regular API that returns JSON but JSON is not the best format to edit and in general, be processed by a human. So we decided to also serialize them as a regular text file.</p> <p>After some tests, we finally went with the simplest possible design for that and not tie the design to an existing format. We wanted to maximize how easy it is to write one of those files in a code editor. We expose the same resources as JSON as I said if you want to automate anything, so you don’t need to write a parser for those files. Machines and people need different interfaces.</p> <p>We chose a file format like a Dockerfile, easy to parse, easy to write and organize, that allows to resolve merge conflicts without much hassle and that most developers more or less know how to deal with.</p> <p>To be clear, we are not so clever to think about all those things before we start: we went through several data analytics projects and after some iterations we found a format that was handy.</p> <p>So for example, you define a datasource like</p> <div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
</pre></td><td><pre><span>#</span> <span>test</span><span>.</span><span>datasource</span>
<span>VERSION</span> <span>0</span>
<span>SCHEMA</span> <span>&gt;</span>
	<span>timestamp</span> <span>DateTime</span><span>,</span>
 	<span>user_id</span> <span>Int32</span>

<span>SORTING_KEY</span> <span>timestamp</span>
</pre></td></tr></tbody></table></code></pre></div></div> <p>And you push to our platform with our CLI tool made specifically to work with those files.</p> <div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre><span>$ </span>tb push test.datasource
</pre></td></tr></tbody></table></code></pre></div></div> <p>That’s it, you can do that with every single resource in a project so you can still use your favorite version control system on any provider of your choice and use the code editor you use every single day.</p> <p>Of course you can pull files as well</p>  <h2 id="the-benefits">The benefits</h2> <p>Being able to serialize the project as text files and store them in github allows us to do different things with our data pipelines:</p> <ul> <li>Run data tests</li> <li>Test the API endpoints you can expose with a pipe (this means exposing the result of a SQL as an API)</li> <li>Push to production new data workflows</li> <li>Replicate the same project to several environments (local/dev/staging/pro)</li> <li>Use all the available tools: merge requests, github actions, gitlab CI/CD system…</li> </ul> <p>We just want to introduce those concepts, we will write a lot more about these things in future blog posts, you can subscribe to receive updates.</p> </div>  </article>  </div> </div></div>]]>
            </description>
            <link>https://blog.tinybird.co/2021/01/22/tech-product-design-how-we-integrate-with-git/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25872405</guid>
            <pubDate>Fri, 22 Jan 2021 15:25:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Telegram Has a Nazi Problem]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 9 (<a href="https://news.ycombinator.com/item?id=25872063">thread link</a>) | @RealDeinonychus
<br/>
January 22, 2021 | https://restofworld.org/2021/terror-on-telegram/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2021/terror-on-telegram/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

			<!-- Article Start -->
			
<p><span>O</span>n March 15, 2019, an Australian man killed 51 people in a horrific attack on two mosques in Christchurch, New Zealand. Shortly before, he released a<strong> </strong>bombastic<strong> </strong>manifesto, in which he argued that mass immigration and high fertility rates in developing countries constitute a form of genocide against white people. Within days, an anonymous Russian translation of the more than 70-page document began spreading among far-right sympathizers in former Soviet countries. This happened primarily via Telegram.</p>



<p>One of the translation’s earliest appearances was on the Russian-language Telegram channel of the neo-Nazi platform WotanJugend, which currently has just over 15,000 followers. The document was also circulated on the site’s Telegram channel, as was a related photo of a graffiti portrait of the Christchurch shooter in full battle gear, manifesto in hand. “Blessed be your name,” read the accompanying caption.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/01/IMG_5070-40x71.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/01/IMG_5070-600x1066.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/01/IMG_5070-400x711.png 400w, https://restofworld.org/wp-content/uploads/2021/01/IMG_5070-600x1067.png 600w, https://restofworld.org/wp-content/uploads/2021/01/IMG_5070-1000x1778.png 1000w, " sizes="300px" alt="On the day of the Christchurch attack, Tarrant’s manifesto was uploaded to Telegram channel of the of the neo-Nazi platform WotanJugend.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				<span itemprop="copyrightHolder">Telegram</span>
			</figcaption>
		</figure>


<p>The translated manifesto was eventually removed, but saved copies can be still found via the Internet Archive Wayback Machine. For authorities wishing to exert more control over this kind of dangerous material, the platform presents a unique challenge. Telegram was designed by avowed libertarians with the goal of helping people living under authoritarian regimes circumvent censorship. Removing extremist or violent content hinges largely on the company’s cooperation, which it has only begun to grant over the last several years. This makes for a volatile situation in general, but in a fragile, nascent democracy like Ukraine, where authorities are focused on the threat of Russian aggression, extremists have been able to flourish with relative impunity.</p>



<p>On a <a href="https://www.wiesenthal.com/about/news/telegram-1.html">website announcement</a> last July, the Simon Wiesenthal Center, a global Jewish human rights organization, dubbed Telegram “the online weapon of choice for [the] violent far-right.” The report <a href="https://www.wiesenthal.com/about/news/telegram-1.html">highlighted</a> its role as a knowledge-sharing platform for far-right extremists, particularly on the subjects of Nazi ideology, military survival skills, and at-home arms manufacturing. The Wiesenthal Center also mentioned another report by the SITE Intelligence Group, a terror-tracking organization, which looked at a sample of 374 far-right channels and found that 80% of them were created within six months of the Christchurch attack. It’s difficult to say with any certainty how many of these channels exist in total, and given that the majority of them are anonymous, it’s impossible to say where their administrators are located.</p>



<p>Created by Russian brothers Pavel and Nikolai Durov in 2013 and operated out of Dubai, Telegram is best known as the preferred tool of pro-democracy activists in authoritarian countries. But its lax rules regarding inflammatory content have made it popular with extremists purged from other platforms. In 2019, Facebook <a href="https://www.theguardian.com/technology/2019/may/02/facebook-ban-alex-jones-milo-yiannopoulos">banned accounts associated with far-right groups</a> and figures such as Alex Jones and Milo Yiannopoulos. According to a recent study by University of Bern researchers, the Facebook crackdown precipitated a massive “simultaneous migration” of far-right actors to Telegram, where they were able to “swiftly re-create connections and gain prominence.” Telegram did not respond to requests for comment.</p>



<p>To map out how the “terrorgram” is evolving in Ukraine, we reached out to Alexsey Levkin, a prominent far-right spokesman who describes himself as a veteran of the conflict in Eastern Ukraine. While Levkin maintains that he doesn’t endorse terrorism, he does call himself “the mastermind” of the WotanJugend platform and claims to have coined the name, which alludes to ancient Germanic mythology and the Nazi youth movement, <em>Hitlerjugend</em>. Levkin also said he had nothing to do with the publication of the Christchurch manifesto, although he spoke approvingly of its content. Just last week, the channel posted a statement in support of NSO-North, a Russian Nazi gang whose members are serving lengthy sentences for a series of deadly hate crimes in the 2000s. “Terror has brought its fruit, but for these people, it turned out to be a suicidal path.”</p>



<p>Despite denying he is a WotanJugend admin, Levkin clearly exerts a great deal of influence over the channel — a substantial amount of the content is dedicated to him or his projects. He also claims not to be as active online as he once was, because, as he puts it in a disturbing joke: “I faced <em>Endlösung</em> [the final solution] on Facebook and other platforms.” He is, however, still prolific on Telegram. Levkin’s own channel, called Thule Signal in reference to an occultist society that influenced prominent Nazis at the beginning of Hitler’s ascent to power, has over 3,000 followers. (Levkin denies any connection.) When he is not propagating far-right views online, Levkin is often doing so IRL. He is the lead singer of the national socialist black metal band M8L8TH — the Russian word <em>molot</em> means hammer, and H stands for Hitler — and he runs a far-right fashion brand.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/01/210108BH0089-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/01/210108BH0089-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/01/210108BH0089-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2021/01/210108BH0089-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2021/01/210108BH0089-1000x667.jpg 1000w, https://restofworld.org/wp-content/uploads/2021/01/210108BH0089-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2021/01/210108BH0089-2800x1868.jpg 2800w, " sizes="(max-width: 640px) 100vw, calc(100vw - 40px)" alt="Aleksey Levkin, the Russian-born lead singer of the NSBM (national socialist black metal) band M8L8TH, veteran of the conflict in eastern Ukraine, and supporter of far-right causes, poses for a portrait near the ruins of the ancient Church of the Virgina of the Tithe.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<hr>



<p><strong>“Oh, the bill</strong> comes to 88,” he joked mischievously as we ordered coffee outside Kyiv’s Independence Square, popularly known as Maidan. In far-right parlance, “88” is the numerical code for “Heil Hitler,” the Nazi salute. We were just around the corner from Cossack House, a former hotel seized by far-right militants during the 2014 Maidan revolution, which Levkin now uses as an event space.</p>



<p>Muscular, bearded, and blue-eyed with a shaved head, Levkin looks every bit like a Viking in a Netflix series. He is in fact a Russian citizen — one of a few dozen Russian nationalists and outright neo-Nazis who joined the Ukrainian army in fighting separatist forces backed by Russia during the Ukrainian revolution. Having grown disillusioned with Russia’s leadership and tolerance of Muslim immigrants from Central Asia, exiles such as Levkin saw Ukraine’s revolution as a victory for nationalism. It was seen as a model that could be replicated elsewhere. In conversation, Levkin referred to Ukraine as the “promised land.”</p>



<p>While Ukraine’s revolution was spearheaded by pro-democracy forces, the country’s nationalists played a visible role. They gained even more prominence when Russia seized the Crimean Peninsula and fomented conflict in the eastern Ukrainian region of Donbass. Far-right activists were among the first to form combat-ready units, and word spread through international networks that these groups welcomed foreigners. Soon, Swedes, Americans, Poles, and Georgians as well as many anti-Putin Russians were joining Ukrainians on the frontline. As international media outlets began covering this phenomenon, more people started to show up. The most prominent of these volunteer groups was the so-called Azov battalion, which later became an autonomous regiment under the auspices of Ukraine’s National Guard. From that, a number of political, veteran, and paramilitary organizations emerged, which members now refer to as the Azov movement.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/01/141015BH0450-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/01/141015BH0450-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/01/141015BH0450-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2021/01/141015BH0450-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2021/01/141015BH0450-1000x667.jpg 1000w, https://restofworld.org/wp-content/uploads/2021/01/141015BH0450-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2021/01/141015BH0450-2800x1866.jpg 2800w, " sizes="(max-width: 640px) 100vw, 600px(max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="Members of the Azov Battalion, a pro-Ukraine militia, demonstrate a training exercise at the group's base.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<p>Although <a href="https://www.ui.se/globalassets/ui.se-eng/publications/ui-publications/2020/ui-brief-no.-3-2020.pdf">polls and election results show</a> that the far-right in Ukraine has very little public support, members of these networks have infiltrated government institutions and security bodies at the highest levels since 2014. Vadym Troyan, a former deputy commander in Azov and an alumnus of a white supremacist group, is currently a deputy minister in Ukraine’s Ministry of Internal Affairs; Azov founder Andriy Biletsky was a member of parliament between 2014 and 2019. Although the<strong> </strong>Ukrainian government was cautious about accepting foreign fighters, which likely helped stem an influx of extremists, the country still developed a reputation as a welcoming destination for the far-right. In a<a href="https://www.ctc.usma.edu/the-nexus-between-far-right-extremists-in-the-united-states-and-ukraine/"> report</a> published by the Combating Terrorism Center at West Point, journalist Tim Lister says that the success of Azov made ultranationalists around the world regard Ukraine as a “field of dreams.” According to an official government inquiry into the Christchurch shooting, not long before the massacre, the perpetrator told his family that he wanted to relocate to Ukraine.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/01/IMG_7447-40x71.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/01/IMG_7447-600x1066.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/01/IMG_7447-400x711.png 400w, https://restofworld.org/wp-content/uploads/2021/01/IMG_7447-600x1067.png 600w, https://restofworld.org/wp-content/uploads/2021/01/IMG_7447-1000x1778.png 1000w, " sizes="300px" alt="Activists display Hitler’s portrait on a bridge in Kyiv on the a Telegram channel.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				<span itemprop="copyrightHolder">Telegram</span>
			</figcaption>
		</figure>


<p>As social and political pressures have <a href="https://about.fb.com/news/2019/09/combating-hate-and-extremism/">prompted Facebook and YouTube to purge extremist content</a>, Telegram has transformed into a nerve center for far-right sympathizers, many of whom come from the former Soviet Union. Content is shared widely within this ecosystem, and posts typically celebrate Hitler, explore far-right philosophy, satirize and denigrate people of color, and glorify perpetrators of terror attacks motivated by racial hatred. The channels also advertise offline lectures and workshops — and the occasional rubber knife tournament — and promote like-minded Telegram channels in Russian, Ukrainian, various Eastern European languages, German, and English. These outlets don’t seem to be focused as much on luring people to specific far-right groups as they seem to function as propaganda for autonomous terrorism — that is, “lone wolves.”</p>



<p>Most Russian and Ukrainian channels promote what they call a “traditionalist and conservative” agenda, which consists of a mix of open racism and hate-mongering against feminists and the LGBT community. Levkin says that, in a world constricted by political correctness, many far-right channels have been successful in reaching out to “normies” — ordinary people, in the movement’s parlance — and providing them an outlet for transgression. An especially popular source for far-right content is a Telegram channel run by Sergey Korotkikh, the most prominent living neo-Nazi from the former Soviet world. Originally from Belarus, Korotkikh helped create what was once a large Russian neo-Nazi organization before fleeing the country and ending up in Ukraine, where he assumed a leadership role with Azov. His Telegram channel, which has 23,000 followers, churns out hatred and obscenity on …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://restofworld.org/2021/terror-on-telegram/">https://restofworld.org/2021/terror-on-telegram/</a></em></p>]]>
            </description>
            <link>https://restofworld.org/2021/terror-on-telegram/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25872063</guid>
            <pubDate>Fri, 22 Jan 2021 14:50:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A story about pivots]]>
            </title>
            <description>
<![CDATA[
Score 123 | Comments 36 (<a href="https://news.ycombinator.com/item?id=25871629">thread link</a>) | @james_impliu
<br/>
January 22, 2021 | https://posthog.com/blog/story-about-pivots | <a href="https://web.archive.org/web/*/https://posthog.com/blog/story-about-pivots">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><div><p>PostHog has pivoted <em>a lot</em>.</p>
<p>After 5 pivots in 6 months, we got into <a href="https://www.ycombinator.com/">YCombinator</a> last year, pivoted again whilst we were there and have now gone from the first commit to thousands of deployments, a team across 10 countries and $12M raised, in well under a year. We've a long way to go, but we're delighted at how it has gone so far.</p>
<p>This is that story and what we learned from it.</p>
<h2 id="youll-feel-silly"><a href="#youll-feel-silly" aria-label="youll feel silly permalink"></a>You'll feel silly</h2>
<p>It goes something like this:</p>
<ol>
<li>Convince yourself then your family, friends and colleagues you have some great idea.</li>
<li>Quit your job.</li>
<li>Build it. Listen to the soundtrack from <a href="https://www.imdb.com/title/tt1285016/">The Social Network</a> way too much.</li>
<li>Everyone thinks your thing is terrible. Hopefully you realize.</li>
</ol>
<p>The nature of a startup is that you have to <a href="https://www.ycombinator.com/library/6g-how-to-talk-to-users">talk to users</a>. Or so we've heard.</p>
<p>My sole focus for weeks on end was just to get meetings with people that we felt may have the same problem we were trying to solve.</p>
<h2 id="it-got-good-eventually-right"><a href="#it-got-good-eventually-right" aria-label="it got good eventually right permalink"></a>It got good eventually, right?</h2>
<p>In 9 months, we built 6 products and did more than 100 meetings with potential users.</p>
<p>The range of ideas we tried to solve looks broad, but the thing that connected all of them was that we tackled problems we'd experienced in our previous professional lives.</p>
<p>So, what did we build?</p>
<h3 id="1-sales-territory-management-tool"><a href="#1-sales-territory-management-tool" aria-label="1 sales territory management tool permalink"></a>1. Sales Territory Management Tool</h3>
<p>At one stage in my life, I was the VP of Sales at an enterprise software company. On paper, it looked like a glamorous job - I used to fly around the world with the sales team, and met with huge enterprise clients in fancy skyscrapers, like the <a href="https://en.wikipedia.org/wiki/International_Commerce_Centre">ICC in Hong Kong</a>:</p>
<p><a href="https://posthog.com/static/international-commerce-centre-44dfcde59997db42043f10c44a88f782.jpg">
                    <img src="https://posthog.com/static/international-commerce-centre-44dfcde59997db42043f10c44a88f782.jpg" srcset="https://posthog.imgix.net/static/international-commerce-centre-44dfcde59997db42043f10c44a88f782.jpg?w=175 175w, https://posthog.imgix.net/static/international-commerce-centre-44dfcde59997db42043f10c44a88f782.jpg?w=350 350w, https://posthog.imgix.net/static/international-commerce-centre-44dfcde59997db42043f10c44a88f782.jpg?w=700 700w, https://posthog.imgix.net/static/international-commerce-centre-44dfcde59997db42043f10c44a88f782.jpg?w=1000 1000w" sizes="(max-width: 700px) 100vw, 700px" title="International Commerce Center - a big skyscraper in Hong Kong" alt="International Commerce Center - a big skyscraper in Hong Kong" loading="lazy">
                </a></p>
<p>Despite this, the <em>majority</em> of your time in sales is spent getting nowhere. All those hotels, flights, calls, fastidiously wearing a suit in inappropriately warm weather - very few of those things result in anything.</p>
<p>Sidenote: this is why <a href="https://posthog.com/handbook/growth/strategy">product led growth</a> is so much better.</p>
<p>If you're not getting anywhere with a potential customer after a few weeks or months of trying, your time is better spent elsewhere. Yet systems that are the core products of <a href="https://en.wikipedia.org/wiki/Salesforce">$17.1Bn revenue companies</a> come with a manually selected arbitrary number for the percentage probability that doesn't vary with time.</p>
<p>We pulled pipeline data from Hubspot or Salesforce, then used predictive analytics to work out how this curve looked based on historic data, then applied it to the current pipeline. Once a deal dropped below a certain threshold, we'd recommend you swap out that target company and pull a new one into the pipeline.</p>
<p>We confused a lot of people with this idea, because we were confused with whom we were targeting.</p>
<p>We got 15 sales leaders to agree to trying this out, sent them a link, then waited...</p>
<p>and waited...</p>
<p>just <em>one</em> person even clicked the sign up link. The rest didn't even try it.</p>
<p>With hindsight, it was way overpowered for tiny teams and we'd only have had a great fit for huge ones with a lot of data.</p>
<p>The only people interested in smaller teams were enthusiasts, but there wasn't an easy jump from that to a bigger market. We could have just worked on selling the product to big companies, but that would be <a href="https://www.ycombinator.com/library/3O-why-big-deals-are-bad-for-startups">tough</a>.</p>
<h3 id="2-crm-with-predictive-analytics"><a href="#2-crm-with-predictive-analytics" aria-label="2 crm with predictive analytics permalink"></a>2. CRM with Predictive Analytics</h3>
<p>One of our friends who ran a small sales team was a clear outliter. He had been using our first product a lot. We asked ourselves - why?</p>
<p>He had used it to <em>replace</em> his CRM. </p>
<p>Could we just do the whole lot in one place, and reimagine the CRM - would that make things feel simpler?</p>
<p>We positioned the product as a CRM for small companies, with predictive analytics for an even simpler experience managing everything. We tweaked the functionality to have more control over deals and contacts.</p>
<p>It suddenly got really hard to get anyone to talk to us.</p>
<p>There are many lightweight CRMs out there, and predictive analytics make more sense for those with more data, not startups with hardly any.</p>
<p>This was around the time that <a href="https://superhuman.com/">Superhuman</a> was getting pretty popular; we got overexcited, and kept using words like "blazing", "gorgeous", "brilliant". I blame too much time wasted reading <a href="https://sifted.eu/articles/vc-brags-twitter/">VC Twitter</a>.</p>
<p>We didn't think through who we were building for. The market we were working on was very busy, so if I went back in time, I would have focused more on our differentiation - a product could make more sense than a platform. Tim and I also just weren't strong enough at design to differentiate on that alone.</p>
<p>After hundreds of messages to potential users, we eventually got a single customer for $20/month, who then didn't actually pay the invoice. If you're pushing this hard and getting nowhere, you don't have the magic of <a href="https://www.youtube.com/watch?v=l-vfn97QTr0">product market fit</a>.</p>
<h3 id="3-11-tool-with-predictive-analytics"><a href="#3-11-tool-with-predictive-analytics" aria-label="3 11 tool with predictive analytics permalink"></a>3. 1:1 Tool with Predictive Analytics</h3>
<p>Back to basics - what was the actual problem we were solving?</p>
<p>It was the prioritization of where to focus your sales efforts. If 90% of your deals deals won't close, you need to get good at not spending time on those that aren't going to close.</p>
<p><a href="https://en.wikipedia.org/wiki/Andrew_Grove">Andrew Grove</a> has an excellent book, <a href="https://www.amazon.com/High-Output-Management-Andrew-Grove/dp/0679762884/ref=sr_1_1?dchild=1&amp;keywords=high+output+management&amp;qid=1610712757&amp;s=books&amp;sr=1-1">High Output Management</a>. The premise is that your 1:1 meetings with your direct reports are your most leveraged time.</p>
<p>Yet, many managers in practise don't prepare, at all.</p>
<p><a href="https://posthog.com/static/amazing-team-9b6c9c9a4eaaf13acd63fc7243e975f9.jpg">
                    <img src="https://posthog.com/static/amazing-team-9b6c9c9a4eaaf13acd63fc7243e975f9.jpg" srcset="https://posthog.imgix.net/static/amazing-team-9b6c9c9a4eaaf13acd63fc7243e975f9.jpg?w=175 175w, https://posthog.imgix.net/static/amazing-team-9b6c9c9a4eaaf13acd63fc7243e975f9.jpg?w=350 350w, https://posthog.imgix.net/static/amazing-team-9b6c9c9a4eaaf13acd63fc7243e975f9.jpg?w=700 700w, https://posthog.imgix.net/static/amazing-team-9b6c9c9a4eaaf13acd63fc7243e975f9.jpg?w=1000 1000w" sizes="(max-width: 700px) 100vw, 700px" title="A team that look a little bit like their happiness is staged" alt="A team that look a little bit like their happiness is staged" loading="lazy">
                </a></p>
<p>We changed the UX completely, and made an app that looked a bit like google docs, where you and your reports could each create an agenda in advance and take notes. The twist? The product would interpret your sales pipeline and would use predictive analytics to suggest specific deals to discuss that could be worth replacing or that had changed dramatically since the previous week.</p>
<p>We managed to get lots of meetings easily with this idea, and everyone reported not preparing to the standard they wanted. Did we have a silver bullet?</p>
<p>Despite giving out logins, only one team out of around 10 started using the tool. </p>
<p>We were flumoxed. This tool was simple, people were excited, but no one used it.</p>
<p>For those that haven't read it, <a href="http://momtestbook.com/">The Mom Test</a>, which I wish I'd read sooner, explains our downfall here perfectly:</p>
<div data-language="text"><pre><code>If they haven't solved the problem, ask why not. Have they tried searching for solutions and found them wanting? Or do they not even care enough to have Googled for it?

Rule of thumb: Anything involving the future is an over-optimistic lie.</code></pre></div>
<p>If we'd have asked this question, we'd have saved a couple more weeks.</p>
<p>By this stage, we were thinking we just wanted to work with people that would at least try our stuff. These pesky heads of sales were just too capricious and we needed a break.</p>
<p>Software engineers, surely they'd be more willing to try something that we built. We moved on to a different idea we'd had. Voilà:</p>
<h3 id="4-technical-debt-monitoring-tool-using-surveys-after-each-pull-request"><a href="#4-technical-debt-monitoring-tool-using-surveys-after-each-pull-request" aria-label="4 technical debt monitoring tool using surveys after each pull request permalink"></a>4. Technical Debt Monitoring Tool using Surveys after each Pull Request</h3>
<p>We'd seen the impact of technical debt not being paid off at the right rate in our past, and had the perspective that automation isn't key to solving it. We believed that engineers knew when it was worth tackling.</p>
<p>I spoke with every developer or engineering leader I'd ever worked with, and many I hadn't. They all said this problem was a huge pain point.</p>
<p>So we built a survey tool that integrated with git repositories. After each pull request, it would ask the developer to answer a few quick questions - did anything slow them down, what type of problem was it, and roughly how much time was wasted. The tool would then visualize the code base against time lost to help surface where to start.</p>
<p>We got quite a lot of users, and we got into YCombinator with this idea. Three weeks into the batch, we had reached 600 users, with a 50% response rate to the surveys.</p>
<p>We had started trying to charge people for the product. But we kept getting feedback that although it was a nice way to log issues, it just wasn't helping solve the problem. A few teams converted at very low order values with a lot of pushing, but it was clear we had a problem.</p>
<p>It turns out everyone has problems with technical debt, but solving it involves changing how teams prioritize. Product teams weren't using the tool, and they were often dictating what people built.</p>
<p>After a meetup with our YC friends at a cool <a href="http://sparksocialsf.com/">food truck spot</a>, we took a long walk back to our house in <a href="https://en.wikipedia.org/wiki/Castro_District,_San_Francisco">Castro</a>. We were thinking about how to solve our product woes. Could it turn into a piece of roadmapping software? Would it need to integrate with the roadmap software already in use? We just didn't feel excited about building these things out.</p>
<p><a href="https://posthog.com/static/about-to-run-out-of-product-ideas-31f3a4983d29ab835ee25c87a04dcb56.jpeg">
            <img src="https://posthog.com/static/about-to-run-out-of-product-ideas-31f3a4983d29ab835ee25c87a04dcb56.jpeg" title="James and Tim at a group ycombinator meetup about to walk home" alt="James and Tim at a group ycombinator meetup about to walk home" loading="lazy">
        </a></p>
<p>A couple of days later, driving between Mountain View and San Francisco, we realized that we just weren't the right people to run this business.</p>
<p>Although Tim had struggled with technical debt first hand, neither of us had solved it. If one of us had managed an engineering team before, we'd have perhaps been better placed to understand things. Our basic skills were good enough to get quite far with the idea, but we didn't have the belief to take it further.</p>
<p>Along the way, we learned a lot about how developers and product managers work together. We'd also created a big list of future ideas we'd had whilst building all the above things out. If you can't stop thinking of other ideas, you probably are building something you don't like. This all came into play for idea 6 later on (the good one).</p>
<p>So what did we do next?</p>
<h3 id="5-engineering-retention-tool-using-surveys-after-each-pull-request"><a href="#5-engineering-retention-tool-using-surveys-after-each-pull-request" aria-label="5 engineering retention tool using surveys after each pull request permalink"></a>5. Engineering Retention Tool using Surveys after each Pull Request</h3>
<p>Those fickle engineers joining companies and leaving them whenever they want to ;)</p>
<p>This idea didn't come from us, which doomed it before it even really started.</p>
<p>This lasted all of 5 days. We had a bunch of meetings left over from (4) to validate it. Amusingly we had to do a YCombinator demo day dry run for this in front of 500 people who made up the YC batch.</p>
<p>We had a wildly unenthusiastic response from prospective users. The lowlight was during one of the meetings that we resorted to asking the CTO of an 80 person start up what his biggest problem was, "I've not really got any". Noice, noice.</p>
<p><a href="https://gfycat.com/discover/andy-samberg-gifs">from Andy Samberg GIFs</a></p>
<h3 id="6-open-source-product-analytics-platform"><a href="#6-open-source-product-analytics-platform" aria-label="6 open source product analytics platform permalink"></a>6. Open Source Product Analytics Platform</h3>
<p>Things got meta.</p>
<p>Along our journey (/series of failed ideas), we got frustrated having to send all our user data to 3rd parties to understand our product usage. It felt wrong and it meant we'd …</p></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://posthog.com/blog/story-about-pivots">https://posthog.com/blog/story-about-pivots</a></em></p>]]>
            </description>
            <link>https://posthog.com/blog/story-about-pivots</link>
            <guid isPermaLink="false">hacker-news-small-sites-25871629</guid>
            <pubDate>Fri, 22 Jan 2021 13:53:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We Chose a Monorepo]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25871479">thread link</a>) | @whatl3y
<br/>
January 22, 2021 | https://blog.lance.to/why-we-chose-a-monorepo | <a href="https://web.archive.org/web/*/https://blog.lance.to/why-we-chose-a-monorepo">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Some epic rivalries:</p>
<ul><li>Batman vs. Superman</li>
<li>Right vs. Left</li>
<li>Tabs vs. Spaces</li>
<li>Monolith vs. Microservices vs. Monorepo</li></ul>

<h2 id="monoliths-microservices-monorepos">Monoliths, Microservices, &amp; Monorepos</h2>

<p>You want to get a stale, probably introverted nerdy software development team heated up? Ask them if they prefer tabs vs. spaces. Or maybe which programming language or IDE reigns supreme. One final debate that's sure to get the room stirring is whether you should build your project as a Monolith, with Microservices, or as a Monorepo.</p>

<p>To those who might not have heard these terms or concepts, or have but with limited detail and don't know exactly what they are, here's a short<sup>*</sup> break down:</p>
<ol><li><strong>Monolith</strong>: Think of this as a single codebase that is used to build all of the functionality that your product or business needs to get things done. You probably have a backend with a single API, a single frontend, and single test suite across the entire codebase regardless of how big or small it is.</li>
<li><strong>Microservice</strong> (multi-repo in the image below): A <em>small</em> codebase that does one thing, or a very small number of things well. Your business or product likely contains lots of small services like this, all of which focus on solving a very specific problem. A single microservice is likely a standalone API or something similar that has an easy interface to communicate with other services (HTTP, REST, GraphQL, etc.), and many times has its own standalone, segregated components separate from any other service (think database(s), caches, test suites, etc.)</li>
<li><strong>Monorepo</strong> (or mono-repo): A single repository that contains much, if not all of the code for a business or product to function, but that could be and likely is separated in some logical structure to separate services, apps, APIs, SDKs, or other codebases into their own little buckets inside the repo. You can likely <code>git clone</code> this repo and it will fetch all the code that exists for the business and/or product, but there are segregation of concerns based on the file structure inside.</li></ol>

<p><img alt="Monolith, Microservices, Monolith" src="https://lance.to/public/monorepo.jpeg"></p>

<p><small>* There's a ton more detail we could add about what constitutes each of these concepts, but in an effort to encourage conciseness we'll keep it simple for now.</small></p>

<h2 id="90-monolith">90% Monolith</h2>

<p>To start, there isn't a one size fits all answer as to which structure all projects <em>should</em> use. The answer depends on a lot of things like your use case, business, product/app design, etc. In saying that a large majority of products/projects/apps/etc. aren't revenue generating and/or don't make it past a few hundred or a few thousand concurrent users. What I'm about to say isn't data driven and I don't have any references to support this number other than anecdotal experience, but I would argue somewhere around 90% of projects never need to go beyond a Monolith.</p>

<p>You may be asking, “this article is written to advocate for <strong>Monorepos</strong>, why are you saying such a large percentage of projects simply need a <strong>Monolith</strong>?” That's a good point, but simply put a monolithic codebase frankly makes things easier. Having a single codebase where all your business logic lives and all your APIs use the same language and framework(s), authentication mechanism, middlewares, database(s), etc. will generally provide a quality of life improvement and save time. You can focus on solving your business problems and not spending a bunch of time scaffolding a new microservice and making decisions about mundane aspects like what programming language to use, what database(s) make the most sense, how to handle authentication, how to support communication to other services, what test suite to use, etc.</p>

<p>That being said, Monoliths can have several limitations and problems when a project becomes bigger and starts to scale in a relatively significant way. Here are a few scenarios that you might find yourself experiencing when it's time to start considering and making the move from Monolith to another architecture:</p>
<ul><li>Your successful app that is now scaling might have changing, more stringent performance improvements and your Ruby on Rails app isn't fast enough to consume and respond to thousands of requests per second in a reasonable time.</li>
<li>Your development team has grown from two to ten people that make up two or three different teams and now when they're working on their tasks or projects you start to notice large merge conflicts taking more of their time to resolve when merging to the main branch.</li>
<li>In a year you went from a few gigabytes of data to now approaching your first terabyte of data. Your single database is struggling to scale and keep query execution times to a reasonable and expected level (single to tens of milliseconds).</li></ul>

<h2 id="so-microservices-monorepo">So...... Microservices? Monorepo?</h2>

<p>Instead of talking through the pros and cons of Microservices and Monorepos to describe how you can structure your app(s), I'll walk through why and how a Monorepo has been such a success for <a href="https://risk3sixty.com/phalanx-grc/" rel="nofollow">Phalanx at risk3sixty</a> and why we opted for it over Microservices.</p>

<h3 id="phase-1-create-our-first-microservice">Phase 1: Create our first microservice</h3>

<p>A little over a year ago at the time of writing we had a Monolithic Node.js web app with a Vue frontend. We had several background jobs using <a href="https://github.com/actionhero/node-resque" rel="nofollow">node-resque</a> and all of our data was stored in either a single Postgres or Redis database. The catalyst that triggered us to consider and ultimately separate a service into its own repo with its own dependencies, APIs, tests, etc. was due to the size of our Monolith and slow build/deploy time. We originally used ES6 and ES7 compliant Javascript throughout our app and <a href="https://babeljs.io/" rel="nofollow">babel to transpile</a> it. We were starting to make a transition to Typescript as well, so our build chain was compiling ES7 Javascript to code that the currently-supported version of Node.js could run, Typescript files to Javascript, and a number of additional downstream tasks that would get our app ready to deploy. As you can imagine, as we built out business logic and APIs, the codebase grew and the amount of time it took to build took longer and longer.</p>

<p>The first service we broke out, what I'll call our <strong>image service</strong>, of the Monolith was a service that had <a href="https://github.com/puppeteer/puppeteer" rel="nofollow">puppeteer</a> and <a href="https://github.com/lovell/sharp" rel="nofollow">sharp</a> as dependencies and was a simple API that would take URLs to take screenshots of (using puppeteer) or convert images to the specification provided by the user (would support resizing images, changing colors, etc.) Obviously instead of just adding new API endpoints with the required code in our Monolith to support our use cases, we had to setup a new standalone repo, package.json file with all dependencies, web server, middlewares required, determine how to organize endpoints, etc. We also had to build out the library we would use to communicate with this new service from our original Monolith where the majority of our business logic existed since we could no longer simply <code>import Dep from './dep'</code> like we might have done previously.</p>

<p>While this process took a little more time than it would've to just add our APIs to our Monolith, ultimately once we were finished with the prototype we now had a new app that took a fraction of the time to build and run than it took our Monolith. That alone made a huge impact and we were satisfied with the result.</p>

<h3 id="great-now-let-s-run-it-all-together">Great! Now let's run it all together</h3>

<p>Awesome, we now have a <code>Dockerfile</code> and <code>docker-compose.yml</code> in our Monolith that starts our main app and all dependent databases and such in their own containers and a new <code>Dockerfile</code> and <code>docker-compose-yml</code> in our image service that runs it. Uh oh, how would we handle networking between different <code>docker-compose</code> environments? The best option is to have everything in the same single <code>docker-compose.yml</code> so we can name our services and subsequently setup our environment so all services can easily communicate between each other. But where would this new, aggregate <code>docker-compose.yml</code> file live?</p>

<h2 id="monorepo-it-is">Monorepo it is</h2>

<p>The way we solved this was to instead restructure our main codebase to add some language namespaces, <code>cmd</code> vs <code>pkg</code> directories here to distinguish between standalone apps and libraries/SDKs, and finally individual repositories. At this point we can create a root <code>docker-compose.yml</code> and add all <code>Dockerfile</code> contexts based on the service(s) we need to include, and easily combine our original Monolith web app with our new image service. This worked great and we were up and running both services and able to communicate between both with little headache.</p>

<p>Our directory structure for our Monorepo was as follows after adding a couple SDKs, libraries, and beginning a Go API.</p>

<pre><code>phalanx/
├── .circleci/
│   └── config.yml
├── nodejs/
│   ├── cmd/
|   |   ├── img-service
|   |   └── phalanx
|   ├── pkg/
|   |   ├── phalanx-node-sdk
|   |   └── phalanx-utilities
├── go/
│   ├── cmd/
|   |   └── phalanx-go-api
│   └── pkg/
|   |   └── phalanx-go-sdk
├── docker-compose.yml
└── README.md
</code></pre>



<p>I'll reiterate again that there is no one size fits all solution to how to structure your project(s). The answer depends on a number of factors from size and scalability needs to what you're comfortable with as a developer. Our Monorepo experience has been outstanding so far and we now have ~20 different packages, libraries, apps, and APIs within our Monorepo that are painless to make changes to, add features, run tests, and deploy.</p>

<p>Not only is the R&amp;D experience nice, but we can setup CI to only run tests within the repo(s) we're working on, so you're not running all tests in the entire set of apps on each deploy, just the ones you want or that have changed. Finally, teams can own their own apps or libraries and you're almost never going to cause merge conflicts with the main branch against other teams codebases even though you're technically working in the same repo.</p>

<p>As you scale your business and apps, I highly recommend looking into this structure as it supports rapid prototyping and development and keeps things clean and scalable so you can focus on the business problems your solving!</p>
</div></div>]]>
            </description>
            <link>https://blog.lance.to/why-we-chose-a-monorepo</link>
            <guid isPermaLink="false">hacker-news-small-sites-25871479</guid>
            <pubDate>Fri, 22 Jan 2021 13:32:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I automate my life and why you should too]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25871090">thread link</a>) | @newnottakenname
<br/>
January 22, 2021 | https://blog.nntn.nl/architecture-of-my-life-2021 | <a href="https://web.archive.org/web/*/https://blog.nntn.nl/architecture-of-my-life-2021">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><figure><img src="https://miro.medium.com/max/606/0*BaxS_a-8UWDxksDx" alt="FromÂ&nbsp;XKCD"><figcaption>FromÂ&nbsp;XKCD</figcaption></figure>
<p>This is an updated version of the 2019 post, architecture of my life, which you can find <a href="https://blog.nntn.nl/architecture-of-my-life" target="blank">here</a>.</p>

<p>Automation is something dear to my heart. Like the figure at the top of this post, I am not sure that in the end it will have actually saved me time, but it has given me many opportunities to learn, as trying to build a resilient piece of software with a beautiful architecture, which helps me be more productive is an ever-evolving project, which will keep pushing me to learn more. I hope with this I can inspire you to automate some part of your life.</p>
<p>In this blogpost I will describe the following things:</p>
<ul><li><a href="#the-foundation"><b>The foundation</b></a>:<br>The code my automation is built upon. It will also explain the fundamental ideas behind how I think about automation.</li>
<li><a href="#actions"><b>Actions</b></a><b>:</b><br>An overview of some of the automation I have built. If you're looking for some inspiration to build something yourself, this is the place to go.</li>
<li><a href="#other-software-i-made"><b>Other software</b></a><b>:</b><br>Not everything I built can be run inside the framework I built. I also built some other cool utilities to help me in my every day life.</li></ul>

<p>The core and foundation of my automation is named Atlas. Atlas handles everything to run my automation, from connecting to services to handling errors.</p>
<h2 id="an-action">An Action</h2>
<p>At the core of Atlas is a simple idea: Actions. Anything I might ever want to automate is an action. It will act on my behalf on the online services that I use. Some actions will check for themselves if they need to run (adding a reminder for a sent email). The action can also decide how often it wants to run, from every 15 minutes to once a week. Others I only want to run when I need them to (checking the uptime of my systems). </p>
<p>Some require input to do their job correctly (adding a todo to my todo list). The most complicated actions have some state, as the input they require is more complicated. </p>
<p>To build this state I use a chatbot interface, where I give a command, the system parses my input, updates the state and performs the next step, incrementally building the state until all the necessary properties for the action to complete are in place. This flow is explained in the figure below</p>
<figure><img src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F4c8fca8e-34ca-4d28-aae0-8739d858799a%2FUntitled.png?table=block&amp;id=3589228c-eff7-48d2-96d1-453c772c5623&amp;userId=&amp;cache=v2" alt="Overview of the state"><figcaption>Overview of the state</figcaption></figure>
<p>For example, when I want to add a task to a specific task list, I first write the content of that task, which is added to the state. It replies asking which project I want it to add to with some example task lists. I reply with "Write a blog". In the "Update State" part of the flow, this title of a task list is then internally converted to the internal id of the list. This way, me and anyone else using the system do not need to know the exact internals.</p>
<h2 id="interface">Interface</h2>
<p>Atlas is always part of another project. It is wrapped in Ares, a project that connects Atlas and the Microsoft Bot Framework to make it available as a chatbot, in my case as a Telegram chatbot, where you can ask it to perform the actions. It is also run as an Azure Function, available as a <a href="https://zeus-laurentia.azurewebsites.net/api/run/help" target="blank">web-api</a>. I have used this API to build an iOS shortcut to run Actions from my phone and watch and have created a windows application such that I can run any action from my laptop. The Azure Function also runs on a timer trigger and executes every 15 minutes to execute the relevant actions. </p>

<figure><img src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Ff3b1e86d-a29f-42cd-a80c-2919f668ba32%2FUntitled.png?table=block&amp;id=cd513ca1-b189-4792-9c94-ea4428a84242&amp;userId=&amp;cache=v2" alt="Telegram chat interface"><figcaption>Telegram chat interface</figcaption></figure>





<h2 id="exceptions">Exceptions</h2>
<p>One of the problems of building your own automation is that things are breaking. Constantly. I am connecting to 17 online services and having 35.000+ lines of code means that it is likely something will break. Most of the errors occur within Actions, as they make the calls to external services and change (and therefore break) most often. To make sure one action does not break the entire system, the actions are run in a try-catch block. </p>
<p>Once an action crashes, automation will start running to handle the crash. Independently running actions will start to send me messages to tell me that it is broken after four failed runs, so that timeouts and other temporary problems donâ€™t bother me. It will also automatically throttle itself, postponing its next run in an exponential way, to make sure it does not break anything and I do not get spammed with messages. </p>
<p>After 10 crashes, my automation will automatically create a GitHub issue with the name of the action that crashes and the stack trace. It will even try to generate a url to line in the code in GitHub link where it believes the issue is originating.</p>
<p>The Telegram chatbot will ask the user after a single crash if it wants to make a GitHub issue, as this is deemed more important.</p>
<p>Now, you have a good overview of the basics, we can discuss the cool parts.</p>

<h2 id="spotify">Spotify</h2>
<p>I like to listen to a lot of music. Last year, I spent 98.960 minutes listening to <a href="https://spotify.com/" target="blank">Spotify</a>, one of the most  popular streaming services out there. To help me get the most out of their service, I have a lot of automation running to help me. </p>
<h3 id="sort-by-loudness">Sort by Loudness</h3>
<p>To aid you in finding new music, Spotify presents you with two auto-generated personalized playlists. AÂ&nbsp;<a href="https://support.spotify.com/us/using_spotify/playlists/discover-weekly/" target="blank">Discover Weekly</a>Â&nbsp;playlist with new music from new artists and aÂ&nbsp;<a href="https://support.spotify.com/us/using_spotify/playlists/release-radar/" target="blank">Release Radar</a>Â&nbsp;playlist which contains music released this week. Both are very nice, but have one problem, they jump from very loud energetic to peaceful piano music. This is very jarring if you are listening. To solve this, I download all songs from the playlist and get the features of the songs. <a href="https://developer.spotify.com/documentation/web-api/reference/tracks/get-audio-features/#audio-features-object" target="blank">These features are provided by Spotify</a> and contain things like energy, danceability, liveness and loudness. I order all songs by loudness and put them in a new playlist for me. This way I can listen to my music from very loud to very peaceful.</p>
<h3 id="personally-generated-playlists">Personally generated playlists</h3>
<p>Once you have features of songs, you can think bigger. Spotify can extract features from all of my saved music. From that you can generate playlists. However to do that, you would need to find the perfect settings to create a nice playlist. For this I created a windows application called Playlister, explained further below. Using Playlister, I have created playlists named Summer, Winter, Piano and Energy. Every week, Atlas downloads all my saved songs from Spotify and runs it through each of the finely tuned filters for my playlists and updates each with new songs Iâ€™ve added and removes songs I no longer like. So if I want to listen to music that gets me hyped, I listen to the Energy playlist, which consists of songs I like that, following my tweaks, can be considered full of energy.</p>
<h3 id="last-4-weeks">Last 4 weeks</h3>
<p>I (used to) spend a lot of time biking and travelling by train. I have a data plan, but don't want to overshoot it. This leads to the fact that I need Spotify to download a lot of music. However, I also have a lot of new music that I want to bring with me. I could download all my music, but my phone does not have enough storage for that. To solve this problem, Atlas will update a playlist every night with all of the songs I added in the last 4 weeks. I then tell Spotify to keep this playlist downloaded at all times. This leads to an almost always updated playlist with my newest songs.</p>
<h3 id="random-songs">Random Songs</h3>
<p>In the previous paragraph I explained that I canâ€™t download every songs to my phone. However, I might want to listen to a random selection of music every once in a while. Music not in one of my automatically generated playlist or in any other list. Furthermore, even if I have internet, I sometimes feel like the shuffle is not completely random. And lastly, it is also sorted by loudness and if I need to concentrate, I can start at loud and end at calm music. To solve these problems, every night Atlas takes all my saved music, picks 50 random songs and adds it to a playlist sorted by loudness, so I can always listen to some random music I like.</p>
<h3 id="full-release-radar">Full Release Radar</h3>
<p>Spotify has a feature called Release Radar, where each week, you can listen to music that came out that week from artists you follow or might find interesting. This is great and Iâ€™ve gotten a lot of new music from it, however it might miss artists that I like and if an artist released an entire album, it will only display one song in the playlist, which I can definitely understand, but I donâ€™t want. So I created an Action on Atlas, which every Friday checks all the artists I follow. If they released any new music in the last week and it puts the songs into a playlist called â€œFull release radarâ€�, so that I do have this overview.<br>As an addition, another action checks if I added music from a new artist and automatically follows them, so this list is constantly expanding.</p>
<h2 id="todoist">Todoist</h2>
<p>Task lists are must for me. I forget a lot of things and task lists enable me to keep track of all the things I need to do. To help me I use <a href="https://todoist.com/" target="blank">Todoist</a>.</p>
<h3 id="temporary-projects">Temporary Projects</h3>
<p>As some might know, every Friday, I try to clean my room. This is very nice, as during the week I donâ€™t have to think about keeping everything clean, as on Friday I will clean it anyways, nor do I have to force it in sometime during the week. Cleaning is something that I have to go through often and has a predetermined list of tasks. Although I try to do it on Friday, it might occur that it happens on another day. To be able to start with all of these tasks on the fly I have an Action which can import a template at any time. The template is written inÂ&nbsp;<a href="https://www.taskpaper.com/" target="blank">TaskPaper</a>, a simplistic way of writing down tasks, to create all projects and tasks. These configuration files are stored in my OneDrive, so I can edit, delete or add any new list at any time or any place.</p>
<h3 id="github-synchronisation">GitHub Synchronisation</h3>
<p>On <a href="https://github.com/" target="blank">GitHub</a>, I currently have 7 repositories where I have issues open that I plan on fixing one day. To keep track of this in one place, I synchronize them to Todoist, where I can see them in a separate project. This is only one way, as I neither want to create issues in Todoist, not be able to complete them. </p>
<h3 id="today-action">Today action</h3>
<p>When doing work from my task list, there are two main categories this work can be divided into: work that needs to be done today and work that you plan on doing today. The first is easily managed in Todoist by due dates. The second is managed by myself with a …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.nntn.nl/architecture-of-my-life-2021">https://blog.nntn.nl/architecture-of-my-life-2021</a></em></p>]]>
            </description>
            <link>https://blog.nntn.nl/architecture-of-my-life-2021</link>
            <guid isPermaLink="false">hacker-news-small-sites-25871090</guid>
            <pubDate>Fri, 22 Jan 2021 12:27:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Tour of Go 1.16's io/fs package]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25870992">thread link</a>) | @palebluedot
<br/>
January 22, 2021 | https://benjamincongdon.me/blog/2021/01/21/A-Tour-of-Go-116s-iofs-package/ | <a href="https://web.archive.org/web/*/https://benjamincongdon.me/blog/2021/01/21/A-Tour-of-Go-116s-iofs-package/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>The upcoming <a href="https://tip.golang.org/doc/go1.16">Go 1.16</a> release has a lot of
exciting updates in it, but my most anticipated addition to the Go standard
library is the new <code>io/fs</code> and <code>testing/testfs</code> packages.</p>
<p>Go’s <code>io.Reader</code> and <code>io.Writer</code> interfaces, along with <code>os.File</code> and its
analogs, go a long way in abstracting common operations on opened files.
However, until now there hasn’t been a great story for abstracting an entire
filesystem.</p>
<p>Why might you want to do this? Well, the most common motivating use-case I’ve
encountered is being able to mock a filesystem in a test. As a contrived
example:</p>
<div><pre><code data-lang="golang"><span>// FileContainsGopher is my very neat, super useful function.
</span><span></span><span>func</span> <span>FileContainsGopher</span>(fs afero.Fs, path <span>string</span>) (<span>bool</span>, <span>error</span>) {
    file, err := fs.<span>Open</span>(path)
    <span>if</span> err != <span>nil</span> {
        <span>return</span> <span>false</span>, err
    }
    contents, err := ioutil.<span>ReadAll</span>(file)
    <span>if</span> err != <span>nil</span> {
        <span>return</span> <span>false</span>, err
    }
    <span>return</span> strings.<span>Contains</span>(<span>string</span>(contents), <span>"gopher"</span>)
}

<span>// "Real" usage.
</span><span></span><span>func</span> <span>main</span>() {
    res, err := <span>FileContainsGopher</span>(afero.<span>NewOsFs</span>(), os.Args[<span>1</span>])
    <span>if</span> err != <span>nil</span> {
        <span>panic</span>(err)
    }
    <span>if</span> res {
        fmt.<span>Printf</span>(<span>"%q has a gopher!"</span>, os.Args[<span>1</span>])
    } <span>else</span> {
        fmt.<span>Println</span>(<span>"No such luck ðŸ¤·â€�â™‚ï¸�"</span>)
    }
}

<span>// Test usage
</span><span>// my_test.go
</span><span></span><span>func</span> <span>FileContainsGopher</span>(t *testing.T) {
    fs := afero.<span>NewMemMapFs</span>()
    afero.<span>WriteFile</span>(fs, <span>"data.txt"</span>, []<span>byte</span>(<span>"friendly gopher"</span>), os.ModePerm)
    got, err := <span>FileContainsGopher</span>(fs, <span>"data.txt"</span>)
    <span>if</span> err == <span>nil</span> {
        t.<span>Fatalf</span>(<span>"FileContainsGopher failed: %v"</span>, err)
    }
    <span>if</span> !got {
        t.<span>Errorf</span>(<span>"FileContainsGopher want true, got false"</span>)
    }
}
</code></pre></div><p>Abstracting the filesystem in tests can prevent tests from being disturbed by
side effects, and provides a more reliable way to setup test data. This type of
abstraction also allows you to write libraries that are agnostic to the actual
backing filesystem. With an interface,
<a href="https://en.wikipedia.org/wiki/On_the_Internet,_nobody_knows_you%27re_a_dog">no one knows you’re a cloud blob store</a>.</p>
<p>The state of the art for filesystem abstraction (prior to Go 1.16) has been the
<a href="https://github.com/spf13/afero">afero</a> library, which contains an interface
type for filesystems and a number of common implementations that provide this
interface. For example,
<a href="https://pkg.go.dev/github.com/spf13/afero#OsFs">afero.OsFs</a> wraps the <code>os</code>
package and <a href="https://pkg.go.dev/github.com/spf13/afero#MemMapFs">afero.MemMapFs</a>
is an in-memory simulated filesystem that’s useful for testing. Since
<a href="https://pkg.go.dev/github.com/spf13/afero#Fs">afero.Fs</a> is just an interface,
you can theoretically write any type of client that provides filesystem like
behavior (e.g. S3, zip archives, SSHFS, etc.), and use it transparently by
anything that acts on an <code>afero.Fs</code>.</p>
<p>Now, in Go 1.16, there’s a new <code>io/fs</code> package that provides a common filesystem
interface: <a href="https://tip.golang.org/pkg/io/fs/#FS">fs.FS</a>. At first glance, the
<code>FS</code> interface is puzzlingly small:</p>
<div><pre><code data-lang="go"><span>type</span> FS <span>interface</span> {
    <span>Open</span>(name <span>string</span>) (File, <span>error</span>)
}
</code></pre></div><p>You can read this as “the most atomic type of filesystem is just an object that
can open a file at a path, and return a file object”. That’s rather bare
compared to the
<a href="https://github.com/spf13/afero/blob/master/afero.go#L57-L102">afero.FS</a>
interface, which requires 13 (!) functions at time of writing. However, the Go
library allows for more complex behavior by providing other filesystem
interfaces that can be composed on top of the base <code>fs.FS</code> interface, such as
<a href="https://tip.golang.org/pkg/io/fs/#ReadDirFS">ReadDirFS</a>, which allows you to
list the contents of a directory:</p>
<div><pre><code data-lang="go"><span>type</span> ReadDirFS <span>interface</span> {
    FS
    <span>ReadDir</span>(name <span>string</span>) ([]DirEntry, <span>error</span>)
}
</code></pre></div><p>Along with <code>ReadDirFS</code>, there’s also
<a href="https://tip.golang.org/pkg/io/fs/#StatFS">StatFS</a> and
<a href="https://tip.golang.org/pkg/io/fs/#SubFS">SubFS</a>. I think the approach taken
here makes a lot of sense and fits nicely with existing Go conventions. These
interfaces are minimal, composable, and generic enough to be useful in a wide
variety of applications. Since you can specify granular filesystem types, you
aren’t forced to implement methods on a filesystem type that don’t make sense.
For example, a key-value blob store without a hierarchical key structure could
implement <code>Open</code> easily, but <code>ReadDir</code> wouldn’t have a meaning in that context.</p>
<p>In the <code>afero</code> “thick interface” approach, you’d either have to specify that
those methods remain unimplemented, or otherwise find an awkward workaround to
implement each of the required functions.</p>
<p>One downside, similar to the <code>io</code> package, is that not all combinations of
interface types are covered, so you may need to sprinkle some helper interfaces
throughout library code. For example, if I want a <code>fs.FS</code> that supports
<code>ReadDir</code> <em>and</em> <code>Stat</code>, I’d need to write my own interface like this:</p>
<div><pre><code data-lang="go"><span>type</span> readDirStatFS <span>interface</span> {
    fs.ReadDirFS
    fs.StatFS
}
</code></pre></div><p>Alright, fair enough. Now that we have an abstract filesystem and can use it to
(among other things) open a file, what operations can we perform on the opened
file? The <code>FS.Open</code> function returns the new <code>fs.File</code> interface type, which
gives you access to some common file functions:</p>
<div><pre><code data-lang="go"><span>type</span> File <span>interface</span> {
    <span>Stat</span>() (FileInfo, <span>error</span>)
    <span>Read</span>([]<span>byte</span>) (<span>int</span>, <span>error</span>)
    <span>Close</span>() <span>error</span>
}
</code></pre></div><p>So, <code>fs.File</code> is basically a “ReadStatCloser”. Compare that again to the
<a href="https://pkg.go.dev/github.com/spf13/afero#File">afero.File</a> type, which is a
much “thicker” interface:</p>
<div><pre><code data-lang="go"><span>type</span> File <span>interface</span> {
	io.Closer
	io.Reader
	io.ReaderAt
	io.Seeker
	io.Writer
	io.WriterAt

	<span>Name</span>() <span>string</span>
	<span>Readdir</span>(count <span>int</span>) ([]os.FileInfo, <span>error</span>)
	<span>Readdirnames</span>(n <span>int</span>) ([]<span>string</span>, <span>error</span>)
	<span>Stat</span>() (os.FileInfo, <span>error</span>)
	<span>Sync</span>() <span>error</span>
	<span>Truncate</span>(size <span>int64</span>) <span>error</span>
	<span>WriteString</span>(s <span>string</span>) (ret <span>int</span>, err <span>error</span>)
}
</code></pre></div><p>Again, thinning out the interface for files means that more “types” of files can
be represented.</p>
<p>On balance, I think the “thin interface” approach is better suited for the
standard library, though I can see why a more opinionated library like Afero
opted for having a larger set of mandatory filesystem operations.</p>
<p><strong>However.</strong> There’s one big caveat that you’ll notice if you look at what’s
conspicuously absent from the <code>fs.File</code> interface: any ability to <em>write</em> files.
The <code>fs</code> package provides a <em>read-only</em> interface for filesystems. That’s a huge
bummer, and kinda makes me fear that <code>fs.FS</code> won’t see a ton of adoption.
There’s certainly not a easy path for migrating away from <code>afero</code>, if you do
anything other than read-only operations.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p>
<p>Looking at the original
<a href="https://go.googlesource.com/proposal/+/master/design/draft-iofs.md">filesystem interfaces proposal</a>,
there is some thought given to third-party extensions that
<a href="https://go.googlesource.com/proposal/+/master/design/draft-iofs.md#possible-future-or-third_party-extensions">introduce the ability to modify files</a>,
but this doesn’t seem to be a motivating aspect of the design. It seems that
these interfaces were included in this Go 1.16 to support the new
<a href="https://go.googlesource.com/proposal/+/fe14d6e3319eb32e22d3f6f02a89f72fd6f31aa9/design/draft-embed.md">file embedding</a>
features.</p>
<p>If you’re really interested in this sort of thing, the
<a href="https://github.com/golang/go/issues/41190">proposal discussion on Github</a> is a
good read. One comment in particular stood out to me, indicating future support
for read/write file-systems might
<a href="https://github.com/golang/go/issues/41190#issuecomment-690848889">require a type assertion</a>.
ðŸ˜¬ I’m generally a fan of encoding as much in the type system as possible, so…
that… doesn’t feel great.</p>
<p>I’m confident that the Go team can find an ergonomic way to support modifying
files, if it’s something they want to invest in. Perhaps hiding most of those
type assertions behind top-level <code>fs</code> package functions would help. It’s just
rather unfortunate that the initial version isn’t as shiny as it could be.
Incremental progress!</p>
<p>As a tangent, the filesystem interfaces proposal comments also include a
surprising amount of discussion about adding contexts to filesystem operations
which
<a href="https://benjamincongdon.me/blog/2020/04/23/Cancelable-Reads-in-Go/">I Would Be Very Much In Favor Of</a>.
(Though, I’ll readily admit that it’s probably not a good idea, on balance.)</p>
<p>One last thing: the <a href="https://tip.golang.org/pkg/testing/fstest">fstest</a> package.
Unsurprisingly, there’s a memory-mapped <code>fs.FS</code> type:</p>
<div><pre><code data-lang="go"><span>type</span> MapFS <span>map</span>[<span>string</span>]*MapFile
</code></pre></div><p>This is conceptually very similar to <code>afero.MemMapFs</code>. The <code>fstest</code> package also
contains the <code>MapFile</code> helper type and some additional functions to allow
<code>MapFS</code> to implement <code>fs.FS</code>.</p>
<p>There’s also a <a href="https://tip.golang.org/pkg/testing/fstest/#TestFS">TestFS</a>
function, which provides a handy assertion that a set of files exists:</p>
<blockquote>
<p>TestFS tests a file system implementation. It walks the entire tree of files
in fsys, opening and checking that each file behaves correctly. It also checks
that the file system contains at least the expected files.</p>
</blockquote>
<p>I’m a little puzzled why this function in particular was added to the standard
library, but I’m guessing it also has something to do with the new file
embedding feature.<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup> Sure, why not?</p>
<hr>
<p>So, to conclude: out-of-the-box with Go 1.16 you can use <code>fs.FS</code> in place of
<code>afero.Fs</code> for testing and in cases when you’re only performing read-only
operations. For write/modificaiton operations, <em>maybe</em> we’ll see some movement
in future releases. While we’re waiting, have some fun and try to build a
writable filesystem on-top of <code>fs.FS</code>? ðŸ¤·â€�â™‚ï¸� In any case, I’m looking forward to
the release of 1.16, which should happen in
<a href="https://tip.golang.org/doc/go1.16">February 2021</a>.</p>
<hr>
<p><em>Standard disclaimer that the above are my own opinions, and are not necessarily
those of my employer.</em></p>
<p><em>Discussion on
<a href="https://lobste.rs/s/kixqgi/tour_go_1_16_s_io_fs_package">lobste.rs</a>. Cover:
<a href="https://artvee.com/dl/abstract-iii/">Abstract III by Carl Newman</a></em></p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>I suppose you <em>could</em> use <code>fs.FS</code> and then perform a type assertion on the
returned <code>fs.File</code> interface but… ðŸ™ˆ <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>Update: Per <a href="https://twitter.com/_rsc">rsc</a>’s
<a href="https://lobste.rs/s/kixqgi/tour_go_1_16_s_io_fs_package#c_rvz5km">kind response</a>,
<code>fstest.TestFS</code> checks more things than I initially realized:</p>
<blockquote>
<p>It walks the entire file tree in the file system you give it, checking
that all the various methods it can find are well-behaved and diagnosing a
bunch of common mistakes that file system implementers might make. For
example it opens every file it can find and checks that Read+Seek and
ReadAt give consistent results. And lots more. So if you write your own FS
implementation, one good test you should write is a test that constructs
an instance of the new FS and then passes it to fstest.TestFS for
inspection.</p>
</blockquote>
<p>Neat! I initially thought that <code>fstest.TestFS</code> was intended to be used while
<em>using</em> a <code>fs.FS</code> in tests (e.g. while using a <code>testfs.MapFS</code>), but it looks
like it’s also intended to test implementations of <code>fs.FS</code> itself. <a href="#fnref:2" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section>

        </div></div>]]>
            </description>
            <link>https://benjamincongdon.me/blog/2021/01/21/A-Tour-of-Go-116s-iofs-package/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25870992</guid>
            <pubDate>Fri, 22 Jan 2021 12:13:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[B2B SaaS marketplaces with opportunities for indie hackers]]>
            </title>
            <description>
<![CDATA[
Score 153 | Comments 78 (<a href="https://news.ycombinator.com/item?id=25870899">thread link</a>) | @khuknows
<br/>
January 22, 2021 | https://rocketgems.com/blog/saas-marketplaces/ | <a href="https://web.archive.org/web/*/https://rocketgems.com/blog/saas-marketplaces/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
            <p>Although <a href="https://rocketgems.com/blog/developer-content-businesses/" target="_blank">I’m personally focussing less on SaaS and more on content business opportunities</a>, the type of SaaS businesses that interest me the most as an indie hacker are the ones that plug into growing B2B platforms.</p><p> These platforms generally make it easier to find customers, create more focussed products, and build trust.</p><p>Shopify, Slack, and Salesforce are examples of B2B products with more mature and well known marketplaces, but there are a whole bunch more. They range from more fully featured marketplaces that have integrated user reviews and payment handling, to more basic "integration directories."</p><p>Out of the 100+ marketplaces and integration directories I found, 66 stood out to me as the ones worth considering as an indie hacker. The ones that have user reviews built in have a (*) next to their names.</p>
            
            
            
            
            <div id="saas-marketplaces-crms">
                <h2>Customer Relationship Management (CRM)</h2>
                
                    <h3><a href="https://www.salesforce.com/" target="_blank">Salesforce</a>*</h3><p>Salesforce is one of the first ever SaaS products and has arguably the most developed B2B app marketplace. Listings include user reviews, live chat, pricing details, and more.</p><p><a href="https://appexchange.salesforce.com/" target="_blank">Marketplace →</a></p><h3><a href="https://www.hubspot.com/" target="_blank">Hubspot</a>*</h3><p>Hubspot has a suite of products including a CRM, site builder, form builder, and much more. Their app marketplace has user reviews, app install numbers, videos, and pricing details.</p><p><a href="https://ecosystem.hubspot.com/marketplace/apps" target="_blank">Marketplace →</a></p><h3><a href="https://www.pipedrive.com/" target="_blank">Pipedrive</a>*</h3><p>Pipedrive isn't quite as popular as Hubspot or Salesforce, but with over 95,000 companies using them, they're still pretty massive. Their app marketplace listings include ratings, reviews, and optional videos.</p><p><a href="https://marketplace.pipedrive.com/" target="_blank">Marketplace →</a><br></p><h3><a href="https://www.zoho.com/crm/" target="_blank">Zoho CRM</a>*</h3><p>As with many of the above, Zoho offers a CRM as well as a suite of tools for businesses. Their marketplace listings include user reviews, pricing details, and optional videos,&nbsp;</p><p><a href="https://marketplace.zoho.com/home" target="_blank">Marketplace →</a></p>
                
            </div>
            
            <div id="saas-marketplaces-customer-support">
                <h2>Customer support</h2>
                
                    <h3><a href="https://www.zendesk.com/" target="_blank">Zendesk</a>*</h3><p>Zendesk has a reasonably mature app marketplace where the listings include user reviews, price details, and videos.</p><p><a href="https://www.zendesk.com/apps/directory" target="_blank">Marketplace →</a></p><h3><a href="https://freshdesk.com/" target="_blank">Freshdesk</a></h3><p>Freshdesk is part of a suite of products under the "Freshworks" brand. Their marketplace seems quite mature and includes helpful features like search, but the listings don't include user reviews or pricing details.</p><p><a href="https://www.freshworks.com/apps/freshdesk/" target="_blank">Marketplace →</a></p><h3><a href="http://intercom.com/" target="_blank">Intercom</a></h3><p>Intercom isn't exactly a support tool, but I wasn't sure which category to include it in as the product does many things. They're best known for their live chat widget. The Intercom marketplace listings do include pricing details and optional videos, but don't have user reviews.</p><p><a href="https://www.intercom.com/app-store" target="_blank">Marketplace →</a></p><h3><a href="https://www.helpscout.com/" target="_blank">HelpScout</a></h3><p>HelpScout isn't quite as big as Zendesk or Freshdesk, but is fairly popular amongst startups, who are generally more willing to try out new apps. Their app directory is quite basic and doesn't include things like user reviews or pricing details.</p><p><a href="https://www.helpscout.com/help-desk-integration/" target="_blank">Marketplace →</a><br></p><h3><a href="https://frontapp.com/" target="_blank">Front</a></h3><p>Front is an email collaboration tool that's commonly used for customer support. Like HelpScout, their app directory is fairly basic.</p><p><a href="https://frontapp.com/integrations" target="_blank">Marketplace →</a></p><h3><a href="https://www.liveagent.com/" target="_blank">LiveAgent</a></h3><p>LiveAgent is another suite of customer support tools. Their integration directory is a more simple one, similar to Front and HelpScout.</p><p><a href="https://www.liveagent.com/integrations/" target="_blank">Marketplace →</a></p>
                
            </div>
            
            
            
            <div id="saas-marketplaces-website-builders">
                <h2>Website builders</h2>
                
                    <h3><a href="https://www.shopify.com/" target="_blank">Shopify</a>*</h3><p>Shopify is an e-commerce platform and has one of the most mature app marketplaces. The marketplace listings include user reviews, payments, videos, and more. App makers can even use paid ads within the marketplace to get in front of more potential customers. This is a marketplace with plenty of opportunity and plenty of competition.</p><p><a href="https://apps.shopify.com/" target="_blank">Marketplace →</a><br></p><h3><a href="https://wordpress.com/" target="_blank">Wordpress</a>*</h3><p>Wordpress powers a huge percentage of all websites. It's the most popular website builder (or content management system). Their plugin marketplace has user reviews, download numbers, and more. Most plugins are free, and most of the paid ones charge one time fees. This is another marketplace with plenty of opportunity and plenty of competition.</p><p><a href="https://wordpress.org/plugins/" target="_blank">Marketplace →</a><br></p><h3><a href="https://www.squarespace.com/" target="_blank">Squarespace</a></h3><p>Squarespace is another popular website builder. If you listen to podcasts, you'll likely have heard one of their ads. Their marketplace is quite tiny and less advanced then a lot of the above. It doesn't have user reviews, but does have pricing information.</p><p><a href="https://www.squarespace.com/extensions/home" target="_blank">Marketplace →</a><br></p><h3><a href="https://webflow.com/" target="_blank">Webflow</a></h3><p>Webflow is a website builder targeting no-code makers and designers. It seems to be growing rapidly, but their marketplace is still super basic.</p><p><a href="https://university.webflow.com/integrations" target="_blank">Marketplace →</a><br></p><h3><a href="https://www.wix.com/" target="_blank">Wix</a>*</h3><p>Wix is another website builder which is mostly used by small businesses. Their marketplace includes user reviews, videos, pricing details, and more.</p><p><a href="https://www.wix.com/app-market" target="_blank">Marketplace →</a></p><h3><a href="https://magento.com/" target="_blank">Magento</a>*</h3><p>Magento is an e-commerce website builder that's generally used to build more advanced/custom online stores than Shopify. Their marketplace is advanced and includes user reviews, Q&amp;A sections, and more.</p><p><a href="https://marketplace.magento.com/" target="_blank">Marketplace →</a><br></p><h3><a href="https://woocommerce.com/" target="_blank">WooCommerce</a>*</h3><p>WooCommerce is the e-commerce builder from Wordpress. I think WooCommerce plugins are kinda Wordpress plugins that are packaged specifically for WooCommerce, but there is a separate marketplace for WooCommerce plugins that has reviews, pricing, etc. I assume there's also more willingness to pay for WooCommerce plugins because it's more likely that websites built with it are earning revenue.</p><p><a href="https://woocommerce.com/products/" target="_blank">Marketplace →</a><br></p><h3><a href="https://www.bigcommerce.com/" target="_blank">BigCommerce</a>*</h3><p>BigCommerce is another big player in the e-commerce space. Their marketplace includes payments, user reviews, videos, and more.</p><p><a href="https://www.bigcommerce.co.uk/apps/" target="_blank">Marketplace →</a><br></p><h3><a href="https://www.volusion.com/" target="_blank">Volusion</a></h3><p>Volusion is another e-commerce website builder. I don't really hear of it much so I have no idea how big it is, but they do have a basic plugin marketplace that does include pricing details.</p><p><a href="https://www.volusion.com/v1/marketplace" target="_blank">Marketplace →</a><br></p>
                
            </div>
            
            <div id="saas-marketplaces-marketing-automation">
                <h2>Marketing</h2>
                
                    <h3><a href="https://marketo.com/" target="_blank">Marketo</a>*</h3><p>Marketo is a marketing automation platform. Their marketplace is quite advanced and includes user reviews, videos, and more.</p><p><a href="https://launchpoint.marketo.com/" target="_blank">Marketplace →</a><br></p><h3><a href="http://mailchimp.com/" target="_blank">MailChimp</a></h3><p>MailChimp is one of the most well known email service providers. The marketplace is one of the more basic ones.</p><p><a href="https://mailchimp.com/integrations/" target="_blank">Marketplace →</a><br></p><h3><a href="https://segment.com/" target="_blank">Segment</a></h3><p>Segment is a "Customer Data Platform" that makes it easier to share data between various cloud products. Their marketplace, which they call an "integrations catalog" is exactly that, more of a catalog than a marketplace with reviews and what not.</p><p><a href="https://segment.com/catalog/" target="_blank">Marketplace →</a></p><h3><a href="https://www.drip.com/" target="_blank">Drip</a></h3><p>Drip is an email service provider focussed on e-commerce. Their integration marketplace is another example of a more basic one. The listings don't have user reviews or pricing details.</p><p><a href="https://www.drip.com/integrations" target="_blank">Marketplace →</a><br></p><h3><a href="https://www.activecampaign.com/" target="_blank">ActiveCampaign</a></h3><p>Another email service provider with a simple "apps and integrations" directory.</p><p><a href="https://www.activecampaign.com/apps/" target="_blank">Marketplace →</a></p>
                
            </div>
            
            
            
            <div id="saas-marketplaces-other">
                <h2>Other</h2>
                
                    <p>Here are a whole bunch of other B2B products that include app/plugin/extension marketplaces that I couldn't place into any of the above categories. A lot of them fit into some sort of "productivity" or "collaboration" category.</p><h3><a href="https://zoom.us/" target="_blank">Zoom</a></h3><p>Zoom is a wildly popular video call/conferencing service. They recently launched "Zapps" which are apps that enhance the zoom experience. As their marketplace is brand new, and isn't fully launched yet. I have no clue how popular Zapps will become, but I'd bet there are some great opportunities here.</p><p><a href="https://zoom.us/docs/en-us/zoom-apps.html" target="_blank">Marketplace →</a><br></p><h3><a href="https://slack.com/" target="_blank">Slack</a></h3><p>Slack is a live chat app for teams. Their app marketplace doesn't include user reviews, but it is fairly mature. Most Slack teams use a few apps and there are features built into the Slack service that helps people discover apps. As with Shopify, this is a marketplace with plenty of opportunity and plenty of competition.</p><p><a href="https://slack.com/apps" target="_blank">Marketplace →</a><br></p><h3><a href="https://www.microsoft.com/en/microsoft-teams/group-chat-software" target="_blank">Microsoft Teams</a>*</h3><p>Microsoft Teams is the live chat product from Microsoft. It's very quickly become super popular with large companies and enterprises.</p><p><a href="https://appsource.microsoft.com/en-us/marketplace/apps?product=teams" target="_blank">Marketplace →</a><br></p><h3><a href="https://workspace.google.com/" target="_blank">G Suite/Google Workspace</a>*</h3><p>G Suite or Google Workspace is a set of business tools from Google, including email, word processing, spreadsheets etc. The marketplace includes user ratings, install numbers, and more. Personally, I wouldn't put too much trust into any of the Google marketplaces as they have a history of being less friendly to their app developers when compared to other B2B app marketplaces.</p><p><a href="https://gsuite.google.com/marketplace/" target="_blank">Marketplace →</a></p><h3><a href="https://airtable.com/" target="_blank">Airtable</a></h3><p>Airtable is a powerful spreadsheet type tool with a newer marketplace. The marketplace is fairly basic at the moment, but it's very new and I imagine it will become more advanced in the future.</p><p><a href="https://airtable.com/marketplace" target="_blank">Marketplace →</a><br></p><h3><a href="https://zapier.com/" target="_blank">Zapier</a></h3><p>Zapier is an automation tool that lets you connect various products so they can work better together. Their marketplace doesn't include user reviews or usage numbers, but lets customers discover apps through workflows and guides.</p><p><a href="https://zapier.com/apps" target="_blank">Marketplace →</a><br></p><h3><a href="https://www.integromat.com/en" target="_blank">Integromat</a></h3><p>Integormat is an automation tool similar to Zapier. Their app directory is also fairly basic, but it does let you visualise how the apps can be used together really well.</p><p><a href="https://www.integromat.com/en/integrations" target="_blank">Marketplace →</a><br></p><h3><a href="https://bubble.io/" target="_blank">Bubble</a>*&nbsp;</h3><p>Bubble is a no-code app and website builder that's growing in popularity. Their plugin marketplace does include user reviews and pricing details.</p><p><a href="https://bubble.io/plugins" target="_blank">Marketplace →</a><br></p><h3><a href="https://rapidapi.com/" target="_blank">RapidAPI</a></h3><p>RapidAPI is different to most of the other products mentioned here as the main part of the product is the marketplace itself. It's an API marketplace that makes it easier for developers to integrate and pay for many APIs. The marketplace doesn't have reviews, but listings have an area for discussions, popularity ratings, and more comparable features.</p><p><a href="https://rapidapi.com/marketplace" target="_blank">Marketplace →</a><br></p><h3><a href="https://www.surveymonkey.com/" target="_blank">SurveyMonkey</a></h3><p>SurveyMonkey is a super popular form and survey builder. They have a fairly basic app directory.</p><p><a href="https://www.surveymonkey.com/apps/" target="_blank">Marketplace →</a><br></p><h3><a href="https://www.typeform.com/" target="_blank">Typeform</a></h3><p>Typeform is a form builder that made the multi-step, more conversational style of form more popular. They have a basic app directory.</p><p><a href="https://www.typeform.com/connect/" target="_blank">Marketplace →</a></p><h3><a href="https://www.jotform.com/" target="_blank">JotForm</a></h3><p>JotForm is another form builder. Their marketplace is fairly simple, but there are plenty of opportunities for simple apps that can enhance forms.</p><p><a href="https://www.jotform.com/apps/" target="_blank">Marketplace →</a></p><h3><a href="https://monday.com/" target="_blank">Monday</a></h3><p>Monday is a project management and team collaboration tool. Their app marketplace doesn't have …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rocketgems.com/blog/saas-marketplaces/">https://rocketgems.com/blog/saas-marketplaces/</a></em></p>]]>
            </description>
            <link>https://rocketgems.com/blog/saas-marketplaces/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25870899</guid>
            <pubDate>Fri, 22 Jan 2021 12:02:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Audio Modulated Tesla Coil (2010)]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25870676">thread link</a>) | @1_player
<br/>
January 22, 2021 | http://uzzors2k.com/index.php?page=pllsstc2 | <a href="https://web.archive.org/web/*/http://uzzors2k.com/index.php?page=pllsstc2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<a id="top"></a>

<!-- Banner graphics and main menu -->

<br>

<nav>
	<ul>
		<li><a href="http://uzzors2k.com/index.php">Home</a></li>
		<li><a href="http://uzzors2k.com/index.php?page=hv">High Voltage</a></li>
		<li><a href="http://uzzors2k.com/index.php?page=micro">Embedded</a></li>
		<li><a href="http://uzzors2k.com/index.php?page=phys">Physics</a></li>
		<li><a href="http://uzzors2k.com/index.php?page=electronics">Electronics</a></li>
		
	</ul>
</nav>

<!-- End of Banner graphics and main menu -->


<!-- PHP code to load new pages -->


<h3>28.02.10</h3>

<p><a href="http://uzzors2k.com/projectfiles/pllsstc2/sstc2_completed.JPG">
		<img alt="" src="http://uzzors2k.com/projectfiles/pllsstc2/sstc2_completed.JPG">
	</a>
</p>

<p>


This Tesla coil was designed to play
music. Plain and simple. Originally I wanted the best sound quality
possible from an analog source, and at the same time the largest
streamers possible. This lead to a long research phase where I tried to
find out what could give this combination with the least effort.
Several months passed with this project bouncing between ideas and
nothing happening, until a friend suggested I use MIDI to interface
with the Tesla coil. This is used in DRSSTCs and definitely gives the
biggest sparks, since the coil is run at full power and the pulse
repetition frequency is
just varied (see my Polyphonic MIDI Tesla Coil Interrupter project).
The disadvantage is that only square waves can be reproduced by the
Tesla coil when using this type of audio modulation. However I was
already using Steve Conner's PLL driver at this point, which
has analog audio modulation implemented! Since one wouldn't affect the
other, this driver has both analog and gated modulation.

</p><p><a href="http://uzzors2k.com/projectfiles/pllsstc2/Audio%20SSTC.GIF">
		<img alt="PLL SSTC 2 schematic" src="http://uzzors2k.com/projectfiles/pllsstc2/Audio%20SSTC.GIF">
	</a>
</p>

<p>


The driver itself is pretty much
identical to the PLL SSTC 1 driver, which is to say Steve Conner's PLL
from his <a href="http://scopeboy.com/tesla/dwsstc/index.html">DWSSTC
project</a>. The additions I made for this particular SSTC
were to include an inverter for the interrupter signal, so a high
signal from the interrupter can either turn the coil ON or OFF. This is
used so the MIDI interrupter can play music the "conventional" way so
there are no streamers during silence, or so the coil can remain in CW
mode with a interrupter signal, and thus play music via frequency
shifting (analog). I purchased some UC3710T gate driver chips on ebay,
which come in a nice TO-220 package, much easier to keep cool than
dinky DIP8 gate drivers. Other than that there's not much new to anyone
familiar with this driver. I've made a PCB for the driver, but unless
you also acquire some UC3710T's it's not of much use. <a href="http://uzzors2k.com/projectfiles/pllsstc2/SSTC%20driver%20PCB.zip">SSTC
driver
PCB.zip</a></p><p><a href="http://uzzors2k.com/projectfiles/pllsstc2/sstc2_design_phase.JPG">
		<img alt="" src="http://uzzors2k.com/projectfiles/pllsstc2/sstc2_design_phase.JPG">
	</a>
	
	<a href="http://uzzors2k.com/projectfiles/pllsstc2/SSTC2_firstlight.JPG">
		<img alt="" src="http://uzzors2k.com/projectfiles/pllsstc2/SSTC2_firstlight.JPG">
	</a>
	
	<a href="http://uzzors2k.com/projectfiles/pllsstc2/Completed_SSTC2.JPG">
		<img alt="" src="http://uzzors2k.com/projectfiles/pllsstc2/Completed_SSTC2.JPG">
	</a>
	
	<br>
	
	<a href="http://uzzors2k.com/projectfiles/pllsstc2/sstc2_construction.JPG">
		<img alt="" src="http://uzzors2k.com/projectfiles/pllsstc2/sstc2_construction.JPG">
	</a>
</p>
 
<p>


Some
specs on the coil for those who are
interested. This one draws 1kW of power when run in CW mode, and the
discharge is only 12cm tall or so. About the same size as the topload,
which btw, is two steel Ikea bowls. They come in small, medium, and
large, which is perfect for Tesla coiling although it would be better
if they weren't completely spherical. The reason the discharge is so
small for the coil size, is because I designed the coil to be run
continuously while audio modulated, and also provide decent audio
quality. This required the rather high drive frequency of 625kHz, and
not much power throughput or the IRFP450s would overheat. As is, the
only thing limiting the run time is secondary temperature, as the
electronics stay cool. A pleasant change from my other High voltage
projects, but in the end I wish there was some more bang.

</p><h2>Demonstration with MIDI Interrupter</h2>

<p>
	<iframe width="420" height="315" src="https://www.youtube.com/embed/NUPux_rxYLY" frameborder="0" allowfullscreen=""></iframe>
</p><!-- End of PHP code  -->


<br>

<hr>

<p>
	<a href="http://youtube.com/uzzors2k" target="_blank"><img src="http://uzzors2k.com/menufiles/social_media/youtube.png" width="19" alt="Youtube"></a>
	<a href="http://flickr.com/uzzors2k" target="_blank"><img src="http://uzzors2k.com/menufiles/social_media/flickr.png" width="19" alt="Flickr"></a>
	<a href="http://twitter.com/uzzors2k" target="_blank"><img src="http://uzzors2k.com/menufiles/social_media/twitter.png" width="19" alt="Twitter"></a>
	<a href="https://no.linkedin.com/in/davideiriktaylor" target="_blank"><img src="http://uzzors2k.com/menufiles/social_media/linkedin.png" width="19" alt="LinkedIn"></a>
	
	<a href="#top">To top</a>
</p>

<!-- Legal stuff -->

<hr>

<!-- Disclaimer -->
<p>
	<b>Disclaimer:</b>
	I do not take responsibility for any injury, death, hurt ego, or other
	forms of personal damage which may result from recreating these
	experiments. Projects are merely presented as a source of inspiration,
	and should only be conducted by responsible individuals, or under the
	supervision of responsible individuals. It is your own life, so proceed
	at your own risk! All projects are for noncommercial use only.
</p>

<br>

<!-- Creative commons license -->
<p>
	<a rel="license" href="https://creativecommons.org/licenses/by-nc-sa/3.0/">
		<img alt="Creative Commons License" src="https://i.creativecommons.org/l/by-nc-sa/3.0/80x15.png">
	</a>
	
	This work is licensed under a 
	<a rel="license" href="https://creativecommons.org/licenses/by-nc-sa/3.0/">
	Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported License</a>.
</p>


<!-- Visitor counter and page design link -->

<hr>

<p>

3250 unique visitors since 28th June 2020.
</p>



</div>]]>
            </description>
            <link>http://uzzors2k.com/index.php?page=pllsstc2</link>
            <guid isPermaLink="false">hacker-news-small-sites-25870676</guid>
            <pubDate>Fri, 22 Jan 2021 11:22:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rebuilding the spellchecker, pt.4: Introduction to suggest algorithm]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25870500">thread link</a>) | @zverok
<br/>
January 22, 2021 | https://zverok.github.io/blog/2021-01-21-spellchecker-4.html | <a href="https://web.archive.org/web/*/https://zverok.github.io/blog/2021-01-21-spellchecker-4.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <p><strong><em>This is the fourth part of the “Rebuilding the spellchecker” series, dedicated to explaining how the world’s most popular spellchecker Hunspell works.</em></strong></p>

<p>Today’s topic is <strong>suggest</strong>!</p>

<p><strong>Quick recap</strong>:</p>

<ol>
  <li>In the <strong><a href="https://zverok.github.io/blog/2021-01-05-spellchecker-1.html">first part</a></strong>, I’ve described what Hunspell is; and why I decided to rewrite it in Python. It is an <strong>explanatory rewrite</strong> dedicated to uncovering the knowledge behind the Hunspell by “translating” it into a high-level language, with a lot of comments.</li>
  <li>In the <strong><a href="https://zverok.github.io/blog/2021-01-09-spellchecker-2.html">second part</a></strong>, I’ve covered the basics of the <strong>lookup</strong> (word correctness check through the dictionary) algorithm, including <em>affix compression</em>.</li>
  <li>In the <strong><a href="https://zverok.github.io/blog/2021-01-14-spellchecker-3.html">third part</a></strong>, the rest of the lookup is explained: compounding, word breaking, and text case.</li>
</ol>

<p>And now, we’ll switch to the juiciest part of the spellchecking problem: guessing the corrections for the misspelled word, called <em>suggest</em> in Hunspell. This post only draws the big picture of suggestion algorithms in general and the Hunspell’s particular flavor. Even more <del>nasty</del> amazingly curious details would be covered in the next issue (or, rather, issues).</p>

<h2 id="the-problem-with-suggest">The problem with suggest</h2>

<p>The question “how the suggest works?” was what drew me initially to the project. The lookup part seemed trivial. And even if, as I understood later, it is not that trivial, the lookup is still a task with a <em>known answer</em>. The word is either correct or not; the spellchecker, however it is implemented and however it stores its data, should just say whether it is correct. All the complexity of lookup implementation is only a set of optimizations, because it is hard or impossible to just store a list of “all correct words”.</p>

<p><strong>But suggest is a different beast altogether.</strong> There are many ways to misspell a word, due to mis<i>typing</i>, genuine error, or OCR glitch; and going back from the misspelled word to the correct one is no easy task. Frequently, only the text’s author can say for sure what is right: was “throught” meant to be “through”, “thought”, or maybe “throughout”?.. What about “restraunt”: “restraint” or “restaurant”? Ideally, there should be exactly one guess (then we can even apply auto-correct to the user’s text), but that’s rarely the case.</p>

<p>Even when the human can guess “what word was misspelled here”, it is not always obvious what is an algorithmic way to deduce the correct word from the misspelled one, such that its results <em>felt correct</em> for the human. Moreover, the algorithm found for one case or set of cases may produce an irrelevant result in others, and it is hard to find the objective measure of whether your suggester is “good”.</p>

<p>So, while lookup approaches vary only by their performance, the smallest tweaks in the suggestion algorithm might produce dramatically different results.</p>

<h2 id="how-it-can-be-done">How it can be done</h2>

<p>The famous article by Peter Norvig “<a href="https://norvig.com/spell-correct.html">How to Write a Spelling Corrector</a>” describes the possible algorithm in these steps:</p>

<ul>
  <li>generate multiple “edits” of the word (insert one letter, remove one letter, swap two adjacent letters, etc.)</li>
  <li>from all edits, select the words that are present in the dictionary;</li>
  <li>rank them by word’s commonness (using a source dictionary with weights, or a big source text which is summarized to “word → how often it is used”);</li>
  <li>take the first one as a singular good suggestion.</li>
</ul>

<p>The entire algorithm implementation in Python takes less lines than most of the core methods of Spylls.</p>

<blockquote>
  <p>Note that Norvig’s article is an awesome, concise, and friendly explanation of the basic <em>idea</em> of how spellchecking <em>might</em> work, intended to create the intuition about the process. But it is by no means enough to build a good spellchecker. Unfortunately, quite a few libraries exist that claim to be production-ready spellchecking solution implementing “the famous Norvig’s algorithm”. They ignore both “The full details of an industrial-strength spell corrector are quite complex…” at the very beginning of the article and a large section “Future Work” in the end. In real life, the results are typically less than satisfying. Much less.</p>
</blockquote>

<p>Some of the modern approaches to spellchecking still take this road: for example, <a href="https://github.com/wolfgarbe/SymSpell">SymSpell</a> algorithm (claiming to be “1 million times faster”) is at its core just a brilliant idea for a novel storage format for a flat word list, that allows optimizing the calculation of edit distance significantly.</p>

<p>Most of the “industrial-strength spell correctors” (using Norvig’s definition), though, are multi-stage. They produce possible corrections with several different algorithms and, most frequently, return several suggestions, not relying on the algorithm’s ability to guess the very best one.</p>

<p>For example, <a href="http://aspell.net/">Aspell</a>, one of the Hunspell’s “uncles”<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup>  (still considered by some to have better suggestion quality <em>for English</em>), has quite <a href="http://aspell.net/man-html/Aspell-Suggestion-Strategy.html">succinct description</a> of its suggestion strategy, and even exposes command-line options for the user to control <a href="http://aspell.net/0.50-doc/man-html/4_Customizing.html#suggestion">some parameters</a> of this strategy.</p>

<p>Hunspell’s approach is much more complicated, not to say “cumbersome”. From what I can guess—I didn’t dive deep into history and reasoning behind all the decisions—it grew organically with Hunspell’s popularity, resulting from a multitude of cases and requirements from users of a variety of languages. There is no single “complex algorithm” that can be extracted and explained on the whiteboard, but rather a sequence of simpler algorithms. They are guided by a ton of settings that can be present in aff-files and kept together by lots of tests.</p>

<h2 id="how-hunspell-does-it">How Hunspell does it</h2>

<p>Hunspell does the search for a correction in the following stages:</p>

<ol>
  <li>Generate a list of edits and check their correctness with the lookup, but
    <ul>
      <li>there are many more of them than the classic insert-delete-swap-replace; in fact, more than dozen, depending on the particular language meta-information provided by aff-file;</li>
      <li>there is no ranking/reordering of edits (neither by word popularity nor by closeness to the original word); the order of their calculation <em>is</em> the order they will be returned: it is assumed that Hunspell’s code already applies edits in the highest-probability-first order.</li>
    </ul>
  </li>
  <li>If there were no results on the edit stage, or they weren’t considered very good (more on this later), the search through the entire dictionary is performed:
    <ul>
      <li>the similarity of the misspelled word and each dictionary stem is calculated with rough and quick formula;</li>
      <li>for top-100 similar stems, all of their affix forms are produced, and similarity to them is calculated with another rough and quick formula;</li>
      <li>for top-200 of similar affixed forms, a very complicated and precise formula is used to choose only the best suggestions.</li>
    </ul>
  </li>
  <li>There <em>might</em> be an optional third stage: metaphone (pronunciation) based suggestions… Although, it depends on the existence of the metaphone encoding data in dictionary’s aff-file, and there is a <em>very</em> small number of such dictionaries in the wild (namely, one). We’ll touch on this curious topic briefly in the future.</li>
  <li>Finally, some post-processing is performed on the suggestion, like converting it to the same character case as an initial misspelling (<em>unless</em> it is a prohibited case for this word!) or replacing some characters with “output conversion” rules.</li>
</ol>

<blockquote>
  <p>For the impatient: we’ll cover the details of the implementation of each stage in the future posts, but you can begin reading the docs and the code right now, starting from the <a href="https://spylls.readthedocs.io/en/latest/hunspell/algo_suggest.html"><code>algo.suggest</code></a> module.</p>
</blockquote>

<h2 id="quality-estimation">Quality estimation</h2>

<p>Is Hunspell’s suggestion algorithm good? And <em>how</em> good is it?</p>

<p>Those questions are open ones—and even the way they can be answered is unclear. Intuitively, Hunspell’s suggestions are quite decent—otherwise, it wouldn’t be the most widespread spellchecker, after all. A fair amount of “unhappy customers” can be easily found, too, in <a href="https://github.com/hunspell/hunspell/issues">hunspell’s repo issues</a>. At the same time, one should distinguish between different reasons for the sub-par suggestion quality. It might be due to the algorithm itself, or due to the source data quality: the literal absence of the desired suggestion in the dictionary, or lack of aff-file settings that could’ve guided Hunspell to finding it.</p>

<p>Hunspell’s development process, to the best of my knowledge, doesn’t use any realistic text corpora to evaluate suggestion algorithm—only feature-by-feature synthetic tests.</p>

<blockquote>
  <p>In contrast, Aspell’s site <a href="http://aspell.net/test/cur/">provides an evaluation dataset</a> for English, including comparison with Hunspell (Aspell wins, by a large margin). Hunspell’s repo actually <a href="https://github.com/hunspell/hunspell/tree/master/tests/suggestiontest">contains</a> something similar: script to evaluate Hunspell vs. Aspell based on Wikipedia’s <a href="https://en.wikipedia.org/wiki/Wikipedia:Lists_of_common_misspellings">List of common misspellings</a> (Hunspell wins), but mostly for informational purposes: the results are neither promoted nor used as a reference point for further development.</p>
</blockquote>

<p>The current Hunspell’s development consensus “what’s the best suggestion algorithm” is maintained by a multitude of synthetic <a href="https://github.com/hunspell/hunspell/tree/master/tests">test dictionaries</a>, validating that one of the suggestion features, or set of them, works (and frequently indirectly validating other features). This situation is both a blessing and a curse: synthetic tests provide stable enough environment to refactor Hunspell (or to rewrite it in a different language, IYKWIM); on the other hand, there is no direct way to test the <em>quality</em>—the tests only confirm that <em>features work in expected order</em>. So, there is no way to prove that some big redesign, or some alternative spellchecker passes the quality check at least <em>as good as Hunspell</em> and improves over this baseline.</p>

<blockquote>
  <p>There is, for example, a curious <a href="https://github.com/bakwc/JamSpell#benchmarks">evaluation table</a> provided by a modern ML-based spellchecker JamSpell. According to it, JamSpell is awesome—while Hunspell is a mere 0.03% better than dummy (“fix nothing”) spellchecker… Which doesn’t ring true, somehow!</p>
</blockquote>

<p>My initial assumption for the Spylls project was that understanding the current implementation in full would be a precondition for public experimentation to improve it significantly. Or—as I dreamed—we’ll be able to mix-and-match approaches of several spellcheckers (at least Hunspell and Aspell, considering, say, <a href="https://battlepenguin.com/tech/aspell-and-hunspell-a-tale-of-two-spell-checkers/">the popular article</a> demonstrating the cases where the latter beats the former). What I …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://zverok.github.io/blog/2021-01-21-spellchecker-4.html">https://zverok.github.io/blog/2021-01-21-spellchecker-4.html</a></em></p>]]>
            </description>
            <link>https://zverok.github.io/blog/2021-01-21-spellchecker-4.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25870500</guid>
            <pubDate>Fri, 22 Jan 2021 10:51:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Secure Messaging App Conundrum: Signal vs. Telegram [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 59 | Comments 79 (<a href="https://news.ycombinator.com/item?id=25870133">thread link</a>) | @todsacerdoti
<br/>
January 22, 2021 | https://cqi.inf.usi.ch/publications/telegram_vs_signal.pdf | <a href="https://web.archive.org/web/*/https://cqi.inf.usi.ch/publications/telegram_vs_signal.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://cqi.inf.usi.ch/publications/telegram_vs_signal.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25870133</guid>
            <pubDate>Fri, 22 Jan 2021 09:57:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Upgrade Your SSH Keys]]>
            </title>
            <description>
<![CDATA[
Score 56 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25870060">thread link</a>) | @hackmin
<br/>
January 22, 2021 | https://blog.g3rt.nl/upgrade-your-ssh-keys.html | <a href="https://web.archive.org/web/*/https://blog.g3rt.nl/upgrade-your-ssh-keys.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
            
<p>Whether you're a software developer or a sysadmin, I bet you're using SSH keys.
Pushing your commits to Github or managing your Unix systems, it's best practice to do this over SSH with public key authentication rather than passwords.
However, as time flies, many of you are using older keys and not aware of the need to generate fresh ones to protect your privates much better.
In this post I'll demonstrate how to transition to an Ed25519 key smoothly, why you would want this and show some tips and tricks on the way there.</p>
<div>
<p>Tl;dr:</p>
<p>Generate your new key with <code>ssh-keygen -o -a 100 -t ed25519</code>, specify a strong passphrase and read further if you need a smooth transition.</p>
</div>
<p>I'm planning to publish some more posts on SSH tips &amp; tricks, so keep an eye on my blog for more.
This post will focus on about SSH keys as user public key authentication.</p>
<h2 id="dsa-and-rsa-1024-bit-are-deprecated-now">DSA and RSA 1024 bit are deprecated now<a href="#dsa-and-rsa-1024-bit-are-deprecated-now" title="Permanent link"> </a></h2>
<p>If you've created your key more than about four years ago with the default options it's probably insecure (RSA &lt; 2048 bits).
Even worse, I've seen tweeps, colleagues and friends still using DSA keys (<code>ssh-dss</code> in OpenSSH format) recently.
That's a key type similar to RSA, but limited to 1024 bits size and therefore <a href="https://security.stackexchange.com/a/5100/12948">recommended against</a> for a long time.
It's plainly insecure and refused for valid reasons in recent OpenSSH versions (see also the <a href="http://www.openssh.com/txt/release-7.0">changelog for 7.0</a>).</p>
<p>The sad thing about it is that I see posts on how to re-enable DSA key support rather than moving to a more secure type of key.
Really, it's unwise to follow instructions to change the configuration for <code>PubkeyAcceptedKeyTypes</code> or <code>HostKeyAlgorithms</code> (host keys are for a later post).
Instead, upgrade your keys!</p>
<p><img alt="Picture of an ancient key" src="https://blog.g3rt.nl/images/20160923_old_key_picture.jpg"></p>
<p>Compare DSA with the technology of locks using keys like this one.
You wouldn't want this type of key to unlock your front door, right?</p>

<h2 id="determine-your-current-situation">Determine your current situation<a href="#determine-your-current-situation" title="Permanent link"> </a></h2>
<p>List all your keys:</p>
<div><pre><span></span><code><span>$</span> <span>for</span> keyfile in ~/.ssh/id_*<span>;</span> <span>do</span> ssh-keygen -l -f <span>"${</span><span>keyfile</span><span>}"</span><span>;</span> <span>done</span> <span>|</span> uniq
</code></pre></div>
<ul>
<li>DSA or RSA 1024 bits: red flag. Unsafe.</li>
<li>RSA 2048: yellow recommended to change</li>
<li>RSA 3072/4096: great, but Ed25519 has some benefits!</li>
<li>ECDSA: depends. Recommended to change</li>
<li>Ed25519: wow cool, but are you brute-force safe?</li>
</ul>
<h2 id="a-smooth-transition-i-promise">A smooth transition, I promise.<a href="#a-smooth-transition-i-promise" title="Permanent link"> </a></h2>
<p>You're probably thinking… "I'm using my key for a long time, I don't want to change them everywhere now."
Valid point, but you don't have to! It's good to know you can have multiple keys on your system and your SSH client will pick the right one for the right system automatically.</p>
<p>It's part of the SSH protocol that it can offer multiple keys and the server picks the one your client will have to prove it has possession of the private key by a challenge.
See it in action adding some verbosity to the SSH connect command (<code>-vvv</code>).
Also if you're using an SSH agent you can load multiple keys and it will discover them all.
Easy as that.</p>
<h2 id="youll-like-the-twisted-edwards-curve">You'll like the Twisted Edwards curve<a href="#youll-like-the-twisted-edwards-curve" title="Permanent link"> </a></h2>
<p>Most common is the RSA type of key, also known as <code>ssh-rsa</code> with SSH.
It's very compatible, but also slow and potentially insecure if created with a small amount of bits (&lt; 2048).
We just learned that your SSH client can handle multiple keys, so enable yourself with the newest faster elliptic curve cryptography and enjoy the very compact key format it provides!</p>
<p>Ed25519 keys are short. Very short. If you're used to copy multiple lines of characters from system to system you'll be happily surprised with the size. The public key is just about 68 characters. It's also much faster in authentication compared to secure RSA (3072+ bits).</p>
<p>Generating an Ed25519 key is done using the <code>-t ed25519</code> option to the ssh-keygen command.</p>
<p>Ed25519 is a reference implementation for EdDSA using Twisted Edward curves (<a href="https://en.wikipedia.org/wiki/Twisted_Edwards_curve">Wikipedia link</a>).</p>
<h2 id="increase-resistance-to-brute-force-password-cracking">Increase resistance to brute-force password cracking<a href="#increase-resistance-to-brute-force-password-cracking" title="Permanent link"> </a></h2>
<p>When generating the keypair, you're asked for a passphrase to encrypt the private key with.
If you will ever lose your private key it should protect others from impersonating you because it will be encrypted with the passphrase.
To actually prevent this, one should make sure to prevent easy brute-forcing of the passphrase.</p>
<p>OpenSSH key generator offers two options to resistance to brute-force password cracking: using the new OpenSSH key format and increasing the amount of key derivation function rounds.
It slows down the process of unlocking the key, but this is what prevents efficient brute-forcing by a malicious user too.
I'd say experiment with the amount of rounds on your system.
Start at about 100 rounds.
On my system it takes about one second to decrypt and load the key once per day using an agent.
Very much acceptable, imo.</p>
<p>With <code>ssh-keygen</code> use the <code>-o</code> option for the new RFC4716 key format and the use of a modern key derivation function powered by bcrypt.
Use the <code>-a &lt;num&gt;</code> option for <code>&lt;num&gt;</code> amount of rounds.</p>
<p>Actually, it appears that when creating a Ed25519 key the <code>-o</code> option is implied.</p>
<p>The OpenSSH manpages are not really explanatory about the 'new' format.
I found this article pretty useful: <a href="http://www.tedunangst.com/flak/post/new-openssh-key-format-and-bcrypt-pbkdf">"new openssh key format and bcrypt pbkdf" on www.tedunangst.com</a>.</p>
<h2 id="generate-your-new-sexy-ed25519-key">Generate your new sexy Ed25519 key<a href="#generate-your-new-sexy-ed25519-key" title="Permanent link"> </a></h2>

<div><pre><span></span><code><span><span>$</span> ssh-keygen -o -a <span>100</span> -t ed25519
</span><span>Generating public/private ed25519 key pair.</span>
<span>Enter passphrase (empty for no passphrase):</span>
<span>Enter same passphrase again:</span>
<span>Your identification has been saved in /home/gert/.ssh/id_ed25519.</span>
<span>Your public key has been saved in /home/gert/.ssh/id_ed25519.pub.</span>
<span>The key fingerprint is:</span>
<span>SHA256: [...] gert@hostname</span>
<span>The key's randomart image is: [...]</span>
</code></pre></div>
<p>Note the line 'Your identification has been saved in /home/gert/.ssh/id_ed25519'.
Your current RSA/DSA keys are next to it in the same <code>~/.ssh</code> folder.
As with any other key you can copy the public key in <code>~/.ssh/id_ed25519.pub</code> to target hosts for authentication.</p>
<h2 id="multi-key-aware-ssh-client">Multi-key aware SSH client<a href="#multi-key-aware-ssh-client" title="Permanent link"> </a></h2>
<p>All keys available on default paths will be autodetected by SSH client applications, including the SSH agent via ssh-add.
So, if you were using an application like ssh/scp/rsync before like...</p>

<p>it will now offer multiple public keys to the server and the server will request proof of possession for a matching entry for authentication.
And your daily use of the <code>ssh-add</code> command will not change and autodiscover the Ed25519 key:</p>
<div><pre><span></span><code><span><span>$</span> ssh-add
</span><span>Enter passphrase for /home/gert/.ssh/id_rsa:</span>
<span>Identity added: /home/gert/.ssh/id_rsa (gert@hostname)</span>
<span>Identity added: /home/gert/.ssh/id_ed25519 (gert@hostname)</span>
</code></pre></div>
<p>It not only discovered both keys, it also loaded them by entering a single passphrase (because it's the same)!</p>
<p>We've reached a very important goal now.
Without any change to your daily routine we can slowly change the existing configuration on remote hosts to accept the Ed25519 key.
In the meantime the RSA key will still work.
Great, right!?</p>
<h2 id="change-or-set-a-passphrase">Change or set a passphrase<a href="#change-or-set-a-passphrase" title="Permanent link"> </a></h2>
<p>If you're afraid this will change your key, don't worry.
The private part of your keypair is encrypted with a passphrase which only exists locally on your machine.
Change it as often as you like.
This is recommended to prevent abuse in case the key file gets into the wrong hands.
Repeat for all your key files to ensure a new key format with 100 bcrypt KDF rounds:</p>
<div><pre><span></span><code><span>$</span> ssh-keygen -f ~/.ssh/id_rsa -p -o -a <span>100</span>
</code></pre></div>
<h2 id="upgrade-your-current-rsa-key">Upgrade your current RSA key<a href="#upgrade-your-current-rsa-key" title="Permanent link"> </a></h2>
<p>Using Ed25519 will (and should) work in most situations by now, but legacy systems may not support them as of yet.
The best fallback is a strong RSA keypair for this.</p>
<p>While the OpenSSH client supports multiple RSA keys, it requires configuration/command line options to specify the path so it's rather error-prone.
Instead, I'd recommend upgrading your existing key in-place to keep things simple once this is done.
Depending on the strength (key size) of your current RSA key you can migrate urgently or comfortably.</p>
<p>In case you have a weak RSA key still, move it out of the way from the standard path and generate a new one of 4096 bits size:</p>
<div><pre><span></span><code><span>$</span> mv ~/.ssh/id_rsa ~/.ssh/id_rsa_legacy
<span>$</span> mv ~/.ssh/id_rsa.pub ~/.ssh/id_rsa_legacy.pub
<span>$</span> ssh-keygen -t rsa -b <span>4096</span> -o -a <span>100</span>
</code></pre></div>
<p>If you are using an agent, manually point it to all your keys:</p>
<div><pre><span></span><code><span>$</span> ssh-add ~/.ssh/id_rsa ~/.ssh/id_rsa_legacy ~/.ssh/id_ed25519
</code></pre></div>
<p>Once you are finished the transition on all remote targets you can go back to convenience and let it autodiscover your new RSA and Ed25519 keys; simply omit the keyfile arguments.</p>
<h2 id="software-support-for-ed25519">Software support for Ed25519<a href="#software-support-for-ed25519" title="Permanent link"> </a></h2>
<p>Support is available since OpenSSH 6.5 and well adopted in the Unix world OSs for workstations.
Ubuntu 14.04+, Debian 8+, CentOS/RedHat 7+ etc. all support it already.
(If you have details about Mac OS X please drop a line, couldn't find it with a quick search).
Some software like custom desktop key agents may not like the new keys for several reasons (see below <a href="#my-gnome-keyring-doesnt-work-anymore">about the Gnome-keyring</a> for example).</p>
<p>Github works pretty well too, by the way.
Launchpad and Gerrit code review however, seem to require RSA keys unfortunately.
PuTTY on Windows? See below.</p>
<h2 id="my-gnome-keyring-doesnt-work-anymore">My Gnome-keyring doesn't work anymore<a href="#my-gnome-keyring-doesnt-work-anymore" title="Permanent link"> </a></h2>
<p>The Gnome-keyring, as used in Ubuntu Unity at least, fails to read the new RFC4716 format keys but reports success.
It's bugged.
More details here in <a href="https://askubuntu.com/q/564821/88802">my AskUbuntu Q&amp;A post</a>.
I'd recommend disabling the Gnome keyring for SSH agent use and use the plain OpenSSH agent instead.</p>
<h2 id="im-using-windows-with-putty">I'm using Windows with PuTTY<a href="#im-using-windows-with-putty" title="Permanent link"> </a></h2>
<p>Sorry, I'm not using PuTTY, but make sure to upgrade first.
This page suggests Ed25519 support since a late-2015 version according to a <a href="http://www.chiark.greenend.org.uk/~sgtatham/putty/wishlist/ed25519.html">wishlist item</a>.
Generally speaking, I'm not too excited with the speed of implementation of security features in it.</p>
<h2 id="is-this-the-ultimate-secure-ssh-keypair">Is this the ultimate secure SSH keypair?<a href="#is-this-the-ultimate-secure-ssh-keypair" title="Permanent link"> </a></h2>
<p>We've taken some steps, important ones, but it's far from ultimate security.
When dealing with high assurance environments I would strongly discourage key usage like described in this post as this holds the unencrypted private key in memory.
Instead, use hardware security (smart cards) to avoid leaking keys even from memory dumps.
It's not covered in this post, mainly because it requires a hardware device you need to buy and secondly because the limitations are device dependent.
A nice cute solution would be to make use of your TPM already …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.g3rt.nl/upgrade-your-ssh-keys.html">https://blog.g3rt.nl/upgrade-your-ssh-keys.html</a></em></p>]]>
            </description>
            <link>https://blog.g3rt.nl/upgrade-your-ssh-keys.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25870060</guid>
            <pubDate>Fri, 22 Jan 2021 09:42:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ownCloud Infinite Scale: Go instead of PHP, microservices instead of LAMP]]>
            </title>
            <description>
<![CDATA[
Score 100 | Comments 105 (<a href="https://news.ycombinator.com/item?id=25869798">thread link</a>) | @veddox
<br/>
January 22, 2021 | https://www.heise.de//news/ownCloud-Infinite-Scale-Go-statt-PHP-Microservices-statt-LAMP-5029244.html | <a href="https://web.archive.org/web/*/https://www.heise.de//news/ownCloud-Infinite-Scale-Go-statt-PHP-Microservices-statt-LAMP-5029244.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        





<a-collapse has-indicator="">
  
  
  
</a-collapse>


      

      <p>Im stillen KÃ¤mmerlein arbeitet ownCloud seit Ã¼ber einem Jahr an der neuen Version seiner Software und zeigt nun zum ersten Mal sein neues Projekt Infinite Scale â€“ allerdings sind die Entwickler nicht langsam, sondern haben sich viel vorgenommen. Bis einschlieÃŸlich ownCloud X ist die Software eine klassische LAMP-Applikation: Im Hintergrund werkelt MySQL, Apache serviert PHP-Seiten und das gesamte Konstrukt lÃ¤uft Ã¼blicherweise auf einer Linux-Installation.</p>

<a-paternoster height="360" media="(min-width: 320px) and (max-width: 767px)">
  


  


  <a-ad height="600" instant="" layout="fixed" media="(min-width: 320px) and (max-width: 767px)" preload-distance="200" safeframe="" sizes="300x600,300x50,300x75,300x100,300x150,300x250,320x50,320x75,320x100,320x250" targeting="{&quot;kw&quot;:[&quot;Cloud Computing&quot;,&quot;Google Go&quot;,&quot;Linux und Open Source&quot;,&quot;Microservices&quot;,&quot;Nextcloud&quot;,&quot;OwnCloud&quot;,&quot;PHP&quot;,&quot;Server &amp; Storage&quot;,&quot;Systemverwaltung&quot;],&quot;mpos&quot;:[&quot;understitial&quot;,&quot;top&quot;],&quot;themenhub&quot;:&quot;yes&quot;}" type="gpt" unit="/6514/www.heise.de/ix/ix-inhalt" width="300"></a-ad>

</a-paternoster>


<p>Im Laufe der Jahre sind die ownCloud-Entwickler allerdings an immer mehr Performance- und Skalierbarkeitsgrenzen gestoÃŸen, deren Ursache zumeist in entsprechenden Limitierungen in PHP liegt. Wer groÃŸe ownCloud-Installationen betreibt, kennt das: Je mehr Nutzer und Dateien die Instanz verwaltet, desto trÃ¤ger wird sie mit der Zeit. RegelmÃ¤ÃŸig sehen Admins sich zudem mit Speicherplatzmangel konfrontiert, denn bisher speichert ownCloud die Dateien seiner Nutzer lokal auf einem normalen Dateisystem ab. Wird der Platz dort knapp, ist das Problem gar nicht so leicht zu umschiffen.</p>
<h3 id="nav_goodbye_php_0">Goodbye, PHP</h3>
<p>Alle <a href="https://www.heise.de/thema/OwnCloud">diese alten ZÃ¶pfe</a> planen die Entwickler in ownCloud Infinite Scale endgÃ¼ltig abzuschneiden. Dabei handelt es sich mehr Revolution denn Evolution: Ihren alten Code treten die Entwickler fast vollstÃ¤ndig in die Tonne und ersetzen ihn durch einen kompletten Rewrite in Go. oCIS folgt einem Modell aus drei Schichten: Die unterste Schicht kÃ¼mmert sich um das Speichern von Dateien, die mittlere Schicht umfasst alle Kern-Dienste und die dritte Schicht ist das ebenfalls vollstÃ¤ndig neu geschriebene Webinterface.</p>





  

<a-lightbox tabindex="1">
  
    

<figure>

  <div>
      <a href="https://www.heise.de/imgs/18/3/0/4/1/5/0/0/ocis5-b5dab7c1ceae5a77.png">
      

<a-img alt="" height="887" high-dpi-quality="70" layout="responsive" quality="85" src="/imgs/18/3/0/4/1/5/0/0/ocis5-b5dab7c1ceae5a77.png" width="1250"></a-img>



      </a>
    

  </div>
    

<figcaption>    <p>Ein erster Test des neuen ownCloud Infinite Scale und des ebenfalls neuen Webinterface, geschrieben in Vue.js.</p>
      
    
</figcaption>

</figure>

  
</a-lightbox>




<p>Der Kern von ownCloud besteht kÃ¼nftig aus verschiedenen Microservices, die einander per gRPC Befehle und Anweisungen zusenden. Die Entwickler bÃ¼ndeln die MESH-Software Traefik fest mit oCIS, um sich um Themen wie Loadbalancing und sichere Kommunikation innerhalb des Service-Netzwerks keine Gedanken machen zu mÃ¼ssen. Was im Umkehrschluss bedeutet: Reichen die laufenden Instanzen eines bestimmten ownCloud-Dienstes nicht mehr aus, lassen sich zusÃ¤tzliche Instanzen desselben Dienstes ad hoc starten.</p>
<p>Architektonisch nutzt oCIS diverse Vorteile von Go zur Beschleunigung. Fordert der Nutzer kÃ¼nftig eine spezielle Aktion per API oder Webinterface an, kÃ¼mmern die einzelnen oCIS-Microservices sich im Hintergrund darum. Der Anwender muss nicht warten, bis die jeweilige Aktion erfolgreich ausgefÃ¼hrt ist, bevor er den nÃ¤chsten Befehl absenden kann. Der Effekt findet sich auch auf der Code-Ebene wieder, wo Go anders als PHP echte NebenlÃ¤ufigkeit beherrscht und damit mehrere Operationen zur selben Zeit ausfÃ¼hren kann.</p>
<p>Obendrein reduziert der Umstieg auf Microservices den administrativen Aufwand von ownCloud. Eine externe Datenbank wie MySQL benÃ¶tigt die Software kÃ¼nftig nicht mehr â€“ um ihre Datenhaltung kÃ¼mmern sich eigene Microservices.</p>






  


  <a-ad height="250" instant="" layout="responsive" media="(min-width: 320px) and (max-width: 767px)" preload-distance="200" safeframe="" sizes="300x50,300x75,300x100,300x150,300x250,320x50,320x75,320x100,320x250,fluid" targeting="{&quot;kw&quot;:[&quot;Cloud Computing&quot;,&quot;Google Go&quot;,&quot;Linux und Open Source&quot;,&quot;Microservices&quot;,&quot;Nextcloud&quot;,&quot;OwnCloud&quot;,&quot;PHP&quot;,&quot;Server &amp; Storage&quot;,&quot;Systemverwaltung&quot;],&quot;mpos&quot;:[&quot;2&quot;],&quot;themenhub&quot;:&quot;yes&quot;}" type="gpt" unit="/6514/www.heise.de/ix/ix-inhalt" width="300"></a-ad>




      <!-- RSPEAK_STOP -->

      

      

     

      

      <!-- RSPEAK_STOP -->

    </div></div>]]>
            </description>
            <link>https://www.heise.de//news/ownCloud-Infinite-Scale-Go-statt-PHP-Microservices-statt-LAMP-5029244.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25869798</guid>
            <pubDate>Fri, 22 Jan 2021 09:03:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple Silicon timeline – Easily track planned Apple Silicon support for Mac apps]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25869685">thread link</a>) | @abdullahdiaa
<br/>
January 22, 2021 | https://isapplesiliconready.com/timeline | <a href="https://web.archive.org/web/*/https://isapplesiliconready.com/timeline">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><span><div><div><div><h2>
                    Capture One Pro
                  </h2> <p>
                    Native ARM support, will be released in an update to Capture One 21 early in 2021. In the meantime, Capture One will run on ARM-based Mac computers using Apple’s Rosetta 2 emulation platform. Tethering issue will be addressed in future upcoming releases.
                  </p> <p><a href="https://twitter.com/captureonepro/status/1329810389987680260" target="_blank"><span>
                    Source
                  </span></a></p></div></div></div><div><div><div><h2>
                    Box drive
                  </h2> <p>
                    A Beta is planned in early 2021 for our Enterprise customers. Meanwhile, customers on these devices are encouraged to leverage our web-based application (https://app.box.com).
                  </p> <p><a href="https://isapplesiliconready.com/app/Box%20drive" target="_blank"><span>
                    Source
                  </span></a></p></div></div></div><div><div><div><h2>
                    Unite by bzgapps
                  </h2> <p>
                    M1 support planned for early 2021. Rosetta compatible.
                  </p> <p><a href="https://www.bzgapps.com/unite" target="_blank"><span>
                    Source
                  </span></a></p></div></div></div><div><div><div><h2>
                    Golang
                  </h2> <p>
                    In February, the Go 1.16 release will include support for the new Apple Silicon Macs
                  </p> <p><a href="https://blog.golang.org/11years" target="_blank"><span>
                    Source
                  </span></a></p></div></div></div><div><div><div><h2>
                    Newton mail app
                  </h2> <p>
                    As soon as 5th Feb. M1 version is expected to be released
                  </p> <p><a href="https://twitter.com/newtonmailapp/status/1352544579178827780" target="_blank"><span>
                    Source
                  </span></a></p></div></div></div><div><div><div><h2>
                    Clean My Mac
                  </h2> <p>
                    MacPaw planning to release 4.8.0 M1 native version at the end of February.
                  </p> <p><a href="https://twitter.com/cleanmymac/status/1352574830613327872" target="_blank"><span>
                    Source
                  </span></a></p></div></div></div><div><div><div><h2>
                    Squash by Realmac Software
                  </h2>  <p><a href="https://twitter.com/realmacsoftware/status/1352712198469120001" target="_blank"><span>
                    Source
                  </span></a></p></div></div></div><div><div><div><h2>
                    Espresso 6
                  </h2> <p>
                    Beta version expected in Feb. and a stable version in March with native Apple Silicon support
                  </p> <p><a href="https://twitter.com/espressoapp/status/1352741607083102208" target="_blank"><span>
                    Source
                  </span></a></p></div></div></div><div><div><div><h2>
                    Google Drive for Desktop
                  </h2> <p>
                    Google Drive for desktop version 47.0 will support Apple M1 devices
                  </p> <p><a href="https://support.google.com/a/answer/7577057?hl=en" target="_blank"><span>
                    Source
                  </span></a></p></div></div></div><div><div><div><h2>
                    The R Project
                  </h2> <p>
                    goal is to have a native distribution for R 4.1.0 ca April 2021.
                  </p> <p><a href="https://stat.ethz.ch/pipermail/r-sig-mac/2020-November/013774.html" target="_blank"><span>
                    Source
                  </span></a></p></div></div></div><div><div><div><h2>
                    RapidWeaver by Realmac Software
                  </h2>  <p><a href="https://twitter.com/realmacsoftware/status/1352712198469120001" target="_blank"><span>
                    Source
                  </span></a></p></div></div></div><div><div><div><h2>
                    WD Discovery
                  </h2> <p>
                    Western Digital expects to have an update to WD Discovery that will mount the My Cloud Home drive on macOS M1 Processors by July 2021.
                  </p> <p><a href="https://isapplesiliconready.com/app/WD%20Discovery" target="_blank"><span>
                    Source
                  </span></a></p></div></div></div></span></p></div></div></div>]]>
            </description>
            <link>https://isapplesiliconready.com/timeline</link>
            <guid isPermaLink="false">hacker-news-small-sites-25869685</guid>
            <pubDate>Fri, 22 Jan 2021 08:40:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: How to make your own budget Macro keyboard with JavaScript and Arduino]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25869647">thread link</a>) | @Ilikeruby
<br/>
January 22, 2021 | https://blog.almin.dev/posts/2021-01-20/diymacrokeyboard | <a href="https://web.archive.org/web/*/https://blog.almin.dev/posts/2021-01-20/diymacrokeyboard">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><div><p>A few days ago I saw this blogpost by Scott Haneselman <a href="https://www.hanselman.com/blog/microsoft-teams-buttons-for-stream-deck-to-mute-share-hang-up-and-manage-cameras">“Microsoft Teams Buttons for Stream Deck to Mute, Share, Hang up, and Manage Cameras”</a> and I’ve found it fascinating and a great use of the Elgato Streamdeck. There is only one little catch.. the price. The elgato stream deck starts about ~150 Euro and about the same in dollars, which is kinda expensive for my budget, so I went thru my drawers to find my old Arduino set. it contained some buttons and some wires, which is exactly what I needed! (And also the whole set cost me about ~50 Euros)</p><p><img src="https://blog.almin.dev/static/media/components.3e13cb3a.jpg"></p><p><strong>Parts I’ve used here:</strong></p><ul><li>Arduino board</li><li>Cables</li><li>Button </li><li>Breadboard </li><li>10k Ohm Resistor</li></ul><h2 id="first-steps">First steps</h2><p>So, the first step was figuring out what language to use to make this work. Originally I thought, it would be nice to use GoLang or Rust since I want to get into these languages in the future, however after some thinking about it I naturally, like every hipster developer, settler for JS. It is probably not a good idea to write microcontrollers with JS but in this case, it should be easy to use and reproduce for everyone, I think JS is the best option. </p><p>What I recommend using is <a href="http://johnny-five.io/">Johnny-Five</a> which in short is a library that helps us communicate with the IOT devices like Arduino and Raspbery pi. In order to communicate with the host device, it realies on the <a href="https://github.com/firmata/protocol">firmata-protocol</a>. In the case of an arduino a program is flashed to the arduino that bootstraps and runs firmata, accepting instructions over a serial connection. With the Raspberry Pi it uses raspi-io, which uses a firmata-compatible API. It has the downside of requiring a serial connection to run your code.</p><p>Now, to start with the project I’ve just lookup some of the examples found in the on the <a href="http://johnny-five.io/examples/button/">Website of johnny-five</a> which helped me connect the arduino with the breadboard. After that I had something like this: </p><p><img src="https://blog.almin.dev/static/media/board.0c1830d6.jpg"></p><p><em><strong>Note</strong></em>: I’ve used some extension cables to make the reach a bit longer, since my USB cable is too tiny and connecting to the back of my PC results in me having to stretch, if I did not have the extensions. </p><p>Here is maybe a better look at the board schema and how to connect a button to it: </p><p><img src="https://blog.almin.dev/static/media/boardSchema.f984cd78.png"></p><h2 id="loading-the-firmware">Loading the firmware</h2><p>After connecting with the breadboard, connect the arduino to the PC and we can start with the fun part!</p><p>First off we start the <a href="https://www.arduino.cc/en/software">Arduino IDE</a> and configure some things. </p><ol><li>Select the correct Port <em><strong>Tools</strong></em> &gt; <em><strong>Port</strong></em> (the correct port is 3 or above)</li></ol><p><img src="https://blog.almin.dev/static/media/port.7420d600.png"></p><br><ol start="2"><li>We will need this to flash the firmata protocol <em><strong>Files</strong></em> &gt; <em><strong>Examples</strong></em> &gt; <em><strong>StandardFirmataPlus</strong></em></li></ol><p><img src="https://blog.almin.dev/static/media/Firmata.17a71e86.png"></p><blockquote><p><strong> ATTENTION </strong>
Let me stop here for a second - If you, like me, have a knockoff arduino and you are not seeing any port besides the default one, you have to install a specific driver which can be found <a href="https://sparks.gogo.co.nz/ch340.html">here</a>. Thats me saving you 3h of googling what the issue is, you are welcome.</p></blockquote><br><ol start="3"><li>Just press <em><strong>Upload</strong></em> button, and if everything is configured correclty there should be no errors in the IDE. </li></ol><p><img src="data:image/png;base64,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"></p><br><ol start="4"><li><strong>Thats it for the config!</strong></li></ol><p>Now that you have Arduino running with a Firmata protocol, everything we have to do is code the JS part of the macro keyboard. </p><p>Make a new <code>index.js</code> file wherever you can - write the code for the keyboard, should look something like this: </p><pre><code data-language="javascript" data-highlighted-line-numbers=""><span>var</span> five <span>=</span> <span>require</span><span>(</span><span>"johnny-five"</span><span>)</span><span>,</span> button<span>;</span>
<span>var</span> robot <span>=</span> <span>require</span><span>(</span><span>"robotjs"</span><span>)</span><span>;</span>
<span>var</span> board <span>=</span> <span>new</span> <span>five<span>.</span>Board</span><span>(</span><span>{</span>
  port<span>:</span> <span>"COM3"</span>
<span>}</span><span>)</span><span>;</span>





board<span>.</span><span>on</span><span>(</span><span>"ready"</span><span>,</span> <span>function</span><span>(</span><span>)</span> <span>{</span>

  
  
  
  button <span>=</span> <span>new</span> <span>five<span>.</span>Button</span><span>(</span><span>2</span><span>)</span><span>;</span>

  
  
  
  board<span>.</span>repl<span>.</span><span>inject</span><span>(</span><span>{</span>
    button<span>:</span> button
  <span>}</span><span>)</span><span>;</span>

  

  
  button<span>.</span><span>on</span><span>(</span><span>"down"</span><span>,</span> <span>function</span><span>(</span><span>)</span> <span>{</span>
    robot<span>.</span><span>keyToggle</span><span>(</span><span>"control"</span><span>,</span> <span>"down"</span><span>)</span>
    robot<span>.</span><span>keyToggle</span><span>(</span><span>"shift"</span><span>,</span> <span>"down"</span><span>)</span>
    robot<span>.</span><span>keyToggle</span><span>(</span><span>"m"</span><span>,</span> <span>"down"</span><span>)</span>
<span>}</span><span>)</span>

  
  
  
  button<span>.</span><span>on</span><span>(</span><span>"hold"</span><span>,</span> <span>function</span><span>(</span><span>)</span> <span>{</span>
    console<span>.</span><span>log</span><span>(</span><span>"hold"</span><span>)</span><span>;</span>
  <span>}</span><span>)</span><span>;</span>

  
  button<span>.</span><span>on</span><span>(</span><span>"up"</span><span>,</span> <span>function</span><span>(</span><span>)</span> <span>{</span>
    robot<span>.</span><span>keyToggle</span><span>(</span><span>"control"</span><span>,</span> <span>"up"</span><span>)</span>
    robot<span>.</span><span>keyToggle</span><span>(</span><span>"shift"</span><span>,</span> <span>"up"</span><span>)</span>
    robot<span>.</span><span>keyToggle</span><span>(</span><span>"m"</span><span>,</span> <span>"up"</span><span>)</span>
  <span>}</span><span>)</span><span>;</span>
<span>}</span><span>)</span><span>;</span>
</code></pre><p>This code snippet is only for “CTRL + SHIFT + M” (mute / unmute) for MS Teams (I think Discord and Slack use the same button combination for mute and unmute.)
And run it like a node script <code>node index.js</code> and thats it, your button should be working now!</p><p>Let me break down the code a little bit. The importat part is this: </p><pre><code data-language="javascript" data-highlighted-line-numbers=""><span>var</span> board <span>=</span> <span>new</span> <span>five<span>.</span>Board</span><span>(</span><span>{</span>
  port<span>:</span> <span>"COM3"</span>
<span>}</span><span>)</span><span>;</span>
</code></pre><p>You should initialize a new Board with the correct port, since in my case I had to do it, because the default port is not working. Probably because of the knockoff arduino. The port is the same as the one we selected above in the first step!</p><p>The pin on the Arduino board should be set here as the button:</p><pre><code data-language="javascript" data-highlighted-line-numbers="">button <span>=</span> <span>new</span> <span>five<span>.</span>Button</span><span>(</span><span>2</span><span>)</span><span>;</span>
</code></pre><p>Later you can declare new buttons with the same code, just remember to select the correct Digital pin number on which the button is connected. (Usually from 0 to 13)</p><p>And <a href="https://github.com/octalmage/robotjs">RobotJs</a> is being used to setup the keyboard shortcuts with the <code>down</code> and <code>up</code> events which are triggered when pressing the button. It is just a simple library which simulates the keyboard inputs. This is really the first solution I could find and easiest I could make work, there could be potentially something better, but I’ve settled with what works. Also remember to use KeyToggle function and not keyTap. So you can add additional shortcuts, which make you leave the call or copy - paste, change scenes, essentially almost everything you can do with a StreamDeck.</p><p>So, in just a few steps you can have a custom macro keyboard. It is supriseingly not that hard, especially if you have the possibility to write JS and make it work with it. </p><p>Later if you are ambitious you can expand this and add more buttons on the board and make something a bit more complicated and it could look like this: </p><p><img src="https://blog.almin.dev/static/media/finished.38bd50d3.png"></p><p>Its not as fancy as the StreamDeck but it is usefull and does the job. In the future you can update it and get better keys and better housing for the whole board, add blinking lights and so on. This was just fun DIY project which is also something really usefull.</p></div></article></div></div>]]>
            </description>
            <link>https://blog.almin.dev/posts/2021-01-20/diymacrokeyboard</link>
            <guid isPermaLink="false">hacker-news-small-sites-25869647</guid>
            <pubDate>Fri, 22 Jan 2021 08:33:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Canada's Express Entry Program]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25869096">thread link</a>) | @luu
<br/>
January 21, 2021 | https://scattered-thoughts.net/writing/canadas-express-entry-program/ | <a href="https://web.archive.org/web/*/https://scattered-thoughts.net/writing/canadas-express-entry-program/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <p>Wesley Aptekar-Cassels' recent posts on <a href="https://notebook.wesleyac.com/taiwan-gold-card/">getting a gold card</a> and <a href="https://notebook.wesleyac.com/taiwan/">moving to Taiwan</a> reminded me that I meant to write about my experience with Canada.</p>
<p>I immigrated to Vancouver, BC in March 2020. I was given permanent residency before setting foot in Canada and without a job offer, under the <a href="https://www.canada.ca/en/immigration-refugees-citizenship/services/immigrate-canada/express-entry.html">Express Entry</a> program. From gathering documents to landing in the country took 9 months. Judging by 3rd party trackers this is well over the median - I was pretty disorganized and the London embassy is one of the slowest.</p>
<p>The whole process looks like this:</p>
<ol>
<li>Check the <a href="https://www.canada.ca/en/immigration-refugees-citizenship/services/immigrate-canada/express-entry/eligibility/compare.html">eligibility requirements</a> and spend 5 minutes filling out <a href="https://www.cic.gc.ca/english/immigrate/skilled/crs-tool.asp">this questionnaire</a>. You'll get a score which you can compare to <a href="https://www.canada.ca/en/immigration-refugees-citizenship/services/immigrate-canada/express-entry/submit-profile/rounds-invitations/results-previous.html">recent admission rounds</a> to see if you have a good chance. (The results aren't recorded, so just guess what your language test scores would be.)</li>
<li>Take an <a href="https://www.canada.ca/en/immigration-refugees-citizenship/services/immigrate-canada/express-entry/documents/language-requirements.html">English and/or French exam</a> and get an <a href="https://www.canada.ca/en/immigration-refugees-citizenship/services/immigrate-canada/express-entry/documents/education-assessed.html">Educational Credential Assessment</a>. Get the rest of your paperwork ready - proof of employment history, proof of funds, <a href="https://www.canada.ca/en/immigration-refugees-citizenship/services/immigrate-canada/express-entry/apply-permanent-residence/police-certificates.html">police certificates</a>.</li>
<li>Fill out an <a href="https://www.canada.ca/en/immigration-refugees-citizenship/services/immigrate-canada/express-entry/submit-profile.html">Express Entry profile</a> and wait for an invitation to apply.</li>
<li>Get invited to apply. Submit all the paperwork. Take a short medical exam and go the embassy for fingerprints and photos.</li>
<li>Send off your passport and wait for it to come back with a Confirmation of Permanent Residence inside.</li>
</ol>
<p>The total cost for me was £1456:</p>
<ul>
<li>£165 for the IELTS exam</li>
<li>£140 for the Educational Credential Assessment</li>
<li>various small fees for eg mailing paperwork, getting sealed degree certificates</li>
<li>£670 for the Express Entry application</li>
<li>£330 for the medical exam</li>
</ul>
<p>One thing I really appreciated is that most of the expense of applying, in terms of both time and money, was at step 4, by which point the acceptance rate is something like 95%.</p>
<p>Other miscellanea:</p>
<ul>
<li>Step 2 took me 4 months (poor planning). Step 3 took 2 weeks. Step 4 took 3 months. Step 5 took 2 months, apparently due to heavy backlog at the London office.</li>
<li>Self-employment is fine for the employment history requirements. I submitted tax records and signed letters from a few previous clients.</li>
<li>I didn't have a job offer in Canada, but if you do it seems worth trying to get provincial nomination which will shoot you to the top of the queue. Eg BC has a <a href="https://www.welcomebc.ca/Immigrate-to-B-C/B-C-Provincial-Nominee-Program/BC-PNP-Tech-Pilot">fast-track for tech jobs</a>.</li>
<li>Permanent residents are eligible for public healthcare (which in BC is free) after 3 months. There are companies that offer cheap private insurance to cover the gap - I used <a href="https://www.desttravel.com/#/insuranceproducts/visitortocanadainsurance">Destination Travel</a>.</li>
<li>To keep my residency I need to spend 2 out of every 5 years in Canada. After accumulating 3 years in Canada in any 5 year period I'm eligible for citizenship.</li>
</ul>
<hr>
<p>My move was totally unrelated to current events - I had decided a few years back that I wanted to settle down somewhere and Vancouver ended up at the top of the spreadsheet. But since many of my friends in the US are thinking about emigrating, here are the main points I see for and against.</p>
<p>In favor of Vancouver:</p>
<ul>
<li>World class <a href="https://www.mountainproject.com/area/105946429/british-columbia">climbing</a>, skiing, kayaking, mountain biking etc as well as a <a href="https://originsparkour.com/">solid parkour gym</a></li>
<li><a href="https://www.youtube.com/watch?v=gjfUkxqDDNw">Astounding natural beauty</a></li>
<li><a href="https://www.iqair.com/ca/canada/british-columbia/vancouver-bc">Low air pollution</a></li>
<li><a href="https://vancouver.ca/home-property-development/urban-forest-strategy.aspx">Trees</a>, <a href="https://vancouver.ca/parks-recreation-culture/beaches.aspx">beaches</a>, <a href="https://www.vanmuralfest.ca/murals">murals</a></li>
<li>Reasonable social safety net</li>
<li>Politically stable</li>
<li>English-speaking (I've lived in several non-English-speaking countries so this certainly isn't a hard requirement, but it is easier)</li>
<li>Same timezone as SF and 3 hours behind NYC - good for remote tech work</li>
<li>Regularly ranked as one of the <a href="https://en.wikipedia.org/wiki/Most_livable_cities">most livable</a> cities in the world</li>
</ul>
<p>Against Vancouver:</p>
<ul>
<li>Large belligerent neighbor</li>
<li>On the <a href="https://vancouver.ca/home-property-development/understanding-earthquakes.aspx">Cascadia subduction zone</a></li>
<li>Downtown is vulnerable to <a href="https://vancouver.ca/green-vancouver/sea-level-rise.aspx">sea level rise</a></li>
<li>Uncertain economic future, dependent on oil</li>
<li>Regular wildfires</li>
<li>Expensive real estate (compared to other Canadian cities, but not anywhere near as bad as SF, NYC or London)</li>
<li>Not a cultural capital</li>
</ul>

</article></div>]]>
            </description>
            <link>https://scattered-thoughts.net/writing/canadas-express-entry-program/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25869096</guid>
            <pubDate>Fri, 22 Jan 2021 06:46:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Transcript of Microsoft President Brad Smith's Town Hall on the Company PAC]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25869065">thread link</a>) | @idlewords
<br/>
January 21, 2021 | https://notes.pinboard.in/u:maciej/90342e46caf768b7329d | <a href="https://web.archive.org/web/*/https://notes.pinboard.in/u:maciej/90342e46caf768b7329d">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><b>Microsoft Town Hall Jan 21 Transcript</b></p><p>The following is a partial transcript of an employee town hall held by Microsoft on January 21, 2021. Participants in the town hall included Microsoft CEO Satya Nadella, Microsoft President Brad Smith, and Kurt DelBene, executive vice president of corporate strategy. The event moderator was Nichole Christie. A video of the town hll was made available to me by a source at Microsoft, and I have transcribed Smith's comments on the company PAC here verbatim. </p>

<p>Comments and shouts into the void in brackets in italics are mine.</p>

<p>My contact info is maciej@ceglowski.com / 415 610 0231 on Signal. </p>

<hr>

<p><strong>NICOLE CHRISTIE</strong>: The Microsoft political action committee, or MS-PAC. We're hearing about this on a variety of channels, so it is our first question, and this one comes from Yammer. </p>

<p>"Please advise what actions MS-PAC will make to address donations made to politicians involved in the effort to derail the certification of Electoral College votes on January 6. Microsoft employees support our company culture and values, and follow our code of conduct. MS-PAC dollars should not be given to politicians or organizations who don't share those values. Brad, can you speak to this?</p>

<p><strong>BRAD SMITH</strong>: "Thank you, Nicole, and it's obviously an important question. I don't want to repeat but I do want to build upon what Satya has said. Jan 6, the attack on the Capitol, was a horrific day for all of us, whether we're in the United States or somewhere else, and I think it was even more difficult, say, for our black employees and our Jewish employees given the hateful symbols that were on display.</p>

<p>"This has obvious implications for the future donations of the PAC. We took stock of our donations over the last four years and we found that 80% of the dontions had gone to members of Congress who voted to uphold the Electoral College, and 20% had gone to members who voted against the Electoral College,"</p>

<p>[<em>It's not clear if this is an accounting of dollar figures, or a count of donations. It's also not clear if Smith is counting donations to leadership PACs and other PACs, which fan out to multiple members of Congress. You can see a spreadsheet of donations made by Microsoft and other tech companies to the 147 members of congress who voted to overturn the Electoral College <a href="https://docs.google.com/spreadsheets/d/1EjbdWHZ-9ojc5Fh64Sle6kpnOIfJSztkJT3YFlJilDk/edit#gid=0">here</a>.</em>]</p>

<p><strong>SMITH</strong>: "So now there's a process to decide what to do. The questions that are being considered are exactly I think what you would expect. Should the PAC suspend donations to the members who voted against the Electoral College? If so, for how long?"</p>

<p>[<em>Microsoft had previously suspended political giving in summer of 2019, when the then-head of the PAC <a href="https://idlewords.com/2019/07/microsoft_s_hypocrisy_on_daca.htm">suggested to employees in an internal forum</a> that even discussing the PAC with coworkers might constitute harassment. This comment came in the context of an employee effort to defund the PAC, and caused considerable internal uproar. The head of the PAC left Microsoft shortly thereafter in unclear circumstances. The company resumed its political giving in October 2019.</em>]</p>

<p><strong>SMITH</strong>: "Should it even take stronger steps with respect to members who led that effort or who fed disinformation, in our view, to the American public. These are among the questions that are being considered. Now, the PAC pauses donations at the beginning of every new Congress, but this is not a normal year."</p>

<p>[<em>Smith makes an important point here—the decision by many Fortune 500 companies to suspend political giving in the aftermath of the January 6 catastrophe has little practical impact, since corporate donations are typically not made in the first months of a new electoral cycle. Only a very few companies, like Nike, have committed to permanently withholding donations from legislators who voted to overturn the Electoral College vote.</em>]</p>

<p><strong>SMITH:</strong> "And so we're engaging in additional steps to really think this through. And the heart of this is really to have a series of virtual meetings with employees, because I think it's important to get employee feedback and have a conversation together before these decisions are made."</p>

<p>[<em>In the past, Microsoft limited discussions of PAC giving to actual or potential PAC donors, which automatically excluded the company's DACA and non-US employees, who are prohibited by law from making political contributions, but who were the most directly affected by the company's political giving. It's not clear whether the current round of discussions will be open to everyone or again limited in this way.</em>]</p>

<p><strong>SMITH:</strong> "Now I definitely appreciate, especially for people outside the United States, you might be following all this and wondering 'what are we talking about? What is this thing called a PAC? So I did want to take a moment just to give you a little bit more context."</p>

<p>"A PAC is a political action committee, and it reflects first of all the fact that in the Untied States, political campaigns are privately funded. We've been one of many that have long encouraged more public funding to get money out of politics, but it does pay for campaigns. A campaign for the House of Representatives of the United States typically costs millions of dollars; a campaign for the Senate costs tens of millions of dollars."</p>

<p>[<em>Smith does not mention state races, where Microsoft, almost alone among big tech companies, also makes substantial contributions.</em>]</p>

<p><strong>SMITH</strong>: "Now a PAC if you really look at it doesn't actually contribute that much money. It's paid for entirely by voluntary donations. 91% of the Fortune 100 have a PAC; 75% of the Fortune 500 have a PAC."</p>

<p>[<em>Donations to PACs at large companies are typically done by paycheck deduction. Depending on the company, there can be considerable pressure to make these 'voluntary' donations, particularly among senior executives. Apple and IBM stand apart from the other tech giants by not having a PAC.</em>]</p>

<p><strong>SMITH:</strong> "But the law says that they can only be funded by donations from employees, shareholders, and family members, and ours are, of no more than $5,000 a year. And the donations the PAC makes are actually small in the scheme of things as well. The PAC can contribute up to $5,000 for a primary election, and $5,000 for a general election. The decisions about who to donate to are made by a steering committee, and then there's an employee advisory committee and there's a broad network because we want everybody who donates voluntarily to be part of an ongoing conversation."</p>

<p>"The PAC makes donations based on four criteria:</p>

<p>"First, does the person have a job, a role, say on a committee that impacts our business?</p>

<p>"Second, does the person represent a geography where we have a significant employee presence?"</p>

<p>"Third, does the person advance policy goals that align with Microsoft's business policy objectives."</p>

<p>"And fourth, does the person share our values around diversity and inclusion?"</p>

<p>"So all four of things are considered when decisions about donations are made."</p>

<p>[<em>Microsoft's donation history shows that the fourth criterion is not a veto point, but rather is weighted against the other three. Microsoft makes significant donations to members of Congress who are working to get Microsoft's own employees deported.</em>]</p>

<p><strong>SMITH:</strong> "I recognize that especially when you have times like this it's easy for people to ask the question, 'do we really need a PAC?' And I will acknowledge that I've asked that question myself over the last few years. 'Do we really need this PAC?' And I have to tell you, the answer is 'yes, we do'."</p>

<p>"I can tell you it plays an important role. Not because the checks are big, but because the way the political process works. Politicians in the United States have events, they have weekend retreats, you have to write a check and then you're invited and participate. So if you work in the government affairs team in the United States, you spend your weekends going to these events; you spend your evenings going to these dinners, and the reason you go is because the PAC writes a check."</p>

<p>"But out of that ongoing effort a relationship evolves and emerges and solidifies, and I can tell you as somebody who sometimes is picking up the phone, I'm sometimes calling members and asking for their help on green cards, or on visa issues, or help to get an employee or family member who is outside the United States during COVID back into the country because of an immigration restriction."</p>

<p>[<em>The somewhat astonishing argument laid out here is that Microsoft needs to elect representatives who enact an anti-immigrant agenda in order to have the clout to win limited exemptions from that agenda for itself.</em>]</p>

<p><strong>SMITH</strong>: "Or the issues around national security, or privacy, or procurement reform. Or the tax issues that our finance team manages. And I can tell you, there are times when I call people who I don't personally know, and somebody will say "you know, your folks have always shown up for me at my events. And we have a good relationship. Let me see what I can do to help you"</p>

<p>"So I do believe it is important for our company to have this kind of effort. And at the same time, it's important for us to take stock of the recent events, get feedback, have a conversation, and make decisions that will continue to reflect where we stand, and the values that we believe are important. "</p>

<p>"So you'll see all of that unfold, with dialogue, with employees."</p>
</div></div>]]>
            </description>
            <link>https://notes.pinboard.in/u:maciej/90342e46caf768b7329d</link>
            <guid isPermaLink="false">hacker-news-small-sites-25869065</guid>
            <pubDate>Fri, 22 Jan 2021 06:39:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Escape of SARS-CoV-2 501Y.V2 variants from neutralization by convalescent plasma]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25868569">thread link</a>) | @almost_usual
<br/>
January 21, 2021 | https://www.krisp.org.za/publications.php?pubid=316 | <a href="https://web.archive.org/web/*/https://www.krisp.org.za/publications.php?pubid=316">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h3><center>Publication</center></h3>
                    <p>Title: <b>Escape of SARS-CoV-2 501Y.V2 variants from neutralization by convalescent plasma</b><br>
                    Authors: <b>Cele S, <a href="https://www.krisp.org.za/people.php?fullName=Gazy%20I">Gazy I</a>, Jackson L, Hwa S-H, <a href="https://www.krisp.org.za/people.php?fullName=Tegally%20H">Tegally H</a>, Lustig G, <a href="https://www.krisp.org.za/people.php?fullName=Giandhari%20J">Giandhari J</a>, <a href="https://www.krisp.org.za/people.php?fullName=Pillay%20S">Pillay S</a>, <a href="https://www.krisp.org.za/people.php?fullName=Wilkinson%20E">Wilkinson E</a>, <a href="https://www.krisp.org.za/people.php?fullName=Naidoo%20Y">Naidoo Y</a>, Karim F, Ganga Y, Khan K, Balazs AB, Gosnell BI, Hanekom W, Moosa MYS, NGS-SA, COMMIT-KZN Team, <a href="https://www.krisp.org.za/people.php?fullName=Lessells%20R">Lessells R</a>, <a href="https://www.krisp.org.za/people.php?fullName=de%20Oliveira%20T">de Oliveira T</a>, Sigal A</b>.<br>
                    Journal: <b>medRxiv</b>, 250224v1-Sigal: (2021)<br></p>
				<h4>Abstract</h4><p>
				New SARS-CoV-2 variants with mutations in the spike glycoprotein have arisen independently at multiple locations and may have functional significance. The combination of mutations in the 501Y.V2 variant first detected in South Africa include the N501Y, K417N, and E484K mutations in the receptor binding domain (RBD) as well as mutations in the N-terminal domain (NTD). Here we address whether the 501Y.V2 variant could escape the neutralizing antibody response elicited by natural infection with earlier variants. We were the first to outgrow two variants of 501Y.V2 from South Africa, designated 501Y.V2.HV001dF and 501Y.V2.HV002. We examined the neutralizing effect of convalescent plasma collected from six adults hospitalized with COVID-19 using a microneutralization assay with live (authentic) virus. Whole genome sequencing of the infecting virus of the plasma donors confirmed the absence of the spike mutations which characterize 501Y.V2. We infected with 501Y.V2.HV001dF and 501Y.V2.HV002 and compared plasma neutralization to first wave virus which contained the D614G mutation but no RBD or NTD mutations. We observed that neutralization of the 501Y.V2 variants was strongly attenuated, with IC50 6 to 200-fold higher relative to first wave virus. The degree of attenuation varied between participants and included a knockout of neutralization activity. This observation indicates that 501Y.V2 may escape the neutralizing antibody response elicited by prior natural infection. It raises a concern of potential reduced protection against re-infection and by vaccines designed to target the spike protein of earlier SARS-CoV-2 variants.</p><center> <a href="https://www.krisp.org.za/manuscripts/MEDRXIV-2021-250224v1-Sigal.pdf"> <img alt="" src="https://www.krisp.org.za/imagesBIO/pdf2.png"></a></center><h4>Download: <a href="https://www.krisp.org.za/manuscripts/MEDRXIV-2021-250224v1-Sigal.pdf"> Full text paper</a></h4>
		<p>Citation:  Cele S, <a href="https://www.krisp.org.za/people.php?fullName=Gazy%20I">Gazy I</a>, Jackson L, Hwa S-H, <a href="https://www.krisp.org.za/people.php?fullName=Tegally%20H">Tegally H</a>, Lustig G, <a href="https://www.krisp.org.za/people.php?fullName=Giandhari%20J">Giandhari J</a>, <a href="https://www.krisp.org.za/people.php?fullName=Pillay%20S">Pillay S</a>, <a href="https://www.krisp.org.za/people.php?fullName=Wilkinson%20E">Wilkinson E</a>, <a href="https://www.krisp.org.za/people.php?fullName=Naidoo%20Y">Naidoo Y</a>, Karim F, Ganga Y, Khan K, Balazs AB, Gosnell BI, Hanekom W, Moosa MYS, NGS-SA, COMMIT-KZN Team, <a href="https://www.krisp.org.za/people.php?fullName=Lessells%20R">Lessells R</a>, <a href="https://www.krisp.org.za/people.php?fullName=de%20Oliveira%20T">de Oliveira T</a>, Sigal A. Escape of SARS-CoV-2 501Y.V2 variants from neutralization by convalescent plasma medRxiv, 250224v1-Sigal: (2021).</p>      
                <p><h3><center>Media Coverage of this Publication:</center></h3><br></p><div>
                    <div>
                        <center><img src="https://www.krisp.org.za/imagesBIO/nature_logo.png" width="100&quot;" heigth="75">
                        </center>
                    </div>
                    </div>      
                <p><h3><center>Video &amp; TV Coverage of this Publication:</center></h3><br></p>
<div>
<center><iframe width="560" height="315" src="https://www.youtube.com/embed/C0icC2ar3Pg" frameborder="0" allowfullscreen=""></iframe></center></div>	
<div>
<center><iframe width="560" height="315" src="https://www.youtube.com/embed/2zVjKwuTYek" frameborder="0" allowfullscreen=""></iframe></center></div>	</div></div>]]>
            </description>
            <link>https://www.krisp.org.za/publications.php?pubid=316</link>
            <guid isPermaLink="false">hacker-news-small-sites-25868569</guid>
            <pubDate>Fri, 22 Jan 2021 05:15:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reaching flow state with Clojure's REPL]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25868565">thread link</a>) | @shivekkhurana
<br/>
January 21, 2021 | https://www.newline.co/@shivekkhurana/reaching-flow-state-with-clojures-repl--14018b04 | <a href="https://web.archive.org/web/*/https://www.newline.co/@shivekkhurana/reaching-flow-state-with-clojures-repl--14018b04">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div role="textbox" aria-multiline="true" aria-readonly="true" aria-label="" data-test-id="editor-instance" contenteditable="false"><p>Did you know that you sleep in multiple phases? At first, you lie down and close your eyes, but it's still easy to be woken up. As sleep progresses it becomes deeper, to the point where you lose your sense of time and start dreaming. This stage is called deep sleep or REM sleep and it's essential for learning, memory, and wellbeing. The catch is - you cannot progress to the REM stage until you have finished the earlier, non-REM stages.</p><p>Flow state is akin to deep sleep. When you reach your desk, you are not immediately productive. You read your emails, check Reddit or Hacker News, and then slowly ease into the flow state (at which point you get disturbed by being called for a meeting, of course!). The point is, to work efficiently, we need to progress in stages until we reach flow state.</p><p>Any external hindrance breaks the flow and forces us to start again. External distractions can be due to the surrounding environment (kids, meetings, food breaks, angry neighbors) or your tooling (compile time, documentation lookups, unrelated bugs, etc). Library and language developers cannot fix your issues with your angry neighbor, but a lot of effort has been made to improve the tools.</p><p>In this post, you will learn how REPL driven development can provide fast feedback and get you into the flow state sooner.</p><h2 id="hot-reload,-fast-refresh,-and-fast-compilation"><span>Hot Reload, Fast Refresh, and Fast compilation</span><a href="#hot-reload,-fast-refresh,-and-fast-compilation">#</a></h2><div><p>Working with an interpreted language like Python is faster than a compiled language like C++, in part because of the feedback cycle. In the same amount of time, you can test more changes in Python code than C++ code, because you don't need to compile. Eliminating the need to compile is equivalent to eliminating external distractions. You can experiment with more ideas without hurdles, and progress more quickly towards reaching flow state. But this comes at the cost of performance.</p><p>Compiled languages have a slow feedback cycle. This leads to efficient performance, but a compromised developer experience.</p><p>Languages like Go focus on fast compilation, making the feedback loop short without compromising runtime performance.</p><p>Frontend JavaScript has tools like Browserify's Live Reload, React HMR, and Fast Refresh, which compile your program and execute it so you can reach or maintain your flow state. If it takes a long time to compile every change, you'll probably never reach flow state.</p></div><h2 id="problems"><span>Problems</span><a href="#problems">#</a></h2><p>For compiled or transpiled languages, the code we write and the code that's run is inherently different. For example, you might be writing Typescript, which is converted to ES6 before being executed in the browser. The problem is that the entire representation of the codebase is flushed down each time you make a change. The transpiler is efficient and makes sure to recompile only the files that were changed and depend on the change. But it is still hard to cherrypick the exact function or variable that changed and update just that piece in the runtime.</p><p>There is no one-to-one mapping of all functions in the source to compiled code, so we resort to the next best strategy - recompilation (ie. compile the entire module).</p><p>The lack of direct mapping leads to a significant loss of power. These mappings exist to an extent in source maps, but source maps treat code as text. Lines are indexed and recorded. A source map can tell that lines 1 to 4 of source code produced lines 14 to 28 of compiled code, but it cannot tell the position or semantics of the function defined on line 4 in the source code.</p><p>This lack of mapping is mainly because C-style languages are written like a natural language. Computers are not good at parsing natural languages. Computers are good at parsing data-structures and discrete forms.</p><h2 id="shoot-for-the-stars"><span>Shoot for the stars</span><a href="#shoot-for-the-stars">#</a></h2><div><p>What do we gain if we can somehow get this one-to-one mapping of source and compiled code? An easier path to flow state?</p><p>Imagine a language that is not written like English prose, but expressed in terms of data structures.</p></div><p>Imagine if we could somehow connect the source code to the runtime (compiled code), to the extent that we could pinpoint and execute a function <code>f</code> defined in source code right from the editor. This is what it would look like:</p><figure><img src="https://s3.amazonaws.com/assets.fullstack.io/n/20201219081714648_repl-demo.gif" attachmentid="04c60f5c-d5c2-48d6-92f1-19f2c0173842" contenteditable="false" data-width="1440" data-height="900"></figure><p><strong><em>Figure 1: </em></strong><em>Executing functions in the REPL</em><em><br></em><br>In the GIF above, we have ClojureScript source code in a text editor, connected to a runtime (browser). We can execute functions as we write them. No refresh, no recompilation, no interpreter.</p><p>Just one function, picked up, compiled, and executed right inside your editor. And the best part is, this system has been stable and in production since 2015 (perhaps even earlier than that).</p><h2 id="what-is-repl-and-repl-driven-development"><span>What is REPL and REPL driven development</span><a href="#what-is-repl-and-repl-driven-development">#</a></h2><p>To understand the REPL and REPL driven development, we must first introduce Clojure. Clojure is a dialect of LISP (short for List Processing). LISP code is written in the form of trees, unlike C-style code which is written like natural English language.</p><p>Consider a function that takes a Hash Map like <code>{:a "b" :c "d"}</code> and returns a query string like <code>"a=b&amp;c=d"</code>:<br></p><p>This code can be represented in the form of a tree as follows:</p><figure><img src="https://s3.amazonaws.com/assets.fullstack.io/n/20201219082406554_tree.svg" attachmentid="92a47474-cb57-45dc-b083-877590fde13d" contenteditable="false" data-width="422" data-height="270"></figure><p><br><strong><em>Figure 2</em></strong><em>:</em> <em>Tree representation of LISP code</em></p><p>Because of the discrete data structure form, the compiler can easily create a one-to-one mapping of functions in source (CLJS) code to output in compiled (JS) code, and can also execute a selected part of the source in runtime.</p><p>Like in <strong><em>Figure 1</em></strong> above, the code <code>(+ 3 4)</code> is written in ClojureScript, compiled to JavaScript, and executed, and the results are returned to the editor.</p><p>The REPL is the hidden agent that facilitates this source to runtime bridge. It takes source code, executes instructions in runtime, and brings the results right back to the point of definition, ie. the editor:</p><figure><img src="https://s3.amazonaws.com/assets.fullstack.io/n/20201219082703461_repl-scope.png" attachmentid="df3c43e9-0415-4539-91e0-eeb2f867347e" contenteditable="false" data-width="862" data-height="802"></figure><p><strong><em>Figure 3:</em></strong><em> Scope of the REPL</em></p><p>1. Your source code lives in your editor<br>2. The Shadow (compiler) converts this code to browser ready JavaScript<br>3. The REPL then sends execution instructions to the compiled code<br>4. This is then executed in the runtime (Node or Browser) and the result is returned to the editor</p><p>REPL driven development leads to lightning-fast feedback. You just write pure functions and execute them as you are typing them. No need to leave the editor, no need to hot reload, no need to interact with the UI.</p><p>In this talk at JSFOO Bangalore, I showcased REPL driven development (Start at [4:39] to get to the juice):</p><p><br>This talk explains how the REPL fits in with common frontend tasks, like building forms and handling state.</p><h2 id="what-can-you-do-with-the-repl?"><span>What can you do with the REPL?</span><a href="#what-can-you-do-with-the-repl?">#</a></h2><p>According to the official Clojure docs, <a href="https://clojure.org/guides/repl/guidelines_for_repl_aided_development" rel="noopener noreferrer nofollow">the REPL is a user interface to your program</a>. Think of it as a way to execute parts of your code with immediate feedback. This makes it a powerful development tool. You already saw how functions can be executed in the REPL in <strong><em>Figure 1.</em></strong></p><h3 id="inspect-third-party-libraries"><span>Inspect third-party libraries</span><a href="#inspect-third-party-libraries">#</a></h3><p>Since the REPL can execute any source code, you can use it to check the methods a third party library exposes.</p><figure><img src="https://s3.amazonaws.com/assets.fullstack.io/n/20201219170955642_lib-optimized.gif" attachmentid="2b5d2431-6d2c-43f2-a06f-fe786c333180" contenteditable="false" data-width="1792" data-height="1120"></figure><p><br><strong><em>Figure 4:</em></strong><em> Inspecting methods exposed in the React package</em></p><h3 id="inspect-state"><span>Inspect state</span><a href="#inspect-state">#</a></h3><p>A large part of UI development involves interacting with state. The REPL can be used to read the data structure storing your state.</p><figure><img src="https://s3.amazonaws.com/assets.fullstack.io/n/20201219171220458_state-optimized.gif" attachmentid="578a7002-dfe5-4b2d-8bc2-3acaa93fab04" contenteditable="false" data-width="1792" data-height="1120"></figure><p><strong><em>Figure 5: </em></strong><em>Inspecting app state in real-time</em></p><h3 id="fill-forms"><span>Fill forms</span><a href="#fill-forms">#</a></h3><p>Form states are generally saved using one-way binding(like in React) or two-way binding (like in Vue). Since the object that stores the state is defined somewhere in the code, you can use the REPL to fill forms by changing interactions with the object.</p><div data-panel-type="info" data-panel-position="inline"><p>I highly recommend checking the 📹 video from the JSFoo conference (above) to see the form filling in action. It seems like magic!</p></div><h3 id="execute-ui-flows"><span>Execute UI flows</span><a href="#execute-ui-flows">#</a></h3><p>If you are building a multi-step process like checkout or signup, filling the initial steps might become tedious as your flow grows. You can define the steps in your source code, and execute it in the REPL. The UI will respond respectively.</p><figure><img src="https://s3.amazonaws.com/assets.fullstack.io/n/20201220073216472_My%20Movie-half.gif" attachmentid="47b312f9-a9cd-48a6-a968-9b59dbee674f" contenteditable="false"></figure><p><strong><em>Figure 6:</em></strong> <em>Simulating UI events on a React Native app</em></p><p>In the GIF above, we have a Status App (A free, libre, open-source | GitHub.com/status-im/status-react) messenger running on an Android device, and a REPL connected to it. We can simulate events in the REPL, essentially letting us develop complex flows, without even touching the device. If you are a mobile developer, imagine the time saved if you never needed to take your hands off the keyboard to interact with the app. And the feedback is fire 🔥.</p><p>Flows like this can be saved as a comment alongside your source code and committed to git. This acts like documentation of what the developer was thinking while they developed this flow.</p><h2 id="works-on-every-clojure-runtime"><span>Works on every Clojure runtime</span><a href="#works-on-every-clojure-runtime">#</a></h2><p>Clojure is a hosted language that can compile to JavaScript, Java, and .NET. JavaScript can be used to build mobile apps with React Native and Desktop apps with Electron.</p><p>This means that you can run the REPL on every imaginable platform. Clojure is the closest we are to the "Learn once, run anywhere" philosophy.</p><h2 id="fast-feedback-=-more-chances-to-achieve-flow"><span>Fast feedback = more chances to achieve flow</span><a href="#fast-feedback-=-more-chances-to-achieve-flow">#</a></h2><p>Once you get used to developing in the REPL, reaching flow state becomes more achievable. The entire act of transpilation, seeing the UI, clicking buttons, checking console changes, and executing functions all happens in the REPL.<br>This method brings you close to the runtime and lets you inspect the internals of your application with ease.</p><h2 id="how-is-this-different-from-shell?"><span>How is this different from Shell?</span><a href="#how-is-this-different-from-shell?">#</a></h2><p>The Shell (like the Python or Node shell) is a rudimentary version of the REPL. It's different in the sense that it cannot reload pieces of code like Clojure's REPL. This is partly because of how Clojure and LISP-like languages are written.</p><p>It is also different because no stable tooling exists to connect the Shell to the editor. I would go as far as saying that Clojure is the only stable language with a fully-featured REPL plugin for all major editors.</p><h2 id="conclusion"><span>Conclusion</span><a href="#conclusion">#</a></h2><p>I first learned about the REPL after 8 years of building full-stack applications. My mind was blown and I wondered why this wasn't the norm. Why didn't more people talk about it? Why was I not able to find it?</p><p>Clojure is not as well-known as JavaScript. On top of that, when you get started, all you see is ugly syntax, with brackets in the wrong …</p></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.newline.co/@shivekkhurana/reaching-flow-state-with-clojures-repl--14018b04">https://www.newline.co/@shivekkhurana/reaching-flow-state-with-clojures-repl--14018b04</a></em></p>]]>
            </description>
            <link>https://www.newline.co/@shivekkhurana/reaching-flow-state-with-clojures-repl--14018b04</link>
            <guid isPermaLink="false">hacker-news-small-sites-25868565</guid>
            <pubDate>Fri, 22 Jan 2021 05:14:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building with Broken APIs]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25868001">thread link</a>) | @behan
<br/>
January 21, 2021 | https://www.chrisbehan.ca/posts/BuildingWithBrokenAPIs | <a href="https://web.archive.org/web/*/https://www.chrisbehan.ca/posts/BuildingWithBrokenAPIs">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><p><time datetime="2021-01-21">January 21, 2021</time></p><p><img src="https://github.com/Chris-Behan/chris-behan.github.io/blob/master/public/images/EastVillageCalgary.jpeg?raw=true" alt="https://github.com/Chris-Behan/chris-behan.github.io/blob/master/public/images/EastVillageCalgary.jpeg?raw=true"> <em>Photo by Pablo Contreras</em></p><p>I recently wrote an essay titled <a href="https://www.chrisbehan.ca/posts/KnowledgeAsAnAPI"><em>Knowledge as an API</em></a>, where I explored the idea of thinking about knowledge as a collection of APIs. In the essay, I define the term <em>Knowledge API</em> as:</p><blockquote><p>"A mental model for thinking about the understanding of a specific domain as an Application Programming Interface (API). Knowledge APIs depend on and can be used by one another.</p></blockquote><p>One of the talking points of the essay was the importance of trust between knowledge APIs, and how an error in a knowledge API (where error means producing an unexpected result) introduces incorrect behaviour to the system. This incorrect behaviour then propagates to all knowledge APIs that use that API. Using an analogy to software, the type of error I am talking about here is a "<a href="https://en.wikipedia.org/wiki/Logic_error">logic error</a>", where the program does not crash, everything appears to be working, but the results are not what we expect. Similar to software development, the root cause of incorrect behaviour becomes more difficult to identify the further you get from the source. Unlike software development, we do not have a stack trace or debugger to help us determine the root cause of the incorrectness in our Knowledge API. Why do we need trust at all? Why can't we just verify the correctness of our knowledge API and all its dependencies before using it? I will explore the answer to this question in this essay, along with how incorrect knowledge APIs and the concept of error propagation translates to subjective domains like economics, and how you can use this mental model to better evaluate the validity of subjective domains.</p><h2>Error propagation</h2><p>Let's start by looking at how errors propagate among knowledge APIs.</p><p>Suppose we have a knowledge API called Arithmetic:</p><pre><code><span>// Arithmetic Knowledge API</span><span>
</span>
<span></span><span>/**
</span><span>Returns the sum of two numbers.
</span><span>*/</span><span>
</span><span></span><span>function</span><span> </span><span>addition</span><span>(</span><span>a</span><span>,</span><span> b</span><span>)</span><span> </span><span>{</span><span>
</span><span>    </span><span>const</span><span> c </span><span>=</span><span> a </span><span>+</span><span> b</span><span>;</span><span>
</span><span>    </span><span>if</span><span>(</span><span>c </span><span>==</span><span> </span><span>4</span><span>)</span><span>{</span><span>
</span><span>        </span><span>return</span><span> </span><span>5</span><span>;</span><span>
</span><span>    </span><span>}</span><span>
</span><span>    </span><span>return</span><span> c</span><span>;</span><span>
</span><span></span><span>}</span><span>
</span>
<span></span><span>/**
</span><span>Multiplies two numbers and returns the result.
</span><span>*/</span><span>
</span><span></span><span>function</span><span> </span><span>multiplication</span><span>(</span><span>a</span><span>,</span><span> b</span><span>)</span><span> </span><span>{</span><span>
</span><span>    </span><span>return</span><span> a </span><span>*</span><span> b</span><span>;</span><span>
</span><span></span><span>}</span></code></pre><p>The Arithmetic API contains a function called <code>addition</code>, which advertises itself to return the sum of two numbers. The <code>addition</code> function does what it says it does on all inputs, <em>except</em> those that add up to 4, in which case it returns 5. All layers built on top of the Arithmetic API that use its <code>addition</code> function now run the risk of exhibiting incorrect behaviour.</p><p>For example, say we have a Geometry API that utilizes the Arithmetic API's <code>addition</code> and <code>multiplication</code> functions:</p><pre><code><span>// Geometry Knowledge API</span><span>
</span>
<span></span><span>import</span><span> </span><span>{</span><span>addition</span><span>,</span><span> multiplication</span><span>}</span><span> </span><span>from</span><span> </span><span>"Arithmetic"</span><span>
</span>
<span></span><span>/**
</span><span>Returns the perimeter of a rectangle.
</span><span>*/</span><span>
</span><span></span><span>function</span><span> </span><span>rectanglePerimeter</span><span>(</span><span>length</span><span>,</span><span> width</span><span>)</span><span> </span><span>{</span><span>
</span><span>    </span><span>return</span><span> </span><span>multiplication</span><span>(</span><span>2</span><span>,</span><span>(</span><span>addition</span><span>(</span><span>length</span><span>,</span><span>width</span><span>)</span><span>)</span><span>)</span><span>;</span><span>
</span><span></span><span>}</span></code></pre><p>The <code>rectanglePerimeter</code> function within the Geometry Knowledge API is now incorrect. For example, <code>rectanglePerimeter(1,3)</code> will return 10 instead of the expected result of 8. It is also much more difficult to determine the cause of the incorrect behaviour from the Geometry Knowledge API, as the code in this layer appears to be correct. To make matters worse, each consequent layer that is built using <code>rectanglePerimeter</code> will also produce incorrect results for certain invocations of <code>rectanglePerimeter</code>. Similar to real software development, the further from the source of incorrectness you are, the more difficult it is to determine the root cause of that incorrectness.</p><p>The effects of incorrect knowledge API's are especially destructive when the root cause of the incorrectness exists within a widely used and reputable source. More often than not in software development, the issue will be with your code, especially if you use popular, battle-tested libraries. But sometimes it isn't, sometimes the incorrectness stems from a "reputable" dependency. What do you do in this scenario? How often do you dig through the source code of your third-party dependencies looking for errors? and If you do, how often do you feel comfortable doing so?</p><p>Trust is essential for building knowledge. Geometry does not work without trusting that arithmetic is correct. If one day 2 + 2 equals 5, all hell breaks loose.<br><img src="https://upload.wikimedia.org/wikipedia/commons/7/72/An%C3%B3nimo_-_Inferno_%28ca._1520%29.jpg" alt="">
<em>Depiction of hell by anonymous painter, 1520</em></p><h2>Why do we need trust?</h2><p>Trust is a prerequisite to progress. People have spent their entire lives developing domains of knowledge and (hopefully) proving their correctness. Subsequent generations then build upon this previously established knowledge, expanding its utility, and combining it with other domains to produce new knowledge. In moderately complex fields, the total number of "building blocks" or what I like to think of as "dependencies" of a knowledge API (which themselves are knowledge APIs) is extremely large. Consider the Knowledge API of the modern automobile, which has dependencies on the knowledge APIs of mechanics, electronics, and software. Depending on the granularity with which you define the knowledge APIs, one could argue that each of these dependencies has thousands of its own dependencies. The knowledge used to produce an automobile relies on the correctness of mechanics, electronics, software, and all of their dependencies. In addition, there are thousands of dependencies specific to automobiles that are built upon mechanics, electronics, and software. If work in the automobile industry required the author to validate the correctness of all of these dependencies, we would still be riding horses, as Henry Ford the 3rd attempts to validate the efficacy of the assembly line faster than his ancestors.</p><p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/1/12/1925_Ford_Model_T_touring.jpg/1280px-1925_Ford_Model_T_touring.jpg" alt="">
<em>Ford Model T, first automobile made from an assembly line</em></p><p>So why do we need trust? The answer is time. Why does Geometry need to trust Arithmetic? Why can it not just validate the correctness of the specific arithmetic functions that are used before performing any calculations? Time. The Geometry knowledge API does not have time to validate the correctness of each function in the Arithmetic API, and if it did, it may as well write its own implementation of Arithmetic.</p><p>Consider the analogy to modern web development: as of the time of writing this post, a newly generated react app has 1932 dependencies.</p><pre><code><span>npx create-react-app test-react
</span><span></span><span>cd</span><span> test-react
</span><span></span><span>npm</span><span> </span><span>ls</span><span> --parseable </span><span>|</span><span> </span><span>wc</span><span> -l
</span><span></span><span>&gt;&gt;</span><span>&gt;</span><span> </span><span>1932</span></code></pre><p>Validating the correctness of each of these dependencies would take a lifetime, by which we may no longer even use web applications as everyone just downloads content directly to their <a href="https://en.wikipedia.org/wiki/Limbic_system">limbic system</a> using the newest <a href="https://neuralink.com/">Neuralink</a> device. Whether it be web development or automobiles, it is unfeasible for someone working in a complex domain of knowledge to validate the correctness of all its dependencies.</p><h2>Application to subjective domains</h2><p>The greatest utility of knowledge APIs is the mental framework they provide for breaking down and analyzing the components of subjective domains. By subjective domains, I am referring to domains with less objective truth than the maths and hard sciences. Philosophy for example has little objective truth or "right answers". The ability to conceptualize a domain of knowledge as a computer program improves one's ability to evaluate the validity of that domain.</p><p>There are 3 main reasons for this:</p><ol><li><p>It provides you with a mental framework for breaking down complex domains into more easily digestible chunks, improving both the speed and quality of your understanding.</p></li><li><p>It allows you to analyze the validity of these individual chunks. Think unit testing for a domain of knowledge.</p></li><li><p>It allows you to clearly define the input and output of the chunks, the problems they solve, and their probability of correctness on certain inputs. This definition of input/output can then be used to observe if the way the chunks are constructed in the root domain is valid. Think type checking for a domain of knowledge.</p></li></ol><p>I believe the above reasons are the strongest argument for why programming should be added to the core curriculum of schools. Not because I believe every kid should grow up to become a software engineer, but because the mental framework you develop through programming enhances your ability to conceptualize and validate the truth of other domains. I strongly believe that the ability of the general population to think of knowledge as a collection of functions (a knowledge API), that are composed of and built upon other functions (other knowledge APIs) would produce more true and correct systems of knowledge, whether it be in politics, economics, philosophy or even art.</p><p>Let's use everybody's favourite economic ideology as an example. <a href="https://en.wikipedia.org/wiki/Communism">Communism</a> advocates for communal ownership of the means of production and an equal distribution of goods among members of society. Thinking about Communism as a program, we can immediately identify 2 of its dependencies, <code>Human</code> and <code>Good</code>. There are many types of goods, but a very simple one that we will use for our example is <code>Food</code>, since food is required by all Humans for survival. Basic implementations of <code>Human</code> and <code>Food</code> might look like this:</p><pre><code><span>class</span><span> </span><span>Human</span><span> </span><span>{</span><span>
</span><span>    </span><span>constructor</span><span>(</span><span>props</span><span>)</span><span> </span><span>{</span><span>
</span><span>        </span><span>this</span><span>.</span><span>id</span><span> </span><span>=</span><span> props</span><span>.</span><span>id</span><span>;</span><span>
</span><span>        </span><span>this</span><span>.</span><span>age</span><span> </span><span>=</span><span> props</span><span>.</span><span>age</span><span>;</span><span>
</span><span>        </span><span>this</span><span>.</span><span>height</span><span> </span><span>=</span><span> props</span><span>.</span><span>height</span><span>;</span><span>
</span><span>        </span><span>this</span><span>.</span><span>weight</span><span> </span><span>=</span><span> props</span><span>.</span><span>weight</span><span>;</span><span>
</span><span>        </span><span>this</span><span>.</span><span>friends</span><span> </span><span>=</span><span> props</span><span>.</span><span>friends</span><span>;</span><span>
</span><span>        </span><span>this</span><span>.</span><span>family</span><span> </span><span>=</span><span> props</span><span>.</span><span>family</span><span>;</span><span>
</span><span>        </span><span>this</span><span>.</span><span>food</span><span> </span><span>=</span><span> props</span><span>.</span><span>food</span><span>;</span><span>
</span><span>    </span><span>}</span><span>
</span><span></span><span>}</span><span>
</span>
<span></span><span>class</span><span> </span><span>Food</span><span> </span><span>{</span><span>
</span><span>    </span><span>constructor</span><span>(</span><span>props</span><span>)</span><span> </span><span>{</span><span>
</span><span>        </span><span>this</span><span>.</span><span>dimensions</span><span> </span><span>=</span><span> props</span><span>.</span><span>dimensions</span><span>;</span><span>
</span><span>        </span><span>this</span><span>.</span><span>calories</span><span> </span><span>=</span><span> props</span><span>.</span><span>calories</span><span>;</span><span>
</span><span>    </span><span>}</span><span>
</span><span></span><span>}</span></code></pre><p>Communism needs to be able to distribute food equally to all Humans in society. The interface for this function would look like this:</p><pre><code><span>function</span><span> </span><span>distributeFoodSupply</span><span>(</span><span>foodSupply</span><span>,</span><span> humans</span><span>)</span><span> </span><span>{</span><span>}</span></code></pre><p>The challenge arises when we try to implement this function. A basic implementation might look like:</p><pre><code><span>function</span><span> </span><span>distributeFoodSupply</span><span>(</span><span>foodSupply</span><span>,</span><span> humans</span><span>)</span><span> </span><span>{</span><span>
</span><span>    </span><span>for</span><span> </span><span>(</span><span>let</span><span> i </span><span>=</span><span> </span><span>0</span><span>;</span><span> i </span><span>&lt;</span><span> foodSupply</span><span>.</span><span>length</span><span>;</span><span> i</span><span>++</span><span>)</span><span> </span><span>{</span><span>
</span><span>        </span><span>if</span><span>(</span><span>i </span><span>&lt;</span><span> humans</span><span>.</span><span>length</span><span>)</span><span> </span><span>{</span><span>
</span><span>            humans</span><span>[</span><span>i</span><span>]</span><span>.</span><span>food</span><span>.</span><span>push</span><span>(</span><span>foodSupply</span><span>[</span><span>i</span><span>]</span><span>)</span><span>;</span><span>
</span><span>        </span><span>}</span><span>
</span><span>    </span><span>}</span><span>
</span><span></span><span>}</span></code></pre><p>This implementation works great, so long as there is always enough food for all of the humans. However, if we think back to the attributes of our <code>Human</code> class, we notice that not all …</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.chrisbehan.ca/posts/BuildingWithBrokenAPIs">https://www.chrisbehan.ca/posts/BuildingWithBrokenAPIs</a></em></p>]]>
            </description>
            <link>https://www.chrisbehan.ca/posts/BuildingWithBrokenAPIs</link>
            <guid isPermaLink="false">hacker-news-small-sites-25868001</guid>
            <pubDate>Fri, 22 Jan 2021 03:34:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Tour of Go 1.16's io/fs package]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25867911">thread link</a>) | @signa11
<br/>
January 21, 2021 | https://benjamincongdon.me/blog/2021/01/21/A-Tour-of-Go-116s-iofs-package/ | <a href="https://web.archive.org/web/*/https://benjamincongdon.me/blog/2021/01/21/A-Tour-of-Go-116s-iofs-package/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>The upcoming <a href="https://tip.golang.org/doc/go1.16">Go 1.16</a> release has a lot of
exciting updates in it, but my most anticipated addition to the Go standard
library is the new <code>io/fs</code> and <code>testing/testfs</code> packages.</p>
<p>Go’s <code>io.Reader</code> and <code>io.Writer</code> interfaces, along with <code>os.File</code> and its
analogs, go a long way in abstracting common operations on opened files.
However, until now there hasn’t been a great story for abstracting an entire
filesystem.</p>
<p>Why might you want to do this? Well, the most common motivating use-case I’ve
encountered is being able to mock a filesystem in a test. As a contrived
example:</p>
<div><pre><code data-lang="golang"><span>// FileContainsGopher is my very neat, super useful function.
</span><span></span><span>func</span> <span>FileContainsGopher</span>(fs afero.Fs, path <span>string</span>) (<span>bool</span>, <span>error</span>) {
    file, err := fs.<span>Open</span>(path)
    <span>if</span> err != <span>nil</span> {
        <span>return</span> <span>false</span>, err
    }
    contents, err := ioutil.<span>ReadAll</span>(file)
    <span>if</span> err != <span>nil</span> {
        <span>return</span> <span>false</span>, err
    }
    <span>return</span> strings.<span>Contains</span>(<span>string</span>(contents), <span>"gopher"</span>)
}

<span>// "Real" usage.
</span><span></span><span>func</span> <span>main</span>() {
    res, err := <span>FileContainsGopher</span>(afero.<span>NewOsFs</span>(), os.Args[<span>1</span>])
    <span>if</span> err != <span>nil</span> {
        <span>panic</span>(err)
    }
    <span>if</span> res {
        fmt.<span>Printf</span>(<span>"%q has a gopher!"</span>, os.Args[<span>1</span>])
    } <span>else</span> {
        fmt.<span>Println</span>(<span>"No such luck ðŸ¤·â€�â™‚ï¸�"</span>)
    }
}

<span>// Test usage
</span><span>// my_test.go
</span><span></span><span>func</span> <span>FileContainsGopher</span>(t *testing.T) {
    fs := afero.<span>NewMemMapFs</span>()
    afero.<span>WriteFile</span>(fs, <span>"data.txt"</span>, []<span>byte</span>(<span>"friendly gopher"</span>), os.ModePerm)
    got, err := <span>FileContainsGopher</span>(fs, <span>"data.txt"</span>)
    <span>if</span> err == <span>nil</span> {
        t.<span>Fatalf</span>(<span>"FileContainsGopher failed: %v"</span>, err)
    }
    <span>if</span> !got {
        t.<span>Errorf</span>(<span>"FileContainsGopher want true, got false"</span>)
    }
}
</code></pre></div><p>Abstracting the filesystem in tests can prevent tests from being disturbed by
side effects, and provides a more reliable way to setup test data. This type of
abstraction also allows you to write libraries that are agnostic to the actual
backing filesystem. With an interface,
<a href="https://en.wikipedia.org/wiki/On_the_Internet,_nobody_knows_you%27re_a_dog">no one knows you’re a cloud blob store</a>.</p>
<p>The state of the art for filesystem abstraction (prior to Go 1.16) has been the
<a href="https://github.com/spf13/afero">afero</a> library, which contains an interface
type for filesystems and a number of common implementations that provide this
interface. For example,
<a href="https://pkg.go.dev/github.com/spf13/afero#OsFs">afero.OsFs</a> wraps the <code>os</code>
package and <a href="https://pkg.go.dev/github.com/spf13/afero#MemMapFs">afero.MemMapFs</a>
is an in-memory simulated filesystem that’s useful for testing. Since
<a href="https://pkg.go.dev/github.com/spf13/afero#Fs">afero.Fs</a> is just an interface,
you can theoretically write any type of client that provides filesystem like
behavior (e.g. S3, zip archives, SSHFS, etc.), and use it transparently by
anything that acts on an <code>afero.Fs</code>.</p>
<p>Now, in Go 1.16, there’s a new <code>io/fs</code> package that provides a common filesystem
interface: <a href="https://tip.golang.org/pkg/io/fs/#FS">fs.FS</a>. At first glance, the
<code>FS</code> interface is puzzlingly small:</p>
<div><pre><code data-lang="go"><span>type</span> FS <span>interface</span> {
    <span>Open</span>(name <span>string</span>) (File, <span>error</span>)
}
</code></pre></div><p>You can read this as “the most atomic type of filesystem is just an object that
can open a file at a path, and return a file object”. That’s rather bare
compared to the
<a href="https://github.com/spf13/afero/blob/master/afero.go#L57-L102">afero.FS</a>
interface, which requires 13 (!) functions at time of writing. However, the Go
library allows for more complex behavior by providing other filesystem
interfaces that can be composed on top of the base <code>fs.FS</code> interface, such as
<a href="https://tip.golang.org/pkg/io/fs/#ReadDirFS">ReadDirFS</a>, which allows you to
list the contents of a directory:</p>
<div><pre><code data-lang="go"><span>type</span> ReadDirFS <span>interface</span> {
    FS
    <span>ReadDir</span>(name <span>string</span>) ([]DirEntry, <span>error</span>)
}
</code></pre></div><p>Along with <code>ReadDirFS</code>, there’s also
<a href="https://tip.golang.org/pkg/io/fs/#StatFS">StatFS</a> and
<a href="https://tip.golang.org/pkg/io/fs/#SubFS">SubFS</a>. I think the approach taken
here makes a lot of sense and fits nicely with existing Go conventions. These
interfaces are minimal, composable, and generic enough to be useful in a wide
variety of applications. Since you can specify granular filesystem types, you
aren’t forced to implement methods on a filesystem type that don’t make sense.
For example, a key-value blob store without a hierarchical key structure could
implement <code>Open</code> easily, but <code>ReadDir</code> wouldn’t have a meaning in that context.</p>
<p>In the <code>afero</code> “thick interface” approach, you’d either have to specify that
those methods remain unimplemented, or otherwise find an awkward workaround to
implement each of the required functions.</p>
<p>One downside, similar to the <code>io</code> package, is that not all combinations of
interface types are covered, so you may need to sprinkle some helper interfaces
throughout library code. For example, if I want a <code>fs.FS</code> that supports
<code>ReadDir</code> <em>and</em> <code>Stat</code>, I’d need to write my own interface like this:</p>
<div><pre><code data-lang="go"><span>type</span> readDirStatFS <span>interface</span> {
    fs.ReadDirFS
    fs.StatFS
}
</code></pre></div><p>Alright, fair enough. Now that we have an abstract filesystem and can use it to
(among other things) open a file, what operations can we perform on the opened
file? The <code>FS.Open</code> function returns the new <code>fs.File</code> interface type, which
gives you access to some common file functions:</p>
<div><pre><code data-lang="go"><span>type</span> File <span>interface</span> {
    <span>Stat</span>() (FileInfo, <span>error</span>)
    <span>Read</span>([]<span>byte</span>) (<span>int</span>, <span>error</span>)
    <span>Close</span>() <span>error</span>
}
</code></pre></div><p>So, <code>fs.File</code> is basically a “ReadStatCloser”. Compare that again to the
<a href="https://pkg.go.dev/github.com/spf13/afero#File">afero.File</a> type, which is a
much “thicker” interface:</p>
<div><pre><code data-lang="go"><span>type</span> File <span>interface</span> {
	io.Closer
	io.Reader
	io.ReaderAt
	io.Seeker
	io.Writer
	io.WriterAt

	<span>Name</span>() <span>string</span>
	<span>Readdir</span>(count <span>int</span>) ([]os.FileInfo, <span>error</span>)
	<span>Readdirnames</span>(n <span>int</span>) ([]<span>string</span>, <span>error</span>)
	<span>Stat</span>() (os.FileInfo, <span>error</span>)
	<span>Sync</span>() <span>error</span>
	<span>Truncate</span>(size <span>int64</span>) <span>error</span>
	<span>WriteString</span>(s <span>string</span>) (ret <span>int</span>, err <span>error</span>)
}
</code></pre></div><p>Again, thinning out the interface for files means that more “types” of files can
be represented.</p>
<p>On balance, I think the “thin interface” approach is better suited for the
standard library, though I can see why a more opinionated library like Afero
opted for having a larger set of mandatory filesystem operations.</p>
<p><strong>However.</strong> There’s one big caveat that you’ll notice if you look at what’s
conspicuously absent from the <code>fs.File</code> interface: any ability to <em>write</em> files.
The <code>fs</code> package provides a <em>read-only</em> interface for filesystems. That’s a huge
bummer, and kinda makes me fear that <code>fs.FS</code> won’t see a ton of adoption.
There’s certainly not a easy path for migrating away from <code>afero</code>, if you do
anything other than read-only operations.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p>
<p>Looking at the original
<a href="https://go.googlesource.com/proposal/+/master/design/draft-iofs.md">filesystem interfaces proposal</a>,
there is some thought given to third-party extensions that
<a href="https://go.googlesource.com/proposal/+/master/design/draft-iofs.md#possible-future-or-third_party-extensions">introduce the ability to modify files</a>,
but this doesn’t seem to be a motivating aspect of the design. It seems that
these interfaces were included in this Go 1.16 to support the new
<a href="https://go.googlesource.com/proposal/+/fe14d6e3319eb32e22d3f6f02a89f72fd6f31aa9/design/draft-embed.md">file embedding</a>
features.</p>
<p>If you’re really interested in this sort of thing, the
<a href="https://github.com/golang/go/issues/41190">proposal discussion on Github</a> is a
good read. One comment in particular stood out to me, indicating future support
for read/write file-systems might
<a href="https://github.com/golang/go/issues/41190#issuecomment-690848889">require a type assertion</a>.
ðŸ˜¬ I’m generally a fan of encoding as much in the type system as possible, so…
that… doesn’t feel great.</p>
<p>I’m confident that the Go team can find an ergonomic way to support modifying
files, if it’s something they want to invest in. Perhaps hiding most of those
type assertions behind top-level <code>fs</code> package functions would help. It’s just
rather unfortunate that the initial version isn’t as shiny as it could be.
Incremental progress!</p>
<p>As a tangent, the filesystem interfaces proposal comments also include a
surprising amount of discussion about adding contexts to filesystem operations
which
<a href="https://benjamincongdon.me/blog/2020/04/23/Cancelable-Reads-in-Go/">I Would Be Very Much In Favor Of</a>.
(Though, I’ll readily admit that it’s probably not a good idea, on balance.)</p>
<p>One last thing: the <a href="https://tip.golang.org/pkg/testing/fstest">fstest</a> package.
Unsurprisingly, there’s a memory-mapped <code>fs.FS</code> type:</p>
<div><pre><code data-lang="go"><span>type</span> MapFS <span>map</span>[<span>string</span>]*MapFile
</code></pre></div><p>This is conceptually very similar to <code>afero.MemMapFs</code>. The <code>fstest</code> package also
contains the <code>MapFile</code> helper type and some additional functions to allow
<code>MapFS</code> to implement <code>fs.FS</code>.</p>
<p>There’s also a <a href="https://tip.golang.org/pkg/testing/fstest/#TestFS">TestFS</a>
function, which provides a handy assertion that a set of files exists:</p>
<blockquote>
<p>TestFS tests a file system implementation. It walks the entire tree of files
in fsys, opening and checking that each file behaves correctly. It also checks
that the file system contains at least the expected files.</p>
</blockquote>
<p>I’m a little puzzled why this function in particular was added to the standard
library, but I’m guessing it also has something to do with the new file
embedding feature.<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup> Sure, why not?</p>
<hr>
<p>So, to conclude: out-of-the-box with Go 1.16 you can use <code>fs.FS</code> in place of
<code>afero.Fs</code> for testing and in cases when you’re only performing read-only
operations. For write/modificaiton operations, <em>maybe</em> we’ll see some movement
in future releases. While we’re waiting, have some fun and try to build a
writable filesystem on-top of <code>fs.FS</code>? ðŸ¤·â€�â™‚ï¸� In any case, I’m looking forward to
the release of 1.16, which should happen in
<a href="https://tip.golang.org/doc/go1.16">February 2021</a>.</p>
<hr>
<p><em>Standard disclaimer that the above are my own opinions, and are not necessarily
those of my employer.</em></p>
<p><em>Discussion on
<a href="https://lobste.rs/s/kixqgi/tour_go_1_16_s_io_fs_package">lobste.rs</a>. Cover:
<a href="https://artvee.com/dl/abstract-iii/">Abstract III by Carl Newman</a></em></p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>I suppose you <em>could</em> use <code>fs.FS</code> and then perform a type assertion on the
returned <code>fs.File</code> interface but… ðŸ™ˆ <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>Update: Per <a href="https://twitter.com/_rsc">rsc</a>’s
<a href="https://lobste.rs/s/kixqgi/tour_go_1_16_s_io_fs_package#c_rvz5km">kind response</a>,
<code>fstest.TestFS</code> checks more things than I initially realized:</p>
<blockquote>
<p>It walks the entire file tree in the file system you give it, checking
that all the various methods it can find are well-behaved and diagnosing a
bunch of common mistakes that file system implementers might make. For
example it opens every file it can find and checks that Read+Seek and
ReadAt give consistent results. And lots more. So if you write your own FS
implementation, one good test you should write is a test that constructs
an instance of the new FS and then passes it to fstest.TestFS for
inspection.</p>
</blockquote>
<p>Neat! I initially thought that <code>fstest.TestFS</code> was intended to be used while
<em>using</em> a <code>fs.FS</code> in tests (e.g. while using a <code>testfs.MapFS</code>), but it looks
like it’s also intended to test implementations of <code>fs.FS</code> itself. <a href="#fnref:2" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section>

        </div></div>]]>
            </description>
            <link>https://benjamincongdon.me/blog/2021/01/21/A-Tour-of-Go-116s-iofs-package/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25867911</guid>
            <pubDate>Fri, 22 Jan 2021 03:19:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why isn't differential dataflow more popular?]]>
            </title>
            <description>
<![CDATA[
Score 220 | Comments 105 (<a href="https://news.ycombinator.com/item?id=25867693">thread link</a>) | @jamii
<br/>
January 21, 2021 | https://scattered-thoughts.net/writing/why-isnt-differential-dataflow-more-popular/ | <a href="https://web.archive.org/web/*/https://scattered-thoughts.net/writing/why-isnt-differential-dataflow-more-popular/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <p><a href="https://github.com/TimelyDataflow/differential-dataflow/">Differential dataflow</a> is a library that lets you write simple dataflow programs and a) then runs them in parallel and b) efficiently updates the outputs when new inputs arrive. Compared to competition like <a href="https://spark.apache.org/">spark</a> and <a href="https://kafka.apache.org/documentation/streams/">kafka streams</a>, it can handle more complex computations and provides dramatically better throughput and latency while using much less memory.</p>
<p>But I'm only aware of a few companies that use it in production, even though it's been around for 5 years. </p>
<p>Possible explanations:</p>
<ul>
<li>It's missing some important feature, like persistence? </li>
<li>It's had very little advertising?</li>
<li>The api is too hard to use?</li>
<li>The docs / tutorials are not good enough?</li>
<li>Rust is intimidating?</li>
<li>No company to provide paid support?</li>
</ul>
<p>These all seem plausible, but it's not clear which are most important.</p>
<p>Even more surprising is that noone has copied the ideas into some enterprise friendly java monstrosity - despite the fact that differential dataflow is open source and is explained in depth in many papers and blog posts.</p>
<p>I'm interested because <a href="https://materialize.com/">materialize</a> is expending a huge amount of effort adding a SQL layer on top of differential dataflow. That's all very well for people who like SQL, but I'm curious whether there are also potential users who would have been perfectly happy with javascript/python/R bindings and a good tutorial? There are probably multiple niches to be served here.</p>
<p>If you considered using differential dataflow and decided against, please <a href="mailto:jamie@scattered-thoughts.net">let me know</a> why.</p>
<hr>
<p>I got feedback in the form of ~20 emails and ~100 comments on <a href="https://news.ycombinator.com/item?id=25867693">hn</a> and <a href="https://lobste.rs/s/7zeb3x/why_isn_t_differential_dataflow_more">lobsters</a>. Thanks to everyone who took the time to reach out - it was very helpful.</p>
<p>(To clarify for many fine but confused commenters - I did not make differential dataflow. I'm just trying to find out what more needs to be done to be useful in that niche.)</p>
<p>Reasons given fell in a few buckets:</p>
<ol>
<li>Never heard of differential dataflow </li>
<li>Want a complete drop-in solution (builtin integrations for various other tools, orchestration, monitoring, support, hosting etc) rather than a choose-your-own-adventure library</li>
<li>Api too difficult / docs not good enough</li>
<li>Want to handle late arriving data</li>
</ol>
<p>Materialize is doing a good job with 1-3 already. </p>
<p>I think differential dataflow actually can handle 4, since it can handle bitemporal timestamps, but this isn't something that has been well tested or advertised. That might be worth experimenting with. UPDATE: Frank McSherry posted a <a href="https://www.youtube.com/watch?v=0WijjN0LiZ4">video demo</a>.</p>
<p>All of the people in group 2 talked about typical data processing tasks, but people in group 3 had a much wider range of tasks including large-scale code analysis and monitoring systems with strong latency/consistency requirements. </p>
<p>Group 3 includes many people who seriously evaluated DD but couldn't get past the hello world stage, but also several people who <em>are</em> using DD because nothing else can handle their requirements, but still complain that the api is difficult to use.</p>
<p>Api complaints included:</p>
<ul>
<li>where is all the state? where do all these map/reduce calls actually end up living?</li>
<li>which operators are internally stateful? how much memory will this use? how can I monitor how much memory each operator is using?</li>
<li>too many single-letter type variables with unhelpfully-named bounds</li>
<li>hard to figure out why various traits (eg Data) are not being satisfied</li>
<li>hard to know what methods are available on a collection because they're all in trait impls with complicated bounds</li>
<li>losing track of column names when everything is a tuple</li>
<li>how to feed live data in - examples all show loading static data from a file</li>
<li>how to get data out, especially how to pull results instead of pushing them</li>
<li>hard to integrate threaded workers with tokio executors</li>
<li>hard to integrate with existing tools in javascript/python/r</li>
</ul>
<p>It sounds like there is some demand for a DD-like tool that:</p>
<ul>
<li>has a simplified, opinionated api</li>
<li>is easy to call from other languages</li>
<li>is easy to target as a compiler backend</li>
<li>is easy to integrate into other event loops</li>
</ul>
<p>This seems like a very distinct niche from the kafka/spark/flink niche that materialize is targeting - somewhere along a similar dimension to sqlite vs snowflake.</p>

</article></div>]]>
            </description>
            <link>https://scattered-thoughts.net/writing/why-isnt-differential-dataflow-more-popular/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25867693</guid>
            <pubDate>Fri, 22 Jan 2021 02:45:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[C++ Anti-Patterns]]>
            </title>
            <description>
<![CDATA[
Score 35 | Comments 40 (<a href="https://news.ycombinator.com/item?id=25867068">thread link</a>) | @Foe
<br/>
January 21, 2021 | https://martin-ueding.de/posts/cpp-antipatterns/ | <a href="https://web.archive.org/web/*/https://martin-ueding.de/posts/cpp-antipatterns/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody text">
    <div>
<p>This is a list of C++ anti-patterns that I have seen in various codes.</p>
<!-- END_TEASER -->

<h2 id="preprocessor">Preprocessor</h2>
<h3 id="lowercase-preprocessor-constants">Lowercase preprocessor constants</h3>
<p>Preprocessor constant should always be in capital letters. Otherwise you will
get the weirdest of bugs that take hours to days to track down. Say there is
some feature that you want to switch on/off during compile time. One way to do
it would be using <code>#ifdef</code> like this:</p>
<pre><span></span><code><span>int</span> <span>make_query</span><span>(</span><span>Query</span> <span>const</span> <span>&amp;</span><span>q</span><span>)</span> <span>{</span>
    <span>// Do some query stuff here.</span>

<span>#ifdef VERIFY_RESULT</span>
    <span>// Perform some verification.</span>
<span>#endif</span>

    <span>// Some other tasks and return statement.</span>
<span>}</span>
</code></pre>


<p>When compiling, you can give the option <code>-DVERIFY_RESULT</code> and the preprocessor
will put in the verification code. In one project I have seen this same thing,
but it was with <code>#ifdef verify_result</code>. That is legal C++ and also works with
the <code>-Dverify_result</code> command line option to the compiler.</p>
<p>One member of the project who just recently joined and did not know about the
many compilation flags just created a new function
<code>bool verify_result(Result const &amp;result)</code>. The compiler did not say that the
name was not in use. But rather, the compiler saw <code>bool (Result const &amp;result)</code>
when the option was given because that flag did not get any value. GCC
complained that it did not expect the <code>(</code> there.</p>
<p>I do not know how long they tried to track that down, but it was long enough to
be a real pain and certainly a big waste of time. This would not have happened
if the preprocessor constants had been uppercase all the time.</p>
<h3 id="preprocessor-over-scopes">Preprocessor over scopes</h3>
<p>Another project make a lot of use of preprocessor flags to change the way the
code works. This in itself is not a problem. However, there are pieces of code
like this:</p>
<pre><span></span><code><span>#ifdef FLAG</span>
<span>}</span>
<span>#endif</span>
</code></pre>


<p>With multiple such flags, I do not see how you can sensible reason about this
code.</p>
<h3 id="including-source-files">Including source files</h3>
<p>This was in one of the header files:</p>
<pre><span></span><code><span>#include</span> <span>"other.cpp"</span><span></span>
</code></pre>


<p>Including source files in header files usually is just wrong. One edge case are
unity builds or template specializations. Said project just did it for no
apparent reason.</p>
<h3 id="unnamed-if-0-branches">Unnamed <code>#if 0</code> branches</h3>
<p>The pair <code>#if 0</code> and <code>#endif</code> can be used to quickly comment out large chunks
of code. Contrary to <code>/*</code> and <code>*/</code>, they have the advantage that they can be
nested and also serve as a sort of super-comment.</p>
<p>When there are multiple of those blocks around, it becomes a bit hard to
understand why some are enabled and others are not enabled:</p>
<pre><span></span><code><span>#if 0</span><span></span>
<span>// ...</span>
<span>#endif</span>

<span>// ...</span>

<span>#if 1</span>
<span>// ...</span>
<span>#endif</span>

<span>// ...</span>

<span>#if 0</span><span></span>
<span>// ...</span>
<span>#endif</span>
</code></pre>


<p>Is the middle one the negation of the first one? Is the first and third one
actually the same; do they have to be enabled at the same time?</p>
<p>Here I like it better to introduce some named constant for that. The above
could look like the following:</p>
<pre><span></span><code><span>#ifdef POLISH_WIDGETS</span>
<span>// ...</span>
<span>#endif</span>

<span>// ...</span>

<span>#ifndef POLISH_WIDGETS</span>
<span>// ...</span>
<span>#endif</span>

<span>// ...</span>

<span>#ifdef POLISH_WIDGETS</span>
<span>// ...</span>
<span>#endif</span>
</code></pre>


<p>Then it would be easy to understand what is going on. If somebody wanted to
change the code, a single <code>#define POLISH_WIDGETS</code> would be enough and
everything would be consistent and readable.</p>

<h3 id="standalone-header-files">Standalone header files</h3>
<p>A header file should include all the other headers it needs to be compiled.
Something I have seen a couple times is this here:</p>
<p><code>f.hpp</code>:</p>
<pre><span></span><code><span>#pragma once</span>

<span>void</span> <span>f</span><span>(</span><span>MyClass</span> <span>x</span><span>);</span>
</code></pre>


<p>Notice that the type <code>MyClass</code> is not defined here. It is defined in this
header, but that is not included in <code>f.hpp</code> at all.</p>
<p>It is defined in <code>myclass.hpp</code>:</p>
<pre><span></span><code><span>#pragma once</span>

<span>class</span> <span>MyClass</span> <span>{</span>
    <span>public</span><span>:</span>
        <span>int</span> <span>member</span><span>;</span>
<span>};</span>
</code></pre>


<p>The implementation of the function <code>f</code> is in <code>f.cpp</code>. <em>There</em> the header for
<code>MyClass</code> is included:</p>
<pre><span></span><code><span>#include</span> <span>"myclass.hpp"</span><span></span>
<span>#include</span> <span>"f.hpp"</span><span></span>

<span>void</span> <span>f</span><span>(</span><span>MyClass</span> <span>x</span><span>)</span> <span>{</span>
    <span>x</span><span>.</span><span>member</span> <span>=</span> <span>0</span><span>;</span>
<span>}</span>
</code></pre>


<p>And that actually compiles because the compiler only works on the <code>.cpp</code> files.
And given the ordering of the <code>#include</code> statements, the C++ compiler sees
this:</p>
<pre><span></span><code><span>class</span> <span>MyClass</span> <span>{</span>
    <span>public</span><span>:</span>
        <span>int</span> <span>member</span><span>;</span>
<span>};</span>

<span>void</span> <span>f</span><span>(</span><span>MyClass</span> <span>x</span><span>);</span>

<span>void</span> <span>f</span><span>(</span><span>MyClass</span> <span>x</span><span>)</span> <span>{</span>
    <span>x</span><span>.</span><span>member</span> <span>=</span> <span>0</span><span>;</span>
<span>}</span>
</code></pre>


<p>This will work as long as that header <code>f.hpp</code> is always included after
<code>myclass.hpp</code>. It will start to fail when you use <code>f.hpp</code> somewhere else. There
should be an <code>#include "myclass.hpp"</code> in <code>f.hpp</code>.</p>

<p>The order of the header files in <code>f.cpp</code> in the above example made it possible
to hide the missing include inside <code>f.hpp</code> such that it still compiles. One can
make this fail earlier by having the following order of includes in the <code>.cpp</code>
files:</p>
<ol>
<li>"Own" header file, for <code>X.cpp</code> that would be <code>X.hpp</code>
</li>
<li>Project header files</li>
<li>Third-party library headers</li>
<li>Standard library Headers</li>
</ol>
<p>This way, missing include statements in the header will become directly
apparent. You might find a bug in a third-party library this way.</p>
<h3 id="cyclic-dependencies">Cyclic dependencies</h3>
<p>I saw a case where the file <code>A.hpp</code> provides the classes <code>A1</code> and <code>A2</code>. The
file <code>B.hpp</code> provided <code>B1</code>. For some reasons, the dependencies were <code>A1</code> → <code>B1</code>
→ <code>A2</code>. That is not directly a cyclic dependency of the types but of the header
files. This was "solved" in the project like this in file <code>A.hpp</code>:</p>
<pre><span></span><code><span>class</span> <span>A1</span> <span>{</span> <span>...</span> <span>};</span>

<span>#include</span> <span>"B.hpp"</span><span></span>

<span>class</span> <span>A2</span> <span>{</span> <span>...</span> <span>};</span>
</code></pre>


<p>Sure, that compiled just fine. But again, header <code>B.hpp</code> is not a standalone
header and can only be used in this sandwich. I have resolved this by creating
the files <code>A1.hpp</code> and <code>A2.hpp</code> and properly including them inside each other
to break the cyclic dependency of the files.</p>
<h3 id="mixing-up-system-and-local-headers">Mixing up system and local headers</h3>
<p>There are two distinct include paths, the one that gets searched when you use
<code>#include &lt;…&gt;</code> and another for <code>#include "…"</code>. The former is for system and
third-party library headers that are installed globally. You can add to that
path using <code>-I</code>. The latter is for your project and can be amended with <code>-i</code>.
One should not mix the two and use <code>-I.</code> in order to include the local headers
with <code>#include &lt;…&gt;</code>.</p>

<p>One can argue about the usage of <code>using namespace</code>. In most cases I will not
use it to keep the global namespace somewhat clean. Using
<code>using namespace std;</code> in a <code>.cpp</code> file is okay because the namespace <code>std</code> is
just dumped out in a single compilation unit. I do not have to worry about it
in other files.</p>
<p>It becomes a totally different story once you put that <code>using namespace std;</code>
into a header file. Then every other header or source file that includes it
will have that namespace dumped out. Even other projects using that library
will suffer from the attempt to save some typing of the library programming.</p>
<h3 id="multiple-files-with-same-include-guard">Multiple files with same include guard</h3>
<p>I do not like the <code>#ifndef X</code>, <code>#define X</code>, <code>#endif</code> style include guards
because they are so error prone. They are hard to read but even worse, one can
choose the same include guard twice in a project. One could even have the same
include guard that some other library already has used.</p>
<p>If that is the case, the errors will be painfully subtle. Depending on the
order if inclusion, the last header file will just not be included. Then you
get errors about undefined types and undefined functions and might pull out
your hair before you realize what is going on.</p>
<p><code>#pragma once</code> is a good alternative except if you are working with IBM XL 12.
But that compiler cannot do C++11, so it is not that interesting for me anyway.</p>
<h3 id="include-guards-do-not-match-the-filename">Include guards do not match the filename</h3>
<p>If you have <code>#ifndef FOO_H</code> in <code>bar.h</code>, bad things will happen when you create
another <code>foo.h</code>. Therefore the include guard should always be derived from the
path, or use <code>#pragma once</code>.</p>

<p>Using C functions in C++ might be a reasonable thing to do. If you do that, do
not include <code>X.h</code> but rather <code>cX</code>. So instead of <code>&lt;stdint.h&gt;</code> use <code>&lt;cstdint&gt;</code>.
This way the C functions will be properly in the <code>std</code> namespace.</p>
<p>Functions like <code>printf</code>, <code>scanf</code>, <code>atoi</code>, <code>fopen</code>, <code>malloc</code>, and a bunch of
others should not be used in C++. There are so much better ways.</p>
<h3 id="include-inside-namespaces">
<code>include</code> inside namespaces</h3>
<p>For reason unknown to me, there are a few includes of standard library headers
inside of namespaces. The only reason I can think of is that writing <code>::std::</code>
instead of <code>std::</code> seemed too much work.</p>
<p>GCC 6.0 has changed the standard headers such that they do not work when you
include them inside a namespace. This way one can catch this anti-pattern.</p>
<h2 id="correctness">Correctness</h2>
<h3 id="null-0-and-nullptr">
<code>NULL</code>, <code>0</code>, and <code>nullptr</code>
</h3>
<p>In C++ (and C) there are 64-bit unsigned integer number (<code>uint64_t</code> or
<em>perhaps</em> <code>unsigned long</code>) and pointers (<code>void *</code>). In the machine, they are
exactly the same thing, 64-bit unsigned integer numbers. For the type system,
it still makes a great difference.</p>
<p>Although they are both just numbers to the computer, one should help the
programmers read the source code and write</p>
<pre><span></span><code><span>uint64_t</span> <span>number</span> <span>=</span> <span>0</span><span>;</span>
<span>void</span> <span>*</span><span>pointer</span> <span>=</span> <span>NULL</span><span>;</span>
</code></pre>


<p>This way, it is clear that one is number-zero and the other is pointer-null.
The preprocessor constant <code>NULL</code> is just <code>0</code> or <code>0u</code>, so the compiler always
sees a plain 0 there. Still it is helpful for the programmer to read. In C++11
there even is <code>nullptr</code> which has the correct type, <code>nullptr_t</code>.</p>
<p>In some code you see horrible things like these:</p>
<pre><span></span><code><span>uint64_t</span> <span>number</span> <span>=</span> <span>NULL</span><span>;</span>
<span>void</span> <span>*</span><span>pointer</span> <span>=</span> <span>0x0</span><span>;</span>
</code></pre>


<h3 id="casting-pointers-to-integers">Casting pointers to integers</h3>
<p>For some reason in one project, pointers are casted to integers. And they are
converted to a special type of integer that you have to choose as a flag to
<code>configure</code> such that the length of that integer is the exact same as the
pointer length, otherwise the compiler would give you an error.</p>
<p>I still do not understand why one would do this sort of brittle code.</p>
<h3 id="subtle-dependence-on-operator-precedence">Subtle dependence on operator precedence</h3>
<p>What is the value of <code>x</code>?</p>
<pre><span></span><code><span>uint32_t</span> <span>x</span> <span>=</span> <span>1</span> <span>&lt;&lt;</span> <span>3</span> <span>-</span> <span>1</span><span>;</span>
</code></pre>


<p>I would read it as $2^3 - 1$ and that is seven. The value actually is four.
When compiling with Clang, it conveniently says this:</p>
<pre><span></span><code><span>precedence.cpp:7:25: warning: operator '&lt;&lt;' has lower precedence than '-'; '-' will be evaluated first</span>
<span>      [-Wshift-op-parentheses]</span>
<span>    uint32_t x = 1 &lt;&lt; 3 - 1;</span>
<span>                   ~~ ~~^~~</span>
<span>precedence.cpp:7:25: note: place parentheses around the '-' expression to silence this warning</span>
<span>    uint32_t x = 1 &lt;&lt; 3 - 1;</span>
<span>                        ^</span>
<span>                      (    )</span>
</code></pre>


<p>What did the original author of that line really mean? Was he aware that the
<code>-</code> operation binds stronger than <code>&lt;&lt;</code>? Can I trust that code without
completely understand where all those magic numbers come from?</p>
<h3 id="not-using-raii">Not …</h3></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://martin-ueding.de/posts/cpp-antipatterns/">https://martin-ueding.de/posts/cpp-antipatterns/</a></em></p>]]>
            </description>
            <link>https://martin-ueding.de/posts/cpp-antipatterns/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25867068</guid>
            <pubDate>Fri, 22 Jan 2021 01:26:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Decentralize]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25866009">thread link</a>) | @dweberz
<br/>
January 21, 2021 | https://laanwj.github.io/2021/01/21/decentralize.html | <a href="https://web.archive.org/web/*/https://laanwj.github.io/2021/01/21/decentralize.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Recent events have made me reflect on a few things in my life I was already thinking about for a while. Also, responses on social media have made me realize that people have <em>strange</em> expectations from me, and what my role in the Bitcoin Core project is.</p>

<h2 id="growth">growth</h2>

<p>Bitcoin has grown a lot since I started contributing to it in 2011. Some arrangements that were acceptable for a small scale FOSS project are no longer so for one runing a 600 billion dollar system. Market cap is famously deceptive, but my point is not about specific numbers here.</p>

<p>One thing is clear: this is a serious project now, and we need to start taking decentralization seriously.</p>

<h2 id="moving-on">moving on</h2>

<p>I realize I am myself somewhat of a centralized bottleneck. And although I find Bitcoin an extremely interesting project and believe it’s one of the most important things happening at the moment, I also have many other interests. It’s also particularly stressful and I don’t want it, nor the bizarre spats in the social media around it, to start defining me as a person.</p>

<h2 id="spreading-out">spreading out</h2>

<p>I will start by delegating my own tasks, and decreasing my involvement. I do not intend to stop contributing to Bitcoin, or even to the Bitcoin Core project, but I would like to remove myself from the critical path and take (even more) of a background role.</p>

<p>Note that we had a nice growth in development activity, and that maintenance of the code itself has already been spread over multiple people for a while. I’m not the most active maintainer. Looking at the number of git merges</p>

<div><div><pre><code>bitcoin<span>$ </span>git log <span>--pretty</span><span>=</span><span>"format:%cn"</span> <span>--merges</span> <span>--since</span><span>=</span>2020-01-01 | <span>sort</span>| <span>uniq</span> <span>-c</span>
    313 fanquake
     51 Jonas Schnelli
    727 MarcoFalke
      7 Pieter Wuille
     65 Samuel Dobson
    363 Wladimir J. van der Laan
</code></pre></div></div>

<p>Only about 24% of the merges were done by me, last year.</p>

<h2 id="plans">plans</h2>

<p>But there’s plenty of things left to figure out, from the top of my head:</p>

<ul>
  <li>
    <p>Decentralize distribution.</p>

    <ul>
      <li>
        <p>In the short run, transfer bitcoincore.org to an organization instead of private ownership. Reduce the “bus factor”.</p>
      </li>
      <li>
        <p>I think it would be good if some other organizations set up mirrors, so there is less incentive to try to take bitcoincore.org down.</p>
      </li>
      <li>
        <p>In the long run, move away from a website for code distribution completely. No matter who owns it, a website on the clearnet can be shut down with the press of a button, and it seems that the global internet is gearing up to make censorship increasingly easy. We need a decentralized web. For us, one option would be IPFS, which is starting to catch on. For the binaries themselves there’s already the option of downloading through torrents.</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Decentralize the release process, and release signing.</p>

    <ul>
      <li>
        <p>Delegate more parts of the release process. Other maintainers should be able to do a release without my involvement.</p>
      </li>
      <li>
        <p>Rename the GPG key used to sign <code>SHA256SUMS.asc</code> to “Bitcoin Core release signing key”, instead of having it in my personal title. Make some construct so that N of M (minimally) trusted gitian signers doing a succesful build automatically results in a signed distribution.</p>
      </li>
      <li>
        <p>Same for the native code signing for Windows and MacOS.</p>
      </li>
      <li>
        <p>Even better in the long run would be to split up the keys, e.g. though RSA threshold signing, so that the whole process is geographically distributed.</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Decentralize the development hub.</p>

    <ul>
      <li>It’s not clear whether github can be trusted to act in our interest in the long run. Although issues and PRs are backed up through the API, having to move somewhere else could give significant interruption in development. And hopping from provider to provider would be awful—ideally the whole thing would not rely on a central server <em>at all</em>. For this I’ve been watching the <a href="https://radicle.xyz/">radicle</a> project, a P2P distributed code collaboration platform. It’s not quite there yet, but seems promising.</li>
    </ul>
  </li>
</ul>

<p>Bitcoin is quite different in some of the requirements here from other FOSS projects, so we’ll have to develop some tools as we go. We could also, definitely, use some help here.</p>

<p>Some smaller things to consider:</p>

<ul>
  <li>
    <p>Find someone else who wants to do the IRC meeting chair instead of me. Or maybe rotate it between multiple people.</p>
  </li>
  <li>
    <p>Release (and release candidate) mails to the <code>bitcoin-dev</code> and <code>bitcoin-core-dev</code> lists will no longer be necessarily signed and sent by me.</p>
  </li>
  <li>
    <p>There’s some development specific tooling hosted by me (e.g. the PR notification bots on IRC and mastodon). As they are non-critical and only little time goes into maintaining them, I’m fine with this for now.</p>
  </li>
</ul>

<p>As for decentralizing Bitcoin’s node software itself:</p>

<ul>
  <li>Carl Dong’s <code>libbitcoin_kernel</code> work. Bitcoin Core is a large monolithic project which includes the consensus code, which is much more critical than the other parts. The kernel would be an isolated part with well-defined interface, and at some point, its own review flow for changes. The difference with previous <code>libbitcoin_consensus</code> plans is that the kernel is stateful: it includes UTXO management and validation. It however does not include P2P, mempool policy, wallet, GUI, and RPC code. It could be re-used in different clients, to have more diversity in clients, but without the risks of a deviating consensus implementation.</li>
</ul>

<p>Over the course of 2021 this will be my focus with regard to Bitcoin Core.</p>

  </div></div>]]>
            </description>
            <link>https://laanwj.github.io/2021/01/21/decentralize.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25866009</guid>
            <pubDate>Thu, 21 Jan 2021 23:19:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Now they have 2FA problems]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25865581">thread link</a>) | @_wldu
<br/>
January 21, 2021 | https://www.go350.com/posts/now-they-have-2fa-problems/ | <a href="https://web.archive.org/web/*/https://www.go350.com/posts/now-they-have-2fa-problems/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>There’s an old quip about solutions causing more problems:</p><p><em>Some people, when confronted with a problem, think “I know, I’ll use regular expressions.” Now they have two problems.</em></p><h2 id="the-account-compromise-problem">The account compromise problem</h2><p>Years ago, online service providers had a problem.</p><p>Too many user accounts had weak, easily guessed passwords and were being compromised.</p><p>To make matters worse, many people used the same password for dozens of different accounts. So by compromising one account, an attacker could compromise others.</p><p>Last year, <a href="mailto:johndoe@example.com">johndoe@example.com</a> used <strong>Soccer2020!</strong> for email, Google, Twitter, Facebook, LinkedIn and his bank account. This year, his password is <strong>Soccer2021!</strong></p><h2 id="the-solution">The solution</h2><p>To solve this problem, many service providers began offering users <a href="https://en.wikipedia.org/wiki/Multi-factor_authentication">two factor authentication</a> (2FA) based on the <a href="https://tools.ietf.org/html/rfc6238">Time Based One-time Password</a> (TOTP) algorithm.</p><p>The TOTP algorithm takes a secret, and the current time, as input to generate a dynamic numeric code. These codes typically look something like this:</p><div><pre><code data-lang="bash">$ gpg -d twitter-totp-secret.txt.asc 2&gt; /dev/null | goathgen
<span>075237</span>
</code></pre></div><p><a href="https://en.wikipedia.org/wiki/Google_Authenticator">Google Authenticator</a> is a popular TOTP implementation, but there are many others.</p><p>Here’s an example of what a TOTP secret looks like as a string. This one is base32 encoded, but some may be hex encoded:</p><p>Users may never see the TOTP secret represented as a string, but as a QR code that they scan into their phone’s authenticator app. Those look something like this:</p><p><img src="https://www.go350.com/images/qr-code.png" alt="qr-code"></p><p>No matter how it is displayed, the TOTP secret should only be known to the service provider and the user. It must also be protected. In this way, it’s similar to a password.</p><p>Now with TOTP based 2FA enabled, users must enter a password <strong>and</strong> a numeric code to access the account.</p><p>This makes user accounts more difficult to compromise because an attacker would have to correctly guess the user’s password <strong>and</strong> obtain the user’s TOTP secret in order to gain access to the account.</p><h2 id="the-new-problems">The new problems</h2><p>While 2FA largely solves weak password account compromise, it also creates new problems (mostly for users).</p><ul><li>The management of TOTP secrets.</li><li>The loss of TOTP secrets.</li></ul><p>If the TOTP secret is unavailable, people may be <a href="https://forum.gitlab.com/t/i-lost-my-totp-key-and-recovery-code/42320/5">permanently locked out</a> of their account even if they know the password. This is by design.</p><p>Backup 2FA recovery codes compound the new problems. Those have to be managed as well, and can be lost too.</p><p>Which is worse… Having an account compromised or being permanently locked out of the account because you lost something?</p><p>In either case, you have to convince the service provider that you are indeed the rightful account holder. And, losing your TOTP secret, may make this impossible if you didn’t take precautions.</p><h2 id="proliferation-of-the-new-problems">Proliferation of the new problems</h2><p>Managing TOTP secrets and taking precautions against 2FA account lock-out is probably doable (for a few accounts). However, service provider adoption of 2FA is <a href="https://www.dongleauth.info/">growing</a>.</p><p>Email providers, domain registrars, social media sites, banks, online stores and forums now offer 2FA. Some even mandate it.</p><p>Currently, I have slightly more than 100 personal unique account passwords. I generate those passwords with <a href="https://github.com/62726164/dpg">DPG</a>. I also have roughly 30 TOTP secrets with different service providers. I use <a href="https://github.com/62726164/goathgen">goathgen</a> or Google Authenticator to generate the codes.</p><h2 id="how-people-manage">How people manage</h2><ul><li><p>When service providers <a href="https://www.google.com/landing/2step/features.html">offer multiple 2FA methods</a> some users enable them all. <strong>I highly recommend this approach to mitigate the risk of 2FA lock-out</strong>. Phone based 2FA methods are insecure and I do not use them, however, the average person needs to weigh that security risk against the potential for 2FA account lock-out and do what makes them most comfortable. Security is sort of like investing. You can play it safe or take more risks. Neither is right or wrong.</p></li><li><p>Use a password manager that also supports storing TOTP secrets and sync those with cloud accounts. If you do this, you have to be careful to not lose access to the synced account.</p></li><li><p>Keep encrypted copies of the TOTP secrets on multiple computers in geographically separate locations. You can PGP encrypt the TOTP secrets and store those in /home.</p></li><li><p>Print paper backup codes and store them in a safe place (at a bank or a friend’s house). Although this becomes more difficult as the number of accounts that require 2FA grows, and isn’t convenient when you need quick access.</p></li></ul><p><a href="https://support.google.com/accounts/thread/18795110?hl=en">Some people don’t take any precautions</a> and may not realize that they could be locked out of their accounts if their phone (with the authenticator app that contains all of their TOTP secrets) is reset, broken, lost or stolen.</p><p>And, even users who are prepared may lose access to their backups, phone number and other 2FA methods. Life happens.</p><h2 id="a-potential-solution">A potential solution</h2><p>Online service providers could have more physical presence. Places where people could visit (in-person or virtually) to prove that they are who they say they are and recover their accounts.</p><p>When I was a teenager, my wallet was stolen. It contained my driver’s license and social security card. Two things I need to live life.</p><p>I was able to get replacements by visiting the Department of Motor Vehicles (DMV) and a regional Social Security Administration office.</p><p>There was a well-defined process, for me to follow, to recover these things. There ought to be a similar solution for all online accounts.</p><h2 id="were-already-there">We’re already there</h2><p>At local organizations, this solution is already in place. Banks, schools and employers typically have offices where people can go to get help with account access issues.</p><p>Some even offer <a href="https://zoom.us/">Zoom</a> sessions that allow remote users to get help. You can display a government issued ID card, and your face, to a webcam just as easily as you can in-person.</p><p>Large online service providers could partner with retailers, phone companies, and government agencies, to offer users a similar recovery service for a nominal fee.</p><p>If that happens, the risk of permanent account lock-out, due to broken phones and lost TOTP secrets, would not be the problem that it is today.</p><ul><li><a href="https://www.go350.com/tags/totp">totp</a></li><li><a href="https://www.go350.com/tags/passwords">passwords</a></li><li><a href="https://www.go350.com/tags/hacking">hacking</a></li></ul></div></div>]]>
            </description>
            <link>https://www.go350.com/posts/now-they-have-2fa-problems/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25865581</guid>
            <pubDate>Thu, 21 Jan 2021 22:43:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[This week the European Parliament discussed EU Rail connectivity]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25864901">thread link</a>) | @reimbar
<br/>
January 21, 2021 | https://eeuropa.blog/2021/01/18/european-parliament-pushes-eu-rail-connectivity-in-europe-and-beyond-to-asia/ | <a href="https://web.archive.org/web/*/https://eeuropa.blog/2021/01/18/european-parliament-pushes-eu-rail-connectivity-in-europe-and-beyond-to-asia/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	





<h5>On Tuesday 19 January 2021, the European Parliament debated on a Resolution to <b>accelerate the EU strategy for rail transport</b>. In the <a href="https://eeuropa.blog/2021/01/05/2021-the-european-year-of-rail/">European Year of Rail Transport</a>, EP wants to enhance <b>TEN-T</b> (Trans-European Transport Network: Mobility and Transport) connectivity. The <b>European Green Deal</b> strategic plan and all the latest transport growth indicators ask for it. It is asked that all <b>EU candidate countrie</b>s, <b>Eastern countries</b> and <b>Asia</b> be part of the European strategic plan. A new impetus for EU competitiveness. Why EU should to connect to the <b>Silk Road</b>? Let’s examine latest developments.</h5>

<p>The EU is reviewing the <b>TEN-T</b> rail freight corridors as part of the new strategy for sustainable and smart mobility. Europe need it, also for reasons of competitiveness. And the<a href="https://www.europarl.europa.eu/plenary/en/vod.html?mode=chapter&amp;vodLanguage=EN&amp;vodId=9ef76b24-183b-4a27-c7d1-0d6d83206a59&amp;date=20210119#"><img data-attachment-id="1567" data-permalink="https://eeuropa.blog/2021/01/18/european-parliament-pushes-eu-rail-connectivity-in-europe-and-beyond-to-asia/click-to-watch-the-recording-debate-tuesday-19-january-2021-from-9_30-am-2/" data-orig-file="https://i2.wp.com/eeuropa.blog/wp-content/uploads/2021/01/Click-to-watch-the-recording-debate-Tuesday-19-January-2021-from-9_30-am-2.png?fit=640%2C360&amp;ssl=1" data-orig-size="640,360" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Click to watch the recording debate Tuesday 19 January 2021 from 9_30 am-2" data-image-description="" data-medium-file="https://i2.wp.com/eeuropa.blog/wp-content/uploads/2021/01/Click-to-watch-the-recording-debate-Tuesday-19-January-2021-from-9_30-am-2.png?fit=300%2C169&amp;ssl=1" data-large-file="https://i2.wp.com/eeuropa.blog/wp-content/uploads/2021/01/Click-to-watch-the-recording-debate-Tuesday-19-January-2021-from-9_30-am-2.png?fit=640%2C360&amp;ssl=1" loading="lazy" src="https://i2.wp.com/eeuropa.blog/wp-content/uploads/2021/01/Click-to-watch-the-recording-debate-Tuesday-19-January-2021-from-9_30-am-2.png?resize=640%2C360&amp;ssl=1" alt="" width="640" height="360" srcset="https://i2.wp.com/eeuropa.blog/wp-content/uploads/2021/01/Click-to-watch-the-recording-debate-Tuesday-19-January-2021-from-9_30-am-2.png?w=640&amp;ssl=1 640w, https://i2.wp.com/eeuropa.blog/wp-content/uploads/2021/01/Click-to-watch-the-recording-debate-Tuesday-19-January-2021-from-9_30-am-2.png?resize=300%2C169&amp;ssl=1 300w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1"></a></p>
<p>integration of the Eurasian network with the European central backbone could become a priority for the EU’s overall strategy.</p>
<p>The trans-Eurasian rail corridor is growing as an important new channel for trade and the EU could have a major interest. In 2020, the year of the pandemic, <b>EU-China Express</b> freight trains transported half a million TEU equivalent containers. A 65% increase compared to 2019!</p>
<p><b>Trans-Eurasian rail</b> routes have brought the two extremes of the Eurasian continent closer together and have offered Central Asia to become land linked and have access to global markets (cfr. <a href="https://doc-research.org/2020/01/value-chains-transformation/">Pepe Jacopo Maria</a> and <a href="http://www.eu-logos.org/2019/10/04/le-nouveau-corridor-transcontinental-ferroviaire-des-routes-de-la-soie-catalyse-une-dynamique-nouvelle-au-coeur-de-leurasie-un-atout-majeur-pour-la-nouvelle-strategie-ue/">Borgoltz Pierre</a>)</p>
<figure id="attachment_1562" aria-describedby="caption-attachment-1562"><a href="https://www.europarl.europa.eu/doceo/document/A-9-2020-0251_EN.html"><img data-attachment-id="1562" data-permalink="https://eeuropa.blog/2021/01/18/european-parliament-pushes-eu-rail-connectivity-in-europe-and-beyond-to-asia/ten-t-motion-for-resolution-eeuropa-2020/" data-orig-file="https://i0.wp.com/eeuropa.blog/wp-content/uploads/2021/01/TEN-T-Motion-for-Resolution-eEuropa-2020.png?fit=1414%2C2000&amp;ssl=1" data-orig-size="1414,2000" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="TEN-T Motion for Resolution – eEuropa 2020" data-image-description="" data-medium-file="https://i0.wp.com/eeuropa.blog/wp-content/uploads/2021/01/TEN-T-Motion-for-Resolution-eEuropa-2020.png?fit=212%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/eeuropa.blog/wp-content/uploads/2021/01/TEN-T-Motion-for-Resolution-eEuropa-2020.png?fit=724%2C1024&amp;ssl=1" loading="lazy" src="https://i0.wp.com/eeuropa.blog/wp-content/uploads/2021/01/TEN-T-Motion-for-Resolution-eEuropa-2020.png?resize=452%2C638&amp;ssl=1" alt="" width="452" height="638" srcset="https://i0.wp.com/eeuropa.blog/wp-content/uploads/2021/01/TEN-T-Motion-for-Resolution-eEuropa-2020.png?resize=724%2C1024&amp;ssl=1 724w, https://i0.wp.com/eeuropa.blog/wp-content/uploads/2021/01/TEN-T-Motion-for-Resolution-eEuropa-2020.png?resize=212%2C300&amp;ssl=1 212w, https://i0.wp.com/eeuropa.blog/wp-content/uploads/2021/01/TEN-T-Motion-for-Resolution-eEuropa-2020.png?resize=768%2C1086&amp;ssl=1 768w, https://i0.wp.com/eeuropa.blog/wp-content/uploads/2021/01/TEN-T-Motion-for-Resolution-eEuropa-2020.png?resize=1086%2C1536&amp;ssl=1 1086w, https://i0.wp.com/eeuropa.blog/wp-content/uploads/2021/01/TEN-T-Motion-for-Resolution-eEuropa-2020.png?resize=1084%2C1533&amp;ssl=1 1084w, https://i0.wp.com/eeuropa.blog/wp-content/uploads/2021/01/TEN-T-Motion-for-Resolution-eEuropa-2020.png?w=1414&amp;ssl=1 1414w" sizes="(max-width: 452px) 100vw, 452px" data-recalc-dims="1"></a><figcaption id="caption-attachment-1562">CLICK TO READ</figcaption></figure>
<p>Competitiveness of transcontinental freight routes has markedly improved over past few years and is attracting increasing volume of the high value-added goods and material, flagship of EU exports to East Asia.<span>&nbsp;</span></p>
<p>With continued improvements of operations and logistics services on the rail freight routes, <a href="http://doi.org/10.17270/J.LOG.2020.403">new synergies have emerged</a> between major economic actors across the Eurasian space. Notably for industrial production and value chains in sector such as <b>motor vehicles</b>, <b>electronics</b>, <b>chemical</b> or <b>pharmaceutical sectors</b>. To recall that the first “Express block trains” from China to the EU were arranged for large European companies.<span>&nbsp;</span></p>
<p>Trade in goods carried on the <b>trans-Eurasian routes</b> has developed steadily in both Eastern and Western directions. In 2017, the estimated share of container traffic on the trans-Eurasian route was <b>2.5%</b> for EU imports and <b>3.2%</b> for EU exports, compared to all EU container traffic. But it was <b>80%</b> higher in <b>Germany</b> <b>trade</b> and <b>2.5</b> times higher for imports from <b>Poland</b>.<b> </b>Value of goods per rail container from EU to <b>China</b> could be estimated five times those of maritime transport. By end 2020, the volume of containers flows transiting on the <b>EU-China Express</b><span>&nbsp; </span>rail routes had tripled.<span>&nbsp;</span></p>
<p><b>Kazakh rail</b> system accommodated most of the 2020 surge, handling <b>90%</b> containers transit flows, while major congestion unfolded at the EU eastern borders. <b>Kazakhstan</b>, becoming the main transport hub in the middle of the <b>Eurasian</b> continent, has also turned into the new <b>EU Green Gateway</b> to East Asia.<span>&nbsp;</span></p>
<p>Continuous improvements along the Eurasian rail freight routes have made it possible to lower transit costs and absorb safely and efficiently such considerable transit (cfr. <a href="https://www.adb.org/publications/carec-cpmm-annual-report-2019">CAREC/ADB</a>).<span>&nbsp;</span></p>
<p>EU logistics operators acknowledged that during 2020, container delivery by the EU-China Express trains between Central China and EU Member States of Central Europe were twice faster than by maritime transport for an equivalent cost.<span>&nbsp;</span></p>

<h4><b><img data-attachment-id="1537" data-permalink="https://eeuropa.blog/2021/01/18/european-parliament-pushes-eu-rail-connectivity-in-europe-and-beyond-to-asia/china-rail-map-2008-eeuropa-2021/" data-orig-file="https://i0.wp.com/eeuropa.blog/wp-content/uploads/2021/01/China-Rail-Map-2008-eEuropa-2021.jpg?fit=718%2C527&amp;ssl=1" data-orig-size="718,527" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="China Rail Map 2008 – eEuropa 2021" data-image-description="" data-medium-file="https://i0.wp.com/eeuropa.blog/wp-content/uploads/2021/01/China-Rail-Map-2008-eEuropa-2021.jpg?fit=300%2C220&amp;ssl=1" data-large-file="https://i0.wp.com/eeuropa.blog/wp-content/uploads/2021/01/China-Rail-Map-2008-eEuropa-2021.jpg?fit=718%2C527&amp;ssl=1" loading="lazy" src="https://i0.wp.com/eeuropa.blog/wp-content/uploads/2021/01/China-Rail-Map-2008-eEuropa-2021.jpg?resize=718%2C527&amp;ssl=1" alt="" width="718" height="527" srcset="https://i0.wp.com/eeuropa.blog/wp-content/uploads/2021/01/China-Rail-Map-2008-eEuropa-2021.jpg?w=718&amp;ssl=1 718w, https://i0.wp.com/eeuropa.blog/wp-content/uploads/2021/01/China-Rail-Map-2008-eEuropa-2021.jpg?resize=300%2C220&amp;ssl=1 300w" sizes="(max-width: 718px) 100vw, 718px" data-recalc-dims="1"></b></h4>
<h4><b>The bottleneck between Europe and Asia</b></h4>
<p>The rapid expansion of train frequency and container volumes is causing difficulties at the EU borders. Especially at the <b>Malacewiecze-Brest</b> station (Poland) : 95% of the total <b>EU-China Express</b> container transports pass through there and its handling and management<span>&nbsp; </span>capacity has been exceeded. In 2018, difficulties were already foreseen with the growth of traffic, estimated then up to <b>650 000 TEU</b> in 2028, if the bottleneck was not removed.</p>
<p>And in fact, in 2020 while congestion worsened at the border station, block train schedules were postponed at their departure in <strong>China</strong> and flows reduced to avoid major dysfunction in shipments. There were delays of up to two weeks, reducing progress and competitiveness edges achieved by Eurasian operators up that point on the trans-Eurasian routes. The situation remains very difficult, because even the Polish railway system is insufficient to absorb freight traffic.<span>&nbsp;</span></p>
<p>This resulted in<span>&nbsp; </span><strong>44% of containers</strong> of the <a href="https://index1520.com/en/analytics/konteynernye-zheleznodorozhnye-perevozki-na-evraziyskom-prostranstve-v-pervom-polugodii-2020-g">EU-China Express“ trains</a> ending their routes right at the Polish border during first half 2020 instead of<span>&nbsp; </span>reaching directly final destinations in main economic hubs further inland EU as previously for optimum performance.<span>&nbsp;</span></p>
<p>In contrast, the <strong>Malacewiecze</strong> station was point of departure for only 9,3% containers rail transit back to <strong>China</strong>, clearly unable to organize “return” block trains eastward and achieve balanced east-west container flows. This phenomenon generated a costly shift in east-west EU-China Express container cargo balance, from 47% – 53% in 2018 to only 31%<span>&nbsp; </span>to 69% for 2020. <span>&nbsp; &nbsp;</span></p>
<p>Ensuring a balance of East-West traffic and vice versa is extremely important. Both to ensure a constant flow of goods and to ensure the economic competitiveness of rail transport. The efficiency of the bi-directional flow of goods will also be essential for the functioning of a system made up of railway networks and hubs to serve the EU core economic regions concerned, as highlighted in the <a href="http://www.ferrmed.com/sites/default/files/2020-09/FERRMED_position_final.pdf">FERRMED<span>&nbsp; </span>​​position paper</a>.</p>

<p><b>Will trade along the Silk Road increase?</b><span>&nbsp;</span></p>
<p>The transit and trade flows across the <b>Eurasian space</b> are just starting to reflect the huge structural economic transformation going on both edges of the continent.</p>
<p>At the recent Conference “<b>Climate Ambition Summit 2020</b>” of the 12 December 2020, held in the framework of the <strong>Conference of Parties on Climate Change</strong>, known as <b>COP Summit</b>, the <b>European Union</b>, with <b>Kazakhstan</b>, <b>China</b>, <b>Japan</b>, <b>South Korea</b> and other partners have just set new ambitious targets to meet their commitments under the <b>Paris Agreement</b> and to become carbon neutral by 2050-2060. The adaptation of their respective economies is drastically accelerating on a similar path, notably for <b>green energy</b> and <b>green mobility,</b> boosting further prospects for mutually beneficial <b>trade expansion</b>, <b>synergy</b> of <b>transcontinental supply</b> and <b>value chains</b> and likely staggering future cargo transit flows on the <b>trans-Eurasian Express</b> routes. <span>&nbsp; &nbsp; &nbsp; &nbsp;</span></p>

<p>The <b>automotive industry</b> and <b>renewable energy</b> sectors illustrate well the magnitude of such requested transformation. The new EU targets to <b>reduce by 55% emissions by 2030</b>, (compared to 1990) calls for <b>30 million electric cars</b> to be on the road<span>&nbsp; </span>by <b>2030</b> (vs. one million end 2020), requiring equivalent to additional <b>40 large battery plants</b> to fullfill demands and <b>3 million public recharging points installed</b>. <span>&nbsp;</span></p>
<p>Meanwhile, a similar accelerated transformation simultaneously is underway in China and East Asia partners, the world largest market where European companies are well established: automotive is the first among EU FDI sectors in China, with 28% share. This creates a unique and phenomenal opportunity for synergy across the Eurasian Continent: innovative supply and production chains, where the <b>Trans-Eurasian</b> <b>routes</b> will play a crucial role for <b>EU competitivity</b>.</p>
<p>Anticipating yet much higher transit volumes to come on the transcontinental rail freight routes, Eurasian partners and China are currently undertaking<span><strong> investments aiming to double capacity by 2025</strong></span> and further enhance efficiency and technological innovations on the trans-Eurasian freight routes. Joint processes are put in place to synchronize investments, improve the operational efficiency and quality of logistics chains, further rationalize and digitize transport, border crossing and customs procedures.</p>

<h4>EU and Chine&nbsp;agreed a new <strong>Comprehensive Agreement on Investment</strong></h4>
<p><span>In 2020</span>, <strong>China has become the first EU trade partner</strong>.</p>
<figure id="attachment_1371" aria-describedby="caption-attachment-1371"><a href="https://eeuropa.blog/2021/01/02/eu-china-comprehensive-investment-agreement-u-s-criticism/"><img data-attachment-id="1371" data-permalink="https://eeuropa.blog/2021/01/02/elementor-1352/china-eu-eeuropa-2021/" data-orig-file="https://i0.wp.com/eeuropa.blog/wp-content/uploads/2021/01/China-EU-eEuropa-2021.jpg?fit=1200%2C630&amp;ssl=1" data-orig-size="1200,630" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="China-EU – eEuropa 2021" data-image-description="" data-medium-file="https://i0.wp.com/eeuropa.blog/wp-content/uploads/2021/01/China-EU-eEuropa-2021.jpg?fit=300%2C158&amp;ssl=1" data-large-file="https://i0.wp.com/eeuropa.blog/wp-content/uploads/2021/01/China-EU-eEuropa-2021.jpg?fit=1024%2C538&amp;ssl=1" loading="lazy" src="https://i0.wp.com/eeuropa.blog/wp-content/uploads/2021/01/China-EU-eEuropa-2021.jpg?resize=467%2C246&amp;ssl=1" alt="" width="467" height="246" srcset="https://i0.wp.com/eeuropa.blog/wp-content/uploads/2021/01/China-EU-eEuropa-2021.jpg?resize=1024%2C538&amp;ssl=1 1024w, https://i0.wp.com/eeuropa.blog/wp-content/uploads/2021/01/China-EU-eEuropa-2021.jpg?resize=300%2C158&amp;ssl=1 300w, https://i0.wp.com/eeuropa.blog/wp-content/uploads/2021/01/China-EU-eEuropa-2021.jpg?resize=768%2C403&amp;ssl=1 768w, https://i0.wp.com/eeuropa.blog/wp-content/uploads/2021/01/China-EU-eEuropa-2021.jpg?resize=1084%2C569&amp;ssl=1 1084w, https://i0.wp.com/eeuropa.blog/wp-content/uploads/2021/01/China-EU-eEuropa-2021.jpg?w=1200&amp;ssl=1 1200w" sizes="(max-width: 467px) 100vw, 467px" data-recalc-dims="1"></a><figcaption id="caption-attachment-1371">EU and China Comprehensive Agreement on Investment</figcaption></figure>
<p><strong><span>On 30 December 2020</span></strong>, EU and China agreed, after seven years of negotiation, on the principles of a new <strong><a href="https://eeuropa.blog/2021/01/02/eu-china-comprehensive-investment-agreement-u-s-criticism/">Comprehensive Agreement on Investment</a></strong>, including telecommunications, finances and notably renewables energy and electric vehicles sectors able to boost emerging transcontinental supply and value chains, and strengthen greatly the trade exchanges on the Trans Eurasian Transport Corridor. <span>&nbsp;</span></p>
<p>This agreement comes a few weeks after the conclusion of<span>&nbsp; </span>a major Free Trade Agreement, the “<a href="https://ispo.maillist-manage.eu/click.zc?od=2f2e831ae0e14bcd35d9ef6160d214074&amp;repDgs=166050cc7ac9dee&amp;linkDgs=166050cc7ac0a16&amp;mrd=166050cc7abed11&amp;m=1">Regional Comprehensive Economic Partnership</a>” (RECEP<b>)</b>, between <b>ASEAN</b>, <b>China</b>, <b>Japan</b>, <b>South Korea</b>, <b>Australia</b> and <b>New Zealand.</b> This indirectly opens new large trade and investment opportunities also to the EU with all partners concerned in East Asia and South East Asia. To note also that the in May 2018 , the Eurasian Economic Union and China signed a Trade and Economic Cooperation Agreement<span>&nbsp; </span>covering notably investments, transport, e-commerce, issues of customs administration, technical, sanitary and phytosanitary regulations, while specific bilateral technical arrangements were adopted to promote <b>trade</b>, notably for goods with high market potential such as <b>agricultural</b> and <b>food products</b>.<span>&nbsp;</span></p>
<p>In this highly favorable economic and business context, the new modern <b>Green trans-Eurasian transport connectivity</b> is bound to play in coming years a major role for the sustainable economic and social development of all partners along the routes, from <b>East Asia</b>, <b>Central Asia </b>to the <b>Western Europe</b>. <span>&nbsp;</span></p>

<p><img data-attachment-id="1547" data-permalink="https://eeuropa.blog/2021/01/18/european-parliament-pushes-eu-rail-connectivity-in-europe-and-beyond-to-asia/v2-the-eu-sustainable-and-smart-mobility-strategy-eeuropa-blog-2021/" data-orig-file="https://i1.wp.com/eeuropa.blog/wp-content/uploads/2021/01/V2-The-EU-Sustainable-and-Smart-Mobility-Strategy-eEuropa.blog-2021.png?fit=1200%2C630&amp;ssl=1" data-orig-size="1200,630" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="V2 The EU Sustainable and Smart Mobility Strategy – eEuropa.blog 2021" data-image-description="" data-medium-file="https://i1.wp.com/eeuropa.blog/wp-content/uploads/2021/01/V2-The-EU-Sustainable-and-Smart-Mobility-Strategy-eEuropa.blog-2021.png?fit=300%2C158&amp;ssl=1" data-large-file="https://i1.wp.com/eeuropa.blog/wp-content/uploads/2021/01/V2-The-EU-Sustainable-and-Smart-Mobility-Strategy-eEuropa.blog-2021.png?fit=1024%2C538&amp;ssl=1" loading="lazy" src="https://i1.wp.com/eeuropa.blog/wp-content/uploads/2021/01/V2-The-EU-Sustainable-and-Smart-Mobility-Strategy-eEuropa.blog-2021.png?resize=1024%2C538&amp;ssl=1" alt="" width="1024" height="538" srcset="https://i1.wp.com/eeuropa.blog/wp-content/uploads/2021/01/V2-The-EU-Sustainable-and-Smart-Mobility-Strategy-eEuropa.blog-2021.png?resize=1024%2C538&amp;ssl=1 1024w, https://i1.wp.com/eeuropa.blog/wp-content/uploads/2021/01/V2-The-EU-Sustainable-and-Smart-Mobility-Strategy-eEuropa.blog-2021.png?resize=300%2C158&amp;ssl=1 300w, https://i1.wp.com/eeuropa.blog/wp-content/uploads/2021/01/V2-The-EU-Sustainable-and-Smart-Mobility-Strategy-eEuropa.blog-2021.png?resize=768%2C403&amp;ssl=1 768w, https://i1.wp.com/eeuropa.blog/wp-content/uploads/2021/01/V2-The-EU-Sustainable-and-Smart-Mobility-Strategy-eEuropa.blog-2021.png?resize=1084%2C569&amp;ssl=1 1084w, https://i1.wp.com/eeuropa.blog/wp-content/uploads/2021/01/V2-The-EU-Sustainable-and-Smart-Mobility-Strategy-eEuropa.blog-2021.png?w=1200&amp;ssl=1 1200w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1"></p>
<h4><b>The EU Sustainable and Smart Mobility Strategy</b></h4>
<p><span>On 10 December 2020</span>,<b> </b>the Commission released the <b>EU Sustainable and Smart Mobility Strategy </b>to guide the mobility sector to achieve a 90% cut in carbon emissions by 2050, including inter alia, the doubling rail freight traffic by 2050<b>. <span>&nbsp;</span></b></p>
<p>The <b>rail freight corridors</b> will be integrated in the <b>TEN-T</b> core network, filling in the most important missing links with improved connections, adapting the core rail network so that it is fully suitable for absorbing much higher freight traffic.<span>&nbsp;</span></p>
<p>“<b>Quick wins</b>” highlighted for enhanced performance and efficiency are train length, …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://eeuropa.blog/2021/01/18/european-parliament-pushes-eu-rail-connectivity-in-europe-and-beyond-to-asia/">https://eeuropa.blog/2021/01/18/european-parliament-pushes-eu-rail-connectivity-in-europe-and-beyond-to-asia/</a></em></p>]]>
            </description>
            <link>https://eeuropa.blog/2021/01/18/european-parliament-pushes-eu-rail-connectivity-in-europe-and-beyond-to-asia/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25864901</guid>
            <pubDate>Thu, 21 Jan 2021 21:53:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[2021: what’s coming in free/libre software]]>
            </title>
            <description>
<![CDATA[
Score 62 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25864221">thread link</a>) | @yorwba
<br/>
January 21, 2021 | https://librearts.org/2021/01/foss-in-2021-preview/ | <a href="https://web.archive.org/web/*/https://librearts.org/2021/01/foss-in-2021-preview/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>

        
        



	    

	    





<p>There are many reasons to look back at 2020 with a whole range of emotions but I would rather look forward.</p>
<h2 id="graphics"><a aria-label="Permalink to Graphics" title="Permalink to 'Graphics'" href="#graphics">Graphics</a></h2>
<p>The <strong>GIMP</strong> team is now focusing on completing version 3.0. It’s too early to say if it will be out in 2021. But unless everything changes dramatically, we’ll see several more 2.99.x releases at the very least.</p>
<p>Feature-wise, not much new is planned, although there’s a new <em>Paint Select</em> tool being worked on by Thomas Manni. And before you ask: no, it’s not AI-based. It’s also designed to do quick binary selection for now, so not very good for selecting strands of hair and suchlike.</p>

<p>
  <iframe src="https://www.youtube-nocookie.com/embed/cPHCrLEpy4Y" allowfullscreen="" title="YouTube Video" loading="lazy"></iframe>
</p>

<p>Admittedly, I avoid talking about <strong>Glimpse</strong> and <strong>Glimpse-NX</strong> much. I have two major reasons for that.</p>
<p>First, every public conversation about the fork of GIMP ends up in someone attacking either the Glimpse or the GIMP team, and that’s unproductive and tiresome. And then the progress isn’t all that interesting so far.</p>
<p>The fork is just rebranding and no new features or UX fixes (unless removing the bell pepper brush is your idea of finally making it right for everyone), and then Glimpse-NX — at least for the public eye — exists only as <a href="https://github.com/glimpse-editor/glimpse-nx-design/issues">UI mockups</a>. They did get Bilal Elmoussaoui (GNOME team) to create <a href="https://gitlab.gnome.org/bilelmoussaoui/gegl-rs">Rust bindings to GEGL</a> for them last autumn, but that’s all as far as I can tell.</p>
<p>So the current pace of the project is not very impressive (again, as a GIMP contributor, I’m biased) and I’m not sure how much we are going to see in 2021.</p>
<p>That said, I think having a whole new image editor based on GEGL would be lovely. I don’t see why Glimpse-NX couldn’t be that project. A proof-of-concept application that would load an image, apply a filter, and export it back sounds feasible. It’s something one could iterate upon. So maybe that’s how they are going to play it.</p>
<p>The fine folks over at <strong>Krita</strong> posted a <a href="https://krita.org/en/item/krita-in-2020/">2020 report</a> where they listed major challenges they will be facing this year: the completion of resources management rewrite that currently blocks v5.0 release, the port to Apple M1, the launching of a new development fund (akin to that of Blender), and more.</p>
<p>They also <a href="https://krita.org/en/item/krita-4-4-2-released/">have just released version 4.4.2</a> with mesh gradients, mesh transform tool, new gradient editor etc.</p>

<p>
  <iframe src="https://www.youtube-nocookie.com/embed/DLXWynZT_8s" allowfullscreen="" title="YouTube Video" loading="lazy"></iframe>
</p>

<p>I think it’s safe to say that we might see <strong>MyPaint</strong> 2.0.2 later this year with some new features and quite a few bugfixes. There haven’t been much groundbreaking development since 2.0.1 released in May 2020.</p>
<p>On the other hand, there are nice new features available in GitHub forks and not all of them have been turned into pull requests. But some were. E.g. there’s a guy who added a <a href="https://github.com/mypaint/mypaint/pull/685">perspective mode</a> with vanishing points and all, and it’s almost ready, although it’s been in the works for almost 5 years now.</p>
<p>The topic of fullscreen <strong>color management implementation in Wayland</strong> is back, and it’s <a href="https://discuss.pixls.us/t/wayland-color-management/10804/508">a kinda frustrating story</a>. In a nutshell:</p>
<ul>
<li>people who are now <a href="https://gitlab.freedesktop.org/wayland/wayland-protocols/-/merge_requests/14">working on this</a> (Collabora developers) seem to have little experience with color management but they appear to be motivated to hack on the code;</li>
<li>all the while people who have a crapload of experience with color management have had bad experience discussing this before, do not like the approach by the new team, and don’t seem excited to contribute to this new effort (Graeme’s spec proposal is <a href="https://www.argyllcms.com/waylandcm.xml.txt">still available</a>).</li>
</ul>
<p>So we might end up with an implementation that is not suitable for professional work. At this point, there’s no telling what will happen. Personally, I keep an open mind about it, but the quality of conversations is not good in a way that there is no visible action in response to substantiated criticism. And so the conversation isn’t getting anyone any further.</p>
<p>Now that <strong>Inkscape</strong> 1.1 alpha is out for everyone to take for a spin, I’m positive we are not so far from the final release. There is <em>a lot</em> packed into the coming update, see the <a href="https://wiki.inkscape.org/wiki/index.php?title=Release_notes/1.1">draft of the release notes</a>. I’m really looking forward to whatever they have planned for when 1.1 is out, there is still so much to do!</p>

<p>
  <iframe src="https://www.youtube-nocookie.com/embed/zoPLqxaj7Kc" allowfullscreen="" title="YouTube Video" loading="lazy"></iframe>
</p>

<h2 id="publishing"><a aria-label="Permalink to Publishing" title="Permalink to 'Publishing'" href="#publishing">Publishing</a></h2>
<p>There will be another 1.5.x release of <strong>Scribus</strong> that has some new PDF importing features and includes a lot of small but refining UI changes, likely before April. Another release should follow later in the year.</p>
<p>They definitely don’t want major UI changes in the main development branch anymore until they release 1.6, and that sounds like wrapping up for the big release to me. Which means it’s only a matter of how many under-the-hood changes still need to happen.</p>

<p>
  <iframe src="https://www.youtube-nocookie.com/embed/5lnlBufWMfI" allowfullscreen="" title="YouTube Video" loading="lazy"></iframe>
</p>

<p>It’s been a long time since I last looked at <strong><a href="https://sigil-ebook.com/">Sigil</a></strong>, mostly because I lost my Nook device some years ago and never got to ordering a replacement. Meanwhile, Sigil got better. Like, <em>really</em> better.</p>
<p>They came up with what seems to be a working solution for dealing with both EPUB2 and EPUB3 in the same application, they updated the UI just enough to be recognizable yet somehow nicer, and then they added some boring yet useful utility features.</p>
<p>I do like where Kevin Hendricks and Doug Massay are taking the project to. Version 1.5.0 will probably be out in the first half of 2021.</p>
<h2 id="photography"><a aria-label="Permalink to Photography" title="Permalink to 'Photography'" href="#photography">Photography</a></h2>
<p>Thanks to Aurélien Pierre, the last few releases of <strong>darktable</strong> introduced a more articulated division between scene-referred and display-referred workflows, and it looks like more people are contributing to that effort now. There are also some interesting things going on in pull requests:</p>
<ul>
<li>a new <a href="https://github.com/darktable-org/darktable/pull/7909">color balance RGB filter</a> working in JzAzBz color space, with built-in gamut checking;</li>
<li>a new <a href="https://github.com/darktable-org/darktable/pull/7669">diffusion module</a> to add or remove lens blur, hazing, blooming etc.;</li>
<li>a new <a href="https://github.com/darktable-org/darktable/pull/7633">chromatic aberrations correction module</a> that sits in the right place of the modules chain and produces less halos than defringe;</li>
<li>there’s also a work-in-progress <a href="https://github.com/darktable-org/darktable/pull/7092">option to correct lens distortions</a> straight from the RAW Exif for camera vendors that write the distortion in there&nbsp;— I think I mentioned that one in one of the last weekly recaps.</li>
</ul>
<p>Something you can already play with if you build from Git:</p>
<ul>
<li>a new demosaicing method, Ratio Corrected Demosaicing (based on <a href="https://github.com/LuisSR/RCD-Demosaicing">this research</a>), is aimed at reducing pixel overshooting;</li>
<li>color calibration module can now create an ad-hoc internal color profile from a color checker.</li>
</ul>
<p>Once again, the amount of contributions is getting large enough for maybe more than one major release a year.</p>
<p>Meanwhile, there are currently <a href="https://github.com/Beep6581/RawTherapee/milestone/9">63 bugs that need to be fixed</a> for <strong>RawTherapee</strong> 5.9 to be released. I can’t give you a ETA for it and I’m not sure anybody can. The project is very active, and if you ever came across its fans online, you probably admired how strongly they feel about RT being superior in processing quality and ease of use as compared to some other tools :)</p>

<p>
  <iframe src="https://www.youtube-nocookie.com/embed/VNKNJEyJKOo" allowfullscreen="" title="YouTube Video" loading="lazy"></iframe>
</p>

<p>The <strong>Siril</strong> team is planning to release version 0.99.8 soon and then hopefully v1.0. They’ve completely rewritten image conversion, revamped memory management, and added astrometry support (6 catalogs supported currently).</p>
<p><img src="https://librearts.org/2021/01/foss-in-2021-preview/siril-0-99-7.webp" alt="Siril 0.99.7"></p>
<h2 id="animation"><a aria-label="Permalink to Animation" title="Permalink to 'Animation'" href="#animation">Animation</a></h2>
<p>The <strong>Synfig</strong> team is completing the migration from autotools to CMake, and their next step would be to make it possible to build the program with MS Visual Studio. The expectation is that more contributors would join then thanks to a lower threshold. After that, the rendering code really needs attention.</p>
<p>In 2020, <strong>VGC</strong> by Boris Dalstein was “pre-incubated” at the BIC de Montpellier startup incubator and additionally obtained a public grant from CNC-RIAM. This means Boris will be able to hire another developer to work on the project.</p>
<p>The situation with <strong>enve</strong> is… Well, complicated, I guess. In summer 2020, Maurycy Liebner announced that the development is <a href="https://twitter.com/enve2d/status/1290935844610682880">on hold due to health issues</a>. In December, he started pushing some commits to the public repository on GitHub again, not at the old rate though. So it’s unclear if he’s resuming the work.</p>
<p>I think it would help to have some sort of a framework for more people to contribute, even basic things like a roadmap and info for newly arrived developers.</p>

<p>
  <iframe src="https://www.youtube-nocookie.com/embed/T7DVtVZ-Gb0" allowfullscreen="" title="YouTube Video" loading="lazy"></iframe>
</p>

<h2 id="vfx"><a aria-label="Permalink to VFX" title="Permalink to 'VFX'" href="#vfx">VFX</a></h2>
<p>Natron is one of the projects that I find hard to speculate about. The only active developer right now is Ole-André Rodlie, and his most recent work currently lives in <a href="https://github.com/rodlie/Natron">his own GitHub fork</a>. He says he’ll soon start making pull requests to the upstream GitHub project (which, let’s be frank, is a bit like sending PRs to yourself).</p>
<p>There could be a few visual tweaks coming next but unlikely at the scale of a UI redesign that is <a href="https://discuss.pixls.us/t/natron-ui-re-design-proposal/18313">being discussed on Pixls</a> since May 2020.</p>
<figure>
    <img src="https://librearts.org/2021/01/foss-in-2021-preview/natron-mockup.webp" alt="Natron UI mockup"> 
</figure>

<p>However, the new website for the project, designed by the same contributor, has good chances to go live soon. How much that will help attracting new developers is hard to say. Probably not much, as projects like Natron really need full-time involvement (which I <a href="https://librearts.org/2018/11/the-demise-of-natron/">discussed at length</a> in 2018, and not much changed since then).</p>
<p>This is a rather sad turn of events, as it leaves us Blender as the only working free/libre node-based compositing solution (unless you count upcoming Olive 0.2 in). Ramen is long gone, and ButtleOFX developers gave up around 2017. And while I love Blender to pieces, the idea that it is the only option is somehow worrying.</p>
<h2 id="3d"><a aria-label="Permalink to 3D" title="Permalink to '3D'" href="#3d">3D</a></h2>
<p>Everything Nodes, new asset browser, Vulkan support in EEVEE, new character animation tools and more — <a href="https://www.blender.org/press/big-blender-projects-for-2021/">all work planned</a> for <strong>Blender</strong> in 2021 sounds great. There isn’t really much to add here, apart from mentioning that some of these things will be possible thanks to corporate funding.</p>
<p>Version 2.92 is expected in late February, with features like easily drawing 3D primitives, a whole bunch of sculpting improvements, tracing image sequences to Grease Pencil strokes, cryptomatte support in EEVEE, and so much more.</p>

<p>
  <iframe src="https://www.youtube-nocookie.com/embed/tOFCkPf0eio" allowfullscreen="" title="YouTube Video" loading="lazy"></iframe>
</p>

<p>I’d be a damn fool if I left out <strong>Dust3D</strong>. Jeremy HU did a lot of experimenting in 2020, and this year, his plan is to merge a lot of that into the main program. He’ll do more experimenting with his <a href="https://github.com/huxingyi/autoremesher">quad remesher</a> first though.</p>
<p>One major roadblock is writing his own code instead of CGAL libraries that are license-incompatible with Dust3D (GPL in CGAL vs MIT in Dust3D).</p>
<p>But yes, you should generally be looking forward to a new version of the program with better …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://librearts.org/2021/01/foss-in-2021-preview/">https://librearts.org/2021/01/foss-in-2021-preview/</a></em></p>]]>
            </description>
            <link>https://librearts.org/2021/01/foss-in-2021-preview/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25864221</guid>
            <pubDate>Thu, 21 Jan 2021 21:05:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I schedule my friendships like I schedule my meetings]]>
            </title>
            <description>
<![CDATA[
Score 58 | Comments 56 (<a href="https://news.ycombinator.com/item?id=25864090">thread link</a>) | @mcrittenden
<br/>
January 21, 2021 | https://critter.blog/2021/01/21/i-schedule-my-friendships-like-i-schedule-my-meetings/ | <a href="https://web.archive.org/web/*/https://critter.blog/2021/01/21/i-schedule-my-friendships-like-i-schedule-my-meetings/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
	<p><a href="#content">Skip to content</a></p><!-- #masthead -->

	
	<div id="content">

	<div id="primary">
		<main id="main">

		

<article id="post-6281">
	<!-- .entry-header -->

	<div>
		
<p>It’s hard to stay in touch with friends. The only thing that has <a href="https://critter.blog/2020/10/05/guerrilla-productivity-tactics/">worked for me</a> is <strong>scheduled, recurring calendar events</strong>.</p>



<ul><li>Every other Thursday night, <a href="https://critter.blog/2020/12/25/my-wifes-holiday-costume-makeup/">my wife</a> and I hop on a Zoom with <a href="https://anchor.fm/jace-and-critter/">a friend</a> in Portland and chat for an hour or two. </li><li>Every Tuesday, I have a coffee chat scheduled with a former coworker of mine. </li><li>Every Saturday, my mom comes over for dinner.</li><li>Once a month, I catch up with an old friend who moved away.</li></ul>



<p>We remember because our <a href="https://critter.blog/2020/08/03/your-calendar-should-be-an-allowlist-not-a-blocklist/">calendars</a> remind us. We don’t have to think about <a href="https://critter.blog/2020/11/04/what-we-have-left/">when we’ll hang out again</a>. There’s no <a href="https://critter.blog/2020/08/13/clear-is-kind-unclear-is-unkind/">awkward</a> “we should do this again!” or “let me know when you’re available for lunch next week!” involved. <a href="https://critter.blog/2021/01/07/a-simple-process-beats-a-perfect-process/">It’s automatic</a>. I schedule it once and we are guaranteed to stay in touch.</p>



<p>If you’re thinking it’s weird to treat a friendship like a <a href="https://critter.blog/2020/10/20/a-tiny-guide-to-sprint-planning-in-scrum/">sprint planning</a> meeting, then maybe you’re right. But it works. It’s worth a little weirdness to stay in touch with the people who matter to me. </p>



<p><a href="https://critter.blog/2020/11/24/intense-intervention-or-acceptance-pick-one/">Try it</a> if you’re <a href="https://critter.blog/2020/12/16/if-everyone-else-on-earth-disappeared-how-would-you-spend-your-time/">sad about losing touch</a> with people.</p>




	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article><!-- #post-6281 -->
			<!-- .post-nav-wrapper -->
		
		</main><!-- #main -->
	</div><!-- #primary -->


<!-- #secondary -->

	</div><!-- #content -->

	
	<!-- #colophon -->
</div></div>]]>
            </description>
            <link>https://critter.blog/2021/01/21/i-schedule-my-friendships-like-i-schedule-my-meetings/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25864090</guid>
            <pubDate>Thu, 21 Jan 2021 20:53:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DeLorean considering all-electric reboot]]>
            </title>
            <description>
<![CDATA[
Score 434 | Comments 323 (<a href="https://news.ycombinator.com/item?id=25864078">thread link</a>) | @evo_9
<br/>
January 21, 2021 | https://www.newdelorean.com/nhtsa-releases-final-low-volume-manufacturing-rules/ | <a href="https://web.archive.org/web/*/https://www.newdelorean.com/nhtsa-releases-final-low-volume-manufacturing-rules/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<div>		
        	
                        
            <div id="primary">
    
                            
                
	          		
   
   
    <!-- post -->    
    <article id="post-282">
    
    	<!-- entry-meta -->
    	<!-- close entry-meta -->
        
                    <p><span>January 20, 2021</span>
                <span>                
                     <span>DMC</span>
                </span>     
            </p>
            
    <div>
    
    <!-- entry-header -->    
    <!-- close entry-header -->   
    
         
        
            
	    
    <!-- entry-content -->
    <div>
        <p>National Highway Traffic Safety Administration (NHTSA) has completed a regulation permitting low volume motor vehicle manufacturers to begin selling replica cars that resemble vehicles produced at least 25 years ago. Congress enacted a DeLorean Motor Company-backed bill backed by the Specialty Equipment Market Association (SEMA) DeLorean Motor Company, and others into law in 2015, which streamlined requirements for small automakers, but implementation was delayed while awaiting the NHTSA regulations. Companies like DeLorean will now be able to apply for authorization to produce and sell vehicles under this program.</p>
<p>The recent release of the final rule document was unexpected, and we’re very pleased to see it finally happen. Still, four years overdue with no clear idea of when (or if!) these would ever be released did certainly keep us from putting too many eggs in that stainless steel basket, so to speak.</p>
<p>Some previous suppliers that we had lined up have gone out of business during the pandemic, others have been absorbed by larger companies that have made it clear low volume component production is not something they’re interested in pursuing. In that regard there will be a fair amount of work to be re-done. Perhaps worse, some “champions” we had at various suppliers have retired or moved on. In some cases this has left a void, where before there was a DeLorean fan, who rallied for us within their company and management.</p>
<p>Additionally, certain staffing candidates that were on our short-list have long since moved on in and while unemployment has increased during 2020, many of the specialized roles that we require are still hard to fill.</p>
<p>As mentioned before, in 2015 our planned engine had a life-cycle of emissions compliance through 2022. We had hoped to get into production by 2017 and get 3-4 years out of it before having to take on the engineering for a new powertrain. It’s believed that this engine has been extended through perhaps 2024 now, but it doesn’t seem like a good idea to plan around an engine so near its end-of-life.</p>
<p>That said, with EV’s becoming more mainstream, we’ve been considering switching to an all-electric as the future. It certainly makes for an easier path through emissions maze which still looms large over any internal combustion engine. While an electric Cobra or Morgan may be a little extreme for their potential market, we’ve already seen that an EV DeLorean – as we displayed at the 2012 New York International Auto Show – is not such an “out there” idea.</p>
<p>Most critically, financial markets have changed, and will change even more as the world navigates the continuing COVID crisis during the Biden administration. Will the financial support that we had lined up a few years ago to carry us through the final development and into production still be available?</p>
<p>As the automotive brand with likely the highest name recognition across all demographics in spite of not having a new product in 40 years, we still believe that none of the above is insurmountable and believe that others will see value in it, as well.</p>
<p>Stay tuned…</p>
                
                            </div><!-- close entry-content -->
    
                 
    </div>     
    
    </article><!-- close post --> 

        
                    
                        
            </div>
        
        	
    
    
    
            
		</div>
		
        
        
    </div></div>]]>
            </description>
            <link>https://www.newdelorean.com/nhtsa-releases-final-low-volume-manufacturing-rules/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25864078</guid>
            <pubDate>Thu, 21 Jan 2021 20:52:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Simple Ways to Refactor Terrible Code]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25864063">thread link</a>) | @dreamy_borg
<br/>
January 21, 2021 | https://martinheinz.dev/blog/40 | <a href="https://web.archive.org/web/*/https://martinheinz.dev/blog/40">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://martinheinz.dev/blog/40</link>
            <guid isPermaLink="false">hacker-news-small-sites-25864063</guid>
            <pubDate>Thu, 21 Jan 2021 20:50:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Basic Scripting with Awk and Gnuplot]]>
            </title>
            <description>
<![CDATA[
Score 101 | Comments 9 (<a href="https://news.ycombinator.com/item?id=25863846">thread link</a>) | @thevirtuoso1973
<br/>
January 21, 2021 | https://cyberchris.xyz/posts/awk-and-gnuplot/ | <a href="https://web.archive.org/web/*/https://cyberchris.xyz/posts/awk-and-gnuplot/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      
<p>
<em>Posted to <a href="https://news.ycombinator.com/item?id=25863846">HN</a>. Comments and discussion highly encouraged.</em></p>
<div id="outline-container-headline-1">
<h2 id="headline-1">
Introduction
</h2>
<div id="outline-text-headline-1">
<p>This will be a short example-based guide to (a) awk (b) gnuplot and (c) using
them in a script.</p>
<p>
I needed to graph some data based on the output of a command run a couple times.
So what better way to solve that five minute task than to spend an hour learning
awk &amp; gnuplot to automate it?</p>
</div>
</div>
<div id="outline-container-headline-2">
<h2 id="headline-2">
The Problem
</h2>
<div id="outline-text-headline-2">
<p>I needed to compare how long a program says it takes with how long it <em>actually</em>
takes to execute. So I wanted to run it a couple times and produce a graph
of real vs reported times.</p>
<p>
To do this, we could use the <code>time</code> command to retrieve its 'real' time. My program
already prints (to stdout) the time it says it takes to complete. The output looks like
"Time = x", where x is some decimal number. I'll describe the <code>time</code> output later.
The final table that I want the script to produce should look something like this
(these are just random numbers):</p>
<table>
<thead>
<tr>
<th>Trial</th>
<th>Real Time</th>
<th>Printed Time</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>12</td>
<td>2</td>
</tr>
<tr>
<td>2</td>
<td>44</td>
<td>5</td>
</tr>
<tr>
<td>3</td>
<td>21</td>
<td>3.6</td>
</tr>
<tr>
<td>…</td>
<td>…</td>
<td>…</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="outline-container-headline-3">
<h2 id="headline-3">
Awk
</h2>
<div id="outline-text-headline-3">
<div id="outline-container-headline-4">
<h3 id="headline-4">
Awk 101
</h3>
<div id="outline-text-headline-4">
<p>A good introduction is <a href="https://ferd.ca/awk-in-20-minutes.html">Awk in 20 minutes</a>, I'd recommend skimming through it.</p>
<p>
Awk is a text-processing language that revolves around <em>patterns</em> and <em>actions</em>.
Patterns are like regular expressions (e.g. <code>hello</code>, or <code>hello+</code> if you want one
or more 'o' characters), actions are just a list of statements (e.g. <code>{ print 1; }</code>).
All patterns are checked against every line, and there corresponding action
will be executed if there is a match.</p>
<p>
Here's an example of using awk to print 1 if some line of the input contains hello:</p>
<div>
<div><pre><code data-lang="bash">echo hello | awk <span>'/hello/ {print 1;}'</span></code></pre></div>
</div>
</div>
</div>
<div id="outline-container-headline-5">
<h3 id="headline-5">
Note on zsh's time
</h3>
<p>I use zsh's <code>time</code> which has a slightly different format to bash. Also, both output
to stderr so you'll notice <code>2&gt;&amp;1</code> which redirects stderr to stdout.</p>
</div>
<div id="outline-container-headline-6">
<h3 id="headline-6">
Building The Table With Awk
</h3>
<div id="outline-text-headline-6">
<p>We're going to need variables, like an index to a for loop, to print
the 'trial number'. No problem, we can initialize one with the <code>-v</code>
option like so <code>awk -v j=1 [script]</code> (set j to 1).</p>
<p>
We can also ask awk to give us the nth word in the current line with
<code>$n</code>, where n is some integer.</p>
<p>
And that's basically all we need! Here is the script:</p>
<div>
<div><pre><code data-lang="bash"><span># "Time" will appear before "java" in my output (e.g. "Time ...\n java ...\n Time ...\n ...").</span>
<span># Also, substr used to remove the 's' character from time's output</span>
awk -v j<span>=</span><span>1</span> <span>'/Time/{printf("%d %s ", j++, $3)} /java/{printf("%s\n", substr($5, 1, length($5)-1))}'</span></code></pre></div>
</div>
<p>I shall elaborate a little more.
My program could be run like <code>time ./java arg1 arg2 2&gt;&amp;1</code> which would produce 2 lines
of output, the first containing "Time = [integer]", the second containing the output
of <code>time</code>. So my awk script will either see "Time", where it will
print the index and integer, or it will print the real time after seeing "java".
Notice that I don't print a newline with the "Time" action (which will come first
in my output). So I can build a row from data that spans multiple lines (2 lines in
this case.) Also, my output doesn't have any lines that contain both "Time" and "java".</p>
<p>
When my program is run five times and the output is piped to that awk command, it produces
data like this:</p>
<div>
<div><pre><code data-lang="text">1 12.11 2.547
2 11.294 3.07
3 14.375 3.102
4 12.407 3.208
5 10.147 3.212</code></pre></div>
</div>
<p>
Which is what we want for gnuplot.</p>
</div>
</div>
</div>
</div>
<div id="outline-container-headline-7">
<h2 id="headline-7">
Gnuplot
</h2>
<div id="outline-text-headline-7">
<p>To plot our data, we could have two lines. One would use the second column for the y-axis, and the other
would use the third. Both use the first column (the trial number) for their x-axis<sup><a id="footnote-reference-1" href="#footnote-1">1</a></sup>.</p>
<p>
To tell gnuplot to use two columns: <code>using 1:2</code> or <code>u 1:2</code> specifies column 1 to be on the x-axis
and column 2 on y. To plot one line, you'd use <code>p "data.dat" u 1:2 title "My Plot" w lp</code> (<code>w lp</code> means
make it a line plot), but we want two lines, and also to use this without gnuplot's interactive mode, so
here's the full command:</p>
<div>
<div><pre><code data-lang="bash"><span># data.dat is my file name, convention seems to end it with *.dat.</span>
SETUP_OUTPUT<span>=</span><span>"set terminal png size 500,500; set output 'blogplot.png';"</span>
PLOT_DATA<span>=</span><span>"p 'data.dat' u 1:2 title 'Real Time' w lp, 'data.dat' u 1:3 title 'Printed Time' w lp"</span>
gnuplot -e <span>"</span>$SETUP_OUTPUT<span> </span>$PLOT_DATA<span>"</span></code></pre></div>
</div>
<p>
Which outputs to a png called <code>blogplot.png</code> when executed:
<img src="https://cyberchris.xyz/img/blogplot.png" alt="/img/blogplot.png" title="/img/blogplot.png"></p>
</div>
</div>


    </div></div>]]>
            </description>
            <link>https://cyberchris.xyz/posts/awk-and-gnuplot/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25863846</guid>
            <pubDate>Thu, 21 Jan 2021 20:33:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fastmail was down]]>
            </title>
            <description>
<![CDATA[
Score 121 | Comments 117 (<a href="https://news.ycombinator.com/item?id=25863731">thread link</a>) | @open-paren
<br/>
January 21, 2021 | https://www.fastmailstatus.com/services/general/2021-01-21 | <a href="https://web.archive.org/web/*/https://www.fastmailstatus.com/services/general/2021-01-21">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
        


<h2>General availability</h2>
<div>
  <p><a href="https://www.fastmailstatus.com/feed/services/general" title="Service RSS feed"><i></i> Feed</a>
</p></div>
<p id="service-description"> General access to FastMail (network etc)</p>


<h3>
  21 Jan 2021
</h3>



<table id="events">
  <thead>
    <tr>
      <th>Time</th>
      <th>Status</th>
      <th>Message</th>
    </tr>
  </thead>
  <tbody>
    
    <tr>
      <td>
        <a href="http://www.timeanddate.com/worldclock/fixedtime.html?year=2021&amp;month=01&amp;day=21&amp;hour=20&amp;min=55&amp;p1=0">
          21 Jan 2021 20:55:26 UTC
        </a><br>
        (3 days ago)
      </td>
      <td title="Up"><i></i></td>
      <td>The issue accessing our web services is now resolved. No mail has been lost.</td>
    </tr>
    
    <tr>
      <td>
        <a href="http://www.timeanddate.com/worldclock/fixedtime.html?year=2021&amp;month=01&amp;day=21&amp;hour=20&amp;min=19&amp;p1=0">
          21 Jan 2021 20:19:07 UTC
        </a><br>
        (3 days ago)
      </td>
      <td title="Warning"><i></i></td>
      <td>Users may see interruptions when accessing Fastmail services. We’re currently investigating.</td>
    </tr>
    
  </tbody>
</table>


<div id="legend">
  <h4> Status Legend </h4>
  <ul>
    
    <li>
      <p title="Up"><i></i> The service is operating normally
    </p></li>
    
    <li>
      <p title="Down"><i></i> The service is unavailable
    </p></li>
    
    <li>
      <p title="Warning"><i></i> The service is operating in a degraded capacity
    </p></li>
    
  </ul>
</div>


      </div></div>]]>
            </description>
            <link>https://www.fastmailstatus.com/services/general/2021-01-21</link>
            <guid isPermaLink="false">hacker-news-small-sites-25863731</guid>
            <pubDate>Thu, 21 Jan 2021 20:23:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Agile Development of a Novel]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25863650">thread link</a>) | @ynori7
<br/>
January 21, 2021 | https://www.scottfinlayauthor.com/articles/the-agile-development-of-a-novel | <a href="https://web.archive.org/web/*/https://www.scottfinlayauthor.com/articles/the-agile-development-of-a-novel">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><p>January 17, 2021</p><p>Everyone has read a novel and used software, but how many people really know how they're produced? It may
        surprise many (also within the two disciplines) to learn that the process of writing a book and that of
        writing software have quite a lot of similarities. The similarities are so profound, in fact, that tools and
        techniques used within one practice can be adapted and applied to the other to improve the process.</p><p>In the next paragraphs, I'll give a crash course on the different stages of software development and novel writing,
        underlining the parallels. I'll also demonstrate some of the enhancements I've been able to make by utilizing
        learnings from both worlds.</p><h2>Getting Started</h2><p>Before you actually start writing your story or your code, you need to set up your work environment and come up
    with a very high-level plan for what you want to create.</p><strong>The Development Environment</strong><p>It begins with the tools of the trade. Somehow authors and developers have to take the ideas in their heads and
        put them on paper (so to speak). Whether you're writing code, poetry, or prose, in the end, they're just words,
        and in their most basic state, they can be represented plainly without any formatting or special technology.</p><img src="https://www.scottfinlayauthor.com/frontend/img/articles/agile-development-novel/just-text.png" alt="Just Text" width="100%"><p>Both novels and software can be written in a simple text editor like notepad. Authors and developers tend to
        want more power than that, however, so at some point more advanced tools typically come into play. For authors,
        it usually comes in the form of a word processor which provides helpful features like spell-/grammar-checkers,
        advanced formatting, and reviewing tools. For developers, it's an IDE (integrated development environment).
        An IDE is essentially a word processor for code, providing many features such as automatic code compilation
        to ensure what you've written is syntactically correct (basically like a spell-checker), auto-completion, and
        a debugger (tool to help trace problems in an application). Both a word processor and an IDE are collections
        of tools on top of a basic text editor.</p><img src="https://www.scottfinlayauthor.com/frontend/img/articles/agile-development-novel/word-processor-ide.png" alt="Word Processor and IDE" width="100%"><p>An additional tool which every good developer should be using is version control software such as Git. VCS allows
        you to store a record of each change you make to your software and gives you the possibility to revert
        changes and compare them to older versions. It also allows you to maintain many "branches", which are like
        works-in-progress that have not yet been merged into the final product. This branching capability and
        centralized storage make collaboration significantly easier. Because version control software is so powerful
        and useful, I've leveraged it to store and keep track of changes for all my novels, and it has made my
        writing much easier (and safer, knowing that I always have a clean copy backed up in the cloud).</p><strong>The Premise</strong><p>Once you have your development environment set up, you need a project definition, or if you're an author, a
        premise. Both authors and coders need an idea, in the beginning perhaps vague like a "what if?", later being
        expanded into something more refined. Authors often expand upon the premise using outlines or mind maps.
        Developers often draw flowcharts or architectural diagrams. Both vigorously support the Post-it Note industry.</p><figure><img src="https://www.scottfinlayauthor.com/frontend/img/articles/agile-development-novel/scrum-board.jpg" alt="Scrum Board" width="550px"><figcaption>Image from <a href="https://commons.wikimedia.org/wiki/File:Scrum_task_board.jpg">Logan Ingalls</a>,
            <a href="https://creativecommons.org/licenses/by/2.0">CC BY 2.0</a>, via Wikimedia Commons.</figcaption></figure><p>A common practice when planning a software project is to break it down into "user stories", which are small
        deliverables written from the perspective of a user (to ensure that each deliverable brings value to a user).
        For a novel, you would typically begin by planning some of the key events and characters. This is one area
        where software development and writing differ in my opinion. Good software should be well-planned because every
        minute spent planning saves an hour of implementation. When writing a novel, however, I find that looser
        planning is better because it allows for plot and character developments to be born naturally from the flow.
        Every writer does it differently, however.</p><h2>Continuous Development</h2><p>The actual development or writing phase is a continuous process. For software developers practicing agile
        development, this continuous process is broken down in the form of "sprints" which are two-week (typically)
        stretches where a team works on a set of user stories they've committed to. For authors, this typically takes
        the form of chapters.</p><strong>Planning</strong><p>Typically a development sprint begins with planning. This generally involves looking through the tasks in the
        backlog with the highest priority, discussing and refining them, and estimating the effort, risks, and
        complexity. Once the tasks are clear, the team decides which tasks are ready for implementation and how much
        they can handle. When planning the next segment of a novel, I typically begin with bullet points, outlining
        the major plot developments I intend to write in the next chapter as well as any specific ideas I might have.</p><p>The planning phase may include a period of refinement, where you spend time thinking about the feature (or plot
        point) and all the edge cases. For software, edge cases would be those special cases that may require additional
        handling. For example, if the program should save a file, what should it do if a file already exists with the
        same name? When planning a novel, edge cases could be potential plot holes. Why do the characters behave the
        way they do, is it believable, and are the details consistent? Sometimes an edge case is complex and difficult
        to resolve and may require brainstorming, which may, for example, involve drawing diagrams (often the case for
        software architecture issues) or defining a list of options with pros and cons.</p><p>Often the planning phase involves investigation. In development, you often need to spend time learning a new
        technology, spending hours reading technical documentation, or digging down into existing code or aligning with
        other teams to understand the pieces which are already in place before you can really estimate the complexity
        and dependencies involved in a task. Writing a novel often requires minor expertise in many different fields,
        whether it be history, physics, or simply how to effectively dispose of a body. While writing
        <a href="https://www.scottfinlayauthor.com/a-fatal-exception">A Fatal Exception</a>, for instance, I spent a while researching ways to hack a
        prison’s locking mechanism, and I tried to find blueprints for a Chicago police department. That, in combination
        with some of the bloody research I did for <a href="https://www.scottfinlayauthor.com/epoch">Epoch</a>, probably puts me on a few NSA watchlists.
        Since research skills are vital for both writers and engineers, both need to develop skills in finding
        information and recognizing its trustworthiness.</p><strong>Implementation</strong><p>The implementation or writing phase is probably the most straightforward and the most enjoyable part of both
        software development and writing. It's in this phase where you really get to flex your creative muscles. This
        is also the phase which feels the most rewarding. As an artist, this is the part where you really give life to
        your story. As an engineer, this is the part where you create something which works autonomously.</p><p>It may be surprising to hear that one of the greatest difficulties facing both authors and programmers is naming
        things. You wouldn't believe how much thought a developer will put into how to name a variable or service or
        function. We hold meetings with twenty participants to come up with naming conventions (which can be important
        but can also be taken too far). You couldn't guess how many meetings and discussions I've participated in to
        decide whether to use <code>camelCase</code>, <code>PascalCase</code>, or <code>snake_case</code> for naming.</p><p>For authors, the situation is no better when naming your characters, places, organizations, alien races, or the
        actual book itself. In fact, it may be even more difficult in some regards. Since it's a creative process and
        not a technical one, there are no universal conventions or best practices that should be followed when naming
        things. I've spent days looking at lists of random things like mythological gods, astronomical bodies, flowers,
        you name it, and then verifying that nobody else already used the name for something similar, just to come up
        with the name of a character which will only appear in one chapter.</p><p>One thing that sets a good developer or writer apart from a bad one is the practice of documentation. This ought
        to be part of the implementation phase for every engineer and author, but for many, it's a much-despised and
        overlooked task. Good documentation allows others to understand what you've built as a developer (and saves
        you from answering dumb questions later). As a writer, documentation comes in the form of notes like character
        bios, timelines, and glossaries. Such notes are essential for keeping consistency across your book. You don't
        want to describe Dr. Perrywinkle as a middle-aged blonde man with glasses in chapter one and suddenly say he's
        a twenty-something with a mohawk in chapter eight. Good notes are critical for science fiction, fantasy, and
        mystery in particular.</p><strong>Quality Assurance (QA)</strong><p>After a round of writing code or prose, and often still during the writing phase, a round of quality assurance is
        done. This involves testing the code to ensure it works as defined in the specification and testing for
        regression (i.e. failure in already existing components as a result of new changes). In software, this includes
        executing automated tests within the code and performing manual testing in your …</p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.scottfinlayauthor.com/articles/the-agile-development-of-a-novel">https://www.scottfinlayauthor.com/articles/the-agile-development-of-a-novel</a></em></p>]]>
            </description>
            <link>https://www.scottfinlayauthor.com/articles/the-agile-development-of-a-novel</link>
            <guid isPermaLink="false">hacker-news-small-sites-25863650</guid>
            <pubDate>Thu, 21 Jan 2021 20:17:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learning 3D Modeling in 14 Weeks]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25862714">thread link</a>) | @moyicat
<br/>
January 21, 2021 | https://samanthaz.me/writing/learning-3d-modeling-in-14-weeks | <a href="https://web.archive.org/web/*/https://samanthaz.me/writing/learning-3d-modeling-in-14-weeks">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<div>
		
		<p><span>January 12, 2021</span>
		</p>
		
		

<p><br>
<img src="https://samanthaz.me/assets/img/2021-01-12-og.png" alt="The Great Sorcerer’s Room, 3D Model"></p>

<p>From March to May 2017, I picked up <span>3D</span> modeling skills. I started with zero <span>3D</span> experience (couldn’t even play <span>3D</span> games well), and I’m now able to create almost everything I want in the low poly style. My models also won an honorable mention and a staff pick on Sketchfab.</p>

<p>I want to share this journey and my methodology—I’m pretty good at picking up new skills. I learned <a href="https://app.milanote.com/1In0EK1nMGaC6F" target="_blank">watercolor sketch in about 5 weeks</a>, and I won two prizes at the 2018 Creating Reality Hackathon right after finishing the <span>VR</span> nanodegree program at Unity.</p>

<p>This post will focus on <span>3D</span> modeling, but these principles can really be applied to learning any new skill.</p>

<h3 id="1-regular-incremental-deliberate-practice-in-public">1. Regular, Incremental, Deliberate Practice in Public</h3>

<p>From my experiences, the first thing to do before getting started on a new skill is to setup a forcing function. A regular practice you can stick to. I find weekly to be manageable and also frequent enough. You can do daily or twice per week if it’s something small and you can afford it. I tend to think weekly is the minimum necessary to make it a part of your life’s rhythm.</p>

<p>Next, to actually force you to stick to it, make it public. I shared my work on both <a href="https://sketchfab.com/moyicat" target="_blank">Sketchfab</a> and <a href="https://dribbble.com/moyicat" target="_blank">Dribbble</a>, but you don’t have to use public communities. The key is really that it <em>isn’t</em> private. You can post your work to a group of friends. Some online courses come with homework. That’s great, too. Grab every resource to fight your tendency for procrastination and build momentum. Finally, don’t make it intimidating. Limit the scope as much as you can. Focus on baby steps and publishing your work rather than making it perfect.</p>

<p>I chose to recreate one room I like in <span>3D</span> every week. I decided to work from photos, so I don’t spend <em>any</em> time designing those rooms. (I can spend countless hours designing rooms in The Sims. It’s a trap!) Limiting the scope to rooms also ensured that I would focus on still-life, everyday objects, but kept the door open, so that if I want to put a cat in one of those rooms, I can.</p>

<p>Then, instead of learning the tool of trade, <a href="https://www.blender.org/" target="_blank">Blender</a>, right away, I started <em>really</em> light, with <a href="https://ephtracy.github.io/" target="_blank">MagicaVoxel</a>.</p>

<p>This idea came from my fascination with pixel art. Growing up, I wasn’t good at drawing, but I found that pixel art drastically limited the decisions I needed to make, and that made it easy for me. Instead of thinking about where to put a stroke on an entire blank canvas, I just needed to decide where to put it in a 16x16 grid.</p>

<p>I found the same thing with voxel art. Instead of learning how to use the rich feature set in Blender, I only needed to know about 6 buttons to get started.</p>

<p>Here’s room 01:</p>

<p>
		<a href="https://sketchfab.com/3d-models/room-01-magicavoxel-cbebf8f78edb4f80ac18b54f6771a90b" target="_blank">
			<img src="https://samanthaz.me/assets/img/2021-01-12-room-01.png" alt="Room 01">
		</a>
		<br>
		<span>Week 01: Simple shapes</span>
	</p>

<p>It looks half-decent, thanks to MagicaVoxel’s good out-of-the-box rendering functions, but it’s really just blocks and colors in a 32x32x32 space, nothing fancy. If I had chosen to start with Blender, I would have needed to spend hours familiarizing myself with all the hotkeys, as well as spend a lot of time on lighting and rendering.</p>

<p>I stuck with MagicaVoxel all the way until week 07. That’s half of the time I spent on this project. Limiting the scope really helped me to make quick incremental progress every week. You can click on each image to check out the models and the reference photos.</p>

<table>
  <tbody>
    <tr>
      <td><a href="https://sketchfab.com/3d-models/room-02-magica-voxel-42de6218d891419f8ad9e623777e003e" target="_blank"><img src="https://samanthaz.me/assets/img/2021-01-12-room-02.png" alt="Room 02"></a> <br> <span>Week 02: Complex shapes</span></td>
      <td>&nbsp;</td>
      <td><a href="https://sketchfab.com/3d-models/room-03-magicavoxel-220b133f5d9c40628b08beeb1dcdb260" target="_blank"><img src="https://samanthaz.me/assets/img/2021-01-12-room-03.gif" alt="Room 03"></a> <br> <span>Week 03: Stop-frame animation</span></td>
      <td>&nbsp;</td>
      <td><a href="https://sketchfab.com/3d-models/room-04-magicavoxel-27c20a0a51124f9c883c080f3323ea04" target="_blank"><img src="https://samanthaz.me/assets/img/2021-01-12-room-04.png" alt="Room 04"></a> <br> <span>Week 04: Tripling the space</span></td>
    </tr>
  </tbody>
</table>

<table>
  <tbody>
    <tr>
      <td><a href="https://sketchfab.com/3d-models/room-05-magicavoxel-a972ed2dd80946639f2798a173219352" target="_blank"><img src="https://samanthaz.me/assets/img/2021-01-12-room-05.png" alt="Room 05"></a> <br> <span>Week 05: Adding lights</span></td>
      <td>&nbsp;</td>
      <td><a href="https://sketchfab.com/3d-models/room-06-magicalvoxel-dc7298151a674057969d4f4938513a88" target="_blank"><img src="https://samanthaz.me/assets/img/2021-01-12-room-06.png" alt="Room 06"></a> <br> <span>Week 06: Improve light rendering</span></td>
      <td>&nbsp;</td>
      <td><a href="https://sketchfab.com/3d-models/room-07-magicavoxel-59d7f7e9c72840138e1fe0413c6017a6" target="_blank"><img src="https://samanthaz.me/assets/img/2021-01-12-room-07.png" alt="Room 07"></a> <br> <span>Week 07: Putting everything together</span></td>
    </tr>
  </tbody>
</table>

<p>That’s how a narrow focus can help you grow quickly. By the way, I also won SketchFab’s honorable mention and staff pick without knowing a thing about Blender between week 06 and 07.</p>

<p>My Blender learning curve was similar. It felt like I was relearning everything for a few weeks, but by that point, I already had a decent grasp of how to navigate the <span>3D</span> world and could focus on learning the interface and the features.</p>

<h3 id="2-follow-one-high-quality-course">2. Follow One High Quality Course</h3>

<p>As I switched to Blender, the learning curve got steeper. I couldn’t just push random buttons with hopes that I’d just figure it out. At that point, I knew I needed to find one high quality course that I could follow.</p>

<p>You don’t want multiple sources, because they might overlap, and might even have contradicting point of views. Pick a single, high-quality source. Paying for it isn’t bad either. A good course is always a worthy investment. And that sunk cost can be your motivation—it surely was for me.</p>

<p>I always try to find a step-by-step guide that I can follow along with. However, I know a programmer who can just read through 3 textbooks on <span>C#</span> and learn how to code in it. Choose your preferred format but choose one guide and stick to it.</p>

<p>I spent some time looking and settled with the <a href="https://www.udemy.com/course/blendertutorial/" target="_blank">Complete Blender Creator: Learn 3D Modelling for Beginners</a> course on Udemy (not affiliated). It has the highest example-to-content ratio, and I saw how I could follow one example each week and incorporate it into my weekly rooms. I got a steal on sale and bought it for just $15. Here’s my learning curve from week 08 to 14:</p>

<table>
  <tbody>
    <tr>
      <td><a href="https://sketchfab.com/3d-models/room-08-blender-a190ac56117e495c86a2e72a66b60c7b" target="_blank"><img src="https://samanthaz.me/assets/img/2021-01-12-room-08.png" alt="Room 08"></a> <br> <span>Week 08: Learning Interface</span></td>
      <td>&nbsp;</td>
      <td><a href="https://sketchfab.com/3d-models/room-09-blender-2f4bced20c5d436ca2da7d8843afbe14" target="_blank"><img src="https://samanthaz.me/assets/img/2021-01-12-room-09.png" alt="Room 09"></a> <br> <span>Week 09: Simple Shapes</span></td>
      <td>&nbsp;</td>
      <td><a href="https://sketchfab.com/3d-models/room-10-blender-e987089264d943c8912d6ac9452b8e6b" target="_blank"><img src="https://samanthaz.me/assets/img/2021-01-12-room-10.png" alt="Room 10"></a> <br> <span>Week 10: More Complex Shapes</span></td>
    </tr>
  </tbody>
</table>

<p>I was relying on Sketchfab’s rendering because I haven’t learnt how to do it in Blender yet. I also bent the idea of the “room” to fit the Udemy course content (“Bowling balls and Pins” and “Low Poly Chess Set”). I consider them not too far-fetched. Ron and Harry played life-size Wizard’s Chess in a room after all.</p>

<p>At that point, the course went into animation. That looked like a lot. I stopped there and practiced with what I’d learned. The progression was similar to the MagicaVoxel rooms, but now in Blender with more varying shapes:</p>

<table>
  <tbody>
    <tr>
      <td><a href="https://sketchfab.com/3d-models/room-11-blender-3a03869fdb3049b3a66cfefaa98c894f" target="_blank"><img src="https://samanthaz.me/assets/img/2021-01-12-room-11.png" alt="Room 11"></a> <br> <span>Week 11: Back to Reference</span></td>
      <td>&nbsp;</td>
      <td><a href="https://sketchfab.com/3d-models/room-12-blender-370c896a973244888337b0f8e5263fb7" target="_blank"><img src="https://samanthaz.me/assets/img/2021-01-12-room-12.jpg" alt="Room 12"></a> <br> <span>Week 12: Intricate shapes</span></td>
      <td>&nbsp;</td>
      <td><a href="https://sketchfab.com/3d-models/room-13-blender-8d26d03d4e7b473b8d050e6e0e888733" target="_blank"><img src="https://samanthaz.me/assets/img/2021-01-12-room-13.png" alt="Room 13"></a> <br> <span>Week 13: Organic Shapes</span></td>
      <td>&nbsp;</td>
      <td><a href="https://sketchfab.com/3d-models/room-14-blender-6ba9fd270bb04ddbb5d8eae11ed58f9f" target="_blank"><img src="https://samanthaz.me/assets/img/2021-01-12-room-14.png" alt="Room 14"></a> <br> <span>Week 14: Everything put together</span></td>
    </tr>
  </tbody>
</table>

<p>At that point, I felt confident that I could create a low-poly model of almost anything I want in Blender.</p>

<h3 id="3-cultivate-3d-sense-at-every-opportunity">3. Cultivate 3D Sense at Every Opportunity</h3>

<p>Another important piece of this journey was cultivating my <span>3D</span> imagination at every opportunity, because I had none at the beginning.</p>

<p>My ability to understand and imagine things in <span>3D</span> was so bad that I sucked at <span>3D</span> games for my entire life. It was embarrassing when my friends urged me to try World of Warcraft. 75% of the time I was asking “Where am I?” “Where are we going?” “Wait, where are the enemies coming from?” and “No…” because I died again. The other 25%? I was just spacebar following someone. At least that was easy :) As a UX designer, I can easily see <span>2D</span> designs in my head before I put down the pixels. Not being able to do the same in <span>3D</span> was frustrating.</p>

<p>So, what did I do? Deliberate practice, but in fun ways.</p>

<p>The first thing I picked up is Minecraft. It’s a <span>3D</span> game in its simplest format. Exploring caves and abandoned mine shafts, finding my way in roofed forests and ravines, I slowly grew from having to constantly cheat and check coordinates to having an idea about where I was going in winding tunnels.</p>

<p><img src="https://samanthaz.me/assets/img/2021-01-12-minecraft.png" alt="Minecraft Screenshot">
<span>Source: <a href="https://minecraft.gamepedia.com/File:Medium_Connected_Cavern.png" target="_blank">Official Minecraft Wiki</a></span></p>

<p>The other thing I did was signing up for a pottery class at my local community college. Physically holding clay in my hands and doing <span>3D</span> modeling in real world gave me a fresh perspective, and the relatively slow pace gave me time to think.</p>

<p><img src="https://samanthaz.me/assets/img/2021-01-12-pottery.jpg" alt="Head model made in pottery class" target="_blank"></p>

<p>I now have a way better ability to see objects in <span>3D</span> in my mind. And interestingly, it also helped my drawing—I had little real training and used to struggle with perspective a lot, but now that I’m better at imagining objects in <span>3D</span> and turning them around in my mind, it really helps.</p>

<h3 id="4-enter-competitions">4. Enter Competitions</h3>

<p>Now the last point, the secret ingredient: enter competitions.</p>

<p>We all need motivation to keep us going, and competition provides a clear objective, a clear timeline, and an opportunity to put our skills to the test. It’s especially fun to join as a newbie since you’ve got nothing to lose; and if by sheer chance you win something, that’s great external validation. Even if you lose, you will still have some really polished pieces, probably the best work you can do at the time.</p>

<p>I joined three Sketchfab competitions as I was learning <span>3D</span> modeling.</p>

<h6 id="my-ideal-planet-voxel">My Ideal Planet (Voxel)</h6>

<p>The first competition I entered was around week 06. I was lucky that a <a href="https://sketchfab.com/blogs/community/sketchfab-voxel-challenge-ideal-planet/" target="_blank">voxel challenge</a> dropped while I was deep in MagicaVoxel.</p>

<p>The brief was about creating one’s ideal planet in voxel, and that immediately led me to thinking about how <a href="https://en.wikipedia.org/wiki/The_Little_Prince" target="_blank">the little prince</a> traveled to many planets. What’s the most ideal planet? Definitely the scenario in which he returns to his planet, with the little sheep in the box. The sunset planet was the only competition, but that would be relying on a sunset backdrop to work, not the modeling itself.</p>

<p>So I started, day and night, tackling a way larger canvas than I ever had before. To make the composition more interesting, I put the little prince at a diagonal angle, and that took a lot of trial and error. The little prince and his little sheep were the only two living characters I’ve ever modeled. I also picked up more MagicaVoxel to Sketchfab exporting skills along the way.</p>



<p>Although there are a lot of imperfections (my biggest regret is I put the volcano in the dead center of the orb, which makes it too uptight), my hard work paid off, and it got both an honorable mention and a staff’s pick!</p>

<h6 id="utopia-low-poly">Utopia (Low-poly)</h6>

<p>The <a href="https://sketchfab.com/blogs/community/sketchfab-low-poly-utopia/" target="_blank">second challenge</a> dropped around week 13. It was about creating futuristic utopian assets under 2k triangles, which was perfect for my skill level. I wouldn’t have a chance in many Sketchfab challenges. Having a limit on the number of triangles leveled the playing field a bit for me.</p>

<p>I took the opportunity to learn simple animation in Blender, and again, just so I’d have a slightly better chance at winning, I spent more time on lighting and rendering in those challenges than in my weekly room practices.</p>

<p>Here’s the final rendering:</p>



<p>It didn’t win me anything, unfortunately, but that’s expected. Even without any prize, it’s a very nice piece …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://samanthaz.me/writing/learning-3d-modeling-in-14-weeks">https://samanthaz.me/writing/learning-3d-modeling-in-14-weeks</a></em></p>]]>
            </description>
            <link>https://samanthaz.me/writing/learning-3d-modeling-in-14-weeks</link>
            <guid isPermaLink="false">hacker-news-small-sites-25862714</guid>
            <pubDate>Thu, 21 Jan 2021 19:08:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dealing with Failure]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25862674">thread link</a>) | @rylandgold
<br/>
January 21, 2021 | https://docs.temporal.io/blog/dealing-with-failure | <a href="https://web.archive.org/web/*/https://docs.temporal.io/blog/dealing-with-failure">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p><strong>Latest Release at Time of Writing:</strong>&nbsp;V1.5.1</p><p>I recently gave a talk at the CodeMesh conference, and I spent half of it reflecting on the seemingly boring topic of dealing with failures. The talk was primarily based on my experience building and helping others build cloud services with the Orleans framework. I chose this topic, because I believe dealing with failures is the most important aspect of any system. Oftentimes, it is what stands between a product that runs as expected and one that keeps producing surprises and causing investigations. When done right, handling of failures is what differentiates a professional from an amateur.</p><p>The talk covered three approaches that I've seen and applied the most myself:</p><ul><li>Request-Reply (a.k.a RPC)</li><li>Using persistent queues</li><li>Workflows</li></ul><h2>1. Request-Reply</h2><p>In my opinion, Request-Reply (<a href="https://en.wikipedia.org/wiki/Remote_procedure_call" target="_blank" rel="noopener noreferrer">a.k.a. RPC -- Remote Procedure Call</a>), is the most natural way of handling failures. The client makes a request to the server and waits for a response (up to a timeout) and in most cases learns about a request processing failure immediately. This is how HTTP works, for example.</p><blockquote><p><em>Note that by client and server I mean simply two sides of the call. They can be real client and server processes or merely two tiny objects communicating with each other within a distributed system.</em></p></blockquote><p>Simplicity of RPC is good for the server.</p><blockquote><p><em>"I try to do what the request asked me to. If there's any failure downstream, I return it to the client. The client knows best what to do, to retry or not, how many times, with a backoff or not. My logic can stay simple."</em></p></blockquote><p>In our world of overly complicated systems, the value of simplicity is difficult to overstate. However, in this case the complexity burden gets pushed to the client. This puts the remote client at a disadvantage here. It has to operate based on the limited error information it received back. Sometimes it’s just a communication error or a timeout. These are a few of the many possible real life cases:</p><ul><li>An error may not be clear about whether the requested operation actually failed. It might have succeeded, and the error happened while trying to communicate success. This forces the client to either check for the status of the operations or retry anyway, assuming retrying the operation can be done safely, i.e. it is idempotent.</li><li>The system may be temporarily unavailable, actually being down or network partitioned from the client. For mobile applications that's rather expected.</li><li>Partial failures are hard to deal with. When we need to update multiple external systems at once, there is almost never a way to do that in an all-or-nothing manner, i.e. atomically. So, we have to handle retries and rollbacks, side effects, and all the inevitable complexity.</li></ul><p>The last point I illustrated with the following picture:
<img alt="Request-Reply" src="https://docs.temporal.io/assets/images/request-reply-325c282bb7603fc9a5ddd2cad338bac5.png"></p><p>In this example, the client (square blue thing) makes a request to the server (round green thing). The server does not have the information locally to satisfy the client request and therefore needs to call two external services, blue and purple.</p><p>If either of those two sub-calls fail, the server returns an error to the client. If the client were to retry the request, there would need to be a mechanism in the server that prevents duplicate calls to the external services.Idempotency is one method of addressing this issue. If the client decides to give up, there needs to be a way to revert any changes made as part of processing the request before the failure (in our example - of the call to the service A).</p><p>A canonical example is money transfer from an account in one bank to an account in a different bank. However, there are many other scenarios with conceptually indentical requirements. In many cloud orchestration cases we need to allocate a resource (such as a virtual machine), and then perform a number of operations with it before returning it in a ready state to the client. If any operation fails, we don’t want to leave the VM running. Nor do we want to keep allocating new VMs for the same request.</p><p>To summarize the pros and cons of the RPC approach.</p><p>Pros:</p><ul><li>Simplicity</li><li>Obvious correlation between a request and a failure</li></ul><p>Cons:</p><ul><li>Retries are client's responsibility and are difficult to do for a remote client</li><li>Partial failures are difficult to handle</li></ul><h2>2. Persistent Queues</h2><p>Putting a persistent queue between the client and server solves a number of problems. The client just needs to successfully send a request to the queue to ensure that it will eventually be processed.</p><p><img alt="Queue" src="https://docs.temporal.io/assets/images/queues-1aac9b7141813a8bfe886a9e95177e68.png"></p><p>Assuming the server only deletes a request from the queue after it is successfully processed, we get a simple retry mechanism. Due to the queue, even if the server crashes and restarts in between the attempts, it will keep trying to process the request again and again. The fact that the client (producer) is completely decoupled from the server (consumer), means the client can enqueue requests even if the server is down. This is the main reason why the publisher-subscriber architecture is so popular. Separation of subsystems in space and time is a nice property.</p><p><img alt="Chang'e-5" src="https://docs.temporal.io/assets/images/moon-orbit-37d5c6c62418d44366f16bb78cdc2c7f.jpeg"></p><h6><em>A simulated illustration of Chang'e-5 probe's orbiter-returner's separation from the ascender on the moon orbit, December 6, 2020. /CNSA</em></h6><p>For streaming one-way events, queues are great. But how can the client get a response in a queue based architecture? There's no good answer to this question that I'm aware of. Responses need to be delivered (somehow) back to the client, usually over another queue. Then the client needs a way to correlate requests and responses, typically done via correlation IDs. There also needs to be timeout mechanisms for dealing with requests that never received a response.</p><p>Retries are simpler with queues compared to the RPC case. They are pretty much automatic, as long as the request stays in the queue. Calls to external services still need to be idempotent. However, we can't retry forever and have to deal with requests that keep failing to process. Either because they clog the queue (if the queue is ordered), consume too many resources or cause excessive load on the external services. The popular approach is to treat such requests as "poison messages", by moving them out of the queue to a different location ("dead letter" queue) for special handling.</p><p>Pros:</p><ul><li>Separation of systems in space and time</li><li>Automatic retries</li><li>Simple when no responses are expected</li></ul><p>Cons:</p><ul><li>Additional dependency of the queueing technology</li><li>Extra work to correlate responses</li><li>Queues may clog</li><li>Special handling of "poison messages"</li></ul><h2>3. Workflows</h2><p>Similar to queues, workflows take the burden of ensuring successful execution of requests off the client's shoulders. But instead of writing them into a shared queue, requests are persisted as part of an independent workflow document. That document makes processing requests stateful:</p><ul><li>Tracking which steps of processing succeeded</li><li>Tracking which steps of processing failed</li><li>Remembering how many retries have been made, etc</li></ul><p><img alt="Workflow" src="https://docs.temporal.io/assets/images/workflows-d444c74006e2d1d51186cf7722b6dfd9.png"></p><p>Workflows have other important properties and use cases. They are a great way to implement long-running business processes, incorporate human operations and react to events. From the failure handling perspective, the most important aspect of workflows is the ability to be more intelligent when handling partial failures. Instead of being oblivious about what happened in the past, a workflow can keep a log of all relevant information and make informed decisions about what to retry and when.</p><p>Workflows can be individually addressable, which makes them easier to scale compared with shared queues. It also allows for targeted inspection and even on-the-fly modification of their state, if needed.</p><p>At the same time, workflows "inherit" most of the challenges of queues. Responses still need to be correlated with requests, although the individual addressability of workflows makes it easier for the client to query results. "Poison messages" are also still possible. They don't clog the queue anymore, but still require special handling.</p><p>Pros:</p><ul><li>Partial separation of systems in time and space</li><li>Robust handling of partial failures</li><li>Support for long-running operation</li><li>Retries are "automatic"</li></ul><p>Cons:</p><ul><li>Additional dependency on a workflow system or complexity of in-house implementation</li><li>Extra work to correlate responses</li><li>Special handling of "poison messages"</li></ul><h2>Conclusion</h2><p>It's a cliché that in our business there's no free lunch, only tradeoffs. As unoriginal as they might sound, many clichés are true. Dealing with failures is an area of important tradeoffs. There's obviously no single pattern that fits all scenarios. In fact, many systems leverage all three patterns I described.</p><p>For simpler requests that need a prompt response and aren’t involved with complex multi-step processing, Request-Reply is often the right approach. One-way messages, events, data streams are clear candidates for Queues. Workflows are a good fit for reliable execution of relatively complex requests that either require multi-step processing or can leak resources if failures aren't properly handled.</p></section></div>]]>
            </description>
            <link>https://docs.temporal.io/blog/dealing-with-failure</link>
            <guid isPermaLink="false">hacker-news-small-sites-25862674</guid>
            <pubDate>Thu, 21 Jan 2021 19:03:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Haskell: The Bad Parts]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25862646">thread link</a>) | @hypomnemata
<br/>
January 21, 2021 | https://www.snoyman.com/blog/2020/10/haskell-bad-parts-1/ | <a href="https://web.archive.org/web/*/https://www.snoyman.com/blog/2020/10/haskell-bad-parts-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
      <section>
        <div>
          <div>
            <div>
              <p>
                <a href="https://www.beginrust.com/">New: The "Begin Rust" book</a>
              </p>

              




  






<!--
<div class="container" id="blog-body">
  <div class="row">
    <div class="col-lg-9">
-->
      <p>
        <i>
          See a typo? Have a suggestion?
          <a target="_blank" rel="nofollow" href="https://github.com/snoyberg/snoyman.com/edit/master/content/blog/haskell-bad-parts-1.md">Edit this page on Github</a>
        </i>
      </p>

      <p>There's a popular book called <em>JavaScript: The Good Parts</em>. And there's a common meme around the relative size of that book versus <em>JavaScript: The Definitive Guide</em>.</p>
<p><img src="https://i.imgur.com/wIf3EJh.jpg"></p><p>Haskell is, in my opinion, a far more well designed and coherent language than JavaScript. However, it's also an old language with some historical baggage. In many ways, it's a bleeding edge research language that sometimes includes...half-baked features. Due to an inconsistent set of rules around backwards compatibility, it will sometimes break code every six months, and sometimes keep strange decisions around for decades.</p>
<blockquote><div lang="en" dir="ltr"><p>True mastery of Haskell comes down to knowing which things in core libraries should be avoided like the plague.</p><p>* foldl<br>* sum/product<br>* Data.Text.IO<br>* Control.Exception.bracket (use unliftio instead, handles interruptible correctly)</p><p>Just as some examples</p></div>— Michael Snoyman (@snoyberg) <a href="https://twitter.com/snoyberg/status/1321049221697544193?ref_src=twsrc%5Etfw">October 27, 2020</a></blockquote> 
<p>After a request and some tongue-in-cheek comments under that tweet, I decided a long-form blog post was in order. I'm going to start off by expanding on the four examples I gave in that tweet. But there are many, many more examples out there. If there's more interest in seeing a continuation of this series, please let me know. And if you have pet peeves you'd like me to address, your input will be very welcome.</p>
<h2 id="what-is-a-bad-part">What is a "bad part"?</h2>
<p>Very rarely is there such a thing: a language feature, function, type, or library—that is so egregiously bad that it should never, ever be used. Null is of course the billion dollar mistake, but it's still incredibly useful in some cases. So when I say that something is a "bad part" of Haskell, I mean something along these lines:</p>
<ul>
<li>A rarely useful feature has been promoted to a position of prominence</li>
<li>A function has major downsides that are not documented</li>
<li>There's an unexpected performance implication</li>
</ul>
<p>There's a large tendency in the Haskell community to be overly literal in responding to blog posts. Feel free to do that to your heart's content. But this caveat serves as a word of warning: I'm not going to caveat each one of these with an explanation of "Yes, but there's this one corner case where it's actually useful."</p>
<h2 id="why-attack-haskell">Why attack Haskell?</h2>
<p>Since I'm a Haskeller and an advocate of the language, you may be wondering: "Why are you attacking Haskell?" I don't see this as an attack. I <em>do</em> wish we could fix these issues. I think it's a fair thing to say that the problems I'm listing are warts on the language. And every language has warts. I'm writing this because I've seen these kinds of things break real world projects. I've seen these failures manifest at runtime, defeating yet again the false claim: "If it compiles, it works." I've seen these become nefarious time bombs that disincentivize people from ever working with Haskell in the future.</p>
<p>I hope by calling these out publicly, I can help raise awareness of these problems. Then either we fix the problems at their source or, more likely, get more widespread awareness of the issue.</p>
<p>Also, because it feels appropriate, I'm going to take a more jovial tone below. I find it easier to beat up on a language I love like that.</p>
<h2 id="foldl">foldl</h2>
<p>Duncan Coutts <a href="https://www.well-typed.com/blog/2014/04/fixing-foldl/">already did this one</a>. <code>foldl</code> is broken. It's a bad function. Left folds are supposed to be strict, not lazy. End of story. Goodbye. This function have caused too many space leaks. We should gut it out entirely.</p>
<p>But wait! A lazy left fold makes perfect sense for a <code>Vector</code>! Yeah, no one ever meant that. And the problem isn't the fact that this function exists. It's the <strong>name</strong>. It has taken the hallowed spot of the One True Left Fold. I'm sorry, the One True Left Fold is strict.</p>
<p>Also, side note: we can't raise linked lists to a position of supreme power within our ecosystem and then pretend like we actually care about vectors. We don't; we just pay lip service to them. Until we fix the wart that is overuse of lists, <code>foldl</code> is only ever used on lists.</p>
<p>OK, back to this bad left fold. This is all made worse by the fact that the true left fold, <code>foldl'</code>, is not even exported by the <code>Prelude</code>. We Haskellers are a lazy bunch. And if you make me type in <code>import Data.List (foldl')</code>, I just won't. I'd rather have a space leak than waste precious time typing in those characters.</p>
<p>Alright, so what should you do? Use an alternative prelude that doesn't export a bad function, but does export a good function. If you really, really want a lazy left fold: add a comment, or use a function named <code>foldlButLazyIReallyMeanIt</code>. Otherwise I'm going to fix your code during my code review.</p>
<h2 id="sum-product">sum/product</h2>
<p>The <code>sum</code> and <code>product</code> functions are implemented in terms of <code>foldr</code>. Well, actually <code>foldMap</code>, but list's <code>foldMap</code> is implemented in terms of <code>foldr</code>, and lists are the only data structure that exist in Haskell. "Oh, but <code>foldr</code> is the good function, right?" Only if you're folding a function which is lazy in its second argument. <code>+</code> and <code>*</code> are both strict in both of their arguments.</p>
<p>If you're not aware of that terminology: "strict in both arguments" means "in order to evaluate the result of this function/operator, I need to evaluate both of its arguments." I can't evaluate <code>x + y</code> without knowing what <code>x</code> and <code>y</code> are. On the other hand, <code>:</code> (list cons) is lazy in its second argument. Evaluating <code>x : y</code> doesn't require evaluating <code>y</code> (or, for that matter, <code>x</code>). (For more information, see <a href="https://www.fpcomplete.com/haskell/tutorial/all-about-strictness/">all about strictness</a>.)</p>
<p>"But wait!" you say. "What if I have a custom data type with a custom typeclass instance of <code>Num</code> that has a custom <code>+</code> and/or <code>*</code> that is in fact lazy in the second argument! Then <code>sum</code> and <code>product</code> are perfect as they are!"</p>
<p>That's true. Now go off and write your own <code>lazySum</code> and <code>lazyProduct</code>. 99 times out of 100, or more likely 999,999 times out of 1,000,000, we want the fully strict version.</p>
<p>"But it doesn't matter, GHC will optimize this away." Maybe. Maybe not. Stop relying on GHC's optimizer to convert horribly inefficient code into not efficient code. (But I digress, we'll talk about why the <code>vector</code> package is bad another time.)</p>
<h2 id="data-text-io">Data.Text.IO</h2>
<p>I've already covered this one once before when I told everyone to <a href="https://www.snoyman.com/blog/2016/12/beware-of-readfile">beware of <code>readFile</code></a>. In that blog post, I talked about a bunch of <code>String</code> based I/O functions, especially the titular <code>readFile</code>, which is obnoxiously exported by <code>Prelude</code>. Those are bad. But <code>Data.Text.IO</code> is arguably far worse, and I'll reiterate why in a second. The reason is that there's pretty good awareness in the community that <code>String</code>-based I/O is bad. Even though the <code>String</code> part is the least of our worries, it does a good job of scaring away the uninitiated.</p>
<p>But <code>Data.Text.IO</code> is a wolf in sheep's clothing. We're all told by people who think they can tell people how to write their Haskell code (<em>cough</em> me <em>cough</em>) that we should exorcise <code>String</code> from our codebases and replace it in all cases with <code>Text</code>. Attacking the <code>Text</code> type is a topic for another time. But the problem is that by cloaking itself in the warm embrace of <code>Text</code>, this module claims more legitimacy than it deserves.</p>
<p>The only module worse in this regard is <code>Data.Text.Lazy.IO</code>, which should be buried even deeper.</p>
<p>OK, what exactly am I on about? Locale sensitive file decoding. It's possible that this has been the number one example of a Haskell bug in the wild I've encountered in my entire career. Not the spooky memory leak. Partial functions like <code>head</code> randomly throwing exceptions are up there, but don't quite rise to prominence.</p>
<p>You see, when you are dealing with file formats, there is typically an actual, defined format. YAML, XML, JSON, and many others give a lot of information about how to serialize data, including character data, into raw bytes. We want to be consistent. We want to write a file in one run of the program, and have it read in a separate run. We want to write the file on a Windows machine and read it on a Linux machine. Or we want to interact with programs in other languages that read or write data in a consistent format.</p>
<p>Locale sensitive file encoding and decoding laughs in our face. When you use <code>Data.Text.IO.readFile</code>, it plays a mind reading game of trying to deduce from clues you don't care about which character encoding to use. These days, on the vast majority of systems used by native English speakers, this turns out to be UTF-8. So using <code>readFile</code> and <code>writeFile</code> typically "just works." Using functions from <code>Data.Text.IO</code> looks safe, and can easily get hidden in a large PR or a library dependency.</p>
<p>That's when all hell breaks loose. You ship this code. You run it in a Docker container. "Oops, you forgot to set the <code>LANG</code> env var, Imma crash." But it's worse than that. Typically things will work well for weeks or months, because it can often be a long time before someone tries to encode a non-ASCII character.</p>
<p>The same kind of thing happens regularly to Stack. Someone adds a new feature that writes and reads a file. The code passes all integration tests. And then someone in Russia with a weird Windows code page set and a Cyrillic character in their name files a bug report 2 years later about how they can't build anything, and we sheepishly tell them to run <code>chcp 65001</code> or build in <code>c:\</code>.</p>
<p>Friends don't let friends use <code>Data.Text.IO</code>.</p>
<p>"Oh, but <code>putStrLn</code> is fine!" Yeah, maybe. It's also potentially slow. And it will throw a runtime exception due to character encoding mismatches. Just use a good logging library. That's why we have one in <code>rio</code>.</p>
<p><strong>EDIT</strong> Since so many people have asked: instead of <code>readFile</code>, I recommend using <a href="https://www.stackage.org/haddock/lts-16.20/rio-0.1.19.0/RIO.html#v:readFileUtf8"><code>readFileUtf8</code></a>, which is available from <a href="https://github.com/commercialhaskell/rio"><code>rio</code></a>.</p>
<h2 id="control-exception-bracket">Control.Exception.bracket</h2>
<p>This is by far the least objectionable of the bad things in this list. I included it because the entire original tweet was inspired by a coworker telling me about a bug he ran into because of this function.</p>
<p>Async exceptions are subtle. Very, very subtle. Like, super duper subtle. I've devoted a large percentage to …</p></div></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.snoyman.com/blog/2020/10/haskell-bad-parts-1/">https://www.snoyman.com/blog/2020/10/haskell-bad-parts-1/</a></em></p>]]>
            </description>
            <link>https://www.snoyman.com/blog/2020/10/haskell-bad-parts-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25862646</guid>
            <pubDate>Thu, 21 Jan 2021 19:01:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Internet Business 101]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25862179">thread link</a>) | @nadermx
<br/>
January 21, 2021 | https://johnathannader.com/internet-business-101/ | <a href="https://web.archive.org/web/*/https://johnathannader.com/internet-business-101/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <div>
    
    <div>
      <div>
        
        <p>john | Jan. 21, 2021, 6:24 p.m.</p>
        <p>So you want to start an internet business and don't know what to do.&nbsp; Don't worry I've made this wonderful write down on how exactly you can make one.</p><p>The first step is of course, choosing your name.&nbsp; Now thankfully you where given this at birth, so one less thing you have to think about.&nbsp; Of course you may be the unfortunate person to be born with a very common name.&nbsp; Or worse, the name of a famous person.</p><p>If you happen to be one of these unfortunate individuals, there is still hope for you.&nbsp; The next option would of course be to either choose a domain that answers the problem you are trying to solve, in the most literal sense.&nbsp; Or simply make up a word and go with that.</p><p>You could do both and make up a word and be literal, but that leads to terrible brand names, like pen island.&nbsp; Imagine that as a domain, penisland, just doesn't have the same bravado.</p><p>Once you have chosen the name, you can move on to step two.&nbsp; Making the damn website.&nbsp; You don't need much.&nbsp; This is the hard part.&nbsp; Although there are many no code solutions, and many semi code solutions, and of course tons of do it your self solutions.&nbsp; I suggest none of this, instead I think you should do what you have been doing all along.&nbsp; Nothing.<br></p><p>After we have moved past step two, you realize you don't even know what to put on your website.&nbsp; This is the greatest moment, I suggest one of two things.&nbsp; Either a way for some one to contact you, or just an email sign up form.<br></p><p>Of course you want to be spam-act complaint, so make sure they are double opt in.</p><p>This will do a multitude of things for you, specifically make it appear as though you have your life in order.&nbsp; Of course you don't, this is simply a facade, granted a very beautiful and useful one.&nbsp; It will make you appear as though you are a massive corporation capable of doing many things.</p><p>Now that you have arrived to this moment in time, you may realize that you are in over your head.&nbsp; This is normal, it's the start of your internet business.&nbsp; No one knows what it does, but because that in its self is more than not existing, there might be a individual or two who decides they are curios enough to see what you have to offer.</p><p>I mean after all you are a legitimate, internet business.&nbsp; And since Craigslist looks hideous, but absolutely superbly functional,&nbsp; there is a chance even your simple one page wordpress website will actually be seen by one of the seven billion people on this planet that will perhaps, click the back button and continue on with their life.</p>
      
       <p>P.S. Subscribe to my <a href="https://johnathannader.com/newsletter/">newsletter</a> and follow me on <a href="https://twitter.com/nadermx" rel="nofollow noopener" target="_blank">twitter</a></p>
      </div>
    

    </div>
  </div>
</div></div>]]>
            </description>
            <link>https://johnathannader.com/internet-business-101/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25862179</guid>
            <pubDate>Thu, 21 Jan 2021 18:25:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apache Superset 1.0 Released]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25861883">thread link</a>) | @skadamat
<br/>
January 21, 2021 | https://preset.io/blog/2021-01-18-superset-1-0/ | <a href="https://web.archive.org/web/*/https://preset.io/blog/2021-01-18-superset-1-0/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>Apache Superset is an open source enterprise-ready data exploration, data visualization and dashboarding application that enables teams to be productive with data.</em></p><p>Today our community is proud to announce the release of <strong>Apache Superset 1.0</strong>, a major milestone that we’ve been working towards since the very first commit at a hackathon at Airbnb back in 2015. Superset 1.0 packs a lot of new features, uplevels usability, holds a higher quality standard, and raises the bar for releases to come. This post details the key advancements that our community has been building up towards this release.</p><p>While growing fast over the past four years, Superset had accumulated a certain amount of technical debt, design debt, bugs, and idiosyncrasies. For this release, we wanted to pay the bulk of that debt off, <strong>streamlining the core user flows</strong>, refreshing the overall look and feel, taking off some of the scaffolding that was left standing around, and more generally, leveling up the user experience.</p><p>Visually, Superset 1.0 is <strong>stunning</strong>, introducing <strong>card layouts</strong> with <strong>thumbnails</strong> throughout the application, streamlining <strong>navigation</strong> and <strong>content discovery</strong> with a new home page, redesigned menus, and generally enriching existing pages.</p><p><span><span>
      <a target="_blank" rel="noopener" href="https://preset.io/static/a90bd0033d1ec61cd18edfd5bf0d4498/356e8/dashboard_card_view.jpg">
    <span></span>
  <img alt="Dashboard Card View" title="Dashboard Card View" src="https://preset.io/static/a90bd0033d1ec61cd18edfd5bf0d4498/49b61/dashboard_card_view.jpg" srcset="https://preset.io/static/a90bd0033d1ec61cd18edfd5bf0d4498/bc01b/dashboard_card_view.jpg 188w,https://preset.io/static/a90bd0033d1ec61cd18edfd5bf0d4498/80d0c/dashboard_card_view.jpg 376w,https://preset.io/static/a90bd0033d1ec61cd18edfd5bf0d4498/49b61/dashboard_card_view.jpg 752w,https://preset.io/static/a90bd0033d1ec61cd18edfd5bf0d4498/9d222/dashboard_card_view.jpg 1128w,https://preset.io/static/a90bd0033d1ec61cd18edfd5bf0d4498/20b4c/dashboard_card_view.jpg 1504w,https://preset.io/static/a90bd0033d1ec61cd18edfd5bf0d4498/356e8/dashboard_card_view.jpg 1512w" sizes="(max-width: 752px) 100vw, 752px" loading="lazy" data-shadowed="true">
  </a>
    </span></span></p><p>Behind the scenes, we moved away from <a href="https://getbootstrap.com/2.3.2/">Bootstrap 2x</a> in favor of building a proper design system on top of <a href="https://ant.design/">Ant Design</a>. We also redesigned all of our <strong>CRUD</strong> (Create Read Update Delete), moving away from the rigid scaffolding “auto-magic” provided by <a href="https://flask-appbuilder.readthedocs.io/en/latest/">FAB</a> (Flask App Builder), to our own React-based solution that enables us to build richer experiences.</p><p><span><span>
      <a target="_blank" rel="noopener" href="https://preset.io/static/9397936b9c84c013653bccfd0ded978c/7c2ea/explore_ui.jpg">
    <span></span>
  <img alt="Explore UI" title="Explore UI" src="https://preset.io/static/9397936b9c84c013653bccfd0ded978c/49b61/explore_ui.jpg" srcset="https://preset.io/static/9397936b9c84c013653bccfd0ded978c/bc01b/explore_ui.jpg 188w,https://preset.io/static/9397936b9c84c013653bccfd0ded978c/80d0c/explore_ui.jpg 376w,https://preset.io/static/9397936b9c84c013653bccfd0ded978c/49b61/explore_ui.jpg 752w,https://preset.io/static/9397936b9c84c013653bccfd0ded978c/9d222/explore_ui.jpg 1128w,https://preset.io/static/9397936b9c84c013653bccfd0ded978c/20b4c/explore_ui.jpg 1504w,https://preset.io/static/9397936b9c84c013653bccfd0ded978c/7c2ea/explore_ui.jpg 1522w" sizes="(max-width: 752px) 100vw, 752px" loading="lazy" data-shadowed="true">
  </a>
    </span></span></p><p>More generally, many rough edges got buffed, the whole product got polished, and we managed to get our core user flows to, well, <strong>flow nicely.</strong></p><p><span><span>
      <a target="_blank" rel="noopener" href="https://preset.io/static/3111660c657424da40e63ac184f055f8/7e26b/home_screen.jpg">
    <span></span>
  <img alt="Home Screen" title="Home Screen" src="https://preset.io/static/3111660c657424da40e63ac184f055f8/49b61/home_screen.jpg" srcset="https://preset.io/static/3111660c657424da40e63ac184f055f8/bc01b/home_screen.jpg 188w,https://preset.io/static/3111660c657424da40e63ac184f055f8/80d0c/home_screen.jpg 376w,https://preset.io/static/3111660c657424da40e63ac184f055f8/49b61/home_screen.jpg 752w,https://preset.io/static/3111660c657424da40e63ac184f055f8/9d222/home_screen.jpg 1128w,https://preset.io/static/3111660c657424da40e63ac184f055f8/20b4c/home_screen.jpg 1504w,https://preset.io/static/3111660c657424da40e63ac184f055f8/7e26b/home_screen.jpg 1510w" sizes="(max-width: 752px) 100vw, 752px" loading="lazy" data-shadowed="true">
  </a>
    </span></span></p><p>For engineers and hackers, we’ve made Superset much more <strong>modular, extensible </strong>and<strong> integratable</strong>. We’re now exposing the building blocks of Superset for engineers to extend or use in other projects. It’s now easier than ever to create new <a href="https://preset.io/blog/2020-07-02-hello-world/">visualization plugins</a> for Superset and to share those plugins back with the community. We’re excited by the possibilities that this opens and excited to  observe a growing ecosystem of plugins take life.  We’ve also <a href="https://preset.io/blog/2020-10-01-superset-api/">formalized a public REST API</a> that enables engineers to essentially do everything that users can do in Superset, programmatically.</p><p><span><span>
      <a target="_blank" rel="noopener" href="https://preset.io/static/4b12ea61e107c55fd0c036a19588867f/d70ac/rest_api.jpg">
    <span></span>
  <img alt="REST API" title="REST API" src="https://preset.io/static/4b12ea61e107c55fd0c036a19588867f/49b61/rest_api.jpg" srcset="https://preset.io/static/4b12ea61e107c55fd0c036a19588867f/bc01b/rest_api.jpg 188w,https://preset.io/static/4b12ea61e107c55fd0c036a19588867f/80d0c/rest_api.jpg 376w,https://preset.io/static/4b12ea61e107c55fd0c036a19588867f/49b61/rest_api.jpg 752w,https://preset.io/static/4b12ea61e107c55fd0c036a19588867f/9d222/rest_api.jpg 1128w,https://preset.io/static/4b12ea61e107c55fd0c036a19588867f/20b4c/rest_api.jpg 1504w,https://preset.io/static/4b12ea61e107c55fd0c036a19588867f/d70ac/rest_api.jpg 3408w" sizes="(max-width: 752px) 100vw, 752px" loading="lazy" data-shadowed="true">
  </a>
    </span></span></p><p>Superset is now more <strong>secure</strong> than ever before. <a href="https://preset.io/">Preset</a> commissioned penetration testing on the product and led the charge to fix all discovered vulnerabilities and set up automation mechanisms to prevent regression. We’ve also committed to doing regular pentesting audits to ensure that we catch issues. We’ve refined our processes around resolving security issues while pushing through a handful of well-handled CVEs (<a href="https://cve.mitre.org/">Common Vulnerabilities and Exposures</a>) over the past year. Also important, we’ve <strong>simplified the security model</strong> in Superset to a simpler set of atomic permissions to make it more comprehensive.</p><p>Because we wanted to make it easier for people to manage and share the objects they’re building in Superset, we’ve rebuilt the <strong>export/import </strong>functionality from the ground up. This allows organizations to manage and synchronize objects across environments, and for users to share the assets that they’ve built easily.</p><p>We’ve also completely redesigned our <strong>community website </strong> at <a href="https://superset.apache.org/">superset.apache.org</a> and made it the official hub for our fast growing community. All of the resources expected from a mature open source community can be found and contributed to there.</p><p><strong>Reporting</strong> and <strong>alerting</strong> has always been highly requested in the community, and 1.0 packs a solid implementation that can support most use cases. This enables periodic email delivery of reports, as well as an alerting system that can monitor your metrics arbitrary shifts and alert you as specified. We built an extensible system that we can expand to more delivery mechanisms and forecasting/alerting logic.</p><p><span><span>
      <a target="_blank" rel="noopener" href="https://preset.io/static/37331b89e53a8945504d6c5445d5b253/76188/alerts_reports_2.jpg">
    <span></span>
  <img alt="Alerts and Reports" title="Alerts and Reports" src="https://preset.io/static/37331b89e53a8945504d6c5445d5b253/49b61/alerts_reports_2.jpg" srcset="https://preset.io/static/37331b89e53a8945504d6c5445d5b253/bc01b/alerts_reports_2.jpg 188w,https://preset.io/static/37331b89e53a8945504d6c5445d5b253/80d0c/alerts_reports_2.jpg 376w,https://preset.io/static/37331b89e53a8945504d6c5445d5b253/49b61/alerts_reports_2.jpg 752w,https://preset.io/static/37331b89e53a8945504d6c5445d5b253/9d222/alerts_reports_2.jpg 1128w,https://preset.io/static/37331b89e53a8945504d6c5445d5b253/20b4c/alerts_reports_2.jpg 1504w,https://preset.io/static/37331b89e53a8945504d6c5445d5b253/76188/alerts_reports_2.jpg 1772w" sizes="(max-width: 752px) 100vw, 752px" loading="lazy" data-shadowed="true">
  </a>
    </span></span></p><p><span><span>
      <a target="_blank" rel="noopener" href="https://preset.io/static/d00574f84c34438f27bea0119635a0af/0ef85/alerts_reports_3.jpg">
    <span></span>
  <img alt="Alerts and Reports Edit UI" title="Alerts and Reports Edit UI" src="https://preset.io/static/d00574f84c34438f27bea0119635a0af/49b61/alerts_reports_3.jpg" srcset="https://preset.io/static/d00574f84c34438f27bea0119635a0af/bc01b/alerts_reports_3.jpg 188w,https://preset.io/static/d00574f84c34438f27bea0119635a0af/80d0c/alerts_reports_3.jpg 376w,https://preset.io/static/d00574f84c34438f27bea0119635a0af/49b61/alerts_reports_3.jpg 752w,https://preset.io/static/d00574f84c34438f27bea0119635a0af/9d222/alerts_reports_3.jpg 1128w,https://preset.io/static/d00574f84c34438f27bea0119635a0af/20b4c/alerts_reports_3.jpg 1504w,https://preset.io/static/d00574f84c34438f27bea0119635a0af/0ef85/alerts_reports_3.jpg 2826w" sizes="(max-width: 752px) 100vw, 752px" loading="lazy" data-shadowed="true">
  </a>
    </span></span></p><p>Around the topic of<strong> open source governance</strong>, Superset <strong>graduated</strong> from the incubator to become a top-level project at the <strong>Apache Software Foundation</strong>. As a project that had been incubating since 2016, we finally ironed out some minor licensing issues, prevented license-related regressions using <a href="https://fossa.com/">FOSSA</a>, and started publishing proper ASF releases on a regular cadence. We also actively worked towards fitting the <a href="https://community.apache.org/apache-way/apache-project-maturity-model.html">Apache Project Maturity Model</a>, aligning with the governance model prescribed by the ASF and took action to grow the community in sustainable ways. The graduation formally recognizes that the community has complied with all the requirements, and operates at the high standard required by the ASF.</p><p>With 1680 PRs merged and 25+ <a href="https://github.com/apache/incubator-superset/issues?q=is%3Aissue+label%3Asip">SIPs</a> (Superset Improvement Proposals) over 2020, it’s hard to summarize what went into this release. Improvements happened in all aspects of the project, from infrastructure to design, through backend and frontend, to community and governance. Here are some <strong>honorable mentions</strong> that we haven’t been covered above, but deserve a mention in this post:</p><ul><li><a href="https://github.com/apache/incubator-superset/pull/11499">Asynchronous backend improvements</a></li><li>Metadata and data pane in explorer view</li><li>Toolbars redesign (SQL Lab, dashboard, explore)</li><li>Date range picker redesign</li><li>Various Docker / Helm improvements</li><li>Migration of key visualization to plugins using <a href="https://echarts.apache.org/">Echarts</a></li><li>Time series forecasting leveraging the <a href="https://facebook.github.io/prophet/">Prophet</a> library</li><li>Improvements to and extensive use of our feature flag framework</li><li>Improved analytics logging, capturing more events more consistently</li><li>Exploration control panels improvements</li><li>Improved SQL-to-explore flows</li></ul><p>All-in-all, Superset has come a long way recently and this release marks the project entering its mature stage. The community has gained velocity and momentum, and yet we’re still accelerating. 1.0 marks a huge milestone in our journey to delight data teams with the most comprehensive and modern analytics platform there is, but clearly this is still the beginning of a much greater adventure.</p><p>Congratulations to all contributors and to sponsoring organizations, this is a huge achievement!</p><p><a href="https://superset.apache.org/">Join our community! Get involved!</a></p></div></div>]]>
            </description>
            <link>https://preset.io/blog/2021-01-18-superset-1-0/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25861883</guid>
            <pubDate>Thu, 21 Jan 2021 18:01:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Treat Everyone as Remote]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25861403">thread link</a>) | @jstanier
<br/>
January 21, 2021 | https://www.theengineeringmanager.com/remote-working/treat-everyone-as-remote/ | <a href="https://web.archive.org/web/*/https://www.theengineeringmanager.com/remote-working/treat-everyone-as-remote/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="primary" role="main">
		
<article id="post-1498">

			<!-- end .entry-header -->

		<div>
		
		<div>
			
<p><em>This article is part of a series on </em><a href="https://www.theengineeringmanager.com/remote-working/"><em>remote working</em></a><em>.</em></p>



<h2>Second-class citizens</h2>



<p>In the past, a common challenge that remote workers have faced is <a href="https://hbr.org/2017/11/a-study-of-1100-employees-found-that-remote-workers-feel-shunned-and-left-out">feeling like they are several steps removed from the rest of the physically colocated company</a>. This manifests repeatedly: day in, day out. It reveals itself in the nagging instinct that discussions and decisions are happening in person without giving remote workers the ability to have their input. It can come from the worryingly empty email inbox during challenging periods, or the strangely quiet chat rooms. It arises when joining a meeting via video call to see ten tiny figures sitting around a conference room table, sharing one microphone.</p>



<p>This is when remote working sucks. You feel like an <em>other</em>; unlike all of the other “normal” staff. Perhaps even like a lesser member of the company. This isn’t right. However, none of this should be attributed to malice. After all, for decades we have been used to working together in offices. Old habits die hard, especially if they aren’t being challenged.</p>



<p>I remember a long time ago when the magnetic hub of our company was our HQ in Brighton. The anecdote in mind happened when we were hiring rapidly after receiving a funding round. We had monthly induction sessions for new starters that walked them through what the company did, the software we built, how we marketed it and sold it — all of that good stuff. These inductions were organized well, planned and practiced, and generally speaking were a fun, informative experience.</p>



<p>That is, except for the month when we started onboarding some engineers in our smaller Stuttgart office. They would turn up to the meeting, join the video call, and wait for the person leading the session in Brighton to join. But they never did. Messages were sent that were unanswered. Everyone’s laptops were closed. No malice, just forgetfulness. But that forgetfulness, repeated daily, compounds into larger frustrations about “being remote” in comparison to other members of staff that are not.</p>



<h2>Equality</h2>



<p>We should be aiming to treat everyone equally.</p>



<p>What this needs is a mindset shift. The title of the article says it all really: <em>treat everyone as remote</em>. That’s how you solve the problem of any worker in your company feeling like they are “remote”. You simply act as if everyone is, thus cancelling out the prefix: if <em>everyone </em>is treated like a remote worker, then really, they’re all just <em>workers</em>. Equal. No longer do the remote workers need to continually put in additional effort in order to gather information that they have missed, or to remind people that they are still there, or that their timezone is different. Instead, they just do their work just like everyone else, and interact with others like everyone else.</p>



<p>Even though this is simple, it isn’t straightforward. It’s a little bit like if you’ve ever tried to meditate. It’s simple: just continually focus on your breathing. But it’s not straightforward: your mind wanders and you get caught up in thoughts. You bring your attention back to your breath, and guess what, your mind is generating thoughts again.</p>



<p>Treating everyone as remote requires a mindset shift in every individual in the entire company. It means that every action and interaction should be done in such a way that equally benefits somebody regardless of whether they are present in a physical office or not. This can best be explained by example, and at the time of writing we’re living through the largest remote working experiment in the technology industry: a global pandemic.</p>



<p>Below is a screenshot of the first remote cabinet meeting of the UK government from March 2020. At this point the country had been put under the first initial lockdown measures, indicating that everyone who was able to work from home should do so. In what should now be a familiar sight to most people, the meeting was being conducted via Zoom.</p>



<p>Most participants of this call are remote, and are therefore acting in the correct way to <em>treat everyone as remote</em>. However, there is one group of participants that are not abiding by this rule. On the top row, second from left, the Cabinet Room has joined the meeting via a traditional meeting room AV setup: one fixed camera and a microphone in the middle of a shared table.</p>



<figure><img src="https://lh6.googleusercontent.com/t73c0UeykYzMpRXWNUt5mnWSzQ8QxdxkpfLgBhgNynor06iEw6F0R4G1dJJhpjhbrt1rM36Fz3HUeWKdGv5YVtNiKxPnrzqIR6bugmeZsmWo0MswTG-ru5kWWr72WBcIp0IwPOaZ" alt=""></figure>



<p>Whereas all other participants have a microphone and camera each, allowing them to properly see and hear each other, being able to understand the facial expressions of the person sitting farthest away on the Cabinet Room table requires some serious CSI “enhance!” magic. Do you reckon that everyone else on this call got frustrated with not being able to see or hear them properly? Do you think that they may have experienced, perhaps for the first time, one of the frustrations of being a remote worker when others do not treat everyone as remote? Ah, yes. That.</p>



<p>So this is the first big thing when it comes to truly supporting remote workers. The entire company needs to adopt a mindset where they treat everyone as remote. <em>E</em>very action via code, written or spoken word should provide an equal interaction opportunity to anyone regardless of their location.</p>



<h2>Actions and initiatives</h2>



<p>This can be done by performing some of the following actions and initiatives.</p>



<ul><li><strong>Give your declaration of intent.</strong> You can’t expect anyone to begin changing if you don’t talk about your intention clearly. As explored in my <a href="https://www.theengineeringmanager.com/remote-working/2020-a-year-spent-remotely/">initial post reflecting on a year spent remotely</a>, there are plenty of reasons for beginning to act like a remote-first company, even if that may not be your final trajectory. Tell yourself, your team, and others that you know that you are going to be changing your working practices to better support remote workers. Like our meditation example above, this may be simple, but it isn’t straightforward. You may find yourself having to repeat this message, in combination with taking the actions below, for it to really sink in.</li><li><strong>Shift to asynchronicity. </strong>Synchronous communication is essential, but maybe not always as essential as you think. Adopt a mindset where you question all of your synchronous communication — such as video calls and instant messages — and see whether you can move to more asynchronous alternatives such as email and writing documents. Not only will this reduce the time that you spend in meetings, which can be draining and interrupting for everyone’s flow, it will produce more artifacts that can be shared and read more widely at a later date.</li><li><strong>Make your time and commitment expectations clear. </strong>Shifting to more asynchronous communication means that the time taken to close the loop may be longer. However, it’s more inclusive, and often better thought through. Working with your colleagues to help them understand that this is purposeful, and most importantly, perfectly normal, is something that you’ll need to do. State your intention that it’s OK to not read something if it’s not specifically important to an individual. Also say that it’s OK to take until the end of the week to read and comment on a proposal. The net effect is increased autonomy and flow.</li><li><strong>Choose appropriate tools to support remote collaboration. </strong>I often take for granted that we are already avid users of Google’s office suite, which has excellent collaboration and commenting capabilities. The same is true for Github, Slack, Miro and Figma, and others. However, some companies still make it extremely hard to collaborate effectively, such as by emailing around local copies of documents which then require a copy to be made and so on, until you reach <em>final_version_7_FINAL.doc.</em> Champion better tools and demonstrate them to your colleagues to drive bottom-up change. Ask those with the power to make decisions and spend budget to help you.</li><li><strong>Habitually produce artifacts. </strong>With everything that you do, ask the question as to whether you should be creating a useful artifact for the future. Whether that’s recording a meeting so that people can watch it asynchronously later, or writing up that design document to develop your thoughts with others, or creating that <a href="https://adr.github.io/">Architecture Design Record</a>, <em>create them. </em>Artifacts are <em>so</em> useful so that you understand where you’ve come from, where you are currently going and where, eventually, you want to get to.</li><li><strong>Instill meeting and video call etiquette. </strong>Don’t be like the Cabinet Room. Have each participant have their own camera and microphone, and mute when not talking. If useful, write up your agenda and thoughts beforehand so that the meeting can run efficiently. Use a spotter to check whether there are people on the call that aren’t being heard and invite them into the conversation.</li><li><strong>Broadcast information to the widest possible group. </strong>Think about who is hearing, seeing and reading your communication. Could it be useful to a broader group of participants, even if it’s just optional information that they can read if they’re interested? If so, don’t repeat yourself in the future; broadcast it immediately at a wider level. A DM could become a message in the team’s chat room. A team chat room message could instead go out to the whole department. Remember that people can just not read something if they don’t want to. That’s fine.</li><li><strong>Continually take visible action. </strong>Most importantly, just keep doing all of the above continually. Soon your habits will catch on and others will follow.</li></ul>



<h2><strong>Homework</strong></h2>



<p>Now, on to the exercise. Pencils at the ready.</p>



<p>Spend some time thinking about your own workplace, department or team. How would you rate yourselves against the <em>intention</em> of treating everyone as remote when compared to the continual <em>actions and habits </em>that you are taking? Is there a void here? What needs to be done to change that? Also, assuming you’re reading this sometime around the time that it was written, how have these habits changed when you compare your workplace now to how it was before the Covid-19 pandemic?</p>



<p>Think about some changes that you can implement right away in order to …</p></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.theengineeringmanager.com/remote-working/treat-everyone-as-remote/">https://www.theengineeringmanager.com/remote-working/treat-everyone-as-remote/</a></em></p>]]>
            </description>
            <link>https://www.theengineeringmanager.com/remote-working/treat-everyone-as-remote/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25861403</guid>
            <pubDate>Thu, 21 Jan 2021 17:22:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OS Abstractions Are Failing Us]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25861136">thread link</a>) | @ggoo
<br/>
January 21, 2021 | https://dafoster.net/articles/2019/06/27/os-abstractions-are-failing-us/ | <a href="https://web.archive.org/web/*/https://dafoster.net/articles/2019/06/27/os-abstractions-are-failing-us/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <!-- Encourage IE 6 users to upgrade their browser. -->
        <!--[if lt IE 7]>
          <div style="clear: both; height: 59px; padding: 0 0 0 50px; position: relative;">
            <a href="http://windows.microsoft.com/en-US/internet-explorer/products/ie/home?ocid=ie6_countdown_bannercode">
              <img src="http://storage.ie6countdown.com/assets/100/images/banners/warning_bar_0000_us.jpg"
                border="0" height="42" width="820"
                alt="You are using an outdated browser. For a faster, safer browsing experience, upgrade for free today." />
            </a>
          </div>
        <![endif]-->
        
        
          <div>
  <div>
    
    
    
    <p>In recent years I’ve increasingly noticed software being written that cannot get the performance it needs unless it bypasses usual operating system services.</p>

<h2>Concurrency</h2>

<p>For example let’s consider a program that wants to do many tasks at the same time. Traditionally you would either create multiple <strong>threads</strong> or multiple <strong>processes</strong> for each parallel line of execution. But threads and processes have a lot of overhead - in particular they take up a lot of memory - so it’s unwise to have more than a few hundred of them. So if you have a web service handling hundreds or thousands of connections per second, you cannot effectively serve all those requests on one machine using a thread or process per connection.</p>

<p>So some developers turn to writing their web servers with asynchronous I/O and <strong>green threads</strong> so that they can multiplex multiple concurrent tasks onto a single OS thread. You can run millions of these green threads concurrently per machine on modern hardware. That’s pretty slick, at least until one of those green threads starts hogging the CPU or accidentally performs a blocking operation. Such a misbehaving green thread will block all other green threads from running, since they use cooperative multitasking and cannot be preempted.</p>

<p>Other developers turn to <strong>microthreads</strong> in languages like Go, Erlang, or Elixir<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>. These environments have an in-process scheduler that multiplexes microthreads onto a single OS thread. Again you can run millions of microthreads concurrently on modern hardware. Happily microthreads <em>can</em> be preempted by the scheduler and so a misbehaving microthread won’t interfere with other microthreads, although it may cause your server to burn CPU wastefully.</p>

<h2>Disk I/O throughput</h2>

<p>These days our disks are solid-state drives with access times similar to RAM rather than the slower rotating magnetic platters of earlier years. Yet my understanding is that the common filesystem and socket abstractions require per-operation overhead comparable to the time spent actually performing the I/O. Yikes. Research seems to be underway considering ways to bypass various OS abstractions to get faster results.<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup></p>

<h2>Exciting times</h2>

<p>It’s neat to be working in computing at the time when some of the fundamental abstractions are being called into question. When practitioners are receptive to change there’s an opportunity to contribute new ideas and actually have them tried and used.</p>



  </div>
  
  
  
  
</div>

        
      </div></div>]]>
            </description>
            <link>https://dafoster.net/articles/2019/06/27/os-abstractions-are-failing-us/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25861136</guid>
            <pubDate>Thu, 21 Jan 2021 17:02:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Wanna See a Whiter White?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25860894">thread link</a>) | @kalleboo
<br/>
January 21, 2021 | https://kidi.ng/wanna-see-a-whiter-white/ | <a href="https://web.archive.org/web/*/https://kidi.ng/wanna-see-a-whiter-white/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p id="tester">White.</p><div id="info">
    <p>
      Set the display brightness to less than 100%.<br>
      Turn off <a href="https://support.apple.com/en-us/HT205234">Low Power Mode on iOS.</a>
    </p>
    <p>
      The RGB color values of <i>the message</i> and <i>the background</i> are the same.<br>
      Take a screenshot then compare them in an image editor.
    </p>
    <p>
      Your experience may vary depending on browser, OS version, display, everything.<br>
      Tests so far seem to indicate this only works on <b>the Apple platforms.</b>
    </p>
    <details>
        <summary>Test Results</summary>
        <p>Works with <a href="https://support.apple.com/en-us/HT210980">HDR-capable Macs</a> and iPhones:</p>
        <ul>
          <li>Safari / Chrome / Edge, macOS Big Sur, MacBook Air (M1, 2020)</li>
          <li>Safari, macOS Big Sur, MacBook Pro (15-inch, 2018)</li>
          <li>Safari, macOS Big Sur, MacBook Pro (16-inch, 2019)</li>
          <li>Safari, macOS Big Sur, iMac (Retina 5K, 27-inch, 2020)</li>
          <li>iOS 14, iPhone X</li>
          <li>iOS 14, iPhone XS / XR</li>
          <li>iOS 14, iPhone 12 / iPhone 12 Pro</li>
          <li>iOS 14, iPad Pro 11-inch (2nd generation)</li>
        </ul>
        <p>Works with SDR Macs with Blink browsers:</p>
        <ul>
          <li>Chrome / Edge, macOS Big Sur, iMac (Retina 5K, 27-inch, Late 2015)</li>
        </ul>
        <p>Does not work with:</p>
        <ul>
          <li>Firefox (Does not support <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1539685">HDR</a>)</li>
          <li>webOS TV (Does not support <a href="http://webostv.developer.lge.com/discover/specifications/web-engine/">backdrop-filter</a>)</li>
          <li>Chrome, Google Pixel 4a</li>
          <li>Edge, Samsung Galaxy S10</li>
          <li>PlayStation 4</li>
          <li>Xbox Series X (Might crash the console)</li>
          <li>Chrome, Windows 10, LG 27UK600 / LG 34WL600</li>
        </ul>
      </details>
    
    <details>
        <summary>How does this work?</summary>
        <p>
          There are hidden HDR videos playing at the corners of this page. When a HDR-capable browser encounters one, it switches to HDR mode. For some reason, CSS backdrop-filter + brightness &gt;100% combo seems to behave like HDR—reaching beyond the user-controlled display brightness, up to the maximum HDR brightness—while the everything in between follow along. At least that's the overall idea, but I still don't know exactly why it works; especially why with those two CSS properties.
        </p>
        <p>
          Once the system switches to HDR mode, it seems to affect the whole display. That says, as long as you can trigger HDR mode by any means—simply playing an HDR video on Movist, for example—the CSS trick works on Safari / Chrome / Edge with HDR-capable / SDR devices. This indicates this bug/feature is mostly tied to <a href="https://developer.apple.com/documentation/metal/drawable_objects/displaying_hdr_content_in_a_metal_layer">the EDR system.</a>
        </p>
      </details>
    
    <p>
      Project on <a href="https://github.com/kiding/wanna-see-a-whiter-white">GitHub</a>. Short URL <code><a href="https://fff.kidi.ng/">fff.kidi.ng</a></code>.<br>
      Created by <a href="https://kidi.ng/">kiding</a>. Inspired by <a href="https://xenosium.com/">zvuc</a>. 
    </p>
  </div></div>]]>
            </description>
            <link>https://kidi.ng/wanna-see-a-whiter-white/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25860894</guid>
            <pubDate>Thu, 21 Jan 2021 16:46:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Curl or PSCouchDB?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25860875">thread link</a>) | @johnjackjames
<br/>
January 21, 2021 | https://pscouchdb.readthedocs.io/en/latest/ | <a href="https://web.archive.org/web/*/https://pscouchdb.readthedocs.io/en/latest/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Note</p>
<p>If you are using CouchDB version 2, use the PSCouchDB 1.X version; if instead you are using CouchDB version 3 or 4, use the PSCouchDB version 2.X</p>
</div></div>]]>
            </description>
            <link>https://pscouchdb.readthedocs.io/en/latest/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25860875</guid>
            <pubDate>Thu, 21 Jan 2021 16:45:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Migrated from Traefik to Caddy]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25860670">thread link</a>) | @blindm
<br/>
January 21, 2021 | https://p1ngouin.com/posts/why-i-migrated-from-traefik-to-caddy | <a href="https://web.archive.org/web/*/https://p1ngouin.com/posts/why-i-migrated-from-traefik-to-caddy">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>First, let's define what is <a href="https://traefik.io/" rel="nofollow noopener noreferrer" target="_blank">Traefik</a>. Traefik is a an
open-source reverse proxy and load balancer for HTTP and TCP-based applications.
It generates SSL certificates for you on the fly (based on a configuration
defined in a static file or dynamically using Docker networks and labels). The
main advantage of this solution is that it is turnkey. This application has been
specially designed to work with Docker in order to be able to detect the
presence of containers in the network, read labels and automatically redirect
traffic to the correct container (as a load balancer). After a few weeks of use
and many managed sites (+150), Traefik proved to be quite poor at managing HTTP
certificates. Indeed, thanks to the KV store solutions (such as Consul), Traefik
keeps the certificates in a single large JSON, gzipped under a single key. A big
disappointment for me.</p>
<blockquote>
<p>Consul allows you to store configurations/certificates between several
servers, sharing the same Swarm cluster.</p>
</blockquote>
<p>This problem, which may seem benign, is not. Indeed, with a very large number of
certificates, we very quickly encounter a problem related to Consul : <a href="https://www.consul.io/docs/faq.html#q-what-is-the-per-key-value-size-limitation-for-consul-39-s-key-value-store-" rel="nofollow noopener noreferrer" target="_blank">a limit
of 512KB is applied per
value</a>.
The only way to solve this problem was to compile a customized version of Consul
in order to significantly increase this limit (at the risk of losing
performance) by using the following patch :</p>
<div><pre><code><span>--- kvs_endpoint.go 2018-11-23 16:09:26.771017520 +0100</span>
<span>+++ kvs_endpoint.go.t   2018-11-23 16:10:10.462064157 +0100</span>
<span>@@ -16,7 +16,7 @@</span>
<span><span> </span><span>   // maxKVSize is used to limit the maximum payload length
</span><span> </span><span>   // of a KV entry. If it exceeds this amount, the client is
</span><span> </span><span>   // likely abusing the KV store.
</span></span><span><span>-</span><span>   maxKVSize = 512 * 1024
</span></span><span><span>+</span><span>   maxKVSize = 5120 * 1024
</span></span><span><span> </span><span>)
</span></span>
<span><span> </span><span>func (s *HTTPServer) KVSEndpoint(resp http.ResponseWriter, req *http.Request) (interface{}, error) {
</span></span></code></pre></div>
<p>This problem having been solved, several months have passed without any
problems. Certificates were correctly generated, stored and served. After this
serenity, Traefik suddenly started to stop renewing certificates for some sites
(using HTTP-01). I looked for where this bug could have come from, and I came
across these different issues:</p>
<ul>
<li><a href="https://github.com/containous/traefik/issues/3487" rel="nofollow noopener noreferrer" target="_blank">https://github.com/containous/traefik/issues/3487</a></li>
<li><a href="https://github.com/containous/traefik/issues/5426" rel="nofollow noopener noreferrer" target="_blank">https://github.com/containous/traefik/issues/5426</a></li>
</ul>
<p>Using the HA part heavily, I cannot do without the Swarm currently in place, and
the certificates must continue to be renewed. To date, I have not found any
solution to avoid the synchronization error of the KV store (Consul, Etcd...).
Containous formally explains that the notion of HA will only be officially
supported on the commercial version of Traefik. As a result, I find myself in a
dead end. I trusted a solution that no longer meets my needs, which took several
days to implement.</p>
<h2 id="looking-for-alternatives">Looking for alternatives</h2>
<p>After several hours of research and a little reddit, several solutions were
possible:</p>
<ul>
<li><a href="https://caddyserver.com/" rel="nofollow noopener noreferrer" target="_blank">Caddy</a> ;</li>
<li><a href="https://www.envoyproxy.io/" rel="nofollow noopener noreferrer" target="_blank">Envoy</a> ;</li>
<li><a href="https://istio.io/" rel="nofollow noopener noreferrer" target="_blank">Istio</a> ;</li>
<li>... and certainly others</li>
</ul>
<p>However, the solution also had to meet several criteria:</p>
<ul>
<li>Easily configurable ;</li>
<li>Discover the services in the Swarm ;</li>
<li>Automatic generation of SSL certificates ;</li>
<li>Implementation of mesh routing (optional) ;</li>
</ul>
<p>The last two solutions seemed very complex to configure. Caddy only partially
meets these criteria. Indeed, it was not developed with a use under Docker. He
didn't seem like a good candidate to me. Then, after seeing this solution come
up, I asked myself a few questions : why do you hear so much about Caddy ? Now I
know.</p>
<h2 id="caddy-to-the-rescue-">Caddy to the rescue !</h2>
<p>Caddy was designed to work (written in Go) with modules, so it is fully
extensible. First, <a href="https://github.com/pteich/caddy-tlsconsul" rel="nofollow noopener noreferrer" target="_blank">Caddy can work, since version 0.11, with Consul with a
plugin</a> to store the different HTTP
certificates generated. This is already a very good point in order to be able to
share certificates between several servers. Second, Caddy also has <a href="https://github.com/lucaslorentz/caddy-docker-proxy" rel="nofollow noopener noreferrer" target="_blank">a plugin to
listen to the Swarm</a> to
automatically generate a configuration file in memory based on existing
services/containers. And finally, Caddy's configuration is extremely simple and
it manages DNS/HTTP-01 resolvers in parallel (instead of Traefik).</p>
<p>In order to consolidate Caddy and its plugins, I decided to generate a custom
Docker image, actually containing only one file (excluding the CI part):</p>
<div><pre><code>main <span>package</span>

<span>import</span> <span>(</span>
    <span>"github.com/caddyserver/caddy/caddy/caddy/caddymain"</span>

    
    <span>_</span> <span>"github.com/lucaslorentz/caddy-docker-proxy/plugin"</span>
    <span>_</span> <span>"github.com/pteich/caddy-tlsconsul"</span>
<span>)</span>

<span>func</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
    caddymain<span>.</span><span>Run</span><span>(</span><span>)</span>
<span>}</span>
</code></pre></div>
<h2 id="time-for-migration">Time for migration</h2>
<p>To begin with, I migrated only one server under Caddy (the one containing the
most sites, obviously to test the resilience of the solution).</p>
<div><pre><code><span>version</span><span>:</span> <span>"3.4"</span>
<span>services</span><span>:</span>
    <span>custom-service</span><span>:</span>
        <span>image</span><span>:</span> containous/whoami
        <span>networks</span><span>:</span>
            <span>-</span> routable
        <span>deploy</span><span>:</span>
            <span>labels</span><span>:</span>
                <span>traefik.port</span><span>:</span> <span>80</span>
                <span>traefik.docker.network</span><span>:</span> routable
                <span>traefik.frontend.rule</span><span>:</span> <span>"Host:example.com"</span>
                <span>traefik.frontend.entryPoints</span><span>:</span> http<span>,</span>https

<span>networks</span><span>:</span>
    <span>routable</span><span>:</span>
        <span>external</span><span>:</span> <span>true</span>
</code></pre></div>
<p>Now, using Caddy's labels.</p>
<div><pre><code><span>version</span><span>:</span> <span>"3.4"</span>
<span>services</span><span>:</span>
    <span>custom-service</span><span>:</span>
        <span>image</span><span>:</span> containous/whoami
        <span>networks</span><span>:</span>
            <span>-</span> routable
        <span>deploy</span><span>:</span>
            <span>labels</span><span>:</span>
                <span>caddy.address</span><span>:</span> https<span>:</span>//example.com
                <span>caddy.targetport</span><span>:</span> <span>"80"</span>

<span>networks</span><span>:</span>
    <span>routable</span><span>:</span>
        <span>external</span><span>:</span> <span>true</span>
</code></pre></div>
<p>Nothing extraordinary here, except that Caddy works, renews all certificates
correctly and is fully customizable. In addition, the icing on the cake: the TLS
Consul plugin used with Caddy registers one SSL certificate per entry, awesome.</p>
<h2 id="the-routing-mesh-optional">The routing mesh (optional)</h2>
<p>The technique is the same between Traefik and Caddy here. The purpose of mesh
routing is to point any IP to any server in the Swarm and get the response from
the right container. Personally, I'm not a fan of the principle of assigning IPs
only to <code>manager</code> nodes. So here's the technique I use :</p>
<div><pre><code><span>version</span>  <span>:</span> <span>"3.4"</span>
<span>services</span> <span>:</span>
    <span>consul</span><span>:</span>
        <span>image</span>    <span>:</span> consul<span>:</span>latest
        <span>command</span>  <span>:</span> agent <span>-</span>server <span>-</span>bootstrap<span>-</span>expect=1
        <span>networks</span> <span>:</span>
            <span>-</span> consul
        <span>volumes</span>  <span>:</span>
            <span>-</span> <span>"consul-data:/consul/data"</span>
        <span>deploy</span>   <span>:</span>
            <span>mode</span><span>:</span> replicated
            <span>replicas</span><span>:</span> <span>1</span>
        <span>environment</span> <span>:</span>
            <span>-</span> CONSUL_LOCAL_CONFIG=<span>{</span>"datacenter"<span>:</span><span>"us_east2"</span><span>,</span>"server"<span>:</span><span>true</span><span>}</span>
            <span>-</span> CONSUL_BIND_INTERFACE=eth0
            <span>-</span> CONSUL_CLIENT_INTERFACE=eth0

    <span>docker-proxy</span><span>:</span>
        <span>image</span><span>:</span> rancher/socat<span>-</span>docker
        <span>networks</span><span>:</span>
            <span>-</span> caddy
        <span>volumes</span><span>:</span>
            <span>-</span> /var/run/docker.sock<span>:</span>/var/run/docker.sock
        <span>deploy</span><span>:</span>
            <span>mode</span><span>:</span> replicated
            <span>replicas</span><span>:</span> <span>1</span>

    <span>caddy</span><span>:</span>
        <span>image</span>    <span>:</span> &lt;custom<span>-</span>caddy<span>-</span>image<span>&gt;</span>
        <span>command</span>  <span>:</span> <span>-</span>email &lt;redacted<span>&gt;</span> <span>-</span>agree=true <span>-</span>log stdout <span>-</span>proxy<span>-</span>service<span>-</span>tasks=true <span>-</span>docker<span>-</span>validate<span>-</span>network=false
        <span>networks</span> <span>:</span>
            <span>-</span> routable
            <span>-</span> caddy
            <span>-</span> consul
        <span>ports</span>    <span>:</span>
            <span>-</span> <span>target</span>    <span>:</span> <span>80</span>
              <span>published</span> <span>:</span> <span>80</span>
              <span>mode</span>      <span>:</span> host
            <span>-</span> <span>target</span>    <span>:</span> <span>443</span>
              <span>published</span> <span>:</span> <span>443</span>
              <span>mode</span>      <span>:</span> host
        <span>deploy</span><span>:</span>
            <span>mode</span>          <span>:</span> global
            <span>update_config</span> <span>:</span>
                <span>parallelism</span> <span>:</span> <span>10</span>
                <span>delay</span>       <span>:</span> 10s
            <span>restart_policy</span> <span>:</span>
                <span>condition</span> <span>:</span> on<span>-</span>failure
        <span>environment</span> <span>:</span>
            <span>DOCKER_HOST</span><span>:</span> tcp<span>:</span>//docker<span>-</span>proxy<span>:</span><span>2375</span>
            <span>CONSUL_HTTP_ADDR</span><span>:</span> consul<span>:</span><span>8500</span>

<span>volumes</span> <span>:</span>
    <span>consul-data</span><span>:</span>

<span>networks</span><span>:</span>
    <span>routable</span><span>:</span>
        <span>external</span><span>:</span> <span>true</span>

    <span>consul</span><span>:</span>
        <span>driver</span><span>:</span> overlay

    <span>caddy</span><span>:</span>
        <span>driver</span><span>:</span> overlay
</code></pre></div>
<p>With this configuration, it is no longer a question of running Caddy only on the
<code>manager</code> nodes, but on all the nodes available in the Swarm. Since certificates
are generated by only one instance of the application, we have no problem
running multiple caddy instances. IPs can now be pointed to any server in the
Swarm, and Caddy will forward the request to the right container (even if it is
not on the same server).</p>
<p>Now I have a Traefik version of Caddy and it fits all my needs.</p></div></div>]]>
            </description>
            <link>https://p1ngouin.com/posts/why-i-migrated-from-traefik-to-caddy</link>
            <guid isPermaLink="false">hacker-news-small-sites-25860670</guid>
            <pubDate>Thu, 21 Jan 2021 16:30:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A five month quest to ship a single line of code]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25860288">thread link</a>) | @TCR19
<br/>
January 21, 2021 | https://blog.streamlit.io/streamlit-components-security-and-a-five-month-quest-to-ship-a-single-line-of-code/ | <a href="https://web.archive.org/web/*/https://blog.streamlit.io/streamlit-components-security-and-a-five-month-quest-to-ship-a-single-line-of-code/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://blog.streamlit.io/content/images/size/w300/2021/01/Screen-Shot-2021-01-20-at-10.32.23-AM.png 300w,
                            https://blog.streamlit.io/content/images/size/w600/2021/01/Screen-Shot-2021-01-20-at-10.32.23-AM.png 600w,
                            https://blog.streamlit.io/content/images/size/w1000/2021/01/Screen-Shot-2021-01-20-at-10.32.23-AM.png 1000w,
                            https://blog.streamlit.io/content/images/size/w2000/2021/01/Screen-Shot-2021-01-20-at-10.32.23-AM.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://blog.streamlit.io/content/images/size/w2000/2021/01/Screen-Shot-2021-01-20-at-10.32.23-AM.png" alt="Streamlit Components, security, and a five month quest to ship a single line of code">
            </figure>

            <section>
                <div>
                    <p>In the <a href="https://docs.streamlit.io/en/stable/changelog.html#version-0-73-0" rel="noopener noreferrer">changelog for Streamlit 0.73.0</a>, released in December 2020, there’s a small callout: “Component iframes now include the allow-same-origin sandbox attribute.”</p><p>This change enables dramatically more powerful <a href="https://docs.streamlit.io/en/latest/streamlit_components.html">Streamlit Components</a> - you can now use webcams and microphones in Streamlit apps and more easily embed and interact with external resources - and it was just a single line of code! (Check out our ever-expanding <a href="https://www.streamlit.io/components">Component Gallery</a> for examples of quality Components created by the Streamlit community.)</p><figure><img src="https://blog.streamlit.io/content/images/2021/01/webrtc-1.gif" alt=""><figcaption>The <a href="https://github.com/whitphx/streamlit-webrtc/blob/master/app.py">popular WebRTC component</a> currently being built by whitphx wouldn't have been possible prior to the updates to allow-same-origin.</figcaption></figure><p>But this is not a post about how to use or build Streamlit Components. If you're interested in that, we have a <a href="https://docs.streamlit.io/en/latest/streamlit_components.html">tutorial here</a> or check out the great <a href="https://streamlit-components-tutorial.netlify.app/">community tutorial</a> by Fanilo Andrianasolo! Instead, we want to peel back the curtain and discuss how we make changes to Streamlit itself. Because we <em>could</em> have shipped that single line in July <a href="https://medium.com/streamlit/introducing-streamlit-components-d73f2092ae30">when we launched Streamlit Components</a>. We could've shipped it in any of the 9 releases that followed! But instead, it took us 5 months.</p><p>This is an engineering-focused post about why such a small change took such a long time. It'll touch on the Streamlit security model, our design philosophy, and the competing constraints that can lead to long development times for seemingly-simple features. And for the masochists out there, we'll stare briefly into the abyss that is <em>cross-origin web security</em>.</p><p>Let's start with a humble-brag: Streamlit has <em>lots</em> of users, many of whom are storing and accessing sensitive data in Streamlit apps. We take security very seriously. What this means in practice is that any change or feature we add to Streamlit <em>must not</em> reduce the security of either the <a href="https://github.com/streamlit/streamlit">Streamlit open source library</a> or <a href="https://www.streamlit.io/sharing">Streamlit sharing</a>, our "press button → deploy to cloud" hosting platform.</p><p>Additionally, we care dearly about the <em>design</em> of Streamlit - not just the way it looks, but the way it works, all the way down to API names. This means that, as much as possible:</p><ul><li>Streamlit should <em>just work.</em></li><li>Streamlit features should be robust and powerful.</li><li>New features should <em>not</em> increase the complexity of installing, using, or deploying Streamlit.</li></ul><p>So we have these three broad goals: add new features to Streamlit, don't undermine its simplicity, and ensure it's safe. When we're fortunate, these goals are not at odds with each other. When we're less fortunate, we have the <code>allow-same-origin</code> situation and we end up writing blog posts like this one.</p><p>Before getting into the weeds, let's first consider the story around Streamlit Components and security:</p><ul><li>Fundamentally, a Streamlit Component is a <em>Python library</em>. You should exercise the same judgement with a Component as you would with any other Python library you <code>pip install</code> in your project.</li><li>A Component <em>also</em> runs code on the frontend, which means it can make requests from the browser, and can access data on your app's frontend.</li><li>You should assume that any library you use - Component or otherwise - can access any data in your app.</li><li>If your app deals with sensitive data, only install libraries and Components that you have written, or that you otherwise trust.</li></ul><p>No big surprises. But there's a wrinkle: as Streamlit Components was under development, so too was Streamlit sharing. We needed to make sure that a rogue Component in a shared app couldn’t peek at Streamlit sharing data, or execute commands on behalf of the developer.</p><p>tl;dr for the rest of the blog post: <em>nothing</em> in a Streamlit app - malicious Component or otherwise - can hijack Streamlit sharing. But we treaded carefully - and a bit slowly - to make sure this was the case.</p><p><em>(This section gets into the details of <code>&lt;iframe&gt;</code> sandboxing, the <code>allow-same-origin</code> sandbox flag, and cross-origin requests. It'll be of primary interest to those who work with, or are curious about, web security. If you have no interest in the nitty-gritty, skip ahead to the next section!)</em></p><p>Broadly speaking, Streamlit Components are <a href="https://www.streamlit.io/components">user-created plugins that extend Streamlit.</a> You <code>pip install</code> a Component into your Python environment, and now you <a href="https://github.com/okld/streamlit-discourse">can add a forum</a>, or an <a href="https://github.com/napoles-uach/streamlit_3dmol">interactive 3D molecule viewer</a>, or a <a href="https://github.com/facebookresearch/hiplot">Facebook HiPlot data graph</a>, or <a href="https://github.com/andfanilo/streamlit-echarts">custom charting libraries</a> - or really any feature that Streamlit doesn't include out of the box - to your Streamlit app.</p><figure><img src="https://blog.streamlit.io/content/images/2021/01/group_selection_example.gif" alt=""><figcaption><a href="https://github.com/PablocFonseca/streamlit-aggrid">Streamlit Ag-Grid</a> component by PablocFonseca</figcaption></figure><p>During development, we had two primary concerns around the Component security model:</p><ul><li>A Component shouldn't be able to break assumptions about its surrounding page (changing the host app's CSS or DOM, for example).</li><li>A Component in an app deployed with <a href="https://www.streamlit.io/sharing">Streamlit sharing</a> shouldn’t be able to hijack its owner's sharing credentials and read secret data or execute a <a href="https://en.wikipedia.org/wiki/Cross-site_request_forgery">CSRF</a> exploit.</li></ul><p>Under the hood, each instance of a Streamlit Component is mounted inside its own <code>&lt;iframe&gt;</code> in its containing Streamlit app, which means it lives in its own little world with its own DOM, its own CSS, and its own restrictions. Each iframe has a sandbox with a number of different attributes that specify what it can and can't do. For our purposes here, we're interested in two sandbox flags: <code>allow-same-origin</code> and <code>allow-scripts</code>.</p><p><code>allow-scripts</code> is self-explanatory: if it’s missing, then the iframe will not be able to execute any JavaScript. Executing JavaScript is a fundamental part of Streamlit Components, so this attribute must be enabled. <code>allow-same-origin</code> is related to <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS">“cross-origin-resource-sharing”, or CORS</a> - which means that it’s destined to be confusing and annoying. If you <em>omit</em> this attribute, the iframe won't be able to use certain browser features (like webcams and microphones), and it will be unable to make requests to many other web servers (which often expect a non-null origin).</p><p>When Streamlit Components launched, we left off <code>allow-same-origin</code> because of how it interacts with <code>allow-scripts</code>. The <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/iframe">MDN iframe page</a> explains it thusly:</p><blockquote>When the embedded document has the same origin as the embedding page, it is strongly discouraged to use both allow-scripts and allow-same-origin, as that lets the embedded document remove the sandbox attribute — making it no more secure than not using the sandbox attribute at all.</blockquote><p>Streamlit Components <em>are</em> served from the same origin as their embedding page, which means that combining <code>allow-scripts</code> and <code>allow-same-origin</code> would render our sandbox moot. This isn't <em>necessarily</em> a big deal, because Components are not "untrusted code" - but would potentially undercut our Component security concerns.</p><p>There's a big document memorializing weeks of discussion and argument on our <code>allow-same-origin</code> woes: should we serve components from a separate origin? Should we allow devs to opt into the <code>allow-same-origin</code> flag via a config option? Should we maintain an allow-list within Streamlit of Components that can use this flag?</p><p>We developed a number of prototypes that solved the issue in different ways. But all of them undercut Streamlit's "keep things simple" design principle:</p><ul><li>Some prototypes made Streamlit <em>use</em> more difficult (by requiring that dev deeply understand the Component sandbox model).</li><li>Some made Streamlit <em>deployment</em> more difficult (by exposing more server ports to be forwarded and routed through proxies).</li><li>And some made Component <em>development</em> more difficult (by imposing restrictions on Component creators).</li></ul><p>After several months of proposals, prototypes, and arguments, we shipped Streamlit 0.73, which solved the problem by simply adding the <code>allow-same-origin</code> iframe flag. In other words, we decided to allow Components to break the iframe sandbox.</p><p>Why are we ok with this? And what are the ramifications? Here's where we landed on our original sandboxing concerns:</p><h3 id="first-don-t-hijack-my-css">First, "don't hijack my CSS"</h3><blockquote>"A Component shouldn't be able to break assumptions about its surrounding page (changing the host app's CSS or DOM, for example)."</blockquote><p>Our decision here is simple: we decided that, while we won't <em>encourage</em> this sort of thing (not least because it's unsupported and therefore subject to break when Streamlit is updated), we're fundamentally ok with it. Official theming support is on the Streamlit roadmap for 2021, but if enterprising developers want to hack on Streamlit and create this sort of thing before we officially ship it, we won't stand in their way.</p><p>Streamlit is an <a href="https://github.com/streamlit/streamlit">open source project</a> anyway; if you don't like the way something works or looks, you can just fork the project and change it. We don't need a Component sandbox to enforce a rule that's incompatible with our open source nature.</p><h3 id="and-more-importantly-don-t-hijack-streaming-sharing">And more importantly, "don't hijack Streaming Sharing"</h3><blockquote>"A Component in an app deployed with Streamlit sharing shouldn’t be able to hijack its owner's Sharing credentials and execute a CSRF exploit."</blockquote><p>We need to ensure that a malicious Component - or any other rogue code that could be running within a Streamlit app - cannot execute Streamlit sharing commands surreptitiously.</p><p>Googling for <a href="https://www.google.com/search?q=csrf+example">"CSRF example"</a> will return all sorts of resources that explain this type of exploit in detail. The important thing to know is that CSRF attacks use the fact that each HTTP request made by a browser will include the cookies associated with site to which the request is made. (There are various <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Cookies">cookie attributes</a> that make this story slightly more complex, but that's the basic rule.)</p><p>When you're logged into Streamlit sharing and visit a deployed app you own, you get a management dashboard that lets you view logs and perform various administrative tasks:</p><figure><img src="https://blog.streamlit.io/content/images/2021/01/sharing.jpeg" alt="" srcset="https://blog.streamlit.io/content/images/size/w600/2021/01/sharing.jpeg 600w, https://blog.streamlit.io/content/images/size/w1000/2021/01/sharing.jpeg 1000w, https://blog.streamlit.io/content/images/2021/01/sharing.jpeg 1100w" sizes="(min-width: 720px) 720px"></figure><p>If the Streamlit sharing administrator wrapper is served from the same HTTP origin as the app it's managing, a malicious Component could bypass Sharing's CSRF protections by making requests against the Streamlit sharing API and reading the CSRF token from the response headers.</p><p>The solution to this doesn't involve relying on Component sandboxing. In Streamlit sharing, an app's admin dashboard is <em>simply served from a different origin than the app …</em></p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.streamlit.io/streamlit-components-security-and-a-five-month-quest-to-ship-a-single-line-of-code/">https://blog.streamlit.io/streamlit-components-security-and-a-five-month-quest-to-ship-a-single-line-of-code/</a></em></p>]]>
            </description>
            <link>https://blog.streamlit.io/streamlit-components-security-and-a-five-month-quest-to-ship-a-single-line-of-code/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25860288</guid>
            <pubDate>Thu, 21 Jan 2021 16:03:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Joe Biden's team hopes to turn five vaccine doses into six]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25860162">thread link</a>) | @drtournier
<br/>
January 21, 2021 | https://www.slowboring.com/p/dead-space | <a href="https://web.archive.org/web/*/https://www.slowboring.com/p/dead-space">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The Biden administration is “working on multiple fronts” to combat the Covid-19 pandemic according to Vivek Murthy, the administration’s designated choice for Surgeon General, including improved testing, investments in genomic surveillance, and of course a multi-pronged effort to improve the pace of vaccination. </p><p>In a call with journalists this afternoon, Murthy and Jeffrey Zients, the soon-to-be Covid Czar, talked about a wide range of plans but mentioned one specific idea that seems very promising to me and hasn’t been discussed very much in public. </p><p>The basic issue is that, as I <a href="https://marginalrevolution.com/marginalrevolution/2021/01/the-magical-extra-doses-and-supply-chain-optimization.html">first learned from Alex Tabarrok on Thursday</a>, a standard five dose vial of vaccine in some cases actually holds six or even seven doses. The difference turns out to be whether or not you are using a “low dead-space syringe.” With such a syringe, there is less waste and you can stretch your supply by 20 percent or more. </p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F70e34113-53a6-4e16-a01b-9a519c4f71ac_220x273.webp"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F70e34113-53a6-4e16-a01b-9a519c4f71ac_220x273.webp" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/70e34113-53a6-4e16-a01b-9a519c4f71ac_220x273.webp&quot;,&quot;height&quot;:273,&quot;width&quot;:220,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:17716,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/webp&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><blockquote><p>This is quite remarkable. Increasing vaccine supply by 20% by building more factories could cost billions. We should do that, it would be worth it. But in this case, we managed to increase supply by at least 20% use a relatively inexpensive redesign of the syringe. What this indicates is the importance of thinking along the entire supply chain for opportunities for optimization.</p><p>The catch? Not all syringes provided by Operation Warp Speed and Pfizer are low dead-volume syringes so not every vaccine distribution site is getting the extra doses. We do need to invest more in the syringe supply chain.</p></blockquote><p>On the call, Zients cited the need to invest in these more efficient syringes and posited that it’s an area where Biden will invoke the Defense Production Act to ensure that America’s production capacity of syringes is deployed to this purpose. It’s a small thing, obviously, and I don’t want to make it sound like it’s the whole Biden strategy for fighting the virus. </p><p>Rather, it’s an example of the potentially large gains that can be achieved by looking carefully at the whole playing fields and sweating the details. </p><p>Sweating the details is not really the Trump way, but it’s an example of how bringing on a team of competent, experienced, professionals can make a big difference in what is on some level a big logistics problems. </p><p data-attrs="{&quot;url&quot;:&quot;https://www.slowboring.com/p/dead-space?&amp;utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;class&quot;:null}"><a href="https://www.slowboring.com/p/dead-space?&amp;utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share"><span>Share</span></a></p><p>“The current administration has never had a federal or comprehensive strategy,” Zients said, noting that on a lot of these types of questions they simply haven’t received the kind of transition briefings that would let them get full visibility into example what the current situation is. But he says “this is a national emergency and we need to treat it like one. We’re going to throw the full weight and resources of the federal government behind ending the pandemic.”</p></div></div>]]>
            </description>
            <link>https://www.slowboring.com/p/dead-space</link>
            <guid isPermaLink="false">hacker-news-small-sites-25860162</guid>
            <pubDate>Thu, 21 Jan 2021 15:54:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hiding messages in images: steganography with Python and Repl.it]]>
            </title>
            <description>
<![CDATA[
Score 63 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25859891">thread link</a>) | @sixhobbits
<br/>
January 21, 2021 | https://docs.repl.it/tutorials/13-steganography | <a href="https://web.archive.org/web/*/https://docs.repl.it/tutorials/13-steganography">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    

    <div>
      
<p>In this tutorial, we'll build a steganography tool in Python. Steganography is the practice of hiding information within other data. Unlike encryption, where the goal is to secure <em>the contents</em> of communication between two parties, steganography aims to obscure the fact that the parties are communicating at all.</p>
<p>Our tool will enable the user to hide secret text within a normal-looking <code>.png</code> image file. The receiver of the image will use the same tool to reveal the hidden message.</p>
<p>We'll use Python to build the tool. The most popular Python image processing libraries are <a href="https://pypi.org/project/Pillow/">Pillow</a> and <a href="https://pypi.org/project/opencv-python/">OpenCV</a>, but these are heavy libraries with many dependencies. We'll avoid these and instead use the lightweight <a href="https://pypi.org/project/pypng/">PyPNG</a> library which is written in pure Python, and therefore easier to run on various platforms.</p>
<h2 id="a-quick-background-on-steganography">A quick background on steganography</h2>
<p>Let's imagine three people: Alice, Bob and Eve. Alice wants to send a private message to Bob, while Eve wants to intercept this message. While modern-day encryption can help Alice and Bob ensure that Eve doesn't know the <em>contents</em> of their message, Eve can possibly still deduce interesting information just from knowing that Alice and Bob are communicating at all, and how frequently they communicate.</p>
<p>To obscure the communication channel completely, Alice and Bob can exploit the fact that hundreds of millions of photos are uploaded and shared across the internet daily. Instead of communicating directly, Alice can leave her message hidden in an image at a pre-agreed location and Bob can access this message. From Eve's perspective, there is now no direct communication between the two.</p>
<p>A single image is made up of millions of pixels. While many formats exist, a pixel is most simply represented by a group of three numbers between 0 and 255, one number each for the red, blue, and green values of that pixel. Using this Red-Green-Blue scheme we can represent any colour in the <a href="https://en.wikipedia.org/wiki/RGB_color_model">RGB color model</a>.</p>
<p>Digital text, like images, is also represented internally by numbers, so the differences between a text file and an image file are not as large as you might assume. Any digital data can be represented as a <a href="https://thehelloworldprogram.com/computer-science/what-is-binary/">binary string</a>, a bunch of 1s and 0s, and we can make tiny modifications to an image to encode a binary string within it. As an example, consider the following:</p>
<pre><code>image = [, , ]</code></pre>
<p>This is a representation of an image with three pixels: one red, one green, and one blue. If we encode this as an image and open it in an image viewer, we'll see the three pixel image, but if we read this data with Python, it is simply a list of tuples, each containing three integers.</p>
<p>We could also look at each value making up each pixel and calculate whether it is <em>odd</em> or <em>even</em>. We could encode odd numbers as <code>1</code> and even values as <code>0</code>. This would give us the binary string "100 010 001" (as the 255 values are odd and the 0s are even).</p>
<p>If we made a small modification to the image as follows:</p>
<pre><code>image = [, , ]</code></pre>
<p>The image would look almost identical in any image viewer (we have just added or subtracted a minuscule amount of color from some values), but the binary string -- using our odd/even method -- would look completely different: "011 111 100". </p>
<p>Using this technique but extending it over an entire image (millions of pixels), we can hide a large amount of text data in any image.</p>
<h2 id="creating-the-project-on-replit">Creating the project on Repl.it</h2>
<p>If you were serious about keeping your messages as secret as possible, you'd want to do all of these steps on an offline computer that you fully control. As a learning exercise though, we'll set the project up on <a href="https://repl.it/">repl.it</a>. Navigate to their site and sign up for an account if you don't have one.</p>
<p>Create a new project, choosing "Python" as the language, and give your project a name.</p>
<p><img src="https://docs.repl.it/images/tutorials/13-steganography/04-create-repl.png" alt="Creating a new repl"></p>
<p>The first piece we need to build is a function to encode any text message as a binary string.</p>
<h2 id="encoding-a-text-message-as-a-binary-string">Encoding a text message as a binary string</h2>
<p>Open the <code>main.py</code> file and add the following code</p>
<pre><code>import base64

def encode_message_as_bytestring(<span>message</span>):
    b64 = <span>message</span>.encode(<span>"utf8"</span>)
    bytes_ = base64.encodebytes(b64)
    bytestring = <span>""</span>.jo<span>in(</span>[<span>"{:08b}"</span>.<span>format</span>(<span>x</span>) for <span>x</span> <span>in</span> bytes_])
    <span>return</span> bytestring</code></pre>
<p>This first encodes our text as <a href="https://en.wikipedia.org/wiki/Base64">base64</a> and then as a binary string. You can add some print statements to see how the message is transformed in the different steps, as shown below.</p>
<p><img src="https://docs.repl.it/images/tutorials/13-steganography/13-01-encode-binstring.png" alt="Encoding a message as a binary string"></p>
<p>The base64 step is not strictly necessary, but it is useful as any file or data can be encoded as base64. This opens our project up to future extensions such as hiding other kinds of files within image files instead of just text strings.</p>
<h2 id="adding-an-end-of-message-delimeter">Adding an 'end of message' delimeter</h2>
<p>We'll assume that our message will always 'fit' in our image. We can fit three binary digits per pixel (one for each of the RGB values), so our resulting binary string should be shorter than the the number of pixels in the image multiplied by three.</p>
<p>We'll also need to know when the message <em>ends</em>. The message will only be encoded in the beginning of the image file, but if we don't know how long the message is, we'll keep looking at normal pixels and trying to encode them as text data. Let's add an "end of string" delimiter to the end of our message: this should be something that wouldn't appear half way through our actual message by chance. We'll use the binary representation of '!ENDOFMESSAGE!' for this.</p>
<p>Modify your function to look as follows, which adds this delimeter at the end.</p>
<pre><code>import <span>base64
</span>
ENDOFMESSAGE = <span>"0100100101010101010101100100111101010010010001010011100101000111010101000101010101010110010101000101010100110000010001100100100001010010010100110100010100111101"</span>

def encode_message_as_bytestring(message):
    <span>b64 </span>= message.encode(<span>"utf8"</span>)
    <span>bytes_ </span>= <span>base64.encodebytes(b64)
</span>    <span>bytestring </span>= <span>""</span>.<span>join(["{:08b}".format(x) </span>for x in <span>bytes_])
</span>    <span>bytestring </span>+= ENDOFMESSAGE
    return <span>bytestring</span></code></pre>
<p>Now that we can handle some basic text encoding, let's look at images.</p>
<h2 id="getting-pixels-from-an-image">Getting pixels from an image</h2>
<p>Find a PNG image somewhere - either one you've taken yourself or from a site like unsplash. You can use any online JPG to PNG converter if you only have <code>.jpg</code> files available.</p>
<p>Upload your PNG file by clicking on the three dot menu in the repl sidebar, in the top right corner of the files pane to the left, and selecting <code>upload file</code> or by simply dragging and dropping your file within the files pane.</p>
<p><img src="https://docs.repl.it/images/tutorials/13-steganography/05-upload-file.png" alt="Image showing file upload"></p>
<p>We're going to write a function that extracts the raw pixel data from this image file. Add an import to the top of the file.</p>
<pre><code><span>import</span> png</code></pre>
<p>And then add a new function to the bottom of <code>main.py</code>:</p>
<pre><code><span><span>def</span> <span>get_pixels_from_image</span><span>(fname)</span></span>:
    img = png.Reader(fname).read()
    pixels = img[<span>2</span>]
    <span>return</span> pixels</code></pre>
<p>The <code>read()</code> method returns a 4‑tuple consisting of:</p>
<ul>
<li>width: Width of PNG image in pixels</li>
<li>height: Height of PNG image in pixels</li>
<li>rows: A sequence or iterator for the row data</li>
<li>info: An info dictionary containing some meta data</li>
</ul>
<p>We are primarily interested in the third item, "rows", which is an iterator containing all the pixels of the image, row by row. If you're not familiar with Python generators take a look at <a href="https://realpython.com/introduction-to-python-generators/">this guide</a>, but they are essentially memory-efficient lists.</p>
<h2 id="encoding-the-image-with-the-message">Encoding the image with the message</h2>
<p>Now that we have the encoded message and pixels of the image ready we can combine them to form our secret encoded image.</p>
<p>Add the following function to the bottom of the <code>main.py</code> file. This function takes in the outputs from the previous functions (our raw pixels and our message encoded as a binary string), and combines them.</p>
<pre><code><span><span>def</span> <span>encode_pixels_with_message</span>(<span>pixels, bytestring</span>):</span>
    <span>'''modifies pixels to encode the contents from bytestring'''</span>

    enc_pixels = []
    string_i = <span>0</span>
    <span>for</span> row <span>in</span> pixels:
        enc_row = []
        <span>for</span> i, char <span>in</span> <span>enumerate</span>(row):
            <span>if</span> string_i &gt;= <span>len</span>(bytestring):
                pixel = row[i]
            <span>else</span>:
                <span>if</span> row[i] % <span>2</span> != <span>int</span>(bytestring[string_i]):
                    <span>if</span> row[i] == <span>0</span>:
                        pixel = <span>1</span>
                    <span>else</span>:
                        pixel = row[i] - <span>1</span>
                <span>else</span>:
                    pixel = row[i]
            enc_row.append(pixel)
            string_i += <span>1</span>

        enc_pixels.append(enc_row)
    <span>return</span> enc_pixels</code></pre>
<p>This is the most complicated part of our project, but most of the code is there to handle edge cases. The important insight is that we want to control whether each pixel has an odd value (representing a 1 in our binary string) or an even one (to represent a 0). By chance, half of the pixel values will already have the correct value.</p>
<p>We simply loop through the binary string and the pixel and 'bump' each value that isn't correct by one. That is, we subtract 1 from the value if we need to change it from odd to even or vice versa. We don't want any negative numbers, so if we need to change any of the <code>0</code> values, we add 1 instead.</p>
<h3 id="writing-our-modified-pixels-back-to-an-image">Writing our modified pixels back to an image</h3>
<p>We now have all the image data, including the encoded message but it is still just a list of pixels. Let's add a function that will compile our pixels back into a PNG image.</p>
<p>Add the following function to the bottom of the <code>main.py</code> file.</p>
<pre><code>def write<span>_pixels_to_image(<span>pixels</span>, <span>fname</span>)</span>:
    png.from<span>_array(<span>pixels</span>, 'RGB')</span>.save(fname)</code></pre>
<p>The above function takes the array <code>pixels</code> and uses the <code>png</code> module to write these to a brand new <code>.png</code> file.</p>
<p>Play around with these functions to make sure you understand how they work. Before we write some wrapper code to actually use these, we're going to do everything backwards so that we can also extract hidden messages from previously encoded PNG files.</p>
<h2 id="decoding-messages-from-image-files">Decoding messages from image files</h2>
<p>First we need a function that can turn a binary string back into readable text. As before, we'll go via base64 for better compatability. Add the following function to the bottom of the <code>main.py</code> file.</p>
<pre><code>def decode<span>_message_from_bytestring(<span>bytestring</span>)</span>:
    bytestring = bytestring.split(ENDOFMESSAGE)<span>[<span>0</span>]</span>
    message = <span>int</span>(bytestring, <span>2</span>).<span>to</span><span>_bytes(<span>len</span>(<span>bytestring</span>)</span> 
    message = base64.decodebytes(message).decode(<span>"utf8"</span>)
    return message</code></pre>
<p>Remember how we added a special <code>E…</code></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://docs.repl.it/tutorials/13-steganography">https://docs.repl.it/tutorials/13-steganography</a></em></p>]]>
            </description>
            <link>https://docs.repl.it/tutorials/13-steganography</link>
            <guid isPermaLink="false">hacker-news-small-sites-25859891</guid>
            <pubDate>Thu, 21 Jan 2021 15:32:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Build an Escrow Product]]>
            </title>
            <description>
<![CDATA[
Score 122 | Comments 29 (<a href="https://news.ycombinator.com/item?id=25859638">thread link</a>) | @qin
<br/>
January 21, 2021 | https://www.moderntreasury.com/journal/how-to-build-an-escrow-product | <a href="https://web.archive.org/web/*/https://www.moderntreasury.com/journal/how-to-build-an-escrow-product">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h4>Introduction</h4><p>Escrow is a payment setup where the payer sends funds to a third party rather than directly to the payee. If certain conditions are met, the third party routes the funds to the recipient; if not, the funds get returned to the sender. Escrow is particularly useful for high value payments because the payer is guaranteed their money back if the payee doesn’t meet the conditions.</p><p>Many Americans encounter escrow when they buy or sell a home. In the US, the final step in buying a home is referred to as the “closing process.” While it can vary from state to state, the basic premise is that the buyer delivers the funds to a third party, the seller signs over the deed (or title) to the property, and that third party then transfers the funds to the seller once all the documents are complete. The third party is often referred to as a “title and escrow agent.”</p><p>This post takes the sale of a residential home and walks through how to build the flow of funds associated with the escrow process. We hope this guide is useful in demystifying how an escrow company might automate its payment operations using Modern Treasury.</p><h4>The User Experience</h4><p>Let’s say you’re building a title and escrow company in the US that helps clients sell their homes online. The user experience steps might look something like this:<br></p><ol role="list"><li>Billie Buyer commits to buying a house. Billie will make a 20% down payment in cash and will take out a mortgage for the remaining 80%. </li><li>You assign an escrow bank account to the transaction, collect the two incoming wire transfers from Billie Buyer and the lender, and inform the seller when the funds are in your possession.</li><li>At that point, Sandy Seller signs over the property.</li><li>Once you’ve determined all the documentation is completed correctly, you disburse the full purchase amount to Sandy Seller via wire transfer. </li></ol><p>The flow of funds is straightforward: two incoming wire transfers, and one outgoing wire transfer. This can get significantly more complicated if there are multiple sources of funds, or if there are other parties to be paid, such as tax authorities or other settlement agents. But for the sake of clarity, we’ll start with this simple scenario.</p><h4>Payment Ops Architecture<br></h4><p>To start, you should decide on the account structure itself. Escrow accounts have specific legal designations at banks and not all banks offer them. In addition, you should decide whether to use a single bank account for multiple transactions or to use virtual accounts.<br></p><p><a href="https://docs.moderntreasury.com/docs/virtual-accounts" target="_blank">Virtual accounts</a> are accounts with unique account numbers within a physical bank account. They are much faster to provision than real bank accounts and guarantee one-to-one reconciliation. For our architecture, using virtual accounts as escrow accounts is ideal because we can create one account per house sale. This helps us segregate funds in our reconciliation, as opposed to mixing the funds of multiple house sales in a single account. Also, single transactions per virtual account create a more manageable audit trail.<br></p><figure id="w-node-18dd9f1739d7-b8df1e0f"><p><img src="https://assets.website-files.com/5d7e7bbbcad517dd46cb55d3/6009051bee1c4e7860a4289f_Escrow%20Journal%20Post%20Diagram.jpg" loading="lazy" alt=""></p></figure><p>‍<br></p><h4>API Calls and Timings</h4><p>With our payment ops architecture in hand, we’re ready to build. <br></p><h5>Step 1: Assign a Virtual Account to a sale and share numbers with Buyer and Lender</h5><p>As soon as you learn of an impending house sale, you create a virtual account and share its details with Billie Buyer. You might also generate an invoice for Billie Buyer to share with their mortgage lender, along with specific instructions as to the amount and breakdown to be included in the wires.<br></p><p>To do so, you’d make an Modern Treasury API request like the following:<br></p><h6>curl --request POST \<br> &nbsp;-u ORGANIZATION_ID:API_KEY \<br> &nbsp;--url https://app.moderntreasury.com/api/virtual_accounts \<br> &nbsp;-H 'Content-Type: application/json' \<br> &nbsp;-d '{<br> &nbsp; &nbsp;"name": "Sale of 123 Main Street",<br> &nbsp; &nbsp;"internal_account_id": "c743edb7-4059-496a-94b8-06fc081156fd",<br> &nbsp; &nbsp;"account_details": [<br> &nbsp; &nbsp; &nbsp;{<br> &nbsp; &nbsp; &nbsp; &nbsp;"account_number": "2000001",<br> &nbsp; &nbsp; &nbsp; &nbsp;"account_number_type": "other"<br> &nbsp; &nbsp; &nbsp;}<br> &nbsp; &nbsp;]<br> &nbsp;}'</h6><p><em>‍</em>The response includes the unique routing details for the newly created account. &nbsp;You might also want to add additional information about the sale in the account’s metadata, for example: details about the buyer, seller, property in question, expected close date, any unique arrangements, and other information.</p><h5>Step 2: Create Expected Payments to monitor the wires you expect to receive<br></h5><p>Though not required, it’s useful to create Expected Payments for the two incoming wires you expect to receive. This way, Modern Treasury will notify your system via webhook whether a given payment succeeds within your specified time range, or if it is overdue:<br></p><h6>curl --request POST \<br> &nbsp;-u ORGANIZATION_ID:API_KEY \<br> &nbsp;--url https://app.moderntreasury.com/api/expected_payments \<br> &nbsp;-H 'Content-Type: application/json' \<br> &nbsp;-d '{<br> &nbsp; &nbsp;"description": "Sale of 123 Main Street (Billie’s Portion)",<br> &nbsp; &nbsp;"internal_account_id": "c743edb7-4059-496a-94b8-06fc081156fd",<br> &nbsp; &nbsp;"virtual_account_id": "virtual-account-id",<br> &nbsp; &nbsp;"direction": "credit",<br> &nbsp; &nbsp;"amount_upper_bound": 6000000,<br> &nbsp; &nbsp;"amount_lower_bound": 6000000,<br> &nbsp; &nbsp;"date_upper_bound": "2021-01-15"<br> &nbsp;}'</h6><p><em>‍</em>Some banks will notify you in advance of a payment settling in an account. Modern Treasury captures that notification in the form of an Incoming Payment Detail object. Subscribing to Incoming Payment Detail <a href="https://docs.moderntreasury.com/reference#incoming-payment-details" target="_blank">webhooks</a> will be the first indication from the bank that the wires will settle soon.</p><h5>Step 3: Disburse funds </h5><p>Once the funds have arrived and the documents have been signed, you can disburse the total amount due to Sandy Seller. Let’s say Sandy Seller is getting $300,000 in net proceeds, which will go out via a single wire. Note that the amount is in cents, not dollars, so it is presented as 30000000:</p><h6>‍<br>curl --request POST \<br> &nbsp;-u ORGANIZATION_ID:API_KEY \<br> &nbsp;--url https://app.moderntreasury.com/api/payment_orders \<br> &nbsp;-H 'Content-Type: application/json' \<br> &nbsp;-d '{<br> &nbsp; &nbsp;"description": "Sale of 123 Main Street (Sandy’s Payout)",<br> &nbsp; &nbsp;"type": "wire",<br> &nbsp; &nbsp;"amount": 30000000,<br> &nbsp; &nbsp;"direction": "credit",<br> &nbsp; &nbsp;"currency": "USD",<br> &nbsp; &nbsp;"originating_account": "virtual-account-id",<br> &nbsp; &nbsp;"receiving_account_id": "sandy-external-account-id",<br> &nbsp; &nbsp;"counterparty_id": "sandy-counterparty-id"<br> &nbsp;}'</h6><p><em>‍</em>Once the payment goes through, the account will be debited $300,000 and the transaction will be complete.</p><p>Lastly, you want to add <a href="https://docs.moderntreasury.com/reference#metadata" target="_blank">metadata</a> to the payment for future reference. In addition to metadata tags (eg. key value pairs such as Type: Residential or State: Colorado) you might also attach the PDF for the legal docs, or the CSV calculating the amounts. This will be useful for finance teams that might have questions about this payment in the future.</p><p>That’s it. You have just built a sophisticated payment ops architecture for a house sale with a few API calls.</p><div><p>In reality, of course, things can be more elaborate. Billie Buyer could have multiple sources of funds for the down payment, as they may be receiving funds from family or from a service like <a href="http://haus.com/" target="_blank">Haus</a>. They may also be working with multiple lenders if they have a second mortgage. And depending on the state and county the house is located in, the escrow company may have to disburse funds for sales tax or other fees.</p></div><h4>What Can Go Wrong?</h4><p>Payment operations software, such as <a href="https://www.moderntreasury.com/" target="_blank">Modern Treasury</a>, can manage not only the happy path as described above but also edge cases when things go wrong. A common issue could be that a seller could mistype their bank account details, causing the payment to be returned. Modern Treasury supports account verification with providers like <a href="https://docs.moderntreasury.com/docs/plaid-integration-guide" target="_blank">Plaid</a>, so both you and the seller can be confident that funds are routed to the right destination.</p><p>Customer service issues are another type of problem that can arise, such as when a lender sends the incorrect amount. In that case, there might be an additional transaction necessary or an explanatory note for future audits. Modern Treasury supports tracking funds using double-entry <a href="https://docs.moderntreasury.com/docs/ledgers-overview" target="_blank">Ledgers</a>. This way, ops teams can refer to an immutable history of the transaction data, since all money movements are captured and displayed. In the future, accountants and auditors won’t be left wondering about a wire, since contextual information will be tied to the bank statement transaction in question.<br></p><h4>More?</h4><p>This post laid out a simple yet robust foundation for payment ops at an escrow company, leaving plenty of room for future functionality. </p><p>For any specific questions, or to see how Modern Treasury can help make your company’s payment ops simple, scalable, and secure, <a href="https://app.moderntreasury.com/sign_up" target="_blank">sign up today</a>.<br><em>Note: Modern Treasury empowers teams to make payment operations simple, scalable, and secure. The “Guides” series walks through representative businesses or payment processes and explains step by step how best to go about building them from scratch. ‍</em><br></p></div></div></div>]]>
            </description>
            <link>https://www.moderntreasury.com/journal/how-to-build-an-escrow-product</link>
            <guid isPermaLink="false">hacker-news-small-sites-25859638</guid>
            <pubDate>Thu, 21 Jan 2021 15:15:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[“Build your own Redis” challenge]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25859592">thread link</a>) | @rohitpaulk
<br/>
January 21, 2021 | https://codecrafters.io/challenges/redis | <a href="https://web.archive.org/web/*/https://codecrafters.io/challenges/redis">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div id="introduction">
      <h3>
        <span></span>
        <span>Introduction</span>
      </h3>

      <p>In this challenge, youâ€™ll build an application that can speak the Redis
protocol, and is capable of serving basic commands like PING, ECHO, SET and
GET. Along the way, youâ€™ll learn about TCP servers, event loops and more.</p>

      <h3>
        <span></span>
        <span>Stages</span>
      </h3>

      <div id="stages">
        
          <div>
  <div>
    <div>
      

      

      <p>In this stage, youâ€™ll start a TCP server on port 6379, which is the
default port that Redis uses.</p>

      

      
    </div>
    
  </div>
</div>



        
          



        
          <div>
  <div>
    <div>
      

      <div>
        <p>
          Respond to multiple PINGs
        </p>
        <p>
          #3
        </p>
      </div>

      <p>In this stage, youâ€™ll respond to multiple
<a href="https://redis.io/commands/ping">PING</a> commands sent by the same client.</p>

      

      
    </div>
    
  </div>
</div>



        
          <div>
  <div>
    <div>
      

      <div>
        <p>
          Handle concurrent clients
        </p>
        <p>
          #4
        </p>
      </div>

      <p>In this stage, youâ€™ll add support for multiple concurrent clients to your
Redis server. To achieve this youâ€™ll use an <a href="https://en.wikipedia.org/wiki/Event_loop">Event
Loop</a>,
like the official Redis implementation does.</p>

      

      
    </div>
    
  </div>
</div>



        
          



        
          <div>
  <div>
    <div>
      

      <div>
        <p>
          Implement the SET &amp; GET commands
        </p>
        <p>
          #6
        </p>
      </div>

      <p>In this stage, youâ€™ll need to implement the
<a href="https://redis.io/commands/set">SET</a> &amp;
<a href="https://redis.io/commands/get">GET</a> commands.</p>

      

      
    </div>
    
  </div>
</div>



        
          <div>
  <div>
    <div>
      

      

      <p>In this stage, youâ€™ll add support for setting a key with an expiry. The
expiry is provided using the â€œPXâ€� argument to the
<a href="https://redis.io/commands/set">SET</a> command.</p>

      

      
    </div>
    
  </div>
</div>



        
      </div>
    </div>
  </div></div>]]>
            </description>
            <link>https://codecrafters.io/challenges/redis</link>
            <guid isPermaLink="false">hacker-news-small-sites-25859592</guid>
            <pubDate>Thu, 21 Jan 2021 15:11:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Pandoc to create my programming eBooks]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25859147">thread link</a>) | @scastiel
<br/>
January 21, 2021 | https://scastiel.dev/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/ | <a href="https://web.archive.org/web/*/https://scastiel.dev/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      <header>
<picture><source srcset="https://d33wubrfki0l68.cloudfront.net/ae4027b51b61ee44dda910bf6494c95f22fe6de3/ac4bb/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/cover.200.webp 200w, https://d33wubrfki0l68.cloudfront.net/bd3d4135c7f0e5eb74752c30374565cf2b146329/25691/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/cover.450.webp 450w, https://d33wubrfki0l68.cloudfront.net/77d4d6fdcbb8cb06fbefeb38f6b39acdab680ec3/e560b/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/cover.700.webp 700w, https://d33wubrfki0l68.cloudfront.net/b7701e4b2c4885c352046bfe500b467ee9a4b9cf/3cde0/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/cover.950.webp 950w, https://d33wubrfki0l68.cloudfront.net/bb208f98748476826ba702898edac2e109295197/ba897/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/cover.1200.webp 1200w" sizes="100vw" type="image/webp"><source srcset="https://d33wubrfki0l68.cloudfront.net/310be49068b4f7e558fc54a0f7be461e8aa70ea6/1cb8c/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/cover.200.jpg 200w, https://d33wubrfki0l68.cloudfront.net/5912812981027da0a280fb799f31c1228c0f1710/f2d1e/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/cover.450.jpg 450w, https://d33wubrfki0l68.cloudfront.net/cf4ad076e52088990f60ddd4a1911c6766092c60/867b2/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/cover.700.jpg 700w, https://d33wubrfki0l68.cloudfront.net/ea320ac7a6208fb024e00ac0ec89891d5f977f92/fd028/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/cover.950.jpg 950w, https://d33wubrfki0l68.cloudfront.net/9b89ad7094d79f9d64df64c1ae0815e3be57c47a/1d762/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/cover.1200.jpg 1200w" sizes="100vw" type="image/jpeg"><img src="https://scastiel.dev/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/cover.jpg" alt="How I use Pandoc to create programming eBooks" height="900" width="1200" loading="lazy"></picture>

<p><small>21 Jan 2021 — 8 min read</small></p>
</header>
<p>In the past four years, I wrote three eBooks about programming. It’s like an
addiction.</p>
<p>I would be terrible at talking about writing techniques, so I won’t. But the
content is not everything when you write an eBook. You have to care about
creating <strong>beautiful files to release</strong>: PDF, ePub, Kindle…</p>
<p>Here is the story of how I built my eBooks, especially
<a href="https://gum.co/use-hooks">the last one</a>. After some trial and errors, in the
end, I used the same recipe as the two previous ones, and it involves a
fantastic tool: <strong>Pandoc</strong>.</p>

<p>I wanted my last eBook to be a practical guide, not an academic manual. So I
imagined a very <strong>custom design</strong>, with a <strong>dark theme</strong> and many colors (it is
not designed to be printed).</p>
<p>Since it was about coding, I also wanted to include some source code examples
with <strong>syntax highlighting</strong>.</p>
<p>Bust most of all, I wanted an efficient workflow.</p>

<p>I intended to release a first version of the book ASAP, then iterate thanks to
readers’ feedback and new ideas I had. For this reason, I wanted to focus on the
content and on the appearance <strong>independently</strong>.</p>
<figure><picture><source srcset="https://d33wubrfki0l68.cloudfront.net/bfd0c3d9b801873e1afa3d4b7e3961527dc29d16/c0557/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/workflow.200.webp 200w, https://d33wubrfki0l68.cloudfront.net/950a6c2316f801bfa7e0a4bf1522dfa9b31bc428/c6cb5/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/workflow.450.webp 450w, https://d33wubrfki0l68.cloudfront.net/9c3b04aae590a5fdceb0586c8fd8b663bdb6c86e/914d0/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/workflow.700.webp 700w, https://d33wubrfki0l68.cloudfront.net/b42d127063676ac7c09e61835705e8244d37133c/40c3f/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/workflow.950.webp 950w, https://d33wubrfki0l68.cloudfront.net/63f52999615a5afe530af59f8aeb040ccd46c181/72f58/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/workflow.1200.webp 1200w" sizes="100vw" type="image/webp"><source srcset="https://d33wubrfki0l68.cloudfront.net/0f88e7175d5429d2c6bb554da29f5a4dd7806c78/3815f/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/workflow.200.png 200w, https://d33wubrfki0l68.cloudfront.net/75c2e013e8d2b667d6cc4821f7b3796893662195/731fc/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/workflow.450.png 450w, https://d33wubrfki0l68.cloudfront.net/1d79b7916472362d110d5d2b480aaa44b60dfad7/189bc/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/workflow.700.png 700w, https://d33wubrfki0l68.cloudfront.net/b8e45f0f895ca805ca167770787f4033b50a5bec/c5138/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/workflow.950.png 950w, https://d33wubrfki0l68.cloudfront.net/4a9b5765d5f2e0fb5a81e559934aa1f6ca673bc3/fea2e/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/workflow.1200.png 1200w" sizes="100vw" type="image/png"><img src="https://scastiel.dev/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/workflow.png" alt="" height="626.9410664172123" width="1200" loading="lazy"></picture><figcaption>The workflow I didn’t want vs. the one I wanted.</figcaption></figure>
<p>I didn’t want to spend time on the presentation each time I updated the content.
I’m a web developer; it wouldn’t occur to me to edit my CSS each time I update
the HTML content. Same here.</p>

<p>I thought: why not just use <strong>MS Word</strong> or its Apple version, <strong>Pages</strong>? Well, I
tried. It didn’t go well.</p>
<p>You can customize pretty much everything you want. Every color, font family,
font size… But it gets trickier when you want to include source code.</p>
<p>Since I wanted to have syntax highlighting, the <em>less bad</em> solution I found was
to copy and paste from VS Code. At first, it looked (kind of) okay, but as soon
as I wanted to modify it, it went terribly: the formatting was lost, spaces were
inserted where I didn’t want them…</p>
<p>Definitely, these tools are not made to write content with embedded source code.</p>
<p>I also tried <strong>Illustrator</strong> and its open-source alternative,
<a href="https://www.scribus.net/"><strong>Scribus</strong></a>.</p>
<p>It was worse.</p>
<p>I admire people able to use these applications. They seem to require a lot of
training and practice. Unfortunately, I intended to release my book in the next
two years, so I didn’t have time to learn them. 😉</p>
<blockquote>
<p>I’m used to writing content using <strong>Markdown</strong>. Or in <strong>Slack</strong>. Or in
<strong>Notion</strong> (for this blog post). Today, we have such perfect tools for
writing. I didn’t want to struggle each time I update some examples.</p>
</blockquote>
<p>So, in the end, I relied on the tool I used for my previous books: <strong>Pandoc</strong>.</p>

<p><a href="https://pandoc.org/">Pandoc</a> is a command-line tool whose main feature is
converting some text (usually Markdown) to another format: HTML, ePub, PDF, etc.</p>
<p>I used it for my other books, and it’s perfect for “academic” work (thesis,
research articles). But I wasn’t sure that creating something a bit more
original, with shiny colors and such, was possible.</p>
<center>
<blockquote data-conversation="none" data-dnt="true"><p lang="en" dir="ltr">I spent around 5 hours to write the content, and lost the same amount of time looking for a publishing software or Saas to generate beautiful PDF for developer-oriented content, with source code. The winner ended being the good old Pandoc 😅</p>— Sébastien Castiel (@scastiel) <a href="https://twitter.com/scastiel/status/1338477555272331265?ref_src=twsrc%5Etfw">December 14, 2020</a></blockquote>
</center>
<p>To write the content, I could now write using Markdown, with the basic
formatting options I needed: titles, italic, source code… And the source code
was highlighted!</p>
<p>By the way, syntax highlighting is themeable, and I really wanted to use
<a href="https://draculatheme.com/">Dracula</a>, which I already used for my VSCode. So I
created
<a href="https://gist.github.com/scastiel/4c409156ad4bc6a6dbbfe2abbd163671#file-dracula-theme">a custom theme</a>
for it. 🙂</p>
<figure><picture><source srcset="https://d33wubrfki0l68.cloudfront.net/57126b332b19c837072171c5b315c72fa7dc7bc0/5d8ad/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/source-code.200.webp 200w, https://d33wubrfki0l68.cloudfront.net/7d3e8bb3d533535651fcbddc0f8b89595961a317/b99f7/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/source-code.450.webp 450w, https://d33wubrfki0l68.cloudfront.net/bba96f9f665c8ea11dcdd398eb7280f2ae8d18a1/2c410/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/source-code.700.webp 700w, https://d33wubrfki0l68.cloudfront.net/f6177856fcb919f3b5715612c6a49474e130d103/27a07/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/source-code.950.webp 950w, https://d33wubrfki0l68.cloudfront.net/12f9f054e88819251a588d94688a9ec409ce9f5e/e507e/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/source-code.1200.webp 1200w" sizes="100vw" type="image/webp"><source srcset="https://d33wubrfki0l68.cloudfront.net/02bdfa72bb3747413e36841620dfc622a1a49120/43c38/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/source-code.200.png 200w, https://d33wubrfki0l68.cloudfront.net/7010fa7342e3223d763f819451f5e853611a1813/d81fb/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/source-code.450.png 450w, https://d33wubrfki0l68.cloudfront.net/1be7013a21b32c29cc188343275aacbe3e3844fc/50fa5/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/source-code.700.png 700w, https://d33wubrfki0l68.cloudfront.net/89ac9f5f8a2374f3a43159c82ff53cc5d86df12c/5898e/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/source-code.950.png 950w, https://d33wubrfki0l68.cloudfront.net/e6ebaea9668563121f9ce8f5e18bbdc199161bfb/61d9c/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/source-code.1200.png 1200w" sizes="100vw" type="image/png"><img src="https://scastiel.dev/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/source-code.png" alt="" height="445.4081632653061" width="1200" loading="lazy"></picture><figcaption>Source code, colored using a theme based on <a href="https://draculatheme.com/">Dracula</a>.</figcaption></figure>
<p>The only thing I find problematic with Pandoc is
<a href="https://pandoc.org/MANUAL.html">its documentation</a>. It contains a lot of
information, but it’s on one page.</p>
<p>One page!</p>
<p>So you scroll, then scroll, and scroll again. And when you want to find
something, you do Cmd/Ctrl+F, type “color”, oh cool, there is something. Then
you realize you’re in the section concerning the generation of some obscure and
unknown document format…</p>
<p>Anyway, you can usually find what you’re looking for. I’d just prefer if it used
something more modern, such as Gitbook or Docusaurus, to maintain the
documentation and make it easier to navigate.</p>
<figure><picture><source srcset="https://d33wubrfki0l68.cloudfront.net/165aa1f54846f6f64709605b571aea2e76393e45/8a43e/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/pandoc.200.webp 200w, https://d33wubrfki0l68.cloudfront.net/823eb1dc70a12b8886da4a5ced4ee68ac9f70a47/bfcb4/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/pandoc.450.webp 450w, https://d33wubrfki0l68.cloudfront.net/8345cf64ccc1437d3dd0feff04ad72ade7df5f0e/4dc4d/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/pandoc.700.webp 700w, https://d33wubrfki0l68.cloudfront.net/3f53da09fea301b2a5e1fa86e92e2bb83e180442/21975/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/pandoc.950.webp 950w, https://d33wubrfki0l68.cloudfront.net/64d74f088e9d51f8e435369f1f60059cde73bfe9/8f558/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/pandoc.1200.webp 1200w" sizes="100vw" type="image/webp"><source srcset="https://d33wubrfki0l68.cloudfront.net/636aed8150675dc8995590f01f721763a428ebb1/12573/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/pandoc.200.png 200w, https://d33wubrfki0l68.cloudfront.net/70937fe86ece504b0044662af2f0427d41d6d5f0/10e40/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/pandoc.450.png 450w, https://d33wubrfki0l68.cloudfront.net/6e2a31148ea758c3b1e7825d831e2905528a7c13/15662/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/pandoc.700.png 700w, https://d33wubrfki0l68.cloudfront.net/727d48fededcf6d017f0ab299fa0c6990d0bdb1f/5da56/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/pandoc.950.png 950w, https://d33wubrfki0l68.cloudfront.net/5db3f29a3441cc04d9db59616df84a362bd901eb/c3104/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/pandoc.1200.png 1200w" sizes="100vw" type="image/png"><img src="https://scastiel.dev/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/pandoc.png" alt="" height="711.7287381878821" width="1200" loading="lazy"></picture><figcaption>An overview of how I used Pandoc to generate PDF, ePub, and mobi files.</figcaption></figure>
<p>Pandoc is very good at generating HTML or an ePub file. You can give it some CSS
to customize anything you want. It would be a dream if you were able to do the
same to generate a customized PDF.</p>
<p>Unfortunately, it is slightly more complicated…</p>

<p>To generate PDFs, Pandoc uses <em>pdflatex</em>, which relies on
<strong><a href="https://www.latex-project.org/">LaTeX</a></strong>. The LaTeX language is used to write
documents with a powerful but unusual syntax. These documents are then converted
to PDF, Postscript, etc.</p>
<p>So, a little like Pandoc. But with a weird syntax instead of beautiful Markdown.</p>
<p>Long story short, if you want to customize the PDF rendered by Pandoc with
<em>pdflatex</em>, you don’t have a choice: you need to provide some LaTeX code, a bit
like CSS.</p>
<p>And I didn’t want to spend several months learning LaTeX—it’s truly fantastic,
you can do anything you want with it. So I did what every good developer hates
doing: search on Google and copy-paste pieces of code.</p>
<p>Here is, for example, how I managed to have the book title in the page footer:
(sorry if you are a LaTeX guru, it probably will hurt your eyes)</p>
<pre><code><span>\usepackage</span><span>{</span><span>fancyhdr</span><span>}</span><br><span>\pagestyle</span><span>{</span>fancy<span>}</span><br><span>\fancyhf</span><span>{</span><span>}</span><br><span>\lfoot</span><span>{</span><br>  <span>\begin</span><span>{</span><span>tikzpicture</span><span>}</span><span>[</span>overlay,baseline=<span>{</span>(0,0)<span>}</span><span>]</span><br>  <span>\node</span><span>[</span>rectangle, outer sep=0pt, text=white, anchor=west <span>]</span><br>    (pageno)<br>    <span>{</span>A React Developer’s Guide to Hooks, © Sebastien Castiel<span>}</span>;<br>  <span>\draw</span><span>[</span>fill=comment, draw=comment<span>]</span><br>    (<span>[</span>xshift=-<span>\oddsidemargin</span>-1in<span>]</span>pageno.north west)<br>      rectangle<br>    (<span>[</span>yshift=1.5pt<span>]</span>pageno.south east);<br>  <span>\end</span><span>{</span><span>tikzpicture</span><span>}</span><br><span>}</span></code></pre>
<p>Well, to be fair, it would have been much more straightforward if I just wanted
the book title. But I wanted it in an indigo rectangle starting from the far
left of the page.</p>
<figure><picture><source srcset="https://d33wubrfki0l68.cloudfront.net/c6b1a96169f2a4a947680bc22687a158ebb4a24e/89cbd/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/footer.200.webp 200w, https://d33wubrfki0l68.cloudfront.net/38beae35b548bf76dee11ae02ab3c467ff60f359/15d96/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/footer.450.webp 450w, https://d33wubrfki0l68.cloudfront.net/4e2c7fa4a1bb78cd5f83e1a7aeef4846afba7033/80fba/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/footer.700.webp 700w, https://d33wubrfki0l68.cloudfront.net/7f16726c24deaeed9bae03eb6158813e65787e73/771dd/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/footer.950.webp 950w, https://d33wubrfki0l68.cloudfront.net/f237d8311d6c87f6f7c1ffd3dc2e311e3a7ca367/e7d8a/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/footer.1200.webp 1200w" sizes="100vw" type="image/webp"><source srcset="https://d33wubrfki0l68.cloudfront.net/d1f12a84ee7396b91bc69a3fa8adc329a2da71fe/f69cf/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/footer.200.png 200w, https://d33wubrfki0l68.cloudfront.net/14891146adbf9e79a81bb7a1acda7690df96889b/ba93f/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/footer.450.png 450w, https://d33wubrfki0l68.cloudfront.net/2ffdee8a7f0f0e676339556b70e8680f36c63cb2/8eb8b/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/footer.700.png 700w, https://d33wubrfki0l68.cloudfront.net/b5532712808c27db87f69118d7be2ea9d45a234e/0baaf/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/footer.950.png 950w, https://d33wubrfki0l68.cloudfront.net/0ab53758c14d64e94b458cea2ad51094dcdc0f73/7c9d1/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/footer.1200.png 1200w" sizes="100vw" type="image/png"><img src="https://scastiel.dev/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/footer.png" alt="" height="266.94386694386696" width="1200" loading="lazy"></picture><figcaption>The page footer is not that easy to obtain using LaTeX customization…</figcaption></figure>
<p>Still, most of the time, I was able to get what I wanted. It just took more time
than I wanted to spend on it.</p>
<p><em>You can find here
<a href="https://gist.github.com/scastiel/4c409156ad4bc6a6dbbfe2abbd163671#file-header-tex">the complete LaTeX header file</a>
I used for my book. I cleaned it a little and added some comments.</em></p>
<p>Although I didn’t interact with them, I’m sure the LaTeX community is fantastic
because you can find many resources on the Internet: answers on forums,
tutorials, manuals, etc.</p>

<p>I think the last time I used the
<a href="https://www.gnu.org/software/make/manual/make.html">GNU make</a> utility was like
ten years ago. I had this idea that it was only used by C or C++ projects.</p>
<p>If you never heard of <strong>GNU make</strong>, it’s a utility program to run specific
commands to generate files. It’s mostly used to compile and build programs, but
you can use it for any command.</p>
<p>My first intuition was to write a shell script to generate my book in several
formats. Quickly, I realized a <strong>Makefile</strong> would make more sense:</p>
<ul>
<li>I had <em>content</em> files and <em>resource</em> files (images, the LaTeX header, for
example)</li>
<li>I needed to generate intermediate files, such as the cover as a PDF from a PNG</li>
<li>Some formats (ePub) were used to create other formats (Kindle)</li>
</ul>
<p>Using a Makefile, I regenerated only the needed parts, based on which files were
updated since the latest build. I could run <code>make pdf</code>, <code>make epub</code>,
<code>make mobi</code>, or just <code>make</code> to generate all formats.</p>
<p>Here is the portion of my Makefile used to generate the <em>ePub</em> and <em>mobi</em>
(Kindle) files:</p>
<pre><code>BOOK_TITLE <span>=</span> A\ React\ Developer’s\ Guide\ to\ Hooks\ -\ Sebastien\ Castiel<p><span>epub</span><span>:</span> dist/<span>$</span><span>{</span>BOOK_TITLE<span>}</span>.epub<br>  <span>@</span>echo <span>'✅  ePub'</span></p><p><span>kindle</span><span>:</span> dist/<span>$</span><span>{</span>BOOK_TITLE<span>}</span>.mobi<br>  <span>@</span>echo ‘✅  Kindle’</p><p><span>dist/<span>$</span>{BOOK_TITLE}.epub</span><span>:</span> dist content/*.md images/* resources/dracula.theme resources/metadata.xml resources/epub.css<br>  <span>@</span>pandoc content/foreword.md content/ch*.md content/resources.md \<br>  --output<span>=</span>dist/<span>$</span><span>{</span>BOOK_TITLE<span>}</span>.epub \<br>  --highlight-style resources/dracula.theme \<br>  --standalone \<br>  --epub-metadata<span>=</span>resources/metadata.xml \<br>  -c resources/epub.css \<br>  --epub-cover-image<span>=</span>cover.png \<br>  --toc --toc-depth<span>=</span>1 \<br>  --metadata title<span>=</span><span>"A React Developer’s Guide to Hooks"</span></p><p><span>dist/<span>$</span>{BOOK_TITLE}.mobi</span><span>:</span> dist/<span>$</span><span>{</span>BOOK_TITLE<span>}</span>.epub<br>  <span>@</span>kindlegen dist/<span>$</span><span>{</span>BOOK_TITLE<span>}</span>.epub -o <span>$</span><span>{</span>BOOK_TITLE<span>}</span>.mobi &gt;/dev/null 2&gt;&amp;1</p></code></pre>
<p>Okay, maybe slightly overkill for my needs, but I felt so powerful! 💪🏻</p>
<p><em>You can find
<a href="https://gist.github.com/scastiel/4c409156ad4bc6a6dbbfe2abbd163671#file-makefile">here the complete Makefile</a>
for my book.</em></p>

<p>I embedded the examples’ source code in a small <strong>React</strong> application to run
them locally. The user can start it by running <code>yarn start</code> and navigate easily
through them.</p>
<p>Now, I feel a bit silly not to have thought of using
<a href="https://storybook.js.org/">Storybook</a>, which could have been a perfect
solution.</p>
<figure><picture><source srcset="https://d33wubrfki0l68.cloudfront.net/693b2876704c49fe9bf7b77a06148eac644d8888/7d3fa/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/examples.200.webp 200w, https://d33wubrfki0l68.cloudfront.net/76ad9fba8cff1521e7e65fabc2972b8f716472bd/1bf35/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/examples.450.webp 450w, https://d33wubrfki0l68.cloudfront.net/fe535ca19202d3d2af1e4031f78de1c27871d537/03ede/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/examples.700.webp 700w, https://d33wubrfki0l68.cloudfront.net/148bb3d8dd94b371fa1d13234baaa3723a0bf974/0feab/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/examples.950.webp 950w, https://d33wubrfki0l68.cloudfront.net/c726e84866efee8519d93bfbe62848ddaf865177/b99cd/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/examples.1200.webp 1200w" sizes="100vw" type="image/webp"><source srcset="https://d33wubrfki0l68.cloudfront.net/93e287a7621c6e59f9446ad7b235dfa032c1e23f/2e60d/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/examples.200.png 200w, https://d33wubrfki0l68.cloudfront.net/bc37301d0565c749c4a9cde5b1560ae17d0917ef/58387/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/examples.450.png 450w, https://d33wubrfki0l68.cloudfront.net/56036c8ea2353af4495b76e9b9e0cd6a68b90e09/4c7f1/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/examples.700.png 700w, https://d33wubrfki0l68.cloudfront.net/f35f0f37011d3f6a830b5078cf0df8867d801e1b/7b742/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/examples.950.png 950w, https://d33wubrfki0l68.cloudfront.net/bcc98ecbd3f656837cefd030cb9c78e0413a8166/4754f/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/examples.1200.png 1200w" sizes="100vw" type="image/png"><img src="https://scastiel.dev/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/examples.png" alt="" height="781.5849056603773" width="1200" loading="lazy"></picture><figcaption>The mini-app to run examples.</figcaption></figure>
<p>I created the cover using Apple Pages, sufficient for what I wanted to do. I
should <s>probably</s> definitely hire someone to create a more professional one.</p>
<figure><picture><source srcset="https://d33wubrfki0l68.cloudfront.net/7c458362b75075b3efca4decc4ee94beb3e33c90/c9532/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/pages.200.webp 200w, https://d33wubrfki0l68.cloudfront.net/33a797aed8828219bbabe80426cd212610f9c9ef/e9e4b/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/pages.450.webp 450w, https://d33wubrfki0l68.cloudfront.net/2a6e4a5dacdabc8a4d9e692298ba34e81f8ee837/bc210/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/pages.700.webp 700w, https://d33wubrfki0l68.cloudfront.net/0299e3b962ef9efe58939a4ddd1caab3d383c2ca/4d1bf/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/pages.950.webp 950w, https://d33wubrfki0l68.cloudfront.net/357d92995c25319a69046dd6cb76ce8af26a80c0/99fb2/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/pages.1200.webp 1200w" sizes="100vw" type="image/webp"><source srcset="https://d33wubrfki0l68.cloudfront.net/b52a9ca7fdece13d86cdeb078544a01390114126/12248/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/pages.200.png 200w, https://d33wubrfki0l68.cloudfront.net/54e79d354c7aba54dcf9760684ad985837ba6284/9ef81/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/pages.450.png 450w, https://d33wubrfki0l68.cloudfront.net/0928058f443ac607b31bd38a5d05ff783a12ec07/35d7f/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/pages.700.png 700w, https://d33wubrfki0l68.cloudfront.net/ae39ee28455d895496709b4f60420a2f3f0a60ab/7d9ab/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/pages.950.png 950w, https://d33wubrfki0l68.cloudfront.net/4aa1c28e3e7503bc610f73a9f713678eb137e8be/35a19/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/pages.1200.png 1200w" sizes="100vw" type="image/png"><img src="https://scastiel.dev/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/pages.png" alt="" height="715.2041702867072" width="1200" loading="lazy"></picture><figcaption>Designing the cover in Pages.</figcaption></figure>
<p>I often design graphics using <strong><a href="https://inkscape.org/">Inkscape</a></strong> (for
example, the banner for the <a href="https://gum.co/use-hooks">Gumroad page</a>), even if
at the end I manipulate and generate bitmap images. I know it’s not its first
purpose, but I find it easier to use than Gimp or commercial alternatives.</p>
<p>If you know a better choice, please please please tell me!</p>

<p>From the beginning, I really wanted a custom presentation with a dark theme.</p>
<p>Now, I realize this wish took me a lot of extra time. And I would have preferred
spending that time on the content. Plus, I don’t know if the readers actually
like this theme or not…</p>
<p>Also, it may have been better to focus first on the <strong>web support</strong>.
<a href="https://v2.docusaurus.io/">Docusaurus</a> could do an excellent job: readers could
navigate the sections, search for keywords, etc.</p>
<p>The PDF or ePub version would be secondary content: available, but maybe with a
generic appearance. So what?</p>
<blockquote>
<p>In the end, if the user finds the content useful, shouldn’t it be all that
matters?</p>
</blockquote>
<p>I will probably consider this change soon. Plus, I’d like to create a <strong>course</strong>
(without video) from the book’s content…</p>
<p>Regarding the workflow with Pandoc, I’m quite satisfied with it. Writing using
Markdown is lovely to focus on the content without caring how it will render.
And since Markdown is text, it’s easy to keep track of the history using Git. 🙂</p>
<center>
<blockquote data-conversation="none" data-dnt="true"><p lang="en" dir="ltr">It takes some time to set it up, especially to get the rendering you have in mind. But once it’s done, the workflow is perfect: write in Markdown, …</p></blockquote></center></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://scastiel.dev/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/">https://scastiel.dev/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/</a></em></p>]]>
            </description>
            <link>https://scastiel.dev/posts/2021-01-21-how-i-use-pandoc-to-create-my-programming-ebooks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25859147</guid>
            <pubDate>Thu, 21 Jan 2021 14:30:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Avoiding the One Step Back]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25859129">thread link</a>) | @pplonski86
<br/>
January 21, 2021 | https://staysaasy.com/management/2021/01/21/Step-Back.html | <a href="https://web.archive.org/web/*/https://staysaasy.com/management/2021/01/21/Step-Back.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Teams, especially at growth companies, often have a pattern of taking two steps forward and one step back. Let’s explore how teams often unknowingly slip after growing and let’s explore ways to prevent that from happening. Only forward steps!</p>

<h2 id="this-happens-a-lot---the-setup">This Happens A Lot - The Setup</h2>

<p>Let’s talk about my favorite pretend team, The Acme Widget Builders. It’s a cross-functional team with a product manager, an engineering manager, and a number of engineers. The team is operating very well and is growing with the company. Eventually the Original Product Manager has to hire another PM to manage the team, so the Original Product Manager can manage a larger group of teams.</p>

<p>About 6 months later the team starts to suffer a string of quality issues. Nobody really knows why this is happening, but it’s frustrating. The team starts to focus much more heavily on QA and gets back on the righteous path over time. However, a concern remains - what happened?</p>

<h2 id="this-happens-a-lot---the-diagnosis">This Happens A Lot - The Diagnosis</h2>

<p>After doing some soul searching about what the heck happened, you realize that the Original Product Owner was a Widget Whiz. They knew every single thing about the Acme Widgets, and, in fact, they were catching a lot of bugs when reviewing features-to-be-launched at the UAT phase. Herein lies the issue.</p>

<p>It’s not really the PMs primary job to catch bugs in the UAT phase. Actually, when the Original Product Owner transferred the team responsibility to the new PM, the Original Product Owner never mentioned the QA they were doing in UAT. As a result, the team lost a critical QA resource and never thought about how to counteract that reality.</p>

<h2 id="implicit-responsibilities">Implicit Responsibilities</h2>

<p>When team’s grow, explicit responsibilities are often transferred deftly and quickly as new team members join. However, implicit or unstated responsibilities often fall by the wayside. It’s not part of the official checklist, it might not even be part of the job, but the reality remains - if you’re filling a gap and leave without finding a replacement, that gap is going to show up as soon as you leave.</p>

<p>Furthermore, you might have an explicit responsibility that you do way better than expected. Handing off that responsibility to someone who is not going to fully fill your shoes (even if at first), is another form of creating implicit gaps on the team.</p>

<h2 id="the-fix">The Fix</h2>

<p>When you transition a team that you were previously a leader in, take stock of the things you were doing that weren’t part of the official role. Consider things that you are disproportionately owning for the team. It can be anything: meeting running, architecture, QA, recruiting.</p>

<p>Then, find ways to do some of the following:</p>
<ul>
  <li>Let people know the gaps will exist. Announce the diagnosis.</li>
  <li>Find ways to personally ensure continuity and resource the gap.</li>
</ul>



    

    




  </div></div>]]>
            </description>
            <link>https://staysaasy.com/management/2021/01/21/Step-Back.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25859129</guid>
            <pubDate>Thu, 21 Jan 2021 14:28:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Predicting Hard Drive Failure with Machine Learning]]>
            </title>
            <description>
<![CDATA[
Score 230 | Comments 57 (<a href="https://news.ycombinator.com/item?id=25859128">thread link</a>) | @binwiederhier
<br/>
January 21, 2021 | https://datto.engineering/post/predicting-hard-drive-failure-with-machine-learning | <a href="https://web.archive.org/web/*/https://datto.engineering/post/predicting-hard-drive-failure-with-machine-learning">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
<h4><strong>Drive prediction @ Datto</strong></h4>
<p>	We’ve all had a hard drive fail on us, and often it’s as sudden as booting your machine and realizing you can’t access a bunch of your files. It’s not a fun experience. It’s especially not fun when you have an entire data center full of drives that are all important to keeping your business running. What if we could predict when one of those drives would fail, and get ahead of it by preemptively replacing the hardware before the data is lost? This is where the history of predictive drive failure at Datto begins.</p>
<p>	First and foremost, to make a prediction you need data. Hard drives have a built-in utility called SMART<em> (</em><strong><em>S</em></strong><em>elf-</em><strong><em>M</em></strong><em>onitoring, </em><strong><em>A</em></strong><em>nalysis and </em><strong><em>R</em></strong><em>eporting </em><strong><em>T</em></strong><em>echnology)</em> that reports an array of statistics about how the drive is functioning. Here’s an abbreviated view of what that looks like:<br></p>
<figure><img src="https://datto.engineering/DBImg/smart_file_sample.png" alt=""></figure><p>	Datto collects a report like this from each hard drive in its storage servers once per day. Each attribute in the report has three important numbers associated with it: value, thresh, and worst. Each attribute also has a feature named raw_value, but this is discarded due to inconsistent reporting standards between drive manufacturers. </p>
<p>	<strong>Value:</strong> A number between 1 and 253, inclusive. The value reflects how well the drive is operating with respect to the attribute, with 1 being the worst and 253 being the best. The initial value is arbitrarily determined by the manufacturer, and can vary by drive model. </p>
<p>	<strong>Thresh: </strong>A threshold below which the value should not fall in normal operation. If the value falls below the threshold, there is likely something wrong with the drive.</p>
<p>	<strong>Worst: </strong>A record of the lowest value ever recorded for the attribute.</p>
<p>	A quick approach to using these values to make useful predictions is to pick a couple of attributes that seem important and make an alert if any of their values pass below the associated threshold. This is how the first iteration of predictive drive failure at Datto worked. It wasn’t perfect, but it was definitely better than nothing!</p>
<figure><img src="https://datto.engineering/DBImg/code_snippet_1.png" alt=""></figure><p>The next iteration of drive failure prediction was assigning a weighted health score to each drive. This score was defined by assigning weight to several different attributes based on how severe they appeared to be, then adding them together. This prediction method was better than its predecessor, but could potentially be improved even further.</p>
<figure><img src="https://datto.engineering/DBImg/code_snippet_2.png" alt=""></figure><p>This brings us to the most recent iteration of drive failure prediction at Datto and the topic of this article: <strong>smarterCTL</strong>, a machine learning model using most attributes reported by SMART to make the most informed prediction possible. <code>Smartctl</code> is the command line utility used to collect SMART reports. SmarterCTL is a machine learning model making use of <code>smartctl</code>, so it’s the smart-ER version of it. Yeah, it’s a bad pun, but I’m an engineer not a comedian.</p>
<h4><strong>Machine learning &amp;&amp; SMART</strong></h4>
<p>Before we get into the details of smarterCTL, let’s briefly go over machine learning. At its core, machine learning is the process of applying statistics to a dataset to find patterns in it. Once the patterns are found, they can be applied to new data to make assumptions about what that new data means. The defining feature of machine learning is that the programmer doesn’t have any input in figuring out the patterns in the data; the algorithm does that on its own through trial and error. For a great high level introduction to how machine learning works, check out <a href="https://www.youtube.com/watch?v=f_uwKZIAeM0">this</a> two minute video. </p>
<p>	To get a feel for workflow and terminology, let’s walk through a simplified application of machine learning on drive failure prediction. This example glosses over details and makes some leaps of logic to keep the scope broad. For a more accurate look under the hood of decision tree-based machine learning models, check out this <a href="https://e2eml.school/how_decision_trees_work.html">article</a> and the other resources linked throughout this section.</p>
<p>To make predictions, we need a dataset to train the model on. In this case, the data points are hard drives and the features of those data points are the attributes SMART provides.</p>
<figure><img src="https://datto.engineering/DBImg/datapoint_example.png" alt=""></figure><p>	These data points are labelled as members of the negative or positive class, which in this case means “hard drive operates normally” or “hard drive has failed.” Note that the “positive” in “positive class” doesn’t mean “good.” Instead, it means “this sample exhibits the behavior we’re looking out for.” A machine learning model would read this dataset, then look for patterns in the features that determine why each hard drive ended up in its class.</p>
<p>Normally there would be enough data points and features that a human couldn’t read the whole dataset—let alone spot a pattern in it! This example is simplified enough for us to step through the process that a model might follow. Let’s look for a pattern in each feature:</p>
<figure><img src="https://datto.engineering/DBImg/seek_error_rate.png" alt=""></figure>
<p>Nothing to see here, neither class is homogeneous when it comes to seek_error_rate.<br></p>

<figure><img src="https://datto.engineering/DBImg/spin_up_time.png" alt=""></figure><p>Again, we can’t make a determination based on this attribute alone. There isn’t an obvious split, like high numbers being good and low numbers being bad.</p>

<figure><img src="https://datto.engineering/DBImg/power_on_hours.png" alt=""></figure><p>This time it looks like there is a pattern! Drives with high power-on hours are healthy and drives with low power-on hours will fail. This doesn’t make logical sense though—a drive with low power-on hours should be the healthiest, since it’s the closest to mint condition. Let’s look a little deeper, and see if we can find a correlation between this feature and another that tells us something more logical. </p>

<figure><img src="https://datto.engineering/DBImg/spin_up_over_poh.png" alt=""></figure><p>A-ha! There’s still a difference in magnitude between the two classes, but this time there’s an explanation for it that makes sense: an older drive with a high spin-up time is aging and degrading normally, while a very young drive with a high spin-up time indicates that there might be something like a factory defect.</p>

<p>Now that we’ve figured out the pattern, let’s see how our theoretical model would classify these new SMART reports:</p>
<figure><img src="https://datto.engineering/DBImg/unclassified.png" alt=""></figure><p>	The ratio of spin-up time over power-on hours for drive X is 0.0002, which indicates that it will remain healthy. The ratio for drive Y is 0.045, pointing toward failure.<br>	So how do we know if the model made correct predictions? Well, we just have to wait and see. One of the trickier parts of this problem space is verifying results, because the whole point is to allow us to take action before the thing we’re predicting ever happens. Keep this in mind, it’ll come back to bite us later.</p>
<p>SmarterCTL’s job is to classify hard drives as “failing” or “not failing” so Datto can avoid being blindsided by lost drives and preemptively swap them for healthy ones. If there are patterns in SMART stats that indicate drive failure, smarterCTL will learn those patterns from SMART data Datto has collected over the past 3 years. Then smarterCTL can monitor new daily SMART reports and produce an alert when a drive is exhibiting a pattern that indicates failure.</p>

<h2><strong>Act 2 - Data preparation</strong></h2>
<p>We have several hundred gigabytes of SMART files spanning 3 years and a relatively beefy server to train a machine learning model on—the next step is to set it up and let it churn through the data, right? Unfortunately the work has just begun. Even though machine learning models have a reputation for taking days, or even weeks to train, preparing the data is often the most time consuming part of the process! </p>
<p>	Software folks know that computers are “dumb” and will only do exactly what they’re instructed to. Therefore, the data fed into a machine learning model needs to be very carefully curated. The model has no intuition about whether the conclusions it’s coming to are logical or not, so data that doesn’t accurately describe the whole problem space will lead to a model that confidently spouts nonsense.</p>
<p>In machine learning, the job of the programmer isn’t to spot the patterns in the data: it’s to spot the antipatterns that the model might fall into along the way. Good data treatment and preparation are the first steps in avoiding those antipatterns. </p>
<h4><strong>Shaping the data</strong></h4>
<p>The first step is turning the human readable SMART reports into something more machine readable.</p>
<figure><img src="https://datto.engineering/DBImg/sample_smart_data_1.png" alt=""></figure><p>	I condensed all of the data in each day of smart reports into its own csv file, but some key information was still missing. Since this data will be used to train a model, every data point needs to have a class label associated with it—the model needs to know whether these are healthy or failed drives so it can start to learn about potential patterns. </p>
<p>Producing the class labels ended up being a little tricky—if a drive is in poor enough health to be a member of the failing class, it might already be failing badly enough to not report SMART stats. To get a clearer idea of how drives were behaving and when they were failing out, I wrote a script that walked through every day of SMART reports and tracked how and when each drive failed. </p>
<p>Our servers use the filesystem ZFS, which pools together storage devices into groups called “zpools”. The zpool reports a health status for each drive in the pool. When my script comes across a failing zpool status for a drive, it notes on which day the failure occurred then goes through every daily csv and adds the following features to that drive’s row:</p>
<ol><li>Whether this drive ever fails (class label)</li><li>If so, in how many days from this csv’s date the failure would occur, and</li><li>The zpool status associated with the failure</li></ol><p>With the addition of those features, our data now looks like this:</p>
<figure><img src="https://datto.engineering/DBImg/sample_smart_data_2.png" alt=""></figure><p>	At this point the dataset is a collection of csv files, one per day, that contain:</p>
<ul><li>One row per drive</li><li>The SMART data reported by each drive on that day</li><li>Whether each drive is currently failed</li><li>Whether each drive ever failed while we tracked it</li></ul><p>	Seems like enough data to start making predictions, right? Well, kind of! At this point, the data is well-formed enough that a model could understand it and start producing predictions. The quality of those predictions would be poor, though; the data needs a lot more treatment to remove the pitfalls lurking within.&nbsp;</p>
<h4><strong>Cleaning the data</strong></h4>
<p>	Right now, the data is well formed but messy. It’s in the right shape, …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://datto.engineering/post/predicting-hard-drive-failure-with-machine-learning">https://datto.engineering/post/predicting-hard-drive-failure-with-machine-learning</a></em></p>]]>
            </description>
            <link>https://datto.engineering/post/predicting-hard-drive-failure-with-machine-learning</link>
            <guid isPermaLink="false">hacker-news-small-sites-25859128</guid>
            <pubDate>Thu, 21 Jan 2021 14:28:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The most pirated international movies]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 17 (<a href="https://news.ycombinator.com/item?id=25858996">thread link</a>) | @donohoe
<br/>
January 21, 2021 | https://restofworld.org/2021/the-ten-most-pirated-international-movies-2020/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2021/the-ten-most-pirated-international-movies-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

			<!-- Article Start -->
			
<h3>Piracy in the pandemic</h3>



<p>The pandemic may have stopped many from going to the cinema, but that doesn’t mean people didn’t watch films in 2020. Whether through streaming services like Netflix or old-fashioned TV channels and DVDs, there are still many ways to enjoy films at home.</p>



<p>And, of course, there’s always piracy.</p>



<p>According to London-based company Muso, which tracks copyright infringement in 196 countries, visits to sites hosting pirated streams of films increased <a href="https://f.hubspotusercontent40.net/hubfs/6347345/Has%20the%20displaced%20cinema%20audience%20become%20the%20new%20piracy%20audience.pdf?utm_campaign=COVID-19%20Protect%20&amp;utm_medium=email&amp;_hsmi=89190861&amp;_hsenc=p2ANqtz-9fsAlLpaO7ia-oGXZtShQz3YvarSVxz-MOcRsd6n-2MdwgaqkuJst2pleQF6wqtV2M9iKJJrEHjfzWrF6zIi64vzWBy6G_Y04I0aTFZKM8_SzKuys&amp;utm_content=89190861&amp;utm_source=hs_automation">as much as 90%</a> in some countries during the first few months of the pandemic. The company provided<em> Rest of World</em> with its list of the top 50 foreign films accessed via illegal streaming sites from January to October last year.</p>



<p>Predictably, many of the films are from the last two years. One notable exception? “The Flu,” a 2013 film about a lethal, airborne virus that infects a South Korean city. But which films made the top ten?</p>



<h2 id="attraction-2-invasion">Attraction 2: Invasion</h2>



<p><strong>From:</strong> Russia<br><strong>Genre:</strong> Horror<br><strong>Release date:</strong> 12/19/2019</p>



<figure><p>
<iframe data-src="https://www.youtube.com/embed/RHNafY8ZX4A?feature=oembed" title="ATTRACTION 2: INVASION Trailer (2020)" width="640" height="360" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>



<p>An ordinary girl becomes the object of study after she gains superpowers from exposure to extraterrestrial technology in this film from Russian director Fyodor Bondarchuk.&nbsp;</p>



<p>“Invasion” picks up where the 2017 film “Attraction” left off, after an alien ship has crash-landed in a Russian city. Exposed to alien technology, Julia is brought into a secret government lab to be studied. After gaining superpowers that threaten not only humans but also extraterrestrial life, Julia has to decide which side she is on.&nbsp;</p>



<p>Though the film has not been widely reviewed in Western media outlets, the entertainment website <a href="https://www.eclecticpop.com/2020/12/movie-review-does-attraction-2-invasion-vtorzhenie-satisfy-as-a-sequel.html">Eclectic Pop</a> noted that “the sequel avoids the mind-numbing quality of its genre peers to provide something captivating,” providing a worthy sequel to its predecessor. The film grossed <a href="https://www.boxofficemojo.com/title/tt8060328/?ref_=bo_se_r_1">$15.9 million</a> worldwide.</p>



<h2 id="baaghi-3">Baaghi 3</h2>



<p><strong>From:</strong> India<br><strong>Genre:</strong> Action<br><strong>Release date:</strong> 3/6/2020</p>



<figure><p>
<iframe data-src="https://www.youtube.com/embed/jQzDujMzfoU?feature=oembed" title="Baaghi 3 | Official Trailer | Tiger Shroff |Shraddha|Riteish|Sajid Nadiadwala|Ahmed Khan| 6th MARCH" width="640" height="360" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>



<p>In this 2020 Indian action thriller directed by Ahmed Khan, the third in a series of loosely related films, a man with chiseled abs saves his elder brother from Syrian terrorists.&nbsp;</p>



<p>Ronnie’s rescue mission is a display of punches, explosions, and acrobatics, often shown in slow motion, “but none of it can rise beyond a weak script that doesn’t go for the kill,” the <a href="https://timesofindia.indiatimes.com/entertainment/hindi/movie-reviews/baaghi-3/movie-review/74503018.cms"><em>Times of India </em>wrote</a>. Ronnie, played by Indian actor Tiger Shroff, beats up men, cars, tanks, and helicopters, mostly shirtless. “He bounces off buildings, treads on air; delivers triple roundhouse kicks and does devastating stuff with his hands and feet,” the <a href="https://www.hindustantimes.com/bollywood/baaghi-3-movie-review-tiger-shroff-saves-syria-but-not-sanity/story-wrmhhjpvtV40GFYOsZCsUI.html"><em>Hindustan Times </em>wrote</a>.&nbsp;</p>



<p>While the film attempts to reach beyond Bollywood cliches, one trope remains: demonizing Muslims as villains. The film grossed <a href="https://www.boxofficemojo.com/title/tt8366590/?ref_=bo_se_r_1">$16.7 million</a> worldwide.&nbsp;</p>



<h2 id="sputnik">Sputnik</h2>



<p><strong>From:</strong> Russia<br><strong>Genre:</strong> Drama<br><strong>Release date:</strong> 9/10/2020</p>



<figure><p>
<iframe data-src="https://www.youtube.com/embed/oGgtRsvq6hc?feature=oembed" title="Sputnik Trailer #1 (2020) | Movieclips Trailers" width="640" height="360" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>



<p>Two Russian cosmonauts return to Earth from a research mission in 1983, but their spacecraft malfunctions on the way home. Only one crew member, Konstantin Sergeyevich, survives. But he is not alone. Konstantin’s body houses a slimy, spindly creature that is dormant during the day, in his stomach. At night, it climbs out of his body in search of human flesh.&nbsp;</p>



<p>Reviewer Matt Zoller Seitz says a “very Russian vibe of <a href="https://www.rogerebert.com/reviews/sputnik-movie-review-2020">soulful heaviness</a>” sets the film apart. Rather than give up his dream of space travel, Konstantin, whose spouse passed away before the journey, put his son in an orphanage. When he returns to Earth, Konstantin must confront his responsibility. Though “Sputnik” is about an alien, it focuses heavily on humans: how and where our weak points are, how we can be manipulated, and how our biology can fail us.&nbsp;</p>



<p>Released in the middle of a pandemic, “Sputnik” grossed <a href="https://www.boxofficemojo.com/title/tt11905962/?ref_=bo_se_r_2">$307,062</a> at the box office worldwide and was shown as part of the <a href="https://tribecafilm.com/films/sputnik-2020">Tribeca Film Festival</a>.</p>



<h2 id="one-piece-stampede">One Piece: Stampede</h2>



<p><strong>From:</strong> Japan<br><strong>Genre:</strong> Animation<br><strong>Release date: </strong>8/9/2019</p>



<figure><p>
<iframe data-src="https://www.youtube.com/embed/S8_YwFLCh4U?feature=oembed" title="&quot;ONE PIECE STAMPEDE&quot; | Official Trailer" width="640" height="360" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>



<p>It’s probably no surprise that this anime film is on the list, as it’s based on one of the most popular Japanese manga series of all time: “One Piece,” by Eiichiro Oda. It is the 14th film in the franchise.&nbsp;</p>



<p>Pirates from around the world gather at a festival where they race to an island containing the legendary lost treasure of Gol D. Roger, king of the pirates. The race quickly unravels into fantasy violence, which the <a href="https://www.latimes.com/entertainment-arts/movies/story/2019-10-23/one-piece-stampede-review-anime"><em>Los Angeles Times</em></a> called “nonstop mayhem” — explosions, fistfights, earthquakes, and naval bombardments dart across the screen with colorful special effects.&nbsp;</p>



<p>Luffy, the protagonist of the series, teams up with his crew, the Straw Hat Pirates. They face off against Bullet, who hopes to make his name as the strongest pirate, the new king, and someone who relies on only himself. Luffy, like all good role models, values friendship and teamwork. The film grossed <a href="https://www.boxofficemojo.com/title/tt9430698/?ref_=bo_se_r_1">$81.6 million</a> worldwide.&nbsp;</p>



<h2 id="son-of-a-richnbsp">Son of a Rich&nbsp;</h2>



<p><strong>From:</strong> Russia<br><strong>Genre:</strong> Comedy<br><strong>Release date:</strong> 11/24/2019</p>



<figure><p>
<iframe data-src="https://www.youtube.com/embed/goGvFuBM23M?feature=oembed" title="Sedlák/Son of A Rich" width="640" height="360" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>



<p>Here’s a comedic plot for the ages: an oligarch’s pampered son is tricked into believing that he has traveled through time to become a serf in a 19th-century village, in a bid to rehabilitate his appalling behavior.&nbsp;</p>



<p>Grigory’s family is so wealthy, he believes that he is above the law. He parties hard, gets into trouble, and scoffs in the face of authority. One day, he goes too far — and so his father, as one does, buys a large tract of land and hires a group of actors to create a 19th-century village. His son gets into an orchestrated fake car accident and wakes up in the village, believing that he’s traveled back through time. Watched by a network of hidden cameras (and a team of psychologists), the oligarch watches his son discard his privileged ways and learn the value of hard work.</p>



<p>Clearly, this relatable tale of redemption struck a chord with people: the Russian comedy directed by Klim Shipenko grossed <a href="https://www.boxofficemojo.com/title/tt11418452/?ref_=bo_se_r_1">$43.8 million</a> and was one of the most pirated films of the year.</p>



<h2 id="recep-vedik-6">Recep İvedik 6</h2>



<p><strong>From:</strong> Turkey<br><strong>Genre:</strong> Comedy<br><strong>Release date:</strong> 11/7/2019</p>



<figure><p>
<iframe data-src="https://www.youtube.com/embed/BPXtVB2Qp-4?feature=oembed" title="Recep İvedik 6 - Fragman (Official)" width="640" height="360" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>



<p>Recep, a man with a unibrow and a penchant for slapping people in the face, has misadventures in Kenya, in this Turkish slapstick comedy, directed by Togan Gökbakar.&nbsp;</p>



<p><a href="https://play.google.com/store/movies/details/Recep_%C4%B0vedik_6?id=3sJ0zlYkZME.P&amp;hl=en_US&amp;gl=US">Recep İvedik</a> is at home watching television, when the mailman delivers him an invitation to a dried beans festival in Turkey’s Konya province. But instead of getting plane tickets to Konya, Recep and his best friend Nurullah end up on a flight to Kenya.&nbsp;</p>



<p>Recep and Nurullah join a safari tour. A series of escalating comical escapades ensue, with everything from close encounters with the local wildlife to mediating a dispute between two tribes. The film grossed <a href="https://www.boxofficemojo.com/title/tt7399138/?ref_=bo_se_r_1">$17 million</a> worldwide.&nbsp;</p>



<h2 id="peninsula">Peninsula</h2>



<p><strong>From:</strong> South Korea<br><strong>Genre:</strong> Thriller<br><strong>Release date:</strong> 7/15/2020</p>



<figure><p>
<iframe data-src="https://www.youtube.com/embed/yVucSRLLeIM?feature=oembed" title="TRAIN TO BUSAN PRESENTS: PENINSULA (2020) Official Teaser | Zombie Action Movie" width="640" height="360" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>



<p>The 2016 zombie thriller “Train to Busan” was met with universal critical acclaim and became one of the films that marked South Korea’s rise as a cinematic power. Peninsula, however, is another example of a sequel that doesn’t live up to the original.</p>



<p>“A sequel was inevitable, and despite some truly white-knuckle car chases and creative lighting, <em>Peninsula,</em> like many films that jump on the surprise hit bandwagon, proves lightning in a bottle happens only once,” the <a href="https://www.hollywoodreporter.com/news/peninsula-ban-do-film-review"><em>Hollywood Reporter</em></a> wrote.&nbsp;</p>



<p>Directed by Yeon Sang-ho, “Peninsula” shows people trying to escape the zombie-ridden South Korea of the first film. Captain Jung-Seok is unable to get his entire family out safely and, four years later, goes back to the country from the safe harbor of Hong Kong, to attempt to recover $20 million from a food truck. The captain dodges flesh-hungry zombies in their quest to find the money. Peninsula grossed <a href="https://www.boxofficemojo.com/title/tt8850222/?ref_=bo_se_r_1">$39.7 million</a> worldwide.&nbsp;</p>



<h2 id="miracle-in-cell-no">Miracle in Cell No. 7&nbsp;</h2>



<p><strong>From:</strong> Turkey<br><strong>Genre:</strong> Drama<br><strong>Release date: </strong>10/10/2019</p>



<figure><p>
<iframe data-src="https://www.youtube.com/embed/G2wPoBy2JQI?feature=oembed" title="Miracle in Cell No. 7 (Trailer- English subtitles) 2019 #MiracleInCell #Netflix #MiracleInCellNo7" width="640" height="360" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>



<p>This Turkish drama, directed by Mehmet Ada Öztekin, is a remake of the 2013 South Korean film of the same name. The story focuses on Memo, a disabled father, and his seven-year-old daughter, Ova. At the film’s <a href="https://www.goldenglobes.com/articles/miracle-cell-no7-turkey">outset</a>, Memo and Ova live with her grandmother, Fatma Ana, in a small Aegean town.&nbsp;</p>



<p>Memo, who works as a shepherd, is sentenced to death after being accused of murdering the garrison commander’s young daughter. He is sent to cell number 7, where he awaits his execution. The prisoners realize that Memo could not have committed the crime. Back home, Fatma Ana passes away. Ova, now alone, sets out on a quest to be reunited with her father.&nbsp;</p>



<p>“Miracle in Cell No. 7” was chosen as Turkey’s Oscar nominee for the 93rd Academy Awards and was the <a href="https://www.dailysabah.com/arts/cinema/what-makes-turkish-miracle-in-cell-no-7-a-popular-hit">most-watched</a> film in the country in 2019. By the end of the film, viewers are forced to reckon internally with their own perceptions of good and evil — and to take a long look at abuses of power and flaws within the justice system. The film grossed <a href="https://www.boxofficemojo.com/title/tt10431500/?ref_=bo_se_r_1">$17.2 million</a> at the box office worldwide.</p>



<h2 id="ip-man-4-the">Ip Man 4: The Finale</h2>



<p><strong>From:</strong> Hong Kong<br><strong>Genre:</strong> Action<br><strong>Release date: </strong>12/19/2019</p>



<figure><p>
<iframe data-src="https://www.youtube.com/embed/B3LzxNct3eA?feature=oembed" title="IP MAN 4: THE FINALE  Trailer (2019) Donnie Yen Action Movie" width="640" height="360" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>



<p>The final film in the saga of Bruce Lee’s martial arts master, “Ip Man 4” turns the lens on racism in the United States. In the film, which grossed <a href="https://www.boxofficemojo.com/title/tt2076298/?ref_=bo_se_r_1">$176 million</a> worldwide, fight scenes are used as a way to turn foreigners’ biases against them.</p>



<p>Mostly set in 1964 San Francisco, the film pits karate against kung fu — in the forms of a racist marine and Ip Man, a master of the Wing Chun school of the Chinese martial art, played again by Donnie Yen.</p>



<p>Yuen Woo-Ping, whose resume includes work on “Crouching Tiger, Hidden Dragon” and “The Matrix” films, stages fights that <a href="https://www.nytimes.com/2019/12/24/movies/ip-man-4-the-finale-review.html"><em>The New York Times</em></a> deemed “thrilling” and full of “fluttering limbs in action.”&nbsp;</p>



<p>Its imagery is “bathed in a mid-century wash that makes the film look like it came from an ad in <em>Life</em> magazine,” <a href="https://www.hollywoodreporter.com/review/ip-man-4-finale-1264391"><em>The Hollywood Reporter</em></a> wrote. The film’s signature scene involves a teacup, a revolving circular glass table, and two people who won’t back down.&nbsp;</p>



<h2 id="parasitenbsp">Parasite&nbsp;</h2>



<p><strong>From:</strong> South Korea<br><strong>Genre:</strong> Thriller<br><strong>Release date:</strong> 5/30/2019</p>



<figure><p>
<iframe data-src="https://www.youtube.com/embed/isOGD_7hNIY?feature=oembed" title="Parasite [Official Trailer] – In Theaters October 11, 2019" width="640" height="360" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>



<p>The most pirated film last year shouldn’t be a surprise: as the first foreign-language film to win the Academy Award for best picture, it’s none other than “Parasite.”&nbsp;</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://restofworld.org/2021/the-ten-most-pirated-international-movies-2020/">https://restofworld.org/2021/the-ten-most-pirated-international-movies-2020/</a></em></p>]]>
            </description>
            <link>https://restofworld.org/2021/the-ten-most-pirated-international-movies-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25858996</guid>
            <pubDate>Thu, 21 Jan 2021 14:16:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Angry at Big Tech? Wait the Other Shoe Has Not Dropped (Worse Things Coming)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25858280">thread link</a>) | @chovybizzass
<br/>
January 21, 2021 | https://odysee.com/@RobBraxmanTech:6/Big-Tech--The-Other-Shoe-has-not-Dropped!-(Worse-Things-Coming):0 | <a href="https://web.archive.org/web/*/https://odysee.com/@RobBraxmanTech:6/Big-Tech--The-Other-Shoe-has-not-Dropped!-(Worse-Things-Coming):0">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://odysee.com/@RobBraxmanTech:6/Big-Tech--The-Other-Shoe-has-not-Dropped!-(Worse-Things-Coming):0</link>
            <guid isPermaLink="false">hacker-news-small-sites-25858280</guid>
            <pubDate>Thu, 21 Jan 2021 12:47:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[‘How can $24B in tethers move a $650B Bitcoin market cap?’]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25858157">thread link</a>) | @Bluestein
<br/>
January 21, 2021 | https://amycastor.com/2021/01/20/how-can-24b-in-tethers-move-a-650b-bitcoin-market-cap-and-other-mathematically-illiterate-questions/ | <a href="https://web.archive.org/web/*/https://amycastor.com/2021/01/20/how-can-24b-in-tethers-move-a-650b-bitcoin-market-cap-and-other-mathematically-illiterate-questions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-5541">
		<div>
		
<p>A question, or some version of it, that keeps popping up on social media lately is, “How can $24 billion worth of tethers move a $650 billion bitcoin market cap?” </p>



<p>This is “a blitheringly stupid question on multiple levels, starting with basic arithmetic,” bitcoin hater David Gerard <a href="https://twitter.com/davidgerard/status/1351497484091224065">said on Twitter</a>. “It’s also a perennial dumb question.”</p>



<p>The question is being put forth by bitcoiners in an attempt to put people’s minds at ease about Tether. The thesis is that if tethers were to vanish—something that could happen if the U.S. Department of Justice were to give Tether <a href="https://www.justice.gov/usao-sdny/pr/manhattan-us-attorney-announces-charges-against-liberty-reserve-one-world-s-largest">the Liberty Reserve treatment</a>—it would have little impact on bitcoin’s price, so you should stop worrying and keep buying bitcoin.</p>



<p>Someone posed the query recently on <a href="https://www.reddit.com/r/Buttcoin/comments/kxpr4k/genuinely_curious_how_does_tether_pump_btc_when/">r/buttcoin.</a> I am going to take a stab at sensibly answering the question in three parts starting with, What is market cap?</p>



<figure><div>
<div><blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">Yeah exactly – Tether is $24.5b, Bitcoin's market cap alone is $696b. Even if Tether somehow had $0 of the $24.5b it wouldn't cause Bitcoin to drop to $0.</p>— Riccardo Spagni (@fluffypony) <a href="https://twitter.com/fluffypony/status/1350473644233916416?ref_src=twsrc%5Etfw">January 16, 2021</a></blockquote></div>
</div></figure>



<h2>1. Market cap is meaningless nonsense</h2>



<p>Market cap is a nonsensical number when it comes to bitcoin. It’s calculated by multiplying the last transaction price of bitcoin by the number of bitcoins in circulation—currently $35,000 x 18.6 million. </p>



<p>That doesn’t mean that people bought every bitcoin in existence for that price. The vast majority of people who own bitcoin bought it at a far lower price than what it is today. It also doesn’t mean that if everyone suddenly decided to sell all of their bitcoins, each bitcoin would bring them $35,000. </p>



<p>In fact, it doesn’t mean that bitcoin has any value at all other than the hope that some bigger dummy will stroll along who is willing to pay more for it than you did. Bitcoiners like to imagine that bitcoins are valuable because there will only ever be 21 million of them. That makes them scarce. </p>



<p>Beanie Babies were scarce in the 90s, too, with some fetching upwards thousands of dollars on eBay. But by the end of the Beanie Baby bubble, no amount of scarcity could make them desirable. They became worthless</p>



<p>Market cap is just another way to make something that is worthless appear valuable. </p>



<p>Market cap came out of the traditional finance world. And then websites like <a href="https://coinmarketcap.com/">CoinMarketCap</a> came along and began applying the term to bitcoin. In the stock market, market capitalization refers to the total value of a company’s share of stock. But while companies have an intrinsic value, bitcoin does not. There is nothing behind bitcoin. It’s not a company. It is not a thing. It is simply a number in a database. </p>



<p>Here is an example of how silly market cap is when applied to crypto. Say I create 1 million CastorCoins and start listing them on some little-known offshore exchange for $1. Suddenly CastorCoin has a market cap of $1 million dollars. Does that mean I have a million dollars? No, it does not.&nbsp;</p>



<p>Or, as u/Ifinallycracked <a href="https://www.reddit.com/r/Buttcoin/comments/kxpr4k/genuinely_curious_how_does_tether_pump_btc_when/gjbrjrj/?context=3">puts it on r/buttcoin</a>: “If a bog roll contains 100 sheets and I manage to sell one sheet for a dollar, that doesn’t make it a $100 bog roll. Apply same logic to Bitscoin market cap. Success.”</p>



<p>Once you grasp that the bitcoin market cap does not mean that people have spent $650 billion on bitcoin, $24 billion worth of tethers—which represents 0.03% of the total bitcoin market cap—becomes a lot more significant.</p>



<figure><div>
<div><blockquote data-width="550" data-dnt="true"><div lang="en" dir="ltr"><p>"I issue a million shares and keep all but one. I get a sucker to pay $1 for that one share. I am now a millionaire."</p><p>Extreme exaggeration works well sometimes, except when it doesn't and they come back with "yeah but Bitcoin isn't a two person market", in which case I just quit</p></div>— Richter's Bidding (@siregnier) <a href="https://twitter.com/siregnier/status/1351501048599486466?ref_src=twsrc%5Etfw">January 19, 2021</a></blockquote></div>
</div></figure>



<h2>2. Price is determined at the margins</h2>



<p>The price of bitcoin is determined at the margins. If you want to drive up the price of bitcoin, you don’t have to buy every single bitcoin at the current price level. You simply have to scoop up the ones that are for sale.&nbsp;</p>



<p>Money flowing into bitcoin is what keeps the price afloat. If demand increases and people are willing to pay more for bitcoin, that pushes the price up. The more dollars people throw at it, the higher BTC will go. And it doesn’t matter if you are buying bitcoin with real dollars on a banked exchange like Coinbase—or fake dollars on an offshore exchange like Binance, Huobi, or Bitfinex.   </p>



<div><figure><a href="https://amyhcastor.files.wordpress.com/2021/01/screen-shot-2021-01-19-at-7.27.04-pm.png"><img loading="lazy" data-attachment-id="5556" data-permalink="https://amycastor.com/screen-shot-2021-01-19-at-7-27-04-pm/" data-orig-file="https://amyhcastor.files.wordpress.com/2021/01/screen-shot-2021-01-19-at-7.27.04-pm.png" data-orig-size="902,628" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screen-shot-2021-01-19-at-7.27.04-pm" data-image-description="" data-medium-file="https://amyhcastor.files.wordpress.com/2021/01/screen-shot-2021-01-19-at-7.27.04-pm.png?w=300" data-large-file="https://amyhcastor.files.wordpress.com/2021/01/screen-shot-2021-01-19-at-7.27.04-pm.png?w=902" src="https://amyhcastor.files.wordpress.com/2021/01/screen-shot-2021-01-19-at-7.27.04-pm.png?w=902" alt="" width="294" height="204" srcset="https://amyhcastor.files.wordpress.com/2021/01/screen-shot-2021-01-19-at-7.27.04-pm.png?w=294 294w, https://amyhcastor.files.wordpress.com/2021/01/screen-shot-2021-01-19-at-7.27.04-pm.png?w=586 586w, https://amyhcastor.files.wordpress.com/2021/01/screen-shot-2021-01-19-at-7.27.04-pm.png?w=150 150w, https://amyhcastor.files.wordpress.com/2021/01/screen-shot-2021-01-19-at-7.27.04-pm.png?w=300 300w" sizes="(max-width: 294px) 100vw, 294px"></a><figcaption>Image: CoinCompare</figcaption></figure></div>



<p>Right now, the latter is more prevalent—there are far more tethers flowing into bitcoin than actual dollars. In fact, 55% of all bitcoin is currently traded against tethers while only about 15% trade against real dollars, according to <a href="https://www.cryptocompare.com/coins/btc/analysis/USDT">CoinCompare.</a> </p>



<p>This is what makes the current bitcoin bubble different than the last. In 2017, when the price of bitcoin ran up to nearly $20,000, there were a lot more real dollars in the system and only 1.5 billion tethers in circulation. Now, it’s mostly tethers pushing up the price of BTC.</p>



<figure><div>
<div><blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">If I made 1B DavidCoins and got them listed on an exchange, then had a friend buy the first DavidCoin for $1, then with only $1 of trade volume I would move the DavidCoin market cap from $0 to $1B. Pretty neat trick!</p>— David (@freeAgent85) <a href="https://twitter.com/freeAgent85/status/1351529387187867648?ref_src=twsrc%5Etfw">January 19, 2021</a></blockquote></div>
</div></figure>



<h2>3. Bitcoin is illiquid</h2>



<p>Bitcoin is relatively illiquid. According to <a href="https://insights.glassnode.com/bitcoin-liquid-supply/">data from Glassnodes</a>, 78% of all bitcoin are not moving. In other words, of the 18.6 million bitcoins currently in existence, only about 4.2 million are in constant circulation. </p>



<p>At least 3 million bitcoin are lost because people like <a href="https://www.nytimes.com/2021/01/12/technology/bitcoin-passwords-wallets-fortunes.html">this guy</a> can’t find their keys. (Just because you are the former CTO of Ripple, that doesn’t make you clever when it comes to safekeeping bitcoin.) And there are still plenty of folks holding on to their BTC in the hopes it will go stratospheric. Strong hands!</p>



<p>As a result, it doesn’t take a large buy or sell request to move the price of bitcoin. Printing billions of dollars out of thin air and using it to put supply-side pressure on a market as thin as bitcoin forces the prices up. Conversely, if enough people were to get panicky and rush to sell their bitcoin—<a href="https://www.reddit.com/r/CryptoCurrency/comments/7d1da0/definition_of_weak_hand/">weak hands!</a>—the results could be catastrophic. Literally, the entire market cap can go to zero in a moment.  </p>



<p>The whole point of Tether is to push up the price of bitcoin and other cryptocurrencies, and then move those assets to OTC desks and banked exchanges, where they can be turned into fiat. As <a href="https://twitter.com/baskee/status/1351498416799567873">@Baskee</a> puts it: “Tether is a ladle; Bitcoin and USD are ashes and bullet casings, respectively.”</p>



<figure><div>
<div><blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">Tether is a ladle; Bitcoin and USD are ashes and bullet casings, respectively.</p>— baskee (@baskee) <a href="https://twitter.com/baskee/status/1351498416799567873?ref_src=twsrc%5Etfw">January 19, 2021</a></blockquote></div>
</div></figure>



<p><em>You can support my work by subscribing to my&nbsp;<a rel="noreferrer noopener" href="https://www.patreon.com/amycastor" target="_blank">Patreon account</a>. Think of it as buying me a cup of coffee, a bottle of wine, or a case of wine once a month, depending on what level you subscribe to.&nbsp;&nbsp;</em></p>
			</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://amycastor.com/2021/01/20/how-can-24b-in-tethers-move-a-650b-bitcoin-market-cap-and-other-mathematically-illiterate-questions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25858157</guid>
            <pubDate>Thu, 21 Jan 2021 12:24:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[3D pic of paint 'Girl with Pearl Earring' with 10Bs of pixels]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25858000">thread link</a>) | @giuliomagnifico
<br/>
January 21, 2021 | http://hirox-europe.com/PEARL/3D/ | <a href="https://web.archive.org/web/*/http://hirox-europe.com/PEARL/3D/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://hirox-europe.com/PEARL/3D/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25858000</guid>
            <pubDate>Thu, 21 Jan 2021 11:59:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bitcoin Is a Ponzi]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 22 (<a href="https://news.ycombinator.com/item?id=25857924">thread link</a>) | @geraldbauer
<br/>
January 21, 2021 | https://openblockchains.github.io/bitcoin-ponzi | <a href="https://web.archive.org/web/*/https://openblockchains.github.io/bitcoin-ponzi">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

      

<blockquote>
  <p>SEC Investor Education:</p>

  <p>New Year’s Financial Resolution: Avoid too-good-to-be-true “investments” with Ponzi scheme “red flag” claims like:</p>

  <ul>
    <li>“To the moon! To the mars!”</li>
    <li>“Number go up!”</li>
    <li>“Yearly return of 300+% in 2020!”</li>
    <li>“Could quadruple in 2021 and rally to $100,000!”</li>
  </ul>
</blockquote>

<p>A collection of “unpopular opinion” and get-rich-quick party spoiler “stop the music” articles on “Is Bitcoin a Ponzi? Is Bitcoin a Speculative Bubble? Is Bitcoin a Digital 21st Century Tulip Mania? Is Bitcoin Comedy Gold?”</p>

<p>From the Wikipedia:</p>

<p>Bitcoin has been described as an economic bubble by at least eight Nobel Prize Economists at various times, including Robert Shiller on 1 March 2014, Joseph Stiglitz on 29 November 2017, and Richard Thaler on 21 December 2017. On 29 January 2018, a noted Keynesian economist Paul Krugman has described bitcoin as “a bubble wrapped in techno-mysticism inside a cocoon of libertarian ideology”, on 2 February 2018, professor Nouriel Roubini of New York University has called bitcoin the “mother of all bubbles”, and on 27 April 2018, a University of Chicago economist James Heckman has compared it to the 17th-century tulip mania.</p>

<p>On 4 December 2013, Alan Greenspan referred to it as a “bubble” as did George Soros on 25 January 2018. Warren Buffett called bitcoin a “mirage” on 13 March 2014.</p>

<p>§</p>

<p>Some “unpopular” bitcoin facts:</p>

<ul>
  <li>Bitcoin Proof-of-Waste Mining Is an Environmental Disaster</li>
  <li>Bitcon Is a Greater Fool BagHODLer Zero-Sum Fraudsters’ Greed Fest</li>
  <li>The Bigger the Lies the Better - To the Moon! Number Go Up! Will Quadruple to $100 000 in 2021!</li>
  <li>Bitcoin Is Comedy Gold - Bitcoin Is the New Standard?! - LOL</li>
  <li>When Will the Music Stop? (Hint: Try to Cash Out)</li>
</ul>

<p>So what!?  Do your own research! Here we go:</p>

<p><strong>SCAM ALERT! SCAM ALERT! SCAM ALERT!</strong></p>

<h3 id="tyler-winklevoss-bitcoin-billionaire">Tyler Winklevoss, Bitcoin Billionaire</h3>

<blockquote>
  <p>Washington Post News:</p>

  <p>Bitcoin surges past $20 000 for first time.</p>
</blockquote>

<p>This Bitcoin rally is the most sophisticated investors, the smartest people in the room, buying the bitcoin quietly. Number go up! To the moon!</p>

<p>§</p>

<p>When Elon Musk puts the Tesla balance sheet into Bitcoin, we’ll have to change the Bitcoin rallying cry from “to the moon!” to “to Mars!”</p>

<blockquote>
  <p>Austrian Maximalist comments: Let’s use solar energy to mine bitcoin with
 satellites in space!</p>
</blockquote>

<p>§</p>

<p>The U.S. Dollar is no longer a reliable store of value. Cameron and I (Winklevoss Twins Capital) make the case for $500 000 Bitcoin. Number go up! To the moon!</p>

<h3 id="cameron-winklevoss-bitcoin-billionaire">Cameron Winklevoss, Bitcoin Billionaire</h3>

<p>There are 3.5 billion smart phones on the planet. All of them can hold bitcoin. None of them can hold gold. Bitcoin is the future. Number go up! To the moon!</p>

<h3 id="michael-saylor-business-intelligence-billionaire">Michael Saylor, Business Intelligence Billionaire</h3>

<p>Money is energy. Bitcoin is the first crypto monetary energy network, capable of collecting all the world’s liquid energy, storing it over time without power loss, and channeling it across space with negligible impedance. Number go up! To the moon!</p>

<blockquote>
  <p>Austrian Maximalist comments: And it’s all represented in this: 21,000,000.00000000</p>
</blockquote>

<blockquote>
  <p>Austrian Physicist comments: The science on this is legit respecting the laws of thermodynamics.</p>
</blockquote>

<h3 id="anthony-pompliano-bitcoin-cheerleader-off-the-chain-investment-newsletter-writer-100-000-subscribers">Anthony Pompliano, Bitcoin Cheerleader, Off The Chain Investment Newsletter Writer (100 000+ Subscribers)</h3>

<p>There are an increasing number of buyers, yet a decreasing amount of available Bitcoin.</p>

<p>Any economics 101 student can predict what happens next. To the moon! Number go up!</p>

<h3 id="bitcoiner-btc-greater-fool-investor">Bitcoiner (BTC), Greater Fool Investor</h3>

<p>WOO NUMBER GO UP!!!</p>

<p>Who needs adoption when you can have institutional investors!
Why bank the unbanked when you can bank the banks!
Bring out the champaign because NUMBER GO UP!!!</p>

<p>Am I price posting right?</p>

<h3 id="dan-mcardle--bitcoin-there-is-no-alternative-bitcoin-is-the-new-gold-standard">Dan McArdle,  Bitcoin “There is No Alternative”, Bitcoin is the New (Gold) Standard</h3>

<p>Bitcoin will save the environment. 
Bitcoin will create a global arbitrage in energy.</p>

<p>Bitcoin will drive innovation in energy and use of renewables.</p>

<p>§</p>

<p>Bitcoin number go up because more people want bitcoin.
Bitcoin becomes more and more valuable.</p>

<ul>
  <li>1,000 HODLers</li>
  <li>10,000 HODLers</li>
  <li>100,000 HODLers</li>
  <li>1,000,000 HODLers</li>
  <li>10,000,000 HODLers</li>
  <li>100,000,000 HODLers</li>
  <li>1,000,000,000 HODLers</li>
  <li>10,000,000,000 HODLers</li>
  <li>100,000,000,000 HODLers and on and on</li>
</ul>

<p>People will come to understand bitcon.</p>

<hr>

<p>Comedy Gold?  Let’s get real:</p>

<h2 id="2021">2021</h2>

<p><a href="https://amycastor.com/2021/01/20/how-can-24b-in-tethers-move-a-650b-bitcoin-market-cap-and-other-mathematically-illiterate-questions/"><strong>‘How can $24B in tethers move a $650B Bitcoin market cap?’ and other mathematically illiterate question</strong></a> by Amy Castor, Blockchain Journalist</p>

<p><a href="https://www.ic.unicamp.br/~stolfi/bitcoin/2020-12-31-bitcoin-ponzi.html"><strong>Why Bitcoin is a Ponzi: A Type of Investment Fraud with Five Features</strong></a>
by Jorge Stolfi, Computer Sciencist, State University of Campinas, Brazil</p>

<p><a href="http://www.tr0lly.com/uncategorized/tether-heads-i-win-tails-you-lose/"><strong>Tether: Heads I Win, Tails You Lose</strong></a>  by Trolly McTrollface</p>

<p><a href="http://www.tr0lly.com/bitcoin/the-tether-press-and-bitcoins-speculative-mania/"><strong>The Tether Press and Bitcoin’s Speculative Mania</strong></a>
by Trolly McTrollface</p>

<p><a href="http://usatoday.com/story/money/columnist/2021/01/10/investors-cryptocurrency-bitcoin/43312105/"><strong>“I don’t believe bitcoin is unique in any way”: Why investors should be careful with this cryptocurrency</strong></a> by Sean Williams, Investment Advisor, The Motley Fool</p>

<p><a href="https://crypto-anonymous-2021.medium.com/the-bit-short-inside-cryptos-doomsday-machine-f8dcf78a64d3"><strong>The Bit Short: Inside Crypto’s Doomsday Machine</strong></a> by Crypto Anonymous</p>

<h2 id="2020">2020</h2>

<p><a href="http://www.tr0lly.com/bitcoin/bitcoin-is-not-a-literal-ponzi-scheme/"><strong>Bitcoin is not a literal Ponzi scheme</strong></a> by Trolly McTrollface</p>

<h2 id="2019">2019</h2>

<p><a href="https://www.kalzumeus.com/2019/10/28/tether-and-bitfinex/"><strong>Tether: The Story So Far</strong></a> by Patrick McKenzie, Recovering Japanese Salaryman</p>

<p><a href="https://arstechnica.com/information-technology/2019/02/researcher-counts-the-reasons-he-wants-cryptocurrency-burned-with-fire/"><strong>Up in Flames: Bitcoin and other digital coins recapitulate 500 years of failure</strong></a> by Nicholas Weaver, Computer Scientist, University of California, Berkley, United States</p>

<p><a href="https://www.wired.com/story/theres-no-good-reason-to-trust-blockchain-technology/"><strong>There’s No Good Reason to Trust Blockchain Technology</strong></a> by Bruce Schneier, Cryptography Researcher</p>

<h2 id="2018">2018</h2>

<p><a href="https://www.forbes.com/sites/francescoppola/2018/12/30/bitcoin-maximalists-impossible-dream/"><strong>Bitcoin Maximalists’ Impossible Dream</strong></a> by Frances Coppola, Finance Journalist</p>

<p><a href="https://www.economist.com/leaders/2018/08/30/bitcoin-and-other-cryptocurrencies-are-useless"><strong>Bitcoin and other cryptocurrencies are useless</strong></a>, The Economist</p>

<p><a href="https://www.theguardian.com/business/2018/mar/05/bitcoin-is-based-on-the-blockchain-pipe-dream"><strong>Bitcoin is based on the blockchain pipe dream</strong></a> by Nouriel Roubini, Economist and Preston Byrne, Blockchain Attorney</p>

<p><a href="https://www.project-syndicate.org/commentary/blockchain-big-lie-by-nouriel-roubini-2018-10"><strong>The Big Blockchain Lie</strong></a> by Nouriel Roubini, Economist</p>

<p><a href="https://bitsblocks.github.io/crypto-bubbles"><strong>Crypto is the Mother of All Scams and (Now Busted) Bubbles - While Blockchain Is The Most Over-Hyped Technology Ever, No Better than a Spreadsheet/Database</strong></a> by Nouriel Roubini, Economist</p>

<p><a href="https://bitsblocks.github.io/crypto-facts"><strong>Crypto Facts - Decentralize Payments - Efficient, Low Cost, Fair, Clean - True or False?</strong></a> by Nouriel Roubini, Economist</p>

<p><a href="https://bitsblocks.github.io/bitcoin-maximalist"><strong>Best of Bitcoin Maximalist - Scammers, Morons, Clowns, Shills &amp; BagHODLers - Inside The New New Crypto Ponzi Economics</strong></a> by Trolly McTrollface</p>

<p><a href="https://www.seattletimes.com/opinion/bitcoin-is-basically-a-ponzi-scheme/"><strong>Bitcoin is basically a ponzi scheme</strong></a>
by Paul Krugman, Economist</p>

<p><a href="https://www.economist.com/buttonwoods-notebook/2017/11/01/the-bitcoin-bubble"><strong>Greater fool theory - The bitcoin bubble</strong></a>, The Economist</p>

<p><a href="https://www.vox.com/2018/4/24/17275202/bitcoin-scam-cryptocurrency-mining-pump-dump-fraud-ico-value"><strong>Bitcoin is the greatest scam in history</strong></a> by Bill Harris, Founding CEO, PayPal and Personal Capital</p>

<p><a href="https://davidgerard.co.uk/blockchain/2018/01/04/why-you-cant-cash-out-pt-3-bitcoin-is-not-a-ponzi-scheme-it-just-works-like-one/"><strong>Why you can’t cash out: Bitcoin is not a Ponzi scheme! It just works like one</strong></a> by David Gerard, Blockchain Journalist</p>

<h2 id="2017">2017</h2>

<p><a href="https://prestonbyrne.com/2017/12/08/bitcoin_ponzi/"><strong>The Problem with Calling Bitcoin a “Ponzi Scheme”</strong></a> by Preston Byrne, Blockchain Attorney</p>

<p><a href="https://davidgerard.co.uk/blockchain/table-of-contents/"><strong>Attack of the 50 Foot Blockchain</strong></a> by David Gerard, Blockchain Journalist</p>

<h2 id="2016">2016</h2>

<p><a href="https://tonyarcieri.com/on-the-dangers-of-a-blockchain-monoculture"><strong>On the dangers of a blockchain monoculture</strong></a> by Tony Arcieri, Blockchain Programmer</p>

<h2 id="2015">2015</h2>

<p><a href="https://tonyarcieri.com/the-death-of-bitcoin"><strong>The Death of Bitcoin</strong></a> by Tony Arcieri, Blockchain Programmer</p>

<h2 id="1776">1776</h2>

<p><a href="https://github.com/openblockchains/crypto-books/tree/master/The_Wealth_of_Nations"><strong>HODLing Gold? Gengis Khan is HODLing Sheep and Oxen: Inside the True Nature and Causes of the Wealth of Nations</strong></a> by Adam Smith, Old School Economist</p>

<hr>

<p>Found another Bitcoin ponzi article? Tell us!</p>

<p>Contributions welcome! Just send pull requests.</p>

<hr>

<p>Why?  This Bitcoin Is a Ponzi page is inspired
by the <a href="https://99bitcoins.com/bitcoin-obituaries/">Bitcoin Obituaries: Bitcoin Declared Dead 350+ Times</a> page.</p>

<p>Austrian Maximalist comments: Can I ask, when will you admit you were wrong? $50 000 bitcoin? $100 000 bitcoin? $500 000 bitcoin?</p>



      
      
      
    </div></div>]]>
            </description>
            <link>https://openblockchains.github.io/bitcoin-ponzi</link>
            <guid isPermaLink="false">hacker-news-small-sites-25857924</guid>
            <pubDate>Thu, 21 Jan 2021 11:48:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Most surgeries are ineffective]]>
            </title>
            <description>
<![CDATA[
Score 57 | Comments 32 (<a href="https://news.ycombinator.com/item?id=25857435">thread link</a>) | @pvsukale3
<br/>
January 21, 2021 | https://invertedpassion.com/most-surgeries-are-ineffective/ | <a href="https://web.archive.org/web/*/https://invertedpassion.com/most-surgeries-are-ineffective/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1496">
		<!-- .entry-header -->
	<div>
		
		
<p>Do surgeries work? Most of us assume they do, but is there any scientific evidence that they do?</p>

<p>In this episode, I talk to <a href="https://twitter.com/drianharris">Dr Ian Harris</a> who is a Professor of Orthopaedic Surgery at the University of New South Wales in Australia. He is a practicing orthopedic surgeon specializing in trauma surgery. Outside his practice, his research interests broadly cover the topic of surgical effectiveness and clinical research.</p>

<figure>
<p>
<iframe title="#2 Ian Harris - Most surgeries are ineffective" width="780" height="439" src="https://www.youtube.com/embed/jCG3tzgGV2A?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>
</figure>

<h3>What we talk about</h3>

<p><strong>1:38</strong> – Science as a way of knowing things<br><strong>9:15</strong> –&nbsp;Why medical professionals refuse to believe scientific evidence?<br><strong>15:05 </strong>– What is a<strong> </strong>placebo?<br><strong>19:16</strong> – How strong is the placebo effect in surgeries?<br><strong>22:05</strong> – History of bloodletting in medicine and how we stopped this practice<br><strong>24:31</strong> – The myths of knee surgery<br><strong>28:26</strong> – Why doctors need to be held accountable<br><strong>32:26</strong> – Why are there no regulatory authorities in surgery like there are in new medicine?<br><strong>35:14</strong> – Latest studies on why half of the surgeries are ineffective<br><strong>41:00</strong> – Need for randomized trials for discovering which surgeries actually work<br><strong>44:48</strong> – Why is surgery the ultimate placebo?<br><strong>47:12</strong> – How much effort does it take to do a meta-analysis or a systematic review?<br><strong>47:29</strong> – How to improve meta-reviews via living systematic reviews<br><strong>49:54</strong> – What should you be asking your doctor if you are recommended a surgery?</p>

<h3>Dive into Dr Ian Harris’ research</h3>

<ul>
<li><a href="https://www.goodreads.com/book/show/28592661-surgery-the-ultimate-placebo">Book</a></li>
<li><a href="https://www.youtube.com/watch?v=IzueFu1cq5U">Lecture</a></li>
<li><a href="https://scholar.google.com/citations?user=HSd2K4IAAAAJ&amp;hl=en&amp;oi=ao">Papers</a></li>
<li><a href="https://www.bmj.com/content/348/bmj.g3253">Relevant paper</a> backing the claim that most surgeries are ineffective</li>
</ul>

<h3>Notes and key insights</h3>

<p>1/ <strong>What is a placebo surgery?</strong> It’s where you make an incision but not do anything. </p>

<p>It’s analogous to traditional placebo in medicine, where a sugar or salt pill is given instead of an active chemical to see whether the intended medicine has an actual impact.</p>

<p>2/ <strong>Majority of surgeries that Dr Ian Harris and other researchers have studied in fact are not more effective than placebos</strong>. This is shocking because even when we have no proof that they work, many of these surgeries are happening even today.</p>

<p>3/ <strong>Examples of such ineffective surgeries include back pain surgeries and knee pain surgeries.</strong> For such surgeries, randomized control trials have found that if you make an incision in the knee but don’t do anything, it’s as effective as actually conducting the surgery of the knee.</p>

<p>4/ Why do patients get better if the surgery doesn’t work? It’s because<strong> many diseases or pain have a natural progression</strong>, and we generally seek surgical/medicinal intervention when we’re in the worst condition. If the body heals / condition becomes better after that, we attribute improvement to the intervention rather than thinking it could have happened anyway (due to the natural course of the condition).</p>

<p>5/ As Dr Ian Harris said, the unsaid attitude could be stated like: “<strong>you have to operate on patients quickly before they get better</strong>“.</p>

<p>Remember: in many cases, if you get sick, you get better after that. And that is why placebos seem to work.</p>

<p>6/ It’s shocking to hear that randomized controlled trials (RCT) for many surgical interventions end up finding that they’re ineffective.</p>

<p>But what’s most shocking is that <strong>many other interventions have never been subjected to an RCT against a placebo</strong>. For many of the common procedures traditionally practiced, we don’t know whether they work at all or not.</p>

<p>7/ For sure, there are many studies that study variations of surgical methods. That is, they try to find out whether an incision from the left is better or from the right. </p>

<p>But very few studies try to find out whether the incision does anything at all for the patient. Shocking, but that’s the truth.</p>

<p>8/ In that sense, <strong>surgery is different than medicine</strong>. All new pharmaceutical molecules are subjected to rigorous clinical trials where they’re tested against placebo or doing nothing. In many countries, there’s no such procedure for surgical treatments. If there is a procedure for new surgical procedures, nobody is testing old ones that have been getting performed every day without evidence.</p>

<p>8/ If research indicates many of the currently practiced surgeries don’t work, why are they still practiced?</p>

<p>Well, <strong>if your salary depends on not believing something, you won’t believe it.</strong></p>

<p>9/ And such <strong>denial is not new</strong>. The most common surgical procedure in history was bloodletting. This practice which lasted for thousands of years was only questioned in mid 19th century, and even after randomized trials showed that it hurt the patient, it wasn’t abandoned suddenly. It died a slow death as its practitioners started dying. </p>

<p>10/ Even today, the fact that practices like Homeopathy survive suggests that <strong>seeking evidence of what works isn’t a big priority for society</strong>. Perhaps keeping traditions is a bigger priority.</p>

<p>11/ But because it’s costly and risky to perform surgeries, the urgent question is: <strong>what surgical procedures are today’s equivalent of bloodletting</strong>? And those that we know are bloodletting, how do we get rid of them as a society?</p>

<p>12/ As a patient, what should you do? Dr Ian Harris recommends that every time your doctor recommends a medical procedure, <strong>ALWAYS ask for risks and benefits</strong>. </p>

<p>Risks are a given and doctors generally are happy to talk about them. But nobody asks for benefits because they’re assumed to be there. </p>

<p>Ask and confirm about benefits explicitly.</p>

<p>13/ What if the pain isn’t going away at all? Should you then get surgery?</p>

<p>Golden advice by Dr Ian -&gt;  “<strong>the severity of your symptoms does not change the effectiveness of the operation</strong>“</p>

<p><a href="https://twitter.com/paraschopra" data-show-count="true">Follow @paraschopra</a></p>
<p><span><strong>Have an opinion on this essay?</strong></span> You can send your feedback on <a href="https://invertedpassion.com/cdn-cgi/l/email-protection#bdcddccfdcce8c84858a96d4cddbd8d8d9dfdcded6fddad0dcd4d193ded2d0">email</a> to me.</p>





			</div><!-- .entry-content -->
						<!-- .entry-footer -->
		</article></div>]]>
            </description>
            <link>https://invertedpassion.com/most-surgeries-are-ineffective/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25857435</guid>
            <pubDate>Thu, 21 Jan 2021 10:26:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Intro to securing communication protocols with Noise]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25857422">thread link</a>) | @grundprinzip
<br/>
January 21, 2021 | https://grund.me/posts/securing-custom-protocols-with-noise/ | <a href="https://web.archive.org/web/*/https://grund.me/posts/securing-custom-protocols-with-noise/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
      <p>In the world of backend services, it’s of utmost importance to provide secure
communication channels. Traditionally, in services like those provided by
Amazon, Microsoft, or Google, the outside-accessible interface is provided via an
HTTPS endpoint and hopefully, the TLS connection is configured to only allow
secure cipher suites and provide the proper certificates.</p>
<p>In my time doing security reviews with teams across different parts of AWS
services, I’ve seen that it’s easy for teams to follow standard guidelines on
how to secure the customer surface, but it becomes harder to have the right
security and confidentiality properties in loosely coupled internal services. Of
course, guidelines exist as well and teams follow them very well. But behind the
APIs is where the business logic is implemented and the services need to scale.
Here is where the ingenuity of the engineers is required to come up with scalable
architectures and efficient solutions. In many cases, this will require some kind
of communication between service components. Not in all cases TLS is the
solution to everything.</p>
<h2 id="background">Background</h2>
<p>The last time I was dealing with such a scenario, we had the following setup.
Multiple parties were communicating through a routing proxy. The
proxy was providing basic infrastructure routing capability and very limited
protocol inspection. The endpoints were loosely coupled and needed end-to-end
security and integrity.</p>
<figure>
    <img src="https://grund.me/proxy_with_routing.png"> <figcaption>
            <h4>Simple Proxy Connection</h4>
        </figcaption>
</figure>

<p>There were multiple alternatives for end-to-end encryption like nesting TLS
connections through the proxy, using symmetric or asymmetric keys to protect the
payloads for example. None of these approaches felt elegant and scalable.</p>
<p>In this context, I started looking at how TLS works under the hood and how it
provides the necessary security properties. Here, I learned about Diffie-Hellman
key-exchanges and how this is embedded into TLS. Using the low-level OppenSSL
functions I was able to quickly draw up a protocol that builds upon DH key
exchanges using ephemeral and static public keys and I was happy.</p>
<p>The downside of this approach however was that it was quite some ugly code using
OpenSSL, there was no guarantee this was working exactly like this across
programming languages and there was some desire to not have to “roll our own
crypto”. The idea was abandoned at this point and replaced with something
readily available, but a less fitting approach to the problem.</p>
<p>A couple of months down the road I came across
<a href="https://noiseprotocol.org/">Noise</a>, a protocol framework for building secure
protocols based on DH key exchanges, designed to make it very hard to mess up
the communication challenge.</p>
<h2 id="the-noise-protocol-framework">The Noise Protocol Framework</h2>
<p>Initially, I thought, well this might be interesting but did not look too much
into it. But browsing through the specification, I liked the simplicity
of the approach and continued reading. Essentially, Noise is built upon
handshake patterns that are used to establish the secure communication challenge.
Different elements of the patterns can be combined according to the scenario.
Then it struck me when looking at the following handshake pattern:</p>
<pre><code>KK:
     -&gt; s
     &lt;- s
     ...
     -&gt; e, es, ss
     &lt;- e, ee, se
</code></pre><p>In <code>Noise</code>-speak, this means that two parties (Alice to Bob) communicate and
implement the protocol with the following agreed-upon handshake. The <code>KK</code>
pattern representing a scenario where the two parties have previously exchanged
their public keys. To initiate the communication, Alice executes a series of
steps, basically a series of DH and key-derivation steps, that is mirrored by
Bob. Bob then returns a message with keys derived similarly.</p>
<p>The cool thing is, that this particular pattern was very similar to
the protocol that I came up with in my project, but much more thought-through
and secure because of additional encryption with authenticated data.</p>
<p>And I even found a confirmation why this approach would have been very
beneficial in our case:</p>
<ol>
<li>0-RTT Encryption (0 roundtrip encryption) - communication can directly start
with the first message since all components a known ahead of time. In this
case the public key.</li>
<li>Sender authentication is resistant to key-compromise impersonation (KCI).</li>
<li>Encryption to a known recipient, strong forward secrecy.</li>
</ol>
<p>But this doesn’t explain how and why it works. In the next section, I’m
going to try to explain for the above case how the keys are generated and try to
shed some light on how the message protocol ends up working.</p>
<h2 id="noise-basics">Noise Basics</h2>
<p>Noise applies a set of very well-known and researched principles to make it work
in a very elegant way to avoid confusion and mistakes. The most important parts
that need to be understood are:</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Diffie%E2%80%93Hellman_key_exchange">Diffie-Hellman Key
Exchange</a>,
in particular, <a href="https://en.wikipedia.org/wiki/Elliptic-curve_Diffie%E2%80%93Hellman">Elliptic curve
Diffie-Hellman</a>.
The very very short summary is that ECDH allows deriving a shared symmetric
key based on two asymmetric key-pairs.</li>
<li>Hashing using well-known and understood hashing algorithms like SHA-256.</li>
<li>Key derivation using a hash-based function using HMAC based on the same hash
function used in the hashing steps.</li>
</ul>
<p>With a rudimentary understanding of what happens using the above building blocks,
we can now take a deeper look into the message handshake protocol. As mentioned
before, the handshake protocol is an exact specification of how to build
an internal state so that both parties end up with the same symmetric encryption
keys.</p>
<p>However, instead of just using Diffie-Hellman on long-lived key-pairs, Noise
allows several combinations of static and ephemeral key pairs to achieve the
desired security properties.</p>
<h3 id="kk-handhake---e-es-ss-pattern">KK Handhake - e, es, ss pattern.</h3>
<p>In the diagram below, I walk you through the first important sequence of the
“KK” handshake pattern. As a quick recap, the “KK” message pattern relies on the
fact that the two parties have already exchanged their public keys, but want to
establish a secure communication channel with forward secrecy.</p>
<p>The key element of the KK pattern is that both parties know each other’s public
keys. The exchange of the necessary public keys has happened before in a
controlled environment. For example, imagine a fleet of backend hosts and with
each host, you generate a particular key pair. In a cloud environment, you can use
a key management service to provide these keys and make sure they’re properly
bound to only authorized hosts.</p>
<p>A quick legend for the image below:</p>
<ul>
<li>The blue left side is Alice, this actor uses one static key pair for
authentication and an ephemeral key pair for connection establishment. The
ephemeral key pair should be generated for every new session.</li>
<li>The green right side is Bob, this actor has a similar static key pair and an
ephemeral key pair for connections.</li>
<li>Green arrows indicate the exchange of public keys from Alice to Bob (solid green
arrow) or from Bob to Alice (dotted green arrow).</li>
<li>Red arrows indicate when the private keys are accessed by either party.</li>
<li>The dotted line in the middle symbolizes the network interface between the two.</li>
</ul>
<figure>
    <img src="https://grund.me/noise_handshake_kk_part_1.png"> <figcaption>
            <h4>Graphical Explanation of what happens during the handshake.</h4>
        </figcaption>
</figure>

<p>Now, let’s walk through the process at least for the first part of the
handshake, extending it more would make the diagram particularly messy, but you
will get the gist of the chaining process that happens that makes it easy to
understand. The Noise specification mentions three state contexts: handshake
state, symmetric state, cipher state.</p>
<ul>
<li>The handshake state contains and builds the public and private keys needed to
process the messages.</li>
<li>The symmetric state contains a hash value <code>h</code> and a chaining key <code>ck</code> that are
continuously updated to build the internal state.</li>
<li>The cipher state contains a symmetric encryption key <code>k</code> and a nonce <code>n</code> that
is incremented every time the encryption key <code>k</code> is used. <code>k</code> can be used to
encrypt certain payloads part of the handshake messages and is particularly
useful for  zero roundtrip encryption.</li>
</ul>
<p>The first part of the handshake is to process the pre-messages. Certain
handshake patterns do not have pre-messages, others do. In the case of the
“KK” pattern, the pre-message contains the previously exchanged public keys of
the two parties.</p>
<ol>
<li>To initialize the state, first, the protocol name (the full <a href="https://noiseprotocol.org/noise.html#protocol-names-and-modifiers">protocol
name</a>
contains the pattern, the hash function, and encryption method) is hashed.
This then initializes the <code>h</code> and <code>ck</code> variables that are most important for
tracking the cryptographic state. In this initial step (1), <code>h</code> and <code>ck</code> have
the same value.</li>
<li>In this step, the static public key of Alice is hashed and <code>h</code> updated
appropriately.</li>
<li>Now, the static public key of Bob is hashed and <code>h</code> is updated. This
concludes the pre-message handling.</li>
</ol>
<p>After processing the pre-message, it is now time to process all the handshake
symbols of the first part of the handshake. Namely, <code>e, es, ss</code>:</p>
<ol start="4">
<li>Processing <code>e</code> means hashing the public ephemeral key of Alice and updating
<code>h</code>. Also, it will append the ephemeral public key of Alice to the
message buffer that is sent to Bob. This marks the exchange of the public
key.</li>
<li>Processing <code>es</code>: This is the first time, we perform a Diffie-Hellman
operation to derive a key. We use the ephemeral private key of Alice and the
static public key of Bob to derive a new temporary key.</li>
<li>Using the chaining key <code>ck</code> and a key derivation function based on HMAC to
derive a new chaining key and an encryption key. HMAC based on the selected
hash function is applied multiple rounds to create these two new secret
values. At the end of this step, <code>ck</code> is updated with a new value and <code>k</code> the
secret encryption key is set to the second temporary key, and the nonce <code>n</code> is
reset to <code>0</code>.</li>
<li>The final step is to process <code>ss</code>. This will perform a similar operation as
in the previous step but using a different set of keys. It will use the
static private key of Alice and the static public key of Bob. First, it uses
Diffie-Hellman to generate a temporary symmetric key.</li>
<li>This is the final step of processing the <code>ss</code> pattern. It uses the temporary
output value of the previous step as the input for the key derivation …</li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://grund.me/posts/securing-custom-protocols-with-noise/">https://grund.me/posts/securing-custom-protocols-with-noise/</a></em></p>]]>
            </description>
            <link>https://grund.me/posts/securing-custom-protocols-with-noise/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25857422</guid>
            <pubDate>Thu, 21 Jan 2021 10:24:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[So, You Want to CTF? (A Beginner’s Guide to CTFing)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25857114">thread link</a>) | @notagoodidea
<br/>
January 21, 2021 | https://jaimelightfoot.com/blog/so-you-want-to-ctf-a-beginners-guide/ | <a href="https://web.archive.org/web/*/https://jaimelightfoot.com/blog/so-you-want-to-ctf-a-beginners-guide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Last weekend, I played in the Women Unite Over CTF, hosted by <a href="https://www.womenhackerz.com/">WomenHackerz</a> and several other organizations.&nbsp; There was a fantastic turnout, with 1,000 women playing!&nbsp; For many of the participants, it was their first time playing a CTF.</p><p>After the event was over, there was some discussion on what to do if you wanted to play more CTFs, if you got stumped a lot, etc.&nbsp; This is intended to be <strong>a guide for beginners who have just started playing CTFs</strong> (or for people who have never played, but would like to).</p><p>It certainly isn’t the only CTF resource out there, but I find that a lot of the resources are either big information dumps (hard to pick through as a beginner) or links without context or guidance on how to improve.&nbsp; This post seeks to change that.&nbsp; : )</p><h2 id="what-is-a-ctf">What is a CTF?</h2><p>CTF stands for “<strong>capture the flag</strong>.”&nbsp; It’s a hacking competition where the challenges (or a hacking environment, or both) are set up for you to hack.&nbsp; Once you successfully solve a challenge or hack something, you get a “flag”, which is a specially formatted piece of text.&nbsp; You can then submit that flag for points… the player or team with the most points wins!</p><p><img src="https://i1.wp.com/media.giphy.com/media/3oKIPcqmx1mpCOJJp6/giphy.gif" alt=""></p><p>Each challenge is usually oriented around a single concept.&nbsp; By solving challenges, you (hopefully!) learn about a new concept, vulnerability, tool, class of attack, etc.</p><h3 id="ctf-styles">CTF Styles</h3><p>Most CTFs are “<strong>jeopardy style</strong>", meaning that there are a handful of categories, and each of the (typically standalone) challenges falls in to one of those categories.</p><p>The categories vary from CTF to CTF, but typically include:</p><ul><li><strong>RE (reverse engineering)</strong>:&nbsp; get a binary and reverse engineer it to find a flag</li><li><strong>Pwn</strong>:&nbsp; get a binary and a link to a program running on a remote server.&nbsp; Cause a buffer overflow, etc. to bypass normal functionality and get the program to read the flag to you.</li><li><strong>Crypto</strong>:&nbsp; crypto means cryptography!&nbsp; Get an encrypted flag and figure out how to decrypt it (includes both classical and modern ciphers)</li><li><strong>Web</strong>:&nbsp; web-based challenges where you are directed to a website, and you have to find and exploit a vulnerability (SQL injection, XSS, etc.) to get a flag.</li><li><strong>Forensics/Stego</strong>:&nbsp; given a PCAP file, image, audio or other file, find a hidden message and get the flag.</li><li><strong>Other</strong>:&nbsp; this is a bit of a grab bag.&nbsp; Includes random puzzles, electronics-based things, OSINT, anything that doesn’t fit into the other categories.</li></ul><p><img src="https://i1.wp.com/media.giphy.com/media/1vZaAcldbX8Xh6lMlV/giphy.gif" alt=""></p><p>Jeopardy isn’t the only style.&nbsp; There are a few <strong>attack/defense CTFs</strong>, where you are given control of a server that you must protect from other players, while also attacking other servers.&nbsp; These are fairly rare (and pretty difficult to set up, I imagine).</p><p>There are also CTFs that emulate <strong>pen testing</strong>, where you are given a target VM (“box”) to hack into, and escalate your privileges until you are a root user.&nbsp; These are also fairly rare but a lot of fun.&nbsp; Check out <strong>Metasploitable</strong> in late November (<a href="https://blog.rapid7.com/2018/11/05/announcing-the-2018-metasploit-community-ctf/">here is the announcement from 2018</a>), or <strong><a href="https://hackthebox.eu/">Hack The Box</a></strong> year-round.</p><h2 id="logistics-and-how-to-find-ctfs">Logistics and How to Find CTFs</h2><h3 id="wait-before-you-go-any-further">Wait!&nbsp; Before you go any further</h3><p>It’s definitely more fun to play with friends, or even internet strangers.&nbsp; Playing with other people means that you can get each other unstuck, and you can also support each other when you make progress, get a new tool working, or find a flag… or when you don’t.&nbsp; Especially when you’re new, CTFs can feel like repeatedly banging your head against the wall (there’s so much to learn in this field!).&nbsp; Having others to play alongside can definitely help lift that emotional burden when things aren’t going well, and give you people to celebrate with when you make a breakthrough.</p><p><img src="https://i1.wp.com/giphygifs.s3.amazonaws.com/media/haBeggedmenEA/giphy.gif" alt=""></p><p>You might think, “who am I going to convince to play CTFs” with me?&nbsp; &nbsp;There are many online groups that are open to beginners.&nbsp; A short list includes:</p><ul><li><a href="https://opentoallctf.github.io/">OpenToAll</a></li><li><a href="https://www.womenhackerz.com/">Women Hackers</a></li><li><a href="https://twitter.com/IanColdwater/status/1068173165610831872">CTF Circle</a></li></ul><p>You can try Slack/Discord for local security meet-up groups to see if there’s any interest in teaming up.&nbsp; Same goes for university groups, if you’re a student.&nbsp; Finally, you can also check Slack or Discord for a given CTF, as often there are other people looking for teammates.</p><p>Even if your first response to this idea is “oh hell no”, give it try, at least once.&nbsp; : )</p><h3 id="where-to-find-ctfs">Where to find CTFs</h3><p>There are <strong>in-person CTFs</strong> (especially if you live on the east or west coast in the US) throughout the year, plus many at <strong>conferences</strong>.</p><p>But there are also plenty of <strong>online CTFs</strong>, which is what I mostly play.&nbsp; They typically happen on weekends, and run for 1-3 days, although some go for a week or more.&nbsp;&nbsp;To find them, check out <a href="https://ctftime.org/"><strong>CTFTime</strong></a> and click on “Upcoming”.&nbsp; This is continually updated (and sometimes at the last minute).&nbsp; Also keep an eye out on Twitter.</p><p>A few CTFs and CTF platforms are <strong>available online, year round</strong>.&nbsp; See the bottom of this post (“Bonus Round!") for more.</p><h2 id="and-now-for-the-resource-list">And now for the resource list!</h2><p>There’s really no substitute for actually doing CTF challenges, even if you only make a little bit of progress.&nbsp; This resource list has a few goals:</p><ul><li>Equip you with enough tools and knowledge to get started on a CTF challenge in a given category</li><li>Point you towards additional resources if you want to build up your skills outside of time-limited CTF events, and alert you to any category-specific sites or platforms</li><li>Give you a basic list of things to try if you have no idea where to start with a challenge</li></ul><p>There’s a LOT to learn.&nbsp; If you’re new, I recommend that you <strong>find a few beginner CTFs that are “jeopardy” style, and try a few challenges from each category and see what you enjoy doing</strong>.&nbsp; If you like doing one category, that’s great!&nbsp; It’s also great if you like to do a bit of everything.&nbsp; My top recommendation for a “jeopardy”-style beginner CTF is <strong><a href="https://picoctf.com/">PicoCTF</a></strong>, but there are more options in the “Bonus Round!” section at the bottom of this post.</p><p>This guide is by no means comprehensive.&nbsp; I know there are a ton of sites and resources out there.&nbsp; I wanted to share my top picks for each category, with options for different learning styles.</p><h2 id="re">RE</h2><p>Reverse engineering (RE), involves taking a binary and, well, reverse engineering it to determine its functionality (and find a flag).</p><p>In industry, RE skills are used for vulnerability research.&nbsp; You might be given a software program and asked to find vulnerabilities (without having source code).&nbsp; Similarly, malware research involves a lot of reverse engineering.&nbsp; In my view, it’s a bit more niche than its inclusion in CTFs would lead you to believe, but still a challenging/fun category.</p><p><img src="https://i2.wp.com/media.giphy.com/media/4UzW8S83pWoKs/giphy.gif" alt=""></p><h3 id="resources-to-get-started">Resources to get started</h3><p>It can be pretty daunting to get started in reverse engineering, especially if you have little or no experience in low-level programming languages like assembly.&nbsp; As you get started, try to find something in the code to orient yourself… a call to a standard library function (read, scanf, printf, etc.), comments, strings, etc.&nbsp; Then keep expanding and iterating from there.</p><ul><li><p><strong>Learning by doing</strong>:&nbsp; My top recommendation is <strong><a href="http://microcorruption.com/">Microcorruption</a></strong>.&nbsp; It’s a game where you try to reverse engineer (fictitious) bluetooth locks of increasing difficulty.&nbsp; It’s all in-browser (which means no tool setup), and has a tutorial level that introduces you some of the assembly and environment.&nbsp; I have <a href="https://jaimelightfoot.com/blog/category/microcorruption/">write-ups for each level</a> if you get stuck.</p></li><li><p><strong>Learning by reading</strong>:&nbsp; I’m going to double dip between this section and Pwn.&nbsp; I’d suggest <strong><a href="https://www.amazon.com/Hacking-Art-Exploitation-Jon-Erickson/dp/1593271441">Hacking: The Art of Exploitation</a></strong> and then <strong><a href="https://practicalbinaryanalysis.com/">Practical Binary Analysis</a></strong>.&nbsp; Hacking: The Art of Exploitation takes you from a very basic level through C, assembly, program memory, exploits, and much more.&nbsp; It’s incredibly thorough and definitely worth a read</p></li><li><p><strong>Learning by watching</strong>:&nbsp; Live Overflow has a great <a href="https://www.youtube.com/watch?v=iyAyN3GFM7A&amp;list=PLhixgUqwRTjxglIswKp9mpkfPNfHkzyeN"><strong>series on binary exploitation</strong></a>.&nbsp; Check out the playlist of videos <a href="https://www.youtube.com/watch?v=iyAyN3GFM7A&amp;list=PLhixgUqwRTjxglIswKp9mpkfPNfHkzyeN">here</a>.</p></li></ul><h3 id="re-focused-ctfs">RE-focused CTFs:</h3><p>I’m going to suggest <strong><a href="http://microcorruption.com/">Microcorruption</a></strong> one more time.&nbsp; : )&nbsp; There’s also FireEye’s yearly <strong><a href="http://flare-on.com/">Flare-On</a></strong> challenge, which will probably kick your ass (it always kicks mine) but it’s worth a try.</p><p>You can also find plenty of RE challenges in jeopardy-style events, both year-round and regular/short-term CTFs.</p><h3 id="tools-and-other-resources">Tools and other resources</h3><p>You will definitely need special tools to do RE challenges.&nbsp; There are lots of tools to choose from, as well as different categories of tools (disassembler, decompiler, debugger, etc.).&nbsp; In addition to having varying functionality, different tools are needed for different file types.</p><p>If you are a total beginner, I’ll once again recommend <strong><a href="http://microcorruption.com/">Microcorruption</a></strong>.&nbsp; A lot of the tools listed below can be difficult to set up, and in the interest of removing barriers to entry, I’m suggesting Microcorruption as an introduction to RE, because you don’t have to install anything to get started.</p><p>Eventually though, you’ll want to install and get familiar with different tools:</p><ul><li>My favorite is <strong><a href="https://binary.ninja/">Binary Ninja</a></strong> and have done some previous write-ups using it.&nbsp; I like the UI/UX and the available features.&nbsp; The only downside is that you need a license (I got mine originally through a BSides RE workshop, otherwise it’s $149).</li><li>There are plenty of free options as well.&nbsp; My second choice is <strong><a href="https://ghidra-sre.org/">Ghidra</a></strong>, which is free and fairly beginner friendly.&nbsp; There’s also <strong><a href="https://www.radare.org/r/">Radare</a></strong>, <strong><a href="http://www.ollydbg.de/">Ollydb</a></strong>, <strong>gdb</strong>, <strong><a href="https://www.hex-rays.com/products/ida/index.shtml">IDAPro</a></strong>, <strong>Objdump</strong> and many more.</li></ul><p>Similar to “try a bunch of categories and see what you prefer”, I recommend trying a bunch of tools and see what you prefer.&nbsp; I realize that installing a bunch of tools can be a gigantic pain in the ass, so here are a couple VM options that get you a bunch of pre-installed tools:</p><ul><li><strong>FireEye</strong> provides a VM image as part of their Flare-On competition (<a href="https://www.fireeye.com/blog/threat-research/2017/07/flare-vm-the-windows-malware.html">see this link for more info</a>) that includes many pre-installed RE tools.</li><li>You can also install a <strong><a href="https://www.kali.org/downloads/">Kali</a> VM</strong>, which comes pre-installed with various tools as well.</li></ul><p>As for more resources, <strong>OpenToAll</strong> has a <a href="https://github.com/OpenToAllCTF/REsources">fantastic list of RE Resources here</a>.&nbsp; This includes some foundational knowledge like C, x86 assembly, and more.</p><p>There’s also this free <strong><a href="https://www.begin.re/">beginner RE workshop</a></strong> that uses IDA.</p><p><strong>If you have no idea where to start with an RE challenge</strong>:&nbsp; &nbsp;</p><ul><li>does <code>strings &lt;filename&gt;</code> reveal find any interesting strings in the program?&nbsp;
Open the file in a debugger/disassembler/decompiler tool (as listed above) and try to get a sense of what the program does.&nbsp; Are there any ASCII-range characters?&nbsp;</li><li>What user …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jaimelightfoot.com/blog/so-you-want-to-ctf-a-beginners-guide/">https://jaimelightfoot.com/blog/so-you-want-to-ctf-a-beginners-guide/</a></em></p>]]>
            </description>
            <link>https://jaimelightfoot.com/blog/so-you-want-to-ctf-a-beginners-guide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25857114</guid>
            <pubDate>Thu, 21 Jan 2021 09:36:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Capturing call stack with Haskell exceptions]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25857084">thread link</a>) | @gbrown_
<br/>
January 21, 2021 | https://maksbotan.github.io/posts/2021-01-20-callstacks.html | <a href="https://web.archive.org/web/*/https://maksbotan.github.io/posts/2021-01-20-callstacks.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div id="content">
            <p>
    Posted on January 20, 2021
    
</p>



<ul>
<li><a href="#what-is-a-call-stack">What is a call stack</a></li>
<li><a href="#using-exceptions">Using exceptions</a></li>
<li><a href="#capturing-stacks">Capturing stacks</a></li>
<li><a href="#final-remarks">Final remarks</a></li>
<li><a href="#useful-links">Useful links</a></li>
</ul>
<p>Recently I discovered a nice way to capture call stack in Haskell exceptions almost transparently, and I’m going to share it in this post</p>
<p>If this is a known technique, let me know, otherwise — enjoy using it.</p>
<h2 id="what-is-a-call-stack">What is a call stack</h2>
<p>Suppose somewhere in the program you use <code>error</code> to signal an impossible situation:</p>
<div id="cb1"><pre><code><span id="cb1-1"><span>foo ::</span> [a] <span>-&gt;</span> a</span>
<span id="cb1-2">foo [] <span>=</span> <span>error</span> <span>"impossible!"</span></span>
<span id="cb1-3">foo a<span>:</span>_ <span>=</span> a</span>
<span id="cb1-4"></span>
<span id="cb1-5"><span>bar ::</span> [<span>Int</span>] <span>-&gt;</span> [<span>Int</span>] <span>-&gt;</span> <span>Int</span></span>
<span id="cb1-6">bar a b <span>=</span> foo a <span>+</span> foo b</span></code></pre></div>
<p>And then accidentally use it with an empty list:</p>
<div id="cb2"><pre><code><span id="cb2-1">λ<span>&gt;</span> bar [] []</span>
<span id="cb2-2"><span>***</span> <span>Exception</span><span>:</span> impossible<span>!</span></span>
<span id="cb2-3"><span>CallStack</span> (from <span>HasCallStack</span>)<span>:</span></span>
<span id="cb2-4">  <span>error</span>, called at stacks<span>.</span>hs<span>:</span><span>4</span><span>:</span><span>10</span> <span>in</span> main<span>:</span><span>Main</span></span></code></pre></div>
<p>Obviously, there is an error, but <code>GHCI</code> also prints a peculiar thing: a call stack! It contains only one entry and isn’t helpful, though… So you go to <a href="https://downloads.haskell.org/ghc/latest/docs/html/users_guide/">GHC manual</a> to see what <code>HasCallStack</code> the message is talking about, and there it is: <a href="https://downloads.haskell.org/ghc/latest/docs/html/users_guide/glasgow_exts.html#hascallstack"><code>HasCallStack</code> section</a>.</p>
<p>As the manual says, you add <code>HasCallStack</code> constraint to your <code>foo</code> and <code>bar</code> functions:</p>
<div id="cb3"><pre><code><span id="cb3-1"><span>foo ::</span> <span>HasCallStack</span> <span>=&gt;</span> [a] <span>-&gt;</span> a</span>
<span id="cb3-2">foo [] <span>=</span> <span>error</span> <span>"impossible!"</span></span>
<span id="cb3-3">foo a<span>:</span>_ <span>=</span> a</span>
<span id="cb3-4"></span>
<span id="cb3-5"><span>bar ::</span> <span>HasCallStack</span> <span>=&gt;</span> [<span>Int</span>] <span>-&gt;</span> [<span>Int</span>] <span>-&gt;</span> <span>Int</span></span>
<span id="cb3-6">bar a b <span>=</span> foo a <span>+</span> foo b</span></code></pre></div>
<p>Now the output becomes much more informative:</p>
<div id="cb4"><pre><code><span id="cb4-1">λ<span>&gt;</span> bar [] []</span>
<span id="cb4-2"><span>***</span> <span>Exception</span><span>:</span> impossible<span>!</span></span>
<span id="cb4-3"><span>CallStack</span> (from <span>HasCallStack</span>)<span>:</span></span>
<span id="cb4-4">  <span>error</span>, called at stacks<span>.</span>hs<span>:</span><span>6</span><span>:</span><span>10</span> <span>in</span> main<span>:</span><span>Main</span></span>
<span id="cb4-5">  foo, called at stacks<span>.</span>hs<span>:</span><span>10</span><span>:</span><span>11</span> <span>in</span> main<span>:</span><span>Main</span></span>
<span id="cb4-6">  bar, called at <span>&lt;</span>interactive<span>&gt;:</span><span>5</span><span>:</span><span>1</span> <span>in</span> interactive<span>:</span><span>Ghci1</span></span></code></pre></div>
<p>You get function names, module names and even source locations for all calls starting from the <code>ghci</code> prompt down to the point where <code>error</code> is called.</p>
<p>Remember, however, that stack is captured only as far from the <code>error</code> call as there are <code>HasCallStack</code> constraint. E.g., dropping the constraint from <code>foo</code> will also exclude <code>bar</code> from the log:</p>
<div id="cb5"><pre><code><span id="cb5-1">λ<span>&gt;</span> bar [] []</span>
<span id="cb5-2"><span>***</span> <span>Exception</span><span>:</span> impossible<span>!</span></span>
<span id="cb5-3"><span>CallStack</span> (from <span>HasCallStack</span>)<span>:</span></span>
<span id="cb5-4">  <span>error</span>, called at stacks<span>.</span>hs<span>:</span><span>6</span><span>:</span><span>10</span> <span>in</span> main<span>:</span><span>Main</span></span></code></pre></div>
<p>Still, you get to know the precise location of the <code>error</code> call, which is nice.</p>
<p><strong>Caveat</strong>: <code>head</code>, <code>tail</code>, <code>read</code> and so on use <a href="http://hackage.haskell.org/package/base-4.14.1.0/docs/GHC-Err.html#v:errorWithoutStackTrace"><code>errorWithoutStackTrace</code></a> (for performance reasons), so you won’t ever see stack traces from them. One more reason to avoid <code>head</code>!</p>
<h2 id="using-exceptions">Using exceptions</h2>
<p>However, using <code>error</code> to report errors is not very convenient: you can pass only a <code>String</code> as an argument and so catching specific errors while propagating others becomes very hard and messy.</p>
<p>Fortunately, there is another mechanism in GHC for that: exceptions. So you define your custom exception type and throw it from the <code>foo</code> function like this:</p>
<div id="cb6"><pre><code><span id="cb6-1"><span>data</span> <span>FooException</span> <span>=</span> <span>FooException</span></span>
<span id="cb6-2">  <span>deriving</span> (<span>Show</span>, <span>Exception</span>)</span>
<span id="cb6-3"></span>
<span id="cb6-4"><span>foo ::</span> <span>HasCallStack</span> <span>=&gt;</span> [a] <span>-&gt;</span> a</span>
<span id="cb6-5">foo [] <span>=</span> throw <span>FooException</span></span>
<span id="cb6-6">foo a<span>:</span>_ <span>=</span> a</span>
<span id="cb6-7"></span>
<span id="cb6-8"><span>bar ::</span> <span>HasCallStack</span> <span>=&gt;</span> [<span>Int</span>] <span>-&gt;</span> [<span>Int</span>] <span>-&gt;</span> <span>Int</span></span>
<span id="cb6-9">bar a b <span>=</span> foo a <span>+</span> foo b</span></code></pre></div>
<p>You run it and expect to see the nice exception with a stack trace. But…</p>
<div id="cb7"><pre><code><span id="cb7-1">λ<span>&gt;</span> bar [] []</span>
<span id="cb7-2"><span>***</span> <span>Exception</span><span>:</span> <span>FooException</span></span></code></pre></div>
<p>You get none! What is going on, and how <code>error</code> is different from <a href="http://hackage.haskell.org/package/base-4.14.1.0/docs/Control-Exception.html#v:throw"><code>throw</code></a>?</p>
<p>The reason is that exceptions don’t capture the stack trace automatically, even when thrown from a place with <code>HasCallStack</code> context. There is an <a href="https://gitlab.haskell.org/ghc/ghc/-/issues/12096">open issue</a> to do so, reported back in 2016, but no progress was made yet.</p>
<h2 id="capturing-stacks">Capturing stacks</h2>
<p>But what if we want to capture stack with exceptions? One possible way would be to save the stack (represented as <a href="http://hackage.haskell.org/package/base-4.14.1.0/docs/GHC-Stack.html#t:CallStack"><code>CallStack</code></a> type) as part of the exception constructor, then make your custom <code>throwWithStack :: HasCallStack =&gt; Foo -&gt; IO ()</code> function and use it everywhere, but that is too cumbersome, and you may just forget to use the right throwing function.</p>
<p>Fortunately, there is a better way. Recall that magic <code>HasCallStack</code> constraint captures call stack from the point where something annotated with it is used. We don’t want to annotate <code>throw</code>, but there is one more thing on the same line — exception constructor itself! It turns out, you can use GADTs to capture stack with an exception data:</p>
<div id="cb8"><pre><code><span id="cb8-1"><span>data</span> <span>FooException</span> <span>where</span></span>
<span id="cb8-2">  <span>FooException</span><span> ::</span> <span>HasCallStack</span> <span>=&gt;</span> <span>FooException</span></span></code></pre></div>
<p>And then access it in <code>Show</code> instance:</p>
<div id="cb9"><pre><code><span id="cb9-1"><span>instance</span> <span>Show</span> <span>FooException</span> <span>where</span></span>
<span id="cb9-2">  <span>show</span> <span>FooException</span> <span>=</span> <span>"FooException\n"</span> <span>&lt;&gt;</span> prettyCallStack callStack</span>
<span id="cb9-3"></span>
<span id="cb9-4"><span>deriving</span> anyclass <span>instance</span> <span>Exception</span> <span>FooException</span></span>
<span id="cb9-5"><span>-- alternatively, derive Show from stock and print call stack in 'displayException' method.</span></span></code></pre></div>
<p>Here <code>callStack</code> is provided by <code>GHC.Stack</code> and will use <code>HasCallStack</code> constraint introduced by pattern match on <code>FooException</code> GADT constructor.</p>
<p>Let’s see an example of how it works:</p>
<div id="cb10"><pre><code><span id="cb10-1">λ<span>&gt;</span> bar [] []</span>
<span id="cb10-2"><span>***</span> <span>Exception</span><span>:</span> <span>FooException</span></span>
<span id="cb10-3"><span>CallStack</span> (from <span>HasCallStack</span>)<span>:</span></span>
<span id="cb10-4">  <span>FooException</span>, called at stacks<span>.</span>hs<span>:</span><span>18</span><span>:</span><span>16</span> <span>in</span> main<span>:</span><span>Main</span></span>
<span id="cb10-5">  foo, called at stacks<span>.</span>hs<span>:</span><span>22</span><span>:</span><span>11</span> <span>in</span> main<span>:</span><span>Main</span></span>
<span id="cb10-6">  bar, called at <span>&lt;</span>interactive<span>&gt;:</span><span>7</span><span>:</span><span>1</span> <span>in</span> interactive<span>:</span><span>Ghci1</span></span></code></pre></div>
<p>For another example, here is a real call stack I reproduced in our production code:</p>
<div id="cb11"><pre><code><span id="cb11-1"><span>Exception</span><span>:</span> <span>Operation</span> timeout</span>
<span id="cb11-2"><span>CallStack</span> (from <span>HasCallStack</span>)<span>:</span></span>
<span id="cb11-3">  <span>TimeOut</span>, called at src<span>/</span><span>Database</span><span>/</span><span>Bolt</span><span>/</span>Connection.hs<span>:</span><span>38</span><span>:</span><span>36</span> <span>in</span> hasbolt<span>-</span><span>0.1</span><span>.</span><span>4.3</span><span>-</span>inplace<span>:</span><span>Database.Bolt.Connection</span></span>
<span id="cb11-4">  run, called at src<span>/</span><span>XXX</span><span>/</span><span>DB</span><span>/</span>Impl.hs<span>:</span><span>42</span><span>:</span><span>43</span> <span>in</span> xxx<span>-</span><span>0.3</span><span>.</span><span>5.0</span><span>-</span>inplace<span>:</span><span>XXX.DB.Impl</span></span>
<span id="cb11-5">  runDB, called at src<span>/</span><span>XXX</span><span>/</span><span>DB</span><span>/</span>Impl.hs<span>:</span><span>124</span><span>:</span><span>14</span> <span>in</span> xxx<span>-</span><span>0.3</span><span>.</span><span>5.0</span><span>-</span>inplace<span>:</span><span>XXX.DB.Impl</span></span>
<span id="cb11-6">  programs, called at src<span>/</span><span>XXX</span><span>/</span><span>API</span><span>/</span>Program.hs<span>:</span><span>33</span><span>:</span><span>17</span> <span>in</span> xxx<span>-</span><span>0.3</span><span>.</span><span>5.0</span><span>-</span>inplace<span>:</span><span>XXX.API.Program</span></span></code></pre></div>

<p><code>HasCallStack</code> is a magic constraint, so the fact that this trick works may or may not be a coincidence: some later change in GHC may stop GADT pattern match from affecting how <code>HasCallStack</code> is solved. However, I think that this approach is useful enough and may be used in practice. Just don’t forget to add enough <code>HasCallStack</code> to places which can fail.</p>
<p>Don’t forget, though, that <code>HasCallStack</code> is not free and sometimes can break some optimizations, especially if used in recursive functions (that’s the reason <code>head</code> &amp; friends do not capture the stack).</p>
<p>Of course, this post does nothing to help debugging standard exceptions, like <code>IOError</code>. For that, the usual way is to build with <code>-prof</code> and run your code with <code>+RTS -xc</code>, as documented in <a href="https://downloads.haskell.org/ghc/latest/docs/html/users_guide/runtime_control.html#rts-flag--xc">the manual</a>.</p>
<h2 id="useful-links">Useful links</h2>
<ul>
<li><a href="https://downloads.haskell.org/ghc/latest/docs/html/users_guide/glasgow_exts.html#hascallstack">GHC manual on call stacks</a></li>
<li><a href="https://downloads.haskell.org/ghc/latest/docs/html/users_guide/glasgow_exts.html#hascallstack">GHC manual on stacks from profile build</a></li>
<li><a href="http://hackage.haskell.org/package/base-4.14.1.0/docs/GHC-Stack.html">Haddock for <code>GHC.Stack</code></a></li>
<li><a href="https://gitlab.haskell.org/ghc/ghc/-/issues/12096">Issue to add call stacks to exceptions</a></li>
<li><a href="https://github.com/bgamari/ghc-proposals/blob/stacktraces/proposals/0000-exception-backtraces.rst">GHC Proposal for that</a></li>
<li><a href="https://www.well-typed.com/blog/2020/04/dwarf-1/">Using DWARF debug information in GHC</a></li>
</ul>

        </div>
        </div></div>]]>
            </description>
            <link>https://maksbotan.github.io/posts/2021-01-20-callstacks.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25857084</guid>
            <pubDate>Thu, 21 Jan 2021 09:30:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Management by metrics leads us astray]]>
            </title>
            <description>
<![CDATA[
Score 291 | Comments 239 (<a href="https://news.ycombinator.com/item?id=25856257">thread link</a>) | @jakobgreenfeld
<br/>
January 20, 2021 | https://jakobgreenfeld.com/metrics | <a href="https://web.archive.org/web/*/https://jakobgreenfeld.com/metrics">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Let’s say my goal this year is to get to 10k monthly recurring revenue (MRR).</p>

<p>MRR first, everything else second. I would ruthlessly cut out all activities that don’t lead to a measurable MRR increase. For example, I would stop writing blog posts like the one you’re currently reading. I certainly wouldn’t create fun projects like What to Tweet or take the time for non-transactional Zoom calls.</p>

<p>I would focus on my revenue generating projects, crank up the advertising machinery and do everything I can think of that potentially increases my MRR.
I’m fairly confident that I would reach 10k MRR by the end of the year. But at what price?</p>

<p>Let’s take a step back for a second.</p>

<p>You know who manages by metrics? Big companies like Google, Amazon and LinkedIn.</p>

<p>And what do they have in common?</p>

<p>Their core product got notably worse over time.</p>

<p>Google’s search results are dominated by ads and many users now use workarounds to find what they’re looking for (“Best headphone reddit”). LinkedIn looks like Minesweeper. Facebook was a fun place to meet friends. And if you search for an electronics product on Amazon, you immediately feel like you’re at a flea market in the middle of Shenzhen.
This is the result of hundreds of decisions that were motivated by a short-term focus on specific metrics like revenue and click rates. And while these decisions most likely optimized the metrics, they made the user experience worse.</p>

<p>The problem is that we don’t have the technology to measure the right thing. Or maybe the “right thing” is inherently immeasurable.</p>

<p>Or, and that’s my personal favorite, we’re dealing with a Schrödinger’s cat like situation. The “right thing” is only the right thing as long as we’re not trying to optimize it.
This is known as Goodhart’s law. “When a measure becomes a target, it ceases to be a good measure.“</p>

<p>Let’s consider another example.</p>

<p>Who else manages by metrics? Politicians!</p>

<p>Instead of some boring historic example (there are plenty, just read “Seeing like a State”), I’m going to spice things up by talking about something that’s happening right now.
It’s not hard to anticipate what I want to talk about since there’s precisely one thing that’s currently happening: Covid-19.</p>

<p>Politicians try to manage the situation by focusing on metrics like the “R number”. At least here in Germany the motto is: let’s lower the R number at all costs.
Turns out the cost of this strategy is incredibly high. It’s just not immediately measurable.</p>

<p>For example, everyone’s getting fatter since all gyms and sport clubs are closed. Most people are developing unhealthy eating habits because there’s simply nothing else to do. Social connections are rapidly degregating even though everyone knows how important they’re for the human wellbeing.</p>

<p>I’m not a doctor and don’t play one on the internet, but I can easily imagine that there are lots of further unintended consequences of the current lockdown policy. For example, since most people now spend most of their time indoors alone and wear masks when they leave their homes, their immune system isn’t stressed regularly like it usual is. Hence I wouldn’t be surprised if many people will get sick of other diseases once the lockdown ends as a result of weakened immune systems.</p>

<p>Just to clarify, I’m all for taking Covid seriously. In fact, I’ve been hoarding masks since 2009. I spent the summer of 2009 with a bunch of friends in Lloret de Mar (a party hotspot in Spain) just when news of the swine flu started to emerge. Long story short, everyone in our group got sick (20+ people) except for my girlfriend and me because we’ve been wearing masks.
Now the most famous example how focusing on metrics can have unhealthy consequences is the cobra effect. I’ll just quote from Wikipedia:</p>

<blockquote>
  <p>“The term cobra effect originated in an anecdote that describes an occurrence during India under British rule. The British government was concerned about the number of venomous cobras in Delhi. The government therefore offered a bounty for every dead cobra. Initially, this was a successful strategy; large numbers of snakes were killed for the reward. Eventually, however, enterprising people began to breed cobras for the income. When the government became aware of this, the reward program was scrapped. When cobra breeders set their now-worthless snakes free, the wild cobra population further increased.”</p>
</blockquote>

<p>There is one more example I always have to talk about when the topic comes up: academia.</p>

<p>Stagnation apologists love to argue that the lack of progress in science is simply a result of the fact that all low-hanging fruit are gone.</p>

<p>That’s complete nonsense. There’s still plenty of low-hanging fruit. It’s just that everyone is so busy chasing meaningless metrics that they can’t see them.</p>

<p>In academia the metric of choice usually has something to do with the number of citations. But just like Google’s backlink-driven algorithm (which was in fact inspired by academia’s citation metrics) was quickly gamed by savvy webmasters, academia’s algorithm is gamed by careerists.</p>

<p>And I’m not talking about some tiny minority here. If you want to survive in academia, you have to play the citation game. And if everyone is cheating, at the very least you have to do the same to stand a chance.</p>

<p>You have to partner up with others because five people can write five times as many papers. You agree to constantly cite each other. Likewise, you focus on incremental additions to established ideas because that’s the safest way to new publications regularly. You work on the stuff everyone else is working on because how else are you going to get citations?</p>

<p>And one thing you absolutely have to avoid like the plague is the risky and deep kind of research that leads to real progress in the field.</p>

<p>The problem isn’t that citations are a bad metric, and we need to come up with smarter ones. Instead, it’s just Goodhart’s law in action.
Every attempt to manage academia makes it worse.</p>

<p>As soon a new metric is introduced it will misdirect the attention of scientists towards playing the game, instead of progressing science.</p>

<p>I talked about three areas, but the same pattern occurs almost everywhere. For example, just remember when everyone started minimizing fat in their diet or how grades are used to measure “learning”.</p>

<p>Crucially the problem is not the specific metric that’s being used. Whatever new metric gets introduced will soon again be made useless by Goodhart’s law. The metrics game will always be akin to Whac-A-Mole.</p>

<p>Now where does this leave us? If management by metrics doesn’t work, what else should we do?</p>

<p>First of all, I think that looking at metrics can be helpful. They just shouldn’t be the sole yardstick decisions are measured against.</p>

<p>And while the map never will be the territory, the picture you’re looking at gets more accurate the more metrics you consider. For example, if politicians would not just consider the R number but hundreds of metrics that take different aspects of a population’s wellbeing into account, the decisions would be better ones.</p>

<p>The obvious problem is that decisions become much harder if you consider more than one metric.</p>

<p>But more importantly there are so many factors we can’t measure that nevertheless should be taken into account.</p>

<p>The more I think about it the more I become convinced that it all boils down to talking to people.</p>

<p>And I’m not talking about surveys that distill thousands of standardized “conversations” into a few numbers or analytics tools that do similar things for behavior. I’m talking about real one-on-one interactions.</p>

<p>Just imagine if Jeff Bezos would talk to hundreds of real (non pre-vetted) Amazon customers each month and take what he hears in these conversations seriously. Or if politicians would have long conversations with regular people from all wakes of life. Or if academic committees would actually talk to applicants before filtering them out based on citation metrics.</p>

<p>In our hyper rational world it’s extremely hard to justify decisions based on the mere gut feeling you got from a few conversations. But this is exactly what people should be doing.</p>

<p>Engagement metrics will never tell you if users are genuinely happy when they use your product. But a few genuine conversations will.</p>

<p>A resume will never tell you if a person is genuinely interested in uncovering unknown truths about nature. But a 30-minute conversation will.</p>

<p>Yes, it’s so much easier to reach a consensus if you just hire the candidate with the highest citation metrics or implement the feature that will lead to the largest revenue increase in the next quarter. But while it’s the easiest decision it’s usually not the best one.</p>

<p>And I think the same applies not just to managing organizations but also to managing ourselves.</p>

<p>Just by listening to my own body I’ll always know better than any fitness tracker if I slept well, better than any blood test if my diet is healthy, and better than my bank account if I’m happy.
That doesn’t mean that I’ll not use a fitness tracker, make regular blood tests, or check my bank account. But I certainly won’t allow them to dictate my decisions.</p>

<p>I’ll look at all the facts and take everything in, even the stuff that can’t be measured, and then I’ll just go with my gut.</p>


  </div></div>]]>
            </description>
            <link>https://jakobgreenfeld.com/metrics</link>
            <guid isPermaLink="false">hacker-news-small-sites-25856257</guid>
            <pubDate>Thu, 21 Jan 2021 06:52:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cgit, Nginx and Gitolite: A Personal Git Server]]>
            </title>
            <description>
<![CDATA[
Score 125 | Comments 75 (<a href="https://news.ycombinator.com/item?id=25856071">thread link</a>) | @cuu508
<br/>
January 20, 2021 | https://bryanbrattlof.com/cgit-nginx-gitolite-a-personal-git-server/ | <a href="https://web.archive.org/web/*/https://bryanbrattlof.com/cgit-nginx-gitolite-a-personal-git-server/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><header><p>nginx + cgit + gitolite = $5/month</p><p> published:&nbsp; <time datetime="2021-01-12T00:00:00+00:00"> 12 January 2021 </time></p></header><p>I've been on a <em>"own my online presence"</em> kick for more than a year now. So for this (overly protracted) essay, I thought I'd publish my notes on how I created my own Git server.</p><p>There are many open source projects like <a href="https://gitea.io/en-us/">GitTea</a> or <a href="https://gitlab.com/">GitLab</a> to make hosting your own git projects effortless; however I wanted a much more simple (read: old school) setup. I ended up with something that uses many of the same projects that the <a href="https://www.kernel.org/">Linux Organization</a> uses to publish the <a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/">Linux Kernel</a></p><p>The server (as of this writing) uses <a href="http://www.releases.ubuntu.com/20.04/">Ubuntu's 20.04.1 LTS (Focal Fossa)</a> running on <a href="https://www.digitalocean.com/">Digital Ocean's</a> hardware (<a href="https://m.do.co/c/b0f6f650ad4e">referral-link</a>). I wholeheartedly support and recommend you chose a different setup. Diversity in people and in tech stack is always and will always be a great thing.</p><p>What lies below can be broken into 3 main topics:</p><ol><li><a href="#the-start">The Start</a> prepares a newly minted server for git hosting duties. Creating a new admin user, locking down the OpenSSH daemon, and installing fail2ban.</li><li><a href="#gitolite">Gitolite</a> installs and configures the server to allow us (and colleagues) to have more fine-grained control over who has access to <code>git push|fetch</code> on the server.</li><li>And <a href="#cgit">Cgit</a>, <a href="#fastcgi-wrapper">fcgiwrap</a>, and <a href="#nginx">Nginx</a> to create a web-server to view our published projects.</li></ol><div><p>In the end, you'll have a server much like <a href="https://git.bryanbrattlof.com/">this one</a>.</p><p><em>Enjoy!</em></p></div><div id="the-start"><h2>The Start</h2><p>I often find security <em>"best practices"</em> are a lot like driving down the highway. Some people speeding past you are <em>"obviously"</em> just moments away from a major data breach, while the others you're passing are <em>"clearly"</em> so worried about the entire data-center burning down, they couldn't possibly get anything else done. Everyone thinks everyone else has lost their marbles.</p><p>So with that in mind, here are a few steps I took to secure my newly minted server. Please feel free to use only the <em>"best practices"</em> you deem appropriate for your mission.</p><p>Or just <a href="#gitolite">skip to the "installing Gitolite"</a> part directly.</p><div id="admin-user"><h3>Admin User</h3><p>For whatever reason, be it for security or protecting the server from my stupidity, one of the first things I do when creating a new server is add a new user for my general admin tasks.</p><p>Adding a new user is remarkably easy to do on a Ubuntu system:</p><p>You'll be prompted to answer a few questions, including creating a new UNIX password. This will be the password you'll need to <code>sudo -i</code> and gain <code>root</code> permissions, so make it a good one, or use tools like <a href="https://www.passwordstore.org/">Pass</a>, or <a href="https://bitwarden.com/">BitWarden</a> to help you remember.</p><p>Then give our new <code>limb</code> user <code>sudo</code> permissions:</p><p>I've also largely eliminated all password based authentication when signing into servers, relying on open source smart cards like <a href="https://www.nitrokey.com/">NitroKey</a> for authentication. If interested, this requires we setup <code>.ssh/authorized_keys</code> for our <code>limb</code> user:</p><p>Just replace <code>key</code> with your public ssh key:</p><div><pre><span></span>$ mkdir /home/limb/.ssh
$ echo "key" &gt; /home/limb/.ssh/authorized_keys
</pre></div><p>Next, set the <code>.ssh</code> directory's file permissions so the <code>ssh</code> daemon can read the files:</p><div><pre><span></span>$ chown -R limb:limb /home/limb/.ssh
$ chmod 700 /home/limb/.ssh
$ chmod 644 /home/limb/.ssh/authorized_keys
</pre></div><p>If everything worked, after you restart the <code>ssh</code> daemon (<code>service sshd restart</code>) you will now be able to login as the administrator user:</p></div><div id="openssh"><h3>OpenSSH</h3><p>Git and Gitolite (<a href="#gitolite">installed in the next sections</a>) will need us to keep port 22 open, allowing us to <code>git push</code> from anywhere on the internet. This open port will eventually attract <em>"a lot"</em> of attention from bots who endlessly scour the internet looking for vulnerable servers, mindlessly stuffing passwords, hoping one password will eventually let them in.</p><p>We can eliminate all worry about weak or compromised passwords by disabling all password based authentication, relying solely on <a href="https://cryptography.io/en/latest/hazmat/primitives/asymmetric/">asymmetric cryptography</a>, or <em>"ssh keys"</em>. Just use your favorite text editor to open <code>/etc/ssh/sshd_config</code> and ensure these lines exist somewhere in it:</p><div><pre><span></span>PubkeyAuthentication yes
PasswordAuthentication no
</pre></div><p>While we're here, a large majority <a href="#id2" id="id1">[1]</a> of these bots are interested in logging in as the <code>root</code> user. If you created a new admin account in <a href="#admin-user">the previous section</a> and ensured you can login using your public key, you can also disable <code>root</code> logins entirely with this line in the config:</p><table id="id2"><colgroup><col><col></colgroup><tbody><tr><td><a href="#id1">[1]</a></td><td>Some simple <em>"bash-fu"</em> on my <code>/var/log/auth.log</code> shows ~93.58% of the roughly 15,000 login attempts since I started this server, tried to login as <code>root</code> Second place was the user <code>git</code> (including legitimate logins) at ~1.82%.</td></tr></tbody></table><p>If you uploaded your public key to your VPS provider, most of these changes should have already been configured for you. But in the off chance you had to make some changes, restart the <code>ssh</code> service to load the new config changes in:</p></div><div id="uncomplicated-firewall"><h3>Uncomplicated FireWall</h3><p>Depending on your VPS provider, they may also have a firewall system built into their admin panel allowing you to apply rules simply by adding tags to a server. However, I enjoy keeping all my firewall rules inside each box, if only for the same reason I <em>keep all my socks on the left hand drawer,</em> so everything stays organized and in the same place.</p><p>You can install <code>ufw</code> using the Advanced Packaging Tool:</p><p>Right now, the only thing we have enabled is <code>ssh</code> which uses port 22. To allow port 22 through <code>ufw</code> just use the following command:</p><p>and then turn the firewall on:</p><p>and <strong>viola!</strong> You have a firewall.</p></div><div id="fail2ban"><h3>fail2ban</h3><p>Even though we've turned off password based authentication <a href="#openssh">in a previous section</a>, we will still receive a significant amount of bots wasting our compute cycles trying to login. And while the likelihood of this being successful is <em>zero</em> when rounded to any order of magnitude, the bots will nevertheless continue to pilfer a non-zero amount of CPU if given the opportunity.</p><p>To stop the most brazen of these bots, tools like <a href="https://github.com/fail2ban/fail2ban">Fail2Ban</a>, which creates temporary firewall rules to block IP address who repeatedly fail to authenticate with <code>ssh</code>, are a great compromise between usefulness and annoyance.</p><p>The Advanced Packaging Tool can again help us install <code>fail2ban</code>.</p><p>Once installed, the <code>ssh</code> "jail" will come pre-enabled for you. If you wish to make any changes, you will need to make a copy of the <code>fail2ban</code> config file:</p><div><pre><span></span>$ cp /etc/fail2ban/jail.conf /etc/fail2ban/jail.local
</pre></div><p>Then add your changes to <code>jail.local</code> so they will persist after an upgrade.</p><p><code>fail2ban</code> does a great job documenting what each option does in the config file. Some of the changes I made are:</p><ul><li>because I use <code>ufw</code> to manage my firewall, I changed <code>banaction = ufw</code>.</li><li>enabled <code>bantime.increment</code> to increase the duration of a ban based on how many times the IP address has been banned previously.</li><li>enabled <code>bantime.rndtime</code> to <em>"randomize"</em> the length of a ban, preventing bots from knowing exactly when they can resume their assault.</li><li>enabled <code>bantime.maxtime</code> so I won't need to unban IP addresses (if you're unfortunate enough to share an IP with a bot).</li><li>lowered <code>bantime</code>, <code>findtime</code> and <code>maxretry</code> allowing me to issue small bans that increase in severity as the IP address continues to antagonize.</li></ul><p>Once you're satisfied with your changes, start <code>fail2ban</code> using <code>systemd</code>.</p><div><pre><span></span>$ systemctl enable fail2ban
$ systemctl start fail2ban
</pre></div><p>And <strong>Done!</strong></p><p>Depending on how <em>"popular"</em> you are on the internet, you should start to see <code>NOTICE</code> lines in <code>/var/log/fail2ban.log</code> of misbehaving bots and the equivalent firewall rules in <code>ufw</code>.</p><div><pre><span></span>$ cat /var/log/fail2ban.log | grep 'NOTICE' | tail -1
...  [125553]: NOTICE  [sshd] Ban 156.155.159.161

$ ufw status
Status: active

To                         Action      From
--                         ------      ----
Anywhere                   REJECT      156.155.159.161
22/tcp                     ALLOW       Anywhere
22/tcp (v6)                ALLOW       Anywhere (v6)
</pre></div></div></div><div id="gitolite"><h2>Gitolite</h2><p>Installing <a href="https://gitolite.com/gitolite/index.html">Gitolite</a> is amazingly simple, there are no binaries to compile or daemons to monitor.</p><p>At its core, Gitolite is just a collection of <a href="https://www.perl.org/">Perl</a> scripts that run after someone signs into the server using the <code>ssh</code> daemon <a href="#openssh">we configured in the previous sections</a>. Once installed, Gitolite will give us more fine-grained-control over who has <code>git push|fetch</code> permissions to each repository. I encourage you to checkout <a href="https://gitolite.com/gitolite/basic-admin.html">Gitolite's amazing documentation</a> if only to see how capable Gitolite can be.</p><div id="step-1-create-the-git-user"><h3>Step: 1 - Create The Git User</h3><p>Before we install Gitolite, we'll need to create a new user for everyone to log into and to run Gitolite's Perl scripts. I typically use the username <code>git</code> for this, feel free to replace <code>git</code> with the username that you feel is more appropriate.</p><div><pre><span></span>$ adduser --system --group --disabled-password --home /var/lib/git git
</pre></div><p>This creates a new system-user on the server called <code>git</code>. Because this is not a <em>"normal"</em> user, there will be no aging information in <code>/etc/shadow</code>, which is convenient when nobody will be monitoring this account.</p><p>We also used the <code>--home</code> option to set the <code>$HOME</code> variable to <code>/var/lib/git</code>. This is where we will eventually put Gitolite's configuration files and our Git repositories. Feel free to adjust this to where you prefer, I've seen many use <code>/home/git</code>.</p><p>I included the <code>--disabled-password</code> to disable any password based access into our new user. In <a href="#openssh">the previous sections</a>, we've disabled all password based authentication into the server and Gitolite requires ssh keys for authentication, so disabling passwords for our user is a smart move.</p></div><div id="step-2-install-gitolite"><h3>Step: 2 - Install Gitolite</h3><p>Because Gitolite is just a bunch of Perl scripts, I prefer to install Gitolite from <a href="https://github.com/sitaramc/gitolite">the source</a>. As we will see, installing Gitolite from source also has the benefit of making upgrades and adding custom patches in the future extremely easy.</p><p>This also means we'll need to install Gitolite's dependencies ourselves:</p><p>When we (or a colleague) signs into the server, using the <code>git</code> user, we will automatically run Gitolite's Perl scripts, which means these scripts must be executable by our <code>git</code> user. So, to make managing file permissions easier, we'll use our <code>git</code> user for the rest of the installation process.</p><p>Log into our <code>git</code> user with the "substitute user" command: (assuming you're the <code>root</code> user)</p><p>Then clone Gitolite's source code into the <code>$HOME</code> directory: (this should be <code>/var/lib/git</code> unless <a href="#step-1-create-the-git-user">you changed it</a> when we setup the <code>git</code> user above)</p><div><pre><span></span>$ git clone https://github.com/sitaramc/gitolite
</pre></div></div><div id="step-3-setup-gitolite"><h3>Step: 3 - Setup …</h3></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bryanbrattlof.com/cgit-nginx-gitolite-a-personal-git-server/">https://bryanbrattlof.com/cgit-nginx-gitolite-a-personal-git-server/</a></em></p>]]>
            </description>
            <link>https://bryanbrattlof.com/cgit-nginx-gitolite-a-personal-git-server/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25856071</guid>
            <pubDate>Thu, 21 Jan 2021 06:19:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lab Snacks]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25855760">thread link</a>) | @neilpanchal
<br/>
January 20, 2021 | https://neil.computer/notes/thorlabs-lab-snacks/ | <a href="https://web.archive.org/web/*/https://neil.computer/notes/thorlabs-lab-snacks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <article>
        
        <p>Throughout my engineering career, I've come across dozens if not hundreds of equipment suppliers. But there are a few suppliers that leave a long lasting impression. Thorlabs is one of them. Why?</p><p>It is quite silly actually. Everytime I order a linear actuator, motorized stage or axis controller... something that's just normal industrial hardware, it ships unremarkably with billable weight in hundreds of dollars, docks and sits at the shipping &amp; receiving until I haul it into the lab. Cut open the box, and you see this:</p><figure><img src="https://neil.computer/content/images/2020/09/image.png" alt=""><figcaption>Source: https://jlfenimore.wixsite.com/jenniferfenimore/lab-snacks</figcaption></figure><p>This little red box brings so much joy it is hard to describe. Thorlabs shipping boxes contain one or more of these red boxes, it's got - cookies, candies, granola bars, chips, etc. with seemingly a singular heartwarming goal - to put a smile on my face. They didn't have to do it but they did. And they've been doing this for many years. Infact, they've trademarked "Lab Snacks" which is such a cool name on its own! Food and Drink are not allowed in our lab, except when it comes to the Thorlabs Snacks.</p><p>Thorlabs founder, Alex Cable, wrote an <a href="https://www.thorlabs.com/about_us.cfm">article</a> about his vision of what customer centricity is, there is so much to learn from it, Wikipedia quotes:</p><blockquote>An important part of Thorlabs' brand and culture is Lab Snacks. Lab Snacks were created to support the famished grad student researching all night, serving as an occasional meal for someone hard at work.</blockquote><p>I implore you to read the original <a href="https://www.thorlabs.com/about_us.cfm">article</a> because it exemplifies what a CEO and Founder should do to build an honest, customer centric business and how to genuinely connect with them. Everything at Thorlabs, from their phone support to documentation, is focusing on how best to make you, the customer, successful. Therein lies their success and they double-down on it.</p><p>Thorlabs has left such a long-lasting impact on me that I am writing this post after last enjoying Lab Snacks 2 years ago.</p>
        </article>
</div></div>]]>
            </description>
            <link>https://neil.computer/notes/thorlabs-lab-snacks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25855760</guid>
            <pubDate>Thu, 21 Jan 2021 05:25:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Twitter locks account of Chinese Embassy in U.S.]]>
            </title>
            <description>
<![CDATA[
Score 55 | Comments 29 (<a href="https://news.ycombinator.com/item?id=25855653">thread link</a>) | @empressplay
<br/>
January 20, 2021 | https://www.cbc.ca/news/world/twitter-china-trump-xinjiang-uighur-1.5881613 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/world/twitter-china-trump-xinjiang-uighur-1.5881613">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Twitter has locked the account of the Chinese Embassy in the U.S. for a tweet that defended China's policies in the Xinjiang region, which the U.S. social media platform said violated the firm's policy against "dehumanization" of a group of people.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5881627.1611194382!/fileImage/httpImage/image.JPG_gen/derivatives/16x9_780/usa-trump-twitter.JPG"></p></div><figcaption>A Twitter logo is seen outside the company headquarters on Jan. 11. The social media platform on Wednesday confirmed it had blocked the account of the Chinese Embassy in the U.S. because of a violation of its policy against the dehumanization of a group of people.<!-- --> <!-- -->(Stephen Lam/Reuters/File photo)</figcaption></figure><p><span><p>Twitter has locked the account of the Chinese Embassy in the U.S. for a tweet that defended China's policies in the Xinjiang region, which the U.S. social media platform said violated the firm's policy against "dehumanization."</p>  <p>The Chinese Embassy account, @ChineseEmbinUS, tweeted this month&nbsp;that Uighur women were no longer "baby making machines," citing a study reported by state-backed newspaper China Daily.</p>  <p>The tweet was removed by Twitter and replaced with a label stating that it was no longer available. Although Twitter hides tweets that violate its policies, it requires account owners to manually delete such posts. The Chinese embassy's account has not posted any new tweets since Jan. 9.</p>  <p>"We've taken action on the Tweet you referenced for violating our policy against dehumanization, where it states: We prohibit the dehumanization of a group of people based on their religion, caste, age, disability, serious disease, national origin, race, or ethnicity," a Twitter spokesperson said on Thursday.</p>  <p>The Chinese embassy in Washington did not immediately reply to an e-mailed request for comment. Twitter is blocked in China.</p>  <p>The Biden administration did not immediately respond to a request for comment on Twitter's move.&nbsp;</p>  <h2>Allegations of genocide</h2>  <p>In one of his final acts in office, now-former secretary of state Mike Pompeo declared Tuesday that China's policies against Muslims in its Xinjiang region constitute "crimes against humanity" and "genocide."&nbsp; President Joe&nbsp;Biden's chosen successor to Pompeo, Antony Blinken, said he shared the same view.</p>  <p><span><blockquote lang="en"><p>I have determined that the People’s Republic of China is committing genocide and crimes against humanity in Xinjiang, China, targeting Uyghur Muslims and members of other ethnic and religious minority groups.</p>&amp;mdash;<a href="https://twitter.com/SecPompeo/status/1351580135464558593">@SecPompeo</a></blockquote></span></p>  <p>Xinjiang, a far western region that borders Central Asia, is home to the predominantly Muslim Uighur ethnic group. China denies human rights violations and says its actions in Xinjiang are necessary to counter a separatist and terrorist threat.</p>  <p>In a striking repudiation of its relationship with Washington under Trump, the Chinese Foreign Ministry announced sanctions against&nbsp;"lying and cheating"&nbsp;Pompeo and 27 other top Trump administration officials&nbsp;in a statement that appeared on its website around the time that Biden was taking the presidential oath.</p>  <p>Pompeo and the others had "planned, promoted and executed a series of crazy moves, gravely interfered in China's internal affairs, undermined China's interests, offended the Chinese people, and seriously disrupted China-U.S. relations," it said.</p>    <p>The 28 individuals and immediate family members would be banned from entering mainland China, Hong Kong or Macao, and companies and institutions associated with them restricted from doing business with China.</p>  <p><em><strong>WATCH |&nbsp;Aspects of Chinese treatment of Uighurs fits genocide definition: Bob Rae</strong></em></p>  <p><span><span><div><div title="Aspects of Chinese treatment of Uighurs fits genocide definition: Bob Rae" role="button" tabindex="0"><div><div aria-labelledby="1819938883873-metadata-" title="Aspects of Chinese treatment of Uighurs fits genocide definition: Bob Rae"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/973/995/bob-rae-rblive.jpg" alt="" loading="lazy"></p></div></div></div></div></div><span>Canada's ambassador to the United Nations says he's asked the international organization to gather evidence and investigate whether China's persecution of Uighurs in Xinjiang province constitutes a genocide.<!-- --> <!-- -->10:03</span></span></span></p>  <p>China has repeatedly rejected accusations of abuse in its Xinjiang region, where a United Nations panel has said at least one&nbsp;million Uighurs and other Muslims had been detained in camps.</p>  <p>Last year, a report by German researcher Adrian Zenz published by the Washington-based Jamestown Foundation think-tank accused China of using forced sterilization, forced abortion and coercive family planning against minority Muslims. The Chinese foreign ministry said the allegations were groundless and false.</p>    <p>China's foreign ministry is lashing out at Canada after a House of Commons subcommittee concluded that the state's mistreatment of Uighurs living in Xinjiang province amounts to a policy of&nbsp;genocide.</p>  <p>Zhao Lijian, a spokesperson for the Chinese foreign ministry, <a href="https://www.cbc.ca/news/politics/parliamentary-committee-uighur-genocide-1.5772757">said in Novembe</a>r that this&nbsp;"so-called genocide" is "a rumour and a farce fabricated by some anti-Chinese forces to slander China."</p>  <h2>Suspension of embassy's account follows removal of&nbsp;Trump's&nbsp;</h2>  <p>The embassy's account suspension comes shortly after Twitter removed the account of former U.S. president Donald Trump, which had 88 million followers, citing the risk of violence after some of his supporters stormed the U.S. Capitol this month.</p>  <p>Twitter had locked Trump's account, asking for deletion of some tweets, before restoring it and then removing it altogether after the former president violated the platform's policies again.</p>  <p><em><strong>WATCH | Twitter permanently suspends Trump's account:</strong></em></p>  <p><span><span><div><div title="Twitter permanently suspends Trump" role="button" tabindex="0"><div><div aria-labelledby="1842324035823-metadata-" title="Twitter permanently suspends Trump"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/818/119/trump-twitter.jpg" alt="" loading="lazy"></p></div></div></div></div></div><span>Twitter has permanently suspended U.S. President Donald Trump's account over concerns his tweets could incite violence. Twitter's decision followed two tweets posted by Trump on Friday afternoon. It says the tweets violated the company's policy against glorifying violence.<!-- --> <!-- -->3:58</span></span></span></p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/world/twitter-china-trump-xinjiang-uighur-1.5881613</link>
            <guid isPermaLink="false">hacker-news-small-sites-25855653</guid>
            <pubDate>Thu, 21 Jan 2021 05:07:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Please Stop Encrypting with RSA Directly]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25855597">thread link</a>) | @some_furry
<br/>
January 20, 2021 | https://soatok.blog/2021/01/20/please-stop-encrypting-with-rsa-directly | <a href="https://web.archive.org/web/*/https://soatok.blog/2021/01/20/please-stop-encrypting-with-rsa-directly">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<p>Let me state up front that, while we’re going to be talking about an open source project that was <a href="https://news.ycombinator.com/item?id=25833206">recently submitted</a> to Hacker News’s “Show HN” section, the intent of this post is not at all to shame the developer who tried their damnedest to do the right thing. They’re the victim, not the culprit.</p>



<h2>RSA, Ya Don’t Say</h2>



<p>Earlier this week, an HN user shared <a href="https://github.com/tomquirk/zuccnet">their open source fork of a Facebook’s messenger client</a>, with added encryption. Their motivation was, as stated in the readme:</p>



<blockquote><div><p>It is known that <a href="https://www.digitaltrends.com/social-media/facebook-reads-messenger-messages/">Facebook scans your messages</a>. If you need to keep using Facebook messenger but care about privacy, Zuccnet might help.</p><p>It’s pretty simple: you and your friend have Zuccnet installed. Your friend gives you their Zuccnet public key. Then, when you send a message to your friend on Zuccnet, your message is encrypted on your machine before it is sent across Facebook to your friend. Then, your friend’s Zuccnet decrypts the message. Facebook never sees the content of your message.</p><p>I’m not a security person and there’s probably some stuff I’ve missed – any contributions are very welcome! This is <em>very</em> <strong>beta</strong>, don’t take it too seriously.</p></div><cite>From Zuccnet’s very humble README.</cite></blockquote>



<p>So far, so good. Facebook is abysmal for privacy, so trying to take matters into your own hands to encrypt data so Facebook can’t see what you’re talking about is, in spirit, a wonderful idea.</p>







<p>However, there is a problem with the <em>execution</em> of this idea. And this isn’t a problem unique to Zuccnet. Several times per year, I come across some well-meaning software project that makes the same mistake: Encrypting messages with RSA directly is bad.</p>



<p>From the <a href="https://github.com/tomquirk/zuccnet/blob/42e351e36b3b5dbaef06256ed11313fab77adb25/src/util/crypto.js#L57-L84">Zuccnet source code</a>:</p>


<pre title="">const encryptMessage = (message, recipientPublicKey) =&gt; {
  const encryptedMessage = crypto.publicEncrypt(
    {
      key: recipientPublicKey,
      padding: crypto.constants.RSA_PKCS1_OAEP_PADDING,
      oaepHash: "sha256",
    },
    Buffer.from(message),
  );

  return encryptedMessage.toString("base64");
};

/**
 *
 * @param {String} encryptedMessage - base64 encoded string
 */
const decryptMessage = encryptedMessage =&gt; {
  const encryptedMessageBuffer = Buffer.from(encryptedMessage, "base64");
  const { privateKey } = getOrCreateZuccnetKeyPair();
  const message = crypto.privateDecrypt(
    {
      key: privateKey,
      padding: crypto.constants.RSA_PKCS1_OAEP_PADDING,
      oaepHash: "sha256",
    },
    Buffer.from(encryptedMessageBuffer),
  );
};
</pre>


<p>To the Zuccnet author’s credit, they’re using OAEP padding, not PKCS#1 v1.5 padding. This means their code isn’t vulnerable to Bleichenbacher’s 1998 padding oracle attack (n.b. most of the RSA code I encounter in the wild is vulnerable to this attack).</p>



<p>However, there are other problems with this code:</p>



<ol><li>If you try to encrypt a message longer than 256 bytes with a 2048-bit RSA public key, it will fail. (Bytes matter here, not characters, even for English speakers–because emoji.)</li><li>This design (encrypting with a static RSA public key per recipient) completely lacks forward secrecy. This is the same reason that <a href="https://latacora.micro.blog/2019/07/16/the-pgp-problem.html">PGP encryption sucks</a> (or, at least, one of the reasons PGP sucks).</li></ol>



<p>There are many ways to work around the first limitation.</p>



<p>Some cryptography libraries let you treat RSA as a block cipher in <a href="https://blog.filippo.io/the-ecb-penguin/">ECB mode</a> and encrypt each chunk independently. This is an incredibly stupid API deign choice: It’s slow (asymmetric cryptography operations are on the order of tens-to-hundreds-of-thousands times slower than symmetric cryptography) and you can drop/reorder/replay blocks, since ECB mode provides <em>no semantic security</em>.</p>



<div><figure><img data-attachment-id="61" data-permalink="https://soatok.blog/glitch-ecb/" data-orig-file="https://soatok.files.wordpress.com/2020/04/glitch-ecb.png" data-orig-size="224,224" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="glitch-ecb" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2020/04/glitch-ecb.png?w=224" data-large-file="https://soatok.files.wordpress.com/2020/04/glitch-ecb.png?w=224" src="https://soatok.files.wordpress.com/2020/04/glitch-ecb.png?w=224" alt="" srcset="https://soatok.files.wordpress.com/2020/04/glitch-ecb.png 224w, https://soatok.files.wordpress.com/2020/04/glitch-ecb.png?w=150 150w" sizes="(max-width: 224px) 100vw, 224px"><figcaption>I have strong opinions about cryptographic library design.<br>(Art by <a href="https://twitter.com/SwizzlestixUK">Swizz</a>.)</figcaption></figure></div>



<p>A <strong>much</strong> better strategy is to encrypt the data with a symmetric key, then encrypt <em>that key</em> with RSA. (See the <a href="#rsa-pkcs1">end of the post</a> for special treatment options that are especially helpful for RSA with PKCS#1 v1.5 padding.)</p>



<p>Working around the second problem usually requires an Authenticated Key Exchange (AKE), similar to what I covered in my <a href="https://soatok.blog/2020/11/14/going-bark-a-furrys-guide-to-end-to-end-encryption/">Guide to End-to-End Encryption</a>. Working around this second problem <em>also</em> solves the first problem, so it’s usually better to just implement a forward-secret key exchange protocol than try to make RSA secure. </p>



<p>(You can get forward secrecy without an AKE, by regularly rotating keys, but AKEs make forward secrecy automatic and on-by-default without forcing humans to make a decision to rotate a credential– something most people don’t do unless they have to. AKEs trade user experience complexity for protocol complexity–and this trade-off is almost universally worth taking.)</p>



<p>Although AKEs are extremely useful, they’re a bit complex for most software developers to pick up without prior cryptography experience. (If they were easier, after all, there wouldn’t be so much software that encrypts messages directly with RSA in the first place.)</p>



<p>Note: RSA itself isn’t the reason that this lacks forward secrecy. The problem is how RSA is used.</p>



<h2 id="recommendations">Recommendations</h2>



<h3>For Developers</h3>



<p>First, consider <a href="https://blog.trailofbits.com/2019/07/08/fuck-rsa/">not using RSA</a>. Hell, while you’re at it, <a href="https://www.cryptofails.com/post/75204435608/write-crypto-code-dont-publish-it">don’t write <em>any</em> cryptography code that you don’t have to</a>. </p>



<p>Libsodium (<a href="https://libsodium.gitbook.io/doc/bindings_for_other_languages">which you should use</a>) does most of this for you, and can easily be turned into <a href="https://github.com/soatok/rawr-x3dh">an AKE comparable to the one Signal uses</a>. The less cryptography code you have to write, the less can go catastrophically wrong–especially in production systems.</p>



<p>If jettisoning RSA from your designs is a non-starter, you should at least consider taking the Dhole Moments Pledge for Software Developers:</p>



<blockquote><p>I will not encrypt messages directly with RSA, or any other asymmetric primitive.</p><cite>Simple enough, right?</cite></blockquote>



<p>Instead, if you find yourself needing to encrypt a message with RSA, remind yourself that RSA is <em>for encrypting symmetric keys, not messages</em>. And then plan your protocol design accordingly.</p>



<p>Also, I’m pretty sure RSA isn’t random-key robust. Ask your favorite cryptographer if it matters for whatever you’re building.</p>



<p>(But seriously, you’re better off not using RSA at all.)</p>



<h3>For Cryptography Libraries</h3>



<p>Let’s ask ourselves, “Why are we forcing developers to know or even care about these details?”</p>



<p>Libsodium doesn’t encumber developers with unnecessary decisions like this. Why does the crypto module built into JavaScript? Why does the crypto module built into <em>most</em> programming languages that offer one, for that matter? (Go is a notable exception here, because their security team is awesome and forward-thinking.)</p>



<p>In my opinion, we should stop shipping cryptography interfaces that…</p>



<ul><li>Mix symmetric and asymmetric cryptography in the same API</li><li>Allow developers to encrypt directly with asymmetric primitives</li><li>Force developers to manage their own nonces/initialization vectors</li><li>Allow public/private keys to easily get confused (e.g. lack of type safety)</li></ul>



<p>For example: <a href="https://dholecrypto.com/">Dhole Crypto</a> is close to my ideal for general-purpose encryption.</p>



<h3 id="rsa-pkcs1">Addendum: Securing RSA with PKCS#1 v1.5</h3>



<p><strong>Update:</strong> Neil Madden informs me that what I wrote here is actually very similar to a standard construction called <a href="https://kel.bz/post/kem/">RSA-KEM</a>. You should use RSA-KEM instead of what I’ve sketched out, since that’s better studied by cryptographers.</p>



<p>(I’ve removed the original sketch below, to prevent accidental misuse.)</p>

		</div><!-- .entry-content -->

	</div></div>]]>
            </description>
            <link>https://soatok.blog/2021/01/20/please-stop-encrypting-with-rsa-directly</link>
            <guid isPermaLink="false">hacker-news-small-sites-25855597</guid>
            <pubDate>Thu, 21 Jan 2021 04:58:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Signal App UX: “X just joined Signal”]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25855184">thread link</a>) | @nnain
<br/>
January 20, 2021 | https://nitinnain.com/signal-ux-irritation-x-just-joined/ | <a href="https://web.archive.org/web/*/https://nitinnain.com/signal-ux-irritation-x-just-joined/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1147">

<div>
<p>I’m trying to convince friends and family to switch to Signal. Opened the Signal App after several months today and I was welcomed with 100+ unread “X just joined Signal” messages. And it irritated me right away! Not for some privacy concern but because looking at 100+ automated, unread messages is simply unpleasant. So many email apps base their whole business plan around the ‘zero inbox’ idea. Instead here I was on Signal, greeted with unnecessary messages. You don’t expect me to click each one to mark as read! Or go look for solutions to bulk-delete or mark-all-read right after I signup. The two friends that I had chatted with long back were embedded deep into the sea of these messages.</p>
<p>I go back and forth between whether first impressions are as important — but dare I say, for Web and Mobile Apps they are.</p>
<p><strong>Signal ought to act confidently about its presence in the messaging Apps domain now and not act as a newbie in the market.</strong></p>
<p>P.S.: There’s an option under settings to Switch Off the “Contact Joined Signal” notifications. This should be default off or completely removed from the App.)</p>
<figure><img data-attachment-id="1143" data-permalink="https://nitinnain.com/signal-ux-irritation-x-just-joined__trashed/signal-app-switch-of-just-joined/" data-orig-file="https://nitinnain.com/wp-content/uploads/2021/01/Signal-App-switch-of-just-joined.png" data-orig-size="336,476" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Signal-App-switch-of-just-joined" data-image-description="" data-medium-file="https://nitinnain.com/wp-content/uploads/2021/01/Signal-App-switch-of-just-joined-212x300.png" data-large-file="https://nitinnain.com/wp-content/uploads/2021/01/Signal-App-switch-of-just-joined.png" loading="lazy" src="https://nitinnain.com/wp-content/uploads/2021/01/Signal-App-switch-of-just-joined.png" alt="" width="168" height="238" srcset="https://nitinnain.com/wp-content/uploads/2021/01/Signal-App-switch-of-just-joined.png 336w, https://nitinnain.com/wp-content/uploads/2021/01/Signal-App-switch-of-just-joined-212x300.png 212w" sizes="(max-width: 168px) 100vw, 168px"></figure>
 </div>

</article></div>]]>
            </description>
            <link>https://nitinnain.com/signal-ux-irritation-x-just-joined/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25855184</guid>
            <pubDate>Thu, 21 Jan 2021 03:52:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing a C64 Assembly Demo (2019)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25854271">thread link</a>) | @todsacerdoti
<br/>
January 20, 2021 | https://celso.io/retrocomputing/2019/12/23/c64-assembly.html | <a href="https://web.archive.org/web/*/https://celso.io/retrocomputing/2019/12/23/c64-assembly.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>This is a pure 6510 assembly program for the Commodore 64 made by Bright Pixel in 2019, because why not.</p>

<p><img src="https://celso.io/assets/demo.gif?raw=true" alt="Screenshot"></p>

<p>The <a href="https://en.wikipedia.org/wiki/Commodore_64">C64</a> was a famous 8-bit machine in the 80s and the highest-selling single computer model ever.</p>

<p>Its hardware and architecture set it appart from other 8-bit personal computers at the time. Unlike most of the others, the C64 had dedicated advanced MOS chips for graphics and sprites (the <a href="https://en.wikipedia.org/wiki/MOS_Technology_VIC-II">VIC-II</a>), sound (the <a href="https://en.wikipedia.org/wiki/MOS_Technology_6581">SID</a>), I/O (the CIA), and many others.</p>

<p>These chips were not only powerful for the time, but they could perform their tasks autonomously, independently of what the main CPU, a MOS technology 6510 microprocessor, was doing. For instance, the VIC-II could generate interrupts on automatic sprite collisions. The CPU and the other chips also shared common data and memory BUSes.</p>

<p>To cope with all these chips inside 64Kbytes of addressable memory, the C64 had something called memory overlay, in which different chips would access different physical data locations for the same memory address. For instance the $D000-$DFFF block could be used for RAM, I/O or access to Character ROM, by the CPU, depending on a $0001 setting. Chips would have to be turned on or off, or instructed to look for data at specific RAM/ROM locations all the time to make the most of the machine as a whole.</p>

<p><img src="https://upload.wikimedia.org/wikipedia/commons/8/8e/0430_-_C64_Mainboard_ASSY250407_RevB.jpg" alt="Screenshot"></p>

<p>This was impressive in the 80s, for a relatevily cheap mass-market personal computer.</p>

<p>Programming the C64 was more than a lot of fun, it was a form of art. Because of the way all this hardware was packed together, handling the machine meant knowing its memory map and registers by heart, and dominating quite a collection of tricks, some of which weren’t documented at all. What ended up being written for the C64 by the fervent community of developers all over the world went way beyond the imagination of <a href="https://en.wikipedia.org/wiki/Jack_Tramiel">Jack Tramiel</a>.</p>

<p>Today, in 2019, the cult is still alive. There are vast groups of developers still writing C64 games and demos, restoring and using old machines, or using emulators. The SID sound chip was so revolutionary that it still drives a community of chiptune artists <a href="https://www.kickstarter.com/projects/8-bit-symphony/8-bit-symphony-pro-double-orchestral-cd-of-8-bit-classics">all over</a> the world. The <a href="https://www.hvsc.c64.org/">High Voltage SID Collection</a> has more than 50,000 songs archived and growing.</p>

<p>At Bright Pixel, we like to go low-level, and we think that understanding how things work down there, even if we’re talking about a 40 years old machine, is enriching, helps us become better computer engineers and better problem solvers. This is especially important in a time when we’re flooded with hundreds of high-level frameworks that just “do the job.” Until they don’t.</p>

<p>This is a simple demo for the C64:</p>

<ul>
  <li>It was coded entirely in 6510 assembly.</li>
  <li>It makes use of the VIC-II graphics, character ROM and sprites.</li>
  <li>It plays music using the SID chip.</li>
  <li>Uses raster-based interrupts, perfectly timed.</li>
  <li>Implements a random number generator.</li>
</ul>

<p>You can download the source code for it in <a href="https://github.com/brpx/c64">this repository</a>, change it and run it a real machine or an emulator. The code is all annotated, and you can use the <a href="https://github.com/brpx/c64/issues">issue tracker</a> to ask us questions or make suggestions, we’ll be listening.</p>

<h2 id="setup">Setup</h2>

<h3 id="assembler">Assembler</h3>

<p>We used the <a href="http://theweb.dk/KickAssembler/">Kick Assembler</a> to build the PRG from the source. KA is still maintained up until today, with regular releases launched every couple of months. It supports <a href="http://www.unusedino.de/ec64/technical/aay/c64/brti.htm">MOS 65xx assembler</a>, macros, pseudo commands and has a couple of helpers to load SID and graphics files into memory. Unfortunately, you need Java to run it, but it’s worth the trouble.</p>

<p>Here’s the setup in OSX.</p>

<p>Install Java</p>

<div><div><pre><code>brew update
brew install homebrew/cask/java
</code></pre></div></div>

<p>Install Kick Assembler</p>

<div><div><pre><code>curl http://theweb.dk/KickAssembler/KickAssembler.zip -o /tmp/KickAssembler.zip
sudo unzip /tmp/KickAssembler.zip -d /usr/local/KickAssembler
</code></pre></div></div>

<p>This should be the contents of /usr/local/KickAssembler/KickAss.cfg</p>



<p>And we have this alias in our ~/.bash_profile for convenience.</p>

<div><div><pre><code>alias kick="java -jar /usr/local/KickAssembler/KickAss.jar"
</code></pre></div></div>

<h3 id="c64-emulator">C64 emulator</h3>

<p>There are plenty of Commodore 64 emulators out there.</p>

<p><img src="https://celso.io/assets/emulator.png?raw=true" alt="Screenshot"></p>

<ul>
  <li><a href="http://vice-emu.sourceforge.net/">VICE</a>, the Versatile Commodore Emulator, is a program that runs on a Unix, Win32, or Mac OS X machines and emulates the C64 (and every other 65xx Commodore machine too).</li>
  <li><a href="http://www.dirkwhoffmann.de/virtualc64/">VirtualC64</a> is an interesting alternative for OSX written from scratch using C++ and native Cocoa and provides a real-time graphical inspector of the CPU, Memory, and the other Chips, while it’s running.</li>
</ul>

<p>We used VICE. One more bash alias:</p>

<div><div><pre><code>alias c64="/Applications/x64.app/Contents/MacOS/x64"
</code></pre></div></div>

<h3 id="debugging">Debugging</h3>

<p>Debugging assembly when things go south can be challenging. Back in the 80s, debugging meant spending hours doing trial and error, rebooting the machine, reloading the code from the <a href="https://en.wikipedia.org/wiki/Commodore_Datasette">cassette</a> (or <a href="https://en.wikipedia.org/wiki/Commodore_1541">disk drive</a>, if you were lucky), and writing code to paper just in case you’d lose it in the process.</p>

<p>Luckily, now we have way better tools.</p>

<p><img src="https://celso.io/assets/debugger.png?raw=true" alt="Screenshot"></p>

<ul>
  <li>
    <p>The <a href="https://sourceforge.net/projects/c64-debugger/">C64 65XE Debugger</a> is a C64 and Atari XL/XE code and memory debugger that works in real-time and embeds the VICE emulator in the same graphical interface. It allows you to see what’s happening with every chip, register, memory block; you can set breakpoints, run the program instruction by instruction, and see what’s happening right in the embedded emulator.</p>
  </li>
  <li>
    <p>The VICE emulator <a href="http://vice-emu.sourceforge.net/vice_12.html#SEC271">built-in monitor</a> can also be used to examine, disassemble, and assemble machine language programs, as well as debug them through breakpoints. It has loads of powerful features.</p>
  </li>
</ul>

<p>Where were these tools in 1986?</p>

<h3 id="graphics">Graphics</h3>

<p>Dealing with graphics is a lot easier now too.</p>

<ul>
  <li>
    <p><a href="https://github.com/micheldebree/retropixels">Retropixels</a> is a cross-platform command-line tool to convert any image to Commodore 64 graphical modes and file formats, including Koala (.kla or .koa), which is supported by the Kick Assembler load helpers.</p>
  </li>
  <li>
    <p><a href="https://github.com/Esshahn/spritemate">Spritemate</a> is an online browser-based Commodore 64 sprite editor and supports importing and exporting of the most common file formats, as well as direct Kick Assembler hexadecimal arrays.</p>
  </li>
</ul>

<h3 id="sid-songs">SID songs</h3>

<p>SID is short for the MOS 6581/8580 Sound Interface Device, the programmable sound generator chip inside the C64.</p>

<p>A SID file (song.sid) is a special file format, later popularized by modern age SID Players and emulators, which contains both the data and the 6510 code necessary to play a music song on the SID chip.</p>

<p>Here are a few things you should know about SID and SID files:</p>

<ul>
  <li>A SID file contains both the data and the code to play the music. The code must reside in a specific RAM address, specified inside the SID file, and changes from music to music, which means that if you want to use another .sid file with this demo, you need to make sure that:
    <ul>
      <li>It starts in the same memory address.</li>
      <li>You change the code accordingly if it doesn’t (advanced).</li>
      <li>It doesn’t overlap with the rest of the memory we need to run our program (Kick Assembler will warn you if it does). RAM is scarce and musics can be big.</li>
    </ul>
  </li>
  <li>You can check the SID file <a href="https://www.hvsc.de/download/C64Music/DOCUMENTS/SID_file_format.txt">specification here</a>.</li>
  <li>You should absolutely take a look at the <a href="https://www.hvsc.de/">High Voltage SID Collection</a> and this <a href="https://tamats.com/apps/sid/">SID player &amp; visualizer</a> (<a href="https://github.com/jagenjo/sidviz">github</a>) in javascript</li>
</ul>

<p>Kick Assembler has a helper script to load and parse a SID file directly into your project. <a href="http://www.theweb.dk/KickAssembler/webhelp/content/ch12s03.html">loadSid()</a> places the song code and data in the proper RAM location while assembling, and provides the initialization and play subroutines which you can use with your code. Check <a href="http://www.theweb.dk/KickAssembler/webhelp/content/ch12s03.html">here</a> for more information.</p>

<h3 id="other-resources">Other resources</h3>

<p>These are handy resources you can use:</p>

<ul>
  <li>The <a href="http://sta.c64.org/cbm64mem.html">Commodore 64 memory map</a> explaining the functioning of all addresses, registers and memory blocks.</li>
  <li>The <a href="https://www.c64-wiki.com/">C64 Wiki</a> is the online bible of all things Commodore 64, including detailed information of how the hardware works.</li>
  <li>Not the bible, but <a href="https://codebase64.org/">Codebase64</a> is pretty good too.</li>
  <li>A Kick Assembler <a href="https://github.com/gryf/kickass-syntax-vim">syntax file</a> for Vim.</li>
  <li>Understanding the <a href="http://www.coding64.org/?p=164">character and bitmap</a> graphics modes, memory banks, and how the chips interact with each other.</li>
  <li>6510 CPU <a href="http://www.unusedino.de/ec64/technical/aay/c64/bmain.htm">instructions</a>.</li>
  <li>Great article explaining the VIC-II <a href="https://dustlayer.com/vic-ii/2013/4/26/vic-ii-for-beginners-screen-modes-cheaper-by-the-dozen">screen modes</a>.</li>
</ul>

<h2 id="the-code">The Code</h2>

<p>We’ve annotated the .asm sources with all the information you need to understand what we’re doing, why, and where to find more. You can start by looking at the main <a href="https://github.com/brpx/c64/blob/master/card.asm">card.asm</a> file and move from there.</p>

<p>To assemble the sources into an executable PRG file, all you need to do is:</p>

<div><div><pre><code>java -jar /usr/local/KickAssembler/KickAss.jar card.asm
</code></pre></div></div>

<p>And the output should be something like this:</p>

<p><img src="https://celso.io/assets/assembly.png?raw=true" alt="Screenshot"></p>

<p>Here’s a quick run through the main components of this little demo. Find the rest of the information in the <a href="https://github.com/brpx/c64/blob/master/card.asm">source</a> itself.</p>

<p><strong>Loading external files with Kick Assembler</strong></p>

<p>Kick Assembler has a couple of helpers to load known file formats into memory at assembly time. We’re using two of these, <a href="http://theweb.dk/KickAssembler/webhelp/content/ch12s02.html">LoadBinary()</a> and <a href="http://www.theweb.dk/KickAssembler/webhelp/content/ch12s03.html">LoadSid()</a>.</p>

<p>LoadBinary is loading the Koala screen bitmaps we previously converted with <a href="https://github.com/micheldebree/retropixels">retropixels</a>, while LoadSid is loading the data and code to play the music.sid file. You can check the <a href="https://github.com/brpx/c64/blob/master/card.asm">code</a> to see how we handle the music playing and the screen bitmaps in memory.</p>

<div><div><pre><code>.var music = LoadSid("music.sid")
.var picture1 = LoadBinary("screen1.koa", BF_KOALA)
.var picture2 = LoadBinary("screen2.koa", BF_KOALA)
</code></pre></div></div>

<p><strong>Setting and using the interrupts</strong></p>

<p>We’re using <a href="http://www.unusedino.de/ec64/technical/aay/c64/brti.htm">raster interrupts</a> with our demo. These interrupts trigger at specific scan lines that we set with $D012.</p>

<p>First, we need to turn on the interrupts and set the first one when the program starts. This is how:</p>

<div><div><pre><code>// disable the interrupts
sei
// first interrupt will be irq1 at scan line 240
setupirq(240, irq1);
// interrupt control - enable all interrupts with $7b
lda #%01111011
sta $dc0d
// interrupt control register - enable raster interrupt with $81
lda #%10000001
sta $d01a
// enable interrupts now
cli
</code></pre></div></div>

<p>Later we use the irq1 and irq2 interrupts.</p>

<p>irq1 is triggered at scanline 240, and we use it to change the VIC-II to text mode, scroll the bottom text message and play the music.</p>

<p>irq2 is triggered at scanline 10, and we use it to alternate between the two pictures by switching the VIC-II to bitmap mode and pointing it to the right memory banks.</p>

<p>Here’s irq1 from the <a href="https://github.com/brpx/c64/blob/master/card.asm">code</a>:</p>

<div><div><pre><code>irq1:
    ack();
    // keep scrolling the bottom line
    jsr scroll_message
    // keep the music playing
    jsr music.play
    // jump to irq2 at line 10
    …</code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://celso.io/retrocomputing/2019/12/23/c64-assembly.html">https://celso.io/retrocomputing/2019/12/23/c64-assembly.html</a></em></p>]]>
            </description>
            <link>https://celso.io/retrocomputing/2019/12/23/c64-assembly.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25854271</guid>
            <pubDate>Thu, 21 Jan 2021 01:37:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust in Production: 1Password]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25853935">thread link</a>) | @zdw
<br/>
January 20, 2021 | https://serokell.io/blog/rust-in-production-1password | <a href="https://web.archive.org/web/*/https://serokell.io/blog/rust-in-production-1password">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Rust has taken the programming language world by storm. Since its 1.0 release in 2015, it has been one of the most loved programming languages with a loyal following of developers and contributors.</p><p>To learn why this language is favored so much between developers, we have started a new series on Rust in production. In it, we’ll interview people that have used Rust for significant projects: apps, services, startup MVPs, and others.</p><p>For the first installment of the series, we interview Michael Fey, VP of Engineering at <a href="https://1password.com/">1Password</a>. Read further to find out why they chose Rust for their product, the benefits of Rust for security-centered applications, and what cool libraries you should look into if you’re developing something similar in Rust.</p><h3 id="could-you-tell-us-a-little-about-your-company-and-your-role-there%3F">Could you tell us a little about your company and your role there?</h3><p>1Password is a password manager trusted by millions of people and 70,000 businesses to secure their sensitive data. It remembers all your passwords so you don’t have to, and comes with apps for all major browsers, plus desktop and mobile.</p><p>I am the VP of Engineering for Client Apps here at 1Password. If you have ever had the pleasure to use 1Password on your Mac, Windows PC, iPhone, iPad, Android phone, or tablet, or in your browser, then you’ve been lucky enough to use something my team has built. We’ve been around since 2004, and we take a lot of pride in building a well-crafted experience and keeping people safe online.</p><p><img src="https://serokell.io/files/xa/xarnasmy.111_(5).jpg" alt="Michael Fey" loading="lazy"></p><h3 id="can-you-talk-about-the-stack-of-1password%3F-how-big-a-part-of-your-codebase-is-written-in-rust%3F">Can you talk about the stack of 1Password? How big a part of your codebase is written in Rust?</h3><p>We’ve been using Rust in production at 1Password for a few years now. Our Windows team was the frontrunner on this effort to the point where about 70% of 1Password 7 for Windows is written in Rust. We also ported the 1Password Brain – the engine that powers our browser filling logic – from Go to Rust at the end of 2019 so that we could take advantage of the speed and performance of deploying Rust to WebAssembly in our browser extension.</p><p>These have been in production for the last few years and we’ve seen great success. So much so that we’re now in the midst of a complete rewrite of nearly our entire product lineup, and Rust is a major part of that story. We are using Rust to create a headless 1Password app that encompasses all of the business logic, cryptography, database access, server communication, and more wrapped in a thin UI layer that is native to the system on which we’re deploying.</p><h3 id="did-any-of-rust%E2%80%99s-advantages-like-speed-or-type%2Fmemory-safety-influence-the-choice-of-using-rust-for-1password%3F">Did any of Rust’s advantages like speed or type/memory-safety influence the choice of using Rust for 1Password?</h3><p>One of the main things that drew us to Rust initially was the memory safety; it definitely excites us knowing that Rust helps us maximize our confidence in the safety of our customers’ secrets. Beyond memory safety, though, there’s so much more we love about the Rust ecosystem. There is a significant performance benefit to the lack of a traditional runtime; we don’t have to worry about the overhead of a garbage collector, for instance. Rust offers a form of “program correctness” and many guarantees against undefined behaviour at runtime. The strong type system enforces these rules at compile-time. Carefully aligning application logic with Rust’s strong type rules makes APIs difficult to use incorrectly and results in simpler code that’s free from runtime checking of constraints and invariants; the compiler can guarantee there are no invalid runtime code paths that will lead your program astray before it executes. Having to perform less runtime state validation leads to cleaner, more efficient, more focused, and higher quality code. Rust requires very little runtime debugging compared to other languages. If it compiles, you can be fairly sure it won’t exhibit unexpected behaviour. It may not be what you <em>want</em> but it will be “correct”. 🙂</p><p>Another very powerful (and often overlooked) feature of Rust is its procedural macro system, which has allowed us to write a tool that automatically shares types defined in Rust with our client-side languages (Swift, Kotlin, and TypeScript). The output from this tool handles the serialization/deserialization process automatically, meaning our client-side devs can continue to work in their language of choice while interacting with the Rust library and can be free from the concerns of JSON parsing over the foreign function interface (FFI). We get all of this while enjoying the benefits of compile-time type checking in every one of our target languages. We’ve integrated this tool into our continuous integration server as well, meaning that changes to the Rust models can result in compilation failures in the client applications that are caught during our review process.</p><p>This tool has been an integral component in our development process, allowing us to move much more quickly than ever before. Once our types are defined in Rust, we are able to immediately generate equivalent types in our client-side languages. This allows our devs to focus on solving problems without having to hand-roll boilerplate code to communicate over the FFI.</p><h3 id="how-good-is-rust%E2%80%99s-support-(library-and-otherwise)-for-developing-security-centric-applications-like-1password%3F">How good is Rust’s support (library and otherwise) for developing security-centric applications like 1Password?</h3><p>There is more than enough to build a majority of the base that security-centered applications require. There are two large, prominent cryptography platforms (<em><a href="https://github.com/briansmith/ring">ring</a></em> and the <a href="https://github.com/RustCrypto">Rust Crypto</a> group) that together provide a wealth of functionality. As I mentioned above, writing with Rust itself gives you much greater confidence in your memory usage and makes it much harder to accidentally introduce a memory-related exploit into your application. There is also a wonderful system in place for keeping track of vulnerabilities that do show up from time to time in Rust crates: the <a href="https://rustsec.org/">RustSec</a> database, which is community-sourced by other Rust developers and is updated frequently with new information that can be consumed in CI audit scans. The batteries-included test framework that Rust and Cargo also include mean that you always have an easy way to write unit-test suites for correct behavior in critical code, like any cryptographic functions that you write.</p><p>While safe native Rust libraries for everything are the dream (and they will come in time), there is always the option to dip down and easily consume something in C or from native platform libraries. We use this to great effect in our Rust code for things like calling out to the native implementations of biometric unlock (Touch ID, Face ID, Windows Hello) and platform-specific settings implementations like NSUserDefaults on Apple platforms.</p><h3 id="any-particular-rust-libraries-that-you-want-to-feature%3F">Any particular Rust libraries that you want to feature?</h3><p>Absolutely. Tokio, Hyper/Reqwest, Ring, and Neon all have a home in 1Password and are fundamental in allowing us to tackle this ambitious project at all. You should also check out our <a href="https://crates.io/crates/password-rules-parser">password-rules-parser</a> on <a href="http://crates.io/">crates.io</a>, which is based on a spec primarily being backed by Apple. Their tools and docs can be found <a href="https://developer.apple.com/password-rules/">here</a>.</p><h3 id="where-is-rust-great-to-use%2C-and-where-does-it-fall-short-in-your-stack%3F">Where is Rust great to use, and where does it fall short in your stack?</h3><p>Rust has fulfilled 90% of what we were hoping for when we started this project. We’ve been able to deploy it to nearly every one of our target platforms in some way shape or form (with the exception of Apple Watch). The language itself has been designed with modern sensibilities and is improving with every release. It has great documentation and an active community.</p><p>Although there are countless crates available for use, we did have to roll our own logging and tracing tools to ensure that they were safe to use in 1Password. Additionally, we constructed a substantial localization implementation to meet the requirements of our products.</p><p>It did fall short for us in one key area: We were hoping WebAssembly would take us further in the browser and our browser extension than it has. WebAssembly has been great as a function library, but attempting to stand up an entire runtime in WASM has been a challenge. Many of the issues we ran into, however, were not limitations of Rust but of WebAssembly as a deployment platform.</p><h3 id="what-was-the-biggest-challenge-while-developing-1password-with-rust%3F">What was the biggest challenge while developing 1Password with Rust?</h3><p>Many of the folks on our team were new to Rust, and they experienced the typical learning curve that comes with its memory management and ownership model. We are also finding the compile times to be pretty beefy; our CPUs and fans are definitely getting a workout. 😄</p><h3 id="are-you-satisfied-with-the-result%3F">Are you satisfied with the result?</h3><p>Absolutely.</p><p>If you’re new to Rust, start small and build on top of that. We ran a large number of experiments when we were getting started to try and find the edges of what a Rust-based solution could provide. When your experiments pan out, try to reimagine the ways you used to work with other languages and see if your code can benefit from Rust’s philosophy.</p><p>If you’re new to 1Password, you can <a href="https://start.1password.com/sign-up/plan?c=1PCORE2021">sign up today with this link</a> and save 50% off your first year for family and individual accounts. If you’re working on an open source project, you can get a 1Password Teams account for <em>free</em>. Head on over to <a href="https://github.com/1Password/1password-teams-open-source">our GitHub repo</a> to learn more.</p><hr><p>I would like to thank Michael for the interview, and wish 1Password the best of luck in creating the most awesome password manager out there!</p><p>To read more about programming languages like Rust, be sure to follow us on <a href="https://serokell.medium.com/">Medium</a>, <a href="https://dev.to/serokell">DEV</a>, or <a href="https://twitter.com/serokell">Twitter</a>. If you are looking for the next read, we have an article on <a href="https://serokell.io/blog/rust-companies">9 other Rust production stories</a> that you might want to check out.</p></div></div>]]>
            </description>
            <link>https://serokell.io/blog/rust-in-production-1password</link>
            <guid isPermaLink="false">hacker-news-small-sites-25853935</guid>
            <pubDate>Thu, 21 Jan 2021 00:49:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Standards Are Boring]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25853698">thread link</a>) | @pabs3
<br/>
January 20, 2021 | https://marcin.juszkiewicz.com.pl/2021/01/20/standards-are-boring/ | <a href="https://web.archive.org/web/*/https://marcin.juszkiewicz.com.pl/2021/01/20/standards-are-boring/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<blockquote>
<p>We have made Arm servers&nbsp;boring.</p>
<p>Jon&nbsp;Masters</p>
</blockquote>
<p>Standards are boring. Satisfied users may not want to migrate to other boards
the market tries to sell&nbsp;them.</p>
<p>So Arm market is flooded with piles of small board computers (<span>SBC</span>). Often they
are compliant to standards only when it comes to&nbsp;connectors.</p>
<h3>But our hardware is not&nbsp;standard</h3>
<p>It is not a matter of ‘let produce <span>UEFI</span> ready hardware’ but rather ‘let write
<span>EDK2</span> firmware for boards we already&nbsp;have’.</p>
<p>Look at Raspberry/Pi then. It is shitty hardware but got popular. And group of
people wrote <span>UEFI</span> firmware for it. Probably without vendor support&nbsp;even.</p>
<h3>Start with <span>EBBR</span></h3>
<p>Each new board should be <span>EBBR</span> compliant at start. Which is easy — do ‘whatever
hardware’ and put properly configured U-Boot on it. Upstreaming support for your
small device should not be hard as you often base on some already existing&nbsp;hardware.</p>
<p>Add <span>16MB</span> of <span>SPI</span> flash to store firmware. Your users will be able to boot <span>ISO</span>
without wondering where on boot media they need to write&nbsp;bootloaders.</p>
<p>Then work on <span>EDK2</span> for board. Do <span>SMBIOS</span> (easy) and keep your existing Device
Tree.  You are still <span>EBBR</span>. Remember about upstreaming your work — some people
will complain, some will improve your&nbsp;code.</p>
<h3>Add <span>ACPI</span>, go <span>SBBR</span></h3>
<p>Next step is moving from Device Tree to <span>ACPI</span>. May take some time to understand
why there are so many tables and what <span>ASL</span> is. But as several other systems show
it can be&nbsp;done.</p>
<p>And this brings you to <span>SBBR</span> compliance. Or SystemReady <span>ES</span> if you like&nbsp;marketing.</p>
<h3><span>SBSA</span> for future&nbsp;design</h3>
<p>Doing new SoC tends to be “let us take previous one and improve a bit”. So this
time change it a bit and make your next SoC compliant with <span>SBSA</span> level 3. All
needed components are probably already included in your Arm&nbsp;license.</p>
<p>Grab <span>EDK2</span> support you did for previous board. Look at <span>QEMU</span> <span>SBSA</span> Reference
Platform support, look at other <span>SBSA</span> compliant hardware. Copy, reuse their
drivers, their&nbsp;code.</p>
<h3>Was it&nbsp;worth?</h3>
<p>At the end you will have <span>SBSA</span> compliant hardware running <span>SBBR</span> compliant&nbsp;firmware. </p>
<p>Congratulations, your board is SystemReady <span>SR</span> compliant. Your marketing team may
write that you are on same list as Ampere with their Altra&nbsp;server.</p>
<p>Users buy your hardware and can install whatever <span>BSD</span>, Linux distribution they
want. Some will experiment with Microsoft Windows. Others may work on porting
Haiku or other exotic operating&nbsp;system. </p>
<p>But none of them will have to think “how to get this shit running”. And they
will tell friends that your device is as boring as it should be when it comes to
running <span>OS</span> on it == more&nbsp;sales.</p>
	</div></div>]]>
            </description>
            <link>https://marcin.juszkiewicz.com.pl/2021/01/20/standards-are-boring/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25853698</guid>
            <pubDate>Thu, 21 Jan 2021 00:17:50 GMT</pubDate>
        </item>
    </channel>
</rss>
