<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Mon, 14 Dec 2020 01:14:57 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Mon, 14 Dec 2020 01:14:57 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Positive habits are underestimated [All the time]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25396845">thread link</a>) | @KlimYadrintsev
<br/>
December 12, 2020 | https://klimy.co/blog/positive-habits-12-12-2020 | <a href="https://web.archive.org/web/*/https://klimy.co/blog/positive-habits-12-12-2020">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="blog">
                    <p>We, humans, tend to have a very tough time taking breaks and regenerating. We tend to set for ourself goals that are either too hard to achieve or straight up take too much of our time.</p>
<p>We have all been there. We decide to learn an additional skill, or we decided to lose that last weight that has been bringing us down.</p>
<p>The problem starts when we have outlined the goal, and we decide on the path of reaching it. We get motivated to start by motion which as a result, at the beginning we fill that we are superhumans. That can cause you to overestimate your free time and capabilities.</p>
<p>How many of us quit the gym completely, just because going there every day was not sustainable? How many of us stopped learning a new language because cramming study sessions on the weekends is not healthy and neither fun? Raise your hands. I know that I did both of those.</p>
<p>I have been a victim for underestimating how much time could the task take and the effort that will be required to finish it. I am <a href="https://klimy.co/blog/why-small-habits-11-12-2020">raising a hand for that.</a></p>
<h2>How human usually deal with no energy</h2>
<p>So if you constantly do something too challenging, you are draining your energy instead of getting the boost of cognitive resources. That, of course, can not go forever and at one point you will realise that you are not able to do the task and even the idea of starting makes you want to do anything, but that.</p>
<p>That is the point at which people can either:</p>
<ol>
<li>Quit</li>
<li>Preserver and quit in a week</li>
<li>Take a break and quit in a month</li>
<li>Change the task completely so that it is sustainable</li>
</ol>
<p>As you could imagine, the 4th option is the optimal one. But it is also the one that is chosen the least. </p>
<p>If you have driven yourself to the point of hate, it will be tough to make you like the habit ever again.</p>
<p>The worst part of our lives is that this is an essential step in understanding how to become more efficient. I don’t know a single person that has become productive and coincidentally achieved greatness in life but hasn’t burned out at least once.</p>
<p>Why is that? It seems to start small and improve everything with little steps(which is <a href="https://link.springer.com/chapter/10.1007%2F978-3-030-58565-5_6">proven to be the best way to achieve great goals</a>), you have to fail in achieving something couple of times.</p>
<p>This knowledge is not programmed into our brain or genes. That is why we need to learn on our own mistakes to understand the right course of actions.</p>
<h2>Why does this matter?</h2>
<p>I understand that some people don’t want to do anything that is not immediately satisfactory. I understand that good habits are boring and not fun at all. </p>
<p>The main reason they are not fun is that the effect and the result are postponed so much into the future that our brain, due to smartphones and social media, has been reprogrammed to expect low-cost dopamine hits in everything that we do. </p>
<p>Why do people still perform good, boring habits, then?</p>
<p>Because in the long run, the total amount of dopamine that you get will increase with every time you do the task, and eventually it will snowball into the most amazing feeling you will ever experience.</p>
<p>Writing a chapter of a book is boring and most likely is <a href="https://klimy.co/blog/when-productivity-increases">extremely unrewarding</a>. You spent your time researching, writing and editing. It was super boring and maybe even painful. There is literally no dopamine there.</p>
<p>But, once you write your book, the combined effect of all the sessions will hit your right in the face with the most amazing and happy feeling ever. Maybe even that book will let you retire and become the happiest human on earth, who knows?</p>
<p><img alt="progress vs happiness" src="https://i.gyazo.com/ee36f0c65178aca1860c7e924f182fc2.png"></p>
<p>The thing is that every good habit is like this. Don’t underestimate what you can achieve by just doing <a href="https://klimy.co/blog/impact-through-motion">the right thing, consistently.</a></p>
<p>Start now. Get perfect later.</p>
<p>Klim Y</p> 
                    
                </div></div>]]>
            </description>
            <link>https://klimy.co/blog/positive-habits-12-12-2020</link>
            <guid isPermaLink="false">hacker-news-small-sites-25396845</guid>
            <pubDate>Sat, 12 Dec 2020 08:52:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tacit Programming (APL)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25396753">thread link</a>) | @jpcooper
<br/>
December 12, 2020 | https://aplwiki.com/wiki/Tacit_programming | <a href="https://web.archive.org/web/*/https://aplwiki.com/wiki/Tacit_programming">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="mw-content-text" lang="en-GB" dir="ltr"><div><p>Tacit functions apply to implicit arguments. This is in contrast to the explicit use of arguments in <a href="https://aplwiki.com/wiki/Dfns" title="Dfns">dfns</a> (<code dir="ltr"><span>⍺</span> <span>⍵</span></code>) and <a href="https://aplwiki.com/wiki/Tradfns" title="Tradfns">tradfns</a> (which have named arguments). Some APL dialects allow to combine functions into <b>trains</b> following a small set of rules. This allows creating complex derived functions without specifying any arguments explicitly.
</p><p>Known dialects which implement trains are <a href="https://aplwiki.com/wiki/Dyalog_APL" title="Dyalog APL">Dyalog APL</a>, <a href="https://aplwiki.com/wiki/Dzaima/APL" title="Dzaima/APL">dzaima/APL</a>, <a href="https://aplwiki.com/wiki/Ngn/apl" title="Ngn/apl">ngn/apl</a> and <a href="https://aplwiki.com/wiki/NARS2000" title="NARS2000">NARS2000</a>.
</p>


<h2><span id="Primitives">Primitives</span></h2>
<p>All <a href="https://aplwiki.com/wiki/Primitive_functions" title="Primitive functions">primitive functions</a> are tacit. Some APLs allow primitive functions to be named.
</p>
<div dir="ltr"><pre><span></span>      <span>plus</span> <span>←</span> <span>+</span>
      <span>times</span> <span>←</span> <span>×</span>
      <span>6</span> <span>times</span> <span>3</span> <span>plus</span> <span>5</span>
<span>48</span>
</pre></div>
<h2><span id="Derived_functions">Derived functions</span></h2>
<p>Functions derived from a monadic operator and an operand, or from a dyadic operator and two operands are tacit functions:
</p>
<div dir="ltr"><pre><span></span>      <span>Sum</span> <span>←</span> <span>+</span><span>/</span>
      <span>Sum</span> <span>⍳</span><span>10</span>
<span>55</span>

      <span>Dot</span> <span>←</span> <span>+</span><span>.</span><span>×</span>
      <span>3</span> <span>1</span> <span>4</span> <span>dot</span> <span>2</span> <span>7</span> <span>1</span>
<span>17</span>
</pre></div>
<h2><span id="Derived_operators">Derived operators</span></h2>
<p>A dyadic operator with its right operand forms a tacit monadic operator:
</p>
<div dir="ltr"><pre><span></span>      <span>1</span><span>(</span><span>+</span><span>⍣</span><span>2</span><span>)</span><span>10</span>
<span>12</span>
      <span>Twice</span> <span>←</span> <span>⍣</span><span>2</span>
      <span>1</span> <span>+</span><span>Twice</span> <span>10</span>
<span>12</span>
</pre></div>
<h2><span id="Trains">Trains</span></h2>
<p>A train is a series of functions in isolation. An isolated function is either surrounded by parentheses or named. Below, <code dir="ltr"><span>⍺</span></code> and <code dir="ltr"><span>⍵</span></code> refer to the arguments of the train. <code dir="ltr"><span>f</span></code>, <code dir="ltr"><span>g</span></code>, and <code dir="ltr"><span>h</span></code> are functions (which themselves can be tacit or not), and <code dir="ltr"><span>A</span></code> is an array. The arguments are processed by the following rules:
</p>
<h3><span id="Forks">Forks</span></h3>
<p>A 3-train is a <i>fork</i>:
</p>

<p>The <i>left tine</i> of a fork can be an array:
</p>

<h3><span id="Atops">Atops</span></h3>
<p>A 2-train is an <i>atop</i>:
</p>

<p>Only <a href="https://aplwiki.com/wiki/Dzaima/APL" title="Dzaima/APL">dzaima/APL</a> allows <code dir="ltr"><span>(</span><span>A</span> <span>h</span><span>)</span></code>, which it treats as <code dir="ltr"><span>A</span><span>∘</span><span>h</span></code>.<sup id="cite_ref-1"><a href="#cite_note-1">[1]</a></sup> See <a href="https://aplwiki.com/wiki/Bind" title="Bind">Bind</a>.
</p>
<h2><span id="Debugging">Debugging</span></h2>
<p>In <a href="https://aplwiki.com/wiki/Dyalog_APL" title="Dyalog APL">Dyalog APL</a>, analysis of trains is assisted by a <a href="https://aplwiki.com/wiki/User_command" title="User command">user command</a> <code dir="ltr"><span>]</span><span>Boxing</span> <span>on</span></code>. This is achieved by executing the command <code dir="ltr"><span>]</span><span>Boxing</span> <span>on</span></code> and then entering a train without any parameters. A structure of the train will be displayed.
</p><p>For example, the "accursed train" from the section below can be analysed like this:
</p>
<div dir="ltr"><pre><span></span>      <span>]</span><span>Boxing</span> <span>on</span>
<span>Was</span> <span>OFF</span>
      <span>((</span><span>+</span><span>.</span><span>×</span><span>⍨</span><span>⊢~</span><span>∘.</span><span>×</span><span>⍨</span><span>)</span><span>1</span><span>↓⍳</span><span>)</span>     <span>⍝ the train to be analysed</span>
<span>┌───────────────────────────────┬───────┐</span>
<span>│┌───────────┬─────────────────┐│┌─┬─┬─┐│</span>
<span>││┌───────┬─┐│┌─┬─┬───────────┐│││</span><span>1</span><span>│</span><span>↓</span><span>│</span><span>⍳</span><span>││</span>
<span>│││┌─┬─┬─┐│</span><span>⍨</span><span>│││</span><span>⊢</span><span>│</span><span>~</span><span>│┌───────┬─┐│││└─┴─┴─┘│</span>
<span>││││</span><span>+</span><span>│</span><span>.</span><span>│</span><span>×</span><span>││</span> <span>│││</span> <span>│</span> <span>││┌─┬─┬─┐│</span><span>⍨</span><span>││││</span>       <span>│</span>
<span>│││└─┴─┴─┘│</span> <span>│││</span> <span>│</span> <span>│││</span><span>∘</span><span>│</span><span>.</span><span>│</span><span>×</span><span>││</span> <span>││││</span>       <span>│</span>
<span>││└───────┴─┘││</span> <span>│</span> <span>││└─┴─┴─┘│</span> <span>││││</span>       <span>│</span>
<span>││</span>           <span>││</span> <span>│</span> <span>│└───────┴─┘│││</span>       <span>│</span>
<span>││</span>           <span>│└─┴─┴───────────┘││</span>       <span>│</span>
<span>│└───────────┴─────────────────┘│</span>       <span>│</span>
<span>└───────────────────────────────┴───────┘</span>
</pre></div>
<p>Alternatively, a train can be represented in form of a tree:
</p>
<div dir="ltr"><pre><span></span>      <span>]</span><span>Boxing</span> <span>on</span> <span>-</span><span>trains</span><span>=</span><span>tree</span>
<span>Was</span> <span>ON</span> <span>-</span><span>trains</span><span>=</span><span>box</span>
      <span>((</span><span>+</span><span>.</span><span>×</span><span>⍨</span><span>⊢~</span><span>∘.</span><span>×</span><span>⍨</span><span>)</span><span>1</span><span>↓⍳</span><span>)</span>     <span>⍝ the train to be analysed</span>
     <span>┌───┴───┐</span>  
   <span>┌─┴─┐</span>   <span>┌─┼─┐</span>
   <span>⍨</span> <span>┌─┼─┐</span> <span>1</span> <span>↓</span> <span>⍳</span>
 <span>┌─┘</span> <span>⊢</span> <span>~</span> <span>⍨</span>      
 <span>.</span>     <span>┌─┘</span>      
<span>┌┴┐</span>    <span>.</span>        
<span>+</span> <span>×</span>   <span>┌┴┐</span>       
      <span>∘</span> <span>×</span>
</pre></div>
<p>Or fully parenthesised:
</p>
<div dir="ltr"><pre><span></span>      <span>]</span><span>Boxing</span> <span>on</span> <span>-</span><span>trains</span><span>=</span><span>parens</span>
<span>Was</span> <span>OFF</span> <span>-</span><span>trains</span><span>=</span><span>box</span>
      <span>((</span><span>+</span><span>.</span><span>×</span><span>⍨</span><span>⊢~</span><span>∘.</span><span>×</span><span>⍨</span><span>)</span><span>1</span><span>↓⍳</span><span>)</span>     <span>⍝ the train to be analysed</span>
<span>(((</span><span>+</span><span>.</span><span>×</span><span>)</span><span>⍨</span><span>)(</span><span>⊢~</span><span>((</span><span>∘.</span><span>×</span><span>)</span><span>⍨</span><span>)))(</span><span>1</span><span>↓⍳</span><span>)</span>
</pre></div>
<h2><span id="Examples">Examples</span></h2>
<p>One of the major benefits of tacit programming is the ability to convey a short, well-defined idea as an isolated expression. This aids both human readability (<a href="https://aplwiki.com/wiki/Semantic_density" title="Semantic density">semantic density</a>) and the computer's ability to interpret code, potentially executing special code for particular <a href="https://aplwiki.com/index.php?title=Idiom&amp;action=edit&amp;redlink=1" title="Idiom (page does not exist)">idioms</a>.
</p>
<h3><span id="Plus_and_minus">Plus and minus</span></h3>
<div dir="ltr"><pre><span></span>      <span>(</span><span>+,-</span><span>)</span> <span>2</span>     <span>⍝ ±2</span>
<span>2</span> <span>¯2</span>
      <span>5</span> <span>(</span><span>+,-</span><span>)</span> <span>2</span>   <span>⍝ 5±2</span>
<span>7</span> <span>3</span>
</pre></div>
<h3><span id="Arithmetic_mean">Arithmetic mean</span></h3>
<div dir="ltr"><pre><span></span>      <span>(</span><span>+</span><span>⌿</span><span>÷≢</span><span>)</span> <span>⍳</span><span>10</span>       <span>⍝ Mean of the first ten integers</span>
<span>5.5</span>
      <span>(</span><span>+</span><span>⌿</span><span>÷≢</span><span>)</span> <span>5</span> <span>4</span><span>⍴⍳</span><span>4</span>    <span>⍝ Mean of columns in a matrix</span>
<span>1</span> <span>2</span> <span>3</span> <span>4</span>
</pre></div>
<h3><span id="Fractions">Fractions</span></h3>
<p>We can convert decimal numbers to fractions. For example, we can convert <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/ace31f232e5ba24a1a418586f322f06724e5e12d" aria-hidden="true" alt="{\displaystyle 2.625}"></span> to the improper fraction <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/1c58d4e0e0fdb69d9aa1ea7296259ddb24d56e39" aria-hidden="true" alt="{\displaystyle {\tfrac {21}{8}}}"></span> with
</p>

<p>Alternatively, we can convert it to the mixed fraction <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/3a15740caaa334e457b2766a3bcfc22366196cec" aria-hidden="true" alt="{\displaystyle 2{\tfrac {5}{8}}}"></span> with a mixed fraction:
</p>

<h3><span id="Is_it_a_palindrome?"></span><span id="Is_it_a_palindrome.3F">Is it a palindrome?</span></h3>
<div dir="ltr"><pre><span></span>      <span>(</span><span>⌽≡⊢</span><span>)</span><span>'racecar'</span>
<span>1</span>
      <span>(</span><span>⌽≡⊢</span><span>)</span><span>'racecat'</span>
<span>0</span>
</pre></div>
<h3><span id="Split_delimited_text">Split delimited text</span></h3>
<div dir="ltr"><pre><span></span>      <span>','</span><span>(</span><span>≠</span><span>⊆</span><span>⊢</span><span>)</span><span>'comma,delimited,text'</span>
<span>┌─────┬─────────┬────┐</span>
<span>│</span><span>comma</span><span>│</span><span>delimited</span><span>│</span><span>text</span><span>│</span>
<span>└─────┴─────────┴────┘</span>
      <span>' '</span><span>(</span><span>≠</span><span>⊆</span><span>⊢</span><span>)</span><span>'space delimited text'</span>
<span>┌─────┬─────────┬────┐</span>
<span>│</span><span>space</span><span>│</span><span>delimited</span><span>│</span><span>text</span><span>│</span>
<span>└─────┴─────────┴────┘</span>
</pre></div>
<h3><span id="Component_of_a_vector_in_the_direction_of_another_vector">Component of a vector in the direction of another vector</span></h3>
<p>Sometimes a train can make an expression nicely resemble its equivalent definition in traditional mathematical notation. As an example, here is a program to compute the component of a vector <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/af9f1604cec45bc8d60e31610f9ec1b7c6599b68" aria-hidden="true" alt="{\displaystyle {\textbf {a}}}"></span> in the direction of another vector <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/29890eb931b98e8816c928582f07d7eaa86cc348" aria-hidden="true" alt="{\displaystyle {\textbf {b}}}"></span>:
</p>
<dl><dd><dl><dd><dl><dd><span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/8bd13a4409c254c27e5740a13f040bac84cb6a93" aria-hidden="true" alt="{\displaystyle {\textbf {a}}_{\textbf {b}}=({\textbf {a}}\cdot {\hat {\textbf {b}}}){\hat {\textbf {b}}}}"></span></dd></dl></dd></dl></dd></dl>
<div dir="ltr"><pre><span></span>      <span>Root</span> <span>←</span> <span>*</span><span>∘</span><span>÷</span><span>⍨</span>              <span>⍝ Nth root</span>
      <span>Norm</span> <span>←</span> <span>2</span> <span>Root</span> <span>+</span><span>.</span><span>×</span><span>⍨</span>       <span>⍝ Magnitude (norm) of numeric vector in Euclidean space</span>
      <span>Unit</span> <span>←</span> <span>⊢÷</span><span>Norm</span>            <span>⍝ Unit vector in direction of vector ⍵</span>
      <span>InDirOf</span> <span>←</span> <span>(</span><span>⊢×+</span><span>.</span><span>×</span><span>)</span><span>∘</span><span>Unit</span>   <span>⍝ Component of vector ⍺ in direction of vector ⍵</span>
      <span>3</span> <span>5</span> <span>2</span> <span>InDirOf</span> <span>0</span> <span>0</span> <span>1</span>      <span>⍝ Trivial example</span>
<span>0</span> <span>0</span> <span>2</span>
</pre></div>
<p>For a more parallel comparison of the notations, see the <a href="https://aplwiki.com/wiki/Comparison_with_traditional_mathematics#Practical_example" title="Comparison with traditional mathematics">comparison with traditional mathematics</a>.
</p>
<h3><span id="The_Number_of_the_Beast">The Number of the Beast</span></h3>
<p>The following expression for computing the <a href="https://en.wikipedia.org/wiki/666_(number)" title="wikipedia:666 (number)">number of the Beast</a> (and of <a href="https://aplwiki.com/wiki/I.P._Sharp" title="I.P. Sharp">I.P. Sharp</a>'s APL-based email system, <a href="https://aplwiki.com/index.php?title=666_BOX&amp;action=edit&amp;redlink=1" title="666 BOX (page does not exist)">666 BOX</a>) nicely illustrates how to read a train.
</p>
<div dir="ltr"><pre><span></span>      <span>((</span><span>+</span><span>.</span><span>×</span><span>⍨</span><span>⊢~</span><span>∘.</span><span>×</span><span>⍨</span><span>)</span><span>1</span><span>↓⍳</span><span>)</span><span>17</span> <span>⍝ Accursed train</span>
<span>666</span>
</pre></div>
<p>First, <code dir="ltr"><span>((</span><span>+</span><span>.</span><span>×</span><span>⍨</span><span>⊢~</span><span>∘.</span><span>×</span><span>)</span><span>1</span><span>↓⍳</span><span>)</span></code> is supplied with only one argument <code dir="ltr"><span>17</span></code> and is thus interpreted monadically.
</p><p>Second, <code dir="ltr"><span>(</span><span>+</span><span>.</span><span>×</span><span>⍨</span><span>⊢~</span><span>∘.</span><span>×</span><span>⍨</span><span>)</span><span>1</span><span>↓⍳</span></code> is a 4-train: reading right-to-left, the last 3 components are interpreted as the fork <code dir="ltr"><span>1</span><span>↓⍳</span></code> and the 4-train is interpreted as the atop <code dir="ltr"><span>(</span><span>+</span><span>.</span><span>×</span><span>⍨</span><span>⊢~</span><span>∘.</span><span>×</span><span>⍨</span><span>)(</span><span>1</span><span>↓⍳</span><span>)</span></code>.
Similarly, <code dir="ltr"><span>(</span><span>+</span><span>.</span><span>×</span><span>⍨</span><span>⊢~</span><span>∘.</span><span>×</span><span>⍨</span><span>)</span></code> is also a 4-train and interpreted as the atop <code dir="ltr"><span>+</span><span>.</span><span>×</span><span>⍨</span><span>(</span><span>⊢~</span><span>∘.</span><span>×</span><span>⍨</span><span>)</span></code>. 
</p><p>Thus the accursed train is interpreted as <code dir="ltr"><span>((</span><span>+</span><span>.</span><span>×</span><span>⍨</span><span>(</span><span>⊢~</span><span>∘.</span><span>×</span><span>⍨</span><span>))(</span><span>1</span><span>↓⍳</span><span>))</span><span>17</span></code>. Having read the train, we now evaluate it monadically.
</p>
<div dir="ltr"><pre><span></span>      <span>((</span><span>+</span><span>.</span><span>×</span><span>⍨</span><span>(</span><span>⊢~</span><span>∘.</span><span>×</span><span>⍨</span><span>))(</span><span>1</span><span>↓⍳</span><span>))</span><span>17</span> <span>⍝ Accursed train as an atop over a fork atop a fork</span>
      <span>+</span><span>.</span><span>×</span><span>⍨</span><span>(</span><span>⊢~</span><span>∘.</span><span>×</span><span>⍨</span><span>)</span><span>1</span><span>↓⍳</span><span>17</span>       <span>⍝ Atop evalution</span>
      <span>+</span><span>.</span><span>×</span><span>⍨</span><span>(</span><span>⊢</span><span>1</span><span>↓⍳</span><span>17</span><span>)</span><span>~</span><span>∘.</span><span>×</span><span>⍨</span><span>1</span><span>↓⍳</span><span>17</span>  <span>⍝ Fork evalution</span>
      <span>+</span><span>.</span><span>×</span><span>⍨</span><span>(</span><span>1</span><span>↓⍳</span><span>17</span><span>)</span><span>~</span><span>∘.</span><span>×</span><span>⍨</span><span>1</span><span>↓⍳</span><span>17</span>   <span>⍝ ⊢ evaluation</span>
      <span>+</span><span>.</span><span>×</span><span>⍨</span><span>2</span> <span>3</span> <span>5</span> <span>7</span> <span>11</span> <span>13</span> <span>15</span> <span>17</span> <span>⍝ numbers 2 through 17 without those appearing in their multiplication table are primes</span>
<span>666</span>                           <span>⍝ the sum of the squares of the primes up to 17</span>
</pre></div>
<p>Note that <code dir="ltr"><span>((</span><span>⊢</span><span>⍨∘.</span><span>×</span><span>⍨</span><span>)</span><span>1</span><span>↓⍳</span><span>)</span></code> is a train computing primes up to the given input.
</p><p>A more satisfying variation of the accursed train is the following.
</p>
<div dir="ltr"><pre><span></span>      <span>(</span><span>⍎⊢,⍕</span><span>∘</span><span>≢</span><span>)</span><span>'((+.×⍨⊢~∘.×⍨)1↓⍳)'</span>                    <span>⍝ Accursed train 2.0</span>
      <span>⍎</span><span>(</span><span>⊢,⍕</span><span>∘</span><span>≢</span><span>)</span><span>'((+.×⍨⊢~∘.×⍨)1↓⍳)'</span>                    <span>⍝ 4-train intepreted as an atop</span>
      <span>⍎</span><span>(</span><span>⊢</span><span>'((+.×⍨⊢~∘.×⍨)1↓⍳)'</span><span>)</span><span>,⍕</span><span>∘</span><span>≢</span><span>'((+.×⍨⊢~∘.×⍨)1↓⍳)'</span> <span>⍝ fork evaluation</span>
      <span>⍎</span><span>'((+.×⍨⊢~∘.×⍨)1↓⍳)'</span><span>,</span><span>'17'</span>                      <span>⍝ ⊢ evaluation and ⍕∘≢ evaluation</span>
      <span>⍎</span><span>'((+.×⍨⊢~∘.×⍨)1↓⍳)17'</span>                         <span>⍝ , evaluation</span>
<span>666</span>                                                  <span>⍝ ⍎ executes original Accursed train</span>
</pre></div>
<h2><span id="External_links">External links</span></h2>
<h3><span id="Tutorials">Tutorials</span></h3>
<ul><li>Dyalog: <a rel="nofollow" href="https://help.dyalog.com/16.0/Content/RelNotes14.0/Function%20Trains.htm">version 14.0 release notes</a></li>
<li><a href="https://aplwiki.com/wiki/APL_Cultivation" title="APL Cultivation">APL Cultivation</a>: <a rel="nofollow" href="https://chat.stackexchange.com/rooms/52405/conversation/lesson-23-transcribing-to-and-reading-trains">Transcribing to and reading trains</a></li>
<li><a href="https://aplwiki.com/wiki/APLtrainer" title="APLtrainer">APLtrainer</a>: <a rel="nofollow" href="https://www.youtube.com/watch?v=kt4lMZbn-so">How to read trains in Dyalog APL code</a> (video)</li>
<li><a href="https://aplwiki.com/wiki/APLtrainer" title="APLtrainer">APLtrainer</a>: <a rel="nofollow" href="https://www.youtube.com/watch?v=A2LqqBosvY0">Function trains in APL</a> (video)</li>
<li><a href="https://aplwiki.com/wiki/Dyalog_webinar" title="Dyalog webinar">Dyalog webinar</a>: <a rel="nofollow" href="https://www.youtube.com/watch?v=Enlh5qwwDuY?t=440">Train Spotting in Dyalog APL</a> (video)</li>
<li><a href="https://aplwiki.com/wiki/Dyalog_%2713" title="Dyalog '13">Dyalog '13</a>: <a rel="nofollow" href="https://www.youtube.com/watch?v=7-93GzDqC08">Train Spotting in Version 14.0</a> (video)</li></ul>
<h3><span id="Documentation">Documentation</span></h3>
<ul><li><a rel="nofollow" href="https://help.dyalog.com/16.0/Content/RelNotes14.0/Function%20Trains.htm">Announcement</a></li>
<li><a rel="nofollow" href="https://help.dyalog.com/latest/Content/Language/Introduction/Trains.htm">Dyalog</a></li></ul>
<h2><span id="References">References</span></h2>


<table>
<tbody><tr>
<th colspan="2"><b><big>APL syntax</big></b> [<a rel="nofollow" href="https://aplwiki.com/index.php?title=Template:APL_syntax&amp;action=edit">edit</a>]
</th></tr>
<tr>
<th><a href="https://aplwiki.com/wiki/APL_syntax" title="APL syntax">General</a>
</th>
<td><a href="https://aplwiki.com/wiki/Comparison_with_traditional_mathematics" title="Comparison with traditional mathematics">Comparison with traditional mathematics</a> ∙ <a href="https://aplwiki.com/index.php?title=Precedence&amp;action=edit&amp;redlink=1" title="Precedence (page does not exist)">Precedence</a> ∙ <a>Tacit programming</a>
</td></tr>
<tr>
<th><a href="https://aplwiki.com/wiki/Array" title="Array">Array</a>
</th>
<td><a href="https://aplwiki.com/index.php?title=Numeric_literal&amp;action=edit&amp;redlink=1" title="Numeric literal (page does not exist)">Numeric literal</a> ∙ <a href="https://aplwiki.com/wiki/String" title="String">String</a> ∙ <a href="https://aplwiki.com/wiki/Strand_notation" title="Strand notation">Strand notation</a> ∙ <a href="https://aplwiki.com/index.php?title=Object_literal&amp;action=edit&amp;redlink=1" title="Object literal (page does not exist)">Object literal</a> ∙ <a href="https://aplwiki.com/wiki/Array_notation" title="Array notation">Array notation</a>
</td></tr>
<tr>
<th><a href="https://aplwiki.com/wiki/Function" title="Function">Function</a>
</th>
<td><a href="https://aplwiki.com/wiki/Argument" title="Argument">Argument</a> ∙ <a href="https://aplwiki.com/wiki/Function_valence" title="Function valence">Function valence</a> ∙ <a href="https://aplwiki.com/wiki/Derived_function" title="Derived function">Derived function</a> ∙ <a href="https://aplwiki.com/wiki/Derived_operator" title="Derived operator">Derived operator</a> ∙ <a href="https://aplwiki.com/wiki/Niladic_function" title="Niladic function">Niladic function</a> ∙ <a href="https://aplwiki.com/wiki/Monadic_function" title="Monadic function">Monadic function</a> ∙ <a href="https://aplwiki.com/wiki/Dyadic_function" title="Dyadic function">Dyadic function</a> ∙ <a href="https://aplwiki.com/wiki/Ambivalent_function" title="Ambivalent function">Ambivalent function</a> ∙ <a href="https://aplwiki.com/wiki/Tradfn" title="Tradfn">Tradfn</a> ∙ <a href="https://aplwiki.com/wiki/Dfn" title="Dfn">Dfn</a> ∙ <a href="https://aplwiki.com/wiki/Function_train" title="Function train">Function train</a>
</td></tr>
<tr>
<th><a href="https://aplwiki.com/wiki/Operator" title="Operator">Operator</a>
</th>
<td><a href="https://aplwiki.com/wiki/Operand" title="Operand">Operand</a> ∙ <a href="https://aplwiki.com/wiki/Operator_valence" title="Operator valence">Operator valence</a> ∙ <a href="https://aplwiki.com/wiki/Tradop" title="Tradop">Tradop</a> ∙ <a href="https://aplwiki.com/wiki/Dop" title="Dop">Dop</a> ∙ <a href="https://aplwiki.com/wiki/Derived_operator" title="Derived operator">Derived operator</a>
</td></tr>
<tr>
<th><a href="https://aplwiki.com/index.php?title=Assignment&amp;action=edit&amp;redlink=1" title="Assignment (page does not exist)">Assignment</a>
</th>
<td><a href="https://aplwiki.com/index.php?title=Multiple_assignment&amp;action=edit&amp;redlink=1" title="Multiple assignment (page does not exist)">Multiple</a> ∙ <a href="https://aplwiki.com/index.php?title=Indexed_assignment&amp;action=edit&amp;redlink=1" title="Indexed assignment (page does not exist)">Indexed</a> ∙ <a href="https://aplwiki.com/index.php?title=Selective_assignment&amp;action=edit&amp;redlink=1" title="Selective assignment (page does not exist)">Selective</a> ∙ <a href="https://aplwiki.com/index.php?title=Modified_assignment&amp;action=edit&amp;redlink=1" title="Modified assignment (page does not exist)">Modified</a>
</td></tr>
<tr>
<th>Other
</th>
<td><a href="https://aplwiki.com/wiki/Function_axis" title="Function axis">Function axis</a> ∙ <a href="https://aplwiki.com/wiki/Branch" title="Branch">Branch</a> ∙ <a href="https://aplwiki.com/wiki/Quad_name" title="Quad name">Quad name</a> ∙ <a href="https://aplwiki.com/wiki/System_command" title="System command">System command</a> ∙ <a href="https://aplwiki.com/wiki/User_command" title="User command">User command</a> ∙ <a href="https://aplwiki.com/index.php?title=Keyword&amp;action=edit&amp;redlink=1" title="Keyword (page does not exist)">Keyword</a> ∙ <a href="https://aplwiki.com/index.php?title=Dot_notation&amp;action=edit&amp;redlink=1" title="Dot notation (page does not exist)">Dot notation</a> ∙ <a href="https://aplwiki.com/wiki/Function-operator_overloading" title="Function-operator overloading">Function-operator overloading</a>
</td></tr></tbody></table>
<!-- 
NewPP limit report
Cached time: 20201113092414
Cache expiry: 86400
Dynamic content: false
CPU time usage: 0.439 seconds
Real time usage: 14.465 seconds
Preprocessor visited node count: 606/1000000
Preprocessor generated node count: 1305/1000000
Post‐expand include size: 1601/2097152 bytes
Template argument size: 0/2097152 bytes
Highest expansion depth: 2/40
Expensive parser function count: 0/100
Unstrip recursion depth: 0/20
Unstrip post‐expand size: 26166/5000000 bytes
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00% 10147.365      1 -total
  0.06%    5.898      6 Template:←→
  0.05%    5.146      1 Template:APL_syntax
-->

<!-- Saved in parser cache with key aplwiki:pcache:idhash:487-0!canonical!math=5 and timestamp 20201113092359 and revision id 5726
 -->
</div></div></div>]]>
            </description>
            <link>https://aplwiki.com/wiki/Tacit_programming</link>
            <guid isPermaLink="false">hacker-news-small-sites-25396753</guid>
            <pubDate>Sat, 12 Dec 2020 08:30:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I made a beautiful purple theme for Jupyter Notebooks]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25396553">thread link</a>) | @DataCrayon
<br/>
December 11, 2020 | https://datacrayon.com/posts/tools/jupyter/theme-purple-please-for-jupyter-lab/ | <a href="https://web.archive.org/web/*/https://datacrayon.com/posts/tools/jupyter/theme-purple-please-for-jupyter-lab/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content" role="main">
    <div>
        <!--Body content-->
        
        
<article itemscope="itemscope" itemtype="http://schema.org/Article"><div>
    
        <div>
            <div>
            <div>
                <div>
                <div>
                    <h2>Get the Books</h2>
                    <p>
                    Enjoying these notebooks and want to support the work? Check out the practical books on Data Science, Visualisation, and Evolutionary Algorithms.
                    </p>
                    <p><a href="https://datacrayon.com/shop/product/data-is-beautiful/">Get the books</a>
                </p></div>
                <p><img src="https://datacrayon.com/images/datacrayon/shop/covertops.jpg">
</p>
                </div>
            </div>
            </div>
        </div>
    
    
    <header>

        
        

    </header><div itemprop="articleBody text">
    <!--% if post.meta('has_toc'):-->
    

        

        
            

            
<div>

<div>

<div>
<div>
<h2 id="Installation-through-Jupyter-Lab">Installation through Jupyter Lab<a href="#Installation-through-Jupyter-Lab">¶</a>
</h2>
<p>You can install it through the Jupyter Lab Extension Manager UI, or with the following command:</p>
<p><code>jupyter labextension install @shahinrostami/theme-purple-please</code></p>
<h2 id="GitHub-Repository">GitHub Repository<a href="#GitHub-Repository">¶</a>
</h2>
<p>You can navigate and download the source code at <a href="https://github.com/shahinrostami/theme-purple-please">https://github.com/shahinrostami/theme-purple-please</a>.</p>

</div>
</div>
</div>

</div>




                    <div id="support-this-work-bottom">
                                    <p>Support this work</p>
                                    <p>
        You can support this work by <a href="https://datacrayon.com/shop/">getting the e-books</a>. This notebook will always be available for free in its online format.
        </p>
                                </div>
                            </div>
                            <!-- Modal -->

                            <!-- Modal -->
</div>
                    </article><!--End of body content-->
</div>
</div></div>]]>
            </description>
            <link>https://datacrayon.com/posts/tools/jupyter/theme-purple-please-for-jupyter-lab/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25396553</guid>
            <pubDate>Sat, 12 Dec 2020 07:52:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bit Manipulation with C++20]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25396151">thread link</a>) | @todsacerdoti
<br/>
December 11, 2020 | http://www.modernescpp.com/index.php/bit-manipulation-with-c-20 | <a href="https://web.archive.org/web/*/http://www.modernescpp.com/index.php/bit-manipulation-with-c-20">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="blogContent">
				<p>This post concludes my presentation of library features in C++20. Today I write about the class<code> std::source_location</code> and a few functions for bit manipulation.</p>

<h2 id="h1-std-source-location"><img src="http://www.modernescpp.com/images/blog/Cpp20/BitManipulation/TimelineCpp20CoreLanguage2.png" alt="TimelineCpp20CoreLanguage2" width="650" height="265"><code>std::source_location</code></h2>
<p><code>std::source_location</code> represents information about the source code. This information includes file names, line numbers, and function names. The information is precious when you need information about the call site, such as for debugging, logging, or testing purposes. The class <code>std::source_location</code> is the better alternative for the predefined C++11 macros <code>__FILE__</code> and<code> __LINE__</code> and should, therefore, be used.</p>
<p>The following table shows the interface of <code>std::source_location</code>.</p>
<p><img src="http://www.modernescpp.com/images/blog/Cpp20/BitManipulation/sourceLocation.png" alt="sourceLocation" width="500" height="161"></p>
<p>The call <code>std::source_location::current()</code> creates a new source location object<code> src. sr</code>c represents the information of the call site. Now, no C++ compiler supports <code>std::source_location</code>. Consequently, the following program <code>sourceLocation.cpp</code> is from <a href="https://en.cppreference.com/w/cpp/utility/source_location">cppreference.com/source_location</a>.</p>

<!-- HTML generated using hilite.me -->
<div>
<pre><span>// sourceLocation.cpp</span>
<span>// from cppreference.com</span>

<span>#include &lt;iostream&gt;</span>
<span>#include &lt;string_view&gt;</span>
<span>#include &lt;source_location&gt;</span>
 
<span>void</span> <span>log</span>(std<span>::</span>string_view message,
         <span>const</span> std<span>::</span>source_location<span>&amp;</span> location <span>=</span> std<span>::</span>source_location<span>::</span>current())
{
    std<span>::</span>cout <span>&lt;&lt;</span> <span>"info:"</span>
              <span>&lt;&lt;</span> location.file_name() <span>&lt;&lt;</span> <span>':'</span>
              <span>&lt;&lt;</span> location.line() <span>&lt;&lt;</span> <span>' '</span>
              <span>&lt;&lt;</span> message <span>&lt;&lt;</span> <span>'\n'</span>;
}
 
<span>int</span> <span>main</span>()
{
    log(<span>"Hello world!"</span>);  <span>// info:main.cpp:19 Hello world!</span>
}
</pre>
</div>

<p>The output of the program is part of its source code.</p>
<p>C++20 makes it quite comfortable to access or manipulate bits or bit sequences.</p>
<h2 id="h2-bit-manipulation">Bit Manipulation</h2>
<p>Thanks to the new type std::endian, you get the endianness of a scalar type.</p>
<h3 id="h2-1-endianness">Endianness</h3>
<ul>
<li>Endianness can be big-endian or little-endian. Big-endian means that the most significant byte comes first; little-endian means that the least significant byte comes first.</li>
<li>A scalar type is either an arithmetic type, an <code>enum</code>, a pointer, a member pointer, or a <code>std::nullptr_t</code>.</li>
</ul>
<p>The class <code>endian</code> provides the endianness of all scalar types:</p>
<div>
<pre><span>enum</span> <span>class</span> <span>endian</span>
{
    little <span>=</span> <span>/*implementation-defined*/</span>,
    big    <span>=</span> <span>/*implementation-defined*/</span>,
    native <span>=</span> <span>/*implementation-defined*/</span>
};
</pre>
</div>

<ul>
<li>If all scalar types are little-endian, <code>std::endian::native</code> is equal to <code>std::endian::little</code>.</li>
<li>If all scalar types are big-endian,<code> std::endian::native</code> is equal <code>to std::endian::big</code>.</li>
</ul>
<p>Even corner cases are supported:</p>
<ul>
<li>If all scalar types have <code>sizeof</code> 1 and therefore endianness does not matter; the values of the enumerators <code>std::endian::little</code>, <code>std::endian::big</code>, and <code>std::endian::native</code> are identical.</li>
<li>If the platform uses mixed endianness, <code>std::endian::native</code> is neither equal to <code>std::endian::big</code> nor <code>std::endian::little</code>.</li>
</ul>
<p>When I perform the following program <code>getEndianness.cpp</code> on an x86 architecture, I get the answer little-endian.</p>

<div>
<div>
<div>
<pre><span>// getEndianness.cpp</span>

<span>#include &lt;bit&gt;</span>
<span>#include &lt;iostream&gt;</span>

<span>int</span> <span>main</span>() {

    <span>if</span> constexpr (std<span>::</span>endian<span>::</span>native <span>==</span> std<span>::</span>endian<span>::</span>big) {
        std<span>::</span>cout <span>&lt;&lt;</span> <span>"big-endian"</span> <span>&lt;&lt;</span> <span>'\n'</span>;
    }
    <span>else</span> <span>if</span> constexpr (std<span>::</span>endian<span>::</span>native <span>==</span> std<span>::</span>endian<span>::</span>little) {
        std<span>::</span>cout <span>&lt;&lt;</span> <span>"little-endian"</span>  <span>&lt;&lt;</span> <span>'\n'</span>;      <span>// little-endian</span>
    }

}
</pre>
</div>

<p><a href="https://en.cppreference.com/w/cpp/language/if"><code>constexpr if</code></a> enables it to compile source code conditionally. This means that the compilation depends on the endianness of your architecture. If you want to know more about endianness, read the same-named <a href="https://en.wikipedia.org/wiki/Endianness">Wikipedia page</a>.</p>
</div>
</div>
<h3 id="h2-2-accessing-or-manipulating-bits-or-bit-sequences">Accessing or Manipulating Bits or Bit Sequences</h3>
<p>The following table gives you the first overview of all functions.</p>

<p><img src="http://www.modernescpp.com/images/blog/Cpp20/BitManipulation/bitInterface5.png" alt="bitInterface5" width="600" height="222"></p>

<p>The functions except of <code>std::bit_cast</code> require an unsigned integer type (<code>unsigned char, unsigned short, unsigned int, unsigned long,</code> or<code> unsigned long long</code>).</p>
<p>The program<code> bit.cpp</code> shows the usage of the functions.</p>

<!-- HTML generated using hilite.me -->
<div>
<pre><span>// bit.cpp</span>

<span>#include &lt;bit&gt;</span>
<span>#include &lt;bitset&gt;</span>
<span>#include &lt;iostream&gt;</span>
 
<span>int</span> <span>main</span>() {
    
    std<span>::</span><span>uint8_t</span> num<span>=</span> <span>0</span>b00110010;
    
    std<span>::</span>cout <span>&lt;&lt;</span> std<span>::</span>boolalpha;
    
    std<span>::</span>cout <span>&lt;&lt;</span> <span>"std::has_single_bit(0b00110010): "</span> <span>&lt;&lt;</span> std<span>::</span>has_single_bit(num) 
              <span>&lt;&lt;</span> <span>'\n'</span>;
    
    std<span>::</span>cout <span>&lt;&lt;</span> <span>"std::bit_ceil(0b00110010): "</span> <span>&lt;&lt;</span> std<span>::</span>bitset<span>&lt;</span><span>8</span><span>&gt;</span>(std<span>::</span>bit_ceil(num)) 
              <span>&lt;&lt;</span> <span>'\n'</span>;
    std<span>::</span>cout <span>&lt;&lt;</span> <span>"std::bit_floor(0b00110010): "</span> 
              <span>&lt;&lt;</span> std<span>::</span>bitset<span>&lt;</span><span>8</span><span>&gt;</span>(std<span>::</span>bit_floor(num)) <span>&lt;&lt;</span> <span>'\n'</span>;
    
    std<span>::</span>cout <span>&lt;&lt;</span> <span>"std::bit_width(5u): "</span> <span>&lt;&lt;</span> std<span>::</span>bit_width(<span>5u</span>) <span>&lt;&lt;</span> <span>'\n'</span>;
    
    std<span>::</span>cout <span>&lt;&lt;</span> <span>"std::rotl(0b00110010, 2): "</span> <span>&lt;&lt;</span> std<span>::</span>bitset<span>&lt;</span><span>8</span><span>&gt;</span>(std<span>::</span>rotl(num, <span>2</span>)) 
              <span>&lt;&lt;</span> <span>'\n'</span>;
    std<span>::</span>cout <span>&lt;&lt;</span> <span>"std::rotr(0b00110010, 2): "</span> <span>&lt;&lt;</span> std<span>::</span>bitset<span>&lt;</span><span>8</span><span>&gt;</span>(std<span>::</span>rotr(num, <span>2</span>)) 
              <span>&lt;&lt;</span> <span>'\n'</span>;
    
    std<span>::</span>cout <span>&lt;&lt;</span> <span>"std::countl_zero(0b00110010): "</span> <span>&lt;&lt;</span> std<span>::</span>countl_zero(num) <span>&lt;&lt;</span> <span>'\n'</span>;
    std<span>::</span>cout <span>&lt;&lt;</span> <span>"std::countl_one(0b00110010): "</span> <span>&lt;&lt;</span> std<span>::</span>countl_one(num) <span>&lt;&lt;</span> <span>'\n'</span>;
    std<span>::</span>cout <span>&lt;&lt;</span> <span>"std::countr_zero(0b00110010): "</span> <span>&lt;&lt;</span> std<span>::</span>countr_zero(num) <span>&lt;&lt;</span> <span>'\n'</span>;
    std<span>::</span>cout <span>&lt;&lt;</span> <span>"std::countr_one(0b00110010): "</span> <span>&lt;&lt;</span> std<span>::</span>countr_one(num) <span>&lt;&lt;</span> <span>'\n'</span>;
    std<span>::</span>cout <span>&lt;&lt;</span> <span>"std::popcount(0b00110010): "</span> <span>&lt;&lt;</span> std<span>::</span>popcount(num) <span>&lt;&lt;</span> <span>'\n'</span>;
    
}
</pre>
</div>

<p>Here is the output of the program:</p>
<p><img src="http://www.modernescpp.com/images/blog/Cpp20/BitManipulation/bit2.png" alt="bit2" width="411" height="286"></p>
<p>The next program shows the application and the output of the functions&nbsp;<code>std::bit_floor</code>,<code> std::bit_ceil</code>, <code>std::bit_width</code>, and <code>std::bit_popcount</code> for the numbers 2 to 7.&nbsp;</p>
<!-- HTML generated using hilite.me -->
<div>
<pre><span>// bitFloorCeil.cpp</span>

<span>#include &lt;bit&gt;</span>
<span>#include &lt;bitset&gt;</span>
<span>#include &lt;iostream&gt;</span>
 
<span>int</span> <span>main</span>() {

    std<span>::</span>cout <span>&lt;&lt;</span> std<span>::</span>endl;
    
    std<span>::</span>cout <span>&lt;&lt;</span> std<span>::</span>boolalpha;
    
    <span>for</span> (<span>auto</span> i <span>=</span> <span>2u</span>; i <span>&lt;</span> <span>8u</span>; <span>++</span>i) {
         std<span>::</span>cout <span>&lt;&lt;</span> <span>"bit_floor("</span> <span>&lt;&lt;</span> std<span>::</span>bitset<span>&lt;</span><span>8</span><span>&gt;</span>(i) <span>&lt;&lt;</span> <span>") = "</span> 
                   <span>&lt;&lt;</span> std<span>::</span>bit_floor(i) <span>&lt;&lt;</span> <span>'\n'</span>;

        std<span>::</span>cout <span>&lt;&lt;</span> <span>"bit_ceil("</span> <span>&lt;&lt;</span> std<span>::</span>bitset<span>&lt;</span><span>8</span><span>&gt;</span>(i) <span>&lt;&lt;</span> <span>") = "</span> 
                  <span>&lt;&lt;</span> std<span>::</span>bit_ceil(i) <span>&lt;&lt;</span> <span>'\n'</span>;

        std<span>::</span>cout <span>&lt;&lt;</span> <span>"bit_width("</span> <span>&lt;&lt;</span> std<span>::</span>bitset<span>&lt;</span><span>8</span><span>&gt;</span>(i) <span>&lt;&lt;</span> <span>") = "</span> 
                  <span>&lt;&lt;</span> std<span>::</span>bit_width(i) <span>&lt;&lt;</span> <span>'\n'</span>;
                  
        std<span>::</span>cout <span>&lt;&lt;</span> <span>"bit_popcount("</span> <span>&lt;&lt;</span> std<span>::</span>bitset<span>&lt;</span><span>8</span><span>&gt;</span>(i) <span>&lt;&lt;</span> <span>") = "</span> 
                  <span>&lt;&lt;</span> std<span>::</span>popcount(i) <span>&lt;&lt;</span> <span>'\n'</span>;   
        
        std<span>::</span>cout <span>&lt;&lt;</span> std<span>::</span>endl;
    }
    
    std<span>::</span>cout <span>&lt;&lt;</span> std<span>::</span>endl;
    
}
</pre>
</div>

<p><img src="http://www.modernescpp.com/images/blog/Cpp20/BitManipulation/bitFloorCeil.PNG" alt="bitFloorCeil" width="250" height="644"></p>
<h2 id="h3-what-s-next">What's next?</h2>
<p>Additionally to coroutines, C++20 has much to offer for concurrency First, C++20 has new atomics. The new atomics exists for floating-point values and smart pointers. C++20 also enables waiting on atomics. To coordinate threads, semaphore, latches, and barriers come into play. Also, the <code>std::thread</code> was improved with <code>std::jthread</code>. The execution of a&nbsp;<code>std::jthread </code>can be interrupted and joins automatically in its destructor.<code><br></code></p>

<div>
	<p><strong>Thanks a lot to my <a href="https://www.patreon.com/rainer_grimm">Patreon Supporters</a></strong><strong>: Matt Braun, Roman Postanciuc, Tobias Zindl, Marko, </strong><span title="Emyr Williams"><strong>G Prvulovic, Reinhold Dröge, Abernitzke,</strong> </span><strong><span title="Emyr Williams">Frank Grimm</span></strong><span title="Emyr Williams"><strong>, Sakib, Broeserl, </strong></span><strong><span title="Emyr Williams">António Pina, Darshan Mody, Sergey Agafyin, <span data-tag="user-details-full-name">Андрей Бурмистров, Jake, GS, Lawton Shoemake, Animus24, Jozo Leko, John Breland, espkk, Wolfgang Gärtner</span></span><span title="Emyr Williams"><span><span></span></span></span>,&nbsp; Louis St-Amour, Stephan Roslen, Venkat Nandam, Jose Francisco, Douglas Tinkham, Kuchlong Kuchlong, Avi Kohn, Robert Blanch, Truels Wissneth, Kris Kafka, Mario Luoni, Neil Wang, Friedrich Huber, Sudhakar Balagurusamy, lennonli, and Pramod Tikare Muralidhara.</strong></p>

<p><strong>Thanks in particular to Jon Hess, Lakshman,</strong> <strong>Christian Wittenhorst, Sherhy Pyton, and Dendi Suhubdy<br></strong></p>

<h2>Seminars</h2>
<p>I'm happy to give online-seminars or face-to-face seminars world-wide. Please call me if you have any questions.</p>
<h3>Bookable (Online)</h3>
<h4>Deutsch</h4>
<ul>
<li><a href="https://www.modernescpp.de/index.php/c/2-c/29-embedded-programmierung-mit-modernem-c20201029102414">Embedded Programmierung mit modernem C++:&nbsp; </a>26.01.2021 - 28.01.2021</li>
</ul>
<h4>English</h4>
<ul>
<li><a href="https://www.modernescpp.net/index.php/c/2-c/31-c-20">C++20 - A Deep Insight: </a>Feb. 1. 2021 - Feb. 3. 2021 (16:00 - 20:00 UTC)</li>
</ul>
<h3>Standard Seminars&nbsp;</h3>
<p>Here is a compilation of my standard seminars. These seminars are only meant to give you a first orientation.</p>
<ul>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/22">C++ - The Core Language</a></li>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/23">C++ - The Standard Library</a></li>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/23">C++ - Compact</a></li>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/18">C++11 and C++14</a></li>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/19">Concurrency with Modern C++</a></li>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/21">Design Patterns and Architecture Patterns with C++</a></li>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/17">Embedded Programming with Modern C++</a></li>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/17">Generic Programming (Templates) with C++</a></li>
</ul>
<h4>New</h4>
<ul>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/16">Clean Code with Modern C++</a></li>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/25">C++20</a></li>
</ul>
<h3>Contact Me</h3>
<ul>
<li>Tel.: +49 7472 917441</li>
<li>Mobil: +49 152 31965939</li>
<li>Mail: <a href="http://www.modernescpp.com/%3Ca%20href="><span id="cloak044112edf939f2c5b396478870549978">This email address is being protected from spambots. You need JavaScript enabled to view it.</span></a></li>
<li>German Seminar Page: <a href="https://www.modernescpp.de/">www.ModernesCpp.de</a></li>
<li>English Seminar Page: <a href="http://www.modernescpp.net/">www.ModernesCpp.net</a></li>
</ul>
<h3>Modernes C++,</h3>
<p><img src="http://www.modernescpp.com/images/signatur/RainerGrimmSmall.png" alt="RainerGrimmSmall"></p></div>

			</div></div>]]>
            </description>
            <link>http://www.modernescpp.com/index.php/bit-manipulation-with-c-20</link>
            <guid isPermaLink="false">hacker-news-small-sites-25396151</guid>
            <pubDate>Sat, 12 Dec 2020 06:34:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google Colab Python Notebooks Useful Tips]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25395858">thread link</a>) | @sean_pedersen
<br/>
December 11, 2020 | https://amitness.com/2020/06/google-colaboratory-tips/ | <a href="https://web.archive.org/web/*/https://amitness.com/2020/06/google-colaboratory-tips/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="text">
<p>Colab is one of the best products to come from Google. It has made GPUs freely accessible to learners and practitioners like me who otherwise wouldn’t be able to afford a high-end GPU.</p>
<p>While the interface is very easy to use, there are many lesser-known and undocumented features in colab. In this post, I will share those features that I’ve discovered from basic usage and their official talks.</p>
<h2 id="1-scratchpad-notebook">1. Scratchpad Notebook</h2>
<p>It’s a pretty common scenario that we have a bunch of cluttered untitled notebooks created when we try out temporary stuff on colab.</p>
<p><img src="https://amitness.com/images/colab-clutter.png" alt="Clutter of Untitled Notebooks in Colab"><br>
To solve this, you can bookmark the link given below. It will open a special <strong>scratch notebook</strong> and any changes you make to that notebook are not saved to your main account.</p>
<blockquote>
<p><a href="https://colab.research.google.com/notebooks/empty.ipynb">https://colab.research.google.com/notebooks/empty.ipynb</a></p>
</blockquote>
<h2 id="2-timing-execution-of-cell">2. Timing Execution of Cell</h2>
<p>It’s pretty common that we manually calculate the difference between start and end times of a piece of code to gauge the time taken.</p>
<p>Colab provides an inbuilt feature to do this. After a cell is executed, just hover over the cell run icon and you will get an estimate of the execution time taken.</p>
<p><img src="https://amitness.com/images/colab-cell-hover.png" alt="Execution Time by hovering on run cell"></p>
<h2 id="3-run-part-of-a-cell">3. Run part of a cell</h2>
<p>You can also run only a part of the cell by selecting it and pressing the <code>Runtime &gt; Run Selection</code> button or using the keyboard shortcut <code>Ctrl + Shift + Enter</code>.</p>
<p><img src="https://amitness.com/images/colab-run-few-lines.gif" alt="Running specific line in colab"></p>
<h2 id="4-jupyter-notebook-keyboard-shortcuts">4. Jupyter Notebook Keyboard Shortcuts</h2>
<p>If you are familiar with keyboard shortcuts from Jupyter Notebook, they don’t work directly in Colab. But I found a mental model to map between them.</p>
<p>Just add <code>Ctrl + M</code> before whatever keyboard shortcut you were using in Jupyter. This rule of thumb works for the majority of common use-cases.</p>
<table>
<thead>
<tr>
<th>Action</th>
<th>Jupyter Notebook</th>
<th>Google Colab</th>
</tr>
</thead>
<tbody>
<tr>
<td>Add a cell above</td>
<td>A</td>
<td>Ctrl + <strong>M</strong> + A</td>
</tr>
<tr>
<td>Add a cell below</td>
<td>B</td>
<td>Ctrl + <strong>M</strong> + B</td>
</tr>
<tr>
<td>See all keyboard shorcuts</td>
<td>H</td>
<td>Ctrl + <strong>M</strong> + H</td>
</tr>
<tr>
<td>Change cell to code</td>
<td>Y</td>
<td>Ctrl + <strong>M</strong> + Y</td>
</tr>
<tr>
<td>Change cell to markdown</td>
<td>M</td>
<td>Ctrl + <strong>M</strong> + M</td>
</tr>
<tr>
<td>Interrupt the kernel</td>
<td>II</td>
<td>Ctrl + <strong>M</strong> + I</td>
</tr>
<tr>
<td>Delete a cell</td>
<td>DD</td>
<td>Ctrl + <strong>M</strong> + D</td>
</tr>
<tr>
<td>Checkpoint notebook</td>
<td>Ctrl + S</td>
<td>Ctrl + <strong>M</strong> + S</td>
</tr>
</tbody>
</table>
<p>Below are some notable exceptions to this rule for which either the shortcut is changed completely or kept the same.</p>
<table>
<thead>
<tr>
<th>Action</th>
<th>Jupyter Notebook</th>
<th>Google Colab</th>
</tr>
</thead>
<tbody>
<tr>
<td>Restart runtime</td>
<td>00</td>
<td>Ctrl + <strong>M</strong> + <strong>.</strong></td>
</tr>
<tr>
<td>Run cell</td>
<td>Ctrl + Enter</td>
<td>Ctrl + Enter</td>
</tr>
<tr>
<td>Run cell and add new cell below</td>
<td>Alt + Enter</td>
<td>Alt + Enter</td>
</tr>
<tr>
<td>Run cell and goto the next cell below</td>
<td>Shift + Enter</td>
<td>Shift + Enter</td>
</tr>
<tr>
<td>Comment current line</td>
<td>Ctrl + /</td>
<td>Ctrl + /</td>
</tr>
</tbody>
</table>
<h2 id="5-jump-to-class-definition">5. Jump to Class Definition</h2>
<p>Similar to an IDE, you can go to a class definition by pressing <code>Ctrl</code> and then clicking a class name. For example, here we view the class definition of the Dense layer in Keras by pressing Ctrl and then clicking the <code>Dense</code> class name.</p>
<p><img src="https://amitness.com/images/colab-goto-class.gif" alt="Demo of jumping to class definition"></p>
<h2 id="6-open-notebooks-from-github">6. Open Notebooks from GitHub</h2>
<p>The Google Colab team provides an official chrome extension to open notebooks on GitHub directly on colab. You can install it from <a href="https://chrome.google.com/webstore/detail/open-in-colab/iogfkhleblhcpcekbiedikdehleodpjo">here</a>.</p>
<p>After installation, click the colab icon on any GitHub notebook to open it directly.</p>
<p><img src="https://amitness.com/images/colab-from-github.png" alt="Extension for opening github notebook in colab"></p>
<p>Alternatively, you can also manually open any GitHub notebook by replacing <code>github.com</code> with <code>colab.research.google.com/github</code>.</p>
<blockquote>
<p>https://<strong>github.com</strong>/fastai/course-v3/blob/master/nbs/dl1/00_notebook_tutorial.ipynb</p>
</blockquote>
<p>to</p>
<blockquote>
<p>https://<strong>colab.research.google.com/github</strong>/fastai/course-v3/blob/master/nbs/dl1/00_notebook_tutorial.ipynb</p>
</blockquote>
<p>An even easier way is to replace <code>github.com</code> with <code>githubtocolab.com</code>. It will redirect you to a colab notebook.</p>
<blockquote>
<p>https://<strong>github.com</strong>/fastai/course-v3/blob/master/nbs/dl1/00_notebook_tutorial.ipynb</p>
</blockquote>
<p>to</p>
<blockquote>
<p>https://<strong>githubtocolab.com</strong>/fastai/course-v3/blob/master/nbs/dl1/00_notebook_tutorial.ipynb</p>
</blockquote>
<h2 id="7-run-flask-apps-from-colab">7. Run Flask apps from Colab</h2>
<p>With a library called <a href="https://github.com/gstaff/flask-ngrok">flask-ngrok</a>, you can easily expose a Flask web app running on colab to demo prototypes. First, you need to install <code>flask</code> and <code>flask-ngrok</code>.</p>
<div><div><pre><code><span>!</span><span>pip</span> <span>install</span> <span>flask</span><span>-</span><span>ngrok</span> <span>flask</span><span>==</span><span>0.12</span><span>.</span><span>2</span>
</code></pre></div></div>
<p>Then, you just need to pass your flask app object to <code>run_with_ngrok</code> function and it will expose a ngrok endpoint when the server is started.</p>
<div><div><pre><code><span>from</span> <span>flask</span> <span>import</span> <span>Flask</span>
<span>from</span> <span>flask_ngrok</span> <span>import</span> <span>run_with_ngrok</span>

<span>app</span> <span>=</span> <span>Flask</span><span>(</span><span>__name__</span><span>)</span>
<span>run_with_ngrok</span><span>(</span><span>app</span><span>)</span>

<span>@</span><span>app</span><span>.</span><span>route</span><span>(</span><span>'/'</span><span>)</span>
<span>def</span> <span>hello</span><span>():</span>
    <span>return</span> <span>'Hello World!'</span>

<span>if</span> <span>__name__</span> <span>==</span> <span>'__main__'</span><span>:</span>
    <span>app</span><span>.</span><span>run</span><span>()</span>
</code></pre></div></div>
<p><img src="https://amitness.com/images/colab-flask.png" alt="Example of running flask-ngrok"></p>
<p>You can try this out from the package author’s <a href="https://colab.research.google.com/github/gstaff/flask-ngrok/blob/master/examples/flask_ngrok_example.ipynb">official example</a> on Colab.</p>
<h2 id="8-switch-between-tensorflow-versions">8. Switch between Tensorflow versions</h2>
<p>You can easily switch between Tensorflow 1 and Tensorflow 2 using this magic flag. <br>
To switch to Tensorflow 1.15.2, use this command:</p>

<p>To switch to Tensorflow 2.2, run this command:</p>

<p>You will need to restart the runtime for the effect to take place. Colab recommends using the pre-installed Tensorflow version instead of installing it from <code>pip</code> for performance reasons.</p>
<h2 id="9-tensorboard-integration">9. Tensorboard Integration</h2>
<p>Colab also provides a magic command to use Tensorboard directly from the notebook. You just need to set the logs directory location using the <code>--logdir</code> flag. You can learn to use it from the <a href="https://colab.research.google.com/github/tensorflow/tensorboard/blob/master/docs/tensorboard_in_notebooks.ipynb">official notebook</a>.</p>
<div><div><pre><code><span>%</span><span>load_ext</span> <span>tensorboard</span>
<span>%</span><span>tensorboard</span> <span>--</span><span>logdir</span> <span>logs</span>
</code></pre></div></div>
<p><img src="https://amitness.com/images/colab-tensorboard.png" alt="Embedded Tensorboard in Colab"></p>
<h2 id="10-gauge-resource-limits">10. Gauge resource limits</h2>
<p>Colab provides the following specs for their free and pro versions. Based on your use case, you can switch to the pro version at $10/month if you need a better runtime, GPU, and memory.</p>
<table>
<thead>
<tr>
<th>Version</th>
<th>GPU</th>
<th>GPU Ram</th>
<th>RAM</th>
<th>Storage</th>
<th>CPU Cores</th>
<th>Idle Timeout</th>
<th>Maximum Runtime</th>
</tr>
</thead>
<tbody>
<tr>
<td>Free</td>
<td>Tesla K80</td>
<td>11.44GB</td>
<td>13.7GB</td>
<td>37GB</td>
<td>2</td>
<td>90 min</td>
<td>12 hrs</td>
</tr>
<tr>
<td>Pro</td>
<td>Tesla P100</td>
<td>16GB</td>
<td>27.4GB</td>
<td>37GB</td>
<td>4</td>
<td>90 min</td>
<td>24 hrs</td>
</tr>
</tbody>
</table>
<p>You can view the GPU you have been assigned by running the following command</p>

<p>For information on the CPU, you can run this command</p>

<p>Similarly, you can view the RAM capacity by running</p>
<div><div><pre><code><span>import</span> <span>psutil</span>
<span>ram_gb</span> <span>=</span> <span>psutil</span><span>.</span><span>virtual_memory</span><span>().</span><span>total</span> <span>/</span> <span>1e9</span>
<span>print</span><span>(</span><span>ram_gb</span><span>)</span>
</code></pre></div></div>
<h2 id="11-use-interactive-shell">11. Use interactive shell</h2>
<p>There is no built-in interactive terminal in Colab. But you can use the <code>bash</code> command to try out shell commands interactively. Just run this command and you will get an interactive input.</p>

<p>Now, you can run any shell command in the given input box.</p>
<p><img src="https://amitness.com/images/colab-bash.png" alt="Using interactive shell in colab"></p>
<p>To quit from the shell, just type <code>exit</code> in the input box.</p>
<p><img src="https://amitness.com/images/colab-bash-exit.png" alt="Exiting interactive shell in colab"></p>
<h2 id="12-current-memory-and-storage-usage">12. Current memory and storage usage</h2>
<p>Colab provides an indicator of RAM and disk usage. If you hover over the indicator, you will get a popup with the current usage and the total capacity.</p>
<p><img src="https://amitness.com/images/colab-ram-usage.png" alt="Showing current memory and ram usage in colab"></p>
<h2 id="13-open-in-colab-badge">13. “Open in Colab” Badge</h2>
<p>You can add a ‘Open in Colab’ badge to your <code>README.md</code> or jupyter notebooks using the following markdown code.<br>
<img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></p>
<p>In the markdown code, we’re loading an SVG image and then linking it to a colab notebook.</p>
<div><div><pre><code><span>[</span><span>![Open In Colab</span><span>](</span><span>https://colab.research.google.com/assets/colab-badge.svg</span><span>)</span>](https://colab.research.google.com/notebooks/basic_features_overview.ipynb)
</code></pre></div></div>
<h2 id="14-interactive-tables-for-pandas">14. Interactive Tables for Pandas</h2>
<p>Colab provides a notebook extension to add interactive sorting and filtering capabilities to pandas dataframes. To use it, run the following code.</p>
<div><div><pre><code><span>%</span><span>load_ext</span> <span>google</span><span>.</span><span>colab</span><span>.</span><span>data_table</span>
</code></pre></div></div>
<p>You can see the regular pandas dataframe and the interactive dataframe after loading the extension below.<br>
<img src="https://amitness.com/images/pandas-table-before.png" alt="Regular pandas dataframe output"><br>
<img src="https://amitness.com/images/colab-pandas-after.png" alt="Interactive pandas dataframe output"></p>
<h2 id="15-setup-conda-environment">15. Setup Conda environment</h2>
<p>If you use miniconda as your python environment manager, you can setup it on colab by running these commands at the top of your notebook.</p>
<div><div><pre><code><span># Download Miniconda installation script</span>
<span>!</span>wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh

<span># Make it executable</span>
<span>!</span><span>chmod</span> +x Miniconda3-latest-Linux-x86_64.sh

<span># Start installation in silent mode</span>
<span>!</span>bash ./Miniconda3-latest-Linux-x86_64.sh <span>-b</span> <span>-f</span> <span>-p</span> /usr/local

<span># Make conda packages available in current environment</span>
import sys
sys.path.append<span>(</span><span>'/usr/local/lib/python3.7/site-packages/'</span><span>)</span>
</code></pre></div></div>
<p>After the cell is executed, you can use conda to install packages as usual.</p>

<h2 id="16-manage-colab-notebooks-from-command-line">16. Manage Colab Notebooks from Command Line</h2>
<p>You can use a library called <a href="https://github.com/Akshay090/colab-cli">colab-cli</a> to easily create and sync colab notebooks with your local notebooks.</p>
<p><a href="https://asciinema.org/a/314749"><img src="https://asciinema.org/a/314749.svg" alt="colab-cli-demo"></a></p>
<h2 id="17-run-background-tasks">17. Run background tasks</h2>
<p>There are use-cases when we need to start some web server or background tasks before we can execute our regular program.</p>
<p>To run background tasks, use the <code>nohup</code> command followed by your regular shell command and add <code>&amp;</code> to the end to run it in the background. This makes sure that you can run cells afterward in the notebook without your background task blocking it.</p>

<h2 id="18-notify-on-training-completion">18. Notify on Training Completion</h2>
<p>If you’re running a long task such as training a model, you can setup Colab to send a desktop notification once it’s completed.</p>
<p>To enable that, goto Tools ⮕ Settings ⮕ Site and enable <code>Show desktop notifications</code> checkbox.</p>
<p><img src="https://amitness.com/images/colab-notification.png" alt=""></p>
<p>You will get a popup to enable browser notification. Just accept it and colab will notify you on task completion even if you are on another tab, window or application.</p>
<h2 id="19-run-javascript-code">19. Run javascript code</h2>
<p>You can run javascript code by using the <code>%%javascript</code> magic command.</p>
<p><img src="https://amitness.com/images/colab-javascript.png" alt=""></p>
<h2 id="20-run-vscode-on-colab">20. Run VSCode on Colab</h2>
<p>You can run a full-fledged VSCode editor on Colab by following the method I have explained in another <a href="https://amitness.com/vscode-on-colab/">article</a>.</p>
<p><img src="https://amitness.com/images/colab-code-step-3.png" alt=""></p>
<h2 id="21-custom-snippets">21. Custom snippets</h2>
<p>You can save your own collections of useful snippets and access them easily in any colab notebook.</p>
<ul>
<li>
<p>Create a colab notebook called <code>snippets.ipynb</code>. To add each of your snippets, create a markdown cell and add name of the snippet as header. Below, the markdown cell, add a code cell with the snippet code.</p>
<p><img src="https://amitness.com/images/custom-snippets-step-1.png" alt=""></p>
</li>
<li>
<p>Copy the link of this notebook from the browser tab.</p>
<p><img src="https://amitness.com/images/custom-snippets-step-2.png" alt=""></p>
</li>
<li>
<p>Click <code>Tools &gt; Settings</code> in your menu bar to open preference of colab.<br>
<img src="https://amitness.com/images/custom-snippets-step-3.png" alt=""></p>
</li>
<li>
<p>Paste the link into the <code>Custom snippet notebook URL</code> textbox and click save.</p>
</li>
</ul>
<p><img src="https://amitness.com/images/custom-snippets-step-4.png" alt=""></p>
<ul>
<li>Now, the snippets are available in any colab notebook you use. Just click the <strong>&lt;&gt;</strong> icon on sidebar, search for your snippet name and click <strong>Insert</strong>. The code will be inserted into a new cell.</li>
</ul>
<p><img src="https://amitness.com/images/custom-snippets-usage.gif" alt=""></p>
<h2 id="22-run-jupyterlab-on-google-colab">22. Run JupyterLab on Google Colab</h2>
<p>You can start a JupyterLab instance on colab by running the following commands in a cell.</p>
<div><div><pre><code><span>!</span><span>pip</span> <span>install</span> <span>jupyterlab</span> <span>pyngrok</span> <span>-</span><span>q</span>

<span># Run jupyterlab in the background
</span><span>!</span><span>nohup</span> <span>jupyter</span> <span>lab</span> <span>--</span><span>ip</span><span>=</span><span>0.0</span><span>.</span><span>0.0</span> <span>&amp;</span>

<span># Get ngrok URL mapped to port 8888
</span><span>from</span> <span>pyngrok</span> <span>import</span> <span>ngrok</span>
<span>print</span><span>(</span><span>ngrok</span><span>.</span><span>connect</span><span>(</span><span>8888</span><span>))</span>
</code></pre></div></div>
<p>Once executed, click the printed ngrok URL to access the JupyterLab interface.</p>
<p><img src="https://amitness.com/images/colab-jupyterlab.png" alt=""></p>
<h2 id="references">References</h2>
<ul>
<li>Timothy Novikoff, <a href="https://www.youtube.com/watch?v=pnClcwTCyc0">“Making the most of Colab (TF Dev Summit ‘20)”</a></li>
<li>Gal Oshri, <a href="https://www.youtube.com/watch?v=xM8sO33x_OU">“What’s new in TensorBoard (TF Dev Summit ‘19)”</a></li>
</ul>
</section></div>]]>
            </description>
            <link>https://amitness.com/2020/06/google-colaboratory-tips/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25395858</guid>
            <pubDate>Sat, 12 Dec 2020 05:33:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Time Flows Toward Order]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25395794">thread link</a>) | @akeck
<br/>
December 11, 2020 | http://m.nautil.us/issue/93/forerunners/time-flows-toward-order | <a href="https://web.archive.org/web/*/http://m.nautil.us/issue/93/forerunners/time-flows-toward-order">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
			<p><span>T</span>he one law of physics that virtually all scientists believe will never be found to be wrong is the second law of thermodynamics. Despite this exalted status, it has long been associated with a great mystery and a bleak implication. The mystery is that all the known laws of nature except one do not distinguish a temporal direction. The second law, however, asserts the existence of an all-powerful unidirectionality in the way all events throughout the universe unfold. According to standard accounts, the second law says that entropy, described as a measure of disorder, will always (with at most small fluctuations) increase. That’s the rub: Time has an arrow that points to heat death.</p><p>Surprisingly, evidence that a more nuanced account is needed is hiding in plain sight: the universe itself. Very soon after the Big Bang, the universe was in an extremely uniform state, which since then has become ever more varied and structured. Even if uniformity equates to order, that initial state was surely bland and dull. And who can see disorder in the fabulously structured galaxies or the colors and shapes of the trees in the fall? In fact, the sequence in which two of the greatest discoveries in science were made resolves the paradox: The second law was discovered eight decades before the expansion of the universe.</p><figure data-alt="Barbour_BREAKER"><img src="http://static.nautil.us/17977_f1b4a1e8b4c12f7c7f2e390c76b4cc12.png" width="733" alt=""><figcaption><span><strong>BOTH SIDES NOW:</strong> Two people walking down opposite sides of Mount Fuji would see the terrain change in much the same way. To author Julian Barbour, the hikers’ perceptions offers an apt analogy for how beings on either side of what he calls a “Janus Point” in the universe would experience moving orderly in time.</span><span>Martina Badini / Shutterstock</span></figcaption></figure><p>The time lag is critical for one simple reason. The laws of thermodynamics, discovered in 1850 by William Thomson (later ennobled to Lord Kelvin) and Rudolf Clausius, emerged from a brilliant study that Sadi Carnot (son of Napoleon’s greatest general) published in 1824. In a slim booklet that laid out all but one of the foundational principles of thermodynamics, he sought to establish the maximum efficiency steam engines could achieve. Steam engines can only function if their working medium is confined in a cylinder. This led all early work on thermodynamics to be based on systems in a conceptual box. Clausius’s discovery and definition of entropy—one of the wonders of science—relied totally on infinitesimal changes from one equilibrium state of a confined system to another. The pioneers of statistical mechanics, the theoretical framework created above all by Clausius, James Clerk Maxwell, and Ludwig Boltzmann to provide a microscopic atomistic explanation of phenomenological thermodynamics, invariably considered models of gas molecules trapped in a box and forced to bounce off its walls and each other.<br></p><p>A rich conceptual framework, completely valid and immensely fruitful for confined systems, developed out of this simple model, and reached its definitive form in the work of J. Willard Gibbs. The model proved the existence of atoms and molecules, established their sizes, determined the incredible number of them in a grain of sand, and struck the death knell of Newtonian classical physics. That was when Planck discovered the first quantum effect in 1900. What’s more, both the first and second law appeared to be founded on a rock-solid principle: the impossibility of creating perpetual motion machines.</p><blockquote><p>I don’t deny the arrow of time. But the “box mentality” has led us to misunderstand what is happening in the universe.</p> </blockquote><p>It’s therefore not surprising that few, if any, scientists have disagreed with the great astrophysicist Arthur Eddington’s warning, “If your theory is found to be against the second law of thermodynamics I can give you no hope; there is nothing for it but to collapse in deepest humiliation.” Einstein, surely a greater scientist than Eddington, was more cautious. A few years before his death, Einstein said of thermodynamics, “It is the only physical theory of universal content which I am convinced that, within the framework of applicability of its basic concepts, will never be overthrown.” The caveat is all important: Do conditions in an expanding universe remain within the framework of applicability?<br></p><p>That is what I question. I don’t suggest we can ever alter the facts that Thomson and Clausius first brought to light. Neither you nor I are going to get younger or see a shattered cup miraculously reassemble itself and jump back onto the table. There is a pervasive unidirectionality, an arrow of time, about the way things happen in the universe. Kelvin, the first to recognize its significance, called it “a universal tendency in nature to the dissipation of mechanical energy.” I don’t deny the existence of the arrow, but I do suggest that the “box mentality” has led us to misunderstand what is happening in the universe and even blinded us to the beauty that it is creating. A one-way street need not lead to a scrap yard; it might bring us to a finely landscaped park.</p><p>Compare two situations. First, the molecules in their box. If, every now and then, you open it to look at them, you can be sure to find them filling the box uniformly and going through their habitual routine—bumping into each other with random outcomes. Nothing of interest develops. This, nevertheless, was the model used to interpret mundane measurements of pressure and temperature. It led to all those marvelous discoveries and much of the technology on which today we so depend. No wonder it inspired confidence.</p><p>But now picture the box in space with its walls suddenly removed. What will the molecules do? The answer’s in Siegfried Sassoon’s poem “Everyone Sang”:</p><p>As prisoned birds must find in freedom, Winging wildly across the white<br>Orchards and dark-green fields; on – on – and out of sight.</p><p>In mathematical rather than poetic terms, the molecules soon cease to interact and fly apart, maintaining forever their release velocities and getting ever further from each other. In fact, a simple calculation may surprise you: The speed with which the molecules move apart approximates ever better the law of galactic recession that Hubble announced in 1929. This simple Big Bang model does not look like disorder on the increase.</p><p><span>T</span>here is a greater mismatch between entropic disorder and reality in the very heart of Newton’s theory of universal gravitation. He achieved fame by explaining not only Kepler’s laws of planetary motion but also the fall of an apple. However, the problem of three bodies—he had in mind the earth, sun, and moon moving in their mutual gravitational fields—gave him headaches. Although a famously difficult problem, in 1772 the great mathematician Joseph-Louis Lagrange made some progress, including a significant discovery about the behavior of a “three-body universe” that was later shown to be true for any number of bodies. It concerns what is now called the center-of-mass moment of inertia, <i>I</i>. This measures the extent of the system—for bees it would be about the diameter of a swarm—and behaves in a characteristic universal way if a single condition is satisfied: The total energy of the system is not negative.</p><blockquote><p>The beauty is in the ratios, and they persist forever even in the expanding universe.</p> </blockquote><p>To understand what the behavior is, assume with Newton that time flows forever forward from past to future. Then what Lagrange found is that <i>I</i> decreases from infinity in the distant past, passes through a unique minimum, and grows to infinity in the distant future. I call this unique minimum a Janus Point. The Roman divinity can be invoked because he looks simultaneously in two opposite directions of time at once. What he sees is striking. In the region around the threshold on which he traditionally stands, the distribution of the particles (especially when there are many) is more uniform than anywhere else on the timeline of the universe. Then, in both directions, the particles cluster, taking on a shape that is more ordered and forming “galaxies.” From his vantage point, Janus can see this, but if you, being a mere mortal, were in such a universe you would necessarily be on one or the other side of the Janus point and could not “see through it” to the other side. You would find that the laws of nature around you do not distinguish a direction of time but that your universe gets ever more clumpy in one direction.</p><p>There is a precise, mathematically significant quantity that may be called complexity and increases (with small fluctuations) in both directions from Janus. The big difference from what entropy does is that growth of complexity reflects an increase of order, not disorder. The effects in confined and unconfined systems are the exact opposites of each other. Moreover, the increase of complexity in unconfined systems follows directly from the governing dynamical law whereas entropy increases in confined systems for statistical reasons.</p><div>
<article>
<p><a href="http://m.nautil.us/issue/41/Selection/how-einstein-and-schrdinger-conspired-to-kill-a-cat" data-trval="how-einstein-and-schrdinger-conspired-to-kill-a-cat" data-trlbl="foc_rec" data-tract="internal_art">
<img src="http://static.nautil.us/10620_89fee0513b6668e555959f5dc23238e9.png" alt="Sapolsky_TH-F1" width="314" height="177">
</a>
</p>


</article>
</div><p>Traditional arguments assume that somehow, for an as yet unfathomable reason, the universe gets in a special state of low entropy and correspondingly high order that is then remorselessly destroyed. A model often given is molecules confined to a little box in the corner of a big box. That’s the special initial condition. Now lift the lid of the little box; the laws of dynamics allow two quite different outcomes. It’s conceivable, but barely so, that the molecules will collect in the corner of the little box and then be in an even more special state. But it is statistically more likely that the molecules will spread out into the large box and eventually fill it uniformly. This is a statistical explanation of the entropic arrow. Applied to the whole universe, a special initial condition of this kind has been dubbed the “Past Hypothesis” by the philosopher of science David Albert. The difficulty is that nothing in the known laws of nature explains the special initial condition.</p><p><span>L</span>et’s now think about the Janus point. It’s unique and a special point. It isn’t there for some …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://m.nautil.us/issue/93/forerunners/time-flows-toward-order">http://m.nautil.us/issue/93/forerunners/time-flows-toward-order</a></em></p>]]>
            </description>
            <link>http://m.nautil.us/issue/93/forerunners/time-flows-toward-order</link>
            <guid isPermaLink="false">hacker-news-small-sites-25395794</guid>
            <pubDate>Sat, 12 Dec 2020 05:15:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Regex literals optimization (or how to cheat on benchmarks)]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25395709">thread link</a>) | @nitely
<br/>
December 11, 2020 | https://nitely.github.io/2020/11/30/regex-literals-optimization.html | <a href="https://web.archive.org/web/*/https://nitely.github.io/2020/11/30/regex-literals-optimization.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>The regex literals optimization avoids running the regex engine on parts of the input text that cannot possibly ever match the regex.</p>

<p>An example of a regex this can be applied to is <code>\w+@\w+\.\w+</code>, where the algorithm <em>quickly</em> finds the first <code>@</code>, then matches <code>\w+</code> backwards to find the start of the match, and then matches <code>\w+\.\w+</code> forward to find the end of the match. It then finds the second <code>@</code>, starting from the end of the previous match, and so on. This is a fairly naive (and incorrect) implementation, but it gives the idea of how it works.</p>

<p>I’ve recently implemented it in my pet project <a href="https://github.com/nitely/nim-regex/pull/68">nim-regex</a>, an NFA based regex engine that runs in (super)linear time. The results show it’s around ~100x faster than before in some benchmarks. It’s up to ~60x faster than PCRE when the optimization kicks in. The tests are based on <a href="https://github.com/mariomka/regex-benchmark">mariomka/regex-benchmark</a>.</p>

<p>This is not to be confused with <em>Chivers’ String Prefix Optimization</em>.</p>

<h2 id="literals-optimization">Literals Optimization</h2>

<p>Since nim-regex has to guarantee linear time, I’ll describe optimizations that are guaranteed to take linear time. We must also ensure the matches are not overlapped.</p>

<p>Here’s a high-level description of the algorithm:</p>

<ul>
  <li>We pick a literal that is <code>memchr</code>‘ed to skip parts of the text.</li>
  <li>The prefix is the regex part before the literal; none of the
characters or symbols within the prefix must match the literal.</li>
  <li>The prefix is ran backwards to find the start of the match.</li>
  <li>A full scan is ran from the start of the match
until a character that cannot be matched is found (safe break point)
or the end is reached. The scan tries to start the match at every character (NFAs can do this in linear time).</li>
  <li>Go to step one and repeat from the last scanned char. Make the prefix
match until the previous last scanned char.</li>
</ul>

<p>There are two important constraints to picking a literal:</p>

<ul>
  <li><em>“none of the characters or symbols within the prefix must match the literal”</em>, why? consider the regex: <code>\d\w+x</code>, and the input text: <code>xxxxxxxxxxx</code>; this would take quadratic time, as the prefix will match until the start of the string every time. What about the limit? while the limit does avoid the excessive matching, sometimes we’d need to match past the limit, ex: regex: <code>\d\w+x</code>, and text: <code>1xxx</code>. If we add this constraint, the literal becomes a delimeter, and these cases are solved.</li>
  <li>The literal cannot be part of a repetition, nor it can be part of an alternation. For example: <code>(abc)*def</code> the first literal candidate is <code>d</code>, since <code>(abc)*</code> may or may not be part of the match. Same thing for alternations.</li>
</ul>

<p>Here’s the main algorithm in <a href="https://nim-lang.org/">Nim</a>:</p>

<figure><pre><code data-lang="nim"><span>func</span> <span>findAll</span><span>(</span>
  <span>matches</span><span>:</span> <span>var</span> <span>Matches</span><span>,</span>
  <span>text</span><span>:</span> <span>string</span><span>,</span>
  <span>regex</span><span>:</span> <span>Regex</span><span>,</span>
  <span>start</span><span>:</span> <span>int</span>
<span>):</span> <span>int</span> <span>=</span>
  <span>var</span> <span>i</span> <span>=</span> <span>start</span>
  <span>var</span> <span>limit</span> <span>=</span> <span>start</span>
  <span>while</span> <span>i</span> <span>&lt;</span> <span>text</span><span>.</span><span>len</span><span>:</span>
    <span>limit</span> <span>=</span> <span>i</span>  <span># rather pointless since the literal is a delimiter</span>
    <span>i</span> <span>=</span> <span>memchr</span><span>(</span><span>text</span><span>,</span> <span>regex</span><span>.</span><span>lit</span><span>,</span> <span>i</span><span>)</span>
    <span>if</span> <span>i</span> <span>==</span> <span>-</span><span>1</span><span>:</span>
      <span>return</span> <span>-</span><span>1</span>
    <span>var</span> <span>litIdx</span> <span>=</span> <span>i</span>
    <span>i</span> <span>=</span> <span>matchPrefix</span><span>(</span><span>text</span><span>,</span> <span>regex</span><span>,</span> <span>i</span><span>,</span> <span>limit</span><span>)</span>
    <span>if</span> <span>i</span> <span>==</span> <span>-</span><span>1</span><span>:</span>
      <span>i</span> <span>=</span> <span>litIdx</span><span>+</span><span>1</span>
    <span>else</span><span>:</span>
      <span>i</span> <span>=</span> <span>findSome</span><span>(</span><span>matches</span><span>,</span> <span>text</span><span>,</span> <span>regex</span><span>,</span> <span>i</span><span>)</span>
      <span>if</span> <span>i</span> <span>==</span> <span>-</span><span>1</span><span>:</span>
        <span>return</span> <span>-</span><span>1</span>
      <span>if</span> <span>matches</span><span>.</span><span>len</span> <span>&gt;</span> <span>0</span><span>:</span>
        <span>return</span> <span>i</span>  <span># this is used as "start" to resume the matching</span>
  <span>return</span> <span>-</span><span>1</span></code></pre></figure>

<p>A given character may be consumed only twice, once by the backward prefix match, and a second time by the forward scan. Hence the algorithm runs in linear time.</p>

<p>I may describe how <code>matchPrefix</code> and <code>findSome</code> work, how to construct the reversed NFA in the right order, and how to pick the literal in a future article. The nim-regex code contains descriptions of the algorithms, though.</p>

<h2 id="benchmarks">Benchmarks</h2>

<p>The <a href="https://github.com/nitely/nim-regex/tree/master/bench">benchmarks</a> regexes are based on <a href="https://github.com/mariomka/regex-benchmark">mariomka/regex-benchmark</a>. The only difference is the regexes are pre-compiled, so just the matching is tested. The results show nim-regex is ~63x faster than PCRE in the email test, and ~2x faster in the URI and IP tests.</p>

<p>Why is nim-regex so fast in the email case? The regex engine doesn’t run as often. There are orders of magnitud more IP/URI candidates than email candidates (<code>@</code> chars within the text) to match. In the former case the time is dominated by the regex engine, while in the latter case it’s dominated by searching the char literal.</p>

<div><div><pre><code>==================================================
GlobalBenchmark       relative  time/iter  iters/s
==================================================
GlobalBenchmark                  294.86ps    3.39G
==================================================
bench.nim             relative  time/iter  iters/s
==================================================
pcre_email                        21.76ms    45.96
nim_regex_email       3247.14%   670.02us    1.49K
nim_regex_email_macro 6335.93%   343.38us    2.91K
pcre_uri                          22.15ms    45.14
nim_regex_uri           92.82%    23.87ms    41.90
nim_regex_uri_macro    256.29%     8.64ms   115.68
pcre_ip                            5.73ms   174.58
nim_regex_ip            88.70%     6.46ms   154.84
nim_regex_ip_macro     214.75%     2.67ms   374.91
</code></pre></div></div>

<blockquote>
  <p>Note Nim’s PCRE is at the top of the mariomka/regex-benchmark. I ran those benchmarks, and IIRC nim-regex was just a bit faster, mainly because the non-macro regex engine is slower (see the above results), and the regex compilation is also tested.</p>
</blockquote>

<h2 id="other-optimizations">Other optimizations</h2>

<p>Here are other possible optimizations:</p>

<ul>
  <li>Picking a literal —even if the prefix matches it— should take linear time as long as the prefix is bounded (i.e: does not contain repetitions), ex: <code>\d\wx</code>.</li>
  <li>Picking a literal within a “one or more” repetition/repetition group should be possible, since <code>(abc)+</code> matches the same as <code>abc(abc)*</code>.</li>
  <li>It’s better to pick the last literal within the first literal sequence, since that way we always try to match as many literals as possible early on, and potentially fail early. We want to keep the prefix regex as short as possible, so the picking a literal in the first sequence is best.</li>
  <li>Alternations can be optimized this very same way in some cases, ex: <code>bar|baz</code>, since both alternations have <code>ba</code> in common, <code>a</code> can be picked as the literal.</li>
  <li>Alternations can be optimized in other cases. PCRE seems to use <code>memchr</code> or similar for up to two alternation terms. A DFA could be used to quickly match candidates instead of <code>memchr</code>, as that’s a more general solution.</li>
</ul>

<h2 id="conclusion">Conclusion</h2>

<p>Literals optimization is not a general optimization as it does not work on every regex, but when it does, it can greatly improve the matching speed.</p>

<p>Can a backtracker like PCRE implement this? PCRE in particular already has some sort of similar optimization, but it’s not as good/fast as this one. Backtrackers cannot implement this as described here exactly, but they can do something similar that requires backtracking. If they provide a resumable <code>find</code> function, then probably yes.</p>

<p>Hopefully, more regex engines will implement these sort of optimizations, so they are more compelling alternatives to backtrackers such as PCRE.</p>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://nitely.github.io/2020/11/30/regex-literals-optimization.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25395709</guid>
            <pubDate>Sat, 12 Dec 2020 04:59:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Amazon owns more than $2B worth of IPv4 addresses]]>
            </title>
            <description>
<![CDATA[
Score 142 | Comments 122 (<a href="https://news.ycombinator.com/item?id=25395432">thread link</a>) | @dangoldin
<br/>
December 11, 2020 | https://dangoldin.com/2020/12/11/amazon-owns-more-than-2b-worth-of-ipv4-addresses/ | <a href="https://web.archive.org/web/*/https://dangoldin.com/2020/12/11/amazon-owns-more-than-2b-worth-of-ipv4-addresses/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
  <article>
    

    <section>
      
<p>While listening to a <a href="https://softwareengineeringdaily.com/2020/12/02/bgp-with-andree-toonk/">podcast discussing BGP</a> I heard the fact that AWS owns more than $2B worth of IP addresses. I knew AWS was massive but this came as a big shock so I decided to do some digging around. I came across a <a href="https://ipv4marketgroup.com/ipv4-pricing/">site</a> that listed the market prices of IP addresses and the range looks to be anywhere from $20 to $30 per IP depending on the block size. Now it was time to figure out the IP addresses owned by Amazon. I figured this would be difficult but lucky for us AWS actually <a href="https://ip-ranges.amazonaws.com/ip-ranges.json">publishes</a> their entire set of IP addresses as JSON.</p>

<p>The work is simply to download the JSON and then convert the CIDR blocks to the number of IPs and add them all up. As of today, December 11, 2020 AWS self reports owning 109,847,486 IPV4 addresses - at a price of $20 this is almost $2.2B and at $30 it’s almost $3.3B. That’s wild.</p>

<figure><pre><code data-lang="python"><span>import</span> <span>urllib.request</span>
<span>import</span> <span>json</span>

<span>with</span> <span>urllib</span><span>.</span><span>request</span><span>.</span><span>urlopen</span><span>(</span><span>' https://ip-ranges.amazonaws.com/ip-ranges.json'</span><span>)</span> <span>as</span> <span>f</span><span>:</span>
    <span>j</span> <span>=</span> <span>json</span><span>.</span><span>loads</span><span>(</span><span>f</span><span>.</span><span>read</span><span>().</span><span>decode</span><span>(</span><span>'utf-8'</span><span>))</span>

<span>print</span><span>(</span><span>'All keys'</span><span>,</span> <span>j</span><span>.</span><span>keys</span><span>())</span>

<span>print</span><span>(</span><span>'IPV4 prefixes'</span><span>,</span> <span>len</span><span>(</span><span>j</span><span>[</span><span>'prefixes'</span><span>]))</span>

<span>ips</span> <span>=</span> <span>0</span>
<span>for</span> <span>prefix</span> <span>in</span> <span>j</span><span>[</span><span>'prefixes'</span><span>]:</span>
    <span>cidr</span> <span>=</span> <span>int</span><span>(</span><span>prefix</span><span>[</span><span>'ip_prefix'</span><span>].</span><span>split</span><span>(</span><span>'/'</span><span>)[</span><span>1</span><span>])</span>
    <span>ips</span> <span>+=</span> <span>2</span><span>**</span><span>(</span><span>32</span><span>-</span><span>cidr</span><span>)</span>

<span>print</span><span>(</span><span>'# IPS'</span><span>,</span> <span>ips</span><span>)</span></code></pre></figure>

    </section>

    
    <br>
    

    

    

    

  </article>
</div></div>]]>
            </description>
            <link>https://dangoldin.com/2020/12/11/amazon-owns-more-than-2b-worth-of-ipv4-addresses/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25395432</guid>
            <pubDate>Sat, 12 Dec 2020 04:08:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Launching an open start up Interviewing SaaS Business Owners]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25394221">thread link</a>) | @hustld
<br/>
December 11, 2020 | https://hustld.com/blog/launching-an-open-start-up-journey | <a href="https://web.archive.org/web/*/https://hustld.com/blog/launching-an-open-start-up-journey">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          
          
<p>This is the date that I, <a href="https://twitter.com/itsdevdaniel" target="_blank" rel="noopener">Daniel Lasek</a>, have launched Hustld. It's meant to be a community of business owners (specifically SaaS owners) who tell their story on how they got started. My goal was to target individuals who want to create their own companies and who might require guidence or inspiration from other entrepreneurs.&nbsp; I only got 5 interviews and soon after I decided I wanted to work on other projects. I closed down the server and stopped the site.</p>

<p>Here we are today. I remembered that I had purchased a server for a year on AWS and enjoyed when users visited Hustld to read business interviews. In addition I want to log my journey of Hustld and how I plan to grow it. I am turning Hustld into an "<a href="https://hackernoon.com/what-does-it-mean-to-be-an-open-startup-f4446984189" target="_blank" rel="noopener">open start up</a>". I will share all my progress on my twitter (<a href="https://twitter.com/itsdevdaniel">@itsdevdaniel</a>) and write blogs on here. As of right now the site is not monetized in anyway but I do plan do add some sponsored posts, subscription and cool features in the future! My primary goal as of now isn't MRR (Monthly Reccuring Revenue) it is the # of interviews I can get per month. I am hoping to get at least 5 interviews before 2021 and 10 interviews in January 2021.</p>
<div><p>If you are a business owner (Saas preferred) and would like me to interview you <a href="https://hustld.com/contact">send me a message</a>.</p></div>

<p>5 New Interviews</p>
          
        </div></div>]]>
            </description>
            <link>https://hustld.com/blog/launching-an-open-start-up-journey</link>
            <guid isPermaLink="false">hacker-news-small-sites-25394221</guid>
            <pubDate>Sat, 12 Dec 2020 01:19:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Principle of Maximum Entropy]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25394064">thread link</a>) | @keyboardman
<br/>
December 11, 2020 | https://leimao.github.io/blog/Maximum-Entropy/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/blog/Maximum-Entropy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>The principle of maximum entropy states that the probability distribution which best represents the current state of knowledge is the one with largest entropy, in the context of precisely stated prior data (such as a proposition that expresses testable information). These prior data serves as the constrains to the probability distribution.</p>



<p>Given the second law of thermodynamics (principle of increase of entropy), isolated systems spontaneously evolve towards thermodynamic equilibrium, the state with maximum entropy, maximum entropy distributions become the most natural distributions under certain constrains. In this blog post, I would like to discuss entropy maximization and a couple of maximum entropy distributions.</p>

<h3 id="prerequisites">Prerequisites</h3>

<h4 id="gaussian-integral">Gaussian Integral</h4><p>

\[\begin{align}
\int_{-\infty}^{\infty} e^{-x^2} dx = \sqrt{\pi} \\
\end{align}\]

</p><p>I will skip the proof here, since the proof from <a href="https://en.wikipedia.org/wiki/Gaussian_integral">Wikipedia</a> is not that difficult to understand.</p>

<h4 id="useful-integrals">Useful Integrals</h4><p>

\[\begin{align}
\int_{-\infty}^{\infty} x e^{-x^2} dx &amp;= -\frac{1}{2} \int_{-\infty}^{\infty} e^{-x^2} d(-x^2) \\
&amp;= -\frac{1}{2} e^{-x^2} \big\rvert_{-\infty}^{\infty}\\
&amp;= 0 \\
\end{align}\]

\[\begin{align}
\int_{-\infty}^{\infty} x^2 e^{-x^2} dx &amp;= -\frac{1}{2} \int_{-\infty}^{\infty} x d (e^{-x^2}) \\
&amp;= -\frac{1}{2} \Big( x e^{-x^2} \big\rvert_{-\infty}^{\infty} - \int_{-\infty}^{\infty} e^{-x^2} dx \Big) \\
&amp;= -\frac{1}{2} \Big( 0 - \sqrt{\pi} \Big) \\
&amp;= \frac{\sqrt{\pi}}{2} \\
\end{align}\]

</p><p>Notice that here we used integral by parts.</p>

<h3 id="entropy-maximization">Entropy Maximization</h3>

<h4 id="discrete-probability-distribution">Discrete Probability Distribution</h4>

<p>Suppose $P$ is a discrete probability distribution. The entropy is defined as</p><p>

\[\begin{align}
H(P) &amp;= - \sum_{x \in X}^{} P(x) \log P(x) \\
\end{align}\]

</p><p>We further have some constrains on $P$:</p>

<ul>
  <li>$P(x) \geq 0$</li>
  <li>$\sum_{x \in X}^{} P(x) = 1$</li>
  <li>$\sum_{x \in X}^{} P(x) r_i(x) = \alpha_i$ for $1 \leq i \leq m$</li>
</ul>

<p>The first two constrains are trivial given $P$ is a probability distribution. The third constrain is optional and it indicates a constrain on the entire system. Notice that there could be more than one constrain if $m &gt; 1$.</p>



<p>We would like to maximize the entropy.</p><p>

\[\max_{P} H(P) = \max_{P} \Big( - \sum_{x \in X}^{} P(x) \log P(x) \Big)\]

</p><p>Letâ€™s try to solve this optimization problem. We would use Lagrange multiplier for the constrains.</p><p>

\[\begin{align}
L(P, \lambda_0, \lambda_1, \cdots, \lambda_m) &amp;= - \sum_{x \in X}^{} P(x) \log P(x) + \lambda_0 \Big(\sum_{x \in X}^{} P(x) - 1 \Big) + \sum_{i=1}^{m} \lambda_i \sum_{x \in X}^{} \Big(P(x) r_i(x) - \alpha_i \Big) \\
\end{align}\]

</p><p>We take the derivative of $L(P, \lambda_0, \lambda_1, \cdots, \lambda_m)$ with respect to $P(x)$ and the derivative should be $0$.</p><p>

\[\begin{align}
\frac{\partial}{\partial P(x)} L(P, \lambda_0, \lambda_1, \cdots, \lambda_m) &amp;= - \log P(x) - 1 + \lambda_0 + \sum_{i=1}^{m} \lambda_i r_i(x) \\
&amp;= 0 \\
\end{align}\]

</p><p>Therefore,</p><p>

\[\begin{align}
P(x) &amp;= e^{\big(\sum_{i=1}^{m} \lambda_i r_i(x)\big) + \lambda_0 - 1 } \\
&amp;= \frac{ e^{\sum_{i=1}^{m} \lambda_i r_i(x)} }{e^{1 - \lambda_0}} \\
\end{align}\]

</p><p>Because $\sum_{x \in X}^{} P(x) = 1$,</p><p>

\[\begin{align}
\sum_{x \in X}^{} P(x) &amp;= \sum_{x \in X}^{} e^{\big(\sum_{i=1}^{m} \lambda_i r_i(x)\big) + \lambda_0 - 1 } \\
&amp;= e^{\lambda_0 - 1} \sum_{x \in X}^{} e^{\sum_{i=1}^{m} \lambda_i r_i(x)} \\
&amp;= 1 \\
\end{align}\]

</p><p>Therefore,</p><p>

\[e^{1 - \lambda_0} = \sum_{x \in X}^{} e^{\sum_{i=1}^{m} \lambda_i r_i(x)}\]

</p><p>With this, we could rewrite $P(x)$ as</p><p>

\[\begin{align}
P(x) &amp;= \frac{ e^{\sum_{i=1}^{m} \lambda_i r_i(x)} }{ \sum_{x \in X}^{} e^{\sum_{i=1}^{m} \lambda_i r_i(x)} } \\
\end{align}\]

</p><h4 id="continuous-probability-distribution">Continuous Probability Distribution</h4>

<p>Similarly, suppose $P$ is a continuous probability distribution. The entropy is defined as</p><p>

\[\begin{align}
H(P) &amp;= - \int_{X}^{} P(x) \log P(x) dx \\
\end{align}\]

</p><p>With the following constrains</p>

<ul>
  <li>$P(x) \geq 0$</li>
  <li>$\int_{X}^{} P(x) dx = 1$</li>
  <li>$\int_{X}^{} P(x) r_i(x) dx = \alpha_i$ for $1 \leq i \leq m$</li>
</ul>

<p>Similarly, to maximize the entropy, we maximize the Lagrangian for the continuous case.</p><p>

\[\begin{align}
L(P, \lambda_0, \lambda_1, \cdots, \lambda_m) &amp;= - \int_{X}^{} P(x) \log P(x) dx + \lambda_0 \Big(\int_{X}^{} P(x)  dx - 1 \Big) + \sum_{i=1}^{m} \lambda_i \Big( \int_{X}^{} P(x) r_i(x)  dx - \alpha_i \Big) \\
\end{align}\]

</p><p>We take the derivative of $L(P, \lambda_0, \lambda_1, \cdots, \lambda_m)$ with respect to $P(x)$ and the derivative should be $0$. We will also use the <a href="https://en.wikipedia.org/wiki/Calculus_of_variations">calculus of variations</a> to compute the derivative, which is slightly more complicated. Without going into all the details, we have the following derivatives.</p><p>

\[\begin{align}
\frac{\partial}{\partial P(x)} L(P, \lambda_0, \lambda_1, \cdots, \lambda_m) &amp;= - \frac{\partial}{\partial P(x)} \int_{X}^{} P(x) \log P(x)  dx + \lambda_0 \frac{\partial}{\partial P(x)} \Big(\int_{X}^{} P(x)  dx - 1 \Big) + \sum_{i=1}^{m} \lambda_i \frac{\partial}{\partial P(x)} \Big( \int_{X}^{} P(x) r_i(x)  dx - \alpha_i \Big) \\
&amp;= - \int_{X}^{} \frac{\partial}{\partial P(x)} \big( P(x) \log P(x) \big)  dx + \lambda_0 \frac{\partial}{\partial P(x)} \Big(\int_{X}^{} P(x)  dx - 1 \Big) + \sum_{i=1}^{m} \lambda_i \frac{\partial}{\partial P(x)} \Big( \int_{X}^{} P(x) r_i(x)  dx - \alpha_i \Big) \\
&amp;= - \log P(x) - 1 + \lambda_0 + \sum_{i=1}^{m} \lambda_i r_i(x) \\
&amp;= 0 \\
\end{align}\]

</p><p>Therefore,</p><p>

\[\begin{align}
P(x) &amp;= e^{\big(\sum_{i=1}^{m} \lambda_i r_i(x)\big) + \lambda_0 - 1 } \\
&amp;= \frac{ e^{\sum_{i=1}^{m} \lambda_i r_i(x)} }{e^{1 - \lambda_0}} \\
\end{align}\]

</p><p>Because $\int_{X}^{} P(x) dx = 1$,</p><p>

\[\begin{align}
\int_{X}^{} P(x) dx &amp;= \int_{X}^{} e^{\big(\sum_{i=1}^{m} \lambda_i r_i(x)\big) + \lambda_0 - 1 } dx \\
&amp;= e^{\lambda_0 - 1} \int_{X}^{} e^{\sum_{i=1}^{m} \lambda_i r_i(x)} dx \\
&amp;= 1 \\
\end{align}\]

</p><p>Therefore,</p><p>

\[e^{1 - \lambda_0} = \int_{X}^{} e^{\sum_{i=1}^{m} \lambda_i r_i(x)} dx\]

</p><p>With this, we could rewrite $P(x)$ as</p><p>

\[\begin{align}
P(x) &amp;= \frac{ e^{\sum_{i=1}^{m} \lambda_i r_i(x)} }{ \int_{X}^{} e^{\sum_{i=1}^{m} \lambda_i r_i(x)} dx } \\
\end{align}\]

</p><h3 id="maximum-entropy-distribution-examples">Maximum Entropy Distribution Examples</h3>

<h4 id="roll-dice">Roll Dice</h4>

<p>A conventional dice has 6 faces. $X = \{ 1, 2, 3, 4, 5, 6 \}$. Because we donâ€™t have additional constrains, therefore</p><p>

\[\lambda_1 = \lambda_2 = \cdots = \lambda_m = 0\]

</p><p>So, the maximum entropy probability distribution of getting each face of the dice is</p><p>

\[\begin{align}
P(x) &amp;= \frac{ e^{\sum_{i=1}^{m} \lambda_i r_i(x)} }{ \sum_{x \in X}^{} e^{\sum_{i=1}^{m} \lambda_i r_i(x)} } \\
&amp;= \frac{ e^{0} }{ \sum_{x \in X}^{} e^{0} } \\
&amp;= \frac{ 1 }{ 6 } \\
\end{align}\]

</p><h4 id="uniform-distribution">Uniform Distribution</h4>

<p>The only constrain we put on a distribution is $X = [a, b]$. Because we donâ€™t have additional constrains, therefore</p><p>

\[\lambda_1 = \lambda_2 = \cdots = \lambda_m = 0\]

</p><p>So the maximum entropy probability distribution is actually uniform distribution.</p><p>

\[\begin{align}
P(x) &amp;= \frac{ e^{\sum_{i=1}^{m} \lambda_i r_i(x)} }{ \int_{X}^{} e^{\sum_{i=1}^{m} \lambda_i r_i(x)} dx } \\
&amp;= \frac{ e^{0} }{ \int_{a}^{b} e^{0} dx } \\
&amp;= \frac{ 1 }{ b - a } \\
\end{align}\]

</p><h4 id="gaussian-distribution">Gaussian Distribution</h4>

<p>We could also derive Gaussian Distribution using entropy maximization. The constrains for the maximum entropy distribution are</p>

<ul>
  <li>$X = (-\infty, \infty)$</li>
  <li>$\mathbb{E}[X] = \int_{-\infty}^{\infty} x P(x) dx = \mu$</li>
  <li>$\mathbb{V}[X] = \mathbb{E}[X^2] - \mathbb{E}[X]^2 = \mathbb{E}[X^2] - \mu^2 = \int_{-\infty}^{\infty} x^2 P(x) dx - \mu^2 = \sigma^2$</li>
</ul>

<p>which translates to</p>

<ul>
  <li>$m = 2$</li>
  <li>$r_1(x) = x$, $\alpha_1 = \mu$</li>
  <li>$r_2(x) = x^2$, $\alpha_2 = \sigma^2$</li>
</ul><p>

\[\begin{align}
P(x) &amp;= e^{\lambda_0 - 1 + \lambda_1 x + \lambda_2 x^2} \\
\end{align}\]

</p><p>Because</p><p>

\[\begin{align}
\int_{-\infty}^{\infty} P(x) dx &amp;= 1 \\
\end{align}\]

</p><p>We have</p><p>

\[\begin{align}
\int_{-\infty}^{\infty} P(x) dx &amp;= \int_{-\infty}^{\infty} e^{\lambda_0 - 1 + \lambda_1 x + \lambda_2 x^2} dx  \\
&amp;= \int_{-\infty}^{\infty} e^{\lambda_0 - 1 + \lambda_1 x + \lambda_2 x^2} dx  \\
&amp;= \int_{-\infty}^{\infty} \exp \big( \lambda_0 - 1 + \lambda_1 x + \lambda_2 x^2 \big) dx  \\
&amp;= \int_{-\infty}^{\infty} \exp \bigg( \lambda_2 \Big[ \big(x + \frac{\lambda_1}{2\lambda_2}\big)^2 - \frac{\lambda_1^2 - 4 \lambda_0 \lambda_2 + 4 \lambda_2}{4\lambda_2^2} \Big] \bigg) dx  \\
&amp;= \int_{-\infty}^{\infty} \exp \bigg( \lambda_2 \big(x + \frac{\lambda_1}{2\lambda_2}\big)^2 - \frac{\lambda_1^2 - 4 \lambda_0 \lambda_2 + 4 \lambda_2}{4\lambda_2} \bigg) dx  \\
&amp;= \exp \bigg( - \frac{\lambda_1^2 - 4 \lambda_0 \lambda_2 + 4 \lambda_2}{4\lambda_2}  \bigg) \int_{-\infty}^{\infty} \exp \bigg( \lambda_2 \big(x + \frac{\lambda_1}{2\lambda_2}\big)^2 \bigg) dx  \\
&amp;= \exp \bigg( - \frac{\lambda_1^2 - 4 \lambda_0 \lambda_2 + 4 \lambda_2}{4\lambda_2}  \bigg) \int_{-\infty}^{\infty} \exp \bigg( -(-\lambda_2) \big(x + \frac{\lambda_1}{2\lambda_2}\big)^2 \bigg) dx  \\
\end{align}\]

</p><p>Here we assume $\lambda_2 &lt; 0$, we further have</p><p>

\[\begin{align}
\int_{-\infty}^{\infty} P(x) dx &amp;= \exp \bigg( - \frac{\lambda_1^2 - 4 \lambda_0 \lambda_2 + 4 \lambda_2}{4\lambda_2}  \bigg) \int_{-\infty}^{\infty} \exp \bigg( -(-\lambda_2) \big(x + \frac{\lambda_1}{2\lambda_2}\big)^2 \bigg) dx  \\
&amp;= \exp \bigg( - \frac{\lambda_1^2 - 4 \lambda_0 \lambda_2 + 4 \lambda_2}{4\lambda_2}  \bigg) \int_{-\infty}^{\infty} \exp \bigg( - \Big( \sqrt{ -\lambda_2 }\big(x + \frac{\lambda_1}{2\lambda_2}\big) \Big)^2 \bigg) dx  \\
&amp;= \frac{1}{\sqrt{ -\lambda_2 }} \exp \bigg( - \frac{\lambda_1^2 - 4 \lambda_0 \lambda_2 + 4 \lambda_2}{4\lambda_2}  \bigg) \int_{-\infty}^{\infty} \exp \bigg( - \Big( \sqrt{ -\lambda_2 }\big(x + \frac{\lambda_1}{2\lambda_2}\big) \Big)^2 \bigg) d \Big( \sqrt{ -\lambda_2 }\big(x + \frac{\lambda_1}{2\lambda_2}\big) \Big)  \\
\end{align}\]

</p><p>To make it more clear, we set</p><p>

\[y = \sqrt{ -\lambda_2 }\big(x + \frac{\lambda_1}{2\lambda_2}\big)\]

</p><p>So using Gaussian integral, we further have</p><p>

\[\begin{align}
\int_{-\infty}^{\infty} P(x) dx &amp;= \frac{1}{\sqrt{ -\lambda_2 }} \exp \bigg( - \frac{\lambda_1^2 - 4 \lambda_0 \lambda_2 + 4 \lambda_2}{4\lambda_2}  \bigg) \int_{-\infty}^{\infty} \exp \bigg( - …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://leimao.github.io/blog/Maximum-Entropy/">https://leimao.github.io/blog/Maximum-Entropy/</a></em></p>]]>
            </description>
            <link>https://leimao.github.io/blog/Maximum-Entropy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25394064</guid>
            <pubDate>Sat, 12 Dec 2020 01:05:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[China’s Radical New Vision of Globalization]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25393779">thread link</a>) | @DimiD
<br/>
December 11, 2020 | https://www.noemamag.com/chinas-radical-new-vision-of-globalization/ | <a href="https://web.archive.org/web/*/https://www.noemamag.com/chinas-radical-new-vision-of-globalization/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

				<div>
  <p>Credits</p>
  <p>James Crabtree is an associate professor in practice at the Lee Kuan Yew School of Public Policy at the National University of Singapore. He is the author of “The Billionaire Raj.”</p>
</div>


<p>SINGAPORE —&nbsp;Back in August, Chinese President Xi Jinping met with a group of economists in Beijing. “In the coming period, we will face more and more headwinds,” he <a href="http://www.xinhuanet.com/english/2020-08/25/c_139314902.htm" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">explained</a>, using unusually blunt language. Without naming names, Xi talked about China’s worsening trade and technology war with the United States under President Donald Trump, set against a backdrop of growing certainty in Beijing that America is bent on containing his nation’s geopolitical rise.</p>



<p>But then came the interesting part. “Since the beginning of this year, I have said on many occasions that we must promote the formation of a new development pattern, in which domestic and international cycles are the mainstay, and the domestic and international dual cycles promote each other,” Xi said. To an outsider, this might seem unremarkable, cloaked as it is in the elliptical phraseology that often marks Chinese economic ideas. But the “dual circulation” strategy Xi outlined actually represents a radical new understanding of globalization and of China’s place within it.</p>



<p>More than just a buzzword, dual circulation describes the deeply pessimistic worldview that has settled over Beijing. Once China’s leaders saw opportunity in globalization. Now, they expect the U.S. and its allies to deny China the technology it needs to build “a modern socialist country” by mid-century, meaning a wealthy superpower fit to rival the U.S. Although likely to be less pugilistic, Beijing rightly believes an incoming Biden administration will also press forward with policies designed to stop advanced technologies finding their way into Beijing’s hands. Chinese thinking has long valorized self-reliance, dating back to ideas developed by former Chinese leader Mao Zedong during the country’s civil war, which ended with the foundation of the People’s Republic of China in 1949. Now, Trump’s tariffs, as well as his campaigns against companies like Huawei and TikTok, have given new impetus to the modern form of self-reliance Xi dubs “internal” development.</p>



<p>Many experts have noted a changing Western consensus on China, as leaders in Washington abandoned the idea that economic modernization would inevitably lead to political liberalization in Beijing. But there has been a comparable shift in China’s internal conversation on the West too. Beginning with semiconductors but potentially expanding to all manner of other areas, China now expects it will have to develop technologically on its own. Xi’s new theory now sits at the heart of the country’s <a href="http://www.xinhuanet.com/english/2020-10/29/c_139476451.htm" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">14th five-year plan</a>, which covers development from 2021 to 2025, and was unveiled in draft form in October. The result will accelerate China’s decoupling from the West, while also increasing the importance of trading links forged with other parts of the world — for instance, via Xi’s signature Belt and Road Initiative. Put more bluntly, while the world was distracted by the drama of the U.S. presidential election, Xi quietly unveiled an economic strategy fit for a new Cold War. Both for China and for globalization itself, the results are likely to be profound.&nbsp;</p>


<!-- Quote Block Template -->

<div>

  <div>

    <p>
      “China expects the U.S. and its allies to act ever more aggressively to deny China the technology it needs.”    </p>

    
    
  </div>
</div>




<hr>



<p>To see how much China’s consensus has changed, recall Xi’s <a href="https://america.cgtn.com/2017/01/17/full-text-of-xi-jinping-keynote-at-the-world-economic-forum" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">remarks</a> at Davos in 2017. There, he portrayed globalization not as a threat, but as an inevitability. “The global economy is the big ocean that you cannot escape from,” he suggested. “China will vigorously foster an external environment of opening-up for common development.” Just as Trump was turning against the idea, China would act as steward of the existing global order. It would even help to remedy many of the problems that rapid integration had caused, Xi argued, from economic inequality to climate change.</p>



<p>Three years later and, under <a href="https://research.nus.edu.sg/eai/wp-content/uploads/sites/2/2020/10/EAIC-20-20201020.pdf" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">dual circulation</a>, things look much different. The idea splits the world into two systems. First comes external circulation, meaning China’s global trade, but also the way it invites foreigners into its domestic economy. This was the focus of Xi’s Davos remarks and the approach that powered his country’s decades of rapid growth, transforming China into an exporting powerhouse. The second component is then internal circulation, meaning domestic demand from Chinese consumers, but also domestic supply chains and “made in China” technologies.&nbsp;</p>



<p>This division shares something in common with “<a href="https://www.straitstimes.com/40-years-of-china-opening-up" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">reform and opening up</a>,” a phrase that has dominated China’s economic thinking for decades. That idea suggested Beijing should reform its domestic (or internal) economy to make it more market-led, while also opening up to the (external) world via globalization, gaining new ideas, production techniques and technologies along the way. Dual circulation also echoes longstanding attempts to wean China off a growth model dominated by exports and infrastructure investment and build instead the kind of consumption-led economy common in rich countries.</p>



<p>Such attempts have been only partially successful. A decade ago, about <a href="https://www.ceicdata.com/en/indicator/china/private-consumption--of-nominal-gdp#:~:text=China's%20Private%20Consumption%20accounted%20for,an%20average%20share%20of%2049.7%20%25." data-wpel-link="external" target="_blank" rel="external noopener noreferrer">34%</a> of China’s economy came via domestic consumption, less than <a href="https://tradingeconomics.com/united-states/final-consumption-expenditure-etc-percent-of-gdp-wb-data.html#:~:text=(%25%20of%20GDP)%20in%20United,compiled%20from%20officially%20recognized%20sources." data-wpel-link="external" target="_blank" rel="external noopener noreferrer">half the level</a> in the U.S. at the time. By 2019, this has reached just <a href="https://www.ceicdata.com/en/indicator/china/private-consumption--of-nominal-gdp#:~:text=China%20Private%20Consumption%3A%20%25%20of%20GDP,-1952%20%2D%202019%20%7C%20Yearly&amp;text=China%20Private%20Consumption%20accounted%20for,an%20average%20share%20of%2049.7%20%25." data-wpel-link="external" target="_blank" rel="external noopener noreferrer">39%</a> — progress, of a sort, but hardly dramatic. When the phrase dual circulation first emerged earlier this year, many saw it as merely yet one more push toward this long-term objective of Chinese internal economic rebalancing.&nbsp;</p>


<!-- Quote Block Template -->

<div>

  <div>

    <p>
      “Beginning with semiconductors but potentially expanding to all manner of other technologies, China now expects it will have to develop economically on its own.”    </p>

    
    
  </div>
</div>




<p>It is China’s deteriorating geopolitical environment that marks dual circulation as a decisive break from the past, however. “China thinks there is a good prospect of even worse relations with the U.S. and its friends in the coming years,” I was told recently by Li Mingjiang, a Chinese political scientist based in Singapore and long-time observer of Beijing’s intricate political economy. “So, it needs to do something about it.”</p>



<p>It is not hard to see why. Trump’s tariffs and battles over soybeans generated more headlines, but it is advanced technology that really matters in Beijing. China is a global tech leader in some sectors, from online payments to artificial intelligence. But it lags in others. Despite its geopolitical heft, it still remains a firmly middle-income economy, with a gross domestic product per capita of roughly <a href="https://www.google.com/search?q=china+gdp+per+capita&amp;rlz=1C5CHFA_enSG865SG865&amp;oq=china+gdp&amp;aqs=chrome.0.69i59j69i57j0i67l3j0j69i60j69i61.4682j0j7&amp;sourceid=chrome&amp;ie=UTF-8" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">$9,700</a> — about on par with <a href="https://www.google.com/search?rlz=1C5CHFA_enSG865SG865&amp;sxsrf=ALeKk03pfVp34z407DFWSFnQvjkGHb2akQ%3A1605820539834&amp;ei=e-C2X7m2Munfz7sP5ZGlgAE&amp;q=kazakhstan+gdp+per+capita&amp;oq=Ka+gdp+per+capita&amp;gs_lcp=CgZwc3ktYWIQAxgAMgYIABAHEB4yBggAEAcQHjIGCAAQBxAeMgYIABAHEB4yBggAEAcQHjIGCAAQBxAeMgYIABAHEB4yBggAEAcQHjIGCAAQBxAeMgYIABAHEB46BAgAEEdQoaoBWMmrAWCUswFoAHADeAGAAesBiAGeApIBBTEuMC4xmAEAoAEBqgEHZ3dzLXdpesgBCMABAQ&amp;sclient=psy-ab" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">Kazakhstan</a> and roughly half that of <a href="https://www.google.com/search?rlz=1C5CHFA_enSG865SG865&amp;sxsrf=ALeKk03pfVp34z407DFWSFnQvjkGHb2akQ%3A1605820539834&amp;ei=e-C2X7m2Munfz7sP5ZGlgAE&amp;q=kazakhstan+gdp+per+capita&amp;oq=Ka+gdp+per+capita&amp;gs_lcp=CgZwc3ktYWIQAxgAMgYIABAHEB4yBggAEAcQHjIGCAAQBxAeMgYIABAHEB4yBggAEAcQHjIGCAAQBxAeMgYIABAHEB4yBggAEAcQHjIGCAAQBxAeMgYIABAHEB46BAgAEEdQoaoBWMmrAWCUswFoAHADeAGAAesBiAGeApIBBTEuMC4xmAEAoAEBqgEHZ3dzLXdpesgBCMABAQ&amp;sclient=psy-ab" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">Greece</a>. Access to cutting-edge technology is critical in changing this, especially as its economy moves away from the kind of basic exported manufactured goods that have long dominated its growth model.</p>



<p>Over recent decades, China has had many routes to acquiring such technology. Often, it simply bought it, as when Chinese companies snapped up everything from Rolls Royce jet engines to Qualcomm semiconductors. Foreign businesses rushed to set up Chinese operations, often as part of local joint ventures, eager to tap into a vast consumer market. Chinese businesses bought foreign technology groups, while Chinese academics and scientists built partnerships at the world’s best universities. Beijing <a href="https://www.cigionline.org/publications/getting-beyond-forced-technology-transfers-analysis-and-recommendations-intangible" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">employed</a> darker methods too, from forced technology transfer to outright intellectual property theft. But there were always plenty of legitimate avenues to go with them.&nbsp;</p>


<!-- Quote Block Template -->

<div>

  <div>

    <p>
      “Xi has quietly unveiled an economic strategy fit for a new Cold War.”    </p>

    
    
  </div>
</div>




<p>Now, many of these routes are closing fast. Rather than tariffs, America’s “entity list” has proved its most potent weapon. Back in 2016, President Barack Obama first used this process in <a href="https://www.cigionline.org/publications/getting-beyond-forced-technology-transfers-analysis-and-recommendations-intangible" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">accusing</a> ZTE, China’s second-largest telecoms supplier, of selling U.S. technologies to Iran, crippling the Chinese company in the process. Trump then escalated this approach, banning U.S. businesses from trading with dozens of Chinese enterprises, from state-owned giants to niche artificial intelligence providers with links to Xinjiang and its embattled Muslim Uighur minority. More recent <a href="https://www.commerce.gov/news/press-releases/2020/08/commerce-department-further-restricts-huawei-access-us-technology-and" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">measures</a> unveiled this August hit foreign suppliers too, for instance stopping semiconductor operators in Taiwan from selling to Chinese entities. Huawei has been one high-profile victim, leading experts to <a href="https://www.ft.com/content/bdd2a70f-ecd2-4aff-b6c7-c0624bfdeebb" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">question</a> whether China’s state-linked tech champion can survive.</p>



<p>What started with semiconductors is unlikely to end there, however, hence dual circulation’s underlying pessimism. Under Trump, the U.S. has unveiled a range of further measures limiting China’s technology access, from its 2018 <a href="https://www.cliffordchance.com/briefings/2018/02/the_export_controlreformactof2018risksan.html" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">Export Control Reform Act</a> to more targeted measures in areas like geospatial imagery software. Allies in Europe are being cajoled to follow suit. Many Western governments have also acted to stop China from buying up advanced tech companies entirely, while also <a href="https://www.chinacenter.net/2020/china_currents/19-3/scholars-or-spies-u-s-china-tension-in-academic-collaboration/" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">limiting</a> academic collaborations with Chinese partners. The recent battle over TikTok was illustrative too, showing how rapidly the U.S. has lowered the bar on what counts as a national security threat, a category that now includes not just critical 5G telecoms architecture of the sort provided by Huawei, but also jocular teenage social media platforms.</p>



<p>Elsewhere, U.S. strategists are particularly vexed by China’s doctrine of “<a href="https://www.floridadaily.com/marco-rubio-introduces-bill-to-keep-chinese-military-companies-from-accessing-american-capital-markets/" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">military-civil fusion</a>,” which mandates that technologies acquired by China’s private sector must be shared with its armed forces. The problem is that, when you look hard enough, almost anything can potentially be seen as a dual-use technology, from nuclear equipment and renewable energy batteries to civilian aircraft, drones and autonomous vehicles.&nbsp;</p>


<!-- Quote Block Template -->

<div>

  <div>

    <p>
      “Xi’s plans clearly place more emphasis on domestic production and state control.”    </p>

    
    </div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.noemamag.com/chinas-radical-new-vision-of-globalization/">https://www.noemamag.com/chinas-radical-new-vision-of-globalization/</a></em></p>]]>
            </description>
            <link>https://www.noemamag.com/chinas-radical-new-vision-of-globalization/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25393779</guid>
            <pubDate>Sat, 12 Dec 2020 00:34:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The era of the JVM is coming to an end]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25392805">thread link</a>) | @pdeva1
<br/>
December 11, 2020 | https://movingfulcrum.com/the-era-of-the-jvm-is-coming-to-an-end/ | <a href="https://web.archive.org/web/*/https://movingfulcrum.com/the-era-of-the-jvm-is-coming-to-an-end/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper">
    
    


    <div id="ajax-container">
        
<div>
<article>
    

    <div>

        <p>For over two decades, the JVM (and thus Java) has ruled supreme while other runtimes have come and gone. Ruby, Python, .Net, NodeJS, have all tried to take the throne. But the JVM offered something none could: a multi-threaded, JIT-compiled, high-performance, fully backward compatible runtime.</p><p>That the JVM hasn't kept up with the times, can be demonstrated with a simple example. Say you write a small command-line utility function in Java that has dependencies on a few jars. How does one package and distribute this utility? One could look at StackOverflow to see which plugin of your favorite build system is currently popular to create a Fat Jar. However, the official 'Java way' to package your code and its dependencies is still the good old .war file. A faster moving organization would have acknowledged how users like to ship their code. They would have extended the .jar file format (or introduced a new file format) to be able to package dependencies in a standardized manner. But no such thing on the horizon with Java.</p><p>Java is moving faster than ever now, one might say. It does get 2 minor releases a year now. (Though, does anyone really use the features of non-LTS Java versions?). Sure the module system in Java 9 allowed the JVM to shed some of its weight, but major additions to the JVM which would put it on par with competition still seem to be a long way away. Project Valhalla, which was supposed to introduce 'Value Types' to Java, was announced back in 2014 and still has no release date. Project Loom, which brings green threads, was announced in 2018 and is in a similar state. Want to interop with native code, one still has to deal with the insanity of 20-year-old JNI interfaces.</p><p>One also wonders, even after these features are introduced, how compelling would they be to use compared to their implementations in other languages/runtimes. Java's Achilles heel after all is the need to maintain backward compatibility. Its that backward compatibility requirement that got us the Java Streams API, where instead of <code>myList.map(...)</code> one has to write the monstrosity that is <code>myList.stream().map(...).collect(Collectors.toList()</code>.</p><p>There was a time where Java was the best choice for almost everything. GWT on the frontend, Spring on the backend. Databases like Hadoop, ElasticSearch, Kafka, Spark, all written on top of the JVM. Java also had the absolute best IDE in Eclipse and Intellij, making it a reason to choose Java over other languages in a professional environment.</p><p>What's different in the 2020s is that over the last decade, languages/runtimes have evolved to become best in class for specific domains. They took their learnings from the JVM, finally realizing that type safety is needed and performance is important. They ackonowledged that one language/runtime doesnt fit all needs.</p><ul><li>Want to write a large, complicated UI? ReactJS and Typescript allow you to do that while providing a type system even more expressive than the JVM.</li><li>Want to write a web server? Golang allows you to handle thousands of requests at a time without the need for a thread per request. It makes concurrency so easy, the equivalent in Java would be an order of magnitude more complex.</li><li>Want to write a big data database? Rust has you covered. Deal with huge amounts of data without needing to battle the GC and interact with low-level system calls without battling with JNI or <code>sun.misc.Unsafe</code>.</li></ul><p>With all these languages being fully typed, Jetbrains now has been able to make equally good IDE for those languages too.</p><p>From 2020 onwards, the JVM doesn't seem to be the best choice for anything. It will continue its legacy as a big, heavyweight, one size fits all VM. Good at everything, but never the best. The future is polyglot and it's free of the JVM.</p>
    </div>

    
</article></div>
    </div>
</div></div>]]>
            </description>
            <link>https://movingfulcrum.com/the-era-of-the-jvm-is-coming-to-an-end/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25392805</guid>
            <pubDate>Fri, 11 Dec 2020 23:03:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Measuring Memory Usage in Rust]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25392791">thread link</a>) | @lukastyrychtr
<br/>
December 11, 2020 | https://rust-analyzer.github.io/blog/2020/12/04/measuring-memory-usage-in-rust.html | <a href="https://web.archive.org/web/*/https://rust-analyzer.github.io/blog/2020/12/04/measuring-memory-usage-in-rust.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="preamble">
<div>

<p>This post documents a couple of fun tricks we use in rust-analyzer for measuring memory consumption.</p>
<p>In general, there are two broad approaches to profiling the memory usage of a program.</p>
<p><em>The first approach</em> is based on “heap parsing”.
At a particular point in time, the profiler looks at all the memory currently occupied by the program (the heap).
In its raw form, the memory is just a bag of bytes, <code>Vec&lt;u8&gt;</code>.
However the profiler, using some help from the language’s runtime, is able to re-interpret these bytes as collections of object (“parse the heap”).
It then traverses the graph of objects and computes how many instances of each object are there and how much memory they occupy.
The profiler also tracks the ownership relations, to ferret out facts like “90% of strings in this program are owned by the <code>Config</code> struct”.
This is the approach I am familiar with from the JVM ecosystem.
Java’s garbage collector needs to understand the heap to search for unreachable objects, and the same information is used to analyze heap snapshots.</p>
<p><em>The second approach</em> is based on instrumenting the calls to allocation and deallocation routines.
The profiler captures backtraces when the program calls <code>malloc</code> and <code>free</code> and constructs a flamegraph displaying “hot” functions which allocate a lot.
This is how, for example, <a href="https://github.com/KDE/heaptrack">heaptrack</a> works (see also <a href="https://github.com/cuviper/alloc_geiger">alloc geiger</a>).</p>
<p>The two approaches are complementary.
If the problem is that the application does too many short-lived allocations (instead of re-using the buffers), it would be invisible for the first approach, but very clear in the second one.
If the problem is that, in a steady state, the application uses too much memory, the first approach would work better for pointing out which data structures need most attention.</p>
<p>In rust-analyzer, we are generally interested in keeping the overall memory usage small, and can make better use of heap parsing approach.
Specifically, most of the rust-analyzer’s data is stored in the incremental computation tables, and we want to know which table is the heaviest.</p>
<p>Unfortunately, Rust does not use garbage collection, so just parsing the heap bytes at runtime is impossible.
The best available alternative is instrumenting data structures for the purposes of measuring memory size.
That is, writing a proc-macro which adds <code>fn total_size(&amp;self) → usize</code> method to annotated types, and calling that manually from the root of the data.
There is Servo’s <a href="https://github.com/servo/servo/tree/2d3811c21bf1c02911d5002f9670349c5cf4f500/components/malloc_size_of"><code>malloc_size_of</code></a> crate for doing that, but it is not published to crates.io.</p>
<p>Another alternative is running the program under valgrind to gain runtime introspectability.
<a href="https://www.valgrind.org/docs/manual/ms-manual.html">Massif</a> and and <a href="https://www.valgrind.org/docs/manual/dh-manual.html">DHAT</a> work that way.
Running with valgrind is pretty slow, and still doesn’t give Java-level fidelity.</p>
<p>Instead, rust-analyzer mainly relies on a much simpler approach for figuring out which things are heavy.
This is the first trick of this article:</p>
</div>
</div><div>
<h2 id="archimedes-method"><a href="#archimedes-method"></a>Archimedes' Method</h2>
<div>
<p>It’s relatively easy to find out the total memory allocated at any given point in time.
For glibc, there’s <a href="https://man7.org/linux/man-pages/man3/mallinfo.3.html">mallinfo</a> function, a <a href="https://docs.rs/jemalloc-ctl/0.3.3/jemalloc_ctl/stats/struct.allocated.html">similar API</a> exists for jemalloc.
It’s even possible to implement a <a href="https://doc.rust-lang.org/stable/std/alloc/trait.GlobalAlloc.html"><code>GlobalAlloc</code></a> which tracks this number.</p>
<p>And, if you can measure total memory usage, you can measure memory usage of any specific data structure by:</p>
<div>
<ol>
<li>
<p>measuring the current memory usage</p>
</li>
<li>
<p>dropping the data structure</p>
</li>
<li>
<p>measuring the current memory usage again</p>
</li>
</ol>
</div>
<p>The difference between the two values is the size of the data structure.
And this is exactly what rust-analyzer does to find the largest caches: <a href="https://github.com/rust-analyzer/rust-analyzer/blob/b988c6f84e06bdc5562c70f28586b9eeaae3a39c/crates/ide_db/src/apply_change.rs#L104-L238">source</a>.</p>
<p>Two small notes about this method:</p>
<div>
<ul>
<li>
<p>It’s important to ask the allocator about the available memory, and not the operating system.
OS can only tell how many pages the program consumes.
Only the allocator knows which of those pages are free and which hold allocated objects.</p>
</li>
<li>
<p>When measuring relative sizes, it’s important to note the unaccounted-for amount in the end, such that the total adds up to 100%.
It might be the case that the bottleneck lies in the dark matter outside of explicit measurements!</p>
</li>
</ul>
</div>
</div>
</div><div>
<h2 id="amdahls-estimator"><a href="#amdahls-estimator"></a>Amdahl’s Estimator</h2>
<div>
<p>The second trick is related to the <a href="https://en.wikipedia.org/wiki/Amdahl%E2%80%99s_law">Amdahl’s law</a>.
When optimizing a specific component, it’s important to note not only how much more efficient it becomes, but also overall contribution of the component to the system.
Making an algorithm twice as fast can improve the overall performance only by 5%, if the algorithm is only 10% of the whole task.</p>
<p>In rust-analyzer’s case, the optimization we are considering is adding interning to <code>Name</code>.
At the moment, a <code>Name</code> is represented with a small sized optimized string (24 bytes inline + maybe some heap storage):</p>
<div>
<div>
<pre><code data-lang="rust"><table><tbody><tr><td><pre>1
2
3
</pre></td><td><pre><span>struct</span> <span>Name</span> <span>{</span>
    <span>text</span><span>:</span> <span>SmolStr</span><span>,</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<p>Instead, we can use an interned index (4 bytes):</p>
<div>
<div>
<pre><code data-lang="rust"><table><tbody><tr><td><pre>1
2
3
</pre></td><td><pre><span>struct</span> <span>Name</span> <span>{</span>
    <span>idx</span><span>:</span> <span>u32</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<p>However, just trying out this optimization is not easy, as an interner is a thorny piece of global state.
Is it worth it?</p>
<p>If we look at the <code>Name</code> itself, it’s pretty clear that the optimization is valuable: it reduces memory usage by 6x!
But how important is it in the grand scheme of things?
How to measure the impact of <code>Name</code>s on overall memory usage?</p>
<p>One approach is to just apply the optimization and measure the improvement after the fact.
But there’s a lazier way: instead of making the <code>Name</code> smaller and measuring the improvement, we make it <strong>bigger</strong> and measure the worsening.
Specifically, its easy to change the <code>Name</code> to this:</p>
<div>
<div>
<pre><code data-lang="rust"><table><tbody><tr><td><pre>1
2
3
4
5
</pre></td><td><pre><span>struct</span> <span>Name</span> <span>{</span>
    <span>text</span><span>:</span> <span>SmolStr</span><span>,</span>
    <span>// Copy of `text`</span>
    <span>_</span><span>ballast</span><span>:</span> <span>SmolStr</span><span>,</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<p>Now, if the new <code>Name</code> increases the overall memory consumption by <code>N</code>, we can estimate the total size of old <code>Name</code>s as <code>N</code> as well, as they are twice as small.</p>
<p>Sometimes, quick and simple hacks works better than the finest instruments :).</p>
</div>
</div></div>]]>
            </description>
            <link>https://rust-analyzer.github.io/blog/2020/12/04/measuring-memory-usage-in-rust.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25392791</guid>
            <pubDate>Fri, 11 Dec 2020 23:02:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Do People Write for Wikipedia? (2005) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25392096">thread link</a>) | @MrXOR
<br/>
December 11, 2020 | http://andreaforte.net/ForteBruckmanWhyPeopleWrite.pdf | <a href="https://web.archive.org/web/*/http://andreaforte.net/ForteBruckmanWhyPeopleWrite.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://andreaforte.net/ForteBruckmanWhyPeopleWrite.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25392096</guid>
            <pubDate>Fri, 11 Dec 2020 22:16:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is the second wave overloading Sweden's intensive care units?]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25391787">thread link</a>) | @juusto
<br/>
December 11, 2020 | https://www.thelocal.se/20201211/is-the-second-wave-overloading-swedens-intensive-care-units | <a href="https://web.archive.org/web/*/https://www.thelocal.se/20201211/is-the-second-wave-overloading-swedens-intensive-care-units">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://storage.googleapis.com/ddos-shield.appspot.com/shield-logo-mono-darktext.svg" width="250px" height="50px" alt="Project Shield Logo"></p><p>You will be connected to <b>www.thelocal.se</b> in just a moment...</p><p><a href="https://g.co/shield">Learn about Project Shield</a></p></div></div>]]>
            </description>
            <link>https://www.thelocal.se/20201211/is-the-second-wave-overloading-swedens-intensive-care-units</link>
            <guid isPermaLink="false">hacker-news-small-sites-25391787</guid>
            <pubDate>Fri, 11 Dec 2020 21:59:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Annual Cost of Sales Tax]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25391483">thread link</a>) | @calicruisin
<br/>
December 11, 2020 | https://www.thriftythoughts.io/sales-tax/ | <a href="https://web.archive.org/web/*/https://www.thriftythoughts.io/sales-tax/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
<div>
    <main>
            <article>
    
    <div>
                <h2 id="how-much-do-we-actually-pay-in-sales-tax-every-year">How much do we actually pay in sales tax every year?</h2><p><br>Sales tax tends to fly under the radar. It can vary depending on what items you purchase, what state you're in, and what city you're in. Whenever you see it show up on a bill or receipt it can appear to be a relatively small, innocuous number. So how much are we actually spending per year on sales tax?</p><p>According to research commissioned by Ladder and conducted by OnePoll Americans spend <strong>$18,000</strong> per year on non-essential items. Given that sales tax generally applies to non-essential items, how much does this sales tax amount to in a given year in different locales across the U.S.?</p><figure><img src="https://www.thriftythoughts.io/content/images/2020/12/UNCLAIMED-PROPERTY--13-.png" alt="" srcset="https://www.thriftythoughts.io/content/images/size/w600/2020/12/UNCLAIMED-PROPERTY--13-.png 600w, https://www.thriftythoughts.io/content/images/2020/12/UNCLAIMED-PROPERTY--13-.png 800w" sizes="(min-width: 720px) 720px"></figure>
                            <section>
                                <h2>Enjoying these posts? Subscribe for more</h2>
                                
                                <br>
                                
                            </section>
    </div>
        
</article>                    
                </main>
</div>
        </div></div>]]>
            </description>
            <link>https://www.thriftythoughts.io/sales-tax/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25391483</guid>
            <pubDate>Fri, 11 Dec 2020 21:43:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[NLP and Named Entity Recognition]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25391245">thread link</a>) | @yuchi
<br/>
December 11, 2020 | https://techblog.smc.it/en/2020-12-11/nlp-ner | <a href="https://web.archive.org/web/*/https://techblog.smc.it/en/2020-12-11/nlp-ner">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p><em>This is the first in a series of articles covering that part of machine learning known as Natural Language Processing (NLP).</em></p><p><em>This article refers to several key concepts in Machine Learning.<br>
Read the article <a href="https://techblog.smc.it/en/2020-05-25/machine-learning-industry"><strong>Machine learning and applications for industry</strong></a>
for the main definitions.</em></p><p>With <a href="https://it.wikipedia.org/wiki/Elaborazione_del_linguaggio_naturale"><strong>Natural Language Processing</strong></a>
we refer to that interdisciplinary research field that embraces computer science, artificial intelligence and linguistics,
whose purpose is to develop algorithms capable of analyzing, representing and therefore "understanding"
natural language, written or spoken, in a similar or even more efficient way than human beings.</p><p>Huge amounts of text and speech content are generated and stored nowadays. Very often
no use is made of this data, unaware of the fact that instead they represent an invaluable source of value, thanks to which
it is possible to create tools and applications which can bring a considerable added value.</p><p>By exploiting the textual and vocal content available, it is possible, for example, to create tools for::</p><ul><li><strong>Named Entity Recognition</strong>: recognize and extract entities and semantic information from the text.</li><li><strong>Text Classification</strong>: classify textual content, for example the sentiment analysis of a text (positive or negative).</li><li><strong>Entity linking</strong>: disambiguate the entities identified in the text (link the textual entities to identifying concepts).</li><li><strong>Topic Modeling</strong>: automatically extract the main topics present in a textual corpus.</li><li><strong>Autocompletion</strong>: autocompletion of a query for example.</li><li><strong>Machine translation</strong>: translation of textual content from one language to another.</li><li><strong>Speech Recognition</strong>: transformation of voice content into textual content (technology behind chatbots).</li></ul><p>In this first article we will cover the task known as <a href="https://en.wikipedia.org/wiki/Named-entity_recognition"><strong>Named Entity Recognition (NER)</strong></a>.
We will see how it is possible to create a tool capable of recognizing entities in the text and what are some of its possible applications.</p><p>The Named Entity Recognition is placed within that subclass of task which in NLP is defined as <a href="https://en.wikipedia.org/wiki/Information_extraction"><strong>Information Extraction</strong></a>.
Through NER it is possible to identify entities in the text and associate them with the corresponding semantic categories such as persons, organizations, entities of
geopolitical type, geographic, numbers, temporal expressions and so on.</p><figure>
    <span>
      <a href="https://techblog.smc.it/static/90e3ba5bcde3bf1fdfe36009d8c9ecc8/8de58/entities.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://techblog.smc.it/static/90e3ba5bcde3bf1fdfe36009d8c9ecc8/c85cb/entities.webp 300w,https://techblog.smc.it/static/90e3ba5bcde3bf1fdfe36009d8c9ecc8/e88ff/entities.webp 600w,https://techblog.smc.it/static/90e3ba5bcde3bf1fdfe36009d8c9ecc8/92f8c/entities.webp 1200w,https://techblog.smc.it/static/90e3ba5bcde3bf1fdfe36009d8c9ecc8/4fba2/entities.webp 1219w" sizes="(max-width: 1200px) 100vw, 1200px" type="image/webp">
        <source srcset="https://techblog.smc.it/static/90e3ba5bcde3bf1fdfe36009d8c9ecc8/5a46d/entities.png 300w,https://techblog.smc.it/static/90e3ba5bcde3bf1fdfe36009d8c9ecc8/0a47e/entities.png 600w,https://techblog.smc.it/static/90e3ba5bcde3bf1fdfe36009d8c9ecc8/c1b63/entities.png 1200w,https://techblog.smc.it/static/90e3ba5bcde3bf1fdfe36009d8c9ecc8/8de58/entities.png 1219w" sizes="(max-width: 1200px) 100vw, 1200px" type="image/png">
        <img alt="Figure 1 - Named Entity Recognition" src="https://techblog.smc.it/static/90e3ba5bcde3bf1fdfe36009d8c9ecc8/c1b63/entities.png" title="Figure 1 - Named Entity Recognition" loading="lazy">
      </picture>
  </a>
    </span>
    <figcaption>Figure 1 - Named Entity Recognition</figcaption>
  </figure>   <p>We are talking about a task that has had a strong development in recent times, especially thanks to the advent of <a href="https://en.wikipedia.org/wiki/Deep_learning"><strong>Deep Learning</strong></a>.
The use of very deep neural networks has greatly increased and improved the effectiveness of entity recognition tools. <br>
Before the advent of Deep Learning, the most used tool was the so-called <a href="https://en.wikipedia.org/wiki/Hidden_Markov_model">Hidden Markov Model</a>,
a statistical model based on <a href="https://en.wikipedia.org/wiki/Markov_chain">Markov chain</a>, but that did not guarantee
the same performance as today's Deep Learning-based models. <br>
Two examples of training models for entity recognition will be shown later in the article, both based on the use of algorithms
made with neural networks.</p><p>The task of the Named Entity Recognition is addressed through approaches of <a href="https://en.wikipedia.org/wiki/Supervised_learning"><strong>supervised type</strong></a>,
and for this reason it is necessary to have a set of labeled data available in order to train a model to recognize entities.
Each textual content must be labeled with the list of tokens and related tags for each entity that is to be recognized in the text.</p><p>There are several formats to represent a training dataset for Named Entity Recognition. Let's see the two most used.</p><p>A first format is the one called <strong> BILUO </strong> scheme, where the different parts of the entities are mapped according to the scheme in Figure 2.
Entities are tagged with the semantic category preceded by one of the defined prefixes.</p><figure>
    <span>
      <a href="https://techblog.smc.it/static/b804a19584581a03fe9c2b735b5213d2/3f3b9/biluooo.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://techblog.smc.it/static/b804a19584581a03fe9c2b735b5213d2/c85cb/biluooo.webp 300w,https://techblog.smc.it/static/b804a19584581a03fe9c2b735b5213d2/e88ff/biluooo.webp 600w,https://techblog.smc.it/static/b804a19584581a03fe9c2b735b5213d2/bf818/biluooo.webp 870w" sizes="(max-width: 870px) 100vw, 870px" type="image/webp">
        <source srcset="https://techblog.smc.it/static/b804a19584581a03fe9c2b735b5213d2/5a46d/biluooo.png 300w,https://techblog.smc.it/static/b804a19584581a03fe9c2b735b5213d2/0a47e/biluooo.png 600w,https://techblog.smc.it/static/b804a19584581a03fe9c2b735b5213d2/3f3b9/biluooo.png 870w" sizes="(max-width: 870px) 100vw, 870px" type="image/png">
        <img alt="Figure 2 - BILUO scheme" src="https://techblog.smc.it/static/b804a19584581a03fe9c2b735b5213d2/3f3b9/biluooo.png" title="Figure 2 - BILUO scheme" loading="lazy">
      </picture>
  </a>
    </span>
    <figcaption>Figure 2 - BILUO scheme</figcaption>
  </figure><p>The mapping between tokens and entities is then saved in a <strong> csv </strong> file, using a separate label for all tokens
that do not fall within the semantic categories of reference.</p><figure>
    <span>
      <a href="https://techblog.smc.it/static/7fe2f42eaa3f2fda77d2487841983bea/d7542/biluo-map.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://techblog.smc.it/static/7fe2f42eaa3f2fda77d2487841983bea/c85cb/biluo-map.webp 300w,https://techblog.smc.it/static/7fe2f42eaa3f2fda77d2487841983bea/e88ff/biluo-map.webp 600w,https://techblog.smc.it/static/7fe2f42eaa3f2fda77d2487841983bea/385bc/biluo-map.webp 810w" sizes="(max-width: 810px) 100vw, 810px" type="image/webp">
        <source srcset="https://techblog.smc.it/static/7fe2f42eaa3f2fda77d2487841983bea/5a46d/biluo-map.png 300w,https://techblog.smc.it/static/7fe2f42eaa3f2fda77d2487841983bea/0a47e/biluo-map.png 600w,https://techblog.smc.it/static/7fe2f42eaa3f2fda77d2487841983bea/d7542/biluo-map.png 810w" sizes="(max-width: 810px) 100vw, 810px" type="image/png">
        <img alt="Figure 3 - Mapping with BILUO scheme" src="https://techblog.smc.it/static/7fe2f42eaa3f2fda77d2487841983bea/d7542/biluo-map.png" title="Figure 3 - Mapping with BILUO scheme" loading="lazy">
      </picture>
  </a>
    </span>
    <figcaption>Figure 3 - Mapping with BILUO scheme</figcaption>
  </figure><p>The BILUO scheme is perhaps the most popular format.</p><p>A second format is a simplified version of the BILUO scheme. It is called the <strong>IOB</strong> schema. This is a less fine-grained scheme, where
the prefix associated with the entity indicates only whether it is a token at the beginning or within the entity consisting of several words. <br>
The scheme follows the specifications defined in the figure below.</p><figure>
    <span>
      <a href="https://techblog.smc.it/static/b804a19584581a03fe9c2b735b5213d2/3f3b9/iob.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://techblog.smc.it/static/b804a19584581a03fe9c2b735b5213d2/c85cb/iob.webp 300w,https://techblog.smc.it/static/b804a19584581a03fe9c2b735b5213d2/e88ff/iob.webp 600w,https://techblog.smc.it/static/b804a19584581a03fe9c2b735b5213d2/bf818/iob.webp 870w" sizes="(max-width: 870px) 100vw, 870px" type="image/webp">
        <source srcset="https://techblog.smc.it/static/b804a19584581a03fe9c2b735b5213d2/5a46d/iob.png 300w,https://techblog.smc.it/static/b804a19584581a03fe9c2b735b5213d2/0a47e/iob.png 600w,https://techblog.smc.it/static/b804a19584581a03fe9c2b735b5213d2/3f3b9/iob.png 870w" sizes="(max-width: 870px) 100vw, 870px" type="image/png">
        <img alt="Figure 4 - IOB Scheme" src="https://techblog.smc.it/static/b804a19584581a03fe9c2b735b5213d2/3f3b9/iob.png" title="Figure 4 - IOB Scheme" loading="lazy">
      </picture>
  </a>
    </span>
    <figcaption>Figure 4 - IOB Scheme</figcaption>
  </figure><p>A third representation is in <strong> jsonl </strong> format.
In this format, each textual content is associated with a list that indicates, for each entity, the position in the text and the associated semantic category.</p><figure><div><div><pre data-language="json" data-index="0"><code><span><span>{   </span></span>
<span><span>  </span><span>"text"</span><span>: </span><span>""</span><span>Sharon</span><span> </span><span>flew</span><span> </span><span>to</span><span> </span><span>Miami</span><span> </span><span>last</span><span> </span><span>friday</span><span>""</span><span>, </span></span>
<span><span>  </span><span>"entities"</span><span>: [</span><span>(</span><span>0</span><span>, </span><span>5</span><span>, </span><span>"PERSON"</span><span>)</span><span>, </span><span>(</span><span>15</span><span>, </span><span>20</span><span>, </span><span>"LOC"</span><span>)</span><span>, </span><span>(</span><span>26</span><span>, </span><span>32</span><span>, </span><span>"DATE"</span><span>)</span><span>]</span></span>
<span><span>}</span></span></code></pre><figcaption>Source Code 1 - Example in jsonl format</figcaption></div></div></figure><p>Experts identify the BILUO scheme as the best to make models for Named Entity Recognition as accurate as possible.
This is because, through the multi-prefix scheme, they specify more detailed information in the text, which improves the capabilities of
learning of the Machine Learning algorithm used. <br>
But even using the IOB and jsonl format, very often it is possible to achieve noteworthy performance. <br>
Switching between formats is relatively simple and can be accomplished by defining rules-based procedures
easy intuition.
In addition, many NLP libraries already define predefined functions to transform your dataset into the desired format.</p><p>To label and transform data into one of these formats, there are ad hoc tools called <strong> annotators </strong>.
An annotator allows you to upload your data as plain text and then label it in a graphical environment which makes the annotation process more agile.
Annotators allow you to label data for NER, but also for textual classification tasks rather than sequence-to-sequence tasks.</p><p>In the case of NER, an annotator presents a graphic like the one below in the figure, with functionalities that allow
to carry out the annotation activity simply by highlighting the text and specifying the label to assign.</p><figure>
    <span>
      <a href="https://techblog.smc.it/static/4bd4c38d814cfd2465665862c558e958/10b63/doccano.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://techblog.smc.it/static/4bd4c38d814cfd2465665862c558e958/c85cb/doccano.webp 300w,https://techblog.smc.it/static/4bd4c38d814cfd2465665862c558e958/e88ff/doccano.webp 600w,https://techblog.smc.it/static/4bd4c38d814cfd2465665862c558e958/92f8c/doccano.webp 1200w,https://techblog.smc.it/static/4bd4c38d814cfd2465665862c558e958/62ed8/doccano.webp 1800w,https://techblog.smc.it/static/4bd4c38d814cfd2465665862c558e958/eccbe/doccano.webp 1897w" sizes="(max-width: 1200px) 100vw, 1200px" type="image/webp">
        <source srcset="https://techblog.smc.it/static/4bd4c38d814cfd2465665862c558e958/5a46d/doccano.png 300w,https://techblog.smc.it/static/4bd4c38d814cfd2465665862c558e958/0a47e/doccano.png 600w,https://techblog.smc.it/static/4bd4c38d814cfd2465665862c558e958/c1b63/doccano.png 1200w,https://techblog.smc.it/static/4bd4c38d814cfd2465665862c558e958/d61c2/doccano.png 1800w,https://techblog.smc.it/static/4bd4c38d814cfd2465665862c558e958/10b63/doccano.png 1897w" sizes="(max-width: 1200px) 100vw, 1200px" type="image/png">
        <img alt="Figure 5 - Docccano screenshot" src="https://techblog.smc.it/static/4bd4c38d814cfd2465665862c558e958/c1b63/doccano.png" title="Figure 5 - Docccano screenshot" loading="lazy">
      </picture>
  </a>
    </span>
    <figcaption>Figure 5 - Docccano screenshot</figcaption>
  </figure><p>The example screen is from <a href="https://github.com/doccano/doccano"><strong>doccano</strong></a>, a well structured and open source annotator. Doccano, once
labeled the data, allows you to export the dataset in <strong>jsonl</strong> format.
To be mentioned, on the other hand, among the paid ones <!-- -->[<strong> Prodigy </strong>]<!-- --> (<a href="https://prodi.gy/">https://prodi.gy/</a>), an advanced annotator, enhanced  through the concept
of active learning; this is developed by <!-- -->[Explosion.ai]<!-- --> (<a href="https://explosion.ai/">https://explosion.ai/</a>), creators of the opensource library of NLP <!-- -->[<strong> Spacy </strong>]<!-- --> (<a href="https://spacy.io/">https://spacy.io/</a>).</p><h2 id="dataset">Dataset</h2><p>If you want to train models for the recognition of entities, one option is to first analyze some labeled datasets present at
state of the art.
These tend to be generic datasets, with entities labeled with semantic categories relating to personal names, organizations, locations, dates,
temporal entities; however, it is also possible to find datasets labeled, concerning to more specific domains.
These datasets are almost always in English, but very often this problem can be overcome by using machine translation tools before carrying out
the activity of Named Entity Recognition, translating the content from the Italian language to the English language, and vice versa.</p><p>Here is a list of some of the tagged datasets on the net:</p><ul><li><a href="https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus?select=ner_dataset.csv"><strong>Annotated Corpus for Named Entity Recognition</strong></a>: dataset
in BILUO Schema containing textual content labeled with geographical, geopolitical, temporal entities, etc ...</li><li><a href="https://www.clips.uantwerpen.be/conll2003/ner/"><strong>CoNLL 2003</strong></a>: dataset in BILUO Scheme containing news articles annotated with (LOC) locality,
ORG (organizations), PER (people) and MISC (miscellaneous).</li><li><a href="http://www.cs.cmu.edu/~enron/"><strong>Enron Email Dataset</strong></a>: more than 500,000 emails tagged with names, dates and time entities.</li><li><a href="https://catalog.ldc.upenn.edu/LDC2013T19"><strong>OntoNotes 5</strong></a>: it is a dataset of news, telephone conversations, blog content tagged with
entities of different kinds.</li></ul><p>At the state of the art there are many tools and libraries that deal with the creation and implementation of tools in the field of
Natural Language Processing. These tools provide both pre-trained templates that are easy to use and quickly integrate into your code, and the
possibility to train new ones with your own data, using predefined modules that simplify the training of new Machine Learning tools. <br>
In the next section we will see how to train custom models on your own data.
Now let's see some easy-to-use tools that provide pre-trained models for recognizing entities in the text.</p><h3 id="spacy">Spacy</h3><figure>
    <span>
      <a href="https://techblog.smc.it/static/52ed935aa044a0f6f08834c364fca63e/f7616/spacy-rasa.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://techblog.smc.it/static/52ed935aa044a0f6f08834c364fca63e/c85cb/spacy-rasa.webp 300w,https://techblog.smc.it/static/52ed935aa044a0f6f08834c364fca63e/e88ff/spacy-rasa.webp 600w,https://techblog.smc.it/static/52ed935aa044a0f6f08834c364fca63e/3fcdd/spacy-rasa.webp 766w" sizes="(max-width: 766px) 100vw, 766px" type="image/webp">
        <source srcset="https://techblog.smc.it/static/52ed935aa044a0f6f08834c364fca63e/5a46d/spacy-rasa.png 300w,https://techblog.smc.it/static/52ed935aa044a0f6f08834c364fca63e/0a47e/spacy-rasa.png 600w,https://techblog.smc.it/static/52ed935aa044a0f6f08834c364fca63e/f7616/spacy-rasa.png 766w" sizes="(max-width: 766px) 100vw, 766px" type="image/png">
        <img alt="Figure 6 - Spacy" src="https://techblog.smc.it/static/52ed935aa044a0f6f08834c364fca63e/f7616/spacy-rasa.png" title="Figure 6 - Spacy" loading="lazy">
      </picture>
  </a>
    </span>
    <figcaption>Figure 6 - Spacy</figcaption>
  </figure><p>[<strong> Spacy </strong>]<!-- --> (<a href="https://spacy.io/">https://spacy.io/</a>) is a Natural Language Processing framework, which deals with the development and implementation of
Machine Learning techniques for many of the most popular nlp tasks.
Spacy, a completely open source tool, also provides a list of pre-trained models, with support for different languages, through
which can be performed on textual content some natural language processing tasks, such as entity recognition.</p><figure><div><div><pre data-language="bash" data-index="1"><code><span><span># installazione di spacy</span></span>
<span><span>pip install -U spacy</span></span>
<span></span>
<span><span>#download del modello</span></span>
<span><span>python -m spacy download it_core_news_sm</span></span></code></pre><pre data-language="python" data-index="2"><code><span><span># import</span></span>
<span><span>import</span><span> spacy</span></span>
<span><span>​</span></span>
<span><span># loading of choosen model</span></span>
<span><span>nlp = spacy.load(</span><span>"en_core_web_sm"</span><span>)</span></span>
<span></span>
<span><span># running model on text and printing recognized entities</span></span>
<span><span>doc = nlp(</span><span>"Apple is looking at buying U.K. startup for $1 billion"</span><span>)</span></span>
<span><span>​</span><span>for</span><span> ent </span><span>in</span><span> doc.ents:</span></span>
<span><span>    </span><span>print</span><span>(ent.text, ent.start_char, ent.end_char, ent.label_)</span></span></code></pre><figcaption>Source Code 2 - Spacy Named Entity Recognition</figcaption></div></div></figure><p>In these two code snippets we see how to install through <a href="https://pypi.org/project/pip/"><strong>pip</strong></a> in the
your <strong>Python</strong> environment the library and download the chosen model.
Subsequently, with two simple lines of code, you can load the model and run it on textual content.</p><h3 id="stanford-nlp">Stanford NLP</h3><figure>
    <span>
      <a href="https://techblog.smc.it/static/1c1141ed75dbdf0ab8861712a460625a/863e1/stanford-ner.jpg" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://techblog.smc.it/static/1c1141ed75dbdf0ab8861712a460625a/d7e55/stanford-ner.webp 225w" sizes="(max-width: 225px) 100vw, 225px" type="image/webp">
        <source srcset="https://techblog.smc.it/static/1c1141ed75dbdf0ab8861712a460625a/863e1/stanford-ner.jpg 225w" sizes="(max-width: 225px) 100vw, 225px" type="image/jpeg">
        <img alt="Figure 7 - Stanford NLP" src="https://techblog.smc.it/static/1c1141ed75dbdf0ab8861712a460625a/863e1/stanford-ner.jpg" title="Figure 7 - Stanford NLP" loading="lazy">
      </picture>
  </a>
    </span>
    <figcaption>Figure 7 - Stanford NLP</figcaption>
  </figure><p><a href="https://nlp.stanford.edu/"><strong>Stanforf NLP</strong></a> is a research group at Stanford University dedicated to NLP and which
has created a <a href="https://nlp.stanford.edu/software/">suite</a> of tools …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://techblog.smc.it/en/2020-12-11/nlp-ner">https://techblog.smc.it/en/2020-12-11/nlp-ner</a></em></p>]]>
            </description>
            <link>https://techblog.smc.it/en/2020-12-11/nlp-ner</link>
            <guid isPermaLink="false">hacker-news-small-sites-25391245</guid>
            <pubDate>Fri, 11 Dec 2020 21:27:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Stopped Hating TDD]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25391169">thread link</a>) | @thip
<br/>
December 11, 2020 | https://davidcapper.dev/posts/how-i-stopped-hating-tdd | <a href="https://web.archive.org/web/*/https://davidcapper.dev/posts/how-i-stopped-hating-tdd">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><img src="https://davidcapper.dev/assets/gabriel-garcia-marengo-2_F8_vP-_Sg-unsplash.jpg" alt="hourglass">
<em>Photo by <a href="https://unsplash.com/@gabrielgm">Gabriel Garcia Marengo</a> on <a href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></em></p>

<p>I didn’t used to enjoy TDD.  I thought I understood it - I’d tell people it was a useful practice and I’d go through all the motions when demonstrating it to them; but when push came to shove I’d quietly drop it as soon as I needed to do anything taxing.</p>

<p>I’ve always felt some embarrassment about this, possibly even guilt. The people I admired and looked up to as developers seemed so adamant that it is the right way to write software. They commanded such respect within the organisations and communities that they worked, and I wanted to be like them; calm, confident and measured , no project too daunting.</p>

<p>Yet, try as I might, I just couldn’t work out what their secret was. Why did they find TDD so enjoyable? Why did I get lost every time I tried to make an honest go of it? Why did I feel like such an imposter?</p>

<p>I think part of the problem was the apparent simplicity of the process. You write test code before you write production code. How hard can it be? It doesn’t help that people who have mastered the practice make it look effortless. The thing is… it’s not effortless. Not to start with anyway. I think the biggest pothole on the road to TDD enlightenment is the idea that you are suddenly going to feel enlightened. Like anything TDD takes practice and experience.</p>

<p>We get better at things little by little, step by step. The premise behind TDD is simple, but its application is nuanced. It’s okay (and normal) for things not to be perfect when you’re just starting out. If you find yourself stuck, don’t get hung up on it. Take a break from TDD and do what you need to do to move on. Writing code that is missing a few tricky tests is much more valuable than having something unfinished that no one gets to use.</p>

<p>It wasn’t until I started to forgive myself for not doing perfect TDD all the time that I started to get better at it. You need to give yourself room to make mistakes and learn what’s easy, and what’s difficult. If you don’t allow yourself to do things sub-optimally and move on, it’s impossible to look back and reflect upon how you might do it differently next time.</p>


  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://davidcapper.dev/posts/how-i-stopped-hating-tdd</link>
            <guid isPermaLink="false">hacker-news-small-sites-25391169</guid>
            <pubDate>Fri, 11 Dec 2020 21:20:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No Code Resource List]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25390486">thread link</a>) | @richardawoyemi
<br/>
December 11, 2020 | https://www.notion.so/No-Code-Resources-1c9a074f65f2419292558a7023cd97ef | <a href="https://web.archive.org/web/*/https://www.notion.so/No-Code-Resources-1c9a074f65f2419292558a7023cd97ef">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.notion.so/No-Code-Resources-1c9a074f65f2419292558a7023cd97ef</link>
            <guid isPermaLink="false">hacker-news-small-sites-25390486</guid>
            <pubDate>Fri, 11 Dec 2020 20:24:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Technical Interviewer's Checklist]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25390177">thread link</a>) | @jchen42
<br/>
December 11, 2020 | https://jeffchen.dev/posts/Technical-Interview-Checklist/ | <a href="https://web.archive.org/web/*/https://jeffchen.dev/posts/Technical-Interview-Checklist/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="__next"><div><div><main><article><div><p>I've interviewed hundreds of engineering candidates across multiple companies. With that experience, I've created a checklist to help ensure my technical interviews are effective and empathetic. Read on for the list!</p>
<!-- excerpt -->
<h2 id="before-the-interview">Before the interview</h2>
<ul>
<li>Read their resume and any prep materials you have (cover letter, notes from previous interviews, etc).</li>
<li>If it's a videocall, make sure your mic and webcam work - and turn your camera on!</li>
<li>Respect the candidate by showing up on time.</li>
</ul>
<h2 id="intros">Intros</h2>
<ul>
<li>Introduce yourself and smile when you do!</li>
<li>Ease the candidate in by having them talk about an interesting project they've worked on.
<ul>
<li>It'll help candidates calm their nerves by thinking about something they're already comfortable with.</li>
<li>Always respond positively to what they say!</li>
</ul>
</li>
<li>Set ground rules before diving into the question: Do you need working code? Can they Google things? What languages can they use? What are you looking to get out of the question?</li>
<li>Your interview question should have a clear CTA. After posing your question, candidates should know exactly what their next steps are.</li>
</ul>
<h2 id="the-technical-question">The technical question</h2>
<ul>
<li>Remember what it's like to be on the other side. Interviews are always stressful and scary: be empathetic and do whatever you can to reduce that stress!</li>
<li>Guide candidates through the question. If they're stuck, help them out. You'll get better signal by seeing them approach the whole problem.
<ul>
<li>In particular - help candidates with standard library calls. Having the standard library memorized or not isn't good signal.</li>
</ul>
</li>
<li>Take notes: it's hard to remember what happened in an interview after the fact.</li>
<li>Try to end on a positive note: if we end in the middle of a section, I like to connect where they are with where I wanted them to go.</li>
<li>As you close the question, tie it back back to a real-world problem.</li>
</ul>
<h2 id="closing-out">Closing out</h2>
<ul>
<li>Leave 5-10 minutes for them to ask you questions - and make sure to end on time.</li>
<li>Have answers to common questions prepared. Some common questions:
<ul>
<li>Why did you join Company X?</li>
<li>What's an interesting problem you've worked on at Company X?</li>
<li>What's something you don't like about Company X?</li>
</ul>
</li>
<li>Thank them for their time.</li>
<li>Submit your interview feedback ASAP.</li>
</ul>
</div><strong>Enjoyed this post? <a href="https://www.twitter.com/iambald" target="_blank">Follow me on Twitter</a> for more content like this!</strong><a href="">Scroll to top</a></article></main></div></div></div></div>]]>
            </description>
            <link>https://jeffchen.dev/posts/Technical-Interview-Checklist/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25390177</guid>
            <pubDate>Fri, 11 Dec 2020 19:59:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[IP Monopolies, Not Pirates, Are the Real Threat to Artists]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25389787">thread link</a>) | @panic
<br/>
December 11, 2020 | https://readpassage.com/ip-monopolies-not-pirates-are-the-real-threat-to-artists/ | <a href="https://web.archive.org/web/*/https://readpassage.com/ip-monopolies-not-pirates-are-the-real-threat-to-artists/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-postid="3718">
  <div>

    <div>
      <div>

        <div>
          
<p>We’ve all been lied to about piracy. Many of us have been made to believe that online “pirates” rob artists of their livelihood, while Intellectual Property (IP) law exists as a means of protecting the rights of individual creators to make a profit and protect their integrity.&nbsp;</p>



<p>What the rise of tech monopolies in the last decade has shown us is the opposite: IP law mostly serves corporate interests, while anyone who participates in digital public preservation, archiving and sharing is increasingly criminalized as a “pirate.”&nbsp;</p>



<p>The IP legal regime wasn’t created as an idealistic attempt to protect the rights of creators, but rather to grease the wheels for the further expansion of capital. Here’s how IP law has been used to create monopolies, crush the public domain and hurt the artists its proponents say it serves.&nbsp;</p>



<h3><strong>IP Laws And Monopolies</strong></h3>



<p>IP — that is, copyright, trademark, patents and to a lesser extent, trade secrets — didn’t really come into vogue until the latter half of the 19th century, notably in England.&nbsp;</p>



<p>At first, when competition was high, industrialists largely opposed expanded trademark and patent protections. Yet as monopolies and cartels grew, they began to support extra protections on trademarks. This is because, <a href="https://monthlyreview.org/2003/01/01/the-political-economy-of-intellectual-property/">according</a> to Marxist economist Michael Perelman, these companies needed more robust legal frameworks for protecting intangible assets such as brand exclusivity, and patents were also incredibly useful for companies in the United States looking to circumvent the Sherman Antitrust Act.&nbsp;</p>



<p>The term “intellectual property” wasn’t <a href="https://cyber.harvard.edu/people/tfisher/iphistory.pdf">used regularly</a> until the post-Second World War economic decline, when companies that had been opposed to state overreach in the past came to view property rights as a means to increase profits.</p>



<p>In the late 1980s, IP began to be even further expanded, at a dizzyingly rapid pace. Since then, scholars and activists have been warning that this expansion is serving monopoly capital in the growing tech sector.</p>



<p>Central European University sociological researcher Jakob Rigi has <a href="https://www.triple-c.at/index.php/tripleC/article/view/487/667">written</a> about how information itself, especially in the digital age, has nearly zero value because it requires little to no labour cost to reproduce (unlike, say, an iPhone). As a result, it’s nearly impossible to extract profit from information.&nbsp;</p>



<p>So, these tech multinationals are now wielding IP law to extract rents by selling access to, and exclusivity of, information — not by selling the information itself. Trademarks, patents and copyrights are instrumental for monopoly capital because they allow these large companies to extract rents in the form of subscriptions, franchises and licensing fees.&nbsp;</p>



<p>For example, the TRIPS agreement, which brought IP law into multilateral trading, was <a href="https://www.eff.org/issues/trips">ratified</a> in 1994. In 1998, United States President Bill Clinton signed the DMCA into law, which is still being <a href="https://www.highlandernews.org/34672/disney-lobbies-congress-change-copyright-laws/">tweaked</a> to privilege rights holders.</p>



<p>This dynamic has only been heightened in the past decade, with the Stop Online Piracy Act and Protect IP Act being brought to the U.S. House floor in 2011 with the <a href="https://en.wikipedia.org/wiki/List_of_organizations_with_official_stances_on_the_SOPA_and_PIPA#:~:text=The%20Stop%20Online%20Piracy%20Act,unions%20in%20the%20cable%2C%20movie%2C">backing</a> of ISPs and established entertainment industry cartels.</p>



<p>These acts were shelved a year later due to <a href="https://www.theverge.com/2012/1/18/2715300/sopa-blackout-wikipedia-reddit-mozilla-google-protest">vociferous resistance</a> from a huge array of tech companies (including Amazon and Google), which were, at that point, still in a period of high competition. However, now that some of these companies have succeeded in conquering the “Wild West” of the Internet and establishing monopolies, they’ve totally inverted their position.</p>



<h3><strong>IP Laws To Crush The Public Domain</strong></h3>



<p>As time wears on, and IP law is used to criminalize all forms of file-sharing and sampling, it becomes increasingly clear that the focus on “piracy” and illegal file-sharing is only a pretext at wearing down what still exists of the public domain to squeeze it for profit. This is because the companies using IP law in this way need to enclose and privatize what remains of the cultural commons to keep up their rate of profit.&nbsp;</p>



<p>In 2002, University of Gothenburg associate professor Johan Söderberg <a href="https://firstmonday.org/article/view/938/860">pointed out</a> that digital activists were fighting a major corporate tide against what remained of fair use and the Creative Commons. This has continued, and there are numerous examples of companies cracking down in the past decade alone.&nbsp;</p>



<p>In 2013, Reddit co-creator Aaron Swartz took his own life after prosecutors pursued charges against him carrying sentences of up to 35 years in federal prison for illicitly downloading nearly five million academic documents off of JSTOR. This happened even though JSTOR <a href="https://www.rollingstone.com/culture/culture-news/the-brilliant-life-and-tragic-death-of-aaron-swartz-177191/">refused</a> to press charges after Swartz returned the documents he’d downloaded (for reasons unknown, it was actually MIT that let the case go forward).</p>



<p>Then, there’s the ongoing lawsuit to destroy the Internet Archive, brought forward by major publishers such as HarperCollins and Hachette. The suit was in response to the Internet Archive launching the National Emergency Library at the outset of the pandemic, which is a temporary lending program to assist students.&nbsp;</p>



<p>The plaintiffs claim that the Internet Archive “illegally” scans the books it lends, which is not only a deliberate misrepresentation of special exceptions for libraries in the Copyright Act, but, according to The Nation writer Maria Bustillos <a href="https://www.thenation.com/article/society/publishers-are-taking-the-internet-to-court/">betrays</a> a “rentier mentality” that could unravel these protections.</p>



<p>Moreover, in late October, Amazon <a href="https://www.hollywoodreporter.com/thr-esq/amazon-argues-users-dont-actually-own-purchased-prime-video-content">filed</a> to dismiss a complaint from an Prime Video user who claimed the tech giant had engaged in “unfair competition and false advertising” for reserving the right to lock or remove on-demand content after it had been purchased.&nbsp;</p>



<p>Amazon’s motion argues that Prime customers don’t purchase the content they view. Rather, they purchase a “limited license” to consume the content. Already-existing IP law enables Amazon, which in its younger days had opposed SOPA and PIPA, to extend its domain into content streaming via a subscription model.&nbsp;</p>



<p>Shortly after, Twitch — an Amazon subsidiary, <a href="https://www.theinformation.com/articles/amazon-nears-deal-to-acquire-twitch">purchased in 2014</a>— found itself on the receiving end of ire for its handling of a sudden influx of DMCA notices (in all likelihood prompted by a pandemic-related <a href="https://www.weforum.org/agenda/2020/05/this-is-how-covid-19-is-affecting-the-music-industry/">drop</a> in recording industry profits this year.) In an official <a href="https://blog.twitch.tv/en/2020/11/11/music-related-copyright-claims-and-twitch/">blog post</a> published on November 11, the live-streaming service magnanimously describes new rules imposed on streamers to comply with copyright claims on background music, including muting in-game music.&nbsp;</p>



<p>These rules and tools were criticized for being haphazard, draconian and confusing, which led Twitch to issue a slight mea culpa before explaining that users can avail themselves of rights-cleared music libraries including Soundtrack, which they just so happen to own.&nbsp;</p>



<p>The consequences of these digital turf battles over licensing between corporate giants inevitably falls on users, while the spoils of profit and ownership go to the monopolies.&nbsp;</p>



<p>The use of IP to enclose information and sell access in exchange for a rent obviously has wide-ranging effects. When all human knowledge is eventually privatized, public archiving, preservation, curation and skill-sharing will be outlawed, and there will be <a href="https://www.i24news.tv/en/news/international/1600882251-zoom-cancels-scheduled-videoconference-with-palestinian-hijacker-leila-khaled">total</a> corporate control of speech rights.&nbsp;</p>



<h3><strong>IP Law Hurting Artists</strong></h3>



<p>Even the recent history of IP law shows that many of us, including artists, have been led astray chasing the windmills of “piracy” while monopolies expand into new frontiers. High profile cases like <a href="https://www.kerrang.com/features/metallica-vs-napster-the-lawsuit-that-redefined-how-we-listen-to-music/">Metallica vs. Napster</a><em> </em>or <a href="https://www.theverge.com/2015/2/14/8039413/megaupload-conviction-felony-nomm-kim-dotcom">Megaupload</a> are instructive, both in terms of the precedents they’ve set and how they’ve helped tech and entertainment companies control the narrative about what’s keeping artists poor.&nbsp;</p>



<p>While it’s reasonable to claim that such third party companies do profit from infringement (unlike the Internet Archive, digital libraries or public domain sites, which rely on work that’s either licensed, out of copyright and otherwise legally obtained), it’s as legitimate to claim that the corporations suing them are just as guilty of theft<strong> </strong>through IP farming, onerous contracts with obscenely low rates and sometimes outright plagiarism.&nbsp;</p>



<p>These monopolies succeeded in part by destroying file-sharing sites and refining and monetizing the streaming model once they were mostly out of the way. Intellectual property rights are as robust as ever, and the rise of music streaming has actually led to a music industry recovery that <a href="https://www.visualcapitalist.com/music-industry-sales/">began</a> in 2017, after about 15 years of decline following the death of the CD thanks to new, untamed digital technology. Yet somehow artists continue to lose both money and control over the work they make.&nbsp;</p>



<p>The recent Union of Musicians and Allied Workers (UMAW) “Justice at Spotify” <a href="https://www.complex.com/music/2020/10/union-of-musicians-and-allied-workers-demands-equity-justice-at-spotify-initiative">campaign</a> demonstrates that the rise of rentier platforms has: lowered the value of creative material to a greater extent than online piracy could ever achieve; made it more difficult for original creators to retain ownership of their work; concentrated the value of this work into fewer hands.&nbsp;</p>



<p>The UMAW <a href="https://www.unionofmusicians.org/justice-at-spotify-demands">list of demands</a> states, “Music workers create all of the enormous wealth Spotify accumulates for its CEO, its investors, and the major labels. But we artists continue to be underpaid, misled, and otherwise exploited by the company.” </p>



<p>UMAW calls for a restructuring of Spotify’s payment model, a 1-cent minimum payout per stream and for Spotify to <a href="https://variety.com/2020/music/news/spotify-amazon-songwriter-royalties-court-appeals-1203528044/">stop fighting artists</a> in court over rate hikes.&nbsp;</p>



<hr>



<p>The obvious answer to the question of monopoly capital and the legal regimes it uses to keep itself in power is usually some form of antitrust policy to break them up and increase competition. But we know from history that the nature of capitalism makes these boon periods temporary, volatile and prone to monopolism regardless of the law.&nbsp;</p>



<p>As writer Gavin Mueller has <a href="https://www.boundary2.org/2018/07/mueller/">noted</a>, the “cyberlibertarian” bent of preserving market competition and even enabling piracy to favour small business is largely “petty producer fantasies” that ignore the capitalist cycles that lead to monopolies in the first …</p></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://readpassage.com/ip-monopolies-not-pirates-are-the-real-threat-to-artists/">https://readpassage.com/ip-monopolies-not-pirates-are-the-real-threat-to-artists/</a></em></p>]]>
            </description>
            <link>https://readpassage.com/ip-monopolies-not-pirates-are-the-real-threat-to-artists/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25389787</guid>
            <pubDate>Fri, 11 Dec 2020 19:34:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[$100 robot kit running ROS2 and Navigation2]]>
            </title>
            <description>
<![CDATA[
Score 150 | Comments 26 (<a href="https://news.ycombinator.com/item?id=25389266">thread link</a>) | @jackp510
<br/>
December 11, 2020 | https://blog.hadabot.com/ros2-nav2-go-to-goal-low-cost-robot-kit.html | <a href="https://web.archive.org/web/*/https://blog.hadabot.com/ros2-nav2-go-to-goal-low-cost-robot-kit.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<div>
	  <p><a href="https://www.hadabot.com/">Hadabot</a> is a low-cost robot kit for students, software engineers, makers to learn <a href="https://index.ros.org/doc/ros2/">ROS2</a> and robotics in a hands-on manner. Our robot kits are easy to build, extensible, and customizable. The Hadabot software stack consists of an open source web browser-based coding environment to make the hacking experience frustration-free.</p>
<p><a href="https://www.hadabot.com/">Hadabot ROS2 "Turtle" robot kits are available for purchase</a>!</p>
<hr>
<p>In a previous post, we showcased the <a href="https://index.ros.org/doc/ros2/Tutorials/Turtlesim/Introducing-Turtlesim/">ROS 2 turtlesim</a> running with the <a href="https://navigation.ros.org/">Navigation2 (aka Nav2)</a> package. That exercise required the use of the <a href="https://wiki.ros.org/tf2">tf2</a> which manages all <a href="https://blog.hadabot.com/ros2-navigation-tf2-tutorial-using-turtlesim.html#what-is-tf2">the various coordinate frames of a robotics application</a>.</p>
<p>In this post, instead of turtlesim, we'll have Nav2 direct a physical Hadabot Turtle differential drive robot to a goal pose - position and orientation. This exercise will bring together rviz, tf2, Nav2 with our past writeups about the <a href="https://blog.hadabot.com/implement-ros2-odometry-using-vscode-in-web-browser.html">Turtle robot's odometry and kinematics</a>. We'll touch upon:</p>
<ol>
<li>
<p>How we compute odometry for Nav2</p>
</li>
<li>
<p>The Nav2 parameters we tweaked</p>
</li>
</ol>
<div>
  <p><img src="https://blog.hadabot.com/images/hadabot_ros2_nav2_logos.jpg">
  </p>
</div>

<hr>
<h3>1. ROS 2 Nav2 with a Hadabot Turtle robot</h3>
<p>As with all Hadabot examples, you can use the Hadabot stacks browser-based VSCode to compile and run the code.</p>
<p>Follow these steps:</p>
<ol>
<li>
<p>Set up / update your turn-key Hadabot software stack (which leverages Docker containers to ensure your code runs securely and efficiently on your local machine):</p>
<ul>
<li>
<p>If <strong>you are new to Hadabot</strong>, follow these <a href="https://www.hadabot.com/new-user-software-stack-setup.html" target="_blank">steps to set up Docker and get the Hadabot software stack up and running</a> (5 to 15 minutes).</p>
</li>
<li>
<p>Else if you are a <strong>returning Hadabot hacker</strong>, follow these <a href="https://www.hadabot.com/software-stack-update.html" target="_blank">steps to update your Hadabot software stack</a> (1-3 minutes).</p>
</li>
</ul>
</li>
<li>
<p><a href="http://localhost:9123/?folder=/home/hadabot/hadabot_main/content/p9" target="_blank">Launch the browser-based VSCode workspace specific to this post</a> (this link points to your localhost so everything is running securely on your local system).</p>
</li>
<li>
<p>In the left VSCode Explorer panel, right-click the <strong>README.md</strong> file -&gt; Open Preview.</p>
</li>
<li>
<p>Follow the instructions in the README to:</p>
<ul>
<li>
<p>Update your ROS 2 packages</p>
</li>
<li>
<p>Flash the example's ESP32 firmware</p>
</li>
<li>
<p>Compile the Navigation2 Hadabot Turtle robot controller and coordinate frame code.</p>
</li>
<li>
<p>Launch a browser-based VNC client to run the example.</p>
</li>
<li>
<p>Run a go-to-goal Navigation2 Hadabot Turtle example.</p>
</li>
</ul>
</li>
</ol>
<div>
    <div>
        <p>
            <iframe src="https://www.youtube-nocookie.com/embed/goSqLnv6jhE?start=0&amp;rel=0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
        </p>
    </div>
</div>

<h5>Rviz to visualize the Nav2 go-to-goal Hadabot Turtle example</h5>
<p>If you successfully ran the example, you'll notice that the Turtle starts in the middle of the "arena" (ie map). Each grid-box represents 1 meter in physical distance. The red-axis presents the Turtle pointed forward. Since ROS uses a right-handed coordinate system, positive <span>\(\omega\)</span> rotation results in the Turtle turning counter-clockwise. </p>
<p>For the video example, the goal pose was 1 meter to the Turtle's left, with a 90 degree orientation from its initial orientation. </p>
<p>Notice the Turtle didn't end up exactly 1 meter to its left, nor was it oriented exactly 90 degrees from its initial pose. This is due to 2 reasons due to nothing happening exactly in the real world (this is not a simulation anymore Dorothy) - (1) the Hadabot Turtle's speed sensors have errors which accumulates over time resulting in odometry drift, and (2) Nav2 goal checker allows for a tolerance in both distance and orientation from the specificed end-goal.</p>
<hr>
<h3>2. How we construct TF2 messages from odometry</h3>
<p>The Hadabot Turtle publishes each wheel's rotational velocity in radians per second. With the measured wheelbase and wheel radius of the Turtle, we apply <a href="https://en.wikipedia.org/wiki/Dead_reckoning">dead-reckoning</a> to determine how far each wheel has traveled in meters.</p>
<p>Once we know how far each wheel has traveled for our differential drive model, we can compute the linear distance and angular rotation <span>\((v, \omega)\)</span> for a unicycle model, which allows us to update the current pose and velocities of our Hadabot Turtle as an <a href="http://docs.ros.org/en/melodic/api/nav_msgs/html/msg/Odometry.html">Odometry ROS message</a>. All this is done in the <em>hadabot_controller.cpp</em> file.</p>
<p>Then we use effectively the same code as the turtlesim example to extract the pose information from the Odometry message and publish that out as tf2 messages which is used by Nav2 and rviz.</p>
<hr>
<h3>3. Setting up Nav2 for the Hadabot Turtle</h3>
<p>Nav2 is a complex ROS 2 package with a number of sub-packages / components around 3 main capabilities - localization, planning/controller, and mapping. For our go-to-goal example, we mainly use the planning/controller component.</p>
<p>There are conceptually 2 types of planners in Nav2 - a global planner, and a local planner. The global planner computes a global trajectoy to get to our goal pose. The local planner references the global plan to determine the best linear and angular velocity for the robot to undertake to safely move along the global trajectory. </p>
<p>The global planner (as of 2020-12) defaults to a variation of a <a href="https://en.wikipedia.org/wiki/A*_search_algorithm">A* search</a> based planner. The local planner is called the <a href="https://vimeo.com/236487972">DWB planner, initially created by David Lu back in the ROS 1 days</a>, which implements the <a href="https://en.wikipedia.org/wiki/Dynamic_window_approach">Dynamic Window Approach (DWA) algorithm</a> created by Dieter Fox, Wolfram Burgard, and Sebastian Thrun. The DWB planner is driven by "critics" which vote on various local trajectories to undertake. Each critic "cares" about a certain behavior (ie avoiding abstacles, avoiding oscillation, going fast, etc). The local trajectory with the highest vote wins and that results as the Twist message command to direct the robot's current velocities.</p>
<p>Configuring Nav2 for our go-to-goal example involved tuning the parameters for the planning/controller. The ones we tweaked for the Hadabot Turtle are the max velocities of our robot, and controller update frequency (to update frequently enough but not so much that it floods our "hobbyist" network capabilities). There are many other <a href="https://navigation.ros.org/configuration/index.html">Nav2 parameters we can consider and tune</a>, which can be a series of posts and exercises on its own. </p>
<hr>
<h3>4. Conclusion</h3>
<p>In this post, we did the following:</p>
<ol>
<li>
<p>Showed a example of running a physical real-life Hadabot Turtle robot using ROS 2 Nav2.</p>
</li>
<li>
<p>We described how we use dead-reckoning to compute the Turtle's pose and velocities.</p>
</li>
<li>
<p>We talked a bit about Nav2 and what we tweaked to get our goal-to-goal example to work.</p>
</li>
</ol>
<p>In future posts, we can take this exercise down 2 separate threads - (1) to walk through some of the Nav2 parameters in more detail, start looking closer at Nav2, or (2) to showcase a Hadabot Turtle with a skirt of range-sensors (add-on for the base Turtle kit) to further explore localization and then SLAM with Nav2.</p>
<p>Additionally, we are working with various professors to create a more structured ROS 2 robotics syllabus and curriculum.</p>
<p>Please sign up to stay in touch for more info (as well as any promo offers we will run in the near future)!</p>
<hr>
<p>Thanks again for following along. If you enjoyed the post, there are 2 ways to continue to learn with Hadabot:</p>
<ol>
<li>
<p>Sign up to stay in touch (via the <strong>Stay in Touch</strong> buttons above and below) with future post updates, as well as promos and giveaway opps.</p>
</li>
<li>
<p><a href="https://www.hadabot.com/purchase.html">Purchase a Hadabot Turtle kit</a> to start your robotics adventures!</p>
</li>
</ol>
<p>Thanks and happy building!<br>
Jack "the Hadabot Maker"</p>

	</div>
      </div></div>]]>
            </description>
            <link>https://blog.hadabot.com/ros2-nav2-go-to-goal-low-cost-robot-kit.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25389266</guid>
            <pubDate>Fri, 11 Dec 2020 18:56:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sales tax creates more unnecessary pain than value added tax]]>
            </title>
            <description>
<![CDATA[
Score 169 | Comments 141 (<a href="https://news.ycombinator.com/item?id=25389123">thread link</a>) | @dyno-might
<br/>
December 11, 2020 | https://dyno-might.github.io/2020/12/09/sales-tax-creates-more-unnecessary-pain-than-value-added-tax/ | <a href="https://web.archive.org/web/*/https://dyno-might.github.io/2020/12/09/sales-tax-creates-more-unnecessary-pain-than-value-added-tax/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
        <div>
            
            <p><strong>Dec 9, 2020</strong></p>
            
            <p>It turns out that sales tax has a huge, gigantic, terrible flaw: It punishes specialized businesses. A value added tax (VAT) has no such problems.</p>

<p>The US has sales tax. Most of the planet has VAT.</p>

<p><img src="https://dyno-might.github.io/img/vat/VAT_map_updated.png" alt="VAT map"></p>

<p>Maybe it’s not the most important issue in the world, but it’s just so <em>clear</em>. Sales tax is dumb and VAT is better.</p>



<p>Many people apparently believe that in the US today, sales tax is only paid by final consumers. <strong><a href="https://www.cost.org/globalassets/cost/state-tax-resources-pdf-pages/cost-studies-articles-reports/1903-3073001_cost-ey-sales-tax-on-business-inputs-study_final-5-16.pdf">THIS IS FALSE</a></strong>. It varies hugely by state, but the current situation is a hybrid between a “pure final retail consumer only” sales tax and what the toy model below describes. You can debate if it’s “sales tax” or “gross receipts tax” or whatever, but it’s a fact that <em>businesses pay tax on business inputs</em> all the time. You can find proof of this <a href="https://www.cost.org/globalassets/cost/state-tax-resources-pdf-pages/cost-studies-articles-reports/1903-3073001_cost-ey-sales-tax-on-business-inputs-study_final-5-16.pdf">here</a> or <a href="https://www.ncsl.org/documents/standcomm/sccomfc/Business-Inputs-Study.pdf">here</a> or <a href="https://www.jstor.org/stable/41788786">here</a> or <a href="https://en.wikipedia.org/wiki/Gross_receipts_tax#United_States">here</a>.</p>

<p>I emphasize that the explanation below is a toy, intended to illustrate in the simplest possible way how specialization gets punished when transfers are taxed in proportion to their values. The current reality not <em>nearly</em> this bad due to many complex exemptions, as I discuss at the end. But the flaw described <em>does</em> exist and <em>does</em> punish specialization. I beg you: <strong><a href="https://www.cost.org/globalassets/cost/state-tax-resources-pdf-pages/cost-studies-articles-reports/1903-3073001_cost-ey-sales-tax-on-business-inputs-study_final-5-16.pdf">IF YOU THINK THE US DOESN’T HAVE TAXES WHERE THE SAME UNIT OF VALUE IS TAXED MULTIPLE TIMES PLEASE READ THIS LINK.</a></strong></p>

<p>OK, let’s continue.</p>



<p>Say you decide to get into the decorative <a href="https://dyno-might.github.io/2020/12/09/sales-tax-creates-more-unnecessary-pain-than-value-added-tax/(https://dyno-might.github.io/2020/09/11/comparative-advantage-and-when-to-blow-up-your-island/)">coconut</a> manufacturing business.</p>

<p>You’re good at painting coconuts. You find a friend who is good at picking them, and another who’s good at making coconut paint. You find a third friend who’s a genius with applying finishing lacquer and a fourth who runs a store.</p>

<p>You buy coconuts and paint, apply the paint, then sell to the finisher. He applies lacquer and sells to a retailer.</p>

<p><img src="https://dyno-might.github.io/img/vat/supply_chain.jpg" alt="supply chain"></p>

<p>After negotiating prices, you settle on $1 for a raw coconut, $1 for a coconut’s worth of paint, $3 for a painted coconut, $4 for a finished coconut, and $5 retail. This works out to everyone making $1 of profit.</p>

<p><img src="https://dyno-might.github.io/img/vat/market.jpg" alt="market"></p>

<p>Here’s a table showing the accounts:</p>

<table>
  <thead>
    <tr>
      <th>Item</th>
      <th>Cost of inputs</th>
      <th>Profit</th>
      <th>Price</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Raw coconuts</td>
      <td>$0</td>
      <td>$1</td>
      <td>$1</td>
    </tr>
    <tr>
      <td>Paint</td>
      <td>$0</td>
      <td>$1</td>
      <td>$1</td>
    </tr>
    <tr>
      <td>Painted coconut</td>
      <td>$2 (raw coconut+paint)</td>
      <td>$1</td>
      <td>$3</td>
    </tr>
    <tr>
      <td>Finished coconut</td>
      <td>$3 (painted coconut)</td>
      <td>$1</td>
      <td>$4</td>
    </tr>
    <tr>
      <td>Retail coconut</td>
      <td>$4 (finished coconut)</td>
      <td>$1</td>
      <td>$5</td>
    </tr>
  </tbody>
</table>



<p>For a while, everything runs beautifully. Every day you wake eager to help capture more beauty in coconut form — and then the government announces a 20% sales tax. Whenever you sell something, you need to pay 20% of the sale price to the government.</p>

<p>You talk it over. Everyone feels they still deserve to make the same $1 profit as before. Since you now pay $1.20 for a raw coconut and $1.20 for paint, you need to mark up to $3.40 before tax, and $4.08 after.</p>

<p>After everyone marks up their prices in this way, here are the results:</p>

<p><img src="https://dyno-might.github.io/img/vat/sales_tax.jpg" alt="sales tax"></p>

<table>
  <thead>
    <tr>
      <th>Item</th>
      <th>Cost of inputs</th>
      <th>Profit</th>
      <th>Price</th>
      <th>Price after tax</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Raw coconut</td>
      <td>$0</td>
      <td>$1</td>
      <td>$1</td>
      <td>$1.2</td>
    </tr>
    <tr>
      <td>Paint</td>
      <td>$0</td>
      <td>$1</td>
      <td>$1</td>
      <td>$1.2</td>
    </tr>
    <tr>
      <td>Painted coconut</td>
      <td>$2.4</td>
      <td>$1</td>
      <td>$3.40</td>
      <td>$4.08</td>
    </tr>
    <tr>
      <td>Finished coconut</td>
      <td>$4.08</td>
      <td>$1</td>
      <td>$5.08</td>
      <td>$6.10</td>
    </tr>
    <tr>
      <td>Retail coconut</td>
      <td>$6.10</td>
      <td>$1</td>
      <td>$7.10</td>
      <td>$8.52</td>
    </tr>
  </tbody>
</table>

<p>Your customers aren’t thrilled about the increase in price, but what are they going to do — live <em>without</em> painted coconuts? So they pay the higher price, the government gets its tax, and life continues.</p>



<p>A few months later, your unscrupulous  cousin hears about your business. He’s the jealous type and decides to try stealing your customers. He opens a store and finds four friends to help make coconuts. Unlike you, however, he hires everyone as <em>employees</em>. He sells the coconuts for $6 ($5 plus tax) and gives everyone $1 per coconut in wages.</p>

<p><img src="https://dyno-might.github.io/img/vat/integrated.jpg" alt="integrated"></p>

<p>Your cousin and friends don’t appreciate the subtle art of coconut decoration. Everyone agrees yours are better but they start to complain: Why are you charging $8.52 when a slightly worse product is available for only $6? Slowly, your loyal customers drift away and you go out of business.</p>

<p>How could this happen? Your team was asking for the same profit while doing a better job! Yet everyone is left with your cousin’s knock-off coconuts.</p>



<p>Suppose the government had instead announced a 20% VAT. With a VAT, whenever you sell something, you only pay tax on the sale price <em>minus the price of the stuff you bought to make it</em>.</p>

<p>As before, you’ll need to pay $1.20 for raw coconuts and $1.20 paint. You charge $3.40 for painted coconuts, now you’re only taxed on the profit of $3.40-$2.40=$1.00. The price with tax is now $3.60.</p>

<p>Here are the final prices as they go through through the system. Everyone is making a profit of $1, so everyone pays a tax of $0.20.</p>

<p><img src="https://dyno-might.github.io/img/vat/vat.jpg" alt="vat"></p>

<table>
  <thead>
    <tr>
      <th>Item</th>
      <th>Cost of inputs</th>
      <th>Profit</th>
      <th>Price</th>
      <th>Price after tax</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Raw coconut</td>
      <td>$0</td>
      <td>$1</td>
      <td>$1</td>
      <td>$1.2</td>
    </tr>
    <tr>
      <td>Paint</td>
      <td>$0</td>
      <td>$1</td>
      <td>$1</td>
      <td>$1.2</td>
    </tr>
    <tr>
      <td>Painted coconut</td>
      <td>$2.4</td>
      <td>$1</td>
      <td>$3.40</td>
      <td>$3.60</td>
    </tr>
    <tr>
      <td>Finished coconut</td>
      <td>$3.60</td>
      <td>$1</td>
      <td>$4.60</td>
      <td>$4.80</td>
    </tr>
    <tr>
      <td>Retail coconut</td>
      <td>$4.80</td>
      <td>$1</td>
      <td>$5.80</td>
      <td>$6.00</td>
    </tr>
  </tbody>
</table>

<p>The final price is $6.00. Since your coconuts are better, your cousin won’t be able to drive you out of business with his low-grade stuff.</p>



<p>What happened? Your cousin created a <em>vertically integrated</em> business. A sales tax is collected every time someone buys something. If you just do it yourself, no tax is collected.</p>

<p>Are vertically integrated businesses bad? Not necessarily.</p>

<p>However, take your chain of independent independent artisans making and selling coconut products. Imagine someone invents a paint that customers prefer. You almost <em>have</em> to switch, or some other painter will drive you out of business. Contrast this with cousin’s integrated business making all coconuts. In theory, the inventor could convince your cousin to hire him or license the paint process. If he won’t be convinced, the only way for that paint to get to customers is if the inventor develops an entire independent coconut manufacturing chain. Vertical integration means there are price signals at fewer points during production, which tends to make it harder for innovations to thrive.</p>

<p>There are times where vertical integration is better. (If everyone is independent, a lot of time is spent on negotiations!) That’s perfectly fine. What we <em>don’t</em> want is to artificially encourage vertical integration even when it’s less efficient, which sales tax does.</p>



<p>Another advantage of the VAT is it tends to be easier to enforce. When I sell something, I need to provide certificates proving I paid VAT on my inputs. This gives everyone an incentive to ensure compliance in the previous layer of the chain. With a sales tax, the government needs to watch every single transaction.</p>

<p>Of course, people know sales tax is distortionary. Many exceptions exist to minimize the worst distortions. For example, a retailer usually won’t pay sales tax on a manufactured good they intend to a consumer in the same form. Without this exception, we’d probably have a crazy economy where manufacterers sell directly to consumers. The messy patchwork of exceptions reduces the problems with sales tax but doesn’t eliminate them.</p>

<p>I think there are two major reasons to oppose replacing sales tax with VAT. The first is a Leninist “worse is better” attitude. If you think <em>all taxes are bad</em> then you’d want to keep them painful and visible so people will be maximally annoyed by them. The second is that VAT is complicated to administer, particularly when sales tax can be different in each local area. This might be true, but I find it a bit hard to believe. VAT is more self-enforcing and sales taxes are <em>already</em> a nightmare, particularly for anyone selling to different cities/states. If we’re keeping the sales tax to keep things simple, where’s the payoff?</p>

<p><img src="https://dyno-might.github.io/img/vat/lenin_text_small.png" alt="lenin"></p>

<h3 id="notes">Notes</h3>

<ul>
  <li>The initial map is based on Wikipedia, but found that many places (<a href="https://taxsummaries.pwc.com/thailand/corporate/other-taxes">Thailand</a>, <a href="https://home.kpmg/us/en/home/insights/2020/05/tnf-saudi-arabia-vat-rate-to-increase-to-15-percent-covid-19.html">Saudi Arabia</a>, <a href="https://en.wikipedia.org/wiki/Taxation_in_Iran#Value_added_tax_(VAT)">Iran</a>, <a href="https://www2.deloitte.com/om/en/pages/tax/articles/oman-to-implement-vat-from-2021.html">Oman</a>, <a href="https://u.ae/en/information-and-services/finance-and-investment/taxation/valueaddedtaxvat">UAE</a>, <a href="https://www.reuters.com/article/us-kuwait-economy-tax-idUSKCN1IG0OW">Kuwait</a>, <a href="https://news.bloombergtax.com/daily-tax-report-international/insight-early-days-for-angola-value-added-tax">Angola</a>, <a href="https://www.avalara.com/vatlive/en/vat-news/liberia-to-introduce-vat-2019.html">Liberia</a>) have recently implemented VAT. I checked that most of the others (<a href="https://taxsummaries.pwc.com/jordan/corporate/other-taxes">Jordan</a>, <a href="https://en.wikipedia.org/wiki/Taxation_in_Greenland">Greenland</a>, <a href="https://www.tradecommissioner.gc.ca/france/market-facts-faits-sur-le-marche/7685.aspx?lang=eng#valuetax">French Guinana</a>, <a href="https://www.nordeatrade.com/en/explore-new-market/cuba/taxes">Cuba</a>, <a href="https://taxsummaries.pwc.com/libya/individual/other-taxes">Libya</a>, Hong Hong) still do not have a VAT.</li>
  <li>To be sure, if you could implement a sales tax that only applied to final consumers, that would be economically equivalent to VAT. Is that how state taxes work in the US? It’s hard to make simple generalizations because (1) it’s sometimes hard to say what a “final consumer” is (2) there are different laws in each state and (3) the relevant tax is sometimes called a “gross receipts” tax. The important question is: <strong>Does the US have taxes on intermediate products</strong> that “cascade” like described in the above model? The answer to that question is <a href="https://www.cost.org/globalassets/cost/state-tax-resources-pdf-pages/cost-studies-articles-reports/1903-3073001_cost-ey-sales-tax-on-business-inputs-study_final-5-16.pdf">YES</a>.</li>
</ul>

        </div>

        

        
        
    </div>
</div></div>]]>
            </description>
            <link>https://dyno-might.github.io/2020/12/09/sales-tax-creates-more-unnecessary-pain-than-value-added-tax/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25389123</guid>
            <pubDate>Fri, 11 Dec 2020 18:45:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No VPN? No problem! Using SSH tunnels for remote access to closed networks]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25388960">thread link</a>) | @admsg
<br/>
December 11, 2020 | https://adamsgaard.dk/ssh-tunnels.html | <a href="https://web.archive.org/web/*/https://adamsgaard.dk/ssh-tunnels.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<header>
	
	<p><strong>Last modification on </strong> <time datetime="2020-12-11">2020-12-11</time></p>
</header>

<h2>Rationale</h2>

<p>Corporate and academic networks are closed by design, with routers
and firewalls forwarding and filtering content going to and from
the wider internet.  For security reasons this is an absolute
necessity, as the guardkeeping prevents unwanted incoming connections
to the networked devices.</p>

<p>However, it is often necessary to connect to internal devices or
services from the outside.  This could be the case if an employee
needs to access a shared database on the company network, or a
subscription website only allows full access from a certain range
of IP addresses.  Network administrators usually offer virtual
private network (VPN) access to achieve such goals.  Unfortunately,
VPN access occasionally requires particular software that may not
work on all operating systems.  In other cases, the network
administrators may enforce strict requirements to the remote systems
before allowing VPN access.</p>

<pre><code> ###### Closed Network ######
 #                          #
 #  +----------+      +----------+             +----------+
 #  |  Office  |      | Router/  |      ?      | Outside  |
 #  | Computer |&lt;~~~~&gt;| Firewall |    ?   ?    | Computer |
 #  +----------+      +----------+             +----------+
 #                          #
 ############################
</code></pre>

<p>So what do you do if you need outside access to a network, have no
administrative rights over the router and firewall, and cannot (or
don't want to) access via VPN?  Fortunately, OpenSSH, the widely
used secure shell (SSH) implementation, offers simple and secure
solutions to this problem.  Almost all Linux/BSD/UNIX/MacOS systems
come with OpenSSH preinstalled, so you might already have it on
your system.</p>

<p>If you can access the closed network from the outside via SSH, this
makes things straightforward as described in Scenario 1 below.  If
not, see Scenario 2.</p>


<h2>Scenario 1: SSH access available from the outside</h2>

<p>Some networks are configured to allow outsiders to connect to an
internal SSH server through port forwarding on the network router:</p>

<pre><code> ###### Closed Network ######
 #                          #
 #  +----------+      +----------+      +----------+
 #  |  Office  |  SSH | Router/  |  SSH | Outside  |
 #  | Computer |&lt;~~~~~| Firewall |&lt;~~~~~| Computer |
 #  +----------+      +----------+      +----------+
 #                          #
 ############################
</code></pre>

<p>For the purposes described here, this is an ideal situation since
it is easy to create a tunnel that connects the outside computer
with the internal network via SSH.  The following command creates
the tunnel when executed on the outside computer:</p>

<pre><code>ssh -D 1337 -C -N company-domain.com
</code></pre>

<p>Note that the port number specified with the -D option should be
greater than 1000 when running as an unpriviledged (non-root) user.
The -C option turns on compression, which is useful for slow network
connections at the cost of little CPU overhead.</p>

<p>With the SSH tunnel in place, you can make most webbrowsers and
other network programs on the outside computer use the tunnel for
all their network traffic by pointing them to the SOCKSv5 proxy
"socks://localhost:1337".  This allows access from programs on the
outside computer to any device within the closed network.  Connections
to the wider internet utilizing the tunnel will originate from an
IP address associated with the closed network, achieving the
objectives stated above.</p>


<h2>Scenario 2: SSH access unavailable from the outside</h2>

<p>Unfortunately, outside SSH access to corporate networks is becoming
increasingly rare.  However, the OpenSSH toolset again offers a
solution if you have a persistent SSH server outside of the network
at your disposal:</p>

<pre><code> ###### Closed Network ######
 #                          #
 #  +----------+      +----------+      +---------+      +---------+
 #  |  Office  |  SSH | Router/  |  SSH | Outside |  SSH | Outside |
 #  | Computer |&lt;~~~~&gt;| Firewall |&lt;~~~~&gt;| Server  |&lt;~~~~~| Laptop  |
 #  +----------+      +----------+      +---------+      +---------+
 #                          #
 ############################
</code></pre>

<p>As long as you can initiate *outgoing* SSH connections from inside
the closed network to your outside SSH server, you can create a
reverse ssh tunnel and utilize it in a similar manner as in the
previous scenario.  On the office computer, create a reverse tunnel
to the outside server:</p>

<pre><code>ssh -f -N -R 10022:localhost:22 outside-server.com
</code></pre>

<p>As long as the above command runs, you can initiate new SSH connections
from the outside server to the office computer with the command
`ssh -p 10022 localhost`.  If you're working from an outside laptop,
you can utilize this reverse tunnel to connect to the office computer
and network.  Add the following configuration to `~/.ssh/config`
on the outside laptop:</p>

<pre><code>Host office_computer
    ProxyCommand ssh -q outside-server.com nc localhost 10022
</code></pre>

<p>With the above configuration, it is very easy to establish a SSH
connection from the outside laptop to the office computer:</p>

<pre><code>ssh office_computer
</code></pre>

<p>As in the previous example, you can use this setup to create a SSH
tunnel all the way from the outside laptop to the office computer:</p>

<pre><code>ssh -D 1337 -C -N office_computer
</code></pre>

<p>Again, this creates a SOCKSv5 proxy that you can use for tunneling
network traffic from the outside laptop to the closed network.  It
is useful to automatically monitor the tunnel status using pgrep(1),
and reinitialize it if the ssh command unexpectedly quits.</p>


<h2>References</h2>

<ul>
<li>OpenSSH: <a href="https://www.openssh.com/">https://www.openssh.com/</a></li>
<li>ssh(1) manual page: <a href="https://man.openbsd.org/ssh">https://man.openbsd.org/ssh</a></li>
<li>gramscii(1), used for drawings in this post: git://bitreich.org/gramscii</li>
</ul>

<p>Thanks to KatolaZ for feedback on this post.</p>

			</article></div>]]>
            </description>
            <link>https://adamsgaard.dk/ssh-tunnels.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25388960</guid>
            <pubDate>Fri, 11 Dec 2020 18:31:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Obscure Government Agency Changing VC Investing]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25388867">thread link</a>) | @donnyNz
<br/>
December 11, 2020 | https://contrarycap.com/content/cfius | <a href="https://web.archive.org/web/*/https://contrarycap.com/content/cfius">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><hr>
<p>When Chinese tech giant ByteDance acquired LA-based <a href="http://musical.ly/">Musical.ly</a> in 2019 to create TikTok, they didn't think the U.S. federal government would even note the transaction.</p>
<p>Then, an obscure group of Treasury Department regulators wrote a report.</p>
<p>Fast-forward to today: <a href="https://www.cnn.com/2020/11/11/tech/tiktok-deadline-trump-november/index.html">TikTok is sitting in legal purgatory</a>, under pressure from the White House, as companies like Oracle and Microsoft attempt to carve off pieces of it from ByteDance. Should the sale fall apart, there's a real possibility the Department of Justice will sue ByteDance to force a divestment.</p>
<p>The TikTok saga is the tip of the iceberg. As recently as 2017, Chinese venture investors were breaking records, putting in billions of dollars across hundreds of deals in U.S. based startups. By 2019, those numbers had fallen by about half, as this graph from Preqin shows.</p>
<p><img src="https://contrarycap.com/images/content/cfius-graph.png" alt="/images/content/cfius-graph.png"></p>
<p>Simultaneously, regulators <a href="https://www.reuters.com/article/us-grindr-m-a-beijingkunlun/chinas-kunlun-tech-agrees-to-u-s-demand-to-sell-grindr-gay-dating-app-idUSKCN1SJ28N">forced the divestment of Grindr</a> and <a href="https://www.stayntouch.com/news/stayntouch-remains-committed-to-customers-and-growth-after-trump-administrations-order">StayNTouch</a>, and blocked a $1.2B deal between Moneygram and Ant Financial.</p>
<p>What happened? <a href="https://www.lawfareblog.com/foreign-investment-risk-review-modernization-act-2018">FIRRMA happened</a>.</p>
<p>This law, passed in August 2018, gave significant new powers to a traditionally toothless Treasury agency, and turned it into one of the most important players in the tech world. We're talking about <strong>the Committee on Foreign Investment in the U.S., or CFIUS.</strong></p>
<p>Almost immediately after Congress beefed up CFIUS, there were reports of previously solid deals that began falling apart as VCs and entrepreneurs became cold on working with foreign sources of capital.</p>
<p>Their new reluctance was well-founded. CFIUS 2.0 has created a lot of risk for entrepreneurs and investors that work with foreign-based capital. This post is a guide on when CFIUS comes into play, and a breakdown of how this Treasury agency has changed venture investing in the last two years.</p>
<h2><a name="its-the-critical-technology"></a>It's the Critical Technology</h2>
<p>The Foreign Investment Risk Review Modernization Act (FIRRMA) didn't get a lot of press coverage when President Trump signed it into law in August 2018, but it made CFIUS powerful.</p>
<p>It expanded their jurisdiction to cover a much larger spread of investments made by foreigners — defined as people who aren't citizens or legal residents of the U.S. — compared to before. Previously, CFIUS review was almost always voluntary, and the agency only reviewed deals where a foreign investor would take a majority stake in a company. FIRRMA gave CFIUS the ability to evaluate any investment in a private company, <em>even a minority stake</em>, so long as all one or more of these triggers apply:</p>
<ul>
<li>The business receiving investment "owns, operates, manufactures, fabricates, or services critical infrastructure"</li>
<li>If the company works with a "critical technology" (this includes 27 broad categories, like artificial intelligence, autonomous mobility, battery technology, Fintech, VR, and cybersecurity)</li>
<li>If the company maintains or collects exploitable, sensitive personal data of U.S. citizens.
<ul>
<li>Grindr's sale to a Chinese company in 2016 prompted this, and in March 2019, CFIUS ordered Kunlun Tech to divest Grindr over expected concerns about access to personal data. That's right - CFIUS can launch an investigation and force divestment any time.</li>
</ul></li>
</ul>
<p>If CFIUS identifies a security risk, the White House can block a deal or force a divestment. <a href="https://www.hklaw.com/en/insights/publications/2020/02/new-cfius-regulations-finally-take-effect">This article</a> from the law firm Holland and Knight gives a deeper dive on the regulations and covers some of the nuances, like the <a href="https://www.lexology.com/library/detail.aspx?g=bc12e415-9a3f-4f66-a14a-5006c91a8005">exempted countries</a>.</p>
<p>CFIUS has had a significant impact in early-stage investing, because lot of VC deals fall the agency's broad definition of critical technology.</p>
<p>If you're an entrepreneur working in their critical technology space, and you try to take on foreign funding, what happens?</p>
<p>Before 2018, nothing. Now, both parties (the company and the investors) are legally obligated to apply for review by CFIUS. They give out big fines for failing to apply, and they work with the FBI to monitor for deals that tried to sneak through without review. They reject any applications where the investment would pose a "national security risk" - which puts Chinese-based investments under high scrutiny given geopolitical tensions.</p>
<p>This might not sound too onerous, and CFIUS reportedly approves a fair percentage of applicants. The issue is time - CFIUS reviews can take up to 90 days. Entrepreneurs that are raising need a fast yes/no from investors, and many haven't been willing to submit to the delays and scrutiny that come with taking foreign capital. Investors are also advising their companies to hunt for capital elsewhere, instead of from a foreign source that might lead to a CFIUS review or a block.</p>
<p>Now, there is a caveat here. CFIUS only comes into play in a non-controlling investment if the foreign investor gains access to "material nonpublic technical information", or "has substantive involvement in the U.S. business's decision-making with respect to the technology, infrastructure, or data."</p>
<p>This leaves room for a lot of exemptions. For example, a VC firm with American general partners could have all foreign-based LPs, and as long as those LPs were kept in the dark on their portfolio companies (and you can bet the FBI will monitor that) the firm would be in the clear. A "silent money" investor, who gives capital but has no real involvement in the business, would also be safe. But, most founders want more from their investors than capital, and most investors aren't going to make a deal where a single update email could lead to regulatory scrutiny.</p>
<p>So while there are potential workarounds, the broad definition of "critical technology" and the long review process is chilling certain foreign investment in U.S. startups.</p>
<h2><a name="cfius-makes-their-mark"></a>CFIUS Makes Their Mark</h2>
<p>Let's not overstate it. Despite CFIUS, billions in foreign capital is still flowing through the U.S. startup ecosystem. They try to approve most applications within a month, and the committee has reviewed then approved hundreds, if not thousands, of deals.</p>
<p>At the same time, a lot less deals are being made by Chinese-based investors compared to before. U.S. investors and entrepreneurs aren't accepting their money with such ease, and prospective Chinese investors are deciding the headache just isn't worth it. Given how broad the "critical technology" category is, too many of their deals are required to file the application. For example, Alibaba, which has invested billions in U.S. based startups since 2013, <a href="https://www.ft.com/content/9f2aaea0-4ae2-11ea-95a0-43d18ec715f5">made no publicly disclosed investments in the U.S.</a> in 2019. In fact, publicly disclosed investments in US start-ups by Baidu, Alibaba and Tencent fell 84 per cent from 2018, according to an analysis by PitchBook. A number of Chinese VC firms, like <a href="https://www.cnbc.com/2019/05/14/kai-fu-lee-sinovation-ventures-retreats-from-us-amid-trade-dispute.html">Sinovation Ventures</a>, have completely stopped making U.S. investments.</p>
<p>Why have Chinese investors been especially hard hit? It's because CFIUS makes a final decision on whether or not to approve a deal based on national security risk. Current political tensions, the Chinese Communist Party's deep involvement in "private" Chinese companies/investors, and the Communist Party's publicly-admitted habit of IP theft, puts investments stemming from China in a high risk category, according to the federal government.</p>
<p>Post-FIRRMA, the environment has changed so much that Chinese investors are willingly opting out of the U.S. market. Their logic is that successful entrepreneurs running hot startups have plenty of options for financing that won't trigger a review by the U.S. government, so a China-based VC firm is unlikely to get in to the best deals, anyway.</p>
<p>Theodore Schleifer has a <a href="https://www.vox.com/recode/2019/5/1/18511540/silicon-valley-foreign-money-china-saudi-arabia-cfius-firrma-geopolitics-venture-capital">solid piece in Recode on foreign cash in Silicon Valley</a>, and collected some interesting words from VCs on how they are cautioning their portfolio companies:</p>
<p>One venture capitalist active in financing companies in frontier technologies said he now assumed that his portfolio companies could never raise money from foreign investors from now on. A second said his firm recommended to a CEO that going through CFIUS review in order to take Chinese capital was not worth the headache. Schleifer writes that "Some in Silicon Valley have even undertaken projects to identify all venture firms primarily backed by the Chinese government — crafting their own private investor blacklists."</p>
<p>These investors are playing it safe for good reason. Ultimately, the new CFIUS, combined with <a href="https://www.washingtonpost.com/opinions/2020/07/14/tensions-with-china-are-rising-whats-next-step/">rising U.S.-China</a> tension, has made it riskier and much more burdensome for entrepreneurs to work with foreign investors. It's also made it riskier for VCs to take on foreign LPs, unless said LPs are truly passive and kept almost completely in the dark on how their portfolio companies are performing. The years of CFIUS flying under the radar have come to an end, and they're going to be a big player in the tech world for decades to come.</p>
</div></div></div>]]>
            </description>
            <link>https://contrarycap.com/content/cfius</link>
            <guid isPermaLink="false">hacker-news-small-sites-25388867</guid>
            <pubDate>Fri, 11 Dec 2020 18:22:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The “Complexity Zoo” has moved]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25388790">thread link</a>) | @furcyd
<br/>
December 11, 2020 | https://complexityzoo.net/Complexity_Zoo | <a href="https://web.archive.org/web/*/https://complexityzoo.net/Complexity_Zoo">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="mw-content-text" lang="en" dir="ltr"><div>
<h2><span id="Introduction">Introduction</span></h2>
<p>Welcome to the <b>Complexity Zoo</b>... There are now 545 classes and counting!
</p>
<div><div><p><a href="https://complexityzoo.net/File:Zoo.gif"><img alt="" src="https://complexityzoo.net/images/f/f6/Zoo.gif" decoding="async" width="200" height="100"></a></p></div></div>
<p><i>Complexity classes by letter:</i>
<a href="https://complexityzoo.net/Complexity_Zoo:Symbols" title="Complexity Zoo:Symbols">Symbols</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A" title="Complexity Zoo:A">A</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B" title="Complexity Zoo:B">B</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C" title="Complexity Zoo:C">C</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:D" title="Complexity Zoo:D">D</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:E" title="Complexity Zoo:E">E</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F" title="Complexity Zoo:F">F</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:G" title="Complexity Zoo:G">G</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:H" title="Complexity Zoo:H">H</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:I" title="Complexity Zoo:I">I</a> -
<a href="https://complexityzoo.net/index.php?title=Complexity_Zoo:J&amp;action=edit&amp;redlink=1" title="Complexity Zoo:J (page does not exist)">J</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:K" title="Complexity Zoo:K">K</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:L" title="Complexity Zoo:L">L</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M" title="Complexity Zoo:M">M</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N" title="Complexity Zoo:N">N</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:O" title="Complexity Zoo:O">O</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P" title="Complexity Zoo:P">P</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q" title="Complexity Zoo:Q">Q</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:R" title="Complexity Zoo:R">R</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S" title="Complexity Zoo:S">S</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:T" title="Complexity Zoo:T">T</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:U" title="Complexity Zoo:U">U</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:V" title="Complexity Zoo:V">V</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:W" title="Complexity Zoo:W">W</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:X" title="Complexity Zoo:X">X</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Y" title="Complexity Zoo:Y">Y</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Z" title="Complexity Zoo:Z">Z</a>
</p><p><i>Lists of related classes:</i>
<a href="https://complexityzoo.net/Complexity_Zoo:List_of_Communication_Complexity_Classes" title="Complexity Zoo:List of Communication Complexity Classes">Communication Complexity</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:List_of_Hierarchies" title="Complexity Zoo:List of Hierarchies">Hierarchies</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:List_of_Nonuniform_Classes" title="Complexity Zoo:List of Nonuniform Classes">Nonuniform</a>
</p>
<dl><dt>Zookeeper</dt>
<dd><a rel="nofollow" href="http://www.scottaaronson.com/">Scott Aaronson</a></dd>
<dt>Veterinarian</dt>
<dd><a rel="nofollow" href="http://www.math.ucdavis.edu/~greg/">Greg Kuperberg</a></dd>
<dt>Zoo Conservationist</dt>
<dd><a rel="nofollow" href="https://www.linkedin.com/in/oliver-habryka-8a585297">Oliver Habryka</a> on behalf of the <a rel="nofollow" href="https://www.lesswrong.com/">LessWrong</a> community</dd></dl>
<p>The Zoo first opened in 2002.  It was made into a wiki in 2005, and hosted at the University of Waterloo from 2012 to 2020.
</p><p>Errors?  Omissions?  Misattributions?  Your favorite class not here?  Then please contribute to the zoo as you see fit by <a href="https://complexityzoo.net/Special:UserLogin" title="Special:UserLogin"> signing up</a> and clicking on the edit links.  Please include references, or better yet links to papers if available.
</p><p>To create a new class, click on the edit link of the class before or after the one that you want to add and copy the format of that class.  (The classes are alphabetized by their tag names.)  Then add the class to the table of contents and increment the total number of classes.  After this, you can use the side edit links to edit the individual sections. For more on using the wiki language, see our <a href="https://complexityzoo.net/index.php?title=Help:Contents&amp;action=edit&amp;redlink=1" title="Help:Contents (page does not exist)"> simple wiki help page</a>.
</p><p>If you would like to contribute but feel unable to make the updates yourself, email the zookeeper at scott at scottaaronson.com.
</p>
<h2><span id="See_Also">See Also</span></h2>
<p><i>Introductory Resources</i>
</p>
<ul><li><a href="https://complexityzoo.net/Zoo_Intro" title="Zoo Intro">Introductory Essay</a>: New visitors may want to stop here and see what the Zoo is all about.</li>
<li><a href="https://complexityzoo.net/Petting_Zoo" title="Petting Zoo">Petting Zoo</a>: A more gentle version of the Zoo with fewer classes, meant for new initiates in complexity. (If you're looking for where the Most Important Classes went, look in the Petting Zoo.)</li></ul>
<p><i>Other Collections and Resources</i>
</p>
<ul><li><a href="https://complexityzoo.net/Complexity_Garden" title="Complexity Garden">Complexity Garden</a>: Problems of interest in complexity theory and some notes about important inclusions.</li>
<li><a href="https://complexityzoo.net/Complexity_Dojo" title="Complexity Dojo">Complexity Dojo</a>: A collection of major theorems in complexity theory.</li>
<li><a href="https://complexityzoo.net/Zoo_Exhibit" title="Zoo Exhibit">Special Exhibit</a>: A collection of classes of quantum states and probability distributions.</li>
<li><a rel="nofollow" href="http://www.math.ucdavis.edu/~greg/zoology/intro.html">Complexity Zoology</a>: A computer-assisted survey maintained by the <a rel="nofollow" href="http://www.math.ucdavis.edu/~greg/">Greg Kuperberg</a>, including <a rel="nofollow" href="http://www.math.ucdavis.edu/~greg/zoology/diagram.xml">active</a> and <a rel="nofollow" href="http://www.math.ucdavis.edu/~greg/zoology/diagram.pdf">static</a> inclusion diagrams.</li>
<li><a rel="nofollow" href="http://satoshihada.wordpress.com/complexity-zoo-for-ipad/">Complexity Zoo for iPad (and iPhone)</a>: An iOS viewer for Complexity Zoo.</li></ul>
<p><i>Appendices</i>
</p>
<ul><li><a href="https://complexityzoo.net/Zoo_Glossary" title="Zoo Glossary">Glossary</a>: Definitions of some complexity theoretic terms.</li>
<li><a href="https://complexityzoo.net/Zoo_References" title="Zoo References">References</a>: Bibliography for the Zoo.</li>
<li><a href="https://complexityzoo.net/Zoo_Pronunciation" title="Zoo Pronunciation">Pronunciation Guide</a>: A resource for those who insist on communicating verbally about complexity.</li>
<li><a href="https://complexityzoo.net/index.php?title=Zoo_Conventions&amp;action=edit&amp;redlink=1" title="Zoo Conventions (page does not exist)">Conventions and Notation</a>: Common notational conventions used here at the Zoo.</li>
<li><a href="https://complexityzoo.net/index.php?title=Zoo_Operators&amp;action=edit&amp;redlink=1" title="Zoo Operators (page does not exist)">Operators</a>: A (very short) list of operators which act upon classes.</li>
<li><a href="https://complexityzoo.net/Zoo_Acknowledgments" title="Zoo Acknowledgments">Acknowledgments</a>: Where the Zookeeper and friends acknowledge those who have helped out with the Zoo.</li>
<li><a href="https://complexityzoo.net/index.php?title=Meta:Complexity_Zoo_Contributor%27s_Guide&amp;action=edit&amp;redlink=1" title="Meta:Complexity Zoo Contributor's Guide (page does not exist)">Complexity Zoo Contributor's Guide</a>: A guide on how to get started helping out with the Zoo.</li></ul>
<p><i>NB:</i> Longtime Zoo watchers may recall Chris Bourke's LaTeX version of the Zoo and Chad Brewbaker's graphical inclusion diagram.  These references are obsolete until further notice.
</p>
<h2><span id="All_Classes">All Classes</span></h2>
<p><i>Complexity classes by letter:</i>
<a href="https://complexityzoo.net/Complexity_Zoo:Symbols" title="Complexity Zoo:Symbols">Symbols</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A" title="Complexity Zoo:A">A</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B" title="Complexity Zoo:B">B</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C" title="Complexity Zoo:C">C</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:D" title="Complexity Zoo:D">D</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:E" title="Complexity Zoo:E">E</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F" title="Complexity Zoo:F">F</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:G" title="Complexity Zoo:G">G</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:H" title="Complexity Zoo:H">H</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:I" title="Complexity Zoo:I">I</a> -
<a href="https://complexityzoo.net/index.php?title=Complexity_Zoo:J&amp;action=edit&amp;redlink=1" title="Complexity Zoo:J (page does not exist)">J</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:K" title="Complexity Zoo:K">K</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:L" title="Complexity Zoo:L">L</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M" title="Complexity Zoo:M">M</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N" title="Complexity Zoo:N">N</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:O" title="Complexity Zoo:O">O</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P" title="Complexity Zoo:P">P</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q" title="Complexity Zoo:Q">Q</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:R" title="Complexity Zoo:R">R</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S" title="Complexity Zoo:S">S</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:T" title="Complexity Zoo:T">T</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:U" title="Complexity Zoo:U">U</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:V" title="Complexity Zoo:V">V</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:W" title="Complexity Zoo:W">W</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:X" title="Complexity Zoo:X">X</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Y" title="Complexity Zoo:Y">Y</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Z" title="Complexity Zoo:Z">Z</a>
</p><p><i>Lists of related classes:</i>
<a href="https://complexityzoo.net/Complexity_Zoo:List_of_Communication_Complexity_Classes" title="Complexity Zoo:List of Communication Complexity Classes">Communication Complexity</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:List_of_Hierarchies" title="Complexity Zoo:List of Hierarchies">Hierarchies</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:List_of_Nonuniform_Classes" title="Complexity Zoo:List of Nonuniform Classes">Nonuniform</a>
</p>
<h3><span id="Symbols">Symbols</span></h3>
<p><a href="https://complexityzoo.net/Complexity_Zoo:Symbols#01npc" title="Complexity Zoo:Symbols">0-1-NP<sub>C</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Symbols#1nauxpdap" title="Complexity Zoo:Symbols">1NAuxPDA<sup>p</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Symbols#2exp" title="Complexity Zoo:Symbols">2-EXP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Symbols#3sumhard" title="Complexity Zoo:Symbols">3SUM-hard</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Symbols#sharpac0" title="Complexity Zoo:Symbols">#AC<sup>0</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Symbols#sharpl" title="Complexity Zoo:Symbols">#L</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Symbols#sharplpoly" title="Complexity Zoo:Symbols">#L/poly</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Symbols#sharpga" title="Complexity Zoo:Symbols">#GA</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Symbols#sharpp" title="Complexity Zoo:Symbols">#P</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Symbols#sharpwt" title="Complexity Zoo:Symbols">#W[t]</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Symbols#parityexp" title="Complexity Zoo:Symbols">⊕EXP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Symbols#parityl" title="Complexity Zoo:Symbols">⊕L</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Symbols#paritylpoly" title="Complexity Zoo:Symbols">⊕L/poly</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Symbols#parityp" title="Complexity Zoo:Symbols">⊕P</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Symbols#paritypcc" title="Complexity Zoo:Symbols">⊕P<sup>cc</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Symbols#paritysac0" title="Complexity Zoo:Symbols">⊕SAC<sup>0</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Symbols#paritysac1" title="Complexity Zoo:Symbols">⊕SAC<sup>1</sup></a>
</p>
<h3><span id="A">A</span></h3>
<p><a href="https://complexityzoo.net/Complexity_Zoo:A#a0pp" title="Complexity Zoo:A">A<sub>0</sub>PP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#ac" title="Complexity Zoo:A">AC</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#ac0" title="Complexity Zoo:A">AC<sup>0</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#ac0m" title="Complexity Zoo:A">AC<sup>0</sup>[m]</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#ac1" title="Complexity Zoo:A">AC<sup>1</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#acc0" title="Complexity Zoo:A">ACC<sup>0</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#ah" title="Complexity Zoo:A">AH</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#al" title="Complexity Zoo:A">AL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#all" title="Complexity Zoo:A">ALL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#alogtime" title="Complexity Zoo:A">ALOGTIME</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#algppoly" title="Complexity Zoo:A">AlgP/poly</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#almostnp" title="Complexity Zoo:A">Almost-NP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#almostp" title="Complexity Zoo:A">Almost-P</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#almostpspace" title="Complexity Zoo:A">Almost-PSPACE</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#am" title="Complexity Zoo:A">AM</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#amcc" title="Complexity Zoo:A">AM<sup>cc</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#amexp" title="Complexity Zoo:A">AM<sub>EXP</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#amicoam" title="Complexity Zoo:A">AM ∩ coAM</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#ampolylog" title="Complexity Zoo:A">AM[polylog]</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#ampmp" title="Complexity Zoo:A">AmpMP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#amppbqp" title="Complexity Zoo:A">AmpP-BQP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#ap" title="Complexity Zoo:A">AP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#app" title="Complexity Zoo:A">APP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#apspace" title="Complexity Zoo:A">APSPACE</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#apx" title="Complexity Zoo:A">APX</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#aspace" title="Complexity Zoo:A">ASPACE</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#atime" title="Complexity Zoo:A">ATIME</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#aucspace" title="Complexity Zoo:A">AUC-SPACE(f(n))</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#auxpda" title="Complexity Zoo:A">AuxPDA</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#avbpp" title="Complexity Zoo:A">AVBPP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#avge" title="Complexity Zoo:A">AvgE</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#avgp" title="Complexity Zoo:A">AvgP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#awp" title="Complexity Zoo:A">AW[P]</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#awpp" title="Complexity Zoo:A">AWPP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#awsat" title="Complexity Zoo:A">AW[SAT]</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#awstar" title="Complexity Zoo:A">AW[*]</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#awt" title="Complexity Zoo:A">AW[t]</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#axp" title="Complexity Zoo:A">AxP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:A#axpp" title="Complexity Zoo:A">AxPP</a>
</p>
<h3><span id="B">B</span></h3>
<p><a href="https://complexityzoo.net/Complexity_Zoo:B#betap" title="Complexity Zoo:B">βP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bcequalsp" title="Complexity Zoo:B">BC<sub>=</sub>P</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bh" title="Complexity Zoo:B">BH</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bpdp" title="Complexity Zoo:B">BP<sub>d</sub>(P)</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bpe" title="Complexity Zoo:B">BPE</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bpee" title="Complexity Zoo:B">BPEE</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bphspace" title="Complexity Zoo:B">BP<sub>H</sub>SPACE(f(n))</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bpl" title="Complexity Zoo:B">BPL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bpnp" title="Complexity Zoo:B">BP&amp;#149;NP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bpp" title="Complexity Zoo:B">BPP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bppcc" title="Complexity Zoo:B">BPP<sup>cc</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bppkcc" title="Complexity Zoo:B">BPP<sub><span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c3c9a2c7b599b37105512c5d570edc034056dd40" aria-hidden="true" alt="{\displaystyle k}"></span></sub><sup>cc</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bppkt" title="Complexity Zoo:B">BPP<sup>KT</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bpplog" title="Complexity Zoo:B">BPP/log</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bppmlog" title="Complexity Zoo:B">BPP/mlog</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bppsslog" title="Complexity Zoo:B">BPP//log</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bpprlog" title="Complexity Zoo:B">BPP/rlog</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bppobdd" title="Complexity Zoo:B">BPP-OBDD</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bpppath" title="Complexity Zoo:B">BPP<sub>path</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bpqp" title="Complexity Zoo:B">BPQP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bpspace" title="Complexity Zoo:B">BPSPACE(f(n))</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bptime" title="Complexity Zoo:B">BPTIME(f(n))</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bqnc" title="Complexity Zoo:B">BQNC</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bqnp" title="Complexity Zoo:B">BQNP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bqp" title="Complexity Zoo:B">BQP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bqplog" title="Complexity Zoo:B">BQP/log</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bqppoly" title="Complexity Zoo:B">BQP/poly</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bqpmlog" title="Complexity Zoo:B">BQP/mlog</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bqpmpoly" title="Complexity Zoo:B">BQP/mpoly</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bqpqlog" title="Complexity Zoo:B">BQP/qlog</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bqpqpoly" title="Complexity Zoo:B">BQP/qpoly</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bqpobdd" title="Complexity Zoo:B">BQP-OBDD</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bqpspace" title="Complexity Zoo:B">BQPSPACE</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bqpctc" title="Complexity Zoo:B">BQP<sub>CTC</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bqpttpoly" title="Complexity Zoo:B">BQP<sub>tt</sub>/poly</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bqtime" title="Complexity Zoo:B">BQTIME(f(n))</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:B#bwbp" title="Complexity Zoo:B">k-BWBP</a>
</p>
<h3><span id="C">C</span></h3>
<p><a href="https://complexityzoo.net/Complexity_Zoo:C#cequalsac0" title="Complexity Zoo:C">C<sub>=</sub>AC<sup>0</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#cequalsl" title="Complexity Zoo:C">C<sub>=</sub>L</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#cequalsp" title="Complexity Zoo:C">C<sub>=</sub>P</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#cc" title="Complexity Zoo:C">CC</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#cc0" title="Complexity Zoo:C">CC<sup>0</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#cfl" title="Complexity Zoo:C">CFL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#clog" title="Complexity Zoo:C">CLOG</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#ch" title="Complexity Zoo:C">CH</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#check" title="Complexity Zoo:C">Check</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#clsharpp" title="Complexity Zoo:C">CL#P</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#ckp" title="Complexity Zoo:C">C<sub>k</sub>P</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#cnp" title="Complexity Zoo:C">CNP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#coam" title="Complexity Zoo:C">coAM</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#cocequalsp" title="Complexity Zoo:C">coC<sub>=</sub>P</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#cofrip" title="Complexity Zoo:C">cofrIP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#coh" title="Complexity Zoo:C">Coh</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#coma" title="Complexity Zoo:C">coMA</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#comodkp" title="Complexity Zoo:C">coMod<sub>k</sub>P</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#compip" title="Complexity Zoo:C">compIP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#compnp" title="Complexity Zoo:C">compNP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#cone" title="Complexity Zoo:C">coNE</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#conexp" title="Complexity Zoo:C">coNEXP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#conl" title="Complexity Zoo:C">coNL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#conp" title="Complexity Zoo:C">coNP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#conpcc" title="Complexity Zoo:C">coNP<sup>cc</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#conppoly" title="Complexity Zoo:C">coNP/poly</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#conqp" title="Complexity Zoo:C">coNQP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#core" title="Complexity Zoo:C">coRE</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#cornc" title="Complexity Zoo:C">coRNC</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#corp" title="Complexity Zoo:C">coRP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#cosl" title="Complexity Zoo:C">coSL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#cosparse" title="Complexity Zoo:C">coSPARSE</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#coucc" title="Complexity Zoo:C">coUCC</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#coup" title="Complexity Zoo:C">coUP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#cp" title="Complexity Zoo:C">CP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#cqsigma2" title="Complexity Zoo:C">cq-Σ<sub>2</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#csize" title="Complexity Zoo:C">CSIZE(f(n))</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#csl" title="Complexity Zoo:C">CSL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#csp" title="Complexity Zoo:C">CSP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:C#czk" title="Complexity Zoo:C">CZK</a>
</p>
<h3><span id="D">D</span></h3>
<p><a href="https://complexityzoo.net/Complexity_Zoo:D#dsharpp" title="Complexity Zoo:D">D#P</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:D#dcfl" title="Complexity Zoo:D">DCFL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:D#delta2p" title="Complexity Zoo:D">Δ<sub>2</sub>P</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:D#deltabpp" title="Complexity Zoo:D">δ-BPP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:D#deltarp" title="Complexity Zoo:D">δ-RP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:D#det" title="Complexity Zoo:D">DET</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:D#diffac0" title="Complexity Zoo:D">DiffAC<sup>0</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:D#disnp" title="Complexity Zoo:D">DisNP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:D#distnp" title="Complexity Zoo:D">DistNP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:D#dp" title="Complexity Zoo:D">DP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:D#dqc1" title="Complexity Zoo:D">DQC1</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:D#dqp" title="Complexity Zoo:D">DQP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:D#dspace" title="Complexity Zoo:D">DSPACE(f(n))</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:D#dtime" title="Complexity Zoo:D">DTIME(f(n))</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:D#dtisp" title="Complexity Zoo:D">DTISP(t(n),s(n))</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:D#dynfo" title="Complexity Zoo:D">Dyn-FO</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:D#dynthc0" title="Complexity Zoo:D">Dyn-ThC<sup>0</sup></a>
</p>
<h3><span id="E">E</span></h3>
<p><a href="https://complexityzoo.net/Complexity_Zoo:E#e" title="Complexity Zoo:E">E</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:E#ee" title="Complexity Zoo:E">EE</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:E#eee" title="Complexity Zoo:E">EEE</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:E#eespace" title="Complexity Zoo:E">EESPACE</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:E#eexp" title="Complexity Zoo:E">EEXP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:E#eh" title="Complexity Zoo:E">EH</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:E#elementary" title="Complexity Zoo:E">ELEMENTARY</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:E#elkp" title="Complexity Zoo:E">EL<sub>k</sub>P</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:E#ep" title="Complexity Zoo:E">EP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:E#eptas" title="Complexity Zoo:E">EPTAS</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:E#eqbp" title="Complexity Zoo:E">k-EQBP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:E#eqp" title="Complexity Zoo:E">EQP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:E#eqpk" title="Complexity Zoo:E">EQP<sub>K</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:E#eqtime" title="Complexity Zoo:E">EQTIME(f(n))</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:E#espace" title="Complexity Zoo:E">ESPACE</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:E#existsbpp" title="Complexity Zoo:E">∃BPP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:E#existsniszk" title="Complexity Zoo:E">∃NISZK</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:E#exp" title="Complexity Zoo:E">EXP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:E#exppoly" title="Complexity Zoo:E">EXP/poly</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:E#expspace" title="Complexity Zoo:E">EXPSPACE</a>
</p>
<h3><span id="F">F</span></h3>
<p><a href="https://complexityzoo.net/Complexity_Zoo:F#fbqp" title="Complexity Zoo:F">FBQP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F#fert" title="Complexity Zoo:F">FERT</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F#fpert" title="Complexity Zoo:F">FPERT</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F#few" title="Complexity Zoo:F">Few</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F#fewexp" title="Complexity Zoo:F">FewEXP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F#fewp" title="Complexity Zoo:F">FewP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F#fh" title="Complexity Zoo:F">FH</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F#fixp" title="Complexity Zoo:F">FIXP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F#fnl" title="Complexity Zoo:F">FNL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F#fnlpoly" title="Complexity Zoo:F">FNL/poly</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F#fnp" title="Complexity Zoo:F">FNP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F#fo" title="Complexity Zoo:F">FO</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F#fodtc" title="Complexity Zoo:F">FO(DTC)</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F#folfp" title="Complexity Zoo:F">FO(LFP)</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F#fopfp" title="Complexity Zoo:F">FO(PFP)</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F#fotc" title="Complexity Zoo:F">FO(TC)</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F#fot" title="Complexity Zoo:F">FO(<span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/70b64a27c4f55221162f329285382cc470e3827e" aria-hidden="true" alt="{\displaystyle t(n)}"></span>)</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F#foll" title="Complexity Zoo:F">FOLL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F#fp" title="Complexity Zoo:F">FP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F#fpnplog" title="Complexity Zoo:F">FP<sup>NP[log]</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F#fpl" title="Complexity Zoo:F">FPL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F#fpr" title="Complexity Zoo:F">FPR</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F#fpras" title="Complexity Zoo:F">FPRAS</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F#fpt" title="Complexity Zoo:F">FPT</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F#fptnu" title="Complexity Zoo:F">FPT<sub>nu</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F#fptsu" title="Complexity Zoo:F">FPT<sub>su</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F#fptas" title="Complexity Zoo:F">FPTAS</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F#fqma" title="Complexity Zoo:F">FQMA</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F#frip" title="Complexity Zoo:F">frIP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F#ftape" title="Complexity Zoo:F">F-TAPE(f(n))</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:F#ftime" title="Complexity Zoo:F">F-TIME(f(n))</a>
</p>
<h3><span id="G">G</span></h3>
<p><a href="https://complexityzoo.net/Complexity_Zoo:G#ga" title="Complexity Zoo:G">GA</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:G#ganspace" title="Complexity Zoo:G">GAN-SPACE(f(n))</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:G#gapac0" title="Complexity Zoo:G">GapAC<sup>0</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:G#gapl" title="Complexity Zoo:G">GapL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:G#gapp" title="Complexity Zoo:G">GapP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:G#gc" title="Complexity Zoo:G">GC(s(n),C)</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:G#gcsl" title="Complexity Zoo:G">GCSL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:G#gi" title="Complexity Zoo:G">GI</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:G#glo" title="Complexity Zoo:G">GLO</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:G#gpcd" title="Complexity Zoo:G">GPCD(r(n),q(n))</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:G#gt" title="Complexity Zoo:G">G[t]</a>
</p>
<h3><span id="H">H</span></h3>
<p><a href="https://complexityzoo.net/Complexity_Zoo:H#halfp" title="Complexity Zoo:H">HalfP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:H#heurbpp" title="Complexity Zoo:H">HeurBPP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:H#heurbptime" title="Complexity Zoo:H">HeurBPTIME(f(n))</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:H#heurdtime" title="Complexity Zoo:H">HeurDTIME<sub><span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c5321cfa797202b3e1f8620663ff43c4660ea03a" aria-hidden="true" alt="{\displaystyle \delta }"></span></sub>(f(n))</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:H#heurp" title="Complexity Zoo:H">HeurP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:H#heurpp" title="Complexity Zoo:H">HeurPP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:H#heurntime" title="Complexity Zoo:H">HeurNTIME<sub><span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c5321cfa797202b3e1f8620663ff43c4660ea03a" aria-hidden="true" alt="{\displaystyle \delta }"></span></sub>(f(n))</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:H#hkp" title="Complexity Zoo:H">H<sub>k</sub>P</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:H#hvszk" title="Complexity Zoo:H">HVSZK</a>
</p>
<h3><span id="I">I</span></h3>
<p><a href="https://complexityzoo.net/Complexity_Zoo:I#iclogpoly" title="Complexity Zoo:I">IC[log,poly]</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:I#ip" title="Complexity Zoo:I">IP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:I#ipp" title="Complexity Zoo:I">IPP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:I#ippolylog" title="Complexity Zoo:I">IP[polylog]</a>
</p>
<h3><span id="L">L</span></h3>
<p><a href="https://complexityzoo.net/Complexity_Zoo:L#l" title="Complexity Zoo:L">L</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:L#lc0" title="Complexity Zoo:L">LC<sup>0</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:L#lh" title="Complexity Zoo:L">LH</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:L#lin" title="Complexity Zoo:L">LIN</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:L#lkp" title="Complexity Zoo:L">L<sub>k</sub>P</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:L#logcfl" title="Complexity Zoo:L">LOGCFL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:L#logfew" title="Complexity Zoo:L">LogFew</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:L#logfewnl" title="Complexity Zoo:L">LogFewNL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:L#loglog" title="Complexity Zoo:L">LOGLOG</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:L#lognp" title="Complexity Zoo:L">LOGNP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:L#logsnp" title="Complexity Zoo:L">LOGSNP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:L#l.2Fpoly" title="Complexity Zoo:L">L/poly</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:L#lwpp" title="Complexity Zoo:L">LWPP</a>
</p>
<h3><span id="M">M</span></h3>
<p><a href="https://complexityzoo.net/Complexity_Zoo:M#ma" title="Complexity Zoo:M">MA</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#macc" title="Complexity Zoo:M">MA<sup>cc</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#maprime" title="Complexity Zoo:M">MA'</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#mac0" title="Complexity Zoo:M">MAC<sup>0</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#mae" title="Complexity Zoo:M">MA<sub>E</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#maexp" title="Complexity Zoo:M">MA<sub>EXP</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#mal" title="Complexity Zoo:M">mAL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#mapolylog" title="Complexity Zoo:M">MA<sub>POLYLOG</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#maxnp" title="Complexity Zoo:M">MaxNP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#maxpb" title="Complexity Zoo:M">MaxPB</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#maxsnp" title="Complexity Zoo:M">MaxSNP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#maxsnp0" title="Complexity Zoo:M">MaxSNP<sub>0</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#mconl" title="Complexity Zoo:M">mcoNL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#minpb" title="Complexity Zoo:M">MinPB</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#mip" title="Complexity Zoo:M">MIP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#mipstar" title="Complexity Zoo:M">MIP*</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#mipns" title="Complexity Zoo:M">MIP<sup>ns</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#mipexp" title="Complexity Zoo:M">MIP<sub>EXP</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#mkp" title="Complexity Zoo:M">(M<sub>k</sub>)P</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#ml" title="Complexity Zoo:M">mL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#mm" title="Complexity Zoo:M">MM</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#mmsnp" title="Complexity Zoo:M">MMSNP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#mnc1" title="Complexity Zoo:M">mNC<sup>1</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#mnl" title="Complexity Zoo:M">mNL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#mnp" title="Complexity Zoo:M">mNP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#modkl" title="Complexity Zoo:M">Mod<sub>k</sub>L</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#modl" title="Complexity Zoo:M">ModL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#modkp" title="Complexity Zoo:M">Mod<sub>k</sub>P</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#modp" title="Complexity Zoo:M">ModP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#modzkl" title="Complexity Zoo:M">ModZ<sub>k</sub>L</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#mp" title="Complexity Zoo:M">mP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#mp2" title="Complexity Zoo:M">MP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#mpc" title="Complexity Zoo:M">MPC</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#mppoly" title="Complexity Zoo:M">mP/poly</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:M#mtc0" title="Complexity Zoo:M">mTC<sup>0</sup></a>
</p>
<h3><span id="N">N</span></h3>
<p><a href="https://complexityzoo.net/Complexity_Zoo:N#nauxpdap" title="Complexity Zoo:N">NAuxPDA<sup>p</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#nc" title="Complexity Zoo:N">NC</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#nc0" title="Complexity Zoo:N">NC<sup>0</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#nc1" title="Complexity Zoo:N">NC<sup>1</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#nc2" title="Complexity Zoo:N">NC<sup>2</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#ne" title="Complexity Zoo:N">NE</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#nepoly" title="Complexity Zoo:N">NE/poly</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#nearlyp" title="Complexity Zoo:N">Nearly-P</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#nee" title="Complexity Zoo:N">NEE</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#neee" title="Complexity Zoo:N">NEEE</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#neexp" title="Complexity Zoo:N">NEEXP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#nexp" title="Complexity Zoo:N">NEXP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#nexppoly" title="Complexity Zoo:N">NEXP/poly</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#nipzk" title="Complexity Zoo:N">NIPZK</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#niqszk" title="Complexity Zoo:N">NIQSZK</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#niszk" title="Complexity Zoo:N">NISZK</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#niszkh" title="Complexity Zoo:N">NISZK<sub>h</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#nl" title="Complexity Zoo:N">NL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#nlpoly" title="Complexity Zoo:N">NL/poly</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#nlin" title="Complexity Zoo:N">NLIN</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#nlo" title="Complexity Zoo:N">NLO</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#nlog" title="Complexity Zoo:N">NLOG</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#none" title="Complexity Zoo:N">NONE</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#nnc" title="Complexity Zoo:N">NNC(f(n))</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#np" title="Complexity Zoo:N">NP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#npc" title="Complexity Zoo:N">NPC</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#npc2" title="Complexity Zoo:N">NP<sub>C</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#npcc" title="Complexity Zoo:N">NP<sup>cc</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#npkcc" title="Complexity Zoo:N">NP<sub><span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c3c9a2c7b599b37105512c5d570edc034056dd40" aria-hidden="true" alt="{\displaystyle k}"></span></sub><sup>cc</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#npi" title="Complexity Zoo:N">NPI</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#npiconp" title="Complexity Zoo:N">NP ∩ coNP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#npiconppoly" title="Complexity Zoo:N">(NP ∩ coNP)/poly</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#nplog" title="Complexity Zoo:N">NP/log</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#npmv" title="Complexity Zoo:N">NPMV</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#npmvsel" title="Complexity Zoo:N">NPMV-sel</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#npmvt" title="Complexity Zoo:N">NPMV<sub>t</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#npmvtsel" title="Complexity Zoo:N">NPMV<sub>t</sub>-sel</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#npo" title="Complexity Zoo:N">NPO</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#npopb" title="Complexity Zoo:N">NPOPB</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#nppoly" title="Complexity Zoo:N">NP/poly</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#nppsamp" title="Complexity Zoo:N">(NP,P-samplable)</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#npr" title="Complexity Zoo:N">NP<sub>R</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#npspace" title="Complexity Zoo:N">NPSPACE</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#npsv" title="Complexity Zoo:N">NPSV</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#npsvsel" title="Complexity Zoo:N">NPSV-sel</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#npsvt" title="Complexity Zoo:N">NPSV<sub>t</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#npsvtsel" title="Complexity Zoo:N">NPSV<sub>t</sub>-sel</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#nqp" title="Complexity Zoo:N">NQP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#nspace" title="Complexity Zoo:N">NSPACE(f(n))</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#nt" title="Complexity Zoo:N">NT</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#ntstar" title="Complexity Zoo:N">NT*</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:N#ntime" title="Complexity Zoo:N">NTIME(f(n))</a>
</p>
<h3><span id="O">O</span></h3>
<p><a href="https://complexityzoo.net/Complexity_Zoo:O#optp" title="Complexity Zoo:O">OptP</a>
</p>
<h3><span id="P">P</span></h3>
<p><a href="https://complexityzoo.net/Complexity_Zoo:P#p" title="Complexity Zoo:P">P</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#plog" title="Complexity Zoo:P">P/log</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#ppoly" title="Complexity Zoo:P">P/poly</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#psharpp" title="Complexity Zoo:P">P<sup>#P</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#psharpp1" title="Complexity Zoo:P">P<sup>#P[1]</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pctc" title="Complexity Zoo:P">P<sub>CTC</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pac0" title="Complexity Zoo:P">PAC<sup>0</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pbp" title="Complexity Zoo:P">PBP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#kpbp" title="Complexity Zoo:P">k-PBP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pc" title="Complexity Zoo:P">P<sub>C</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pcc" title="Complexity Zoo:P">P<sup>cc</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pkcc" title="Complexity Zoo:P">P<sub><span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c3c9a2c7b599b37105512c5d570edc034056dd40" aria-hidden="true" alt="{\displaystyle k}"></span></sub><sup>cc</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pcd" title="Complexity Zoo:P">PCD(r(n),q(n))</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pclose" title="Complexity Zoo:P">P-Close</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pcp" title="Complexity Zoo:P">PCP(r(n),q(n))</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pdqp" title="Complexity Zoo:P">PDQP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#permup" title="Complexity Zoo:P">PermUP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pexp" title="Complexity Zoo:P">PEXP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pf" title="Complexity Zoo:P">PF</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pfchk" title="Complexity Zoo:P">PFCHK(t(n))</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#ph" title="Complexity Zoo:P">PH</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#phcc" title="Complexity Zoo:P">PH<sup>cc</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#phi2p" title="Complexity Zoo:P">Φ<sub>2</sub>P</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#php" title="Complexity Zoo:P">PhP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pi2p" title="Complexity Zoo:P">Π<sub>2</sub>P</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pinc" title="Complexity Zoo:P">PINC</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pio" title="Complexity Zoo:P">PIO</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pk" title="Complexity Zoo:P">P<sup>K</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pkc" title="Complexity Zoo:P">PKC</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pl" title="Complexity Zoo:P">PL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pl1" title="Complexity Zoo:P">PL<sub>1</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#plinfinity" title="Complexity Zoo:P">PL<sub>∞</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#plf" title="Complexity Zoo:P">PLF</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pll" title="Complexity Zoo:P">PLL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pls" title="Complexity Zoo:P">PLS</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pnp" title="Complexity Zoo:P">P<sup>NP</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pnpcc" title="Complexity Zoo:P">P<sup>NPcc</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pparnp" title="Complexity Zoo:P">P<sup>||NP</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pnpk" title="Complexity Zoo:P">P<sup>NP[k]</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pnplog" title="Complexity Zoo:P">P<sup>NP[log]</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pnplog2" title="Complexity Zoo:P">P<sup>NP[log^2]</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pobdd" title="Complexity Zoo:P">P-OBDD</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#podn" title="Complexity Zoo:P">PODN</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#polyl" title="Complexity Zoo:P">polyL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#postbpp" title="Complexity Zoo:P">PostBPP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#postbppcc" title="Complexity Zoo:P">PostBPP<sup>cc</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#postbqp" title="Complexity Zoo:P">PostBQP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pp" title="Complexity Zoo:P">PP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#ppcc" title="Complexity Zoo:P">PP<sup>cc</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pppoly" title="Complexity Zoo:P">PP/poly</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#ppa" title="Complexity Zoo:P">PPA</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#ppad" title="Complexity Zoo:P">PPAD</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#ppads" title="Complexity Zoo:P">PPADS</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#ppp2" title="Complexity Zoo:P">P<sup>PP</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#ppp" title="Complexity Zoo:P">PPP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#ppspace" title="Complexity Zoo:P">PPSPACE</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pqmalog" title="Complexity Zoo:P">P<sup>QMA[log]</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pquery" title="Complexity Zoo:P">PQUERY</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pr" title="Complexity Zoo:P">PR</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pr2" title="Complexity Zoo:P">P<sub>R</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#prhspace" title="Complexity Zoo:P">Pr<sub>H</sub>SPACE(f(n))</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#promisebpp" title="Complexity Zoo:P">PromiseBPP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#promisebqp" title="Complexity Zoo:P">PromiseBQP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#promisep" title="Complexity Zoo:P">PromiseP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#promiserp" title="Complexity Zoo:P">PromiseRP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#promiseup" title="Complexity Zoo:P">PromiseUP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#prspace" title="Complexity Zoo:P">PrSPACE(f(n))</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#psel" title="Complexity Zoo:P">P-Sel</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#psk" title="Complexity Zoo:P">PSK</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pspace" title="Complexity Zoo:P">PSPACE</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pspacecc" title="Complexity Zoo:P">PSPACE<sup>cc</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pspacepoly" title="Complexity Zoo:P">PSPACE/poly</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pt1" title="Complexity Zoo:P">PT<sub>1</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#ptape" title="Complexity Zoo:P">PTAPE</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#ptas" title="Complexity Zoo:P">PTAS</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#ptwk" title="Complexity Zoo:P">PT/WK(f(n),g(n))</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:P#pzk" title="Complexity Zoo:P">PZK</a>
</p>
<h3><span id="Q">Q</span></h3>
<p><a href="https://complexityzoo.net/Complexity_Zoo:Q#q" title="Complexity Zoo:Q">Q</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qac0" title="Complexity Zoo:Q">QAC<sup>0</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qac0m" title="Complexity Zoo:Q">QAC<sup>0</sup>[m]</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qacc0" title="Complexity Zoo:Q">QACC<sup>0</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qacwf0" title="Complexity Zoo:Q">QAC<sub>f</sub><sup>0</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qam" title="Complexity Zoo:Q">QAM</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qcfl" title="Complexity Zoo:Q">QCFL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qcma" title="Complexity Zoo:Q">QCMA</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qcph" title="Complexity Zoo:Q">QCPH</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qh" title="Complexity Zoo:Q">QH</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qip" title="Complexity Zoo:Q">QIP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qip2" title="Complexity Zoo:Q">QIP[2]</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#ql" title="Complexity Zoo:Q">QL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qma" title="Complexity Zoo:Q">QMA</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qma-plus" title="Complexity Zoo:Q">QMA-plus</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qma2" title="Complexity Zoo:Q">QMA(2)</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qma1" title="Complexity Zoo:Q">QMA<sub>1</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qmalog" title="Complexity Zoo:Q">QMA<sub>log</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qmam" title="Complexity Zoo:Q">QMAM</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qmaqpoly" title="Complexity Zoo:Q">QMA/qpoly</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qmip" title="Complexity Zoo:Q">QMIP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qmiple" title="Complexity Zoo:Q">QMIP<sub>le</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qmipne" title="Complexity Zoo:Q">QMIP<sub>ne</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qnc" title="Complexity Zoo:Q">QNC</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qnc0" title="Complexity Zoo:Q">QNC<sup>0</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qncf0" title="Complexity Zoo:Q">QNC<sub>f</sub><sup>0</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qnc1" title="Complexity Zoo:Q">QNC<sup>1</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qp" title="Complexity Zoo:Q">QP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qph" title="Complexity Zoo:Q">QPH</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qplin" title="Complexity Zoo:Q">QPLIN</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qpspace" title="Complexity Zoo:Q">QPSPACE</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qrg" title="Complexity Zoo:Q">QRG</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qrgk" title="Complexity Zoo:Q">QRG(k)</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qrg2" title="Complexity Zoo:Q">QRG(2)</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qrg1" title="Complexity Zoo:Q">QRG(1)</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Q#qszk" title="Complexity Zoo:Q">QSZK</a>
</p>
<h3><span id="R">R</span></h3>
<p><a href="https://complexityzoo.net/Complexity_Zoo:R#r" title="Complexity Zoo:R">R</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:R#rbqp" title="Complexity Zoo:R">RBQP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:R#re" title="Complexity Zoo:R">RE</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:R#reg" title="Complexity Zoo:R">REG</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:R#revspace" title="Complexity Zoo:R">RevSPACE(f(n))</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:R#rg" title="Complexity Zoo:R">RG</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:R#rg1" title="Complexity Zoo:R">RG[1]</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:R#rhl" title="Complexity Zoo:R">R<sub>H</sub>L</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:R#rhspace" title="Complexity Zoo:R">R<sub>H</sub>SPACE(f(n))</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:R#rl" title="Complexity Zoo:R">RL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:R#rnc" title="Complexity Zoo:R">RNC</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:R#rp" title="Complexity Zoo:R">RP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:R#rpcc" title="Complexity Zoo:R">RP<sup>cc</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:R#rpkcc" title="Complexity Zoo:R">RP<sub><span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c3c9a2c7b599b37105512c5d570edc034056dd40" aria-hidden="true" alt="{\displaystyle k}"></span></sub><sup>cc</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:R#rpp" title="Complexity Zoo:R">RPP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:R#rqp" title="Complexity Zoo:R">RQP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:R#rspace" title="Complexity Zoo:R">RSPACE(f(n))</a>
</p>
<h3><span id="S">S</span></h3>
<p><a href="https://complexityzoo.net/Complexity_Zoo:S#s2p" title="Complexity Zoo:S">S<sub>2</sub>P</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#s2exppnp" title="Complexity Zoo:S">S<sub>2</sub>-EXP&amp;#149;P<sup>NP</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#sac" title="Complexity Zoo:S">SAC</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#sac0" title="Complexity Zoo:S">SAC<sup>0</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#sac1" title="Complexity Zoo:S">SAC<sup>1</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#saptime" title="Complexity Zoo:S">SAPTIME</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#sbp" title="Complexity Zoo:S">SBP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#sbpcc" title="Complexity Zoo:S">SBP<sup>cc</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#sbqp" title="Complexity Zoo:S">SBQP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#sc" title="Complexity Zoo:S">SC</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#se" title="Complexity Zoo:S">SE</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#seh" title="Complexity Zoo:S">SEH</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#selfnp" title="Complexity Zoo:S">SelfNP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#sfk" title="Complexity Zoo:S">SF<sub>k</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#sigma2p" title="Complexity Zoo:S">Σ<sub>2</sub>P</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#skc" title="Complexity Zoo:S">SKC</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#sl" title="Complexity Zoo:S">SL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#slicewisepspace" title="Complexity Zoo:S">SLICEWISE PSPACE</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#snp" title="Complexity Zoo:S">SNP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#so" title="Complexity Zoo:S">SO</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#sohorn" title="Complexity Zoo:S">SO(Horn)</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#sokrom" title="Complexity Zoo:S">SO(Krom)</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#solfp" title="Complexity Zoo:S">SO(LFP)</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#sotc" title="Complexity Zoo:S">SO(TC)</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#sot" title="Complexity Zoo:S">SO[<span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/70b64a27c4f55221162f329285382cc470e3827e" aria-hidden="true" alt="{\displaystyle t(n)}"></span>]</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#sp" title="Complexity Zoo:S">SP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#spanl" title="Complexity Zoo:S">span-L</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#spanp" title="Complexity Zoo:S">span-P</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#sparse" title="Complexity Zoo:S">SPARSE</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#spl" title="Complexity Zoo:S">SPL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#spp" title="Complexity Zoo:S">SPP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#sqg" title="Complexity Zoo:S">SQG</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#subexp" title="Complexity Zoo:S">SUBEXP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#symp" title="Complexity Zoo:S">symP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#szk" title="Complexity Zoo:S">SZK</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:S#szkh" title="Complexity Zoo:S">SZK<sub>h</sub></a>
</p>
<h3><span id="T">T</span></h3>
<p><a href="https://complexityzoo.net/Complexity_Zoo:T#tally" title="Complexity Zoo:T">TALLY</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:T#tc0" title="Complexity Zoo:T">TC<sup>0</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:T#tfnp" title="Complexity Zoo:T">TFNP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:T#theta2p" title="Complexity Zoo:T">Θ<sub>2</sub>P</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:T#ti" title="Complexity Zoo:T">TI</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:T#tower" title="Complexity Zoo:T">Tower</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:T#treebqp" title="Complexity Zoo:T">TreeBQP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:T#treeregular" title="Complexity Zoo:T">TREE-REGULAR</a>
</p>
<h3><span id="U">U</span></h3>
<p><a href="https://complexityzoo.net/Complexity_Zoo:U#uamcc" title="Complexity Zoo:U">UAM<sup>cc</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:U#uap" title="Complexity Zoo:U">UAP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:U#ucc" title="Complexity Zoo:U">UCC</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:U#ucc" title="Complexity Zoo:U">UCFL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:U#ue" title="Complexity Zoo:U">UE</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:U#ul" title="Complexity Zoo:U">UL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:U#ulpoly" title="Complexity Zoo:U">UL/poly</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:U#up" title="Complexity Zoo:U">UP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:U#upcc" title="Complexity Zoo:U">UP<sup>cc</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:U#upostbppcc" title="Complexity Zoo:U">UPostBPP<sup>cc</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:U#uppcc" title="Complexity Zoo:U">UPP<sup>cc</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:U#us" title="Complexity Zoo:U">US</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:U#usbpcc" title="Complexity Zoo:U">USBP<sup>cc</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:U#uwappcc" title="Complexity Zoo:U">UWAPP<sup>cc</sup></a>
</p>
<h3><span id="V">V</span></h3>
<p><a href="https://complexityzoo.net/Complexity_Zoo:V#vck" title="Complexity Zoo:V">VC<sub>k</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:V#vcor" title="Complexity Zoo:V">VC<sub>OR</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:V#vnc" title="Complexity Zoo:V">VNC<sub>k</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:V#vnp" title="Complexity Zoo:V">VNP<sub>k</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:V#vp" title="Complexity Zoo:V">VP<sub>k</sub></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:V#vpl" title="Complexity Zoo:V">VPL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:V#vqp" title="Complexity Zoo:V">VQP<sub>k</sub></a>
</p>
<h3><span id="W">W</span></h3>
<p><a href="https://complexityzoo.net/Complexity_Zoo:W#w1" title="Complexity Zoo:W">W[1]</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:W#wapp" title="Complexity Zoo:W">WAPP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:W#wappcc" title="Complexity Zoo:W">WAPP<sup>cc</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:W#while" title="Complexity Zoo:W">WHILE</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:W#wp" title="Complexity Zoo:W">W[P]</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:W#wpp" title="Complexity Zoo:W">WPP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:W#wsat" title="Complexity Zoo:W">W[SAT]</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:W#wstar" title="Complexity Zoo:W">W[*]</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:W#wt" title="Complexity Zoo:W">W[t]</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:W#wstart" title="Complexity Zoo:W">W<sup>*</sup>[t]</a>
</p>
<h3><span id="X">X</span></h3>
<p><a href="https://complexityzoo.net/Complexity_Zoo:X#xormipstar21" title="Complexity Zoo:X">XOR-MIP*[2,1]</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:X#xl" title="Complexity Zoo:X">XL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:X#xnl" title="Complexity Zoo:X">XNL</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:X#xp" title="Complexity Zoo:X">XP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:X#xpuniform" title="Complexity Zoo:X">XP<sub>uniform</sub></a>
</p>
<h3><span id="Y">Y</span></h3>
<p><a href="https://complexityzoo.net/Complexity_Zoo:Y#yacc" title="Complexity Zoo:Y">YACC</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Y#yp" title="Complexity Zoo:Y">YP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Y#ypp" title="Complexity Zoo:Y">YPP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Y#yqp" title="Complexity Zoo:Y">YQP</a>
</p>
<h3><span id="Z">Z</span></h3>
<p><a href="https://complexityzoo.net/Complexity_Zoo:Z#zamcc" title="Complexity Zoo:Z">ZAM<sup>cc</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Z#zbqp" title="Complexity Zoo:Z">ZBQP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Z#zk" title="Complexity Zoo:Z">ZK</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Z#zpe" title="Complexity Zoo:Z">ZPE</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Z#zpp" title="Complexity Zoo:Z">ZPP</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Z#zppcc" title="Complexity Zoo:Z">ZPP<sup>cc</sup></a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Z#zptime" title="Complexity Zoo:Z">ZPTIME(f(n))</a> -
<a href="https://complexityzoo.net/Complexity_Zoo:Z#zqp" title="Complexity Zoo:Z">ZQP</a>
</p>
<!-- 
NewPP limit report
Cached time: 20201214005353
Cache expiry: 86400
Dynamic content: false
Complications: []
CPU time usage: 0.167 seconds
Real time usage: 0.433 seconds
Preprocessor visited node count: 855/1000000
Post‐expand include size: 45273/2097152 bytes
Template argument size: 8963/2097152 bytes
Highest expansion depth: 5/40
Expensive parser function count: 0/100
Unstrip recursion depth: 0/20
Unstrip post‐expand size: 288/5000000 bytes
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%   84.770      1 -total
 91.64%   77.686     25 Template:CZ-Letter-Section
  4.97%    4.215      1 Template:CZ-P
  4.30%    3.648      1 Template:CZ-N
  3.91%    3.317      1 Template:CZ-B
  3.89%    3.300      1 Template:CZ-S
  3.83%    3.247      1 Template:CZ-C
  3.82%    3.234      1 Template:CZ-Q
  3.74%    3.167      1 Template:CZ-A
  3.69%    3.130      1 Template:CZ-M
-->

<!-- Saved in parser cache with key zoo:pcache:idhash:8-0!canonical!math=5 and timestamp 20201214005352 and revision id 6693
 -->
</div></div></div>]]>
            </description>
            <link>https://complexityzoo.net/Complexity_Zoo</link>
            <guid isPermaLink="false">hacker-news-small-sites-25388790</guid>
            <pubDate>Fri, 11 Dec 2020 18:16:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Canada to implement its first national vaccine injury compensation program]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25388410">thread link</a>) | @finphil
<br/>
December 11, 2020 | https://www.ctvnews.ca/health/coronavirus/canada-to-implement-its-first-national-vaccine-injury-compensation-program-1.5226609 | <a href="https://web.archive.org/web/*/https://www.ctvnews.ca/health/coronavirus/canada-to-implement-its-first-national-vaccine-injury-compensation-program-1.5226609">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>TORONTO -- 
	As part of Canadaâ€™s vaccine rollout, the federal government has announced that anyone who experiences a severe adverse reaction to a COVID-19 vaccine will be eligible for compensation â€” a first in Canadaâ€™s history.</p>
<p>
	The no-fault program was announced Thursday, as Canada gets ready to roll out the first of seven new vaccines.</p>
<p>
	â€œSerious side-effects are incredibly rare,â€� Prime Minister Justin Trudeau said in a press conference Thursday. â€œIn the very unlikely event of an adverse reaction though, we want to make sure Canadians have fair access to support. So today, I can announce that weâ€™re creating a federal support program around vaccine safety for all Canadians and for all vaccines. This includes COVID-19 vaccines that will be rolled out soon.â€�</p>
<ul>
	<li>
		<em><strong><a href="https://www.ctvnews.ca/newsletters/the-covid19-brief-newsletter-signup" target="_blank">Newsletter sign-up: Get The COVID-19 Brief sent to your inbox</a></strong></em></li>
</ul>
<p>
	Before a vaccine reaches the public, it will have gone through clinical trials involving thousands of people. The Pfizer-BioNTech vaccine, which Health Canada approved Wednesday, used more than 40,000 people in its final phases of testing. Although side-effects did occur for some participants, almost all were temporary, and the vaccine has been deemed safe for the general public.</p>
<p>
	Serious reactions are not impossible, however. In the U.K., two people with a history of severe allergic reactions to things such as vaccines, medicine or food <a href="https://www.ctvnews.ca/world/u-k-to-refine-allergy-warning-on-pfizer-vaccine-sparked-by-two-adverse-reactions-1.5223107" target="_blank">suffered serious reactions to the Pfizer vaccine this week.</a> The situation is still being investigated to figure out what triggered the reactions.</p>
<p>
	<a href="https://www.canada.ca/en/public-health/news/2020/12/government-of-canada-announces-pan-canadian-vaccine-injury-support-program.html" target="_blank">In a news release on todayâ€™s compensation program</a>, the federal government pointed out that the chances of someone experiencing a truly serious adverse reaction are â€œextremely rare -- less than one in a million.â€�</p>
<p>
	Trudeau added in the press conference that the program was â€œbased on the model that Quebec has had for the last 30 years and follows the lead of all other G7 countries.â€�</p>
<p>
	More than 20 countries already have vaccine injury support programs, according to the press release, with Canada being the last G7 country to follow suit.</p>
<p>
	â€œCanadians can have confidence in the rigour of the vaccine approvals system, however, in the rare event that a person experiences an adverse reaction, this program will help ensure they get the support they need,â€� Health Minister Patty Hajdu said in the release. â€œI will work with my provincial and territorial counterparts to set this program in place quickly.â€�</p>
<p>
	So far, no details have been released on how one would qualify for the program, or how much they could be eligible for in response to a permanent injury as a result of taking a vaccine.</p>
<p>
	<em>With files from Avis Favaro&nbsp;</em></p>
                                              </div></div>]]>
            </description>
            <link>https://www.ctvnews.ca/health/coronavirus/canada-to-implement-its-first-national-vaccine-injury-compensation-program-1.5226609</link>
            <guid isPermaLink="false">hacker-news-small-sites-25388410</guid>
            <pubDate>Fri, 11 Dec 2020 17:43:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Emacs Survey 2020 Results]]>
            </title>
            <description>
<![CDATA[
Score 135 | Comments 70 (<a href="https://news.ycombinator.com/item?id=25388353">thread link</a>) | @todd8
<br/>
December 11, 2020 | https://emacssurvey.org/2020/ | <a href="https://web.archive.org/web/*/https://emacssurvey.org/2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h2>Questions</h2>
      <p>For reference, this was <a href="https://emacssurvey.org/2020/emacs-user-survey-2020.org">the survey questions</a> in org-mode format.</p>
      <h2>Data</h2>
      <ul>
        <li>
          <a href="https://emacssurvey.org/2020/Emacs-User-Survey-2020-raw.csv">Raw data</a>
          <ul>
            <li>the reconciled data from both webform and email submissions</li>
            <li>absolutely no change made aside from a few instances where PII and email addresses were redacted</li>
          </ul>
        </li>
        <li>
          <a href="https://emacssurvey.org/2020/Emacs-User-Survey-2020-clean.csv">Cleaned up data</a><br>
          It might get updated in the future, but right now it was derived from the raw data in a best-effort attempt:
          <ul>
            <li>removed negative years in "For how many years have you been using Emacs?"</li>
            <li>unified responses for "How did you hear about this survey?" as Hacker News, Emacs China and Emacs News weren't part of the options</li>
            <li>unified responses for "Which theme do you use?", especially around spelling</li>
            <li>general cleanup and unified of responses which only differed by punctuation and casing</li>
          </ul>
        </li>
      </ul>
      <h2>Statistics about the survey</h2>
      
      <h2>Analysis</h2>
      <p>There is a lot of data to look at in many different ways. For now, I performed a simple question-by-question analysis using a <a href="https://github.com/abrochard/emacs-survey/blob/main/2020/Emacs%20User%20Survey%202020.ipynb">Jupyter Notebook</a>.</p>
      <p>Also, since free text was available for most questions, it can be hard to categorize some of the results. For multiple choice questions, I did a best effort attempt to bundle responses with low cardinality into an "other" section, which can get quite big in some cases! I also did not attempt to graph anything for pure free text questions. I encourage anyone who is curious to inspect the full responses, either in the notebook or looking at the data directly. The omitted free text questions are:
        </p><ul>
          <li>If you use org-mode, for what purpose?</li>
          <li>Do you use a language server with lsp-mode or eglot? With what languages?</li>
          <li>Do you use an Emacs debugger interface? What do you use? (Gdb, dap-mode etc)</li>
          <li>What are some of the Emacs improvements you are the most interested in?</li>
          <li>What do you think are Emacs' greatest strengths?</li>
          <li>Can you recall any difficulties you faced initially learning Emacs?</li>
          <li>What is the one thing you would like Emacs to do differently?</li>
          <li>If there is another survey in 2021, would you be opposed to it containing optional &amp; general demographics questions?</li>
          <li>Do you have a preferred platform for filling out the survey in the future?</li>
          <li>Do you have general feedback about the survey process?</li>
        </ul>
      

      <p>Also if you have some cool analysis and want to share it, please <a href="mailto:contact@emacssurvey.org">let us know</a> and we can link to you.</p>
      <p><img src="https://emacssurvey.org/2020/how-would-you-characterize-your-use-of-emacs.png">
      <img src="https://emacssurvey.org/2020/what-do-you-use-emacs-for.png">
      <img src="https://emacssurvey.org/2020/for-how-many-years-have-you-been-using-emacs.png">
      <img src="https://emacssurvey.org/2020/which-version-of-emacs-do-you-primarily-use.png">
      <img src="https://emacssurvey.org/2020/which-os-do-you-primarily-use-emacs-on.png">
      <img src="https://emacssurvey.org/2020/how-do-you-run-emacs.png">
      <img src="https://emacssurvey.org/2020/how-do-you-use-emacs.png">
      <img src="https://emacssurvey.org/2020/if-you-use-emacs-gui-do-you-disable-any-of-the-graphical-elements.png">
      <img src="https://emacssurvey.org/2020/is-your-configuration-based-on-any-starter-kit.png">
      <img src="https://emacssurvey.org/2020/what-keybindings-do-you-use-now.png">
      <img src="https://emacssurvey.org/2020/when-you-started-using-emacs-what-keybindings-did-you-use-then.png">
      <img src="https://emacssurvey.org/2020/prior-to-using-emacs-what-was-your-primary-editor.png">
      <img src="https://emacssurvey.org/2020/describe-your-org-mode-usage.png"></p><!-- <p>If you use org-mode, for what purpose?</p> -->
      <p><img src="https://emacssurvey.org/2020/which-completionselection-framework-do-you-use.png">
      <img src="https://emacssurvey.org/2020/how-do-you-manage-third-party-elisp.png">
      <img src="https://emacssurvey.org/2020/how-do-you-get-emacs-packagesif-applicable.png">
      <img src="https://emacssurvey.org/2020/can-you-list-some-of-your-favorite-packages.png">
      <img src="https://emacssurvey.org/2020/which-theme-do-you-use.png">
      <img src="https://emacssurvey.org/2020/what-package-do-you-use-for-error-checking.png">
      <img src="https://emacssurvey.org/2020/do-you-use-tramp.png">
      <img src="https://emacssurvey.org/2020/do-you-use-magit.png">
      <img src="https://emacssurvey.org/2020/what-package-do-you-use-for-project-management.png">
      <img src="https://emacssurvey.org/2020/do-you-use-a-shellterminal-emulator-in-emacs.png">
      <img src="https://emacssurvey.org/2020/do-you-use-an-email-client-in-emacs.png">
      <img src="https://emacssurvey.org/2020/what-is-your-elisp-proficiency.png">
      <img src="https://emacssurvey.org/2020/if-you-use-emacs-for-programming-which-languages-do-you-program-in.png"></p><!-- <p>Do you use a language server with lsp-mode or eglot? With what languages?</p>
           <p>Do you use an Emacs debugger interface? What do you use? (Gdb, dap-mode etc)</p> -->
      <p><img src="https://emacssurvey.org/2020/have-you-ever-contributed-to-gnu-emacs-coreelpa.png">
      <img src="https://emacssurvey.org/2020/have-you-ever-contributed-to-melpa-package.png">
      <img src="https://emacssurvey.org/2020/have-you-ever-contributed-financially-to-emacs-development-either-via-fsf-or-directly.png">
      <img src="https://emacssurvey.org/2020/what-emacs-community-forums-have-you-visited-in-the-past-year.png"></p><!-- <p>What are some of the Emacs improvements you are the most interested in?</p>
           <p>What do you think are Emacs' greatest strengths?</p>
           <p>Can you recall any difficulties you faced initially learning Emacs?</p>
           <p>What is the one thing you would like Emacs to do differently?</p> -->
      <p><img src="https://emacssurvey.org/2020/how-did-you-hear-about-this-survey.png"></p><!-- <p>If there is another survey in 2021, would you be opposed to it containing optional & general demographics questions?</p>
           <p>Do you have a preferred platform for filling out the survey in the future?</p>
           <p>Do you have general feedback about the survey process?</p> -->
    </div></div>]]>
            </description>
            <link>https://emacssurvey.org/2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25388353</guid>
            <pubDate>Fri, 11 Dec 2020 17:38:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a garbage-free network stack for Kafka streams]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25388119">thread link</a>) | @prtkgpt
<br/>
December 11, 2020 | https://questdb.io/blog/2020/12/10/building-a-garbage-free-network-stack-for-kafka-streams | <a href="https://web.archive.org/web/*/https://questdb.io/blog/2020/12/10/building-a-garbage-free-network-stack-for-kafka-streams">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><figure><img alt="Steam network of a Pennsylvania coal power plant" height="433" src="https://questdb.io/img/blog/2020-12-10/banner.jpg" width="650"><figcaption>Photo by <a href="https://unsplash.com/photos/a_PDPUPuNZ8" target="_blank" rel="noopener noreferrer">Martin Adams</a> on <a href="https://unsplash.com/" target="_blank" rel="noopener noreferrer">Unsplash</a></figcaption></figure><p>We recently improved the PostgreSQL wire protocol in QuestDB to support ingesting
messages via Kafka streams. At its heart, the implementation uses an
IODispatcher component, which we thought readers might find interesting to hear
about. This component is a generic core subsystem that is now used to handle all
incoming network connections to QuestDB.</p><p>In this article, you will find out how we achieved garbage-free execution and
how we handle multiple TCP network connections on a single thread, allowing us
to reliably run in multi-tenant mode and directly decouple functionality from
the number of available threads.</p><h2>Flow control<a href="#flow-control" title="Direct link to heading">#</a></h2><p>When we have multiple nodes on a network, there are usually disparities in their
performance in computing power and network bandwidth. Some nodes can read
incoming packets at different rates than others, or conversely, some nodes may
be able to send data at a different rate.</p><p>Let's say we have a network with two nodes; a sender and a receiver. If the
sender can produce a lot more data than the receiver can read, the receiver is
likely to be overwhelmed. We're in luck, though, as TCP uses a built-in flow
control protocol that acts as a pressure valve to ensure the receiver is not
affected by such cases.</p><p>Control flow manifests itself in different ways, depending on whether the
network socket is blocking or non-blocking. If the receiver can process data
faster than a sender, a non-blocking socket is identical to a blocking one, and
the receiver thread would be parked while no data is read. There's not much
concern about this situation if it happens infrequently, but the park and unpark
is a waste of resources and CPU cycles if the receiver is under heavy load.</p><p>Let's assume the receiver gets 0-length data on a non-blocking socket, indicating
no data has arrived from the sender; there are two options:</p><ol><li>Loop over reads continuously, waiting for data to arrive on a socket.</li><li>Stop looping and consult our parser on two possible actions to take: park for
more reads or switch to write.</li></ol><p>The first option is quite wasteful, so we went with the second approach. To park
socket read operations without blocking the thread, we need a dedicated system
to enqueue the socket and notify us when the socket has more data to read. On
the OS kernel level, IO notification utilities exist as <code>epoll</code> on Linux,
<code>kqueue</code> on FreeBSD and OSX, and <code>select</code> on Windows. In QuestDB, we've
implemented a dispatcher that operates exactly as these IO notification systems
for enqueuing sockets, and we named it IODispatcher.</p><h2>Java NIO and garbage collection<a href="#java-nio-and-garbage-collection" title="Direct link to heading">#</a></h2><p>As you would expect from cross-platform languages, the IO Notification system
must be abstracted away to make application code portable. In Java, this
abstraction is called <code>Selector</code>. If we were to oversimplify a typical
interaction with the IO Notification system, it would essentially be a loop.
More often than not, this is an infinite loop, or rather, it executes
continuously during the server's uptime.</p><p>Since we are on a quest to have everything garbage-free, Selector presents a
problem right away - the output of the selector is a set of keys, coming from a
concurrent hash map via an iterator. All of this allocates objects on every
iteration of the loop. If you are not careful, this allocation continues even
when the server is idling. The behavior is intrinsic to the Java Non-blocking
I/O (NIO) implementation and cannot be changed.</p><p>To send or receive data from the network, Java mandates ByteBuffer instances.
When looked at in a vacuum, ByteBuffer may seem like a reasonable abstraction.
But if we look closer, it's easy to see it's a bit confused. It is a concrete
class instead of an interface, meaning that the whole NIO is stuck with the
provided implementation. The API is inconsistent as the OS requires memory
pointers for send and receive methods, but ByteBuffer does not provide an
explicit semantic for each case. So how does ByteBuffer translate to a memory
pointer?</p><p>When your data is on the heap, there is a memory copy for each socket IO. When
ByteBuffer is direct, there is no copy, but there is an issue releasing memory
and general Java paranoia about language safety.</p><div><p>Native Java socket write implementation</p></div><p>Considering the allocating nature of the Selector, that Java NIO libraries are a
layer above the OS, and how computationally expensive the overhead is with
ByteBuffer, we decided to go out on a limb and interact directly with the OS via
the Java Native Interface (JNI). This worked for QuestDB insofar as the API is
non-allocating outside of the normal bootstrap phase and lets us work with the
memory pointers directly.</p><div><p>QuestDB's JNI call for sending data to a socket</p></div><h2>QuestDB's thread model<a href="#questdbs-thread-model" title="Direct link to heading">#</a></h2><p>Starting threads is expensive, and they're more often than not just wrappers for
the connection state. QuestDB operates a fixed number of threads to isolate the
database instance to specific cores and reduce the overhead of starting and
stopping threads at runtime. The actual threads are encapsulated by a WorkerPool
class.</p><p>The worker pool's idea is to have a simple list of "jobs" that all workers will
run all the time. Jobs themselves encapsulate "piece of work" and do not have
tight loops in them. Hence a job can simply return if IO is not available or the
queue is full or empty.</p><p>We have a notion of a "synchronized job." It is different from the definition of
"synchronized" in Java in that the QuestDB's thread never blocks. However,
synchronized jobs guarantee that only one thread can execute a job instance at
any moment in time.</p><h2>Introducing QuestDB's IODispatcher<a href="#introducing-questdbs-iodispatcher" title="Direct link to heading">#</a></h2><p>IODispatcher is QuestDB's implementation of the IO Notification loop. We have
implemented <code>epoll</code>, <code>kqueue</code>, and <code>select</code>, so this works cross-platform. The
appropriate implementation is automatically chosen at runtime based on the OS.
The IODispatched API is message-driven via QuestDB's implementation of
non-blocking and non-allocating queues. These queues are outside of the scope of
this article, but you can read about them in our community
<a href="https://questdb.io/blog/2020/11/26/http-server-contribution">contribution from Alex Pelagenko</a>.</p><figure><img alt="A diagram of QuestDB's IODispatcher" height="284" src="https://questdb.io/img/blog/2020-12-10/iodispatcher-diagram.png" width="650"><figcaption>IODispatcher and queues for events, interest, and disconnections</figcaption></figure><p>IODispatcher is a synchronized job. It consumes queues on the left and publishes
to the queue on the right. Let's take a look at the components in the diagram
above with an outline of their purpose:</p><p><strong>IO Event Queue:</strong> Single publisher, multiple consumer queue. It is the
recipient of the IO events from as in epoll, kqueue, select. The events are
socket handles and the type of operation the OS has associated them with, e.g.,
read or write. The IODispatcher plays the publisher role, and any number of
worker threads are the consumers.</p><p><strong>Interest Queue:</strong> Multiple publisher, single consumer queue. Worker threads
publish socket handles and operations to this queue when IO is unavailable,
e.g., socket read or write returns zero. The IODispatcher will enqueue the
socket handle for more reads or writes as defined by the operation.</p><p><strong>Disconnect Queue:</strong> Multiple publisher, single consumer queue. Worker threads
publish socket handles to this queue destined to be disconnected from the server
and have their resources reused by other connections. The worker thread does not
disconnect the socket by itself because multiple threads may attempt to access a
data structure that is not thread-safe.</p><h3>Configuration<a href="#configuration" title="Direct link to heading">#</a></h3><p>We disregarded ByteBuffer for not being an interface, so it would only be fair
for us to have interfaces in key places. One of these places is configuration,
which provides IODispatcher with basics such as:</p><ul><li>The IP address of the network interface</li><li>Port to bind to</li><li>Bias</li><li>Buffer sizes</li><li>Network facade</li><li>Clock facade</li><li>Connection context factory</li></ul><p>It's necessary to explain bias here, which might not be so obvious. When the TCP
connection is first accepted, it is enqueued for IO right away. The bias
provides an expectation of the initial operation of a connection, such as read
or write. For example, most TCP protocols would have 'read bias', which means
that connecting clients will have to send data before the server replies
anything. You can probably think of a protocol that requires the server to
respond first before the client sends anything - in this case, the bias will be
'write'.</p><p>Network &amp; clock facades have static implementations for production runtime, but
for tests, they can be both spot-implemented to simulate OS failures and produce
stable timestamps.</p><h3>Connection Context<a href="#connection-context" title="Direct link to heading">#</a></h3><p>Connection context is a Java object that encapsulates the connection state,
which is protocol-specific. It is stored together with the socket handle and
managed by IODispatcher via the context factory. We talked a little about the
QuestDB thread model and that workers are very likely to execute the same job
instance simultaneously unless the job is synchronized. In this scenario, the
only place a job can reliably store a state is the connection context.</p><h3>Protocol Parsers<a href="#protocol-parsers" title="Direct link to heading">#</a></h3><p>Protocol parsers are used by worker threads to make sense of the incoming data.
QuestDB has a convention that all protocol parsers must be streaming, e.g., they
never hold on to the entirety of the data sent over the network. These parsers
are typically state machines, with state held in connection context. This type
of parser allows fully real-time ingestion of large data segments, such as text
file import.</p><h3>Worker Threads<a href="#worker-threads" title="Direct link to heading">#</a></h3><p>Worker threads are required to consume the IO event queue. You might see already
that the IODispatcher neither reads nor writes connected sockets itself. This is
the responsibility of the worker threads.</p><p>Worker threads almost always use protocol parsers to interpret socket data. They
must continue to work with the socket until the socket cannot read or write
anymore. In which case, the worker threads either express "interest" in further
socket interaction or disconnects the socket. In this situation, IODispatcher is
not on the execution path during most of the socket interaction.</p><h2>Summary<a href="#summary" title="Direct link to heading">#</a></h2><p>In this article, we've covered our approach to implementing non-blocking IO
using what we think is a …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://questdb.io/blog/2020/12/10/building-a-garbage-free-network-stack-for-kafka-streams">https://questdb.io/blog/2020/12/10/building-a-garbage-free-network-stack-for-kafka-streams</a></em></p>]]>
            </description>
            <link>https://questdb.io/blog/2020/12/10/building-a-garbage-free-network-stack-for-kafka-streams</link>
            <guid isPermaLink="false">hacker-news-small-sites-25388119</guid>
            <pubDate>Fri, 11 Dec 2020 17:18:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Federated Learning in less than 20 lines of code]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25387700">thread link</a>) | @tanto
<br/>
December 11, 2020 | https://flower.dev/blog/2020-12-11-federated-learning-in-less-than-20-lines-of-code | <a href="https://web.archive.org/web/*/https://flower.dev/blog/2020-12-11-federated-learning-in-less-than-20-lines-of-code">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Can we build a fully-fledged Federated Learning system in less than 20 lines of code? Spoiler alert: yes, we can.</p><p><a href="https://flower.dev/">Flower</a> was built with a strong focus on usability. This blog post shows how we can use Flower and <a href="https://tensorflow.org/">TensorFlow</a> to train <a href="https://arxiv.org/abs/1801.04381">MobilNetV2</a> on <a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10</a> - in just 19 lines of code.
The system will start one server and two clients, each holding their own local dataset.</p><h2>Flower client</h2><p>Let's first build the client in <code>client.py</code>.
The client starts by importing Flower (<code>flwr</code>) and TensorFlow, compiling the model (MobileNetV2), and loading the data (CIFAR-10):</p><div><article><p>Copy</p><pre><code><span>import</span><span> flwr </span><span>as</span><span> fl
</span><span></span><span>import</span><span> tensorflow </span><span>as</span><span> tf
</span>
<span></span><span># Load and compile Keras model</span><span>
</span><span>model = tf.keras.applications.MobileNetV2((</span><span>32</span><span>, </span><span>32</span><span>, </span><span>3</span><span>), classes=</span><span>10</span><span>, weights=</span><span>None</span><span>)
</span><span>model.</span><span>compile</span><span>(</span><span>"adam"</span><span>, </span><span>"sparse_categorical_crossentropy"</span><span>, metrics=[</span><span>"accuracy"</span><span>])
</span>
<span></span><span># Load CIFAR-10 dataset</span><span>
</span>(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()
</code></pre></article></div><p>This should look familiar to anyone who has prior experience with TensorFlow or Keras.
Next, we build a Flower client called <code>CifarClient</code> which is derived from Flower's convenience class <code>KerasClient</code>.
The abstract base class <code>KerasClient</code> defines three methods that clients need to override.
These methods allow Flower to trigger training and evaluation of the previously defined Keras model:</p><div><article><p>Copy</p><pre><code><span># Define Flower client</span><span>
</span><span></span><span>class</span><span> </span><span>CifarClient</span><span>(</span><span>fl.client.keras_client.KerasClient</span><span>):</span><span>
</span><span>    </span><span>def</span><span> </span><span>get_weights</span><span>(</span><span>self</span><span>):</span><span>
</span><span>        </span><span>return</span><span> model.get_weights()
</span>
<span>    </span><span>def</span><span> </span><span>fit</span><span>(</span><span>self, weights, config</span><span>):</span><span>
</span>        model.set_weights(weights)
<span>        model.fit(x_train, y_train, epochs=</span><span>1</span><span>, batch_size=</span><span>32</span><span>, steps_per_epoch=</span><span>3</span><span>)  </span><span># Remove `steps_per_epoch=3` to train on the full dataset</span><span>
</span><span>        </span><span>return</span><span> model.get_weights(), </span><span>len</span><span>(x_train), </span><span>len</span><span>(x_train)
</span>
<span>    </span><span>def</span><span> </span><span>evaluate</span><span>(</span><span>self, weights, config</span><span>):</span><span>
</span>        model.set_weights(weights)
<!-- -->        loss, accuracy = model.evaluate(x_test, y_test)
<span>        </span><span>return</span><span> </span><span>len</span><span>(x_test), loss, accuracy</span></code></pre></article></div><p>Flower's <code>KerasClient.fit</code> method receives weights from the server, updates the model with those weights, trains the model on the locally held dataset (<code>x_train</code>/<code>y_train</code>), and then returns the updated weights (via <code>model.get_weights</code>).
Note that you can do a quick "dry run" by passing <code>steps_per_epoch=3</code> to <code>model.fit</code> - this will only process three batches per epoch instead of the entire dataset.
Remove <code>steps_per_epoch=3</code> to train on the full dataset (this will take longer).</p><p>The <code>evaluate</code> method works similarly, but it uses the provided weights to evaluate the model on the locally held dataset (<code>x_test</code>/<code>y_test</code>).
The last step is to create an instance of <code>CifarClient</code> and run it:</p><div><article><p>Copy</p><pre><code><span># Start Flower client</span><span>
</span><span>fl.client.start_keras_client(server_address=</span><span>"[::]:8080"</span><span>, client=CifarClient())</span></code></pre></article></div><p>That's it for the client. We create the model, load the data, implement a subclass <code>KerasClient</code>, and start the client. Let's build the server script next.</p><h2>Flower server</h2><p>In a new script called <code>server.py</code>, we add the following two lines to start a Flower server that performs three rounds of <a href="https://arxiv.org/pdf/1602.05629.pdf">Federated Averaging</a>:</p><div><article><p>Copy</p><pre><code><span>import</span><span> flwr </span><span>as</span><span> fl
</span><span>fl.server.start_server(config={</span><span>"num_rounds"</span><span>: </span><span>3</span><span>})</span></code></pre></article></div><p>That's it! We can now run our system. Are we still within our lines of code limit? Lines of code (excluding blank lines or comments): 19 <!-- -->🎉</p><h2>Running the system</h2><p>First, we start the server:</p><p>Next, we open a new terminal and start the first client:</p><p>Finally, we open another new terminal and start the second client:</p><p>This should result in the following output in terminal 2 or 3 (one of those running <code>client.py</code>).
We can see that three rounds of federated learning improve the accuracy to about 46% on the training set and 28% on the test set (if we train on the full dataset, so no <code>steps_per_epoch=3</code>).
There's obviously lots of room for improvement, for example, by doing more rounds of federated learning and by tuning hyperparameters. </p><div><article><p>Copy</p><pre><code><span>DEBUG flower </span><span>2020</span><span>-12</span><span>-04</span><span> </span><span>18</span><span>:</span><span>57</span><span>:</span><span>18</span><span>,</span><span>259</span><span> | connection.py:</span><span>36</span><span> | ChannelConnectivity.IDLE
</span><span>DEBUG flower </span><span>2020</span><span>-12</span><span>-04</span><span> </span><span>18</span><span>:</span><span>57</span><span>:</span><span>18</span><span>,</span><span>260</span><span> | connection.py:</span><span>36</span><span> | ChannelConnectivity.CONNECTING
</span><span>DEBUG flower </span><span>2020</span><span>-12</span><span>-04</span><span> </span><span>18</span><span>:</span><span>57</span><span>:</span><span>18</span><span>,</span><span>261</span><span> | connection.py:</span><span>36</span><span> | ChannelConnectivity.READY
</span><span>INFO flower </span><span>2020</span><span>-12</span><span>-04</span><span> </span><span>18</span><span>:</span><span>57</span><span>:</span><span>18</span><span>,</span><span>261</span><span> | app.py:</span><span>61</span><span> | Opened (insecure) gRPC connection
</span><span></span><span>1563</span><span>/</span><span>1563</span><span> [==============================] - </span><span>123</span><span>s </span><span>79</span><span>ms/step - loss: </span><span>1.8809</span><span> - accuracy: </span><span>0.3158</span><span>
</span><span></span><span>313</span><span>/</span><span>313</span><span> [==============================] - </span><span>6</span><span>s </span><span>21</span><span>ms/step - loss: </span><span>2.3204</span><span> - accuracy: </span><span>0.1000</span><span>
</span><span></span><span>1563</span><span>/</span><span>1563</span><span> [==============================] - </span><span>141</span><span>s </span><span>90</span><span>ms/step - loss: </span><span>1.7094</span><span> - accuracy: </span><span>0.3861</span><span>
</span><span></span><span>313</span><span>/</span><span>313</span><span> [==============================] - </span><span>4</span><span>s </span><span>13</span><span>ms/step - loss: </span><span>2.3337</span><span> - accuracy: </span><span>0.1000</span><span>
</span><span></span><span>1563</span><span>/</span><span>1563</span><span> [==============================] - </span><span>140</span><span>s </span><span>90</span><span>ms/step - loss: </span><span>1.5050</span><span> - accuracy: </span><span>0.4645</span><span>
</span><span></span><span>313</span><span>/</span><span>313</span><span> [==============================] - </span><span>5</span><span>s </span><span>14</span><span>ms/step - loss: </span><span>2.0941</span><span> - accuracy: </span><span>0.2799</span><span>
</span><span>DEBUG flower </span><span>2020</span><span>-12</span><span>-04</span><span> </span><span>19</span><span>:</span><span>04</span><span>:</span><span>30</span><span>,</span><span>284</span><span> | connection.py:</span><span>68</span><span> | Insecure gRPC channel closed
</span><span>INFO flower </span><span>2020</span><span>-12</span><span>-04</span><span> </span><span>19</span><span>:</span><span>04</span><span>:</span><span>30</span><span>,</span><span>284</span><span> | app.py:</span><span>72</span><span> | Disconnect </span><span>and</span><span> shut down</span></code></pre></article></div><p>Congratulations, you have built a running Federated Learning system in less than 20 lines of code!</p><p>The full source code can be found <a href="https://github.com/adap/flower/tree/main/src/py/flwr_example/tensorflow_minimal">here</a>.</p><h2>Next steps</h2><p>Our system is of course simplified in some ways, for example, both clients load the same dataset.
Real-world FL systems would use a different data partition on each client and a lot more clients overall.
Here are a few ideas on what to try next:</p><ul><li>Split CIFAR-10 into two partitions and load one partition on each client</li><li>Start additional clients and see how the server behaves (no coding required, just open more terminals or use a script which starts client processes in the background)</li><li>Try to find better hyperparameters</li><li>Use your own model and/or dataset</li><li><a href="https://flower.dev/docs/strategies.html">Customize the federated learning strategy</a></li></ul><p>We'd be delighed to hear from you!</p><ul><li>Join the Flower community on Slack! -&gt; Button in the top right corner</li><li><a href="https://github.com/adap/flower">Star Flower on GitHub</a></li></ul></div></div></div>]]>
            </description>
            <link>https://flower.dev/blog/2020-12-11-federated-learning-in-less-than-20-lines-of-code</link>
            <guid isPermaLink="false">hacker-news-small-sites-25387700</guid>
            <pubDate>Fri, 11 Dec 2020 16:44:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Paper, Pen and Tools for Thinking]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25387504">thread link</a>) | @kawera
<br/>
December 11, 2020 | https://situated.blog/2020/11/tools-for-thinking | <a href="https://web.archive.org/web/*/https://situated.blog/2020/11/tools-for-thinking">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" role="main"><article role="article"><time datetime="2020-11-19T00:00:00+00:00">November 19, 2020</time><blockquote><p>“The art of thinking is grounded in the mind’s astonishing capacity to create beyond what it intends, beyond what it can foresee.” — Theodore Roszak, <a href="https://www.ucpress.edu/book/9780520085848/the-cult-of-information">The Cult of Information</a></p></blockquote><p>Perhaps one of the best habits that I’ve picked up and sustained in 2020 is the art of <a href="https://bulletjournal.com/pages/learn">bullet journaling</a>. Now that I’m a few months in, my journal has since become a trusty sidekick, the daily ritual of its care and feeding now an essential, calming practice. Journaling is how I both start and end my day. It is how I reflect on the activities of the previous week, the highs and lows of the previous month, how I track all of my tasks and todos and remember important events. Writing things down on paper in a structured way has genuinely helped me focus, remember things, think more clearly, maintain other habits, and even pare down my commitments in ways I was never able to achieve with more sophisticated digital tools. And over the years I have tried <em>a lot</em> of digital tools—<a href="https://todoist.com/">todo lists</a>, <a href="https://dayoneapp.com/">journaling apps</a>, <a href="https://www.onenote.com/">notetaking apps</a> and <a href="https://www.notion.so/">apps that transcend these boundaries</a>. I still use these tools, but they have become secondary, playing a supporting role to a <a href="https://www.leuchtturm1917.us/notebook-medium-a5-hardcover-251-numbered-pages-5-3-4-x-8-1-4-in.html">simple, black dotted notebook</a> that has since become the star of my daily routine.</p><p>The allure and promise of so many digital productivity tools is that they purport to be better than the analog tools from which they derive inspiration. In some ways this is true; they offer near-ubiquitous ease of access, better searchability, collaboration support with distant colleagues, protection against data loss, etc. But computational devices—be they laptops, desktops, phones, tablets—remain fairly poor instruments for the act of <em>thinking</em>. In this, nothing seems to top the simplicity of paper and pen.</p><p>There are several reasons for this:</p><ul><li><p>First, paper is <em>approachable</em> in a way that a blank screen is not. It is disposable. It invites mark-making, doodling, folding, crumpling and tossing. Something about the tangiblity of paper feels less intimidating during those tenuous first moments when you’re trying to coax your mind to focus and action. But beyond that it encourages fiddling, which in turn stimulates the mind in a way I haven’t found replicable with digital devices. Without a better way of describing it, paper is simply more human.</p></li><li><p>Second, paper is <em>immediate</em>. There is no machine to power on, no app to find and open. It’s just right there, available and ready to absorb a thought. Assuming you have a pen handy, the number of obstacles you have to overcome from moment you have a thought to recording that thought is essentially zero.</p></li><li><p>Finally, paper encourages <em>focus</em>. It is a single-purpose object without unnecessary distractions. Whether you’re taking notes in a notebook or papering your wall with post-it notes, analog tools create an environment that won’t distract you from the task of thinking. There are no notifications, no icons tempting you to browse the web or check Twitter.</p></li></ul><p>A few days ago I <a href="https://www.youtube.com/watch?v=vrhBaR2fNjQ&amp;feature=youtu.be&amp;ab_channel=TheGeneralist">watched a panel conversation</a> put together by Mario Gabriele of <a href="https://thegeneralist.substack.com/">The Generalist</a> on independent research, tools for thought and internet academia. The conversation opens with the question: “What is your favorite tool for thought?” Several of the panelists respond by sharing favorite analog tools—reams of dot-matrix printer paper, four-color pens, books, post-it notes. When any panelist did share a digital tool—<a href="https://www.are.na/">Are.na</a> or <a href="">Google Scholar</a>, for instance—it was a tool used for purposes of information gathering and organization rather than creating, assembling, drawing, searching for patterns, the hard work of thought.</p><p>Computing just isn’t there yet.</p><p>The devices <a href="https://web.archive.org/web/20141022035044/http://www.ubiq.com/hypertext/weiser/SciAmDraft3.html">Mark Weiser once dreamed about</a> have become reality, with input modalities on par with the expressive fidelity of paper and pen. And perhaps one day we will invent better tools for augmenting thought beyond digital facsimiles of analog solutions. But not without much more investment in this space. Over two decades ago, during the heyday of labs like <a href="https://en.wikipedia.org/wiki/PARC_%28company%29">Xerox PARC</a>, computing tools for thinking, productivity and creativity felt richly explored and researched. Today, the bulk of the tech world has focused on, as <a href="https://twitter.com/_adamwiggins_">Adam Wiggins</a> asserts in the conversation mentioned above, social media, video, search, and other consumer-focused endeavors. The promise of computing to serve human creativity, thought, and productivity feels, these days, somewhat quaint—a whisper of some bygone era lost in a cacophony of services competing for ever-smaller slices of attention.</p><p>There’s a lot of room to innovate, but lately the industry feels like it’s lost all ambition here.</p></article></div></div>]]>
            </description>
            <link>https://situated.blog/2020/11/tools-for-thinking</link>
            <guid isPermaLink="false">hacker-news-small-sites-25387504</guid>
            <pubDate>Fri, 11 Dec 2020 16:28:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Smash Training Retrospective]]>
            </title>
            <description>
<![CDATA[
Score 29 | Comments 19 (<a href="https://news.ycombinator.com/item?id=25387356">thread link</a>) | @arxanas
<br/>
December 11, 2020 | https://waleedkhan.name/blog/smash-training-retrospective/ | <a href="https://web.archive.org/web/*/https://waleedkhan.name/blog/smash-training-retrospective/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    
    <p><a href="https://ssb.fit/"><em>Smash Training</em></a> is a spaced-repetition training web-app I created to help my progression with <em>Super Smash Bros. Ultimate</em>. I released it on May 16, 2020 <a href="https://www.reddit.com/r/CrazyHand/comments/gkybpe/trying_to_get_into_elite_smash_this_quarantine/?utm_source=share&amp;utm_medium=web2x&amp;context=3">on Reddit</a> to warm reception. As of December 2020, it receives 150-200 monthly users. I’d rank it as my most successful project!</p>

<p>In this article, I discuss the choices I made for this project. The source code is available at <a href="https://github.com/arxanas/smashtraining">https://github.com/arxanas/smashtraining</a>.</p>

<ul id="markdown-toc">
  <li><a href="#project-requirements" id="markdown-toc-project-requirements">Project requirements</a></li>
  <li><a href="#domain-name" id="markdown-toc-domain-name">Domain name</a></li>
  <li><a href="#user-studies-and-ui" id="markdown-toc-user-studies-and-ui">User studies and UI</a>    <ul>
      <li><a href="#ui" id="markdown-toc-ui">UI</a></li>
      <li><a href="#documentation" id="markdown-toc-documentation">Documentation</a></li>
    </ul>
  </li>
  <li><a href="#tech-stack" id="markdown-toc-tech-stack">Tech stack</a>    <ul>
      <li><a href="#build-system" id="markdown-toc-build-system">Build system</a></li>
      <li><a href="#typescript" id="markdown-toc-typescript">TypeScript</a></li>
      <li><a href="#vue" id="markdown-toc-vue">Vue</a></li>
      <li><a href="#vuetify" id="markdown-toc-vuetify">Vuetify</a></li>
      <li><a href="#netlify-for-hosting" id="markdown-toc-netlify-for-hosting">Netlify for hosting</a></li>
      <li><a href="#custom-database" id="markdown-toc-custom-database">Custom database</a></li>
      <li><a href="#github-as-a-static-data-store" id="markdown-toc-github-as-a-static-data-store">Github as a static data-store</a></li>
    </ul>
  </li>
  <li><a href="#conclusions" id="markdown-toc-conclusions">Conclusions</a></li>
</ul>

<h2 id="project-requirements">Project requirements</h2>

<p>I decided that I wanted to build a spaced-repetition training app, rather than reuse a general-purpose spaced-repetition flash-card system such as Anki, because the project would benefit from domain-specific knowledge. For example:</p>

<ul>
  <li>Exercises have large numbers of variants, such as “short-hop” vs “full-hop”, or “facing left” vs “facing right”, which should be tracked separately.</li>
  <li>Many of the exercises have natural dependencies on others: they shouldn’t be attempted unless a certain underlying fundamental skill has been mastered.</li>
  <li>Exercises to train one character don’t necessarily confer the same skill for other characters. Some exercises may only be applicable to some characters.</li>
</ul>

<p>I decided to make an app to automate the spaced repetition regimen I was attempting to follow by hand, which I could then share with others.</p>

<p>Here were my engineering requirements:</p>

<ul>
  <li>Should be mobile-first, but preferably also available on desktop.</li>
  <li>Should be local-first, or at least not require creating an account to use.</li>
  <li>Should be architected to support sync between devices, although the sync itself was not a requirement for the first iteration.</li>
  <li>Should have approximately zero hosting costs.</li>
  <li>Should be hosted on of a stable platform which doesn’t require monitoring (e.g. not my home computer).</li>
</ul>

<h2 id="domain-name">Domain name</h2>

<p>I wanted to choose between a permutation like the following for the domain name:</p>

<ul>
  <li>smashtraining.com</li>
  <li>ssbtraining.com</li>
  <li>smash.training</li>
  <li>ssb.training</li>
  <li>smash.fit</li>
  <li>ssb.fit</li>
</ul>

<p>In the end, I used <code>ssb.fit</code> because 1) <code>smash.training</code> got taken (!) and 2) I wanted to optimize for typing it in on a mobile device, even though the name is less memorable. This lack of memorability unfortunately manifested in <a href="https://www.reddit.com/r/CrazyHand/comments/gp9sem/wtf_was_that_smash_training_website_called/frkscwe/?context=3">this Reddit thread titled “WTF was that smash training website called?”</a>. However, another commenter writes “ssb.fit is better, short for mobile”, perhaps vindicating the original choice.</p>

<p>It’s unfortunate that the domain name and the website title don’t exactly match up. Many people seemed to address it as “ssb.fit” hence, so maybe that’s what the project should have been called too (rather than “Smash Training”).</p>

<h2 id="user-studies-and-ui">User studies and UI</h2>

<p>I conducted several user studies with friends and family, including some people who had played Smash before and some who hadn’t.</p>

<h3 id="ui">UI</h3>

<p>The first main thing I iterated on was the design of the exercise tracker widget. I originally based it off of the <em>Stronglifts</em> app:</p>

<figure>
        <a href="https://waleedkhan.name/blog/assets/posts/smash-training-retrospective/stronglifts.png"><img src="https://waleedkhan.name/blog/assets/posts/smash-training-retrospective/stronglifts.png" alt="Advertisement screenshot of the Stronglifts workout app." title="Advertisement screenshot of the Stronglifts workout app."></a>
        <figcaption><p>Advertisement screenshot of the Stronglifts workout app.</p>
</figcaption>
      </figure>

<p><em>Stronglifts</em> has you note down how many repetitions of the exercise you succeeded at (out of five). However, the <em>Smash Training</em> paradigm is different, and has you repeat the exercise for a length of time and rate your accuracy.</p>

<p>I experimented with a “smiley-face” UI rather than a rep-count UI, as in Stronglifts, along with a few other options. After a lot of feedback from friends, I arrived at a slider-based widget like this:</p>

<figure>
        <a href="https://waleedkhan.name/blog/assets/posts/smash-training-retrospective/smash-training-exercise-widget.png"><img src="https://waleedkhan.name/blog/assets/posts/smash-training-retrospective/smash-training-exercise-widget.png" alt="Screenshot of the Smash Training exercise widget." title="Screenshot of the Smash Training exercise widget."></a>
        <figcaption><p>Screenshot of the Smash Training exercise widget.</p>
</figcaption>
      </figure>

<p>This uses a slider approach (with five possible notches), and renders a description of what each notch corresponds to, i.e. “all or nearly all reps correct”.</p>

<h3 id="documentation">Documentation</h3>

<p>The second main thing was the ordering of the elements in the “Learn exercise” page. Each exercise has a step-by-step description of how to do the exercise, what controller inputs must be performed, background on the technique and its importance, a video tutorial, etc.</p>

<p>My assumption was that most people would read very little of it, so I should put the most important items first. However, various users disagreed on which item was the most important. There was no strong consensus, but the end result was this ordering:</p>

<ul>
  <li>Step-by-step exercise description.</li>
  <li>Controller inputs.</li>
  <li>Technique overview.</li>
  <li>The rest of the documentation elements (not as important).</li>
</ul>

<p>There were also hints on these steps such as how to enter the Training Stage to perform the exercises. Some users missed these steps altogether, and were left confused on how to perform the exercise. Unfortunately, I was unable to design a UI that mitigated this problem.</p>

<h2 id="tech-stack">Tech stack</h2>

<p>I chose to write a web-app, since they are cross-platform and I already had some familiarity with the area. In particular, I didn’t want to spend money on an iOS developer license, but I also didn’t want to exclude iOS users. (Post-hoc analytics indicate that the ratio of Android-to-iOS users is about 2:1, which consitutes a significant cohort for iOS.)</p>

<h3 id="build-system">Build system</h3>

<p>All Javascript web-app bundling solutions are fundamentally terrible, and Webpack is no exception. But it works.</p>

<p><a href="https://github.com/arxanas/smashtraining/commit/f621f02af95da697435cb720563b590d57f38b87">I encountered one mysterious bug in Babel during development</a>, which I was unable to isolate. I worked around it by targeting only newer browsers, after which the problem disappeared.</p>

<p>I used <code>vue-cli-service</code> as a wrapper around the build, test, and lint actions, as recommended by Vue. But I found it hard to configure and debug. When I had an issue with tests not properly compiling an imported module, <a href="https://github.com/arxanas/smashtraining/blame/d0c31a33ab880e8c58824c0f58247c8bd8f38485/src/utils.ts#L38-L44">I gave up and reimplemented the function I needed myself</a>.</p>

<h3 id="typescript">TypeScript</h3>

<p>I also used <a href="https://www.typescriptlang.org/">TypeScript</a>, since I find its static typing system useful for maintenance purposes.</p>

<p>TypeScript support for Vue was not ideal. Many Vue patterns are not easy to express in TypeScript. Libraries like <a href="https://github.com/istrib/vuex-typescript"><code>vuex-typescript</code></a> exist, but require a lot of boilerplate in order to get static typing support. The <a href="https://github.com/paroi-tech/direct-vuex"><code>direct-vuex</code></a> library had less boilerplate, but <a href="https://github.com/arxanas/smashtraining/commit/9a8c0c0baf05d048a564b11f62afdfafc9f66a62">I couldn’t figure out how to test it</a>.</p>

<p>TypeScript was generally pleasant to work with, although in the project, I pushed it to its extremes and it was unable to keep pace. In my case, it was unable to track associated/mapped types adequately. It’s perhaps exemplified by this <code>@ts-ignore</code> comment:</p>

<div><div><pre><code><span>export</span> <span>type</span> <span>TechVariantOf</span><span>&lt;</span><span>T</span> <span>extends</span> <span>TechId</span><span>&gt;</span> <span>=</span> <span>{</span>
  <span>// @ts-ignore "Type 'x' cannot be used to index type 'AllTechVariants'."</span>
  <span>// Strangely, the correct type is calculated here anyways, and can be used for</span>
  <span>// exhaustiveness-checking later.</span>
  <span>[</span><span>x</span> <span>in</span> <span>keyof</span> <span>AllTechMetadata</span><span>[</span><span>T</span><span>][</span><span>"</span><span>variants</span><span>"</span><span>]]:</span> <span>AllTechVariants</span><span>[</span><span>x</span><span>];</span>
<span>};</span>
</code></pre></div></div>

<p>I also ran into <a href="https://github.com/microsoft/TypeScript/issues/13215#issuecomment-531632919">this issue</a> when working on the same thing.</p>

<p>Given that this is reasonably advanced type-level hackery, I was generally happy with TypeScript’s ability to describe the data domain.</p>

<h3 id="vue">Vue</h3>

<p>I chose to use <a href="https://vuejs.org/">Vue</a> as the front-end web framework, since I had heard good things about it from <a href="https://news.ycombinator.com/">Hacker News</a>. In particular, I wanted an opinionated framework, so as to spend less time configuring things myself.</p>

<p>When I used it, Vue promoted the <a href="https://vuejs.org/v2/guide/single-file-components.html">“single-file component”</a> system, in which HTML, CSS, and Javascript are mixed into the same file. It was not a great experience:</p>

<ul>
  <li>This complicates the build process, as something has to convert these single-file components into assets consumable by the browser.</li>
  <li>The mental model is an extra layer of indirection, as these single-file components are themselves compiled into Javascript classes, but also contain Javascript classes in the script portion of the file.</li>
  <li>The tooling support was poor. For example, go-to-definition doesn’t work on the HTML components, despite the fact that they’re ultimately backed by Javascript classes.</li>
  <li>TypeScript does not check the HTML components.</li>
</ul>

<p>I would have preferred to use a <a href="https://www.typescriptlang.org/docs/handbook/jsx.html">JSX</a> solution, as it removes some of the indirection and has better tooling support.</p>

<p>I wish Vue had fewer ways to do things. For example, attributes on HTML elements can be set with the normal <code>=</code> syntax, but also with a leading <code>:</code> (expression evaluation) or a leading <code>@</code> (callback) for brevity. In comparison, React with JSX only has <code>=</code> for all of these situations.</p>

<h3 id="vuetify">Vuetify</h3>

<p><a href="https://vuetifyjs.com/">Vuetify</a> is a library to provide Material Design UI for Vue. The presence of a solid, all-in-one Material Design library was one other reason why I chose to use Vue. The library and documentation are both very good, and I was able to prototype my app (from a UI perspective) effectively. I would strongly recommend it if you’re using Vue.</p>

<p><a href="https://github.com/vuetifyjs/vuetify/pull/8877">I opened one pull request</a> for the documentation, which was merged promptly, <a href="https://github.com/vuetifyjs/vuetify/issues/10140">and +1’d one documentation issue</a>, which has a workaround but unfortunately remains unresolved.</p>

<h3 id="netlify-for-hosting">Netlify for hosting</h3>

<p>I used <a href="https://www.netlify.com/">Netlify</a> to host the front-end of the website using its free tier, and stored data locally for the user. This worked well, as Netlify knew how to build and deploy my Vue project, and had good Github integrations.</p>

<p>Another option would have been Github Pages, which would have made the project dependent on fewer underlying services, but also would have required me to write a build step of my own.</p>

<h3 id="custom-database">Custom database</h3>

<p>I stored data locally on the client using the <a href="https://developer.mozilla.org/docs/Web/API/Window/localStorage"><code>localStorage</code> APIs</a>. I was careful to design the data schema such that it was append-only and such that each record had a unique ID, the idea being to make it easy to merge changes from multiple clients. However, this alone makes it difficult to delete records without some more thought.</p>

<p>I later discovered <a href="https://couchdb.apache.org/">CouchDB</a> as a distributed document-store in exactly the manner I had already architected my application, but including sync and delete capabilities. I also discovered the <a href="https://pouchdb.com/">PouchDB</a> library, which exposes a CouchDB interface and allows you to store your data locally or sync it remotely. It also supports more backends than just <code>localStorage</code>.</p>

<p>I wish I had used PouchDB from the beginning! Now I’m stuck with an inefficient, feature-lacking implementation of it, which would …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://waleedkhan.name/blog/smash-training-retrospective/">https://waleedkhan.name/blog/smash-training-retrospective/</a></em></p>]]>
            </description>
            <link>https://waleedkhan.name/blog/smash-training-retrospective/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25387356</guid>
            <pubDate>Fri, 11 Dec 2020 16:14:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Delight, a free hosted cross-platform Spark UI and Spark History Server]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25387036">thread link</a>) | @jstephan
<br/>
December 11, 2020 | https://www.datamechanics.co/blog-post/were-releasing-a-free-cross-platform-spark-ui-and-spark-history-server | <a href="https://web.archive.org/web/*/https://www.datamechanics.co/blog-post/were-releasing-a-free-cross-platform-spark-ui-and-spark-history-server">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><div><p>Data Mechanics is a cloud-based Spark platform - an alternative to Databricks, EMR, Dataproc, Azure HDInsight, and so forth - with a focus on making Spark easy-to-use and cost-effective for data engineers. It is deployed on a Kubernetes cluster inside our customers’ cloud account, and adds a lot of <a href="https://www.datamechanics.co/blog-post/spark-on-kubernetes-made-easy-how-data-mechanics-improves-on-spark-on-k8s-open-source" target="_blank">features on top of Spark on Kubernetes open source</a>.&nbsp;<br></p><p>But today, we’re not talking about a new feature of our platform.&nbsp;<br></p><p>Today we’re releasing a web-based Spark UI which works on top of any Spark platform, whether it’s on-premise or in the cloud, over Kubernetes or over YARN, with a commercial service or running on open-source Apache Spark.</p><figure id="w-node-88b9c15563c8-19fe54b3"><p><img src="https://uploads-ssl.webflow.com/5e72486289a61e0d8c9dbb56/5fb28b0e04eb4b7fc26fca43_Free%20Hosted%20Spark%20History%20Server.png" loading="lazy" alt=""></p></figure><p>It consists of a dashboard listing your Spark applications after they have finished running, and a hosted Spark History Server that will back the Spark UI for this application at the click of a button. This project is partially open-sourced, and it is entirely free of charge.</p><h2>How Can I Use it?<br></h2><h3>Create an account on <a href="https://delight.datamechanics.co/login" target="_blank">https://delight.datamechanics.co/login</a>.</h3><p>You should use your company’s Google account if you want to share a single dashboard with your colleagues, or your personal Google account if you want the dashboard to be private to you. As of today, you need a Google account to access our dashboard, but additional sign-in methods will be added in the future. Once your account is created, go under Settings and create a personal access token. This will be needed in the next step.<br></p><h3>Attach our open-source agent to your Spark applications.</h3><p>Follow the instructions on our <a href="https://github.com/datamechanics/delight" target="_blank">Github page.</a> We have instructions available for the most common setups of Spark, with instructions for generic spark-submit, and instructions specific to Databricks, EMR, Dataproc, and <a href="https://www.datamechanics.co/apache-spark-on-kubernetes">Spark on Kubernetes</a> using the Spark operator. If you run into an issue, <a href="https://www.datamechanics.co/contact" target="_blank">ask us a question</a>, we’ll be happy to help.</p><figure id="w-node-371025b2e346-19fe54b3"><p><img src="https://uploads-ssl.webflow.com/5e72486289a61e0d8c9dbb56/5fb28c47df3884aa76c86847_Spark%20History%20Server%20%26%20Spark%20UI%20-%20Delight%20Dashboard.png" loading="lazy" alt=""></p></figure><p>Your applications will automatically appear on our dashboard once they complete (successfully or with a failure). Clicking on an application opens up the corresponding Spark UI. That’s it!</p><h2>How Does It Work? Is It Secure?</h2><p>This project consists of two parts:</p><ul role="list"><li>An <a href="https://github.com/datamechanics/delight" target="_blank">open-source</a> Spark agent which runs inside your Spark applications. This agent will stream non-sensitive Spark event logs from your Spark application to our backend.</li><li>A closed-source backend consisting of a real-time logs ingestion pipeline, storage services, a web application, and an authentication layer to make this secure.<br></li></ul><figure id="w-node-6a6ad7bcf1a5-19fe54b3"><p><img src="https://uploads-ssl.webflow.com/5e72486289a61e0d8c9dbb56/5fb2b739e125da142c5bbf46_ezgif.com-gif-maker.png" loading="lazy" alt=""></p></figure><p>The agent collects your Spark applications event logs. This is non-sensitive information about the metadata of your Spark application. For example, for each Spark task there is metadata on memory usage, CPU usage, network traffic (<a href="https://uploads-ssl.webflow.com/5e724862760345325327026c/5fc104251c29738912ed5a94_Sample%20Event%20Log%20Delight.png" target="_blank">view a sample event log</a>). The agent does not record sensitive information such as the data that your Spark applications actually work on. The agent does not collect your application logs either -- as typically they may contain sensitive information.<br></p><p>This data is encrypted using your personal access token and sent over the internet using the HTTPS protocol. This information is then stored securely inside the Data Mechanics control plane behind an authentication layer. Only you and your colleagues from your Google/GSuite organization will be able to see your application in our dashboard. The collected data will automatically be deleted 30 days after your Spark application completion.&nbsp;</p><h2>What’s Next?</h2><p>The release of this free and cross-platform hosted Spark History Server is our first step towards building a Spark UI replacement tool called <a href="https://www.datamechanics.co/delight" target="_blank">Data Mechanics Delight</a>. This will be a free and cross-platform Spark UI replacement with new metrics and visualizations that will "delight" you! Our announcement in June 2020 to build a Spark UI replacement had indeed generated a <a href="https://www.datamechanics.co/blog-post/building-a-better-spark-ui-data-mechanics-delight" target="_blank">lot of interest</a> from the Spark community. We’re targeting the next release for January 2021.</p><figure><p><img src="https://uploads-ssl.webflow.com/5e72486289a61e0d8c9dbb56/5ef23be7c40e3df997a03146_gif4.gif" loading="lazy" alt=""></p></figure><p>We know the current release is far from what Delight fans expect, but we hope it will still be valuable to the Spark community, as the Spark History Server is not always easy to set up. More importantly, the current release means we have built most of the base infrastructure of the project -- the Spark agent, a real-time logs collection pipeline, a storage system, an authentication layer and a webapp. We will now gradually add the new screens and visualizations that the community awaits.<br></p><p>The next release of Delight, scheduled in January 2021, will consist of an overview screen giving a bird’s-eye view of your applications’ performance. Links to specific jobs, stages or executor pages will still take you to the corresponding Spark UI pages until we gradually replace these pages too. If you’d like to be notified when the next release is out, <a href="https://www.datamechanics.co/delight#form" target="_blank">fill out this form</a>.&nbsp;<br></p><p>Our mission at Data Mechanics is to make Spark easier-to-use and more cost-effective for data engineering workloads. We hope this tool will contribute to this goal and prove useful to the Spark community. We’d love your feedback about it!<br></p></div></div></div></div></div><div><div data-w-id="5a5714fb-90d7-002f-5fdc-7fabecb251ba"><h4>Read more</h4><h4>Our Latest Blog Posts<br></h4><p>Learn about company news, product updates, and technology best practices straight from the Data Mechanics engineering team.</p></div><div><div><div role="list"><div role="listitem"><div><a href="https://www.datamechanics.co/blog-post/data-ai-summit-europe-2020-highlights"></a><a href="https://www.datamechanics.co/blog-post/data-ai-summit-europe-2020-highlights"></a><p>Data + AI Summit 2020 Highlights: What’s new for the Apache Spark community? In this article we’ll go over the highlights of the conference, focusing on the new developments which were recently added to Apache Spark or are coming up in the coming months: Spark on Kubernetes, Koalas, Project Zen.</p><p>Tuesday, November 24, 2020</p></div></div><div role="listitem"><div><a href="https://www.datamechanics.co/blog-post/were-releasing-a-free-cross-platform-spark-ui-and-spark-history-server" aria-current="page"></a><a href="https://www.datamechanics.co/blog-post/were-releasing-a-free-cross-platform-spark-ui-and-spark-history-server" aria-current="page"></a><p>Today we’re releasing a web-based Spark UI and Spark History Server which work on top of any Spark platform, whether it’s on-premise or in the cloud, over Kubernetes or YARN, with a commercial service or using open-source Apache Spark. This is our first step towards building Data Mechanics Delight - the new and improved Spark UI.</p><p>Monday, November 16, 2020</p></div></div><div role="listitem"><div><a href="https://www.datamechanics.co/blog-post/spark-on-kubernetes-made-easy-how-data-mechanics-improves-on-spark-on-k8s-open-source"></a><a href="https://www.datamechanics.co/blog-post/spark-on-kubernetes-made-easy-how-data-mechanics-improves-on-spark-on-k8s-open-source"></a><p>How Is Data Mechanics different than running Spark on Kubernetes open-source? In this article, we explain how our platform extends and improves on Spark on Kubernetes to make it easy-to-use, flexible, and cost-effective. We'll go over our intuitive user interfaces, dynamic optimizations, and custom integrations</p><p>Tuesday, November 10, 2020</p></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.datamechanics.co/blog-post/were-releasing-a-free-cross-platform-spark-ui-and-spark-history-server</link>
            <guid isPermaLink="false">hacker-news-small-sites-25387036</guid>
            <pubDate>Fri, 11 Dec 2020 15:50:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kubectl Create Pizza]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25387011">thread link</a>) | @cirowrc
<br/>
December 11, 2020 | https://ops.tips/notes/kubernetes-pizza/ | <a href="https://web.archive.org/web/*/https://ops.tips/notes/kubernetes-pizza/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <section itemprop="articleBody">
    <p>Hey,</p>
<p>I recently created a series of articles and videos that goes through the
development of Kubernetes custom resources and controllers (see
<a href="https://gum.co/kubernetes-crds">gum.co/kubernetes-crds</a>), but I missed that
nice catchy example that would showcase what custom resources are all about.</p>
<p>So, why not implement the ultimate missing feature that Kubernetes should have?</p>
<p><img width="300px" src="https://user-images.githubusercontent.com/3574444/101922101-b81fe600-3b9b-11eb-95a3-9a5f2a067997.JPG"></p>
<p><em>tl;dr: see <a href="https://github.com/cirocosta/pizza-controller">https://github.com/cirocosta/pizza-controller</a></em></p>
<h2 id="usage">usage</h2>
<p>First, create a secret with the credit card information (<em>yeah, this is fine,
trust me</em>) to be used during payment:</p>
<div><pre><code data-lang="yaml"><span>kind</span><span>:</span><span> </span><span>Secret</span><span>
</span><span></span><span>apiVersion</span><span>:</span><span> </span><span>v1</span><span>
</span><span></span><span>metadata</span><span>:</span><span>
</span><span>  </span><span>name</span><span>:</span><span> </span><span>credit-card</span><span>
</span><span></span><span>stringData</span><span>:</span><span>
</span><span>  </span><span>number</span><span>:</span><span> </span><span>123343132314232</span><span>
</span><span>  </span><span>expiration</span><span>:</span><span> </span><span>12</span><span>/02</span><span>
</span><span>  </span><span>securityCode</span><span>:</span><span> </span><span>123</span><span>
</span><span>  </span><span>zip</span><span>:</span><span> </span><span>m5d0l2</span><span>
</span></code></pre></div><p>then, create a <code>PizzaCustomer</code>, the representation of <em>you</em>, the customer:</p>
<div><pre><code data-lang="yaml"><span>kind</span><span>:</span><span> </span><span>PizzaCustomer</span><span>
</span><span></span><span>apiVersion</span><span>:</span><span> </span><span>ops.tips/v1alpha1</span><span>
</span><span></span><span>metadata</span><span>:</span><span>
</span><span>  </span><span>name</span><span>:</span><span> </span><span>you</span><span>
</span><span></span><span>spec</span><span>:</span><span>
</span><span>  </span><span>firstName</span><span>:</span><span> </span><span>barack</span><span>
</span><span>  </span><span>lastName</span><span>:</span><span> </span><span>obama</span><span>
</span><span>  </span><span>email</span><span>:</span><span> </span><span>obama@gov.gov</span><span>
</span><span>  </span><span>phone</span><span>:</span><span> </span><span>"31241323"</span><span>
</span><span>  </span><span>streetNumber</span><span>:</span><span> </span><span>"20"</span><span>
</span><span>  </span><span>streetName</span><span>:</span><span> </span><span>King St</span><span>
</span><span>  </span><span>city</span><span>:</span><span> </span><span>Toronto</span><span>
</span><span>  </span><span>state</span><span>:</span><span> </span><span>"ON"</span><span>
</span><span>  </span><span>zip</span><span>:</span><span> </span><span>m5lz8j</span><span>
</span></code></pre></div><p>With the <code>PizzaCustomer</code> object created, we can see what’s the closest store available
for it:</p>
<pre><code data-lang="console">$ kubectl get pizzacustomer

NAME              CLOSEST
you               store-123
</code></pre><p>Looking at the PizzaStore object, we can check out its menu:</p>
<pre><code data-lang="console">$ kubectl get pizzastore store-123 -o yaml

kind: PizzaStore
metadata:
  name: store-123
spec:
  address: |
    51 Niagara St
    Toronto, ON M5V1C3
  id: "10391"
  phone: 416-364-3939
  products:
    - description: Unique Lymon (lemon-lime) flavor, clear, clean and crisp with no caffeine.
      id: 2LSPRITE
      name: Sprite
      size: 2 Litre
</code></pre><p>Knowing what’s available to us, we can place the order:</p>
<div><pre><code data-lang="yaml"><span>kind</span><span>:</span><span> </span><span>PizzaOrder</span><span>
</span><span></span><span>apiVersion</span><span>:</span><span> </span><span>ops.tips/v1</span><span>
</span><span></span><span>metadata</span><span>:</span><span>
</span><span>  </span><span>name</span><span>:</span><span> </span><span>ma-pizza</span><span>
</span><span></span><span>spec</span><span>:</span><span>
</span><span>  </span><span>yeahSurePlaceThisOrder</span><span>:</span><span> </span><span>true</span><span>  </span><span># otherwise, it'll just calculate the price</span><span>
</span><span>  </span><span>storeRef</span><span>:</span><span> </span>{<span>name</span><span>:</span><span> </span><span>store-123}</span><span>
</span><span>  </span><span>customerRef</span><span>:</span><span> </span>{<span>name</span><span>:</span><span> </span><span>you}</span><span>
</span><span>  </span><span>payment</span><span>:</span><span>
</span><span>    </span><span>creditCardSecretRef</span><span>:</span><span> </span>{<span>name</span><span>:</span><span> </span><span>cc}</span><span>
</span><span>  </span><span>items</span><span>:</span><span>
</span><span>    </span>- <span>ticker</span><span>:</span><span> </span><span>10SCREEN</span><span>
</span><span>      </span><span>quantity</span><span>:</span><span> </span><span>1</span><span>
</span></code></pre></div><p>To keep track of what’s going on with your pizza, check out the order’s status:</p>
<pre><code data-lang="console">$ kubectl get pizzaorder ma-pizza

NAME    PRICE      ID                     CONDITION     AGE
order   9.030000   Wlz6HcE6BPlfQNlxDAXa   OrderPlaced   68m
</code></pre><p>and, there we go!</p>
<p><img width="300px" src="https://user-images.githubusercontent.com/3574444/101922114-bb1ad680-3b9b-11eb-8850-5fca08598d2d.JPG"></p>
<h2 id="wait-but-why">wait, but why?</h2>
<p>no no, wait, <strong>why not</strong>?</p>
<p>see, with CI/CD being part of Kubernetes through projects like Argo and Tekton,
where you declare what your pipeline/workflow will be in terms of Kubernetes
resources, we’re now able to get that nice pizza for the team after a
successfull release.</p>
<pre><code>apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: release-
spec:
  entrypoint: pi-tmpl
  templates:
  - name: main
    steps:
      - - name: unit-tests
          template: test
        - name: integration-tests
          template: test
          arguments:
            parameters:
              - name: type
                value: integration
      - - name: release
          template: release
      - - name: get-that-pizza
          template: order-pizza

  - name: order-pizza
    resource:
      action: create      
      manifest: |
        kind: PizzaOrder
        apiVersion: ops.tips/v1
        metadata:
          name: ma-pizza
        spec:
          yeahSurePlaceThisOrder: true
          storeRef: {name: store-123}
          customerRef: {name: you}
          payment:
            creditCardSecretRef: {name: cc}
          items:
            - ticker: 10SCREEN
              quantity: 2
</code></pre><p>i don’t know about you, but that sounds quite right to me <code>¯\_(ツ)_/¯</code></p>
<h2 id="installation">installation</h2>
<p>being a legit Kubernetes custom resource, you install it just like you would
install Tekton, kpack, or anything like that: you submit a manifest that
contains the <code>CustomResourceDefinition</code> objects to Kubernetes, a <code>Deployment</code>
that materializes the controller as a container in a pod, and then … that’s
it!</p>
<pre><code>git clone https://github.com/cirocosta/pizza-controller
cd pizza-controller

kapp deploy -a pizza-controller -f ./config/release.yaml


# OR .. plain old kubectl
#
kubectl apply -f ./config/release.yaml
</code></pre><h2 id="but-thats-dumb">but, that’s dumb</h2>
<p>i disagree</p>
<p>I think it’s a pretty cool example of the concepts behind extending
kubernetes via custom resources, and something that might bring you some
thoughts of ways in which you could bring the
declarative nature of Kubernetes objects plus the level-triggered approach to
controllers to bring to Kubernetes the ability to request external resources.</p>
<p>for instance, projects like <a href="https://crossplane.io/">crossplane</a> give you pretty
much that, except that instead of ordering a pizza, you’re ordering … a
database (or things like that).</p>
<h2 id="whats-next">what’s next?</h2>
<p>are you <em>really</em> into ordering pizza using <code>kubectl</code>?</p>
<p>like, really? are you sure?</p>
<p>here’s what’s missing:</p>
<ul>
<li>well, any .. tests :horse:</li>
<li>order tracking (it’s <code>xml</code>-based - SOAP stuff)</li>
<li>being more flexible with non-canadian folks (it’s currently hardcoded for
Canada, but could easily be changed)</li>
</ul>
<p>at the moment I got my pizza .. development finished :sweat_smile: maybe you’ll
carry it forward? head to <a href="https://github.com/cirocosta/pizza-controller">https://github.com/cirocosta/pizza-controller</a></p>
<h2 id="want-to-know-more">want to know more?</h2>
<p>check out <a href="https://gum.co/kubernetes-crds">https://gum.co/kubernetes-crds</a></p>

  </section>
</article></div>]]>
            </description>
            <link>https://ops.tips/notes/kubernetes-pizza/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25387011</guid>
            <pubDate>Fri, 11 Dec 2020 15:48:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I got to $9.99 MRR after 7 years]]>
            </title>
            <description>
<![CDATA[
Score 252 | Comments 104 (<a href="https://news.ycombinator.com/item?id=25386872">thread link</a>) | @louisbarclay
<br/>
December 11, 2020 | https://cloak.ist/blog/how-i-got-to-9-99-mrr-after-7-years/ | <a href="https://web.archive.org/web/*/https://cloak.ist/blog/how-i-got-to-9-99-mrr-after-7-years/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>It's been a really long ride at <a href="http://cloak.ist/">Cloakist</a>.</p><p>I've been through the highest highs, and the lowest lows.</p><p>But now, looking back on it all, with $9.99 coming into my bank account every month <em>just like clockwork</em>, I can definitively say:</p><p>It's all been worth it.</p><p>Here is the story of how I managed to turn 7 years of my life into cold, hard cash.</p><p>And not just any amount of cash.</p><p>$9.99 so far.</p><h2 id="you-can-t-succeed-without-starting">You can't succeed without starting</h2><p>7 years ago, I was just another incredibly privileged highly-skilled software developer whose parents can support him indefinitely meaning he doesn't have to get a proper job and can risk it all on starting a business, even though his Uncle Les offered him a good, stable living as a junior accountant at his firm, as his mum never goddamn stops reminding him.</p><p>Today, I am the CEO of a successful startup.</p><p>How did I get there?</p><p>It's simple.</p><p>I started.</p><p>One day, I woke up and navigated to <a href="https://godaddy.com/">GoDaddy.com</a>.</p><p>You might not have heard of it if you aren't a software developer.</p><p>It's a place you go to buy startup websites.</p><p>It's really that simple. You think of a name, and then you go there and type it in.</p><p>In <em>seconds, </em>you'll have results showing you whether your name is available.</p><p>For me, it took a few tries to get it right. I started off trying <code>business.com</code> Â&nbsp;because I wanted my business to have a name that made it clear that it was a business.</p><p>But it was already taken.</p><p>So I moved onto <code>company.com</code>. That was taken too.</p><p>Eventually I landed on https://cloak.ist.</p><p>The journey had started.</p><h2 id="the-long-hard-slog">The long hard slog</h2><p>But boy, it was one hell of a journey.</p><p>This is where another key startup concept comes in:</p><p><em>The pivot.</em></p><p>I wasn't always banking hot, fresh Benjamins from selling custom domains as a service, like I do now.</p><p>I went through 365 different products <em>a year</em> before I settled on custom domains.</p><p>You might be thinking 'Huh, strange â€“ that's the exact number of days in a year'.</p><p>You've hit the nail on the head. Cloakist started off by offering NCaaS.</p><p>Neighborhood-Chores-as-a-service.</p><p>They say you should start with a problem that you see in real life.</p><p>Well, in my mum's neighborhood, I saw hundreds of problems.</p><p>And there were people willing to pay for <em>all of them!</em></p><p>There was Mr Baxter, whose toilet got blocked by his cat. That was a particularly hard pivot to make.</p><p>There were many, many clients in the plus-age category who needed ambulatory assistance with regards to pedestrian activity.</p><p>In other words, they needed help crossing the road.</p><p>And there was teaching coding to the kids at the local primary school, until the bullying became too much for me to handle.</p><p>But here's why none of those NCaaS offerings could ever have worked:</p><p><em>I wasn't getting recurring revenue.</em></p><p>None of my customers came back for a second time.</p><p>It wasn't anything to do with me. I know this because my mum told me so. It was that the products I was offering weren't sticky enough.</p><p>I wanted â€“ I <em>craved â€“ </em>my Stripe account filling up with money every month <em>without me even having to do anything!</em></p><h2 id="sometimes-your-customer-is-right-under-your-nose">Sometimes your customer is right under your nose</h2><p>I still remember how it happened.</p><p>I had spent another night cranking on code in my mum's basement.</p><p>I came up to get some orange juice from the fridge.</p><p>A shoe came hurtling through the air at my computer, which fell and smashed on the ground. I lost all my code, because for 7 whole years I'd never figured out a way to back it up.</p><p>"You lazy, no-good piece of crap!"</p><p>My mum was angry.</p><p>I'd never <em>seen </em>her this angry.</p><p>I knew something had to change. And I got this twinkle in my eye.</p><p>"Mum, do you need a custom domain for one of your public sites like Notion, Trello, Airtable, or anything else?"</p><p>I'd found my first customer.</p><h2 id="the-negotiation">The negotiation</h2><p>But boy, did she fight me on it.</p><p>I started off asking for $100 a month, to try and recoup some of the costs of working for nothing for 7 years.</p><p>My mum wasn't having it. She didn't understand what a custom domain was, and she didn't understand what a public site was.</p><p>That severely limited the amount she was willing to pay for my solution.</p><p>I offered $50/m. She said no.</p><p>I offered $20/m. She went to take out the trash. And when she came back, she still said no.</p><p>Finally, I offered $10/m. And...</p><p>She said $9.99.</p><p>And I said...</p><p>"HELL YES!"</p><p>We both started crying.</p><p>Me, out of joy.</p><p>Her, I think out of sadness for what I am and what I've become.</p><p>But still â€“ it was raw, unfettered emotion.</p><p>The MRR had started to pour in.</p><p>And who cares if it's tied to other conditions, like me moving out and promising to think again about Uncle Les's accounting firm.</p><p>MRR is MRR. It's as simple as that.</p><h2 id="it-doesn-t-stop-there">It doesn't stop there</h2><p>The crazy thing about where I've got to now is how much momentum I'm feeling.</p><p>Next month, if all goes well, it's looking like I'll have $19.98 in my bank account.</p><p>The month after that, $29.97.</p><p>Because that's how momentum works.</p><p>Once you get it started, it just keeps going on its own.</p><p>Here's to the next 7 years!</p><hr><p>Thank you so much for reading.</p><p>Give yourself a congratulations: you've just completed Startup Lesson 101: How To Succeed.</p><p>If you'd like to enrol in further classes, feel free to <a href="https://twitter.com/louisbarclay">follow me on Twitter</a>.</p><p>And if you'd like to read a true, but much more boring story about getting MRR, go <a href="https://cloak.ist/blog/how-we-got-to-400-mrr-in-5-months/">here</a>.</p>
</div></div>]]>
            </description>
            <link>https://cloak.ist/blog/how-i-got-to-9-99-mrr-after-7-years/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25386872</guid>
            <pubDate>Fri, 11 Dec 2020 15:36:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Implementing Rust's dbg! in Python]]>
            </title>
            <description>
<![CDATA[
Score 113 | Comments 44 (<a href="https://news.ycombinator.com/item?id=25386358">thread link</a>) | @soopurman
<br/>
December 11, 2020 | https://rtpg.co/2020/12/11/dbg-in-python.html | <a href="https://web.archive.org/web/*/https://rtpg.co/2020/12/11/dbg-in-python.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <p>Rust has an <a href="https://doc.rust-lang.org/edition-guide/rust-next/dbg-macro.html">amazing dbg macro</a> that lets you quickly set up an expression printer that will also put in the source line. It also returns the value of the expression so you can even easily inline the printing when you want to! </p>
<div><pre><span></span><code><span>let</span><span> </span><span>a</span><span> </span><span>=</span><span> </span><span>2</span><span>;</span><span></span>
<span>let</span><span> </span><span>b</span><span> </span><span>=</span><span> </span><span>dbg!</span><span>(</span><span>a</span><span> </span><span>*</span><span> </span><span>2</span><span>)</span><span> </span><span>+</span><span> </span><span>1</span><span>;</span><span></span>
<span>//      ^-- prints: [src/main.rs:2] a * 2 = 4</span>
<span>assert_eq!</span><span>(</span><span>b</span><span>,</span><span> </span><span>5</span><span>);</span><span></span>
</code></pre></div>

<p>Doing a bunch of Python, I <em>want this</em> in Python as well. I want a debug macro, one that gives me the file location + the expression used to calculate the value.</p>
<p>My <em>ideal</em> would be to have a function where <code>dbg(foo.bar[1])</code> that would:</p>
<ul>
<li>print <code>[source line] foo.bar[1] = &lt;the value&gt;</code></li>
<li>return the value so we can use it within expressions easily</li>
</ul>
<p>When doing this by hand I always reach for <code>f</code>-strings, to do something like:</p>
<div><pre><span></span><code><span>print</span><span>(</span><span>f</span><span>"foo.bar[1]=</span><span>{</span><span>foo</span><span>.</span><span>bar</span><span>[</span><span>1</span><span>]</span><span>}</span><span>"</span><span>)</span>
</code></pre></div>

<p>This is annoying because you end up typing the same expression twice, you can't inline it, and it just doesn't look very cool.</p>
<p>The first thing when trying to implement this is to come to terms with Python's lack of macros. You can't really mess with the syntax tree, so you're really only operating on calculated values. So it's really hard to capture an expression <em>and its result</em> in a single operation because, well, your expressions get evaluated.</p>
<p>So it'll be hard, to print <code>some_expr = &lt;result of some_expr&gt;</code> without providing the string of <code>some_expr</code> at one point.</p>
<p><em>However</em>, thanks to <code>eval</code>, you can flip this idea on its head. You <em>need</em> the string for the expression, but you don't need the expression itself!</p>
<div><pre><span></span><code><span>foo</span> <span>=</span> <span>{</span>
    <span>'bar'</span><span>:</span> <span>3</span>
<span>}</span>
<span>print</span><span>(</span><span>eval</span><span>(</span><span>"foo['bar'[]"</span><span>))</span> <span># prints 3</span>
</code></pre></div>

<p>One step backwards, let's now go two steps forward. We can start writing our <code>dbg</code> helper function</p>
<div><pre><span></span><code><span>foo</span> <span>=</span> <span>{</span>
    <span>"bar"</span><span>:</span> <span>3</span>
<span>}</span>

<span>def</span> <span>dbg</span><span>(</span><span>expr</span><span>):</span>
    <span>result</span> <span>=</span> <span>eval</span><span>(</span><span>expr</span><span>)</span>
    <span>print</span><span>(</span><span>f</span><span>"</span><span>{</span><span>expr</span><span>}</span><span> = </span><span>{</span><span>result</span><span>}</span><span>"</span><span>)</span>

<span>dbg</span><span>(</span><span>"foo['bar']"</span><span>)</span>  <span># foo['bar'] = 3</span>
</code></pre></div>

<p>So far so good, we have a nice pretty printer here at the cost of two quotation marks.</p>
<p>Of course this doesn't work perfectly:</p>
<div><pre><span></span><code><span>expr</span> <span>=</span> <span>5</span>
<span>dbg</span><span>(</span><span>"expr"</span><span>)</span> <span># expr = expr</span>
</code></pre></div>

<p>Turns out that when calling <code>eval</code> without arguments we are evaluating <em>within the scope of <code>dbg</code></em>. Our examples work because <code>dbg</code> is defined alongside our expressions (so <code>foo</code> is accessible within <code>dbg</code>) but it's susceptible to name shadowing or outright not being able to calculate the expression because it could be defined in a different scope</p>
<div><pre><span></span><code><span>def</span> <span>dbg</span><span>(</span><span>expr</span><span>):</span>
    <span># we're calculating the result here....</span>
    <span>result</span> <span>=</span> <span>eval</span><span>(</span><span>expr</span><span>)</span>
    <span>print</span><span>(</span><span>f</span><span>"</span><span>{</span><span>expr</span><span>}</span><span> = </span><span>{</span><span>result</span><span>}</span><span>"</span><span>)</span>

<span># but actually want to calculate</span>
<span># the result within this scope</span>
<span>dbg</span><span>(</span><span>"expr"</span><span>)</span>
</code></pre></div>

<p><code>eval</code> by default will evaluate the expression within the current frame. But we can pass in our own globals and locals to instead evaluate the expression within an arbitrary environment</p>
<div><pre><span></span><code><span>x</span> <span>=</span> <span>3</span>
<span>print</span><span>(</span><span>eval</span><span>(</span><span>"x"</span><span>,</span> <span>{</span><span>"x"</span><span>:</span> <span>4</span><span>}))</span> <span># gives 4</span>
</code></pre></div>

<p>So let's reproduce the caller's environment to get us the right results. Enter <a href="https://docs.python.org/3/library/inspect.html"><code>inspect</code></a>:</p>
<blockquote>
<p>There are four main kinds of services provided by this module: type checking, <em>getting source code</em>, inspecting classes and functions, and <em>examining the interpreter stack</em>.</p>
</blockquote>
<p>Let's try out <code>inspect.stack()</code></p>
<div><pre><span></span><code><span>import</span> <span>inspect</span>

<span>def</span> <span>dbg</span><span>(</span><span>expr</span><span>):</span>
    <span>print</span><span>(</span><span>inspect</span><span>.</span><span>stack</span><span>()[</span><span>0</span><span>]</span><span>.</span><span>code_context</span><span>)</span>
    <span>result</span> <span>=</span> <span>eval</span><span>(</span><span>expr</span><span>)</span>
    <span>print</span><span>(</span><span>f</span><span>"</span><span>{</span><span>expr</span><span>}</span><span> = </span><span>{</span><span>result</span><span>}</span><span>"</span><span>)</span>
    <span>return</span> <span>result</span>

<span>dbg</span><span>(</span><span>"foo['bar']"</span><span>)</span>

<span>expr</span> <span>=</span> <span>5</span>

<span>dbg</span><span>(</span><span>"expr"</span><span>)</span>

<span>if</span> <span>dbg</span><span>(</span><span>"True"</span><span>):</span>
    <span>print</span><span>(</span><span>"Passed"</span><span>)</span>
</code></pre></div>

<p>trying this out, we get the following:</p>
<div><pre><span></span><code><span>[</span><span>'    print(inspect.stack()[0].code_context)</span><span>\n</span><span>'</span><span>]</span>
<span>foo</span><span>[</span><span>'bar'</span><span>]</span> <span>=</span> <span>3</span>
<span>[</span><span>'    print(inspect.stack()[0].code_context)</span><span>\n</span><span>'</span><span>]</span>
<span>expr</span> <span>=</span> <span>expr</span>
<span>[</span><span>'    print(inspect.stack()[0].code_context)</span><span>\n</span><span>'</span><span>]</span>
<span>True</span> <span>=</span> <span>True</span>
<span>Passed</span>
</code></pre></div>

<p>Since this is in a function call we'll actually need to go up the stack one frame (<code>inspect.stack()[1]</code>) to get the proper line:</p>
<div><pre><span></span><code><span>[</span><span>'dbg("foo[</span><span>\'</span><span>bar</span><span>\'</span><span>]")</span><span>\n</span><span>'</span><span>]</span>
<span>foo</span><span>[</span><span>'bar'</span><span>]</span> <span>=</span> <span>3</span>
<span>[</span><span>'dbg("expr")</span><span>\n</span><span>'</span><span>]</span>
<span>expr</span> <span>=</span> <span>expr</span>
<span>[</span><span>'if dbg("True"):</span><span>\n</span><span>'</span><span>]</span>
<span>True</span> <span>=</span> <span>True</span>
<span>Passed</span>
</code></pre></div>

<p>OK, now we are getting closer to where we need. the second element in our stack is where we'll also get the file path and the line number. Let's clean this up a bit and now we get:</p>
<div><pre><span></span><code><span>[</span><span>/</span><span>home</span><span>/</span><span>rtpg</span><span>/</span><span>proj</span><span>/</span><span>configfiles</span><span>/</span><span>pyhelpers</span><span>.</span><span>py</span><span>:</span> <span>21</span><span>]</span> <span>foo</span><span>[</span><span>'bar'</span><span>]</span> <span>=</span> <span>3</span>
<span>[</span><span>/</span><span>home</span><span>/</span><span>rtpg</span><span>/</span><span>proj</span><span>/</span><span>configfiles</span><span>/</span><span>pyhelpers</span><span>.</span><span>py</span><span>:</span> <span>25</span><span>]</span> <span>expr</span> <span>=</span> <span>expr</span>
<span>[</span><span>/</span><span>home</span><span>/</span><span>rtpg</span><span>/</span><span>proj</span><span>/</span><span>configfiles</span><span>/</span><span>pyhelpers</span><span>.</span><span>py</span><span>:</span> <span>27</span><span>]</span> <span>True</span> <span>=</span> <span>True</span>
</code></pre></div>

<p>Here we have the full file path... one might do a trick here to stick with the file name:</p>
<div><pre><span></span><code><span>def</span> <span>dbg</span><span>(</span><span>expr</span><span>):</span>
    <span>frame</span> <span>=</span> <span>inspect</span><span>.</span><span>stack</span><span>()[</span><span>1</span><span>]</span><span>.</span><span>frame</span>
    <span>filename</span> <span>=</span> <span>frame</span><span>.</span><span>filename</span><span>.</span><span>split</span><span>(</span><span>"/"</span><span>)[</span><span>-</span><span>1</span><span>]</span>
    <span>print</span><span>(</span><span>f</span><span>"[</span><span>{</span><span>filename</span><span>}</span><span>: </span><span>{</span><span>frame</span><span>.</span><span>lineno</span><span>}</span><span>] </span><span>{</span><span>expr</span><span>}</span><span> = </span><span>{</span><span>result</span><span>}</span><span>"</span><span>)</span>
    <span>return</span> <span>result</span>
</code></pre></div>

<p>OK so with this we end up with the following nice printed output</p>
<div><pre><span></span><code><span>[</span><span>pyhelpers</span><span>.</span><span>py</span><span>:</span> <span>21</span><span>]</span> <span>foo</span><span>[</span><span>'bar'</span><span>]</span> <span>=</span> <span>3</span>
<span>[</span><span>pyhelpers</span><span>.</span><span>py</span><span>:</span> <span>25</span><span>]</span> <span>expr</span> <span>=</span> <span>expr</span>
<span>[</span><span>pyhelpers</span><span>.</span><span>py</span><span>:</span> <span>27</span><span>]</span> <span>True</span> <span>=</span> <span>True</span>
</code></pre></div>

<p>OK so this is good on the formatting. But we still haven't fixed <code>eval</code>! That's a tiny fix this:</p>
<div><pre><span></span><code><span>def</span> <span>dbg</span><span>(</span><span>expr</span><span>):</span>
    <span>frame</span> <span>=</span> <span>inspect</span><span>.</span><span>stack</span><span>()[</span><span>1</span><span>]</span><span>.</span><span>frame</span>
    <span>result</span> <span>=</span> <span>eval</span><span>(</span><span>expr</span><span>,</span> <span>frame</span><span>.</span><span>f_globals</span><span>,</span> <span>frame</span><span>.</span><span>f_locals</span><span>)</span>
    <span>print</span><span>(</span><span>f</span><span>"</span><span>{</span><span>expr</span><span>}</span><span> = </span><span>{</span><span>result</span><span>}</span><span>"</span><span>)</span>
    <span>return</span> <span>result</span>
</code></pre></div>

<p>This gets us the right values, properly evaluating <code>expr</code> from the calling scope instead of <code>dbg</code>:</p>
<div><pre><span></span><code><span>[</span><span>pyhelpers</span><span>.</span><span>py</span><span>:</span> <span>21</span><span>]</span> <span>foo</span><span>[</span><span>'bar'</span><span>]</span> <span>=</span> <span>3</span>
<span>[</span><span>pyhelpers</span><span>.</span><span>py</span><span>:</span> <span>25</span><span>]</span> <span>expr</span> <span>=</span> <span>5</span> 
<span>[</span><span>pyhelpers</span><span>.</span><span>py</span><span>:</span> <span>27</span><span>]</span> <span>True</span> <span>=</span> <span>True</span>
</code></pre></div>

<p>The <code>f_globals</code> and <code>f_locals</code> on the frames is still one of my favorite Python features. It lets basically anyone write very good debugging tools without having to do a bunch of magic.</p>
<p>As an added bonus, if you're an IPython user you can add this to <a href="https://switowski.com/blog/ipython-startup-files">a startup script</a>  over in <code>~/.ipython/profile_default/</code> and make this available in any interactive shell.</p>
<p>For those who value silly things like correctness, performance, and intellectual integrity your journey ends here. This is a nice little helper that you can use in your projects, and there's nothing else for you to see here.</p>
<p>For those who like to live dangerously, I have something to show you.....</p>
<p>



So.</p>
<p>Inside the frame, we have a bunch of information, but one thing that's pretty nice for explorative debugging is the <code>code_context</code></p>
<div><pre><span></span><code><span>print</span><span>(</span><span>frame</span><span>.</span><span>code_context</span><span>[</span><span>0</span><span>])</span>
<span># prints dbg('foo["bar"]')</span>
</code></pre></div>

<p>So we actually have the source line from the <code>dbg</code> call built in!</p>
<p>Let's imagine going back a bit to our "idealized" debug function:</p>


<p>Now, if we ran such a function, the body would receive the <em>value</em> of <code>foo['bar']</code> and not the expression. <em>But</em> thanks to the stack we could theoretically recover the original expression! </p>
<p>This gets a bit tricker if you want to do more clever stuff like:</p>
<div><pre><span></span><code><span>if</span> <span>dbg</span><span>(</span><span>my_func</span><span>(</span><span>3</span><span>,</span> <span>foo</span><span>[</span><span>"bar"</span><span>]</span> <span>+</span> <span>"()"</span><span>)))</span> <span>==</span> <span>5</span><span>:</span>
   <span>do_stuff</span><span>()</span>
</code></pre></div>

<p>But let's try to work this out from first principles a bit.</p>
<p>If you have the source code line with the <code>dbg</code> call, how can you recover the expression being debugged?</p>
<p>The first thing is just to find the beginning of the expression. That's pretty easy, just look for <code>dbg(</code></p>
<div><pre><span></span><code>if dbg(my_func(3, foo["bar"] + "()")) == 5:
   ^^^^
</code></pre></div>

<p>So we find the beginning of the expression, right? And since a function call in Python is an open parentheses, some expressions, then a close parentheses, we just have to find the close parentheses and we have the string fragment representing our expression. Let's apply the logic here:</p>
<div><pre><span></span><code>if dbg(my_func(3, foo["bar"] + "()")) == 5:
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
</code></pre></div>

<p>Great! Our expression is <code>my_func(3, foo["bar"] + "(</code>. Definitely what we wanted. Yep.</p>
<p>This is one of those things where the only way to parse out an expression is to actually parse it out. Simple string matching won't cut it, especially when you start getting inner function calls in the mix.</p>
<p>You could write a simple parser, try and count parens, open quotes, escaping in quotes, all the fun little games. But honestly I want a thing that works, and I don't want to think about it too hard.</p>
<p>I just want to find out where the expression is in this string.</p>
<p>So here's my amazing plan to deal with this:</p>
<div><pre><span></span><code><span>ast</span><span>.</span><span>parse</span><span>(</span><span>'my_func(3, foo["bar"] + "()")) == 5:'</span><span>)</span>
<span># fails</span>
<span>ast</span><span>.</span><span>parse</span><span>(</span><span>'my_func(3, foo["bar"] + "()")) == 5'</span><span>)</span>
<span># fails</span>
<span>ast</span><span>.</span><span>parse</span><span>(</span><span>'my_func(3, foo["bar"] + "()")) == '</span><span>)</span>
<span># fails</span>
<span>...</span>
<span>ast</span><span>.</span><span>parse</span><span>(</span><span>'my_func(3, foo["bar"] + "()")'</span><span>)</span>
<span># doesn't fail =&gt; I have my expression!</span>
</code></pre></div>

<p>I just start with the longest possible string, and slowly shrink it until I find something that looks like an expression. Because the <code>)</code> from the debug call imbalances everything I'm like... 80% sure that this way of finding the expression is correct.</p>
<p>There are some edge cases that make this strategy not work. For example if you do something like:</p>


<p>You have two <code>dbg</code>s on the same line, so it's hard to know <em>which</em> call you're in, because you're only provided the line number. (On some other project I spent a lot of time hand-wringing on this exact problem and could not find a solution, even with tricks like counting executions. I'm fairly convinced this is equivalent to the halting problem somehow)</p>
<p>And to be honest my solution here isn't battle-tested, it just feels right and works with the complicated expressions I've thrown at it. But it was a fun thing to write and now the following works:</p>
<div><pre><span></span><code><span>dbg</span><span>(</span><span>foo</span><span>[</span><span>"bar"</span><span>])</span>
<span># [pyhelpers.py: 49] foo["bar"] = 3</span>

<span>if</span> <span>dbg</span><span>(</span><span>my_func</span><span>(</span><span>3</span><span>,</span> <span>foo</span><span>[</span><span>"bar"</span><span>]</span> <span>+</span> <span>"()"</span><span>))</span> <span>==</span> <span>5</span><span>:</span>
<span># [pyhelpers.py: 52] my_func(3, foo["bar"] + "()") = 5</span>
    <span>print</span><span>(</span><span>"Success"</span><span>)</span>
</code></pre></div>

<p>No more stringifying silliness, no more calls to <code>eval</code>, just a really silly parsing hack that has no real foundation except my gut feeling. </p>
<p>Good enough for me!</p>
<p>the final implemetaion is below:</p>
<div><pre><span></span><code><span>def</span> <span>dbg</span><span>(</span><span>result</span><span>):</span>
    <span>"""</span>
<span>    Recover the expression giving the result, and then</span>
<span>    print a helpful debug statement showing this</span>
<span>    """</span>
    <span>frame</span> <span>=</span> <span>inspect</span><span>.</span><span>stack</span><span>()[</span><span>1</span><span>]</span>
    <span>expr</span> <span>=</span> <span>extract_dbg</span><span>(</span><span>frame</span><span>.</span><span>code_context</span><span>[</span><span>0</span><span>])</span>
    <span>filename</span> <span>=</span> <span>frame</span><span>.</span><span>filename</span><span>.</span><span>split</span><span>(</span><span>"/"</span><span>)[</span><span>-</span><span>1</span><span>]</span>
    <span>print</span><span>(</span><span>f</span><span>"[</span><span>{</span><span>filename</span><span>}</span><span>: </span><span>{</span><span>frame</span><span>.</span><span>lineno</span><span>}</span><span>] </span><span>{</span><span>expr</span><span>}</span><span> = </span><span>{</span><span>result</span><span>}</span><span>"</span><span>)</span>
    <span>return</span> <span>result</span>

<span>def</span> <span>extract_dbg</span><span>(</span><span>code_fragment</span><span>):</span>
    <span># from a line of source text, try and find the expression </span>
    <span># given to a call to dbg</span>
    <span>expression_options</span> <span>=</span> <span>code_fragment</span><span>.</span><span>split</span><span>(</span><span>"dbg("</span><span>)</span>
    <span>if</span> <span>len</span><span>(</span><span>expression_options</span><span>)</span> <span>!=</span> <span>2</span><span>:</span>
        <span># if there are either multiple dbg statements</span>
        <span># or I can't find the dbg line, bail</span>
        <span>return</span> <span>"???"</span>
    <span># get the part to the right of dbg(</span>
    <span>expr_candidate</span> <span>=</span> <span>expression_options</span><span>[</span><span>1</span><span>]</span>
    <span>while</span> <span>expr_candidate</span><span>:</span>
        <span>try</span><span>:</span>
            <span>ast</span><span>.</span><span>parse</span><span>(</span><span>expr_candidate</span><span>)</span>
            <span>return</span> <span>expr_candidate</span>
        <span>except</span> <span>SyntaxError</span><span>:</span>
            <span>expr_candidate</span> <span>=</span> <span>expr_candidate</span><span>[:</span><span>-</span><span>1</span><span>]</span>
    <span># …</span></code></pre></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rtpg.co/2020/12/11/dbg-in-python.html">https://rtpg.co/2020/12/11/dbg-in-python.html</a></em></p>]]>
            </description>
            <link>https://rtpg.co/2020/12/11/dbg-in-python.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25386358</guid>
            <pubDate>Fri, 11 Dec 2020 14:47:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rugpullindex.com, the first decentralized dataset index in the world]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25385834">thread link</a>) | @timdaub
<br/>
December 11, 2020 | https://timdaub.github.io/2020/12/11/rugpullindex/ | <a href="https://web.archive.org/web/*/https://timdaub.github.io/2020/12/11/rugpullindex/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <h2 id="tldr">TL;DR</h2>
<p><strong>TL;DR:</strong> I built a financial index that <strong>rates data sets</strong> by their markets' performance (<strong>liquidity</strong> and <strong>equality of liquidity shares</strong>). <strong>Check out the <a target="_blank" rel="noopener" href="https://rugpullindex.com/">website</a></strong> and the minimalistic <a target="_blank" rel="noopener" href="https://rugpullindex.com/changelog.txt">blog</a>, or keep on reading the article.</p>
<p><img src="https://timdaub.github.io/assets/images/rugpullindex.png" alt="A screenshot of the
rugpullindex.com website"></p>
<h2 id="why-building-a-data-set-index">Why Building a Data Set Index?</h2>
<p><strong>Would you pay a stranger on the internet</strong> to buy a data set their offering without knowing them or ever having seen the data? Tough decision! But that's precisely the type of situation <a target="_blank" rel="noopener" href="https://oceanprotocol.com/">Ocean Protocol</a> users face in its newly-launched decentralized <a target="_blank" rel="noopener" href="https://market.oceanprotocol.com/">data set market</a> [3].</p>
<p>I'll spare you most of the details of how it all works and say this: 2020's most transforming technology has been <strong>on-chain markets</strong>. In particular, the implementation that <a target="_blank" rel="noopener" href="https://uniswap.org/">uniswap.org</a> is using called <strong>automated market makers</strong>.</p>
<p>Simply put, they work by incentivizing users to <em>pool</em> a pair of assets at a ratio they deem as the assets' current prices. These users, I herein call them <strong>liquidity providers</strong>, e.g., pool 1 ETH and 540 USDC, so that when a buyer of either asset comes along, they can immediately trade 1 ETH for 540 USDC or 540 USDC for 1 ETH. This principle works fantastically at scale, as the pool incentivizes liquidity-providing by charging buyers and sellers a small fee, which is distributed by the pool to each liquidity provider, respectively [1].</p>
<p><img src="https://timdaub.github.io/assets/images/marketmakers.png"></p>
<p>This model has been so successful that there've been days where decentralized trading on Uniswap outperformed volumes on Coinbase! Which, of course, has lots of implications on the cryptocurrency space. I think it's no overstatement to say that automated market makers may be <strong>the killer app for crypto</strong>.</p>

<p>But there's one implication I've been particularly keen on exploring: all <strong>the openly-accessible data produced by on-chain markets</strong>. See, if you ever tried building a trading bot, you'll have noticed the terrible resolution publicly-available market data has. You might have also noticed that it's quite difficult even to find data at all. It's not by accident. <strong>Trading data is valuable</strong>.</p>
<h2 id="rating-a-data-set-by-its-markets-performance">Rating a Data Set by its Market's Performance</h2>
<p>Remember when I asked you at the beginning of this article about <strong>buying a data set from a random stranger on the internet?</strong> Well, it turns out that Ocean Protocol is now betting on the same technology that made Uniswap successful. They allow users to publish a data set, along with a fungible <strong>data token</strong> and an integrated <strong>automated market maker</strong>. Meaning, you can now buy access to a data set by purchasing tokens. These tokens get priced by liquidity providers providing a ratio of OCEAN Tokens to <em>data tokens</em>.</p>
<p>However, just because data sets are now available for sale on the market, doesn't mean you know they're valuable! After all, if ebay.com didn't have a rating system for sellers, how would you know which seller to trust?</p>
<p>On ebay.com, you know which seller to trust because you can see how many articles they've sold and what each buyer's experience was. It's a simple identity-based rating system.</p>
<p>But within the anarchistic world of cryptocurrencies, there are no working identity-based rating systems! Instead, the space is filled with <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Sock_puppet_account">sock puppets</a> and <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Sybil_attack">sybils</a>. <strong>Then, without buying a data set first, how are we supposed to know if a data set is valuable or an outright scam?</strong></p>
<h2 id="introducing-rugpullindex.com">Introducing rugpullindex.com</h2>
<p>That's where <a target="_blank" rel="noopener" href="https://rugpullindex.com/">rugpullindex.com</a> comes into play. <strong>We crawl all of Ocean Protocol's data token pools daily</strong> and rate each market's liquidity provider distribution by its equality using the <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Gini_coefficient">Gini coefficient</a>. While ranking markets based on their liquidity is common industry-practice, calculating a Gini score for each market's liquidity provider shares isn't. The idea behind this is that the more liquidity providers with an equal share back an asset in the market, the less likely it is for a "rug pull" attack to happen (details <a target="_blank" rel="noopener" href="https://github.com/oceanprotocol/multi-repo-issue/issues/30#issuecomment-726132174">here</a>). By factoring in a pool's relative liquidity, it allows us to derive a score <span><span><math><semantics><mrow><mi>s</mi></mrow><annotation encoding="application/x-tex">s</annotation></semantics></math></span></span> that is <span><span><math><semantics><mrow><mn>0</mn><mo>&lt;</mo><mi>s</mi><mo>&lt;</mo><mn>100</mn></mrow><annotation encoding="application/x-tex">0 &lt; s &lt; 100</annotation></semantics></math></span></span>.</p>
<p>For users of <a target="_blank" rel="noopener" href="https://rugpullindex.com/">rugpullindex.com</a>, this <strong>yields a few attractive benefits</strong>:</p>
<ol type="1">
<li>They can now choose to adjust their data set investments based on market data.</li>
<li>They can decide to invest in data sets relative to their performance on to <em>increase their diversivication and hence lower their exposure risk</em>. And finally;</li>
<li>If they're unsure about <strong>sending a random stranger on the internet money for a data set</strong>, they can check out the data set's market performance to make an informed decision.</li>
</ol>
<p>It's a widely-known fact that index-based investment yields superior results compared to stock picking [2]. The same is true when <em>investing</em> in data, which makes me excited about working on this project.</p>
<h2 id="what-does-the-future-hold">What Does The Future Hold?</h2>
<p>I have many ideas for <a target="_blank" rel="noopener" href="https://rugpullindex.com/">rugpullindex.com</a> and not as much time as I'd like to have. However, my overarching goal is to make the ranking so reliable that I can build a smart contract-based index fund on top of it.</p>
<p>I think that rating assets based on their markets' performance is valuable occupation in itself. Not only within the data set market but beyond. I'm particularly interested in rating a wide range of on-chain asset markets, but I'm also thinking about rating more on-chain intellectual property markets. I'm eager to crawl more data and explore. Until then, I hope you're having fun using <a target="_blank" rel="noopener" href="https://rugpullindex.com/">rugpullindex.com</a>.</p>
<p><em><strong>If you have questions, feedback, or business inquiries, please contact me: tim@daubenschuetz.de</strong>. If you want to follow along by building journey, <strong>please subscribe to my newsletter at the end of the page!</strong></em></p>
<h2 id="references">References</h2>
<ul>
<li>1: <a target="_blank" rel="noopener" href="https://ethresear.ch/t/improving-front-running-resistance-of-x-y-k-market-makers/1281">Ethresearch: Improving front running resistance of x*y=k market makers</a></li>
<li>2: KAHNEMAN, Daniel. Thinking, fast and slow. Macmillan, 2011.</li>
<li>3: <a target="_blank" rel="noopener" href="https://blog.oceanprotocol.com/oceans-on-ethereum-mainnet-ba9be1aee0ce">Ocean’s on Ethereum Mainnet</a></li>
</ul>

  </div></div>]]>
            </description>
            <link>https://timdaub.github.io/2020/12/11/rugpullindex/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25385834</guid>
            <pubDate>Fri, 11 Dec 2020 14:03:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nietzsche on Truth and Lie (1991)]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 10 (<a href="https://news.ycombinator.com/item?id=25385213">thread link</a>) | @chordalkeyboard
<br/>
December 11, 2020 | http://rickroderick.org/202-nietzsche-on-truth-and-lie-1991/ | <a href="https://web.archive.org/web/*/http://rickroderick.org/202-nietzsche-on-truth-and-lie-1991/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Last updated: 04 November 2020</p>
<p><strong>Download: </strong><a href="http://rickroderick.org/download/1991%20Nietzsche%20and%20the%20Post-Modern%20Condition/2%20-%20Nietzsche%20on%20Truth%20and%20Lie.mov">Nietzsche and the Post-Modern Condition (1991) Lecture 2: Nietzsche on Truth and Lie.mov</a></p>

<p><strong>Transcript: </strong>Lecture two will attempt to answer one of the paradoxes I raised in the first lecture – and this will be a specific form of it – and that’s a rather famous charge in philosophy. In fact this is the charge of relativism and one of the things that professional philosophers do in order to display their professional credentials is to respond to the relativist and to the sceptic. Nietzsche has been accused of being a relativist. One form of this accusation is a kind of mislabelling – in my opinion it’s a mislabelling – of Nietzsche’s view about the function of truth and lie. He opposes that to true and false. Truth and lie. The function of that within philosophical discourse. He has an account of that we are going to discuss. <span id="more-53"></span></p>
<p>One of the ways that philosophers have mislabelled this position is “perspectivism”, and the reason I hate that label is like “relativism”, it makes someone think that someone – in this case Nietzsche, or someone else – might hold the absolutely ridiculous view that every view was as good as every other view. That is a complete straw person argument. No-one has ever – or does now – hold the view that every view is as good as every other view.</p>
<p>So whenever the spectre of relativism is raised, you know, by someone for you, either in the popular press or in a university setting, the first small thing that should come to your mind is there aren’t any. So the refutation in a certain sense is bound to miss at least one point, namely that you are not arguing against anyone. Now it could be the case that my audience today, or the audience that will watch the tapes, I will find someone in the United States, or across the world that will hold the view that every other view is as good as every other view. But if I do, it will be very idiosyncratic, and in my experience so far, no.</p>
<p>Nietzsche is not a relativist, and I think perspectivism is also an unfortunate term to describe Nietzsche’s style of thinking. Because perspectivism calls up the idea that, “Well, I am right from my perspective, and you are right from your perspective, and everybody is right from their perspectives”, and I also don’t believe that that’s a view that anyone can hold or has ever held. I think, and this is the the way I will try to discuss Nietzsche’s paradox in terms of relativism, is that…</p>
<p>Nietzsche was opposed to what might be called the dogmatism of not only the Western Philosophical tradition, but the Western Theoretical tradition in general. Its dogmatism in this regard. Believing… about its beliefs that they were good not only for them and their tribe… because after all Western Civilisation is a big word… it’s a strange word… you know, big words and strange words, but, after all it is just a very large tribe with very large armies and lots of televisions… and a large historical project, but still its a tribe. Big, big tribe.</p>
<p>I think Nietzsche considered it dogmatic to hold that your beliefs – or the beliefs of your tribe – were binding on all. That is the way I want to present Nietzsche’s perspectivism. In other words, he didn’t believe that all beliefs were equally good, interesting, or whatever. In fact, I am sure he considered some of his own beliefs to be far more interesting than for example, the beliefs of John Stuart Mill, who he referred to as “That blockhead”. Or I think that he found his views more interesting than the views of the English Utilitarians in general, about whom he said “No human beings want to be happy. Only the British want that”. [crowd laughter]. So I think he thinks his views were more interesting than those.</p>
<p>And I think where the dogmatism for Nietzsche came in was when you search for views… and then develop your beliefs, and then think that they should be binding on all. This is not a criticism that you shouldn’t have beliefs, or that all your beliefs are no better than anyone else’s. It’s just the further belief about your beliefs that everyone else should believe the same damn way. So it’s a meta-belief, if you will. A belief about your beliefs.</p>
<p>In fact I think that it’s perfectly consistent to believe a wide number of things with a great deal of passion, and then believe about those beliefs that you could be wrong. I hope that’s not a further paradox, I do not think that it is. It seems to me to be perfectly consistent to believe something passionately, to believe it in a very deep way and have a belief about that belief that “Well, you know. I could be wrong.”</p>
<p>So the dogmatism that Nietzsche is after runs very deep in our theoretical traditions. I can’t overestimate this. It’s a dogmatism that has continued throughout what might be called the project of the West, and it’s even built into the Socratic pursuit. When Socrates asks the question “What is X?”, and what fills in the “X” are those famous Greek ideals; virtue, excellence, beauty, goodness, and so on. Now Nietzsche had the highest respect for Socrates, and as I just said, as I said before, Nietzsche considered him to be an <a href="http://dictionary.reference.com/browse/exemplary" onclick="_gaq.push(['_trackEvent', 'outbound-article', 'http://dictionary.reference.com/browse/exemplary', 'exemplary']);">exemplary</a> person, coupled with Plato’s construction of him, they in a way were ideal for Nietzsche.</p>
<p>But the dogmatic part of Socrates was that Socrates wanted – for Nietzsche – Socrates wanted an answer to the question “What is X”, like what is beauty, goodness, truth, excellence. It wouldn’t be good for just Socrates, or good for the Greeks, but once discovered had to bind everyone. In other words, it wouldn’t be enough just to believe it, which seems… what Nietzsche calls the gay, happy theorist to be enough, to just find a belief that you can live with and believe. No, the theoretical enterprise of the West is imperialistic in a way. It’s got to find a belief that others then have to believe, and that he considered dogmatic.</p>
<p>This by the way you may notice is not – in my view – a relativist position at all. Because it’s not inconsistent with the view that you think your beliefs – precisely because they are your beliefs – are superior to some other beliefs. In fact I take it to be banally the case that if you didn’t think that, they wouldn’t be your beliefs. In other words, somebody comes up to you and gives you some other ones and you go “Oh hell, those are better than mine”. Then they will be yours after you have heard them out, right? So it seems fairly natural that you believe your beliefs. The dogmatic assumption is that everyone else should believe your beliefs. And this is not relativism. There have been some modern philosophical names attached to this position called <a href="https://en.wikipedia.org/wiki/Fallibilism" onclick="_gaq.push(['_trackEvent', 'outbound-article', 'https://en.wikipedia.org/wiki/Fallibilism', 'fallibilism']);">fallibilism</a>, and yet Nietzsche is too interesting in a certain way to be called that either.</p>
<p>In other words, I want to present Nietzsche not specifically within that philosophical context, but I do want to present him as addressing it, which he does. And anyone who has ever addressed any issue in philosophy knows that the irritating thing is how the simplest questions can turn into philosophical ones. Sometimes philosophers realise that what we do is ask a series of rhetorical questions that come up whenever people are very frustrated. In other words, we ask questions like “What the hell does that mean?”. You know, generally in a fight – a domestic fight – a rhetorical question. “I can’t do the dishes now” – “Well what the hell does that mean?”. Well, the philosopher takes that rhetorical question and just places it in a foreign context. Someone goes “There’s an object” and you go “Object… what the hell does that mean?” [crowd laughter]. In the other context, the remark had a home and a meaning, and so it means that the person’s <em>pissed</em>, I guess. Or <em>upset</em>, okay. In this other context though, “What does it – you know – does it mean?” doesn’t seem to have any purchase.</p>
<p>About those, sort of, metaphysical beliefs, Nietzsche was no metaphysician. In fact, he thought that was, in a way, a very pompous thing to be. To try to answer those kinds of questions in a way binding for all. Now I call that a kind of <em>imperialism</em>, and I didn’t use that political term without thinking about it for a while. It’s the kind of imperialism – this dogmatic tradition against which Socrates saw himself fighting – is the kind of imperialist tradition we might have in some of our educational institutions when we have an African-American student who speaks eloquent rap street language talk. And I am not trying to say that’s all that African-Americans speak. Some of them are Neo-Conservatives that garble around as bad as others. Paleo-Conservatives. You know, some are just as unfortunately stupid as their Anglo-American, or Anglo-Saxon counterparts.</p>
<p>No, but I mean I am talking now about, you know, someone who does… says “ain’t” and repeats themselves, rhymes and things. Well, in a way it’s just imperialistic to think that that is somehow less profound than the Cambridge accent that discusses in detail the problem of relativism. It is not only a class and a racial bias, it’s just stupid. Because, as <a href="http://en.wikipedia.org/wiki/William_James" onclick="_gaq.push(['_trackEvent', 'outbound-article', 'http://en.wikipedia.org/wiki/William_James', 'William James']);">William James</a> once said “The trail of the human serpent is over all”. There are many forms of life, many cultures, many ways to look at things. And Nietzsche at his best expresses in his work that diversity and that complexity of the many ways to interpret, to speak.</p>
<p>Now, “imperialistic” in this educational sense means that we want you to leave our institutions of higher learning talking like we talk and writing like we write. And we divide through by the issue of whether you think at all, because all the evidence we have for that is what you have said and what you have written. You may be not thinking at all, or thinking very bizarre thoughts, or you may be on some hallucinogenic drug, who knows what’s inside. But if you leave there writing like we write, talking like we talk – in short obeying relations of power – then you are educated. You certainly… and certainly Nietzsche saw this as conformity, and not connected with truth.</p>
<p>So …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://rickroderick.org/202-nietzsche-on-truth-and-lie-1991/">http://rickroderick.org/202-nietzsche-on-truth-and-lie-1991/</a></em></p>]]>
            </description>
            <link>http://rickroderick.org/202-nietzsche-on-truth-and-lie-1991/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25385213</guid>
            <pubDate>Fri, 11 Dec 2020 12:59:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DIY Dynamic DNS with Netlify API and Bash]]>
            </title>
            <description>
<![CDATA[
Score 41 | Comments 14 (<a href="https://news.ycombinator.com/item?id=25384968">thread link</a>) | @krustymeathead
<br/>
December 11, 2020 | https://blog.skylerlewis.io/2020/12/diy-dynamic-dns-using-netlify-api.html | <a href="https://web.archive.org/web/*/https://blog.skylerlewis.io/2020/12/diy-dynamic-dns-using-netlify-api.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-606233900384767253">
<p>I don't really need to send many calls back to my network at my house when I am away, but when I want to show someone the progress we are making on the family Minecraft Christmas village, it is nice to be able to call to a <a href="https://github.com/miclav/mapcrafter/tree/world116">Mapcrafter</a> server at my house.</p><table><tbody><tr><td><a href="https://1.bp.blogspot.com/-X1eJAH2v7Wg/X9AD2Ct3cjI/AAAAAAAARVQ/o29jbVBMlLAWv1UAhF_DMsEsYiyKj052wCLcBGAsYHQ/s2048/christmas_village.png"><img data-original-height="1200" data-original-width="2048" height="376" src="https://1.bp.blogspot.com/-X1eJAH2v7Wg/X9AD2Ct3cjI/AAAAAAAARVQ/o29jbVBMlLAWv1UAhF_DMsEsYiyKj052wCLcBGAsYHQ/w640-h376/christmas_village.png" title="The Family Minecraft Christmas Village" width="640"></a></td></tr><tr><td>This is the current family Minecraft Christmas Village. The image is generated by Mapcrafter&nbsp;using <a href="https://github.com/skylerwlewis/realms-mapcrafter-renderer">this group</a> of Bash scripts.</td></tr></tbody></table><p>Now I don't have a business internet line at my house, so my IP can change theoretically at any time. I have looked at a&nbsp;<a href="https://www.noip.com/">few</a> <a href="https://dyndnss.net/eng/">services</a> offering Dynamic DNS, however, some didn't fit my needs. Also they all cost money, and my preference would be to not spend any money if I don't have to.</p><p>I found some projects on Github that communicate with the <a href="https://open-api.netlify.com/#tag/dnsZone">Netlify API</a> using an access token to update the domain entry dynamically, however, I had issues with the <a href="https://github.com/lytedev/netlify-ddns">projects</a> <a href="https://github.com/oscartbeaumont/netlify-dynamic-dns">I</a> <a href="https://github.com/lukehsiao/netlify-ddns-rs">tried</a>. I wanted to stick to apt for installing software, I didn't want to install Docker, and some of the domain updates were leaving duplicates domain entries. Since I've been playing with my Plex Media Server, I've been on a Bash script kick, so I figured I would try to create a Bash script for this I could run through cron.</p><p>The main tool for this job, other than Bash and the Netlify API, is <a href="https://stedolan.github.io/jq/">jq</a>. It is a lightweight command-line tool for handling everything JSON-related. This script requires jq is installed, but shouldn't have any other dependencies. If you try it out, let me know what you think.</p>

</div></div>]]>
            </description>
            <link>https://blog.skylerlewis.io/2020/12/diy-dynamic-dns-using-netlify-api.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25384968</guid>
            <pubDate>Fri, 11 Dec 2020 12:25:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Journey with Elixir and Flow-Based Programming]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25384954">thread link</a>) | @allanmacgregor
<br/>
December 11, 2020 | https://preslav.me/2020/12/10/elixir-community-voices-allan-macgregor/ | <a href="https://web.archive.org/web/*/https://preslav.me/2020/12/10/elixir-community-voices-allan-macgregor/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div id="post-body"><p><em>I first met Allan over a Zoom call about a week ago. I have been following <a href="https://allanmacgregor.com/">his blog</a> for some time and wanted to know more about his book draft about design patterns in Elixir. It wasn't until the call itself that I found out how many ideas we share - about the future of Elixir, its role as an alternative to present-day distributed solutions, and last but not least, its potential for the next generation of e-commerce solutions. </em></p><h2 id="who-are-you">Who are you?</h2><p><strong>Allan:</strong> I'm a software engineer with 15 years of experience, based in Toronto, Ontario. I was born and grew up in Mexico, and over the last 11 years, I have been able to build a career and life in Canada.</p><p>Most of my professional career has been focused on e-commerce development, which I would say can be broken down into three main categories:</p><ul><li>Building user-facing experiences</li><li>Building e-commerce engines to map the business logic</li><li>Integrations with third-party systems</li></ul><p>Over ten years of e-commerce development, I had the opportunity to work with many notable brands in Canada and the US and solve many challenges in the space. I have also dabbled working with product companies in multiple capacities - from CTO to currently a Senior Engineering Manager at <a href="https://www.humi.ca/" rel="noopener noreferrer">Humi</a>.</p><p>In terms of technologies, I have had a chance to work with many different stacks and programming languages, notably PHP (LAMP), some Ruby on Rails, some Scala during my time at Hopper, and a bit of Elixir to tackle quick prototypes and transparent proxy for an e-commerce project.</p><p>Currently, I'm a Senior Engineering Manager at Humi, a great company in the HR and payroll space. I am also building a couple of micro-SaaS projects - the first one being <a href="https://siteguardian.dev/" rel="noopener noreferrer">SiteGuardian</a>, intended to be a complete solution for website monitoring and security. It should be close to beta release later this month.</p><figure><a href="https://siteguardian.dev/"><div><p>Siteguardian · Better Site Monitoring</p></div><p><img src="https://siteguardian.dev/images/siteguardian_logo-4a1bbe5ed6d4c7832ee675694a7aed47.svg?vsn=d"></p></a></figure><h2 id="what-brought-you-to-elixir">What brought you to Elixir?</h2><p><strong>Allan: </strong>I stumbled into Elixir in a bit of a weird way, going back to one of the problems that I mentioned on the e-commerce space — integration with third-party systems like ERP, OMS, and the like, — for that kind of problems, the idea of <a href="https://jpaulm.github.io/fbp/index.html">Flow-based programming</a> made a lot of sense.</p><p>In essence, you structure your application to be a pipeline of black boxes that transform, filter, or handle the data in some way or another. Looking for implementations of this library, I landed on a library called <a href="https://github.com/antonmi/flowex">FlowEx</a>, which is written in Elixir. As I started diving deeper into the language, I honestly fell in love with it.</p><p>Elixir to me seems like this almost perfect mix of all the right qualities:</p><ul><li>Flexibility and power</li><li>Low Learning curve</li><li>Extensibility</li><li>Expressiveness</li></ul><p>If I had to pinpoint any particular quality of Elixir that caught my attention, it would be the expressiveness of the language - how much you can achieve with very little code.</p><p><strong>Allan: </strong>For me, the biggest challenge was adapting to a new paradigm and getting rid of the "bad" habits I picked up from working with Object-Oriented Languages. It is not the syntax that is different, but how you reason and think about the data flows in your program.</p><p>I guess the other challenging bit, which seems fairly common, was grasping the use of the Enum variable, Map, reduce, and the like. But once those things click, you are off to the races.</p><p>The other challenge that is still somewhat applicable is getting buying for the business or clients to use Elixir as a solution; however, I'm happy to see that it is gaining popularity and is being adopted by larger companies and teams.</p><p><strong>Allan: </strong>First, it is important to clarify what this next generation of e-commerce solutions looks like. We are currently in transition from the traditional catalog/search &gt; product page &gt; shopping cart &gt; checkout experience; and moving into a stage where e-commerce becomes ubiquitous, for example, integrated into an Instagram post or inside content.</p><p>This kind of change will present a couple of interesting challenges, both in terms of scalability / performance and architectures. The current generation of e-commerce platforms is fairly monolithic, or in the case of some of the SaaS offerings, fairly restrictive.</p><p>I can see an interesting future for Elixir and similar technologies to be used to develop the next generation e-commerce platforms and services; this is especially applicable when talking about integrations between OMS, Inventory systems, and Product Information Management systems.</p><p><strong>Allan: </strong>Absolutely! Right now, I'm working on a small SaaS project called <a href="https://siteguardian.dev/">SiteGuardian</a>, which aims to provide a robust solution for website site security and availability monitoring.</p><p>I chose Elixir for this project because first, I wanted to validate some architectural ideas and patterns that I'm researching for a book; and second, the Elixir stack allows me to build robust features and do so very efficiently.</p><p>To me, it is that perfect combination of development speed, robustness, and low operating costs that enables me to build a competitive micro-SaaS. Not to mention that my ability to iterate and build in this stack has been incredible compared to if was doing this in Laravel, or Ruby on Rails.</p><p>The second thing that I have in progress right now is a book on Elixir and design patterns. The idea is to explore and do a deep dive into the multiple variations of architectural and behavioral patterns that are relevant to functional programming and Elixir.</p><p>For anyone interested in the progress of the book, you can subscribe to my newsletter here: <a href="https://allanmacgregor.com/newsletter/">https://allanmacgregor.com/newsletter/</a></p><p><strong>Allan: </strong>For people considering using Elixir / Erlang, my word of advice is to give things time to sink in. Functional programming is likely to be a new idea and paradigm and might take a while to grok the concepts, but once you do, the time invested is going to pay off ten-fold.</p><hr><h2 id="references">References</h2><figure><a href="https://allanmacgregor.com/"><div><p>Hi, I’m Allan, this is where I write. - Allan MacGregor</p><p>Expert Software Engineer and Manager • Writer • Functional Programming Advocate</p><p><span>Allan MacGregor</span></p></div><p><img src="https://allanmacgregor.com/static/logo-white-3bbb2d0ba72789f13cdee16471616911.png"></p></a></figure><figure><a href="https://siteguardian.dev/"><div><p>Siteguardian · Better Site Monitoring</p></div><p><img src="https://siteguardian.dev/images/siteguardian_logo-4a1bbe5ed6d4c7832ee675694a7aed47.svg?vsn=d"></p></a></figure><figure><a href="https://github.com/antonmi/flowex"><div><p>antonmi/flowex</p><p>Flow-Based Programming framework for Elixir. Contribute to antonmi/flowex development by creating an account on GitHub.</p><p><img src="https://github.githubassets.com/favicons/favicon.svg"><span>GitHub</span></p></div><p><img src="https://avatars3.githubusercontent.com/u/835853?s=400&amp;v=4"></p></a></figure><figure><a href="https://jpaulm.github.io/fbp/index.html"><div><p>Flow-based Programming</p><p>Official website for flow-based programming</p><p><img src="https://jpaulm.github.io/fbp/images/favicon.ico"></p></div><p><img src="https://jpaulm.github.io/fbp/bottling_factory.png"></p></a></figure></div>
</div></div>]]>
            </description>
            <link>https://preslav.me/2020/12/10/elixir-community-voices-allan-macgregor/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25384954</guid>
            <pubDate>Fri, 11 Dec 2020 12:23:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Web Crawling with Python]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25384774">thread link</a>) | @daolf
<br/>
December 11, 2020 | https://www.scrapingbee.com/blog/crawling-python/ | <a href="https://web.archive.org/web/*/https://www.scrapingbee.com/blog/crawling-python/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><img src="https://d33wubrfki0l68.cloudfront.net/0ace011709806f528c970a43a82d2905e536aced/0c7a2/images/authors/ari.png" alt="Ari Bajo">
            
            <span>
                
                
                
                <span>
                    <small> ● </small>
                    
                    
                    <span>11 December, 2020</span>
                    
                    <small> ● </small>
                    <span> 13 min read </span>
                </span>
                <p> Ari is an expert Data Engineer and a talented technical writer. He wrote the entire Scrapy integration for ScrapingBee and this awesome article.
                        
                        <a href="https://twitter.com/ari_bajo" target="_blank">
                        <svg style="height: 14px" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512">
                            <path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z" fill="currentColor"></path>
                        </svg>
                        </a>
                        
                        
                    </p>
            </span>
        </p><div property="articleBody">
          





















<div>
  
  <p><img loading="lazy" srcset="
      
        , https://d33wubrfki0l68.cloudfront.net/ec113f2bdce1bd490836cf9b4a48bf623d1038e4/f3edd/blog/crawling-python/python_crawl_huc3299db23da91c71a01641e8130027ed_40687_825x0_resize_catmullrom_2.png 825w
      
      
        , https://d33wubrfki0l68.cloudfront.net/9b928b664ed803937fcd03fd8a1d933dbec2ed21/cb134/blog/crawling-python/python_crawl_huc3299db23da91c71a01641e8130027ed_40687_1200x0_resize_catmullrom_2.png 1200w
      
      " src="https://d33wubrfki0l68.cloudfront.net/5868bb8e66c49ac2ce5428289f43fe12e77f1a59/1f7da/blog/crawling-python/python_crawl.png" width="1200" height="628" alt="Blog post header" data-srcset="
    
      , https://d33wubrfki0l68.cloudfront.net/ec113f2bdce1bd490836cf9b4a48bf623d1038e4/f3edd/blog/crawling-python/python_crawl_huc3299db23da91c71a01641e8130027ed_40687_825x0_resize_catmullrom_2.png 825w
    
    
      , https://d33wubrfki0l68.cloudfront.net/9b928b664ed803937fcd03fd8a1d933dbec2ed21/cb134/blog/crawling-python/python_crawl_huc3299db23da91c71a01641e8130027ed_40687_1200x0_resize_catmullrom_2.png 1200w
    
    " data-src="https://d33wubrfki0l68.cloudfront.net/5868bb8e66c49ac2ce5428289f43fe12e77f1a59/1f7da/blog/crawling-python/python_crawl.png">
  
</p></div>




<p>Web crawling is a powerful technique to collect data from the web by finding all the URLs for one or multiple domains. Python has several popular web crawling libraries and frameworks.</p>
<p>In this article, we will first introduce different crawling strategies and use cases. Then we will build a simple web crawler from scratch in Python using two libraries: requests and Beautiful Soup. Next, we will see why it’s better to use a web crawling framework like Scrapy. Finally, we will build an example crawler with Scrapy to collect film metadata from IMDb and see how Scrapy scales to websites with several million pages.</p>
<h2 id="what-is-a-web-crawler">What is a web crawler?</h2>
<p><a href="https://en.wikipedia.org/wiki/Web_crawler">Web crawling</a> and <a href="https://en.wikipedia.org/wiki/Web_scraping">web scraping</a> are two different but related concepts. Web crawling is a component of web scraping, the crawler logic finds URLs to be processed by the scraper code.</p>
<p>A web crawler starts with a list of URLs to visit, called the seed. For each URL, the crawler finds links in the HTML, filters those links based on some criteria and adds the new links to a queue. All the HTML or some specific information is extracted to be processed by a different pipeline.</p>






















<div>
  
  <p><img loading="lazy" srcset="
      
        , https://d33wubrfki0l68.cloudfront.net/f294e8de9a7fe601fbf262d904c7b669c5b8696f/5e7ba/blog/crawling-python/diagram1_hu304a3bf9eddda4dffec92719eab9431a_277432_825x0_resize_q75_catmullrom.jpg 825w
      
      
        , https://d33wubrfki0l68.cloudfront.net/c5ceb8078645ba6d68e1c456916872c6d6301237/83b29/blog/crawling-python/diagram1_hu304a3bf9eddda4dffec92719eab9431a_277432_1200x0_resize_q75_catmullrom.jpg 1200w
      
      
        , https://d33wubrfki0l68.cloudfront.net/fd2fbb0ec91131c342888def031d4335bbd6755d/dcfcb/blog/crawling-python/diagram1_hu304a3bf9eddda4dffec92719eab9431a_277432_1500x0_resize_q75_catmullrom.jpg 1500w 
      " src="https://d33wubrfki0l68.cloudfront.net/b4162831034444f8813eb39bec97bddc885cfeab/4c624/blog/crawling-python/diagram1.jpg" width="1668" height="2154" alt="Web crawling diagram" data-srcset="
    
      , https://d33wubrfki0l68.cloudfront.net/f294e8de9a7fe601fbf262d904c7b669c5b8696f/5e7ba/blog/crawling-python/diagram1_hu304a3bf9eddda4dffec92719eab9431a_277432_825x0_resize_q75_catmullrom.jpg 825w
    
    
      , https://d33wubrfki0l68.cloudfront.net/c5ceb8078645ba6d68e1c456916872c6d6301237/83b29/blog/crawling-python/diagram1_hu304a3bf9eddda4dffec92719eab9431a_277432_1200x0_resize_q75_catmullrom.jpg 1200w
    
    
      , https://d33wubrfki0l68.cloudfront.net/fd2fbb0ec91131c342888def031d4335bbd6755d/dcfcb/blog/crawling-python/diagram1_hu304a3bf9eddda4dffec92719eab9431a_277432_1500x0_resize_q75_catmullrom.jpg 1500w 
    " data-src="https://d33wubrfki0l68.cloudfront.net/b4162831034444f8813eb39bec97bddc885cfeab/4c624/blog/crawling-python/diagram1.jpg">
  
</p></div>

<br>


<h2 id="web-crawling-strategies">Web crawling strategies</h2>
<p>In practice, web crawlers only visit a subset of pages depending on the crawler budget, which can be a maximum number of pages per domain, depth or execution time.</p>
<p>Most popular websites provide a <a href="https://en.wikipedia.org/wiki/Robots_exclusion_standard">robots.txt</a> file to indicate which areas of the website are disallowed to crawl by each user agent. The opposite of the robots file is the <a href="https://en.wikipedia.org/wiki/Sitemaps">sitemap.xml</a> file, that lists the pages that can be crawled.</p>
<p>Popular web crawler use cases include:</p>
<ul>
<li>Search engines (Googlebot, Bingbot, Yandex Bot…) collect all the HTML for a significant part of the Web. This data is indexed to make it searchable.</li>
<li>SEO analytics tools on top of collecting the HTML also collect metadata like the response time, response status to detect broken pages and the links between different domains to collect backlinks.</li>
<li>Price monitoring tools crawl e-commerce websites to find product pages and extract metadata, notably the price. Product pages are then periodically revisited.</li>
<li>Common Crawl maintains an <a href="https://commoncrawl.org/the-data/get-started/">open repository of web crawl data</a>. For example, the archive from October 2020 contains 2.71 billion web pages.</li>
</ul>
<p>Next, we will compare three different strategies for building a web crawler in Python. First, using only standard libraries, then third party libraries for making HTTP requests and parsing HTML and finally, a web crawling framework.</p>
<h2 id="building-a-simple-web-crawler-in-python-from-scratch">Building a simple web crawler in Python from scratch</h2>
<p>To build a simple web crawler in Python we need at least one library to download the HTML from a URL and an HTML parsing library to extract links. Python provides standard libraries <a href="https://docs.python.org/3.9/library/urllib.html">urllib</a> for making HTTP requests and <a href="https://docs.python.org/3/library/html.parser.html">html.parser</a> for parsing HTML. An example Python crawler built only with standard libraries can be found on <a href="https://github.com/xukai92/crawlerfromscratch/blob/master/spider.py">Github</a>.</p>
<p>The standard Python libraries for requests and HTML parsing are not very developer-friendly. Other popular libraries like <a href="https://requests.readthedocs.io/en/master/">requests</a>, branded as HTTP for humans, and <a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/">Beautiful Soup</a> provide a better developer experience. You can install the two libraries locally. \</p>
<p><code>pip install requests bs4</code></p>
<p>A basic crawler can be built following the previous architecture diagram.</p>
<div><pre><code data-lang="python">



<span>import</span> logging
<span>from</span> urllib.parse <span>import</span> urljoin
<span>import</span> requests
<span>from</span> bs4 <span>import</span> BeautifulSoup

logging<span>.</span>basicConfig(
    format<span>=</span><span></span><span>'</span><span>%(asctime)s</span><span> </span><span>%(levelname)s</span><span>:</span><span>%(message)s</span><span>'</span>,
    level<span>=</span>logging<span>.</span>INFO)

<span>class</span> <span>Crawler</span>:

    <span>def</span> __init__(self, urls<span>=</span>[]):
        self<span>.</span>visited_urls <span>=</span> []
        self<span>.</span>urls_to_visit <span>=</span> urls

    <span>def</span> <span>download_url</span>(self, url):
        <span>return</span> requests<span>.</span>get(url)<span>.</span>text

    <span>def</span> <span>get_linked_urls</span>(self, url, html):
        soup <span>=</span> BeautifulSoup(html, <span></span><span>'</span><span>html.parser</span><span>'</span>)
        <span>for</span> link <span>in</span> soup<span>.</span>find_all(<span></span><span>'</span><span>a</span><span>'</span>):
            path <span>=</span> link<span>.</span>get(<span></span><span>'</span><span>href</span><span>'</span>)
            <span>if</span> path <span>and</span> path<span>.</span>startswith(<span></span><span>'</span><span>/</span><span>'</span>):
                path <span>=</span> urljoin(url, path)
            <span>yield</span> path

    <span>def</span> <span>add_url_to_visit</span>(self, url):
        <span>if</span> url <span>not</span> <span>in</span> self<span>.</span>visited_urls <span>and</span> url <span>not</span> <span>in</span> self<span>.</span>urls_to_visit:
            self<span>.</span>urls_to_visit<span>.</span>append(url)

    <span>def</span> <span>crawl</span>(self, url):
        html <span>=</span> self<span>.</span>download_url(url)
        <span>for</span> url <span>in</span> self<span>.</span>get_linked_urls(url, html):
            self<span>.</span>add_url_to_visit(url)

    <span>def</span> <span>run</span>(self):
        <span>while</span> self<span>.</span>urls_to_visit:
            url <span>=</span> self<span>.</span>urls_to_visit<span>.</span>pop(<span>0</span>)
            logging<span>.</span>info(f<span></span><span>'</span><span>Crawling: {url}</span><span>'</span>)
            <span>try</span>:
                self<span>.</span>crawl(url)
            <span>except</span> <span>Exception</span>:
                logging<span>.</span>exception(f<span></span><span>'</span><span>Failed to crawl: {url}</span><span>'</span>)
            <span>finally</span>:
                self<span>.</span>visited_urls<span>.</span>append(url)

<span>if</span> __name__ <span>==</span> <span></span><span>'</span><span>__main__</span><span>'</span>:
    Crawler(urls<span>=</span>[<span></span><span>'</span><span>https://www.imdb.com/</span><span>'</span>])<span>.</span>run()
</code></pre></div><p>The code above defines a Crawler class with helper methods to download_url using the requests library, get_linked_urls using the Beautiful Soup library and add_url_to_visit to filter URLs. The URLs to visit and the visited URLs are stored in two separate lists. You can run the crawler on your terminal.</p>
<p>python crawler.py</p>
<p>The crawler logs one line for each visited URL.</p>
<div><pre><code data-lang="bash">
2020-12-04 18:10:10,737 INFO:Crawling: https://www.imdb.com/
2020-12-04 18:10:11,599 INFO:Crawling: https://www.imdb.com/?ref_<span>=</span>nv_home
2020-12-04 18:10:12,868 INFO:Crawling: https://www.imdb.com/calendar/?ref_<span>=</span>nv_mv_cal
2020-12-04 18:10:13,526 INFO:Crawling: https://www.imdb.com/list/ls016522954/?ref_<span>=</span>nv_tvv_dvd
2020-12-04 18:10:19,174 INFO:Crawling: https://www.imdb.com/chart/top/?ref_<span>=</span>nv_mv_250
2020-12-04 18:10:20,624 INFO:Crawling: https://www.imdb.com/chart/moviemeter/?ref_<span>=</span>nv_mv_mpm
2020-12-04 18:10:21,556 INFO:Crawling: https://www.imdb.com/feature/genre/?ref_<span>=</span>nv_ch_gr
</code></pre></div><p>The code is very simple but there are many performance and usability issues to solve before successfully crawling a complete website.</p>
<ul>
<li>The crawler is slow and supports no parallelism. As can be seen from the timestamps, it takes about one second to crawl each URL. Each time the crawler makes a request it waits for the request to be resolved and no work is done in between.</li>
<li>The download URL logic has no retry mechanism, the URL queue is not a real queue and not very efficient with a high number of URLs.</li>
<li>The link extraction logic doesn’t support standardizing URLs by removing URL query string parameters, doesn’t handle URLs starting with #, doesn’t support filtering URLs by domain or filtering out requests to static files.</li>
<li>The crawler doesn’t identify itself and ignores the robots.txt file.</li>
</ul>
<p>Next, we will see how Scrapy provides all these functionalities and makes it easy to extend for your custom crawls.</p>
<h2 id="web-crawling-with-scrapy">Web crawling with Scrapy</h2>
<p>Scrapy is the most popular web scraping and crawling Python framework with 40k stars on <a href="https://github.com/scrapy/scrapy">Github</a>. One of the advantages of Scrapy is that requests are scheduled and handled asynchronously. This means that Scrapy can send another request before the previous one is completed or do some other work in between. Scrapy can handle many concurrent requests but can also be configured to respect the websites with custom <a href="https://docs.scrapy.org/en/latest/topics/settings.html">settings</a>, as we’ll see later.</p>
<p>Scrapy has a multi-component architecture. Normally, you will implement at least two different classes: <a href="https://docs.scrapy.org/en/latest/topics/spiders.html">Spider</a> and <a href="https://docs.scrapy.org/en/latest/topics/item-pipeline.html">Pipeline</a>. Web scraping can be thought of as an ETL where you extract data from the web and load it to your own storage. Spiders extract the data and pipelines load it into the storage. Transformation can happen both in spiders and pipelines, but I recommend that you set a custom Scrapy pipeline to transform each item independently of each other. This way, failing to process an item has no effect on other items.</p>
<p>On top of all that, you can add spider and downloader middlewares in between components as it can be seen in the diagram below.</p>






















<div>
  
  <p><img loading="lazy" srcset="
      
        , https://d33wubrfki0l68.cloudfront.net/9ec6172a2d9d57f9d3d935ce7ef9f25878ca9509/4e2cb/blog/crawling-python/image2_hu2c5c023b068fe63956b3eac3483ae818_71063_825x0_resize_catmullrom_2.png 825w
      
      
        , https://d33wubrfki0l68.cloudfront.net/acdcf2034b0684bb719531d883ad3e0879dcc338/dd6fb/blog/crawling-python/image2_hu2c5c023b068fe63956b3eac3483ae818_71063_1200x0_resize_catmullrom_2.png 1200w
      
      " src="https://d33wubrfki0l68.cloudfront.net/76867f9d2c73d7e0def2e2a38a1671bedf2afa1a/fcc2c/blog/crawling-python/image2.png" width="1400" height="940" alt="Scrapy architecture diagram" data-srcset="
    
      , https://d33wubrfki0l68.cloudfront.net/9ec6172a2d9d57f9d3d935ce7ef9f25878ca9509/4e2cb/blog/crawling-python/image2_hu2c5c023b068fe63956b3eac3483ae818_71063_825x0_resize_catmullrom_2.png 825w
    
    
      , https://d33wubrfki0l68.cloudfront.net/acdcf2034b0684bb719531d883ad3e0879dcc338/dd6fb/blog/crawling-python/image2_hu2c5c023b068fe63956b3eac3483ae818_71063_1200x0_resize_catmullrom_2.png 1200w
    
    " data-src="https://d33wubrfki0l68.cloudfront.net/76867f9d2c73d7e0def2e2a38a1671bedf2afa1a/fcc2c/blog/crawling-python/image2.png">
  
</p></div>




<p>Scrapy Architecture Overview [<a href="https://docs.scrapy.org/en/latest/topics/architecture.html#data-flow">source</a>]</p>
<p>If you have used Scrapy before, you know that a web scraper is defined as a class that inherits from the base Spider class and implements a parse method to handle each response. If you are new to Scrapy, you can read this article for <a href="https://www.scrapingbee.com/blog/web-scraping-with-scrapy/">easy scraping with Scrapy</a>.</p>
<div><pre><code data-lang="python"><span>from</span> scrapy.spiders <span>import</span> Spider

<span>class</span> <span>ImdbSpider</span>(Spider):
    name <span>=</span> <span></span><span>'</span><span>imdb</span><span>'</span>
    allowed_domains <span>=</span> [<span></span><span>'</span><span>[www.imdb.com](www.imdb.com)</span><span>'</span>]
    start_urls <span>=</span> [<span></span><span>'</span><span>[https://www.imdb.com/](https://www.imdb.com/)</span><span>'</span>]

<span>def</span> <span>parse</span>(self, response):
    <span>pass</span>
</code></pre></div><p>Scrapy also provides several <a href="https://docs.scrapy.org/en/latest/topics/spiders.html#generic-spiders">generic spider classes</a>: CrawlSpider, XMLFeedSpider, CSVFeedSpider and SitemapSpider. The <a href="https://docs.scrapy.org/en/latest/topics/spiders.html#crawlspider">CrawlSpider</a> class inherits from the base Spider class and provides an extra rules attribute to define how to crawl a website. Each rule uses a <a href="https://docs.scrapy.org/en/latest/topics/link-extractors.html#topics-link-extractors">LinkExtractor</a> to specify which links are extracted from each page. Next, we will see how to use each one of them by building a crawler for IMDb, the Internet Movie Database.</p>
<h2 id="building-an-example-scrapy-crawler-for-imdb">Building an example Scrapy crawler for IMDb</h2>
<p>Before trying to crawl IMDb, I checked <a href="https://www.imdb.com/robots.txt">IMDb robots.txt</a> file to see which URL paths are allowed. The robots file only disallows 26 paths for all user-agents. Scrapy reads the robots.txt file beforehand and respects when the <a href="https://docs.scrapy.org/en/latest/topics/settings.html#robotstxt-obey">ROBOTSTXT_OBEY</a> setting is set to true. This is the case for all projects generated with the Scrapy command startproject.</p>
<p>scrapy startproject scrapy_crawler</p>
<p>This command creates a new project with the default Scrapy project folder structure.</p>
<div><pre><code data-lang="bash">scrapy_crawler/

├── scrapy.cfg
└── scrapy_crawler
    ├── __init__.py
    ├── items.py
    ├── middlewares.py
    ├── pipelines.py
    ├── settings.py
 …</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.scrapingbee.com/blog/crawling-python/">https://www.scrapingbee.com/blog/crawling-python/</a></em></p>]]>
            </description>
            <link>https://www.scrapingbee.com/blog/crawling-python/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25384774</guid>
            <pubDate>Fri, 11 Dec 2020 11:58:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Small Habits Count]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25384459">thread link</a>) | @KlimYadrintsev
<br/>
December 11, 2020 | https://klimy.co/blog/why-small-habits-11-12-2020 | <a href="https://web.archive.org/web/*/https://klimy.co/blog/why-small-habits-11-12-2020">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="blog">
                    <p>My problem in life is that if I am doing something, I tend to try to get the most out of it. That is what people call maximalism.</p>
<p>It has been present in the habits that I tried implementing as well. It has been present in a gym membership. It has been present in learning a new language. Basically, I couldn’t do anything a healthy amount and tried to do as much as I could straight away.</p>
<p>As you might have guessed it, even though in the potential that would allow me to get the most amount of results out of the action, it would also cause me to burn out very fast. Usually so fast, that the first results just started showing when I quit.</p>
<p>After reading <a href="https://jamesclear.com/atomic-habits">James Clear Atomic Habits</a>, I understood that the biggest problem with positive habit-forming is exactly what I have been doing. It said that starting with a hard habit is what will make it less likely to stick. While on the other hand, making a habit small and easy is exactly what would make a habit stick and would allow you to scale it after a period of time potentially.</p>
<p>Going to the gym every day, 7 days a week for one hour was the initial goal I would usually set. Now it's: put running shoes and walk outside of your house for 10 minutes.</p>
<p>Reading 50 books in a year, now became read a page per day.</p>
<p>Learn how to build Facebook. Now is: learn how to make this button blue.</p>
<p>Everything became smaller and much easier to do. The result? I have been in the habit of doing things for more than 3 months, and I would never go back.</p>
<h2>Why Maximalism is not always bad</h2>
<p>The good news for me is that I only have to battle with my inner understanding of the world when I start as long as I have started and the habit in the motion of slowly integrating with my life, I can also start to scale it slowly. That is how I started with everything so far and to be completely honest, I don’t see a reason to do it any other way.</p>
<p>The main issue of why positive habits are so much harder to integrate in comparison to the negative habits is because the rewards and the dopamine hits are postponed to some time in the future. Actually so far, that our short term brain doesn’t see it.</p>
<p>That is why by making a habit easy and maybe even pairing with some positive reward for yourself, would make the habit sticking more likely. </p>
<p>Make sure that what you do is good for you, before putting down the reward. <a href="https://klimy.co/blog/nano-problems-09-12-2020">Don’t reward yourself for doing yourself worse.</a></p>
<h2>Why small habits count</h2>
<p>Even though some habits have stayed for me <a href="https://klimy.co/blog/practice-makes-perfect-30-11-2020">very small</a>, the presence of that small habit in my life has <a href="https://klimy.co/blog/front-page-hn">changed me completely</a>.</p>
<p>I didn’t understand why spending 10 minutes per day doing something can improve me so much, then I remembered James Clear maths example.</p>
<p>1.01^365 = 37.8</p>
<p>Which is crazy to think about, and it turns out it is also true in practice.</p>
<p>Even if you can only do 5 minutes of something per day, don’t postpone it. In a month or even a year, you will look back, and you will be a completely different, better person.</p>
<p>Start now. Get perfect later.</p>
<p>Klim Y</p> 
                    
                </div></div>]]>
            </description>
            <link>https://klimy.co/blog/why-small-habits-11-12-2020</link>
            <guid isPermaLink="false">hacker-news-small-sites-25384459</guid>
            <pubDate>Fri, 11 Dec 2020 11:14:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A practical guide on generating hellishly good ideas]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25384443">thread link</a>) | @paus
<br/>
December 11, 2020 | https://www.sobieckipioneering.com/creativity-guide | <a href="https://web.archive.org/web/*/https://www.sobieckipioneering.com/creativity-guide">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-ix="row-5"><div><div><p>Over 200 business, science and productivity books, studies on the subject.</p><p>My personal experience in theoretical physics and business.<br></p><p>Private discussions with top businessman and scientists - I had an incredible privilege to discuss this issue with billionaires and a Nobel Price laureat.<br></p><p>Methods used by 43 people being at the top of their fields, including<br><em>Elon Musk, Steve Jobs, Bill Gates, Warren Buffett, Richard Branson, Larry Page and Sergey Brin, Sam Walton, Andrew Carnegie, Vincent van Gogh, Pablo Picasso, Leonardo da Vinci, Roger Penrose, Stephen Hawking</em><br></p></div></div></div><div data-ix="row-6"><div><h2>Wide spectrum</h2><p>Our methods are exceptional as they were not only based on how hyper-productive people think and work, but also how the most innovative companies operated to get where they are now. Among them are</p><h2>Why</h2><p>Our business is based on creativity. It required going thorugh historic and presently practiced solutions to build a compendium of creativity.<em> </em></p><p><em>So we did it. </em></p><p>Now we, as a team, decided to share with you the pinnacle - the strategies most consistent in generating results. Working with this methodology we are able to suprisingly frequently help businesses to get onto an exponential growth path and scientists to come up with breakthrough experimets and theories.</p><p>We believe in simplicity. Having that in mind, the process was distilled to a Triple Pareto state - that is to the 1% that can give you half of the results you would be likely to get after years of training. Read our 20 page guide to acquire the proficiency you would expect to get in a half of a 2000 page finest quality manuscript.</p></div></div></div>]]>
            </description>
            <link>https://www.sobieckipioneering.com/creativity-guide</link>
            <guid isPermaLink="false">hacker-news-small-sites-25384443</guid>
            <pubDate>Fri, 11 Dec 2020 11:12:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How the Python object system works]]>
            </title>
            <description>
<![CDATA[
Score 281 | Comments 59 (<a href="https://news.ycombinator.com/item?id=25384433">thread link</a>) | @r4victor
<br/>
December 11, 2020 | https://tenthousandmeters.com/blog/python-behind-the-scenes-6-how-python-object-system-works/ | <a href="https://web.archive.org/web/*/https://tenthousandmeters.com/blog/python-behind-the-scenes-6-how-python-object-system-works/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<!-- /.post-info -->      <p>As we know from the previous parts of this series, the execution of a Python program consists of two major steps:</p>
<ol>
<li><a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-2-how-the-cpython-compiler-works/">The CPython compiler</a> translates Python code to bytecode.</li>
<li><a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-1-how-the-cpython-vm-works/">The CPython VM</a> executes the bytecode.</li>
</ol>
<p>We've been focusing on the second step for quite a while. In <a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-4-how-python-bytecode-is-executed/">part 4</a> we've looked at the evaluation loop, a place where Python bytecode gets executed. And in <a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-5-how-variables-are-implemented-in-cpython/">part 5</a> we've studied how the VM executes the instructions that are used to implement variables. What we haven't covered yet is how the VM actually computes something. We postponed this question because to answer it, we first need to understand how the most fundamental part of the language works. Today, we'll study the Python object system.</p>
<p><strong>Note</strong>: In this post I'm referring to CPython 3.9. Some implementation details will certainly change as CPython evolves. I'll try to keep track of important changes and add update notes.</p>
<h2>Motivation</h2>
<p>Consider an extremely simple piece of Python code:</p>



<p>To compute the function <code>f</code>, CPython must evaluate the expression <code>x + 7</code>. The question I'd like to ask is: How does CPython do that? Special methods such as <code>__add__()</code> and <code>__radd__()</code> probably come to your mind. When we define these methods on a class, the instances of that class can be added using the <code>+</code> operator. So, you might think that CPython does something like this:</p>
<ol>
<li>It calls <code>x.__add__(7)</code> or <code>type(x).__add__(x, 7)</code>.</li>
<li>If <code>x</code> doesn't have <code>__add__()</code>, or if this method fails, it calls <code>(7).__radd__(x)</code> or <code>int.__radd__(7, x)</code>.</li>
</ol>
<p>The reality, tough, is a bit more complicated. What really happens depends on what <code>x</code> is. For example, if <code>x</code> is an instance of a user-defined class, the algorithm described above resembles the truth. If, however, <code>x</code> is an instance of a built-in type, like <code>int</code> or <code>float</code>, CPython doesn't call any special methods at all.</p>
<p>To learn how some Python code is executed, we can do the following:</p>
<ol>
<li>Disassemble the code into bytecode.</li>
<li>Study how the VM executes the disassembled bytecode instructions.</li>
</ol>
<p>Let's apply this algorithm to the function <code>f</code>. The compiler translates the body of this function to the following bytecode:</p>
<div><pre><span></span>$ python -m dis f.py
...
  2           0 LOAD_FAST                0 (x)
              2 LOAD_CONST               1 (7)
              4 BINARY_ADD
              6 RETURN_VALUE
</pre></div>


<p>And here's what these bytecode instructions do:</p>
<ol>
<li><code>LOAD_FAST</code> loads the value of the parameter <code>x</code> onto the stack.</li>
<li><code>LOAD_CONST</code> loads the constant <code>7</code> onto the stack.</li>
<li><code>BINARY_ADD</code> pops two values from the stack, adds them and pushes the result back onto the stack.</li>
<li><code>RETURN_VALUE</code> pops the value from the stack and returns it.</li>
</ol>
<p>How does the VM add two values? To answer this question, we need to understand what these values are. For us, <code>7</code> is an instance of <code>int</code> and <code>x</code> is, well, anything. For the VM, though, everything is a Python object. All values the VM pushes onto the stack and pops from the stack are pointers to <code>PyObject</code> structs (hence the phrase "Everything in Python is an object").</p>
<p>The VM doesn't need to know how to add integers or strings, that is, how to do the arithmetic or concatenate sequences. All it needs to know is that every Python object has a type. A type, in turn, knows everything about its objects. For example, the <code>int</code> type knows how to add integers, and the <code>float</code> type knows how to add floats. So, the VM asks the type to perform the operation.</p>
<p>This simplified explanation captures the essence of the solution, but it also omits a lot of important details. To get a more realistic picture, we need to understand what Python objects and types really are and how they work.</p>
<h2>Python objects and types</h2>
<p>We've discussed Python objects a little in <a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-3-stepping-through-the-cpython-source-code/">part 3</a>. This discussion is worth repeating here.</p>
<p>We begin with the definition of the <code>PyObject</code> struct:</p>
<div><pre><span></span><span>typedef</span> <span>struct</span> <span>_object</span> <span>{</span>
    <span>_PyObject_HEAD_EXTRA</span> <span>// macro, for debugging purposes only</span>
    <span>Py_ssize_t</span> <span>ob_refcnt</span><span>;</span>
    <span>PyTypeObject</span> <span>*</span><span>ob_type</span><span>;</span>
<span>}</span> <span>PyObject</span><span>;</span>
</pre></div>


<p>It has two members:</p>
<ul>
<li>a reference count <code>ob_refcnt</code> that CPython uses for garbage collection; and</li>
<li>a pointer to the object's type <code>ob_type</code>.</li>
</ul>
<p>We said that the VM treats any Python object as <code>PyObject</code>. How is that possible? The C programming language has no notion of classes and inheritance. Nevertheless, it's possible to implement in C something that can be called a single inheritance. The C standard states that a pointer to any struct can be converted to a pointer to its first member and vice versa. So, we can "extend" <code>PyObject</code> by defining a new struct whose first member is <code>PyObject</code>.</p>
<p>Here's, for example, how the <code>float</code> object is defined:</p>
<div><pre><span></span><span>typedef</span> <span>struct</span> <span>{</span>
    <span>PyObject</span> <span>ob_base</span><span>;</span> <span>// expansion of PyObject_HEAD macro</span>
    <span>double</span> <span>ob_fval</span><span>;</span>
<span>}</span> <span>PyFloatObject</span><span>;</span>
</pre></div>


<p>A <code>float</code> object stores everything <code>PyObject</code> stores plus a floating-point value <code>ob_fval</code>. The C standard simply states that we can convert a pointer to <code>PyFloatObject</code> to a pointer to <code>PyObject</code> and vice versa:</p>
<div><pre><span></span><span>PyFloatObject</span> <span>float_object</span><span>;</span>
<span>// ...</span>
<span>PyObject</span> <span>*</span><span>obj_ptr</span> <span>=</span> <span>(</span><span>PyObject</span> <span>*</span><span>)</span><span>&amp;</span><span>float_object</span><span>;</span>
<span>PyFloatObject</span> <span>*</span><span>float_obj_ptr</span> <span>=</span> <span>(</span><span>PyFloatObject</span> <span>*</span><span>)</span><span>obj_ptr</span><span>;</span>
</pre></div>


<p>The reason why the VM treats every Python object as <code>PyObject</code> is because all it needs to access is the object's type. A type is also a Python object, an instance of the <code>PyTypeObject</code> struct:</p>
<div><pre><span></span><span>// PyTypeObject is a typedef for "struct _typeobject"</span>

<span>struct</span> <span>_typeobject</span> <span>{</span>
    <span>PyVarObject</span> <span>ob_base</span><span>;</span> <span>// expansion of PyObject_VAR_HEAD macro</span>
    <span>const</span> <span>char</span> <span>*</span><span>tp_name</span><span>;</span> <span>/* For printing, in format "&lt;module&gt;.&lt;name&gt;" */</span>
    <span>Py_ssize_t</span> <span>tp_basicsize</span><span>,</span> <span>tp_itemsize</span><span>;</span> <span>/* For allocation */</span>

    <span>/* Methods to implement standard operations */</span>

    <span>destructor</span> <span>tp_dealloc</span><span>;</span>
    <span>Py_ssize_t</span> <span>tp_vectorcall_offset</span><span>;</span>
    <span>getattrfunc</span> <span>tp_getattr</span><span>;</span>
    <span>setattrfunc</span> <span>tp_setattr</span><span>;</span>
    <span>PyAsyncMethods</span> <span>*</span><span>tp_as_async</span><span>;</span> <span>/* formerly known as tp_compare (Python 2)</span>
<span>                                    or tp_reserved (Python 3) */</span>
    <span>reprfunc</span> <span>tp_repr</span><span>;</span>

    <span>/* Method suites for standard classes */</span>

    <span>PyNumberMethods</span> <span>*</span><span>tp_as_number</span><span>;</span>
    <span>PySequenceMethods</span> <span>*</span><span>tp_as_sequence</span><span>;</span>
    <span>PyMappingMethods</span> <span>*</span><span>tp_as_mapping</span><span>;</span>

    <span>/* More standard operations (here for binary compatibility) */</span>

    <span>hashfunc</span> <span>tp_hash</span><span>;</span>
    <span>ternaryfunc</span> <span>tp_call</span><span>;</span>
    <span>reprfunc</span> <span>tp_str</span><span>;</span>
    <span>getattrofunc</span> <span>tp_getattro</span><span>;</span>
    <span>setattrofunc</span> <span>tp_setattro</span><span>;</span>

    <span>/* Functions to access object as input/output buffer */</span>
    <span>PyBufferProcs</span> <span>*</span><span>tp_as_buffer</span><span>;</span>

    <span>/* Flags to define presence of optional/expanded features */</span>
    <span>unsigned</span> <span>long</span> <span>tp_flags</span><span>;</span>

    <span>const</span> <span>char</span> <span>*</span><span>tp_doc</span><span>;</span> <span>/* Documentation string */</span>

    <span>/* Assigned meaning in release 2.0 */</span>
    <span>/* call function for all accessible objects */</span>
    <span>traverseproc</span> <span>tp_traverse</span><span>;</span>

    <span>/* delete references to contained objects */</span>
    <span>inquiry</span> <span>tp_clear</span><span>;</span>

    <span>/* Assigned meaning in release 2.1 */</span>
    <span>/* rich comparisons */</span>
    <span>richcmpfunc</span> <span>tp_richcompare</span><span>;</span>

    <span>/* weak reference enabler */</span>
    <span>Py_ssize_t</span> <span>tp_weaklistoffset</span><span>;</span>

    <span>/* Iterators */</span>
    <span>getiterfunc</span> <span>tp_iter</span><span>;</span>
    <span>iternextfunc</span> <span>tp_iternext</span><span>;</span>

    <span>/* Attribute descriptor and subclassing stuff */</span>
    <span>struct</span> <span>PyMethodDef</span> <span>*</span><span>tp_methods</span><span>;</span>
    <span>struct</span> <span>PyMemberDef</span> <span>*</span><span>tp_members</span><span>;</span>
    <span>struct</span> <span>PyGetSetDef</span> <span>*</span><span>tp_getset</span><span>;</span>
    <span>struct</span> <span>_typeobject</span> <span>*</span><span>tp_base</span><span>;</span>
    <span>PyObject</span> <span>*</span><span>tp_dict</span><span>;</span>
    <span>descrgetfunc</span> <span>tp_descr_get</span><span>;</span>
    <span>descrsetfunc</span> <span>tp_descr_set</span><span>;</span>
    <span>Py_ssize_t</span> <span>tp_dictoffset</span><span>;</span>
    <span>initproc</span> <span>tp_init</span><span>;</span>
    <span>allocfunc</span> <span>tp_alloc</span><span>;</span>
    <span>newfunc</span> <span>tp_new</span><span>;</span>
    <span>freefunc</span> <span>tp_free</span><span>;</span> <span>/* Low-level free-memory routine */</span>
    <span>inquiry</span> <span>tp_is_gc</span><span>;</span> <span>/* For PyObject_IS_GC */</span>
    <span>PyObject</span> <span>*</span><span>tp_bases</span><span>;</span>
    <span>PyObject</span> <span>*</span><span>tp_mro</span><span>;</span> <span>/* method resolution order */</span>
    <span>PyObject</span> <span>*</span><span>tp_cache</span><span>;</span>
    <span>PyObject</span> <span>*</span><span>tp_subclasses</span><span>;</span>
    <span>PyObject</span> <span>*</span><span>tp_weaklist</span><span>;</span>
    <span>destructor</span> <span>tp_del</span><span>;</span>

    <span>/* Type attribute cache version tag. Added in version 2.6 */</span>
    <span>unsigned</span> <span>int</span> <span>tp_version_tag</span><span>;</span>

    <span>destructor</span> <span>tp_finalize</span><span>;</span>
    <span>vectorcallfunc</span> <span>tp_vectorcall</span><span>;</span>
<span>};</span>
</pre></div>


<p>By the way, note that the first member of a type is not <code>PyObject</code> but <code>PyVarObject</code>, which is defined as follows:</p>
<div><pre><span></span><span>typedef</span> <span>struct</span> <span>{</span>
    <span>PyObject</span> <span>ob_base</span><span>;</span>
    <span>Py_ssize_t</span> <span>ob_size</span><span>;</span> <span>/* Number of items in variable part */</span>
<span>}</span> <span>PyVarObject</span><span>;</span>
</pre></div>


<p>Nevertheless, since the first member of <code>PyVarObject</code> is <code>PyObject</code>, a pointer to a type can still be converted to a pointer to <code>PyObject</code>.</p>
<p>So, what is a type and why does it have so many members? A type determines how the objects of that type behave. Each member of a type, called slot, is responsible for a particular aspect of the object's behavior. For example:</p>
<ul>
<li><code>tp_new</code> is a pointer to a function that creates new objects of the type.</li>
<li><code>tp_str</code> is a pointer to a function that implements  <code>str()</code> for objects of the type.</li>
<li><code>tp_hash</code> is a pointer to a function that implements  <code>hash()</code> for objects of the type.</li>
</ul>
<p>Some slots, called sub-slots, are grouped together in suites. A suite is just a struct that contains related slots. For example, the <code>PySequenceMethods</code> struct is a suite of sub-slots that implement the sequence protocol:</p>
<div><pre><span></span><span>typedef</span> <span>struct</span> <span>{</span>
    <span>lenfunc</span> <span>sq_length</span><span>;</span>
    <span>binaryfunc</span> <span>sq_concat</span><span>;</span>
    <span>ssizeargfunc</span> <span>sq_repeat</span><span>;</span>
    <span>ssizeargfunc</span> <span>sq_item</span><span>;</span>
    <span>void</span> <span>*</span><span>was_sq_slice</span><span>;</span>
    <span>ssizeobjargproc</span> <span>sq_ass_item</span><span>;</span>
    <span>void</span> <span>*</span><span>was_sq_ass_slice</span><span>;</span>
    <span>objobjproc</span> <span>sq_contains</span><span>;</span>

    <span>binaryfunc</span> <span>sq_inplace_concat</span><span>;</span>
    <span>ssizeargfunc</span> <span>sq_inplace_repeat</span><span>;</span>
<span>}</span> <span>PySequenceMethods</span><span>;</span>
</pre></div>


<p>If you count all the slots and sub-slots, you'll get a scary number. Fortunately, each slot is very well <a href="https://docs.python.org/3/c-api/typeobj.html">documented</a> in the Python/C API Reference Manual (I strongly recommend you to bookmark this link). Today we'll cover only a few slots. Nevertheless, it shall give us a general idea of how slots are used.</p>
<p>Since we're interested in how CPython adds objects, let's find the slots responsible for addition. There must be at least one such slot. After careful inspection of the <code>PyTypeObject</code> struct, we find that it has the "number" suite <code>PyNumberMethods</code>, and the first slot of this suite is a binary function called <code>nd_add</code>:</p>
<div><pre><span></span><span>typedef</span> <span>struct</span> <span>{</span>
    <span>binaryfunc</span> <span>nb_add</span><span>;</span> <span>// typedef PyObject * (*binaryfunc)(PyObject *, PyObject *)</span>
    <span>binaryfunc</span> <span>nb_subtract</span><span>;</span>
    <span>binaryfunc</span> <span>nb_multiply</span><span>;</span>
    <span>binaryfunc</span> <span>nb_remainder</span><span>;</span>
    <span>binaryfunc</span> <span>nb_divmod</span><span>;</span>
    <span>// ... more sub-slots</span>
<span>}</span> <span>PyNumberMethods</span><span>;</span>
</pre></div>


<p>It seems that the <code>nb_add</code> slot is what we're looking for. Two questions naturally arise regarding this …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-6-how-python-object-system-works/">https://tenthousandmeters.com/blog/python-behind-the-scenes-6-how-python-object-system-works/</a></em></p>]]>
            </description>
            <link>https://tenthousandmeters.com/blog/python-behind-the-scenes-6-how-python-object-system-works/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25384433</guid>
            <pubDate>Fri, 11 Dec 2020 11:11:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[UI and Design Inspiration for Developers]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25384428">thread link</a>) | @kitsao
<br/>
December 11, 2020 | https://tipjarr.net/post/7-web-and-ui-design-inspiration-websites | <a href="https://web.archive.org/web/*/https://tipjarr.net/post/7-web-and-ui-design-inspiration-websites">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img alt="5 website to get UI and design inspiration as a developer" data-srcset="https://images.unsplash.com/photo-1523726491678-bf852e717f6a?ixid=MXwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHw%3D&amp;ixlib=rb-1.2.1&amp;auto=format&amp;fit=crop&amp;w=1350&amp;q=80"></p><p>User Interface (UI) and Web design is the the process of planning the  overall feel of your website, how itâ€™s presented, how it looks, and how people can interact with it. This is important because a successful UI design contributes to a positive user experience, which is a competitive advantage.
Below are some of the  websites that might inspire your web/UI design eye as a web developer</p><h2><a href="https://dribbble.com/">Dribbble</a></h2><p><img alt="dribbble image" data-srcset="https://cdn.dribbble.com/assets/pro/landing-page/profile-desktop-x2-01baa8faad0be1942d913c0751648e13cc4d19228dcbb0d4e3abb2cb8f26b90a.png" src="https://cdn.dribbble.com/assets/pro/landing-page/profile-desktop-x2-01baa8faad0be1942d913c0751648e13cc4d19228dcbb0d4e3abb2cb8f26b90a.png"></p><p><strong>Dribbble</strong> is an online community for showcasing user-made artwork. It functions as a self-promotion and networking platform for:</p><ul><li>graphic design,</li><li>web design,</li><li>illustration,</li><li><p>photography</p></li></ul><p>Creative professionals such as illustrators, web designers, graphic designers and icon artists use Dribbble to promote their work and meet colleagues. As a web developer or UI designer dribbble is a great place to find inspiration for your next design. Dribbbble also offers amazing filter tools you can filter designs by color, Tags, Timeframe, and many other attributes Dribbble also has a pro subscription where you  get to email the designer of a particular shot you like. Overall its a neat platform to get inspiration from.</p><h2><a href="https://dribbble.com/">Behance</a></h2><p><img alt="Behance image" data-srcset="https://mir-s3-cdn-cf.behance.net/project_modules/1400/165af265485593.5af5bf8eae575.jpg" src="https://mir-s3-cdn-cf.behance.net/project_modules/1400/165af265485593.5af5bf8eae575.jpg"></p><p>Just like Dribbble <strong>Behance</strong> is also a social network owned by Adobe for creatives of just about every field and discipline. It's a place to connect, inspire, and get hiredâ€”a portfolio site that's so much more. 
As a developer, you can utilize Behance advanced  tools to search for design and get inspired
Behance  offers great filter tools like color, location, Layouts, and more...</p><h2><a href="https://www.awwwards.com/">Awwwards</a></h2><p><img alt="Awwwards image" data-srcset="https://assets.awwwards.com/awards/submissions/2019/02/5c54795c58ddb236387697.jpg" src="https://assets.awwwards.com/awards/submissions/2019/02/5c54795c58ddb236387697.jpg"></p><p><strong>Awwwards</strong> is a platform that recognizes the talent and effort of the best web designers, developers and agencies in the world.
It is a website competition that developers can submit to. The best year-round submissions are awarded at the Awwwards conference and prize-giving ceremony, which take place in various cities across the United States and Europe.
Awwwards also features a rating system for the websites featured and selects a new site each day to showcase.</p><h2><a href="https://www.frontendmentor.io/">Frontend Mentor</a></h2><p><img alt="Frontend mentor image" data-srcset="https://res.cloudinary.com/dz209s6jk/image/upload/v1585172856/Meta/meta-homepage.png" src="https://res.cloudinary.com/dz209s6jk/image/upload/v1585172856/Meta/meta-homepage.png"></p><p>Unlike Dribbble and Behance <strong>Frontend Mentors</strong> Gives You real-world HTML, CSS and JavaScript challenges whilst working to professional designs. Its a community of over 81,559 developers building projects, reviewing code, and helping each other get better.</p><h3>HOW IT WORKS</h3><ul><li><strong>Choose your challenge</strong><ul><li>Have a look through different collections of web designs. Pick one that you feel will be a nice challenge for you at this stage.</li></ul></li><li><strong>Code the design</strong><ul><li>Start the challenge and download all the starter files. They provide all the files you'll need to complete the challenge. Building it is up to you!</li></ul></li><li><strong>Submit your solution</strong><ul><li>Post your solution on the platform for everyone to see and get feedback on your code from other developers in the community.</li></ul></li><li><strong>Give others feedback</strong><ul><li>Thinking critically about other people's code is a crucial skill. Help others while deepening your own knowledge by giving feedback on solutions.</li></ul></li></ul><p>Frontend Masters helps you gain real experience of building websites and providing code reviews. Build your portfolio and help others achieve their goals.</p><h2><a href="https://www.pinterest.com/">Pinterest</a></h2><p><img alt="Pinterest image" data-srcset="https://s.pinimg.com/images/facebook_share_image.png" src="https://s.pinimg.com/images/facebook_share_image.png"></p><p><strong>Pinterest</strong> is a visual discovery engine for finding ideas like recipes, home and style inspiration, and more.
Pinterest is can be a great source for all kinds of design inspiration. You can use the â€˜Exploreâ€™ link to view categories like photography and illustration, or plug in â€˜web designâ€™ to filter images of various websites.</p><h3>Pins</h3><p>Pins are bookmarks that people use to save ideas they love on Pinterest.</p><p>With billions of Pins on Pinterest, you'll always find ideas to spark inspiration. When you discover Pins you love, save them to boards to keep your ideas organized and easy to find.
If you click through the Pin, you can visit the website to learn how to make it or where to buy it. As you discover Pins you love, click the red Save button to save them to your boards.</p><h2><a href="https://land-book.com/">Land book</a></h2><p><img alt="Landbook image" data-srcset="https://land-book.com/images/facebook-ad.png" src="https://land-book.com/images/facebook-ad.png"></p><p><strong>Land-book</strong> is a Design gallery  carefully collected websites. Landbook seeks to help creatives find inspiration &amp; motivation to make really cool stuff on the internet
Overall its a great place to find inspiration</p><h2><a href="https://httpster.net/">Httpster</a></h2><p><img alt="Httpster image" data-srcset="https://armory.visualsoldiers.com/wp-content/uploads/2017/08/httpster.jpg" src="https://armory.visualsoldiers.com/wp-content/uploads/2017/08/httpster.jpg"></p><p><strong>Httpster</strong> is an inspiration resource showcasing totally rocking websites made by people from all over the world.
Its simple design lets you easily discover and possibly get inspired by designs from around
the world</p><h2>Conclusion</h2><p>Finding design inspiration as a developer can be challenging, but hopefully the resources above might
come in handy whenever you face a design block. Happy hacking .</p></div></div>]]>
            </description>
            <link>https://tipjarr.net/post/7-web-and-ui-design-inspiration-websites</link>
            <guid isPermaLink="false">hacker-news-small-sites-25384428</guid>
            <pubDate>Fri, 11 Dec 2020 11:10:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Decoding the Language of Genomes]]>
            </title>
            <description>
<![CDATA[
Score 35 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25384412">thread link</a>) | @srom
<br/>
December 11, 2020 | https://caltechletters.org/science/decoding-the-language-of-genomes | <a href="https://web.archive.org/web/*/https://caltechletters.org/science/decoding-the-language-of-genomes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">

<p><img src="https://caltechletters.org/media/posts/2020-11-03-decoding-the-genome/wilson_dna.jpg" alt=""></p>

<p><a href="https://sarahzeichner.weebly.com/" target="_blank">Illustration by Sarah Zeichner for Caltech Letters</a></p>
<p><span>T</span>he year was 2003, and the first human genome had been <a href="https://www.genome.gov/human-genome-project" target="_blank">sequenced</a>.</p>
<p>By almost every metric, it was an extraordinary achievement. The completion of the Human Genome Project provided a starting point for scientists to study the “<a href="https://medlineplus.gov/genetics/" target="_blank">blueprint for building a person</a>”. Pharmaceutical companies suddenly possessed a genetic chart to design more targeted medicines. Archaeologists gained a roadmap to compare human genomes through the ages. Biologists acquired a lodestar to locate the genes governing health and behavior. The floodgates of the genomic era had officially opened. But the project also revealed a mystery.</p>
<p>In the 1990s, scientists <a href="https://web.ornl.gov/sci/techresources/Human_Genome/project/5yrplan/index.shtml" target="_blank">estimated</a> that the Human Genome Project would unveil 100,000 human genes. But the sequencing results revealed a stark reality: humans only have 20,000 genes—<a href="https://www.nsf.gov/news/news_summ.jsp?cntn_id=118530" target="_blank">10,000 fewer than a water flea</a>. It seems remarkable that humans—with our fancy bipedalism and oversized brains—could have fewer genes than a microscopic crustacean.</p>
<p>A lot has changed in the two decades since the Human Genome Project. The technology to sequence genes has gotten cheaper and faster. The first human genome sequence cost three billion dollars, involved thousands of scientists, and took 13 years to complete. Today, sequencing machines can read a human genome in less than a day for a few hundred dollars. But technology is not a substitute for knowledge, and scientists still don’t fully understand how the genome works.</p>
<p><img src="https://caltechletters.org/media/posts/2020-11-03-decoding-the-genome/broad_center.jpg" alt=""></p>
<p>The Broad Center for the Biological Sciences at Caltech.</p>
<p>Photo by Suzy Beeler</p>
<p>Nestled in the back corner of the <a href="https://broadfoundation.org/grantees/the-broad-center-for-biological-science-at-caltech/" target="_blank">Broad Center for the Biological Sciences</a> at Caltech, our research laboratory aims to understand how genomes encode and express information. To find us on campus, look for the cubic building made from metal and travertine, with sweeping views of the San Gabriel mountains. On a clear day many months ago, before the pandemic confined us to untidy apartments, we could see Mt. Wilson Observatory from our offices. Its white telescopes dot the mountain’s summit, silhouetted against the rising sun. Inside the lab, our benches are cluttered with liquid-filled bottles and metal pipettes.</p>
<p>We study genomes, in part, because of the impact on our impressionable young minds when the Human Genome Project made national news back in 2003. The structure of DNA had been <a href="https://www.nature.com/scitable/topicpage/discovery-of-dna-structure-and-function-watson-397/" target="_blank">established</a> fifty years earlier, thanks to herculean efforts from Rosalind Franklin, James Watson, Francis Crick, and others. Our understanding of genomes came a long way in those 50 years, from structure to sequence. But we know that there is more to learn.</p>
<p>About <a href="https://www.forbes.com/sites/matthewherper/2017/01/09/illumina-promises-to-sequence-human-genome-for-100-but-not-quite-yet/#14098b8f386d" target="_blank">500,000 human genomes</a> have been sequenced since 2003. Sequencing machines are now commonplace at universities. Humming on tables, they look like space-age computer systems, with touch screens and tiny, pneumatic tubes. DNA is extracted from living cells, trillions of copies are made using a technique called <a href="https://www.youtube.com/watch?v=matsiHSuoOw&amp;vl=en" target="_blank">PCR</a>, and the copied molecules are loaded (carefully!) into the machine. A few hours later, after the humming subsides, an interminable string of characters appears on the screen, made up of four letters: A, T, C, and G.</p>
<p>All genomes on earth are made up of these letters, called nucleotides. Each letter is a unique molecule—adenine, thymine, cytosine, and guanine—that links up to the others, forming a minimal alphabet. With these four letters, our cells construct words, or—in the context of biology—genes.</p>
<p>Much as a Xerox machine can make thousands of copies from a single document, genes are converted to messenger RNA in a process called <a href="https://www.youtube.com/watch?v=whV_CkKT7F0" target="_blank">transcription</a>, which then serves as a template to build proteins. The human genome encodes about 20,000 genes, which in turn produce proteins that fend off viral invaders, manage blood sugar levels, and everything in between.</p>
<iframe width="280" height="156" src="https://www.youtube.com/embed/8M198uHJd_8?start=0" frameborder="0" allowfullscreen=""></iframe>
<p>This short animation shows how transcription happens.</p>

<p>But we cannot “see” these dynamic changes with a DNA sequence. The order of letters in a genome tells us nothing about how a gene is controlled in the molecular confines of a cell. Gene expression is dynamic and changing. Genes are turned on and off as proteins are needed, and these changes over time may explain how genomes can give rise to the most beautiful of lifeforms. In other words, it may explain how we are human, despite a trifling 20,000 genes.</p>
<p>We study how genomes are controlled because we want to understand ourselves. In doing so, we are building upon more than 80 years of experimental history.</p>
<hr>
<p>In the 1940s, Jacques Monod and François Jacob, frantically working in a little laboratory in the Necker neighborhood of Paris, found that cells control protein numbers by turning genes “on” or “off”. Though their results seem obvious today (the best results always do), they shared the <a href="https://www.nobelprize.org/prizes/medicine/1965/summary/" target="_blank">1965 Nobel Prize</a> in Physiology or Medicine for their work.</p>
<p>Genes are regulated by proteins called transcription factors, of which there are two types: activators, which bind to DNA near the start of a gene and increase the amount of mRNA copies made from a gene, much like loading more paper into a Xerox tray, and repressors, which decrease the amount of mRNA copies. Transcription factors hold dominion over the genome, controlling when each gene gets to make its Xerox copies.</p>
<p>Jacob and Monod’s findings provided a potential solution to the question that arose from the first human genome sequence, 60 years later. Perhaps an organism’s complexity is dictated not by how many genes are present in a genome, but rather by how those genomes are controlled, over time, by transcription factors.
To build upon the work of our scientific heroes, our lab at Caltech wanted to determine which type of transcription factor—activator or repressor—regulates each and every gene. To test our experiments, we decided to start with a small genome. We turned to a bacterium, <em>Escherichia coli</em>.</p>
<p>In the grand order of nature, <em>E. coli</em> is relatively simple, containing 4,000 genes and 200 transcription factors. But, despite its meager size, we still do not know how two-thirds of its genes are regulated.</p>
<p><img src="https://caltechletters.org/media/posts/2020-11-03-decoding-the-genome/ecoli_genome.png" alt=""></p>
<p>The <i>E. coli</i> genome contains about 4.6 million nucleotides and 4,000 genes. In this diagram, genes that have known regulation (which means that we know which transcription factors regulate them) are marked in blue. For most genes (roughly two-thirds), we have no idea which transcription factors regulate or control them (marked in red).</p>
<p>Diagram by Niko McCarty</p>
<p>We knew that if we ever wanted to understand how even a small bacterial genome is regulated, a new experimental method would be needed. So we <i>created</i> one.</p>
<hr>
<p>When <a href="https://sites.uw.edu/theriotlab/members/" target="_blank">Nathan Belliveau</a> joined the lab, a few years ago, his objective was simple: find an easy way to determine how genes in <em>E. coli</em> are regulated.</p>
<p>Sitting at the bench, he harvested genetic material from <em>E. coli</em> and loaded the DNA into a sequencer. After a few years—and hundreds of trials—he <a href="https://www.pnas.org/content/115/21/E4796" target="_blank">reported</a> the foundations of a radical method that would eventually enable our laboratory to figure out which transcription factors regulate hundreds, or thousands, of genes at a time. Nathan left the group in 2017, PhD in hand, and flew to colder climates. Bill Ireland and Suzy Beeler (an author of this article) took over the project.</p>
<p>They, too, spent years agonizing over the method. After using thousands of tubes of DNA and covering their benches in teetering stacks of bacteria-streaked agar plates, Bill and Suzy managed to extend Nathan’s findings to more than a hundred genes. In the process, they refined a powerful method that lends deep insights into the intricate, molecular machines that regulate genomes.</p>
<p>Here’s how the method works.</p>
<p>We begin by literally mail ordering short sequences of DNA—the regions immediately in front of a gene—where transcription factors typically bind. A computer helps us design mutated versions of each DNA sequence, randomly changing the letters until we have thousands of variants for each sequence. A company in San Francisco takes our digital letters, creates physical copies, and ships them in a little plastic tube to our laboratory. We then place these synthetic pieces of DNA inside of <em>E. coli</em> cells, and use a modified version of DNA sequencing to determine whether each “letter” change made a gene produce more or fewer Xerox copies.</p>
<p>If a DNA sequence produces very little RNA inside of the cell, this suggests that the letter change (or mutation) blocked transcription; it choked up the Xerox machine. It also indicates that an activator was probably binding to that DNA sequence, and the mutation prevented it from doing its job. Some mutations, however, increase the amount of RNA produced from a DNA sequence, suggesting that the mutation is preventing a repressor from binding.</p>
<p>By analyzing this data and running it through mathematical models, we can determine whether each gene is regulated by an activator or repressor, how many transcription factors regulate each gene, and where those transcription factors actually bind.</p>
<p>In other words, we can map the genome’s regulatory networks.</p>
<p><img src="https://caltechletters.org/media/posts/2020-11-03-decoding-the-genome/lab.jpg" alt=""></p>
<p>A bench in our laboratory, where this work was performed</p>
<p>Photo by Suzy Beeler</p>
<p>After performing this experiment on more than one hundred genes, we made some startling discoveries. In one case, we found a transcription factor with dual activity: it activated the transcription of one gene while repressing the transcription of another. We also identified transcription factors that are only active in certain environments; when <em>E. coli</em> is grown in the presence of a sugar, for example, a transcription factor called GlpR represses a handful of genes. Without the sugar, GlpR doesn’t work at all.</p>
<p>In our opinion, this <a href="https://elifesciences.org/articles/55308" target="_blank">study</a> marks a major advancement in genomic research. But it didn’t come for free.</p>
<p>Throughout the last five years, we have failed repeatedly. We have mislabeled tubes and used ethanol instead of water to dilute DNA. We have dropped flasks, shattering glass and spilling bacteria on the floor. We have been frustrated, again and again. But we continued on, inching closer …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://caltechletters.org/science/decoding-the-language-of-genomes">https://caltechletters.org/science/decoding-the-language-of-genomes</a></em></p>]]>
            </description>
            <link>https://caltechletters.org/science/decoding-the-language-of-genomes</link>
            <guid isPermaLink="false">hacker-news-small-sites-25384412</guid>
            <pubDate>Fri, 11 Dec 2020 11:08:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How the Slowest Computer Programs Illuminate Math’s Fundamental Limits]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25384333">thread link</a>) | @dnetesn
<br/>
December 11, 2020 | http://abstractions.nautil.us/article/651/how-the-slowest-computer-programs-illuminate-maths-fundamental-limits | <a href="https://web.archive.org/web/*/http://abstractions.nautil.us/article/651/how-the-slowest-computer-programs-illuminate-maths-fundamental-limits">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p><span>P</span>rogrammers normally want to minimize the time their code takes to execute. But in 1962, the Hungarian mathematician Tibor RadÃ³ posed the opposite problem. He asked: How long can a simple computer program possibly run before it terminates? RadÃ³ nicknamed these maximally inefficient but still functional programs â€œbusy beavers.â€�</p>

<p>Finding these programs has been a fiendishly diverting puzzle for programmers and other mathematical hobbyists ever since it was popularized in Scientific Americanâ€™s&nbsp;<a href="https://www.scientificamerican.com/article/computer-recreations-1984-08/" target="_blank">â€œComputer Recreationsâ€� column</a>&nbsp;in 1984. But in the last several years, the busy beaver game, as itâ€™s known, has become an object of study in its own right, because it has yielded connections to some of the loftiest concepts and open problems in mathematics.</p>
<p>â€œIn math, there is a very permeable boundary between whatâ€™s an amusing recreation and what is actually important,â€� said&nbsp;<a href="https://www.cs.utexas.edu/people/faculty-researchers/scott-aaronson" target="_blank">Scott Aaronson</a>, a theoretical computer scientist at the University of Texas, Austin who published a&nbsp;<a href="https://dl.acm.org/doi/10.1145/3427361.3427369" target="_blank">survey</a>&nbsp;of progress in â€œBusyBeaverology.â€�<br></p>
<p>The recent work suggests that the search for long-running computer programs can illuminate the state of mathematical knowledge, and even tell us whatâ€™s knowable. According to researchers, the busy beaver game provides a concrete benchmark for evaluating the difficulty of certain problems, such as the unsolved Goldbach conjecture and Riemann hypothesis. It even offers a glimpse of where the logical bedrock underlying math breaks down. The logician Kurt GÃ¶del proved the existence of such mathematical terra incognita nearly a century ago. But the busy beaver game can show where it actually lies on a number line, like an ancient map depicting the edge of the world.</p><p><strong>An Uncomputable Computer Game</strong></p>
<p>The busy beaver game is all about the behavior of Turing machines—the primitive, idealized computers&nbsp;<a href="https://www.cs.virginia.edu/~robins/Turing_Paper_1936.pdf" target="_blank">conceived by Alan Turing in 1936</a>. A Turing machine performs actions on an endless strip of tape divided into squares. It does so according to a list of rules. The first rule might say:</p>
<blockquote>If the square contains a 0, replace it with a 1, move one square to the right and consult rule 2. If the square contains a 1, leave the 1, move one square to the left and consult rule 3.</blockquote>
<p>Each rule has this forking choose-your-own-adventure style. Some rules say to jump back to previous rules; eventually thereâ€™s a rule containing an instruction to â€œhalt.â€� Turing proved that this simple kind of computer is capable of performing any possible calculation, given the right instructions and enough time.</p>
<p>As Turing noted in 1936, in order to compute something, a Turing machine must eventually halt—it canâ€™t get trapped in an infinite loop. But he also proved that thereâ€™s no reliable, repeatable method for distinguishing machines that halt from machines that simply run forever—a fact known as the halting problem.</p>
<p>The busy beaver game asks: Given a certain number of rules, whatâ€™s the maximum number of steps that a Turing machine can take before halting?</p>
<figure><img src="https://s3.amazonaws.com/nautilus-vertical/abstractions_448ca98db9d7b1349758c6545cdf7237.jpg" alt="nautilus tibor rado"><figcaption><span>Tibor RadÃ³, shown here in an undated photo, invented the busy beaver game as a way of making the theoretical notion of uncomputability concrete. </span><br><span>Courtesy of The Ohio State University Archives</span></figcaption></figure>
<p>For instance, if youâ€™re only allowed one rule, and you want to ensure that the Turing machine halts, youâ€™re forced to include the halt instruction right away. The busy beaver number of a one-rule machine, or BB(1), is therefore 1.</p>
<p>But adding just a few more rules instantly blows up the number of machines to consider. Of 6,561 possible machines with two rules, the one that runs the longest—six steps—before halting is the busy beaver. But some others simply run forever. None of these are the busy beaver, but how do you definitively rule them out? Turing proved that thereâ€™s no way to automatically tell whether a machine that runs for a thousand or a million steps wonâ€™t eventually terminate.</p>
<p>Thatâ€™s why finding busy beavers is so hard. Thereâ€™s no general approach for identifying the longest-running Turing machines with an arbitrary number of instructions; you have to puzzle out the specifics of each case on its own. In other words, the busy beaver game is, in general, â€œuncomputable.â€�</p>
<p>Proving that BB(2) = 6 and that BB(3) = 107 was difficult enough that RadÃ³â€™s student Shen Lin earned a doctorate for the work in 1965. RadÃ³ considered BB(4) â€œentirely hopeless,â€� but&nbsp;the case was&nbsp;<a href="https://www.ams.org/journals/mcom/1983-40-162/S0025-5718-1983-0689479-6/S0025-5718-1983-0689479-6.pdf" target="_blank">finally solved in 1983</a>. Beyond that, the values virtually explode; researchers have identified a five-rule Turing machine, for instance, that runs for 47,176,870 steps before stopping, so BB(5) is at least that big. BB(6) is at least 7.4 Ã— 1036,534.&nbsp;&nbsp;Proving the exact values â€œwill need new ideas and new insights, if it can be done at all,â€� said Aaronson.</p>
<p><strong>Threshold of Unknowability</strong></p>
<p><a href="https://www.cs.umd.edu/users/gasarch/" target="_blank">William Gasarch</a>, a computer scientist at the University of Maryland, College Park, said heâ€™s less intrigued by the prospect of pinning down busy beaver numbers than by â€œthe general concept that itâ€™s actually uncomputable.â€� He and other mathematicians are mainly interested in using the game as a yardstick for gauging the difficulty of important open problems in mathematics—or for figuring out what is mathematically knowable at all.</p>
<p>The Goldbach conjecture, for instance, asks whether every even integer greater than 2 is the sum of two primes. Proving the conjecture true or false would be an epochal event in number theory, allowing mathematicians to better understand the distribution of prime numbers. In 2015, an anonymous GitHub user named Code Golf Addict&nbsp;<a href="https://gist.github.com/anonymous/a64213f391339236c2fe31f8749a0df6" target="_blank">published code</a>&nbsp;for a 27-rule Turing machine that halts if—and only if—the Goldbach conjecture is false. It works by counting upward through all even integers greater than 4; for each one, it grinds through all the possible ways to get that integer by adding two others, checking whether the pair is prime. When it finds a suitable pair of primes, it moves up to the next even integer and repeats the process. If it finds an even integer that canâ€™t be summed by a pair of prime numbers, it halts.</p>
<p>Running this mindless machine isnâ€™t a practical way to solve the conjecture, because we canâ€™t know if it will ever halt until it does. But the busy beaver game sheds some light on the problem. If it were possible to compute BB(27), that would provide a ceiling on how long weâ€™d have to wait for the Goldbach conjecture to be settled automatically. Thatâ€™s because BB(27) corresponds to the maximum number of steps this 27-rule Turing machine would have to execute in order to halt (if it ever did). If we knew that number, we could run the Turing machine for exactly that many steps. If it halted by that point, weâ€™d know the Goldbach conjecture was false. But if it went that many steps and didnâ€™t halt, weâ€™d know for certain that it never would—thus proving the conjecture true.</p>
<p>The rub is that BB(27) is such an incomprehensibly huge number that even writing it down, much less running the Goldbach-falsifying machine for that many steps, isnâ€™t remotely possible in our physical universe. Nevertheless, that incomprehensibly huge number is still an exact figure whose magnitude, according to Aaronson, represents â€œa statement about our current knowledgeâ€� of number theory.</p>
<p>In 2016, Aaronson established a similar result in collaboration with Yuri Matiyasevich and Stefan Oâ€™Rear. They identified a 744-rule Turing machine that halts if and only if the Riemann hypothesis is false. The Riemann hypothesis also concerns the distribution of prime numbers and is one of the Clay Mathematics Instituteâ€™s&nbsp;<a href="https://www.claymath.org/millennium-problems/riemann-hypothesis" target="_blank">â€œMillennium Problemsâ€�</a>&nbsp;worth $1 million. Aaronsonâ€™s machine will deliver an automatic solution in BB(744) steps. (It works by essentially the same mindless process as the Goldbach machine, iterating upward until it finds a counterexample.)</p>
<p>Of course, BB(744) is an even more unattainably large number than BB(27). But working to pin down something easier, like BB(5), â€œmay actually turn up some new number theory questions that are interesting in their own right,â€� Aaronson said. For instance, the mathematician Pascal Michel&nbsp;<a href="https://link.springer.com/article/10.1007/BF01409968" target="_blank">proved</a>&nbsp;in 1993 that the record-holding five-rule Turing machine exhibits behavior similar to that of the function described in the Collatz conjecture, another&nbsp;<a href="https://www.quantamagazine.org/why-mathematicians-still-cant-solve-the-collatz-conjecture-20200922/" target="_blank">famous open problem</a>&nbsp;in number theory.</p>
<p>â€œSo much of math can be encoded as a question of, â€˜Does this Turing machine halt or not?â€™â€� Aaronson said. â€œIf you knew all the busy beaver numbers, then you could settle all of those questions.â€�</p>
<p>More recently, Aaronson has used a busy-beaver-derived yardstick to gauge what he calls â€œthe threshold of unknowabilityâ€� for entire systems of mathematics. GÃ¶delâ€™s famous&nbsp;<a href="https://www.quantamagazine.org/how-godels-incompleteness-theorems-work-20200714/" target="_blank">incompleteness theorems</a>&nbsp;of 1931 proved that any set of basic axioms that could serve as a possible logical foundation for mathematics is doomed to one of two fates: Either the axioms will be inconsistent, leading to contradictions (like proving that 0 = 1), or theyâ€™ll be incomplete, unable to prove some true statements about numbers (like the fact that 2 + 2 = 4). The axiomatic system underpinning almost all modern math, known as Zermelo-Fraenkel (ZF) set theory, has its own GÃ¶delian boundaries—and Aaronson wanted to use the busy beaver game to establish where they are.</p>
<p>In 2016, he and his graduate student Adam Yedidia specified a 7,910-rule Turing machine that would only halt if ZF set theory is inconsistent. This means BB(7,910) is a calculation that eludes the axioms of ZF set theory. Those axioms canâ€™t be used to prove that BB(7,910) represents one number instead of another, which is like not being able to prove that 2 + 2 = 4 instead of 5.</p>
<p>Oâ€™Rear subsequently devised a much simpler 748-rule machine that halts if ZF is inconsistent—essentially moving the threshold of unknowability closer, from BB(7,910) to BB(748). â€œThat is a kind of a dramatic thing, that the number [of rules] is not completely ridiculous,â€� said&nbsp;<a href="https://math.osu.edu/people/friedman.8" target="_blank">Harvey Friedman</a>, a mathematical …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://abstractions.nautil.us/article/651/how-the-slowest-computer-programs-illuminate-maths-fundamental-limits">http://abstractions.nautil.us/article/651/how-the-slowest-computer-programs-illuminate-maths-fundamental-limits</a></em></p>]]>
            </description>
            <link>http://abstractions.nautil.us/article/651/how-the-slowest-computer-programs-illuminate-maths-fundamental-limits</link>
            <guid isPermaLink="false">hacker-news-small-sites-25384333</guid>
            <pubDate>Fri, 11 Dec 2020 10:49:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Start a Podcast in 2021 – A Step by Step Guide]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25384162">thread link</a>) | @tomhuntio
<br/>
December 11, 2020 | https://www.bcast.fm/blog/how-to-start-a-podcast | <a href="https://web.archive.org/web/*/https://www.bcast.fm/blog/how-to-start-a-podcast">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p><strong><em>This is the first post in the three-part series. Part two focuses on </em></strong><a href="https://www.bcast.fm/blog/how-to-launch-a-podcast" target="_blank"><strong><em>how to launch a podcast</em></strong></a><strong><em>, and part three focuses on how to grow a podcast.</em></strong></p><p>The podcast industry is snowballing.&nbsp;</p><p>But don’t worry, the number of listeners is growing faster than the number of podcasts. </p><p>All the BIG tech businesses are investing heavily in the podcast space, bringing bigger and better audio tools, which in turn bring more people to podcasts.</p><ul role="list"><li>Apple - Apple Podcasts and AirPods</li><li>Google - Google Podcasts and Google Podcast Manager</li><li>Spotify - Spotify for Podcasters</li><li>Amazon - Amazon Music and Alexa</li></ul><p>We’re talking billions of dollars being spent on enabling more and more people to flood into podcasts… you just have to be there to mop them up :)</p><figure id="w-node-f4cfd1480d0a-4992c8f8"><p><img src="https://uploads-ssl.webflow.com/5f8d8ab496d65849f731ba00/5fa3cf93b331b3c358913488_4X1o_362OKLNxFY5BysBQvm9-hmMKWsrZaYwN-X3atvqRXHV361ktXo_hXBJN6mXC1rcbQHcBBZFbUFOMmLssnfNVUcMlMpj6fuFnM6sFzOiVmQ2lzBMzssQmMlu-AgzVQtfxVz2.gif" alt=""></p></figure><p>Research has shown that over <a href="https://www.statista.com/statistics/786826/podcast-listeners-in-the-us/" target="_blank">103 million Americans have at least one podcast</a> they listen to every month in the US – this number will keep growing. Despite this... there are still over 600 blogs for every podcast in the world ;)</p><figure id="w-node-a4cc97581060-4992c8f8"><p><img src="https://uploads-ssl.webflow.com/5f8d8ab496d65849f731ba00/5fa3cf92a6071203f4bd93fc_s-So6SEwWD4eheC2_twd61hX0idTzHglF81LuQoxdwe3gACuUrSqGmx5PPGKQkwEaZ5d_iWW9BsNFTCyJ8JUodSpf5Qoyk6lnOHAlFA3ODwgO1SO4jvmFBofVKLD4lsVuIu4aigH.png" alt=""></p><figcaption><em>Source: Statista.com</em></figcaption></figure><p><strong>A podcast will grow your brand.</strong></p><p>Whether that be you as a person or you for your business. There are many reasons why you should start a podcast.</p><p>And fortunately, if you want to know the right steps to make to start a successful podcast, you are in the right place.</p><p>In this easy-to-understand step-by-step guide, we will break down everything you need to start your podcast for free from developing a plan to securing the right equipment and software to use.&nbsp;</p><p>Bookmark this page and keep referring back to as you move through the process of starting your first (or next!) podcast, and when you launch make sure you ping us a link by email to <a href="mailto:support@bcast.fm">support@bcast.fm</a> - we will subscribe!</p><figure id="w-node-e9418c7b6c75-4992c8f8"><p><img src="https://uploads-ssl.webflow.com/5f8d8ab496d65849f731ba00/5fa3cf93154cd636df1dd20b_QUaPSMMrdnQRcLu0jfIP-o-iLKto34jtuaLiEPQDSJSu_4NBmW8vDPuKaMumd-4VF51oguynh0RW81UeQZxtwWyfiC0zuL0wQBmwBpBM-GP81DiWV9UUle1Jr44v-JSw_CB6HxYs.gif" alt=""></p></figure><h2><strong>STEP 1: DEVELOP A PLAN</strong></h2><p>Of course... you need a solid plan before starting a podcast. </p><p>Your podcast is a result of your thoughts and actions, and this is why you need a plan. You need to be deliberate about what you create. Your podcast gets its uniqueness from you, as you are the creator and director. </p><p>Your podcast is a result of your<strong> imagination</strong> and your <strong>ability to execute</strong>.</p><p>You must have a reason for starting your podcast, and this where the “WHY” and “WHAT” questions come in. The answer to these questions will help you create a podcast that is both unique to you but will also be able to add massive value to anyone that subscribes.&nbsp;</p><h3><strong>Why Do You Want To Start A Podcast?</strong></h3><p>There are various reasons for starting a podcast, and it varies per person. This question can have a lot of answers, but your conviction is the most important factor.</p><p><em>How much do you want to start a podcast?</em></p><p>Because if your answer is not a firm yes, then you may have challenges putting in the consistent effort to make it grow.</p><p><em>Why do you want to start a podcast?</em></p><p>There could be various reasons...<br></p><ul role="list"><li>To promote your business</li><li>To talk about your passion</li><li>To preach to the world</li><li>To share your message</li><li>To establish yourself as an authority</li><li>To have fun</li></ul><p>Whatever your reason is, you must be convinced.</p><p>This conviction will help you create a lasting relationship with your audience as you continue to execute over time when others fail to be consistent.</p><p>If&nbsp;you look at all the most popular podcasts... you will see that they have been running for years and even decades. This is what you must be prepared to do to generate a sizeable audience.</p><h3><strong>What Is The Topic Of Your Podcast?</strong></h3><p>It's now time to choose a theme/topic for your podcast. </p><p>This is the BIG one. It's make or break.</p><p>You MUST consider:</p><ul role="list"><li>Your passion on the topic</li><li>Your expertise and experience of the topic</li><li>The ability for your to monetise the topic</li></ul><p>Here at bCast, we are all about podcast profitability. We're not hobbyists. We know you need to get paid if you're going to do this for the long term and build a podcast worth listening to.</p><p>Now monetisation can come from advertising... so you don't necessarily need to have products or services in the niche or topic of your podcast... but you will need an intense passion.</p><p>Once you have spent a long time sitting in a dark room thinking about this... you then need to understand the #1 thing that will define the success or failure of your podcast:</p><p><strong><em>How are you different or better for a specific group of people?</em></strong></p><p>As if you are not... and you don't have a load of money to spend on Facebook Ads, it's going to be hard to make your podcast grow. Trust me... we know.</p><p>Maybe you only ask specific types of questions; perhaps you focus on a particular niche, perhaps you only interview three people at a time… it can be anything as long as it makes you different or better for a specific group of people.</p><p>If you are VERY particular about this… you will more than double your chances of succeeding.</p><h3><strong>Who Are Your Listeners?</strong></h3><p>Now that you have answered the WHY and WHAT, it is time to answer the WHO question.</p><p>Every podcast needs listeners, and in order for your podcast to grow... you must know exactly who your listeners are and where to find them.&nbsp;</p><figure id="w-node-08046cb77a20-4992c8f8"><p><img src="https://uploads-ssl.webflow.com/5f8d8ab496d65849f731ba00/5fa3cf937aa690314e79dafd__co8aVE5evZ3_Tzk8ZugkGqAFkT8oBN3HT-ksoEWq5FNU4yYXhOaV3P8uJZ27GaH8Ha-aIdbGh3PPQqOLLXsAZ-K6sSfKjXfmjcmVJW5xRfolNsufXY7OnFRKVLn4GMako-ZIAM_.gif" alt=""></p></figure><p>You need to find out:</p><ul role="list"><li>Where they are&nbsp;</li><li>How old they are</li><li>What catches their attention</li><li>What they eat for breakfast</li><li>Who they hate</li><li>Who they love</li></ul><p>This is why it's normally a great strategy for you to actually BE&nbsp;YOUR&nbsp;PERFECT&nbsp;LISTENER. This is a shortcut through this stage of the process as if this is the case, you should know the answers to all of those questions ;)</p><p>Once this is defined you then need to list out a number of places where these people hang out online:</p><ul role="list"><li>Blogs</li><li>Other podcasts</li><li>Facebook Groups</li><li>subReddits</li><li>Linkedin Groups</li><li>YouTube Channels</li></ul><p>We will need this list later in the process when we move through the launch and grow stages.</p><h3><strong>How Do You Name Your Podcast?</strong></h3><p>There are a number of strategies to follow here...</p><ul role="list"><li><strong><em>Make it concise</em></strong></li></ul><p>Succinct podcast names land better as they convey the message most strongly.</p><ul role="list"><li><strong><em>Do not neglect the relevant keyword</em></strong></li></ul><p><strong><em>‍</em></strong>If your podcast is about soccer, let the name convey that; this is important in searches, as your podcast name will pop up in searches related to your industry.</p><ul role="list"><li>‍<strong><em>Make it easy on the tongue</em></strong></li></ul><p><strong><em>‍</em></strong>You don’t want a twisted name, as you will mention it time and again on your podcast – it should be smooth to say.</p><ul role="list"><li><strong><em>Keep it simple</em></strong></li></ul><p><strong><em>‍</em></strong>You don’t want the stress of explaining your podcast name every time. Embrace simplicity</p><ul role="list"><li><strong><em>Look out for rhyme and alliteration opportunities</em></strong></li></ul><p>The best names of anything normally incorporate rhyme and/or alliteration... be on the look out for these opportunities and incorporate them if they arise.</p><p>To make this clearer... here are some great examples along with an explanation for why:</p><p><a href="https://podcasts.bcast.fm/sales-ops-demystified" target="_blank"><strong>Sales Ops Demystified</strong></a>: We include the core key word AND the value proposition of the show. It's clear and concise and succinctly tells the potential listener why they should listen.</p><p><a href="https://podcasts.bcast.fm/mobile-growth-pancakes" target="_blank"><strong>Mobile Growth and Pancakes</strong></a>: Keyword conscious and not boring. This podcast name is exciting, and a listener will want to hear what they have to say. It lays a foundation for what to expect, which is discussing mobile growth in a fun and slightly... different way.&nbsp;</p><p><a href="https://podcasts.bcast.fm/shine-a-podcast-by-star" target="_blank"><strong>Shine: a Podcast by Star</strong></a>: Simple and short. The host already directs the listener's thought from the first word. It also promotes the host, as a name is attached to the podcast and conveys an aspect of the hosts brand: shining through technology.</p><p><a href="https://podcasts.bcast.fm/be-more-a-podcast-by-peakon" target="_blank"><strong>Be More - a podcast by Peakon</strong></a>: If you want to be more, you have to listen. Everyone wants to be more, and this podcast name exploits that emotional aspect with this name: it's aspirational. The listener wants to know how they can "be more".&nbsp;</p><h3><strong>How Do You Describe Your Podcast?</strong></h3><p>Research has shown that your <a href="https://www.thepodcasthost.com/promotion/podcast-discoverability/" target="_blank">podcast description</a> is the number one factor that new listeners consider when deciding whether to subscribe. When describing your podcast, you must be able to offer value to the listener quickly. You must tell in precise terms, what they stand to gain by listening to your show.</p><p>You also have to consider search engines as you construct e your podcast description. Your show description must be able to rank to stand a chance of getting any free exposure from Google. Include relevant keywords in the industry you cover.&nbsp;</p><p>When writing your description, you should consider attention span. You need to grab listeners' attention by putting the juicy points first. You also need to make fair use of the description by avoiding repetition.&nbsp;</p><p>Be concise, offer value, and grab attention with the first lines.&nbsp;</p><h3><strong>How Do You Pick The Right Category For Your Podcast?</strong></h3><p>The primary way podcast listeners discover podcasts is through searching within podcast listening apps. They navigate through different categories and topics and look for the best shows in that category – <strong>this is why</strong> you need to place your podcast in the right category. It will increase the chance that your perfect listener will discover your podcast.</p><p>You get three chances:</p><ul role="list"><li>1 Primary category</li><li>2 Sub categories</li></ul><p>I won't share much more on this as I assume you know the category in which your podcast should reside!</p><h3><strong>What Podcast Format Should You Adopt?</strong></h3><p>There are different formats for podcasts. The good thing is, you have creative control over the structure of your podcast. In most cases, the format you choose depends on the message you are trying to convey to your audience.&nbsp;</p><p>There are different types of formats:</p><ul role="list"><li><strong>Interview podcast:</strong> this format involves a host that brings guests on the show, and interviews them. These guests are usually experts in their field, and the host asks them relevant questions in their industry.&nbsp;</li><li><strong>Monologue podcast:</strong> this format involves the host alone. The host will run solo and speak about their experiences and area of expertise. It is mostly educational and a teaching type of format.</li><li><strong>Co-hosted podcast:</strong> this format will involve two hosts that will have conversations. They share their experiences and have a back and forth when needed.&nbsp;</li><li><strong>Story-based podcast:</strong> this format involves a host that tells a story like a drama to the audience. The story could be fiction or non-fiction. The host finds ways to spice it up through the use of different effects.</li></ul><p>That said, there is room for more than one format on your podcast. You could adopt different forms for different episodes, depending on the message you are trying to pass.</p><p>So why not start out with one... test, gather …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.bcast.fm/blog/how-to-start-a-podcast">https://www.bcast.fm/blog/how-to-start-a-podcast</a></em></p>]]>
            </description>
            <link>https://www.bcast.fm/blog/how-to-start-a-podcast</link>
            <guid isPermaLink="false">hacker-news-small-sites-25384162</guid>
            <pubDate>Fri, 11 Dec 2020 10:18:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We can have democracy or we can have Facebook]]>
            </title>
            <description>
<![CDATA[
Score 268 | Comments 466 (<a href="https://news.ycombinator.com/item?id=25383976">thread link</a>) | @imartin2k
<br/>
December 11, 2020 | https://the.ink/p/we-can-have-democracy-or-we-can-have | <a href="https://web.archive.org/web/*/https://the.ink/p/we-can-have-democracy-or-we-can-have">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0c86dcd-c055-427e-910c-ccc4314253f1_2094x1147.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0c86dcd-c055-427e-910c-ccc4314253f1_2094x1147.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/f0c86dcd-c055-427e-910c-ccc4314253f1_2094x1147.jpeg&quot;,&quot;height&quot;:798,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:277616,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>Being on the phone with <a href="https://twitter.com/matthewstoller">Matt Stoller</a> when a giant antitrust case is announced against Facebook is like texting with the pope when the Second Coming, you know, comes.</p><p>It’s a little on the nose. A little exciting.</p><p>I’d been wanting to talk to Matt for a while, in part because the pope actually turned down my recent interview request (someone please tell him how book tours work).</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F37ce1cde-dec5-4068-8ca8-3359f838647c_1308x264.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F37ce1cde-dec5-4068-8ca8-3359f838647c_1308x264.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/37ce1cde-dec5-4068-8ca8-3359f838647c_1308x264.png&quot;,&quot;height&quot;:264,&quot;width&quot;:1308,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:51146,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>And in part because I consider him (Matt) one of the more interesting, iconoclastic, morally committed, unpredictable, critics-may-care thinkers today. In the course of a typical Twitter day, which is a week in human time, I agree with Matt, disagree with him, wish I had thought of something he said, regret something he said on his behalf, retweet something he wrote, and make a mental note to talk with him soon. So I did.</p><p>And there we were, talking about everything — his political education, why he goes back and forth between thinking of himself as a progressive and not, his highly influential recent book, “<a href="https://www.simonandschuster.com/books/Goliath/Matt-Stoller/9781501182891">Goliath: The 100-Year War Between Monopoly Power and Democracy</a>” — when my phone began to crackle with <a href="https://www.nytimes.com/2020/12/09/technology/facebook-antitrust-monopoly.html">news of an historic antitrust case against Facebook</a>.</p><p>Naturally, I began to ask Matt about it. What he said was so compelling that I’ve decided to break our interview into two issues of the newsletter. Today: Matt Stoller on Facebook, this important case, and how monopoly is mistaken as a policy issue when in fact it represents an existential question of whether we are actually a democracy.</p><p>Then, before long, <a href="https://www.imdb.com/title/tt0107144/">part deux</a>, the political education of Matt Stoller — thinker, writer, civil servant, trustbuster, Twitter beefer, and, presently, aspiring political philosopher.</p><p>Without shame, I’ll add, in the spirit of Matt’s ideas, that if you want to do your part to support small, independent media, and haven’t yet, consider subscribing to The Ink.</p><h3>“The way we do business is the way we do justice”: a conversation with Matt Stoller, part one</h3><p>ANAND: Right as we're talking, I get a news alert: “<a href="https://www.nytimes.com/2020/12/09/technology/facebook-antitrust-monopoly.html">Facebook illegally crushed competition by buying up its rivals, according to lawsuits filed by 48 states and federal regulators</a>.” So this is the big case that we've been waiting for. Can you explain to a person who has never focused on this issue before in their life, and who just uses Facebook to try to get with their high-school ex, why is this a big deal? What does this mean?</p><p>MATT: So Facebook is a financial conglomerate. People think of Facebook as that website you use or the app that you use, but really Facebook, as a political institution, is a financial conglomerate and owns dozens of different companies, including Instagram and WhatsApp and Facebook, the social network. And it's a giant advertising company. So they have roughly three billion users. And they try to get their users to do things that their advertisers want them to do, because that's how you sell advertising.</p><p>The business model is to divert revenue that used to go to newspapers and publishers to themselves. And so by manipulating people in this specific way that they do, which is to keep them using their system and keep surveilling them so that they can target them with ads, they are, in the process, crushing newspapers and publishers, who no longer have any financing, particularly local newspapers and niche publications like Black-owned newspapers.</p><p>So increasingly those kinds of publications don't exist. You don't have reporters covering state houses and city halls and whatnot. Instead, people are now consuming things that Facebook likes them to consume because it keeps them using, and it keeps them available to sell ads to them, which are anti-social publications or posts, like anti-vax stuff or QAnon or whatever it is.</p><p>So that's the basic problem. It's a $70-, $80-, $100-billion-a-year revenue company that's destroying newspapers and publishers all over the world and getting people to pass conspiracy theories to each other so that Facebook can make money on advertising.</p><p>ANAND: You're an anti-monopoly guy. If there were three or five companies in healthy competition with each other, all doing exactly what you just described, wouldn't it still be problematic? Is the issue here that there's only one of them of that heft, or would a competitive market with five such players still be incredibly troubling?</p><p>MATT: There's a lot more that you have to do than just break them up. But the answer is, it would improve things dramatically if they were broken up, and you don't have to imagine it.</p><p>There used to be a bunch of social networks. Facebook's main competitor was Myspace, but there were a bunch of others. There was BlackPlanet; there was Friendster. And the way that Facebook actually defeated Myspace was by promising a safer, more private experience. They defeated Myspace by saying, We will treat your data carefully; in fact, when we change the terms of service, we will let our users vote on the terms of service.</p><p>This was back in 2007, 2008, 2009. And once they killed their competition, and then they bought up nascent competitors like Instagram and WhatsApp, then they didn't have to compete by offering a higher-quality service, a.k.a one that was less intrusive in terms of surveillance. They could just surveil anybody they wanted, and you didn't really have a choice.</p><p>ANAND: Where do you think this case is going?</p><p>MATT: They’re going to aim to break up the company. The House Antitrust Subcommittee did this long investigation of big tech, which includes Facebook. And one of the things they found is that Mark Zuckerberg was writing emails saying they were buying these companies to block competition. And so that's evidence that the mergers were illegal, because you're not supposed to buy companies to block competition. That's a violation of the Clayton Act. My guess is that they're going to have a pretty good complaint.&nbsp;</p><p>ANAND: Based on the history of such cases, would your assumption be that Facebook is broken up within a period of years?</p><p>MATT: Yes.</p><p>However, we haven't enforced the law for 20 years, so it’s not entirely clear. The law at this point is crazy and incoherent because we haven't done enforcement, and to the extent that we have, judges have just made wildly inconsistent rulings.</p><p>ANAND: This kind of action that's being announced today is the epitome of a systemic, public response to a problem. And when I, like you, advocate for those types of things, I often hear this response that I'm sure you do, too, which is, “OK, that's fine, but what about individual actions?” A lot of people are like, “Yes, let’s delete Facebook.” Or: “Why aren't you supporting the Facebook boycott?”, and there are different views on it.</p><p>There are some people who make the argument that those kind of small personal things are sideshows, distractions, maybe even unhelpful, because they reduce the perceived need for bigger systemic change. I fall more into that camp. There are others who say it's a gateway drug, it's a waystation, like: “Delete Facebook and then work yourself up to a political response." How do you weigh in on that?</p><p>MATT: I think it's a bad vision of politics. It's not doing politics to say, “Me, as a consumer, I can change power arrangements based on what I consume or don’t.” That's a real 1970s consumer-rights Democrat vision of the world, and that's one in which you as a citizen are irrelevant.</p><p>A boycott is only political if the goal is a policy change. If you go in and you say, "Well, I don't like Facebook, I want to change Facebook, so I'm going to delete Facebook," that's not going to do anything. If it's part of some larger political action saying, "Well, I'm going to delete Facebook, and then I'm going to push policymakers to break it up," I mean, I guess that makes sense.</p><p>But the general view of these boycotts is that just not using Facebook is the political action. But that's actually not a political action.</p><p>ANAND: An issue like monopoly is different from, say, healthcare, where you don't have to explain to most people the problem with our healthcare system. How do you think about making the issue of monopoly real to people and vivid and relevant to their lives?</p><p>MATT: I'm going to challenge the premise. I don't think monopoly is an <em>issue</em>. I think monopoly is a worldview.</p><p>My book is called “<a href="https://www.simonandschuster.com/books/Goliath/Matt-Stoller/9781501182891">Goliath: The 100-Year War Between Monopoly Power and Democracy</a>.” Anti-monopolism is a lens through which you understand power, and particularly commercial power. That’s the lens that I see the world through. And I don't just focus on Facebook or Google. I’m focused on anti-monopolism in general. How you use business institutions to coerce and bully — or liberate — other people in your society.</p><p>There's a monopolist who controls the cheerleading industry, which is very weird. I just learned there is a private-equity company that is trying to monopolize the software that churches run. There is a monopoly of Ultimate Fighting Championship-style contests. And then in healthcare there are endless numbers of monopolists. Ultimately, what a monopolist is is a person or institution that is controlling and governing a market. It's a private government versus a public government.</p><p>ANAND: You’re saying it’s incompatible with democracy.</p><p>MATT: Right. It’s a different system. When Mark Zuckerberg says he’s going to arrange electoral discourse in this particular way, or going to start a <a href="https://www.businessinsider.com/meet-the-first-20-members-of-facebook-supreme-court-2020-5">Supreme Court</a>, or going to ban this or allow that, he is operating as the global privacy commissioner. <a href="https://www.vox.com/the-big-idea/2018/4/9/17214752/zuckerberg-facebook-power-regulation-data-privacy-control-political-theory-data-breach-king">He even said</a>, "In a lot of ways Facebook is more like a government than a traditional company." That's a direct quote.</p><p>As a society, the way we do business is the way we do justice.</p><p>ANAND: Understanding how these platforms work, do you think that if Mark Zuckerberg wanted to tip an election, he could? Would that even be illegal under our current system?</p><p>MATT: I don't know if it's possible, but it's certainly legal if he decided to.</p><p>I listened to this podcast with Zuckerberg where he said — this was right before he became unpopular, so he was still being relatively …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://the.ink/p/we-can-have-democracy-or-we-can-have">https://the.ink/p/we-can-have-democracy-or-we-can-have</a></em></p>]]>
            </description>
            <link>https://the.ink/p/we-can-have-democracy-or-we-can-have</link>
            <guid isPermaLink="false">hacker-news-small-sites-25383976</guid>
            <pubDate>Fri, 11 Dec 2020 09:48:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No, engineers don't suck at time estimates]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25383838">thread link</a>) | @bbu
<br/>
December 11, 2020 | https://blog.nukemberg.com/post/no-engineers-dont-suck-at-estimates/ | <a href="https://web.archive.org/web/*/https://blog.nukemberg.com/post/no-engineers-dont-suck-at-estimates/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main"><div><div><article role="main"><p>No, engineers don’t suck at time estimates - and generally speaking humans are better estimators than what most people believe. This seems rather surprising given all we’ve heard about the problems of bad time estimations, projects going overboard, etc and of course, your personal experience with software time estimates. But if people are really bad at estimation, how does that fit with our obvious evolutionary need to make quick decisions based on partial data? if we can’t estimate well how did we decide if a gap is wide enough to jump over, if an animal is worth the hunt, if a certain area is more likely to have water and shade? Without estimation skills we wouldn’t survive. So what’s going on?</p><p>One obvious explanation is that we are only good at estimating physical things such as sizes and distances. However, this does not seem likely given the large number of non-physical decisions we needed to make, like selecting a mate.
Another, more likely explanation is that the estimates are good, but the interpretation and usage of the estimates is flawed. In other (slightly cynical) words: the engineers are good at estimating, it’s the project managers who suck at using the estimates.</p><p>Let me explain.</p><p>“your estimate was wrong” - is something i’ve heard many times. But this sentence doesn’t make any sense… after all, an estimate is by definition not exact; in fact, if the results would always agree with estimates foul play would be immedialy suspected. If I estimated one day and the actual time was 1.5 days, was I “wrong”? most people would say I wasn’t. But if if the actual time was 20 days most people would argue I was wrong. Somewhere between one and 20 days there is an implicit “reasonable error” threshold we never discussed! I never gave an error margin for my estimate, did I?</p><p>Since we don’t expect an estimate to be an exact guess of the actual value, what do we expect from an estimate? When we make decisions based on estimates, we can only be right or wrong in our decision, you can’t be “a lot more right”. We need to guess a value beyond a certain threshold and within a certain tolerance, with high probability of being right because that our lives depend on that gap being just short enough for us to jump over. Decisions are almost always non-linear like that and it should not be surprising given the nature of knowledge and learning. We take in examples and extrapolate patterns and behaviours. Which means we are dealing with groups, and probability distributions. This may be surprising at first, because when you are estimating this one <em>particular</em> job, you don’t think of a distribution of a million other <em>different</em> jobs. An estimate is predicting the future in which we see the actual value.
</p><div><figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject"><p><img itemprop="thumbnail" src="https://blog.nukemberg.com/img/time-estimate.jpg" alt="/img/time-estimate.jpg"></p><a href="https://blog.nukemberg.com/img/time-estimate.jpg" itemprop="contentUrl"></a></figure></div><p>What we need to know, is that in a certain number of futures, say 90% of them, a value won’t be over or under a certain threshold. Or phrased mathematically, that the 90th percentile of the distribution of futures will be over (or under) a certain number. An estimate is a percentile! but which percentile? is it the median? the 99th?
For software time estimates it has been <a href="https://erikbern.com/2019/04/15/why-software-projects-take-longer-than-you-think-a-statistical-model.html">observed to be the median</a> (50th percentile), meaning to be right about half the times. Is this inherent? Estimates can desmonstrably be calibrated to higher percentiles by as little as <a href="https://www.tonym-v.com/blog/2019/10/2/improve-your-estimations-with-the-equivalent-bet-test">brief emotional self manipulation</a>; You could easily estimate the 90th percentile of many things - just read <a href="https://www.amazon.com/How-Measure-Anything-Intangibles-Business-ebook/dp/B00INUYS2U">How to measure anything</a>.</p><p>Usally when I tell this to people, they often respond with “we’ll train to estimate the average”. Sadly, this is not possible. The mean is a statistically “unstable” or “unrobust” aggregate, where as percentiles are “stable” or “robust”. Consider a group of task completion times [73, 67, 12, 38, 18, 11, 42]. The mean is ~37.29 and the median is pretty close, 38. But as soon as we get another measurement, say 293, the mean changes significantly to 69.25 while the median changes only slightly to 42. The mean is sensitive to outliers, and the more skewed and high variance the distribution the less robust and stable it will be.</p><p>Having estimated tasks, what do we do with them? We sum them up.</p><p>Either for project budget or for by enqueuing with the next tasks, we sum them. But wait, we know that percentiles are not additive! how can this ever work? it never does. Summing up percentiles compounds errors and with skewed distributions, and in particular heavy tailed distributions, the errors are very large. Let’s have a look at what a task completion time distribution would look like:</p><div><figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject"><p><img itemprop="thumbnail" src="https://blog.nukemberg.com/img/task-time-distribution.png" alt="/img/task-time-distribution.png"></p><a href="https://blog.nukemberg.com/img/task-time-distribution.png" itemprop="contentUrl"></a></figure></div><p>A task has some minimum time it has to take, but beyond that it can pretty much take as long as inifinity. We all know from experience, that when things get out of control they go wayyyy out of control. Once you hit a rare bug, you might be chasing a wild goose for two months. That 10% over the estimate might be a day late or a year, the higher percentile you pick the more extreme the errors relatively.</p><p>To be honest, it’s old news; This has been known for a long time. Percentile based project predictions have been done as early as World War II, perhaps even before that - yet they remain fairly unknown in the industry. Not only are we ignorant of proven methods, we invent new ones which are outright harmful. Remember that burn down chart? the <em>backlog</em> is nothing more than a sum of time estimates! And every two weeks, sitting in the famous sprint retrospective people work to calibrate their estimates to the random walk sum of task completion times on the burndown chart. How do you calibrate a percentile to a sum? If the distribution is something like a log-normal distribution, the random walk sum will converge to the mean, and the median is relatively close to the mean - which is summable, and both are pretty stable. So by repeatedly calibrating estimates to the running-sum of task completion times (the backlog) you will converge close to the median. Now go tell your project manager there is a 50% chance of their project running late, anywhere between a day and eternity, and see how they respond. A 50% chance of uncapped delay is a useless estimate.</p><p><strong>Scrum is a training method for useless time estimates</strong>. It actively destroys your ability to manage your project.</p><p>Don’t get me wrong, I’m not against Agile; The spirit of Agile, some of the methods and ceremonies of Scrum have value. But Scrum <em>as a system</em> is actively harmful, especially in high variance situations where the work is far from the nice log-normal distribution. If you <a href="https://blog.nukemberg.com/post/the-burndown-chart-fallacy/">optimize for an arbitrary metric</a>, you will get arbitrary results. In ops/SRE and pure research many people have intuitive sense that Scrum and traditional project management are wrong, although they can’t quite articulate why. The reasons become very clear when we consider what happens to sum based project management methods if the task distribution becomes heavy tailed. A task that is one week late is likely to take <em>at least</em> one more week - is a common thumb rule in such domains; This is called a “Power law” and can be modeled by the famous Pareto distribution. The thing about the Pareto distribution is that its mean does not converge! In other words, using sum based planning methods with such distributions is equivalent to managing by rolling dice. A little worse actually, as dice are a cheap method of generating random numbers where as time estimates are intrusive and sometimes expensive. This isn’t a problem unique to Scrum, nor does it originate from it. The problem is the assumption of determinism and accuracy which is the prevaling “machine age” mindset. Pretty much all of the common project management tools have the same issue - have a look at a Gantt chart, it has no probability intervals or error ranges. They are all worse than useless. It shouldn’t be a surprise that despite people being bad at estimating large tasks naive estimates are reliably more accurate than project management tools.</p><p>Recognizing the probabilistic nature of the world is key. Probability isn’t a tool for making predictions, it is a tool for quantifiying uncertainty. Instead of managing resources (which are usually highly certain) we should be managing uncertainty, with probabilistic methods appropriate for the task. With this mindset, the first thing to do is understand the business context and the distributions involed: are you in a low or high variation domain? Industrial methods which aim to improve throughput and efficiency all assume low variance, sometimes actively force low variance by getting rid of outliers; this isn’t necessarily possible in your business context. Industrial methods are good when used in context, but horrible when used in high variability and unpredictable domains. For those we have other methods, which emphasize low latency and rapid adaptation. Instead of Scrum, you could try:</p><ul><li><a href="https://www.joelonsoftware.com/2007/10/26/evidence-based-scheduling/">Monte-Carlo simulations based on time estimates</a></li><li><a href="https://basecamp.com/shapeup/2.1-chapter-07">Time boxing and bets</a></li><li>Latency optimizing methods which dispense with time estimates, like Kanban</li></ul><p>I’ve listed the methods above in order of rising uncertainty, Monte-Carlo simulations or time boxing would probably be easiest to start with. The biggest obstacle in implementing these is convincing managers that “predictability” isn’t so important as they imagine. For high variation domains it’s nothing more than a fantasy anyway.</p><p>So there you have it: people don’t suck at estimation. They suck at management 🤷</p><hr></article></div></div></div></div>]]>
            </description>
            <link>https://blog.nukemberg.com/post/no-engineers-dont-suck-at-estimates/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25383838</guid>
            <pubDate>Fri, 11 Dec 2020 09:21:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kubernetes Operators 101]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25383807">thread link</a>) | @evenh
<br/>
December 11, 2020 | https://thecloud.christmas/2020/11 | <a href="https://web.archive.org/web/*/https://thecloud.christmas/2020/11">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><main id="main-content"><article><img src="https://i.imgur.com/PRCyBqa.jpg" alt=""><div><section><p>Kubernetes has become the <em>de facto</em> container orchestrator since it's initial release in 2014. It is a great tool for managing diverse workloads in clusters of machines, possibly spanning multiple availability zones. As the usage grows, new requirements for how to deploy and operate specialized software emerges. The Operator pattern is one of the more prominent responses to these new requirements.</p>
</section><article><section><p>The Operator pattern is best described in the <a href="https://kubernetes.io/docs/concepts/extend-kubernetes/operator/">official Kubernetes documentation</a>:</p>
<blockquote>
<p>The Operator pattern aims to capture the key aim of a human operator who is managing a service or set of services. Human operators who look after specific applications and services have deep knowledge of how the system ought to behave, how to deploy it, and how to react if there are problems.</p>
<p>People who run workloads on Kubernetes often like to use automation to take care of repeatable tasks. The Operator pattern captures how you can write code to automate a task beyond what Kubernetes itself provides.</p>
</blockquote>
<p><strong>TL;DR</strong> Operators automate operation of applications and services with human know-how.</p>
<h2>How does an Operator work?</h2>
<p>An Operator consists at a minimum of one Custom Resource Definition (<code>CRD</code>) and a Controller. The <code>CRD</code> describes the various configuration options for this kind of resource. Given a custom resource for a <code>PostgresDatabase</code>, one might find options for specifying custom <code>StorageClass</code>es, resource allocation, backup schedule/destinations, authentication methods, etc.</p>
<p>Given an instance (<code>CR</code>) of <code>PostgresDatabase</code>, it's now the job of the controller to ensure that the desired state is reconciled with the cluster. In this example one can assume that the controller will create a <code>StatefulSet</code> for running the database itself, along with needed configuration in a <code>ConfigMap</code>, certificates for mutual TLS in a <code>Secret</code>. Backup can be done by either mounting and writing to a volume defined in the <code>CR</code> or injecting a sidecar for sending backups to another location.</p>
<p>Patching, reboots and failovers can be specified in the <code>CR</code> and taken care of by the controller, using methods recommended by experienced DBA's. The fact that complex operational knowledge can be encoded into the controller is a key enabler for many organizations that would like to run complex software, but not necessarily invest countless hours into learning the nitty-gritty details on how to operate it.</p>
<p>Like any other software there will be bugs and abstractions will leak. There's no silver bullet.</p>
<h2>How do I create my own Operator?</h2>
<p>As with the rest of the Kubernetes community, multiple solutions exists.</p>
<ul>
<li>For a declarative experience, check out <a href="https://kudo.dev/">KUDU</a></li>
<li>If you'd like a more official way to do it, see <a href="https://github.com/kubernetes-sigs/kubebuilder">kubebuilder</a></li>
<li>The most popular option seems to be <a href="https://github.com/operator-framework/operator-sdk">Operator SDK</a></li>
</ul>
<p>As with most cloud native software, Go seems to be the lingua franca. There is nothing stopping you from writing an Operator in Java, C#, Python or any other language that can communicate with the Kubernetes APIs.</p>
<h2>Examples of known Operators</h2>
<p>The community has produced a lot of Operators for about everything one can imagine. These are some popular examples:</p>
<ul>
<li><a href="https://github.com/argoproj/argo-cd">Argo CD</a> – a  declarative, GitOps continuous delivery tool for Kubernetes.</li>
<li><a href="https://github.com/jetstack/cert-manager">cert-manager</a> – automatically provisions TLS certificates via the ACME protocol. Can be used with certificate issuers such as <a href="https://letsencrypt.org/">Let's Encrypt</a>, <a href="https://www.buypass.no/ssl/resources/acme-free-ssl">Buypass</a> and <a href="https://zerossl.com/documentation/acme/">ZeroSSL</a>.</li>
<li><a href="https://github.com/prometheus-operator/prometheus-operator">Prometheus Operator</a> – often used in combination with <a href="https://github.com/prometheus-operator/kube-prometheus">kube-prometheus</a> for a batteries included monitoring suite</li>
<li><a href="https://kubedb.com/">KubeDB</a> – a real-life implementation of the <code>PostgresDatabase</code> example, plus support for MySQL/MariaDB/MongoDB/Redis/Memcached and more</li>
</ul>
<p><small>Header image: RIA Novosti archive, image #305015 / Alexey Danichev / CC-BY-SA 3.0</small></p></section></article></div></article><section><ul><li></li><li></li></ul></section></main></div></div>]]>
            </description>
            <link>https://thecloud.christmas/2020/11</link>
            <guid isPermaLink="false">hacker-news-small-sites-25383807</guid>
            <pubDate>Fri, 11 Dec 2020 09:13:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Life in the Baby Universe: The Physics of Babies (2014)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25383711">thread link</a>) | @philshem
<br/>
December 11, 2020 | https://smalldata.dev/posts/physics-of-babies/ | <a href="https://web.archive.org/web/*/https://smalldata.dev/posts/physics-of-babies/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><sub><em>This article was originally published in</em>
<a href="https://physicsworld.com/a/the-september-2013-issue-of-physics-world-is-out-now/" target="_blank" rel="noopener"><em>Physics World</em></a> <em>September 2013, copyright IOP Publishing, reproduced here with permission.</em></sub></p><p><img src="https://smalldata.dev/images/baby_physics/header.jpeg" alt="header image - baby with avocado face"></p><hr><p><strong>I became a first-time father</strong> around the same time my postdoc contract ended. My wife had another year to finish her PhD, so I took a sabbatical to be a stay-at-home dad. My months away from research were intended to be full of fun projects. And relaxation. It was to be the Year of Naps – or so I thought.</p><p>Unfortunately, while physics problems have solutions that are constant, baby-related problems have solutions that are random and change from day to day. What had worked yesterday will not work today. Maybe it will work tomorrow. This is the gist of the Baby Universe. In this universe, time only means a start and a finish, and contains no information in-between. If the physicist-dad discovers a method to get the baby to eat her breakfast, it is unlikely to work by dinner. This is significant because eating is one of four fundamental dimensions of the Baby Universe, and the same principle of random solutions also applies to the other three: playing, crying and sleeping. (Some scientists consider pooping to be a separate dimension. However, I can assure you that this is always included as part of one of the other four.)</p><p><img src="https://smalldata.dev/images/baby_physics/sarah_photo.jpeg" alt="baby - who me?">
<sup>Photo credit :
<a href="https://www.sarahperryphotography.com/" target="_blank" rel="noopener">Sarah Perry</a></sup></p><p><strong>The first challenge</strong> in my physicist-to-dad transition came with my inability to feed my daughter naturally. My thesis-writing wife’s fresh-pumped milk was in demand and its administration required complex algorithms for its optimal, timely use. Solid food, once introduced, posed a whole new set of problems, as each spoonful required extensive parental coercion. This may have had its upsides: recent research shows that the more you talk to your child, the higher the child’s IQ will be. The fine print that the researchers don’t mention is that this IQ boost comes at your expense, as you must donate those IQ points to the child via non-stop one-way conversations: “Look. Yams. Mmmmm. You like yams. You liked yams yesterday. Oooh, yaaaaaams.”</p><p>Later, my daughter acquired a rudimentary ability to feed herself, and the physics of the eating dimension became more complex. If I offer her a spoonful of food, she comes running to see what is on the spoon. If the food is not to her liking, she is scattered like a charged particle from a similarly charged hard sphere. But when, instead, a sticky ball of white rice is presented to her, it triggers a primal urge to make chaos. The “entropy of rice” principle dictates that the dispersion of rice across a 2D “table” is sudden, yet erratic. After adequate time, every grain of rice is scattered into a circle with a radius equal to one baby arm. Given infinite time, it is predicted that babies would not rest until every grain of rice was at every end of the universe.</p><p><img src="https://smalldata.dev/images/baby_physics/yogurt_face.jpeg" alt="baby - yogurt face">
<sup>Photo credit : Debby Shemella, aka Grandma (2012)</sup></p><p>As the preceding paragraph indicates, the “eating” dimension of the Baby Universe is closely coupled to the “playing” dimension. Before she could crawl or walk, my daughter would nevertheless want to change her position during playtime. She employed the theory of relativity to satisfy this urge: by moving her playmat from underneath her, she could therefore move herself off the mat. Once mobile, she liked to increase her potential energy by dragging herself up and onto whatever obstacle she could find. If stairs existed, that obstacle was most definitely stairs. This is unfortunate, because although babies understand gravity if they are dropping something (and can even anticipate the “Boom!” the object makes upon impact), they have no comprehension of gravity if they are the body upon which it is acting. It is therefore the physicist-parent’s job to decrease the baby’s potential energy whenever it grows too large, and it is the baby’s work to regain what was taken away.</p><p><iframe src="https://www.youtube.com/embed/RbAYEdjcyjc" allowfullscreen="" title="YouTube Video"></iframe></p><p><sup><em>The
<a href="http://www.pechakucha.org/" target="_blank" rel="noopener">PechaKucha</a> talk that started this research.</em></sup></p><p>The two remaining dimensions of the Baby Universe – crying and sleeping – are also tightly coupled. To deal with daytime crying sessions, I devised a “terror threat level” system of graded responses, with passivation techniques such as singing, dancing, guitar and something I copied from
<a href="https://www.youtube.com/watch?v=eCLp7zodUiI" target="_blank" rel="noopener">Monty Python’s “Ministry of Silly Walks”</a>. For inducing sleep, I adopted similarly complex patterns of rocking, bouncing, walking, singing, shushing and waiting. Some of these patterns involved a Swiss ball – a large, inflated exercise ball that serves as a rocking chair for the 21st century. This ball has harmonic degrees of freedom in the side-to-side and front-to-back directions as well as the primary up-and-down one, and is essential for bouncing and rocking a baby to sleep. In addition, it is good for the physicist-parent’s core strength, and can be easily deflated and packed up before relocating for yet another postdoc.</p><p>Once the baby is asleep, the physicist-parent is faced with the challenge of escaping the room – in my case over creaky hardwood floors. Doing this before my daughter realizes she is asleep requires knowledge of the “path of least noise”. Once I have exited the room, though, I have a dilemma. No sounds come from the crib. Is my daughter asleep or awake? A measurement is required. As I silently slide on my socks into the dark room, my measurement wakes her and her original state remains unknown. This is Schrödinger’s baby.</p><p><strong>My time at home</strong> has been a great period in my life and I know I will miss this when I’m back at work. As I write this essay in my head, my daughter rests on my shoulder. Her breathing turns to snoring and I synchronize my own breathing to be in phase with hers. Together we plan all the things I need to do during her naptime. I definitely don’t have time for a nap of my own.</p><hr><p><img src="https://smalldata.dev/images/baby_physics/author_muse.jpeg" alt="author and muse">
The author and his muse (2013)</p><hr><p><sup>This article is also available on
<a href="https://medium.com/@philshem/life-in-the-baby-universe-f52561c4a8ae" target="_blank" rel="noopener">Medium</a>.</sup></p></div></div>]]>
            </description>
            <link>https://smalldata.dev/posts/physics-of-babies/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25383711</guid>
            <pubDate>Fri, 11 Dec 2020 08:52:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Rise and Fall of Ambrosia Software (2019)]]>
            </title>
            <description>
<![CDATA[
Score 132 | Comments 119 (<a href="https://news.ycombinator.com/item?id=25383485">thread link</a>) | @kaptain
<br/>
December 11, 2020 | https://lifeandtimes.games/episodes/files/pax-aus-19-ambrosia-sw-talk | <a href="https://web.archive.org/web/*/https://lifeandtimes.games/episodes/files/pax-aus-19-ambrosia-sw-talk">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>While I'm away on my honeymoon, here's my complete talk from PAX Australia 2019, on the rise and fall of legendary shareware publisher Ambrosia Software.</p><p>For Mac gamers in the 90s, the people of Ambrosia Software were rockstars. Heroes. And with brilliant games like Maelstrom, Escape Velocity, Harry the Handsome Executive, Apeiron, and more, plus a company newsletter that spoke directly to the fans, they could do no wrong. In light of Ambrosia's recent closure (finally!), Secret History of Mac Gaming author Richard Moss recounts the studio's high and lowpoints and tells the stories behind its best games.</p><p>Thanks as always to my supporters on Patreon — especially my $10+ backers Vivek Mohan, Simon Moss, Wade Tregaskis, Eric Zocher, and Seth Robinson. And a very big thank you (and warm welcome!) to my five new patrons this month. If you'd like to become a supporter, for as little as $1 a month, head to <a href="https://www.patreon.com/lifeandtimesofvideogames" target="_blank">my Patreon page</a> and sign up.</p><p>There'll be no regular episode of The Life &amp; Times of Video Games this week because I'm off on my honeymoon. But to tide you by until I'm back, I thought you might enjoy listening to my talk from PAX Australia 2019 about the lesser-known of the indie game publishing giants from before the time of Braid and Steam and all that other stuff we've had over the past 15 years.</p><p>The talk was called The Rise &amp; Fall of Ambrosia Software, '90s Mac Legends, and you can find accompanying slides at <a href="https://tinyurl.com/paxausambrosiatalk" target="_blank">https://tinyurl.com/paxausambrosiatalk</a> as well as my full script on the accompanying blog post at lifeandtimes.games. So please, enjoy, and I'll see you in a couple of weeks.</p><div><p><em>[note that this won't correspond exactly to the audio, as it was my written script rather than what I actually said. If you're looking at the slides, "[NEXT]" means go to the next slide.]]<br></em><br>Hello everyone. My name is Richard Moss, and today I'm going to talk to you about a company that's pretty near and dear to my heart, not only as someone who grew up playing some of their games — [NEXT] but also as the author of a book called The Secret History of Mac Gaming, which covers their history, along with lots of other games and game developers from the 1980s and 90s Mac gaming scene. [NEXT]</p><p>If you were a Mac gamer in the late 90s, chances are pretty high that you would have had at least one game in your collection that came from Ambrosia Software. [NEXT] They were heroes among the Macintosh faithful, one of only a few companies that made its games exclusive to the Mac. And arguably the best among them in terms of the quality of its output.</p><p>Games like [NEXT] Maelstrom, [NEXT] Escape Velocity, [NEXT] Ferazel's Wand, [NEXT] Apeiron, and [NEXT] Bubble Trouble were hallmarks of quality, even if most of them were essentially just jazzed-up versions of classic 80s games. And they had top-drawer offbeat gaming options, too, with titles like [NEXT] Avara, a kinda abstract-looking arena-style first-person shooter, and [NEXT] Harry the Handsome Executive, where you guide a middle management executive through an office electronics apocalypse while scooting around in a swivel chair.</p><p>For about 15 years or so, from 1993 to around 2008, the Ambrosia Software name was inseparable from quality Macintosh games. But then it faded rapidly into the background, for reasons I'll get to later, and finally the company closed its doors at the end of last year.</p><p>***</p><p>So in recognition of Ambrosia's achievements, which have slipped a bit under the radar outside of the old-school Mac faithful, I wanted to give you a tour through the company's rise and fall. </p><p>There's not enough time to cover everything, but I'll try to get to all the key stuff and you'll hopefully come away with a good sense of a) why Ambrosia Software matters to the history of computer games and b) what made Ambrosia special to the Macintosh flock. </p><p>I've got some interview clips, a bit of gameplay footage, some photos and old documents to help us along the way. I wanted to set up an emulator as well but just ran out of time unfortunately. And hopefully there'll be plenty of time at the end for questions and stories from you in the audience.</p><p>But before we go into rise and fall of Ambrosia, let's do some quick background. First, on Ambrosia founder Andrew Welch. Then second on the Mac gaming scene in the early 90s.</p><p>[NEXT] So, Andrew Welch. His dad owned a marketing company, and it was through that business that young Andrew planted the seed for what would become Ambrosia. When he was something like 12 or 13 years old, he found the company's library of books and documents on typography. He thought it was cool, so he learnt how to design his own typefaces on his Macintosh. Then, starting from age 14 or so, he sold them on America OnLine.</p><p>But most people doing this sold their fonts without any documentation at all, so there was no way to know after the fact who made it, how to pay for it, who to contact for support, and so on. So Andrew taught himself how to code a utility program that could wrap his fonts in a simple document reader thing.</p><p>He enjoyed coding so much that he kept doing it, and made various other utilities for his relatives. Then he went off to college to study photojournalism and in his spare time he created [NEXT] his first game, a Wheel of Fortune clone called Wacky Wheel.</p><p>[NEXT] [show it in action]</p><p>This was kind of par for the course with small Mac games at the time. There were lots of people putting out crappy little games as freeware or shareware, but even the rare good ones weren't really making anything more than pizza and beer money.</p><p>[NEXT] Or literally beer.</p><p>Quick definition of shareware: [NEXT] it's software that you give away, free, but you ask that if someone likes it they pay you a registration fee — which, depending on the exact implementation, might get that person customer support or free updates or maybe just remove the nag screen from the boot-up process.</p><p>[NEXT] This is a pretty typical shareware notice, taken from an early DOS game.</p><p>Over on the PC side, shareware had already taken off. [NEXT] Apogee Software and Epic MegaGames were making a fortune working with independent developers and selling their games in a clever twist of the standard shareware model called The Apogee Model. Instead of giving away the whole thing for free and requesting that people pay if they like it, Apogee and Epic's games were [NEXT] episodic — episode one distributed freely over the internet and BBSs and through mail-order floppy disks, and all subsequent episodes available to order for a set fee.</p><p>I'm actually writing a book about this stuff, so if you're curious to learn more ask me about it later.</p><p>And id Software were just starting to make their name at this point as well. [NEXT] Wolfenstein 3D dropped in 92, then [NEXT] Doom in 93, both published as shareware on PC through Apogee. </p><p>So the time was ripe for shareware to step up and hit the big time on the Mac side, too. The Mac was at the peak of its [NEXT] pre-iMac popularity. College kids across the United States had Macs set up in their dorm rooms, while creative professionals all around the world had taken up the Mac mantle and were keen for more time-wasters to get them through the lulls in their output.</p><p>But there weren't many games coming out — the porting industry, which took PC games and put them on Mac, was still in its infancy after struggling with the [NEXT] peculiarities of adapting games for the Mac's multi-window mouse and menu-driven interface. Truly cross-platform commercial computer games that had concurrent Mac and PC releases were still rare (though there were a few special ones like [NEXT] SimCity 2000), and Mac-first development had gone into a bit of a lull (for a variety of reasons) at the end of the 1980s — from which it had yet to fully recover.</p><p>So there was lots of room for a great new Mac-native game to stand out.</p><p>And, crucially for our story here, someone was wrong on the Internet. I'll let you hear this bit straight from Andrew: [NEXT]</p><p><em>AW: I think it was the summer after maybe my freshman year of college that someone had said — I think it was called the Mac IIci or something like that. It was one of the colour Macs that came out. And someone had said something about the fact that while it was too slow to do decent animation on — and by that point in time I had actually taught myself for Assembly language, as well. So I set out to prove this guy wrong, because it's always fun to try to prove someone on the Internet that they're wrong. <p>*laughs* So, yeah, so that's how I started writing — and I really wasn't sure what I was going to do yet — but I started writing some kind of animation stuff. I grew up going to a lot of the arcades where we played games like Asteroids and Centipede and that type of thing where after school I would get dropped off there and play. So I decided to make an Asteroids-based game.</p></em></p><p>[NEXT]<br>He asked a couple of friends to help him out with the graphics, and got together with a few of his college buddies and a microphone to make a bunch of silly noises and record stuff off the TV for sound effects.</p><p>They pulled liberally from pop culture, drawing tiny clips and references (without permission) from all over the place, kind of like the wall of sound that early hip-hop and remix culture had.[NEXT]</p><p>He called the game Maelstrom and put it online as shareware, published under the name Ambrosia Software — a name he pulled from Greek mythology. You could play it and share it freely, but it'd nag you to send in a cheque to register every time you booted the game. And a lot of people did. [NEXT]</p><p><em>everyday we would go to the mailbox and there'd be letters from all over the world. I just had a blast. I thought it was really really cool that I could do something just sitting in my room in upstate New York, which was where I was at the time. And I got these contacts from all over the world. I thought that was really really cool, and it was at a time where people were just starting to get connected online.<p>Like now it's no big deal — you can go on …</p></em></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lifeandtimes.games/episodes/files/pax-aus-19-ambrosia-sw-talk">https://lifeandtimes.games/episodes/files/pax-aus-19-ambrosia-sw-talk</a></em></p>]]>
            </description>
            <link>https://lifeandtimes.games/episodes/files/pax-aus-19-ambrosia-sw-talk</link>
            <guid isPermaLink="false">hacker-news-small-sites-25383485</guid>
            <pubDate>Fri, 11 Dec 2020 08:05:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ransomware – A Devastating Form of Digital Extortion]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25383148">thread link</a>) | @roberla
<br/>
December 10, 2020 | https://security.christmas/2020/11 | <a href="https://web.archive.org/web/*/https://security.christmas/2020/11">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>We live in a digital era where the most precious commodity no longer is oil or gold, but data. But what if this data, including personal files, customer lists and company data, flight traffic information, or even sensitive hospital records were stolen? What would you do, or pay, to get it back?</p>
</section><article><section><p>Ransomware has been on the rise the past years, where criminals effectively take all the data on your computer hostage and demand a ransom to give it back to you. Refusing to pay may result in your data being lost permanently. </p>
<p>Everyone is a potential target for ransomware, including single individuals, small to large companies, and even public institutions. A disconcerting trend is the targeting of hospitals and the public sector. Only last year the Hollywood Presbyterian Medical Center in Los Angeles was <a href="https://sanfrancisco.cbslocal.com/2016/02/18/california-hospital-ransomware-attack-hackers/">attacked by ransomware</a>, blocking the company’s access to their own network and crucial patient data for 10 whole days. The hospital ended up paying the ransom of $17 000 in bitcoin to decrypt the data. </p>
<p>The demands have also increased drastically the last few years, where the <a href="https://www.coveware.com/blog/q2-2020-ransomware-marketplace-report">average ransom payment</a> having increased to an exorbitant $178 000 in Q2 of 2020. Some bigger companies also receive very high demands. For instance, Garmin was attacked in 2020 with an initial ransom demand of $10 million, which some <a href="https://www.bleepingcomputer.com/news/security/confirmed-garmin-received-decryptor-for-wastedlocker-ransomware/">sources</a> claim they chose to pay. And this does not include the costs of other factors such as downtime, loss of revenue, mistrust from consumers, and resources used to get everything up and running again. </p>
<p>Clearly, ransomware is a growing problem with an increase in both attacks and in the ransom demands themselves, as well as the targeting of sectors with the possible consequence of directly endangering lives. </p>
<p>But how to the criminals make their attacks so successful, either forcing a victim to pay or having to accept the loss of their data? The main principle of ransomware is that attackers will encrypt all the files rendering them unreadable, and only by buying the key to decrypt the files will they be accessible again. The first step to achieve this, is to obtain access to a computer or network in order to install the ransomware. </p>
<h2>How does ransomware get installed on my computer?</h2>
<p>Ransomware is a type of malware, which is a malicious piece of software that installs itself without permission on someone’s computer or even an organization’s whole system. The most common ways the attackers get access to your computer are:</p>
<ol>
<li>Phishing – a cyber-attack imitating a trusted source, where an employee or private person is tricked into installing the malware without knowing it. This can be through clicking a link or downloading an attachment in a seemingly legit email.</li>
<li>Drive by downloads – visiting compromised websites that then installs the malware on your computer.</li>
<li>Security vulnerabilities – if systems are not up to date and are known to have weaknesses, then attackers will exploit these to install their malware. </li>
</ol>
<h2>How does ransomware encrypt my files?</h2>
<p>Once the ransomware is installed, it encrypts all the data on your computer. Unfortunately, the encryption methods used now are so complex that it is unfeasible to decrypt the files without the decryption key, which is known only to the attackers. To achieve a secure encryption of your data, the attackers use a combination of symmetric and asymmetric encryption. </p>
<h4>Symmetric encryption</h4>
<p>One of the oldest ciphers in history is the shift cipher, which shifts each letter a set number of times back or forth in the alphabet. Knowing this set number, also referred to as the “key”, is therefore enough to both encrypt and decrypt a text. Julius Caesar was believed to use a shift cipher, substituting each letter with the one 3 spaces to the right. This is one of the simplest examples of a symmetric encryption. </p>
<p>Today, there are more advanced versions, which can be broadly categorized as block ciphers (encrypts in byte-sized blocks) or stream ciphers (encrypts single digits). These methods are fast and only require the same key to encrypt and decrypt. </p>
<h4>Asymmetric encryption</h4>
<p>Asymmetric encryption is slower and uses two keys instead of one: one public and one private. The private key is only in the possession of the key pair owner, whereas the public one is widely distributed. When using the public key to encrypt a message it can only be decrypted using the private key, and vice versa.  </p>
<h4>Ransomware take advantage of both encryption methods.</h4>
<p>One of the most common ways a ransomware takes over your computer, is through the following steps:</p>
<ol>
<li>When the ransomware is installed on a computer, it comes with an asymmetric public key, which it used to establish contact with the attackers’ server. All communication is encrypted using this asymmetric encryption, making it impossible to intercept and interpret the communication between the affected computer and the server. </li>
<li>The ransomware will then request a new asymmetric public key from the server, which is specific for the victim’s computer (making it impossible to share a key with other victims). </li>
<li>Once received, the ransomware also creates a symmetric key, which quickly encrypts all the files. </li>
<li>The symmetric key is then encrypted using the asymmetric key specific to the victim. This means that only the private key on the attackers’ server can be used to unlock the symmetric key, which again will decrypt all the files. </li>
</ol>
<p>This makes the whole process fast and yet very secure, and almost impossible to decrypt without paying the ransom. </p>
<h2>Victims of ransomware</h2>
<p>Originally, ransomware was used to target individuals, with a low enough ransom so most people would choose to pay. While individuals are still affected, organizations are targeted on a more regular basis, and can offer a more lucrative pay-off if successful. In fact, <a href="https://news.sophos.com/en-us/2020/05/12/the-state-of-ransomware-2020/">one study</a> showed that over half of the companies had been subjected to a ransomware attack in the past year, and that 73% of these attacks were successful. A recent trend also shows an increase in attacks targeting <a href="https://edition.cnn.com/2020/10/28/politics/hospitals-targeted-ransomware-attacks/index.html">government institutions and hospitals</a>.  </p>
<h2>Costs and solutions</h2>
<p>An estimate shows that total ransom demands will reach a staggering <a href="https://cybersecurityventures.com/global-ransomware-damage-costs-predicted-to-reach-20-billion-usd-by-2021/">20 billion USD by 2021</a>. </p>
<p>While paying the ransom is strongly discouraged as it helps create a marked for extorting money in this manner, some still choose to pay the ransom to retrieve their data. One recent <a href="https://news.sophos.com/en-us/2020/05/12/the-state-of-ransomware-2020/">study</a> of 5000 IT people showed that about 26% chose to pay and that of these, 95% did actually get the decryption key needed to unlock their files again. Over half chose not to pay and instead used backups of their data, while the rest used other methods.</p>
<p>However, even though paying up may seem like the best way to get things restored again, it may actually double the costs of being affected. All organizations attacked by ransomware had a high cost due to downtime, network costs, lost opportunity etc. even without paying the ransom. In fact, the authors of this <a href="https://news.sophos.com/en-us/2020/05/12/the-state-of-ransomware-2020/">study</a> argue that the organizations that chose to pay  had the same costs as those who did not with getting their systems back online, except they also had the cost of removing the encryption in addition to their other expenses.</p>
<p>As most attacks are successful and as it is nearly impossible to decrypt your files after an attack, it’s best to try and prevent an attack in the first place. Good strategies include having regular and off-site backup of data, installing anti-ransomware on your system, training employees in recognizing phishing, and closing any technological vulnerabilites that could be exploited. Stay tuned for more on this and other good preventative measure in our next article.</p></section></article></div>]]>
            </description>
            <link>https://security.christmas/2020/11</link>
            <guid isPermaLink="false">hacker-news-small-sites-25383148</guid>
            <pubDate>Fri, 11 Dec 2020 06:57:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[That Dothraki Horde, Part II: Subsistence on the Hoof]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25382899">thread link</a>) | @parsecs
<br/>
December 10, 2020 | https://acoup.blog/2020/12/11/collections-that-dothraki-horde-part-ii-subsistence-on-the-hoof/ | <a href="https://web.archive.org/web/*/https://acoup.blog/2020/12/11/collections-that-dothraki-horde-part-ii-subsistence-on-the-hoof/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>This is the second part of a four part (<a href="https://acoup.blog/2020/12/04/collections-that-dothraki-horde-part-i-barbarian-couture/">I</a>, III, IV) look at the Dothraki, the fictional horse-borne nomads of the <em>A Song of Ice and Fire</em> / <em>Game of Thrones</em> series.  We’re looking at, in particular, the degree to which George R.R. Martin’s claim that the Dothraki are “an amalgam of a number of steppe and plains cultures” holds up in the face of research.  Our last part, “<a href="https://acoup.blog/2020/12/04/collections-that-dothraki-horde-part-i-barbarian-couture/">Barbarian Couture</a>” looked at the influences that shaped the visual depiction of the Dothraki and found them badly wanting, more based in stereotypes and misconceptions than historical reality.</p>



<p>This week, we’re turning to the foundation of social structures: <strong>patterns of subsistence</strong> (<strong>which, to be clear, means in plain English: “how do they get food and basic resources?” </strong> That’s all subsistence is – how do you get enough resources to survive.)  Originally this was going to fit into a larger argument about culture, but I decided to break it out because we are <em>at long last</em> looking at the logistics and subsistence strategies of nomadic peoples.  Every time we have covered the <a href="https://acoup.blog/2019/05/10/collections-the-siege-of-gondor/">logistics </a>of <a href="https://acoup.blog/2020/07/24/collections-bread-how-did-they-make-it-part-i-farmers/">agrarian </a><a href="https://acoup.blog/2019/10/04/collections-the-preposterous-logistics-of-the-loot-train-battle-game-of-thrones-s7e4/">armies </a>and <a href="https://acoup.blog/2019/07/12/collections-the-lonely-city-part-i-the-ideal-city/">societies</a>, there has been a request to do a deeper dive into the way that Steppe nomads in particular, and nomads more generally, are different.  <strong>Well here it is!</strong></p>



<p>As always, if you like what you are reading here, please share it; if you really like it, you can support me on <a href="https://www.patreon.com/user?u=20122096">Patreon</a>. And if you want updates whenever a new post appears, you can click below for email updates or follow me on twitter (@BretDevereaux) for updates as to new posts as well as my occasional ancient history, foreign policy or military history musings.</p>






<p>(Bibliography note before we dive in.  I am not going to run through everything I’ve glanced at here, but for those looking to read more on this or retrace my steps more generally, a good starting place on the Steppe peoples is T. May, <em>The Mongol Art of War</em> (2007).  There’s also more than a dash here of bits from K. Chase, <em>Firearms: A Global History to 1700</em> (2008) as well as T. Ratchnevsky, <em>Genghis Khan: His Life and Legacy</em>, trans. T.N Haining (1991).  For the Native Americans of the Great Plains, I have relied principally on A.R. McGinnis, <em>Counting Coup and Cutting Horses: Intertribal Warfare on the Northern Plains, 1738-1889</em> (1990), F.R. Secoy, <em>Changing Military Patterns of the Great Plains Indians (17th Century through Early 19th Century)</em> (1958), and A.C. Isenberg, <em>The Destruction of the Bison: An Environmental History, 1750-1920</em> (2020))</p>



<p><strong>As with the past essay, the key statement we are really assessing here is <a href="https://www.westeros.org/Citadel/SSM/Entry/6040/">this one by George R.R. Martin</a>:</strong></p>



<blockquote><p>The Dothraki were actually fashioned as an amalgam of a number of steppe and plains cultures… Mongols and Huns, certainly, but also Alans, Sioux, Cheyenne, and various other Amerindian tribes… seasoned with a dash of pure fantasy.</p></blockquote>



<p>A statement which claims, quite directly, that the Dothraki are modeled primarily off of both Eurasian Steppe nomads and Great Plains Native Americans (with a ‘dash’ of fantasy).  Last time, we found that the <em>appearance</em> of the Dothraki fit almost entirely within the ‘dash’ of fantasy.  So this time we will begin to ask the same question about Dothraki culture –<strong> to what degree may it be said to be based in any <em>actual</em> historical horse-nomad cultures?</strong></p>



<h2>A Feast For People</h2>



<p>Now ‘culture’ is such a huge topic, it may well be asked why start with subsistence strategies. <strong> The answer is that in the pre-modern world, subsistence was one of, if not the, most dominant factor shaping culture</strong>.  After all, most people before the industrial revolution spent most of their time just doing the basic activities (herding, farming, spinning, weaving, cooking, etc.) that made survival possible!  Government structures, military organization, cultural values, marriage and fertility patterns, social structures all flow out of those things which most people were doing to survive, shaped by the needs of those subsistence strategies.</p>



<p>(A brief pedantic note: this sort of approach to history, beginning with big, slow changing patterns (what I often call here ‘structures’ – not a term I made up, by any means) like climate, geography, subsistence strategies, culture, etc. is generally associated with what is called the <em>Annales</em> school of history, which is a <em>method</em> of history.  This framework is often more interested in <em>La longue durée</em> (lit: ‘the (really) long term’) which is just a fancy French way of saying ‘a focus on the long-term historical structures (like those listed above) instead of short-term events (like wars, rulers, that sort of thing).’  As always, this sort of historical theory is a toolbox, not a dogma; different approaches to answer different questions.  But in this case, it is handy because of the way that the basic activities necessary for survival in a given climate form a sort of ‘bounding box’ for cultural possibility.)</p>



<p>What is particularly notable is with <em>A Song of Ice and Fire</em> and <em>Game of Thrones</em> is that our viewpoint character for Dothraki culture is a young woman who spends her time with the Dothraki in the <em>khalassar’s</em> (the Dothraki word for a tribe or clan) moving encampment.  Daenerys can only really view warfare second hand (at least in the books we get; the show is another matter), <strong>but she ought to be able to witnesses the subsistence system directly</strong>.  Even if she wasn’t involved in it directly (because she’s a high status queen), the daily work of survival would be going on all around her and in practice much of it would likely be at her direction as she exercises authority over lower-status individuals in the camp.</p>



<p>Now normally we would start this by looking at how subsistence strategies are represented in the books and show, but I think in this case it is going to be more helpful to begin with the historical subsistence systems <em>first</em>, since they are complex and we’re going to have several of them.  We’re actually going to start at the ending as well, with subsistence strategies of Native Americans on the Great Plains, for reasons that will be clearer once we’ve discussed it.</p>



<h2>A Changing of Patterns</h2>



<p><strong>The domesticated horse is not native to the Americas</strong>.  There is perhaps no more important fact when trying to understand how the horse-borne nomadic cultures of the Eurasian Steppe relate to those of the Great Plains.  The first domesticated horses arrived in the Americans with European explorer/conquerors and the settler-colonists that followed them.  Eventually enough of those horses escaped to create a self-reproducing wild (technically feral, since they were once domesticated) horse population, the <a href="https://en.wikipedia.org/wiki/Mustang">mustangs</a>, but they are not indigenous and mustangs were never really the primary source of new horses the way that wild horses on the Steppe were (before someone goes full nerd in the comments, yes I am aware that there were some early equines in the Americas at very early dates, but they were extinct before there was any chance for them to be domesticated).</p>



<div><figure><img data-attachment-id="5517" data-permalink="https://acoup.blog/horsescd1l-095/" data-orig-file="https://acoupdotblog.files.wordpress.com/2020/12/horsescd1l-095.jpg" data-orig-size="524,344" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="horsescd1l-095" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2020/12/horsescd1l-095.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2020/12/horsescd1l-095.jpg?w=524" src="https://acoupdotblog.files.wordpress.com/2020/12/horsescd1l-095.jpg?w=524" alt="" srcset="https://acoupdotblog.files.wordpress.com/2020/12/horsescd1l-095.jpg 524w, https://acoupdotblog.files.wordpress.com/2020/12/horsescd1l-095.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2020/12/horsescd1l-095.jpg?w=300 300w" sizes="(max-width: 524px) 100vw, 524px"><figcaption><a href="https://en.wikipedia.org/wiki/Mustang">Via Wikipedia</a>, American mustangs.  Mustangs are descendants mostly of Spanish horse breeds.  Notably, they tend to be smaller than many other breeds of European horses, even in cases where their domesticated forebears were larger breeds of draft horses or destriers.  This is because big stable-fed horses can’t survive on grass alone.</figcaption></figure></div>



<p><strong>Horses arrived in the Great Plains form the south via the Spanish and moving through Native American peoples west of the Rocky Mountains by both trade and eventually raiding in the early 1700s</strong>.  Notably firearms <em>also</em> began moving into the region in the same period, but from the opposite direction, coming from British and French traders to the North and West (the Spanish had regulations against trading firearms to Native Americans, making them unavailable as a source).  Both were thus initially <em>expensive trade goods</em> which could only be obtained from outside and then percolated unevenly through the territory; unlike firearms, which remained wholly external in their supply, horses were bred on the plains, but raiding and trade were still essential sources of supply for most peoples on the plains.  We’ll get to this more when we talk about warfare (where we’ll get into the four different military systems created by this diffusion), but being in a position where one’s neighbors had either the horse or the gun and your tribe did not was an <em>extreme</em> military disadvantage and it’s clear that the ‘falling out’ period whereby these two military innovations distributed over the area was very disruptive.</p>



<p><strong>But unlike guns</strong>, which seem to have had massive military impacts but only minimal subsistence impacts (a bow being just as good for hunting bison as a musket, generally), <strong>the arrival of the horse had <em>massive</em> subsistence impacts</strong> because it made hunting <em>wildly</em> more effective.  But the key thing to remember here is: the horse was <em>introduced</em> to the Great Plains no earlier than 1700, horse availability expanded only slowly over the area, but by 1877 (with the end of the <a href="https://en.wikipedia.org/wiki/Great_Sioux_War_of_1876">Black Hills War</a>), true Native American independence on the Great Plains was functionally over.  <strong>Consequently, unlike the Steppe, where we have a fairly ‘set’ system that had already been refined for centuries, <em>all</em> we see of the Plains Native American horse-based subsistence system is rapid change</strong>.  There was no finally reached stable end state, as far as I can tell.</p>



<p>Though there is considerable variation and also severe limits to the evidence, it seems that prior to the arrival of the horse, most Native peoples around the Great Plains practiced two major subsistence systems: <strong>nomadic hunter-gathering on foot </strong>(distinct from what will follow in that it places much more emphasis on the gathering part)<strong> on the one hand and a mixed subsistence system of small-scale farming mixed seasonally with plains hunting seems to have been the main options pre-horse</strong>, based on the degree to which the local area permitted farming in this way (for more on those, note Isenberg, <em>op. cit.</em>, 31-40).  Secoy …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://acoup.blog/2020/12/11/collections-that-dothraki-horde-part-ii-subsistence-on-the-hoof/">https://acoup.blog/2020/12/11/collections-that-dothraki-horde-part-ii-subsistence-on-the-hoof/</a></em></p>]]>
            </description>
            <link>https://acoup.blog/2020/12/11/collections-that-dothraki-horde-part-ii-subsistence-on-the-hoof/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25382899</guid>
            <pubDate>Fri, 11 Dec 2020 06:18:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Some doctors, therapists get Health Canada permission to use magic mushrooms]]>
            </title>
            <description>
<![CDATA[
Score 175 | Comments 59 (<a href="https://news.ycombinator.com/item?id=25382497">thread link</a>) | @billyharris
<br/>
December 10, 2020 | https://www.cbc.ca/news/canada/london/some-doctors-therapists-get-health-canada-permission-to-use-magic-mushrooms-1.5834485 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/canada/london/some-doctors-therapists-get-health-canada-permission-to-use-magic-mushrooms-1.5834485">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Four months after it allowed a handful of palliative care patients to use psilocybin as a way to relieve end-of-life suffering, Health Canada has cleared the way for more than a dozen health professionals to use the psychedelic drug themselves to help develop therapies for future use.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.4039727.1492805330!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/63883228.jpg"></p></div><figcaption>Psilocybin is the ingredient in magic mushrooms that causes hallucinations, but in medically supervised settings, can also potentially help people overcome depression.<!-- --> <!-- -->(Shutterstock / gsplanet)</figcaption></figure><p><span><p>Four months after it allowed a handful of palliative care patients to use psilocybin as a way to relieve end-of-life suffering, Health Canada has cleared the way for more than a dozen health professionals to use the psychedelic drug themselves to help develop therapies for future use.&nbsp;</p>  <p>Health Canada says it granted 16 exemptions to a selection of nurses, doctors, therapists and social workers, allowing them to possess and use&nbsp;psilocybin&nbsp;for personal training without fear of prosecution under the country's drug laws.&nbsp;</p>  <p>"This is not a small step. This is a seismic step," said Dr. Sean O'Sullivan, a Tillsonburg, Ont., doctor and medical director of TheraPsil, a non-profit group that advocates for the therapeutic use of psilocybin.&nbsp;</p>  <p>"This is permission from the Ministry of Health and the Minister of Health to allow therapists to forward their own training in psychedelic medicine."&nbsp;</p>  <p><span><span><div><div role="button" tabindex="0" title="Mushrooms: The Magic Medicine"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/337/291/Sickboy-640x360.jpg" alt=""></p><p><span>Sickboy</span><span>1:02:33</span><span>Mushrooms: The Magic Medicine</span></p></div></div></div><span>Thomas Hartle never used drugs before his Stage IV cancer diagnosis. That’s changed thanks to Therapsil. A couple months ago, he became the first Canadian to legally use psychedelic mushrooms to treat end of life anxiety and depression. Take a listen to his story with an open mind.<!-- --> <!-- -->1:02:33</span></span></span><span><ul><li><a href="https://www.cbc.ca/news/health/microdosing-pschedelics-study-1.4771647" data-contentid="" flag="" text="How and why people 'microdose' tiny hits of psychedelic drugs"><span>How and why people 'microdose' tiny hits of psychedelic drugs</span></a></li></ul></span></p>  <p>The move comes after Health Canada&nbsp;gave <a href="https://www.cbc.ca/news/canada/british-columbia/magic-mushrooms-therapy-1.5675637" target="_blank">four exemptions to palliative care patients</a> to use the drug&nbsp;for end-of-life psychotherapy in August. Since then, other exemptions have been given to patients who want to use magic mushrooms.&nbsp;</p>  <p>The exemptions for health professionals will allow those who want to treat patients with psilocybin&nbsp;to understand what it would feel like and how best to use it.&nbsp;</p>  <p>They are good for one year.&nbsp;</p>  <p>"Psychedelic substances and treatment using these substances, such as&nbsp;psilocybin, is a growing area of scientific study and research. Because&nbsp;psilocybin&nbsp;is not an authorized therapeutic substance, the availability of rigorous scientific evidence demonstrating its safety and efficacy is limited," Health Canada said in a statement to CBC News.&nbsp;</p>  <p>"The exemptions do not permit the health care professionals to prescribe or provide mushrooms containing&nbsp;psilocybin&nbsp;to another person. There are no drugs containing&nbsp;psilocybin&nbsp;that have been authorized&nbsp; by Health Canada. Health Canada's decision to grant these exemptions does not constitute an opinion or endorsement from Health Canada on&nbsp;psilocybin-assisted psychotherapy, training, or the safety, effectiveness, or quality of&nbsp;psilocybin."</p>  <h2>Psychiatrists, nurses given exemptions</h2>  <p>"This is an immense step that the minister has taken, and a very wise step, a step that is totally congruent with the science and the published literature and is a very courageous move on her part and on our government's part," O'Sullivan said.&nbsp;</p>  <p>Psychedelic therapies such as psilocybin and LSD have had negative reputations, in part because of the war on drugs, O'Sullivan said.&nbsp;</p>    <p>"The war on drugs has been an unmitigated disaster worldwide. It has criminalized behaviour that does not need to be criminalized. Cannabis has been legalized, and the sky has not fallen," O'Sullivan said.&nbsp;</p>  <p>Those who have been given exemptions include psychiatrists associated with the University of Toronto, a community psychiatrist in Hamilton and his partner, as well as health professionals in Calgary and British Columbia.&nbsp;</p>  <p>O'Sullivan and his wife both got an exemption. He is a general practitioner and she is a therapist. He said it's important for doctors who could eventually prescribe psychedelics to be well versed in their effects.&nbsp;</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5834847.1607546851!/fileImage/httpImage/image.JPG_gen/derivatives/original_300/dr-sean-o-sullivan.JPG 300w,https://i.cbc.ca/1.5834847.1607546851!/fileImage/httpImage/image.JPG_gen/derivatives/original_460/dr-sean-o-sullivan.JPG 460w,https://i.cbc.ca/1.5834847.1607546851!/fileImage/httpImage/image.JPG_gen/derivatives/original_620/dr-sean-o-sullivan.JPG 620w,https://i.cbc.ca/1.5834847.1607546851!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/dr-sean-o-sullivan.JPG 780w,https://i.cbc.ca/1.5834847.1607546851!/fileImage/httpImage/image.JPG_gen/derivatives/original_1180/dr-sean-o-sullivan.JPG 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5834847.1607546851!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/dr-sean-o-sullivan.JPG"></p></div><figcaption>Dr. Sean O'Sullivan is one of 16 health professionals who has been granted an exemption from Canada's drug laws to use magic mushrooms. <!-- --> <!-- -->(Submitted by Sean O'Sullivan)</figcaption></figure></span></p>  <p>"You would not expect a guide to take any journey over any terrain with&nbsp;which the guide was not familiar. When it comes to psychedelics, the terrain is so unusual and so outlandish that it is absolutely imperative that the therapist have familiarity with the realms of the human unconscious that are visited under psychedelics because they can help guide the patient through situations that might seem utterly bizarre, even psychotic to an untrained therapist," O'Sullivan said.</p>  <p>"Great information can be obtained if you dissect and unpack that material that comes up under these medications."</p>  <p>Psilocybin&nbsp;allows the brain to put away the "default mode network," the part of our brain that worries about taxes and dinner and the shopping list, and dive deeper.&nbsp;</p>    <p>"If you look at your <a href="https://www.cbc.ca/news/health/seeking-seat-of-consciousness-in-dark-side-of-brain-1.1415607" target="_blank">default mode network</a>, you will find that the themes that come up are the same themes that came up last year and the year before and the decade before," O'Sullivan said. "Psychedelics disassemble the default mode network and they allow a person to have new experiences in a carefully controlled clinical setting. When the default mode network is put back together, it's not put back together in the same way as it was previously."</p>  <p>That's why a single dose of a psychedelic medicine can have more effect than years of talk therapy or medication, he said.</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/canada/london/some-doctors-therapists-get-health-canada-permission-to-use-magic-mushrooms-1.5834485</link>
            <guid isPermaLink="false">hacker-news-small-sites-25382497</guid>
            <pubDate>Fri, 11 Dec 2020 05:03:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Economics of Software Performance]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25381748">thread link</a>) | @ivanmontillam
<br/>
December 10, 2020 | https://www.ivanmontilla.com/2020/12/economics-of-software-performance/ | <a href="https://web.archive.org/web/*/https://www.ivanmontilla.com/2020/12/economics-of-software-performance/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p><em><strong>Disclaimer:</strong> I’m presenting this post without any figures or math, so it’s just my opinion based on professional past eye-witnessed experiences. This post will not be about hate, but rather on the weaknesses of delivery of recent trending technologies.</em></p>



<p>Recently I’ve seen a dangerous trend in software development, more specifically about web and desktop technologies. I wish not to bash on software frameworks such as Electron, but I think there are hidden costs for both junior developers and enterprises are ignoring. Let’s dig a bit deeper ahead.</p>



<p>Whenever you take the technical choice to abstract your codebase with a multiplatform framework, you need to be sure about the hidden costs of using it, and I’m not talking just about the implied costs of software performance. If you provide a poor user experience because your app feels <em>crap</em> to use, that’s a potential paying user that you’ll lose or at least will be upfront harder to acquire. </p>



<p>Sometimes software development teams are on a budget and need to make a choice like this, in order to increase market access and in that way, achieve faster market-product fit. I can understand that, but what is hard to reconcile to me, is the cost you save equals the cost your customers end up paying. Ideally, you’d not cut costs on this because after all, you need to provide the <em>best-in-class</em> experience to your users if you’re to retain them over several billing renewal cycles.</p>



<p>To put it bluntly: As a company, you might mistakenly think to save on software development costs, but your users actually don’t. What actually happens is: They end up paying the costs you <em>attempted</em> to save (more on this later), exponentially. It’s inversely proportional.</p>



<p>Did you deliver an app to the marketplace quickly? Yes. Does your app solve the problem? To some degree. Does the app perform <em>painlessly fast</em>? Muddy waters my friend. Can it run Crysis? I don’t think so.</p>



<p>The expected outcome is that you save on costs and have a greater runway for your startup to live, but let’s not forget: <em><a href="https://stackoverflow.com/questions/30490018/can-poor-performance-be-considered-as-a-software-bug" target="_blank" rel="noreferrer noopener">Poor software performance can be considered a bug</a></em>. If you’ve read <em>Steve McConnell’s Code Complete 2nd. Ed.</em>, you’ll notice <strong>proper software development is hard</strong>, and most of the time: with 5, 6 or even 7 figures on costs. And if your ideal resource-saving scenario doesn’t realize (time and money), your company will eventually find themselves reimplementing the app again in the latest technology-fad of that moment, feeding the vicious cycle.</p>



<p>Conversely, paying high costs on software development, while doesn’t guarantee business success, certainly helps in capturing better engineering for your product or service. So you had to have a team on iOS development, another one for Android development, another one for Windows, macOS, and Linux, but you delivered a superior experience. You might need to strike a balance between these two tug-of-war situations, to meet both business requirements and good engineering.</p>



<p>Imagine a world where mobile devices and personal computers ran on public clouds (much like Google Stadia), such as AWS or Azure. In such a scenario, your users would have to provision more expensive compute instances to actually run your 300 Mb social media application (without accounting for the data it stores locally). Storage and RAM are evergrowing, but here’s a little secret nobody tells you: <strong>There’s no need to take it up in its entirety!</strong></p>



<p><a href="https://mcfunley.com/choose-boring-technology" target="_blank" rel="noreferrer noopener">Boring technology is really great</a> not only because of its predictability, but it’s also great because most of the time it has been battle-tested for performance. The vulnerability of bloated technologies lies in the trend that some applications seem to be running really fast, but these are very few. So few they can be counted with the fingers of a single hand. All other applications range from overweight to really heavy on the OSes they run on. Maybe the framework is an easy “abusable” trap to create underperforming applications. Hat tip to these engineers of these few applications, these are a great feat of debugging, profiling, and engineering to achieve these results.</p>



<p>Yes, I can hear you… “<em>money talks</em>,” but if that’s the case, then consider technologies that overall reduce the cost to implement and to run. Example: <a href="https://sciter.com/" target="_blank" rel="noreferrer noopener">Sciter</a>‘s learning curve is harder than Electron’s, it actually requires you to learn a native or intermediate language to implement your business logic, and it also has <a href="https://www.kickstarter.com/projects/c-smile/open-source-sciter-engine" target="_blank" rel="noreferrer noopener">5 times less carbon footprint</a>, but hey! You’re a proper engineer shipping some serious code to production environments, after all, you choose what’s best for your customers, or do you? <strong>😉</strong></p>



<p>On a side note: I consider the origin of this dangerous trend to be from the specific situation when junior software developers skip computer, software architecture, and software design classes irresponsibly delivering bloated software to the marketplace.</p>



<p>Ignorance is the root and stem of all evils, Plato once said.</p>



<p>Source of inspiration: <a href="https://cr.yp.to/bib/1995/wirth.pdf" target="_blank" rel="noreferrer noopener">A Plea for Lean Software (Niklaus Wirth, 1995)</a></p>
		</div></div>]]>
            </description>
            <link>https://www.ivanmontilla.com/2020/12/economics-of-software-performance/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25381748</guid>
            <pubDate>Fri, 11 Dec 2020 02:57:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Clubhouse Conversation with Dylan Field]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25381458">thread link</a>) | @giacaglia
<br/>
December 10, 2020 | https://www.joinclubhouse.com/event/9mW6WaMX | <a href="https://web.archive.org/web/*/https://www.joinclubhouse.com/event/9mW6WaMX">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.joinclubhouse.com/event/9mW6WaMX</link>
            <guid isPermaLink="false">hacker-news-small-sites-25381458</guid>
            <pubDate>Fri, 11 Dec 2020 02:15:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google Alternatives]]>
            </title>
            <description>
<![CDATA[
Score 273 | Comments 222 (<a href="https://news.ycombinator.com/item?id=25380999">thread link</a>) | @yepgwer
<br/>
December 10, 2020 | https://justprivacy.org/google-alternatives/ | <a href="https://web.archive.org/web/*/https://justprivacy.org/google-alternatives/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><span color="000000"><p>We may earn a small commission if you choose to purchase from our links <strong>(at no extra cost to you!)</strong></p></span></p><div data-elementor-type="wp-post" data-elementor-id="989" data-elementor-settings="[]"><div><div><section data-id="10b593b" data-element_type="section"></section><section data-id="c631736" data-element_type="section"><div><div><div data-id="72201ec" data-element_type="column"><div><div><div data-id="e877a4b" data-element_type="widget" data-widget_type="image.default"><div><p><img width="992" height="558" src="https://justprivacy.org/media/2020/03/Google-Alternatives-1024x576.jpg" data-lazy-type="image" data-src="https://justprivacy.org/media/2020/03/Google-Alternatives-1024x576.jpg" alt="Google Alternatives" loading="lazy" srcset="https://justprivacy.org/media/2020/03/Google-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Google-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Google-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Google-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Google-Alternatives-2048x1152.jpg 2048w" data-srcset="https://justprivacy.org/media/2020/03/Google-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Google-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Google-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Google-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Google-Alternatives-2048x1152.jpg 2048w" sizes="(max-width: 992px) 100vw, 992px" title="Google Alternatives Google Alternatives: Protecting Your Data"></p></div></div></div></div></div></div></div></section><section data-id="c32dc21" data-element_type="section"><div><div><div data-id="af9583c" data-element_type="column"><div><div><div data-id="797f602" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>The purpose of this guide is to be the most in-depth list of the best alternatives to Google and its products.</p><p>Privacy and security of personal data online has become more of an issue, this means people are trying to find alternatives to Google.</p><p>The way Google makes money is by data collection and advertisements, with both affect your online privacy. The more data Google has on you the better they can find out what you’re interested in (target you) and therefore make more money off you. Did you know Google had over <a href="https://www.statista.com/statistics/267606/quarterly-revenue-of-google/" target="_blank" rel="noopener">$159 billion dollars in revenue</a> in 2019?</p><p>However, there is a growing amount of people who are looking for alternatives to Google.</p><p><span>Note:</span> None of these alternatives are in order, it depends on you’re specific needs.</p></div></div></div></div></div></div></div></div></section><section data-id="8997902" data-element_type="section"><div><div><div data-id="b2c7c82" data-element_type="column"><div><div><div data-id="a225dd3" data-element_type="widget" data-widget_type="heading.default"><p><h2>Google Search Engine Alternatives</h2></p></div><div data-id="6838ece" data-element_type="widget" data-widget_type="image.default"><div><p><img width="992" height="519" src="https://justprivacy.org/media/2020/03/Google-Search-Alternatives-1024x536.jpg" data-lazy-type="image" data-src="https://justprivacy.org/media/2020/03/Google-Search-Alternatives-1024x536.jpg" alt="Google Search Alternatives" loading="lazy" srcset="https://justprivacy.org/media/2020/03/Google-Search-Alternatives-1024x536.jpg 1024w, https://justprivacy.org/media/2020/03/Google-Search-Alternatives-300x157.jpg 300w, https://justprivacy.org/media/2020/03/Google-Search-Alternatives-768x402.jpg 768w, https://justprivacy.org/media/2020/03/Google-Search-Alternatives.jpg 1200w" data-srcset="https://justprivacy.org/media/2020/03/Google-Search-Alternatives-1024x536.jpg 1024w, https://justprivacy.org/media/2020/03/Google-Search-Alternatives-300x157.jpg 300w, https://justprivacy.org/media/2020/03/Google-Search-Alternatives-768x402.jpg 768w, https://justprivacy.org/media/2020/03/Google-Search-Alternatives.jpg 1200w" sizes="(max-width: 992px) 100vw, 992px" title="Google Search Alternatives Google Alternatives: Protecting Your Data"></p></div></div><div data-id="4d6be8b" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>Privacy and Google search don’t go hand in hand. When you use Google search, they will record your IP address, your search terms, and usually a unique ID.</p><p>Here are some good alternatives to Google search.</p><ol><li><a href="https://duckduckgo.com/" target="_blank" rel="noopener">DuckDuckGo</a> – An internet search engine whose goal is to protect users’ privacy and avoiding personalized search results (tracking).</li><li><a href="https://www.qwant.com/" target="_blank" rel="noopener">Qwant</a> – Is a French search engine that doesn’t track users.</li><li><a href="https://searx.me/" target="_blank" rel="noopener">SearX</a> – Is a free metasearch engine, intended to protect the privacy of its users.</li><li><a href="https://startpage.com/" target="_blank" rel="noopener">Startpage</a> – a search engine extension that allows users to browse while not being tracked.</li><li><a href="https://swisscows.com/" target="_blank" rel="noopener">SwissCows</a> – Is a Swiss search engine that was launched in 2014. They don’t keep track of the searches done on their site.</li><li><a href="https://www.mojeek.com/" target="_blank" rel="noopener">Mojeek</a> – Is a UK-based search engine, they are independent and have unbiased results which means no user tracking.</li><li><a href="https://info.ecosia.org/" target="_blank" rel="nofollow noopener">ecosia</a> – Berlin-based search engine whose profits go into planting trees to fight against climate change! They are also privacy-friendly and ethical.</li><li>&nbsp;</li><li><a href="https://metager.org/" target="_blank" rel="noopener">MetaGer</a> – Is a search engine based on protecting users’ privacy, it’s also based in Germany.</li><li><a href="https://yandex.com/" target="_blank" rel="noopener">Yandex Search</a> – Is a search engine based in Russia and owned by a Russian corporation <a href="https://en.wikipedia.org/wiki/Yandex" target="_blank" rel="noopener">Yandex</a>.</li><li><a href="https://yacy.net/" target="_blank" rel="noopener">YaCy</a> – Is a free search engine built on principles of P2P (peer-to-peer) networks.</li></ol><p>Most of the search engines above are metasearch engines (except Mokeej and Yandex) meaning they source their search results from larger search engines like Google and Bing.</p></div></div></div></div></div></div></div></div></section><section data-id="56efb89" data-element_type="section"><div><div><div data-id="1091847" data-element_type="column"><div><div><div data-id="653fe9a" data-element_type="widget" data-widget_type="heading.default"><p><h2>Google Chrome Alternatives</h2></p></div><div data-id="0470836" data-element_type="widget" data-widget_type="image.default"><div><p><img width="992" height="558" src="https://justprivacy.org/media/2020/03/Chrome-Alternatives-1024x576.jpg" data-lazy-type="image" data-src="https://justprivacy.org/media/2020/03/Chrome-Alternatives-1024x576.jpg" alt="Chrome Alternatives" loading="lazy" srcset="https://justprivacy.org/media/2020/03/Chrome-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Chrome-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Chrome-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Chrome-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Chrome-Alternatives.jpg 1920w" data-srcset="https://justprivacy.org/media/2020/03/Chrome-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Chrome-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Chrome-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Chrome-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Chrome-Alternatives.jpg 1920w" sizes="(max-width: 992px) 100vw, 992px" title="Chrome Alternatives Google Alternatives: Protecting Your Data"></p></div></div><div data-id="25f82ad" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>Chrome is an extremely popular web browser and billions of searches are done monthly.</p><p>As you can see Google has 92.07% of the Search Engine Market Share Worldwide as of February 2020!</p></div></div></div><div data-id="e99d120" data-element_type="widget" data-widget_type="image.default"><div><p><a href="https://gs.statcounter.com/search-engine-market-share" target="_blank" rel="noopener"> <img width="992" height="269" src="https://justprivacy.org/media/2020/03/Market-Share-Chrome-1024x278.png" data-lazy-type="image" data-src="https://justprivacy.org/media/2020/03/Market-Share-Chrome-1024x278.png" alt="Market Share Chrome" loading="lazy" srcset="https://justprivacy.org/media/2020/03/Market-Share-Chrome-1024x278.png 1024w, https://justprivacy.org/media/2020/03/Market-Share-Chrome-300x81.png 300w, https://justprivacy.org/media/2020/03/Market-Share-Chrome-768x208.png 768w, https://justprivacy.org/media/2020/03/Market-Share-Chrome-1536x417.png 1536w, https://justprivacy.org/media/2020/03/Market-Share-Chrome.png 1629w" data-srcset="https://justprivacy.org/media/2020/03/Market-Share-Chrome-1024x278.png 1024w, https://justprivacy.org/media/2020/03/Market-Share-Chrome-300x81.png 300w, https://justprivacy.org/media/2020/03/Market-Share-Chrome-768x208.png 768w, https://justprivacy.org/media/2020/03/Market-Share-Chrome-1536x417.png 1536w, https://justprivacy.org/media/2020/03/Market-Share-Chrome.png 1629w" sizes="(max-width: 992px) 100vw, 992px" title="Market Share Chrome Google Alternatives: Protecting Your Data">		</a></p></div></div><div data-id="2d8725f" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>Remember that Google Chrome is not only a search engine but a super successful data collection tool! More and more people are noticing this. There are many articles saying that Google Chrome has become spyware!</p><p>If you want to read more about this you can read this forum on <a href="https://www.reddit.com/r/BATProject/comments/c3q51d/goodbye_chrome_googles_web_browser_has_become_spy/?utm_source=share&amp;utm_medium=web2x" target="_blank" rel="noopener">Reddit</a> and an article on <a href="https://www.washingtonpost.com/technology/2019/06/21/google-chrome-has-become-surveillance-software-its-time-switch/" target="_blank" rel="noopener">Washington Post.</a></p><p>Here are some good alternatives to Chrome:</p><ol><li><a href="https://www.torproject.org/projects/torbrowser.html.en" target="_blank" rel="noopener">Tor Browser</a> – Is a global and decentralized computer network. This allows you to hide from tracking and surveillance.</li><li><a href="https://www.mozilla.org/fr/firefox/new/" target="_blank" rel="noopener">Firefox</a> – Is a free and open-source web browser, it was developed by Mozilla Foundation and help from thousands of volunteers!</li><li><a href="https://brave.com/fr/" target="_blank" rel="noopener">Brave</a> – Is an open-source web browser whose goal is to protect the privacy of their users by blocking trackers or preferring pages in HTTPS.</li><li><a href="https://iridiumbrowser.de/" target="_blank" rel="noopener">Iridium Browser</a> – Is based on the Chromium codebase. All modifications enhance privacy for the user.</li><li><a href="https://ungoogled-software.github.io/ungoogled-chromium-binaries/" target="_blank" rel="noopener">Ungoogled Chromium</a> – Is an open-source version of Chromium that has been modified to enhance users’ privacy.</li><li><a href="https://www.waterfox.net/" target="_blank" rel="noopener">Waterfox</a> – Is an open-source web browser that is based on Mozilla Firefox. Its purpose is to be speedy and ethical.</li><li><a href="https://www.epicbrowser.com/" target="_blank" rel="noopener">Epic Browser</a> – Is a “Privacy Browser” that is a secure chromium-based web browser.</li><li><a href="https://www.gnu.org/software/gnuzilla/" target="_blank" rel="noopener">GNUzilla</a> – Its a GNU version of the Mozilla suite. Its main advantage is that it’s ethical and entirely free!</li></ol><p>There are other alternatives to Google Chrome like Apple’s Safari and Microsoft’s Edge but many of these have serious privacy issues.</p></div></div></div></div></div></div></div></div></section><section data-id="0f232f2" data-element_type="section"><div><div><div data-id="dcd92ec" data-element_type="column"><div><div><div data-id="c5b213d" data-element_type="widget" data-widget_type="image.default"><div><p><img width="992" height="558" src="https://justprivacy.org/media/2020/03/Gmail-Alternatives-1024x576.jpg" data-lazy-type="image" data-src="https://justprivacy.org/media/2020/03/Gmail-Alternatives-1024x576.jpg" alt="Gmail Alternatives" loading="lazy" srcset="https://justprivacy.org/media/2020/03/Gmail-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Gmail-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Gmail-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Gmail-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Gmail-Alternatives.jpg 1920w" data-srcset="https://justprivacy.org/media/2020/03/Gmail-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Gmail-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Gmail-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Gmail-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Gmail-Alternatives.jpg 1920w" sizes="(max-width: 992px) 100vw, 992px" title="Gmail Alternatives Google Alternatives: Protecting Your Data"></p></div></div><div data-id="acb282e" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>Your inbox is where the most important information is sent. You can find a lot of information on a person based on your inbox.</p><p>The unfortunate thing is that Google and its partners have access to all your information and they can <a href="https://www.wsj.com/articles/techs-dirty-secret-the-app-developers-sifting-through-your-gmail-1530544442" target="_blank" rel="noopener">collect data</a>, they can display ads inside your inbox, and the contents of your inbox are shared with random <a href="https://www.wsj.com/articles/techs-dirty-secret-the-app-developers-sifting-through-your-gmail-1530544442" target="_blank" rel="noopener">third parties</a>.</p><p>Here are some more secure Gmail alternatives:</p><ol><li><a href="https://protonmail.com/" target="_blank" rel="noopener">ProtonMail</a> – Is an encrypted email service created in 2013 by CERN and MIT scientists.</li><li><a href="https://tutanota.com/" target="_blank" rel="noopener">Tutanota</a> – Is a German-based email provider that is open-sourced with end-to-end email software. Tutanota also offers a web messaging service.</li><li><a href="https://posteo.de/en/" target="_blank" rel="noopener">Posteo</a> – Is a German email provider whose IT foundation is based on open-source software. They also use green energy from Greenpeace Energy and is also ad-free! The service costs € 1 per month.</li><li><a href="https://runbox.com/" target="_blank" rel="noopener">Runbox</a> – Is a company that provides email and web hosting services. It was founded in March 2011 and its headquarters are located in Oslo.</li><li><a href="https://mailbox.org/en/" target="_blank" rel="noopener">Mailbox.org</a> – Its an ad-free and secure email provider based in Germany, they offer a calendar, contacts lists and more.</li><li><a href="https://www.startmail.com/" target="_blank" rel="noopener">StartMail</a> – Is created by the people who created StartPage (a secure search engine).&nbsp;</li><li><a href="https://mailfence.com/en/" target="_blank" rel="noopener">Mailfence</a> – Is an encrypted email service based in Belgium. It offers free accounts.</li><li><a href="https://countermail.com/" target="_blank" rel="noopener">CounterMail</a> – Is a secure email provider that is based in Sweden.&nbsp;</li></ol></div></div></div></div></div></div></div></div></section><section data-id="9dd4dfa" data-element_type="section"><div><div><div data-id="5d3cd03" data-element_type="column"><div><div><div data-id="6d29af4" data-element_type="widget" data-widget_type="heading.default"><p><h2>Google Calendar Alternatives</h2></p></div><div data-id="fc23717" data-element_type="widget" data-widget_type="image.default"><div><p><img width="992" height="558" src="https://justprivacy.org/media/2020/03/Gmail-Alternatives-1-1024x576.jpg" data-lazy-type="image" data-src="https://justprivacy.org/media/2020/03/Gmail-Alternatives-1-1024x576.jpg" alt="Gmail Alternatives 1" loading="lazy" srcset="https://justprivacy.org/media/2020/03/Gmail-Alternatives-1-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Gmail-Alternatives-1-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Gmail-Alternatives-1-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Gmail-Alternatives-1-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Gmail-Alternatives-1.jpg 1920w" data-srcset="https://justprivacy.org/media/2020/03/Gmail-Alternatives-1-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Gmail-Alternatives-1-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Gmail-Alternatives-1-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Gmail-Alternatives-1-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Gmail-Alternatives-1.jpg 1920w" sizes="(max-width: 992px) 100vw, 992px" title="Gmail Alternatives 1 Google Alternatives: Protecting Your Data"></p></div></div><div data-id="a3398d3" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>Google Calendar is amazing it helps users manage their time, set goals, and remember things.</p><p>There are many upsides to Google’s Calendar app but there are some major privacy issues and many people are looking for alternatives.</p><p>Here are multiple Google Calendar alternatives:</p><ol><li><a href="https://www.simplemobiletools.com/" target="_blank" rel="noopener">Simple Calendar</a> – It’s an ad-free app without any unnecessary permissions.</li><li><a href="https://fruux.com/" target="_blank" rel="noopener">Fruux</a> – Offers a free account, supports many operating systems, and is open-source.</li><li><a href="https://timetreeapp.com/intl/en/" target="_blank" rel="noopener">TimeTree</a> – It offers a free account and supports Android, iOS, and browser.</li><li><a href="https://protonmail.com/blog/protoncalendar-beta-announcement/" target="_blank" rel="noopener">ProtonCalendar</a> – Created by the same people who made ProtonMail!</li><li><a href="https://github.com/Kartones/flask-calendar#introduction" target="_blank" rel="noopener">Flask-Calendar</a> – Basic, self-hosted Calendar, has a few features as well</li></ol><p>There are a few services that offer both email and calendar services in one:</p><ul><li><a href="https://tutanota.com/" target="_blank" rel="noopener">Tutanota</a></li><li><a href="https://mailbox.org/en/" target="_blank" rel="noopener">Mailbox.org</a></li><li><a href="https://posteo.de/" target="_blank" rel="noopener">Posteo</a></li><li><a href="https://mailfence.com/" target="_blank" rel="noopener">Mailfence</a></li><li><a href="https://outlook.live.com/" target="_blank" rel="noopener">Outlook</a></li></ul></div></div></div></div></div></div></div></div></section><section data-id="c72fb6b" data-element_type="section"><div><div><div data-id="f3c4b93" data-element_type="column"><div><div><div data-id="021a025" data-element_type="widget" data-widget_type="heading.default"><p><h2>Google Drive Alternatives</h2></p></div><div data-id="a27452e" data-element_type="widget" data-widget_type="image.default"><div><p><img width="992" height="558" src="https://justprivacy.org/media/2020/03/Google-Drive-Alternatives-1024x576.jpg" data-lazy-type="image" data-src="https://justprivacy.org/media/2020/03/Google-Drive-Alternatives-1024x576.jpg" alt="Google Drive Alternatives" loading="lazy" srcset="https://justprivacy.org/media/2020/03/Google-Drive-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Google-Drive-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Google-Drive-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Google-Drive-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Google-Drive-Alternatives.jpg 1920w" data-srcset="https://justprivacy.org/media/2020/03/Google-Drive-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Google-Drive-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Google-Drive-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Google-Drive-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Google-Drive-Alternatives.jpg 1920w" sizes="(max-width: 992px) 100vw, 992px" title="Google Drive Alternatives Google Alternatives: Protecting Your Data"></p></div></div><div data-id="067a2fa" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>Google Drive is a popular option because it’s free and extremely convenient, but Google doesn’t care about users’ privacy that much. It collects your data and uses it for their own purposes.</p><p>Here are some good Drive Alternatives:</p><ol><li><a href="https://www.dropbox.com/" target="_blank" rel="noopener">Dropbox</a> – Is a file hosting service owned by the American company Dropbox.</li><li><a href="https://www.sync.com/" target="_blank" rel="noopener">Sync.com</a> – Is based in Canada. They offer secure and encrypted cloud storage for both businesses and individuals.</li><li><a href="https://mega.nz/" target="_blank" rel="noopener">Mega</a> – Is a secure cloud storage service that offers free 50 GB of storage.</li><li><a href="https://nextcloud.com/" target="_blank" rel="noopener">Nextcloud</a> – This is a free and open-source file sharing platform that is based in Germany.</li><li><a href="https://github.com/syncthing/syncthing/tree/master" target="_blank" rel="noopener">Syncthing</a> – Peer-to-peer, an open-sourced cloud storage platform.</li><li><a href="https://tresorit.com/" target="_blank" rel="noopener">Tresorit</a>d Hungary that is serious about en<span>&nbsp;– Is a storage service based in Switzerland enhanced</span>&nbsp;security and data encryption.&nbsp;</li><li><a href="https://owncloud.org/" target="_blank" rel="noopener">ownCloud</a> – This is an open-source file sharing platform based in Germany.</li><li><a href="http://www.infomaniak.com/" target="_blank" rel="noopener">Infomaniak</a> – Switzerland-based privacy-friendly service that offers drive, calendar, and more services.</li></ol><p>Some of my recommendations above (Dropbox, Mega) aren’t the best for privacy but are much more privacy-friendly than Google Drive.</p></div></div></div></div></div></div></div></div></section><section data-id="560065d" data-element_type="section"><div><div><div data-id="473c144" data-element_type="column"><div><div><div data-id="f1693c6" data-element_type="widget" data-widget_type="image.default"><div><p><img width="992" height="558" src="https://justprivacy.org/media/2020/03/Google-Docs-Alternatives-1024x576.jpg" data-lazy-type="image" data-src="https://justprivacy.org/media/2020/03/Google-Docs-Alternatives-1024x576.jpg" alt="Google Docs Alternatives" loading="lazy" srcset="https://justprivacy.org/media/2020/03/Google-Docs-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Google-Docs-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Google-Docs-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Google-Docs-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Google-Docs-Alternatives.jpg 1920w" data-srcset="https://justprivacy.org/media/2020/03/Google-Docs-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Google-Docs-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Google-Docs-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Google-Docs-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Google-Docs-Alternatives.jpg 1920w" sizes="(max-width: 992px) 100vw, 992px" title="Google Docs Alternatives Google Alternatives: Protecting Your Data"></p></div></div><div data-id="98b5c8d" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>Google Docs offers users to create documents easily online. But Google makes its money through data collection and Google’s bots have been caught crawling through users’ documents.</p><p>Here are some good alternatives to Google Drive:</p><ol><li><a href="https://www.zoho.com/docs/" target="_blank" rel="noopener">Zoho Office</a> – This is a good Google alternative for docs since it has a good interface and works well.</li><li><a href="https://etherpad.org/" target="_blank" rel="noopener">EtherPad</a> – Is an online free text editor that allows users to work collaboratively and in real-time.</li><li><a href="https://cryptpad.fr/" target="_blank" rel="noopener">CryptPad</a> – Is a great privacy-focused alternative to Google Docs.</li><li><a href="https://www.openoffice.org/" target="_blank" rel="noopener">Apache OpenOffice</a> – Is a good office suite platform that is also available <span>offline.</span></li><li><a href="https://personal.onlyoffice.com/" target="_blank" rel="noopener">OnlyOffice</a> – Is a multifunctional online office suite.</li><li><a href="https://www.nuclino.com/" target="_blank" rel="noopener">Nuclino</a> – Is a cloud-based collaboration software that allows teams to work on projects together and share information in real-time.</li><li><a href="https://flibreoffice.org/" target="_blank" rel="noopener">LibreOffice</a> – Is a good free and open-sourced office suite that is also available <span>offline.</span></li></ol></div></div></div></div></div></div></div></div></section><section data-id="46d2732" data-element_type="section"><div><div><div data-id="c3a000e" data-element_type="column"><div><div><div data-id="2f0a056" data-element_type="widget" data-widget_type="image.default"><div><p><img width="992" height="558" src="https://justprivacy.org/media/2020/03/YouTube-Alternatives-1024x576.jpg" data-lazy-type="image" data-src="https://justprivacy.org/media/2020/03/YouTube-Alternatives-1024x576.jpg" alt="YouTube Alternatives" loading="lazy" srcset="https://justprivacy.org/media/2020/03/YouTube-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/YouTube-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/YouTube-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/YouTube-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/YouTube-Alternatives.jpg 1920w" data-srcset="https://justprivacy.org/media/2020/03/YouTube-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/YouTube-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/YouTube-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/YouTube-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/YouTube-Alternatives.jpg 1920w" sizes="(max-width: 992px) 100vw, 992px" title="YouTube Alternatives Google Alternatives: Protecting Your Data"></p></div></div></div></div></div></div></div></section><section data-id="46501a2" data-element_type="section"><div><div><div data-id="ce19e75" data-element_type="column"><div><div><div data-id="8f49f0c" data-element_type="widget" data-widget_type="heading.default"><p><h2>Google Photos Alternatives</h2></p></div><div data-id="3b7c0a6" data-element_type="widget" data-widget_type="image.default"><div><p><img width="992" height="558" src="https://justprivacy.org/media/2020/03/Google-Photos-Alternatives-1024x576.jpg" data-lazy-type="image" data-src="https://justprivacy.org/media/2020/03/Google-Photos-Alternatives-1024x576.jpg" alt="Google Photos Alternatives" loading="lazy" srcset="https://justprivacy.org/media/2020/03/Google-Photos-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Google-Photos-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Google-Photos-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Google-Photos-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Google-Photos-Alternatives.jpg 1920w" data-srcset="https://justprivacy.org/media/2020/03/Google-Photos-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Google-Photos-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Google-Photos-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Google-Photos-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Google-Photos-Alternatives.jpg 1920w" sizes="(max-width: 992px) 100vw, 992px" title="Google Photos Alternatives Google Alternatives: Protecting Your Data"></p></div></div><div data-id="9979111" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>Google offers unlimited storage for photo’s but Google isn’t doing it to be nice. They will use your photos to scan your pictures and track things you do. I don’t think Google or any company needs to know that much about you.</p><p>Here are a few good Google Photo’s alternatives:</p><ol><li><a href="https://piwigo.org/" target="_blank" rel="noopener">Piwigo</a> – Is an open-source photo gallery software.&nbsp;</li><li><a href="https://zyl.ai/" target="_blank" rel="noopener">Zyl</a> – Is a great mobile app that cares about privacy.</li><li><a href="https://crypt.ee/" target="_blank" rel="noopener">Cryptee</a> –&nbsp; Is a great option if you’re serious about your privacy. They offer many services as well as not just photos.</li><li><a href="https://cluster.co/" target="_blank" rel="noopener">Cluster</a> – A free app that’s allows you to create photo albums and share them with people you choose.</li><li><a href="https://photostructure.com/" target="_blank" rel="noopener">PhotoStructure</a> – relatively new self-hosted privacy-friendly photo manager</li></ol></div></div></div></div></div></div></div></div></section><section data-id="e855368" data-element_type="section"><div><div><div data-id="205ce2f" data-element_type="column"><div><div><div data-id="2236d87" data-element_type="widget" data-widget_type="heading.default"><p><h2>Google Analytics Alternatives</h2></p></div><div data-id="643d0e7" data-element_type="widget" data-widget_type="image.default"><div><p><img width="992" height="558" src="https://justprivacy.org/media/2020/03/Google-Analytics-Alternative-1024x576.jpg" data-lazy-type="image" data-src="https://justprivacy.org/media/2020/03/Google-Analytics-Alternative-1024x576.jpg" alt="Google Analytics Alternative" loading="lazy" srcset="https://justprivacy.org/media/2020/03/Google-Analytics-Alternative-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Google-Analytics-Alternative-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Google-Analytics-Alternative-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Google-Analytics-Alternative-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Google-Analytics-Alternative.jpg 1920w" data-srcset="https://justprivacy.org/media/2020/03/Google-Analytics-Alternative-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Google-Analytics-Alternative-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Google-Analytics-Alternative-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Google-Analytics-Alternative-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Google-Analytics-Alternative.jpg 1920w" sizes="(max-width: 992px) 100vw, 992px" title="Google Analytics Alternative Google Alternatives: Protecting Your Data"></p></div></div><div data-id="fc58c6b" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>If you’re running a website there are good reasons to use alternatives to Google Analytics. One, you’re respecting your visitor’s privacy and there are more friendly alternatives.</p><p>Websites who run Google Adsense campaigns are the ones who usually use Google Analytics because it would be much more difficult to track your results without it.</p><p>Here are a few Analytics alternatives:</p><ol><li><a href="https://plausible.io/" target="_blank" rel="nofollow noopener">Plausible</a> – A simple and privacy-friendly alternative to Google Analytics. It’s also lightweight, open-source, and has no cookies.</li><li><a href="https://matomo.org/" target="_blank" rel="noopener">Matomo</a> – It was formerly Piwik, and is an open-sourced platform that understands the privacy of the users. It also allows website admins to import historic Google Analytics data to Matomo.</li><li><a href="https://usefathom.com/" target="_blank" rel="noopener">Fathom Analytics</a> – Is an open-sourced website analytics platform that is efficient and fast. (<a href="https://github.com/usefathom/fathom" target="_blank" rel="noopener">GitHub</a>)</li><li><a href="https://clicky.com/" target="_blank" rel="noopener">Clicky</a> – Is a good alternative to Google Analytics because it keeps the user’s privacy by making their IP anonymous. It’s also efficient and user-friendly. It is also certified by <a href="https://www.privacyshield.gov/welcome" target="_blank" rel="noopener">Privacy Shield</a>!</li><li><a href="https://www.atinternet.com/en/" target="_blank" rel="noopener">AT Internet</a> – Is a French company that was created in 1996. It’s good for performance measurement or sites, and applications.</li><li><a href="https://www.foxmetrics.com/" target="_blank" rel="noopener">FoxMetrics</a> – Is a platform that allows you to understand and analyze your customer’s actions from your desktop and mobile device.</li></ol></div></div></div></div></div></div></div></div></section><section data-id="9f07b94" data-element_type="section"><div><div><div data-id="5b063df" data-element_type="column"><div><div><div data-id="dafc60c" data-element_type="widget" data-widget_type="heading.default"><p><h2>Google Translate Alternatives</h2></p></div><div data-id="eb7e8e7" data-element_type="widget" data-widget_type="image.default"><div><p><img width="992" height="558" src="https://justprivacy.org/media/2020/03/Google-Translate-Alternatives-1024x576.jpg" data-lazy-type="image" data-src="https://justprivacy.org/media/2020/03/Google-Translate-Alternatives-1024x576.jpg" alt="Google Translate Alternatives" loading="lazy" srcset="https://justprivacy.org/media/2020/03/Google-Translate-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Google-Translate-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Google-Translate-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Google-Translate-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Google-Translate-Alternatives.jpg 1920w" data-srcset="https://justprivacy.org/media/2020/03/Google-Translate-Alternatives-1024x576.jpg 1024w, https://justprivacy.org/media/2020/03/Google-Translate-Alternatives-300x169.jpg 300w, https://justprivacy.org/media/2020/03/Google-Translate-Alternatives-768x432.jpg 768w, https://justprivacy.org/media/2020/03/Google-Translate-Alternatives-1536x864.jpg 1536w, https://justprivacy.org/media/2020/03/Google-Translate-Alternatives.jpg 1920w" sizes="(max-width: 992px) 100vw, 992px" title="Google Translate Alternatives Google Alternatives: Protecting Your Data"></p></div></div><div data-id="bae68a8" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>Google has many privacy issues and Google Translate is no exception. Google …</p></div></div></div></div></div></div></div></div></section></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://justprivacy.org/google-alternatives/">https://justprivacy.org/google-alternatives/</a></em></p>]]>
            </description>
            <link>https://justprivacy.org/google-alternatives/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25380999</guid>
            <pubDate>Fri, 11 Dec 2020 00:59:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How a Kubernetes Pod Gets an IP Address]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25380898">thread link</a>) | @freedomben
<br/>
December 10, 2020 | https://ronaknathani.com/blog/2020/08/how-a-kubernetes-pod-gets-an-ip-address/ | <a href="https://web.archive.org/web/*/https://ronaknathani.com/blog/2020/08/how-a-kubernetes-pod-gets-an-ip-address/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>One of the core requirements of the
<a href="https://kubernetes.io/docs/concepts/cluster-administration/networking/#the-kubernetes-network-model" target="_blank" rel="noopener">Kubernetes networking model</a> is that every pod should get its own IP address and that every pod in the cluster should be able to talk to it using this IP address. There are several network providers (flannel, calico, canal, etc.) that implement this networking model.</p><p>As I started working on Kubernetes, it wasn’t completely clear to me how every pod is assigned an IP address. I understood how various components worked independently, however, it wasn’t clear how these components fit together. For instance, I understood what CNI plugins were, however, I didn’t know how they were invoked. So, I wanted to write this post to share what I have learned about various networking components and how they are stitched together in a kubernetes cluster for every pod to receive an IP address.</p><p>There are various ways of setting up networking in kubernetes and various options for a container runtime. For this post, I will use
<a href="https://github.com/coreos/flannel" target="_blank" rel="noopener">Flannel</a> as the network provider and
<a href="https://github.com/containerd/containerd" target="_blank" rel="noopener">Containerd</a> as the container runtime. Also, I am going to assume that you know how container networking works and only share a very brief overview below for context.</p><h2 id="some-background-concepts">Some Background Concepts</h2><h3 id="container-networking-a-very-brief-overview">Container Networking: A Very Brief Overview</h3><p>There are some really good posts explaining how container networking works. For context, I will go over a very high level overview here with a single approach that involves linux bridge networking and packet encapsulation. I am skipping details here as container networking deserves a blog post of itself. Some of the posts that I have found to be very educational in this space are
<a href="#container-networking">linked in the references below</a>.</p><h4 id="containers-on-the-same-host">Containers on the same host</h4><p>One of the ways containers running on the same host can talk to each other via their IP addresses is through a linux bridge. In the kubernetes (and docker) world, a
<a href="https://man7.org/linux/man-pages/man4/veth.4.html" target="_blank" rel="noopener">veth (virtual ethernet)</a> device is created to achieve this. One end of this veth device is inserted into the container network namespace and the other end is connected to a
<a href="https://wiki.archlinux.org/index.php/Network_bridge" target="_blank" rel="noopener">linux bridge</a> on the host network. All containers on the same host have one end of this veth pair connected to the linux bridge and they can talk to each other using their IP addresses via the bridge. The linux bridge is also assigned an IP address and it acts as a gateway for egress traffic from pods destined to different nodes.
<img src="https://ronaknathani.com/blog/2020/08/how-a-kubernetes-pod-gets-an-ip-address/bridge-networking.png" alt="bridge networking"></p><h4 id="containers-on-different-hosts">Containers on different hosts</h4><p>One of the ways containers running on different hosts can talk to each other via their IP addresses is by using packet encapsulation. Flannel supports this through
<a href="https://vincent.bernat.ch/en/blog/2017-vxlan-linux" target="_blank" rel="noopener">vxlan</a> which wraps the original packet inside a UDP packet and sends it to the destination.</p><p>In a kubernetes cluster, flannel creates a vxlan device and some route table entries on each of the nodes. Every packet that’s destined for a container on a different host goes through the vxlan device and is encapsulated in a UDP packet. On the destination, the encapsulated packet is retrieved and the packet is routed through to the destined pod.
<img src="https://ronaknathani.com/blog/2020/08/how-a-kubernetes-pod-gets-an-ip-address/flannel-networking.png" alt="flannel networking"></p><p><em>NOTE: This is just one of the ways how networking between containers can be configured.</em></p><h3 id="what-is-cri">What Is CRI?</h3><p><a href="https://github.com/kubernetes/cri-api" target="_blank" rel="noopener">CRI (Container Runtime Interface)</a> is a plugin interface that allows kubelet to use different container runtimes. Various container runtimes implement the CRI API and this allows users to use the container runtime of their choice in their kubernetes installation.</p><h3 id="what-is-cni">What is CNI?</h3><p><a href="https://github.com/containernetworking/cni" target="_blank" rel="noopener">CNI project</a> includes a
<a href="https://github.com/containernetworking/cni/blob/master/SPEC.md" target="_blank" rel="noopener">spec</a> to provide a generic plugin-based networking solution for linux containers. It also consists of various
<a href="https://github.com/containernetworking/plugins" target="_blank" rel="noopener">plugins</a> which perform different functions in configuring the pod network. A CNI plugin is an executable that follows the CNI spec and we’ll discuss some plugins in the post below.</p><h2 id="assigning-subnets-to-nodes-for-pod-ip-addresses">Assigning Subnets To Nodes For Pod IP Addresses</h2><p>If all pods are required to have an IP address, it’s important to ensure that all pods across the entire cluster have a unique IP address. This is achieved by assigning each node a unique subnet from which pods are assigned IP addresses on that node.</p><h3 id="node-ipam-controller">Node IPAM Controller</h3><p>When <code>nodeipam</code> is passed as an option to the
<a href="https://kubernetes.io/docs/reference/command-line-tools-reference/kube-controller-manager/" target="_blank" rel="noopener">kube-controller-manager’s</a> <code>--controllers</code> command line flag, it allocates each node a dedicated subnet (podCIDR) from the cluster CIDR (IP range for the cluster network). Since these podCIDRs are disjoint subnets, it allows assigning each pod a unique IP address.</p><p>A kubernetes node is assigned a podCIDR when the node first registers with the cluster. To change the podCIDR allocated to nodes in a cluster, nodes need to be de-registered and then re-registered with any configuration changes first applied to the kubernetes control plane. <code>podCIDR</code> for a node can be listed using the following command.</p><pre><code>$ kubectl get no &lt;nodeName&gt; -o json | jq '.spec.podCIDR'
10.244.0.0/24
</code></pre><h2 id="kubelet-container-runtime-and-cni-plugins---how-its-all-stitched-together">Kubelet, Container Runtime and CNI Plugins - how it’s all stitched together</h2><p>When a pod is scheduled on a node, a lot of things happen to start up a pod. In this section, I’ll only focus on the interactions that relate to configuring network for the pod.</p><p>Once a pod is scheduled on the node, the following interactions result in configuring the network and starting the application container.
<img src="https://ronaknathani.com/blog/2020/08/how-a-kubernetes-pod-gets-an-ip-address/kubelet-cri-cni-flowchart.png" alt="kubelet-cri-cni-flowchart"></p><p>Ref:
<a href="https://github.com/containerd/cri/blob/v1.11.1/docs/architecture.md" target="_blank" rel="noopener">Containerd cri plugin architecture</a></p><h2 id="interactions-between-container-runtime-and-cni-plugins">Interactions between Container Runtime and CNI Plugins</h2><p>Every network provider has a CNI plugin which is invoked by the container runtime to configure network for a pod as it’s started. With containerd as the container runtime,
<a href="https://github.com/containerd/cri" target="_blank" rel="noopener">Containerd CRI plugin</a> invokes the CNI plugin. Every network provider also has an agent that’s installed on each of the kubernetes node to configure pod networking. When the network provider agent is installed, it either ships with the CNI config or it creates one on the node which is then used by the CRI plugin to figure out which CNI plugin to call.</p><p>The location for the CNI config file is configurable and the default value is <code>/etc/cni/net.d/&lt;config-file&gt;</code>. CNI plugins need to be shipped on every node by the cluster administrators. The location for CNI plugins is configurable as well and the default value is <code>/opt/cni/bin</code>.</p><p>In case of containerd as the container runtime, path for CNI configuration and CNI plugin binaries can be specified under <code>[plugins."io.containerd.grpc.v1.cri".cni]</code> section of the
<a href="https://github.com/containerd/cri/blob/master/docs/config.md" target="_blank" rel="noopener">containerd config</a>.</p><p>Since we are referring to Flannel as the network provider here, I’ll talk a little about how Flannel is set up. Flanneld is the Flannel daemon and is typically installed on a kubernetes cluster as a daemonset with <code>install-cni</code> as an
<a href="https://github.com/coreos/flannel/blob/master/Documentation/kube-flannel.yml#L172" target="_blank" rel="noopener">init container</a>. The <code>install-cni</code> container creates the
<a href="https://gist.github.com/ronaknnathani/957a56210bd4fbd8e11120273c6b4ede" target="_blank" rel="noopener">CNI configuration file</a> - <code>/etc/cni/net.d/10-flannel.conflist</code> - on each node. Flanneld creates a vxlan device, fetches networking metadata from the apiserver and watches for updates on pods. As pods are created, it distributes routes for all pods across the entire cluster and these routes allow pods to connect to each other via their IP addresses. For details on how flannel works, I recommend the
<a href="#how-flannel-works">linked references below</a>.</p><p>The interactions between Containerd CRI Plugin and CNI plugins can be visualized as follows:
<img src="https://ronaknathani.com/blog/2020/08/how-a-kubernetes-pod-gets-an-ip-address/kubelet-cri-cni-interactions.png" alt="kubelet-cri-cni-interactions"></p><p>As described above, kubelet calls the Containerd CRI plugin in order to create a pod and Containerd CRI plugin calls the CNI plugin to configure network for the pod. The network provider CNI plugin calls other base CNI plugins to configure the network. The interactions between CNI plugins are described below.</p><h3 id="interactions-between-cni-plugins">Interactions Between CNI Plugins</h3><p>There are various CNI plugins that help configure networking between containers on a host. For this post, we will refer to 3 plugins.</p><h4 id="flannel-cni-plugin">Flannel CNI Plugin</h4><p>When using Flannel as the network provider, the Containerd CRI plugin invokes the
<a href="https://github.com/containernetworking/plugins/tree/master/plugins/meta/flannel" target="_blank" rel="noopener">Flannel CNI plugin</a> using the CNI configuration file - <code>/etc/cni/net.d/10-flannel.conflist</code>.</p><pre><code>$ cat /etc/cni/net.d/10-flannel.conflist
{
  "name": "cni0",
  "plugins": [
    {
      "type": "flannel",
      "delegate": {
		 "ipMasq": false,
        "hairpinMode": true,
        "isDefaultGateway": true
      }
    }
  ]
}
</code></pre><p>The Fannel CNI plugin works in conjunction with Flanneld. When Flanneld starts up, it fetches the podCIDR and other network related details from the apiserver and stores them in a file - <code>/run/flannel/subnet.env</code>.</p><pre><code>FLANNEL_NETWORK=10.244.0.0/16 
FLANNEL_SUBNET=10.244.0.1/24
FLANNEL_MTU=1450 
FLANNEL_IPMASQ=false
</code></pre><p>The Flannel CNI plugin uses the information in <code>/run/flannel/subnet.env</code> to configure and invoke the bridge CNI plugin.</p><h4 id="bridge-cni-plugin">Bridge CNI Plugin</h4><p>Flannel CNI plugin calls the Bridge CNI plugin with the following configuration:</p><pre><code>{
  "name": "cni0",
  "type": "bridge",
  "mtu": 1450,
  "ipMasq": false,
  "isGateway": true,
  "ipam": {
    "type": "host-local",
    "subnet": "10.244.0.0/24"
  }
}
</code></pre><p>When
<a href="https://github.com/containernetworking/plugins/tree/master/plugins/main/bridge" target="_blank" rel="noopener">Bridge CNI plugin</a> is invoked for the first time, it creates a linux bridge with the <code>"name": "cni0"</code> specified in the config file. For every pod, it then creates a veth pair - one end of the pair is in the container’s network namespace and the other end is connected to the linux bridge on the host network. With Bridge CNI plugin, all containers on a host are connected to the linux bridge on the host network.</p><p>After configuring the veth pair, Bridge plugin invokes the host-local IPAM CNI plugin. Which IPAM plugin to use can be configured in the CNI config CRI plugin uses to call the flannel CNI plugin.</p><h4 id="host-local-ipam-cni-plugins">Host-local IPAM CNI plugins</h4><p>The Bridge CNI plugin calls the
<a href="https://github.com/containernetworking/plugins/tree/master/plugins/ipam/host-local" target="_blank" rel="noopener">host-local IPAM CNI plugin</a> with the following configuration:</p><pre><code>{
  "name": "cni0",
  "ipam": {
    "type": "host-local",
    "subnet": "10.244.0.0/24",
    "dataDir": "/var/lib/cni/networks"
  }
}
</code></pre><p>Host-local IPAM (IP Address Management) plugin returns an IP address for the container from the <code>subnet</code> and stores the allocated IP locally on the host under the directory specified under <code>dataDir</code> - <code>/var/lib/cni/networks/&lt;network-name=cni0&gt;/&lt;ip&gt;</code>. <code>/var/lib/cni/networks/&lt;network-name=cni0&gt;/&lt;ip&gt;</code> file contains the container ID to which the IP is assigned.</p><p>When invoked, the host-local IPAM plugin returns the following payload</p><pre><code>{
  "ip4": {
    "ip": "10.244.4.2",
    "gateway": "10.244.4.3"
  },
  "dns": {}
}
</code></pre><h2 id="summary">Summary</h2><p>Kube-controller-manager assigns a podCIDR to each node. Pods on a node are …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ronaknathani.com/blog/2020/08/how-a-kubernetes-pod-gets-an-ip-address/">https://ronaknathani.com/blog/2020/08/how-a-kubernetes-pod-gets-an-ip-address/</a></em></p>]]>
            </description>
            <link>https://ronaknathani.com/blog/2020/08/how-a-kubernetes-pod-gets-an-ip-address/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25380898</guid>
            <pubDate>Fri, 11 Dec 2020 00:44:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Simplify, batch, and cache: how Shopify optimized storefront response times]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25380697">thread link</a>) | @vaillancourtmax
<br/>
December 10, 2020 | https://shopify.engineering/simplify-batch-cache-optimized-server-side-storefront-rendering | <a href="https://web.archive.org/web/*/https://shopify.engineering/simplify-batch-cache-optimized-server-side-storefront-rendering">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
  <p><em><strong>On December 16, 2020 Shipit! presents: Performance Tips from the Storefront Renderer Team.&nbsp;Celso and Maxime will share how the&nbsp;team optimized this Ruby application for the particular use case of serving storefront traffic. <a href="#Register">Please Register!</a></strong></em></p>
<p><strong>By Celso Dantas and Maxime Vaillancourt</strong></p>
<p>In the previous post about <a href="https://shopify.engineering/how-shopify-reduced-storefront-response-times-rewrite" target="_blank" title="How Shopify Reduced Storefront Response Times with a Rewrite" rel="nofollow noopener noreferrer">our new storefront rendering engine</a>, we described how we went about the rewrite process and smoothly transitioned to serve storefront requests with the new implementation. As a follow-up and based on readers’ comments and questions, this post dives deeper into the technical details of how we built the new storefront rendering engine to be faster than the previous implementation.</p>
<p>To set the table, let’s see how the new storefront rendering engine performs:</p>
<ul>
<li>It generates a response in less than ~45ms for 75% of storefront requests;</li>
<li>It generates a response in less than ~230ms for 90% of storefront requests;</li>
<li>It generates a response in less than ~900ms for 99% of storefront requests.</li>
</ul>
<p>Thanks to the new storefront rendering engine, the average storefront response is nearly 5x faster than with the previous implementation. Of course, how fast the rendering engine is able to process a request and spit out a response depends on two key factors: the shop’s Liquid theme implementation, and the number of resources needed to process the request. To get a better idea of where the storefront rendering engine spends its time when processing a request, try using the <a href="https://shopify.engineering/in-depth-liquid-render-analysis-shopify-theme-inspector-chrome-extension" target="_blank" title="How to Do an In-depth Liquid Render Analysis with Theme Inspector" rel="nofollow noopener noreferrer">Shopify Theme Inspector</a>: this tool will help you identify potential bottlenecks so you can work on improving performance in those areas.</p>
<figure><img alt="A data scheme diagram showing that the Storefront Renderer and Redis instance are contained in a Kubernetes node. The Storefront Renderer sends Redis data. The Storefront Renderer sends data to two sharded data stores outside of the Kubernetes node: Sharded MySQL and Sharded Redis" data-src="https://cdn.shopify.com/s/files/1/0779/4361/files/Storefront-renderer-data-schema_c5f379b7-619f-4ddb-8064-d093550c4731.jpg?v=1607636250" src="https://cdn.shopify.com/s/files/1/0779/4361/files/Storefront-renderer-data-schema_c5f379b7-619f-4ddb-8064-d093550c4731.jpg?v=1607636250">
<figcaption>A simplified data schema of the application</figcaption>
</figure>
<p>Before we cover each topic, let’s briefly describe our application stack. As mentioned in the previous post, the new storefront rendering engine is a Ruby application. It talks to a sharded MySQL database and uses Redis to store and retrieve cached data.</p>
<p>Optimizing how we load all that data is extremely important. As one of our requirements was to improve rendering time for Storefront requests. Here are some of the approaches that we took to accomplish that.</p>

<p>To reduce the number of network round trips to the database, we use <a href="https://dev.mysql.com/doc/internals/en/multi-statement.html" target="_blank" title="MySQL - 14.8.2 Multi-Statement" rel="nofollow noopener noreferrer">MySQL’s multi-statement feature</a> to allow sending multiple queries at once. With a single request to the database, we can load data from multiple tables at once. Here’s a simplified example:</p>
<figure>

</figure>
<p>This request is especially useful to batch-load a lot of data very early in the response lifecycle based on the incoming request. After identifying the type of request, we trigger a single multi-statement query to fetch the data we need for that particular request in one go, which we’ll discuss later in this blog post. For example, for a request for a product page, we’ll load data for the product, its variants, its images, and other product-related resources in addition to information about the shop and the storefront theme, all in a single round-trip to MySQL.</p>

<p>As shown above, the new storefront rendering engine uses handcrafted, optimized SQL queries. This allows us to easily write fine-tuned SQL queries to select only the columns we need for each resource and leverage JOINs and sub-SELECT statements to optimize data loading based on the resources to load which are sometimes less straightforward to implement with a full-service object-relational mapping (ORM) layer.</p>
<p>However, the main benefit of this approach is the tiny memory footprint of using a raw MySQL client compared to using an object-relational mapping (ORM) layer that’s unnecessarily complex for our needs. Since there’s no unnecessary abstraction, forgoing the use of an ORM drastically simplifies the flow of data. Once the raw rows come back from MySQL, we effectively use the simplest ORM possible: we create plain old Ruby objects from the raw rows to model the business domain. We then use these Ruby objects for the remainder of the request. Below is an example of how it’s done.</p>
<figure>

</figure>
<p>Of course, not using an ORM layer comes with a cost: if implemented poorly, this approach can lead to more complexity leaking into the application code. Creating thin model abstractions using plain old Ruby objects prevents this from happening, and makes it easier to interact with resources while meeting our performance criteria. Of course, this approach isn’t particularly common and has the potential to cause panic in software engineers who aren’t heavily involved in performance work, instead worrying about schema migrations and compatibility issues. However, when speed is critical, we accept to take on that complexity.</p>

<p>An HTTP request for a Shopify storefront may end up requiring many different resources from data stores to render properly. For example, a request for a product page could lead to requiring information about other products, images, variants, inventory information, and a whole lot of other data not loaded on multi-statement select. The first time the storefront rendering engine loads this page, it needs to query the database, sometimes making multiple requests, to retrieve all the information it needs. This usually happens during the request at any given time.</p>
<figure><img alt="A flow diagram showing the Storefront Renderer's requests from  the data stores and how it uses a Query Book Keeper Middlewear to eager-load data" data-src="https://cdn.shopify.com/s/files/1/0779/4361/files/flow-request-bookeeping-solution_adbd68eb-cc30-4be5-9bdf-104011224ad2.jpg?v=1607636269" src="https://cdn.shopify.com/s/files/1/0779/4361/files/flow-request-bookeeping-solution_adbd68eb-cc30-4be5-9bdf-104011224ad2.jpg?v=1607636269">
<figcaption>Flow of a request with the Book-keeping solution</figcaption>
</figure>
<p>As it retrieves this data for the first time, the storefront rendering engine keeps track of the queries it performed on the database for that particular product page and stores that list of queries in a key-value store for later use. When an HTTP request for the same product page comes in later (which it knows when the cache key matches), the rendering engine looks up the list of queries it performed throughout the previous request of the same type and performs those queries all at once, at the very beginning of the current request, because we’re pretty confident we’ll need them for this request (since they were used in the previous request).</p>
<p>This book-keeping mechanism lets us eager-load data we’re pretty confident we’ll need. Of course, when a page changes, this may lead to over-fetching and/or under-fetching, which is expected, and the shape of the data we fetch stabilizes quickly over time as more requests come in.</p>
<p>On the other side, some liquid models of Shopify’s storefronts are not accessed as frequently, and we don’t need to eager-load data related to them. If we did, we’d increase I/O wait time for something that we probably wouldn’t use very often. What the new rendering engine does instead is lazy-load this data by default. Unless the book-keeping mechanism described above eager-loads it, we’ll defer retrieving data to only load it if it’s needed for a particular request.</p>

<p>Much like a CPU’s caching architecture, the new rendering engine implements multiple layers of caching to accelerate responses.</p>
<p>A critical aside before we jump into this section: adding caching should never be the first step towards building performance-oriented software. Start by building a solution that’s extremely fast from the get go, even without caching. Once this is achieved, then consider adding caching to reduce load on the various components on the system while accelerating frequent use cases. Caching is like a sharp knife and can introduce hard to detect bugs.</p>
<h2>In-Memory Cache</h2>
<figure><img alt="A data scheme diagram showing that the Storefront Renderer and Redis instance are contained in a Kubernetes node. Within the Storefront Renderer is an In-memory cache. The Storefront Renderer sends Redis data. The Storefront Renderer sends data to two sharded data stores outside of the Kubernetes node: Sharded MySQL and Sharded Redis" data-src="https://cdn.shopify.com/s/files/1/0779/4361/files/Storefront-renderer-data-schema-in-memory-cache.jpg?v=1607636398" src="https://cdn.shopify.com/s/files/1/0779/4361/files/Storefront-renderer-data-schema-in-memory-cache.jpg?v=1607636398">
<figcaption>A simplified data schema of the application with an in-memory cache for the Storefront Renderer</figcaption>
</figure>
<p>At the frontline of our caching system is an in-memory cache that you can essentially think of as a global hash that’s shared across requests within each web worker. Much like the majority of our caching mechanisms, this caching layer uses the LRU caching algorithm. As a result, we use this caching layer for data that’s accessed very often. This layer is especially useful in high throughput scenarios such as flash sales.</p>
<h2>Node-local Shared Caching</h2>
<p>As a second layer on top of the in-memory cache, the new rendering engine leverages a node-local Redis store that’s shared across all server workers on the same node. Since the database is available on the same machine as the rendering engine process itself, this node-local data transfer prevents network overhead and improves response times. As a result, multiple Ruby processes benefit from sharing cached data with one another.</p>
<h2>Full-page Caching</h2>
<p>Once the rendering engine successfully renders a full storefront response for a particular type of request, we store the final output (most often an HTML or JSON string) into the local Redis for later retrieval for subsequent requests that match the same cache key. This full-page caching solution lets us prevent regenerating storefront responses if we can by using the output we previously computed.</p>
<h2>Database Query Results Caching</h2>
<p>In a scenario where the full-page output cache, the in-memory cache, and the node-local cache doesn’t have a valid entry for a given request, we need to reach all the way to the database. Once we get a result back from MySQL, we transparently cache the results in Redis for later retrieval based on the queries and their parameters. As long as the cache keys don’t change, running the same database queries over and over always hit Redis instead of reaching all the way to the database.</p>
<h2>Liquid Object Memoizer</h2>
<p>Thanks to the Liquid templating language, merchants and partners may build custom storefront themes. When loading a particular storefront page, it’s possible that the Liquid template to render includes multiple references to the same object. This is common on the product page for example, where the template will include many references to the product object: <br><code>{{ product.title }}</code>, <code>{{ product.description }}</code>, <code>{{ product.featured_media }}</code>, and others.</p>
<p>Of course, when each of these are executed, we don’t fetch the product over and over again from the database—we fetch it once, then keep it in memory for later use throughout the request lifecycle. This means that if the same product object is required multiple times at different locations during the render process, we’ll always use the same one and only instance of it throughout the entire …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://shopify.engineering/simplify-batch-cache-optimized-server-side-storefront-rendering">https://shopify.engineering/simplify-batch-cache-optimized-server-side-storefront-rendering</a></em></p>]]>
            </description>
            <link>https://shopify.engineering/simplify-batch-cache-optimized-server-side-storefront-rendering</link>
            <guid isPermaLink="false">hacker-news-small-sites-25380697</guid>
            <pubDate>Fri, 11 Dec 2020 00:20:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Older patients 23% more likely to die if surgery occurs on surgeon's birthday]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25380320">thread link</a>) | @Bologo
<br/>
December 10, 2020 | https://www.psychnewsdaily.com/elderly-emergency-surgery-patients-23-more-likely-to-die-if-operation-takes-place-on-surgeons-birthday/ | <a href="https://web.archive.org/web/*/https://www.psychnewsdaily.com/elderly-emergency-surgery-patients-23-more-likely-to-die-if-operation-takes-place-on-surgeons-birthday/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-5563" role="main"><div><div><div><p>A <a href="https://www.bmj.com/content/371/bmj.m4381" target="_blank" rel="noreferrer noopener">new study has found</a> that elderly patients who underwent emergency surgery on their surgeon’s birthday had significantly higher 30-day mortality rates than patients whose surgery took place on any other day of the year. <span data-ez-name="psychnewsdaily_com-medrectangle-3"></span></p><p>The 30-day mortality rate (defined as death within 30 days after surgery)&nbsp;for the “surgeon’s birthday” group was 6.9%. This was 23% higher than the 5.6% rate for the “other day” group.</p><p>The study, which appears today in the <em>British Medical Journal</em> (<a href="https://www.bmj.com/" target="_blank" rel="noreferrer noopener">BMJ</a>),&nbsp;looked at 980,876 procedures performed in US hospitals by 47,489 surgeons.&nbsp;Of those procedures, 2,064 (0.2%) took place on a surgeon’s birthday.&nbsp;The patients were all Medicare beneficiaries aged 65 to 99. They had all undergone one of 17 common emergency surgical procedures between 2011 and 2014.</p><h2>Distractions during the most common emergency surgery types</h2><p>Examples of those 17 procedures included cardiovascular surgeries, hip and femur fracture, appendectomy, and small bowel resection. The study focused on&nbsp;emergency surgery, so as to&nbsp;minimize the potential selection bias. For example, surgeons might otherwise choose patients based on their illness severity, or patients might choose their surgeon.</p><p>As the authors write, “The effect size of surgeons’ birthday observed in our analysis (1.3 percentage point increase or a 23% increase in mortality), though substantial, is comparable to the impact of other events, including holidays (e.g., Christmas and New Year) and weekends.” <span data-ez-name="psychnewsdaily_com-medrectangle-4"></span></p><p>In fact, the <a href="https://amzn.to/3m5rimG" target="_blank" rel="noreferrer noopener">history of surgery</a> has often demonstrated that external factors can influence surgical outcomes. The authors refer to a 2014 study showing that <a href="https://pubmed.ncbi.nlm.nih.gov/23345314/" target="_blank" rel="noreferrer noopener">patients admitted to Scottish emergency rooms on&nbsp;public holidays had a 27% increase</a> in 30-day mortality.&nbsp;Other research has found, for example,&nbsp;that doctors are more likely to <a href="https://jamanetwork.com/journals/jamainternalmedicine/fullarticle/1910546" target="_blank" rel="noreferrer noopener">prescribe antibiotics</a> and <a href="https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2749268" target="_blank" rel="noreferrer noopener">opioids</a> — and <a href="https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2733171" target="_blank" rel="noreferrer noopener">less likely to order&nbsp;cancer screening tests</a> — as the workday progresses. This is most likely because the “cumulative cognitive demand” of such decisions gradually takes its toll.&nbsp;</p><p>Research on judges has yielded similar results. It has found, for example, that external factors as diverse as outdoor temperatures and sports results can influence judges’ decisions.&nbsp;</p><h2>A natural experiment: ER surgery on the doctor’s birthday</h2><p>But the authors say the “natural experiment” in the present study is more revealing than, for example, holiday-related mortality rates. That is because “those events not only affect physicians’ performance but also influence patients’ decision to seek care (i.e., patients seeking care on these special days might be sicker than those seeking care on other days), as well as hospital staffing.” Unless, of course, the patients know their surgeon’s birthday, which is unlikely (though that may change if this study becomes widely known).&nbsp;</p><p>The 1.3% effect size was the result after a very through series of controls. These included, for example, excluding those surgeons with the highest patient mortality rates. Other controls included assigning a random “pseudo-birthday” to surgeons to see whether the results still held up, or checking whether the surgeon did an above-average number of procedures on their birthday. </p><p>Likewise, the researchers controlled for “milestone” birthdays (such as 40 or 50). They also controlled for whether a birthday fell on a Friday, which might make after-work birthday festivities more likely.&nbsp;Their findings also held up when the analysis was restricted to procedures with the highest average mortality, or to only the most ill patients.&nbsp;In fact, without these adjustments, the 30-day mortality rate difference between the birthday and non-birthday groups (the unadjusted rate) was even higher (7.0% vs. 5.6%, or a 1.4% difference).</p><h2><strong>Why</strong> does emergency surgery suffer on surgeon’s birthday?</h2><p>The authors propose a few potential explanations for this “birthday effect.”&nbsp;</p><p>These include hurrying through an emergency surgery to be on time for after-work birthday events; <a href="https://www.psychnewsdaily.com/study-finds-users-not-notifications-initiate-89-of-smartphone-interactions/" target="_blank" rel="noreferrer noopener">distracting</a> birthday-related phone calls or text messages; more conversations with well-wishing staff members; and a decreased likelihood to go back to the hospital that evening if a patient’s condition deteriorates.</p><p>They also found that some surgeons did not work on their birthdays. While 2,144 surgeons in this study performed procedures one day before their birthday, and 2,027 did so one day after their birthday, only 1,805 surgeons carried out procedures on their actual birthday. This does not affect the results of the study’s analyses. But it does suggest “that birthdays are an important enough factor for some surgeons to choose not to operate on that day, which supports the credibility of our assumption that a birthday could be a distracting factor for those surgeons who choose to operate on that day,” the authors write.&nbsp;</p><h2><strong>Limitations</strong> <strong>and future directions</strong></h2><p>The researchers emphasized that this study focused on common procedures, and on older Medicare patients. This means that the findings may not apply to other types of patients, or to other surgical procedures.</p><p>Still, the authors write, these results may lead to “additional support for surgeons who have potentially distracting events,” such as birthdays, “to make sure that patients receive high quality surgical care regardless of when undergo surgery.”</p><hr><p><strong>Study: </strong>“<a href="https://dx.doi.org/10.1136/bmj.m4381" target="_blank" rel="noreferrer noopener">Patient mortality after surgery on the surgeon’s birthday: observational study</a>“<br><strong>Authors:</strong> Hirotaka Kato, Anupam B. Jena, and Yusuke Tsugawa<br><strong>Published in:</strong> <a href="https://www.bmj.com/" target="_blank" rel="noreferrer noopener"><em>The BMJ</em></a><br><strong>Publication date: </strong>December 10, 2020<br><strong>DOI:</strong> <a href="https://dx.doi.org/10.1136/bmj.m4381" target="_blank" rel="noreferrer noopener">https://dx.doi.org/10.1136/bmj.m4381</a><br><strong>Photo: </strong>by&nbsp;<a href="https://pixabay.com/users/theshiv76-1022681/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=766166">Jason Shivers</a>&nbsp;from&nbsp;<a href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=766166">Pixabay</a>&nbsp;</p><p>For a weekly summary of the latest psychology news, subscribe to our <a href="https://www.psychnewsdaily.com/the-psych-news-weekly-newsletter/" target="_blank" rel="noreferrer noopener">Psych News Weekly newsletter</a>.</p></div></div></div></article></div>]]>
            </description>
            <link>https://www.psychnewsdaily.com/elderly-emergency-surgery-patients-23-more-likely-to-die-if-operation-takes-place-on-surgeons-birthday/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25380320</guid>
            <pubDate>Thu, 10 Dec 2020 23:40:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[In Defense of Mutual TLS]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 22 (<a href="https://news.ycombinator.com/item?id=25380003">thread link</a>) | @dogecoinbase
<br/>
December 10, 2020 | https://www.notion.so/In-Defense-of-Mutual-TLS-a86e30759b79446eb50befbc2f474a8f | <a href="https://web.archive.org/web/*/https://www.notion.so/In-Defense-of-Mutual-TLS-a86e30759b79446eb50befbc2f474a8f">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.notion.so/In-Defense-of-Mutual-TLS-a86e30759b79446eb50befbc2f474a8f</link>
            <guid isPermaLink="false">hacker-news-small-sites-25380003</guid>
            <pubDate>Thu, 10 Dec 2020 23:05:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[FreeBSD Remote Process Plugin: Final Milestone Achieved]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25379737">thread link</a>) | @fcambus
<br/>
December 10, 2020 | https://www.moritz.systems/blog/freebsd-remote-plugin-final-milestone-achieved/ | <a href="https://web.archive.org/web/*/https://www.moritz.systems/blog/freebsd-remote-plugin-final-milestone-achieved/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<p>Moritz Systems have been <a href="https://www.moritz.systems/blog/lldb-debugger-improvements-for-freebsd/">contracted</a>
by the <a href="https://freebsdfoundation.org/">FreeBSD Foundation</a> to modernize the
<a href="https://lldb.llvm.org/">LLDB</a> debugger’s support for
<a href="https://www.freebsd.org/">FreeBSD</a>.  We are working on a new plugin
utilizing the more modern client-server layout that is already used
by Darwin, Linux, NetBSD and (unofficially) OpenBSD.  The new plugin is
going to gradually replace the legacy one.</p>

<p><img src="https://raw.githubusercontent.com/Moritz-Systems/moritz_staticDir/master/LLVM_Logo.svg" alt="LLVM">
</p><center><small><small>This dragon image is owned by Apple Inc.</small></small></center>

<p>The Project Schedule was divided into three milestones, each taking
approximately one month:</p>

<ul>
<li>M1 Introduce new FreeBSD Remote Process Plugin for x86_64 with
basic support and upstream to LLVM.</li>
<li>M2 Ensure and add the mandated features in the project (process
launch, process attach (pid), process attach (name), userland
core files, breakpoints, watchpoints, threads, remote debugging)
for FreeBSD/amd64 and FreeBSD/i386.</li>
<li>M3 Iterate over the LLDB tests. Detect and as time permits fix bugs.
Ensure bug reports for each non-fixed and known problem. Add missing
man pages and update the FreeBSD Handbook.</li>
</ul>

<p>In the <a href="https://www.moritz.systems/blog/freebsd-remote-plugin-is-now-the-default-in-lldb/">previous report</a>
we have announced the completion of the second project’s milestone,
that is achieving the feature parity with the legacy plugin and enabling
the new plugin by default on 32 and 64-bit x86.  We have explained how different
platforms express process and thread identifiers and how <code>SIGTRAP</code> is used
to deliver event notifications to the debugger.  We have also described
the two alternative approaches on hooking the debugger up to the process -
either via launching it, or attaching to a running process.</p>

<p>The third milestone was focused on fixing bugs, updating the test suite
state and documentation.  We are proud to announce that this stage
is finished as well, and therefore <strong>the whole contract is accomplished
timely and successfully</strong>.
In this article, we would like to shortly summarize our work
and describe some of the more interesting areas of focus in detail.</p>

<h2 id="a-race-condition-while-copying-watchpoints-to-new-threads">A race condition while copying watchpoints to new threads</h2>

<p>The primary goal in the third milestone was to go through failing tests
and either fix them, or at least document the failures and mark
the respective tests as expected to fail.  The first really interesting
problem we’ve found while investigating the
<a href="https://github.com/llvm/llvm-project/blob/7e2ef84fe7232368f92ec0835c3eda869c85a445/lldb/test/API/commands/watchpoints/multiple_threads/main.cpp">commands/watchpoints/multiple_threads</a>
test.
The purpose of the test is to verify that watchpoints work when
the respective variables are altered by a non-main thread.</p>

<p>Originally, the test was done in two variants: with the watchpoint being
set before starting the new thread, and after starting it.  The first
variant was supposed to verify whether LLDB correctly copies existing
watchpoints to new threads as they are being started.  The second
variant verified whether the <code>watchpoint</code> command correctly adds
the new watchpoint to all running threads.</p>

<p><img src="https://raw.githubusercontent.com/Moritz-Systems/moritz_staticDir/master/debug_regs_copying.svg" alt="Debug Registers in threading application"></p>

<p>What’s important here is that hardware-assisted watchpoints on x86
are configured via altering the state of Debug Registers.  Like other
register sets, the values of DRs are thread-local, and therefore
the debugger needs to set them separately for every thread.
Furthermore, new threads inherit the DR state from parent threads
on FreeBSD, and our original watchpoint code relied on new threads
having the correct DR at start.</p>

<p>However, there is a catch.  The new thread is not reported to
the debugger until it is actually ready to start.  During this time,
the DRs are copied from the parent thread and it continues execution.
In fact, it is entirely feasible that the process is stopped due
to breakpoint in the parent thread before the new thread is actually
reported ready.  This creates an ample opportunity for the user to set
a new watchpoint, and this is precisely what happened to us during
the test.</p>

<p>At this point, the debugger is not yet aware that another thread
is being created.  However, the kernel has already copied the Debug
Register values from the parent thread.  As a result, the new thread
is created with the old DR values, while the debugger assumed that it
had the new values instead.</p>

<p>We have <a href="https://bugs.freebsd.org/bugzilla/show_bug.cgi?id=250954">reported this confusing behavior</a>
to the FreeBSD Bugzilla.  For the time being, we’ve changed the plugin
to explicitly copy DRs when a new thread is reported, therefore
guaranteeing that any changes during the problematic period are
propagated.  We have also extended the original test to cover three
scenarios: watchpoint set before requesting the new thread, watchpoint
set immediately after requesting it (i.e. falling into our race
condition) and watchpoint set after waiting for the new thread
to actually start running (i.e. covering the original intent).</p>

<h2 id="simplifying-the-register-reading-and-writing-logic">Simplifying the register reading and writing logic</h2>

<p>The original register reading and writing logic in the new plugin
has been inspired by the code present in the NetBSD plugin.  It roughly
consisted of <a href="https://github.com/llvm/llvm-project/commit/58abbf821ce88f4d35cdfa36cdb486e2d56a04e2#diff-fe8211dffcb3e79e018065063ac970a718e5905c699517348d80c61859fcd989L538">a large switch-case construct</a>
that mapped enumeration values into appropriate operations on system
structures.  There were three large switches in total: one for reading
register values, one for writing register values and one for mapping
enumeration values from i386 to amd64 platform.  Furthermore, the first
two needed large separate variants for i386 and amd64.</p>

<p>At the same time, LLDB already carried another set of register
information that was created via macros by inspecting struct field
offsets and sizes.  Unlike the plugin logic, it did not use system
structures but instead <a href="https://github.com/llvm/llvm-project/blob/58abbf821ce88f4d35cdfa36cdb486e2d56a04e2/lldb/source/Plugins/Process/Utility/RegisterContextFreeBSD_x86_64.cpp#L17">inlined them</a>.
This is because the same structures are used to access core dumps,
and avoiding system headers makes it possible to compile the code
and inspect FreeBSD core dumps on other systems.</p>

<p><img src="https://raw.githubusercontent.com/Moritz-Systems/moritz_staticDir/master/register_mode.svg" alt="LLDB Registers"></p>

<p>Unlike NetBSD, the Linux plugin actually reused the offsets and sizes
from this data to access register sets.  We have decided to follow suit,
and replace the aforementioned custom logic with accesses based
on offset and size values, and this allowed us to reduce code
duplication significantly.  We have also added platform-specific <a href="https://github.com/llvm/llvm-project/blob/6adb55877c4bae6c75ab0d2c0374fab6787bff2d/lldb/unittests/Process/Utility/RegisterContextFreeBSDTest.cpp">tests
that verify that the offsets and sizes are correct, compared to system
structures</a>.</p>

<p>What’s even more important is that this change improved maintainability
a lot.  We have had hit cryptic bugs that turned out to be caused
by wrong integer type being used inside the switch-case.  Storing
the sizes inside a list makes it possible to easily verify their
correctness and avoid future bugs due to size mismatches.</p>

<h2 id="fixing-cases-of-the-legacy-plugin-being-wrongly-used">Fixing cases of the legacy plugin being wrongly used</h2>

<p><img src="https://raw.githubusercontent.com/Moritz-Systems/moritz_staticDir/master/lldb_plugins.svg" alt="LLDB plugins"></p>

<p>The process plugins in LLDB are split into two kinds: client plugins
and server plugins.  Client plugins are used by the LLDB client, while
server plugins are used by <code>lldb-server</code> to implement the remote
protocol.  The legacy FreeBSD plugin is a client plugin - it is loaded
by LLDB and used to debug a program.  The modern FreeBSD plugin is
a server plugin - it is loaded by the LLDB server and used to implement
the GDB remote protocol.  Another plugin called <code>gdb-remote</code> provides
a glue between the client and server.  It is loaded by the client,
it spawns lldb-server and fulfills client’s requests by communicating
with the server.</p>

<p>Therefore, by switching between the legacy and remote FreeBSD plugins,
we are actually switching between using the legacy client plugin
and the <code>gdb-remote</code> plugin that spawns lldb-server with the remote
FreeBSD plugin.  Our original switching logic (based on the prior art
from the Windows plugin) consisted of two pieces: <a href="https://github.com/llvm/llvm-project/blob/2c2eb5e6702bf3bbb8fb8f09790b1ab7b139e879/lldb/source/Plugins/Platform/FreeBSD/PlatformFreeBSD.cpp#L250">a boolean switch in
PlatformFreeBSD</a>
and a code blocking the legacy plugin from being loaded when the new
plugin should be used.  However, we have established that the latter
is not really necessary, and we have removed the latter part as we
changed the preferred plugin.</p>

<p>During the final testing period, we’ve found and fixed two cases where
this was not correct: when choosing plugin for <code>process connect</code>,
and when attaching to a running process.</p>

<p>The <code>process connect</code> command is supposed to iterate through all
available process plugins, find one that initializes successfully
and use it to establish a connection to the server.  However, it lacked
any means of actually determining whether the plugin in consideration
supported remote connections at all.  This was acceptable for
non-transitional platforms that had only one candidate client plugin.
However, on FreeBSD it could randomly choose either the legacy plugin,
or the <code>gdb-remote</code> plugin.  To resolve this, we have added <a href="https://github.com/llvm/llvm-project/commit/18e4272a4fe4667a44f4d323140645a83ddfd864">explicit
filtering for remote connection support</a>,
using similar approach as for determining core file support.</p>

<p>The plugin used for launching and attaching processes was supposed
to be controlled by the aforementioned boolean switch.  If the new
plugin was to be used, the method returned true and the launch/attach
implementation from
<a href="https://github.com/llvm/llvm-project/blob/1a1cc0ba7db549025ab1a504633ae4554042fd60/lldb/source/Plugins/Platform/POSIX/PlatformPOSIX.cpp#L359">PlatformPOSIX</a>
was being used.  Otherwise, it returned false and the legacy plugin
kicked in.</p>

<p>The <code>PlatformPOSIX::DebugProcess()</code> method used to launch programs
explicitly forced the <code>gdb-remote</code> plugin.  However,
the <code>PlatformPOSIX::Attach()</code> method did not specify the plugin name
and could therefore use either.  To fix this, we’ve updated it to force
<code>gdb-remote</code> consistently within the class.</p>

<h2 id="the-interaction-between-dynamic-loader-and-the-debugger">The interaction between dynamic loader and the debugger</h2>

<p>The dynamic loader is the system component responsible for loading
shared libraries that are used by the program.  This includes both
loading the linked libraries as specified by <code>DT_NEEDED</code> ELF header,
and loading additional modules at runtime via <code>dlopen(3)</code>.</p>

<p>The dynamic linker provides a <code>r_debug</code> structure that can be used
by the debugger to inspect its state, as well as monitor events - that
is, loading and unloading shared libraries.  The <code>r_debug</code> structure
is consistent across most of the Unix systems (with Solaris being
an exception).  On FreeBSD, it is declared in <code>&lt;sys/link_elf.h&gt;</code> as:</p>

<div><pre><code data-lang="c"><span>struct</span> r_debug {
        <span>int</span>             r_version;      <span>/* Currently '1' */</span>
        <span>struct</span> link_map <span>*</span>r_map;         <span>/* list of loaded images */</span>
        <span>void</span>            (<span>*</span>r_brk)(<span>struct</span> r_debug <span>*</span>, <span>struct</span> link_map <span>*</span>);
                                        <span>/* pointer to break point */</span>
        <span>enum</span> {
                RT_CONSISTENT,          <span>/* things are …</span></code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.moritz.systems/blog/freebsd-remote-plugin-final-milestone-achieved/">https://www.moritz.systems/blog/freebsd-remote-plugin-final-milestone-achieved/</a></em></p>]]>
            </description>
            <link>https://www.moritz.systems/blog/freebsd-remote-plugin-final-milestone-achieved/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25379737</guid>
            <pubDate>Thu, 10 Dec 2020 22:37:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fast Feedback Pyramid]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25379658">thread link</a>) | @atomkirk
<br/>
December 10, 2020 | https://atomkirk.com/2020-07-27-fast-feedback-pyramid/ | <a href="https://web.archive.org/web/*/https://atomkirk.com/2020-07-27-fast-feedback-pyramid/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><header><p>July 27, 2020</p></header><section><p>I wrote before about the importance of <a href="https://atomkirk.com/2020-07-01-fast-feedback-loops/">fast feedback loops</a> and
the <a href="http://localhost:8000/2020-07-16-the-5-categories-of-bugs/">5 categories of bugs</a> and today I thought about how
this could be represented as a pyramid, much like the <a href="https://martinfowler.com/articles/practical-test-pyramid.html#:~:text=The%20%22Test%20Pyramid%22%20is%20a,put%20it%20into%20practice%20properly.">Test Pyramid</a>.</p>
<p><span>
      <a href="https://atomkirk.com/static/11512354ec81d7b82353c81f694066a5/e16ee/pyramid.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Fast feedback pyramid" title="Fast feedback pyramid" src="https://atomkirk.com/static/11512354ec81d7b82353c81f694066a5/fcda8/pyramid.png" srcset="https://atomkirk.com/static/11512354ec81d7b82353c81f694066a5/12f09/pyramid.png 148w,
https://atomkirk.com/static/11512354ec81d7b82353c81f694066a5/e4a3f/pyramid.png 295w,
https://atomkirk.com/static/11512354ec81d7b82353c81f694066a5/fcda8/pyramid.png 590w,
https://atomkirk.com/static/11512354ec81d7b82353c81f694066a5/efc66/pyramid.png 885w,
https://atomkirk.com/static/11512354ec81d7b82353c81f694066a5/c83ae/pyramid.png 1180w,
https://atomkirk.com/static/11512354ec81d7b82353c81f694066a5/e16ee/pyramid.png 1963w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<p>Toward the bottom are the mistakes we make as programmers most frequently. They are also typically the fastest to catch
and correct.</p>
<p>Syntax errors happen as soon as you save the file and try to build. It’s even the very first thing a compiler
will do: parse your files. If it can’t parse it, you’ll get a syntax error.</p>
<p>Second, we type function/variable names wrong or we forget the shape of data in a variable and use it wrong. If you’ve
got a good test pyramid, your tests will run fast and often and hopefully catch these problems quickly. But it requires
that your tests are thorough and optimized. Let’s face it, this is hard and most test suites aren’t. That’s why a
lot of teams
are turning to type safety, because you can collapse the second level into the first so that both syntax and
reference/type errors are caught immediately when you try to compile/build.</p>
<p>Type safety also allows powerful tooling that can tighten feedback loops further by offering relevant suggestions, information
on hover &amp; descriptive inline errors.</p>
<p>And, once again, with languages with value type errors and exhaustive results handling (i.e. Elm, Rust, etc.), you can
even make the third layer of this pyramid provide immediate feedback at build time, further tightening your feedback
loop.</p></section><hr></article></div>]]>
            </description>
            <link>https://atomkirk.com/2020-07-27-fast-feedback-pyramid/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25379658</guid>
            <pubDate>Thu, 10 Dec 2020 22:27:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reddit is down (10th Dec 2020)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25379256">thread link</a>) | @mystcb
<br/>
December 10, 2020 | https://www.redditstatus.com/incidents/qr5vky5kwn3r | <a href="https://web.archive.org/web/*/https://www.redditstatus.com/incidents/qr5vky5kwn3r">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  

  <div>
    

    <div>
      <!-- postmortem if it's published -->

      <!-- incident updates in reverse order -->
        <div>
          <p>
            Resolved
          </p>
          <div>
            <p>
              This incident has been resolved.
            </p>
            <p>
              Posted <span data-datetime-unix="1607642418000"></span>Dec <var data-var="date">10</var>, <var data-var="year">2020</var> - <var data-var="time">15:20</var> PST
            </p>
          </div>
        </div>
        <div>
          <p>
            Update
          </p>
          <div>
            <p>
              We are continuing to monitor for any further issues.
            </p>
            <p>
              Posted <span data-datetime-unix="1607642044000"></span>Dec <var data-var="date">10</var>, <var data-var="year">2020</var> - <var data-var="time">15:14</var> PST
            </p>
          </div>
        </div>
        <div>
          <p>
            Monitoring
          </p>
          <div>
            <p>
              A fix has been implemented and we are monitoring the results.
            </p>
            <p>
              Posted <span data-datetime-unix="1607642008000"></span>Dec <var data-var="date">10</var>, <var data-var="year">2020</var> - <var data-var="time">15:13</var> PST
            </p>
          </div>
        </div>
        <div>
          <p>
            Update
          </p>
          <div>
            <p>
              We are continuing to work on a fix for this issue.
            </p>
            <p>
              Posted <span data-datetime-unix="1607642004000"></span>Dec <var data-var="date">10</var>, <var data-var="year">2020</var> - <var data-var="time">15:13</var> PST
            </p>
          </div>
        </div>
        <div>
          <p>
            Update
          </p>
          <div>
            <p>
              Systems are slowly recovering, but we are still seeing elevated error rates and degradation in our mobile clients.
            </p>
            <p>
              Posted <span data-datetime-unix="1607640732000"></span>Dec <var data-var="date">10</var>, <var data-var="year">2020</var> - <var data-var="time">14:52</var> PST
            </p>
          </div>
        </div>
        <div>
          <p>
            Identified
          </p>
          <div>
            <p>
              reddit.com is currently down. A fix has been identified and is in the process of being applied.
            </p>
            <p>
              Posted <span data-datetime-unix="1607637872000"></span>Dec <var data-var="date">10</var>, <var data-var="year">2020</var> - <var data-var="time">14:04</var> PST
            </p>
          </div>
        </div>
        <div>
          <p>
            Investigating
          </p>
          <div>
            <p>
              We are currently investigating this issue.
            </p>
            <p>
              Posted <span data-datetime-unix="1607637171000"></span>Dec <var data-var="date">10</var>, <var data-var="year">2020</var> - <var data-var="time">13:52</var> PST
            </p>
          </div>
        </div>

      <!-- affected components -->
        <p>
          This incident affected: reddit.com (Desktop Web, Mobile Web, Native Mobile Apps).
        </p>
    </div>

    
  </div>

  
</div></div>]]>
            </description>
            <link>https://www.redditstatus.com/incidents/qr5vky5kwn3r</link>
            <guid isPermaLink="false">hacker-news-small-sites-25379256</guid>
            <pubDate>Thu, 10 Dec 2020 21:54:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DeepMind’s AlphaFold 2–An Impressive Advance with Hyperbolic Coverage]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25379061">thread link</a>) | @andreyk
<br/>
December 10, 2020 | https://www.skynettoday.com/briefs/alphafold2 | <a href="https://web.archive.org/web/*/https://www.skynettoday.com/briefs/alphafold2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h2 id="summary">Summary</h2>

<ul>
  <li>DeepMind’s AlphaFold 2, a deep-learning model that predicts protein structures, achieved significant improvements over other methods in the biannual CAPS protein folding prediction competition.</li>
  <li>The improvements are so large that some claim protein folding is a solved problem. However, while almost all applaud the impressive advancement, many note the caveats and limitations of AlphaFold 2 in both the problem of protein folding and downstream uses in biology.</li>
  <li>After weighing the opinions of many experts, we take the view that while AlphaFold 2 should be celebrated, it is still just one step (though a big one!), and will not significantly advance practical applications like drug discovery.</li>
</ul>

<h2 id="what-happened">What Happened</h2>

<p>On the last day of November 2020, Critical Assessment of Structure Prediction (CASP), a biennial challenge for computational biologists on the problem of “protein folding”, released its results, showing DeepMind’s AI-driven <a href="https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology">Alphafold 2</a> outperforming its competitors by a large margin. 
The pace of Alphafold’s improvement came as a shock to many researchers and mainstream media publications, <a href="https://www.bbc.com/news/science-environment-55133972">who heralded the development as a game-changer for biology</a>. 
Others acknowledged the uses of the tool, but <a href="http://occamstypewriter.org/scurry/2020/12/02/no-deepmind-has-not-solved-protein-folding/">cautioned that there were many more challenges </a>in the protein-folding prediction space that may warrant a tempering of expectations, let alone the broader field of biology.</p>

<figure>
 <img src="https://www.skynettoday.com/assets/img/briefs/alphafold2/image1.png" alt="AlphaFold 2's CAPS results.">
  <figcaption>
    Left: AlphaFold 2’s impressive score on the CAPS protein folding competition. Right: Examples of predicted (blue) vs. actual (green) protein structures.
    Source: <a href="https://www.deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology">DeepMind</a>
  </figcaption>
</figure>

<p>In the world of proteins, form determines function. 
Thus, the ability to look forward and predict protein structures would help all kinds of biology subfields, from the more basic science work to drug discovery. 
Historically, attempts to model proteins have failed due to exponentially increasing computing costs, but <a href="https://dl.acm.org/doi/pdf/10.5555/3433701.3433707">specialized computational hardware</a> appears well-equipped to address this issue.</p>

<p>Alphafold made some waves with its 2018 CASP win, but the <a href="https://www.sciencemag.org/news/2018/12/google-s-deepmind-aces-protein-folding">media coverage was decidedly more muted then</a>. 
The pace of Alphafold’s 2020 improvement on top of its own success in 2018 was shocking for many experts, who felt that a solution to the <a href="https://scitechdaily.com/major-scientific-advance-deepmind-ai-alphafold-solves-50-year-old-grand-challenge-of-protein-structure-prediction/">50-year old protein-solving problem </a>was finally in sight. 
One important note is that AlphaFold 2, like other methods submitted to CASP, doesn’t actually model <em>how</em> proteins fold - it just predicts the final structure of the protein after it has folded.</p>

<p>There are a number of quality blog posts that explain protein folding and AlphaFold 2. <a href="https://twitter.com/jasoncrawford">Jason Crawford</a> at Roots of Progress gives an accessible review of protein folding in <a href="https://rootsofprogress.org/alphafold-protein-folding-explainer">What is the “protein folding problem”? A brief explanation.</a> It is also summarized in this excellent Twitter thread:</p>

<blockquote><div lang="en" dir="ltr"><p>Today Google <a href="https://twitter.com/DeepMind?ref_src=twsrc%5Etfw">@DeepMind</a> announced that their deep learning system AlphaFold has achieved unprecedented levels of accuracy on the “protein folding problem”, a grand challenge problem in computational biochemistry.</p><p>What is this problem, and why is it hard?<a href="https://t.co/OjbP3RBPEi">https://t.co/OjbP3RBPEi</a></p></div>— Jason Crawford (@jasoncrawford) <a href="https://twitter.com/jasoncrawford/status/1333576221418930176?ref_src=twsrc%5Etfw">December 1, 2020</a></blockquote>


<p>For a more technical explanation of AlphaFold 2 itself, we refer readers to the blog posts by <a href="https://moalquraishi.wordpress.com/2020/12/08/alphafold2-casp14-it-feels-like-ones-child-has-left-home/">Mohammed AlQuraishi</a> and <a href="https://www.blopig.com/blog/2020/12/casp14-what-google-deepminds-alphafold-2-really-achieved-and-what-it-means-for-protein-folding-biology-and-bioinformatics/">Carlos Outeiral</a>. In summary, DeepMind trained a neural network model on 170k known protein structures in the publicly available <a href="https://www.rcsb.org/">Protein Data Bank dataset (PDB)</a>. In addition to its many novel architecture designs, one important aspect of this neural network seems to be its use of attention mechanisms, a similar kind of architecture used by recent state-of-the-art language models like GPT-3.</p>

<blockquote><p lang="en" dir="ltr">An attention-based technique was used, which has shown promise across ML in language/vision/etc. This allows for efficient learning (ie capturing relations between elements) and uncovering broader principles: <a href="https://t.co/hKTcb5mTkr">https://t.co/hKTcb5mTkr</a></p>— Ali Madani (@thisismadani) <a href="https://twitter.com/thisismadani/status/1333481997210161160?ref_src=twsrc%5Etfw">November 30, 2020</a></blockquote>


<blockquote><div lang="en" dir="ltr"><p>Very exciting results this week from AlphaFold in CASP14. An incredible and inspiring achievement by the DeepMind team. Many new possibilities.</p><p>*Attention* mechanism is key to the result. Interestingly we find the exact same in our work on *unsupervised* learning for proteins.</p></div>— Alex Rives (@alexrives) <a href="https://twitter.com/alexrives/status/1334942570682716163?ref_src=twsrc%5Etfw">December 4, 2020</a></blockquote>


<h2 id="the-reactions">The Reactions</h2>

<h3 id="from-the-press">From the Press</h3>

<p>The press was very optimistic about AlphaFold 2’s progress in protein folding and its broader implications in biology and beyond, with headlines like:</p>

<ul>
  <li>Nature: <a href="https://www.nature.com/articles/d41586-020-03348-4">‘It will change everything’: DeepMind’s AI makes gigantic leap in solving protein structures</a></li>
  <li>Science: <a href="https://www.sciencemag.org/news/2020/11/game-has-changed-ai-triumphs-solving-protein-structures">‘The game has changed.’ AI triumphs at solving protein structures</a></li>
  <li>MIT Tech Review: <a href="https://www.technologyreview.com/2020/11/30/1012712/deepmind-protein-folding-ai-solved-biology-science-drugs-disease/">DeepMind’s protein-folding AI has solved a 50-year-old grand challenge of biology</a></li>
  <li>IEEE Spectrum: <a href="https://spectrum.ieee.org/tech-talk/artificial-intelligence/medical-ai/alphafold-proves-that-ai-can-crack-fundamental-scientific-problems">AlphaFold Proves That AI Can Crack Fundamental Scientific Problems</a></li>
</ul>

<h3 id="from-the-experts">From the Experts</h3>

<p><a href="https://twitter.com/c_outeiral/status/1334779365280903169">Carlos Outeiral</a>, Computational Biology research scientist at Oxford, also highlighted the “astoundingly” impressive results of AlphaFold 2, in the post <a href="https://www.blopig.com/blog/2020/12/casp14-what-google-deepminds-alphafold-2-really-achieved-and-what-it-means-for-protein-folding-biology-and-bioinformatics/">CASP14: what Google DeepMind’s AlphaFold 2 really achieved, and what it means for protein folding, biology and bioinformatics</a>:</p>

<blockquote>
  <p>After three decades of competitions, the assessors declared that AlphaFold 2 had succeeded in solving a challenge open for 50 years: to develop a method that can accurately, generally and competitively predict a protein structure from its sequence (or, well, a multiple sequence alignment, as we will see later). There are caveats and edge cases, as in any application — but the magnitude of the breakthrough, as well as its potential impact, are undeniable.</p>
</blockquote>

<p>Comparing AlphaFold 2’s results to those of other methods: “AlphaFold 2’s accuracy is simply on a whole different level.”</p>

<figure>
 <img src="https://www.skynettoday.com/assets/img/briefs/alphafold2/image2.png" alt="Comparing AlphaFold 2’s score (left most) to other methods in this year’s CAPS competition.">
  <figcaption>
  Comparing AlphaFold 2’s score (left most) to other methods in this year’s CAPS competition.
  Source: <a href="https://predictioncenter.org/casp14/zscores_final.cgi">CAPS</a>
  </figcaption>
</figure>

<p>Similarly, <a href="https://twitter.com/MoAlQuraishi">Mohammed AlQuraishi</a>, Professor of Systems Biology at Columbia, gave praise to DeepMind’s achievements:</p>

<blockquote><p lang="en" dir="ltr">CASP14 <a href="https://twitter.com/hashtag/s?src=hash&amp;ref_src=twsrc%5Etfw">#s</a> just came out and they’re astounding—DeepMind looks to have solved protein structure prediction. Median GDT_TS went from 68.5 (CASP13) to 92.4!!!! Cf. their 2nd best CASP13 struct scored 92.8 (out of 100). Median RMSD is 2.1Å. I think it's over <a href="https://t.co/dQ1BOJWuwn">https://t.co/dQ1BOJWuwn</a></p>— Mohammed AlQuraishi (@MoAlQuraishi) <a href="https://twitter.com/MoAlQuraishi/status/1333383634649313280?ref_src=twsrc%5Etfw">November 30, 2020</a></blockquote>


<p>In his detailed blog post last year on the first iteration of AlphaFold, <a href="https://moalquraishi.wordpress.com/2018/12/09/alphafold-casp13-what-just-happened/#s2.2">AlphaFold @ CASP13: “What just happened?”</a>, Professor AlQuraishi discussed what DeepMind’s progress meant for academia and pharmaceutical companies:</p>

<ul>
  <li>This is “an indictment of academic science” - “There are dozens of academic groups, with researchers likely numbering in the (low) hundreds, working on protein structure prediction. […] For DeepMind’s group of ~10 researchers, with primarily (but certainly not exclusively) ML expertise, to so thoroughly route everyone surely demonstrates the structural inefficiency of academic science.”</li>
  <li>This is also “an indictment of pharma” - “What is worse than academic groups getting scooped by DeepMind? The fact that the collective powers of Novartis, Pfizer, etc, with their hundreds of thousands (~million?) of employees, let an industrial lab that is a complete outsider to the field, with virtually no prior molecular sciences experience, come in and thoroughly beat them on a problem that is, quite frankly, of far greater importance to pharmaceuticals than it is to Alphabet.”</li>
</ul>

<p>Responding to this year’s AlphaFold 2 is his new post <a href="https://moalquraishi.wordpress.com/2020/12/08/alphafold2-casp14-it-feels-like-ones-child-has-left-home/">AlphaFold2 @ CASP14: “It feels like one’s child has left home.”</a>:</p>

<ul>
  <li>While AlphaFold 2 still has a lot of caveats, Professor AlQuraishi defends using “solved” to describe protein folding, at least in the scientific sense. He argues the remaining deficiencies of AlphaFold 2 are not scientific problems, but rather engineering ones. While engineering problems can still be exceedingly difficult, “competent domain experts know the pieces that need to fall into place to solve them.”</li>
  <li>As for AlphaFold 2’s potential applications to advance biology as a whole: “It won’t happen overnight. None of what I’m saying here will. It will take years and maybe decades, but now that protein structure prediction has become an engineering exercise, we know that many of these ideas can be realized.”</li>
</ul>

<p>Specifically for drug development:</p>
<blockquote>
  <p>I will end this section with the question that gets asked most often about protein structure prediction—will it change drug discovery? Truthfully, in the short term, the answer is most likely no. But it’s complicated. 
One important thing to note is that, of the entire drug development pipeline, the early discovery stage is just that, an early stage. Even if crystallography were to become fast and routine, it would still not fundamentally alter the dynamics of drug discovery as it is practiced today, as most of the cost is in the later stages of drug development beyond medicinal chemistry and well into biology and physiology. Reliable protein structure prediction doesn’t change that.</p>
</blockquote>

<p>However, not everyone saw the same magnitude of advancement in AlphaFold 2.
In the post <a href="http://occamstypewriter.org/scurry/2020/12/02/no-deepmind-has-not-solved-protein-folding/">No, DeepMind has not solved protein folding</a>, <a href="https://twitter.com/Stephen_Curry">Stephen Curry</a>, Professor of Structural Biology at Imperial College London, cautioned against using the word “solved” to describe protein folding:</p>

<blockquote>
  <p>But we are not yet at the point where we can say that protein folding is ‘solved’. For one thing, only two-thirds of DeepMind’s solutions were comparable to the experimentally determined structure of the protein. This is impressive but you have to bear in mind that they didn’t know which two-thirds of their predictions were correct until the comparison with experimental solutions was made. Would you buy a satnav that was only 67% accurate?
So a dose of realism is required. It is also difficult to see right now, despite DeepMind’s impressive performance, that this will immediately transform biology.</p>
</blockquote>

<p>Despite AlphaFold 2’s average accuracy of 1.6 Å:</p>
<blockquote>
  <p>it’s still not nearly good enough for delivering reliable insights into protein chemistry or drug design. To do that, we want to be confident of atomic positions to …</p></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.skynettoday.com/briefs/alphafold2">https://www.skynettoday.com/briefs/alphafold2</a></em></p>]]>
            </description>
            <link>https://www.skynettoday.com/briefs/alphafold2</link>
            <guid isPermaLink="false">hacker-news-small-sites-25379061</guid>
            <pubDate>Thu, 10 Dec 2020 21:36:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Making of “The Godfather” – Sort of a home movie (1971)]]>
            </title>
            <description>
<![CDATA[
Score 93 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25378576">thread link</a>) | @dadt
<br/>
December 10, 2020 | http://www.thestacksreader.com/the-making-of-the-godfather-sort-of-a-home-movie/ | <a href="https://web.archive.org/web/*/http://www.thestacksreader.com/the-making-of-the-godfather-sort-of-a-home-movie/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					
<p>As was his custom before the drive home from work with his son, the old man walked across the narrow, tenement‐lined street in Manhattan’s Little Italy to buy some fresh fruit. The grocer, who had known him for many years, helped the old man sort out some prize oranges and, as a gift, handed him a perfectly ripened, home‐grown fig. The old man smiled, accepted the backyard offering with a slight nod and started toward his car. It was then that he spotted two gunmen.</p>
<p>He called out to his son and began to sprint toward the safety of his car with surprising speed for a man of his age, but the gunmen were too quick. As they opened fire, the old man seemed caught in a great leap, suspended momentarily in the air, his arms thrown protectively around his head. Loud shots hammered through the street, bright oranges rolled across the gray pavement and the old man crashed onto the fender of his car and collapsed. The people of Mott Street watched in silence from tenement windows, fire escapes and rooftops as the gunmen slipped away. Then, to spontaneous applause, the grim street tableau came to life, and the old man—the godfather, <a href="http://www.thestacksreader.com/brando/">Marlon Brando</a>—lifted himself slowly from the ground, smiled at the cheering crowd and bowed.</p>
<p>At 11 o’clock on April 12, just as Brando was getting shot on Mott Street, Carlo Gambino, one of New York’s real godfathers, sat around the corner in a Grand Street cafe, sipping black coffee from a glass and holding 18th‐century Sicilian court in 20th‐century New York. He had arrived moments earlier in the company of his brother, Paul, and five bodyguards. It was his custom, as well as his duty as head of a Mafia family, to hear at regular intervals the endless woes of racketeers, dishonored fathers and deportable husbands. They were ushered before him, one at a time, from a waiting area in a restaurant across the street. He was the final judge to people still willing to accept his decisions as law.</p>
<hr>
<p>Back on Mott Street, two Mafiosi assigned to observe the movie production were unaware of his arrival. For hours, they had been watching Brando getting shot. They had had innumerable cups of coffee and had adjusted their open‐throat, hand ironed shirts so often that their collars had begun to wilt. Neither of them had been impressed when they heard Brando was to play the godfather, so they watched his performance critically. They volunteered to grips, cameramen and extras that they would have preferred Ernest Borgnine or Anthony Quinn.</p>
<p>“A man of that stature,” one of them said, pointing to Brando, “would never wear a hat like that. They never pinched them in the front like that. Italian block, that’s the way they wore them, Italian block.”</p>
<p>They did not like Brando’s wearing his belt below his trouser loops, either.</p>
<p>“He makes the old man look like an iceman. That’s not right. A man like that had style. He should have a diamond belt buckle. They all had diamond belt buckles. And a diamond ring and tie clasp. Those old bosses loved diamonds. They all wore them. Brando makes the guy look like an iceman.”</p>
<p>In truth, Brando did not look like the traditional double‐breasted, wide lapeled, blue‐serge racketeer. He had accepted the advice of an Italian American friend, rather than the Mafiosi themselves, and made himself look old and bent. He wore a sack shaped suit of an undistinguished brown stripe and an outsize over coat. He wore a cardboard‐stiff white shirt with a collar at least two sizes too large and a striped tie so indifferently knotted that its back, label and all, faced front. The makeup man, who was never very far away, had fixed Brando with an elaborate mouth plate that made his jaw heavy and extended his jowls. Brando’s complexion was sallow, his eyes were made to droop on the side and with his graying temples and mustache many people on Mott Street that day did not recognize him until the filming began.</p>
<h5>There was an aura about the production that was unmistakable, just as there is an aura of real and imagined power around the honored society itself.</h5>
<p>The two Mafiosi did approve the vintage cars and were amused by the streetlamps, pushcarts and prices, circa 1940, tacked up in store windows. But they did not like the way the godfather’s assassins fired their guns.</p>
<p>“They hold pieces like flowers,” one said.</p>
<p>Shortly before noon a third man came up behind the pair and whispered:</p>
<p>“The old man’s around the corner.” The two men were stunned. “You kidding?” one asked. “Believe me, he’s around the corner.”</p>
<p>“Kee‐rist!”</p>
<p>“Shooo!”</p>
<p>Without further hesitation—and with the same pitch of excitement most neighborhood people saved for a peek at Brando—the trio left the movie set. They walked quickly toward the intersection and stopped. One of them darted his head around the corner of the building for a quick peek and shot back to his friends: “He’s there. He’s there. I see his car. I see Paul’s guy.”</p>
<hr>
<p>Mario Puzo’s best seller may have started out to be just another multimillion‐dollar movie for Paramount, but it wasn’t long before its producers realized that to the Mafiosi themselves the making of <em>The Godfather</em> was like the filming of a home movie. Before Puzo’s book, cops‐and‐robbers novels and films about organized crime left the mobsters cold. <em>The Godfather</em> was different. When it was published in 1969 word quickly spread across the country’s most regularly tapped telephone wires about this different book on the “honored society.” It was their <em>Forsyte Saga</em>. It was filled with bits of underworld gossip and its characters could be compared to live dons, singers, movie moguls and hit men. It depicted not only their lives, but the lives of their children, wives, enemies and friends. It emphasized their peculiar code of honor rather than their seedy, greedy little maneuverings. It dealt with their strong sense of family and their passionate loyalties. It romanticized and exaggerated their political power, wealth and influence in legitimate business. But most important, it humanized rather than condemned them.</p>
<p>The godfather himself, for instance, was shot because he refused to deal in the dirty business of narcotics. Sonny Corleone, his impetuous heir, was killed in an ambush because he tried to save his pregnant sister from a brutal husband. Michael Carleone, the godfather’s college educated war‐hero son, assumed his father’s Mafia mantle not out of greed, but from a sense of responsibility to his father, who, for all his illegal activities, was a far more honorable man than all the crooked cops, venal judges, corrupt politicians and perverted businessmen who peppered the plot.</p>
<p>Though certain Italian‐American politicians and organizations condemned Puzo for defaming all Italians, the author heard no such criticism from the society about which he had written. In fact, shortly after his book’s publication, Puzo found that some Mafiosi were anxious to meet him. They wanted to compare notes with the author of <em>The Godfather.</em> They, like other fans, refused to believe that the book was all fiction. In Las Vegas he found that a gambling debt he had run up was somehow marked paid. When Puzo protested he was told, “It’s a certain party’s pleasure.” On other occasions, bottles of champagne would arrive at his table unordered. Multisyllabic names were whispered in his ear by reverential headwaiters, and men with sunglasses and diamond rings waved at him across darkened restaurants.</p>
<hr>
<p>Six weeks before the Mott Street shooting of Brando, Albert Ruddy, the film’s producer, was uncertain whether he would be able to make the movie at all. Paramount had been deluged with letters describing the project as anti‐Italian and threatening demonstrations, boycotts and wildcat strikes by everyone from maintenance men to electricians. Letters had come from Congressmen in New York, New Jersey, Connecticut, Louisiana and Pennsylvania, as well as from dozens of New York State legislators, judges, civic leaders and businessmen.</p>
<p>One of them began: “A book like <em>The Godfather</em> leaves one with the sickening feeling that a great deal of effort and labor to eliminate a false image concerning Americans of Italian descent and also an ethnic connotation to organized crime has been wasted …. There are so many careers and biographies that could be made into constructive and intellient movies, such as the life of Enrico Fermi, the great scientist; Mother Cabrini; Colonel Ceslona, a hero of the Civil War; Garibaldi, the great Italian who unified Italy; William Paca, a signer of the Declaration of Independence; Guglielmo Marconi, and many, many others.”</p>
<p>The letter was signed by “the Grand Venerable of the Grand Council of the Grand Lodge of New York State’s Sons of Italy.” It also informed Paramount that the studio could expect an economic boycott of the film, petitions of protest from all Sons of Italy lodges, regional meetings to plan protests, a complaint filed with the State Human Rights Division and demands that no governmental authorities give the production any cooperation whatever.</p>
<p>And as if this were not enough, there were rumors of union walkouts, work stoppages and boycotts. Ruddy could envision costly delays. He had already run into trouble trying to negotiate with householders in Manhasset, L.I., for a site that looked like a godfather’s compound. The entire community and its bureaucrats had ganged up to sabotage his efforts.</p>
<p>“First, they’d complain that we would bring additional cars into the area and take up parking space,” Ruddy said. “So we’d promise to bus our people to the locations. Then they’d say they didn’t want buses in the area. Some said that if we did use their homes for the mall and the wedding the newspapers couldn’t know about it. How could we guarantee that? We were ready to pay, rent, replant, repaint, replace everything in the area for them. We were ready to make all kinds of concessions, but in the end I realized that they just didn’t want us. They never flat came out and said no, but it amounted to the same thing.</p>
<p>“For …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.thestacksreader.com/the-making-of-the-godfather-sort-of-a-home-movie/">http://www.thestacksreader.com/the-making-of-the-godfather-sort-of-a-home-movie/</a></em></p>]]>
            </description>
            <link>http://www.thestacksreader.com/the-making-of-the-godfather-sort-of-a-home-movie/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25378576</guid>
            <pubDate>Thu, 10 Dec 2020 20:59:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Inuttitut, a language shaped by humility, poetry, and the land]]>
            </title>
            <description>
<![CDATA[
Score 74 | Comments 30 (<a href="https://news.ycombinator.com/item?id=25378558">thread link</a>) | @diaphanous
<br/>
December 10, 2020 | https://beside.media/new-narratives/nuna/ | <a href="https://web.archive.org/web/*/https://beside.media/new-narratives/nuna/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <section>
                          <p>Text — Juliana Léveillé-Trudel<br>
Photos — Alexi Hobbs</p>
                                                


      

                  <div>
        <p>“She’s away on vacation for two weeks,” said Bobby, manager of the village of Quaqtaq.</p>
<p>He was talking about the head of the recreation department, who had all of the keys, most importantly the one for the Isummasarvik School’s storage room. We needed it to get the sports equipment to keep the kids occupied at day camp: balls, badminton racquets, nets, and hockey sticks.</p>
<p>I sighed inwardly. Ever since I’d been working in Nunavik, finding a key had been a recurring nightmare. I had already given up hope.</p>
<p>“Maybe you could ask the caretaker,” Bobby suggested.</p>
<p>Anne, my colleague, nodded and waved me on. We got back into the truck. On the other side of the windows, the June sun was beating down on the frozen bay that it could not crack. We stopped in front of a house near the footbridge spanning the river. The caretaker was out, but her husband exchanged a few words with Anne in Inuttitut, then disappeared and returned with the miraculous key. I pinched myself. It had taken all of five minutes.</p>
<p>That was back in 2015, my fifth summer in Nunavik. If it had happened a few years earlier, I would have probably told the story on my blog, joking about how even a simple task can be so immensely complicated in the North.</p>
<p>But as the old man held out the keys, it hit me: it was my fault that it was complicated. I had begun setting up day camps in the North in 2011. Everything that I had found difficult then was difficult because I was trying to make things work my way: planning activities and appointments in advance, holding daily meetings, requiring long-term commitment from the camp’s employees. There was another problem too: I didn’t know the people or the language well enough. I didn’t know who the caretaker was or where she lived. I wouldn’t have been able to speak with her husband, who spoke only in Inuttitut.</p>

      </div>
      

            
    
      

            
      <div>
        <figure>
          <div>
            <p><img src="https://content.beside.media/beside_/app/www/2020/10/B09_Nuna_Alexis-Hobbs-02.jpg" alt="">
                        </p>
          </div>
        </figure>
      </div>

      
    
      

                  <div>
        <p>I’d learned a few words, of course, especially words useful for working with children: <em>come here, sit down, do you understand, hurry up, are you ready, stop, wait, again, a little, a lot, yesterday, today, tomorrow, yes, no, maybe, what’s your name, and how old are you.</em> We’d played Twister once, so I also knew the names of body parts, colours, left and right. I knew the names of all the animals. It was a start, but not enough to converse with the caretaker’s husband.</p>
<p>Many of the <em>Qallunaat</em> (whites) I met among the Inuit described Inuttitut as “impossible to learn.” It did indeed seem complicated, with all those qs, ks, and js, but I loved its rough sonority. Moreover, I could never feel at ease with this linguistic one-sidedness. Some of my friends were taking online courses with Professor Marc-Antoine Mahieu at INALCO (Institut National des Langues et Civilisations Orientales), affiliated with the Sorbonne in Paris. They all spoke about the class with the same blissful smile. In 2016 I signed up too. I had just quit my job to devote myself to writing. It meant that I would no longer be travelling to Nunavik but that I had more time—and I very much wanted to learn Inuttitut and keep a foot in the North.</p>
<p>In our first class, Marc-Antoine made a point of destroying our hopes. Inuttitut is a highly unfamiliar language, not nearly as easily learned as English or Spanish. Acquiring competence would take years of study and practice, and despite all that effort, we would very likely never be able to really converse.</p>
<p>Strangely, this bleak prospect soon seemed irrelevant. Little by little, I discovered a spectacular language, immensely creative and full of humour. A language that had to invent all sorts of slightly eccentric ways of naming the elements of modern life, but that described the land and hunting techniques with staggering precision. A language that seemed made for poetry with its constructed words and love of repetition; a language that taught me so many things about people that I’d been among for years without ever really knowing.</p>

      </div>
      

            
    
      

            
        

      
    
      

                  <div>
        






<p>Don’t believe everything you’ve heard, however: there are not hundreds of words for snow.</p>

      </div>
      

            
    
      

            
      <div>
        <figure>
          <div>
            <p><img src="https://content.beside.media/beside_/app/www/2020/10/B09_Nuna_Alexis-Hobbs-06.jpg" alt="">
                        </p>
          </div>
        </figure>
      </div>

      
    
      

                  <div>
        <p>Over and over, I’d said what so many others have: that the Inuit have a very liberal concept of time. I learned that it could be as structured as my own; it was just structured around other things. For example, the months are defined by animal behaviours.</p>
<p>September, October, November: <em>amiraijaut, arnalirnguutivik, natjuijarvik.</em></p>
<p>Time when antlers lose their velvet. Time when the males compete for females. Time when caribou shed their antlers.</p>
<p>Places that I had known by their French or English names regained their original appellations: I now dared to utter the word <em>Kangiqsualujjuaq</em>; I no longer needed to say <em>George River</em>. I was unlearning my geography, just as so many Indigenous people have had to unlearn theirs. Even the idea of “the Arctic” once hadn’t existed for the Inuit. They had to invent a word for it that suited a Western geographical perspective: <em>Ukiurtatuq</em>, which translates as “repeated winter.”</p>
<p>I found that the language had a harmonious relationship with the environment—despite the occasionally ruthless climate. In the very first Inuttitut dictionary, written by Taamusi Qumaq in 1991, Nunavik is defined as “a large country occupied by animals.” I admired this humility, this awareness that a place is shared with other species, that one is living, in a way, on <em>their</em>&nbsp; land.</p>

      </div>
      

            
    
      

            
      <div>
        <figure>
                      <img src="https://content.beside.media/beside_/app/www/2020/10/AWH_2318.jpg" alt="">
                            </figure>
       </div>

              
    
      

                  <div>
        <p>It’s perhaps precisely because of this humility that one should never speak ill of <em>sila</em>, the weather. This was a blessing for a snow lover like me, tired of the eternal whinging about winter.</p>
<p>All of these words for different kinds of snow and ice, for Northern hunting and fishing techniques, show the extent to which the Inuit were at one with their land. Some people have bandied about the idea that the ancestors of the <em>Nunavimmiut</em>&nbsp; found themselves stuck in the North, blocked from going south by the Cree in the west and Innus in the east, but this is false. Research has concluded that the ancient peoples of the Arctic in fact moved even further north during a period of warming around the year 1000, because they did not know how to survive without the cold. Today, climate change has had particularly devastating consequences for the populations of Nunavik and Nunavut.</p>
<p>In the land that would become Canada, European explorers (<em>tariup akiani</em>, “from across the sea”) saw a vast reservoir of natural resources for exploitation. Our current climate crisis is the direct result of this unbridled exploitation, our stubborn insistence on doing things our way, our belief that we can draw a hermetic border between us and <em>nuna</em>, the great land, when in fact we live in each other.</p>
<p>Our language navigates modern urbanity with much more ease than Inuttitut, but it reflects a far more distant relationship with the environment, often stuck in the idea of fighting against the elements. Could the rich vocabulary of the Inuit inspire us to redefine our relationship with nature? <span>■</span></p>

      </div>
      

            
    
      

                    <div>
          <p>Born in Montréal in 1985, <strong>Juliana Léveillé-Trudel</strong> writes in various genres: fiction (<em>Nirliit</em>, La Peuplade, 2015, translated by Anita Anand, Véhicule Press, 2018), children’s literature (<em>How to Catch a Bear Who Loves to Read</em>, Chouette, 2018, coauthored with Andrew Katz), blogs, and plays. She has presented many of her theatrical and literary creations on stage. In 2018 she founded Productions de Brousse.</p>
        </div>

            
                
        </section>
      </div></div>]]>
            </description>
            <link>https://beside.media/new-narratives/nuna/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25378558</guid>
            <pubDate>Thu, 10 Dec 2020 20:57:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[“The tragedy of the commons” in software development]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25378442">thread link</a>) | @mcrittenden
<br/>
December 10, 2020 | https://critter.blog/2020/12/10/the-tragedy-of-the-commons-in-software-development/ | <a href="https://web.archive.org/web/*/https://critter.blog/2020/12/10/the-tragedy-of-the-commons-in-software-development/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-4179">

	
<!-- .entry-header -->

	<div>

		<div>

			
<blockquote><p>The&nbsp;<strong>tragedy of the commons</strong>&nbsp;is a situation in a shared-resource system where individual users, acting independently according to their&nbsp;own self-interest, behave contrary to the common good of all users by depleting or spoiling the shared resource through their&nbsp;collective action.&nbsp;</p><cite><a href="https://en.wikipedia.org/wiki/Tragedy_of_the_commons">Wikipedia</a></cite></blockquote>



<p>Remind you of anything? Toilet paper in 2020, perhaps?</p>



<p>I’m struck by how often this pops up in software development:</p>



<ul><li>Hitting refresh over and over when your test environment won’t load because everyone is overloading the dev server by hitting refresh.</li><li>Teams don’t volunteer to upgrade dependencies because they all have their own milestones to meet, and eventually an upgrade would be a nightmare because they waited too long. </li><li>Disk space, disk space, disk space. “A few extra MB won’t hurt” repeated thousands of times until the drive is chock full.</li><li>One vaguely named variable ain’t no thing, but 5 years of vaguely named variables equals <a href="https://critter.blog/2020/09/08/2-things-ive-learned-from-reading-refactoring-by-martin-fowler/">one unmaintainable codebase</a>. </li></ul>



<p>The classic <a href="https://blog.codinghorror.com/the-broken-window-theory/">broken window theory</a> is a part of this. Once someone sets the precedent, it’s hard to walk it back. Another part is <a href="https://critter.blog/2020/11/06/all-self-help-boils-down-to-choose-long-term-over-short-term/">choosing short term over long term</a>, the enemy of growth.</p>



<p>Those two plus a healthy dose of regular old human greed adds up to <em>the tragedy of the commons</em>. </p>



<p>I have no useful insight here other than to say that it exists, and sometimes naming a thing is enough to prevent it.</p>





		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://critter.blog/2020/12/10/the-tragedy-of-the-commons-in-software-development/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25378442</guid>
            <pubDate>Thu, 10 Dec 2020 20:50:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Installing and Using Docker and Kubernetes on FreeBSD]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25378236">thread link</a>) | @mikece
<br/>
December 10, 2020 | https://yom.iaelu.net/2020/05/freebsd-using-docker-and-kubernetes.html | <a href="https://web.archive.org/web/*/https://yom.iaelu.net/2020/05/freebsd-using-docker-and-kubernetes.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><article role="main"><p><strong>These configuration have been tested only on FreeBSD 12.1-RELEASE.</strong></p><h2 id="1-introduction">1. Introduction</h2><p>Wait… what? FreeBSD does not have Docker! Doesn’t it?</p><p>Well of course not really, but you can still install Docker using FreeBSD, it won’t just be FreeBSD in Docker since FreeBSD is not supported as Docker images.</p><p>In this blog post, I won’t discuss exactly how to install a few things, I will mostly point to blog posts and documentations so that you know what to do to install Docker and Kubernetes <strong>using</strong> FreeBSD.</p><p>I will not be using Minikube or Kind, not that I don’t like it, but my opinion is that Minikube is nice for quick and dirty small tests and it’s using VirtualBox which is like a big problem to me, but also Bhyve + VirtualBox … choice?!. And Kind is also mostly for tests, it’s closer to an installation with kubeadm, but I really prefer to try things as close to production as possible.</p><p>All these have been tested on a PC installed with FreeBSD 12.1-RELEASE. It has a 6 cores cpu, and 32GB of memory.</p><p>Here is a quick summary:</p><ul><li><a href="#1-introduction">1. Introduction</a></li><li><a href="#2-details">2. Details</a><ul><li><a href="#21-install-sysutilsvm-bhyve-packages">2.1 Install <code>sysutils/vm-bhyve</code> packages</a></li><li><a href="#22-configure-freebsd-sysctls-to-easily-bridge-out">2.2 Configure FreeBSD sysctls to easily bridge out</a></li><li><a href="#23-install-docker">2.3 Install Docker</a></li><li><a href="#24-install-kubernetes">2.4 Install Kubernetes</a></li></ul></li><li><a href="#the-end-is-the-beginning">The end is the beginning…</a></li></ul><h2 id="2-details">2. Details</h2><h3 id="21-install-sysutilsvm-bhyve-packages">2.1 Install <code>sysutils/vm-bhyve</code> packages</h3><p><a href="https://github.com/churchers/vm-bhyve"><code>sysutils/vm-bhyve</code></a> is a shell based, minimal dependency bhyve manager. And <a href="https://www.freebsd.org/doc/handbook/virtualization-host-bhyve.html">Bhyve</a> is a BSD licenced hypervisor. It’s being heavily developped with FreeBSD, and honestly it’s really well integrated to FreeBSD.</p><p>To install <code>vm-bhyve</code> on FreeBSD, you have to be root ofc for good reasons:</p><div><pre><code data-lang="shell"><span># 'sysrc -f /boot/loader.conf vmm_load="YES"'</span>
<span># Load the 'vmm' kernel module</span>
kldload vmm
<span># 'sysrc -f /boot/loader.conf nmdm_load="YES"'</span>
<span># Load the 'nmdm' kernel module</span>
kldload nmdm
<span># vm on bridge is using tap interface</span>
sysctl net.link.tap.up_on_open<span>=</span><span>1</span>
<span># edit '/etc/sysctl.conf', add 'net.link.tap.up_on_open=1'</span>
pkg install sysutils/vm-bhyve
</code></pre></div><p>I’m inviting you to go to the <code>vm-bhyve</code> GitHub page and to review its README, it has a lot of interesting informations. Just do not forget to create a switch (vm-bhyve term) and also to add your network interface to that switch.</p><p>The next thing is mostly the handling of this package. But one thing about this project is that it’s using bridge. I personaly like to have my bridge free of use, and to use firewall when it’s needed, and to be able to address my VM to my needs, which are generaly to have internet access to ease installations. Which is leading to my next point.</p><h3 id="22-configure-freebsd-sysctls-to-easily-bridge-out">2.2 Configure FreeBSD sysctls to easily bridge out</h3><p>I’m usually using PF for firewall, and to be able to have my best use of the bridge you can create with <code>vm-bhyve</code>. To this goal, I’m deciding not to firewall the bridge in any way, and to tell PF not to care about bridge it’s quite easy, it’s even a configuration I’m using for VNET jails.</p><p>So let’s change the PF behavior with bridge with these sysctls, descriptions:</p><div><pre><code data-lang="text">net.link.bridge.pfil_bridge: Packet filter on the bridge interface
net.link.bridge.pfil_onlyip: Only pass IP packets when pfil is enabled
net.link.bridge.pfil_member: Packet filter on the member interface
</code></pre></div><p>commands:</p><div><pre><code data-lang="shell">sysctl net.link.bridge.pfil_bridge<span>=</span><span>0</span>
sysctl net.link.bridge.pfil_onlyip<span>=</span><span>0</span>
sysctl net.link.bridge.pfil_member<span>=</span><span>0</span>
</code></pre></div><p>You can put these sysctls directly in your <code>/etc/sysctl.conf</code> so that at reboot it’s already configured.</p><p>Now you can only care for what’s important, and if you want to firewall your VM, you can always add one inside the VM itself.</p><h3 id="23-install-docker">2.3 Install Docker</h3><p>Just follow this blog: <a href="https://www.gamsjager.nl/2019/01/11/How-to-run-Docker-on-FreeBSD-12/">How to run Docker on FreeBSD 12</a></p><p>In this blog, the author is telling to get Debian 9 ISO, but you can also get Debian 10, it’s working as well.
Once the debian is installed, just don’t forget to follow these two links, I’ve followed them and it’s working:</p><ul><li><a href="https://docs.docker.com/install/linux/docker-ce/debian/">Install Docker Engine on Debian</a></li><li><a href="https://success.docker.com/article/how-do-i-enable-the-remote-api-for-dockerd">How do I enable the remote API for dockerd</a></li></ul><p>When you are finished with this section, you should be able to use docker inside the VM, and outside, so on your host.</p><h3 id="24-install-kubernetes">2.4 Install Kubernetes</h3><p>Honestly, it should be as simple as search in your favorite Search Engine <code>Install Kubernetes</code>, but the first link you get is this one: <a href="https://kubernetes.io/docs/setup/">Getting started</a>.
So… yes you could follow this link but, this is not the goal!</p><p>Instead we want the <strong>R</strong>eal thing, to get closer to a production environment, even if that’s for testing. So you can get there: <a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/">Installing kubeadm</a>. You can follow everything on this page, it’s not hard at all. But the page only tells you to install <code>kubeadm</code>, <code>kubelet</code> and <code>kubectl</code>.</p><p>The hardest part comes with: <a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/">Creating a single control-plane cluster with kubeadm</a>. And here are my tips:</p><ul><li>When you install docker inside your vm, you installed it with <code>containerd.io</code>. This Kubernetes page tells you about what’s possible, either <code>Containerd.io</code>, or <code>CRI-o</code>, just do not install CRI-o, it’s not needed.</li><li>Do not forget to enable Docker in <code>systemd</code> so it’s launched when you’re VM is started</li><li>Do not forget to disable swap<ul><li><code>swapoff -a</code></li><li>edit your <code>/etc/fstab</code> to comment out the swap line</li></ul></li><li>You have to configure Docker to use the systemd cgroup and restart it, here’s my <code>/etc/docker/daemon.json</code>:</li></ul><div><pre><code data-lang="json"><span>{</span>
        <span>"dns"</span><span>:</span> <span>[</span><span>"8.8.8.8"</span><span>,</span> <span>"8.8.4.4"</span><span>],</span>
        <span>"exec-opts"</span><span>:</span> <span>[</span><span>"native.cgroupdriver=systemd"</span><span>],</span>
        <span>"log-driver"</span><span>:</span> <span>"json-file"</span><span>,</span>
        <span>"log-opts"</span><span>:</span> <span>{</span>
                <span>"max-size"</span><span>:</span> <span>"100m"</span>
        <span>},</span>
        <span>"storage-driver"</span><span>:</span> <span>"overlay2"</span>
<span>}</span>
</code></pre></div><ul><li>You have to reconfigure <code>containerd.io</code> so that it will use systemd cgroup<ul><li>reconfigure <code>containerd.io</code> with defaults, as root:</li></ul></li></ul><div><pre><code data-lang="shell">containerd config default &gt; /etc/containerd/config.toml
</code></pre></div><ul><li>then edit the <code>/etc/containerd/config.toml</code> file and change <code>systemd_cgroup = false</code> to <code>systemd_cgroup = true</code></li><li>restart <code>containerd.io</code>:</li></ul><div><pre><code data-lang="shell">systemctl restart containerd
</code></pre></div><ul><li>You should create a <code>/etc/sysctl.d/k8s.conf</code>, with these values:</li></ul><div><pre><code data-lang="text">net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
net.ipv4.ip_forward = 1
</code></pre></div><ul><li>and reload sysctl with:</li></ul><ul><li>If you do not care about default values, you can initialize the control-plane mode with just: <code>sudo kubeadm init</code></li><li>I’ve install Calico as the Network Pod, since I don’t know a thing for now about the pod network, I’ve installed the first one, also it seems to be tested with <code>e2e</code>, which seems to be CNCF standards.</li><li>Skip <code>Joining nodes</code> if you do not plane to install many nodes.</li><li>At this point, you should have a single control-plane cluster installed.</li><li>If you want to <code>kubectl run</code> images, you will need to untaint the master:</li></ul><div><pre><code data-lang="shell">kubectl taint nodes --all node-role.kubernetes.io/master-
</code></pre></div><h2 id="the-end-is-the-beginning">The end is the beginning…</h2><p>So here we are at the end of this post, thank you if you’ve read me up until now. My feelings are that Docker is easy to install, it’s really well integrated with Linux, even if I prefer FreeBSD. Also, Kubernetes is really nice, I’m just peeling the onion slowly.</p><p>At this point, I’ve already tried 2 (3 in fact…) other products installations with Kubernetes:</p><ul><li><a href="https://github.com/kubernetes/dashboard">Kubernetes Dashboard</a>: This one is nice to have a Web UI to watch what’s in your Kubernetes cluser</li><li><a href="https://www.digitalocean.com/community/tutorials/how-to-set-up-a-kubernetes-monitoring-stack-with-prometheus-grafana-and-alertmanager-on-digitalocean">How To Set Up a Kubernetes Monitoring Stack with Prometheus, Grafana and Alertmanager on DigitalOcean</a>: And this one, although it’s about DigitalOcean Kubernetes… I’ve managed to install in my Kubernetes cluster, that was a lot of searching and testing because they are using DigitalOcean Kubernetes capabilities such as creating DO Block Storage. To that end, I had to install a <a href="https://github.com/kubernetes-sigs/sig-storage-local-static-provisioner">Static provisioner of local volumes</a> (the 3rd product 😋), and a Kubernetes Storage Class that would mimics at least the <code>do-block-storage</code> storage class in a very “simple” way.</li></ul><p>Clearly, that was a lot of time invested, but I’m quite happy since I’ve discovered and learnt quite some informations. I’m really well aware that it’s a lot of informations to handle, but if you’ve got some time to kill, it’s really worth the trip.</p><p>Eye Candy:
<a href="https://yom.iaelu.net/Screenshot-2020-05-31-20-59-35.png"><img src="https://yom.iaelu.net/Screenshot-2020-05-31-20-59-35.png" alt="kubectl get all -A"></a></p></article></div></div></div></div>]]>
            </description>
            <link>https://yom.iaelu.net/2020/05/freebsd-using-docker-and-kubernetes.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25378236</guid>
            <pubDate>Thu, 10 Dec 2020 20:34:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deploy an Alexa Skill and Get an Echo]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25378078">thread link</a>) | @rolldeez
<br/>
December 10, 2020 | https://www.stackery.io/blog/reinvent-alexa-quiz-challenge | <a href="https://web.archive.org/web/*/https://www.stackery.io/blog/reinvent-alexa-quiz-challenge">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>We are excited to announce that if you <strong>deploy our AWS Trivia Alexa Skill from Stackery</strong>  we will send you $100 AWS credits and an Amazon Echo!</p>
<h2>Details</h2>
<ol>
<li>Build an Alexa Skill (tutorial below)using Stackery to deploy into your AWS account.</li>
<li>You can deploy the code as-is out of Stackery, or modify the content of the quiz.</li>
<li><a href="https://twitter.com/stackeryio">Tweet us</a> a screenshot of your deployed backend. It'll look something like this:</li>
</ol>
<p><img src="https://media.graphcms.com/AB6B8KcTGKPiTL4gqi99" alt="alexa1.png"></p>
<h2>Q&amp;A</h2>
<h4>What is an Alexa Skill?</h4>
<p>A Skill is a voice app that can be opened on an Alexa-enabled device, such as a smart speaker, a smart home device that's Alexa-enabled, a smartwatch.</p>
<h4>What does this Skill do?</h4>
<p>This Skill asks users questions about AWS services, such as Lambda, Cognito or EC2, in a 10-question quiz game. It also gives users facts about certain AWS services.</p>
<h4>Do I need to be an AWS expert to follow this tutorial?</h4>
<p>Nope! Stackery makes it easy for <em>anyone</em> to deploy serverless apps on AWS, and adding infrastructure is as simple as dragging and dropping! You just need an AWS account, a modern browser, and a computer connected to the Internet.</p>
<h4>Do I need a lot of programming experience to follow this tutorial?</h4>
<p>No! If you can copy-paste, you can build and deploy this app. If you want to customize the quiz, you will need to know basic JavaScript.</p>
<h4>Do I need an Alexa-enabled device to test my Skill?</h4>
<p>No. The Alexa developer console includes an in-browser Alexa simulator for testing.</p>
<h4>What does it cost?</h4>
<p>Everything should fit easily within AWS's free tier, and the AWS account and Amazon Developer account are free.</p>
<h4>Can I make Alexa speak in a sarcastic tone?</h4>
<p>Sadly, no (believe me, I tried). But there are some cool things you can do with <a href="https://developer.amazon.com/en-US/docs/alexa/custom-skills/speech-synthesis-markup-language-ssml-reference.html">SSML</a>, the markup language used to dictate how Alexa generates phrases.</p>
<h4>Resources</h4>
<ul>
<li><a href="https://developer.amazon.com/en-US/docs/alexa/ask-overviews/build-skills-with-the-alexa-skills-kit.html">Alexa Developer docs</a></li>
<li><a href="https://github.com/alexa/skill-sample-nodejs-quiz-game">Skill sample</a></li>
<li><a href="https://github.com/stackery/alexa-reinvent-quiz">Git repo</a></li>
</ul>
<h2>Tutorial</h2>
<h4>Prerequisites:</h4>
<ol>
<li><a href="https://developer.amazon.com/en-US/alexa/alexa-skills-kit">Free Amazon Developer account</a></li>
<li><a href="https://stackery.io/sign-up">Free Stackery Account </a></li>
</ol>
<h3>1. Create an Alexa Skill</h3>
<ol>
<li>Log in to the <a href="https://developer.amazon.com/alexa/console/ask">Alexa Developer Console</a>, and click the <strong>Create Skill</strong> button</li>
<li>Name your skill whatever you'd like</li>
<li>Choose <strong>Custom</strong> as your model</li>
<li>Choose <strong>Provision your own</strong> as the method to host your skill's backend resources</li>
<li>Scroll back up, make sure everything looks right, and click <strong>Create skill</strong></li>
</ol>
<p>You'll now see your newly-created skill in a list of all skills:</p>
<p><img src="https://media.graphcms.com/XNpSqCP6SlGhz2Nq1Yh5" alt="alexa2.png"></p>
<ol start="6">
<li>Click on the skill name, and navigate to <strong>Interaction Model</strong> -&gt; <strong>JSON editor</strong></li>
</ol>
<p>This is where you will paste a JSON file that describes the different forms of interactions your Skill will have with users, as well as the custom data that serves as the allowable answers to quiz questions.</p>
<ol start="7">
<li>Copy the entire contents of <a href="https://raw.githubusercontent.com/stackery/alexa-reinvent-quiz/master/src/models/en-US.json">this JSON file</a> from our <a href="https://github.com/stackery/alexa-reinvent-quiz">alexa-reinvent-quiz repo</a></li>
<li>Paste the copied contents into the Alexa JSON editor, then click <strong>Save Model</strong> at the top, followed by <strong>Build Model</strong></li>
</ol>
<p><img src="https://media.graphcms.com/6AXcts9JREKAOzGB68Ts" alt="alexa3.png"></p>
<p>Once you save, you will see that your Intents were auto-populated. Feel free to poke around and view the sample utterances and <a href="https://developer.amazon.com/en-US/docs/alexa/custom-skills/slot-type-reference.html">slot types</a> that are there now. When you're done, return to the main console where all of your skills are listed, as you'll need to get your Skill ID in a few moments, so be sure to leave this browser tab open.</p>
<h3>2. Build your backend in Stackery</h3>
<p><em>For this step you'll need a <a href="https://www.stackery.io/sign-up/">free Stackery account</a>, a Git provider, and a code editor. If you're a first-time Stackery user, you'll need to link your Git provider and AWS account the first time you commit and deploy a stack. Don't worry, the process is fairly quick and simple and the app will walk you through it.</em></p>
<ol>
<li>In a new tab, log in to Stackery, and create a new stack with a new repo</li>
</ol>
<p><img src="https://media.graphcms.com/AfJ27NQSjmRwqGjrlWL8" alt="alexa-step1.gif"></p>
<ol start="2">
<li>In the Visual edit mode, add a function and give it the name <code>AlexaHandler</code> and change its code source directory to <code>src/AlexaHandler</code>. Scroll down and hit <strong>Save</strong></li>
</ol>
<p><img src="https://media.graphcms.com/aH74Msn0QDOMZ1AzVGpk" alt="alexa-step2.gif"></p>
<ol start="4">
<li>Flip to the Template edit mode, and add the following YAML as part of the <code>Properties</code> of your <code>AlexaHandler</code> function:
<deckgo-highlight-code terminal="carbon" theme="one-light" language="yaml">
                    <code slot="code">   Events:
     AlexaSkillEvent:
       Type: AlexaSkill
       SkillId: [your-skill-id]
</code>
        </deckgo-highlight-code></li>
<li>Replace <code>[your-skill-id]</code> with the <code>Skill ID</code> you noted above<sup>1</sup></li>
</ol>
<p>This is what allows your Lambda function to be accessed by the specific skill you are building, and not any other.</p>
<p>Your template should look now something like this:</p>
<deckgo-highlight-code terminal="carbon" theme="one-light" language="yaml">
                    <code slot="code">AWSTemplateFormatVersion: '2010-09-09'
Transform: AWS::Serverless-2016-10-31
Resources:
  AlexaHandler:
    Type: AWS::Serverless::Function
    Properties:
      FunctionName: !Sub ${AWS::StackName}-AlexaHandler
      ...
      Policies:
        - AWSXrayWriteOnlyAccess
      Events:
        AlexaSkillEvent:
          Type: AlexaSkill
          SkillId: amzn1.ask.skill.some-long-numbers-and-letters
Parameters:
  ...
</code>
        </deckgo-highlight-code><p>If you want to double-check your formatting, you can refer to our <a href="https://github.com/stackery/alexa-reinvent-quiz/blob/master/template.yaml">SAM template</a> in the tutorial repo.</p>
<ol start="8">
<li>If everything looks right, click the <strong>Commit...</strong> button to commit your changes to your Git repository</li>
<li>Follow the repo link below the stack name to access your newly-created repository</li>
</ol>
<p><img src="https://media.graphcms.com/p6X5aC2jQcqDDmuQyjcQ" alt="alexa4.png"></p>
<ol start="10">
<li>Clone your repo to your computer and open it in your favorite (or least-favorite, we're not particular) IDE</li>
</ol>
<h3>3. Add function code</h3>
<p>When you created a function in Stackery, it stubbed out some function code for you in the chosen runtime, which is Node 12 in this case. We're going to replace the function code with the Alexa backend from the <a href="https://github.com/stackery/alexa-reinvent-quiz/">tutorial repo</a>, as well as its <code>package.json</code> contents to add the required dependencies.</p>
<ol>
<li>Open <code>your-repo/src/AlexaHandler/index.js</code> and replace its contents with the contents of <a href="https://raw.githubusercontent.com/stackery/alexa-reinvent-quiz/master/src/AlexaHandler/index.js">Stackery's Alexa Skill code</a>. Save the file</li>
<li>Open <code>your-repo/src/AlexaHandler/package.json</code> and replace its contents with the following and save:</li>
</ol>
<deckgo-highlight-code terminal="carbon" theme="one-light" language="javascript">
                    <code slot="code">{
  "name": "alexahandler",
  "version": "1.0.0",
  "description": "",
  "main": "index.js",
  "author": "Stackery",
  "license": "MIT",
  "devDependencies": {
    "aws-sdk": "^2.796.0"
  },
  "dependencies": {
    "ask-sdk-core": "^2.9.0",
    "ask-sdk-model": "^1.34.1"
  }
}
</code>
        </deckgo-highlight-code><ol start="3">
<li>Commit the changes and push to your Git repo</li>
</ol>
<p>If you kept your Stackery tab open, you'll have noticed that it detected the changes you pushed up. Go ahead and hit the refresh link:</p>
<p><img src="https://media.graphcms.com/kV2cc64TQ2XcWfsWT1f6" alt="alexa5.png"></p>
<h3>4. Deploy to AWS</h3>
<ol>
<li>In the Stackery app, navigate to the <strong>Deploy</strong> tab</li>
<li>Select an environment to deploy to (if this is your first time deploying with Stackery, you'll be guided through linking to AWS first). Click <strong>Prepare new deployment</strong> and then <strong>Prepare Deployment</strong> to start your deployment</li>
</ol>
<p><img src="https://media.graphcms.com/rQ8rAzWASfG0eKVF3Fd4" alt="alexa-step3.gif"></p>
<ol start="3">
<li>Once the deployment is prepared (which will take about a minute), click <strong>Deploy</strong>. A tab will open in your AWS Console, where you'll need to click <strong>Execute</strong> to kick off the deployment<sup>2</sup></li>
</ol>
<p><img src="https://media.graphcms.com/GEnQASVcTrqah2nExmAf" alt="alexa-step4.gif"></p>
<p>This will take a few minutes - get yourself a coffee and a pat on the back, because you're 90% done with deploying your first Alexa Skill!</p>
<ol start="4">
<li>You'll get a notification when your stack has deployed. Click the <strong>View</strong> tab to see your live stack</li>
<li>Grab your screenshot for Twitter!</li>
<li>Double-click the <code>AlexaHandler</code> function to pull up some handy data and links.</li>
<li>Copy the function's ARN, as you'll need it for the final step</li>
</ol>
<p><img src="https://media.graphcms.com/N2pitl1jQwe6gs28hxmY" alt="alexa-step5.gif"></p>
<h3>5. Connect your backend to your Skill</h3>
<p>This is it: the final stage, when we connect all the dots and test our Alexa Skill!</p>
<ol>
<li>Back in the Amazon Developer Console, select <strong>Endpoint</strong> from the menu</li>
<li>Enter the ARN you copied in the previous step like so:</li>
</ol>
<p><img src="https://media.graphcms.com/oWHUCWAYQeLTiyXCeFx1" alt="alexa6.png"></p>
<ol start="3">
<li>Click <strong>Save Endpoints</strong></li>
</ol>
<p>Now you're ready to test your Skill! Navigate to <strong>Test</strong>, and say or type "Start Stackery re:Invent Quiz" to kick off the quiz. You can try the quiz yourself, or get some trivia information about specific AWS services. Knock yourself out - this is the fun part!</p>
<p><img src="https://media.graphcms.com/0JO6s23ZRjqStQh6y42u" alt="alexa7.png"></p>
<p>Return to the Stackery Dashboard, notice that your function was successfully invoked while you were testing!</p>
<p><img src="https://media.graphcms.com/Xl8eDGDQRy7TSQCCrxdd" alt="alexa8.png"></p>
<h2>Next steps</h2>
<p>Hopefully, this tutorial piqued your interests in building Alexa Skills. With a Lambda backend, you can build skills in just about any runtime, and Stackery helps you deploy changes quickly (and automatically with our <a href="https://docs.stackery.io/docs/using-stackery/dashboard#deployment-pipeline">Deployment Pipelines</a>).<br>
I'd love to see what you build - feel free to send your projects <a href="https://twitter.com/annaspies">my way on Twitter</a>, and  don't forget to send your deployed stack to <a href="https://twitter.com/stackeryio">Stackery on Twitter</a>.</p>
<p><em><sup>1</sup> For the sake of this tutorial, we are hard-coding the Skill ID. <strong>If you are saving your Skill ID directly in the template, make sure your repo is private.</strong> Alternatively, you can use Stackery's <a href="https://docs.stackery.io/docs/using-stackery/environments#setting-parameter-store-values">Environments and Parameter Store</a> to follow best practices and store your Skill ID as in AWS's <a href="https://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-parameter-store.html">Systems Manager Parameter Store</a> and reference it at build time.</em></p>
<p><em><sup>2</sup> This tutorial walks you through deploying manually in the browser, but there are other ways to deploy that will likely suit your workflow better. You can deploy with the <a href="https://docs.stackery.io/docs/using-stackery/cli">Stackery CLI</a> with just one command, or completely automate this process upon a merge to the repo's main branch, including automated test runs, with Stackery's <a href="https://docs.stackery.io/docs/using-stackery/dashboard#deployment-pipeline">Deployment Pipelines</a>.</em></p>
</div></div>]]>
            </description>
            <link>https://www.stackery.io/blog/reinvent-alexa-quiz-challenge</link>
            <guid isPermaLink="false">hacker-news-small-sites-25378078</guid>
            <pubDate>Thu, 10 Dec 2020 20:22:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Solving River Crossing Puzzles with MiniZinc]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25378057">thread link</a>) | @rsas
<br/>
December 10, 2020 | https://sasnauskas.eu/solving-river-crossing-puzzles-with-minizinc/ | <a href="https://web.archive.org/web/*/https://sasnauskas.eu/solving-river-crossing-puzzles-with-minizinc/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<article>
    <p>The objective of river crossing puzzles is to bring items from one river bank to the other in the fewest possible steps.
One prominent puzzle is the <strong>wolf, goat and cabbage problem</strong>.
From Wikipedia:</p>
<blockquote>
<p>“Once upon a time a farmer went to a market and purchased a wolf, a goat, and a cabbage.
On his way home, the farmer came to the bank of a river and rented a boat.
But crossing the river by boat, the farmer could carry only himself and a single one of his purchases: the wolf, the goat, or the cabbage.
If left unattended together, the wolf would eat the goat, or the goat would eat the cabbage.</p>
</blockquote>
<blockquote>
<p>The farmer’s challenge was to carry himself and his purchases to the far bank of the river, leaving each purchase intact. How did he do it?”</p>
</blockquote>
<h3 id="minizinc">MiniZinc</h3>
<p><a href="https://www.minizinc.org/">MiniZinc</a> is a high-level constraint modeling language.
It allows you to model optimization and constraint satisfaction problems.
In the backend, one is free to choose from a wide range of solvers.</p>
<h3 id="structure-of-minizinc-models">Structure of MiniZinc Models</h3>
<p>A MiniZinc model consists of <em>parameters</em>, <em>decision variables</em>, <em>constraints</em>, <em>objective</em>, and <em>output</em>.
They all can be specified in any order.</p>
<h4 id="parameters">Parameters</h4>
<p>Parameters define the concrete inputs for the model.
In our river crossing puzzle, the parameters can be defined as follows:</p>
<div><pre><code data-lang="minizinc"><span>enum</span> <span>PASSENGER</span> <span>=</span> <span>{</span><span>Farmer</span><span>,</span> <span>Wolf</span><span>,</span> <span>Goat</span><span>,</span> <span>Cabbage</span><span>};</span>
<span>enum</span> <span>LOC</span> <span>=</span> <span>{</span><span>bankA</span><span>,</span> <span>bankB</span><span>};</span>

<span>int</span><span>:</span> <span>maxstep</span> <span>=</span> <span>10</span><span>;</span>
<span>set</span> <span>of</span> <span>int</span><span>:</span> <span>STEP0</span> <span>=</span> <span>0</span><span>..</span><span>maxstep</span><span>;</span>
<span>set</span> <span>of</span> <span>int</span><span>:</span> <span>STEP</span> <span>=</span> <span>1</span><span>..</span><span>maxstep</span><span>;</span>
</code></pre></div><p>Apart from the enumerations, the only parameter in this puzzle is <code>maxstep</code>.
It is always a good idea to specify some upper bound for the search space during modeling.
<code>STEP0</code> and <code>STEP1</code> are two helper arrays.
We will need these later.</p>
<h4 id="decision-variables">Decision Variables</h4>
<p>A decision variable represents the unknown solution space.
In our puzzle, we are looking for the farmer’s concrete steps to carry the purchases to the far bank of the river.
In MiniZinc, we can use arrays or <code>var</code> variables to represent the unknown locations at each step:</p>
<div><pre><code data-lang="minizinc"><span>array</span><span>[</span><span>STEP0</span><span>]</span> <span>of</span> <span>var</span> <span>LOC</span><span>:</span> <span>farmerLoc</span><span>;</span>
<span>array</span><span>[</span><span>STEP0</span><span>]</span> <span>of</span> <span>var</span> <span>LOC</span><span>:</span> <span>wolfLoc</span><span>;</span>
<span>array</span><span>[</span><span>STEP0</span><span>]</span> <span>of</span> <span>var</span> <span>LOC</span><span>:</span> <span>goatLoc</span><span>;</span>
<span>array</span><span>[</span><span>STEP0</span><span>]</span> <span>of</span> <span>var</span> <span>LOC</span><span>:</span> <span>cabbageLoc</span><span>;</span>

<span>% Helper type: two-dimensional array of the unknown locations.
</span><span></span><span>array</span><span>[</span><span>PASSENGER</span><span>,</span> <span>STEP0</span><span>]</span> <span>of</span> <span>var</span> <span>LOC</span><span>:</span> <span>loc</span> <span>=</span>
    <span>array2d</span><span>(</span><span>PASSENGER</span><span>,</span> <span>STEP0</span><span>,</span>
            <span>farmerLoc</span> <span>++</span> <span>wolfLoc</span> <span>++</span> <span>goatLoc</span> <span>++</span> <span>cabbageLoc</span><span>);</span>

<span>var</span> <span>STEP</span><span>:</span> <span>end</span><span>;</span>
</code></pre></div><p>The <code>end</code> variable represents the unknown number of steps to solve the puzzle.</p>
<h4 id="constraints">Constraints</h4>
<p>The constraints define the restrictions on the decision variables:</p>
<blockquote>
<p>“the farmer could carry only himself and a single one of his purchases: the wolf, the goat, or the cabbage. If left unattended together, the wolf would eat the goat, or the goat would eat the cabbage.”</p>
</blockquote>
<p>Modeling constraints is the most challenging (and fun) part of MiniZinc.
Fortunately, you can use established techniques for modeling common problems.
In the following, we will constrain the farmer’s locations and his purchases at each step to represent the boat crossing the river.</p>
<div><pre><code data-lang="minizinc"><span>% The farmer arrives at the river with his purchases.
</span><span></span><span>constraint</span> <span>forall</span><span>(</span><span>p</span> <span>in</span> <span>PASSENGER</span><span>)(</span><span>loc</span><span>[</span><span>p</span><span>,</span><span>0</span><span>]</span> <span>=</span> <span>bankA</span><span>);</span>
<span>% The farmer crosses the river with his purchases after end steps.
</span><span></span><span>constraint</span> <span>forall</span><span>(</span><span>p</span> <span>in</span> <span>PASSENGER</span><span>,</span> <span>s</span> <span>in</span> <span>STEP</span> <span>where</span> <span>s</span> <span>&gt;=</span> <span>end</span><span>)</span>
                 <span>(</span><span>loc</span><span>[</span><span>p</span><span>,</span><span>s</span><span>]</span> <span>=</span> <span>bankB</span><span>);</span>
<span>constraint</span> <span>end</span> <span>&lt;=</span> <span>maxstep</span><span>;</span>
</code></pre></div><p>How should we model the crossing of the river?
We can simply iterate over the <code>loc</code> array and constrain the previous and the next location of the farmer and his items.
To avoid code duplication, we can create a <em>predicate</em>.</p>
<div><pre><code data-lang="minizinc"><span>% If the location of a passenger changes from one river bank
</span><span>% to the other, so should change the location of the farmer too.
</span><span>% Note that STEP is 1..maxtep allowing us to access s-1.
</span><span></span><span>predicate</span> <span>passenger_moves</span><span>(</span><span>var</span> <span>PASSENGER</span><span>:</span> <span>p</span><span>,</span> <span>var</span> <span>STEP</span><span>:</span> <span>s</span><span>)</span> <span>=</span>
    <span>let</span> <span>{</span> <span>var</span> <span>LOC</span><span>:</span> <span>farmer_last_pos</span> <span>=</span> <span>loc</span><span>[</span><span>Farmer</span><span>,</span><span>s</span><span>-</span><span>1</span><span>];</span>
          <span>var</span> <span>LOC</span><span>:</span> <span>farmer_new_pos</span> <span>=</span> <span>loc</span><span>[</span><span>Farmer</span><span>,</span><span>s</span><span>];</span>
          <span>var</span> <span>LOC</span><span>:</span> <span>last_pos</span> <span>=</span> <span>loc</span><span>[</span><span>p</span><span>,</span><span>s</span><span>-</span><span>1</span><span>];</span>
          <span>var</span> <span>LOC</span><span>:</span> <span>new_pos</span> <span>=</span> <span>loc</span><span>[</span><span>p</span><span>,</span><span>s</span><span>];</span> <span>}</span> <span>in</span>
          <span>last_pos</span> <span>!=</span> <span>new_pos</span>
          <span>-&gt;</span>
          <span>farmer_last_pos</span> <span>=</span> <span>last_pos</span> <span>/\</span> <span>farmer_new_pos</span> <span>=</span> <span>new_pos</span><span>;</span>
<span>% Constrain all passengers (farmer and his purchases).
</span><span></span><span>constraint</span> <span>forall</span><span>(</span><span>p</span> <span>in</span> <span>PASSENGER</span><span>,</span> <span>s</span> <span>in</span> <span>STEP</span><span>)(</span><span>passenger_moves</span><span>(</span><span>p</span><span>,</span> <span>s</span><span>));</span>
</code></pre></div><p>Done!
Let’s finish by adding the two remaining constraints.</p>
<div><pre><code data-lang="minizinc"><span>% Never leave the wolf with the goat or the goat with the cabbage alone.
</span><span></span><span>constraint</span> <span>forall</span><span>(</span><span>s</span> <span>in</span> <span>STEP</span><span>)</span>
                 <span>(</span><span>wolfLoc</span><span>[</span><span>s</span><span>]</span> <span>=</span> <span>goatLoc</span><span>[</span><span>s</span><span>]</span> <span>\/</span> <span>goatLoc</span><span>[</span><span>s</span><span>]</span> <span>=</span> <span>cabbageLoc</span><span>[</span><span>s</span><span>]</span> 
                  <span>-&gt;</span>
                  <span>farmerLoc</span><span>[</span><span>s</span><span>]</span> <span>=</span> <span>goatLoc</span><span>[</span><span>s</span><span>]);</span>

<span>% The farmer can carry only himself and a single one of his purchases.
</span><span>% If the location of the farmer changes, at most one purchase can
</span><span>% change its location as well.
</span><span></span><span>constraint</span> <span>forall</span><span>(</span><span>s</span> <span>in</span> <span>STEP</span><span>)</span>
                 <span>(</span><span>farmerLoc</span><span>[</span><span>s</span><span>-</span><span>1</span><span>]</span> <span>!=</span> <span>farmerLoc</span><span>[</span><span>s</span><span>]</span>
                  <span>-&gt;</span>
                  <span>sum</span><span>(</span><span>p</span> <span>in</span> <span>PASSENGER</span> <span>where</span> <span>p</span> <span>!=</span> <span>Farmer</span><span>)</span>
                     <span>(</span><span>loc</span><span>[</span><span>p</span><span>,</span><span>s</span><span>-</span><span>1</span><span>]</span> <span>!=</span> <span>loc</span><span>[</span><span>p</span><span>,</span><span>s</span><span>])</span>
                  <span>&lt;=</span> <span>1</span><span>);</span>
</code></pre></div><h4 id="objective">Objective</h4>
<p>The objective function can be either constraint satisfaction or minimization/maximization of the decision variables.
We are looking for the least number of steps to cross the river.</p>
<h4 id="output">Output</h4>
<p>Printing custom output of the solution is optional and a bit tricky.
There are built-in MiniZinc functions for that, and together with the support of emojis, we can craft the explanation of the solution found by MiniZinc.</p>
<div><pre><code data-lang="minizinc"><span>% Our emojis.
</span><span></span><span>array</span><span>[</span><span>PASSENGER</span><span>]</span> <span>of</span> <span>string</span><span>:</span> <span>emoji</span> <span>=</span> <span>[</span><span>"👨‍🌾"</span><span>,</span><span>"🐺"</span><span>,</span><span>"🐐"</span><span>,</span><span>"🥬"</span><span>]</span> <span>::</span><span>output_only</span><span>;</span>

<span>output</span>
<span>[</span> <span>"Step \(s): "</span> <span>++</span> <span>% step prefix
</span><span></span>  <span>show</span><span>([</span> <span>emoji</span><span>[</span><span>p</span><span>]</span> <span>|</span> <span>p</span> <span>in</span> <span>PASSENGER</span> <span>where</span> <span>fix</span><span>(</span><span>loc</span><span>[</span><span>p</span><span>,</span><span>s</span><span>])</span> <span>=</span> <span>bankA</span> <span>])</span> <span>++</span>
  <span>" &lt;-&gt; "</span> <span>++</span>
  <span>show</span><span>([</span> <span>emoji</span><span>[</span><span>p</span><span>]</span> <span>|</span> <span>p</span> <span>in</span> <span>PASSENGER</span> <span>where</span> <span>fix</span><span>(</span><span>loc</span><span>[</span><span>p</span><span>,</span><span>s</span><span>])</span> <span>=</span> <span>bankB</span> <span>])</span> <span>++</span>
  <span>"\n"</span>
  <span>|</span> <span>s</span> <span>in</span> <span>1</span><span>..</span><span>fix</span><span>(</span><span>end</span><span>)</span> <span>];</span> <span>% generator
</span></code></pre></div><p>It’s time to put the pieces together and run our model.
Assuming you have MiniZinc available in your <code>PATH</code>, pass the model file to the executable.</p>
<div><pre><code data-lang="plain">$ minizinc --version
MiniZinc to FlatZinc converter, version 2.5.3, build 220798393
Copyright (C) 2014-2020 Monash University, NICTA, Data61

$ time minizinc farmer-wolf-goat-cabbage.mzn
Step 1: ["🐺", "🥬"] &lt;-&gt; ["🧑🏻‍🌾", "🐐"]
Step 2: ["🧑🏻‍🌾", "🐺", "🥬"] &lt;-&gt; ["🐐"]
Step 3: ["🥬"] &lt;-&gt; ["🧑🏻‍🌾", "🐺", "🐐"]
Step 4: ["🧑🏻‍🌾", "🐐", "🥬"] &lt;-&gt; ["🐺"]
Step 5: ["🐐"] &lt;-&gt; ["🧑🏻‍🌾", "🐺", "🥬"]
Step 6: ["🧑🏻‍🌾", "🐐"] &lt;-&gt; ["🐺", "🥬"]
Step 7: [] &lt;-&gt; ["🧑🏻‍🌾", "🐺", "🐐", "🥬"]
----------
==========

real	0m0.850s
user	0m0.072s
sys	0m0.059s
</code></pre></div><p>We need 7 steps to cross the river, and this is provably the minimal solution!
<a href="https://github.com/rsas/minizinc-examples/blob/main/farmer-wolf-goat-cabbage.mzn">Grab the model from GitHub</a> and try it yourself.</p>
<h3 id="conclusion">Conclusion</h3>
<p>This post was inspired by the <a href="https://www.youtube.com/watch?v=kiX1FOw1GUU">MiniZinc tutorial of Lucas DiCioccio</a>.
There are many ways to model this problem.
I used the techniques from the two MiniZinc courses available in Coursera, <a href="https://www.coursera.org/learn/basic-modeling">Basic Modeling for Discrete Optimization</a> and <a href="https://www.coursera.org/learn/advanced-modeling">Advanced Modeling for Discrete Optimization</a>, which I highly recommend.</p>
</article>

        </div></div>]]>
            </description>
            <link>https://sasnauskas.eu/solving-river-crossing-puzzles-with-minizinc/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25378057</guid>
            <pubDate>Thu, 10 Dec 2020 20:20:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tee in Haskell using streaming-bytestring]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25377939">thread link</a>) | @anardil
<br/>
December 10, 2020 | https://anardil.net/2020/haskell-coreutils-tee.html | <a href="https://web.archive.org/web/*/https://anardil.net/2020/haskell-coreutils-tee.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>I've implemented some <a href="https://github.com/Gandalf-/coreutils">Unix core utilities in Haskell</a>, and want to start a series of
posts going through the details - starting with simple programs like <code>cat</code>,
<code>seq</code>, and <code>which</code>, and then moving on towards more featureful programs like
<code>uniq</code>, <code>tr</code> and maybe <code>grep</code>.</p>
<p>You can find the full source from this post
<a href="https://github.com/Gandalf-/coreutils/blob/master/Coreutils/Tee.hs">here</a>.
Let's implement <code>tee</code> in Haskell!</p>

<p>What does <code>tee</code> do? From the man page, "read from standard input and write to
standard output and files". Seems simple enough; <code>tee</code> is like <code>cat</code> except
that it additionally writes whatever passes between <code>stdin</code> and <code>stdout</code> to any
number of files along the way. Like the majority of coreutils, this is done in
a streaming fashion for performance and to reduce memory usage. It's
unacceptable, for instance, to read all of stdin, then write it to stdout and
each output file in turn. We need to <em>stream</em> the data to each output, or sink,
as it becomes available.</p>

<p>Let's sketch out the program in types to see what we need. We'll use this as a
reference for each section below:</p>
<div><pre><span></span><span>teeMain</span> <span>::</span> <span>[</span><span>String</span><span>]</span> <span>-&gt;</span> <span>IO</span> <span>()</span>
<span>-- ^ parse arguments with defaults, look for errors, call runTee</span>

<span>runTee</span> <span>::</span> <span>Options</span> <span>-&gt;</span> <span>[</span><span>FilePath</span><span>]</span> <span>-&gt;</span> <span>IO</span> <span>()</span>
<span>-- ^ open handles for each filepath according to provided options, call tee</span>

<span>tee</span> <span>::</span> <span>[</span><span>Handle</span><span>]</span> <span>-&gt;</span> <span>IO</span> <span>()</span>
<span>-- ^ read from stdin, write to each provided handle and stdout</span>
</pre></div>
<p>Let's work our way top down, starting with argument parsing, then down to
our runtime, and lastly the business logic.</p>

<p>Our main concern is streaming data, for which Haskell has a couple libraries.
We'll be using <code>streaming</code> and <code>streaming-bytestring</code> which provide
<code>Data.ByteString.Streaming</code>. ByteStrings are the way to go since <code>tee</code> must
behave itself with binary input, and besides we don't need to concern ourselves
with the content of stdin means to move it around. <code>System.Console.GetOpt</code> will
handle argument parsing, while the other <code>System</code> and <code>Control</code> libraries
provide some basics: <code>bracket</code>, <code>unless</code>, <code>die</code>, <code>openBinaryFile</code>, open flags,
and <code>Handle</code>. We'll see how these are each used in the following sections.</p>
<div><pre><span></span><span>module</span> <span>Coreutils.Tee</span> <span>where</span>

<span>import</span>           <span>Control.Exception</span>
<span>import</span>           <span>Control.Monad</span>
<span>import</span> <span>qualified</span> <span>Data.ByteString.Streaming</span> <span>as</span> <span>Q</span>
<span>import</span>           <span>System.Console.GetOpt</span>
<span>import</span>           <span>System.Exit</span>
<span>import</span>           <span>System.IO</span>
</pre></div>

<p>BSD <code>tee</code> has just two options</p>
<ul>
<li><code>-a</code> to append to output files rather than overwriting them</li>
<li><code>-i</code> to ignore SIGINT</li>
</ul>
<p>GNU tee has some more options related to error path behavior, but let's ignore
those and BSD's <code>-i</code> for the time being. This leaves us with three things to do
in our argument parsing:</p>
<ul>
<li>look for help flags to show usage</li>
<li>look for <code>-a</code> or <code>--append</code> to indicate append mode for writing</li>
<li>collect everything else as output file names</li>
</ul>
<p><code>System.Console.GetOpt</code> provides a simple pattern to describe this exactly, we
provide a data type describing our options (in this case, just one), the
defaults, and some help text and it'll figure out the details internally.</p>
<div><pre><span></span><span>newtype</span> <span>Options</span> <span>=</span> <span>Options</span> <span>{</span> <span>optMode</span> <span>::</span> <span>IOMode</span> <span>}</span>

<span>defaults</span> <span>::</span> <span>Options</span>
<span>defaults</span> <span>=</span> <span>Options</span> <span>{</span> <span>optMode</span> <span>=</span> <span>WriteMode</span> <span>}</span>

<span>options</span> <span>::</span> <span>[</span><span>OptDescr</span> <span>(</span><span>Options</span> <span>-&gt;</span> <span>Either</span> <span>String</span> <span>Options</span><span>)]</span>
<span>options</span> <span>=</span>
    <span>[</span> <span>Option</span> <span>"a"</span> <span>[</span><span>"append"</span><span>]</span>
        <span>(</span><span>NoArg</span>
            <span>(</span><span>\</span><span>opt</span> <span>-&gt;</span> <span>Right</span> <span>opt</span> <span>{</span> <span>optMode</span> <span>=</span> <span>AppendMode</span> <span>}))</span>
        <span>"append to given files, do not overwrite"</span>

    <span>,</span> <span>Option</span> <span>"h"</span> <span>[</span><span>"help"</span><span>]</span>
        <span>(</span><span>NoArg</span>
            <span>(</span><span>\</span><span>_</span> <span>-&gt;</span> <span>Left</span> <span>$</span> <span>usageInfo</span> <span>"tee"</span> <span>options</span><span>))</span>
        <span>"show this help text"</span>
    <span>]</span>
</pre></div>
<p><code>getOpt</code> automatically tracks which arguments aren't parsed and provides those
separately, perfect for our usecase. Let's plug this all together in our pseudo
main function.</p>
<div><pre><span></span><span>teeMain</span> <span>::</span> <span>[</span><span>String</span><span>]</span> <span>-&gt;</span> <span>IO</span> <span>()</span>
<span>teeMain</span> <span>args</span> <span>=</span> <span>do</span>
        <span>unless</span> <span>(</span><span>null</span> <span>errors</span><span>)</span> <span>$</span>
            <span>die</span> <span>$</span> <span>unlines</span> <span>errors</span>

        <span>either</span> <span>die</span> <span>(`</span><span>runTee</span><span>`</span> <span>filenames</span><span>)</span> <span>$</span>
            <span>foldM</span> <span>(</span><span>flip</span> <span>id</span><span>)</span> <span>defaults</span> <span>opts</span>
    <span>where</span>
        <span>(</span><span>opts</span><span>,</span> <span>filenames</span><span>,</span> <span>errors</span><span>)</span> <span>=</span> <span>getOpt</span> <span>RequireOrder</span> <span>options</span> <span>args</span>
</pre></div>
<p>The real driver here is:</p>
<div><pre><span></span><span>*</span><span>Coreutils</span><span>.</span><span>Tee</span><span>&gt;</span> <span>:</span><span>t</span> <span>getOpt</span>
<span>getOpt</span>
  <span>::</span> <span>ArgOrder</span> <span>a</span> <span>-&gt;</span> <span>[</span><span>OptDescr</span> <span>a</span><span>]</span> <span>-&gt;</span> <span>[</span><span>String</span><span>]</span> <span>-&gt;</span> <span>([</span><span>a</span><span>],</span> <span>[</span><span>String</span><span>],</span> <span>[</span><span>String</span><span>])</span>

<span>*</span><span>Coreutils</span><span>.</span><span>Tee</span><span>&gt;</span> <span>let</span> <span>someArgs</span> <span>=</span> <span>[</span><span>"-a"</span><span>,</span> <span>"out.txt"</span><span>]</span>
<span>*</span><span>Coreutils</span><span>.</span><span>Tee</span><span>&gt;</span> <span>:</span><span>t</span> <span>getOpt</span> <span>RequireOrder</span> <span>options</span> <span>someArgs</span>
<span>getOpt</span> <span>RequireOrder</span> <span>options</span> <span>someArgs</span>
  <span>::</span> <span>([</span><span>Options</span> <span>-&gt;</span> <span>Either</span> <span>String</span> <span>Options</span><span>],</span> <span>[</span><span>String</span><span>],</span> <span>[</span><span>String</span><span>])</span>
</pre></div>
<p>where <code>options</code> describes the flags we're looking to parse, and <code>args</code> are the
command line arguments, as per <code>System.Environment.getArgs</code>. Once parsed, we
check for errors, apply defaults with <code>foldM (flip id) defaults opts</code>, and run.
The <code>foldM</code> has a bit going on, let's break that down by specializing the
arguments one at a time.</p>
<div><pre><span></span><span>*</span><span>Coreutils</span><span>.</span><span>Tee</span><span>&gt;</span> <span>:</span><span>t</span> <span>foldM</span>
<span>foldM</span>
  <span>::</span> <span>(</span><span>Foldable</span> <span>t</span><span>,</span> <span>Monad</span> <span>m</span><span>)</span> <span>=&gt;</span> <span>(</span><span>b</span> <span>-&gt;</span> <span>a</span> <span>-&gt;</span> <span>m</span> <span>b</span><span>)</span> <span>-&gt;</span> <span>b</span> <span>-&gt;</span> <span>t</span> <span>a</span> <span>-&gt;</span> <span>m</span> <span>b</span>

<span>*</span><span>Coreutils</span><span>.</span><span>Tee</span><span>&gt;</span> <span>:</span><span>t</span> <span>foldM</span> <span>(</span><span>flip</span> <span>id</span><span>)</span>
<span>foldM</span> <span>(</span><span>flip</span> <span>id</span><span>)</span>
  <span>::</span> <span>(</span><span>Foldable</span> <span>t</span><span>,</span> <span>Monad</span> <span>m</span><span>)</span> <span>=&gt;</span> <span>b</span> <span>-&gt;</span> <span>t</span> <span>(</span><span>b</span> <span>-&gt;</span> <span>m</span> <span>b</span><span>)</span> <span>-&gt;</span> <span>m</span> <span>b</span>

<span>*</span><span>Coreutils</span><span>.</span><span>Tee</span><span>&gt;</span> <span>:</span><span>t</span> <span>foldM</span> <span>(</span><span>flip</span> <span>id</span><span>)</span> <span>defaults</span>
<span>foldM</span> <span>(</span><span>flip</span> <span>id</span><span>)</span> <span>defaults</span>
  <span>::</span> <span>(</span><span>Foldable</span> <span>t</span><span>,</span> <span>Monad</span> <span>m</span><span>)</span> <span>=&gt;</span> <span>t</span> <span>(</span><span>Options</span> <span>-&gt;</span> <span>m</span> <span>Options</span><span>)</span> <span>-&gt;</span> <span>m</span> <span>Options</span>
</pre></div>
<p>What about <code>opts</code>? We can see the types align with <code>getOpt</code>'s first tuple if
our Foldable is a list and Monad is Either. This makes sense from a higher
level too; we have multiple "combine-able" operations (parsing flags) that can
succeed (provide an <code>Option</code>) or fail (provide a <code>String</code> error message). All
together, this executes the parsing functions <code>opts</code> in turn to build an
<code>Either String Options</code>, filling in the blanks with our defaults as necessary.</p>
<p>When we're all done, we have <code>Options</code> and a list of everything else not parsed
which we can use as the list of output filenames.</p>

<p>Let's take a look back and see what we're supposed to do next.</p>
<div><pre><span></span><span>runTee</span> <span>::</span> <span>Options</span> <span>-&gt;</span> <span>[</span><span>FilePath</span><span>]</span> <span>-&gt;</span> <span>IO</span> <span>()</span>
<span>-- ^ open handles for each filepath according to provided options, call tee</span>
</pre></div>
<p>So we have our options and filenames, and need to convert those into handles to
call the next layer. To properly manage our resources (these handles), we need
to close them too. Breaking these steps out in a <code>do</code> block would work most of
the time, but would leak if we hit an exception. On Linux, this isn't such a
big deal - the process exiting will close all the handles. However on Windows
(which we can support for free thanks to Haskell's IO libraries), not closing
the handles can mean that data doesn't get written. To that point, Haskell uses
exceptions to communicate IO errors, the exact type of errors we're likely to
encounter opening and writing to files. Luckily, <code>bracket</code> is perfect for this
situation; let's check it out.</p>
<div><pre><span></span><span>*</span><span>Coreutils</span><span>.</span><span>Tee</span><span>&gt;</span> <span>:</span><span>t</span> <span>bracket</span>
<span>bracket</span> <span>::</span> <span>IO</span> <span>a</span> <span>-&gt;</span> <span>(</span><span>a</span> <span>-&gt;</span> <span>IO</span> <span>b</span><span>)</span> <span>-&gt;</span> <span>(</span><span>a</span> <span>-&gt;</span> <span>IO</span> <span>c</span><span>)</span> <span>-&gt;</span> <span>IO</span> <span>c</span>
</pre></div>
<p>Provided some IO computation that produces resources, a function that uses
those resources, and a function that releases those resources, <code>bracket</code> will
run everything together, ensuring that the resources are released even if
there's an exception while they're being used.</p>
<div><pre><span></span><span>runTee</span> <span>::</span> <span>Options</span> <span>-&gt;</span> <span>[</span><span>FilePath</span><span>]</span> <span>-&gt;</span> <span>IO</span> <span>()</span>
<span>runTee</span> <span>o</span> <span>fs</span> <span>=</span>
        <span>bracket</span> <span>acquire</span> <span>release</span> <span>tee</span>
    <span>where</span>
        <span>acquire</span> <span>=</span> <span>mapM</span> <span>(`</span><span>openBinaryFile</span><span>`</span> <span>optMode</span> <span>o</span><span>)</span> <span>fs</span>
        <span>release</span> <span>=</span> <span>mapM_</span> <span>hClose</span>
</pre></div>
<p>Pretty easy!</p>

<p>So now we have our collection of handles, time to use them to do some real
work. Let's see it all together, then break it down.</p>
<div><pre><span></span><span>tee</span> <span>::</span> <span>[</span><span>Handle</span><span>]</span> <span>-&gt;</span> <span>IO</span> <span>()</span>
<span>-- build up n computations that copy the stream and write it a file</span>
<span>tee</span> <span>=</span> <span>Q</span><span>.</span><span>stdout</span> <span>.</span> <span>foldr</span> <span>(</span><span>\</span><span>h</span> <span>-&gt;</span> <span>Q</span><span>.</span><span>toHandle</span> <span>h</span> <span>.</span> <span>Q</span><span>.</span><span>copy</span><span>)</span> <span>Q</span><span>.</span><span>stdin</span>
</pre></div>
<p><code>Data.ByteString.Streaming</code> usage works right to left, where the right side is
the source of the stream, and the left side is the sink, where the data ends
up. The space between is where we can mutate the stream. The simplest <code>tee</code> is
with no files, in which it's just a simplified <code>cat</code> that only reads from
<code>stdin</code>. To describe that with these streams, that'd be:</p>
<div><pre><span></span><span>*</span><span>Coreutils</span><span>.</span><span>Tee</span><span>&gt;</span> <span>let</span> <span>cat</span> <span>=</span> <span>Q</span><span>.</span><span>stdout</span> <span>Q</span><span>.</span><span>stdin</span>
<span>*</span><span>Coreutils</span><span>.</span><span>Tee</span><span>&gt;</span> <span>:</span><span>t</span> <span>cat</span>
<span>cat</span> <span>::</span> <span>Control</span><span>.</span><span>Monad</span><span>.</span><span>IO</span><span>.</span><span>Class</span><span>.</span><span>MonadIO</span> <span>m</span> <span>=&gt;</span> <span>m</span> <span>()</span>
</pre></div>
<p>Take everything from stdin and stream it to stdout. For our purposes, <code>m</code> is
<code>IO</code>, nothing else is needed here. We can specialize our types to see this
ourselves, and that we're going to fit into the prototype we sketched out
initially for <code>tee</code>.</p>
<div><pre><span></span><span>*</span><span>Coreutils</span><span>.</span><span>Tee</span><span>&gt;</span> <span>let</span> <span>cat</span> <span>=</span> <span>Q</span><span>.</span><span>stdout</span> <span>Q</span><span>.</span><span>stdin</span> <span>::</span> <span>IO</span> <span>()</span>
<span>*</span><span>Coreutils</span><span>.</span><span>Tee</span><span>&gt;</span> <span>:</span><span>t</span> <span>cat</span>
<span>cat</span> <span>::</span> <span>IO</span> <span>()</span>
</pre></div>
<p>Now, for writing streams to handles we have <code>Q.toHandle</code>, but this has a
problem - it acts like a sink, consuming all of the input stream. This won't
work, since the input from <code>stdin</code> will never make it to <code>stdout</code>. We can't
read the stream twice either; for a file we could read everything twice, it
would just be wasteful, but for <code>stdin</code> it's not possible - the data only
exists once.</p>
<p>The library has something for us though: <code>Q.copy</code> forks a stream, allowing you
to do two separate, independent computations on it. Internally, this is
essentially sending the chunks that make up the input stream two different
places, creating two streams from one.</p>
<p>Let's build up a <code>cat</code> the preserves the input stream beyond writing to stdout
rather than consuming it.</p>
<div><pre><span></span><span>*</span><span>Coreutils</span><span>.</span><span>Tee</span><span>&gt;</span> <span>:</span><span>t</span> <span>Q</span><span>.</span><span>copy</span>
<span>Q</span><span>.</span><span>copy</span>
  <span>::</span> <span>Monad</span> <span>m</span> <span>=&gt;</span> <span>Q</span><span>.</span><span>ByteString</span> <span>m</span> <span>r</span> <span>-&gt;</span> <span>Q</span><span>.</span><span>ByteString</span> <span>(</span><span>Q</span><span>.</span><span>ByteString</span> <span>m</span><span>)</span> <span>r</span>

<span>*</span><span>Coreutils</span><span>.</span><span>Tee</span><span>&gt;</span> <span>:</span><span>t</span> <span>Q</span><span>.</span><span>copy</span> <span>Q</span><span>.</span><span>stdin</span>
<span>Q</span><span>.</span><span>copy</span> <span>Q</span><span>.</span><span>stdin</span>
  <span>::</span> <span>Control</span><span>.</span><span>Monad</span><span>.</span><span>IO</span><span>.</span><span>Class</span><span>.</span><span>MonadIO</span> <span>m</span> <span>=&gt;</span>
     <span>Q</span><span>.</span><span>ByteString</span> <span>(</span><span>Q</span><span>.</span><span>ByteString</span> <span>m</span><span>)</span> <span>()</span>

<span>*</span><span>Coreutils</span><span>.</span><span>Tee</span><span>&gt;</span> <span>:</span><span>t</span> <span>(</span><span>Q</span><span>.</span><span>stdout</span> <span>.</span> <span>Q</span><span>.</span><span>copy</span><span>)</span> <span>Q</span><span>.</span><span>stdin</span>
<span>(</span><span>Q</span><span>.</span><span>stdout</span> <span>.</span> <span>Q</span><span>.</span><span>copy</span><span>)</span> <span>Q</span><span>.</span><span>stdin</span>
  <span>::</span> <span>Control</span><span>.</span><span>Monad</span><span>.</span><span>IO</span><span>.</span><span>Class</span><span>.</span><span>MonadIO</span> <span>m</span> <span>=&gt;</span> <span>Q</span><span>.</span><span>ByteString</span> <span>m</span> <span>()</span>
</pre></div>
<p>While we're here thinking about stdout, let's note that <code>Q.stdout</code> isn't doing
anything magical compared to <code>Q.tohandle</code>, just sparing us some typing. This is
useful, because it let's us treat stdout as "just another output", the same as
the handles we're creating.</p>
<div><pre><span></span><span>*</span><span>Coreutils</span><span>.</span><span>Tee</span><span>&gt;</span> <span>:</span><span>t</span> <span>Q</span><span>.</span><span>toHandle</span> <span>stdout</span>
<span>Q</span><span>.</span><span>toHandle</span> <span>stdout</span>
  <span>::</span> <span>Control</span><span>.</span><span>Monad</span><span>.</span><span>IO</span><span>.</span><span>Class</span><span>.</span><span>MonadIO</span> <span>m</span> <span>=&gt;</span> <span>Q</span><span>.</span><span>ByteString</span> <span>m</span> <span>r</span> <span>-&gt;</span> <span>m</span> <span>r</span>

<span>*</span><span>Coreutils</span><span>.</span><span>Tee</span><span>&gt;</span> <span>:</span><span>t</span> <span>Q</span><span>.</span><span>stdout</span>
<span>Q</span><span>.</span><span>stdout</span>
  <span>::</span> <span>Control</span><span>.</span><span>Monad</span><span>.</span><span>IO</span><span>.</span><span>Class</span><span>.</span><span>MonadIO</span> <span>m</span> <span>=&gt;</span> <span>Q</span><span>.</span><span>ByteString</span> <span>m</span> <span>r</span> <span>-&gt;</span> <span>m</span> <span>r</span>
</pre></div>
<p>With our stream copying ability, we can create a waterfall of streams! stdin to
the first handle + new stream 1, new stream 1 to the second handle + new stream
2, and so on until the last stream, which just goes to stdout.</p>
<p>Good old <code>foldr</code> matches this pattern well; take some initial value, run a
computation on it with the first input to produce an output, then use that as
the new initial value for the second input value, and so on.</p>
<div><pre><span></span><span>*</span><span>Coreutils</span><span>.</span><span>T…</span></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://anardil.net/2020/haskell-coreutils-tee.html">https://anardil.net/2020/haskell-coreutils-tee.html</a></em></p>]]>
            </description>
            <link>https://anardil.net/2020/haskell-coreutils-tee.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25377939</guid>
            <pubDate>Thu, 10 Dec 2020 20:10:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Quick guide to the security features of euro banknotes [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25377645">thread link</a>) | @dt3ft
<br/>
December 10, 2020 | https://www.ecb.europa.eu/euro/pdf/material/Quick_Guide_EN_Specimen.pdf | <a href="https://web.archive.org/web/*/https://www.ecb.europa.eu/euro/pdf/material/Quick_Guide_EN_Specimen.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.ecb.europa.eu/euro/pdf/material/Quick_Guide_EN_Specimen.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25377645</guid>
            <pubDate>Thu, 10 Dec 2020 19:43:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Non-Dilutive Funding for SaaS]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25377563">thread link</a>) | @tacon
<br/>
December 10, 2020 | https://www.trypaper.io/funders | <a href="https://web.archive.org/web/*/https://www.trypaper.io/funders">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.trypaper.io/funders</link>
            <guid isPermaLink="false">hacker-news-small-sites-25377563</guid>
            <pubDate>Thu, 10 Dec 2020 19:37:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learning about Elixir's generic server processes with a real-world example]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25377107">thread link</a>) | @areichert
<br/>
December 10, 2020 | https://papercups.io/blog/genserver | <a href="https://web.archive.org/web/*/https://papercups.io/blog/genserver">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://papercups.io/blog/genserver</link>
            <guid isPermaLink="false">hacker-news-small-sites-25377107</guid>
            <pubDate>Thu, 10 Dec 2020 19:02:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A New Take on RSS]]>
            </title>
            <description>
<![CDATA[
Score 138 | Comments 33 (<a href="https://news.ycombinator.com/item?id=25376849">thread link</a>) | @jacobobryant
<br/>
December 10, 2020 | https://findka.com/blog/new-take-on-rss/ | <a href="https://web.archive.org/web/*/https://findka.com/blog/new-take-on-rss/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Findka now includes an RSS aggregator.</p><p><img src="https://findka.com/img/subscriptions-example.png" alt="Example of subscribing to RSS feeds on Findka"></p><p>If you subscribe to any feeds, then 50% of the articles in your regular Findka
emails will be sampled from those feeds.
I added this because, <a href="https://findka.com/blog/2020-12-05/">as I mentioned</a>,
I'm going to start doing more manual curation to make sure that Findka has a
steady stream of new, great essays. I also think it's a valuable feature for
anyone who wants a little more control over their Findka recommendations.</p><p>How's this different from existing RSS aggregators? For one thing, since this
is built into Findka, any articles that you like will start to be recommended
to other users, too. But there's more.</p><p>Most RSS aggregators keep your feeds separate. Findka instead merges them into
a single feed using a bandit algorithm. If you've subscribed to three
feeds—A, B and C—Findka will start out picking articles from the
feeds uniformly. 1/3 of the articles will come from feed A, etc. As time goes
on, Findka will adjust the distribution based on your usage data. If you never
click on articles from feed A and you always click on articles from feed B,
then Findka will show you fewer articles from A and more articles from B.</p><p>On top of that, the number of articles in your feed is controlled by you, not
by the feeds you subscribe to.</p><p><img src="https://findka.com/img/frequency-setting.png" alt="Example of subscribing to RSS feeds on Findka"></p><p>The result is that using RSS now takes extremely little effort. You get a
single, small feed that improves itself automatically.</p><p>I'm planning to add more RSS-related features—stay tuned.</p></div></div>]]>
            </description>
            <link>https://findka.com/blog/new-take-on-rss/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25376849</guid>
            <pubDate>Thu, 10 Dec 2020 18:40:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Blog from Emacs via magit-forge backed by GitHub issues]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25376755">thread link</a>) | @sgrove
<br/>
December 10, 2020 | https://sgrove.essay.dev/post/25/essaydev-a-real-time-blog-from-emacs-magit-forge-based-on-github-issues | <a href="https://web.archive.org/web/*/https://sgrove.essay.dev/post/25/essaydev-a-real-time-blog-from-emacs-magit-forge-based-on-github-issues">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><a href="https://twitter.com/sgrove"><p><img alt="Sean Grove" src="https://sgrove.essay.dev/api/image/aHR0cHM6Ly9hdmF0YXJzMy5naXRodWJ1c2VyY29udGVudC5jb20vdS8zNTI5Nj9zPTk2JnU9OTc1M2U1MmU2NjRkYmEyYWI4M2IyYzA4YjlhNmNjOTBhNWNhYzdiYiZ2PTQ"></p></a></div></div><p><span><p>So @dwwoelfel and I have been working on a powerful blogging system that keeps all of your data inside of GitHub issues - you can see the result (and post yourself) live on <a href="https://essay.dev/">essay.dev</a> - or you can fork the open-source repo and deploy your instance, and all the instructions below will work just fine on your own repo.</p><h4 id="watch-me-create-a-blog-post-from-inside-magit-forge">Watch me create a blog post from inside magit-forge</h4><p><iframe title="https://www.youtube.com/watch?v=VVOd1yOKVqQ" type="text/html" width="100%" height="360" src="https://www.youtube.com/embed/VVOd1yOKVqQ" frameborder="0"></iframe></p><h3 id="github-issue-powered-blogging-and-commenting">GitHub-issue powered blogging and commenting</h3><p>The entire site is powered by GitHub issues and next.js (and hosted on Vercel). Any issue with a <code>Publish</code> tag will be made publicly available immediately (and can be similarly unpublished by removing the <code>Publish</code> label).</p><p>That's pretty fantastic for lots of reasons - your posts are now in an API that's easy to slice and dice so there's no lock-in to your content or comments, it's a familiar place for devs to work, etc.</p><p>There are hundreds of features and polish in essay.dev, but importantly for me, it's compatible with emacs' <code>magit-forge</code>!</p><h3 id="magit-forge-i-choose-you"><code>magit-forge</code>, I choose you!</h3><p><code>magit</code> is the famous git control system for emacs, and it has an equally powerful integration to manage GitHub issues called <code>magit-forge</code>.</p><p><span><img src="https://sgrove.essay.dev/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vMzUyOTYvMTAxMDgwMzI3LTgyNTg3ZDAwLTM1NWQtMTFlYi04MmFiLTQwZTI0MGZlYWY3Ni5wbmc" alt="Preview of reading a rich post on `essay.dev` in `magit-forge`"></span></p><p>You can do all the normal CRUD operations on GitHub issues inside a familiar emacs workflow - which means we can do the same for our posts<sup>1</sup>!</p><h3 id="creating-a-post-on-essaydev">Creating a post on essay.dev</h3><p>First make sure you've installed <a href="https://magit.vc/"><code>magit</code></a> and <a href="https://magit.vc/manual/forge.html"><code>magit-forge</code></a> (or for spacemacs users, just add the <a href="https://develop.spacemacs.org/layers/+source-control/github/README.html"><code>GitHub layer</code></a>).</p><p>Now, let's clone the <code>essay.dev</code> repo:</p><div><pre><code><span>git clone https://github.com/OneGraph/essay.dev.git</span>
<span>cd essay.dev</span>
<span>emacs README.md</span></code></pre></div><p>Next we'll connect <code>forge</code> with our GitHub repository via <code>M-x forge-add-repository</code> - and now we're ready to see a list of all of the posts, so run <code>M-x forge-list-issues</code>:</p><p><span><img src="https://sgrove.essay.dev/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vMzUyOTYvMTAxMDgwMDkxLTMxNDg4OTAwLTM1NWQtMTFlYi05MDgyLTMzYzMxYzQ3NmFiMy5wbmc" alt="`magit-forge` listing posts on `essay.dev`"></span></p><p>If we hit <kbd>Enter</kbd> on any of the issues, we'll see the content and the comments:</p><p><span><img src="https://sgrove.essay.dev/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vMzUyOTYvMTAxMDgwNDM2LWE2YjQ1OTgwLTM1NWQtMTFlYi04ZDUzLTQ5Y2JhMTBhMmNlYy5wbmc" alt="Look at this excellent post - we'll have to up our game from now on"></span></p><h4 id="create-a-new-post">Create a new post</h4><p>Running <code>M-x forge-create-issue</code> will create a new buffer pre-filled via the default <code>new-post</code> template:</p><p><span><img src="https://sgrove.essay.dev/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vMzUyOTYvMTAxMDgwODYxLTJhNmU0NjAwLTM1NWUtMTFlYi04YTU0LTczNmE0ZDExOWYyYS5wbmc" alt="We're ready to write our next great post"></span></p><p>Simply fill out the title and the body, and when you're ready, "commit" the new post via <code>C-c C-c</code>. Forge will commit it to a local database first for safe-keeping, and then create an issue on GitHub! Back in the <code>*forge-issue-list...*</code> buffer, hit <kbd>g</kbd> to refresh the lists of posts, with your newest one at the top. Hit <kbd>Enter</kbd> on it to view the contents.</p><h4 id="your-post-is-ready">Your post is ready!</h4><p>A few seconds later, run <code>M-x forge-pull</code> to update your local copy - you should find there's a new comment waiting for you from <code>onegraph-bot</code>:</p><span><blockquote><p>View your post at https://<username></username>.essay.dev/post/<issue-number></issue-number>/<issue-title></issue-title></p></blockquote></span><p><span><img src="https://sgrove.essay.dev/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vMzUyOTYvMTAxMDgwOTE3LTQyZGU2MDgwLTM1NWUtMTFlYi05ODAwLWFmM2M3MTFhYjY5MC5wbmc" alt="Our post is all grown up and ready for the world"></span></p><p>That's it, your post is available to the world.</p><p>You can also leave comments on your posts (and others) with <code>M-x forge-create-post</code>:</p><p><span><img src="https://sgrove.essay.dev/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vMzUyOTYvMTAxMDgxMDUwLTY5MDQwMDgwLTM1NWUtMTFlYi04ODU2LTUzNzRkMGE1NjRiOC5wbmc" alt="Why leave emacs to leave a comment?"></span></p><p>It'll show up instantly on your post (both in forge and on the site):</p><p><span><img src="https://sgrove.essay.dev/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vMzUyOTYvMTAxMDgxMTE4LTdmMTFjMTAwLTM1NWUtMTFlYi05M2ZkLWMzMDJiOGYyNGNiZC5wbmc" alt="Thanks to the API-based backend (and some clever engineering), posts and comments show up everywhere seamlessly"></span></p><h3 id="whats-next">What's next?</h3><p>Your content belongs to you, and is easily accessible through the GitHub API - here's an example query that'll pull out the posts for you:</p><div><pre><code><span>query</span><span> MyPostsOnGitHub(</span>
<span>  $owner: String = </span><span>"onegraph"</span>
<span>  $name: String = </span><span>"essay.dev"</span>
<span>  $createdBy: String = </span><span>"sgrove"</span>
<span>) {</span>
<span>  gitHub {</span>
<span>    repository(name: $name, owner: $owner) {</span>
<span>      issues(</span>
<span>        first: </span><span>10</span>
<span>        orderBy: { </span><span>field</span><span>: CREATED_AT, </span><span>direction</span><span>: DESC }</span>
<span>        filterBy: { </span><span>createdBy</span><span>: $createdBy }</span>
<span>      ) {</span>
<span>        edges {</span>
<span>          node {</span>
<span>            body</span>
<span>            number</span>
<span>            title</span>
<span>          }</span>
<span>        }</span>
<span>      }</span>
<span>    }</span>
<span>  }</span>
<span>}</span></code></pre></div><p>Try it out <a href="https://www.onegraph.com/graphiql?shortenedId=R8KXQM&amp;snippetKey=JavaScript%3Areact-apollo">here</a></p><p>And again, note that this setup will work with any repo, so if you want to self-host your content it's as easy as using the <a href="https://vercel.com/new/git/external?repository-url=https%3A%2F%2Fgithub.com%2FOneGraph%2Foneblog%2Ftree%2Fnext&amp;env=NEXT_PUBLIC_ONEGRAPH_APP_ID,NEXT_PUBLIC_TITLE,OG_GITHUB_TOKEN,OG_DASHBOARD_ACCESS_TOKEN,VERCEL_URL,VERCEL_GITHUB_ORG,VERCEL_GITHUB_REPO&amp;envDescription=Variables%20needed%20to%20build%20your%20OneBlog&amp;envLink=https%3A%2F%2Fgithub.com%2FOneGraph%2Foneblog%2Ftree%2Fnext%23environment-variables&amp;project-name=oneblog&amp;repo-name=oneblog">deploy on vercel</a> link.</p></span></p></div></div>]]>
            </description>
            <link>https://sgrove.essay.dev/post/25/essaydev-a-real-time-blog-from-emacs-magit-forge-based-on-github-issues</link>
            <guid isPermaLink="false">hacker-news-small-sites-25376755</guid>
            <pubDate>Thu, 10 Dec 2020 18:31:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Docker to Manage Your Test Database(s)]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25376621">thread link</a>) | @craigkerstiens
<br/>
December 10, 2020 | https://www.tonic.ai/post/using-docker-to-manage-your-test-database | <a href="https://web.archive.org/web/*/https://www.tonic.ai/post/using-docker-to-manage-your-test-database">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><figure id="w-node-b46f52e7cc86-94242d82"><p><img src="https://uploads-ssl.webflow.com/5f0ae1534d32e5a91598eb9c/5fb81ee39c9c19251287e848_Docker%20for%20Test%20DB.png" loading="lazy" alt=""></p></figure><p><em>TL;DR: Docker is a great tool for packaging and distributing test databases among your team and testing environment. We’ve created </em><a href="https://github.com/TonicAI/docker-testdb" target="_blank"><em>a starter repository</em></a><em> to show these concepts in PostgreSQL and MySQL </em><a href="https://github.com/TonicAI/docker-testdb" target="_blank"><em>on Github</em></a><em> if you’d like to dig in immediately while reviewing our process below.</em></p><p>Containers are a valuable resource for us developers. They give you the ability to package your production code, dependencies, and assets into a standardized unit. Once conveniently packaged, running your application in a variety of environments is a breeze. And yet despite containerization’s immense value, we often see teams overlook containers entirely when it comes to managing test databases. At Tonic, whether we’re helping our customers improve testing with high-quality test databases or building our own testing environments, we rely on Docker as a key part of the pipeline. Our customers are finding a lot of value in the approach, so we thought we’d share our strategy.</p><h2>The Trouble With Test Databases</h2><p>Let’s take a look at the typical growth of a test database for a team:</p><ol role="list"><li>You and your team realize that testing in production is a bad idea. You’ve heard about it or you’ve felt the pain yourself: mistakes that lead to data loss and time spent restoring from backups; poor reliability in production due to increased database load; the security team raising their eyebrows at giving too many people access to sensitive data; and the omnipresent anxiety that testing might take down production.</li><li>You decide you need data that’s similar to your production environment, so you write some scripts to generate some fake data (like<a href="https://www.tonic.ai/post/how-to-generate-simple-test-data-with-faker" target="_blank"> faker</a>), use some free or paid services to generate some random data for you (like<a href="https://www.tonic.ai/post/tonic-mockaroo" target="_blank"> Mockaroo</a>), or extract data from production and attempt to anonymize it later (dealing with the mess of maintaining referential integrity).</li><li>You shove either those scripts or data files into your code repo.</li><li>You write in a README the loader command to get it into your database of choice, and like a rite of passage, everyone on the team struggles through getting it to work during onboarding.</li></ol><p>And struggle you will! Databases are notorious for requiring large installations with a multitude of dependencies, navigating arcane configuration, and the extensive work of establishing the test dataset: creating schemas, creating tables, and finally loading your generated data.</p><p>Many teams will have a separate installation process for each operating system their developers use, each of which usually takes a good bit of trial and error after poring over database documentation. Others will set up a staging or test server for their team to use, but it risks becoming out-dated without a regular rebuild, it means a lot of coordination between team members, and there is rarely a one-size-fits-all test environment. For example, when you want to test the scale of your application, your entire team is saddled with a giant database that slows everyone down; likewise, too small of a database can limit effective testing for certain projects.</p><p>Wouldn’t it be great if there were a tool that made it easy to package a database, its dependencies, loader scripts, and its data for any operating system? That any team member could use to easily test their code against a test environment, be it on their local machine or on a quickly spun-up test server in the cloud?</p><h2>Doing Better with Docker</h2><p>Good news, everyone! There is a better way! The many benefits that Docker provides for shipping your code in production work likewise for testing. You can create a database that is easy to distribute, deploy, and reset so that individuals and teams can work effectively without stepping on each other’s toes. For larger organizations, you can even package multiple test databases that each contain different tables or amounts of data, easily available to everyone in your engineering org. Best of all, you don’t need a different local installation README for each operating system—developers can just use the OS they feel most productive in without the headaches of the past.</p><h3>The Basics</h3><p>The simplest way to get started is to use a vanilla database image for your database of choice. By using docker-compose, you can set up the configuration once, and it’s just a<tt> docker-compose up -d </tt>to start the database. Here’s a basic configuration below:</p><h5>version: '3'<br>services:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;testdb_postgres:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;image: postgres:12<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;restart: always<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ports:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- 5432:5432<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;environment:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;POSTGRES_USER: user<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;POSTGRES_PASSWORD: password<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;POSTGRES_DB: test_data<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;container_name: testdb_postgres<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;volumes:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- /tmp:/tmp<br></h5><p>This configuration does the following:</p><div><ul role="“list”">
<li>Creates a container named<tt> testdb_postgres </tt>that runs off of a PostgreSQL 12 image</li>
<li>Opens up Postgres’ default port of 5432 to 5432 on your host machine</li>
<li>Attaches the<tt> /tmp </tt>folder to your host machine’s<tt> /tmp </tt>folder</li>
<li>Creates a new user with credentials<tt> user/password</tt>, and a new database called<tt> testdb_postgres</tt>.</li></ul></div><p>Right off the bat, we’ve removed a lot of work from the README, and if you have data or data-generating scripts in your repo, you’ve made it much easier to get up and running quickly by simply pointing them to load into the database via the host part. Many databases have official images, including <a href="https://hub.docker.com/_/postgres/" target="_blank">Postgres</a>, <a href="https://hub.docker.com/_/mysql" target="_blank">MySQL</a>, <a href="https://hub.docker.com/_/microsoft-mssql-server" target="_blank">MS SQL Server</a>, <a href="https://hub.docker.com/_/oraclelinux" target="_blank">Oracle</a>, and <a href="https://hub.docker.com/_/mongo" target="_blank">Mongo</a>, among others.</p><h3>Even Better: Packaging Your Data &amp; Scripts with Docker</h3><p>Instead of just using the available database image and calling it a day, you can easily create a new Docker image based off of your database’s official image. Many official images have an entry point folder that allows you to run scripts upon initialization, enabling the container to be immediately useful as soon as it’s up. To do this, you’ll likely need to add a Dockerfile and a build script, and potentially any data import scripts.</p><h4>Dockerfile</h4><p>Making a basic Dockerfile is not hard at all, in fact it’s only two lines:</p><h5>FROM postgres:12<br>COPY sql/*.sql /docker-entrypoint-initdb.d/</h5><p>Here we did the following:<br></p><div><ol role="list">
<li>We started by defining a<tt> Dockerfile </tt>with a<tt> FROM </tt>declaration pointing to the base image of your database.</li>
<li>We copied over all of our data import scripts (defined in a subdirectory named sql) to the<tt> /docker-entrypoint-initdb.d/ </tt>directory. Postgres <a href="https://hub.docker.com/_/postgres/">defines this folder</a> for SQL scripts to be run during initialization.</li>
</ol></div><p>In our <a href="https://github.com/TonicAI/docker-testdb" target="_blank">code repository</a>, you’ll see we’ve commented out additional options to consider for your use case, such as:</p><ul role="list"><li>Adding any additional dependencies, like database extensions or certificates using typical package manager commands.</li><li>Adding data files to an accessible directory for use with data import scripts.</li><li>Adding custom scripts to import data outside of the container, e.g. via S3 or other data storage.</li></ul><h4>Build Script</h4><p>Here we simply create a shell script to make it easier to build the container. Our build.sh contains the following command which merely tags the new container as<tt> testdb_postgres </tt>and specifies the Dockerfile to use.</p><h5>docker build -f Dockerfile -t testdb_postgres .<br></h5><p>If you were building this in a CI environment, we’d recommend giving the tag a unique version for each build and release as a script argument, such as<tt> testdb_postgres:1.0.4</tt>.</p><h4>SQL Scripts</h4><p>Next, you’ll need to create SQL loader scripts that create your schema and load in your data. Typically the easiest way to do this is by using database dump commands with an existing test database. We recommend three scripts: the first one creates your schema without constraints, the second one loads your data, and the third one adds your constraints to all of your tables. This way, you’re able to load your data without worrying about the order in which it’s loaded (which would matter if foreign key constraints were already in place).</p><p>Some databases will turn off constraints using a data import tool until the import is complete, which means you can just keep your constraints in the schema script. For simplicity, in <a href="https://github.com/TonicAI/docker-testdb" target="_blank">our example code</a> we only use two scripts since our data script loads tables in order and doesn’t break referential integrity.</p><p>Sticking with PostgreSQL as our example, you can run the following command to get a dump of your existing schema and constraints:</p><h5>pg_dump -U user -s -f 1_schema.sql [YOUR DATABASE NAME];</h5><p>Followed by a similar command to get just the data:<br></p><h5>pg_dump -U user -a -f 2_data.sql test_data;<br></h5><p>Notably, we’ve added numbers to the beginning of each filename to ensure that the schema script is run before the data load script. (Postgres runs the scripts in this folder in alphabetical order.)</p><p>Take a look at our code to see the full output of both of these files. Feel free to modify these files as you like or write them from scratch, especially if you plan to load your data using a COPY or LOAD command.</p><h4>Modifying your docker-compose.yml</h4><p>Lastly, update the image you’re using to the name of your newly tagged one: image: testdb_postgres. If you’re versioning your container when you build it, we recommend specifying a stable release tag such as<tt> testdb_postgres:stable </tt>so that users can pull the latest update to that tag with<tt> docker-compose pull</tt>.</p><h4>Setting up CI</h4><p>Now you can check your Dockerfile, scripts, and data files into a code repo, and create a build for the Docker container in your CI service of choice using your build script. Any time the scripts or data files are changed, we recommend triggering a new release build for the container and pushing it to your container repository for use by your entire team (of course, after you’ve checked that nothing new caused the build to break 😉).</p><p>If everything is set up, it should be as simple as distributing the docker-compose.yml file to your team and running a<tt> docker-compose up</tt>.</p><h2>Next Level Test Data Management</h2><p>If you’ve followed the steps thus far, you’ll likely find that your testing setup is much more reliable and useful to your entire team, and it’s a big leap forward in efficiency.</p><p>From here, there are a lot of ways …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.tonic.ai/post/using-docker-to-manage-your-test-database">https://www.tonic.ai/post/using-docker-to-manage-your-test-database</a></em></p>]]>
            </description>
            <link>https://www.tonic.ai/post/using-docker-to-manage-your-test-database</link>
            <guid isPermaLink="false">hacker-news-small-sites-25376621</guid>
            <pubDate>Thu, 10 Dec 2020 18:19:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mystery illness in India found excessive levels of lead, nickel in blood]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25375917">thread link</a>) | @gmays
<br/>
December 10, 2020 | https://www.cbc.ca/news/world/india-mystery-illness-nickel-lead-1.5833982 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/world/india-mystery-illness-nickel-lead-1.5833982">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Indian health officials have found traces of nickel and lead in a few of the blood samples taken from hundreds of patients who have been hospitalized by a mysterious illness in a southern state, the state government says.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5834017.1607524630!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/india-mystery-illness.jpg"></p></div><figcaption>Health officials and experts in India are investigating a mysterious illness linked to the death of one person and the hospitalization of 585 others. In this photo, taken Tuesday, a patient is assisted out of an ambulance at the district government hospital in Eluru, Andhra Pradesh state. <!-- --> <!-- -->(The Associated Press)</figcaption></figure><p><span><p>Indian health officials have found traces of nickel and lead in a few of the&nbsp;blood samples taken from hundreds of patients who have been hospitalized by a mysterious illness in a southern state, officials said.</p>  <p>The Andhra Pradesh state government said in a statement Tuesday night that investigations by experts from the All India Institute of Medical Sciences have&nbsp;not been able to determine&nbsp;the source of excessive nickel and lead particles in the patients' blood.</p>  <p>The government was still waiting for results of other tests, including toxicology reports and blood cultures, being conducted by experts at the Indian Institute of Chemical Technology, the statement said&nbsp; &nbsp;</p>  <p>Health officials and experts appeared to be baffled&nbsp;by how the heavy metals got into the patients' blood, and whether those metals&nbsp;caused the mysterious illness linked&nbsp;to the death of one person&nbsp;and the hospitalization of&nbsp;more than 585 others.</p>    <p>The illness was first detected Saturday evening in Eluru, an ancient city famous for its handwoven products.</p>  <p>People with the illness started convulsing without any warning, said Geeta Prasadini, a state health official.</p>  <p>Andhra Pradesh Chief Minister Y.S. Jaganmohan Reddy held a virtual meeting Wednesday with officials who included experts from India's top scientific institutes.</p>  <p>Reddy said 502 of the people who went to hospital were&nbsp;discharged after showing improvement.</p>  <h2>No apparent common link</h2>  <p>The patients showed symptoms ranging from nausea and anxiety to loss of consciousness.</p>  <p>What is confounding experts is that there doesn't seem to be any common link among the hundreds of people who have fallen sick.</p>  <p>All of the patients have tested negative for the coronavirus and other viral diseases such as dengue, chikungunya and herpes.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5834023.1607524932!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/india-mystery-illness.jpg 300w,https://i.cbc.ca/1.5834023.1607524932!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/india-mystery-illness.jpg 460w,https://i.cbc.ca/1.5834023.1607524932!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/india-mystery-illness.jpg 620w,https://i.cbc.ca/1.5834023.1607524932!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/india-mystery-illness.jpg 780w,https://i.cbc.ca/1.5834023.1607524932!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/india-mystery-illness.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5834023.1607524932!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/india-mystery-illness.jpg"></p></div><figcaption>A man carries a young patient at the district government hospital in Eluru on Monday. About 70 children are among those stricken by the mystery illness.<!-- --> <!-- -->(The Associated Press)</figcaption></figure></span></p>  <p>Those who became ill aren't related to each other and don't all live in the same area. They represent different age groups, including about 70 children, but very few are elderly.</p>  <p>Initially, officials suspected contaminated water. But the chief minister's office confirmed that people who don't use the municipal water supply have also fallen ill, and that initial tests of water samples didn't reveal any harmful chemicals.</p>  <p>A 45-year-old man who goes by the single name Sridhar went to hospital with symptoms resembling epilepsy and died Sunday evening, doctors said. Prasadini said his autopsy didn't shed any light on the cause of death.</p>  <p>Andhra Pradesh state is among those worst-hit by the coronavirus, with over 800,000 detected cases. The health system in the state, like the rest of India, has been frayed by the virus.</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/world/india-mystery-illness-nickel-lead-1.5833982</link>
            <guid isPermaLink="false">hacker-news-small-sites-25375917</guid>
            <pubDate>Thu, 10 Dec 2020 17:19:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Double fetches, scheduling algorithms, and onion rings]]>
            </title>
            <description>
<![CDATA[
Score 46 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25375637">thread link</a>) | @markmossberg
<br/>
December 10, 2020 | https://offlinemark.com/2020/11/12/double-fetches-scheduling-algorithms-onion-rings/ | <a href="https://web.archive.org/web/*/https://offlinemark.com/2020/11/12/double-fetches-scheduling-algorithms-onion-rings/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p>Most people thought I was crazy for doing this, but I spent the last few months of my gap year working as a short order cook at a family-owned fast-food restaurant. (More on this <a href="https://offlinemark.com/2020/11/12/gap-year-restaurant/">here</a>.) I’m a programmer by trade, so I enjoyed thinking about the restaurant’s systems from a programmer’s point of view. Here’s some thoughts about two such systems.</p>



<h2>Double, triple, and even quadruple fetching</h2>



<p>Human systems, at first glance, can appear broken, but due to subtle human factors, they might actually work just fine.</p>



<p>My best example is the system for taking and fulfilling orders. We never wrote anything down, and would re-ask orders multiples times, including when ringing customers up. (In computer security, this is known as a <a href="https://ctf-wiki.github.io/ctf-wiki/pwn/linux/kernel/double-fetch/">double fetch</a>.) Not great service and can theoretically let customers lie and pay less. </p>



<p>In practice most customers didn’t mind too much, liars are rare, and we can loosely detect when something seems off with an order.</p>



<p>Writing orders down and asking strictly once seems optimal but has subtle flaws. For one thing, there’s not enough space behind the counter for everyone to walk to the written order, so it requires more internal communication. This will fail during a rush when you’re blocked on order details and coworkers are too busy for questions. <strong>Customers are always idle; coworkers aren’t</strong>.</p>



<p>It can increase confusion if order slips aren’t thrown out when orders are finished and is also logistically (and literally) messy if you have greasy gloves and want to avoid touching a pen, then food. Lastly, many of my coworkers were older and very used to the existing system. <strong>A major transition to a new system would have generated more confusion than it’s worth</strong>.</p>



<h2>Scheduling algorithms for the fry cook</h2>



<p>While I covered a range of duties including the cash register, milkshake machine, and grill, I spent the most time on the deep fryer. I’m delighted to present this overanalysis of life as a fry cook, from a programmer’s point of view.</p>



<p>This is what deep fryers look like (<a href="https://www.google.com/url?sa=i&amp;url=https%3A%2F%2Fwww.nachi.org%2Fdeep-fryer-inspection.htm&amp;psig=AOvVaw1D90dsceyn1wmU-KOGAEuy&amp;ust=1605391502547000&amp;source=images&amp;cd=vfe&amp;ved=0CAIQjRxqFwoTCNCq-sPDgO0CFQAAAAAdAAAAABAE">source</a>):</p>



<div><figure><img loading="lazy" src="https://i0.wp.com/d12m281ylf13f0.cloudfront.net/images10-2/commercial-fryer-2.jpg?resize=360%2C352&amp;ssl=1" alt="Deep Fryer" width="360" height="352" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/d12m281ylf13f0.cloudfront.net/images10-2/commercial-fryer-2.jpg?resize=360%2C352&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>



<p>This picture has 2 fryers, each with 2 baskets that can be submerged to sit in the vats of hot oil below. At work, only 1 fryer would be active on any given day which effectively allows 2 items to be fried at the same time.</p>



<p><strong>Fry cooks have a lot in common with operating systems in that they are both responsible for scheduling</strong>. Operating systems schedule threads to run on a limited number of cores; fry cooks schedule food to be fried in a limited number of fryers. Different food items have different priorities, and different lengths of time to cook.</p>



<p>French fries, curly fries, and onion rings (collectively, “fries”) are the main menu items from the deep fryer. Each fry order could be large or small (except for rings which were only large) and eat-in or to-go. The job of the fry cook is to:</p>



<ul><li>Accept fry orders from the greeter.</li><li>Allocate portions of fries from the big bags of raw fries</li><li>Cook them in the fryers</li><li>Put them into the appropriate eat-in/to-go container</li><li>Serve them onto the customer’s tray on the counter, or their to-go bag</li></ul>



<p>The goal is to do this with maximum speed and accuracy and without dropping orders. You’ll ideally minimize the number of times you ask customers and coworkers for order details. In addition, there are a few sources of complexity to handle:</p>



<ul><li><strong>Incomplete information</strong>: Depending on the greeter, they may forget to specify if it’s eat-in or to-go. You can always ask the customer, but the grill chef will likely ask the same question in a little bit. You might be able to save a customer ask if you can eavesdrop on that interaction.</li><li><strong>Timing requirements</strong>: You need to finish orders by the time the grill chef finishes the burgers/hot dogs, but you shouldn’t finish too early. If you put the fries on the counter way before the burgers are ready, they’ll get cold. This matters less for to-go orders, which you can serve into the bag immediately.</li><li><strong>Scale</strong>: During a rush, you might receive many orders per minute, while only being able to process 1-2 per minute. Once the greeter relays the order, they forget it, so it’s up to you to remember. And remember: no writing things down.</li><li><span><strong>Waste avoidance</strong>: </span>Sometimes you or another cook will make too many fries. To avoid wasting them, you can use the excess towards a future order by refreshing them with a splash later and adding them to a fresh batch.</li><li><strong>Changing orders</strong>: Customers sometimes change their order after you’ve started cooking (e.g. regular fry to curly fry). Now you have to figure out what to do with the partially cooked portion currently in the fryer.</li><li><strong><strong>Misc items</strong></strong>: In addition to fries, there other items that need to be scheduled for time in the fryer, including chicken patties, bacon, clam strips, and fish fillets. </li></ul>



<p>A few techniques to manage all this:</p>



<ul><li><strong>Batching orders together</strong>. If a large and small fry order are in the queue, you can cook them in the same basket at the same time.<ul><li>Some customers request their fries “well done”, meaning cooked extra long. This makes batching more complicated.</li></ul></li><li><strong>“Wait n Splash”</strong>: If a fry order is done cooking far before the rest of the grill items and you don’t have pressing items that need fryer time, you can raise the basket from the oil, but leave the food in it. When the grill items finish, you can quickly splash the food back in the oil to refresh it, then serve it. This will prevent it from getting cold on the counter.</li><li><strong>Inactive fryer baskets</strong>: It can be handy to have extra storage space for cooked food. If you have a “wait n splash” order waiting, but you have more orders to fry, you can use the 2 spare baskets from the inactive fryer to store the waiting order and free up the fryer slot. This is also useful when customers change their order and you need to quickly stash the half cooked portion somewhere and start the adjusted order.</li><li><strong>“The tong dip”</strong>: If both fryers are in use and the grill chef hands you bacon to be urgently cooked, you can hold the bacon in tongs and dip it into one of the submerged baskets. This lets you effectively cook more than 2 things at the same time.</li></ul>



<p>Here’s the system I ended up using. When a new order came in, I’d stop whatever I was doing and grab the appropriate container and place it in the corresponding fry bucket. This captures all 3 pieces of information about the order (fry type, size, to-go?) letting me forget it. If I strictly follow this, I can just process the containers in the buckets like a queue. However, I still need to keep a sense of order memorized because the system doesn’t capture global ordering – if I have containers in the fry, curly fry, and onion ring buckets, I can’t tell which order came in first.</p>



<p>I don’t have a solution for this. On a super busy day, this system falls apart and I drop orders. Extreme load like that has only happened a few times and in that case, I just make large batches, forget about syncing up with the grill items, and hope I don’t have too much excess at the end. Generally, the system worked nicely.</p>



<h2>Conclusion</h2>



<p>It’s fun to think about human systems, like those in a restaurant, from a programmer’s point of view. A fry cook’s job closely resembles that of an operating system scheduler, complete with optimization points and edge cases. One can try to optimize human systems as if they were computer systems, but it’s critical to understand the subtle human aspects of the system when evaluating improvements.</p>



<div><div>
<div><div>
<div><div>
<hr>



<h3>Learn something new? Let me know!</h3>



<p>Did you learn something from this post? I’d love to hear what it was — tweet me <a href="https://twitter.com/offlinemark">@offlinemark</a>! </p>



<p>I also have a mailing list if you want to know when I write new posts:</p>






<hr>
</div></div>
</div></div>
</div></div>
					</div></div>]]>
            </description>
            <link>https://offlinemark.com/2020/11/12/double-fetches-scheduling-algorithms-onion-rings/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25375637</guid>
            <pubDate>Thu, 10 Dec 2020 16:53:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I built a tool to visualise pathfinding algorithms (Desktop only)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25375391">thread link</a>) | @anthonyatp
<br/>
December 10, 2020 | https://anthonyatp.github.io/pathfinder-visualiser/ | <a href="https://web.archive.org/web/*/https://anthonyatp.github.io/pathfinder-visualiser/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://anthonyatp.github.io/pathfinder-visualiser/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25375391</guid>
            <pubDate>Thu, 10 Dec 2020 16:29:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New Relic to open-source Pixie’s eBPF observability platform]]>
            </title>
            <description>
<![CDATA[
Score 337 | Comments 63 (<a href="https://news.ycombinator.com/item?id=25375170">thread link</a>) | @htroisi
<br/>
December 10, 2020 | https://blog.pixielabs.ai/pixie-new-relic/ | <a href="https://web.archive.org/web/*/https://blog.pixielabs.ai/pixie-new-relic/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>We are excited to announce that we signed a <a href="http://blog.newrelic.com/product-news/pixie-developer-first-observability" target="_blank" rel="noopener noreferrer">definitive agreement</a> to join New Relic -- an outcome we certainly never predicted after only just two years.</p><p>New Relic’s focus on the developer is legendary. When New Relic's Founder/CEO, Lew Cirne, first started tinkering around with Pixie and participating in our community, we noticed an alignment in our visions for the future of observability, as well as echoes of New Relic’s developer-centric roots in Pixie. Joining New Relic will provide us with an unprecedented opportunity to reach millions of developers faster by open-sourcing a self-managed version of Pixie in the upcoming months.</p><p>When we started Pixie in 2018, Kubernetes was rapidly gaining traction. We felt that a new approach to observability was needed due to the new, fundamental challenges in observing distributed, ephemeral systems. We founded Pixie in order to provide instant, flexible observability for developers like ourselves who were building applications on Kubernetes.</p><p>However, we knew that the most developer-friendly version of Pixie must be open-source. In a forward-looking move, New Relic is giving us the opportunity to open-source Pixie and focus on providing world-class observability to all developers. The developer community is a core element of New Relic’s vision, and Pixie’s open-source offering will be a key part of that initiative and the primary area of focus for the Pixie team going forward.</p><p>We are so excited to begin working with New Relic on our shared vision for the future of observability. In the coming months, we’ll be jointly committing our roadmap in the following initiatives:</p><ul><li><p><strong>Pixie Core</strong>: An open-source and self-managed version of Pixie which we will release to the CNCF sandbox early next year. As part of the process, we look forward to speaking with you about this at Kubecon-EU on May’21. Due to Pixie’s and New Relic’s commitment to open standards, we also plan to build out integrations with OpenTelemetry, Prometheus, and Grafana.</p></li><li><p><strong>Pixie By New Relic</strong>: Our current Pixie Community offering will continue as a hosted version of Pixie Core and existing New Relic One customers will soon get instant access to Pixie data with a few clicks. Their existing experiences will be augmented with the metrics, logs, events, and application traces that Pixie automatically provides.</p></li><li><p><strong>Pixie by New Relic, Enterprise Edition</strong>: Industry-specific solutions for sectors such as Media, Telecommunications, and Government that allow enterprise customers to install Pixie entirely inside production clusters while meeting compliance, data security, support, and performance requirements.</p></li></ul><p>Finally, our journey is just beginning. We are a team of 12 people with a huge vision to reach every Kubernetes developer. As we embark on this part of our journey, we encourage anyone passionate about open source, Kubernetes, and observability to apply to join us <a href="https://pixielabs.ai/careers/" target="_blank" rel="noopener noreferrer">here</a>.</p><p>You can try out Pixie <a href="https://work.withpixie.ai/auth/signup?UTM=PXNR" target="_blank" rel="noopener noreferrer">here</a>, learn more about us <a href="https://pixielabs.ai/" target="_blank" rel="noopener noreferrer">here</a> and ping us anytime on our Pixienaut community slack.</p></div></div></div></div>]]>
            </description>
            <link>https://blog.pixielabs.ai/pixie-new-relic/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25375170</guid>
            <pubDate>Thu, 10 Dec 2020 16:08:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A guide to product analytics tools for startups]]>
            </title>
            <description>
<![CDATA[
Score 142 | Comments 27 (<a href="https://news.ycombinator.com/item?id=25375148">thread link</a>) | @Fission
<br/>
December 10, 2020 | https://satchel.com/web-analytics/ | <a href="https://web.archive.org/web/*/https://satchel.com/web-analytics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main_content"><div><div><p>Last Updated </p><!-- --><p>May 30, 2020</p></div><div><p>Reading Times:</p><p>Summary only: 1 minute</p></div></div><h2 id="introduction">Introduction</h2><p>Every YC batch, Michael Seibel gives a talk about building product. He'll ask: "<a href="https://youtu.be/C27RVio2rOs?t=1677">How many of you are using Google Analytics as your primary source of metrics?</a>" But it's a trick question. When the majority of the audience eventually raises their hands, he'll fake a sigh and tell everyone that they're doing it wrong, and that they should instead by relying on an event-based analytics tool.<span></span><span>The linked video is from Startup School, but the same talk is given at YC Core as well.</span></p><p>It's a perennial favorite, but don't let the humor distract you. Michael's got a
good point. Without using an event-based analytics tool, which tracks the interactions your users have with your product, you won't know <em>how</em> your
users are using your product. This is arguably just as important as actually
building out the product. There are a lot of event-based analytics tools out
there, but we think that if you're an early-stage startup, Heap makes the best tradeoffs.</p><div><p><a target="_blank" href="https://heap.io/"><img src="https://d33wubrfki0l68.cloudfront.net/b6fae69c970dbd3257184ea4d909f5d858810bdc/35c24/logos/heap.svg"></a></p><div><p>Our Recommendation</p><p><a target="_blank" href="https://heap.io/">Heap</a></p><p>Highest benefit-to-effort ratio</p><p>Gave us auto-tracking functionality, which we think is an exceptionally good safety net for an early-stage startup with rapidly-changing features and limited engineering resources, although it lacks some of the extensibility and more advanced analysis capabilities of its competitors. That said, we think this tradeoff best suits an early-stage startup.</p><p><a target="_blank" href="https://heap.io/">heap.io</a></p></div></div><summary><h2 id="summary">Summary</h2><ul><li>"Setting up event-based metrics is something that's super important very early in your company, because it's how you know whether your product is being used or not. And it's the number one source of new product ideas and inspiration." - Michael Seibel</li><li>Google Analytics by itself is insufficient to figure out how your users are using your product, although it is useful to complement an event-based analytics tool.</li><li>Event-based analytics help you figure out what actions a user took on your website.</li><li>We are primarily focused on evaluating the three main event-based analytics tools: Mixpanel, Amplitude, and Heap.</li><li>We found that event-based analytics is a category of SaaS with some of the most feature parity.</li><li>The core analytics functionality of all three tools is more or less equivalent.</li><li>The key considerations for an early-stage startup are the amount of maintenance and discipline required to maintain useful analytics, and the ability to go far without spending a lot of money.</li><li>We found that defining events in code while having auto-track as a safety net is a near-ideal setup for an early stage startup.</li><li>We recommend Heap, because it is the only major analytics tool that offers this capability. The main downside for an early-stage startup is that you can't get as far on a free plan on Heap compared to Mixpanel or Amplitude.</li><li>If pricing is the main consideration, then we recommend Amplitude. Even though its product is oriented towards later-stage companies, Amplitude has the most generous free plan of the major event-based analytics providers.</li></ul></summary><h2 id="ratings-matrix">Ratings Matrix</h2><h2 id="context">Context</h2><h3 id="what-is-event-based-analytics">What is event-based analytics?</h3><p>Pageview-based analytics tools like Google Analytics and event-based analytics tools such as Mixpanel, Amplitude, and Heap are typically grouped together under the heading of analytics tools. However, we think that lumping them all under the same heading is misleading, because they fundamentally do different things. To better understand what event-based analytics are, we need to understand what exactly Google Analytics does, figure out where its gaps are, and then use that context to motivate event-based analytics tools. </p><p>Google Analytics uses a pageview-driven paradigm, a holdover from what was important in the early 2000s. Its focus on pageviews helps answer questions such as how many users came to your website, what pages they visited, and how they found your website. Unfortunately, it isn't able to help you figure out which specific actions a user performed on any given page of your website. For example, it doesn't answer whether a user clicked on a CTA button, if they abandoned their cart, how far they got into signing up, or what part of the page they were looking at before they converted. Answering these kinds of questions can be quite informative to early-stage startups' decision-making, and can be accomplished quite easily by using an event-based analytics tool.</p><p>An event-based tool will provide two things: an interface to collect "events", and an interface to analyze those events. You can define and implement your events (commonly referred to as instrumenting) by calling the API of the event-based analytics tool you're using.</p><p>To illustrate, let's say you run an ecommerce store. You want to figure out what types of items people checkout without hesitation, and what types of items often result in abandoned carts. This isn't something that can be accomplished with pageview-based analytics tools such as Google Analytics. However, this can be performed quite easily with an event-based analytics tool. If you track two events — when someone adds something to their cart, and when someone checks out their cart — you can figure out which SKUs lead to a high checkout rate, and which SKUs lead to abandoned carts. This is implemented by calling two functions: </p><ol><li><p>a function <code>track('add-to-cart', {&lt;metadata&gt;})</code>, including metadata about the item added (e.g. SKU, name, price) in your code that executes when someone adds something to cart, and </p></li><li><p>a similar function <code>track('checkout', {&lt;metadata&gt;})</code> in your code that runs when someone checkouts. Data from these events will be sent to your analytics provider, which will provide an interface to analyze and draw conclusions from your data.</p></li></ol><p>This is a simple example, but is already quite a powerful tool to understand your users, and can be easily extended. The same power generalizes beyond an ecommerce store to any startup's web product, helping one answer essential questions such as: Is your CTA convincing? What are the characteristics of products that customers are the most hesitant about buying? What part of the signup process needs to be improved to prevent potential users from dropping off? Which portion of your product page was the most engaging and persuaded customers to take the next step?</p><h3 id="early-stage-startups-and-their-analytics-dilemma">Early-stage startups and their analytics dilemma</h3><p>If event-based analytics are so important for early-stage startups, one might rightly wonder why so many YC startups, whose founders are quite sharp in aggregate, rely primarily on Google Analytics?</p><p>It turns out that this is a rather illuminating question. The main contributor to this phenomenon is easy to understand and empathize with. Startups are busy and overworked, and analytics are often ostensibly seen as orthogonal to the priorities of understanding their users and building product<span></span><span>The <a href="https://blog.ycombinator.com/ycs-essential-startup-advice/">canonical priorities</a> for early-stage startups.</span>. Therefore, event-based analytics often fall to the wayside as they typically require engineering time and discipline to maintain. If you forget to update an event, or don't have time to implement analytics for a new feature, then you can't get any benefit out of it at all.</p><p>Yet, in reality, event-based analytics are one of the best sources of new product insights and inspiration and are a fantastic way to understand how your users are using your product. This is one of our main motivations for writing this particular guide. Early-stage startups have a unique set of challenges to face, particularly around prioritizing their time and engineering resources. That said, we think that there's an approach that can make event-based analytics require a lot less discipline, and therefore make it a lot more attainable for an early-stage startup.</p><h2 id="methodology">Methodology</h2><p>Based on a few years of first-hand experience using and testing event-based analytics tools, in addition to aggregating feedback from other founders, we have found the following factors matter most for early-stage startups choosing an analytics tool:</p><ul><li><p><strong>Core Analytics Functionality</strong> refers to the standard analytics features that are critical for an early-stage startup to understand their users. These include standard analysis tools, such as funnel analysis (i.e. figuring out when users drop out in each step of a process), retention analysis (i.e. figuring out how many users churn, and when), and cohort analysis (i.e. figuring out how different user segments interact with your product). </p></li><li><p><strong>Robustness / Ease of Maintenance:</strong> Early-stage startups need to use analytics just as much as larger companies, but also have to be a lot more resourceful and focused with their time and energy. What happens if you change a component, and don't update the tracking code? What happens if you're under time pressure from a customer and make the conscious decision to launch a complex product without tracking? While large companies have the ability to implement strict QA processes and are okay with extended deadlines, early-stage startups don't have these options. Therefore, we've kept a close eye out for how each analytics tool performs under less-than-ideal situations.</p></li><li><p><strong>Affordability:</strong> Web analytics tools are somewhat notable/notorious for giving generous free plans, attaining lock-in, and then making things more expensive once your company starts becoming successful <span></span><span>This is one of the reasons why <a href="#consider-using-segment-as-a-wrapper">we suggest using Segment</a>, since it helps you avoid vendor lock-in and gives you more negotiating power.</span>. That said, several analytics tools have generous free tiers or deals that can last you quite a long time without paying. Therefore, we've split this criterion into two subcriteria: <strong>How far you can get without paying</strong>, and <strong>Paid Plan Affordability</strong>. The latter is actually somewhat non-trivial to evaluate, because most analytics providers hide their pricing behind a Contact Us gate, even for early-stage startups. That said, we got our hands on a decent amount of data on the actual cost of each service, and we have also compiled a list of typical discounts and deals that you can reasonably expect to get from each analytics provider.</p></li><li><p><strong>Ease…</strong></p></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://satchel.com/web-analytics/">https://satchel.com/web-analytics/</a></em></p>]]>
            </description>
            <link>https://satchel.com/web-analytics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25375148</guid>
            <pubDate>Thu, 10 Dec 2020 16:06:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A typical day as an engineering manager]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25375100">thread link</a>) | @karlhughes
<br/>
December 10, 2020 | https://www.karllhughes.com/posts/engineering-manager | <a href="https://web.archive.org/web/*/https://www.karllhughes.com/posts/engineering-manager">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
<article>
<div>
<p><img src="https://www.karllhughes.com/assets/img/engineering-manager-time.png" alt="A Day in the Life of an Engineering Manager">
</p> 

<p>
2020, Nov 01&nbsp;&nbsp;&nbsp;—&nbsp;
7 minute read
</p>
<section id="mc_embed_signup">

</section>
<p>During the eight years I spent as an engineering manager, I regularly tracked how I spent my time. As a startup engineering manager, I was responsible for a wide range of duties, so keeping track of which areas I spent the most time on helped me plan and schedule appropriately.</p>
<p>For example, I knew that I typically spent about 1/3rd of my time helping my team solve technical problems or pairing with teammates. Knowing this, I reserved some free blocks of time for them. If my whole week were full of meetings and big-picture planning, I’d become a blocker for my team who needed my input on specific issues.</p>
<p>Since many prospective software engineering managers ask me about my job and what it entails, I decided to create this detailed look at how I spent my time. While every company and role is different, I hope this post gives you some first-hand insight into a day in the life of an engineering manager.</p>
<p><em>Note: If you’re looking for some books to help you on your journey as a software engineering manager, <a href="https://www.karllhughes.com/posts/reading-for-engineering-managers">here are some of my favorites</a>.</em></p>
<h2 id="what-does-an-engineering-manager-do">What Does an Engineering Manager Do?</h2>
<p>First, a little bit about my roles as an engineering manager: my first management role was at <a href="https://www.packback.co/">Packback</a>, a question and answer platform for college professors.</p>
<p>I joined the team when there were just four people in the company - it was essentially myself and the founders. In the intervening three years, I saw the company raise close to $5 million and grow to almost 30 people. My engineering team was pretty lean - there were five when I left in 2016 - but my role changed quite a bit over my years with the company.</p>
<p>After <a href="https://www.karllhughes.com/posts/joining-the-graide-network">I left Packback to join The Graide Network</a>, I started over as an engineering manager. Initially, my team was just a contractor and me, but over my four years at Graide, I <a href="https://www.karllhughes.com/posts/hiring-process">hired three other engineers</a> and <a href="https://www.karllhughes.com/posts/product-management-process">took on more of the product management duties</a>.</p>
<p>While my day-to-day work changed a lot over the years, <strong>as a software engineering manager, I was ultimately responsible for helping my team ship software that worked as expected on schedule and within budget.</strong></p>
<p>The tricky word there is “helping.” What does that mean exactly? Does it mean that an engineering manager writes code? Or do they just make sure everyone on their team is writing code?</p>
<p>The short answer is: it depends.</p>
<h3 id="engineering-managers-must-be-technical">Engineering Managers Must be Technical</h3>
<p>Generally, engineering managers write less code than the senior developers on their team, but <a href="https://medium.com/swlh/do-engineering-managers-need-to-write-code-d89903d68e8d">they should write some code to keep their skills sharp</a>. They also need to be good at helping their team members get “unstuck.” Sometimes this means answering technical questions, and sometimes it means solving disputes between team members.</p>
<p>They’re likely to play a role in <a href="https://www.karllhughes.com/posts/developing-talent">training new engineers</a> as well as evaluating candidates on a technical and interpersonal basis.</p>
<h3 id="engineering-managers-have-to-be-good-with-people">Engineering Managers Have to be Good with People</h3>
<p>Being “good with people” is a tough label to nail down.</p>
<p><img src="https://i.imgur.com/e7ML5PR.gif" alt="I have people skills! - Office Space"></p>
<p>Many people assume that you have to be an extrovert to be an effective manager, <a href="https://www.inc.com/john-brandon/are-extroverts-the-best-leaders-maybe-not.html">but that’s not necessarily true</a>. Having empathy for your team and helping them through challenges - both technical and personal - is one of an engineering manager’s primary mandates.</p>
<p>But, engineering managers have to “manage up” as well. This means they need to look out for their team’s best interests when their boss asks them for feedback, and it means they might have to let a team member go if they’re not getting the job done.</p>
<h3 id="the-hardest-part-about-engineering-management">The Hardest Part About Engineering Management</h3>
<p>As I moved into my first management role, the most challenging part was adjusting my method for self-evaluation. Nickolas Means says it well in his <a href="https://leaddev.com/self-care-burnout/learning-love-meta-productivity">fantastic piece on meta productivity for managers</a>:</p>
<blockquote>
<p>“Every so often, I have a day where I look up after the last meeting has ended and feel like I’ve gotten absolutely nothing done. I’ve been busy all day long: having conversations, reading documents, and checking in with peers and team members. I’m exhausted, but I’ve accomplished nothing.” - Nickolas Means</p>
</blockquote>
<p>It was <em>relatively</em> easy for me to tell how productive I had been as a software engineer. I usually made progress on shipping a feature or opened up a pull request, but as a manager, I had a really hard time telling whether my day was productive or not.</p>
<p>That’s why I started tracking my time. While time spent on a task is not a perfect measurement of productivity, it helped me make sure I was investing enough time into each area of my job.</p>
<h2 id="how-does-an-engineering-manager-spend-their-time">How Does an Engineering Manager Spend Their Time?</h2>
<p>Engineering managers tend to have a wide range of responsibilities, and these responsibilities vary based on the employer’s size and organizational structure. To help you see how an engineering manager spends their time, I broke my time down into four categories:</p>
<ul>
<li><strong>Technical</strong> (35%)</li>
<li><strong>Managerial</strong> (35%)</li>
<li><strong>Recruiting</strong> (15%)</li>
<li><strong>Administrative</strong> (15%)</li>
</ul>
<p>In this section, you’ll see how I spent my time as an engineering manager. I’ll offer a little bit about the specific tasks encompassed in each area and why it was an important part of my daily work.</p>
<p>While I tracked my time pretty rigidly for periods of my 8-year management career, I decided to round each category to a nice round number for the sake of simplicity. Exact hours spent on each task aren’t the point here, but I found it helpful to know if one area spiked in one week or dropped sharply in another.</p>
<p><img src="https://i.imgur.com/Tx9pTaz.png" alt="engineering-manager-time"></p>
<h3 id="technical">Technical</h3>
<p><em>35% of my time.</em></p>
<p>Technical work includes writing code, code reviews, hunting down bugs, pairing with teammates, and reading software updates and best practices. As my teams grew, the amount of time I devoted to writing and reviewing code dwindled, but I do think it’s important for engineering managers to spend at least <a href="http://www.drdobbs.com/architecture-and-design/engineering-managers-should-code-30-of-t/240165174">some of their time elbows deep in the code</a>.</p>
<h3 id="managerial">Managerial</h3>
<p><em>35% of my time.</em></p>
<p>This includes direct people management, creating timelines, strategic planning, and meetings with technical and non-technical team members. Making sure my team was happy, advocating for them in business meetings, and helping our product team create technical specs were all part of my engineering manager duties at Packback.</p>
<p>At The Graide Network, I took a more strategic role by consulting with the founders on software choices and jumping in on important sales calls. Interestingly, while the tasks I took on were different, the time breakdown was pretty similar.</p>
<h3 id="recruiting">Recruiting</h3>
<p><em>15% of my time.</em></p>
<p>Recruiting time included going to conferences, meetups, and coding bootcamps, writing blog posts, meeting with job candidates, and evaluating technical screenings.</p>
<p>While I spent more of my time on recruiting when I had an open engineering job, smart engineering managers are <em>always</em> hiring. The best candidates are usually the passive ones who rarely look for a job, so I spent a portion of my time getting in front of them each week.</p>
<h3 id="administrative">Administrative</h3>
<p><em>15% of my time.</em></p>
<p>Finally, I spent a few hours per week reading and writing emails, answering questions in Slack, random conversations, and “other” day-to-day things to support my team. As the manager, I tried to keep these kinds of distractions away from my engineering team, but I’d schedule time with team members when necessary.</p>
<p>If an engineering manager’s job is to make their team as productive as possible, it stands to reason that most of the administrative work will fall to them.</p>
<h2 id="what-makes-a-good-engineering-manager">What Makes a Good Engineering Manager?</h2>
<p>I don’t think I can give you <em>everything</em> you need to know about being a good engineering manager in just one blog post (<a href="https://www.karllhughes.com/posts/reading-for-engineering-managers">here are some good books on the topic though</a>), so I’ll just pick the three things that I focus on first.</p>
<h3 id="1-empower-your-team">1. Empower Your Team</h3>
<p>Being a good manager is all about <a href="http://www.jrothman.com/articles/1999/01/successful-engineering-management-7-lessons-learned/">helping others achieve great things</a>.</p>
<p>This means that as a manager, your <a href="https://leaddev.com/self-care-burnout/learning-love-meta-productivity">impact is much less direct</a>, and therefore, you can’t spend all your time heads down in the code. It was frustrating for me to see my weekly accomplishments list shrink, but once I learned to accept that my team was getting more done without my individual contributions, I started to really enjoy the role.</p>
<h3 id="2-overcommunicate">2. Overcommunicate</h3>
<p>Whether your team is working in one room or working <a href="https://www.karllhughes.com/posts/managing-remote-engineering">remotely across the world</a>, communication is one of your most crucial roles as a manager. In marketing, there’s an idea that <a href="https://www.linkedin.com/pulse/its-nagging-repetition-effective-communication-marton-jojarth/">people must hear your message seven times before they internalize it</a>, and I think this applies to team communication as well.</p>
<p>I’m not saying you should repeat everything seven times in the same meeting, but think about reiterating significant changes in one-on-ones, group settings, via email, and in passing. Change is scary, but the more people hear about something, the less scary it tends to be.</p>
<h3 id="3-be-the-source-of-calm">3. Be the Source of Calm</h3>
<p>Finally, as the engineering manager, your role is to “<a href="https://staysaasy.com/management/2020/07/07/dont-create-chaos.html">vacuum up chaos</a>:”</p>
<blockquote>
<p>“Any room that you enter should have more certainty and a firmer plan by the time that you leave it. Good leaders can walk into a situation where people have lost track of their goals and get everyone aligned on a clear path forward.”</p>
</blockquote>
<p>Don’t create or perpetuate drama, divide your team from the rest of the company, or pit team members against each other. Instead, be the one who absorbs uncertainty and stress so your team can get sh** done.</p>
<hr>
<p>If you’re an aspiring engineering manager or you’re just wondering what your boss does all day, I hope this helps you.</p>
<p>Interested in more great reading material? Here are some of the <a href="https://www.karllhughes.com/posts/reading-for-engineering-managers">books that helped me on my journey to become an engineering manager</a>.</p>

<section id="mc_embed_signup">

</section>
</div> 
</article> 
</section></div>]]>
            </description>
            <link>https://www.karllhughes.com/posts/engineering-manager</link>
            <guid isPermaLink="false">hacker-news-small-sites-25375100</guid>
            <pubDate>Thu, 10 Dec 2020 16:01:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Get Justice Against a Cable Company: Step-by-Step]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25375034">thread link</a>) | @KaiserSanchez
<br/>
December 10, 2020 | https://fairshake.com/consumer-guides/file-a-complaint-against-cable-company/ | <a href="https://web.archive.org/web/*/https://fairshake.com/consumer-guides/file-a-complaint-against-cable-company/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
        <div>
            <section>
                <div>
                    <p><span><img src="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/00-Header-300x171.jpg" alt="" width="500" height="286" srcset="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/00-Header-300x171.jpg 300w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/00-Header-1024x585.jpg 1024w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/00-Header-768x439.jpg 768w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/00-Header-1536x877.jpg 1536w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/00-Header.jpg 2022w" sizes="(max-width: 500px) 100vw, 500px" data-srcset="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/00-Header-300x171.jpg 300w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/00-Header-1024x585.jpg 1024w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/00-Header-768x439.jpg 768w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/00-Header-1536x877.jpg 1536w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/00-Header.jpg 2022w" data-src="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/00-Header-300x171.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">How many times have you heard someone in your life </span><a href="https://fairshake.com/consumer-news/comcast-customer-service-complaint/"><span>complaining about their cable company</span></a><span>?</span></p>
<p><span>Even worse, how many times have </span><i><span>you</span></i><span> been the one complaining about a cable provider?</span></p>
<p><span>Complaints about cable companies might sound like cliches. But cable providers aren’t like the DMV or the post office —&nbsp;services that draw a lot of consumer ire but ultimately tend to be doing their best to get their jobs done. On the contrary, cable companies have actually been </span><a href="https://fairshake.com/consumer-news/comcast-biggest-scams-claim-cash/"><span>caught engaging in a lot of shady behaviors</span></a><span> that fully justify their customers’ complaints.</span></p>
<p><span>But what if you want to take your dispute with your cable company further than your watercooler chat? What do you do if you have a legitimate complaint about your cable company that you need resolved? Where do you go if you need help getting justice against a cable company that’s gone beyond just providing an unpleasant customer service experience —&nbsp;but has actually wronged you?</span></p>
<p><span>These are questions that a lot of consumers have, and we’re here to help. In this article, we’ll discuss some of the common reasons people might want to seek justice against their cable companies. Then, we’ll explain, step-by-step, how to file a complaint against a cable company, and point you toward some resources that will be on your side if you need help getting justice.&nbsp;</span></p>
<h2><span>Why Do So Many People Have Complaints About Their Cable Companies?</span></h2>
<p><span>Let’s start at the beginning: Why do so many people complain about cable companies? And, more importantly, are people complaining about just annoyances, or actual injustices?</span></p>
<p><span>The American Consumer Satisfaction Index </span><a href="https://www.theacsi.org/index.php?option=com_content&amp;view=article&amp;id=148&amp;Itemid=213"><span>surveys consumers</span></a><span> and scores industries based on how well they provide satisfactory services at fair prices. Consistently, year after year, the cable TV industry ranks lowest out of the dozens of industries the ACSI tracks.</span></p>
<p><img src="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/01-Image.jpg" alt="Graph of American Consumer Satisfaction Index Scores for the Cable TV Industry" width="2022" height="1825" srcset="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/01-Image.jpg 2022w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/01-Image-300x271.jpg 300w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/01-Image-1024x924.jpg 1024w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/01-Image-768x693.jpg 768w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/01-Image-1536x1386.jpg 1536w" sizes="(max-width: 2022px) 100vw, 2022px" data-srcset="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/01-Image.jpg 2022w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/01-Image-300x271.jpg 300w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/01-Image-1024x924.jpg 1024w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/01-Image-768x693.jpg 768w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/01-Image-1536x1386.jpg 1536w" data-src="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/01-Image.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p>
<p><span>In 2020, the cable industry has scored </span><a href="https://www.theacsi.org/index.php?option=com_content&amp;view=article&amp;id=149&amp;catid=&amp;Itemid=212&amp;i=Subscription+Television+Service"><span>64 out of 100 points on the ACSI index</span></a><span>, which is actually a 3.2 percent increase over last year. But the industry still has the lowest score in the ACSI rankings, reflecting more dissatisfied customers than ISPs, cell phone providers, online news media, and many other industries that consumers love to complain about. Additionally, this year is the first time since 2016 that the cable industry saw an increase in its ACSI ranking.</span></p>
<p><span>ACSI rankings aren’t even the worst evidence against the cable industry, though.</span></p>
<p><span>News reports reveal that some of what cable companies have been up to goes beyond just bad customer service. For example,</span></p>
<ul>
<li><span>Some AT&amp;T customers found they were </span><a href="https://fairshake.com/consumer-news/att-overcharging-customers-complaints"><span>being charged three times the rate</span></a><span> the company promised them. The situation was so bad, one legal expert called AT&amp;T’s policies “a license to steal.”</span></li>
<li><span>Comcast </span><a href="https://fairshake.com/consumer-news/comcast-biggest-scams-claim-cash"><span>wrongly charged a small business owner $1,800 in cancelation fees</span></a><span>, and then spent </span><i><span>two years</span></i><span> fighting against returning that wronged customer’s money.</span></li>
<li><span>Cox employees were found to be </span><a href="https://wjla.com/features/7-on-your-side/cox-communications-complaints-fake-accounts"><span>creating customer accounts without permission</span></a><span> so they could charge users more.</span></li>
<li><span>Optimum got caught advertising a $99 promotion rate, but </span><a href="https://www.thehour.com/business/article/After-profitable-2017-Altice-USA-hikes-Optimum-12885236.php"><span>actually billed users more than $160 for it</span></a><span>.</span></li>
<li><span>DirecTV </span><a href="https://fairshake.com/consumer-news/feds-sue-direct-tv-claim-money"><span>broke its contracts with 33 million customers</span></a><span> by wrongly raising their rates.</span></li>
</ul>
<p><span>These are just some examples of how cable companies have done shady (or even outright illegal) things to their customers. In all these cases (and any others like them), the customers deserve justice. But it can be difficult to figure out how to get it.</span></p>
<h2><span>How to File a Complaint Against a Cable Company</span></h2>
<p><span>The exact process for filing a complaint might vary from one cable company to the next. For more detailed advice about taking on a specific company, visit our consumer guides.</span></p>
<p><span>But no matter what cable company your dispute is with, there are certain steps you can take to file and escalate your complaint. Here’s what you need to know.</span></p>
<h3><span>Step 1: Contact the Cable Company</span></h3>
<p><span>For anyone who’s suffered through an unproductive customer service call, this probably won’t be welcome news. But any time you have a complaint against a company, before taking it to any outside agencies, you need to try to resolve it with the company itself. This is important, because if you end up escalating your complaint to the FTC, FCC, or a local franchising authority, they’ll expect that you’ve already tried to resolve your dispute with the company directly.</span></p>
<p><span>Some best practices to keep in mind here: Try to address the complaint with your cable company in writing, whenever possible. Email is a great option for this. This ensures that you have a record of exactly what’s said by both parties, and you have proof that you attempted to resolve the complaint directly with the cable company, as well as proof of why that didn’t work.</span></p>
<p><span>If you’ve tried this and your cable company was unable or unwilling to help you reach a resolution, it’s time for step two.</span></p>
<h3><span>Step 2: Find the Right Regulatory Agency</span></h3>
<p><span>If your cable company is unable or unwilling to help you, you can escalate your complaint to a regulatory agency. However, finding the right one can be a challenge.</span></p>
<p><span>Cable companies are overseen by a number of entities: The Federal Communications Commission, the Federal Trade Commission, public utility commissions, and local franchising authorities are the ones that are likely to be most relevant to any dispute you might have. Here’s where this gets complicated: Each of them has different jurisdiction and can only help with certain issues.</span></p>
<p><span>Here’s who you should contact, depending on your complaint.</span></p>
<p><img src="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/02-Image-scaled.jpg" alt="Where to File a Complaint against Your Cable Company" width="1881" height="2560" srcset="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/02-Image-scaled.jpg 1881w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/02-Image-220x300.jpg 220w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/02-Image-752x1024.jpg 752w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/02-Image-768x1045.jpg 768w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/02-Image-1129x1536.jpg 1129w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/02-Image-1505x2048.jpg 1505w" sizes="(max-width: 1881px) 100vw, 1881px" data-srcset="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/02-Image-scaled.jpg 1881w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/02-Image-220x300.jpg 220w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/02-Image-752x1024.jpg 752w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/02-Image-768x1045.jpg 768w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/02-Image-1129x1536.jpg 1129w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/02-Image-1505x2048.jpg 1505w" data-src="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/02-Image-scaled.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p>
<h4><span>Local Franchising Authorities</span></h4>
<p><span>Local franchising authorities are government organizations that regulate cable TV service at a municipal, county, or other local level. You can usually find the name of your local franchising authority on your cable bill. If not, you can contact your cable company or your local town or city hall to request that information.</span></p>
<p><span>Local franchising authorities can help you with these issues:</span></p>
<ul>
<li><span>Rates for basic service and equipment, and service charges related to basic cable.</span></li>
<li><span>Rates for cable service tiers, particularly if rates for your cable service have been increased within the past 90 days.</span></li>
<li><span>Customer service problems, like availability of customer service representatives, office hours, timeliness of service visits, and outages.</span></li>
<li><span>Franchise fees.</span></li>
<li><span>Signal quality.</span></li>
<li><span>Use of public or informational channels that are required as part of your cable company’s franchise agreement.</span></li>
</ul>
<h4><span>Public Utility Commissions</span></h4>
<p><span>In some states, public utility commissions oversee certain issues related to cable or satellite TV services.</span></p>
<p><span>To find out more about your state’s public utility commission, check the </span><a href="https://www.naruc.org/about-naruc/regulatory-commissions/"><span>National Association of Regulatory Utility Commissioners</span></a><span>. If your state has one, PUCs can help you with these issues:</span></p>
<ul>
<li><span>Rates and programming for stand-alone satellite TV services.</span></li>
<li><span>Rates and programming for stand-alone cable TV services (not including basic tier plans).</span></li>
<li><span>Installation of cable or satellite TV services that are not bundled with other services.</span></li>
<li><span>Burial of phone or cable TV wires.</span></li>
</ul>
<h4><span>Federal Communications Commission</span></h4>
<p><span>The FCC is a department of the federal government that exists to regulate businesses and prevent them from taking advantage of or unfairly treating consumers.</span></p>
<p><span>There are a number of ways you can contact the FCC if you have a complaint about a cable company that falls under its jurisdiction. You can visit the </span><a href="https://consumercomplaints.fcc.gov/hc/en-us"><span>FCC Complaint Center</span></a><span> to file your complaint online or get the right information to mail it, or you can call 1-888-225-5322 for information and general questions.&nbsp;</span></p>
<p><span>The FCC can help with these kinds of complaints:</span></p>
<ul>
<li><span>Equal Opportunity Employment complaints.</span></li>
<li><span>Signal leakage that might affect other spectrum users.</span></li>
<li><span>Cable companies that violate rules about home cable wiring.</span></li>
<li><span>Cable companies that violate commercial limits during kids’ programming.</span></li>
<li><span>Indecency or obscenity on a cable TV program.</span></li>
</ul>
<h4><span>Federal Trade Commission</span></h4>
<p><span>And finally, the right entity to receive your complaint might be the FTC, which is another department of the federal government. It has similar goals to the FCC, but oversees different things.&nbsp;</span></p>
<p><span>Also similarly to the FCC, you have a few options for contacting the FTC about your complaint. You can use an </span><a href="https://www.ftccomplaintassistant.gov/"><span>online complaint portal</span></a><span>, or you can reach the agency by phone at 1-877-FTC-HELP.&nbsp;</span></p>
<p><span>Here are some of the types of complaints that would fall under the jurisdiction of the FTC:</span></p>
<ul>
<li><a href="https://fairshake.com/consumer-guides/false-advertising-and-misleading-marketing/"><span>False advertising</span></a><span>.</span></li>
<li><span>Deceptive business practices.</span></li>
<li><span>Scams.</span></li>
<li><span>Problems with debt collection.</span></li>
</ul>
<h2><span>What to Expect After Filing a Complaint Against a Cable Company</span></h2>
<p><span>After filing a complaint with any of the entities listed above, you might be wondering what comes next. The answer, unfortunately, is that it depends.</span></p>
<p><span>Regulatory agencies, particularly at the federal level, will typically investigate a company if they receive complaints about it. If they find that the company did, in fact, do something wrong, they may impose fines or other punishments. But typically, a federal agency like the FTC or the FCC </span><a href="https://fairshake.com/consumer-guides/getting-your-refund/"><span>won’t help you get a refund</span></a><span>, get charges reversed, or get justice in any other, similar way. For that, you have other resources.</span></p>
<h2><span>How to Get Justice Against a Cable Company</span></h2>
<p><span>If resolving your dispute means getting a refund, a zero balance, other compensation, or some other form of justice, you might feel like you have a long, uphill road to climb.</span></p>
<p><span>Most cable companies have clauses built into their contracts that say you can’t sue them, unless it’s in small claims court. But what you can do is </span><a href="https://fairshake.com/how-it-works/"><span>take advantage of consumer arbitration</span></a><span>.</span></p>
<p><span>Arbitration works a little bit like small claims: You’ll send a legal demand to your cable company, and then collect any evidence you have and present it to an independent third party, or arbitrator. The arbitrator will hear both sides of the dispute and make a legally binding decision.</span></p>
<p><span>But even that might sound overwhelming. And if you’ve never been through the process of arbitration before, we don’t blame you if you feel intimidated by the paperwork, the process, or just the thought of taking on a big company with major legal resources.</span></p>
<p><span>So let us help. </span><a href="https://fairshake.com/"><span>Fai…</span></a></p></div></section></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://fairshake.com/consumer-guides/file-a-complaint-against-cable-company/">https://fairshake.com/consumer-guides/file-a-complaint-against-cable-company/</a></em></p>]]>
            </description>
            <link>https://fairshake.com/consumer-guides/file-a-complaint-against-cable-company/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25375034</guid>
            <pubDate>Thu, 10 Dec 2020 15:56:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Problem with Corporate Innovation]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25375013">thread link</a>) | @nicotesla
<br/>
December 10, 2020 | https://blog.codelitt.com/corporate-innovation/ | <a href="https://web.archive.org/web/*/https://blog.codelitt.com/corporate-innovation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <article>
      

      
      <section id="Post__Main-Content">
        <div>
          <h2 id="discovering-the-problem">Discovering the Problem</h2><p>Startups are swallowing corporations' markets. This is mainly because corporations struggle with innovation, regardless of how much they use that word in press releases and PPT presentations. About 7 years ago we started <a href="http://www.codelitt.com/">Codelitt</a>, a corporate skunkworks and product incubator company. We build startups for corporations and invest 20% of our time in building products, tools, and <a href="https://github.com/codelittinc">open source projects</a> for the web. </p><p>In the beginning, we didn't set out to discover a specific problem. Put another way, we weren't being purposeful about searching for a problem to solve. This post is half about the problem with corporate innovation and half about our discovery process that led us to where we are today:</p><h2 id="eye-opening">Eye-opening</h2><p>In the beginning of my career I worked for investors in Latin America helping to build and launch startups before later moving to corporate America. Although I'm often critical of corporate culture, it was really eye opening and integral to my career. Really this is one of the best pieces of advice I can give to entrepreneurs looking for problems to solve:</p><blockquote>If you are smart and ambitious but can't find a problem to solve, go work for a large (preferably traditional) corporation. You'll find plenty there.</blockquote><p>Large enterprises succeed <em>in spite</em> of themselves. It really is a wonder that they get anything done at all. I can't speak for every single large company, but I've worked with quite a few. In one way or another they all have systemic issues. This is not to say that startups or more modern tech companies don't have their own issues. We do. But the proof is in the pudding and startups are launching products monthly that will take a huge chunk of traditional companies' markets or even render them completely irrelevant.</p><p>Some large enterprises have realized that their biggest threat isn't another corporate giant, it's some unknown kid building something. In order to compete, they have to create new value, do a little disruption of their own, and start shipping.</p><blockquote>However, traditional companies spend millions in R&amp;D and take several years to come to market.</blockquote><p>So the question is, why are they at such a disadvantage when their seemingly endless budgets should afford them a solid advantage? The answer is that the same tools, systems, and culture that they rely on to manage their large organization don't work for innovation and skunkworks teams.</p><h2 id="decisions-by-consensus">Decisions by Consensus</h2><p>Traditionally the vast majority make decisions by consensus. Note: there is a difference between collaboration and consensus. Collaboration takes different points into account but can still have one decision maker, whereas consensus decision making requires every single person to have input and be onboard. This is crippling to organizations. Teams should have a single decision maker.</p><p>Any startup who has experienced the sales cycle of a large company can attest to this first hand. While many sales people focus on identifying "the decision maker level," this person is rarely the only decision maker and they'll likely have an entire team to convince. When making a sales pitch (even for a $1,000 a month SaaS product) you'll very likely spend time in a room of 12 or so people from different areas of the company. Most of those people will likely have different needs and agendas. The same is true when it comes to developing new products, processes, or strategy. Decision making time is multiplied by an exponential factor.</p><blockquote>In the time it takes a large organization to make a decision just to move forward with something, a startup could have built, launched, and validated a new feature or model.</blockquote><h2 id="corporate-it">Corporate IT</h2><p>There are a number of reasons why normal innovation processes, product prototyping, and building new business models is so costly inside a large organization. Time is a huge factor. A close second is the cost of actual development. As with everything, I'm sure there are reasons for why things are done the way they are done. But from a product development perspective and coming from the startup world, they are nearly impossible to understand.</p><p>Corporate IT departments have a hard time looking at a product as something that develops. They see a project as having a start date, an end date, and a full set of features. There is no iterative development. They plan for every possible scenario and build to the full spec. Version releases begin with 1.0.0 launch and following releases are security patches at best.</p><p>Instead of using open source tools, large IT teams are locked in to Microsoft and Oracle products. I've never been able to understand why this is completely. It could be the fact that they spend a solid chunk of time earning Oracle or Microsoft Certifications. It could be the comfort of having support just a phone call away. Or it could even be an unwillingness to learn something new. </p><p>From a security perspective, it's like looking for a babysitter to watch your kids, asking for her recommendations, and she tells you, "Just trust me. I promise your child is secure. But just so you know, we'll be doing things my way; your house rules don't apply."</p><p>From a time perspective, there are open source technologies that allow you to whip up an MVP in much less time. Even with complaints about Rail's "magic under the hood," you can't deny that it's a powerful tool to quickly build a prototype.</p><p>From a cost perspective, licenses are expensive and they add up quickly. Millions of dollars are spent on IT licensing every year by large orgs. Imagine if that money was spent on employing core devs for the respective clients like we've seen with Red Hat, Bitpay, and Google.</p><blockquote>Developing a new product or business can often cost millions to develop with the traditional IT infrastructure and business processes. Timelines, again, are measured in years, not weeks.</blockquote><h2 id="risk-averse">Risk-averse</h2><p>The final piece to the puzzle which impedes progress and innovation is often a risk-averse nature. Being risk-averse is 'consultant speak' inside a large organization. Entire teams are dedicated to mitigating risk. I've heard a lot of different theories for why this is from insiders and outsiders over the years:</p><p><strong>Job security</strong> is one that gets floated around a lot. The 25 year Rolex, the benefits, and the cushy salary really don't require a whole lot. Don't upset the status quo, don't argue with the wrong people, play the politics, and work well with others. Do those 4 things and you have very little to worry about. Large companies rarely fire people who do those things. It's easy for anyone to become complacent when basic needs are taken care of. Unfortunately for them however, disruption requires risk. There's always the risk of being wrong. Being wrong is rarely celebrated in corporate culture and that stigma can follow someone around for the rest of their career preventing any sort of upward mobility. In our world, many of us have failed a few times, succeeded a couple, and worked for several companies. Our entire attitude towards failure and opportunity is a completely different perspective.</p><p>Another is the <strong>high visibility</strong> that corporations have in the public eye. Because of their size, most things they do are considered <a href="http://www.mediacollege.com/journalism/news/newsworthy.html">newsworthy</a> due to the impact it could have on their customers, employees, or investors. In the startup world, we have the luxury of being able to fail relatively quietly. Our customers and beta users are usually very understanding of certain degrees of failures to the point they even expect them. Remember those corporate departments dedicated to risk management? These often include legal, public relations, and marketing communications teams. They all have the responsibility to keep the public face of the company as free from blemishes as possible.</p><blockquote>Disruption requires risk. No great invention, change, or innovation ever came from doing the same thing over and over. <a href="https://blog.codelitt.com/not-innovating/">You have to be ready to break things along the way</a>.</blockquote><h2 id="their-disadvantage">Their Disadvantage</h2><p>When you begin to understand the issues that are faced by teams tasked with innovation projects, skunkworks programs, or disrupting old models you can see how simple objectives for us turn into difficult ones for them. While many of us perhaps envy their resources, they're actually at a huge disadvantage to us in every other way. They have a massive problem, one that we set out to solve:</p><blockquote>For them innovation, product development, and skunkworks is expensive, slow, regulated, ineffective, and swimming against the current.</blockquote>
        </div>
      </section>


        <div>
  <h3>Stay up to date!</h3>
  <p>
    Get all the latest &amp; greatest information delivered straight to your inbox
  </p>

  
</div>

    </article>
  </div></div>]]>
            </description>
            <link>https://blog.codelitt.com/corporate-innovation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25375013</guid>
            <pubDate>Thu, 10 Dec 2020 15:55:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CentOS Stream, or Debian?]]>
            </title>
            <description>
<![CDATA[
Score 91 | Comments 96 (<a href="https://news.ycombinator.com/item?id=25374783">thread link</a>) | @pabs3
<br/>
December 10, 2020 | https://jonathancarter.org/2020/12/10/centos-stream-or-debian/ | <a href="https://web.archive.org/web/*/https://jonathancarter.org/2020/12/10/centos-stream-or-debian/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><strong>It’s the end of CentOS as we know it</strong></p><p>Earlier this week, the CentOS project announced the shift <a href="https://blog.centos.org/2020/12/future-is-centos-stream/">to CentOS stream</a>. In a nutshell, this means that they will discontinue being a close clone of RHEL along with security updates, and instead it will serve as a development branch of RHEL.</p><p>As you can probably imagine (or gleam from the comments in that post I referenced), a lot of people are unhappy about this.</p><p>One particular quote got my attention this morning while catching up on this <a href="https://lwn.net/Articles/838889/">week’s edition of Linux Weekly News</a>, under the distributions quotes section:</p><blockquote><p>I have been doing this for 17 years and CentOS is basically my life’s work. This was (for me personally) a heart wrenching decision. However, i see no other decision as a possibility. If there was, it would have been made.</p><cite><a href="https://lwn.net/Articles/839521/">Johnny Hughes</a></cite></blockquote><p>I feel really sorry for this person and can empathize, I’ve been in similar situations in my life before where I’ve poured all my love and energy into something and then due to some corporate or organisational decisions (and usually poor ones), the project got discontinued and all that work that went into it vanishes into the ether. Also, 17 years is really long to be contributing to any one project so I can imagine that this must have been especially gutting.</p><p><strong>Throw me a freakin’ bone here</strong></p><p>I’m also somewhat skeptical of how successful CentOS Stream will really be in any form of a community project. It seems that Red Hat is expecting that volunteers should contribute to their product development for free, and then when these contributors actually want to use that resulting product, they’re expected to pay a corporate subscription fee to do so. This seems like a very lop-sided relationship to me, and I’m not sure it will be sustainable in the long term. In <a href="https://www.redhat.com/en/blog/centos-stream-building-innovative-future-enterprise-linux">Red Hat’s announcement of CentOS Stream</a>, they kind of throw the community a bone by saying “In the first half of 2021, we plan to introduce low- or no-cost programs for a variety of use cases”- it seems likely that this will just be for experimental purposes similar to the <a href="https://insider.windows.com/">Windows Insider program</a> and won’t be of much use for production users at all.</p><p>Red Hat does point out that their <a href="https://developers.redhat.com/products/rhel/ubi">Universal Base Image</a> (UBI) is free to use and that users could just use that on any system in a container, but this doesn’t add much comfort to the individuals and organisations who have contributed huge amounts of time and effort to CentOS over the years who rely on a stable, general-purpose Linux system that can be installed on bare metal.</p><p><strong>Way forward for CentOS users</strong></p><p>Where to from here? I suppose CentOS users could start coughing up for RHEL subscriptions. For many CentOS use cases that won’t make much sense. They could move to another distribution, or fork/restart CentOS. The latter is already happening. One of the original founders of the CentOS project, Gregory Kurtzer, is now working on <a href="https://rockylinux.org/" data-type="URL" data-id="https://rockylinux.org/">Rocky Linux</a>, which aims to be a new free system built from the RHEL sources.</p><p>Some people from Red Hat and Canonical are often a bit surprised or skeptical when I point out to them that binary licenses are also important. This whole saga is yet another data point, but it proves that yet again. If Red Hat had from the beginning released RHEL with free sources and unobfuscated patches,  then none of this would’ve been necessary in the first place. And while I wish Rocky Linux all the success it aims to achieve, I do not think that working for free on a system that ultimately supports Red Hat’s selfish eco-system is really productive or helpful.</p><p>The fact is, Debian is already a free enterprise-scale system already used by huge organisations like Google and many others, which has stable releases, LTS support and ELTS offerings from external organisations if someone really needs it. And while RHEL clones have come and gone through the years, Debian’s <a href="https://www.debian.org/social_contract">mission and contract to its users</a> is something that stays consistent and I believe Debian and its ideals will be around for as long as people need Unixy operating systems to run anywhere (i.e.  a very long time).</p><p>While we sometimes fall short of some of our technical goals in Debian, and while we don’t always agree on everything, we do tend to make great long-term progress, and usually in the right direction. We’ve proved that our method of building a system together is sustainable, that we can do so reliably and timely and that we can collectively support it. From there on it can only get even better when we join forces and work together, because when either individuals or organisations contribute to Debian, they can use the end result for both private or commercial purposes without having to pay any fee or be encumbered by legal gotchas.</p><p>Don’t get caught by greedy corporate motivations that will result in you losing years of your life’s work for absolutely no good reason. Make your time and effort count and either contribute to Debian or give your employees time to do so on company time. Many already do and reap the rewards of this, and don’t look back.</p><p>While Debian is a very container and virtualization friendly system, we’ve managed to remain a good general-purpose operating system that manages to span use cases so vast that I’d have to use a blog post longer than this one just to cover them.</p><p>And while learning a whole new set of package build chain, package manager and new organisational culture and so on can be uhm, really rocky at the start, I’d say that it’s a good investment with Debian and unlikely to be time that you’ll ever felt was wasted. As Debian project leader, I’m personally available to help answer any questions that someone might have if they are interested in coming over to Debian. Feel free to mail leader_AT_debian.org (replace _AT_ with @) or find me on the oftc IRC network with the nick <em>highvoltage</em>. I believe that together, we can make Debian the <em>de facto</em> free enterprise system, and that it would be to the benefit of all its corporate users, instead of tilting <em>all</em> the benefit to just one or two corporations who certainly don’t have your best interests in mind.</p></div></div></div>]]>
            </description>
            <link>https://jonathancarter.org/2020/12/10/centos-stream-or-debian/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25374783</guid>
            <pubDate>Thu, 10 Dec 2020 15:36:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[One-off scripts: DevOps last mile]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25374731">thread link</a>) | @andriosr
<br/>
December 10, 2020 | https://andrios.co/articles/oneoffs | <a href="https://web.archive.org/web/*/https://andrios.co/articles/oneoffs">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>Companies chasing DevOps have an internal team dedicated to automation. Developers use tools built by this team to run and operate their code. They have many names, but let’s call them Platform, which most companies do.</p><p>Platform teams create abstractions on top of the infrastructure. The goal is to increase developer speed and make systems reliable. They increase speed by simplifying infrastructure APIs and reliability by automating manual tasks. <strong>Automation lowers the risk of service disruptions, but companies aren’t automating the highest-risk tasks.</strong></p><p><strong>What should we automate?</strong></p><p>We used to ship software by accessing servers and running commands inside boxes to pull new code. Now code goes from Git to servers without human intervention. Developers define what they need with code. Platform teams build the tools to make code changes become running systems.</p><p>The goal is doing this for everything, from business code to infrastructure like networking, databases, and queues. But this is hard. Platform teams have a lengthy backlog; they focus on items demanded with higher frequency.</p><p>Developers make manual changes for things not yet automated. Some companies have compliance, regulations, and other constraints. <strong>It’s hard to get developers direct access to production. So they have the Platform team running these changes for developers.</strong></p><p>It’s what makes the higher frequency items get priority. Engineers want to write software, not run repetitive manual tasks. But this backlog is never decreasing. The business changes and adopts new technologies. Headcount grows, adding new items to the automation backlog. And this mysterious type of task is always left behind.</p><p><strong>One-offs.</strong></p><p>Sometimes a bug in software messes with a customers' money, time, health, or ego. They won’t wait for three iterations of code reviews, tests, code analysis, and gradual rollouts. It takes time. Someone will access the database and update it. These are one-off scripts. <strong>They solve a problem for one or a few customers before the team creates a definitive fix.</strong></p><p>One-off scripts have a terrible reputation. When this happens too much, it’s a sign that the software is not stable. In the ideal world, it would never happen. Engineers would spot such time-critical problems during the design and code review phases. Production issues should be light and wait for regular software delivery flow.</p><p>Almost every company lives under the illusion that one-offs should not exist. Or that they will stop happening at some point. Yes, one should not do this every day. <strong>But having a few senior engineers run manual scripts in production because it’s an exceptional case is a mistake.</strong></p><blockquote><p>Almost every company lives under the illusion that one-offs should not exist.</p></blockquote><p><strong>Am I doing one-offs?</strong></p><p>Here are some common one-off solutions companies use in production:</p><ul><li>Call Raketasks using Rails console.</li><li>Use IEx to call Elixir functions.</li><li>Exec into servers/containers/pods and make localhost calls to an HTTP API</li><li>Make DML queries against the database.</li><li>Run bash/Python scripts through VPNs.</li></ul><p><strong>A myth.</strong></p><p>One-offs won’t go away, and companies need to embrace it. Avoiding them will drive the company to the wrong path. Centralizing execution with experienced engineers; or creating a team dedicated to analyzing and running them isn’t reasonable. It’s the opposite of DevOps.</p><blockquote><p>One-offs won’t go away, and companies need to embrace it.</p></blockquote><p>Most big companies solve this problem with a slow and manual Change Management workflow. Developers find the problem and add a script to a ticketing system. <strong>Someone from the operations team runs it without all the context</strong> of what she is doing. Avoiding one-offs is the shortest path to this model.</p><p><strong>What about Runbooks?</strong></p><p>Runbooks are great. Tools like <a href="https://www.rundeck.com/" target="_blank" rel="noreferrer noopener">Rundeck</a>
and <a href="https://stackstorm.com/" target="_blank" rel="noreferrer noopener">StackStorm</a>
automate fixing problems you know exist. They remove manual operations for routine tasks. But 1) creating Runbooks takes time, and 2) Runbook tools focus on infrastructure. One-off solutions need a faster track and application layer changes.</p><p>One-offs are the most challenging piece to automate. When you don’t know what problems will happen, it’s hard to build a solution upfront. Few companies I know 1) embrace one-offs, and 2) and try to automate them.</p><p><strong>For unknown unknowns, pre-existing solutions won’t work.</strong> The automation supporting this flow needs to be open-ended. The fastest is using direct access to resources and running ad-hoc solutions manually. But we can do better. It won’t get to the level of regular code, but we can get close.</p><blockquote><p>When you don’t know what problems will happen, it’s hard to build a solution upfront.</p></blockquote><p><strong>Isn’t this a bad incentive?</strong></p><p>A common misconception about one-offs is that formalizing them will increase their usage. They are faster to build than regular code. So it makes sense to think developers will prefer them over traditional pipelines. But this couldn’t be further from the truth. <strong>By making one-offs first-class citizens, you start to measure them. You can only change what you measure.</strong></p><p>One-offs must link to tasks with definitive fixes. Teams running them too much should decrease the number of features in the next sprint. Product prioritization should take into account what types of one-offs happen the most. All this is only possible with measurements. There is no upside in making one-offs hard to build and run.</p><blockquote><p>There is no upside in making one-offs hard to build and run.</p></blockquote><p><strong>One-offs as first-class citizens</strong></p><p>I built automations to support one-off scripts at previous jobs. It took a few months for the team as we had other duties, and the solution was not perfect. But <strong>developers were happy with the autonomy</strong> to build and run all solutions to their problems. Security and compliance were happier with audit trails &amp; logs. SREs were happy with fewer manual interventions in production. It was hard but paid off.</p><p>Today, I’m the founder of <a href="http://runops.io/" target="_blank" rel="noreferrer noopener">RunOps</a>
, a tool that automates one-offs. It lets you run scripts as if you had direct access to resources. Still, transparent controls and reviews make them safe, compliant, and reliable. It takes minutes to set up, our early users are very excited. Feel free to reach out on<a href="https://twitter.com/andriosrobert" target="_blank" rel="noreferrer noopener"> Twitter</a>
or shoot me an <a href="mailto:first@runops.io" target="_blank">e-mail</a>
to learn more.</p><p>I’m writing a few other articles exploring the topic. Subscribe to get the next in your inbox.</p><br></article></div>]]>
            </description>
            <link>https://andrios.co/articles/oneoffs</link>
            <guid isPermaLink="false">hacker-news-small-sites-25374731</guid>
            <pubDate>Thu, 10 Dec 2020 15:32:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building 5G Edge Clouds for Containers with OpenNebula and AWS Wavelength]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25374553">thread link</a>) | @amarti
<br/>
December 10, 2020 | https://opennebula.io/building-5g-edge-clouds-for-containers-with-opennebula-and-aws-wavelength/ | <a href="https://web.archive.org/web/*/https://opennebula.io/building-5g-edge-clouds-for-containers-with-opennebula-and-aws-wavelength/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
			    <!-- .entry-header -->

				
					
<article id="post-29317">

    <!-- .entry-header -->

    <div>

		
<div><div id="kt-layout-id_df94ee-55"><div>
<div><p>🌎 OpenNebula’s new <a href="https://opennebula.io/true-hybrid/" target="_blank" rel="noopener noreferrer">True Hybrid Cloud Architecture</a> enables true hybrid and edge cloud computing by combining <strong>public and private</strong> cloud operations with <strong>workload portability</strong> and <strong>unified management</strong> of your IT infrastructure and applications.</p></div>



<div><p>Since the release of version 5.8 ‘Edge’ in February 2019, OpenNebula comes with a number of innovative features that provide organizations with a truly simple way to create and manage <strong>highly distributed cloud infrastructures</strong>. Thanks to these tools—developed in the context of our <a href="https://oneedge.io/">ONEedge</a> initiative—companies can easily deploy and manage remote clusters outside their premises in <strong>cloud and edge locations</strong> that are geographically dispersed or in close proximity to their end-users and customers.</p></div>
</div></div></div>



<p>By using <strong>OpenNebula’s new provisioning tools</strong>, cloud admins can now expand their private clouds in an incredibly flexible way using resources offered by <strong>third-party cloud providers like AWS and Equinix Metal</strong>, incorporating when necessary the distributed dedicated infrastructure they need to satisfy their users’ requirements for fault tolerance, capacity or low latency.&nbsp;</p>



<p>OpenNebula users can <strong>automatically allocate resources when needed</strong>, deploying and controlling edge nodes based on the current demand at those specific geographical locations. This approach simplifies significantly the process of <strong>provisioning and managing edge resources</strong>, without the organization that’s using this solution having to provide or own those underlying resources at all.</p>



<div><figure><img src="https://opennebula.io/wp-content/uploads/2020/11/MasteringContainers.jpg" alt="" width="750" height="263" srcset="https://opennebula.io/wp-content/uploads/2020/11/MasteringContainers.jpg 1000w, https://opennebula.io/wp-content/uploads/2020/11/MasteringContainers-300x105.jpg 300w, https://opennebula.io/wp-content/uploads/2020/11/MasteringContainers-768x269.jpg 768w" sizes="(max-width: 750px) 100vw, 750px"></figure></div>



<p>OpenNebula also offers a simple, but powerful approach for <a href="https://opennebula.io/mastering-containers/">running containerized applications and workflows</a>—both <strong>on-premises and on cloud or edge locations</strong>—by directly using Docker official images from the <a href="https://support.opennebula.pro/hc/en-us/articles/360046667892-Using-the-Docker-Hub-Marketplace-to-Deploy-Container-based-Applications">Docker Hub</a> and running them as lightweight <a href="https://opennebula.io/firecracker/">Firecracker</a> microVMs. For those cases where Kubernetes is required or is the best fit, OpenNebula also provides a <a href="https://opennebula.io/certified-kubernetes-appliance/">Certified Kubernetes</a> Virtual Appliance available from the OpenNebula Public Marketplace, although for <strong>Kubernetes deployments at the edge</strong> we normally recommend a lighter solution based on <a href="https://k3s.io/">K3s</a> clusters 😉</p>



<h2>The New AWS Wavelength Service</h2>



<p>Recently, Amazon Web Services (AWS), in collaboration with <strong>Verizon, Vodafone and other 5G telecommunication providers</strong>, has presented its new <a href="https://aws.amazon.com/wavelength/">AWS Wavelength</a> service (read <a href="https://aws.amazon.com/blogs/aws/aws-wavelength-zones-are-now-open-in-boston-san-francisco/">here</a> the full announcement by AWS Chief Evangelist Jeff Barr back in August). <strong>Wavelength Zones</strong> bring AWS compute and storage capabilities and services to the edge of existing 5G networks, embedding AWS hardware and software within their data centers. This enables developers to innovate and build a new class of edge applications that can exploit <strong>high bandwidth and ultra-low latencies</strong> as offered by the new 5G networks.</p>



<figure><p>
<iframe title="AWS Wavelength - Edge Computing for 5G Networks" width="640" height="360" src="https://www.youtube.com/embed/EhMqwPqPzcY?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>



<p>Thanks to AWS Wavelength, application traffic from 5G devices can reach the servers running in Wavelength Zones <strong>without leaving the telecommunications network</strong>, thus avoiding having to traverse multiple hops across the Internet to reach their final destination, as it happens with a traditional approach based on a centralized cloud solution. This new service enables both developers and end-users to finally take full advantage of the latency and bandwidth benefits offered by 5G networks 📱</p>



<p>At OpenNebula, we have already started <strong>testing the new AWS Wavelength resources</strong> as part of our <a href="https://oneedge.io/">ONEedge</a> initiative. Eventually, this new service will be incorporated into our <strong>catalogue of cloud and edge providers</strong> available for OpenNebula users. We expect this integration to really simplify the process of provisioning and managing resources close to 5G devices, helping organizations using OpenNebula to <strong>build and quickly deploy edge applications</strong> that can benefit from 5G high bandwidth and ultra-low latency, including machine learning, video streaming, multiplayer gaming, Internet of Things, augmented reality, and real-time analytics.&nbsp;</p>



<h2>OpenNebula’s First 5G Edge Architecture based on AWS Wavelength</h2>



<p>As part of our first tests of this new AWS service, we’ve adapted the scenario described by AWS Senior Developer Mike Coleman in a <a href="https://aws.amazon.com/blogs/compute/deploying-your-first-5g-enabled-application-with-aws-wavelength/">post on AWS Wavelength</a> published in early August. In our case, a company with an OpenNebula private cloud wants to <strong>deploy a multi-container application at the edge</strong> (i.e a Machine Learning solution), closer to the 5G devices of their end-users. The following diagram describes how this would be implemented based on the features provided by OpenNebula and on the new resources made available by AWS Wavelength:</p>



<div><figure><img src="https://opennebula.io/wp-content/uploads/2020/12/OpenNebula-Wavelength_Architecture-1024x563.png" alt="" srcset="https://opennebula.io/wp-content/uploads/2020/12/OpenNebula-Wavelength_Architecture-1024x563.png 1024w, https://opennebula.io/wp-content/uploads/2020/12/OpenNebula-Wavelength_Architecture-300x165.png 300w, https://opennebula.io/wp-content/uploads/2020/12/OpenNebula-Wavelength_Architecture-768x422.png 768w, https://opennebula.io/wp-content/uploads/2020/12/OpenNebula-Wavelength_Architecture.png 1500w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></div>



<p>AWS Wavelength is designed to provide access to services and applications that require low latency, but it’s important to remember that you don’t need to deploy your entire application in a Wavelength Zone. You only need to deploy those<strong> latency-sensitive parts of your application</strong> that are really going to benefit from being deployed at the 5G edge. In our demo scenario, the API server and inference engine are located on the Wavelength Zone because one of the design goals of the application is low-latency processing of the inference requests. On the other hand, given that the web server doesn’t have those latency requirements, it doesn’t really need to be hosted on the Wavelength Zone.</p>



<p>Each Wavelength Zone is <strong>associated with a specific AWS Region, known as the “parent region”</strong>. For our experiment we have picked the Boston area, which is one of the first regions—along with San Francisco—in which the new Wavelength service was made available. Also, Wavelength instances are only accessible from 5G devices on a specific telecom provider network, in this case from those of <strong>Verizon customers in the Boston area</strong> 🧱</p>







<figure><img src="https://opennebula.io/wp-content/uploads/2020/12/OpenNebula-Wavelength_AWSportal-1024x189.png" alt="" srcset="https://opennebula.io/wp-content/uploads/2020/12/OpenNebula-Wavelength_AWSportal-1024x189.png 1024w, https://opennebula.io/wp-content/uploads/2020/12/OpenNebula-Wavelength_AWSportal-300x55.png 300w, https://opennebula.io/wp-content/uploads/2020/12/OpenNebula-Wavelength_AWSportal-768x142.png 768w, https://opennebula.io/wp-content/uploads/2020/12/OpenNebula-Wavelength_AWSportal.png 1319w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>







<p>For the deployment of a multi-container application that benefits from this approach, we have used a number of <strong>well-known open source technologies</strong>. One of them has been <a href="https://k3s.io/">K3s</a>, a certified Kubernetes distribution originally developed by <strong>Rancher Labs</strong> and now hosted by the <a href="https://rancher.com/press/rancher-labs-k3s-joins-cloud-native-computing-foundation-sandbox-project">Cloud Native Computing Foundation</a> (CNCF). K3s is a lightweight, production-grade distribution designed for organizations looking to run Kubernetes in resource-constrained environments, which makes it ideal for deployments at the edge. We have used a customized K3s image for this demo, but in the near future users will be able to deploy a K3s cluster by simply using its public Docker image 🤩</p>



<p>When <strong>bare-metal resources</strong> are available, OpenNebula users can also benefit from our latest, super-cool integration with <a href="https://opennebula.io/firecracker/">Firecracker</a>. Firecracker is a new open source virtualization technology—widely used by AWS as part of its <strong>Fargate and Lambda</strong> services—especially designed for <strong>serverless deployments</strong>. By running application containers (e.g. the K3s Docker image) as a <strong>Firecracker microVM</strong>, we immediately obtain the enhanced security and workload isolation of a traditional VM, but without undermining the speed and resource efficiency of a container.</p>



<p>Unfortunately, right now, bare-metal instances are not available in the current Wavelength zones, so we cannot use Firecracker for our 5G edge deployment, only at the associated AWS parent region (i.e. us-east-1). Thus, for Wavelength instances, and thanks to another great feature of OpenNebula, we can use <strong>Ubuntu</strong>’s <a href="https://linuxcontainers.org/lxd/getting-started-opennebula/">LXD system containers</a> to deploy K3s agents on the Wavelength resources.</p>



<p>As show in the figure, in order to deploy a containerized application composed of different components, OpenNebula allows to <strong>instantiate a K3s cluster across multiple hosts with mixed hypervisors</strong> and then let the customer deploy the application (e.g. using an helm chart or kubectl) by scheduling the components on the right resources, typically deploying the latency-sensitive components (i.e. the Inference Engine and the API server) on the Wavelength Zone, and the rest of components (i.e. Web Server) on the AWS parent region.</p>



<h2>Integration of AWS Wavelength Resources within OpenNebula</h2>



<p>OK, let’s get into some more detail… 🤓 The first step required to set up AWS Wavelength resources is the deployment of an <strong>AWS Virtual Private Cloud</strong> (VPC) with two zones: one is related to the associated AWS parent region, and one is related to the Wavelength Zone. We have then to associate to the VPC an Internet Gateway that is used to assign public IPs to resources that are deployed within the parent region, plus a Carrier Gateway that is used to assign carrier public IPs to the resources deployed on the Wavelength Zone.</p>



<p>In the VPC we have to define two subnets: one for the resources at the parent region and one for Wavelength Zone resources. The parent region subnet will be associated with the Internet Gateway to get public IPs, whereas the Wavelength subnet will be associated with the Carrier Gateway to get public IPs from the 5G carrier network.</p>



<p>The Carrier Gateway in a Wavelength Zone only allows access from the carrier’s 5G network. So, since the Wavelength zone resources cannot be accessed by using the internet, it is not possible to provision, configure and set up those resources by directly accessing them. In order to integrate Wavelength Zone resources with OpenNebula, we have to <strong>use the parent zone’s servers as “bastion hosts”</strong> to access Wavelength Zone resources via SSH, since they are only reachable through the private VPC subnet. Resources in the parent region can also be used to deploy those parts of our application that are not latency-sensitive or require high-bandwidth.&nbsp;</p>



<p>Provisioning resources on regular AWS zones for deploying application parts that are not latency-sensitive is already possible for OpenNebula and can be performed by using its standard <a href="https://docs.opennebula.io/5.8/advanced_components/ddc/overview.html">OneProvision</a> tool. By using a bastion host and customized SSH configuration files, it is then possible to <strong>provision and configure instances on the Wavelength Zone</strong> and to add them as hosts to the OpenNebula front-end. Since OpenNebula uses SSH to perform any operation on the hosts, once bastion and Wavelength resources are set up, it is possible to <strong>deploy containerized applications</strong> (i.e. a K3s cluster) both on the parent region and on the …</p></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://opennebula.io/building-5g-edge-clouds-for-containers-with-opennebula-and-aws-wavelength/">https://opennebula.io/building-5g-edge-clouds-for-containers-with-opennebula-and-aws-wavelength/</a></em></p>]]>
            </description>
            <link>https://opennebula.io/building-5g-edge-clouds-for-containers-with-opennebula-and-aws-wavelength/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25374553</guid>
            <pubDate>Thu, 10 Dec 2020 15:18:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Problem with Acronyms]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25374486">thread link</a>) | @thismodernlife
<br/>
December 10, 2020 | https://headey.net/the-problem-with-acronyms | <a href="https://web.archive.org/web/*/https://headey.net/the-problem-with-acronyms">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
  <p><em>Reducing the use of unnecessary acronyms in your business will increase productivity and employee happiness, and reduce cynicism as you grow. Here's how.<br></em><br>
</p>
<div>
<action-text-attachment sgid="BAh7CEkiCGdpZAY6BkVUSSI1Z2lkOi8vYmxvZ2xpbmUvQWN0aXZlU3RvcmFnZTo6QmxvYi83OT9leHBpcmVzX2luBjsAVEkiDHB1cnBvc2UGOwBUSSIPYXR0YWNoYWJsZQY7AFRJIg9leHBpcmVzX2F0BjsAVDA=--492323e7f82eed9da3abe777946f97eda1fea850" content-type="image/jpeg" url="https://blogline.co/rails/active_storage/blobs/redirect/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBWQT09IiwiZXhwIjpudWxsLCJwdXIiOiJibG9iX2lkIn19--ad4630a4a9904956efb76f599a435812aa947e98/choose-your-words.jpg" filename="choose-your-words.jpg" filesize="47482" width="800" height="600" previewable="true" presentation="gallery"><figure>
    <img src="https://headey.net/rails/active_storage/representations/redirect/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBWQT09IiwiZXhwIjpudWxsLCJwdXIiOiJibG9iX2lkIn19--ad4630a4a9904956efb76f599a435812aa947e98/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaDdDRG9MWm05eWJXRjBTU0lJYW5CbkJqb0dSVlE2RkhKbGMybDZaVjkwYjE5c2FXMXBkRnNIYVFJQUJHa0NBQU02QzJ4dllXUmxjbnNHT2dsd1lXZGxNQT09IiwiZXhwIjpudWxsLCJwdXIiOiJ2YXJpYXRpb24ifX0=--a716ef5bd361b6dfee383a3ae715134b65b59d48/choose-your-words.jpg">

  <figcaption>
  </figcaption>
</figure></action-text-attachment><p><a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=&amp;ved=2ahUKEwiRlcKCp5jtAhWNQEEAHfPgCOYQFjAAegQIBBAC&amp;url=https%3A%2F%2Fheadey.net%2Fspectacular-vernacular&amp;usg=AOvVaw0rJ08bs82T25D_W2oBjORi">Confusing vernacular</a> isn’t a new thing to me, but I’ve noticed that an acronym[1] population steadily increases as projects, or entire companies, expand. I can sort of understand. When a company is bigger, there are more people and more things going on. More projects, more meetings, more presentations. Typing “Engaged User Growth Hack” becomes tedious the 14th time you write it in your proposal, so someone initialises it (EUGH) the first time and uses the acronym there on in. Once the document is circulated, it’s inevitable that at some point – it might take a few meetings, but eventually – it becomes common parlance. "How is the EUGH rate looking this week, Ted?"</p></div>
<div><p>One of the many problems you’re going to encounter in a growing business is a lack of clarity among staff. A successful business is one where employees understand things, and when they don’t it's okay because they know where to go to find the information required to understand things.&nbsp;</p><p>Whether you’re a new hire reviewing an onboarding guide on your first day, or a seasoned employee reading the latest project proposal, you’re probably going to be faced with a sea of acronyms. The more there are, the more confused you'll be. This is bad for morale and bad for business, so it's your job as a leader in an organisation to spare everyone from this misery by eliminating acronyms as much as possible in your organisation. Here are my top tips.</p></div>


<div><p>Some acronyms are so universally understood and accepted that it would be weird not to use them (HTML, RAM). There are some acronyms where the majority of people know what they mean, even if they don't know specifically what the abbreviation stands for. There are some that are <strong>very dependent on context</strong> so proceed with caution unless they are truly universal or if you really know your specific audience. For instance:</p></div>
<ul>
<li>NHS. Everyone in Britain will know what this means, but many people from other countries might be confused.</li>
<li>FBI. You know what it is, but what does it stand for?&nbsp;</li>
<li>UFO. People of a certain age will know about UFOs, but has anyone talked about them since 1989?&nbsp;</li>
</ul>


<div><p>If we accept the premise that more acronyms means more confusion, why would we add to this? Writing Average Page Load Time is tedious for the author, but creates clarity and removes any confusion about what it means (given the appropriate context). APLT does neither. Adopting universal acronyms into your organisation isn't necessarily a bad thing, but inventing your own probably is.</p><p>One exception to this rule is code names. Calling your new internal app <strong>PERSI</strong> is better than calling it Predictive Enterprise Relationship System Integration, and it's fun to ask the team "How is PERSI doing this morning?". Personality goes a long way.<br>.</p></div>

<div><p>Even if we're not creating any new acronyms, there will always be a heap in common use already. When you’re writing a document, always write the words in full on first use and put the acronym in brackets after it. For example, don't write:</p></div>
<blockquote>In our company, we live and die by OKRs and KPIs.</blockquote>

<blockquote>In our company, we live and die by Objectives and Key Results (OKRs) and Key Performance Indicators (KPIs).&nbsp;</blockquote>
<div>
<p>Given that everything is likely to be in digital form you should also, wherever possible, link to even more information. Context is king. So your document should look more like this:</p></div>
<blockquote>In our company, we live and die by <a href="https://www.youtube.com/watch?v=mJB83EZtAjc">Objectives and Key Results</a> (OKRs) and <a href="https://en.wikipedia.org/wiki/Performance_indicator">Key Performance Indicators</a> (KPIs).&nbsp;</blockquote>
<div>
<p>Do this always. Even if you think it's unnecessary, it's really not. It is helping communication, not hindering.</p></div>


<blockquote><em>To maximize clarity, use abbreviations sparingly<p>— American Psychological Association</p></em></blockquote>
<div>
<p>Just because everyone else does, you don't actually have to use acronyms yourself. You can assume everyone knows what KPI means, and perhaps they do know that it stands for Key Performance Indicator, but do they know what a "performance indicator" actually is? Wouldn't it be better to ditch the acronym entirely and say "measure of success"? You could say the same thing about OKRs (goals), CTR (ad click rate), and CRM (customer database). </p><p><a href="http://www.plainenglish.co.uk/">Plain English</a> is liberating.&nbsp;</p></div>

<div><p>You need to write down all the acronyms being used in your daily business so, at the very least, people can look things up rather than sit there silently and fearfully in ignorance. Doing this is a fun company crowdsourcing exercise where you can talk about the perils of acronyms and get this front and centre so people actually know about it and use it.&nbsp;</p><p>This glossary should be reasonably short. If it's not, you're probably using too many acronyms in your business and you need to go on a diet. You could write an OKR for that.</p></div>
<div>
<p>The intention of this article is to make you think about how acronyms are being used in your business, and for you to keep a sharper eye on new ones appearing. You should feel empowered to question their invention, and you should call it out when a document lands in your inbox that is populated with unreferenced jargon. </p><p>You could even go all Elon Musk, <a href="https://gist.github.com/klaaspieter/12cd68f54bb71a3940eae5cdd4ea1764">berate the entire company</a> and demand sign-off of any new acronyms. Extreme behaviour, perhaps, but it goes to show the negative impact acronyms have on a business and the secret power of that liberating feeling of clarity when they're eliminated from use.</p><p><a href="https://en.wikipedia.org/wiki/TTFN">TTFN</a>.<br><em><br>[1] I only learned this recently but an acronym is a word formed from the first letters of other words and is pronounceable, for example </em><strong><em>laser</em></strong><em> or </em><strong><em>radar</em></strong><em> (🤯 I know, right), whereas an initialism is an abbreviation in which each letter is pronounced separately, such as OMG or NHS. In this article I only use the word acronym because I'm pretty sure no-one ever uses the word initialism.</em></p></div>
</div>

  </div><div data-controller="email-subscribers">
    <p>Subscribe to Email Updates</p>

    

      </div></div>]]>
            </description>
            <link>https://headey.net/the-problem-with-acronyms</link>
            <guid isPermaLink="false">hacker-news-small-sites-25374486</guid>
            <pubDate>Thu, 10 Dec 2020 15:13:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting our first thousand users in one day]]>
            </title>
            <description>
<![CDATA[
Score 153 | Comments 55 (<a href="https://news.ycombinator.com/item?id=25374319">thread link</a>) | @frankdilo
<br/>
December 10, 2020 | https://francescodilorenzo.com/typefully-launch | <a href="https://web.archive.org/web/*/https://francescodilorenzo.com/typefully-launch">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>Yesterday we launched <a href="https://typefully.app/">Typefully</a>, a write-only interface for Twitter, after weeks of work and refinement. I documented the whole story on Twitter <a href="https://twitter.com/frankdilo">@frankdilo</a>.</p>
<p>Not much deep work happened on launch day and for good reasons. It was a bigger launch than <a href="https://francescodilorenzo.com/mailbrew-launch-numbers">Mailbrew's</a>.</p>
<p>Here the numbers:</p>
<ul>
<li>16,400 Pageviews </li>
<li>1,432 Signups </li>
<li>1,843 Drafts created</li>
<li>256 Threads published</li>
<li>$155 Revenue (more on this at the end).</li>
</ul>
<p>The traffic breakdown reveals what happened:</p>
<ul>
<li>Hacker News: 6.3k</li>
<li>Twitter: 2.1k</li>
<li>ProductHunt: 1.9k</li>
</ul>
<p>Yeah, we finally managed to hit the <a href="https://news.ycombinator.com/item?id=25358108">Hacker News frontpage</a>. </p>
<p>The perfect formula was:</p>
<ul>
<li>interesting product</li>
<li>no-bullshit title</li>
<li>sparking a controversial discussion in the comments.</li>
</ul>
<p>When it comes to Twitter, we have been building a following there for some time, so it was a matter of publishing the <a href="https://twitter.com/frankdilo/status/1336589322670268416?s=21">right tweet</a>, at the right time, and getting the right people to retweet it.</p>
<p>For Product Hunt, we partnered with our friend <a href="https://twitter.com/chrismessina">Chris</a>. His followers got a notification when he hunted us, but we also did our part and emailed our lists.  That helped to get fast on the front page and to kickstart the discussion.</p>
<p>Once we were in front of enough people, the product did the rest.</p>
<p>Servers did hold up without a sweat. </p>
<p>It's crazy what you can do these days with a couple of well-configured dynos on Heroku and a Django app! We peaked at 8 RPS when we hit the HN frontpage.</p>
<p>Typefully was born as <a href="https://twitter.com/linuz90">Fabrizio</a>'s personal side-project. I jumped in to make the editor crazy-fast, and write the server-side code. When <a href="https://twitter.com/meseali">Ali</a> helped us refine positioning and copy, we knew we had a winner and promoted it to an official <a href="https://mailbrew.com/">Mailbrew</a> project.</p>
<p>Plans for the future? Implement all the great feature requests we got, and monetize this thing. </p>
<p>We launched with a tip-jar system where people could become <em>patrons</em> by tipping us, but with $150 earned after a crazy launch day like this, it's clear that this is not going to pay the bills. </p>
<p>We are thinking of adding some paid features. What's free is gonna stay free though, because this was first and foremost a labor of love.</p>
</article></div>]]>
            </description>
            <link>https://francescodilorenzo.com/typefully-launch</link>
            <guid isPermaLink="false">hacker-news-small-sites-25374319</guid>
            <pubDate>Thu, 10 Dec 2020 14:59:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A list of small teams behind billion dollar start-ups]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25374145">thread link</a>) | @maxejennings
<br/>
December 10, 2020 | https://stevepulec.com/posts/small/ | <a href="https://web.archive.org/web/*/https://stevepulec.com/posts/small/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<article>
    <p>Patrick Collison has a <a href="https://patrickcollison.com/fast">great list</a> of people quickly accomplishing ambitious things. Inspired by that, I created a page of impressive things accomplished by small teams.</p>
<ul>
<li>
<p><strong>Instagram</strong> had 13 employees when they were acquired by Facebook for $1 billion. They had 30 millions users at the time. <a href="https://www.cnbc.com/2019/09/24/facebook-bought-instagram-because-it-was-scared-of-twitter-and-google.html">Source</a></p>
</li>
<li>
<p><strong>Mojang</strong> (the company behind Minecraft) had 37 employees when they were acquired by Microsoft for $2.5 billion. At that time, Mojang had revenue of about $290 million annually with profits of over $100 million. <a href="https://www.ft.com/content/6eb85da4-38f4-11e4-9526-00144feabdc0">Source</a></p>
</li>
<li>
<p><strong>WhatsApp</strong> had 55 employees when they were acquired by Facebook for $19 billion. <a href="https://www.wired.com/2015/09/whatsapp-serves-900-million-users-50-engineers/">Source</a></p>
</li>
<li>
<p><a href="https://www.notion.so/"><strong>Notion</strong></a> has raised money at a $2 billion valuation with under 50 employees. <a href="https://techcrunch.com/2020/04/01/notion-hits-2-billion-valuation-in-new-raise/">Source</a></p>
</li>
<li>
<p><strong>BuiltWith</strong> generates $14 million/year with a single employee. <a href="https://twitter.com/theSamParr/status/1257819248484745216">Source</a> (an investor in the business)</p>
</li>
<li>
<p>The <strong>Gartman Letter</strong> had a single employee and was rumored to be doing $25M/year</p>
</li>
<li>
<p>Kylie Jenner sold a 51% stake in the <strong>Kylie Cosmetics</strong> for $600 million with just seven full-time and five part-time employees. <a href="https://www.forbes.com/sites/forbesdigitalcovers/2018/07/11/how-20-year-old-kylie-jenner-built-a-900-million-fortune-in-less-than-3-years/">Source</a></p>
</li>
<li>
<p><strong>Craigslist</strong> generates around $1 billion/year with about 50 employees. <a href="https://www.cnbc.com/2019/01/24/craigslist-posts-annual-revenue-of-1-billion-study.html">Source</a></p>
</li>
<li>
<p><strong>Plenty of Fish</strong> sold for $575 million with 75 employees. <a href="https://www.businessinsider.com/how-markus-frind-bootstrapped-plentyoffish-and-sold-it-for-575-million-2015-7">Source</a></p>
</li>
<li>
<p><strong>Liberty Media</strong> had 16 employees and was worth multi-billions in the 90s. <a href="https://www.amazon.com/Not-Fade-Away-Short-Lived/dp/006073731X">Source</a></p>
</li>
<li>
<p><strong>Joe Rogan</strong> is making between $30-$50 million/year with a handful of employees. <a href="https://www.forbes.com/sites/arielshapiro/2020/05/19/the-new-howard-stern-podcast-giant-joe-rogan-inks-exclusive-deal-with-spotify/">Source</a></p>
</li>
<li>
<p>The progress that the <strong>Wright brothers</strong> made on powered flight was so unbelievable that they had to spend two years convincing the US and French governments that it was true. <a href="http://wrightbros.org/History_Wing/Wright_Story/Showing_the_World/Prize_Patrol/Prize_Patrol.htm">Source</a></p>
</li>
</ul>
<p>This list is very business heavy right now, but I would love to add some non-business examples too! Have more? Please <a href="https://stevepulec.com/about/">reach out</a>.</p>
<p><em><a href="https://twitter.com/spulec">Follow me</a> on Twitter for more updates</em></p>
<p>Related resources:</p>
<ul>
<li><a href="https://www.theguardian.com/technology/2018/apr/24/the-two-pizza-rule-and-the-secret-of-amazons-success">Two pizza rule</a></li>
<li>Something something Margaret Mead quote something something.</li>
<li><a href="https://en.wikipedia.org/wiki/Ringelmann_effect">Ringelmann effect</a></li>
</ul>
</article>

        </div></div>]]>
            </description>
            <link>https://stevepulec.com/posts/small/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25374145</guid>
            <pubDate>Thu, 10 Dec 2020 14:43:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Data You Give]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25374120">thread link</a>) | @henrikwm
<br/>
December 10, 2020 | https://security.christmas/2020/10 | <a href="https://web.archive.org/web/*/https://security.christmas/2020/10">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>He sees you when you’re sleeping, he knows when your awake, he knows if you ‘we been bad or good so be good for goodness sake. This is a line of a popular Christmas song. It obviously refers to Santa Claus. However… What if this is true, not only for Santa, but for large companies worldwide. We’ll take a closer look on the data you give and the repercussions.</p>
</section><article><section><p>In today’s modern world, our phones are an integral part of our lives. We carry it everywhere, whether it is at work, when we are out and about or in the hospital. In every situation, our phone is nearby. The phone gives us easy access to information, communication and you might say there is an app for everything. If you need to see the local weather, it is right there in your phone, the same goes for the directions to the cinema or if you want to know what your friends are up to – check your phone. And it is all free of charge. Well, not exactly, nothing is free.</p>
<h2>The payment</h2>
<p>Although you might not spend any money on an app, the app still collect a form of payment from you. Your information is the currency and it is collected through every action you make on the internet and in the apps on your phone. Your device information, your likes and dislikes and your email is just some of the data they might collect. And the hottest commodity is your location data. You might say the phone is a tracking device you wear 24/7.</p>
<p>Some of this data, we give willingly. This can be photos, statuses, interests and in some cases, who your friends are, where you live and so on. It is easy to believe that the information you give to a specific app will be contained within the app. This is often not the case. Selling consumer data is a multi-billion-dollar industry and your data is sold for targeted marketing, to analytics companies and to research. </p>
<p>You might not know what you do online every day, but the 50 apps you have on your phone does and what you do says a lot about you.</p>
<h2>I have nothing to hide</h2>
<p>You might not know why you should care about the fact that your data is collected, you have nothing to hide. A couple of emails with “special offers” in terms of marketing might not be the worst thing. But here is why you should care. </p>
<p>There are no restrictions on who can by this data and more parties are showing interest. In fact, earlier this year the Wall Street Journal found that the <a href="https://www.wsj.com/articles/federal-agencies-use-cellphone-location-data-for-immigration-enforcement-11581078600">U.S government bought commercially available location data</a> and used if for detecting undocumented immigrants or others trying to get across the U.S border. It also played a part in discovering a drug smuggling tunnel beneath the border between USA and Mexico in an abandoned KFC restaurant. </p>
<p>The police usually must acquire warrants to get this kind of information on your phone, but what if they can just buy it commercially? When is it ok to use these data and when is it surveillance? <a href="https://privacy-pc.com/interviews/bruce-schneier-nsa-is-wasteful-and-dangerous.html">Like the comparisons the cryptographer Bruce Sneider draws:</a> If the government said: “Whenever you make a new friend, you must inform the police”. We would laugh, but we willingly tell Facebook and Facebook informs the government. Or if the government says: ”Whenever you send a message or write a letter or send a note to somebody, send us a copy, please”. That would never happen, we would not do that. However, Google does it for you.</p>
<p>Throughout your days of using your phone or computer, you give pieces of information to each application or website, and although this data is supposed to be anonymous, it is not hard to connect the missing pieces. When seeing all the data from different sources together and by adding simple searches on specific information, your name and identity will be found and the data will no longer be anonymous. This was illustrated when <a href="https://www.nytimes.com/interactive/2018/12/10/business/location-data-privacy-apps.html">The New York Times</a> bought commercially sold location data. With this data they could easily find the person to whom the data belonged. Even though the name of the woman they were tracking, was not among the bought information, they deduced a lot about her. They could see that she was at a weight watchers meeting, doing a procedure at the dermatologist and by the amount of time she was spending at a school, she was most likely a teacher. The phone tracked her every two seconds and giving information about her she found disturbing.</p>
<p><a href="https://www.nrk.no/norge/xl/avslort-av-mobilen-1.14911685">NRK</a>, a TV-channel in Norway did the same. By analysing the person’s patterns, they could see where he spent his days and where he spent his nights. By this information alone one can easily find out who lives at the address he slept at and who works at the address he was during the day, to find the name of the person using the phone. They even found that the person was going to interviews with another company, which he had not told anyone. And some time after these interviews he change his place of work.</p>
<p>All your data collected is a foundation for through analysis of you as a person. They can put you in boxes and make assumptions about you. Sometimes they are right, and sometimes they are not. If you are classified as likely to become a gambler, could it get in the way of you getting a loan in the future? Or could marketing pray on your weaknesses to get you to buy something you don’t need? You can easily be manipulated by companies gaining in-depth knowledge about you. This was proven by “Folkeopplysningen”, a show in Norway that informs the public about different topics. In one episode they <a href="https://www.nrk.no/dokumentar/xl/ble-manipulert-etter-nrk-spionering-pa-hans-digitale-liv-1.14759796">manipulate an intelligent man to give up his company, his life’s work, purely based off of information found on him online</a>. By his likes on Facebook, they could perform a personality test. By the pictures on Instagram they could see that he liked to work out, that he loved superheroes and all kind of other information. They staged a day for him to be considered for a super hero-part in a Hollywood production. All he had to do was give up his business. This is something he probably would never do if it wasn't for being manipulated for an entire day based on the information the TV-show could find on his social media and other online accounts.</p>
<h2>What about GDPR</h2>
<p>If you live in Europe, you have probably heard of General Data Protection Regulation or GDPR. <a href="https://www.investopedia.com/terms/g/general-data-protection-regulation-gdpr.asp">GDPR</a>&nbsp;is a legal framework that sets guidelines for the collection and processing of personal information from people who live in the EU. It is there to give consumers of the internet more right as to what data is collected.</p>
<p>As a consumer, you notice it best by having to accept the use of cookies on the web or by giving permissions to the apps of which data they can have access to. However, the government can only do so much if consumers keep accepting the usage. The web or phone applications often make it hard not to accept by writing the terms incomprehensible or too long. In some cases, you must even go to completely different applications to turn it all the way off.&nbsp;<em>As long as it is easier to accept, we will accept.</em>&nbsp;It can also be difficult to investigate where the commercially sold data comes from because not all companies are located in Europe and in some cases the terms does not specify all the different ways your data can be spread. </p>
<h2>Off the grid</h2>
<p>By highlighting some downsides of sharing data, you might feel the need to stop sharing data all together, but it is important to state that data sharing is not all bad. First of all, getting commercials tailored for you can be a good thing as you can get offers based off of previous purchases and get more effective services. Another great thing about sharing your data is that it can benefit scientists. Research on cancer be done studying patient data, why we are the way we are can be explored by looking at data from Facebook and so on. Looking at large sets of data can give us a better understanding of the world today.</p>
<p>The thing to think about is that you do not have to share your data all the time and to every app or website. For instance, a flashlight app does not need permissions to track your location. There are ways of sharing less data by limiting the apps on your phone to only sharing location data when the app is used or turning it completely of when you are not active on your phone.&nbsp;</p>
<p>When it is all said and done it is&nbsp;<em>your</em>&nbsp;data.</p></section></article></div>]]>
            </description>
            <link>https://security.christmas/2020/10</link>
            <guid isPermaLink="false">hacker-news-small-sites-25374120</guid>
            <pubDate>Thu, 10 Dec 2020 14:40:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Adding native integrations to your app with FusionAuth and Xkit]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25374028">thread link</a>) | @mooreds
<br/>
December 10, 2020 | https://fusionauth.io/blog/2020/12/09/xkit-and-fusionauth/ | <a href="https://web.archive.org/web/*/https://fusionauth.io/blog/2020/12/09/xkit-and-fusionauth/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
              <p>FusionAuth and Xkit came together for this blog post to share how you can use our services to boost your engineering team’s productivity. If you’re working on growing your SaaS business, you know just how much your engineers have on their plates. At both FusionAuth and Xkit, we believe that outsourcing what you can – like authentication and integration infrastructure – lets your team focus on the products and services that drive your business.</p>

<!--more-->

<p>We’ve written this post to lay out how you can use our services together to simplify your auth and build native integrations into your app faster. No more telling your customers that the integrations they’ve been asking for are “on the roadmap”. Follow the steps below and you can ship them in no time.</p>

<h2 id="what-is-xkit">What is Xkit</h2>

<p>Xkit is a SaaS platform which makes integrating third party systems a snap. Suppose you are writing a recipe management application and are going to sell it for big money to all the cooks of the world. After some market research, you realize that you want to integrate with other services. Your users are clamoring for the ability to export the steps of a recipe to a Trello board for sharing and Dropbox for backups. These are all services with APIs.</p>

<p>End users can give your application access to their accounts with these services, but that takes some coding. There’s also a fair bit of hoop jumping: setting up API keys and OAuth consent screens, among other things.</p>

<p>This is the problem which Xkit solves. Xkit has built connections to many services; <a href="https://docs.xkit.co/docs/connecting-with-apps-overview">here’s a current list</a>. Once configured, your application can connect a user’s account with an external service to your application. I (Dan) was able to connect Trello and my app in about an hour. The user experience of connecting the external application is smooth and far better than something I could whip up in a day, let alone an hour.</p>

<h2 id="xkit-and-fusionauth-integration">Xkit and FusionAuth integration</h2>

<h3 id="install-fusionauth">Install FusionAuth</h3>

<p>FusionAuth offers <a href="https://fusionauth.io/docs/v1/tech/installation-guide/">a number of different methods you can use to install the service</a>. Once you’ve installed it, there’s a Setup Wizard to walk you through the next steps. You’ll need to create your application in the FusionAuth interface and then add a few elements to your application code base to fully implement the FusionAuth login flow. A <a href="https://fusionauth.io/docs/v1/tech/5-minute-setup-guide/">full, detailed setup guide</a> is also available. Feel free to create additional <a href="https://fusionauth.io/docs/v1/tech/core-concepts/users/">users via the FusionAuth administrative user interface</a>.</p>

<p>Once FusionAuth is installed and configured, you have a full featured user management system, ready to go. APIs to control everything, multi factor authentication, consent management, SAML, OIDC, and more, hosted wherever you want. There’s also FusionAuth Cloud, a managed services offering, if you don’t want to host FusionAuth yourself.</p>

<h3 id="install-xkit">Install Xkit</h3>

<p>After you’re set up with FusionAuth you’ll want to head over and <a href="https://app.xkit.co/sign-up">create your Xkit account</a>. Upon sign-up, Xkit will also prompt you with some basic information needed to set up the environment. Fill out those details and you’re good to go there.</p>

<p>To set up Xkit in your code base, you’ll need to add the script tag for <code>xkit.js</code> on your front-end:</p>

<div><div><pre><code><span>&lt;script </span><span>src=</span><span>"https://&lt;your-slug&gt;.xkit.co/xkit.js"</span><span>&gt;&lt;/script&gt;</span>
</code></pre></div></div>

<p>In addition, your users need a place to actually sign in to their apps, such as Dropbox for your cooking recipe sharers. The easiest way to do this is to direct users to the hosted integration catalog Xkit has set up for you:</p>

<div><div><pre><code><span>&lt;a</span> <span>href=</span><span>"https://&lt;your-slug&gt;.xkit.co"</span><span>&gt;</span>Integration Catalog<span>&lt;/a&gt;</span>
</code></pre></div></div>
<p>Alternatively, if you need more customization, you can embed Xkit’s catalog on your site and customize its styling to fit your look and feel (<a href="https://docs.xkit.co/docs/self-hosted-catalog">details here</a>). If you still need more flexibility, you can use the SDK.</p>

<h3 id="connect-fusionauth-with-xkit">Connect FusionAuth with Xkit</h3>

<p>Now that you have both FusionAuth and Xkit set up, you’ll need to connect the two. We do this by collecting some information from your FusionAuth dashboard and inputting it into Xkit.</p>

<p>Specifically, you’ll need to generate an RSA key and then add your “iss” claim, “aud” claim and JWKS URL into your Xkit account. This setup is <a href="https://docs.xkit.co/docs/fusionauth">fully documented</a>.</p>

<p><img src="https://fusionauth.io/assets/img/blogs/xkit-fusionauth-integration/rsa-keypair.png" alt="The generated RSA key for use with Xkit."></p>

<p>Once you’ve done that and clicked save, FusionAuth and Xkit will be connected. Huzzah!</p>

<p>You can now have your users log in using FusionAuth’s Login API. You’ll get a JWT from FusionAuth on successful user authentication. This JWT can then be sent to Xkit to authenticate the user in Xkit, and therefore grant them access to integrations you’ve configured.</p>

<p>In your code base you can log your user into Xkit simply by using your FusionAuth ID token:</p>

<div><div><pre><code><span>//...</span>
<span>xkit</span><span>.</span><span>ready</span><span>(()</span> <span>=&gt;</span> <span>{</span>
  <span>xkit</span><span>.</span><span>login</span><span>(</span><span>'</span><span>eyJhbGciOi...</span><span>'</span><span>)</span>
<span>})</span>
<span>//...</span>
</code></pre></div></div>

<p>This easy JWT-based connection saves you the trouble of dealing with API keys and provisioning users for Xkit; you can instead maintain them in FusionAuth. You can also use FusionAuth for all your other applications, providing one view of all your users.</p>

<p>The security minded among you will notice that this JWT is available in the DOM, and therefore exposed to cross site scripting attacks, should any malicious JavaScript be executed on the same page. To minimize the risks, lock the permissions associated with this JWT down and don’t allow its use as a bearer token for any other more sensitive APIs or services.</p>

<h2 id="add-an-integration">Add an integration</h2>

<p>Now to actually set up your first integration! Say you want your users to be able to connect their Trello accounts with your app. To do this, you’ll first need to get an <a href="https://trello.com/app-key">Trello API key</a>.</p>

<p><img src="https://fusionauth.io/assets/img/blogs/xkit-fusionauth-integration/xkit-trello-screenshot.png" alt="The Xkit Trello integration screen."></p>

<p>Next you’ll need to add Trello as a connector in your Xkit platform and provide Xkit with the API key. After filling out a bit more information in the Xkit Trello connector page to set the permissions you require and what your users see when they’re connecting the app, you’ll click save.</p>

<p>You’re now ready to retrieve access tokens! You simply make one API call to retrieve a user’s fresh access token:</p>

<div><div><pre><code><span>const</span> <span>trelloToken</span> <span>=</span> <span>await</span> <span>xkit</span><span>.</span><span>getConnectionToken</span><span>(</span><span>"</span><span>trello</span><span>"</span><span>)</span>
</code></pre></div></div>

<p>If the token isn’t available, you should send the user to the appropriate place in your integration catalog to connect it.</p>

<div><div><pre><code><span>//...</span>
<span>if</span> <span>(</span><span>!</span><span>trelloToken</span><span>)</span> <span>{</span>
  <span>window</span><span>.</span><span>location</span><span>.</span><span>href</span> <span>=</span> <span>xkit</span><span>.</span><span>connectorUrl</span><span>(</span><span>"</span><span>trello</span><span>"</span><span>)</span>
<span>}</span>
<span>//...</span>
</code></pre></div></div>

<p>Behind the scenes here, Xkit handles all the complicated parts of managing the access tokens — dealing with each SaaS app’s protocol differences, token expirations, refresh tokens, protection against CSRF attacks, token encryption and more — so that it’s as simple as one API call for you. This setup also makes it easy to retrieve the token anywhere in your stack, be it in Cloud Functions, on the front-end, from your web server, etc. You can then use the token to make calls to the Trello API.</p>

<p>To add integrations to other apps, you follow essentially the same steps and retrieve the token with the same API call. Specific guides for different apps <a href="https://docs.xkit.co/docs/connecting-with-apps-overview">can be found here</a>.</p>

<p>We’re always looking for feedback and suggestions so let us know your thoughts! Thanks for reading.</p>

<p>This post can also be found on the <a href="https://xkit.co/post/adding-native-integrations-to-your-app-with-xkit-and-fusionauth">Xkit blog</a>.</p>

            
          </div></div>]]>
            </description>
            <link>https://fusionauth.io/blog/2020/12/09/xkit-and-fusionauth/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25374028</guid>
            <pubDate>Thu, 10 Dec 2020 14:31:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Top React libraries you need to know in 2021]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25373927">thread link</a>) | @oczek
<br/>
December 10, 2020 | https://blog.graphqleditor.com/react-libs-2021/ | <a href="https://web.archive.org/web/*/https://blog.graphqleditor.com/react-libs-2021/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Last time we looked a bit at the background and some built-in features of React. As promised it’s now time to look at some optional tools. Just like with Vue and Angular, components play a big role here and as usual you can create your own or use some of those made by the rapidly growing community. Let’s take a look at React libraries you should check before 2020 ends.</p>
<h2>React based frameworks</h2>
<p>If you’re planning on working with React most likely you’re going to have to pick between two starter frameworks, Gatsby.js and Next.js. React by itself works only on the client side and does not provide server side rendering, while those two build on top of React and provide SSR/SSG. Both also follow JAMStack architecture and provide you with a boilerplate which helps speed up and simplify the development process. That’s enough about similarities and let’s look at what the choice boils down to:</p>
<ul>
<li><strong><a href="https://www.gatsbyjs.com/">Gatsby.js</a>:</strong> generates HTML via server side generator during the build time, this means you don’t need a Node.js server to handle rendering and you’ll have HTML files ready right after build.  Data fetching is handled via GraphQL which has its benefits (you only fetch what you need which saves resources and time) but also ties you to GraphQL which not everyone likes or wants to use. Prominent uses of Gatsby.js include Figma.com, React’s official site and State of Javascript.</li>
<li><strong><a href="https://nextjs.org/">Next.js</a>:</strong> renders pages via server side rendering, this requires a Node.js server to run applications and handle dynamic HTML rendering. If you don’t like that Next.js also supports SSG since version 9.3. What you use for data fetching is up to you, hell you can even use GraphQL. Prominent uses of Next.js include TikTok, Hulu and Twitch mobile.</li>
</ul>
<p><span>
      <a href="https://blog.graphqleditor.com/static/16baf61b61b37e6763d3daa0a856b518/00d43/base.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="React based frameworks" title="React based frameworks" src="https://blog.graphqleditor.com/static/16baf61b61b37e6763d3daa0a856b518/fcda8/base.png" srcset="https://blog.graphqleditor.com/static/16baf61b61b37e6763d3daa0a856b518/12f09/base.png 148w,
https://blog.graphqleditor.com/static/16baf61b61b37e6763d3daa0a856b518/e4a3f/base.png 295w,
https://blog.graphqleditor.com/static/16baf61b61b37e6763d3daa0a856b518/fcda8/base.png 590w,
https://blog.graphqleditor.com/static/16baf61b61b37e6763d3daa0a856b518/efc66/base.png 885w,
https://blog.graphqleditor.com/static/16baf61b61b37e6763d3daa0a856b518/00d43/base.png 1000w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h5>Source: <a href="https://undraw.co/">undraw.co</a></h5>
<h2>State management</h2>
<p>State management is the most crucial part of any modern React app. Most of the time it is the biggest challenge any developer faces while working on their frontend project, especially when it comes to large and complex enterprise-grade commercial apps. Managing state is such a complex task that proper handling requires using external libraries, as at some point React itself will no longer be able to provide a satisfactory solution.</p>
<ul>
<li><strong><a href="https://redux.js.org/">Redux</a>:</strong> a predictable, standalone state container for JavaScript apps which helps you write applications that behave consistently and run in different environments. Being a standalone library means you can use Redux even if you don’t have a UI setup yet. Redux can be used with any UI framework i.e React, where you can describe your UI as a function of your state and make Redux keep track of your components state and update them accordingly in response to UI actions. Redux is definitely the most popular choice when it comes to state management with React with almost 5 million weekly downloads on NPM.</li>
<li><strong><a href="https://mobx.js.org/README.html">MobX</a>:</strong> a simple, scalable state management solution. It’s easier to learn and simpler to use than Redux and focuses on helping develop simpler apps with less boilerplate code. The main focus is reducing the number of bugs by mapping the relations between state and derivatives while maintaining referential integrity. Another plus is that it can be used either client side or server side and, as a JavaScript library, lets you keep the existing utilities of JS.</li>
</ul>
<p><span>
      <a href="https://blog.graphqleditor.com/static/50db609b41df6b682b0cc9f6dcf4ce10/00d43/state.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="State management" title="State management" src="https://blog.graphqleditor.com/static/50db609b41df6b682b0cc9f6dcf4ce10/fcda8/state.png" srcset="https://blog.graphqleditor.com/static/50db609b41df6b682b0cc9f6dcf4ce10/12f09/state.png 148w,
https://blog.graphqleditor.com/static/50db609b41df6b682b0cc9f6dcf4ce10/e4a3f/state.png 295w,
https://blog.graphqleditor.com/static/50db609b41df6b682b0cc9f6dcf4ce10/fcda8/state.png 590w,
https://blog.graphqleditor.com/static/50db609b41df6b682b0cc9f6dcf4ce10/efc66/state.png 885w,
https://blog.graphqleditor.com/static/50db609b41df6b682b0cc9f6dcf4ce10/00d43/state.png 1000w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h5>Source: <a href="https://undraw.co/">undraw.co</a></h5>
<h2>Forms</h2>
<p>Forms are present in most web and mobile apps.  Unlike Angular and Vue, which both give you a way to validate forms out of the box, React requires you to handle them all by yourself. Fortunately there are some libraries rushing to help you out.</p>
<ul>
<li><strong><a href="https://formik.org/">Formik</a>:</strong> is the most popular form library for React (and React Native). Formik is packed with dozens of micro features like different types of validation, handling API errors, auto-saving forms data and many more. It’s the result of the React community’s years of experience in terms of UI, security, accessibility etc. With Formik you can focus on developing your product instead of battling with all aspects of forms. It’s a well-tested and highly optimized solution, using which will leave you with less chances for unexpected errors and edge cases in your forms.</li>
<li><strong><a href="https://react-hook-form.com/">React Hook Forms</a>:</strong>  a light-weight form library for React, allowing you to achieve astonishing results with a minimal amount of code, which makes it very performance oriented. React Hook Forms is optimized to remove any unnecessary re-renders of your components by providing the developer a way to isolate component re-renders, improving performance of your mobile or web application. It is a great way to empower your applications with highly-performant, flexible, easy to use and manage forms.</li>
</ul>
<p><span>
      <a href="https://blog.graphqleditor.com/static/98a6ad12da0f3937ed7a8a1140dcd3d7/00d43/forms.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Forms" title="Forms" src="https://blog.graphqleditor.com/static/98a6ad12da0f3937ed7a8a1140dcd3d7/fcda8/forms.png" srcset="https://blog.graphqleditor.com/static/98a6ad12da0f3937ed7a8a1140dcd3d7/12f09/forms.png 148w,
https://blog.graphqleditor.com/static/98a6ad12da0f3937ed7a8a1140dcd3d7/e4a3f/forms.png 295w,
https://blog.graphqleditor.com/static/98a6ad12da0f3937ed7a8a1140dcd3d7/fcda8/forms.png 590w,
https://blog.graphqleditor.com/static/98a6ad12da0f3937ed7a8a1140dcd3d7/efc66/forms.png 885w,
https://blog.graphqleditor.com/static/98a6ad12da0f3937ed7a8a1140dcd3d7/00d43/forms.png 1000w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h5>Source: <a href="https://undraw.co/">undraw.co</a></h5>
<h2>Testing</h2>
<p>Test-driven development (TDD) is now one of the leading approaches to application development. It’s becoming more and more popular as it reduces the chance of major bugs occurring in the future. An obvious downside of test-driven development is that it usually takes longer to bring a product to market than while using a behavior-driven development approach. Fortunately there are some useful React libraries that can make writing tests a much easier task.</p>
<ul>
<li><strong><a href="https://enzymejs.github.io/enzyme/">Enzyme</a>:</strong> a JS testing utility that makes testing your React components super easy. You can manipulate, traverse and in some ways simulate runtime given the output. Enzyme was created internally at AirBnB and released as an open source project in 2015. The tool aims to be as easy as possible by providing an intuitive API inspired by jQuery’s API for DOM manipulation and traversal.</li>
<li><strong><a href="https://testing-library.com/docs/react-testing-library/intro/">React Testing Library</a>:</strong> a tool that lets you test React components without relying on their implementation details. This approach helps focus on accessibility as it basically puts you in the shoes of the end-user of the React app. The guiding principle here is that the more your tests look like the way your software is supposed to be used, the more confidence running them can give you. It’s much lighter and easier to get started with than Enzyme (which on the other hand has a lot more functions) and is the recommended testing app according to React’s docs.</li>
</ul>
<p><span>
      <a href="https://blog.graphqleditor.com/static/7e29fd12f75fb2f92d52f9bbc60ddbb5/00d43/test.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Tests" title="Tests" src="https://blog.graphqleditor.com/static/7e29fd12f75fb2f92d52f9bbc60ddbb5/fcda8/test.png" srcset="https://blog.graphqleditor.com/static/7e29fd12f75fb2f92d52f9bbc60ddbb5/12f09/test.png 148w,
https://blog.graphqleditor.com/static/7e29fd12f75fb2f92d52f9bbc60ddbb5/e4a3f/test.png 295w,
https://blog.graphqleditor.com/static/7e29fd12f75fb2f92d52f9bbc60ddbb5/fcda8/test.png 590w,
https://blog.graphqleditor.com/static/7e29fd12f75fb2f92d52f9bbc60ddbb5/efc66/test.png 885w,
https://blog.graphqleditor.com/static/7e29fd12f75fb2f92d52f9bbc60ddbb5/00d43/test.png 1000w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h5>Source: <a href="https://undraw.co/">undraw.co</a></h5>
<h2>UI</h2>
<p>If it goes for out of the box React components there’s a bunch of useful libraries made by the community to check out. Using these can help you in a variety of ways by providing practical and reusable solutions, which really impact the time and effort development takes.</p>
<ul>
<li><strong><a href="https://react-bootstrap.github.io/">React Bootstrap</a>:</strong> a UI kit which replaces Bootstrap’s JavaScript with React code. Arguably the best way to quickly start building UI as it has thousands of ready to use themes and resources. No wonder it’s among the most popular component libraries with over 700k weekly downloads on NPM.</li>
<li><strong><a href="https://material-ui.com/">Material UI</a>:</strong> a set of components created by Google based on their famous material design protocols. The components are self-sustaining in nature and only inject the styles they need to display. It also provides a lot of accessible and configurable UI widgets and ready to use site templates. This makes for a pretty significant performance boost especially considering the library is regularly updated and has very strong community support with over 60k stars on GitHub and is probably the most popular component library with over 1,6 mln weekly downloads on NPM.</li>
<li><strong><a href="https://rebassjs.org/">Rebass</a>:</strong> a tiny component library that packs a punch. Rebass contains only 8 components and weighs only 4 KBs but can be used to create a robust set of themable UI elements. It’s based on the Styled System library and focuses on providing a quick start for your development process. It’s really handy if you don’t want to rely too much on community component libraries or you intend to create your own custom UI.</li>
<li><strong><a href="https://react.semantic-ui.com/">Semantic UI React</a>:</strong> the official React integration for Semantic UI. This offers all the extra functions of the jQuery based re-scripted in React code. Comes with tons of prebuilt components designed specifically to make it easier to work with and produce Semantic-friendly code.</li>
<li><strong><a href="https://ant.design/">Ant Design</a>:</strong> a design system for enterprise level products. Based on the Ant Design project it provides you with over 60 high quality components crafted based on a design language developed by the creators. The components are customizable and include support for dozens of languages. The focus is on helping build rich, interactive UIs for internal desktop applications (no worries there’s also Ant Design Mobile for mobile apps)</li>
</ul>
<p><span>
      <a href="https://blog.graphqleditor.com/static/b51248107ef9d2356e7d8a06b984aa04/00d43/ui.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="UI" title="UI" src="https://blog.graphqleditor.com/static/b51248107ef9d2356e7d8a06b984aa04/fcda8/ui.png" srcset="https://blog.graphqleditor.com/static/b51248107ef9d2356e7d8a06b984aa04/12f09/ui.png 148w,
https://blog.graphqleditor.com/static/b51248107ef9d2356e7d8a06b984aa04/e4a3f/ui.png 295w,
https://blog.graphqleditor.com/static/b51248107ef9d2356e7d8a06b984aa04/fcda8/ui.png 590w,
https://blog.graphqleditor.com/static/b51248107ef9d2356e7d8a06b984aa04/efc66/ui.png 885w,
https://blog.graphqleditor.com/static/b51248107ef9d2356e7d8a06b984aa04/00d43/ui.png 1000w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h5>Source: <a href="https://undraw.co/">undraw.co</a></h5>
<h2>Join up!</h2>
<p>Obviously that’s just a few popular libraries, there’s a myriad more and everyone will easily find some useful ones. Most of them aren’t complicated and take a short while to get a hang of, which is time well invested considering they usually speed up and simplify the development process by quite a bit. Creating everything yourself has its benefits, but all in all the rapidly growing and already sizable React community is probably the biggest advantage using it provides.</p></div><p>The GraphQL Editor is a supportive tool for both advanced GraphQL users as well as those taking their first steps with GraphQL APIs. Our all-in-one development environment for GraphQL will help you build, manage &amp; deploy your GraphQL API much faster thanks to dozens of built-in micro features. Its graphical interface will also fix communication within your product team. Visualization is the key!</p></div>]]>
            </description>
            <link>https://blog.graphqleditor.com/react-libs-2021/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25373927</guid>
            <pubDate>Thu, 10 Dec 2020 14:20:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: A DIY particle detector kit developed at CERN]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25373912">thread link</a>) | @kasbah
<br/>
December 10, 2020 | https://shop.kitspace.org/buy/electron-detector/ | <a href="https://web.archive.org/web/*/https://shop.kitspace.org/buy/electron-detector/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>A kit to make the electron detector variant of the DIY Particle Detector project.</p><p>This open hardware project is a mobile low-cost detector for measuring ionising radiation like electrons from beta radiation (plus some gamma photons). It's an educational tool and citizen science device made for exploring natural and synthetic sources of radioactivity such as stones, airborne radon, potassium-rich salt or food and every-day objects (Uranium glass, old Radium watches etc.).</p><p>This project is developed by Oliver Keller at CERN, see full project details <a href="https://kitspace.org/boards/github.com/ozel/diy_particle_detector/electron-detector/">here.</a></p><p>This is a kit to make your own electron detector. A required metal enclosure (see the<!-- --> <a href="https://github.com/ozel/DIY_particle_detector/wiki/Enclosures">wiki</a>) and a 9V battery are not included.</p><div><p><span>Worldwide Shipping (estimated delivery by Monday, December 21, 2020)</span></p><p><span>€15.00</span></p></div><p><b>Total: </b><b>€45.00</b></p></div></div>]]>
            </description>
            <link>https://shop.kitspace.org/buy/electron-detector/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25373912</guid>
            <pubDate>Thu, 10 Dec 2020 14:18:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Intercepting system calls to fix broken software]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25373860">thread link</a>) | @todsacerdoti
<br/>
December 10, 2020 | https://yairchu.github.io/posts/intercept-to-fix | <a href="https://web.archive.org/web/*/https://yairchu.github.io/posts/intercept-to-fix">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <p>Apple sure like to change things, so when my new computer shipped with the new macOS 11.0, some things didn't work - specifically the Haskell compiler, GHC, failed linking my programs with OpenGL and other system libraries.</p>
<p><a href="https://gitlab.haskell.org/ghc/ghc/-/issues/18446">The problem</a> is already fixed in the GHC git repository, and I could try building it, but that might send me on new adventures due to more new-version behaviours, so instead I looked into working around the problem by making macOS 11 behave like macOS 10 did in the way that GHC expects!</p>
<h3 id="short-problem-description">Short problem description</h3>
<p>When linking with OpenGL, GHC verifies that the file <code>/System/Library/Frameworks/OpenGL.framework/OpenGL</code> exists, but it no longer does!</p>
<p>We can't add the file there (not even with <code>sudo</code>) because macOS's <code>/System</code> folder is special.</p>
<h3 id="solution">Solution</h3>
<p>We can trick GHC to believe that the file exist, and then everything would work!</p>
<p>This can be done by hijacking its calls to the <a href="https://en.wikipedia.org/wiki/Stat_(system_call)"><code>stat</code></a> system call and returning fake results.</p>
<p>MacOS lets us inject additional code into programs using the <code>DYLD_INSERT_LIBRARIES</code> environment variable, and it also supports special pragmas to tell it to replace library functions (aka "interpose" or "hook").</p>
<div id="cb1"><pre><code><span id="cb1-1"><span>int</span> my_stat (<span>const</span> <span>char</span>* <span>restrict</span> path, <span>struct</span> stat* <span>restrict</span> buf)</span>
<span id="cb1-2">{</span>
<span id="cb1-3">    <span>if</span> (STARTS_WITH (<span>"/System/Library/Frameworks/"</span>, path))</span>
<span id="cb1-4">    {</span>
<span id="cb1-5">        <span>// Pretend that the file exists</span></span>
<span id="cb1-6">        <span>return</span> <span>0</span>;</span>
<span id="cb1-7">    }</span>
<span id="cb1-8">    <span>return</span> stat (path, buf);</span>
<span id="cb1-9">}</span>
<span id="cb1-10"></span>
<span id="cb1-11">DYLD_INTERPOSE (my_stat, stat)</span></code></pre></div>
<p>The above injected code tricks GHC to believe that any file inside <code>/System/Library/Frameworks/</code> exists, and that makes it work!</p>
<p>To work around the problem when executing <code>ghc</code> from a build system, it takes a bit more work to make sure that the injection propagates to it, but my complete solution isn't too long, see: <a href="https://github.com/yairchu/macos11-haskell-workaround/">github.com/yairchu/macos11-haskell-workaround</a></p>
<ul>
<li><img src="https://yairchu.github.io/images/reddit.svg" alt="reddit"> <a href="https://www.reddit.com/r/haskell/comments/k9r2cy/workaround_for_haskell_woes_on_macos_11_big_sur/">r/haskell discussion</a> on this work-around</li>
<li>I want to get this workaround into the Haskell build tool <code>stack</code>, if you want that too then please share your opinion on <a href="https://github.com/commercialhaskell/stack/issues/5456">the issue</a>!</li>
<li>FYI: The Linux equivalent of <code>DYLD_INSERT_LIBRARIES</code> is called <a href="https://tbrindus.ca/correct-ld-preload-hooking-libc/"><code>LD_PRELOAD</code></a>, and it can do similar things on Linux.</li>
<li>Image by <a href="https://pixabay.com/illustrations/vaccine-syringe-antidote-cure-3314164/">LillyCantible</a> from PixaBay.</li>
</ul>

    <!--Share buttons-->
    
</article></div>]]>
            </description>
            <link>https://yairchu.github.io/posts/intercept-to-fix</link>
            <guid isPermaLink="false">hacker-news-small-sites-25373860</guid>
            <pubDate>Thu, 10 Dec 2020 14:14:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Never work as a software engineer in a startup]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25373431">thread link</a>) | @veebuv
<br/>
December 10, 2020 | https://www.buildingstartups.co/blog/never-work-as-a-software-engineer-in-a-startup | <a href="https://web.archive.org/web/*/https://www.buildingstartups.co/blog/never-work-as-a-software-engineer-in-a-startup">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I'm speaking in front of 200 people tomorrow on the topic around software development for startups. There are hundreds of books written on this so I'll try to condense my learnings from most.</p><p>Even though we're a startup company at <a href="#"></a><a href="#"></a><a href="#"></a><a href="#"></a>, I stopped hiring software engineers, hell I tried to unlearn and relearn a few things in the journey as well.</p><p>Confusing I know - I still have to grapple around the entirety of it all but the honest truth is being a software engineer alone will get you easily fired or unvalued in a startup.</p><p>You need to fire yourself from that role and re-hire yourself as a product engineer. I've referenced this point multiple times in my previous articles and I really stand by this.</p><p>I don't think this necessarily applies for larger companies when they're hiring specialists and algo heavy engineers, however in a startup you need to think about the product, the marketing and most important the customer.</p><p>There is a significant disconnect in larger firms from the creator (developer) to the end user, all the way from hierarchy, to Project Managers, to Product Managers, to Marketers, to Execs etc - but in a startup, if you push code up... it's up.</p><p>So whats so special about being a product engineer that a software engineer can't do? A few things:</p><h3>1. They carry a get shit done attitude</h3><p>Sure some engineers carry that too, these statements aren't binary or exclusive but address the vast majority. When you look at github discussions or you look at conference events where people share their discoveries, it's all based around the engineer - not as much around the customer.</p><p>So yes, product engineers have a get shit done attitude, keeping in mind that they need to push good work out, but are quick on their feet to understand how much of debt some technical decisions will be vs others. This will be understood better over time, and even after a decade of programming, I can confirm that there is no right or wrong answer, its extremely situational based.</p><h3>2. Business first, software second</h3><p>You should toughen up and realise that building on the latest and greatest tech will not make you a better engineer. You almost NEVER have as much a good reputation for being the engineer for a bad startup as you may of a good startup, even though your code in the bad startup might be worthy of awards and your code in the good startup might be worthy of firing. It's inherent you see - good code isn't coincidentally in good companies, its because the companies made the smart decision of hiring mini-CTOs, people who understood that their customer mattered as much as their code.</p><p>This doesn't mean you give up all morals and build on PHP(I'M JOKING :p), but it kinda does. Not PHP but any language that is deemed unfit just because it's popular or not. You do a direct risk analysis on what will get me to my next goal ASAP. Whether that's faster iteration, more features or modularised code bases.</p><h3>3. Customer first, business second</h3><p>It should all come down to how you can make the life of the customer as easy as possible when you're solving the problem for them. Sometimes business requirements become business requirements and not customer requirements, and if you're just a software engineer by title, you will be doing what you're told to do because thats the limitation you have, at least the limitation I had a couple of years ago.</p><p>By stepping out of that box and understanding that if the business requirements step outside of the customer requirements, you get to voice your opinion and more importantly add the kicker to your "opinion" by justifying it with your technical abilities, techies are badass, we're the makers, so in the end if we have the knowledge around consumerism AS well as execution, it'll make us bulletproof.</p><p>So yes, if you're in a startup - don't work as a software engineer, work as a product engineer. Your impact will be 10X I kid you not.</p><p>People will take you ALOT more seriously, you'll climb the ranks faster, your code will matter a lot more, and the impact will be at scale. Your work matters and there should be no reason why more people shouldn't experience your genius code, the way you can make that happen is by being product focused and ensuring your customers are having the best time of their life.</p><p>As with any post, I'm always always looking to learn and become better at what I do, so I'd love to hear what you have to say, good or bad 🙌</p><p>If you liked this, definitely follow me on for the similar stuff:</p><p>twitter: twitter.com/<a href="https://dev.to/veebuv">@veebuv</a><br>linkedin: linkedin.com/in/vaibhavnamburi<br>instagram:_veebuv</p><p>‍</p></div></div>]]>
            </description>
            <link>https://www.buildingstartups.co/blog/never-work-as-a-software-engineer-in-a-startup</link>
            <guid isPermaLink="false">hacker-news-small-sites-25373431</guid>
            <pubDate>Thu, 10 Dec 2020 13:26:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AR with SceneKit and Metal]]>
            </title>
            <description>
<![CDATA[
Score 143 | Comments 42 (<a href="https://news.ycombinator.com/item?id=25373105">thread link</a>) | @emllnd
<br/>
December 10, 2020 | https://emillindfors.com/blog/2020-12/ar-with-scenekit-and-metal/ | <a href="https://web.archive.org/web/*/https://emillindfors.com/blog/2020-12/ar-with-scenekit-and-metal/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Recently I found myself needing to process and visualize both point clouds and meshes in an iOS application utilizing ARKit, with the point cloud being gathered using the 2020 iPad “LiDAR” sensor. To enable maximum performance and content creation convenience I thought it would be nice to have both custom shaders and a regular, easy-to-work-with 3D hierarchy available. The best options available seemed to be Metal and SceneKit, which required some initial setup to get working together. That setup is detailed in this post.</p>
<p><em>If all this sounds unfamiliar see <a href="https://blog.halide.cam/lidar-peek-into-the-future-with-ipad-pro-11d38910e9f8">here</a>, <a href="https://developer.apple.com/metal/">here</a> and <a href="https://www.raywenderlich.com/2243-scene-kit-tutorial-getting-started">here</a> for introductions to these technologies.</em></p>












<a href="https://emillindfors.com/img/blog/2020-12/sceneKitAndPointCloud.webp">
    <picture>
        <source type="image/webp" srcset="https://emillindfors.com/img-preview/blog/2020-12/sceneKitAndPointCloud.webp">
        <source type="image/webp" srcset="https://emillindfors.com/img/blog/2020-12/sceneKitAndPointCloud.webp">
        <img src="https://emillindfors.com/img-fallback/blog/2020-12/sceneKitAndPointCloud.jpg">
    </picture>
</a>

<p>To help you recreate what I did, the post is accompanied by a GitHub repository showing the specifics: <a href="https://github.com/emllnd/ar-with-scenekit-and-metal">github.com/emllnd/ar-with-scenekit-and-metal</a>.</p>

<p><em>Note that the repo uses slightly confusing naming. XCode project name is “smTest” (for “SceneKit Metal test”), which leads to combinations such as smTestTest for the auto-generated unit testing project… not the best choice, but bear with me.</em></p>
<p><em>Also note that this is not really beginner level stuff, nor is having both SceneKit and Metal rendering usually required. If you just want to do some 3D+AR on iOS, good tech to start with would likely be either <a href="https://developer.apple.com/documentation/realitykit/">RealityKit</a>+<a href="https://developer.apple.com/documentation/realitykit/creating_3d_content_with_reality_composer">RealityComposer</a>, the more widely applicable tool <a href="https://tutorialsforar.com/creating-an-ar-app-for-ios-using-unity-and-arkit/">Unity</a> or just plain <a href="https://blog.pusher.com/building-an-ar-app-with-arkit-and-scenekit/">SceneKit</a>.</em></p>

<p>RealityKit seems like the future, but I was interested in custom shaping of meshes at runtime with e.g. geometry shaders and there did not (yet?) seem to be hooks for integrating that kind of processing in RealityKit.</p>
<p>Turns out those hooks do exist in SceneKit, which is an older and more mature technology. They can be used to implement custom render steps either before or after regular rendering. A helpful blog post with details that aided me with the ‘<strong>renderer didRenderScene</strong>’ hook can be found here: <a href="https://rozengain.medium.com/custom-metal-drawing-in-scenekit-921728e590f1">Custom Metal Drawing in SceneKit</a>. Thanks for the writeup Mr. Ippel!</p>
<p>I chose to get started with combining ARKit, SceneKit and custom Metal rendering by mashing two of Apple’s example applications together:</p>
<ul>
<li>The Scene Depth demo app (<a href="https://developer.apple.com/documentation/arkit/visualizing_a_point_cloud_using_scene_depth">Visualizing a Point Cloud Using Scene Depth</a>)</li>
<li>The default SceneKit AR project created by the XCode project wizard (creation steps depicted below)</li>
</ul>












<a href="https://emillindfors.com/img/blog/2020-12/newSceneKitARProj.webp">
    <picture>
        <source type="image/webp" srcset="https://emillindfors.com/img-preview/blog/2020-12/newSceneKitARProj.webp">
        <source type="image/webp" srcset="https://emillindfors.com/img/blog/2020-12/newSceneKitARProj.webp">
        <img src="https://emillindfors.com/img-fallback/blog/2020-12/newSceneKitARProj.jpg">
    </picture>
</a>


<p>The trickiest part was to get the depth blending working correctly. SceneKit and the custom Metal renderer of the Point Cloud demo use different depth buffer conventions, which caused a few moments of initial confusion before realizing I would have to adjust depth settings to make them compatible.</p>
<p>Initial depth buffer ranges <em>(from memory, might be incorrect)</em>:</p>
<ul>
<li>
<p>SceneKit:</p>
<ul>
<li>empty = zero</li>
<li>growing towards camera</li>
<li>range around 0.00-0.05</li>
</ul>
</li>
<li>
<p>SceneDepthPointCloud Metal renderer</p>
<ul>
<li>empty = negative infinity(?)</li>
<li>shrinking towards camera</li>
<li>range around 1.0-9.9995</li>
</ul>
</li>
</ul>
<p>To make the depth blending behave nicely and consistently, it was needed to set the proper depth blending mode (<em>shown as DepthStencilState –&gt; DepthCompareFunction in the XCode Frame Debugger</em>), to find matching value ranges for both depth buffers and to keep the 3D scenes of both renderers in their respective camera frustums (having good values for znear and zfar) so that they would not get culled off by being too near or too far.</p>












<a href="https://emillindfors.com/img/blog/2020-12/xcodeGPUFrameDebug.webp">
    <picture>
        <source type="image/webp" srcset="https://emillindfors.com/img-preview/blog/2020-12/xcodeGPUFrameDebug.webp">
        <source type="image/webp" srcset="https://emillindfors.com/img/blog/2020-12/xcodeGPUFrameDebug.webp">
        <img src="https://emillindfors.com/img-fallback/blog/2020-12/xcodeGPUFrameDebug.jpg">
    </picture>
</a>


<p>If you’re working in a recent Apple dev environment in a fairly empty project, there’s a good chance you can get started with GPU debugging right away. You just need to build and run your app and press the camera icon (and wait a bit):</p>












<a href="https://emillindfors.com/img/blog/2020-12/xcodeGPUFrameCaptureButton.webp">
    <picture>
        <source type="image/webp" srcset="https://emillindfors.com/img-preview/blog/2020-12/xcodeGPUFrameCaptureButton.webp">
        <source type="image/webp" srcset="https://emillindfors.com/img/blog/2020-12/xcodeGPUFrameCaptureButton.webp">
        <img src="https://emillindfors.com/img-fallback/blog/2020-12/xcodeGPUFrameCaptureButton.jpg">
    </picture>
</a>

<p><em>(from here: <a href="https://developer.apple.com/documentation/metal/frame_capture_debugging_tools/viewing_your_frame_graph">Viewing Your Frame Graph</a>)</em></p>
<p>If you crave more in-depth GPU debug options or have trouble getting started, more info can be found on the page about <a href="https://developer.apple.com/documentation/metal/frame_capture_debugging_tools">Frame Capture Debugging Tools</a> as well as the guide page for <a href="https://developer.apple.com/documentation/metal/frame_capture_debugging_tools/enabling_frame_capture">Enabling Frame Capture</a>.</p>

<p>For more specific details on how I combined the two renderers, see the changes included in the first few commits (Nov 24th &amp; 28th) on the <a href="https://github.com/emllnd/ar-with-scenekit-and-metal/commits/main">commits page</a> of the example repository. It shows the history of how I:</p>
<ul>
<li>started with a blank SceneKit AR project using the Project Wizard (<a href="https://github.com/emllnd/ar-with-scenekit-and-metal/commit/3d5358507d2824d0d57335d6988ec81d20291b9d">Initial commit</a>)</li>
<li>added custom Metal rendering as per Mr. Ippel’s <a href="https://rozengain.medium.com/custom-metal-drawing-in-scenekit-921728e590f1">post</a> (<a href="https://github.com/emllnd/ar-with-scenekit-and-metal/commit/75ad32f2012594ba3c09df9f351299d64f0ecb59">draws simple triangle, …</a>)</li>
<li>copied in the <a href="https://developer.apple.com/documentation/arkit/visualizing_a_point_cloud_using_scene_depth">SceneDepthPointCloud</a> demo and made sure the application still builds (<a href="https://github.com/emllnd/ar-with-scenekit-and-metal/commit/cbcdaf130a288a7ad68cd2a848ddd671269b93d6">builds with SceneDepthPointCloud …</a>)</li>
<li>fiddled with accumulation settings etc confusedly to get the thing closer to working (<a href="https://github.com/emllnd/ar-with-scenekit-and-metal/commit/39ba6d28e7f22ae202e20344c503a2136932f3ff">almost works …</a>)</li>
<li>and finally adjusted the depth blending, depth range and camera frustum settings to be able to see both scenes together (<a href="https://github.com/emllnd/ar-with-scenekit-and-metal/commit/4a60df6c60b380d72ec740171c3440ffa09ddc23">improved …</a>, <a href="https://github.com/emllnd/ar-with-scenekit-and-metal/commit/39c9a0e7a997567ca978e1190b67cd2af9790666">draws both …</a>)</li>
</ul>

<p>The end result of all these steps can be seen in motion below. It is of course merely the starting point for a more interesting application that leverages the ease and speed of regular 3D asset workflows and selectively applies the power of customized GPU processing as needed.</p>



<p><iframe src="https://player.vimeo.com/video/485931370?title=0&amp;byline=0&amp;portrait=0" frameborder="0" allow="autoplay; fullscreen" allowfullscreen=""></iframe></p>



<p>At the time of first publication of this post (Dec 2020) I’m not sure if the depth buffer is entirely in sync between the two renderers, even though they both do render simultaneously. The point cloud looks alright behind the rocketplane(? 😄), but I’m not sure whether they behave correctly in overlap situations. However, the fix should be just a matter of adjusting camera and depth buffer parameters and possibly scene scale (<em>famous last words…</em>).</p>
<p>If and when time permits, I will update the post and the repository with improved details.</p>
<p>Thanks for reading!</p>


    	</div></div>]]>
            </description>
            <link>https://emillindfors.com/blog/2020-12/ar-with-scenekit-and-metal/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25373105</guid>
            <pubDate>Thu, 10 Dec 2020 12:46:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lessons from Running a Sale That Earned 3 Month's Profit in a Week]]>
            </title>
            <description>
<![CDATA[
Score 185 | Comments 42 (<a href="https://news.ycombinator.com/item?id=25372636">thread link</a>) | @czue
<br/>
December 10, 2020 | https://www.coryzue.com/writing/black-friday/ | <a href="https://web.archive.org/web/*/https://www.coryzue.com/writing/black-friday/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
                <p>A few weeks ago I was in a bad place.</p>

<p>My product Pegasus—a <a href="https://www.saaspegasus.com/">Django boilerplate for SaaS applications</a>—was 
having its worst sales slump in recent history.
Meanwhile, my other product, Place Card Me—an <a href="https://www.placecard.me/">online place card maker</a>—continued
to be hit hard by the pandemic, with sales down almost $10,000 from 2019.
It looked like I was going to fall short on my targets for the month. 
<em>Again</em>.</p>

<p><img src="https://www.coryzue.com/images/black-friday/place-card-me-2020.png" alt="Place Card Me"></p>

<p>The grey line is Place Card Me’s profits in 2019. The purple line is 2020. Thanks, Covid.</p>

<p>And then on a lark I thought, “well maybe I’ll try running a Black Friday sale.”</p>

<p><strong>And my month’s trajectory completely changed.</strong></p>

<p>A few hours of work and a week later, and I had shattered my previous earnings for any month—earning
more than 3 months’ worth of typical profit in a single week.</p>

<p>Through the process, I learned a lot about running sales—lessons I thought I should share.
Because Black Friday <em>is</em> a huge opportunity for online creators and indie hackers. 
One that—if you’re anything like me—you’re probably not taking full advantage of.</p>

<p>Here’s what I did and what I learned along the way.</p>

<h2 id="deciding-to-run-a-sale-by-overcoming-the-ickiness-factor">Deciding to run a sale by overcoming the “ickiness factor”</h2>

<p>If you’re like me, your first reaction to the idea of a Black Friday sale might be something along the lines of 
“ugh, those are so overdone and spammy”.
And it’s true, Black Friday and Cyber Monday sales have become ubiquitous online.</p>

<p><em>But Black Friday sales aren’t inherently bad.</em></p>

<p>Many consumers, including myself, happily take place in Black Friday deals.
They’re a great way to support creators and pick up products you’ve long considered buying.</p>

<p>To get over my fear of “Black Friday ickiness”, I decided to turn to other successful creators who were also running deals.
Adam Wathan and Steve Shoger of <a href="https://tailwindui.com/">Tailwind UI</a> / <a href="https://refactoringui.com/">Refactoring UI</a>;
online educator extraordinaire <a href="https://wesbos.com/">Wes Bos</a>;
fellow solopreneur <a href="https://mtlynch.io/">Mike Lynch</a> for his product <a href="https://tinypilotkvm.com/">TinyPilot</a>.
How were they doing Black Friday and what could I learn from them?</p>

<p>My favorite example came from Wes Bos, which <a href="https://marketingexamples.com/">Harry’s Marketing Examples</a>
did a great job analyzing:</p>

<p><img src="https://www.coryzue.com/images/black-friday/wes-bos-black-friday.jpeg" alt="Wes Bos Black Friday"></p>

<p>Wes Bos’s “masterful” Black Friday email. Image and analysis from <a href="https://twitter.com/GoodMarketingHQ/status/1331573176405536769">Harry’s Marketing Examples</a></p>

<p>This email and the others I looked at all shared similar qualities.
They were <em>genuine</em>, they <em>put the reader first</em>, and they <em>weren’t too pushy</em>.
It was “hey, here’s a great deal in case you’re interested, if not, sorry to bug you.”</p>

<p>Seeing that it was possible to run a deal in a classy way was enough to get me over the “ickiness” factor,
and provided a framework for crafting my own sales communications.</p>

<p><strong>Lesson: Running a sale doesn’t have to be “icky” if you do it right.</strong></p>

<h2 id="choosing-the-right-sale-structure-by-adding-value">Choosing the right sale structure by <em>adding value</em></h2>

<p>People expect Black Friday deals to offer a huge discount from normal prices—particularly 
for online products. Here’s a typical deal I received, with bundle of fonts being offered at 95% off 
the normal price:</p>

<p><img src="https://www.coryzue.com/images/black-friday/wild-ones-black-friday.png" alt="Wild Ones Font Bundle"></p>

<p>A typical Black Friday deal—offering 95%-off a bundle of commercial fonts.</p>

<p>Offering a huge discount is a great way to drive sales, but it comes with a huge cost. 
<em>Literally</em>. A big discount will substantially reduce your revenue-per-customer and 
leave money on the table.</p>

<p>And that’s not the only problem.</p>

<p>In addition to the lost revenue, <em>massive discounts devalue your product</em>.
If your customers know that you sometimes sell your product for 95% off, they’re likely 
to think it’s only worth 5% of it’s price.
<em>You’ve just turned your valuable good into a commodity.</em></p>

<p>So how do you run a sale without reducing your prices? <strong><em>You add value.</em></strong></p>

<p>Take Adam Wathan and Steve Shoger’s deal.
They took their two products, <a href="https://tailwindui.com/">Tailwind UI</a> (normally $249) and 
<a href="https://refactoringui.com/">Refactoring UI</a> (normally $149), and bundled them together for $279.
Their customers are simultaneously <em>saving $120</em> while <em>paying more than the price of either individual product.</em>
This is adding value at its finest.</p>

<p><img src="https://www.coryzue.com/images/black-friday/refactoring-ui.jpg" alt="Refactoring UI Black Friday"></p>

<p>The Tailwind UI / Refactoring UI deal—which used bundling to offer 30% off while simultaneously increasing prices.</p>

<p><em>Bundling</em>—what Adam and Steve did by offering two products together at a discount—is a great way to 
add value while not lowering prices.
A similar approach is to <em>offer increased benefits on a lower pricing tier</em>. 
This is the approach I took with my own product.</p>

<p>My product, <a href="https://www.saaspegasus.com/">SaaS Pegasus</a>, is designed to help people launch new web applications quickly.
Pegasus has two pricing tiers, a <em>single-site</em> version for $295, and an <em>unlimited</em> version for $750.
The product is the same, but the single-site version is only able to be used on—well—a single site,
while the unlimited version can be used on—you guessed it—unlimited sites.
The unlimited version also comes with lifetime updates to Pegasus itself, instead of just a year.</p>

<p>Anyway, the details aren’t important, but what <em>is</em> important is that more than 90% of my customers 
opt—at least initially—for single-site. 
So for my Black Friday deal I decided to offer the unlimited version at price of single-site. 
This allowed me to offer a 60% discount without significantly reducing my revenue per customer
or devaluing my product.</p>

<p>Whether you use bundling, the “increased benefits on a lower tier” approach, or something else, 
adding value is a great way to create a “Black Friday deal” feeling while not incurring 
some of the financial and psychological costs associated with heavy discounting.</p>

<p><strong>Lesson: Don’t lower prices, add value.</strong></p>



<p>Ok, you’ve gotten over the ickiness factor and you’ve chosen a sale structure that adds value.
Now’s the most important part: <em>spreading the word</em>.</p>

<p>When considering how best to get the word out, think of the following breakdown.
Everyone is either <em>interested</em> or <em>not interested</em> in your sale.
Likewise everyone will either <em>find out</em> or <em>not find out</em> about it.
This creates four buckets that any person might fall into:</p>

<p><img src="https://www.coryzue.com/images/black-friday/sale-matrix.png" alt="Sale Categorization Breakdown"></p>

<p>Breakdown of the possible ways people can experience your sale.</p>

<p>The two green boxes are what you’re aiming for. 
Of course, you want everyone who might be interested in the sale to find out about it—these are your potential customers!
Also, you want everyone who <em>isn’t</em> interested in the sale to not get spammed by it—the blissfully unaware.</p>

<p>The tradeoffs and mistakes happen in the red boxes.
What you really want to prevent is <em>lost customers</em>—people who would have been interested in the deal
but never knew it was happening.
You also want to annoy as few people as possible, but <em>it’s generally better to promote the deal to someone who wasn’t interested
than to have someone who was interested miss it</em>. 
The upside of a potential sale clearly outweighs the downside of mildly annoying someone.</p>

<p><strong>Lesson: Default to promoting everywhere that the signal-to-noise ratio isn’t terrible.</strong></p>

<h3 id="where-to-promote-your-sale">Where to promote your sale</h3>

<p>The key avenues for promotion—in order of importance—are your <em>website</em>, your <em>email list</em>, and <em>other online marketing channels</em>.</p>

<p><strong>Your website is your best source of potential customers.</strong></p>

<p>No one is more likely to be interested in your deal than someone who is already browsing your product website,
so you should do everything you can to ensure all website visitors see your deal.</p>

<p>I used the common technique of splashing a big-ass colorful banner on every page of the site.
Here’s what it looked like.</p>

<p><img src="https://www.coryzue.com/images/black-friday/pegasus-sale.png" alt="Pegasus Sale"></p>

<p>Don’t be shy promoting your sale on your website. These are the people most likely to benefit from it.</p>

<p>Your goal is to make it impossible for someone visiting your website to not hear of the sale,
so err on the side of flashy, even if it seems a bit much.</p>

<p><strong>Your email list is your next best source of potential customers.</strong></p>

<p>People on your email list were interested in your product at one point, and so are more likely
than almost anyone else to still be interested, so make sure to let them know!</p>

<p>My email sequence consisted of two mails:</p>

<ol>
  <li>An email at the start of the sale telling people about it.</li>
  <li>An email with 24 hours left in the sale telling people it was about to end.</li>
</ol>

<p>Some people add a third email in the middle—often with 48 hours to go. 
I don’t recommend more than 3 emails as you seriously risk pushing people 
further into the “annoyed” category.</p>

<p>In terms of email copy—you can’t do better than the Wes Bos example above.
But for the sake of transparency, here’s the mail I used:</p>

<p><img src="https://www.coryzue.com/images/black-friday/pegasus-email.png" alt="Pegasus Email"></p>

<p>The first email in my sequence announcing the Pegasus Black Friday deal.</p>

<p>One difference between Wes and I is that my email list is <em>cold</em>—I almost never use it.
So I added a reminder for people who might be wondering what Pegasus even was.
I also included details on some new features to show that I’m still improving the product.</p>

<p><strong>All other channels besides your website and email list are a distant third in terms of usefulness.</strong></p>

<p>For this reason, I severely limited promotion in other places unless they were 
specifically aggregating Black Friday deals—and therefore unlikely to annoy anyone.</p>

<p>Depending on your product and audience, social media can be a good channel, though it’s not for Pegasus
so I didn’t bother promoting there.<sup id="fnref:2"><a href="#fn:2">1</a></sup></p>



<p>It’s important to realize that unless you did something very wrong, 
<strong><em>people will be more likely to purchase your product during a sale than at any other time.</em></strong></p>

<p>Now, if you’ve taken the advice above and are still getting good revenue-per-customer during
the sale, there is an interesting side-effect:
<strong>website traffic <em>during a sale</em> is more valuable than at any other time</strong>.</p>

<p>I’ll show you just how much more valuable it was for me in the next section <em>(preview: it was way more than I expected)</em>.</p>

<p>In practice, this means that any additional effort you can expend to get people to your website—for any reason—will 
have a higher payoff during a sale.</p>

<p>How you leverage this information depends on your marketing strategy.
If you’re running ads, consider increasing your budget while the sale is running;
if you do content marketing, consider publishing your next big article during the sale, etc.
These efforts—while not necessarily directly related to the sale—will have the side-effect of getting
more eyes on your site at the exact moment your …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.coryzue.com/writing/black-friday/">https://www.coryzue.com/writing/black-friday/</a></em></p>]]>
            </description>
            <link>https://www.coryzue.com/writing/black-friday/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25372636</guid>
            <pubDate>Thu, 10 Dec 2020 11:47:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Eisenhower Matrix – How to Prioritise and Master Tasks]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25372423">thread link</a>) | @rossnoel
<br/>
December 10, 2020 | https://productive.fish/blog/eisenhower-matrix/ | <a href="https://web.archive.org/web/*/https://productive.fish/blog/eisenhower-matrix/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>30 Oct 2020 • 5 min read</p><p>Throughout his life, President Dwight D. Eisenhower was well known as a man of productivity. Before he was president, he was a five start general of the US Army, being a key strategist for many invasions against the Nazis in World War II. On becoming President, he launched many of the significant projects and departments that are still integral to the USA today, such as the interstate highway system, NASA and DARPA. His productivity became well-renowned and researched, and by far one of the most useful strategies he's credited for devising is the Eisenhower Matrix. A simple method to deploy in our everyday lives, it can help you increase productivity, avoid procrastination, and order your workflow. So, what exactly is it and how does it work?</p><picture><source type="image/webp" media="(min-width: 1100px)" srcset="https://productive.fish/blog/eisenhower-matrix/eisenhower-matrix.webp, https://productive.fish/blog/eisenhower-matrix/eisenhower-matrix@2x.webp 2x"><source type="image/webp" media="(max-width: 1099px) and (min-width: 421px)" srcset="https://productive.fish/blog/eisenhower-matrix/eisenhower-matrix-md.webp, https://productive.fish/blog/eisenhower-matrix/eisenhower-matrix-md@2x.webp 2x"><source type="image/webp" media="(max-width: 420px)" srcset="https://productive.fish/blog/eisenhower-matrix/eisenhower-matrix-sm.webp, https://productive.fish/blog/eisenhower-matrix/eisenhower-matrix-sm@2x.webp 2x"><source media="(min-width: 1100px)" srcset="https://productive.fish/blog/eisenhower-matrix/eisenhower-matrix.jpg, https://productive.fish/blog/eisenhower-matrix/eisenhower-matrix@2x.jpg 2x"><source media="(max-width: 1099px) and (min-width: 421px)" srcset="https://productive.fish/blog/eisenhower-matrix/eisenhower-matrix-md.jpg, https://productive.fish/blog/eisenhower-matrix/eisenhower-matrix-md@2x.jpg 2x"><source media="(max-width: 420px)" srcset="https://productive.fish/blog/eisenhower-matrix/eisenhower-matrix-sm.jpg, https://productive.fish/blog/eisenhower-matrix/eisenhower-matrix-sm@2x.jpg 2x"><img src="https://productive.fish/blog/eisenhower-matrix/eisenhower-matrix.jpg" alt="Illustration of person watching on Eisenhower Matrix and thinking"></picture><h2 id="what-is-the-eisenhower-matrix%3F">What is the Eisenhower Matrix?</h2><p>The method begins by creating a 2x2 matrix. On the X axis of our matrix we have Urgent and Not Urgent. On the Y axis, we have Important and Not Important. With these different boxes, we have four quadrants, each with a different value, and as such, each to be handled very differently.</p><p>The four quadrants are essentially divided into the following categories:</p><ul><li>Urgent and important - <strong>do it</strong></li><li>Important, but not urgent - <strong>schedule it</strong></li><li>Urgent, but not important - <strong>delegate i</strong>t</li><li>Neither urgent, nor important - <strong>eliminate it</strong></li></ul><p>The Eisenhower Matrix teaches us to swiftly recognise the importance and urgency of tasks on our to-do lists. By categorising the tasks in the above way we can figure out which ones to prioritise, which to put on the back-burner for later, which to delegate, and which to eliminate. This will both put your to-do list in an order of priority, and shrink it down.</p><p>But how do we distinguish between “urgent and important” and everything in between?</p><h2 id="what-are-%22urgent%22-and-%22important%22-activities%3F">What Are "Urgent" and "Important" Activities?</h2><p>Important things are, well, important.They are the things that move us closer to our defined goals, dreams, and aspirations in life. They have meaning and impact to what actually matters to us in our lives. Running in alignment with your values, important things include, going to the gym, spending time with your family, or coming up with a strategic plan for your business.</p><p>On the other hand, we have urgent things. Urgent things require your immediate attention like a call from an angry customer, or picking up your kid from the nurse's office at school.</p><p>More often than not, things don’t tend to be both important and urgent. A lot of the time we mistake urgent tasks as being inherently important, with their acute timeframe masking the true value of what they actually represent in our lives.</p><p>The Eisenhower Matrix is an amazing tool to combat this frequent “mislabelling” of tasks in our workflow, and by mapping out a matrix of urgency and importance, we get a clearer picture of what’s on our slate.</p><h2 id="how-to-use-the-eisenhower-matrix-effectively">How to Use the Eisenhower Matrix Effectively</h2><p>In order to implement the Eisenhower Matrix effectively, one must identify which of the four quadrants a task or a project sits in, and then give it the appropriate action. So what are the traits that come with each category, and (having filed the task appropriately) what should you do with it?</p><h3 id="quadrant-one%3A-urgent-and-important">Quadrant One: Urgent and Important</h3><p>These are tasks that are not only important, but also time sensitive. These might include taking care of a sick relative, addressing an order-dispute for your biggest customer or fixing a crucial bug on the company website. Hopefully you shouldn’t have too many of these but something landing in this box should be done immediately with everything else put aside to make space for it.</p><h3 id="quadrant-two%3A-important%2C-but-not-urgent">Quadrant Two: Important, But Not Urgent</h3><p>This is where some of the most important things in our lives live, and yet many people will see tasks piling up here. Why? Because these jobs are not urgent we often let them slide or delay into the indefinite. Whilst they might not have the immediacy of Quadrant One tasks, it’s important to recognise they are truly no less important.</p><p>These tasks include long-term strategy and planning meetings with your team, performing regular website maintenance, exercising, spending quality time with your friends and family, meditating, and sleeping enough.</p><p>These things won't pop out at you with red flashing lights, but there's no denying that they are extremely important. Indeed if not taken care of, they could soon turn into a hoard of urgent jobs bashing on the door of Quadrant One.</p><p>When it comes to Quadrant Two tasks, stop procrastinating and make a decision. Ask yourself, “When will I sit down and do these things?”. If you're a business owner or a manager in a company, these tasks are probably the most significant part of your job. It’s tempting to ignore Quadrant Two for the sake of addressing Quadrant Ones and Quadrant Threes, but come under no illusions, these need to be tackled, so schedule them in and stick to those deadlines.</p><h3 id="quadrant-three%3A-urgent%2C-but-not-important">Quadrant Three: Urgent, But Not Important</h3><p>We all hate to admit it, but a lot of the stuff we do, whilst urgent, is actually not important at all. For example, monitoring comments on your website or social media, attending a quarterly business update, or scheduling a Zoom meeting. Of course these are worth doing, but they’re just not important. Certainly not enough for you to actually do them yourself. That's why the answer to Quadrant Three tasks is a simple one: delegate. Find a technological solution, an automation, or a human being who can help you with this task and pass it off to them. Ideally you want to spend as little of your time as possible in Quadrant Three.</p><h3 id="quadrant-four%3A-not-urgent%2C-and-not-important">Quadrant Four: Not Urgent, and Not Important</h3><p>These represent a large category of tasks that aren't worth your time or anyone else’s for that matter (not even that programme or person you got to help you out in Quadrant Three). Some of these may be enjoyable, but they're not moving you towards your desired goals in any way, shape, or form. Things like watching television or scrolling through social media for example. While Quadrant Four tasks inevitably pervade our lives, look to try and eliminate these activities as much as possible.</p><h2 id="how-to-use-the-eisenhower-matrix-to-increase-productivity">How to Use the Eisenhower Matrix To Increase Productivity</h2><p>The Eisenhower Matrix is especially useful if you find yourself dealing with excessive amounts of work. With an overabundance of tasks, taking a bit of time to categorise your jobs into the four quadrants above can restore order to an otherwise chaotic workflow.</p><p>It’s also good to incorporate the overarching philosophy of this time management matrix into your daily workflow. Whether it’s on a daily or weekly basis, the Eisenhower Matrix will help prioritise the items on your to-do list. Look to commit to scheduling or prioritising your tasks as per the above, and you’ll find yourself with a clearer and more effective work-day</p><h2 id="conclusion">Conclusion</h2><p>The nature of our work-environment today, as shaped by email, instant messaging and the like, means we feel constantly in need of prioritising our requests in order of when the message was received. However, this approach often leaves us with a feeling of dissatisfaction with our own productivity, finding that the majority of the day has been spent handling items we could have delegated or just eliminated, and jobs that don’t progress our life-goals or objectives.</p><p>Instead, the Eisenhower Decision Matrix provides an excellent framework to help you cut through the clutter and finish your most important work in record time, whilst making sure you’re not wasting precious hours and minutes on things that can either be done elsewhere or just not at all. By giving you the skill of distinguishing between which tasks truly demand your attention, and those that don’t, the Eisenhower Box will keep you focused on what’s important, and in doing so change not just the output you see in your day or your week, but also your life.</p></article></div>]]>
            </description>
            <link>https://productive.fish/blog/eisenhower-matrix/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25372423</guid>
            <pubDate>Thu, 10 Dec 2020 11:12:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Paul Chan: Drawings for Word Book by Ludwig Wittgenstein]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25372417">thread link</a>) | @mellosouls
<br/>
December 10, 2020 | https://greenenaftaligallery-viewingroom.exhibit-e.art/viewing-room/paul-chan | <a href="https://web.archive.org/web/*/https://greenenaftaligallery-viewingroom.exhibit-e.art/viewing-room/paul-chan">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="contentWrapper" tabindex="-1">
        <div>
    
    




                                                                    




  
            <section id="head-image">
                                                    <div id="screen-head-image">
                    







                                                                                            <div>
                <div>
                                    <div>
                                                <p><img alt="Paul Chan" src="https://s3.amazonaws.com/files.collageplatform.com.prod/image_cache/enlarge_2x/5e8ca70ea5aa2cee698b4567/726b414cb16ec1cc6726d4ebce11a7ff.jpeg" srcset="https://s3.amazonaws.com/files.collageplatform.com.prod/image_cache/enlarge/5e8ca70ea5aa2cee698b4567/726b414cb16ec1cc6726d4ebce11a7ff.jpeg 1x, https://s3.amazonaws.com/files.collageplatform.com.prod/image_cache/enlarge_2x/5e8ca70ea5aa2cee698b4567/726b414cb16ec1cc6726d4ebce11a7ff.jpeg 2x"></p>
                                                                    </div>
                                        
                </div>
            </div>
            </div>

                    </section>
                    <section id="modular-1">
                                                    <div id="screen-modular-1">
                    







                                                                            <div>
                <div>
                                    <div>
                        <div>
                                                    <div><p>Greene Naftali is pleased to present Paul Chan’s solo exhibition,<em>&nbsp;Drawings for Word Book by Ludwig Wittgenstein</em>. The artist’s fifth solo exhibition at the gallery,&nbsp;<em>Drawings for Word Book by Ludwig Wittgenstein</em>&nbsp;features a series of drawings Chan created as illustrations for his latest publication,&nbsp;<em>Word Book</em>, which was published in the fall of 2020.</p><p>

Word Book is now available to purchase at Greene Naftali or on&nbsp;<a href="https://bookshop.org/books/word-book-9781943263240/9781943263240">Bookshop.org</a>.</p></div>

                        
                                                                                                    </div>
                    </div>
                </div>
            </div>
                                                                                        <div>
                <div>
                                    <div>
                                                <p><img alt="Install 1" src="https://s3.amazonaws.com/files.collageplatform.com.prod/image_cache/enlarge/5e8ca70ea5aa2cee698b4567/245c01c71abf86bd6cbfef6a71d7189f.jpeg"></p><p>Paul Chan, Installation view, <em>Drawings for Word Book by Ludwig Wittgenstein</em>, Greene Naftali, New York, 2020</p>
                                                                    </div>
                                        
                </div>
            </div>
                                                                                        <div>
                <div>
                                    <div>
                                                <p><img alt="Image" src="https://s3.amazonaws.com/files.collageplatform.com.prod/image_cache/enlarge/5e8ca70ea5aa2cee698b4567/b49c23add2c71e580333b7b895c43369.jpeg"></p><p>Paul Chan<br>
<em>Spekulieren (to speculate)</em>, 2020<br>
Ink on paper<br>
Paper: 150 x 48 inches (381 x 243.8 cm) each<br>
Frames: 155 x 53 x 3 inches (393.7 x 134.6 x 7.6 cm) each</p>
                                                                    </div>
                                        
                </div>
            </div>
                                                                                        <div>
                <div>
                                    <div>
                                                <p><img alt="PC1214" src="https://s3.amazonaws.com/files.collageplatform.com.prod/image_cache/enlarge/5e8ca70ea5aa2cee698b4567/0e230a820fa187e879bad51339c680ed.jpeg"></p><div><p>Paul Chan</p>

<p><em>der Rotz (snot)</em>, 2020</p>

<p>Ink on paper</p>

<p>Paper: 30 x 22 inches (76.2 x 55.9 cm)</p>

<p>Frame: 36 x 28 1/4 x 1 1/2 inches (91.4 x 71.8 x 3.8 cm)</p></div>
                                                                    </div>
                                        
                </div>
            </div>
                                                                                        <div>
                <div>
                                    <div>
                                                <p><img alt="Install 2" src="https://s3.amazonaws.com/files.collageplatform.com.prod/image_cache/enlarge/5e8ca70ea5aa2cee698b4567/34b7bab79a5138d4b442fc86311a29fc.jpeg"></p><p>Paul Chan, Installation view, <em>Drawings for Word Book by Ludwig Wittgenstein</em>, Greene Naftali, New York, 2020</p>
                                                                    </div>
                                        
                </div>
            </div>
                                                                                        <div>
                <div>
                                    <div>
                                                <p><img alt="PC1221" src="https://s3.amazonaws.com/files.collageplatform.com.prod/image_cache/enlarge/5e8ca70ea5aa2cee698b4567/40191a918ce7a184267a0e52d59a5c89.jpeg"></p><div><p>Paul Chan</p>

<p><em>der Grieche, griechisch, Griechenland (the Greek, Greek, Greece)</em>, 2020<br>
Ink on paper<br>
Paper: 49 7/8 x 38 3/8 inches (126.7 x 97.5 cm)<br>
Frame: 53 1/8 x 41 5/8 x 1 3/4 inches (134.9 x 105.7 x 4.4 cm)</p></div>
                                                                    </div>
                                        
                </div>
            </div>
                                                                                        <div>
                <div>
                                    <div>
                                                <p><img alt="1232" src="https://s3.amazonaws.com/files.collageplatform.com.prod/image_cache/enlarge/5e8ca70ea5aa2cee698b4567/d63adb49f8927dbaf9d9120d142e15fe.jpeg"></p><div><p>Paul Chan</p>

<p><em>die Währung (currency)</em>, 2020</p>

<p>Ink on paper</p>

<p>Paper: 49 7/8 x 38 3/8 inches (126.7 x 97.5 cm)</p>

<p>Frame: 53 1/8 x 41 5/8 x 1 3/4 inches (134.9 x 105.7 x 4.4 cm)</p></div>
                                                                    </div>
                                        
                </div>
            </div>
                                                                                        <div>
                <div>
                                    <div>
                                                <p><img alt="1230" src="https://s3.amazonaws.com/files.collageplatform.com.prod/image_cache/enlarge/5e8ca70ea5aa2cee698b4567/4ccbacf5928be150df88f974583404dd.jpeg"></p><div><p>Paul Chan</p>

<p><em>die Nelke (carnation)</em>, 2020</p>

<p>Ink on paper</p>

<p>Paper: 49 7/8 x 38 3/8 inches (126.7 x 97.5 cm)</p>

<p>Frame: 53 1/8 x 41 5/8 x 1 3/4 inches (134.9 x 105.7 x 4.4 cm)</p></div>
                                                                    </div>
                                        
                </div>
            </div>
                                                                                        <div>
                <div>
                                    <div>
                                                <p><img alt="PC1239" src="https://s3.amazonaws.com/files.collageplatform.com.prod/image_cache/enlarge/5e8ca70ea5aa2cee698b4567/a6a882fac76424bfcfb651c5073d1c69.jpeg"></p><p>Paul Chan<br>
<em>Kurieren (or to cure / to heal)</em>, 2020<br>
Ink on paper<br>
Paper: 50 5/8 x 98 3/4 inches (128.6 x 250.8 cm)<br>
Frame: 54 5/8 x 102 3/4 x 2 7/8 inches (138.7 x 261 x 7.3 cm)</p>
                                                                    </div>
                                        
                </div>
            </div>
                                                                                        <div>
                <div>
                                    <div>
                                                <p><img alt="image" src="https://s3.amazonaws.com/files.collageplatform.com.prod/image_cache/enlarge/5e8ca70ea5aa2cee698b4567/536e7906b4c2f9175de38809a352bd93.jpeg"></p><p>Paul Chan, Installation view, <em>Drawings for Word Book by Ludwig Wittgenstein</em>, Greene Naftali, New York, 2020</p>
                                                                    </div>
                                        
                </div>
            </div>
                                                                                        <div>
                <div>
                                    <div>
                                                <p><img alt="1236" src="https://s3.amazonaws.com/files.collageplatform.com.prod/image_cache/enlarge/5e8ca70ea5aa2cee698b4567/ca92f09a88cebc5c088fbc5c160ab9c9.jpeg"></p><div><p>Paul Chan</p>

<p><em>versäumen (to fail to do something)</em>, 2020</p>

<p>Ink on paper</p>

<p>Paper: 49 7/8 x 38 3/8 inches (126.7 x 97.5 cm)</p>

<p>Frame: 53 1/8 x 41 5/8 x 1 3/4 inches (134.9 x 105.7 x 4.4 cm)</p></div>
                                                                    </div>
                                        
                </div>
            </div>
                                                                                        <div>
                <div>
                                    <div>
                                                <p><img alt="1228" src="https://s3.amazonaws.com/files.collageplatform.com.prod/image_cache/enlarge/5e8ca70ea5aa2cee698b4567/435474f572a5ea51183cb39f4ef77bd0.jpeg"></p><div><p>Paul Chan</p>

<p><em>die Galerie (gallery)</em>, 2020</p>

<p>Ink on paper</p>

<p>Paper: 49 7/8 x 38 3/8 inches (126.7 x 97.5 cm)</p>

<p>Frame: 53 1/8 x 41 5/8 x 1 3/4 inches (134.9 x 105.7 x 4.4 cm</p></div>
                                                                    </div>
                                        
                </div>
            </div>
                                                                                        <div>
                <div>
                                    <div>
                                                <p><img alt="Image" src="https://s3.amazonaws.com/files.collageplatform.com.prod/image_cache/enlarge/5e8ca70ea5aa2cee698b4567/05ce1ddb79994d1d57e75c31e196a091.jpeg"></p><p>Paul Chan, Installation view, <em>Drawings for Word Book by Ludwig Wittgenstein</em>, Greene Naftali, New York, 2020</p>
                                                                    </div>
                                        
                </div>
            </div>
                                                                                        <div>
                <div>
                                    <div>
                                                <p><img alt="PC1231" src="https://s3.amazonaws.com/files.collageplatform.com.prod/image_cache/enlarge/5e8ca70ea5aa2cee698b4567/51d0e12542a7abe6cd4abf50c2c9670e.jpeg"></p><p>Paul Chan<br>
<em>die Seuche (epidemic)</em>, 2020<br>
Ink on paper<br>
Paper: 50 1/2 x 136 inches (128.3 x 345.4 cm)<br>
Frame: 54 1/2 x 140 x 2 7/8 inches (138.4 x 355.6 x 7.3 cm)</p>
                                                                    </div>
                                        
                </div>
            </div>
                                                                                        <div>
                <div>
                                    <div>
                                                <p><img alt="PC1238" src="https://s3.amazonaws.com/files.collageplatform.com.prod/image_cache/enlarge/5e8ca70ea5aa2cee698b4567/3878040e54e07efdca13502efe0923fd.jpeg"></p><p>Paul Chan<br>
<em>Primitiv</em>, 2020<br>
Ink on paper<br>
Paper: 50 1/2 x 132 inches (128.3 x 335.3 cm)<br>
Frame: 54 5/8 x 136 1/8 x 2 7/8 inches (138.7 x 345.8 x 7.3 cm)</p>
                                                                    </div>
                                        
                </div>
            </div>
                                                                                        <div>
                <div>
                                    <div>
                                                <p><img alt="Image" src="https://s3.amazonaws.com/files.collageplatform.com.prod/image_cache/enlarge/5e8ca70ea5aa2cee698b4567/c541ffa5e5ba09489e6171fa16068a9f.jpeg"></p><p>Paul Chan, Installation view, <em>Drawings for Word Book by Ludwig Wittgenstein</em>, Greene Naftali, New York, 2020</p>
                                                                    </div>
                                        
                </div>
            </div>
                                                                                        <div>
                <div>
                                    <div>
                                                <p><img alt="Image" src="https://s3.amazonaws.com/files.collageplatform.com.prod/image_cache/enlarge/5e8ca70ea5aa2cee698b4567/da92b9c4f6efdc0029fe71cb68952dc9.jpeg"></p><p>Paul Chan, Installation view, <em>Drawings for Word Book by Ludwig Wittgenstein</em>, Greene Naftali, New York, 2020</p>
                                                                    </div>
                                        
                </div>
            </div>
                                                                                        <div>
                <div>
                                    <div>
                                                <p><img alt="PC1207" src="https://s3.amazonaws.com/files.collageplatform.com.prod/image_cache/enlarge/5e8ca70ea5aa2cee698b4567/04cb41e97395a842c81a5ffe26ad945b.jpeg"></p><div><p>Paul Chan</p>

<p><em>das Edelweiß (edelweiss)</em>, 2020</p>

<p>Ink on paper</p>

<p>Paper: 39 1/4 x 27 1/2 inches (99.7 x 69.9 cm)</p>

<p>Frame: 42 1/2 x 30 7/8 x 1 1/2 inches (108 x 78.4 x 3.8 cm)</p></div>
                                                                    </div>
                                        
                </div>
            </div>
                                                                                        <div>
                <div>
                                    <div>
                                                <p><img alt="PC1206" src="https://s3.amazonaws.com/files.collageplatform.com.prod/image_cache/enlarge/5e8ca70ea5aa2cee698b4567/0a9629b0741c17286d1eb109ae5b165b.jpeg"></p><div><p>Paul Chan</p>

<p><em>die Pflege, pflegen, der Pfleger (care, to take care, caretaker)</em>, 2020</p>

<p>Ink on paper</p>

<p>Paper: 39 1/4 x 27 1/2 inches (99.7 x 69.9 cm)</p>

<p>Frame: 42 1/2 x 30 7/8 x 1 1/2 inches …</p></div></div></div></div></div></section></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://greenenaftaligallery-viewingroom.exhibit-e.art/viewing-room/paul-chan">https://greenenaftaligallery-viewingroom.exhibit-e.art/viewing-room/paul-chan</a></em></p>]]>
            </description>
            <link>https://greenenaftaligallery-viewingroom.exhibit-e.art/viewing-room/paul-chan</link>
            <guid isPermaLink="false">hacker-news-small-sites-25372417</guid>
            <pubDate>Thu, 10 Dec 2020 11:10:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Burnt $72k testing Firebase and Cloud Run and almost went bankrupt]]>
            </title>
            <description>
<![CDATA[
Score 265 | Comments 373 (<a href="https://news.ycombinator.com/item?id=25372336">thread link</a>) | @bharatsb
<br/>
December 10, 2020 | https://blog.tomilkieway.com/72k-1/ | <a href="https://web.archive.org/web/*/https://blog.tomilkieway.com/72k-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>                
			<blockquote>
  <p>This is the story of how close we came to shutting down before even launching our first product, how we survived, and the lessons we learnt.</p>
</blockquote>

<p>In March, 2020, when COVID hit the world, our startup Milkie Way too was hit with a big blow and almost shut down. <strong>We burnt $72,000 while exploring and internally testing Cloud Run with Firebase within a few hours.</strong></p>

<p>In November 2019, after having the idea, I started developing <strong>Announce <a href="https://annc.in/">https://announce.today</a></strong>. The goal was to create an “MVP”, a functional V1 of the  product, and for this reason our code was based on a simple stack. We used JS, Python and deployed our product on Google App engine.</p>

<center>
<em>Announce on Desktop</em>
<img src="https://blog.tomilkieway.com/assets/images/post_images/anc-first-look.png" width="100%"><br>
</center>

<p>Having a very small team, our focus was on writing code, designing the UI and getting product ready. I spent minimal time in Cloud management, just enough to make us go live, and have basic development flow (cicd) going.</p>

<p>In the V1 web application, user experience was not the smoothest, but we just wanted to make a product that some of our users could experiment with, while we built a better version of Announce. With Covid hitting the world, we thought it was the best time to make a difference as Announce could be used by the governments to make announcements world wide.</p>

<p>Wouldn’t it be cool to have some rich data on the platform even if users don’t create content to begin with? This thought that led to another project, called <strong>Announce-AI</strong>. It’s purpose was to create rich content for Announce automatically. Rich data == events, safety warnings like earthquakes, and possibly local relevant news.</p>

<h3 id="some-technical-details">Some Technical Details</h3>
<p>To begin developing Announce-AI, we used Cloud Functions. As our bot scraping the web was fairly young, we believed light weight Cloud functions were the way to go. However, as we decided to scale, we ran into troubles because Cloud Functions have a timeout of ~9 minutes.</p>

<p>At this time we learn about Cloud Run, which then had a big free usage tier! Without understanding it completely, I asked my team to deploy a “test” Announce AI function on Cloud Run, and see it’s performance. The goal was to play around with Cloud Run, so we can learn and explore it really fast.</p>

<center>
<img src="https://blog.tomilkieway.com/assets/images/72K/cloud-run.jpg" width="80%"><br>
<em>Google Cloud Run</em></center>

<p>To keep it simple, as our experiment was for a very small site, we used Firebase for database, as Cloud Run doesn’t have any storage, and deploying on SQL server, or any other DB for a test run would have been an over kill.</p>

<p>I created a new GCP project ANC-AI Dev, set up $7 Cloud Billing budget, kept Firebase Project on the Free (Spark) plan. The worst case we imagined was exceeding the daily free Firestore limits if we faltered.</p>

<p>After some code modifications, we deployed the code, ran it by making few requests in middle of the day manually and then left it.</p>

<h3 id="nightmare-begins">Nightmare Begins</h3>
<p>Everything went fine on the day of test, and we got back to developing Announce. Next day after working, I went for a quick nap in late afternoon. On waking up I read few emails from Google Cloud, all sent within few minutes of each other.</p>

<center>
<em>First Email: Auto upgrade of our Firebase Project</em>
<img src="https://blog.tomilkieway.com/assets/images/72K/auto-upgrade.jpg" width="80%"><br>
</center>

<center>
<em>Second Email: Budget Exceeded</em>

<img src="https://blog.tomilkieway.com/assets/images/72K/budget.jpg" width="80%"><br>
</center>

<p>Luckily my card had a spending limit of $100 preset. This led to declining the charges, and Google suspending all our accounts with it.</p>

<center>
<em>Third email: Card was declined</em>

<img src="https://blog.tomilkieway.com/assets/images/72K/card-declined.jpg" width="80%"><br>
</center>

<p>I jumped out of the bed, logged into Google Cloud Billing, and saw a bill for ~$5,000. Super stressed, and not sure what happened, I clicked around, trying to figure out what was happening. I also started thinking of what may have happened, and how we could “possibly” pay the $5K bill.</p>

<p>The problem was, every minute the bill kept going up.</p>

<p>After 5 minutes, the bill read $15,000, in 20 mins, it said $25,000. I wasn’t sure where it would stop. Perhaps it won’t stop?</p>

<p>After two hours, it settled at a little short of $72,000.</p>

<p>By this time, my team and I were on a call, I was in a state of complete shock and had absolutely no clue about what we would do next. We disabled billing, closed all services.</p>

<p>Because we used same company card across all our GCP Projects, all our accounts and projects were suspended by Google.</p>

<h3 id="nightmare-continues">Nightmare Continues</h3>
<p>This happened on Friday evening, March 27th, 3 days before we had planned V1 of Announce to go live. Our product development was dead as Google suspended all our projects as they were tied to same credit card. My morale was as low as it could be, and the future of our company was unsure.</p>

<center>
<img src="https://blog.tomilkieway.com/assets/images/72K/suspended.jpg" width="80%"><br>
<em>All our Cloud Projects were suspended; development stopped</em></center>

<p>Once my mind made peace with this new reality, at midnight I sat down to actually investigate what happened. I started writing a document detailing all the investigations… I called this document: “Chapter 11”.</p>

<p>Two of my team members who were in this experiment also stayed up all night investigating and trying to make sense of what had happened.</p>

<p>The next morning on Saturday, March 28th, I called and emailed over a dozen law firms to book an appointment / have a chat with some attorney. All of them were away, but I was able to get response from one of them over email. Because the details of the incident are so complicated even for engineers, explaining this to an attorney in plain english was a challenge of its own.</p>

<blockquote>
  <p>As a bootstrapped company, there was no way for us to come up with $72K.</p>
</blockquote>

<p>By this time, I was well versed with Chapter 7 and Chapter 11 of Bankruptcy and mentally prepared of what could come next.</p>

<h3 id="some-breather--gcp-loopholes">Some Breather : GCP Loopholes</h3>

<p>On the Saturday after sending emails to lawyers, I started reading more and going through every single page in GCP Documentation. We did make mistakes, but it didn’t make sense that Google let us spend $72K without even making a payment on the project before!</p>

<center>
<img src="https://blog.tomilkieway.com/assets/images/72K/firebasegcp.jpg" width="80%"><br>
<em>GCP and Firebase</em></center>

<h4 id="1-automatic-upgrade-of-firebase-account-to-paid-account">1. Automatic Upgrade of Firebase Account to Paid Account</h4>
<p>We never anticipated this, nor was this ever displayed while signing up for Firebase. Our GCP project had billing connected to have Cloud Run execute, but Firebase was under Free plan (Spark). GCP just out of the blue upgraded it, and charged us for the amount it needed to.</p>

<p>It turns out this is their process as “Firebase and GCP are deeply integrated”.</p>

<h4 id="2-billing-limits-dont-exist-budgets-are-at-least-a-day-late">2. Billing “Limits” don’t exist. Budgets are at least a day late.</h4>
<p>GCP Billing is actually delayed by at least a day. In most of their documentation Google suggests using Budgets and auto shut-off cloud function. Well guess what, by the time the cut off function would trigger, or the Cloud Users be notified, the damage would’ve probably been done.</p>

<p>Billing takes about a day to be synced, and that’s why we noticed the charges the next day.</p>

<h4 id="3-google-was-supposed-to-charge-us-100-not-72k">3. Google was supposed to charge us $100, not $72K!</h4>
<p>As our account had not made any payment thus far, GCP should’ve first made charge for $100 as <a href="https://cloud.google.com/billing/docs/how-to/billing-cycle#find-threshold-amount">per billing info</a>, and on non-payment, stopped the services. But it didn’t. I understood the reason later, but it’s still not the user’s fault!</p>

<p>The first billing charge made to our account was of ~ $5,000. The next one for $72,000.</p>

<center>
<img src="https://blog.tomilkieway.com/assets/images/72K/automatic-payments.jpg" width="100%">
<em>Billing threshold for our account was $100</em>

</center>

<h4 id="4-dont-rely-on-firebase-dashboard">4. Don’t rely on Firebase Dashboard!</h4>
<p>Not just Billing, but even Firebase Dashboard took more than 24 hours to update.</p>

<p>As per Firebase Console documentation, the Firebase console dashboard numbers may differ ‘slightly’ from Billing reports.</p>

<p>In our case, it differed by <strong>86,585,365.85 %</strong>, or 86 million percentage points. Even when the bill was notified to us, Firebase Console dashboard still said 42,000 read+writes for the month (below the daily limit).</p>

<h3 id="new-day-new-challenge">New Day, New Challenge</h3>
<p>Having been a Googler for ~6.5 years and written dozens of project documents, postmortem reports, and what not, I started a document to share with Google outlining the incident, and adding the loopholes from Google’s side in a postmortem. Google team would come back to work in 2 days.</p>

<p>EDIT: Some readers suggested that I used my internal contacts at Google. The truth is that I haven’t been in touch with anyone, and I used the path that any normal developer / company would take. Like any other small developer, I spent countless hours on chat, in consults, lengthy emails, and bugs. In one of my next posts on how to look at incidents, I’d like to share the doc/postmortem I sent to Google during this incident.</p>

<center>
<img src="https://blog.tomilkieway.com/assets/images/72K/googleplex.jpg" width="40%"><br>
<em>Last day at Google</em></center>

<p>Another task was to understand our mistake, and devise our product development strategy. Not everyone on the team knew what was going on, but it was quite clear that we were in some big trouble.</p>

<p>As a Googler I had experienced teams making mistakes costing Google millions of dollars, but the Google culture saves the employees (except engineers have to write a long incident report). This time, there was no Google. Our own limited capital and our hard work, was at complete stake.</p>

<hr>

<p>This post is already getting long, so I’ll continue the details of how we managed to make this blunder, how we survived, and what did we learn.</p>

<p>See you in <strong><a href="https://blog.tomilkieway.com/72k-2/">Part 2: https://blog.tomilkieway.com/72k-2</a></strong>.</p>
                
			</article></div>]]>
            </description>
            <link>https://blog.tomilkieway.com/72k-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25372336</guid>
            <pubDate>Thu, 10 Dec 2020 10:56:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deutsche Post to support DIY postal stamps (via handwritten code)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25372252">thread link</a>) | @tosh
<br/>
December 10, 2020 | https://www.sueddeutsche.de/wirtschaft/digitalstrategie-wie-die-post-den-brief-digitalisieren-will-1.4829327 | <a href="https://web.archive.org/web/*/https://www.sueddeutsche.de/wirtschaft/digitalstrategie-wie-die-post-den-brief-digitalisieren-will-1.4829327">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Kunden sollen früh wissen, welche Briefe für sie unterwegs sind und wo sich Pakete befinden. Das Unternehmen will sich damit auch auf junge Kunden einstellen und sucht einen zeitgemäßen Weg für seine sehr analogen Produkte.</p><div itemprop="articleBody" data-testid="article-body"><p>Zwischen den Managern in schwarzen Anzügen strahlt ein Paketbote in gelb-roter DHL-Montur hervor. Wenn er nicht gerade bei der Vorstellung der neuen Digitalstrategie der Deutschen Post Modell steht, dann fährt Maik Berkholz mit einem 3,5-Tonner durch Berlin-Mitte. Seit zehn Jahren liefert Berkholz Pakete aus. Und neuerdings trägt er neben seinem Unterschriftgerät einen kleinen Drucker am Hosenbund. Denn Berkholz ist nicht mehr nur Paketbote, er frankiert auch Pakete und Briefe und nimmt sie im Lieferwagen mit. "Die Kunden finden das super", sagt er mit abgehacktem Berliner Zungenschlag, "wenn sie mir das mitgeben können und nicht bei der nächsten Filiale anstehen&nbsp;müssen."</p><p>Der kleine Drucker ist eine der vielen Ideen, mit der die Post eine dreifache Herausforderung meistern will: Ihre Kunden versenden von Jahr zu Jahr weniger Briefe, wenngleich die Menge in Deutschland bislang nicht so stark eingebrochen ist wie in anderen Staaten. Zugleich transportiert die Post immer mehr Pakete durchs Land, vor allem wegen des boomenden Onlinehandels. Die Bundesnetzagentur meldet freilich auch, dass sich immer mehr Menschen über die Post&nbsp;beschweren.</p><div><div data-hydration-component-name="ImageAsset"><figure><div><div><picture><source type="image/webp"><img alt="20 Jahre Briefzentrum Gera" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></picture></div></div><figcaption><p>Eine Mitarbeiterin arbeitet an der Briefsortierungsanlage im Briefzentrum in Gera, Thüringen.</p> <small>(Foto: Martin Schutt/dpa)</small></figcaption></figure></div></div><p>"Wir wollen die sichere Zustellung von Paketen und Briefen beibehalten, diese aber mit der Digitalisierung koppeln", sagt Tobias Meyer, der Brief- und Paketchef der Post in&nbsp;Deutschland.</p><p>Dass Kunden Boten wie Berkholz Pakete mitgeben, das ging zwar schon früher. Neu ist aber, dass der Kunde das Adress- und Frankierfeld nicht mehr aufkleben muss. Stattdessen kann Berkholz ein selbstklebendes Adressfeld und eine Marke aus seinem mobilen Drucker ausdrucken. Dafür scannt der Bote einen Code vom Handy des Kunden ein. Der Code wurde erstellt, nachdem der Kunde via Post-App auf seinem Smartphone das Porto bezahlt und die Adresse eingegeben hat. Die "mobile Paketmarke" für die "mobile Retour", so nennt es Manager&nbsp;Meyer.</p><p>Mit der Digitalstrategie will die Post neuen Bedürfnissen der Kunden gerecht werden, aber auch Geld sparen. Das Versenden, das Empfangen, das Nachverfolgen von Sendungen - selbst Vorabbenachrichtigungen, was morgen im heimischen Briefkasten ankommen soll: All das soll effizienter werden. Bei der Vorstellung in Berlin erklären Männer in schwarzen Anzügen und eine Frau die neuen&nbsp;Services.</p><h4>Abfotografierte Briefe</h4><p>Einer der Männer in schwarz zeigt an seiner Station ein E-Mail-Postfach, in dem lauter gelbe Mails von der DHL lagern. Denn vom kommenden Sommer an wird es für Nutzer von GMX und Web.de möglich sein, Fotos von ihren Briefen zu sehen, bevor sie ausgeliefert&nbsp;werden.</p><p>Dazu scannt die Post eintreffende Briefe ein, ohne sie zu öffnen, und der Empfänger bekommt eine Mail mit dem Foto der Umschläge. Damit kennt man zwar beispielsweise noch nicht die Höhe des Bußgeldbescheids, aber weiß, dass ein solcher auf dem Weg&nbsp;ist.</p><p>Kunden müssen sich für dieses Angebot anmelden. Eine weitere Station präsentiert den Prototypen einer künftigen App-Funktion, die es im Laufe dieses Jahres ermöglichen soll, nachzusehen, wo sich ein erwartetes Paket gerade befindet. Damit reagiert die Post nicht nur auf die vielen Beschwerden über verspätete oder verloren gegangene Sendungen. Experten gehen auch davon aus, dass die sogenannte letzte Meile zu den Adressaten etwa die Hälfte der Kosten von Paketdiensten ausmachen. Konzerne wie die Post können also viel Geld sparen, wenn sie erfolglose Zustellversuche verhindern. Das neue Tracking zeigt den Kunden, wie viele Stopps noch zwischen dem Paketboten und der eigenen Haustüre liegen. Außerdem will die Post künftig am Tag vor der Auslieferung ein Zeitfenster von 90 Minuten angeben, in dem der Paketbote vorbei kommt. Empfänger könnten auch kurzfristig noch mitteilen, falls das Paket beim Nachbarn abgegeben werden soll, im Hausflur abgelegt werden soll, oder in der nächsten&nbsp;Packstation.</p><h4>Erweiterte Packstation</h4><p>Zudem führt ein Postvertreter die Packstation der Zukunft vor, die im Videochat mit dem Kunden kommunizieren soll und ebenfalls Adressfelder und Portosticker drucken kann. Die Post möchte die Zahl der Packstationen von 4000 im Laufe des Jahres auf 7000&nbsp;erhöhen.</p><p>Politisch interessant ist diese Ankündigung, da das Bundeswirtschaftsministerium derzeit an einer Reform des alten Postgesetzes von 1997 arbeitet. Ein Streitpunkt dabei: Wie viele Filialen muss die Post künftig noch aufrechterhalten? Sollte der Gesetzgeber die erweiterten Packstationen als Verkaufsstellen auf dem Land akzeptieren, hätte es der Konzern künftig einfacher, die Vorgaben zu&nbsp;erfüllen.</p><h4>Selbstgemachte Briefmarken</h4><p>An der letzten Station führt die Post vor, wie sie das Briefgeschäft auch für sogenannte Digital Natives - also junge Leute, die mit dem Internet großgeworden sind - attraktiv halten will. Über eine App kann der Kunde die Höhe des Portos wählen, diese spuckt dann einen Code aus Zahlen und Buchstaben aus. Der Kunde schreibt den Code auf das Kuvert mit dem Zusatz "#Porto" - und fertig ist die selbstgemalte Briefmarke. Aber Moment, die Handschrift als Teil einer&nbsp;Digitalisierungsoffensive?</p><p>Was paradox anmutet, soll es Kunden von Ende 2020 an ermöglichen, mit ihrem Handy eine Marke zu generieren. Bezahlt wird die "mobile Briefmarke" über die App mittels dem verbreiteten Bezahldienst Paypal. Ist dies das Ende der bunten Bildchen auf randgezackten Briefmarken? "Nein, nein", wiegelt Post-Vorstand Meyer ab. Es würden nach wie vor Briefmarken angeboten. Zudem glaubt er, dass die Code-Briefmarke aus dem Smartphone nur eine Ergänzung sein&nbsp;wird.</p><div><div><p><span>Streetscooter-Aus verstimmt Zulieferer</span></p><div><p>Die Deutsche Post hat mit dem angekündigten Aus ihrer Produktion des Streetscooters offenbar wichtige Vertragspartner überrumpelt. So erfuhr der Zulieferer Neapco nach eigenen Angaben "überraschend aus den Medien von dieser Nachricht". Neapco stellt der Post in Düren Produktionsflächen sowie etwa 120 Beschäftigte für die Montage der batteriebetriebenen Nutzfahrzeuge zur Verfügung. "Geplant war ein Anstieg der Mitarbeiterzahlen auf etwa 200 in den kommenden Monaten", heißt es von dem Dienstleister.</p>
<p>Die Post hat vorige Woche die Suche nach einem Käufer oder Investor für Streetscooter aufgegeben. Der Konzern verweist auf Millionenverluste seiner Autotochter. Er will die mehr als 11 000 bereits hergestellten E-Fahrzeuge zwar weiterbetreiben, doch soll die Produktion in Aachen und Düren in diesem Jahr auslaufen. Streetscooter beschäftigt selbst etwa 500 Menschen; hinzu kommen Mitarbeiter bei Dienstleistern wie Neapco. Die Post erklärt, dass sie das Aus von Streetscooter ad hoc kommunizieren musste, da es auch für den Kapitalmarkt relevant sei. Der Konzern geht davon aus, dass sich die Abschreibungen auf Streetscooter sowie die Kosten für den Personalabbau und die Abwicklung der Verträge auf bis zu 400 Millionen Euro summieren werden.</p>
<p>Unterdessen kritisiert der Streetscooter-Gründer Günther Schuh, die Post habe nach der Übernahme des Start-ups 2014 "Amateure eingesetzt, jegliche Verbesserung verboten und auf eine Gelegenheit gewartet, das Geschäft unter einem Vorwand einzustellen". Die Post habe Streetscooter weder ausreichend finanziert noch einen Zugang zum Kapitalmarkt gewährt, moniert der Aachener Professor in einem Handelsblatt-Gastbeitrag. Schuh war nach der Übernahme bei Streetscooter ausgeschieden. <span>Benedikt Müller</span></p></div></div></div></div></div>]]>
            </description>
            <link>https://www.sueddeutsche.de/wirtschaft/digitalstrategie-wie-die-post-den-brief-digitalisieren-will-1.4829327</link>
            <guid isPermaLink="false">hacker-news-small-sites-25372252</guid>
            <pubDate>Thu, 10 Dec 2020 10:46:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[This Week in Rust 368]]>
            </title>
            <description>
<![CDATA[
Score 81 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25371862">thread link</a>) | @todsacerdoti
<br/>
December 10, 2020 | https://this-week-in-rust.org/blog/2020/12/09/this-week-in-rust-368/ | <a href="https://web.archive.org/web/*/https://this-week-in-rust.org/blog/2020/12/09/this-week-in-rust-368/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <p>Hello and welcome to another issue of <em>This Week in Rust</em>!
<a href="http://rust-lang.org/">Rust</a> is a systems language pursuing the trifecta: safety, concurrency, and speed.
This is a weekly summary of its progress and community.
Want something mentioned? Tweet us at <a href="https://twitter.com/ThisWeekInRust">@ThisWeekInRust</a> or <a href="https://github.com/rust-lang/this-week-in-rust">send us a pull request</a>.
Want to get involved? <a href="https://github.com/rust-lang/rust/blob/master/CONTRIBUTING.md">We love contributions</a>.</p>
<p><em>This Week in Rust</em> is openly developed <a href="https://github.com/rust-lang/this-week-in-rust">on GitHub</a>.
If you find any errors in this week's issue, <a href="https://github.com/rust-lang/this-week-in-rust/pulls">please submit a PR</a>.</p>

<h3 id="official">Official</h3>
<ul>
<li><a href="https://blog.rust-lang.org/2020/12/07/the-foundation-conversation.html">The Foundation Conversation</a></li>
</ul>
<h3 id="newsletters">Newsletters</h3>
<ul>
<li><a href="https://rust-gamedev.github.io/posts/newsletter-016/">This Month in Rust GameDev #16 - November 2020</a></li>
<li><a href="https://www.reddit.com/r/rust/comments/k6cka7/rib_newsletter_18_on_to_the_ribbles/">RiB Newsletter #18 - On to the Ribbles</a></li>
</ul>
<h3 id="tooling">Tooling</h3>
<ul>
<li><a href="https://rust-analyzer.github.io/thisweek/2020/12/07/changelog-54.html">Rust Analyzer Changelog #54</a></li>
<li><a href="https://ferrous-systems.com/blog/knurling-changelog-9/">Knurling-rs Changelog #9</a></li>
<li><a href="https://blog.jetbrains.com/clion/2020/12/intellij-rust-updates-for-2020-3/">IntelliJ Rust: Updates for 2020.3</a></li>
</ul>
<h3 id="observationsthoughts">Observations/Thoughts</h3>
<ul>
<li><a href="https://www.fpcomplete.com/blog/monads-gats-nightly-rust/">Monads and GATs in Nightly Rust</a></li>
<li><a href="https://fanf.dreamwidth.org/134024.html">Vanishing zeroes for geometric algebra in Rust</a></li>
<li><a href="https://blog.thomasheartman.com/posts/on-generics-and-associated-types">On Generics and Associated Types</a></li>
<li><a href="https://vector.dev/blog/adaptive-request-concurrency/">Adaptive Request Concurrency. Resilient observability at scale.</a></li>
<li><a href="https://blog.logrocket.com/rust-compression-libraries/">Rust compression libraries</a></li>
<li><a href="https://www.marcoieni.com/2020/12/rust-makes-cross-compilation-childs-play/">Rust makes cross compilation child's play</a></li>
<li><a href="https://jmmv.dev/2020/12/builder-pattern-for-tests.html">Using the builder pattern to define test scenarios</a></li>
<li><a href="https://rust-analyzer.github.io/blog/2020/12/04/measuring-memory-usage-in-rust.html">Measuring Memory Usage in Rust</a></li>
<li><a href="https://www.tag1consulting.com/blog/saving-time-switching-users-async-support-goose">Saving time by switching users: Async support in Goose</a></li>
<li><a href="https://evrone.com/rust-vs-c">Why Rust is meant to replace C</a></li>
</ul>
<h3 id="rust-walkthroughs">Rust Walkthroughs</h3>
<ul>
<li><a href="https://subvisual.com/blog/posts/real-time-video-processing-with-rust-ffmpeg-opencv/">Real-time video processing with Rust, FFmpeg and OpenCV</a></li>
<li><a href="https://dev.to/creativcoder/merge-k-sorted-arrays-in-rust-1b2f">Merge k sorted arrays in Rust</a></li>
<li><a href="https://arzg.github.io/lang/13/">Make A Language - Part Thirteen: Whitespace &amp; Events</a></li>
<li><a href="https://jmmv.dev/2020/12/unit-testing-a-console-app.html">Unit-testing a console app (a text editor)</a></li>
<li><a href="https://blog.drogue.io/rust-and-async/">Rust and Async (on embedded devices)</a></li>
<li><a href="https://www.fpcomplete.com/blog/avoiding-duplicating-strings-rust/">Avoiding Duplicating Strings in Rust</a></li>
<li><a href="https://blog.knoldus.com/os-in-rust-custom-target-to-build-kernel-for-a-bare-metal-part-3/">OS in Rust: Custom target to build kernel for bare metal: Part-3</a></li>
<li><a href="https://blog.knoldus.com/os-in-rust-building-kernel-for-custom-target-part-4/">OS in Rust: Building kernel for custom target: Part-4</a></li>
<li>[video] <a href="https://youtu.be/lLWchWTUFOQ">Introduction to Rust Part 2</a></li>
</ul>
<h3 id="project-updates">Project Updates</h3>
<ul>
<li><a href="https://github.com/EmbarkStudios/rust-gpu/releases/tag/v0.2">rust-gpu v0.2</a></li>
<li><a href="https://ibraheem.ca/posts/rust-interior-mutability-understanding-cell">Interior Mutability in Rust: Understanding The Cell Type</a></li>
</ul>
<h3 id="miscellaneous">Miscellaneous</h3>
<ul>
<li><a href="https://www.infoq.com/news/2020/12/cpp-rust-interop-cxx/">Safe Interoperability between Rust and C++ with CXX</a></li>
<li><a href="https://opensource.googleblog.com/2020/12/expanding-fuchsias-open-source-model.html">Expanding Fuchsia's open source model</a></li>
<li><a href="https://www.reddit.com/r/rust/comments/k75tez/miri_can_now_detect_data_races/">Miri can now detect data races</a></li>
</ul>

<p>This week's crate is <a href="https://github.com/not-a-seagull/breadx">breadx</a>, a X-windows protocol implementation in 100% safe and mutex-free Rust.</p>
<p>Thanks to <a href="https://users.rust-lang.org/t/crate-of-the-week/2704/851">Willi Kappler</a> for the suggestion!</p>
<p><a href="https://users.rust-lang.org/t/crate-of-the-week/2704">Submit your suggestions and votes for next week</a>!</p>

<p>Always wanted to contribute to open-source projects but didn't know where to start?
Every week we highlight some tasks from the Rust community for you to pick and get started!</p>
<p>Some of these tasks may also have mentors available, visit the task page for more information.</p>
<p>If you are a Rust project owner and are looking for contributors, please submit tasks <a href="https://users.rust-lang.org/t/twir-call-for-participation/4821">here</a>.</p>
<ul>
<li><a href="https://github.com/AaronErhardt/Triox/labels/good%20first%20issue">Triox - Good First Issues</a></li>
<li><a href="https://github.com/libssh2/libssh2/pull/517">libssh2 - Pull Request Needs Windows Reviewer</a></li>
</ul>

<p>279 pull requests were <a href="https://github.com/search?q=is%3Apr+org%3Arust-lang+is%3Amerged+merged%3A2020-11-30..2020-12-07">merged in the last week</a></p>
<ul>
<li><a href="https://github.com/rust-lang/rust/pull/78684">add wasm32 support to inline asm</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/79509">improve attribute message error spans</a></li>
<li><a href="https://github.com/rust-lang/chalk/pull/659">chalk: always relate with Invariant to non-General inference vars</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/79680">fix perf regression caused by match exhaustiveness split</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/79623">pass around Symbols instead of Idents in doctree</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/79620">tweak diagnostics on shadowing lifetimes/labels</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/78122">avoid panic_bounds_check in <code>fmt::write</code></a></li>
<li><a href="https://github.com/rust-lang/rust/pull/79650">fix incorrect <code>io::Take</code>'s limit resulting from <code>io::copy</code> specialization</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/79600"><code>std::io</code>: use sendfile for UnixStream</a></li>
<li><a href="https://github.com/rust-lang/cargo/pull/8937">cargo: slightly optimize `cargo vendor</a></li>
<li><a href="https://github.com/rust-lang/cargo/pull/8725">cargo: add "--workspace" to update command</a></li>
<li><a href="https://github.com/rust-lang/rust/pull/79539">rustdoc: JSON backend experimental impl</a></li>
</ul>
<h2 id="rust-compiler-performance-triage">Rust Compiler Performance Triage</h2>
<ul>
<li><a href="https://github.com/rust-lang/rustc-perf/blob/master/triage/2020-12-08.md">2020-12-08</a>:
0 Regressions, 2 Improvements, 1 Mixed</li>
</ul>
<p>Triage done by @simulacrum.</p>
<p>See the <a href="https://github.com/rust-lang/rustc-perf/blob/master/triage/2020-12-08.md">full report</a> for more.</p>
<h2 id="approved-rfcs">Approved RFCs</h2>
<p>Changes to Rust follow the Rust <a href="https://github.com/rust-lang/rfcs#rust-rfcs">RFC (request for comments) process</a>. These
are the RFCs that were approved for implementation this week:</p>
<p><em>No RFCs were approved this week.</em></p>

<p>Every week <a href="https://www.rust-lang.org/team.html">the team</a> announces the
'final comment period' for RFCs and key PRs which are reaching a
decision. Express your opinions now.</p>
<h3 id="rfcs"><a href="https://github.com/rust-lang/rfcs/labels/final-comment-period">RFCs</a></h3>
<ul>
<li><a href="https://github.com/rust-lang/rfcs/pull/3007">RFC: Plan to make core and std's panic identical</a></li>
<li><a href="https://github.com/rust-lang/rfcs/pull/2992">RFC: Add <code>target_abi</code> configuration</a></li>
<li><a href="https://github.com/rust-lang/rfcs/pull/2859">added secret types rfc</a></li>
</ul>
<h3 id="tracking-issues-prs"><a href="https://github.com/rust-lang/rust/labels/final-comment-period">Tracking Issues &amp; PRs</a></h3>
<ul>
<li>[disposition: merge] <a href="https://github.com/rust-lang/rust/pull/79642">rustdoc: stabilise --default-theme command line option</a></li>
<li>[disposition: merge] <a href="https://github.com/rust-lang/rust/pull/79502">Implement <code>From&lt;char&gt;</code> for u64 and u128.</a></li>
<li>[disposition: merge] <a href="https://github.com/rust-lang/rust/pull/79485">Stabilize <code>unsafe_cell_get_mut</code></a></li>
<li>[disposition: merge] <a href="https://github.com/rust-lang/rust/pull/79473">Move <code>{f32,f64}::clamp</code> to core</a></li>
<li>[disposition: merge] <a href="https://github.com/rust-lang/rust/pull/79342">Stabilize all stable methods of <code>Ipv4Addr</code>, <code>Ipv6Addr</code> and <code>IpAddr</code> as const</a></li>
<li>[disposition: merge] <a href="https://github.com/rust-lang/rust/pull/79270">Acknowledge that <code>[CONST; N]</code> is stable</a></li>
<li>[disposition: merge] <a href="https://github.com/rust-lang/rust/pull/79261">Deprecate atomic compare_and_swap method</a></li>
<li>[disposition: merge] <a href="https://github.com/rust-lang/rust/pull/79213">Stabilize <code>core::slice::fill</code></a></li>
<li>[disposition: close] <a href="https://github.com/rust-lang/rust/pull/79188">Made matches! more useful by adding mapping support</a></li>
<li>[disposition: merge] <a href="https://github.com/rust-lang/rust/pull/79073">passes: prohibit invalid attrs on generic params</a></li>
<li>[disposition: merge] <a href="https://github.com/rust-lang/rust/pull/79022">stabilize deque_range</a></li>
<li>[disposition: close] <a href="https://github.com/rust-lang/rust/pull/78367">Apply <code>unused_doc_comments</code> lint to inner items</a></li>
<li>[disposition: merge] <a href="https://github.com/rust-lang/rust/pull/78242">Rename <code>overlapping_patterns</code> lint</a></li>
<li>[disposition: merge] <a href="https://github.com/rust-lang/rust/pull/78083">Stabilize or_insert_with_key</a></li>
<li>[disposition: close] <a href="https://github.com/rust-lang/rust/pull/77688">Add built-in implementations of <code>Default</code> for function definition and… </a></li>
<li>[disposition: merge] <a href="https://github.com/rust-lang/rust/pull/74699">Mark <code>-1</code> as an available niche for file descriptors</a></li>
<li>[disposition: merge] <a href="https://github.com/rust-lang/rust/pull/74304">Stabilize the Wake trait</a></li>
<li>[disposition: merge] <a href="https://github.com/rust-lang/rust/issues/63514">Tracking issue for map_ok and map_err method for <code>Poll&lt;Option&lt;Result&lt;T, E&gt;&gt;&gt;</code></a></li>
</ul>
<h2 id="new-rfcs">New RFCs</h2>
<p><em>No new RFCs were proposed this week.</em></p>

<h3 id="online">Online</h3>
<ul>
<li><a href="https://www.meetup.com/de-DE/Rust-Community-Stuttgart/events/274892215/">December 10, Stuttgart, DE - Hack &amp; Learn - Directions for 2021 - Rust Community Stuttgart</a></li>
<li><a href="https://www.meetup.com/San-Diego-Rust/events/274757235/">December 10, San Diego, CA, US - San Diego Rust December 2020 Tele-Meetup - San Diego Rust</a></li>
<li><a href="https://www.meetup.com/RustDC/events/274460587">December 10, Washington, DC, US - How oso built a runtime reflection system for Rust—Rust DC</a></li>
<li><a href="https://www.meetup.com/Rust-%D0%B2-%D0%9C%D0%BE%D1%81%D0%BA%D0%B2%D0%B5/events/274924961/">December 15, Russia - Russian Rust Online Meetup</a></li>
<li><a href="https://www.meetup.com/Vancouver-Rust/events/npqfbsybcqbvb/">December 16, Vancouver, BC, US - Are Results just Checked Exceptions? - Vancouver Rust</a></li>
</ul>
<h3 id="north-america">North America</h3>
<ul>
<li><a href="https://www.meetup.com/utah-rust/events/273530244/">December 10, Provo, UT, US - Mob Programming: Add <code>--tree -d</code> to <code>lsd</code></a></li>
</ul>
<p>If you are running a Rust event please add it to the <a href="https://www.google.com/calendar/embed?src=apd9vmbc22egenmtu5l6c5jbfc%40group.calendar.google.com">calendar</a> to get
it mentioned here. Please remember to add a link to the event too.
Email the <a href="mailto:community-team@rust-lang.org">Rust Community Team</a> for access.</p>

<p><em>Tweet us at <a href="https://twitter.com/ThisWeekInRust">@ThisWeekInRust</a> to get your job offers listed here!</em></p>
<ul>
<li><a href="https://www.pathai.com/careers/?gh_jid=4983568002">Software Engineer, Systems at PathAI (Boston, MA, US)</a></li>
<li><a href="https://www.welcometothejungle.com/fr/companies/meilisearch/jobs/software-developer-rust_paris">Software Developer (Rust) at MeiliSearch (Remote)</a></li>
<li><a href="https://jobs.lever.co/kraken/4019a818-4a7b-46ef-9225-c53c7a7f238c">Backend Engineer - Rust at Kraken (Remote NA, SA, EMEA)</a></li>
<li><a href="https://jobs.lever.co/kraken/fe1e07f4-6d7c-4f65-9a8f-27cf3b3fd2b1">Backend Engineer, Kraken Futures - Rust at Kraken (Remote)</a></li>
<li><a href="https://jobs.lever.co/kraken/2442ee5c-56b6-4a73-a477-8cdda2b218d5">Rust Engineer, Desktop GUI - Cryptowatch at Kraken (Remote)</a></li>
<li><a href="https://jobs.lever.co/kraken/4c864c8f-bde6-443d-b521-dd90df0e9105">Senior Backend Engineer - Rust at Kraken (Remote NA, SA, EMEA)</a></li>
<li><a href="https://jobs.lever.co/kraken/2863623f-13c9-4f50-992d-7c25736a60f9">Senior Banking Engineer - Rust at Kraken (Remote)</a></li>
<li><a href="https://jobs.lever.co/kraken/4485f672-dc5f-4e49-a10b-2b0399e28a8d">Software Engineer - Trading Technology (Rust) at Kraken (Remote NA, SA, EMEA)</a></li>
<li><a href="https://stackoverflow.com/jobs/294502/rust-for-embedded-environments-ockam">Rust for Embedded Environments at Ockam (Remote)</a></li>
<li><a href="https://stackoverflow.com/jobs/400828/messaging-protocol-architect-in-elixir-and-rust-ockam">Messaging protocol architect in Elixir (and Rust) at Ockam (Remote)</a></li>
<li><a href="https://nzxt.bamboohr.com/jobs/view.php?id=259">Senior Software Engineer (Rust &amp; C++) at NZXT (Remote)</a></li>
<li><a href="https://www.notion.so/Embedded-Firmware-Engineer-in-C-Rust-a9c741c539454ee7b8bbb969d8e90da2">Embedded Firmware Engineer in C &amp; Rust at Astropad (Remote, US)</a></li>
</ul>

<blockquote>
<p>Writing rust for me is a gradual process of the compiler patiently guiding me towards the program I should have written in the first place, and at the end I take all the credit.</p>
</blockquote>
<p>– <a href="https://discord.com/channels/442252698964721669/448238009733742612/783395725991084074">@felixwatts on Discord</a></p>
<p>Thanks to <a href="https://users.rust-lang.org/t/twir-quote-of-the-week/328/972">Joshua Nelson</a> for the suggestion.</p>
<p><a href="https://users.rust-lang.org/t/twir-quote-of-the-week/328">Please submit quotes and vote for next week!</a></p>
<p><em>This Week in Rust is edited by: <a href="https://github.com/nellshamrell">nellshamrell</a>, <a href="https://github.com/llogiq">llogiq</a>, and <a href="https://github.com/cdmistman">cdmistman</a>.</em></p>
<p><small><a href="https://www.reddit.com/r/rust/comments/ka8fvg/this_week_in_rust_368/">Discuss on r/rust</a></small></p>
  </article></div>]]>
            </description>
            <link>https://this-week-in-rust.org/blog/2020/12/09/this-week-in-rust-368/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25371862</guid>
            <pubDate>Thu, 10 Dec 2020 09:54:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a Web Service to Manage Scientific Simulation Data Using GraphQL]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25371580">thread link</a>) | @felipez
<br/>
December 10, 2020 | https://blog.esciencecenter.nl/building-a-web-service-to-manage-scientific-simulation-data-using-graphql-a0bbf1c3f6e9 | <a href="https://web.archive.org/web/*/https://blog.esciencecenter.nl/building-a-web-service-to-manage-scientific-simulation-data-using-graphql-a0bbf1c3f6e9">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><div><div><div><div><p><a href="https://medium.com/@f.zapata?source=post_page-----a0bbf1c3f6e9--------------------------------" rel="noopener"><img alt="Felipe" src="https://miro.medium.com/fit/c/96/96/1*f7WZ93VZ5pv2qgIxOhxJUA.jpeg" width="48" height="48"></a></p></div></div></div></div><p id="77c2">Scientific simulations generate large volume of data that needs to be stored and processed by multidisciplinary teams across different geographical locations. Distributing computational expensive simulations among the available resources, avoiding duplication and keeping the data safe are challenges that scientists face every day.</p><p id="8d66">In this post we present our web service <a href="https://insilico-server.readthedocs.io/en/latest/" rel="noopener">Insilico</a> and its command line interface <a href="https://moka-command-line-interface.readthedocs.io/en/latest/" rel="noopener">Moka</a>. Insilico solves the problem of <em>computing</em>, <em>storing</em> and <em>securely sharing</em> computationally <em>expensive</em> simulation results. Researchers can save significant time and resources by easily computing new data and reusing existing simulation data to answer their questions.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/9856/0*bI9DbwobcmYvOYyk" width="4928" height="3280" srcset="https://miro.medium.com/max/552/0*bI9DbwobcmYvOYyk 276w, https://miro.medium.com/max/1104/0*bI9DbwobcmYvOYyk 552w, https://miro.medium.com/max/1280/0*bI9DbwobcmYvOYyk 640w, https://miro.medium.com/max/1400/0*bI9DbwobcmYvOYyk 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*bI9DbwobcmYvOYyk?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@publicpowerorg?utm_source=medium&amp;utm_medium=referral" rel="noopener">American Public Power Association</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener">Unsplash</a></figcaption></figure><blockquote><p id="71c5">At the <a href="https://www.esciencecenter.nl/" rel="noopener">Netherlands eScience Center</a> we empower academic researchers by building together simulation tools, data pipelines, etc. A common goal among several tools that we develop for projects in different scientific fields, is to reduce the calculation time of computationally expensive physical simulations (e.g. molecular processes) by applying statistical methods to previously simulated data.</p></blockquote><p id="204c">The aforementioned methodology can potentially save us significant human and computational resources by easily generating high value data using previous computations. But before we are ready to apply any statistical method we of course need the data and for doing so, we need to ask ourselves questions like:</p><blockquote><p id="7c69">What input is required?</p><p id="75eb">Who is going to perform the simulation?</p><p id="a35c">What facilities are going to be used?</p><p id="93ec">Where is the resulting data going to be stored?</p><p id="6091">How to access the available data?</p></blockquote><p id="6fb9">Physical simulations usually require intricate input that takes into consideration several aspects and parameters used by different models to approximate the phenomena under consideration. Also, scientific simulations are computationally demanding tasks, so they are usually run in (inter)national supercomputers or very specialized facilities. We also want to maximize the impact of the data in the scientific community, therefore we want other scientists to be able to access the data and even add their own, but we need some security layers to protect such valuable data.</p><p id="bcb8">There is no silver bullet to address all the previous questions, but there are amazing initiatives like the <a href="https://foldingathome.org/" rel="noopener">folding at home project</a> that distributes some computational tasks among volunteers around the world who give away some time in their computers to simulate protein dynamics.</p><p id="6858">It seems that if we want to collaborate on the distribution of computational tasks and the assemblage of the resulting data, we need a central “entity” that (1) allows users to request new tasks, (2) receives the task’s results to be stored and (3) returns some available data when requested. It sounds like we need a web service!</p><blockquote><p id="6a2b">Writing a web service is a nontrivial task, you need to be aware of different technologies, libraries, etc. while making sure that your data is going to be safe and of course you need some infrastructure to host your service. This post goal is to give you some hints about building a web service for scientific applications and it is by no means a complete guide to writing web applications.</p></blockquote><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/9662/0*HnAn4y-BQGmvGjGZ" width="4831" height="3221" srcset="https://miro.medium.com/max/552/0*HnAn4y-BQGmvGjGZ 276w, https://miro.medium.com/max/1104/0*HnAn4y-BQGmvGjGZ 552w, https://miro.medium.com/max/1280/0*HnAn4y-BQGmvGjGZ 640w, https://miro.medium.com/max/1400/0*HnAn4y-BQGmvGjGZ 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*HnAn4y-BQGmvGjGZ?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@johnschno?utm_source=medium&amp;utm_medium=referral" rel="noopener">John Schnobrich</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener">Unsplash</a></figcaption></figure><p id="a44e">Before entering into the web service technical details, let’s explore what its behavior should be.</p><p id="74cc">So, once it has been decided what are the best approximations and models to perform the simulations, we can compile all the simulation metadata into different jobs. For instance, a job can be a single molecular simulation under some specific conditions. We would like to make all these jobs available to the users, in such a way that they can run one or more jobs at a time but avoiding that the same job is run by more than one user.</p><p id="2b33">It would be great that when the simulation is done a user can send the results to the web service or ask for already available results. We also want to be able to call the web service from our local computer, specialized infrastructure or wherever we want to perform the computation, without worrying about where the service is running.</p><p id="be30">It seems, that we want a <a href="https://en.wikipedia.org/wiki/Git" rel="noopener">Git</a>-like behavior where we can pull jobs (or available data) and push results.</p><p id="ba78">With these requirements in mind, I have developed an open source web service called <a href="https://github.com/nlesc-nano/insilico-server" rel="noopener">Insilico-server</a>. Let’s see how it works!</p></div></div></section><section><div><div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/7296/0*P4hHvh84YZQLPGgi" width="3648" height="2432" srcset="https://miro.medium.com/max/552/0*P4hHvh84YZQLPGgi 276w, https://miro.medium.com/max/1104/0*P4hHvh84YZQLPGgi 552w, https://miro.medium.com/max/1280/0*P4hHvh84YZQLPGgi 640w, https://miro.medium.com/max/1400/0*P4hHvh84YZQLPGgi 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*P4hHvh84YZQLPGgi?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@andrew_gook?utm_source=medium&amp;utm_medium=referral" rel="noopener">Andrew Gook</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener">Unsplash</a></figcaption></figure><p id="773a">The web service consists of two parts: a small command line interface (CLI) that communicates with the service and the <a href="https://insilico-server.readthedocs.io/en/latest/" rel="noopener">Insilico web service</a> that handles all the data.</p><p id="0fa0">Our CLI is called <a href="https://moka-command-line-interface.readthedocs.io/en/latest/" rel="noopener">Moka</a> and it offers several actions to interact with the service, like logging in, computing, querying, etc. as shown in the following snippet:</p><pre><span id="4e44">&gt;&gt;&gt; moka --help<br>usage: moka [-h] [--version] {login,compute,report,query,add,manage} ...</span><span id="84c2">positional arguments:<br>  {login,compute,report,query,add,manage}<br>                        Interact with the properties web service<br>    login               Log in to the Insilico web service<br>    compute             Compute available jobs<br>    report              Report the results back to the server<br>    query               Query some properties from the database<br>    add                 Add new jobs to the database<br>    manage              Change jobs status</span><span id="6b00">optional arguments:<br>  -h, --help            show this help message and exit<br>  --version             show program's version number and exit</span></pre><p id="b5c4">Using <a href="https://moka-command-line-interface.readthedocs.io/en/latest/" rel="noopener">Moka</a> we can compute some jobs using a command like:</p><pre><span id="f521">moka compute -c collection_name -j number_of_jobs_to_compute</span></pre><p id="8e50">The previous command handles the communication with the web service, fetches the requested jobs from a given collection (or dataset) and runs them directly or invokes a <a href="https://en.wikipedia.org/wiki/Job_scheduler" rel="noopener">job scheduler</a> like <a href="https://slurm.schedmd.com/documentation.html" rel="noopener">Slurm</a>. To communicate with the service, <a href="https://moka-command-line-interface.readthedocs.io/en/latest/" rel="noopener">Moka</a> invokes the <a href="https://requests.readthedocs.io/en/master/" rel="noopener">Python Requests library</a> that handles the communication.</p><p id="54f9">Once the jobs are done we can report the computed data like:</p><pre><span id="2183">moka report</span></pre><p id="eafc">You may be wondering how does the client know what data it needs to send/receive. Well, that is the subject of the next section!</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/8064/0*o_Zzwgbaexr6Fz8y" width="4032" height="3024" srcset="https://miro.medium.com/max/552/0*o_Zzwgbaexr6Fz8y 276w, https://miro.medium.com/max/1104/0*o_Zzwgbaexr6Fz8y 552w, https://miro.medium.com/max/1280/0*o_Zzwgbaexr6Fz8y 640w, https://miro.medium.com/max/1400/0*o_Zzwgbaexr6Fz8y 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*o_Zzwgbaexr6Fz8y?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@tofi?utm_source=medium&amp;utm_medium=referral" rel="noopener">Tobias Fischer</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener">Unsplash</a></figcaption></figure><p id="e270">The main goal of the web service is to minimize the interaction between the users and the data. If the client requests some read-only action you just return the data (if available) and if the client wants to change something, you need to ensure that (1) the client has permissions to mutate the data (2) only the mutations specified by the client are carried out but nothing more. I will skip authentication in this post.</p><p id="2b72">Therefore, the <a href="https://insilico-server.readthedocs.io/en/latest/" rel="noopener">Insilico</a> web service needs to handle two kinds of requests by the client: read-only queries and mutations on the datasets. These “queries” and “mutations” can be easily describe with <a href="https://graphql.org/" rel="noopener">GraphQL</a>.</p><p id="0dbe">In a nutshell, <a href="https://graphql.org/" rel="noopener">GraphQL</a> defines a contract (known as a schema) between the actions that a client can perform with the web service and the possible outcomes of those actions. More formally, <a href="https://graphql.org/" rel="noopener">GraphQL</a> is a query language that allows you to specify an application Programming interface (API) using different programming languages. If you have previous experience with <a href="https://en.wikipedia.org/wiki/Representational_state_transfer" rel="noopener">RESTful API</a> have a look at a comparison between <a href="https://www.howtographql.com/basics/1-graphql-is-the-better-rest/" rel="noopener">GraphQL and REST</a>.</p><p id="ecf0">But how does GraphQL work? First, you need to define a schema using the <a href="https://graphql.org/" rel="noopener">GraphQL</a> schema language. The following code snippet defines a schema to query a job using its status,</p><figure><div></div><figcaption>Schema definition for job query</figcaption></figure><p id="2045">The <strong>Query</strong> schema specifies that in order to request some <strong><em>jobs</em></strong> you need to provide a <em>Status</em> argument, where <em>Status</em> can be one of four possibilities: <em>AVAILABLE, DONE, FAILED</em> and <em>RUNNING. </em>The exclamation mark (!) indicates that the argument cannot be <em>Null</em> (a.k.a <em>None</em> in Python).</p><p id="5870">The following <strong>Mutation</strong> schema defines the required arguments to update a given job status.</p><figure><div></div><figcaption>Schema definitation for Job status mutation</figcaption></figure><p id="9dd2">The <strong><em>updateJob</em></strong> action specifies that you must provide an <em>id</em> and a <em>new_status</em> in order to be able to update a job. You will receive a <em>Reply</em> specifying whether the update action has succeeded.</p><p id="54d3">Have a look at the Insilico <a href="https://github.com/nlesc-nano/insilico-server/blob/master/insilicoserver/sdl/Query.graphql" rel="noopener">queries</a> and <a href="https://github.com/nlesc-nano/insilico-server/blob/master/insilicoserver/sdl/Mutation.graphql" rel="noopener">mutations</a> schemas. They are slightly more complex than the aforementioned schemas but follow the same rationale as the previous examples. You can also have a look at the official <a href="https://graphql.org/learn/" rel="noopener">introduction to GraphQL</a>.</p><p id="33f0">We have just defined the schemas that specify the actions that we want to perform. We still need to implement the actions and for doing so, we need a GraphQL engine: a library that takes the schemas together with the code that implements the actions and generates an API.</p><p id="39ea">We have chosen the <a href="https://tartiflette.io/" rel="noopener">Tartiflette GraphQL engine</a> to implement our web service mostly because it is easy to use and open source. The following snippet shows a possible implementation for querying jobs based on their status using <a href="https://tartiflette.io/" rel="noopener">Tartiflette</a>.</p><figure><div></div></figure><p id="affa">the <strong><em>Resolver</em></strong> decorator indicates that the <strong><em>resolver_query_jobs</em></strong> function corresponds to the implementation of the <strong><em>query jobs</em></strong> schema. The function takes 4 arguments of which I only use <strong><em>args</em></strong> and <strong><em>ctx</em></strong><em> </em>(You can refer to <a href="https://tartiflette.io/" rel="noopener">Tartiflette</a> for further details). <strong><em>args </em></strong>contains the arguments given by the client code, while <strong><em>ctx </em></strong>contains the context for running the current function, for example the handler to access the database that is called <strong><em>mongodb</em></strong> in this code snippet.</p><p id="9242">Notice that the definition of the aforementioned function starts with the <em>async</em> keyword. <a href="https://docs.python.org/3/library/asyncio.html" rel="noopener">Asyncio</a> is a popular built-in Python library to write concurrent code. It is extensively used to write high performance web services.</p><p id="fb0a">In the Insilico web service implementation of the <a href="https://github.com/nlesc-nano/insilico-server/tree/master/provisioning" rel="noopener"><strong>queries</strong></a> and <a href="https://github.com/nlesc-nano/insilico-server/blob/master/insilicoserver/mutation_resolvers.py" rel="noopener"><strong>mutations</strong></a>, there are definitions for all the Python functions that perform the actions specified in the GraphQL schemas. For each query and mutation, there is a corresponding function.</p><p id="632b">We need a database not only for storing the interesting data but also to store the jobs metadata, like what jobs are available. For the Insilico web service we use <a href="https://www.mongodb.com/" rel="noopener">MongoDB</a>.</p><p id="1b90">My personal opinion is that a <a href="https://en.wikipedia.org/wiki/NoSQL" rel="noopener">NoSQL database</a> like <a href="https://www.mongodb.com/" rel="noopener">MongoDB</a> gives a significant advantage over traditional SQL databases on research projects where up-front design of the schemas to store data is unfeasible. The research priorities can change as the project evolves and having dynamic …</p></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.esciencecenter.nl/building-a-web-service-to-manage-scientific-simulation-data-using-graphql-a0bbf1c3f6e9">https://blog.esciencecenter.nl/building-a-web-service-to-manage-scientific-simulation-data-using-graphql-a0bbf1c3f6e9</a></em></p>]]>
            </description>
            <link>https://blog.esciencecenter.nl/building-a-web-service-to-manage-scientific-simulation-data-using-graphql-a0bbf1c3f6e9</link>
            <guid isPermaLink="false">hacker-news-small-sites-25371580</guid>
            <pubDate>Thu, 10 Dec 2020 09:19:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ProtoPie 5.2: Turn Figma designs into realistic, conditional prototypes]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25371555">thread link</a>) | @heytmt
<br/>
December 10, 2020 | https://blog.protopie.io/protopie-plugin-for-figma-a-revamped-import-experience-to-boost-productivity-5758892c4c58 | <a href="https://web.archive.org/web/*/https://blog.protopie.io/protopie-plugin-for-figma-a-revamped-import-experience-to-boost-productivity-5758892c4c58">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h2 id="72bc">A far better Figma import for ProtoPie. Lightning speed and flexibility at your fingertips.</h2><div><div><div><p><a href="https://medium.com/@fredotan?source=post_page-----5758892c4c58--------------------------------" rel="noopener"><img alt="Fredo Tan" src="https://miro.medium.com/fit/c/96/96/1*6aaH5nx9yHmC7KcdczcZTg@2x.jpeg" width="48" height="48"></a></p></div></div></div></div></div><div><div><p id="ebd5">We are beyond excited that today we can finally introduce the <a href="https://www.figma.com/community/plugin/908870217222043020/ProtoPie-Plugin" rel="noopener"><strong>ProtoPie plugin for Figma</strong></a>—a far better Figma import for ProtoPie.</p><p id="7ead">The introduction of this plugin goes hand-in-hand with the <a href="https://protopie.io/?utm_source=medium&amp;utm_medium=social&amp;utm_campaign=standard-article&amp;utm_content=figma-plugin" rel="noopener"><strong>ProtoPie 5.2</strong></a> release.</p><p id="f675">ProtoPie plugins for Adobe XD and Sketch are coming soon.</p><p id="95c4">A lot of you have been using the Figma integration we introduced in early 2019. Many designers, since then, rely on a Figma + ProtoPie workflow on a daily basis—designing, prototyping, iterating, and anything in between.</p><p id="588e">As this workflow became essential for many rapidly, we received tons of feedback on how we could make this particular workflow better.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2616/1*35ZGJ7gZQN-LKqgbRZZj9Q.png" width="1308" height="262" srcset="https://miro.medium.com/max/552/1*35ZGJ7gZQN-LKqgbRZZj9Q.png 276w, https://miro.medium.com/max/1104/1*35ZGJ7gZQN-LKqgbRZZj9Q.png 552w, https://miro.medium.com/max/1280/1*35ZGJ7gZQN-LKqgbRZZj9Q.png 640w, https://miro.medium.com/max/1400/1*35ZGJ7gZQN-LKqgbRZZj9Q.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*35ZGJ7gZQN-LKqgbRZZj9Q.png?q=20"></p></div></div></div><figcaption>A better Figma import was one of the top <a href="https://protopie.canny.io/" rel="noopener">feature requests</a>.</figcaption></figure><p id="2208">Quickly we realized that we needed to provide a better workflow in which designers can merely focus on what they need ProtoPie for: making realistic, highly interactive prototypes.</p><p id="e4fd">So, we decided to build something new, entirely from scratch.</p><p id="1618">The new import experience is completely different from the previous one, which we now call the legacy Figma import.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3840/1*rINB-qGSruwy8te26r1hlA.gif" width="1920" height="1080" srcset="https://miro.medium.com/max/552/1*rINB-qGSruwy8te26r1hlA.gif 276w, https://miro.medium.com/max/1104/1*rINB-qGSruwy8te26r1hlA.gif 552w, https://miro.medium.com/max/1280/1*rINB-qGSruwy8te26r1hlA.gif 640w, https://miro.medium.com/max/1400/1*rINB-qGSruwy8te26r1hlA.gif 700w" sizes="700px" data-old-src="https://miro.medium.com/freeze/max/60/1*rINB-qGSruwy8te26r1hlA.gif?q=20"></p></div></div></div><figcaption>ProtoPie plugin for Figma: a revamped import experience to boost productivity.</figcaption></figure><p id="ffdc">With the new <a href="https://www.figma.com/community/plugin/908870217222043020/ProtoPie-Plugin" rel="noopener"><strong>ProtoPie plugin for Figma</strong></a>, you have lightning speed and flexibility at your fingertips. Import your designs from Figma into ProtoPie, all done locally—without any latency.</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1280/1*xLg44E8hgKI01r3ML45Jjg.gif" width="640" height="360" srcset="https://miro.medium.com/max/552/1*xLg44E8hgKI01r3ML45Jjg.gif 276w, https://miro.medium.com/max/1104/1*xLg44E8hgKI01r3ML45Jjg.gif 552w, https://miro.medium.com/max/1280/1*xLg44E8hgKI01r3ML45Jjg.gif 640w" sizes="640px" data-old-src="https://miro.medium.com/freeze/max/60/1*xLg44E8hgKI01r3ML45Jjg.gif?q=20"></p></div></div><figcaption>Control what you import. At lightning speed.</figcaption></figure><p id="29cc">Control what you import. Import top-level frames as scenes, and objects with the same layer hierarchy, positioning, and constraints as in Figma.</p><p id="9ce9">The ProtoPie plugin for Figma requires ProtoPie 5.2 or higher.</p><h2 id="d98b">Differences with the legacy Figma import?</h2><p id="6d13">Spend less time on bringing your designs from Figma into ProtoPie. With the new plugin, you save time and can spend more time on prototyping.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3200/1*P_QobAhiTx_KYU4fFHnwUw.png" width="1600" height="1006" srcset="https://miro.medium.com/max/552/1*P_QobAhiTx_KYU4fFHnwUw.png 276w, https://miro.medium.com/max/1104/1*P_QobAhiTx_KYU4fFHnwUw.png 552w, https://miro.medium.com/max/1280/1*P_QobAhiTx_KYU4fFHnwUw.png 640w, https://miro.medium.com/max/1400/1*P_QobAhiTx_KYU4fFHnwUw.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*P_QobAhiTx_KYU4fFHnwUw.png?q=20"></p></div></div></div><figcaption>The legacy Figma import on the left, the new ProtoPie plugin for Figma on the right.</figcaption></figure><ul><li id="b8f3">Import one or multiple frames and objects.</li><li id="9195">Import top-level frames as scenes.</li><li id="5eed">Import what you selected.</li><li id="e346">Import vector layers as SVG.</li><li id="ea4c">Import text layers as SVG that can be converted to text layers.</li><li id="7d1e">Import constraints as constraints.</li></ul><p id="9549"><a href="https://protopie.io/learn/docs/basic-features/import#import?utm_source=medium&amp;utm_medium=social&amp;utm_campaign=standard-article&amp;utm_content=figma-plugin" rel="noopener"><strong>Learn more</strong></a> about the ProtoPie plugin for Figma.</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1200/1*6R6YL9UkyU9bwS3PBqaSag.jpeg" width="600" height="300" srcset="https://miro.medium.com/max/552/1*6R6YL9UkyU9bwS3PBqaSag.jpeg 276w, https://miro.medium.com/max/1104/1*6R6YL9UkyU9bwS3PBqaSag.jpeg 552w, https://miro.medium.com/max/1200/1*6R6YL9UkyU9bwS3PBqaSag.jpeg 600w" sizes="600px" data-old-src="https://miro.medium.com/max/60/1*6R6YL9UkyU9bwS3PBqaSag.jpeg?q=20"></p></div></div></figure><p id="f67c">ProtoPie is the tool that helps you to bring your Figma designs come to life, indistinguishable from the end product.</p><p id="feec">It’s simply a matter of adding powerful interactions to your designs. Think of dynamic interactions involving conditions, formulas, and variables. Add another level of realism by including text input, camera, voice, media playback to your prototypes. Or even make prototypes that can communicate with each other. The possibilities are endless.</p><h2 id="9d2a">New to ProtoPie?</h2><p id="45a6">Try the ProtoPie plugin for Figma with this <a href="https://r.protopie.io/en/figma-plugin/marketing-file/" rel="noopener"><strong>example file</strong></a>.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2160/1*4kJjwUMw6iXIJVcYmy7Asw.png" width="1080" height="540" srcset="https://miro.medium.com/max/552/1*4kJjwUMw6iXIJVcYmy7Asw.png 276w, https://miro.medium.com/max/1104/1*4kJjwUMw6iXIJVcYmy7Asw.png 552w, https://miro.medium.com/max/1280/1*4kJjwUMw6iXIJVcYmy7Asw.png 640w, https://miro.medium.com/max/1400/1*4kJjwUMw6iXIJVcYmy7Asw.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*4kJjwUMw6iXIJVcYmy7Asw.png?q=20"></p></div></div></div></figure><p id="0d0d">Join our live event as our Head of Product Design, David Lee shares the journey of how we revamped the Figma import experience.</p><p id="6329">👉 <a href="https://www.eventbrite.com/e/protopies-journey-behind-revamping-the-figma-import-tickets-130748563473" rel="noopener"><strong>Register now</strong></a>.</p><ul><li id="f42c">Single sign-on (SSO) for ProtoPie Enterprise</li><li id="2c31">Auto line height</li><li id="6898">Duplicate with same distance</li><li id="2993">App icon for macOS Big Sur</li><li id="74e3">Trigger &amp; response names for voice prototyping</li></ul><figure><a href="https://protopie.io/?utm_source=medium&amp;utm_medium=social&amp;utm_campaign=standard-article&amp;utm_content=figma-plugin"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3336/0*PwpFUw9I5BCcmPr0.png" width="1668" height="390" srcset="https://miro.medium.com/max/552/0*PwpFUw9I5BCcmPr0.png 276w, https://miro.medium.com/max/1104/0*PwpFUw9I5BCcmPr0.png 552w, https://miro.medium.com/max/1280/0*PwpFUw9I5BCcmPr0.png 640w, https://miro.medium.com/max/1400/0*PwpFUw9I5BCcmPr0.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*PwpFUw9I5BCcmPr0.png?q=20"></p></div></div></a></figure><p id="cdbd"><em>Thanks for reading! :) If you enjoyed this article, hit that clap button below </em>👏<em>. Feel free to </em><a href="https://protopie.io/support" rel="noopener"><em>contact us</em></a><em> with your feedback and/or questions.</em></p></div></div></div>]]>
            </description>
            <link>https://blog.protopie.io/protopie-plugin-for-figma-a-revamped-import-experience-to-boost-productivity-5758892c4c58</link>
            <guid isPermaLink="false">hacker-news-small-sites-25371555</guid>
            <pubDate>Thu, 10 Dec 2020 09:14:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Digital Twins, a Requirement for Industrial AI]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25371343">thread link</a>) | @MorganeR
<br/>
December 10, 2020 | https://blog.senx.io/digital-twins-requirement-for-industrial-ai/ | <a href="https://web.archive.org/web/*/https://blog.senx.io/digital-twins-requirement-for-industrial-ai/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Using AI to make industrial assets more efficient and reduce their downtime is on many agendas. Learn how digital twins and time series data play a major role in this plan.</p><article>
      
<p><strong>When interviewed, CEOs across industries all state that AI is part of their top priorities.</strong> But when it comes to actual implementation AI projects are not very glamorous. Past simple proofs of concept and the hiring of a team of data scientists, there is usually no sign of the highly anticipated digital transformation wished by the CEOs.</p>



<p>There are multiple reasons for this disenchantment, far too many to list here. But among those, some are directly related to what we focus on at <a href="https://senx.io/" target="_blank" rel="noreferrer noopener">SenX</a>, data, and the way industries introduce them in their environment.</p>



<h2>No digital transformation without data</h2>



<p>The willingness to transform is genuine in many organizations, driven by ambitious visions or just the consciousness that the competitive landscape is evolving.</p>



<p>The next step is usually for those businesses to pick some quick wins to prove that the transformation can be initiated and comfort everyone that it does not mean changing teams or radically modifying their way of working.</p>



<p>Those short projects aim at demonstrating the methodology for transforming limited operational perimeters. They often involve solving a problem with approaches to leveraging new technologies. Those technologies, 100% digital, need fuel to work, and that fuel is data. <strong>So the first step is to ensure data are available</strong>.</p>



<p>The firms hired to help in building those quick wins will then wander among departments. They will harvest datasets here and there until they have sufficient matter for implementing their solutions.</p>



<p>This step can sometimes take time if the data is not well identified and distributed across the organization. But it is a mandatory path to follow as without data no digital transformation will happen.</p>



<figure></figure>



<h2>No AI without big data</h2>



<p>Past the simple quick wins done to bootstrap the transformation comes a time when more ambitious projects are brought on the table, and that is when AI (Artificial Intelligence) comes into the conversation. The hype around AI is so strong that projects around AI and ML (Machine Learning) cannot be neglected.</p>



<p>The problem with the current hype is that very few people really understand what AI actually implies. <strong>For many</strong>,<strong> you buy an AI like you buy a Microsoft Office 365 subscription</strong>, this is just not true. The promise of AI is to bring new, automatic, ways to use data to help in or even completely assume the decision process. This promise can only be fulfilled if the actual AI put to work, otherwise called the model, is actually trained on the data in your very own organization, and this requires once again the same digital transformation fuel, data. The difference is that this time you need more of it. You are no longer trying to light a fondue burner but a rocket engine!</p>



<p>Training a model does indeed require a lot of data covering the various aspects of your business operations you want the model to focus on, also covering a long period of time so trend and seasonality can be modeled. </p>



<h4>This has several impacts</h4>



<ul><li>The first is that you cannot expect to train a model and efficiently introduce AI in your operations until you actually have collected enough meaningful data. And if your organization has not done so so far you need to start as soon as possible. </li><li>The second impact is that this data collection process is not a one time job. It does not stop once you have enough data for training a model. It needs to go on and on so you keep on accumulating signals on how your business operates to retrain your models in the future if their performance starts to degrade. This means that prior to your journey into the core of AI you need to plan for big data to be collected, stored and made available to teams across your organization so they can start looking at the data and imagine possible uses and models.</li></ul>



<h2>No industrial AI without Digital Twins</h2>



<p>Among verticals, industrial organizations face the hardest problems of data collection. Industries whose data mainly relates to users using their services are lucky. In the end, their data are not that massive. Sure we have all heard stories of banks or retailers hoarding piles of data. But we are talking about a few thousand interactions per year per user. So even with a billion users, which not that many banks or retailers have, we are talking a few trillion events per year.</p>



<p>In the industrial world, things are different, the assets producing data do not eat or sleep. They work day and night and sometimes produce thousands of measurements per second.</p>



<h3>For example...</h3>



<p>Take for example the CERN experiments at the LHC. They produced 600 million events per second during the campaigns for the quest of the Higgs boson. That is 51 trillion events per day. Luckily for the CERN, not all events needed to be retained. With highly efficient AI-based detectors, which needed to be trained with massive data themselves, they were able to limit the production to 100 000 events per second sent for digital reconstruction and ultimately 200 events persisted per second. </p>



<p>But other sectors need to retain more data. Synchro phasors (or PMUs, phase monitoring units) monitoring electrical grids, for example. They each produce several 1000s measures per second, and there are thousands of those at the scale of a country like France. This means millions of C37.118.2 messages sent every second, not to mention the IEC61850 messages sent to supervise the substations. </p>



<p>Same thing in aeronautics where aircraft typically produce 5 000 to 15 000 data points per second they are operating, or industrial assets whose PLC (Programmable Logic Controllers) track the state of many sensors and actuators.</p>



<p>The use of AI in those verticals requires that those truly massive data be collected and organized. Since they are data related to physical assets, it is wise to use an approach which mimics these assets in a digital form, this approach is called Digital Twins. </p>



<figure></figure>



<h3>What are Digital Twins?</h3>



<p>The Digital Twin of an asset is the set of measures coming from its sensors and actuators. Those measures need to be tracked in time to catch the dynamics of the assets' operations. And the technology of choice to do so is a <a href="https://blog.senx.io/which-time-series-database-suited-to-your-needs/" target="_blank" rel="noreferrer noopener">Time Series Database</a>. Indeed Digital Twins are nothing else than time series, some for the sensors, some for the actuators with their states. And if you want more advanced digital twins, some with the control commands sent to the assets to modify how it behaves.</p>



<p>Once you start collecting the data from your assets in a Time Series Database, you can easily access the state of those assets at any point in time. More importantly, you can start extracting features to train models to detect anomalies and perform predictive maintenance.</p>



<h2>Takeaways</h2>



<p>AI is on every business' agenda, but the importance of data is too often overlooked. <strong>When it comes to industrial AI, the first step towards a successful implementation is the collection of all sensor data to build Digital Twins of the physical assets involved.</strong> This approach needs to leverage a Time Series Database, the kind of database SenX offers with the <a href="https://warp10.io/" target="_blank" rel="noreferrer noopener">Warp 10 Time Series Platform</a>.</p>



<p><a href="mailto:contact@senx.io" target="_blank" rel="noreferrer noopener">Contact us</a> to learn how SenX and its technologies can help you master your industrial AI adventure.</p>








<!-- relpost-thumb-wrapper --><!-- close relpost-thumb-wrapper -->      
           
    </article></div>]]>
            </description>
            <link>https://blog.senx.io/digital-twins-requirement-for-industrial-ai/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25371343</guid>
            <pubDate>Thu, 10 Dec 2020 08:45:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: A Rust-Based Fast Static Site Builder]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25371125">thread link</a>) | @camsjams
<br/>
December 10, 2020 | https://camsjams.github.io/rust-coal/ | <a href="https://web.archive.org/web/*/https://camsjams.github.io/rust-coal/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p><img src="https://camsjams.github.io/rust-coal/assets/images/favicon.png" alt="Coal in a mine cart"></p><div>
<p><strong>Coal</strong> is a command-line interface (CLI) to speed up your ability to create static HTML
websites
without having to setup dependencies or install other libraries.</p><p>

Just install <strong>Coal</strong> once on your machine, and get building!
</p></div>
</div></div>]]>
            </description>
            <link>https://camsjams.github.io/rust-coal/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25371125</guid>
            <pubDate>Thu, 10 Dec 2020 08:09:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thoughts about Mapbox GL JS moving to a NON-OS License]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25371037">thread link</a>) | @D_Guidi
<br/>
December 9, 2020 | http://blog.cleverelephant.ca/2020/12/mapbox-morrison.html | <a href="https://web.archive.org/web/*/http://blog.cleverelephant.ca/2020/12/mapbox-morrison.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <p><span>09 Dec 2020</span></p><p>Yesterday, Mapbox announced that they were moving their <a href="https://github.com/mapbox/mapbox-gl-js">Mapbox GL JS</a> library from a standard BSD license to a new very much <a href="https://github.com/mapbox/mapbox-gl-js/blob/main/LICENSE.txt">non-open source license</a>.</p>

<p><a href="https://joemorrison.medium.com/death-of-an-open-source-business-model-62bc227a7e9b">Joe Morrison said</a> the news “shook” him (and also the readers of the Hacker News front page, well done Joe). It did me as well. Although apparently for completely different reasons.</p>

<blockquote>
  <p>Mapbox is the protagonist of a story I’ve told myself and others countless times. It’s a seductive tale about the incredible, counterintuitive concept of the “open core” business model for software companies.
<br>– Joe Morrison</p>
</blockquote>

<p>There’s a couple things wrong with Joe’s encomium to Mapbox and “open core”:</p>

<ul>
  <li>first, Mapbox was <strong>never</strong> an open core business;</li>
  <li>second, open core is a <strong>pretty ugly model</strong> that has very little to do with the open source ethos of shared intellectual pursuit.</li>
</ul>

<p><img src="http://blog.cleverelephant.ca/images//2020/core.jpg" alt="Open Core"></p>

<h2 id="mapbox-was-never-open-core">Mapbox was never Open Core</h2>

<p>From the very start (well, at least from the early middle), Mapbox was built to be a location-based services business. It was to be the Google Maps for people who were unwilling to accept the downsides of Google Maps.</p>

<p>Google Maps will track you. They will take your data exhaust and ruthlessly monetize it. They will take your data and use it to build a better Google Maps that they will then re-sell to others.</p>

<p>If you value your data at all (if you are, say, a major auto maker), you probably don’t want to use Google Maps, because they are going to steal your data while providing you services. Also, Google Maps is increasingly the “only game in town” for location based services, and it seems reasonable to expect price increases (<a href="https://housesigma.com/blog-en/2018/06/07/google-map-price-hike/">it has already happened once</a>).</p>

<p><img src="http://blog.cleverelephant.ca/images//2020/google-location-history.png" alt="Google is Tracking You"></p>

<p>Nobody can compete with Google Maps, can they? Why yes, they can! Mapbox fuses the collaborative goodness of the <a href="https://openstreemap.org/">OpenStreetMap</a> community with clever software that enables the kinds of services that Google sells 
(<a href="https://docs.mapbox.com/api/maps/#raster-tiles">map tiles</a>, 
<a href="https://docs.mapbox.com/#search">geocoding</a>, 
<a href="https://docs.mapbox.com/#navigation">routing</a>, 
<a href="https://docs.mapbox.com/help/troubleshooting/access-elevation-data/">elevation services</a>), and a bunch of services Google doesn’t sell (like <a href="https://www.mapbox.com/mapbox-studio/">custom map authoring</a>) or won’t sell (like <a href="https://www.mapbox.com/vision/">automotive vision</a>).</p>

<p>But like Google, the value proposition Mapbox sells isn’t in the software, so much as the data and the platform underneath. Mapbox has built a unique, scalable platform for handling the huge problem of turning raw OSM data into usable services, and raw location streams into usable services. They sell access to that platform.</p>

<p>Mapbox has never been a software company, they’ve always been a data and services company.</p>

<p>The last company I worked for, <a href="https://carto.com/">CARTO</a>, had a similar model, only moreso. All the parts of their value proposition (PostgreSQL, PostGIS, the CARTO UI, the tile server, the upload, everything) are <a href="https://github.com/cartodb">open source</a>. But they want you to pay them when you load your data into their service and use their software there. How can that be? Well, do you want to assemble all those open source parts into a working system and keep it running? Of course not. You just want to publish a map, or run an analysis, or add a spatial analysis to an existing system. So you pay them money.</p>

<p>Is Mapbox an “open core” company? No, is there a “Mapbox Community Edition” everyone can have, but an “Enterprise Edition” that is only available under a proprietary license? No. Does Mapbox even sell <strong>any software at all</strong>? No. (Yes, some.) They (mostly) sell services.</p>

<p>So what’s with the re-licensing? I’ll come back to that, but first…</p>

<h2 id="open-core-is-a-shitty-model">Open Core is a Shitty Model</h2>

<p>Actually, no, it seems to be a passable <strong>monetization</strong> model, for some businesses. It’s a shitty open source model though.</p>

<ul>
  <li>MongoDB has an open source core, and sells a bunch of proprietary enterprise add-ons. They’ve grown very fast and might even reach sufficient velocity to escape their huge VC valuation (or they may yet be sucked into the singularity).</li>
  <li>Cloudera before them reached huge valuations selling proprietary add-ons around the open Hadoop ecosystem.</li>
  <li>MySQL flirted with an open core model for many years, but mostly stuck to spreading FUD about the GPL in order to get customers to pay them for proprietary licenses.</li>
</ul>

<p>Easily the strangest part of the MySQL model was trash-talking the very open source license <strong>they chose</strong> to place their open source software under.</p>

<p>All those companies have been quite succesful along the axes of “getting users” and “making money”. Let me tell you why open core is nonetheless a shitty model:</p>

<ul>
  <li>Tell me about the MongoDB developer community. Where do they work? Oh right, Mongo.</li>
  <li>Tell me about the Cloudary developer community? Where do they work?</li>
  <li>Tell me about the MySQL developer community? Where to they work? Oh right, <strong>Oracle</strong>. (There’s a whole other blog post to be written about why sole corporate control of open source projects is a <strong>bad idea</strong>.)</li>
</ul>

<p>A good open source model is one that promotes heterogeneity of contributors, a sharing of control, and a rising of all boats when the software succeeds. Open core is all about centralizing gain and control to the sponsoring organization.</p>

<p>This is going to sound precious, but the leaders of open core companies don’t “care” about the ethos of open source. The CEOs of open core companies view open source (correctly, from their point of view) as a “sales channel”. It’s a way for customers to discover their paid offerings, it’s not an end in itself.</p>

<p><img src="http://blog.cleverelephant.ca/images//2020/funnel.png" width="75%" alt="Sales Funnel"></p>

<blockquote>
  <p>We didn’t open source it to get help from the community, to make the product better. We open sourced as a freemium strategy; to drive adoption. 
<br>– Dev Ittycheria, CEO, MongoDB</p>
</blockquote>

<p>So, yeah, open core is a way to make money but it doesn’t “do” anything for open source as a shared proposition for building useful tools anyone can use, for anything they find useful, anytime and anywhere they like.</p>

<p>Check out <a href="https://www.youtube.com/watch?v=8q5o-4pnxDQ">Adam Jacob’s take</a> on the current contradictions in the world of open source ethics; there are no hard and fast answers.</p>

<h2 id="mapbox-shook-me-too">Mapbox Shook Me Too</h2>

<p>I too was a little shook to learn of the <a href="https://news.ycombinator.com/item?id=25347310">Mapbox GL JS relicensing</a>, but perhaps not “surprised”. This had happened before, with <a href="https://news.ycombinator.com/item?id=14734589">Tilemill</a> (open) morphing into <a href="https://www.mapbox.com/mapbox-studio/">Mapbox Studio</a> (closed).</p>

<p>The change says nothing about “open source” in the large as a model, and everything about “single vendor projects” and whether you should, strategically, believe their licensing.</p>

<p><img src="http://blog.cleverelephant.ca/images//2020/empty-promise.jpg" alt="Empty Promises"></p>

<p>I (and others) took the licensing (incorrectly) of Mapbox GL JS to be a promise, not only for now but the future, and made decisions based on that (incorrect) interpretation. I integrated GL JS into <a href="https://github.com/CrunchyData/pg_tileserv/blob/master/assets/preview-table.html">an open source project</a> and now I have to revisit that decision.</p>

<p>The license change also says something about the business realities Mapbox is facing going forward. The business of selling location based services is a competitive one, and one that is perhaps not panning out as well as their venture capital valuation (<a href="https://blog.mapbox.com/softbank-mapbox-series-c-be207b866b27">billions?</a>) would promise.</p>

<p>No doubt the board meetings are fraught. Managers are casting about for future sources of revenue, for places where more potential customers can be <strong>squeeeeezed</strong> into the sales funnel.</p>

<p>I had high hopes for Mapbox as a counterweight to Google Maps, a behemoth that seems <a href="https://www.justinobeirne.com/google-maps-moat">likely to consume us all</a>. The signs that the financial vice is beginning to close on it, that the promise might not be fulfilled, they shake me.</p>

<p>So, yeah, Joe, this is big news. Shaking news. But it has nothing to do with “open source as a business model”.</p>


</div></div>]]>
            </description>
            <link>http://blog.cleverelephant.ca/2020/12/mapbox-morrison.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25371037</guid>
            <pubDate>Thu, 10 Dec 2020 07:54:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Restore pictures for free with deep learning tool]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25370708">thread link</a>) | @panabee
<br/>
December 9, 2020 | https://hotpot.ai/restore-picture | <a href="https://web.archive.org/web/*/https://hotpot.ai/restore-picture">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="rootBody">

		


		<div id="rootYield">
			




<div id="pageBox">

	


	<div id="mainBox">

		<div id="controlBoxWrapper">
			<div id="controlBox">

				<div>
					<p><img src="https://hotpot.ai/images/site/transparent.gif">
					</p>
				</div>

				

				<p><span>Restore</span>
				</p>

			</div>
		</div>

		

	</div>


	<article id="apiAccess">
		<h2>API Access</h2>

		<p>
			Add this service to your app, website, or company workflow with the <a href="https://hotpot.ai/docs/api">Hotpot API</a>.
		</p>
	</article>

	


	<article>
		<h2>Directions</h2>

		<p>
			Upload an image.
		</p>

		<p>
			Enable "Has Scratches" to explicitly remove scratches.
		</p>

		<p>
			To turn black &amp; white pictures to color, try our AI <a href="https://hotpot.ai/colorize-picture?s=restorer">Picture Colorizer</a> service.
		</p>
	</article>


	<article>
		<h2>Overview</h2>

		<p>
			This Hotpot AI service restores pictures by automatically performing scratch removal, face enhancement, and color sharpening. What used to require trained professionals hours can now be accomplished in seconds.
		</p>

		<p>
			The service can repair and restore both color and black &amp; white photographs.
		</p>

		<p>
			While this service automates photo restoration, it cannot replace experts for demanding restoration jobs. It is designed to help consumers with lightweight requirements while helping professionals save time on difficult restoration requests.
		</p>

		<p>
			For this service, pictures are not saved without user permission. For storage costs and user privacy, we only retain images for as long as necessary to run our machine learning models, and do not store photos beyond this.
		</p>

		<p>
			Note: the maximum image resolution we support is 1280x1280, but our new model supports larger images and is launching soon. Please contact us to try this newer model.
		</p>
	</article>


	<article>
	<h2>AI Tools</h2>

	<p>
		Explore other Hotpot <a href="https://hotpot.ai/tools">AI tools</a>, including ones for <a href="https://hotpot.ai/remove-background">background removal</a>, <a href="https://hotpot.ai/personalize-art">art personalization</a>, <a href="https://hotpot.ai/enlarge-picture">image upscaler</a> for photo prints, <a href="https://hotpot.ai/restore-picture">picture restoration</a>, <a href="https://hotpot.ai/colorize-picture">picture colorization</a>, and more.
	</p>
</article>


	<article>
		<h2>Research Credit</h2>

		<p>
			Our technology applies proprietary enhancements to the amazing Microsoft research project, <a href="https://github.com/microsoft/Bringing-Old-Photos-Back-to-Life" target="_blank">Bringing Old Photos Back to Life</a>.
		</p>
	</article>


	<article>
		<h2>Contribute</h2>

		<p>
			Help improve our AI by <a href="https://hotpot.ai/contact">sharing images</a> that convert poorly.
		</p>
	</article>


</div>








<!---------------------------- Hotjar BEGIN ---------------------------->



<!---------------------------- Hotjar END ----------------------------->
		</div>

	</div></div>]]>
            </description>
            <link>https://hotpot.ai/restore-picture</link>
            <guid isPermaLink="false">hacker-news-small-sites-25370708</guid>
            <pubDate>Thu, 10 Dec 2020 07:02:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Measuring page performance – Learn Puppeteer and Playwright]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25370533">thread link</a>) | @kiyanwang
<br/>
December 9, 2020 | https://theheadless.dev/posts/basics-performance/ | <a href="https://web.archive.org/web/*/https://theheadless.dev/posts/basics-performance/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>The need for fast and responsive applications has never been greater because of the move from <a href="https://gs.statcounter.com/platform-market-share/desktop-mobile-tablet/worldwide/2019" target="_blank" rel="noopener noreferrer">desktop to mobile</a>. Still, web applications have been increasing in <a href="https://httparchive.org/reports/page-weight" target="_blank" rel="noopener noreferrer">complexity and size</a>, with rising load times. It is therefore clear why the topic of webpage performance is more popular today than it likely ever was.</p> <p>This article aims at giving a practical introduction to the whys and hows of web performance, without getting lost in the depth or breadth of this massive topic.</p> <h2 id="why-performance-matters"><a href="#why-performance-matters">#</a> Why performance matters</h2> <p>The time it takes for a service to become usable, as well as its general responsiveness, bear a lot of weight on the user's perception of that service. Helpful features, great design and other prominent characteristics all become irrelevant when an online service is so slow that users navigate away.</p> <p>You can build the best web application in the world, but be mindful that each user will have a specific amount of time they are willing to invest in your service to solve their problems. Exceed that amount, and you risk losing them to a different, more performant solution. This is even truer for new users, who haven't yet been given proof of the quality of your service, and are essentially investing their time up-front, hoping for a return.</p> <h3 id="a-competitive-differentiator"><a href="#a-competitive-differentiator">#</a> A competitive differentiator</h3> <p>There is a brighter side to the topic: if low performance can sink an online platform, high performance can very well help it rise to the top. Speed and responsiveness can be a differentiating characteristic for a service, prompting users to choose it over the competition. Therefore an investment in this area will almost always pay off. Some notorious real-world examples from known businesses include:</p> <ol><li>Pinterest decreasing wait time for their users, <a href="https://medium.com/@Pinterest_Engineering/driving-user-growth-with-performance-improvements-cfc50dafadd7" target="_blank" rel="noopener noreferrer">increasing both traffic and conversions</a>.</li> <li>Zalando applying small improvements in load time and finding a direct correlation with <a href="https://engineering.zalando.com/posts/2018/06/loading-time-matters.html" target="_blank" rel="noopener noreferrer">increased revenue per session</a>.</li> <li>The BBC discovering that every extra second that a page took to load led to 10% of <a href="https://www.creativebloq.com/features/how-the-bbc-builds-websites-that-scale" target="_blank" rel="noopener noreferrer">users leaving the page</a>.</li></ol> <h2 id="measuring-performance"><a href="#measuring-performance">#</a> Measuring performance</h2> <p>Given the importance of page performance, it is no coincidence that browsers expose a ton of insights into <a href="https://web.dev/metrics/" target="_blank" rel="noopener noreferrer">performance metrics</a>. Being aware of how your application scores against these <em>across time</em> will provide you the feedback you need to keep it performant for your users. There are several approaches that can be combined to achieve the best results:</p> <ol><li><em>Real user monitoring</em> to understand what performance actual end-users of your service are experiencing.</li> <li><em>Synthetic monitoring</em> to proactively gather intel on service performance, as well as to find issues before users stumble into them.</li> <li><em>Performance testing</em> to avoid releasing performance regression to production in the first place.</li> <li><em>Regular audits</em> to get an overview of your page's performance and suggestions on how to improve it, e.g. with tools such as <a href="https://developers.google.com/web/tools/lighthouse" target="_blank" rel="noopener noreferrer">Google Lighthouse</a>.</li></ol>  <p>As much as we should be striving to build performant applications, we should commit to monitoring and testing performance to enable continuous feedback and rapid intervention in case of degradation. Puppeteer and Playwright give us a great toolkit to power both synthetic monitoring and performance testing.</p> <ol><li>Access to the Web Performance APIs, especially <a href="https://developer.mozilla.org/en-US/docs/Web/API/PerformanceNavigationTiming" target="_blank" rel="noopener noreferrer">PerformanceNavigationTiming</a> and <a href="https://developer.mozilla.org/en-US/docs/Web/API/PerformanceResourceTiming" target="_blank" rel="noopener noreferrer">PerformanceResourceTiming</a>.</li> <li>Whenever testing against Chromium, access to the Chrome DevTools Protocol for traffic inspection, network emulation and more.</li> <li>Easy interoperability with performance libraries from the Node.js ecosystem.</li></ol> <h3 id="web-performance-apis"><a href="#web-performance-apis">#</a> Web Performance APIs</h3> <p>The <a href="https://www.w3.org/TR/navigation-timing/" target="_blank" rel="noopener noreferrer">Navigation Timing</a> and the <a href="https://www.w3.org/TR/resource-timing-1/" target="_blank" rel="noopener noreferrer">Resource Timing</a> performance APIs are <a href="https://www.w3.org/" target="_blank" rel="noopener noreferrer">W3C</a> specifications. The <a href="https://developer.mozilla.org/en-US/docs/Web/Performance/Navigation_and_resource_timings" target="_blank" rel="noopener noreferrer">MDN docs</a> very clearly define the scope of both:</p> <blockquote><p>Navigation timings are metrics measuring a browser's document navigation events. Resource timings are detailed network timing measurements regarding the loading of an application's resources. Both provide the same read-only properties, but navigation timing measures the main document's timings whereas the resource timing provides the times for all the assets or resources called in by that main document and the resources' requested resources.</p></blockquote> <p>We can use the Navigation Timing API to retrieve timestamps of key events in the page load timeline.</p>  <p>The Resource Timing API allows us to zoom in to single resources and get accurate information about how quickly they are being loaded. For example, we could specifically look at our website's logo:</p>  <h3 id="chrome-devtools-for-performance"><a href="#chrome-devtools-for-performance">#</a> Chrome DevTools for performance</h3> <p>The Chrome DevTools Protocol offers many great performance tools for us to leverage together with Puppeteer and Playwright.</p> <p>One important example is network throttling, through which we can simulate the experience of users accessing our page with different network conditions.</p>  <p>The DevTools Protocol is quite extensive. We recommend exploring the <a href="https://chromedevtools.github.io/devtools-protocol/" target="_blank" rel="noopener noreferrer">documentation</a> and getting a comprehensive overview of its capabilities.</p> <h3 id="additional-performance-libraries"><a href="#additional-performance-libraries">#</a> Additional performance libraries</h3> <p>Lighthouse can easily be used programmatically with Playwright and Puppeteer to gather values and scores for different metrics, like <a href="https://web.dev/interactive/" target="_blank" rel="noopener noreferrer">Time To Interactive (TTI)</a>:</p>  <h2 id="further-reading"><a href="#further-reading">#</a> Further reading</h2> <ol><li>The comprehensive <a href="https://developer.mozilla.org/en-US/docs/Web/Performance" target="_blank" rel="noopener noreferrer">MDN Web Performance documentation</a></li> <li><a href="https://web.dev/learn/#performance" target="_blank" rel="noopener noreferrer">web.dev's performance section</a></li> <li><a href="https://addyosmani.com/blog/puppeteer-recipes/" target="_blank" rel="noopener noreferrer">Web Performance Recipes With Puppeteer</a> by Addy Osmani</li> <li><a href="https://github.com/aslushnikov/getting-started-with-cdp" target="_blank" rel="noopener noreferrer">Getting started with Chrome DevTools Protocol</a> by Andrey Lushnikov</li> <li><a href="https://developers.google.com/web/tools/lighthouse#get-started" target="_blank" rel="noopener noreferrer">Get Started with Google Lighthouse</a></li></ol></div></div>]]>
            </description>
            <link>https://theheadless.dev/posts/basics-performance/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25370533</guid>
            <pubDate>Thu, 10 Dec 2020 06:35:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A New species of whale has been discovered off the western coast of Mexico]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25370430">thread link</a>) | @williamsharris
<br/>
December 9, 2020 | https://www.thevast.net/post/breaking-new-species-of-whale-discovered | <a href="https://web.archive.org/web/*/https://www.thevast.net/post/breaking-new-species-of-whale-discovered">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="8.7.1"><div dir="ltr"><div><div id="viewer-bjhjd"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.thevast.net/post/breaking-new-species-of-whale-discovered" data-pin-media="https://static.wixstatic.com/media/1f143b_237418f1ee6d42bcaac120d3280c4e62~mv2.png/v1/fit/w_768%2Ch_432%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/1f143b_237418f1ee6d42bcaac120d3280c4e62~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p></div></div></div></div><p id="viewer-2vu4e"><span>According to a recent press release by Sea Shepherd Conservation Society, a <a href="https://www.thevast.net/post/breaking-new-species-discovered-in-waters-off-puerto-rico" target="_blank" rel="noopener"><u>new species</u></a> of whale has been discovered off the western coast of Mexico, near the San Benito islands - an island range located about 300 miles from the U.S.-California border.<a href="https://ctt.ac/4M9Hw" target="_blank" rel="noopener"><u> Click to tweet!</u></a></span></p><p id="viewer-5bcr9"><span>Sea Shepherd received some interesting underwater acoustic signals from the San Benito islands - acoustic signals that had never been recorded before. All species of whale have their own distinct set of sounds, and acoustic matching is frequently used to identify whale species; but what happens when you pick up a sound that no one has ever heard before? In Sea Shepherds case, they decided to send a crew to check it out and find the source of the sound. They <em>never</em> expected to discover a new species in the process.</span></p><h2 id="viewer-e6u0c"><span>The Sound of a New Species</span></h2><p id="viewer-d0g91"><span>If the sound was previously unidentified, then why were the scientists so surprised to find a new species? Wouldn't it seem that a new sound and new species go hand in hand?</span></p><p id="viewer-bv409"><span>Well, the group of researchers, which included Jay Barlow, Elizabeth Henderson, and Gustavo Cardenas Hinojosa (a beaked whale expert) matched the sound to a likely candidate; the Perrins Beaked Whale. In 2018, they received a prior set of unidentified acoustic signals from the San Benito islands which the researchers expected to be from the Perrins Beaked Whale - so in their recent pursuit, this is what they expected to find. The Perrins Beaked Whale is an extremely rare type of whale characterized by only six specimens, many of which were observed in a stranding (carcasses washed up on shore); a species with an incredibly small amount of data and information - a problem that is unfortunately not uncommon when dealing with marine sciences.</span></p><p id="viewer-ei3c8"><span>So, when the research team arrived on site, they were pleasantly shocked and surprised to see what was there to greet them; three friendly, unidentified beaked whales! According to the scientists, the whales approached the ship up to three times, which made it easy for them to record data. Aside from the sightings of the beaked whales, the scientists were able to record acoustic data, take photographs and video, and collect genetic samples. The experts claim to easily be able to confirm, based on morphology and acoustics, that the whales are a new species - however, to be perfectly clear, genetic testing on the samples will need to be conducted to classify and describe the new species. These samples were taken as eDNA - a new, fancy technique in which gallons of the surrounding water is captured and filtered for bits of DNA which can then be cross-checked against the DNA of known species. As Sea Shepherd is known for their care for whales and other marine mammals, this is the best method for them to use as it poses no risk to the specimen.</span></p><p id="viewer-94u0b"><span>To hear it from <a href="https://seashepherd.org/news/sea-shepherd-research-mission-discovers-possible-new-species-of-whale-in-mexico/" target="_blank" rel="noopener"><u>the researchers</u></a>, <span>“We saw something new. Something that was not expected in this area, something that doesn’t match, either visually or acoustically, anything that is known to exist,” said Dr. Jay Barlow. “It just sends chills up and down my spine when I think that we might have accomplished what most people would say was truly impossible – finding a large mammal that exists on this earth that is totally unknown to science.”</span></span></p><p id="viewer-6lno8"><span><span>As the scientific name has not yet been given, the common name is up to the general public. Common names are given to a species of fish, usually based on looks, and usually have nothing to do with the scientific name - TheVast supports the suggested name "Fortune Whale", because they may be a sign of good fortune riding the waves at the end of the notorious year, 2020! They may truly be a whale of fortune. What do you think they should be named? Do you like the name Fortune Whale? </span><a href="https://ctt.ac/6qO1o" target="_blank" rel="noopener"><span><u>Let us know on Twitter</u></span></a><span>!</span></span></p><h2 id="viewer-aap6s"><span><span>Echolocation and Sonar Among Cetaceans</span></span></h2><div id="viewer-90q3l"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.thevast.net/post/breaking-new-species-of-whale-discovered" data-pin-media="https://static.wixstatic.com/media/1f143b_0057b2503b1a4b93b6a189270c47e633~mv2.jpg/v1/fit/w_1000%2Ch_1000%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/1f143b_0057b2503b1a4b93b6a189270c47e633~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p></div></div></div></div><p id="viewer-9sptk"><span>Whales, and all cetaceans, have distinct and unique acoustic signals that they use for communication and echolocation. The water is a much different medium than air, so these tools allow the species to thrive in their harsh environment.</span></p><p id="viewer-fatfo"><span>Toothed whales, of which the beaked whales fit into, are known as <strong>Odontocetes</strong> and they produce a sound that can be described as a click - very piercing - for their survival, navigation, and reproduction. A notable example would be dolphins, which most people may be familiar with. The odontocete whale uses air (sometimes recycled) to produce the sounds, pushing it through the <strong>phonic lips</strong> (located above the head) which contract and compress to cause vibrations in the membrane, which then passes into the <strong>melon</strong> (the bulbous protrusion of the whale's forehead; again think dolphin) which condenses, shapes, and projects the vibrations into the water like a beam. Pretty incredible, right? Sonar in the Navy works in a similar way. A great example of how the natural world can inform human mechanics and developments to increase our potential or lead to more innovation. </span></p><p id="viewer-8gukb"><span>If you enjoy reading this type of content as much as we like producing it, you should seriously consider following us on <a href="https://twitter.com/TheVastNews" target="_blank" rel="noopener"><u>Twitter</u></a> and <a href="https://www.facebook.com/TheVastNews" target="_blank" rel="noopener"><u>Facebook</u></a>, as well as subscribing to our <a href="https://www.youtube.com/channel/UC87f-kaURLLfrTRaLD0IWkA?view_as=subscriber" target="_blank" rel="noopener"><u>Youtube channel</u></a> to keep up with all of our articles and videos. You might also consider <a href="https://www.thevast.net/newsletter" target="_blank" rel="noopener"><u>subscribing to our newsletter</u></a> - we pick our top stories of the month, get comments and engagement from readers, and find top content from similar content producers and send the newsletter out so you can stay up to date with all the exciting marine science and ocean exploration news!</span></p></div></div></div></div></article></div></div>]]>
            </description>
            <link>https://www.thevast.net/post/breaking-new-species-of-whale-discovered</link>
            <guid isPermaLink="false">hacker-news-small-sites-25370430</guid>
            <pubDate>Thu, 10 Dec 2020 06:19:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Set Up OBS Studio for Screen Recording – Step-by-Step Procedure]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25369651">thread link</a>) | @ponderingfish
<br/>
December 9, 2020 | https://ottverse.com/setup-obs-studio-for-recording-screen-tutorial/ | <a href="https://web.archive.org/web/*/https://ottverse.com/setup-obs-studio-for-recording-screen-tutorial/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

		<div>

		

	<div id="primary">

		
					<main id="main">

				
					
					

<article id="post-2893" itemtype="https://schema.org/CreativeWork" itemscope="itemscope">

		
	
	
<div>

	
	<!-- .entry-header -->

	
	<div itemprop="text">

		
		
<p>So, you’ve downloaded and installed <a href="https://obsproject.com/" target="_blank" rel="noopener">OBS Studio</a> on your computer and you want to start recording your screen, but you’re lost?</p>



<p>Well, simply <strong>follow this step-by-step tutorial and you will be ready to start recording high-quality videos of your screen in no time with OBS Studio</strong>. </p>



<p>Let’s get started.</p>



<hr>



<h2>A Brief Overview of OBS Studio</h2>



<p>Before we go further, let’s get an idea of the GUI layout of OBS Studio. To keep things simple, we will divide OBS Studio into 6 sections.</p>



<div><figure><img width="1024" height="550" src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/obs-screen.png?resize=1024%2C550&amp;ssl=1" alt="Set up OBS Studio for Recording" srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/obs-screen.png?resize=1024%2C550&amp;ssl=1 1024w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/obs-screen.png?resize=300%2C161&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/obs-screen.png?resize=768%2C412&amp;ssl=1 768w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/obs-screen.png?resize=1536%2C825&amp;ssl=1 1536w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/obs-screen.png?resize=1200%2C644&amp;ssl=1 1200w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/obs-screen.png?w=1598&amp;ssl=1 1598w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20550'%3E%3C/svg%3E" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/obs-screen.png?resize=1024%2C550&amp;ssl=1 1024w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/obs-screen.png?resize=300%2C161&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/obs-screen.png?resize=768%2C412&amp;ssl=1 768w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/obs-screen.png?resize=1536%2C825&amp;ssl=1 1536w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/obs-screen.png?resize=1200%2C644&amp;ssl=1 1200w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/obs-screen.png?w=1598&amp;ssl=1 1598w" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/obs-screen.png?resize=1024%2C550&amp;ssl=1"></figure></div>



<h3>1. Scenes</h3>



<p>If OBS is a canvas, <code>Scenes</code> would be a place that stores various pictures you can switch at any time. Each scene is used for different purposes. For example, a streamer would use different ones to signify when he is playing, waiting in a lobby, or taking a break.</p>



<h3>2. Sources</h3>



<p>You can think of <code>Sources</code> like a set of colors, you use to paint a scene. These are all of the elements shown on your screen during a recording. A good example of Sources are your logo, webcam, and chat window.</p>



<h3>3. Audio Mixer</h3>



<p>The mixer is where you will set up everything audio-related. More on that later.</p>



<h3>4. Scene Transitions</h3>



<p>Transitions provide you with animations you can play while switching up the scenes.</p>



<h3>5. Controls</h3>



<p>This houses the most important controls you will use to manipulate your recording.</p>



<h3>6. Preview Window</h3>



<p>Finally, there is a Preview Window. This shows exactly what you will see after you’ve recorded your video.</p>



<p>And don’t forget that OBS Studio is really customizable. You can drag and drop all of these windows and re-organize them to create a unique layout that suits your workflow.</p>



<p>Great, now that you have an idea of what hte OBS Studio layout looks like, let’s get started with setting up OBS Studio for recording.</p>



<hr>



<h2>Setup OBS Studio for Recording Your Screen</h2>



<p>Now let’s follow this step-by-step procedure to setup OBS Studio and start recording! </p>



<h3>1. Add Audio Sources</h3>



<p>Let’s start by setting up the audio. First, go to the <code>Controls &gt; Settings &gt; Audio</code>. Set both <code>Desktop Audio</code> and <code>Mic Audio</code> to <code>default</code>. Everything else should be disabled.</p>



<div><figure><img width="1024" height="576" src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Audio-Settings.png?resize=1024%2C576&amp;ssl=1" alt="Set up OBS Studio for Recording" srcset="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Audio-Settings.png?resize=1024%2C576&amp;ssl=1 1024w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Audio-Settings.png?resize=300%2C169&amp;ssl=1 300w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Audio-Settings.png?resize=768%2C432&amp;ssl=1 768w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Audio-Settings.png?resize=1536%2C864&amp;ssl=1 1536w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Audio-Settings.png?resize=1200%2C675&amp;ssl=1 1200w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Audio-Settings.png?w=1600&amp;ssl=1 1600w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20576'%3E%3C/svg%3E" data-lazy-srcset="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Audio-Settings.png?resize=1024%2C576&amp;ssl=1 1024w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Audio-Settings.png?resize=300%2C169&amp;ssl=1 300w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Audio-Settings.png?resize=768%2C432&amp;ssl=1 768w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Audio-Settings.png?resize=1536%2C864&amp;ssl=1 1536w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Audio-Settings.png?resize=1200%2C675&amp;ssl=1 1200w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Audio-Settings.png?w=1600&amp;ssl=1 1600w" data-lazy-src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Audio-Settings.png?resize=1024%2C576&amp;ssl=1"></figure></div>



<p>Let’s quickly add some filters to make your voice sound more professional. Click on the gear icon next to <code>Mic/Aux</code> in <code>Audio Mixer</code>.</p>



<div><figure><img width="742" height="431" src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Filter.png?resize=742%2C431&amp;ssl=1" alt="Set up OBS Studio for Recording" srcset="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Filter.png?w=742&amp;ssl=1 742w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Filter.png?resize=300%2C174&amp;ssl=1 300w" sizes="(max-width: 742px) 100vw, 742px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20742%20431'%3E%3C/svg%3E" data-lazy-srcset="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Filter.png?w=742&amp;ssl=1 742w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Filter.png?resize=300%2C174&amp;ssl=1 300w" data-lazy-src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/Filter.png?resize=742%2C431&amp;ssl=1"></figure></div>



<p>Here we have 3 options: <code>Noise Suppression</code>, <code>Noise Gate</code>, and <code>Gain</code>.</p>



<div><figure><img width="598" height="257" src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/0_4ByvJMTJqxt68LJG_.png?resize=598%2C257&amp;ssl=1" alt="Set up OBS Studio for Recording" srcset="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/0_4ByvJMTJqxt68LJG_.png?w=598&amp;ssl=1 598w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/0_4ByvJMTJqxt68LJG_.png?resize=300%2C129&amp;ssl=1 300w" sizes="(max-width: 598px) 100vw, 598px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20598%20257'%3E%3C/svg%3E" data-lazy-srcset="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/0_4ByvJMTJqxt68LJG_.png?w=598&amp;ssl=1 598w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/0_4ByvJMTJqxt68LJG_.png?resize=300%2C129&amp;ssl=1 300w" data-lazy-src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/0_4ByvJMTJqxt68LJG_.png?resize=598%2C257&amp;ssl=1"></figure></div>



<ul><li><strong>Noise Suppression</strong> will remove most of your background noise. Start from -10 dB and drop lower until you can’t hear the noise.</li><li><strong>Noise Gate</strong> will turn off your microphone when the volume drops below the Close Threshold. This way you won’t record your breathing. Settings will vary depending on your type of mic, so play with it until it feels natural.</li><li><strong>Gain</strong> is used for changing the volume of your mic.</li></ul>



<h3>2. Choose Recording Quality</h3>



<p>Go to the <code>Output</code> tab on the left and under <code>Recording</code> choose the path where OBS will save all your videos. By default, it’s set to <code>\Users\OBS\Videos</code>.</p>



<div><figure><img width="1024" height="576" src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Output.png?resize=1024%2C576&amp;ssl=1" alt="Set up OBS Studio for Recording" srcset="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Output.png?resize=1024%2C576&amp;ssl=1 1024w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Output.png?resize=300%2C169&amp;ssl=1 300w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Output.png?resize=768%2C432&amp;ssl=1 768w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Output.png?resize=1536%2C864&amp;ssl=1 1536w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Output.png?resize=1200%2C675&amp;ssl=1 1200w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Output.png?w=1600&amp;ssl=1 1600w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20576'%3E%3C/svg%3E" data-lazy-srcset="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Output.png?resize=1024%2C576&amp;ssl=1 1024w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Output.png?resize=300%2C169&amp;ssl=1 300w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Output.png?resize=768%2C432&amp;ssl=1 768w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Output.png?resize=1536%2C864&amp;ssl=1 1536w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Output.png?resize=1200%2C675&amp;ssl=1 1200w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Output.png?w=1600&amp;ssl=1 1600w" data-lazy-src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Output.png?resize=1024%2C576&amp;ssl=1"></figure></div>



<p>Next, click on <code>Recording Quality</code>.</p>



<div><figure><img src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Stream-quality.png?resize=874%2C675&amp;ssl=1" alt="Set up OBS Studio for Recording" width="874" height="675" srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Stream-quality.png?w=985&amp;ssl=1 985w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Stream-quality.png?resize=300%2C232&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Stream-quality.png?resize=768%2C593&amp;ssl=1 768w" sizes="(max-width: 874px) 100vw, 874px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20874%20675'%3E%3C/svg%3E" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Stream-quality.png?w=985&amp;ssl=1 985w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Stream-quality.png?resize=300%2C232&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Stream-quality.png?resize=768%2C593&amp;ssl=1 768w" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Stream-quality.png?resize=874%2C675&amp;ssl=1"></figure></div>



<p>If you are just beginning to record your videos, we recommend that you choose <code>High Quality</code>. This will provide you with pretty good quality and reasonable file size.</p>



<p>Others should pick <code>Indistinguishable Quality</code>. This will give you a fully professional video that you can later edit in post-processing.</p>



<p>We can’t really recommend <code>Lossless</code> as it will eat up your storage without providing a perceptible difference.</p>



<p>Under <code>Recording Format</code> choose either <code>MKV</code> or <code>FLV</code> as they are very stable container formats. In case your PC or PBS crashes, you will likely be able to save your recording. </p>



<div><figure><img src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Format.png?resize=864%2C666&amp;ssl=1" alt="Set up OBS Studio for Recording" width="864" height="666" srcset="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Format.png?w=979&amp;ssl=1 979w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Format.png?resize=300%2C231&amp;ssl=1 300w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Format.png?resize=768%2C592&amp;ssl=1 768w" sizes="(max-width: 864px) 100vw, 864px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20864%20666'%3E%3C/svg%3E" data-lazy-srcset="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Format.png?w=979&amp;ssl=1 979w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Format.png?resize=300%2C231&amp;ssl=1 300w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Format.png?resize=768%2C592&amp;ssl=1 768w" data-lazy-src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-Format.png?resize=864%2C666&amp;ssl=1"></figure></div>



<p>You can easily convert your files later, by going to <code>File &gt; Remux Recording</code>.</p>



<div><figure><img src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/Remux.png?resize=942%2C530&amp;ssl=1" alt="Set up OBS Studio for Recording" width="942" height="530" srcset="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/Remux.png?resize=1024%2C576&amp;ssl=1 1024w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/Remux.png?resize=300%2C169&amp;ssl=1 300w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/Remux.png?resize=768%2C432&amp;ssl=1 768w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/Remux.png?resize=1536%2C864&amp;ssl=1 1536w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/Remux.png?resize=1200%2C675&amp;ssl=1 1200w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/Remux.png?w=1600&amp;ssl=1 1600w" sizes="(max-width: 942px) 100vw, 942px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20942%20530'%3E%3C/svg%3E" data-lazy-srcset="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/Remux.png?resize=1024%2C576&amp;ssl=1 1024w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/Remux.png?resize=300%2C169&amp;ssl=1 300w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/Remux.png?resize=768%2C432&amp;ssl=1 768w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/Remux.png?resize=1536%2C864&amp;ssl=1 1536w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/Remux.png?resize=1200%2C675&amp;ssl=1 1200w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/Remux.png?w=1600&amp;ssl=1 1600w" data-lazy-src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/12/Remux.png?resize=942%2C530&amp;ssl=1"></figure></div>



<h3>3. Add Scenes</h3>



<p>Now, you will want to create a game scene by clicking on the plus sign in <code>Scenes</code>. A new window will pop up where you can name it.</p>



<div><figure><img width="1024" height="576" src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Scenes.png?resize=1024%2C576&amp;ssl=1" alt="Set up OBS Studio for Recording" srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Scenes.png?resize=1024%2C576&amp;ssl=1 1024w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Scenes.png?resize=300%2C169&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Scenes.png?resize=768%2C432&amp;ssl=1 768w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Scenes.png?resize=1536%2C864&amp;ssl=1 1536w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Scenes.png?resize=1200%2C675&amp;ssl=1 1200w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Scenes.png?w=1600&amp;ssl=1 1600w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20576'%3E%3C/svg%3E" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Scenes.png?resize=1024%2C576&amp;ssl=1 1024w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Scenes.png?resize=300%2C169&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Scenes.png?resize=768%2C432&amp;ssl=1 768w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Scenes.png?resize=1536%2C864&amp;ssl=1 1536w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Scenes.png?resize=1200%2C675&amp;ssl=1 1200w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Scenes.png?w=1600&amp;ssl=1 1600w" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Scenes.png?resize=1024%2C576&amp;ssl=1"></figure></div>



<h3>4. Capture Your Game</h3>



<p>After creating an in-game scene, keep it selected and click on the <code>+</code> sign in <code>Sources</code>, and select <code>Game Capture</code>. This will open up the properties and let you pick which game you want to record.</p>



<div><figure><img width="562" height="380" src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Game-Capture.png?resize=562%2C380&amp;ssl=1" alt="Set up OBS Studio for Recording" srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Game-Capture.png?w=562&amp;ssl=1 562w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Game-Capture.png?resize=300%2C203&amp;ssl=1 300w" sizes="(max-width: 562px) 100vw, 562px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20562%20380'%3E%3C/svg%3E" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Game-Capture.png?w=562&amp;ssl=1 562w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Game-Capture.png?resize=300%2C203&amp;ssl=1 300w" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Game-Capture.png?resize=562%2C380&amp;ssl=1"></figure></div>



<p>For <code>Mode</code> make sure it’s set to <code>Capture</code> any fullscreen application. Once you start playing your game, OBS will automatically focus on it.</p>



<p>Nowadays, many games have an anti-cheat system that might affect OBS Studio. For this reason, you should select <code>Use anti-cheat compatibility hook</code>. Don’t worry, you won’t get banned for it.</p>



<p>If you enable 3rd party overlays like Discord or Steam, OBS will try and capture them as well. However, this does not always work, so make sure to check the preview window.</p>



<div><figure><img width="717" height="605" src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-capture.png?resize=717%2C605&amp;ssl=1" alt="Set up OBS Studio for Recording" srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-capture.png?w=717&amp;ssl=1 717w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-capture.png?resize=300%2C253&amp;ssl=1 300w" sizes="(max-width: 717px) 100vw, 717px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20717%20605'%3E%3C/svg%3E" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-capture.png?w=717&amp;ssl=1 717w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-capture.png?resize=300%2C253&amp;ssl=1 300w" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/OBS-capture.png?resize=717%2C605&amp;ssl=1"></figure></div>



<p>Once you are done with the setup, click OK and exit. Your game should now be displayed in the OBS.</p>



<h3>5. Add your Webcam</h3>



<p>Go back to the <code>+</code> sign in <code>Sources</code> and select <code>Video Capture Device</code>.</p>



<div><figure><img width="500" height="393" src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Video-Capture.png?resize=500%2C393&amp;ssl=1" alt="Set up OBS Studio for Recording" srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Video-Capture.png?w=500&amp;ssl=1 500w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Video-Capture.png?resize=300%2C236&amp;ssl=1 300w" sizes="(max-width: 500px) 100vw, 500px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20500%20393'%3E%3C/svg%3E" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Video-Capture.png?w=500&amp;ssl=1 500w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Video-Capture.png?resize=300%2C236&amp;ssl=1 300w" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/12/Video-Capture.png?resize=500%2C393&amp;ssl=1"></figure></div>



<p>That will take you to the <code>Properties</code>. Make sure that you select the right webcam and OBS will set it up. By default, <code>Resolution Type</code> is set to custom. If you want to change it, we recommend choosing either <code>1080p</code> or <code>720p</code>. Hit <code>OK</code> and your webcam will appear under <code>Scenes</code>. Just drag it where you want and resize if needed.</p>



<p>And that’s it! You are now ready to start recording videos in OBS Studio.</p>



<p>Hope you were able to follow this guide and set up your computer to record using <a href="https://obsproject.com/" target="_blank" rel="noopener">OBS Studio</a>. Have fun recording your screen, or games! Let us know if you have any tips for setting up your OBS Studio installation and we’ll publish it. Thanks! </p>



<hr>

<!-- MOLONGUI AUTHORSHIP PLUGIN 4.2.11 -->
<!-- https://www.molongui.com/authorship/ -->

<div id="mab-6131592810" data-plugin-release="4.2.11" data-plugin-version="free" data-box-layout="slim" data-box-position="below" data-multiauthor="false" data-author-type="user" itemscope="" itemtype="https://schema.org/Person">

	
    <!-- Author headline -->
    <p>
        <h3>
            <span>About The Author</span>
        </h3>
    </p>

    <div>

        <div data-profile-layout="layout-1" data-author-ref="user-194568617">
            
<!-- End of .m-a-box-content-top -->

<div>

    <!-- Author picture -->
    
	<p><a href="https://ottverse.com/author/vkr2020/">
                    <img alt="" src="https://secure.gravatar.com/avatar/1b73140b34f836d184d53fbb00f406dd?s=150&amp;d=mp&amp;r=g" srcset="https://secure.gravatar.com/avatar/1b73140b34f836d184d53fbb00f406dd?s=300&amp;d=mp&amp;r=g 2x" height="150" width="150" itemprop="image" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7">                </a>
                	</p>

    <!-- Author social -->
    
    <!-- Author data -->
    <div>

        <!-- Author name -->
        

        <!-- Author metadata -->
        

        <!-- Author bio -->
        
<div itemprop="description">
	<p>I’m Dr. Krishna Rao Vijayanagar, and I am the Founder and Editor of OTTVerse.com. I've spent several years working hands-on with Video Codecs (AVC, HEVC, MultiView Plus Depth), ABR streaming, and Video Analytics (QoE, Content &amp; Audience, and Ad). I hope to use my experience and love for video streaming to bring you information and insights into the OTT universe. Please use the Contact Page to get in touch with me.</p>
</div>

        
            <!-- Author related posts -->
            <!-- End of .m-a-box-related -->

        
    </div><!-- End of .m-a-box-data -->

</div><!-- End of .m-a-box-content-middle -->

<!-- End of .m-a-box-content-bottom -->        </div><!-- End of .m-a-box-profile -->

        
    </div><!-- End of .m-a-box-container -->

	
</div><!-- End of .m-a-box -->

		
		
			</div><!-- .entry-content .clear -->
</div>

	
</article><!-- #post-## -->


<!-- #comments -->

					
					
				
			</main><!-- #main -->
			
		
	</div><!-- #primary -->


	<!-- #secondary -->


			
			</div> <!-- ast-container -->

		</div></div>]]>
            </description>
            <link>https://ottverse.com/setup-obs-studio-for-recording-screen-tutorial/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25369651</guid>
            <pubDate>Thu, 10 Dec 2020 04:19:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Crossminds.ai – A knowledge graph indexed AI research video library]]>
            </title>
            <description>
<![CDATA[
Score 87 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25369075">thread link</a>) | @tecresearch
<br/>
December 9, 2020 | https://crossminds.ai/explore/ | <a href="https://web.archive.org/web/*/https://crossminds.ai/explore/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://crossminds.ai/explore/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25369075</guid>
            <pubDate>Thu, 10 Dec 2020 02:54:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Running Google Firestore Locally]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25368698">thread link</a>) | @adrianancona
<br/>
December 9, 2020 | https://ncona.com/2020/12/running-google-firestore-locally/ | <a href="https://web.archive.org/web/*/https://ncona.com/2020/12/running-google-firestore-locally/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>In a previous article, <a href="https://ncona.com/2020/12/introduction-to-google-firestore/">we started playing with Google Firestore</a>. In this article we are going to learn how we can test our applications without the need to talk to Google Cloud.</p>

<p>Note that the local version of Google Firestore is intended for testing only and shouldn’t be used for production systems. It doesn’t provide the reliability or scalability features that the real Firestore does.</p>

<h2 id="firebase-emulator-suite">Firebase emulator suite</h2>

<p>Google provides this suite to help developers test applications without having to use production data or incur cost. The suite doesn’t only emulate the database, but also cloud functions and real-time functionality, to name a couple. In this article we’re only going to focus on the Firestore database.</p>

<!--more-->

<h2 id="firebase-cli">Firebase CLI</h2>

<p>We start by installing the <a href="https://firebase.google.com/docs/cli">Firebase CLI</a>:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>curl -sL https://firebase.tools | bash
</pre></td></tr></tbody></table></code></pre></div></div>

<p>We can then start an instance of Firestore:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>firebase emulators:start --only firestore
</pre></td></tr></tbody></table></code></pre></div></div>

<p>As part of the output we will get something like this:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
</pre></td><td><pre>┌───────────┬────────────────┐
│ Emulator  │ Host:Port      │
├───────────┼────────────────┤
│ Firestore │ localhost:8080 │
└───────────┴────────────────┘
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Port <code>8080</code> is the default for Firestore. When the emulator starts it will look for a file named <code>firebase.json</code> where we can override the port:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
</pre></td><td><pre><span>{</span><span>
  </span><span>"emulators"</span><span>:</span><span> </span><span>{</span><span>
    </span><span>"firestore"</span><span>:</span><span> </span><span>{</span><span>
      </span><span>"port"</span><span>:</span><span> </span><span>"9999"</span><span>
    </span><span>}</span><span>
  </span><span>}</span><span>
</span><span>}</span><span>
</span></pre></td></tr></tbody></table></code></pre></div></div>

<p>One important thing to keep in mind about the emulator is that the data will be lost every time the emulator is stoped.</p>

<h2 id="connecting-to-the-emulator">Connecting to the emulator</h2>

<p>In <a href="https://ncona.com/2020/12/introduction-to-google-firestore/">Introduction to Google Firestore</a> we learned how to create a firestore client:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
</pre></td><td><pre><span>// Constants necessary to create the firestore client</span>
<span>const</span> <span>GcpCredentialsFile</span> <span>=</span> <span>"/tmp/my-key.json"</span>
<span>const</span> <span>ProjectId</span> <span>=</span> <span>"project-12345"</span>

<span>// When done with the client, close it using:</span>
<span>// defer client.Close()</span>
<span>func</span> <span>createClient</span><span>(</span><span>ctx</span> <span>context</span><span>.</span><span>Context</span><span>)</span> <span>*</span><span>firestore</span><span>.</span><span>Client</span> <span>{</span>
  <span>client</span><span>,</span> <span>err</span> <span>:=</span> <span>firestore</span><span>.</span><span>NewClient</span><span>(</span><span>ctx</span><span>,</span> <span>ProjectId</span><span>,</span> <span>option</span><span>.</span><span>WithCredentialsFile</span><span>(</span><span>GcpCredentialsFile</span><span>))</span>

  <span>if</span> <span>err</span> <span>!=</span> <span>nil</span> <span>{</span>
    <span>log</span><span>.</span><span>Fatalf</span><span>(</span><span>"Failed to create client: %v"</span><span>,</span> <span>err</span><span>)</span>
  <span>}</span>

  <span>return</span> <span>client</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>To tell our app that we want to use the emulator, we need to set an environment variable:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre><span>export </span><span>FIRESTORE_EMULATOR_HOST</span><span>=</span>localhost:8080
</pre></td></tr></tbody></table></code></pre></div></div>

<p>This will cause the credentials to be ignored, and the client will connect to the emulator instead.</p>

<h2 id="conclusion">Conclusion</h2>

<p>This was a quick article to show how we can easily start a local version of Google Firestore that can be used for testing. The emulator provides a lot of advanced features, but I haven’t had the need for them, so I haven’t dived into them.</p>

  </div></div>]]>
            </description>
            <link>https://ncona.com/2020/12/running-google-firestore-locally/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25368698</guid>
            <pubDate>Thu, 10 Dec 2020 02:07:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Programming the ATtiny10]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25368633">thread link</a>) | @taf2
<br/>
December 9, 2020 | http://www.technoblogy.com/show?1YQY | <a href="https://web.archive.org/web/*/http://www.technoblogy.com/show?1YQY">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

<p>11th November 2017</p>
<p>This article describes how to program the ATtiny10, Microchip's diminuitive 6-pin processor, using the Arduino IDE. It's a great chip for building small gadgets and wearables, or designing interface logic for other projects, and it really lives up to its "tiny" name:</p>
<p><img src="http://www.technoblogy.com/pictures/kvm/attiny10.jpg" alt="ATtiny10.jpg" width="250" height="300"></p>
<p>The following sections explain how to program the ATtiny10 in C, and how to download programs using a low-cost ISP programmer. It also illustrates some simple applications with example programs.</p>
<p>For a couple of projects based on the ATtiny10 see&nbsp;<a href="http://www.technoblogy.com/show?201J">ATtiny10 POV Pendant</a>&nbsp;and&nbsp;<a href="http://www.technoblogy.com/show?2G8A">ATtiny10 Thermometer</a>.</p>
<h3><span>Introduction</span></h3>
<p>If, like me, you like using the simplest possible chip for each application, the ATtiny10 will appeal to you&nbsp;<sup id="cite_ref1"><a href="#cite_note1">[1]</a></sup>; it's a 6-pin processor, about the same size as an 0805 SMD resistor, and it costs about 35p/35¢. It packs in the following features:</p>
<ul>
<li>Internal 8MHz clock, by default prescaled to 1MHz.</li>
<li>Three I/O lines.</li>
<li>Two 16-bit PWM analogue outputs.</li>
<li>Three 8-bit analogue inputs.</li>
<li>An analogue comparator.</li>
<li>A 16-bit timer with input capture and an event counter.</li>
<li>A watchdog timer.</li>
<li>1024 bytes of program memory, 32 bytes of RAM, and no EEPROM.</li>
</ul>
<p>All of these features will be familiar to users of the larger AVR chips. Here's the pinout (using Spence Konde's design conventions):</p>
<p><img src="http://www.technoblogy.com/pictures/kvm/attiny10pinout.gif" alt="ATtiny10Pinout.gif" width="701" height="159"></p>
<p>The internal oscillator is accurate to within 10%, but you can calibrate it in software to within 1%. You can configure RESET as a fourth I/O line, which prevents further programming, but I don't cover that in this article.</p>
<p>To work with the ATtiny10 on a breadboard you can mount it on a SOT23 breakout board, such as the one available from Sparkfun <sup id="cite_ref2"><a href="#cite_note2">[2]</a></sup>.</p>
<h3>Programming the ATtiny10</h3>
<p>Unlike the SPI protocol used to program the larger AVR chips, such as the ATmega328 in the Arduino Uno, the ATtiny10 uses a programming protocol called TPI (Tiny Programming Interface) which needs only five wires. Fortunately Thomas Fischl's excellent USBasp programmer supports this protocol&nbsp;<sup id="cite_ref3"><a href="#cite_note3">[3]</a></sup>; you can build your own, order one from his site, or they are widely available on eBay&nbsp;<sup id="cite_ref4"><a href="#cite_note4">[4]</a></sup>, Banggood&nbsp;<sup id="cite_ref5"><a href="#cite_note5">[5]</a></sup>, etc. I recommend getting one with a 10-pin to 6-pin adapter for ISP programming. The current versions of the Arduino IDE support the ATtiny10, so you can program it in C and upload programs as easily as with the other AVR chips. Since an Arduino core would use up almost half of the available program memory the best way to program it is to access the registers directly, and I give an overview of how to do this in the section&nbsp;<a href="#Alternatives">Alternatives to core functions</a>&nbsp;below.</p>
<p>Here are step-by-step instructions for programming the ATtiny10.</p>
<p>NOTE: There is a problem with compiling for the ATtiny10 with versions of the Arduino IDE 1.8.9 and higher. If necessary, run version 1.8.8 to do this, or for a workaround see the Disqus comments below.</p>
<ul>
<li>Download the <strong>ATtiny10Core</strong> hardware configuration from my repository on GitHub <a href="https://github.com/technoblogy/attiny10core" target="_blank">ATtiny10Core</a>.</li>
<li>Copy it to the&nbsp;<strong>hardware</strong>&nbsp;folder in your&nbsp;<strong>Arduino</strong>&nbsp;folder in your <strong>Documents</strong> folder. If there isn't already a <strong>hardware</strong> folder there, create one first.</li>
<li>Restart the Arduino IDE.</li>
</ul>
<p>This should add an&nbsp;<strong>ATtiny10Core</strong>&nbsp;heading to the <strong>Board</strong> menu.</p>
<ul>
<li>Enter your program into the Arduino IDE editor.</li>
</ul>
<p>For example, try the&nbsp;<strong>Blink</strong>&nbsp;example program given below.</p>
<ul>
<li>Connect the USBasp to the ATtiny10 as shown in the following diagram:</li>
</ul>
<p><img src="http://www.technoblogy.com/pictures/kvm/attiny10usbasp.gif" alt="ATtiny10USBasp.gif" width="203" height="157"></p>
<p><em>Connecting the USBasp programmer to an ATtiny10.</em></p>
<ul>
<li>Choose&nbsp;<strong>Board</strong>&nbsp;from the&nbsp;<strong>Tools</strong>&nbsp;menu, and select the&nbsp;<strong>ATtiny10/9/5/4</strong>&nbsp;option under the <strong>ATtiny10Core</strong> heading; it's the only option.</li>
<li>Choose the chip you want from the <strong>Chip</strong> menu; for example&nbsp;<strong>ATtiny10</strong>.</li>
<li>Choose <strong>USBasp</strong> from the&nbsp;<strong>Programmer&nbsp;</strong>option on the&nbsp;<strong>Tools</strong>&nbsp;menu.</li>
<li>Choose&nbsp;<strong>Upload</strong>&nbsp;to upload the program.</li>
</ul>
<p>The LED should blink at 0.5Hz.</p>
<p>Here's my test setup on a mini breadboard:</p>
<p><img src="http://www.technoblogy.com/pictures/kvm/usbasp.jpg" alt="USBasp.jpg" width="680" height="324"></p>
<p><em>Testing the ATtiny10 Blink program on a mini breadboard, using the USBasp programmer.</em></p>
<h3>Examples</h3>
<p>Here are a couple of examples using the ATtiny10:</p>
<h4>Blink</h4>
<p>This is the ubiquitous Blink program:</p>
<pre>#include &lt;avr/io.h&gt;
#include &lt;stdint.h&gt;

int main (void) {
  DDRB = 1;                       // PB0 as an output
  TCCR0A = 1&lt;&lt;COM0A0 | 0&lt;&lt;WGM00;  // Toggle OC0A, CTC mode
  TCCR0B = 1&lt;&lt;WGM02 | 3&lt;&lt;CS00;    // CTC mode; use OCR0A; /64
  OCR0A = 15624;                  // 1 second; ie 0.5Hz
  while (1);
}</pre>
<p>To run it connect an LED to PB0 as follows:</p>
<p><img src="http://www.technoblogy.com/pictures/kvm/attiny10usbasp2.gif" alt="ATtiny10USBasp2.gif" width="157" height="128"></p>
<p><em>Circuit using an ATtiny10 to blink an LED.</em></p>
<p>It uses Timer/Counter0 to divide the 1MHz system clock by a prescaler value of 64, and then by 15625, toggling the output PB0 with a period of 1 second.</p>
<h4>Analogue frequency generator</h4>
<p>The following program reads the voltage from a potentiometer on analogue input ADC1 (PB1), and then uses this to set the compare match register OCR0A of Timer/Counter0, to generate a square wave on PB0 whose frequency you can control with the potentiometer:</p>
<pre>#include &lt;avr/io.h&gt;
#include &lt;stdint.h&gt;

int main (void) {
  DDRB = 1;                       // PB0 as an output
  // Set up ADC on PB2
  ADMUX = 1&lt;&lt;MUX0;                // ADC1 (PB1)
  ADCSRA = 1&lt;&lt;ADEN | 3&lt;&lt;ADPS0;    // Enable ADC, 125kHz clock
  // Set up waveform on PB0
  TCCR0A = 1&lt;&lt;COM0A0 | 3&lt;&lt;WGM00;  // Toggle OC0A, Fast PWM
  TCCR0B = 3&lt;&lt;WGM02 | 4&lt;&lt;CS00;    // Fast PWM with OCR0A as TOP; /256
  // Main loop
  for (;;) {
    ADCSRA = ADCSRA | 1&lt;&lt;ADSC;    // Start
    while (ADCSRA &amp; 1&lt;&lt;ADSC);     // Wait while conversion in progress
    OCR0A = ADCL;                 // Copy result to frequency output
  }
}</pre>
<p>Note that because we're changing the compare match value, we need to use Fast PWM mode in this application, because it double-buffers the compare match value. Here's the circuit:</p>
<p><img src="http://www.technoblogy.com/pictures/kvm/attiny10usbasp3.gif" alt="ATtiny10USBasp3.gif" width="247" height="132"></p>
<p><em>Circuit using a potentiometer to adjust the frequency of a square wave generated by an ATtiny10.</em></p>
<p>It generates a frequency between 1MHz/256/256, or about 15Hz, and 1MHz/256/1, or 3.9kHz.</p>
<h3 id="Alternatives">Alternatives to core functions</h3>
<p>The following sections give some tips on programming the ATtiny10 to achieve some of the things provided by the Arduino core functions.</p>
<h4>includes</h4>
<p>You need to add these includes at the start of your program to include the AVR register definitions and standard C++ routines:</p>
<pre>#include &lt;avr/io.h&gt;
#include &lt;stdint.h&gt;</pre>
<h4>setup and loop</h4>
<p>Arduino programs are normally written with the initialization in&nbsp;<strong>setup()</strong>&nbsp;and the main program in&nbsp;<strong>loop()</strong>, rather than the standard&nbsp;<strong>int&nbsp;main()</strong>&nbsp;function required by C. If you want to keep to this convention you'll need to add the following definition at the end of your program:</p>
<pre>int main() {
  setup();
  for(;;) loop();
}</pre>
<h4>pinMode</h4>
<p>To specify whether pins are inputs or outputs you set the corresponding bits in the <strong>DDRB</strong> register to 0 or 1 respectively. For example, to define pins 1 and 3 as outputs (and leave the other pins as inputs):</p>
<pre>DDRB = 0b0101; &nbsp; &nbsp;     // Equivalent to pinMode(1, OUTPUT); pinMode(3, OUTPUT);</pre>
<h4>Input pullups</h4>
<p>Unlike the older AVR chips, such as the ATmega328 and ATtiny85, the ATtiny10 enables pullup resistors using a separate pullup register, <strong>PUEB</strong>. To set pullups on input pins you set the corresponding bits in this&nbsp;register. For example, to set a pullup resistor on input pin 2:</p>
<pre>PUEB = 0b0010;         // Equivalent to pinMode(2, INPUT_PULLUP);</pre>
<p>Note that it doesn't make sense to set a pullup on an output.</p>
<h4>digitalWrite</h4>
<p>To set the state of an output you set the corresponding bits in the <strong>PORTB</strong> register. For example, to set bit 1 low and bit 3 high (assuming they have been defined as outputs):</p>
<pre>PORTB = 0b0100;        // Equivalent to&nbsp;digitalWrite(1, LOW);&nbsp;digitalWrite(3, HIGH);</pre>
<p>Changing the state of&nbsp;an input has no effect.</p>
<h4>digitalRead</h4>
<p>To read the state of the I/O pins you read the <strong>PINB</strong> register:</p>
<pre>int temp = PINB;</pre>
<h4>analogWrite</h4>
<p>You can use OC0A (PB0) and OC0B (PB1) for analogue output using PWM. You first need to configure the Timer/Counter into PWM mode for that pin; for example, using PB0:</p>
<pre>TCCR0A = 2&lt;&lt;COM0A0 | 3&lt;&lt;WGM00; // 10-bit PWM on OC0A (PB0), non-inverting mode
TCCR0B = 0&lt;&lt;WGM02 | 1&lt;&lt;CS00;   // Divide clock by 1
DDRB = 0b0001;                 // Make PB0 an output</pre>
<p>To write an analogue value we then need to write the value to the appropriate output compare register, OCR0A:</p>
<pre>OCR0A = 1000;                  // Equivalent to analogWrite(0, 1000)</pre>
<p>With a 5V supply this will set PB0 to 1000/1024 * 5V, or 4.88V.</p>
<h4>analogRead</h4>
<p>To use an I/O pin for analogue input you first need to configure the Analogue-to-Digital Converter. For example, to use ADC0:</p>
<pre>ADMUX = 0&lt;&lt;MUX0;               // ADC0 (PB0)
ADCSRA = 1&lt;&lt;ADEN | 3&lt;&lt;ADPS0;   // Enable ADC, 125kHz clock</pre>
<p>To read an analogue value from the pin we then need to start a conversion, and when the conversion is ready read the ADC register:</p>
<pre>ADCSRA = ADCSRA | 1&lt;&lt;ADSC;     // Start
while (ADCSRA &amp; 1&lt;&lt;ADSC);      // Wait while conversion in progress
int temp = ADCL;               // Copy result to temp
</pre>
<h4>delay</h4>
<p>For a simple substitute for&nbsp;<strong>delay()</strong>&nbsp;you can use a loop adjusted to give roughly the right timing:</p>
<pre>void delay (int millis) {
  for (volatile unsigned int i = 34*millis; i&gt;0; i--);
}</pre>
<p>This would provide an alternative way of writing the Blink program. Note that the counter variable&nbsp;<strong>i</strong>&nbsp;must be defined as&nbsp;<strong>volatile</strong>&nbsp;or the compiler will optimise it out of the loop, eliminating the delay.</p>
<p>For more accurate delays, and to implement timers like&nbsp;<strong>millis()</strong>, you could set up Timer/Counter0 as a timer, or use the Watchdog Timer.</p>
<h3>Update</h3>
<p>30th December 2019: Added a note about problems compiling for the ATtiny10 with versions of the Arduino IDE 1.8.9 or later. Use 1.8 to 1.8.8.</p><hr>
<ol>
<li id="cite_note1"><a href="#cite_ref1">^</a> <a href="http://ww1.microchip.com/downloads/en/DeviceDoc/Atmel-8127-AVR-8-bit-Microcontroller-ATtiny4-ATtiny5-ATtiny9-ATtiny10_Datasheet.pdf">ATtiny10 Datasheet</a> on Microchip.</li>
<li id="cite_note2"><a href="#cite_ref2">^</a> <a href="https://www.sparkfun.com/products/717" target="_blank">Sparkfun SOT23 to DIP Adapter</a> on Sparkfun.</li>
<li id="cite_note3"><a href="#cite_ref3">^</a> <a href="http://www.fischl.de/usbasp/" target="_blank">USBasp - USP programmer for Atmel AVE controllers</a>&nbsp;on www.fischl.de.</li>
<li id="cite_note4"><a href="#cite_ref4">^</a> <a href="https://www.ebay.co.uk/itm/USBASP-USBISP-ISP-Programmer-Cable-Adapter-KK2-0-KK2-1-Atmel-AVR-ATMega-ARDUINO/131241223483" target="_blank">USBASP ISP Programmer Cable Adapter</a>&nbsp;from Boos Bits on eBay.</li>
<li id="cite_note5"><a href="#cite_ref5">^</a> <a href="https://www.banggood.com/USBASP-USBISP-3_3-5V-AVR-Downloader-Programmer-With-ATMEGA8-ATMEGA128-p-934425.html" target="_blank">USBASP 3.3 5V AVR Downloader Programmer</a>&nbsp;on Banggood.</li>
</ol>

<hr>


<p><a href="http://disqus.com/">blog comments powered by </a></p></div></div>]]>
            </description>
            <link>http://www.technoblogy.com/show?1YQY</link>
            <guid isPermaLink="false">hacker-news-small-sites-25368633</guid>
            <pubDate>Thu, 10 Dec 2020 02:01:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Behind the scenes photos of YC S20]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25368499">thread link</a>) | @cheeseblubber
<br/>
December 9, 2020 | https://papercups.io/blog/what-remote-demo-day-looked-like | <a href="https://web.archive.org/web/*/https://papercups.io/blog/what-remote-demo-day-looked-like">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://papercups.io/blog/what-remote-demo-day-looked-like</link>
            <guid isPermaLink="false">hacker-news-small-sites-25368499</guid>
            <pubDate>Thu, 10 Dec 2020 01:45:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How eBPF Works]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25367728">thread link</a>) | @gk1
<br/>
December 9, 2020 | https://goteleport.com/blog/what-is-ebpf/ | <a href="https://web.archive.org/web/*/https://goteleport.com/blog/what-is-ebpf/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      
      <a href="https://goteleport.com/blog/index.xml"><i></i></a>
      
      

        

<p><img src="https://goteleport.com/blog/images/2020/what-is-ebpf-header.png" width="100%" alt="what is ebpf"></p>

<p>About a year ago, a friend of mine decided to build an <a href="https://medium.com/mycrypto/the-ethereum-virtual-machine-how-does-it-work-9abac2b7c9e">EVM</a> (Ethereum Virtual Machine) assembler in Rust. After some prodding from him, I began to help by writing unit tests. At the time, I knew very little about operating systems and started to read about lexical and symbolical analyzers. I was quickly in way over my head. What I did retain, however, was a newfound appreciation for the OS as a whole. So, when he started raving about eBPF, I knew I was in for a treat.</p>

<p>The bar for understanding what eBPF is and what it can do is high. Finding a good foothold to start was difficult for me. On the spectrum of basic 500-word mini-blogs to <a href="https://cilium.io/">Cilium’s</a> overwhelming documentation, material certainly skews towards documentation. My goal here is to provide a thorough entrypoint into this nascent technology, preparing you for progressively technical deep dives, like <a href="https://lwn.net/Articles/740157/">Linux Weekly News</a>, <a href="http://www.brendangregg.com/index.html">Brendan Gregg’s</a> website, and Cilium’s <a href="https://docs.cilium.io/en/stable/bpf/">documentation</a>. Together, we will explore:</p>

<ul>
<li>What eBPF does</li>
<li>How eBPF works</li>
<li>An example of eBPF in use</li>
<li>How to start using eBPF</li>
</ul>

<h2 id="what-does-ebpf-do">What Does eBPF Do?</h2>

<p>eBPF lets programmers execute custom bytecode within the kernel <em>without</em> having to change the kernel or load kernel modules. Exciting? Maybe not yet. eBPF is closely intertwined with the Linux kernel. For context, let’s briefly review some fundamental concepts.</p>

<p>Linux divides its OS into two distinct areas: kernel space and user space. Kernel space is where the core of the operating system resides. It has full and unrestricted access to all hardware - memory, storage, CPU, etc. Due to the privileged nature of kernel access, the space is protected and allowed to run only the most trusted code. User space is where anything that is not a kernel process runs - I/O, file system manipulation, etc. These programs have limited access to hardware and must make syscalls through an API exposed by the kernel. In other words, user space programs must be filtered through the kernel space.</p>

<p>While the system call interface was sufficient in most cases, developers need more flexibility to add support for new hardware, filesystems, network protocols, or even custom system calls. There had to be a way for custom programs to access hardware directly, a way to extend the base kernel without adding directly to the kernel source code. <a href="https://tldp.org/LDP/lkmpg/2.6/html/lkmpg.html">Linux Kernel Modules</a> (LKMs) serve this function. Unlike system calls, whereby requests traverse from the user space to kernel space, LKMs are loaded directly into the kernel, making them a part of it. Perhaps the most valuable feature of LKMs is that it can be loaded at runtime, removing the need to recompile the entire kernel and reboot the machine.</p>

<p><img src="https://goteleport.com/blog/images/2020/what-is-ebpf-1.png" width="60%" alt="LKMs in kernel space"></p>

<p>Figure 1 - LKMs can be dynamically loaded and unloaded as part of kernel space (<a href="http://derekmolloy.ie/writing-a-linux-kernel-module-part-1-introduction/">Source</a>)</p>

<p>As helpful as LKMs are, they do introduce a lot of risk to the system. The division of kernel and user spaces added a number of security measures to the OS. The kernel space is meant to run only a privileged OS kernel. The layer between, connected by the system call interface, separated user space programs that could mess with finely tuned hardware. In other words, LKMs could certainly crash the kernel. Aside from the wide blast radius of security vulnerabilities, modules incur a large overhead maintenance cost in that kernel version upgrades could break the module.</p>

<h4 id="what-is-ebpf">What is eBPF</h4>

<p>eBPF programs are a more recent invention for accessing services and hardware from the Linux kernel space. Already these programs have been used for networking, debugging, tracing, firewalls, and more.</p>

<p>Born out of a need for better Linux tracing tools, eBPF drew inspiration from <code>dtrace</code>, a dynamic tracing tool available primarily for Solaris and BSD operating systems. Unlike <code>dtrace</code>, Linux could not get a global overview of running systems, it was limited to specific frameworks for system calls, library calls, and functions. Building on the Berkeley Packet Filter (BPF), a tool for writing packer-filtering code using an in-kernel VM, a small group of engineers began to extend the BPF backend to provide a similar set of features as <code>dtrace</code>. First released in limited capacity in 2014 with Linux 3.18, making full use of eBPF requires at least Linux 4.4 or above.</p>

<p><img src="https://goteleport.com/blog/images/2020/what-is-ebpf-2.png" width="100%" alt="simplified visualization of eBPF architecture"></p>

<p>Figure 2</p>

<p>In Figure 2, we see a simplified visualization of eBPF architecture. Before being loaded into the kernel, the eBPF program must pass a certain set of requirements. Verification involves executing the eBPF program within the virtual machine. Doing so allows the <a href="https://github.com/torvalds/linux/blob/master/kernel/bpf/verifier.c">verifier</a>, with 10,000+ lines of code, to perform a series of checks. The verifier will traverse the potential paths the eBPF program may take when executed in the kernel, making sure the program does indeed run to completion without any looping that would cause a kernel lockup. Other checks, from valid register state, program size, to out of bound jumps, must also be met. Almost immediately, eBPF sets itself apart from LKMs with important safety controls in place.</p>

<p>If all checks are passed, the eBPFprogram is loaded and compiled into the kernel at a point in a code path and listens for the right signal. That signal comes in the form of an event that passes where the program is loaded in the code path. Once triggered, the bytecode executes and collects information as per its instructions.</p>

<p>So what does eBPF do? It lets programmers safely execute custom bytecode within the Linux kernel without modifying or adding to kernel source code. While still a far cry from replacing LKMs as a whole, eBPF programs introduce custom code to interact with protected hardware resources with minimal threat to the kernel.</p>

<h2 id="how-ebpf-works">How eBPF Works</h2>

<p>So far, I’ve reduced eBPF to its bare architecture. But, there are more components working together, each of which has layers of complexity of their own.</p>

<h3 id="anatomy-of-an-ebpf-program">Anatomy of an eBPF Program</h3>

<h4 id="events-and-hooking">Events and Hooking</h4>

<p>eBPF programs are triggered by events that pass a particular location in the kernel. These events are captured at hooks when a specific set of instructions are executed in a single run. When triggered, these hooks will execute an eBPF program, letting us capture or manipulate data. The diversity of hook locations is one of the many aspects that makes eBPF so useful. A quick sampling of these locations include:</p>

<ul>
<li>System Calls - Inserted when user space functions transfer execution to the kernel</li>
<li>Function Entry and Exit - Intercepts calls to pre-existing functions</li>
<li>Network Events - Executes when packets are received</li>
<li>Kprobes and uprobes - Attach to probes for kernel or user functions</li>
</ul>

<h4 id="helper-calls">Helper Calls</h4>

<p>When eBPF programs are triggered at their hook points, they make calls to helper functions. These special functions are what makes eBPF feature-rich in accessing memory. For example, helpers can perform a wide variety of tasks:</p>

<ul>
<li>Search, update, and delete key-value pairs in tables</li>
<li>Generate a pseudo-random number</li>
<li>Collect and flag tunnel metadata</li>
<li>Chain eBPF programs together, known as tail calls</li>
<li>Perform tasks with sockets, like binding, retrieve cookies, redirect packets, etc.</li>
</ul>

<p>These helper functions must be defined by the kernel, meaning there is a whitelist of calls eBPF programs can make. But the <a href="https://man7.org/linux/man-pages/man7/bpf-helpers.7.html">number</a> is large and continues to grow.</p>

<h4 id="maps">Maps</h4>

<p>To store and share data between the program and kernel or user spaces, eBPF makes use of maps. As implied by the name, maps are key-value pairs. Supporting a number of different data structures, like hash tables, arrays, and tries, programs are able to send and receive data in maps using helper functions.</p>

<h3 id="executing-an-ebpf-program">Executing an eBPF Program</h3>

<h4 id="loading-and-verifying">Loading and Verifying</h4>

<p>The kernel expects all eBPF programs to be loaded as bytecode, so unless bytecode is being written, we need a way to compile higher level languages. To build out this compiler, eBPF uses <a href="https://llvm.org/">LLVM</a> as its back-end infrastructure on which a front-end for any programming language can be built. Because eBPF programs are written in C, that language front end is <a href="https://clang.llvm.org/">Clang</a>. But before compiled bytecode can be hooked anywhere, it must pass a series of checks. By simulating the program in a VM-like construct, an <a href="https://elixir.bootlin.com/linux/latest/source/kernel/bpf/verifier.c">in-kernel verifier</a> can prevent programs that loop, do not have the right permissions, or crash the kernel. If the program passes all checks, program bytecode will be loaded onto the hook point using a <code>bpf()</code> system call</p>

<h4 id="just-in-time-jit-compiler">Just-In-Time (JIT) Compiler</h4>

<p>After verification, eBPF bytecode is JIT’d into native machine code. eBPF has a modern design, meaning it has been upgraded to be 64-bit encoded with 11 total registers. This closely maps eBPF to hardware for x86_64, ARM, and arm64 architecture, amongst others. Fast compilation at runtime makes it possible for eBPF to remain performant even as it must first pass through a VM.</p>

<p><img src="https://goteleport.com/blog/images/2020/what-is-ebpf-3.png" width="100%" alt="eBPF architecture"></p>

<p>eBPF Architecture (<a href="https://lucid.app/invitations/accept/0096e31e-14f9-47d4-a1a0-57e82b3bc6f5">Raw LucidChart</a>)</p>

<h3 id="summary">Summary</h3>

<p>Putting this conceptual jigsaw together, eBPF programs are inserted into a hook point after passing a number of safety checks. When they are triggered by an event, programs execute immediately, using a combination of helper functions and maps to manipulate and store data. We’ll take a closer look at how these components work together in the next section</p>

<h2 id="example-ebpf-in-action">Example: eBPF in Action</h2>

<p>At Teleport, we’ve used a few eBPF programs in one of our open source projects, Teleport, for tracing and networking. For some necessary context: <a href="https://goteleport.com/teleport">Teleport</a> gives developers secure server access via SSH. Because organizations want to know what happens during a session, Teleport records user actions. Yet there are ways to bypass session recording entirely by obfuscating behavior within encoded commands, commands run in shell scripts, or even terminal commands like disabling <code>echo</code>.</p>

<p>Earlier this year with our <a href="https://goteleport.com/blog/teleport-release-4-2">Teleport 4.2 release</a>, we introduced <em>enhanced</em> session recording, which uses three eBPF programs (for now!) to take unstructured SSH sessions and transform them into a stream of structured events.</p>

<p>Consider <code>echo Y3VybCBodHRwOi8vd3d3LmV4YW1wbGUuY29tCg== | base64 --decode | sh</code>. Though we can capture this command printed in the terminal, it means nothing to us as the …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://goteleport.com/blog/what-is-ebpf/">https://goteleport.com/blog/what-is-ebpf/</a></em></p>]]>
            </description>
            <link>https://goteleport.com/blog/what-is-ebpf/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25367728</guid>
            <pubDate>Thu, 10 Dec 2020 00:27:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DOSBox-X 0.83.8 Released]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25367662">thread link</a>) | @fm77
<br/>
December 9, 2020 | https://dosbox-x.com/release-0.83.8.html | <a href="https://web.archive.org/web/*/https://dosbox-x.com/release-0.83.8.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div width="100%">
            <tbody><tr>
            <td></td>
            <td>
            <p>1. Notable New Features</p>
<ul>
<li><p>Scalable TrueType font (TTF) output for DOS applications</p>With the new TrueType font (TTF) output, you will get nice high resolution DOS screen rendered using a TrueType font (either the built-in one or a TTF font of your choice), and the window can be set to almost any usable number of lines and columns. This feature greatly improved DOSBox-X's support for DOS applications. Set "output=ttf" (or from the "Video" menu) to enable this output.</li>

<li><p>On-screen text styles for DOS applications</p>With the TrueType font output, DOSBox-X now supports on-screen text styles for DOS applications including WordPerfect, WordStar, and XyWrite. With this feature you will visually see fonts in bold for bold text, and fonts in italics for italicized text, and so on. Set a DOS word processor (WP/WS/XY) to enable this feature.</li>

<li><p>Support for Apple M1 Mac and macOS Big Sur</p>DOSBox-X now supports the new Apple ARM-based M1 MacBooks! The dynamic core now works on the new ARM-based macOS systems. The audio also works once again when compiled and run on macOS 11 Big Sur.</li>

<li><p>Pasting clipboard text in macOS SDL1 builds</p>Pasting text from the host system clipboard is now supported in the macOS SDL1 build, similar to the Linux SDL1 build. On all other platforms (Windows SDL1/SDL2, Linux SDL2, and macOS SDL2) both copying to and pasting from the clipboard are supported.</li>

<li><p>System menu in Windows SDL2 builds</p>The system menu that was available in Windows SDL1 builds is now also
available for Windows SDL2 builds, which includes a few common menu options such as the configuration tool and the mapper editor.</li>

<li><p>Select common host keys from the menu</p>You can now select a host key from the "Main" menu, which now includes common key combinations such as Ctrl+Alt, Ctrl+Shift, and Alt+Shift, or you may just use the mapper-defined host key (which default to F11 on Windows and F12
otherwise). The default shortcuts for a few items are changed to use the host key style.</li>

<li><p>Switch OpenGL (GLSL) shaders at run-time</p>With the OpenGL outputs (opengl/opengnb/openghq), you can now select and switch to a different GLSL shader at the run-time by selecting the menu item "Select OpenGL (GLSL) shader..." from the "Video" menu, similar to the function for Direct3D pixel shaders for the Direct3D output.</li>

<li><p>Display IDE disk or CD status</p>There is now a menu option under "DOS" menu which allows you to see the current assignments (disk or CD image) of the IDE controllers.</li>

<li><p>Support for mounting MAME CHD CD images</p>Mounting the MAME CHD images is now supported in DOSBox-X! You can mount CHD files as CD images with IMGMOUNT command, or from the "Drive" menu.</li>

<li><p>Support for saving your files for the save-state feature</p>There is a now a FLAGSAVE command which allows you to mark files to be saved and loaded by the save-state feature. Type "FLAGSAVE /?" at the DOSBox-X shell for more usage information.</li>

<li><p>Enhanced MODE command to change screen dimensions</p>You can now change the number of columns and lines on the screen with the
MODE command, similar to real DOS systems. Alternatively, this can be done from the "Video" menu (within "Text-mode" menu group).</li>

<li><p>Improved LOADFIX command to auto-allocate memory</p>The LOADFIX command now has an -a option which will automatically allocate enough memory to fill lowest 64KB memory instead of using exactly 64KB memory. This will let some memory-demanding DOS programs or games to run with this command.</li>

<li><p>Improved automatic fix for the "Packed file corrupt" error</p>The handler for the "Packed file corrupt" error has been greatly improved so that it will likely automatically handle the error more efficiently. There is now also an option to silence the messages during the automatic fix.</li>

</ul>

            <p>2. Notable Usability Improvements</p>
<ul>
<li><p>Improved mapper editor interface</p>The mapper editor interface has been enhanced! The texts for the shortcut functions are now longer and clearer, and there are now multiple pages in the mapper, navigable with the "Previous Page" and "Next Page" buttons.</li>

<li><p>Load DOSBox-X mapper files from menu</p>You can now select and load DOSBox-X mapper files at run-time from the "Main" menu. Previously it was possible to load a mapper file dynmically from the command line, but now you can do so from the menu too.</li>

<li><p>List network interfaces from menu</p>There is now a "List network interfaces" menu option under the "Help" menu that will list the current network interfaces for the NE2000 networking feature. Previously you can only see the network interface list from the log file.</li>

<li><p>Display DOS command help from menu</p>You can now find a "DOS commands" menu group under the "Help" menu, which allows you to select a DOS shell command (DIR, CD, etc) to see its help messages. Alternatively you can type "[COMMAND] /?" (e.g. "DIR /?") for help information for the command.</li>

<li><p>Searching for config file and mapper file in DOSBox-X executable path</p>DOSBox-X will now look for the config file (e.g.
dosbox-x.conf) and the mapper file in the directory containing the DOSBox-X executable too if they cannot be found in the DOSBox-X working directory. This makes DOSBox-X even more portable.</li>

<li><p>More saving options for the built-in configuration tool</p>The graphical configuration tool now provides the option to save
to the primary or user config files, not just the dosbox-x.conf file.</li>

<li><p>New config options for save state options</p>The config options "saveremark" and "forceloadstate" are added to [dosbox]
section which can be used to control the save state-related options from the config file. In the previous section these can only be done from the "Capture" menu.</li>

</ul>

            <p>3. Bugfixes and Other Improvements</p>
There are also many bugfixes and other improvements, such as fixing the CD audio issue with the game "The Secret of Monkey Island" when talking to the pirate in Scumm Bar. Please see the full changelogs below for more information.
<p>4. Full Changelog In This Version</p>
<ul>
<li>
Added support for scalable TrueType font (TTF)
output for text-mode programs. Set "output=ttf"
and optionally a monospaced TTF font (such as
consola) with config option "ttf.font" to use it.
Lines and columns can be specified with config
options "ttf.lins" and "ttf.cols", and the cursor
can be made blinking with the option "ttf.blinkc".
The config options "ttf.ptsize" and "ttf.winperc"
can be used to set the TTF font size and window
percentage respectively. If you specify a TTF font
size with "ttf.ptsize" then "ttf.winperc" will be
ignored. You can also specify a word processor
(WP=WordPerfect, WS=WordStar, XY=XyWrite) for the
on-screen text-style and 512-character font (WP)
features. When using the TTF output DOSBox-X will
temporarily switch to a different output when a
graphical mode is requested (or when trying to take
a screenshot); the TTF output will be auto-switched
back later), which can be customized via config
option "ttf.outputswitch" (which defaults to auto).
Menu items in the "Text-mode" menu group (under
"Video" menu) have been expanded to support TTF
options such as increasing/decreasing the TTF font
sizes and on-screen text style toggling (including
bold, italics, underline and strikeout). You can
also select a TTF font to use at run-time with the
"Select TrueType font (TTF)" menu option. (Wengier)
</li><li>
Added the "Load mapper file..." menu option (under
"Main") to select and load a DOSBox-X mapper file
at run-time. Be sure to select a SDL1 mapper file
for SDL1 builds, and similar for SDL2. (Wengier)
</li><li>
You can now select a host key from the menu (under
"Main") including Ctrl+Alt, Ctrl+Shift, Alt+Shift,
or use the mapper-defined host key as in previous
versions (which default to F11 on Windows and F12
otherwise). A config option "hostkey" is added so
that you can specify it from config file. (Wengier)
</li><li>
Pasting text from the clipboard on macOS SDL1 build
is now supported like Linux SDL1 build. (Wengier)
</li><li>
Added support for ARM-based Apple M1 MacBook. The
dynamic core now works on ARM-based macOS systems.
SDL1 builds updated to use newer audio APIs on the
macOS platform so that the audio works once again
when compiled and run on macOS 11 (Big Sur). Prior
to the change, ancient versions of the API dating
back to the mid 2000s were used which no longer
work on Big Sur.
</li><li>
DOSBox-X will now look for the config file (i.e.
dosbox-x.conf/dosbox.conf) and the mapper file in
the directory containing the DOSBox-X executable
too if the config or mapper file cannot be found
in the DOSBox-X working directory. (Wengier)
</li><li>
The system menu in Windows SDL1 builds is now also
available for Windows SDL2 builds, and menu items
"Reset font size", "Increase TTF font size" and
"Decrease TTF font size" are added. (Wengier)
</li><li>
Enhanced the mapper editor interface to allow more
keyboard shortcuts to be added, shown in multiple
pages in the mapper, navigable with the "Previous
Page" and "Next Page" buttons. The text in the
grids are now longer and clearer too. The default
shortcuts for a few items are changed to use the
Host key style (e.g. Host+S and Host+L for saving
and loading states respectively). (Wengier)
</li><li>
Added menu item "List network interfaces" under
"Help" menu to list network interfaces in the host
system for the NE2000 feature. (Wengier)
</li><li>
Added menu group "DOS commands" under "Help" menu
to display the help content for the selected DOS
shell command (DIR, CD, etc). (Wengier)
</li><li>
Configuration Tool now provides the option to save
to the primary or user config files. (Wengier)
</li><li>
Certain config options (e.g. doublescan) that were
marked as advanced options are now general config
options and will appear in dosbox-x.reference.conf
apart from dosbox-x.reference.full.conf. (Wengier)
</li><li>
Added config options "saveremark" (default: true)
and "forceloadstate" (default: false) in [dosbox]
section which can be used to control if DOSBox-X
should ask users to enter remarks when saving a
state or show warnings when loading a saved state
if there is a mismatch found. (Wengier)
</li><li>
The config option "pixelshader" is moved from the
section [gui] to [render] …</li></ul></td></tr></tbody></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dosbox-x.com/release-0.83.8.html">https://dosbox-x.com/release-0.83.8.html</a></em></p>]]>
            </description>
            <link>https://dosbox-x.com/release-0.83.8.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25367662</guid>
            <pubDate>Thu, 10 Dec 2020 00:22:12 GMT</pubDate>
        </item>
    </channel>
</rss>
